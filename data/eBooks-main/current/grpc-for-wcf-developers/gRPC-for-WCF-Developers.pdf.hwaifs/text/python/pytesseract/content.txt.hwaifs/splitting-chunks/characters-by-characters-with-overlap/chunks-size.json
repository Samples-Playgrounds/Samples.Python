"[\"ae Microsoft\\n\\ngRPC tor WCF\\nDevelopers\\n\\nMark Rendle\\nMiranda Steiner\\nmE Microsoft\\n\\nEDITION v7.0 - Updated to ASP.NET Core 7.0\\n\\nRefer changelog for the book updates and community contributions.\\nPUBLISHED BY\\n\\nMicrosoft Developer Division, .NET, and Visual Studio product teams\\nA division of Microsoft Corporation\\n\\nOne Microsoft Way\\n\\nRedmond, Washington 98052-6399\\n\\nCopyright \\u00a9 2023 by Microsoft Corporation\\n\\nAll rights reserved. No part of the contents o\", \"f this book may be reproduced or transmitted in any\\nform or by any means without the written permission of the publisher.\\n\\nThis book is provided \\u201cas-is\\u201d and expresses the author's views and opinions. The views, opinions and\\ninformation expressed in this book, including URL and other Internet website references, may change\\nwithout notice.\\n\\nSome examples depicted herein are provided for illustration only and are fictitious. No real association\\nor c\", \"onnection is intended or should be inferred.\\n\\nMicrosoft and the trademarks listed at https://www.microsoft.com on the \\u201cTrademarks\\u201d webpage are\\ntrademarks of the Microsoft group of companies.\\n\\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permission.\\nAll other marks and logos are property of their respective owners.\\nAuthors:\\n\\nMark Rendle - Chief Technical Officer - Visual Recode\\nMiranda Steiner - Technical Author\\nEditor:\\n\", \"\\nMaira Wenzel - Sr. Content Developer - Microsoft\\n\\nIntroduction\\n\\ngRPC is a modern framework for building networked services and distributed applications. Imagine\\nthe performance of Windows Communication Foundation (WCF) NetTCP bindings, combined with the\\ncross-platform interoperability of SOAP. gRPC builds on HTTP/2 and the Protobuf message-encoding\\nprotocol to provide high performance, low-bandwidth communication between applications and\\nservice\", \"s. It supports server and client code generation across most popular programming languages\\nand platforms, including .NET, Java, Python, Node.js, Go, and C++. With the first-class support for\\ngRPC in ASP.NET Core 7.0, alongside the existing gRPC tools and libraries for .NET Framework 4.x, it's\\nan excellent alternative to WCF for development teams looking to adopt .NET in their organizations.\\nmE Microsoft\\n\\nWho should use this guide\\n\\nThis guide was \", \"written for developers working in .NET Framework or .NET who have previously used\\nWCF, and who are seeking to migrate their applications to a modern RPC environment for .NET Core\\n3.0 and later versions. More generally, if you are upgrading, or considering upgrading, to .NET 7, and\\nyou want to use the built-in gRPC tools, this guide is also useful.\\n\\nHow you can use this guide\\n\\nThis is a short introduction to building gRPC Services in ASP.NET Core \", \"7.0, with particular reference to\\nWCF as an analogous platform. It explains the principles of gRPC, relating each concept to the\\nequivalent features of WCF, and offers guidance for migrating an existing WCF application to gRPC.\\nIt's also useful for developers who have experience with WCF and are looking to learn gRPC to build\\nnew services. You can use the sample applications as a template or reference for your own projects,\\nand you are free to co\", \"py and reuse code from the book or its samples.\\n\\nFeel free to forward this guide to your team to help ensure a common understanding of these\\nconsiderations and opportunities. Having everybody working from a common set of terms and\\nunderlying principles helps ensure consistent application of architectural patterns and practices.\\n\\nReferences\\n\\u00b0 gRPC website https://grpc.io\\n\\n. Choosing between .NET 5 and .NET Framework for server apps\\n\\nhttps://learn.\", \"microsoft.com/dotnet/standard/choosing-core-framework-server\\nContents\\n\\nIntroduction to gRPC for WCF developetrs ................sssscccscccssssscsccsssssssssssssssssssssssssssccssccssees 1\\nHISCOLY .o.cesessesessesessesessecscsesucsesscsecussessssecussecussesussesussesussesusssussssssucsssecsesesussessssesussesussesussessesesssseesesesussessesessssessesesassesseseeseaeeneaeeneass 1\\nMICFOSEIVICES .....cesesessessessesscsssecsecuesecsecucsucscsesucs\", \"scsecuesucsscsecucsucsesuesuesecsecuesecsecuesucsecnecucsucsesuecucaesuecuesucsecnesueaeenecucsesaeeneaueaeeneeneesens 2\\nADOUt THIS QUIKEL... ee ccessesessesessesessessssessssesussesussesussesussesussesussesussesussesussesussesussesussessssesussesussesucsesussesussesusseseesesesseaesseaesseaeeseans 3\\nWh this Guide iS FOF... ececessessessesesssssesscsessessecessessecucsucsessssussessecussussesussucsssecussussecscsussssesussussecussucsecsesussessee\", \"ussesseenssesseeseensseess 3\\n\\nGRPC OVErVIEW....................ccccccssscsssssssssssssscccssccccscssccescccceccccccccccccccccsccccscsscccesccscesessssssssssssssssees 4.\\nK@Y PIINCIPIeS oo. eecesesessessssesecsecessecsssesussessssessesessssesussessssessssessssessesessssessesessssecsssessesessssessssessesesseaessesessesessssessssessesesseaeeneaeeneens 4\\nHOW GRPC approaches RPC... cesssssssessssessesessssesscsesscsessesesecsessesessesessssessesecsese\", \"ssssessesesseseesesessesessesessesessesessesessesesaeaeeseaeeneess 5\\nInterface DefINItiOn LANGUAGE ........essessessesessessessesessecsesussessesussussessesussessecussussessesussussecscsussessecussesseensaussesseaussesaeencaueseeneensseess 6\\nNetwork Protocols .....ccccesesssssssssssssssssssssssssssssessssessssesssssssssessssessssessssessssessssessesessssessssessessesssessssessesessssessesessesessesesseaesseaeeneens 7\\n\\nKey features Of HTTP/2 ..cec\", \"ccccecesssssssssssssesssssssscscsessesscsusssssesussessssncsussessesussessesussussessecussussesussussessecussessecucsesseeneaesseeseensaeas 7\\nWhy we recommend GRPC for WCF developers ......c.cecscsssssssessssesssssesesssssesscsessessesussessecucsucsessesussesseeussesseencsesseeseensseess 8\\nSIMI arity TO WCE uu. eeccssesessessssesscsescsesscsesscsesucsesscsessssessssessesesscsesscsessescscsesussssssessesessssussesessesussesecsesessesecsesessesesee\", \"sesseaeeneees 8\\nBenefits Of GRPC ue ecccssesssssessssessesscsessessesussessecscsussessesussessesussussessssussessecussussscscsussecsecussussecussussecuesussessecuesucseeneaesaeeneeneaeens 8\\nCOMPAriSON WITH COPEWCE ou... cecesesssssssessssecessecssecscsecussessssesussessssessssesussesussessesecsesessesesusseceeseseesesssseeusseeesseeeesesnsseeeeseeess 9\\n\\nProtocol buffers..................cccccccccccccccscccsssssssssssssssssssssssssscccsccccccsssss\", \"ssssssssssssssesssssssccsssssssssscees 11\\nHOW Protobuf WOFKS 20... ecessessesssssessessessesscssscussscsucsucsucsussussucsucsucsecsecscsecsecsessecsecuecuscuceuscucsucsucsussucsucsussusseeseeaeeaeeseeneeseeseeneens 11\\nProtODUf MESSAGES........cesessessessssessessesessessesscsussessecussessecussucsscsesucsussesussussscsesussusseenssussecsesussussesussussecsesussessecussesseenseesseeseenessess 11\\n\\nDe ClariNG A MESSAGE... .cecesscsessessssesessesess\", \"esessessssesessesessesssesessssessesssssessesessesucsesesuesessssessssesussecussecsssecesseseeseceesesesseensaeenees 11\\nFI@I MUIMDETS .....eeececsessessesseseesecscsscsecsesscsscsecnecucsscsecuesucsessecucsscaesuesucsessecussucsessesuesecsecucsuesesuesussessecucsecsecneeueaeeaeeeneeaeeneeneaees 12\\nTYPES ooeesscsssessssesssscsesesscsesesucsesessesesesuesesssuesesesucsssesscsssesucuesesssussesesuesesesucsesesscsesesscnesesessesesesuesesesucuesesean\", \"esesesseseseseeseseaeeeeseseeneeees 13\\nThe Generated COE uo. .cececcccesssssssesessessssesessessssessssessssesessesssessssesessessssessssessssessssesussesussessssesussesssesessesessesessesesseeesseaeeseeess 13\\nProtobuf scalar data tyes .o..cccccccesssssssssssssessesesssssecsssessessesussessesussessessesussessecussussessesussessecussussecuesussessecucsessecnssesseeseeneseess 13\\nOther .NET primitive tyPe oo. ecsesssssssesssscsessssesscsessssesssses\", \"sssessesessssessssessesecsssessesessssesseseesesessesessesecsesessesesseseeseaseneess 14\\nDO CIIMAIS......eeeseesessessessesessessecsesecsecsecscsscsecucsucsessecucsscsesuesuesessecucssssesuesucsessecussucsessesucsecsecuessesecuesucaessecucsessecnesueaeeaeenenteaeeneeneaee 16\\nProtobuf N@Sted tyPes .o..eececceccccesssssesssssssessssessessessssessecucsussessssussessecussussessesussessecussussecsssussessecuesussecsesussesseeucsesseenssesseeneeneseess\", \" 17\\nRepeated fields for lists AN ALrAYS.......ccessessssessessessesessesscsessessecsssessecsesucsessecussessecsssussessecussessecsesecsessecussesseenssesseeseeneseess 18\\nProtobuf reserved FI@IS wc ccceesssssessessessssscsssssssucsucsussussscsussessecsecsecsessecsessessecsecuseuccuceuccucsucsussucsussussucseeseeaeeaeeaeeaeeneeneeneens 18\\nContents\\nANDY cececssssssessssssesecscsesesscsesesscsesesscsesesessesesesuesesesussesesucsesessssesesesuesesesu\", \"csesesussesesscsesesanesesesuesesesuesesesucsesesecueseseaseseseausaeseeeeeeseneeneaees 19\\nOMOOF on eceesessessessessesseesecsecsecsessecsecuecsccuccuscussucsucsucsussussucsucsucsscsucsscsucsessecsecsecsecsecsecuccuscuccuccucsussussussussucsucsusseeseeseeseeaeeneeneeateneenss 20\\nProtobUut CNUMETATIONS o.....ececcessessessessessessecsesscsscsnssussussucsscsucsesscsecsecsecsecsecsecsecuecsecuscuccuccucsucsucsucsucsussucseeseeaeeateneeaeeseeneenens \", \"21\\nProtobuf Maps FOr CICTIONALIOS.......c.ccccesessessessesessessecscsssssssesecsessecucsussessesussessecussussessesussessecussessecsesussessecussesseenssesseeseeneseees 22\\nUsing MapField properties 1 COG... ccessssesssssssessssessssssssscsesscsssscssssssssscsessssessssesscsessssesesseesssesesseseesecnsseeesseeesseenees 22\\nFUrther r@ ain ou... c.cecesscsessssessesessesessesessesessesessesessesessesessesussesessesucsessssssessesessssussesecsesesss\", \"sessssesessecessecsesecessesuesesesseeesseensseeeees 23\\nComparing WCE to GRPC...................ssssssssscsssssssscccccsccccecccccecccccccccccccccsccscsccssccsscccseesssssssssees 24\\nGRPC CxXaMple wu... ceeccccessessssessssesessesessesessesssessssesussesussesussesussesussessssesussesussesuesesuesessesesussesussesussesussesuesesuesesssesessesesseeesseensaeeess 24\\nWCE endpoints and GRPC Methods uu... ccesssessessssessssesssssssssssessessssesussecsss\", \"esussesessecessesessecsssecessesessecusseeesseeessecesseeesseenees 25\\nOperatioNCOntract PrOPe|rties uc ccecsssssesessesessessssssessssessssessssessssessssessesessssessesesseseeseseesesesseseesesesseseessseesssesseaseneens 25\\nWCE BINdingS AN tranSPOSts ......c.eececesssssssecessecessecessesssesccsecsssesussesussecussecessecsesecessesussesessecessecessesussecssseceeseeesseeeeseensaeenees 26\\nNO@tT CP ....esecsecsssssssssssssssssnssucsussussussussucs\", \"ucsucsucsssucsessecsecsecsscsecnecsessesscsuccuccuscucsucsussussucsussussucsucsussussessesseeaeeaeeseeaeeaeeaeeaeeaeeneenee 26\\nHTTP uu. escsscssssssscsscsssssssussucsucsucsussussucsussucsucsucsucsucsucsucsucsssecsecsecnecsecsecuccuscuscuccuccucsussucsussucsussucsussucsussessueseeseeaeeaeeaeeaeeaeeaeeaeeneenee 27\\nNAME PIPeS......eecccsessesessesessesessesessesessesessesessessssesessesessesussesssesssesssssessesessesssssessesecsssesessesussesessece\", \"ssessssesuesesnssesesseeneseenees 27\\nNS) \\\\ 0 eee 27\\nWEeDHItPBINGING uu... ceescesessesessessssesessesessesssesussesussessssesuesesussesussesussessssessssesussesussesussesussesussesussesussesessesessessseeessesnsaeaeeseeess 2/7\\nTyPe@sS Of RPC... cecccessessssessessesssessesscsssessecussssessesussessecussussessesussussesucsussussesucsussesussussessesussussesussussessecucsesseesesesseeseeuesesaeeneeessess 27\\nREQUEST/FEDLY......cecessecessesessesesse\", \"ssssesessesessesessessssesussesessesussesussesussesucsssussssussessussussssessesucsssesussesussecessecussesesseseesecusseensaeensaeeneas 28\\nWCE duplex, ONE Way tO CHEN wc ccesscsesesessessssessssessssessssesessesssessssessssesussesussesussesussessssesussessseaessesesseeesaesesseaeeseeess 28\\nWCF one-way operations and GRPC CliQ@nt StreaMING ou... cccesesessessssesessesessesessesessessssesesseeessessssesesseeesseeesseeess 30\\nWCE full-Guplex SOrViCe\", \"S ....cececcessssessessessesessesscsussessesucsussessesussessecussussessesussessecussusseesesussessesussecsecucsusseesecussesseensseeseeneaeeaees 31\\nMetadata on... eeececessesssssssessesessessessesussessecucsssessesussssesucscsesuesucsesnesucsscsessesucscnesucsscsecuesucaessesucsessecueaucsecussusaesseeucssaecnesesaeeneeneasens 32\\nError DAndling.......e.sesessessssecsssessssessssesessesessesssesscsesussesussesussesussesussesussesucsessssesussesss\", \"sesessessssesessesucsesussesessesessesessesessesesseseeseseeseess 33\\nRaise errors IN ASP.NET Core GRPC wu... ceessssesssssssesssssesscsesscsessssessesessesessesessesessesessssesussessssecsesesussesessecesseeesseeseaeeneas 34\\nCatch Errors IN GRPC CHENtS .... ee eeesessessesessesessesessesesscsesscsessesessesessesessesessesessesessssessesessesessesecsesessesesseseesesesseseeneaeeeeess 34\\nQRPC richer Error MOE... ce ecesesssssssesessesessesessesesse\", \"sessesessssessesessesessesscsesussesecsesussesessesessesessesessesessesesseaeessseeeeseeneaeeneess 35\\nWS-* Protocol s.....cccccessessssesessscsssessssssesessssecsssssessecsssessssessssesussesussesussesussesussesussecsssecussesussesussecessecessesussecueseeessecesseensseeesaeenees 35\\nMetadata exchange: WS-Policy, WS-DiSCOVELY, AN SO ON... cessesesssssessssesesssesscseseesessesesessecsesecssseeesseensseenees 35\\nSecurity: WS-Security, WS-Federation,\", \" XML Encryption, ANd SO ON... ccessesessesessecessesesseeesseeesseeesseesseenees 35\\nWS-ReliablEMessagiing .....c.cscssssssessesessessssessssesessessssesessesssesssesussesussesussessssesussesussesussesussessssesussesssecessesesseeessesesseeeeseeess 36\\nWS-Transaction, WS-COOrdination ........cececcesssssssssssssessesessessecsesessessessesecsesucsessesnesucsessecucsessecuesucsessesecaeeseeeseeeaeeneeenes 36\\n\\nii Contents\\nMigrate a WCE solution to GRP\", \"C ...............ccssssssssscsscccccccccccccccccccccssssssssssssssssssssssssccccccccoeees 37\\n\\nCreate a new ASP.NET Core GRPC project ou... cccesscssssessssessssessssesessesessesessesessesssesssesussesussesssesssesessesessesesseeeeseeneseeess 37\\nCreate the project by USING VisUal StUCIOL... ec esssessssessesesseseesssessesessesessesessssessesessesessesessssesseseeseseesssesseaneneess 37\\nCreate the project by Using the .NET Cou. cessssssssessesesse\", \"sessesessesessesessssessesessesessesessesessesessesesseseesesesseseeneens 40\\nClean UP the ExaMPle COE uu... ..eeccscssssssssessssesessesessesessssesscssssesessesessesessesessesessesessesessesessesessesessesesseseeseaeeseseessseeneaeeneess 41\\n\\nMigrate a WCF request-reply service to a GRPC UNALY RPC... eesssessesessesessesessesessesessesessesessesessesesseseeseseeseens 42\\nTHE WCE SOLUTION oon. ceeceesessessssessessessssessecscsscsecsecucsscsesnesuc\", \"scsecucsucsesuecucsessesuesecsesucsucsessesucsessecucsussecuesueseesesueaesaeeueeesaeeneeenees 42\\nThe POrtfOliOS. Proto FIC... ecccessessesesessessesessesssssssessessesussessecsssessessssusseesecussessessssussessesussesseenssesseeseassesseensseeseeneeeesee 44\\nConvert the DataContract classes tO GRPC MESSAGES.......eeessssessessssesessesessesessesessesessesessesessesessesessesesseseeneaeeneess 44\\nConvert ServiceContract to a GRPC SEIVICE uu... eee\", \"cesessssessesessesessesessesessesessesessesessesessesessesessesessesessesesseseesesesneaeeneess 45\\nMigrate the PortfolioData library to NET... ccsessessssessessesessessecsssesssssesussesssesssessessecessesseenesessesseeseseeseeneeesees 46\\nUse ASP.NET Core Gependency INJjectiOn .......cceceessssesssssssesssssssssessssssesscsessesessesecsssesecsecessecsssesesseenesecesseeesseensseenees 47\\nIMpleMent the GRPC SErVICE......eeesscsessesessessssesessese\", \"ssesessesessesessessssssessesessesssnesessesessesesussecussecsssecsesecessesuesecnsseeesseeneaeenees 48\\nGene|rate CHEN COKE... eceececsessessessesesseseseesecnecsesessecucsessesnesussecsesuesucsessesscaessecucassesucsucsessesucaecsecuesecsesnesusseeseeueaeeneeneaneass 50\\n\\nMigrate WCF duplex Services to GRPC uu... eescsessessssessssessssesessessssesessesessesssesssesussesussesussesussesessesessesessesessesesseaesseseeneens 53\\nSErver StrEAMING RPC.\", \".. eeccsesssssssessssessssessssesessesessessssesssesussessssesussesussesussesussessssesussessssesussecussesussecesseeusseensseeesseensseenees 53\\nBidirectional Str@AMING .......cccsscssssessssessssesessessssesessessssesessesessesesscsessssessesessesessessssesessesessssesessecessecsesecesseseesecssseensseensaeenees 58\\n\\nGRPC streaming Services VS. repeated FIEIAS oo... ccecessessessssessesscsessessecessessessesessessecussecseesesecsesseenssesseesess\", \"seeseessseesss 63\\nWhen) to USE repeated FEISS... eeccccssessessesessessesscsessessesssessecsssessessesussessecussessessssussessesussesseeucsusseesecessesseeesseeseeneeessees 63\\nWhen) to USE Stream Methods... eeeececsessesseseeseesesseseesessesuesessecsesssessessesessesuesscsessecuesessesucsucsesuesucsessesueseeseeneeeeaeeneeenees 64\\n\\nCreate GRPC client lIDraries.... ce esesesessessssesessesessessssesessesessesssesssesssesussesesesussesussesussesu\", \"ssesesesssecesseseesesesseessaeeeeseeess 64\\nUseful OxtenSiOns .....eeceececsesssssssssssessessecseesecsessessessecsessessecsessecsessesucesecsscuccucsucsucsussussussussucsussusseseeseeseeseeaeeseeseeaeeaeeaeeaeeneenee 65\\nSUIMIM ALY... eesesssesessssesesesesesscscsesesescscsesesesesesscsesesesesesesussesesesesesesusuesesesesesessuesesesesesesucsesesesesesesssuesesesesesecucsescseseseeeenesenesenenees 6/7\\n\\nSecurity in GRPC applications ............\", \".....ccccscscccssssccssccccsccccsscscssssssssssssssssssssssssssssssssssssssssssees 68\\n\\nWCE authentication and AUtHOriZation on. eececcesessessessessessesessesecsesseseseesecnescsessecscsessesseseesesseseeseeseenesesaeeneeteseeaeeeetenee 68\\n\\nGRPC authentication And AUTHOSIZATION 0... eecessesessesessessesesessesessesessesssecsssessssesssesussessseseseseesesesesessesesseetsseetsseeess 68\\n\\nCall Credentials... eeecesesessessessssessesesessessesncsess\", \"essecussecnesuesssessesucsessecucsucsecsesucsssesucsucsessesucsecsecucsucsesnesucaesaesuccucsesneaueaeeneeneeseass 69\\nWS-FeCEration ....e.eececscsesssssessesessessessssessesscsssessesucsessesuesucsessesuesessessesucsessesuesessesuesucsessesucsessesucsecsessesueseesesussesaeeneeeeaeeneenenees 69\\nJWT Bearer token o....eeceecessessessssessesssessesscscsesscsucsessesucsucsesnesuesscsecucsucsessesuesecsesucsussesuesucsessecucsucsessesueseeseseeaesseee\", \"eeeeaeeneenenes 69\\nAdd authentication and authorization to the S\\u20acrVel....c.ceecsessssssssessesessessessssesseseeseeseeseseeseeseseesessseeeeeeaeeteeeenee 70\\nProvide call credentials in the cleNt ADPlICAtTION oe eececessesessesessesessesessesessesecseseceesecsesesesseseesecnsseeesseeneseenees 71\\n\\nChannel Credentials... ecccsesessesssssesessesessessecsesessessesussessesscsussessecucsecsessesussessecucsussesuesucsessesucsucaesnesucsesaecueseeaeeaeeu\", \"eaeeneeneeseass 72\\n\\niil Contents\\nAdd certificate AUTHENTICATION TO TNE SEPVE oc cccccccccsccccsseccsscccescscescsceccsccscsccscsccscsscscescsecsesecsescsacsacseescsecseseaeess 72\\n\\nProvide channel credentials in the client APPLICATION oo... ee eeesessessesessesesesesessesecsececseceesessssesseseessseensseeneseenees 73\\nCombine ChannelCredentials and CallCredentials 0... ccecsesssssssessessssesseceesessesseseesesseseesessesnesesseeneeeeaeeaeeneseaes\", \" 74\\nENCryption ANd NEtWOFK SECULITY uu... .cceesessesessesessesessessssesessesessesssessssesssesssesessesessesessesessesessesessesessesessesessesessesesseseeneees 15\\nGRPC in Production. ....................ssssssssssssssssscssssccsscsscssccccscccccccccccccccccccccscsccsccscccsscssssssssssssssees 77\\nSelf-hosted GRPC application .u....cecccccesssssessssessesscsesssssesscsessecscsssessecussessecsssussessecsssessesussucsessecussessecscsesseeseesseese\", \"eneseeses 77\\nRUN YOUF APP AS a WINCOWS SEPVICE.......eesessssessessssesessesessesessesesscsessesessssessesessesessesessssecsesecessecsesesuesesussecnsseensseensseenees 77\\nRUN YOUF APP aS a LINUX SErVICE WITN SYSTEMA uu... eecesessesesessesessesessesessesessesesssseseesecuesecsssesessesueseensseeeeseeneseenees 78\\nHTTPS certificates for self-hosted APPliCAtlONS ......cecscessesseseseesessecsssesseesesecsesseesssesssssecssseeseesesesseeseeeseeseenee\", \"esee 80\\nCreate DOCKED IMAGES .......cecessesessessssesessessssesessesessesessesssesssesussesussesussesussesussesussessesesussesussesussesussesessesussesssesessesesseeesseeeeseeess 81\\nMicrosoft base images for ASP.NET Core applications........ccccecscsssessessesesssssecsssessessecssesssesesessseseeteseeseeeeeesee 81\\nCreate a DOCKED IMAGE ......eeecesesssssssssessesessesessesessesessesesssssssesessssussesessescsesussescsesussesessesessesessesessese\", \"ssesecseaeeseseeseseeneaeeneens 82\\nBUI the IMAC... .ceessesessessssesessesessesessesessesessesssesessesscsesussesussessssesscsssussesucsesssesessesussesessssesussesussesuesesessesuesecesseensseensaeeneas 84\\nRun the image In a CONtAINEF ON YOUF MACHING uu... eeecessessssessesesscsesscsessesessesesscseseesessesessesesssseseeseensseeesseeesseenees 84\\nPUSH the IMAGE tO a FEGISUIY.......ceeccccessesessesessesessesessesessesessesessesessssessesessesess\", \"esessssessesessssesessecussecsesesesseseesecnsseeesseensaeenees 84\\nKUDErNe te... eesessesessessessessesessecsesussecscsucsscsessesucsecsesucsscsesuesucsscsecuesscsecuesuesecsesucsucsesussucsessesuesessecuesscsecuesueaecsecucssseenesusaeeneeneasees 85\\nKUbernetes terMinOlOGy.....c.ccsccessesessessssessssessssesessesessssessessssssesscsessssessesessssessesessesessesesessesussecessecessecessesessecesseeesseensseeeees 85\\nGet Started WIth KUD|rnete 0..\", \". eececsessesseseesessessesessecsessesecsecsesecsecucsucsesnecucscsecucsucsessecucsecsecucsussesuecueseeneeneateneeneaneass 86\\nRUN SEFVICES ON KUDEFNeteS ou... eeeesecsessesseseeseesecsescsessecscsessecucsscsessecuesucsecsessesessecucsecsessesucsessecucscaecnesueaesaeeneseeaeeneeneaees 87\\nSEPVICE MESNES.....eseesessessesesessessesscsecsecsesscsecsecscsscsesuesscscscsucsscsesucsucsecsesucaucsecsesscsesuesucaessecussucsecsesucaessecucsecaeenecueaee\", \"necueseeneeneeseass 93\\nSErVICE MESH OPTtiONS.......cccessssesssssssesessessssesessesessesessessssesssessssessssesussessesesussesussessesesussessssesessesussesuesesessesueseessseeeeseeneseesees 94\\nExample: Add Linkerd to a GeployMe nt... cecsssssssessssssssssssssssssssesscsessssesscsesscsessesecsssecsssesessesussecesseeesseensseenees 94\\nLOA DalaNCiNG GRPC ou... cecessesessessssesessessssesessesessesssessssesssesussesessesussessssesussessssesussesu\", \"ssesessesessesecsesessesessesessesessesessesesseseeneees 97\\nLA load Dalance rs uo. eeeceecessesessesseseesesseseesessecsesessecnesscsessesucsessesuesucsessecussecsessesecsessesucsessessesucsessecueseeaecneseeaeeaeeeateaeeneeeaee 97\\nL7 LOAM Dalance rs uo. eeeseesessessessesesseesessesscsessecscsessecsesucsessesucsscsecuecucsessecussucsessesucsessecuesssecsesucsessecueseesecnesueaeeaeeenteaeeneeneaees 97\\nLoad balancing Within KUDernete uu... eceses\", \"sssessssssesessssesscsessssssscsessesesscsessssessssesessecsssecessecsssesessesessecesseeesseeesseenees 98\\nApplication Performance Manageme nt .u.......ccccccsssssssesessessesscsesssssesessesssesssesseesesussessscucsucseesecussessecsessseeseeneseeaeeneaeeses 98\\nThe difference between LOGGING AN MEtIICS .......ccccessessesesessessessssessesssesssesssessessesssseeseesesesseesesessesseesseeseeneaesees 98\\nLOGGING IN ASP.NET Core GRPC wu... eeeessssss\", \"sssessesessesesscsesscsesscsesscsessesessesessesessssessesecussecsesecessecsesecessesessecnsseeesseensaeenees 98\\nMetrics In ASP.NET Core GRPC wu... .ceessssesssssssesssscsesscsessesessesessesessssessesessessscssucsessssesussessssecessessesesessesessecesseeesseensaeenees 99\\nDIStriDUTE\\u201d TrACING ......cecessesessesessecessesessecsssessssesussecsssecsssessssessssecsssescssecsssesussesussecussecussecsssecusseeussecussesussecessecesseeesseeneseenees 10\", \"1\\nAppendix A - Transactions ..............ssssssscsscsccccccccccccccccccsssssssssssssssssscsscccccccccscccccscccesssssssosess 104\\n\\niV Contents\\nCHAPTER\\n\\nIntroduction to gRPC for\\nWCF developers\\n\\nHelping machines communicate with each other has been one of the primary preoccupations of the\\ndigital age. In particular, there's an ongoing effort to determine the optimal remote communication\\nmechanism that will suit the interoperability demands of the c\", \"urrent infrastructure. As you can\\nimagine, that mechanism changes as either the demands or the infrastructure evolves.\\n\\nThe release of .NET Core 3.0 marks a shift in the way that Microsoft delivers remote communication\\nsolutions to developers who want to deliver services across a range of platforms. .NET Core and later\\ndoesn't offer Windows Communication Foundation (WCF) out of the box but, with the release of\\nASP.NET Core 3.0, it does provide bu\", \"ilt-in gRPC functionality.\\n\\ngRPC is a popular framework in the wider software community. It's used by developers across many\\nprogramming languages for modern RPC scenarios. The community and the ecosystem are vibrant\\nand active. Support for the gRPC protocol is being added to infrastructure components like\\nKubernetes, service meshes, load balancers, and more. These factors, together with its performance,\\nefficiency, and cross-platform compatibili\", \"ty, make gRPC a natural choice for new apps and WCF apps\\nmoving to .NET.\\n\\nHistory\\n\\nThe fundamental principle of a computer network as nothing more than a group of computers\\nexchanging data with each other to achieve a set of interrelated tasks hasn't changed since its\\ninception. But the complexity, scale, and expectations have grown exponentially.\\n\\nDuring the 1990s, the emphasis was mainly on improving internal networks that used the same\\nlanguag\", \"e and platforms. TCP/IP became the gold standard for this type of communication.\\n\\nThe focus soon shifted to how best to optimize communication across multiple platforms by\\npromoting a language-agnostic approach. Service-oriented architecture (SOA) provided a structure\\nfor loosely coupling a broad collection of services that could be provided to an application.\\n\\nThe development of web services occurred when all major platforms could access the int\", \"ernet, but\\nthey still couldn't interact with each other. Web services have open standards and protocols,\\nincluding:\\n\\n. XML to tag and code data.\\n\\n1 CHAPTER 1 | Introduction to gRPC for WCF developers\\n. Simple Object Access Protocol (SOAP) to transfer data.\\n\\n. Web Services Definition Language (WSDL) to describe and connect web services to client\\napplications.\\n\\n. Universal Description, Discovery, and Integration (UDDI) to make web services discover\", \"able by\\nother services.\\n\\nSOAP defines the rules by which distributed elements of an application can communicate with each\\nother, even if they're on different platforms. SOAP is based on XML, so it\\u2019s human-readable. The\\nsacrifice for making SOAP easily understood is size; SOAP messages are larger than messages in\\ncomparable protocols. SOAP was designed to break monolithic applications into multicomponent\\nform without losing security or control. So\", \" WCF was designed to work with that kind of system, unlike\\ngRPC, which began as a distributed system. WCF addressed some of these limitations by developing\\nand documenting proprietary extension protocols for the SOAP stack, but at the cost of a lack of\\nsupport from other platforms.\\n\\nWindows Communication Foundation is a framework for building services. It was designed in the early\\n2000s to help developers using early SOA to manage the complexitie\", \"s of working with SOAP.\\nAlthough it removes the requirement for the developers to write their own SOAP protocols, WCF still\\nuses SOAP to enable interoperability with other systems. WCF was also designed to deliver solutions\\nacross multiple protocols (HTTP/1.1, Net.TCP, and so on).\\n\\nMicroservices\\n\\nIn microservice architectures, large applications are built as a collection of smaller modular services.\\nEach component does a specific task or process,\", \" and components are designed to work interoperably\\nbut can be isolated as necessary.\\n\\nAdvantages to microservices include:\\n\\n. Changes and upgrades can be handled independently.\\n\\n. Error handling becomes more efficient because problems can be traced to specific services\\nthat are then isolated, rebuilt, tested, and redeployed independently of the other services.\\n\\n\\u00b0 Scalability can be confined to specific instances or services rather than the whole \", \"application.\\n\\n. Development can happen across multiple teams, with less friction than occurs when many\\nteams work on a single codebase.\\n\\nThe move towards increasing virtualization, cloud computing, containers, and the Internet of Things\\nhas contributed to the ongoing rise of microservices. But microservices aren't without their challenges.\\nThe fragmented/decentralized infrastructure put more emphasis on the need for simplicity and speed\\nwhen comm\", \"unicating between services. This in turn drew attention to the sometimes laborious and\\ncontorted nature of SOAP.\\n\\nIt was into this environment that gRPC was launched, 10 years after Microsoft first released WCF.\\nEvolved directly from Google's internal infrastructure RPC (Stubby), gRPC was never based on the\\nsame standards and protocols that had informed the parameters of many earlier RPCs. And gRPC was\\nonly ever based on HTTP/2. That's why it cou\", \"ld draw on the new capabilities that advanced transport\\nprotocol provided. In particular, bidirectional streaming, binary messaging, and multiplexing.\\n\\n2 CHAPTER 1 | Introduction to gRPC for WCF developers\\nAbout this guide\\n\\nThis guide covers the key features of gRPC. The early chapters take a high-level look at the main\\nfeatures of WCF and compare them to those of gRPC. It identifies where there are direct correlations\\nbetween WCF and gRPC and al\", \"so where gRPC offers an advantage. When there's no correlation\\nbetween WCF and gRPC, or when gRPC isn\\u2019t able to offer an equivalent solution to WCF, this guide\\nwill suggest workarounds or where to go for more information.\\n\\nUsing a set of sample WCF applications, Chapter 5 is a deep-dive look at converting the main types of\\nWCF service (simple request-reply, one-way, and streaming) to their equivalents in gRPC.\\n\\nThe final section of the book looks\", \" at how to get the best from gRPC in practice. This section includes\\ninformation on using additional tools, like Docker containers or Kubernetes, to take advantage of the\\n\\nefficiency of gRPC. It also includes a detailed look at monitoring with logging, metrics, and distributed\\ntracing.\\n\\nWho this guide is for\\n\\nThis guide was written for developers working in .NET Framework or .NET Core who have used WCF\\nand who are seeking to migrate their applica\", \"tions to a modern RPC environment for .NET Core 3.0\\nand later versions. The guide might also be useful more generally for developers upgrading or\\nconsidering upgrading to .NET and who want to use the built-in gRPC tools.\\n\\n3 CHAPTER 1 | Introduction to gRPC for WCF developers\\nCHAPTER 2\\n\\ngRPC overview\\n\\nAfter looking at the genesis of both Windows Communication Foundation (WCF) and gRPC in the last\\nchapter, this chapter considers some of the key fea\", \"tures of gRPC and how they compare to WCF.\\n\\nASP.NET Core 3.0 is the first release of ASP.NET that natively supports gRPC as a first-class citizen,\\nwith Microsoft teams contributing to the official NET implementation of gRPC. It\\u2019s recommended for\\nbuilding distributed applications with .NET that can interoperate with all other major programming\\nlanguages and frameworks.\\n\\nKey principles\\n\\nAs discussed in chapter 1, Google wanted to use the introducti\", \"on of HTTP/2 to replace Stubby, its\\ninternal, general purpose RPC infrastructure. gRPC, based on Stubby, now can take advantage of\\nstandardization and would extend its applicability to mobile computing, the cloud, and the Internet of\\nThings.\\n\\nTo achieve this standardization, the Cloud Native Computing Foundation (CNCF) established a set of\\nprinciples that would govern gRPC. The following list shows the most relevant ones, which are\\nprimarily conc\", \"erned with maximizing accessibility and usability:\\n\\n. Free and open - All artifacts should be open source, with licensing that doesn\\u2019t constrain\\ndevelopers from adopting gRPC.\\n\\n. Coverage and simplicity \\u2014 gRPC should be available across every popular platform, and\\nsimple enough to build on any platform.\\n\\n. Interoperability and reach \\u2014 It should be possible to use gRPC on any network, regardless of\\nbandwidth or latency, by using widely available n\", \"etwork standards.\\n\\n. General purpose and performant \\u2014 The framework should be usable by as broad a range of\\nuse-cases as possible, without compromising performance.\\n\\n. Streaming \\u2014 The protocol should provide streaming semantics for large datasets or\\nasynchronous messaging.\\n\\n. Metadata exchange \\u2014 The protocol allows non-business data, such as authentication tokens,\\nto be handled separately from actual business data.\\n\\n. Standardized status codes \\u2014 \", \"The variability of error codes should be reduced to make error\\nhandling decisions clearer. Where additional, richer error handling is required, a mechanism\\nshould be provided for managing behavior within the metadata exchange.\\n\\n4 CHAPTER 2 | gRPC overview\\nHow gRPC approaches RPC\\n\\nWindows Communication Foundation (WCF) and gRPC are both implementations of the Remote\\nProcedure Call (RPC) pattern. This pattern aims to make calls to services that run\", \" on a different\\nmachine, or in a different process, work seamlessly, like method calls in the client application. While\\nthe aims of WCF and gRPC are the same, the details of the implementation are quite different.\\n\\nThe following table sets out how the key features of WCF relate to gRPC, and where you can find\\nmore detailed explanations.\\n\\nObjective Separate business | Separate business code\\ncode from from interface definition\\nnetworking and networ\", \"king\\nimplementation. | implementation.\\n\\nDefine services and messages (chapters 3-4) Service Contract, | Uses proto file to\\nOperation declare services and\\nContract, and messages.\\nData Contract.\\n\\nLanguage (chapters 3-5) Contracts written | Protocol Buffer\\nin C# or Visual language.\\nBasic.\\n\\nWire format (chapter 3) Configurable, Protocol Buffer binary\\nincluding format (although it's\\nSOAP/XML, Plain | possible to use other\\nXML, JSON, and formats).\\n.NET\", \" Binary.\\n\\nInteroperability (chapter 4) When using Official support: .NET,\\nSOAP over HTTP. | Java, Python, JavaScript,\\nC/C++, Go, Rust, Ruby,\\nSwift, Dart, PHP.\\nUnofficial support for\\nother languages from\\nthe community.\\n\\nNetworking (chapter 4) Configured at run | HTTP/2, currently over\\ntime. Switch TCP only with ASP.NET\\nbetween NetTCP, | Core gRPC.\\n\\nHTTP, and\\nMSMQ.\\n\\n5 CHAPTER 2 | gRPC overview\\nApproach (chapter 4) Runtime Build-time generation of\\ng\", \"eneration of serialization,\\nserialization, deserialization, and\\ndeserialization, networking code in base\\nand networking classes.\\ncode in base\\nclasses.\\n\\nSecurity (chapter 6) Authentication, Credentials, ASP.NET\\nWS-Security, Core security, TLS\\nmessage networking.\\nencryption.\\n\\nInterface Definition Language\\n\\nWith Windows Communication Foundation (WCF), services can expose description metadata by using\\nthe Web Service Definition Language (WSDL). WSDL \", \"is generated dynamically by using .NET reflection\\nat run time. Developers can use this metadata to generate clients for those services, potentially in\\nother languages if they're using a platform-neutral binding such as SOAP over HTTP.\\n\\ngRPC uses the Interface Definition Language (IDL) from Protocol Buffers. The Protocol Buffers IDL is a\\ncustom, platform-neutral language with an open specification. Developers author .proto files to\\ndescribe servic\", \"es, along with their inputs and outputs. These .proto files can then be used to generate\\nlanguage- or platform-specific stubs for clients and servers, allowing multiple different platforms to\\ncommunicate. By sharing .proto files, teams can generate code to use each others\\u2019 services, without\\nneeding to take a code dependency.\\n\\nOne of the advantages of the Protobuf IDL is that as a custom language, it enables gRPC to be\\ncompletely language and plat\", \"form agnostic, not favoring any technology over another.\\n\\nThe Protobuf IDL is also designed for humans to both read and write, whereas WSDL is intended as a\\nmachine-readable/writable format. Changing the WSDL of a WCF service typically requires changing\\nthe service, running the service, and regenerating the WSDL file from the server. By contrast, with a\\n.proto file, changes are simple to apply with a text editor, and automatically flow through th\", \"e\\ngenerated code. Visual Studio 2022 builds .proto files in the background when they are saved. With\\nother editors, such as VS Code, the changes are applied when the project is built.\\n\\nWhen compared with XML, and particularly SOAP, messages encoded by using Protobuf have many\\nadvantages. Protobuf messages tend to be smaller than the same data serialized as SOAP XML, and\\nencoding, decoding, and transmitting them over a network can be faster.\\n\\nThe \", \"potential disadvantage of Protobuf compared to SOAP is that, because the messages aren't\\nreadable by humans, additional tooling is required to debug message content.\\n\\n6 CHAPTER 2 | gRPC overview\\nTip\\n\\ngRPC does support server reflection for dynamically accessing services without pre-compiled stubs,\\nalthough it's intended more for general-purpose tools than application-specific clients. For more\\ninformation, see GRPC Server Reflection Protocol on G\", \"itHub.\\n\\nNote\\n\\nWCF's binary format, used with the NetTCP binding, is much closer to Protobuf in terms of\\ncompactness and performance. But NetTCP is only usable between .NET clients and servers, whereas\\nProtobuf is a cross-platform solution.\\n\\nNetwork protocols\\n\\nUnlike Windows Communication Foundation (WCF), gRPC uses HTTP/2 as a base for its networking.\\nThis protocol offers significant advantages over WCF and SOAP, which operate only on HTTP/1.1. F\", \"or\\ndevelopers wanting to use gRPC, given that there\\u2019s no alternative to HTTP/2, it would seem to be the\\nideal moment to explore HTTP/2 in more detail and identify additional benefits of using gRPC.\\n\\nHTTP/2, released by Internet Engineering Task Force in 2015, was derived from the experimental SPDY\\nprotocol, which was already being used by Google. It was specifically designed to be more efficient,\\nfaster, and more secure than HTTP/1.1.\\n\\nKey featur\", \"es of HTTP/2\\n\\nThis list shows some of the key features and advantages of HTTP/2:\\n\\nBinary protocol\\n\\nRequest/response cycles no longer need text commands. This activity simplifies and speeds up the\\nimplementation of commands. Specifically, parsing data is faster and uses less memory, network\\nlatency is reduced with obvious related improvements to speed, and there\\u2019s an overall better use of\\nnetwork resources.\\n\\nStreams\\n\\nStreams allow you to create lo\", \"ng-lived connections between sender and receiver, over which multiple\\nmessages or frames can be sent asynchronously. Multiple streams can operate independently over a\\nsingle HTTP/2 connection.\\n\\nRequest multiplexing over a single TCP connection\\n\\nThis feature is one of the most important innovations of HTTP/2. Because it allows multiple parallel\\nrequests for data, it\\u2019s now possible to download web files concurrently from a single server. Websites\\nl\", \"oad faster, and the need for optimization is reduced. Head-of-line (HOL) blocking, where responses\\n\\n7 CHAPTER 2 | gRPC overview\\nthat are ready must wait to be sent until an earlier request is completed, is also mitigated (although\\nHOL blocking can still occur at the TCP-transport level).\\n\\nNet.TCP-like performance, cross-platform\\n\\nFundamentally, the combination of gRPC and HTTP/2 offers developers at least the equivalent speed\\nand efficiency of Ne\", \"t.TCP bindings for WCF, and in some cases even greater speed and efficiency. But,\\nunlike Net. TCP, gRPC over HTTP/2 isn't constrained to .NET applications.\\n\\nWhy we recommend gRPC for WCF developers\\n\\nBefore we dive deeply into the language and techniques of gRPC, it\\u2019s worth discussing why gRPC is\\nthe right solution for Windows Communication Foundation (WCF) developers who want to migrate to\\n.NET.\\n\\nSimilarity to WCF\\n\\nAlthough the implementation and\", \" approach are different for gRPC, the experience of developing and\\nconsuming services with gRPC should be intuitive for WCF developers. The underlying goal is the\\nsame: make it possible to code as though the client and server are on the same platform, without\\nneeding to worry about networking.\\n\\nBoth platforms share the principle of declaring and then implementing an interface, even though the\\nprocess for declaring that interface is different. And\", \" as you'll see in chapter 5, the different types of\\nRPC calls that gRPC supports map well to the bindings available to WCF services.\\n\\nBenefits of gRPC\\n\\ngRPC stands above other solutions for the following reasons.\\n\\nPerformance\\n\\nUsing HTTP/2 rather than HTTP/1.1 removes the requirement for human-readable messages and\\ninstead uses the smaller, faster binary protocol. This is more efficient for computers to parse. HTTP/2\\nalso supports multiplexing re\", \"quests over a single connection. This support enables responses to be\\nsent as soon as they're ready without the need to wait in a queue. (In HTTP/1.1, this issue is known as\\n\\u201chead-of-line (HOL) blocking.\\u201d) You need fewer resources when using gRPC, which makes it a good\\nsolution to use for mobile devices and over slower networks.\\n\\nInteroperability\\n\\nThere are gRPC tools and libraries for all major programming languages and platforms, including\\n.NET\", \", Java, Python, Go, C++, Node,js, Swift, Dart, Ruby, and PHP. Thanks to the Protocol Buffers binary\\nwire format and the efficient code generation for each platform, developers can build performant\\napps while still enjoying full cross-platform support.\\n\\n8 CHAPTER 2 | gRPC overview\\nUsability and productivity\\n\\ngRPC is a comprehensive RPC solution. It works consistently across multiple languages and platforms.\\nIt also provides excellent tooling, with\", \" much of the necessary boilerplate code automatically\\ngenerated. So more developer time is freed up to focus on business logic.\\n\\nStreaming\\n\\ngRPC has full bidirectional streaming, which provides similar functionality to WCF's full-duplex\\nservices. gRPC streaming can operate over regular internet connections, load balancers, and service\\nmeshes.\\n\\nDeadline/timeouts and cancellation\\n\\ngRPC allows clients to specify a maximum time for an RPC to finish. \", \"If the specified deadline Is\\nexceeded, the server can cancel the operation independently of the client. Deadlines and cancellations\\ncan be propagated through further gRPC calls to help enforce resource usage limits. Clients can also\\nstop operations when a deadline is exceeded, or earlier if necessary (for example, because of a user\\ninteraction).\\n\\nSecurity\\n\\ngRPC Is implicitly secure when it\\u2019s using HTTP/2 over a TLS end-to-end encrypted connection\", \". Support\\nfor client certificate authentication (see chapter 6) further increases security and trust between client\\nand server.\\n\\nComparison with CoreWCF\\n\\nA notable alternative to gRPC for replacing WCF services when migrating to .NET is CoreWCF. Both\\ngRPC and CoreWCF are Microsoft endorsed paths forward for WCF applications and each comes with\\nits own benefits and drawbacks.\\n\\nCoreWCF is a community-owned .NET Foundation project supported by Micro\", \"soft that implements\\nWCF server APIs for .NET. CoreWCF is an effort to allow existing WCF services to work with minimal\\nchanges on .NET. Your Data Contracts for WCF are unchanged with CoreWCF, and it supports many of\\nthe bindings and APIs from WCF. The main differences are around the patterns for starting WCF\\nservices, and not all configuration options are available (some configuration must now be done in\\ncode).\\n\\nServices and interfaces can often\", \" migrate with few changes. Because of this, a key benefit of CoreWCF\\nis its very high compatibility with WCF. Where changes have been made, they are to adapt to the\\nprogramming style of modern .NET, for example hosting now through ASP.NET Core, and APIs now\\nuse the Task based async patterns usable with await rather than the older BeginXXX / EndXXX pattern.\\n\\nOn the other hand, gRPC is a modern remote communication solution with a number of feature\", \"s, as\\ndiscussed previously. Benefits of using gRPC include better interoperability across languages, its\\nrelatively simple modern API, and a broad community ecosystem.\\n\\nWhen deciding whether to use CoreWCF or gRPC to migrate a WCF application to .NET, CoreWCF is\\ntypically a better fit if the goal is to migrate the application with minimal changes whereas gRPC may\\n\\n9 CHAPTER 2 | gRPC overview\\nbe a better fit if the goal is to modernize the applica\", \"tion while retargeting to .NET. The remainder of\\nthis guide focuses on that modernization with gRPC.\\n\\n10 CHAPTER 2 | gRPC overview\\nCHAPTER\\n\\nProtocol buffers\\n\\ngRPC services send and receive data as Protocol Buffer (Protobuf) messages, similar to data contracts in\\nWindows Communication Foundation (WCF). Protobuf is an efficient way of serializing structured data\\nfor machines to read and write, without the overhead that human-readable formats like X\", \"ML or JSON\\n\\nincur.\\n\\nThis chapter covers how Protobuf works, and how to define your own Protobuf messages.\\n\\nHow Protobuf works\\n\\nMost .NET object serialization techniques, including WCF\\u2019s data contracts, work by using reflection to\\nanalyze the object structure at run time. By contrast, most Protobuf libraries require you to define the\\nstructure up front by using a dedicated language (Protocol Buffer Language) in a .proto file. A compiler\\nthen uses \", \"this file to generate code for any of the supported platforms. Supported platforms include\\n.NET, Java, C/C++, JavaScript, and many more.\\n\\nThe Protobuf compiler, protoc, is maintained by Google, although alternative implementations are\\navailable. The generated code is efficient and optimized for fast serialization and deserialization of\\ndata.\\n\\nThe Protobuf wire format is a binary encoding. It uses some clever tricks to minimize the number of\\nbytes\", \" used to represent messages. Knowledge of the binary encoding format isn\\u2019t necessary to use\\nProtobuf. But if you're interested, you can learn more about it on the Protocol Buffers website.\\n\\nProtobuf messages\\n\\nThis section covers how to declare Protocol Buffer (Protobuf) messages in .proto files. It explains the\\nfundamental concepts of field numbers and types, and it looks at the C# code that the protoc\\ncompiler generates.\\n\\nThe rest of the chapter\", \" will look in more detail at how different types of data are represented in\\n\\nProtobuf.\\n\\nDeclaring a message\\n\\nIn Windows Communication Foundation (WCF), a Stock class for a stock market trading application\\nmight be defined like the following example:\\n\\n| namespace TraderSys; |\\n\\n11 CHAPTER 3 | Protocol buffers\\n[DataContract |\\npublic class Stock\\n{\\n[| DataMember |\\npublic int Id { get; set; }\\n[| DataMember |\\npublic string Symbol { get; set; }\\n[| DataMe\", \"mber |\\npublic string DisplayName { get; set; }\\n[| DataMember |\\npublic int MarketId { get; set; }\\n\\nTo implement the equivalent class in Protobuf, you must declare it in the .proto file. The protoc\\ncompiler will then generate the .NET class as part of the build process.\\n\\nsyntax = \\\"proto3\\\";\\noption csharp_namespace = \\\"TraderSys\\\";\\nmessage Stock {\\n\\nint32 id = 1;\\n\\nstring symbol = 2;\\n\\nstring display_name\\nint32 market_id = 4;\\n\\nIl\\nUW\\nwe\\n\\nThe first line dec\", \"lares the syntax version being used. Version 3 of the language was released in 2016.\\nIt's the version that we recommend for gRPC services.\\n\\nThe option csharp_namespace line specifies the namespace to be used for the generated C# types.\\nThis option will be ignored when the .proto file is compiled for other languages. Protobuf files often\\ncontain language-specific options for several languages.\\n\\nThe Stock message definition specifies four fields. E\", \"ach has a type, a name, and a field number.\\n\\nField numbers\\n\\nField numbers are an important part of Protobuf. They're used to identify fields in the binary encoded\\ndata, which means they can\\u2019t change from version to version of your service. The advantage is that\\nbackward compatibility and forward compatibility are possible. Clients and services will ignore field\\nnumbers that they don\\u2019t know about, as long as the possibility of missing values is ha\", \"ndled.\\n\\nIn the binary format, the field number is combined with a type identifier. Field numbers from 1 to 15\\ncan be encoded with their type as a single byte. Numbers from 16 to 2,047 take 2 bytes. You can go\\nhigher if you need more than 2,047 fields on a message for any reason. The single-byte identifiers for\\nfield numbers 1 to 15 offer better performance, so you should use them for the most basic, frequently\\nused fields.\\n\\n12 CHAPTER 3 | Protoco\", \"l buffers\\nTypes\\n\\nThe type declarations are using Protobuf's native scalar data types, which are discussed in more detail\\nin the next section. The rest of this chapter will cover Protobuf's built-in types and show how they\\nrelate to common .NET types.\\n\\nNote\\n\\nProtobuf doesn\\u2019t natively support a decimal type, so double is used instead. For applications that\\nrequire full decimal precision, refer to the section on decimals in the next part of this cha\", \"pter.\\n\\nThe generated code\\n\\nWhen you build your application, Protobuf creates classes for each of your messages, mapping Its\\nnative types to C# types. The generated Stock type would have the following signature:\\n\\npublic class Stock\\n\\n{\\npublic int Id { get; set; }\\npublic string Symbol { get; set; }\\npublic string DisplayName { get; set; }\\npublic int MarketId { get; set; }\\n\\nThe actual code that's generated is far more complicated than this. The reason\", \" is that each class\\ncontains all the code necessary to serialize and deserialize itself to the binary wire format.\\n\\nProperty names\\n\\nNote that the Protobuf compiler applied PascalCase to the property names, although they were\\nsnake_case in the .proto file. The Protobuf style guide recommends using snake_case in your message\\ndefinitions so that the code generation for other platforms produces the expected case for their\\nconventions.\\n\\nProtobuf scala\", \"r data types\\n\\nProtocol Buffer (Protobuf) supports a range of native scalar value types. The following table lists them\\nall with their equivalent C# type:\\n\\ndouble double\\nFloat float\\nint32 int\\n\\n13 CHAPTER 3 | Protocol buffers\\nsint32 int\\n\\nsfixed32 int\\n\\nstixed64 long\\n\\nbool\\n\\nstring string\\n\\nbytes ByteString\\nNotes:\\n\\n1. The standard encoding for int32 and int64 is inefficient when you're working with signed\\nvalues. If your field is likely to contain nega\", \"tive numbers, use sint32 or sint64 instead. These\\ntypes map to the C# int and long types, respectively.\\n\\n2. _ The fixed fields always use the same number of bytes no matter what the value Is. This\\nbehavior makes serialization and deserialization faster for larger values.\\n\\n3.  Protobuf strings are UTF-8 (or 7-bit ASCII) encoded. The encoded length can't be greater than\\n232.\\n\\n4. The Protobuf runtime provides a ByteString type that maps easily to an\", \"d from C# byte[]\\narrays.\\n\\nOther .NET primitive types\\n\\nDates and times\\n\\nThe native scalar types don\\u2019t provide for date and time values, equivalent to C#\\u2019s DateTimeOffset,\\nDateTime, and TimeSpan. You can specify these types by using some of Google's \\u201cWell Known Types\\u201d\\nextensions. These extensions provide code generation and runtime support for complex field types\\nacross the supported platforms.\\n\\nThe following table shows the date and time types:\\n\\np\", \"rotobuf well-known type\\nDateTimeOffset google.protobuf.Timestamp\\n\\ngoogle.protobuf.Timestamp\\ngoogle.protobuf.Duration\\n\\nsyntax = \\\"proto3\\\"\\n\\nimport \\\"google/protobuf/duration.proto\\\" ;\\nimport \\\"google/protobuf/timestamp. proto\\\";\\n\\nmessage Meeting {\\n\\n14 CHAPTER 3 | Protocol buffers\\nstring subject = 1;\\ngoogle.protobuf.Timestamp time = 2;\\ngoogle.protobuf.Duration duration =\\n\\n33\\n\\nThe generated properties in the C# class aren't the .NET date and time types. T\", \"he properties use the\\nTimestamp and Duration classes in the Google.Protobuf.WellKnownTypes namespace. These classes\\nprovide methods for converting to and from DateTimeOffset, DateTime, and TimeSpan.\\n\\n// Create Timestamp and Duration from .NET DateTimeOffset and TimeSpan\\nvar meeting = new Meeting\\n\\nt\\n\\nTime = Timestamp.FromDateTimeOffset(meetingTime), // also FromDateTime()\\nDuration = Duration. FromTimeSpan(meetingLength)\\n\\n}3\\n// Convert Timestamp an\", \"d Duration to .NET DateTimeOffset and TimeSpan\\n\\nDateTimeOffset time = meeting.Time.ToDateTimeOffset() ;\\nTimeSpan? duration = meeting.Duration?.ToTimeSpan() ;\\n\\nNote\\n\\nThe Timestamp type works with UTC times. DateTimeOffset values always have an offset of zero, and\\nthe DateTime.Kind property is always DateTimeKind.Utc.\\n\\nSystem.Guid\\n\\nProtobuf doesn\\u2019t directly support the Guid type, known as UUID on other platforms. There\\u2019s no well-\\nknown type for it.\", \"\\n\\nThe best approach is to handle Guid values as a string field, by using the standard 8-4-4-4-12\\nhexadecimal format (for example, 45a9fda3-bd01-47a9-8460-c1cd7484b0b3). All languages and\\nplatforms can parse that format.\\n\\nDon't use a bytes field for Guid values. Problems with endianness (Wikipedia definition) can result in\\nerratic behavior when Protobuf is interacting with other platforms, such as Java.\\n\\nNullable types\\n\\nThe Protobuf code generatio\", \"n for C# uses the native types, such as int for int32. So the values are\\nalways included and can't be null.\\n\\nFor values that require explicit null, such as using int? in your C# code, Protobuf's \\u201cWell Known Types\\u201d\\ninclude wrappers that are compiled to nullable C# types. To use them, import wrappers.proto into\\nyour .proto file, like this:\\n\\nsyntax = \\\"proto3\\\"\\n\\nimport \\\"google/protobuf/wrappers. proto\\\";\\n\\nmessage Person {\\n\\n15 CHAPTER 3 | Protocol buffe\", \"rs\\ngoogle.protobuf.Int32Value age = 5;\\n\\nProtobuf will use the simple T? (for example, int?) for the generated message property.\\n\\nThe following table shows the complete list of wrapper types with their equivalent C# type:\\n\\nng?\\nfine\\nng?\\n\\nlong? google.protobuf.|nt64Value\\nuint? google.protobuf.UInt32Value\\nulong? google.protobuf.UInt64Value\\n\\nThe well-known types Timestamp and Duration are represented in .NET as classes. In C# 8 and\\nbeyond, you can use\", \" nullable reference types. But it\\u2019s important to check for null on properties of\\nthose types when you're converting to DateTimeOffset or TimeSpan.\\n\\nDecimals\\n\\nProtobuf doesn\\u2019t natively support the .NET decimal type, just double and float. There\\u2019s an ongoing\\ndiscussion in the Protobuf project about the possibility of adding a standard Decimal type to the well-\\nknown types, with platform support for languages and frameworks that support it. Nothing \", \"has been\\nimplemented yet.\\n\\nIt's possible to create a message definition to represent the decimal type that would work for safe\\nserialization between .NET clients and servers. But developers on other platforms would have to\\nunderstand the format being used and implement their own handling for it.\\n\\nCreating a custom decimal type for Protobuf\\n\\nA simple implementation might be similar to the nonstandard Money type that some Google APIs\\nuse, without t\", \"he currency field.\\n\\npackage CustomTypes;\\n\\n// Example: 12345.6789 -> { units = 12345, nanos = 678900000 }\\nmessage DecimalValue {\\n\\n// Whole units part of the amount\\nint64 units = 1;\\n\\n// Nano units of the amount (10%-9)\\n// Must be same sign as units\\nsfixed32 nanos = 2;\\n\\n16 CHAPTER 3 | Protocol buffers\\nThe nanos field represents values from 0.999 _999_999 to -0.999_999_999. For example, the decimal\\nvalue 1.5m would be represented as { units = 1, nano\", \"s = 500_000_000 }. This is why the nanos field in\\nthis example uses the sfixed32 type, which encodes more efficiently than int32 for larger values. If the\\nunits field is negative, the nanos field should also be negative.\\n\\nNote\\n\\nThere are multiple other algorithms for encoding decimal values as byte strings, but this message is\\n\\neasier to understand than any of them. The values are not affected by endianness on different\\nplatforms.\\n\\nConversion bet\", \"ween this type and the BCL decimal type might be implemented in C# like this:\\n\\nnamespace CustomTypes;\\npublic partial class DecimalValue\\n\\n{\\nprivate const decimal NanoFactor = 1 000 000 000;\\n\\npublic DecimalValue(long units, int nanos)\\n\\nUnits = units;\\nNanos nanos;\\n\\n}\\n\\npublic static implicit operator decimal(CustomTypes.DecimalValue grpcDecimal)\\n\\nt\\n}\\n\\nreturn grpcDecimal.Units + grpcDecimal.Nanos / NanoFactor;\\n\\npublic static implicit operator CustomTy\", \"pes.DecimalValue(decimal value)\\n\\nt\\n\\nvar units = decimal. ToInt64(value) ;\\nvar nanos = decimal. ToInt32((value - units) * NanoFactor) ;\\nreturn new CustomTypes.DecimalValue(units, nanos) ;\\n\\nImportant\\n\\nWhenever you use custom message types like this, you must document them with comments in\\n.proto. Other developers can then implement conversion to and from the equivalent type in their own\\nlanguage or framework.\\n\\nProtobuf nested types\\n\\nJust as C# allo\", \"ws you to declare classes inside other classes, Protocol Buffer (Protobuf) allows you to\\nnest message definitions within other messages. The following example shows how to create nested\\nmessage types:\\n\\nmessage Outer {\\nmessage Inner {\\nstring text = 1;\\n\\n}\\n\\n17 CHAPTER 3 | Protocol buffers\\nInner inner = 1;\\n\\ni\\n\\nIn the generated C# code, the Inner type will be declared in a nested static Types class within the\\nHelloRequest class:\\n\\nvar inner = new Outer\", \".Types.Inner { Text = \\\"Hello\\\" };\\n\\nRepeated fields for lists and arrays\\n\\nYou specify lists in Protocol Buffer (Protobuf) by using the repeated prefix keyword. The following\\nexample shows how to create a list:\\n\\nmessage Person {\\n// Other fields elided\\n\\nrepeated string aliases\\n\\nIn the generated code, repeated fields are represented by read-only properties of the\\nGoogle.Protobuf.Collections.RepeatedField<T> type rather than any of the built-in .NET co\", \"llection\\ntypes. This type implements all the standard .NET collection interfaces, such as IList and IEnumerable.\\nSo you can use LINQ queries or convert it to an array or a list easily.\\n\\nThe RepeatedField<T> type includes the code required to serialize and deserialize the list to the\\nbinary wire format.\\n\\nProtobuf reserved fields\\n\\nThe backward-compatibility guarantees in Protocol Buffer (Protobuf) rely on field numbers always\\nrepresenting the same \", \"data item. If a field is removed from a message in a new version of the service,\\nthat field number should never be reused. You can enforce this behavior by using the reserved\\nkeyword.\\n\\nIf the displayName and marketld fields were removed from the Stock message defined earlier, their\\nfield numbers should be reserved as in the following example.\\n\\nsyntax \\\"proto3\\\";\\n\\nmessage Stock {\\n\\nreserved 3, 4;\\nint32 id = 1;\\nstring symbol = 2;\\n\\nYou can also use the\", \" reserved keyword as a placeholder for fields that might be added in the future.\\nYou can express contiguous field numbers as a range by using the to keyword.\\n\\nsyntax \\\"proto3\\\";\\nmessage Info {\\n\\n18 CHAPTER 3 | Protocol buffers\\nreserved 2, 9 to 11, 15;\\n// ...\\n\\nProtobuf Any and Oneot fields for variant types\\n\\nHandling dynamic property types (that is, properties of type object) in Windows Communication\\nFoundation (WCF) is complicated. For example, you \", \"must specify serializers and provide KnownType\\nattributes.\\n\\nProtocol Buffer (Protobuf) provides two simpler options for dealing with values that might be of more\\nthan one type. The Any type can represent any known Protobuf message type. And you can use the\\noneof keyword to specify that only one of a range of fields can be set in any message.\\n\\nAny\\n\\nAny is one of Protobuf's \\u201cwell-known types\\u201d: a collection of useful, reusable message types with\\nimp\", \"lementations in all supported languages. To use the Any type, you must import the\\ngoogle/protobuf/any.proto definition.\\n\\nsyntax = \\\"proto3\\\";\\nimport \\\"google/protobuf/any.proto\\u201d ;\\n\\nmessage Stock {\\n// Stock-specific data\\n}\\n\\nmessage Currency {\\n// Currency-specific data\\n\\n5\\n\\nmessage ChangeNotification {\\nint32 id = 1;\\ngoogle.protobuf.Any instrument = 2;\\n\\nIn the C# code, the Any class provides methods for setting the field, extracting the message, and\\nche\", \"cking the type.\\n\\npublic void FormatChangeNotification(ChangeNotification change)\\n\\nif (change. Instrument.Is(Stock.Descriptor) )\\n\\n{\\nFormatStock( change. Instrument .Unpack<Stock>());\\n\\nelse if (change. Instrument.Is(Currency.Descriptor) )\\n\\nt\\n}\\n\\nelse\\n\\nt\\n\\nFormatCurrency (change. Instrument.Unpack<Currency>());\\n\\nthrow new ArgumentException( \\\"Unknown instrument type\\\") ;\\n\\n19 CHAPTER 3 | Protocol buffers\\nhe |\\n\\nProtobuf's internal reflection code uses the\", \" Descriptor static field on each generated type to resolve\\nAny field types. There's also a TryUnpack<T> method, but that creates an uninitialized instance of T\\neven when it fails. It\\u2019s better to use the Is method as shown earlier.\\n\\nOneof\\n\\nOneof fields are a language feature: the compiler handles the oneof keyword when it generates the\\nmessage class. Using oneof to specify the ChangeNotification message might look like this:\\n\\nmessage Stock {\\n// St\", \"ock-specific data\\n\\n5\\n\\nmessage Currency {\\n// Currency-specific data\\n\\n5\\n\\nmessage ChangeNotification {\\nint32 id = 1;\\noneof instrument {\\nStock stock = 2;\\nCurrency currency = 3;\\n}\\n}\\n\\nFields within the oneof set must have unique field numbers in the overall message declaration.\\n\\nWhen you use oneof, the generated C# code includes an enum that specifies which of the fields has\\nbeen set. You can test the enum to find which field Is set. Fields that aren't\", \" set return null or the\\ndefault value, rather than throwing an exception.\\n\\npublic void FormatChangeNotification(ChangeNotification change)\\n\\nt\\n\\nSwitch (change. InstrumentCase)\\n{\\ncase ChangeNotification. InstrumentOneofCase.None:\\nreturn;\\ncase ChangeNotification. InstrumentOneofCase. Stock:\\nFormatStock(change.Stock) ;\\n\\nbreak;\\ncase ChangeNotification. InstrumentOneofCase. Currency:\\nFormatCurrency(change.Currency) ;\\nbreak;\\ndefault:\\nthrow new ArgumentE\", \"xception(\\\"Unknown instrument type\\\") ;\\n\\nSetting any field that\\u2019s part of a oneof set will automatically clear any other fields in the set. You can't\\nuse repeated with oneof. Instead, you can create a nested message with either the repeated field or\\nthe oneof set to work around this limitation.\\n\\n20 CHAPTER 3 | Protocol buffers\\nProtobuf enumerations\\n\\nProtobuf supports enumeration types. You saw this support in the previous section, where an enum\\nwas\", \" used to determine the type of a Oneof field. You can define your own enumeration types, and\\nProtobuf will compile them to C# enum types.\\n\\nBecause you can use Protobuf with various languages, the naming conventions for enumerations are\\ndifferent from the C# conventions. However, the code generator converts the names to the traditional\\nC# case. If the Pascal-case equivalent of the field name starts with the enumeration name, then it's\\nremoved.\\n\\nFo\", \"r example, in the following Protobuf enumeration, the fields are prefixed with ACCOUNT_STATUS.\\nThis prefix is equivalent to the Pascal-case enum name, AccountStatus.\\n\\nenum AccountStatus {\\nACCOUNT_STATUS_ UNKNOWN 0;\\nACCOUNT_STATUS_ PENDING 1;\\n\\nACCOUNT STATUS ACTIVE = 2;\\nACCOUNT STATUS SUSPENDED = 3;\\nACCOUNT STATUS CLOSED = 4;\\n\\nThe generator creates a C# enum equivalent to the following code:\\n\\npublic enum AccountStatus\\n{\\n\\nUnknown 0,\\n\\nPending = 1,\\n\\n\", \"Active = 2,\\n\\nSuspended = 3,\\n\\nClosed = 4\\n\\nProtobuf enumeration definitions must have a zero constant as their first field. As in C#, you can\\ndeclare multiple fields with the same value. But you must explicitly enable this option by using the\\nallow_alias option in the enum:\\n\\nenum AccountStatus {\\noption allow_alias = true;\\nACCOUNT_STATUS_ UNKNOWN = @;\\nACCOUNT_STATUS_PENDING = 1;\\n\\nACCOUNT STATUS ACTIVE = 2;\\nACCOUNT STATUS SUSPENDED = 3;\\nACCOUNT STATU\", \"S CLOSED = 4;\\n\\nYou can declare enumerations at the top level in a .proto file, or nested within a message definition.\\nNested enumerations\\u2014like nested messages\\u2014will be declared within the .Types static class in the\\ngenerated message class.\\n\\nThere's no way to apply the [Flags] attribute to a Protobuf-generated enum, and Protobuf doesn\\u2019t\\nunderstand bitwise enum combinations. Look at the following example:\\n\\nenum Region {\\nREGION_NONE = @;\\n\\n21 CHAPTER \", \"3 | Protocol buffers\\nREGION _NORTH_AMERICA\\nREGION SOUTH_AMERICA\\nREGION_EMEA = 4;\\nREGION_APAC =\\n\\n}\\n\\nmessage Product {\\nRegion available _ in = 1;\\n\\n}\\n\\nIf you set product.Availableln to Region.NorthAmerica | Region.SouthAmerica, it\\u2019s serialized as the\\ninteger value 3. When a client or server tries to deserialize the value, it won't find a match in the enum\\ndefinition for 3. The result will be Region.None.\\n\\nThe best way to work with multiple enum valu\", \"es in Protobuf is to use a repeated field of the enum\\ntype.\\n\\nProtobuf maps for dictionaries\\n\\nIt's important to be able to represent arbitrary collections of named values in messages. In .NET, this\\nactivity is commonly handled through dictionary types. The equivalent of the .NET\\n[Dictionary<TKey,TValue> type in Protocol Buffer (Protobuf) is the map<key_type, value_type> type.\\nThis section shows how to declare a map type in Protobuf, and how to use\", \" the generated code.\\n\\nmessage StockPrices {\\n\\nmap<string, double> prices = 1;\\n\\ni\\n\\nIn the generated code, map fields are represented by read-only properties of the\\nGoogle.Protobuf.Collections.MapField<TKey, TValue> type. This type implements the standard .NET\\ncollection interfaces, including |Dictionary<TKey,TValue>.\\n\\nMap fields can't be directly repeated in a message definition. But you can create a nested message\\nthat contains a map and use repea\", \"ted on the message type, as in the following example:\\nmessage Order {\\nmessage Attributes {\\nmap<string, string> values = 1;\\n\\nrepeated Attributes attributes = 1;\\n\\nUsing MapField properties in code\\n\\nThe MapField properties generated from map fields are read-only, and will never be null. To set a map\\nproperty, use the Add(IDictionary<TKey,TValue> values) method on the empty MapField property to\\ncopy values from any .NET dictionary.\\n\\npublic Order Crea\", \"teOrder(Dictionary<string, string> attributes)\\n\\nt\\n\\nvar order = new Order();\\norder.Attributes.Add(attributes) ;\\n\\n22 CHAPTER 3 | Protocol buffers\\nreturn order;\\n| } |\\n\\nFurther reading\\n\\nFor more information about Protobuf, see the official Protobuf documentation.\\n\\n23 CHAPTER 3 | Protocol buffers\\nCHAPTER\\n\\nComparing WCF to gRPC\\n\\nThe previous chapter gave you a good look at Protobuf and how gRPC handles messages. Before you\\nwork through a detailed conve\", \"rsion from Windows Communication Foundation (WCF) to gRPC, it\\u2019s\\nimportant to know how the features available in WCF are handled in gRPC and what workarounds you\\ncan use when there's no gRPC equivalent. In particular, this chapter will cover the following subjects:\\n\\n. Operations and methods\\n\\n. Bindings and transports\\n\\u00b0 RPC types\\n\\n. Metadata\\n\\n. Error handling\\n\\n. WS-* protocols\\n\\ngRPC example\\n\\nWhen you create a new ASP.NET Core 7.0 gRPC project from \", \"Visual Studio 2022 or the command line,\\nthe gRPC equivalent of \\u201cHello World\\u201d is generated for you. It consists of a greeter.proto file that\\n\\ndefines the service and its messages, and a GreeterService.cs file with an implementation of the\\n\\nservice.\\nsyntax = \\\"proto3\\\";\\noption csharp_namespace = \\\"HelloGrpc\\\";\\n\\npackage Greet;\\n\\n// The greeting service definition.\\nservice Greeter {\\n// Sends a greeting\\nrpc SayHello (HelloRequest) returns (HelloReply) ;\\n\\n5\", \"\\n\\n// The request message that contains the user's name.\\nmessage HelloRequest {\\nstring name = 1;\\n\\n5\\n\\n// The response message that contains the greetings.\\nmessage HelloReply {\\nstring message = 1;\\n\\n5\\n\\n24 CHAPTER 4 | Comparing WCF to gRPC\\nnamespace HelloGrpc;\\n\\npublic class GreeterService : Greeter.GreeterBase\\n\\nt\\n\\nprivate readonly ILogger<GreeterService> _logger;\\npublic GreeterService(ILogger<GreeterService> logger)\\n\\nt\\n}\\n\\n_logger = logger;\\n\\npublic ove\", \"rride Task<HelloReply> SayHello(HelloRequest request, ServerCallContext\\ncontext)\\n\\nt\\n\\nreturn Task.FromResult (new HelloReply\\n\\nt\\n\\nMessage = \\\"Hello \\\" + request.Name\\n\\nThis chapter will refer to this example code when explaining different concepts and features of gRPC.\\n\\nWCF endpoints and gRPC methods\\n\\nIn Windows Communication Foundation (WCF), when you're writing your application code, you use\\none of the following methods:\\n\\n\\u00b0 You write the application\", \" code in a class and decorate methods with the OperationContract\\nattribute.\\n\\n\\u00b0 You declare an interface for the service and add OperationContract attributes to the interface.\\n\\nFor example, the WCF equivalent of the greet.proto Greeter service might be written as follows:\\n\\n[ServiceContract |\\npublic interface IGreeterService\\n\\nt\\n\\n[OperationContract |\\nstring SayHello(string name) ;\\n\\nChapter 3 showed that Protobuf message definitions are used to gener\", \"ate data classes. Service and\\nmethod declarations are used to generate base classes that you inherit from to implement the service.\\nYou just declare the methods to be implemented in the .proto file, and the compiler generates a base\\nclass with virtual methods that you must override.\\n\\nOperationContract properties\\n\\nThe OperationContract attribute has properties to control or refine how it works. gRPC methods don't\\noffer this type of control. The fo\", \"llowing table lists those OperationContract properties and describes\\nhow the functionality that they specify is (or isn\\u2019t) dealt with in gRPC:\\n\\n25 CHAPTER 4 | Comparing WCF to gRPC\\npackage, service, and rpc from the .proto file.\\n\\nIsOneWay One-way gRPC methods return Empty results or use client\\nstreaming.\\n\\nIsTerminating See the paragraph after this table.\\n\\nName This property is SOAP related and has no meaning in gRPC.\\n\\nProtectionLevel There's no m\", \"essage encryption. Network encryption is\\nhandled at the transport layer (TLS over HTTP/2).\\n\\nReplyAction This property is SOAP related and has no meaning in gRPC.\\n\\nThe IsInitiating property lets you indicate that a method within ServiceContract can\\u2019t be the first\\nmethod called as part of a session. The IsTerminating property causes the server to close the session\\nafter an operation is called (or the client, if the property is used on a callback cl\", \"ient). In gRPC, streams\\nare created by single methods and closed explicitly. See gRPC streaming.\\n\\nFor more information on gRPC security and encryption, see chapter 6.\\n\\nWCF bindings and transports\\n\\nWindows Communication Foundation (WCF) has built-in bindings that specify different network\\nprotocols, wire formats, and other implementation details. gRPC effectively has just one network\\nprotocol and one wire format. (Technically you can customize the\", \" wire format, but that\\u2019s beyond the\\nscope of this book.) You're likely to discover that gRPC offers the best solution in most cases.\\n\\nWhat follows is a short discussion about the most relevant WCF bindings and how they compare to\\ntheir equivalents in gRPC.\\n\\nNetTCP\\n\\nWCF's NetTCP binding allows for persistent connections, small messages, and two-way messaging.\\nBut it works only between .NET clients and servers. gRPC allows the same functionality bu\", \"t is\\nsupported across multiple programming languages and platforms.\\n\\ngRPC has many features of WCF's NetTCP binding, but they\\u2019re not always implemented in the same\\nway. For example, in WCF, encryption is controlled through configuration and handled in the\\nframework. In gRPC, encryption is achieved at the connection level through HTTP/2 over TLS.\\n\\n26 CHAPTER 4 | Comparing WCF to gRPC\\nHTTP\\n\\nThe WCF binding called BasicHttpBinding is usually text-ba\", \"sed and uses SOAP as the wire format. It\\u2019s\\nslow compared to the NetTCP binding. It\\u2019s used to provide cross-platform interoperability, or\\nconnection over internet infrastructure.\\n\\nThe equivalent in gRPC uses HTTP/2 as the underlying transport layer with the binary Protobuf wire\\nformat for messages. So it can offer performance at the NetTCP service level and full cross-platform\\ninteroperability with all modern programming languages and frameworks.\\n\", \"\\nNamed pipes\\n\\nWCF provided a named pipes binding for communication between processes on the same physical\\nmachine. ASP.NET Core gRPC doesn't support named pipes. For inter-process communication (IPC)\\nusing gRPC instead supports Unix domain sockets. Unix domain sockets are supported on Linux and\\nmodern versions of Windows.\\n\\nFor more information, see Inter-process communication with gRPC.\\n\\nMSMQ\\n\\nMSMQ is a proprietary Windows message queue. WCF's bi\", \"nding to MSMQ enables \\u201cfire and forget\\u201d\\nrequests from clients that might be processed at any time in the future. gRPC doesn't natively provide\\nany message queue functionality.\\n\\nThe best alternative is to directly use a messaging system like Azure Service Bus, RabbitMQ, or Kafka.\\nYou can implement this functionality with the client placing messages directly onto the queue, or a\\ngRPC client streaming service that enqueues the messages.\\n\\nWebHttpBind\", \"ing\\n\\nWebHttpBinding (also known as WCF REST), with the WebGet and WebInvoke attributes, enabled you\\nto develop RESTful APIs that could speak JSON at a time when this behavior was less common. If you\\nhave a RESTful API built with WCF REST, consider migrating it to a regular ASP.NET Core MVC Web\\nAPI application. This migration would provide the same functionality as a conversion to gRPC.\\n\\nTypes of RPC\\n\\nAs a Windows Communication Foundation (WCF) de\", \"veloper, you're probably used to dealing with the\\nfollowing types of remote procedure call (RPC):\\n\\n\\u00b0 Request/reply\\n\\n\\u00b0 Duplex:\\n- One-way duplex with session\\n- Full duplex with session\\n\\n\\u00b0 One-way\\n\\n27 CHAPTER 4 | Comparing WCF to gRPC\\nIt's possible to map these RPC types fairly naturally to existing gRPC concepts. This chapter will look at\\neach of these areas in turn. Chapter 5 will explore similar examples in greater depth.\\n\\nWCF gRPC\\n\\nDuplex servic\", \"e with session using a client | Server streaming\\ncallback interface\\nFull duplex service with session Bidirectional streaming\\n\\nOne-way operations Client streaming\\n\\nRequest/reply\\n\\nFor simple request/reply methods that take and return small amounts of data, use the simplest gRPC\\npattern, the unary RPC.\\n\\nservice Things {\\nrpc Get(GetThingRequest) returns (GetThingResponse) ;\\n\\npublic class ThingService : Things.ThingsBase\\n\\n{\\npublic override async Task<\", \"GetThingResponse> Get(GetThingRequest request,\\nServerCallContext context)\\n\\n// Get thing from database\\nreturn new GetThingResponse { Thing = thing };\\n\\npublic async Task ShowThing(int thingId)\\n{\\n\\nvar thing = await _thingsClient.GetAsync(new GetThingRequest { ThingId = thingId });\\nConsole.WriteLine($\\\"{thing.Name}\\\") ;\\n\\nAs you can see, implementing a gRPC unary RPC service method is similar to implementing a WCF\\noperation. The difference is that with \", \"gRPC, you override a base class method instead of\\nimplementing an interface. On the server, gRPC base methods always return Task, although the client\\nprovides both async and blocking methods to call the service.\\n\\nWCF duplex, one way to client\\n\\nWCF applications (with certain bindings) can create a persistent connection between client and server.\\nThe server can asynchronously send data to the client until the connection is closed, by using a\\ncallba\", \"ck interface specified in the ServiceContractAttribute.CallbackContract property.\\n\\ngRPC services provide similar functionality with message streams. Streams don't map exactly to WCF\\nduplex services in terms of implementation, but you can achieve the same results.\\n\\n28 CHAPTER 4 | Comparing WCF to gRPC\\ngRPC streaming\\n\\ngRPC supports the creation of persistent streams from client to server, and from server to client. Both\\ntypes of stream can be activ\", \"e concurrently. This ability is called bidirectional streaming.\\n\\nYou can use streams for arbitrary, asynchronous messaging over time. Or you can use them for\\npassing large datasets that are too big to generate and send in a single request or response.\\n\\nThe following example shows a server-streaming RPC.\\n\\nservice ClockStreamer {\\nrpc Subscribe(ClockSubscribeRequest) returns (stream ClockMessage) ;\\n\\n5\\n\\npublic class ClockStreamerService : ClockStream\", \"er.ClockStreamerBase\\n\\nt\\n\\npublic override async Task Subscribe(ClockSubscribeRequest request,\\nIServerStreamWriter<ClockMessage> responseStream,\\nServerCallContext context)\\n\\nwhile (!context.CancellationToken.IsCancellationRequested)\\n\\nt\\n\\nvar time = DateTimeOffset.UtcNow;\\n\\nawait responseStream.WriteAsync(new ClockMessage { message = $\\\"The time is\\n{time:t}.\\\" });\\n\\nawait Task.Delay(TimeSpan.FromSeconds(1@), context.CancellationToken) ;\\n\\nThis server strea\", \"m can be consumed from a client application, as shown in the following code:\\n\\npublic async Task TellTheTimeAsync(CancellationToken token)\\n\\n{\\nvar channel = GrpcChannel.ForAddress(\\\"https://localhost:50@1\\\") ;\\n\\nvar client = new ClockStreamer.ClockStreamerClient (channel) ;\\n\\nvar request = new ClockSubscribeRequest() ;\\nvar response = client.Subscribe(request) ;\\n\\nawait foreach (var update in response.ResponseStream.ReadAllAsync(token) )\\n\\nt\\n}\\n\\nConsole.Wr\", \"iteLine(update.Message) ;\\n\\nNote\\n\\nServer-streaming RPCs are useful for subscription-style services. They're also useful for sending large\\ndatasets when it would be inefficient or impossible to build the entire dataset in memory. However,\\nstreaming responses isn't as fast as sending repeated fields in a single message. As a rule, streaming\\nshouldn't be used for small datasets.\\n\\n29 CHAPTER 4 | Comparing WCF to gRPC\\nDifferences from WCF\\n\\nA WCF duplex\", \" service uses a client callback interface that can have multiple methods. A gRPC server-\\nstreaming service can only send messages over a single stream. If you need multiple methods, use a\\nmessage type with either an Any field or a oneof field to send different messages, and write code in\\nthe client to handle them.\\n\\nIn WCF, the ServiceContract class with the session is kept alive until the connection is closed. Multiple\\nmethods can be called withi\", \"n the session. In gRPC, the Task that the implementation method returns\\nshouldn't finish until the connection is closed.\\n\\nWCF one-way operations and gRPC client streaming\\n\\nWCF provides one-way operations (marked with [OperationContract(IsOneWay = true)]) that return a\\ntransport-specific acknowledgment. gRPC service methods always return a response, even if it's\\nempty. The client should always await that response. For the \\u201cfire-and-forget\\u201d style o\", \"f messaging in\\nQRPC, you can create a client streaming service.\\n\\nthing_log.proto\\n\\nservice ThingLog {\\n\\nrpc OpenConnection(stream Thing) returns (ConnectionClosedResponse) ;\\n\\ni\\n\\nThingLogService.cs\\n\\npublic class ThingLogService : Protos. ThingLog.ThingLogBase\\n{\\n\\nprivate static readonly ConnectionClosedResponse EmptyResponse = new\\nConnectionClosedResponse() ;\\n\\nprivate readonly ILogger<ThingLogService> _logger;\\n\\npublic ThingLogService(ILogger<ThingLog\", \"Service> logger)\\n\\nt\\n_logger = logger;\\n\\npublic override async Task<CompletedResponse> OpenConnection(IAsyncStreamReader<Thing>\\nrequestStream, ServerCallContext context)\\n\\nwhile (await requestStream.MoveNext(context.CancellationToken) )\\n\\nt\\n}\\n\\nreturn EmptyResponse;\\n\\n_logger.LogInformation(requestStream.Current.Description) ;\\n\\nThingLog client example\\n\\npublic class ThingLogger : IAsyncDisposable\\n{\\n\\nprivate readonly ThingLog.ThingLogClient _client;\\npriv\", \"ate readonly AsyncClientStreamingCall<ThingLogRequest, CompletedResponse> _stream;\\n\\npublic ThingLogger(ThingLog.ThingLogClient client)\\n\\n30 CHAPTER 4 | Comparing WCF to gRPC\\n_client = client;\\n_stream = client.OpenConnection() ;\\n}\\npublic async Task WriteAsync(string description)\\n{\\nawait _stream.RequestStream.WriteAsync(new Thing\\n{\\nDescription = description,\\nTime = Timestamp.FromDateTimeOffset (DateTimeOffset .UtcNow)\\n})3\\n}\\n\\npublic async ValueTask D\", \"isposeAsync()\\n{\\n\\nawait _stream.RequestStream.CompleteAsync();\\n_stream.Dispose();\\n\\nYou can use client-streaming RPCs for fire-and-forget messaging, as shown in the previous example.\\nYou can also use them for sending very large datasets to the server. The same warning about\\nperformance applies: for smaller datasets, use repeated fields in regular messages.\\n\\nWCF full-duplex services\\n\\nWCF duplex binding supports multiple one-way operations on both th\", \"e service interface and the\\nclient callback interface. This support allows ongoing conversations between client and server. gRPC\\nsupports something similar with bidirectional streaming RPCs, where both parameters are marked\\nwith the stream modifier.\\n\\nchat.proto\\n\\nservice Chatter {\\n\\nrpc Connect(stream IncomingMessage) returns (stream OutgoingMessage) ;\\n\\ni\\n\\nChatterService.cs\\n\\npublic class ChatterService : Chatter.ChatterBase\\n\\nt\\n\\nprivate readonly ICh\", \"atHub _hub;\\n\\npublic ChatterService(IChatHub hub)\\n{\\n\\n}\\n\\n_hub = hub;\\n\\npublic override async Task Connect(IAsyncStreamReader<MessageRequest> requestStream,\\nIServerStreamWriter<MessageResponse> responseStream, ServerCallContext context)\\n\\nt\\n\\n_hub.MessageReceived += async (sender, args) =>\\nawait responseStream.WriteAsync(new MessageResponse {Text = args.Message}) ;\\n\\nwhile (await requestStream.MoveNext(context.CancellationToken) )\\n\\nt\\n\\n31 CHAPTER 4 | Com\", \"paring WCF to gRPC\\nawait _hub.SendAsync(requestStream. Current. Text) ;\\n\\nIn the previous example, you can see that the implementation method receives both a request stream\\n([AsyncStreamReader<MessageRequest>) and a response stream\\n(IServerStreamWriter<MessageResponse>). The method can read and write messages until the\\nconnection is closed.\\n\\nChatter client\\n\\npublic class Chat : IAsyncDisposable\\n{\\nprivate readonly Chatter.ChatterClient _client;\\npriv\", \"ate readonly AsyncDuplexStreamingCall<MessageRequest, MessageResponse> _stream;\\nprivate readonly CancellationTokenSource _cancellationTokenSource;\\nprivate readonly Task _readTask;\\n\\npublic Chat(Chatter.ChatterClient client)\\n{\\n\\n_client = client;\\n\\n_stream = _client.Connect();\\n\\n_cancellationTokenSource = new CancellationTokenSource() ;\\n_readTask = ReadAsync(_cancellationTokenSource. Token) ;\\n\\n}\\n\\npublic async Task SendAsync(string message)\\n\\nt\\n}\\n\\nawait\", \" _stream.RequestStream.WriteAsync(new MessageRequest {Text = message});\\n\\nprivate async Task ReadAsync(CancellationToken token)\\n\\nt\\n\\nwhile (await _stream.ResponseStream.MoveNext (token) )\\n\\nt\\n}\\n\\nConsole.WriteLine(_stream.ResponseStream.Current.Text) ;\\n\\n}\\n\\npublic async ValueTask DisposeAsync()\\n\\nawait _stream.RequestStream.CompleteAsync();\\nawait _readTask;\\n_stream.Dispose();\\n\\nMetadata\\n\\nMetadata refers to additional data that might be useful during the\", \" processing of requests and\\nresponses but that\\u2019s not part of the actual application data. Metadata might include authentication\\ntokens, request identifiers and tags for monitoring purposes, and information about the data, like the\\nnumber of records in a dataset.\\n\\n32 CHAPTER 4 | Comparing WCF to gRPC\\nIt's possible to add generic key/value headers to Windows Communication Foundation (WCF)\\nmessages by using an OperationContextScope and the Operation\", \"Context.OutgoingMessageHeaders\\nproperty and handle them by using MessageProperties.\\n\\ngRPC calls and responses can also include metadata that's similar to HTTP headers. This metadata is\\nmostly invisible to gRPC itself and is passed through to be processed by your application code or\\nmiddleware. Metadata is represented as key/value pairs, where the key is a string and the value is\\neither a string or binary data. You don\\u2019t need to specify metadata i\", \"n the .proto file.\\n\\nMetadata is handled by the Metadata class of the Grpc.Core.Api NuGet package. This class can be\\nused with collection initializer syntax.\\n\\nThis example shows how to add metadata to a call from a C# client:\\n\\nvar metadata = new Metadata\\n\\n{ \\\"Requester\\\", _clientName }\\n\\nJ\\n\\nvar request = new GetPortfolioRequest\\n\\n{\\n}3\\n\\nId = portfoliolId\\n\\nvar response = await client.GetPortfolioAsync(request, metadata) ;\\ngRPC services can access metada\", \"ta from the ServerCallContext argument\\u2019s RequestHeaders property:\\n\\npublic async Task<GetPortfolioResponse> GetPortfolio(GetPortfolioRequest request,\\nServerCallContext context)\\n\\nt\\n\\nvar requesterHeader = context.RequestHeaders.FirstOrDefault(e => e.Key == \\\"Requester\\\" ) ;\\nif (requesterHeader != null)\\n\\nt\\n\\n_logger.LogInformation($\\\"Request from {requesterHeader.Value}\\\") ;\\n\\nHi coc\\n\\nServices can send metadata to clients by using the ResponseTrailers prop\", \"erty of ServerCallContext:\\n\\npublic async Task<GetPortfolioResponse> GetPortfolio(GetPortfolioRequest request,\\nServerCallContext context)\\n\\nt\\n\\nHi coc\\n\\ncontext.ResponseTrailers.Add(\\\"Responder\\\", _serverName) ;\\n\\nHi coc\\n\\nError handling\\n\\nWindows Communication Foundation (WCF) uses FaultException and FaultContract to provide\\ndetailed error information, including supporting the SOAP Fault standard.\\n\\n33 CHAPTER 4 | Comparing WCF to gRPC\\nUnfortunately, the \", \"current version of gRPC lacks the sophistication found with WCF, and only has\\nlimited built-in error handling based on simple status codes and metadata. The following table is a\\nquick guide to the most commonly used status codes:\\n\\nGRPC_STATUS_UNIMPLEMENTED\\nGRPC_STATUS_ UNAVAILABLE\\nGRPC_STATUS_UNKNOWN\\n\\nGRPC_STATUS_INTERNAL Problem with encoding/decoding.\\nGRPC_STATUS UNAUTHENTICATED Authentication failed.\\n\\nGRPC_STATUS PERMISSION_DENIED Authorizatio\", \"n failed.\\n\\nGRPC_STATUS_CANCELLED Call was canceled, usually by the\\ncaller.\\n\\nRaise errors in ASP.NET Core gRPC\\n\\nAn ASP.NET Core gRPC service can send an error response by throwing an RpcException, which can be\\ncaught by the client as if it were in the same process. The RpcException must include a status code\\nand description, and can optionally include metadata and a longer exception message. The metadata\\ncan be used to send supporting data, simila\", \"r to how FaultContract objects can carry additional data\\nfor WCF errors.\\n\\npublic async Task<GetPortfolioResponse> GetPortfolio(GetPortfolioRequest request,\\nServerCallContext context)\\n{\\n\\nvar user = context.GetHttpContext().User;\\n\\nif (!ValidateUser(user) )\\n\\n{\\n\\nvar metadata = new Metadata\\n\\n{\\nIre\\n\\nthrow new RpcException(new Status(StatusCode.PermissionDenied, \\\"Permission\\ndenied\\\"), metadata) ;\\n\\n{ \\\"User\\\", user.Identity.Name }\\n\\n}\\n\\nCatch errors in gRPC c\", \"lients\\n\\nJust like WCF clients can catch FaultException errors, a gRPC client can catch an RpcException to\\nhandle errors. Because RpcException isn't a generic type, you can't catch different error types in\\ndifferent blocks. But you can use C#\\u2019s exception filters feature to declare separate catch blocks for\\ndifferent status codes, as shown in the following example:\\n\\ntry\\naf\\n\\nvar portfolio = await client.GetPortfolioAsync(new GetPortfolioRequest { Id\", \" = id });\\n\\ncatch (RpcException ex) when (ex.StatusCode == StatusCode.PermissionDenied )\\n\\n34 CHAPTER 4 | Comparing WCF to gRPC\\nvar userEntry = ex.Trailers.FirstOrDefault(e => e.Key == \\\"User\\\");\\nConsole.WriteLine($\\\"User '{userEntry.Value}' does not have permission to view this\\nportfolio.\\\");\\n}\\ncatch (RpcException)\\n\\n// Handle any other error type ...\\n\\nImportant\\n\\nWhen you provide additional metadata for errors, be sure to document the relevant keys and\", \" values\\nin your API documentation, or in comments in your .proto file.\\n\\ngRPC richer error model\\n\\nGoogle has developed a richer error model that\\u2019s more like WCF's FaultContract, but this model isn't\\nsupported in C# yet. Currently, it\\u2019s only available for Go, Java, Python, and C++.\\n\\nWS-* protocols\\n\\nOne of the real benefits of working with Windows Communication Foundation (WCF) was that it\\nsupported many of the existing WS-* standard protocols. This\", \" section will briefly cover how gRPC\\nmanages the same WS-* protocols and discuss what options are available when there's no alternative.\\n\\nMetadata exchange: WS-Policy, WS-Discovery, and so on\\n\\nSOAP services expose Web Services Description Language (WSDL) schema documents with\\ninformation such as data formats, operations, or communication options. You can use this schema to\\ngenerate the client code.\\n\\ngRPC works best when servers and clients are ge\", \"nerated from the same .proto files, but a Server\\nReflection optional extension does provide a way to expose dynamic information from a running\\nserver. For more information, see the Grpc.Reflection NuGet package.\\n\\nThe WS-Discovery protocol is used to locate services on a local network. gRPC services are located\\nthrough DNS or a service registry such as Consul or ZooKeeper.\\n\\nSecurity: WS-Security, WS-Federation, XML Encryption, and so on\\n\\nSecurity,\", \" authentication, and authorization are covered in much more detail in chapter 6. But it\\u2019s worth\\nnoting here that, unlike WCF, gRPC doesn't support WS-Security, WS-Federation, or XML Encryption.\\nEven so, gRPC provides excellent security. All gRPC network traffic is automatically encrypted when it's\\nusing HTTP/2 over TLS. You can use X509 certificates for mutual client/server authentication.\\n\\n35 CHAPTER 4 | Comparing WCF to gRPC\\nWS-ReliableMessagin\", \"g\\n\\ngRPC does not provide an equivalent to WS-ReliableMessaging. Retry semantics should be handled in\\ncode, possibly with a library like Polly. When you're running in Kubernetes or similar orchestration\\nenvironments, service meshes can also help to provide reliable messaging between services.\\n\\nWS-Transaction, WS-Coordination\\n\\nWCF's implementation of distributed transactions uses Microsoft Distributed Transaction Coordinator\\n(MSDTC). It works with \", \"resource managers that specifically support it, like SQL Server, MSMQ, or\\nWindows file systems. There\\u2019s no equivalent yet in the modern microservices world, in part due to the\\nwider range of technologies in use. For a discussion of transactions, see Appendix A.\\n\\n36 CHAPTER 4 | Comparing WCF to gRPC\\nCHAPTER 5\\n\\nMigrate a WCF solution to\\nQgRPC\\n\\nThis chapter will describe how to work with ASP.NET Core 7.0 gRPC projects and demonstrate\\nmigrating diffe\", \"rent types of Windows Communication Foundation (WCF) services to the gRPC\\nequivalent:\\n\\n\\u00b0 Create an ASP.NET Core 7.0 gRPC project.\\n\\n. Simple request-reply operations to gRPC unary RPC.\\n\\n. One-way operations to gRPC client streaming RPC.\\n\\n. Full-duplex services to gRPC bidirectional streaming RPC.\\n\\nThere's also a comparison of using streaming services versus repeated fields for returning datasets,\\nand there\\u2019s a discussion of the use of client libra\", \"ries at the end of the chapter.\\n\\nThe sample WCF application is a minimal stub of a set of stock trading services. It uses the open-\\nsource Inversion of Control (loC) container library called Autofac for dependency injection. It includes\\nthree services, one for each WCF service type. The services will be discussed in more detail in the\\n\\nfollowing sections. You can download the solutions from dotnet-architecture/grpc-for-wcf-developers\\n\\non GitHub. \", \"The services use fake data to minimize external dependencies.\\n\\nThe samples include the WCF and gRPC implementations of each service.\\n\\nCreate a new ASP.NET Core gRPC project\\n\\nThe .NET SDK comes with a powerful CLI tool, dotnet, which enables you to create and manage\\nprojects and solutions from the command line. The SDK is closely integrated with Visual Studio, so\\neverything is also available through the familiar graphical user interface. This chap\", \"ter shows both ways\\nto create a new ASP.NET Core gRPC project.\\n\\nCreate the project by using Visual Studio\\n\\nImportant\\n\\nTo develop any ASP.NET Core 7.0 app, you need Visual Studio 2022, with the ASP.NET and web\\ndevelopment workload installed.\\n\\n37 CHAPTER 5 | Migrate a WCF solution to gRPC\\nCreate an empty solution called TraderSys from the Blank Solution template. Add a solution folder\\ncalled src. Then, right-click on the folder and choose Add > New\", \" Project. Enter grpc in the template\\nsearch box, and you should see a project template called gRPC Service.\\n\\nOo x\\nproj deni\\nRecent project templates All languages . All platforms \\u2019 All project types ,\\nA list of your recently accessed templates will be :\\n\\u2018alana se y grec ASP.NET Core RPC Service\\nA project template for creating a gRPC ASP.NET Core service.\\nC# Linux macOS Windows Cloud Service Web\\nNot finding what you're looking for?\\nInstall more to\", \"ols and features\\nNext\\n\\nSelect Next to continue to the Configure your new project dialog box. Name the project\\nTraderSys.Portfolios and add an src subdirectory to the Location.\\n\\n38 CHAPTER 5 | Migrate a WCF solution to gRPC\\nConfigure your new project\\n\\nASP.NET Core gRPC Service C# Linux = macOS = Windows = Cloud-~\\u2014 Service = Web\\n\\nProject name\\n\\nLocation\\n\\nC:\\\\Code\\\\TraderSys \\u2019\\n\\nBack Next\\n\\nSelect Next to continue to the Create a new gRPC service dialog \", \"box.\\n\\n39 CHAPTER 5 | Migrate a WCF solution to gRPC\\nAdditional information\\n\\nASP.NET Core gRPC Service linux = =macOS = Windows = Cloud_\\u2014s Service |= Web\\n\\nFramework @\\n\\n-NET 7.0 (Standard Term Support) |\\n[|_| Enable Docker @\\nDocker OS @\\n\\nLinux\\n\\n|_| Do not use top-level statements @\\n\\nAt present, you have limited options for the service creation. Docker will be introduced later, so for\\nnow, leave that option unselected. Just select Create. Your first\", \" ASP.NET Core 7.0 gRPC project is\\ngenerated and added to the solution. If you don\\u2019t want to know about working with the dotnet CLI,\\n\\nskip to the Clean up the example code section.\\n\\nCreate the project by using the .NET CLI\\n\\nThis section covers the creation of solutions and projects from the command line.\\n\\nCreate the solution as shown in the following command. The -o (or --output) flag specifies the output\\ndirectory, which is created in the current\", \" directory if it doesn\\u2019t already exist. The solution has the same\\nname as the directory: TraderSys.sIn. You can provide a different name by using the -n (or --name)\\nflag.\\n\\ndotnet new sln -o TraderSys\\ncd TraderSys\\n\\nASP.NET Core 7.0 comes with a CLI template for gRPC services. Create the new project by using this\\ntemplate, putting it into an src subdirectory as is conventional for ASP.NET Core projects. The project\\nis named after the directory (Tra\", \"derSys.Portfolios.csproj), unless you specify a different name with the\\n-n flag.\\n\\ndotnet new grpc -o src/TraderSys.Portfolios\\n\\nFinally, add the project to the solution by using the dotnet sln command:\\n\\ndotnet sln add src/TraderSys.Portfolios\\n\\n40 CHAPTER 5 | Migrate a WCF solution to gRPC\\nTip\\n\\nBecause the particular directory only contains a single .csproj file, you can specify just the directory, to\\nsave typing.\\n\\nYou can now open this solution in\", \" Visual Studio 2022, Visual Studio Code, or whatever editor you\\nprefer.\\n\\nClean up the example code\\n\\nYou've now created an example service by using the gRPC template, which was reviewed earlier in the\\nbook. This code isn\\u2019t useful in our stock trading context, so we'll edit things for our first project.\\nRename and edit the proto file\\n\\nGo ahead and rename the Protos/greet.proto file to Protos/portfolios.proto, and open it in your\\neditor. Delete ever\", \"ything after the package line. Then change the option csharp_namespace, package\\nand service names, and remove the default SayHello service. The code now looks like the following:\\n\\nsyntax = \\\"proto3\\\";\\noption csharp_namespace = \\\"TraderSys.Portfolios.Protos\\\";\\npackage PortfolioServer;\\n\\nservice Portfolios {\\n// RPCs will go here\\n}\\n\\nTip\\n\\nThe template doesn't add the Protos namespace part by default, but adding it makes it easier to keep\\ngRPC-generated cl\", \"asses and your own classes clearly separated in your code.\\n\\nIf you rename the greet.proto file in an integrated development environment (IDE) like Visual Studio, a\\nreference to this file is automatically updated in the .csproj file. But in some other editor, such as\\nVisual Studio Code, this reference isn't updated automatically, so you need to edit the project file\\nmanually.\\n\\nIn the gRPC build targets, there\\u2019s a Protobuf item element that lets yo\", \"u specify which .proto files\\nshould be compiled, and which form of code generation Is required (that is, \\u201cServer\\u201d or \\u201cClient\\u2019).\\n\\n<ItemGroup>\\n\\n<Protobuf Include=\\\"Protos\\\\portfolios.proto\\\" GrpcServices=\\\"Server\\\" />\\n</ItemGroup>\\n\\nRename the GreeterService class\\n\\nThe GreeterService class is in the Services folder and inherits from Greeter.GreeterBase. Rename it to\\nPortfolioService, and change the base class to Portfolios.PortfoliosBase. Delete the over\", \"ride methods.\\n\\nAl CHAPTER 5 | Migrate a WCF solution to gRPC\\npublic class PortfolioService : Protos.Portfolios.PortfoliosBase\\n\\nt\\n}\\n\\nThere was a reference to the GreeterService class in the Program.cs. If you used refactoring to rename\\nthe class, this reference should have been updated automatically. However, if you didn't, you need to\\nedit it manually.\\n\\nuSing TraderSys.Portfolios.Services;\\n\\nvar builder = WebApplication.CreateBuilder(args) ;\\n\\n// A\", \"dd services to the container.\\n\\nbuilder.Services.AddGrpc();\\n\\nvar app = builder.Build();\\n\\n// Configure the HTTP request pipeline.\\n\\napp .MapGrpcService<PortfolioService>() ;\\n\\napp.MapGet(\\\"/\\\", () => \\\"Communication with gRPC endpoints must be made through a gRPC\\nclient. To learn how to create a client, visit:\\n\\nhttps://go.microsoft.com/fwlink/ ?linkid=20869@9\\\" ) ;\\n\\napp.Run();\\n\\nIn the next section, we'll add functionality to this new service.\\n\\nMigrate a \", \"WCF request-reply service to a gRPC\\nunary RPC\\n\\nThis section covers how to migrate a basic request-reply service in WCF to a unary RPC service in\\nASP.NET Core gRPC. These services are the simplest service types in both Windows Communication\\nFoundation (WCF) and gRPC, so it's an excellent place to start. After migrating the service, you'll learn\\nhow to generate a client library from the same .proto file to consume the service from a .NET client\\napp\", \"lication.\\n\\nThe WCF solution\\n\\nThe PortfoliosSample solution includes a simple request-reply Portfolio service to download either a\\nsingle portfolio or all portfolios for a given trader. The service is defined in the interface\\n[PortfolioService with a ServiceContract attribute:\\n\\n[ServiceContract |\\npublic interface IPortfolioService\\n\\nt\\n\\n[OperationContract |\\n\\nTask<Portfolio> Get(Guid traderId, int portfoliolId) ;\\n\\n[OperationContract |\\nTask<List<Portf\", \"olio>> GetAll(Guid traderId) ;\\n\\n42 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe Portfolio model is a simple C# class marked with DataContract and including a list of\\nPortfolioltem objects. These models are defined in the TraderSys.PortfolioData project along with a\\nrepository class that represents a data access abstraction.\\n\\n[DataContract ]\\npublic class Portfolio\\n{\\n[| DataMember |\\npublic int Id { get; set; }\\n\\n[| DataMember ]\\npublic Guid TraderI\", \"d { get; set; }\\n\\n[| DataMember ]\\npublic List<PortfolioItem> Items { get; set; }\\n\\n}\\n\\n[DataContract ]\\npublic class PortfolioItem\\n\\naf\\n[| DataMember ]\\n\\npublic int Id { get; set; }\\n\\n[| DataMember ]\\npublic int ShareId { get; set; }\\n\\n[| DataMember ]\\npublic int Holding { get; set; }\\n\\n[| DataMember ]\\npublic decimal Cost { get; set; }\\n\\nThe ServiceContract implementation uses a repository class provided via dependency injection that\\nreturns instances of the\", \" DataContract types:\\n\\npublic class PortfolioService : Protos.Portfolios.PortfoliosBase\\n\\n{\\n\\nprivate readonly IPortfolioRepository _repository;\\n\\npublic PortfolioService(IPortfolioRepository repository)\\n\\nt\\n}\\n\\n_repository = repository;\\n\\npublic async Task<Portfolio> Get(Guid traderId, int portfoliolId)\\n{\\n\\nreturn await _repository.GetAsync(traderId, portfoliold) ;\\n\\n}\\n\\npublic async Task<List<Portfolio>> GetAll(Guid traderId)\\n{\\n\\n}\\n\\nreturn await _reposito\", \"ry.GetAllAsync(traderId) ;\\n\\n43 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe portfolios.proto file\\n\\nIf you followed the instructions in the previous section, you should have a gRPC project with a\\nportfolios.proto file that looks like this:\\n\\nsyntax = \\\"proto3\\\";\\n\\noption csharp_namespace = \\\"TraderSys.Portfolios.Protos\\\";\\n\\npackage PortfolioServer;\\n\\nservice Portfolios {\\n// RPCs will go here\\n}\\n\\nThe first step is to migrate the DataContract classes to th\", \"eir Protobuf equivalents.\\n\\nConvert the DataContract classes to gRPC messages\\n\\nThe Portfolioltem class will be converted to a Protobuf message first, because the Portfolio class\\ndepends on it. The class is simple, and three of the properties map directly to gRPC data types. The\\nCost property, which represents the price paid for the shares at purchase, is a decimal field. gRPC\\nsupports only float or double for real numbers, which aren't suitable fo\", \"r currency. Because share\\nprices vary by a minimum of one cent, the cost can be expressed as an int32 of cents.\\n\\nNote\\n\\nRemember to use snake_case for field names in your .proto file. The C# code generator will convert\\nthem to PascalCase for you, and users of other languages will thank you for respecting their different\\ncoding standards.\\n\\nmessage PortfolioItem {\\nint32 id = 1;\\nint32 share_id = 2;\\nint32 holding = 3;\\n\\nint32 cost_cents = 4;\\n\\nThe Portf\", \"olio class is a little more complicated. In the WCF code, the developer used a Guid for the\\nTraderld property, and contains a List<Portfolioltem>. In Protobuf, which doesn\\u2019t have a first-class\\nUUID type, you should use a string for the traderld field and parse it in your own code. For the list of\\nitems, use the repeated keyword on the field.\\n\\nmessage Portfolio {\\nint32 id = 1;\\n\\nstring trader_id = 2;\\nrepeated PortfolioItem items = 3;\\n\\nNow that you \", \"have the data messages, you can declare the service RPC endpoints.\\n\\n44 CHAPTER 5 | Migrate a WCF solution to gRPC\\nConvert ServiceContract to a gRPC service\\n\\nThe WCF Get method takes two parameters: Guid traderld and int portfoliold. gRPC service methods\\ncan take only a single parameter, so you need to create a message to hold the two values. It's\\ncommon practice to name these request objects with the same name as the method followed by the\\nsuffix\", \" Request. Again, string is being used for the traderld field instead of Guid.\\n\\nThe service could just return a Portfolio message directly, but again, this could affect backward\\ncompatibility in the future. It's a good practice to define separate Request and Response messages for\\nevery method in a service, even if many of them are the same right now. So declare a GetResponse\\nmessage with a single Portfolio field.\\n\\nThis example shows the declaratio\", \"n of the gRPC service method with the GetRequest message:\\n\\nmessage GetRequest {\\nstring trader_id =\\nint32 portfolio id\\n\\n1;\\n}\\n\\nmessage GetResponse {\\nPortfolio portfolio = 1;\\n\\n5\\n\\nservice Portfolios {\\nrpc Get(GetRequest) returns (GetResponse) ;\\n\\nThe WCF GetAll method takes only a single parameter, traderld, so it might seem that you could\\nspecify string as the parameter type. But gRPC requires a defined message type. This requirement\\nhelps to enforce\", \" the practice of using custom messages for all inputs and outputs, for future backward\\ncompatibility.\\n\\nThe WCF method also returns a List<Portfolio>, but for the same reason it doesn\\u2019t allow simple\\nparameter types, gRPC won't allow repeated Portfolio as a return type. Instead, create a\\nGetAllResponse type to wrap the list.\\n\\nWarning\\n\\nYou might be tempted to create a PortfolioList message or something similar and use it across\\nmultiple service meth\", \"ods, but you should resist this temptation. It\\u2019s impossible to know how the\\n\\nvarious methods on a service will evolve, so keep their messages specific and cleanly separated.\\n\\nmessage GetAllRequest {\\nstring trader_id = 1;\\n\\n5\\n\\nmessage GetAllResponse {\\nrepeated Portfolio portfolios = 1;\\n\\n5\\n\\nservice Portfolios {\\nrpc Get(GetRequest) returns (GetResponse) ;\\n\\n45 CHAPTER 5 | Migrate a WCF solution to gRPC\\nrpc GetAll(GetAllRequest) returns (GetAllResponse\", \") ;\\n| } |\\n\\nIf you save your project with these changes, the gRPC build target will run in the background and\\ngenerate all the Protobuf message types and a base class that you can inherit to implement the\\nservice.\\n\\nOpen the Services/GreeterService.cs class and delete the example code. Now you can add the\\nPortfolio service implementation. The generated base class will be in the Protos namespace and is\\ngenerated as a nested class. gRPC creates a sta\", \"tic class with the same name as the service in the\\n.proto file and a base class with the suffix Base inside that static class, so the full identifier for the base\\ntype is TraderSys.Portfolios.Protos.Portfolios.PortfoliosBase.\\n\\nnamespace TraderSys.Portfolios.Services;\\n\\npublic class PortfolioService : Protos.Portfolios.PortfoliosBase\\n\\nt\\n}\\n\\nThe base class declares virtual methods for Get and GetAll that can be overridden to implement the\\nservice. Th\", \"e methods are virtual rather than abstract so that if you don\\u2019t implement them, the service\\ncan return an explicit gRPC Unimplemented status code, much like you might throw a\\nNotimplementedException in regular C# code.\\n\\nThe signature for all gRPC unary service methods in ASP.NET Core Is consistent. There are two\\nparameters: the first is the message type declared in the .proto file, and the second is a\\nServerCallContext that works similarly to the\", \" HttpContext from ASP.NET Core. In fact, there\\u2019s an\\nextension method called GetHttpContext on the ServerCallContext class that you can use to get the\\nunderlying HttpContext, although you shouldn't need to use it often. We'll take a look at\\nServerCallContext later in this chapter, and also in the chapter that discusses authentication.\\n\\nThe method's return type is a Task<T>, where T is the response message type. All gRPC service\\nmethods are asynchr\", \"onous.\\n\\nMigrate the PortfolioData library to .NET\\n\\nAt this point, the project needs the Portfolio repository and models contained in the\\nTraderSys.PortfolioData class library in the WCF solution. The easiest way to bring them across is to\\ncreate a new class library by using either the Visual Studio New project dialog box with the Class\\nLibrary (.NET Standard) template, or from the command line by using the .NET CLI, running these\\ncommands from th\", \"e directory that contains the TraderSys.sIn file:\\n\\ndotnet new classlib -o src/TraderSys.PortfolioData\\ndotnet sln add src/TraderSys.PortfolioData\\n\\nAfter you've created the library and added it to the solution, delete the generated Class1.cs file and\\ncopy the files from the WCF solution's library into the new class library's folder, keeping the folder\\nstructure:\\n\\nModels\\nPortfolio.cs\\nPortfolioItem.cs\\n\\n46 CHAPTER 5 | Migrate a WCF solution to gRPC\\nIP\", \"ortfolioRepository.cs\\nPortfolioRepository.cs\\n\\nSDK-style .NET projects automatically include any .cs files in or under their own directory, so you don't\\nneed to explicitly add them to the project. The only step remaining is to remove the DataContract and\\nDataMember attributes from the Portfolio and Portfolioltem classes so they're plain old C# classes:\\n\\npublic class Portfolio\\n\\n{\\n\\npublic int Id { get; set; }\\npublic Guid TraderId { get; set; }\\npubli\", \"c List<PortfolioItem> Items { get; set; }\\n\\n}\\n\\npublic class PortfolioItem\\n\\n{\\npublic int Id { get; set; }\\npublic int ShareId { get; set; }\\npublic int Holding { get; set; }\\npublic decimal Cost { get; set; }\\n\\nUse ASP.NET Core dependency injection\\n\\nNow you can add a reference to this library to the gRPC application project and consume the\\nPortfolioRepository class by using dependency injection in the gRPC service implementation. In the\\nWCF application\", \", dependency injection was provided by the Autofac loC container. ASP.NET Core has\\ndependency injection baked in. You can register the repository in the Program.cs itself:\\n\\nusing TraderSys.Portfolios.Services;\\nvar builder = WebApplication.CreateBuilder(args) ;\\n\\n// Register the repository class as a scoped service (instance per request)\\nbuilder.Services.AddScoped<IPortfolioRepository, PortfolioRepository>() ;\\n\\nbuilder.Services.AddGrpc();\\n\\nvar app \", \"= builder.Build();\\n\\n// Configure the HTTP request pipeline.\\n\\napp .MapGrpcService<PortfolioService>() ;\\n\\napp.MapGet(\\\"/\\\", () => \\\"Communication with gRPC endpoints must be made through a gRPC\\nclient. To learn how to create a client, visit:\\n\\nhttps://go.microsoft.com/fwlink/ ?linkid=20869@9\\\" ) ;\\n\\napp.Run();\\n\\nThe |PortfolioRepository implementation can now be specified as a constructor parameter in the\\nPortfolioService class, as follows:\\n\\npublic class \", \"PortfolioService : Protos.Portfolios.PortfoliosBase\\n\\n{\\n\\nprivate readonly IPortfolioRepository _repository;\\n\\npublic PortfolioService(IPortfolioRepository repository)\\n\\n{\\n\\n47 CHAPTER 5 | Migrate a WCF solution to gRPC\\n_repository = repository;\\n\\nImplement the gRPC service\\n\\nNow that you've declared your messages and your service in the portfolios.proto file, you have to\\nimplement the service methods in the PortfolioService class that inherits from the\", \" gRPC-generated\\nPortfolios.PortfoliosBase class. The methods are declared as virtual in the base class. If you don't\\noverride them, they'll return a gRPC \\u201cNot Implemented\\u201d status code by default.\\n\\nStart by implementing the Get method. The default override looks like this example:\\n\\npublic override Task<GetResponse> Get(GetRequest request, ServerCallContext context)\\n\\nt\\n\\nreturn base.Get(request, context) ;\\n\\n}\\n\\nThe first problem is that request.Trade\", \"rld is a string, and the service requires a Guid. Even though the\\nexpected format for the string is UUID, the code has to deal with the possibility that a caller has sent\\nan invalid value and respond appropriately. The service can respond with errors by throwing an\\nRpcException and use the standard InvalidArgument status code to express the problem:\\n\\npublic override Task<GetResponse> Get(GetRequest request, ServerCallContext context)\\n\\n{\\nif (!Guid\", \".TryParse(request.TraderId, out var traderId) )\\n{\\nthrow new RpcException(new Status(StatusCode.InvalidArgument, \\\"traderId must be a\\nUUID\\\") ) ;\\n\\nreturn base.Get(request, context) ;\\n\\nAfter there\\u2019s a proper Guid value for traderld, you can use the repository to retrieve the Portfolio and\\nreturn it to the client:\\n\\nvar response = new GetResponse\\n\\n{\\n}3\\n\\nPortfolio = await _repository.GetAsync(request.TraderId, request.PortfoliolId)\\n\\nMap internal models \", \"to gRPC messages\\n\\nThe previous code doesn't actually work because the repository is returning its own POCO model\\nPortfolio, but gRPC needs its own Protobuf message Portfolio. As when you map Entity Framework\\ntypes to data transfer types, the best solution is to provide a conversion between the two. A good\\nplace to put the code for this conversion Is in the Protobuf-generated class, which is declared as a\\npartial class so it can be extended:\\n\\nname\", \"space TraderSys.Portfolios.Protos;\\n\\npublic partial class PortfolioItem\\n\\n{\\npublic static PortfolioItem FromRepositoryModel(PortfolioData.Models.PortfolioItem\\n\\n48 CHAPTER 5 | Migrate a WCF solution to gRPC\\nsource)\\n\\n{\\nif (source is null) return null;\\nreturn new PortfolioItem\\n{\\nId = source.Id,\\nShareId = source.Shareld,\\nHolding = source.Holding,\\nCostCents = (int)(source.Cost * 10@)\\n}3\\n}\\n\\n}\\n\\npublic partial class Portfolio\\n\\nt\\n\\npublic static Portfolio Fr\", \"omRepositoryModel(PortfolioData.Models.Portfolio source)\\n\\nt\\n\\nif (source is null) return null;\\n\\nvar target = new Portfolio\\n\\nt\\n\\nId = source.Id,\\nTraderId = source. TraderId.ToString(),\\n\\n}5\\ntarget.Items.AddRange(source.Items.Select(PortfolioItem. FromRepositoryModel1) ) ;\\n\\nreturn target;\\n\\nNote\\n\\nYou could use a library like AutoMapper to handle this conversion from internal model classes to\\nProtobuf types, as long as you configure the lower-level type\", \" conversions like string/Guid or\\ndecimal/double and the list mapping.\\n\\nNow that you have the conversion code in place, you can complete the Get method implementation:\\n\\npublic override async Task<GetResponse> Get(GetRequest request, ServerCallContext context)\\n\\n{\\nif (!Guid.TryParse(request.TraderId, out var traderId) )\\n\\nt\\nthrow new RpcException(new Status(StatusCode.InvalidArgument, \\\"traderId must be a\\nUUID\\\") ) ;\\n\\n}\\n\\nvar portfolio = await _reposito\", \"ry.GetAsync(traderId, request.Portfoliold) ;\\n\\nreturn new GetResponse\\n\\n{\\n}3\\n\\nPortfolio = Portfolio. FromRepositoryModel (portfolio)\\n\\n49 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe implementation of the GetAll method is similar. Note that the repeated fields on Protobuf\\nmessages are generated as readonly properties of type RepeatedField<T>, so you have to add items\\nto them by using the AddRange method, like in this example:\\n\\npublic override asyn\", \"c Task<GetAllResponse> GetAl1l(GetAllRequest request, ServerCallContext\\ncontext )\\n\\nif (!Guid.TryParse(request.TraderId, out var traderId) )\\n{\\n\\nthrow new RpcException(new Status(StatusCode.InvalidArgument, \\\"traderId must be a\\n\\nUUID\\\") ) ;\\n\\nvar portfolios = await _repository.GetAllAsync(traderId) ;\\n\\nvar response = new GetAllResponse() ;\\nresponse.Portfolios.AddRange(portfolios.Select(Portfolio.FromRepositoryModel1) ) ;\\n\\nreturn response;\\n\\nHaving succe\", \"ssfully migrated the WCF request-reply service to gRPC, let's look at creating a client for\\nit from the .proto file.\\n\\nGenerate client code\\n\\nCreate a .NET Standard class library in the same solution to contain the client. This is primarily an\\nexample of creating client code, but you could package such a library by using NuGet and distribute it\\non an internal repository for other .NET teams to consume. Go ahead and add a new .NET Standard\\nclass lib\", \"rary called TraderSys.Portfolios.Client to the solution and delete the Class1.cs file.\\n\\nCaution\\n\\nThe Grpc.Net.Client NuGet package requires .NET Core 3.0 or later (or another .NET Standard 2.1-\\n\\ncompliant runtime). Earlier versions of .NET Framework and .NET Core are supported by the Grpc.Core\\nNuGet package.\\n\\nIn Visual Studio 2022, you can add references to gRPC services in a way that\\u2019s similar to how you'd\\nadd service references to WCF projects \", \"in earlier versions of Visual Studio. Service references and\\nconnected services are all managed under the same UI now. You can access the UI by right-clicking\\nthe Dependencies node in the TraderSys.Portfolios.Client project in Solution Explorer and selecting\\nManage Connected Service. In the tool window that appears, select the Connected Services section,\\nthen select Add a service reference in Service References section, select gRPC and click Next\", \":\\n\\n50 CHAPTER 5 | Migrate a WCF solution to gRPC\\nConnected Services Service Dependencies\\n\\nPublish There are currently no service dependencies configured.\\n\\nAdd a service dependency\\n\\nService References (OpenAPI, gRPC, WCF Web Service)\\n\\nThere are currently no service references configured.\\n\\nAdd a service reference\\n\\nAdd service reference\\n\\nSelect a service reference to add to your application\\n\\nOpenAPI\\nConsume web services which conform to the OpenAPI \", \"Specification\\n\\nConsume and produce web services which conform to the gRPC open source universal RPC framework\\n\\nWCF Web Service\\nAdd a WCF web service reference to your project.\\n\\nG\\ne+ gRPC\\nce\\n\\nNext | Finish | Cancel |\\n\\nBrowse to the portfolios.proto file in the TraderSys.Portfolios project, leave Client under Select the\\ntype of class to be generated, and then select OK:\\n\\n51 CHAPTER 5 | Migrate a WCF solution to gRPC\\nAdd new gRPC service reference\\nS\", \"elect a file or URL\\n\\n@ File\\n\\nC:\\\\\\\\Code\\\\ TraderSys\\\\ TraderSys.Portfolios\\\\ TraderSys.Portfolios\\\\Protos\\\\portfolios.proto\\n\\n\\u00a9 URL\\n\\nSelect the type of class to be generated\\n\\nClient\\n\\nFinish Cancel\\n\\nTip\\n\\nNotice that this dialog box also provides a URL field. If your organization maintains a web-accessible\\ndirectory of .proto files, you can create clients just by setting this URL address.\\n\\nWhen you use the Visual Studio Add Connected Service feature, the p\", \"ortfolios.proto file is added to\\nthe class library project as a linked file rather than copied, so changes to the file in the service project\\n\\nwill automatically be applied in the client project. The <Protobuf> element in the csproj file looks like\\nthis:\\n\\n<Protobuf Include=\\\"..\\\\TraderSys.Portfolios\\\\Protos\\\\portfolios.proto\\\" GrpcServices=\\\"Client\\\">\\n<Link>Protos\\\\portfolios.proto</Link>\\n</Protobuf >\\n\\nTip\\n\\nIf you're not using Visual Studio or prefer to \", \"work from the command line, you can use the dotnet-\\ngrpc global tool to manage Protobuf references in a .NET gRPC project. For more information, see the\\ndotnet-grpc_documentation.\\n\\nUse the Portfolios service from a client application\\n\\nThe following code is a brief example of how to use the generated client in a console application. A\\nmore detailed exploration of the gRPC client code is at the end of this chapter.\\n\\n52 CHAPTER 5 | Migrate a WCF sol\", \"ution to gRPC\\npublic class Program\\n\\n{\\n\\npublic async Task Main(string[ ] args)\\n{\\n\\nGetResponse response;\\nusing (var channel = GrpcChannel.ForAddress(\\\"https://localhost: 5001\\\" ) )\\nvar client = new Protos.Portfolios.PortfoliosClient(channel1) ;\\n\\nresponse = await client.GetAsync(new GetRequest\\n\\nTraderId = args[@],\\nPortfolioId = int.Parse(args[1])\\n})3\\n}\\n\\nforeach (var item in response.Portfolio. Items)\\n\\n{\\n\\nConsole.WriteLine($\\\"Holding {item.Holding} of S\", \"hare ID {item.ShareId}.\\\");\\n\\nYou've now migrated a basic WCF application to an ASP.NET Core gRPC service and created a client to\\nconsume the service from a .NET application. The next section will cover the more involved duplex\\nservices.\\n\\nMigrate WCF duplex services to gRPC\\n\\nNow that you have a sense of the basic concepts, in this section, you'll look at the more complicated\\nstreaming gRPC services.\\n\\nThere are multiple ways to use duplex services i\", \"n Windows Communication Foundation (WCF). Some\\nservices are initiated by the client and then they stream data from the server. Other full-duplex\\nservices might involve more ongoing two-way communication, like the classic Calculator example in\\nthe WCF documentation. This chapter will take two possible WCF stock ticker implementations and\\nmigrate them to gRPC: one that uses a server streaming RPC and another one that uses a bidirectional\\nstreaming \", \"RPC.\\n\\nServer streaming RPC\\n\\nIn the sample SimpleStockTicker WCF solution, SimpleStockPriceTicker, there\\u2019s a duplex service for\\nwhich the client starts the connection with a list of stock symbols, and the server uses the callback\\ninterface to send updates as they become available. The client implements that interface to respond\\nto calls from the server.\\n\\nThe WCF solution\\n\\nThe WCF solution is implemented as a self-hosted Net.TCP server in a .NET Fr\", \"amework 4.x console\\napplication.\\n\\n53 CHAPTER 5 | Migrate a WCF solution to gRPC\\nServiceContract\\n\\n[ServiceContract(SessionMode = SessionMode.Required, CallbackContract =\\ntypeof (ISimpleStockTickerCallback) ) |\\npublic interface ISimpleStockTickerService\\n\\n{\\n[OperationContract(IsOneWay = true) ]\\n\\nvoid Subscribe(string[ ] symbols) ;\\n\\nThe service has a single method with no return type because it uses the callback interface\\nISimpleStockTickerCallback t\", \"o send data to the client in real time.\\n\\nThe callback interface\\n\\n[ServiceContract |\\npublic interface ISimpleStockTickerCallback\\n{\\n[OperationContract(IsOneWay = true) ]\\nvoid Update(string symbol, decimal price);\\n\\nYou can find the implementations of these interfaces in the solution, along with faked external\\ndependencies to provide test data.\\n\\ngRPC streaming\\n\\nThe gRPC process for handling real-time data is different from the WCF process. A call fro\", \"m client to\\nserver can create a persistent stream, which can be monitored for messages that arrive\\nasynchronously. Despite the difference, streams can be a more intuitive way of dealing with this data\\nand are more relevant in modern programming, which emphasizes LINQ, Reactive Streams, functional\\nprogramming, and so on.\\n\\nThe service definition needs two messages: one for the request and one for the stream. The service\\nreturns a stream of the Stoc\", \"kTickerUpdate message with the stream keyword in its return declaration.\\nWe recommend that you add a Timestamp to the update to show the exact time of the price change.\\n\\nsimple_stock_ticker.proto\\n\\nsyntax = \\\"proto3\\\";\\n\\noption csharp_namespace = \\\"TraderSys.SimpleStockTickerServer.Protos\\\" ;\\nimport \\\"google/protobuf/timestamp. proto\\u201d;\\npackage SimpleStockTickerServer ;\\n\\nservice SimpleStockTicker {\\nrpc Subscribe (SubscribeRequest) returns (stream StockTi\", \"ckerUpdate) ;\\n\\n5\\n\\nmessage SubscribeRequest {\\nrepeated string symbols = 1;\\n\\n5\\n\\nmessage StockTickerUpdate {\\n\\n54 CHAPTER 5 | Migrate a WCF solution to gRPC\\nstring symbol = 1;\\nint32 price cents = 2;\\ngoogle.protobuf.Timestamp time = 3;\\n\\ni\\n\\nImplement SimpleStockTicker\\n\\nReuse the fake StockPriceSubscriber from the WCF project by copying the three classes from the\\nTraderSys.StockMarket class library into a new .NET Standard class library in the target so\", \"lution. To\\nbetter follow best practices, add a Factory type to create instances of it, and register the\\nIStockPriceSubscriberFactory with the ASP.NET Core dependency injection services.\\n\\nThe factory implementation\\n\\npublic interface IStockPriceSubscriberFactory\\n\\nt\\n}\\n\\nIStockPriceSubscriber GetSubscriber(string| ] symbols) ;\\n\\npublic class StockPriceSubscriberFactory : IStockPriceSubscriberFactory\\n\\naf\\npublic IStockPriceSubscriber GetSubscriber(string\", \"[ |] symbols)\\n\\nt\\n}\\n\\nreturn new StockPriceSubscriber (symbols) ;\\n\\nRegister the factory\\n\\nvar builder = WebApplication.CreateBuilder (args) ;\\n\\n// Additional configuration is required to successfully run gRPC on macOS.\\n\\n// For instructions on how to configure Kestrel and gRPC clients on macOS, visit\\nhttps://go.microsoft.com/fwlink/ ?linkid=2099682\\n\\n// Add services to the container.\\n\\n// Register the factory\\nbuilder.Services.AddSingleton<IStockPriceSub\", \"scriberFactory, StockPriceSubscriberFactory>() ;\\n\\nbuilder.Services.AddGrpc();\\nvar app = builder.Build();\\n// Configure the HTTP request pipeline.\\n\\napp .MapGrpcService<StockTickerService>() ;\\napp.MapGet(\\\"/\\\", async context =>\\n\\nawait context.Response.WriteAsync(\\\"Communication with gRPC endpoints must be made\\nthrough a gRPC client. To learn how to create a client, visit:\\nhttps://go.microsoft.com/fwlink/ ?linkid=20869@9\\\" ) ;\\n\\n})5\\n\\napp.Run();\\n\\nThis clas\", \"s can now be used to implement the gRPC StockTickerService.\\n\\n55 CHAPTER 5 | Migrate a WCF solution to gRPC\\nStockTickerService.cs\\n\\npublic class StockTickerService : Protos.SimpleStockTicker.SimpleStockTickerBase\\n\\n{\\n\\nprivate readonly IStockPriceSubscriberFactory _subscriberFactory;\\n\\npublic StockTickerService(IStockPriceSubscriberFactory subscriberFactory )\\n\\nt\\n}\\n\\n_subscriberFactory = subscriberFactory;\\n\\npublic override async Task Subscribe(Subscribe\", \"Request request,\\nIServerStreamWriter<StockTickerUpdate> responseStream, ServerCallContext context)\\n{\\n\\nvar subscriber = _subscriberFactory.GetSubscriber(request.Symbols.ToArray() );\\n\\nsubscriber.Update += async (sender, args) =>\\nawait WriteUpdateAsync(responseStream, args.Symbol, args.Price);\\n\\nawait AwaitCancellation(context.CancellationToken) ;\\n\\n}\\n\\nprivate async Task WriteUpdateAsync(IServerStreamWriter<StockTickerUpdate> stream,\\nstring symbol, de\", \"cimal price)\\n{\\ntry\\n{\\nawait stream.WriteAsync(new StockTickerUpdate\\n{\\nSymbol = symbol,\\nPriceCents = (int)(price * 100),\\nTime = Timestamp.FromDateTimeOffset (DateTimeOffset .UtcNow)\\n})5\\n}\\n\\ncatch (Exception e)\\n\\n// Handle any errors caused by broken connection, etc.\\n_logger.LogError($\\\"Failed to write message: {e.Message}\\\");\\n\\n}\\n\\nprivate static Task AwaitCancellation(CancellationToken token)\\n{\\nvar completion = new TaskCompletionSource<object>();\\ntoken.\", \"Register(() => completion.SetResult(nul1) ) ;\\nreturn completion.Task;\\n\\nAs you can see, although the declaration in the .proto file says the method returns a stream of\\nStockTickerUpdate messages, it actually returns a Task. The job of creating the stream is handled by\\nthe generated code and the gRPC runtime libraries, which provide the\\nIServerStreamWriter<StockTickerUpdate> response stream, ready to use.\\n\\nUnlike a WCF duplex service, where the ins\", \"tance of the service class is kept alive while the connection\\nis open, the gRPC service uses the returned task to keep the service alive. The task shouldn't complete\\nuntil the connection Is closed.\\n\\n56 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe service can tell when the client has closed the connection by using the CancellationToken from\\nthe ServerCallContext. A simple static method, AwaitCancellation, is used to create a task that\\ncompletes \", \"when the token is canceled.\\n\\nIn the Subscribe method, then, get a StockPriceSubscriber and add an event handler that writes to the\\nresponse stream. Then wait for the connection to be closed before immediately disposing the\\nsubscriber to prevent it from trying to write data to the closed stream.\\n\\nThe WriteUpdateAsync method has a try/catch block to handle any errors that might happen when a\\nmessage is written to the stream. This consideration is i\", \"mportant in persistent connections over\\nnetworks, which could be broken at any millisecond, whether intentionally or because of a failure\\nsomewhere.\\n\\nUse StockTickerService from a client application\\n\\nFollow the same steps in the previous section to create a shareable client class library from the .proto\\nfile. In the sample, there\\u2019s a .NET console application that demonstrates how to use the client.\\n\\nExample Program.cs\\n\\nclass Program\\n\\n{\\n\\nstatic as\", \"ync Task Main(string[ ] args)\\n\\n{\\nusing var channel = GrpcChannel.ForAddress(\\\"https://localhost:50@1\\\") ;\\nvar client = new SimpleStockTicker.SimpleStockTickerClient(channel1) ;\\n\\nvar request = new SubscribeRequest() ;\\nrequest .Symbols.AddRange(args) ;\\n\\nuSing var stream = client.Subscribe(request) ;\\n\\nvar tokenSource = new CancellationTokenSource() ;\\nvar task = DisplayAsync(stream.ResponseStream, tokenSource. Token) ;\\nWaitForExitKey() ;\\n\\ntokenSource.C\", \"ancel();\\nawait task;\\n\\nIn this case, the Subscribe method on the generated client isn\\u2019t asynchronous. The stream is created\\nand usable right away because its MoveNext method is asynchronous and the first time it\\u2019s called it\\nwon't complete until the connection is alive.\\n\\nThe stream is passed to an asynchronous DisplayAsync method. The application then waits for the\\nuser to press a key, and then cancels the DisplayAsync method and waits for the task\", \" to complete\\nbefore exiting.\\n\\n57 CHAPTER 5 | Migrate a WCF solution to gRPC\\nNote\\n\\nThis code uses the new C# 8 using declaration syntax to dispose of the stream and the channel when\\nthe Main method exits. It's a small change, but a nice one that reduces indentations and empty lines.\\n\\nConsume the stream\\n\\nWCF uses callback interfaces to allow the server to call methods directly on the client. gRPC streams\\nwork differently. The client iterates over t\", \"he returned stream and processes messages, just as though\\nthey were returned from a local method returning an IEnumerable.\\n\\nThe lAsyncStreamReader<T> type works much like an IEnumerator<T>. There\\u2019s a MoveNext method\\nthat returns true as long as there\\u2019s more data, and a Current property that returns the latest value. The\\nonly difference is that the MoveNext method returns a Task<bool> instead of just a bool. The\\nReadAllAsync extension method wraps\", \" the stream in a standard C# 8 [AsyncEnumerable that can be\\nused with the new await foreach syntax.\\n\\nStatic async Task DisplayAsync(IAsyncStreamReader<StockTickerUpdate> stream,\\nCancellationToken token)\\n\\naf\\ntry\\n\\n{\\n\\nawait foreach (var update in stream. ReadAllAsync(token) )\\n\\nt\\n}\\n\\nConsole.WriteLine($\\\"{update.Symbol}: {update.Price}\\\") ;\\n\\ncatch (RpcException e) when (e.StatusCode == StatusCode.Cancelled)\\n{\\n\\nreturn;\\n\\ncatch (OperationCanceledException \", \")\\n\\nt\\n}\\n\\nConsole.WriteLine(\\\"Finished.\\\") ;\\n\\nFor developers using reactive programming patterns, the section on client libraries at the end of this\\nchapter shows how to add an extension method and classes to wrap IAsyncStreamReader<T> in an\\nlObservable<T>.\\n\\nAgain, be sure to catch exceptions here because of the possibility of network failure, and because of\\nthe OperationCanceledException that will inevitably be thrown because the code Is using a\\nCan\", \"cellationToken to break the loop. The RpcException type has a lot of useful information about\\ngRPC runtime errors, including the StatusCode. For more information, see Error handling in Chapter 4.\\n\\nBidirectional streaming\\n\\nA WCF full-duplex service allows for asynchronous, real-time messaging in both directions. In the\\nserver streaming example, the client starts a request and then receives a stream of updates. A better\\n\\n58 CHAPTER 5 | Migrate a WC\", \"F solution to gRPC\\nversion of that service would allow the client to add and remove stocks from the list without having to\\nstop and create a new subscription. That functionality has been implemented in the FullStockTicker\\n\\nsample solution.\\nThe IFullStockTickerService interface provides three methods:\\n\\n\\u00b0 Subscribe starts the connection.\\n\\u00b0 AddSymbol adds a stock symbol to watch.\\n\\n\\u00b0 RemoveSymbol removes a symbol from the watched list.\\n\\n[ServiceContr\", \"act(SessionMode = SessionMode.Required, CallbackContract =\\ntypeof (IFullStockTickerCallback) ) |\\npublic interface IFullStockTickerService\\n\\nt\\n\\n[OperationContract(IsOneWay = true) ]\\nvoid Subscribe();\\n\\n[OperationContract(IsOneWay = true) ]\\nvoid AddSymbol(string symbol) ;\\n\\n[OperationContract(IsOneWay = true) ]\\nvoid RemoveSymbol(string symbol) ;\\n\\nThe callback interface remains the same.\\n\\nImplementing this pattern in gRPC Is less straightforward becaus\", \"e there are now two streams of data\\nwith messages being passed: one from client to server and another from server to client. It isn't\\npossible to use multiple methods to implement the add and remove operations, but you can pass\\nmore than one type of message on a single stream by using either the Any type or the oneof\\nkeyword, which were covered in Chapter 3.\\n\\nIn a case where there's a specific set of types that are acceptable, oneof is a better w\", \"ay to go. Use an\\nActionMessage that can hold either an AddSymbolRequest or a RemoveSymbolRequest:\\n\\nmessage ActionMessage {\\noneof action {\\nAddSymbolRequest add = 1;\\nRemoveSymbolRequest remove = 2;\\n}\\n}\\n\\nmessage AddSymbolRequest {\\nstring symbol = 1;\\n}\\n\\nmessage RemoveSymbolRequest {\\nstring symbol = 1;\\n}\\n\\nDeclare a bidirectional streaming service that takes a stream of ActionMessage messages:\\n\\nservice FullStockTicker {\\n\\nrpc Subscribe (stream ActionMes\", \"sage) returns (stream StockTickerUpdate) ;\\n\\ni\\n\\n59 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe implementation for this service is similar to that of the previous example, except the first\\nparameter of the Subscribe method is now an lAsyncStreamReader<ActionMessage>, which can be\\nused to handle the Add and Remove requests:\\n\\npublic override async Task Subscribe(IAsyncStreamReader<ActionMessage> requestStream,\\nIServerStreamWriter<StockTickerUpdate\", \"> responseStream, ServerCallContext context)\\naf\\n\\nuSing var subscriber = _subscriberFactory.GetSubscriber() ;\\n\\nsubscriber.Update += async (sender, args) =>\\nawait WriteUpdateAsync(responseStream, args.Symbol, args.Price) ;\\n\\nvar actionsTask = HandleActions(requestStream, subscriber, context.CancellationToken) ;\\n\\n_logger.LogInformation(\\\"Subscription started.\\\");\\nawait AwaitCancellation(context.CancellationToken) ;\\n\\ntry { await actionsTask; } catch { /\", \"* Ignored */ }\\n\\n_logger.LogInformation(\\\"Subscription finished.\\\") ;\\n\\n}\\n\\nprivate async Task WriteUpdateAsync(IServerStreamwWriter<StockTickerUpdate> stream, string\\nsymbol, decimal price)\\n\\n{\\ntry\\n{\\nawait stream.WriteAsync(new StockTickerUpdate\\n{\\nSymbol = symbol,\\nPriceCents = (int)(price * 100),\\nTime = Timestamp.FromDateTimeOffset (DateTimeOffset .UtcNow)\\n})3\\ncatch (Exception e)\\n// Handle any errors caused by broken connection, etc.\\n_logger.LogError($\", \"\\\"Failed to write message: {e.Message}\\\");\\n}\\n}\\nprivate static Task AwaitCancellation(CancellationToken token)\\n{\\nvar completion = new TaskCompletionSource<object>();\\ntoken.Register(() => completion.SetResult(null1) ) ;\\nreturn completion. Task;\\n}\\n\\nThe ActionMessage class that gRPC has generated guarantees that only one of the Add and Remove\\nproperties can be set. Finding which one isn\\u2019t null is a valid way to determine which type of message\\nis used, \", \"but there\\u2019s a better way. The code generation also created an enum ActionOneOfCase in the\\nActionMessage class, which looks like this:\\n\\npublic enum ActionOneofCase {\\nNone = @,\\n\\nAdd = 1,\\nRemove = 2,\\n\\n60 CHAPTER 5 | Migrate a WCF solution to gRPC\\nThe property ActionCase on the ActionMessage object can be used with a switch statement to\\ndetermine which field is set:\\n\\nprivate async Task HandleActions(IAsyncStreamReader<ActionMessage> requestStream,\\nIF\", \"ullStockPriceSubscriber subscriber, CancellationToken token)\\n\\n{\\n\\nawait foreach (var action in requestStream.ReadAllAsync(token) )\\n{\\nSwitch (action.ActionCase)\\n{\\ncase ActionMessage.ActionOneofCase.None:\\n_logger.LogWarning(\\\"No Action specified.\\\") ;\\nbreak;\\ncase ActionMessage.ActionOneofCase. Add:\\nsubscriber.Add(action.Add.Symbo1) ;\\nbreak;\\ncase ActionMessage.ActionOneofCase. Remove:\\nsubscriber.Remove(action.Remove. Symbol) ;\\nbreak;\\ndefault:\\n_logger.L\", \"ogWarning($\\\"Unknown Action '{action.ActionCase}'.\\\");\\nbreak;\\n\\nThe switch statement has a default case that logs a warning if it encounters an unknown\\nActionOneOfCase value. This could be useful to indicate that a client is using a later version of the\\n.proto file that has added more actions. This is one reason why using a switch is better than testing for\\nnull on known fields.\\n\\nUse FullStockTickerService from a client application\\n\\nThere's a simple\", \" .NET WPF application that demonstrates the use of this more complex client. You can\\nfind the full application on GitHub.\\n\\nThe client is used in the MainWindowViewModel class, which gets an instance of the\\nFullStockTicker.FullStockTickerClient type from dependency injection:\\n\\npublic class MainWindowViewModel : IAsyncDisposable, INotifyPropertyChanged\\n{\\n\\nprivate readonly FullStockTicker.FullStockTickerClient _client;\\n\\nprivate readonly AsyncDuplexS\", \"treamingCall<ActionMessage, StockTickerUpdate>\\n_duplexStream;\\n\\nprivate readonly CancellationTokenSource _cancellationTokenSource;\\n\\nprivate readonly Task _responseTask;\\n\\nprivate string _addSymbol;\\n\\npublic MainWindowViewModel (FullStockTicker.FullStockTickerClient client)\\n{\\n\\n_cancellationTokenSource = new CancellationTokenSource() ;\\n\\n_client = client;\\n\\n_duplexStream = _client.Subscribe() ;\\n\\n_responseTask = HandleResponsesAsync(_cancellationTokenSou\", \"rce. Token) ;\\n\\n61 CHAPTER 5 | Migrate a WCF solution to gRPC\\nAddCommand = new AsyncCommand(Add, CanAdd) ;\\n\\nThe object returned by the client.Subscribe() method is now an instance of the gRPC library type\\nAsyncDuplexStreamingCall<TRequest, TResponse>, which provides a RequestStream for sending\\nrequests to the server and a ResponseStream for handling responses.\\n\\nThe request stream is used from some WPF ICommand methods to add and remove symbols. Fo\", \"r\\neach operation, set the relevant field on an ActionMessage object:\\n\\nprivate async Task Add()\\n\\n{\\nif (CanAdd() )\\n\\nawait _duplexStream.RequestStream.WriteAsync(new ActionMessage {Add = new\\nAddSymbolRequest {Symbol = AddSymbol1}}) ;\\n\\n}\\n}\\n\\npublic async Task Remove(PriceViewModel priceViewModel )\\n\\nt\\n\\nawait _duplexStream.RequestStream.WriteAsync(new ActionMessage {Remove = new\\nRemoveSymbolRequest {Symbol = priceViewModel.Symbol}}) ;\\nPrices.Remove(pric\", \"eViewModel1) ;\\n\\n}\\n\\nImportant\\n\\nSetting a oneof field's value on a message automatically clears any fields that have been set\\npreviously.\\n\\nThe stream of responses is handled in an async method. The Task it returns is held to be disposed\\nwhen the window is closed:\\n\\nprivate async Task HandleResponsesAsync(CancellationToken token)\\n\\nt\\n\\nvar stream = _duplexStream.ResponseStream;\\ntry\\n\\nawait foreach (var update in stream. ReadAllAsync(token) )\\n\\n{\\nvar pric\", \"e = Prices.FirstOrDefault(p => p.Symbol.Equals(update.Symbol1) ) ;\\nif (price == null)\\n\\nprice = new PriceViewModel(this) {Symbol = update.Symbol, Price =\\nupdate.PriceCents / 10@m};\\nPrices .Add(price) ;\\n\\n}\\n\\nelse\\n\\nt\\n}\\n\\nprice.Price = update.PriceCents / 100m;\\n\\n62 CHAPTER 5 | Migrate a WCF solution to gRPC\\ncatch (OperationCancelledException) { }\\n| } |\\n\\nClient cleanup\\n\\nWhen the window is closed and the MainWindowViewModel is disposed (from the Closed e\", \"vent of\\nMainWindow), we recommend that you properly dispose the AsyncDuplexStreamingCall object. In\\nparticular, the CompleteAsync method on the RequestStream should be called to gracefully close the\\nstream on the server. This example shows the DisposeAsync method from the sample view-model:\\n\\npublic async ValueTask DisposeAsync()\\n\\nt\\ntry\\n\\n{\\nawait _duplexStream. RequestStream.CompleteAsync().ConfigureAwait (false) ;\\nawait _responseTask.ConfigureAwai\", \"t (false) ;\\n\\n}\\nfinally\\n\\nt\\n}\\n\\n_duplexStream.Dispose() ;\\n\\nClosing request streams enables the server to dispose of its own resources in a timely way. This\\nimproves the efficiency and scalability of services and prevents exceptions.\\n\\ngRPC streaming services vs. repeated fields\\n\\ngRPC services provide two ways of returning datasets, or lists of objects. The Protocol Buffers message\\nspecification uses the repeated keyword for declaring lists or arrays \", \"of messages within another\\nmessage. The gRPC service specification uses the stream keyword to declare a long-running persistent\\nconnection. Over that connection, multiple messages are sent, and can be processed, individually.\\n\\nYou can also use the stream feature for long-running temporal data such as notifications or log\\nmessages. But this chapter will consider its use for returning a single dataset.\\n\\nWhich you should use depends on factors such \", \"as:\\n\\n\\u00b0 The overall size of the dataset.\\n\\u00b0 The time it took to create the dataset at either the client or server end.\\n\\n. Whether the consumer of the dataset can start acting on it as soon as the first item is\\navailable, or needs the complete dataset to do anything useful.\\n\\nWhen to use repeated fields\\n\\nFor any dataset that\\u2019s constrained in size and that can be generated in Its entirety in a short time\\u2014\\nsay, under one second\\u2014you should use a repeate\", \"d field in a regular Protobuf message. For example,\\nin an e-commerce system, to build a list of items within an order is probably quick and the list won't\\nbe very large. Returning a single message with a repeated field is an order of magnitude faster than\\nusing stream and incurs less network overhead.\\n\\n63 CHAPTER 5 | Migrate a WCF solution to gRPC\\nIf the client needs all the data before starting to process it and the dataset is small enough to\\nco\", \"nstruct in memory, then consider using a repeated field. Consider it even if the creation of the\\ndataset in memory on the server is slower.\\n\\nWhen to use stream methods\\n\\nWhen the message objects in your datasets are potentially very large, it's best for you transfer them\\nby using streaming requests or responses. It's more efficient to construct a large object in memory,\\nwrite it to the network, and then free up the resources. This approach will im\", \"prove the scalability of\\nyour service.\\n\\nSimilarly, you should send datasets of unconstrained size over streams to avoid running out of\\nmemory while constructing them.\\n\\nFor datasets where the consumer can separately process each item, you should consider using a\\nstream if it means that progress can be indicated to the user. Using a stream can improve the\\nresponsiveness of an application, but you should balance it against the overall performance of\", \" the\\napplication.\\n\\nAnother scenario where streams can be useful is where a message is being processed across multiple\\nservices. If each service in a chain returns a stream, then the terminal service (that is, the last one in\\nthe chain) can start returning messages. These messages can be processed and passed back along the\\nchain to the original requestor. The requestor can either return a stream or aggregate the results into\\na single response mess\", \"age. This approach lends itself well to patterns like MapReduce.\\n\\nCreate gRPC client libraries\\n\\nIt isn't necessary to distribute client libraries for a gRPC application. You can create a shared library of\\n.proto files within your organization, and other teams can use those files to generate client code in\\ntheir own projects. But if you have a private NuGet repository and many other teams are using .NET,\\nyou can create and publish client NuGet pac\", \"kages as part of your service project. This approach can\\nbe a good way of sharing and promoting your service.\\n\\nOne advantage of distributing a client library is that you can enhance the generated gRPC and\\nProtobuf classes with helpful \\u201cconvenience\\u201d methods and properties. In the client code, as in the\\nserver, all the classes are declared as partial, so you can extend them without editing the generated\\ncode. This behavior means it\\u2019s easy to add co\", \"nstructors, methods, and calculated properties to the\\nbasic types.\\n\\nCaution\\n\\nYou shouldn't use custom code to provide essential functionality. You don\\u2019t want to restrict that\\n\\nessential functionality to .NET teams that use the shared library, and not provide it to teams that use\\nother languages or platforms, such as Python or Java.\\n\\nEnsure that as many teams as possible can access your gRPC service. The best way to do this\\nfunctionality is to sha\", \"re .proto files so developers can generate their own clients. This approach is\\n\\n64 CHAPTER 5 | Migrate a WCF solution to gRPC\\nparticularly true in a multi-platform environment, where different teams frequently use different\\nprogramming languages and frameworks, or where your API is externally accessible.\\n\\nUseful extensions\\n\\nThere are two commonly used interfaces in .NET for dealing with streams of objects: |Enumerable and\\nlObservable. Starting wi\", \"th .NET Core 3.0 and C# 8.0, there\\u2019s an [AsyncEnumerable interface for\\nprocessing streams asynchronously, and an await foreach syntax for using the interface. This section\\npresents reusable code for applying these interfaces to gRPC streams.\\n\\nWith the .NET gRPC client libraries, there\\u2019s a ReadAllAsync extension method for\\n[AsyncStreamReader<T> that creates an [AsyncEnumerable<T> interface. For developers using\\nreactive programming, an equivalent \", \"extension method to create an |Observable<T> interface might\\nlook like the example in the following section.\\n\\nlObservable\\n\\nThe lObservable<T> interface is the \\u201creactive\\u201d inverse of IEnumerable<T>. Rather than pulling items\\nfrom a stream, the reactive approach lets the stream push items to a subscriber. This behavior is very\\nsimilar to gRPC streams, and it\\u2019s easy to wrap an |Observable<T> interface around an\\n[AsyncStreamReader<T> interface.\\n\\nThis \", \"code is longer than the [AsyncEnumerable<T> code, because C# doesn\\u2019t have built-in support for\\nworking with observables. You have to create the implementation class manually. It's a generic class,\\nthough, so a single implementation works across all types.\\n\\nnamespace Grpc.Core;\\n\\npublic class GrpcStreamObservable<T> : IObservable<T>\\n{\\nprivate readonly IAsyncStreamReader<T> _reader;\\nprivate readonly CancellationToken _token;\\nprivate int _used;\\n\\npubl\", \"ic GrpcStreamObservable(IAsyncStreamReader<T> reader, CancellationToken token =\\ndefault )\\n{\\n_reader = reader ?? throw new ArgumentNullException(nameof (reader) ) ;\\n_token = token;\\n_used = Q;\\n\\n}\\n\\npublic IDisposable Subscribe(IObserver<T> observer) =>\\nInterlocked.Exchange(ref _used, 1) ==\\n>? new GrpcStreamSubscription<T>(_reader, observer, _token)\\n: throw new InvalidOperationException(\\\"Subscribe can only be called once.\\\");\\n\\n65 CHAPTER 5 | Migrate a\", \" WCF solution to gRPC\\nImportant\\n\\nThis observable implementation allows the Subscribe method to be called only once, because having\\n\\nmultiple subscribers trying to read from the stream would result in chaos. There are operators, such as\\nReplay in the System.Reactive.Ling, that enable buffering and repeatable sharing of observables,\\nwhich can be used with this implementation.\\n\\nThe GrpcStreamSubscription class handles the enumeration of the [AsyncSt\", \"reamReader:\\n\\npublic class GrpcStreamSubscription<T> : IDisposable\\n\\nt\\n\\nprivate readonly IAsyncStreamReader<T> _reader;\\nprivate readonly IObserver<T> _observer;\\n\\nprivate readonly CancellationTokenSource _tokenSource;\\nprivate readonly Task _task;\\nprivate bool _completed;\\n\\npublic GrpcStreamSubscription(IAsyncStreamReader<T> reader, IObserver<T> observer,\\nCancellationToken token = default)\\n\\nt\\n\\n_reader = reader ?? throw new ArgumentNullException(nameof\", \" (reader) ) ;\\n_observer = observer ?? throw new ArgumentNullException(nameof (observer) ) ;\\n\\n_tokenSource = new CancellationTokenSource() ;\\ntoken.Register(_tokenSource.Cancel1) ;\\n\\n_task = Run(_tokenSource. Token) ;\\n\\n}\\n\\nprivate async Task Run(CancellationToken token)\\n\\nt\\n\\nwhile (!token.IsCancellationRequested )\\n\\nt\\ntry\\n\\nt\\n\\n}\\ncatch (RpcException e) when (e.StatusCode == Grpc.Core.StatusCode.NotFound)\\n\\nt\\n}\\n\\ncatch (OperationCanceledException )\\n\\nt\\n}\\n\\nca\", \"tch (Exception e)\\n\\nt\\n\\nif (!await _reader.MoveNext(token)) break;\\n\\nbreak;\\n\\nbreak;\\n\\n_observer.OnError(e) ;\\n_completed = true;\\nreturn;\\n\\n}\\n\\n_observer.OnNext(_reader.Current) ;\\n\\n}\\n\\n_completed = true;\\n\\n66 CHAPTER 5 | Migrate a WCF solution to gRPC\\n_observer.OnCompleted() ;\\n\\n}\\npublic void Dispose()\\n{\\nif (! completed && !_tokenSource.IsCancellationRequested)\\n{\\n_tokenSource.Cancel();\\n}\\n_tokenSource.Dispose() ;\\n_task.Dispose();\\n}\\n\\nAll that is required now \", \"is a simple extension method to create the observable from the stream reader.\\n\\nnamespace Grpc.Core;\\npublic static class AsyncStreamReaderObservableExtensions\\n\\n{\\npublic static IObservable<T> AsObservable<T>(\\n\\nthis IAsyncStreamReader<T> reader,\\nCancellationToken cancellationToken = default) =>\\nnew GrpcStreamObservable<T>(reader, cancellationToken) ;\\n\\nSummary\\n\\nThe IAsyncEnumerable and !Observable models are both well-supported and well-documented wa\", \"ys\\nof dealing with asynchronous streams of data in .NET. gRPC streams map well to both paradigms,\\noffering close integration with .NET, and reactive and asynchronous programming styles.\\n\\n67 CHAPTER 5 | Migrate a WCF solution to gRPC\\nCHAPTER\\n\\nsecurity in GRPC\\napplications\\n\\nIn any real-world scenario, securing applications and services are essential. Security covers three key\\nareas:\\n\\n. Encrypting network traffic to prevent malicious hackers from in\", \"tercepting it.\\n. Authenticating clients and servers to establish identity and trust.\\n\\n. Authorizing clients to control access to systems and apply permissions based on identity.\\n\\nNote\\n\\nAuthentication is concerned with establishing the identity of a client or server. Authorization is\\nconcerned with determining whether a client has permission to access a resource or issue a command.\\n\\nThis chapter will cover the facilities for authentication and aut\", \"horization in gRPC for ASP.NET Core. It\\nwill also discuss network security through TLS encrypted connections.\\n\\nWCE authentication and authorization\\n\\nIn Windows Communication Foundation (WCF), authentication and authorization were handled in\\ndifferent ways, depending on the transports and bindings being used. WCF supported various WS-*\\nsecurity standards. It also supported Windows authentication for HTTP services running in IIS or\\nNetTCP services \", \"between Windows systems.\\n\\ngRPC authentication and authorization\\n\\ngRPC authentication and authorization works on two levels:\\n\\n. Call-level authentication/authorization is usually handled through tokens that are applied in\\nmetadata when the call is made.\\n\\n. Channel-level authentication uses a client certificate that's applied at the connection level. It\\ncan also include call-level authentication/authorization credentials to be applied to every call\", \"\\non the channel automatically.\\n\\nYou can use either or both of these mechanisms to help secure your service.\\n\\n68 CHAPTER 6 | Security in gRPC applications\\nThe ASP.NET Core implementation of gRPC supports authentication and authorization through most\\nof the standard ASP.NET Core mechanisms:\\n\\n. Call authentication\\n\\u2014 Azure Active Directory\\n- IdentityServer\\n- JWT Bearer Token\\n\\u2014- OAuth 2.0\\n- OpenID Connect\\n\\u2014 WS-Federation\\n. Channel authentication\\n\\u2014 Cli\", \"ent certificate\\n\\nThe call authentication methods are all based on tokens. The only real difference is how the tokens are\\ngenerated and the libraries that are used to validate the tokens in the ASP.NET Core service.\\n\\nFor more information, see the Authentication and authorization article.\\n\\nNote\\n\\nWhen you're using gRPC over a TLS-encrypted HTTP/2 connection, all traffic between clients and\\nservers is encrypted, even if you don\\u2019t use channel-level au\", \"thentication.\\n\\nThis chapter will show how to apply call credentials and channel credentials to a gRPC service. It will\\nalso show how to use credentials from a .NET gRPC client to authenticate with the service.\\n\\nCall credentials\\n\\nCall credentials are all based on a token passed in metadata with each request.\\n\\nWS-Federation\\n\\nASP.NET Core supports WS-Federation using the WsFederation NuGet package. WS-Federation is the\\nclosest available alternative \", \"to Windows Authentication, which isn't supported over HTTP/2. Users are\\nauthenticated by using Active Directory Federation Services (AD FS), which provides a token that can\\nbe used to authenticate with ASP.NET Core.\\n\\nFor more information on how to get started with this authentication method, see Authenticate users\\nwith WS-Federation in ASP.NET Core.\\n\\nJWT Bearer tokens\\n\\nThe JSON Web Token (JWT) standard provides a way to encode information about a\", \" user and their\\nclaims in an encoded string. It also provides a way to sign that token, so that the consumer can verify\\nthe integrity of the token by using public key cryptography. You can use various services, such as\\nIdentityServer4, to authenticate users and generate OpenID Connect (OIDC) tokens to use with gRPC\\nand HTTP APIs.\\n\\n69 CHAPTER 6 | Security in gRPC applications\\nASP.NET Core 7.0 can handle JWTs by using the JWT Bearer package. The co\", \"nfiguration is exactly the\\nsame for a gRPC application as it is for an ASP.NET Core MVC application. Here, we'll focus on JWT\\nBearer tokens, because they're easier to develop with than WS-Federation.\\n\\nAdd authentication and authorization to the server\\n\\nThe JWT Bearer package isn't included in ASP.NET Core 7.0 by default. Install the\\nMicrosoft.AsoNetCore.Authentication.JwtBearer NuGet package in your app.\\n\\nAdd the Authentication service in the Pro\", \"gram.cs class, and configure the JWT Bearer handler:\\n//\\n\\n//\\nbuilder.Services.AddGrpc();\\n\\nvar signingKey = ObtainSigningKeySomehow( ) ;\\n\\nbuilder.Services.AddAuthentication(JwtBearerDefaults .AuthenticationScheme)\\n.AddJwtBearer(options =>\\n{\\noptions.TokenValidationParameters =\\nnew TokenValidationParameters\\n{\\nValidateAudience = false,\\nValidateIssuer = false,\\nValidateActor = false,\\nValidateLifetime = true,\\nIssuerSigningKey = signingKey\\n\\nThe IssuerSign\", \"ingKey property requires an implementation of\\nMicrosoft.|dentityModels.Tokens.SecurityKey with the cryptographic data necessary to validate the\\nsigned tokens. Store this token securely in a secrets server, like Azure Key Vault.\\n\\nNext, add the Authorization service, which controls access to the system:\\n\\nservices.AddAuthorization(options =>\\n\\naf\\noptions .AddPolicy(JwtBearerDefaults.AuthenticationScheme, policy =>\\naf\\npolicy .AddAuthenticationSchemes(\", \"JwtBearerDefaults.AuthenticationScheme) ;\\npolicy.RequireClaim(ClaimTypes.Name) ;\\n})3\\n})3\\n\\nAuthentication and authorization are two separate steps. You use authentication to determine the\\n\\nuser's identity. You use authorization to decide whether that user is allowed to access various parts of\\nthe system.\\n\\n70 CHAPTER 6 | Security in gRPC applications\\nNow add the authentication and authorization middleware to the ASP.NET Core pipeline in the\\nProgram\", \".cs:\\n\\n//\\napp .UseRouting();\\n\\n// Authenticate, then Authorize\\napp.UseAuthentication() ;\\napp .UseAuthorization() ;\\n\\napp.UseEndpoints(endpoints =>\\n\\nendpoints .MapGrpcService<PortfolioService>() ;\\n\\n})3\\n\\nFinally, apply the [Authorize] attribute to any services or methods to be secured, and use the User\\nproperty from the underlying HttpContext to verify permissions.\\n\\n[ Authorize |\\npublic override async Task<GetResponse> Get(GetRequest request, ServerCa\", \"llContext context)\\n\\n{\\nif (!TryValidateUser(request.TraderId, context.GetHttpContext().User) )\\n{\\n\\n}\\n\\nvar portfolio = await _repository.GetAsync(traderId, request.Portfoliold) ;\\n\\nthrow new RpcException(new Status(StatusCode.PermissionDenied, \\\"Denied.\\\"));\\n\\nreturn new GetResponse\\n\\n{\\n}3\\n\\nPortfolio = Portfolio. FromRepositoryModel (portfolio)\\n\\nProvide call credentials in the client application\\n\\nAfter you've obtained a JWT token from an identity server,\", \" you can use it to authenticate gRPC calls\\nfrom the client by adding it as a metadata header on the call, as follows:\\n\\npublic async Task ShowPortfolioAsync(int portfoliolId)\\n{\\n\\nvar headers = new Grpc.Core.Metadata\\n\\n{ \\\"Authorization\\\", $\\u00a2$\\\"Bearer {_userToken}\\\" }\\n}5\\nvar request = new GetRequest\\n{\\nTraderId = _userld,\\nPortfolioId = portfoliolId\\n}5\\n\\nvar response = await _portfoliosClient.GetAsync(request, headers) ;\\n\\n// Display portfolio\\n\\nNow you've se\", \"cured your gRPC service by using JWT bearer tokens as call credentials. A version of the\\n\\nportfolios sample gRPC application with authentication and authorization added is on GitHub.\\n\\n71 CHAPTER 6 | Security in gRPC applications\\nChannel credentials\\n\\nAs the name implies, channel credentials are attached to the underlying gRPC channel. The standard\\nform of channel credentials uses client certificate authentication. In this process, the client provi\", \"des a\\nTLS certificate when it\\u2019s making the connection, and then the server verifies this certificate before\\nallowing any calls to be made.\\n\\nYou can combine channel credentials with call credentials to provide comprehensive security for a\\nQRPC service. The channel credentials prove that the client application is allowed to access the service,\\nand the call credentials provide information about the person who is using the client application.\\n\\nClient\", \" certificate authentication works for gRPC the same way it works for ASP.NET Core. For more\\ninformation, see Configure certificate authentication in ASP.NET Core.\\n\\nFor development purposes you can use a self-signed certificate, but for production you should use a\\nproper HTTPS certificate signed by a trusted authority.\\n\\nAdd certificate authentication to the server\\n\\nConfigure certificate authentication both at the host level (for example, on the Ke\", \"strel server), and in\\nthe ASP.NET Core pipeline.\\n\\nConfigure certificate validation on Kestrel\\n\\nYou can configure Kestrel (the ASP.NET Core HTTP server) to require a client certificate, and optionally\\nto carry out some validation of the supplied certificate, before accepting incoming connections. You\\nspecify this configuration in the Program.cs:\\n\\nvar builder = WebApplication.CreateBuilder(args) ;\\n\\nvar serverCert = ObtainServerCertificate() ;\\n\\nbuil\", \"der .WebHost .UseKestrel(kestrelServerOptions => {\\nkestrelServerOptions.ConfigureHttpsDefaults(opt =>\\n\\nopt.ClientCertificateMode = ClientCertificateMode.RequireCertificate;\\n\\n// Nerify that client certificate was issued by same CA as server certificate\\nopt.ClientCertificateValidation = (certificate, chain, errors) =>\\ncertificate.Issuer == serverCert.Issuer;\\n\\n})3\\n\\n})5\\n\\nThe ClientCertificateMode.RequireCertificate setting causes Kestrel to immediate\", \"ly reject any\\nconnection request that doesn\\u2019t provide a client certificate, but this setting by itself won't validate a\\ncertificate that is provided. Add the ClientCertificateValidation callback to enable Kestrel to validate\\nthe client certificate at the point the connection is made, before the ASP.NET Core pipeline is\\nengaged. (In this case, the callback ensures that it was issued by the same Certificate Authority as the\\nserver certificate.)\\n\\n72\", \" CHAPTER 6 | Security in gRPC applications\\nAdd ASP.NET Core certificate authentication\\n\\nThe Microsoft.AspNetCore.Authentication.Certificate NuGet package provides certificate\\nauthentication.\\n\\nAdd the certificate authentication service in the Program.cs, and add authentication and authorization\\nto the ASP.NET Core pipeline.\\n\\n//\\n\\nbuilder.Services.AddAuthentication(CertificateAuthenticationDefaults .AuthenticationScheme )\\n.AddCertificate(options =>\\n\", \"{\\n\\noptions.AllowedCertificateTypes = CertificateTypes.Chained;\\noptions.RevocationMode = X509RevocationMode.NoCheck;\\n\\noptions.Events = new CertificateAuthenticationEvents\\n\\n{\\n}3\\n\\nOnCertificateValidated = DevelopmentModeCertificateHelper.Validate\\nbuilder.Services.AddAuthorization() ;\\nbuilder.Services.AddGrpc();\\nvar app = builder.Build();\\n// Configure the HTTP request pipeline.\\n\\napp.UseRouting();\\n\\napp.UseAuthentication() ;\\napp.UseEndpoints(endpoints \", \"=> { endpoints.MapGrpcService<GreeterService>(); });\\n\\n//\\n\\nProvide channel credentials in the client application\\nWith the Grpc.Net.Client package, you configure certificates on an HttpClient instance that is provided\\n\\nto the GrpcChannel used for the connection.\\n\\nLoad a client certificate from a .PFX file\\n\\nA certificate can be loaded from a .pjfx file.\\n\\nclass Program\\n\\nt\\n\\nstatic async Task Main(string[ ] args)\\n\\nt\\n\\n// Assume path to a client .pfx fil\", \"e and password are passed from command line\\n// On Windows this would probably be a reference to the Certificate Store\\nvar cert = new X509Certificate2(args[@], args[1]);\\n\\nvar handler = new HttpClientHandler() ;\\nhandler.ClientCertificates.Add(cert) ;\\nvar httpClient = new HttpClient(handler) ;\\n\\nvar channel = GrpcChannel.ForAddress(\\\"https://localhost:5001/\\\", new\\nGrpcChannelOptions\\n\\nHttpClient = httpClient\\n\\n73 CHAPTER 6 | Security in gRPC applications\", \"\\n})3\\n\\nvar grpc = new Greeter.GreeterClient (channel) ;\\nvar response = await grpc.SayHelloAsync(new HelloRequest { Name = \\\"Bob\\\" });\\nSystem. Console.WriteLine(response.Message) ;\\n\\nLoad a client certificate from certificate and private key .PEM files\\n\\nA certificate can be loaded from a certificate and private key .pem file.\\n\\nclass Program\\n{\\nstatic async Task Main(string[ ] args)\\n{\\n// Assume path to a certificate and private key .pem files are passed\", \" from command\\nline\\nstring certificatePem = File.ReadAllText(args[0]);\\nstring privateKeyPem = File.ReadAllText(args[1]);\\nvar cert = X5e9Certificate2.CreateFromPem(certificatePem, privateKeyPem) ;\\n\\nvar handler = new HttpClientHandler() ;\\nhandler.ClientCertificates.Add(cert) ;\\nusing HttpClient httpClient = new(handler) ;\\n\\nvar channel = GrpcChannel.ForAddress(\\\"https://localhost:5001/\\\", new\\nGrpcChannelOptions\\n\\nHttpClient = httpClient\\n})3\\n\\nvar grpc = n\", \"ew Greeter.GreeterClient (channel) ;\\nvar response = await grpc.SayHelloAsync(new HelloRequest { Name = \\\"Bob\\\" });\\nSystem. Console.WriteLine(response.Message) ;\\n\\nNote\\n\\nDue to an internal Windows bug as documented here, you'll need to apply the following workaround\\nif the certificate is created from a certificate and private key PEM data.\\n\\n]{custom-style=Code} csharp X509Certificate2 cert = X509Certificate2.CreateFromPem(certificatePem,\\nrsaPrivateKe\", \"yPem); if (Runtimelnformation.lsOSPlatform(OSPlatform.Windows)) { var originalCert =\\ncert; cert = new X509Certificate2(cert.Export(X509ContentType.Pkcs12)); originalCert.Dispose(); } [\\n\\nCombine ChannelCredentials and CallCredentials\\n\\nYou can configure your server to use both certificate and token authentication. To do this, apply the\\ncertificate changes to the Kestrel server, and use the JWT bearer middleware in ASP.NET Core.\\n\\nTo provide both Cha\", \"nnelCredentials and CallCredentials on the client, use the\\nChannelCredentials.Create method to apply the call credentials. You still need to apply certificate\\nauthentication by using the HttpClient instance. If you pass any arguments to the SslCredentials\\n\\n74 CHAPTER 6 | Security in gRPC applications\\nconstructor, the internal client code throws an exception. The SslCredentials parameter is only\\nincluded in the Grpc.Net.Client package's Create met\", \"hod to maintain compatibility with the Grpc.Core\\npackage.\\n\\nvar handler = new HttpClientHandler() ;\\nhandler.ClientCertificates.Add(cert) ;\\n\\nvar httpClient = new HttpClient (handler) ;\\n\\nvar callCredentials = CallCredentials.FromInterceptor(((context, metadata) =>\\n\\n{\\nmetadata.Add(\\\"Authorization\\\", $\\\"Bearer {_token}\\\") ;\\n\\nreturn Task.CompletedTask;\\n}))3\\n\\nvar channelCredentials = ChannelCredentials.Create(new SslCredentials(), callCredentials) ;\\nvar cha\", \"nnel = GrpcChannel.ForAddress(\\\"https://localhost:5001/\\\", new GrpcChannelOptions\\n\\nHttpClient = httpClient,\\nCredentials = channelCredentials\\n\\n})3\\n\\nvar grpc = new Portfolios.PortfoliosClient (channel) ;\\n\\nTip\\n\\nYou can use the ChannelCredentials.Create method for a client without certificate authentication. This\\nis a useful way to pass token credentials with every call made on the channel.\\n\\nA version of the FullStockTicker sample gRPC application with\", \" certificate authentication added is on\\nGitHub.\\n\\nEncryption and network security\\n\\nThe network security model for Windows Communication Foundation (WCF) is extensive and complex.\\nIt includes transport-level security by using HTTPS or TLS-over-TCP, and message-level security by\\nusing the WS-Security specification to encrypt individual messages.\\n\\ngRPC leaves secure networking to the underlying HTTP/2 protocol, which you can secure by using TLS\\ncerti\", \"ficates.\\n\\nWeb browsers insist on using TLS connections for HTTP/2, but most programmatic clients, including\\n.NET\\u2019s HttpClient, can use HTTP/2 over unencrypted connections.\\n\\nFor public APIs, you should always use TLS connections, and provide valid certificates for your services\\nfrom a proper SSL authority. LetsEncrypt provides free, automated SSL certificates, and most hosting\\ninfrastructure today supports the LetsEncrypt standard with common plug\", \"-ins or extensions.\\n\\nFor internal services across a corporate network, you should still consider using TLS to secure network\\ntraffic to and from your gRPC services.\\n\\n75 CHAPTER 6 | Security in gRPC applications\\nIf you need to use explicit TLS between services running in Kubernetes, consider using an in-cluster\\ncertificate authority and a certificate manager controller like cert-manager. You can then automatically\\nassign certificates to services a\", \"t deployment time.\\n\\n76 CHAPTER 6 | Security in gRPC applications\\nCHAPTER\\n\\ngRPC in production\\n\\nYou can run ASP.NET Core 7.0 applications, including gRPC services, on Windows, on Linux, and in\\ncontainers using modern platforms like Docker and Kubernetes. This chapter explores the various\\noptions for running your gRPC services in production, and looks at monitoring and logging options to\\nensure the optimal operation of systems.\\n\\nSelf-hosted gRPC app\", \"lications\\n\\nAlthough ASP.NET Core 7.0 applications can be hosted in IIS on Windows Server, currently it isn\\u2019t\\npossible to host a gRPC application in IIS because some of the HTTP/2 functionality isn\\u2019t supported.\\nThis functionality is a goal for a future update to Windows Server.\\n\\nYou can run your application as a Windows service. Or you can run it as a Linux service controlled by\\n\\nsystemd, because of features introduced in the .NET 6 hosting extens\", \"ions.\\n\\nRun your app as a Windows service\\n\\nTo configure your ASP.NET Core application to run as a Windows service, install the\\nMicrosoft.Extensions.Hosting.WindowsServices package from NuGet. Then add a call to\\nUseWindowsService to the CreateHostBuilder method in Program.cs.\\n\\nHost.CreateDefaultBuilder(args)\\n. UseWindowsService()\\n\\nNote\\n\\nIf the application isn\\u2019t running as a Windows service, the UseWindowsService method doesn't do\\nanything.\\n\\nNow pub\", \"lish your application by using one of these methods:\\n\\n. From Visual Studio by right-clicking the project and selecting Publish on the shortcut menu.\\n\\n\\u00b0 From the .NET CLI.\\nWhen you publish a .NET application, you can choose to create a framework-dependent deployment\\nor a self-contained deployment. Framework-dependent deployments require the .NET Shared Runtime\\n\\nto be installed on the host where they're run. Self-contained deployments are published\", \" with a\\ncomplete copy of the .NET runtime and framework and can be run on any host. For more information,\\n\\n77 CHAPTER 7 | gRPC in production\\nincluding the advantages and disadvantages of each approach, see the .NET application deployment\\ndocumentation.\\n\\nTo publish a self-contained build of the application that doesn\\u2019t require the .NET 5 runtime to be\\ninstalled on the host, specify the runtime to be included with the application. Use the -r (or --\", \"runtime)\\nflag.\\n\\ndotnet publish -c Release -r win-x64 -o ./publish\\n\\nTo publish a framework-dependent build, omit the -r flag.\\n\\ndotnet publish -c Release -o ./publish\\n\\nCopy the complete contents of the publish directory to an installation folder. Then, use the sc tool to\\n\\ncreate a Windows service for the executable file.\\n\\nsc create MyService binPath=C: \\\\MyService\\\\MyService.exe\\n\\nLog to the Windows event log\\n\\nThe UseWindowsService method automaticall\", \"y adds a logging provider that writes log messages to\\nthe Windows event log. You can configure logging for this provider by adding an EventLog entry to\\nthe Logging section of appsettings.json or another configuration source.\\n\\nYou can override the source name used in the event log by setting a SourceName property in these\\nsettings. If you don\\u2019t specify a name, the default application name (normally the executable assembly\\nname) will be used.\\n\\nMore\", \" information on logging is at the end of this chapter.\\n\\nRun your app as a Linux service with systemd\\n\\nTo configure your ASP.NET Core application to run as a Linux service (or daemon in Linux parlance),\\ninstall the Microsoft.Extensions.Hosting.Systemd package from NuGet. Then add a call to UseSystemd\\nto the CreateHostBuilder method in Program.cs.\\n\\npublic static IHostBuilder CreateHostBuilder(string[] args) =>\\nHost.CreateDefaultBuilder (args)\\n.UseS\", \"ystemd() // Enable running as a Systemd service\\n.ConfigureServices((hostContext, services) =>\\n\\nt\\n\\nHe\\n\\nNote\\n\\nIf the application isn\\u2019t running as a Linux service, the UseSystemd method doesn't do anything.\\n\\nNow publish your application. The application can be either framework dependent or self-contained\\nfor the relevant Linux runtime (for example, linux-x64). You can publish by using one of these\\nmethods:\\n\\n78 CHAPTER 7 | gRPC in production\\n. From V\", \"isual Studio by right-clicking the project and selecting Publish on the shortcut menu.\\n\\n. From the .NET CLI, by using the following command:\\n\\ndotnet publish -c Release -r linux-x64 -o ./publish\\n\\nCopy the complete contents of the publish directory to an installation folder on the Linux host.\\nRegistering the service requires a special file, called a unit file, to be added to the /etc/systemd/system\\ndirectory. You'll need root permission to create a\", \" file in this folder. Name the file with the identifier\\nthat you want systemd to use and the .service extension. For example, use\\n/etc/systemd/system/myapp.service.\\n\\nThe service file uses INI format, as shown in this example:\\n\\n[Unit ]\\nDescription=My gRPC Application\\n\\n[Service]\\n\\nType=notify\\nExecStart=/usr/sbin/myapp\\n\\n[Install]\\nWantedBy=multi-user.target\\n\\nThe Type=notify property tells systemd that the application will notify it on startup and shut\", \"down. The\\nWantedBy=multi-user.target setting will cause the service to start when the Linux system reaches\\n\\u201crunlevel 2,\\u201d which means a nongraphical, multi-user shell is active.\\n\\nBefore systemd will recognize the service, it needs to reload its configuration. You control systemd by\\nusing the systemctl command. After reloading, use the status subcommand to confirm that the\\napplication has registered successfully.\\n\\nsudo systemctl daemon-reload\\nsudo \", \"systemctl status myapp\\nIf you've configured the service correctly, you'll get the following output:\\n\\nmyapp.service - My gRPC Application\\nLoaded: loaded (/etc/systemd/system/myapp.service; disabled; vendor preset: enabled)\\nActive: inactive (dead)\\n\\nUse the start command to start the service.\\n\\nsudo systemctl start myapp.service\\n\\nTip\\n\\nThe .service extension is optional when you're using systemctl start.\\n\\nTo tell systemd to start the service automatic\", \"ally on system startup, use the enable command.\\n\\nsudo systemctl enable myapp\\n\\n79 CHAPTER 7 | gRPC in production\\nLog to journald\\n\\nThe Linux equivalent of the Windows event log is journald, a structured logging system service that\\u2019s\\npart of systemd. Log messages written to the standard output by a Linux daemon are automatically\\nwritten to journald. To configure logging levels, use the Console section of the logging configuration.\\nThe UseSystemd hos\", \"t builder method automatically configures the console output format to suit the\\njournal.\\n\\nBecause journald is the standard for Linux logs, a variety of tools integrate with it. You can easily route\\nlogs from journald to an external logging system. Working locally on the host, you can use the\\njournalctl command to view logs from the command line.\\n\\nsudo journalctl -u myapp\\n\\nTip\\n\\nIf you have a GUI environment available on your host, a few graphical \", \"log viewers are available for\\nLinux, such as QJournalctl and gnome-logs.\\n\\nTo learn more about querying the systemd journal from the command line by using journalctl, see the\\nmanpages.\\n\\nHTTPS certificates for self-hosted applications\\n\\nWhen you're running a gRPC application in production, you should use a TLS certificate from a trusted\\ncertificate authority (CA). This CA might be a public CA, or an internal one for your organization.\\n\\nOn Windows ho\", \"sts, you can load the certificate from a secure certificate store by using the X509Store\\nclass. You can also use the X509Store class with the OpenSSL key store on some Linux hosts.\\n\\nYou can also create certificates by using one of the X509Certificate2 constructors, from either:\\n\\n. A file, such as a .pfx file protected by a strong password\\n\\n\\u00b0 Binary data retrieved from a secure storage service such as Azure Key Vault\\n\\nYou can configure Kestrel to \", \"use a certificate in two ways: from configuration or in code.\\n\\nSet HTTPS certificates by using configuration\\n\\nThe configuration approach requires setting the password and path to the certificate .pfx file in the\\nKestrel configuration section. In appsettings.json, that looks like this:\\n\\n\\\"Kestrel\\\": {\\n\\\"Certificates\\\": {\\n\\\"Default\\\": {\\n\\\"Path\\\": \\\"cert.pfx\\\",\\n\\n\\\"Password\\\": \\\"DO NOT STORE PLAINTEXT PASSWORDS IN APPSETTINGS FILES\\\"\\n\\n80 CHAPTER 7 | gRPC in produc\", \"tion\\nProvide the password by using a secure configuration source such as Azure Key Vault or Hashicorp\\nVault.\\n\\nImportant\\n\\nDon't store unencrypted passwords in configuration files.\\n\\nSet HTTPS certificates in code\\n\\nTo configure HTTPS on Kestrel in code, use the ConfigureKestrel method on I!WebHostBuilder in the\\nProgram class.\\n\\npublic static IHostBuilder CreateHostBuilder(string[ |] args) =>\\nHost.CreateDefaultBuilder (args)\\n.ConfigureWebHostDefaults(\", \"webBuilder =>\\n{\\n\\nwebBuilder.ConfigureKestrel(kestrel =>\\n\\nkestrel.ConfigureHttpsDefaults(https =>\\n{\\nhttps.ServerCertificate = new X509Certificate2(\\\"mycert.pfx\\\",\\n\\\"password\\\" ) ;\\n})3\\n})3\\n})3\\n\\nAgain, be sure to store the password for the .pfx file in, and retrieve it from, a secure configuration\\nsource.\\n\\nCreate Docker images\\n\\nThis section covers the creation of Docker images for ASP.NET Core gRPC applications, ready to run in\\nDocker, Kubernetes, or ot\", \"her container environments. The sample application used, with an ASP.NET\\n\\nCore MVC web app and a gRPC service, is available on the dotnet-architecture/grpc-for-wcf-\\ndevelopers repository on GitHub.\\nMicrosoft base images for ASP.NET Core applications\\n\\nMicrosoft provides a range of base images for building and running .NET applications. To create an\\nASP.NET Core 7.0 image, you use two base images:\\n\\n. An SDK image to build and publish the applicatio\", \"n.\\n\\n. A runtime image for deployment.\\n\\nptmage | eseripticm\\n\\nmcer.microsoft.com/dotnet/sd | For building applications with docker build. Not to be used in\\nproduction.\\n\\nmcer.microsoft.com/dotnet/as | Contains the runtime and ASP.NET Core dependencies. For\\npnet production.\\n\\nFor each image, there are four variants based on different Linux distributions, distinguished by tags.\\n\\n81 CHAPTER 7 | gRPC in production\\n7.0-bullseye-slim, 7.0 Debian 11 The def\", \"ault image if no\\nOS variant is specified.\\n\\n7.0-alpine Alpine 3.17 Alpine base images are\\nmuch smaller than\\nDebian or Ubuntu ones.\\n\\nThe Alpine base image Is around 100 MB, compared to 200 MB for the Debian and Ubuntu images.\\nSome software packages or libraries might not be available in Alpine\\u2019s package management. If you're\\nnot sure which image to use, you should probably choose the default Debian.\\n\\nImportant\\n\\nMake sure you use the same variant of\", \" Linux for the build and the runtime. Applications built and\\npublished on one variant might not work on another.\\n\\nCreate a Docker image\\n\\nA Docker image is defined by a Dockerfile. This Dockerfile is a text file that contains all the commands\\nneeded to build the application and install any dependencies that are required for either building or\\nrunning the application. The following example shows the simplest Dockerfile for an ASP.NET Core 7.0\\nappli\", \"cation:\\n\\nFROM mcr.microsoft.com/dotnet/sdk:7.0 as build\\n\\nWORKDIR /src\\n\\nCOPY ./StockKube.sln .\\n\\nCOPY ./src/StockData/StockData.csproj ./src/StockData/\\nCOPY ./src/StockWeb/StockWeb.csproj ./src/StockWeb/\\nRUN dotnet restore\\n\\nCOPY .\\n\\nRUN dotnet publish --no-restore -c Release -o /published src/StockData/StockData.csproj\\n\\nFROM mcr.microsoft.com/dotnet/aspnet:7.@ as runtime\\n\\n# Uncomment the line below if running with HTTPS\\n# ENV ASPNETCORE_URLS=https:/\", \"/+:443\\n\\nWORKDIR /app\\n\\nCOPY --from=build /published .\\n\\nENTRYPOINT [ \\\"dotnet\\\", \\\"StockData.dll\\\" |\\n\\nThe Dockerfile has two parts: the first uses the sdk base image to build and publish the application;\\nthe second creates a runtime image from the aspnet base. This is because the sdk image is around\\n900 MB, compared to around 200 MB for the runtime image, and most of its contents are unnecessary\\nat run time.\\n\\n82 CHAPTER 7 | gRPC in production\\nThe build\", \" steps\\n\\nstep | scription\\nFROM ... Declares the base image and assigns the builder alias.\\nWORKDIR /src Creates the /src directory and sets it as the current working directory.\\n\\nCOPY .. Copies everything below the current directory on the host into the\\ncurrent directory on the image.\\n\\nRUN dotnet restore Restores any external packages (ASP.NET Core 3.0 framework is\\npreinstalled with the SDK).\\n\\nRUN dotnet publish ... Builds and publishes a Release bu\", \"ild. The --runtime flag isn\\u2019t required.\\n\\nThe runtime image steps\\n\\nPp step | scription\\nFROM ... Declares a new base image.\\nWORKDIR /app Creates the /app directory and sets it as the current working directory.\\n\\nCOPY --from=builder ... | Copies the published application from the previous image, by using the\\nbuilder alias from the first FROM line.\\n\\nENTRYPOINT [... ] Sets the command to run when the container starts. The dotnet\\ncommand in the runtime \", \"image can only run DLL files.\\n\\nHTTPS in Docker\\n\\nMicrosoft base images for Docker set the ASPNETCORE_URLS environment variable to http://+:80,\\nmeaning that Kestrel runs without HTTPS on that port. If you're using HTTPS with a custom certificate\\n(as described in Self-hosted gRPC applications), you should override this configuration. Set the\\nenvironment variable in the runtime image creation part of your Dockerrfile.\\n\\n# Runtime image creation\\nFROM m\", \"cr.microsoft.com/dotnet/aspnet:7.@\\n\\nENV ASPNETCORE_URLS=https://+:443\\n\\nThe .dockerignore file\\n\\nMuch like .gitignore files that exclude certain files and directories from source control, the\\n.dockerignore file can be used to exclude files and directories from being copied to the image during\\nbuild. This file not only saves time copying, but can also avoid some errors that arise from having the\\nobj directory from your PC copied into the image. At a\", \" minimum, you should add entries for bin and\\nobj to your .dockerignore file.\\n\\nbin/\\n\\nobj/\\n\\n83 CHAPTER 7 | gRPC in production\\nBuild the image\\n\\nFor a StockKube.sIn solution containing two different applications StockData and StockWeb, it's\\nsimplest to put the Dockerfile for each one of them in the base directory. In that case, to build the\\nimage, use the following docker build command from the same directory where .sln file resides.\\n\\ndocker build -t\", \" stockdata:1.0.0 -f ./src/StockData/Dockerfile .\\n\\nThe confusingly named --tag flag (which can be shortened to -t) specifies the whole name of the\\nimage, including the actual tag if specified. The . at the end specifies the context in which the build\\nwill be run; the current working directory for the COPY commands in the Dockerfile.\\n\\nIf you have multiple applications within a single solution, you can keep the Dockerfile for each\\napplication in its\", \" own folder, beside the .csproj file. You should still run the docker build command\\nfrom the base directory to ensure that the solution and all the projects are copied into the image. You\\ncan specify a Dockerfile below the current directory by using the --file (or -f) flag.\\n\\ndocker build -t stockdata:1.0.0 -f ./src/StockData/Dockerfile .\\n\\nRun the image in a container on your machine\\n\\nTo run the image in your local Docker instance, use the docker \", \"run command.\\n\\ndocker run -ti -p 5000:80 stockdata:1.0.0\\n\\nThe -ti flag connects your current terminal to the container\\u2019s terminal, and runs in interactive mode.\\nThe -p 5000:80 publishes (links) port 80 on the container to port 5000 on the localhost network\\ninterface.\\n\\nPush the image to a registry\\n\\nAfter you've verified that the image works, push it to a Docker registry to make it available on other\\nsystems. Internal networks will need to provision\", \" a Docker registry. This activity can be as simple as\\nrunning Docker's own registry_image (the Docker registry runs in a Docker container), but there are\\nvarious more comprehensive solutions available. For external sharing and cloud use, there are various\\nmanaged registries available, such as Azure Container Registry or Docker Hub.\\n\\nTo push to Docker Hub, prefix the image name with your user or organization name.\\n\\ndocker tag stockdata:1.0.0 <myor\", \"g>/stockdata:1.0.0\\n\\ndocker push <myorg>/stockdata:1.0.0\\n\\nTo push to a private registry, prefix the image name with the registry host name and the organization\\nname.\\n\\ndocker tag stockdata <internal-registry:5000>/<myorg>/stockdata:1.0.0\\n\\ndocker push <internal-registry :500@>/<myorg>/stockdata:1.0.0\\n\\nAfter the image Is in a registry, you can deploy it to individual Docker hosts, or to a container\\norchestration engine like Kubernetes.\\n\\n84 CHAPTER 7 \", \"| gRPC in production\\nKubernetes\\n\\nAlthough it's possible to run containers manually on Docker hosts, for reliable production systems it's\\nbetter to use a container orchestration engine to manage multiple instances running across several\\nservers in a cluster. There are various container orchestration engines available, including Kubernetes,\\nDocker Swarm, and Apache Mesos. But of these engines, Kubernetes is far and away the most widely\\nused, so it \", \"will be the focus of this chapter.\\n\\nKubernetes includes the following functionality:\\n\\n. Scheduling runs containers on multiple nodes within a cluster, ensuring balanced usage of\\nthe available resource, keeping containers running if there are outages, and handling rolling\\nupdates to new versions of images or new configurations.\\n\\n. Health checks monitor containers to ensure continued service.\\n\\u00b0 DNS & service discovery handles routing between servic\", \"es within a cluster.\\n. Ingress exposes selected services externally and generally provides load-balancing across\\n\\ninstances of those services.\\n\\u00b0 Resource management attaches external resources like storage to containers.\\n\\nThis chapter will detail how to deploy an ASP.NET Core gRPC service and a website that consumes the\\nservice into a Kubernetes cluster. The sample application used is available in the dotnet-\\n\\narchitecture/grpc-for-wcf-developers\", \" repository on GitHub.\\n\\nKubernetes terminology\\n\\nKubernetes uses desired state configuration: the API is used to describe objects like Pods, Deployments,\\nand Services, and the Control Plane takes care of implementing the desired state across all the nodes\\nin a cluster. A Kubernetes cluster has a Master node that runs the Kubernetes API, which you can\\ncommunicate with programmatically or by using the kubectl command-line tool. kubectl can create\\nan\", \"d manage objects through command-line arguments, but it works best with YAML files that contain\\ndeclaration data for Kubernetes objects.\\n\\nKubernetes YAML files\\n\\nEvery Kubernetes YAML file will have at least three top-level properties:\\n\\napiVersion: v1\\nkind: Namespace\\n\\nmetadata:\\n# Object properties\\n\\nThe apiVersion property is used to specify which version (and which API) the file is intended for. The\\nkind property specifies the kind of object the Y\", \"AML represents. The metadata property contains\\nobject properties like name, namespace, and labels.\\n\\nMost Kubernetes YAML files will also have a spec section that describes the resources and\\nconfiguration necessary to create the object.\\n\\n85 CHAPTER 7 | gRPC in production\\nPods\\n\\nPods are the basic units of execution in Kubernetes. They can run multiple containers, but they\\u2019re also\\nused to run single containers. The pod also includes any storage reso\", \"urces required by the containers,\\nand the network IP address.\\n\\nServices\\n\\nServices are meta-objects that describe Pods (or sets of Pods) and provide a way to access them\\nwithin the cluster, such as mapping a service name to a set of pod IP addresses by using the cluster\\nDNS service.\\n\\nDeployments\\n\\nDeployments are the desired state objects for Pods. If you create a pod manually, it won't be restarted\\nwhen it terminates. Deployments are used to tell \", \"the cluster which Pods, and how many replicas of\\nthose Pods, should be running at the present time.\\n\\nOther objects\\n\\nPods, Services, and Deployments are just three of the most basic object types. There are dozens of\\nother object types that are managed by Kubernetes clusters. For more information, see the\\n\\nKubernetes Concepts documentation.\\n\\nNamespaces\\n\\nKubernetes clusters are designed to scale to hundreds or thousands of nodes and to run similar\\nn\", \"umbers of services. To avoid clashes between object names, namespaces are used to group objects\\ntogether as part of larger applications. Kubernetes\\u2019s own services run in a default namespace. All user\\nobjects should be created in their own namespaces to avoid potential clashes with default objects or\\nother tenants in the cluster.\\n\\nGet started with Kubernetes\\n\\nIf you're running Docker Desktop for Windows or Docker Desktop for Mac, Kubernetes is alr\", \"eady\\navailable. Just enable it in the Kubernetes section of the Settings window:\\n\\n86 CHAPTER 7 | gRPC in production\\n@ docker \\u00a9 Es e sughosneo\\n\\nSettings x\\n\\n= General Kubernetes\\n\\nv1.19.3\\n{\\u00a9 Resources\\n\\nEnable Kubernetes\\n\\nStart a Kubernetes single-node cluster when starting Docker Desktop.\\n\\n@ Docker Engine\\n\\n& Experimental Features\\n. 7 (1) Deploy Docker Stacks to Kubernetes by default\\n\\nKubernetes Make Kubernetes the default orchestrator for \\\"docker st\", \"ack\\\" commands (changes \\\"~/.docker/config.json\\\")\\n\\n(J Show system containers (advanced)\\n\\nShow Kubernetes internal containers when using Docker commands.\\n\\nReset Kubernetes Cluster\\n\\nAll stacks and Kubernetes resources will be deleted.\\n\\n@ Docker running @ Kubernetes running Apply & Restart\\n\\nTo run a local Kubernetes cluster on Linux, consider minikube, or MicroK8s if your Linux distribution\\nsupports snaps.\\n\\nTo confirm that your cluster is running and \", \"accessible, run the kubectl version command:\\n\\nkubectl version\\n\\nClient Version: version.Info{Major:\\\"1\\\", Minor:\\\"19\\\", GitVersion:\\\"v1.19.3\\\",\\nGitCommit: \\\"1e11e4a2108024935ecfcb2912226cedeafd99df\\\", GitTreeState: \\\"clean\\\",\\nBuildDate:\\\"2020-10-14T12:50:19Z\\\", GoVersion:\\\"go1.15.2\\\", Compiler:\\\"gc\\\",\\n\\nPlatform: \\\"windows/amd64\\\" }\\n\\nServer Version: version.Info{Major:\\\"1\\\", Minor:\\\"19\\\", GitVersion:\\\"v1.19.3\\\",\\nGitCommit: \\\"1e11e4a2108024935ecfcb2912226cedeafd99df\\\", GitTr\", \"eeState: \\\"clean\\\",\\nBuildDate:\\\"2020-10-14T12:41:49Z\\\", GoVersion:\\\"go1.15.2\\\", Compiler:\\\"gc\\\",\\nPlatform: \\\"linux/amd64\\\"}\\n\\nIn this example, both the kubectl CLI and the Kubernetes server are running version 1.14.6. Each\\nversion of kubectl is supposed to support the previous and next version of the server, so kubectl 1.14\\nshould work with server versions 1.13 and 1.15 as well.\\n\\nRun services on Kubernetes\\n\\nThe sample application has a kube directory that c\", \"ontains three YAML files. The namespace.yml file\\ndeclares a custom namespace: stocks. The stockdata.yml file declares the Deployment and the Service\\nfor the gRPC application, and the stockweb.yml file declares the Deployment and Service for an\\nASP.NET Core 7.0 MVC web application that consumes the gRPC service.\\n\\nTo use a YAML file with kubectl, run the apply -f command:\\n\\nkubectl apply -f object.yml\\n\\nThe apply command will check the validity of th\", \"e YAML file and display any errors received from the\\nAPI, but doesn\\u2019t wait until all the objects declared in the file have been created because this step can\\n\\n87 CHAPTER 7 | gRPC in production\\ntake some time. Use the kubectl get command with the relevant object types to check on object\\ncreation in the cluster.\\n\\nThe namespace declaration\\n\\nNamespace declaration is simple and requires only assigning a name:\\n\\napiVersion: v1\\nkind: Namespace\\n\\nmetadata:\", \"\\nname: stocks\\n\\nUse kubectl to apply the namespace.yml file and to confirm the namespace is created successfully:\\n\\n> kubectl apply -f namespace.yml\\nnamespace/stocks created\\n\\n> kubectl get namespaces\\nNAME STATUS\\nstocks Active\\n\\nThe StockData application\\n\\nThe stockdata.yml file declares two objects: a Deployment and a Service.\\n\\nThe StockData Deployment\\n\\nThe Deployment part of the YAML file provides the spec for the deployment itself, including the\\nnu\", \"mber of replicas required, and a template for the Pod objects to be created and managed by the\\ndeployment. Note that Deployment objects are managed by the apps API, as specified in apiVersion,\\nrather than the main Kubernetes API.\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\nname: stockdata\\nnamespace: stocks\\nspec:\\nselector:\\nmatchLabels:\\nrun: stockdata\\nreplicas: 1\\ntemplate:\\nmetadata:\\nlabels:\\n\\nrun: stockdata\\n\\nspec:\\ncontainers:\\n- name: stockdata\\ni\", \"mage: stockdata:1.0.0\\nimagePullPolicy: Never\\nresources:\\nlimits:\\ncpu: 100m\\nmemory: 10Q@Mi\\nports:\\n- containerPort: 80\\n\\n88 CHAPTER 7 | gRPC in production\\nThe spec.selector property is used to match running Pods to the Deployment. The Pod's\\nmetadata.labels property must match the matchLabels property or the API call will fail.\\n\\nThe template.spec section declares the container to be run. When you're working with a local\\nKubernetes cluster, such as the\", \" one provided by Docker Desktop, you can specify images that were\\nbuilt locally as long as they have a version tag.\\n\\nImportant\\n\\nBy default, Kubernetes will always check for and try to pull a new image. If it can\\u2019t find the image in\\n\\nany of its known repositories, the Pod creation will fail. To work with local images, set the\\nimagePullPolicy to Never.\\n\\nThe ports property specifies which container ports should be published on the Pod. The stockserv\", \"ice\\nimage runs the service on the standard HTTP port, so port 80 is published.\\n\\nThe resources section applies resource limits to the container running within the Pod. This is a good\\npractice because it prevents an individual Pod from consuming all the available CPU or memory ona\\nnode.\\n\\nNote\\n\\nASP.NET Core 7.0 has been optimized and tuned to run in resource-limited containers. The\\ndotnet/core/aspnet Docker image sets an environment variable to tell\", \" the dotnet runtime that it's in a\\ncontainer.\\n\\nThe StockData Service\\n\\nThe Service part of the YAML file declares the service that provides access to the Pods within the\\ncluster.\\n\\napiVersion: v1\\nkind: Service\\nmetadata:\\nname: stockdata\\nnamespace: stocks\\n\\nspec:\\nports:\\n- port: 80\\nselector:\\nrun: stockdata\\n\\nThe Service spec uses the selector property to match running Pods, in this case looking for Pods that\\nhave a label run: stockdata. The specified po\", \"rt on matching Pods is published by the named service.\\nOther Pods running in the stocks namespace can access HTTP on this service by using\\nhttp://stockdata as the address. Pods running in other namespaces can use the http://stockdata.stocks\\nhost name. You can control cross-namespace service access by using Network Policies.\\n\\nDeploy the StockData application\\n\\nUse kubectl to apply the stockdata.yml file and confirm that the Deployment and Service w\", \"ere\\ncreated:\\n\\n89 CHAPTER 7 | gRPC in production\\n> kubectl apply -f .\\\\stockdata.yml\\ndeployment.apps/stockdata created\\nservice/stockdata created\\n\\n> kubectl get deployment stockdata --namespace stocks\\n\\nNAME READY UP-TO-DATE AVAILABLE AGE\\nstockdata 1/1 1 1 17s\\n\\n> kubectl get service stockdata --namespace stocks\\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\\nstockdata ClusterIP 10.97.132.103 <none> 80/TCP 33s\\n\\nThe StockWeb application\\nThe stockweb.yml f\", \"ile declares the Deployment and Service for the MVC application.\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\nname: stockweb\\nnamespace: stocks\\nspec:\\nselector:\\nmatchLabels:\\nrun: stockweb\\nreplicas: 1\\ntemplate:\\nmetadata:\\nlabels:\\n\\nrun: stockweb\\n\\nspec:\\ncontainers:\\n- name: stockweb\\n\\nimage: stockweb:1.0.0\\n\\nimagePullPolicy: Never\\n\\nresources:\\nlimits:\\ncpu: 100m\\nmemory: 10QMi\\n\\nports:\\n\\n- containerPort: 80\\n\\nenv:\\n\\n- name: StockData_Address\\nvalue: \\\"http://st\", \"ockdata\\\"\\nname: DOTNET SYSTEM _NET_HTTP_SOCKETSHTTPHANDLER_HTTP2UNENCRYPTEDSUPPORT\\nvalue: \\\"true\\\"\\n\\napiVersion: v1\\nkind: Service\\nmetadata:\\n\\nname: stockweb\\n\\nnamespace: stocks\\nspec:\\n\\ntype: NodePort\\n\\nports:\\n\\n- port: 80\\n\\nselector:\\n\\nrun: stockweb\\n\\n90 CHAPTER 7 | gRPC in production\\nEnvironment variables\\n\\nThe env section of the Deployment object specifies environment variables to be set in the container\\nthat\\u2019s running the stockweb:1.0.0 images.\\n\\nThe StockD\", \"ata_Address environment variable will map to the StockData:Address configuration\\nsetting thanks to the EnvironmentVariables configuration provider. This setting uses double\\nunderscores between names to separate sections. The address uses the service name of the stockdata\\nService, which is running in the same Kubernetes namespace.\\n\\nThe DOTNET_SYSTEM_NET_HTTP_SOCKETSHTTPHANDLER_HTTP2UNENCRYPTEDSUPPORT\\nenvironment variable sets an AppContext switch \", \"that enables unencrypted HTTP/2 connections for\\nHttpClient. This environment variable does the same thing as setting the switch in code, as shown\\nhere:\\n\\nIf you use an environment variable for the switch, you can easily change the context depending on the\\ncontext in which the application is running.\\n\\nService types\\n\\nThe type: NodePort property is used to make the web application accessible from outside the cluster.\\nThis property type causes Kuberne\", \"tes to publish port 80 on the Service to an arbitrary port on the\\ncluster\\u2019s external network sockets. You can find the assigned port by using the kubectl get service\\ncommand.\\n\\nThe stockdata Service shouldn't be accessible from outside the cluster, so it uses the default type,\\nClusterIP.\\n\\nProduction systems will most likely use an integrated load balancer to expose public applications to\\nexternal consumers. Services exposed in this way should use \", \"the LoadBalancer type.\\n\\nFor more information on Service types, see the Kubernetes Publishing Services documentation.\\n\\nDeploy the StockWeb application\\n\\nUse kubectl to apply the stockweb.yml file and confirm that the Deployment and Service were created:\\n\\n> kubectl apply -f .\\\\stockweb.yml\\ndeployment.apps/stockweb created\\nservice/stockweb created\\n\\n> kubectl get deployment stockweb --namespace stocks\\nNAME READY UP-TO-DATE AVAILABLE AGE\\nstockweb 1/1 1 \", \"1 8S\\n\\n> kubectl get service stockweb --namespace stocks\\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\\nstockweb NodePort 10.106.141.5 <none> 80:32564/TCP 13s\\n\\nThe output of the get service command shows that the HTTP port has been published to port 32564\\non the external network. For Docker Desktop, this IP address will be localhost. You can access the\\napplication by browsing to http://localhost:32564.\\n\\n91 CHAPTER 7 | gRPC in production\\nTest the app\", \"lication\\n\\nThe StockWeb application displays a list of NASDAQ stocks that are retrieved from a simple request-\\nreply service. For this demonstration, each line also shows the unique ID of the Service instance that\\nreturned it.\\n\\nMR Home Page - StockWeb x +\\n\\u2014 \\u00a9) \\u00a9 localhost:32564 (Guest (R)\\nStockWeb Home Privacy\\nNASDAQ 100\\nSymbol Name Server\\nAAL American Airlines Group Inc 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495\\nAAPL Apple Inc 83345e3b-7b5e-4ad6-aa84-c\", \"2c0a1d83495\\nADBE Adobe Inc. 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495\\nADI Analog Devices Inc 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495\\nADP Automatic Data Processing Inc 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495\\nADSK Autodesk Inc 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495\\nALGN Align Technology Inc 83345e3b-7b5e-4ad6-aa84-c2c0a1d83495 .\\n\\u00bb\\n\\nIf the number of replicas of the stockdata Service were increased, you might expect the Server value\\nto change from line to line, b\", \"ut in fact all 100 records are always returned from the same instance. If\\nyou refresh the page every few seconds, the server ID remains the same. Why does this happen?\\nThere are two factors at play here.\\n\\nFirst, the Kubernetes Service discovery system uses round-robin load balancing by default. The first\\ntime the DNS server is queried, it will return the first matching IP address for the Service. The next\\ntime, it will return the next IP address \", \"in the list, and so on, until the end. At that point, it loops back to\\nthe start.\\n\\nSecond, the HttpClient used for the StockWeb application's gRPC client is created and managed by\\nthe ASP.NET Core HttpClientFactory, and a single instance of this client is used for every call to the\\npage. The client only does one DNS lookup, so all requests are routed to the same IP address. And\\nbecause the HttpClientHandler is cached for performance reasons, mult\", \"iple requests in quick\\nsuccession will all use the same IP address, until the cached DNS entry expires or the handler instance\\nis disposed for some reason.\\n\\nThe result is that by default requests to a gRPC Service aren't balanced across all instances of that\\nService in the cluster. Different consumers will use different instances, but that doesn't guarantee a\\ngood distribution of requests or a balanced use of resources.\\n\\nThe next chapter, Service\", \" meshes, will address this problem.\\n\\n92 CHAPTER 7 | gRPC in production\\nService meshes\\n\\nA service mesh is an infrastructure component that takes control of routing service requests within a\\nnetwork. Service meshes can handle all kinds of network-level concerns within a Kubernetes cluster,\\nincluding:\\n\\n. Service discovery\\n. Load balancing\\n\\n. Fault tolerance\\n\\n: Encryption\\n\\n\\u00b0 Monitoring\\n\\nKubernetes service meshes work by adding an extra container, cal\", \"led a sidecar proxy, to each pod\\nincluded in the mesh. The proxy takes over handling all inbound and outbound network requests. You\\ncan then keep the configuration and management of networking matters separate from the\\napplication containers. In many cases, this separation doesn't require any changes to the application\\ncode.\\n\\nIn the previous chapter's example, the gRPC requests from the web application were all routed to a\\nsingle instance of the \", \"gRPC service. This happens because the service's host name is resolved to an |P\\naddress, and that IP address is cached for the lifetime of the HttpClientHandler instance. It might be\\npossible to work around this behavior by handling DNS lookups manually or creating multiple clients.\\nBut this workaround would complicate the application code without adding any business or customer\\nvalue.\\n\\nWhen you use a service mesh, the requests from the applicati\", \"on container are sent to the sidecar\\nproxy. The sidecar proxy can then distribute them intelligently across all instances of the other service.\\nThe mesh can also:\\n\\n\\u00b0 Respond seamlessly to failures of individual instances of a service.\\n. Handle retry semantics for failed calls or timeouts.\\n. Reroute failed requests to an alternate instance without returning to the client application.\\n\\nThe following screenshot shows the StockWeb application running\", \" with the Linkerd service mesh.\\nThere are no changes to the application code, and the Docker image isn't being used. The only\\nchange required was the addition of an annotation to the deployment in the YAML files for the\\nstockdata and stockweb services.\\n\\n93 CHAPTER 7 | gRPC in production\\n\\u2014\\ni) localhost:3170C (_Guest |) ()\\n\\nStockWeb Home Privacy\\n\\nNASDAQ 100\\n\\nSymbol Name Server\\n\\nAAL American Airlines Group Inc 1a897dc1-f57c-4739-83cb-01001704fb3c\\n| \", \"AAPL Apple Inc 1a897dc1-f57c-4739-83cb-01001704fb3c\\n| ADBE Adobe Inc. 1a897dc1-f57c-4739-83cb-01001704fb3c\\n\\nADI Analog Devices Inc e61d578d-19af-491 1-aef0-1ab5a4284536\\n\\nADP Automatic Data Processing Inc 1a897dc1-f57c-4739-83cb-01001704fb3c\\n\\nADSK Autodesk Inc e\\u20ac61d578d-19af-491 1-aef0-1ab5a4284536\\n\\nALGN Align Technology Inc e\\u20ac61d578d-19af-491 1-aef0-1ab5a4284536\\n\\nYou can see from the Server column that the requests from the StockWeb application h\", \"ave been\\nrouted to both replicas of the StockData service, despite originating from a single HttpClient instance\\nin the application code. In fact, if you review the code, you'll see that all 100 requests to the StockData\\nservice are made simultaneously by using the same HttpClient instance. With the service mesh, those\\nrequests will be balanced across however many service instances are available.\\n\\nService meshes apply only to traffic within a clu\", \"ster. For external clients, see the next chapter, Load\\nBalancing.\\n\\nService mesh options\\n\\nThree general-purpose service mesh implementations are currently available for use with Kubernetes:\\nIstio, Linkerd, and Consul Connect. All three provide request routing/proxying, traffic encryption,\\nresilience, host-to-host authentication, and traffic control.\\n\\nChoosing a service mesh depends on multiple factors:\\n\\n. The organization's specific requirements a\", \"round costs, compliance, paid support plans, and so\\non.\\n\\n. The nature of the cluster, its size, the number of services deployed, and the volume of traffic\\nwithin the cluster network.\\n\\n\\u00b0 Ease of deploying and managing the mesh and using it with services.\\n\\nExample: Add Linkerd to a deployment\\n\\nIn this example, you'll learn how to use the Linkerd service mesh with the StockKube application from\\nthe previous section. To follow this example, you'll ne\", \"ed to install the Linkerd CLI. You can download\\n\\n94 CHAPTER 7 | gRPC in production\\nWindows binaries from the section that lists GitHub releases. Be sure to use the most recent stable\\nrelease and not one of the edge releases.\\n\\nWith the Linkerd CLI installed, follow the Getting Started instructions to install the Linkerd\\ncomponents on your Kubernetes cluster. The instructions are straightforward, and the installation\\nshould take only a couple of mi\", \"nutes on a local Kubernetes instance.\\n\\nAdd Linkerd to Kubernetes deployments\\n\\nThe Linkerd CLI provides an inject command to add the necessary sections and properties to\\nKubernetes files. You can run the command and write the output to a new file.\\n\\nlinkerd inject stockdata.yml > stockdata-with-mesh. yml\\nlinkerd inject stockweb.yml > stockweb-with-mesh.yml\\n\\nYou can inspect the new files to see what changes have been made. For deployment objects, a\\n\", \"metadata annotation is added to tell Linkerd to inject a sidecar proxy container into the pod when it's\\ncreated.\\n\\nIt's also possible to pipe the output of the linkerd inject command to kubectl directly. The following\\ncommands will work in PowerShell or any Linux shell.\\n\\nInspect services in the Linkerd dashboard\\nOpen the Linkerd dashboard by using the linkerd CLI.\\n\\nlinkerd dashboard\\n\\nThe dashboard provides detailed information about all services t\", \"hat are connected to the mesh.\\n\\n95 CHAPTER 7 | gRPC in production\\nLINKERD\\nstocks\\n\\nft Overview\\n\\nNamespace: stocks\\n\\nor\\n\\nTap\\n= _ Top\\n% Top Routes Deployments =\\nS Service Mesh Deployment 4S Meshed Success Rate RPS atenc P95 Latency P99 Latency Grafana\\n= Resources v\\nstockdata 2/2 _ _ _ _ _ +)\\nB Documentation stockweb 1/1 \\u2014 \\u2014 \\u2014 _\\u2014 _ 5G)\\nae Community\\nJoin the Mailing List _\\nPods =\\n\\u20ac} Join us on Slack\\n. Pod 4 vestec Rate nes Latency Latency Latency ne\\n\\u00a9 \", \"File anlssue\\nstockdata-558d4f55ff-7tcxv 1/1 _ _ \\u2014 _ 6\\nRunning Linkerd 2.5.0 (stable). tockdata-558d4f55\\u00a2f\\nP . stockdata- -\\nLinkerd is up to date. 85494 1/1 \\u2014 \\u2014 \\u2014 \\u2014 PG)\\nstockweb-6df4f86777-cpptv 1/1 _ \\u2014 \\u2014 ~ Gy\\n\\nIf you increase the number of replicas of the StockData gRPC service as shown in the following\\nexample, and refresh the StockWeb page in the browser, you should see a mix of IDs in the Server\\ncolumn. This mix indicates that all the availabl\", \"e instances are serving requests.\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n\\nname: stockdata\\nnamespace: stocks\\n\\nspec:\\n\\n96\\n\\nselector:\\nmatchLabels:\\n\\nrun: stockdata\\nreplicas: 2 # Increase the target number of instances\\ntemplate:\\nmetadata:\\nannotations:\\nlinkerd.io/inject: enabled\\n\\ncreationTimestamp: null\\nlabels:\\nrun: stockdata\\nspec:\\ncontainers:\\n- name: stockdata\\nimage: stockdata:1.0.0\\nimagePullPolicy: Never\\nresources:\\nlimits:\\ncpu: 100m\\nmemory: 1\", \"0Q@Mi\\nports:\\n- containerPort: 80\\n\\nCHAPTER 7 | gRPC in production\\nLoad balancing gRPC\\n\\nA typical deployment of a gRPC application includes a number of identical instances of the service,\\nproviding resilience and horizontal scalability. Load balancing distributes incoming requests across\\nthese instances to provide full usage of all available resources. To make this load balancing invisible to\\nthe client, it's common to use a proxy load balancer ser\", \"ver to handle requests from clients and route\\nthem to back-end instances.\\n\\nLoad balancers are classified according to the layer they operate on. Layer 4 load balancers work on\\nthe transport level, for example, with TCP sockets, connections, and packets. Layer 7 load balancers\\nwork at the application level, specifically handling HTTP/2 requests for gRPC applications.\\n\\nL4 load balancers\\n\\nAn L4 load balancer accepts a TCP connection request from a c\", \"lient, opens another connection to one\\nof the back-end instances, and copies data between the two connections with no real processing. L4\\noffers excellent performance and low latency, but with little control or intelligence. As long as the\\nclient keeps the connection open, all requests will be directed to the same back-end instance.\\n\\nAzure Load Balancer is an example of an L4 load balancer.\\n\\nL7 load balancers\\n\\nAn L7 load balancer parses incoming \", \"HTTP/2 requests and passes them on to back-end instances on a\\nrequest-by-request basis, no matter how long the connection is held by the client.\\n\\nExamples of L7 load balancers:\\n\\n\\u00b0 NGINX\\n\\u00b0 HAProxy\\n\\u00b0 Traefik\\n\\nAs a rule of thumb, L7 load balancers are the best choice for gRPC and other HTTP/2 applications (and\\nfor HTTP applications generally, in fact). L4 load balancers will work with gRPC applications, but\\nthey're primarily useful when low latency \", \"and low overhead are important.\\n\\nImportant\\n\\nAt the time of this writing, some L7 load balancers don\\u2019t support all the parts of the HTTP/2\\nspecification that are required by gRPC services, such as trailing headers.\\n\\nIf you're using TLS encryption, load balancers can terminate the TLS connection and pass unencrypted\\nrequests to the back-end application, or they can pass the encrypted request along. Either way, the\\nload balancer will need to be conf\", \"igured with the server's public and private key so it can decrypt\\nrequests for processing.\\n\\nSee to the documentation for your preferred load balancer to find out how to configure it to handle\\nHTTP/2 requests with your back-end services.\\n\\n97 CHAPTER 7 | gRPC in production\\nLoad balancing within Kubernetes\\n\\nSee the section on service meshes for a discussion of load balancing across internal services on\\nKubernetes.\\n\\nApplication Performance Management\", \"\\n\\nIn production environments like Kubernetes, it\\u2019s important to monitor applications to ensure they're\\nrunning optimally. Logging and metrics are important in particular. ASP.NET Core, including gRPC,\\nprovides built-in support for producing and managing log messages and metrics data, as well as\\ntracing data.\\n\\nThe difference between logging and metrics\\n\\nLogging |s concerned with text messages that record detailed information about things that have\", \"\\nhappened in the system. Log messages might include exception data, like stack traces, or structured\\ndata that provide context about the message. Logging output is commonly written to a searchable\\ntext store.\\n\\nMetrics refers to numeric data designed to be aggregated and presented by using charts and graphs\\nin a dashboard. The dashboard provides a view of the overall health and performance of an\\napplication. Metrics data can also be used to trigge\", \"r automated alerts when a threshold is exceeded.\\nHere are some examples of metrics data:\\n\\n\\u00b0 Time taken to process requests.\\n\\u00b0 The number of requests per second being handled by an instance of a service.\\n\\n. The number of failed requests on an instance.\\n\\nLogging tn ASP.NET Core gRPC\\n\\nASP.NET Core provides built-in support for logging, in the form of Microsoft.Extensions.Logging\\nNuGet package. The core parts of this library are included with the Web\", \" SDK, so there\\u2019s no need to\\ninstall it manually. By default, log messages are written to the standard output (the \\u201cconsole\\u201d) and to\\nany attached debugger. To write logs to persistent external data stores, you might need to import\\n\\noptional logging sink packages.\\n\\nThe ASP.NET Core gRPC framework writes detailed diagnostic logging messages to this logging\\nframework, so they can be processed and stored along with your application\\u2019s own messages.\\n\\nPr\", \"oduce log messages\\n\\nThe logging extension is automatically registered with ASP.NET Core\\u2019s dependency injection system,\\nso you can specify loggers as a constructor parameter on gRPC service types.\\n\\npublic class StockData : Stocks.StocksBase\\n{\\n\\nprivate readonly ILogger<StockData> _logger;\\npublic StockData(ILogger<StockData> logger)\\n\\n98 CHAPTER 7 | gRPC in production\\n_logger = logger;\\n\\nMany log messages, such as requests and exceptions, are provided\", \" by the ASP.NET Core and gRPC\\nframework components. Add your own log messages to provide detail and context about application\\nlogic, rather than lower-level concerns.\\n\\nFor more information about writing log messages and available logging sinks and targets, see\\nLogging in .NET Core and ASP.NET Core.\\n\\nMetrics in ASP.NET Core gRPC\\n\\nThe .NET Core runtime provides a set of components for emitting and observing metrics. These\\ninclude APIs such as the E\", \"ventSource and EventCounter classes. These APIs can emit basic numeric\\ndata that can be consumed by external processes, like the dotnet-counters global tool, or Event\\nTracing for Windows. For more information about using EventCounter in your own code, see\\nEventCounter introduction.\\n\\nFor more advanced metrics and for writing metric data to a wider range of data stores, you might try\\nan open-source project called App Metrics. This suite of librarie\", \"s provides an extensive set of types to\\ninstrument your code. It also offers packages to write metrics to different kinds of targets that include\\ntime-series databases, such as Prometheus and InfluxDB, and Application Insights. The\\nApp.Metrics.AspNetCore.Mvc NuGet package even adds a comprehensive set of basic metrics that are\\nautomatically generated via integration with the ASP.NET Core framework. The project website\\nprovides templates for displ\", \"aying those metrics with the Grafana visualization platform.\\n\\nProduce metrics\\n\\nMost metrics platforms support the following types:\\n\\nCounter Tracks how often something happens, such as\\nrequests and errors.\\n\\nGauge Records a single value that changes over time,\\nsuch as active connections.\\n\\nHistogram Measures a distribution of values across\\n\\narbitrary limits. For example, a histogram can\\ntrack dataset size, counting how many\\ncontained <10 records, ho\", \"w many contained\\n11-100 records, how many contained 101-1000\\nrecords, and how many contained > 1000\\nrecords.\\n\\nMeter Measures the rate at which an event occurs in\\nvarious time spans.\\n\\n99 CHAPTER 7 | gRPC in production\\nTimer Tracks the duration of events and the rate at\\nwhich it occurs, stored as a histogram.\\n\\nBy using App Metrics, an |Metrics interface can be obtained via dependency injection, and used to\\nrecord any of these metrics for a gRPC ser\", \"vice. The following example shows how to count the\\nnumber of Get requests made over time:\\n\\npublic class StockData : Stocks.StocksBase\\n{\\n\\nprivate static readonly CounterOptions GetRequestCounter = new CounterOptions\\n\\n{\\nName = \\\"StockData_Get_ Requests\\\",\\n\\nMeasurementUnit = Unit.Calls\\n\\nIre\\n\\nprivate readonly IStockRepository _repository;\\nprivate readonly IMetrics _metrics;\\n\\npublic StockData(IStockRepository repository, IMetrics metrics)\\n{\\n\\n_repository\", \" = repository;\\n_metrics = metrics;\\n\\n}\\n\\npublic override async Task<GetResponse> Get(GetRequest request, ServerCallContext\\ncontext )\\n\\n{\\n\\n_metrics.Measure.Counter. Increment (GetRequestCounter ) ;\\n\\n// Serve request...\\n\\nStore and visualize metrics data\\n\\nThe best way to store metrics data is in a time-series database, a specialized data store designed to\\nrecord numerical data series marked with timestamps. The most popular of these databases are\\nProme\", \"theus and InfluxDB. Microsoft Azure also provides dedicated metrics storage through the Azure\\nMonitor service.\\n\\nThe current go-to solution for visualizing metrics data is Grafana, which works with a wide range of\\nstorage providers. The following image shows an example Grafana dashboard that displays metrics\\n\\nfrom the Linkerd service mesh running the StockData sample:\\n\\n100 CHAPTER 7 | gRPC in production\\n83 Linkerd Deployment -\\n\\nfi) deploy/stockdat\", \"a\\n\\nSUCCESS RATE REQUEST RATE\\n\\n0 RPS\\n\\nINBOUND TRAFFIC\\n\\nREQUEST RATE\\n\\nInbound TCP Metrics\\n\\nINBOUND DEPLOYMENTS\\n\\ndeploy/stockweb\\n\\nOUTBOUND TRAFFIC\\n\\nREQUEST RATE\\n\\nThe numerical nature of metrics data means that it's ideally suited to drive alerting systems, notifying\\ndevelopers or support engineers when a value falls outside of some defined tolerance. The platforms\\nalready mentioned all provide support for alerting via a range of options, including e\", \"mails, text\\nmessages, or in-dashboard visualizations.\\n\\nDistributed tracing is a relatively recent development in monitoring, which has arisen from the\\nincreasing use of microservices and distributed architectures. A single request from a client browser,\\napplication, or device can be broken down into many steps and sub-requests, and involve the use of\\nmany services across a network. This activity makes it difficult to correlate log messages and me\", \"trics\\nwith the specific request that triggered them. Distributed tracing applies identifiers to requests, and\\nallows logs and metrics to be correlated with a particular operation. This tracing is similar to\\n\\n, but it's applied across multiple platforms.\\n\\nDistributed tracing has grown quickly in popularity and is beginning to standardize. The Cloud Native\\nComputing Foundation created the , attempting to provide vendor-neutral\\nlibraries for working\", \" with back ends like and . At the same time, Google created the\\n\\nto address the same set of problems. These two projects are merging into a new\\nproject, , which aims to be the industry standard of the future.\\n\\nDistributed tracing is based on the concept of spans: named, timed operations that are part of a single\\ntrace, which can involve processing on multiple nodes of a system. When a new operation Is initiated,\\na trace is created with a unique i\", \"dentifier. For each sub-operation, a span is created with its own\\nidentifier and trace identifier. As the request passes around the system, various components can\\ncreate child spans that include the identifier of their parent. A span has a context, which contains the\\ntrace and span identifiers, as well as useful data in the form of key and value pairs (called baggage).\\n\\nDistributed tracing with DiagnosticSource\\n\\n.NET has an internal module that m\", \"aps well to distributed traces and spans: DiagnosticSource. As well\\nas providing a simple way to produce and consume diagnostics within a process, the\\nDiagnosticSource module has the concept of an activity. An activity is effectively an implementation of\\na distributed trace, or a span within a trace. The internals of the module take care of parent/child\\nactivities, including allocating identifiers. For more information about using the Activity ty\", \"pe, see the\\n\\nActivity User Guide on GitHub.\\n\\nBecause DiagnosticSource is a part of the core framework and later, it\\u2019s supported by several core\\ncomponents. These include HttpClient, Entity Framework Core, and ASP.NET Core, including explicit\\nsupport in the gRPC framework. When ASP.NET Core receives a request, it checks for a pair of HTTP\\nheaders matching the W3C Trace Context standard. If the headers are found, an activity is started by\\nusing the\", \" identity values and context from the headers. If no headers are found, an activity is started\\nwith generated identity values that match the standard format. Any diagnostics generated by the\\nframework or by application code during the lifetime of this activity can be tagged with the trace and\\nSpan identifiers. The HttpClient support extends this functionality further by checking for a current\\nactivity on every request, and automatically adding th\", \"e trace headers to the outgoing request.\\n\\nThe ASP.NET Core gRPC client and server libraries include explicit support for DiagnosticSource and\\nActivity, and create activities and apply and use header information automatically.\\n\\nNote\\n\\nAll of this happens only if a listener is consuming the diagnostic information. If there's no listener, no\\ndiagnostics are written and no activities are created.\\n\\nAdd your own DiagnosticSource and Activity\\n\\nTo add you\", \"r own diagnostics or create explicit spans within your application code, see the\\nDiagnosticSource User Guide and Activity User Guide.\\n\\nStore distributed trace data\\n\\nAt the time of writing, the OpenTelemetry project is still in the early stages, and only alpha-quality\\npackages are available for .NET applications. The OpenTracing project currently offers more mature\\nlibraries.\\n\\nThe Opentracing API is described in the following section. If you want \", \"to use the OpenTelemetry API\\nin your application instead, refer to the OpenTelemetry .NET SDK repository on GitHub.\\n\\nUse the OpenTracing package to store distributed trace data\\n\\nThe OpentTracing NuGet package supports all OpenTracing-compliant back ends (which can be used\\nindependently of DiagnosticSource). There\\u2019s an additional package from the OpenTracing API\\n\\n102 CHAPTER 7 | gRPC in production\\nContributions project, OQpenTracing.Contrib.NetCor\", \"e. This package adds a DiagnosticSource listener,\\nand writes events and activities to a back end automatically. Enabling this package is as simple as\\ninstalling it from NuGet and adding it as a service in your Program class.\\n\\n//\\n\\nbuilder.Services.AddOpenTracing() ;\\n\\n//\\n\\nThe OpentTracing package Is an abstraction layer, and as such it requires implementation specific to\\nthe back end. OpenTracing API implementations are available for the following \", \"open source back\\nends.\\n\\nee\\n\\nElastic APM Elastic. Apm.NetCoreAll elastic.co/products/apm\\n\\nFor more information on the OpentTracing API for .NET, see the OpenTracing for C# and the\\nOpentTracing Contrib C#/.NET Core repositories on GitHub.\\n\\n103 CHAPTER 7 | gRPC in production\\nCHAPTER\\n\\nAppendix A - Transactions\\n\\nWindows Communication Foundation (WCF) supports distributed transactions, allowing you to\\nperform atomic operations across multiple services.\", \" This functionality is based on the Microsoft\\nDistributed Transaction Coordinator.\\n\\nIn the newer microservices landscape, this type of automated distributed transaction processing isn\\u2019t\\npossible. There are too many different technologies involved, including relational databases, NoSQL\\ndata stores, and messaging systems. There might also be a mix of operating systems, programming\\nlanguages, and frameworks in use in a single environment.\\n\\nWCF distr\", \"ibuted transaction is an implementation of what is known as a two-phase commit (2PC). You\\ncan implement 2PC transactions manually by coordinating messages across services, creating open\\ntransactions within each service, and sending commit or rollback messages, depending upon success\\nor failure. However, the complexity involved in managing 2PC can increase exponentially as systems\\nevolve. Open transactions hold database locks that can negatively a\", \"ffect performance, or, worse, cause\\ncross-service deadlocks.\\n\\nIf possible, it's best to avoid distributed transactions altogether. If two items of data are so linked as to\\nrequire atomic updates, consider handling them both with the same service. Apply those atomic\\nchanges by using a single request or message to that service.\\n\\nIf that isn't possible, then one alternative is to use the Saga pattern. In a saga, updates are processed\\nsequentially; a\", \"s each update succeeds, the next one is triggered. These triggers can be propagated\\nfrom service to service, or managed by a saga coordinator or orchestrator. If an update fails at any\\npoint during the process, the services that have already completed their updates apply specific logic\\nto reverse them.\\n\\nAnother option is to use Domain Driven Design (DDD) and Command/Query Responsibility\\nSegregation (CQRS), as described in the .NET Microservices e\", \"-book. In particular, using domain events\\nor event sourcing can help to ensure that updates are consistently, if not immediately, applied.\\n\\n104 CHAPTER 8 | Appendix A - Transactions\\n\"]"