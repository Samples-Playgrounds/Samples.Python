"[\" \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nEDITION v7.0 - Updated to ASP.NET Core 7\", \".0 \\nRefer changelog for the book updates and community contributions. \\nThis guide is an introduction\", \" to developing microservices-based applications and managing them \\nusing containers. It discusses ar\", \"chitectural design and implementation approaches using .NET and \\nDocker containers. \\nTo make it easi\", \"er to get started, the guide focuses on a reference containerized and microservice-\\nbased applicatio\", \"n that you can explore. The reference application is available at the \\neShopOnContainers GitHub repo\", \". \\nAction links \\n\\u2022 \\nThis e-book is also available in a PDF format (English version only) Download \\n\\u2022\", \" \\nClone/Fork the reference application eShopOnContainers on GitHub \\n\\u2022 \\nWatch the introductory video \", \"\\n\\u2022 \\nGet to know the Microservices Architecture right away \\nIntroduction \\nEnterprises are increasingl\", \"y realizing cost savings, solving deployment problems, and improving \\nDevOps and production operatio\", \"ns by using containers. Microsoft has been releasing container \\ninnovations for Windows and Linux by\", \" creating products like Azure Kubernetes Service and Azure \\nService Fabric, and by partnering with i\", \"ndustry leaders like Docker, Mesosphere, and Kubernetes. \\nThese products deliver container solutions\", \" that help companies build and deploy applications at cloud \\nspeed and scale, whatever their choice \", \"of platform or tools. \\nDocker is becoming the de facto standard in the container industry, supported\", \" by the most significant \\nvendors in the Windows and Linux ecosystems. (Microsoft is one of the main\", \" cloud vendors \\nsupporting Docker). In the future, Docker will probably be ubiquitous in any datacen\", \"ter in the cloud or \\non-premises. \\nIn addition, the microservices architecture is emerging as an imp\", \"ortant approach for distributed \\nmission-critical applications. In a microservice-based architecture\", \", the application is built on a \\ncollection of services that can be developed, tested, deployed, and\", \" versioned independently. \\nAbout this guide \\nThis guide is an introduction to developing microservic\", \"es-based applications and managing them \\nusing containers. It discusses architectural design and imp\", \"lementation approaches using .NET and \\nDocker containers. To make it easier to get started with cont\", \"ainers and microservices, the guide \\nfocuses on a reference containerized and microservice-based app\", \"lication that you can explore. The \\nsample application is available at the eShopOnContainers GitHub \", \"repo. \\n \\nThis guide provides foundational development and architectural guidance primarily at a deve\", \"lopment \\nenvironment level with a focus on two technologies: Docker and .NET. Our intention is that \", \"you read \\nthis guide when thinking about your application design without focusing on the infrastruct\", \"ure (cloud \\nor on-premises) of your production environment. You will make decisions about your infra\", \"structure \\nlater, when you create your production-ready applications. Therefore, this guide is inten\", \"ded to be \\ninfrastructure agnostic and more development-environment-centric. \\nAfter you have studied\", \" this guide, your next step would be to learn about production-ready \\nmicroservices on Microsoft Azu\", \"re. \\nVersion \\nThis guide has been revised to cover .NET 7 version along with many additional updates\", \" related to \\nthe same \\u201cwave\\u201d of technologies (that is, Azure and additional third-party technologies\", \") coinciding in \\ntime with the .NET 7 release. That\\u2019s why the book version has also been updated to \", \"version 7.0. \\nWhat this guide does not cover \\nThis guide does not focus on the application lifecycle\", \", DevOps, CI/CD pipelines, or team work. The \\ncomplementary guide Containerized Docker Application L\", \"ifecycle with Microsoft Platform and Tools \\nfocuses on that subject. The current guide also does not\", \" provide implementation details on Azure \\ninfrastructure, such as information on specific orchestrat\", \"ors. \\nAdditional resources \\n\\u2022 \\nContainerized Docker Application Lifecycle with Microsoft Platform an\", \"d Tools (downloadable \\ne-book) \\nhttps://aka.ms/dockerlifecycleebook \\nWho should use this guide \\nWe w\", \"rote this guide for developers and solution architects who are new to Docker-based application \\ndeve\", \"lopment and to microservices-based architecture. This guide is for you if you want to learn how \\nto \", \"architect, design, and implement proof-of-concept applications with Microsoft development \\ntechnolog\", \"ies (with special focus on .NET) and with Docker containers. \\nYou will also find this guide useful i\", \"f you are a technical decision maker, such as an enterprise \\narchitect, who wants an architecture an\", \"d technology overview before you decide on what approach to \\nselect for new and modern distributed a\", \"pplications. \\nHow to use this guide \\nThe first part of this guide introduces Docker containers, disc\", \"usses how to choose between .NET 7 and \\nthe .NET Framework as a development framework, and provides \", \"an overview of microservices. This \\ncontent is for architects and technical decision makers who want\", \" an overview but don\\u2019t need to focus \\non code implementation details. \\n \\nThe second part of the guid\", \"e starts with the Development process for Docker based applications \\nsection. It focuses on the deve\", \"lopment and microservice patterns for implementing applications using \\n.NET and Docker. This section\", \" will be of most interest to developers and architects who want to focus \\non code and on patterns an\", \"d implementation details. \\nRelated microservice and container-based reference \\napplication: eShopOnC\", \"ontainers \\nThe eShopOnContainers application is an open-source reference app for .NET and microservi\", \"ces that \\nis designed to be deployed using Docker containers. The application consists of multiple s\", \"ubsystems, \\nincluding several e-store UI front-ends (a Web MVC app, a Web SPA, and a native mobile a\", \"pp). It also \\nincludes the back-end microservices and containers for all required server-side operat\", \"ions. \\nThe purpose of the application is to showcase architectural patterns. IT IS NOT A PRODUCTION-\", \"\\nREADY TEMPLATE to start real-world applications. In fact, the application is in a permanent beta \\ns\", \"tate, as it\\u2019s also used to test new potentially interesting technologies as they show up. \\nCredits \\n\", \"Co-Authors: \\nCesar de la Torre, Sr. PM, .NET product team, Microsoft Corp. \\nBill Wagner, Sr. Content\", \" Developer, C+E, Microsoft Corp. \\nMike Rousos, Principal Software Engineer, DevDiv CAT team, Microso\", \"ft \\nEditors: \\nMike Pope \\nSteve Hoag \\nParticipants and reviewers: \\nJeffrey Richter, Partner Software \", \"Eng, Azure team, Microsoft \\nJimmy Bogard, Chief Architect at Headspring \\nUdi Dahan, Founder & CEO, P\", \"articular Software \\nJimmy Nilsson, Co-founder and CEO of Factor10 \\nGlenn Condron, Sr. Program Manage\", \"r, ASP.NET team \\nMark Fussell, Principal PM Lead, Azure Service Fabric team, Microsoft \\nDiego Vega, \", \"PM Lead, Entity Framework team, Microsoft \\nBarry Dorrans, Sr. Security Program Manager \\nRowan Miller\", \", Sr. Program Manager, Microsoft \\n \\nAnkit Asthana, Principal PM Manager, .NET team, Microsoft \\nScott\", \" Hunter, Partner Director PM, .NET team, Microsoft \\nNish Anil, Sr. Program Manager, .NET team, Micro\", \"soft \\nDylan Reisenberger, Architect and Dev Lead at Polly \\nSteve \\u201cardalis\\u201d Smith - Software Architec\", \"t and Trainer - Ardalis.com \\nIan Cooper, Coding Architect at Brighter \\nUnai Zorrilla, Architect and \", \"Dev Lead at Plain Concepts \\nEduard Tomas, Dev Lead at Plain Concepts \\nRamon Tomas, Developer at Plai\", \"n Concepts \\nDavid Sanz, Developer at Plain Concepts \\nJavier Valero, Chief Operating Officer at Grupo\", \" Solutio \\nPierre Millet, Sr. Consultant, Microsoft \\nMichael Friis, Product Manager, Docker Inc \\nChar\", \"les Lowell, Software Engineer, VS CAT team, Microsoft \\nMiguel Veloso, Software Development Engineer \", \"at Plain Concepts \\nSumit Ghosh, Principal Consultant at Neudesic \\nCopyright \\nPUBLISHED BY \\nMicrosoft\", \" Developer Division, .NET and Visual Studio product teams \\nA division of Microsoft Corporation \\nOne \", \"Microsoft Way \\nRedmond, Washington 98052-6399 \\nCopyright \\u00a9 2023 by Microsoft Corporation \\nAll rights\", \" reserved. No part of the contents of this book may be reproduced or transmitted in any \\nform or by \", \"any means without the written permission of the publisher. \\nThis book is provided \\u201cas-is\\u201d and expres\", \"ses the author\\u2019s views and opinions. The views, opinions and \\ninformation expressed in this book, in\", \"cluding URL and other Internet website references, may change \\nwithout notice. \\nSome examples depict\", \"ed herein are provided for illustration only and are fictitious. No real association \\nor connection \", \"is intended or should be inferred. \\n \\nMicrosoft and the trademarks listed at https://www.microsoft.c\", \"om on the \\u201cTrademarks\\u201d webpage are \\ntrademarks of the Microsoft group of companies. \\nMac and macOS a\", \"re trademarks of Apple Inc. \\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by\", \" permission. \\nAll other marks and logos are property of their respective owners. \\n \\ni \\nContents \\n \\nC\", \"ontents \\nIntroduction to Containers and Docker .....................................................\", \"........................... 1 \\nWhat is Docker? .....................................................\", \"....................................................................................................\", \"............... 2 \\nComparing Docker containers with virtual machines ...............................\", \"............................................................ 3 \\nA simple analogy ...................\", \"....................................................................................................\", \".......................................... 4 \\nDocker terminology ...................................\", \"....................................................................................................\", \"......................... 5 \\nDocker containers, images, and registries .............................\", \"........................................................................................ 7 \\nChoosing\", \" Between .NET and .NET Framework for Docker Containers .............................. 9 \\nGeneral gui\", \"dance ..............................................................................................\", \"....................................................................... 9 \\nWhen to choose .NET for D\", \"ocker containers ...................................................................................\", \".......................... 10 \\nDeveloping and deploying cross platform .............................\", \"............................................................................... 10 \\nUsing containers\", \" for new (\\u201cgreen-field\\u201d) projects ..................................................................\", \"............................. 11 \\nCreate and deploy microservices on containers ....................\", \".............................................................................. 11 \\nDeploying high de\", \"nsity in scalable systems ..........................................................................\", \"................................ 11 \\nWhen to choose .NET Framework for Docker containers ...........\", \".......................................................................... 12 \\nMigrating existing ap\", \"plications directly to a Windows Server container ..................................................\", \" 12 \\nUsing third-party .NET libraries or NuGet packages not available for .NET 7 ...................\", \"...................... 12 \\nUsing .NET technologies not available for .NET 7 ........................\", \"....................................................................... 12 \\nUsing a platform or API \", \"that doesn\\u2019t support .NET 7 ........................................................................\", \"................ 13 \\nPorting existing ASP.NET application to .NET 7 ................................\", \"................................................................... 13 \\nDecision table: .NET impleme\", \"ntations to use for Docker .........................................................................\", \"............ 13 \\nWhat OS to target with .NET containers ............................................\", \".......................................................................... 14 \\nOfficial .NET Docker \", \"images .............................................................................................\", \"................................................ 16 \\n.NET and Docker image optimizations for develop\", \"ment versus production ........................................... 16 \\nArchitecting container and mi\", \"croservice-based applications .......................................... 18 \\nContainer design princi\", \"ples ...............................................................................................\", \"............................................... 18 \\nContainerizing monolithic applications .........\", \"....................................................................................................\", \".......... 19 \\nDeploying a monolithic application as a container ...................................\", \"......................................................... 21 \\nPublishing a single-container-based ap\", \"plication to Azure App Service .................................................... 21 \\n \\nii \\nConten\", \"ts \\nManage state and data in Docker applications ...................................................\", \"..................................................... 22 \\nService-oriented architecture ............\", \"....................................................................................................\", \"........................... 25 \\nMicroservices architecture .........................................\", \"....................................................................................................\", \".... 25 \\nAdditional resources ......................................................................\", \"................................................................................. 27 \\nData sovereign\", \"ty per microservice ................................................................................\", \"................................................ 27 \\nThe relationship between microservices and the \", \"Bounded Context pattern ........................................... 29 \\nLogical architecture versus \", \"physical architecture ..............................................................................\", \"....................... 30 \\nChallenges and solutions for distributed data management ...............\", \"............................................................... 31 \\nChallenge #1: How to define the \", \"boundaries of each microservice ............................................................ 31 \\nCha\", \"llenge #2: How to create queries that retrieve data from several microservices .....................\", \"....... 32 \\nChallenge #3: How to achieve consistency across multiple microservices .................\", \".............................. 33 \\nChallenge #4: How to design communication across microservice bou\", \"ndaries .................................... 35 \\nAdditional resources ..............................\", \"....................................................................................................\", \"..................... 36 \\nIdentify domain-model boundaries for each microservice ...................\", \"............................................................... 36 \\nThe API gateway pattern versus t\", \"he Direct client-to-microservice communication .................................. 40 \\nDirect client-\", \"to-microservice communication ......................................................................\", \"................................ 40 \\nWhy consider API Gateways instead of direct client-to-microserv\", \"ice communication ....................... 41 \\nWhat is the API Gateway pattern? .....................\", \"....................................................................................................\", \".... 42 \\nMain features in the API Gateway pattern ..................................................\", \"........................................................... 44 \\nUsing products with API Gateway feat\", \"ures ...............................................................................................\", \"............. 45 \\nDrawbacks of the API Gateway pattern .............................................\", \"...................................................................... 47 \\nAdditional resources ....\", \"....................................................................................................\", \"............................................... 48 \\nCommunication in a microservice architecture ...\", \"....................................................................................................\", \". 48 \\nCommunication types ..........................................................................\", \".......................................................................... 49 \\nAsynchronous microser\", \"vice integration enforces microservice\\u2019s autonomy ........................................... 50 \\nCo\", \"mmunication styles .................................................................................\", \"................................................................... 52 \\nAsynchronous message-based c\", \"ommunication .......................................................................................\", \"................ 54 \\nSingle-receiver message-based communication ...................................\", \"............................................................. 55 \\nMultiple-receivers message-based c\", \"ommunication .......................................................................................\", \"... 56 \\nAsynchronous event-driven communication ....................................................\", \".................................................... 56 \\nA note about messaging technologies for pro\", \"duction systems ................................................................... 57 \\nResiliently \", \"publishing to the event bus ........................................................................\", \"........................................... 58 \\n \\niii \\nContents \\nAdditional resources ..............\", \"....................................................................................................\", \"..................................... 58 \\nCreating, evolving, and versioning microservice APIs and c\", \"ontracts ............................................................... 59 \\nAdditional resources ..\", \"....................................................................................................\", \"................................................. 59 \\nMicroservices addressability and the service r\", \"egistry ............................................................................................\", \" 60 \\nAdditional resources ..........................................................................\", \"............................................................................. 60 \\nCreating composite\", \" UI based on microservices .........................................................................\", \".............................. 60 \\nAdditional resources ............................................\", \"....................................................................................................\", \"....... 62 \\nResiliency and high availability in microservices ......................................\", \"................................................................ 63 \\nHealth management and diagnosti\", \"cs in microservices ................................................................................\", \".... 63 \\nAdditional resources ......................................................................\", \"................................................................................. 65 \\nOrchestrate mi\", \"croservices and multi-container applications for high scalability and availability ....... 66 \\nSoftw\", \"are platforms for container clustering, orchestration, and scheduling ..............................\", \"............. 68 \\nUsing container-based orchestrators in Microsoft Azure ...........................\", \"..................................................... 68 \\nUsing Azure Kubernetes Service ...........\", \"....................................................................................................\", \"................. 69 \\nDevelopment environment for Kubernetes .......................................\", \".................................................................... 70 \\nGetting started with Azure \", \"Kubernetes Service (AKS) ...........................................................................\", \"............ 70 \\nDeploy with Helm charts into Kubernetes clusters ..................................\", \"........................................................... 71 \\nAdditional resources ...............\", \"....................................................................................................\", \".................................... 71 \\nDevelopment process for Docker-based applications .........\", \".............................................. 72 \\nDevelopment environment for Docker apps .........\", \"....................................................................................................\", \" 72 \\nDevelopment tool choices: IDE or editor .......................................................\", \"......................................................... 72 \\nAdditional resources .................\", \"....................................................................................................\", \".................................. 73 \\n.NET languages and frameworks for Docker containers .........\", \".............................................................................. 73 \\nDevelopment workf\", \"low for Docker apps ................................................................................\", \"..................................... 73 \\nWorkflow for developing Docker container-based application\", \"s .................................................................. 73 \\nStep 1. Start coding and cr\", \"eate your initial application or service baseline ............................................. 75 \\n\", \"Step 2. Create a Dockerfile related to an existing .NET base image .................................\", \"........................... 76 \\nStep 3. Create your custom Docker images and embed your application \", \"or service in them .......... 83 \\nStep 4. Define your services in docker-compose.yml when building a\", \" multi-container Docker \\napplication ...............................................................\", \"....................................................................................................\", \"....... 84 \\nStep 5. Build and run your Docker application ..........................................\", \".......................................................... 87 \\nStep 6. Test your Docker application \", \"using your local Docker host ............................................................ 89 \\n \\niv \\n\", \"Contents \\nSimplified workflow when developing containers with Visual Studio ........................\", \"................................ 90 \\nUsing PowerShell commands in a Dockerfile to set up Windows Con\", \"tainers ......................................... 91 \\nDesigning and Developing Multi-Container and M\", \"icroservice-Based .NET Applications\\n ...............................................................\", \".................................................................................. 93 \\nDesign a micr\", \"oservice-oriented application ......................................................................\", \"........................................ 93 \\nApplication specifications ............................\", \"....................................................................................................\", \"............. 93 \\nDevelopment team context .........................................................\", \"................................................................................ 94 \\nChoosing an arc\", \"hitecture ..........................................................................................\", \".................................................... 94 \\nBenefits of a microservice-based solution .\", \"....................................................................................................\", \"........ 97 \\nDownsides of a microservice-based solution ............................................\", \"........................................................... 98 \\nExternal versus internal architectur\", \"e and design patterns...............................................................................\", \" 99 \\nThe new world: multiple architectural patterns and polyglot microservices .....................\", \"..................... 100 \\nCreating a simple data-driven CRUD microservice .........................\", \"...................................................................... 102 \\nDesigning a simple CRUD \", \"microservice .......................................................................................\", \"......................... 102 \\nImplementing a simple CRUD microservice with ASP.NET Core ...........\", \"...................................................... 103 \\nThe DB connection string and environment\", \" variables used by Docker containers ............................. 109 \\nGenerating Swagger descripti\", \"on metadata from your ASP.NET Core Web API ................................... 111 \\nDefining your mu\", \"lti-container application with docker-compose.yml ..................................................\", \"....... 116 \\nUse a database server running as a container ..........................................\", \".............................................................. 127 \\nSQL Server running as a containe\", \"r with a microservice-related database .............................................. 128 \\nSeeding w\", \"ith test data on Web application startup ...........................................................\", \".............................. 129 \\nEF Core InMemory database versus SQL Server running as a contain\", \"er ................................................. 132 \\nUsing a Redis cache service running in a c\", \"ontainer ......................................................................................... 1\", \"32 \\nImplementing event-based communication between microservices (integration events) ..............\", \"..... 133 \\nUsing message brokers and service buses for production systems ..........................\", \"................................ 134 \\nIntegration events ...........................................\", \"....................................................................................................\", \"........... 135 \\nThe event bus .....................................................................\", \"............................................................................................. 136 \\nA\", \"dditional resources ................................................................................\", \"..................................................................... 138 \\nImplementing an event bus\", \" with RabbitMQ for the development or test environment ....................... 138 \\nImplementing a s\", \"imple publish method with RabbitMQ .................................................................\", \".............. 139 \\nImplementing the subscription code with the RabbitMQ API .......................\", \".............................................. 140 \\nAdditional resources ...........................\", \"....................................................................................................\", \"...................... 141 \\n \\nv \\nContents \\nSubscribing to events ...................................\", \"....................................................................................................\", \"................. 141 \\nPublishing events through the event bus......................................\", \"....................................................................... 142 \\nIdempotency in update m\", \"essage events ......................................................................................\", \"........................ 149 \\nDeduplicating integration event messages .............................\", \"............................................................................ 150 \\nTesting ASP.NET Co\", \"re services and web apps ...........................................................................\", \"............................. 152 \\nTesting in eShopOnContainers ....................................\", \"............................................................................................. 155 \\nI\", \"mplement background tasks in microservices with IHostedService and the BackgroundService class\\n ....\", \"....................................................................................................\", \"............................................................................................ 157 \\nRe\", \"gistering hosted services in your WebHost or Host ..................................................\", \"................................. 159 \\nThe IHostedService interface ................................\", \"....................................................................................................\", \". 159 \\nImplementing IHostedService with a custom hosted service class deriving from the \\nBackgroundS\", \"ervice base class...................................................................................\", \"................................................ 160 \\nAdditional resources .........................\", \"....................................................................................................\", \"........................ 163 \\nImplement API Gateways with Ocelot ...................................\", \"..................................................................................... 163 \\nArchitect\", \" and design your API Gateways ......................................................................\", \"........................................ 163 \\nImplementing your API Gateways with Ocelot ...........\", \"....................................................................................... 168 \\nUsing K\", \"ubernetes Ingress plus Ocelot API Gateways .........................................................\", \"............................. 180 \\nAdditional cross-cutting features in an Ocelot API Gateway ......\", \"................................................................. 181 \\nTackle Business Complexity in\", \" a Microservice with DDD and CQRS Patterns .............. 182 \\nApply simplified CQRS and DDD pattern\", \"s in a microservice............................................................................. 184\", \" \\nAdditional resources .............................................................................\", \"........................................................................ 186 \\nApply CQRS and CQS app\", \"roaches in a DDD microservice in eShopOnContainers ................................. 186 \\nCQRS and D\", \"DD patterns are not top-level architectures ........................................................\", \"....................... 187 \\nImplement reads/queries in a CQRS microservice ........................\", \"........................................................................ 188 \\nUse ViewModels specifi\", \"cally made for client apps, independent from domain model constraints\\n .............................\", \"....................................................................................................\", \".............................................................. 189 \\nUse Dapper as a micro ORM to per\", \"form queries .......................................................................................\", \"....... 189 \\nDynamic versus static ViewModels ......................................................\", \"................................................................... 190 \\nAdditional resources ......\", \"....................................................................................................\", \"........................................... 193 \\nDesign a DDD-oriented microservice ................\", \"....................................................................................................\", \"..... 194 \\nKeep the microservice context boundaries relatively small ...............................\", \"........................................... 194 \\nLayers in DDD microservices .......................\", \"....................................................................................................\", \".......... 195 \\n \\nvi \\nContents \\nDesign a microservice domain model .................................\", \"....................................................................................... 199 \\nThe Dom\", \"ain Entity pattern .................................................................................\", \"........................................................ 199 \\nImplement a microservice domain model \", \"with .NET ..........................................................................................\", \".. 204 \\nDomain model structure in a custom .NET Standard Library ...................................\", \".................................... 204 \\nStructure aggregates in a custom .NET Standard library ...\", \"............................................................................ 205 \\nImplement domain e\", \"ntities as POCO classes ............................................................................\", \"......................... 206 \\nEncapsulate data in the Domain Entities .............................\", \"................................................................................. 207 \\nSeedwork (reu\", \"sable base classes and interfaces for your domain model) ...........................................\", \"....... 210 \\nThe custom Entity base class ..........................................................\", \"........................................................................... 211 \\nRepository contract\", \"s (interfaces) in the domain model layer ...........................................................\", \"........... 212 \\nAdditional resources ..............................................................\", \"....................................................................................... 213 \\nImpleme\", \"nt value objects ...................................................................................\", \"............................................................... 213 \\nImportant characteristics of va\", \"lue objects ........................................................................................\", \"................... 214 \\nValue object implementation in C# .........................................\", \"............................................................................... 215 \\nHow to persist \", \"value objects in the database with EF Core 2.0 and later ...........................................\", \"..... 217 \\nPersist value objects as owned entity types in EF Core 2.0 and later ....................\", \".................................... 218 \\nAdditional resources .....................................\", \"....................................................................................................\", \"............ 221 \\nUse enumeration classes instead of enum types ....................................\", \"............................................................... 221 \\nImplement an Enumeration base c\", \"lass ...............................................................................................\", \"................... 222 \\nAdditional resources ......................................................\", \"............................................................................................... 223 \", \"\\nDesign validations in the domain model layer ......................................................\", \"................................................. 223 \\nImplement validations in the domain model lay\", \"er ........................................................................................... 224 \\n\", \"Additional resources ...............................................................................\", \"...................................................................... 225 \\nClient-side validation (\", \"validation in the presentation layers) .............................................................\", \"............... 226 \\nAdditional resources ..........................................................\", \"........................................................................................... 227 \\nDom\", \"ain events: Design and implementation ..............................................................\", \"............................................ 227 \\nWhat is a domain event? ..........................\", \"....................................................................................................\", \"............... 228 \\nDomain events versus integration events .......................................\", \"..................................................................... 228 \\nDomain events as a prefer\", \"red way to trigger side effects across multiple aggregates within the \\nsame domain .................\", \"....................................................................................................\", \".............................................. 229 \\nImplement domain events ........................\", \"....................................................................................................\", \".............. 231 \\nConclusions on domain events ...................................................\", \".............................................................................. 237 \\n \\nvii \\nContents \", \"\\nAdditional resources ..............................................................................\", \"....................................................................... 238 \\nDesign the infrastructu\", \"re persistence layer ...............................................................................\", \"............................... 238 \\nThe Repository pattern ........................................\", \"....................................................................................................\", \".... 238 \\nAdditional resources .....................................................................\", \"................................................................................ 243 \\nImplement the \", \"infrastructure persistence layer with Entity Framework Core ........................................\", \".... 243 \\nIntroduction to Entity Framework Core ....................................................\", \"............................................................. 244 \\nInfrastructure in Entity Framewor\", \"k Core from a DDD perspective ............................................................. 244 \\nImp\", \"lement custom repositories with Entity Framework Core ..............................................\", \"........................ 246 \\nEF DbContext and IUnitOfWork instance lifetime in your IoC container .\", \"................................................ 248 \\nThe repository instance lifetime in your IoC c\", \"ontainer ................................................................................... 249 \\nTa\", \"ble mapping ........................................................................................\", \"........................................................................ 250 \\nImplement the Query Sp\", \"ecification pattern ................................................................................\", \"........................ 253 \\nUse NoSQL databases as a persistence infrastructure ..................\", \"....................................................................... 255 \\nIntroduction to Azure C\", \"osmos DB and the native Cosmos DB API ........................................................... 25\", \"6 \\nImplement .NET code targeting MongoDB and Azure Cosmos DB .......................................\", \"................... 258 \\nDesign the microservice application layer and Web API .....................\", \"............................................................... 266 \\nUse SOLID principles and Depend\", \"ency Injection .....................................................................................\", \"......... 266 \\nImplement the microservice application layer using the Web API ......................\", \"........................................... 267 \\nUse Dependency Injection to inject infrastructure o\", \"bjects into your application layer ..................... 267 \\nImplement the Command and Command Hand\", \"ler patterns ....................................................................... 271 \\nThe Comman\", \"d process pipeline: how to trigger a command handler ...............................................\", \"...... 278 \\nImplement the command process pipeline with a mediator pattern (MediatR) ...............\", \"................... 281 \\nApply cross-cutting concerns when processing commands with the Behaviors in\", \" MediatR .......... 287 \\nImplement resilient applications ..........................................\", \"............................................. 291 \\nHandle partial failure ..........................\", \"....................................................................................................\", \"........................... 292 \\nStrategies to handle partial failure ..............................\", \"................................................................................................. 29\", \"4 \\nAdditional resources ............................................................................\", \"......................................................................... 295 \\nImplement retries wit\", \"h exponential backoff ..............................................................................\", \".............................. 295 \\nImplement resilient Entity Framework Core SQL connections.......\", \"................................................................... 295 \\nExecution strategies and ex\", \"plicit transactions using BeginTransaction and multiple DbContexts296 \\nAdditional resources ........\", \"....................................................................................................\", \"......................................... 298 \\nUse IHttpClientFactory to implement resilient HTTP re\", \"quests ......................................................................... 298 \\n \\nviii \\nConten\", \"ts \\nIssues with the original HttpClient class available in .NET ....................................\", \"......................................... 298 \\nBenefits of using IHttpClientFactory ................\", \"....................................................................................................\", \"... 299 \\nMultiple ways to use IHttpClientFactory ...................................................\", \"............................................................ 300 \\nHow to use Typed Clients with IHtt\", \"pClientFactory .....................................................................................\", \"...... 300 \\nAdditional resources ...................................................................\", \".................................................................................. 304 \\nImplement HT\", \"TP call retries with exponential backoff with IHttpClientFactory and Polly policies ... 304 \\nAdd a j\", \"itter strategy to the retry policy .................................................................\", \"................................................ 305 \\nAdditional resources .........................\", \"....................................................................................................\", \"........................ 306 \\nImplement the Circuit Breaker pattern ................................\", \"....................................................................................... 306 \\nImpleme\", \"nt Circuit Breaker pattern with IHttpClientFactory and Polly .......................................\", \".............. 307 \\nTest Http retries and circuit breakers in eShopOnContainers ....................\", \".................................................. 308 \\nAdditional resources .......................\", \"....................................................................................................\", \".......................... 310 \\nHealth monitoring ..................................................\", \"....................................................................................................\", \"........ 310 \\nImplement health checks in ASP.NET Core services .....................................\", \"................................................... 311 \\nUse watchdogs .............................\", \"....................................................................................................\", \"............................... 315 \\nHealth checks when using orchestrators ........................\", \"...................................................................................... 317 \\nAdvanced\", \" monitoring: visualization, analysis, and alerts ...................................................\", \"............................ 317 \\nAdditional resources .............................................\", \"....................................................................................................\", \".... 318 \\nMake secure .NET Microservices and Web Applications ......................................\", \"........... 319 \\nImplement authentication in .NET microservices and web applications ...............\", \"....................................... 319 \\nAuthenticate with ASP.NET Core Identity ...............\", \".............................................................................................. 320 \\n\", \"Authenticate with external providers ...............................................................\", \"...................................................... 321 \\nAuthenticate with bearer tokens ........\", \"....................................................................................................\", \".................. 323 \\nAuthenticate with an OpenID Connect or OAuth 2.0 Identity provider .........\", \".......................................... 324 \\nIssue security tokens from an ASP.NET Core service .\", \"...................................................................................... 325 \\nConsume \", \"security tokens ....................................................................................\", \"........................................................ 326 \\nAdditional resources .................\", \"....................................................................................................\", \"..................................... 327 \\nAbout authorization in .NET microservices and web applica\", \"tions .................................................................. 327 \\nImplement role-based a\", \"uthorization .......................................................................................\", \".............................. 328 \\nImplement policy-based authorization ...........................\", \"...................................................................................... 329 \\nAuthoriz\", \"ation and minimal apis .............................................................................\", \".................................................. 330 \\nAdditional resources .......................\", \"....................................................................................................\", \".......................... 330 \\n \\nix \\nContents \\nStore application secrets safely during development \", \".......................................................................................... 330 \\nStor\", \"e secrets in environment variables .................................................................\", \"................................................ 331 \\nStore secrets with the ASP.NET Core Secret Man\", \"ager .................................................................................... 331 \\nUse A\", \"zure Key Vault to protect secrets at production time ...............................................\", \"............................... 332 \\nAdditional resources ..........................................\", \"....................................................................................................\", \"....... 333 \\n.NET Microservices Architecture key takeaways .........................................\", \"..................... 334 \\n \\n1 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\nCHAPTER 1 \\nIntr\", \"oduction to Containers \\nand Docker \\nContainerization is an approach to software development in which\", \" an application or service, its \\ndependencies, and its configuration (abstracted as deployment manif\", \"est files) are packaged together \\nas a container image. The containerized application can be tested \", \"as a unit and deployed as a \\ncontainer image instance to the host operating system (OS). \\nJust as sh\", \"ipping containers allow goods to be transported by ship, train, or truck regardless of the \\ncargo in\", \"side, software containers act as a standard unit of software deployment that can contain \\ndifferent \", \"code and dependencies. Containerizing software this way enables developers and IT \\nprofessionals to \", \"deploy them across environments with little or no modification. \\nContainers also isolate application\", \"s from each other on a shared OS. Containerized applications run \\non top of a container host that in\", \" turn runs on the OS (Linux or Windows). Containers therefore have a \\nsignificantly smaller footprin\", \"t than virtual machine (VM) images. \\nEach container can run a whole web application or a service, as\", \" shown in Figure 2-1. In this example, \\nDocker host is a container host, and App1, App2, Svc 1, and \", \"Svc 2 are containerized applications or \\nservices. \\n \\nFigure 2-1. Multiple containers running on a c\", \"ontainer host \\n \\n2 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\nAnother benefit of containe\", \"rization is scalability. You can scale out quickly by creating new containers \\nfor short-term tasks.\", \" From an application point of view, instantiating an image (creating a container) is \\nsimilar to ins\", \"tantiating a process like a service or a web app. For reliability, however, when you run \\nmultiple i\", \"nstances of the same image across multiple host servers, you typically want each container \\n(image i\", \"nstance) to run in a different host server or VM in different fault domains. \\nIn short, containers o\", \"ffer the benefits of isolation, portability, agility, scalability, and control across the \\nwhole app\", \"lication lifecycle workflow. The most important benefit is the environment\\u2019s isolation \\nprovided bet\", \"ween Dev and Ops. \\nWhat is Docker? \\nDocker is an open-source project for automating the deployment o\", \"f applications as portable, self-\\nsufficient containers that can run on the cloud or on-premises. Do\", \"cker is also a company that \\npromotes and evolves this technology, working in collaboration with clo\", \"ud, Linux, and Windows \\nvendors, including Microsoft. \\n \\nFigure 2-2. Docker deploys containers at al\", \"l layers of the hybrid cloud. \\nDocker containers can run anywhere, on-premises in the customer datac\", \"enter, in an external service \\nprovider or in the cloud, on Azure. Docker image containers can run n\", \"atively on Linux and Windows. \\nHowever, Windows images can run only on Windows hosts and Linux image\", \"s can run on Linux hosts \\nand Windows hosts (using a Hyper-V Linux VM, so far), where host means a s\", \"erver or a VM. \\nDevelopers can use development environments on Windows, Linux, or macOS. On the deve\", \"lopment \\ncomputer, the developer runs a Docker host where Docker images are deployed, including the \", \"app \\nand its dependencies. Developers who work on Linux or on macOS use a Docker host that is Linux \", \"\\nbased, and they can create images only for Linux containers. (Developers working on macOS can edit \", \"\\ncode or run the Docker CLI from macOS, but as of the time of this writing, containers don\\u2019t run \\n \\n\", \"3 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\ndirectly on macOS.) Developers who work on W\", \"indows can create images for either Linux or Windows \\nContainers. \\nTo host containers in development\", \" environments and provide additional developer tools, Docker \\nships Docker Desktop for Windows or fo\", \"r macOS. These products install the necessary VM (the Docker \\nhost) to host the containers. \\nTo run \", \"Windows Containers, there are two types of runtimes: \\n\\u2022 \\nWindows Server Containers provide applicati\", \"on isolation through process and namespace \\nisolation technology. A Windows Server Container shares \", \"a kernel with the container host and \\nwith all containers running on the host. \\n\\u2022 \\nHyper-V Container\", \"s expand on the isolation provided by Windows Server Containers by \\nrunning each container in a high\", \"ly optimized virtual machine. In this configuration, the kernel \\nof the container host isn\\u2019t shared \", \"with the Hyper-V Containers, providing better isolation. \\nThe images for these containers are create\", \"d the same way and function the same. The difference is in \\nhow the container is created from the im\", \"age running a Hyper-V Container requires an extra \\nparameter. For details, see Hyper-V Containers. \\n\", \"Comparing Docker containers with virtual machines \\nFigure 2-3 shows a comparison between VMs and Doc\", \"ker containers. \\nVirtual Machines \\nDocker Containers \\n \\n \\n4 \\nCHAPTER 1 | Introduction to Containers \", \"and Docker \\n \\nVirtual Machines \\nDocker Containers \\nVirtual machines include the application, the \\nre\", \"quired libraries or binaries, and a full guest \\noperating system. Full virtualization requires \\nmore\", \" resources than containerization. \\nContainers include the application and all its \\ndependencies. How\", \"ever, they share the OS kernel \\nwith other containers, running as isolated \\nprocesses in user space \", \"on the host operating \\nsystem. (Except in Hyper-V containers, where \\neach container runs inside of a\", \" special virtual \\nmachine per container.) \\nFigure 2-3. Comparison of traditional virtual machines to\", \" Docker containers \\nFor VMs, there are three base layers in the host server, from the bottom-up: inf\", \"rastructure, Host \\nOperating System and a Hypervisor and on top of all that each VM has its own OS a\", \"nd all necessary \\nlibraries. For Docker, the host server only has the infrastructure and the OS and \", \"on top of that, the \\ncontainer engine, that keeps container isolated but sharing the base OS service\", \"s. \\nBecause containers require far fewer resources (for example, they don\\u2019t need a full OS), they\\u2019re\", \" easy to \\ndeploy and they start fast. This allows you to have higher density, meaning that it allows\", \" you to run \\nmore services on the same hardware unit, thereby reducing costs. \\nAs a side effect of r\", \"unning on the same kernel, you get less isolation than VMs. \\nThe main goal of an image is that it ma\", \"kes the environment (dependencies) the same across different \\ndeployments. This means that you can d\", \"ebug it on your machine and then deploy it to another \\nmachine with the same environment guaranteed.\", \" \\nA container image is a way to package an app or service and deploy it in a reliable and reproducib\", \"le \\nway. You could say that Docker isn\\u2019t only a technology but also a philosophy and a process. \\nWhe\", \"n using Docker, you won\\u2019t hear developers say, \\u201cIt works on my machine, why not in production?\\u201d \\nThe\", \"y can simply say, \\u201cIt runs on Docker\\u201d, because the packaged Docker application can be executed \\non a\", \"ny supported Docker environment, and it runs the way it was intended to on all deployment \\ntargets (\", \"such as Dev, QA, staging, and production). \\nA simple analogy \\nPerhaps a simple analogy can help gett\", \"ing the grasp of the core concept of Docker. \\nLet\\u2019s go back in time to the 1950s for a moment. There\", \" were no word processors, and the \\nphotocopiers were used everywhere (kind of). \\nImagine you\\u2019re resp\", \"onsible for quickly issuing batches of letters as required, to mail them to \\ncustomers, using real p\", \"aper and envelopes, to be delivered physically to each customer\\u2019s address \\n(there was no email back \", \"then). \\nAt some point, you realize the letters are just a composition of a large set of paragraphs, \", \"which are \\npicked and arranged as needed, according to the purpose of the letter, so you devise a sy\", \"stem to \\nissue letters quickly, expecting to get a hefty raise. \\nThe system is simple: \\n1. \\nYou begi\", \"n with a deck of transparent sheets containing one paragraph each. \\n \\n5 \\nCHAPTER 1 | Introduction to\", \" Containers and Docker \\n \\n2. \\nTo issue a set of letters, you pick the sheets with the paragraphs you\", \" need, then you stack and \\nalign them so they look and read fine. \\n3. \\nFinally, you place the set in\", \" the photocopier and press start to produce as many letters as \\nrequired. \\nSo, simplifying, that\\u2019s t\", \"he core idea of Docker. \\nIn Docker, each layer is the resulting set of changes that happen to the fi\", \"lesystem after executing a \\ncommand, such as, installing a program. \\nSo, when you \\u201clook\\u201d at the file\", \"system after the layer has been copied, you see all the files, included in \\nthe layer when the progr\", \"am was installed. \\nYou can think of an image as an auxiliary read-only hard disk ready to be install\", \"ed in a \\u201ccomputer\\u201d \\nwhere the operating system is already installed. \\nSimilarly, you can think of a \", \"container as the \\u201ccomputer\\u201d with the image hard disk installed. The \\ncontainer, just like a computer\", \", can be powered on or off. \\nDocker terminology \\nThis section lists terms and definitions you should\", \" be familiar with before getting deeper into Docker. \\nFor further definitions, see the extensive glo\", \"ssary provided by Docker. \\nContainer image: A package with all the dependencies and information need\", \"ed to create a container. \\nAn image includes all the dependencies (such as frameworks) plus deployme\", \"nt and execution \\nconfiguration to be used by a container runtime. Usually, an image derives from mu\", \"ltiple base images \\nthat are layers stacked on top of each other to form the container\\u2019s filesystem.\", \" An image is immutable \\nonce it has been created. \\nDockerfile: A text file that contains instruction\", \"s for building a Docker image. It\\u2019s like a batch script, \\nthe first line states the base image to be\", \"gin with and then follow the instructions to install required \\nprograms, copy files, and so on, unti\", \"l you get the working environment you need. \\nBuild: The action of building a container image based o\", \"n the information and context provided by its \\nDockerfile, plus additional files in the folder where\", \" the image is built. You can build images with the \\nfollowing Docker command: \\ndocker build \\nContain\", \"er: An instance of a Docker image. A container represents the execution of a single \\napplication, pr\", \"ocess, or service. It consists of the contents of a Docker image, an execution \\nenvironment, and a s\", \"tandard set of instructions. When scaling a service, you create multiple instances \\nof a container f\", \"rom the same image. Or a batch job can create multiple containers from the same \\nimage, passing diff\", \"erent parameters to each instance. \\nVolumes: Offer a writable filesystem that the container can use.\", \" Since images are read-only but most \\nprograms need to write to the filesystem, volumes add a writab\", \"le layer, on top of the container image, \\nso the programs have access to a writable filesystem. The \", \"program doesn\\u2019t know it\\u2019s accessing a \\n \\n6 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\nlay\", \"ered filesystem, it\\u2019s just the filesystem as usual. Volumes live in the host system and are managed \", \"\\nby Docker. \\nTag: A mark or label you can apply to images so that different images or versions of th\", \"e same image \\n(depending on the version number or the target environment) can be identified. \\nMulti-\", \"stage Build: Is a feature, since Docker 17.05 or higher, that helps to reduce the size of the final \", \"\\nimages. For example, a large base image, containing the SDK can be used for compiling and \\npublishi\", \"ng and then a small runtime-only base image can be used to host the application. \\nRepository (repo):\", \" A collection of related Docker images, labeled with a tag that indicates the image \\nversion. Some r\", \"epos contain multiple variants of a specific image, such as an image containing SDKs \\n(heavier), an \", \"image containing only runtimes (lighter), etc. Those variants can be marked with tags. A \\nsingle rep\", \"o can contain platform variants, such as a Linux image and a Windows image. \\nRegistry: A service tha\", \"t provides access to repositories. The default registry for most public images is \\nDocker Hub (owned\", \" by Docker as an organization). A registry usually contains repositories from \\nmultiple teams. Compa\", \"nies often have private registries to store and manage images they\\u2019ve created. \\nAzure Container Regi\", \"stry is another example. \\nMulti-arch image: For multi-architecture (or multi-platform), it\\u2019s a Docke\", \"r feature that simplifies the \\nselection of the appropriate image, according to the platform where D\", \"ocker is running. For example, \\nwhen a Dockerfile requests a base image FROM mcr.microsoft.com/dotne\", \"t/sdk:7.0 from the \\nregistry, it actually gets 7.0-nanoserver-ltsc2022, 7.0-nanoserver-1809 or 7.0-b\", \"ullseye-slim, \\ndepending on the operating system and version where Docker is running. \\nDocker Hub: A\", \" public registry to upload images and work with them. Docker Hub provides Docker \\nimage hosting, pub\", \"lic or private registries, build triggers and web hooks, and integration with GitHub \\nand Bitbucket.\", \" \\nAzure Container Registry: A public resource for working with Docker images and its components in \\n\", \"Azure. This provides a registry that\\u2019s close to your deployments in Azure and that gives you control\", \" \\nover access, making it possible to use your Azure Active Directory groups and permissions. \\nDocker\", \" Trusted Registry (DTR): A Docker registry service (from Docker) that can be installed on-\\npremises \", \"so it lives within the organization\\u2019s datacenter and network. It\\u2019s convenient for private \\nimages th\", \"at should be managed within the enterprise. Docker Trusted Registry is included as part of \\nthe Dock\", \"er Datacenter product. \\nDocker Desktop: Development tools for Windows and macOS for building, runnin\", \"g, and testing \\ncontainers locally. Docker Desktop for Windows provides development environments for\", \" both Linux \\nand Windows Containers. The Linux Docker host on Windows is based on a Hyper-V virtual \", \"machine. \\nThe host for Windows Containers is directly based on Windows. Docker Desktop for Mac is ba\", \"sed on \\nthe Apple Hypervisor framework and the xhyve hypervisor, which provides a Linux Docker host \", \"virtual \\nmachine on macOS. Docker Desktop for Windows and for Mac replaces Docker Toolbox, which was\", \" \\nbased on Oracle VirtualBox. \\nCompose: A command-line tool and YAML file format with metadata for d\", \"efining and running multi-\\ncontainer applications. You define a single application based on multiple\", \" images with one or more \\n.yml files that can override values depending on the environment. After yo\", \"u\\u2019ve created the definitions, \\n \\n7 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\nyou can dep\", \"loy the whole multi-container application with a single command (docker-compose up) \\nthat creates a \", \"container per image on the Docker host. \\nCluster: A collection of Docker hosts exposed as if it were\", \" a single virtual Docker host, so that the \\napplication can scale to multiple instances of the servi\", \"ces spread across multiple hosts within the \\ncluster. Docker clusters can be created with Kubernetes\", \", Azure Service Fabric, Docker Swarm and \\nMesosphere DC/OS. \\nOrchestrator: A tool that simplifies th\", \"e management of clusters and Docker hosts. Orchestrators \\nenable you to manage their images, contain\", \"ers, and hosts through a command-line interface (CLI) or a \\ngraphical UI. You can manage container n\", \"etworking, configurations, load balancing, service discovery, \\nhigh availability, Docker host config\", \"uration, and more. An orchestrator is responsible for running, \\ndistributing, scaling, and healing w\", \"orkloads across a collection of nodes. Typically, orchestrator \\nproducts are the same products that \", \"provide cluster infrastructure, like Kubernetes and Azure Service \\nFabric, among other offerings in \", \"the market. \\nDocker containers, images, and registries \\nWhen using Docker, a developer creates an ap\", \"p or service and packages it and its dependencies into \\na container image. An image is a static repr\", \"esentation of the app or service and its configuration and \\ndependencies. \\nTo run the app or service\", \", the app\\u2019s image is instantiated to create a container, which will be running \\non the Docker host. \", \"Containers are initially tested in a development environment or PC. \\nDevelopers should store images \", \"in a registry, which acts as a library of images and is needed when \\ndeploying to production orchest\", \"rators. Docker maintains a public registry via Docker Hub; other \\nvendors provide registries for dif\", \"ferent collections of images, including Azure Container Registry. \\nAlternatively, enterprises can ha\", \"ve a private registry on-premises for their own Docker images. \\nFigure 2-4 shows how images and regi\", \"stries in Docker relate to other components. It also shows the \\nmultiple registry offerings from ven\", \"dors. \\n \\n8 \\nCHAPTER 1 | Introduction to Containers and Docker \\n \\n \\nFigure 2-4. Taxonomy of Docker te\", \"rms and concepts \\nThe registry is like a bookshelf where images are stored and available to be pulle\", \"d for building \\ncontainers to run services or web apps. There are private Docker registries on-premi\", \"ses and on the \\npublic cloud. Docker Hub is a public registry maintained by Docker, along the Docker\", \" Trusted Registry \\nan enterprise-grade solution, Azure offers the Azure Container Registry. AWS, Goo\", \"gle, and others also \\nhave container registries. \\nPutting images in a registry lets you store static\", \" and immutable application bits, including all their \\ndependencies at a framework level. Those image\", \"s can then be versioned and deployed in multiple \\nenvironments and therefore provide a consistent de\", \"ployment unit. \\nPrivate image registries, either hosted on-premises or in the cloud, are recommended\", \" when: \\n\\u2022 \\nYour images must not be shared publicly due to confidentiality. \\n\\u2022 \\nYou want to have mini\", \"mum network latency between your images and your chosen \\ndeployment environment. For example, if you\", \"r production environment is Azure cloud, you \\nprobably want to store your images in Azure Container \", \"Registry so that network latency will \\nbe minimal. In a similar way, if your production environment \", \"is on-premises, you might want \\nto have an on-premises Docker Trusted Registry available within the \", \"same local network. \\n \\n9 \\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers\", \" \\n \\nCHAPTER 2 \\nChoosing Between .NET \\nand .NET Framework for \\nDocker Containers \\nThere are two suppo\", \"rted frameworks for building server-side containerized Docker applications with \\n.NET: .NET Framewor\", \"k and .NET 7. They share many .NET platform components, and you can share \\ncode across the two. Howe\", \"ver, there are fundamental differences between them, and which \\nframework you use will depend on wha\", \"t you want to accomplish. This section provides guidance on \\nwhen to choose each framework. \\nGeneral\", \" guidance \\nThis section provides a summary of when to choose .NET 7 or .NET Framework. We provide mo\", \"re \\ndetails about these choices in the sections that follow. \\nUse .NET 7, with Linux or Windows Cont\", \"ainers, for your containerized Docker server application when: \\n\\u2022 \\nYou have cross-platform needs. Fo\", \"r example, you want to use both Linux and Windows \\nContainers. \\n\\u2022 \\nYour application architecture is \", \"based on microservices. \\n\\u2022 \\nYou need to start containers fast and want a small footprint per contain\", \"er to achieve better \\ndensity or more containers per hardware unit in order to lower your costs. \\nIn\", \" short, when you create new containerized .NET applications, you should consider .NET 7 as the \\ndefa\", \"ult choice. It has many benefits and fits best with the containers philosophy and style of working. \", \"\\nAn extra benefit of using .NET 7 is that you can run side-by-side .NET versions for applications wi\", \"thin \\nthe same machine. This benefit is more important for servers or VMs that do not use containers\", \", \\nbecause containers isolate the versions of .NET that the app needs. (As long as they are compatib\", \"le \\nwith the underlying OS.) \\nUse .NET Framework for your containerized Docker server application wh\", \"en: \\n\\u2022 \\nYour application currently uses .NET Framework and has strong dependencies on Windows. \\n \\n10\", \" \\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n \\n\\u2022 \\nYou need to use W\", \"indows APIs that are not supported by .NET 7. \\n\\u2022 \\nYou need to use third-party .NET libraries or NuGe\", \"t packages that are not available for .NET 7. \\nUsing .NET Framework on Docker can improve your deplo\", \"yment experiences by minimizing \\ndeployment issues. This \\u201clift and shift\\u201d scenario is important for \", \"containerizing legacy applications that \\nwere originally developed with the traditional .NET Framewo\", \"rk, like ASP.NET WebForms, MVC web \\napps, or WCF (Windows Communication Foundation) services. \\nAddit\", \"ional resources \\n\\u2022 \\nE-book: Modernize existing .NET Framework applications with Azure and Windows \\nC\", \"ontainers \\nhttps://aka.ms/liftandshiftwithcontainersebook \\n\\u2022 \\nSample apps: Modernization of legacy A\", \"SP.NET web apps by using Windows Containers \\nhttps://aka.ms/eshopmodernizing \\nWhen to choose .NET fo\", \"r Docker containers \\nThe modularity and lightweight nature of .NET 7 makes it perfect for containers\", \". When you deploy \\nand start a container, its image is far smaller with .NET 7 than with .NET Framew\", \"ork. In contrast, to use \\n.NET Framework for a container, you must base your image on the Windows Se\", \"rver Core image, which \\nis a lot heavier than the Windows Nano Server or Linux images that you use f\", \"or .NET 7. \\nAdditionally, .NET 7 is cross-platform, so you can deploy server apps with Linux or Wind\", \"ows container \\nimages. However, if you are using the traditional .NET Framework, you can only deploy\", \" images based \\non Windows Server Core. \\nThe following is a more detailed explanation of why to choos\", \"e .NET 7. \\nDeveloping and deploying cross platform \\nClearly, if your goal is to have an application \", \"(web app or service) that can run on multiple platforms \\nsupported by Docker (Linux and Windows), th\", \"e right choice is .NET 7, because .NET Framework only \\nsupports Windows. \\n.NET 7 also supports macOS\", \" as a development platform. However, when you deploy containers to a \\nDocker host, that host must (c\", \"urrently) be based on Linux or Windows. For example, in a development \\nenvironment, you could use a \", \"Linux VM running on a Mac. \\nVisual Studio provides an integrated development environment (IDE) for W\", \"indows and supports \\nDocker development. \\nVisual Studio for Mac is an IDE, evolution of Xamarin Stud\", \"io, that runs on macOS and supports \\nDocker-based application development. This tool should be the p\", \"referred choice for developers \\nworking in Mac machines who also want to use a powerful IDE. \\nYou ca\", \"n also use Visual Studio Code on macOS, Linux, and Windows. Visual Studio Code fully \\nsupports .NET \", \"7, including IntelliSense and debugging. Because VS Code is a lightweight editor, you \\n \\n11 \\nCHAPTER\", \" 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n \\ncan use it to develop contain\", \"erized apps on the machine in conjunction with the Docker CLI and the \\n.NET CLI. You can also target\", \" .NET 7 with most third-party editors like Sublime, Emacs, vi, and the \\nopen-source OmniSharp projec\", \"t, which also provides IntelliSense support. \\nIn addition to the IDEs and editors, you can use the .\", \"NET CLI for all supported platforms. \\nUsing containers for new (\\u201cgreen-field\\u201d) projects \\nContainers \", \"are commonly used in conjunction with a microservices architecture, although they can \\nalso be used \", \"to containerize web apps or services that follow any architectural pattern. You can use \\n.NET Framew\", \"ork on Windows Containers, but the modularity and lightweight nature of .NET 7 makes \\nit perfect for\", \" containers and microservices architectures. When you create and deploy a container, its \\nimage is f\", \"ar smaller with .NET 7 than with .NET Framework. \\nCreate and deploy microservices on containers \\nYou\", \" could use the traditional .NET Framework for building microservices-based applications (without \\nco\", \"ntainers) by using plain processes. That way, because the .NET Framework is already installed and \\ns\", \"hared across processes, processes are light and fast to start. However, if you are using containers,\", \" the \\nimage for the traditional .NET Framework is also based on Windows Server Core and that makes i\", \"t too \\nheavy for a microservices-on-containers approach. However, teams have been looking for \\noppor\", \"tunities to improve the experience for .NET Framework users as well. Recently, size of the \\nWindows \", \"Server Core container images have been reduced to >40% smaller. \\nOn the other hand, .NET 7 is the be\", \"st candidate if you\\u2019re embracing a microservices-oriented system \\nthat is based on containers becaus\", \"e .NET 7 is lightweight. In addition, its related container images, for \\neither Linux or Windows Nan\", \"o Server, are lean and small, making containers light and fast to start. \\nA microservice is meant to\", \" be as small as possible: to be light when spinning up, to have a small \\nfootprint, to have a small \", \"Bounded Context (check DDD, Domain-Driven Design), to represent a small \\narea of concerns, and to be\", \" able to start and stop fast. For those requirements, you will want to use \\nsmall and fast-to-instan\", \"tiate container images like the .NET 7 container image. \\nA microservices architecture also allows yo\", \"u to mix technologies across a service boundary. This \\napproach enables a gradual migration to .NET \", \"7 for new microservices that work in conjunction with \\nother microservices or with services develope\", \"d with Node.js, Python, Java, GoLang, or other \\ntechnologies. \\nDeploying high density in scalable sy\", \"stems \\nWhen your container-based system needs the best possible density, granularity, and performanc\", \"e, \\n.NET and ASP.NET Core are your best options. ASP.NET Core is up to 10 times faster than ASP.NET \", \"in \\nthe traditional .NET Framework, and it leads to other popular industry technologies for microser\", \"vices, \\nsuch as Java servlets, Go, and Node.js. \\nThis approach is especially relevant for microservi\", \"ces architectures, where you could have hundreds of \\nmicroservices (containers) running. With ASP.NE\", \"T Core images (based on the .NET runtime) on Linux \\nor Windows Nano, you can run your system with a \", \"much lower number of servers or VMs, ultimately \\nsaving costs in infrastructure and hosting. \\n \\n12 \\n\", \"CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n \\nWhen to choose .NET Fr\", \"amework for Docker \\ncontainers \\nWhile .NET 7 offers significant benefits for new applications and ap\", \"plication patterns, .NET Framework \\nwill continue to be a good choice for many existing scenarios. \\n\", \"Migrating existing applications directly to a Windows Server container \\nYou might want to use Docker\", \" containers just to simplify deployment, even if you are not creating \\nmicroservices. For example, p\", \"erhaps you want to improve your DevOps workflow with Docker\\u2014\\ncontainers can give you better isolated\", \" test environments and can also eliminate deployment issues \\ncaused by missing dependencies when you\", \" move to a production environment. In cases like these, \\neven if you are deploying a monolithic appl\", \"ication, it makes sense to use Docker and Windows \\nContainers for your current .NET Framework applic\", \"ations. \\nIn most cases for this scenario, you will not need to migrate your existing applications to\", \" .NET 7; you \\ncan use Docker containers that include the traditional .NET Framework. However, a reco\", \"mmended \\napproach is to use .NET 7 as you extend an existing application, such as writing a new serv\", \"ice in \\nASP.NET Core. \\nUsing third-party .NET libraries or NuGet packages not available for \\n.NET 7 \", \"\\nThird-party libraries are quickly embracing .NET Standard, which enables code sharing across all .N\", \"ET \\nflavors, including .NET 7. With .NET Standard 2.0 and later, the API surface compatibility acros\", \"s \\ndifferent frameworks has become significantly larger. Even more, .NET Core 2.x and newer applicat\", \"ions \\ncan also directly reference existing .NET Framework libraries (see .NET Framework 4.6.1 suppor\", \"ting \\n.NET Standard 2.0). \\nIn addition, the Windows Compatibility Pack extends the API surface avail\", \"able for .NET Standard 2.0 \\non Windows. This pack allows recompiling most existing code to .NET Stan\", \"dard 2.x with little or no \\nmodification, to run on Windows. \\nHowever, even with that exceptional pr\", \"ogression since .NET Standard 2.0 and .NET Core 2.1 or later, \\nthere might be cases where certain Nu\", \"Get packages need Windows to run and might not support \\n.NET Core or later. If those packages are cr\", \"itical for your application, then you will need to use .NET \\nFramework on Windows Containers. \\nUsing\", \" .NET technologies not available for .NET 7 \\nSome .NET Framework technologies aren\\u2019t available in .N\", \"ET 7. Some of them might become available \\nin later releases, but others don\\u2019t fit the new applicati\", \"on patterns targeted by .NET Core and might \\nnever be available. \\nThe following list shows most of t\", \"he technologies that aren\\u2019t available in .NET 7: \\n \\n13 \\nCHAPTER 2 | Choosing Between .NET and .NET F\", \"ramework for Docker Containers \\n \\n\\u2022 \\nASP.NET Web Forms. This technology is only available on .NET Fr\", \"amework. Currently there are \\nno plans to bring ASP.NET Web Forms to .NET or later. \\n\\u2022 \\nWorkflow-rel\", \"ated services. Windows Workflow Foundation (WF), Workflow Services (WCF + \\nWF in a single service), \", \"and WCF Data Services (formerly known as ADO.NET Data Services) \\nare only available on .NET Framewor\", \"k. There are currently no plans to bring them to .NET 7. \\nIn addition to the technologies listed in \", \"the official .NET roadmap, other features might be ported to \\nthe new unified .NET platform. You mig\", \"ht consider participating in the discussions on GitHub so that \\nyour voice can be heard. And if you \", \"think something is missing, file a new issue in the dotnet/runtime \\nGitHub repository. \\nUsing a plat\", \"form or API that doesn\\u2019t support .NET 7 \\nSome Microsoft and third-party platforms don\\u2019t support .NET\", \" 7. For example, some Azure services \\nprovide an SDK that isn\\u2019t yet available for consumption on .NE\", \"T 7 yet. Most Azure SDK should \\neventually be ported to .NET 7/.NET Standard, but some might not for\", \" several reasons. You can see \\nthe available Azure SDKs in the Azure SDK Latest Releases page. \\nIn t\", \"he meantime, if any platform or service in Azure still doesn\\u2019t support .NET 7 with its client API, y\", \"ou \\ncan use the equivalent REST API from the Azure service or the client SDK on .NET Framework. \\nPor\", \"ting existing ASP.NET application to .NET 7 \\n.NET Core is a revolutionary step forward from .NET Fra\", \"mework. It offers a host of advantages over \\n.NET Framework across the board from productivity to pe\", \"rformance, and from cross-platform support \\nto developer satisfaction. If you are using .NET Framewo\", \"rk and planning to migrate your application \\nto .NET Core or .NET 5+, see Porting Existing ASP.NET A\", \"pps to .NET Core. \\nAdditional resources \\n\\u2022 \\n.NET fundamentals \\nhttps://learn.microsoft.com/dotnet/fu\", \"ndamentals \\n\\u2022 \\nPorting Projects to .NET 5 \\nhttps://learn.microsoft.com/events/dotnetconf-2020/portin\", \"g-projects-to-net-5 \\n\\u2022 \\n.NET on Docker Guide \\nhttps://learn.microsoft.com/dotnet/core/docker/introdu\", \"ction \\nDecision table: .NET implementations to use for \\nDocker \\nThe following decision table summari\", \"zes whether to use .NET Framework or .NET 7. Remember that \\nfor Linux containers, you need Linux-bas\", \"ed Docker hosts (VMs or servers), and that for Windows \\nContainers, you need Windows Server-based Do\", \"cker hosts (VMs or servers). \\n \\n14 \\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker \", \"Containers \\n \\nImportant \\nYour development machines will run one Docker host, either Linux or Windows\", \". Related microservices \\nthat you want to run and test together in one solution will all need to run\", \" on the same container \\nplatform. \\nArchitecture / App Type \\nLinux containers \\nWindows Containers \\nMi\", \"croservices on containers \\n.NET 7 \\n.NET 7 \\nMonolithic app \\n.NET 7 \\n.NET Framework \\n.NET 7 \\nBest-in-c\", \"lass performance and \\nscalability \\n.NET 7 \\n.NET 7 \\nWindows Server legacy app (\\u201cbrown-\\nfield\\u201d) migrat\", \"ion to containers \\n\\u2013 \\n.NET Framework \\nNew container-based development \\n(\\u201cgreen-field\\u201d) \\n.NET 7 \\n.NET\", \" 7 \\nASP.NET Core \\n.NET 7 \\n.NET 7 (recommended) \\n.NET Framework \\nASP.NET 4 (MVC 5, Web API 2, and \\nWe\", \"b Forms) \\n\\u2013 \\n.NET Framework \\nSignalR services \\n.NET Core 2.1 or higher \\nversion \\n.NET Framework \\n.NE\", \"T Core 2.1 or higher \\nversion \\nWCF, WF, and other legacy \\nframeworks \\nWCF in .NET Core (client \\nlibr\", \"ary only) or CoreWCF \\n.NET Framework \\nWCF in .NET 7 (client library \\nonly) or CoreWCF \\nConsumption o\", \"f Azure services \\n.NET 7 \\n(eventually most Azure \\nservices will provide client \\nSDKs for .NET 7) \\n.N\", \"ET Framework \\n.NET 7 \\n(eventually most Azure \\nservices will provide client \\nSDKs for .NET 7) \\nWhat O\", \"S to target with .NET containers \\nGiven the diversity of operating systems supported by Docker and t\", \"he differences between .NET \\nFramework and .NET 7, you should target a specific OS and specific vers\", \"ions depending on the \\nframework you are using. \\nFor Windows, you can use Windows Server Core or Win\", \"dows Nano Server. These Windows versions \\nprovide different characteristics (IIS in Windows Server C\", \"ore versus a self-hosted web server like \\nKestrel in Nano Server) that might be needed by .NET Frame\", \"work or .NET 7, respectively. \\nFor Linux, multiple distros are available and supported in official .\", \"NET Docker images (like Debian). \\n \\n15 \\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Doc\", \"ker Containers \\n \\nIn Figure 3-1, you can see the possible OS version depending on the .NET framework\", \" used. \\n \\nFigure 3-1. Operating systems to target depending on versions of the .NET framework \\nWhen \", \"deploying legacy .NET Framework applications you have to target Windows Server Core, \\ncompatible wit\", \"h legacy apps and IIS, but it has a larger image. When deploying .NET 7 applications, \\nyou can targe\", \"t Windows Nano Server, which is cloud optimized, uses Kestrel and is smaller and starts \\nfaster. You\", \" can also target Linux, supporting Debian, Alpine, and others. \\nYou can also create your own Docker \", \"image in cases where you want to use a different Linux distro or \\nwhere you want an image with versi\", \"ons not provided by Microsoft. For example, you might create an \\nimage with ASP.NET Core running on \", \"the traditional .NET Framework and Windows Server Core, which \\nis a not-so-common scenario for Docke\", \"r. \\nWhen you add the image name to your Dockerfile file, you can select the operating system and \\nve\", \"rsion depending on the tag you use, as in the following examples: \\nImage \\nComments \\nmcr.microsoft.co\", \"m/dotnet/runtime:7.0 \\n.NET 7 multi-architecture: Supports Linux and Windows \\nNano Server depending o\", \"n the Docker host. \\nmcr.microsoft.com/dotnet/aspnet:7.0 \\nASP.NET Core 7.0 multi-architecture: Suppor\", \"ts Linux and \\nWindows Nano Server depending on the Docker host. \\nThe aspnetcore image has a few opti\", \"mizations for \\nASP.NET Core. \\nmcr.microsoft.com/dotnet/aspnet:7.0-\\nbullseye-slim \\n.NET 7 runtime-onl\", \"y on Linux Debian distro \\nmcr.microsoft.com/dotnet/aspnet:7.0-\\nnanoserver-1809 \\n.NET 7 runtime-only \", \"on Windows Nano Server (Windows \\nServer version 1809) \\n \\n16 \\nCHAPTER 2 | Choosing Between .NET and .\", \"NET Framework for Docker Containers \\n \\nOfficial .NET Docker images \\nThe Official .NET Docker images \", \"are Docker images created and optimized by Microsoft. They\\u2019re \\npublicly available on Microsoft Artif\", \"act Registry. You can search over the catalog to find all .NET image \\nrepositories, for example .NET\", \" SDK repository. \\nEach repository can contain multiple images, depending on .NET versions, and depen\", \"ding on the OS \\nand versions (Linux Debian, Linux Alpine, Windows Nano Server, Windows Server Core, \", \"and so on). \\nImage repositories provide extensive tagging to help you select not just a specific fra\", \"mework version, \\nbut also to choose an OS (Linux distribution or Windows version). \\n.NET and Docker \", \"image optimizations for development versus \\nproduction \\nWhen building Docker images for developers, \", \"Microsoft focused on the following main scenarios: \\n\\u2022 \\nImages used to develop and build .NET apps. \\n\", \"\\u2022 \\nImages used to run .NET apps. \\nWhy multiple images? When developing, building, and running contai\", \"nerized applications, you usually \\nhave different priorities. By providing different images for thes\", \"e separate tasks, Microsoft helps \\noptimize the separate processes of developing, building, and depl\", \"oying apps. \\nDuring development and build \\nDuring development, what is important is how fast you can\", \" iterate changes, and the ability to debug \\nthe changes. The size of the image isn\\u2019t as important as\", \" the ability to make changes to your code and \\nsee the changes quickly. Some tools and \\u201cbuild-agent \", \"containers\\u201d, use the development .NET image \\n(mcr.microsoft.com/dotnet/sdk:7.0) during development a\", \"nd build process. When building inside a \\nDocker container, the important aspects are the elements t\", \"hat are needed to compile your app. This \\nincludes the compiler and any other .NET dependencies. \\nWh\", \"y is this type of build image important? You don\\u2019t deploy this image to production. Instead, it\\u2019s an\", \" \\nimage that you use to build the content you place into a production image. This image would be use\", \"d \\nin your continuous integration (CI) environment or build environment when using Docker multi-stag\", \"e \\nbuilds. \\nIn production \\nWhat is important in production is how fast you can deploy and start your\", \" containers based on a \\nproduction .NET image. Therefore, the runtime-only image based on \\nmcr.micro\", \"soft.com/dotnet/aspnet:7.0 is small so that it can travel quickly across the network from your \\nDock\", \"er registry to your Docker hosts. The contents are ready to run, enabling the fastest time from \\nsta\", \"rting the container to processing results. In the Docker model, there is no need for compilation \\nfr\", \"om C# code, as there\\u2019s when you run dotnet build or dotnet publish when using the build container. \\n\", \" \\n17 \\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n \\nIn this optimize\", \"d image, you put only the binaries and other content needed to run the application. \\nFor example, th\", \"e content created by dotnet publish contains only the compiled .NET binaries, images, \\n.js, and .css\", \" files. Over time, you\\u2019ll see images that contain pre-jitted (the compilation from IL to native \\ntha\", \"t occurs at run time) packages. \\nAlthough there are multiple versions of the .NET and ASP.NET Core i\", \"mages, they all share one or more \\nlayers, including the base layer. Therefore, the amount of disk s\", \"pace needed to store an image is \\nsmall; it consists only of the delta between your custom image and\", \" its base image. The result is that \\nit\\u2019s quick to pull the image from your registry. \\nWhen you expl\", \"ore the .NET image repositories at Microsoft Artifact Registry, you\\u2019ll find multiple image \\nversions\", \" classified or marked with tags. These tags help to decide which one to use, depending on the \\nversi\", \"on you need, like those in the following table: \\nImage \\nComments \\nmcr.microsoft.com/dotnet/aspnet:7.\", \"0 \\nASP.NET Core, with runtime only and ASP.NET Core \\noptimizations, on Linux and Windows (multi-arch\", \") \\nmcr.microsoft.com/dotnet/sdk:7.0 \\n.NET 7, with SDKs included, on Linux and Windows \\n(multi-arch) \", \"\\nYou can find all the available docker images in dotnet-docker and also refer to the latest preview \", \"\\nreleases by using nightly build mcr.microsoft.com/dotnet/nightly/* \\n \\n18 \\nCHAPTER 3 | Architecting \", \"container and microservice-based applications \\n \\nCHAPTER 3 \\nArchitecting container and \\nmicroservice\", \"-based \\napplications \\nMicroservices offer great benefits but also raise huge new challenges. Microse\", \"rvice architecture patterns \\nare fundamental pillars when creating a microservice-based application.\", \" \\nEarlier in this guide, you learned basic concepts about containers and Docker. That information wa\", \"s \\nthe minimum you needed to get started with containers. Even though containers are enablers of, an\", \"d \\na great fit for microservices, they aren\\u2019t mandatory for a microservice architecture. Many archit\", \"ectural \\nconcepts in this architecture section could be applied without containers. However, this gu\", \"ide focuses \\non the intersection of both due to the already introduced importance of containers. \\nEn\", \"terprise applications can be complex and are often composed of multiple services instead of a \\nsingl\", \"e service-based application. For those cases, you need to understand other architectural \\napproaches\", \", such as the microservices and certain Domain-Driven Design (DDD) patterns plus \\ncontainer orchestr\", \"ation concepts. Note that this chapter describes not just microservices on \\ncontainers, but any cont\", \"ainerized application, as well. \\nContainer design principles \\nIn the container model, a container im\", \"age instance represents a single process. By defining a \\ncontainer image as a process boundary, you \", \"can create primitives that can be used to scale or batch \\nthe process. \\nWhen you design a container \", \"image, you\\u2019ll see an ENTRYPOINT definition in the Dockerfile. This \\ndefinition defines the process w\", \"hose lifetime controls the lifetime of the container. When the process \\ncompletes, the container lif\", \"ecycle ends. Containers might represent long-running processes like web \\nservers, but can also repre\", \"sent short-lived processes like batch jobs, which formerly might have been \\nimplemented as Azure Web\", \"Jobs. \\nIf the process fails, the container ends, and the orchestrator takes over. If the orchestrato\", \"r was \\nconfigured to keep five instances running and one fails, the orchestrator will create another\", \" container \\ninstance to replace the failed process. In a batch job, the process is started with para\", \"meters. When the \\nprocess completes, the work is complete. This guidance drills-down on orchestrator\", \"s, later on. \\n \\n19 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nYou mi\", \"ght find a scenario where you want multiple processes running in a single container. For that \\nscena\", \"rio, since there can be only one entry point per container, you could run a script within the \\nconta\", \"iner that launches as many programs as needed. For example, you can use Supervisor or a \\nsimilar too\", \"l to take care of launching multiple processes inside a single container. However, even \\nthough you \", \"can find architectures that hold multiple processes per container, that approach isn\\u2019t very \\ncommon.\", \" \\nContainerizing monolithic applications \\nYou might want to build a single, monolithically deployed \", \"web application or service and deploy it as \\na container. The application itself might not be intern\", \"ally monolithic, but structured as several \\nlibraries, components, or even layers (application layer\", \", domain layer, data-access layer, etc.). \\nExternally, however, it\\u2019s a single container\\u2014a single pro\", \"cess, a single web application, or a single \\nservice. \\nTo manage this model, you deploy a single con\", \"tainer to represent the application. To increase \\ncapacity, you scale out, that is, just add more co\", \"pies with a load balancer in front. The simplicity \\ncomes from managing a single deployment in a sin\", \"gle container or VM. \\n \\nFigure 4-1. Example of the architecture of a containerized monolithic applic\", \"ation \\nYou can include multiple components, libraries, or internal layers in each container, as illu\", \"strated in \\nFigure 4-1. A monolithic containerized application has most of its functionality within \", \"a single \\ncontainer, with internal layers or libraries, and scales out by cloning the container on m\", \"ultiple \\nservers/VMs. However, this monolithic pattern might conflict with the container principle \\u201c\", \"a container \\ndoes one thing, and does it in one process\\u201d, but might be ok for some cases. \\nThe downs\", \"ide of this approach becomes evident if the application grows, requiring it to scale. If the \\nentire\", \" application can scale, it isn\\u2019t really a problem. However, in most cases, just a few parts of the \\n\", \"application are the choke points that require scaling, while other components are used less. \\nFor ex\", \"ample, in a typical e-commerce application, you likely need to scale the product information \\nsubsys\", \"tem, because many more customers browse products than purchase them. More customers use \\n \\n20 \\nCHAPT\", \"ER 3 | Architecting container and microservice-based applications \\n \\ntheir basket than use the payme\", \"nt pipeline. Fewer customers add comments or view their purchase \\nhistory. And you might have only a\", \" handful of employees that need to manage the content and \\nmarketing campaigns. If you scale the mon\", \"olithic design, all the code for these different tasks is \\ndeployed multiple times and scaled at the\", \" same grade. \\nThere are multiple ways to scale an application-horizontal duplication, splitting diff\", \"erent areas of the \\napplication, and partitioning similar business concepts or data. But, in additio\", \"n to the problem of \\nscaling all components, changes to a single component require complete retestin\", \"g of the entire \\napplication, and a complete redeployment of all the instances. \\nHowever, the monoli\", \"thic approach is common, because the development of the application is initially \\neasier than for mi\", \"croservices approaches. Thus, many organizations develop using this architectural \\napproach. While s\", \"ome organizations have had good enough results, others are hitting limits. Many \\norganizations desig\", \"ned their applications using this model because tools and infrastructure made it \\ntoo difficult to b\", \"uild service-oriented architectures (SOA) years ago, and they did not see the need-\\nuntil the applic\", \"ation grew. \\nFrom an infrastructure perspective, each server can run many applications within the sa\", \"me host and \\nhave an acceptable ratio of efficiency in resources usage, as shown in Figure 4-2. \\n \\nF\", \"igure 4-2. Monolithic approach: Host running multiple apps, each app running as a container \\nMonolit\", \"hic applications in Microsoft Azure can be deployed using dedicated VMs for each instance. \\nAddition\", \"ally, using Azure virtual machine scale sets, you can easily scale the VMs. Azure App Service \\ncan a\", \"lso run monolithic applications and easily scale instances without requiring you to manage the \\nVMs.\", \" Since 2016, Azure App Services can run single instances of Docker containers as well, simplifying \\n\", \"deployment. \\nAs a QA environment or a limited production environment, you can deploy multiple Docker\", \" host VMs \\nand balance them using the Azure balancer, as shown in Figure 4-3. This lets you manage s\", \"caling with \\na coarse-grain approach, because the whole application lives within a single container.\", \" \\n \\n21 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\nFigure 4-3. Exam\", \"ple of multiple hosts scaling up a single container application \\nDeployment to the various hosts can\", \" be managed with traditional deployment techniques. Docker \\nhosts can be managed with commands like \", \"docker run or docker-compose performed manually, or \\nthrough automation such as continuous delivery \", \"(CD) pipelines. \\nDeploying a monolithic application as a container \\nThere are benefits to using cont\", \"ainers to manage monolithic application deployments. Scaling \\ncontainer instances is far faster and \", \"easier than deploying additional VMs. Even if you use virtual \\nmachine scale sets, VMs take time to \", \"start. When deployed as traditional application instances instead \\nof containers, the configuration \", \"of the application is managed as part of the VM, which isn\\u2019t ideal. \\nDeploying updates as Docker ima\", \"ges is far faster and network efficient. Docker images typically start \\nin seconds, which speeds rol\", \"louts. Tearing down a Docker image instance is as easy as issuing a \\ndocker stop command, and typica\", \"lly completes in less than a second. \\nBecause containers are immutable by design, you never need to \", \"worry about corrupted VMs. In \\ncontrast, update scripts for a VM might forget to account for some sp\", \"ecific configuration or file left on \\ndisk. \\nWhile monolithic applications can benefit from Docker, \", \"we\\u2019re touching only on the benefits. \\nAdditional benefits of managing containers come from deploying\", \" with container orchestrators, which \\nmanage the various instances and lifecycle of each container i\", \"nstance. Breaking up the monolithic \\napplication into subsystems that can be scaled, developed, and \", \"deployed individually is your entry \\npoint into the realm of microservices. \\nPublishing a single-con\", \"tainer-based application to Azure App Service \\nWhether you want to get validation of a container dep\", \"loyed to Azure or when an application is simply \\na single-container application, Azure App Service p\", \"rovides a great way to provide scalable single-\\ncontainer-based services. Using Azure App Service is\", \" simple. It provides great integration with Git to \\nmake it easy to take your code, build it in Visu\", \"al Studio, and deploy it directly to Azure. \\n \\n22 \\nCHAPTER 3 | Architecting container and microservi\", \"ce-based applications \\n \\n \\nFigure 4-4. Publishing a single-container application to Azure App Servic\", \"e from Visual Studio 2022 \\nWithout Docker, if you needed other capabilities, frameworks, or dependen\", \"cies that aren\\u2019t supported \\nin Azure App Service, you had to wait until the Azure team updated those\", \" dependencies in App \\nService. Or you had to switch to other services like Azure Cloud Services or V\", \"Ms, where you had \\nfurther control and you could install a required component or framework for your \", \"application. \\nContainer support in Visual Studio 2017 and later gives you the ability to include wha\", \"tever you want \\nin your application environment, as shown in Figure 4-4. Since you\\u2019re running it in \", \"a container, if you \\nadd a dependency to your application, you can include the dependency in your Do\", \"ckerfile or Docker \\nimage. \\nAs also shown in Figure 4-4, the publish flow pushes an image through a \", \"container registry. This can \\nbe the Azure Container Registry (a registry close to your deployments \", \"in Azure and secured by Azure \\nActive Directory groups and accounts), or any other Docker registry, \", \"like Docker Hub or an on-\\npremises registry. \\nManage state and data in Docker applications \\nIn most \", \"cases, you can think of a container as an instance of a process. A process doesn\\u2019t maintain \\npersist\", \"ent state. While a container can write to its local storage, assuming that an instance will be \\narou\", \"nd indefinitely would be like assuming that a single location in memory will be durable. You \\n \\n23 \\n\", \"CHAPTER 3 | Architecting container and microservice-based applications \\n \\nshould assume that contain\", \"er images, like processes, have multiple instances or will eventually be \\nkilled. If they\\u2019re managed\", \" with a container orchestrator, you should assume that they might get \\nmoved from one node or VM to \", \"another. \\nThe following solutions are used to manage data in Docker applications: \\nFrom the Docker h\", \"ost, as Docker Volumes: \\n\\u2022 \\nVolumes are stored in an area of the host filesystem that\\u2019s managed by D\", \"ocker. \\n\\u2022 \\nBind mounts can map to any folder in the host filesystem, so access can\\u2019t be controlled f\", \"rom \\nDocker process and can pose a security risk as a container could access sensitive OS folders. \\n\", \"\\u2022 \\ntmpfs mounts are like virtual folders that only exist in the host\\u2019s memory and are never \\nwritten\", \" to the filesystem. \\nFrom remote storage: \\n\\u2022 \\nAzure Storage, which provides geo-distributable storag\", \"e, providing a good long-term \\npersistence solution for containers. \\n\\u2022 \\nRemote relational databases \", \"like Azure SQL Database or NoSQL databases like Azure Cosmos \\nDB, or cache services like Redis. \\nFro\", \"m the Docker container: \\n\\u2022 \\nOverlay File System. This Docker feature implements a copy-on-write task\", \" that stores \\nupdated information to the root file system of the container. That information is \\u201con \", \"top\\u201d of \\nthe original image on which the container is based. If the container is deleted from the \\ns\", \"ystem, those changes are lost. Therefore, while it\\u2019s possible to save the state of a container \\nwith\", \"in its local storage, designing a system around this would conflict with the premise of \\ncontainer d\", \"esign, which by default is stateless. \\nHowever, using Docker Volumes is now the preferred way to han\", \"dle local data in Docker. If you need \\nmore information about storage in containers check on Docker \", \"storage drivers and About storage \\ndrivers. \\nThe following provides more detail about these options:\", \" \\nVolumes are directories mapped from the host OS to directories in containers. When code in the \\nco\", \"ntainer has access to the directory, that access is actually to a directory on the host OS. This \\ndi\", \"rectory is not tied to the lifetime of the container itself, and the directory is managed by Docker \", \"and \\nisolated from the core functionality of the host machine. Thus, data volumes are designed to pe\", \"rsist \\ndata independently of the life of the container. If you delete a container or an image from t\", \"he Docker \\nhost, the data persisted in the data volume isn\\u2019t deleted. \\nVolumes can be named or anony\", \"mous (the default). Named volumes are the evolution of Data \\nVolume Containers and make it easy to s\", \"hare data between containers. Volumes also support \\nvolume drivers that allow you to store data on r\", \"emote hosts, among other options. \\nBind mounts are available since a long time ago and allow the map\", \"ping of any folder to a mount \\npoint in a container. Bind mounts have more limitations than volumes \", \"and some important security \\nissues, so volumes are the recommended option. \\n \\n24 \\nCHAPTER 3 | Archi\", \"tecting container and microservice-based applications \\n \\ntmpfs mounts are basically virtual folders \", \"that live only in the host\\u2019s memory and are never written to \\nthe filesystem. They are fast and secu\", \"re but use memory and are only meant for temporary, non-\\npersistent data. \\nAs shown in Figure 4-5, r\", \"egular Docker volumes can be stored outside of the containers themselves \\nbut within the physical bo\", \"undaries of the host server or VM. However, Docker containers can\\u2019t access \\na volume from one host s\", \"erver or VM to another. In other words, with these volumes, it isn\\u2019t possible \\nto manage data shared\", \" between containers that run on different Docker hosts, although it could be \\nachieved with a volume\", \" driver that supports remote hosts. \\n \\nFigure 4-5. Volumes and external data sources for container-b\", \"ased applications \\nVolumes can be shared between containers, but only in the same host, unless you u\", \"se a remote driver \\nthat supports remote hosts. In addition, when Docker containers are managed by a\", \"n orchestrator, \\ncontainers might \\u201cmove\\u201d between hosts, depending on the optimizations performed by \", \"the cluster. \\nTherefore, it isn\\u2019t recommended that you use data volumes for business data. But they\\u2019\", \"re a good \\nmechanism to work with trace files, temporal files, or similar that will not impact busin\", \"ess data \\nconsistency. \\nRemote data sources and cache tools like Azure SQL Database, Azure Cosmos DB\", \", or a remote cache \\nlike Redis can be used in containerized applications the same way they are used\", \" when developing \\nwithout containers. This is a proven way to store business application data. \\nAzur\", \"e Storage. Business data usually will need to be placed in external resources or databases, like \\nAz\", \"ure Storage. Azure Storage, in concrete, provides the following services in the cloud: \\n\\u2022 \\nBlob stor\", \"age stores unstructured object data. A blob can be any type of text or binary data, \\nsuch as documen\", \"t or media files (images, audio, and video files). Blob storage is also referred \\nto as Object stora\", \"ge. \\n \\n25 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n\\u2022 \\nFile storage\", \" offers shared storage for legacy applications using standard SMB protocol. Azure \\nvirtual machines \", \"and cloud services can share file data across application components via \\nmounted shares. On-premise\", \"s applications can access file data in a share via the File service \\nREST API. \\n\\u2022 \\nTable storage sto\", \"res structured datasets. Table storage is a NoSQL key-attribute data store, \\nwhich allows rapid deve\", \"lopment and fast access to large quantities of data. \\nRelational databases and NoSQL databases. Ther\", \"e are many choices for external databases, from \\nrelational databases like SQL Server, PostgreSQL, O\", \"racle, or NoSQL databases like Azure Cosmos DB, \\nMongoDB, etc. These databases are not going to be e\", \"xplained as part of this guide since they are in a \\ncompletely different subject. \\nService-oriented \", \"architecture \\nService-oriented architecture (SOA) was an overused term and has meant different thing\", \"s to different \\npeople. But as a common denominator, SOA means that you structure your application b\", \"y \\ndecomposing it into multiple services (most commonly as HTTP services) that can be classified as \", \"\\ndifferent types like subsystems or tiers. \\nThose services can now be deployed as Docker containers,\", \" which solves deployment issues, because \\nall the dependencies are included in the container image. \", \"However, when you need to scale up SOA \\napplications, you might have scalability and availability ch\", \"allenges if you\\u2019re deploying based on single \\nDocker hosts. This is where Docker clustering software\", \" or an orchestrator can help you, as explained in \\nlater sections where deployment approaches for mi\", \"croservices are described. \\nDocker containers are useful (but not required) for both traditional ser\", \"vice-oriented architectures and \\nthe more advanced microservices architectures. \\nMicroservices deriv\", \"e from SOA, but SOA is different from microservices architecture. Features like \\nlarge central broke\", \"rs, central orchestrators at the organization level, and the Enterprise Service Bus \\n(ESB) are typic\", \"al in SOA. But in most cases, these are anti-patterns in the microservice community. In \\nfact, some \", \"people argue that \\u201cThe microservice architecture is SOA done right.\\u201d \\nThis guide focuses on microser\", \"vices, because a SOA approach is less prescriptive than the \\nrequirements and techniques used in a m\", \"icroservice architecture. If you know how to build a \\nmicroservice-based application, you also know \", \"how to build a simpler service-oriented application. \\nMicroservices architecture \\nAs the name implie\", \"s, a microservices architecture is an approach to building a server application as a \\nset of small s\", \"ervices. That means a microservices architecture is mainly oriented to the back-end, \\nalthough the a\", \"pproach is also being used for the front end. Each service runs in its own process and \\ncommunicates\", \" with other processes using protocols such as HTTP/HTTPS, WebSockets, or AMQP. \\nEach microservice im\", \"plements a specific end-to-end domain or business capability within a certain \\ncontext boundary, and\", \" each must be developed autonomously and be deployable independently. \\nFinally, each microservice sh\", \"ould own its related domain data model and domain logic (sovereignty \\n \\n26 \\nCHAPTER 3 | Architecting\", \" container and microservice-based applications \\n \\nand decentralized data management) and could be ba\", \"sed on different data storage technologies \\n(SQL, NoSQL) and different programming languages. \\nWhat \", \"size should a microservice be? When developing a microservice, size shouldn\\u2019t be the important \\npoin\", \"t. Instead, the important point should be to create loosely coupled services so you have \\nautonomy o\", \"f development, deployment, and scale, for each service. Of course, when identifying and \\ndesigning m\", \"icroservices, you should try to make them as small as possible as long as you don\\u2019t have \\ntoo many d\", \"irect dependencies with other microservices. More important than the size of the \\nmicroservice is th\", \"e internal cohesion it must have and its independence from other services. \\nWhy a microservices arch\", \"itecture? In short, it provides long-term agility. Microservices enable better \\nmaintainability in c\", \"omplex, large, and highly-scalable systems by letting you create applications based \\non many indepen\", \"dently deployable services that each have granular and autonomous lifecycles. \\nAs an additional bene\", \"fit, microservices can scale out independently. Instead of having a single \\nmonolithic application t\", \"hat you must scale out as a unit, you can instead scale out specific \\nmicroservices. That way, you c\", \"an scale just the functional area that needs more processing power or \\nnetwork bandwidth to support \", \"demand, rather than scaling out other areas of the application that \\ndon\\u2019t need to be scaled. That m\", \"eans cost savings because you need less hardware. \\n \\nFigure 4-6. Monolithic deployment versus the mi\", \"croservices approach \\nAs Figure 4-6 shows, in the traditional monolithic approach, the application s\", \"cales by cloning the \\nwhole app in several servers/VM. In the microservices approach, functionality \", \"is segregated in smaller \\nservices, so each service can scale independently. The microservices appro\", \"ach allows agile changes \\nand rapid iteration of each microservice, because you can change specific,\", \" small areas of complex, \\nlarge, and scalable applications. \\nArchitecting fine-grained microservices\", \"-based applications enables continuous integration and \\ncontinuous delivery practices. It also accel\", \"erates delivery of new functions into the application. Fine-\\ngrained composition of applications als\", \"o allows you to run and test microservices in isolation, and to \\n \\n27 \\nCHAPTER 3 | Architecting cont\", \"ainer and microservice-based applications \\n \\nevolve them autonomously while maintaining clear contra\", \"cts between them. As long as you don\\u2019t \\nchange the interfaces or contracts, you can change the inter\", \"nal implementation of any microservice or \\nadd new functionality without breaking other microservice\", \"s. \\nThe following are important aspects to enable success in going into production with a microservi\", \"ces-\\nbased system: \\n\\u2022 \\nMonitoring and health checks of the services and infrastructure. \\n\\u2022 \\nScalable\", \" infrastructure for the services (that is, cloud and orchestrators). \\n\\u2022 \\nSecurity design and impleme\", \"ntation at multiple levels: authentication, authorization, secrets \\nmanagement, secure communication\", \", etc. \\n\\u2022 \\nRapid application delivery, usually with different teams focusing on different microservi\", \"ces. \\n\\u2022 \\nDevOps and CI/CD practices and infrastructure. \\nOf these, only the first three are covered \", \"or introduced in this guide. The last two points, which are \\nrelated to application lifecycle, are c\", \"overed in the additional Containerized Docker Application \\nLifecycle with Microsoft Platform and Too\", \"ls e-book. \\nAdditional resources \\n\\u2022 \\nMark Russinovich. Microservices: An application revolution powe\", \"red by the cloud \\nhttps://azure.microsoft.com/blog/microservices-an-application-revolution-powered-b\", \"y-the-\\ncloud/ \\n\\u2022 \\nMartin Fowler. Microservices \\nhttps://www.martinfowler.com/articles/microservices.\", \"html \\n\\u2022 \\nMartin Fowler. Microservice Prerequisites \\nhttps://martinfowler.com/bliki/MicroservicePrere\", \"quisites.html \\n\\u2022 \\nJimmy Nilsson. Chunk Cloud Computing \\nhttps://www.infoq.com/articles/CCC-Jimmy-Nil\", \"sson \\n\\u2022 \\nCesar de la Torre. Containerized Docker Application Lifecycle with Microsoft Platform \\nand \", \"Tools (downloadable e-book) \\nhttps://aka.ms/dockerlifecycleebook \\nData sovereignty per microservice \", \"\\nAn important rule for microservices architecture is that each microservice must own its domain data\", \" \\nand logic. Just as a full application owns its logic and data, so must each microservice own its l\", \"ogic \\nand data under an autonomous lifecycle, with independent deployment per microservice. \\nThis me\", \"ans that the conceptual model of the domain will differ between subsystems or microservices. \\nConsid\", \"er enterprise applications, where customer relationship management (CRM) applications, \\n \\n28 \\nCHAPTE\", \"R 3 | Architecting container and microservice-based applications \\n \\ntransactional purchase subsystem\", \"s, and customer support subsystems each call on unique customer \\nentity attributes and data, and whe\", \"re each employs a different Bounded Context (BC). \\nThis principle is similar in Domain-driven design\", \" (DDD), where each Bounded Context or autonomous \\nsubsystem or service must own its domain model (da\", \"ta plus logic and behavior). Each DDD Bounded \\nContext correlates to one business microservice (one \", \"or several services). This point about the \\nBounded Context pattern is expanded in the next section.\", \" \\nOn the other hand, the traditional (monolithic data) approach used in many applications is to have\", \" a \\nsingle centralized database or just a few databases. This is often a normalized SQL database tha\", \"t\\u2019s \\nused for the whole application and all its internal subsystems, as shown in Figure 4-7. \\n \\nFigu\", \"re 4-7. Data sovereignty comparison: monolithic database versus microservices \\nIn the traditional ap\", \"proach, there\\u2019s a single database shared across all services, typically in a tiered \\narchitecture. I\", \"n the microservices approach, each microservice owns its model/data. The centralized \\ndatabase appro\", \"ach initially looks simpler and seems to enable reuse of entities in different subsystems \\nto make e\", \"verything consistent. But the reality is you end up with huge tables that serve many different \\nsubs\", \"ystems, and that include attributes and columns that aren\\u2019t needed in most cases. It\\u2019s like trying \\n\", \"to use the same physical map for hiking a short trail, taking a day-long car trip, and learning \\ngeo\", \"graphy. \\nA monolithic application with typically a single relational database has two important bene\", \"fits: ACID \\ntransactions and the SQL language, both working across all the tables and data related t\", \"o your \\napplication. This approach provides a way to easily write a query that combines data from mu\", \"ltiple \\ntables. \\nHowever, data access becomes much more complicated when you move to a microservices\", \" \\narchitecture. Even when using ACID transactions within a microservice or Bounded Context, it is cr\", \"ucial \\nto consider that the data owned by each microservice is private to that microservice and shou\", \"ld only \\n \\n29 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nbe accessed\", \" either synchronously through its API endpoints(REST, gRPC, SOAP, etc) or asynchronously \\nvia messag\", \"ing(AMQP or similar). \\nEncapsulating the data ensures that the microservices are loosely coupled and\", \" can evolve \\nindependently of one another. If multiple services were accessing the same data, schema\", \" updates \\nwould require coordinated updates to all the services. This would break the microservice l\", \"ifecycle \\nautonomy. But distributed data structures mean that you can\\u2019t make a single ACID transacti\", \"on across \\nmicroservices. This in turn means you must use eventual consistency when a business proce\", \"ss spans \\nmultiple microservices. This is much harder to implement than simple SQL joins, because yo\", \"u can\\u2019t \\ncreate integrity constraints or use distributed transactions between separate databases, as\", \" we\\u2019ll \\nexplain later on. Similarly, many other relational database features aren\\u2019t available across\", \" multiple \\nmicroservices. \\nGoing even further, different microservices often use different kinds of \", \"databases. Modern \\napplications store and process diverse kinds of data, and a relational database i\", \"sn\\u2019t always the best \\nchoice. For some use cases, a NoSQL database such as Azure CosmosDB or MongoDB\", \" might have a \\nmore convenient data model and offer better performance and scalability than a SQL da\", \"tabase like \\nSQL Server or Azure SQL Database. In other cases, a relational database is still the be\", \"st approach. \\nTherefore, microservices-based applications often use a mixture of SQL and NoSQL datab\", \"ases, which \\nis sometimes called the polyglot persistence approach. \\nA partitioned, polyglot-persist\", \"ent architecture for data storage has many benefits. These include \\nloosely coupled services and bet\", \"ter performance, scalability, costs, and manageability. However, it can \\nintroduce some distributed \", \"data management challenges, as explained in \\u201cIdentifying domain-model \\nboundaries\\u201d later in this cha\", \"pter. \\nThe relationship between microservices and the Bounded Context \\npattern \\nThe concept of micro\", \"service derives from the Bounded Context (BC) pattern in domain-driven design \\n(DDD). DDD deals with\", \" large models by dividing them into multiple BCs and being explicit about their \\nboundaries. Each BC\", \" must have its own model and database; likewise, each microservice owns its \\nrelated data. In additi\", \"on, each BC usually has its own ubiquitous language to help communication \\nbetween software develope\", \"rs and domain experts. \\nThose terms (mainly domain entities) in the ubiquitous language can have dif\", \"ferent names in different \\nBounded Contexts, even when different domain entities share the same iden\", \"tity (that is, the unique ID \\nthat\\u2019s used to read the entity from storage). For instance, in a user-\", \"profile Bounded Context, the User \\ndomain entity might share identity with the Buyer domain entity i\", \"n the ordering Bounded Context. \\nA microservice is therefore like a Bounded Context, but it also spe\", \"cifies that it\\u2019s a distributed service. \\nIt\\u2019s built as a separate process for each Bounded Context, \", \"and it must use the distributed protocols \\nnoted earlier, like HTTP/HTTPS, WebSockets, or AMQP. The \", \"Bounded Context pattern, however, \\ndoesn\\u2019t specify whether the Bounded Context is a distributed serv\", \"ice or if it\\u2019s simply a logical \\nboundary (such as a generic subsystem) within a monolithic-deployme\", \"nt application. \\nIt\\u2019s important to highlight that defining a service for each Bounded Context is a g\", \"ood place to start. \\nBut you don\\u2019t have to constrain your design to it. Sometimes you must design a \", \"Bounded Context or \\n \\n30 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n\", \"business microservice composed of several physical services. But ultimately, both patterns -Bounded \", \"\\nContext and microservice- are closely related. \\nDDD benefits from microservices by getting real bou\", \"ndaries in the form of distributed microservices. \\nBut ideas like not sharing the model between micr\", \"oservices are what you also want in a Bounded \\nContext. \\nAdditional resources \\n\\u2022 \\nChris Richardson. \", \"Pattern: Database per service \\nhttps://microservices.io/patterns/data/database-per-service.html \\n\\u2022 \\n\", \"Martin Fowler. BoundedContext \\nhttps://martinfowler.com/bliki/BoundedContext.html \\n\\u2022 \\nMartin Fowler.\", \" PolyglotPersistence \\nhttps://martinfowler.com/bliki/PolyglotPersistence.html \\n\\u2022 \\nAlberto Brandolini\", \". Strategic Domain Driven Design with Context Mapping \\nhttps://www.infoq.com/articles/ddd-contextmap\", \"ping \\nLogical architecture versus physical architecture \\nIt\\u2019s useful at this point to stop and discu\", \"ss the distinction between logical architecture and physical \\narchitecture, and how this applies to \", \"the design of microservice-based applications. \\nTo begin, building microservices doesn\\u2019t require the\", \" use of any specific technology. For instance, \\nDocker containers aren\\u2019t mandatory to create a micro\", \"service-based architecture. Those microservices \\ncould also be run as plain processes. Microservices\", \" is a logical architecture. \\nMoreover, even when a microservice could be physically implemented as a\", \" single service, process, or \\ncontainer (for simplicity\\u2019s sake, that\\u2019s the approach taken in the ini\", \"tial version of eShopOnContainers), \\nthis parity between business microservice and physical service \", \"or container isn\\u2019t necessarily required in \\nall cases when you build a large and complex application\", \" composed of many dozens or even \\nhundreds of services. \\nThis is where there\\u2019s a difference between \", \"an application\\u2019s logical architecture and physical \\narchitecture. The logical architecture and logic\", \"al boundaries of a system do not necessarily map one-\\nto-one to the physical or deployment architect\", \"ure. It can happen, but it often doesn\\u2019t. \\nAlthough you might have identified certain business micro\", \"services or Bounded Contexts, it doesn\\u2019t \\nmean that the best way to implement them is always by crea\", \"ting a single service (such as an ASP.NET \\nWeb API) or single Docker container for each business mic\", \"roservice. Having a rule saying each \\nbusiness microservice has to be implemented using a single ser\", \"vice or container is too rigid. \\nTherefore, a business microservice or Bounded Context is a logical \", \"architecture that might coincide (or \\nnot) with physical architecture. The important point is that a\", \" business microservice or Bounded \\nContext must be autonomous by allowing code and state to be indep\", \"endently versioned, deployed, \\nand scaled. \\n \\n31 \\nCHAPTER 3 | Architecting container and microservic\", \"e-based applications \\n \\nAs Figure 4-8 shows, the catalog business microservice could be composed of \", \"several services or \\nprocesses. These could be multiple ASP.NET Web API services or any other kind o\", \"f services using \\nHTTP or any other protocol. More importantly, the services could share the same da\", \"ta, as long as \\nthese services are cohesive with respect to the same business domain. \\n \\nFigure 4-8.\", \" Business microservice with several physical services \\nThe services in the example share the same da\", \"ta model because the Web API service targets the same \\ndata as the Search service. So, in the physic\", \"al implementation of the business microservice, you\\u2019re \\nsplitting that functionality so you can scal\", \"e each of those internal services up or down as needed. \\nMaybe the Web API service usually needs mor\", \"e instances than the Search service, or vice versa. \\nIn short, the logical architecture of microserv\", \"ices doesn\\u2019t always have to coincide with the physical \\ndeployment architecture. In this guide, when\", \"ever we mention a microservice, we mean a business or \\nlogical microservice that could map to one or\", \" more (physical) services. In most cases, this will be a \\nsingle service, but it might be more. \\nCha\", \"llenges and solutions for distributed data \\nmanagement \\nChallenge #1: How to define the boundaries o\", \"f each microservice \\nDefining microservice boundaries is probably the first challenge anyone encount\", \"ers. Each microservice \\nhas to be a piece of your application and each microservice should be autono\", \"mous with all the \\nbenefits and challenges that it conveys. But how do you identify those boundaries\", \"? \\nFirst, you need to focus on the application\\u2019s logical domain models and related data. Try to iden\", \"tify \\ndecoupled islands of data and different contexts within the same application. Each context cou\", \"ld have \\na different business language (different business terms). The contexts should be defined an\", \"d managed \\nindependently. The terms and entities that are used in those different contexts might sou\", \"nd similar, \\nbut you might discover that in a particular context, a business concept with one is use\", \"d for a different \\n \\n32 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\np\", \"urpose in another context, and might even have a different name. For instance, a user can be \\nreferr\", \"ed as a user in the identity or membership context, as a customer in a CRM context, as a buyer in \\na\", \"n ordering context, and so forth. \\nThe way you identify boundaries between multiple application cont\", \"exts with a different domain for \\neach context is exactly how you can identify the boundaries for ea\", \"ch business microservice and its \\nrelated domain model and data. You always attempt to minimize the \", \"coupling between those \\nmicroservices. This guide goes into more detail about this identification an\", \"d domain model design in \\nthe section Identifying domain-model boundaries for each microservice late\", \"r. \\nChallenge #2: How to create queries that retrieve data from several \\nmicroservices \\nA second cha\", \"llenge is how to implement queries that retrieve data from several microservices, while \\navoiding ch\", \"atty communication to the microservices from remote client apps. An example could be a \\nsingle scree\", \"n from a mobile app that needs to show user information that\\u2019s owned by the basket, \\ncatalog, and us\", \"er identity microservices. Another example would be a complex report involving many \\ntables located \", \"in multiple microservices. The right solution depends on the complexity of the queries. \\nBut in any \", \"case, you\\u2019ll need a way to aggregate information if you want to improve the efficiency in \\nthe commu\", \"nications of your system. The most popular solutions are the following. \\nAPI Gateway. For simple dat\", \"a aggregation from multiple microservices that own different databases, \\nthe recommended approach is\", \" an aggregation microservice referred to as an API Gateway. However, \\nyou need to be careful about i\", \"mplementing this pattern, because it can be a choke point in your \\nsystem, and it can violate the pr\", \"inciple of microservice autonomy. To mitigate this possibility, you can \\nhave multiple fined-grained\", \" API Gateways each one focusing on a vertical \\u201cslice\\u201d or business area of \\nthe system. The API Gatew\", \"ay pattern is explained in more detail in the API Gateway section later. \\nGraphQL Federation One opt\", \"ion to consider if your microservices are already using GraphQL is \\nGraphQL Federation. Federation a\", \"llows you to define \\u201csubgraphs\\u201d from other services and compose \\nthem into an aggregate \\u201csupergraph\\u201d\", \" that acts as a standalone schema. \\nCQRS with query/reads tables. Another solution for aggregating d\", \"ata from multiple microservices is \\nthe Materialized View pattern. In this approach, you generate, i\", \"n advance (prepare denormalized data \\nbefore the actual queries happen), a read-only table with the \", \"data that\\u2019s owned by multiple \\nmicroservices. The table has a format suited to the client app\\u2019s need\", \"s. \\nConsider something like the screen for a mobile app. If you have a single database, you might pu\", \"ll \\ntogether the data for that screen using a SQL query that performs a complex join involving multi\", \"ple \\ntables. However, when you have multiple databases, and each database is owned by a different \\nm\", \"icroservice, you cannot query those databases and create a SQL join. Your complex query becomes \\na c\", \"hallenge. You can address the requirement using a CQRS approach\\u2014you create a denormalized \\ntable in \", \"a different database that\\u2019s used just for queries. The table can be designed specifically for the \\nd\", \"ata you need for the complex query, with a one-to-one relationship between fields needed by your \\nap\", \"plication\\u2019s screen and the columns in the query table. It could also serve for reporting purposes. \\n\", \"This approach not only solves the original problem (how to query and join across microservices), but\", \" it \\nalso improves performance considerably when compared with a complex join, because you already \\n\", \" \\n33 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nhave the data that t\", \"he application needs in the query table. Of course, using Command and Query \\nResponsibility Segregat\", \"ion (CQRS) with query/reads tables means additional development work, and \\nyou\\u2019ll need to embrace ev\", \"entual consistency. Nonetheless, requirements on performance and high \\nscalability in collaborative \", \"scenarios (or competitive scenarios, depending on the point of view) are \\nwhere you should apply CQR\", \"S with multiple databases. \\n\\u201cCold data\\u201d in central databases. For complex reports and queries that m\", \"ight not require real-time \\ndata, a common approach is to export your \\u201chot data\\u201d (transactional data\", \" from the microservices) as \\n\\u201ccold data\\u201d into large databases that are used only for reporting. That\", \" central database system can be \\na Big Data-based system, like Hadoop; a data warehouse like one bas\", \"ed on Azure SQL Data \\nWarehouse; or even a single SQL database that\\u2019s used just for reports (if size\", \" won\\u2019t be an issue). \\nKeep in mind that this centralized database would be used only for queries and\", \" reports that do not \\nneed real-time data. The original updates and transactions, as your source of \", \"truth, have to be in your \\nmicroservices data. The way you would synchronize data would be either by\", \" using event-driven \\ncommunication (covered in the next sections) or by using other database infrast\", \"ructure import/export \\ntools. If you use event-driven communication, that integration process would \", \"be similar to the way \\nyou propagate data as described earlier for CQRS query tables. \\nHowever, if y\", \"our application design involves constantly aggregating information from multiple \\nmicroservices for \", \"complex queries, it might be a symptom of a bad design -a microservice should be \\nas isolated as pos\", \"sible from other microservices. (This excludes reports/analytics that always should \\nuse cold-data c\", \"entral databases.) Having this problem often might be a reason to merge \\nmicroservices. You need to \", \"balance the autonomy of evolution and deployment of each microservice \\nwith strong dependencies, coh\", \"esion, and data aggregation. \\nChallenge #3: How to achieve consistency across multiple \\nmicroservice\", \"s \\nAs stated previously, the data owned by each microservice is private to that microservice and can\", \" only \\nbe accessed using its microservice API. Therefore, a challenge presented is how to implement \", \"end-to-\\nend business processes while keeping consistency across multiple microservices. \\nTo analyze \", \"this problem, let\\u2019s look at an example from the eShopOnContainers reference application. \\nThe Catalo\", \"g microservice maintains information about all the products, including the product price. \\nThe Baske\", \"t microservice manages temporal data about product items that users are adding to their \\nshopping ba\", \"skets, which includes the price of the items at the time they were added to the basket. \\nWhen a prod\", \"uct\\u2019s price is updated in the catalog, that price should also be updated in the active \\nbaskets that\", \" hold that same product, plus the system should probably warn the user saying that a \\nparticular ite\", \"m\\u2019s price has changed since they added it to their basket. \\nIn a hypothetical monolithic version of \", \"this application, when the price changes in the products table, \\nthe catalog subsystem could simply \", \"use an ACID transaction to update the current price in the Basket \\ntable. \\nHowever, in a microservic\", \"es-based application, the Product and Basket tables are owned by their \\nrespective microservices. No\", \" microservice should ever include tables/storage owned by another \\nmicroservice in its own transacti\", \"ons, not even in direct queries, as shown in Figure 4-9. \\n \\n34 \\nCHAPTER 3 | Architecting container a\", \"nd microservice-based applications \\n \\n \\nFigure 4-9. A microservice can\\u2019t directly access a table in \", \"another microservice \\nThe Catalog microservice shouldn\\u2019t update the Basket table directly, because t\", \"he Basket table is \\nowned by the Basket microservice. To make an update to the Basket microservice, \", \"the Catalog \\nmicroservice should use eventual consistency probably based on asynchronous communicati\", \"on such \\nas integration events (message and event-based communication). This is how the eShopOnConta\", \"iners \\nreference application performs this type of consistency across microservices. \\nAs stated by t\", \"he CAP theorem, you need to choose between availability and ACID strong consistency. \\nMost microserv\", \"ice-based scenarios demand availability and high scalability as opposed to strong \\nconsistency. Miss\", \"ion-critical applications must remain up and running, and developers can work \\naround strong consist\", \"ency by using techniques for working with weak or eventual consistency. This is \\nthe approach taken \", \"by most microservice-based architectures. \\nMoreover, ACID-style or two-phase commit transactions are\", \" not just against microservices principles; \\nmost NoSQL databases (like Azure Cosmos DB, MongoDB, et\", \"c.) do not support two-phase commit \\ntransactions, typical in distributed databases scenarios. Howev\", \"er, maintaining data consistency across \\nservices and databases is essential. This challenge is also\", \" related to the question of how to propagate \\nchanges across multiple microservices when certain dat\", \"a needs to be redundant\\u2014for example, when \\nyou need to have the product\\u2019s name or description in the\", \" Catalog microservice and the Basket \\nmicroservice. \\nA good solution for this problem is to use even\", \"tual consistency between microservices articulated \\nthrough event-driven communication and a publish\", \"-and-subscribe system. These topics are covered \\nin the section Asynchronous event-driven communicat\", \"ion later in this guide. \\n \\n35 \\nCHAPTER 3 | Architecting container and microservice-based applicatio\", \"ns \\n \\nChallenge #4: How to design communication across microservice \\nboundaries \\nCommunicating acros\", \"s microservice boundaries is a real challenge. In this context, communication \\ndoesn\\u2019t refer to what\", \" protocol you should use (HTTP and REST, AMQP, messaging, and so on). Instead, \\nit addresses what co\", \"mmunication style you should use, and especially how coupled your \\nmicroservices should be. Dependin\", \"g on the level of coupling, when failure occurs, the impact of that \\nfailure on your system will var\", \"y significantly. \\nIn a distributed system like a microservices-based application, with so many artif\", \"acts moving around \\nand with distributed services across many servers or hosts, components will even\", \"tually fail. Partial \\nfailure and even larger outages will occur, so you need to design your microse\", \"rvices and the \\ncommunication across them considering the common risks in this type of distributed s\", \"ystem. \\nA popular approach is to implement HTTP (REST)-based microservices, due to their simplicity.\", \" An \\nHTTP-based approach is perfectly acceptable; the issue here is related to how you use it. If yo\", \"u use \\nHTTP requests and responses just to interact with your microservices from client applications\", \" or from \\nAPI Gateways, that\\u2019s fine. But if you create long chains of synchronous HTTP calls across \", \"microservices, \\ncommunicating across their boundaries as if the microservices were objects in a mono\", \"lithic \\napplication, your application will eventually run into problems. \\nFor instance, imagine that\", \" your client application makes an HTTP API call to an individual microservice \\nlike the Ordering mic\", \"roservice. If the Ordering microservice in turn calls additional microservices using \\nHTTP within th\", \"e same request/response cycle, you\\u2019re creating a chain of HTTP calls. It might sound \\nreasonable ini\", \"tially. However, there are important points to consider when going down this path: \\n\\u2022 \\nBlocking and \", \"low performance. Due to the synchronous nature of HTTP, the original request \\ndoesn\\u2019t get a response\", \" until all the internal HTTP calls are finished. Imagine if the number of \\nthese calls increases sig\", \"nificantly and at the same time one of the intermediate HTTP calls to a \\nmicroservice is blocked. Th\", \"e result is that performance is impacted, and the overall scalability \\nwill be exponentially affecte\", \"d as additional HTTP requests increase. \\n\\u2022 \\nCoupling microservices with HTTP. Business microservices\", \" shouldn\\u2019t be coupled with other \\nbusiness microservices. Ideally, they shouldn\\u2019t \\u201cknow\\u201d about the e\", \"xistence of other \\nmicroservices. If your application relies on coupling microservices as in the exa\", \"mple, achieving \\nautonomy per microservice will be almost impossible. \\n\\u2022 \\nFailure in any one microse\", \"rvice. If you implemented a chain of microservices linked by HTTP \\ncalls, when any of the microservi\", \"ces fails (and eventually they will fail) the whole chain of \\nmicroservices will fail. A microservic\", \"e-based system should be designed to continue to work \\nas well as possible during partial failures. \", \"Even if you implement client logic that uses retries \\nwith exponential backoff or circuit breaker me\", \"chanisms, the more complex the HTTP call \\nchains are, the more complex it is to implement a failure \", \"strategy based on HTTP. \\nIn fact, if your internal microservices are communicating by creating chain\", \"s of HTTP requests as \\ndescribed, it could be argued that you have a monolithic application, but one\", \" based on HTTP between \\nprocesses instead of intra-process communication mechanisms. \\n \\n36 \\nCHAPTER \", \"3 | Architecting container and microservice-based applications \\n \\nTherefore, in order to enforce mic\", \"roservice autonomy and have better resiliency, you should minimize \\nthe use of chains of request/res\", \"ponse communication across microservices. It\\u2019s recommended that \\nyou use only asynchronous interacti\", \"on for inter-microservice communication, either by using \\nasynchronous message- and event-based comm\", \"unication, or by using (asynchronous) HTTP polling \\nindependently of the original HTTP request/respo\", \"nse cycle. \\nThe use of asynchronous communication is explained with additional details later in this\", \" guide in the \\nsections Asynchronous microservice integration enforces microservice\\u2019s autonomy and A\", \"synchronous \\nmessage-based communication. \\nAdditional resources \\n\\u2022 \\nCAP theorem \\nhttps://en.wikipedi\", \"a.org/wiki/CAP_theorem \\n\\u2022 \\nEventual consistency \\nhttps://en.wikipedia.org/wiki/Eventual_consistency \", \"\\n\\u2022 \\nData Consistency Primer \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v=pandp.\", \"10) \\n\\u2022 \\nMartin Fowler. CQRS (Command and Query Responsibility Segregation) \\nhttps://martinfowler.com\", \"/bliki/CQRS.html \\n\\u2022 \\nMaterialized View \\nhttps://learn.microsoft.com/azure/architecture/patterns/mate\", \"rialized-view \\n\\u2022 \\nCharles Row. ACID vs. BASE: The Shifting pH of Database Transaction Processing \\nht\", \"tps://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-\\nprocessing/ \\n\\u2022 \\nComp\", \"ensating Transaction \\nhttps://learn.microsoft.com/azure/architecture/patterns/compensating-transacti\", \"on \\n\\u2022 \\nUdi Dahan. Service Oriented Composition \\nhttps://udidahan.com/2014/07/30/service-oriented-com\", \"position-with-video/ \\nIdentify domain-model boundaries for each \\nmicroservice \\nThe goal when identif\", \"ying model boundaries and size for each microservice isn\\u2019t to get to the most \\ngranular separation p\", \"ossible, although you should tend toward small microservices if possible. \\nInstead, your goal should\", \" be to get to the most meaningful separation guided by your domain \\nknowledge. The emphasis isn\\u2019t on\", \" the size, but instead on business capabilities. In addition, if there\\u2019s \\nclear cohesion needed for \", \"a certain area of the application based on a high number of dependencies, \\nthat indicates the need f\", \"or a single microservice, too. Cohesion is a way to identify how to break apart \\n \\n37 \\nCHAPTER 3 | A\", \"rchitecting container and microservice-based applications \\n \\nor group together microservices. Ultima\", \"tely, while you gain more knowledge about the domain, you \\nshould adapt the size of your microservic\", \"e, iteratively. Finding the right size isn\\u2019t a one-shot process. \\nSam Newman, a recognized promoter \", \"of microservices and author of the book Building Microservices, \\nhighlights that you should design y\", \"our microservices based on the Bounded Context (BC) pattern \\n(part of domain-driven design), as intr\", \"oduced earlier. Sometimes, a BC could be composed of several \\nphysical services, but not vice versa.\", \" \\nA domain model with specific domain entities applies within a concrete BC or microservice. A BC \\nd\", \"elimits the applicability of a domain model and gives developer team members a clear and shared \\nund\", \"erstanding of what must be cohesive and what can be developed independently. These are the \\nsame goa\", \"ls for microservices. \\nAnother tool that informs your design choice is Conway\\u2019s law, which states th\", \"at an application will \\nreflect the social boundaries of the organization that produced it. But some\", \"times the opposite is true -\\nthe company\\u2019s organization is formed by the software. You might need to\", \" reverse Conway\\u2019s law and \\nbuild the boundaries the way you want the company to be organized, leanin\", \"g toward business \\nprocess consulting. \\nTo identify bounded contexts, you can use a DDD pattern call\", \"ed the Context Mapping pattern. With \\nContext Mapping, you identify the various contexts in the appl\", \"ication and their boundaries. It\\u2019s \\ncommon to have a different context and boundary for each small s\", \"ubsystem, for instance. The Context \\nMap is a way to define and make explicit those boundaries betwe\", \"en domains. A BC is autonomous \\nand includes the details of a single domain -details like the domain\", \" entities- and defines integration \\ncontracts with other BCs. This is similar to the definition of a\", \" microservice: it\\u2019s autonomous, it \\nimplements certain domain capability, and it must provide interf\", \"aces. This is why Context Mapping \\nand the Bounded Context pattern are good approaches for identifyi\", \"ng the domain model boundaries \\nof your microservices. \\nWhen designing a large application, you\\u2019ll s\", \"ee how its domain model can be fragmented - a domain \\nexpert from the catalog domain will name entit\", \"ies differently in the catalog and inventory domains \\nthan a shipping domain expert, for instance. O\", \"r the user domain entity might be different in size and \\nnumber of attributes when dealing with a CR\", \"M expert who wants to store every detail about the \\ncustomer than for an ordering domain expert who \", \"just needs partial data about the customer. It\\u2019s very \\nhard to disambiguate all domain terms across \", \"all the domains related to a large application. But the \\nmost important thing is that you shouldn\\u2019t \", \"try to unify the terms. Instead, accept the differences and \\nrichness provided by each domain. If yo\", \"u try to have a unified database for the whole application, \\nattempts at a unified vocabulary will b\", \"e awkward and won\\u2019t sound right to any of the multiple domain \\nexperts. Therefore, BCs (implemented \", \"as microservices) will help you to clarify where you can use \\ncertain domain terms and where you\\u2019ll \", \"need to split the system and create additional BCs with \\ndifferent domains. \\nYou\\u2019ll know that you go\", \"t the right boundaries and sizes of each BC and domain model if you have few \\nstrong relationships b\", \"etween domain models, and you do not usually need to merge information \\nfrom multiple domain models \", \"when performing typical application operations. \\nPerhaps the best answer to the question of how larg\", \"e a domain model for each microservice should \\nbe is the following: it should have an autonomous BC,\", \" as isolated as possible, that enables you to \\nwork without having to constantly switch to other con\", \"texts (other microservice\\u2019s models). In Figure 4-\\n \\n38 \\nCHAPTER 3 | Architecting container and micro\", \"service-based applications \\n \\n10, you can see how multiple microservices (multiple BCs) each has the\", \"ir own model and how their \\nentities can be defined, depending on the specific requirements for each\", \" of the identified domains in \\nyour application. \\n \\nFigure 4-10. Identifying entities and microservi\", \"ce model boundaries \\nFigure 4-10 illustrates a sample scenario related to an online conference manag\", \"ement system. The \\nsame entity appears as \\u201cUsers\\u201d, \\u201cBuyers\\u201d, \\u201cPayers\\u201d, and \\u201cCustomers\\u201d depending on \", \"the bounded \\ncontext. You\\u2019ve identified several BCs that could be implemented as microservices, base\", \"d on domains \\nthat domain experts defined for you. As you can see, there are entities that are prese\", \"nt just in a single \\nmicroservice model, like Payments in the Payment microservice. Those will be ea\", \"sy to implement. \\nHowever, you might also have entities that have a different shape but share the sa\", \"me identity across \\nthe multiple domain models from the multiple microservices. For example, the Use\", \"r entity is identified \\nin the Conferences Management microservice. That same user, with the same id\", \"entity, is the one \\nnamed Buyers in the Ordering microservice, or the one named Payer in the Payment\", \" microservice, and \\neven the one named Customer in the Customer Service microservice. This is becaus\", \"e, depending on \\nthe ubiquitous language that each domain expert is using, a user might have a diffe\", \"rent perspective \\neven with different attributes. The user entity in the microservice model named Co\", \"nferences \\nManagement might have most of its personal data attributes. However, that same user in th\", \"e shape of \\nPayer in the microservice Payment or in the shape of Customer in the microservice Custom\", \"er Service \\nmight not need the same list of attributes. \\nA similar approach is illustrated in Figure\", \" 4-11. \\n \\n39 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\nFigure 4-1\", \"1. Decomposing traditional data models into multiple domain models \\nWhen decomposing a traditional d\", \"ata model between bounded contexts, you can have different \\nentities that share the same identity (a\", \" buyer is also a user) with different attributes in each bounded \\ncontext. You can see how the user \", \"is present in the Conferences Management microservice model as \\nthe User entity and is also present \", \"in the form of the Buyer entity in the Pricing microservice, with \\nalternate attributes or details a\", \"bout the user when it\\u2019s actually a buyer. Each microservice or BC might \\nnot need all the data relat\", \"ed to a User entity, just part of it, depending on the problem to solve or the \\ncontext. For instanc\", \"e, in the Pricing microservice model, you do not need the address or the name of \\nthe user, just the\", \" ID (as identity) and Status, which will have an impact on discounts when pricing the \\nseats per buy\", \"er. \\nThe Seat entity has the same name but different attributes in each domain model. However, Seat \", \"\\nshares identity based on the same ID, as happens with User and Buyer. \\nBasically, there\\u2019s a shared \", \"concept of a user that exists in multiple services (domains), which all share \\nthe identity of that \", \"user. But in each domain model there might be additional or different details \\nabout the user entity\", \". Therefore, there needs to be a way to map a user entity from one domain \\n(microservice) to another\", \". \\nThere are several benefits to not sharing the same user entity with the same number of attributes\", \" \\nacross domains. One benefit is to reduce duplication, so that microservice models do not have any \", \"\\ndata that they do not need. Another benefit is having a primary microservice that owns a certain ty\", \"pe \\nof data per entity so that updates and queries for that type of data are driven only by that \\nmi\", \"croservice. \\n \\n40 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nThe API\", \" gateway pattern versus the Direct client-to-\\nmicroservice communication \\nIn a microservices archite\", \"cture, each microservice exposes a set of (typically) fine-grained endpoints. \\nThis fact can impact \", \"the client-to-microservice communication, as explained in this section. \\nDirect client-to-microservi\", \"ce communication \\nA possible approach is to use a direct client-to-microservice communication archit\", \"ecture. In this \\napproach, a client app can make requests directly to some of the microservices, as \", \"shown in Figure 4-\\n12. \\n \\nFigure 4-12. Using a direct client-to-microservice communication architect\", \"ure \\nIn this approach, each microservice has a public endpoint, sometimes with a different TCP port \", \"for \\neach microservice. An example of a URL for a particular service could be the following URL in A\", \"zure: \\nhttp://eshoponcontainers.westus.cloudapp.azure.com:88/ \\nIn a production environment based on \", \"a cluster, that URL would map to the load balancer used in the \\ncluster, which in turn distributes t\", \"he requests across the microservices. In production environments, \\nyou could have an Application Del\", \"ivery Controller (ADC) like Azure Application Gateway between your \\nmicroservices and the Internet. \", \"This layer acts as a transparent tier that not only performs load \\nbalancing, but secures your servi\", \"ces by offering SSL termination. This approach improves the load of \\nyour hosts by offloading CPU-in\", \"tensive SSL termination and other routing duties to the Azure \\nApplication Gateway. In any case, a l\", \"oad balancer and ADC are transparent from a logical application \\narchitecture point of view. \\nA dire\", \"ct client-to-microservice communication architecture could be good enough for a small \\nmicroservice-\", \"based application, especially if the client app is a server-side web application like an \\nASP.NET MV\", \"C app. However, when you build large and complex microservice-based applications (for \\nexample, when\", \" handling dozens of microservice types), and especially when the client apps are \\nremote mobile apps\", \" or SPA web applications, that approach faces a few issues. \\n \\n41 \\nCHAPTER 3 | Architecting containe\", \"r and microservice-based applications \\n \\nConsider the following questions when developing a large ap\", \"plication based on microservices: \\n\\u2022 \\nHow can client apps minimize the number of requests to the bac\", \"k end and reduce chatty \\ncommunication to multiple microservices? \\nInteracting with multiple microse\", \"rvices to build a single UI screen increases the number of round trips \\nacross the Internet. This ap\", \"proach increases latency and complexity on the UI side. Ideally, responses \\nshould be efficiently ag\", \"gregated in the server side. This approach reduces latency, since multiple \\npieces of data come back\", \" in parallel and some UI can show data as soon as it\\u2019s ready. \\n\\u2022 \\nHow can you handle cross-cutting c\", \"oncerns such as authorization, data transformations, and \\ndynamic request dispatching? \\nImplementing\", \" security and cross-cutting concerns like security and authorization on every \\nmicroservice can requ\", \"ire significant development effort. A possible approach is to have those services \\nwithin the Docker\", \" host or internal cluster to restrict direct access to them from the outside, and to \\nimplement thos\", \"e cross-cutting concerns in a centralized place, like an API Gateway. \\n\\u2022 \\nHow can client apps commun\", \"icate with services that use non-Internet-friendly protocols? \\nProtocols used on the server side (li\", \"ke AMQP or binary protocols) are not supported in client apps. \\nTherefore, requests must be performe\", \"d through protocols like HTTP/HTTPS and translated to the \\nother protocols afterwards. A man-in-the-\", \"middle approach can help in this situation. \\n\\u2022 \\nHow can you shape a facade especially made for mobil\", \"e apps? \\nThe API of multiple microservices might not be well designed for the needs of different cli\", \"ent \\napplications. For instance, the needs of a mobile app might be different than the needs of a we\", \"b app. \\nFor mobile apps, you might need to optimize even further so that data responses can be more \", \"\\nefficient. You might do this functionality by aggregating data from multiple microservices and \\nret\", \"urning a single set of data, and sometimes eliminating any data in the response that isn\\u2019t needed \\nb\", \"y the mobile app. And, of course, you might compress that data. Again, a facade or API in between \\nt\", \"he mobile app and the microservices can be convenient for this scenario. \\nWhy consider API Gateways \", \"instead of direct client-to-microservice \\ncommunication \\nIn a microservices architecture, the client\", \" apps usually need to consume functionality from more than \\none microservice. If that consumption is\", \" performed directly, the client needs to handle multiple calls \\nto microservice endpoints. What happ\", \"ens when the application evolves and new microservices are \\nintroduced or existing microservices are\", \" updated? If your application has many microservices, \\nhandling so many endpoints from the client ap\", \"ps can be a nightmare. Since the client app would be \\ncoupled to those internal endpoints, evolving \", \"the microservices in the future can cause high impact \\nfor the client apps. \\nTherefore, having an in\", \"termediate level or tier of indirection (Gateway) can be convenient for \\nmicroservice-based applicat\", \"ions. If you don\\u2019t have API Gateways, the client apps must send requests \\ndirectly to the microservi\", \"ces and that raises problems, such as the following issues: \\n \\n42 \\nCHAPTER 3 | Architecting containe\", \"r and microservice-based applications \\n \\n\\u2022 \\nCoupling: Without the API Gateway pattern, the client ap\", \"ps are coupled to the internal \\nmicroservices. The client apps need to know how the multiple areas o\", \"f the application are \\ndecomposed in microservices. When evolving and refactoring the internal micro\", \"services, \\nthose actions impact maintenance because they cause breaking changes to the client apps \\n\", \"due to the direct reference to the internal microservices from the client apps. Client apps need \\nto\", \" be updated frequently, making the solution harder to evolve. \\n\\u2022 \\nToo many round trips: A single pag\", \"e/screen in the client app might require several calls to \\nmultiple services. That approach can resu\", \"lt in multiple network round trips between the client \\nand the server, adding significant latency. A\", \"ggregation handled in an intermediate level could \\nimprove the performance and user experience for t\", \"he client app. \\n\\u2022 \\nSecurity issues: Without a gateway, all the microservices must be exposed to the \", \"\\u201cexternal \\nworld\\u201d, making the attack surface larger than if you hide internal microservices that are\", \"n\\u2019t \\ndirectly used by the client apps. The smaller the attack surface is, the more secure your \\nappl\", \"ication can be. \\n\\u2022 \\nCross-cutting concerns: Each publicly published microservice must handle concern\", \"s such as \\nauthorization and SSL. In many situations, those concerns could be handled in a single ti\", \"er so \\nthe internal microservices are simplified. \\nWhat is the API Gateway pattern? \\nWhen you design\", \" and build large or complex microservice-based applications with multiple client \\napps, a good appro\", \"ach to consider can be an API Gateway. This pattern is a service that provides a \\nsingle-entry point\", \" for certain groups of microservices. It\\u2019s similar to the Facade pattern from object-\\noriented desig\", \"n, but in this case, it\\u2019s part of a distributed system. The API Gateway pattern is also \\nsometimes k\", \"nown as the \\u201cbackend for frontend\\u201d (BFF) because you build it while thinking about the \\nneeds of the\", \" client app. \\nTherefore, the API gateway sits between the client apps and the microservices. It acts\", \" as a reverse \\nproxy, routing requests from clients to services. It can also provide other cross-cut\", \"ting features such \\nas authentication, SSL termination, and cache. \\nFigure 4-13 shows how a custom A\", \"PI Gateway can fit into a simplified microservice-based architecture \\nwith just a few microservices.\", \" \\n \\n43 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\nFigure 4-13. Usi\", \"ng an API Gateway implemented as a custom service \\nApps connect to a single endpoint, the API Gatewa\", \"y, that\\u2019s configured to forward requests to \\nindividual microservices. In this example, the API Gate\", \"way would be implemented as a custom \\nASP.NET Core WebHost service running as a container. \\nIt\\u2019s imp\", \"ortant to highlight that in that diagram, you would be using a single custom API Gateway \\nservice fa\", \"cing multiple and different client apps. That fact can be an important risk because your API \\nGatewa\", \"y service will be growing and evolving based on many different requirements from the client \\napps. E\", \"ventually, it will be bloated because of those different needs and effectively it could be similar \\n\", \"to a monolithic application or monolithic service. That\\u2019s why it\\u2019s very much recommended to split th\", \"e \\nAPI Gateway in multiple services or multiple smaller API Gateways, one per client app form-factor\", \" \\ntype, for instance. \\nYou need to be careful when implementing the API Gateway pattern. Usually it \", \"isn\\u2019t a good idea to \\nhave a single API Gateway aggregating all the internal microservices of your a\", \"pplication. If it does, it \\nacts as a monolithic aggregator or orchestrator and violates microservic\", \"e autonomy by coupling all \\nthe microservices. \\nTherefore, the API Gateways should be segregated bas\", \"ed on business boundaries and the client apps \\nand not act as a single aggregator for all the intern\", \"al microservices. \\nWhen splitting the API Gateway tier into multiple API Gateways, if your applicati\", \"on has multiple client \\napps, that can be a primary pivot when identifying the multiple API Gateways\", \" types, so that you can \\nhave a different facade for the needs of each client app. This case is a pa\", \"ttern named \\u201cBackend for \\nFrontend\\u201d (BFF) where each API Gateway can provide a different API tailore\", \"d for each client app type, \\npossibly even based on the client form factor by implementing specific \", \"adapter code which \\nunderneath calls multiple internal microservices, as shown in the following imag\", \"e: \\n \\n44 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\nFigure 4-13.1.\", \" Using multiple custom API Gateways \\nFigure 4-13.1 shows API Gateways that are segregated by client \", \"type; one for mobile clients and one \\nfor web clients. A traditional web app connects to an MVC micr\", \"oservice that uses the web API \\nGateway. The example depicts a simplified architecture with multiple\", \" fine-grained API Gateways. In \\nthis case, the boundaries identified for each API Gateway are based \", \"purely on the \\u201cBackend for \\nFrontend\\u201d (BFF) pattern, hence based just on the API needed per client a\", \"pp. But in larger applications \\nyou should also go further and create other API Gateways based on bu\", \"siness boundaries as a second \\ndesign pivot. \\nMain features in the API Gateway pattern \\nAn API Gatew\", \"ay can offer multiple features. Depending on the product it might offer richer or simpler \\nfeatures,\", \" however, the most important and foundational features for any API Gateway are the \\nfollowing design\", \" patterns: \\nReverse proxy or gateway routing. The API Gateway offers a reverse proxy to redirect or \", \"route \\nrequests (layer 7 routing, usually HTTP requests) to the endpoints of the internal microservi\", \"ces. The \\ngateway provides a single endpoint or URL for the client apps and then internally maps the\", \" requests \\nto a group of internal microservices. This routing feature helps to decouple the client a\", \"pps from the \\nmicroservices but it\\u2019s also convenient when modernizing a monolithic API by sitting th\", \"e API Gateway \\nin between the monolithic API and the client apps, then you can add new APIs as new m\", \"icroservices \\nwhile still using the legacy monolithic API until it\\u2019s split into many microservices i\", \"n the future. Because \\nof the API Gateway, the client apps won\\u2019t notice if the APIs being used are i\", \"mplemented as internal \\nmicroservices or a monolithic API and more importantly, when evolving and re\", \"factoring the \\nmonolithic API into microservices, thanks to the API Gateway routing, client apps won\", \"\\u2019t be impacted \\nwith any URI change. \\n \\n45 \\nCHAPTER 3 | Architecting container and microservice-base\", \"d applications \\n \\nFor more information, see Gateway routing pattern. \\nRequests aggregation. As part \", \"of the gateway pattern you can aggregate multiple client requests \\n(usually HTTP requests) targeting\", \" multiple internal microservices into a single client request. This \\npattern is especially convenien\", \"t when a client page/screen needs information from several \\nmicroservices. With this approach, the c\", \"lient app sends a single request to the API Gateway that \\ndispatches several requests to the interna\", \"l microservices and then aggregates the results and sends \\neverything back to the client app. The ma\", \"in benefit and goal of this design pattern is to reduce \\nchattiness between the client apps and the \", \"backend API, which is especially important for remote \\napps out of the datacenter where the microser\", \"vices live, like mobile apps or requests coming from \\nSPA apps that come from JavaScript in client r\", \"emote browsers. For regular web apps performing the \\nrequests in the server environment (like an ASP\", \".NET Core MVC web app), this pattern is not so \\nimportant as the latency is very much smaller than f\", \"or remote client apps. \\nDepending on the API Gateway product you use, it might be able to perform th\", \"is aggregation. \\nHowever, in many cases it\\u2019s more flexible to create aggregation microservices under\", \" the scope of the \\nAPI Gateway, so you define the aggregation in code (that is, C# code): \\nFor more \", \"information, see Gateway aggregation pattern. \\nCross-cutting concerns or gateway offloading. Dependi\", \"ng on the features offered by each API \\nGateway product, you can offload functionality from individu\", \"al microservices to the gateway, which \\nsimplifies the implementation of each microservice by consol\", \"idating cross-cutting concerns into one \\ntier. This approach is especially convenient for specialize\", \"d features that can be complex to implement \\nproperly in every internal microservice, such as the fo\", \"llowing functionality: \\n\\u2022 \\nAuthentication and authorization \\n\\u2022 \\nService discovery integration \\n\\u2022 \\nRe\", \"sponse caching \\n\\u2022 \\nRetry policies, circuit breaker, and QoS \\n\\u2022 \\nRate limiting and throttling \\n\\u2022 \\nLoa\", \"d balancing \\n\\u2022 \\nLogging, tracing, correlation \\n\\u2022 \\nHeaders, query strings, and claims transformation \", \"\\n\\u2022 \\nIP allowlisting \\nFor more information, see Gateway offloading pattern. \\nUsing products with API \", \"Gateway features \\nThere can be many more cross-cutting concerns offered by the API Gateways products\", \" depending on \\neach implementation. We\\u2019ll explore here: \\n\\u2022 \\nAzure API Management \\n\\u2022 \\nOcelot \\n \\n46 \\nC\", \"HAPTER 3 | Architecting container and microservice-based applications \\n \\nAzure API Management \\nAzure\", \" API Management (as shown in Figure 4-14) not only solves your API Gateway needs but \\nprovides featu\", \"res like gathering insights from your APIs. If you\\u2019re using an API management solution, \\nan API Gate\", \"way is only a component within that full API management solution. \\n \\nFigure 4-14. Using Azure API Ma\", \"nagement for your API Gateway \\nAzure API Management solves both your API Gateway and Management need\", \"s like logging, security, \\nmetering, etc. In this case, when using a product like Azure API Manageme\", \"nt, the fact that you might \\nhave a single API Gateway is not so risky because these kinds of API Ga\", \"teways are \\u201cthinner\\u201d, meaning \\nthat you don\\u2019t implement custom C# code that could evolve towards a m\", \"onolithic component. \\nThe API Gateway products usually act like a reverse proxy for ingress communic\", \"ation, where you can \\nalso filter the APIs from the internal microservices plus apply authorization \", \"to the published APIs in \\nthis single tier. \\nThe insights available from an API Management system he\", \"lp you get an understanding of how your \\nAPIs are being used and how they are performing. They do th\", \"is activity by letting you view near real-\\ntime analytics reports and identifying trends that might \", \"impact your business. Plus, you can have logs \\nabout request and response activity for further onlin\", \"e and offline analysis. \\nWith Azure API Management, you can secure your APIs using a key, a token, a\", \"nd IP filtering. These \\nfeatures let you enforce flexible and fine-grained quotas and rate limits, m\", \"odify the shape and \\nbehavior of your APIs using policies, and improve performance with response cac\", \"hing. \\nIn this guide and the reference sample application (eShopOnContainers), the architecture is l\", \"imited to \\na simpler and custom-made containerized architecture in order to focus on plain container\", \"s without \\n \\n47 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nusing Paa\", \"S products like Azure API Management. But for large microservice-based applications that \\nare deploy\", \"ed into Microsoft Azure, we encourage you to evaluate Azure API Management as the base \\nfor your API\", \" Gateways in production. \\nOcelot \\nOcelot is a lightweight API Gateway, recommended for simpler appro\", \"aches. Ocelot is an Open Source \\n.NET Core-based API Gateway especially made for microservices archi\", \"tectures that need unified points \\nof entry into their systems. It\\u2019s lightweight, fast, and scalable\", \" and provides routing and authentication \\namong many other features. \\nThe main reason to choose Ocel\", \"ot for the eShopOnContainers reference application 2.0 is because \\nOcelot is a .NET Core lightweight\", \" API Gateway that you can deploy into the same application \\ndeployment environment where you\\u2019re depl\", \"oying your microservices/containers, such as a Docker \\nHost, Kubernetes, etc. And since it\\u2019s based o\", \"n .NET Core, it\\u2019s cross-platform allowing you to deploy on \\nLinux or Windows. \\nThe previous diagrams\", \" showing custom API Gateways running in containers are precisely how you can \\nalso run Ocelot in a c\", \"ontainer and microservice-based application. \\nIn addition, there are many other products in the mark\", \"et offering API Gateways features, such as \\nApigee, Kong, MuleSoft, WSO2, and other products like Li\", \"nkerd and Istio for service mesh ingress \\ncontroller features. \\nAfter the initial architecture and p\", \"atterns explanation sections, the next sections explain how to \\nimplement API Gateways with Ocelot. \", \"\\nDrawbacks of the API Gateway pattern \\n\\u2022 \\nThe most important drawback is that when you implement an \", \"API Gateway, you\\u2019re coupling \\nthat tier with the internal microservices. Coupling like this might in\", \"troduce serious difficulties \\nfor your application. Clemens Vaster, architect at the Azure Service B\", \"us team, refers to this \\npotential difficulty as \\u201cthe new ESB\\u201d in the \\u201cMessaging and Microservices\\u201d \", \"session at GOTO \\n2016. \\n\\u2022 \\nUsing a microservices API Gateway creates an additional possible single p\", \"oint of failure. \\n\\u2022 \\nAn API Gateway can introduce increased response time due to the additional netw\", \"ork call. \\nHowever, this extra call usually has less impact than having a client interface that\\u2019s to\", \"o chatty \\ndirectly calling the internal microservices. \\n\\u2022 \\nIf not scaled out properly, the API Gatew\", \"ay can become a bottleneck. \\n\\u2022 \\nAn API Gateway requires additional development cost and future maint\", \"enance if it includes \\ncustom logic and data aggregation. Developers must update the API Gateway in \", \"order to \\nexpose each microservice\\u2019s endpoints. Moreover, implementation changes in the internal \\nmi\", \"croservices might cause code changes at the API Gateway level. However, if the API \\nGateway is just \", \"applying security, logging, and versioning (as when using Azure API \\nManagement), this additional de\", \"velopment cost might not apply. \\n \\n48 \\nCHAPTER 3 | Architecting container and microservice-based app\", \"lications \\n \\n\\u2022 \\nIf the API Gateway is developed by a single team, there can be a development bottlen\", \"eck. This \\naspect is another reason why a better approach is to have several fined-grained API Gatew\", \"ays \\nthat respond to different client needs. You could also segregate the API Gateway internally \\nin\", \"to multiple areas or layers that are owned by the different teams working on the internal \\nmicroserv\", \"ices. \\nAdditional resources \\n\\u2022 \\nChris Richardson. Pattern: API Gateway / Backend for Front-End \\nhttp\", \"s://microservices.io/patterns/apigateway.html \\n\\u2022 \\nAPI Gateway pattern \\nhttps://learn.microsoft.com/a\", \"zure/architecture/microservices/gateway \\n\\u2022 \\nAggregation and composition pattern \\nhttps://microservic\", \"es.io/patterns/data/api-composition.html \\n\\u2022 \\nAzure API Management \\nhttps://azure.microsoft.com/servi\", \"ces/api-management/ \\n\\u2022 \\nUdi Dahan. Service Oriented Composition \\nhttps://udidahan.com/2014/07/30/ser\", \"vice-oriented-composition-with-video/ \\n\\u2022 \\nClemens Vasters. Messaging and Microservices at GOTO 2016 \", \"(video) \\nhttps://www.youtube.com/watch?v=rXi5CLjIQ9k \\n\\u2022 \\nAPI Gateway in a Nutshell (ASP.NET Core API\", \" Gateway Tutorial Series) \\nhttps://www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.html \\nCommunic\", \"ation in a microservice architecture \\nIn a monolithic application running on a single process, compo\", \"nents invoke one another using \\nlanguage-level method or function calls. These can be strongly coupl\", \"ed if you\\u2019re creating objects with \\ncode (for example, new ClassName()), or can be invoked in a deco\", \"upled way if you\\u2019re using \\nDependency Injection by referencing abstractions rather than concrete obj\", \"ect instances. Either way, \\nthe objects are running within the same process. The biggest challenge w\", \"hen changing from a \\nmonolithic application to a microservices-based application lies in changing th\", \"e communication \\nmechanism. A direct conversion from in-process method calls into RPC calls to servi\", \"ces will cause a \\nchatty and not efficient communication that won\\u2019t perform well in distributed envi\", \"ronments. The \\nchallenges of designing distributed system properly are well enough known that there\\u2019\", \"s even a canon \\nknown as the Fallacies of distributed computing that lists assumptions that develope\", \"rs often make \\nwhen moving from monolithic to distributed designs. \\nThere isn\\u2019t one solution, but se\", \"veral. One solution involves isolating the business microservices as \\nmuch as possible. You then use\", \" asynchronous communication between the internal microservices and \\nreplace fine-grained communicati\", \"on that\\u2019s typical in intra-process communication between objects \\nwith coarser-grained communication\", \". You can do this by grouping calls, and by returning data that \\naggregates the results of multiple \", \"internal calls, to the client. \\n \\n49 \\nCHAPTER 3 | Architecting container and microservice-based appl\", \"ications \\n \\nA microservices-based application is a distributed system running on multiple processes \", \"or services, \\nusually even across multiple servers or hosts. Each service instance is typically a pr\", \"ocess. Therefore, \\nservices must interact using an inter-process communication protocol such as HTTP\", \", AMQP, or a \\nbinary protocol like TCP, depending on the nature of each service. \\nThe microservice c\", \"ommunity promotes the philosophy of \\u201csmart endpoints and dumb pipes\\u201d. This \\nslogan encourages a desi\", \"gn that\\u2019s as decoupled as possible between microservices, and as cohesive \\nas possible within a sing\", \"le microservice. As explained earlier, each microservice owns its own data and \\nits own domain logic\", \". But the microservices composing an end-to-end application are usually simply \\nchoreographed by usi\", \"ng REST communications rather than complex protocols such as WS-* and \\nflexible event-driven communi\", \"cations instead of centralized business-process-orchestrators. \\nThe two commonly used protocols are \", \"HTTP request/response with resource APIs (when querying \\nmost of all), and lightweight asynchronous \", \"messaging when communicating updates across multiple \\nmicroservices. These are explained in more det\", \"ail in the following sections. \\nCommunication types \\nClient and services can communicate through man\", \"y different types of communication, each one \\ntargeting a different scenario and goals. Initially, t\", \"hose types of communications can be classified in \\ntwo axes. \\nThe first axis defines if the protocol\", \" is synchronous or asynchronous: \\n\\u2022 \\nSynchronous protocol. HTTP is a synchronous protocol. The clien\", \"t sends a request and waits \\nfor a response from the service. That\\u2019s independent of the client code \", \"execution that could be \\nsynchronous (thread is blocked) or asynchronous (thread isn\\u2019t blocked, and \", \"the response will \\nreach a callback eventually). The important point here is that the protocol (HTTP\", \"/HTTPS) is \\nsynchronous and the client code can only continue its task when it receives the HTTP ser\", \"ver \\nresponse. \\n\\u2022 \\nAsynchronous protocol. Other protocols like AMQP (a protocol supported by many op\", \"erating \\nsystems and cloud environments) use asynchronous messages. The client code or message \\nsend\", \"er usually doesn\\u2019t wait for a response. It just sends the message as when sending a \\nmessage to a Ra\", \"bbitMQ queue or any other message broker. \\nThe second axis defines if the communication has a single\", \" receiver or multiple receivers: \\n\\u2022 \\nSingle receiver. Each request must be processed by exactly one \", \"receiver or service. An \\nexample of this communication is the Command pattern. \\n\\u2022 \\nMultiple receiver\", \"s. Each request can be processed by zero to multiple receivers. This type of \\ncommunication must be \", \"asynchronous. An example is the publish/subscribe mechanism used \\nin patterns like Event-driven arch\", \"itecture. This is based on an event-bus interface or message \\nbroker when propagating data updates b\", \"etween multiple microservices through events; it\\u2019s \\nusually implemented through a service bus or sim\", \"ilar artifact like Azure Service Bus by using \\ntopics and subscriptions. \\n \\n50 \\nCHAPTER 3 | Architec\", \"ting container and microservice-based applications \\n \\nA microservice-based application will often us\", \"e a combination of these communication styles. The \\nmost common type is single-receiver communicatio\", \"n with a synchronous protocol like HTTP/HTTPS \\nwhen invoking a regular Web API HTTP service. Microse\", \"rvices also typically use messaging protocols \\nfor asynchronous communication between microservices.\", \" \\nThese axes are good to know so you have clarity on the possible communication mechanisms, but \\nthe\", \"y\\u2019re not the important concerns when building microservices. Neither the asynchronous nature of \\ncli\", \"ent thread execution nor the asynchronous nature of the selected protocol are the important points \\n\", \"when integrating microservices. What is important is being able to integrate your microservices \\nasy\", \"nchronously while maintaining the independence of microservices, as explained in the following \\nsect\", \"ion. \\nAsynchronous microservice integration enforces microservice\\u2019s \\nautonomy \\nAs mentioned, the imp\", \"ortant point when building a microservices-based application is the way you \\nintegrate your microser\", \"vices. Ideally, you should try to minimize the communication between the \\ninternal microservices. Th\", \"e fewer communications between microservices, the better. But in many \\ncases, you\\u2019ll have to somehow\", \" integrate the microservices. When you need to do that, the critical rule \\nhere is that the communic\", \"ation between the microservices should be asynchronous. That doesn\\u2019t \\nmean that you have to use a sp\", \"ecific protocol (for example, asynchronous messaging versus \\nsynchronous HTTP). It just means that t\", \"he communication between microservices should be done only \\nby propagating data asynchronously, but \", \"try not to depend on other internal microservices as part of \\nthe initial service\\u2019s HTTP request/res\", \"ponse operation. \\nIf possible, never depend on synchronous communication (request/response) between \", \"multiple \\nmicroservices, not even for queries. The goal of each microservice is to be autonomous and\", \" available \\nto the client consumer, even if the other services that are part of the end-to-end appli\", \"cation are down \\nor unhealthy. If you think you need to make a call from one microservice to other m\", \"icroservices (like \\nperforming an HTTP request for a data query) to be able to provide a response to\", \" a client application, \\nyou have an architecture that won\\u2019t be resilient when some microservices fai\", \"l. \\nMoreover, having HTTP dependencies between microservices, like when creating long \\nrequest/respo\", \"nse cycles with HTTP request chains, as shown in the first part of the Figure 4-15, not \\nonly makes \", \"your microservices not autonomous but also their performance is impacted as soon as \\none of the serv\", \"ices in that chain isn\\u2019t performing well. \\nThe more you add synchronous dependencies between microse\", \"rvices, such as query requests, the \\nworse the overall response time gets for the client apps. \\n \\n51\", \" \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\nFigure 4-15. Anti-patt\", \"erns and patterns in communication between microservices \\nAs shown in the above diagram, in synchron\", \"ous communication a \\u201cchain\\u201d of requests is created \\nbetween microservices while serving the client r\", \"equest. This is an anti-pattern. In asynchronous \\ncommunication microservices use asynchronous messa\", \"ges or http polling to communicate with other \\nmicroservices, but the client request is served right\", \" away. \\nIf your microservice needs to raise an additional action in another microservice, if possibl\", \"e, do not \\nperform that action synchronously and as part of the original microservice request and re\", \"ply \\noperation. Instead, do it asynchronously (using asynchronous messaging or integration events, \\n\", \"queues, etc.). But, as much as possible, do not invoke the action synchronously as part of the origi\", \"nal \\nsynchronous request and reply operation. \\nAnd finally (and this is where most of the issues ari\", \"se when building microservices), if your initial \\nmicroservice needs data that\\u2019s originally owned by\", \" other microservices, do not rely on making \\nsynchronous requests for that data. Instead, replicate \", \"or propagate that data (only the attributes you \\nneed) into the initial service\\u2019s database by using \", \"eventual consistency (typically by using integration \\nevents, as explained in upcoming sections). \\nA\", \"s noted earlier in the Identifying domain-model boundaries for each microservice section, \\nduplicati\", \"ng some data across several microservices isn\\u2019t an incorrect design\\u2014on the contrary, when \\ndoing tha\", \"t you can translate the data into the specific language or terms of that additional domain or \\nBound\", \"ed Context. For instance, in the eShopOnContainers application you have a microservice named \\nidenti\", \"ty-api that\\u2019s in charge of most of the user\\u2019s data with an entity named User. However, when you \\nnee\", \"d to store data about the user within the Ordering microservice, you store it as a different entity \", \"\\nnamed Buyer. The Buyer entity shares the same identity with the original User entity, but it might \", \"have \\nonly the few attributes needed by the Ordering domain, and not the whole user profile. \\n \\n52 \\n\", \"CHAPTER 3 | Architecting container and microservice-based applications \\n \\nYou might use any protocol\", \" to communicate and propagate data asynchronously across microservices \\nin order to have eventual co\", \"nsistency. As mentioned, you could use integration events using an event \\nbus or message broker or y\", \"ou could even use HTTP by polling the other services instead. It doesn\\u2019t \\nmatter. The important rule\", \" is to not create synchronous dependencies between your microservices. \\nThe following sections expla\", \"in the multiple communication styles you can consider using in a \\nmicroservice-based application. \\nC\", \"ommunication styles \\nThere are many protocols and choices you can use for communication, depending o\", \"n the \\ncommunication type you want to use. If you\\u2019re using a synchronous request/response-based \\ncom\", \"munication mechanism, protocols such as HTTP and REST approaches are the most common, \\nespecially if\", \" you\\u2019re publishing your services outside the Docker host or microservice cluster. If you\\u2019re \\ncommuni\", \"cating between services internally (within your Docker host or microservices cluster), you \\nmight al\", \"so want to use binary format communication mechanisms (like WCF using TCP and binary \\nformat). Alter\", \"natively, you can use asynchronous, message-based communication mechanisms such as \\nAMQP. \\nThere are\", \" also multiple message formats like JSON or XML, or even binary formats, which can be more \\nefficien\", \"t. If your chosen binary format isn\\u2019t a standard, it\\u2019s probably not a good idea to publicly \\npublish\", \" your services using that format. You could use a non-standard format for internal \\ncommunication be\", \"tween your microservices. You might do this when communicating between \\nmicroservices within your Do\", \"cker host or microservice cluster (for example, Docker orchestrators), or \\nfor proprietary client ap\", \"plications that talk to the microservices. \\nRequest/response communication with HTTP and REST \\nWhen \", \"a client uses request/response communication, it sends a request to a service, then the service \\npro\", \"cesses the request and sends back a response. Request/response communication is especially well \\nsui\", \"ted for querying data for a real-time UI (a live user interface) from client apps. Therefore, in a \\n\", \"microservice architecture you\\u2019ll probably use this communication mechanism for most queries, as \\nsho\", \"wn in Figure 4-16. \\n \\nFigure 4-16. Using HTTP request/response communication (synchronous or asynchr\", \"onous) \\n \\n53 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nWhen a clien\", \"t uses request/response communication, it assumes that the response will arrive in a \\nshort time, ty\", \"pically less than a second, or a few seconds at most. For delayed responses, you need to \\nimplement \", \"asynchronous communication based on messaging patterns and messaging technologies, \\nwhich is a diffe\", \"rent approach that we explain in the next section. \\nA popular architectural style for request/respon\", \"se communication is REST. This approach is based on, \\nand tightly coupled to, the HTTP protocol, emb\", \"racing HTTP verbs like GET, POST, and PUT. REST is the \\nmost commonly used architectural communicati\", \"on approach when creating services. You can \\nimplement REST services when you develop ASP.NET Core W\", \"eb API services. \\nThere\\u2019s additional value when using HTTP REST services as your interface definitio\", \"n language. For \\ninstance, if you use Swagger metadata to describe your service API, you can use too\", \"ls that generate \\nclient stubs that can directly discover and consume your services. \\nAdditional res\", \"ources \\n\\u2022 \\nMartin Fowler. Richardson Maturity Model A description of the REST model. \\nhttps://martin\", \"fowler.com/articles/richardsonMaturityModel.html \\n\\u2022 \\nSwagger The official site. \\nhttps://swagger.io/\", \" \\nPush and real-time communication based on HTTP \\nAnother possibility (usually for different purpose\", \"s than REST) is a real-time and one-to-many \\ncommunication with higher-level frameworks such as ASP.\", \"NET SignalR and protocols such as \\nWebSockets. \\nAs Figure 4-17 shows, real-time HTTP communication m\", \"eans that you can have server code pushing \\ncontent to connected clients as the data becomes availab\", \"le, rather than having the server wait for a \\nclient to request new data. \\n \\n54 \\nCHAPTER 3 | Archite\", \"cting container and microservice-based applications \\n \\n \\nFigure 4-17. One-to-many real-time asynchro\", \"nous message communication \\nSignalR is a good way to achieve real-time communication for pushing con\", \"tent to the clients from a \\nback-end server. Since communication is in real time, client apps show t\", \"he changes almost instantly. \\nThis is usually handled by a protocol such as WebSockets, using many W\", \"ebSockets connections (one \\nper client). A typical example is when a service communicates a change i\", \"n the score of a sports game \\nto many client web apps simultaneously. \\nAsynchronous message-based co\", \"mmunication \\nAsynchronous messaging and event-driven communication are critical when propagating cha\", \"nges \\nacross multiple microservices and their related domain models. As mentioned earlier in the dis\", \"cussion \\nmicroservices and Bounded Contexts (BCs), models (User, Customer, Product, Account, etc.) c\", \"an mean \\ndifferent things to different microservices or BCs. That means that when changes occur, you\", \" need \\nsome way to reconcile changes across the different models. A solution is eventual consistency\", \" and \\nevent-driven communication based on asynchronous messaging. \\nWhen using messaging, processes c\", \"ommunicate by exchanging messages asynchronously. A client \\nmakes a command or a request to a servic\", \"e by sending it a message. If the service needs to reply, it \\nsends a different message back to the \", \"client. Since it\\u2019s a message-based communication, the client \\nassumes that the reply won\\u2019t be receiv\", \"ed immediately, and that there might be no response at all. \\nA message is composed by a header (meta\", \"data such as identification or security information) and a \\nbody. Messages are usually sent through \", \"asynchronous protocols like AMQP. \\nThe preferred infrastructure for this type of communication in th\", \"e microservices community is a \\nlightweight message broker, which is different than the large broker\", \"s and orchestrators used in SOA. \\nIn a lightweight message broker, the infrastructure is typically \\u201c\", \"dumb,\\u201d acting only as a message \\nbroker, with simple implementations such as RabbitMQ or a scalable \", \"service bus in the cloud like \\n \\n55 \\nCHAPTER 3 | Architecting container and microservice-based appli\", \"cations \\n \\nAzure Service Bus. In this scenario, most of the \\u201csmart\\u201d thinking still lives in the endp\", \"oints that are \\nproducing and consuming messages-that is, in the microservices. \\nAnother rule you sh\", \"ould try to follow, as much as possible, is to use only asynchronous messaging \\nbetween the internal\", \" services, and to use synchronous communication (such as HTTP) only from the \\nclient apps to the fro\", \"nt-end services (API Gateways plus the first level of microservices). \\nThere are two kinds of asynch\", \"ronous messaging communication: single receiver message-based \\ncommunication, and multiple receivers\", \" message-based communication. The following sections \\nprovide details about them. \\nSingle-receiver m\", \"essage-based communication \\nMessage-based asynchronous communication with a single receiver means th\", \"ere\\u2019s point-to-point \\ncommunication that delivers a message to exactly one of the consumers that\\u2019s r\", \"eading from the \\nchannel, and that the message is processed just once. However, there are special si\", \"tuations. For \\ninstance, in a cloud system that tries to automatically recover from failures, the sa\", \"me message could \\nbe sent multiple times. Due to network or other failures, the client has to be abl\", \"e to retry sending \\nmessages, and the server has to implement an operation to be idempotent in order\", \" to process a \\nparticular message just once. \\nSingle-receiver message-based communication is especia\", \"lly well suited for sending asynchronous \\ncommands from one microservice to another as shown in Figu\", \"re 4-18 that illustrates this approach. \\nOnce you start sending message-based communication (either \", \"with commands or events), you should \\navoid mixing message-based communication with synchronous HTTP\", \" communication. \\n \\nFigure 4-18. A single microservice receiving an asynchronous message \\n \\n56 \\nCHAPT\", \"ER 3 | Architecting container and microservice-based applications \\n \\nWhen the commands come from cli\", \"ent applications, they can be implemented as HTTP synchronous \\ncommands. Use message-based commands \", \"when you need higher scalability or when you\\u2019re already \\nin a message-based business process. \\nMulti\", \"ple-receivers message-based communication \\nAs a more flexible approach, you might also want to use a\", \" publish/subscribe mechanism so that your \\ncommunication from the sender will be available to additi\", \"onal subscriber microservices or to external \\napplications. Thus, it helps you to follow the open/cl\", \"osed principle in the sending service. That way, \\nadditional subscribers can be added in the future \", \"without the need to modify the sender service. \\nWhen you use a publish/subscribe communication, you \", \"might be using an event bus interface to \\npublish events to any subscriber. \\nAsynchronous event-driv\", \"en communication \\nWhen using asynchronous event-driven communication, a microservice publishes an in\", \"tegration event \\nwhen something happens within its domain and another microservice needs to be aware\", \" of it, like a \\nprice change in a product catalog microservice. Additional microservices subscribe t\", \"o the events so \\nthey can receive them asynchronously. When that happens, the receivers might update\", \" their own \\ndomain entities, which can cause more integration events to be published. This publish/s\", \"ubscribe \\nsystem is performed by using an implementation of an event bus. The event bus can be desig\", \"ned as \\nan abstraction or interface, with the API that\\u2019s needed to subscribe or unsubscribe to event\", \"s and to \\npublish events. The event bus can also have one or more implementations based on any inter\", \"-process \\nand messaging broker, like a messaging queue or service bus that supports asynchronous \\nco\", \"mmunication and a publish/subscribe model. \\nIf a system uses eventual consistency driven by integrat\", \"ion events, it\\u2019s recommended that this \\napproach is made clear to the end user. The system shouldn\\u2019t\", \" use an approach that mimics \\nintegration events, like SignalR or polling systems from the client. T\", \"he end user and the business \\nowner have to explicitly embrace eventual consistency in the system an\", \"d realize that in many cases \\nthe business doesn\\u2019t have any problem with this approach, as long as i\", \"t\\u2019s explicit. This approach is \\nimportant because users might expect to see some results immediately\", \" and this aspect might not \\nhappen with eventual consistency. \\nAs noted earlier in the Challenges an\", \"d solutions for distributed data management section, you can use \\nintegration events to implement bu\", \"siness tasks that span multiple microservices. Thus, you\\u2019ll have \\neventual consistency between those\", \" services. An eventually consistent transaction is made up of a \\ncollection of distributed actions. \", \"At each action, the related microservice updates a domain entity and \\npublishes another integration \", \"event that raises the next action within the same end-to-end business \\ntask. \\nAn important point is \", \"that you might want to communicate to multiple microservices that are \\nsubscribed to the same event.\", \" To do so, you can use publish/subscribe messaging based on event-\\ndriven communication, as shown in\", \" Figure 4-19. This publish/subscribe mechanism isn\\u2019t exclusive to \\nthe microservice architecture. It\", \"\\u2019s similar to the way Bounded Contexts in DDD should communicate, \\nor to the way you propagate updat\", \"es from the write database to the read database in the Command \\n \\n57 \\nCHAPTER 3 | Architecting conta\", \"iner and microservice-based applications \\n \\nand Query Responsibility Segregation (CQRS) architecture\", \" pattern. The goal is to have eventual \\nconsistency between multiple data sources across your distri\", \"buted system. \\n \\nFigure 4-19. Asynchronous event-driven message communication \\nIn asynchronous event\", \"-driven communication, one microservice publishes events to an event bus and \\nmany microservices can\", \" subscribe to it, to get notified and act on it. Your implementation will \\ndetermine what protocol t\", \"o use for event-driven, message-based communications. AMQP can help \\nachieve reliable queued communi\", \"cation. \\nWhen you use an event bus, you might want to use an abstraction level (like an event bus in\", \"terface) \\nbased on a related implementation in classes with code using the API from a message broker\", \" like \\nRabbitMQ or a service bus like Azure Service Bus with Topics. Alternatively, you might want t\", \"o use a \\nhigher-level service bus like NServiceBus, MassTransit, or Brighter to articulate your even\", \"t bus and \\npublish/subscribe system. \\nA note about messaging technologies for production systems \\nTh\", \"e messaging technologies available for implementing your abstract event bus are at different levels.\", \" \\nFor instance, products like RabbitMQ (a messaging broker transport) and Azure Service Bus sit at a\", \" \\nlower level than other products like NServiceBus, MassTransit, or Brighter, which can work on top \", \"of \\nRabbitMQ and Azure Service Bus. Your choice depends on how many rich features at the application\", \" \\nlevel and out-of-the-box scalability you need for your application. For implementing just a proof-\", \"of-\\nconcept event bus for your development environment, as it was done in the eShopOnContainers \\nsam\", \"ple, a simple implementation on top of RabbitMQ running on a Docker container might be \\nenough. \\nHow\", \"ever, for mission-critical and production systems that need hyper-scalability, you might want to \\nev\", \"aluate Azure Service Bus. For high-level abstractions and features that make the development of \\ndis\", \"tributed applications easier, we recommend that you evaluate other commercial and open-source \\nservi\", \"ce buses, such as NServiceBus, MassTransit, and Brighter. Of course, you can build your own \\n \\n58 \\nC\", \"HAPTER 3 | Architecting container and microservice-based applications \\n \\nservice-bus features on top\", \" of lower-level technologies like RabbitMQ and Docker. But that plumbing \\nwork might cost too much f\", \"or a custom enterprise application. \\nResiliently publishing to the event bus \\nA challenge when imple\", \"menting an event-driven architecture across multiple microservices is how to \\natomically update stat\", \"e in the original microservice while resiliently publishing its related integration \\nevent into the \", \"event bus, somehow based on transactions. The following are a few ways to accomplish \\nthis functiona\", \"lity, although there could be additional approaches as well. \\n\\u2022 \\nUsing a transactional (DTC-based) q\", \"ueue like MSMQ. (However, this is a legacy approach.) \\n\\u2022 \\nUsing transaction log mining. \\n\\u2022 \\nUsing fu\", \"ll Event Sourcing pattern. \\n\\u2022 \\nUsing the Outbox pattern: a transactional database table as a message\", \" queue that will be the \\nbase for an event-creator component that would create the event and publish\", \" it. \\nFor a more complete description of the challenges in this space, including how messages with \\n\", \"potentially incorrect data can end up being published, see Data platform for mission-critical \\nworkl\", \"oads on Azure: Every message must be processed. \\nAdditional topics to consider when using asynchrono\", \"us communication are message idempotence \\nand message deduplication. These topics are covered in the\", \" section Implementing event-based \\ncommunication between microservices (integration events) later in\", \" this guide. \\nAdditional resources \\n\\u2022 \\nEvent Driven Messaging \\nhttps://patterns.arcitura.com/soa-pat\", \"terns/design_patterns/event_driven_messaging \\n\\u2022 \\nPublish/Subscribe Channel \\nhttps://www.enterprisein\", \"tegrationpatterns.com/patterns/messaging/PublishSubscribeChannel.\\nhtml \\n\\u2022 \\nUdi Dahan. Clarified CQRS\", \" \\nhttps://udidahan.com/2009/12/09/clarified-cqrs/ \\n\\u2022 \\nCommand and Query Responsibility Segregation (\", \"CQRS) \\nhttps://learn.microsoft.com/azure/architecture/patterns/cqrs \\n\\u2022 \\nCommunicating Between Bounde\", \"d Contexts \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/jj591572(v=pandp.10) \\n\\u2022 \\nEventual \", \"consistency \\nhttps://en.wikipedia.org/wiki/Eventual_consistency \\n\\u2022 \\nJimmy Bogard. Refactoring Toward\", \"s Resilience: Evaluating Coupling \\nhttps://jimmybogard.com/refactoring-towards-resilience-evaluating\", \"-coupling/ \\n \\n59 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nCreating\", \", evolving, and versioning microservice APIs \\nand contracts \\nA microservice API is a contract betwee\", \"n the service and its clients. You\\u2019ll be able to evolve a \\nmicroservice independently only if you do\", \" not break its API contract, which is why the contract is so \\nimportant. If you change the contract,\", \" it will impact your client applications or your API Gateway. \\nThe nature of the API definition depe\", \"nds on which protocol you\\u2019re using. For instance, if you\\u2019re using \\nmessaging, like AMQP, the API con\", \"sists of the message types. If you\\u2019re using HTTP and RESTful \\nservices, the API consists of the URLs\", \" and the request and response JSON formats. \\nHowever, even if you\\u2019re thoughtful about your initial c\", \"ontract, a service API will need to change over \\ntime. When that happens\\u2014and especially if your API \", \"is a public API consumed by multiple client \\napplications \\u2014 you typically can\\u2019t force all clients to\", \" upgrade to your new API contract. You usually \\nneed to incrementally deploy new versions of a servi\", \"ce in a way that both old and new versions of a \\nservice contract are running simultaneously. Theref\", \"ore, it\\u2019s important to have a strategy for your \\nservice versioning. \\nWhen the API changes are small\", \", like if you add attributes or parameters to your API, clients that use \\nan older API should switch\", \" and work with the new version of the service. You might be able to provide \\ndefault values for any \", \"missing attributes that are required, and the clients might be able to ignore any \\nextra response at\", \"tributes. \\nHowever, sometimes you need to make major and incompatible changes to a service API. Beca\", \"use \\nyou might not be able to force client applications or services to upgrade immediately to the ne\", \"w \\nversion, a service must support older versions of the API for some period. If you\\u2019re using an HTT\", \"P-\\nbased mechanism such as REST, one approach is to embed the API version number in the URL or into \", \"\\nan HTTP header. Then you can decide between implementing both versions of the service \\nsimultaneous\", \"ly within the same service instance, or deploying different instances that each handle a \\nversion of\", \" the API. A good approach for this functionality is the Mediator pattern (for example, \\nMediatR libr\", \"ary) to decouple the different implementation versions into independent handlers. \\nFinally, if you\\u2019r\", \"e using a REST architecture, Hypermedia is the best solution for versioning your services \\nand allow\", \"ing evolvable APIs. \\nAdditional resources \\n\\u2022 \\nScott Hanselman. ASP.NET Core RESTful Web API versioni\", \"ng made easy \\nhttps://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx \\n\\u2022 \\nVers\", \"ioning a RESTful web API \\nhttps://learn.microsoft.com/azure/architecture/best-practices/api-design#v\", \"ersioning-a-\\nrestful-web-api \\n\\u2022 \\nRoy Fielding. Versioning, Hypermedia, and REST \\nhttps://www.infoq.c\", \"om/articles/roy-fielding-on-versioning \\n \\n60 \\nCHAPTER 3 | Architecting container and microservice-ba\", \"sed applications \\n \\nMicroservices addressability and the service registry \\nEach microservice has a u\", \"nique name (URL) that\\u2019s used to resolve its location. Your microservice needs \\nto be addressable whe\", \"rever it\\u2019s running. If you have to think about which computer is running a \\nparticular microservice,\", \" things can go bad quickly. In the same way that DNS resolves a URL to a \\nparticular computer, your \", \"microservice needs to have a unique name so that its current location is \\ndiscoverable. Microservice\", \"s need addressable names that make them independent from the \\ninfrastructure that they\\u2019re running on\", \". This approach implies that there\\u2019s an interaction between how \\nyour service is deployed and how it\", \"\\u2019s discovered, because there needs to be a service registry. In the \\nsame vein, when a computer fail\", \"s, the registry service must be able to indicate where the service is \\nnow running. \\nThe service reg\", \"istry pattern is a key part of service discovery. The registry is a database containing the \\nnetwork\", \" locations of service instances. A service registry needs to be highly available and up-to-date. \\nCl\", \"ients could cache network locations obtained from the service registry. However, that information \\ne\", \"ventually goes out of date and clients can no longer discover service instances. So, a service regis\", \"try \\nconsists of a cluster of servers that use a replication protocol to maintain consistency. \\nIn s\", \"ome microservice deployment environments (called clusters, to be covered in a later section), \\nservi\", \"ce discovery is built in. For example, an Azure Kubernetes Service (AKS) environment can handle \\nser\", \"vice instance registration and deregistration. It also runs a proxy on each cluster host that plays \", \"the \\nrole of server-side discovery router. \\nAdditional resources \\n\\u2022 \\nChris Richardson. Pattern: Serv\", \"ice registry \\nhttps://microservices.io/patterns/service-registry.html \\n\\u2022 \\nAuth0. The Service Registr\", \"y \\nhttps://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-registry/ \\n\\u2022 \\nGabriel \", \"Schenker. Service discovery \\nhttps://lostechies.com/gabrielschenker/2016/01/27/service-discovery/ \\nC\", \"reating composite UI based on microservices \\nMicroservices architecture often starts with the server\", \"-side handling data and logic, but, in many \\ncases, the UI is still handled as a monolith. However, \", \"a more advanced approach, called micro \\nfrontends, is to design your application UI based on microse\", \"rvices as well. That means having a \\ncomposite UI produced by the microservices, instead of having m\", \"icroservices on the server and just a \\nmonolithic client app consuming the microservices. With this \", \"approach, the microservices you build \\ncan be complete with both logic and visual representation. \\nF\", \"igure 4-20 shows the simpler approach of just consuming microservices from a monolithic client \\nappl\", \"ication. Of course, you could have an ASP.NET MVC service in between producing the HTML and \\nJavaScr\", \"ipt. The figure is a simplification that highlights that you have a single (monolithic) client UI \\n \", \"\\n61 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nconsuming the microse\", \"rvices, which just focus on logic and data and not on the UI shape (HTML and \\nJavaScript). \\n \\nFigure\", \" 4-20. A monolithic UI application consuming back-end microservices \\nIn contrast, a composite UI is \", \"precisely generated and composed by the microservices themselves. \\nSome of the microservices drive t\", \"he visual shape of specific areas of the UI. The key difference is that \\nyou have client UI componen\", \"ts (TypeScript classes, for example) based on templates, and the data-\\nshaping-UI ViewModel for thos\", \"e templates comes from each microservice. \\nAt client application start-up time, each of the client U\", \"I components (TypeScript classes, for example) \\nregisters itself with an infrastructure microservice\", \" capable of providing ViewModels for a given \\nscenario. If the microservice changes the shape, the U\", \"I changes also. \\nFigure 4-21 shows a version of this composite UI approach. This approach is simplif\", \"ied because you \\nmight have other microservices that are aggregating granular parts that are based o\", \"n different \\ntechniques. It depends on whether you\\u2019re building a traditional web approach (ASP.NET M\", \"VC) or an \\nSPA (Single Page Application). \\n \\n62 \\nCHAPTER 3 | Architecting container and microservice\", \"-based applications \\n \\n \\nFigure 4-21. Example of a composite UI application shaped by back-end micro\", \"services \\nEach of those UI composition microservices would be similar to a small API Gateway. But in\", \" this case, \\neach one is responsible for a small UI area. \\nA composite UI approach that\\u2019s driven by \", \"microservices can be more challenging or less so, \\ndepending on what UI technologies you\\u2019re using. F\", \"or instance, you won\\u2019t use the same techniques for \\nbuilding a traditional web application that you \", \"use for building an SPA or for native mobile app (as \\nwhen developing Xamarin apps, which can be mor\", \"e challenging for this approach). \\nThe eShopOnContainers sample application uses the monolithic UI a\", \"pproach for multiple reasons. \\nFirst, it\\u2019s an introduction to microservices and containers. A compos\", \"ite UI is more advanced but also \\nrequires further complexity when designing and developing the UI. \", \"Second, eShopOnContainers also \\nprovides a native mobile app based on Xamarin, which would make it m\", \"ore complex on the client C# \\nside. \\nHowever, we encourage you to use the following references to le\", \"arn more about composite UI based \\non microservices. \\nAdditional resources \\n\\u2022 \\nMicro Frontends (Mart\", \"in Fowler\\u2019s blog) \\nhttps://martinfowler.com/articles/micro-frontends.html \\n\\u2022 \\nMicro Frontends (Micha\", \"el Geers site) \\nhttps://micro-frontends.org/ \\n\\u2022 \\nComposite UI using ASP.NET (Particular\\u2019s Workshop) \", \"\\nhttps://github.com/Particular/Workshop/tree/master/demos/asp-net-core \\n\\u2022 \\nRuben Oostinga. The Monol\", \"ithic Frontend in the Microservices Architecture \\nhttps://xebia.com/blog/the-monolithic-frontend-in-\", \"the-microservices-architecture/ \\n \\n63 \\nCHAPTER 3 | Architecting container and microservice-based app\", \"lications \\n \\n\\u2022 \\nMauro Servienti. The secret of better UI composition \\nhttps://particular.net/blog/se\", \"cret-of-better-ui-composition \\n\\u2022 \\nViktor Farcic. Including Front-End Web Components Into Microservic\", \"es \\nhttps://technologyconversations.com/2015/08/09/including-front-end-web-components-\\ninto-microser\", \"vices/ \\n\\u2022 \\nManaging Frontend in the Microservices Architecture \\nhttps://allegro.tech/2016/03/Managin\", \"g-Frontend-in-the-microservices-architecture.html \\nResiliency and high availability in microservices\", \" \\nDealing with unexpected failures is one of the hardest problems to solve, especially in a distribu\", \"ted \\nsystem. Much of the code that developers write involves handling exceptions, and this is also w\", \"here \\nthe most time is spent in testing. The problem is more involved than writing code to handle fa\", \"ilures. \\nWhat happens when the machine where the microservice is running fails? Not only do you need\", \" to \\ndetect this microservice failure (a hard problem on its own), but you also need something to re\", \"start \\nyour microservice. \\nA microservice needs to be resilient to failures and to be able to restar\", \"t often on another machine for \\navailability. This resiliency also comes down to the state that was \", \"saved on behalf of the microservice, \\nwhere the microservice can recover this state from, and whethe\", \"r the microservice can restart \\nsuccessfully. In other words, there needs to be resiliency in the co\", \"mpute capability (the process can \\nrestart at any time) as well as resilience in the state or data (\", \"no data loss, and the data remains \\nconsistent). \\nThe problems of resiliency are compounded during o\", \"ther scenarios, such as when failures occur \\nduring an application upgrade. The microservice, workin\", \"g with the deployment system, needs to \\ndetermine whether it can continue to move forward to the new\", \"er version or instead roll back to a \\nprevious version to maintain a consistent state. Questions suc\", \"h as whether enough machines are \\navailable to keep moving forward and how to recover previous versi\", \"ons of the microservice need to \\nbe considered. This approach requires the microservice to emit heal\", \"th information so that the overall \\napplication and orchestrator can make these decisions. \\nIn addit\", \"ion, resiliency is related to how cloud-based systems must behave. As mentioned, a cloud-\\nbased syst\", \"em must embrace failures and must try to automatically recover from them. For instance, in \\ncase of \", \"network or container failures, client apps or client services must have a strategy to retry \\nsending\", \" messages or to retry requests, since in many cases failures in the cloud are partial. The \\nImplemen\", \"ting Resilient Applications section in this guide addresses how to handle partial failure. It \\ndescr\", \"ibes techniques like retries with exponential backoff or the Circuit Breaker pattern in .NET by \\nusi\", \"ng libraries like Polly, which offers a large variety of policies to handle this subject. \\nHealth ma\", \"nagement and diagnostics in microservices \\nIt may seem obvious, and it\\u2019s often overlooked, but a mic\", \"roservice must report its health and \\ndiagnostics. Otherwise, there\\u2019s little insight from an operati\", \"ons perspective. Correlating diagnostic \\nevents across a set of independent services and dealing wit\", \"h machine clock skews to make sense of \\n \\n64 \\nCHAPTER 3 | Architecting container and microservice-ba\", \"sed applications \\n \\nthe event order is challenging. In the same way that you interact with a microse\", \"rvice over agreed-\\nupon protocols and data formats, there\\u2019s a need for standardization in how to log\", \" health and \\ndiagnostic events that ultimately end up in an event store for querying and viewing. In\", \" a microservices \\napproach, it\\u2019s key that different teams agree on a single logging format. There ne\", \"eds to be a \\nconsistent approach to viewing diagnostic events in the application. \\nHealth checks \\nHe\", \"alth is different from diagnostics. Health is about the microservice reporting its current state to \", \"take \\nappropriate actions. A good example is working with upgrade and deployment mechanisms to \\nmain\", \"tain availability. Although a service might currently be unhealthy due to a process crash or \\nmachin\", \"e reboot, the service might still be operational. The last thing you need is to make this worse \\nby \", \"performing an upgrade. The best approach is to do an investigation first or allow time for the \\nmicr\", \"oservice to recover. Health events from a microservice help us make informed decisions and, in \\neffe\", \"ct, help create self-healing services. \\nIn the Implementing health checks in ASP.NET Core services s\", \"ection of this guide, we explain how to \\nuse a new ASP.NET HealthChecks library in your microservice\", \"s so they can report their state to a \\nmonitoring service to take appropriate actions. \\nYou also hav\", \"e the option of using an excellent open-source library called \\nAspNetCore.Diagnostics.HealthChecks, \", \"available on GitHub and as a NuGet package. This library also \\ndoes health checks, with a twist, it \", \"handles two types of checks: \\n\\u2022 \\nLiveness: Checks if the microservice is alive, that is, if it\\u2019s abl\", \"e to accept requests and respond. \\n\\u2022 \\nReadiness: Checks if the microservice\\u2019s dependencies (Database\", \", queue services, etc.) are \\nthemselves ready, so the microservice can do what it\\u2019s supposed to do. \", \"\\nUsing diagnostics and logs event streams \\nLogs provide information about how an application or serv\", \"ice is running, including exceptions, \\nwarnings, and simple informational messages. Usually, each lo\", \"g is in a text format with one line per \\nevent, although exceptions also often show the stack trace \", \"across multiple lines. \\nIn monolithic server-based applications, you can write logs to a file on dis\", \"k (a logfile) and then analyze \\nit with any tool. Since application execution is limited to a fixed \", \"server or VM, it generally isn\\u2019t too \\ncomplex to analyze the flow of events. However, in a distribut\", \"ed application where multiple services \\nare executed across many nodes in an orchestrator cluster, b\", \"eing able to correlate distributed events \\nis a challenge. \\nA microservice-based application should \", \"not try to store the output stream of events or logfiles by \\nitself, and not even try to manage the \", \"routing of the events to a central place. It should be \\ntransparent, meaning that each process shoul\", \"d just write its event stream to a standard output that \\nunderneath will be collected by the executi\", \"on environment infrastructure where it\\u2019s running. An \\nexample of these event stream routers is Micro\", \"soft.Diagnostic.EventFlow, which collects event streams \\nfrom multiple sources and publishes it to o\", \"utput systems. These can include simple standard output \\nfor a development environment or cloud syst\", \"ems like Azure Monitor and Azure Diagnostics. There are \\nalso good third-party log analysis platform\", \"s and tools that can search, alert, report, and monitor logs, \\neven in real time, like Splunk. \\n \\n65\", \" \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\nOrchestrators managing h\", \"ealth and diagnostics information \\nWhen you create a microservice-based application, you need to dea\", \"l with complexity. Of course, a \\nsingle microservice is simple to deal with, but dozens or hundreds \", \"of types and thousands of \\ninstances of microservices is a complex problem. It isn\\u2019t just about buil\", \"ding your microservice \\narchitecture\\u2014you also need high availability, addressability, resiliency, he\", \"alth, and diagnostics if you \\nintend to have a stable and cohesive system. \\n \\nFigure 4-22. A Microse\", \"rvice Platform is fundamental for an application\\u2019s health management \\nThe complex problems shown in \", \"Figure 4-22 are hard to solve by yourself. Development teams should \\nfocus on solving business probl\", \"ems and building custom applications with microservice-based \\napproaches. They should not focus on s\", \"olving complex infrastructure problems; if they did, the cost of \\nany microservice-based application\", \" would be huge. Therefore, there are microservice-oriented \\nplatforms, referred to as orchestrators \", \"or microservice clusters, that try to solve the hard problems of \\nbuilding and running a service and\", \" using infrastructure resources efficiently. This approach reduces \\nthe complexities of building app\", \"lications that use a microservices approach. \\nDifferent orchestrators might sound similar, but the d\", \"iagnostics and health checks offered by each of \\nthem differ in features and state of maturity, some\", \"times depending on the OS platform, as explained \\nin the next section. \\nAdditional resources \\n\\u2022 \\nThe\", \" Twelve-Factor App. XI. Logs: Treat logs as event streams \\nhttps://12factor.net/logs \\n\\u2022 \\nMicrosoft D\", \"iagnostic EventFlow Library GitHub repo. \\nhttps://github.com/Azure/diagnostics-eventflow \\n\\u2022 \\nWhat is\", \" Azure Diagnostics \\nhttps://learn.microsoft.com/azure/azure-diagnostics \\n \\n66 \\nCHAPTER 3 | Architect\", \"ing container and microservice-based applications \\n \\n\\u2022 \\nConnect Windows computers to the Azure Monit\", \"or service \\nhttps://learn.microsoft.com/azure/azure-monitor/platform/agent-windows \\n\\u2022 \\nLogging What \", \"You Mean: Using the Semantic Logging Application Block \\nhttps://learn.microsoft.com/previous-version\", \"s/msp-n-p/dn440729(v=pandp.60) \\n\\u2022 \\nSplunk Official site. \\nhttps://www.splunk.com/ \\n\\u2022 \\nEventSource Cl\", \"ass API for events tracing for Windows (ETW) \\nhttps://learn.microsoft.com/dotnet/api/system.diagnost\", \"ics.tracing.eventsource \\nOrchestrate microservices and multi-container \\napplications for high scalab\", \"ility and availability \\nUsing orchestrators for production-ready applications is essential if your a\", \"pplication is based on \\nmicroservices or simply split across multiple containers. As introduced prev\", \"iously, in a microservice-\\nbased approach, each microservice owns its model and data so that it will\", \" be autonomous from a \\ndevelopment and deployment point of view. But even if you have a more traditi\", \"onal application that\\u2019s \\ncomposed of multiple services (like SOA), you\\u2019ll also have multiple contain\", \"ers or services comprising a \\nsingle business application that need to be deployed as a distributed \", \"system. These kinds of systems \\nare complex to scale out and manage; therefore, you absolutely need \", \"an orchestrator if you want to \\nhave a production-ready and scalable multi-container application. \\nF\", \"igure 4-23 illustrates deployment into a cluster of an application composed of multiple microservice\", \"s \\n(containers). \\n \\n67 \\nCHAPTER 3 | Architecting container and microservice-based applications \\n \\n \\n\", \"Figure 4-23. A cluster of containers \\nYou use one container for each service instance. Docker contai\", \"ners are \\u201cunits of deployment\\u201d and a \\ncontainer is an instance of a Docker. A host handles many cont\", \"ainers. It looks like a logical approach. \\nBut how are you handling load-balancing, routing, and orc\", \"hestrating these composed applications? \\nThe plain Docker Engine in single Docker hosts meets the ne\", \"eds of managing single image instances \\non one host, but it falls short when it comes to managing mu\", \"ltiple containers deployed on multiple \\nhosts for more complex distributed applications. In most cas\", \"es, you need a management platform \\nthat will automatically start containers, scale out containers w\", \"ith multiple instances per image, \\nsuspend them or shut them down when needed, and ideally also cont\", \"rol how they access resources \\nlike the network and data storage. \\nTo go beyond the management of in\", \"dividual containers or simple composed apps and move toward \\nlarger enterprise applications with mic\", \"roservices, you must turn to orchestration and clustering \\nplatforms. \\nFrom an architecture and deve\", \"lopment point of view, if you\\u2019re building large enterprise composed of \\nmicroservices-based applicat\", \"ions, it\\u2019s important to understand the following platforms and products \\nthat support advanced scena\", \"rios: \\nClusters and orchestrators. When you need to scale out applications across many Docker hosts,\", \" as \\nwhen a large microservice-based application, it\\u2019s critical to be able to manage all those hosts\", \" as a \\nsingle cluster by abstracting the complexity of the underlying platform. That\\u2019s what the cont\", \"ainer \\nclusters and orchestrators provide. Kubernetes is an example of an orchestrator, and is avail\", \"able in \\nAzure through Azure Kubernetes Service. \\nSchedulers. Scheduling means to have the capabilit\", \"y for an administrator to launch containers in a \\ncluster so they also provide a UI. A cluster sched\", \"uler has several responsibilities: to use the cluster\\u2019s \\n \\n68 \\nCHAPTER 3 | Architecting container an\", \"d microservice-based applications \\n \\nresources efficiently, to set the constraints provided by the u\", \"ser, to efficiently load-balance containers \\nacross nodes or hosts, and to be robust against errors \", \"while providing high availability. \\nThe concepts of a cluster and a scheduler are closely related, s\", \"o the products provided by different \\nvendors often provide both sets of capabilities. The following\", \" list shows the most important platform \\nand software choices you have for clusters and schedulers. \", \"These orchestrators are generally offered \\nin public clouds like Azure. \\nSoftware platforms for cont\", \"ainer clustering, orchestration, and \\nscheduling \\nPlatform \\nDescription \\nKubernetes \\n \\nKubernetes is\", \" an open-source \\nproduct that provides functionality \\nthat ranges from cluster \\ninfrastructure and c\", \"ontainer \\nscheduling to orchestrating \\ncapabilities. It lets you automate \\ndeployment, scaling, and \", \"\\noperations of application \\ncontainers across clusters of hosts. \\n \\nKubernetes provides a container-\", \"\\ncentric infrastructure that groups \\napplication containers into logical \\nunits for easy management \", \"and \\ndiscovery. \\n \\nKubernetes is mature in Linux, less \\nmature in Windows. \\nAzure Kubernetes Service\", \" (AKS) \\n \\nAKS is a managed Kubernetes \\ncontainer orchestration service in \\nAzure that simplifies Kub\", \"ernetes \\ncluster\\u2019s management, deployment, \\nand operations. \\nAzure Container Apps \\n \\nAzure Container\", \" Apps is a managed \\nserverless container service for \\nbuilding and deploying modern \\napps at scale. \", \"\\nUsing container-based orchestrators in Microsoft Azure \\nSeveral cloud vendors offer Docker containe\", \"rs support plus Docker clusters and orchestration support, \\nincluding Microsoft Azure, Amazon EC2 Co\", \"ntainer Service, and Google Container Engine. Microsoft \\nAzure provides Docker cluster and orchestra\", \"tor support through Azure Kubernetes Service (AKS). \\n \\n69 \\nCHAPTER 3 | Architecting container and mi\", \"croservice-based applications \\n \\nUsing Azure Kubernetes Service \\nA Kubernetes cluster pools multiple\", \" Docker hosts and exposes them as a single virtual Docker host, so \\nyou can deploy multiple containe\", \"rs into the cluster and scale-out with any number of container \\ninstances. The cluster will handle a\", \"ll the complex management plumbing, like scalability, health, and \\nso forth. \\nAKS provides a way to \", \"simplify the creation, configuration, and management of a cluster of virtual \\nmachines in Azure that\", \" are preconfigured to run containerized applications. Using an optimized \\nconfiguration of popular o\", \"pen-source scheduling and orchestration tools, AKS enables you to use \\nyour existing skills or draw \", \"on a large and growing body of community expertise to deploy and \\nmanage container-based application\", \"s on Microsoft Azure. \\nAzure Kubernetes Service optimizes the configuration of popular Docker cluste\", \"ring open-source tools \\nand technologies specifically for Azure. You get an open solution that offer\", \"s portability for both your \\ncontainers and your application configuration. You select the size, the\", \" number of hosts, and the \\norchestrator tools, and AKS handles everything else. \\n \\nFigure 4-24. Kube\", \"rnetes cluster\\u2019s simplified structure and topology \\n \\n70 \\nCHAPTER 3 | Architecting container and mic\", \"roservice-based applications \\n \\nIn figure 4-24, you can see the structure of a Kubernetes cluster wh\", \"ere a master node (VM) controls \\nmost of the coordination of the cluster and you can deploy containe\", \"rs to the rest of the nodes, which \\nare managed as a single pool from an application point of view a\", \"nd allows you to scale to thousands \\nor even tens of thousands of containers. \\nDevelopment environme\", \"nt for Kubernetes \\nIn the development environment, Docker announced in July 2018 that Kubernetes can\", \" also run in a \\nsingle development machine (Windows 10 or macOS) by installing Docker Desktop. You c\", \"an later \\ndeploy to the cloud (AKS) for further integration tests, as shown in figure 4-25. \\n \\nFigur\", \"e 4-25. Running Kubernetes in dev machine and the cloud \\nGetting started with Azure Kubernetes Servi\", \"ce (AKS) \\nTo begin using AKS, you deploy an AKS cluster from the Azure portal or by using the CLI. F\", \"or more \\ninformation on deploying a Kubernetes cluster in Azure, see Deploy an Azure Kubernetes Serv\", \"ice \\n(AKS) cluster. \\nThere are no fees for any of the software installed by default as part of AKS. \", \"All default options are \\nimplemented with open-source software. AKS is available for multiple virtua\", \"l machines in Azure. \\nYou\\u2019re charged only for the compute instances you choose, and the other underl\", \"ying infrastructure \\nresources consumed, such as storage and networking. There are no incremental ch\", \"arges for AKS itself. \\nThe default production deployment option for Kubernetes is to use Helm charts\", \", which are introduced \\nin the next section. \\n \\n71 \\nCHAPTER 3 | Architecting container and microserv\", \"ice-based applications \\n \\nDeploy with Helm charts into Kubernetes clusters \\nWhen deploying an applic\", \"ation to a Kubernetes cluster, you can use the original kubectl.exe CLI tool \\nusing deployment files\", \" based on the native format (.yaml files), as already mentioned in the previous \\nsection. However, f\", \"or more complex Kubernetes applications such as when deploying complex \\nmicroservice-based applicati\", \"ons, it\\u2019s recommended to use Helm. \\nHelm Charts helps you define, version, install, share, upgrade, \", \"or rollback even the most complex \\nKubernetes application. \\nGoing further, Helm usage is also recomm\", \"ended because other Kubernetes environments in Azure, \\nsuch as Azure Dev Spaces are also based on He\", \"lm charts. \\nHelm is maintained by the Cloud Native Computing Foundation (CNCF) - in collaboration wi\", \"th \\nMicrosoft, Google, Bitnami, and the Helm contributor community. \\nFor more implementation informa\", \"tion on Helm charts and Kubernetes, see the Using Helm Charts to \\ndeploy eShopOnContainers to AKS po\", \"st. \\nAdditional resources \\n\\u2022 \\nGetting started with Azure Kubernetes Service (AKS) \\nhttps://learn.mic\", \"rosoft.com/azure/aks/kubernetes-walkthrough-portal \\n\\u2022 \\nAzure Dev Spaces \\nhttps://learn.microsoft.com\", \"/azure/dev-spaces/azure-dev-spaces \\n\\u2022 \\nKubernetes The official site. \\nhttps://kubernetes.io/ \\n \\n72 \\n\", \"CHAPTER 4 | Development process for Docker-based applications \\n \\nCHAPTER 4 \\nDevelopment process for \", \"\\nDocker-based applications \\nDevelop containerized .NET applications the way you like, either Integra\", \"ted Development Environment \\n(IDE) focused with Visual Studio and Visual Studio tools for Docker or \", \"CLI/Editor focused with Docker CLI \\nand Visual Studio Code. \\nDevelopment environment for Docker apps\", \" \\nDevelopment tool choices: IDE or editor \\nWhether you prefer a full and powerful IDE or a lightweig\", \"ht and agile editor, Microsoft has tools that \\nyou can use for developing Docker applications. \\nVisu\", \"al Studio (for Windows). Docker-based .NET 7 application development with Visual Studio \\nrequires Vi\", \"sual Studio 2022 version 17.0 or later. Visual Studio 2022 comes with tools for Docker \\nalready buil\", \"t in. The tools for Docker let you develop, run, and validate your applications directly in the \\ntar\", \"get Docker environment. You can press F5 to run and debug your application (single container or \\nmul\", \"tiple containers) directly into a Docker host, or press CTRL + F5 to edit and refresh your \\napplicat\", \"ion without having to rebuild the container. This IDE is the most powerful development choice \\nfor D\", \"ocker-based apps. \\nVisual Studio for Mac. It\\u2019s an IDE, evolution of Xamarin Studio, running in macOS\", \". This tool should \\nbe the preferred choice for developers working in macOS machines who also want t\", \"o use a powerful \\nIDE. \\nVisual Studio Code and Docker CLI. If you prefer a lightweight and cross-pla\", \"tform editor that \\nsupports any development language, you can use Visual Studio Code and the Docker \", \"CLI. This IDE is a \\ncross-platform development approach for macOS, Linux, and Windows. Additionally,\", \" Visual Studio \\nCode supports extensions for Docker such as IntelliSense for Dockerfiles and shortcu\", \"t tasks to run \\nDocker commands from the editor. \\nBy installing Docker Desktop, you can use a single\", \" Docker CLI to build apps for both Windows and \\nLinux. \\n \\n73 \\nCHAPTER 4 | Development process for Do\", \"cker-based applications \\n \\nAdditional resources \\n\\u2022 \\nVisual Studio. Official site. \\nhttps://visualstu\", \"dio.microsoft.com/vs/ \\n\\u2022 \\nVisual Studio Code. Official site. \\nhttps://code.visualstudio.com/download\", \" \\n\\u2022 \\nDocker Desktop for Windows \\nhttps://hub.docker.com/editions/community/docker-ce-desktop-windows\", \" \\n\\u2022 \\nDocker Desktop for Mac \\nhttps://hub.docker.com/editions/community/docker-ce-desktop-mac \\n.NET l\", \"anguages and frameworks for Docker \\ncontainers \\nAs mentioned in earlier sections of this guide, you \", \"can use .NET Framework, .NET 7, or the open-\\nsource Mono project when developing Docker containerize\", \"d .NET applications. You can develop in \\nC#, F#, or Visual Basic when targeting Linux or Windows Con\", \"tainers, depending on which .NET \\nframework is in use. For more details about.NET languages, see the\", \" blog post The .NET Language \\nStrategy. \\nDevelopment workflow for Docker apps \\nThe application devel\", \"opment life cycle starts at your computer, as a developer, where you code the \\napplication using you\", \"r preferred language and test it locally. With this workflow, no matter which \\nlanguage, framework, \", \"and platform you choose, you\\u2019re always developing and testing Docker \\ncontainers, but doing so local\", \"ly. \\nEach container (an instance of a Docker image) includes the following components: \\n\\u2022 \\nAn operat\", \"ing system selection, for example, a Linux distribution, Windows Nano Server, or \\nWindows Server Cor\", \"e. \\n\\u2022 \\nFiles added during development, for example, source code and application binaries. \\n\\u2022 \\nConfig\", \"uration information, such as environment settings and dependencies. \\nWorkflow for developing Docker \", \"container-based applications \\nThis section describes the inner-loop development workflow for Docker \", \"container-based applications. \\nThe inner-loop workflow means it\\u2019s not considering the broader DevOps\", \" workflow, which can include \\nup to production deployment, and just focuses on the development work \", \"done on the developer\\u2019s \\ncomputer. The initial steps to set up the environment aren\\u2019t included, sinc\", \"e those steps are done only \\nonce. \\n \\n74 \\nCHAPTER 4 | Development process for Docker-based applicati\", \"ons \\n \\nAn application is composed of your own services plus additional libraries (dependencies). The\", \" \\nfollowing are the basic steps you usually take when building a Docker application, as illustrated \", \"in \\nFigure 5-1. \\n \\nFigure 5-1. Step-by-step workflow for developing Docker containerized apps \\nIn th\", \"is section, this whole process is detailed and every major step is explained by focusing on a Visual\", \" \\nStudio environment. \\nWhen you\\u2019re using an editor/CLI development approach (for example, Visual Stu\", \"dio Code plus Docker \\nCLI on macOS or Windows), you need to know every step, generally in more detai\", \"l than if you\\u2019re using \\nVisual Studio. For more information about working in a CLI environment, see \", \"the e-book \\nContainerized Docker Application lifecycle with Microsoft Platforms and Tools. \\nWhen you\", \"\\u2019re using Visual Studio 2022, many of those steps are handled for you, which dramatically \\nimproves \", \"your productivity. This is especially true when you\\u2019re using Visual Studio 2022 and targeting \\nmulti\", \"-container applications. For instance, with just one mouse click, Visual Studio adds the Dockerfile \", \"\\nand docker-compose.yml file to your projects with the configuration for your application. When you \", \"\\nrun the application in Visual Studio, it builds the Docker image and runs the multi-container \\nappl\", \"ication directly in Docker; it even allows you to debug several containers at once. These features \\n\", \"will boost your development speed. \\nHowever, just because Visual Studio makes those steps automatic \", \"doesn\\u2019t mean that you don\\u2019t need \\nto know what\\u2019s going on underneath with Docker. Therefore, the fol\", \"lowing guidance details every \\nstep. \\n \\n75 \\nCHAPTER 4 | Development process for Docker-based applica\", \"tions \\n \\n \\nStep 1. Start coding and create your initial application or service \\nbaseline \\nDeveloping\", \" a Docker application is similar to the way you develop an application without Docker. The \\ndifferen\", \"ce is that while developing for Docker, you\\u2019re deploying and testing your application or \\nservices r\", \"unning within Docker containers in your local environment (either a Linux VM setup by \\nDocker or dir\", \"ectly Windows if using Windows Containers). \\nSet up your local environment with Visual Studio \\nTo be\", \"gin, make sure you have Docker Desktop for Windows for Windows installed, as explained in the \\nfollo\", \"wing instructions: \\nGet started with Docker Desktop for Windows \\nIn addition, you need Visual Studio\", \" 2022 version 17.0, with the .ASP.NET and web development \\nworkload installed, as shown in Figure 5-\", \"2. \\n \\nFigure 5-2. Selecting the ASP.NET and web development workload during Visual Studio 2022 setup\", \" \\nYou can start coding your application in plain .NET (usually in .NET Core or later if you\\u2019re plann\", \"ing to \\nuse containers) even before enabling Docker in your application and deploying and testing in\", \" Docker. \\nHowever, it is recommended that you start working on Docker as soon as possible, because t\", \"hat will \\nbe the real environment and any issues can be discovered as soon as possible. This is enco\", \"uraged \\n \\n76 \\nCHAPTER 4 | Development process for Docker-based applications \\n \\nbecause Visual Studio\", \" makes it so easy to work with Docker that it almost feels transparent\\u2014the best \\nexample when debugg\", \"ing multi-container applications from Visual Studio. \\nAdditional resources \\n\\u2022 \\nGet started with Dock\", \"er Desktop for Windows \\nhttps://docs.docker.com/docker-for-windows/ \\n\\u2022 \\nVisual Studio 2022 \\nhttps://\", \"visualstudio.microsoft.com/downloads/ \\n \\nStep 2. Create a Dockerfile related to an existing .NET bas\", \"e image \\nYou need a Dockerfile for each custom image you want to build; you also need a Dockerfile f\", \"or each \\ncontainer to be deployed, whether you deploy automatically from Visual Studio or manually u\", \"sing the \\nDocker CLI (docker run and docker-compose commands). If your application contains a single\", \" custom \\nservice, you need a single Dockerfile. If your application contains multiple services (as i\", \"n a \\nmicroservices architecture), you need one Dockerfile for each service. \\nThe Dockerfile is place\", \"d in the root folder of your application or service. It contains the commands \\nthat tell Docker how \", \"to set up and run your application or service in a container. You can manually \\ncreate a Dockerfile \", \"in code and add it to your project along with your .NET dependencies. \\nWith Visual Studio and its to\", \"ols for Docker, this task requires only a few mouse clicks. When you \\ncreate a new project in Visual\", \" Studio 2022, there\\u2019s an option named Enable Docker Support, as \\nshown in Figure 5-3. \\n \\n77 \\nCHAPTER\", \" 4 | Development process for Docker-based applications \\n \\n \\nFigure 5-3. Enabling Docker Support when\", \" creating a new ASP.NET Core project in Visual Studio 2022 \\nYou can also enable Docker support on an\", \" existing ASP.NET Core web app project by right-clicking \\nthe project in Solution Explorer and selec\", \"ting Add > Docker Support\\u2026, as shown in Figure 5-4. \\n \\nFigure 5-4. Enabling Docker support in an exi\", \"sting Visual Studio 2022 project \\n \\n78 \\nCHAPTER 4 | Development process for Docker-based application\", \"s \\n \\nThis action adds a Dockerfile to the project with the required configuration, and is only avail\", \"able on \\nASP.NET Core projects. \\nIn a similar fashion, Visual Studio can also add a docker-compose.y\", \"ml file for the whole solution with \\nthe option Add > Container Orchestrator Support\\u2026. In step 4, we\", \"\\u2019ll explore this option in greater \\ndetail. \\nUsing an existing official .NET Docker image \\nYou usual\", \"ly build a custom image for your container on top of a base image you get from an official \\nreposito\", \"ry like the Docker Hub registry. That is precisely what happens under the covers when you \\nenable Do\", \"cker support in Visual Studio. Your Dockerfile will use an existing dotnet/core/aspnet image. \\nEarli\", \"er we explained which Docker images and repos you can use, depending on the framework and \\nOS you ha\", \"ve chosen. For instance, if you want to use ASP.NET Core (Linux or Windows), the image to \\nuse is mc\", \"r.microsoft.com/dotnet/aspnet:7.0. Therefore, you just need to specify what base Docker \\nimage you w\", \"ill use for your container. You do that by adding FROM \\nmcr.microsoft.com/dotnet/aspnet:7.0 to your \", \"Dockerfile. This will be automatically performed by \\nVisual Studio, but if you were to update the ve\", \"rsion, you update this value. \\nUsing an official .NET image repository from Docker Hub with a versio\", \"n number ensures that the same \\nlanguage features are available on all machines (including developme\", \"nt, testing, and production). \\nThe following example shows a sample Dockerfile for an ASP.NET Core c\", \"ontainer. \\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 \\nARG source \\nWORKDIR /app \\nEXPOSE 80 \\nCOPY ${sou\", \"rce:-obj/Docker/publish} . \\nENTRYPOINT [\\\"dotnet\\\", \\\" MySingleContainerWebApp.dll \\\"] \\nIn this case, th\", \"e image is based on version 7.0 of the official ASP.NET Core Docker image (multi-arch \\nfor Linux and\", \" Windows). This is the setting FROM mcr.microsoft.com/dotnet/aspnet:7.0. (For more \\ninformation abou\", \"t this base image, see the ASP.NET Core Docker Image page.) In the Dockerfile, you \\nalso need to ins\", \"truct Docker to listen on the TCP port you will use at runtime (in this case, port 80, as \\nconfigure\", \"d with the EXPOSE setting). \\nYou can specify additional configuration settings in the Dockerfile, de\", \"pending on the language and \\nframework you\\u2019re using. For instance, the ENTRYPOINT line with [\\\"dotnet\", \"\\\", \\n\\\"MySingleContainerWebApp.dll\\\"] tells Docker to run a .NET application. If you\\u2019re using the SDK a\", \"nd \\nthe .NET CLI (dotnet CLI) to build and run the .NET application, this setting would be different\", \". The \\nbottom line is that the ENTRYPOINT line and other settings will be different depending on the\", \" \\nlanguage and platform you choose for your application. \\nAdditional resources \\n\\u2022 \\nBuilding Docker I\", \"mages for ASP.NET Core Applications \\nhttps://learn.microsoft.com/dotnet/core/docker/building-net-doc\", \"ker-images \\n \\n79 \\nCHAPTER 4 | Development process for Docker-based applications \\n \\n\\u2022 \\nBuild your own\", \" image. In the official Docker documentation. \\nhttps://docs.docker.com/engine/tutorials/dockerimages\", \"/ \\n\\u2022 \\nStaying up-to-date with .NET Container Images \\nhttps://devblogs.microsoft.com/dotnet/staying-u\", \"p-to-date-with-net-container-images/ \\n\\u2022 \\nUsing .NET and Docker Together - DockerCon 2018 Update \\nhtt\", \"ps://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2018-\\nupdate/ \\nUsing mult\", \"i-arch image repositories \\nA single repo can contain platform variants, such as a Linux image and a \", \"Windows image. This feature \\nallows vendors like Microsoft (base image creators) to create a single \", \"repo to cover multiple platforms \\n(that is Linux and Windows). For example, the .NET repository avai\", \"lable in the Docker Hub registry \\nprovides support for Linux and Windows Nano Server by using the sa\", \"me repo name. \\nIf you specify a tag, targeting a platform that is explicit like in the following cas\", \"es: \\n\\u2022 \\nmcr.microsoft.com/dotnet/aspnet:7.0-bullseye-slim \\nTargets: .NET 7 runtime-only on Linux \\n\\u2022 \", \"\\nmcr.microsoft.com/dotnet/aspnet:7.0-nanoserver-ltsc2022 \\nTargets: .NET 7 runtime-only on Windows Na\", \"no Server \\nBut, if you specify the same image name, even with the same tag, the multi-arch images (l\", \"ike the \\naspnet image) will use the Linux or Windows version depending on the Docker host OS you\\u2019re \", \"\\ndeploying, as shown in the following example: \\n\\u2022 \\nmcr.microsoft.com/dotnet/aspnet:7.0 \\nMulti-arch: \", \".NET 7 runtime-only on Linux or Windows Nano Server depending on the Docker \\nhost OS \\nThis way, when\", \" you pull an image from a Windows host, it will pull the Windows variant, and pulling \\nthe same imag\", \"e name from a Linux host will pull the Linux variant. \\nMulti-stage builds in Dockerfile \\nThe Dockerf\", \"ile is similar to a batch script. Similar to what you would do if you had to set up the \\nmachine fro\", \"m the command line. \\nIt starts with a base image that sets up the initial context, it\\u2019s like the sta\", \"rtup filesystem, that sits on \\ntop of the host OS. It\\u2019s not an OS, but you can think of it like \\u201cthe\", \"\\u201d OS inside the container. \\nThe execution of every command line creates a new layer on the filesyste\", \"m with the changes from the \\nprevious one, so that, when combined, produce the resulting filesystem.\", \" \\nSince every new layer \\u201crests\\u201d on top of the previous one and the resulting image size increases wi\", \"th \\nevery command, images can get very large if they have to include, for example, the SDK needed to\", \" \\nbuild and publish an application. \\nThis is where multi-stage builds get into the plot (from Docker\", \" 17.05 and higher) to do their magic. \\n \\n80 \\nCHAPTER 4 | Development process for Docker-based applic\", \"ations \\n \\nThe core idea is that you can separate the Dockerfile execution process in stages, where a\", \" stage is an \\ninitial image followed by one or more commands, and the last stage determines the fina\", \"l image size. \\nIn short, multi-stage builds allow splitting the creation in different \\u201cphases\\u201d and t\", \"hen assemble the \\nfinal image taking only the relevant directories from the intermediate stages. The\", \" general strategy to \\nuse this feature is: \\n1. \\nUse a base SDK image (doesn\\u2019t matter how large), wit\", \"h everything needed to build and \\npublish the application to a folder and then \\n2. \\nUse a base, smal\", \"l, runtime-only image and copy the publishing folder from the previous stage \\nto produce a small fin\", \"al image. \\nProbably the best way to understand multi-stage is going through a Dockerfile in detail, \", \"line by line, \\nso let\\u2019s begin with the initial Dockerfile created by Visual Studio when adding Docke\", \"r support to a \\nproject and will get into some optimizations later. \\nThe initial Dockerfile might lo\", \"ok something like this: \\n 1  FROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\n 2  WORKDIR /app \\n 3 \", \" EXPOSE 80 \\n 4 \\n 5  FROM mcr.microsoft.com/dotnet/sdk:7.0 AS build \\n 6  WORKDIR /src \\n 7  COPY src/S\", \"ervices/Catalog/Catalog.API/Catalog.API.csproj \\u2026 \\n 8  COPY src/BuildingBlocks/HealthChecks/src/Micro\", \"soft.AspNetCore.HealthChecks \\u2026 \\n 9  COPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions.He\", \"althChecks \\u2026 \\n10  COPY src/BuildingBlocks/EventBus/IntegrationEventLogEF/ \\u2026 \\n11  COPY src/BuildingBl\", \"ocks/EventBus/EventBus/EventBus.csproj \\u2026 \\n12  COPY src/BuildingBlocks/EventBus/EventBusRabbitMQ/Even\", \"tBusRabbitMQ.csproj \\u2026 \\n13  COPY src/BuildingBlocks/EventBus/EventBusServiceBus/EventBusServiceBus.cs\", \"proj \\u2026 \\n14  COPY src/BuildingBlocks/WebHostCustomization/WebHost.Customization \\u2026 \\n15  COPY src/Build\", \"ingBlocks/HealthChecks/src/Microsoft.Extensions \\u2026 \\n16  COPY src/BuildingBlocks/HealthChecks/src/Micr\", \"osoft.Extensions \\u2026 \\n17  RUN dotnet restore src/Services/Catalog/Catalog.API/Catalog.API.csproj \\n18  \", \"COPY . . \\n19  WORKDIR /src/src/Services/Catalog/Catalog.API \\n20  RUN dotnet build Catalog.API.csproj\", \" -c Release -o /app \\n21 \\n22  FROM build AS publish \\n23  RUN dotnet publish Catalog.API.csproj -c Rel\", \"ease -o /app \\n24 \\n25  FROM base AS final \\n26  WORKDIR /app \\n27  COPY --from=publish /app . \\n28  ENTR\", \"YPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"] \\nAnd these are the details, line by line: \\n\\u2022 \\nLine #1: Begin a \", \"stage with a \\u201csmall\\u201d runtime-only base image, call it base for reference. \\n\\u2022 \\nLine #2: Create the /a\", \"pp directory in the image. \\n\\u2022 \\nLine #3: Expose port 80. \\n \\n81 \\nCHAPTER 4 | Development process for D\", \"ocker-based applications \\n \\n\\u2022 \\nLine #5: Begin a new stage with the \\u201clarge\\u201d image for building/publis\", \"hing. Call it build for \\nreference. \\n\\u2022 \\nLine #6: Create directory /src in the image. \\n\\u2022 \\nLine #7: Up\", \" to line 16, copy referenced .csproj project files to be able to restore packages \\nlater. \\n\\u2022 \\nLine #\", \"17: Restore packages for the Catalog.API project and the referenced projects. \\n\\u2022 \\nLine #18: Copy all\", \" directory tree for the solution (except the files/directories included in the \\n.dockerignore file) \", \"to the /src directory in the image. \\n\\u2022 \\nLine #19: Change the current folder to the Catalog.API proje\", \"ct. \\n\\u2022 \\nLine #20: Build the project (and other project dependencies) and output to the /app \\ndirecto\", \"ry in the image. \\n\\u2022 \\nLine #22: Begin a new stage continuing from the build. Call it publish for refe\", \"rence. \\n\\u2022 \\nLine #23: Publish the project (and dependencies) and output to the /app directory in the \", \"\\nimage. \\n\\u2022 \\nLine #25: Begin a new stage continuing from base and call it final. \\n\\u2022 \\nLine #26: Change\", \" the current directory to /app. \\n\\u2022 \\nLine #27: Copy the /app directory from stage publish to the curr\", \"ent directory. \\n\\u2022 \\nLine #28: Define the command to run when the container is started. \\nNow let\\u2019s exp\", \"lore some optimizations to improve the whole process performance that, in the case of \\neShopOnContai\", \"ners, means about 22 minutes or more to build the complete solution in Linux \\ncontainers. \\nYou\\u2019ll ta\", \"ke advantage of Docker\\u2019s layer cache feature, which is quite simple: if the base image and the \\ncomm\", \"ands are the same as some previously executed, it can just use the resulting layer without the \\nneed\", \" to execute the commands, thus saving some time. \\nSo, let\\u2019s focus on the build stage, lines 5-6 are \", \"mostly the same, but lines 7-17 are different for every \\nservice from eShopOnContainers, so they hav\", \"e to execute every single time, however if you changed \\nlines 7-16 to: \\nCOPY . . \\nThen it would be j\", \"ust the same for every service, it would copy the whole solution and would create a \\nlarger layer bu\", \"t: \\n1. \\nThe copy process would only be executed the first time (and when rebuilding if a file is \\nch\", \"anged) and would use the cache for all other services and \\n2. \\nSince the larger image occurs in an i\", \"ntermediate stage, it doesn\\u2019t affect the final image size. \\n \\n82 \\nCHAPTER 4 | Development process fo\", \"r Docker-based applications \\n \\nThe next significant optimization involves the restore command execut\", \"ed in line 17, which is also \\ndifferent for every service of eShopOnContainers. If you change that l\", \"ine to just: \\nRUN dotnet restore \\nIt would restore the packages for the whole solution, but then aga\", \"in, it would do it just once, instead \\nof the 15 times with the current strategy. \\nHowever, dotnet r\", \"estore only runs if there\\u2019s a single project or solution file in the folder, so achieving \\nthis is a\", \" bit more complicated and the way to solve it, without getting into too many details, is this: \\n1. \\n\", \"Add the following lines to .dockerignore: \\n\\u2013 \\n*.sln, to ignore all solution files in the main folder\", \" tree \\n\\u2013 \\n!eShopOnContainers-ServicesAndWebApps.sln, to include only this solution file. \\n2. \\nInclud\", \"e the /ignoreprojectextensions:.dcproj argument to dotnet restore, so it also ignores the \\ndocker-co\", \"mpose project and only restores the packages for the eShopOnContainers-\\nServicesAndWebApps solution.\", \" \\nFor the final optimization, it just happens that line 20 is redundant, as line 23 also builds the \", \"\\napplication and comes, in essence, right after line 20, so there goes another time-consuming \\ncomma\", \"nd. \\nThe resulting file is then: \\n 1  FROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\n 2  WORKDIR \", \"/app \\n 3  EXPOSE 80 \\n 4 \\n 5  FROM mcr.microsoft.com/dotnet/sdk:7.0 AS publish \\n 6  WORKDIR /src \\n 7 \", \" COPY . . \\n 8  RUN dotnet restore /ignoreprojectextensions:.dcproj \\n 9  WORKDIR /src/src/Services/Ca\", \"talog/Catalog.API \\n10  RUN dotnet publish Catalog.API.csproj -c Release -o /app \\n11 \\n12  FROM base A\", \"S final \\n13  WORKDIR /app \\n14  COPY --from=publish /app . \\n15  ENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.API.dl\", \"l\\\"] \\nCreating your base image from scratch \\nYou can create your own Docker base image from scratch. \", \"This scenario is not recommended for \\nsomeone who is starting with Docker, but if you want to set th\", \"e specific bits of your own base image, \\nyou can do so. \\nAdditional resources \\n\\u2022 \\nMulti-arch .NET Co\", \"re images. \\nhttps://github.com/dotnet/announcements/issues/14 \\n \\n83 \\nCHAPTER 4 | Development process\", \" for Docker-based applications \\n \\n\\u2022 \\nCreate a base image. Official Docker documentation. \\nhttps://do\", \"cs.docker.com/develop/develop-images/baseimages/ \\n \\nStep 3. Create your custom Docker images and emb\", \"ed your \\napplication or service in them \\nFor each service in your application, you need to create a \", \"related image. If your application is made up \\nof a single service or web application, you just need\", \" a single image. \\nNote that the Docker images are built automatically for you in Visual Studio. The \", \"following steps are \\nonly needed for the editor/CLI workflow and explained for clarity about what ha\", \"ppens underneath. \\nYou, as a developer, need to develop and test locally until you push a completed \", \"feature or change to \\nyour source control system (for example, to GitHub). This means that you need \", \"to create the Docker \\nimages and deploy containers to a local Docker host (Windows or Linux VM) and \", \"run, test, and debug \\nagainst those local containers. \\nTo create a custom image in your local enviro\", \"nment by using Docker CLI and your Dockerfile, you can \\nuse the docker build command, as in Figure 5\", \"-5. \\n \\nFigure 5-5. Creating a custom Docker image \\nOptionally, instead of directly running docker bu\", \"ild from the project folder, you can first generate a \\ndeployable folder with the required .NET libr\", \"aries and binaries by running dotnet publish, and then \\nuse the docker build command. \\nThis will cre\", \"ate a Docker image with the name cesardl/netcore-webapi-microservice-docker:first. In \\nthis case, :f\", \"irst is a tag that represents a specific version. You can repeat this step for each custom \\nimage yo\", \"u need to create for your composed Docker application. \\nWhen an application is made of multiple cont\", \"ainers (that is, it is a multi-container application), you \\ncan also use the docker-compose up --bui\", \"ld command to build all the related images with a single \\ncommand by using the metadata exposed in t\", \"he related docker-compose.yml files. \\nYou can find the existing images in your local repository by u\", \"sing the docker images command, as \\nshown in Figure 5-6. \\n \\n84 \\nCHAPTER 4 | Development process for \", \"Docker-based applications \\n \\n \\nFigure 5-6. Viewing existing images using the docker images command \\n\", \"Creating Docker images with Visual Studio \\nWhen you use Visual Studio to create a project with Docke\", \"r support, you don\\u2019t explicitly create an \\nimage. Instead, the image is created for you when you pre\", \"ss F5 (or Ctrl+F5) to run the dockerized \\napplication or service. This step is automatic in Visual S\", \"tudio and you won\\u2019t see it happen, but it\\u2019s \\nimportant that you know what\\u2019s going on underneath. \\n \\n\", \"Step 4. Define your services in docker-compose.yml when building a \\nmulti-container Docker applicati\", \"on \\nThe docker-compose.yml file lets you define a set of related services to be deployed as a compos\", \"ed \\napplication with deployment commands. It also configures its dependency relations and runtime \\nc\", \"onfiguration. \\nTo use a docker-compose.yml file, you need to create the file in your main or root so\", \"lution folder, with \\ncontent similar to that in the following example: \\nversion: '3.4' \\n \\nservices: \", \"\\n \\n  webmvc: \\n    image: eshop/web \\n    environment: \\n      - CatalogUrl=http://catalog-api \\n      -\", \" OrderingUrl=http://ordering-api \\n    ports: \\n      - \\\"80:80\\\" \\n    depends_on: \\n      - catalog-api \", \"\\n      - ordering-api \\n \\n  catalog-api: \\n    image: eshop/catalog-api \\n    environment: \\n      - Con\", \"nectionString=Server=sqldata;Port=1433;Database=CatalogDB;\\u2026 \\n    ports: \\n      - \\\"81:80\\\" \\n    depend\", \"s_on: \\n      - sqldata \\n \\n  ordering-api: \\n    image: eshop/ordering-api \\n \\n85 \\nCHAPTER 4 | Developm\", \"ent process for Docker-based applications \\n \\n    environment: \\n      - ConnectionString=Server=sqlda\", \"ta;Database=OrderingDb;\\u2026 \\n    ports: \\n      - \\\"82:80\\\" \\n    extra_hosts: \\n      - \\\"CESARDLBOOKVHD:10.\", \"0.75.1\\\" \\n    depends_on: \\n      - sqldata \\n \\n  sqldata: \\n    image: mcr.microsoft.com/mssql/server:l\", \"atest \\n    environment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"\", \"5433:1433\\\" \\nThis docker-compose.yml file is a simplified and merged version. It contains static conf\", \"iguration data \\nfor each container (like the name of the custom image), which is always required, an\", \"d configuration \\ninformation that might depend on the deployment environment, like the connection st\", \"ring. In later \\nsections, you will learn how to split the docker-compose.yml configuration into mult\", \"iple docker-\\ncompose files and override values depending on the environment and execution type (debu\", \"g or \\nrelease). \\nThe docker-compose.yml file example defines four services: the webmvc service (a we\", \"b application), \\ntwo microservices (ordering-api and basket-api), and one data source container, sql\", \"data, based on \\nSQL Server for Linux running as a container. Each service will be deployed as a cont\", \"ainer, so a Docker \\nimage is required for each. \\nThe docker-compose.yml file specifies not only what\", \" containers are being used, but how they are \\nindividually configured. For instance, the webmvc cont\", \"ainer definition in the .yml file: \\n\\u2022 \\nUses a pre-built eshop/web:latest image. However, you could a\", \"lso configure the image to be \\nbuilt as part of the docker-compose execution with an additional conf\", \"iguration based on a \\nbuild: section in the docker-compose file. \\n\\u2022 \\nInitializes two environment var\", \"iables (CatalogUrl and OrderingUrl). \\n\\u2022 \\nForwards the exposed port 80 on the container to the extern\", \"al port 80 on the host machine. \\n\\u2022 \\nLinks the web app to the catalog and ordering service with the d\", \"epends_on setting. This \\ncauses the service to wait until those services are started. \\nWe will revis\", \"it the docker-compose.yml file in a later section when we cover how to implement \\nmicroservices and \", \"multi-container apps. \\nWorking with docker-compose.yml in Visual Studio 2022 \\nBesides adding a Docke\", \"rfile to a project, as we mentioned before, Visual Studio 2017 (from version \\n15.8 on) can add orche\", \"strator support for Docker Compose to a solution. \\nWhen you add container orchestrator support, as s\", \"hown in Figure 5-7, for the first time, Visual Studio \\ncreates the Dockerfile for the project and cr\", \"eates a new (service section) project in your solution with \\n \\n86 \\nCHAPTER 4 | Development process f\", \"or Docker-based applications \\n \\nseveral global docker-compose*.yml files, and then adds the project \", \"to those files. You can then open \\nthe docker-compose.yml files and update them with additional feat\", \"ures. \\nRepeat this operation for every project you want to include in the docker-compose.yml file. \\n\", \"At the time of this writing, Visual Studio supports Docker Compose orchestrators. \\n \\nFigure 5-7. Add\", \"ing Docker support in Visual Studio 2022 by right-clicking an ASP.NET Core project \\nAfter you add or\", \"chestrator support to your solution in Visual Studio, you will also see a new node (in \\nthe docker-c\", \"ompose.dcproj project file) in Solution Explorer that contains the added docker-\\ncompose.yml files, \", \"as shown in Figure 5-8. \\n \\nFigure 5-8. The docker-compose tree node added in Visual Studio 2022 Solu\", \"tion Explorer \\nYou could deploy a multi-container application with a single docker-compose.yml file \", \"by using the \\ndocker-compose up command. However, Visual Studio adds a group of them so you can over\", \"ride \\nvalues depending on the environment (development or production) and execution type (release or\", \" \\ndebug). This capability will be explained in later sections. \\n \\n87 \\nCHAPTER 4 | Development proces\", \"s for Docker-based applications \\n \\n \\nStep 5. Build and run your Docker application \\nIf your applicat\", \"ion only has a single container, you can run it by deploying it to your Docker host (VM \\nor physical\", \" server). However, if your application contains multiple services, you can deploy it as a \\ncomposed \", \"application, either using a single CLI command (docker-compose up), or with Visual Studio, \\nwhich wi\", \"ll use that command under the covers. Let\\u2019s look at the different options. \\nOption A: Running a sing\", \"le-container application \\nUsing Docker CLI \\nYou can run a Docker container using the docker run comm\", \"and, as shown in Figure 5-9: \\ndocker run -t -d -p 80:5000 cesardl/netcore-webapi-microservice-docker\", \":first \\nThe above command will create a new container instance from the specified image, every time \", \"it\\u2019s run. \\nYou can use the --name parameter to give a name to the container and then use docker star\", \"t {name} \\n(or use the container ID or automatic name) to run an existing container instance. \\n \\nFigu\", \"re 5-9. Running a Docker container using the docker run command \\nIn this case, the command binds the\", \" internal port 5000 of the container to port 80 of the host \\nmachine. This means that the host is li\", \"stening on port 80 and forwarding to port 5000 on the \\ncontainer. \\nThe hash shown is the container I\", \"D and it\\u2019s also assigned a random readable name if the --name \\noption is not used. \\nUsing Visual Stu\", \"dio \\nIf you haven\\u2019t added container orchestrator support, you can also run a single container app in\", \" Visual \\nStudio by pressing Ctrl+F5 and you can also use F5 to debug the application within the cont\", \"ainer. The \\ncontainer runs locally using docker run. \\nOption B: Running a multi-container applicatio\", \"n \\nIn most enterprise scenarios, a Docker application will be composed of multiple services, which m\", \"eans \\nyou need to run a multi-container application, as shown in Figure 5-10. \\n \\n88 \\nCHAPTER 4 | Dev\", \"elopment process for Docker-based applications \\n \\n \\nFigure 5-10. VM with Docker containers deployed \", \"\\nUsing Docker CLI \\nTo run a multi-container application with the Docker CLI, you use the docker-comp\", \"ose up command. \\nThis command uses the docker-compose.yml file that you have at the solution level t\", \"o deploy a \\nmulti-container application. Figure 5-11 shows the results when running the command from\", \" your \\nmain solution directory, which contains the docker-compose.yml file. \\n \\nFigure 5-11. Example \", \"results when running the docker-compose up command \\nAfter the docker-compose up command runs, the ap\", \"plication and its related containers are deployed \\ninto your Docker host, as depicted in Figure 5-10\", \". \\nUsing Visual Studio \\nRunning a multi-container application using Visual Studio 2019 can\\u2019t get any\", \" simpler. You just press \\nCtrl+F5 to run or F5 to debug, as usual, setting up the docker-compose pro\", \"ject as the startup project. \\nVisual Studio handles all needed setup, so you can create breakpoints \", \"as usual and debug what finally \\nbecome independent processes running in \\u201cremote servers\\u201d, with the \", \"debugger already attached, just \\nlike that. \\nAs mentioned before, each time you add Docker solution \", \"support to a project within a solution, that \\nproject is configured in the global (solution-level) d\", \"ocker-compose.yml file, which lets you run or \\ndebug the whole solution at once. Visual Studio will \", \"start one container for each project that has \\nDocker solution support enabled, and perform all the \", \"internal steps for you (dotnet publish, docker \\nbuild, etc.). \\nIf you want to take a peek at all the\", \" drudgery, take a look at the file: \\n{root solution folder}\\\\obj\\\\Docker\\\\docker-compose.vs.debug.g.yml\", \" \\n \\n89 \\nCHAPTER 4 | Development process for Docker-based applications \\n \\nThe important point here is\", \" that, as shown in Figure 5-12, in Visual Studio 2019 there is an additional \\nDocker command for the\", \" F5 key action. This option lets you run or debug a multi-container \\napplication by running all the \", \"containers that are defined in the docker-compose.yml files at the \\nsolution level. The ability to d\", \"ebug multiple-container solutions means that you can set several \\nbreakpoints, each breakpoint in a \", \"different project (container), and while debugging from Visual \\nStudio you will stop at breakpoints \", \"defined in different projects and running on different containers. \\n \\nFigure 5-12. Running multi-con\", \"tainer apps in Visual Studio 2022 \\nAdditional resources \\n\\u2022 \\nDeploy an ASP.NET container to a remote \", \"Docker host \\nhttps://learn.microsoft.com/visualstudio/containers/hosting-web-apps-in-docker \\nA note \", \"about testing and deploying with orchestrators \\nThe docker-compose up and docker run commands (or ru\", \"nning and debugging the containers in \\nVisual Studio) are adequate for testing containers in your de\", \"velopment environment. But you should \\nnot use this approach for production deployments, where you s\", \"hould target orchestrators like \\nKubernetes or Service Fabric. If you\\u2019re using Kubernetes, you have \", \"to use pods to organize containers \\nand services to network them. You also use deployments to organi\", \"ze pod creation and modification. \\n \\nStep 6. Test your Docker application using your local Docker ho\", \"st \\nThis step will vary depending on what your application is doing. In a simple .NET Web applicatio\", \"n that \\nis deployed as a single container or service, you can access the service by opening a browse\", \"r on the \\nDocker host and navigating to that site, as shown in Figure 5-13. (If the configuration in\", \" the Dockerfile \\nmaps the container to a port on the host that is anything other than 80, include th\", \"e host port in the \\nURL.) \\n \\nFigure 5-13. Example of testing your Docker application locally using l\", \"ocalhost \\n \\n90 \\nCHAPTER 4 | Development process for Docker-based applications \\n \\nIf localhost is not\", \" pointing to the Docker host IP (by default, when using Docker CE, it should), to \\nnavigate to your \", \"service, use the IP address of your machine\\u2019s network card. \\nThis URL in the browser uses port 80 fo\", \"r the particular container example being discussed. However, \\ninternally the requests are being redi\", \"rected to port 5000, because that was how it was deployed with \\nthe docker run command, as explained\", \" in a previous step. \\nYou can also test the application using curl from the terminal, as shown in Fi\", \"gure 5-14. In a Docker \\ninstallation on Windows, the default Docker Host IP is always 10.0.75.1 in a\", \"ddition to your machine\\u2019s \\nactual IP address. \\n \\nFigure 5-14. Example of testing your Docker applica\", \"tion locally using curl \\nTesting and debugging containers with Visual Studio 2022 \\nWhen running and \", \"debugging the containers with Visual Studio 2022, you can debug the .NET \\napplication in much the sa\", \"me way as you would when running without containers. \\nTesting and debugging without Visual Studio \\nI\", \"f you\\u2019re developing using the editor/CLI approach, debugging containers is more difficult and you\\u2019ll\", \" \\nprobably want to debug by generating traces. \\nAdditional resources \\n\\u2022 \\nQuickstart: Docker in Visua\", \"l Studio. \\nhttps://learn.microsoft.com/visualstudio/containers/container-tools \\n\\u2022 \\nDebugging apps in\", \" a local Docker container \\nhttps://learn.microsoft.com/visualstudio/containers/edit-and-refresh \\nSim\", \"plified workflow when developing containers with Visual Studio \\nEffectively, the workflow when using\", \" Visual Studio is a lot simpler than if you use the editor/CLI \\napproach. Most of the steps required\", \" by Docker related to the Dockerfile and docker-compose.yml \\nfiles are hidden or simplified by Visua\", \"l Studio, as shown in Figure 5-15. \\n \\n91 \\nCHAPTER 4 | Development process for Docker-based applicati\", \"ons \\n \\n \\nFigure 5-15. Simplified workflow when developing with Visual Studio \\nIn addition, you need \", \"to perform step 2 (adding Docker support to your projects) just once. Therefore, \\nthe workflow is si\", \"milar to your usual development tasks when using .NET for any other development. \\nYou need to know w\", \"hat is going on under the covers (the image build process, what base images \\nyou\\u2019re using, deploymen\", \"t of containers, etc.) and sometimes you will also need to edit the Dockerfile \\nor docker-compose.ym\", \"l file to customize behaviors. But most of the work is greatly simplified by using \\nVisual Studio, m\", \"aking you a lot more productive. \\nUsing PowerShell commands in a Dockerfile to set up Windows \\nConta\", \"iners \\nWindows Containers allow you to convert your existing Windows applications into Docker images\", \" and \\ndeploy them with the same tools as the rest of the Docker ecosystem. To use Windows Containers\", \", \\nyou run PowerShell commands in the Dockerfile, as shown in the following example: \\nFROM mcr.micro\", \"soft.com/windows/servercore \\nLABEL Description=\\\"IIS\\\" Vendor=\\\"Microsoft\\\" Version=\\\"10\\\" \\nRUN powershell\", \" -Command Add-WindowsFeature Web-Server \\nCMD [ \\\"ping\\\", \\\"localhost\\\", \\\"-t\\\" ] \\nIn this case, we are usi\", \"ng a Windows Server Core base image (the FROM setting) and installing IIS with \\na PowerShell command\", \" (the RUN setting). In a similar way, you could also use PowerShell commands \\nto set up additional c\", \"omponents like ASP.NET 4.x, .NET Framework 4.6, or any other Windows \\nsoftware. For example, the fol\", \"lowing command in a Dockerfile sets up ASP.NET 4.5: \\nRUN powershell add-windowsfeature web-asp-net45\", \" \\nAdditional resources \\n\\u2022 \\naspnet-docker/Dockerfile. Example PowerShell commands to run from dockerf\", \"iles to \\ninclude Windows features. \\n \\n92 \\nCHAPTER 4 | Development process for Docker-based applicati\", \"ons \\n \\nhttps://github.com/Microsoft/aspnet-docker/blob/master/4.7.1-windowsservercore-\\nltsc2016/runt\", \"ime/Dockerfile \\n \\n93 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications \\n \\nCHAPTER 5 \\nDesigning and Developing \\nMulti-Container and \\nMicroservice-Based .NET\", \" \\nApplications \\nDeveloping containerized microservice applications means you are building multi-cont\", \"ainer \\napplications. However, a multi-container application could also be simpler\\u2014for example, a thr\", \"ee-tier \\napplication\\u2014and might not be built using a microservice architecture. \\nEarlier we raised th\", \"e question \\u201cIs Docker necessary when building a microservice architecture?\\u201d The \\nanswer is a clear n\", \"o. Docker is an enabler and can provide significant benefits, but containers and \\nDocker are not a h\", \"ard requirement for microservices. As an example, you could create a \\nmicroservices-based applicatio\", \"n with or without Docker when using Azure Service Fabric, which \\nsupports microservices running as s\", \"imple processes or as Docker containers. \\nHowever, if you know how to design and develop a microserv\", \"ices-based application that is also based \\non Docker containers, you will be able to design and deve\", \"lop any other, simpler application model. \\nFor example, you might design a three-tier application th\", \"at also requires a multi-container approach. \\nBecause of that, and because microservice architecture\", \"s are an important trend within the container \\nworld, this section focuses on a microservice archite\", \"cture implementation using Docker containers. \\nDesign a microservice-oriented application \\nThis sect\", \"ion focuses on developing a hypothetical server-side enterprise application. \\nApplication specificat\", \"ions \\nThe hypothetical application handles requests by executing business logic, accessing databases\", \", and \\nthen returning HTML, JSON, or XML responses. We will say that the application must support va\", \"rious \\nclients, including desktop browsers running Single Page Applications (SPAs), traditional web \", \"apps, \\nmobile web apps, and native mobile apps. The application might also expose an API for third p\", \"arties \\n \\n94 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appli\", \"cations \\n \\nto consume. It should also be able to integrate its microservices or external application\", \"s \\nasynchronously, so that approach will help resiliency of the microservices in the case of partial\", \" failures. \\nThe application will consist of these types of components: \\n\\u2022 \\nPresentation components. \", \"These components are responsible for handling the UI and \\nconsuming remote services. \\n\\u2022 \\nDomain or b\", \"usiness logic. This component is the application\\u2019s domain logic. \\n\\u2022 \\nDatabase access logic. This com\", \"ponent consists of data access components responsible for \\naccessing databases (SQL or NoSQL). \\n\\u2022 \\nA\", \"pplication integration logic. This component includes a messaging channel, based on \\nmessage brokers\", \". \\nThe application will require high scalability, while allowing its vertical subsystems to scale ou\", \"t \\nautonomously, because certain subsystems will require more scalability than others. \\nThe applicat\", \"ion must be able to be deployed in multiple infrastructure environments (multiple public \\nclouds and\", \" on-premises) and ideally should be cross-platform, able to move from Linux to Windows \\n(or vice ver\", \"sa) easily. \\nDevelopment team context \\nWe also assume the following about the development process fo\", \"r the application: \\n\\u2022 \\nYou have multiple dev teams focusing on different business areas of the appli\", \"cation. \\n\\u2022 \\nNew team members must become productive quickly, and the application must be easy to \\nun\", \"derstand and modify. \\n\\u2022 \\nThe application will have a long-term evolution and ever-changing business \", \"rules. \\n\\u2022 \\nYou need good long-term maintainability, which means having agility when implementing \\nne\", \"w changes in the future while being able to update multiple subsystems with minimum \\nimpact on the o\", \"ther subsystems. \\n\\u2022 \\nYou want to practice continuous integration and continuous deployment of the ap\", \"plication. \\n\\u2022 \\nYou want to take advantage of emerging technologies (frameworks, programming language\", \"s, \\netc.) while evolving the application. You do not want to make full migrations of the \\napplicatio\", \"n when moving to new technologies, because that would result in high costs and \\nimpact the predictab\", \"ility and stability of the application. \\nChoosing an architecture \\nWhat should the application deplo\", \"yment architecture be? The specifications for the application, along \\nwith the development context, \", \"strongly suggest that you should architect the application by \\ndecomposing it into autonomous subsys\", \"tems in the form of collaborating microservices and \\ncontainers, where a microservice is a container\", \". \\n \\n95 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicatio\", \"ns \\n \\nIn this approach, each service (container) implements a set of cohesive and narrowly related f\", \"unctions. \\nFor example, an application might consist of services such as the catalog service, orderi\", \"ng service, \\nbasket service, user profile service, etc. \\nMicroservices communicate using protocols s\", \"uch as HTTP (REST), but also asynchronously (for \\nexample, using AMQP) whenever possible, especially\", \" when propagating updates with integration \\nevents. \\nMicroservices are developed and deployed as con\", \"tainers independently of one another. This approach \\nmeans that a development team can be developing\", \" and deploying a certain microservice without \\nimpacting other subsystems. \\nEach microservice has it\", \"s own database, allowing it to be fully decoupled from other microservices. \\nWhen necessary, consist\", \"ency between databases from different microservices is achieved using \\napplication-level integration\", \" events (through a logical event bus), as handled in Command and Query \\nResponsibility Segregation (\", \"CQRS). Because of that, the business constraints must embrace eventual \\nconsistency between the mult\", \"iple microservices and related databases. \\neShopOnContainers: A reference application for .NET and m\", \"icroservices deployed \\nusing containers \\nSo that you can focus on the architecture and technologies \", \"instead of thinking about a hypothetical \\nbusiness domain that you might not know, we have selected \", \"a well-known business domain\\u2014namely, \\na simplified e-commerce (e-shop) application that presents a c\", \"atalog of products, takes orders from \\ncustomers, verifies inventory, and performs other business fu\", \"nctions. This container-based application \\nsource code is available in the eShopOnContainers GitHub \", \"repo. \\nThe application consists of multiple subsystems, including several store UI front ends (a Web\", \" \\napplication and a native mobile app), along with the back-end microservices and containers for all\", \" the \\nrequired server-side operations with several API Gateways as consolidated entry points to the \", \"internal \\nmicroservices. Figure 6-1 shows the architecture of the reference application. \\n \\n96 \\nCHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigur\", \"e 6-1. The eShopOnContainers reference application architecture for development environment \\nThe abo\", \"ve diagram shows that Mobile and SPA clients communicate to single API gateway endpoints, \\nthat then\", \" communicate to microservices. Traditional web clients communicate to MVC microservice, \\nthat commun\", \"icates to microservices through the API gateway. \\nHosting environment. In Figure 6-1, you see severa\", \"l containers deployed within a single Docker host. \\nThat would be the case when deploying to a singl\", \"e Docker host with the docker-compose up \\ncommand. However, if you are using an orchestrator or cont\", \"ainer cluster, each container could be \\nrunning in a different host (node), and any node could be ru\", \"nning any number of containers, as we \\nexplained earlier in the architecture section. \\nCommunication\", \" architecture. The eShopOnContainers application uses two communication types, \\ndepending on the kin\", \"d of the functional action (queries versus updates and transactions): \\n\\u2022 \\nHttp client-to-microservic\", \"e communication through API Gateways. This approach is used for \\nqueries and when accepting update o\", \"r transactional commands from the client apps. The \\napproach using API Gateways is explained in deta\", \"il in later sections. \\n\\u2022 \\nAsynchronous event-based communication. This communication occurs through \", \"an event bus \\nto propagate updates across microservices or to integrate with external applications. \", \"The \\nevent bus can be implemented with any messaging-broker infrastructure technology like \\nRabbitMQ\", \", or using higher-level (abstraction-level) service buses like Azure Service Bus, \\nNServiceBus, Mass\", \"Transit, or Brighter. \\nThe application is deployed as a set of microservices in the form of containe\", \"rs. Client apps can \\ncommunicate with those microservices running as containers through the public U\", \"RLs published by \\nthe API Gateways. \\n \\n97 \\nCHAPTER 5 | Designing and Developing Multi-Container and \", \"Microservice-Based .NET Applications \\n \\nData sovereignty per microservice \\nIn the sample application\", \", each microservice owns its own database or data source, although all SQL \\nServer databases are dep\", \"loyed as a single container. This design decision was made only to make it \\neasy for a developer to \", \"get the code from GitHub, clone it, and open it in Visual Studio or Visual \\nStudio Code. Or alternat\", \"ively, it makes it easy to compile the custom Docker images using the .NET \\nCLI and the Docker CLI, \", \"and then deploy and run them in a Docker development environment. Either \\nway, using containers for \", \"data sources lets developers build and deploy in a matter of minutes without \\nhaving to provision an\", \" external database or any other data source with hard dependencies on \\ninfrastructure (cloud or on-p\", \"remises). \\nIn a real production environment, for high availability and for scalability, the database\", \"s should be \\nbased on database servers in the cloud or on-premises, but not in containers. \\nTherefor\", \"e, the units of deployment for microservices (and even for databases in this application) are \\nDocke\", \"r containers, and the reference application is a multi-container application that embraces \\nmicroser\", \"vices principles. \\nAdditional resources \\n\\u2022 \\neShopOnContainers GitHub repo. Source code for the refer\", \"ence application \\nhttps://aka.ms/eShopOnContainers/ \\nBenefits of a microservice-based solution \\nA mi\", \"croservice-based solution like this has many benefits: \\nEach microservice is relatively small\\u2014easy t\", \"o manage and evolve. Specifically: \\n\\u2022 \\nIt is easy for a developer to understand and get started quic\", \"kly with good productivity. \\n\\u2022 \\nContainers start fast, which makes developers more productive. \\n\\u2022 \\nA\", \"n IDE like Visual Studio can load smaller projects fast, making developers productive. \\n\\u2022 \\nEach micr\", \"oservice can be designed, developed, and deployed independently of other \\nmicroservices, which provi\", \"de agility because it is easier to deploy new versions of \\nmicroservices frequently. \\nIt is possible\", \" to scale out individual areas of the application. For instance, the catalog service or \\nthe basket \", \"service might need to be scaled out, but not the ordering process. A microservices \\ninfrastructure w\", \"ill be much more efficient with regard to the resources used when scaling out than a \\nmonolithic arc\", \"hitecture would be. \\nYou can divide the development work between multiple teams. Each service can be\", \" owned by a \\nsingle development team. Each team can manage, develop, deploy, and scale their service\", \" \\nindependently of the rest of the teams. \\nIssues are more isolated. If there is an issue in one ser\", \"vice, only that service is initially impacted \\n(except when the wrong design is used, with direct de\", \"pendencies between microservices), and other \\nservices can continue to handle requests. In contrast,\", \" one malfunctioning component in a monolithic \\n \\n98 \\nCHAPTER 5 | Designing and Developing Multi-Cont\", \"ainer and Microservice-Based .NET Applications \\n \\ndeployment architecture can bring down the entire \", \"system, especially when it involves resources, such \\nas a memory leak. Additionally, when an issue i\", \"n a microservice is resolved, you can deploy just the \\naffected microservice without impacting the r\", \"est of the application. \\nYou can use the latest technologies. Because you can start developing servi\", \"ces independently and \\nrun them side by side (thanks to containers and .NET), you can start using th\", \"e latest technologies and \\nframeworks expediently instead of being stuck on an older stack or framew\", \"ork for the whole \\napplication. \\nDownsides of a microservice-based solution \\nA microservice-based so\", \"lution like this also has some drawbacks: \\nDistributed application. Distributing the application add\", \"s complexity for developers when they are \\ndesigning and building the services. For example, develop\", \"ers must implement inter-service \\ncommunication using protocols like HTTP or AMQP, which adds comple\", \"xity for testing and exception \\nhandling. It also adds latency to the system. \\nDeployment complexity\", \". An application that has dozens of microservices types and needs high \\nscalability (it needs to be \", \"able to create many instances per service and balance those services across \\nmany hosts) means a hig\", \"h degree of deployment complexity for IT operations and management. If \\nyou are not using a microser\", \"vice-oriented infrastructure (like an orchestrator and scheduler), that \\nadditional complexity can r\", \"equire far more development efforts than the business application itself. \\nAtomic transactions. Atom\", \"ic transactions between multiple microservices usually are not possible. \\nThe business requirements \", \"have to embrace eventual consistency between multiple microservices. \\nIncreased global resource need\", \"s (total memory, drives, and network resources for all the servers or \\nhosts). In many cases, when y\", \"ou replace a monolithic application with a microservices approach, the \\namount of initial global res\", \"ources needed by the new microservice-based application will be larger \\nthan the infrastructure need\", \"s of the original monolithic application. This approach is because the \\nhigher degree of granularity\", \" and distributed services requires more global resources. However, given \\nthe low cost of resources \", \"in general and the benefit of being able to scale out certain areas of the \\napplication compared to \", \"long-term costs when evolving monolithic applications, the increased use of \\nresources is usually a \", \"good tradeoff for large, long-term applications. \\nIssues with direct client-to-microservice communic\", \"ation. When the application is large, with \\ndozens of microservices, there are challenges and limita\", \"tions if the application requires direct client-\\nto-microservice communications. One problem is a po\", \"tential mismatch between the needs of the \\nclient and the APIs exposed by each of the microservices.\", \" In certain cases, the client application might \\nneed to make many separate requests to compose the \", \"UI, which can be inefficient over the Internet \\nand would be impractical over a mobile network. Ther\", \"efore, requests from the client application to the \\nback-end system should be minimized. \\nAnother pr\", \"oblem with direct client-to-microservice communications is that some microservices might \\nbe using p\", \"rotocols that are not Web-friendly. One service might use a binary protocol, while another \\nservice \", \"might use AMQP messaging. Those protocols are not firewall-friendly and are best used \\ninternally. U\", \"sually, an application should use protocols such as HTTP and WebSockets for \\ncommunication outside o\", \"f the firewall. \\n \\n99 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applications \\n \\nYet another drawback with this direct client-to-service approach is that it make\", \"s it difficult to refactor \\nthe contracts for those microservices. Over time developers might want t\", \"o change how the system is \\npartitioned into services. For example, they might merge two services or\", \" split a service into two or \\nmore services. However, if clients communicate directly with the servi\", \"ces, performing this kind of \\nrefactoring can break compatibility with client apps. \\nAs mentioned in\", \" the architecture section, when designing and building a complex application based \\non microservices\", \", you might consider the use of multiple fine-grained API Gateways instead of the \\nsimpler direct cl\", \"ient-to-microservice communication approach. \\nPartitioning the microservices. Finally, no matter, wh\", \"ich approach you take for your microservice \\narchitecture, another challenge is deciding how to part\", \"ition an end-to-end application into multiple \\nmicroservices. As noted in the architecture section o\", \"f the guide, there are several techniques and \\napproaches you can take. Basically, you need to ident\", \"ify areas of the application that are decoupled \\nfrom the other areas and that have a low number of \", \"hard dependencies. In many cases, this approach \\nis aligned to partitioning services by use case. Fo\", \"r example, in our e-shop application, we have an \\nordering service that is responsible for all the b\", \"usiness logic related to the order process. We also \\nhave the catalog service and the basket service\", \" that implement other capabilities. Ideally, each service \\nshould have only a small set of responsib\", \"ilities. This approach is similar to the single responsibility \\nprinciple (SRP) applied to classes, \", \"which states that a class should only have one reason to change. But \\nin this case, it is about micr\", \"oservices, so the scope will be larger than a single class. Most of all, a \\nmicroservice has to be a\", \"utonomous, end to end, including responsibility for its own data sources. \\nExternal versus internal \", \"architecture and design patterns \\nThe external architecture is the microservice architecture compose\", \"d by multiple services, following the \\nprinciples described in the architecture section of this guid\", \"e. However, depending on the nature of \\neach microservice, and independently of high-level microserv\", \"ice architecture you choose, it is \\ncommon and sometimes advisable to have different internal archit\", \"ectures, each based on different \\npatterns, for different microservices. The microservices can even \", \"use different technologies and \\nprogramming languages. Figure 6-2 illustrates this diversity. \\n \\n100\", \" \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \", \"\\nFigure 6-2. External versus internal architecture and design \\nFor instance, in our eShopOnContainer\", \"s sample, the catalog, basket, and user profile microservices are \\nsimple (basically, CRUD subsystem\", \"s). Therefore, their internal architecture and design is \\nstraightforward. However, you might have o\", \"ther microservices, such as the ordering microservice, \\nwhich is more complex and represents ever-ch\", \"anging business rules with a high degree of domain \\ncomplexity. In cases like these, you might want \", \"to implement more advanced patterns within a \\nparticular microservice, like the ones defined with do\", \"main-driven design (DDD) approaches, as we are \\ndoing in the eShopOnContainers ordering microservice\", \". (We will review these DDD patterns in the \\nsection later that explains the implementation of the e\", \"ShopOnContainers ordering microservice.) \\nAnother reason for a different technology per microservice\", \" might be the nature of each microservice. \\nFor example, it might be better to use a functional prog\", \"ramming language like F#, or even a language \\nlike R if you are targeting AI and machine learning do\", \"mains, instead of a more object-oriented \\nprogramming language like C#. \\nThe bottom line is that eac\", \"h microservice can have a different internal architecture based on different \\ndesign patterns. Not a\", \"ll microservices should be implemented using advanced DDD patterns, because \\nthat would be over-engi\", \"neering them. Similarly, complex microservices with ever-changing business \\nlogic should not be impl\", \"emented as CRUD components, or you can end up with low-quality code. \\nThe new world: multiple archit\", \"ectural patterns and polyglot \\nmicroservices \\nThere are many architectural patterns used by software\", \" architects and developers. The following are a \\nfew (mixing architecture styles and architecture pa\", \"tterns): \\n\\u2022 \\nSimple CRUD, single-tier, single-layer. \\n \\n101 \\nCHAPTER 5 | Designing and Developing Mu\", \"lti-Container and Microservice-Based .NET Applications \\n \\n\\u2022 \\nTraditional N-Layered. \\n\\u2022 \\nDomain-Drive\", \"n Design N-layered. \\n\\u2022 \\nClean Architecture (as used with eShopOnWeb) \\n\\u2022 \\nCommand and Query Responsib\", \"ility Segregation (CQRS). \\n\\u2022 \\nEvent-Driven Architecture (EDA). \\nYou can also build microservices wit\", \"h many technologies and languages, such as ASP.NET Core Web \\nAPIs, NancyFx, ASP.NET Core SignalR (av\", \"ailable with .NET Core 2 or later), F#, Node.js, Python, Java, \\nC++, GoLang, and more. \\nThe importan\", \"t point is that no particular architecture pattern or style, nor any particular technology, is \\nrigh\", \"t for all situations. Figure 6-3 shows some approaches and technologies (although not in any \\npartic\", \"ular order) that could be used in different microservices. \\n \\nFigure 6-3. Multi-architectural patter\", \"ns and the polyglot microservices world \\nMulti-architectural pattern and polyglot microservices mean\", \"s you can mix and match languages and \\ntechnologies to the needs of each microservice and still have\", \" them talking to each other. As shown in \\nFigure 6-3, in applications composed of many microservices\", \" (Bounded Contexts in domain-driven \\ndesign terminology, or simply \\u201csubsystems\\u201d as autonomous micros\", \"ervices), you might implement \\neach microservice in a different way. Each might have a different arc\", \"hitecture pattern and use different \\nlanguages and databases depending on the application\\u2019s nature, \", \"business requirements, and \\npriorities. In some cases, the microservices might be similar. But that \", \"is not usually the case, because \\neach subsystem\\u2019s context boundary and requirements are usually dif\", \"ferent. \\n \\n102 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET App\", \"lications \\n \\nFor instance, for a simple CRUD maintenance application, it might not make sense to des\", \"ign and \\nimplement DDD patterns. But for your core domain or core business, you might need to apply \", \"more \\nadvanced patterns to tackle business complexity with ever-changing business rules. \\nEspecially\", \" when you deal with large applications composed by multiple subsystems, you should not \\napply a sing\", \"le top-level architecture based on a single architecture pattern. For instance, CQRS should \\nnot be \", \"applied as a top-level architecture for a whole application, but might be useful for a specific set \", \"\\nof services. \\nThere is no silver bullet or a right architecture pattern for every given case. You c\", \"annot have \\u201cone \\narchitecture pattern to rule them all.\\u201d Depending on the priorities of each microse\", \"rvice, you must \\nchoose a different approach for each, as explained in the following sections. \\nCrea\", \"ting a simple data-driven CRUD microservice \\nThis section outlines how to create a simple microservi\", \"ce that performs create, read, update, and \\ndelete (CRUD) operations on a data source. \\nDesigning a \", \"simple CRUD microservice \\nFrom a design point of view, this type of containerized microservice is ve\", \"ry simple. Perhaps the \\nproblem to solve is simple, or perhaps the implementation is only a proof of\", \" concept. \\n \\nFigure 6-4. Internal design for simple CRUD microservices \\nAn example of this kind of s\", \"imple data-drive service is the catalog microservice from the \\neShopOnContainers sample application.\", \" This type of service implements all its functionality in a single \\nASP.NET Core Web API project tha\", \"t includes classes for its data model, its business logic, and its data \\naccess code. It also stores\", \" its related data in a database running in SQL Server (as another container \\nfor dev/test purposes),\", \" but could also be any regular SQL Server host, as shown in Figure 6-5. \\n \\n103 \\nCHAPTER 5 | Designin\", \"g and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-5. Simple da\", \"ta-driven/CRUD microservice design \\nThe previous diagram shows the logical Catalog microservice, tha\", \"t includes its Catalog database, \\nwhich can be or not in the same Docker host. Having the database i\", \"n the same Docker host might be \\ngood for development, but not for production. When you are developi\", \"ng this kind of service, you only \\nneed ASP.NET Core and a data-access API or ORM like Entity Framew\", \"ork Core. You could also \\ngenerate Swagger metadata automatically through Swashbuckle to provide a d\", \"escription of what your \\nservice offers, as explained in the next section. \\nNote that running a data\", \"base server like SQL Server within a Docker container is great for \\ndevelopment environments, becaus\", \"e you can have all your dependencies up and running without \\nneeding to provision a database in the \", \"cloud or on-premises. This approach is convenient when \\nrunning integration tests. However, for prod\", \"uction environments, running a database server in a \\ncontainer is not recommended, because you usual\", \"ly do not get high availability with that approach. \\nFor a production environment in Azure, it is re\", \"commended that you use Azure SQL DB or any other \\ndatabase technology that can provide high availabi\", \"lity and high scalability. For example, for a NoSQL \\napproach, you might choose CosmosDB. \\nFinally, \", \"by editing the Dockerfile and docker-compose.yml metadata files, you can configure how the \\nimage of\", \" this container will be created\\u2014what base image it will use, plus design settings such as \\ninternal \", \"and external names and TCP ports. \\nImplementing a simple CRUD microservice with ASP.NET Core \\nTo imp\", \"lement a simple CRUD microservice using .NET and Visual Studio, you start by creating a \\nsimple ASP.\", \"NET Core Web API project (running on .NET so it can run on a Linux Docker host), as \\nshown in Figure\", \" 6-6. \\n \\n104 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appli\", \"cations \\n \\n \\nFigure 6-6. Creating an ASP.NET Core Web API project in Visual Studio 2019 \\nTo create a\", \"n ASP.NET Core Web API Project, first select an ASP.NET Core Web Application and then \\nselect the AP\", \"I type. After creating the project, you can implement your MVC controllers as you would \\nin any othe\", \"r Web API project, using the Entity Framework API or other API. In a new Web API project, \\nyou can s\", \"ee that the only dependency you have in that microservice is on ASP.NET Core itself. \\nInternally, wi\", \"thin the Microsoft.AspNetCore.All dependency, it is referencing Entity Framework and \\nmany other .NE\", \"T NuGet packages, as shown in Figure 6-7. \\n \\n105 \\nCHAPTER 5 | Designing and Developing Multi-Contain\", \"er and Microservice-Based .NET Applications \\n \\n \\nFigure 6-7. Dependencies in a simple CRUD Web API m\", \"icroservice \\nThe API project includes references to Microsoft.AspNetCore.App NuGet package, that inc\", \"ludes \\nreferences to all essential packages. It could include some other packages as well. \\nImplemen\", \"ting CRUD Web API services with Entity Framework Core \\nEntity Framework (EF) Core is a lightweight, \", \"extensible, and cross-platform version of the popular \\nEntity Framework data access technology. EF C\", \"ore is an object-relational mapper (ORM) that enables \\n.NET developers to work with a database using\", \" .NET objects. \\nThe catalog microservice uses EF and the SQL Server provider because its database is\", \" running in a \\ncontainer with the SQL Server for Linux Docker image. However, the database could be \", \"deployed into \\n \\n106 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications \\n \\nany SQL Server, such as Windows on-premises or Azure SQL DB. The only thing you w\", \"ould need to \\nchange is the connection string in the ASP.NET Web API microservice. \\nThe data model \\n\", \"With EF Core, data access is performed by using a model. A model is made up of (domain model) \\nentit\", \"y classes and a derived context (DbContext) that represents a session with the database, allowing \\ny\", \"ou to query and save data. You can generate a model from an existing database, manually code a \\nmode\", \"l to match your database, or use EF migrations technique to create a database from your model, \\nusin\", \"g the code-first approach (that makes it easy to evolve the database as your model changes over \\ntim\", \"e). For the catalog microservice, the last approach has been used. You can see an example of the \\nCa\", \"talogItem entity class in the following code example, which is a simple Plain Old Class Object \\n(POC\", \"O) entity class. \\npublic class CatalogItem \\n{ \\n    public int Id { get; set; } \\n    public string Na\", \"me { get; set; } \\n    public string Description { get; set; } \\n    public decimal Price { get; set; \", \"} \\n    public string PictureFileName { get; set; } \\n    public string PictureUri { get; set; } \\n    \", \"public int CatalogTypeId { get; set; } \\n    public CatalogType CatalogType { get; set; } \\n    public\", \" int CatalogBrandId { get; set; } \\n    public CatalogBrand CatalogBrand { get; set; } \\n    public in\", \"t AvailableStock { get; set; } \\n    public int RestockThreshold { get; set; } \\n    public int MaxSto\", \"ckThreshold { get; set; } \\n \\n    public bool OnReorder { get; set; } \\n    public CatalogItem() { } \\n\", \" \\n    // Additional code ... \\n} \\nYou also need a DbContext that represents a session with the databa\", \"se. For the catalog microservice, \\nthe CatalogContext class derives from the DbContext base class, a\", \"s shown in the following example: \\npublic class CatalogContext : DbContext \\n{ \\n    public CatalogCon\", \"text(DbContextOptions<CatalogContext> options) : base(options) \\n    { } \\n    public DbSet<CatalogIte\", \"m> CatalogItems { get; set; } \\n    public DbSet<CatalogBrand> CatalogBrands { get; set; } \\n    publi\", \"c DbSet<CatalogType> CatalogTypes { get; set; } \\n \\n    // Additional code ... \\n} \\nYou can have addit\", \"ional DbContext implementations. For example, in the sample Catalog.API \\nmicroservice, there\\u2019s a sec\", \"ond DbContext named CatalogContextSeed where it automatically \\npopulates the sample data the first t\", \"ime it tries to access the database. This method is useful for demo \\ndata and for automated testing \", \"scenarios, as well. \\n \\n107 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Ba\", \"sed .NET Applications \\n \\nWithin the DbContext, you use the OnModelCreating method to customize objec\", \"t/database entity \\nmappings and other EF extensibility points. \\nQuerying data from Web API controlle\", \"rs \\nInstances of your entity classes are typically retrieved from the database using Language-Integr\", \"ated \\nQuery (LINQ), as shown in the following example: \\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class\", \" CatalogController : ControllerBase \\n{ \\n    private readonly CatalogContext _catalogContext; \\n    pr\", \"ivate readonly CatalogSettings _settings; \\n    private readonly ICatalogIntegrationEventService _cat\", \"alogIntegrationEventService; \\n \\n    public CatalogController( \\n        CatalogContext context, \\n    \", \"    IOptionsSnapshot<CatalogSettings> settings, \\n        ICatalogIntegrationEventService catalogInte\", \"grationEventService) \\n    { \\n        _catalogContext = context ?? throw new ArgumentNullException(na\", \"meof(context)); \\n        _catalogIntegrationEventService = catalogIntegrationEventService \\n         \", \"   ?? throw new ArgumentNullException(nameof(catalogIntegrationEventService)); \\n \\n        _settings \", \"= settings.Value; \\n        context.ChangeTracker.QueryTrackingBehavior = QueryTrackingBehavior.NoTra\", \"cking; \\n    } \\n \\n    // GET api/v1/[controller]/items[?pageSize=3&pageIndex=10] \\n    [HttpGet] \\n    \", \"[Route(\\\"items\\\")] \\n    [ProducesResponseType(typeof(PaginatedItemsViewModel<CatalogItem>), \\n(int)Http\", \"StatusCode.OK)] \\n    [ProducesResponseType(typeof(IEnumerable<CatalogItem>), (int)HttpStatusCode.OK)\", \"] \\n    [ProducesResponseType((int)HttpStatusCode.BadRequest)] \\n    public async Task<IActionResult> \", \"ItemsAsync( \\n        [FromQuery]int pageSize = 10, \\n        [FromQuery]int pageIndex = 0, \\n        s\", \"tring ids = null) \\n    { \\n        if (!string.IsNullOrEmpty(ids)) \\n        { \\n            var items \", \"= await GetItemsByIdsAsync(ids); \\n \\n            if (!items.Any()) \\n            { \\n                re\", \"turn BadRequest(\\\"ids value invalid. Must be comma-separated list of \\nnumbers\\\"); \\n            } \\n \\n  \", \"          return Ok(items); \\n        } \\n \\n        var totalItems = await _catalogContext.CatalogItem\", \"s \\n            .LongCountAsync(); \\n \\n        var itemsOnPage = await _catalogContext.CatalogItems \\n \", \"           .OrderBy(c => c.Name) \\n            .Skip(pageSize * pageIndex) \\n \\n108 \\nCHAPTER 5 | Design\", \"ing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n            .Take(pag\", \"eSize) \\n            .ToListAsync(); \\n \\n        itemsOnPage = ChangeUriPlaceholder(itemsOnPage); \\n \\n \", \"       var model = new PaginatedItemsViewModel<CatalogItem>( \\n            pageIndex, pageSize, total\", \"Items, itemsOnPage); \\n \\n        return Ok(model); \\n    } \\n    //... \\n} \\nSaving data \\nData is created\", \", deleted, and modified in the database using instances of your entity classes. You \\ncould add code \", \"like the following hard-coded example (mock data, in this case) to your Web API \\ncontrollers. \\nvar c\", \"atalogItem = new CatalogItem() {CatalogTypeId=2, CatalogBrandId=2, \\n                                \", \"     Name=\\\"Roslyn T-Shirt\\\", Price = 12}; \\n_context.Catalog.Add(catalogItem); \\n_context.SaveChanges()\", \"; \\nDependency Injection in ASP.NET Core and Web API controllers \\nIn ASP.NET Core, you can use Depend\", \"ency Injection (DI) out of the box. You do not need to set up a \\nthird-party Inversion of Control (I\", \"oC) container, although you can plug your preferred IoC container \\ninto the ASP.NET Core infrastruct\", \"ure if you want. In this case, it means that you can directly inject the \\nrequired EF DBContext or a\", \"dditional repositories through the controller constructor. \\nIn the CatalogController class mentioned\", \" earlier, CatalogContext (which inherits from DbContext) type \\nis injected along with the other requ\", \"ired objects in the CatalogController() constructor. \\nAn important configuration to set up in the We\", \"b API project is the DbContext class registration into \\nthe service\\u2019s IoC container. You typically d\", \"o so in the Program.cs file by calling the \\nbuilder.Services.AddDbContext<CatalogContext>() method, \", \"as shown in the following simplified \\nexample: \\n// Additional code... \\n \\nbuilder.Services.AddDbConte\", \"xt<CatalogContext>(options => \\n{ \\n    options.UseSqlServer(builder.Configuration[\\\"ConnectionString\\\"]\", \", \\n    sqlServerOptionsAction: sqlOptions => \\n    { \\n        sqlOptions.MigrationsAssembly( \\n       \", \"     typeof(Program).GetTypeInfo().Assembly.GetName().Name); \\n \\n        //Configuring Connection Res\", \"iliency: \\n        sqlOptions. \\n            EnableRetryOnFailure(maxRetryCount: 5, \\n            maxRe\", \"tryDelay: TimeSpan.FromSeconds(30), \\n            errorNumbersToAdd: null); \\n    }); \\n \\n \\n109 \\nCHAPTE\", \"R 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n    // Ch\", \"anging default behavior when client evaluation occurs to throw. \\n    // Default in EFCore would be t\", \"o log warning when client evaluation is done. \\n    options.ConfigureWarnings(warnings => warnings.Th\", \"row( \\n        RelationalEventId.QueryClientEvaluationWarning)); \\n}); \\nAdditional resources \\n\\u2022 \\nQuery\", \"ing Data \\nhttps://learn.microsoft.com/ef/core/querying/index \\n\\u2022 \\nSaving Data \\nhttps://learn.microsof\", \"t.com/ef/core/saving/index \\nThe DB connection string and environment variables used by Docker \\nconta\", \"iners \\nYou can use the ASP.NET Core settings and add a ConnectionString property to your settings.js\", \"on file \\nas shown in the following example: \\n{ \\n    \\\"ConnectionString\\\": \\\"Server=tcp:127.0.0.1,5433;I\", \"nitial \\nCatalog=Microsoft.eShopOnContainers.Services.CatalogDb;User Id=sa;Password=[PLACEHOLDER]\\\", \\n\", \"    \\\"ExternalCatalogBaseUrl\\\": \\\"http://host.docker.internal:5101\\\", \\n    \\\"Logging\\\": { \\n        \\\"Includ\", \"eScopes\\\": false, \\n        \\\"LogLevel\\\": { \\n            \\\"Default\\\": \\\"Debug\\\", \\n            \\\"System\\\": \\\"Inf\", \"ormation\\\", \\n            \\\"Microsoft\\\": \\\"Information\\\" \\n        } \\n    } \\n} \\nThe settings.json file can \", \"have default values for the ConnectionString property or for any other \\nproperty. However, those pro\", \"perties will be overridden by the values of environment variables that \\nyou specify in the docker-co\", \"mpose.override.yml file, when using Docker. \\nFrom your docker-compose.yml or docker-compose.override\", \".yml files, you can initialize those \\nenvironment variables so that Docker will set them up as OS en\", \"vironment variables for you, as shown \\nin the following docker-compose.override.yml file (the connec\", \"tion string and other lines wrap in this \\nexample, but it would not wrap in your own file). \\n# docke\", \"r-compose.override.yml \\n \\n# \\ncatalog-api: \\n  environment: \\n    - \\nConnectionString=Server=sqldata;Da\", \"tabase=Microsoft.eShopOnContainers.Services.CatalogDb;Use\\nr Id=sa;Password=[PLACEHOLDER] \\n    # Addi\", \"tional environment variables for this service \\n  ports: \\n    - \\\"5101:80\\\" \\n \\n110 \\nCHAPTER 5 | Designi\", \"ng and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nThe docker-compose.yml\", \" files at the solution level are not only more flexible than configuration files \\nat the project or \", \"microservice level, but also more secure if you override the environment variables \\ndeclared at the \", \"docker-compose files with values set from your deployment tools, like from Azure \\nDevOps Services Do\", \"cker deployment tasks. \\nFinally, you can get that value from your code by using builder.Configuratio\", \"n\\\\[\\\"ConnectionString\\\"\\\\], as \\nshown in an earlier code example. \\nHowever, for production environments\", \", you might want to explore additional ways on how to store \\nsecrets like the connection strings. An\", \" excellent way to manage application secrets is using Azure Key \\nVault. \\nAzure Key Vault helps to st\", \"ore and safeguard cryptographic keys and secrets used by your cloud \\napplications and services. A se\", \"cret is anything you want to keep strict control of, like API keys, \\nconnection strings, passwords, \", \"etc. and strict control includes usage logging, setting expiration, \\nmanaging access, among others. \", \"\\nAzure Key Vault allows a detailed control level of the application secrets usage without the need t\", \"o let \\nanyone know them. The secrets can even be rotated for enhanced security without disrupting \\nd\", \"evelopment or operations. \\nApplications have to be registered in the organization\\u2019s Active Directory\", \", so they can use the Key \\nVault. \\nYou can check the Key Vault Concepts documentation for more detai\", \"ls. \\nImplementing versioning in ASP.NET Web APIs \\nAs business requirements change, new collections o\", \"f resources may be added, the relationships \\nbetween resources might change, and the structure of th\", \"e data in resources might be amended. \\nUpdating a Web API to handle new requirements is a relatively\", \" straightforward process, but you must \\nconsider the effects that such changes will have on client a\", \"pplications consuming the Web API. \\nAlthough the developer designing and implementing a Web API has \", \"full control over that API, the \\ndeveloper does not have the same degree of control over client appl\", \"ications that might be built by \\nthird-party organizations operating remotely. \\nVersioning enables a\", \" Web API to indicate the features and resources that it exposes. A client \\napplication can then subm\", \"it requests to a specific version of a feature or resource. There are several \\napproaches to impleme\", \"nt versioning: \\n\\u2022 \\nURI versioning \\n\\u2022 \\nQuery string versioning \\n\\u2022 \\nHeader versioning \\nQuery string an\", \"d URI versioning are the simplest to implement. Header versioning is a good \\napproach. However, head\", \"er versioning is not as explicit and straightforward as URI versioning. \\nBecause URL versioning is t\", \"he simplest and most explicit, the eShopOnContainers sample application \\nuses URI versioning. \\n \\n111\", \" \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nW\", \"ith URI versioning, as in the eShopOnContainers sample application, each time you modify the Web \\nAP\", \"I or change the schema of resources, you add a version number to the URI for each resource. \\nExistin\", \"g URIs should continue to operate as before, returning resources that conform to the schema \\nthat ma\", \"tches the requested version. \\nAs shown in the following code example, the version can be set by usin\", \"g the Route attribute in the \\nWeb API controller, which makes the version explicit in the URI (v1 in\", \" this case). \\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class CatalogController : ControllerBase \\n{ \\n  \", \"  // Implementation ... \\nThis versioning mechanism is simple and depends on the server routing the r\", \"equest to the \\nappropriate endpoint. However, for a more sophisticated versioning and the best metho\", \"d when using \\nREST, you should use hypermedia and implement HATEOAS (Hypertext as the Engine of Appl\", \"ication \\nState). \\nAdditional resources \\n\\u2022 \\nASP.NET API Versioning  https://github.com/dotnet/aspnet-\", \"api-versioning \\n\\u2022 \\nScott Hanselman. ASP.NET Core RESTful Web API versioning made easy \\nhttps://www.h\", \"anselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx \\n\\u2022 \\nVersioning a RESTful web API \\nh\", \"ttps://learn.microsoft.com/azure/architecture/best-practices/api-design#versioning-a-\\nrestful-web-ap\", \"i \\n\\u2022 \\nRoy Fielding. Versioning, Hypermedia, and REST \\nhttps://www.infoq.com/articles/roy-fielding-on\", \"-versioning \\nGenerating Swagger description metadata from your ASP.NET Core \\nWeb API \\nSwagger is a c\", \"ommonly used open source framework backed by a large ecosystem of tools that helps \\nyou design, buil\", \"d, document, and consume your RESTful APIs. It is becoming the standard for the APIs \\ndescription me\", \"tadata domain. You should include Swagger description metadata with any kind of \\nmicroservice, eithe\", \"r data-driven microservices or more advanced domain-driven microservices (as \\nexplained in the follo\", \"wing section). \\nThe heart of Swagger is the Swagger specification, which is API description metadata\", \" in a JSON or \\nYAML file. The specification creates the RESTful contract for your API, detailing all\", \" its resources and \\noperations in both a human- and machine-readable format for easy development, di\", \"scovery, and \\nintegration. \\nThe specification is the basis of the OpenAPI Specification (OAS) and is\", \" developed in an open, \\ntransparent, and collaborative community to standardize the way RESTful inte\", \"rfaces are defined. \\n \\n112 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Ba\", \"sed .NET Applications \\n \\nThe specification defines the structure for how a service can be discovered\", \" and how its capabilities \\nunderstood. For more information, including a web editor and examples of \", \"Swagger specifications \\nfrom companies like Spotify, Uber, Slack, and Microsoft, see the Swagger sit\", \"e (https://swagger.io). \\nWhy use Swagger? \\nThe main reasons to generate Swagger metadata for your AP\", \"Is are the following. \\nAbility for other products to automatically consume and integrate your APIs. \", \"Dozens of products \\nand commercial tools and many libraries and frameworks support Swagger. Microsof\", \"t has high-level \\nproducts and tools that can automatically consume Swagger-based APIs, such as the \", \"following: \\n\\u2022 \\nAutoRest. You can automatically generate .NET client classes for calling Swagger. Thi\", \"s tool can \\nbe used from the CLI and it also integrates with Visual Studio for easy use through the \", \"GUI. \\n\\u2022 \\nMicrosoft Flow. You can automatically use and integrate your API into a high-level Microsof\", \"t \\nFlow workflow, with no programming skills required. \\n\\u2022 \\nMicrosoft PowerApps. You can automaticall\", \"y consume your API from PowerApps mobile apps \\nbuilt with PowerApps Studio, with no programming skil\", \"ls required. \\n\\u2022 \\nAzure App Service Logic Apps. You can automatically use and integrate your API into\", \" an Azure \\nApp Service Logic App, with no programming skills required. \\nAbility to automatically gen\", \"erate API documentation. When you create large-scale RESTful APIs, \\nsuch as complex microservice-bas\", \"ed applications, you need to handle many endpoints with different \\ndata models used in the request a\", \"nd response payloads. Having proper documentation and having a \\nsolid API explorer, as you get with \", \"Swagger, is key for the success of your API and adoption by \\ndevelopers. \\nSwagger\\u2019s metadata is what\", \" Microsoft Flow, PowerApps, and Azure Logic Apps use to understand how \\nto use APIs and connect to t\", \"hem. \\nThere are several options to automate Swagger metadata generation for ASP.NET Core REST API \\na\", \"pplications, in the form of functional API help pages, based on swagger-ui. \\nProbably the best know \", \"is Swashbuckle, which is currently used in eShopOnContainers and we\\u2019ll cover \\nin some detail in this\", \" guide but there\\u2019s also the option to use NSwag, which can generate Typescript \\nand C# API clients, \", \"as well as C# controllers, from a Swagger or OpenAPI specification and even by \\nscanning the .dll th\", \"at contains the controllers, using NSwagStudio. \\nHow to automate API Swagger metadata generation wit\", \"h the Swashbuckle NuGet \\npackage \\nGenerating Swagger metadata manually (in a JSON or YAML file) can \", \"be tedious work. However, you \\ncan automate API discovery of ASP.NET Web API services by using the S\", \"washbuckle NuGet package to \\ndynamically generate Swagger API metadata. \\nSwashbuckle automatically g\", \"enerates Swagger metadata for your ASP.NET Web API projects. It \\nsupports ASP.NET Core Web API proje\", \"cts and the traditional ASP.NET Web API and any other flavor, \\n \\n113 \\nCHAPTER 5 | Designing and Deve\", \"loping Multi-Container and Microservice-Based .NET Applications \\n \\nsuch as Azure API App, Azure Mobi\", \"le App, Azure Service Fabric microservices based on ASP.NET. It \\nalso supports plain Web API deploye\", \"d on containers, as in for the reference application. \\nSwashbuckle combines API Explorer and Swagger\", \" or swagger-ui to provide a rich discovery and \\ndocumentation experience for your API consumers. In \", \"addition to its Swagger metadata generator \\nengine, Swashbuckle also contains an embedded version of\", \" swagger-ui, which it will automatically \\nserve up once Swashbuckle is installed. \\nThis means you ca\", \"n complement your API with a nice discovery UI to help developers to use your API. \\nIt requires a sm\", \"all amount of code and maintenance because it is automatically generated, allowing \\nyou to focus on \", \"building your API. The result for the API Explorer looks like Figure 6-8. \\n \\nFigure 6-8. Swashbuckle\", \" API Explorer based on Swagger metadata\\u2014eShopOnContainers catalog microservice \\nThe Swashbuckle gene\", \"rated Swagger UI API documentation includes all published actions. The API \\nexplorer is not the most\", \" important thing here. Once you have a Web API that can describe itself in \\nSwagger metadata, your A\", \"PI can be used seamlessly from Swagger-based tools, including client \\nproxy-class code generators th\", \"at can target many platforms. For example, as mentioned, AutoRest \\nautomatically generates .NET clie\", \"nt classes. But additional tools like swagger-codegen are also \\navailable, which allow code generati\", \"on of API client libraries, server stubs, and documentation \\nautomatically. \\nCurrently, Swashbuckle \", \"consists of five internal NuGet packages under the high-level metapackage \\nSwashbuckle.AspNetCore fo\", \"r ASP.NET Core applications. \\nAfter you have installed these NuGet packages in your Web API project,\", \" you need to configure \\nSwagger in the Program.cs class, as in the following simplified code: \\n \\n// \", \"Add framework services. \\n \\nbuilder.Services.AddSwaggerGen(options => \\n{ \\n \\n114 \\nCHAPTER 5 | Designin\", \"g and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n    options.DescribeAll\", \"EnumsAsStrings(); \\n    options.SwaggerDoc(\\\"v1\\\", new OpenApiInfo \\n    { \\n        Title = \\\"eShopOnCont\", \"ainers - Catalog HTTP API\\\", \\n        Version = \\\"v1\\\", \\n        Description = \\\"The Catalog Microservic\", \"e HTTP API. This is a Data-Driven/CRUD \\nmicroservice sample\\\" \\n    }); \\n}); \\n \\n// Other startup code.\", \".. \\n \\napp.UseSwagger() \\n    .UseSwaggerUI(c => \\n    { \\n        c.SwaggerEndpoint(\\\"/swagger/v1/swagge\", \"r.json\\\", \\\"My API V1\\\"); \\n    }); \\n    ``` \\n    ::: \\n \\nOnce this is done, you can start your applicati\", \"on and browse the following Swagger JSON and \\nUI endpoints using URLs like these: \\n \\n:::{custom-styl\", \"e=CodeBox} \\n```console \\n  http://<your-root-url>/swagger/v1/swagger.json \\n \\n  http://<your-root-url>\", \"/swagger/ \\nYou previously saw the generated UI created by Swashbuckle for a URL like http://<your-ro\", \"ot-\\nurl>/swagger. In Figure 6-9, you can also see how you can test any API method. \\n \\n115 \\nCHAPTER 5\", \" | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-9\", \". Swashbuckle UI testing the Catalog/Items API method \\nThe Swagger UI API detail shows a sample of t\", \"he response and can be used to execute the real API, \\nwhich is great for developer discovery. Figure\", \" 6-10 shows the Swagger JSON metadata generated \\nfrom the eShopOnContainers microservice (which is w\", \"hat the tools use underneath) when you request \\nhttp://<your-root-url>/swagger/v1/swagger.json using\", \" Postman. \\n \\n116 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET A\", \"pplications \\n \\n \\nFigure 6-10. Swagger JSON metadata \\nIt is that simple. And because it is automatica\", \"lly generated, the Swagger metadata will grow when you \\nadd more functionality to your API. \\nAdditio\", \"nal resources \\n\\u2022 \\nASP.NET Web API Help Pages using Swagger \\nhttps://learn.microsoft.com/aspnet/core/\", \"tutorials/web-api-help-pages-using-swagger \\n\\u2022 \\nGet started with Swashbuckle and ASP.NET Core \\nhttps:\", \"//learn.microsoft.com/aspnet/core/tutorials/getting-started-with-swashbuckle \\n\\u2022 \\nGet started with NS\", \"wag and ASP.NET Core \\nhttps://learn.microsoft.com/aspnet/core/tutorials/getting-started-with-nswag \\n\", \"Defining your multi-container application with \\ndocker-compose.yml \\nIn this guide, the docker-compos\", \"e.yml file was introduced in the section Step 4. Define your services \\nin docker-compose.yml when bu\", \"ilding a multi-container Docker application. However, there are \\nadditional ways to use the docker-c\", \"ompose files that are worth exploring in further detail. \\nFor example, you can explicitly describe h\", \"ow you want to deploy your multi-container application in \\nthe docker-compose.yml file. Optionally, \", \"you can also describe how you are going to build your \\ncustom Docker images. (Custom Docker images c\", \"an also be built with the Docker CLI.) \\n \\n117 \\nCHAPTER 5 | Designing and Developing Multi-Container \", \"and Microservice-Based .NET Applications \\n \\nBasically, you define each of the containers you want to\", \" deploy plus certain characteristics for each \\ncontainer deployment. Once you have a multi-container\", \" deployment description file, you can deploy \\nthe whole solution in a single action orchestrated by \", \"the docker-compose up CLI command, or you \\ncan deploy it transparently from Visual Studio. Otherwise\", \", you would need to use the Docker CLI to \\ndeploy container-by-container in multiple steps by using \", \"the docker run command from the \\ncommand line. Therefore, each service defined in docker-compose.yml\", \" must specify exactly one \\nimage or build. Other keys are optional, and are analogous to their docke\", \"r run command-line \\ncounterparts. \\nThe following YAML code is the definition of a possible global bu\", \"t single docker-compose.yml file for \\nthe eShopOnContainers sample. This code is not the actual dock\", \"er-compose file from \\neShopOnContainers. Instead, it is a simplified and consolidated version in a s\", \"ingle file, which is not the \\nbest way to work with docker-compose files, as will be explained later\", \". \\nversion: '3.4' \\n \\nservices: \\n  webmvc: \\n    image: eshop/webmvc \\n    environment: \\n      - Catalo\", \"gUrl=http://catalog-api \\n      - OrderingUrl=http://ordering-api \\n      - BasketUrl=http://basket-ap\", \"i \\n    ports: \\n      - \\\"5100:80\\\" \\n    depends_on: \\n      - catalog-api \\n      - ordering-api \\n      \", \"- basket-api \\n \\n  catalog-api: \\n    image: eshop/catalog-api \\n    environment: \\n      - ConnectionSt\", \"ring=Server=sqldata;Initial Catalog=CatalogData;User \\nId=sa;Password=[PLACEHOLDER] \\n    expose: \\n   \", \"   - \\\"80\\\" \\n    ports: \\n      - \\\"5101:80\\\" \\n    #extra hosts can be used for standalone SQL Server or \", \"services at the dev PC \\n    extra_hosts: \\n      - \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on: \\n    \", \"  - sqldata \\n \\n  ordering-api: \\n    image: eshop/ordering-api \\n    environment: \\n      - ConnectionS\", \"tring=Server=sqldata;Database=Services.OrderingDb;User \\nId=sa;Password=[PLACEHOLDER] \\n    ports: \\n  \", \"    - \\\"5102:80\\\" \\n    #extra hosts can be used for standalone SQL Server or services at the dev PC \\n \", \"   extra_hosts: \\n      - \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on: \\n      - sqldata \\n \\n118 \\nCHAPT\", \"ER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\n  bask\", \"et-api: \\n    image: eshop/basket-api \\n    environment: \\n      - ConnectionString=sqldata \\n    ports:\", \" \\n      - \\\"5103:80\\\" \\n    depends_on: \\n      - sqldata \\n \\n  sqldata: \\n    environment: \\n      - SA_PA\", \"SSWORD=[PLACEHOLDER] \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5434:1433\\\" \\n \\n  basketdata: \\n    i\", \"mage: redis \\nThe root key in this file is services. Under that key, you define the services you want\", \" to deploy and run \\nwhen you execute the docker-compose up command or when you deploy from Visual St\", \"udio by using \\nthis docker-compose.yml file. In this case, the docker-compose.yml file has multiple \", \"services defined, \\nas described in the following table. \\nService name \\nDescription \\nwebmvc \\nContaine\", \"r including the ASP.NET Core MVC \\napplication consuming the microservices from \\nserver-side C# \\ncata\", \"log-api \\nContainer including the Catalog ASP.NET Core \\nWeb API microservice \\nordering-api \\nContainer\", \" including the Ordering ASP.NET \\nCore Web API microservice \\nsqldata \\nContainer running SQL Server fo\", \"r Linux, \\nholding the microservices databases \\nbasket-api \\nContainer with the Basket ASP.NET Core We\", \"b \\nAPI microservice \\nbasketdata \\nContainer running the REDIS cache service, \\nwith the basket databas\", \"e as a REDIS cache \\nA simple Web Service API container \\nFocusing on a single container, the catalog-\", \"api container-microservice has a straightforward \\ndefinition: \\n  catalog-api: \\n    image: eshop/cata\", \"log-api \\n    environment: \\n      - ConnectionString=Server=sqldata;Initial Catalog=CatalogData;User \", \"\\nId=sa;Password=[PLACEHOLDER] \\n    expose: \\n \\n119 \\nCHAPTER 5 | Designing and Developing Multi-Contai\", \"ner and Microservice-Based .NET Applications \\n \\n      - \\\"80\\\" \\n    ports: \\n      - \\\"5101:80\\\" \\n    #ex\", \"tra hosts can be used for standalone SQL Server or services at the dev PC \\n    extra_hosts: \\n      -\", \" \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on: \\n      - sqldata \\nThis containerized service has the f\", \"ollowing basic configuration: \\n\\u2022 \\nIt is based on the custom eshop/catalog-api image. For simplicity\\u2019\", \"s sake, there is no \\nbuild: key setting in the file. This means that the image must have been previo\", \"usly built (with \\ndocker build) or have been downloaded (with the docker pull command) from any Dock\", \"er \\nregistry. \\n\\u2022 \\nIt defines an environment variable named ConnectionString with the connection stri\", \"ng to be \\nused by Entity Framework to access the SQL Server instance that contains the catalog data \", \"\\nmodel. In this case, the same SQL Server container is holding multiple databases. Therefore, \\nyou n\", \"eed less memory in your development machine for Docker. However, you could also \\ndeploy one SQL Serv\", \"er container for each microservice database. \\n\\u2022 \\nThe SQL Server name is sqldata, which is the same n\", \"ame used for the container that is \\nrunning the SQL Server instance for Linux. This is convenient; b\", \"eing able to use this name \\nresolution (internal to the Docker host) will resolve the network addres\", \"s so you don\\u2019t need to \\nknow the internal IP for the containers you are accessing from other contain\", \"ers. \\nBecause the connection string is defined by an environment variable, you could set that variab\", \"le \\nthrough a different mechanism and at a different time. For example, you could set a different \\nc\", \"onnection string when deploying to production in the final hosts, or by doing it from your CI/CD \\npi\", \"pelines in Azure DevOps Services or your preferred DevOps system. \\n\\u2022 \\nIt exposes port 80 for interna\", \"l access to the catalog-api service within the Docker host. The \\nhost is currently a Linux VM becaus\", \"e it is based on a Docker image for Linux, but you could \\nconfigure the container to run on a Window\", \"s image instead. \\n\\u2022 \\nIt forwards the exposed port 80 on the container to port 5101 on the Docker hos\", \"t machine \\n(the Linux VM). \\n\\u2022 \\nIt links the web service to the sqldata service (the SQL Server insta\", \"nce for Linux database \\nrunning in a container). When you specify this dependency, the catalog-api c\", \"ontainer will not \\nstart until the sqldata container has already started; this aspect is important b\", \"ecause catalog-\\napi needs to have the SQL Server database up and running first. However, this kind o\", \"f \\ncontainer dependency is not enough in many cases, because Docker checks only at the \\ncontainer le\", \"vel. Sometimes the service (in this case SQL Server) might still not be ready, so it is \\nadvisable t\", \"o implement retry logic with exponential backoff in your client microservices. That \\nway, if a depen\", \"dency container is not ready for a short time, the application will still be \\nresilient. \\n\\u2022 \\nIt is c\", \"onfigured to allow access to external servers: the extra_hosts setting allows you to access \\nexterna\", \"l servers or machines outside of the Docker host (that is, outside the default Linux VM, \\n \\n120 \\nCHA\", \"PTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nwhich \", \"is a development Docker host), such as a local SQL Server instance on your \\ndevelopment PC. \\nThere a\", \"re also other, more advanced docker-compose.yml settings that we\\u2019ll discuss in the following \\nsectio\", \"ns. \\nUsing docker-compose files to target multiple environments \\nThe docker-compose.*.yml files are \", \"definition files and can be used by multiple infrastructures that \\nunderstand that format. The most \", \"straightforward tool is the docker-compose command. \\nTherefore, by using the docker-compose command \", \"you can target the following main scenarios. \\nDevelopment environments \\nWhen you develop application\", \"s, it is important to be able to run an application in an isolated \\ndevelopment environment. You can\", \" use the docker-compose CLI command to create that \\nenvironment or Visual Studio, which uses docker-\", \"compose under the covers. \\nThe docker-compose.yml file allows you to configure and document all your\", \" application\\u2019s service \\ndependencies (other services, cache, databases, queues, etc.). Using the doc\", \"ker-compose CLI \\ncommand, you can create and start one or more containers for each dependency with a\", \" single \\ncommand (docker-compose up). \\nThe docker-compose.yml files are configuration files interpre\", \"ted by Docker engine but also serve as \\nconvenient documentation files about the composition of your\", \" multi-container application. \\nTesting environments \\nAn important part of any continuous deployment \", \"(CD) or continuous integration (CI) process are the \\nunit tests and integration tests. These automat\", \"ed tests require an isolated environment so they are \\nnot impacted by the users or any other change \", \"in the application\\u2019s data. \\nWith Docker Compose, you can create and destroy that isolated environmen\", \"t very easily in a few \\ncommands from your command prompt or scripts, like the following commands: \\n\", \"docker-compose -f docker-compose.yml -f docker-compose-test.override.yml up -d \\n./run_unit_tests \\ndo\", \"cker-compose -f docker-compose.yml -f docker-compose-test.override.yml down \\nProduction deployments \", \"\\nYou can also use Compose to deploy to a remote Docker Engine. A typical case is to deploy to a \\nsin\", \"gle Docker host instance (like a production VM or server provisioned with Docker Machine). \\nIf you a\", \"re using any other orchestrator (Azure Service Fabric, Kubernetes, etc.), you might need to add \\nset\", \"up and metadata configuration settings like those in docker-compose.yml, but in the format \\nrequired\", \" by the other orchestrator. \\nIn any case, docker-compose is a convenient tool and metadata format fo\", \"r development, testing and \\nproduction workflows, although the production workflow might vary on the\", \" orchestrator you are \\nusing. \\n \\n121 \\nCHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications \\n \\nUsing multiple docker-compose files to handle several environment\", \"s \\nWhen targeting different environments, you should use multiple compose files. This approach lets \", \"you \\ncreate multiple configuration variants depending on the environment. \\nOverriding the base docke\", \"r-compose file \\nYou could use a single docker-compose.yml file as in the simplified examples shown i\", \"n previous \\nsections. However, that is not recommended for most applications. \\nBy default, Compose r\", \"eads two files, a docker-compose.yml and an optional docker-\\ncompose.override.yml file. As shown in \", \"Figure 6-11, when you are using Visual Studio and enabling \\nDocker support, Visual Studio also creat\", \"es an additional docker-compose.vs.debug.g.yml file for \\ndebugging the application, you can take a l\", \"ook at this file in folder obj\\\\Docker\\\\ in the main solution \\nfolder. \\n \\nFigure 6-11. docker-compose \", \"files in Visual Studio 2019 \\ndocker-compose project file structure: \\n\\u2022 \\n.dockerignore - used to igno\", \"re files \\n\\u2022 \\ndocker-compose.yml - used to compose microservices \\n\\u2022 \\ndocker-compose.override.yml - us\", \"ed to configure microservices environment \\nYou can edit the docker-compose files with any editor, li\", \"ke Visual Studio Code or Sublime, and run the \\napplication with the docker-compose up command. \\nBy c\", \"onvention, the docker-compose.yml file contains your base configuration and other static \\nsettings. \", \"That means that the service configuration should not change depending on the deployment \\nenvironment\", \" you are targeting. \\nThe docker-compose.override.yml file, as its name suggests, contains configurat\", \"ion settings that \\noverride the base configuration, such as configuration that depends on the deploy\", \"ment environment. \\nYou can have multiple override files with different names also. The override file\", \"s usually contain \\nadditional information needed by the application but specific to an environment o\", \"r to a deployment. \\nTargeting multiple environments \\nA typical use case is when you define multiple \", \"compose files so you can target multiple environments, \\nlike production, staging, CI, or development\", \". To support these differences, you can split your \\nCompose configuration into multiple files, as sh\", \"own in Figure 6-12. \\n \\n122 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Ba\", \"sed .NET Applications \\n \\n \\nFigure 6-12. Multiple docker-compose files overriding values in the base \", \"docker-compose.yml file \\nYou can combine multiple docker-compose*.yml files to handle different envi\", \"ronments. You start with \\nthe base docker-compose.yml file. This base file contains the base or stat\", \"ic configuration settings that \\ndo not change depending on the environment. For example, the eShopOn\", \"Containers app has the \\nfollowing docker-compose.yml file (simplified with fewer services) as the ba\", \"se file. \\n#docker-compose.yml (Base) \\nversion: '3.4' \\nservices: \\n  basket-api: \\n    image: eshop/bas\", \"ket-api:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfile: src/Services/Basket/Basket.A\", \"PI/Dockerfile \\n    depends_on: \\n      - basketdata \\n      - identity-api \\n      - rabbitmq \\n \\n  cata\", \"log-api: \\n    image: eshop/catalog-api:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfil\", \"e: src/Services/Catalog/Catalog.API/Dockerfile \\n    depends_on: \\n      - sqldata \\n      - rabbitmq \\n\", \" \\n  marketing-api: \\n    image: eshop/marketing-api:${TAG:-latest} \\n    build: \\n      context: . \\n   \", \"   dockerfile: src/Services/Marketing/Marketing.API/Dockerfile \\n    depends_on: \\n      - sqldata \\n  \", \"    - nosqldata \\n      - identity-api \\n      - rabbitmq \\n \\n  webmvc: \\n    image: eshop/webmvc:${TAG:\", \"-latest} \\n \\n123 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications \\n \\n    build: \\n      context: . \\n      dockerfile: src/Web/WebMVC/Dockerfile \\n    depends\", \"_on: \\n      - catalog-api \\n      - ordering-api \\n      - identity-api \\n      - basket-api \\n      - m\", \"arketing-api \\n \\n  sqldata: \\n    image: mcr.microsoft.com/mssql/server:2019-latest \\n \\n  nosqldata: \\n \", \"   image: mongo \\n \\n  basketdata: \\n    image: redis \\n \\n  rabbitmq: \\n    image: rabbitmq:3-management \", \"\\nThe values in the base docker-compose.yml file should not change because of different target \\ndeplo\", \"yment environments. \\nIf you focus on the webmvc service definition, for instance, you can see how th\", \"at information is much \\nthe same no matter what environment you might be targeting. You have the fol\", \"lowing information: \\n\\u2022 \\nThe service name: webmvc. \\n\\u2022 \\nThe container\\u2019s custom image: eshop/webmvc. \\n\\u2022\", \" \\nThe command to build the custom Docker image, indicating which Dockerfile to use. \\n\\u2022 \\nDependencies\", \" on other services, so this container does not start until the other dependency \\ncontainers have sta\", \"rted. \\nYou can have additional configuration, but the important point is that in the base docker-\\nco\", \"mpose.yml file, you just want to set the information that is common across environments. Then in \\nth\", \"e docker-compose.override.yml or similar files for production or staging, you should place \\nconfigur\", \"ation that is specific for each environment. \\nUsually, the docker-compose.override.yml is used for y\", \"our development environment, as in the \\nfollowing example from eShopOnContainers: \\n#docker-compose.o\", \"verride.yml (Extended config for DEVELOPMENT env.) \\nversion: '3.4' \\n \\nservices: \\n# Simplified number\", \" of services here: \\n \\n  basket-api: \\n    environment: \\n      - ASPNETCORE_ENVIRONMENT=Development \\n \", \"     - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - ConnectionString=${ESHOP_AZURE_REDIS_BASKET_DB:-ba\", \"sketdata} \\n      - identityUrl=http://identity-api \\n      - IdentityUrlExternal=http://${ESHOP_EXTER\", \"NAL_DNS_NAME_OR_IP}:5105 \\n \\n124 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservi\", \"ce-Based .NET Applications \\n \\n      - EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq} \\n     \", \" - EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} \\n      - EventBusPassword=${ESHOP_SERVICE_BUS_PASS\", \"WORD} \\n      - AzureServiceBusEnabled=False \\n      - ApplicationInsights__InstrumentationKey=${INSTR\", \"UMENTATION_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n      - UseLoadTest=${USE_LOADTEST:-\", \"False} \\n \\n    ports: \\n      - \\\"5103:80\\\" \\n \\n  catalog-api: \\n    environment: \\n      - ASPNETCORE_ENVI\", \"RONMENT=Development \\n      - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - ConnectionString=${ESHOP_AZU\", \"RE_CATALOG_DB:-\\nServer=sqldata;Database=Microsoft.eShopOnContainers.Services.CatalogDb;User \\nId=sa;P\", \"assword=[PLACEHOLDER]} \\n      - PicBaseUrl=${ESHOP_AZURE_STORAGE_CATALOG_URL:-\\nhttp://host.docker.in\", \"ternal:5202/api/v1/catalog/items/[0]/pic/} \\n      - EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-ra\", \"bbitmq} \\n      - EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} \\n      - EventBusPassword=${ESHOP_SE\", \"RVICE_BUS_PASSWORD} \\n      - AzureStorageAccountName=${ESHOP_AZURE_STORAGE_CATALOG_NAME} \\n      - Az\", \"ureStorageAccountKey=${ESHOP_AZURE_STORAGE_CATALOG_KEY} \\n      - UseCustomizationData=True \\n      - \", \"AzureServiceBusEnabled=False \\n      - AzureStorageEnabled=False \\n      - ApplicationInsights__Instru\", \"mentationKey=${INSTRUMENTATION_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n    ports: \\n    \", \"  - \\\"5101:80\\\" \\n \\n  marketing-api: \\n    environment: \\n      - ASPNETCORE_ENVIRONMENT=Development \\n   \", \"   - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - ConnectionString=${ESHOP_AZURE_MARKETING_DB:-\\nServer\", \"=sqldata;Database=Microsoft.eShopOnContainers.Services.MarketingDb;User \\nId=sa;Password=[PLACEHOLDER\", \"]} \\n      - MongoConnectionString=${ESHOP_AZURE_COSMOSDB:-mongodb://nosqldata} \\n      - MongoDatabas\", \"e=MarketingDb \\n      - EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq} \\n      - EventBusUser\", \"Name=${ESHOP_SERVICE_BUS_USERNAME} \\n      - EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD} \\n      - \", \"identityUrl=http://identity-api \\n      - IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}\", \":5105 \\n      - CampaignDetailFunctionUri=${ESHOP_AZUREFUNC_CAMPAIGN_DETAILS_URI} \\n      - PicBaseUrl\", \"=${ESHOP_AZURE_STORAGE_MARKETING_URL:-\\nhttp://host.docker.internal:5110/api/v1/campaigns/[0]/pic/} \\n\", \"      - AzureStorageAccountName=${ESHOP_AZURE_STORAGE_MARKETING_NAME} \\n      - AzureStorageAccountKe\", \"y=${ESHOP_AZURE_STORAGE_MARKETING_KEY} \\n      - AzureServiceBusEnabled=False \\n      - AzureStorageEn\", \"abled=False \\n      - ApplicationInsights__InstrumentationKey=${INSTRUMENTATION_KEY} \\n      - Orchest\", \"ratorType=${ORCHESTRATOR_TYPE} \\n      - UseLoadTest=${USE_LOADTEST:-False} \\n    ports: \\n      - \\\"511\", \"0:80\\\" \\n \\n  webmvc: \\n \\n125 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications \\n \\n    environment: \\n      - ASPNETCORE_ENVIRONMENT=Development \\n      - ASPNET\", \"CORE_URLS=http://0.0.0.0:80 \\n      - PurchaseUrl=http://webshoppingapigw \\n      - IdentityUrl=http:/\", \"/10.0.75.1:5105 \\n      - MarketingUrl=http://webmarketingapigw \\n      - CatalogUrlHC=http://catalog-\", \"api/hc \\n      - OrderingUrlHC=http://ordering-api/hc \\n      - IdentityUrlHC=http://identity-api/hc \\n\", \"      - BasketUrlHC=http://basket-api/hc \\n      - MarketingUrlHC=http://marketing-api/hc \\n      - Pa\", \"ymentUrlHC=http://payment-api/hc \\n      - SignalrHubUrl=http://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5202\", \" \\n      - UseCustomizationData=True \\n      - ApplicationInsights__InstrumentationKey=${INSTRUMENTATI\", \"ON_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n      - UseLoadTest=${USE_LOADTEST:-False} \\n\", \"    ports: \\n      - \\\"5100:80\\\" \\n  sqldata: \\n    environment: \\n      - SA_PASSWORD=[PLACEHOLDER] \\n    \", \"  - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5433:1433\\\" \\n  nosqldata: \\n    ports: \\n      - \\\"27017:27017\\\" \", \"\\n  basketdata: \\n    ports: \\n      - \\\"6379:6379\\\" \\n  rabbitmq: \\n    ports: \\n      - \\\"15672:15672\\\" \\n   \", \"   - \\\"5672:5672\\\" \\nIn this example, the development override configuration exposes some ports to the \", \"host, defines \\nenvironment variables with redirect URLs, and specifies connection strings for the de\", \"velopment \\nenvironment. These settings are all just for the development environment. \\nWhen you run d\", \"ocker-compose up (or launch it from Visual Studio), the command reads the overrides \\nautomatically a\", \"s if it were merging both files. \\nSuppose that you want another Compose file for the production envi\", \"ronment, with different \\nconfiguration values, ports, or connection strings. You can create another \", \"override file, like file named \\ndocker-compose.prod.yml with different settings and environment vari\", \"ables. That file might be stored \\nin a different Git repo or managed and secured by a different team\", \". \\nHow to deploy with a specific override file \\nTo use multiple override files, or an override file \", \"with a different name, you can use the -f option with \\nthe docker-compose command and specify the fi\", \"les. Compose merges files in the order they are \\nspecified on the command line. The following exampl\", \"e shows how to deploy with override files. \\ndocker-compose -f docker-compose.yml -f docker-compose.p\", \"rod.yml up -d \\n \\n126 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications \\n \\nUsing environment variables in docker-compose files \\nIt is convenient, especially\", \" in production environments, to be able to get configuration information \\nfrom environment variables\", \", as we have shown in previous examples. You can reference an \\nenvironment variable in your docker-c\", \"ompose files using the syntax ${MY_VAR}. The following line \\nfrom a docker-compose.prod.yml file sho\", \"ws how to reference the value of an environment variable. \\nIdentityUrl=http://${ESHOP_PROD_EXTERNAL_\", \"DNS_NAME_OR_IP}:5105 \\nEnvironment variables are created and initialized in different ways, depending\", \" on your host \\nenvironment (Linux, Windows, Cloud cluster, etc.). However, a convenient approach is \", \"to use an .env \\nfile. The docker-compose files support declaring default environment variables in th\", \"e .env file. These \\nvalues for the environment variables are the default values. But they can be ove\", \"rridden by the values \\nyou might have defined in each of your environments (host OS or environment v\", \"ariables from your \\ncluster). You place this .env file in the folder where the docker-compose comman\", \"d is executed from. \\nThe following example shows an .env file like the .env file for the eShopOnCont\", \"ainers application. \\n# .env file \\n \\nESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker.internal \\n \\nESHOP_PROD\", \"_EXTERNAL_DNS_NAME_OR_IP=10.121.122.92 \\nDocker-compose expects each line in an .env file to be in th\", \"e format <variable>=<value>. \\nThe values set in the run-time environment always override the values \", \"defined inside the .env file. In a \\nsimilar way, values passed via command-line arguments also overr\", \"ide the default values set in the .env \\nfile. \\nAdditional resources \\n\\u2022 \\nOverview of Docker Compose \\n\", \"https://docs.docker.com/compose/overview/ \\n\\u2022 \\nMultiple Compose files \\nhttps://docs.docker.com/compos\", \"e/multiple-compose-files/ \\nBuilding optimized ASP.NET Core Docker images \\nIf you are exploring Docke\", \"r and .NET on sources on the Internet, you will find Dockerfiles that \\ndemonstrate the simplicity of\", \" building a Docker image by copying your source into a container. These \\nexamples suggest that by us\", \"ing a simple configuration, you can have a Docker image with the \\nenvironment packaged with your app\", \"lication. The following example shows a simple Dockerfile in this \\nvein. \\nFROM mcr.microsoft.com/dot\", \"net/sdk:7.0 \\nWORKDIR /app \\nENV ASPNETCORE_URLS http://+:80 \\nEXPOSE 80 \\nCOPY . . \\nRUN dotnet restore \", \"\\nENTRYPOINT [\\\"dotnet\\\", \\\"run\\\"] \\n \\n127 \\nCHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications \\n \\nA Dockerfile like this will work. However, you can substantially \", \"optimize your images, especially your \\nproduction images. \\nIn the container and microservices model,\", \" you are constantly starting containers. The typical way of \\nusing containers does not restart a sle\", \"eping container, because the container is disposable. \\nOrchestrators (like Kubernetes and Azure Serv\", \"ice Fabric) create new instances of images. What this \\nmeans is that you would need to optimize by p\", \"recompiling the application when it is built so the \\ninstantiation process will be faster. When the \", \"container is started, it should be ready to run. Don\\u2019t \\nrestore and compile at run time using the do\", \"tnet restore and dotnet build CLI commands as you may \\nsee in blog posts about .NET and Docker. \\nThe\", \" .NET team has been doing important work to make .NET and ASP.NET Core a container-optimized \\nframew\", \"ork. Not only is .NET a lightweight framework with a small memory footprint; the team has \\nfocused o\", \"n optimized Docker images for three main scenarios and published them in the Docker Hub \\nregistry at\", \" dotnet/, beginning with version 2.1: \\n1. \\nDevelopment: The priority is the ability to quickly itera\", \"te and debug changes, and where size \\nis secondary. \\n2. \\nBuild: The priority is compiling the applic\", \"ation, and the image includes binaries and other \\ndependencies to optimize binaries. \\n3. \\nProduction\", \": The focus is fast deploying and starting of containers, so these images are \\nlimited to the binari\", \"es and content needed to run the application. \\nThe .NET team provides four basic variants in dotnet/\", \" (at Docker Hub): \\n1. \\nsdk: for development and build scenarios \\n2. \\naspnet: for ASP.NET production \", \"scenarios \\n3. \\nruntime: for .NET production scenarios \\n4. \\nruntime-deps: for production scenarios of\", \" self-contained applications \\nFor faster startup, runtime images also automatically set aspnetcore_u\", \"rls to port 80 and use Ngen to \\ncreate a native image cache of assemblies. \\nAdditional resources \\n\\u2022 \", \"\\nBuilding Optimized Docker Images with ASP.NET Core \\nhttps://learn.microsoft.com/archive/blogs/steve\", \"lasker/building-optimized-docker-images-\\nwith-asp-net-core \\n\\u2022 \\nBuilding Docker Images for .NET Appli\", \"cations \\nhttps://learn.microsoft.com/dotnet/core/docker/building-net-docker-images \\nUse a database s\", \"erver running as a container \\nYou can have your databases (SQL Server, PostgreSQL, MySQL, etc.) on r\", \"egular standalone servers, in \\non-premises clusters, or in PaaS services in the cloud like Azure SQL\", \" DB. However, for development \\nand test environments, having your databases running as containers is\", \" convenient, because you don\\u2019t \\n \\n128 \\nCHAPTER 5 | Designing and Developing Multi-Container and Micr\", \"oservice-Based .NET Applications \\n \\nhave any external dependency and simply running the docker-compo\", \"se up command starts the whole \\napplication. Having those databases as containers is also great for \", \"integration tests, because the \\ndatabase is started in the container and is always populated with th\", \"e same sample data, so tests can \\nbe more predictable. \\nSQL Server running as a container with a mic\", \"roservice-related \\ndatabase \\nIn eShopOnContainers, there\\u2019s a container named sqldata, as defined in \", \"the docker-compose.yml file, \\nthat runs a SQL Server for Linux instance with the SQL databases for a\", \"ll microservices that need one. \\nA key point in microservices is that each microservice owns its rel\", \"ated data, so it should have its own \\ndatabase. However, the databases can be anywhere. In this case\", \", they are all in the same container to \\nkeep Docker memory requirements as low as possible. Keep in\", \" mind that this is a good-enough \\nsolution for development and, perhaps, testing but not for product\", \"ion. \\nThe SQL Server container in the sample application is configured with the following YAML code \", \"in the \\ndocker-compose.yml file, which is executed when you run docker-compose up. Note that the YAM\", \"L \\ncode has consolidated configuration information from the generic docker-compose.yml file and the \", \"\\ndocker-compose.override.yml file. (Usually you would separate the environment settings from the \\nba\", \"se or static information related to the SQL Server image.) \\n  sqldata: \\n    image: mcr.microsoft.com\", \"/mssql/server:2017-latest \\n    environment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEPT_EULA=Y \\n \", \"   ports: \\n      - \\\"5434:1433\\\" \\nIn a similar way, instead of using docker-compose, the following doc\", \"ker run command can run that \\ncontainer: \\ndocker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=Pass@word' -\", \"p 5433:1433 -d \\nmcr.microsoft.com/mssql/server:2017-latest \\nHowever, if you are deploying a multi-co\", \"ntainer application like eShopOnContainers, it is more \\nconvenient to use the docker-compose up comm\", \"and so that it deploys all the required containers for \\nthe application. \\nWhen you start this SQL Se\", \"rver container for the first time, the container initializes SQL Server with the \\npassword that you \", \"provide. Once SQL Server is running as a container, you can update the database \\nby connecting throu\", \"gh any regular SQL connection, such as from SQL Server Management Studio, \\nVisual Studio, or C# code\", \". \\nThe eShopOnContainers application initializes each microservice database with sample data by \\nsee\", \"ding it with data on startup, as explained in the following section. \\nHaving SQL Server running as a\", \" container is not just useful for a demo where you might not have \\naccess to an instance of SQL Serv\", \"er. As noted, it is also great for development and testing \\n \\n129 \\nCHAPTER 5 | Designing and Develop\", \"ing Multi-Container and Microservice-Based .NET Applications \\n \\nenvironments so that you can easily \", \"run integration tests starting from a clean SQL Server image and \\nknown data by seeding new sample d\", \"ata. \\nAdditional resources \\n\\u2022 \\nRun the SQL Server Docker image on Linux, Mac, or Windows \\nhttps://le\", \"arn.microsoft.com/sql/linux/sql-server-linux-setup-docker \\n\\u2022 \\nConnect and query SQL Server on Linux \", \"with sqlcmd \\nhttps://learn.microsoft.com/sql/linux/sql-server-linux-connect-and-query-sqlcmd \\nSeedin\", \"g with test data on Web application startup \\nTo add data to the database when the application starts\", \" up, you can add code like the following to \\nthe Main method in the Program class of the Web API pro\", \"ject: \\npublic static int Main(string[] args) \\n{ \\n    var configuration = GetConfiguration(); \\n \\n    \", \"Log.Logger = CreateSerilogLogger(configuration); \\n \\n    try \\n    { \\n        Log.Information(\\\"Configu\", \"ring web host ({ApplicationContext})...\\\", AppName); \\n        var host = CreateHostBuilder(configurat\", \"ion, args); \\n \\n        Log.Information(\\\"Applying migrations ({ApplicationContext})...\\\", AppName); \\n \", \"       host.MigrateDbContext<CatalogContext>((context, services) => \\n        { \\n            var env \", \"= services.GetService<IWebHostEnvironment>(); \\n            var settings = services.GetService<IOptio\", \"ns<CatalogSettings>>(); \\n            var logger = services.GetService<ILogger<CatalogContextSeed>>()\", \"; \\n \\n            new CatalogContextSeed() \\n                .SeedAsync(context, env, settings, logger\", \") \\n                .Wait(); \\n        }) \\n        .MigrateDbContext<IntegrationEventLogContext>((_, _\", \"_) => { }); \\n \\n        Log.Information(\\\"Starting web host ({ApplicationContext})...\\\", AppName); \\n   \", \"     host.Run(); \\n \\n        return 0; \\n    } \\n    catch (Exception ex) \\n    { \\n        Log.Fatal(ex,\", \" \\\"Program terminated unexpectedly ({ApplicationContext})!\\\", AppName); \\n        return 1; \\n    } \\n   \", \" finally \\n    { \\n        Log.CloseAndFlush(); \\n    } \\n} \\n \\n130 \\nCHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applications \\n \\nThere\\u2019s an important caveat when applyi\", \"ng migrations and seeding a database during container \\nstartup. Since the database server might not \", \"be available for whatever reason, you must handle retries \\nwhile waiting for the server to be availa\", \"ble. This retry logic is handled by the MigrateDbContext() \\nextension method, as shown in the follow\", \"ing code: \\npublic static IWebHost MigrateDbContext<TContext>( \\n    this IWebHost host, \\n    Action<T\", \"Context, \\n    IServiceProvider> seeder) \\n      where TContext : DbContext \\n{ \\n    var underK8s = hos\", \"t.IsInKubernetes(); \\n \\n    using (var scope = host.Services.CreateScope()) \\n    { \\n        var servi\", \"ces = scope.ServiceProvider; \\n \\n        var logger = services.GetRequiredService<ILogger<TContext>>(\", \"); \\n \\n        var context = services.GetService<TContext>(); \\n \\n        try \\n        { \\n            \", \"logger.LogInformation(\\\"Migrating database associated with context \\n{DbContextName}\\\", typeof(TContext\", \").Name); \\n \\n            if (underK8s) \\n            { \\n                InvokeSeeder(seeder, context, \", \"services); \\n            } \\n            else \\n            { \\n                var retry = Policy.Handl\", \"e<SqlException>() \\n                    .WaitAndRetry(new TimeSpan[] \\n                    { \\n        \", \"            TimeSpan.FromSeconds(3), \\n                    TimeSpan.FromSeconds(5), \\n                \", \"    TimeSpan.FromSeconds(8), \\n                    }); \\n \\n                //if the sql server contain\", \"er is not created on run docker compose this \\n                //migration can't fail for network rel\", \"ated exception. The retry options for \\nDbContext only \\n                //apply to transient exceptio\", \"ns \\n                // Note that this is NOT applied when running some orchestrators (let the \\norche\", \"strator to recreate the failing service) \\n                retry.Execute(() => InvokeSeeder(seeder, c\", \"ontext, services)); \\n            } \\n \\n            logger.LogInformation(\\\"Migrated database associate\", \"d with context \\n{DbContextName}\\\", typeof(TContext).Name); \\n        } \\n        catch (Exception ex) \\n\", \"        { \\n            logger.LogError(ex, \\\"An error occurred while migrating the database used on \\n\", \"context {DbContextName}\\\", typeof(TContext).Name); \\n            if (underK8s) \\n            { \\n       \", \"         throw;          // Rethrow under k8s because we rely on k8s to re-run the \\n \\n131 \\nCHAPTER 5\", \" | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\npod \\n       \", \"     } \\n        } \\n    } \\n \\n    return host; \\n} \\nThe following code in the custom CatalogContextSeed\", \" class populates the data. \\npublic class CatalogContextSeed \\n{ \\n    public static async Task SeedAsy\", \"nc(IApplicationBuilder applicationBuilder) \\n    { \\n        var context = (CatalogContext)application\", \"Builder \\n            .ApplicationServices.GetService(typeof(CatalogContext)); \\n        using (contex\", \"t) \\n        { \\n            context.Database.Migrate(); \\n            if (!context.CatalogBrands.Any()\", \") \\n            { \\n                context.CatalogBrands.AddRange( \\n                    GetPreconfigu\", \"redCatalogBrands()); \\n                await context.SaveChangesAsync(); \\n            } \\n            \", \"if (!context.CatalogTypes.Any()) \\n            { \\n                context.CatalogTypes.AddRange( \\n   \", \"                 GetPreconfiguredCatalogTypes()); \\n                await context.SaveChangesAsync();\", \" \\n            } \\n        } \\n    } \\n \\n    static IEnumerable<CatalogBrand> GetPreconfiguredCatalogBra\", \"nds() \\n    { \\n        return new List<CatalogBrand>() \\n       { \\n           new CatalogBrand() { Bra\", \"nd = \\\"Azure\\\"}, \\n           new CatalogBrand() { Brand = \\\".NET\\\" }, \\n           new CatalogBrand() { B\", \"rand = \\\"Visual Studio\\\" }, \\n           new CatalogBrand() { Brand = \\\"SQL Server\\\" } \\n       }; \\n    } \", \"\\n \\n    static IEnumerable<CatalogType> GetPreconfiguredCatalogTypes() \\n    { \\n        return new Lis\", \"t<CatalogType>() \\n        { \\n            new CatalogType() { Type = \\\"Mug\\\"}, \\n            new Catalog\", \"Type() { Type = \\\"T-Shirt\\\" }, \\n            new CatalogType() { Type = \\\"Backpack\\\" }, \\n            new \", \"CatalogType() { Type = \\\"USB Memory Stick\\\" } \\n        }; \\n    } \\n} \\nWhen you run integration tests, h\", \"aving a way to generate data consistent with your integration tests is \\nuseful. Being able to create\", \" everything from scratch, including an instance of SQL Server running on a \\ncontainer, is great for \", \"test environments. \\n \\n132 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications \\n \\nEF Core InMemory database versus SQL Server running as a container \\nAnother \", \"good choice when running tests is to use the Entity Framework InMemory database provider. \\nYou can s\", \"pecify that configuration in the ConfigureServices method of the Startup class in your Web \\nAPI proj\", \"ect: \\npublic class Startup \\n{ \\n    // Other Startup code ... \\n    public void ConfigureServices(ISer\", \"viceCollection services) \\n    { \\n        services.AddSingleton<IConfiguration>(Configuration); \\n    \", \"    // DbContext using an InMemory database provider \\n        services.AddDbContext<CatalogContext>(\", \"opt => opt.UseInMemoryDatabase()); \\n        //(Alternative: DbContext using a SQL Server provider \\n \", \"       //services.AddDbContext<CatalogContext>(c => \\n        //{ \\n            // c.UseSqlServer(Conf\", \"iguration[\\\"ConnectionString\\\"]); \\n            // \\n        //}); \\n    } \\n \\n    // Other Startup code .\", \".. \\n} \\nThere is an important catch, though. The in-memory database does not support many constraints\", \" that \\nare specific to a particular database. For instance, you might add a unique index on a column\", \" in your \\nEF Core model and write a test against your in-memory database to check that it does not l\", \"et you add \\na duplicate value. But when you are using the in-memory database, you cannot handle uniq\", \"ue indexes \\non a column. Therefore, the in-memory database does not behave exactly the same as a rea\", \"l SQL \\nServer database\\u2014it does not emulate database-specific constraints. \\nEven so, an in-memory dat\", \"abase is still useful for testing and prototyping. But if you want to create \\naccurate integration t\", \"ests that take into account the behavior of a specific database implementation, \\nyou need to use a r\", \"eal database like SQL Server. For that purpose, running SQL Server in a container is \\na great choice\", \" and more accurate than the EF Core InMemory database provider. \\nUsing a Redis cache service running\", \" in a container \\nYou can run Redis on a container, especially for development and testing and for pr\", \"oof-of-concept \\nscenarios. This scenario is convenient, because you can have all your dependencies r\", \"unning on \\ncontainers\\u2014not just for your local development machines, but for your testing environment\", \"s in your \\nCI/CD pipelines. \\nHowever, when you run Redis in production, it is better to look for a h\", \"igh-availability solution like \\nRedis Microsoft Azure, which runs as a PaaS (Platform as a Service).\", \" In your code, you just need to \\nchange your connection strings. \\nRedis provides a Docker image with\", \" Redis. That image is available from Docker Hub at this URL: \\nhttps://hub.docker.com/_/redis/ \\n \\n133\", \" \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nY\", \"ou can directly run a Docker Redis container by executing the following Docker CLI command in your \\n\", \"command prompt: \\ndocker run --name some-redis -d redis \\nThe Redis image includes expose:6379 (the po\", \"rt used by Redis), so standard container linking will \\nmake it automatically available to the linked\", \" containers. \\nIn eShopOnContainers, the basket-api microservice uses a Redis cache running as a cont\", \"ainer. That \\nbasketdata container is defined as part of the multi-container docker-compose.yml file,\", \" as shown in the \\nfollowing example: \\n#docker-compose.yml file \\n#... \\n  basketdata: \\n    image: redi\", \"s \\n    expose: \\n      - \\\"6379\\\" \\nThis code in the docker-compose.yml defines a container named basket\", \"data based on the redis image \\nand publishing the port 6379 internally. This configuration means tha\", \"t it will only be accessible from \\nother containers running within the Docker host. \\nFinally, in the\", \" docker-compose.override.yml file, the basket-api microservice for the \\neShopOnContainers sample def\", \"ines the connection string to use for that Redis container: \\n  basket-api: \\n    environment: \\n      \", \"# Other data ... \\n      - ConnectionString=basketdata \\n      - EventBusConnection=rabbitmq \\nAs menti\", \"oned before, the name of the microservice basketdata is resolved by Docker\\u2019s internal \\nnetwork DNS. \", \"\\nImplementing event-based communication between \\nmicroservices (integration events) \\nAs described ea\", \"rlier, when you use event-based communication, a microservice publishes an event \\nwhen something not\", \"able happens, such as when it updates a business entity. Other microservices \\nsubscribe to those eve\", \"nts. When a microservice receives an event, it can update its own business \\nentities, which might le\", \"ad to more events being published. This is the essence of the eventual \\nconsistency concept. This pu\", \"blish/subscribe system is usually performed by using an implementation \\nof an event bus. The event b\", \"us can be designed as an interface with the API needed to subscribe and \\nunsubscribe to events and t\", \"o publish events. It can also have one or more implementations based on \\nany inter-process or messag\", \"ing communication, such as a messaging queue or a service bus that \\nsupports asynchronous communicat\", \"ion and a publish/subscribe model. \\nYou can use events to implement business transactions that span \", \"multiple services, which give you \\neventual consistency between those services. An eventually consis\", \"tent transaction consists of a series \\n \\n134 \\nCHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET Applications \\n \\nof distributed actions. At each action, the microservice \", \"updates a business entity and publishes an \\nevent that triggers the next action. Figure 6-18 below, \", \"shows a PriceUpdated event published through \\nan event bus, so the price update is propagated to the\", \" Basket and other microservices. \\n \\nFigure 6-18. Event-driven communication based on an event bus \\nT\", \"his section describes how you can implement this type of communication with .NET by using a \\ngeneric\", \" event bus interface, as shown in Figure 6-18. There are multiple potential implementations, \\neach u\", \"sing a different technology or infrastructure such as RabbitMQ, Azure Service Bus, or any other \\nthi\", \"rd-party open-source or commercial service bus. \\nUsing message brokers and service buses for product\", \"ion systems \\nAs noted in the architecture section, you can choose from multiple messaging technologi\", \"es for \\nimplementing your abstract event bus. But these technologies are at different levels. For in\", \"stance, \\nRabbitMQ, a messaging broker transport, is at a lower level than commercial products like A\", \"zure \\nService Bus, NServiceBus, MassTransit, or Brighter. Most of these products can work on top of \", \"either \\nRabbitMQ or Azure Service Bus. Your choice of product depends on how many features and how \\n\", \"much out-of-the-box scalability you need for your application. \\nFor implementing just an event bus p\", \"roof-of-concept for your development environment, as in the \\neShopOnContainers sample, a simple impl\", \"ementation on top of RabbitMQ running as a container \\nmight be enough. But for mission-critical and \", \"production systems that need high scalability, you \\nmight want to evaluate and use Azure Service Bus\", \". \\nIf you require high-level abstractions and richer features like Sagas for long-running processes \", \"that \\nmake distributed development easier, other commercial and open-source service buses like \\nNSer\", \"viceBus, MassTransit, and Brighter are worth evaluating. In this case, the abstractions and API to \\n\", \"use would usually be directly the ones provided by those high-level service buses instead of your ow\", \"n \\nabstractions (like the simple event bus abstractions provided at eShopOnContainers). For that mat\", \"ter, \\n \\n135 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applic\", \"ations \\n \\nyou can research the forked eShopOnContainers using NServiceBus (additional derived sample\", \" \\nimplemented by Particular Software). \\nOf course, you could always build your own service bus featu\", \"res on top of lower-level technologies \\nlike RabbitMQ and Docker, but the work needed to \\u201creinvent t\", \"he wheel\\u201d might be too costly for a \\ncustom enterprise application. \\nTo reiterate: the sample event \", \"bus abstractions and implementation showcased in the \\neShopOnContainers sample are intended to be us\", \"ed only as a proof of concept. Once you have \\ndecided that you want to have asynchronous and event-d\", \"riven communication, as explained in the \\ncurrent section, you should choose the service bus product\", \" that best fits your needs for production. \\nIntegration events \\nIntegration events are used for brin\", \"ging domain state in sync across multiple microservices or external \\nsystems. This functionality is \", \"done by publishing integration events outside the microservice. When an \\nevent is published to multi\", \"ple receiver microservices (to as many microservices as are subscribed to \\nthe integration event), t\", \"he appropriate event handler in each receiver microservice handles the event. \\nAn integration event \", \"is basically a data-holding class, as in the following example: \\npublic class ProductPriceChangedInt\", \"egrationEvent : IntegrationEvent \\n{ \\n    public int ProductId { get; private set; } \\n    public deci\", \"mal NewPrice { get; private set; } \\n    public decimal OldPrice { get; private set; } \\n \\n    public \", \"ProductPriceChangedIntegrationEvent(int productId, decimal newPrice, \\n        decimal oldPrice) \\n   \", \" { \\n        ProductId = productId; \\n        NewPrice = newPrice; \\n        OldPrice = oldPrice; \\n    \", \"} \\n} \\nThe integration events can be defined at the application level of each microservice, so they a\", \"re \\ndecoupled from other microservices, in a way comparable to how ViewModels are defined in the \\nse\", \"rver and client. What is not recommended is sharing a common integration events library across \\nmult\", \"iple microservices; doing that would be coupling those microservices with a single event \\ndefinition\", \" data library. You do not want to do that for the same reasons that you do not want to share \\na comm\", \"on domain model across multiple microservices: microservices must be completely \\nautonomous. For mor\", \"e information, see this blog post on the amount of data to put in events. Be \\ncareful not to take th\", \"is too far, as this other blog post describes the problem data deficient messages \\ncan produce. Your\", \" design of your events should aim to be \\u201cjust right\\u201d for the needs of their \\nconsumers. \\nThere are o\", \"nly a few kinds of libraries you should share across microservices. One is libraries that are \\nfinal\", \" application blocks, like the Event Bus client API, as in eShopOnContainers. Another is libraries \\nt\", \"hat constitute tools that could also be shared as NuGet components, like JSON serializers. \\n \\n136 \\nC\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nThe \", \"event bus \\nAn event bus allows publish/subscribe-style communication between microservices without r\", \"equiring \\nthe components to explicitly be aware of each other, as shown in Figure 6-19. \\n \\nFigure 6-\", \"19. Publish/subscribe basics with an event bus \\nThe above diagram shows that microservice A publishe\", \"s to Event Bus, which distributes to subscribing \\nmicroservices B and C, without the publisher needi\", \"ng to know the subscribers. The event bus is \\nrelated to the Observer pattern and the publish-subscr\", \"ibe pattern. \\nObserver pattern \\nIn the Observer pattern, your primary object (known as the Observabl\", \"e) notifies other interested \\nobjects (known as Observers) with relevant information (events). \\nPubl\", \"ish/Subscribe (Pub/Sub) pattern \\nThe purpose of the Publish/Subscribe pattern is the same as the Obs\", \"erver pattern: you want to notify \\nother services when certain events take place. But there is an im\", \"portant difference between the \\nObserver and Pub/Sub patterns. In the observer pattern, the broadcas\", \"t is performed directly from the \\nobservable to the observers, so they \\u201cknow\\u201d each other. But when u\", \"sing a Pub/Sub pattern, there is a \\nthird component, called broker, or message broker or event bus, \", \"which is known by both the \\npublisher and subscriber. Therefore, when using the Pub/Sub pattern the \", \"publisher and the \\nsubscribers are precisely decoupled thanks to the mentioned event bus or message \", \"broker. \\nThe middleman or event bus \\nHow do you achieve anonymity between publisher and subscriber? \", \"An easy way is let a middleman \\ntake care of all the communication. An event bus is one such middlem\", \"an. \\nAn event bus is typically composed of two parts: \\n\\u2022 \\nThe abstraction or interface. \\n\\u2022 \\nOne or m\", \"ore implementations. \\n \\n137 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-B\", \"ased .NET Applications \\n \\nIn Figure 6-19 you can see how, from an application point of view, the eve\", \"nt bus is nothing more than \\na Pub/Sub channel. The way you implement this asynchronous communicatio\", \"n can vary. It can have \\nmultiple implementations so that you can swap between them, depending on th\", \"e environment \\nrequirements (for example, production versus development environments). \\nIn Figure 6-\", \"20, you can see an abstraction of an event bus with multiple implementations based on \\ninfrastructur\", \"e messaging technologies like RabbitMQ, Azure Service Bus, or another event/message \\nbroker. \\n \\nFigu\", \"re 6- 20. Multiple implementations of an event bus \\nIt\\u2019s good to have the event bus defined through \", \"an interface so it can be implemented with several \\ntechnologies, like RabbitMQ, Azure Service bus o\", \"r others. However, and as mentioned previously, \\nusing your own abstractions (the event bus interfac\", \"e) is good only if you need basic event bus \\nfeatures supported by your abstractions. If you need ri\", \"cher service bus features, you should probably \\nuse the API and abstractions provided by your prefer\", \"red commercial service bus instead of your own \\nabstractions. \\nDefining an event bus interface \\nLet\\u2019\", \"s start with some implementation code for the event bus interface and possible implementations \\nfor \", \"exploration purposes. The interface should be generic and straightforward, as in the following \\ninte\", \"rface. \\npublic interface IEventBus \\n{ \\n    void Publish(IntegrationEvent @event); \\n \\n    void Subscr\", \"ibe<T, TH>() \\n        where T : IntegrationEvent \\n        where TH : IIntegrationEventHandler<T>; \\n \", \"\\n    void SubscribeDynamic<TH>(string eventName) \\n        where TH : IDynamicIntegrationEventHandler\", \"; \\n \\n \\n138 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applica\", \"tions \\n \\n    void UnsubscribeDynamic<TH>(string eventName) \\n        where TH : IDynamicIntegrationEv\", \"entHandler; \\n \\n    void Unsubscribe<T, TH>() \\n        where TH : IIntegrationEventHandler<T> \\n      \", \"  where T : IntegrationEvent; \\n} \\nThe Publish method is straightforward. The event bus will broadcas\", \"t the integration event passed to it \\nto any microservice, or even an external application, subscrib\", \"ed to that event. This method is used by \\nthe microservice that is publishing the event. \\nThe Subscr\", \"ibe methods (you can have several implementations depending on the arguments) are \\nused by the micro\", \"services that want to receive events. This method has two arguments. The first is the \\nintegration e\", \"vent to subscribe to (IntegrationEvent). The second argument is the integration event \\nhandler (or c\", \"allback method), named IIntegrationEventHandler<T>, to be executed when the receiver \\nmicroservice g\", \"ets that integration event message. \\nAdditional resources \\nSome production-ready messaging solutions\", \": \\n\\u2022 \\nAzure Service Bus \\nhttps://learn.microsoft.com/azure/service-bus-messaging/ \\n\\u2022 \\nNServiceBus \\nh\", \"ttps://particular.net/nservicebus \\n\\u2022 \\nMassTransit \\nhttps://masstransit-project.com/ \\nImplementing an\", \" event bus with RabbitMQ for the \\ndevelopment or test environment \\nWe should start by saying that if\", \" you create your custom event bus based on RabbitMQ running in a \\ncontainer, as the eShopOnContainer\", \"s application does, it should be used only for your development \\nand test environments. Don\\u2019t use it\", \" for your production environment, unless you are building it as a \\npart of a production-ready servic\", \"e bus as described in the Additional resources section below. A \\nsimple custom event bus might be mi\", \"ssing many production-ready critical features that a commercial \\nservice bus has. \\nOne of the event \", \"bus custom implementations in eShopOnContainers is basically a library using the \\nRabbitMQ API. (The\", \"re\\u2019s another implementation based on Azure Service Bus.) \\nThe event bus implementation with RabbitMQ\", \" lets microservices subscribe to events, publish events, \\nand receive events, as shown in Figure 6-2\", \"1. \\n \\n139 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicat\", \"ions \\n \\n \\nFigure 6-21. RabbitMQ implementation of an event bus \\nRabbitMQ functions as an intermediar\", \"y between message publisher and subscribers, to handle \\ndistribution. In the code, the EventBusRabbi\", \"tMQ class implements the generic IEventBus interface. \\nThis implementation is based on Dependency In\", \"jection so that you can swap from this dev/test \\nversion to a production version. \\npublic class Even\", \"tBusRabbitMQ : IEventBus, IDisposable \\n{ \\n    // Implementation using RabbitMQ API \\n    //... \\n} \\nTh\", \"e RabbitMQ implementation of a sample dev/test event bus is boilerplate code. It has to handle the \\n\", \"connection to the RabbitMQ server and provide code for publishing a message event to the queues. It \", \"\\nalso has to implement a dictionary of collections of integration event handlers for each event type\", \"; \\nthese event types can have a different instantiation and different subscriptions for each receive\", \"r \\nmicroservice, as shown in Figure 6-21. \\nImplementing a simple publish method with RabbitMQ \\nThe f\", \"ollowing code is a simplified version of an event bus implementation for RabbitMQ, to \\nshowcase the \", \"whole scenario. You don\\u2019t really handle the connection this way. To see the full \\nimplementation, se\", \"e the actual code in the dotnet-architecture/eShopOnContainers repository. \\npublic class EventBusRab\", \"bitMQ : IEventBus, IDisposable \\n{ \\n    // Member objects and other methods ... \\n    // ... \\n \\n    pu\", \"blic void Publish(IntegrationEvent @event) \\n    { \\n        var eventName = @event.GetType().Name; \\n \", \"       var factory = new ConnectionFactory() { HostName = _connectionString }; \\n        using (var c\", \"onnection = factory.CreateConnection()) \\n        using (var channel = connection.CreateModel()) \\n \\n1\", \"40 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \", \"\\n        { \\n            channel.ExchangeDeclare(exchange: _brokerName, \\n                type: \\\"direc\", \"t\\\"); \\n            string message = JsonConvert.SerializeObject(@event); \\n            var body = Enco\", \"ding.UTF8.GetBytes(message); \\n            channel.BasicPublish(exchange: _brokerName, \\n             \", \"   routingKey: eventName, \\n                basicProperties: null, \\n                body: body); \\n   \", \"    } \\n    } \\n} \\nThe actual code of the Publish method in the eShopOnContainers application is impro\", \"ved by using a \\nPolly retry policy, which retries the task some times in case the RabbitMQ container\", \" is not ready. This \\nscenario can occur when docker-compose is starting the containers; for example,\", \" the RabbitMQ \\ncontainer might start more slowly than the other containers. \\nAs mentioned earlier, t\", \"here are many possible configurations in RabbitMQ, so this code should be \\nused only for dev/test en\", \"vironments. \\nImplementing the subscription code with the RabbitMQ API \\nAs with the publish code, the\", \" following code is a simplification of part of the event bus \\nimplementation for RabbitMQ. Again, yo\", \"u usually do not need to change it unless you are improving \\nit. \\npublic class EventBusRabbitMQ : IE\", \"ventBus, IDisposable \\n{ \\n    // Member objects and other methods ... \\n    // ... \\n \\n    public void \", \"Subscribe<T, TH>() \\n        where T : IntegrationEvent \\n        where TH : IIntegrationEventHandler<\", \"T> \\n    { \\n        var eventName = _subsManager.GetEventKey<T>(); \\n \\n        var containsKey = _subs\", \"Manager.HasSubscriptionsForEvent(eventName); \\n        if (!containsKey) \\n        { \\n            if (\", \"!_persistentConnection.IsConnected) \\n            { \\n                _persistentConnection.TryConnect\", \"(); \\n            } \\n \\n            using (var channel = _persistentConnection.CreateModel()) \\n       \", \"     { \\n                channel.QueueBind(queue: _queueName, \\n                                    ex\", \"change: BROKER_NAME, \\n                                    routingKey: eventName); \\n            } \\n  \", \"      } \\n \\n        _subsManager.AddSubscription<T, TH>(); \\n    } \\n} \\n \\n141 \\nCHAPTER 5 | Designing an\", \"d Developing Multi-Container and Microservice-Based .NET Applications \\n \\nEach event type has a relat\", \"ed channel to get events from RabbitMQ. You can then have as many event \\nhandlers per channel and ev\", \"ent type as needed. \\nThe Subscribe method accepts an IIntegrationEventHandler object, which is like \", \"a callback method in \\nthe current microservice, plus its related IntegrationEvent object. The code t\", \"hen adds that event \\nhandler to the list of event handlers that each integration event type can have\", \" per client microservice. \\nIf the client code has not already been subscribed to the event, the code\", \" creates a channel for the \\nevent type so it can receive events in a push style from RabbitMQ when t\", \"hat event is published from \\nany other service. \\nAs mentioned above, the event bus implemented in eS\", \"hopOnContainers has only an educational \\npurpose, since it only handles the main scenarios, so it\\u2019s \", \"not ready for production. \\nFor production scenarios check the additional resources below, specific f\", \"or RabbitMQ, and the \\nImplementing event-based communication between microservices section. \\nAdditio\", \"nal resources \\nA production-ready solution with support for RabbitMQ. \\n\\u2022 \\nNServiceBus - Fully-suppor\", \"ted commercial service bus with advanced management and \\nmonitoring tooling for .NET \\nhttps://partic\", \"ular.net/ \\n\\u2022 \\nEasyNetQ - Open Source .NET API client for RabbitMQ \\nhttps://easynetq.com/ \\n\\u2022 \\nMassTra\", \"nsit - Free, open-source distributed application framework for .NET \\nhttps://masstransit-project.com\", \"/ \\n\\u2022 \\nRebus - Open source .NET Service Bus \\nhttps://github.com/rebus-org/Rebus \\nSubscribing to event\", \"s \\nThe first step for using the event bus is to subscribe the microservices to the events they want \", \"to \\nreceive. That functionality should be done in the receiver microservices. \\nThe following simple \", \"code shows what each receiver microservice needs to implement when starting \\nthe service (that is, i\", \"n the Startup class) so it subscribes to the events it needs. In this case, the basket-\\napi microser\", \"vice needs to subscribe to ProductPriceChangedIntegrationEvent and the \\nOrderStartedIntegrationEvent\", \" messages. \\nFor instance, when subscribing to the ProductPriceChangedIntegrationEvent event, that ma\", \"kes the \\nbasket microservice aware of any changes to the product price and lets it warn the user abo\", \"ut the \\nchange if that product is in the user\\u2019s basket. \\nvar eventBus = app.ApplicationServices.GetR\", \"equiredService<IEventBus>(); \\n \\neventBus.Subscribe<ProductPriceChangedIntegrationEvent, \\n \\n142 \\nCHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n       \", \"            ProductPriceChangedIntegrationEventHandler>(); \\n \\neventBus.Subscribe<OrderStartedIntegra\", \"tionEvent, \\n                   OrderStartedIntegrationEventHandler>(); \\nAfter this code runs, the su\", \"bscriber microservice will be listening through RabbitMQ channels. When \\nany message of type Product\", \"PriceChangedIntegrationEvent arrives, the code invokes the event \\nhandler that is passed to it and p\", \"rocesses the event. \\nPublishing events through the event bus \\nFinally, the message sender (origin mi\", \"croservice) publishes the integration events with code similar to \\nthe following example. (This appr\", \"oach is a simplified example that does not take atomicity into \\naccount.) You would implement simila\", \"r code whenever an event must be propagated across multiple \\nmicroservices, usually right after comm\", \"itting data or transactions from the origin microservice. \\nFirst, the event bus implementation objec\", \"t (based on RabbitMQ or based on a service bus) would be \\ninjected at the controller constructor, as\", \" in the following code: \\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class CatalogController : Controller\", \"Base \\n{ \\n    private readonly CatalogContext _context; \\n    private readonly IOptionsSnapshot<Settin\", \"gs> _settings; \\n    private readonly IEventBus _eventBus; \\n \\n    public CatalogController(CatalogCon\", \"text context, \\n        IOptionsSnapshot<Settings> settings, \\n        IEventBus eventBus) \\n    { \\n   \", \"     _context = context; \\n        _settings = settings; \\n        _eventBus = eventBus; \\n    } \\n    /\", \"/ ... \\n} \\nThen you use it from your controller\\u2019s methods, like in the UpdateProduct method: \\n[Route(\", \"\\\"items\\\")] \\n[HttpPost] \\npublic async Task<IActionResult> UpdateProduct([FromBody]CatalogItem product)\", \" \\n{ \\n    var item = await _context.CatalogItems.SingleOrDefaultAsync( \\n        i => i.Id == product.\", \"Id); \\n    // ... \\n    if (item.Price != product.Price) \\n    { \\n        var oldPrice = item.Price; \\n \", \"       item.Price = product.Price; \\n        _context.CatalogItems.Update(item); \\n        var @event \", \"= new ProductPriceChangedIntegrationEvent(item.Id, \\n            item.Price, \\n            oldPrice); \", \"\\n        // Commit changes in original transaction \\n        await _context.SaveChangesAsync(); \\n    \", \"    // Publish integration event to the event bus \\n        // (RabbitMQ or a service bus underneath)\", \" \\n \\n143 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicatio\", \"ns \\n \\n        _eventBus.Publish(@event); \\n        // ... \\n    } \\n    // ... \\n} \\nIn this case, since \", \"the origin microservice is a simple CRUD microservice, that code is placed right into \\na Web API con\", \"troller. \\nIn more advanced microservices, like when using CQRS approaches, it can be implemented in \", \"the \\nCommandHandler class, within the Handle() method. \\nDesigning atomicity and resiliency when publ\", \"ishing to the event bus \\nWhen you publish integration events through a distributed messaging system \", \"like your event bus, you \\nhave the problem of atomically updating the original database and publishi\", \"ng an event (that is, either \\nboth operations complete or none of them). For instance, in the simpli\", \"fied example shown earlier, the \\ncode commits data to the database when the product price is changed\", \" and then publishes a \\nProductPriceChangedIntegrationEvent message. Initially, it might look essenti\", \"al that these two \\noperations be performed atomically. However, if you are using a distributed trans\", \"action involving the \\ndatabase and the message broker, as you do in older systems like Microsoft Mes\", \"sage Queuing \\n(MSMQ), this approach is not recommended for the reasons described by the CAP theorem.\", \" \\nBasically, you use microservices to build scalable and highly available systems. Simplifying somew\", \"hat, \\nthe CAP theorem says that you cannot build a (distributed) database (or a microservice that ow\", \"ns its \\nmodel) that\\u2019s continually available, strongly consistent, and tolerant to any partition. You\", \" must choose \\ntwo of these three properties. \\nIn microservices-based architectures, you should choos\", \"e availability and tolerance, and you should \\nde-emphasize strong consistency. Therefore, in most mo\", \"dern microservice-based applications, you \\nusually do not want to use distributed transactions in me\", \"ssaging, as you do when you implement \\ndistributed transactions based on the Windows Distributed Tra\", \"nsaction Coordinator (DTC) with \\nMSMQ. \\nLet\\u2019s go back to the initial issue and its example. If the s\", \"ervice crashes after the database is updated \\n(in this case, right after the line of code with _cont\", \"ext.SaveChangesAsync()), but before the integration \\nevent is published, the overall system could be\", \"come inconsistent. This approach might be business \\ncritical, depending on the specific business ope\", \"ration you are dealing with. \\nAs mentioned earlier in the architecture section, you can have several\", \" approaches for dealing with this \\nissue: \\n\\u2022 \\nUsing the full Event Sourcing pattern. \\n\\u2022 \\nUsing trans\", \"action log mining. \\n\\u2022 \\nUsing the Outbox pattern. This is a transactional table to store the integrat\", \"ion events \\n(extending the local transaction). \\nFor this scenario, using the full Event Sourcing (ES\", \") pattern is one of the best approaches, if not the \\nbest. However, in many application scenarios, y\", \"ou might not be able to implement a full ES system. ES \\nmeans storing only domain events in your tra\", \"nsactional database, instead of storing current state \\n \\n144 \\nCHAPTER 5 | Designing and Developing M\", \"ulti-Container and Microservice-Based .NET Applications \\n \\ndata. Storing only domain events can have\", \" great benefits, such as having the history of your system \\navailable and being able to determine th\", \"e state of your system at any moment in the past. However, \\nimplementing a full ES system requires y\", \"ou to rearchitect most of your system and introduces many \\nother complexities and requirements. For \", \"example, you would want to use a database specifically \\nmade for event sourcing, such as Event Store\", \", or a document-oriented database such as Azure \\nCosmos DB, MongoDB, Cassandra, CouchDB, or RavenDB.\", \" ES is a great approach for this problem, but \\nnot the easiest solution unless you are already famil\", \"iar with event sourcing. \\nThe option to use transaction log mining initially looks transparent. Howe\", \"ver, to use this approach, \\nthe microservice has to be coupled to your RDBMS transaction log, such a\", \"s the SQL Server transaction \\nlog. This approach is probably not desirable. Another drawback is that\", \" the low-level updates recorded \\nin the transaction log might not be at the same level as your high-\", \"level integration events. If so, the \\nprocess of reverse-engineering those transaction log operation\", \"s can be difficult. \\nA balanced approach is a mix of a transactional database table and a simplified\", \" ES pattern. You can \\nuse a state such as \\u201cready to publish the event,\\u201d which you set in the origina\", \"l event when you commit \\nit to the integration events table. You then try to publish the event to th\", \"e event bus. If the publish-\\nevent action succeeds, you start another transaction in the origin serv\", \"ice and move the state from \\n\\u201cready to publish the event\\u201d to \\u201cevent already published.\\u201d \\nIf the publ\", \"ish-event action in the event bus fails, the data still will not be inconsistent within the origin \\n\", \"microservice\\u2014it is still marked as \\u201cready to publish the event,\\u201d and with respect to the rest of the\", \" \\nservices, it will eventually be consistent. You can always have background jobs checking the state\", \" of \\nthe transactions or integration events. If the job finds an event in the \\u201cready to publish the \", \"event\\u201d \\nstate, it can try to republish that event to the event bus. \\nNotice that with this approach,\", \" you are persisting only the integration events for each origin \\nmicroservice, and only the events t\", \"hat you want to communicate to other microservices or external \\nsystems. In contrast, in a full ES s\", \"ystem, you store all domain events as well. \\nTherefore, this balanced approach is a simplified ES sy\", \"stem. You need a list of integration events with \\ntheir current state (\\u201cready to publish\\u201d versus \\u201cpu\", \"blished\\u201d). But you only need to implement these \\nstates for the integration events. And in this appr\", \"oach, you do not need to store all your domain data \\nas events in the transactional database, as you\", \" would in a full ES system. \\nIf you are already using a relational database, you can use a transacti\", \"onal table to store integration \\nevents. To achieve atomicity in your application, you use a two-ste\", \"p process based on local \\ntransactions. Basically, you have an IntegrationEvent table in the same da\", \"tabase where you have your \\ndomain entities. That table works as an insurance for achieving atomicit\", \"y so that you include persisted \\nintegration events into the same transactions that are committing y\", \"our domain data. \\nStep by step, the process goes like this: \\n1. \\nThe application begins a local data\", \"base transaction. \\n2. \\nIt then updates the state of your domain entities and inserts an event into t\", \"he integration \\nevent table. \\n3. \\nFinally, it commits the transaction, so you get the desired atomic\", \"ity and then \\n \\n145 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NE\", \"T Applications \\n \\n4. \\nYou publish the event somehow (next). \\nWhen implementing the steps of publishi\", \"ng the events, you have these choices: \\n\\u2022 \\nPublish the integration event right after committing the \", \"transaction and use another local \\ntransaction to mark the events in the table as being published. T\", \"hen, use the table just as an \\nartifact to track the integration events in case of issues in the rem\", \"ote microservices, and \\nperform compensatory actions based on the stored integration events. \\n\\u2022 \\nUse\", \" the table as a kind of queue. A separate application thread or process queries the \\nintegration eve\", \"nt table, publishes the events to the event bus, and then uses a local \\ntransaction to mark the even\", \"ts as published. \\nFigure 6-22 shows the architecture for the first of these approaches. \\n \\nFigure 6-\", \"22. Atomicity when publishing events to the event bus \\nThe approach illustrated in Figure 6-22 is mi\", \"ssing an additional worker microservice that is in charge \\nof checking and confirming the success of\", \" the published integration events. In case of failure, that \\nadditional checker worker microservice \", \"can read events from the table and republish them, that is, \\nrepeat step number 2. \\nAbout the second\", \" approach: you use the EventLog table as a queue and always use a worker \\nmicroservice to publish th\", \"e messages. In that case, the process is like that shown in Figure 6-23. This \\nshows an additional m\", \"icroservice, and the table is the single source when publishing events. \\n \\n146 \\nCHAPTER 5 | Designin\", \"g and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-23. Atomicit\", \"y when publishing events to the event bus with a worker microservice \\nFor simplicity, the eShopOnCon\", \"tainers sample uses the first approach (with no additional processes or \\nchecker microservices) plus\", \" the event bus. However, the eShopOnContainers sample is not handling \\nall possible failure cases. I\", \"n a real application deployed to the cloud, you must embrace the fact that \\nissues will arise eventu\", \"ally, and you must implement that check and resend logic. Using the table as a \\nqueue can be more ef\", \"fective than the first approach if you have that table as a single source of events \\nwhen publishing\", \" them (with the worker) through the event bus. \\nImplementing atomicity when publishing integration e\", \"vents through the event \\nbus \\nThe following code shows how you can create a single transaction invol\", \"ving multiple DbContext \\nobjects\\u2014one context related to the original data being updated, and the sec\", \"ond context related to \\nthe IntegrationEventLog table. \\nThe transaction in the example code below wi\", \"ll not be resilient if connections to the database have \\nany issue at the time when the code is runn\", \"ing. This can happen in cloud-based systems like Azure \\nSQL DB, which might move databases across se\", \"rvers. For implementing resilient transactions across \\nmultiple contexts, see the Implementing resil\", \"ient Entity Framework Core SQL connections section later \\nin this guide. \\nFor clarity, the following\", \" example shows the whole process in a single piece of code. However, the \\neShopOnContainers implemen\", \"tation is refactored and splits this logic into multiple classes so it\\u2019s \\neasier to maintain. \\n// Up\", \"date Product from the Catalog microservice \\n// \\npublic async Task<IActionResult> UpdateProduct([From\", \"Body]CatalogItem productToUpdate) \\n{ \\n  var catalogItem = \\n       await _catalogContext.CatalogItems\", \".SingleOrDefaultAsync(i => i.Id == \\n                                                               p\", \"roductToUpdate.Id); \\n \\n147 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Ba\", \"sed .NET Applications \\n \\n  if (catalogItem == null) return NotFound(); \\n \\n  bool raiseProductPriceCh\", \"angedEvent = false; \\n  IntegrationEvent priceChangedEvent = null; \\n \\n  if (catalogItem.Price != prod\", \"uctToUpdate.Price) \\n          raiseProductPriceChangedEvent = true; \\n \\n  if (raiseProductPriceChange\", \"dEvent) // Create event if price has changed \\n  { \\n      var oldPrice = catalogItem.Price; \\n      pr\", \"iceChangedEvent = new ProductPriceChangedIntegrationEvent(catalogItem.Id, \\n                         \", \"                                         productToUpdate.Price, \\n                                   \", \"                               oldPrice); \\n  } \\n  // Update current product \\n  catalogItem = product\", \"ToUpdate; \\n \\n  // Just save the updated product if the Product's Price hasn't changed. \\n  if (!raise\", \"ProductPriceChangedEvent) \\n  { \\n      await _catalogContext.SaveChangesAsync(); \\n  } \\n  else  // Pub\", \"lish to event bus only if product price changed \\n  { \\n        // Achieving atomicity between origina\", \"l DB and the IntegrationEventLog \\n        // with a local transaction \\n        using (var transactio\", \"n = _catalogContext.Database.BeginTransaction()) \\n        { \\n           _catalogContext.CatalogItems\", \".Update(catalogItem); \\n           await _catalogContext.SaveChangesAsync(); \\n \\n           await _int\", \"egrationEventLogService.SaveEventAsync(priceChangedEvent); \\n \\n           transaction.Commit(); \\n    \", \"    } \\n \\n      // Publish the integration event through the event bus \\n      _eventBus.Publish(price\", \"ChangedEvent); \\n \\n      _integrationEventLogService.MarkEventAsPublishedAsync( \\n                    \", \"                            priceChangedEvent); \\n  } \\n \\n  return Ok(); \\n} \\nAfter the ProductPriceCha\", \"ngedIntegrationEvent integration event is created, the transaction that \\nstores the original domain \", \"operation (update the catalog item) also includes the persistence of the \\nevent in the EventLog tabl\", \"e. This makes it a single transaction, and you will always be able to check \\nwhether event messages \", \"were sent. \\nThe event log table is updated atomically with the original database operation, using a \", \"local \\ntransaction against the same database. If any of the operations fail, an exception is thrown \", \"and the \\ntransaction rolls back any completed operation, thus maintaining consistency between the do\", \"main \\noperations and the event messages saved to the table. \\n \\n148 \\nCHAPTER 5 | Designing and Develo\", \"ping Multi-Container and Microservice-Based .NET Applications \\n \\nReceiving messages from subscriptio\", \"ns: event handlers in receiver microservices \\nIn addition to the event subscription logic, you need \", \"to implement the internal code for the \\nintegration event handlers (like a callback method). The eve\", \"nt handler is where you specify where the \\nevent messages of a certain type will be received and pro\", \"cessed. \\nAn event handler first receives an event instance from the event bus. Then it locates the c\", \"omponent to \\nbe processed related to that integration event, propagating and persisting the event as\", \" a change in \\nstate in the receiver microservice. For example, if a ProductPriceChanged event origin\", \"ates in the \\ncatalog microservice, it is handled in the basket microservice and changes the state in\", \" this receiver \\nbasket microservice as well, as shown in the following code. \\nnamespace Microsoft.eS\", \"hopOnContainers.Services.Basket.API.IntegrationEvents.EventHandling \\n{ \\n    public class ProductPric\", \"eChangedIntegrationEventHandler : \\n        IIntegrationEventHandler<ProductPriceChangedIntegrationEv\", \"ent> \\n    { \\n        private readonly IBasketRepository _repository; \\n \\n        public ProductPriceC\", \"hangedIntegrationEventHandler( \\n            IBasketRepository repository) \\n        { \\n            _r\", \"epository = repository; \\n        } \\n \\n        public async Task Handle(ProductPriceChangedIntegratio\", \"nEvent @event) \\n        { \\n            var userIds = await _repository.GetUsers(); \\n            fore\", \"ach (var id in userIds) \\n            { \\n                var basket = await _repository.GetBasket(id)\", \"; \\n                await UpdatePriceInBasketItems(@event.ProductId, @event.NewPrice, basket); \\n     \", \"       } \\n        } \\n \\n        private async Task UpdatePriceInBasketItems(int productId, decimal ne\", \"wPrice, \\n            CustomerBasket basket) \\n        { \\n            var itemsToUpdate = basket?.Item\", \"s?.Where(x => int.Parse(x.ProductId) == \\n                productId).ToList(); \\n            if (items\", \"ToUpdate != null) \\n            { \\n                foreach (var item in itemsToUpdate) \\n             \", \"   { \\n                    if(item.UnitPrice != newPrice) \\n                    { \\n                   \", \"     var originalPrice = item.UnitPrice; \\n                        item.UnitPrice = newPrice; \\n      \", \"                  item.OldUnitPrice = originalPrice; \\n                    } \\n                } \\n    \", \"            await _repository.UpdateBasket(basket); \\n            } \\n        } \\n    } \\n} \\n \\n149 \\nCHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nThe eve\", \"nt handler needs to verify whether the product exists in any of the basket instances. It also \\nupdat\", \"es the item price for each related basket line item. Finally, it creates an alert to be displayed to\", \" \\nthe user about the price change, as shown in Figure 6-24. \\n \\nFigure 6-24. Displaying an item price\", \" change in a basket, as communicated by integration events \\nIdempotency in update message events \\nAn\", \" important aspect of update message events is that a failure at any point in the communication \\nshou\", \"ld cause the message to be retried. Otherwise a background task might try to publish an event \\nthat \", \"has already been published, creating a race condition. Make sure that the updates are either \\nidempo\", \"tent or that they provide enough information to ensure that you can detect a duplicate, \\ndiscard it,\", \" and send back only one response. \\nAs noted earlier, idempotency means that an operation can be perf\", \"ormed multiple times without \\nchanging the result. In a messaging environment, as when communicating\", \" events, an event is \\nidempotent if it can be delivered multiple times without changing the result f\", \"or the receiver \\nmicroservice. This may be necessary because of the nature of the event itself, or b\", \"ecause of the way \\nthe system handles the event. Message idempotency is important in any application\", \" that uses \\nmessaging, not just in applications that implement the event bus pattern. \\nAn example of\", \" an idempotent operation is a SQL statement that inserts data into a table only if that \\ndata is not\", \" already in the table. It does not matter how many times you run that insert SQL statement; \\nthe res\", \"ult will be the same\\u2014the table will contain that data. Idempotency like this can also be \\nnecessary \", \"when dealing with messages if the messages could potentially be sent and therefore \\n \\n150 \\nCHAPTER 5\", \" | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nprocessed mo\", \"re than once. For instance, if retry logic causes a sender to send exactly the same \\nmessage more th\", \"an once, you need to make sure that it is idempotent. \\nIt is possible to design idempotent messages.\", \" For example, you can create an event that says \\u201cset the \\nproduct price to $25\\u201d instead of \\u201cadd $5 t\", \"o the product price.\\u201d You could safely process the first \\nmessage any number of times and the result\", \" will be the same. That is not true for the second \\nmessage. But even in the first case, you might n\", \"ot want to process the first event, because the system \\ncould also have sent a newer price-change ev\", \"ent and you would be overwriting the new price. \\nAnother example might be an order-completed event t\", \"hat\\u2019s propagated to multiple subscribers. The \\napp has to make sure that order information is update\", \"d in other systems only once, even if there are \\nduplicated message events for the same order-comple\", \"ted event. \\nIt is convenient to have some kind of identity per event so that you can create logic th\", \"at enforces that \\neach event is processed only once per receiver. \\nSome message processing is inhere\", \"ntly idempotent. For example, if a system generates image \\nthumbnails, it might not matter how many \", \"times the message about the generated thumbnail is \\nprocessed; the outcome is that the thumbnails ar\", \"e generated and they are the same every time. On \\nthe other hand, operations such as calling a payme\", \"nt gateway to charge a credit card may not be \\nidempotent at all. In these cases, you need to ensure\", \" that processing a message multiple times has \\nthe effect that you expect. \\nAdditional resources \\n\\u2022 \", \"\\nHonoring message idempotency \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/jj591565(v=pand\", \"p.10)#honoring-\\nmessage-idempotency \\nDeduplicating integration event messages \\nYou can make sure tha\", \"t message events are sent and processed only once per subscriber at different \\nlevels. One way is to\", \" use a deduplication feature offered by the messaging infrastructure you are \\nusing. Another is to i\", \"mplement custom logic in your destination microservice. Having validations at \\nboth the transport le\", \"vel and the application level is your best bet. \\nDeduplicating message events at the EventHandler le\", \"vel \\nOne way to make sure that an event is processed only once by any receiver is by implementing ce\", \"rtain \\nlogic when processing the message events in event handlers. For example, that is the approach\", \" used \\nin the eShopOnContainers application, as you can see in the source code of the \\nUserCheckoutA\", \"cceptedIntegrationEventHandler class when it receives a \\nUserCheckoutAcceptedIntegrationEvent integr\", \"ation event. (In this case, the CreateOrderCommand is \\nwrapped with an IdentifiedCommand, using the \", \"eventMsg.RequestId as an identifier, before sending it \\nto the command handler). \\n \\n151 \\nCHAPTER 5 |\", \" Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nDeduplicating \", \"messages when using RabbitMQ \\nWhen intermittent network failures happen, messages can be duplicated,\", \" and the message receiver \\nmust be ready to handle these duplicated messages. If possible, receivers\", \" should handle messages in \\nan idempotent way, which is better than explicitly handling them with de\", \"duplication. \\nAccording to the RabbitMQ documentation, \\u201cIf a message is delivered to a consumer and \", \"then \\nrequeued (because it was not acknowledged before the consumer connection dropped, for example)\", \" \\nthen RabbitMQ will set the redelivered flag on it when it is delivered again (whether to the same \", \"\\nconsumer or a different one). \\nIf the \\u201credelivered\\u201d flag is set, the receiver must take that into a\", \"ccount, because the message might \\nalready have been processed. But that is not guaranteed; the mess\", \"age might never have reached the \\nreceiver after it left the message broker, perhaps because of netw\", \"ork issues. On the other hand, if the \\n\\u201credelivered\\u201d flag is not set, it is guaranteed that the mess\", \"age has not been sent more than once. \\nTherefore, the receiver needs to deduplicate messages or proc\", \"ess messages in an idempotent way \\nonly if the \\u201credelivered\\u201d flag is set in the message. \\nAdditional\", \" resources \\n\\u2022 \\nForked eShopOnContainers using NServiceBus (Particular Software) \\nhttps://go.particul\", \"ar.net/eShopOnContainers \\n\\u2022 \\nEvent Driven Messaging \\nhttps://patterns.arcitura.com/soa-patterns/desi\", \"gn_patterns/event_driven_messaging \\n\\u2022 \\nJimmy Bogard. Refactoring Towards Resilience: Evaluating Coup\", \"ling \\nhttps://jimmybogard.com/refactoring-towards-resilience-evaluating-coupling/ \\n\\u2022 \\nPublish-Subscr\", \"ibe channel \\nhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChanne\", \"l.\\nhtml \\n\\u2022 \\nCommunicating Between Bounded Contexts \\nhttps://learn.microsoft.com/previous-versions/ms\", \"p-n-p/jj591572(v=pandp.10) \\n\\u2022 \\nEventual Consistency \\nhttps://en.wikipedia.org/wiki/Eventual_consiste\", \"ncy \\n\\u2022 \\nPhilip Brown. Strategies for Integrating Bounded Contexts \\nhttps://www.culttt.com/2014/11/26\", \"/strategies-integrating-bounded-contexts/ \\n\\u2022 \\nChris Richardson. Developing Transactional Microservic\", \"es Using Aggregates, Event \\nSourcing and CQRS - Part 2 \\nhttps://www.infoq.com/articles/microservices\", \"-aggregates-events-cqrs-part-2-richardson \\n\\u2022 \\nChris Richardson. Event Sourcing pattern \\nhttps://micr\", \"oservices.io/patterns/data/event-sourcing.html \\n\\u2022 \\nIntroducing Event Sourcing \\nhttps://learn.microso\", \"ft.com/previous-versions/msp-n-p/jj591559(v=pandp.10) \\n \\n152 \\nCHAPTER 5 | Designing and Developing M\", \"ulti-Container and Microservice-Based .NET Applications \\n \\n\\u2022 \\nEvent Store database. Official site. \\n\", \"https://geteventstore.com/ \\n\\u2022 \\nPatrick Nommensen. Event-Driven Data Management for Microservices \\nht\", \"tps://dzone.com/articles/event-driven-data-management-for-microservices-1 \\n\\u2022 \\nThe CAP Theorem \\nhttps\", \"://en.wikipedia.org/wiki/CAP_theorem \\n\\u2022 \\nWhat is CAP Theorem? \\nhttps://www.quora.com/What-Is-CAP-The\", \"orem-1 \\n\\u2022 \\nData Consistency Primer \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v\", \"=pandp.10) \\n\\u2022 \\nRick Saling. The CAP Theorem: Why \\u201cEverything is Different\\u201d with the Cloud and \\nInter\", \"net \\nhttps://learn.microsoft.com/archive/blogs/rickatmicrosoft/the-cap-theorem-why-everything-\\nis-di\", \"fferent-with-the-cloud-and-internet/ \\n\\u2022 \\nEric Brewer. CAP Twelve Years Later: How the \\u201cRules\\u201d Have C\", \"hanged \\nhttps://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed \\n\\u2022 \\nCAP, PA\", \"CELC, and Microservices \\nhttps://ardalis.com/cap-pacelc-and-microservices/ \\n\\u2022 \\nAzure Service Bus. Br\", \"okered Messaging: Duplicate Detection \\nhttps://github.com/microsoftarchive/msdn-code-gallery-\\nmicros\", \"oft/tree/master/Windows%20Azure%20Product%20Team/Brokered%20Messaging%20\\nDuplicate%20Detection \\n\\u2022 \\nR\", \"eliability Guide (RabbitMQ documentation) \\nhttps://www.rabbitmq.com/reliability.html#consumer \\nTesti\", \"ng ASP.NET Core services and web apps \\nControllers are a central part of any ASP.NET Core API servic\", \"e and ASP.NET MVC Web application. As \\nsuch, you should have confidence they behave as intended for \", \"your application. Automated tests can \\nprovide you with this confidence and can detect errors before\", \" they reach production. \\nYou need to test how the controller behaves based on valid or invalid input\", \"s, and test controller \\nresponses based on the result of the business operation it performs. However\", \", you should have these \\ntypes of tests for your microservices: \\n\\u2022 \\nUnit tests. These tests ensure t\", \"hat individual components of the application work as expected. \\nAssertions test the component API. \\n\", \"\\u2022 \\nIntegration tests. These tests ensure that component interactions work as expected against \\nexter\", \"nal artifacts like databases. Assertions can test component API, UI, or the side effects of \\nactions\", \" like database I/O, logging, etc. \\n \\n153 \\nCHAPTER 5 | Designing and Developing Multi-Container and M\", \"icroservice-Based .NET Applications \\n \\n\\u2022 \\nFunctional tests for each microservice. These tests ensure\", \" that the application works as \\nexpected from the user\\u2019s perspective. \\n\\u2022 \\nService tests. These tests\", \" ensure that end-to-end service use cases, including testing multiple \\nservices at the same time, ar\", \"e tested. For this type of testing, you need to prepare the \\nenvironment first. In this case, it mea\", \"ns starting the services (for example, by using docker-\\ncompose up). \\nImplementing unit tests for AS\", \"P.NET Core Web APIs \\nUnit testing involves testing a part of an application in isolation from its in\", \"frastructure and \\ndependencies. When you unit test controller logic, only the content of a single ac\", \"tion or method is \\ntested, not the behavior of its dependencies or of the framework itself. Unit tes\", \"ts do not detect issues \\nin the interaction between components\\u2014that is the purpose of integration te\", \"sting. \\nAs you unit test your controller actions, make sure you focus only on their behavior. A cont\", \"roller unit \\ntest avoids things like filters, routing, or model binding (the mapping of request data\", \" to a ViewModel \\nor DTO). Because they focus on testing just one thing, unit tests are generally sim\", \"ple to write and \\nquick to run. A well-written set of unit tests can be run frequently without much \", \"overhead. \\nUnit tests are implemented based on test frameworks like xUnit.net, MSTest, Moq, or NUnit\", \". For the \\neShopOnContainers sample application, we are using xUnit. \\nWhen you write a unit test for\", \" a Web API controller, you instantiate the controller class directly using \\nthe new keyword in C#, s\", \"o that the test will run as fast as possible. The following example shows how \\nto do this when using\", \" xUnit as the Test framework. \\n[Fact] \\npublic async Task Get_order_detail_success() \\n{ \\n    //Arrang\", \"e \\n    var fakeOrderId = \\\"12\\\"; \\n    var fakeOrder = GetFakeOrder(); \\n \\n    //... \\n \\n    //Act \\n    v\", \"ar orderController = new OrderController( \\n        _orderServiceMock.Object, \\n        _basketService\", \"Mock.Object, \\n        _identityParserMock.Object); \\n \\n    orderController.ControllerContext.HttpCont\", \"ext = _contextMock.Object; \\n    var actionResult = await orderController.Detail(fakeOrderId); \\n \\n   \", \" //Assert \\n    var viewResult = Assert.IsType<ViewResult>(actionResult); \\n    Assert.IsAssignableFro\", \"m<Order>(viewResult.ViewData.Model); \\n} \\n \\n154 \\nCHAPTER 5 | Designing and Developing Multi-Container\", \" and Microservice-Based .NET Applications \\n \\nImplementing integration and functional tests for each \", \"microservice \\nAs noted, integration tests and functional tests have different purposes and goals. Ho\", \"wever, the way \\nyou implement both when testing ASP.NET Core controllers is similar, so in this sect\", \"ion we \\nconcentrate on integration tests. \\nIntegration testing ensures that an application\\u2019s compone\", \"nts function correctly when assembled. \\nASP.NET Core supports integration testing using unit test fr\", \"ameworks and a built-in test web host that \\ncan be used to handle requests without network overhead.\", \" \\nUnlike unit testing, integration tests frequently involve application infrastructure concerns, suc\", \"h as a \\ndatabase, file system, network resources, or web requests and responses. Unit tests use fake\", \"s or mock \\nobjects in place of these concerns. But the purpose of integration tests is to confirm th\", \"at the system \\nworks as expected with these systems, so for integration testing you do not use fakes\", \" or mock objects. \\nInstead, you include the infrastructure, like database access or service invocati\", \"on from other services. \\nBecause integration tests exercise larger segments of code than unit tests,\", \" and because integration \\ntests rely on infrastructure elements, they tend to be orders of magnitude\", \" slower than unit tests. Thus, \\nit is a good idea to limit how many integration tests you write and \", \"run. \\nASP.NET Core includes a built-in test web host that can be used to handle HTTP requests withou\", \"t \\nnetwork overhead, meaning that you can run those tests faster than when using a real web host. Th\", \"e \\ntest web host (TestServer) is available in a NuGet component as Microsoft.AspNetCore.TestHost. It\", \" can \\nbe added to integration test projects and used to host ASP.NET Core applications. \\nAs you can \", \"see in the following code, when you create integration tests for ASP.NET Core controllers, \\nyou inst\", \"antiate the controllers through the test host. This functionality is comparable to an HTTP \\nrequest,\", \" but it runs faster. \\npublic class PrimeWebDefaultRequestShould \\n{ \\n    private readonly TestServer \", \"_server; \\n    private readonly HttpClient _client; \\n \\n    public PrimeWebDefaultRequestShould() \\n   \", \" { \\n        // Arrange \\n        _server = new TestServer(new WebHostBuilder() \\n           .UseStartu\", \"p<Startup>()); \\n        _client = _server.CreateClient(); \\n    } \\n \\n    [Fact] \\n    public async Tas\", \"k ReturnHelloWorld() \\n    { \\n        // Act \\n        var response = await _client.GetAsync(\\\"/\\\"); \\n  \", \"      response.EnsureSuccessStatusCode(); \\n        var responseString = await response.Content.ReadA\", \"sStringAsync(); \\n        // Assert \\n        Assert.Equal(\\\"Hello World!\\\", responseString); \\n    } \\n} \", \"\\n \\n155 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Application\", \"s \\n \\nAdditional resources \\n\\u2022 \\nSteve Smith. Testing controllers (ASP.NET Core) \\nhttps://learn.microso\", \"ft.com/aspnet/core/mvc/controllers/testing \\n\\u2022 \\nSteve Smith. Integration testing (ASP.NET Core) \\nhttp\", \"s://learn.microsoft.com/aspnet/core/test/integration-tests \\n\\u2022 \\nUnit testing in .NET using dotnet tes\", \"t \\nhttps://learn.microsoft.com/dotnet/core/testing/unit-testing-with-dotnet-test \\n\\u2022 \\nxUnit.net. Offi\", \"cial site. \\nhttps://xunit.net/ \\n\\u2022 \\nUnit Test Basics. \\nhttps://learn.microsoft.com/visualstudio/test/\", \"unit-test-basics \\n\\u2022 \\nMoq. GitHub repo. \\nhttps://github.com/moq/moq \\n\\u2022 \\nNUnit. Official site. \\nhttps:\", \"//nunit.org/ \\nImplementing service tests on a multi-container application \\nAs noted earlier, when yo\", \"u test multi-container applications, all the microservices need to be running \\nwithin the Docker hos\", \"t or container cluster. End-to-end service tests that include multiple operations \\ninvolving several\", \" microservices require you to deploy and start the whole application in the Docker \\nhost by running \", \"docker-compose up (or a comparable mechanism if you are using an orchestrator). \\nOnce the whole appl\", \"ication and all its services is running, you can execute end-to-end integration and \\nfunctional test\", \"s. \\nThere are a few approaches you can use. In the docker-compose.yml file that you use to deploy th\", \"e \\napplication at the solution level you can expand the entry point to use dotnet test. You can also\", \" use \\nanother compose file that would run your tests in the image you are targeting. By using anothe\", \"r \\ncompose file for integration tests that includes your microservices and databases on containers, \", \"you \\ncan make sure that the related data is always reset to its original state before running the te\", \"sts. \\nOnce the compose application is up and running, you can take advantage of breakpoints and \\nexc\", \"eptions if you are running Visual Studio. Or you can run the integration tests automatically in your\", \" \\nCI pipeline in Azure DevOps Services or any other CI/CD system that supports Docker containers. \\nT\", \"esting in eShopOnContainers \\nThe reference application (eShopOnContainers) tests were recently restr\", \"uctured and now there are \\nfour categories: \\n1. \\nUnit tests, just plain old regular unit tests, cont\", \"ained in the {MicroserviceName}.UnitTests \\nprojects \\n \\n156 \\nCHAPTER 5 | Designing and Developing Mul\", \"ti-Container and Microservice-Based .NET Applications \\n \\n2. \\nMicroservice functional/integration tes\", \"ts, with test cases involving the infrastructure for \\neach microservice but isolated from the others\", \" and are contained in the \\n{MicroserviceName}.FunctionalTests projects. \\n3. \\nApplication functional/\", \"integration tests, which focus on microservices integration, with test \\ncases that exert several mic\", \"roservices. These tests are located in project \\nApplication.FunctionalTests. \\nWhile unit and integra\", \"tion tests are organized in a test folder within the microservice project, \\napplication and load tes\", \"ts are managed separately under the root folder, as shown in Figure 6-25. \\n \\nFigure 6-25. Test folde\", \"r structure in eShopOnContainers \\nMicroservice and Application functional/integration tests are run \", \"from Visual Studio, using the regular \\ntests runner, but first you need to start the required infras\", \"tructure services, with a set of docker-\\ncompose files contained in the solution test folder: \\ndocke\", \"r-compose-test.yml \\nversion: '3.4' \\n \\nservices: \\n  redis.data: \\n    image: redis:alpine \\n  rabbitmq:\", \" \\n    image: rabbitmq:3-management-alpine \\n  sqldata: \\n \\n157 \\nCHAPTER 5 | Designing and Developing M\", \"ulti-Container and Microservice-Based .NET Applications \\n \\n    image: mcr.microsoft.com/mssql/server\", \":2017-latest \\n  nosqldata: \\n    image: mongo \\ndocker-compose-test.override.yml \\nversion: '3.4' \\n \\nse\", \"rvices: \\n  redis.data: \\n    ports: \\n      - \\\"6379:6379\\\" \\n  rabbitmq: \\n    ports: \\n      - \\\"15672:156\", \"72\\\" \\n      - \\\"5672:5672\\\" \\n  sqldata: \\n    environment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEP\", \"T_EULA=Y \\n    ports: \\n      - \\\"5433:1433\\\" \\n  nosqldata: \\n    ports: \\n      - \\\"27017:27017\\\" \\nSo, to r\", \"un the functional/integration tests you must first run this command, from the solution test \\nfolder:\", \" \\ndocker-compose -f docker-compose-test.yml -f docker-compose-test.override.yml up \\nAs you can see, \", \"these docker-compose files only start the Redis, RabbitMQ, SQL Server, and MongoDB \\nmicroservices. \\n\", \"Additional resources \\n\\u2022 \\nUnit & Integration testing on the eShopOnContainers \\nhttps://github.com/dot\", \"net-architecture/eShopOnContainers/wiki/Unit-and-integration-\\ntesting \\n\\u2022 \\nLoad testing on the eShopO\", \"nContainers \\nhttps://github.com/dotnet-architecture/eShopOnContainers/wiki/Load-testing \\nImplement b\", \"ackground tasks in microservices with \\nIHostedService and the BackgroundService class \\nBackground ta\", \"sks and scheduled jobs are something you might need to use in any application, \\nwhether or not it fo\", \"llows the microservices architecture pattern. The difference when using a \\nmicroservices architectur\", \"e is that you can implement the background task in a separate \\nprocess/container for hosting so you \", \"can scale it down/up based on your need. \\n \\n158 \\nCHAPTER 5 | Designing and Developing Multi-Containe\", \"r and Microservice-Based .NET Applications \\n \\nFrom a generic point of view, in .NET we called these \", \"type of tasks Hosted Services, because they are \\nservices/logic that you host within your host/appli\", \"cation/microservice. Note that in this case, the \\nhosted service simply means a class with the backg\", \"round task logic. \\nSince .NET Core 2.0, the framework provides a new interface named IHostedService \", \"helping you to \\neasily implement hosted services. The basic idea is that you can register multiple b\", \"ackground tasks \\n(hosted services) that run in the background while your web host or host is running\", \", as shown in the \\nimage 6-26. \\n \\nFigure 6-26. Using IHostedService in a WebHost vs. a Host \\nASP.NET\", \" Core 1.x and 2.x support IWebHost for background processes in web apps. .NET Core 2.1 and \\nlater ve\", \"rsions support IHost for background processes with plain console apps. Note the difference \\nmade bet\", \"ween WebHost and Host. \\nA WebHost (base class implementing IWebHost) in ASP.NET Core 2.0 is the infr\", \"astructure artifact you \\nuse to provide HTTP server features to your process, such as when you\\u2019re im\", \"plementing an MVC web \\napp or Web API service. It provides all the new infrastructure goodness in AS\", \"P.NET Core, enabling you \\nto use dependency injection, insert middlewares in the request pipeline, a\", \"nd similar. The WebHost \\nuses these very same IHostedServices for background tasks. \\nA Host (base cl\", \"ass implementing IHost) was introduced in .NET Core 2.1. Basically, a Host allows you \\nto have a sim\", \"ilar infrastructure than what you have with WebHost (dependency injection, hosted \\nservices, etc.), \", \"but in this case, you just want to have a simple and lighter process as the host, with \\nnothing rela\", \"ted to MVC, Web API or HTTP server features. \\nTherefore, you can choose and either create a speciali\", \"zed host-process with IHost to handle the \\nhosted services and nothing else, such a microservice mad\", \"e just for hosting the IHostedServices, or \\nyou can alternatively extend an existing ASP.NET Core We\", \"bHost, such as an existing ASP.NET Core \\nWeb API or MVC app. \\n \\n159 \\nCHAPTER 5 | Designing and Devel\", \"oping Multi-Container and Microservice-Based .NET Applications \\n \\nEach approach has pros and cons de\", \"pending on your business and scalability needs. The bottom line \\nis basically that if your backgroun\", \"d tasks have nothing to do with HTTP (IWebHost) you should use \\nIHost. \\nRegistering hosted services \", \"in your WebHost or Host \\nLet\\u2019s drill down further on the IHostedService interface since its usage is\", \" pretty similar in a WebHost or \\nin a Host. \\nSignalR is one example of an artifact using hosted serv\", \"ices, but you can also use it for much simpler \\nthings like: \\n\\u2022 \\nA background task polling a databas\", \"e looking for changes. \\n\\u2022 \\nA scheduled task updating some cache periodically. \\n\\u2022 \\nAn implementation \", \"of QueueBackgroundWorkItem that allows a task to be executed on a \\nbackground thread. \\n\\u2022 \\nProcessing\", \" messages from a message queue in the background of a web app while sharing \\ncommon services such as\", \" ILogger. \\n\\u2022 \\nA background task started with Task.Run(). \\nYou can basically offload any of those act\", \"ions to a background task that implements IHostedService. \\nThe way you add one or multiple IHostedSe\", \"rvices into your WebHost or Host is by registering them \\nup through the AddHostedService extension m\", \"ethod in an ASP.NET Core WebHost (or in a Host in \\n.NET Core 2.1 and above). Basically, you have to \", \"register the hosted services within application startup \\nin Program.cs. \\n//Other DI registrations; \\n\", \" \\n// Register Hosted Services \\nbuilder.Services.AddHostedService<GracePeriodManagerService>(); \\nbuil\", \"der.Services.AddHostedService<MyHostedServiceB>(); \\nbuilder.Services.AddHostedService<MyHostedServic\", \"eC>(); \\n//... \\nIn that code, the GracePeriodManagerService hosted service is real code from the Orde\", \"ring business \\nmicroservice in eShopOnContainers, while the other two are just two additional sample\", \"s. \\nThe IHostedService background task execution is coordinated with the lifetime of the application\", \" (host \\nor microservice, for that matter). You register tasks when the application starts and you ha\", \"ve the \\nopportunity to do some graceful action or clean-up when the application is shutting down. \\nW\", \"ithout using IHostedService, you could always start a background thread to run any task. The \\ndiffer\", \"ence is precisely at the app\\u2019s shutdown time when that thread would simply be killed without \\nhaving\", \" the opportunity to run graceful clean-up actions. \\nThe IHostedService interface \\nWhen you register \", \"an IHostedService, .NET calls the StartAsync() and StopAsync() methods of your \\nIHostedService type \", \"during application start and stop respectively. For more details, see \\nIHostedService interface. \\n \\n\", \"160 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\", \" \\nAs you can imagine, you can create multiple implementations of IHostedService and register each of\", \" \\nthem in Program.cs, as shown previously. All those hosted services will be started and stopped alo\", \"ng \\nwith the application/microservice. \\nAs a developer, you are responsible for handling the stoppin\", \"g action of your services when \\nStopAsync() method is triggered by the host. \\nImplementing IHostedSe\", \"rvice with a custom hosted service class \\nderiving from the BackgroundService base class \\nYou could \", \"go ahead and create your custom hosted service class from scratch and implement the \\nIHostedService,\", \" as you need to do when using .NET Core 2.0 and later. \\nHowever, since most background tasks will ha\", \"ve similar needs in regard to the cancellation tokens \\nmanagement and other typical operations, ther\", \"e is a convenient abstract base class you can derive \\nfrom, named BackgroundService (available since\", \" .NET Core 2.1). \\nThat class provides the main work needed to set up the background task. \\nThe next \", \"code is the abstract BackgroundService base class as implemented in .NET. \\n// Copyright (c) .NET Fou\", \"ndation. Licensed under the Apache License, Version 2.0. \\n/// <summary> \\n/// Base class for implemen\", \"ting a long running <see cref=\\\"IHostedService\\\"/>. \\n/// </summary> \\npublic abstract class BackgroundS\", \"ervice : IHostedService, IDisposable \\n{ \\n    private Task _executingTask; \\n    private readonly Canc\", \"ellationTokenSource _stoppingCts = \\n                                                   new Cancellat\", \"ionTokenSource(); \\n \\n    protected abstract Task ExecuteAsync(CancellationToken stoppingToken); \\n \\n \", \"   public virtual Task StartAsync(CancellationToken cancellationToken) \\n    { \\n        // Store the \", \"task we're executing \\n        _executingTask = ExecuteAsync(_stoppingCts.Token); \\n \\n        // If th\", \"e task is completed then return it, \\n        // this will bubble cancellation and failure to the cal\", \"ler \\n        if (_executingTask.IsCompleted) \\n        { \\n            return _executingTask; \\n       \", \" } \\n \\n        // Otherwise it's running \\n        return Task.CompletedTask; \\n    } \\n \\n    public vir\", \"tual async Task StopAsync(CancellationToken cancellationToken) \\n    { \\n        // Stop called withou\", \"t start \\n        if (_executingTask == null) \\n        { \\n            return; \\n        } \\n \\n \\n161 \\nCH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n     \", \"   try \\n        { \\n            // Signal cancellation to the executing method \\n            _stopping\", \"Cts.Cancel(); \\n        } \\n        finally \\n        { \\n            // Wait until the task completes o\", \"r the stop token triggers \\n            await Task.WhenAny(_executingTask, Task.Delay(Timeout.Infinit\", \"e, \\n                                                          cancellationToken)); \\n        } \\n \\n   \", \" } \\n \\n    public virtual void Dispose() \\n    { \\n        _stoppingCts.Cancel(); \\n    } \\n} \\nWhen deriv\", \"ing from the previous abstract base class, thanks to that inherited implementation, you just \\nneed t\", \"o implement the ExecuteAsync() method in your own custom hosted service class, as in the \\nfollowing \", \"simplified code from eShopOnContainers which is polling a database and publishing \\nintegration event\", \"s into the Event Bus when needed. \\npublic class GracePeriodManagerService : BackgroundService \\n{ \\n  \", \"  private readonly ILogger<GracePeriodManagerService> _logger; \\n    private readonly OrderingBackgro\", \"undSettings _settings; \\n \\n    private readonly IEventBus _eventBus; \\n \\n    public GracePeriodManager\", \"Service(IOptions<OrderingBackgroundSettings> settings, \\n                                     IEventB\", \"us eventBus, \\n                                     ILogger<GracePeriodManagerService> logger) \\n    {\", \" \\n        // Constructor's parameters validations... \\n    } \\n \\n    protected override async Task Exe\", \"cuteAsync(CancellationToken stoppingToken) \\n    { \\n        _logger.LogDebug($\\\"GracePeriodManagerServ\", \"ice is starting.\\\"); \\n \\n        stoppingToken.Register(() => \\n            _logger.LogDebug($\\\" GracePe\", \"riod background task is stopping.\\\")); \\n \\n        while (!stoppingToken.IsCancellationRequested) \\n   \", \"     { \\n            _logger.LogDebug($\\\"GracePeriod task doing background work.\\\"); \\n \\n            // \", \"This eShopOnContainers method is querying a database table \\n            // and publishing events int\", \"o the Event Bus (RabbitMQ / ServiceBus) \\n            CheckConfirmedGracePeriodOrders(); \\n \\n         \", \"   try { \\n                    await Task.Delay(_settings.CheckUpdateTime, stoppingToken); \\n         \", \"       } \\n            catch (TaskCanceledException exception) { \\n                    _logger.LogCrit\", \"ical(exception, \\\"TaskCanceledException Error\\\", \\nexception.Message); \\n \\n162 \\nCHAPTER 5 | Designing an\", \"d Developing Multi-Container and Microservice-Based .NET Applications \\n \\n                } \\n        \", \"} \\n \\n        _logger.LogDebug($\\\"GracePeriod background task is stopping.\\\"); \\n    } \\n \\n    .../... \\n}\", \" \\nIn this specific case for eShopOnContainers, it\\u2019s executing an application method that\\u2019s querying \", \"a \\ndatabase table looking for orders with a specific state and when applying changes, it is publishi\", \"ng \\nintegration events through the event bus (underneath it can be using RabbitMQ or Azure Service B\", \"us). \\nOf course, you could run any other business background task, instead. \\nBy default, the cancell\", \"ation token is set with a 5 seconds timeout, although you can change that value \\nwhen building your \", \"WebHost using the UseShutdownTimeout extension of the IWebHostBuilder. This \\nmeans that our service \", \"is expected to cancel within 5 seconds otherwise it will be more abruptly killed. \\nThe following cod\", \"e would be changing that time to 10 seconds. \\nWebHost.CreateDefaultBuilder(args) \\n    .UseShutdownTi\", \"meout(TimeSpan.FromSeconds(10)) \\n    ... \\nSummary class diagram \\nThe following image shows a visual \", \"summary of the classes and interfaces involved when \\nimplementing IHostedServices. \\n \\nFigure 6-27. C\", \"lass diagram showing the multiple classes and interfaces related to IHostedService \\nClass diagram: I\", \"WebHost and IHost can host many services, which inherit from BackgroundService, \\nwhich implements IH\", \"ostedService. \\n \\n163 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications \\n \\nDeployment considerations and takeaways \\nIt is important to note that the way you\", \" deploy your ASP.NET Core WebHost or .NET Host might \\nimpact the final solution. For instance, if yo\", \"u deploy your WebHost on IIS or a regular Azure App \\nService, your host can be shut down because of \", \"app pool recycles. But if you are deploying your host \\nas a container into an orchestrator like Kube\", \"rnetes, you can control the assured number of live \\ninstances of your host. In addition, you could c\", \"onsider other approaches in the cloud especially made \\nfor these scenarios, like Azure Functions. Fi\", \"nally, if you need the service to be running all the time and \\nare deploying on a Windows Server you\", \" could use a Windows Service. \\nBut even for a WebHost deployed into an app pool, there are scenarios\", \" like repopulating or flushing \\napplication\\u2019s in-memory cache that would be still applicable. \\nThe I\", \"HostedService interface provides a convenient way to start background tasks in an ASP.NET Core \\nweb \", \"application (in .NET Core 2.0 and later versions) or in any process/host (starting in .NET Core 2.1 \", \"\\nwith IHost). Its main benefit is the opportunity you get with the graceful cancellation to clean-up\", \" the \\ncode of your background tasks when the host itself is shutting down. \\nAdditional resources \\n\\u2022 \", \"\\nBuilding a scheduled task in ASP.NET Core/Standard 2.0 \\nhttps://blog.maartenballiauw.be/post/2017/0\", \"8/01/building-a-scheduled-cache-updater-in-\\naspnet-core-2.html \\n\\u2022 \\nImplementing IHostedService in AS\", \"P.NET Core 2.0 \\nhttps://www.stevejgordon.co.uk/asp-net-core-2-ihostedservice \\n\\u2022 \\nGenericHost Sample \", \"using ASP.NET Core 2.1 \\nhttps://github.com/aspnet/Hosting/tree/release/2.1/samples/GenericHostSample\", \" \\nImplement API Gateways with Ocelot \\nImportant \\nThe reference microservice application eShopOnConta\", \"iners is currently using features provided by \\nEnvoy to implement the API Gateway instead of the ear\", \"lier referenced Ocelot. We made this design \\nchoice because of Envoy\\u2019s built-in support for the WebS\", \"ocket protocol, required by the new gRPC \\ninter-service communications implemented in eShopOnContain\", \"ers. However, we\\u2019ve retained this \\nsection in the guide so you can consider Ocelot as a simple, capa\", \"ble, and lightweight API Gateway \\nsuitable for production-grade scenarios. Also, latest Ocelot versi\", \"on contains a breaking change on its \\njson schema. Consider using Ocelot < v16.0.0, or use the key R\", \"outes instead of ReRoutes. \\nArchitect and design your API Gateways \\nThe following architecture diagr\", \"am shows how API Gateways were implemented with Ocelot in \\neShopOnContainers. \\n \\n164 \\nCHAPTER 5 | De\", \"signing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-28. eS\", \"hopOnContainers architecture with API Gateways \\nThat diagram shows how the whole application is depl\", \"oyed into a single Docker host or development \\nPC with \\u201cDocker for Windows\\u201d or \\u201cDocker for Mac\\u201d. How\", \"ever, deploying into any orchestrator would \\nbe similar, but any container in the diagram could be s\", \"caled out in the orchestrator. \\nIn addition, the infrastructure assets such as databases, cache, and\", \" message brokers should be \\noffloaded from the orchestrator and deployed into high available systems\", \" for infrastructure, like Azure \\nSQL Database, Azure Cosmos DB, Azure Redis, Azure Service Bus, or a\", \"ny HA clustering solution on-\\npremises. \\nAs you can also notice in the diagram, having several API G\", \"ateways allows multiple development \\nteams to be autonomous (in this case Marketing features vs. Sho\", \"pping features) when developing and \\ndeploying their microservices plus their own related API Gatewa\", \"ys. \\nIf you had a single monolithic API Gateway that would mean a single point to be updated by seve\", \"ral \\ndevelopment teams, which could couple all the microservices with a single part of the applicati\", \"on. \\nGoing much further in the design, sometimes a fine-grained API Gateway can also be limited to a\", \" \\nsingle business microservice depending on the chosen architecture. Having the API Gateway\\u2019s \\nbound\", \"aries dictated by the business or domain will help you to get a better design. \\nFor instance, fine g\", \"ranularity in the API Gateway tier can be especially useful for more advanced \\ncomposite UI applicat\", \"ions that are based on microservices, because the concept of a fine-grained API \\nGateway is similar \", \"to a UI composition service. \\nWe delve into more details in the previous section Creating composite \", \"UI based on microservices. \\nAs a key takeaway, for many medium- and large-size applications, using a\", \" custom-built API Gateway \\nproduct is usually a good approach, but not as a single monolithic aggreg\", \"ator or unique central \\ncustom API Gateway unless that API Gateway allows multiple independent confi\", \"guration areas for the \\nseveral development teams creating autonomous microservices. \\n \\n165 \\nCHAPTER\", \" 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nSample mic\", \"roservices/containers to reroute through the API Gateways \\nAs an example, eShopOnContainers has arou\", \"nd six internal microservice-types that have to be \\npublished through the API Gateways, as shown in \", \"the following image. \\n \\nFigure 6-29. Microservice folders in eShopOnContainers solution in Visual St\", \"udio \\nAbout the Identity service, in the design it\\u2019s left out of the API Gateway routing because it\\u2019\", \"s the only \\ncross-cutting concern in the system, although with Ocelot it\\u2019s also possible to include \", \"it as part of the \\nrerouting lists. \\nAll those services are currently implemented as ASP.NET Core We\", \"b API services, as you can tell from \\nthe code. Let\\u2019s focus on one of the microservices like the Cat\", \"alog microservice code. \\n \\nFigure 6-30. Sample Web API microservice (Catalog microservice) \\n \\n166 \\nC\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nYou \", \"can see that the Catalog microservice is a typical ASP.NET Core Web API project with several \\ncontro\", \"llers and methods like in the following code. \\n[HttpGet] \\n[Route(\\\"items/{id:int}\\\")] \\n[ProducesRespon\", \"seType((int)HttpStatusCode.BadRequest)] \\n[ProducesResponseType((int)HttpStatusCode.NotFound)] \\n[Prod\", \"ucesResponseType(typeof(CatalogItem),(int)HttpStatusCode.OK)] \\npublic async Task<IActionResult> GetI\", \"temById(int id) \\n{ \\n    if (id <= 0) \\n    { \\n        return BadRequest(); \\n    } \\n    var item = awa\", \"it _catalogContext.CatalogItems. \\n                                          SingleOrDefaultAsync(ci \", \"=> ci.Id == id); \\n    //\\u2026 \\n \\n    if (item != null) \\n    { \\n        return Ok(item); \\n    } \\n    retu\", \"rn NotFound(); \\n} \\nThe HTTP request will end up running that kind of C# code accessing the microserv\", \"ice database and \\nany additional required action. \\nRegarding the microservice URL, when the containe\", \"rs are deployed in your local development PC \\n(local Docker host), each microservice\\u2019s container alw\", \"ays has an internal port (usually port 80) \\nspecified in its dockerfile, as in the following dockerf\", \"ile: \\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\nWORKDIR /app \\nEXPOSE 80 \\nThe port 80 shown i\", \"n the code is internal within the Docker host, so it can\\u2019t be reached by client apps. \\nClient apps c\", \"an access only the external ports (if any) published when deploying with docker-\\ncompose. \\nThose ext\", \"ernal ports shouldn\\u2019t be published when deploying to a production environment. For this \\nspecific re\", \"ason, why you want to use the API Gateway, to avoid the direct communication between the \\nclient app\", \"s and the microservices. \\nHowever, when developing, you want to access the microservice/container di\", \"rectly and run it through \\nSwagger. That\\u2019s why in eShopOnContainers, the external ports are still sp\", \"ecified even when they won\\u2019t \\nbe used by the API Gateway or the client apps. \\nHere\\u2019s an example of t\", \"he docker-compose.override.yml file for the Catalog microservice: \\ncatalog-api: \\n  environment: \\n   \", \" - ASPNETCORE_ENVIRONMENT=Development \\n    - ASPNETCORE_URLS=http://0.0.0.0:80 \\n    - ConnectionStri\", \"ng=YOUR_VALUE \\n    - ... Other Environment Variables \\n \\n167 \\nCHAPTER 5 | Designing and Developing Mu\", \"lti-Container and Microservice-Based .NET Applications \\n \\n  ports: \\n    - \\\"5101:80\\\"   # Important: I\", \"n a production environment you should remove the external \\nport (5101) kept here for microservice de\", \"bugging purposes. \\n                  # The API Gateway redirects and access through the internal por\", \"t (80). \\nYou can see how in the docker-compose.override.yml configuration the internal port for the \", \"Catalog \\ncontainer is port 80, but the port for external access is 5101. But this port shouldn\\u2019t be \", \"used by the \\napplication when using an API Gateway, only to debug, run, and test just the Catalog mi\", \"croservice. \\nNormally, you won\\u2019t be deploying with docker-compose into a production environment beca\", \"use the \\nright production deployment environment for microservices is an orchestrator like Kubernete\", \"s or \\nService Fabric. When deploying to those environments you use different configuration files whe\", \"re you \\nwon\\u2019t publish directly any external port for the microservices but, you\\u2019ll always use the re\", \"verse proxy \\nfrom the API Gateway. \\nRun the catalog microservice in your local Docker host. Either r\", \"un the full eShopOnContainers solution \\nfrom Visual Studio (it runs all the services in the docker-c\", \"ompose files), or start the Catalog \\nmicroservice with the following docker-compose command in CMD o\", \"r PowerShell positioned at the \\nfolder where the docker-compose.yml and docker-compose.override.yml \", \"are placed. \\ndocker-compose run --service-ports catalog-api \\nThis command only runs the catalog-api \", \"service container plus dependencies that are specified in the \\ndocker-compose.yml. In this case, the\", \" SQL Server container and RabbitMQ container. \\nThen, you can directly access the Catalog microservic\", \"e and see its methods through the Swagger UI \\naccessing directly through that \\u201cexternal\\u201d port, in th\", \"is case http://host.docker.internal:5101/swagger: \\n \\n168 \\nCHAPTER 5 | Designing and Developing Multi\", \"-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-31. Testing the Catalog microservi\", \"ce with its Swagger UI \\nAt this point, you could set a breakpoint in C# code in Visual Studio, test \", \"the microservice with the \\nmethods exposed in Swagger UI, and finally clean-up everything with the d\", \"ocker-compose down \\ncommand. \\nHowever, direct-access communication to the microservice, in this case\", \" through the external port \\n5101, is precisely what you want to avoid in your application. And you c\", \"an avoid that by setting the \\nadditional level of indirection of the API Gateway (Ocelot, in this ca\", \"se). That way, the client app won\\u2019t \\ndirectly access the microservice. \\nImplementing your API Gatewa\", \"ys with Ocelot \\nOcelot is basically a set of middleware that you can apply in a specific order. \\nOce\", \"lot is designed to work with ASP.NET Core only. The latest version of the package is 18.0 which \\ntar\", \"gets .NET 6 and hence is not suitable for .NET Framework applications. \\n \\n169 \\nCHAPTER 5 | Designing\", \" and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nYou install Ocelot and i\", \"ts dependencies in your ASP.NET Core project with Ocelot\\u2019s NuGet package, \\nfrom Visual Studio. \\nInst\", \"all-Package Ocelot \\nIn eShopOnContainers, its API Gateway implementation is a simple ASP.NET Core We\", \"bHost project, \\nand Ocelot\\u2019s middleware handles all the API Gateway features, as shown in the follow\", \"ing image: \\n \\nFigure 6-32. The OcelotApiGw base project in eShopOnContainers \\nThis ASP.NET Core WebH\", \"ost project is built with two simple files: Program.cs and Startup.cs. \\nThe Program.cs just needs to\", \" create and configure the typical ASP.NET Core BuildWebHost. \\nnamespace OcelotApiGw \\n{ \\n    public c\", \"lass Program \\n    { \\n        public static void Main(string[] args) \\n        { \\n            BuildWeb\", \"Host(args).Run(); \\n        } \\n \\n        public static IWebHost BuildWebHost(string[] args) \\n        \", \"{ \\n            var builder = WebHost.CreateDefaultBuilder(args); \\n \\n            builder.ConfigureSer\", \"vices(s => s.AddSingleton(builder)) \\n                    .ConfigureAppConfiguration( \\n              \", \"            ic => ic.AddJsonFile(Path.Combine(\\\"configuration\\\", \\n                                    \", \"                        \\\"configuration.json\\\"))) \\n                    .UseStartup<Startup>(); \\n      \", \"      var host = builder.Build(); \\n            return host; \\n        } \\n    } \\n} \\n \\n170 \\nCHAPTER 5 |\", \" Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nThe important \", \"point here for Ocelot is the configuration.json file that you must provide to the builder \\nthrough t\", \"he AddJsonFile() method. That configuration.json is where you specify all the API Gateway \\nReRoutes,\", \" meaning the external endpoints with specific ports and the correlated internal endpoints, \\nusually \", \"using different ports. \\n{ \\n    \\\"ReRoutes\\\": [], \\n    \\\"GlobalConfiguration\\\": {} \\n} \\nThere are two sect\", \"ions to the configuration. An array of ReRoutes and a GlobalConfiguration. The \\nReRoutes are the obj\", \"ects that tell Ocelot how to treat an upstream request. The Global configuration \\nallows overrides o\", \"f ReRoute specific settings. It\\u2019s useful if you don\\u2019t want to manage lots of ReRoute \\nspecific setti\", \"ngs. \\nHere\\u2019s a simplified example of ReRoute configuration file from one of the API Gateways from \\ne\", \"ShopOnContainers. \\n{ \\n  \\\"ReRoutes\\\": [ \\n    { \\n      \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{every\", \"thing}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"DownstreamHostAndPorts\\\": [ \\n        { \\n         \", \" \\\"Host\\\": \\\"catalog-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/\", \"api/{version}/c/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ] \\n    }, \\n    { \", \"\\n      \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n\", \"      \\\"DownstreamHostAndPorts\\\": [ \\n        { \\n          \\\"Host\\\": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \", \"\\n        } \\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\", \\n      \\\"Upstrea\", \"mHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\n      \\\"AuthenticationOptions\\\": { \\n        \\\"AuthenticationPr\", \"oviderKey\\\": \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\": [] \\n      } \\n    } \\n \\n  ], \\n    \\\"GlobalConfi\", \"guration\\\": { \\n      \\\"RequestIdKey\\\": \\\"OcRequestId\\\", \\n      \\\"AdministrationPath\\\": \\\"/administration\\\" \\n \", \"   } \\n  } \\n \\n171 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET A\", \"pplications \\n \\nThe main functionality of an Ocelot API Gateway is to take incoming HTTP requests and\", \" forward them \\non to a downstream service, currently as another HTTP request. Ocelot\\u2019s describes the\", \" routing of one \\nrequest to another as a ReRoute. \\nFor instance, let\\u2019s focus on one of the ReRoutes \", \"in the configuration.json from above, the \\nconfiguration for the Basket microservice. \\n{ \\n      \\\"Dow\", \"nstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"Down\", \"streamHostAndPorts\\\": [ \\n        { \\n          \\\"Host\\\": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \\n        } \", \"\\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\", \\n      \\\"UpstreamHttpMethod\", \"\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\n      \\\"AuthenticationOptions\\\": { \\n        \\\"AuthenticationProviderKey\\\":\", \" \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\": [] \\n      } \\n} \\nThe DownstreamPathTemplate, Scheme, and\", \" DownstreamHostAndPorts make the internal \\nmicroservice URL that this request will be forwarded to. \", \"\\nThe port is the internal port used by the service. When using containers, the port specified at its\", \" \\ndockerfile. \\nThe Host is a service name that depends on the service name resolution you are using.\", \" When using \\ndocker-compose, the services names are provided by the Docker Host, which is using the \", \"service \\nnames provided in the docker-compose files. If using an orchestrator like Kubernetes or Ser\", \"vice \\nFabric, that name should be resolved by the DNS or name resolution provided by each orchestrat\", \"or. \\nDownstreamHostAndPorts is an array that contains the host and port of any downstream services t\", \"hat \\nyou wish to forward requests to. Usually this configuration will just contain one entry but som\", \"etimes \\nyou might want to load balance requests to your downstream services and Ocelot lets you add \", \"more \\nthan one entry and then select a load balancer. But if using Azure and any orchestrator it is \", \"probably a \\nbetter idea to load balance with the cloud and orchestrator infrastructure. \\nThe Upstrea\", \"mPathTemplate is the URL that Ocelot will use to identify which \\nDownstreamPathTemplate to use for a\", \" given request from the client. Finally, the \\nUpstreamHttpMethod is used so Ocelot can distinguish b\", \"etween different requests (GET, POST, PUT) \\nto the same URL. \\nAt this point, you could have a single\", \" Ocelot API Gateway (ASP.NET Core WebHost) using one or \\nmultiple merged configuration.json files or\", \" you can also store the configuration in a Consul KV store. \\nBut as introduced in the architecture a\", \"nd design sections, if you really want to have autonomous \\nmicroservices, it might be better to spli\", \"t that single monolithic API Gateway into multiple API \\nGateways and/or BFF (Backend for Frontend). \", \"For that purpose, let\\u2019s see how to implement that \\napproach with Docker containers. \\n \\n172 \\nCHAPTER \", \"5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\nUsing a sin\", \"gle Docker container image to run multiple different API Gateway / BFF \\ncontainer types \\nIn eShopOnC\", \"ontainers, we\\u2019re using a single Docker container image with the Ocelot API Gateway but \\nthen, at run\", \" time, we create different services/containers for each type of API-Gateway/BFF by \\nproviding a diff\", \"erent configuration.json file, using a docker volume to access a different PC folder for \\neach servi\", \"ce. \\n \\nFigure 6-33. Reusing a single Ocelot Docker image across multiple API Gateway types \\nIn eShop\", \"OnContainers, the \\u201cGeneric Ocelot API Gateway Docker Image\\u201d is created with the project \\nnamed \\u2018Ocel\", \"otApiGw\\u2019 and the image name \\u201ceshop/ocelotapigw\\u201d that is specified in the docker-\\ncompose.yml file. T\", \"hen, when deploying to Docker, there will be four API-Gateway containers created \\nfrom that same Doc\", \"ker image, as shown in the following extract from the docker-compose.yml file. \\n  mobileshoppingapig\", \"w: \\n    image: eshop/ocelotapigw:${TAG:-latest} \\n \\n173 \\nCHAPTER 5 | Designing and Developing Multi-C\", \"ontainer and Microservice-Based .NET Applications \\n \\n    build: \\n      context: . \\n      dockerfile:\", \" src/ApiGateways/ApiGw-Base/Dockerfile \\n \\n  mobilemarketingapigw: \\n    image: eshop/ocelotapigw:${TA\", \"G:-latest} \\n    build: \\n      context: . \\n      dockerfile: src/ApiGateways/ApiGw-Base/Dockerfile \\n \", \"\\n  webshoppingapigw: \\n    image: eshop/ocelotapigw:${TAG:-latest} \\n    build: \\n      context: . \\n   \", \"   dockerfile: src/ApiGateways/ApiGw-Base/Dockerfile \\n \\n  webmarketingapigw: \\n    image: eshop/ocelo\", \"tapigw:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfile: src/ApiGateways/ApiGw-Base/Do\", \"ckerfile \\nAdditionally, as you can see in the following docker-compose.override.yml file, the only d\", \"ifference \\nbetween those API Gateway containers is the Ocelot configuration file, which is different\", \" for each \\nservice container and it\\u2019s specified at run time through a Docker volume. \\nmobileshopping\", \"apigw: \\n  environment: \\n    - ASPNETCORE_ENVIRONMENT=Development \\n    - IdentityUrl=http://identity-\", \"api \\n  ports: \\n    - \\\"5200:80\\\" \\n  volumes: \\n    - ./src/ApiGateways/Mobile.Bff.Shopping/apigw:/app/c\", \"onfiguration \\n \\nmobilemarketingapigw: \\n  environment: \\n    - ASPNETCORE_ENVIRONMENT=Development \\n   \", \" - IdentityUrl=http://identity-api \\n  ports: \\n    - \\\"5201:80\\\" \\n  volumes: \\n    - ./src/ApiGateways/M\", \"obile.Bff.Marketing/apigw:/app/configuration \\n \\nwebshoppingapigw: \\n  environment: \\n    - ASPNETCORE_\", \"ENVIRONMENT=Development \\n    - IdentityUrl=http://identity-api \\n  ports: \\n    - \\\"5202:80\\\" \\n  volumes\", \": \\n    - ./src/ApiGateways/Web.Bff.Shopping/apigw:/app/configuration \\n \\nwebmarketingapigw: \\n  enviro\", \"nment: \\n    - ASPNETCORE_ENVIRONMENT=Development \\n    - IdentityUrl=http://identity-api \\n  ports: \\n \", \"   - \\\"5203:80\\\" \\n \\n174 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applications \\n \\n  volumes: \\n    - ./src/ApiGateways/Web.Bff.Marketing/apigw:/app/configuration \\n\", \"Because of that previous code, and as shown in the Visual Studio Explorer below, the only file neede\", \"d \\nto define each specific business/BFF API Gateway is just a configuration.json file, because the f\", \"our API \\nGateways are based on the same Docker image. \\n \\nFigure 6-34. The only file needed to define\", \" each API Gateway / BFF with Ocelot is a configuration file \\nBy splitting the API Gateway into multi\", \"ple API Gateways, different development teams focusing on \\ndifferent subsets of microservices can ma\", \"nage their own API Gateways by using independent Ocelot \\nconfiguration files. Plus, at the same time\", \" they can reuse the same Ocelot Docker image. \\nNow, if you run eShopOnContainers with the API Gatewa\", \"ys (included by default in VS when opening \\neShopOnContainers-ServicesAndWebApps.sln solution or if \", \"running \\u201cdocker-compose up\\u201d), the \\nfollowing sample routes will be performed. \\nFor instance, when vi\", \"siting the upstream URL \\nhttp://host.docker.internal:5202/api/v1/c/catalog/items/2/ served by the we\", \"bshoppingapigw API \\nGateway, you get the same result from the internal Downstream URL http://catalog\", \"-api/api/v1/2 \\nwithin the Docker host, as in the following browser. \\n \\nFigure 6-35. Accessing a micr\", \"oservice through a URL provided by the API Gateway \\nBecause of testing or debugging reasons, if you \", \"wanted to directly access to the Catalog Docker \\ncontainer (only at the development environment) wit\", \"hout passing through the API Gateway, since \\n\\u2018catalog-api\\u2019 is a DNS resolution internal to the Docke\", \"r host (service discovery handled by docker-\\ncompose service names), the only way to directly access\", \" the container is through the external port \\npublished in the docker-compose.override.yml, which is \", \"provided only for development tests, such as \\nhttp://host.docker.internal:5101/api/v1/Catalog/items/\", \"1 in the following browser. \\n \\n175 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microse\", \"rvice-Based .NET Applications \\n \\n \\nFigure 6-36. Direct access to a microservice for testing purposes\", \" \\nBut the application is configured so it accesses all the microservices through the API Gateways, n\", \"ot \\nthrough the direct port \\u201cshortcuts\\u201d. \\nThe Gateway aggregation pattern in eShopOnContainers \\nAs i\", \"ntroduced previously, a flexible way to implement requests aggregation is with custom services, by \\n\", \"code. You could also implement request aggregation with the Request Aggregation feature in Ocelot, \\n\", \"but it might not be as flexible as you need. Therefore, the selected way to implement aggregation in\", \" \\neShopOnContainers is with an explicit ASP.NET Core Web API service for each aggregator. \\nAccording\", \" to that approach, the API Gateway composition diagram is in reality a bit more extended \\nwhen consi\", \"dering the aggregator services that are not shown in the simplified global architecture \\ndiagram sho\", \"wn previously. \\nIn the following diagram, you can also see how the aggregator services work with the\", \"ir related API \\nGateways. \\n \\nFigure 6-37. eShopOnContainers architecture with aggregator services \\nZ\", \"ooming in further, on the \\u201cShopping\\u201d business area in the following image, you can see that \\nchattin\", \"ess between the client apps and the microservices is reduced when using the aggregator \\nservices in \", \"the API Gateways. \\n \\n176 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Base\", \"d .NET Applications \\n \\n \\nFigure 6-38. Zoom in vision of the Aggregator services \\nYou can notice how \", \"when the diagram shows the possible requests coming from the API Gateways it \\ncan get complex. On th\", \"e other hand, when you use the aggregator pattern, you can see how the \\narrows in blue would simplif\", \"y the communication from a client app perspective. This pattern not only \\nhelps to reduce the chatti\", \"ness and latency in the communication, it also improves the user experience \\nsignificantly for the r\", \"emote apps (mobile and SPA apps). \\nIn the case of the \\u201cMarketing\\u201d business area and microservices, i\", \"t is a simple use case so there was no \\nneed to use aggregators, but it could also be possible, if n\", \"eeded. \\nAuthentication and authorization in Ocelot API Gateways \\nIn an Ocelot API Gateway, you can s\", \"it the authentication service, such as an ASP.NET Core Web API \\nservice using IdentityServer providi\", \"ng the auth token, either out or inside the API Gateway. \\nSince eShopOnContainers is using multiple \", \"API Gateways with boundaries based on BFF and business \\nareas, the Identity/Auth service is left out\", \" of the API Gateways, as highlighted in yellow in the \\nfollowing diagram. \\n \\n177 \\nCHAPTER 5 | Design\", \"ing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n \\nFigure 6-39. Positi\", \"on of the Identity service in eShopOnContainers \\nHowever, Ocelot also supports sitting the Identity/\", \"Auth microservice within the API Gateway \\nboundary, as in this other diagram. \\n \\nFigure 6-40. Authen\", \"tication in Ocelot \\nAs the previous diagram shows, when the Identity microservice is beneath the API\", \" gateway (AG): 1) AG \\nrequests an auth token from identity microservice, 2) The identity microservic\", \"e returns token to AG, 3-\\n4) AG requests from microservices using the auth token. Because eShopOnCon\", \"tainers application has \\nsplit the API Gateway into multiple BFF (Backend for Frontend) and business\", \" areas API Gateways, \\nanother option would have been to create an additional API Gateway for cross-c\", \"utting concerns. That \\nchoice would be fair in a more complex microservice based architecture with m\", \"ultiple cross-cutting \\nconcerns microservices. Since there\\u2019s only one cross-cutting concern in eShop\", \"OnContainers, it was \\ndecided to just handle the security service out of the API Gateway realm, for \", \"simplicity\\u2019s sake. \\n \\n178 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications \\n \\nIn any case, if the app is secured at the API Gateway level, the authenticat\", \"ion module of the Ocelot \\nAPI Gateway is visited at first when trying to use any secured microservic\", \"e. That redirects the HTTP \\nrequest to visit the Identity or auth microservice to get the access tok\", \"en so you can visit the protected \\nservices with the access_token. \\nThe way you secure with authenti\", \"cation any service at the API Gateway level is by setting the \\nAuthenticationProviderKey in its rela\", \"ted settings at the configuration.json. \\n    { \\n      \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{eve\", \"rything}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"DownstreamHostAndPorts\\\": [ \\n        { \\n       \", \"   \\\"Host\\\": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"\", \"/api/{version}/b/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\": [], \\n      \\\"AuthenticationOptions\\\": { \\n\", \"        \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\": [] \\n      } \\n    } \", \"\\nWhen Ocelot runs, it will look at the ReRoutes AuthenticationOptions.AuthenticationProviderKey and \", \"\\ncheck that there is an Authentication Provider registered with the given key. If there isn\\u2019t, then \", \"Ocelot \\nwill not start up. If there is, then the ReRoute will use that provider when it executes. \\nB\", \"ecause the Ocelot WebHost is configured with the authenticationProviderKey = \\\"IdentityApiKey\\\", \\nthat\", \" will require authentication whenever that service has any requests without any auth token. \\nnamespa\", \"ce OcelotApiGw \\n{ \\n    public class Startup \\n    { \\n        private readonly IConfiguration _cfg; \\n \", \"\\n        public Startup(IConfiguration configuration) => _cfg = configuration; \\n \\n        public voi\", \"d ConfigureServices(IServiceCollection services) \\n        { \\n            var identityUrl = _cfg.GetV\", \"alue<string>(\\\"IdentityUrl\\\"); \\n            var authenticationProviderKey = \\\"IdentityApiKey\\\"; \\n       \", \"                  //\\u2026 \\n            services.AddAuthentication() \\n                .AddJwtBearer(authe\", \"nticationProviderKey, x => \\n                { \\n                    x.Authority = identityUrl; \\n     \", \"               x.RequireHttpsMetadata = false; \\n                    x.TokenValidationParameters = ne\", \"w \\nMicrosoft.IdentityModel.Tokens.TokenValidationParameters() \\n                    { \\n              \", \"          ValidAudiences = new[] { \\\"orders\\\", \\\"basket\\\", \\\"locations\\\", \\n\\\"marketing\\\", \\\"mobileshoppingagg\", \"\\\", \\\"webshoppingagg\\\" } \\n                    }; \\n                }); \\n            //... \\n \\n179 \\nCHAPTE\", \"R 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n \\n        }\", \" \\n    } \\n} \\nThen, you also need to set authorization with the [Authorize] attribute on any resource \", \"to be accessed \\nlike the microservices, such as in the following Basket microservice controller. \\nna\", \"mespace Microsoft.eShopOnContainers.Services.Basket.API.Controllers \\n{ \\n    [Route(\\\"api/v1/[controll\", \"er]\\\")] \\n    [Authorize] \\n    public class BasketController : Controller \\n    { \\n      //... \\n    } \\n\", \"} \\nThe ValidAudiences such as \\u201cbasket\\u201d are correlated with the audience defined in each microservice\", \" \\nwith AddJwtBearer() at the ConfigureServices() of the Startup class, such as in the code below. \\n/\", \"/ prevent from mapping \\\"sub\\\" claim to nameidentifier. \\nJwtSecurityTokenHandler.DefaultInboundClaimTy\", \"peMap.Clear(); \\n \\nvar identityUrl = Configuration.GetValue<string>(\\\"IdentityUrl\\\"); \\n \\nservices.AddAu\", \"thentication(options => \\n{ \\n    options.DefaultAuthenticateScheme = JwtBearerDefaults.Authentication\", \"Scheme; \\n    options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme; \\n \\n}).AddJwtBe\", \"arer(options => \\n{ \\n    options.Authority = identityUrl; \\n    options.RequireHttpsMetadata = false; \", \"\\n    options.Audience = \\\"basket\\\"; \\n}); \\nIf you try to access any secured microservice, like the Bask\", \"et microservice with a ReRoute URL based \\non the API Gateway like http://host.docker.internal:5202/a\", \"pi/v1/b/basket/1, then you\\u2019ll get a 401 \\nUnauthorized unless you provide a valid token. On the other\", \" hand, if a ReRoute URL is authenticated, \\nOcelot will invoke whatever downstream scheme is associat\", \"ed with it (the internal microservice URL). \\nAuthorization at Ocelot\\u2019s ReRoutes tier. Ocelot support\", \"s claims-based authorization evaluated after \\nthe authentication. You set the authorization at a rou\", \"te level by adding the following lines to the \\nReRoute configuration. \\n\\\"RouteClaimsRequirement\\\": { \\n\", \"    \\\"UserType\\\": \\\"employee\\\" \\n} \\nIn that example, when the authorization middleware is called, Ocelot \", \"will find if the user has the claim \\ntype \\u2018UserType\\u2019 in the token and if the value of that claim is \", \"\\u2018employee\\u2019. If it isn\\u2019t, then the user will not \\nbe authorized and the response will be 403 forbidde\", \"n. \\n \\n180 \\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicat\", \"ions \\n \\nUsing Kubernetes Ingress plus Ocelot API Gateways \\nWhen using Kubernetes (like in an Azure K\", \"ubernetes Service cluster), you usually unify all the HTTP \\nrequests through the Kubernetes Ingress \", \"tier based on Nginx. \\nIn Kubernetes, if you don\\u2019t use any ingress approach, then your services and p\", \"ods have IPs only \\nroutable by the cluster network. \\nBut if you use an ingress approach, you\\u2019ll have\", \" a middle tier between the Internet and your services \\n(including your API Gateways), acting as a re\", \"verse proxy. \\nAs a definition, an Ingress is a collection of rules that allow inbound connections to\", \" reach the cluster \\nservices. An ingress is configured to provide services externally reachable URLs\", \", load balance traffic, \\nSSL termination and more. Users request ingress by POSTing the Ingress reso\", \"urce to the API server. \\nIn eShopOnContainers, when developing locally and using just your developme\", \"nt machine as the \\nDocker host, you are not using any ingress but only the multiple API Gateways. \\nH\", \"owever, when targeting a \\u201cproduction\\u201d environment based on Kubernetes, eShopOnContainers is \\nusing a\", \"n ingress in front of the API gateways. That way, the clients still call the same base URL but the \\n\", \"requests are routed to multiple API Gateways or BFF. \\nAPI Gateways are front-ends or fa\\u00e7ades surfaci\", \"ng only the services but not the web applications that \\nare usually out of their scope. In addition,\", \" the API Gateways might hide certain internal microservices. \\nThe ingress, however, is just redirect\", \"ing HTTP requests but not trying to hide any microservice or web \\napp. \\nHaving an ingress Nginx tier\", \" in Kubernetes in front of the web applications plus the several Ocelot API \\nGateways / BFF is the i\", \"deal architecture, as shown in the following diagram. \\n \\nFigure 6-41. The ingress tier in eShopOnCon\", \"tainers when deployed into Kubernetes \\nA Kubernetes Ingress acts as a reverse proxy for all traffic \", \"to the app, including the web applications, \\nthat are out of the Api gateway scope. When you deploy \", \"eShopOnContainers into Kubernetes, it \\n \\n181 \\nCHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET Applications \\n \\nexposes just a few services or endpoints via ingress, bas\", \"ically the following list of postfixes on the \\nURLs: \\n\\u2022 \\n/ for the client SPA web application \\n\\u2022 \\n/w\", \"ebmvc for the client MVC web application \\n\\u2022 \\n/webstatus for the client web app showing the status/he\", \"althchecks \\n\\u2022 \\n/webshoppingapigw for the web BFF and shopping business processes \\n\\u2022 \\n/webmarketingap\", \"igw for the web BFF and marketing business processes \\n\\u2022 \\n/mobileshoppingapigw for the mobile BFF and\", \" shopping business processes \\n\\u2022 \\n/mobilemarketingapigw for the mobile BFF and marketing business pro\", \"cesses \\nWhen deploying to Kubernetes, each Ocelot API Gateway is using a different \\u201cconfiguration.js\", \"on\\u201d file \\nfor each pod running the API Gateways. Those \\u201cconfiguration.json\\u201d files are provided by mo\", \"unting \\n(originally with the deploy.ps1 script) a volume created based on a Kubernetes config map na\", \"med \\n\\u2018ocelot\\u2019. Each container mounts its related configuration file in the container\\u2019s folder named \", \"\\n/app/configuration. \\nIn the source code files of eShopOnContainers, the original \\u201cconfiguration.jso\", \"n\\u201d files can be found \\nwithin the k8s/ocelot/ folder. There\\u2019s one file for each BFF/APIGateway. \\nAdd\", \"itional cross-cutting features in an Ocelot API Gateway \\nThere are other important features to resea\", \"rch and use, when using an Ocelot API Gateway, described \\nin the following links. \\n\\u2022 \\nService discov\", \"ery in the client side integrating Ocelot with Consul or Eureka \\nhttps://ocelot.readthedocs.io/en/la\", \"test/features/servicediscovery.html \\n\\u2022 \\nCaching at the API Gateway tier \\nhttps://ocelot.readthedocs.\", \"io/en/latest/features/caching.html \\n\\u2022 \\nLogging at the API Gateway tier \\nhttps://ocelot.readthedocs.i\", \"o/en/latest/features/logging.html \\n\\u2022 \\nQuality of Service (Retries and Circuit breakers) at the API G\", \"ateway tier \\nhttps://ocelot.readthedocs.io/en/latest/features/qualityofservice.html \\n\\u2022 \\nRate limitin\", \"g \\nhttps://ocelot.readthedocs.io/en/latest/features/ratelimiting.html \\n\\u2022 \\nSwagger for Ocelot \\nhttps:\", \"//github.com/Burgyn/MMLib.SwaggerForOcelot \\n \\n182 \\nCHAPTER 6 | Tackle Business Complexity in a Micro\", \"service with DDD and CQRS Patterns \\n \\nCHAPTER 6 \\nTackle Business \\nComplexity in a \\nMicroservice with\", \" DDD \\nand CQRS Patterns \\nDesign a domain model for each microservice or Bounded Context that reflect\", \"s understanding of the \\nbusiness domain. \\nThis section focuses on more advanced microservices that y\", \"ou implement when you need to tackle \\ncomplex subsystems, or microservices derived from the knowledg\", \"e of domain experts with ever-\\nchanging business rules. The architecture patterns used in this secti\", \"on are based on domain-driven \\ndesign (DDD) and Command and Query Responsibility Segregation (CQRS) \", \"approaches, as illustrated \\nin Figure 7-1. \\n \\n183 \\nCHAPTER 6 | Tackle Business Complexity in a Micro\", \"service with DDD and CQRS Patterns \\n \\n \\nFigure 7-1. External microservice architecture versus intern\", \"al architecture patterns for each microservice \\nHowever, most of the techniques for data driven micr\", \"oservices, such as how to implement an ASP.NET \\nCore Web API service or how to expose Swagger metada\", \"ta with Swashbuckle or NSwag, are also \\napplicable to the more advanced microservices implemented in\", \"ternally with DDD patterns. This \\nsection is an extension of the previous sections, because most of \", \"the practices explained earlier also \\napply here or for any kind of microservice. \\nThis section firs\", \"t provides details on the simplified CQRS patterns used in the eShopOnContainers \\nreference applicat\", \"ion. Later, you will get an overview of the DDD techniques that enable you to find \\ncommon patterns \", \"that you can reuse in your applications. \\nDDD is a large topic with a rich set of resources for lear\", \"ning. You can start with books like Domain-\\nDriven Design by Eric Evans and additional materials fro\", \"m Vaughn Vernon, Jimmy Nilsson, Greg \\nYoung, Udi Dahan, Jimmy Bogard, and many other DDD/CQRS expert\", \"s. But most of all you need to try \\nto learn how to apply DDD techniques from the conversations, whi\", \"teboarding, and domain modeling \\nsessions with the experts in your concrete business domain. \\nAdditi\", \"onal resources \\nDDD (Domain-Driven Design) \\n\\u2022 \\nEric Evans. Domain Language \\nhttps://domainlanguage.c\", \"om/ \\n\\u2022 \\nMartin Fowler. Domain-Driven Design \\nhttps://martinfowler.com/tags/domain%20driven%20design.\", \"html \\n\\u2022 \\nJimmy Bogard. Strengthening your domain: a primer \\nhttps://lostechies.com/jimmybogard/2010/\", \"02/04/strengthening-your-domain-a-primer/ \\n \\n184 \\nCHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns \\n \\nDDD books \\n\\u2022 \\nEric Evans. Domain-Driven Design: Tackling Comple\", \"xity in the Heart of Software \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoft\", \"ware/dp/0321125215/ \\n\\u2022 \\nEric Evans. Domain-Driven Design Reference: Definitions and Pattern Summarie\", \"s \\nhttps://www.amazon.com/Domain-Driven-Design-Reference-Definitions-2014-09-\\n22/dp/B01N8YB4ZO/ \\n\\u2022 \\n\", \"Vaughn Vernon. Implementing Domain-Driven Design \\nhttps://www.amazon.com/Implementing-Domain-Driven-\", \"Design-Vaughn-\\nVernon/dp/0321834577/ \\n\\u2022 \\nVaughn Vernon. Domain-Driven Design Distilled \\nhttps://www.\", \"amazon.com/Domain-Driven-Design-Distilled-Vaughn-Vernon/dp/0134434420/ \\n\\u2022 \\nJimmy Nilsson. Applying D\", \"omain-Driven Design and Patterns \\nhttps://www.amazon.com/Applying-Domain-Driven-Design-Patterns-\\nExa\", \"mples/dp/0321268202/ \\n\\u2022 \\nCesar de la Torre. N-Layered Domain-Oriented Architecture Guide with .NET \\n\", \"https://www.amazon.com/N-Layered-Domain-Oriented-Architecture-Guide-\\nNET/dp/8493903612/ \\n\\u2022 \\nAbel Avr\", \"am and Floyd Marinescu. Domain-Driven Design Quickly \\nhttps://www.amazon.com/Domain-Driven-Design-Qu\", \"ickly-Abel-Avram/dp/1411609255/ \\n\\u2022 \\nScott Millett, Nick Tune - Patterns, Principles, and Practices o\", \"f Domain-Driven Design \\nhttps://www.wiley.com/Patterns%2C+Principles%2C+and+Practices+of+Domain+Driv\", \"en+Des\\nign-p-9781118714706 \\nDDD training \\n\\u2022 \\nJulie Lerman and Steve Smith. Domain-Driven Design Fund\", \"amentals \\nhttps://www.pluralsight.com/courses/fundamentals-domain-driven-design \\nApply simplified CQ\", \"RS and DDD patterns in a \\nmicroservice \\nCQRS is an architectural pattern that separates the models f\", \"or reading and writing data. The related \\nterm Command Query Separation (CQS) was originally defined\", \" by Bertrand Meyer in his book Object-\\nOriented Software Construction. The basic idea is that you ca\", \"n divide a system\\u2019s operations into two \\nsharply separated categories: \\n\\u2022 \\nQueries. These queries re\", \"turn a result and don\\u2019t change the state of the system, and they\\u2019re \\nfree of side effects. \\n\\u2022 \\nComma\", \"nds. These commands change the state of a system. \\n \\n185 \\nCHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns \\n \\nCQS is a simple concept: it is about methods within the\", \" same object being either queries or \\ncommands. Each method either returns state or mutates state, b\", \"ut not both. Even a single repository \\npattern object can comply with CQS. CQS can be considered a f\", \"oundational principle for CQRS. \\nCommand and Query Responsibility Segregation (CQRS) was introduced \", \"by Greg Young and strongly \\npromoted by Udi Dahan and others. It\\u2019s based on the CQS principle, altho\", \"ugh it\\u2019s more detailed. It can \\nbe considered a pattern based on commands and events plus optionally\", \" on asynchronous messages. \\nIn many cases, CQRS is related to more advanced scenarios, like having a\", \" different physical database \\nfor reads (queries) than for writes (updates). Moreover, a more evolve\", \"d CQRS system might \\nimplement Event-Sourcing (ES) for your updates database, so you would only stor\", \"e events in the \\ndomain model instead of storing the current-state data. However, this approach is n\", \"ot used in this \\nguide. This guide uses the simplest CQRS approach, which consists of just separatin\", \"g the queries from \\nthe commands. \\nThe separation aspect of CQRS is achieved by grouping query opera\", \"tions in one layer and commands \\nin another layer. Each layer has its own data model (note that we s\", \"ay model, not necessarily a different \\ndatabase) and is built using its own combination of patterns \", \"and technologies. More importantly, the \\ntwo layers can be within the same tier or microservice, as \", \"in the example (ordering microservice) used \\nfor this guide. Or they could be implemented on differe\", \"nt microservices or processes so they can be \\noptimized and scaled out separately without affecting \", \"one another. \\nCQRS means having two objects for a read/write operation where in other contexts there\", \"\\u2019s one. There \\nare reasons to have a denormalized reads database, which you can learn about in more \", \"advanced \\nCQRS literature. But we aren\\u2019t using that approach here, where the goal is to have more fl\", \"exibility in \\nthe queries instead of limiting the queries with constraints from DDD patterns like ag\", \"gregates. \\nAn example of this kind of service is the ordering microservice from the eShopOnContainer\", \"s reference \\napplication. This service implements a microservice based on a simplified CQRS approach\", \". It uses a \\nsingle data source or database, but two logical models plus DDD patterns for the transa\", \"ctional \\ndomain, as shown in Figure 7-2. \\n \\n186 \\nCHAPTER 6 | Tackle Business Complexity in a Microse\", \"rvice with DDD and CQRS Patterns \\n \\n \\nFigure 7-2. Simplified CQRS- and DDD-based microservice \\nThe L\", \"ogical \\u201cOrdering\\u201d Microservice includes its Ordering database, which can be, but doesn\\u2019t have to \\nbe\", \", the same Docker host. Having the database in the same Docker host is good for development, but \\nno\", \"t for production. \\nThe application layer can be the Web API itself. The important design aspect here\", \" is that the \\nmicroservice has split the queries and ViewModels (data models especially created for \", \"the client \\napplications) from the commands, domain model, and transactions following the CQRS patte\", \"rn. This \\napproach keeps the queries independent from restrictions and constraints coming from DDD p\", \"atterns \\nthat only make sense for transactions and updates, as explained in later sections. \\nAdditio\", \"nal resources \\n\\u2022 \\nGreg Young. Versioning in an Event Sourced System (Free to read online e-book) \\nht\", \"tps://leanpub.com/esversioning/read \\nApply CQRS and CQS approaches in a DDD \\nmicroservice in eShopOn\", \"Containers \\nThe design of the ordering microservice at the eShopOnContainers reference application i\", \"s based on \\nCQRS principles. However, it uses the simplest approach, which is just separating the qu\", \"eries from the \\ncommands and using the same database for both actions. \\nThe essence of those pattern\", \"s, and the important point here, is that queries are idempotent: no matter \\nhow many times you query\", \" a system, the state of that system won\\u2019t change. In other words, queries \\nare side-effect free. \\n \\n\", \"187 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nTherefor\", \"e, you could use a different \\u201creads\\u201d data model than the transactional logic \\u201cwrites\\u201d domain \\nmodel,\", \" even though the ordering microservices are using the same database. Hence, this is a \\nsimplified CQ\", \"RS approach. \\nOn the other hand, commands, which trigger transactions and data updates, change state\", \" in the \\nsystem. With commands, you need to be careful when dealing with complexity and ever-changin\", \"g \\nbusiness rules. This is where you want to apply DDD techniques to have a better modeled system. \\n\", \"The DDD patterns presented in this guide should not be applied universally. They introduce \\nconstrai\", \"nts on your design. Those constraints provide benefits such as higher quality over time, \\nespecially\", \" in commands and other code that modifies system state. However, those constraints add \\ncomplexity w\", \"ith fewer benefits for reading and querying data. \\nOne such pattern is the Aggregate pattern, which \", \"we examine more in later sections. Briefly, in the \\nAggregate pattern, you treat many domain objects\", \" as a single unit as a result of their relationship in \\nthe domain. You might not always gain advant\", \"ages from this pattern in queries; it can increase the \\ncomplexity of query logic. For read-only que\", \"ries, you do not get the advantages of treating multiple \\nobjects as a single Aggregate. You only ge\", \"t the complexity. \\nAs shown in Figure 7-2 in the previous section, this guide suggests using DDD pat\", \"terns only in the \\ntransactional/updates area of your microservice (that is, as triggered by command\", \"s). Queries can \\nfollow a simpler approach and should be separated from commands, following a CQRS a\", \"pproach. \\nFor implementing the \\u201cqueries side\\u201d, you can choose between many approaches, from your ful\", \"l-blown \\nORM like EF Core, AutoMapper projections, stored procedures, views, materialized views or a\", \" micro \\nORM. \\nIn this guide and in eShopOnContainers (specifically the ordering microservice) we cho\", \"se to \\nimplement straight queries using a micro ORM like Dapper. This guide lets you implement any q\", \"uery \\nbased on SQL statements to get the best performance, thanks to a light framework with little \\n\", \"overhead. \\nWhen you use this approach, any updates to your model that impact how entities are persis\", \"ted to a \\nSQL database also need separate updates to SQL queries used by Dapper or any other separat\", \"e (non-\\nEF) approaches to querying. \\nCQRS and DDD patterns are not top-level architectures \\nIt\\u2019s imp\", \"ortant to understand that CQRS and most DDD patterns (like DDD layers or a domain model \\nwith aggreg\", \"ates) are not architectural styles, but only architecture patterns. Microservices, SOA, and \\nevent-d\", \"riven architecture (EDA) are examples of architectural styles. They describe a system of many \\ncompo\", \"nents, such as many microservices. CQRS and DDD patterns describe something inside a single \\nsystem \", \"or component; in this case, something inside a microservice. \\nDifferent Bounded Contexts (BCs) will \", \"employ different patterns. They have different responsibilities, \\nand that leads to different soluti\", \"ons. It is worth emphasizing that forcing the same pattern everywhere \\nleads to failure. Do not use \", \"CQRS and DDD patterns everywhere. Many subsystems, BCs, or \\nmicroservices are simpler and can be imp\", \"lemented more easily using simple CRUD services or using \\nanother approach. \\n \\n188 \\nCHAPTER 6 | Tack\", \"le Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nThere is only one application\", \" architecture: the architecture of the system or end-to-end application \\nyou are designing (for exam\", \"ple, the microservices architecture). However, the design of each Bounded \\nContext or microservice w\", \"ithin that application reflects its own tradeoffs and internal design decisions \\nat an architecture \", \"patterns level. Do not try to apply the same architectural patterns as CQRS or DDD \\neverywhere. \\nAdd\", \"itional resources \\n\\u2022 \\nMartin Fowler. CQRS \\nhttps://martinfowler.com/bliki/CQRS.html \\n\\u2022 \\nGreg Young. \", \"CQRS Documents \\nhttps://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf \\n\\u2022 \\nUdi Dahan. Clarified\", \" CQRS \\nhttps://udidahan.com/2009/12/09/clarified-cqrs/ \\nImplement reads/queries in a CQRS microservi\", \"ce \\nFor reads/queries, the ordering microservice from the eShopOnContainers reference application \\ni\", \"mplements the queries independently from the DDD model and transactional area. This \\nimplementation \", \"was done primarily because the demands for queries and for transactions are \\ndrastically different. \", \"Writes execute transactions that must be compliant with the domain logic. \\nQueries, on the other han\", \"d, are idempotent and can be segregated from the domain rules. \\nThe approach is simple, as shown in \", \"Figure 7-3. The API interface is implemented by the Web API \\ncontrollers using any infrastructure, s\", \"uch as a micro Object Relational Mapper (ORM) like Dapper, and \\nreturning dynamic ViewModels dependi\", \"ng on the needs of the UI applications. \\n \\nFigure 7-3. The simplest approach for queries in a CQRS m\", \"icroservice \\nThe simplest approach for the queries-side in a simplified CQRS approach can be impleme\", \"nted by \\nquerying the database with a Micro-ORM like Dapper, returning dynamic ViewModels. The query\", \" \\n \\n189 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\ndefi\", \"nitions query the database and return a dynamic ViewModel built on the fly for each query. Since \\nth\", \"e queries are idempotent, they won\\u2019t change the data no matter how many times you run a query. \\nTher\", \"efore, you don\\u2019t need to be restricted by any DDD pattern used in the transactional side, like \\naggr\", \"egates and other patterns, and that is why queries are separated from the transactional area. You \\nq\", \"uery the database for the data that the UI needs and return a dynamic ViewModel that does not \\nneed \", \"to be statically defined anywhere (no classes for the ViewModels) except in the SQL statements \\nthem\", \"selves. \\nSince this approach is simple, the code required for the queries side (such as code using a\", \" micro ORM \\nlike Dapper) can be implemented within the same Web API project. Figure 7-4 shows this a\", \"pproach. \\nThe queries are defined in the Ordering.API microservice project within the eShopOnContain\", \"ers \\nsolution. \\n \\nFigure 7-4. Queries in the Ordering microservice in eShopOnContainers \\nUse ViewMod\", \"els specifically made for client apps, independent from \\ndomain model constraints \\nSince the queries\", \" are performed to obtain the data needed by the client applications, the returned \\ntype can be speci\", \"fically made for the clients, based on the data returned by the queries. These models, \\nor Data Tran\", \"sfer Objects (DTOs), are called ViewModels. \\nThe returned data (ViewModel) can be the result of join\", \"ing data from multiple entities or tables in the \\ndatabase, or even across multiple aggregates defin\", \"ed in the domain model for the transactional area. \\nIn this case, because you are creating queries i\", \"ndependent of the domain model, the aggregates \\nboundaries and constraints are ignored and you\\u2019re fr\", \"ee to query any table and column you might \\nneed. This approach provides great flexibility and produ\", \"ctivity for the developers creating or updating \\nthe queries. \\nThe ViewModels can be static types de\", \"fined in classes (as is implemented in the ordering \\nmicroservice). Or they can be created dynamical\", \"ly based on the queries performed, which is agile for \\ndevelopers. \\nUse Dapper as a micro ORM to per\", \"form queries \\nYou can use any micro ORM, Entity Framework Core, or even plain ADO.NET for querying. \", \"In the \\nsample application, Dapper was selected for the ordering microservice in eShopOnContainers a\", \"s a \\ngood example of a popular micro ORM. It can run plain SQL queries with great performance, becau\", \"se \\nit\\u2019s a light framework. Using Dapper, you can write a SQL query that can access and join multipl\", \"e \\ntables. \\n \\n190 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patter\", \"ns \\n \\nDapper is an open-source project (original created by Sam Saffron), and is part of the buildin\", \"g blocks \\nused in Stack Overflow. To use Dapper, you just need to install it through the Dapper NuGe\", \"t package, \\nas shown in the following figure: \\n \\nYou also need to add a using directive so your code\", \" has access to the Dapper extension methods. \\nWhen you use Dapper in your code, you directly use the\", \" SqlConnection class available in the \\nMicrosoft.Data.SqlClient namespace. Through the QueryAsync me\", \"thod and other extension methods \\nthat extend the SqlConnection class, you can run queries in a stra\", \"ightforward and performant way. \\nDynamic versus static ViewModels \\nWhen returning ViewModels from th\", \"e server-side to client apps, you can think about those \\nViewModels as DTOs (Data Transfer Objects) \", \"that can be different to the internal domain entities of \\nyour entity model because the ViewModels h\", \"old the data the way the client app needs. Therefore, in \\nmany cases, you can aggregate data coming \", \"from multiple domain entities and compose the \\nViewModels precisely according to how the client app \", \"needs that data. \\nThose ViewModels or DTOs can be defined explicitly (as data holder classes), like \", \"the OrderSummary \\nclass shown in a later code snippet. Or, you could just return dynamic ViewModels \", \"or dynamic DTOs \\nbased on the attributes returned by your queries as a dynamic type. \\nViewModel as d\", \"ynamic type \\nAs shown in the following code, a ViewModel can be directly returned by the queries by \", \"just returning \\na dynamic type that internally is based on the attributes returned by a query. That \", \"means that the \\nsubset of attributes to be returned is based on the query itself. Therefore, if you \", \"add a new column to \\nthe query or join, that data is dynamically added to the returned ViewModel. \\nu\", \"sing Dapper; \\nusing Microsoft.Extensions.Configuration; \\nusing System.Data.SqlClient; \\nusing System.\", \"Threading.Tasks; \\nusing System.Dynamic; \\nusing System.Collections.Generic; \\n \\npublic class OrderQuer\", \"ies : IOrderQueries \\n{ \\n    public async Task<IEnumerable<dynamic>> GetOrdersAsync() \\n    { \\n       \", \" using (var connection = new SqlConnection(_connectionString)) \\n        { \\n            connection.Op\", \"en(); \\n            return await connection.QueryAsync<dynamic>( \\n                @\\\"SELECT o.[Id] as \", \"ordernumber, \\n                o.[OrderDate] as [date],os.[Name] as [status], \\n                SUM(oi\", \".units*oi.unitprice) as total \\n                FROM [ordering].[Orders] o \\n                LEFT JOIN\", \"[ordering].[orderitems] oi ON o.Id = oi.orderid \\n                LEFT JOIN[ordering].[orderstatus] o\", \"s on o.OrderStatusId = os.Id \\n \\n191 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with D\", \"DD and CQRS Patterns \\n \\n                GROUP BY o.[Id], o.[OrderDate], os.[Name]\\\"); \\n        } \\n   \", \" } \\n} \\nThe important point is that by using a dynamic type, the returned collection of data is dynam\", \"ically \\nassembled as the ViewModel. \\nPros: This approach reduces the need to modify static ViewModel\", \" classes whenever you update the \\nSQL sentence of a query, making this design approach agile when co\", \"ding, straightforward, and quick \\nto evolve in regard to future changes. \\nCons: In the long term, dy\", \"namic types can negatively impact the clarity and the compatibility of a \\nservice with client apps. \", \"In addition, middleware software like Swashbuckle cannot provide the same \\nlevel of documentation on\", \" returned types if using dynamic types. \\nViewModel as predefined DTO classes \\nPros: Having static, p\", \"redefined ViewModel classes, like \\u201ccontracts\\u201d based on explicit DTO classes, is \\ndefinitely better f\", \"or public APIs but also for long-term microservices, even if they are only used by the \\nsame applica\", \"tion. \\nIf you want to specify response types for Swagger, you need to use explicit DTO classes as th\", \"e return \\ntype. Therefore, predefined DTO classes allow you to offer richer information from Swagger\", \". That \\nimproves the API documentation and compatibility when consuming an API. \\nCons: As mentioned \", \"earlier, when updating the code, it takes some more steps to update the DTO \\nclasses. \\nTip based on \", \"our experience: In the queries implemented at the Ordering microservice in \\neShopOnContainers, we st\", \"arted developing by using dynamic ViewModels as it was straightforward \\nand agile on the early devel\", \"opment stages. But, once the development was stabilized, we chose to \\nrefactor the APIs and use stat\", \"ic or pre-defined DTOs for the ViewModels, because it is clearer for the \\nmicroservice\\u2019s consumers t\", \"o know explicit DTO types, used as \\u201ccontracts\\u201d. \\nIn the following example, you can see how the query\", \" is returning data by using an explicit ViewModel \\nDTO class: the OrderSummary class. \\nusing Dapper;\", \" \\nusing Microsoft.Extensions.Configuration; \\nusing System.Data.SqlClient; \\nusing System.Threading.Ta\", \"sks; \\nusing System.Dynamic; \\nusing System.Collections.Generic; \\n \\npublic class OrderQueries : IOrder\", \"Queries \\n{ \\n  public async Task<IEnumerable<OrderSummary>> GetOrdersAsync() \\n    { \\n        using (v\", \"ar connection = new SqlConnection(_connectionString)) \\n        { \\n            connection.Open(); \\n  \", \"          return await connection.QueryAsync<OrderSummary>( \\n                  @\\\"SELECT o.[Id] as or\", \"dernumber, \\n                  o.[OrderDate] as [date],os.[Name] as [status], \\n \\n192 \\nCHAPTER 6 | Tac\", \"kle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n                  SUM(oi.uni\", \"ts*oi.unitprice) as total \\n                  FROM [ordering].[Orders] o \\n                  LEFT JOIN\", \"[ordering].[orderitems] oi ON  o.Id = oi.orderid \\n                  LEFT JOIN[ordering].[orderstatus\", \"] os on o.OrderStatusId = os.Id \\n                  GROUP BY o.[Id], o.[OrderDate], os.[Name] \\n      \", \"            ORDER BY o.[Id]\\\"); \\n        } \\n    } \\n} \\nDescribe response types of Web APIs \\nDevelopers\", \" consuming web APIs and microservices are most concerned with what is returned\\u2014\\nspecifically respons\", \"e types and error codes (if not standard). The response types are handled in the \\nXML comments and d\", \"ata annotations. \\nWithout proper documentation in the Swagger UI, the consumer lacks knowledge of wh\", \"at types are \\nbeing returned or what HTTP codes can be returned. That problem is fixed by adding the\", \" \\nMicrosoft.AspNetCore.Mvc.ProducesResponseTypeAttribute, so Swashbuckle can generate richer \\ninform\", \"ation about the API return model and values, as shown in the following code: \\nnamespace Microsoft.eS\", \"hopOnContainers.Services.Ordering.API.Controllers \\n{ \\n    [Route(\\\"api/v1/[controller]\\\")] \\n    [Autho\", \"rize] \\n    public class OrdersController : Controller \\n    { \\n        //Additional code... \\n        \", \"[Route(\\\"\\\")] \\n        [HttpGet] \\n        [ProducesResponseType(typeof(IEnumerable<OrderSummary>), \\n  \", \"          (int)HttpStatusCode.OK)] \\n        public async Task<IActionResult> GetOrders() \\n        { \", \"\\n            var userid = _identityService.GetUserIdentity(); \\n            var orders = await _order\", \"Queries \\n                .GetOrdersFromUserAsync(Guid.Parse(userid)); \\n            return Ok(orders)\", \"; \\n        } \\n    } \\n} \\nHowever, the ProducesResponseType attribute cannot use dynamic as a type but\", \" requires to use \\nexplicit types, like the OrderSummary ViewModel DTO, shown in the following exampl\", \"e: \\npublic class OrderSummary \\n{ \\n    public int ordernumber { get; set; } \\n    public DateTime date\", \" { get; set; } \\n    public string status { get; set; } \\n    public double total { get; set; } \\n} \\n//\", \" or using C# 8 record types: \\npublic record OrderSummary(int ordernumber, DateTime date, string stat\", \"us, double total); \\n \\n193 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S Patterns \\n \\nThis is another reason why explicit returned types are better than dynamic types, in t\", \"he long term. \\nWhen using the ProducesResponseType attribute, you can also specify what is the expec\", \"ted outcome \\nregarding possible HTTP errors/codes, like 200, 400, etc. \\nIn the following image, you \", \"can see how Swagger UI shows the ResponseType information. \\n \\nFigure 7-5. Swagger UI showing respons\", \"e types and possible HTTP status codes from a Web API \\nThe image shows some example values based on \", \"the ViewModel types and the possible HTTP status \\ncodes that can be returned. \\nAdditional resources \", \"\\n\\u2022 \\nDapper \\nhttps://github.com/StackExchange/dapper-dot-net \\n\\u2022 \\nJulie Lerman. Data Points - Dapper, \", \"Entity Framework and Hybrid Apps (MSDN \\nmagazine article) \\n \\n194 \\nCHAPTER 6 | Tackle Business Comple\", \"xity in a Microservice with DDD and CQRS Patterns \\n \\nhttps://learn.microsoft.com/archive/msdn-magazi\", \"ne/2016/may/data-points-dapper-entity-\\nframework-and-hybrid-apps \\n\\u2022 \\nASP.NET Core Web API Help Pages\", \" using Swagger \\nhttps://learn.microsoft.com/aspnet/core/tutorials/web-api-help-pages-using-\\nswagger?\", \"tabs=visual-studio \\n\\u2022 \\nCreate record types https://learn.microsoft.com/dotnet/csharp/whats-new/tutor\", \"ials/records \\nDesign a DDD-oriented microservice \\nDomain-driven design (DDD) advocates modeling base\", \"d on the reality of business as relevant to your \\nuse cases. In the context of building applications\", \", DDD talks about problems as domains. It describes \\nindependent problem areas as Bounded Contexts (\", \"each Bounded Context correlates to a \\nmicroservice), and emphasizes a common language to talk about \", \"these problems. It also suggests \\nmany technical concepts and patterns, like domain entities with ri\", \"ch models (no anemic-domain \\nmodel), value objects, aggregates, and aggregate root (or root entity) \", \"rules to support the internal \\nimplementation. This section introduces the design and implementation\", \" of those internal patterns. \\nSometimes these DDD technical rules and patterns are perceived as obst\", \"acles that have a steep \\nlearning curve for implementing DDD approaches. But the important part is n\", \"ot the patterns \\nthemselves, but organizing the code so it is aligned to the business problems, and \", \"using the same \\nbusiness terms (ubiquitous language). In addition, DDD approaches should be applied \", \"only if you are \\nimplementing complex microservices with significant business rules. Simpler respons\", \"ibilities, like a \\nCRUD service, can be managed with simpler approaches. \\nWhere to draw the boundari\", \"es is the key task when designing and defining a microservice. DDD \\npatterns help you understand the\", \" complexity in the domain. For the domain model for each Bounded \\nContext, you identify and define t\", \"he entities, value objects, and aggregates that model your domain. \\nYou build and refine a domain mo\", \"del that is contained within a boundary that defines your context. \\nAnd that is explicit in the form\", \" of a microservice. The components within those boundaries end up \\nbeing your microservices, althoug\", \"h in some cases a BC or business microservices can be composed of \\nseveral physical services. DDD is\", \" about boundaries and so are microservices. \\nKeep the microservice context boundaries relatively sma\", \"ll \\nDetermining where to place boundaries between Bounded Contexts balances two competing goals. \\nFi\", \"rst, you want to initially create the smallest possible microservices, although that should not be t\", \"he \\nmain driver; you should create a boundary around things that need cohesion. Second, you want to \", \"\\navoid chatty communications between microservices. These goals can contradict one another. You \\nsho\", \"uld balance them by decomposing the system into as many small microservices as you can until \\nyou se\", \"e communication boundaries growing quickly with each additional attempt to separate a new \\nBounded C\", \"ontext. Cohesion is key within a single bounded context. \\nIt is similar to the Inappropriate Intimac\", \"y code smell when implementing classes. If two microservices \\nneed to collaborate a lot with each ot\", \"her, they should probably be the same microservice. \\n \\n195 \\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n \\nAnother way to look at this aspect is autonomy. If a \", \"microservice must rely on another service to \\ndirectly service a request, it is not truly autonomous\", \". \\nLayers in DDD microservices \\nMost enterprise applications with significant business and technical\", \" complexity are defined by \\nmultiple layers. The layers are a logical artifact, and are not related \", \"to the deployment of the service. \\nThey exist to help developers manage the complexity in the code. \", \"Different layers (like the domain \\nmodel layer versus the presentation layer, etc.) might have diffe\", \"rent types, which mandate translations \\nbetween those types. \\nFor example, an entity could be loaded\", \" from the database. Then part of that information, or an \\naggregation of information including addit\", \"ional data from other entities, can be sent to the client UI \\nthrough a REST Web API. The point here\", \" is that the domain entity is contained within the domain \\nmodel layer and should not be propagated \", \"to other areas that it does not belong to, like to the \\npresentation layer. \\nAdditionally, you need \", \"to have always-valid entities (see the Designing validations in the domain \\nmodel layer section) con\", \"trolled by aggregate roots (root entities). Therefore, entities should not be \\nbound to client views\", \", because at the UI level some data might still not be validated. This reason is \\nwhat the ViewModel\", \" is for. The ViewModel is a data model exclusively for presentation layer needs. \\nThe domain entitie\", \"s do not belong directly to the ViewModel. Instead, you need to translate between \\nViewModels and do\", \"main entities and vice versa. \\nWhen tackling complexity, it is important to have a domain model cont\", \"rolled by aggregate roots that \\nmake sure that all the invariants and rules related to that group of\", \" entities (aggregate) are performed \\nthrough a single entry-point or gate, the aggregate root. \\nFigu\", \"re 7-5 shows how a layered design is implemented in the eShopOnContainers application. \\n \\n196 \\nCHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n \\nFigure 7-5. DDD \", \"layers in the ordering microservice in eShopOnContainers \\nThe three layers in a DDD microservice lik\", \"e Ordering. Each layer is a VS project: Application layer is \\nOrdering.API, Domain layer is Ordering\", \".Domain and the Infrastructure layer is Ordering.Infrastructure. \\nYou want to design the system so t\", \"hat each layer communicates only with certain other layers. That \\napproach may be easier to enforce \", \"if layers are implemented as different class libraries, because you \\ncan clearly identify what depen\", \"dencies are set between libraries. For instance, the domain model layer \\nshould not take a dependenc\", \"y on any other layer (the domain model classes should be Plain Old Class \\nObjects, or POCO, classes)\", \". As shown in Figure 7-6, the Ordering.Domain layer library has \\ndependencies only on the .NET libra\", \"ries or NuGet packages, but not on any other custom library, such \\nas data library or persistence li\", \"brary. \\n \\nFigure 7-6. Layers implemented as libraries allow better control of dependencies between l\", \"ayers \\nThe domain model layer \\nEric Evans\\u2019s excellent book Domain Driven Design says the following a\", \"bout the domain model layer \\nand the application layer. \\nDomain Model Layer: Responsible for represe\", \"nting concepts of the business, information about the \\nbusiness situation, and business rules. State\", \" that reflects the business situation is controlled and used \\nhere, even though the technical detail\", \"s of storing it are delegated to the infrastructure. This layer is \\nthe heart of business software. \", \"\\n \\n197 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nThe d\", \"omain model layer is where the business is expressed. When you implement a microservice \\ndomain mode\", \"l layer in .NET, that layer is coded as a class library with the domain entities that capture \\ndata \", \"plus behavior (methods with logic). \\nFollowing the Persistence Ignorance and the Infrastructure Igno\", \"rance principles, this layer must \\ncompletely ignore data persistence details. These persistence tas\", \"ks should be performed by the \\ninfrastructure layer. Therefore, this layer should not take direct de\", \"pendencies on the infrastructure, \\nwhich means that an important rule is that your domain model enti\", \"ty classes should be POCOs. \\nDomain entities should not have any direct dependency (like deriving fr\", \"om a base class) on any data \\naccess infrastructure framework like Entity Framework or NHibernate. I\", \"deally, your domain entities \\nshould not derive from or implement any type defined in any infrastruc\", \"ture framework. \\nMost modern ORM frameworks like Entity Framework Core allow this approach, so that \", \"your domain \\nmodel classes are not coupled to the infrastructure. However, having POCO entities is n\", \"ot always \\npossible when using certain NoSQL databases and frameworks, like Actors and Reliable Coll\", \"ections in \\nAzure Service Fabric. \\nEven when it is important to follow the Persistence Ignorance pri\", \"nciple for your Domain model, you \\nshould not ignore persistence concerns. It is still important to \", \"understand the physical data model and \\nhow it maps to your entity object model. Otherwise you can c\", \"reate impossible designs. \\nAlso, this aspect does not mean you can take a model designed for a relat\", \"ional database and directly \\nmove it to a NoSQL or document-oriented database. In some entity models\", \", the model might fit, but \\nusually it does not. There are still constraints that your entity model \", \"must adhere to, based both on \\nthe storage technology and ORM technology. \\nThe application layer \\nMo\", \"ving on to the application layer, we can again cite Eric Evans\\u2019s book Domain Driven Design: \\nApplica\", \"tion Layer: Defines the jobs the software is supposed to do and directs the expressive domain \\nobjec\", \"ts to work out problems. The tasks this layer is responsible for are meaningful to the business or \\n\", \"necessary for interaction with the application layers of other systems. This layer is kept thin. It \", \"does \\nnot contain business rules or knowledge, but only coordinates tasks and delegates work to \\ncol\", \"laborations of domain objects in the next layer down. It does not have state reflecting the business\", \" \\nsituation, but it can have state that reflects the progress of a task for the user or the program.\", \" \\nA microservice\\u2019s application layer in .NET is commonly coded as an ASP.NET Core Web API project. \\n\", \"The project implements the microservice\\u2019s interaction, remote network access, and the external Web \\n\", \"APIs used from the UI or client apps. It includes queries if using a CQRS approach, commands \\naccept\", \"ed by the microservice, and even the event-driven communication between microservices \\n(integration \", \"events). The ASP.NET Core Web API that represents the application layer must not contain \\nbusiness r\", \"ules or domain knowledge (especially domain rules for transactions or updates); these \\nshould be own\", \"ed by the domain model class library. The application layer must only coordinate tasks \\nand must not\", \" hold or define any domain state (domain model). It delegates the execution of business \\nrules to th\", \"e domain model classes themselves (aggregate roots and domain entities), which will \\nultimately upda\", \"te the data within those domain entities. \\n \\n198 \\nCHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns \\n \\nBasically, the application logic is where you implement all use\", \" cases that depend on a given front end. \\nFor example, the implementation related to a Web API servi\", \"ce. \\nThe goal is that the domain logic in the domain model layer, its invariants, the data model, an\", \"d \\nrelated business rules must be completely independent from the presentation and application layer\", \"s. \\nMost of all, the domain model layer must not directly depend on any infrastructure framework. \\nT\", \"he infrastructure layer \\nThe infrastructure layer is how the data that is initially held in domain e\", \"ntities (in memory) is persisted \\nin databases or another persistent store. An example is using Enti\", \"ty Framework Core code to \\nimplement the Repository pattern classes that use a DBContext to persist \", \"data in a relational \\ndatabase. \\nIn accordance with the previously mentioned Persistence Ignorance a\", \"nd Infrastructure Ignorance \\nprinciples, the infrastructure layer must not \\u201ccontaminate\\u201d the domain \", \"model layer. You must keep the \\ndomain model entity classes agnostic from the infrastructure that yo\", \"u use to persist data (EF or any \\nother framework) by not taking hard dependencies on frameworks. Yo\", \"ur domain model layer class \\nlibrary should have only your domain code, just POCO entity classes imp\", \"lementing the heart of your \\nsoftware and completely decoupled from infrastructure technologies. \\nTh\", \"us, your layers or class libraries and projects should ultimately depend on your domain model layer \", \"\\n(library), not vice versa, as shown in Figure 7-7. \\n \\nFigure 7-7. Dependencies between layers in DD\", \"D \\nDependencies in a DDD Service, the Application layer depends on Domain and Infrastructure, and \\nI\", \"nfrastructure depends on Domain, but Domain doesn\\u2019t depend on any layer. This layer design should \\nb\", \"e independent for each microservice. As noted earlier, you can implement the most complex \\nmicroserv\", \"ices following DDD patterns, while implementing simpler data-driven microservices (simple \\nCRUD in a\", \" single layer) in a simpler way. \\n \\n199 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wi\", \"th DDD and CQRS Patterns \\n \\nAdditional resources \\n\\u2022 \\nDevIQ. Persistence Ignorance principle \\nhttps:/\", \"/deviq.com/persistence-ignorance/ \\n\\u2022 \\nOren Eini. Infrastructure Ignorance \\nhttps://ayende.com/blog/3\", \"137/infrastructure-ignorance \\n\\u2022 \\nAngel Lopez. Layered Architecture In Domain-Driven Design \\nhttps://\", \"ajlopez.wordpress.com/2008/09/12/layered-architecture-in-domain-driven-design/ \\nDesign a microservic\", \"e domain model \\nDefine one rich domain model for each business microservice or Bounded Context. \\nYou\", \"r goal is to create a single cohesive domain model for each business microservice or Bounded \\nContex\", \"t (BC). Keep in mind, however, that a BC or business microservice could sometimes be \\ncomposed of se\", \"veral physical services that share a single domain model. The domain model must \\ncapture the rules, \", \"behavior, business language, and constraints of the single Bounded Context or \\nbusiness microservice\", \" that it represents. \\nThe Domain Entity pattern \\nEntities represent domain objects and are primarily\", \" defined by their identity, continuity, and \\npersistence over time, and not only by the attributes t\", \"hat comprise them. As Eric Evans says, \\u201can \\nobject primarily defined by its identity is called an En\", \"tity.\\u201d Entities are very important in the domain \\nmodel, since they are the base for a model. Theref\", \"ore, you should identify and design them carefully. \\nAn entity\\u2019s identity can cross multiple microse\", \"rvices or Bounded Contexts. \\nThe same identity (that is, the same Id value, although perhaps not the\", \" same domain entity) can be \\nmodeled across multiple Bounded Contexts or microservices. However, tha\", \"t does not imply that the \\nsame entity, with the same attributes and logic would be implemented in m\", \"ultiple Bounded Contexts. \\nInstead, entities in each Bounded Context limit their attributes and beha\", \"viors to those required in that \\nBounded Context\\u2019s domain. \\nFor instance, the buyer entity might hav\", \"e most of a person\\u2019s attributes that are defined in the user \\nentity in the profile or identity micr\", \"oservice, including the identity. But the buyer entity in the ordering \\nmicroservice might have fewe\", \"r attributes, because only certain buyer data is related to the order \\nprocess. The context of each \", \"microservice or Bounded Context impacts its domain model. \\nDomain entities must implement behavior i\", \"n addition to implementing data attributes. \\nA domain entity in DDD must implement the domain logic \", \"or behavior related to the entity data (the \\nobject accessed in memory). For example, as part of an \", \"order entity class you must have business logic \\nand operations implemented as methods for tasks suc\", \"h as adding an order item, data validation, and \\ntotal calculation. The entity\\u2019s methods take care o\", \"f the invariants and rules of the entity instead of \\nhaving those rules spread across the applicatio\", \"n layer. \\n \\n200 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\", \" \\n \\nFigure 7-8 shows a domain entity that implements not only data attributes but operations or meth\", \"ods \\nwith related domain logic. \\n \\nFigure 7-8. Example of a domain entity design implementing data p\", \"lus behavior \\nA domain model entity implements behaviors through methods, that is, it\\u2019s not an \\u201canem\", \"ic\\u201d model. Of \\ncourse, sometimes you can have entities that do not implement any logic as part of th\", \"e entity class. \\nThis can happen in child entities within an aggregate if the child entity does not \", \"have any special logic \\nbecause most of the logic is defined in the aggregate root. If you have a co\", \"mplex microservice that \\nhas logic implemented in the service classes instead of in the domain entit\", \"ies, you could be falling \\ninto the anemic domain model, explained in the following section. \\nRich d\", \"omain model versus anemic domain model \\nIn his post AnemicDomainModel, Martin Fowler describes an an\", \"emic domain model this way: \\nThe basic symptom of an Anemic Domain Model is that at first blush it l\", \"ooks like the real thing. There \\nare objects, many named after the nouns in the domain space, and th\", \"ese objects are connected with \\nthe rich relationships and structure that true domain models have. T\", \"he catch comes when you look at \\nthe behavior, and you realize that there is hardly any behavior on \", \"these objects, making them little \\nmore than bags of getters and setters. \\nOf course, when you use a\", \"n anemic domain model, those data models will be used from a set of \\nservice objects (traditionally \", \"named the business layer) which capture all the domain or business logic. \\nThe business layer sits o\", \"n top of the data model and uses the data model just as data. \\nThe anemic domain model is just a pro\", \"cedural style design. Anemic entity objects are not real objects \\nbecause they lack behavior (method\", \"s). They only hold data properties and thus it is not object-\\noriented design. By putting all the be\", \"havior out into service objects (the business layer), you \\nessentially end up with spaghetti code or\", \" transaction scripts, and therefore you lose the advantages \\nthat a domain model provides. \\nRegardle\", \"ss, if your microservice or Bounded Context is very simple (a CRUD service), the anemic \\ndomain mode\", \"l in the form of entity objects with just data properties might be good enough, and it \\nmight not be\", \" worth implementing more complex DDD patterns. In that case, it will be simply a \\npersistence model,\", \" because you have intentionally created an entity with only data for CRUD \\npurposes. \\n \\n201 \\nCHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nThat is why microser\", \"vices architectures are perfect for a multi-architectural approach depending on \\neach Bounded Contex\", \"t. For instance, in eShopOnContainers, the ordering microservice implements \\nDDD patterns, but the c\", \"atalog microservice, which is a simple CRUD service, does not. \\nSome people say that the anemic doma\", \"in model is an anti-pattern. It really depends on what you are \\nimplementing. If the microservice yo\", \"u are creating is simple enough (for example, a CRUD service), \\nfollowing the anemic domain model it\", \" is not an anti-pattern. However, if you need to tackle the \\ncomplexity of a microservice\\u2019s domain t\", \"hat has a lot of ever-changing business rules, the anemic \\ndomain model might be an anti-pattern for\", \" that microservice or Bounded Context. In that case, \\ndesigning it as a rich model with entities con\", \"taining data plus behavior as well as implementing \\nadditional DDD patterns (aggregates, value objec\", \"ts, etc.) might have huge benefits for the long-term \\nsuccess of such a microservice. \\nAdditional re\", \"sources \\n\\u2022 \\nDevIQ. Domain Entity \\nhttps://deviq.com/entity/ \\n\\u2022 \\nMartin Fowler. The Domain Model \\nhtt\", \"ps://martinfowler.com/eaaCatalog/domainModel.html \\n\\u2022 \\nMartin Fowler. The Anemic Domain Model \\nhttps:\", \"//martinfowler.com/bliki/AnemicDomainModel.html \\nThe Value Object pattern \\nAs Eric Evans has noted, \", \"\\u201cMany objects do not have conceptual identity. These objects describe \\ncertain characteristics of a \", \"thing.\\u201d \\nAn entity requires an identity, but there are many objects in a system that do not, like th\", \"e Value \\nObject pattern. A value object is an object with no conceptual identity that describes a do\", \"main aspect. \\nThese are objects that you instantiate to represent design elements that only concern \", \"you temporarily. \\nYou care about what they are, not who they are. Examples include numbers and strin\", \"gs, but can also \\nbe higher-level concepts like groups of attributes. \\nSomething that is an entity i\", \"n a microservice might not be an entity in another microservice, because \\nin the second case, the Bo\", \"unded Context might have a different meaning. For example, an address in \\nan e-commerce application \", \"might not have an identity at all, since it might only represent a group of \\nattributes of the custo\", \"mer\\u2019s profile for a person or company. In this case, the address should be \\nclassified as a value ob\", \"ject. However, in an application for an electric power utility company, the \\ncustomer address could \", \"be important for the business domain. Therefore, the address must have an \\nidentity so the billing s\", \"ystem can be directly linked to the address. In that case, an address should be \\nclassified as a dom\", \"ain entity. \\nA person with a name and surname is usually an entity because a person has identity, ev\", \"en if the \\nname and surname coincide with another set of values, such as if those names also refer t\", \"o a different \\nperson. \\nValue objects are hard to manage in relational databases and ORMs like Entit\", \"y Framework (EF), \\nwhereas in document-oriented databases they are easier to implement and use. \\n \\n2\", \"02 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nEF Core 2\", \".0 and later versions include the Owned Entities feature that makes it easier to handle value \\nobjec\", \"ts, as we\\u2019ll see in detail later on. \\nAdditional resources \\n\\u2022 \\nMartin Fowler. Value Object pattern \\n\", \"https://martinfowler.com/bliki/ValueObject.html \\n\\u2022 \\nValue Object \\nhttps://deviq.com/value-object/ \\n\\u2022\", \" \\nValue Objects in Test-Driven Development \\nhttps://leanpub.com/tdd-ebook/read#leanpub-auto-value-ob\", \"jects \\n\\u2022 \\nEric Evans. Domain-Driven Design: Tackling Complexity in the Heart of Software. (Book; \\nin\", \"cludes a discussion of value objects) \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexi\", \"ty-\\nSoftware/dp/0321125215/ \\nThe Aggregate pattern \\nA domain model contains clusters of different da\", \"ta entities and processes that can control a \\nsignificant area of functionality, such as order fulfi\", \"llment or inventory. A more fine-grained DDD unit is \\nthe aggregate, which describes a cluster or gr\", \"oup of entities and behaviors that can be treated as a \\ncohesive unit. \\nYou usually define an aggreg\", \"ate based on the transactions that you need. A classic example is an \\norder that also contains a lis\", \"t of order items. An order item will usually be an entity. But it will be a \\nchild entity within the\", \" order aggregate, which will also contain the order entity as its root entity, \\ntypically called an \", \"aggregate root. \\nIdentifying aggregates can be hard. An aggregate is a group of objects that must be\", \" consistent \\ntogether, but you cannot just pick a group of objects and label them an aggregate. You \", \"must start \\nwith a domain concept and think about the entities that are used in the most common tran\", \"sactions \\nrelated to that concept. Those entities that need to be transactionally consistent are wha\", \"t forms an \\naggregate. Thinking about transaction operations is probably the best way to identify ag\", \"gregates. \\nThe Aggregate Root or Root Entity pattern \\nAn aggregate is composed of at least one entit\", \"y: the aggregate root, also called root entity or primary \\nentity. Additionally, it can have multipl\", \"e child entities and value objects, with all entities and objects \\nworking together to implement req\", \"uired behavior and transactions. \\nThe purpose of an aggregate root is to ensure the consistency of t\", \"he aggregate; it should be the only \\nentry point for updates to the aggregate through methods or ope\", \"rations in the aggregate root class. \\nYou should make changes to entities within the aggregate only \", \"via the aggregate root. It is the \\naggregate\\u2019s consistency guardian, considering all the invariants \", \"and consistency rules you might need \\nto comply with in your aggregate. If you change a child entity\", \" or value object independently, the \\n \\n203 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS Patterns \\n \\naggregate root cannot ensure that the aggregate is in a valid state. \", \"It would be like a table with a \\nloose leg. Maintaining consistency is the main purpose of the aggre\", \"gate root. \\nIn Figure 7-9, you can see sample aggregates like the buyer aggregate, which contains a \", \"single entity \\n(the aggregate root Buyer). The order aggregate contains multiple entities and a valu\", \"e object. \\n \\nFigure 7-9. Example of aggregates with multiple or single entities \\nA DDD domain model \", \"is composed from aggregates, an aggregate can have just one entity or more, \\nand can include value o\", \"bjects as well. Note that the Buyer aggregate could have additional child \\nentities, depending on yo\", \"ur domain, as it does in the ordering microservice in the eShopOnContainers \\nreference application. \", \"Figure 7-9 just illustrates a case in which the buyer has a single entity, as an \\nexample of an aggr\", \"egate that contains only an aggregate root. \\nIn order to maintain separation of aggregates and keep \", \"clear boundaries between them, it is a good \\npractice in a DDD domain model to disallow direct navig\", \"ation between aggregates and only having \\nthe foreign key (FK) field, as implemented in the Ordering\", \" microservice domain model in \\neShopOnContainers. The Order entity only has a foreign key field for \", \"the buyer, but not an EF Core \\nnavigation property, as shown in the following code: \\npublic class Or\", \"der : Entity, IAggregateRoot \\n{ \\n    private DateTime _orderDate; \\n    public Address Address { get;\", \" private set; } \\n    private int? _buyerId; // FK pointing to a different aggregate root \\n    public\", \" OrderStatus OrderStatus { get; private set; } \\n    private readonly List<OrderItem> _orderItems; \\n \", \"   public IReadOnlyCollection<OrderItem> OrderItems => _orderItems; \\n    // ... Additional code \\n} \\n\", \" \\n204 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nIdenti\", \"fying and working with aggregates requires research and experience. For more information, see \\nthe f\", \"ollowing Additional resources list. \\nAdditional resources \\n\\u2022 \\nVaughn Vernon. Effective Aggregate Des\", \"ign - Part I: Modeling a Single Aggregate (from \\nhttps://dddcommunity.org/) \\nhttps://dddcommunity.or\", \"g/wp-content/uploads/files/pdf_articles/Vernon_2011_1.pdf \\n\\u2022 \\nVaughn Vernon. Effective Aggregate Des\", \"ign - Part II: Making Aggregates Work \\nTogether (from https://dddcommunity.org/) \\nhttps://dddcommuni\", \"ty.org/wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf \\n\\u2022 \\nVaughn Vernon. Effective Aggregat\", \"e Design - Part III: Gaining Insight Through \\nDiscovery (from https://dddcommunity.org/) \\nhttps://dd\", \"dcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_3.pdf \\n\\u2022 \\nSergey Grybniak. DDD Tact\", \"ical Design Patterns \\nhttps://www.codeproject.com/Articles/1164363/Domain-Driven-Design-Tactical-Des\", \"ign-\\nPatterns-Part \\n\\u2022 \\nChris Richardson. Developing Transactional Microservices Using Aggregates \\nht\", \"tps://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richardson \\n\\u2022 \\nDevIQ. The A\", \"ggregate pattern \\nhttps://deviq.com/aggregate-pattern/ \\nImplement a microservice domain model with .\", \"NET \\nIn the previous section, the fundamental design principles and patterns for designing a domain \", \"model \\nwere explained. Now it\\u2019s time to explore possible ways to implement the domain model by using\", \" .NET \\n(plain C# code) and EF Core. Your domain model will be composed simply of your code. It will \", \"have \\njust the EF Core model requirements, but not real dependencies on EF. You shouldn\\u2019t have hard \", \"\\ndependencies or references to EF Core or any other ORM in your domain model. \\nDomain model structur\", \"e in a custom .NET Standard Library \\nThe folder organization used for the eShopOnContainers referenc\", \"e application demonstrates the DDD \\nmodel for the application. You might find that a different folde\", \"r organization more clearly \\ncommunicates the design choices made for your application. As you can s\", \"ee in Figure 7-10, in the \\nordering domain model there are two aggregates, the order aggregate and t\", \"he buyer aggregate. Each \\naggregate is a group of domain entities and value objects, although you co\", \"uld have an aggregate \\ncomposed of a single domain entity (the aggregate root or root entity) as wel\", \"l. \\n \\n205 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n \\n\", \"Figure 7-10. Domain model structure for the ordering microservice in eShopOnContainers \\nAdditionally\", \", the domain model layer includes the repository contracts (interfaces) that are the \\ninfrastructure\", \" requirements of your domain model. In other words, these interfaces express what \\nrepositories and \", \"the methods the infrastructure layer must implement. It\\u2019s critical that the \\nimplementation of the r\", \"epositories be placed outside of the domain model layer, in the infrastructure \\nlayer library, so th\", \"e domain model layer isn\\u2019t \\u201ccontaminated\\u201d by API or classes from infrastructure \\ntechnologies, like \", \"Entity Framework. \\nYou can also see a SeedWork folder that contains custom base classes that you can\", \" use as a base for \\nyour domain entities and value objects, so you don\\u2019t have redundant code in each\", \" domain\\u2019s object \\nclass. \\nStructure aggregates in a custom .NET Standard library \\nAn aggregate refer\", \"s to a cluster of domain objects grouped together to match transactional \\nconsistency. Those objects\", \" could be instances of entities (one of which is the aggregate root or root \\nentity) plus any additi\", \"onal value objects. \\nTransactional consistency means that an aggregate is guaranteed to be consisten\", \"t and up to date at \\nthe end of a business action. For example, the order aggregate from the eShopOn\", \"Containers ordering \\nmicroservice domain model is composed as shown in Figure 7-11. \\n \\n206 \\nCHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n \\nFigure 7-11. The or\", \"der aggregate in Visual Studio solution \\nIf you open any of the files in an aggregate folder, you ca\", \"n see how it\\u2019s marked as either a custom \\nbase class or interface, like entity or value object, as i\", \"mplemented in the SeedWork folder. \\nImplement domain entities as POCO classes \\nYou implement a domai\", \"n model in .NET by creating POCO classes that implement your domain \\nentities. In the following exam\", \"ple, the Order class is defined as an entity and also as an aggregate \\nroot. Because the Order class\", \" derives from the Entity base class, it can reuse common code related to \\nentities. Bear in mind tha\", \"t these base classes and interfaces are defined by you in the domain model \\nproject, so it is your c\", \"ode, not infrastructure code from an ORM like EF. \\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE 5.0 \\n// \", \"Entity is a custom base class with the ID \\npublic class Order : Entity, IAggregateRoot \\n{ \\n    priva\", \"te DateTime _orderDate; \\n    public Address Address { get; private set; } \\n    private int? _buyerId\", \"; \\n \\n    public OrderStatus OrderStatus { get; private set; } \\n    private int _orderStatusId; \\n \\n  \", \"  private string _description; \\n    private int? _paymentMethodId; \\n \\n    private readonly List<Orde\", \"rItem> _orderItems; \\n    public IReadOnlyCollection<OrderItem> OrderItems => _orderItems; \\n \\n    pub\", \"lic Order(string userId, Address address, int cardTypeId, string cardNumber, string \\ncardSecurityNum\", \"ber, \\n            string cardHolderName, DateTime cardExpiration, int? buyerId = null, int? \\npayment\", \"MethodId = null) \\n    { \\n        _orderItems = new List<OrderItem>(); \\n        _buyerId = buyerId; \\n\", \"        _paymentMethodId = paymentMethodId; \\n        _orderStatusId = OrderStatus.Submitted.Id; \\n   \", \"     _orderDate = DateTime.UtcNow; \\n \\n207 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice \", \"with DDD and CQRS Patterns \\n \\n        Address = address; \\n \\n        // ...Additional code ... \\n    }\", \" \\n \\n    public void AddOrderItem(int productId, string productName, \\n                            dec\", \"imal unitPrice, decimal discount, \\n                            string pictureUrl, int units = 1) \\n  \", \"  { \\n        //... \\n        // Domain rules/logic for adding the OrderItem to the order \\n        // \", \"... \\n \\n        var orderItem = new OrderItem(productId, productName, unitPrice, discount, \\npictureUr\", \"l, units); \\n \\n        _orderItems.Add(orderItem); \\n \\n    } \\n    // ... \\n    // Additional methods wi\", \"th domain rules/logic related to the Order aggregate \\n    // ... \\n} \\nIt\\u2019s important to note that thi\", \"s is a domain entity implemented as a POCO class. It doesn\\u2019t have any \\ndirect dependency on Entity F\", \"ramework Core or any other infrastructure framework. This \\nimplementation is as it should be in DDD,\", \" just C# code implementing a domain model. \\nIn addition, the class is decorated with an interface na\", \"med IAggregateRoot. That interface is an empty \\ninterface, sometimes called a marker interface, that\", \"\\u2019s used just to indicate that this entity class is also \\nan aggregate root. \\nA marker interface is s\", \"ometimes considered as an anti-pattern; however, it\\u2019s also a clean way to mark \\na class, especially \", \"when that interface might be evolving. An attribute could be the other choice for \\nthe marker, but i\", \"t\\u2019s quicker to see the base class (Entity) next to the IAggregate interface instead of \\nputting an A\", \"ggregate attribute marker above the class. It\\u2019s a matter of preferences, in any case. \\nHaving an agg\", \"regate root means that most of the code related to consistency and business rules of \\nthe aggregate\\u2019\", \"s entities should be implemented as methods in the Order aggregate root class (for \\nexample, AddOrde\", \"rItem when adding an OrderItem object to the aggregate). You should not create \\nor update OrderItems\", \" objects independently or directly; the AggregateRoot class must keep control \\nand consistency of an\", \"y update operation against its child entities. \\nEncapsulate data in the Domain Entities \\nA common pr\", \"oblem in entity models is that they expose collection navigation properties as publicly \\naccessible \", \"list types. This allows any collaborator developer to manipulate the contents of these \\ncollection t\", \"ypes, which may bypass important business rules related to the collection, possibly leaving \\nthe obj\", \"ect in an invalid state. The solution to this is to expose read-only access to related collections \\n\", \"and explicitly provide methods that define ways in which clients can manipulate them. \\nIn the previo\", \"us code, note that many attributes are read-only or private and are only updatable by the \\nclass met\", \"hods, so any update considers business domain invariants and logic specified within the class \\nmetho\", \"ds. \\n \\n208 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nF\", \"or example, following DDD patterns, you should not do the following from any command handler \\nmethod\", \" or application layer class (actually, it should be impossible for you to do so): \\n// WRONG ACCORDIN\", \"G TO DDD PATTERNS \\u2013 CODE AT THE APPLICATION LAYER OR \\n// COMMAND HANDLERS \\n// Code in command handle\", \"r methods or Web API controllers \\n//... (WRONG) Some code with business logic out of the domain clas\", \"ses ... \\nOrderItem myNewOrderItem = new OrderItem(orderId, productId, productName, \\n    pictureUrl, \", \"unitPrice, discount, units); \\n \\n//... (WRONG) Accessing the OrderItems collection directly from the \", \"application layer // or \\ncommand handlers \\nmyOrder.OrderItems.Add(myNewOrderItem); \\n//... \\nIn this c\", \"ase, the Add method is purely an operation to add data, with direct access to the OrderItems \\ncollec\", \"tion. Therefore, most of the domain logic, rules, or validations related to that operation with the \", \"\\nchild entities will be spread across the application layer (command handlers and Web API controller\", \"s). \\nIf you go around the aggregate root, the aggregate root cannot guarantee its invariants, its va\", \"lidity, or \\nits consistency. Eventually you\\u2019ll have spaghetti code or transactional script code. \\nTo\", \" follow DDD patterns, entities must not have public setters in any entity property. Changes in an \\ne\", \"ntity should be driven by explicit methods with explicit ubiquitous language about the change \\nthey\\u2019\", \"re performing in the entity. \\nFurthermore, collections within the entity (like the order items) shou\", \"ld be read-only properties (the \\nAsReadOnly method explained later). You should be able to update it\", \" only from within the aggregate \\nroot class methods or the child entity methods. \\nAs you can see in \", \"the code for the Order aggregate root, all setters should be private or at least read-\\nonly external\", \"ly, so that any operation against the entity\\u2019s data or its child entities has to be performed \\nthrou\", \"gh methods in the entity class. This maintains consistency in a controlled and object-oriented \\nway \", \"instead of implementing transactional script code. \\nThe following code snippet shows the proper way \", \"to code the task of adding an OrderItem object to \\nthe Order aggregate. \\n// RIGHT ACCORDING TO DDD--\", \"CODE AT THE APPLICATION LAYER OR COMMAND HANDLERS \\n// The code in command handlers or WebAPI control\", \"lers, related only to application stuff \\n// There is NO code here related to OrderItem object's busi\", \"ness logic \\nmyOrder.AddOrderItem(productId, productName, pictureUrl, unitPrice, discount, units); \\n \", \"\\n// The code related to OrderItem params validations or domain rules should \\n// be WITHIN the AddOrd\", \"erItem method. \\n \\n//... \\nIn this snippet, most of the validations or logic related to the creation o\", \"f an OrderItem object will be \\nunder the control of the Order aggregate root\\u2014in the AddOrderItem met\", \"hod\\u2014especially validations \\nand logic related to other elements in the aggregate. For instance, you \", \"might get the same product \\nitem as the result of multiple calls to AddOrderItem. In that method, yo\", \"u could examine the product \\nitems and consolidate the same product items into a single OrderItem ob\", \"ject with several units. \\n \\n209 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD a\", \"nd CQRS Patterns \\n \\nAdditionally, if there are different discount amounts but the product ID is the \", \"same, you would likely \\napply the higher discount. This principle applies to any other domain logic \", \"for the OrderItem object. \\nIn addition, the new OrderItem(params) operation will also be controlled \", \"and performed by the \\nAddOrderItem method from the Order aggregate root. Therefore, most of the logi\", \"c or validations \\nrelated to that operation (especially anything that impacts the consistency betwee\", \"n other child \\nentities) will be in a single place within the aggregate root. That is the ultimate p\", \"urpose of the \\naggregate root pattern. \\nWhen you use Entity Framework Core 1.1 or later, a DDD entit\", \"y can be better expressed because it \\nallows mapping to fields in addition to properties. This is us\", \"eful when protecting collections of child \\nentities or value objects. With this enhancement, you can\", \" use simple private fields instead of \\nproperties and you can implement any update to the field coll\", \"ection in public methods and provide \\nread-only access through the AsReadOnly method. \\nIn DDD, you w\", \"ant to update the entity only through methods in the entity (or the constructor) in order \\nto contro\", \"l any invariant and the consistency of the data, so properties are defined only with a get \\naccessor\", \". The properties are backed by private fields. Private members can only be accessed from \\nwithin the\", \" class. However, there is one exception: EF Core needs to set these fields as well (so it can \\nretur\", \"n the object with the proper values). \\nMap properties with only get accessors to the fields in the d\", \"atabase table \\nMapping properties to database table columns is not a domain responsibility but part \", \"of the \\ninfrastructure and persistence layer. We mention this here just so you\\u2019re aware of the new c\", \"apabilities \\nin EF Core 1.1 or later related to how you can model entities. Additional details on th\", \"is topic are \\nexplained in the infrastructure and persistence section. \\nWhen you use EF Core 1.0 or \", \"later, within the DbContext you need to map the properties that are \\ndefined only with getters to th\", \"e actual fields in the database table. This is done with the HasField \\nmethod of the PropertyBuilder\", \" class. \\nMap fields without properties \\nWith the feature in EF Core 1.1 or later to map columns to f\", \"ields, it\\u2019s also possible to not use \\nproperties. Instead, you can just map columns from a table to \", \"fields. A common use case for this is \\nprivate fields for an internal state that doesn\\u2019t need to be \", \"accessed from outside the entity. \\nFor example, in the preceding OrderAggregate code example, there \", \"are several private fields, like the \\n_paymentMethodId field, that have no related property for eith\", \"er a setter or getter. That field could \\nalso be calculated within the order\\u2019s business logic and us\", \"ed from the order\\u2019s methods, but it needs \\nto be persisted in the database as well. So in EF Core (s\", \"ince v1.1), there\\u2019s a way to map a field without \\na related property to a column in the database. Th\", \"is is also explained in the Infrastructure layer section \\nof this guide. \\n \\n210 \\nCHAPTER 6 | Tackle \", \"Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nAdditional resources \\n\\u2022 \\nVaughn \", \"Vernon. Modeling Aggregates with DDD and Entity Framework. Note that this is \\nnot Entity Framework C\", \"ore. \\nhttps://kalele.io/blog-posts/modeling-aggregates-with-ddd-and-entity-framework/ \\n\\u2022 \\nJulie Lerm\", \"an. Data Points - Coding for Domain-Driven Design: Tips for Data-Focused \\nDevs \\nhttps://learn.micros\", \"oft.com/archive/msdn-magazine/2013/august/data-points-coding-for-\\ndomain-driven-design-tips-for-data\", \"-focused-devs \\n\\u2022 \\nUdi Dahan. How to create fully encapsulated Domain Models \\nhttps://udidahan.com/20\", \"08/02/29/how-to-create-fully-encapsulated-domain-models/ \\n\\u2022 \\nSteve Smith. What is the difference bet\", \"ween a DTO and a POCO?  https://ardalis.com/dto-\\nor-poco/ \\nSeedwork (reusable base classes and inter\", \"faces for \\nyour domain model) \\nThe solution folder contains a SeedWork folder. This folder contains \", \"custom base classes that you can \\nuse as a base for your domain entities and value objects. Use thes\", \"e base classes so you don\\u2019t have \\nredundant code in each domain\\u2019s object class. The folder for these\", \" types of classes is called SeedWork \\nand not something like Framework. It\\u2019s called SeedWork because\", \" the folder contains just a small \\nsubset of reusable classes that cannot really be considered a fra\", \"mework. Seedwork is a term \\nintroduced by Michael Feathers and popularized by Martin Fowler but you \", \"could also name that \\nfolder Common, SharedKernel, or similar. \\nFigure 7-12 shows the classes that f\", \"orm the seedwork of the domain model in the ordering \\nmicroservice. It has a few custom base classes\", \" like Entity, ValueObject, and Enumeration, plus a few \\ninterfaces. These interfaces (IRepository an\", \"d IUnitOfWork) inform the infrastructure layer about what \\nneeds to be implemented. Those interfaces\", \" are also used through Dependency Injection from the \\napplication layer. \\n \\nFigure 7-12. A sample se\", \"t of domain model \\u201cseedwork\\u201d base classes and interfaces \\nThis is the type of copy and paste reuse t\", \"hat many developers share between projects, not a formal \\nframework. You can have seedworks in any l\", \"ayer or library. However, if the set of classes and \\ninterfaces gets large enough, you might want to\", \" create a single class library. \\n \\n211 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns \\n \\nThe custom Entity base class \\nThe following code is an example of an Enti\", \"ty base class where you can place code that can be used \\nthe same way by any domain entity, such as \", \"the entity ID, equality operators, a domain event list per \\nentity, etc. \\n// COMPATIBLE WITH ENTITY \", \"FRAMEWORK CORE (1.1 and later) \\npublic abstract class Entity \\n{ \\n    int? _requestedHashCode; \\n    i\", \"nt _Id; \\n    private List<INotification> _domainEvents; \\n    public virtual int Id \\n    { \\n        g\", \"et \\n        { \\n            return _Id; \\n        } \\n        protected set \\n        { \\n            _Id\", \" = value; \\n        } \\n    } \\n \\n    public List<INotification> DomainEvents => _domainEvents; \\n    pu\", \"blic void AddDomainEvent(INotification eventItem) \\n    { \\n        _domainEvents = _domainEvents ?? n\", \"ew List<INotification>(); \\n        _domainEvents.Add(eventItem); \\n    } \\n    public void RemoveDomai\", \"nEvent(INotification eventItem) \\n    { \\n        if (_domainEvents is null) return; \\n        _domainE\", \"vents.Remove(eventItem); \\n    } \\n \\n    public bool IsTransient() \\n    { \\n        return this.Id == d\", \"efault(Int32); \\n    } \\n \\n    public override bool Equals(object obj) \\n    { \\n        if (obj == null\", \" || !(obj is Entity)) \\n            return false; \\n        if (Object.ReferenceEquals(this, obj)) \\n  \", \"          return true; \\n        if (this.GetType() != obj.GetType()) \\n            return false; \\n   \", \"     Entity item = (Entity)obj; \\n        if (item.IsTransient() || this.IsTransient()) \\n            \", \"return false; \\n        else \\n            return item.Id == this.Id; \\n    } \\n \\n    public override in\", \"t GetHashCode() \\n    { \\n        if (!IsTransient()) \\n \\n212 \\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n \\n        { \\n            if (!_requestedHashCode.HasVal\", \"ue) \\n                _requestedHashCode = this.Id.GetHashCode() ^ 31; \\n            // XOR for random\", \" distribution. See: \\n            // https://learn.microsoft.com/archive/blogs/ericlippert/guidelines\", \"-and-rules-\\nfor-gethashcode \\n            return _requestedHashCode.Value; \\n        } \\n        else \\n\", \"            return base.GetHashCode(); \\n    } \\n    public static bool operator ==(Entity left, Entit\", \"y right) \\n    { \\n        if (Object.Equals(left, null)) \\n            return (Object.Equals(right, nu\", \"ll)); \\n        else \\n            return left.Equals(right); \\n    } \\n    public static bool operator \", \"!=(Entity left, Entity right) \\n    { \\n        return !(left == right); \\n    } \\n} \\nThe previous code \", \"using a domain event list per entity will be explained in the next sections when \\nfocusing on domain\", \" events. \\nRepository contracts (interfaces) in the domain model layer \\nRepository contracts are simp\", \"ly .NET interfaces that express the contract requirements of the \\nrepositories to be used for each a\", \"ggregate. \\nThe repositories themselves, with EF Core code or any other infrastructure dependencies a\", \"nd code \\n(Linq, SQL, etc.), must not be implemented within the domain model; the repositories should\", \" only \\nimplement the interfaces you define in the domain model. \\nA pattern related to this practice \", \"(placing the repository interfaces in the domain model layer) is the \\nSeparated Interface pattern. A\", \"s explained by Martin Fowler, \\u201cUse Separated Interface to define an \\ninterface in one package but im\", \"plement it in another. This way a client that needs the dependency to \\nthe interface can be complete\", \"ly unaware of the implementation.\\u201d \\nFollowing the Separated Interface pattern enables the applicatio\", \"n layer (in this case, the Web API \\nproject for the microservice) to have a dependency on the requir\", \"ements defined in the domain model, \\nbut not a direct dependency to the infrastructure/persistence l\", \"ayer. In addition, you can use \\nDependency Injection to isolate the implementation, which is impleme\", \"nted in the infrastructure/ \\npersistence layer using repositories. \\nFor example, the following examp\", \"le with the IOrderRepository interface defines what operations the \\nOrderRepository class will need \", \"to implement at the infrastructure layer. In the current \\nimplementation of the application, the cod\", \"e just needs to add or update orders to the database, since \\nqueries are split following the simplif\", \"ied CQRS approach. \\n// Defined at IOrderRepository.cs \\npublic interface IOrderRepository : IReposito\", \"ry<Order> \\n{ \\n \\n213 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patt\", \"erns \\n \\n    Order Add(Order order); \\n \\n    void Update(Order order); \\n \\n    Task<Order> GetAsync(int\", \" orderId); \\n} \\n \\n// Defined at IRepository.cs (Part of the Domain Seedwork) \\npublic interface IRepos\", \"itory<T> where T : IAggregateRoot \\n{ \\n    IUnitOfWork UnitOfWork { get; } \\n} \\nAdditional resources \\n\", \"\\u2022 \\nMartin Fowler. Separated Interface. \\nhttps://www.martinfowler.com/eaaCatalog/separatedInterface.h\", \"tml \\nImplement value objects \\nAs discussed in earlier sections about entities and aggregates, identi\", \"ty is fundamental for entities. \\nHowever, there are many objects and data items in a system that do \", \"not require an identity and \\nidentity tracking, such as value objects. \\nA value object can reference\", \" other entities. For example, in an application that generates a route that \\ndescribes how to get fr\", \"om one point to another, that route would be a value object. It would be a \\nsnapshot of points on a \", \"specific route, but this suggested route would not have an identity, even \\nthough internally it migh\", \"t refer to entities like City, Road, etc. \\nFigure 7-13 shows the Address value object within the Ord\", \"er aggregate. \\n \\n214 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pat\", \"terns \\n \\n \\nFigure 7-13. Address value object within the Order aggregate \\nAs shown in Figure 7-13, an\", \" entity is usually composed of multiple attributes. For example, the Order \\nentity can be modeled as\", \" an entity with an identity and composed internally of a set of attributes such \\nas OrderId, OrderDa\", \"te, OrderItems, etc. But the address, which is simply a complex-value composed of \\ncountry/region, s\", \"treet, city, etc., and has no identity in this domain, must be modeled and treated as a \\nvalue objec\", \"t. \\nImportant characteristics of value objects \\nThere are two main characteristics for value objects\", \": \\n\\u2022 \\nThey have no identity. \\n\\u2022 \\nThey are immutable. \\nThe first characteristic was already discussed\", \". Immutability is an important requirement. The values of \\na value object must be immutable once the\", \" object is created. Therefore, when the object is \\n \\n215 \\nCHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns \\n \\nconstructed, you must provide the required values, but \", \"you must not allow them to change during the \\nobject\\u2019s lifetime. \\nValue objects allow you to perform\", \" certain tricks for performance, thanks to their immutable nature. \\nThis is especially true in syste\", \"ms where there may be thousands of value object instances, many of \\nwhich have the same values. Thei\", \"r immutable nature allows them to be reused; they can be \\ninterchangeable objects, since their value\", \"s are the same and they have no identity. This type of \\noptimization can sometimes make a difference\", \" between software that runs slowly and software with \\ngood performance. Of course, all these cases d\", \"epend on the application environment and deployment \\ncontext. \\nValue object implementation in C# \\nIn\", \" terms of implementation, you can have a value object base class that has basic utility methods like\", \" \\nequality based on the comparison between all the attributes (since a value object must not be base\", \"d \\non identity) and other fundamental characteristics. The following example shows a value object ba\", \"se \\nclass used in the ordering microservice from eShopOnContainers. \\npublic abstract class ValueObje\", \"ct \\n{ \\n    protected static bool EqualOperator(ValueObject left, ValueObject right) \\n    { \\n        \", \"if (ReferenceEquals(left, null) ^ ReferenceEquals(right, null)) \\n        { \\n            return false\", \"; \\n        } \\n        return ReferenceEquals(left, right) || left.Equals(right); \\n    } \\n \\n    prote\", \"cted static bool NotEqualOperator(ValueObject left, ValueObject right) \\n    { \\n        return !(Equa\", \"lOperator(left, right)); \\n    } \\n \\n    protected abstract IEnumerable<object> GetEqualityComponents(\", \"); \\n \\n    public override bool Equals(object obj) \\n    { \\n        if (obj == null || obj.GetType() !\", \"= GetType()) \\n        { \\n            return false; \\n        } \\n \\n        var other = (ValueObject)ob\", \"j; \\n \\n        return this.GetEqualityComponents().SequenceEqual(other.GetEqualityComponents()); \\n   \", \" } \\n \\n    public override int GetHashCode() \\n    { \\n        return GetEqualityComponents() \\n        \", \"    .Select(x => x != null ? x.GetHashCode() : 0) \\n            .Aggregate((x, y) => x ^ y); \\n    } \\n\", \"    // Other utility methods \\n} \\n \\n216 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns \\n \\n \\nThe ValueObject is an abstract class type, but in this example, it does\", \"n\\u2019t overload the == and != \\noperators. You could choose to do so, making comparisons delegate to the\", \" Equals override. For \\nexample, consider the following operator overloads to the ValueObject type: \\n\", \"public static bool operator ==(ValueObject one, ValueObject two) \\n{ \\n    return EqualOperator(one, t\", \"wo); \\n} \\n \\npublic static bool operator !=(ValueObject one, ValueObject two) \\n{ \\n    return NotEqualO\", \"perator(one, two); \\n} \\nYou can use this class when implementing your actual value object, as with th\", \"e Address \\nvalue object shown in the following example: \\npublic class Address : ValueObject \\n{ \\n    \", \"public String Street { get; private set; } \\n    public String City { get; private set; } \\n    public\", \" String State { get; private set; } \\n    public String Country { get; private set; } \\n    public Str\", \"ing ZipCode { get; private set; } \\n \\n    public Address() { } \\n \\n    public Address(string street, s\", \"tring city, string state, string country, string \\nzipcode) \\n    { \\n        Street = street; \\n       \", \" City = city; \\n        State = state; \\n        Country = country; \\n        ZipCode = zipcode; \\n    }\", \" \\n \\n    protected override IEnumerable<object> GetEqualityComponents() \\n    { \\n        // Using a yi\", \"eld return statement to return each element one at a time \\n        yield return Street; \\n        yie\", \"ld return City; \\n        yield return State; \\n        yield return Country; \\n        yield return Zi\", \"pCode; \\n    } \\n} \\nThis value object implementation of Address has no identity, and therefore no ID f\", \"ield is defined for it, \\neither in the Address class definition or the ValueObject class definition.\", \" \\nHaving no ID field in a class to be used by Entity Framework (EF) was not possible until EF Core 2\", \".0, \\nwhich greatly helps to implement better value objects with no ID. That is precisely the explana\", \"tion of \\nthe next section. \\nIt could be argued that value objects, being immutable, should be read-o\", \"nly (that is, have get-only \\nproperties), and that\\u2019s indeed true. However, value objects are usually\", \" serialized and deserialized to go \\n \\n217 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice \", \"with DDD and CQRS Patterns \\n \\nthrough message queues, and being read-only stops the deserializer fro\", \"m assigning values, so you \\njust leave them as private set, which is read-only enough to be practica\", \"l. \\nValue object comparison semantics \\nTwo instances of the Address type can be compared using all t\", \"he following methods: \\nvar one = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); \\nva\", \"r two = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); \\n \\nConsole.WriteLine(Equalit\", \"yComparer<Address>.Default.Equals(one, two)); // True \\nConsole.WriteLine(object.Equals(one, two)); /\", \"/ True \\nConsole.WriteLine(one.Equals(two)); // True \\nConsole.WriteLine(one == two); // True \\nWhen al\", \"l the values are the same, the comparisons are correctly evaluated as true. If you didn\\u2019t choose \\nto\", \" overload the == and != operators, then the last comparison of one == two would evaluate as false. \\n\", \"For more information, see Overload ValueObject equality operators. \\nHow to persist value objects in \", \"the database with EF Core 2.0 and later \\nYou just saw how to define a value object in your domain mo\", \"del. But how can you actually persist it \\ninto the database using Entity Framework Core since it usu\", \"ally targets entities with identity? \\nBackground and older approaches using EF Core 1.1 \\nAs backgrou\", \"nd, a limitation when using EF Core 1.0 and 1.1 was that you could not use complex types \\nas defined\", \" in EF 6.x in the traditional .NET Framework. Therefore, if using EF Core 1.0 or 1.1, you \\nneeded to\", \" store your value object as an EF entity with an ID field. Then, so it looked more like a value \\nobj\", \"ect with no identity, you could hide its ID so you make clear that the identity of a value object is\", \" \\nnot important in the domain model. You could hide that ID by using the ID as a shadow property. \\nS\", \"ince that configuration for hiding the ID in the model is set up in the EF infrastructure level, it \", \"would \\nbe kind of transparent for your domain model. \\nIn the initial version of eShopOnContainers (.\", \"NET Core 1.1), the hidden ID needed by EF Core \\ninfrastructure was implemented in the following way \", \"in the DbContext level, using Fluent API at the \\ninfrastructure project. Therefore, the ID was hidde\", \"n from the domain model point of view, but still \\npresent in the infrastructure. \\n// Old approach wi\", \"th EF Core 1.1 \\n// Fluent API within the OrderingContext:DbContext in the Infrastructure project \\nvo\", \"id ConfigureAddress(EntityTypeBuilder<Address> addressConfiguration) \\n{ \\n    addressConfiguration.To\", \"Table(\\\"address\\\", DEFAULT_SCHEMA); \\n \\n    addressConfiguration.Property<int>(\\\"Id\\\")  // Id is a shadow\", \" property \\n        .IsRequired(); \\n    addressConfiguration.HasKey(\\\"Id\\\");   // Id is a shadow proper\", \"ty \\n} \\nHowever, the persistence of that value object into the database was performed like a regular \", \"entity in \\na different table. \\n \\n218 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patterns \\n \\nWith EF Core 2.0 and later, there are new and better ways to persist value \", \"objects. \\nPersist value objects as owned entity types in EF Core 2.0 and later \\nEven with some gaps \", \"between the canonical value object pattern in DDD and the owned entity type in \\nEF Core, it\\u2019s curren\", \"tly the best way to persist value objects with EF Core 2.0 and later. You can see \\nlimitations at th\", \"e end of this section. \\nThe owned entity type feature was added to EF Core since version 2.0. \\nAn ow\", \"ned entity type allows you to map types that do not have their own identity explicitly defined in \\nt\", \"he domain model and are used as properties, such as a value object, within any of your entities. An \", \"\\nowned entity type shares the same CLR type with another entity type (that is, it\\u2019s just a regular c\", \"lass). \\nThe entity containing the defining navigation is the owner entity. When querying the owner, \", \"the \\nowned types are included by default. \\nJust by looking at the domain model, an owned type looks \", \"like it doesn\\u2019t have any identity. However, \\nunder the covers, owned types do have the identity, but\", \" the owner navigation property is part of this \\nidentity. \\nThe identity of instances of owned types \", \"is not completely their own. It consists of three components: \\n\\u2022 \\nThe identity of the owner \\n\\u2022 \\nThe \", \"navigation property pointing to them \\n\\u2022 \\nIn the case of collections of owned types, an independent c\", \"omponent (supported in EF Core \\n2.2 and later). \\nFor example, in the Ordering domain model at eShopO\", \"nContainers, as part of the Order entity, the \\nAddress value object is implemented as an owned entit\", \"y type within the owner entity, which is the \\nOrder entity. Address is a type with no identity prope\", \"rty defined in the domain model. It is used as a \\nproperty of the Order type to specify the shipping\", \" address for a particular order. \\nBy convention, a shadow primary key is created for the owned type \", \"and it will be mapped to the same \\ntable as the owner by using table splitting. This allows to use o\", \"wned types similarly to how complex \\ntypes are used in EF6 in the traditional .NET Framework. \\nIt is\", \" important to note that owned types are never discovered by convention in EF Core, so you have \\nto d\", \"eclare them explicitly. \\nIn eShopOnContainers, in the OrderingContext.cs file, within the OnModelCre\", \"ating() method, multiple \\ninfrastructure configurations are applied. One of them is related to the O\", \"rder entity. \\n// Part of the OrderingContext.cs class at the Ordering.Infrastructure project \\n// \\npr\", \"otected override void OnModelCreating(ModelBuilder modelBuilder) \\n{ \\n    modelBuilder.ApplyConfigura\", \"tion(new ClientRequestEntityTypeConfiguration()); \\n    modelBuilder.ApplyConfiguration(new PaymentMe\", \"thodEntityTypeConfiguration()); \\n    modelBuilder.ApplyConfiguration(new OrderEntityTypeConfiguratio\", \"n()); \\n    modelBuilder.ApplyConfiguration(new OrderItemEntityTypeConfiguration()); \\n    //...Additi\", \"onal type configurations \\n} \\n \\n219 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DD\", \"D and CQRS Patterns \\n \\nIn the following code, the persistence infrastructure is defined for the Orde\", \"r entity: \\n// Part of the OrderEntityTypeConfiguration.cs class \\n// \\npublic void Configure(EntityTyp\", \"eBuilder<Order> orderConfiguration) \\n{ \\n    orderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEF\", \"AULT_SCHEMA); \\n    orderConfiguration.HasKey(o => o.Id); \\n    orderConfiguration.Ignore(b => b.Domai\", \"nEvents); \\n    orderConfiguration.Property(o => o.Id) \\n        .ForSqlServerUseSequenceHiLo(\\\"orderse\", \"q\\\", OrderingContext.DEFAULT_SCHEMA); \\n \\n    //Address value object persisted as owned entity in EF C\", \"ore 2.0 \\n    orderConfiguration.OwnsOne(o => o.Address); \\n \\n    orderConfiguration.Property<DateTime\", \">(\\\"OrderDate\\\").IsRequired(); \\n \\n    //...Additional validations, constraints and code... \\n    //... \", \"\\n} \\nIn the previous code, the orderConfiguration.OwnsOne(o => o.Address) method specifies that the \\n\", \"Address property is an owned entity of the Order type. \\nBy default, EF Core conventions name the dat\", \"abase columns for the properties of the owned entity \\ntype as EntityProperty_OwnedEntityProperty. Th\", \"erefore, the internal properties of Address will appear \\nin the Orders table with the names Address_\", \"Street, Address_City (and so on for State, Country, and \\nZipCode). \\nYou can append the Property().Ha\", \"sColumnName() fluent method to rename those columns. In the \\ncase where Address is a public property\", \", the mappings would be like the following: \\norderConfiguration.OwnsOne(p => p.Address) \\n           \", \"                 .Property(p=>p.Street).HasColumnName(\\\"ShippingStreet\\\"); \\n \\norderConfiguration.OwnsO\", \"ne(p => p.Address) \\n                            .Property(p=>p.City).HasColumnName(\\\"ShippingCity\\\"); \", \"\\nIt\\u2019s possible to chain the OwnsOne method in a fluent mapping. In the following hypothetical \\nexamp\", \"le, OrderDetails owns BillingAddress and ShippingAddress, which are both Address types. Then \\nOrderD\", \"etails is owned by the Order type. \\norderConfiguration.OwnsOne(p => p.OrderDetails, cb => \\n    { \\n  \", \"      cb.OwnsOne(c => c.BillingAddress); \\n        cb.OwnsOne(c => c.ShippingAddress); \\n    }); \\n//..\", \". \\n//... \\npublic class Order \\n{ \\n    public int Id { get; set; } \\n    public OrderDetails OrderDetai\", \"ls { get; set; } \\n} \\n \\npublic class OrderDetails \\n{ \\n    public Address BillingAddress { get; set; }\", \" \\n \\n220 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    \", \"public Address ShippingAddress { get; set; } \\n} \\n \\npublic class Address \\n{ \\n    public string Street\", \" { get; set; } \\n    public string City { get; set; } \\n} \\nAdditional details on owned entity types \\n\\u2022\", \" \\nOwned types are defined when you configure a navigation property to a particular type using \\nthe O\", \"wnsOne fluent API. \\n\\u2022 \\nThe definition of an owned type in our metadata model is a composite of: the \", \"owner type, the \\nnavigation property, and the CLR type of the owned type. \\n\\u2022 \\nThe identity (key) of \", \"an owned type instance in our stack is a composite of the identity of the \\nowner type and the defini\", \"tion of the owned type. \\nOwned entities capabilities \\n\\u2022 \\nOwned types can reference other entities, e\", \"ither owned (nested owned types) or non-owned \\n(regular reference navigation properties to other ent\", \"ities). \\n\\u2022 \\nYou can map the same CLR type as different owned types in the same owner entity through \", \"\\nseparate navigation properties. \\n\\u2022 \\nTable splitting is set up by convention, but you can opt out by\", \" mapping the owned type to a \\ndifferent table using ToTable. \\n\\u2022 \\nEager loading is performed automati\", \"cally on owned types, that is, there\\u2019s no need to call \\n.Include() on the query. \\n\\u2022 \\nCan be configur\", \"ed with attribute [Owned], using EF Core 2.1 and later. \\n\\u2022 \\nCan handle collections of owned types (u\", \"sing version 2.2 and later). \\nOwned entities limitations \\n\\u2022 \\nYou can\\u2019t create a DbSet<T> of an owned\", \" type (by design). \\n\\u2022 \\nYou can\\u2019t call ModelBuilder.Entity<T>() on owned types (currently by design).\", \" \\n\\u2022 \\nNo support for optional (that is, nullable) owned types that are mapped with the owner in the \\n\", \"same table (that is, using table splitting). This is because mapping is done for each property, \\nthe\", \"re is no separate sentinel for the null complex value as a whole. \\n\\u2022 \\nNo inheritance-mapping support\", \" for owned types, but you should be able to map two leaf \\ntypes of the same inheritance hierarchies \", \"as different owned types. EF Core will not reason \\nabout the fact that they are part of the same hie\", \"rarchy. \\n \\n221 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \", \"\\n \\nMain differences with EF6\\u2019s complex types \\n\\u2022 \\nTable splitting is optional, that is, they can opti\", \"onally be mapped to a separate table and still \\nbe owned types. \\nAdditional resources \\n\\u2022 \\nMartin Fow\", \"ler. ValueObject pattern \\nhttps://martinfowler.com/bliki/ValueObject.html \\n\\u2022 \\nEric Evans. Domain-Dri\", \"ven Design: Tackling Complexity in the Heart of Software. (Book; \\nincludes a discussion of value obj\", \"ects) \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/ \\n\\u2022 \\n\", \"Vaughn Vernon. Implementing Domain-Driven Design. (Book; includes a discussion of \\nvalue objects) \\nh\", \"ttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\nVernon/dp/0321834577/ \\n\\u2022 \\nOwned Enti\", \"ty Types \\nhttps://learn.microsoft.com/ef/core/modeling/owned-entities \\n\\u2022 \\nShadow Properties \\nhttps:/\", \"/learn.microsoft.com/ef/core/modeling/shadow-properties \\n\\u2022 \\nComplex types and/or value objects. Disc\", \"ussion in the EF Core GitHub repo (Issues tab) \\nhttps://github.com/dotnet/efcore/issues/246 \\n\\u2022 \\nValu\", \"eObject.cs. Base value object class in eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/e\", \"ShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\\nk/ValueObject.cs \\n\\u2022 \\nValueOb\", \"ject.cs. Base value object class in CSharpFunctionalExtensions. \\nhttps://github.com/vkhorikov/CSharp\", \"FunctionalExtensions/blob/master/CSharpFunctionalExte\\nnsions/ValueObject/ValueObject.cs \\n\\u2022 \\nAddress \", \"class. Sample value object class in eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/eSho\", \"pOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesModel/OrderAggregate/Address\", \".cs \\nUse enumeration classes instead of enum types \\nEnumerations (or enum types for short) are a thi\", \"n language wrapper around an integral type. You \\nmight want to limit their use to when you are stori\", \"ng one value from a closed set of values. \\nClassification based on sizes (small, medium, large) is a\", \" good example. Using enums for control flow \\nor more robust abstractions can be a code smell. This t\", \"ype of usage leads to fragile code with many \\ncontrol flow statements checking values of the enum. \\n\", \" \\n222 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nInstea\", \"d, you can create Enumeration classes that enable all the rich features of an object-oriented \\nlangu\", \"age. \\nHowever, this isn\\u2019t a critical topic and in many cases, for simplicity, you can still use regu\", \"lar enum \\ntypes if that\\u2019s your preference. The use of enumeration classes is more related to busines\", \"s-related \\nconcepts. \\nImplement an Enumeration base class \\nThe ordering microservice in eShopOnConta\", \"iners provides a sample Enumeration base class \\nimplementation, as shown in the following example: \\n\", \"public abstract class Enumeration : IComparable \\n{ \\n    public string Name { get; private set; } \\n \\n\", \"    public int Id { get; private set; } \\n \\n    protected Enumeration(int id, string name) => (Id, Na\", \"me) = (id, name); \\n \\n    public override string ToString() => Name; \\n \\n    public static IEnumerable\", \"<T> GetAll<T>() where T : Enumeration => \\n        typeof(T).GetFields(BindingFlags.Public | \\n       \", \"                     BindingFlags.Static | \\n                            BindingFlags.DeclaredOnly) \\n\", \"                 .Select(f => f.GetValue(null)) \\n                 .Cast<T>(); \\n \\n    public override\", \" bool Equals(object obj) \\n    { \\n        if (obj is not Enumeration otherValue) \\n        { \\n        \", \"    return false; \\n        } \\n \\n        var typeMatches = GetType().Equals(obj.GetType()); \\n        \", \"var valueMatches = Id.Equals(otherValue.Id); \\n \\n        return typeMatches && valueMatches; \\n    } \\n\", \" \\n    public int CompareTo(object other) => Id.CompareTo(((Enumeration)other).Id); \\n \\n    // Other u\", \"tility methods ... \\n} \\nYou can use this class as a type in any entity or value object, as for the fo\", \"llowing \\nCardType : Enumeration class: \\npublic class CardType \\n    : Enumeration \\n{ \\n    public stat\", \"ic CardType Amex = new(1, nameof(Amex)); \\n    public static CardType Visa = new(2, nameof(Visa)); \\n \", \"   public static CardType MasterCard = new(3, nameof(MasterCard)); \\n \\n    public CardType(int id, st\", \"ring name) \\n        : base(id, name) \\n    { \\n \\n223 \\nCHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS Patterns \\n \\n    } \\n} \\nAdditional resources \\n\\u2022 \\nJimmy Bogard. Enumeration \", \"classes \\nhttps://lostechies.com/jimmybogard/2008/08/12/enumeration-classes/ \\n\\u2022 \\nSteve Smith. Enum Al\", \"ternatives in C# \\nhttps://ardalis.com/enum-alternatives-in-c \\n\\u2022 \\nEnumeration.cs. Base Enumeration cl\", \"ass in eShopOnContainers \\nhttps://github.com/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Ser\", \"vices/Ordering/Ordering.Domain/SeedWor\\nk/Enumeration.cs \\n\\u2022 \\nCardType.cs. Sample Enumeration class in\", \" eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Services\", \"/Ordering/Ordering.Domain/Aggregat\\nesModel/BuyerAggregate/CardType.cs \\n\\u2022 \\nSmartEnum. Ardalis - Class\", \"es to help produce strongly typed smarter enums in .NET. \\nhttps://www.nuget.org/packages/Ardalis.Sma\", \"rtEnum/ \\nDesign validations in the domain model layer \\nIn DDD, validation rules can be thought as in\", \"variants. The main responsibility of an aggregate is to \\nenforce invariants across state changes for\", \" all the entities within that aggregate. \\nDomain entities should always be valid entities. There are\", \" a certain number of invariants for an object \\nthat should always be true. For example, an order ite\", \"m object always has to have a quantity that must \\nbe a positive integer, plus an article name and pr\", \"ice. Therefore, invariants enforcement is the \\nresponsibility of the domain entities (especially of \", \"the aggregate root) and an entity object should not \\nbe able to exist without being valid. Invariant\", \" rules are simply expressed as contracts, and exceptions \\nor notifications are raised when they are \", \"violated. \\nThe reasoning behind this is that many bugs occur because objects are in a state they sho\", \"uld never \\nhave been in. \\nLet\\u2019s propose we now have a SendUserCreationEmailService that takes a User\", \"Profile \\u2026 how can we \\nrationalize in that service that Name is not null? Do we check it again? Or mo\", \"re likely \\u2026 you just don\\u2019t \\nbother to check and \\u201chope for the best\\u201d\\u2014you hope that someone bothered t\", \"o validate it before \\nsending it to you. Of course, using TDD one of the first tests we should be wr\", \"iting is that if I send a \\ncustomer with a null name that it should raise an error. But once we star\", \"t writing these kinds of tests \\nover and over again we realize \\u2026 \\u201cwhat if we never allowed name to b\", \"ecome null? we wouldn\\u2019t have \\nall of these tests!\\u201d. \\n \\n224 \\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n \\nImplement validations in the domain model layer \\nVali\", \"dations are usually implemented in domain entity constructors or in methods that can update the \\nent\", \"ity. There are multiple ways to implement validations, such as verifying data and raising exceptions\", \" \\nif the validation fails. There are also more advanced patterns such as using the Specification pat\", \"tern \\nfor validations, and the Notification pattern to return a collection of errors instead of retu\", \"rning an \\nexception for each validation as it occurs. \\nValidate conditions and throw exceptions \\nThe\", \" following code example shows the simplest approach to validation in a domain entity by raising \\nan \", \"exception. In the references table at the end of this section you can see links to more advanced \\nim\", \"plementations based on the patterns we have discussed previously. \\npublic void SetAddress(Address ad\", \"dress) \\n{ \\n    _shippingAddress = address?? throw new ArgumentNullException(nameof(address)); \\n} \\nA \", \"better example would demonstrate the need to ensure that either the internal state did \\nnot change, \", \"or that all the mutations for a method occurred. For example, the following \\nimplementation would le\", \"ave the object in an invalid state: \\npublic void SetAddress(string line1, string line2, \\n    string \", \"city, string state, int zip) \\n{ \\n    _shippingAddress.line1 = line1 ?? throw new ... \\n    _shippingA\", \"ddress.line2 = line2; \\n    _shippingAddress.city = city ?? throw new ... \\n    _shippingAddress.state\", \" = (IsValid(state) ? state : throw new \\u2026); \\n} \\nIf the value of the state is invalid, the first addre\", \"ss line and the city have already been changed. That \\nmight make the address invalid. \\nA similar app\", \"roach can be used in the entity\\u2019s constructor, raising an exception to make sure that the \\nentity is\", \" valid once it is created. \\nUse validation attributes in the model based on data annotations \\nData a\", \"nnotations, like the Required or MaxLength attributes, can be used to configure EF Core \\ndatabase fi\", \"eld properties, as explained in detail in the Table mapping section, but they no longer work \\nfor en\", \"tity validation in EF Core (neither does the IValidatableObject.Validate method), as they have \\ndone\", \" since EF 4.x in .NET Framework. \\nData annotations and the IValidatableObject interface can still be\", \" used for model validation during \\nmodel binding, prior to the controller\\u2019s actions invocation as us\", \"ual, but that model is meant to be a \\nViewModel or DTO and that\\u2019s an MVC or API concern not a domain\", \" model concern. \\nHaving made the conceptual difference clear, you can still use data annotations and\", \" \\nIValidatableObject in the entity class for validation, if your actions receive an entity class obj\", \"ect \\nparameter, which is not recommended. In that case, validation will occur upon model binding, ju\", \"st \\nbefore invoking the action and you can check the controller\\u2019s ModelState.IsValid property to che\", \"ck \\n \\n225 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nth\", \"e result, but then again, it happens in the controller, not before persisting the entity object in t\", \"he \\nDbContext, as it had done since EF 4.x. \\nYou can still implement custom validation in the entity\", \" class using data annotations and the \\nIValidatableObject.Validate method, by overriding the DbConte\", \"xt\\u2019s SaveChanges method. \\nYou can see a sample implementation for validating IValidatableObject enti\", \"ties in this comment on \\nGitHub. That sample doesn\\u2019t do attribute-based validations, but they should\", \" be easy to implement \\nusing reflection in the same override. \\nHowever, from a DDD point of view, th\", \"e domain model is best kept lean with the use of exceptions in \\nyour entity\\u2019s behavior methods, or b\", \"y implementing the Specification and Notification patterns to \\nenforce validation rules. \\nIt can mak\", \"e sense to use data annotations at the application layer in ViewModel classes (instead of \\ndomain en\", \"tities) that will accept input, to allow for model validation within the UI layer. However, this \\nsh\", \"ould not be done at the exclusion of validation within the domain model. \\nValidate entities by imple\", \"menting the Specification pattern and the Notification \\npattern \\nFinally, a more elaborate approach \", \"to implementing validations in the domain model is by \\nimplementing the Specification pattern in con\", \"junction with the Notification pattern, as explained in \\nsome of the additional resources listed lat\", \"er. \\nIt is worth mentioning that you can also use just one of those patterns\\u2014for example, validating\", \" \\nmanually with control statements, but using the Notification pattern to stack and return a list of\", \" \\nvalidation errors. \\nUse deferred validation in the domain \\nThere are various approaches to deal wi\", \"th deferred validations in the domain. In his book \\nImplementing Domain-Driven Design, Vaughn Vernon\", \" discusses these in the section on validation. \\nTwo-step validation \\nAlso consider two-step validati\", \"on. Use field-level validation on your command Data Transfer Objects \\n(DTOs) and domain-level valida\", \"tion inside your entities. You can do this by returning a result object \\ninstead of exceptions in or\", \"der to make it easier to deal with the validation errors. \\nUsing field validation with data annotati\", \"ons, for example, you do not duplicate the validation \\ndefinition. The execution, though, can be bot\", \"h server-side and client-side in the case of DTOs \\n(commands and ViewModels, for instance). \\nAdditio\", \"nal resources \\n\\u2022 \\nRachel Appel. Introduction to model validation in ASP.NET Core MVC \\nhttps://learn.\", \"microsoft.com/aspnet/core/mvc/models/validation \\n\\u2022 \\nRick Anderson. Adding validation \\nhttps://learn.\", \"microsoft.com/aspnet/core/tutorials/first-mvc-app/validation \\n \\n226 \\nCHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS Patterns \\n \\n\\u2022 \\nMartin Fowler. Replacing Throwing Excepti\", \"ons with Notification in Validations \\nhttps://martinfowler.com/articles/replaceThrowWithNotification\", \".html \\n\\u2022 \\nSpecification and Notification Patterns \\nhttps://www.codeproject.com/Tips/790758/Specifica\", \"tion-and-Notification-Patterns \\n\\u2022 \\nLev Gorodinski. Validation in Domain-Driven Design (DDD) \\nhttp://\", \"gorodinski.com/blog/2012/05/19/validation-in-domain-driven-design-ddd/ \\n\\u2022 \\nColin Jack. Domain Model \", \"Validation \\nhttps://colinjack.blogspot.com/2008/03/domain-model-validation.html \\n\\u2022 \\nJimmy Bogard. Va\", \"lidation in a DDD world \\nhttps://lostechies.com/jimmybogard/2009/02/15/validation-in-a-ddd-world/ \\nC\", \"lient-side validation (validation in the presentation \\nlayers) \\nEven when the source of truth is the\", \" domain model and ultimately you must have validation at the \\ndomain model level, validation can sti\", \"ll be handled at both the domain model level (server side) and \\nthe UI (client side). \\nClient-side v\", \"alidation is a great convenience for users. It saves time they would otherwise spend \\nwaiting for a \", \"round trip to the server that might return validation errors. In business terms, even a few \\nfractio\", \"ns of seconds multiplied hundreds of times each day adds up to a lot of time, expense, and \\nfrustrat\", \"ion. Straightforward and immediate validation enables users to work more efficiently and \\nproduce be\", \"tter quality input and output. \\nJust as the view model and the domain model are different, view mode\", \"l validation and domain model \\nvalidation might be similar but serve a different purpose. If you are\", \" concerned about DRY (the Don\\u2019t \\nRepeat Yourself principle), consider that in this case code reuse m\", \"ight also mean coupling, and in \\nenterprise applications it is more important not to couple the serv\", \"er side to the client side than to \\nfollow the DRY principle. \\nEven when using client-side validatio\", \"n, you should always validate your commands or input DTOs in \\nserver code, because the server APIs a\", \"re a possible attack vector. Usually, doing both is your best bet \\nbecause if you have a client appl\", \"ication, from a UX perspective, it is best to be proactive and not allow \\nthe user to enter invalid \", \"information. \\nTherefore, in client-side code you typically validate the ViewModels. You could also v\", \"alidate the client \\noutput DTOs or commands before you send them to the services. \\nThe implementatio\", \"n of client-side validation depends on what kind of client application you are \\nbuilding. It will be\", \" different if you are validating data in a web MVC web application with most of the \\ncode in .NET, a\", \" SPA web application with that validation being coded in JavaScript or TypeScript, or a \\nmobile app \", \"coded with Xamarin and C#. \\n \\n227 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS Patterns \\n \\nAdditional resources \\nValidation in Xamarin mobile apps \\n\\u2022 \\nValidate Text Inpu\", \"t and Show Errors \\nhttps://developer.xamarin.com/recipes/ios/standard_controls/text_field/validate_i\", \"nput/ \\n\\u2022 \\nValidation Callback \\nhttps://developer.xamarin.com/samples/xamarin-forms/XAML/ValidationCa\", \"llback/ \\nValidation in ASP.NET Core apps \\n\\u2022 \\nRick Anderson. Adding validation \\nhttps://learn.microso\", \"ft.com/aspnet/core/tutorials/first-mvc-app/validation \\nValidation in SPA Web apps (Angular 2, TypeSc\", \"ript, JavaScript, Blazor \\nWebAssembly) \\n\\u2022 \\nForm Validation \\nhttps://angular.io/guide/form-validation\", \" \\n\\u2022 \\nValidation. Breeze documentation. \\nhttps://breeze.github.io/doc-js/validation.html \\n\\u2022 \\nASP.NET \", \"Core Blazor forms and input components   \\nIn summary, these are the most important concepts in regar\", \"ds to validation: \\n\\u2022 \\nEntities and aggregates should enforce their own consistency and be \\u201calways va\", \"lid\\u201d. \\nAggregate roots are responsible for multi-entity consistency within the same aggregate. \\n\\u2022 \\nI\", \"f you think that an entity needs to enter an invalid state, consider using a different object \\nmodel\", \"\\u2014for example, using a temporary DTO until you create the final domain entity. \\n\\u2022 \\nIf you need to cre\", \"ate several related objects, such as an aggregate, and they are only valid \\nonce all of them have be\", \"en created, consider using the Factory pattern. \\n\\u2022 \\nIn most of the cases, having redundant validatio\", \"n in the client side is good, because the \\napplication can be proactive. \\nDomain events: Design and \", \"implementation \\nUse domain events to explicitly implement side effects of changes within your domain\", \". In other words, \\nand using DDD terminology, use domain events to explicitly implement side effects\", \" across multiple \\naggregates. Optionally, for better scalability and less impact in database locks, \", \"use eventual \\nconsistency between aggregates within the same domain. \\n \\n228 \\nCHAPTER 6 | Tackle Busi\", \"ness Complexity in a Microservice with DDD and CQRS Patterns \\n \\nWhat is a domain event? \\nAn event is\", \" something that has happened in the past. A domain event is, something that happened in \\nthe domain \", \"that you want other parts of the same domain (in-process) to be aware of. The notified \\nparts usuall\", \"y react somehow to the events. \\nAn important benefit of domain events is that side effects can be ex\", \"pressed explicitly. \\nFor example, if you\\u2019re just using Entity Framework and there has to be a reacti\", \"on to some event, you \\nwould probably code whatever you need close to what triggers the event. So th\", \"e rule gets coupled, \\nimplicitly, to the code, and you have to look into the code to, hopefully, rea\", \"lize the rule is \\nimplemented there. \\nOn the other hand, using domain events makes the concept expli\", \"cit, because there\\u2019s a DomainEvent \\nand at least one DomainEventHandler involved. \\nFor example, in t\", \"he eShopOnContainers application, when an order is created, the user becomes a \\nbuyer, so an OrderSt\", \"artedDomainEvent is raised and handled in the \\nValidateOrAddBuyerAggregateWhenOrderStartedDomainEven\", \"tHandler, so the underlying concept is \\nevident. \\nIn short, domain events help you to express, expli\", \"citly, the domain rules, based in the ubiquitous \\nlanguage provided by the domain experts. Domain ev\", \"ents also enable a better separation of concerns \\namong classes within the same domain. \\nIt\\u2019s import\", \"ant to ensure that, just like a database transaction, either all the operations related to a \\ndomain\", \" event finish successfully or none of them do. \\nDomain events are similar to messaging-style events,\", \" with one important difference. With real \\nmessaging, message queuing, message brokers, or a service\", \" bus using AMQP, a message is always \\nsent asynchronously and communicated across processes and mach\", \"ines. This is useful for integrating \\nmultiple Bounded Contexts, microservices, or even different ap\", \"plications. However, with domain \\nevents, you want to raise an event from the domain operation you\\u2019r\", \"e currently running, but you want \\nany side effects to occur within the same domain. \\nThe domain eve\", \"nts and their side effects (the actions triggered afterwards that are managed by event \\nhandlers) sh\", \"ould occur almost immediately, usually in-process, and within the same domain. Thus, \\ndomain events \", \"could be synchronous or asynchronous. Integration events, however, should always be \\nasynchronous. \\n\", \"Domain events versus integration events \\nSemantically, domain and integration events are the same th\", \"ing: notifications about something that \\njust happened. However, their implementation must be differ\", \"ent. Domain events are just messages \\npushed to a domain event dispatcher, which could be implemente\", \"d as an in-memory mediator based \\non an IoC container or any other method. \\nOn the other hand, the p\", \"urpose of integration events is to propagate committed transactions and \\nupdates to additional subsy\", \"stems, whether they are other microservices, Bounded Contexts or even \\n \\n229 \\nCHAPTER 6 | Tackle Bus\", \"iness Complexity in a Microservice with DDD and CQRS Patterns \\n \\nexternal applications. Hence, they \", \"should occur only if the entity is successfully persisted, otherwise it\\u2019s \\nas if the entire operatio\", \"n never happened. \\nAs mentioned before, integration events must be based on asynchronous communicati\", \"on between \\nmultiple microservices (other Bounded Contexts) or even external systems/applications. \\n\", \"Thus, the event bus interface needs some infrastructure that allows inter-process and distributed \\nc\", \"ommunication between potentially remote services. It can be based on a commercial service bus, \\nqueu\", \"es, a shared database used as a mailbox, or any other distributed and ideally push based \\nmessaging \", \"system. \\nDomain events as a preferred way to trigger side effects across \\nmultiple aggregates within\", \" the same domain \\nIf executing a command related to one aggregate instance requires additional domai\", \"n rules to be run \\non one or more additional aggregates, you should design and implement those side \", \"effects to be \\ntriggered by domain events. As shown in Figure 7-14, and as one of the most important\", \" use cases, a \\ndomain event should be used to propagate state changes across multiple aggregates wit\", \"hin the same \\ndomain model. \\n \\nFigure 7-14. Domain events to enforce consistency between multiple ag\", \"gregates within the same domain \\nFigure 7-14 shows how consistency between aggregates is achieved by\", \" domain events. When the user \\ninitiates an order, the Order Aggregate sends an OrderStarted domain \", \"event. The OrderStarted \\ndomain event is handled by the Buyer Aggregate to create a Buyer object in \", \"the ordering \\nmicroservice, based on the original user info from the identity microservice (with inf\", \"ormation provided \\nin the CreateOrder command). \\nAlternately, you can have the aggregate root subscr\", \"ibed for events raised by members of its \\naggregates (child entities). For instance, each OrderItem \", \"child entity can raise an event when the item \\nprice is higher than a specific amount, or when the p\", \"roduct item amount is too high. The aggregate \\nroot can then receive those events and perform a glob\", \"al calculation or aggregation. \\n \\n230 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with\", \" DDD and CQRS Patterns \\n \\nIt\\u2019s important to understand that this event-based communication is not im\", \"plemented directly within \\nthe aggregates; you need to implement domain event handlers. \\nHandling th\", \"e domain events is an application concern. The domain model layer should only focus on \\nthe domain l\", \"ogic\\u2014things that a domain expert would understand, not application infrastructure like \\nhandlers and\", \" side-effect persistence actions using repositories. Therefore, the application layer level is \\nwher\", \"e you should have domain event handlers triggering actions when a domain event is raised. \\nDomain ev\", \"ents can also be used to trigger any number of application actions, and what is more \\nimportant, mus\", \"t be open to increase that number in the future in a decoupled way. For instance, when \\nthe order is\", \" started, you might want to publish a domain event to propagate that info to other \\naggregates or ev\", \"en to raise application actions like notifications. \\nThe key point is the open number of actions to \", \"be executed when a domain event occurs. Eventually, \\nthe actions and rules in the domain and applica\", \"tion will grow. The complexity or number of side-\\neffect actions when something happens will grow, b\", \"ut if your code were coupled with \\u201cglue\\u201d (that is, \\ncreating specific objects with new), then every \", \"time you needed to add a new action you would also \\nneed to change working and tested code. \\nThis ch\", \"ange could result in new bugs and this approach also goes against the Open/Closed principle \\nfrom SO\", \"LID. Not only that, the original class that was orchestrating the operations would grow and \\ngrow, w\", \"hich goes against the Single Responsibility Principle (SRP). \\nOn the other hand, if you use domain e\", \"vents, you can create a fine-grained and decoupled \\nimplementation by segregating responsibilities u\", \"sing this approach: \\n1. \\nSend a command (for example, CreateOrder). \\n2. \\nReceive the command in a co\", \"mmand handler. \\n\\u2013 \\nExecute a single aggregate\\u2019s transaction. \\n\\u2013 \\n(Optional) Raise domain events for \", \"side effects (for example, \\nOrderStartedDomainEvent). \\n3. \\nHandle domain events (within the current \", \"process) that will execute an open number of side \\neffects in multiple aggregates or application act\", \"ions. For example: \\n\\u2013 \\nVerify or create buyer and payment method. \\n\\u2013 \\nCreate and send a related inte\", \"gration event to the event bus to propagate states \\nacross microservices or trigger external actions\", \" like sending an email to the buyer. \\n\\u2013 \\nHandle other side effects. \\nAs shown in Figure 7-15, starti\", \"ng from the same domain event, you can handle multiple actions \\nrelated to other aggregates in the d\", \"omain or additional application actions you need to perform \\nacross microservices connecting with in\", \"tegration events and the event bus. \\n \\n231 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS Patterns \\n \\n \\nFigure 7-15. Handling multiple actions per domain \\nThere can be sev\", \"eral handlers for the same domain event in the Application Layer, one handler can \\nsolve consistency\", \" between aggregates and another handler can publish an integration event, so other \\nmicroservices ca\", \"n do something with it. The event handlers are typically in the application layer, \\nbecause you\\u2019ll u\", \"se infrastructure objects like repositories or an application API for the microservice\\u2019s \\nbehavior. \", \"In that sense, event handlers are similar to command handlers, so both are part of the \\napplication \", \"layer. The important difference is that a command should be processed only once. A \\ndomain event cou\", \"ld be processed zero or n times, because it can be received by multiple receivers or \\nevent handlers\", \" with a different purpose for each handler. \\nHaving an open number of handlers per domain event allo\", \"ws you to add as many domain rules as \\nneeded, without affecting current code. For instance, impleme\", \"nting the following business rule might \\nbe as easy as adding a few event handlers (or even just one\", \"): \\nWhen the total amount purchased by a customer in the store, across any number of orders, exceeds\", \" \\n$6,000, apply a 10% off discount to every new order and notify the customer with an email about th\", \"at \\ndiscount for future orders. \\nImplement domain events \\nIn C#, a domain event is simply a data-hol\", \"ding structure or class, like a DTO, with all the information \\nrelated to what just happened in the \", \"domain, as shown in the following example: \\npublic class OrderStartedDomainEvent : INotification \\n{ \", \"\\n    public string UserId { get; } \\n    public string UserName { get; } \\n    public int CardTypeId {\", \" get; } \\n    public string CardNumber { get; } \\n    public string CardSecurityNumber { get; } \\n \\n232\", \" \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    public \", \"string CardHolderName { get; } \\n    public DateTime CardExpiration { get; } \\n    public Order Order \", \"{ get; } \\n \\n    public OrderStartedDomainEvent(Order order, string userId, string userName, \\n       \", \"                            int cardTypeId, string cardNumber, \\n                                   s\", \"tring cardSecurityNumber, string cardHolderName, \\n                                   DateTime cardEx\", \"piration) \\n    { \\n        Order = order; \\n        UserId = userId; \\n        UserName = userName; \\n  \", \"      CardTypeId = cardTypeId; \\n        CardNumber = cardNumber; \\n        CardSecurityNumber = cardS\", \"ecurityNumber; \\n        CardHolderName = cardHolderName; \\n        CardExpiration = cardExpiration; \\n\", \"    } \\n} \\nThis is essentially a class that holds all the data related to the OrderStarted event. \\nIn\", \" terms of the ubiquitous language of the domain, since an event is something that happened in the \\np\", \"ast, the class name of the event should be represented as a past-tense verb, like \\nOrderStartedDomai\", \"nEvent or OrderShippedDomainEvent. That\\u2019s how the domain event is \\nimplemented in the ordering micro\", \"service in eShopOnContainers. \\nAs noted earlier, an important characteristic of events is that since\", \" an event is something that \\nhappened in the past, it shouldn\\u2019t change. Therefore, it must be an imm\", \"utable class. You can see in \\nthe previous code that the properties are read-only. There\\u2019s no way to\", \" update the object, you can only \\nset values when you create it. \\nIt\\u2019s important to highlight here t\", \"hat if domain events were to be handled asynchronously, using a \\nqueue that required serializing and\", \" deserializing the event objects, the properties would have to be \\n\\u201cprivate set\\u201d instead of read-onl\", \"y, so the deserializer would be able to assign the values upon \\ndequeuing. This is not an issue in t\", \"he Ordering microservice, as the domain event pub/sub is \\nimplemented synchronously using MediatR. \\n\", \"Raise domain events \\nThe next question is how to raise a domain event so it reaches its related even\", \"t handlers. You can use \\nmultiple approaches. \\nUdi Dahan originally proposed (for example, in severa\", \"l related posts, such as Domain Events \\u2013 Take 2) \\nusing a static class for managing and raising the \", \"events. This might include a static class named \\nDomainEvents that would raise domain events immedia\", \"tely when it\\u2019s called, using syntax like \\nDomainEvents.Raise(Event myEvent). Jimmy Bogard wrote a bl\", \"og post (Strengthening your domain: \\nDomain Events) that recommends a similar approach. \\nHowever, wh\", \"en the domain events class is static, it also dispatches to handlers immediately. This \\nmakes testin\", \"g and debugging more difficult, because the event handlers with side-effects logic are \\nexecuted imm\", \"ediately after the event is raised. When you\\u2019re testing and debugging, you just want to \\nfocus on wh\", \"at is happening in the current aggregate classes; you don\\u2019t want to suddenly be \\n \\n233 \\nCHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nredirected to other event\", \" handlers for side effects related to other aggregates or application logic. \\nThis is why other appr\", \"oaches have evolved, as explained in the next section. \\nThe deferred approach to raise and dispatch \", \"events \\nInstead of dispatching to a domain event handler immediately, a better approach is to add th\", \"e \\ndomain events to a collection and then to dispatch those domain events right before or right afte\", \"r \\ncommitting the transaction (as with SaveChanges in EF). (This approach was described by Jimmy \\nBo\", \"gard in this post A better domain events pattern.) \\nDeciding if you send the domain events right bef\", \"ore or right after committing the transaction is \\nimportant, since it determines whether you will in\", \"clude the side effects as part of the same transaction \\nor in different transactions. In the latter \", \"case, you need to deal with eventual consistency across \\nmultiple aggregates. This topic is discusse\", \"d in the next section. \\nThe deferred approach is what eShopOnContainers uses. First, you add the eve\", \"nts happening in your \\nentities into a collection or list of events per entity. That list should be \", \"part of the entity object, or \\neven better, part of your base entity class, as shown in the followin\", \"g example of the Entity base class: \\npublic abstract class Entity \\n{ \\n     //... \\n     private List<\", \"INotification> _domainEvents; \\n     public List<INotification> DomainEvents => _domainEvents; \\n \\n   \", \"  public void AddDomainEvent(INotification eventItem) \\n     { \\n         _domainEvents = _domainEvent\", \"s ?? new List<INotification>(); \\n         _domainEvents.Add(eventItem); \\n     } \\n \\n     public void \", \"RemoveDomainEvent(INotification eventItem) \\n     { \\n         _domainEvents?.Remove(eventItem); \\n    \", \" } \\n     //... Additional code \\n} \\nWhen you want to raise an event, you just add it to the event col\", \"lection from code at any method of \\nthe aggregate-root entity. \\nThe following code, part of the Orde\", \"r aggregate-root at eShopOnContainers, shows an example: \\nvar orderStartedDomainEvent = new OrderSta\", \"rtedDomainEvent(this, //Order object \\n                                                          card\", \"TypeId, cardNumber, \\n                                                          cardSecurityNumber, \\n\", \"                                                          cardHolderName, \\n                         \", \"                                 cardExpiration); \\nthis.AddDomainEvent(orderStartedDomainEvent); \\nNo\", \"tice that the only thing that the AddDomainEvent method is doing is adding an event to the list. \\nNo\", \" event is dispatched yet, and no event handler is invoked yet. \\n \\n234 \\nCHAPTER 6 | Tackle Business C\", \"omplexity in a Microservice with DDD and CQRS Patterns \\n \\nYou actually want to dispatch the events l\", \"ater on, when you commit the transaction to the database. If \\nyou are using Entity Framework Core, t\", \"hat means in the SaveChanges method of your EF DbContext, \\nas in the following code: \\n// EF Core DbC\", \"ontext \\npublic class OrderingContext : DbContext, IUnitOfWork \\n{ \\n    // ... \\n    public async Task<\", \"bool> SaveEntitiesAsync(CancellationToken cancellationToken = \\ndefault(CancellationToken)) \\n    { \\n \", \"       // Dispatch Domain Events collection. \\n        // Choices: \\n        // A) Right BEFORE commit\", \"ting data (EF SaveChanges) into the DB. This makes \\n        // a single transaction including side e\", \"ffects from the domain event \\n        // handlers that are using the same DbContext with Scope lifet\", \"ime \\n        // B) Right AFTER committing data (EF SaveChanges) into the DB. This makes \\n        // \", \"multiple transactions. You will need to handle eventual consistency and \\n        // compensatory act\", \"ions in case of failures. \\n        await _mediator.DispatchDomainEventsAsync(this); \\n \\n        // Af\", \"ter this line runs, all the changes (from the Command Handler and Domain \\n        // event handlers)\", \" performed through the DbContext will be committed \\n        var result = await base.SaveChangesAsync\", \"(); \\n    } \\n} \\nWith this code, you dispatch the entity events to their respective event handlers. \\nT\", \"he overall result is that you\\u2019ve decoupled the raising of a domain event (a simple add into a list i\", \"n \\nmemory) from dispatching it to an event handler. In addition, depending on what kind of dispatche\", \"r \\nyou are using, you could dispatch the events synchronously or asynchronously. \\nBe aware that tran\", \"sactional boundaries come into significant play here. If your unit of work and \\ntransaction can span\", \" more than one aggregate (as when using EF Core and a relational database), this \\ncan work well. But\", \" if the transaction cannot span aggregates, you have to implement additional steps \\nto achieve consi\", \"stency. This is another reason why persistence ignorance is not universal; it depends \\non the storag\", \"e system you use. \\nSingle transaction across aggregates versus eventual consistency across \\naggregat\", \"es \\nThe question of whether to perform a single transaction across aggregates versus relying on even\", \"tual \\nconsistency across those aggregates is a controversial one. Many DDD authors like Eric Evans a\", \"nd \\nVaughn Vernon advocate the rule that one transaction = one aggregate and therefore argue for \\nev\", \"entual consistency across aggregates. For example, in his book Domain-Driven Design, Eric Evans \\nsay\", \"s this: \\nAny rule that spans Aggregates will not be expected to be up-to-date at all times. Through \", \"event \\nprocessing, batch processing, or other update mechanisms, other dependencies can be resolved \", \"\\nwithin some specific time. (page 128) \\nVaughn Vernon says the following in Effective Aggregate Desi\", \"gn. Part II: Making Aggregates Work \\nTogether: \\n \\n235 \\nCHAPTER 6 | Tackle Business Complexity in a M\", \"icroservice with DDD and CQRS Patterns \\n \\nThus, if executing a command on one aggregate instance req\", \"uires that additional business rules \\nexecute on one or more aggregates, use eventual consistency [\\u2026\", \"] There is a practical way to support \\neventual consistency in a DDD model. An aggregate method publ\", \"ishes a domain event that is in time \\ndelivered to one or more asynchronous subscribers. \\nThis ratio\", \"nale is based on embracing fine-grained transactions instead of transactions spanning many \\naggregat\", \"es or entities. The idea is that in the second case, the number of database locks will be \\nsubstanti\", \"al in large-scale applications with high scalability needs. Embracing the fact that highly \\nscalable\", \" applications need not have instant transactional consistency between multiple aggregates \\nhelps wit\", \"h accepting the concept of eventual consistency. Atomic changes are often not needed by \\nthe busines\", \"s, and it is in any case the responsibility of the domain experts to say whether particular \\noperati\", \"ons need atomic transactions or not. If an operation always needs an atomic transaction \\nbetween mul\", \"tiple aggregates, you might ask whether your aggregate should be larger or wasn\\u2019t \\ncorrectly designe\", \"d. \\nHowever, other developers and architects like Jimmy Bogard are okay with spanning a single \\ntran\", \"saction across several aggregates\\u2014but only when those additional aggregates are related to side \\neff\", \"ects for the same original command. For instance, in A better domain events pattern, Bogard says \\nth\", \"is: \\nTypically, I want the side effects of a domain event to occur within the same logical transacti\", \"on, but \\nnot necessarily in the same scope of raising the domain event [\\u2026] Just before we commit our\", \" \\ntransaction, we dispatch our events to their respective handlers. \\nIf you dispatch the domain even\", \"ts right before committing the original transaction, it is because you \\nwant the side effects of tho\", \"se events to be included in the same transaction. For example, if the EF \\nDbContext SaveChanges meth\", \"od fails, the transaction will roll back all changes, including the result of \\nany side effect opera\", \"tions implemented by the related domain event handlers. This is because the \\nDbContext life scope is\", \" by default defined as \\u201cscoped.\\u201d Therefore, the DbContext object is shared \\nacross multiple reposito\", \"ry objects being instantiated within the same scope or object graph. This \\ncoincides with the HttpRe\", \"quest scope when developing Web API or MVC apps. \\nActually, both approaches (single atomic transacti\", \"on and eventual consistency) can be right. It really \\ndepends on your domain or business requirement\", \"s and what the domain experts tell you. It also \\ndepends on how scalable you need the service to be \", \"(more granular transactions have less impact \\nwith regard to database locks). And it depends on how \", \"much investment you\\u2019re willing to make in \\nyour code, since eventual consistency requires more compl\", \"ex code in order to detect possible \\ninconsistencies across aggregates and the need to implement com\", \"pensatory actions. Consider that if \\nyou commit changes to the original aggregate and afterwards, wh\", \"en the events are being dispatched, \\nif there\\u2019s an issue and the event handlers cannot commit their \", \"side effects, you\\u2019ll have inconsistencies \\nbetween aggregates. \\nA way to allow compensatory actions \", \"would be to store the domain events in additional database \\ntables so they can be part of the origin\", \"al transaction. Afterwards, you could have a batch process that \\ndetects inconsistencies and runs co\", \"mpensatory actions by comparing the list of events with the \\ncurrent state of the aggregates. The co\", \"mpensatory actions are part of a complex topic that will require \\ndeep analysis from your side, whic\", \"h includes discussing it with the business user and domain experts. \\n \\n236 \\nCHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns \\n \\nIn any case, you can choose the appro\", \"ach you need. But the initial deferred approach\\u2014raising the \\nevents before committing, so you use a \", \"single transaction\\u2014is the simplest approach when using EF \\nCore and a relational database. It\\u2019s easi\", \"er to implement and valid in many business cases. It\\u2019s also the \\napproach used in the ordering micro\", \"service in eShopOnContainers. \\nBut how do you actually dispatch those events to their respective eve\", \"nt handlers? What\\u2019s the \\n_mediator object you see in the previous example? It has to do with the tec\", \"hniques and artifacts you \\nuse to map between events and their event handlers. \\nThe domain event dis\", \"patcher: mapping from events to event handlers \\nOnce you\\u2019re able to dispatch or publish the events, \", \"you need some kind of artifact that will publish the \\nevent, so that every related handler can get i\", \"t and process side effects based on that event. \\nOne approach is a real messaging system or even an \", \"event bus, possibly based on a service bus as \\nopposed to in-memory events. However, for the first c\", \"ase, real messaging would be overkill for \\nprocessing domain events, since you just need to process \", \"those events within the same process (that \\nis, within the same domain and application layer). \\nHow \", \"to subscribe to domain events \\nWhen you use MediatR, each event handler must use an event type that \", \"is provided on the generic \\nparameter of the INotificationHandler interface, as you can see in the f\", \"ollowing code: \\npublic class ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler \\n  : INot\", \"ificationHandler<OrderStartedDomainEvent> \\nBased on the relationship between event and event handler\", \", which can be considered the \\nsubscription, the MediatR artifact can discover all the event handler\", \"s for each event and trigger each \\none of those event handlers. \\nHow to handle domain events \\nFinall\", \"y, the event handler usually implements application layer code that uses infrastructure \\nrepositorie\", \"s to obtain the required additional aggregates and to execute side-effect domain logic. The \\nfollowi\", \"ng domain event handler code at eShopOnContainers, shows an implementation example. \\npublic class Va\", \"lidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler \\n    : INotificationHandler<OrderStarted\", \"DomainEvent> \\n{ \\n    private readonly ILogger _logger; \\n    private readonly IBuyerRepository _buyer\", \"Repository; \\n    private readonly IOrderingIntegrationEventService _orderingIntegrationEventService;\", \" \\n \\n    public ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler( \\n        ILogger<Valid\", \"ateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler> logger, \\n        IBuyerRepository buyerRep\", \"ository, \\n        IOrderingIntegrationEventService orderingIntegrationEventService) \\n    { \\n        \", \"_buyerRepository = buyerRepository ?? throw new \\nArgumentNullException(nameof(buyerRepository)); \\n  \", \"      _orderingIntegrationEventService = orderingIntegrationEventService ?? throw new \\nArgumentNullE\", \"xception(nameof(orderingIntegrationEventService)); \\n \\n237 \\nCHAPTER 6 | Tackle Business Complexity in\", \" a Microservice with DDD and CQRS Patterns \\n \\n        _logger = logger ?? throw new ArgumentNullExce\", \"ption(nameof(logger)); \\n    } \\n \\n    public async Task Handle( \\n        OrderStartedDomainEvent doma\", \"inEvent, CancellationToken cancellationToken) \\n    { \\n        var cardTypeId = domainEvent.CardTypeI\", \"d != 0 ? domainEvent.CardTypeId : 1; \\n        var buyer = await _buyerRepository.FindAsync(domainEve\", \"nt.UserId); \\n        var buyerExisted = buyer is not null; \\n \\n        if (!buyerExisted) \\n        { \", \"\\n            buyer = new Buyer(domainEvent.UserId, domainEvent.UserName); \\n        } \\n \\n        buye\", \"r.VerifyOrAddPaymentMethod( \\n            cardTypeId, \\n            $\\\"Payment Method on {DateTime.UtcN\", \"ow}\\\", \\n            domainEvent.CardNumber, \\n            domainEvent.CardSecurityNumber, \\n           \", \" domainEvent.CardHolderName, \\n            domainEvent.CardExpiration, \\n            domainEvent.Order\", \".Id); \\n \\n        var buyerUpdated = buyerExisted ? \\n            _buyerRepository.Update(buyer) : \\n  \", \"          _buyerRepository.Add(buyer); \\n \\n        await _buyerRepository.UnitOfWork \\n            .Sa\", \"veEntitiesAsync(cancellationToken); \\n \\n        var integrationEvent = new OrderStatusChangedToSubmit\", \"tedIntegrationEvent( \\n            domainEvent.Order.Id, domainEvent.Order.OrderStatus.Name, buyer.Na\", \"me); \\n        await _orderingIntegrationEventService.AddAndSaveEventAsync(integrationEvent); \\n \\n    \", \"    OrderingApiTrace.LogOrderBuyerAndPaymentValidatedOrUpdated( \\n            _logger, buyerUpdated.I\", \"d, domainEvent.Order.Id); \\n    } \\n} \\nThe previous domain event handler code is considered applicatio\", \"n layer code because it uses \\ninfrastructure repositories, as explained in the next section on the i\", \"nfrastructure-persistence layer. \\nEvent handlers could also use other infrastructure components. \\nDo\", \"main events can generate integration events to be published outside of the \\nmicroservice boundaries \", \"\\nFinally, it\\u2019s important to mention that you might sometimes want to propagate events across multipl\", \"e \\nmicroservices. That propagation is an integration event, and it could be published through an eve\", \"nt \\nbus from any specific domain event handler. \\nConclusions on domain events \\nAs stated, use domain\", \" events to explicitly implement side effects of changes within your domain. To \\nuse DDD terminology,\", \" use domain events to explicitly implement side effects across one or multiple \\naggregates. Addition\", \"ally, and for better scalability and less impact on database locks, use eventual \\nconsistency betwee\", \"n aggregates within the same domain. \\n \\n238 \\nCHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS Patterns \\n \\nThe reference app uses MediatR to propagate domain events synchronou\", \"sly across aggregates, within \\na single transaction. However, you could also use some AMQP implement\", \"ation like RabbitMQ or \\nAzure Service Bus to propagate domain events asynchronously, using eventual \", \"consistency but, as \\nmentioned above, you have to consider the need for compensatory actions in case\", \" of failures. \\nAdditional resources \\n\\u2022 \\nGreg Young. What is a Domain Event? \\nhttps://cqrs.files.word\", \"press.com/2010/11/cqrs_documents.pdf#page=25 \\n\\u2022 \\nJan Stenberg. Domain Events and Eventual Consistenc\", \"y \\nhttps://www.infoq.com/news/2015/09/domain-events-consistency \\n\\u2022 \\nJimmy Bogard. A better domain ev\", \"ents pattern \\nhttps://lostechies.com/jimmybogard/2014/05/13/a-better-domain-events-pattern/ \\n\\u2022 \\nVaug\", \"hn Vernon. Effective Aggregate Design Part II: Making Aggregates Work Together \\nhttps://dddcommunity\", \".org/wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf \\n\\u2022 \\nJimmy Bogard. Strengthening your do\", \"main: Domain Events \\nhttps://lostechies.com/jimmybogard/2010/04/08/strengthening-your-domain-domain-\", \"\\nevents/ \\n\\u2022 \\nUdi Dahan. How to create fully encapsulated Domain Models \\nhttps://udidahan.com/2008/02\", \"/29/how-to-create-fully-encapsulated-domain-models/ \\n\\u2022 \\nUdi Dahan. Domain Events \\u2013 Take 2 \\nhttps://u\", \"didahan.com/2008/08/25/domain-events-take-2/ \\n\\u2022 \\nUdi Dahan. Domain Events \\u2013 Salvation \\nhttps://udida\", \"han.com/2009/06/14/domain-events-salvation/ \\n\\u2022 \\nCesar de la Torre. Domain Events vs. Integration Eve\", \"nts in DDD and microservices \\narchitectures \\nhttps://devblogs.microsoft.com/cesardelatorre/domain-ev\", \"ents-vs-integration-events-in-\\ndomain-driven-design-and-microservices-architectures/ \\nDesign the inf\", \"rastructure persistence layer \\nData persistence components provide access to the data hosted within \", \"the boundaries of a \\nmicroservice (that is, a microservice\\u2019s database). They contain the actual impl\", \"ementation of \\ncomponents such as repositories and Unit of Work classes, like custom Entity Framewor\", \"k (EF) \\nDbContext objects. EF DbContext implements both the Repository and the Unit of Work patterns\", \". \\nThe Repository pattern \\nThe Repository pattern is a Domain-Driven Design pattern intended to keep\", \" persistence concerns \\noutside of the system\\u2019s domain model. One or more persistence abstractions - \", \"interfaces - are defined \\n \\n239 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD a\", \"nd CQRS Patterns \\n \\nin the domain model, and these abstractions have implementations in the form of \", \"persistence-specific \\nadapters defined elsewhere in the application. \\nRepository implementations are\", \" classes that encapsulate the logic required to access data sources. \\nThey centralize common data ac\", \"cess functionality, providing better maintainability and decoupling \\nthe infrastructure or technolog\", \"y used to access databases from the domain model. If you use an \\nObject-Relational Mapper (ORM) like\", \" Entity Framework, the code that must be implemented is \\nsimplified, thanks to LINQ and strong typin\", \"g. This lets you focus on the data persistence logic rather \\nthan on data access plumbing. \\nThe Repo\", \"sitory pattern is a well-documented way of working with a data source. In the book Patterns \\nof Ente\", \"rprise Application Architecture, Martin Fowler describes a repository as follows: \\nA repository perf\", \"orms the tasks of an intermediary between the domain model layers and data \\nmapping, acting in a sim\", \"ilar way to a set of domain objects in memory. Client objects declaratively \\nbuild queries and send \", \"them to the repositories for answers. Conceptually, a repository encapsulates a \\nset of objects stor\", \"ed in the database and operations that can be performed on them, providing a way \\nthat is closer to \", \"the persistence layer. Repositories, also, support the purpose of separating, clearly \\nand in one di\", \"rection, the dependency between the work domain and the data allocation or mapping. \\nDefine one repo\", \"sitory per aggregate \\nFor each aggregate or aggregate root, you should create one repository class. \", \"You may be able to \\nleverage C# Generics to reduce the total number concrete classes you need to mai\", \"ntain (as \\ndemonstrated later in this chapter). In a microservice based on Domain-Driven Design (DDD\", \") patterns, \\nthe only channel you should use to update the database should be the repositories. This\", \" is because \\nthey have a one-to-one relationship with the aggregate root, which controls the aggrega\", \"te\\u2019s \\ninvariants and transactional consistency. It\\u2019s okay to query the database through other channe\", \"ls (as \\nyou can do following a CQRS approach), because queries don\\u2019t change the state of the databas\", \"e. \\nHowever, the transactional area (that is, the updates) must always be controlled by the reposito\", \"ries \\nand the aggregate roots. \\nBasically, a repository allows you to populate data in memory that c\", \"omes from the database in the \\nform of the domain entities. Once the entities are in memory, they ca\", \"n be changed and then persisted \\nback to the database through transactions. \\nAs noted earlier, if yo\", \"u\\u2019re using the CQS/CQRS architectural pattern, the initial queries are performed \\nby side queries ou\", \"t of the domain model, performed by simple SQL statements using Dapper. This \\napproach is much more \", \"flexible than repositories because you can query and join any tables you \\nneed, and these queries ar\", \"en\\u2019t restricted by rules from the aggregates. That data goes to the \\npresentation layer or client ap\", \"p. \\nIf the user makes changes, the data to be updated comes from the client app or presentation laye\", \"r to \\nthe application layer (such as a Web API service). When you receive a command in a command \\nha\", \"ndler, you use repositories to get the data you want to update from the database. You update it in \\n\", \"memory with the data passed with the commands, and you then add or update the data (domain \\nentities\", \") in the database through a transaction. \\n \\n240 \\nCHAPTER 6 | Tackle Business Complexity in a Microse\", \"rvice with DDD and CQRS Patterns \\n \\nIt\\u2019s important to emphasize again that you should only define on\", \"e repository for each aggregate root, \\nas shown in Figure 7-17. To achieve the goal of the aggregate\", \" root to maintain transactional \\nconsistency between all the objects within the aggregate, you shoul\", \"d never create a repository for \\neach table in the database. \\n \\nFigure 7-17. The relationship betwee\", \"n repositories, aggregates, and database tables \\nThe above diagram shows the relationships between D\", \"omain and Infrastructure layers: Buyer \\nAggregate depends on the IBuyerRepository and Order Aggregat\", \"e depends on the IOrderRepository \\ninterfaces, these interfaces are implemented in the Infrastructur\", \"e layer by the corresponding \\nrepositories that depend on UnitOfWork, also implemented there, that a\", \"ccesses the tables in the Data \\ntier. \\nEnforce one aggregate root per repository \\nIt can be valuable\", \" to implement your repository design in such a way that it enforces the rule that only \\naggregate ro\", \"ots should have repositories. You can create a generic or base repository type that \\nconstrains the \", \"type of entities it works with to ensure they have the IAggregateRoot marker interface. \\nThus, each \", \"repository class implemented at the infrastructure layer implements its own contract or \\ninterface, \", \"as shown in the following code: \\nnamespace Microsoft.eShopOnContainers.Services.Ordering.Infrastruct\", \"ure.Repositories \\n{ \\n    public class OrderRepository : IOrderRepository \\n    { \\n      // ... \\n \\n241\", \" \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    } \\n} \\nE\", \"ach specific repository interface implements the generic IRepository interface: \\npublic interface IO\", \"rderRepository : IRepository<Order> \\n{ \\n    Order Add(Order order); \\n    // ... \\n} \\nHowever, a bette\", \"r way to have the code enforce the convention that each repository is related to a \\nsingle aggregate\", \" is to implement a generic repository type. That way, it\\u2019s explicit that you\\u2019re using a \\nrepository \", \"to target a specific aggregate. That can be easily done by implementing a generic \\nIRepository base \", \"interface, as in the following code: \\npublic interface IRepository<T> where T : IAggregateRoot \\n{ \\n \", \"   //.... \\n} \\nThe Repository pattern makes it easier to test your application logic \\nThe Repository \", \"pattern allows you to easily test your application with unit tests. Remember that unit \\ntests only t\", \"est your code, not infrastructure, so the repository abstractions make it easier to achieve \\nthat go\", \"al. \\nAs noted in an earlier section, it\\u2019s recommended that you define and place the repository inter\", \"faces in \\nthe domain model layer so the application layer, such as your Web API microservice, doesn\\u2019\", \"t depend \\ndirectly on the infrastructure layer where you\\u2019ve implemented the actual repository classe\", \"s. By doing \\nthis and using Dependency Injection in the controllers of your Web API, you can impleme\", \"nt mock \\nrepositories that return fake data instead of data from the database. This decoupled approa\", \"ch allows \\nyou to create and run unit tests that focus the logic of your application without requiri\", \"ng connectivity \\nto the database. \\nConnections to databases can fail and, more importantly, running \", \"hundreds of tests against a \\ndatabase is bad for two reasons. First, it can take a long time because\", \" of the large number of tests. \\nSecond, the database records might change and impact the results of \", \"your tests, especially if your \\ntests are running in parallel, so that they might not be consistent.\", \" Unit tests typically can run in \\nparallel; integration tests may not support parallel execution dep\", \"ending on their implementation. \\nTesting against the database isn\\u2019t a unit test but an integration t\", \"est. You should have many unit tests \\nrunning fast, but fewer integration tests against the database\", \"s. \\nIn terms of separation of concerns for unit tests, your logic operates on domain entities in mem\", \"ory. It \\nassumes the repository class has delivered those. Once your logic modifies the domain entit\", \"ies, it \\nassumes the repository class will store them correctly. The important point here is to crea\", \"te unit tests \\nagainst your domain model and its domain logic. Aggregate roots are the main consiste\", \"ncy \\nboundaries in DDD. \\nThe repositories implemented in eShopOnContainers rely on EF Core\\u2019s DbConte\", \"xt implementation of \\nthe Repository and Unit of Work patterns using its change tracker, so they don\", \"\\u2019t duplicate this \\nfunctionality. \\n \\n242 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice w\", \"ith DDD and CQRS Patterns \\n \\nThe difference between the Repository pattern and the legacy Data Acces\", \"s class \\n(DAL class) pattern \\nA typical DAL object directly performs data access and persistence ope\", \"rations against storage, often \\nat the level of a single table and row. Simple CRUD operations imple\", \"mented with a set of DAL classes \\nfrequently do not support transactions (though this is not always \", \"the case). Most DAL class \\napproaches make minimal use of abstractions, resulting in tight coupling \", \"between application or \\nBusiness Logic Layer (BLL) classes that call the DAL objects. \\nWhen using re\", \"pository, the implementation details of persistence are encapsulated away from the \\ndomain model. Th\", \"e use of an abstraction provides ease of extending behavior through patterns like \\nDecorators or Pro\", \"xies. For instance, cross-cutting concerns like caching, logging, and error handling \\ncan all be app\", \"lied using these patterns rather than hard-coded in the data access code itself. It\\u2019s also \\ntrivial \", \"to support multiple repository adapters which may be used in different environments, from \\nlocal dev\", \"elopment to shared staging environments to production. \\nImplementing Unit of Work \\nA unit of work re\", \"fers to a single transaction that involves multiple insert, update, or delete operations. \\nIn simple\", \" terms, it means that for a specific user action, such as a registration on a website, all the \\ninse\", \"rt, update, and delete operations are handled in a single transaction. This is more efficient than \\n\", \"handling multiple database operations in a chattier way. \\nThese multiple persistence operations are \", \"performed later in a single action when your code from the \\napplication layer commands it. The decis\", \"ion about applying the in-memory changes to the actual \\ndatabase storage is typically based on the U\", \"nit of Work pattern. In EF, the Unit of Work pattern is \\nimplemented by a DbContext and is executed \", \"when a call is made to SaveChanges. \\nIn many cases, this pattern or way of applying operations again\", \"st the storage can increase application \\nperformance and reduce the possibility of inconsistencies. \", \"It also reduces transaction blocking in the \\ndatabase tables, because all the intended operations ar\", \"e committed as part of one transaction. This is \\nmore efficient in comparison to executing many isol\", \"ated operations against the database. Therefore, \\nthe selected ORM can optimize the execution agains\", \"t the database by grouping several update \\nactions within the same transaction, as opposed to many s\", \"mall and separate transaction executions. \\nThe Unit of Work pattern can be implemented with or witho\", \"ut using the Repository pattern. \\nRepositories shouldn\\u2019t be mandatory \\nCustom repositories are usefu\", \"l for the reasons cited earlier, and that is the approach for the ordering \\nmicroservice in eShopOnC\", \"ontainers. However, it isn\\u2019t an essential pattern to implement in a DDD \\ndesign or even in general .\", \"NET development. \\nFor instance, Jimmy Bogard, when providing direct feedback for this guide, said th\", \"e following: \\nThis\\u2019ll probably be my biggest feedback. I\\u2019m really not a fan of repositories, mainly \", \"because they hide \\nthe important details of the underlying persistence mechanism. It\\u2019s why I go for \", \"MediatR for \\ncommands, too. I can use the full power of the persistence layer, and push all that dom\", \"ain behavior \\ninto my aggregate roots. I don\\u2019t usually want to mock my repositories \\u2013 I still need t\", \"o have that \\n \\n243 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rns \\n \\nintegration test with the real thing. Going CQRS meant that we didn\\u2019t really have a need for \", \"\\nrepositories any more. \\nRepositories might be useful, but they are not critical for your DDD design\", \" in the way that the \\nAggregate pattern and a rich domain model are. Therefore, use the Repository p\", \"attern or not, as you \\nsee fit. \\nAdditional resources \\nRepository pattern \\n\\u2022 \\nEdward Hieatt and Rob \", \"Mee. Repository pattern. \\nhttps://martinfowler.com/eaaCatalog/repository.html \\n\\u2022 \\nThe Repository pat\", \"tern \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/ff649690(v=pandp.10) \\n\\u2022 \\nEric Evans. Dom\", \"ain-Driven Design: Tackling Complexity in the Heart of Software. (Book; \\nincludes a discussion of th\", \"e Repository pattern) \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/\", \"0321125215/ \\nUnit of Work pattern \\n\\u2022 \\nMartin Fowler. Unit of Work pattern. \\nhttps://martinfowler.com\", \"/eaaCatalog/unitOfWork.html \\n\\u2022 \\nImplementing the Repository and Unit of Work Patterns in an ASP.NET \", \"MVC \\nApplication \\nhttps://learn.microsoft.com/aspnet/mvc/overview/older-versions/getting-started-wit\", \"h-ef-5-\\nusing-mvc-4/implementing-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-\\napplica\", \"tion \\nImplement the infrastructure persistence layer with \\nEntity Framework Core \\nWhen you use relat\", \"ional databases such as SQL Server, Oracle, or PostgreSQL, a recommended \\napproach is to implement t\", \"he persistence layer based on Entity Framework (EF). EF supports LINQ and \\nprovides strongly typed o\", \"bjects for your model, as well as simplified persistence into your database. \\nEntity Framework has a\", \" long history as part of the .NET Framework. When you use .NET, you should \\nalso use Entity Framewor\", \"k Core, which runs on Windows or Linux in the same way as .NET. EF Core is a \\ncomplete rewrite of En\", \"tity Framework that\\u2019s implemented with a much smaller footprint and \\nimportant improvements in perfo\", \"rmance. \\n \\n244 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \", \"\\n \\nIntroduction to Entity Framework Core \\nEntity Framework (EF) Core is a lightweight, extensible, a\", \"nd cross-platform version of the popular \\nEntity Framework data access technology. It was introduced\", \" with .NET Core in mid-2016. \\nSince an introduction to EF Core is already available in Microsoft doc\", \"umentation, here we simply \\nprovide links to that information. \\nAdditional resources \\n\\u2022 \\nEntity Fram\", \"ework Core \\nhttps://learn.microsoft.com/ef/core/ \\n\\u2022 \\nGetting started with ASP.NET Core and Entity Fr\", \"amework Core using Visual Studio \\nhttps://learn.microsoft.com/aspnet/core/data/ef-mvc/ \\n\\u2022 \\nDbContext\", \" Class \\nhttps://learn.microsoft.com/dotnet/api/microsoft.entityframeworkcore.dbcontext \\n\\u2022 \\nCompare E\", \"F Core & EF6.x \\nhttps://learn.microsoft.com/ef/efcore-and-ef6/index \\nInfrastructure in Entity Framew\", \"ork Core from a DDD perspective \\nFrom a DDD point of view, an important capability of EF is the abil\", \"ity to use POCO domain entities, \\nalso known in EF terminology as POCO code-first entities. If you u\", \"se POCO domain entities, your \\ndomain model classes are persistence-ignorant, following the Persiste\", \"nce Ignorance and the \\nInfrastructure Ignorance principles. \\nPer DDD patterns, you should encapsulat\", \"e domain behavior and rules within the entity class itself, so \\nit can control invariants, validatio\", \"ns, and rules when accessing any collection. Therefore, it is not a \\ngood practice in DDD to allow p\", \"ublic access to collections of child entities or value objects. Instead, \\nyou want to expose methods\", \" that control how and when your fields and property collections can be \\nupdated, and what behavior a\", \"nd actions should occur when that happens. \\nSince EF Core 1.1, to satisfy those DDD requirements, yo\", \"u can have plain fields in your entities instead \\nof public properties. If you do not want an entity\", \" field to be externally accessible, you can just create \\nthe attribute or field instead of a propert\", \"y. You can also use private property setters. \\nIn a similar way, you can now have read-only access t\", \"o collections by using a public property typed as \\nIReadOnlyCollection<T>, which is backed by a priv\", \"ate field member for the collection (like a List<T>) \\nin your entity that relies on EF for persisten\", \"ce. Previous versions of Entity Framework required \\ncollection properties to support ICollection<T>,\", \" which meant that any developer using the parent \\nentity class could add or remove items through its\", \" property collections. That possibility would be \\nagainst the recommended patterns in DDD. \\nYou can \", \"use a private collection while exposing a read-only IReadOnlyCollection<T> object, as shown \\nin the \", \"following code example: \\npublic class Order : Entity \\n{ \\n \\n245 \\nCHAPTER 6 | Tackle Business Complexi\", \"ty in a Microservice with DDD and CQRS Patterns \\n \\n    // Using private fields, allowed since EF Cor\", \"e 1.1 \\n    private DateTime _orderDate; \\n    // Other fields ... \\n \\n    private readonly List<OrderI\", \"tem> _orderItems; \\n    public IReadOnlyCollection<OrderItem> OrderItems => _orderItems; \\n \\n    prote\", \"cted Order() { } \\n \\n    public Order(int buyerId, int paymentMethodId, Address address) \\n    { \\n    \", \"    // Initializations ... \\n    } \\n \\n    public void AddOrderItem(int productId, string productName,\", \" \\n                             decimal unitPrice, decimal discount, \\n                             st\", \"ring pictureUrl, int units = 1) \\n    { \\n        // Validation logic... \\n \\n        var orderItem = ne\", \"w OrderItem(productId, productName, \\n                                      unitPrice, discount, \\n   \", \"                                   pictureUrl, units); \\n        _orderItems.Add(orderItem); \\n    } \\n\", \"} \\nThe OrderItems property can only be accessed as read-only using IReadOnlyCollection<OrderItem>. \\n\", \"This type is read-only so it is protected against regular external updates. \\nEF Core provides a way \", \"to map the domain model to the physical database without \\u201ccontaminating\\u201d \\nthe domain model. It is pu\", \"re .NET POCO code, because the mapping action is implemented in the \\npersistence layer. In that mapp\", \"ing action, you need to configure the fields-to-database mapping. In \\nthe following example of the O\", \"nModelCreating method from OrderingContext and the \\nOrderEntityTypeConfiguration class, the call to \", \"SetPropertyAccessMode tells EF Core to access the \\nOrderItems property through its field. \\n// At Ord\", \"eringContext.cs from eShopOnContainers \\nprotected override void OnModelCreating(ModelBuilder modelBu\", \"ilder) \\n{ \\n   // ... \\n   modelBuilder.ApplyConfiguration(new OrderEntityTypeConfiguration()); \\n   //\", \" Other entities' configuration ... \\n} \\n \\n// At OrderEntityTypeConfiguration.cs from eShopOnContainer\", \"s \\nclass OrderEntityTypeConfiguration : IEntityTypeConfiguration<Order> \\n{ \\n    public void Configur\", \"e(EntityTypeBuilder<Order> orderConfiguration) \\n    { \\n        orderConfiguration.ToTable(\\\"orders\\\", \", \"OrderingContext.DEFAULT_SCHEMA); \\n        // Other configuration \\n \\n        var navigation = \\n      \", \"        orderConfiguration.Metadata.FindNavigation(nameof(Order.OrderItems)); \\n \\n        //EF access\", \" the OrderItem collection property through its backing field \\n        navigation.SetPropertyAccessMo\", \"de(PropertyAccessMode.Field); \\n \\n \\n246 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns \\n \\n        // Other configuration \\n    } \\n} \\nWhen you use fields instead of \", \"properties, the OrderItem entity is persisted as if it had a \\nList<OrderItem> property. However, it \", \"exposes a single accessor, the AddOrderItem method, for \\nadding new items to the order. As a result,\", \" behavior and data are tied together and will be consistent \\nthroughout any application code that us\", \"es the domain model. \\nImplement custom repositories with Entity Framework Core \\nAt the implementatio\", \"n level, a repository is simply a class with data persistence code coordinated by a \\nunit of work (D\", \"BContext in EF Core) when performing updates, as shown in the following class: \\n// using directives.\", \".. \\nnamespace Microsoft.eShopOnContainers.Services.Ordering.Infrastructure.Repositories \\n{ \\n    publ\", \"ic class BuyerRepository : IBuyerRepository \\n    { \\n        private readonly OrderingContext _contex\", \"t; \\n        public IUnitOfWork UnitOfWork \\n        { \\n            get \\n            { \\n              \", \"  return _context; \\n            } \\n        } \\n \\n        public BuyerRepository(OrderingContext conte\", \"xt) \\n        { \\n            _context = context ?? throw new ArgumentNullException(nameof(context)); \", \"\\n        } \\n \\n        public Buyer Add(Buyer buyer) \\n        { \\n            return _context.Buyers.A\", \"dd(buyer).Entity; \\n        } \\n \\n        public async Task<Buyer> FindAsync(string buyerIdentityGuid)\", \" \\n        { \\n            var buyer = await _context.Buyers \\n                .Include(b => b.Payments\", \") \\n                .Where(b => b.FullName == buyerIdentityGuid) \\n                .SingleOrDefaultAsy\", \"nc(); \\n \\n            return buyer; \\n        } \\n    } \\n} \\nThe IBuyerRepository interface comes from t\", \"he domain model layer as a contract. However, the \\nrepository implementation is done at the persiste\", \"nce and infrastructure layer. \\nThe EF DbContext comes through the constructor through Dependency Inj\", \"ection. It is shared between \\nmultiple repositories within the same HTTP request scope, thanks to it\", \"s default lifetime \\n(ServiceLifetime.Scoped) in the IoC container (which can also be explicitly set \", \"with \\nservices.AddDbContext<>). \\n \\n247 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns \\n \\nMethods to implement in a repository (updates or transactions versus quer\", \"ies) \\nWithin each repository class, you should put the persistence methods that update the state of \", \"entities \\ncontained by its related aggregate. Remember there is one-to-one relationship between an a\", \"ggregate \\nand its related repository. Consider that an aggregate root entity object might have embed\", \"ded child \\nentities within its EF graph. For example, a buyer might have multiple payment methods as\", \" related \\nchild entities. \\nSince the approach for the ordering microservice in eShopOnContainers is \", \"also based on CQS/CQRS, \\nmost of the queries are not implemented in custom repositories. Developers \", \"have the freedom to \\ncreate the queries and joins they need for the presentation layer without the r\", \"estrictions imposed by \\naggregates, custom repositories per aggregate, and DDD in general. Most of t\", \"he custom repositories \\nsuggested by this guide have several update or transactional methods but jus\", \"t the query methods \\nneeded to get data to be updated. For example, the BuyerRepository repository i\", \"mplements a \\nFindAsync method, because the application needs to know whether a particular buyer exis\", \"ts before \\ncreating a new buyer related to the order. \\nHowever, the real query methods to get data t\", \"o send to the presentation layer or client apps are \\nimplemented, as mentioned, in the CQRS queries \", \"based on flexible queries using Dapper. \\nUsing a custom repository versus using EF DbContext directl\", \"y \\nThe Entity Framework DbContext class is based on the Unit of Work and Repository patterns and can\", \" \\nbe used directly from your code, such as from an ASP.NET Core MVC controller. The Unit of Work and\", \" \\nRepository patterns result in the simplest code, as in the CRUD catalog microservice in \\neShopOnCo\", \"ntainers. In cases where you want the simplest code possible, you might want to directly \\nuse the Db\", \"Context class, as many developers do. \\nHowever, implementing custom repositories provides several be\", \"nefits when implementing more \\ncomplex microservices or applications. The Unit of Work and Repositor\", \"y patterns are intended to \\nencapsulate the infrastructure persistence layer so it is decoupled from\", \" the application and domain-\\nmodel layers. Implementing these patterns can facilitate the use of moc\", \"k repositories simulating \\naccess to the database. \\nIn Figure 7-18, you can see the differences betw\", \"een not using repositories (directly using the EF \\nDbContext) versus using repositories, which makes\", \" it easier to mock those repositories. \\n \\n248 \\nCHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS Patterns \\n \\n \\nFigure 7-18. Using custom repositories versus a plain DbContext \", \"\\nFigure 7-18 shows that using a custom repository adds an abstraction layer that can be used to ease\", \" \\ntesting by mocking the repository. There are multiple alternatives when mocking. You could mock ju\", \"st \\nrepositories or you could mock a whole unit of work. Usually mocking just the repositories is en\", \"ough, \\nand the complexity to abstract and mock a whole unit of work is usually not needed. \\nLater, w\", \"hen we focus on the application layer, you will see how Dependency Injection works in \\nASP.NET Core \", \"and how it is implemented when using repositories. \\nIn short, custom repositories allow you to test \", \"code more easily with unit tests that are not impacted \\nby the data tier state. If you run tests tha\", \"t also access the actual database through the Entity \\nFramework, they are not unit tests but integra\", \"tion tests, which are a lot slower. \\nIf you were using DbContext directly, you would have to mock it\", \" or to run unit tests by using an in-\\nmemory SQL Server with predictable data for unit tests. But mo\", \"cking the DbContext or controlling \\nfake data requires more work than mocking at the repository leve\", \"l. Of course, you could always test \\nthe MVC controllers. \\nEF DbContext and IUnitOfWork instance lif\", \"etime in your IoC container \\nThe DbContext object (exposed as an IUnitOfWork object) should be share\", \"d among multiple \\nrepositories within the same HTTP request scope. For example, this is true when th\", \"e operation being \\nexecuted must deal with multiple aggregates, or simply because you are using mult\", \"iple repository \\ninstances. It is also important to mention that the IUnitOfWork interface is part o\", \"f your domain layer, \\nnot an EF Core type. \\nIn order to do that, the instance of the DbContext objec\", \"t has to have its service lifetime set to \\nServiceLifetime.Scoped. This is the default lifetime when\", \" registering a DbContext with \\nbuilder.Services.AddDbContext in your IoC container from the Program.\", \"cs file in your ASP.NET Core \\nWeb API project. The following code illustrates this. \\n \\n249 \\nCHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n// Add framework serv\", \"ices. \\nbuilder.Services.AddMvc(options => \\n{ \\n    options.Filters.Add(typeof(HttpGlobalExceptionFilt\", \"er)); \\n}).AddControllersAsServices(); \\n \\nbuilder.Services.AddEntityFrameworkSqlServer() \\n    .AddDbC\", \"ontext<OrderingContext>(options => \\n    { \\n        options.UseSqlServer(Configuration[\\\"ConnectionStr\", \"ing\\\"], \\n                            sqlOptions => \\nsqlOptions.MigrationsAssembly(typeof(Startup).Get\", \"TypeInfo(). \\n                                                                                \\nAssemb\", \"ly.GetName().Name)); \\n    }, \\n    ServiceLifetime.Scoped // Note that Scoped is the default choice \\n\", \"                            // in AddDbContext. It is shown here only for \\n                         \", \"   // pedagogic purposes. \\n    ); \\nThe DbContext instantiation mode should not be configured as Serv\", \"iceLifetime.Transient or \\nServiceLifetime.Singleton. \\nThe repository instance lifetime in your IoC c\", \"ontainer \\nIn a similar way, repository\\u2019s lifetime should usually be set as scoped (InstancePerLifeti\", \"meScope in \\nAutofac). It could also be transient (InstancePerDependency in Autofac), but your servic\", \"e will be more \\nefficient in regards to memory when using the scoped lifetime. \\n// Registering a Rep\", \"ository in Autofac IoC container \\nbuilder.RegisterType<OrderRepository>() \\n    .As<IOrderRepository>\", \"() \\n    .InstancePerLifetimeScope(); \\nUsing the singleton lifetime for the repository could cause yo\", \"u serious concurrency problems when \\nyour DbContext is set to scoped (InstancePerLifetimeScope) life\", \"time (the default lifetimes for a \\nDBContext). As long as your service lifetimes for your repositori\", \"es and your DbContext are both \\nScoped, you\\u2019ll avoid these issues. \\nAdditional resources \\n\\u2022 \\nImpleme\", \"nting the Repository and Unit of Work Patterns in an ASP.NET MVC \\nApplication \\nhttps://www.asp.net/m\", \"vc/overview/older-versions/getting-started-with-ef-5-using-mvc-\\n4/implementing-the-repository-and-un\", \"it-of-work-patterns-in-an-asp-net-mvc-application \\n\\u2022 \\nJonathan Allen. Implementation Strategies for \", \"the Repository Pattern with Entity \\nFramework, Dapper, and Chain \\nhttps://www.infoq.com/articles/rep\", \"ository-implementation-strategies \\n\\u2022 \\nCesar de la Torre. Comparing ASP.NET Core IoC container servic\", \"e lifetimes with Autofac \\nIoC container instance scopes \\nhttps://devblogs.microsoft.com/cesardelator\", \"re/comparing-asp-net-core-ioc-service-life-\\ntimes-and-autofac-ioc-instance-scopes/ \\n \\n250 \\nCHAPTER 6\", \" | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nTable mapping \\nTable m\", \"apping identifies the table data to be queried from and saved to the database. Previously you \\nsaw h\", \"ow domain entities (for example, a product or order domain) can be used to generate a related \\ndatab\", \"ase schema. EF is strongly designed around the concept of conventions. Conventions address \\nquestion\", \"s like \\u201cWhat will the name of a table be?\\u201d or \\u201cWhat property is the primary key?\\u201d Conventions \\nare t\", \"ypically based on conventional names. For example, it is typical for the primary key to be a \\nproper\", \"ty that ends with Id. \\nBy convention, each entity will be set up to map to a table with the same nam\", \"e as the DbSet<TEntity> \\nproperty that exposes the entity on the derived context. If no DbSet<TEntit\", \"y> value is provided for \\nthe given entity, the class name is used. \\nData Annotations versus Fluent \", \"API \\nThere are many additional EF Core conventions, and most of them can be changed by using either \", \"\\ndata annotations or Fluent API, implemented within the OnModelCreating method. \\nData annotations mu\", \"st be used on the entity model classes themselves, which is a more intrusive way \\nfrom a DDD point o\", \"f view. This is because you are contaminating your model with data annotations \\nrelated to the infra\", \"structure database. On the other hand, Fluent API is a convenient way to change \\nmost conventions an\", \"d mappings within your data persistence infrastructure layer, so the entity model \\nwill be clean and\", \" decoupled from the persistence infrastructure. \\nFluent API and the OnModelCreating method \\nAs menti\", \"oned, in order to change conventions and mappings, you can use the OnModelCreating \\nmethod in the Db\", \"Context class. \\nThe ordering microservice in eShopOnContainers implements explicit mapping and confi\", \"guration, \\nwhen needed, as shown in the following code. \\n// At OrderingContext.cs from eShopOnContai\", \"ners \\nprotected override void OnModelCreating(ModelBuilder modelBuilder) \\n{ \\n   // ... \\n   modelBuil\", \"der.ApplyConfiguration(new OrderEntityTypeConfiguration()); \\n   // Other entities' configuration ...\", \" \\n} \\n \\n// At OrderEntityTypeConfiguration.cs from eShopOnContainers \\nclass OrderEntityTypeConfigurat\", \"ion : IEntityTypeConfiguration<Order> \\n{ \\n    public void Configure(EntityTypeBuilder<Order> orderCo\", \"nfiguration) \\n    { \\n        orderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_SCHEMA); \\n\", \" \\n        orderConfiguration.HasKey(o => o.Id); \\n \\n        orderConfiguration.Ignore(b => b.DomainEv\", \"ents); \\n \\n        orderConfiguration.Property(o => o.Id) \\n            .UseHiLo(\\\"orderseq\\\", OrderingC\", \"ontext.DEFAULT_SCHEMA); \\n \\n \\n251 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD \", \"and CQRS Patterns \\n \\n        //Address value object persisted as owned entity type supported since E\", \"F Core 2.0 \\n        orderConfiguration \\n            .OwnsOne(o => o.Address, a => \\n            { \\n  \", \"              a.WithOwner(); \\n            }); \\n \\n        orderConfiguration \\n            .Property<i\", \"nt?>(\\\"_buyerId\\\") \\n            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n            .HasColu\", \"mnName(\\\"BuyerId\\\") \\n            .IsRequired(false); \\n \\n        orderConfiguration \\n            .Prope\", \"rty<DateTime>(\\\"_orderDate\\\") \\n            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n         \", \"   .HasColumnName(\\\"OrderDate\\\") \\n            .IsRequired(); \\n \\n        orderConfiguration \\n          \", \"  .Property<int>(\\\"_orderStatusId\\\") \\n            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n  \", \"          .HasColumnName(\\\"OrderStatusId\\\") \\n            .IsRequired(); \\n \\n        orderConfiguration \", \"\\n            .Property<int?>(\\\"_paymentMethodId\\\") \\n            .UsePropertyAccessMode(PropertyAccessM\", \"ode.Field) \\n            .HasColumnName(\\\"PaymentMethodId\\\") \\n            .IsRequired(false); \\n \\n      \", \"  orderConfiguration.Property<string>(\\\"Description\\\").IsRequired(false); \\n \\n        var navigation = \", \"\\norderConfiguration.Metadata.FindNavigation(nameof(Order.OrderItems)); \\n \\n        // DDD Patterns co\", \"mment: \\n        //Set as field (New since EF 1.1) to access the OrderItem collection property \\nthrou\", \"gh its field \\n        navigation.SetPropertyAccessMode(PropertyAccessMode.Field); \\n \\n        orderCo\", \"nfiguration.HasOne<PaymentMethod>() \\n            .WithMany() \\n            .HasForeignKey(\\\"_paymentMe\", \"thodId\\\") \\n            .IsRequired(false) \\n            .OnDelete(DeleteBehavior.Restrict); \\n \\n       \", \" orderConfiguration.HasOne<Buyer>() \\n            .WithMany() \\n            .IsRequired(false) \\n      \", \"      .HasForeignKey(\\\"_buyerId\\\"); \\n \\n        orderConfiguration.HasOne(o => o.OrderStatus) \\n        \", \"    .WithMany() \\n            .HasForeignKey(\\\"_orderStatusId\\\"); \\n    } \\n} \\nYou could set all the Flue\", \"nt API mappings within the same OnModelCreating method, but it\\u2019s \\nadvisable to partition that code a\", \"nd have multiple configuration classes, one per entity, as shown in \\n \\n252 \\nCHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns \\n \\nthe example. Especially for large mod\", \"els, it is advisable to have separate configuration classes for \\nconfiguring different entity types.\", \" \\nThe code in the example shows a few explicit declarations and mapping. However, EF Core \\nconventio\", \"ns do many of those mappings automatically, so the actual code you would need in your \\ncase might be\", \" smaller. \\nThe Hi/Lo algorithm in EF Core \\nAn interesting aspect of code in the preceding example is\", \" that it uses the Hi/Lo algorithm as the key \\ngeneration strategy. \\nThe Hi/Lo algorithm is useful wh\", \"en you need unique keys before committing changes. As a summary, \\nthe Hi-Lo algorithm assigns unique\", \" identifiers to table rows while not depending on storing the row in \\nthe database immediately. This\", \" lets you start using the identifiers right away, as happens with regular \\nsequential database IDs. \", \"\\nThe Hi/Lo algorithm describes a mechanism for getting a batch of unique IDs from a related database\", \" \\nsequence. These IDs are safe to use because the database guarantees the uniqueness, so there will \", \"be \\nno collisions between users. This algorithm is interesting for these reasons: \\n\\u2022 \\nIt does not br\", \"eak the Unit of Work pattern. \\n\\u2022 \\nIt gets sequence IDs in batches, to minimize round trips to the da\", \"tabase. \\n\\u2022 \\nIt generates a human readable identifier, unlike techniques that use GUIDs. \\nEF Core sup\", \"ports HiLo with the UseHiLo method, as shown in the preceding example. \\nMap fields instead of proper\", \"ties \\nWith this feature, available since EF Core 1.1, you can directly map columns to fields. It is \", \"possible to \\nnot use properties in the entity class, and just to map columns from a table to fields.\", \" A common use \\nfor that would be private fields for any internal state that do not need to be access\", \"ed from outside the \\nentity. \\nYou can do this with single fields or also with collections, like a Li\", \"st<> field. This point was mentioned \\nearlier when we discussed modeling the domain model classes, b\", \"ut here you can see how that \\nmapping is performed with the PropertyAccessMode.Field configuration h\", \"ighlighted in the previous \\ncode. \\nUse shadow properties in EF Core, hidden at the infrastructure le\", \"vel \\nShadow properties in EF Core are properties that do not exist in your entity class model. The v\", \"alues \\nand states of these properties are maintained purely in the ChangeTracker class at the infras\", \"tructure \\nlevel. \\n \\n253 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS \", \"Patterns \\n \\nImplement the Query Specification pattern \\nAs introduced earlier in the design section, \", \"the Query Specification pattern is a Domain-Driven Design \\npattern designed as the place where you c\", \"an put the definition of a query with optional sorting and \\npaging logic. \\nThe Query Specification p\", \"attern defines a query in an object. For example, in order to encapsulate a \\npaged query that search\", \"es for some products you can create a PagedProduct specification that takes \\nthe necessary input par\", \"ameters (pageNumber, pageSize, filter, etc.). Then, within any Repository \\nmethod (usually a List() \", \"overload) it would accept an IQuerySpecification and run the expected query \\nbased on that specifica\", \"tion. \\nAn example of a generic Specification interface is the following code, which is similar to co\", \"de used in \\nthe eShopOnWeb reference application. \\n// GENERIC SPECIFICATION INTERFACE \\n// https://gi\", \"thub.com/dotnet-architecture/eShopOnWeb \\n \\npublic interface ISpecification<T> \\n{ \\n    Expression<Fun\", \"c<T, bool>> Criteria { get; } \\n    List<Expression<Func<T, object>>> Includes { get; } \\n    List<str\", \"ing> IncludeStrings { get; } \\n} \\nThen, the implementation of a generic specification base class is t\", \"he following. \\n// GENERIC SPECIFICATION IMPLEMENTATION (BASE CLASS) \\n// https://github.com/dotnet-ar\", \"chitecture/eShopOnWeb \\n \\npublic abstract class BaseSpecification<T> : ISpecification<T> \\n{ \\n    publ\", \"ic BaseSpecification(Expression<Func<T, bool>> criteria) \\n    { \\n        Criteria = criteria; \\n    }\", \" \\n    public Expression<Func<T, bool>> Criteria { get; } \\n \\n    public List<Expression<Func<T, objec\", \"t>>> Includes { get; } = \\n                                           new List<Expression<Func<T, obj\", \"ect>>>(); \\n \\n    public List<string> IncludeStrings { get; } = new List<string>(); \\n \\n    protected \", \"virtual void AddInclude(Expression<Func<T, object>> includeExpression) \\n    { \\n        Includes.Add(\", \"includeExpression); \\n    } \\n \\n    // string-based includes allow for including children of children \", \"\\n    // e.g. Basket.Items.Product \\n    protected virtual void AddInclude(string includeString) \\n    \", \"{ \\n        IncludeStrings.Add(includeString); \\n    } \\n} \\n \\n254 \\nCHAPTER 6 | Tackle Business Complexi\", \"ty in a Microservice with DDD and CQRS Patterns \\n \\nThe following specification loads a single basket\", \" entity given either the basket\\u2019s ID or the ID of the \\nbuyer to whom the basket belongs. It will eag\", \"erly load the basket\\u2019s Items collection. \\n// SAMPLE QUERY SPECIFICATION IMPLEMENTATION \\n \\npublic cla\", \"ss BasketWithItemsSpecification : BaseSpecification<Basket> \\n{ \\n    public BasketWithItemsSpecificat\", \"ion(int basketId) \\n        : base(b => b.Id == basketId) \\n    { \\n        AddInclude(b => b.Items); \\n\", \"    } \\n \\n    public BasketWithItemsSpecification(string buyerId) \\n        : base(b => b.BuyerId == b\", \"uyerId) \\n    { \\n        AddInclude(b => b.Items); \\n    } \\n} \\nAnd finally, you can see below how a ge\", \"neric EF Repository can use such a specification to filter and \\neager-load data related to a given e\", \"ntity type T. \\n// GENERIC EF REPOSITORY WITH SPECIFICATION \\n// https://github.com/dotnet-architectur\", \"e/eShopOnWeb \\n \\npublic IEnumerable<T> List(ISpecification<T> spec) \\n{ \\n    // fetch a Queryable that\", \" includes all expression-based includes \\n    var queryableResultWithIncludes = spec.Includes \\n      \", \"  .Aggregate(_dbContext.Set<T>().AsQueryable(), \\n            (current, include) => current.Include(i\", \"nclude)); \\n \\n    // modify the IQueryable to include any string-based include statements \\n    var se\", \"condaryResult = spec.IncludeStrings \\n        .Aggregate(queryableResultWithIncludes, \\n            (c\", \"urrent, include) => current.Include(include)); \\n \\n    // return the result of the query using the sp\", \"ecification's criteria expression \\n    return secondaryResult \\n                    .Where(spec.Crite\", \"ria) \\n                    .AsEnumerable(); \\n} \\nIn addition to encapsulating filtering logic, the spe\", \"cification can specify the shape of the data to be \\nreturned, including which properties to populate\", \". \\nAlthough we don\\u2019t recommend returning IQueryable from a repository, it\\u2019s perfectly fine to use th\", \"em \\nwithin the repository to build up a set of results. You can see this approach used in the List m\", \"ethod \\nabove, which uses intermediate IQueryable expressions to build up the query\\u2019s list of include\", \"s before \\nexecuting the query with the specification\\u2019s criteria on the last line. \\nLearn how the spe\", \"cification pattern is applied in the eShopOnWeb sample. \\n \\n255 \\nCHAPTER 6 | Tackle Business Complexi\", \"ty in a Microservice with DDD and CQRS Patterns \\n \\nAdditional resources \\n\\u2022 \\nTable Mapping \\nhttps://l\", \"earn.microsoft.com/ef/core/modeling/relational/tables \\n\\u2022 \\nUse HiLo to generate keys with Entity Fram\", \"ework Core \\nhttps://www.talkingdotnet.com/use-hilo-to-generate-keys-with-entity-framework-core/ \\n\\u2022 \\n\", \"Backing Fields \\nhttps://learn.microsoft.com/ef/core/modeling/backing-field \\n\\u2022 \\nSteve Smith. Encapsul\", \"ated Collections in Entity Framework Core \\nhttps://ardalis.com/encapsulated-collections-in-entity-fr\", \"amework-core \\n\\u2022 \\nShadow Properties \\nhttps://learn.microsoft.com/ef/core/modeling/shadow-properties \\n\", \"\\u2022 \\nThe Specification pattern \\nhttps://deviq.com/specification-pattern/ \\n  \\nArdalis.Specification NuG\", \"et Package Used by \\neShopOnWeb.  https://www.nuget.org/packages/Ardalis.Specification \\nUse NoSQL dat\", \"abases as a persistence infrastructure \\nWhen you use NoSQL databases for your infrastructure data ti\", \"er, you typically do not use an ORM like \\nEntity Framework Core. Instead you use the API provided by\", \" the NoSQL engine, such as Azure Cosmos \\nDB, MongoDB, Cassandra, RavenDB, CouchDB, or Azure Storage \", \"Tables. \\nHowever, when you use a NoSQL database, especially a document-oriented database like Azure \", \"\\nCosmos DB, CouchDB, or RavenDB, the way you design your model with DDD aggregates is partially \\nsim\", \"ilar to how you can do it in EF Core, in regards to the identification of aggregate roots, child ent\", \"ity \\nclasses, and value object classes. But, ultimately, the database selection will impact in your \", \"design. \\nWhen you use a document-oriented database, you implement an aggregate as a single document,\", \" \\nserialized in JSON or another format. However, the use of the database is transparent from a domai\", \"n \\nmodel code point of view. When using a NoSQL database, you still are using entity classes and \\nag\", \"gregate root classes, but with more flexibility than when using EF Core because the persistence is \\n\", \"not relational. \\nThe difference is in how you persist that model. If you implemented your domain mod\", \"el based on \\nPOCO entity classes, agnostic to the infrastructure persistence, it might look like you\", \" could move to a \\ndifferent persistence infrastructure, even from relational to NoSQL. However, that\", \" should not be your \\ngoal. There are always constraints and trade-offs in the different database tec\", \"hnologies, so you will \\nnot be able to have the same model for relational or NoSQL databases. Changi\", \"ng persistence models \\nis not a trivial task, because transactions and persistence operations will b\", \"e very different. \\nFor example, in a document-oriented database, it is okay for an aggregate root to\", \" have multiple child \\ncollection properties. In a relational database, querying multiple child colle\", \"ction properties is not \\n \\n256 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD an\", \"d CQRS Patterns \\n \\neasily optimized, because you get a UNION ALL SQL statement back from EF. Having \", \"the same \\ndomain model for relational databases or NoSQL databases is not simple, and you should not\", \" try to \\ndo it. You really have to design your model with an understanding of how the data is going \", \"to be \\nused in each particular database. \\nA benefit when using NoSQL databases is that the entities \", \"are more denormalized, so you do not set a \\ntable mapping. Your domain model can be more flexible th\", \"an when using a relational database. \\nWhen you design your domain model based on aggregates, moving \", \"to NoSQL and document-\\noriented databases might be even easier than using a relational database, bec\", \"ause the aggregates \\nyou design are similar to serialized documents in a document-oriented database.\", \" Then you can \\ninclude in those \\u201cbags\\u201d all the information you might need for that aggregate. \\nFor i\", \"nstance, the following JSON code is a sample implementation of an order aggregate when using \\na docu\", \"ment-oriented database. It is similar to the order aggregate we implemented in the \\neShopOnContainer\", \"s sample, but without using EF Core underneath. \\n{ \\n    \\\"id\\\": \\\"2024001\\\", \\n    \\\"orderDate\\\": \\\"2/25/202\", \"4\\\", \\n    \\\"buyerId\\\": \\\"1234567\\\", \\n    \\\"address\\\": [ \\n        { \\n        \\\"street\\\": \\\"100 One Microsoft Wa\", \"y\\\", \\n        \\\"city\\\": \\\"Redmond\\\", \\n        \\\"state\\\": \\\"WA\\\", \\n        \\\"zip\\\": \\\"98052\\\", \\n        \\\"country\\\":\", \" \\\"U.S.\\\" \\n        } \\n    ], \\n    \\\"orderItems\\\": [ \\n        {\\\"id\\\": 20240011, \\\"productId\\\": \\\"123456\\\", \\\"pr\", \"oductName\\\": \\\".NET T-Shirt\\\", \\n        \\\"unitPrice\\\": 25, \\\"units\\\": 2, \\\"discount\\\": 0}, \\n        {\\\"id\\\": 20\", \"240012, \\\"productId\\\": \\\"123457\\\", \\\"productName\\\": \\\".NET Mug\\\", \\n        \\\"unitPrice\\\": 15, \\\"units\\\": 1, \\\"dis\", \"count\\\": 0} \\n    ] \\n} \\nIntroduction to Azure Cosmos DB and the native Cosmos DB API \\nAzure Cosmos DB \", \"is Microsoft\\u2019s globally distributed database service for mission-critical applications. \\nAzure Cosmo\", \"s DB provides turn-key global distribution, elastic scaling of throughput and storage \\nworldwide, si\", \"ngle-digit millisecond latencies at the 99th percentile, five well-defined consistency \\nlevels, and \", \"guaranteed high availability, all backed by industry-leading SLAs. Azure Cosmos DB \\nautomatically in\", \"dexes data without requiring you to deal with schema and index management. It is \\nmulti-model and su\", \"pports document, key-value, graph, and columnar data models. \\n \\n257 \\nCHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS Patterns \\n \\n \\nFigure 7-19. Azure Cosmos DB global distri\", \"bution \\nWhen you use a C# model to implement the aggregate to be used by the Azure Cosmos DB API, th\", \"e \\naggregate can be similar to the C# POCO classes used with EF Core. The difference is in the way t\", \"o \\nuse them from the application and infrastructure layers, as in the following code: \\n// C# EXAMPLE\", \" OF AN ORDER AGGREGATE BEING PERSISTED WITH AZURE COSMOS DB API \\n// *** Domain Model Code *** \\n// Ag\", \"gregate: Create an Order object with its child entities and/or value objects. \\n// Then, use Aggregat\", \"eRoot's methods to add the nested objects so invariants and \\n// logic is consistent across the neste\", \"d properties (value objects and entities). \\n \\nOrder orderAggregate = new Order \\n{ \\n    Id = \\\"2024001\", \"\\\", \\n    OrderDate = new DateTime(2005, 7, 1), \\n    BuyerId = \\\"1234567\\\", \\n    PurchaseOrderNumber = \\\"\", \"PO18009186470\\\" \\n} \\n \\nAddress address = new Address \\n{ \\n    Street = \\\"100 One Microsoft Way\\\", \\n    Ci\", \"ty = \\\"Redmond\\\", \\n    State = \\\"WA\\\", \\n    Zip = \\\"98052\\\", \\n    Country = \\\"U.S.\\\" \\n} \\n \\norderAggregate.Up\", \"dateAddress(address); \\n \\nOrderItem orderItem1 = new OrderItem \\n{ \\n \\n258 \\nCHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    Id = 20240011, \\n    ProductId = \\\"123\", \"456\\\", \\n    ProductName = \\\".NET T-Shirt\\\", \\n    UnitPrice = 25, \\n    Units = 2, \\n    Discount = 0; \\n};\", \" \\n \\n//Using methods with domain logic within the entity. No anemic-domain model \\norderAggregate.AddO\", \"rderItem(orderItem1); \\n// *** End of Domain Model Code *** \\n \\n// *** Infrastructure Code using Cosmo\", \"s DB Client API *** \\nUri collectionUri = UriFactory.CreateDocumentCollectionUri(databaseName, \\n    c\", \"ollectionName); \\n \\nawait client.CreateDocumentAsync(collectionUri, orderAggregate); \\n \\n// As your ap\", \"p evolves, let's say your object has a new schema. You can insert \\n// OrderV2 objects without any ch\", \"anges to the database tier. \\nOrder2 newOrder = GetOrderV2Sample(\\\"IdForSalesOrder2\\\"); \\nawait client.C\", \"reateDocumentAsync(collectionUri, newOrder); \\nYou can see that the way you work with your domain mod\", \"el can be similar to the way you use it in \\nyour domain model layer when the infrastructure is EF. Y\", \"ou still use the same aggregate root methods \\nto ensure consistency, invariants, and validations wit\", \"hin the aggregate. \\nHowever, when you persist your model into the NoSQL database, the code and API c\", \"hange \\ndramatically compared to EF Core code or any other code related to relational databases. \\nImp\", \"lement .NET code targeting MongoDB and Azure Cosmos DB \\nUse Azure Cosmos DB from .NET containers \\nYo\", \"u can access Azure Cosmos DB databases from .NET code running in containers, like from any other \\n.N\", \"ET application. For instance, the Locations.API and Marketing.API microservices in \\neShopOnContainer\", \"s are implemented so they can consume Azure Cosmos DB databases. \\nHowever, there\\u2019s a limitation in A\", \"zure Cosmos DB from a Docker development environment point of \\nview. Even though there\\u2019s an on-premi\", \"ses Azure Cosmos DB Emulator that can run in a local \\ndevelopment machine, it only supports Windows.\", \" Linux and macOS aren\\u2019t supported. \\nThere\\u2019s also the possibility to run this emulator on Docker, but\", \" just on Windows Containers, not with \\nLinux Containers. That\\u2019s an initial handicap for the developm\", \"ent environment if your application is \\ndeployed as Linux containers, since, currently, you can\\u2019t de\", \"ploy Linux and Windows Containers on \\nDocker for Windows at the same time. Either all containers bei\", \"ng deployed have to be for Linux or for \\nWindows. \\nThe ideal and more straightforward deployment for\", \" a dev/test solution is to be able to deploy your \\ndatabase systems as containers along with your cu\", \"stom containers so your dev/test environments are \\nalways consistent. \\n \\n259 \\nCHAPTER 6 | Tackle Bus\", \"iness Complexity in a Microservice with DDD and CQRS Patterns \\n \\nUse MongoDB API for local dev/test \", \"Linux/Windows containers plus Azure Cosmos \\nDB \\nCosmos DB databases support MongoDB API for .NET as \", \"well as the native MongoDB wire protocol. \\nThis means that by using existing drivers, your applicati\", \"on written for MongoDB can now \\ncommunicate with Cosmos DB and use Cosmos DB databases instead of Mo\", \"ngoDB databases, as \\nshown in Figure 7-20. \\n \\nFigure 7-20. Using MongoDB API and protocol to access \", \"Azure Cosmos DB \\nThis is a very convenient approach for proof of concepts in Docker environments wit\", \"h Linux \\ncontainers because the MongoDB Docker image is a multi-arch image that supports Docker Linu\", \"x \\ncontainers and Docker Windows containers. \\nAs shown in the following image, by using the MongoDB \", \"API, eShopOnContainers supports MongoDB \\nLinux and Windows containers for the local development envi\", \"ronment but then, you can move to a \\nscalable, PaaS cloud solution as Azure Cosmos DB by simply chan\", \"ging the MongoDB connection \\nstring to point to Azure Cosmos DB. \\n \\n260 \\nCHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS Patterns \\n \\n \\nFigure 7-21. eShopOnContainers using M\", \"ongoDB containers for dev-env or Azure Cosmos DB for production \\nThe production Azure Cosmos DB woul\", \"d be running in Azure\\u2019s cloud as a PaaS and scalable service. \\nYour custom .NET containers can run o\", \"n a local development Docker host (that is using Docker for \\nWindows in a Windows 10 machine) or be \", \"deployed into a production environment, like Kubernetes in \\nAzure AKS or Azure Service Fabric. In th\", \"is second environment, you would deploy only the .NET \\ncustom containers but not the MongoDB contain\", \"er since you\\u2019d be using Azure Cosmos DB in the \\ncloud for handling the data in production. \\nA clear \", \"benefit of using the MongoDB API is that your solution could run in both database engines, \\nMongoDB \", \"or Azure Cosmos DB, so migrations to different environments should be easy. However, \\nsometimes it i\", \"s worthwhile to use a native API (that is the native Cosmos DB API) in order to take full \\nadvantage\", \" of the capabilities of a specific database engine. \\nFor further comparison between simply using Mon\", \"goDB versus Cosmos DB in the cloud, see the \\nBenefits of using Azure Cosmos DB in this page. \\nAnalyz\", \"e your approach for production applications: MongoDB API vs. Cosmos DB \\nAPI \\nIn eShopOnContainers, w\", \"e\\u2019re using MongoDB API because our priority was fundamentally to have a \\nconsistent dev/test environ\", \"ment using a NoSQL database that could also work with Azure Cosmos DB. \\n \\n261 \\nCHAPTER 6 | Tackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS Patterns \\n \\nHowever, if you are planning to us\", \"e MongoDB API to access Azure Cosmos DB in Azure for \\nproduction applications, you should analyze th\", \"e differences in capabilities and performance when \\nusing MongoDB API to access Azure Cosmos DB data\", \"bases compared to using the native Azure \\nCosmos DB API. If it is similar you can use MongoDB API an\", \"d you get the benefit of supporting two \\nNoSQL database engines at the same time. \\nYou could also us\", \"e MongoDB clusters as the production database in Azure\\u2019s cloud, too, with \\nMongoDB Azure Service. Bu\", \"t that is not a PaaS service provided by Microsoft. In this case, Azure is just \\nhosting that soluti\", \"on coming from MongoDB. \\nBasically, this is just a disclaimer stating that you shouldn\\u2019t always use \", \"MongoDB API against Azure \\nCosmos DB, as we did in eShopOnContainers because it was a convenient cho\", \"ice for Linux containers. \\nThe decision should be based on the specific needs and tests you need to \", \"do for your production \\napplication. \\nThe code: Use MongoDB API in .NET applications \\nMongoDB API fo\", \"r .NET is based on NuGet packages that you need to add to your projects, like in the \\nLocations.API \", \"project shown in the following figure. \\n \\n262 \\nCHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS Patterns \\n \\n \\nFigure 7-22. MongoDB API NuGet packages references in a .NET pro\", \"ject \\nLet\\u2019s investigate the code in the following sections. \\nA Model used by MongoDB API \\nFirst, you\", \" need to define a model that will hold the data coming from the database in your \\napplication\\u2019s memo\", \"ry space. Here\\u2019s an example of the model used for Locations at \\neShopOnContainers. \\nusing MongoDB.Bs\", \"on; \\nusing MongoDB.Bson.Serialization.Attributes; \\nusing MongoDB.Driver.GeoJsonObjectModel; \\nusing S\", \"ystem.Collections.Generic; \\n \\npublic class Locations \\n{ \\n \\n263 \\nCHAPTER 6 | Tackle Business Complexi\", \"ty in a Microservice with DDD and CQRS Patterns \\n \\n    [BsonId] \\n    [BsonRepresentation(BsonType.Ob\", \"jectId)] \\n    public string Id { get; set; } \\n    public int LocationId { get; set; } \\n    public st\", \"ring Code { get; set; } \\n    [BsonRepresentation(BsonType.ObjectId)] \\n    public string Parent_Id { \", \"get; set; } \\n    public string Description { get; set; } \\n    public double Latitude { get; set; } \\n\", \"    public double Longitude { get; set; } \\n    public GeoJsonPoint<GeoJson2DGeographicCoordinates> L\", \"ocation \\n                                                             { get; private set; } \\n    pub\", \"lic GeoJsonPolygon<GeoJson2DGeographicCoordinates> Polygon \\n                                        \", \"                     { get; private set; } \\n    public void SetLocation(double lon, double lat) => S\", \"etPosition(lon, lat); \\n    public void SetArea(List<GeoJson2DGeographicCoordinates> coordinatesList)\", \" \\n                                                    => SetPolygon(coordinatesList); \\n \\n    private\", \" void SetPosition(double lon, double lat) \\n    { \\n        Latitude = lat; \\n        Longitude = lon; \", \"\\n        Location = new GeoJsonPoint<GeoJson2DGeographicCoordinates>( \\n            new GeoJson2DGeog\", \"raphicCoordinates(lon, lat)); \\n    } \\n \\n    private void SetPolygon(List<GeoJson2DGeographicCoordina\", \"tes> coordinatesList) \\n    { \\n        Polygon = new GeoJsonPolygon<GeoJson2DGeographicCoordinates>( \", \"\\n                  new GeoJsonPolygonCoordinates<GeoJson2DGeographicCoordinates>( \\n                 \", \" new GeoJsonLinearRingCoordinates<GeoJson2DGeographicCoordinates>( \\n                                \", \"                                 coordinatesList))); \\n    } \\n} \\nYou can see there are a few attribut\", \"es and types coming from the MongoDB NuGet packages. \\nNoSQL databases are usually very well suited f\", \"or working with non-relational hierarchical data. In this \\nexample, we are using MongoDB types espec\", \"ially made for geo-locations, like \\nGeoJson2DGeographicCoordinates. \\nRetrieve the database and the c\", \"ollection \\nIn eShopOnContainers, we have created a custom database context where we implement the co\", \"de to \\nretrieve the database and the MongoCollections, as in the following code. \\npublic class Locat\", \"ionsContext \\n{ \\n    private readonly IMongoDatabase _database = null; \\n \\n    public LocationsContext\", \"(IOptions<LocationSettings> settings) \\n    { \\n        var client = new MongoClient(settings.Value.Co\", \"nnectionString); \\n        if (client != null) \\n            _database = client.GetDatabase(settings.V\", \"alue.Database); \\n    } \\n \\n    public IMongoCollection<Locations> Locations \\n    { \\n \\n264 \\nCHAPTER 6 \", \"| Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n        get \\n        { \", \"\\n            return _database.GetCollection<Locations>(\\\"Locations\\\"); \\n        } \\n    } \\n} \\nRetrieve \", \"the data \\nIn C# code, like Web API controllers or custom Repositories implementation, you can write \", \"similar \\ncode to the following when querying through the MongoDB API. Note that the _context object \", \"is an \\ninstance of the previous LocationsContext class. \\npublic async Task<Locations> GetAsync(int l\", \"ocationId) \\n{ \\n    var filter = Builders<Locations>.Filter.Eq(\\\"LocationId\\\", locationId); \\n    return\", \" await _context.Locations \\n                            .Find(filter) \\n                            .F\", \"irstOrDefaultAsync(); \\n} \\nUse an env-var in the docker-compose.override.yml file for the MongoDB con\", \"nection \\nstring \\nWhen creating a MongoClient object, it needs a fundamental parameter which is preci\", \"sely the \\nConnectionString parameter pointing to the right database. In the case of eShopOnContainer\", \"s, the \\nconnection string can point to a local MongoDB Docker container or to a \\u201cproduction\\u201d Azure C\", \"osmos \\nDB database. That connection string comes from the environment variables defined in the docke\", \"r-\\ncompose.override.yml files used when deploying with docker-compose or Visual Studio, as in the \\nf\", \"ollowing yml code. \\n# docker-compose.override.yml \\nversion: '3.4' \\nservices: \\n  # Other services \\n  \", \"locations-api: \\n    environment: \\n      # Other settings \\n      - ConnectionString=${ESHOP_AZURE_COS\", \"MOSDB:-mongodb://nosqldata} \\nThe ConnectionString environment variable is resolved this way: If the \", \"ESHOP_AZURE_COSMOSDB \\nglobal variable is defined in the .env file with the Azure Cosmos DB connectio\", \"n string, it will use it to \\naccess the Azure Cosmos DB database in the cloud. If it\\u2019s not defined, \", \"it will take the \\nmongodb://nosqldata value and use the development MongoDB container. \\nThe followin\", \"g code shows the .env file with the Azure Cosmos DB connection string global \\nenvironment variable, \", \"as implemented in eShopOnContainers: \\n# .env file, in eShopOnContainers root folder \\n# Other Docker \", \"environment variables \\n \\nESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker.internal \\nESHOP_PROD_EXTERNAL_DNS\", \"_NAME_OR_IP=<YourDockerHostIP> \\n \\n#ESHOP_AZURE_COSMOSDB=<YourAzureCosmosDBConnData> \\n \\n265 \\nCHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n \\n#Other environment \", \"variables for additional Azure infrastructure assets \\n#ESHOP_AZURE_REDIS_BASKET_DB=<YourAzureRedisBa\", \"sketInfo> \\n#ESHOP_AZURE_STORAGE_CATALOG_URL=<YourAzureStorage_Catalog_BLOB_URL> \\n#ESHOP_AZURE_SERVIC\", \"E_BUS=<YourAzureServiceBusInfo> \\nUncomment the ESHOP_AZURE_COSMOSDB line and update it with your Azu\", \"re Cosmos DB \\nconnection string obtained from the Azure portal as explained in Connect a MongoDB app\", \"lication to \\nAzure Cosmos DB. \\nIf the ESHOP_AZURE_COSMOSDB global variable is empty, meaning it\\u2019s co\", \"mmented out in the .env \\nfile, then the container uses a default MongoDB connection string. This con\", \"nection string points to \\nthe local MongoDB container deployed in eShopOnContainers that is named no\", \"sqldata and was \\ndefined at the docker-compose file, as shown in the following .yml code: \\n# docker-\", \"compose.yml \\nversion: '3.4' \\nservices: \\n  # ...Other services... \\n  nosqldata: \\n    image: mongo \\nAd\", \"ditional resources \\n\\u2022 \\nModeling document data for NoSQL databases \\nhttps://learn.microsoft.com/azure\", \"/cosmos-db/modeling-data \\n\\u2022 \\nVaughn Vernon. The Ideal Domain-Driven Design Aggregate Store? \\nhttps:/\", \"/kalele.io/blog-posts/the-ideal-domain-driven-design-aggregate-store/ \\n\\u2022 \\nIntroduction to Azure Cosm\", \"os DB: API for MongoDB \\nhttps://learn.microsoft.com/azure/cosmos-db/mongodb-introduction \\n\\u2022 \\nAzure C\", \"osmos DB: Build a MongoDB API web app with .NET and the Azure portal \\nhttps://learn.microsoft.com/az\", \"ure/cosmos-db/create-mongodb-dotnet \\n\\u2022 \\nUse the Azure Cosmos DB Emulator for local development and t\", \"esting \\nhttps://learn.microsoft.com/azure/cosmos-db/local-emulator \\n\\u2022 \\nConnect a MongoDB application\", \" to Azure Cosmos DB \\nhttps://learn.microsoft.com/azure/cosmos-db/connect-mongodb-account \\n\\u2022 \\nThe Cos\", \"mos DB Emulator Docker image (Windows Container) \\nhttps://hub.docker.com/r/microsoft/azure-cosmosdb-\", \"emulator/ \\n\\u2022 \\nThe MongoDB Docker image (Linux and Windows Container) \\nhttps://hub.docker.com/_/mongo\", \"/ \\n\\u2022 \\nUse MongoChef (Studio 3T) with an Azure Cosmos DB: API for MongoDB account \\nhttps://learn.micr\", \"osoft.com/azure/cosmos-db/mongodb-mongochef \\n \\n266 \\nCHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS Patterns \\n \\nDesign the microservice application layer and Web \\nAPI \\nUse S\", \"OLID principles and Dependency Injection \\nSOLID principles are critical techniques to be used in any\", \" modern and mission-critical application, \\nsuch as developing a microservice with DDD patterns. SOLI\", \"D is an acronym that groups five \\nfundamental principles: \\n\\u2022 \\nSingle Responsibility principle \\n\\u2022 \\nOp\", \"en/closed principle \\n\\u2022 \\nLiskov substitution principle \\n\\u2022 \\nInterface Segregation principle \\n\\u2022 \\nDepend\", \"ency Inversion principle \\nSOLID is more about how you design your application or microservice intern\", \"al layers and about \\ndecoupling dependencies between them. It is not related to the domain, but to t\", \"he application\\u2019s \\ntechnical design. The final principle, the Dependency Inversion principle, allows \", \"you to decouple the \\ninfrastructure layer from the rest of the layers, which allows a better decoupl\", \"ed implementation of the \\nDDD layers. \\nDependency Injection (DI) is one way to implement the Depende\", \"ncy Inversion principle. It is a \\ntechnique for achieving loose coupling between objects and their d\", \"ependencies. Rather than directly \\ninstantiating collaborators, or using static references (that is,\", \" using new\\u2026), the objects that a class \\nneeds in order to perform its actions are provided to (or \\u201ci\", \"njected into\\u201d) the class. Most often, classes \\nwill declare their dependencies via their constructor\", \", allowing them to follow the Explicit \\nDependencies principle. Dependency Injection is usually base\", \"d on specific Inversion of Control (IoC) \\ncontainers. ASP.NET Core provides a simple built-in IoC co\", \"ntainer, but you can also use your favorite \\nIoC container, like Autofac or Ninject. \\nBy following t\", \"he SOLID principles, your classes will tend naturally to be small, well-factored, and easily \\ntested\", \". But how can you know if too many dependencies are being injected into your classes? If you \\nuse DI\", \" through the constructor, it will be easy to detect that by just looking at the number of \\nparameter\", \"s for your constructor. If there are too many dependencies, this is generally a sign (a code \\nsmell)\", \" that your class is trying to do too much, and is probably violating the Single Responsibility \\nprin\", \"ciple. \\nIt would take another guide to cover SOLID in detail. Therefore, this guide requires you to \", \"have only a \\nminimum knowledge of these topics. \\nAdditional resources \\n\\u2022 \\nSOLID: Fundamental OOP Pri\", \"nciples \\nhttps://deviq.com/solid/ \\n \\n267 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice w\", \"ith DDD and CQRS Patterns \\n \\n\\u2022 \\nInversion of Control Containers and the Dependency Injection pattern\", \" \\nhttps://martinfowler.com/articles/injection.html \\n\\u2022 \\nSteve Smith. New is Glue \\nhttps://ardalis.com\", \"/new-is-glue \\nImplement the microservice application layer using \\nthe Web API \\nUse Dependency Inject\", \"ion to inject infrastructure objects into your \\napplication layer \\nAs mentioned previously, the appl\", \"ication layer can be implemented as part of the artifact (assembly) \\nyou are building, such as withi\", \"n a Web API project or an MVC web app project. In the case of a \\nmicroservice built with ASP.NET Cor\", \"e, the application layer will usually be your Web API library. If you \\nwant to separate what is comi\", \"ng from ASP.NET Core (its infrastructure plus your controllers) from your \\ncustom application layer \", \"code, you could also place your application layer in a separate class library, \\nbut that is optional\", \". \\nFor instance, the application layer code of the ordering microservice is directly implemented as \", \"part of \\nthe Ordering.API project (an ASP.NET Core Web API project), as shown in Figure 7-23. \\n \\nFig\", \"ure 7-23. The application layer in the Ordering.API ASP.NET Core Web API project \\nASP.NET Core inclu\", \"des a simple built-in IoC container (represented by the IServiceProvider interface) \\nthat supports c\", \"onstructor injection by default, and ASP.NET makes certain services available through \\nDI. ASP.NET C\", \"ore uses the term service for any of the types you register that will be injected through \\nDI. You c\", \"onfigure the built-in container\\u2019s services in your application\\u2019s Program.cs file. Your \\n \\n268 \\nCHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\ndependencies are i\", \"mplemented in the services that a type needs and that you register in the IoC \\ncontainer. \\nTypically\", \", you want to inject dependencies that implement infrastructure objects. A typical \\ndependency to in\", \"ject is a repository. But you could inject any other infrastructure dependency that \\nyou may have. F\", \"or simpler implementations, you could directly inject your Unit of Work pattern object \\n(the EF DbCo\", \"ntext object), because the DBContext is also the implementation of your infrastructure \\npersistence \", \"objects. \\nIn the following example, you can see how .NET is injecting the required repository object\", \"s through \\nthe constructor. The class is a command handler, which will get covered in the next secti\", \"on. \\npublic class CreateOrderCommandHandler \\n        : IRequestHandler<CreateOrderCommand, bool> \\n{ \", \"\\n    private readonly IOrderRepository _orderRepository; \\n    private readonly IIdentityService _ide\", \"ntityService; \\n    private readonly IMediator _mediator; \\n    private readonly IOrderingIntegrationE\", \"ventService _orderingIntegrationEventService; \\n    private readonly ILogger<CreateOrderCommandHandle\", \"r> _logger; \\n \\n    // Using DI to inject infrastructure persistence Repositories \\n    public CreateO\", \"rderCommandHandler(IMediator mediator, \\n        IOrderingIntegrationEventService orderingIntegration\", \"EventService, \\n        IOrderRepository orderRepository, \\n        IIdentityService identityService, \", \"\\n        ILogger<CreateOrderCommandHandler> logger) \\n    { \\n        _orderRepository = orderReposito\", \"ry ?? throw new \\nArgumentNullException(nameof(orderRepository)); \\n        _identityService = identit\", \"yService ?? throw new \\nArgumentNullException(nameof(identityService)); \\n        _mediator = mediator\", \" ?? throw new ArgumentNullException(nameof(mediator)); \\n        _orderingIntegrationEventService = o\", \"rderingIntegrationEventService ?? throw new \\nArgumentNullException(nameof(orderingIntegrationEventSe\", \"rvice)); \\n        _logger = logger ?? throw new ArgumentNullException(nameof(logger)); \\n    } \\n \\n   \", \" public async Task<bool> Handle(CreateOrderCommand message, CancellationToken \\ncancellationToken) \\n \", \"   { \\n        // Add Integration event to clean the basket \\n        var orderStartedIntegrationEvent\", \" = new \\nOrderStartedIntegrationEvent(message.UserId); \\n        await \\n_orderingIntegrationEventServi\", \"ce.AddAndSaveEventAsync(orderStartedIntegrationEvent); \\n \\n        // Add/Update the Buyer AggregateR\", \"oot \\n        // DDD patterns comment: Add child entities and value-objects through the Order \\nAggreg\", \"ate-Root \\n        // methods and constructor so validations, invariants and business logic \\n        \", \"// make sure that consistency is preserved across the whole aggregate \\n        var address = new Add\", \"ress(message.Street, message.City, message.State, \\nmessage.Country, message.ZipCode); \\n        var o\", \"rder = new Order(message.UserId, message.UserName, address, \\nmessage.CardTypeId, message.CardNumber,\", \" message.CardSecurityNumber, message.CardHolderName, \\nmessage.CardExpiration); \\n \\n        foreach (v\", \"ar item in message.OrderItems) \\n \\n269 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with\", \" DDD and CQRS Patterns \\n \\n        { \\n            order.AddOrderItem(item.ProductId, item.ProductName\", \", item.UnitPrice, \\nitem.Discount, item.PictureUrl, item.Units); \\n        } \\n \\n        _logger.LogInf\", \"ormation(\\\"----- Creating Order - Order: {@Order}\\\", order); \\n \\n        _orderRepository.Add(order); \\n\", \" \\n        return await _orderRepository.UnitOfWork \\n            .SaveEntitiesAsync(cancellationToken\", \"); \\n    } \\n} \\nThe class uses the injected repositories to execute the transaction and persist the st\", \"ate changes. It \\ndoes not matter whether that class is a command handler, an ASP.NET Core Web API co\", \"ntroller \\nmethod, or a DDD Application Service. It is ultimately a simple class that uses repositori\", \"es, domain \\nentities, and other application coordination in a fashion similar to a command handler. \", \"Dependency \\nInjection works the same way for all the mentioned classes, as in the example using DI b\", \"ased on the \\nconstructor. \\nRegister the dependency implementation types and interfaces or abstractio\", \"ns \\nBefore you use the objects injected through constructors, you need to know where to register the\", \" \\ninterfaces and classes that produce the objects injected into your application classes through DI.\", \" (Like \\nDI based on the constructor, as shown previously.) \\nUse the built-in IoC container provided \", \"by ASP.NET Core \\nWhen you use the built-in IoC container provided by ASP.NET Core, you register the \", \"types you want \\nto inject in the Program.cs file, as in the following code: \\n// Register out-of-the-\", \"box framework services. \\nbuilder.Services.AddDbContext<CatalogContext>(c => \\n    c.UseSqlServer(Conf\", \"iguration[\\\"ConnectionString\\\"]), \\n    ServiceLifetime.Scoped); \\n \\nbuilder.Services.AddMvc(); \\n// Regi\", \"ster custom application dependencies. \\nbuilder.Services.AddScoped<IMyCustomRepository, MyCustomSQLRe\", \"pository>(); \\nThe most common pattern when registering types in an IoC container is to register a pa\", \"ir of types\\u2014an \\ninterface and its related implementation class. Then when you request an object from\", \" the IoC \\ncontainer through any constructor, you request an object of a certain type of interface. F\", \"or instance, in \\nthe previous example, the last line states that when any of your constructors have \", \"a dependency on \\nIMyCustomRepository (interface or abstraction), the IoC container will inject an in\", \"stance of the \\nMyCustomSQLServerRepository implementation class. \\nUse the Scrutor library for automa\", \"tic types registration \\nWhen using DI in .NET, you might want to be able to scan an assembly and aut\", \"omatically register its \\ntypes by convention. This feature is not currently available in ASP.NET Cor\", \"e. However, you can use the \\n \\n270 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DD\", \"D and CQRS Patterns \\n \\nScrutor library for that. This approach is convenient when you have dozens of\", \" types that need to be \\nregistered in your IoC container. \\nAdditional resources \\n\\u2022 \\nMatthew King. Re\", \"gistering services with Scrutor \\nhttps://www.mking.net/blog/registering-services-with-scrutor \\n\\u2022 \\nKr\", \"istian Hellang. Scrutor. GitHub repo. \\nhttps://github.com/khellang/Scrutor \\nUse Autofac as an IoC co\", \"ntainer \\nYou can also use additional IoC containers and plug them into the ASP.NET Core pipeline, as\", \" in the \\nordering microservice in eShopOnContainers, which uses Autofac. When using Autofac you typi\", \"cally \\nregister the types via modules, which allow you to split the registration types between multi\", \"ple files \\ndepending on where your types are, just as you could have the application types distribut\", \"ed across \\nmultiple class libraries. \\nFor example, the following is the Autofac application module f\", \"or the Ordering.API Web API project \\nwith the types you will want to inject. \\npublic class Applicati\", \"onModule : Autofac.Module \\n{ \\n    public string QueriesConnectionString { get; } \\n    public Applica\", \"tionModule(string qconstr) \\n    { \\n        QueriesConnectionString = qconstr; \\n    } \\n \\n    protecte\", \"d override void Load(ContainerBuilder builder) \\n    { \\n        builder.Register(c => new OrderQuerie\", \"s(QueriesConnectionString)) \\n            .As<IOrderQueries>() \\n            .InstancePerLifetimeScope\", \"(); \\n        builder.RegisterType<BuyerRepository>() \\n            .As<IBuyerRepository>() \\n         \", \"   .InstancePerLifetimeScope(); \\n        builder.RegisterType<OrderRepository>() \\n            .As<IO\", \"rderRepository>() \\n            .InstancePerLifetimeScope(); \\n        builder.RegisterType<RequestMan\", \"ager>() \\n            .As<IRequestManager>() \\n            .InstancePerLifetimeScope(); \\n   } \\n} \\nAuto\", \"fac also has a feature to scan assemblies and register types by name conventions. \\nThe registration \", \"process and concepts are very similar to the way you can register types with the built-\\nin ASP.NET C\", \"ore IoC container, but the syntax when using Autofac is a bit different. \\nIn the example code, the a\", \"bstraction IOrderRepository is registered along with the implementation \\nclass OrderRepository. This\", \" means that whenever a constructor is declaring a dependency through the \\n \\n271 \\nCHAPTER 6 | Tackle \", \"Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nIOrderRepository abstraction or \", \"interface, the IoC container will inject an instance of the \\nOrderRepository class. \\nThe instance sc\", \"ope type determines how an instance is shared between requests for the same service \\nor dependency. \", \"When a request is made for a dependency, the IoC container can return the following: \\n\\u2022 \\nA single in\", \"stance per lifetime scope (referred to in the ASP.NET Core IoC container as scoped). \\n\\u2022 \\nA new insta\", \"nce per dependency (referred to in the ASP.NET Core IoC container as transient). \\n\\u2022 \\nA single instan\", \"ce shared across all objects using the IoC container (referred to in the ASP.NET \\nCore IoC container\", \" as singleton). \\nAdditional resources \\n\\u2022 \\nIntroduction to Dependency Injection in ASP.NET Core \\nhttp\", \"s://learn.microsoft.com/aspnet/core/fundamentals/dependency-injection \\n\\u2022 \\nAutofac. Official document\", \"ation. \\nhttps://docs.autofac.org/en/latest/ \\n\\u2022 \\nComparing ASP.NET Core IoC container service lifetim\", \"es with Autofac IoC container \\ninstance scopes - Cesar de la Torre. \\nhttps://devblogs.microsoft.com/\", \"cesardelatorre/comparing-asp-net-core-ioc-service-life-\\ntimes-and-autofac-ioc-instance-scopes/ \\nImpl\", \"ement the Command and Command Handler patterns \\nIn the DI-through-constructor example shown in the p\", \"revious section, the IoC container was injecting \\nrepositories through a constructor in a class. But\", \" exactly where were they injected? In a simple Web \\nAPI (for example, the catalog microservice in eS\", \"hopOnContainers), you inject them at the MVC \\ncontrollers\\u2019 level, in a controller constructor, as pa\", \"rt of the request pipeline of ASP.NET Core. However, \\nin the initial code of this section (the Creat\", \"eOrderCommandHandler class from the Ordering.API \\nservice in eShopOnContainers), the injection of de\", \"pendencies is done through the constructor of a \\nparticular command handler. Let us explain what a c\", \"ommand handler is and why you would want to \\nuse it. \\nThe Command pattern is intrinsically related t\", \"o the CQRS pattern that was introduced earlier in this \\nguide. CQRS has two sides. The first area is\", \" queries, using simplified queries with the Dapper micro \\nORM, which was explained previously. The s\", \"econd area is commands, which are the starting point for \\ntransactions, and the input channel from o\", \"utside the service. \\nAs shown in Figure 7-24, the pattern is based on accepting commands from the cl\", \"ient-side, \\nprocessing them based on the domain model rules, and finally persisting the states with \", \"transactions. \\n \\n272 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pat\", \"terns \\n \\n \\nFigure 7-24. High-level view of the commands or \\u201ctransactional side\\u201d in a CQRS pattern \\nF\", \"igure 7-24 shows that the UI app sends a command through the API that gets to a \\nCommandHandler, tha\", \"t depends on the Domain model and the Infrastructure, to update the \\ndatabase. \\nThe command class \\nA\", \" command is a request for the system to perform an action that changes the state of the system. \\nCom\", \"mands are imperative, and should be processed just once. \\nSince commands are imperatives, they are t\", \"ypically named with a verb in the imperative mood (for \\nexample, \\u201ccreate\\u201d or \\u201cupdate\\u201d), and they mig\", \"ht include the aggregate type, such as \\nCreateOrderCommand. Unlike an event, a command is not a fact\", \" from the past; it is only a request, \\nand thus may be refused. \\nCommands can originate from the UI \", \"as a result of a user initiating a request, or from a process \\nmanager when the process manager is d\", \"irecting an aggregate to perform an action. \\nAn important characteristic of a command is that it sho\", \"uld be processed just once by a single receiver. \\nThis is because a command is a single action or tr\", \"ansaction you want to perform in the application. \\nFor example, the same order creation command shou\", \"ld not be processed more than once. This is an \\nimportant difference between commands and events. Ev\", \"ents may be processed multiple times, \\nbecause many systems or microservices might be interested in \", \"the event. \\nIn addition, it is important that a command be processed only once in case the command i\", \"s not \\nidempotent. A command is idempotent if it can be executed multiple times without changing the\", \" \\nresult, either because of the nature of the command, or because of the way the system handles the \", \"\\ncommand. \\nIt is a good practice to make your commands and updates idempotent when it makes sense un\", \"der \\nyour domain\\u2019s business rules and invariants. For instance, to use the same example, if for any \", \"reason \\n(retry logic, hacking, etc.) the same CreateOrder command reaches your system multiple times\", \", you \\nshould be able to identify it and ensure that you do not create multiple orders. To do so, yo\", \"u need to \\n \\n273 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pattern\", \"s \\n \\nattach some kind of identity in the operations and identify whether the command or update was \\n\", \"already processed. \\nYou send a command to a single receiver; you do not publish a command. Publishin\", \"g is for events \\nthat state a fact\\u2014that something has happened and might be interesting for event re\", \"ceivers. In the \\ncase of events, the publisher has no concerns about which receivers get the event o\", \"r what they do it. \\nBut domain or integration events are a different story already introduced in pre\", \"vious sections. \\nA command is implemented with a class that contains data fields or collections with\", \" all the \\ninformation that is needed in order to execute that command. A command is a special kind o\", \"f Data \\nTransfer Object (DTO), one that is specifically used to request changes or transactions. The\", \" command \\nitself is based on exactly the information that is needed for processing the command, and \", \"nothing \\nmore. \\nThe following example shows the simplified CreateOrderCommand class. This is an immu\", \"table \\ncommand that is used in the ordering microservice in eShopOnContainers. \\n// DDD and CQRS patt\", \"erns comment: Note that it is recommended to implement immutable \\nCommands \\n// In this case, its imm\", \"utability is achieved by having all the setters as private \\n// plus only being able to update the da\", \"ta just once, when creating the object through its \\nconstructor. \\n// References on Immutable Command\", \"s: \\n// http://cqrs.nu/Faq \\n// https://docs.spine3.org/motivation/immutability.html \\n// http://blog.g\", \"auffin.org/2012/06/griffin-container-introducing-command-support/ \\n// https://learn.microsoft.com/do\", \"tnet/csharp/programming-guide/classes-and-structs/how-to-\\nimplement-a-lightweight-class-with-auto-im\", \"plemented-properties \\n \\n[DataContract] \\npublic class CreateOrderCommand \\n    : IRequest<bool> \\n{ \\n  \", \"  [DataMember] \\n    private readonly List<OrderItemDTO> _orderItems; \\n \\n    [DataMember] \\n    public\", \" string UserId { get; private set; } \\n \\n    [DataMember] \\n    public string UserName { get; private \", \"set; } \\n \\n    [DataMember] \\n    public string City { get; private set; } \\n \\n    [DataMember] \\n    pu\", \"blic string Street { get; private set; } \\n \\n    [DataMember] \\n    public string State { get; private\", \" set; } \\n \\n    [DataMember] \\n    public string Country { get; private set; } \\n \\n    [DataMember] \\n  \", \"  public string ZipCode { get; private set; } \\n \\n    [DataMember] \\n \\n274 \\nCHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    public string CardNumber { get; pri\", \"vate set; } \\n \\n    [DataMember] \\n    public string CardHolderName { get; private set; } \\n \\n    [Data\", \"Member] \\n    public DateTime CardExpiration { get; private set; } \\n \\n    [DataMember] \\n    public st\", \"ring CardSecurityNumber { get; private set; } \\n \\n    [DataMember] \\n    public int CardTypeId { get; \", \"private set; } \\n \\n    [DataMember] \\n    public IEnumerable<OrderItemDTO> OrderItems => _orderItems; \", \"\\n \\n    public CreateOrderCommand() \\n    { \\n        _orderItems = new List<OrderItemDTO>(); \\n    } \\n \", \"\\n    public CreateOrderCommand(List<BasketItem> basketItems, string userId, string userName, \\nstring\", \" city, string street, string state, string country, string zipcode, \\n        string cardNumber, stri\", \"ng cardHolderName, DateTime cardExpiration, \\n        string cardSecurityNumber, int cardTypeId) : th\", \"is() \\n    { \\n        _orderItems = basketItems.ToOrderItemsDTO().ToList(); \\n        UserId = userId;\", \" \\n        UserName = userName; \\n        City = city; \\n        Street = street; \\n        State = stat\", \"e; \\n        Country = country; \\n        ZipCode = zipcode; \\n        CardNumber = cardNumber; \\n      \", \"  CardHolderName = cardHolderName; \\n        CardExpiration = cardExpiration; \\n        CardSecurityNu\", \"mber = cardSecurityNumber; \\n        CardTypeId = cardTypeId; \\n        CardExpiration = cardExpiratio\", \"n; \\n    } \\n \\n \\n    public class OrderItemDTO \\n    { \\n        public int ProductId { get; set; } \\n \\n \", \"       public string ProductName { get; set; } \\n \\n        public decimal UnitPrice { get; set; } \\n \\n\", \"        public decimal Discount { get; set; } \\n \\n        public int Units { get; set; } \\n \\n        p\", \"ublic string PictureUrl { get; set; } \\n    } \\n} \\n \\n275 \\nCHAPTER 6 | Tackle Business Complexity in a \", \"Microservice with DDD and CQRS Patterns \\n \\nBasically, the command class contains all the data you ne\", \"ed for performing a business transaction by \\nusing the domain model objects. Thus, commands are simp\", \"ly data structures that contain read-only \\ndata, and no behavior. The command\\u2019s name indicates its p\", \"urpose. In many languages like C#, \\ncommands are represented as classes, but they are not true class\", \"es in the real object-oriented sense. \\nAs an additional characteristic, commands are immutable, beca\", \"use the expected usage is that they are \\nprocessed directly by the domain model. They do not need to\", \" change during their projected lifetime. \\nIn a C# class, immutability can be achieved by not having \", \"any setters or other methods that change \\nthe internal state. \\nKeep in mind that if you intend or ex\", \"pect commands to go through a serializing/deserializing process, \\nthe properties must have a private\", \" setter, and the [DataMember] (or [JsonProperty]) attribute. \\nOtherwise, the deserializer won\\u2019t be a\", \"ble to reconstruct the object at the destination with the required \\nvalues. You can also use truly r\", \"ead-only properties if the class has a constructor with parameters for all \\nproperties, with the usu\", \"al camelCase naming convention, and annotate the constructor as \\n[JsonConstructor]. However, this op\", \"tion requires more code. \\nFor example, the command class for creating an order is probably similar i\", \"n terms of data to the order \\nyou want to create, but you probably do not need the same attributes. \", \"For instance, \\nCreateOrderCommand does not have an order ID, because the order has not been created \", \"yet. \\nMany command classes can be simple, requiring only a few fields about some state that needs to\", \" be \\nchanged. That would be the case if you are just changing the status of an order from \\u201cin proces\", \"s\\u201d to \\n\\u201cpaid\\u201d or \\u201cshipped\\u201d by using a command similar to the following: \\n[DataContract] \\npublic clas\", \"s UpdateOrderStatusCommand \\n    :IRequest<bool> \\n{ \\n    [DataMember] \\n    public string Status { get\", \"; private set; } \\n \\n    [DataMember] \\n    public string OrderId { get; private set; } \\n \\n    [DataMe\", \"mber] \\n    public string BuyerIdentityGuid { get; private set; } \\n} \\nSome developers make their UI r\", \"equest objects separate from their command DTOs, but that is just a \\nmatter of preference. It is a t\", \"edious separation with not much additional value, and the objects are \\nalmost exactly the same shape\", \". For instance, in eShopOnContainers, some commands come directly \\nfrom the client-side. \\nThe Comman\", \"d handler class \\nYou should implement a specific command handler class for each command. That is how\", \" the pattern \\nworks, and it\\u2019s where you\\u2019ll use the command object, the domain objects, and the infra\", \"structure \\nrepository objects. The command handler is in fact the heart of the application layer in \", \"terms of CQRS \\nand DDD. However, all the domain logic should be contained in the domain classes\\u2014with\", \"in the \\naggregate roots (root entities), child entities, or domain services, but not within the comm\", \"and handler, \\nwhich is a class from the application layer. \\n \\n276 \\nCHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS Patterns \\n \\nThe command handler class offers a strong step\", \"ping stone in the way to achieve the Single \\nResponsibility Principle (SRP) mentioned in a previous \", \"section. \\nA command handler receives a command and obtains a result from the aggregate that is used.\", \" The \\nresult should be either successful execution of the command, or an exception. In the case of a\", \"n \\nexception, the system state should be unchanged. \\nThe command handler usually takes the following\", \" steps: \\n\\u2022 \\nIt receives the command object, like a DTO (from the mediator or other infrastructure ob\", \"ject). \\n\\u2022 \\nIt validates that the command is valid (if not validated by the mediator). \\n\\u2022 \\nIt instant\", \"iates the aggregate root instance that is the target of the current command. \\n\\u2022 \\nIt executes the met\", \"hod on the aggregate root instance, getting the required data from the \\ncommand. \\n\\u2022 \\nIt persists the\", \" new state of the aggregate to its related database. This last operation is the \\nactual transaction.\", \" \\nTypically, a command handler deals with a single aggregate driven by its aggregate root (root enti\", \"ty). \\nIf multiple aggregates should be impacted by the reception of a single command, you could use \", \"\\ndomain events to propagate states or actions across multiple aggregates. \\nThe important point here \", \"is that when a command is being processed, all the domain logic should be \\ninside the domain model (\", \"the aggregates), fully encapsulated and ready for unit testing. The \\ncommand handler just acts as a \", \"way to get the domain model from the database, and as the final \\nstep, to tell the infrastructure la\", \"yer (repositories) to persist the changes when the model is changed. \\nThe advantage of this approach\", \" is that you can refactor the domain logic in an isolated, fully \\nencapsulated, rich, behavioral dom\", \"ain model without changing code in the application or \\ninfrastructure layers, which are the plumbing\", \" level (command handlers, Web API, repositories, etc.). \\nWhen command handlers get complex, with too\", \" much logic, that can be a code smell. Review them, \\nand if you find domain logic, refactor the code\", \" to move that domain behavior to the methods of the \\ndomain objects (the aggregate root and child en\", \"tity). \\nAs an example of a command handler class, the following code shows the same \\nCreateOrderComm\", \"andHandler class that you saw at the beginning of this chapter. In this case, it also \\nhighlights th\", \"e Handle method and the operations with the domain model objects/aggregates. \\npublic class CreateOrd\", \"erCommandHandler \\n        : IRequestHandler<CreateOrderCommand, bool> \\n{ \\n    private readonly IOrde\", \"rRepository _orderRepository; \\n    private readonly IIdentityService _identityService; \\n    private \", \"readonly IMediator _mediator; \\n    private readonly IOrderingIntegrationEventService _orderingIntegr\", \"ationEventService; \\n    private readonly ILogger<CreateOrderCommandHandler> _logger; \\n \\n    // Using\", \" DI to inject infrastructure persistence Repositories \\n    public CreateOrderCommandHandler(IMediato\", \"r mediator, \\n        IOrderingIntegrationEventService orderingIntegrationEventService, \\n        IOrd\", \"erRepository orderRepository, \\n \\n277 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patterns \\n \\n        IIdentityService identityService, \\n        ILogger<CreateOrderComma\", \"ndHandler> logger) \\n    { \\n        _orderRepository = orderRepository ?? throw new \\nArgumentNullExce\", \"ption(nameof(orderRepository)); \\n        _identityService = identityService ?? throw new \\nArgumentNu\", \"llException(nameof(identityService)); \\n        _mediator = mediator ?? throw new ArgumentNullExcepti\", \"on(nameof(mediator)); \\n        _orderingIntegrationEventService = orderingIntegrationEventService ??\", \" throw new \\nArgumentNullException(nameof(orderingIntegrationEventService)); \\n        _logger = logge\", \"r ?? throw new ArgumentNullException(nameof(logger)); \\n    } \\n \\n    public async Task<bool> Handle(C\", \"reateOrderCommand message, CancellationToken \\ncancellationToken) \\n    { \\n        // Add Integration \", \"event to clean the basket \\n        var orderStartedIntegrationEvent = new \\nOrderStartedIntegrationEv\", \"ent(message.UserId); \\n        await \\n_orderingIntegrationEventService.AddAndSaveEventAsync(orderStar\", \"tedIntegrationEvent); \\n \\n        // Add/Update the Buyer AggregateRoot \\n        // DDD patterns comm\", \"ent: Add child entities and value-objects through the Order \\nAggregate-Root \\n        // methods and \", \"constructor so validations, invariants and business logic \\n        // make sure that consistency is \", \"preserved across the whole aggregate \\n        var address = new Address(message.Street, message.City\", \", message.State, \\nmessage.Country, message.ZipCode); \\n        var order = new Order(message.UserId, \", \"message.UserName, address, \\nmessage.CardTypeId, message.CardNumber, message.CardSecurityNumber, mess\", \"age.CardHolderName, \\nmessage.CardExpiration); \\n \\n        foreach (var item in message.OrderItems) \\n \", \"       { \\n            order.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice, \\nitem.Dis\", \"count, item.PictureUrl, item.Units); \\n        } \\n \\n        _logger.LogInformation(\\\"----- Creating Or\", \"der - Order: {@Order}\\\", order); \\n \\n        _orderRepository.Add(order); \\n \\n        return await _ord\", \"erRepository.UnitOfWork \\n            .SaveEntitiesAsync(cancellationToken); \\n    } \\n} \\nThese are add\", \"itional steps a command handler should take: \\n\\u2022 \\nUse the command\\u2019s data to operate with the aggregat\", \"e root\\u2019s methods and behavior. \\n\\u2022 \\nInternally within the domain objects, raise domain events while t\", \"he transaction is executed, \\nbut that is transparent from a command handler point of view. \\n\\u2022 \\nIf th\", \"e aggregate\\u2019s operation result is successful and after the transaction is finished, raise \\nintegrati\", \"on events. (These might also be raised by infrastructure classes like repositories.) \\n \\n278 \\nCHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nAdditional resources\", \" \\n\\u2022 \\nMark Seemann. At the Boundaries, Applications are Not Object-Oriented \\nhttps://blog.ploeh.dk/20\", \"11/05/31/AttheBoundaries,ApplicationsareNotObject-Oriented/ \\n\\u2022 \\nCommands and events \\nhttps://cqrs.nu\", \"/faq/Command%20and%20Events \\n\\u2022 \\nWhat does a command handler do? \\nhttps://cqrs.nu/faq/Command%20Handl\", \"ers \\n\\u2022 \\nJimmy Bogard. Domain Command Patterns \\u2013 Handlers \\nhttps://jimmybogard.com/domain-command-pat\", \"terns-handlers/ \\n\\u2022 \\nJimmy Bogard. Domain Command Patterns \\u2013 Validation \\nhttps://jimmybogard.com/doma\", \"in-command-patterns-validation/ \\nThe Command process pipeline: how to trigger a command handler \\nThe\", \" next question is how to invoke a command handler. You could manually call it from each related \\nASP\", \".NET Core controller. However, that approach would be too coupled and is not ideal. \\nThe other two m\", \"ain options, which are the recommended options, are: \\n\\u2022 \\nThrough an in-memory Mediator pattern artif\", \"act. \\n\\u2022 \\nWith an asynchronous message queue, in between controllers and handlers. \\nUse the Mediator \", \"pattern (in-memory) in the command pipeline \\nAs shown in Figure 7-25, in a CQRS approach you use an \", \"intelligent mediator, similar to an in-memory \\nbus, which is smart enough to redirect to the right c\", \"ommand handler based on the type of the \\ncommand or DTO being received. The single black arrows betw\", \"een components represent the \\ndependencies between objects (in many cases, injected through DI) with\", \" their related interactions. \\n \\n279 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with D\", \"DD and CQRS Patterns \\n \\n \\nFigure 7-25. Using the Mediator pattern in process in a single CQRS micros\", \"ervice \\nThe above diagram shows a zoom-in from image 7-24: the ASP.NET Core controller sends the \\nco\", \"mmand to MediatR\\u2019s command pipeline, so they get to the appropriate handler. \\nThe reason that using \", \"the Mediator pattern makes sense is that in enterprise applications, the \\nprocessing requests can ge\", \"t complicated. You want to be able to add an open number of cross-\\ncutting concerns like logging, va\", \"lidations, audit, and security. In these cases, you can rely on a \\nmediator pipeline (see Mediator p\", \"attern) to provide a means for these extra behaviors or cross-\\ncutting concerns. \\nA mediator is an o\", \"bject that encapsulates the \\u201chow\\u201d of this process: it coordinates execution based on \\nstate, the way\", \" a command handler is invoked, or the payload you provide to the handler. With a \\nmediator component\", \", you can apply cross-cutting concerns in a centralized and transparent way by \\napplying decorators \", \"(or pipeline behaviors since MediatR 3). For more information, see the Decorator \\npattern. \\nDecorato\", \"rs and behaviors are similar to Aspect Oriented Programming (AOP), only applied to a \\nspecific proce\", \"ss pipeline managed by the mediator component. Aspects in AOP that implement cross-\\ncutting concerns\", \" are applied based on aspect weavers injected at compilation time or based on object \\ncall intercept\", \"ion. Both typical AOP approaches are sometimes said to work \\u201clike magic,\\u201d because it is \\nnot easy to\", \" see how AOP does its work. When dealing with serious issues or bugs, AOP can be difficult \\nto debug\", \". On the other hand, these decorators/behaviors are explicit and applied only in the context \\nof the\", \" mediator, so debugging is much more predictable and easy. \\nFor example, in the eShopOnContainers or\", \"dering microservice, has an implementation of two sample \\nbehaviors, a LogBehavior class and a Valid\", \"atorBehavior class. The implementation of the behaviors is \\nexplained in the next section by showing\", \" how eShopOnContainers uses MediatR behaviors. \\n \\n280 \\nCHAPTER 6 | Tackle Business Complexity in a M\", \"icroservice with DDD and CQRS Patterns \\n \\nUse message queues (out-of-proc) in the command\\u2019s pipeline\", \" \\nAnother choice is to use asynchronous messages based on brokers or message queues, as shown in \\nFi\", \"gure 7-26. That option could also be combined with the mediator component right before the \\ncommand \", \"handler. \\n \\nFigure 7-26. Using message queues (out of the process and inter-process communication) w\", \"ith CQRS commands \\nCommand\\u2019s pipeline can also be handled by a high availability message queue to de\", \"liver the \\ncommands to the appropriate handler. Using message queues to accept the commands can furt\", \"her \\ncomplicate your command\\u2019s pipeline, because you will probably need to split the pipeline into t\", \"wo \\nprocesses connected through the external message queue. Still, it should be used if you need to \", \"have \\nimproved scalability and performance based on asynchronous messaging. Consider that in the cas\", \"e of \\nFigure 7-26, the controller just posts the command message into the queue and returns. Then th\", \"e \\ncommand handlers process the messages at their own pace. That is a great benefit of queues: the \\n\", \"message queue can act as a buffer in cases when hyper scalability is needed, such as for stocks or a\", \"ny \\nother scenario with a high volume of ingress data. \\nHowever, because of the asynchronous nature \", \"of message queues, you need to figure out how to \\ncommunicate with the client application about the \", \"success or failure of the command\\u2019s process. As a \\nrule, you should never use \\u201cfire and forget\\u201d comm\", \"ands. Every business application needs to know if a \\ncommand was processed successfully, or at least\", \" validated and accepted. \\nThus, being able to respond to the client after validating a command messa\", \"ge that was submitted to \\nan asynchronous queue adds complexity to your system, as compared to an in\", \"-process command \\nprocess that returns the operation\\u2019s result after running the transaction. Using q\", \"ueues, you might \\nneed to return the result of the command process through other operation result me\", \"ssages, which will \\nrequire additional components and custom communication in your system. \\n \\n281 \\nC\", \"HAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nAdditionally, \", \"async commands are one-way commands, which in many cases might not be needed, as \\nis explained in th\", \"e following interesting exchange between Burtsev Alexey and Greg Young in an \\nonline conversation: \\n\", \"[Burtsev Alexey] I find lots of code where people use async command handling or one-way command \\nmes\", \"saging without any reason to do so (they are not doing some long operation, they are not \\nexecuting \", \"external async code, they do not even cross-application boundary to be using message \\nbus). Why do t\", \"hey introduce this unnecessary complexity? And actually, I haven\\u2019t seen a CQRS code \\nexample with bl\", \"ocking command handlers so far, though it will work just fine in most cases. \\n[Greg Young] [\\u2026] an as\", \"ynchronous command doesn\\u2019t exist; it\\u2019s actually another event. If I must accept \\nwhat you send me an\", \"d raise an event if I disagree, it\\u2019s no longer you telling me to do something [that \\nis, it\\u2019s not a \", \"command]. It\\u2019s you telling me something has been done. This seems like a slight \\ndifference at first\", \", but it has many implications. \\nAsynchronous commands greatly increase the complexity of a system, \", \"because there is no simple way \\nto indicate failures. Therefore, asynchronous commands are not recom\", \"mended other than when \\nscaling requirements are needed or in special cases when communicating the i\", \"nternal microservices \\nthrough messaging. In those cases, you must design a separate reporting and r\", \"ecovery system for \\nfailures. \\nIn the initial version of eShopOnContainers, it was decided to use sy\", \"nchronous command processing, \\nstarted from HTTP requests and driven by the Mediator pattern. That e\", \"asily allows you to return the \\nsuccess or failure of the process, as in the CreateOrderCommandHandl\", \"er implementation. \\nIn any case, this should be a decision based on your application\\u2019s or microservi\", \"ce\\u2019s business \\nrequirements. \\nImplement the command process pipeline with a mediator pattern \\n(Media\", \"tR) \\nAs a sample implementation, this guide proposes using the in-process pipeline based on the Medi\", \"ator \\npattern to drive command ingestion and route commands, in memory, to the right command \\nhandle\", \"rs. The guide also proposes applying behaviors in order to separate cross-cutting concerns. \\nFor imp\", \"lementation in .NET, there are multiple open-source libraries available that implement the \\nMediator\", \" pattern. The library used in this guide is the MediatR open-source library (created by Jimmy \\nBogar\", \"d), but you could use another approach. MediatR is a small and simple library that allows you to \\npr\", \"ocess in-memory messages like a command, while applying decorators or behaviors. \\nUsing the Mediator\", \" pattern helps you to reduce coupling and to isolate the concerns of the requested \\nwork, while auto\", \"matically connecting to the handler that performs that work\\u2014in this case, to \\ncommand handlers. \\nAno\", \"ther good reason to use the Mediator pattern was explained by Jimmy Bogard when reviewing \\nthis guid\", \"e: \\n \\n282 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\nI \", \"think it might be worth mentioning testing here \\u2013 it provides a nice consistent window into the \\nbeh\", \"avior of your system. Request-in, response-out. We\\u2019ve found that aspect quite valuable in building \\n\", \"consistently behaving tests. \\nFirst, let\\u2019s look at a sample WebAPI controller where you actually wou\", \"ld use the mediator object. If \\nyou weren\\u2019t using the mediator object, you\\u2019d need to inject all the \", \"dependencies for that controller, \\nthings like a logger object and others. Therefore, the constructo\", \"r would be complicated. On the other \\nhand, if you use the mediator object, the constructor of your \", \"controller can be a lot simpler, with just a \\nfew dependencies instead of many dependencies if you h\", \"ad one per cross-cutting operation, as in the \\nfollowing example: \\npublic class MyMicroserviceContro\", \"ller : Controller \\n{ \\n    public MyMicroserviceController(IMediator mediator, \\n                     \", \"               IMyMicroserviceQueries microserviceQueries) \\n    { \\n        // ... \\n    } \\n} \\nYou can\", \" see that the mediator provides a clean and lean Web API controller constructor. In addition, \\nwithi\", \"n the controller methods, the code to send a command to the mediator object is almost one line: \\n[Ro\", \"ute(\\\"new\\\")] \\n[HttpPost] \\npublic async Task<IActionResult> ExecuteBusinessOperation([FromBody]RunOpCo\", \"mmand \\n                                                               runOperationCommand) \\n{ \\n    v\", \"ar commandResult = await _mediator.SendAsync(runOperationCommand); \\n \\n    return commandResult ? (IA\", \"ctionResult)Ok() : (IActionResult)BadRequest(); \\n} \\nImplement idempotent Commands \\nIn eShopOnContain\", \"ers, a more advanced example than the above is submitting a \\nCreateOrderCommand object from the Orde\", \"ring microservice. But since the Ordering business \\nprocess is a bit more complex and, in our case, \", \"it actually starts in the Basket microservice, this action \\nof submitting the CreateOrderCommand obj\", \"ect is performed from an integration-event handler \\nnamed UserCheckoutAcceptedIntegrationEventHandle\", \"r instead of a simple WebAPI controller called \\nfrom the client App as in the previous simpler examp\", \"le. \\nNevertheless, the action of submitting the Command to MediatR is pretty similar, as shown in th\", \"e \\nfollowing code. \\nvar createOrderCommand = new CreateOrderCommand(eventMsg.Basket.Items, \\n        \", \"                                        eventMsg.UserId, eventMsg.City, \\n                           \", \"                     eventMsg.Street, eventMsg.State, \\n                                             \", \"   eventMsg.Country, eventMsg.ZipCode, \\n                                                eventMsg.Car\", \"dNumber, \\n                                                eventMsg.CardHolderName, \\n                \", \"                                eventMsg.CardExpiration, \\n                                          \", \"      eventMsg.CardSecurityNumber, \\n                                                eventMsg.CardTyp\", \"eId); \\n \\n283 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \", \"\\n \\nvar requestCreateOrder = new IdentifiedCommand<CreateOrderCommand,bool>(createOrderCommand, \\n    \", \"                                                                    \\neventMsg.RequestId); \\nresult = \", \"await _mediator.Send(requestCreateOrder); \\nHowever, this case is also slightly more advanced because\", \" we\\u2019re also implementing idempotent \\ncommands. The CreateOrderCommand process should be idempotent, \", \"so if the same message comes \\nduplicated through the network, because of any reason, like retries, t\", \"he same business order will be \\nprocessed just once. \\nThis is implemented by wrapping the business c\", \"ommand (in this case CreateOrderCommand) and \\nembedding it into a generic IdentifiedCommand, which i\", \"s tracked by an ID of every message coming \\nthrough the network that has to be idempotent. \\nIn the c\", \"ode below, you can see that the IdentifiedCommand is nothing more than a DTO with and ID \\nplus the w\", \"rapped business command object. \\npublic class IdentifiedCommand<T, R> : IRequest<R> \\n    where T : I\", \"Request<R> \\n{ \\n    public T Command { get; } \\n    public Guid Id { get; } \\n    public IdentifiedComm\", \"and(T command, Guid id) \\n    { \\n        Command = command; \\n        Id = id; \\n    } \\n} \\nThen the Com\", \"mandHandler for the IdentifiedCommand named IdentifiedCommandHandler.cs will \\nbasically check if the\", \" ID coming as part of the message already exists in a table. If it already exists, that \\ncommand won\", \"\\u2019t be processed again, so it behaves as an idempotent command. That infrastructure \\ncode is performe\", \"d by the _requestManager.ExistAsync method call below. \\n// IdentifiedCommandHandler.cs \\npublic class\", \" IdentifiedCommandHandler<T, R> : IRequestHandler<IdentifiedCommand<T, R>, R> \\n        where T : IRe\", \"quest<R> \\n{ \\n    private readonly IMediator _mediator; \\n    private readonly IRequestManager _reques\", \"tManager; \\n    private readonly ILogger<IdentifiedCommandHandler<T, R>> _logger; \\n \\n    public Ident\", \"ifiedCommandHandler( \\n        IMediator mediator, \\n        IRequestManager requestManager, \\n        \", \"ILogger<IdentifiedCommandHandler<T, R>> logger) \\n    { \\n        _mediator = mediator; \\n        _requ\", \"estManager = requestManager; \\n        _logger = logger ?? throw new System.ArgumentNullException(nam\", \"eof(logger)); \\n    } \\n \\n    /// <summary> \\n    /// Creates the result value to return if a previous \", \"request was found \\n    /// </summary> \\n    /// <returns></returns> \\n \\n284 \\nCHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    protected virtual R CreateResultFo\", \"rDuplicateRequest() \\n    { \\n        return default(R); \\n    } \\n \\n    /// <summary> \\n    /// This met\", \"hod handles the command. It just ensures that no other request exists with \\nthe same ID, and if this\", \" is the case \\n    /// just enqueues the original inner command. \\n    /// </summary> \\n    /// <param \", \"name=\\\"message\\\">IdentifiedCommand which contains both original command & \\nrequest ID</param> \\n    ///\", \" <returns>Return value of inner command or default value if request same ID was \\nfound</returns> \\n  \", \"  public async Task<R> Handle(IdentifiedCommand<T, R> message, CancellationToken \\ncancellationToken)\", \" \\n    { \\n        var alreadyExists = await _requestManager.ExistAsync(message.Id); \\n        if (alre\", \"adyExists) \\n        { \\n            return CreateResultForDuplicateRequest(); \\n        } \\n        els\", \"e \\n        { \\n            await _requestManager.CreateRequestForCommandAsync<T>(message.Id); \\n      \", \"      try \\n            { \\n                var command = message.Command; \\n                var comman\", \"dName = command.GetGenericTypeName(); \\n                var idProperty = string.Empty; \\n             \", \"   var commandId = string.Empty; \\n \\n                switch (command) \\n                { \\n           \", \"         case CreateOrderCommand createOrderCommand: \\n                        idProperty = nameof(cr\", \"eateOrderCommand.UserId); \\n                        commandId = createOrderCommand.UserId; \\n         \", \"               break; \\n \\n                    case CancelOrderCommand cancelOrderCommand: \\n          \", \"              idProperty = nameof(cancelOrderCommand.OrderNumber); \\n                        commandI\", \"d = $\\\"{cancelOrderCommand.OrderNumber}\\\"; \\n                        break; \\n \\n                    case\", \" ShipOrderCommand shipOrderCommand: \\n                        idProperty = nameof(shipOrderCommand.Or\", \"derNumber); \\n                        commandId = $\\\"{shipOrderCommand.OrderNumber}\\\"; \\n               \", \"         break; \\n \\n                    default: \\n                        idProperty = \\\"Id?\\\"; \\n      \", \"                  commandId = \\\"n/a\\\"; \\n                        break; \\n                } \\n \\n         \", \"       _logger.LogInformation( \\n                    \\\"----- Sending command: {CommandName} - {IdPrope\", \"rty}: {CommandId} \\n({@Command})\\\", \\n                    commandName, \\n                    idProperty,\", \" \\n                    commandId, \\n \\n285 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice wi\", \"th DDD and CQRS Patterns \\n \\n                    command); \\n \\n                // Send the embedded bu\", \"siness command to mediator so it runs its related \\nCommandHandler \\n                var result = awai\", \"t _mediator.Send(command, cancellationToken); \\n \\n                _logger.LogInformation( \\n          \", \"          \\\"----- Command result: {@Result} - {CommandName} - {IdProperty}: \\n{CommandId} ({@Command})\", \"\\\", \\n                    result, \\n                    commandName, \\n                    idProperty, \\n\", \"                    commandId, \\n                    command); \\n \\n                return result; \\n   \", \"         } \\n            catch \\n            { \\n                return default(R); \\n            } \\n   \", \"     } \\n    } \\n} \\nSince the IdentifiedCommand acts like a business command\\u2019s envelope, when the busi\", \"ness command \\nneeds to be processed because it is not a repeated ID, then it takes that inner busine\", \"ss command and \\nresubmits it to Mediator, as in the last part of the code shown above when running \\n\", \"_mediator.Send(message.Command), from the IdentifiedCommandHandler.cs. \\nWhen doing that, it will lin\", \"k and run the business command handler, in this case, the \\nCreateOrderCommandHandler, which is runni\", \"ng transactions against the Ordering database, as shown \\nin the following code. \\n// CreateOrderComma\", \"ndHandler.cs \\npublic class CreateOrderCommandHandler \\n        : IRequestHandler<CreateOrderCommand, \", \"bool> \\n{ \\n    private readonly IOrderRepository _orderRepository; \\n    private readonly IIdentitySer\", \"vice _identityService; \\n    private readonly IMediator _mediator; \\n    private readonly IOrderingInt\", \"egrationEventService _orderingIntegrationEventService; \\n    private readonly ILogger<CreateOrderComm\", \"andHandler> _logger; \\n \\n    // Using DI to inject infrastructure persistence Repositories \\n    publi\", \"c CreateOrderCommandHandler(IMediator mediator, \\n        IOrderingIntegrationEventService orderingIn\", \"tegrationEventService, \\n        IOrderRepository orderRepository, \\n        IIdentityService identity\", \"Service, \\n        ILogger<CreateOrderCommandHandler> logger) \\n    { \\n        _orderRepository = orde\", \"rRepository ?? throw new \\nArgumentNullException(nameof(orderRepository)); \\n        _identityService \", \"= identityService ?? throw new \\nArgumentNullException(nameof(identityService)); \\n        _mediator =\", \" mediator ?? throw new ArgumentNullException(nameof(mediator)); \\n        _orderingIntegrationEventSe\", \"rvice = orderingIntegrationEventService ?? throw new \\nArgumentNullException(nameof(orderingIntegrati\", \"onEventService)); \\n        _logger = logger ?? throw new ArgumentNullException(nameof(logger)); \\n \\n2\", \"86 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n    } \\n \\n\", \"    public async Task<bool> Handle(CreateOrderCommand message, CancellationToken \\ncancellationToken)\", \" \\n    { \\n        // Add Integration event to clean the basket \\n        var orderStartedIntegrationEv\", \"ent = new \\nOrderStartedIntegrationEvent(message.UserId); \\n        await \\n_orderingIntegrationEventSe\", \"rvice.AddAndSaveEventAsync(orderStartedIntegrationEvent); \\n \\n        // Add/Update the Buyer Aggrega\", \"teRoot \\n        // DDD patterns comment: Add child entities and value-objects through the Order \\nAgg\", \"regate-Root \\n        // methods and constructor so validations, invariants and business logic \\n     \", \"   // make sure that consistency is preserved across the whole aggregate \\n        var address = new \", \"Address(message.Street, message.City, message.State, \\nmessage.Country, message.ZipCode); \\n        va\", \"r order = new Order(message.UserId, message.UserName, address, \\nmessage.CardTypeId, message.CardNumb\", \"er, message.CardSecurityNumber, message.CardHolderName, \\nmessage.CardExpiration); \\n \\n        foreach\", \" (var item in message.OrderItems) \\n        { \\n            order.AddOrderItem(item.ProductId, item.Pr\", \"oductName, item.UnitPrice, \\nitem.Discount, item.PictureUrl, item.Units); \\n        } \\n \\n        _logg\", \"er.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order); \\n \\n        _orderRepository.Add(\", \"order); \\n \\n        return await _orderRepository.UnitOfWork \\n            .SaveEntitiesAsync(cancella\", \"tionToken); \\n    } \\n} \\nRegister the types used by MediatR \\nIn order for MediatR to be aware of your \", \"command handler classes, you need to register the mediator \\nclasses and the command handler classes \", \"in your IoC container. By default, MediatR uses Autofac as \\nthe IoC container, but you can also use \", \"the built-in ASP.NET Core IoC container or any other container \\nsupported by MediatR. \\nThe following\", \" code shows how to register Mediator\\u2019s types and commands when using Autofac \\nmodules. \\npublic class\", \" MediatorModule : Autofac.Module \\n{ \\n    protected override void Load(ContainerBuilder builder) \\n   \", \" { \\n        builder.RegisterAssemblyTypes(typeof(IMediator).GetTypeInfo().Assembly) \\n            .As\", \"ImplementedInterfaces(); \\n \\n        // Register all the Command classes (they implement IRequestHand\", \"ler) \\n        // in assembly holding the Commands \\n        builder.RegisterAssemblyTypes(typeof(Crea\", \"teOrderCommand).GetTypeInfo().Assembly) \\n                .AsClosedTypesOf(typeof(IRequestHandler<,>)\", \"); \\n        // Other types registration \\n \\n287 \\nCHAPTER 6 | Tackle Business Complexity in a Microser\", \"vice with DDD and CQRS Patterns \\n \\n        //... \\n    } \\n} \\nThis is where \\u201cthe magic happens\\u201d with M\", \"ediatR. \\nAs each command handler implements the generic IRequestHandler<T> interface, when you regis\", \"ter \\nthe assemblies using RegisteredAssemblyTypes method all the types marked as IRequestHandler als\", \"o \\ngets registered with their Commands. For example: \\npublic class CreateOrderCommandHandler \\n  : IR\", \"equestHandler<CreateOrderCommand, bool> \\n{ \\nThat is the code that correlates commands with command h\", \"andlers. The handler is just a simple class, \\nbut it inherits from RequestHandler<T>, where T is the\", \" command type, and MediatR makes sure it is \\ninvoked with the correct payload (the command). \\nApply \", \"cross-cutting concerns when processing commands with the \\nBehaviors in MediatR \\nThere is one more th\", \"ing: being able to apply cross-cutting concerns to the mediator pipeline. You can \\nalso see at the e\", \"nd of the Autofac registration module code how it registers a behavior type, \\nspecifically, a custom\", \" LoggingBehavior class and a ValidatorBehavior class. But you could add other \\ncustom behaviors, too\", \". \\npublic class MediatorModule : Autofac.Module \\n{ \\n    protected override void Load(ContainerBuilde\", \"r builder) \\n    { \\n        builder.RegisterAssemblyTypes(typeof(IMediator).GetTypeInfo().Assembly) \\n\", \"            .AsImplementedInterfaces(); \\n \\n        // Register all the Command classes (they impleme\", \"nt IRequestHandler) \\n        // in assembly holding the Commands \\n        builder.RegisterAssemblyTy\", \"pes( \\n                              typeof(CreateOrderCommand).GetTypeInfo().Assembly). \\n           \", \"                        AsClosedTypesOf(typeof(IRequestHandler<,>)); \\n        // Other types registr\", \"ation \\n        //... \\n        builder.RegisterGeneric(typeof(LoggingBehavior<,>)). \\n                \", \"                                   As(typeof(IPipelineBehavior<,>)); \\n        builder.RegisterGeneri\", \"c(typeof(ValidatorBehavior<,>)). \\n                                                   As(typeof(IPipe\", \"lineBehavior<,>)); \\n    } \\n} \\nThat LoggingBehavior class can be implemented as the following code, w\", \"hich logs information about \\nthe command handler being executed and whether it was successful or not\", \". \\npublic class LoggingBehavior<TRequest, TResponse> \\n         : IPipelineBehavior<TRequest, TRespon\", \"se> \\n{ \\n    private readonly ILogger<LoggingBehavior<TRequest, TResponse>> _logger; \\n    public Logg\", \"ingBehavior(ILogger<LoggingBehavior<TRequest, TResponse>> logger) => \\n                              \", \"                                    _logger = logger; \\n \\n288 \\nCHAPTER 6 | Tackle Business Complexity\", \" in a Microservice with DDD and CQRS Patterns \\n \\n \\n    public async Task<TResponse> Handle(TRequest \", \"request, \\n                                        RequestHandlerDelegate<TResponse> next) \\n    { \\n  \", \"      _logger.LogInformation($\\\"Handling {typeof(TRequest).Name}\\\"); \\n        var response = await nex\", \"t(); \\n        _logger.LogInformation($\\\"Handled {typeof(TResponse).Name}\\\"); \\n        return response;\", \" \\n    } \\n} \\nJust by implementing this behavior class and by registering it in the pipeline (in the M\", \"ediatorModule \\nabove), all the commands processed through MediatR will be logging information about \", \"the \\nexecution. \\nThe eShopOnContainers ordering microservice also applies a second behavior for basi\", \"c validations, \\nthe ValidatorBehavior class that relies on the FluentValidation library, as shown in\", \" the following code: \\npublic class ValidatorBehavior<TRequest, TResponse> \\n         : IPipelineBehav\", \"ior<TRequest, TResponse> \\n{ \\n    private readonly IValidator<TRequest>[] _validators; \\n    public Va\", \"lidatorBehavior(IValidator<TRequest>[] validators) => \\n                                             \", \"            _validators = validators; \\n \\n    public async Task<TResponse> Handle(TRequest request, \\n\", \"                                        RequestHandlerDelegate<TResponse> next) \\n    { \\n        var \", \"failures = _validators \\n            .Select(v => v.Validate(request)) \\n            .SelectMany(resul\", \"t => result.Errors) \\n            .Where(error => error != null) \\n            .ToList(); \\n \\n        i\", \"f (failures.Any()) \\n        { \\n            throw new OrderingDomainException( \\n                $\\\"Com\", \"mand Validation Errors for type {typeof(TRequest).Name}\\\", \\n                        new ValidationExc\", \"eption(\\\"Validation exception\\\", failures)); \\n        } \\n \\n        var response = await next(); \\n     \", \"   return response; \\n    } \\n} \\nHere the behavior is raising an exception if validation fails, but yo\", \"u could also return a result object, \\ncontaining the command result if it succeeded or the validatio\", \"n messages in case it didn\\u2019t. This would \\nprobably make it easier to display validation results to t\", \"he user. \\nThen, based on the FluentValidation library, you would create validation for the data pass\", \"ed with \\nCreateOrderCommand, as in the following code: \\npublic class CreateOrderCommandValidator : A\", \"bstractValidator<CreateOrderCommand> \\n{ \\n    public CreateOrderCommandValidator() \\n    { \\n        Ru\", \"leFor(command => command.City).NotEmpty(); \\n        RuleFor(command => command.Street).NotEmpty(); \\n\", \" \\n289 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n      \", \"  RuleFor(command => command.State).NotEmpty(); \\n        RuleFor(command => command.Country).NotEmpt\", \"y(); \\n        RuleFor(command => command.ZipCode).NotEmpty(); \\n        RuleFor(command => command.Ca\", \"rdNumber).NotEmpty().Length(12, 19); \\n        RuleFor(command => command.CardHolderName).NotEmpty();\", \" \\n        RuleFor(command => \\ncommand.CardExpiration).NotEmpty().Must(BeValidExpirationDate).WithMes\", \"sage(\\\"Please specify \\na valid card expiration date\\\"); \\n        RuleFor(command => command.CardSecuri\", \"tyNumber).NotEmpty().Length(3); \\n        RuleFor(command => command.CardTypeId).NotEmpty(); \\n       \", \" RuleFor(command => command.OrderItems).Must(ContainOrderItems).WithMessage(\\\"No \\norder items found\\\")\", \"; \\n    } \\n \\n    private bool BeValidExpirationDate(DateTime dateTime) \\n    { \\n        return dateTim\", \"e >= DateTime.UtcNow; \\n    } \\n \\n    private bool ContainOrderItems(IEnumerable<OrderItemDTO> orderIt\", \"ems) \\n    { \\n        return orderItems.Any(); \\n    } \\n} \\nYou could create additional validations. Th\", \"is is a very clean and elegant way to implement your \\ncommand validations. \\nIn a similar way, you co\", \"uld implement other behaviors for additional aspects or cross-cutting concerns \\nthat you want to app\", \"ly to commands when handling them. \\nAdditional resources \\nThe mediator pattern \\n\\u2022 \\nMediator pattern \", \"\\nhttps://en.wikipedia.org/wiki/Mediator_pattern \\nThe decorator pattern \\n\\u2022 \\nDecorator pattern \\nhttps:\", \"//en.wikipedia.org/wiki/Decorator_pattern \\nMediatR (Jimmy Bogard) \\n\\u2022 \\nMediatR. GitHub repo. \\nhttps:/\", \"/github.com/jbogard/MediatR \\n\\u2022 \\nCQRS with MediatR and AutoMapper \\nhttps://lostechies.com/jimmybogard\", \"/2015/05/05/cqrs-with-mediatr-and-automapper/ \\n\\u2022 \\nPut your controllers on a diet: POSTs and commands\", \". \\nhttps://lostechies.com/jimmybogard/2013/12/19/put-your-controllers-on-a-diet-posts-and-\\ncommands/\", \" \\n \\n290 \\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n \\n\\u2022 \\nT\", \"ackling cross-cutting concerns with a mediator pipeline \\nhttps://lostechies.com/jimmybogard/2014/09/\", \"09/tackling-cross-cutting-concerns-with-a-\\nmediator-pipeline/ \\n\\u2022 \\nCQRS and REST: the perfect match \\n\", \"https://lostechies.com/jimmybogard/2016/06/01/cqrs-and-rest-the-perfect-match/ \\n\\u2022 \\nMediatR Pipeline \", \"Examples \\nhttps://lostechies.com/jimmybogard/2016/10/13/mediatr-pipeline-examples/ \\n\\u2022 \\nVertical Slic\", \"e Test Fixtures for MediatR and ASP.NET Core \\nhttps://lostechies.com/jimmybogard/2016/10/24/vertical\", \"-slice-test-fixtures-for-mediatr-and-\\nasp-net-core/ \\n\\u2022 \\nMediatR Extensions for Microsoft Dependency \", \"Injection Released \\nhttps://lostechies.com/jimmybogard/2016/07/19/mediatr-extensions-for-microsoft-\\n\", \"dependency-injection-released/ \\nFluent validation \\n\\u2022 \\nJeremy Skinner. FluentValidation. GitHub repo.\", \" \\nhttps://github.com/JeremySkinner/FluentValidation \\n \\n291 \\nCHAPTER 7 | Implement resilient applicat\", \"ions \\n \\nCHAPTER 7 \\nImplement resilient \\napplications \\nYour microservice and cloud-based applications\", \" must embrace the partial failures that will certainly \\noccur eventually. You must design your appli\", \"cation to be resilient to those partial failures. \\nResiliency is the ability to recover from failure\", \"s and continue to function. It isn\\u2019t about avoiding \\nfailures but accepting the fact that failures w\", \"ill happen and responding to them in a way that avoids \\ndowntime or data loss. The goal of resilienc\", \"y is to return the application to a fully functioning state \\nafter a failure. \\nIt\\u2019s challenging enou\", \"gh to design and deploy a microservices-based application. But you also need to \\nkeep your applicati\", \"on running in an environment where some sort of failure is certain. Therefore, your \\napplication sho\", \"uld be resilient. It should be designed to cope with partial failures, like network \\noutages or node\", \"s or VMs crashing in the cloud. Even microservices (containers) being moved to a \\ndifferent node wit\", \"hin a cluster can cause intermittent short failures within the application. \\nThe many individual com\", \"ponents of your application should also incorporate health monitoring \\nfeatures. By following the gu\", \"idelines in this chapter, you can create an application that can work \\nsmoothly in spite of transien\", \"t downtime or the normal hiccups that occur in complex and cloud-based \\ndeployments. \\nImportant \\neSh\", \"opOnContainer had been using the Polly library to implement resiliency using Typed Clients up \\nuntil\", \" the release 3.0.0. \\nStarting with release 3.0.0, the HTTP calls resiliency is implemented using a L\", \"inkerd mesh, that handles \\nretries in a transparent and configurable fashion, within a Kubernetes cl\", \"uster, without having to \\nhandle those concerns in the code. \\nThe Polly library is still used to add\", \" resilience to database connections, specially while starting up the \\nservices. \\n \\n \\nWarning \\nAll co\", \"de samples and images in this section were valid before using Linkerd and are not updated to \\nreflec\", \"t the current actual code. So they make sense in the context of this section. \\n \\n292 \\nCHAPTER 7 | Im\", \"plement resilient applications \\n \\nHandle partial failure \\nIn distributed systems like microservices-\", \"based applications, there\\u2019s an ever-present risk of partial \\nfailure. For instance, a single microse\", \"rvice/container can fail or might not be available to respond for a \\nshort time, or a single VM or s\", \"erver can crash. Since clients and services are separate processes, a \\nservice might not be able to \", \"respond in a timely way to a client\\u2019s request. The service might be \\noverloaded and responding very \", \"slowly to requests or might simply not be accessible for a short time \\nbecause of network issues. \\nF\", \"or example, consider the Order details page from the eShopOnContainers sample application. If the \\no\", \"rdering microservice is unresponsive when the user tries to submit an order, a bad implementation \\no\", \"f the client process (the MVC web application)\\u2014for example, if the client code were to use \\nsynchron\", \"ous RPCs with no timeout\\u2014would block threads indefinitely waiting for a response. Besides \\ncreating \", \"a bad user experience, every unresponsive wait consumes or blocks a thread, and threads are \\nextreme\", \"ly valuable in highly scalable applications. If there are many blocked threads, eventually the \\nappl\", \"ication\\u2019s runtime can run out of threads. In that case, the application can become globally \\nunrespo\", \"nsive instead of just partially unresponsive, as shown in Figure 8-1. \\n \\nFigure 8-1. Partial failure\", \"s because of dependencies that impact service thread availability \\nIn a large microservices-based ap\", \"plication, any partial failure can be amplified, especially if most of \\nthe internal microservices i\", \"nteraction is based on synchronous HTTP calls (which is considered an anti-\\npattern). Think about a \", \"system that receives millions of incoming calls per day. If your system has a \\nbad design that\\u2019s bas\", \"ed on long chains of synchronous HTTP calls, these incoming calls might result in \\nmany more million\", \"s of outgoing calls (let\\u2019s suppose a ratio of 1:4) to dozens of internal microservices \\nas synchrono\", \"us dependencies. This situation is shown in Figure 8-2, especially dependency #3, that \\nstarts a cha\", \"in, calling dependency #4, which then calls #5. \\n \\n293 \\nCHAPTER 7 | Implement resilient applications\", \" \\n \\n \\nFigure 8-2. The impact of having an incorrect design featuring long chains of HTTP requests \\nI\", \"ntermittent failure is guaranteed in a distributed and cloud-based system, even if every dependency \", \"\\nitself has excellent availability. It\\u2019s a fact you need to consider. \\nIf you do not design and impl\", \"ement techniques to ensure fault tolerance, even small downtimes can \\nbe amplified. As an example, 5\", \"0 dependencies each with 99.99% of availability would result in several \\nhours of downtime each mont\", \"h because of this ripple effect. When a microservice dependency fails \\nwhile handling a high volume \", \"of requests, that failure can quickly saturate all available request threads \\nin each service and cr\", \"ash the whole application. \\n \\nFigure 8-3. Partial failure amplified by microservices with long chain\", \"s of synchronous HTTP calls \\n \\n294 \\nCHAPTER 7 | Implement resilient applications \\n \\nTo minimize this\", \" problem, in the section Asynchronous microservice integration enforce microservice\\u2019s \\nautonomy, thi\", \"s guide encourages you to use asynchronous communication across the internal \\nmicroservices. \\nIn add\", \"ition, it\\u2019s essential that you design your microservices and client applications to handle partial \\n\", \"failures\\u2014that is, to build resilient microservices and client applications. \\nStrategies to handle pa\", \"rtial failure \\nTo deal with partial failures, use one of the strategies described here. \\nUse asynchr\", \"onous communication (for example, message-based communication) across \\ninternal microservices. It\\u2019s \", \"highly advisable not to create long chains of synchronous HTTP calls \\nacross the internal microservi\", \"ces because that incorrect design will eventually become the main cause \\nof bad outages. On the cont\", \"rary, except for the front-end communications between the client \\napplications and the first level o\", \"f microservices or fine-grained API Gateways, it\\u2019s recommended to use \\nonly asynchronous (message-ba\", \"sed) communication once past the initial request/response cycle, \\nacross the internal microservices.\", \" Eventual consistency and event-driven architectures will help to \\nminimize ripple effects. These ap\", \"proaches enforce a higher level of microservice autonomy and \\ntherefore prevent against the problem \", \"noted here. \\nUse retries with exponential backoff. This technique helps to avoid short and intermitt\", \"ent failures \\nby performing call retries a certain number of times, in case the service was not avai\", \"lable only for a \\nshort time. This might occur due to intermittent network issues or when a microser\", \"vice/container is \\nmoved to a different node in a cluster. However, if these retries are not designe\", \"d properly with circuit \\nbreakers, it can aggravate the ripple effects, ultimately even causing a De\", \"nial of Service (DoS). \\nWork around network timeouts. In general, clients should be designed not to \", \"block indefinitely and \\nto always use timeouts when waiting for a response. Using timeouts ensures t\", \"hat resources are never \\ntied up indefinitely. \\nUse the Circuit Breaker pattern. In this approach, t\", \"he client process tracks the number of failed \\nrequests. If the error rate exceeds a configured limi\", \"t, a \\u201ccircuit breaker\\u201d trips so that further attempts \\nfail immediately. (If a large number of reque\", \"sts are failing, that suggests the service is unavailable and \\nthat sending requests is pointless.) \", \"After a timeout period, the client should try again and, if the new \\nrequests are successful, close \", \"the circuit breaker. \\nProvide fallbacks. In this approach, the client process performs fallback logi\", \"c when a request fails, \\nsuch as returning cached data or a default value. This is an approach suita\", \"ble for queries, and is more \\ncomplex for updates or commands. \\nLimit the number of queued requests.\", \" Clients should also impose an upper bound on the number \\nof outstanding requests that a client micr\", \"oservice can send to a particular service. If the limit has been \\nreached, it\\u2019s probably pointless t\", \"o make additional requests, and those attempts should fail \\nimmediately. In terms of implementation,\", \" the Polly Bulkhead Isolation policy can be used to fulfill this \\nrequirement. This approach is esse\", \"ntially a parallelization throttle with SemaphoreSlim as the \\nimplementation. It also permits a \\u201cque\", \"ue\\u201d outside the bulkhead. You can proactively shed excess load \\neven before execution (for example, \", \"because capacity is deemed full). This makes its response to \\n \\n295 \\nCHAPTER 7 | Implement resilient\", \" applications \\n \\ncertain failure scenarios faster than a circuit breaker would be, since the circuit\", \" breaker waits for the \\nfailures. The BulkheadPolicy object in Polly exposes how full the bulkhead a\", \"nd queue are, and offers \\nevents on overflow so can also be used to drive automated horizontal scali\", \"ng. \\nAdditional resources \\n\\u2022 \\nResiliency patterns \\nhttps://learn.microsoft.com/azure/architecture/fr\", \"amework/resiliency/reliability-patterns \\n\\u2022 \\nAdding Resilience and Optimizing Performance \\nhttps://le\", \"arn.microsoft.com/previous-versions/msp-n-p/jj591574(v=pandp.10) \\n\\u2022 \\nBulkhead. GitHub repo. Implemen\", \"tation with Polly policy. \\nhttps://github.com/App-vNext/Polly/wiki/Bulkhead \\n\\u2022 \\nDesigning resilient \", \"applications for Azure \\nhttps://learn.microsoft.com/azure/architecture/framework/resiliency/app-desi\", \"gn \\n\\u2022 \\nTransient fault handling \\nhttps://learn.microsoft.com/azure/architecture/best-practices/trans\", \"ient-faults \\nImplement retries with exponential backoff \\nRetries with exponential backoff is a techn\", \"ique that retries an operation, with an exponentially \\nincreasing wait time, up to a maximum retry c\", \"ount has been reached (the exponential backoff). This \\ntechnique embraces the fact that cloud resour\", \"ces might intermittently be unavailable for more than a \\nfew seconds for any reason. For example, an\", \" orchestrator might be moving a container to another \\nnode in a cluster for load balancing. During t\", \"hat time, some requests might fail. Another example \\ncould be a database like SQL Azure, where a dat\", \"abase can be moved to another server for load \\nbalancing, causing the database to be unavailable for\", \" a few seconds. \\nThere are many approaches to implement retries logic with exponential backoff. \\nImp\", \"lement resilient Entity Framework Core SQL \\nconnections \\nFor Azure SQL DB, Entity Framework (EF) Cor\", \"e already provides internal database connection resiliency \\nand retry logic. But you need to enable \", \"the Entity Framework execution strategy for each DbContext \\nconnection if you want to have resilient\", \" EF Core connections. \\nFor instance, the following code at the EF Core connection level enables resi\", \"lient SQL connections that \\nare retried if the connection fails. \\n// Program.cs from any ASP.NET Cor\", \"e Web API \\n// Other code ... \\nbuilder.Services.AddDbContext<CatalogContext>(options => \\n    { \\n \\n296\", \" \\nCHAPTER 7 | Implement resilient applications \\n \\n        options.UseSqlServer(builder.Configuration\", \"[\\\"ConnectionString\\\"], \\n        sqlServerOptionsAction: sqlOptions => \\n        { \\n            sqlOpti\", \"ons.EnableRetryOnFailure( \\n            maxRetryCount: 10, \\n            maxRetryDelay: TimeSpan.FromS\", \"econds(30), \\n            errorNumbersToAdd: null); \\n        }); \\n    }); \\nExecution strategies and e\", \"xplicit transactions using BeginTransaction \\nand multiple DbContexts \\nWhen retries are enabled in EF\", \" Core connections, each operation you perform using EF Core becomes \\nits own retryable operation. Ea\", \"ch query and each call to SaveChanges will be retried as a unit if a \\ntransient failure occurs. \\nHow\", \"ever, if your code initiates a transaction using BeginTransaction, you\\u2019re defining your own group \\no\", \"f operations that need to be treated as a unit. Everything inside the transaction has to be rolled b\", \"ack \\nif a failure occurs. \\nIf you try to execute that transaction when using an EF execution strateg\", \"y (retry policy) and you call \\nSaveChanges from multiple DbContexts, you\\u2019ll get an exception like th\", \"is one: \\nSystem.InvalidOperationException: The configured execution strategy \\n\\u2018SqlServerRetryingExec\", \"utionStrategy\\u2019 does not support user initiated transactions. Use the execution \\nstrategy returned by\", \" \\u2018DbContext.Database.CreateExecutionStrategy()\\u2019 to execute all the operations in \\nthe transaction as\", \" a retriable unit. \\nThe solution is to manually invoke the EF execution strategy with a delegate rep\", \"resenting everything \\nthat needs to be executed. If a transient failure occurs, the execution strate\", \"gy will invoke the delegate \\nagain. For example, the following code shows how it\\u2019s implemented in eS\", \"hopOnContainers with two \\nmultiple DbContexts (_catalogContext and the IntegrationEventLogContext) w\", \"hen updating a product \\nand then saving the ProductPriceChangedIntegrationEvent object, which needs \", \"to use a different \\nDbContext. \\npublic async Task<IActionResult> UpdateProduct( \\n    [FromBody]Catal\", \"ogItem productToUpdate) \\n{ \\n    // Other code ... \\n \\n    var oldPrice = catalogItem.Price; \\n    var \", \"raiseProductPriceChangedEvent = oldPrice != productToUpdate.Price; \\n \\n    // Update current product \", \"\\n    catalogItem = productToUpdate; \\n \\n    // Save product's data and publish integration event thro\", \"ugh the Event Bus \\n    // if price has changed \\n    if (raiseProductPriceChangedEvent) \\n    { \\n     \", \"   //Create Integration Event to be published through the Event Bus \\n        var priceChangedEvent =\", \" new ProductPriceChangedIntegrationEvent( \\n          catalogItem.Id, productToUpdate.Price, oldPrice\", \"); \\n \\n297 \\nCHAPTER 7 | Implement resilient applications \\n \\n \\n       // Achieving atomicity between o\", \"riginal Catalog database operation and the \\n       // IntegrationEventLog thanks to a local transact\", \"ion \\n       await _catalogIntegrationEventService.SaveEventAndCatalogContextChangesAsync( \\n         \", \"  priceChangedEvent); \\n \\n       // Publish through the Event Bus and mark the saved event as publish\", \"ed \\n       await _catalogIntegrationEventService.PublishThroughEventBusAsync( \\n           priceChang\", \"edEvent); \\n    } \\n    // Just save the updated product because the Product's Price hasn't changed. \\n\", \"    else \\n    { \\n        await _catalogContext.SaveChangesAsync(); \\n    } \\n} \\nThe first DbContext is\", \" _catalogContext and the second DbContext is within the \\n_catalogIntegrationEventService object. The\", \" Commit action is performed across all DbContext objects \\nusing an EF execution strategy. \\nTo achiev\", \"e this multiple DbContext commit, the SaveEventAndCatalogContextChangesAsync uses a \\nResilientTransa\", \"ction class, as shown in the following code: \\npublic class CatalogIntegrationEventService : ICatalog\", \"IntegrationEventService \\n{ \\n    //\\u2026 \\n    public async Task SaveEventAndCatalogContextChangesAsync( \\n\", \"        IntegrationEvent evt) \\n    { \\n        // Use of an EF Core resiliency strategy when using mu\", \"ltiple DbContexts \\n        // within an explicit BeginTransaction(): \\n        // https://learn.micro\", \"soft.com/ef/core/miscellaneous/connection-resiliency \\n        await ResilientTransaction.New(_catalo\", \"gContext).ExecuteAsync(async () => \\n        { \\n            // Achieving atomicity between original c\", \"atalog database \\n            // operation and the IntegrationEventLog thanks to a local transaction \", \"\\n            await _catalogContext.SaveChangesAsync(); \\n            await _eventLogService.SaveEvent\", \"Async(evt, \\n                _catalogContext.Database.CurrentTransaction.GetDbTransaction()); \\n      \", \"  }); \\n    } \\n} \\nThe ResilientTransaction.ExecuteAsync method basically begins a transaction from th\", \"e passed \\nDbContext (_catalogContext) and then makes the EventLogService use that transaction to sav\", \"e \\nchanges from the IntegrationEventLogContext and then commits the whole transaction. \\npublic class\", \" ResilientTransaction \\n{ \\n    private DbContext _context; \\n    private ResilientTransaction(DbContex\", \"t context) => \\n        _context = context ?? throw new ArgumentNullException(nameof(context)); \\n \\n  \", \"  public static ResilientTransaction New (DbContext context) => \\n        new ResilientTransaction(co\", \"ntext); \\n \\n    public async Task ExecuteAsync(Func<Task> action) \\n    { \\n \\n298 \\nCHAPTER 7 | Implemen\", \"t resilient applications \\n \\n        // Use of an EF Core resiliency strategy when using multiple DbC\", \"ontexts \\n        // within an explicit BeginTransaction(): \\n        // https://learn.microsoft.com/e\", \"f/core/miscellaneous/connection-resiliency \\n        var strategy = _context.Database.CreateExecution\", \"Strategy(); \\n        await strategy.ExecuteAsync(async () => \\n        { \\n            await using var\", \" transaction = await _context.Database.BeginTransactionAsync(); \\n            await action(); \\n      \", \"      await transaction.CommitAsync(); \\n        }); \\n    } \\n} \\nAdditional resources \\n\\u2022 \\nConnection R\", \"esiliency and Command Interception with EF in an ASP.NET MVC \\nApplication \\nhttps://learn.microsoft.c\", \"om/aspnet/mvc/overview/getting-started/getting-started-with-ef-\\nusing-mvc/connection-resiliency-and-\", \"command-interception-with-the-entity-framework-in-\\nan-asp-net-mvc-application \\n\\u2022 \\nCesar de la Torre.\", \" Using Resilient Entity Framework Core SQL Connections and \\nTransactions \\nhttps://devblogs.microsoft\", \".com/cesardelatorre/using-resilient-entity-framework-core-sql-\\nconnections-and-transactions-retries-\", \"with-exponential-backoff/ \\nUse IHttpClientFactory to implement resilient HTTP \\nrequests \\nIHttpClient\", \"Factory is a contract implemented by DefaultHttpClientFactory, an opinionated factory, \\navailable si\", \"nce .NET Core 2.1, for creating HttpClient instances to be used in your applications. \\nIssues with t\", \"he original HttpClient class available in .NET \\nThe original and well-known HttpClient class can be \", \"easily used, but in some cases, it isn\\u2019t being \\nproperly used by many developers. \\nThough this class\", \" implements IDisposable, declaring and instantiating it within a using statement is \\nnot preferred b\", \"ecause when the HttpClient object gets disposed of, the underlying socket is not \\nimmediately releas\", \"ed, which can lead to a socket exhaustion problem. For more information about this \\nissue, see the b\", \"log post You\\u2019re using HttpClient wrong and it\\u2019s destabilizing your software. \\nTherefore, HttpClient \", \"is intended to be instantiated once and reused throughout the life of an \\napplication. Instantiating\", \" an HttpClient class for every request will exhaust the number of sockets \\navailable under heavy loa\", \"ds. That issue will result in SocketException errors. Possible approaches to \\nsolve that problem are\", \" based on the creation of the HttpClient object as singleton or static, as \\nexplained in this Micros\", \"oft article on HttpClient usage. This can be a good solution for short-lived \\nconsole apps or simila\", \"r, that run a few times a day. \\n \\n299 \\nCHAPTER 7 | Implement resilient applications \\n \\nAnother issue\", \" that developers run into is when using a shared instance of HttpClient in long-running \\nprocesses. \", \"In a situation where the HttpClient is instantiated as a singleton or a static object, it fails to \\n\", \"handle the DNS changes as described in this issue of the dotnet/runtime GitHub repository. \\nHowever,\", \" the issue isn\\u2019t really with HttpClient per se, but with the default constructor for HttpClient, \\nbe\", \"cause it creates a new concrete instance of HttpMessageHandler, which is the one that has sockets \\ne\", \"xhaustion and DNS changes issues mentioned above. \\nTo address the issues mentioned above and to make\", \" HttpClient instances manageable, .NET Core 2.1 \\nintroduced two approaches, one of them being IHttpC\", \"lientFactory. It\\u2019s an interface that\\u2019s used to \\nconfigure and create HttpClient instances in an app \", \"through Dependency Injection (DI). It also \\nprovides extensions for Polly-based middleware to take a\", \"dvantage of delegating handlers in \\nHttpClient. \\nThe alternative is to use SocketsHttpHandler with c\", \"onfigured PooledConnectionLifetime. This \\napproach is applied to long-lived, static or singleton Htt\", \"pClient instances. To learn more about \\ndifferent strategies, see HttpClient guidelines for .NET. \\nP\", \"olly is a transient-fault-handling library that helps developers add resiliency to their application\", \"s, by \\nusing some pre-defined policies in a fluent and thread-safe manner. \\nBenefits of using IHttpC\", \"lientFactory \\nThe current implementation of IHttpClientFactory, that also implements IHttpMessageHan\", \"dlerFactory, \\noffers the following benefits: \\n\\u2022 \\nProvides a central location for naming and configur\", \"ing logical HttpClient objects. For \\nexample, you may configure a client (Service Agent) that\\u2019s pre-\", \"configured to access a specific \\nmicroservice. \\n\\u2022 \\nCodify the concept of outgoing middleware via del\", \"egating handlers in HttpClient and \\nimplementing Polly-based middleware to take advantage of Polly\\u2019s\", \" policies for resiliency. \\n\\u2022 \\nHttpClient already has the concept of delegating handlers that could b\", \"e linked together for \\noutgoing HTTP requests. You can register HTTP clients into the factory and yo\", \"u can use a \\nPolly handler to use Polly policies for Retry, CircuitBreakers, and so on. \\n\\u2022 \\nManage t\", \"he lifetime of HttpMessageHandler to avoid the mentioned problems/issues that \\ncan occur when managi\", \"ng HttpClient lifetimes yourself. \\nTip \\nThe HttpClient instances injected by DI can be disposed of s\", \"afely, because the associated \\nHttpMessageHandler is managed by the factory. Injected HttpClient ins\", \"tances are Transient from a DI \\nperspective, while HttpMessageHandler instances can be regarded as S\", \"coped. HttpMessageHandler \\ninstances have their own DI scopes, separate from the application scopes \", \"(for example, ASP.NET \\nincoming request scopes). For more information, see Using HttpClientFactory i\", \"n .NET. \\n \\n \\n \\n300 \\nCHAPTER 7 | Implement resilient applications \\n \\nNote \\nThe implementation of IHtt\", \"pClientFactory (DefaultHttpClientFactory) is tightly tied to the DI \\nimplementation in the Microsoft\", \".Extensions.DependencyInjection NuGet package. If you need to use \\nHttpClient without DI or with oth\", \"er DI implementations, consider using a static or singleton HttpClient \\nwith PooledConnectionLifetim\", \"e set up. For more information, see HttpClient guidelines for .NET. \\nMultiple ways to use IHttpClien\", \"tFactory \\nThere are several ways that you can use IHttpClientFactory in your application: \\n\\u2022 \\nBasic \", \"usage \\n\\u2022 \\nUse Named Clients \\n\\u2022 \\nUse Typed Clients \\n\\u2022 \\nUse Generated Clients \\nFor the sake of brevity\", \", this guidance shows the most structured way to use IHttpClientFactory, which \\nis to use Typed Clie\", \"nts (Service Agent pattern). However, all options are documented and are currently \\nlisted in this a\", \"rticle covering the IHttpClientFactory usage. \\nNote \\nIf your app requires cookies, it might be bette\", \"r to avoid using IHttpClientFactory in your app. For \\nalternative ways of managing clients, see Guid\", \"elines for using HTTP clients \\nHow to use Typed Clients with IHttpClientFactory \\nSo, what\\u2019s a \\u201cTyped\", \" Client\\u201d? It\\u2019s just an HttpClient that\\u2019s pre-configured for some specific use. This \\nconfiguration c\", \"an include specific values such as the base server, HTTP headers or time outs. \\nThe following diagra\", \"m shows how Typed Clients are used with IHttpClientFactory: \\n \\n301 \\nCHAPTER 7 | Implement resilient \", \"applications \\n \\n \\nFigure 8-4. Using IHttpClientFactory with Typed Client classes. \\nIn the above imag\", \"e, a ClientService (used by a controller or client code) uses an HttpClient created by \\nthe register\", \"ed IHttpClientFactory. This factory assigns an HttpMessageHandler from a pool to the \\nHttpClient. Th\", \"e HttpClient can be configured with Polly\\u2019s policies when registering the \\nIHttpClientFactory in the\", \" DI container with the extension method AddHttpClient. \\nTo configure the above structure, add IHttpC\", \"lientFactory in your application by installing the \\nMicrosoft.Extensions.Http NuGet package that inc\", \"ludes the AddHttpClient extension method for \\nIServiceCollection. This extension method registers th\", \"e internal DefaultHttpClientFactory class to be \\nused as a singleton for the interface IHttpClientFa\", \"ctory. It defines a transient configuration for the \\nHttpMessageHandlerBuilder. This message handler\", \" (HttpMessageHandler object), taken from a pool, \\nis used by the HttpClient returned from the factor\", \"y. \\nIn the next snippet, you can see how AddHttpClient() can be used to register Typed Clients (Serv\", \"ice \\nAgents) that need to use HttpClient. \\n// Program.cs \\n//Add http client services at ConfigureSer\", \"vices(IServiceCollection services) \\nbuilder.Services.AddHttpClient<ICatalogService, CatalogService>(\", \"); \\nbuilder.Services.AddHttpClient<IBasketService, BasketService>(); \\nbuilder.Services.AddHttpClient\", \"<IOrderingService, OrderingService>(); \\n \\n302 \\nCHAPTER 7 | Implement resilient applications \\n \\nRegis\", \"tering the client services as shown in the previous snippet, makes the DefaultClientFactory create \\n\", \"a standard HttpClient for each service. The typed client is registered as transient with DI containe\", \"r. In \\nthe preceding code, AddHttpClient() registers CatalogService, BasketService, OrderingService \", \"as \\ntransient services so they can be injected and consumed directly without any need for additional\", \" \\nregistrations. \\nYou could also add instance-specific configuration in the registration to, for exa\", \"mple, configure the \\nbase address, and add some resiliency policies, as shown in the following: \\nbui\", \"lder.Services.AddHttpClient<ICatalogService, CatalogService>(client => \\n{ \\n    client.BaseAddress = \", \"new Uri(builder.Configuration[\\\"BaseUrl\\\"]); \\n}) \\n    .AddPolicyHandler(GetRetryPolicy()) \\n    .AddPol\", \"icyHandler(GetCircuitBreakerPolicy()); \\nIn this next example, you can see the configuration of one o\", \"f the above policies: \\nstatic IAsyncPolicy<HttpResponseMessage> GetRetryPolicy() \\n{ \\n    return Http\", \"PolicyExtensions \\n        .HandleTransientHttpError() \\n        .OrResult(msg => msg.StatusCode == Sy\", \"stem.Net.HttpStatusCode.NotFound) \\n        .WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSecond\", \"s(Math.Pow(2, \\nretryAttempt))); \\n} \\nYou can find more details about using Polly in the Next article.\", \" \\nHttpClient lifetimes \\nEach time you get an HttpClient object from the IHttpClientFactory, a new in\", \"stance is returned. But \\neach HttpClient uses an HttpMessageHandler that\\u2019s pooled and reused by the \", \"IHttpClientFactory to \\nreduce resource consumption, as long as the HttpMessageHandler\\u2019s lifetime has\", \"n\\u2019t expired. \\nPooling of handlers is desirable as each handler typically manages its own underlying \", \"HTTP \\nconnections; creating more handlers than necessary can result in connection delays. Some handl\", \"ers \\nalso keep connections open indefinitely, which can prevent the handler from reacting to DNS \\nch\", \"anges. \\nThe HttpMessageHandler objects in the pool have a lifetime that\\u2019s the length of time that an\", \" \\nHttpMessageHandler instance in the pool can be reused. The default value is two minutes, but it ca\", \"n \\nbe overridden per Typed Client. To override it, call SetHandlerLifetime() on the IHttpClientBuild\", \"er \\nthat\\u2019s returned when creating the client, as shown in the following code: \\n//Set 5 min as the li\", \"fetime for the HttpMessageHandler objects in the pool used for the \\nCatalog Typed Client \\nbuilder.Se\", \"rvices.AddHttpClient<ICatalogService, CatalogService>() \\n    .SetHandlerLifetime(TimeSpan.FromMinute\", \"s(5)); \\nEach Typed Client can have its own configured handler lifetime value. Set the lifetime to \\nI\", \"nfiniteTimeSpan to disable handler expiry. \\n \\n303 \\nCHAPTER 7 | Implement resilient applications \\n \\nI\", \"mplement your Typed Client classes that use the injected and configured \\nHttpClient \\nAs a previous s\", \"tep, you need to have your Typed Client classes defined, such as the classes in the \\nsample code, li\", \"ke \\u2018BasketService\\u2019, \\u2018CatalogService\\u2019, \\u2018OrderingService\\u2019, etc. \\u2013 A Typed Client is a class \\nthat acce\", \"pts an HttpClient object (injected through its constructor) and uses it to call some remote \\nHTTP se\", \"rvice. For example: \\npublic class CatalogService : ICatalogService \\n{ \\n    private readonly HttpClie\", \"nt _httpClient; \\n    private readonly string _remoteServiceBaseUrl; \\n \\n    public CatalogService(Htt\", \"pClient httpClient) \\n    { \\n        _httpClient = httpClient; \\n    } \\n \\n    public async Task<Catalo\", \"g> GetCatalogItems(int page, int take, \\n                                               int? brand, i\", \"nt? type) \\n    { \\n        var uri = API.Catalog.GetAllCatalogItems(_remoteServiceBaseUrl, \\n         \", \"                                        page, take, brand, type); \\n \\n        var responseString = aw\", \"ait _httpClient.GetStringAsync(uri); \\n \\n        var catalog = JsonConvert.DeserializeObject<Catalog>\", \"(responseString); \\n        return catalog; \\n    } \\n} \\nThe Typed Client (CatalogService in the exampl\", \"e) is activated by DI (Dependency Injection), which \\nmeans it can accept any registered service in i\", \"ts constructor, in addition to HttpClient. \\nA Typed Client is effectively a transient object, that m\", \"eans a new instance is created each time one is \\nneeded. It receives a new HttpClient instance each \", \"time it\\u2019s constructed. However, the \\nHttpMessageHandler objects in the pool are the objects that are\", \" reused by multiple HttpClient \\ninstances. \\nUse your Typed Client classes \\nFinally, once you have yo\", \"ur typed classes implemented, you can have them registered and configured \\nwith AddHttpClient(). Aft\", \"er that you can use them wherever services are injected by DI, such as in \\nRazor page code or an MVC\", \" web app controller, shown in the below code from eShopOnContainers: \\nnamespace Microsoft.eShopOnCon\", \"tainers.WebMVC.Controllers \\n{ \\n    public class CatalogController : Controller \\n    { \\n        priva\", \"te ICatalogService _catalogSvc; \\n \\n        public CatalogController(ICatalogService catalogSvc) => \\n\", \"                                                           _catalogSvc = catalogSvc; \\n \\n        publ\", \"ic async Task<IActionResult> Index(int? BrandFilterApplied, \\n                                       \", \"        int? TypesFilterApplied, \\n \\n304 \\nCHAPTER 7 | Implement resilient applications \\n \\n           \", \"                                    int? page, \\n                                               [From\", \"Query]string errorMsg) \\n        { \\n            var itemsPage = 10; \\n            var catalog = await \", \"_catalogSvc.GetCatalogItems(page ?? 0, \\n                                                            \", \"itemsPage, \\n                                                            BrandFilterApplied, \\n       \", \"                                                     TypesFilterApplied); \\n            //\\u2026 Additiona\", \"l code \\n        } \\n \\n        } \\n} \\nUp to this point, the above code snippet only shows the example o\", \"f performing regular HTTP \\nrequests. But the \\u2018magic\\u2019 comes in the following sections where it shows \", \"how all the HTTP requests \\nmade by HttpClient can have resilient policies such as retries with expon\", \"ential backoff, circuit \\nbreakers, security features using auth tokens, or even any other custom fea\", \"ture. And all of these can \\nbe done just by adding policies and delegating handlers to your register\", \"ed Typed Clients. \\nAdditional resources \\n\\u2022 \\nHttpClient guidelines for .NET \\nhttps://learn.microsoft.\", \"com/en-us/dotnet/fundamentals/networking/http/httpclient-\\nguidelines \\n\\u2022 \\nUsing HttpClientFactory in \", \".NET \\nhttps://learn.microsoft.com/en-us/dotnet/core/extensions/httpclient-factory \\n\\u2022 \\nUsing HttpClie\", \"ntFactory in ASP.NET Core \\nhttps://learn.microsoft.com/aspnet/core/fundamentals/http-requests \\n\\u2022 \\nHt\", \"tpClientFactory source code in the dotnet/runtime GitHub repository \\nhttps://github.com/dotnet/runti\", \"me/tree/release/7.0/src/libraries/Microsoft.Extensions.Http/ \\n\\u2022 \\nPolly (.NET resilience and transien\", \"t-fault-handling library) \\nhttps://thepollyproject.azurewebsites.net/ \\nImplement HTTP call retries w\", \"ith exponential backoff \\nwith IHttpClientFactory and Polly policies \\nThe recommended approach for re\", \"tries with exponential backoff is to take advantage of more \\nadvanced .NET libraries like the open-s\", \"ource Polly library. \\nPolly is a .NET library that provides resilience and transient-fault handling \", \"capabilities. You can \\nimplement those capabilities by applying Polly policies such as Retry, Circui\", \"t Breaker, Bulkhead \\nIsolation, Timeout, and Fallback. Polly targets .NET Framework 4.x and .NET Sta\", \"ndard 1.0, 1.1, and 2.0 \\n(which supports .NET Core and later). \\n \\n305 \\nCHAPTER 7 | Implement resilie\", \"nt applications \\n \\nThe following steps show how you can use Http retries with Polly integrated into \", \"IHttpClientFactory, \\nwhich is explained in the previous section. \\nInstall .NET packages \\nFirst, you \", \"will need to install the Microsoft.Extensions.Http.Polly package. \\n\\u2022 \\nInstall with Visual Studio \\n\\u2022 \", \"\\nInstall with dotnet CLI \\n\\u2022 \\nInstall with nuget.exe CLI \\n\\u2022 \\nInstall with Package Manager Console (Po\", \"werShell) \\nReference the .NET 7 packages \\nIHttpClientFactory is available since .NET Core 2.1, howev\", \"er, we recommend you use the latest .NET 7 \\npackages from NuGet in your project. You typically also \", \"need to reference the extension package \\nMicrosoft.Extensions.Http.Polly. \\nConfigure a client with P\", \"olly\\u2019s Retry policy, in app startup \\nThe AddPolicyHandler() method is what adds policies to the Http\", \"Client objects you\\u2019ll use. In this \\ncase, it\\u2019s adding a Polly\\u2019s policy for Http Retries with exponen\", \"tial backoff. \\nTo have a more modular approach, the Http Retry Policy can be defined in a separate m\", \"ethod within \\nthe Program.cs file, as shown in the following code: \\nstatic IAsyncPolicy<HttpResponse\", \"Message> GetRetryPolicy() \\n{ \\n    return HttpPolicyExtensions \\n        .HandleTransientHttpError() \\n\", \"        .OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound) \\n        .WaitAndRetr\", \"yAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, \\n                                        \", \"                            retryAttempt))); \\n} \\nAs shown in previous sections, you need to define a\", \" named or typed client HttpClient configuration in \\nyour standard Program.cs app configuration. Now \", \"you add incremental code specifying the policy for \\nthe Http retries with exponential backoff, as fo\", \"llows: \\n// Program.cs \\nbuilder.Services.AddHttpClient<IBasketService, BasketService>() \\n        .Set\", \"HandlerLifetime(TimeSpan.FromMinutes(5))  //Set lifetime to five minutes \\n        .AddPolicyHandler(\", \"GetRetryPolicy()); \\nWith Polly, you can define a Retry policy with the number of retries, the expone\", \"ntial backoff \\nconfiguration, and the actions to take when there\\u2019s an HTTP exception, such as loggin\", \"g the error. In \\nthis case, the policy is configured to try six times with an exponential retry, sta\", \"rting at two seconds. \\nAdd a jitter strategy to the retry policy \\nA regular Retry policy can affect \", \"your system in cases of high concurrency and scalability and under \\nhigh contention. To overcome pea\", \"ks of similar retries coming from many clients in partial outages, a \\ngood workaround is to add a ji\", \"tter strategy to the retry algorithm/policy. This strategy can improve \\nthe overall performance of t\", \"he end-to-end system. As recommended in Polly: Retry with Jitter, a good \\n \\n306 \\nCHAPTER 7 | Impleme\", \"nt resilient applications \\n \\njitter strategy can be implemented by smooth and evenly distributed ret\", \"ry intervals applied with a \\nwell-controlled median initial retry delay on an exponential backoff. T\", \"his approach helps to spread out \\nthe spikes when the issue arises. The principle is illustrated by \", \"the following example: \\n \\nvar delay = Backoff.DecorrelatedJitterBackoffV2(medianFirstRetryDelay: \\nTi\", \"meSpan.FromSeconds(1), retryCount: 5); \\n \\nvar retryPolicy = Policy \\n    .Handle<FooException>() \\n   \", \" .WaitAndRetryAsync(delay); \\nAdditional resources \\n\\u2022 \\nRetry pattern https://learn.microsoft.com/azur\", \"e/architecture/patterns/retry \\n\\u2022 \\nPolly and IHttpClientFactory https://github.com/App-vNext/Polly/wi\", \"ki/Polly-and-\\nHttpClientFactory \\n\\u2022 \\nPolly (.NET resilience and transient-fault-handling library) htt\", \"ps://github.com/App-\\nvNext/Polly \\n\\u2022 \\nPolly: Retry with Jitter https://github.com/App-vNext/Polly/wik\", \"i/Retry-with-jitter \\n\\u2022 \\nMarc Brooker. Jitter: Making Things Better With Randomness \\nhttps://brooker.\", \"co.za/blog/2015/03/21/backoff.html \\nImplement the Circuit Breaker pattern \\nAs noted earlier, you sho\", \"uld handle faults that might take a variable amount of time to recover from, \\nas might happen when y\", \"ou try to connect to a remote service or resource. Handling this type of fault \\ncan improve the stab\", \"ility and resiliency of an application. \\nIn a distributed environment, calls to remote resources and\", \" services can fail due to transient faults, \\nsuch as slow network connections and timeouts, or if re\", \"sources are responding slowly or are \\ntemporarily unavailable. These faults typically correct themse\", \"lves after a short time, and a robust cloud \\napplication should be prepared to handle them by using \", \"a strategy like the \\u201cRetry pattern\\u201d. \\nHowever, there can also be situations where faults are due to \", \"unanticipated events that might take \\nmuch longer to fix. These faults can range in severity from a \", \"partial loss of connectivity to the \\ncomplete failure of a service. In these situations, it might be\", \" pointless for an application to continually \\nretry an operation that\\u2019s unlikely to succeed. \\nInstea\", \"d, the application should be coded to accept that the operation has failed and handle the failure \\na\", \"ccordingly. \\nUsing Http retries carelessly could result in creating a Denial of Service (DoS) attack\", \" within your own \\nsoftware. As a microservice fails or performs slowly, multiple clients might repea\", \"tedly retry failed \\nrequests. That creates a dangerous risk of exponentially increasing traffic targ\", \"eted at the failing \\nservice. \\n \\n307 \\nCHAPTER 7 | Implement resilient applications \\n \\nTherefore, you\", \" need some kind of defense barrier so that excessive requests stop when it isn\\u2019t worth \\nto keep tryi\", \"ng. That defense barrier is precisely the circuit breaker. \\nThe Circuit Breaker pattern has a differ\", \"ent purpose than the \\u201cRetry pattern\\u201d. The \\u201cRetry pattern\\u201d \\nenables an application to retry an operat\", \"ion in the expectation that the operation will eventually \\nsucceed. The Circuit Breaker pattern prev\", \"ents an application from performing an operation that\\u2019s \\nlikely to fail. An application can combine \", \"these two patterns. However, the retry logic should be \\nsensitive to any exception returned by the c\", \"ircuit breaker, and it should abandon retry attempts if the \\ncircuit breaker indicates that a fault \", \"is not transient. \\nImplement Circuit Breaker pattern with IHttpClientFactory and Polly \\nAs when impl\", \"ementing retries, the recommended approach for circuit breakers is to take advantage of \\nproven .NET\", \" libraries like Polly and its native integration with IHttpClientFactory. \\nAdding a circuit breaker \", \"policy into your IHttpClientFactory outgoing middleware pipeline is as simple \\nas adding a single in\", \"cremental piece of code to what you already have when using IHttpClientFactory. \\nThe only addition h\", \"ere to the code used for HTTP call retries is the code where you add the Circuit \\nBreaker policy to \", \"the list of policies to use, as shown in the following incremental code. \\n// Program.cs \\nvar retryPo\", \"licy = GetRetryPolicy(); \\nvar circuitBreakerPolicy = GetCircuitBreakerPolicy(); \\n \\nbuilder.Services.\", \"AddHttpClient<IBasketService, BasketService>() \\n        .SetHandlerLifetime(TimeSpan.FromMinutes(5))\", \"  // Sample: default lifetime is 2 \\nminutes \\n        .AddHttpMessageHandler<HttpClientAuthorizationD\", \"elegatingHandler>() \\n        .AddPolicyHandler(retryPolicy) \\n        .AddPolicyHandler(circuitBreake\", \"rPolicy); \\nThe AddPolicyHandler() method is what adds policies to the HttpClient objects you\\u2019ll use.\", \" In this case, \\nit\\u2019s adding a Polly policy for a circuit breaker. \\nTo have a more modular approach, \", \"the Circuit Breaker Policy is defined in a separate method called \\nGetCircuitBreakerPolicy(), as sho\", \"wn in the following code: \\n// also in Program.cs \\nstatic IAsyncPolicy<HttpResponseMessage> GetCircui\", \"tBreakerPolicy() \\n{ \\n    return HttpPolicyExtensions \\n        .HandleTransientHttpError() \\n        .\", \"CircuitBreakerAsync(5, TimeSpan.FromSeconds(30)); \\n} \\nIn the code example above, the circuit breaker\", \" policy is configured so it breaks or opens the circuit \\nwhen there have been five consecutive fault\", \"s when retrying the Http requests. When that happens, \\nthe circuit will break for 30 seconds: in tha\", \"t period, calls will be failed immediately by the circuit-\\nbreaker rather than actually be placed. T\", \"he policy automatically interprets relevant exceptions and \\nHTTP status codes as faults. \\nCircuit br\", \"eakers should also be used to redirect requests to a fallback infrastructure if you had issues \\nin a\", \" particular resource that\\u2019s deployed in a different environment than the client application or \\n \\n30\", \"8 \\nCHAPTER 7 | Implement resilient applications \\n \\nservice that\\u2019s performing the HTTP call. That way\", \", if there\\u2019s an outage in the datacenter that impacts \\nonly your backend microservices but not your \", \"client applications, the client applications can redirect \\nto the fallback services. Polly is planni\", \"ng a new policy to automate this failover policy scenario. \\nAll those features are for cases where y\", \"ou\\u2019re managing the failover from within the .NET code, as \\nopposed to having it managed automaticall\", \"y for you by Azure, with location transparency. \\nFrom a usage point of view, when using HttpClient, \", \"there\\u2019s no need to add anything new here \\nbecause the code is the same than when using HttpClient wi\", \"th IHttpClientFactory, as shown in \\nprevious sections. \\nTest Http retries and circuit breakers in eS\", \"hopOnContainers \\nWhenever you start the eShopOnContainers solution in a Docker host, it needs to sta\", \"rt multiple \\ncontainers. Some of the containers are slower to start and initialize, like the SQL Ser\", \"ver container. This \\nis especially true the first time you deploy the eShopOnContainers application \", \"into Docker because it \\nneeds to set up the images and the database. The fact that some containers s\", \"tart slower than others \\ncan cause the rest of the services to initially throw HTTP exceptions, even\", \" if you set dependencies \\nbetween containers at the docker-compose level, as explained in previous s\", \"ections. Those docker-\\ncompose dependencies between containers are just at the process level. The co\", \"ntainer\\u2019s entry point \\nprocess might be started, but SQL Server might not be ready for queries. The \", \"result can be a cascade \\nof errors, and the application can get an exception when trying to consume \", \"that particular container. \\nYou might also see this type of error on startup when the application is\", \" deploying to the cloud. In that \\ncase, orchestrators might be moving containers from one node or VM\", \" to another (that is, starting new \\ninstances) when balancing the number of containers across the cl\", \"uster\\u2019s nodes. \\nThe way \\u2018eShopOnContainers\\u2019 solves those issues when starting all the containers is \", \"by using the Retry \\npattern illustrated earlier. \\nTest the circuit breaker in eShopOnContainers \\nThe\", \"re are a few ways you can break/open the circuit and test it with eShopOnContainers. \\nOne option is \", \"to lower the allowed number of retries to 1 in the circuit breaker policy and redeploy \\nthe whole so\", \"lution into Docker. With a single retry, there\\u2019s a good chance that an HTTP request will \\nfail durin\", \"g deployment, the circuit breaker will open, and you get an error. \\nAnother option is to use custom \", \"middleware that\\u2019s implemented in the Basket microservice. When \\nthis middleware is enabled, it catch\", \"es all HTTP requests and returns status code 500. You can enable \\nthe middleware by making a GET req\", \"uest to the failing URI, like the following: \\n\\u2022 \\nGET http://localhost:5103/failing \\nThis request ret\", \"urns the current state of the middleware. If the middleware is enabled, the \\nrequest return status c\", \"ode 500. If the middleware is disabled, there\\u2019s no response. \\n\\u2022 \\nGET http://localhost:5103/failing?e\", \"nable \\nThis request enables the middleware. \\n \\n309 \\nCHAPTER 7 | Implement resilient applications \\n \\n\", \"\\u2022 \\nGET http://localhost:5103/failing?disable \\nThis request disables the middleware. \\nFor instance, o\", \"nce the application is running, you can enable the middleware by making a request \\nusing the followi\", \"ng URI in any browser. Note that the ordering microservice uses port 5103. \\nhttp://localhost:5103/fa\", \"iling?enable \\nYou can then check the status using the URI http://localhost:5103/failing, as shown in\", \" Figure 8-5. \\n \\nFigure 8-5. Checking the state of the \\u201cFailing\\u201d ASP.NET middleware \\u2013 In this case, d\", \"isabled. \\nAt this point, the Basket microservice responds with status code 500 whenever you call inv\", \"oke it. \\nOnce the middleware is running, you can try making an order from the MVC web application. B\", \"ecause \\nthe requests fail, the circuit will open. \\nIn the following example, you can see that the MV\", \"C web application has a catch block in the logic for \\nplacing an order. If the code catches an open-\", \"circuit exception, it shows the user a friendly message \\ntelling them to wait. \\npublic class CartCon\", \"troller : Controller \\n{ \\n    //\\u2026 \\n    public async Task<IActionResult> Index() \\n    { \\n        try \\n\", \"        { \\n            var user = _appUserParser.Parse(HttpContext.User); \\n            //Http reques\", \"ts using the Typed Client (Service Agent) \\n            var vm = await _basketSvc.GetBasket(user); \\n \", \"           return View(vm); \\n        } \\n        catch (BrokenCircuitException) \\n        { \\n         \", \"   // Catches error when Basket.api is in circuit-opened mode \\n            HandleBrokenCircuitExcept\", \"ion(); \\n        } \\n        return View(); \\n    } \\n \\n    private void HandleBrokenCircuitException() \", \"\\n    { \\n        TempData[\\\"BasketInoperativeMsg\\\"] = \\\"Basket Service is inoperative, please try later \", \"\\non. (Business message due to Circuit-Breaker)\\\"; \\n    } \\n} \\nHere\\u2019s a summary. The Retry policy tries\", \" several times to make the HTTP request and gets HTTP errors. \\nWhen the number of retries reaches th\", \"e maximum number set for the Circuit Breaker policy (in this \\ncase, 5), the application throws a Bro\", \"kenCircuitException. The result is a friendly message, as shown in \\nFigure 8-6. \\n \\n310 \\nCHAPTER 7 | \", \"Implement resilient applications \\n \\n \\nFigure 8-6. Circuit breaker returning an error to the UI \\nYou \", \"can implement different logic for when to open/break the circuit. Or you can try an HTTP request \\nag\", \"ainst a different back-end microservice if there\\u2019s a fallback datacenter or redundant back-end \\nsyst\", \"em. \\nFinally, another possibility for the CircuitBreakerPolicy is to use Isolate (which forces open \", \"and holds \\nopen the circuit) and Reset (which closes it again). These could be used to build a utili\", \"ty HTTP \\nendpoint that invokes Isolate and Reset directly on the policy. Such an HTTP endpoint could\", \" also be \\nused, suitably secured, in production for temporarily isolating a downstream system, such \", \"as when \\nyou want to upgrade it. Or it could trip the circuit manually to protect a downstream syste\", \"m you \\nsuspect to be faulting. \\nAdditional resources \\n\\u2022 \\nCircuit Breaker pattern \\nhttps://learn.micr\", \"osoft.com/azure/architecture/patterns/circuit-breaker \\nHealth monitoring \\nHealth monitoring can allo\", \"w near-real-time information about the state of your containers and \\nmicroservices. Health monitorin\", \"g is critical to multiple aspects of operating microservices and is \\nespecially important when orche\", \"strators perform partial application upgrades in phases, as explained \\nlater. \\nMicroservices-based a\", \"pplications often use heartbeats or health checks to enable their performance \\nmonitors, schedulers,\", \" and orchestrators to keep track of the multitude of services. If services cannot \\nsend some sort of\", \" \\u201cI\\u2019m alive\\u201d signal, either on demand or on a schedule, your application might face \\nrisks when you \", \"deploy updates, or it might just detect failures too late and not be able to stop \\ncascading failure\", \"s that can end up in major outages. \\nIn the typical model, services send reports about their status,\", \" and that information is aggregated to \\nprovide an overall view of the state of health of your appli\", \"cation. If you\\u2019re using an orchestrator, you \\ncan provide health information to your orchestrator\\u2019s \", \"cluster, so that the cluster can act accordingly. If \\nyou invest in high-quality health reporting th\", \"at\\u2019s customized for your application, you can detect and \\nfix issues for your running application mu\", \"ch more easily. \\n \\n311 \\nCHAPTER 7 | Implement resilient applications \\n \\nImplement health checks in A\", \"SP.NET Core services \\nWhen developing an ASP.NET Core microservice or web application, you can use t\", \"he built-in health \\nchecks feature that was released in ASP .NET Core 2.2 \\n(Microsoft.Extensions.Dia\", \"gnostics.HealthChecks). Like many ASP.NET Core features, health checks \\ncome with a set of services \", \"and a middleware. \\nHealth check services and middleware are easy to use and provide capabilities tha\", \"t let you validate if \\nany external resource needed for your application (like a SQL Server database\", \" or a remote API) is \\nworking properly. When you use this feature, you can also decide what it means\", \" that the resource is \\nhealthy, as we explain later. \\nTo use this feature effectively, you need to f\", \"irst configure services in your microservices. Second, you \\nneed a front-end application that querie\", \"s for the health reports. That front-end application could be a \\ncustom reporting application, or it\", \" could be an orchestrator itself that can react accordingly to the \\nhealth states. \\nUse the HealthCh\", \"ecks feature in your back-end ASP.NET microservices \\nIn this section, you\\u2019ll learn how to implement \", \"the HealthChecks feature in a sample ASP.NET Core 7.0 \\nWeb API application when using the Microsoft.\", \"Extensions.Diagnostics.HealthChecks package. The \\nImplementation of this feature in a large-scale mi\", \"croservices like the eShopOnContainers is explained \\nin the next section. \\nTo begin, you need to def\", \"ine what constitutes a healthy status for each microservice. In the sample \\napplication, we define t\", \"he microservice is healthy if its API is accessible via HTTP and its related SQL \\nServer database is\", \" also available. \\nIn .NET 7, with the built-in APIs, you can configure the services, add a Health Ch\", \"eck for the \\nmicroservice and its dependent SQL Server database in this way: \\n// Program.cs from .NE\", \"T 7 Web API sample \\n \\n//... \\n// Registers required services for health checks \\nbuilder.Services.AddH\", \"ealthChecks() \\n    // Add a health check for a SQL Server database \\n    .AddCheck( \\n        \\\"Orderin\", \"gDB-check\\\", \\n        new SqlConnectionHealthCheck(builder.Configuration[\\\"ConnectionString\\\"]), \\n     \", \"   HealthStatus.Unhealthy, \\n        new string[] { \\\"orderingdb\\\" }); \\nIn the previous code, the servi\", \"ces.AddHealthChecks() method configures a basic HTTP check that \\nreturns a status code 200 with \\u201cHea\", \"lthy\\u201d. Further, the AddCheck() extension method configures a \\ncustom SqlConnectionHealthCheck that c\", \"hecks the related SQL Database\\u2019s health. \\nThe AddCheck() method adds a new health check with a speci\", \"fied name and the implementation of \\ntype IHealthCheck. You can add multiple Health Checks using Add\", \"Check method, so a microservice \\nwon\\u2019t provide a \\u201chealthy\\u201d status until all its checks are healthy. \", \"\\n \\n312 \\nCHAPTER 7 | Implement resilient applications \\n \\nSqlConnectionHealthCheck is a custom class t\", \"hat implements IHealthCheck, which takes a connection \\nstring as a constructor parameter and execute\", \"s a simple query to check if the connection to the SQL \\ndatabase is successful. It returns HealthChe\", \"ckResult.Healthy() if the query was executed successfully \\nand a FailureStatus with the actual excep\", \"tion when it fails. \\n// Sample SQL Connection Health Check \\npublic class SqlConnectionHealthCheck : \", \"IHealthCheck \\n{ \\n    private const string DefaultTestQuery = \\\"Select 1\\\"; \\n \\n    public string Connec\", \"tionString { get; } \\n \\n    public string TestQuery { get; } \\n \\n    public SqlConnectionHealthCheck(s\", \"tring connectionString) \\n        : this(connectionString, testQuery: DefaultTestQuery) \\n    { \\n    }\", \" \\n \\n    public SqlConnectionHealthCheck(string connectionString, string testQuery) \\n    { \\n        C\", \"onnectionString = connectionString ?? throw new \\nArgumentNullException(nameof(connectionString)); \\n \", \"       TestQuery = testQuery; \\n    } \\n \\n    public async Task<HealthCheckResult> CheckHealthAsync(He\", \"althCheckContext context, \\nCancellationToken cancellationToken = default(CancellationToken)) \\n    { \", \"\\n        using (var connection = new SqlConnection(ConnectionString)) \\n        { \\n            try \\n \", \"           { \\n                await connection.OpenAsync(cancellationToken); \\n \\n                if (\", \"TestQuery != null) \\n                { \\n                    var command = connection.CreateCommand();\", \" \\n                    command.CommandText = TestQuery; \\n \\n                    await command.ExecuteN\", \"onQueryAsync(cancellationToken); \\n                } \\n            } \\n            catch (DbException e\", \"x) \\n            { \\n                return new HealthCheckResult(status: context.Registration.Failure\", \"Status, \\nexception: ex); \\n            } \\n        } \\n \\n        return HealthCheckResult.Healthy(); \\n \", \"   } \\n} \\nNote that in the previous code, Select 1 is the query used to check the Health of the datab\", \"ase. To \\nmonitor the availability of your microservices, orchestrators like Kubernetes periodically \", \"perform \\nhealth checks by sending requests to test the microservices. It\\u2019s important to keep your da\", \"tabase \\nqueries efficient so that these operations are quick and don\\u2019t result in a higher utilizatio\", \"n of resources. \\n \\n313 \\nCHAPTER 7 | Implement resilient applications \\n \\nFinally, add a middleware th\", \"at responds to the url path /hc: \\n// Program.cs from .NET 7 Web Api sample \\n \\napp.MapHealthChecks(\\\"/\", \"hc\\\"); \\nWhen the endpoint <yourmicroservice>/hc is invoked, it runs all the health checks that are co\", \"nfigured \\nin the AddHealthChecks() method in the Startup class and shows the result. \\nHealthChecks i\", \"mplementation in eShopOnContainers \\nMicroservices in eShopOnContainers rely on multiple services to \", \"perform its task. For example, the \\nCatalog.API microservice from eShopOnContainers depends on many \", \"services, such as Azure Blob \\nStorage, SQL Server, and RabbitMQ. Therefore, it has several health ch\", \"ecks added using the \\nAddCheck() method. For every dependent service, a custom IHealthCheck implemen\", \"tation that \\ndefines its respective health status would need to be added. \\nThe open-source project A\", \"spNetCore.Diagnostics.HealthChecks solves this problem by providing \\ncustom health check implementat\", \"ions for each of these enterprise services, that are built on top of \\n.NET 7. Each health check is a\", \"vailable as an individual NuGet package that can be easily added to the \\nproject. eShopOnContainers \", \"uses them extensively in all its microservices. \\nFor instance, in the Catalog.API microservice, the \", \"following NuGet packages were added: \\n \\nFigure 8-7. Custom Health Checks implemented in Catalog.API \", \"using AspNetCore.Diagnostics.HealthChecks \\nIn the following code, the health check implementations a\", \"re added for each dependent service and \\nthen the middleware is configured: \\n// Extension method fro\", \"m Catalog.api microservice \\n// \\npublic static IServiceCollection AddCustomHealthCheck(this IServiceC\", \"ollection services, \\nIConfiguration configuration) \\n{ \\n    var accountName = configuration.GetValue<\", \"string>(\\\"AzureStorageAccountName\\\"); \\n    var accountKey = configuration.GetValue<string>(\\\"AzureStora\", \"geAccountKey\\\"); \\n \\n    var hcBuilder = services.AddHealthChecks(); \\n \\n314 \\nCHAPTER 7 | Implement res\", \"ilient applications \\n \\n \\n    hcBuilder \\n        .AddSqlServer( \\n            configuration[\\\"Connectio\", \"nString\\\"], \\n            name: \\\"CatalogDB-check\\\", \\n            tags: new string[] { \\\"catalogdb\\\" }); \\n\", \" \\n    if (!string.IsNullOrEmpty(accountName) && !string.IsNullOrEmpty(accountKey)) \\n    { \\n        h\", \"cBuilder \\n            .AddAzureBlobStorage( \\n                \\n$\\\"DefaultEndpointsProtocol=https;Accou\", \"ntName={accountName};AccountKey={accountKey};Endpoint\\nSuffix=core.windows.net\\\", \\n                nam\", \"e: \\\"catalog-storage-check\\\", \\n                tags: new string[] { \\\"catalogstorage\\\" }); \\n    } \\n    i\", \"f (configuration.GetValue<bool>(\\\"AzureServiceBusEnabled\\\")) \\n    { \\n        hcBuilder \\n            .A\", \"ddAzureServiceBusTopic( \\n                configuration[\\\"EventBusConnection\\\"], \\n                topic\", \"Name: \\\"eshop_event_bus\\\", \\n                name: \\\"catalog-servicebus-check\\\", \\n                tags: n\", \"ew string[] { \\\"servicebus\\\" }); \\n    } \\n    else \\n    { \\n        hcBuilder \\n            .AddRabbitMQ(\", \" \\n                $\\\"amqp://{configuration[\\\"EventBusConnection\\\"]}\\\", \\n                name: \\\"catalog-r\", \"abbitmqbus-check\\\", \\n                tags: new string[] { \\\"rabbitmqbus\\\" }); \\n    } \\n \\n    return serv\", \"ices; \\n} \\nFinally, add the HealthCheck middleware to listen to \\u201c/hc\\u201d endpoint: \\n// HealthCheck middl\", \"eware \\napp.UseHealthChecks(\\\"/hc\\\", new HealthCheckOptions() \\n{ \\n    Predicate = _ => true, \\n    Respo\", \"nseWriter = UIResponseWriter.WriteHealthCheckUIResponse \\n}); \\nQuery your microservices to report abo\", \"ut their health status \\nWhen you\\u2019ve configured health checks as described in this article and you ha\", \"ve the microservice \\nrunning in Docker, you can directly check from a browser if it\\u2019s healthy. You h\", \"ave to publish the \\ncontainer port in the Docker host, so you can access the container through the e\", \"xternal Docker host IP \\nor through host.docker.internal, as shown in figure 8-8. \\n \\n315 \\nCHAPTER 7 |\", \" Implement resilient applications \\n \\n \\nFigure 8-8. Checking health status of a single service from a\", \" browser \\nIn that test, you can see that the Catalog.API microservice (running on port 5101) is heal\", \"thy, returning \\nHTTP status 200 and status information in JSON. The service also checked the health \", \"of its SQL Server \\ndatabase dependency and RabbitMQ, so the health check reported itself as healthy.\", \" \\nUse watchdogs \\nA watchdog is a separate service that can watch health and load across services, an\", \"d report health \\nabout the microservices by querying with the HealthChecks library introduced earlie\", \"r. This can help \\nprevent errors that would not be detected based on the view of a single service. W\", \"atchdogs also are a \\ngood place to host code that can perform remediation actions for known conditio\", \"ns without user \\ninteraction. \\nThe eShopOnContainers sample contains a web page that displays sample\", \" health check reports, as \\nshown in Figure 8-9. This is the simplest watchdog you could have since i\", \"t only shows the state of the \\nmicroservices and web applications in eShopOnContainers. Usually a wa\", \"tchdog also takes actions \\nwhen it detects unhealthy states. \\nFortunately, AspNetCore.Diagnostics.He\", \"althChecks also provides AspNetCore.HealthChecks.UI NuGet \\npackage that can be used to display the h\", \"ealth check results from the configured URIs. \\n \\n316 \\nCHAPTER 7 | Implement resilient applications \\n\", \" \\n \\nFigure 8-9. Sample health check report in eShopOnContainers \\nIn summary, this watchdog service q\", \"ueries each microservice\\u2019s \\u201c/hc\\u201d endpoint. This will execute all the \\nhealth checks defined within i\", \"t and return an overall health state depending on all those checks. The \\nHealthChecksUI is easy to c\", \"onsume with a few configuration entries and two lines of code that needs \\nto be added into the Start\", \"up.cs of the watchdog service. \\nSample configuration file for health check UI: \\n// Configuration \\n{ \", \"\\n  \\\"HealthChecksUI\\\": { \\n    \\\"HealthChecks\\\": [ \\n      { \\n        \\\"Name\\\": \\\"Ordering HTTP Check\\\", \\n    \", \"    \\\"Uri\\\": \\\"http://host.docker.internal:5102/hc\\\" \\n      }, \\n      { \\n        \\\"Name\\\": \\\"Ordering HTTP \", \"Background Check\\\", \\n        \\\"Uri\\\": \\\"http://host.docker.internal:5111/hc\\\" \\n      }, \\n      //... \\n   \", \" ]} \\n} \\nProgram.cs file that adds HealthChecksUI: \\n \\n317 \\nCHAPTER 7 | Implement resilient applicatio\", \"ns \\n \\n// Program.cs from WebStatus(Watch Dog) service \\n// \\n// Registers required services for health\", \" checks \\nbuilder.Services.AddHealthChecksUI(); \\n// build the app, register other middleware \\napp.Use\", \"HealthChecksUI(config => config.UIPath = \\\"/hc-ui\\\"); \\nHealth checks when using orchestrators \\nTo moni\", \"tor the availability of your microservices, orchestrators like Kubernetes and Service Fabric \\nperiod\", \"ically perform health checks by sending requests to test the microservices. When an \\norchestrator de\", \"termines that a service/container is unhealthy, it stops routing requests to that \\ninstance. It also\", \" usually creates a new instance of that container. \\nFor instance, most orchestrators can use health \", \"checks to manage zero-downtime deployments. Only \\nwhen the status of a service/container changes to \", \"healthy will the orchestrator start routing traffic to \\nservice/container instances. \\nHealth monitor\", \"ing is especially important when an orchestrator performs an application upgrade. \\nSome orchestrator\", \"s (like Azure Service Fabric) update services in phases\\u2014for example, they might \\nupdate one-fifth of\", \" the cluster surface for each application upgrade. The set of nodes that\\u2019s upgraded \\nat the same tim\", \"e is referred to as an upgrade domain. After each upgrade domain has been upgraded \\nand is available\", \" to users, that upgrade domain must pass health checks before the deployment moves \\nto the next upgr\", \"ade domain. \\nAnother aspect of service health is reporting metrics from the service. This is an adva\", \"nced capability of \\nthe health model of some orchestrators, like Service Fabric. Metrics are importa\", \"nt when using an \\norchestrator because they are used to balance resource usage. Metrics also can be \", \"an indicator of \\nsystem health. For example, you might have an application that has many microservic\", \"es, and each \\ninstance reports a requests-per-second (RPS) metric. If one service is using more reso\", \"urces (memory, \\nprocessor, etc.) than another service, the orchestrator could move service instances\", \" around in the \\ncluster to try to maintain even resource utilization. \\nNote that Azure Service Fabri\", \"c provides its own Health Monitoring model, which is more advanced \\nthan simple health checks. \\nAdva\", \"nced monitoring: visualization, analysis, and alerts \\nThe final part of monitoring is visualizing th\", \"e event stream, reporting on service performance, and \\nalerting when an issue is detected. You can u\", \"se different solutions for this aspect of monitoring. \\nYou can use simple custom applications showin\", \"g the state of your services, like the custom page \\nshown when explaining the AspNetCore.Diagnostics\", \".HealthChecks. Or you could use more advanced \\ntools like Azure Monitor to raise alerts based on the\", \" stream of events. \\nFinally, if you\\u2019re storing all the event streams, you can use Microsoft Power BI\", \" or other solutions like \\nKibana or Splunk to visualize the data. \\n \\n318 \\nCHAPTER 7 | Implement resi\", \"lient applications \\n \\nAdditional resources \\n\\u2022 \\nHealthChecks and HealthChecks UI for ASP.NET Core \\nht\", \"tps://github.com/Xabaril/AspNetCore.Diagnostics.HealthChecks \\n\\u2022 \\nIntroduction to Service Fabric heal\", \"th monitoring \\nhttps://learn.microsoft.com/azure/service-fabric/service-fabric-health-introduction \\n\", \"\\u2022 \\nAzure Monitor \\nhttps://azure.microsoft.com/services/monitor/ \\n \\n319 \\nCHAPTER 8 | Make secure .NET\", \" Microservices and Web Applications \\n \\nCHAPTER 8 \\nMake secure .NET \\nMicroservices and Web \\nApplicati\", \"ons \\nThere are so many aspects about security in microservices and web applications that the topic c\", \"ould \\neasily take several books like this one. So, in this section, we\\u2019ll focus on authentication, a\", \"uthorization, \\nand application secrets. \\nImplement authentication in .NET microservices and \\nweb app\", \"lications \\nIt\\u2019s often necessary for resources and APIs published by a service to be limited to certa\", \"in trusted users \\nor clients. The first step to making these sorts of API-level trust decisions is a\", \"uthentication. \\nAuthentication is the process of reliably verifying a user\\u2019s identity. \\nIn microserv\", \"ice scenarios, authentication is typically handled centrally. If you\\u2019re using an API Gateway, \\nthe g\", \"ateway is a good place to authenticate, as shown in Figure 9-1. If you use this approach, make \\nsure\", \" that the individual microservices cannot be reached directly (without the API Gateway) unless \\naddi\", \"tional security is in place to authenticate messages whether they come from the gateway or not. \\n \\nF\", \"igure 9-1. Centralized authentication with an API Gateway \\nWhen the API Gateway centralizes authenti\", \"cation, it adds user information when forwarding requests \\nto the microservices. If services can be \", \"accessed directly, an authentication service like Azure Active \\n \\n320 \\nCHAPTER 8 | Make secure .NET \", \"Microservices and Web Applications \\n \\nDirectory or a dedicated authentication microservice acting as\", \" a security token service (STS) can be \\nused to authenticate users. Trust decisions are shared betwe\", \"en services with security tokens or \\ncookies. (These tokens can be shared between ASP.NET Core appli\", \"cations, if needed, by implementing \\ncookie sharing.) This pattern is illustrated in Figure 9-2. \\n \\n\", \"Figure 9-2. Authentication by identity microservice; trust is shared using an authorization token \\nW\", \"hen microservices are accessed directly, trust, that includes authentication and authorization, is \\n\", \"handled by a security token issued by a dedicated microservice, shared between microservices. \\nAuthe\", \"nticate with ASP.NET Core Identity \\nThe primary mechanism in ASP.NET Core for identifying an applica\", \"tion\\u2019s users is the ASP.NET Core \\nIdentity membership system. ASP.NET Core Identity stores user info\", \"rmation (including sign-in \\ninformation, roles, and claims) in a data store configured by the develo\", \"per. Typically, the ASP.NET \\nCore Identity data store is an Entity Framework store provided in the \\n\", \"Microsoft.AspNetCore.Identity.EntityFrameworkCore package. However, custom stores or other third-\\npa\", \"rty packages can be used to store identity information in Azure Table Storage, CosmosDB, or other \\nl\", \"ocations. \\nTip \\nASP.NET Core 2.1 and later provides ASP.NET Core Identity as a Razor Class Library, \", \"so you won\\u2019t see \\nmuch of the necessary code in your project, as was the case for previous versions.\", \" For details on how \\nto customize the Identity code to suit your needs, see Scaffold Identity in ASP\", \".NET Core projects. \\nThe following code is taken from the ASP.NET Core Web Application MVC 3.1 proje\", \"ct template with \\nindividual user account authentication selected. It shows how to configure ASP.NET\", \" Core Identity \\nusing Entity Framework Core in the Program.cs file. \\n//... \\nbuilder.Services.AddDbCo\", \"ntext<ApplicationDbContext>(options => \\n    options.UseSqlServer( \\n        builder.Configuration.Get\", \"ConnectionString(\\\"DefaultConnection\\\"))); \\n \\n \\n321 \\nCHAPTER 8 | Make secure .NET Microservices and We\", \"b Applications \\n \\nbuilder.Services.AddDefaultIdentity<IdentityUser>(options => \\n    options.SignIn.R\", \"equireConfirmedAccount = true) \\n        .AddEntityFrameworkStores<ApplicationDbContext>(); \\n \\nbuilde\", \"r.Services.AddRazorPages(); \\n//... \\nOnce ASP.NET Core Identity is configured, you enable it by addin\", \"g the \\napp.UseAuthentication() and endpoints.MapRazorPages() as shown in the following code in the \\n\", \"service\\u2019s Program.cs file: \\n//... \\napp.UseRouting(); \\n \\napp.UseAuthentication(); \\napp.UseAuthorizati\", \"on(); \\n \\napp.UseEndpoints(endpoints => \\n{ \\n    endpoints.MapRazorPages(); \\n}); \\n//... \\n \\n \\nImportant\", \" \\nThe lines in the preceding code MUST BE IN THE ORDER SHOWN for Identity to work correctly. \\nUsing \", \"ASP.NET Core Identity enables several scenarios: \\n\\u2022 \\nCreate new user information using the UserManag\", \"er type (userManager.CreateAsync). \\n\\u2022 \\nAuthenticate users using the SignInManager type. You can use \", \"signInManager.SignInAsync to \\nsign in directly, or signInManager.PasswordSignInAsync to confirm the \", \"user\\u2019s password is \\ncorrect and then sign them in. \\n\\u2022 \\nIdentify a user based on information stored i\", \"n a cookie (which is read by ASP.NET Core \\nIdentity middleware) so that subsequent requests from a b\", \"rowser will include a signed-in \\nuser\\u2019s identity and claims. \\nASP.NET Core Identity also supports tw\", \"o-factor authentication. \\nFor authentication scenarios that make use of a local user data store and \", \"that persist identity between \\nrequests using cookies (as is typical for MVC web applications), ASP.\", \"NET Core Identity is a \\nrecommended solution. \\nAuthenticate with external providers \\nASP.NET Core al\", \"so supports using external authentication providers to let users sign in via OAuth 2.0 \\nflows. This \", \"means that users can sign in using existing authentication processes from providers like \\nMicrosoft,\", \" Google, Facebook, or Twitter and associate those identities with an ASP.NET Core identity \\nin your \", \"application. \\nTo use external authentication, besides including the authentication middleware as men\", \"tioned before, \\nusing the app.UseAuthentication() method, you also have to register the external pro\", \"vider in \\nProgram.cs as shown in the following example: \\n \\n322 \\nCHAPTER 8 | Make secure .NET Microse\", \"rvices and Web Applications \\n \\n//... \\nservices.AddDefaultIdentity<IdentityUser>(options => options.S\", \"ignIn.RequireConfirmedAccount \\n= true) \\n    .AddEntityFrameworkStores<ApplicationDbContext>(); \\n \\nse\", \"rvices.AddAuthentication() \\n    .AddMicrosoftAccount(microsoftOptions => \\n    { \\n        microsoftOp\", \"tions.ClientId = \\nbuilder.Configuration[\\\"Authentication:Microsoft:ClientId\\\"]; \\n        microsoftOpti\", \"ons.ClientSecret = \\nbuilder.Configuration[\\\"Authentication:Microsoft:ClientSecret\\\"]; \\n    }) \\n    .Ad\", \"dGoogle(googleOptions => { ... }) \\n    .AddTwitter(twitterOptions => { ... }) \\n    .AddFacebook(face\", \"bookOptions => { ... }); \\n//... \\nPopular external authentication providers and their associated NuGe\", \"t packages are shown in the \\nfollowing table: \\nProvider \\nPackage \\nMicrosoft \\nMicrosoft.AspNetCore.Au\", \"thentication.MicrosoftAccount \\nGoogle \\nMicrosoft.AspNetCore.Authentication.Google \\nFacebook \\nMicroso\", \"ft.AspNetCore.Authentication.Facebook \\nTwitter \\nMicrosoft.AspNetCore.Authentication.Twitter \\nIn all \", \"cases, you must complete an application registration procedure that is vendor dependent and \\nthat us\", \"ually involves: \\n1. \\nGetting a Client Application ID. \\n2. \\nGetting a Client Application Secret. \\n3. \", \"\\nConfiguring a redirection URL, that\\u2019s handled by the authorization middleware and the \\nregistered p\", \"rovider \\n4. \\nOptionally, configuring a sign-out URL to properly handle sign out in a Single Sign On \", \"(SSO) \\nscenario. \\nFor details on configuring your app for an external provider, see the External pro\", \"vider authentication \\nin the ASP.NET Core documentation). \\nTip \\nAll details are handled by the autho\", \"rization middleware and services previously mentioned. So, you \\njust have to choose the Individual U\", \"ser Account authentication option when you create the ASP.NET \\nCore web application project in Visua\", \"l Studio, as shown in Figure 9-3, besides registering the \\nauthentication providers previously menti\", \"oned. \\n \\n323 \\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n \\n \\nFigure 9-3. Selec\", \"ting the Individual User Accounts option, for using external authentication, when creating a web \\nap\", \"plication project in Visual Studio 2019. \\nIn addition to the external authentication providers liste\", \"d previously, third-party packages are \\navailable that provide middleware for using many more extern\", \"al authentication providers. For a list, \\nsee the AspNet.Security.OAuth.Providers repository on GitH\", \"ub. \\nYou can also create your own external authentication middleware to solve some special need. \\nAu\", \"thenticate with bearer tokens \\nAuthenticating with ASP.NET Core Identity (or Identity plus external \", \"authentication providers) works \\nwell for many web application scenarios in which storing user infor\", \"mation in a cookie is appropriate. \\nIn other scenarios, though, cookies are not a natural means of p\", \"ersisting and transmitting data. \\nFor example, in an ASP.NET Core Web API that exposes RESTful endpo\", \"ints that might be accessed by \\nSingle Page Applications (SPAs), by native clients, or even by other\", \" Web APIs, you typically want to \\nuse bearer token authentication instead. These types of applicatio\", \"ns do not work with cookies, but \\ncan easily retrieve a bearer token and include it in the authoriza\", \"tion header of subsequent requests. \\nTo enable token authentication, ASP.NET Core supports several o\", \"ptions for using OAuth 2.0 and \\nOpenID Connect. \\n \\n324 \\nCHAPTER 8 | Make secure .NET Microservices a\", \"nd Web Applications \\n \\nAuthenticate with an OpenID Connect or OAuth 2.0 Identity provider \\nIf user i\", \"nformation is stored in Azure Active Directory or another identity solution that supports \\nOpenID Co\", \"nnect or OAuth 2.0, you can use the \\nMicrosoft.AspNetCore.Authentication.OpenIdConnect package to au\", \"thenticate using the OpenID \\nConnect workflow. For example, to authenticate to the Identity.Api micr\", \"oservice in \\neShopOnContainers, an ASP.NET Core web application can use middleware from that package\", \" as \\nshown in the following simplified example in Program.cs: \\n// Program.cs \\n \\nvar identityUrl = bu\", \"ilder.Configuration.GetValue<string>(\\\"IdentityUrl\\\"); \\nvar callBackUrl = builder.Configuration.GetVal\", \"ue<string>(\\\"CallBackUrl\\\"); \\nvar sessionCookieLifetime = builder.Configuration.GetValue(\\\"SessionCooki\", \"eLifetimeMinutes\\\", \\n60); \\n \\n// Add Authentication services \\n \\nservices.AddAuthentication(options => \", \"\\n{ \\n    options.DefaultScheme = CookieAuthenticationDefaults.AuthenticationScheme; \\n    options.Defa\", \"ultChallengeScheme = JwtBearerDefaults.AuthenticationScheme; \\n}) \\n.AddCookie(setup => setup.ExpireTi\", \"meSpan = TimeSpan.FromMinutes(sessionCookieLifetime)) \\n.AddOpenIdConnect(options => \\n{ \\n    options.\", \"SignInScheme = CookieAuthenticationDefaults.AuthenticationScheme; \\n    options.Authority = identityU\", \"rl.ToString(); \\n    options.SignedOutRedirectUri = callBackUrl.ToString(); \\n    options.ClientId = u\", \"seLoadTest ? \\\"mvctest\\\" : \\\"mvc\\\"; \\n    options.ClientSecret = \\\"secret\\\"; \\n    options.ResponseType = us\", \"eLoadTest ? \\\"code id_token token\\\" : \\\"code id_token\\\"; \\n    options.SaveTokens = true; \\n    options.Ge\", \"tClaimsFromUserInfoEndpoint = true; \\n    options.RequireHttpsMetadata = false; \\n    options.Scope.Ad\", \"d(\\\"openid\\\"); \\n    options.Scope.Add(\\\"profile\\\"); \\n    options.Scope.Add(\\\"orders\\\"); \\n    options.Scope\", \".Add(\\\"basket\\\"); \\n    options.Scope.Add(\\\"marketing\\\"); \\n    options.Scope.Add(\\\"locations\\\"); \\n    optio\", \"ns.Scope.Add(\\\"webshoppingagg\\\"); \\n    options.Scope.Add(\\\"orders.signalrhub\\\"); \\n}); \\n \\n// Build the ap\", \"p \\n//\\u2026 \\napp.UseAuthentication(); \\n//\\u2026 \\napp.UseEndpoints(endpoints => \\n{ \\n    //... \\n}); \\nWhen you us\", \"e this workflow, the ASP.NET Core Identity middleware is not needed, because all user \\ninformation s\", \"torage and authentication is handled by the Identity service. \\n \\n325 \\nCHAPTER 8 | Make secure .NET M\", \"icroservices and Web Applications \\n \\nIssue security tokens from an ASP.NET Core service \\nIf you pref\", \"er to issue security tokens for local ASP.NET Core Identity users rather than using an \\nexternal ide\", \"ntity provider, you can take advantage of some good third-party libraries. \\nIdentityServer4 and Open\", \"Iddict are OpenID Connect providers that integrate easily with ASP.NET Core \\nIdentity to let you iss\", \"ue security tokens from an ASP.NET Core service. The IdentityServer4 \\ndocumentation has in-depth ins\", \"tructions for using the library. However, the basic steps to using \\nIdentityServer4 to issue tokens \", \"are as follows. \\n1. \\nYou configure IdentityServer4 in Program.cs by making a call to \\nbuilder.Servic\", \"es.AddIdentityServer. \\n2. \\nYou call app.UseIdentityServer in Program.cs to add IdentityServer4 to th\", \"e application\\u2019s HTTP \\nrequest processing pipeline. This lets the library serve requests to OpenID Co\", \"nnect and \\nOAuth2 endpoints like /connect/token. \\n3. \\nYou configure identity server by setting the f\", \"ollowing data: \\n\\u2013 \\nThe credentials to use for signing. \\n\\u2013 \\nThe Identity and API resources that users\", \" might request access to: \\n\\u2022 \\nAPI resources represent protected data or functionality that a user ca\", \"n access \\nwith an access token. An example of an API resource would be a web API (or \\nset of APIs) t\", \"hat requires authorization. \\n\\u2022 \\nIdentity resources represent information (claims) that are given to \", \"a client to \\nidentify a user. The claims might include the user name, email address, and so \\non. \\n\\u2013 \", \"\\nThe clients that will be connecting in order to request tokens. \\n\\u2013 \\nThe storage mechanism for user \", \"information, such as ASP.NET Core Identity or an \\nalternative. \\nWhen you specify clients and resourc\", \"es for IdentityServer4 to use, you can pass an IEnumerable \\ncollection of the appropriate type to me\", \"thods that take in-memory client or resource stores. Or for \\nmore complex scenarios, you can provide\", \" client or resource provider types via Dependency Injection. \\nA sample configuration for IdentitySer\", \"ver4 to use in-memory resources and clients provided by a \\ncustom IClientStore type might look like \", \"the following example: \\n// Program.cs \\n \\nbuilder.Services.AddSingleton<IClientStore, CustomClientSto\", \"re>(); \\nbuilder.Services.AddIdentityServer() \\n    .AddSigningCredential(\\\"CN=sts\\\") \\n    .AddInMemoryA\", \"piResources(MyApiResourceProvider.GetAllResources()) \\n    .AddAspNetIdentity<ApplicationUser>(); \\n//\", \"... \\n \\n326 \\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n \\nConsume security toke\", \"ns \\nAuthenticating against an OpenID Connect endpoint or issuing your own security tokens covers som\", \"e \\nscenarios. But what about a service that simply needs to limit access to those users who have val\", \"id \\nsecurity tokens that were provided by a different service? \\nFor that scenario, authentication mi\", \"ddleware that handles JWT tokens is available in the \\nMicrosoft.AspNetCore.Authentication.JwtBearer \", \"package. JWT stands for \\u201cJSON Web Token\\u201d and \\nis a common security token format (defined by RFC 7519\", \") for communicating security claims. A \\nsimplified example of how to use middleware to consume such \", \"tokens might look like this code \\nfragment, taken from the Ordering.Api microservice of eShopOnConta\", \"iners. \\n// Program.cs \\n \\nvar identityUrl = builder.Configuration.GetValue<string>(\\\"IdentityUrl\\\"); \\n \", \"\\n// Add Authentication services \\n \\nbuilder.Services.AddAuthentication(options => \\n{ \\n    options.Def\", \"aultAuthenticateScheme = \\nAspNetCore.Authentication.JwtBearer.JwtBearerDefaults.AuthenticationScheme\", \"; \\n    options.DefaultChallengeScheme = \\nAspNetCore.Authentication.JwtBearer.JwtBearerDefaults.Authe\", \"nticationScheme; \\n \\n}).AddJwtBearer(options => \\n{ \\n    options.Authority = identityUrl; \\n    options\", \".RequireHttpsMetadata = false; \\n    options.Audience = \\\"orders\\\"; \\n}); \\n \\n// Build the app \\n \\napp.Use\", \"Authentication(); \\n//\\u2026 \\napp.UseEndpoints(endpoints => \\n{ \\n    //... \\n}); \\nThe parameters in this usa\", \"ge are: \\n\\u2022 \\nAudience represents the receiver of the incoming token or the resource that the token gr\", \"ants \\naccess to. If the value specified in this parameter does not match the parameter in the token,\", \" \\nthe token will be rejected. \\n\\u2022 \\nAuthority is the address of the token-issuing authentication serve\", \"r. The JWT bearer \\nauthentication middleware uses this URI to get the public key that can be used to\", \" validate the \\ntoken\\u2019s signature. The middleware also confirms that the iss parameter in the token m\", \"atches \\nthis URI. \\nAnother parameter, RequireHttpsMetadata, is useful for testing purposes; you set \", \"this parameter to \\nfalse so you can test in environments where you don\\u2019t have certificates. In real-\", \"world deployments, \\nJWT bearer tokens should always be passed only over HTTPS. \\n \\n327 \\nCHAPTER 8 | M\", \"ake secure .NET Microservices and Web Applications \\n \\nWith this middleware in place, JWT tokens are \", \"automatically extracted from authorization headers. \\nThey are then deserialized, validated (using th\", \"e values in the Audience and Authority parameters), and \\nstored as user information to be referenced\", \" later by MVC actions or authorization filters. \\nThe JWT bearer authentication middleware can also s\", \"upport more advanced scenarios, such as using a \\nlocal certificate to validate a token if the author\", \"ity is not available. For this scenario, you can specify a \\nTokenValidationParameters object in the \", \"JwtBearerOptions object. \\nAdditional resources \\n\\u2022 \\nSharing cookies between applications \\nhttps://lea\", \"rn.microsoft.com/aspnet/core/security/cookie-sharing \\n\\u2022 \\nIntroduction to Identity \\nhttps://learn.mic\", \"rosoft.com/aspnet/core/security/authentication/identity \\n\\u2022 \\nRick Anderson. Two-factor authentication\", \" with SMS \\nhttps://learn.microsoft.com/aspnet/core/security/authentication/2fa \\n\\u2022 \\nEnabling authenti\", \"cation using Facebook, Google and other external providers \\nhttps://learn.microsoft.com/aspnet/core/\", \"security/authentication/social/ \\n\\u2022 \\nMichell Anicas. An Introduction to OAuth 2 \\nhttps://www.digitalo\", \"cean.com/community/tutorials/an-introduction-to-oauth-2 \\n\\u2022 \\nAspNet.Security.OAuth.Providers (GitHub \", \"repo for ASP.NET OAuth providers) \\nhttps://github.com/aspnet-contrib/AspNet.Security.OAuth.Providers\", \"/tree/dev/src \\n\\u2022 \\nIdentityServer4. Official documentation \\nhttps://identityserver4.readthedocs.io/en\", \"/latest/ \\nAbout authorization in .NET microservices and web \\napplications \\nAfter authentication, ASP\", \".NET Core Web APIs need to authorize access. This process allows a service \\nto make APIs available t\", \"o some authenticated users, but not to all. Authorization can be done based \\non users\\u2019 roles or base\", \"d on custom policy, which might include inspecting claims or other heuristics. \\nRestricting access t\", \"o an ASP.NET Core MVC route is as easy as applying an Authorize attribute to the \\naction method (or \", \"to the controller\\u2019s class if all the controller\\u2019s actions require authorization), as \\nshown in follo\", \"wing example: \\npublic class AccountController : Controller \\n{ \\n    public ActionResult Login() \\n    \", \"{ \\n    } \\n \\n    [Authorize] \\n \\n328 \\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \", \"\\n \\n    public ActionResult Logout() \\n    { \\n    } \\n} \\nBy default, adding an Authorize attribute with\", \"out parameters will limit access to authenticated users \\nfor that controller or action. To further r\", \"estrict an API to be available for only specific users, the \\nattribute can be expanded to specify re\", \"quired roles or policies that users must satisfy. \\nImplement role-based authorization \\nASP.NET Core \", \"Identity has a built-in concept of roles. In addition to users, ASP.NET Core Identity \\nstores inform\", \"ation about different roles used by the application and keeps track of which users are \\nassigned to \", \"which roles. These assignments can be changed programmatically with the RoleManager \\ntype that updat\", \"es roles in persisted storage, and the UserManager type that can grant or revoke roles \\nfrom users. \", \"\\nIf you\\u2019re authenticating with JWT bearer tokens, the ASP.NET Core JWT bearer authentication \\nmiddle\", \"ware will populate a user\\u2019s roles based on role claims found in the token. To limit access to an \\nMV\", \"C action or controller to users in specific roles, you can include a Roles parameter in the Authoriz\", \"e \\nannotation (attribute), as shown in the following code fragment: \\n[Authorize(Roles = \\\"Administrat\", \"or, PowerUser\\\")] \\npublic class ControlPanelController : Controller \\n{ \\n    public ActionResult SetTi\", \"me() \\n    { \\n    } \\n \\n    [Authorize(Roles = \\\"Administrator\\\")] \\n    public ActionResult ShutDown() \\n\", \"    { \\n    } \\n} \\nIn this example, only users in the Administrator or PowerUser roles can access APIs\", \" in the \\nControlPanel controller (such as executing the SetTime action). The ShutDown API is further\", \" restricted \\nto allow access only to users in the Administrator role. \\nTo require a user be in multi\", \"ple roles, you use multiple Authorize attributes, as shown in the following \\nexample: \\n[Authorize(Ro\", \"les = \\\"Administrator, PowerUser\\\")] \\n[Authorize(Roles = \\\"RemoteEmployee \\\")] \\n[Authorize(Policy = \\\"Cus\", \"tomPolicy\\\")] \\npublic ActionResult API1 () \\n{ \\n} \\nIn this example, to call API1, a user must: \\n\\u2022 \\nBe \", \"in the Administrator or PowerUser role, and \\n\\u2022 \\nBe in the RemoteEmployee role, and \\n \\n329 \\nCHAPTER 8\", \" | Make secure .NET Microservices and Web Applications \\n \\n\\u2022 \\nSatisfy a custom handler for CustomPoli\", \"cy authorization. \\nImplement policy-based authorization \\nCustom authorization rules can also be writ\", \"ten using authorization policies. This section provides an \\noverview. For more information, see the \", \"ASP.NET Authorization Workshop. \\nCustom authorization policies are registered in the Startup.Configu\", \"reServices method using the \\nservice.AddAuthorization method. This method takes a delegate that conf\", \"igures an \\nAuthorizationOptions argument. \\nservices.AddAuthorization(options => \\n{ \\n    options.AddP\", \"olicy(\\\"AdministratorsOnly\\\", policy => \\n        policy.RequireRole(\\\"Administrator\\\")); \\n \\n    options.\", \"AddPolicy(\\\"EmployeesOnly\\\", policy => \\n        policy.RequireClaim(\\\"EmployeeNumber\\\")); \\n \\n    options\", \".AddPolicy(\\\"Over21\\\", policy => \\n        policy.Requirements.Add(new MinimumAgeRequirement(21))); \\n})\", \"; \\nAs shown in the example, policies can be associated with different types of requirements. After t\", \"he \\npolicies are registered, they can be applied to an action or controller by passing the policy\\u2019s \", \"name as \\nthe Policy argument of the Authorize attribute (for example, [Authorize(Policy=\\\"EmployeesOn\", \"ly\\\")]) \\nPolicies can have multiple requirements, not just one (as shown in these examples). \\nIn the \", \"previous example, the first AddPolicy call is just an alternative way of authorizing by role. If \\n[A\", \"uthorize(Policy=\\\"AdministratorsOnly\\\")] is applied to an API, only users in the Administrator role wi\", \"ll \\nbe able to access it. \\nThe second AddPolicy call demonstrates an easy way to require that a part\", \"icular claim should be \\npresent for the user. The RequireClaim method also optionally takes expected\", \" values for the claim. If \\nvalues are specified, the requirement is met only if the user has both a \", \"claim of the correct type and \\none of the specified values. If you\\u2019re using the JWT bearer authentic\", \"ation middleware, all JWT \\nproperties will be available as user claims. \\nThe most interesting policy\", \" shown here is in the third AddPolicy method, because it uses a custom \\nauthorization requirement. B\", \"y using custom authorization requirements, you can have a great deal of \\ncontrol over how authorizat\", \"ion is performed. For this to work, you must implement these types: \\n\\u2022 \\nA Requirements type that der\", \"ives from IAuthorizationRequirement and that contains fields \\nspecifying the details of the requirem\", \"ent. In the example, this is an age field for the sample \\nMinimumAgeRequirement type. \\n\\u2022 \\nA handler \", \"that implements AuthorizationHandler, where T is the type of \\nIAuthorizationRequirement that the han\", \"dler can satisfy. The handler must implement the \\nHandleRequirementAsync method, which checks whethe\", \"r a specified context that contains \\ninformation about the user satisfies the requirement. \\n \\n330 \\nC\", \"HAPTER 8 | Make secure .NET Microservices and Web Applications \\n \\nIf the user meets the requirement,\", \" a call to context.Succeed will indicate that the user is authorized. If \\nthere are multiple ways th\", \"at a user might satisfy an authorization requirement, multiple handlers can \\nbe created. \\nIn additio\", \"n to registering custom policy requirements with AddPolicy calls, you also need to register \\ncustom \", \"requirement handlers via Dependency Injection (services.AddTransient<IAuthorizationHandler, \\nMinimum\", \"AgeHandler>()). \\nAn example of a custom authorization requirement and handler for checking a user\\u2019s \", \"age (based on a \\nDateOfBirth claim) is available in the ASP.NET Core authorization documentation. \\nA\", \"uthorization and minimal apis \\nASP.NET supports minimal APIs as an alternative to controller-based A\", \"PIs. Authorization policies are \\nthe recommended way to configure authorization for minimal APIs, as\", \" this example demonstrates: \\n// Program.cs \\nbuilder.Services.AddAuthorizationBuilder() \\n  .AddPolicy\", \"(\\\"admin_greetings\\\", policy => \\n        policy \\n            .RequireRole(\\\"admin\\\") \\n            .Requi\", \"reScope(\\\"greetings_api\\\")); \\n \\n// build the app \\n \\napp.MapGet(\\\"/hello\\\", () => \\\"Hello world!\\\") \\n  .Req\", \"uireAuthorization(\\\"admin_greetings\\\"); \\nAdditional resources \\n\\u2022 \\nASP.NET Core Authentication \\nhttps:/\", \"/learn.microsoft.com/aspnet/core/security/authentication/identity \\n\\u2022 \\nASP.NET Core Authorization \\nht\", \"tps://learn.microsoft.com/aspnet/core/security/authorization/introduction \\n\\u2022 \\nRole-based Authorizati\", \"on \\nhttps://learn.microsoft.com/aspnet/core/security/authorization/roles \\n\\u2022 \\nCustom Policy-Based Aut\", \"horization \\nhttps://learn.microsoft.com/aspnet/core/security/authorization/policies \\n\\u2022 \\nAuthenticati\", \"on and authorization in minimal \\nAPIs  https://learn.microsoft.com/aspnet/core/fundamentals/minimal-\", \"apis/security \\nStore application secrets safely during development \\nTo connect with protected resour\", \"ces and other services, ASP.NET Core applications typically need to \\nuse connection strings, passwor\", \"ds, or other credentials that contain sensitive information. These \\nsensitive pieces of information \", \"are called secrets. It\\u2019s a best practice to not include secrets in source \\n \\n331 \\nCHAPTER 8 | Make s\", \"ecure .NET Microservices and Web Applications \\n \\ncode and making sure not to store secrets in source\", \" control. Instead, you should use the ASP.NET \\nCore configuration model to read the secrets from mor\", \"e secure locations. \\nYou must separate the secrets for accessing development and staging resources f\", \"rom the ones used \\nfor accessing production resources, because different individuals will need acces\", \"s to those different \\nsets of secrets. To store secrets used during development, common approaches a\", \"re to either store \\nsecrets in environment variables or by using the ASP.NET Core Secret Manager too\", \"l. For more secure \\nstorage in production environments, microservices can store secrets in an Azure \", \"Key Vault. \\nStore secrets in environment variables \\nOne way to keep secrets out of source code is fo\", \"r developers to set string-based secrets as \\nenvironment variables on their development machines. Wh\", \"en you use environment variables to store \\nsecrets with hierarchical names, such as the ones nested \", \"in configuration sections, you must name the \\nvariables to include the complete hierarchy of its sec\", \"tions, delimited with colons (:). \\nFor example, setting an environment variable Logging:LogLevel:Def\", \"ault to Debug value would be \\nequivalent to a configuration value from the following JSON file: \\n{ \\n\", \"    \\\"Logging\\\": { \\n        \\\"LogLevel\\\": { \\n            \\\"Default\\\": \\\"Debug\\\" \\n        } \\n    } \\n} \\nTo acc\", \"ess these values from environment variables, the application just needs to call \\nAddEnvironmentVaria\", \"bles on its ConfigurationBuilder when constructing an IConfigurationRoot \\nobject. \\nNote \\nEnvironment\", \" variables are commonly stored as plain text, so if the machine or process with the \\nenvironment var\", \"iables is compromised, the environment variable values will be visible. \\nStore secrets with the ASP.\", \"NET Core Secret Manager \\nThe ASP.NET Core Secret Manager tool provides another method of keeping sec\", \"rets out of source \\ncode during development. To use the Secret Manager tool, install the package \\nMi\", \"crosoft.Extensions.Configuration.SecretManager in your project file. Once that dependency is \\npresen\", \"t and has been restored, the dotnet user-secrets command can be used to set the value of \\nsecrets fr\", \"om the command line. These secrets will be stored in a JSON file in the user\\u2019s profile \\ndirectory (d\", \"etails vary by OS), away from source code. \\nSecrets set by the Secret Manager tool are organized by \", \"the UserSecretsId property of the project \\nthat\\u2019s using the secrets. Therefore, you must be sure to \", \"set the UserSecretsId property in your project \\nfile, as shown in the snippet below. The default val\", \"ue is a GUID assigned by Visual Studio, but the \\nactual string is not important as long as it\\u2019s uniq\", \"ue in your computer. \\n \\n332 \\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n \\n<Pro\", \"pertyGroup> \\n    <UserSecretsId>UniqueIdentifyingString</UserSecretsId> \\n</PropertyGroup> \\nUsing sec\", \"rets stored with Secret Manager in an application is accomplished by calling \\nAddUserSecrets<T> on t\", \"he ConfigurationBuilder instance to include secrets for the application in its \\nconfiguration. The g\", \"eneric parameter T should be a type from the assembly that the UserSecretId was \\napplied to. Usually\", \", using AddUserSecrets<Startup> is fine. \\nThe AddUserSecrets<Startup>() is included in the default o\", \"ptions for the Development environment \\nwhen using the CreateDefaultBuilder method in Program.cs. \\nU\", \"se Azure Key Vault to protect secrets at production \\ntime \\nSecrets stored as environment variables o\", \"r stored by the Secret Manager tool are still stored locally \\nand unencrypted on the machine. A more\", \" secure option for storing secrets is Azure Key Vault, which \\nprovides a secure, central location fo\", \"r storing keys and secrets. \\nThe Azure.Extensions.AspNetCore.Configuration.Secrets package allows an\", \" ASP.NET Core \\napplication to read configuration information from Azure Key Vault. To start using se\", \"crets from an \\nAzure Key Vault, you follow these steps: \\n1. \\nRegister your application as an Azure A\", \"D application. (Access to key vaults is managed by \\nAzure AD.) This can be done through the Azure ma\", \"nagement portal. \\n \\n  \\nAlternatively, if you want your application to authenticate using a certifica\", \"te instead of a \\npassword or client secret, you can use the New-AzADApplication PowerShell cmdlet. T\", \"he \\ncertificate that you register with Azure Key Vault needs only your public key. Your application \", \"\\nwill use the private key. \\n2. \\nGive the registered application access to the key vault by creating \", \"a new service principal. You \\ncan do this using the following PowerShell commands: \\n$sp = New-AzADSe\", \"rvicePrincipal -ApplicationId \\\"<Application ID guid>\\\" \\nSet-AzKeyVaultAccessPolicy -VaultName \\\"<Vault\", \"Name>\\\" -ServicePrincipalName \\n$sp.ServicePrincipalNames[0] -PermissionsToSecrets all -ResourceGroupN\", \"ame \\\"<KeyVault \\nResource Group>\\\" \\n3. \\nInclude the key vault as a configuration source in your applic\", \"ation by calling the \\nAzureKeyVaultConfigurationExtensions.AddAzureKeyVault extension method when yo\", \"u create \\nan IConfigurationRoot instance. \\nNote that calling AddAzureKeyVault requires the applicati\", \"on ID that was registered and given access \\nto the key vault in the previous steps. Or you can first\", \"ly running the Azure CLI command: az login, \\nthen using an overload of AddAzureKeyVault that takes a\", \" DefaultAzureCredential in place of the \\nclient. \\n \\n333 \\nCHAPTER 8 | Make secure .NET Microservices \", \"and Web Applications \\n \\nImportant \\nWe recommend that you register Azure Key Vault as the last config\", \"uration provider, so it can override \\nconfiguration values from previous providers. \\nAdditional reso\", \"urces \\n\\u2022 \\nUsing Azure Key Vault to protect application secrets \\nhttps://learn.microsoft.com/azure/ar\", \"chitecture/multitenant-identity \\n\\u2022 \\nSafe storage of app secrets during development \\nhttps://learn.mi\", \"crosoft.com/aspnet/core/security/app-secrets \\n\\u2022 \\nConfiguring data protection \\nhttps://learn.microsof\", \"t.com/aspnet/core/security/data-protection/configuration/overview \\n\\u2022 \\nData Protection key management\", \" and lifetime in ASP.NET Core \\nhttps://learn.microsoft.com/aspnet/core/security/data-protection/conf\", \"iguration/default-\\nsettings \\n \\n334 \\nCHAPTER 9 | .NET Microservices Architecture key takeaways \\n \\nCHA\", \"PTER 9 \\n.NET Microservices \\nArchitecture key takeaways \\nAs a summary and key takeaways, the followin\", \"g are the most important conclusions from this guide. \\nBenefits of using containers. Container-based\", \" solutions provide important cost savings because \\nthey help reduce deployment problems caused by fa\", \"iling dependencies in production environments. \\nContainers significantly improve DevOps and producti\", \"on operations. \\nContainers will be ubiquitous. Docker-based containers are becoming the de facto sta\", \"ndard in the \\nindustry, supported by key vendors in the Windows and Linux ecosystems, such as Micros\", \"oft, Amazon \\nAWS, Google, and IBM. Docker will probably soon be ubiquitous in both the cloud and on-\", \"premises \\ndatacenters. \\nContainers as a unit of deployment. A Docker container is becoming the stand\", \"ard unit of \\ndeployment for any server-based application or service. \\nMicroservices. The microservic\", \"es architecture is becoming the preferred approach for distributed and \\nlarge or complex mission-cri\", \"tical applications based on many independent subsystems in the form of \\nautonomous services. In a mi\", \"croservice-based architecture, the application is built as a collection of \\nservices that are develo\", \"ped, tested, versioned, deployed, and scaled independently. Each service can \\ninclude any related au\", \"tonomous database. \\nDomain-driven design and SOA. The microservices architecture patterns derive fro\", \"m service-\\noriented architecture (SOA) and domain-driven design (DDD). When you design and develop \\n\", \"microservices for environments with evolving business needs and rules, it\\u2019s important to consider DD\", \"D \\napproaches and patterns. \\nMicroservices challenges. Microservices offer many powerful capabilitie\", \"s, like independent \\ndeployment, strong subsystem boundaries, and technology diversity. However, the\", \"y also raise many \\nnew challenges related to distributed application development, such as fragmented\", \" and independent \\ndata models, resilient communication between microservices, eventual consistency, \", \"and operational \\ncomplexity that results from aggregating logging and monitoring information from mu\", \"ltiple \\nmicroservices. These aspects introduce a much higher complexity level than a traditional mon\", \"olithic \\napplication. As a result, only specific scenarios are suitable for microservice-based appli\", \"cations. These \\ninclude large and complex applications with multiple evolving subsystems. In these c\", \"ases, it\\u2019s worth \\ninvesting in a more complex software architecture, because it will provide better \", \"long-term agility and \\napplication maintenance. \\n \\n335 \\nCHAPTER 9 | .NET Microservices Architecture \", \"key takeaways \\n \\nContainers for any application. Containers are convenient for microservices, but ca\", \"n also be useful \\nfor monolithic applications based on the traditional .NET Framework, when using Wi\", \"ndows \\nContainers. The benefits of using Docker, such as solving many deployment-to-production issue\", \"s and \\nproviding state-of-the-art Dev and Test environments, apply to many different types of applic\", \"ations. \\nCLI versus IDE. With Microsoft tools, you can develop containerized .NET applications using\", \" your \\npreferred approach. You can develop with a CLI and an editor-based environment by using the D\", \"ocker \\nCLI and Visual Studio Code. Or you can use an IDE-focused approach with Visual Studio and its\", \" unique \\nfeatures for Docker, such as multi-container debugging. \\nResilient cloud applications. In c\", \"loud-based systems and distributed systems in general, there is \\nalways the risk of partial failure.\", \" Since clients and services are separate processes (containers), a \\nservice might not be able to res\", \"pond in a timely way to a client\\u2019s request. For example, a service might \\nbe down because of a parti\", \"al failure or for maintenance; the service might be overloaded and \\nresponding slowly to requests; o\", \"r it might not be accessible for a short time because of network \\nissues. Therefore, a cloud-based a\", \"pplication must embrace those failures and have a strategy in place \\nto respond to those failures. T\", \"hese strategies can include retry policies (resending messages or \\nretrying requests) and implementi\", \"ng circuit-breaker patterns to avoid exponential load of repeated \\nrequests. Basically, cloud-based \", \"applications must have resilient mechanisms\\u2014either based on cloud \\ninfrastructure or custom, as the \", \"high-level ones provided by orchestrators or service buses. \\nSecurity. Our modern world of container\", \"s and microservices can expose new vulnerabilities. There are \\nseveral ways to implement basic appli\", \"cation security, based on authentication and authorization. \\nHowever, container security must consid\", \"er additional key components that result in inherently safer \\napplications. A critical element of bu\", \"ilding safer apps is having a secure way of communicating with \\nother apps and systems, something th\", \"at often requires credentials, tokens, passwords, and the like, \\ncommonly referred to as application\", \" secrets. Any secure solution must follow security best practices, \\nsuch as encrypting secrets while\", \" in transit and at rest, and preventing secrets from leaking when \\nconsumed by the final application\", \". Those secrets need to be stored and kept safely, as when using \\nAzure Key Vault. \\nOrchestrators. C\", \"ontainer-based orchestrators, such as Azure Kubernetes Service and Azure Service \\nFabric are key par\", \"t of any significant microservice and container-based application. These applications \\ncarry with th\", \"em high complexity, scalability needs, and go through constant evolution. This guide has \\nintroduced\", \" orchestrators and their role in microservice-based and container-based solutions. If your \\napplicat\", \"ion needs are moving you toward complex containerized apps, you will find it useful to seek \\nout add\", \"itional resources for learning more about orchestrators. \\n\"]"