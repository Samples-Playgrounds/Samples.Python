"[\"\\u2014= Microsoft\\n\\nNET Microservices:\\n\\nArchitecture for\\nContainerized .NET\\nApplications\\n\\nro\\n\\n=\\n\\nBill Wagn\", \"er\\n\\noy\\n\\na\\n\\nae!\\nLa!\\n\\nMicrosoft Corporation\\n\\nme Microsoft\\n\\nEDITION v7.0 - Updated to ASP.NET Core 7.0\\n\", \"Refer changelog for the book updates and community contributions.\\n\\nThis guide is an introduction to \", \"developing microservices-based applications and managing them\\nusing containers. It discusses archite\", \"ctural design and implementation approaches using .NET and\\nDocker containers.\\n\\nTo make it easier to \", \"get started, the guide focuses on a reference containerized and microservice-\\nbased application that\", \" you can explore. The reference application is available at the\\n\\neShopOnContainers GitHub repo.\\n\\nAct\", \"ion links\\n\\n. This e-book is also available in a PDF format (English version only) Download\\n. Clone/F\", \"ork the reference application eShopOnContainers on GitHub\\n\\n\\u00b0 Watch the introductory video\\n\\n\\u00b0 Get to \", \"know the Microservices Architecture right away\\n\\nIntroduction\\n\\nEnterprises are increasingly realizing\", \" cost savings, solving deployment problems, and improving\\nDevOps and production operations by using \", \"containers. Microsoft has been releasing container\\ninnovations for Windows and Linux by creating pro\", \"ducts like Azure Kubernetes Service and Azure\\nService Fabric, and by partnering with industry leader\", \"s like Docker, Mesosphere, and Kubernetes.\\nThese products deliver container solutions that help comp\", \"anies build and deploy applications at cloud\\nspeed and scale, whatever their choice of platform or t\", \"ools.\\n\\nDocker is becoming the de facto standard in the container industry, supported by the most sig\", \"nificant\\nvendors in the Windows and Linux ecosystems. (Microsoft is one of the main cloud vendors\\nsu\", \"pporting Docker). In the future, Docker will probably be ubiquitous in any datacenter in the cloud o\", \"r\\non-premises.\\n\\nIn addition, the microservices architecture is emerging as an important approach for\", \" distributed\\nmission-critical applications. In a microservice-based architecture, the application is\", \" built on a\\ncollection of services that can be developed, tested, deployed, and versioned independen\", \"tly.\\n\\nAbout this guide\\n\\nThis guide is an introduction to developing microservices-based applications\", \" and managing them\\nusing containers. It discusses architectural design and implementation approaches\", \" using .NET and\\nDocker containers. To make it easier to get started with containers and microservice\", \"s, the guide\\nfocuses on a reference containerized and microservice-based application that you can ex\", \"plore. The\\nsample application is available at the eShopOnContainers GitHub repo.\\nme Microsoft\\n\\nThis \", \"guide provides foundational development and architectural guidance primarily at a development\\nenviro\", \"nment level with a focus on two technologies: Docker and .NET. Our intention is that you read\\nthis g\", \"uide when thinking about your application design without focusing on the infrastructure (cloud\\nor on\", \"-premises) of your production environment. You will make decisions about your infrastructure\\nlater, \", \"when you create your production-ready applications. Therefore, this guide is intended to be\\ninfrastr\", \"ucture agnostic and more development-environment-centric.\\n\\nAfter you have studied this guide, your n\", \"ext step would be to learn about production-ready\\nmicroservices on Microsoft Azure.\\n\\nVersion\\n\\nThis g\", \"uide has been revised to cover .NET 7 version along with many additional updates related to\\nthe same\", \" \\u201cwave\\u201d of technologies (that is, Azure and additional third-party technologies) coinciding in\\ntime \", \"with the .NET 7 release. That's why the book version has also been updated to version 7.0.\\n\\nWhat thi\", \"s guide does not cover\\n\\nThis guide does not focus on the application lifecycle, DevOps, CI/CD pipeli\", \"nes, or team work. The\\ncomplementary guide Containerized Docker Application Lifecycle with Microsoft\", \" Platform and Tools\\nfocuses on that subject. The current guide also does not provide implementation \", \"details on Azure\\ninfrastructure, such as information on specific orchestrators.\\n\\nAdditional resource\", \"s\\n\\n. Containerized Docker Application Lifecycle with Microsoft Platform and Tools (downloadable\\ne-bo\", \"ok)\\n\\nhttps://aka.ms/dockerlifecycleebook\\n\\nWho should use this guide\\n\\nWe wrote this guide for develop\", \"ers and solution architects who are new to Docker-based application\\ndevelopment and to microservices\", \"-based architecture. This guide is for you if you want to learn how\\nto architect, design, and implem\", \"ent proof-of-concept applications with Microsoft develooment\\ntechnologies (with special focus on .NE\", \"T) and with Docker containers.\\n\\nYou will also find this guide useful if you are a technical decision\", \" maker, such as an enterprise\\narchitect, who wants an architecture and technology overview before yo\", \"u decide on what approach to\\nselect for new and modern distributed applications.\\n\\nHow to use this gu\", \"ide\\n\\nThe first part of this guide introduces Docker containers, discusses how to choose between .NET\", \" 7 and\\nthe .NET Framework as a development framework, and provides an overview of microservices. Thi\", \"s\\ncontent is for architects and technical decision makers who want an overview but don\\u2019t need to foc\", \"us\\non code implementation details.\\nme Microsoft\\n\\nThe second part of the guide starts with the Develo\", \"pment process for Docker based applications\\n\\nsection. It focuses on the development and microservice\", \" patterns for implementing applications using\\n.NET and Docker. This section will be of most interest\", \" to developers and architects who want to focus\\non code and on patterns and implementation details.\\n\", \"\\nRelated microservice and container-based reference\\napplication: eshopOnContainers\\n\\nThe eShopOnConta\", \"iners application is an open-source reference app for .NET and microservices that\\nis designed to be \", \"deployed using Docker containers. The application consists of multiple subsystems,\\nincluding several\", \" e-store UI front-ends (a Web MVC app, a Web SPA, and a native mobile app). It also\\nincludes the bac\", \"k-end microservices and containers for all required server-side operations.\\n\\nThe purpose of the appl\", \"ication is to showcase architectural patterns. IT IS NOT A PRODUCTION-\\nREADY TEMPLATE to start real-\", \"world applications. In fact, the application is in a permanent beta\\nstate, as it\\u2019s also used to test\", \" new potentially interesting technologies as they show up.\\n\\nCredits\\n\\nCo-Authors:\\n\\nCesar de la Torre,\", \" Sr. PM, .NET product team, Microsoft Corp.\\n\\nBill Wagner, Sr. Content Developer, C+E, Microsoft Corp\", \".\\n\\nMike Rousos, Principal Software Engineer, DevDiv CAT team, Microsoft\\nEditors:\\n\\nMike Pope\\n\\nSteve H\", \"oag\\n\\nParticipants and reviewers:\\n\\nJeffrey Richter, Partner Software Eng, Azure team, Microsoft\\n\\nJimm\", \"y Bogard, Chief Architect at Headspring\\n\\nUdi Dahan, Founder & CEO, Particular Software\\n\\nJimmy Nilsso\", \"n, Co-founder and CEO of Factor10\\n\\nGlenn Condron, Sr. Program Manager, ASP.NET team\\n\\nMark Fussell, P\", \"rincipal PM Lead, Azure Service Fabric team, Microsoft\\nDiego Vega, PM Lead, Entity Framework team, M\", \"icrosoft\\n\\nBarry Dorrans, Sr. Security Program Manager\\n\\nRowan Miller, Sr. Program Manager, Microsoft\\n\", \"Ankit Asthana, Principal PM Manager, .NET team, Microsoft\\nScott Hunter, Partner Director PM, .NET te\", \"am, Microsoft\\n\\nNish Anil, Sr. Program Manager, .NET team, Microsoft\\n\\nDylan Reisenberger, Architect a\", \"nd Dev Lead at Polly\\n\\nSteve \\u201cardalis\\u201d Smith - Software Architect and Trainer - Ardalis.com\\nlan Coope\", \"r, Coding Architect at Brighter\\n\\nUnai Zorrilla, Architect and Dev Lead at Plain Concepts\\n\\nEduard Tom\", \"as, Dev Lead at Plain Concepts\\n\\nRamon Tomas, Developer at Plain Concepts\\n\\nDavid Sanz, Developer at P\", \"lain Concepts\\n\\nJavier Valero, Chief Operating Officer at Grupo Solutio\\n\\nPierre Millet, Sr. Consultan\", \"t, Microsoft\\n\\nMichael Friis, Product Manager, Docker Inc\\n\\nCharles Lowell, Software Engineer, VS CAT \", \"team, Microsoft\\nMiguel Veloso, Software Development Engineer at Plain Concepts\\n\\nSumit Ghosh, Princip\", \"al Consultant at Neudesic\\n\\nCopyright\\n\\nPUBLISHED BY\\n\\nMicrosoft Developer Division, .NET and Visual St\", \"udio product teams\\nA division of Microsoft Corporation\\n\\nOne Microsoft Way\\n\\nRedmond, Washington 98052\", \"-6399\\n\\nCopyright \\u00a9 2023 by Microsoft Corporation\\n\\nme Microsoft\\n\\nAll rights reserved. No part of the \", \"contents of this book may be reproduced or transmitted in any\\n\\nform or by any means without the writ\", \"ten permission of the publisher.\\n\\nThis book is provided \\u201cas-is\\u201d and expresses the author's views and\", \" opinions. The views, opinions and\\ninformation expressed in this book, including URL and other Inter\", \"net website references, may change\\n\\nwithout notice.\\n\\nSome examples depicted herein are provided for \", \"illustration only and are fictitious. No real association\\n\\nor connection is intended or should be in\", \"ferred.\\nme Microsoft\\n\\nMicrosoft and the trademarks listed at https://www.microsoft.com on the \\u201cTrade\", \"marks\\u201d webpage are\\ntrademarks of the Microsoft group of companies.\\n\\nMac and macOS are trademarks of \", \"Apple Inc.\\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permission.\\n\\nAll \", \"other marks and logos are property of their respective owners.\\nContents\\n\\nIntroduction to Containers \", \"and Docker......................ssssssssssssscssssssssssccsscccceccccccccsccccsscssessseees 1\\nWhaat \", \"1S DOCKEr? oe eceesessessesseseesessesuesessecsesueseenecucsscsesucsscscsecucsscsesucsucsessesucsscs\", \"esucsucsecuesusassecucsucsesuesucsesuesuesessesneaeaesnecueaeeneeneasens 2\\nComparing Docker containe\", \"rs with Virtlal MACHINES uu... cccessesessesessecessecessesessecssecessecessssesseeessesessestsseets\", \"seeesseeess 3\\n\\nA SIMPIE ANALOGY uu... eceesessesessessssesessesessesessesessesessesssessssesussessss\", \"esucsessssesessesussesucsesessesecsesessssessssessssesuesecuesecesseceesecesseeesseensseenees 4\\nDOCK\", \"er ter MinOlOGy .....e.sesessessssesssssssssecssssssssesscsesscsessssesucsessssessssecuesessesesssse\", \"ssesecussessssessesessesessesessesessesesseaeessassssaessesesseaeeseaeeneass 5\\nDocker CONTAINETS, IM\", \"AGES, ANC FEGISCIIES oo... eecessesessesessesesessesessesessesecsesecsesessesessesessesessesessesess\", \"esessesessesessesesseseeseseeneens 7\\nChoosing Between .NET and .NET Framework for Docker Containers.\", \"....................ssssseee 9\\nGENEKAl QUIDANCE ou... eeeeccessssesesessessssesessesessesecsesussess\", \"ssesucsessesssussesucsesuesssssssucsssesssucussesussecsssessesecuesesussecussesusseceesecusseensseen\", \"eseenees 9\\nWhen to choose .NET for Docker CONtTAINELS.......eeessesessessessessecsessecsecsecsecucen\", \"scucsucsussucsucsuesucsessesseeseeaeeateseeaeesteaeeneenee 10\\nDeveloping and deploying Cross PlatfOr\", \"M uu... ccccccessessessesesssssesessessessesessessesessssseesssesssssececsesseessseeseeseeeseeseenee\", \"eesee 10\\nUsing containers for new (\\u201cgreen -field\\u201d) Projects... .ccccessessesessessessesesssssessssss\", \"essssesssssecessesseesesessesseeeseeseeneeeesee 11\\nCreate and Geploy MICFOSEFVICES ON CONTAINELS ...\", \"...ccccessssessssessesessesessesessesessesessesessesessesessesessesesseseeseseeseseeseaeeseess 11\\nDe\", \"ploying high density in scalable SYSteMS uu... ceecesssssssesssessssesssscsessesessesesscsessssesess\", \"ecsssessssessssesesseensseeesseensseenees 11\\nWhen to choose .NET Framework for Docker CONTAINS .....\", \"..eceeseessesesessessesssseesecsescseeseeseeseeseeseeseeseeseesteneeneenee 12\\nMigrating existing app\", \"lications directly to a WINGOWS Server CONTAINED ou... eeceseseseseceeseeteseeeeseeeseenees 12\\nUsing\", \" third-party .NET libraries or NuGet packages not available for .NET 7 wo. eesseseeseeseeteeeesee 12\", \"\\nUsing .NET technologies not available for NET 7... .cccccsssscsessessssscsessessesssessesscsessesse\", \"sessesseesesesseeseeeseeseeneeeesees 12\\nUsing a platform or API that doesn\\u2019t Support .NET 7 vnc cccc\", \"ccesesscsessessesessessesscsessessecessesseesssessesseeeseeseeneeesee 13\\nPorting existing ASP.NET ap\", \"plication to NET 7 ui.ccsecsesssssssesssssssssssessssescssssssesessecessessssesssseseesecesseesseees\", \"seenees 13\\nDecision table: .NET implementations to USe fOr DOCKED wc. ccccecesssssssssessesessessesu\", \"csessecsesecssssceucsessecnssesseeneeneseess 13\\nWhat OS to target With .NET CONTAINELS ...... ee ece\", \"sesessesessecssecessesscsecussesessesussesussesussesussecsssecessesnssecussecnssecessecesseensaeenee\", \"s 14\\nOfficial NET DOCKer IMG .....c.ccccessessssessessesssessessesessessecussussessecussussesussusse\", \"ssecussussessesucsussecussucsesuesussessecussucseeueaussneaeensaeeass 16\\n.NET and Docker image optim\", \"izations for development Versus PrOdUCTION .......ecsccsesessestesesseeseeeeseens 16\\nArchitecting co\", \"ntainer and microservice-based applications ...................ssssssssssssseseeeeeees 18\\nCONtAaINE|\", \"r ESIGN PLINCIPI\\u2122S uo... eeessesesessssesessesessesessesessesssessesesussessssesussesussesuesesueses\", \"ussesussesussesuesesussesesseseesesesseetsseeneseeess 18\\nCONTAINETIZING MONOLITHIC APPIICATIONS eee \", \"essesessesesseseesesessesessesessecscsecsesecsesessssesussesussesesesesesessesesseetsseeteseeseseees\", \"s 19\\nDeploying a MONOIithic APPLICATION AS A CONTAINED ou... ee ececessesessesesesecsesesesessesesse\", \"secesseesesesesseseeseensseeesseessseenees 21\\nPublishing a single-container-based application to AZU\", \"re App S@rviCe ou... eesessssesesesseseesesesseeesseeteseenees 21\\n\\ni Contents\\nManage State and data \", \"In Docker applications... ccccessessssessssesessessssesessesessesessesessesessesessesessesessesesses\", \"esseseeseseeneess 22\\n\\nSErvice-OrleNted ALCHIteCtUre.......eececsecsesessessessessesesseseseesecnesee\", \"secsessesessecsesessesnesussessecucscsecsesucsecsesuesessecseceaeeseeeaeeaeeneeseass 25\\nMICrOSEFVICE\", \"S ALFCHITECTULE..... es eeeeseesessessesseseesecsecsesecsecsesscsecsecuesscsecuessesecsesucscsesussu\", \"caesnesucsesaecuesucsecnesusaessecuesessecnesueaeeneenensens 25\\nACditional reSOULCES ......sessesess\", \"essessessesessessesssseesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecu\", \"esueseesesucseeseeneeteaeeneenenees 2/7\\nData SOVErEIGNLY PEF MICFOSEFVICE ou... escesessesessesesses\", \"essecsssessssesssesussessssesussesussesussessssesessessesesussesessesessesessesessesesseaesseseeneen\", \"s 2/7\\nThe relationship between microservices and the Bounded Context pattern... ccceseseseseseeeesee\", \"es 29\\nLogical architecture versus physical architecture... cceesscsessessssessssessssessssesessssess\", \"esessesessesessesessesessesessesessesesseseeneens 30\\nChallenges and solutions for distributed data M\", \"ANAGEMENE.......ccccessessessesessessecesesseesesessesseeseseeseesesessseseeneseeess 31\\nChallenge #1\", \": How to define the boundaries Of GCaCH MICFOSEFVICE uu... eesessessesessesseseesesseesesessessestes\", \"eeseenesseaes 31\\nChallenge #2: How to create queries that retrieve data from Several MICFOSEFVICES .\", \".......cceceseseseeseeees 32\\nChallenge #3: How to achieve consistency across MUItiPle MICFOSEFVICES \", \".......eeesesessesessesesseseeeseeseeeeseees 33\\nChallenge #4: How to design communication across MIC\", \"rOSerViCe DOUNCATLIES ........eesesssesseseeteseeseees 35\\nACditional reSOULCES ......sessesessessess\", \"essesessessesssseesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesuese\", \"esesucseeseeneeteaeeneenenees 36\\nIdentify domain-model boundaries for CACH MICFOSEFVICE .......csces\", \"sessesessessecsesessessecsesessecsesecseesecucsesseenssesseeseenessess 36\\nThe API gateway pattern ve\", \"rsus the Direct client-to-MICroservice COMMUNICATION .......ccessesesseseeeeeeseeeees 40\\nDirect Clie\", \"nt-tO-MICFOSEFVICE COMMUNICATION oe eeeseesessessesseseeseesessesesecsecscsesessesuesessecucseesesne\", \"seaeeseeeateaeeneenenee 40\\nWhy consider API Gateways instead of direct client-to-microservice COMMUN\", \"ICATION ........ cesses 41\\nWhat Is the API Gateway Pattern? ..... cc ccsesssssssssessssessssessssess\", \"ssesssssssssssessessssesussesssesessesessesessesesseeesseeesseeesseeesseeess 42\\nMain features in the\", \" API Gateway pattern oo... cccccsessesssssssessesessessssscsesssssesnssesseesssssessecussesseescsess\", \"esseeteseeseeneeesee 44\\nUsing products with API Gateway features.....ccccessesssssssssssssesessssecs\", \"ssesssssesssssssessssesssssesessesseenssessesseeeseeseeneeeses 45\\nDrawbacks of the API Gateway patte\", \"rn .n...cccceeccssssssssssssssssssesssesssssssesssssssessssssesssesssssecessesssenssessesseeeseeseen\", \"eeeeaees 47\\nACditional reSOULCES ......sessesessessessessesessessesssseesecucsecsecsesucsessesucsecs\", \"ecuesucsessessescsesuesucsesnecuesessesucsucsecuesueseesesucseeseeneeteaeeneenenees 48\\nCOMMUNICATION\", \" IN A MICFOSEFVICE AFCNITECTULE oo... eeeececesseseeseesecsesesessecsesesecsessesecnecnesscsessecses\", \"ecsecucseeseeneceaeeneeneeseass 48\\nCOMMUNICATION TYPES o...eecsessssessesessesessesesscsessesesseses\", \"sesssssessesessssussssusseseesssssesucsesucsesessesucsesssesessesessesesseseesesesseaeeneaneneens 49\", \"\\nAsynchronous microservice integration enforces MICrOSErViCe\\u2019S AUTONOMY .......esessessesesseseetese\", \"eseeeeeesee 50\\nCOMMUNICATION STYLES oo... eesessessesesesessesessesessesessesessesessssessssessscuss\", \"esessesucsesucseseesesussesessesesseseeseseesesessssesseseeseseessseeseaneneens 52\\nASYNCHFONOUS MESS\", \"AGE-HASEM COMMUNICATION .........essecessssessecsssecessecssecsesecussecessesecseseesecessecnssecuss\", \"ecnesecesseceeseensaeenees 54\\nSingle-receiver MESSAGE-DASEM COMMUNICATION ......ececessesessesessess\", \"ssesessessssecssesssesssecessecssecsssesesseetsseetsseesseenees 55\\nMultiple-receivers Message-based \", \"COMMUNICATION ........cccessessessssessssesesesessesssscsecsesessesecsesecesseseeseeusseeneseeeeseen\", \"ees 56\\nASYNCHFONOUS eVENT-AFIVEN COMMUNICATION ........eesessesessesessesessessssessssesessessssecus\", \"sesssecesesessesessesessesesseeesseensseeeeseeess 56\\nA note about messaging technologies for Product\", \"iON SYSTEMS ......csessessesseseesessessesesseesesessesseetesteseeseseesee 5/7\\nResiliently DUbIISHIN\", \"G to the EVENT DUS uo. ecessesessesessesessssessesessssesscsessesessesessssessssecessecuesesessesees\", \"eensseeesseensseenees 58\\n\\nContents\\nACitioNal rESOULCES ....eceeeceeccsccsseccecceccesesceccescescecc\", \"sscsccscescescsccsecsecsesccesecsecacesesscsccsecsecaecsesscsscsccsecsecsceacccsccaecseeseeseecacens\", \" 58\\n\\nCreating, evolving, and versioning microservice APIS ANd CONTACTS ou... escesessesessesessesess\", \"esessesessestsseetsseeeeseees 59\\nACditional reSOULCES ......sessesessessessessesessessesssseesecucse\", \"csecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesueseesesucseeseeneeteaeeneene\", \"nees 59\\nMicroservices addressability and the S\\u20acrvice reGistry ......cccscsessessssessssessssesessese\", \"ssesessesessesessesessesessesessesessesseseseeneees 60\\nACditional reSOULCES ......sessesessessessess\", \"esessessesssseesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesueseese\", \"sucseeseeneeteaeeneenenees 60\\nCreating COMpOsite Ul DASE ON MICFOSEFVICES ou... cecessesessesessesss\", \"sesessesesseseesecsssesessesssessseseesecssecessessesesesseetsseeeeseees 60\\nACditional reSOULCES ...\", \"...sessesessessessessesessessesssseesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecueses\", \"sesucsucsecuesueseesesucseeseeneeteaeeneenenees 62\\nResiliency and high availability in MICFOSEFVICES\", \" .......ceesecsessesessesessesessesessesessesessesessesessesessesessesessesessesessesesseseeseseenee\", \"ns 63\\nHealth management and CiagGnOStiCs IN MICFOSEFVICES .......ecesessssessssecsssesesessssessesec\", \"essesessesesseseeseensseesseensseenees 63\\nACditional reSOULCES ......sessesessessessessesessessessss\", \"eesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesueseesesucseeseeneet\", \"eaeeneenenees 65\\nOrchestrate microservices and multi-container applications for high scalability and\", \" availability ....... 66\\nSoftware platforms for container clustering, orchestration, ANd SCHECUIING \", \"uu... ecesccsesesestesessesseeeeseens 68\\nUsing container-based orchestrators In MicrOSOft AZUL ou...\", \" eececcesessessessesessessessesessessecessesseesesesseeseeeseeseeneeeesees 68\\nUsing Azure KUbernetes\", \" Service oo... ccecesssssssssssssssssessssessssssesscsesscsesssssssssesscsessssessssessssesessecesse\", \"cuesesussesesseeesseeesseensseenees 69\\nDevelopment environment for KUDErNeteS uu... ccccesessesssses\", \"sessesessessesscsesssssesessessesnesssessecussesseesesesseeseeeseeseeneeesees 70\\nGetting started wit\", \"h Azure Kubernetes Service (AKS) ....ccesssssssssessesesssssscsessesessesessesessesessesesscsessssee\", \"ssseeneeeeseess 70\\nDeploy with Helm charts into Kubernetes ClUSters.......ccsessssessssessesssscsess\", \"esessssesessecesseceesesesseeessecesseeesseeseseenees 71\\nACditional reSOULCES ......sessesessessesse\", \"ssesessessesssseesecucsecsecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesuesee\", \"sesucseeseeneeteaeeneenenees 71\\nDevelopment process for Docker-based application....................\", \".ccccsssssssssssssssssssssssscceees 72\\nDevelopment environment for DOCKEr APPS \\u00abou... eesessessesses\", \"sssesseesesessessecussessessesussessecuesessecsesussessecuesesseenesesseeneeneseess 72\\nDevelopment t\", \"ool Choices: IDE OF CCItOP ee eeeesessessesessssessssessesesscsessesessesessesessssesussecessecseses\", \"esseseesesesseeesseensseeeees 72\\nACditional reSOULCES ......sessesessessessessesessessesssseesecucse\", \"csecsesucsessesucsecsecuesucsessessescsesuesucsesnecuesessesucsucsecuesueseesesucseeseeneeteaeeneene\", \"nees 73\\n.NET languages and frameworks for DOCker CONTAINETS ........cecccsessessessesesssssesscsesse\", \"cscsscsessecucsessecucssseesecucseeseenesseass 73\\nDevelopment workflow for DOCKEr APPS... ceccecesse\", \"ssesesessessesssessecsesessessecussessecsesussessecussessecsesussessecucsesseenssesseeseeneseess 73\\n\", \"Workflow for developing Docker container-based applications ......ccccessessesssessessessesessesesse\", \"sseeteseeseeeeeses 73\\nStep 1. Start coding and create your initial application Or Service DASElING u\", \"e cesesesseeesseeteseeteseenees 75\\nStep 2. Create a Dockerfile related to an existing .NET DaS@ IMAG\", \"... ceccccessessessesesseesestssessessesesseeseeeseens 76\\nStep 3. Create your custom Docker images a\", \"nd embed your application or service in them........... 83\\n\\nStep 4. Define your services in docker-c\", \"ompose.yml when building a multi-container Docker\\n\\nAPPLICATION ou... eesesessssessesessesessesessese\", \"ssesessesssessssesssesussesussessssesucsesucsesuesesucsesscsesucsesucsesussesussesessesecsesecsesess\", \"esecsesesseseeseaeeneaeeseees 84\\nStep 5. Build and run your Docker Application oo... ececessessssess\", \"ssesessessssesessesessesessesessecssecssessseeessecesseeesseesseenees 87\\nStep 6. Test your Docker ap\", \"plication using your local DOCKer NOSt uw... ecessesessecsssecessesesseeesseessseeneseenees 89\\n\\nCont\", \"ents\\nSimplified workflow when developing containers with Visual StUCIO 0... eessessesesseeseeseesees\", \"eeseeseeseeneens 90\\nUsing PowerShell commands in a Dockerfile to set UD WINGOWS CONTAINETS .......ce\", \"ceeesessesteseeseeteeeeeee 91\\n\\nDesigning and Developing Multi-Container and Microservice-Based .NET \", \"Applications\\n\\nsecccscccsccescccscccsccescccsccesccescccsscesscescccesccssccsscessccesccesccssccescee\", \"sccssccesccesccssccesceesccesscescccsscescesscesscscooese 93\\nD@SIGN A MICFOSEFVICE-OFIENTEM APPLICAT\", \"ION ......eeecessesessesessessssessssessssesessecessesessesessesessesessesesseseesesesseseeseseesese\", \"eseseeneens 93\\nApplication SPECIFICATIONS oo... e.ceccecessessesesessessesessessecsssssessesussessec\", \"ussussessesussessecussusseeucsussessesussesseeuesusseesecussesseensseeseeneaeesees 93\\nDevelOPMENt tE\", \"AM CONTEXT oe ecececccsessessssessssesessesessesessessssssesscsssssssssesessssessssessssessssesssses\", \"ussecesseceesecesseseesecesseeesseeneaeenses 94\\nCHOOSING AN AFCHITECTULE oo... esecesessessesesseses\", \"sesessesessesessesessesessesucsescsesucsesessesecsesucsesessesessesessesecsesessesesseseeseseesesees\", \"eaeeneens 94\\nBenefits Of a MICrOSErVICE-DAaSEM SOLUTION .......ececeessessessessessessecsessessssses\", \"sesscsucsuesuesesesueseseeseeseeseeseeseeseeateaeeaeeneenees 97\\nDownsides of a MICrOSErVviCe-DAaSEM \", \"SOLUTION .......eceeceesessessessessessessessesscssessessesueseseseseeseeseeseeseeseeseeaeeseeseesee\", \"neenee 98\\nExternal versus internal architecture and AeSIGN Patterns... ccesessesessscsssssecsseseses\", \"sssseseesseesseeeseenees 99\\nThe new world: multiple architectural patterns and polyglot MICFOSEFVICE\", \"S.......ceseseseseseeseeesseeteseeees 100\\nCreating a simple data-driven CRUD MICrOSEFVICE ......eees\", \"ecssessessesssssessssssscsessesecscsecscseceesecussesussesssseceesecesseeneseenees 102\\nDeSIGNING a S\", \"IMPIE CRUD MICFOSEFVICE .....eeeesesessesessesessecessessssecsesecussecscsesussecussecussecsesecusse\", \"cussesussecesseensseeneseensseenees 102\\nImplementing a simple CRUD microservice with ASP.NET Core ..\", \"...ccccscsessssssessssecessecessesesseeesseessseeneseenees 103\\nThe DB connection string and environm\", \"ent variables used by Docker COntaine\\u2019s ........ eee 109\\nGenerating Swagger description metadata fro\", \"m your ASP.NET Core Web API .......cccecceseseseeeeseeees 111\\nDefining your multi-container applicat\", \"ion with COCKer-COMPOSE.YM ......c.cececsesseseseesessesesesseeseseesesseeseseeass 116\\nUse a databas\", \"e Server FUNNING AS a CONTAINE|D oo... eeeececessessssessesesesesscsessesesscsecsesessesessesesseses\", \"sesessesecseseesesesseseeseseeneess 127\\nSQL Server running as a container with a microservice-relate\", \"d database... cesses 128\\nSeeding with test data ON Web application Startup... cececssssssssesesesess\", \"sssssssesssssssesessssesseseeseseseeseessseeeees 129\\nEF Core InMemory database versus SQL Server ruN\", \"NING AS a CONTAINED uu... eeeeeceseseseceeseeeeseeeeseeeeseenees 132\\nUsing a Redis cache Service FUN\", \"NING IN a CONTAINED... eecesessesessecessesessecssecsesecuesecussecsesecussecuesecesseensseeneseenee\", \"s 132\\nImplementing event-based communication between microservices (integration events) ..........e \", \"133\\nUsing message brokers and service buses for Production SYSTEMS ......cecccsessessessesessesseses\", \"sessessesteseeseeeseens 134\\nINTEGFATION EVENTS... eececccsesessesessesessessssecsssecsssessssecsssec\", \"sssessssessssecsssecussecsssesussesussesussecussecsssecsssecuesecussecussecesseeesseeeeseensseenees \", \"135\\nTNE COVENT DUS oo. eececesesessessessesesecsecscsscsecsecuescsecuesscsecnecuesessecussucsecnecue\", \"secsesuesuesecsesusscsecuesucaeesecuesessecuesussesseseeateneeneeneaees 136\\nACditional reSOUMCES ...\", \"....eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesu\", \"eseesecucseesesneseaeeneeeeateneeneenenees 138\\nImplementing an event bus with RabbitMQ for the devel\", \"opment or test ENVIFONMENt......... eee 138\\nImplementing a simple publish Method With RADDItMQ i. ce\", \"sssssssecsssecessecessecsesecssecesseeesseeesseetsseeneseenees 139\\nImplementing the subscription cod\", \"e with the RabbDitMQ API ou. ccssessessssecessesessesesseeseseeesseensseeneseenees 140\\nACditional re\", \"SOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesu\", \"csecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 141\\n\\niV Contents\\nSUDSCIIDING tO CVENTS .....ee\", \"secsessesessesessesessesessessssesessesessesssesussesssesssessssessssesussesuesesussesussesussessses\", \"ussesussesesseaessesessesesseaeeseeess 141\\n\\nPublishing events through the eVent DUS... cessessesssse\", \"sesseccssesessesessessssesussecussesessecuesececsesussecesseeesseeesseeneseenees 142\\nIdeMPOteNncy IN\", \" UPCate MESSAGE EVENS ......ecsccessesessesessecessecesseccesecsssecsesecussecsssecsssecsssecussecee\", \"secuesecesseeesseeesseeeseenees 149\\nDeduplicating Integration EVENT MESSAGES ........cecessesesseses\", \"sesessecsesesessecsesesssessssececsecsssecussecessecussecesseeesseesseeeeseenees 150\\nTesting ASP.NET\", \" Core Services And WeD APD ou... cecessessssessssessssessssesessesessesessesessesessesessesussesesse\", \"sessesessesesseaeeseeeeneens 152\\nT@STING IN ESNOPONCONTAINETS uu... ecesessssessesessesessesessesess\", \"esessesessesessesessesessesessesessesessssessssecussessesesessecesseeessecesseeneaeeeees 155\\nImpleme\", \"nt background tasks in microservices with IHostedService and the BackgroundService class\\nsascuscucsu\", \"csuccuscucsussucsucsucsucsucsucsucsucascsecsessecsesnssuscuscuecuccuseucsussussussussucsussucsucscss\", \"caucsscsessesnecuecuecuecuecussussusaucsuseussucsucsussessesneeaeeaeeaeeaeenseneenes 157\\nRegistering\", \" hosted services in yOUr WeDHOSt OF HOS oo... ecessessssesessecessecssecsssecsesecuesecussecuesecues\", \"eensseeneseenees 159\\nThe IHostedService Interface .......cececsessssssssssssessssessessessessecsesse\", \"csessesssesecsecsecsecuecuccussuseussucsucsucsussusscsesseeaeeaeeseeaeeaeeneeneens 159\\nImplementing \", \"IHostedService with a custom hosted service class deriving from the\\nBackgQroUNndService DASE CASS...\", \" .cesessssessesessessssecessesscsesussecsssessssecuesecussessesesussecussecsssecussecsesecessesussec\", \"usseeesseeneseeneseenees 160\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucsssse\", \"cuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 163\\n\", \"Implement API Gateways WIth OCElOt ec eesessessesssssesesessesesssssssssecsesessssessssessesessesess\", \"sseesssessesesseseesesesneseeseseeneaes 163\\nArchitect and design your API] GatewayS......cccssesssss\", \"sssssssessssssesssssssssssssssssesessssessssesssseesssesussesessecesseseeseeesseeesseenees 163\\nImple\", \"menting your API Gateways With OCelOt uo... ceesessessssesessesessesessecssecssecussessssecesseeusse\", \"essseeeseesseeeseenees 168\\nUsing Kubernetes Ingress plus Ocelot API Gateway uu... cccsesessessssesss\", \"sesssscessessssessssecesseessecesseeesseeesseeesseenees 180\\nAdditional cross-cutting features in an \", \"Ocelot API] Gateway .......cccccsessessesssessessesessesseesssessesseeteseeseeneeeesee 181\\nTackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS Patterns............... 182\\nApply simplified C\", \"QRS and DDD patterns IN a MICFOSEFVICE LQ... ececcessessesesessessecessessecscsscsessecussecseencsts\", \"seeneeneseens 184\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecse\", \"cuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 186\\nApply CQRS \", \"and CQS approaches in a DDD microservice In ESHOPONCONTAINETS \\u00ab0... ee eeeeseeseeesteeeeeeees 186\\nCQ\", \"RS and DDD patterns are not top-level architeCtUres...... ce ccesesessessssecssseseesessssesessecess\", \"eeesseetsseeesseeneseees 187\\nImplement reads/queries IN a CQRS MICFOSELVICE ......eeesessessesessess\", \"ssesessesessesecsesessesessesessesessesessesessesesseseeseseeseaeeseass 188\\n\\nUse ViewModels specific\", \"ally made for client apps, independent from domain model constraints\\n\\nsassuesscuecucssesscucsucsscse\", \"suessessuesussscsesuesucsesuecucscuecucsucsesuesucacnecuesussecsesuesecnesuesucsecuesucscnesuesucaec\", \"uesuesesnecuesucsesnecucsessecussecaecnecucaeeneeneaneass 189\\nUse Dapper aS a MICFO ORM to Perform Q\", \"UETIOS........cccessessessssessessesessessecscsessessecessessecncsusseesececseeseencsesseeneeneseess\", \" 189\\nDyNaMIC Versus Static VIEWMOGEIS .......cecessesessesessesessesessecssecssecsssessssessssesusse\", \"cussecussecussesussecussesussecsssecesseeneseeneseenees 190\\nACditional reSOUMCES .......eeessssssses\", \"sesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesn\", \"eseaeeneeeeateneeneenenees 193\\nDesIGn a DDD-Or ented MICFOSEFVICE ......e.ecessesessessssesesecseses\", \"sesessesessssessesessesecsesessssessesessesessesessssesseseesesessesesneaeeseseeneass 194\\nKeep the m\", \"icroservice context boundaries relatively Small occ csesesessecsssesessecessesessesesseeesseeesseene\", \"seenees 194\\nLayers IN DDD MICrOSEIVICES oo... ecessesessesessesessecsseccssecussesussecussecussessss\", \"esussesussesussecussecussecsesecussecussesussecseseeusseensseeneseenees 195\\n\\nV Contents\\nvi\\n\\nD@SIGN A\", \" MICFOSEFVICE COMAIN MOE]... ceecesesssssssessssesssesscsessesessesessesecuesessesessesessesessesees\", \"eseesesessesessesessssesseseeseseeneans 199\\n\\nThe Domain Entity pattern oc cccssssssessssssesssssssss\", \"essssessssessssessssessssessssessssessssessssecsssesessesuesecessecesseeesseeesseensaeenees 199\\nImpl\", \"ement a microservice CoMaiN MOdel WITH .NET uu... eesesssssssesseseccsessesessesessesessesessesesses\", \"eeseseesesesssseeseseeseens 204\\nDomain model structure in a CUStoM .NET Standard LIDrary on. eccesse\", \"sessessssesesseeessesessecesseeesseensseeeeseenees 204\\nStructure aggregates In a CUSTOM .NET Standar\", \"d library oo. ecsessessssssessesesesesscsessesessssessesessestssesneseens 205\\nImplement domain entit\", \"ies aS POCO ClaSSES oo... eccecesessessssessssesessesessesssecussecussecussecsssecussecussecesseenss\", \"eeesseeeeseenees 206\\nEncapsulate data In the Domain Entities oc cessessessssessssecsssecsssesesssses\", \"secessecessecusseesssecessecussecessecesseeesseeeseenees 207\\nSeedwork (reusable base classes and int\", \"erfaces for your dOMAIN MOEl) ou... cceeesessectesesseetesesseeeeeesee 210\\nThe CUSTOM Entity base Cl\", \"AaSS oo... ecssssssesessesessesssssssssssessesessssessssessesessssesssseesssessesecsssessssesssseses\", \"sesesseeesseeesseensaeenees 211\\nRepository contracts (interfaces) in the doMaIN MOel laYE oe cceeces\", \"sesesessessecsesesseeseceseeseeseseeseeseeeesess 212\\nACditional reSOUMCES .......eeesssssssessessese\", \"seesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeen\", \"eeeeateneeneenenees 213\\nIMpleMent ValUC ODJECtS......cececesessssesssessssssesessssessssessssecssses\", \"sssessssessesessssessesecsssessssessssessesssseseesesessesesseseesesesusseessseeeeans 213\\nImportant \", \"Characteristics Of VAlUG ODJECtS wo. eccessessessesessessecsesessessessssessecscsessessecessessecsss\", \"essesseeusseeseeneaesseeneeeesess 214\\nValue object IMpleMentation iN CH oo. ccccessssssssssssssssese\", \"ssesessssesssssssssessssessesessssecsesessssessesesuesesnsseceeseeesseeesseensseenees 215\\nHow to per\", \"sist value objects in the database with EF Core 2.0 and later... ecesesseeeeseeeeseeeeseeees 217\\nPer\", \"sist value objects as owned entity types in EF Core 2.0 and later... cesesesesseseeseeessesesseeeese\", \"eees 218\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucses\", \"secseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 221\\nUse enumeration clas\", \"ses instead Of CENUM TYPOS .......ccesessssssessesssessssscsessessecsssessecsssessessececsesseensses\", \"sessessseeseeneseeass 221\\nImplement an EnUMEr ation DaSe ClAaSS..... ce ecessesessesessecessesessecs\", \"secssseccsesssecsssecsssecsesessssecessecesseceeseesseeesseeeseenees 222\\nACditional reSOUMCES ......\", \".eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesuese\", \"esecucseesesneseaeeneeeeateneeneenenees 223\\nDesign validations in the doMAIN MOAel lAYEF uu... ee es\", \"essessesessesecsesessesecsesessesecsesesseseesesessesessesesseseesesesseseeseseeseans 223\\nImplement \", \"validations in the domain MOel layer... cessesessesessesessecssecssececsecessecesecesseceseeeeseeess\", \"eeeeseesees 224\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecsecu\", \"esucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 225\\nClient-side v\", \"alidation (validation in the presentation layers)... ceessssesssssssssssessessesecssssessecsseeessee\", \"sseeeeseeeees 226\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecse\", \"cuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 227\\nDomain even\", \"ts: DeSIGn ANd IMPIEMENtAtION oe cecesesessessesesesessesessesecsesessesecsesessesessesecsesessesees\", \"eseesesesseseesesseseass 227\\nWhaat iS a COMAIN CVENT? un. ee eecessessesesseesessesesessecsesesecses\", \"uesessesuesucsecnecuesecsecuesuesecsecusscsesnesucsecsecueseesecuessaeesesueseeneeneeneaees 228\\nDOMA\", \"IN Events VEFSUS INTEGFAtiION OVENS uo... cececessesessecessecsssecessesessecesesssecssseccssecsssec\", \"sssecsssecnssecessecesseesseeneseenees 228\\n\\nDomain events as a preferred way to trigger side effects\", \" across multiple aggregates within the\\n\\nSAME COMAIN ou. c.cecceccescceccecceccesscesceccessecesccssc\", \"scesceccsccsccsecscacsccsccsecsecacescsccsccsecsecscsscsccscesecaceacsacscesecsecseescacscesecaecaee\", \"seeceacenees 229\\nIMPlEMENt COMAIN CVENKS........cecsecessesessesessesessecessecssesscsesussecsssesss\", \"sessssesussessesesussecussecussesussecsssecessecussecesseeesseensseeneaeenees 231\\nCONCIUSIONS ON COM\", \"AIN CVENKS.........cccccccccccecceccssesccsceccecceccsccsccccescsccsccsecsecccscsccsecsecsescsccsccs\", \"cesecsceseesccesecaeeseeseceacenees 237\\n\\nContents\\nACitional rESOULCES ......ccccccesceccsccscescecce\", \"cceccccsccscescescccsccsecscescsccscsccsccaccsceccsacsscsccsecscesesscsccsccsecaecacesccesecsecaecse\", \"escesesseasens 238\\n\\nDesign the infrastructure PersiSteNCe AYVEM .......ccececsesssessessecessessecsc\", \"sesssesssessessecsssesseesesusseesecucsessesuesecsessesessesaeeeeseeses 238\\nThe REPOSITOLY PatteIN o\", \"n ccecccesessssesessesessesessesessesessessesssessssessssessssessssessssessssessssessssecssseenssese\", \"ssecessecesseeesseeesseeneseenees 238\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesess\", \"ecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneene\", \"nees 243\\n\\nImplement the infrastructure persistence layer with Entity Framework Cre ......ccecesssses\", \"essesecesseeseseeseeees 243\\nINtroduction to Entity Framework COre...ccccccsssessessssecsssecssssssss\", \"ecessessssesesseccsseccssecsssecsssecssesesseeseseeesseeesseeeeseesess 244\\nInfrastructure in Entity \", \"Framework Core from a DDD PePrspeCtive......ececcccessessessesessessecessessesesseseeseeteseens 244\\n\", \"Implement custom repositories with Entity FraMework COre ......cccessssssesessecsssesessecessecsssse\", \"essseesseessseeesseeeees 246\\nEF DbContext and IUnitOfWork instance lifetime in your IOC CONTAINED uu\", \"... cceeestesseseeseesesesteseeseeeseens 248\\nThe repository instance lifetime IN YOUr lOC CONTAINED.\", \".. eccesessessessestesessecscsesseesesesseeseencsssesseesseeseeneeeses 249\\nTADIO MAPPING ......eeeee\", \"esesscsessesessesessesessesessesessesssesessesscsesussesssesssesucsssussesesssscsssessssessssessssec\", \"sssesussessesecussecesseensseensseeneaeenees 250\\nImplement the Query Specification PAtteMN uc ccecec\", \"esessessessesessessessssessecsesessessesesseeseesssesseeseeesseesseseseeseeseeesseess 253\\n\\nUse NoSQL\", \" databases as a persistence INFraStrUCtULe.....c.ceccesessessessesessessecsssessecsesesssssesessesse\", \"eucsessessesssesseeeeseeaes 255\\nIntroduction to Azure Cosmos DB and the native COSMOS DB API ......e\", \"eeseesessessessesesseeseeecseesesseeteseeneenensens 256\\nImplement .NET code targeting MongoDB and Az\", \"ure COSMOS DB ou... cecesesssssssessssesesseceeseeesseeesseeneseenees 258\\n\\nDesign the microservice a\", \"pplication layer ANd Web API... eeesessessssessessssesessesessesessesessesessesessesesseseeseseeseae\", \"s 266\\nUse SOLID principles and Dependency INJeCtiON ...... ee cecsesessesessesessesesseeessecssseces\", \"secessecesseesseeesseesseeesseeeseenees 266\\n\\nImplement the microservice application layer USINg the \", \"Web API... cessssessesessesesseseseseeseseseseeseseeseens 267\\nUse Dependency Injection to inject inf\", \"rastructure objects into your application layer... 267\\nImplement the Command and Command Handler pat\", \"terns .......ccccessessssessssessssecessesesseessseeeeseeesseeneseenees 271\\nThe Command process pipe\", \"line: how to trigger a COMMANA Nandlel uc eseseeseseeeceeseseeeeesseeteseeees 278\\nImplement the comm\", \"and process pipeline with a mediator pattern (MediatR) ......... ee cceeeeeeteceeeeees 281\\nApply cro\", \"ss-cutting concerns when processing commands with the Behaviors in MediatR .......... 287\\n\\nImplement\", \" resilient applications .......................sssssssssssssssssssssscssccscssscccssccccsccccccccccs\", \"scssssssees 291\\n\\nHandle partial failure ....cccccesessssessessessssessesscsessessesussessecscsussess\", \"esussessesussussessssussessecussussessesussessesucsessesuesessesseaussesseeneseeaes 292\\n\\nStrategies \", \"to handle partial failUre cc eesessesessessessssessessssesseesesessessecucsessessssesssesesessessees\", \"csesseesesesseeseeeseeseeneeeeses 294\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesess\", \"ecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneene\", \"nees 295\\n\\nImplement retries with exponential DaCKOFF oc ccccesessessssessessssessessesessessecscsess\", \"ecsesussesseescsesseesesesseesesessesseeneseeaes 295\\n\\nImplement resilient Entity Framework Core SQL \", \"CONNECTIONS......cececessessesessesesesessesessssessesessesessesessesseseseeseans 295\\n\\nExecution str\", \"ategies and explicit transactions using BeginTransaction and multiple DoContexts296\\nACditional reSOU\", \"MCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucse\", \"csecnesueseesecucseesesneseaeeneeeeateneeneenenees 298\\n\\nUse IHttpClientFactory to implement resilien\", \"t HTTP requests uu... esessssssssssssesessssessssesesesssssssssessssseseseeneens 298\\n\\nvil Contents\\nI\", \"ssues with the original HttpClient class available in NET uu. csesessesessecessesessecessecessesesse\", \"eesseeesseeneseenees 298\\n\\nBenefits Of USING IHttOClentFactOry nc cceccssessessssessessesssessesscses\", \"sessesessessscsssessessesessessecsssesseeseeusseeseencseeseeneeesseess 299\\nMultiple ways to use IHtt\", \"pClentFactOry un. cccccessessssessssescssscsssessssesssesessecsssecessessssecsssecessecessecessecsse\", \"eesseeneseeeees 300\\nHow to use Typed Clients with IHttpClentFactOry wc ccccssessssesssssssssscessecs\", \"ssecsssecesseeessesessesesseeesseeesseensseenees 300\\nACditional reSOUMCES .......eeesssssssessessese\", \"seesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeen\", \"eeeeateneeneenenees 304\\n\\nImplement HTTP call retries with exponential backoff with IHttpClientFactor\", \"y and Polly policies ...304\\n\\nAdd a jitter strategy to the retry Policy ...cccccssssssssssesessssssss\", \"ssssssessssessssessssessssessssessssessesesessesessesesseeesseeesseeeees 305\\nACditional reSOUMCES ..\", \".....eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnes\", \"ueseesecucseesesneseaeeneeeeateneeneenenees 306\\nImplement the Circuit Breaker pattern... ccccsssssss\", \"ssssssssssssesssssssssssssssssssessssesssssssssesssssesssessssesseseessseesssesseseeseseeseees 306\\nI\", \"mplement Circuit Breaker pattern with IHttpClientFactory and Poly cc eeseseeeeseeesseeeeseeeeseeees \", \"307\\nTest Http retries and circuit breakers in ESHOPONCONTAINETS........cceesesesssseseesecsesecesece\", \"ssesesesesseesseeeseenees 308\\nACditional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssss\", \"ecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 310\", \"\\nHealth MONIOSING .....ceececessesessesessesessessssesscsesucsesuesessssessssessssessssecussecsssess\", \"ssecsesecsssecsssessssessssessesecsesecsesessesesuesesscsesseseeseseeneans 310\\nImplement health chec\", \"ks in ASP.NET Core S@rviCe ......cececsesessessssessssesessecessesssesscsecsssecessecussecusseeessee\", \"esseeeeseenees 311\\nUSE WatChOdS ......c.cecessssssssssssesessesessesssessssessssecussesussecussesuss\", \"esussecussesussessesesussesussesussecussesussesuesecussesessesussesseseeueseeeeseeneseeeees 315\\nHeal\", \"th checks when USING Orchestrators ......ccecsesessesessecessecesseccssecssecscsesssecesseccssessese\", \"csssecessecussecesseeesseesseeeeseeeees 317\\nAdvanced monitoring: visualization, analysis, AN Alerts \", \"oe sesessssessesesssscssececsessesecsssesssecsseeesseeeseenees 317\\nACditional reSOUMCES .......eeess\", \"sssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecuc\", \"seesesneseaeeneeeeateneeneenenees 318\\nMake secure .NET Microservices and Web Applications. .........\", \"......ccccccccccsccccsssccssssssssseees 319\\nImplement authentication in .NET microservices and Web a\", \"pplications .......cecssssessesesseseeesesesesteseeseees 319\\nAuthenticate with ASP.NET Core ID@ntity\", \" a... ccesssssssesssssssssssssssesssssssssessssessssecsssessssessssessssesessecessecesseensseenees 3\", \"20\\nAuthenticate with external Providers .......ccecccssssssssssssssssessssssessssessssessssessssesss\", \"sessssecsssesessesnssecsesecessesessecesseeneseenees 321\\nAuthenticate with bearer tokens .......cece\", \"eessssssssssssesssssesessesssessessessesessesucsussecsesucsessecnesusaeesecusseeseeneeesaesseeeeaeen\", \"eeneeeeaees 323\\nAuthenticate with an OpenID Connect or OAuth 2.0 Identity Provider... cesesessecesse\", \"sesseeteseeteseeeees 324\\nIssue security tokens from an ASP.NET COre S@rviCe ....c.cscsssssessesseses\", \"sessecscsessessessssessecncsesseesceucsesseencseeseeneenssess 325\\nCONSUME SECULITY TOKENS wu... eeec\", \"essesessessssesssesscsesucsesuesecussecsssesussesuesesussessesesuesecussesussesussesuesecussecuesece\", \"sseeesseeesseeesseaeeseeess 326\\nACditional rESOULCES 0... eeesessessessesseseesessesnesessecsecucses\", \"secsesscsesuesucsessecucsucsecuesuesessecsesscsessesucsecsesucsucsecuecuesecsecucsecaeeneeueaeeneene\", \"asens 327\\nAbout authorization in .NET microservices and Web applications ou... cccesecsesesssseseses\", \"essesessssessesesesesseseeseees 327\\nImplement role-based AUTHOPIZATION ....... ee ccessesessesessese\", \"ssecessecscsecsesecessesscsecussecussecucsecussecussecussecussecusseceeseeesseensseenees 328\\nImpleme\", \"nt policy-based AUTHOLIZAtTION \\u00ab0... ccessesessesessecessecesseccesecsssesscsesussecusseccesecsesecu\", \"ssecussecuesesssseensseesseeneseenees 329\\nAUthOriZation ANd MINIMA APIS ou... eeeessesescsessesesses\", \"essesessesesscsesseseesesesscsessesessssessssesseseesssessesecessecessecesseeesseensseenees 330\\nACdi\", \"tional reSOUMCES .......eeesssssssessesseseseesecsessesessecucssssecuesucsecsecuesucsessecseacsecues\", \"ucsesnesucsecsecnesueseesecucseesesneseaeeneeeeateneeneenenees 330\\nvill Contents\\nStore application s\", \"ecrets safely CUriINgG CEVEIOPME|N........ ce cesessessesseseesesseesesesssesesssseeseesesessesseses\", \"esseeseseeseeneeeses 330\\n\\nStore Secrets IN ENVIFONMENT VArIADIE!S oo... ececsessesesseesessesessesse\", \"sscsessecsesuesessecuesecsecuesuesecsecsesecsecuecusaeenecueneeseeneaseass 331\\nStore secrets with th\", \"e ASP.NET Core Secret Manager uuu... ccsssssssssssssssssssesssssssssessssessssessssessesesseseeseses\", \"seseeneens 331\\n\\nUse Azure Key Vault to protect secrets at PrOdUCTION TIME ou... eececesssssssesseses\", \"sesessesesscsessesessesesseseesesteseseeneens 332\\nACditional reSOUMCES .......eeesssssssessessesesee\", \"secsessesessecucssssecuesucsecsecuesucsessecseacsecuesucsesnesucsecsecnesueseesecucseesesneseaeeneee\", \"eateneeneenenees 333\\n-NET Microservices Architecture key takeawayS ..............ccccccccccccsscsccc\", \"ssscsssscsssssssssssssssseees 334\\n\\nix Contents\\nCHAPTER\\n\\nIntroduction to Containers\\nand Docker\\n\\nConta\", \"inerization is an approach to software development in which an application or service, its\\ndependenc\", \"ies, and its configuration (abstracted as deployment manifest files) are packaged together\\nas a cont\", \"ainer image. The containerized application can be tested as a unit and deployed as a\\ncontainer image\", \" instance to the host operating system (OS).\\n\\nJust as shipping containers allow goods to be transpor\", \"ted by ship, train, or truck regardless of the\\ncargo inside, software containers act as a standard u\", \"nit of software deployment that can contain\\ndifferent code and dependencies. Containerizing software\", \" this way enables developers and IT\\nprofessionals to deploy them across environments with little or \", \"no modification.\\n\\nContainers also isolate applications from each other on a shared OS. Containerized\", \" applications run\\non top of a container host that in turn runs on the OS (Linux or Windows). Contain\", \"ers therefore have a\\nsignificantly smaller footprint than virtual machine (VM) images.\\n\\nEach contain\", \"er can run a whole web application or a service, as shown in Figure 2-1. In this example,\\nDocker hos\", \"t is a container host, and App1, App2, Svc 1, and Svc 2 are containerized applications or\\nservices.\\n\", \"\\nDocker Host\\n\\nFigure 2-1. Multiple containers running on a container host\\n\\n1 CHAPTER 1 | Introductio\", \"n to Containers and Docker\\nAnother benefit of containerization is scalability. You can scale out qui\", \"ckly by creating new containers\\nfor short-term tasks. From an application point of view, instantiati\", \"ng an image (creating a container) is\\nsimilar to instantiating a process like a service or a web app\", \". For reliability, however, when you run\\nmultiple instances of the same image across multiple host s\", \"ervers, you typically want each container\\n(image instance) to run in a different host server or VM i\", \"n different fault domains.\\n\\nIn short, containers offer the benefits of isolation, portability, agili\", \"ty, scalability, and control across the\\nwhole application lifecycle workflow. The most important ben\", \"efit is the environment\\u2019s isolation\\nprovided between Dev and Ops.\\n\\nWhat is Docker?\\n\\nDocker is an Ope\", \"n-source project for automating the deployment of applications as portable, self-\\nsufficient contain\", \"ers that can run on the cloud or on-premises. Docker is also a company that\\npromotes and evolves thi\", \"s technology, working in collaboration with cloud, Linux, and Windows\\nvendors, including Microsoft.\\n\", \"\\nRun anywhere\\n\\nWindows Server\\nContainer\\n\\nDocker\\n\\nFigure 2-2. Docker deploys containers at all layers\", \" of the hybrid cloud.\\n\\nDocker containers can run anywhere, on-premises in the customer datacenter, i\", \"n an external service\\nprovider or in the cloud, on Azure. Docker image containers can run natively o\", \"n Linux and Windows.\\nHowever, Windows images can run only on Windows hosts and Linux images can run \", \"on Linux hosts\\nand Windows hosts (using a Hyper-V Linux VM, so far), where host means a server or a \", \"VM.\\n\\nDevelopers can use development environments on Windows, Linux, or macOS. On the development\\ncom\", \"puter, the developer runs a Docker host where Docker images are deployed, including the app\\nand its \", \"dependencies. Developers who work on Linux or on macOS use a Docker host that is Linux\\nbased, and th\", \"ey can create images only for Linux containers. (Developers working on macOS can edit\\ncode or run th\", \"e Docker CLI from macOS, but as of the time of this writing, containers don\\u2019t run\\n\\n2 CHAPTER 1 | Int\", \"roduction to Containers and Docker\\ndirectly on macOS.) Developers who work on Windows can create ima\", \"ges for either Linux or Windows\\nContainers.\\n\\nTo host containers in development environments and prov\", \"ide additional developer tools, Docker\\nships Docker Desktop for Windows or for macOS. These products\", \" install the necessary VM (the Docker\\nhost) to host the containers.\\n\\nTo run Windows Containers, ther\", \"e are two types of runtimes:\\n\\n. Windows Server Containers provide application isolation through proc\", \"ess and namespace\\nisolation technology. A Windows Server Container shares a kernel with the containe\", \"r host and\\nwith all containers running on the host.\\n\\n. Hyper-V Containers expand on the Isolation pr\", \"ovided by Windows Server Containers by\\nrunning each container in a highly optimized virtual machine.\", \" In this configuration, the kernel\\nof the container host isn't shared with the Hyper-V Containers, p\", \"roviding better isolation.\\n\\nThe images for these containers are created the same way and function th\", \"e same. The difference is in\\nhow the container is created from the image running a Hyper-V Container\", \" requires an extra\\nparameter. For details, see Hyper-V Containers.\\n\\nComparing Docker containers with\", \" virtual machines\\n\\nFigure 2-3 shows a comparison between VMs and Docker containers.\\n\\nApp\\nBins/Libs B\", \"ins/Libs Bins/Libs App 1 App 2\\nBins/Libs Bins/Libs\\nGuest OS Guest OS Guest OS\\nContainer Engine\\n\\nHype\", \"rvisor\\n\\nOperating System\\n\\nHost Operating System\\n\\nInfrastructure\\n\\nInfrastructure || = f.\\n\\n3 CHAPTER 1\", \" | Introduction to Containers and Docker\\nVirtual Machines Docker Containers\\n\\nVirtual machines includ\", \"e the application, the Containers include the application and all its\\nrequired libraries or binaries\", \", and a full guest dependencies. However, they share the OS kernel\\noperating system. Full virtualiza\", \"tion requires with other containers, running as isolated\\n\\nmore resources than containerization. proc\", \"esses in user space on the host operating\\nsystem. (Except in Hyper-V containers, where\\neach containe\", \"r runs inside of a special virtual\\nmachine per container.)\\n\\nFigure 2-3. Comparison of traditional vi\", \"rtual machines to Docker containers\\n\\nFor VMs, there are three base layers in the host server, from t\", \"he bottom-up: infrastructure, Host\\nOperating System and a Hypervisor and on top of all that each VM \", \"has its own OS and all necessary\\nlibraries. For Docker, the host server only has the infrastructure \", \"and the OS and on top of that, the\\ncontainer engine, that keeps container isolated but sharing the b\", \"ase OS services.\\n\\nBecause containers require far fewer resources (for example, they don\\u2019t need a ful\", \"l OS), they're easy to\\ndeploy and they start fast. This allows you to have higher density, meaning t\", \"hat it allows you to run\\nmore services on the same hardware unit, thereby reducing costs.\\n\\nAs a side\", \" effect of running on the same kernel, you get less isolation than VMs.\\n\\nThe main goal of an image i\", \"s that it makes the environment (dependencies) the same across different\\ndeployments. This means tha\", \"t you can debug it on your machine and then deploy it to another\\nmachine with the same environment g\", \"uaranteed.\\n\\nA container image is a way to package an app or service and deploy it in a reliable and \", \"reproducible\\nway. You could say that Docker isn't only a technology but also a philosophy and a proc\", \"ess.\\n\\nWhen using Docker, you won't hear developers say, \\u201cIt works on my machine, why not in producti\", \"on?\\u201d\\nThey can simply say, \\u201cIt runs on Docker\\u201d, because the packaged Docker application can be execut\", \"ed\\non any supported Docker environment, and it runs the way it was intended to on all deployment\\ntar\", \"gets (such as Dev, QA, staging, and production).\\n\\nA simple analogy\\n\\nPerhaps a simple analogy can hel\", \"p getting the grasp of the core concept of Docker.\\n\\nLet's go back in time to the 1950s for a moment.\", \" There were no word processors, and the\\nphotocopiers were used everywhere (kind of).\\n\\nImagine you're\", \" responsible for quickly issuing batches of letters as required, to mail them to\\ncustomers, using re\", \"al paper and envelopes, to be delivered physically to each customer's address\\n(there was no email ba\", \"ck then).\\n\\nAt some point, you realize the letters are just a composition of a large set of paragraph\", \"s, which are\\npicked and arranged as needed, according to the purpose of the letter, so you devise a \", \"system to\\nissue letters quickly, expecting to get a hefty raise.\\n\\nThe system Is simple:\\n1. You begin\", \" with a deck of transparent sheets containing one paragraph each.\\n\\n4 CHAPTER 1 | Introduction to Con\", \"tainers and Docker\\n2. To issue a set of letters, you pick the sheets with the paragraphs you need, t\", \"hen you stack and\\nalign them so they look and read fine.\\n\\n3. Finally, you place the set in the photo\", \"copier and press start to produce as many letters as\\nrequired.\\n\\nSo, simplifying, that\\u2019s the core ide\", \"a of Docker.\\n\\nIn Docker, each layer is the resulting set of changes that happen to the filesystem af\", \"ter executing a\\ncommand, such as, installing a program.\\n\\nSo, when you \\u201clook\\u201d at the filesystem after\", \" the layer has been copied, you see all the files, included in\\nthe layer when the program was instal\", \"led.\\n\\nYou can think of an image as an auxiliary read-only hard disk ready to be installed in a \\u201ccomp\", \"uter\\u201d\\nwhere the operating system is already installed.\\n\\nSimilarly, you can think of a container as t\", \"he \\u201ccomputer\\u201d with the image hard disk installed. The\\ncontainer, just like a computer, can be powere\", \"d on or off.\\n\\nDocker terminology\\n\\nThis section lists terms and definitions you should be familiar wi\", \"th before getting deeper into Docker.\\nFor further definitions, see the extensive glossary provided b\", \"y Docker.\\n\\nContainer image: A package with all the dependencies and information needed to create a c\", \"ontainer.\\nAn image includes all the dependencies (such as frameworks) plus deployment and execution\\n\", \"configuration to be used by a container runtime. Usually, an image derives from multiple base images\", \"\\nthat are layers stacked on top of each other to form the container\\u2019s filesystem. An image is immuta\", \"ble\\nonce it has been created.\\n\\nDockerfile: A text file that contains instructions for building a Doc\", \"ker image. It\\u2019s like a batch script,\\nthe first line states the base image to begin with and then fol\", \"low the instructions to install required\\nprograms, copy files, and so on, until you get the working \", \"environment you need.\\n\\nBuild: The action of building a container image based on the information and \", \"context provided by its\\nDockerfile, plus additional files in the folder where the image is built. Yo\", \"u can build images with the\\nfollowing Docker command:\\n\\ndocker build\\n\\nContainer: An instance of a Doc\", \"ker image. A container represents the execution of a single\\napplication, process, or service. It con\", \"sists of the contents of a Docker image, an execution\\nenvironment, and a standard set of instruction\", \"s. When scaling a service, you create multiple instances\\nof a container from the same image. Or a ba\", \"tch job can create multiple containers from the same\\nimage, passing different parameters to each ins\", \"tance.\\n\\nVolumes: Offer a writable filesystem that the container can use. Since images are read-only \", \"but most\\nprograms need to write to the filesystem, volumes add a writable layer, on top of the conta\", \"iner image,\\nso the programs have access to a writable filesystem. The program doesn\\u2019t know it's acce\", \"ssing a\\n\\n5 CHAPTER 1 | Introduction to Containers and Docker\\nlayered filesystem, it\\u2019s just the files\", \"ystem as usual. Volumes live in the host system and are managed\\nby Docker.\\n\\nTag: A mark or label you\", \" can apply to images so that different images or versions of the same image\\n(depending on the versio\", \"n number or the target environment) can be identified.\\n\\nMulti-stage Build: Is a feature, since Docke\", \"r 17.05 or higher, that helps to reduce the size of the final\\nimages. For example, a large base imag\", \"e, containing the SDK can be used for compiling and\\npublishing and then a small runtime-only base im\", \"age can be used to host the application.\\n\\nRepository (repo): A collection of related Docker images, \", \"labeled with a tag that indicates the image\\nversion. Some repos contain multiple variants of a speci\", \"fic image, such as an image containing SDKs\\n\\n(heavier), an image containing only runtimes (lighter),\", \" etc. Those variants can be marked with tags. A\\nsingle repo can contain platform variants, such as a\", \" Linux image and a Windows image.\\n\\nRegistry: A service that provides access to repositories. The def\", \"ault registry for most public images is\\nDocker Hub (owned by Docker as an organization). A registry \", \"usually contains repositories from\\nmultiple teams. Companies often have private registries to store \", \"and manage images they've created.\\nAzure Container Registry is another example.\\n\\nMulti-arch image: F\", \"or multi-architecture (or multi-platform), it\\u2019s a Docker feature that simplifies the\\nselection of th\", \"e appropriate image, according to the platform where Docker is running. For example,\\nwhen a Dockerfi\", \"le requests a base image FROM mcr.microsoft.com/dotnet/sdk:7.0 from the\\nregistry, it actually gets 7\", \".0-nanoserver-Itsc2022, 7.0-nanoserver-1809 or 7.0-bullseye-slim,\\ndepending on the operating system \", \"and version where Docker is running.\\n\\nDocker Hub: A public registry to upload images and work with t\", \"hem. Docker Hub provides Docker\\nimage hosting, public or private registries, build triggers and web \", \"hooks, and integration with GitHub\\nand Bitbucket.\\n\\nAzure Container Registry: A public resource for w\", \"orking with Docker images and its components in\\nAzure. This provides a registry that\\u2019s close to your\", \" deployments in Azure and that gives you control\\nover access, making it possible to use your Azure A\", \"ctive Directory groups and permissions.\\n\\nDocker Trusted Registry (DTR): A Docker registry service (f\", \"rom Docker) that can be installed on-\\npremises so it lives within the organization's datacenter and \", \"network. It\\u2019s convenient for private\\nimages that should be managed within the enterprise. Docker Tru\", \"sted Registry is included as part of\\nthe Docker Datacenter product.\\n\\nDocker Desktop: Development too\", \"ls for Windows and macOS for building, running, and testing\\ncontainers locally. Docker Desktop for W\", \"indows provides development environments for both Linux\\nand Windows Containers. The Linux Docker hos\", \"t on Windows is based on a Hyper-V virtual machine.\\nThe host for Windows Containers is directly base\", \"d on Windows. Docker Desktop for Mac is based on\\nthe Apple Hypervisor framework and the xhyve hyperv\", \"isor, which provides a Linux Docker host virtual\\nmachine on macOS. Docker Desktop for Windows and fo\", \"r Mac replaces Docker Toolbox, which was\\nbased on Oracle VirtualBox.\\n\\nCompose: A command-line tool a\", \"nd YAML file format with metadata for defining and running multi-\\ncontainer applications. You define\", \" a single application based on multiple images with one or more\\n.yml files that can override values \", \"depending on the environment. After you've created the definitions,\\n\\n6 CHAPTER 1 | Introduction to C\", \"ontainers and Docker\\nyou can deploy the whole multi-container application with a single command (doc\", \"ker-compose up)\\nthat creates a container per image on the Docker host.\\n\\nCluster: A collection of Doc\", \"ker hosts exposed as if it were a single virtual Docker host, so that the\\napplication can scale to m\", \"ultiple instances of the services spread across multiple hosts within the\\ncluster. Docker clusters c\", \"an be created with Kubernetes, Azure Service Fabric, Docker Swarm and\\n\\nMesosphere DC/OS.\\n\\nOrchestrat\", \"or: A tool that simplifies the management of clusters and Docker hosts. Orchestrators\\nenable you to \", \"manage their images, containers, and hosts through a command-line interface (CLI) or a\\ngraphical Ul.\", \" You can manage container networking, configurations, load balancing, service discovery,\\nhigh availa\", \"bility, Docker host configuration, and more. An orchestrator is responsible for running,\\ndistributin\", \"g, scaling, and healing workloads across a collection of nodes. Typically, orchestrator\\nproducts are\", \" the same products that provide cluster infrastructure, like Kubernetes and Azure Service\\nFabric, am\", \"ong other offerings in the market.\\n\\nDocker containers, images, and registries\\n\\nWhen using Docker, a \", \"developer creates an app or service and packages it and its dependencies into\\na container image. An \", \"image Is a static representation of the app or service and its configuration and\\ndependencies.\\n\\nTo r\", \"un the app or service, the app\\u2019s image is instantiated to create a container, which will be running\\n\", \"on the Docker host. Containers are initially tested in a development environment or PC.\\n\\nDevelopers \", \"should store images in a registry, which acts as a library of images and is needed when\\ndeploying to\", \" production orchestrators. Docker maintains a public registry via Docker Hub; other\\nvendors provide \", \"registries for different collections of images, including Azure Container Registry.\\nAlternatively, e\", \"nterprises can have a private registry on-premises for their own Docker images.\\n\\nFigure 2-4 shows ho\", \"w images and registries in Docker relate to other components. It also shows the\\nmultiple registry of\", \"ferings from vendors.\\n\\n7 CHAPTER 1 | Introduction to Containers and Docker\\nBasic taxonomy In Docker \", \"Hosted Docker\\n\\nRegistry\\nOn-premises\\nDocker Trusted (\\u2018n\\u2019 private organizations)\\nRegistry on-prem.\\n\\nDo\", \"cker Hub\\nA Registry Registry\\nStores many\\nstatic images Docker Trusted\\n\\nRegistry on-cloud\\n\\n' Azure Co\", \"ntainer\\nmages\\n\\na Static, persisted container image Registry\\nAWS Container Public Cloud\\nV4 Registry (\", \"specific vendors)\\nTi Google\\n: Container\\n4 | Container Registry\\n7 @ \\u00bb, > |mage-instance running\\noe ~ \", \"S_ anapp process (service/web) Quay\\nRegistry\\nOther Cloud\\n\\nFigure 2-4. Taxonomy of Docker terms and c\", \"oncepts\\n\\nThe registry is like a bookshelf where images are stored and available to be pulled for bui\", \"lding\\ncontainers to run services or web apps. There are private Docker registries on-premises and on\", \" the\\npublic cloud. Docker Hub is a public registry maintained by Docker, along the Docker Trusted Re\", \"gistry\\nan enterprise-grade solution, Azure offers the Azure Container Registry. AWS, Google, and oth\", \"ers also\\nhave container registries.\\n\\nPutting images in a registry lets you store static and immutabl\", \"e application bits, including all their\\ndependencies at a framework level. Those images can then be \", \"versioned and deployed in multiple\\nenvironments and therefore provide a consistent deployment unit.\\n\", \"\\nPrivate image registries, either hosted on-premises or in the cloud, are recommended when:\\n\\n. Your \", \"images must not be shared publicly due to confidentiality.\\n\\n. You want to have minimum network laten\", \"cy between your images and your chosen\\ndeployment environment. For example, if your production envir\", \"onment is Azure cloud, you\\nprobably want to store your images in Azure Container Registry so that ne\", \"twork latency will\\nbe minimal. In a similar way, if your production environment is on-premises, you \", \"might want\\nto have an on-premises Docker Trusted Registry available within the same local network.\\n\\n\", \"8 CHAPTER 1 | Introduction to Containers and Docker\\nCHAPTER\\n\\nCnoosing Between .NET\\nand .NET Framewor\", \"k for\\nDocker Containers\\n\\nThere are two supported frameworks for building server-side containerized D\", \"ocker applications with\\n.NET: .NET Framework and .NET 7. They share many .NET platform components, a\", \"nd you can share\\ncode across the two. However, there are fundamental differences between them, and w\", \"hich\\nframework you use will depend on what you want to accomplish. This section provides guidance on\", \"\\nwhen to choose each framework.\\n\\nGeneral guidance\\n\\nThis section provides a summary of when to choose\", \" .NET 7 or .NET Framework. We provide more\\ndetails about these choices in the sections that follow.\\n\", \"\\nUse .NET 7, with Linux or Windows Containers, for your containerized Docker server application when\", \":\\n\\n. You have cross-platform needs. For example, you want to use both Linux and Windows\\nContainers.\\n\", \"\\n. Your application architecture is based on microservices.\\n\\n. You need to start containers fast and\", \" want a small footprint per container to achieve better\\ndensity or more containers per hardware unit\", \" in order to lower your costs.\\n\\nIn short, when you create new containerized .NET applications, you s\", \"hould consider .NET 7 as the\\ndefault choice. It has many benefits and fits best with the containers \", \"philosophy and style of working.\\n\\nAn extra benefit of using .NET 7 is that you can run side-by-side \", \".NET versions for applications within\\nthe same machine. This benefit is more important for servers o\", \"r VMs that do not use containers,\\nbecause containers isolate the versions of .NET that the app needs\", \". (As long as they are compatible\\nwith the underlying OS.)\\n\\nUse .NET Framework for your containerize\", \"d Docker server application when:\\n\\n. Your application currently uses .NET Framework and has strong d\", \"ependencies on Windows.\\n\\n9 CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Container\", \"s\\n. You need to use Windows APIs that are not supported by .NET 7.\\n. You need to use third-party .NE\", \"T libraries or NuGet packages that are not available for .NET 7.\\n\\nUsing .NET Framework on Docker can\", \" improve your deployment experiences by minimizing\\ndeployment issues. This \\u201clift and shift\\u201d scenario\", \" is important for containerizing legacy applications that\\nwere originally developed with the traditi\", \"onal .NET Framework, like ASP.NET WebForms, MVC web\\napps, or WCF (Windows Communication Foundation) \", \"services.\\n\\nAdditional resources\\n\\n\\u00b0 E-book: Modernize existing .NET Framework applications with Azure\", \" and Windows\\nContainers\\n\\nhttps://aka.ms/liftandshiftwithcontainersebook\\n\\n. Sample apps: Modernizatio\", \"n of legacy ASP.NET web apps by using Windows Containers\\nhttps://aka.ms/eshopmodernizing\\n\\nWhen to ch\", \"oose .NET for Docker containers\\n\\nThe modularity and lightweight nature of .NET 7 makes it perfect fo\", \"r containers. When you deploy\\nand start a container, its image is far smaller with .NET 7 than with \", \".NET Framework. In contrast, to use\\n.NET Framework for a container, you must base your image on the \", \"Windows Server Core image, which\\nis a lot heavier than the Windows Nano Server or Linux images that \", \"you use for .NET 7.\\n\\nAdditionally, .NET 7 is cross-platform, so you can deploy server apps with Linu\", \"x or Windows container\\nimages. However, if you are using the traditional .NET Framework, you can onl\", \"y deploy images based\\non Windows Server Core.\\n\\nThe following is a more detailed explanation of why t\", \"o choose .NET 7.\\n\\nDeveloping and deploying cross platform\\n\\nClearly, if your goal is to have an appli\", \"cation (web app or service) that can run on multiple platforms\\nsupported by Docker (Linux and Window\", \"s), the right choice is .NET 7, because .NET Framework only\\nsupports Windows.\\n\\n.NET 7 also supports \", \"macOS as a development platform. However, when you deploy containers to a\\nDocker host, that host mus\", \"t (currently) be based on Linux or Windows. For example, in a development\\nenvironment, you could use\", \" a Linux VM running on a Mac.\\n\\nVisual Studio provides an integrated development environment (IDE) fo\", \"r Windows and supports\\nDocker development.\\n\\nVisual Studio for Mac is an IDE, evolution of Xamarin St\", \"udio, that runs on macOS and supports\\nDocker-based application development. This tool should be the \", \"preferred choice for developers\\nworking in Mac machines who also want to use a powerful IDE.\\n\\nYou ca\", \"n also use Visual Studio Code on macOS, Linux, and Windows. Visual Studio Code fully\\nsupports .NET 7\", \", including Intellisense and debugging. Because VS Code is a lightweight editor, you\\n\\n10 CHAPTER 2 |\", \" Choosing Between .NET and .NET Framework for Docker Containers\\ncan use it to develop containerized \", \"apps on the machine in conjunction with the Docker CLI and the\\n.NET CLI. You can also target .NET 7 \", \"with most third-party editors like Sublime, Emacs, vi, and the\\nopen-source OmniSharp project, which \", \"also provides Intellisense support.\\n\\nIn addition to the IDEs and editors, you can use the .NET CLI f\", \"or all supported platforms.\\n\\nUsing containers for new (\\u201cgreen-field\\u201d) projects\\n\\nContainers are commo\", \"nly used in conjunction with a microservices architecture, although they can\\nalso be used to contain\", \"erize web apps or services that follow any architectural pattern. You can use\\n.NET Framework on Wind\", \"ows Containers, but the modularity and lightweight nature of .NET 7 makes\\nit perfect for containers \", \"and microservices architectures. When you create and deploy a container, its\\nimage is far smaller wi\", \"th .NET 7 than with .NET Framework.\\n\\nCreate and deploy microservices on containers\\n\\nYou could use th\", \"e traditional .NET Framework for building microservices-based applications (without\\ncontainers) by u\", \"sing plain processes. That way, because the .NET Framework is already installed and\\nshared across pr\", \"ocesses, processes are light and fast to start. However, if you are using containers, the\\nimage for \", \"the traditional .NET Framework is also based on Windows Server Core and that makes it too\\nheavy for \", \"a microservices-on-containers approach. However, teams have been looking for\\nopportunities to improv\", \"e the experience for .NET Framework users as well. Recently, size of the\\n\\nWindows Server Core contai\", \"ner images have been reduced to >40% smaller.\\n\\nOn the other hand, .NET 7 is the best candidate if yo\", \"u're embracing a microservices-oriented system\\nthat is based on containers because .NET 7 is lightwe\", \"ight. In addition, its related container images, for\\neither Linux or Windows Nano Server, are lean a\", \"nd small, making containers light and fast to start.\\n\\nA microservice is meant to be as small as poss\", \"ible: to be light when spinning up, to have a small\\nfootprint, to have a small Bounded Context (chec\", \"k DDD, Domain-Driven Design), to represent a small\\narea of concerns, and to be able to start and sto\", \"p fast. For those requirements, you will want to use\\nsmall and fast-to-instantiate container images \", \"like the .NET 7 container image.\\n\\nA microservices architecture also allows you to mix technologies a\", \"cross a service boundary. This\\napproach enables a gradual migration to .NET 7 for new microservices \", \"that work in conjunction with\\nother microservices or with services developed with Node,js, Python, J\", \"ava, GoLang, or other\\ntechnologies.\\n\\nDeploying high density in scalable systems\\n\\nWhen your container\", \"-based system needs the best possible density, granularity, and performance,\\n.NET and ASP.NET Core a\", \"re your best options. ASP.NET Core is up to 10 times faster than ASP.NET in\\nthe traditional .NET Fra\", \"mework, and it leads to other popular industry technologies for microservices,\\nsuch as Java servlets\", \", Go, and Nodes.\\n\\nThis approach is especially relevant for microservices architectures, where you co\", \"uld have hundreds of\\nmicroservices (containers) running. With ASP.NET Core images (based on the .NET\", \" runtime) on Linux\\nor Windows Nano, you can run your system with a much lower number of servers or V\", \"Ms, ultimately\\nsaving costs in infrastructure and hosting.\\n\\n11 CHAPTER 2 | Choosing Between .NET and\", \" .NET Framework for Docker Containers\\nWhen to choose .NET Framework for Docker\\ncontainers\\n\\nWhile .NE\", \"T 7 offers significant benefits for new applications and application patterns, .NET Framework\\nwill c\", \"ontinue to be a good choice for many existing scenarios.\\n\\nMigrating existing applications directly t\", \"o a Windows Server container\\n\\nYou might want to use Docker containers just to simplify deployment, e\", \"ven if you are not creating\\nmicroservices. For example, perhaps you want to improve your DevOps work\", \"flow with Docker\\u2014\\ncontainers can give you better isolated test environments and can also eliminate d\", \"eployment issues\\ncaused by missing dependencies when you move to a production environment. In cases \", \"like these,\\neven if you are deploying a monolithic application, it makes sense to use Docker and Win\", \"dows\\nContainers for your current .NET Framework applications.\\n\\nIn most cases for this scenario, you \", \"will not need to migrate your existing applications to .NET 7; you\\ncan use Docker containers that in\", \"clude the traditional .NET Framework. However, a recommended\\napproach is to use .NET 7 as you extend\", \" an existing application, such as writing a new service in\\nASP.NET Core.\\n\\nUsing third-party .NET lib\", \"raries or NuGet packages not available for\\n.NET 7\\n\\nThird-party libraries are quickly embracing .NET \", \"Standard, which enables code sharing across all .NET\\nflavors, including .NET 7. With .NET Standard 2\", \".0 and later, the API surface compatibility across\\ndifferent frameworks has become significantly lar\", \"ger. Even more, .NET Core 2.x and newer applications\\ncan also directly reference existing .NET Frame\", \"work libraries (see .NET Framework 4.6.1 supporting\\n.NET Standard 2.0).\\n\\nIn addition, the Windows Co\", \"mpatibility Pack extends the API surface available for .NET Standard 2.0\\non Windows. This pack allow\", \"s recompiling most existing code to .NET Standard 2.x with little or no\\nmodification, to run on Wind\", \"ows.\\n\\nHowever, even with that exceptional progression since .NET Standard 2.0 and .NET Core 2.1 or l\", \"ater,\\nthere might be cases where certain NuGet packages need Windows to run and might not support\\n.N\", \"ET Core or later. If those packages are critical for your application, then you will need to use .NE\", \"T\\nFramework on Windows Containers.\\n\\nUsing .NET technologies not available for .NET 7\\n\\nSome .NET Fram\", \"ework technologies aren't available in .NET 7. Some of them might become available\\nin later releases\", \", but others don't fit the new application patterns targeted by .NET Core and might\\nnever be availab\", \"le.\\n\\nThe following list shows most of the technologies that aren't available in .NET 7:\\n\\n12 CHAPTER \", \"2 | Choosing Between .NET and .NET Framework for Docker Containers\\n\\u00b0 ASP.NET Web Forms. This technol\", \"ogy is only available on .NET Framework. Currently there are\\nno plans to bring ASP.NET Web Forms to \", \".NET or later.\\n\\n\\u00b0 Workflow-related services. Windows Workflow Foundation (WF), Workflow Services (WC\", \"F +\\nWF in a single service), and WCF Data Services (formerly known as ADO.NET Data Services)\\nare onl\", \"y available on .NET Framework. There are currently no plans to bring them to .NET 7.\\n\\nIn addition to\", \" the technologies listed in the official .NET roadmap, other features might be ported to\\n\\nthe new un\", \"ified .NET platform. You might consider participating in the discussions on GitHub so that\\n\\nyour voi\", \"ce can be heard. And if you think something is missing, file a new issue in the dotnet/runtime\\nGitHu\", \"b repository.\\n\\nUsing a platform or API that doesn\\u2019t support .NET 7\\n\\nSome Microsoft and third-party p\", \"latforms don\\u2019t support .NET 7. For example, some Azure services\\nprovide an SDK that isn\\u2019t yet availa\", \"ble for consumption on .NET 7 yet. Most Azure SDK should\\neventually be ported to .NET 7/.NET Standar\", \"d, but some might not for several reasons. You can see\\nthe available Azure SDKs in the Azure SDK Lat\", \"est Releases page.\\n\\nIn the meantime, if any platform or service in Azure still doesn\\u2019t support .NET \", \"7 with its client API, you\\ncan use the equivalent REST API from the Azure service or the client SDK \", \"on .NET Framework.\\n\\nPorting existing ASP.NET application to .NET 7\\n\\n.NET Core is a revolutionary ste\", \"p forward from .NET Framework. It offers a host of advantages over\\n.NET Framework across the board f\", \"rom productivity to performance, and from cross-platform support\\nto developer satisfaction. If you a\", \"re using .NET Framework and planning to migrate your application\\n\\nto .NET Core or .NET 5+, see Porti\", \"ng Existing ASP.NET Apps to .NET Core.\\n\\nAdditional resources\\n\\n\\u00b0 -NET fundamentals\\n\\nhttps://learn.mic\", \"rosoft.com/dotnet/fundamentals\\n\\n. Porting Projects to .NET 5\\nhttps://learn.microsoft.com/events/dotn\", \"etconf-2020/porting-projects-to-net-5\\n\\n\\u00b0 -NET on Docker Guide\\nhttps://learn.microsoft.com/dotnet/cor\", \"e/docker/introduction\\n\\nDecision table: NET implementations to use for\\nDocker\\n\\nThe following decision\", \" table summarizes whether to use .NET Framework or .NET 7. Remember that\\nfor Linux containers, you n\", \"eed Linux-based Docker hosts (VMs or servers), and that for Windows\\nContainers, you need Windows Ser\", \"ver-based Docker hosts (VMs or servers).\\n\\n13 CHAPTER 2 | Choosing Between .NET and .NET Framework fo\", \"r Docker Containers\\nImportant\\n\\nYour development machines will run one Docker host, either Linux or W\", \"indows. Related microservices\\n\\nthat you want to run and test together in one solution will all need \", \"to run on the same container\\nplatform.\\n\\nArchitecture / App Type Windows Containers\\nMicroservices on \", \"containers .NET 7 .NET 7\\n\\nMonolithic app .NET 7 .NET Framework\\n.NET 7\\n\\nBest-in-class performance and\", \" .NET 7 .NET 7\\n\\nscalability\\n\\nWindows Server legacy app (\\u201cbrown- .NET Framework\\n\\nfield\\\") migration to\", \" containers\\n\\nNew container-based development .NET 7 .NET 7\\n\\n(\\u201cgreen-field\\u201d)\\n\\nASP.NET Core .NET 7 .NE\", \"T 7 (recommended)\\n.NET Framework\\n\\nASP.NET 4 (MVC 5, Web API 2, and .NET Framework\\n\\nWeb Forms)\\n\\nSigna\", \"lR services .NET Core 2.1 or higher .NET Framework\\nversion .NET Core 2.1 or higher\\nversion\\n\\nWCF, WF,\", \" and other legacy WCF in .NET Core (client .NET Framework\\nframeworks library only) or CoreWCF WCF in\", \" .NET 7 (client library\\nonly) or CoreWCF\\n\\nConsumption of Azure services .NET 7 .NET Framework\\n(event\", \"ually most Azure .NET 7\\nservices will provide client | (eventually most Azure\\nSDKs for .NET 7) servi\", \"ces will provide client\\nSDKs for .NET 7)\\n\\nWhat OS to target with .NET containers\\n\\nGiven the diversit\", \"y of operating systems supported by Docker and the differences between .NET\\nFramework and .NET 7, yo\", \"u should target a specific OS and specific versions depending on the\\nframework you are using.\\n\\nFor W\", \"indows, you can use Windows Server Core or Windows Nano Server. These Windows versions\\nprovide diffe\", \"rent characteristics (IIS in Windows Server Core versus a self-hosted web server like\\nKestrel in Nan\", \"o Server) that might be needed by .NET Framework or .NET 7, respectively.\\n\\nFor Linux, multiple distr\", \"os are available and supported in official .NET Docker images (like Debian).\\n\\n14 CHAPTER 2 | Choosin\", \"g Between .NET and .NET Framework for Docker Containers\\nIn Figure 3-1, you can see the possible OS v\", \"ersion depending on the .NET framework used.\\n\\nWhat OS to target with .NET containers\\n\\n\\\\\\n\\u00abgs . Compat\", \"ible with |\\nExisting .NET Framework Windows existing apps |\\n. IIS |\\napps 3.5, 4.x Server Core Larger\", \" Image\\n/\\nCloud Optimized,\\nWindows Container OS\\nKestrel\\nNano Server Smaller, Faster Start\\nTime\\n\\nDebia\", \"n, Alpine, etc.\\nKestrel\\n\\nSmaller, Faster Start\\nTime\\n\\nFigure 3-1. Operating systems to target dependi\", \"ng on versions of the .NET framework\\n\\nWhen deploying legacy .NET Framework applications you have to \", \"target Windows Server Core,\\ncompatible with legacy apps and IIS, but it has a larger image. When dep\", \"loying .NET 7 applications,\\nyou can target Windows Nano Server, which is cloud optimized, uses Kestr\", \"el and is smaller and starts\\nfaster. You can also target Linux, supporting Debian, Alpine, and other\", \"s.\\n\\nYou can also create your own Docker image in cases where you want to use a different Linux distr\", \"o or\\nwhere you want an image with versions not provided by Microsoft. For example, you might create \", \"an\\nimage with ASP.NET Core running on the traditional .NET Framework and Windows Server Core, which\\n\", \"is a not-so-common scenario for Docker.\\n\\nWhen you add the image name to your Dockerfile file, you ca\", \"n select the operating system and\\nversion depending on the tag you use, as in the following examples\", \":\\n\\nmcr.microsoft.com/dotnet/runtime:7.0 | .NET 7 multi-architecture: Supports Linux and Windows\\nNano\", \" Server depending on the Docker host.\\n\\nmcr.microsoft.com/dotnet/aspnet:7.0 ASP.NET Core 7.0 multi-ar\", \"chitecture: Supports Linux and\\nWindows Nano Server depending on the Docker host.\\nThe aspnetcore imag\", \"e has a few optimizations for\\nASP.NET Core.\\n\\nmcr.microsoft.com/dotnet/aspnet:7.0- | .NET 7 runtime-o\", \"nly on Linux Debian distro\\nbullseye-slim\\n\\nmcr.microsoft.com/dotnet/aspnet:7.0- | .NET 7 runtime-only\", \" on Windows Nano Server (Windows\\nnanoserver- 1809 Server version 1809)\\n\\n15 CHAPTER 2 | Choosing Betw\", \"een .NET and .NET Framework for Docker Containers\\n\\nOfficial INET Docker images\\n\\nThe Official NET Doc\", \"ker images are Docker images created and optimized by Microsoft. They're\\npublicly available on Micro\", \"soft Artifact Registry. You can search over the catalog to find all .NET image\\nrepositories, for exa\", \"mple .NET SDK repository.\\n\\nEach repository can contain multiple images, depending on .NET versions, \", \"and depending on the OS\\nand versions (Linux Debian, Linux Alpine, Windows Nano Server, Windows Serve\", \"r Core, and so on).\\nImage repositories provide extensive tagging to help you select not just a speci\", \"fic framework version,\\nbut also to choose an OS (Linux distribution or Windows version).\\n\\n.NET and D\", \"ocker image optimizations for development versus\\nproduction\\n\\nWhen building Docker images for develop\", \"ers, Microsoft focused on the following main scenarios:\\n. Images used to develop and build .NET apps\", \".\\n\\u00b0 Images used to run .NET apps.\\n\\nWhy multiple images? When developing, building, and running conta\", \"inerized applications, you usually\\nhave different priorities. By providing different images for thes\", \"e separate tasks, Microsoft helps\\noptimize the separate processes of developing, building, and deplo\", \"ying apps.\\n\\nDuring development and build\\n\\nDuring development, what is important is how fast you can \", \"iterate changes, and the ability to debug\\nthe changes. The size of the image isn't as important as t\", \"he ability to make changes to your code and\\nsee the changes quickly. Some tools and \\u201cbuild-agent con\", \"tainers\\u201d, use the development .NET image\\n(mcr.microsoft.com/dotnet/sdk:7.0) during development and b\", \"uild process. When building inside a\\nDocker container, the important aspects are the elements that a\", \"re needed to compile your app. This\\nincludes the compiler and any other .NET dependencies.\\n\\nWhy is t\", \"his type of build image important? You don't deploy this image to production. Instead, it's an\\nimage\", \" that you use to build the content you place into a production image. This image would be used\\nin yo\", \"ur continuous integration (Cl) environment or build environment when using Docker multi-stage\\nbuilds\", \".\\n\\nIn production\\n\\nWhat is important in production is how fast you can deploy and start your containe\", \"rs based on a\\nproduction .NET image. Therefore, the runtime-only image based on\\nmcr.microsoft.com/do\", \"tnet/aspnet:7.0 is small so that it can travel quickly across the network from your\\nDocker registry \", \"to your Docker hosts. The contents are ready to run, enabling the fastest time from\\nstarting the con\", \"tainer to processing results. In the Docker model, there is no need for compilation\\nfrom C# code, as\", \" there\\u2019s when you run dotnet build or dotnet publish when using the build container.\\n\\n16 CHAPTER 2 |\", \" Choosing Between .NET and .NET Framework for Docker Containers\\nIn this optimized image, you put onl\", \"y the binaries and other content needed to run the application.\\nFor example, the content created by \", \"dotnet publish contains only the compiled .NET binaries, images,\\nJs, and .css files. Over time, you'\", \"ll see images that contain pre-jitted (the compilation from IL to native\\nthat occurs at run time) pa\", \"ckages.\\n\\nAlthough there are multiple versions of the .NET and ASP.NET Core images, they all share on\", \"e or more\\nlayers, including the base layer. Therefore, the amount of disk space needed to store an i\", \"mage is\\nsmall; it consists only of the delta between your custom image and its base image. The resul\", \"t is that\\nit's quick to pull the image from your registry.\\n\\nWhen you explore the .NET image reposito\", \"ries at Microsoft Artifact Registry, you'll find multiple image\\nversions classified or marked with t\", \"ags. These tags help to decide which one to use, depending on the\\n\\nversion you need, like those in t\", \"he following table:\\n\\nmcr.microsoft.com/dotnet/aspnet:7.0 ASP.NET Core, with runtime only and ASP.NET\", \" Core\\n\\noptimizations, on Linux and Windows (multi-arch)\\n\\nmcr.microsoft.com/dotnet/sdk:7.0 NET 7, wit\", \"h SDKs included, on Linux and Windows\\n(multi-arch)\\n\\nYou can find all the available docker images in \", \"dotnet-docker and also refer to the latest preview\\n\\nreleases by using nightly build mcr.microsoft.co\", \"m/dotnet/nightly/*\\n\\n17 CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers\\nCH\", \"APTER\\n\\nArcnitecting container and\\nmicroservice-based\\napplications\\n\\nMicroservices offer great benefit\", \"s but also raise huge new challenges. Microservice architecture patterns\\nare fundamental pillars whe\", \"n creating a microservice-based application.\\n\\nEarlier in this guide, you learned basic concepts abou\", \"t containers and Docker. That information was\\nthe minimum you needed to get started with containers.\", \" Even though containers are enablers of, and\\na great fit for microservices, they aren't mandatory fo\", \"r a microservice architecture. Many architectural\\nconcepts in this architecture section could be app\", \"lied without containers. However, this guide focuses\\non the intersection of both due to the already \", \"introduced importance of containers.\\n\\nEnterprise applications can be complex and are often composed \", \"of multiple services instead of a\\nsingle service-based application. For those cases, you need to und\", \"erstand other architectural\\napproaches, such as the microservices and certain Domain-Driven Design (\", \"DDD) patterns plus\\ncontainer orchestration concepts. Note that this chapter describes not just micro\", \"services on\\ncontainers, but any containerized application, as well.\\n\\nContainer design principles\\n\\nIn\", \" the container model, a container image instance represents a single process. By defining a\\ncontaine\", \"r image as a process boundary, you can create primitives that can be used to scale or batch\\nthe proc\", \"ess.\\n\\nWhen you design a container image, you'll see an ENTRYPOINT definition in the Dockerfile. This\", \"\\ndefinition defines the process whose lifetime controls the lifetime of the container. When the proc\", \"ess\\ncompletes, the container lifecycle ends. Containers might represent long-running processes like \", \"web\\nservers, but can also represent short-lived processes like batch jobs, which formerly might have\", \" been\\nimplemented as Azure WebJobs.\\n\\nIf the process fails, the container ends, and the orchestrator \", \"takes over. If the orchestrator was\\nconfigured to keep five instances running and one fails, the orc\", \"hestrator will create another container\\ninstance to replace the failed process. In a batch job, the \", \"process is started with parameters. When the\\nprocess completes, the work is complete. This guidance \", \"drills-down on orchestrators, later on.\\n\\n18 CHAPTER 3 | Architecting container and microservice-base\", \"d applications\\nYou might find a scenario where you want multiple processes running in a single conta\", \"iner. For that\\nscenario, since there can be only one entry point per container, you could run a scri\", \"pt within the\\ncontainer that launches as many programs as needed. For example, you can use Superviso\", \"r or a\\nsimilar tool to take care of launching multiple processes inside a single container. However,\", \" even\\nthough you can find architectures that hold multiple processes per container, that approach is\", \"n't very\\ncommon.\\n\\nContainerizing monolithic applications\\n\\nYou might want to build a single, monolith\", \"ically deployed web application or service and deploy it as\\na container. The application itself migh\", \"t not be internally monolithic, but structured as several\\nlibraries, components, or even layers (app\", \"lication layer, domain layer, data-access layer, etc.).\\nExternally, however, it\\u2019s a single container\", \"\\u2014a single process, a single web application, or a single\\nservice.\\n\\nTo manage this model, you deploy \", \"a single container to represent the application. To increase\\ncapacity, you scale out, that is, just \", \"add more copies with a load balancer in front. The simplicity\\ncomes from managing a single deploymen\", \"t in a single container or VM.\\n\\nMonolithic Containerized application\\n\\nApp 1 = 1 Container A monolith\", \"ic application has\\nmost of its functionality within\\na single process/container that\\nis componentized\", \" with internal\\ni layers or libraries.\\nHost 1 [=]\\n(Server/VM)\\nHost 2 Scales out by cloning\\n(Server/VM\", \") [s ] the app/container on\\nmultiple servers/VMs\\nHost 3\\n(Server/VM) Ls]\\n\\nNeed to deploy Coarse-grain\", \"ed\\nthe full density of\\n\\napplication applications\\n\\nFigure 4-1. Example of the architecture of a conta\", \"inerized monolithic application\\n\\nYou can include multiple components, libraries, or internal layers \", \"in each container, as illustrated in\\nFigure 4-1. A monolithic containerized application has most of \", \"its functionality within a single\\ncontainer, with internal layers or libraries, and scales out by cl\", \"oning the container on multiple\\nservers/VMs. However, this monolithic pattern might conflict with th\", \"e container principle \\u201ca container\\ndoes one thing, and does it in one process\\u201d, but might be ok for \", \"some cases.\\n\\nThe downside of this approach becomes evident if the application grows, requiring it to\", \" scale. If the\\nentire application can scale, it isn\\u2019t really a problem. However, in most cases, just\", \" a few parts of the\\napplication are the choke points that require scaling, while other components ar\", \"e used less.\\n\\nFor example, in a typical e-commerce application, you likely need to scale the product\", \" information\\nsubsystem, because many more customers browse products than purchase them. More custome\", \"rs use\\n\\n19 CHAPTER 3 | Architecting container and microservice-based applications\\ntheir basket than \", \"use the payment pipeline. Fewer customers add comments or view their purchase\\nhistory. And you might\", \" have only a handful of employees that need to manage the content and\\nmarketing campaigns. If you sc\", \"ale the monolithic design, all the code for these different tasks is\\ndeployed multiple times and sca\", \"led at the same grade.\\n\\nThere are multiple ways to scale an application-horizontal duplication, spli\", \"tting different areas of the\\napplication, and partitioning similar business concepts or data. But, i\", \"n addition to the problem of\\nscaling all components, changes to a single component require complete \", \"retesting of the entire\\napplication, and a complete redeployment of all the instances.\\n\\nHowever, the\", \" monolithic approach is common, because the development of the application is initially\\neasier than \", \"for microservices approaches. Thus, many organizations develop using this architectural\\napproach. Wh\", \"ile some organizations have had good enough results, others are hitting limits. Many\\norganizations d\", \"esigned their applications using this model because tools and infrastructure made it\\ntoo difficult t\", \"o build service-oriented architectures (SOA) years ago, and they did not see the need-\\nuntil the app\", \"lication grew.\\n\\nFrom an infrastructure perspective, each server can run many applications within the\", \" same host and\\nhave an acceptable ratio of efficiency in resources usage, as shown in Figure 4-2.\\n\\nH\", \"ost running multiple apps/containers\\n\\nHost Te] App 1 I App 2\\n(Server/VM) App 3.\\n\\nFigure 4-2. Monolit\", \"hic approach: Host running multiple apps, each app running as a container\\n\\nMonolithic applications i\", \"n Microsoft Azure can be deployed using dedicated VMs for each instance.\\nAdditionally, using Azure v\", \"irtual machine scale sets, you can easily scale the VMs. Azure App Service\\ncan also run monolithic a\", \"pplications and easily scale instances without requiring you to manage the\\nVMs. Since 2016, Azure Ap\", \"p Services can run single instances of Docker containers as well, simplifying\\ndeployment.\\n\\nAs a QA e\", \"nvironment or a limited production environment, you can deploy multiple Docker host VMs\\nand balance \", \"them using the Azure balancer, as shown in Figure 4-3. This lets you manage scaling with\\na coarse-gr\", \"ain approach, because the whole application lives within a single container.\\n\\n20 CHAPTER 3 | Archite\", \"cting container and microservice-based applications\\nArchitecture in Docker infrastructure\\nfor monoli\", \"thic applications\\n\\nG@ Microsoft\\n> Azure\\nHost 1 (VM)\\nAor SS\\nBrowser or / Host 2 (VM)\\nClient app \\\\ ) O\", \"f Bae\\n\\nHost 3 (VM)\\nA or FY\\n\\nFigure 4-3. Example of multiple hosts scaling up a single container appl\", \"ication\\n\\nDeployment to the various hosts can be managed with traditional deployment techniques. Dock\", \"er\\nhosts can be managed with commands like docker run or docker-compose performed manually, or\\nthrou\", \"gh automation such as continuous delivery (CD) pipelines.\\n\\nDeploying a monolithic application as a c\", \"ontainer\\n\\nThere are benefits to using containers to manage monolithic application deployments. Scali\", \"ng\\ncontainer instances is far faster and easier than deploying additional VMs. Even if you use virtu\", \"al\\nmachine scale sets, VMs take time to start. When deployed as traditional application instances in\", \"stead\\nof containers, the configuration of the application is managed as part of the VM, which isn't \", \"ideal.\\n\\nDeploying updates as Docker images is far faster and network efficient. Docker images typica\", \"lly start\\nin seconds, which speeds rollouts. Tearing down a Docker image instance is as easy as issu\", \"ing a\\ndocker stop command, and typically completes in less than a second.\\n\\nBecause containers are im\", \"mutable by design, you never need to worry about corrupted VMs. In\\ncontrast, update scripts for a VM\", \" might forget to account for some specific configuration or file left on\\ndisk.\\n\\nWhile monolithic app\", \"lications can benefit from Docker, we're touching only on the benefits.\\nAdditional benefits of manag\", \"ing containers come from deploying with container orchestrators, which\\nmanage the various instances \", \"and lifecycle of each container instance. Breaking up the monolithic\\napplication into subsystems tha\", \"t can be scaled, developed, and deployed individually is your entry\\npoint into the realm of microser\", \"vices.\\n\\nPublishing a single-container-based application to Azure App Service\\n\\nWhether you want to ge\", \"t validation of a container deployed to Azure or when an application is simply\\na single-container ap\", \"plication, Azure App Service provides a great way to provide scalable single-\\ncontainer-based servic\", \"es. Using Azure App Service is simple. It provides great integration with Git to\\nmake it easy to tak\", \"e your code, build it in Visual Studio, and deploy it directly to Azure.\\n\\n21 CHAPTER 3 | Architectin\", \"g container and microservice-based applications\\n| Create new\\n\\nPublish Ci; Azure Container Registry\\n\\n\", \"Select existing or cre\\n\\nTarget DNS prefix\\n\\nSpecific target exploreacr\\n\\n; Subscription name\\nApp Servi\", \"ce\\n\\nContainer Registry\\nResource group\\n\\nAPI Management explore-net-6-rg (South Central US)\\n\\nSKU\\nStand\", \"ard\\n\\nRegistry location\\nWest US\\n\\nCancel\\n\\nFigure 4-4. Publishing a single-container application to Azu\", \"re App Service from Visual Studio 2022\\n\\nWithout Docker, if you needed other capabilities, frameworks\", \", or dependencies that aren't supported\\nin Azure App Service, you had to wait until the Azure team u\", \"pdated those dependencies in App\\nService. Or you had to switch to other services like Azure Cloud Se\", \"rvices or VMs, where you had\\nfurther control and you could install a required component or framework\", \" for your application.\\n\\nContainer support in Visual Studio 2017 and later gives you the ability to i\", \"nclude whatever you want\\nin your application environment, as shown in Figure 4-4. Since you're runni\", \"ng it in a container, if you\\nadd a dependency to your application, you can include the dependency in\", \" your Dockerfile or Docker\\nimage.\\n\\nAs also shown in Figure 4-4, the publish flow pushes an image thr\", \"ough a container registry. This can\\nbe the Azure Container Registry (a registry close to your deploy\", \"ments in Azure and secured by Azure\\nActive Directory groups and accounts), or any other Docker regis\", \"try, like Docker Hub or an on-\\npremises registry.\\n\\nIn most cases, you can think of a container as an\", \" instance of a process. A process doesn\\u2019t maintain\\npersistent state. While a container can write to \", \"its local storage, assuming that an instance will be\\naround indefinitely would be like assuming that\", \" a single location in memory will be durable. You\\nshould assume that container images, like processe\", \"s, have multiple instances or will eventually be\\nkilled. If they're managed with a container orchest\", \"rator, you should assume that they might get\\nmoved from one node or VM to another.\\n\\nThe following so\", \"lutions are used to manage data in Docker applications:\\nFrom the Docker host, as Docker Volumes:\\n\\n. \", \"Volumes are stored in an area of the host filesystem that's managed by Docker.\\n\\n. Bind mounts can ma\", \"p to any folder in the host filesystem, so access can't be controlled from\\nDocker process and can po\", \"se a security risk as a container could access sensitive OS folders.\\n\\n. tmpfs mounts are like virtua\", \"l folders that only exist in the host\\u2019s memory and are never\\nwritten to the filesystem.\\n\\nFrom remote\", \" storage:\\n\\n. Azure Storage, which provides geo-distributable storage, providing a good long-term\\nper\", \"sistence solution for containers.\\n\\n\\u00b0 Remote relational databases like Azure SQL Database or NoSQL da\", \"tabases like Azure Cosmos\\nDB, or cache services like Redis.\\n\\nFrom the Docker container:\\n\\n. Overlay F\", \"ile System. This Docker feature implements a copy-on-write task that stores\\nupdated information to t\", \"he root file system of the container. That information is \\u201con top\\u201d of\\nthe original image on which th\", \"e container is based. If the container is deleted from the\\nsystem, those changes are lost. Therefore\", \", while it\\u2019s possible to save the state of a container\\nwithin its local storage, designing a system \", \"around this would conflict with the premise of\\ncontainer design, which by default is stateless.\\n\\nHow\", \"ever, using Docker Volumes is now the preferred way to handle local data in Docker. If you need\\nmore\", \" information about storage in containers check on Docker storage drivers and About storage\\ndrivers.\\n\", \"\\nThe following provides more detail about these options:\\n\\nVolumes are directories mapped from the ho\", \"st OS to directories in containers. When code in the\\ncontainer has access to the directory, that acc\", \"ess is actually to a directory on the host OS. This\\ndirectory is not tied to the lifetime of the con\", \"tainer itself, and the directory is managed by Docker and\\nisolated from the core functionality of th\", \"e host machine. Thus, data volumes are designed to persist\\ndata independently of the life of the con\", \"tainer. If you delete a container or an image from the Docker\\nhost, the data persisted in the data v\", \"olume isn\\u2019t deleted.\\n\\nVolumes can be named or anonymous (the default). Named volumes are the evoluti\", \"on of Data\\nVolume Containers and make it easy to share data between containers. Volumes also support\", \"\\nvolume drivers that allow you to store data on remote hosts, among other options.\\n\\nBind mounts are \", \"available since a long time ago and allow the mapping of any folder to a mount\\npoint in a container.\", \" Bind mounts have more limitations than volumes and some important security\\nissues, SO volumes are t\", \"he recommended option.\\n\\n23 CHAPTER 3 | Architecting container and microservice-based applications\\ntm\", \"pfs mounts are basically virtual folders that live only in the host's memory and are never written t\", \"o\\nthe filesystem. They are fast and secure but use memory and are only meant for temporary, non-\\nper\", \"sistent data.\\n\\nAs shown in Figure 4-5, regular Docker volumes can be stored outside of the container\", \"s themselves\\nbut within the physical boundaries of the host server or VM. However, Docker containers\", \" can't access\\na volume from one host server or VM to another. In other words, with these volumes, it\", \" isn't possible\\nto manage data shared between containers that run on different Docker hosts, althoug\", \"h it could be\\nachieved with a volume driver that supports remote hosts.\\n\\nData Volume and Data Volume\", \" Container\\n\\nMicrosoft\\n2 Azure\\n\\nee Stateless\\n\\nData Stateless\\nVolume \\u2014 SQL DB\\ncontainer ow\\n\\nBrowser or\", \"\\nClient app\\n\\nrm Stateless Cosmos DB\\n*\\n= container S&S\\n\\nStateless\\n\\nData Volume Container |MmecaihScbu\", \"bbenl\\n\\nFigure 4-5. Volumes and external data sources for container-based applications\\n\\nVolumes can b\", \"e shared between containers, but only in the same host, unless you use a remote driver\\nthat supports\", \" remote hosts. In addition, when Docker containers are managed by an orchestrator,\\ncontainers might \", \"\\u201cmove\\u201d between hosts, depending on the optimizations performed by the cluster.\\nTherefore, it isn\\u2019t r\", \"ecommended that you use data volumes for business data. But they're a good\\nmechanism to work with tr\", \"ace files, temporal files, or similar that will not impact business data\\nconsistency.\\n\\nRemote data s\", \"ources and cache tools like Azure SQL Database, Azure Cosmos DB, or a remote cache\\nlike Redis can be\", \" used in containerized applications the same way they are used when developing\\nwithout containers. T\", \"his is a proven way to store business application data.\\n\\nAzure Storage. Business data usually will n\", \"eed to be placed in external resources or databases, like\\nAzure Storage. Azure Storage, in concrete,\", \" provides the following services in the cloud:\\n\\n. Blob storage stores unstructured object data. A bl\", \"ob can be any type of text or binary data,\\nsuch as document or media files (images, audio, and video\", \" files). Blob storage is also referred\\nto as Object storage.\\n\\n24 CHAPTER 3 | Architecting container \", \"and microservice-based applications\\n. File storage offers shared storage for legacy applications usi\", \"ng standard SMB protocol. Azure\\nvirtual machines and cloud services can share file data across appli\", \"cation components via\\nmounted shares. On-premises applications can access file data in a share via t\", \"he File service\\nREST API.\\n\\n. Table storage stores structured datasets. Table storage is a NoSQL key-\", \"attribute data store,\\nwhich allows rapid development and fast access to large quantities of data.\\n\\nR\", \"elational databases and NoSQL databases. There are many choices for external databases, from\\nrelatio\", \"nal databases like SQL Server, PostgreSQL, Oracle, or NoSQL databases like Azure Cosmos DB,\\nMongoDB,\", \" etc. These databases are not going to be explained as part of this guide since they are ina\\ncomplet\", \"ely different subject.\\n\\nService-oriented architecture\\n\\nService-oriented architecture (SOA) was an ov\", \"erused term and has meant different things to different\\npeople. But as a common denominator, SOA mea\", \"ns that you structure your application by\\ndecomposing it into multiple services (most commonly as HT\", \"TP services) that can be classified as\\ndifferent types like subsystems or tiers.\\n\\nThose services can\", \" now be deployed as Docker containers, which solves deployment issues, because\\nall the dependencies \", \"are included in the container image. However, when you need to scale up SOA\\napplications, you might \", \"have scalability and availability challenges if you're deploying based on single\\nDocker hosts. This \", \"is where Docker clustering software or an orchestrator can help you, as explained in\\nlater sections \", \"where deployment approaches for microservices are described.\\n\\nDocker containers are useful (but not \", \"required) for both traditional service-oriented architectures and\\nthe more advanced microservices ar\", \"chitectures.\\n\\nMicroservices derive from SOA, but SOA is different from microservices architecture. F\", \"eatures like\\nlarge central brokers, central orchestrators at the organization level, and the Enterpr\", \"ise Service Bus\\n(ESB) are typical in SOA. But in most cases, these are anti-patterns in the microser\", \"vice community. In\\nfact, some people argue that \\u201cThe microservice architecture is SOA done right.\\u201d\\n\\n\", \"This guide focuses on microservices, because a SOA approach is less prescriptive than the\\nrequiremen\", \"ts and techniques used in a microservice architecture. If you know how to build a\\nmicroservice-based\", \" application, you also know how to build a simpler service-oriented application.\\n\\nMicroservices arch\", \"itecture\\n\\nAs the name implies, a microservices architecture is an approach to building a server appl\", \"ication as a\\nset of small services. That means a microservices architecture is mainly oriented to th\", \"e back-end,\\nalthough the approach is also being used for the front end. Each service runs in its own\", \" process and\\ncommunicates with other processes using protocols such as HTTP/HTTPS, WebSockets, or AM\", \"QP.\\nEach microservice implements a specific end-to-end domain or business capability within a certai\", \"n\\ncontext boundary, and each must be developed autonomously and be deployable independently.\\nFinally\", \", each microservice should own its related domain data model and domain logic (sovereignty\\n\\n25 CHAPT\", \"ER 3 | Architecting container and microservice-based applications\\nand decentralized data management)\", \" and could be based on different data storage technologies\\n(SQL, NoSQL) and different programming la\", \"nguages.\\n\\nWhat size should a microservice be? When developing a microservice, size shouldn't be the \", \"important\\npoint. Instead, the important point should be to create loosely coupled services so you ha\", \"ve\\nautonomy of development, deployment, and scale, for each service. Of course, when identifying and\", \"\\ndesigning microservices, you should try to make them as small as possible as long as you don't have\", \"\\ntoo many direct dependencies with other microservices. More important than the size of the\\nmicroser\", \"vice is the internal cohesion it must have and its independence from other services.\\n\\nWhy a microser\", \"vices architecture? In short, it provides long-term agility. Microservices enable better\\nmaintainabi\", \"lity in complex, large, and highly-scalable systems by letting you create applications based\\non many\", \" independently deployable services that each have granular and autonomous lifecycles.\\n\\nAs an additio\", \"nal benefit, microservices can scale out independently. Instead of having a single\\nmonolithic applic\", \"ation that you must scale out as a unit, you can instead scale out specific\\nmicroservices. That way,\", \" you can scale just the functional area that needs more processing power or\\nnetwork bandwidth to sup\", \"port demand, rather than scaling out other areas of the application that\\ndon't need to be scaled. Th\", \"at means cost savings because you need less hardware.\\n\\nMonolithic deployment approach Microservices \", \"application approach\\n\\n* A traditional application has\\nmost of its functionality within a\\nfew process\", \"es that are\\ncomponentized with layers and\\nlibraries.\\n\\n* Scales by cloning the app on\\nmultiple server\", \"s/VMs\\n\\nApp 1 \\u00b0\\n\\nCoarse-grained\\ndensity of\\n\\napps/services\\n\\nNeed to deploy\\nthe full\\n\\napplication\\n\\n[e]\\n\", \"\\n_\\u2014\\n\\nA microservice application\\n\\nsegregates functionality into _ \\\\\\nseparate smaller services. @\\nScal\", \"es out by deploying each\\nservice independently with\\n\\nmultiple instances across\\n\\nae eee ee\\n\\na\\n\\nserver\", \"s/VMs\\n\\nIndependent\\ndeployment of\\n\\nmicroservice\\n\\nFine-grained\\ndensity of\\n\\nservices\\n\\n)\\n\\u201cee\\n\\nFigure 4-6\", \". Monolithic deployment versus the microservices approach\\n\\nAs Figure 4-6 shows, in the traditional m\", \"onolithic approach, the application scales by cloning the\\nwhole app in several servers/VM. In the mi\", \"croservices approach, functionality is segregated in smaller\\nservices, So each service can scale ind\", \"ependently. The microservices approach allows agile changes\\n\\nand rapid iteration of each microservic\", \"e, because you can change specific, small areas of complex,\\n\\nlarge, and scalable applications.\\n\\nArch\", \"itecting fine-grained microservices-based applications enables continuous integration and\\n\\ncontinuou\", \"s delivery practices. It also accelerates delivery of new functions into the application. Fine-\\ngrai\", \"ned composition of applications also allows you to run and test microservices in isolation, and to\\n\\n\", \"26\\n\\nCHAPTER 3 | Architecting container and microservice-based applications\\nevolve them autonomously \", \"while maintaining clear contracts between them. As long as you don't\\nchange the interfaces or contra\", \"cts, you can change the internal implementation of any microservice or\\nadd new functionality without\", \" breaking other microservices.\\n\\nThe following are important aspects to enable success in going into \", \"production with a microservices-\\nbased system:\\n\\n. Monitoring and health checks of the services and i\", \"nfrastructure.\\n\\u00b0 Scalable infrastructure for the services (that is, cloud and orchestrators).\\n\\n. Sec\", \"urity design and implementation at multiple levels: authentication, authorization, secrets\\nmanagemen\", \"t, secure communication, etc.\\n\\n. Rapid application delivery, usually with different teams focusing o\", \"n different microservices.\\n. DevOps and CI/CD practices and infrastructure.\\n\\nOf these, only the firs\", \"t three are covered or introduced in this guide. The last two points, which are\\nrelated to applicati\", \"on lifecycle, are covered in the additional Containerized Docker Application\\n\\nLifecycle with Microso\", \"ft Platform and Tools e-book.\\n\\nAdditional resources\\n\\n. Mark Russinovich. Microservices: An applicati\", \"on revolution powered by the cloud\\nhttos://azure.microsoft.com/blog/microservices-an-application-rev\", \"olution-powered-by-the-\\n\\n\\u00b0 Martin Fowler. Microservices\\nhttps://www.martinfowler.com/articles/micros\", \"ervices.html\\n. Martin Fowler. Microservice Prerequisites\\n\\nhttps://martinfowler.com/bliki/Microservic\", \"ePrerequisites.html\\n\\n\\u00b0 Jimmy Nilsson. Chunk Cloud Computing\\n\\nhttps://www.infog.com/articles/CCC-Jimm\", \"y-Nilsson\\n\\n. Cesar de la Torre. Containerized Docker Application Lifecycle with Microsoft Platform\\na\", \"nd Tools (downloadable e-book)\\n\\nhttps://aka.ms/dockerlifecycleebook\\n\\nData sovereignty per microservi\", \"ce\\n\\nAn important rule for microservices architecture is that each microservice must own Its domain d\", \"ata\\nand logic. Just as a full application owns its logic and data, so must each microservice own its\", \" logic\\nand data under an autonomous lifecycle, with independent deployment per microservice.\\n\\nThis m\", \"eans that the conceptual model of the domain will differ between subsystems or microservices.\\nConsid\", \"er enterprise applications, where customer relationship management (CRM) applications,\\n\\n27 CHAPTER 3\", \" | Architecting container and microservice-based applications\\ntransactional purchase subsystems, and\", \" customer support subsystems each call on unique customer\\nentity attributes and data, and where each\", \" employs a different Bounded Context (BC).\\n\\nThis principle is similar in Domain-driven design (DDD),\", \" where each Bounded Context or autonomous\\nsubsystem or service must own Its domain model (data plus \", \"logic and behavior). Each DDD Bounded\\nContext correlates to one business microservice (one or severa\", \"l services). This point about the\\nBounded Context pattern is expanded in the next section.\\n\\nOn the o\", \"ther hand, the traditional (monolithic data) approach used in many applications is to have a\\nsingle \", \"centralized database or just a few databases. This is often a normalized SQL database that\\u2019s\\nused fo\", \"r the whole application and all its internal subsystems, as shown in Figure 4-7.\\n\\nData in Traditiona\", \"l approach Data in Microservices approach\\n* Single monolithic database * Graph of interconnected mic\", \"roservices\\n* Tiers of specific technologies * State typically scoped to the microservice\\n\\n\\u00a2 Remote S\", \"torage for cold data\\n\\nWeb Tier\\nServices Tier\\nWeb presentation\\nservices\\nCache Tier\\n\\\\\\n| Stateless\\n| se\", \"rvices\\n|\\n| Stateful\\nData Tier services\\n|\\n\\nStateless services\\nwith\\nseparate store\\n\\nFigure 4-7. Data s\", \"overeignty comparison: monolithic database versus microservices\\n\\nIn the traditional approach, there\\u2019\", \"s a single database shared across all services, typically in a tiered\\narchitecture. In the microserv\", \"ices approach, each microservice owns its model/data. The centralized\\ndatabase approach initially lo\", \"oks simpler and seems to enable reuse of entities in different subsystems\\nto make everything consist\", \"ent. But the reality is you end up with huge tables that serve many different\\nsubsystems, and that i\", \"nclude attributes and columns that aren't needed in most cases. It\\u2019s like trying\\nto use the same phy\", \"sical map for hiking a short trail, taking a day-long car trip, and learning\\ngeography.\\n\\nA monolithi\", \"c application with typically a single relational database has two important benefits: ACID\\ntransacti\", \"ons and the SQL language, both working across all the tables and data related to your\\napplication. T\", \"his approach provides a way to easily write a query that combines data from multiple\\ntables.\\n\\nHoweve\", \"r, data access becomes much more complicated when you move to a microservices\\narchitecture. Even whe\", \"n using ACID transactions within a microservice or Bounded Context, it is crucial\\nto consider that t\", \"he data owned by each microservice is private to that microservice and should only\\n\\n28 CHAPTER 3 | A\", \"rchitecting container and microservice-based applications\\nbe accessed either synchronously through i\", \"ts API endpoints(REST, gRPC, SOAP, etc) or asynchronously\\nvia messaging(AMQP or similar).\\n\\nEncapsula\", \"ting the data ensures that the microservices are loosely coupled and can evolve\\nindependently of one\", \" another. If multiple services were accessing the same data, schema updates\\nwould require coordinate\", \"d updates to all the services. This would break the microservice lifecycle\\nautonomy. But distributed\", \" data structures mean that you can\\u2019t make a single ACID transaction across\\nmicroservices. This in tu\", \"rn means you must use eventual consistency when a business process spans\\nmultiple microservices. Thi\", \"s is much harder to implement than simple SQL joins, because you can't\\ncreate integrity constraints \", \"or use distributed transactions between separate databases, as we'll\\nexplain later on. Similarly, ma\", \"ny other relational database features aren't available across multiple\\nmicroservices.\\n\\nGoing even fu\", \"rther, different microservices often use different kinds of databases. Modern\\napplications store and\", \" process diverse kinds of data, and a relational database isn't always the best\\nchoice. For some use\", \" cases, a NoOSQL database such as Azure CosmosDB or MongoDB might have a\\nmore convenient data model \", \"and offer better performance and scalability than a SQL database like\\nSQL Server or Azure SQL Databa\", \"se. In other cases, a relational database is still the best approach.\\nTherefore, microservices-based\", \" applications often use a mixture of SQL and NoSQL databases, which\\nis sometimes called the polyglot\", \" persistence approach.\\n\\nA partitioned, polyglot-persistent architecture for data storage has many be\", \"nefits. These include\\nloosely coupled services and better performance, scalability, costs, and manag\", \"eability. However, it can\\nintroduce some distributed data management challenges, as explained in \\u201cId\", \"entifying domain-model\\nboundaries\\u201d later in this chapter.\\n\\nThe relationship between microservices an\", \"d the Bounded Context\\npattern\\n\\nThe concept of microservice derives from the Bounded Context (BC) pat\", \"tern in domain-driven design\\n(DDD). DDD deals with large models by dividing them into multiple BCs a\", \"nd being explicit about their\\n\\nboundaries. Each BC must have its own model and database; likewise, e\", \"ach microservice owns its\\nrelated data. In addition, each BC usually has its own ubiquitous language\", \" to help communication\\nbetween software developers and domain experts.\\n\\nThose terms (mainly domain e\", \"ntities) in the ubiquitous language can have different names in different\\nBounded Contexts, even whe\", \"n different domain entities share the same identity (that is, the unique ID\\nthat's used to read the \", \"entity from storage). For instance, in a user-profile Bounded Context, the User\\n\\ndomain entity might\", \" share identity with the Buyer domain entity in the ordering Bounded Context.\\n\\nA microservice is the\", \"refore like a Bounded Context, but it also specifies that it's a distributed service.\\nIt's built as \", \"a separate process for each Bounded Context, and it must use the distributed protocols\\nnoted earlier\", \", like HTTP/HTTPS, WebSockets, or AMQP. The Bounded Context pattern, however,\\ndoesn't specify whethe\", \"r the Bounded Context Is a distributed service or if it's simply a logical\\nboundary (such as a gener\", \"ic subsystem) within a monolithic-deployment application.\\n\\nIt's important to highlight that defining\", \" a service for each Bounded Context is a good place to start.\\nBut you don't have to constrain your d\", \"esign to it. Sometimes you must design a Bounded Context or\\n\\n29 CHAPTER 3 | Architecting container a\", \"nd microservice-based applications\\nbusiness microservice composed of several physical services. But \", \"ultimately, both patterns -Bounded\\nContext and microservice- are closely related.\\n\\nDDD benefits from\", \" microservices by getting real boundaries in the form of distributed microservices.\\nBut ideas like n\", \"ot sharing the model between microservices are what you also want in a Bounded\\nContext.\\n\\nAdditional \", \"resources\\n\\n. Chris Richardson. Pattern: Database per service\\n\\nhttps://microservices.io/patterns/data\", \"/database-per-service.html\\n\\n\\u00b0 Martin Fowler. BoundedContext\\nhttps://martinfowler.com/bliki/BoundedCo\", \"ntext.html\\n. Martin Fowler. PolyglotPersistence\\n\\nhttps://martinfowler.com/bliki/PolyglotPersistence.\", \"html\\n\\n\\u00b0 Alberto Brandolini. Strategic Domain Driven Design with Context Mapping\\n\\nhttps://www.infog.c\", \"om/articles/ddd-contextmapping\\n\\nLogical architecture versus physical architecture\\n\\nIt's useful at th\", \"is point to stop and discuss the distinction between logical architecture and physical\\narchitecture,\", \" and how this applies to the design of microservice-based applications.\\n\\nTo begin, building microser\", \"vices doesn\\u2019t require the use of any specific technology. For instance,\\nDocker containers aren't man\", \"datory to create a microservice-based architecture. Those microservices\\ncould also be run as plain p\", \"rocesses. Microservices is a logical architecture.\\n\\nMoreover, even when a microservice could be phys\", \"ically implemented as a single service, process, or\\ncontainer (for simplicity\\u2019s sake, that's the app\", \"roach taken in the initial version of eShopOnContainers),\\nthis parity between business microservice \", \"and physical service or container isn't necessarily required in\\nall cases when you build a large and\", \" complex application composed of many dozens or even\\nhundreds of services.\\n\\nThis is where there's a \", \"difference between an application's logical architecture and physical\\narchitecture. The logical arch\", \"itecture and logical boundaries of a system do not necessarily map one-\\nto-one to the physical or de\", \"ployment architecture. It can happen, but it often doesn't.\\n\\nAlthough you might have identified cert\", \"ain business microservices or Bounded Contexts, it doesn't\\nmean that the best way to implement them \", \"Is always by creating a single service (such as an ASP.NET\\nWeb API) or single Docker container for e\", \"ach business microservice. Having a rule saying each\\nbusiness microservice has to be implemented usi\", \"ng a single service or container is too rigid.\\n\\nTherefore, a business microservice or Bounded Contex\", \"t is a logical architecture that might coincide (or\\nnot) with physical architecture. The important p\", \"oint is that a business microservice or Bounded\\nContext must be autonomous by allowing code and stat\", \"e to be independently versioned, deployed,\\nand scaled.\\n\\n30 CHAPTER 3 | Architecting container and mi\", \"croservice-based applications\\nAs Figure 4-8 shows, the catalog business microservice could be compos\", \"ed of several services or\\nprocesses. These could be multiple ASP.NET Web API services or any other k\", \"ind of services using\\nHTTP or any other protocol. More importantly, the services could share the sam\", \"e data, as long as\\nthese services are cohesive with respect to the same business domain.\\n\\na Pen ee e\", \"s Se .\\n, Catalog business microservice \\\\\\n| Web AP )\\n|\\n| Caryice\\n| Service Ne SQLServer |\\n|\\n) databas\", \"e )\\n| |\\n|\\n)\\noe ee _\\u201d\\n\\nFigure 4-8. Business microservice with several physical services\\n\\nThe services\", \" in the example share the same data model because the Web API service targets the same\\ndata as the S\", \"earch service. So, in the physical implementation of the business microservice, you're\\nsplitting tha\", \"t functionality so you can scale each of those internal services up or down as needed.\\nMaybe the Web\", \" API service usually needs more instances than the Search service, or vice versa.\\n\\nIn short, the log\", \"ical architecture of microservices doesn't always have to coincide with the physical\\ndeployment arch\", \"itecture. In this guide, whenever we mention a microservice, we mean a business or\\nlogical microserv\", \"ice that could map to one or more (physical) services. In most cases, this will be a\\nsingle service,\", \" but it might be more.\\n\\nChallenges and solutions for distributed data\\nManagement\\n\\nChallenge #1: How \", \"to define the boundaries of each microservice\\n\\nDefining microservice boundaries is probably the firs\", \"t challenge anyone encounters. Each microservice\\nhas to be a piece of your application and each micr\", \"oservice should be autonomous with all the\\nbenefits and challenges that it conveys. But how do you i\", \"dentify those boundaries?\\n\\nFirst, you need to focus on the application's logical domain models and r\", \"elated data. Try to identify\\ndecoupled islands of data and different contexts within the same applic\", \"ation. Each context could have\\na different business language (different business terms). The context\", \"s should be defined and managed\\nindependently. The terms and entities that are used in those differe\", \"nt contexts might sound similar,\\nbut you might discover that in a particular context, a business con\", \"cept with one is used for a different\\n\\n31 CHAPTER 3 | Architecting container and microservice-based \", \"applications\\npurpose in another context, and might even have a different name. For instance, a user \", \"can be\\nreferred as a user in the identity or membership context, as a customer in a CRM context, as \", \"a buyer in\\nan ordering context, and so forth.\\n\\nThe way you identify boundaries between multiple appl\", \"ication contexts with a different domain for\\neach context Is exactly how you can identify the bounda\", \"ries for each business microservice and its\\nrelated domain model and data. You always attempt to min\", \"imize the coupling between those\\nmicroservices. This guide goes into more detail about this identifi\", \"cation and domain model design in\\n\\nthe section Identifying domain-model boundaries for each microser\", \"vice later.\\n\\nChallenge #2: How to create queries that retrieve data from several\\nmicroservices\\n\\nA se\", \"cond challenge is how to implement queries that retrieve data from several microservices, while\\navoi\", \"ding chatty communication to the microservices from remote client apps. An example could be a\\nsingle\", \" screen from a mobile app that needs to show user information that\\u2019s owned by the basket,\\ncatalog, a\", \"nd user identity microservices. Another example would be a complex report involving many\\ntables loca\", \"ted in multiple microservices. The right solution depends on the complexity of the queries.\\nBut in a\", \"ny case, you'll need a way to aggregate information if you want to improve the efficiency in\\nthe com\", \"munications of your system. The most popular solutions are the following.\\n\\nAPI Gateway. For simple d\", \"ata aggregation from multiple microservices that own different databases,\\nthe recommended approach i\", \"s an aggregation microservice referred to as an API Gateway. However,\\nyou need to be careful about i\", \"mplementing this pattern, because it can be a choke point in your\\nsystem, and it can violate the pri\", \"nciple of microservice autonomy. To mitigate this possibility, you can\\nhave multiple fined-grained A\", \"PI Gateways each one focusing on a vertical \\u201cslice\\u201d or business area of\\nthe system. The API Gateway \", \"pattern is explained in more detail in the API Gateway section later.\\n\\nGraphQL Federation One option\", \" to consider if your microservices are already using GraphQL is\\nGraphQL Federation. Federation allow\", \"s you to define \\u201csubgraphs\\u201d from other services and compose\\nthem into an aggregate \\u201csupergraph\\u201d that\", \" acts as a standalone schema.\\n\\nCQRS with query/reads tables. Another solution for aggregating data f\", \"rom multiple microservices is\\nthe Materialized View pattern. In this approach, you generate, in adva\", \"nce (prepare denormalized data\\nbefore the actual queries happen), a read-only table with the data th\", \"at\\u2019s owned by multiple\\nmicroservices. The table has a format suited to the client app\\u2019s needs.\\n\\nCons\", \"ider something like the screen for a mobile app. If you have a single database, you might pull\\ntoget\", \"her the data for that screen using a SQL query that performs a complex join involving multiple\\ntable\", \"s. However, when you have multiple databases, and each database is owned by a different\\nmicroservice\", \", you cannot query those databases and create a SQL join. Your complex query becomes\\na challenge. Yo\", \"u can address the requirement using a CQRS approach\\u2014you create a denormalized\\ntable in a different d\", \"atabase that\\u2019s used just for queries. The table can be designed specifically for the\\ndata you need f\", \"or the complex query, with a one-to-one relationship between fields needed by your\\napplication's scr\", \"een and the columns in the query table. It could also serve for reporting purposes.\\n\\nThis approach n\", \"ot only solves the original problem (how to query and join across microservices), but it\\nalso improv\", \"es performance considerably when compared with a complex join, because you already\\n\\n32 CHAPTER 3 | A\", \"rchitecting container and microservice-based applications\\nhave the data that the application needs i\", \"n the query table. Of course, using Command and Query\\nResponsibility Segregation (CQRS) with query/r\", \"eads tables means additional development work, and\\nyou'll need to embrace eventual consistency. None\", \"theless, requirements on performance and high\\nscalability in collaborative scenarios (or competitive\", \" scenarios, depending on the point of view) are\\nwhere you should apply CQRS with multiple databases.\", \"\\n\\n\\u201cCold data\\u201d in central databases. For complex reports and queries that might not require real-time\", \"\\ndata, a common approach is to export your \\u201chot data\\u201d (transactional data from the microservices) as\", \"\\n\\u201ccold data\\u201d into large databases that are used only for reporting. That central database system can\", \" be\\na Big Data-based system, like Hadoop; a data warehouse like one based on Azure SQL Data\\nWarehous\", \"e; or even a single SQL database that\\u2019s used just for reports (if size won't be an issue).\\n\\nKeep in \", \"mind that this centralized database would be used only for queries and reports that do not\\nneed real\", \"-time data. The original updates and transactions, as your source of truth, have to be in your\\nmicro\", \"services data. The way you would synchronize data would be either by using event-driven\\ncommunicatio\", \"n (covered in the next sections) or by using other database infrastructure import/export\\ntools. If y\", \"ou use event-driven communication, that integration process would be similar to the way\\nyou propagat\", \"e data as described earlier for CQRS query tables.\\n\\nHowever, if your application design involves con\", \"stantly aggregating information from multiple\\nmicroservices for complex queries, it might be a sympt\", \"om of a bad design -a microservice should be\\nas isolated as possible from other microservices. (This\", \" excludes reports/analytics that always should\\nuse cold-data central databases.) Having this problem\", \" often might be a reason to merge\\nmicroservices. You need to balance the autonomy of evolution and d\", \"eployment of each microservice\\nwith strong dependencies, cohesion, and data aggregation.\\n\\nChallenge \", \"#3: How to achieve consistency across multiple\\nmicroservices\\n\\nAs stated previously, the data owned b\", \"y each microservice is private to that microservice and can only\\nbe accessed using its microservice \", \"API. Therefore, a challenge presented is how to implement end-to-\\nend business processes while keepi\", \"ng consistency across multiple microservices.\\n\\nTo analyze this problem, let\\u2019s look at an example fro\", \"m the eShopOnContainers reference application.\\nThe Catalog microservice maintains information about \", \"all the products, including the product price.\\nThe Basket microservice manages temporal data about p\", \"roduct items that users are adding to their\\nshopping baskets, which includes the price of the items \", \"at the time they were added to the basket.\\nWhen a product's price is updated in the catalog, that pr\", \"ice should also be updated in the active\\nbaskets that hold that same product, plus the system should\", \" probably warn the user saying that a\\nparticular item's price has changed since they added it to the\", \"ir basket.\\n\\nIn a hypothetical monolithic version of this application, when the price changes in the \", \"products table,\\nthe catalog subsystem could simply use an ACID transaction to update the current pri\", \"ce in the Basket\\ntable.\\n\\nHowever, in a microservices-based application, the Product and Basket table\", \"s are owned by their\\nrespective microservices. No microservice should ever include tables/storage ow\", \"ned by another\\nmicroservice in its own transactions, not even in direct queries, as shown in Figure \", \"4-9.\\n\\n33 CHAPTER 3 | Architecting container and microservice-based applications\\nCatalog Basket\\n\\nmicr\", \"oservice microservice\\npO ~~. Eventual 9,270\\n\\n\\u2014\\n\\u2018 \\u00a5 %\\nonsistency / \\\\\\n\\niD ProdPrice | ProdName\\n\\nProduc\", \"t table Basket table\\n\\\\ in Catalog DB / \\\\ in Basket DB /\\n\\neee ee\\n\\nel el\\n\\nDatabases are private per mi\", \"croservice\\n\\nFigure 4-9. A microservice can't directly access a table in another microservice\\n\\nThe Ca\", \"talog microservice shouldn't update the Basket table directly, because the Basket table is\\nowned by \", \"the Basket microservice. To make an update to the Basket microservice, the Catalog\\nmicroservice shou\", \"ld use eventual consistency probably based on asynchronous communication such\\nas integration events \", \"(message and event-based communication). This is how the eSshopOnContainers\\nreference application pe\", \"rforms this type of consistency across microservices.\\n\\nAs stated by the CAP theorem, you need to cho\", \"ose between availability and ACID strong consistency.\\n\\nMost microservice-based scenarios demand avai\", \"lability and high scalability as opposed to strong\\nconsistency. Mission-critical applications must r\", \"emain up and running, and developers can work\\naround strong consistency by using techniques for work\", \"ing with weak or eventual consistency. This is\\nthe approach taken by most microservice-based archite\", \"ctures.\\n\\nMoreover, ACID-style or two-phase commit transactions are not just against microservices pr\", \"inciples;\\nmost NoSQL databases (like Azure Cosmos DB, MongoDB, etc.) do not support two-phase commit\", \"\\ntransactions, typical in distributed databases scenarios. However, maintaining data consistency acr\", \"oss\\nservices and databases is essential. This challenge is also related to the question of how to pr\", \"opagate\\nchanges across multiple microservices when certain data needs to be redundant\\u2014for example, w\", \"hen\\nyou need to have the product's name or description in the Catalog microservice and the Basket\\nmi\", \"croservice.\\n\\nA good solution for this problem is to use eventual consistency between microservices a\", \"rticulated\\nthrough event-driven communication and a publish-and-subscribe system. These topics are c\", \"overed\\n\\nin the section Asynchronous event-driven communication later in this guide.\\n\\n34 CHAPTER 3 | \", \"Architecting container and microservice-based applications\\nChallenge #4: How to design communication\", \" across microservice\\nboundaries\\n\\nCommunicating across microservice boundaries Is a real challenge. I\", \"n this context, communication\\ndoesn't refer to what protocol you should use (HTTP and REST, AMQP, me\", \"ssaging, and so on). Instead,\\nit addresses what communication style you should use, and especially h\", \"ow coupled your\\nmicroservices should be. Depending on the level of coupling, when failure occurs, th\", \"e impact of that\\nfailure on your system will vary significantly.\\n\\nIn a distributed system like a mic\", \"roservices-based application, with so many artifacts moving around\\nand with distributed services acr\", \"oss many servers or hosts, components will eventually fail. Partial\\nfailure and even larger outages \", \"will occur, so you need to design your microservices and the\\ncommunication across them considering t\", \"he common risks in this type of distributed system.\\n\\nA popular approach is to implement HTTP (REST)-\", \"based microservices, due to their simplicity. An\\nHTTP-based approach is perfectly acceptable; the is\", \"sue here is related to how you use it. If you use\\nHTTP requests and responses just to interact with \", \"your microservices from client applications or from\\nAPI Gateways, that\\u2019s fine. But if you create lon\", \"g chains of synchronous HTTP calls across microservices,\\ncommunicating across their boundaries as if\", \" the microservices were objects in a monolithic\\napplication, your application will eventually run in\", \"to problems.\\n\\nFor instance, imagine that your client application makes an HTTP API call to an indivi\", \"dual microservice\\nlike the Ordering microservice. If the Ordering microservice in turn calls additio\", \"nal microservices using\\nHTTP within the same request/response cycle, you're creating a chain of HTTP\", \" calls. It might sound\\nreasonable initially. However, there are important points to consider when go\", \"ing down this path:\\n\\n. Blocking and low performance. Due to the synchronous nature of HTTP, the orig\", \"inal request\\ndoesn't get a response until all the internal HTTP calls are finished. Imagine if the n\", \"umber of\\nthese calls increases significantly and at the same time one of the intermediate HTTP calls\", \" to a\\nmicroservice is blocked. The result is that performance is impacted, and the overall scalabili\", \"ty\\nwill be exponentially affected as additional HTTP requests increase.\\n\\n. Coupling microservices wi\", \"th HTTP. Business microservices shouldn't be coupled with other\\nbusiness microservices. Ideally, the\", \"y shouldn't \\u201cknow\\u201d about the existence of other\\nmicroservices. If your application relies on couplin\", \"g microservices as in the example, achieving\\nautonomy per microservice will be almost impossible.\\n\\n\\u00b0\", \" Failure in any one microservice. If you implemented a chain of microservices linked by HTTP\\ncalls, \", \"when any of the microservices fails (and eventually they will fail) the whole chain of\\nmicroservices\", \" will fail. A microservice-based system should be designed to continue to work\\nas well as possible d\", \"uring partial failures. Even if you implement client logic that uses retries\\nwith exponential backof\", \"f or circuit breaker mechanisms, the more complex the HTTP call\\nchains are, the more complex it is t\", \"o implement a failure strategy based on HTTP.\\n\\nIn fact, if your internal microservices are communica\", \"ting by creating chains of HTTP requests as\\ndescribed, it could be argued that you have a monolithic\", \" application, but one based on HTTP between\\nprocesses instead of intra-process communication mechani\", \"sms.\\n\\n35 CHAPTER 3 | Architecting container and microservice-based applications\\nTherefore, in order \", \"to enforce microservice autonomy and have better resiliency, you should minimize\\nthe use of chains o\", \"f request/response communication across microservices. It's recommended that\\nyou use only asynchrono\", \"us interaction for inter-microservice communication, either by using\\nasynchronous message- and event\", \"-based communication, or by using (asynchronous) HTTP polling\\nindependently of the original HTTP req\", \"uest/response cycle.\\n\\nThe use of asynchronous communication is explained with additional details lat\", \"er in this guide in the\\n\\nsections Asynchronous microservice integration enforces microservice\\u2019s auto\", \"nomy and Asynchronous\\nmessage-based communication.\\n\\nAdditional resources\\n\\n\\u00b0 CAP theorem\\nhttps://en.w\", \"ikipedia.org/wiki/CAP theorem\\n\\n. Eventual consistency\\nhttps://en.wikipedia.org/wiki/Eventual_ consis\", \"tency\\n\\u00b0 Data Consistency Primer\\n\\nhttos://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v=pa\", \"ndp.10\\n\\n. Martin Fowler. CQRS (Command and Query Responsibility Segregation)\\nhttps://martinfowler.co\", \"m/bliki/CQRS.html\\n\\n\\u00b0 Materialized View\\n\\nhttps://learn.microsoft.com/azure/architecture/patterns/mate\", \"rialized-view\\n\\n. Charles Row. ACID vs. BASE: The Shifting pH of Database Transaction Processing\\nhtto\", \"s://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-\\n\\nprocessing/\\n\\n. Compen\", \"sating Transaction\\n\\nhttps://learn.microsoft.com/azure/architecture/patterns/compensating-transaction\", \"\\n\\n\\u00b0 Udi Dahan. Service Oriented Composition\\n\\nhttps://udidahan.com/2014/07/30/service-oriented-compos\", \"ition-with-video\\n\\nIdentify domain-model boundaries for each\\nmicroservice\\n\\nThe goal when identifying \", \"model boundaries and size for each microservice isn't to get to the most\\ngranular separation possibl\", \"e, although you should tend toward small microservices if possible.\\nInstead, your goal should be to \", \"get to the most meaningful separation guided by your domain\\nknowledge. The emphasis isn't on the siz\", \"e, but instead on business capabilities. In addition, if there's\\nclear cohesion needed for a certain\", \" area of the application based on a high number of dependencies,\\nthat indicates the need for a singl\", \"e microservice, too. Cohesion is a way to identify how to break apart\\n\\n36 CHAPTER 3 | Architecting c\", \"ontainer and microservice-based applications\\nor group together microservices. Ultimately, while you \", \"gain more knowledge about the domain, you\\nshould adapt the size of your microservice, iteratively. F\", \"inding the right size isn\\u2019t a one-shot process.\\n\\nSam Newman, a recognized promoter of microservices \", \"and author of the book Building Microservices,\\nhighlights that you should design your microservices \", \"based on the Bounded Context (BC) pattern\\n(part of domain-driven design), as introduced earlier. Som\", \"etimes, a BC could be composed of several\\n\\nphysical services, but not vice versa.\\n\\nA domain model wi\", \"th specific domain entities applies within a concrete BC or microservice. A BC\\ndelimits the applicab\", \"ility of a domain model and gives developer team members a clear and shared\\nunderstanding of what mu\", \"st be cohesive and what can be developed independently. These are the\\nsame goals for microservices.\\n\", \"\\nAnother tool that informs your design choice is Conway's law, which states that an application will\", \"\\nreflect the social boundaries of the organization that produced it. But sometimes the opposite is t\", \"rue -\\nthe company\\u2019s organization is formed by the software. You might need to reverse Conway's law a\", \"nd\\nbuild the boundaries the way you want the company to be organized, leaning toward business\\nproces\", \"s consulting.\\n\\nTo identify bounded contexts, you can use a DDD pattern called the Context Mapping pa\", \"ttern. With\\nContext Mapping, you identify the various contexts in the application and their boundari\", \"es. It's\\ncommon to have a different context and boundary for each small subsystem, for instance. The\", \" Context\\nMap is a way to define and make explicit those boundaries between domains. A BC is autonomo\", \"us\\nand includes the details of a single domain -details like the domain entities- and defines integr\", \"ation\\ncontracts with other BCs. This is similar to the definition of a microservice: it\\u2019s autonomous\", \", it\\nimplements certain domain capability, and it must provide interfaces. This is why Context Mappi\", \"ng\\nand the Bounded Context pattern are good approaches for identifying the domain model boundaries\\no\", \"f your microservices.\\n\\nWhen designing a large application, you'll see how its domain model can be fr\", \"agmented - a domain\\nexpert from the catalog domain will name entities differently in the catalog and\", \" inventory domains\\nthan a shipping domain expert, for instance. Or the user domain entity might be d\", \"ifferent in size and\\nnumber of attributes when dealing with a CRM expert who wants to store every de\", \"tail about the\\ncustomer than for an ordering domain expert who just needs partial data about the cus\", \"tomer. It\\u2019s very\\nhard to disambiguate all domain terms across all the domains related to a large app\", \"lication. But the\\nmost important thing is that you shouldn't try to unify the terms. Instead, accept\", \" the differences and\\nrichness provided by each domain. If you try to have a unified database for the\", \" whole application,\\nattempts at a unified vocabulary will be awkward and won't sound right to any of\", \" the multiple domain\\nexperts. Therefore, BCs (implemented as microservices) will help you to clarify\", \" where you can use\\ncertain domain terms and where you'll need to split the system and create additio\", \"nal BCs with\\ndifferent domains.\\n\\nYou'll know that you got the right boundaries and sizes of each BC \", \"and domain model if you have few\\nstrong relationships between domain models, and you do not usually \", \"need to merge information\\nfrom multiple domain models when performing typical application operations\", \".\\n\\nPerhaps the best answer to the question of how large a domain model for each microservice should\\n\", \"be is the following: it should have an autonomous BC, as isolated as possible, that enables you to\\nw\", \"ork without having to constantly switch to other contexts (other microservice\\u2019s models). In Figure 4\", \"-\\n\\n37 CHAPTER 3 | Architecting container and microservice-based applications\\n10, you can see how mul\", \"tiple microservices (multiple BCs) each has their own model and how their\\nentities can be defined, d\", \"epending on the specific requirements for each of the identified domains in\\nyour application.\\n\\nIdent\", \"ifying a Domain Model per Microservice or Bounded Context\\n\\nOrders and Registration\\n\\nConferences Mana\", \"gement\\n\\nPayment Customer Service\\n\\nPayments\\n\\nFigure 4-10. Identifying entities and microservice model\", \" boundaries\\n\\nFigure 4-10 illustrates a sample scenario related to an online conference management sy\", \"stem. The\\nsame entity appears as \\u201cUsers\\u201d, \\u201cBuyers\\u201d, \\u201cPayers\\u201d, and \\u201cCustomers\\u201d depending on the bound\", \"ed\\ncontext. You've identified several BCs that could be implemented as microservices, based on domai\", \"ns\\nthat domain experts defined for you. As you can see, there are entities that are present just in \", \"a single\\nmicroservice model, like Payments in the Payment microservice. Those will be easy to implem\", \"ent.\\n\\nHowever, you might also have entities that have a different shape but share the same identity \", \"across\\nthe multiple domain models from the multiple microservices. For example, the User entity is i\", \"dentified\\nin the Conferences Management microservice. That same user, with the same identity, is the\", \" one\\nnamed Buyers in the Ordering microservice, or the one named Payer in the Payment microservice, \", \"and\\neven the one named Customer in the Customer Service microservice. This is because, depending on\\n\", \"the ubiquitous language that each domain expert is using, a user might have a different perspective\\n\", \"even with different attributes. The user entity in the microservice model named Conferences\\nManageme\", \"nt might have most of its personal data attributes. However, that same user in the shape of\\nPayer in\", \" the microservice Payment or in the shape of Customer in the microservice Customer Service\\nmight not\", \" need the same list of attributes.\\n\\nA similar approach is illustrated in Figure 4-11.\\n\\n38 CHAPTER 3 \", \"| Architecting container and microservice-based applications\\nDecomposing a traditional data model in\", \"to multiple domain models\\n(One domain model per microservice or Bounded-Context)\\n\\nConferences\\n\\npubli\", \"c class User Management\\n{\\nFirstName\\nLastName FirstName\\nStatus LastName\\nAddress Address\\n// Tens of at\", \"tributes Company\\n7 // ... //etc\\nTraditional //... Models per\\nEntities Bounded Context or\\nwith \\u2018All m\", \"icroservice\\npossible\\\"\\nattributes public class Seat\\n\\n{\\nID\\nDescription\\nPrice\\n// Tens of attributes\\n// \", \"...\\n// ...\\n\\n}\\n\\nStatus\\n\\nSeat\\n\\nID\\nPrice\\n\\nFigure 4-11. Decomposing traditional data models into multipl\", \"e domain models\\n\\nWhen decomposing a traditional data model between bounded contexts, you can have di\", \"fferent\\nentities that share the same identity (a buyer is also a user) with different attributes in \", \"each bounded\\ncontext. You can see how the user is present in the Conferences Management microservice\", \" model as\\nthe User entity and is also present in the form of the Buyer entity in the Pricing microse\", \"rvice, with\\nalternate attributes or details about the user when it's actually a buyer. Each microser\", \"vice or BC might\\nnot need all the data related to a User entity, just part of it, depending on the p\", \"roblem to solve or the\\ncontext. For instance, in the Pricing microservice model, you do not need the\", \" address or the name of\\nthe user, just the ID (as identity) and Status, which will have an impact on\", \" discounts when pricing the\\nseats per buyer.\\n\\nThe Seat entity has the same name but different attrib\", \"utes in each domain model. However, Seat\\nshares identity based on the same ID, as happens with User \", \"and Buyer.\\n\\nBasically, there\\u2019s a shared concept of a user that exists in multiple services (domains)\", \", which all share\\nthe identity of that user. But in each domain model there might be additional or d\", \"ifferent details\\nabout the user entity. Therefore, there needs to be a way to map a user entity from\", \" one domain\\n(microservice) to another.\\n\\nThere are several benefits to not sharing the same user enti\", \"ty with the same number of attributes\\nacross domains. One benefit is to reduce duplication, so that \", \"microservice models do not have any\\ndata that they do not need. Another benefit is having a primary \", \"microservice that owns a certain type\\nof data per entity so that updates and queries for that type o\", \"f data are driven only by that\\nmicroservice.\\n\\n39 CHAPTER 3 | Architecting container and microservice\", \"-based applications\\nThe API gateway pattern versus the Direct client-to-\\nmicroservice communication\\n\", \"\\nIn a microservices architecture, each microservice exposes a set of (typically) fine-grained endpoi\", \"nts.\\nThis fact can impact the client-to-microservice communication, as explained in this section.\\n\\nD\", \"irect client-to-microservice communication\\n\\nA possible approach is to use a direct client-to-microse\", \"rvice communication architecture. In this\\napproach, a client app can make requests directly to some \", \"of the microservices, as shown in Figure 4-\\n12.\\n\\nDirect Client-To-Microservice communication\\nArchite\", \"cture\\n\\n/ Client Apps \\\\\\n\\nMobile <1\\nApp -\\n\\nFigure 4-12. Using a direct client-to-microservice communic\", \"ation architecture\\n\\nIn this approach, each microservice has a public endpoint, sometimes with a diff\", \"erent TCP port for\\neach microservice. An example of a URL for a particular service could be the foll\", \"owing URL in Azure:\\n\\nhttp://eshoponcontainers.westus.cloudapp.azure.com:88/\\n\\nIn a production environ\", \"ment based on a cluster, that URL would map to the load balancer used in the\\ncluster, which in turn \", \"distributes the requests across the microservices. In production environments,\\nyou could have an App\", \"lication Delivery Controller (ADC) like Azure Application Gateway between your\\nmicroservices and the\", \" Internet. This layer acts as a transparent tier that not only performs load\\nbalancing, but secures \", \"your services by offering SSL termination. This approach improves the load of\\nyour hosts by offloadi\", \"ng CPU-intensive SSL termination and other routing duties to the Azure\\nApplication Gateway. In any c\", \"ase, a load balancer and ADC are transparent from a logical application\\narchitecture point of view.\\n\", \"\\nA direct client-to-microservice communication architecture could be good enough for a small\\nmicrose\", \"rvice-based application, especially if the client app is a server-side web application like an\\nASP.N\", \"ET MVC app. However, when you build large and complex microservice-based applications (for\\nexample, \", \"when handling dozens of microservice types), and especially when the client apps are\\nremote mobile a\", \"pps or SPA web applications, that approach faces a few issues.\\n\\n40 CHAPTER 3 | Architecting containe\", \"r and microservice-based applications\\nConsider the following questions when developing a large appli\", \"cation based on microservices:\\n\\n\\u00b0 How can client apps minimize the number of requests to the back en\", \"d and reduce chatty\\ncommunication to multiple microservices?\\n\\nInteracting with multiple microservice\", \"s to build a single Ul screen increases the number of round trips\\nacross the Internet. This approach\", \" increases latency and complexity on the UI side. Ideally, responses\\nshould be efficiently aggregate\", \"d in the server side. This approach reduces latency, since multiple\\npieces of data come back in para\", \"llel and some UI can show data as soon as It's ready.\\n\\n\\u00b0 How can you handle cross-cutting concerns s\", \"uch as authorization, data transformations, and\\ndynamic request dispatching?\\n\\nImplementing security \", \"and cross-cutting concerns like security and authorization on every\\nmicroservice can require signifi\", \"cant development effort. A possible approach is to have those services\\nwithin the Docker host or int\", \"ernal cluster to restrict direct access to them from the outside, and to\\nimplement those cross-cutti\", \"ng concerns in a centralized place, like an API Gateway.\\n\\n\\u00b0 How can client apps communicate with ser\", \"vices that use non-Internet-friendly protocols?\\n\\nProtocols used on the server side (like AMQP or bin\", \"ary protocols) are not supported in client apps.\\nTherefore, requests must be performed through proto\", \"cols like HTTP/HTTPS and translated to the\\nother protocols afterwards. A man-in-the-middle approach \", \"can help in this situation.\\n\\n. How can you shape a facade especially made for mobile apps?\\n\\nThe API \", \"of multiple microservices might not be well designed for the needs of different client\\napplications.\", \" For instance, the needs of a mobile app might be different than the needs of a web app.\\nFor mobile \", \"apps, you might need to optimize even further so that data responses can be more\\nefficient. You migh\", \"t do this functionality by aggregating data from multiple microservices and\\nreturning a single set o\", \"f data, and sometimes eliminating any data in the response that isn't needed\\nby the mobile app. And,\", \" of course, you might compress that data. Again, a facade or API in between\\nthe mobile app and the m\", \"icroservices can be convenient for this scenario.\\n\\nWhy consider API Gateways instead of direct clien\", \"t-to-microservice\\ncommunication\\n\\nIn a microservices architecture, the client apps usually need to co\", \"nsume functionality from more than\\none microservice. If that consumption is performed directly, the \", \"client needs to handle multiple calls\\nto microservice endpoints. What happens when the application e\", \"volves and new microservices are\\nintroduced or existing microservices are updated? If your applicati\", \"on has many microservices,\\nhandling so many endpoints from the client apps can be a nightmare. Since\", \" the client app would be\\ncoupled to those internal endpoints, evolving the microservices in the futu\", \"re can cause high impact\\nfor the client apps.\\n\\nTherefore, having an intermediate level or tier of in\", \"direction (Gateway) can be convenient for\\nmicroservice-based applications. If you don\\u2019t have API Gat\", \"eways, the client apps must send requests\\ndirectly to the microservices and that raises problems, su\", \"ch as the following issues:\\n\\n41 CHAPTER 3 | Architecting container and microservice-based applicatio\", \"ns\\n. Coupling: Without the API Gateway pattern, the client apps are coupled to the internal\\nmicroser\", \"vices. The client apps need to know how the multiple areas of the application are\\ndecomposed in micr\", \"oservices. When evolving and refactoring the internal microservices,\\nthose actions impact maintenanc\", \"e because they cause breaking changes to the client apps\\ndue to the direct reference to the internal\", \" microservices from the client apps. Client apps need\\nto be updated frequently, making the solution \", \"harder to evolve.\\n\\n. Too many round trips: A single page/screen in the client app might require seve\", \"ral calls to\\nmultiple services. That approach can result in multiple network round trips between the\", \" client\\nand the server, adding significant latency. Aggregation handled in an intermediate level cou\", \"ld\\nimprove the performance and user experience for the client app.\\n\\n. Security issues: Without a gat\", \"eway, all the microservices must be exposed to the \\u201cexternal\\nworld\\u201d, making the attack surface large\", \"r than if you hide internal microservices that aren't\\ndirectly used by the client apps. The smaller \", \"the attack surface is, the more secure your\\napplication can be.\\n\\n. Cross-cutting concerns: Each publ\", \"icly published microservice must handle concerns such as\\nauthorization and SSL. In many situations, \", \"those concerns could be handled in a single tier so\\nthe internal microservices are simplified.\\n\\nWhat\", \" is the API Gateway pattern?\\n\\nWhen you design and build large or complex microservice-based applicat\", \"ions with multiple client\\napps, a good approach to consider can be an API Gateway. This pattern Is a\", \" service that provides a\\nsingle-entry point for certain groups of microservices. It's similar to the\", \" Facade pattern from object-\\noriented design, but in this case, it's part of a distributed system. T\", \"he API Gateway pattern is also\\nsometimes known as the \\u201cbackend for frontend\\u201d (BFF) because you build\", \" it while thinking about the\\nneeds of the client app.\\n\\nTherefore, the API gateway sits between the c\", \"lient apps and the microservices. It acts as a reverse\\nproxy, routing requests from clients to servi\", \"ces. It can also provide other cross-cutting features such\\nas authentication, SSL termination, and c\", \"ache.\\n\\nFigure 4-13 shows how a custom API Gateway can fit into a simplified microservice-based archi\", \"tecture\\nwith just a few microservices.\\n\\n42 CHAPTER 3 | Architecting container and microservice-based\", \" applications\\nUsing a single custom API Gateway service\\n\\nWebHost\\n\\nSS a SS SS SS Ss co\\n\\nI Back end\\n| \", \"( Microservice 1\\nJSON | ! |\\n|\\n|\\nI \\u201cAPiGateway\\n. J |\\n\\nTraditional Web app\\n\\nClient WebApp MVC\\nI\\nI\\n\\n|\\n\\n\", \"|\\n\\nBrowser \\u00ab\\u2014\\u2014\\u20144+\\u2014\\u2014_ PNET Core MVC [c) | |\\nHTML\\n\\ncontainer\\n\\nI\\n\\\\\\n\\nHTML\\n\\noe oe oe\\n\\nFigure 4-13. Using \", \"an API Gateway implemented as a custom service\\n\\nApps connect to a single endpoint, the API Gateway, \", \"that\\u2019s configured to forward requests to\\nindividual microservices. In this example, the API Gateway \", \"would be implemented as a custom\\nASP.NET Core WebHost service running as a container.\\n\\nIt's importan\", \"t to highlight that in that diagram, you would be using a single custom API Gateway\\nservice facing m\", \"ultiple and different client apps. That fact can be an important risk because your API\\nGateway servi\", \"ce will be growing and evolving based on many different requirements from the client\\napps. Eventuall\", \"y, it will be bloated because of those different needs and effectively it could be similar\\nto a mono\", \"lithic application or monolithic service. That's why it\\u2019s very much recommended to split the\\nAPI Gat\", \"eway in multiple services or multiple smaller API Gateways, one per client app form-factor\\ntype, for\", \" instance.\\n\\nYou need to be careful when implementing the API Gateway pattern. Usually it isn\\u2019t a goo\", \"d idea to\\nhave a single API Gateway aggregating all the internal microservices of your application. \", \"If it does, it\\nacts as a monolithic aggregator or orchestrator and violates microservice autonomy by\", \" coupling all\\nthe microservices.\\n\\nTherefore, the API Gateways should be segregated based on business\", \" boundaries and the client apps\\nand not act as a single aggregator for all the internal microservice\", \"s.\\n\\nWhen splitting the API Gateway tier into multiple API Gateways, if your application has multiple\", \" client\\napps, that can be a primary pivot when identifying the multiple API Gateways types, so that \", \"you can\\nhave a different facade for the needs of each client app. This case is a pattern named \\u201cBack\", \"end for\\nFrontend\\u201d (BFF) where each API Gateway can provide a different API tailored for each client \", \"app type,\\npossibly even based on the client form factor by implementing specific adapter code which\\n\", \"underneath calls multiple internal microservices, as shown in the following image:\\n\\n43 CHAPTER 3 | A\", \"rchitecting container and microservice-based applications\\nUsing multiple API Gateways / BFF\\n\\n| Back \", \"end\\n\\n\\\\\\n|\\n|\\n|\\n|\\n\\nASPNET Core\\nWebHost\\n\\nee ee\\n\\ncontainer\\n\\n7 . . N\\n( Microservice 2\\n| Web AP |\\n|\\n|\\n\\nSe e\", \"e ee ee ee ee ee ee ee ee ee oe oe\\n\\nJavaScript/Angularjs \\\\\\n\\\\\\n|\\n\\n| Web AP\\nTraditionalWebapp , f/f : x\", \"ey |\\n7 |\\n\\n| Client WebApp MVC\\n\\nI\\nBrowser HTML container Key |\\n| \\\\ ee /\\n\\name ee ee ee ee ee eK\\n\\nHTML\\n\", \"\\nee oe\\n\\nFigure 4-13.71. Using multiple custom AP! Gateways\\n\\nFigure 4-13.1 shows API Gateways that ar\", \"e segregated by client type; one for mobile clients and one\\nfor web clients. A traditional web app c\", \"onnects to an MVC microservice that uses the web API\\nGateway. The example depicts a simplified archi\", \"tecture with multiple fine-grained API Gateways. In\\nthis case, the boundaries identified for each AP\", \"! Gateway are based purely on the \\u201cBackend for\\nFrontend\\u201d (BFF) pattern, hence based just on the API \", \"needed per client app. But in larger applications\\nyou should also go further and create other AP! Ga\", \"teways based on business boundaries as a second\\ndesign pivot.\\n\\nMain features in the API Gateway patt\", \"ern\\n\\nAn API Gateway can offer multiple features. Depending on the product it might offer richer or s\", \"impler\\nfeatures, however, the most important and foundational features for any API Gateway are the\\nf\", \"ollowing design patterns:\\n\\nReverse proxy or gateway routing. The API Gateway offers a reverse proxy \", \"to redirect or route\\nrequests (layer 7 routing, usually HTTP requests) to the endpoints of the inter\", \"nal microservices. The\\ngateway provides a single endpoint or URL for the client apps and then intern\", \"ally maps the requests\\nto a group of internal microservices. This routing feature helps to decouple \", \"the client apps from the\\nmicroservices but it\\u2019s also convenient when modernizing a monolithic API by\", \" sitting the API Gateway\\nin between the monolithic API and the client apps, then you can add new API\", \"s as new microservices\\nwhile still using the legacy monolithic API until it\\u2019s split into many micros\", \"ervices in the future. Because\\nof the API Gateway, the client apps won't notice if the APIs being us\", \"ed are implemented as internal\\nmicroservices or a monolithic API and more importantly, when evolving\", \" and refactoring the\\nmonolithic API into microservices, thanks to the API Gateway routing, client ap\", \"ps won't be impacted\\nwith any URI change.\\n\\n44 CHAPTER 3 | Architecting container and microservice-ba\", \"sed applications\\nFor more information, see Gateway routing pattern.\\n\\nRequests aggregation. As part o\", \"f the gateway pattern you can aggregate multiple client requests\\n(usually HTTP requests) targeting m\", \"ultiple internal microservices into a single client request. This\\npattern is especially convenient w\", \"hen a client page/screen needs information from several\\nmicroservices. With this approach, the clien\", \"t app sends a single request to the API Gateway that\\ndispatches several requests to the internal mic\", \"roservices and then aggregates the results and sends\\neverything back to the client app. The main ben\", \"efit and goal of this design pattern Is to reduce\\nchattiness between the client apps and the backend\", \" API, which is especially important for remote\\napps out of the datacenter where the microservices li\", \"ve, like mobile apps or requests coming from\\nSPA apps that come from JavaScript in client remote bro\", \"wsers. For regular web apps performing the\\nrequests in the server environment (like an ASP.NET Core \", \"MVC web app), this pattern is not so\\nimportant as the latency is very much smaller than for remote c\", \"lient apps.\\n\\nDepending on the API Gateway product you use, it might be able to perform this aggregat\", \"ion.\\nHowever, in many cases it\\u2019s more flexible to create aggregation microservices under the scope o\", \"f the\\nAPI Gateway, so you define the aggregation in code (that is, C# code):\\n\\nFor more information, \", \"see Gateway aggregation pattern.\\n\\nCross-cutting concerns or gateway offloading. Depending on the fea\", \"tures offered by each API\\nGateway product, you can offload functionality from individual microservic\", \"es to the gateway, which\\nsimplifies the implementation of each microservice by consolidating cross-c\", \"utting concerns into one\\ntier. This approach Is especially convenient for specialized features that \", \"can be complex to implement\\nproperly in every internal microservice, such as the following functiona\", \"lity:\\n\\n\\u00b0 Authentication and authorization\\n\\n\\u00b0 Service discovery integration\\n\\n\\u00b0 Response caching\\n\\n\\u00b0 Re\", \"try policies, circuit breaker, and QoS\\n\\n\\u00b0 Rate limiting and throttling\\n\\n. Load balancing\\n\\n. Logging,\", \" tracing, correlation\\n\\n. Headers, query strings, and claims transformation\\n\\u00b0 IP allowlisting\\n\\nFor mo\", \"re information, see Gateway offloading pattern.\\n\\nUsing products with API Gateway features\\n\\nThere can\", \" be many more cross-cutting concerns offered by the API Gateways products depending on\\neach implemen\", \"tation. We'll explore here:\\n\\n\\u00b0 Azure API Management\\n\\u00b0 Ocelot\\n\\n45 CHAPTER 3 | Architecting container \", \"and microservice-based applications\\nAzure API Management\\n\\nAzure API Management (as shown in Figure 4\", \"-14) not only solves your API Gateway needs but\\nprovides features like gathering insights from your \", \"APIs. If you're using an API management solution,\\nan API Gateway is only a component within that ful\", \"l API management solution.\\n\\nAPI Gateway with Azure API Management\\nArchitecture\\n\\nAzure API Management\", \" |\\n\\u00b0 ( Microservice 1}\\n| im |\\n|\\n|\\nDeveloper \\\\comener /\\nportal l\\n( Microservice 2\\u2018 I\\n|\\n| /\\n\\nAPI Gatew\", \"ay _ ee y\\n\\na ee EE\\n\\nMicroservice 3\\n\\nl\\n\\nl\\n\\n7\\n\\nte I |\\n\\n| teh, AD | |\\n\\ni 7\\n\\n|\\n\\n|\\n\\nPublisher portal \\\\~5-\", \"------------- \\u2018\\n\\ncontainer\\n\\n|\\n\\n| |\\n\\n| |\\n\\n| ' ASPNET Core MVC\\n\\n| Browser *\\u2014\\u2014+\\u20141> | ore\\\" oy\\n| \\\\\\n\\n|\\n\\n|\\n\", \"\\nFigure 4-14. Using Azure AP! Management for your API Gateway\\n\\nAzure API Management solves both your\", \" API Gateway and Management needs like logging, security,\\nmetering, etc. In this case, when using a \", \"product like Azure AP! Management, the fact that you might\\nhave a single API Gateway is not so risky\", \" because these kinds of API Gateways are \\u201cthinner\\u201d, meaning\\nthat you don't implement custom C# code \", \"that could evolve towards a monolithic component.\\n\\nThe API Gateway products usually act like a rever\", \"se proxy for ingress communication, where you can\\nalso filter the APIs from the internal microservic\", \"es plus apply authorization to the published APIs in\\nthis single tier.\\n\\nThe insights available from \", \"an API Management system help you get an understanding of how your\\nAPIs are being used and how they \", \"are performing. They do this activity by letting you view near real-\\ntime analytics reports and iden\", \"tifying trends that might impact your business. Plus, you can have logs\\nabout request and response a\", \"ctivity for further online and offline analysis.\\n\\nWith Azure API Management, you can secure your API\", \"s using a key, a token, and IP filtering. These\\nfeatures let you enforce flexible and fine-grained q\", \"uotas and rate limits, modify the shape and\\nbehavior of your APIs using policies, and improve perfor\", \"mance with response caching.\\n\\nIn this guide and the reference sample application (eShopOnContainers)\", \", the architecture is limited to\\na simpler and custom-made containerized architecture in order to fo\", \"cus on plain containers without\\n\\n46 CHAPTER 3 | Architecting container and microservice-based applic\", \"ations\\nusing PaaS products like Azure API Management. But for large microservice-based applications \", \"that\\nare deployed into Microsoft Azure, we encourage you to evaluate Azure API Management as the bas\", \"e\\nfor your API Gateways in production.\\n\\nOcelot\\n\\nOcelot is a lightweight API Gateway, recommended for\", \" simpler approaches. Ocelot is an Open Source\\n.NET Core-based API Gateway especially made for micros\", \"ervices architectures that need unified points\\nof entry into their systems. It's lightweight, fast, \", \"and scalable and provides routing and authentication\\n\\namong many other features.\\n\\nThe main reason to\", \" choose Ocelot for the eshopOnContainers reference application 2.0 is because\\nOcelot is a .NET Core \", \"lightweight API Gateway that you can deploy into the same application\\ndeployment environment where y\", \"ou're deploying your microservices/containers, such as a Docker\\nHost, Kubernetes, etc. And since it'\", \"s based on .NET Core, it\\u2019s cross-platform allowing you to deploy on\\nLinux or Windows.\\n\\nThe previous \", \"diagrams showing custom API Gateways running in containers are precisely how you can\\nalso run Ocelot\", \" in a container and microservice-based application.\\n\\nIn addition, there are many other products in t\", \"he market offering API Gateways features, such as\\nApigee, Kong, MuleSoft, WSO2, and other products l\", \"ike Linkerd and Istio for service mesh ingress\\ncontroller features.\\n\\nAfter the initial architecture \", \"and patterns explanation sections, the next sections explain how to\\nimplement API Gateways with Ocel\", \"ot.\\n\\nDrawbacks of the API Gateway pattern\\n\\n. The most important drawback is that when you implement \", \"an API Gateway, you're coupling\\nthat tier with the internal microservices. Coupling like this might \", \"introduce serious difficulties\\nfor your application. Clemens Vaster, architect at the Azure Service \", \"Bus team, refers to this\\npotential difficulty as \\u201cthe new ESB\\u201d in the \\u201cMessaging and Microservices\\u201d \", \"session at GOTO\\n2016.\\n\\n. Using a microservices AP] Gateway creates an additional possible single poi\", \"nt of failure.\\n\\n\\u00b0 An API Gateway can introduce increased response time due to the additional network\", \" call.\\nHowever, this extra call usually has less impact than having a client interface that's too ch\", \"atty\\ndirectly calling the internal microservices.\\n\\n. If not scaled out properly, the API Gateway can\", \" become a bottleneck.\\n\\n\\u00b0 An API Gateway requires additional development cost and future maintenance \", \"if it includes\\ncustom logic and data aggregation. Developers must update the API Gateway in order to\", \"\\nexpose each microservice\\u2019s endpoints. Moreover, implementation changes in the internal\\nmicroservice\", \"s might cause code changes at the API Gateway level. However, if the API\\nGateway is just applying se\", \"curity, logging, and versioning (as when using Azure API\\nManagement), this additional development co\", \"st might not apply.\\n\\n47 CHAPTER 3 | Architecting container and microservice-based applications\\n. If \", \"the API Gateway is developed by a single team, there can be a development bottleneck. This\\naspect is\", \" another reason why a better approach is to have several fined-grained API Gateways\\nthat respond to \", \"different client needs. You could also segregate the API Gateway internally\\ninto multiple areas or l\", \"ayers that are owned by the different teams working on the internal\\nmicroservices.\\n\\nAdditional resou\", \"rces\\n\\n. Chris Richardson. Pattern: API Gateway / Backend for Front-End\\nhttps://microservices.io/patt\", \"erns/apigateway.html\\n\\n\\u00b0 API Gateway pattern\\nhttps://learn.microsoft.com/azure/architecture/microserv\", \"ices/gateway\\n\\n\\u00b0 Aggregation and composition pattern\\n\\nhttps://microservices.io/patterns/data/api-comp\", \"osition.html\\n\\n\\u00b0 Azure API Management\\n\\nhttps://azure.microsoft.com/services/api-management/\\n\\n\\u00b0 Udi Da\", \"han. Service Oriented Composition\\nhttps://udidahan.com/2014/07/30/service-oriented-composition-with-\", \"video\\n\\n. Clemens Vasters. Messaging and Microservices at GOTO 2016 (video)\\n\\nhttps://www.youtube.com/\", \"watch?v=rxi5CLjIQ9k\\n\\n\\u00b0 API Gateway in a Nutshell (ASP.NET Core API Gateway Tutorial Series)\\nhttps://\", \"www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.htm!\\n\\nCommunication in a microservice architectur\", \"e\\n\\nIn a monolithic application running on a single process, components invoke one another using\\nlang\", \"uage-level method or function calls. These can be strongly coupled if you're creating objects with\\nc\", \"ode (for example, new ClassName()), or can be invoked in a decoupled way if you're using\\nDependency \", \"Injection by referencing abstractions rather than concrete object instances. Either way,\\nthe objects\", \" are running within the same process. The biggest challenge when changing from a\\nmonolithic applicat\", \"ion to a microservices-based application lies in changing the communication\\nmechanism. A direct conv\", \"ersion from in-process method calls into RPC calls to services will cause a\\nchatty and not efficient\", \" communication that won't perform well in distributed environments. The\\nchallenges of designing dist\", \"ributed system properly are well enough known that there\\u2019s even a canon\\nknown as the Fallacies of di\", \"stributed computing that lists assumptions that developers often make\\nwhen moving from monolithic to\", \" distributed designs.\\n\\nThere isn't one solution, but several. One solution involves isolating the bu\", \"siness microservices as\\nmuch as possible. You then use asynchronous communication between the intern\", \"al microservices and\\nreplace fine-grained communication that\\u2019s typical in intra-process communicatio\", \"n between objects\\nwith coarser-grained communication. You can do this by grouping calls, and by retu\", \"rning data that\\naggregates the results of multiple internal calls, to the client.\\n\\n48 CHAPTER 3 | Ar\", \"chitecting container and microservice-based applications\\nA microservices-based application is a dist\", \"ributed system running on multiple processes or services,\\nusually even across multiple servers or ho\", \"sts. Each service instance Is typically a process. Therefore,\\nservices must interact using an inter-\", \"process communication protocol such as HTTP, AMQP, or a\\nbinary protocol like TCP, depending on the n\", \"ature of each service.\\n\\nThe microservice community promotes the philosophy of \\u201csmart endpoints and d\", \"umb pipes\\u201d. This\\nslogan encourages a design that\\u2019s as decoupled as possible between microservices, a\", \"nd as cohesive\\nas possible within a single microservice. As explained earlier, each microservice own\", \"s its own data and\\nits own domain logic. But the microservices composing an end-to-end application a\", \"re usually simply\\nchoreographed by using REST communications rather than complex protocols such as W\", \"S-* and\\nflexible event-driven communications instead of centralized business-process-orchestrators.\\n\", \"\\nThe two commonly used protocols are HTTP request/response with resource APIs (when querying\\nmost of\", \" all), and lightweight asynchronous messaging when communicating updates across multiple\\nmicroservic\", \"es. These are explained in more detail in the following sections.\\n\\nCommunication types\\n\\nClient and s\", \"ervices can communicate through many different types of communication, each one\\ntargeting a differen\", \"t scenario and goals. Initially, those types of communications can be classified in\\ntwo axes.\\n\\nThe f\", \"irst axis defines if the protocol is synchronous or asynchronous:\\n\\n. Synchronous protocol. HTTP is a\", \" synchronous protocol. The client sends a request and waits\\nfor a response from the service. That's \", \"independent of the client code execution that could be\\nsynchronous (thread is blocked) or asynchrono\", \"us (thread isn't blocked, and the response will\\nreach a callback eventually). The important point he\", \"re is that the protocol (HTTP/HTTPS) is\\nsynchronous and the client code can only continue its task w\", \"hen it receives the HTTP server\\nresponse.\\n\\n. Asynchronous protocol. Other protocols like AMQP (a pro\", \"tocol supported by many operating\\nsystems and cloud environments) use asynchronous messages. The cli\", \"ent code or message\\nsender usually doesn\\u2019t wait for a response. It just sends the message as when se\", \"nding a\\nmessage to a RabbitMQ queue or any other message broker.\\n\\nThe second axis defines if the com\", \"munication has a single receiver or multiple receivers:\\n\\n. Single receiver. Each request must be pro\", \"cessed by exactly one receiver or service. An\\nexample of this communication is the Command pattern.\\n\", \"\\n. Multiple receivers. Each request can be processed by zero to multiple receivers. This type of\\ncom\", \"munication must be asynchronous. An example is the publish/subscribe mechanism used\\nin patterns like\", \" Event-driven architecture. This is based on an event-bus interface or message\\nbroker when propagati\", \"ng data updates between multiple microservices through events; it\\u2019s\\nusually implemented through a se\", \"rvice bus or similar artifact like Azure Service Bus by using\\n\\ntopics and subscriptions.\\n\\n49 CHAPTER\", \" 3 | Architecting container and microservice-based applications\\nA microservice-based application wil\", \"l often use a combination of these communication styles. The\\nmost common type is single-receiver com\", \"munication with a synchronous protocol like HTTP/HTTPS\\nwhen invoking a regular Web API HTTP service.\", \" Microservices also typically use messaging protocols\\nfor asynchronous communication between microse\", \"rvices.\\n\\nThese axes are good to know so you have clarity on the possible communication mechanisms, b\", \"ut\\nthey're not the important concerns when building microservices. Neither the asynchronous nature o\", \"f\\nclient thread execution nor the asynchronous nature of the selected protocol are the important poi\", \"nts\\nwhen integrating microservices. What ts important is being able to integrate your microservices\\n\", \"asynchronously while maintaining the independence of microservices, as explained in the following\\nse\", \"ction.\\n\\nAsynchronous microservice integration enforces microservice\\u2019s\\nautonomy\\n\\nAs mentioned, the im\", \"portant point when building a microservices-based application is the way you\\nintegrate your microser\", \"vices. Ideally, you should try to minimize the communication between the\\ninternal microservices. The\", \" fewer communications between microservices, the better. But in many\\ncases, you'll have to somehow i\", \"ntegrate the microservices. When you need to do that, the critical rule\\nhere is that the communicati\", \"on between the microservices should be asynchronous. That doesn't\\nmean that you have to use a specif\", \"ic protocol (for example, asynchronous messaging versus\\nsynchronous HTTP). It just means that the co\", \"mmunication between microservices should be done only\\nby propagating data asynchronously, but try no\", \"t to depend on other internal microservices as part of\\nthe initial service\\u2019s HTTP request/response o\", \"peration.\\n\\nIf possible, never depend on synchronous communication (request/response) between multipl\", \"e\\nmicroservices, not even for queries. The goal of each microservice is to be autonomous and availab\", \"le\\nto the client consumer, even if the other services that are part of the end-to-end application ar\", \"e down\\nor unhealthy. If you think you need to make a call from one microservice to other microservic\", \"es (like\\nperforming an HTTP request for a data query) to be able to provide a response to a client a\", \"pplication,\\nyou have an architecture that won't be resilient when some microservices fail.\\n\\nMoreover\", \", having HTTP dependencies between microservices, like when creating long\\nrequest/response cycles wi\", \"th HTTP request chains, as shown in the first part of the Figure 4-15, not\\nonly makes your microserv\", \"ices not autonomous but also their performance is impacted as soon as\\none of the services in that ch\", \"ain isn't performing well.\\n\\nThe more you add synchronous dependencies between microservices, such as\", \" query requests, the\\nworse the overall response time gets for the client apps.\\n\\n50 CHAPTER 3 | Archi\", \"tecting container and microservice-based applications\\nSynchronous vs. async communication across mic\", \"roservices\\n\\nAnti-pattern\\n\\nSynchronous\\nall request/response\\ncycle\\n\\nAsynchronous\\nComm. across internal\", \"\\n\\nHttp syne.\\n- request\\nClient\\n\\nHttp sync.\\nresponse\\n\\nSuch as MVC ap\\nAPI Gateway\\n\\nHttp syne.\\nrequest\\n\\n\", \"\\u2014\\u2014\\n|\\n\\nHttp sync. Http sync. Http syne.\\nrequest d request request\\nOrderin Catalo\\nlS \\u2014-,] 2\\nHttp sync.\", \" Http syne.\\nresponse response\\n\\nHttp sync.\\nresponse\\n\\nSame http request/response cycle!\\n\\nClient\\n\\n$l\\nee\", \"\\n\\nmicroservices\\n(EventBus: like AMQP)\\n\\nHttp sync.\\nresponse\\n\\nDm)\\nbe PS\\n~ =. 7 Catalog 3 4\\n\\\\\\n~~\\n\\nHttp\\n\", \"Polling\\n\\nSuch as MVC app,\\nAPI Gateway\\n\\nHttp sync. Http Http\\nrequest Polling Polling\\nOrdering\\nHttp sy\", \"ne.\\n\\nresponse\\n\\n\\u201cAsynchronous\\u201d\\nComm. across\\ninternal microservices\\n(Polling: Http)\\n\\nSuch as MVC app,\\n\", \"API Gateway\\n\\nFigure 4-15. Anti-patterns and patterns in communication between microservices\\n\\nAs show\", \"n in the above diagram, in synchronous communication a \\u201cchain\\u201d of requests is created\\nbetween micros\", \"ervices while serving the client request. This is an anti-pattern. In asynchronous\\ncommunication mic\", \"roservices use asynchronous messages or http polling to communicate with other\\nmicroservices, but th\", \"e client request is served right away.\\n\\nIf your microservice needs to raise an additional action in \", \"another microservice, if possible, do not\\nperform that action synchronously and as part of the origi\", \"nal microservice request and reply\\noperation. Instead, do it asynchronously (using asynchronous mess\", \"aging or integration events,\\nqueues, etc.). But, as much as possible, do not invoke the action synch\", \"ronously as part of the original\\nsynchronous request and reply operation.\\n\\nAnd finally (and this is \", \"where most of the issues arise when building microservices), if your initial\\nmicroservice needs data\", \" that\\u2019s originally owned by other microservices, do not rely on making\\nsynchronous requests for that\", \" data. Instead, replicate or propagate that data (only the attributes you\\nneed) into the initial ser\", \"vice's database by using eventual consistency (typically by using integration\\nevents, as explained i\", \"n upcoming sections).\\n\\nAs noted earlier in the Identifying domain-model boundaries for each microser\", \"vice section,\\n\\nduplicating some data across several microservices isn't an incorrect design\\u2014on the c\", \"ontrary, when\\ndoing that you can translate the data into the specific language or terms of that addi\", \"tional domain or\\nBounded Context. For instance, in the eshopOnContainers application you have a micr\", \"oservice named\\nidentity-api that's in charge of most of the user's data with an entity named User. H\", \"owever, when you\\nneed to store data about the user within the Ordering microservice, you store it as\", \" a different entity\\nnamed Buyer. The Buyer entity shares the same identity with the original User en\", \"tity, but it might have\\nonly the few attributes needed by the Ordering domain, and not the whole use\", \"r profile.\\n\\n51 CHAPTER 3 | Architecting container and microservice-based applications\\nYou might use \", \"any protocol to communicate and propagate data asynchronously across microservices\\nin order to have \", \"eventual consistency. As mentioned, you could use integration events using an event\\nbus or message b\", \"roker or you could even use HTTP by polling the other services instead. It doesn't\\nmatter. The impor\", \"tant rule is to not create synchronous dependencies between your microservices.\\n\\nThe following secti\", \"ons explain the multiple communication styles you can consider using ina\\nmicroservice-based applicat\", \"ion.\\n\\nCommunication styles\\n\\nThere are many protocols and choices you can use for communication, depe\", \"nding on the\\ncommunication type you want to use. If you're using a synchronous request/response-base\", \"d\\ncommunication mechanism, protocols such as HTTP and REST approaches are the most common,\\nespeciall\", \"y if you're publishing your services outside the Docker host or microservice cluster. If you're\\ncomm\", \"unicating between services internally (within your Docker host or microservices cluster), you\\nmight \", \"also want to use binary format communication mechanisms (like WCF using TCP and binary\\nformat). Alte\", \"rnatively, you can use asynchronous, message-based communication mechanisms such as\\nAMQP.\\n\\nThere are\", \" also multiple message formats like JSON or XML, or even binary formats, which can be more\\nefficient\", \". If your chosen binary format isn\\u2019t a standard, it\\u2019s probably not a good idea to publicly\\npublish y\", \"our services using that format. You could use a non-standard format for internal\\ncommunication betwe\", \"en your microservices. You might do this when communicating between\\nmicroservices within your Docker\", \" host or microservice cluster (for example, Docker orchestrators), or\\nfor proprietary client applica\", \"tions that talk to the microservices.\\n\\nRequest/response communication with HTTP and REST\\n\\nWhen a cli\", \"ent uses request/response communication, it sends a request to a service, then the service\\nprocesses\", \" the request and sends back a response. Request/response communication is especially well\\nsuited for\", \" querying data for a real-time UI (a live user interface) from client apps. Therefore, in a\\nmicroser\", \"vice architecture you'll probably use this communication mechanism for most queries, as\\nshown in Fig\", \"ure 4-16.\\n\\nRequest/response communication for live queries and updates\\nHTTP-based Services\\n\\n, Back e\", \"nd (Catalog microservice >\\n|\\n|\\n\\nI\\n\\\\\\nWeb AP| | |\\nrel |e] SQL Server |\\ncontainer | |\\n/\\nI\\n\\nce ee ee ee \", \"eee ee we i\\n\\nBasket microservice |\\n\\nker] 4 Redis cache\\ncontainer J I\\n=\\n\\nSS SS SS SS SS SD ED GD ED G\", \"D GD GD a a a a ee\\n\\nFigure 4-16. Using HTTP request/response communication (synchronous or asynchron\", \"ous)\\n\\n52 CHAPTER 3 | Architecting container and microservice-based applications\\nWhen a client uses r\", \"equest/response communication, it assumes that the response will arrive in a\\nshort time, typically l\", \"ess than a second, or a few seconds at most. For delayed responses, you need to\\nimplement asynchrono\", \"us communication based on messaging patterns and messaging technologies,\\nwhich is a different approa\", \"ch that we explain in the next section.\\n\\nA popular architectural style for request/response communic\", \"ation is REST. This approach is based on,\\nand tightly coupled to, the HTTP protocol, embracing HTTP \", \"verbs like GET, POST, and PUT. REST is the\\nmost commonly used architectural communication approach w\", \"hen creating services. You can\\nimplement REST services when you develop ASP.NET Core Web API service\", \"s.\\n\\nThere's additional value when using HTTP REST services as your interface definition language. Fo\", \"r\\ninstance, if you use Swagger metadata to describe your service API, you can use tools that generat\", \"e\\nclient stubs that can directly discover and consume your services.\\n\\nAdditional resources\\n\\n. Martin\", \" Fowler. Richardson Maturity Model A description of the REST model.\\nhttps://martinfowler.com/article\", \"s/richardsonMaturityModel.html\\n\\n. Swagger The official site.\\n\\nhttps://swagger.1o/\\n\\nPush and real-tim\", \"e communication based on HTTP\\n\\nAnother possibility (usually for different purposes than REST) is a r\", \"eal-time and one-to-many\\ncommunication with higher-level frameworks such as ASP.NET SignalR and prot\", \"ocols such as\\nWebSockets.\\n\\nAs Figure 4-17 shows, real-time HTTP communication means that you can hav\", \"e server code pushing\\ncontent to connected clients as the data becomes available, rather than having\", \" the server wait for a\\nclient to request new data.\\n\\n53 CHAPTER 3 | Architecting container and micros\", \"ervice-based applications\\nPush and real-time communication based on HTTP\\nOne-to-many communication\\n\\n\", \"\\u2018\\u201cClient-1 WebApp SPA \\u00bb\\n\\n7\\n!\\n!\\n!\\nl\\nl\\n!\\n!\\n\\n| Back end\\n|\\n\\n_\\u2014\\n\\n=a se ee\\n\\npy! SignalR service hub\\n\\n| |\\n|\", \" ;\\n>\\n| mA | eS \\u00ae ervice\\n\\n| to communicate\\nN\\n\\n~\\u2014-\\u2014\\u2014 \\u2014\\n\\n\\u2014\\nee ee ee ee oe\\n\\nee oe\\n\\n/\\n\\nFigure 4-17. One-t\", \"o-many real-time asynchronous message communication\\n\\nSignalR is a good way to achieve real-time comm\", \"unication for pushing content to the clients from a\\n\\nback-end server. Since communication is in real\", \" time, client apps show the changes almost instantly.\\n\\nThis is usually handled by a protocol such as\", \" WebSockets, using many WebSockets connections (one\\nper client). A typical example is when a service\", \" communicates a change in the score of a sports game\\nto many client web apps simultaneously.\\n\\nAsynch\", \"ronous message-based communication\\n\\nAsynchronous messaging and event-driven communication are critic\", \"al when propagating changes\\nacross multiple microservices and their related domain models. As mentio\", \"ned earlier in the discussion\\nmicroservices and Bounded Contexts (BCs), models (User, Customer, Prod\", \"uct, Account, etc.) can mean\\ndifferent things to different microservices or BCs. That means that whe\", \"n changes occur, you need\\nsome way to reconcile changes across the different models. A solution is e\", \"ventual consistency and\\nevent-driven communication based on asynchronous messaging.\\n\\nWhen using mess\", \"aging, processes communicate by exchanging messages asynchronously. A client\\nmakes a command or a re\", \"quest to a service by sending it a message. If the service needs to reply, it\\nsends a different mess\", \"age back to the client. Since it\\u2019s a message-based communication, the client\\nassumes that the reply \", \"won't be received immediately, and that there might be no response at all.\\n\\nA message is composed by\", \" a header (metadata such as identification or security information) and a\\nbody. Messages are usually\", \" sent through asynchronous protocols like AMQP.\\n\\nThe preferred infrastructure for this type of commu\", \"nication in the microservices community Is a\\nlightweight message broker, which is different than the\", \" large brokers and orchestrators used in SOA.\\nIn a lightweight message broker, the infrastructure is\", \" typically \\u201cdumb,\\u201d acting only as a message\\nbroker, with simple implementations such as RabbitMQ or \", \"a scalable service bus in the cloud like\\n\\n54 CHAPTER 3 | Architecting container and microservice-bas\", \"ed applications\\nAzure Service Bus. In this scenario, most of the \\u201csmart\\u201d thinking still lives in the\", \" endpoints that are\\nproducing and consuming messages-that is, in the microservices.\\n\\nAnother rule yo\", \"u should try to follow, as much as possible, is to use only asynchronous messaging\\nbetween the inter\", \"nal services, and to use synchronous communication (such as HTTP) only from the\\nclient apps to the f\", \"ront-end services (API Gateways plus the first level of microservices).\\n\\nThere are two kinds of asyn\", \"chronous messaging communication: single receiver message-based\\ncommunication, and multiple receiver\", \"s message-based communication. The following sections\\nprovide details about them.\\n\\nSingle-receiver m\", \"essage-based communication\\n\\nMessage-based asynchronous communication with a single receiver means th\", \"ere's point-to-point\\ncommunication that delivers a message to exactly one of the consumers that\\u2019s re\", \"ading from the\\nchannel, and that the message is processed just once. However, there are special situ\", \"ations. For\\ninstance, in a cloud system that tries to automatically recover from failures, the same \", \"message could\\nbe sent multiple times. Due to network or other failures, the client has to be able to\", \" retry sending\\nmessages, and the server has to implement an operation to be idempotent in order to p\", \"rocess a\\nparticular message just once.\\n\\nSingle-receiver message-based communication is especially we\", \"ll suited for sending asynchronous\\ncommands from one microservice to another as shown in Figure 4-18\", \" that illustrates this approach.\\n\\nOnce you start sending message-based communication (either with co\", \"mmands or events), you should\\navoid mixing message-based communication with synchronous HTTP communi\", \"cation.\\n\\nSingle receiver message-based communication\\n(i.e. Message-based Commands)\\n\\n| Back end I\\n| i\", \"r Basket Microservice \\u2018\\\\ a Ordering Microservice Y 1\\n| | (3) | |\\n| | (1) Web AP| | CreateOrder | erv\", \"ice | |\\n\\nI | ConvertToOrder | command ! |\\n$$]. $$$ qq >\\ncomman |\\n| | Async.Message | |\\nGet basket da\", \"ta | | | |\\n|\\n| | | | <=> |\\nCache i Database | t\\n/\\n| NL / \\\\. Fe l\\n| Message based communication for c\", \"ertain asynchronous commands t\\n\\nFigure 4-18. A single microservice receiving an asynchronous message\", \"\\n\\n55 CHAPTER 3 | Architecting container and microservice-based applications\\nWhen the commands come f\", \"rom client applications, they can be implemented as HTTP synchronous\\ncommands. Use message-based com\", \"mands when you need higher scalability or when you're already\\nin a message-based business process.\\n\\n\", \"Multiple-receivers message-based communication\\n\\nAs a more flexible approach, you might also want to \", \"use a publish/subscribe mechanism so that your\\ncommunication from the sender will be available to ad\", \"ditional subscriber microservices or to external\\napplications. Thus, it helps you to follow the open\", \"/closed principle in the sending service. That way,\\nadditional subscribers can be added in the futur\", \"e without the need to modify the sender service.\\n\\nWhen you use a publish/subscribe communication, yo\", \"u might be using an event bus interface to\\npublish events to any subscriber.\\n\\nAsynchronous event-dri\", \"ven communication\\n\\nWhen using asynchronous event-driven communication, a microservice publishes an i\", \"ntegration event\\nwhen something happens within its domain and another microservice needs to be aware\", \" of it, like a\\nprice change in a product catalog microservice. Additional microservices subscribe to\", \" the events so\\nthey can receive them asynchronously. When that happens, the receivers might update t\", \"heir own\\ndomain entities, which can cause more integration events to be published. This publish/subs\", \"cribe\\nsystem is performed by using an implementation of an event bus. The event bus can be designed \", \"as\\nan abstraction or interface, with the API that\\u2019s needed to subscribe or unsubscribe to events and\", \" to\\npublish events. The event bus can also have one or more implementations based on any inter-proce\", \"ss\\nand messaging broker, like a messaging queue or service bus that supports asynchronous\\ncommunicat\", \"ion and a publish/subscribe model.\\n\\nIf a system uses eventual consistency driven by integration even\", \"ts, it\\u2019s recommended that this\\napproach is made clear to the end user. The system shouldn't use an a\", \"pproach that mimics\\nintegration events, like SignalR or polling systems from the client. The end use\", \"r and the business\\nowner have to explicitly embrace eventual consistency in the system and realize t\", \"hat in many cases\\nthe business doesn't have any problem with this approach, as long as it\\u2019s explicit\", \". This approach is\\nimportant because users might expect to see some results immediately and this asp\", \"ect might not\\nhappen with eventual consistency.\\n\\nAs noted earlier in the Challenges and solutions fo\", \"r distributed data management section, you can use\\nintegration events to implement business tasks th\", \"at soan multiple microservices. Thus, you'll have\\n\\neventual consistency between those services. An e\", \"ventually consistent transaction is made up of a\\ncollection of distributed actions. At each action, \", \"the related microservice updates a domain entity and\\npublishes another integration event that raises\", \" the next action within the same end-to-end business\\ntask.\\n\\nAn important point is that you might wan\", \"t to communicate to multiple microservices that are\\nsubscribed to the same event. To do so, you can \", \"use publish/subscribe messaging based on event-\\ndriven communication, as shown in Figure 4-19. This \", \"publish/subscribe mechanism isn't exclusive to\\nthe microservice architecture. It's similar to the wa\", \"y Bounded Contexts in DDD should communicate,\\nor to the way you propagate updates from the write dat\", \"abase to the read database in the Command\\n\\n56 CHAPTER 3 | Architecting container and microservice-ba\", \"sed applications\\nand Query Responsibility Segregation (CQRS) architecture pattern. The goal is to ha\", \"ve eventual\\n\\nconsistency between multiple data sources across your distributed system.\\n\\nAsynchronous\", \" event-driven communication\\nMultiple receivers\\n\\nSe lleeti eee ioeettieeetcstli es ieeetii eee eet en\", \" ieee tee iee eli ite tie linia,\\n\\n| Back end |\\n| Basket microservice\\n|\\ncel =\\u2014 Database as | |\\noe ne \", \"|\\n/ User-Profile Microservice \\\\ | \\\"Service Cache |\\n@ MX UserUpdated event > Buyer info I\\nUpdateUser\\n\", \"command UserUpdated event\\n\\n(Publish Action)\\nDB update\\n\\n|\\n\\nDatabase |\\n\\n| |\\n\\n _\\u2014 ! Omm O | Database |\\n\", \"\\n|\\na\\nPo\\n|\\n|\\nPo\\n1\\n\\\\\\n|\\n\\nEventual consistency across microservices based on event-driven async communic\", \"ation\\n\\nFigure 4-19. Asynchronous event-driven message communication\\n\\nIn asynchronous event-driven co\", \"mmunication, one microservice publishes events to an event bus and\\nmany microservices can subscribe \", \"to it, to get notified and act on it. Your implementation will\\ndetermine what protocol to use for ev\", \"ent-driven, message-based communications. AMQP can help\\nachieve reliable queued communication.\\n\\nWhen\", \" you use an event bus, you might want to use an abstraction level (like an event bus interface)\\nbase\", \"d on a related implementation in classes with code using the API from a message broker like\\nRabbitMQ\", \" or a service bus like Azure Service Bus with Topics. Alternatively, you might want to use a\\nhigher-\", \"level service bus like NServiceBus, MassTransit, or Brighter to articulate your event bus and\\npublis\", \"h/subscribe system.\\n\\nA note about messaging technologies for production systems\\n\\nThe messaging techn\", \"ologies available for implementing your abstract event bus are at different levels.\\nFor instance, pr\", \"oducts like RabbitMQ (a messaging broker transport) and Azure Service Bus sit at a\\nlower level than \", \"other products like NServiceBus, MassTransit, or Brighter, which can work on top of\\n\\nRabbitMQ and Az\", \"ure Service Bus. Your choice depends on how many rich features at the application\\nlevel and out-of-t\", \"he-box scalability you need for your application. For implementing just a proof-of-\\nconcept event bu\", \"s for your development environment, as it was done in the eShopOnContainers\\nsample, a simple impleme\", \"ntation on top of RabbitMQ running on a Docker container might be\\nenough.\\n\\nHowever, for mission-crit\", \"ical and production systems that need hyper-scalability, you might want to\\nevaluate Azure Service Bu\", \"s. For high-level abstractions and features that make the development of\\ndistributed applications ea\", \"sier, we recommend that you evaluate other commercial and open-source\\nservice buses, such as NServic\", \"eBus, MassTransit, and Brighter. Of course, you can build your own\\n\\n57 CHAPTER 3 | Architecting cont\", \"ainer and microservice-based applications\\nservice-bus features on top of lower-level technologies li\", \"ke RabbitMQ and Docker. But that plumbing\\nwork might cost too much for a custom enterprise applicati\", \"on.\\n\\nResiliently publishing to the event bus\\n\\nA challenge when implementing an event-driven architec\", \"ture across multiple microservices is how to\\natomically update state in the original microservice wh\", \"ile resiliently publishing its related integration\\nevent into the event bus, somehow based on transa\", \"ctions. The following are a few ways to accomplish\\nthis functionality, although there could be addit\", \"ional approaches as well.\\n\\n. Using a transactional (DTC-based) queue like MSMQ. (However, this is a \", \"legacy approach.)\\n\\u00b0 Using transaction log mining.\\n\\n. Using full Event Sourcing pattern.\\n\\n. Using the\", \" Outbox pattern: a transactional database table as a message queue that will be the\\nbase for an even\", \"t-creator component that would create the event and publish it.\\n\\nFor a more complete description of \", \"the challenges in this space, including how messages with\\npotentially incorrect data can end up bein\", \"g published, see Data platform for mission-critical\\n\\nworkloads on Azure: Every message must be proce\", \"ssed.\\n\\nAdditional topics to consider when using asynchronous communication are message idempotence\\na\", \"nd message deduplication. These topics are covered in the section Implementing event-based\\n\\ncommunic\", \"ation between microservices (integration events) later in this guide.\\n\\nAdditional resources\\n\\n\\u00b0 Event\", \" Driven Messaging\\n\\nhttps://patterns.arcitura.com/soa-patterns/design patterns/event driven messaging\", \"\\n\\n\\u00b0 Publish/Subscribe Channel\\n\\nhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/Publ\", \"ishSubscribeChannel.\\nhtml\\n\\n\\u00b0 Udi Dahan. Clarified CQRS\\nhttps://udidahan.com/2009/12/09/clarified-caq\", \"rs/\\n\\n. Command and Query Responsibility Segregation (CQRS)\\nhttps://learn.microsoft.com/azure/archite\", \"cture/patterns/caqrs\\n\\n. Communicating Between Bounded Contexts\\n\\n. Eventual consistency\\n\\nhttps://en.w\", \"ikipedia.org/wiki/Eventual consistency\\n\\n\\u00b0 Jimmy Bogard. Refactoring Towards Resilience: Evaluating C\", \"oupling\\nhttos://limmybogard.com/refactoring-towards-resilience-evaluating-couplin\\n\\n58 CHAPTER 3 | Ar\", \"chitecting container and microservice-based applications\\nCreating, evolving, and versioning microser\", \"vice APIs\\nand contracts\\n\\nA microservice API is a contract between the service and its clients. You'l\", \"l be able to evolve a\\nmicroservice independently only if you do not break its API contract, which is\", \" why the contract is so\\nimportant. If you change the contract, it will impact your client applicatio\", \"ns or your API Gateway.\\n\\nThe nature of the API definition depends on which protocol you're using. Fo\", \"r instance, if you're using\\nmessaging, like AMQP, the API consists of the message types. If you're u\", \"sing HTTP and RESTful\\nservices, the API consists of the URLs and the request and response JSON forma\", \"ts.\\n\\nHowever, even if you're thoughtful about your initial contract, a service API will need to chan\", \"ge over\\ntime. When that happens\\u2014and especially if your API is a public API consumed by multiple clie\", \"nt\\napplications \\u2014 you typically can\\u2019t force all clients to upgrade to your new API contract. You usu\", \"ally\\nneed to incrementally deploy new versions of a service in a way that both old and new versions \", \"of a\\nservice contract are running simultaneously. Therefore, it's important to have a strategy for y\", \"our\\nservice versioning.\\n\\nWhen the API changes are small, like if you add attributes or parameters to\", \" your API, clients that use\\nan older API should switch and work with the new version of the service.\", \" You might be able to provide\\ndefault values for any missing attributes that are required, and the c\", \"lients might be able to ignore any\\nextra response attributes.\\n\\nHowever, sometimes you need to make m\", \"ajor and incompatible changes to a service API. Because\\nyou might not be able to force client applic\", \"ations or services to upgrade immediately to the new\\nversion, a service must support older versions \", \"of the API for some period. If you're using an HTTP-\\nbased mechanism such as REST, one approach is t\", \"o embed the API version number in the URL or into\\nan HTTP header. Then you can decide between implem\", \"enting both versions of the service\\nsimultaneously within the same service instance, or deploying di\", \"fferent instances that each handle a\\nversion of the API. A good approach for this functionality is t\", \"he Mediator pattern (for example,\\nMediatR library) to decouple the different implementation versions\", \" into independent handlers.\\n\\nFinally, if you're using a REST architecture, Hypermedia is the best so\", \"lution for versioning your services\\nand allowing evolvable APIs.\\n\\nAdditional resources\\n\\n. Scott Hans\", \"elman. ASP.NET Core RESTful Web API versioning made easy\\nhttps://www.hanselman.com/blog/ASPNETCoreRE\", \"STfulWebAPIVersioningMadeEasy.aspx\\n\\n\\u00b0 Versioning a RESTful web API\\nhttos://learn.microsoft.com/azure\", \"/architecture/best-practices/api-design#versioning-a-\\n\\nrestful-web-api\\n\\n\\u00b0 Roy Fielding. Versioning, \", \"Hypermedia, and REST\\n\\nhttos://www.infog.com/articles/roy-fielding-on-versionin\\n\\n59 CHAPTER 3 | Archi\", \"tecting container and microservice-based applications\\nMicroservices addressability and the service r\", \"egistry\\n\\nEach microservice has a unique name (URL) that\\u2019s used to resolve its location. Your microse\", \"rvice needs\\nto be addressable wherever it\\u2019s running. If you have to think about which computer Is ru\", \"nning a\\nparticular microservice, things can go bad quickly. In the same way that DNS resolves a URL \", \"to a\\nparticular computer, your microservice needs to have a unique name so that its current location\", \" is\\ndiscoverable. Microservices need addressable names that make them independent from the\\ninfrastru\", \"cture that they're running on. This approach implies that there's an interaction between how\\nyour se\", \"rvice is deployed and how it's discovered, because there needs to be a service registry. In the\\nsame\", \" vein, when a computer fails, the registry service must be able to indicate where the service is\\nnow\", \" running.\\n\\nThe service registry pattern is a key part of service discovery. The registry is a databa\", \"se containing the\\nnetwork locations of service instances. A service registry needs to be highly avai\", \"lable and up-to-date.\\nClients could cache network locations obtained from the service registry. Howe\", \"ver, that information\\neventually goes out of date and clients can no longer discover service instanc\", \"es. So, a service registry\\nconsists of a cluster of servers that use a replication protocol to maint\", \"ain consistency.\\n\\nIn some microservice deployment environments (called clusters, to be covered in a \", \"later section),\\nservice discovery is built in. For example, an Azure Kubernetes Service (AKS) enviro\", \"nment can handle\\nservice instance registration and deregistration. It also runs a proxy on each clus\", \"ter host that plays the\\nrole of server-side discovery router.\\n\\nAdditional resources\\n\\n. Chris Richard\", \"son. Pattern: Service registry\\n\\nhttps://microservices.io/patterns/service-registry.html\\n\\n. Auth0O. T\", \"he Service Registry\\nhttps://auth0O.com/blog/an-introduction-to-microservices-part-3-the-service-regi\", \"str\\n\\n\\u00b0 Gabriel Schenker. Service discovery\\n\\nhttps://lostechies.com/gabrielschenker/2016/01/27/servic\", \"e-discovery/\\n\\nCreating composite Ul based on microservices\\n\\nMicroservices architecture often starts \", \"with the server-side handling data and logic, but, in many\\ncases, the Ul is still handled as a monol\", \"ith. However, a more advanced approach, called micro\\nfrontends, is to design your application UI bas\", \"ed on microservices as well. That means having a\\ncomposite UI produced by the microservices, instead\", \" of having microservices on the server and just a\\nmonolithic client app consuming the microservices.\", \" With this approach, the microservices you build\\ncan be complete with both logic and visual represen\", \"tation.\\n\\nFigure 4-20 shows the simpler approach of just consuming microservices from a monolithic cl\", \"ient\\napplication. Of course, you could have an ASP.NET MVC service in between producing the HTML and\", \"\\nJavaScript. The figure is a simplification that highlights that you have a single (monolithic) clie\", \"nt UI\\n\\n60 CHAPTER 3 | Architecting container and microservice-based applications\\nconsuming the micro\", \"services, which just focus on logic and data and not on the UI shape (HTML and\\nJavaScript).\\n\\nMonolit\", \"hic Ul consuming microservices\\n\\nMonolithic Uk: Visual layout,\\n\\nshapes and styles are defined in\\n\\n| t\", \"he client app, and don't depend\\n\\n\\u2018on the microservices y,\\n\\u2018\\u201c\\n\\n|\\n/\\n\\nSm ee ee ee ee ee ae ae ee\\n\\n~~ Le\", \"\\n\\n| Microservices |\\nTr ae CI ( Microservice 1 \\\\ |\\n/ Monolithic UI \\\\ I | Web API | I\\n| | | |\\n| | | |\\n\", \"! | container) I\\n| |\\n| a |\\n| ( Microservice 2 |\\n| | : Web API |\\n| |\\n| | | | I\\ncontainer )\\n| | \\\\ / |\\n\", \"| |\\n|\\n\\nFigure 4-20. A monolithic Ul application consuming back-end microservices\\n\\nIn contrast, a com\", \"posite UI is precisely generated and composed by the microservices themselves.\\nSome of the microserv\", \"ices drive the visual shape of specific areas of the UI. The key difference is that\\nyou have client \", \"Ul components (TypeScript classes, for example) based on templates, and the data-\\nshaping-UI ViewMod\", \"el for those templates comes from each microservice.\\n\\nAt client application start-up time, each of t\", \"he client Ul components (TypeScript classes, for example)\\nregisters itself with an infrastructure mi\", \"croservice capable of providing ViewModels for a given\\nscenario. If the microservice changes the sha\", \"pe, the UI changes also.\\n\\nFigure 4-21 shows a version of this composite Ul approach. This approach i\", \"s simplified because you\\nmight have other microservices that are aggregating granular parts that are\", \" based on different\\ntechniques. It depends on whether you're building a traditional web approach (AS\", \"P.NET MVC) or an\\nSPA (Single Page Application).\\n\\n61 CHAPTER 3 | Architecting container and microserv\", \"ice-based applications\\nComposite Ul generated by microservices\\n\\n~oomororornrenr er eee ee ee eee eee\", \" ee er\\n\\n- ~ a = = a el \\u2014 as = = = = = = = \\u2014 a =\\na\\u201c Ld \\u201c o e\\n/ Composite UI \\u2018\\\\ i Backend Microservice\", \"s |\\n/ NC Fe een\\ni a Fo UI Composition > JSON ( CY |\\n\\u2014_= se Microservice 1 NOs p\\u2014-\\u2014\\u2014\\u2014-\\u2014\\u2014\\u2014\\u2014 =---\\\\ K ) \", \"| |\\n| UI Composition \\\\ | 1 |\\nMicroservice 2 | | Ki |\\n|\\n| | @~  & & @ 8 8 *s 26% G =] Composed S\\u2014\\u2014\\u2014\\u2014 \", \"romaine __ 1 |\\nae ee ee ccna ss |\\n| UI Composition S |\\n| Microservice3 | D/Os ~_______ a | \\u2018|\\n| Key \", \"( UlComposition | | Other internal |\\n| a ; Microservice 4 | microservices \\u2018|\\n| S_-_ Lontainer || |\\n|\", \" Li,\\n| Award wiene Boo Compose \\\\ ) | Key |\\n| ViewMod \\u201c~\\\"l Composition \\u00bb eee 7 |\\n| = _ | ( omposition\", \" | json | i]\\n| == Microservice 5 DIOs  L ~. | Key |\\n. \\u2014_ \\u00ab_lompostd__| | eas \\\\ |\\n~otenm the Morh Cot\", \"ebrity Picks Recommended Spring Amazon Book Rewew YiewMoge! Key | he Pree iC) | | |\\nfremont & thee .\", \" a renee = icroservice\\ni - Sen ot Bee at Cottrty Moke \\u201d ote ci a A 4 |\\n\\\\ | | ow\\n\\\\ BEES / Compodd \\\\ \\\\\", \" () }\\nNS _7\\u201d ViewModgel \\\\------\\u2014--\\u2014---- 4 Sw - l\\nSS moe\\n\\nFigure 4-27. Example of a composite Ul! app\", \"lication shaped by back-end microservices\\n\\nEach of those Ul composition microservices would be simil\", \"ar to a small API Gateway. But in this case,\\neach one is responsible for a small Ul area.\\n\\nA composi\", \"te UI approach that\\u2019s driven by microservices can be more challenging or less so,\\ndepending on what \", \"UI technologies you're using. For instance, you won't use the same techniques for\\nbuilding a traditi\", \"onal web application that you use for building an SPA or for native mobile app (as\\nwhen developing X\", \"amarin apps, which can be more challenging for this approach).\\n\\nThe eShopOnContainers sample applica\", \"tion uses the monolithic Ul approach for multiple reasons.\\nFirst, it's an introduction to microservi\", \"ces and containers. A composite UI is more advanced but also\\nrequires further complexity when design\", \"ing and developing the UI. Second, eshopOnContainers also\\nprovides a native mobile app based on Xama\", \"rin, which would make it more complex on the client C#\\nside.\\n\\nHowever, we encourage you to use the f\", \"ollowing references to learn more about composite UI based\\non microservices.\\n\\nAdditional resources\\n\\n\", \". Micro Frontends (Martin Fowler\\u2019s blog)\\n\\nhttps://martinfowler.com/articles/micro-frontends.html\\n\\n\\u00b0 \", \"Micro Frontends (Michael Geers site)\\n\\nhttps://micro-frontends.org/\\n\\n. Composite UI using ASP.NET (Pa\", \"rticular\\u2019s Workshop)\\nhttps://github.com/Particular/Workshop/tree/master/demos/asp-net-core\\n\\n. Ruben \", \"Oostinga. The Monolithic Frontend in the Microservices Architecture\\nhttps://xebia.com/blog/the-monol\", \"ithic-frontend-in-the-microservices-architecture\\n\\n62 CHAPTER 3 | Architecting container and microser\", \"vice-based applications\\n\\u00b0 Mauro Servienti. The secret of better Ul composition\\n\\nhttps://particular.n\", \"et/blog/secret-of-better-ui-composition\\n\\n\\u00b0 Viktor Farcic. Including Front-End Web Components Into Mi\", \"croservices\\n\\nhttps://technologyconversations.com/2015/08/09/including-front-end-web-components-\\ninto\", \"-microservices/\\n\\n. Managing Frontend in the Microservices Architecture\\nhttps://allegro.tech/2016/03/\", \"Managing-Frontend-in-the-microservices-architecture.html\\n\\nResiliency and high availability in micros\", \"ervices\\n\\nDealing with unexpected failures is one of the hardest problems to solve, especially in a d\", \"istributed\\n\\nsystem. Much of the code that developers write involves handling exceptions, and this is\", \" also where\\nthe most time is spent in testing. The problem is more involved than writing code to han\", \"dle failures.\\nWhat happens when the machine where the microservice is running fails? Not only do you\", \" need to\\n\\ndetect this microservice failure (a hard problem on its own), but you also need something \", \"to restart\\nyour microservice.\\n\\nA microservice needs to be resilient to failures and to be able to re\", \"start often on another machine for\\navailability. This resiliency also comes down to the state that w\", \"as saved on behalf of the microservice,\\nwhere the microservice can recover this state from, and whet\", \"her the microservice can restart\\nsuccessfully. In other words, there needs to be resiliency in the c\", \"ompute capability (the process can\\nrestart at any time) as well as resilience in the state or data (\", \"no data loss, and the data remains\\nconsistent).\\n\\nThe problems of resiliency are compounded during ot\", \"her scenarios, such as when failures occur\\nduring an application upgrade. The microservice, working \", \"with the deployment system, needs to\\ndetermine whether it can continue to move forward to the newer \", \"version or instead roll back to a\\nprevious version to maintain a consistent state. Questions such as\", \" whether enough machines are\\navailable to keep moving forward and how to recover previous versions o\", \"f the microservice need to\\nbe considered. This approach requires the microservice to emit health inf\", \"ormation so that the overall\\napplication and orchestrator can make these decisions.\\n\\nIn addition, re\", \"siliency is related to how cloud-based systems must behave. As mentioned, a cloud-\\nbased system must\", \" embrace failures and must try to automatically recover from them. For instance, in\\ncase of network \", \"or container failures, client apps or client services must have a strategy to retry\\nsending messages\", \" or to retry requests, since in many cases failures in the cloud are partial. The\\nImplementing Resil\", \"ient Applications section in this guide addresses how to handle partial failure. It\\ndescribes techni\", \"ques like retries with exponential backoff or the Circuit Breaker pattern in .NET by\\nusing libraries\", \" like Polly, which offers a large variety of policies to handle this subject.\\n\\nHealth management and\", \" diagnostics in microservices\\n\\nIt may seem obvious, and it's often overlooked, but a microservice mu\", \"st report its health and\\ndiagnostics. Otherwise, there\\u2019s little insight from an operations perspecti\", \"ve. Correlating diagnostic\\nevents across a set of independent services and dealing with machine cloc\", \"k skews to make sense of\\n\\n63 CHAPTER 3 | Architecting container and microservice-based applications\\n\", \"the event order is challenging. In the same way that you interact with a microservice over agreed-\\nu\", \"pon protocols and data formats, there\\u2019s a need for standardization in how to log health and\\ndiagnost\", \"ic events that ultimately end up in an event store for querying and viewing. In a microservices\\nappr\", \"oach, it\\u2019s key that different teams agree on a single logging format. There needs to be a\\nconsistent\", \" approach to viewing diagnostic events in the application.\\n\\nHealth checks\\n\\nHealth is different from \", \"diagnostics. Health is about the microservice reporting its current state to take\\nappropriate action\", \"s. A good example is working with upgrade and deployment mechanisms to\\nmaintain availability. Althou\", \"gh a service might currently be unhealthy due to a process crash or\\nmachine reboot, the service migh\", \"t still be operational. The last thing you need is to make this worse\\nby performing an upgrade. The \", \"best approach is to do an investigation first or allow time for the\\nmicroservice to recover. Health \", \"events from a microservice help us make informed decisions and, in\\neffect, help create self-healing \", \"services.\\n\\nIn the Implementing health checks in ASP.NET Core services section of this guide, we expl\", \"ain how to\\nuse a new ASP.NET HealthChecks library in your microservices so they can report their sta\", \"te to a\\n\\nmonitoring service to take appropriate actions.\\n\\nYou also have the option of using an excel\", \"lent open-source library called\\nAspNetCore.Diagnostics.HealthChecks, available on GitHub and as a Nu\", \"Get package. This library also\\ndoes health checks, with a twist, it handles two types of checks:\\n\\n. \", \"Liveness: Checks if the microservice is alive, that Is, if it's able to accept requests and respond.\", \"\\n\\n. Readiness: Checks if the microservice\\u2019s dependencies (Database, queue services, etc.) are\\nthemse\", \"lves ready, so the microservice can do what it\\u2019s supposed to do.\\n\\nUsing diagnostics and logs event s\", \"treams\\n\\nLogs provide information about how an application or service is running, including exception\", \"s,\\nwarnings, and simple informational messages. Usually, each log is in a text format with one line \", \"per\\nevent, although exceptions also often show the stack trace across multiple lines.\\n\\nIn monolithic\", \" server-based applications, you can write logs to a file on disk (a logfile) and then analyze\\nit wit\", \"h any tool. Since application execution is limited to a fixed server or VM, it generally isn't too\\nc\", \"omplex to analyze the flow of events. However, in a distributed application where multiple services\\n\", \"are executed across many nodes in an orchestrator cluster, being able to correlate distributed event\", \"s\\nis a challenge.\\n\\nA microservice-based application should not try to store the output stream of eve\", \"nts or logfiles by\\nitself, and not even try to manage the routing of the events to a central place. \", \"It should be\\ntransparent, meaning that each process should just write its event stream to a standard\", \" output that\\nunderneath will be collected by the execution environment infrastructure where it\\u2019s run\", \"ning. An\\nexample of these event stream routers is Microsoft.Diagnostic.EventFlow, which collects eve\", \"nt streams\\nfrom multiple sources and publishes it to output systems. These can include simple standa\", \"rd output\\nfor a development environment or cloud systems like Azure Monitor and Azure Diagnostics. T\", \"here are\\nalso good third-party log analysis platforms and tools that can search, alert, report, and \", \"monitor logs,\\neven in real time, like Splunk.\\n\\n64 CHAPTER 3 | Architecting container and microservic\", \"e-based applications\\nOrchestrators managing health and diagnostics information\\n\\nWhen you create a mi\", \"croservice-based application, you need to deal with complexity. Of course, a\\nsingle microservice Is \", \"simple to deal with, but dozens or hundreds of types and thousands of\\ninstances of microservices is \", \"a complex problem. It isn\\u2019t just about building your microservice\\narchitecture\\u2014you also need high av\", \"ailability, addressability, resiliency, health, and diagnostics if you\\nintend to have a stable and c\", \"ohesive system.\\n\\nYour microservices\\n@,0\\u00b0)70,0\\u00b0:)7e,6\\u00b0)7e\\n@, 00> alae pene\\n\\nLifecycle Independent Ind\", \"ependent Always On Resource  Stateless/\\n\\nMgmt Scaling Updates Availability Efficient Stateful\\n\\nMicro\", \"service Platform\\n\\n(Orchestrators/Clusters)\\n\\nFigure 4-22. A Microservice Platform is fundamental for \", \"an application's health management\\n\\nThe complex problems shown in Figure 4-22 are hard to solve by y\", \"ourself. Development teams should\\nfocus on solving business problems and building custom application\", \"s with microservice-based\\napproaches. They should not focus on solving complex infrastructure proble\", \"ms; if they did, the cost of\\nany microservice-based application would be huge. Therefore, there are \", \"microservice-oriented\\nplatforms, referred to as orchestrators or microservice clusters, that try to \", \"solve the hard problems of\\nbuilding and running a service and using infrastructure resources efficie\", \"ntly. This approach reduces\\nthe complexities of building applications that use a microservices appro\", \"ach.\\n\\nDifferent orchestrators might sound similar, but the diagnostics and health checks offered by \", \"each of\\nthem differ in features and state of maturity, sometimes depending on the OS platform, as ex\", \"plained\\nin the next section.\\n\\nAdditional resources\\n\\n\\u00b0 The Twelve-Factor App. XI. Logs: Treat logs as\", \" event streams\\n\\nhttps://12factor.net/logs\\n\\n. Microsoft Diagnostic EventFlow Library GitHub repo.\\nhtt\", \"ps://github.com/Azure/diagnostics-eventflow\\n\\n. What is Azure Diagnostics\\n\\nhttps://learn.microsoft.co\", \"m/azure/azure-diagnostics\\n\\n65 CHAPTER 3 | Architecting container and microservice-based applications\", \"\\n. Connect Windows computers to the Azure Monitor service\\n\\nhttps://learn.microsoft.com/azure/azure-m\", \"onitor/platform/agent-windows\\n\\u00b0 Logging What You Mean: Using the Semantic Logging Application Block\\n\", \"\\n. Splunk Official site.\\nhttps://www.splunk.com/\\n\\n\\u00b0 EventSource Class API for events tracing for Win\", \"dows (ETW)\\n\\nhttps://learn.microsoft.com/dotnet/api/system.diagnostics.tracing.eventsource\\n\\nOrchestra\", \"te microservices and multi-container\\napplications for high scalability and availability\\n\\nUsing orche\", \"strators for production-ready applications is essential if your application is based on\\nmicroservice\", \"s or simply split across multiple containers. As introduced previously, in a microservice-\\nbased app\", \"roach, each microservice owns its model and data so that it will be autonomous from a\\ndevelopment an\", \"d deployment point of view. But even if you have a more traditional application that\\u2019s\\ncomposed of m\", \"ultiple services (like SOA), you'll also have multiple containers or services comprising a\\nsingle bu\", \"siness application that need to be deployed as a distributed system. These kinds of systems\\nare comp\", \"lex to scale out and manage; therefore, you absolutely need an orchestrator if you want to\\nhave a pr\", \"oduction-ready and scalable multi-container application.\\n\\nFigure 4-23 illustrates deployment into a \", \"cluster of an application composed of multiple microservices\\n(containers).\\n\\n66 CHAPTER 3 | Architect\", \"ing container and microservice-based applications\\nComposed Docker Applications in a Cluster\\n\\n* For e\", \"ach service instance you use one container APPT \\u2014 My Docker Images\\n* Docker images/containers are \\u201cu\", \"nits of deployment\\u201d\\n\\n(\\n* A container is an instance of a Docker Image | @ \\u00ae <=> Key Key rey\\n* A host\", \" (VM/server) handles many containers e it @ Key re) Key\\n\\nServices /\\nof\\naan\\na | OF Official Docker Im\", \"ages\\nwie https://hub.docker.com\\n\\nA node A\\nol ees rena ao\\nContainers\\n\\nA Kou Ker a:\\nLs kon\\nal\\n\\nCluster\", \" of\\n\\nFigure 4-23. A cluster of containers\\n\\nYou use one container for each service instance. Docker c\", \"ontainers are \\u201cunits of deployment\\u201d and a\\ncontainer is an instance of a Docker. A host handles many \", \"containers. It looks like a logical approach.\\nBut how are you handling load-balancing, routing, and \", \"orchestrating these composed applications?\\n\\nThe plain Docker Engine in single Docker hosts meets the\", \" needs of managing single image instances\\non one host, but it falls short when it comes to managing \", \"multiple containers deployed on multiple\\nhosts for more complex distributed applications. In most ca\", \"ses, you need a management platform\\nthat will automatically start containers, scale out containers w\", \"ith multiple instances per image,\\nsuspend them or shut them down when needed, and ideally also contr\", \"ol how they access resources\\nlike the network and data storage.\\n\\nTo go beyond the management of indi\", \"vidual containers or simple composed apps and move toward\\nlarger enterprise applications with micros\", \"ervices, you must turn to orchestration and clustering\\nplatforms.\\n\\nFrom an architecture and developm\", \"ent point of view, if you're building large enterprise composed of\\nmicroservices-based applications,\", \" it's important to understand the following platforms and products\\nthat support advanced scenarios:\\n\", \"\\nClusters and orchestrators. When you need to scale out applications across many Docker hosts, as\\nwh\", \"en a large microservice-based application, it\\u2019s critical to be able to manage all those hosts as a\\ns\", \"ingle cluster by abstracting the complexity of the underlying platform. That\\u2019s what the container\\ncl\", \"usters and orchestrators provide. Kubernetes is an example of an orchestrator, and is available in\\nA\", \"zure through Azure Kubernetes Service.\\n\\nSchedulers. Scheduling means to have the capability for an a\", \"dministrator to launch containers in a\\ncluster so they also provide a UI. A cluster scheduler has se\", \"veral responsibilities: to use the cluster\\u2019s\\n\\n67 CHAPTER 3 | Architecting container and microservice\", \"-based applications\\nresources efficiently, to set the constraints provided by the user, to efficient\", \"ly load-balance containers\\nacross nodes or hosts, and to be robust against errors while providing hi\", \"gh availability.\\n\\nThe concepts of a cluster and a scheduler are closely related, so the products pro\", \"vided by different\\nvendors often provide both sets of capabilities. The following list shows the mos\", \"t important platform\\nand software choices you have for clusters and schedulers. These orchestrators \", \"are generally offered\\nin public clouds like Azure.\\n\\nSoftware platforms for container clustering, orc\", \"hestration, and\\n\\nscheduling\\n\\nKubernetes Kubernetes is an open-source\\nproduct that provides functiona\", \"lity\\net that ranges from cluster\\ninfrastructure and container\\nscheduling to orchestrating\\ncapabiliti\", \"es. It lets you automate\\ndeployment, scaling, and\\n\\noperations of application\\ncontainers across clust\", \"ers of hosts.\\n\\nKubernetes provides a container-\\ncentric infrastructure that groups\\napplication conta\", \"iners into logical\\nunits for easy Management and\\ndiscovery.\\n\\nKubernetes is mature in Linux, less\\nmat\", \"ure in Windows.\\n\\nAzure Kubernetes Service (AKS) AKS is a managed Kubernetes\\n| il} container orchestr\", \"ation service In\\n1 Ob oe Azure that simplifies Kubernetes\\n| il cluster\\u2019s management, deployment,\\nand\", \" operations.\\n\\nAzure Container Apps Azure Container Apps is a managed\\nserverless container service fo\", \"r\\nbuilding and deploying modern\\napps at scale.\\n\\nUsing container-based orchestrators in Microsoft Azu\", \"re\\n\\nSeveral cloud vendors offer Docker containers support plus Docker clusters and orchestration sup\", \"port,\\nincluding Microsoft Azure, Amazon EC2 Container Service, and Google Container Engine. Microsof\", \"t\\nAzure provides Docker cluster and orchestrator support through Azure Kubernetes Service (AKS).\\n\\n68\", \" CHAPTER 3 | Architecting container and microservice-based applications\\nUsing Azure Kubernetes Servi\", \"ce\\n\\nA Kubernetes cluster pools multiple Docker hosts and exposes them as a single virtual Docker hos\", \"t, so\\nyou can deploy multiple containers into the cluster and scale-out with any number of container\", \"\\ninstances. The cluster will handle all the complex management plumbing, like scalability, health, a\", \"nd\\nso forth.\\n\\nAKS provides a way to simplify the creation, configuration, and management of a cluste\", \"r of virtual\\nmachines in Azure that are preconfigured to run containerized applications. Using an op\", \"timized\\nconfiguration of popular open-source scheduling and orchestration tools, AKS enables you to \", \"use\\nyour existing skills or draw on a large and growing body of community expertise to deploy and\\nma\", \"nage container-based applications on Microsoft Azure.\\n\\nAzure Kubernetes Service optimizes the config\", \"uration of popular Docker clustering open-source tools\\nand technologies specifically for Azure. You \", \"get an open solution that offers portability for both your\\ncontainers and your application configura\", \"tion. You select the size, the number of hosts, and the\\norchestrator tools, and AKS handles everythi\", \"ng else.\\n\\n> Op\\n\\nAKS  Kubernetes\\n\\n- DNS\\n- Scheduler\\n- Proxy\\n- Ete, ;\\nKubernetes\\ncluster | | | . |\\n\\nFi\", \"gure 4-24. Kubernetes cluster's simplified structure and topology\\n\\n69 CHAPTER 3 | Architecting conta\", \"iner and microservice-based applications\\nIn figure 4-24, you can see the structure of a Kubernetes c\", \"luster where a master node (VM) controls\\nmost of the coordination of the cluster and you can deploy \", \"containers to the rest of the nodes, which\\nare managed as a single pool from an application point of\", \" view and allows you to scale to thousands\\nor even tens of thousands of containers.\\n\\nDevelopment env\", \"ironment for Kubernetes\\n\\nIn the development environment, Docker announced in July 2018 that Kubernet\", \"es can also run ina\\nsingle development machine (Windows 10 or macOS) by installing Docker Desktop. Y\", \"ou can later\\ndeploy to the cloud (AKS) for further integration tests, as shown in figure 4-25.\\n\\nDock\", \"er Registry\\n\\nMA Azure\\n\\nAzure Kubernetes Service (AKS)\\n\\n[J\\n\\nDocker Image\\nRepository\\n\\nPC/Development E\", \"nvironment Racker Hab \\u201cManaged Kubernetes\\u201d for production\\nWindows 10 or macOS Or AR\\n\\u2018Docker Desktop\\u2019\", \" with . on B\\nlocal-dev Kubernetes cluster ii) il)\\nAKS Kubernetes\\ndocker build\\nLocal docker push = ac\", \"e)\\n\\n\\u2014 ais\\n\\nKubernetes \\u2018\\n\\nme\\n\\nLocal-dev\\nSB. Kubernetes cluster\\n\\njode\\n\\nFigure 4-25. Running Kubernetes\", \" in dev machine and the cloud\\n\\nGetting started with Azure Kubernetes Service (AKS)\\n\\nTo begin using A\", \"KS, you deploy an AKS cluster from the Azure portal or by using the CLI. For more\\ninformation on dep\", \"loying a Kubernetes cluster in Azure, see Deploy an Azure Kubernetes Service\\n(AKS) cluster.\\n\\nThere a\", \"re no fees for any of the software installed by default as part of AKS. All default options are\\nimpl\", \"emented with open-source software. AKS is available for multiple virtual machines in Azure.\\nYou're c\", \"harged only for the compute instances you choose, and the other underlying infrastructure\\nresources \", \"consumed, such as storage and networking. There are no incremental charges for AKS itself.\\n\\nThe defa\", \"ult production deployment option for Kubernetes is to use Helm charts, which are introduced\\nin the n\", \"ext section.\\n\\n70 CHAPTER 3 | Architecting container and microservice-based applications\\nDeploy with \", \"Helm charts into Kubernetes clusters\\n\\nWhen deploying an application to a Kubernetes cluster, you can\", \" use the original kubectl.exe CLI tool\\nusing deployment files based on the native format (.yaml file\", \"s), as already mentioned in the previous\\nsection. However, for more complex Kubernetes applications \", \"such as when deploying complex\\nmicroservice-based applications, it's recommended to use Helm.\\n\\nHelm \", \"Charts helps you define, version, install, share, upgrade, or rollback even the most complex\\nKuberne\", \"tes application.\\n\\nGoing further, Helm usage is also recommended because other Kubernetes environment\", \"s in Azure,\\nsuch as Azure Dev Spaces are also based on Helm charts.\\n\\nHelm is maintained by the Cloud\", \" Native Computing Foundation (CNCF) - in collaboration with\\n\\nMicrosoft, Google, Bitnami, and the Hel\", \"m contributor community.\\n\\nFor more implementation information on Helm charts and Kubernetes, see the\", \" Using Helm Charts to\\ndeploy eShopOnContainers to AKS post.\\n\\nAdditional resources\\n\\n\\u00b0 Getting started\", \" with Azure Kubernetes Service (AKS)\\n\\nhttps://learn.microsoft.com/azure/aks/kubernetes-walkthrough-p\", \"ortal\\n\\n. Azure Dev Spaces\\n\\nhttps://learn.microsoft.com/azure/dev-spaces/azure-dev-spaces\\n\\n\\u00b0 Kubernet\", \"es The official site.\\n\\nhttps://kubernetes.io/\\n\\n71 CHAPTER 3 | Architecting container and microservic\", \"e-based applications\\nCHAPTER |\\n\\nDevelopment process for\\nDocker-based applications\\n\\nDevelop container\", \"ized .NET applications the way you like, either Integrated Development Environment\\n(IDE) focused wit\", \"h Visual Studio and Visual Studio tools for Docker or CLI/Editor focused with Docker CLI\\nand Visual \", \"Studio Code.\\n\\nDevelopment environment for Docker apps\\n\\nDevelopment tool choices: IDE or editor\\n\\nWhet\", \"her you prefer a full and powerful IDE or a lightweight and agile editor, Microsoft has tools that\\ny\", \"ou can use for developing Docker applications.\\n\\nVisual Studio (for Windows). Docker-based .NET 7 app\", \"lication development with Visual Studio\\nrequires Visual Studio 2022 version 17.0 or later. Visual St\", \"udio 2022 comes with tools for Docker\\nalready built in. The tools for Docker let you develop, run, a\", \"nd validate your applications directly in the\\ntarget Docker environment. You can press F5 to run and\", \" debug your application (single container or\\nmultiple containers) directly into a Docker host, or pr\", \"ess CTRL + F5 to edit and refresh your\\napplication without having to rebuild the container. This IDE\", \" is the most powerful development choice\\nfor Docker-based apps.\\n\\nVisual Studio for Mac. It's an IDE,\", \" evolution of Xamarin Studio, running in macOS. This tool should\\nbe the preferred choice for develop\", \"ers working in macOS machines who also want to use a powerful\\nIDE.\\n\\nVisual Studio Code and Docker CL\", \"I. If you prefer a lightweight and cross-platform editor that\\nsupports any development language, you\", \" can use Visual Studio Code and the Docker CLI. This IDE is a\\ncross-platform development approach fo\", \"r macOS, Linux, and Windows. Additionally, Visual Studio\\nCode supports extensions for Docker such as\", \" Intellisense for Dockerfiles and shortcut tasks to run\\nDocker commands from the editor.\\n\\nBy install\", \"ing Docker Desktop, you can use a single Docker CLI to build apps for both Windows and\\nLinux.\\n\\n72 CH\", \"APTER 4 | Development process for Docker-based applications\\nAdditional resources\\n\\n\\u00b0 Visual Studio. O\", \"fficial site.\\nhttps://visualstudio.microsoft.com/vs/\\n\\n\\u00b0 Visual Studio Code. Official site.\\nhttps://c\", \"ode.visualstudio.com/download\\n\\n. Docker Desktop for Windows\\nhttps://hub.docker.com/editions/communit\", \"y/docker-ce-desktop-windows\\n\\n. Docker Desktop for Mac\\nhttps://hub.docker.com/editions/community/dock\", \"er-ce-desktop-mac\\n\\n.NET languages and frameworks for Docker\\ncontainers\\n\\nAs mentioned in earlier sect\", \"ions of this guide, you can use .NET Framework, .NET 7, or the open-\\nsource Mono project when develo\", \"ping Docker containerized .NET applications. You can develop in\\nC#, F#, or Visual Basic when targeti\", \"ng Linux or Windows Containers, depending on which .NET\\nframework is in use. For more details about.\", \"NET languages, see the blog post The .NET Language\\n\\nStrategy.\\n\\nDevelopment workflow for Docker apps\\n\", \"\\nThe application development life cycle starts at your computer, as a developer, where you code the\\n\", \"application using your preferred language and test it locally. With this workflow, no matter which\\nl\", \"anguage, framework, and platform you choose, you're always developing and testing Docker\\ncontainers,\", \" but doing so locally.\\n\\nEach container (an instance of a Docker image) includes the following compon\", \"ents:\\n\\n\\u00b0 An operating system selection, for example, a Linux distribution, Windows Nano Server, or\\nW\", \"indows Server Core.\\n\\n. Files added during development, for example, source code and application bina\", \"ries.\\n\\n. Configuration information, such as environment settings and dependencies.\\n\\nWorkflow for dev\", \"eloping Docker container-based applications\\n\\nThis section describes the inner-loop development workf\", \"low for Docker container-based applications.\\nThe inner-loop workflow means it's not considering the \", \"broader DevOps workflow, which can include\\nup to production deployment, and just focuses on the deve\", \"lopment work done on the developer's\\ncomputer. The initial steps to set up the environment aren't in\", \"cluded, since those steps are done only\\nonce.\\n\\n73 CHAPTER 4 | Development process for Docker-based a\", \"pplications\\nAn application is composed of your own services plus additional libraries (dependencies)\", \". The\\nfollowing are the basic steps you usually take when building a Docker application, as illustra\", \"ted in\\nFigure 5-1.\\n\\nInner-Loop development workflow for Docker apps\\n\\n1. 2. 3. 4. (Opt.in)\\n\\nRun 6.\\n\\nW\", \"rite Create Images Define services\\nCode Dockerfile/s defined at | by writing Containers / Test\\nyour \", \"app Dockerfile/s docker-compose.ymi Compose app your app or\\n\\no cS microservices\\nMy My\\nCo ners\\n\\nhttp\\n\", \"1tT]\\nMy\\na |\\nLocal\\n\\naccess...\\nDocker\\nRepos\\n\\ndocker build\\n\\nBase TTT\\nImages\\n\\nRemote\\nDocker Registry\\n7. \", \"(i.e. Docker Hub)\\n\\ngit push Push or | [iis\\n\\n\\u2014\\u2014_- Continue\\n\\ndeveloping\\n\\nFigure 5-7. Step-by-step work\", \"flow for developing Docker containerized apps\\n\\nIn this section, this whole process is detailed and e\", \"very major step is explained by focusing on a Visual\\nStudio environment.\\n\\nWhen you're using an edito\", \"r/CLI development approach (for example, Visual Studio Code plus Docker\\nCLI on macOS or Windows), yo\", \"u need to know every step, generally in more detail than if you're using\\nVisual Studio. For more inf\", \"ormation about working in a CLI environment, see the e-book\\n\\nContainerized Docker Application lifecy\", \"cle with Microsoft Platforms and Tools.\\n\\nWhen you're using Visual Studio 2022, many of those steps a\", \"re handled for you, which dramatically\\nimproves your productivity. This is especially true when you'\", \"re using Visual Studio 2022 and targeting\\nmulti-container applications. For instance, with just one \", \"mouse click, Visual Studio adds the Dockerfile\\nand docker-compose.yml file to your projects with the\", \" configuration for your application. When you\\nrun the application in Visual Studio, it builds the Do\", \"cker image and runs the multi-container\\napplication directly in Docker; it even allows you to debug \", \"several containers at once. These features\\nwill boost your development speed.\\n\\nHowever, just because\", \" Visual Studio makes those steps automatic doesn\\u2019t mean that you don't need\\nto know what's going on \", \"underneath with Docker. Therefore, the following guidance details every\\nstep.\\n\\n74 CHAPTER 4 | Develo\", \"pment process for Docker-based applications\\n1.\\n\\nCode\\n\\nyour app\\n\\nDeveloping a Docker application is s\", \"imilar to the way you develop an application without Docker. The\\ndifference is that while developing\", \" for Docker, you're deploying and testing your application or\\nservices running within Docker contain\", \"ers in your local environment (either a Linux VM setup by\\nDocker or directly Windows if using Window\", \"s Containers).\\n\\nTo begin, make sure you have for Windows installed, as explained in the\\nfollowing in\", \"structions:\\n\\nIn addition, you need Visual Studio 2022 version 17.0, with the .ASP.NET and web develo\", \"pment\\nworkload installed, as shown in Figure 5-2.\\n\\nInstalling \\u2014 Visual Studio Enterprise 2022 \\u2014 17.0\", \".1\\nWorkloads _Individualcomponents Language packs _Installation locations\\n\\nWeb & Cloud (4) . ;\\nInsta\", \"llation details\\n\\n& ASP.NET and web development A Azure development \\u00bb |Visual Studio core editor\\nBuil\", \"d web applications using ASP.NET Core, ASP.NET, Azure SDKs, tools, and projects for developing cloud\", \" apps\\n\\nHTML/JavaScript, and Containers including Docker supp... and creating resources using .NET an\", \"d .NET Framework... > ASPNET and web development\\n\\ny Individual components\\n.NET 6.0 Runtime\\nPython de\", \"velopment Node.js development\\nEditing, debugging, interactive development and source Build scalable \", \"network applications using Node,js, an\\ncontrol for Python. asynchronous event-driven JavaScript runt\", \"ime.\\n\\nDesktop & Mobile (5)\\n\\nMobile development with .NET -NET desktop development\\nBuild cross-platfo\", \"rm applications for 10S, Android or Build WPF, Windows Forms, and console applications\\nWindows using\", \" Xamarin. using C#, Visual Basic, and F# with .NET and .NET Frame...\\n\\nDesktop development with C++ r\", \" || Universal Windows Platform development\\n\\u2018Op P pm\\n\\nBuild modem C++ apps for Windows using tools of\", \" your ea Create applications for the Universal Windows Platform\\nchoice, including MSVC, Clang, CMake\", \", or MSBuild. with C#, VB, or optionally C++.\\n\\nLocation\\nC:\\\\Program Files\\\\Microsoft Visual Studio\\\\202\", \"2\\\\Enterpnse Change...\\n\\nTotal space required 4.22 GB\\nBy continuing, you agree to the license for the \", \"Visual Studio edition you selected. We also offer the ability to download other software with Visual\", \" Studio.\\n\\nThis software is licensed separately, as set out in the 3rd Party Notices or in its accomp\", \"anying license. By continuing, you also agree to those licenses. Install while downloading | ~ Insta\", \"ll\\n\\nFigure 5-2. Selecting the ASP.NET and web development workload during Visual Studio 2022 setup\\n\\n\", \"You can start coding your application in plain .NET (usually in .NET Core or later if you're plannin\", \"g to\\nuse containers) even before enabling Docker in your application and deploying and testing in Do\", \"cker.\\nHowever, it is recommended that you start working on Docker as soon as possible, because that \", \"will\\nbe the real environment and any issues can be discovered as soon as possible. This is encourage\", \"d\\nbecause Visual Studio makes it so easy to work with Docker that it almost feels transparent\\u2014the be\", \"st\\nexample when debugging multi-container applications from Visual Studio.\\n\\nAdditional resources\\n\\n. \", \"Get started with Docker Desktop for Windows\\nhttps://docs.docker.com/docker-for-windows/\\n\\n\\u00b0 Visual St\", \"udio 2022\\nhttps://visualstudio.microsoft.com/downloads/\\n\\n2.\\nWrite\\nDockerfile's\\n\\n-\\\"\\n\\nStep 2. Create a\", \" Dockerfile related to an existing .NET base image\\n\\nYou need a Dockerfile for each custom image you \", \"want to build; you also need a Dockerfile for each\\ncontainer to be deployed, whether you deploy auto\", \"matically from Visual Studio or manually using the\\nDocker CLI (docker run and docker-compose command\", \"s). If your application contains a single custom\\nservice, you need a single Dockerfile. If your appl\", \"ication contains multiple services (as in a\\nmicroservices architecture), you need one Dockerfile for\", \" each service.\\n\\nThe Dockerfile is placed in the root folder of your application or service. It conta\", \"ins the commands\\nthat tell Docker how to set up and run your application or service in a container. \", \"You can manually\\ncreate a Dockerfile in code and add it to your project along with your .NET depende\", \"ncies.\\n\\nWith Visual Studio and its tools for Docker, this task requires only a few mouse clicks. Whe\", \"n you\\ncreate a new project in Visual Studio 2022, there\\u2019s an option named Enable Docker Support, as\\n\", \"shown in Figure 5-3.\\n\\n76 CHAPTER 4 | Development process for Docker-based applications\\nAdditional in\", \"formation\\n\\nLinux macOS Windows Cloud\\n\\nASP.NET Core Web API @\\nFramework @\\n\\n-NET 6.0 (Long-term suppor\", \"t)\\nAuthentication type @\\n\\nNone\\n\\n[v] Configure for HTTPS @\\n\\nEnable Docker @\\nDocker OS @\\n\\nUse controll\", \"ers (uncheck to use minimal APls) @\\n\\nEnable OpenAP! support @\\n\\nService\\n\\nWeb\\n\\nCreate\\n\\nFigure 5-3. Ena\", \"bling Docker Support when creating a new ASP.NET Core project in Visual Studio 2022\\n\\nYou can also en\", \"able Docker support on an existing ASP.NET Core web app project by right-clicking\\nthe project in Sol\", \"ution Explorer and selecting Add > Docker Support..., as shown in Figure 5-4.\\n\\nCtrl+Shift+A\\nShift+ A\", \"lt+A\\n\\nNew ltern...\\nExisting Item...\\nNew Scaffolded Iter...\\n\\nNew Folder\\n\\nContainer Orchestrator Suppo\", \"rt...\\nDocker Support...\\n\\n2)\\n\\nApplication Insights Telemetry...\\nClient-Side Library...\\n\\nNew Azure Web\", \"lJob Project\\nExisting Project as Azure WebJob\\nReference...\\n\\nService Reference...\\n\\nConnected Service\\n\", \"\\nClass...\\n\\nAdd (1)\\nManage NuGet Packages...\\nManage Client-Side Libraries...\\n\\nManage User Secrets\\nSet\", \" as StartUp Project\\nDebug\\n\\nSource Control\\n\\nCut Ctrl+xX\\n\\nRemove Del\\n\\nRename\\n\\nUnload Project\\n\\nLoad Pro\", \"ject Dependencies\\n\\nOpen Folder in File Explorer\\n\\nOpen in Visual Studio Code\\n\\nFigure 5-4. Enabling Do\", \"cker support in an existing Visual Studio 2022 project\\n\\n77 CHAPTER 4 | Development process for Docke\", \"r-based applications\\n\\nThis action adds a Dockerfile to the project with the required configuration, \", \"and is only available on\\nASP.NET Core projects.\\n\\nIn a similar fashion, Visual Studio can also add a \", \"docker-compose.yml file for the whole solution with\\nthe option Add > Container Orchestrator Support.\", \"... In step 4, we'll explore this option in greater\\ndetail.\\n\\nUsing an existing official .NET Docker \", \"image\\n\\nYou usually build a custom image for your container on top of a base image you get from an of\", \"ficial\\nrepository like the Docker Hub registry. That is precisely what happens under the covers when\", \" you\\nenable Docker support in Visual Studio. Your Dockerfile will use an existing dotnet/core/aspnet\", \" image.\\n\\nEarlier we explained which Docker images and repos you can use, depending on the framework \", \"and\\nOS you have chosen. For instance, if you want to use ASP.NET Core (Linux or Windows), the image \", \"to\\nuse is mcr.microsoft.com/dotnet/aspnet:7.0. Therefore, you just need to specify what base Docker\\n\", \"image you will use for your container. You do that by adding FROM\\nmcr.microsoft.com/dotnet/aspnet:7.\", \"0 to your Dockerfile. This will be automatically performed by\\nVisual Studio, but if you were to upda\", \"te the version, you update this value.\\n\\nUsing an official NET image repository from Docker Hub with \", \"a version number ensures that the same\\nlanguage features are available on all machines (including de\", \"velopment, testing, and production).\\n\\nThe following example shows a sample Dockerfile for an ASP.NET\", \" Core container.\\n\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0\\nARG source\\nWORKDIR /app\\n\\nEXPOSE 80\\nCOPY \\u00a2\", \"${source:-obj/Docker/publish} .\\nENTRYPOINT [\\\"dotnet\\\", \\\" MySingleContainerWebApp.dll \\\"|\\n\\nIn this case\", \", the image is based on version 7.0 of the official ASP.NET Core Docker image (multi-arch\\nfor Linux \", \"and Windows). This is the setting FROM mcr.microsoft.com/dotnet/aspnet:7.0. (For more\\ninformation ab\", \"out this base image, see the ASP.NET Core Docker Image page.) In the Dockerfile, you\\nalso need to in\", \"struct Docker to listen on the TCP port you will use at runtime (in this case, port 80, as\\nconfigure\", \"d with the EXPOSE setting).\\n\\nYou can specify additional configuration settings in the Dockerfile, de\", \"pending on the language and\\nframework you're using. For instance, the ENTRYPOINT line with [\\\"dotnet\\\"\", \",\\n\\\"MySingleContainerWebApp.dll\\\"] tells Docker to run a .NET application. If you're using the SDK and\", \"\\nthe .NET CLI (dotnet CLI) to build and run the .NET application, this setting would be different. T\", \"he\\nbottom line is that the ENTRYPOINT line and other settings will be different depending on the\\nlan\", \"guage and platform you choose for your application.\\n\\nAdditional resources\\n\\n\\u00b0 Building Docker Images \", \"for ASP.NET Core Applications\\nhttps://learn.microsoft.com/dotnet/core/docker/building-net-docker-ima\", \"ges\\n\\n78 CHAPTER 4 | Development process for Docker-based applications\\n. Build your own image. In the\", \" official Docker documentation.\\n\\nhttps://docs.docker.com/engine/tutorials/dockerimages/\\n\\n. Staying u\", \"p-to-date with .NET Container Images\\n\\nhttps://devblogs.microsoft.com/dotnet/staying-up-to-date-with-\", \"net-container-images\\n\\nUsing multi-arch image repositories\\n\\nA single repo can contain platform varian\", \"ts, such as a Linux image and a Windows image. This feature\\nallows vendors like Microsoft (base imag\", \"e creators) to create a single repo to cover multiple platforms\\n(that is Linux and Windows). For exa\", \"mple, the .NET repository available in the Docker Hub registry\\nprovides support for Linux and Window\", \"s Nano Server by using the same repo name.\\n\\nIf you specify a tag, targeting a platform that is expli\", \"cit like in the following cases:\\n\\n\\u00b0 mcr.microsoft.com/dotnet/aspnet:7.0-bullseye-slim\\nTargets: .NET \", \"7 runtime-only on Linux\\n\\n. mcr.microsoft.com/dotnet/aspnet:7.0-nanoserver-Itsc2022\\nTargets: .NET 7 r\", \"untime-only on Windows Nano Server\\n\\nBut, if you specify the same image name, even with the same tag,\", \" the multi-arch images (like the\\naspnet image) will use the Linux or Windows version depending on th\", \"e Docker host OS you're\\ndeploying, as shown in the following example:\\n\\n. mcr.microsoft.com/dotnet/as\", \"pnet:7.0\\nMulti-arch: .NET 7 runtime-only on Linux or Windows Nano Server depending on the Docker\\nhos\", \"t OS\\n\\nThis way, when you pull an image from a Windows host, it will pull the Windows variant, and pu\", \"lling\\nthe same image name from a Linux host will pull the Linux variant.\\n\\nMulti-stage builds in Dock\", \"erfile\\n\\nThe Dockerfile is similar to a batch script. Similar to what you would do if you had to set \", \"up the\\nmachine from the command line.\\n\\nIt starts with a base image that sets up the initial context,\", \" it's like the startup filesystem, that sits on\\ntop of the host OS. It's not an OS, but you can thin\", \"k of it like \\u201cthe\\u201d OS inside the container.\\n\\nThe execution of every command line creates a new layer\", \" on the filesystem with the changes from the\\nprevious one, so that, when combined, produce the resul\", \"ting filesystem.\\n\\nSince every new layer \\u201crests\\u201d on top of the previous one and the resulting image s\", \"ize increases with\\nevery command, images can get very large if they have to include, for example, th\", \"e SDK needed to\\nbuild and publish an application.\\n\\nThis is where multi-stage builds get into the plo\", \"t (from Docker 17.05 and higher) to do their magic.\\n\\n79 CHAPTER 4 | Development process for Docker-b\", \"ased applications\\nThe core idea is that you can separate the Dockerfile execution process in stages,\", \" where a stage is an\\ninitial image followed by one or more commands, and the last stage determines t\", \"he final image size.\\n\\nIn short, multi-stage builds allow splitting the creation in different \\u201cphases\", \"\\u201d and then assemble the\\nfinal image taking only the relevant directories from the intermediate stage\", \"s. The general strategy to\\nuse this feature is:\\n\\n1. | Use a base SDK image (doesn't matter how large\", \"), with everything needed to build and\\npublish the application to a folder and then\\n\\n2. Use a base, \", \"small, runtime-only image and copy the publishing folder from the previous stage\\nto produce a small \", \"final image.\\n\\nProbably the best way to understand multi-stage is going through a Dockerfile in detai\", \"l, line by line,\\nso let\\u2019s begin with the initial Dockerfile created by Visual Studio when adding Doc\", \"ker support to a\\nproject and will get into some optimizations later.\\n\\nThe initial Dockerfile might l\", \"ook something like this:\\n\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base\\nWORKDIR /app\\nEXPOSE 80\\n\\nF\", \"ROM mcr.microsoft.com/dotnet/sdk:7.@ AS build\\n\\nWORKDIR /src\\n\\nCOPY src/Services/Catalog/Catalog.API/C\", \"atalog.API.csproj .\\n\\nCOPY src/BuildingBlocks/HealthChecks/src/Microsoft. AspNetCore. HealthChecks ..\", \"\\nCOPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions.HealthChecks ..\\nCOPY src/BuildingBloc\", \"ks/EventBus/IntegrationEventLogEF/ ..\\n\\nCOPY src/BuildingBlocks/EventBus/EventBus/EventBus.csproj ..\\n\", \"\\nCOPY src/BuildingBlocks/EventBus/EventBusRabbitMQ/EventBusRabbitMQ.csproj ..\\nCOPY src/BuildingBlock\", \"s/EventBus/EventBusServiceBus/EventBusServiceBus.csproj ..\\nCOPY src/BuildingBlocks/WebHostCustomizat\", \"ion/WebHost.Customization ..\\n\\nWON AU BWN RP\\n\\nCOPY src/BuildingBlocks/HealthChecks/src/Microsoft.Exte\", \"nsions ..\\n\\nCOPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions ..\\n\\nRUN dotnet restore src/\", \"Services/Catalog/Catalog.API/Catalog.API.csproj\\nCOPY .\\n\\nWORKDIR /src/src/Services/Catalog/Catalog.AP\", \"I\\n\\nRUN dotnet build Catalog.API.csproj -c Release -o /app\\n\\nFROM build AS publish\\nRUN dotnet publish \", \"Catalog.API.csproj -c Release -o /app\\n\\nFROM base AS final\\n\\nWORKDIR /app\\n\\nCOPY --from=publish /app .\\n\", \"\\nENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.API.d11\\\"]\\n\\nAnd these are the details, line by line:\\n\\u00b0 Line #1: Begin\", \" a stage with a \\u201csmall\\u201d runtime-only base image, call it base for reference.\\n. Line #2: Create the /\", \"app directory in the image.\\n\\n: Line #3: Expose port 80.\\n\\n80 CHAPTER 4 | Development process for Dock\", \"er-based applications\\n\\u00b0 Line #5: Begin a new stage with the \\u201clarge\\u201d image for building/publishing. C\", \"all it build for\\n\\nreference.\\n\\n. Line #6: Create directory /sre in the image.\\n\\n. Line #7: Up to line \", \"16, copy referenced .csproj project files to be able to restore packages\\nlater.\\n\\n. Line #17: Restore\", \" packages for the Catalog.API project and the referenced projects.\\n\\n\\u00b0 Line #18: Copy all directory t\", \"ree for the solution (except the files/directories included in the\\n-dockerignore file) to the /sre d\", \"irectory in the image.\\n\\n. Line #19: Change the current folder to the Catalog.API project.\\n\\n. Line #2\", \"0: Build the project (and other project dependencies) and output to the /app\\ndirectory in the image.\", \"\\n\\n. Line #22: Begin a new stage continuing from the build. Call it publish for reference.\\n\\n. Line #2\", \"3: Publish the project (and dependencies) and output to the /app directory in the\\nimage.\\n\\n\\u00b0 Line #25\", \": Begin a new stage continuing from base and call it final.\\n\\n. Line #26: Change the current director\", \"y to /app.\\n\\n. Line #27: Copy the /app directory from stage publish to the current directory.\\n. Line \", \"#28: Define the command to run when the container is started.\\n\\nNow let's explore some optimizations \", \"to improve the whole process performance that, in the case of\\neShopOnContainers, means about 22 minu\", \"tes or more to build the complete solution in Linux\\ncontainers.\\n\\nYou'll take advantage of Docker's l\", \"ayer cache feature, which is quite simple: if the base image and the\\ncommands are the same as some p\", \"reviously executed, it can just use the resulting layer without the\\nneed to execute the commands, th\", \"us saving some time.\\n\\nSo, let's focus on the build stage, lines 5-6 are mostly the same, but lines 7\", \"-17 are different for every\\nservice from eShopOnContainers, so they have to execute every single tim\", \"e, however if you changed\\nlines 7-16 to:\\n\\nCOPY .\\n\\nThen it would be just the same for every service, \", \"it would copy the whole solution and would create a\\nlarger layer but:\\n\\n1. | The copy process would o\", \"nly be executed the first time (and when rebuilding if a file is\\nchanged) and would use the cache fo\", \"r all other services and\\n\\n2. Since the larger image occurs in an intermediate stage, it doesn't affe\", \"ct the final image size.\\n\\n81 CHAPTER 4 | Development process for Docker-based applications\\nThe next \", \"significant optimization involves the restore command executed in line 17, which is also\\ndifferent f\", \"or every service of eshopOnContainers. If you change that line to just:\\n\\nRUN dotnet restore\\n\\nIt woul\", \"d restore the packages for the whole solution, but then again, it would do it just once, instead\\nof \", \"the 15 times with the current strategy.\\n\\nHowever, dotnet restore only runs if there\\u2019s a single proje\", \"ct or solution file in the folder, so achieving\\nthis is a bit more complicated and the way to solve \", \"it, without getting into too many details, is this:\\n\\n1. Add the following lines to .dockerignore:\\n- \", \"* sIn, to ignore all solution files in the main folder tree\\n- !eShopOnContainers-ServicesAndWebApps:\", \".sIn, to include only this solution file.\\n\\n2. Include the /ignoreprojectextensions:.dcproj argument \", \"to dotnet restore, so it also ignores the\\ndocker-compose project and only restores the packages for \", \"the eshopOnContainers-\\nServicesAndWebApps solution.\\n\\nFor the final optimization, it just happens tha\", \"t line 20 is redundant, as line 23 also builds the\\napplication and comes, in essence, right after li\", \"ne 20, so there goes another time-consuming\\ncommand.\\n\\nThe resulting file is then:\\n\\nFROM mcr.microsof\", \"t.com/dotnet/aspnet:7.0 AS base\\nWORKDIR /app\\nEXPOSE 80\\n\\nFROM mcr.microsoft.com/dotnet/sdk:7.@ AS pub\", \"lish\\n\\nWORKDIR /src\\n\\nCOPY .\\n\\nRUN dotnet restore /ignoreprojectextensions: .dcproj\\nWORKDIR /src/src/Se\", \"rvices/Catalog/Catalog.API\\n\\nRUN dotnet publish Catalog.API.csproj -c Release -o /app\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n\", \"8\\n9\\n\\nFROM base AS final\\n\\nWORKDIR /app\\n\\nCOPY --from=publish /app .\\n\\nENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.AP\", \"I.d11\\\"]\\n\\nCreating your base image from scratch\\n\\nYou can create your own Docker base image from scrat\", \"ch. This scenario is not recommended for\\nsomeone who is starting with Docker, but if you want to set\", \" the specific bits of your own base image,\\nyou can do so.\\n\\nAdditional resources\\n\\n. Multi-arch .NET C\", \"ore images.\\nhttps://github.com/dotnet/announcements/issues/14\\n\\n82 CHAPTER 4 | Development process fo\", \"r Docker-based applications\\n. Create a base image. Official Docker documentation.\\n\\nhttps://docs.dock\", \"er.com/develop/develop-images/baseimages/\\n\\n3.\\n\\nCreate Images\\n\\ndefined at\\n\\nDeackerfila/s\\n|\\n\\nStep 3. C\", \"reate your custom Docker images and embed your\\napplication or service in them\\n\\nFor each service in y\", \"our application, you need to create a related image. If your application is made up\\nof a single serv\", \"ice or web application, you just need a single image.\\n\\nNote that the Docker images are built automat\", \"ically for you in Visual Studio. The following steps are\\nonly needed for the editor/CLI workflow and\", \" explained for clarity about what happens underneath.\\n\\nYou, as a developer, need to develop and test\", \" locally until you push a completed feature or change to\\nyour source control system (for example, to\", \" GitHub). This means that you need to create the Docker\\nimages and deploy containers to a local Dock\", \"er host (Windows or Linux VM) and run, test, and debug\\nagainst those local containers.\\n\\nTo create a \", \"custom image in your local environment by using Docker CLI and your Dockerfile, you can\\nuse the dock\", \"er build command, as in Figure 5-5.\\n\\nPS c:\\\\dev\\\\netcore-webapi -microservice-docker> build cesard|/ne\", \"tcore-webapi-microservice-docker:first .\\nSending build context to Docker daemon 1.148 MB\\n: FROM micr\", \"osoft/dotnet: latest\\n: Pulling from microsoft/dotnet\\n\\u00a7c90d4a2d1a8: Downloading [ 18.34 MB/51.35 MB\\na\", \"b30c63719b1: Downloading [ 18.48 MB/18.55 MB\\n\\nc6072700a242: Downloading [ |] 18.34 MB/42.53 MB\\n121d7\", \"eef6c20: waiting\\neb57cf4f29ee: waiting\\nb2cS5ae2d325b: waiting\\n\\nFigure 5-5. Creating a custom Docker \", \"image\\n\\nOptionally, instead of directly running docker build from the project folder, you can first g\", \"enerate a\\ndeployable folder with the required .NET libraries and binaries by running dotnet publish,\", \" and then\\nuse the docker build command.\\n\\nThis will create a Docker image with the name cesardl/netco\", \"re-webapi-microservice-docker-first. In\\nthis case, :first is a tag that represents a specific versio\", \"n. You can repeat this step for each custom\\nimage you need to create for your composed Docker applic\", \"ation.\\n\\nWhen an application is made of multiple containers (that is, it is a multi-container applica\", \"tion), you\\ncan also use the docker-compose up --build command to build all the related images with a\", \" single\\ncommand by using the metadata exposed in the related docker-compose.yml files.\\n\\nYou can find\", \" the existing images in your local repository by using the docker images command, as\\nshown in Figure\", \" 5-6.\\n\\n83 CHAPTER 4 | Development process for Docker-based applications\\nPS C:\\\\dev\\\\netcore-webap1-mic\", \"roserv1ce-docker> images\\n\\nREPOSITORY TAG IMAGE ID CREATED SIZE\\ncesard|/netcore-webapi -microservice-\", \"docker first 384c4ac1809b 4 minutes ago 579.8 MB\\nmicrosoft/dotnet latest 49aaf5daa850 30 hours ago\\n\\n\", \"ubuntu latest cf62323fa025 5 days ago\\n\\nhel lo-world latest c54a2cc56cbb 12 days ago 1.848 kB\\n\\nFigure\", \" 5-6. Viewing existing images using the docker images command\\n\\nCreating Docker images with Visual St\", \"udio\\n\\nWhen you use Visual Studio to create a project with Docker support, you don't explicitly creat\", \"e an\\nimage. Instead, the image is created for you when you press F5 (or Ctrl+F5) to run the dockeriz\", \"ed\\napplication or service. This step is automatic in Visual Studio and you won't see it happen, but \", \"it\\u2019s\\nimportant that you know what's going on underneath.\\n\\n4. io pt)\\n\\nDefine services\\n\\nby writing\\n\\ndo\", \"cker-compos.yrmnl\\n\\nStep 4. Define your services in docker-compose.yml when building a\\nmulti-containe\", \"r Docker application\\n\\nThe docker-compose.yml file lets you define a set of related services to be de\", \"ployed as a composed\\napplication with deployment commands. It also configures its dependency relatio\", \"ns and runtime\\nconfiguration.\\n\\nTo use a docker-compose.yml file, you need to create the file in your\", \" main or root solution folder, with\\ncontent similar to that in the following example:\\n\\nversion: '3.4\", \"'\\n\\nservices:\\n\\nwebmvc:\\nimage: eshop/web\\nenvironment:\\n- CatalogUrl=http://catalog-api\\n- OrderingUrl=ht\", \"tp://ordering-api\\nports:\\n- \\\"80:80\\\"\\ndepends_on:\\n- catalog-api\\n- ordering-api\\n\\ncatalog-api:\\nimage: esh\", \"op/catalog-api\\nenvironment:\\n- ConnectionString=Server=sqldata;Port=1433;Database=CatalogDB,...\\nports\", \":\\n- \\\"81:80\\\"\\ndepends_on:\\n- sqldata\\n\\nordering-api:\\nimage: eshop/ordering-api\\n\\n84 CHAPTER 4 | Developme\", \"nt process for Docker-based applications\\nenvironment:\\n- ConnectionString=Server=sqldata;Database=Ord\", \"eringDb3...\\nports:\\n- \\\"82:80\\\"\\nextra_hosts:\\n- \\\"CESARDLBOOKVHD:10.0.75.1\\\"\\ndepends_on:\\n- sqldata\\n\\nsqldat\", \"a:\\nimage: mcr.microsoft.com/mssql/server: latest\\nenvironment:\\n- SA PASSWORD=Pass@word\\n- ACCEPT_EULA=\", \"Y\\nports:\\n- \\\"5433:1433\\\"\\n\\nThis docker-compose.yml file is a simplified and merged version. It contains\", \" static configuration data\\nfor each container (like the name of the custom image), which is always r\", \"equired, and configuration\\ninformation that might depend on the deployment environment, like the con\", \"nection string. In later\\nsections, you will learn how to split the docker-compose.yml configuration \", \"into multiple docker-\\ncompose files and override values depending on the environment and execution t\", \"ype (debug or\\nrelease).\\n\\nThe docker-compose.yml file example defines four services: the webmvc servi\", \"ce (a web application),\\ntwo microservices (ordering-api and basket-api), and one data source contain\", \"er, sqldata, based on\\nSQL Server for Linux running as a container. Each service will be deployed as \", \"a container, so a Docker\\nimage is required for each.\\n\\nThe docker-compose.yml file specifies not only\", \" what containers are being used, but how they are\\nindividually configured. For instance, the webmvc \", \"container definition in the .yml file:\\n\\n. Uses a pre-built eshop/web:latest image. However, you coul\", \"d also configure the image to be\\nbuilt as part of the docker-compose execution with an additional co\", \"nfiguration based on a\\nbuild: section in the docker-compose file.\\n\\n. Initializes two environment var\", \"iables (CatalogUrl and OrderingUrl).\\n. Forwards the exposed port 80 on the container to the external\", \" port 80 on the host machine.\\n. Links the web app to the catalog and ordering service with the depen\", \"ds_on setting. This\\n\\ncauses the service to wait until those services are started.\\n\\nWe will revisit t\", \"he docker-compose.yml file in a later section when we cover how to implement\\nmicroservices and multi\", \"-container apps.\\n\\nWorking with docker-compose.yml in Visual Studio 2022\\n\\nBesides adding a Dockerfile\", \" to a project, as we mentioned before, Visual Studio 2017 (from version\\n15.8 on) can add orchestrato\", \"r support for Docker Compose to a solution.\\n\\nWhen you add container orchestrator support, as shown i\", \"n Figure 5-7, for the first time, Visual Studio\\ncreates the Dockerfile for the project and creates a\", \" new (service section) project in your solution with\\n\\n85 CHAPTER 4 | Development process for Docker-\", \"based applications\\nseveral global docker-compose*.yml files, and then adds the project to those file\", \"s. You can then open\\n\\nthe docker-compose.yml files and update them with additional features.\\n\\nRepeat\", \" this operation for every project you want to include in the docker-compose.yml file.\\n\\nAt the time o\", \"f this writing, Visual Studio supports Docker Compose orchestrators.\\n\\nNew Item...\\nExisting Item...\\nN\", \"ew Scaffolded Item...\\n\\nNew Folder\\n\\nContainer Orchestrator Support...\\n\\nDocker Support...\\n\\nCtrl+Shitt+\", \"A\\n\\nShift+Alt+A\\n\\n2)\\n\\nAdd (1)\\nManage NuGet Package\\u2019\\n\\nManage Client-Side Libraries...\\nManage User Secre\", \"ts\\nSet as StartUp Project\\n\\nDebug\\n\\nApplication Insights Telemetry... Cut Ctrl+x\\n\\nClient-Side Library.\", \"..\\nRemove Del\\nNew Azure Weblob Project\\n: Rename\\nExisting Project as Azure WebJob\\nUnload Project\\n\\u201cREE\", \" EL Load Project Dependencies\\nService Reference...\\nConnected Service Open Folder in File Explorer\\nOp\", \"en in Visual Studio Code\\n\\nOpen Command Line\\n\\nFigure 5-7. Adding Docker support in Visual Studio 2022\", \" by right-clicking an ASP.NET Core project\\n\\nAfter you add orchestrator support to your solution in V\", \"isual Studio, you will also see a new node (in\\nthe docker-compose.dcproj project file) in Solution E\", \"xplorer that contains the added docker-\\ncompose.yml files, as shown in Figure 5-8.\\n\\ni\\n\\nL) .dockerign\", \"ore\\n4 4) docker-composeymil\\n\\n7) docker-com pose.averride.yml\\n\\nFigure 5-8. The docker-compose tree no\", \"de added in Visual Studio 2022 Solution Explorer\\n\\nYou could deploy a multi-container application wit\", \"h a single docker-compose.yml file by using the\\ndocker-compose up command. However, Visual Studio ad\", \"ds a group of them so you can override\\nvalues depending on the environment (development or productio\", \"n) and execution type (release or\\ndebug). This capability will be explained in later sections.\\n5.\\nRu\", \"in\\n\\nContainers ;\\n\\nLompose app\\n\\nStep 5. Build and run your Docker application\\n\\nIf your application on\", \"ly has a single container, you can run it by deploying it to your Docker host (VM\\nor physical server\", \"). However, if your application contains multiple services, you can deploy it as a\\ncomposed applicat\", \"ion, either using a single CLI command (docker-compose up), or with Visual Studio,\\nwhich will use th\", \"at command under the covers. Let's look at the different options.\\n\\nOption A: Running a single-contai\", \"ner application\\n\\nUsing Docker CLI\\nYou can run a Docker container using the docker run command, as sh\", \"own in Figure 5-9:\\n\\ndocker run -t -d -p 80:5000 cesardl/netcore-webapi-microservice-docker: first\\n\\nT\", \"he above command will create a new container instance from the specified image, every time it\\u2019s run.\", \"\\nYou can use the --name parameter to give a name to the container and then use docker start {name}\\n(\", \"or use the container ID or automatic name) to run an existing container instance.\\n\\nPS C:\\\\dev\\\\netcore\", \"-webapi -microservice-docke 80:5000 cesard|1/netcore-webapi-microservice-docker: first\\n\\nd96975a683b0\", \"a9411595816F63be6c135801878b8a85181a4d86dc848ea4ca6t\\n\\nFigure 5-9. Running a Docker container using t\", \"he docker run command\\n\\nIn this case, the command binds the internal port 5000 of the container to po\", \"rt 80 of the host\\nmachine. This means that the host Is listening on port 80 and forwarding to port 5\", \"000 on the\\ncontainer.\\n\\nThe hash shown is the container ID and it's also assigned a random readable n\", \"ame if the --name\\noption is not used.\\nUsing Visual Studio\\n\\nIf you haven't added container orchestrat\", \"or support, you can also run a single container app in Visual\\nStudio by pressing Ctrl+F5 and you can\", \" also use F5 to debug the application within the container. The\\ncontainer runs locally using docker \", \"run.\\n\\nOption B: Running a multi-container application\\n\\nIn most enterprise scenarios, a Docker applic\", \"ation will be composed of multiple services, which means\\nyou need to run a multi-container applicati\", \"on, as shown in Figure 5-10.\\n\\n87 CHAPTER 4 | Development process for Docker-based applications\\nMy My\", \"\\nContainer 1||| Container 2\\n\\nFigure 5-10. VM with Docker containers deployed\\n\\nUsing Docker CLI\\n\\nTo r\", \"un a multi-container application with the Docker CLI, you use the docker-compose up command.\\nThis co\", \"mmand uses the docker-compose.yml file that you have at the solution level to deploy a\\nmulti-contain\", \"er application. Figure 5-11 shows the results when running the command from your\\nmain solution direc\", \"tory, which contains the docker-compose.yml file.\\n\\nPS C:\\\\Dev\\\\webApplication> up\\n\\nRecreating SS SS US\", \"\\n\\nAttaching to webapplication_webapplication_1 .\\nHosting environment: Production\\n\\nContent root path:\", \" /app\\nNow listening on: http://*:80\\nApplication started. Press Ctrl+C to shut down.\\n\\nFigure 5-17. Ex\", \"ample results when running the docker-compose up command\\n\\nAfter the docker-compose up command runs, \", \"the application and its related containers are deployed\\ninto your Docker host, as depicted in Figure\", \" 5-10.\\n\\nUsing Visual Studio\\n\\nRunning a multi-container application using Visual Studio 2019 can\\u2019t ge\", \"t any simpler. You just press\\nCtrl+F5 to run or F5 to debug, as usual, setting up the docker-compose\", \" project as the startup project.\\nVisual Studio handles all needed setup, so you can create breakpoin\", \"ts as usual and debug what finally\\nbecome independent processes running in \\u201cremote servers\\u201d, with th\", \"e debugger already attached, just\\nlike that.\\n\\nAs mentioned before, each time you add Docker solution\", \" support to a project within a solution, that\\nproject is configured in the global (solution-level) d\", \"ocker-compose.yml file, which lets you run or\\ndebug the whole solution at once. Visual Studio will s\", \"tart one container for each project that has\\nDocker solution support enabled, and perform all the in\", \"ternal steps for you (dotnet publish, docker\\nbuild, etc.).\\n\\nIf you want to take a peek at all the dr\", \"udgery, take a look at the file:\\n\\n{root solution folder}\\\\obj\\\\Docker\\\\docker-compose.vs.debug.g.yml\\n\\n8\", \"8 CHAPTER 4 | Development process for Docker-based applications\\nThe important point here is that, as\", \" shown in Figure 5-12, in Visual Studio 2019 there is an additional\\nDocker command for the F5 key ac\", \"tion. This option lets you run or debug a multi-container\\napplication by running all the containers \", \"that are defined in the docker-compose.yml files at the\\nsolution level. The ability to debug multipl\", \"e-container solutions means that you can set several\\nbreakpoints, each breakpoint in a different pro\", \"ject (container), and while debugging from Visual\\nStudio you will stop at breakpoints defined in dif\", \"ferent projects and running on different containers.\\n\\npe | FILE EDIT VIEW PROJECT BUILD DEBUG TEST A\", \"NALYZE TOOLS EXTENSIONS WINDOW HELP\\n\\ni Debug Any CPU docker-compose Docker Compose\\n\\ndocker-compose.y\", \"ml + X& docker-compose.override.yml\\n\\nFigure 5-12. Running multi-container apps in Visual Studio 2022\", \"\\n\\nAdditional resources\\n\\n\\u00b0 Deploy an ASP.NET container to a remote Docker host\\nhttos://learn.microsof\", \"t.com/visualstudio/containers/hosting-web-apps-in-docker\\n\\nA note about testing and deploying with or\", \"chestrators\\n\\nThe docker-compose up and docker run commands (or running and debugging the containers \", \"in\\nVisual Studio) are adequate for testing containers in your development environment. But you shoul\", \"d\\nnot use this approach for production deployments, where you should target orchestrators like\\nKuber\", \"netes or Service Fabric. If you're using Kubernetes, you have to use pods to organize containers\\nand\", \" services to network them. You also use deployments to organize pod creation and modification.\\n\\n6.\\n\\n\", \"Test\\n\\nyour app or\\n\\nMICrOServices\\n\\nStep 6. Test your Docker application using your local Docker host\\n\", \"\\nThis step will vary depending on what your application is doing. In a simple .NET Web application t\", \"hat\\nis deployed as a single container or service, you can access the service by opening a browser on\", \" the\\nDocker host and navigating to that site, as shown in Figure 5-13. (If the configuration in the \", \"Dockerfile\\nmaps the container to a port on the host that is anything other than 80, include the host\", \" port in the\\nURL.)\\n\\n& CL localhost/AP!/values\\n\\n[\\u201cHowdy!\\\", \\\"Cheers mate!\\\" ]\\n\\nFigure 5-13. Example of \", \"testing your Docker application locally using localhost\\n\\n89 CHAPTER 4 | Development process for Dock\", \"er-based applications\\nIf localhost is not pointing to the Docker host IP (by default, when using Doc\", \"ker CE, it should), to\\nnavigate to your service, use the IP address of your machine's network card.\\n\", \"\\nThis URL in the browser uses port 80 for the particular container example being discussed. However,\", \"\\ninternally the requests are being redirected to port 5000, because that was how it was deployed wit\", \"h\\nthe docker run command, as explained in a previous step.\\n\\nYou can also test the application using \", \"curl from the terminal, as shown in Figure 5-14. In a Docker\\ninstallation on Windows, the default Do\", \"cker Host IP is always 10.0.75.1 in addition to your machine's\\nactual IP address.\\n\\nPS C:\\\\dev\\\\netcore\", \"-webapi-microservice-docker> http://10.0.75.1/API/values\\n\\nStatusCode : 200\\nStatusDescription : OK\\nCo\", \"ntent : [\\\"\\u201cHowdy!\\\", \\\"Cheers mate!\\\" ]\\nRawcontent : HTTP/1.1 200 OK\\nTransfer-Encoding: chunked\\nContent\", \"-Type: application/json; charset=utf-8\\nDate: Thu, 14 Jul 2016 19:48:18 GMT\\nServer: Kestrel\\n\\n[\\\"\\u201cHowdy\", \"!\\\", \\\"Cheers mate!\\\"]\\n\\n: {[Transfer-Encoding, chunked], [Content-Type, application/json;\\ncharset=utf-8\", \"], [Date, Thu, 14 Jul 2016 19:48:18 GMT], [Server, Kestrel] }\\n\\na tt\\n: i}\\n\\n: <r\\n: mshtml.HTMLDocument\", \"Class\\nRawcontentLength : 25\\n\\nFigure 5-14. Example of testing your Docker application locally using c\", \"url\\n\\nTesting and debugging containers with Visual Studio 2022\\n\\nWhen running and debugging the contai\", \"ners with Visual Studio 2022, you can debug the .NET\\napplication in much the same way as you would w\", \"hen running without containers.\\n\\nTesting and debugging without Visual Studio\\n\\nIf you're developing u\", \"sing the editor/CLI approach, debugging containers is more difficult and you'll\\nprobably want to deb\", \"ug by generating traces.\\n\\nAdditional resources\\n\\n\\u00b0 Quickstart: Docker in Visual Studio.\\n\\nhttps://lear\", \"n.microsoft.com/visualstudio/containers/container-tools\\n\\n. Debugging apps in a local Docker containe\", \"r\\n\\nhttps://learn.microsoft.com/visualstudio/containers/edit-and-refresh\\n\\nSimplified workflow when de\", \"veloping containers with Visual Studio\\n\\nEffectively, the workflow when using Visual Studio is a lot \", \"simpler than if you use the editor/CLI\\napproach. Most of the steps required by Docker related to the\", \" Dockerfile and docker-compose.yml\\nfiles are hidden or simplified by Visual Studio, as shown in Figu\", \"re 5-15.\\n\\n90 CHAPTER 4 | Development process for Docker-based applications\\nVS development workflow f\", \"or Docker apps\\n\\n1. 2. (Once)\\n\\nR jai b 4.\\nun/Debug\\n\\nCode Add Docker Containers / Test\\nyour app suppor\", \"t to Compose app your app or\\n\\n= projects i microservices\\n\\nMy\\n\\n| Containers\\nImages docker run / http\\n\", \"\\nDocker-compose up access...\\n[T]\\nlinn\\nImages\\nRemote |\\n\\nMy\\nImages\\n\\u2014 Remote \\u2014 Local\\n\\nDocker Registry D\", \"ocker\\n5. (i.e. Docker Hub) Repos\\n\\ngit push Push or\\n\\noa Continue\\n\\ndeveloping\\n\\nFigure 5-15. Simplified\", \" workflow when developing with Visual Studio\\n\\nIn addition, you need to perform step 2 (adding Docker\", \" support to your projects) just once. Therefore,\\nthe workflow is similar to your usual development t\", \"asks when using .NET for any other development.\\nYou need to know what is going on under the covers (\", \"the image build process, what base images\\nyou're using, deployment of containers, etc.) and sometime\", \"s you will also need to edit the Dockerfile\\nor docker-compose.yml file to customize behaviors. But m\", \"ost of the work is greatly simplified by using\\nVisual Studio, making you a lot more productive.\\n\\nUsi\", \"ng PowerShell commands in a Dockerfile to set up Windows\\nContainers\\n\\nWindows Containers allow you to\", \" convert your existing Windows applications into Docker images and\\ndeploy them with the same tools a\", \"s the rest of the Docker ecosystem. To use Windows Containers,\\nyou run PowerShell commands in the Do\", \"ckerfile, as shown in the following example:\\n\\nFROM mcr.microsoft.com/windows/servercore\\nLABEL Descri\", \"ption=\\\"IIS\\\" Vendor=\\\"Microsoft\\\" Version=\\\"10\\\"\\n\\nRUN powershell -Command Add-WindowsFeature Web-Server\\nC\", \"MD [ \\\"ping\\\", \\\"localhost\\\", \\\"-t\\\" |\\n\\nIn this case, we are using a Windows Server Core base image (the F\", \"ROM setting) and installing IIS with\\na PowerShell command (the RUN setting). In a similar way, you c\", \"ould also use PowerShell commands\\nto set up additional components like ASP.NET 4.x, .NET Framework 4\", \".6, or any other Windows\\nsoftware. For example, the following command in a Dockerfile sets up ASP.NE\", \"T 4.5:\\n\\nRUN powershell add-windowsfeature web-asp-net45\\n\\nAdditional resources\\n\\n. aspnet-docker/Docke\", \"rfile. Example PowerShell commands to run from dockerfiles to\\ninclude Windows features.\\n\\n91 CHAPTER \", \"4 | Development process for Docker-based applications\\n92\\n\\nhttps://github.com/Microsoft/aspnet-docker\", \"/blob/master/4.7.1-windowsservercore-\\ntsc2016/runtime/Dockerfile\\n\\nCHAPTER 4 | Development process fo\", \"r Docker-based applications\\nCHAPTER\\n\\nDesigning ana Developing\\nMulti-Container and\\nMicroservice-Based\", \" .NET\\nApplications\\n\\nDeveloping containerized microservice applications means you are building multi-\", \"container\\napplications. However, a multi-container application could also be simpler\\u2014for example, a \", \"three-tier\\napplication\\u2014and might not be built using a microservice architecture.\\n\\nEarlier we raised \", \"the question \\u201cIs Docker necessary when building a microservice architecture?\\u201d The\\nanswer is a clear \", \"no. Docker is an enabler and can provide significant benefits, but containers and\\nDocker are not a h\", \"ard requirement for microservices. As an example, you could create a\\nmicroservices-based application\", \" with or without Docker when using Azure Service Fabric, which\\nsupports microservices running as sim\", \"ple processes or as Docker containers.\\n\\nHowever, if you know how to design and develop a microservic\", \"es-based application that is also based\\non Docker containers, you will be able to design and develop\", \" any other, simpler application model.\\nFor example, you might design a three-tier application that a\", \"lso requires a multi-container approach.\\nBecause of that, and because microservice architectures are\", \" an important trend within the container\\nworld, this section focuses on a microservice architecture \", \"implementation using Docker containers.\\n\\nDesign a microservice-oriented application\\n\\nThis section fo\", \"cuses on developing a hypothetical server-side enterprise application.\\n\\nApplication specifications\\n\\n\", \"The hypothetical application handles requests by executing business logic, accessing databases, and\\n\", \"then returning HTML, JSON, or XML responses. We will say that the application must support various\\nc\", \"lients, including desktop browsers running Single Page Applications (SPAs), traditional web apps,\\n\\nm\", \"obile web apps, and native mobile apps. The application might also expose an API for third parties\\n\\n\", \"93 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nto \", \"consume. It should also be able to integrate its microservices or external applications\\nasynchronous\", \"ly, so that approach will help resiliency of the microservices in the case of partial failures.\\n\\nThe\", \" application will consist of these types of components:\\n\\n. Presentation components. These components\", \" are responsible for handling the UI and\\nconsuming remote services.\\n\\n. Domain or business logic. Thi\", \"s component is the application's domain logic.\\n\\n. Database access logic. This component consists of \", \"data access components responsible for\\naccessing databases (SQL or NoSQL).\\n\\n\\u00b0 Application integratio\", \"n logic. This component includes a messaging channel, based on\\nmessage brokers.\\n\\nThe application wil\", \"l require high scalability, while allowing its vertical subsystems to scale out\\nautonomously, becaus\", \"e certain subsystems will require more scalability than others.\\n\\nThe application must be able to be \", \"deployed in multiple infrastructure environments (multiple public\\nclouds and on-premises) and ideall\", \"y should be cross-platform, able to move from Linux to Windows\\n(or vice versa) easily.\\n\\nDevelopment \", \"team context\\nWe also assume the following about the development process for the application:\\n. You h\", \"ave multiple dev teams focusing on different business areas of the application.\\n\\n. New team members \", \"must become productive quickly, and the application must be easy to\\nunderstand and modify.\\n\\n\\u00b0 The ap\", \"plication will have a long-term evolution and ever-changing business rules.\\n\\n\\u00b0 You need good long-te\", \"rm maintainability, which means having agility when implementing\\nnew changes in the future while bei\", \"ng able to update multiple subsystems with minimum\\nimpact on the other subsystems.\\n\\n. You want to pr\", \"actice continuous integration and continuous deployment of the application.\\n\\n\\u00b0 You want to take adva\", \"ntage of emerging technologies (frameworks, programming languages,\\netc.) while evolving the applicat\", \"ion. You do not want to make full migrations of the\\napplication when moving to new technologies, bec\", \"ause that would result in high costs and\\nimpact the predictability and stability of the application.\", \"\\n\\nChoosing an architecture\\n\\nWhat should the application deployment architecture be? The specificatio\", \"ns for the application, along\\nwith the development context, strongly suggest that you should archite\", \"ct the application by\\ndecomposing it into autonomous subsystems in the form of collaborating microse\", \"rvices and\\ncontainers, where a microservice is a container.\\n\\n94 CHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applications\\nIn this approach, each service (container)\", \" implements a set of cohesive and narrowly related functions.\\nFor example, an application might cons\", \"ist of services such as the catalog service, ordering service,\\nbasket service, user profile service,\", \" etc.\\n\\nMicroservices communicate using protocols such as HTTP (REST), but also asynchronously (for\\ne\", \"xample, using AMQP) whenever possible, especially when propagating updates with integration\\nevents.\\n\", \"\\nMicroservices are developed and deployed as containers independently of one another. This approach\\n\", \"means that a development team can be developing and deploying a certain microservice without\\nimpacti\", \"ng other subsystems.\\n\\nEach microservice has its own database, allowing it to be fully decoupled from\", \" other microservices.\\nWhen necessary, consistency between databases from different microservices is \", \"achieved using\\napplication-level integration events (through a logical event bus), as handled in Com\", \"mand and Query\\nResponsibility Segregation (CQRS). Because of that, the business constraints must emb\", \"race eventual\\nconsistency between the multiple microservices and related databases.\\n\\neShopOnContaine\", \"rs: A reference application for .NET and microservices deployed\\nusing containers\\n\\nSo that you can fo\", \"cus on the architecture and technologies instead of thinking about a hypothetical\\nbusiness domain th\", \"at you might not know, we have selected a well-known business domain\\u2014namely,\\na simplified e-commerce\", \" (e-shop) application that presents a catalog of products, takes orders from\\ncustomers, verifies inv\", \"entory, and performs other business functions. This container-based application\\nsource code Is avail\", \"able in the eSshopOnContainers GitHub repo.\\n\\nThe application consists of multiple subsystems, includ\", \"ing several store UI front ends (a Web\\napplication and a native mobile app), along with the back-end\", \" microservices and containers for all the\\nrequired server-side operations with several API Gateways \", \"as consolidated entry points to the internal\\nmicroservices. Figure 6-1 shows the architecture of the\", \" reference application.\\n\\n95 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Ba\", \"sed .NET Applications\\neShopOnContainers reference application\\n(Development environment architecture)\", \"\\n\\nClient apps Docker Host\\neShop mobile app I \\\\ ow ( Identity microservice (STS+users) |\\nXamarin.Form\", \"s | \\u2014 ww database ~\\\\\\nC# ; \\\\ \\\\ wee )\\nnor \\\\\\nen \\u2014<\\nRabbitMQ\\nm\\n<} or\\nS\\n=\\no| &\\n|\\nc \\u2014\\nmm . Azure\\n\\nTypeScri\", \"pt/Angular 2\\n\\n\\u20ac\\n\\u2014 = = = = = \\u2014 it = = = = \\u2014 = \\u2014\\n\\nFigure 6-1. The eShopOnContainers reference applicat\", \"ion architecture for development environment\\n\\nThe above diagram shows that Mobile and SPA clients co\", \"mmunicate to single API gateway endpoints,\\nthat then communicate to microservices. Traditional web c\", \"lients communicate to MVC microservice,\\nthat communicates to microservices through the API gateway.\\n\", \"\\nHosting environment. |n Figure 6-1, you see several containers deployed within a single Docker host\", \".\\nThat would be the case when deploying to a single Docker host with the docker-compose up\\ncommand. \", \"However, if you are using an orchestrator or container cluster, each container could be\\nrunning in a\", \" different host (node), and any node could be running any number of containers, as we\\nexplained earl\", \"ier in the architecture section.\\n\\nCommunication architecture. The eShopOnContainers application uses\", \" two communication types,\\ndepending on the kind of the functional action (queries versus updates and\", \" transactions):\\n\\n. Http client-to-microservice communication through API Gateways. This approach is \", \"used for\\nqueries and when accepting update or transactional commands from the client apps. The\\nappro\", \"ach using API Gateways is explained in detail in later sections.\\n\\n\\u00b0 Asynchronous event-based communi\", \"cation. This communication occurs through an event bus\\nto propagate updates across microservices or \", \"to integrate with external applications. The\\nevent bus can be implemented with any messaging-broker \", \"infrastructure technology like\\nRabbitMQ, or using higher-level (abstraction-level) service buses lik\", \"e Azure Service Bus,\\nNServiceBus, MassTransit, or Brighter.\\n\\nThe application is deployed as a set of\", \" microservices in the form of containers. Client apps can\\ncommunicate with those microservices runni\", \"ng as containers through the public URLs published by\\nthe API Gateways.\\n\\n96 CHAPTER 5 | Designing an\", \"d Developing Multi-Container and Microservice-Based .NET Applications\\nData sovereignty per microserv\", \"ice\\n\\nIn the sample application, each microservice owns its own database or data source, although all\", \" SQL\\nServer databases are deployed as a single container. This design decision was made only to make\", \" it\\neasy for a developer to get the code from GitHub, clone it, and open it in Visual Studio or Visu\", \"al\\nStudio Code. Or alternatively, it makes it easy to compile the custom Docker images using the .NE\", \"T\\nCLI and the Docker CLI, and then deploy and run them in a Docker development environment. Either\\nw\", \"ay, using containers for data sources lets developers build and deploy in a matter of minutes withou\", \"t\\nhaving to provision an external database or any other data source with hard dependencies on\\ninfras\", \"tructure (cloud or on-premises).\\n\\nIn a real production environment, for high availability and for sc\", \"alability, the databases should be\\nbased on database servers in the cloud or on-premises, but not in\", \" containers.\\n\\nTherefore, the units of deployment for microservices (and even for databases in this a\", \"pplication) are\\nDocker containers, and the reference application is a multi-container application th\", \"at embraces\\nmicroservices principles.\\n\\nAdditional resources\\n\\n\\u00b0 eShopOnContainers GitHub repo. Source\", \" code for the reference application\\n\\nhttps://aka.ms/eShopOnContainers/\\n\\nBenefits of a microservice-b\", \"ased solution\\n\\nA microservice-based solution like this has many benefits:\\n\\nEach microservice is rela\", \"tively small\\u2014easy to manage and evolve. Specifically:\\n\\n. It is easy for a developer to understand an\", \"d get started quickly with good productivity.\\n. Containers start fast, which makes developers more p\", \"roductive.\\n. An IDE like Visual Studio can load smaller projects fast, making developers productive.\", \"\\n\\n. Each microservice can be designed, developed, and deployed independently of other\\nmicroservices,\", \" which provide agility because it is easier to deploy new versions of\\nmicroservices frequently.\\n\\nIt \", \"is possible to scale out individual areas of the application. For instance, the catalog service or\\nt\", \"he basket service might need to be scaled out, but not the ordering process. A microservices\\ninfrast\", \"ructure will be much more efficient with regard to the resources used when scaling out than a\\nmonoli\", \"thic architecture would be.\\n\\nYou can divide the development work between multiple teams. Each servic\", \"e can be owned by a\\nsingle development team. Each team can manage, develop, deploy, and scale their \", \"service\\nindependently of the rest of the teams.\\n\\nIssues are more isolated. If there is an issue in o\", \"ne service, only that service is initially impacted\\n(except when the wrong design Is used, with dire\", \"ct dependencies between microservices), and other\\nservices can continue to handle requests. In contr\", \"ast, one malfunctioning component in a monolithic\\n\\n97 CHAPTER 5 | Designing and Developing Multi-Con\", \"tainer and Microservice-Based .NET Applications\\ndeployment architecture can bring down the entire sy\", \"stem, especially when it involves resources, such\\nas amemory leak. Additionally, when an issue in a \", \"microservice is resolved, you can deploy just the\\naffected microservice without impacting the rest o\", \"f the application.\\n\\nYou can use the latest technologies. Because you can start developing services i\", \"ndependently and\\nrun them side by side (thanks to containers and .NET), you can start using the late\", \"st technologies and\\nframeworks expediently instead of being stuck on an older stack or framework for\", \" the whole\\napplication.\\n\\nDownsides of a microservice-based solution\\n\\nA microservice-based solution l\", \"ike this also has some drawbacks:\\n\\nDistributed application. Distributing the application adds comple\", \"xity for developers when they are\\ndesigning and building the services. For example, developers must \", \"implement inter-service\\ncommunication using protocols like HTTP or AMQP, which adds complexity for t\", \"esting and exception\\nhandling. It also adds latency to the system.\\n\\nDeployment complexity. An applic\", \"ation that has dozens of microservices types and needs high\\nscalability (it needs to be able to crea\", \"te many instances per service and balance those services across\\nmany hosts) means a high degree of d\", \"eployment complexity for IT operations and management. If\\nyou are not using a microservice-oriented \", \"infrastructure (like an orchestrator and scheduler), that\\nadditional complexity can require far more\", \" development efforts than the business application itself.\\n\\nAtomic transactions. Atomic transactions\", \" between multiple microservices usually are not possible.\\nThe business requirements have to embrace \", \"eventual consistency between multiple microservices.\\n\\nIncreased global resource needs (total memory,\", \" drives, and network resources for all the servers or\\nhosts). In many cases, when you replace a mono\", \"lithic application with a microservices approach, the\\namount of initial global resources needed by t\", \"he new microservice-based application will be larger\\nthan the infrastructure needs of the original m\", \"onolithic application. This approach is because the\\nhigher degree of granularity and distributed ser\", \"vices requires more global resources. However, given\\nthe low cost of resources in general and the be\", \"nefit of being able to scale out certain areas of the\\napplication compared to long-term costs when e\", \"volving monolithic applications, the increased use of\\nresources is usually a good tradeoff for large\", \", long-term applications.\\n\\nIssues with direct client-to-microservice communication. When the applica\", \"tion is large, with\\ndozens of microservices, there are challenges and limitations if the application\", \" requires direct client-\\nto-microservice communications. One problem is a potential mismatch between\", \" the needs of the\\nclient and the APIs exposed by each of the microservices. In certain cases, the cl\", \"ient application might\\nneed to make many separate requests to compose the UI, which can be inefficie\", \"nt over the Internet\\nand would be impractical over a mobile network. Therefore, requests from the cl\", \"ient application to the\\nback-end system should be minimized.\\n\\nAnother problem with direct client-to-\", \"microservice communications is that some microservices might\\nbe using protocols that are not Web-fri\", \"endly. One service might use a binary protocol, while another\\nservice might use AMQP messaging. Thos\", \"e protocols are not firewall-friendly and are best used\\ninternally. Usually, an application should u\", \"se protocols such as HTTP and WebSockets for\\ncommunication outside of the firewall.\\n\\n98 CHAPTER 5 | \", \"Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nYet another drawba\", \"ck with this direct client-to-service approach Is that it makes it difficult to refactor\\nthe contrac\", \"ts for those microservices. Over time developers might want to change how the system is\\npartitioned \", \"into services. For example, they might merge two services or split a service into two or\\nmore servic\", \"es. However, If clients communicate directly with the services, performing this kind of\\nrefactoring \", \"can break compatibility with client apps.\\n\\nAs mentioned in the architecture section, when designing \", \"and building a complex application based\\non microservices, you might consider the use of multiple fi\", \"ne-grained API Gateways instead of the\\nsimpler direct client-to-microservice communication approach.\", \"\\n\\nPartitioning the microservices. Finally, no matter, which approach you take for your microservice\\n\", \"architecture, another challenge is deciding how to partition an end-to-end application into multiple\", \"\\nmicroservices. As noted in the architecture section of the guide, there are several techniques and\\n\", \"approaches you can take. Basically, you need to identify areas of the application that are decoupled\", \"\\nfrom the other areas and that have a low number of hard dependencies. In many cases, this approach\\n\", \"is aligned to partitioning services by use case. For example, in our e-shop application, we have an\\n\", \"ordering service that is responsible for all the business logic related to the order process. We als\", \"o\\nhave the catalog service and the basket service that implement other capabilities. Ideally, each s\", \"ervice\\nshould have only a small set of responsibilities. This approach is similar to the single resp\", \"onsibility\\nprinciple (SRP) applied to classes, which states that a class should only have one reason\", \" to change. But\\nin this case, it is about microservices, so the scope will be larger than a single c\", \"lass. Most of all, a\\nmicroservice has to be autonomous, end to end, including responsibility for its\", \" own data sources.\\n\\nExternal versus internal architecture and design patterns\\n\\nThe external architec\", \"ture is the microservice architecture composed by multiple services, following the\\nprinciples descri\", \"bed in the architecture section of this guide. However, depending on the nature of\\neach microservice\", \", and independently of high-level microservice architecture you choose, it is\\ncommon and sometimes a\", \"dvisable to have different internal architectures, each based on different\\npatterns, for different m\", \"icroservices. The microservices can even use different technologies and\\nprogramming languages. Figur\", \"e 6-2 illustrates this diversity.\\n\\n99 CHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications\\nExternal architecture \\u2014 Internal architecture\\noer application per mi\", \"croservice\\n\\n| Back end I\\n~ Client apps\\n| app ( =\\n.\\na \\u2014=_\\u2014 \\\\ A Ns \\\\Seontainer__ ON\\nWeb ; \\u2014e8-\\u2014\\napp; i\", \"t ( Microservice 3\\nee / I | Web AP\\nrr\\nPee LL\\n\\u00a2 External microservice patterns * Simple data driven/C\", \"RUD design versus\\n* API Gateway advanced design patterns, DDD, etc.\\n* Resilient communication * Sing\", \"le or multiple libraries\\n* Pub/Sub and event driven * Dependency Injection, loC, and SOLID\\n\\nFigure 6\", \"-2. External versus internal architecture and design\\n\\nFor instance, in our eshopOnContainers sample,\", \" the catalog, basket, and user profile microservices are\\nsimple (basically, CRUD subsystems). Theref\", \"ore, their internal architecture and design is\\nstraightforward. However, you might have other micros\", \"ervices, such as the ordering microservice,\\nwhich is more complex and represents ever-changing busin\", \"ess rules with a high degree of domain\\ncomplexity. In cases like these, you might want to implement \", \"more advanced patterns within a\\nparticular microservice, like the ones defined with domain-driven de\", \"sign (DDD) approaches, as we are\\ndoing in the eShopOnContainers ordering microservice. (We will revi\", \"ew these DDD patterns in the\\nsection later that explains the implementation of the eShopOnContainers\", \" ordering microservice.)\\n\\nAnother reason for a different technology per microservice might be the na\", \"ture of each microservice.\\nFor example, it might be better to use a functional programming language \", \"like F#, or even a language\\nlike R if you are targeting Al and machine learning domains, instead of \", \"a more object-oriented\\nprogramming language like C#.\\n\\nThe bottom line is that each microservice can \", \"have a different internal architecture based on different\\ndesign patterns. Not all microservices sho\", \"uld be implemented using advanced DDD patterns, because\\nthat would be over-engineering them. Similar\", \"ly, complex microservices with ever-changing business\\nlogic should not be implemented as CRUD compon\", \"ents, or you can end up with low-quality code.\\n\\nThe new world: multiple architectural patterns and p\", \"olyglot\\nmicroservices\\n\\nThere are many architectural patterns used by software architects and develop\", \"ers. The following are a\\nfew (mixing architecture styles and architecture patterns):\\n\\n. Simple CRUD,\", \" single-tier, single-layer.\\n\\n100 CHAPTER 5 | Designing and Developing Multi-Container and Microservi\", \"ce-Based .NET Applications\\n. Traditional N-Layered.\\n\\n. Domain-Driven Design N-layered.\\n\\n\\u00b0 Clean Arch\", \"itecture (as used with eshopOnWeb)\\n\\n\\u00b0 Command and Query Responsibility Segregation (CQRS).\\n\\u00b0 Event-D\", \"riven Architecture (EDA).\\n\\nYou can also build microservices with many technologies and languages, su\", \"ch as ASP.NET Core Web\\nAPIs, NancyFx, ASP.NET Core SignalR (available with .NET Core 2 or later), F#\", \", Node.js, Python, Java,\\nC++, GoLang, and more.\\n\\nThe important point is that no particular architect\", \"ure pattern or style, nor any particular technology, is\\nright for all situations. Figure 6-3 shows s\", \"ome approaches and technologies (although not in any\\nparticular order) that could be used in differe\", \"nt microservices.\\n\\nThe Multi-Architectural-Patterns and polyglot microservices world\\n\\n* ASP.NET Core\", \"\\n* Queries projection\\n\\n* ASP.NET Core\\n* DDD & CQRS patterns\\n\\n* ASP.NET Core\\n\\u00a2 Simple CRUD Design\\n\\n((\", \" Microservice 1 \\u2018 ( \\u201cMicroservice 2 oN ( Microservice 3 \\u2018\\n| em SQL Server eee SQL Server == DocDB /\\n\", \"Key a database ww database Key 3] MongoDB\\n\\n| Container Container Container\\n\\n|\\n\\n|\\n\\n|\\n\\neee ee ee ae ee\", \" ee\\n\\n\\\\\\n| |\\n| |\\n| |\\n| |\\n| |\\n|\\n\\n|\\n| |\\n|\\n\\n\\\\\\n\\na=~a\\u2014osoer eee\\n\\n\\u2018\\\\2_Entity Framework Core /  \\\\2_EF Core + \", \"Dapper ZN 2_Pocds/Mongobs AM -/\\n(( \\u201cMicroservice 4 5 ( \\u201cMicroservice 5 5 ( \\u201cMicroservice6 }\\u201d\\u00a9 \\u00bb\\n| Po\", \"stgreSQL! | = | |\\nKk )}\\u2014__m gresQ Vy xrey\\u2014__- yaRedis cache} | () om Mysql\\n| WD database 1 | . it \\u2014\\u2014\", \" database !\\n| Container ; | Container i | Container\\n* NancyFX (.NET Core) | * ASP.NET Core | + Node.\", \"js |\\n1 Simple CRUD Design 1 os Simple CRUD Design | \\u00a9 Simple CRUD Design\\nNot Massive UY \\u2018\\\\t RedisAPL\", \" vo \\\\ yy\\n( \\u201cMicroservice 7 \\u2018 ( \\u201cMicroservice 8 \\\\ ( \\u201cMicroservice 9 \\u2018\\n| ey ee MySa! | Kel ee Oracle |\", \" roy\\u2014_- ee Event Store |\\n: ww database ! | : | LJ database ! | : io database!\\n| Container | Containe\", \"r | Container\\n| * Python | | + Java | | + ASP.NET Core |\\n| * Simple CRUD Design | \\u00a9 DDD patterns | \\u00a2\", \" Event Sourcing patterns\\nie oe _/ \\\\ oe / No Event Store API oe /\\n(\\\" Microservice 10 } (- Microservic\", \"e 11 } (\\\" Microservice 12 }\\n| l |\\n| + SignalR(.NETCore2) | | + Fit NET Core I * GoLang\\n| \\u00a2 Hub for R\", \"ealTimecomm. | ! * i.e. Calculus focused | | \\u00a2 Stateless process |\\n\\\\ Container | Container | Contain\", \"er |\\n/ / /\\n~ ~ a\\n\\ncc cc se ee ee ee ee es ee ca a a\\n\\nFigure 6-3. Multi-architectural patterns and th\", \"e polyglot microservices world\\n\\nMulti-architectural pattern and polyglot microservices means you can\", \" mix and match languages and\\ntechnologies to the needs of each microservice and still have them talk\", \"ing to each other. As shown in\\nFigure 6-3, in applications composed of many microservices (Bounded C\", \"ontexts in domain-driven\\ndesign terminology, or simply \\u201csubsystems\\u201d as autonomous microservices), yo\", \"u might implement\\neach microservice in a different way. Each might have a different architecture pat\", \"tern and use different\\nlanguages and databases depending on the application's nature, business requi\", \"rements, and\\npriorities. In some cases, the microservices might be similar. But that is not usually \", \"the case, because\\neach subsystem\\u2019s context boundary and requirements are usually different.\\n\\n101 CHA\", \"PTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nFor insta\", \"nce, for a simple CRUD maintenance application, it might not make sense to design and\\nimplement DDD \", \"patterns. But for your core domain or core business, you might need to apply more\\nadvanced patterns \", \"to tackle business complexity with ever-changing business rules.\\n\\nEspecially when you deal with larg\", \"e applications composed by multiple subsystems, you should not\\napply a single top-level architecture\", \" based on a single architecture pattern. For instance, CQRS should\\nnot be applied as a top-level arc\", \"hitecture for a whole application, but might be useful for a specific set\\nof services.\\n\\nThere is no \", \"silver bullet or a right architecture pattern for every given case. You cannot have \\u201cone\\narchitectur\", \"e pattern to rule them all.\\u201d Depending on the priorities of each microservice, you must\\nchoose a dif\", \"ferent approach for each, as explained in the following sections.\\n\\nCreating a simple data-driven CRU\", \"D microservice\\n\\nThis section outlines how to create a simple microservice that performs create, read\", \", update, and\\ndelete (CRUD) operations on a data source.\\n\\nDesigning a simple CRUD microservice\\n\\nFrom\", \" a design point of view, this type of containerized microservice is very simple. Perhaps the\\nproblem\", \" to solve is simple, or perhaps the implementation is only a proof of concept.\\n\\n( Microservice 1 >)\\n\", \"Ygee ae '\\n\\nponnneonnannaaa= I\\n\\u2018Client apps \\\\y\\n\\n} \\\\ container /\\n' Mobile ee ere\\n' app ( API Gateway |\", \" ( Microservice 2 4\\n(pp \\u2014 ean .____ /\\n| Web .\\u2014\\u2014\\u2122 @-\\n\\n( app = | tN ier oservice 3\\u201d\\n\\nWeb AP\\n\\n( Microse\", \"rvice 3 >)\\nart\\n' vreu Ar\\n\\nExternal microservice patterns Internal design patterns per microservice\\nA\", \"PI Gateway\\n\\nResilient communication\\n\\nPub/Sub and event driven\\n\\nFigure 6-4. Internal design for simpl\", \"e CRUD microservices\\n\\nAn example of this kind of simple data-drive service is the catalog microservi\", \"ce from the\\neShopOnContainers sample application. This type of service implements all its functional\", \"ity in a single\\nASP.NET Core Web API project that includes classes for its data model, its business \", \"logic, and its data\\naccess code. It also stores its related data in a database running in SQL Server\", \" (as another container\\nfor dev/test purposes), but could also be any regular SQL Server host, as sho\", \"wn in Figure 6-5.\\n\\n102 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applications\\nData-Driven/CRUD microservice container\\n\\ni _ ioeieeeetietienntimenimentiantantetmmn\", \"tentmmanntentendamtentetemtetetemtetetemtamtamietiataeteetantememtetemtent\\n\\n\\u2014 \\u2014 \\u2014 \\u2014 =\\n\\n~\\\\\\n\\n\\\\\\n\\ni\\n\\u00b0\\n\\u2018Q\", \",\\na]\\n|S\\nfe)\\nfs?)\\not\\n\\n| a\\n\\u00b0\\nQa\\n=\\nal\\n=\\n\\u00b0\\n\\u201c\\ni)\\n=\\ns.\\na]\\n\\u00a9\\n\\u201c\\n\\nExternal IP\\nand Port\\n\\nSQL Server\\n\\nTechnolog\", \"ies:\\nASP.NET Core\\nEntity Framework Core /\\n\\\\ * \\u2014 Swashbuckle (Optional) y\\n\\nss ee ee\\n\\n|\\n\\n|\\n\\n|\\n\\n[>\\n\\nCon\", \"trollers\\n\\u201cCatalog\\u201d \\\\\\n\\nData Access Database |\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\nee ee\\n\\u201c\\n\\nFigure 6-5. Simple data-driv\", \"en/CRUD microservice design\\n\\nThe previous diagram shows the logical Catalog microservice, that inclu\", \"des its Catalog database,\\nwhich can be or not in the same Docker host. Having the database in the sa\", \"me Docker host might be\\ngood for development, but not for production. When you are developing this k\", \"ind of service, you only\\nneed ASP.NET Core and a data-access API or ORM like Entity Framework Core. \", \"You could also\\ngenerate Swagger metadata automatically through Swashbuckle to provide a description \", \"of what your\\nservice offers, as explained in the next section.\\n\\nNote that running a database server \", \"like SQL Server within a Docker container is great for\\ndevelopment environments, because you can hav\", \"e all your dependencies up and running without\\nneeding to provision a database in the cloud or on-pr\", \"emises. This approach is convenient when\\nrunning integration tests. However, for production environm\", \"ents, running a database server in a\\ncontainer is not recommended, because you usually do not get hi\", \"gh availability with that approach.\\nFor a production environment in Azure, it is recommended that yo\", \"u use Azure SQL DB or any other\\ndatabase technology that can provide high availability and high scal\", \"ability. For example, for a NoSQL\\napproach, you might choose CosmosDB.\\n\\nFinally, by editing the Dock\", \"erfile and docker-compose.yml metadata files, you can configure how the\\nimage of this container will\", \" be created\\u2014what base image it will use, plus design settings such as\\ninternal and external names an\", \"d TCP ports.\\n\\nImplementing a simple CRUD microservice with ASP.NET Core\\n\\nTo implement a simple CRUD \", \"microservice using .NET and Visual Studio, you start by creating a\\nsimple ASP.NET Core Web API proje\", \"ct (running on .NET so it can run on a Linux Docker host), as\\nshown in Figure 6-6.\\n\\n103 CHAPTER 5 | \", \"Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nCreate a new proje\", \"ct\\n\\nRecent project templates All languages All platforms . All project types\\n\\n@ ASP.NET Core Web App\", \"lication\\n\\nCo and web APIs for s, Linux and macOS using .NET Core or .NET Framework, Create web apps \", \"with\\n= Windows Forms App (.NET) taza < (6 ruilar React ar React + Redinw\\n\\n= gRPC Service\\n\\nBB concole\", \" App (NET Core Create a new ASP.NET Core web application\\n3 xUnit Test Project (.NET Core)\\n\\n-NET Core\", \" ~ ASP.NET Core 5.0\\n& Class Library (.NET Core)\\n\\nASP.NET Core Empty Authentication\\nDs\\n\\nAn empty proj\", \"ect template for creating an ASP.NET Core application. This template does not have any content in No\", \" Authentication\\nit.\\n\\nASP.NET Core Web API\\n\\nA project template for creating an ASP.NET Core applicati\", \"on with an example Controller for a RESTful HTTP service.\\nThis template can also be used for ASP.NET\", \" Core MVC Views and Controllers.\\nAdvanced\\n\\nASP.NET Core Web App \\u00a5| Configure for HTTPS\\n\\nA project te\", \"mplate for creating an ASP.NET Core application with example ASP.NET Razor Pages content. \\u00a5| Enable \", \"Docker Support\\n(Requires )\\nASP.NET Core Web App (Model-View-Controller)\\nLinux\\nA project template for\", \" creating an ASP.NET Core application with example ASP.NET Core MVC Views and\\nControllers. This temp\", \"late can also be used for RESTful HTTP services.\\n\\u00a5} Enable OpenAPI support\\n\\nA ASP.NET Core with Angu\", \"lar\\n\\nA project template for creating an ASP.NET Core application with Angular\\n\\nASP.NET Core with Rea\", \"ct.js Author: Microsoft\\n\\nSource: Templates 5.0.0\\n\\nBack Create\\n\\nFigure 6-6. Creating an ASP.NET Core \", \"Web API project in Visual Studio 2019\\n\\nTo create an ASP.NET Core Web API Project, first select an AS\", \"P.NET Core Web Application and then\\nselect the API type. After creating the project, you can impleme\", \"nt your MVC controllers as you would\\nin any other Web API project, using the Entity Framework API or\", \" other API. In a new Web API project,\\nyou can see that the only dependency you have in that microser\", \"vice is on ASP.NET Core itself.\\nInternally, within the Microsoft.AspNetCore.All dependency, it is re\", \"ferencing Entity Framework and\\nmany other .NET NuGet packages, as shown in Figure 6-7.\\n\\n104 CHAPTER \", \"5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n2)\\n\\n& Connecte\", \"d Services\\n\\n-F\\n\\n40 oe Dependencies\\n\\n> og Analyzers\\n\\n4 ef] Frameworks\\nef MicrosofttAspNetCore.App\\nee!\", \" Micrasoft.NETCore.App\\n\\n4 \\u2018WB Packages\\n\\u2018@ AspNetCore.HealthChecks.AzureServiceBus (3.0.0)\\n\\u2018@ AspNetC\", \"ore.HealthChecks.AzureStorage (3.0.1)\\n\\u2018@ AspNetCore.HealthChecks.Rabbitmg (3.0.3)\\n\\u2018@ AspNetCore.Heal\", \"thChecks.SqlServer (3.0.0)\\n\\u2018@ AspNetCore.HealthChecks.UI.Client (3.0.0)\\n\\u2018@ Autofac.Extensions.Depend\", \"encylnjection (5.0.1)\\n\\u2018@ Google.Protobuf (3.11.2)\\n\\u2018 Grpc.AspNetCore.Server (2.25.0)\\n'@ Grpc.Tools (2\", \".25.0)\\n\\u2018@ Microsoft.ApplicationInsights.AspNetCore (2.12.0)\\n\\u2018@ Microsoft. ApplicationInsights.Depend\", \"encyCollector (2.12.0)\\n\\u2018@ Microsoft.Applicationinsights.Kubernetes (1.1.1)\\n\\u2018B Microsoft.AspNetCore.H\", \"ealthChecks (1.0.0)\\n'@ Microsoft.Extensions. Configuration. AzureKeyVault (3.1.0)\\n\\u2018@ Microsoft.Exten\", \"sions.Logging.AzureAppServices (3.1.0)\\n\\u2018 Serilog.AspNetCore (3.2.0)\\n\\nerilog.Enrichers.Environment (2\", \".1.3)\\n\\nenlog.Sinks.Console (3.1.2-dev-00824)\\nernlog.Sinks.Http (5.2.0)\\nerilog.Sinks.Seq (4.0.1-dev-0\", \"0159)\\nwashbuckle.AspNetCore (5.0.0-re2)\\n\\u2018 System./0.Compression.ZipFile (4.4.0-beta-24913-02)\\n> [EF]\", \" Projects\\nb aM Properties\\n\\ni\\\".\\ni.\\n*.\\nis\\ni\\ni.\\n\\n5\\n5\\n5\\n5\\n5\\n5\\n5\\n\\nFigure 6-7. Dependencies in a simple CR\", \"UD Web API microservice\\n\\nThe API project includes references to Microsoft.AsoNetCore.App NuGet packa\", \"ge, that includes\\nreferences to all essential packages. It could include some other packages as well\", \".\\n\\nEntity Framework (EF) Core is a lightweight, extensible, and cross-platform version of the popula\", \"r\\nEntity Framework data access technology. EF Core is an object-relational mapper (ORM) that enables\", \"\\n.NET developers to work with a database using .NET objects.\\n\\nThe catalog microservice uses EF and t\", \"he SQL Server provider because its database is running ina\\ncontainer with the SQL Server for Linux D\", \"ocker image. However, the database could be deployed into\\nany SQL Server, such as Windows on-premise\", \"s or Azure SQL DB. The only thing you would need to\\n\\nchange is the connection string in the ASP.NET \", \"Web API microservice.\\n\\nThe data model\\n\\nWith EF Core, data access is performed by using a model. A mo\", \"del is made up of (domain model)\\n\\nentity classes and a derived context (DbContext) that represents a\", \" session with the database, allowing\\n\\nyou to query and save data. You can generate a model from an e\", \"xisting database, manually code a\\n\\nmodel to match your database, or use EF migrations technique to c\", \"reate a database from your model,\\n\\nusing the code-first approach (that makes it easy to evolve the d\", \"atabase as your model changes over\\ntime). For the catalog microservice, the last approach has been u\", \"sed. You can see an example of the\\n\\nCatalogltem entity class in the following code example, which is\", \" a simple Plain Old Class Object\\n(POCO) entity class.\\n\\npublic class CatalogItem\\n\\n{\\n\\npublic\\npublic\\npu\", \"blic\\npublic\\npublic\\npublic\\npublic\\npublic\\npublic\\npublic\\npublic\\npublic\\npublic\\n\\npublic\\npublic\\n\\nint Id { \", \"get; set; }\\n\\nstring Name { get; set; }\\n\\nstring Description { get; set; }\\ndecimal Price { get; set; }\", \"\\n\\nstring PictureFileName { get; set; }\\nstring PictureUri { get; set; }\\n\\nint CatalogTypelId { get; se\", \"t; }\\nCatalogType CatalogType { get; set; }\\nint CatalogBrandId { get; set; }\\nCatalogBrand CatalogBran\", \"d { get; set; }\\nint AvailableStock { get; set; }\\n\\nint RestockThreshold { get; set; }\\nint MaxStockThr\", \"eshold { get; set; }\\n\\nbool OnReorder { get; set; }\\nCatalogItem() { }\\n\\n// Additional code ...\\n\\nYou al\", \"so need a DbContext that represents a session with the database. For the catalog microservice,\\n\\nthe \", \"CatalogContext class derives from the DbContext base class, as shown in the following example:\\n\\npubl\", \"ic class CatalogContext : DbContext\\n{\\n\\npublic\\n{ }\\n\\npublic\\npublic\\npublic\\n\\nCatalogContext (DbContextOp\", \"tions<CatalogContext> options) : base(options)\\n\\nDbSet<CatalogItem> CatalogItems { get; set; }\\nDbSet<\", \"CatalogBrand> CatalogBrands { get; set; }\\nDbSet<CatalogType> CatalogTypes { get; set; }\\n\\n// Addition\", \"al code ...\\n\\nYou can have additional DoContext implementations. For example, in the sample Catalog.A\", \"PI\\n\\nmicroservice, there's a second DbContext named CatalogContextSeed where it automatically\\n\\npopula\", \"tes the sample data the first time it tries to access the database. This method is useful for demo\\nd\", \"ata and for automated testing scenarios, as well.\\n\\n106\\n\\nCHAPTER 5 | Designing and Developing Multi-C\", \"ontainer and Microservice-Based .NET Applications\\nWithin the DbContext, you use the OnModelCreating \", \"method to customize object/database entity\\nmappings and other EF extensibility points.\\n\\nQuerying dat\", \"a from Web API controllers\\n\\nInstances of your entity classes are typically retrieved from the databa\", \"se using Language-Integrated\\nQuery (LINQ), as shown in the following example:\\n\\n[Route(\\\"api/v1/[contr\", \"oller]\\\") |\\npublic class CatalogController : ControllerBase\\n\\n{\\n\\nprivate readonly CatalogContext _cata\", \"logContext;\\nprivate readonly CatalogSettings _settings;\\nprivate readonly ICatalogIntegrationEventSer\", \"vice _catalogIntegrationEventService;\\n\\npublic CatalogController(\\n\\n}\\n\\nCatalogContext context,\\nIOption\", \"sSnapshot<CatalogSettings> settings,\\nICatalogiIntegrationEventService catalogIntegrationEventService\", \" )\\n\\n_catalogContext = context ?? throw new ArgumentNullException(nameof (context) ) ;\\n_catalogIntegr\", \"ationEventService = catalogIntegrationEventService\\n?? throw new ArgumentNullException(nameof (catalo\", \"gIntegrationEventService) ) ;\\n\\n_settings = settings.Value;\\ncontext.ChangeTracker.QueryTrackingBehavi\", \"or = QueryTrackingBehavior .NoTracking;\\n\\n// GET api/v1/[ controller ]/items[ ?pageSize=3&pageIndex=1\", \"0 |\\n\\n[HttpGet ]\\n\\n[Route( \\\"items\\\" ) ]\\n\\n[ ProducesResponseType(typeof (PaginatedItemsViewModel<Catalog\", \"Iitem>),\\n\\n(int )HttpStatusCode.OK) ]\\n\\n[| ProducesResponseType(typeof(IEnumerable<CatalogItem>), (int\", \")HttpStatusCode.OK) ]\\n[| ProducesResponseType( (int )HttpStatusCode.BadRequest) |\\n\\npublic async Task\", \"<IActionResult> ItemsAsync(\\n\\n[FromQuery |int pageSize = 10,\\n[FromQuery |int pageIndex = @,\\nstring id\", \"s = null)\\n\\nif (!string.IsNullOrEmpty(ids) )\\n{\\n\\nvar items = await GetItemsByIdsAsync(ids) ;\\n\\nif (!ite\", \"ms.Any())\\n{\\n\\nreturn BadRequest(\\\"ids value invalid. Must be comma-separated list of\\n\\nnumbers\\\") ;\\n\\n107\", \"\\n\\n}\\n\\nreturn Ok(items) ;\\n\\n}\\n\\nvar totalItems = await _catalogContext.CatalogItems\\n. LongCountAsync();\\n\", \"\\nvar itemsOnPage = await _catalogContext.CatalogItems\\n\\n.OrderBy(c => c.Name)\\n.Skip(pageSize * pageIn\", \"dex)\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n\", \". Take(pageSize)\\n. ToListAsync();\\n\\nitemsOnPage = ChangeUriPlaceholder(itemsOnPage) ;\\n\\nvar model = ne\", \"w PaginatedItemsViewModel<CatalogItem> (\\npageIndex, pageSize, totalItems, itemsOnPage) ;\\n\\nreturn Ok(\", \"mode1) ;\\n\\nSaving data\\n\\nData is created, deleted, and modified in the database using instances of you\", \"r entity classes. You\\ncould add code like the following hard-coded example (mock data, in this case)\", \" to your Web API\\ncontrollers.\\n\\nvar catalogiItem = new CatalogItem() {CatalogTypeId=2, CatalogBrandId\", \"=2,\\nName=\\\"Roslyn T-Shirt\\\", Price = 12};\\n\\n_context.Catalog.Add(catalogItem) ;\\n_context.SaveChanges() \", \";\\n\\nDependency Injection in ASP.NET Core and Web API controllers\\n\\nIn ASP.NET Core, you can use Depend\", \"ency Injection (DI) out of the box. You do not need to set up a\\nthird-party Inversion of Control (lo\", \"C) container, although you can plug your preferred loC container\\n\\ninto the ASP.NET Core infrastructu\", \"re if you want. In this case, it means that you can directly inject the\\nrequired EF DBContext or add\", \"itional repositories through the controller constructor.\\n\\nIn the CatalogController class mentioned e\", \"arlier, CatalogContext (which inherits from DbContext) type\\nis injected along with the other require\", \"d objects in the CatalogController() constructor.\\n\\nAn important configuration to set up in the Web A\", \"PI project is the DoContext class registration into\\nthe service's loC container. You typically do so\", \" in the Program.cs file by calling the\\nbuilder.Services.AddDbContext<CatalogContext>() method, as sh\", \"own in the following simplified\\nexample:\\n\\n// Additional code...\\n\\nbuilder.Services.AddDbContext<Catal\", \"ogContext>(options =>\\n{\\noptions .UseSqlServer (builder.Configuration[ \\\"ConnectionString\\u201d ],\\nsqlServe\", \"rOptionsAction: sqlOptions =>\\n{\\nsqlOptions .MigrationsAssembly (\\ntypeof (Program) .GetTypeInfo().Ass\", \"embly.GetName() .Name) ;\\n\\n//Configuring Connection Resiliency:\\n\\nsqlOptions.\\nEnableRetryOnFailure(max\", \"RetryCount: 5,\\nmaxRetryDelay: TimeSpan.FromSeconds(3@),\\nerrorNumbersToAdd: null) ;\\n\\n})3\\n\\n108 CHAPTER\", \" 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n// Changing d\", \"efault behavior when client evaluation occurs to throw.\\n\\n// Default in EFCore would be to log warnin\", \"g when client evaluation is done.\\n\\noptions.ConfigureWarnings(warnings => warnings. Throw(\\nRelational\", \"EventId.QueryClientEvaluationWarning) ) ;\\n\\n})5\\n\\nAdditional resources\\n\\n. Querying Data\\nhttps://learn.\", \"microsoft.com/ef/core/querying/index\\n\\n\\u00b0 Saving Data\\nhttps://learn.microsoft.com/ef/core/saving/index\", \"\\n\\nThe DB connection string and environment variables used by Docker\\ncontainers\\n\\nYou can use the ASP.\", \"NET Core settings and add a ConnectionString property to your settings.json file\\nas shown in the fol\", \"lowing example:\\n\\n{\\n\\\"\\u201cConnectionString\\\": \\\"Server=tcp:127.0.0.1,5433;Initial\\nCatalog=Microsoft.eShopOn\", \"Containers.Services.CatalogDb;User Id=sa;Password=[ PLACEHOLDER |\\\",\\n\\\"ExternalCatalogBaseUrl\\\": \\\"http:\", \"//host.docker.internal:5101\\\",\\n\\\"Logging\\\": {\\n\\\"IncludeScopes\\\": false,\\n\\u201cLogLevel\\\": {\\n\\\"Default\\\": \\\"Debug\\\",\", \"\\n\\\"System\\\": \\\"Information\\\",\\n\\\"Microsoft\\\": \\\"Information\\\"\\n\\nThe settings.json file can have default values\", \" for the ConnectionString property or for any other\\nproperty. However, those properties will be over\", \"ridden by the values of environment variables that\\nyou specify in the docker-compose.override.yml fi\", \"le, when using Docker.\\n\\nFrom your docker-compose.yml or docker-compose.override.yml files, you can i\", \"nitialize those\\nenvironment variables so that Docker will set them up as OS environment variables fo\", \"r you, as shown\\nin the following docker-compose.override.yml file (the connection string and other l\", \"ines wrap in this\\nexample, but it would not wrap in your own file).\\n\\n# docker-compose.override.yml\\n\\n\", \"#\\ncatalog-api:\\nenvironment:\\n\\nConnectionString=Server=sqldata;Database=Microsoft.eShopOnContainers.Se\", \"rvices.CatalogDb;Use\\nr Id=sa;Password=[ PLACEHOLDER ]\\n# Additional environment variables for this se\", \"rvice\\nports:\\n- \\\"5101:80\\\"\\n\\n109 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-\", \"Based .NET Applications\\nThe docker-compose.yml files at the solution level are not only more flexibl\", \"e than configuration files\\nat the project or microservice level, but also more secure if you overrid\", \"e the environment variables\\ndeclared at the docker-compose files with values set from your deploymen\", \"t tools, like from Azure\\nDevOps Services Docker deployment tasks.\\n\\nFinally, you can get that value f\", \"rom your code by using builder.Configuration\\\\[\\\"ConnectionString\\\"\\\\], as\\nshown in an earlier code exam\", \"ple.\\n\\nHowever, for production environments, you might want to explore additional ways on how to stor\", \"e\\nsecrets like the connection strings. An excellent way to manage application secrets is using Azure\", \" Key\\nVault.\\n\\nAzure Key Vault helps to store and safeguard cryptographic keys and secrets used by you\", \"r cloud\\napplications and services. A secret is anything you want to keep strict control of, like API\", \" keys,\\nconnection strings, passwords, etc. and strict control includes usage logging, setting expira\", \"tion,\\nmanaging access, among others.\\n\\nAzure Key Vault allows a detailed control level of the applica\", \"tion secrets usage without the need to let\\nanyone know them. The secrets can even be rotated for enh\", \"anced security without disrupting\\ndevelopment or operations.\\n\\nApplications have to be registered in \", \"the organization's Active Directory, so they can use the Key\\nVault.\\n\\nYou can check the Key Vault Con\", \"cepts documentation for more details.\\n\\nImplementing versioning in ASP.NET Web APIs\\n\\nAs business requ\", \"irements change, new collections of resources may be added, the relationships\\nbetween resources migh\", \"t change, and the structure of the data in resources might be amended.\\nUpdating a Web API to handle \", \"new requirements is a relatively straightforward process, but you must\\nconsider the effects that suc\", \"h changes will have on client applications consuming the Web API.\\nAlthough the developer designing a\", \"nd implementing a Web API has full control over that API, the\\ndeveloper does not have the same degre\", \"e of control over client applications that might be built by\\nthird-party organizations operating rem\", \"otely.\\n\\nVersioning enables a Web API to indicate the features and resources that it exposes. A clien\", \"t\\napplication can then submit requests to a specific version of a feature or resource. There are sev\", \"eral\\napproaches to implement versioning:\\n\\n. URI versioning\\n. Query string versioning\\n\\u00b0 Header versio\", \"ning\\n\\nQuery string and URI versioning are the simplest to implement. Header versioning is a good\\napp\", \"roach. However, header versioning Is not as explicit and straightforward as URI versioning.\\nBecause \", \"URL versioning is the simplest and most explicit, the eshopOnContainers sample application\\nuses URI \", \"versioning.\\n\\n110 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications\\nWith URI versioning, as in the eshopOnContainers sample application, each time you modify\", \" the Web\\nAPI or change the schema of resources, you add a version number to the URI for each resourc\", \"e.\\nExisting URIs should continue to operate as before, returning resources that conform to the schem\", \"a\\nthat matches the requested version.\\n\\nAs shown in the following code example, the version can be se\", \"t by using the Route attribute in the\\nWeb API controller, which makes the version explicit in the UR\", \"I (v1 in this case).\\n\\n[Route(\\\"api/v1/[controller]\\\") |\\npublic class CatalogController : ControllerBas\", \"e\\n\\nt\\n\\n// Implementation ...\\n\\nThis versioning mechanism is simple and depends on the server routing t\", \"he request to the\\nappropriate endpoint. However, for a more sophisticated versioning and the best me\", \"thod when using\\n\\nREST, you should use hypermedia and implement HATEOAS (Hypertext as the Engine of A\", \"pplication\\nState).\\n\\nAdditional resources\\n\\nASP.NET API Versioning https://github.com/dotnet/aspnet-ap\", \"i-versioning\\n\\nScott Hanselman. ASP.NET Core RESTful Web API versioning made easy\\nhttps://www.hanselm\", \"an.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx\\n\\nVersioning a RESTful web API\\nhttos://lea\", \"rn.microsoft.com/azure/architecture/best-practices/api-design#versioning-a-\\n\\nrestful-web-api\\n\\nRoy Fi\", \"elding. Versioning, Hypermedia, and REST\\n\\nhttos://www.infog.com/articles/roy-fielding-on-versionin\\n\\n\", \"Generating Swagger description metadata from your ASP.NET Core\\nWeb API\\n\\nSwagger is a commonly used o\", \"pen source framework backed by a large ecosystem of tools that helps\\nyou design, build, document, an\", \"d consume your RESTful APIs. It is becoming the standard for the APIs\\ndescription metadata domain. Y\", \"ou should include Swagger description metadata with any kind of\\nmicroservice, either data-driven mic\", \"roservices or more advanced domain-driven microservices (as\\nexplained in the following section).\\n\\nTh\", \"e heart of Swagger is the Swagger specification, which is API description metadata in a JSON or\\nYAML\", \" file. The specification creates the RESTful contract for your API, detailing all its resources and\\n\", \"operations in both a human- and machine-readable format for easy development, discovery, and\\nintegra\", \"tion.\\n\\nThe specification is the basis of the OpenAPI Specification (OAS) and is developed in an open\", \",\\ntransparent, and collaborative community to standardize the way RESTful interfaces are defined.\\n\\n1\", \"11\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nTh\", \"e specification defines the structure for how a service can be discovered and how its capabilities\\nu\", \"nderstood. For more information, including a web editor and examples of Swagger specifications\\nfrom \", \"companies like Spotify, Uber, Slack, and Microsoft, see the Swagger site (https://swagger.io).\\n\\nWhy \", \"use Swagger?\\n\\nThe main reasons to generate Swagger metadata for your APIs are the following.\\n\\nAbilit\", \"y for other products to automatically consume and integrate your APIs. Dozens of products\\nand commer\", \"cial tools and many libraries and frameworks support Swagger. Microsoft has high-level\\nproducts and \", \"tools that can automatically consume Swagger-based APIs, such as the following:\\n\\n. AutoRest. You can\", \" automatically generate .NET client classes for calling Swagger. This tool can\\nbe used from the CLI \", \"and it also integrates with Visual Studio for easy use through the GUI.\\n\\n. Microsoft Flow. You can a\", \"utomatically use and integrate your API into a high-level Microsoft\\nFlow workflow, with no programmi\", \"ng skills required.\\n\\n. Microsoft PowerApps. You can automatically consume your API from PowerApps mo\", \"bile apps\\nbuilt with PowerApps Studio, with no programming skills required.\\n\\n. Azure App Service Log\", \"ic Apps. You can automatically use and integrate your API into an Azure\\nApp Service Logic App, with \", \"no programming skills required.\\n\\nAbility to automatically generate API documentation. When you creat\", \"e large-scale RESTful APIs,\\nsuch as complex microservice-based applications, you need to handle many\", \" endpoints with different\\ndata models used in the request and response payloads. Having proper docum\", \"entation and having a\\nsolid API explorer, as you get with Swagger, is key for the success of your AP\", \"I and adoption by\\ndevelopers.\\n\\nSwagger\\u2019's metadata is what Microsoft Flow, PowerApps, and Azure Logi\", \"c Apps use to understand how\\nto use APIs and connect to them.\\n\\nThere are several options to automate\", \" Swagger metadata generation for ASP.NET Core REST API\\napplications, in the form of functional API h\", \"elp pages, based on swagger-ul.\\n\\nProbably the best know is Swashbuckle, which is currently used in e\", \"ShopOnContainers and we'll cover\\nin some detail in this guide but there\\u2019s also the option to use NSw\", \"ag, which can generate Typescript\\nand C# API clients, as well as C# controllers, from a Swagger or O\", \"penAPI specification and even by\\nscanning the .dll that contains the controllers, using NSwagStudio.\", \"\\n\\nHow to automate API Swagger metadata generation with the Swashbuckle NuGet\\npackage\\n\\nGenerating Swa\", \"gger metadata manually (in a JSON or YAML file) can be tedious work. However, you\\ncan automate API d\", \"iscovery of ASP.NET Web API services by using the Swashbuckle NuGet package to\\ndynamically generate \", \"Swagger API metadata.\\n\\nSwashbuckle automatically generates Swagger metadata for your ASP.NET Web API\", \" projects. It\\nsupports ASP.NET Core Web API projects and the traditional ASP.NET Web API and any oth\", \"er flavor,\\n\\n112 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET App\", \"lications\\nsuch as Azure API App, Azure Mobile App, Azure Service Fabric microservices based on ASP.N\", \"ET. It\\nalso supports plain Web API deployed on containers, as in for the reference application.\\n\\nSwa\", \"shbuckle combines API Explorer and Swagger or swagger-ui to provide a rich discovery and\\ndocumentati\", \"on experience for your API consumers. In addition to its Swagger metadata generator\\nengine, Swashbuc\", \"kle also contains an embedded version of swagger-ui, which it will automatically\\nserve up once Swash\", \"buckle is installed.\\n\\nThis means you can complement your API with a nice discovery UI to help develo\", \"pers to use your API.\\nIt requires a small amount of code and maintenance because it is automatically\", \" generated, allowing\\nyou to focus on building your API. The result for the API Explorer looks like F\", \"igure 6-8.\\n\\nSwagger UI\\n\\nA Not secure | host.docker.interna cs @& InPrivate {\\n\\nSwagger SO Tae ee iieu\", \"me \\u00a7Catalog.APl V1 v\\n\\neShopOnContainers - Catalog HTTP API @\\n\\napiswagger\\u2019/v 1/swagger js\\n\\nThe Catalo\", \"g Microservice HTTP API. This is a Data-Driven/CRUD microservice sample\\n\\n/api/v1/Catalog/items Vv\\n[u\", \"r | /api/v1/Catalog/items v]\\n/api/v1/Catalog/items Vv\\n| GET /api/v1/Catalog/items/{id} Vv\\n=\\n\\n/api/v1\", \"/Catalog/items/withname/ {name} Vv\\n\\nFigure 6-8. Swashbuckle API Explorer based on Swagger metadata\\u2014e\", \"ShopOnContainers catalog microservice\\n\\nThe Swashbuckle generated Swagger UI API documentation includ\", \"es all published actions. The API\\nexplorer is not the most important thing here. Once you have a Web\", \" API that can describe itself in\\nSwagger metadata, your API can be used seamlessly from Swagger-base\", \"d tools, including client\\nproxy-class code generators that can target many platforms. For example, a\", \"s mentioned, AutoRest\\nautomatically generates .NET client classes. But additional tools like swagger\", \"-codegen are also\\navailable, which allow code generation of API client libraries, server stubs, and \", \"documentation\\nautomatically.\\n\\nCurrently, Swashbuckle consists of five internal NuGet packages under \", \"the high-level metapackage\\nSwashbuckle.AsoNetCore for ASP.NET Core applications.\\n\\nAfter you have ins\", \"talled these NuGet packages in your Web API project, you need to configure\\nSwagger in the Program.cs\", \" class, as in the following simplified code:\\n\\n// Add framework services.\\n\\nbuilder.Services.AddSwagge\", \"rGen(options =>\\n\\n{\\n\\n113 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based \", \".NET Applications\\noptions.DescribeAllEnumsAsStrings() ;\\noptions.SwaggerDoc(\\\"v1i\\\", new OpenApilnfo\\n{\\n\", \"Title = \\\"\\u201ceShopOnContainers - Catalog HTTP API\\\",\\nVersion = \\\"v1\\\",\\nDescription = \\\"The Catalog Microser\", \"vice HTTP API. This is a Data-Driven/CRUD\\nmicroservice sample\\\"\\n})3\\n})3\\n\\n// Other startup code...\\n\\nap\", \"p .UseSwagger ( )\\n.UseSwaggerUI(c =>\\n\\n{\\nc. SwaggerEndpoint(\\\"/swagger/v1/swagger.json\\\", \\\"My API V1\\\");\", \"\\n})3\\n\\n~~\\n\\nOnce this is done, you can start your application and browse the following Swagger JSON an\", \"d\\nUI endpoints using URLs like these:\\n\\n:::{custom-style=CodeBox }\\n~*~ console\\nhttp: //<your-root-url\", \">/swagger/v1/swagger.json\\n\\nhttp: //<your-root-url>/swagger/\\n\\nYou previously saw the generated UI cre\", \"ated by Swashbuckle for a URL like http://<your-root-\\nurl>/swagger. In Figure 6-9, you can also see \", \"how you can test any API method.\\n\\n114 CHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications\\n| (4) Swagger UI x|/+ Vv = oO x\\n<\\u00a2 > OO fn @_localhost:5101/swagge +\", \"r x f\\u00a3 ef 5\\nCatalog v\\n\\n| cet | f/api/v1/Catalog/items\\n\\npageSize\\ninteger\\n\\n(query)\\n\\npagelndex\\ninteger\\n\", \"\\n(query)\\n\\nids\\nstring\\n\\n(query)\\n\\nnen comm ete [ease\\n\\ncurl -X GET \\u201chttp://locelhost:5101/api/vl/Catelog\", \"/items?pageSize=l2ipageiIndex=0\\\" -H \\u201caccept: text/plain\\u201d\\n\\nRequest URL\\n\\nhttp: //locelhost:5191/api/wl\", \"1/Catelog/items? pageSize=12ipsageIndex=8\\n\\nServer response\\n\\n200\\n\\n\\\"pageIndex\\\": 9,\\n\\\"pageSize\\\"\\u2122: 12,\\n\\\"c\", \"ount\\\": 12,\\n\\\"date\\\": [\\n\\n{\\n\\n\\\"id\\\": 2,\\n\\\".NET Black & White Mug\\n\\nption\\\": \\\".NET Black & White Mus\\\",\\n5\\n\\n\\\"pri\", \"ce\\\" \\u00ab5;\\n\\u201cpictureFileName\\\": \\\"2.pne\\\",\\n\\n\\u201cpictureUri\\\": \\u201chttp: //lLocelhost:5202/api/vl/c/catalog/items/2\", \"/pic/\\\",\\n\\\"\\u201ccataloglypeld\\u2122:\\n\\n\\\"\\u201ccataloglype\\\": null,\\n\\n\\u201ccatslogBrandId\\\"\\u2122: 2,\\n\\n\\\"\\u201ccatslogBrend\\u201d: null,\\n\\nFig\", \"ure 6-9. Swashbuckle UI testing the Catalog/Items API method\\n\\nThe Swagger UI API detail shows a samp\", \"le of the response and can be used to execute the real API,\\nwhich is great for developer discovery. \", \"Figure 6-10 shows the Swagger JSON metadata generated\\nfrom the eShopOnContainers microservice (which\", \" is what the tools use underneath) when you request\\nhttp://< your-root-url>/swagger/v1/swagger.json \", \"using Postman.\\n\\n115 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" Applications\\nD Runner Builder ( \\u00bb) Sign In a & 4\\n\\nNo Environment\\nhttp://localhost:5101/\\n\\nGET http:/\", \"/localhost:5101/swagger/v1/swagger.json Params Save\\n\\nAuthorization\\n\\nHistory\\n\\nToday\\n\\nGET http://local\", \"host:5101/swe\\n\\nger.json\\n\\nNovember 8\\nBod\\nGET http://10.120.158.69:8740 d\\ns/?tenantid=CDLTLL\\nPretty\\nGE\", \"T http://10.106.144.95:8740/api/vehicle\\n/?tenantid=CDLTLL ivi{\\n\\\"swagger\\\": \\\"2.6\\\",\\nGET http://myworld-\", \"cluster.westus.cloudap 3\\u00b0 \\\"info\\\": {\\n4 \\u201cversion\\u201d: \\\"v1\\\",\\n\\u2014 \\\"title\\\": \\\"eShopOnContainers - Catalog HTTP \", \"API\\\",\\nid=CDLTLL 6 \\\"description\\\": \\\"The Catalog Microservice HTTP API. This is a Data-Driven/CRUD micr\", \"oservice sample\\\",\\n\\\"termsOfService\\\": \\\"Terms Of Service\\\"\\n\\np.azure.com:8740/api/vehicles/?tenant\\n\\ns| },\", \"\\nNovember 6 9 \\u201cbasePath\\\": \\\"/\\\",\\n\\\"paths\\\": {\\nGET http://myworld-cluster.westus.cloudap _ \\u201c/api/vi/Catal\", \"og/Items\\\": {\\ny \\\"get\\\": {\\n\\u201ctags\\\": [\\n\\\"Catalog\\\"\\n\\np.azure,com:8740/api/vehic\\n\\n\\u2019\\n\\u201coperationId\\\": \\\"\\u201cApiVicat\", \"alogItemsGet\\\",\\n\\u201cconsumes\\u201d:\\n\\u201cproduces\\u201d:\\n\\u201cparameters\\u201d: [\\n{\\n\\\"name\\\": \\u201cpageSize\\\",\\n\\\"in\\\": \\u201cmodelbinding\\\",\\n\\u201c\", \"required\\u201d: false,\\n\\u201ctype\\\": \\u201cinteger\\u201d,\\n\\\"format\\\": \\u201cint32\\\"\\n\\nFigure 6-10. Swagger JSON metadata\\n\\nIt is th\", \"at simple. And because it is automatically generated, the Swagger metadata will grow when you\\nadd mo\", \"re functionality to your API.\\n\\nAdditional resources\\n. ASP.NET Web API Help Pages using Swagger\\n\\n\\u00b0 Ge\", \"t started with Swashbuckle and ASP.NET Core\\nhttps://learn.microsoft.com/aspnet/core/tutorials/gettin\", \"g-started-with-swashbuckle\\n\\n. Get started with NSwag and ASP.NET Core\\nhttps://learn.microsoft.com/as\", \"pnet/core/tutorials/getting-started-with-nswag\\n\\nDefining your multi-container application with\\ndocke\", \"r-compose.yml\\n\\nIn this guide, the docker-compose.yml file was introduced in the section Step 4. Defi\", \"ne your services\\n\\nin docker-compose.yml when building a multi-container Docker application. However,\", \" there are\\nadditional ways to use the docker-compose files that are worth exploring in further detai\", \"l.\\n\\nFor example, you can explicitly describe how you want to deploy your multi-container application\", \" in\\nthe docker-compose.yml file. Optionally, you can also describe how you are going to build your\\nc\", \"ustom Docker images. (Custom Docker images can also be built with the Docker CLI.)\\n\\n116 CHAPTER 5 | \", \"Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nBasically, you def\", \"ine each of the containers you want to deploy plus certain characteristics for each\\ncontainer deploy\", \"ment. Once you have a multi-container deployment description file, you can deploy\\nthe whole solution\", \" in a single action orchestrated by the docker-compose up CLI command, or you\\ncan deploy it transpar\", \"ently from Visual Studio. Otherwise, you would need to use the Docker CLI to\\ndeploy container-by-con\", \"tainer in multiple steps by using the docker run command from the\\ncommand line. Therefore, each serv\", \"ice defined in docker-compose.yml must specify exactly one\\nimage or build. Other keys are optional, \", \"and are analogous to their docker run command-line\\ncounterparts.\\n\\nThe following YAML code is the def\", \"inition of a possible global but single docker-compose.yml file for\\nthe eShopOnContainers sample. Th\", \"is code is not the actual docker-compose file from\\neShopOnContainers. Instead, it is a simplified an\", \"d consolidated version in a single file, which is not the\\nbest way to work with docker-compose files\", \", as will be explained later.\\n\\nversion: '3.4'\\n\\nservices:\\nwebmvc:\\nimage: eshop/webmvc\\nenvironment:\\n- \", \"CatalogUrl=http://catalog-api\\n- OrderingUrl=http://ordering-api\\n- BasketUrl=http://basket-api\\nports:\", \"\\n- \\\"510@:80\\\"\\ndepends_on:\\n- catalog-api\\n- ordering-api\\n- basket-api\\n\\ncatalog-api:\\nimage: eshop/catalo\", \"g-api\\nenvironment:\\n- ConnectionString=Server=sqldata;Initial Catalog=CatalogData;User\\nId=sa;Password\", \"=[PLACEHOLDER |\\nexpose:\\n- \\\"8e\\\"\\nports:\\n- \\\"5101:80\\\"\\n#extra hosts can be used for standalone SQL Server\", \" or services at the dev PC\\nextra_hosts:\\n- \\\"CESARDLSURFBOOK:10.0.75.1\\\"\\ndepends_on:\\n- sqldata\\n\\norderin\", \"g-api:\\nimage: eshop/ordering-api\\nenvironment:\\n- ConnectionString=Server=sqldata;Database=Services.Or\", \"deringDb;User\\nId=sa;Password=[PLACEHOLDER |\\nports:\\n- \\\"5102:80\\\"\\n#extra hosts can be used for standalo\", \"ne SQL Server or services at the dev PC\\nextra_hosts:\\n- \\\"CESARDLSURFBOOK:10.0.75.1\\\"\\ndepends_on:\\n- sql\", \"data\\n\\n117 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicati\", \"ons\\nbasket-api:\\nimage: eshop/basket-api\\nenvironment:\\n- ConnectionString=sqldata\\nports:\\n- \\\"5103:80\\\"\\nd\", \"epends_on:\\n- sqlidata\\n\\nsqldata:\\nenvironment:\\n- SA PASSWORD=[ PLACEHOLDER |\\n- ACCEPT_EULA=Y\\nports:\\n- \", \"\\\"5434:1433\\\"\\n\\nbasketdata:\\nimage: redis\\n\\nThe root key in this file is services. Under that key, you de\", \"fine the services you want to deploy and run\\nwhen you execute the docker-compose up command or when \", \"you deploy from Visual Studio by using\\nthis docker-compose.yml file. In this case, the docker-compos\", \"e.yml file has multiple services defined,\\nas described in the following table.\\n\\nwebmvc Container inc\", \"luding the ASP.NET Core MVC\\napplication consuming the microservices from\\nserver-side C#\\n\\ncatalog-api\", \" Container including the Catalog ASP.NET Core\\nWeb API microservice\\n\\nordering-api Container including\", \" the Ordering ASP.NET\\nCore Web API microservice\\n\\nsqidata Container running SQL Server for Linux,\\nhol\", \"ding the microservices databases\\n\\nbasket-apl Container with the Basket ASP.NET Core Web\\nAPI microser\", \"vice\\n\\nbasketdata Container running the REDIS cache service,\\nwith the basket database as a REDIS cach\", \"e\\n\\nA simple Web Service API container\\n\\nFocusing on a single container, the catalog-api container-mic\", \"roservice has a straightforward\\ndefinition:\\n\\ncatalog-api:\\nimage: eshop/catalog-api\\nenvironment:\\n\\n- C\", \"onnectionString=Server=sqldata;Initial Catalog=CatalogData;User\\nId=sa;Password=[PLACEHOLDER |\\nexpose\", \":\\n\\n118 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\", \"\\n- \\\"8Q\\\"\\nports:\\n- \\\"5101:80\\\"\\n#extra hosts can be used for standalone SQL Server or services at the dev\", \" PC\\nextra_hosts:\\n- \\\"CESARDLSURFBOOK:10.@.75.1\\\"\\ndepends_on:\\n- sqldata\\n\\nThis containerized service has\", \" the following basic configuration:\\n\\n. It is based on the custom eshop/catalog-api image. For simpli\", \"city\\u2019s sake, there is no\\nbuild: key setting in the file. This means that the image must have been pr\", \"eviously built (with\\ndocker build) or have been downloaded (with the docker pull command) from any D\", \"ocker\\nregistry.\\n\\n. It defines an environment variable named ConnectionString with the connection str\", \"ing to be\\nused by Entity Framework to access the SQL Server instance that contains the catalog data\\n\", \"model. In this case, the same SQL Server container is holding multiple databases. Therefore,\\nyou nee\", \"d less memory in your development machine for Docker. However, you could also\\ndeploy one SQL Server \", \"container for each microservice database.\\n\\n\\u00b0 The SQL Server name is sqldata, which is the same name \", \"used for the container that is\\nrunning the SQL Server instance for Linux. This is convenient; being \", \"able to use this name\\nresolution (internal to the Docker host) will resolve the network address so y\", \"ou don\\u2019t need to\\nknow the internal IP for the containers you are accessing from other containers.\\n\\nB\", \"ecause the connection string is defined by an environment variable, you could set that variable\\nthro\", \"ugh a different mechanism and at a different time. For example, you could set a different\\nconnection\", \" string when deploying to production in the final hosts, or by doing it from your CI/CD\\npipelines in\", \" Azure DevOps Services or your preferred DevOps system.\\n\\n\\u00b0 It exposes port 80 for internal access to\", \" the catalog-api service within the Docker host. The\\nhost is currently a Linux VM because it is base\", \"d on a Docker image for Linux, but you could\\nconfigure the container to run on a Windows image inste\", \"ad.\\n\\n. It forwards the exposed port 80 on the container to port 5101 on the Docker host machine\\n(the\", \" Linux VM).\\n\\n. It links the web service to the sqldata service (the SQL Server instance for Linux da\", \"tabase\\nrunning in a container). When you specify this dependency, the catalog-api container will not\", \"\\nstart until the sqldata container has already started; this aspect is important because catalog-\\nap\", \"i needs to have the SQL Server database up and running first. However, this kind of\\ncontainer depend\", \"ency is not enough in many cases, because Docker checks only at the\\ncontainer level. Sometimes the s\", \"ervice (in this case SQL Server) might still not be ready, so it is\\nadvisable to implement retry log\", \"ic with exponential backoff in your client microservices. That\\nway, if a dependency container is not\", \" ready for a short time, the application will still be\\nresilient.\\n\\n. It is configured to allow acces\", \"s to external servers: the extra_hosts setting allows you to access\\nexternal servers or machines out\", \"side of the Docker host (that is, outside the default Linux VM,\\n\\n119 CHAPTER 5 | Designing and Devel\", \"oping Multi-Container and Microservice-Based .NET Applications\\nwhich is a development Docker host), \", \"such as a local SQL Server instance on your\\ndevelopment PC.\\n\\nThere are also other, more advanced doc\", \"ker-compose.yml settings that we'll discuss in the following\\nsections.\\n\\nUsing docker-compose files t\", \"o target multiple environments\\n\\nThe docker-compose.*.yml files are definition files and can be used \", \"by multiple infrastructures that\\nunderstand that format. The most straightforward tool is the docker\", \"-compose command.\\n\\nTherefore, by using the docker-compose command you can target the following main \", \"scenarios.\\n\\nDevelopment environments\\n\\nWhen you develop applications, it is important to be able to r\", \"un an application in an isolated\\ndevelopment environment. You can use the docker-compose CLI command\", \" to create that\\nenvironment or Visual Studio, which uses docker-compose under the covers.\\n\\nThe docke\", \"r-compose.yml file allows you to configure and document all your application\\u2019s service\\ndependencies \", \"(other services, cache, databases, queues, etc.). Using the docker-compose CLI\\ncommand, you can crea\", \"te and start one or more containers for each dependency with a single\\ncommand (docker-compose up).\\n\\n\", \"The docker-compose.yml files are configuration files interpreted by Docker engine but also serve as\\n\", \"convenient documentation files about the composition of your multi-container application.\\n\\nTesting e\", \"nvironments\\n\\nAn important part of any continuous deployment (CD) or continuous integration (Cl) proc\", \"ess are the\\nunit tests and integration tests. These automated tests require an isolated environment \", \"so they are\\nnot impacted by the users or any other change in the application's data.\\n\\nWith Docker Co\", \"mpose, you can create and destroy that isolated environment very easily in a few\\ncommands from your \", \"command prompt or scripts, like the following commands:\\ndocker-compose -f docker-compose.yml -f dock\", \"er-compose-test.override.yml up -d\\n\\n./run_unit_tests\\ndocker-compose -f docker-compose.yml -f docker-\", \"compose-test.override.yml down\\n\\nProduction deployments\\n\\nYou can also use Compose to deploy to a remo\", \"te Docker Engine. A typical case is to deploy to a\\nsingle Docker host instance (like a production VM\", \" or server provisioned with Docker Machine).\\n\\nIf you are using any other orchestrator (Azure Service\", \" Fabric, Kubernetes, etc.), you might need to add\\nsetup and metadata configuration settings like tho\", \"se in docker-compose.yml, but in the format\\nrequired by the other orchestrator.\\n\\nIn any case, docker\", \"-compose is a convenient tool and metadata format for development, testing and\\nproduction workflows,\", \" although the production workflow might vary on the orchestrator you are\\nUSING.\\n\\n120 CHAPTER 5 | Des\", \"igning and Developing Multi-Container and Microservice-Based .NET Applications\\nUsing multiple docker\", \"-compose files to handle several environments\\n\\nWhen targeting different environments, you should use\", \" multiple compose files. This approach lets you\\ncreate multiple configuration variants depending on \", \"the environment.\\n\\nOverriding the base docker-compose file\\n\\nYou could use a single docker-compose.yml\", \" file as in the simplified examples shown in previous\\nsections. However, that is not recommended for\", \" most applications.\\n\\nBy default, Compose reads two files, a docker-compose.yml and an optional docke\", \"r-\\ncompose.override.yml file. As shown in Figure 6-11, when you are using Visual Studio and enabling\", \"\\nDocker support, Visual Studio also creates an additional docker-compose.vs.debug.g.yml file for\\ndeb\", \"ugging the application, you can take a look at this file in folder obj\\\\Docker\\\\ in the main solution\\n\", \"folder.\\n\\n4 =| docker-compose\\nL) .dockerignore\\n\\n4 4) docker-composeymil\\nCL] docker-compose.override.y\", \"ml\\n\\nFigure 6-11. docker-compose files in Visual Studio 2019\\n\\ndocker-compose project file structure:\\n\", \"\\n. .dockerignore - used to ignore files\\n. docker-compose.yml - used to compose microservices\\n. docke\", \"r-compose.override.yml - used to configure microservices environment\\n\\nYou can edit the docker-compos\", \"e files with any editor, like Visual Studio Code or Sublime, and run the\\napplication with the docker\", \"-compose up command.\\n\\nBy convention, the docker-compose.yml file contains your base configuration an\", \"d other static\\nsettings. That means that the service configuration should not change depending on th\", \"e deployment\\nenvironment you are targeting.\\n\\nThe docker-compose.override.yml file, as its name sugge\", \"sts, contains configuration settings that\\noverride the base configuration, such as configuration tha\", \"t depends on the deployment environment.\\nYou can have multiple override files with different names a\", \"lso. The override files usually contain\\nadditional information needed by the application but specifi\", \"c to an environment or to a deployment.\\n\\nTargeting multiple environments\\n\\nA typical use case is when\", \" you define multiple compose files so you can target multiple environments,\\nlike production, staging\", \", Cl, or development. To support these differences, you can split your\\nCompose configuration into mu\", \"ltiple files, as shown in Figure 6-12.\\n\\n121 CHAPTER 5 | Designing and Developing Multi-Container and\", \" Microservice-Based .NET Applications\\nMultiple docker-compose files\\n\\ndocker-compose.override.ym| doc\", \"ker-compose.prod.ym| docker-compose.staging.ym|\\n\\ndocker-compose.yml\\n\\nFigure 6-12. Multiple docker-co\", \"mpose files overriding values in the base docker-compose.ym| file\\n\\nYou can combine multiple docker-c\", \"ompose*.yml files to handle different environments. You start with\\nthe base docker-compose.yml file.\", \" This base file contains the base or static configuration settings that\\ndo not change depending on t\", \"he environment. For example, the eShopOnContainers app has the\\nfollowing docker-compose.yml file (si\", \"mplified with fewer services) as the base file.\\n\\n#docker-compose.yml (Base)\\nversion: '3.4'\\nservices:\", \"\\nbasket-api:\\nimage: eshop/basket-api:${TAG: -latest}\\nbuild:\\ncontext:\\ndockerfile: src/Services/Basket\", \"/Basket.API/Dockerfile\\ndepends_on:\\n- basketdata\\n- identity-api\\n- rabbitmgq\\n\\ncatalog-api:\\nimage: esho\", \"p/catalog-api:${TAG: -latest}\\nbuild:\\ncontext:\\ndockerfile: src/Services/Catalog/Catalog.API/Dockerfil\", \"e\\ndepends_on:\\n- sqldata\\n- rabbitmgq\\n\\nmarketing-api:\\nimage: eshop/marketing-api:${TAG: -latest}\\nbuild\", \":\\ncontext:\\ndockerfile: src/Services/Marketing/Marketing.API/Dockerfile\\ndepends_on:\\n- sqldata\\n- nosql\", \"data\\n- identity-api\\n- rabbitmgq\\n\\nwebmvc:\\nimage: eshop/webmvc:${TAG: -latest}\\n\\n122 CHAPTER 5 | Design\", \"ing and Developing Multi-Container and Microservice-Based .NET Applications\\nbuild:\\n\\ncontext:\\n\\ndocker\", \"file: src/Web/WebMVC/Dockerfile\\ndepends_on:\\n\\n- catalog-api\\n\\n- ordering-api\\n\\n- identity-api\\n\\n- basket\", \"-api\\n\\n- marketing-api\\n\\nsqldata:\\nimage: mcr.microsoft.com/mssql/server: 2019-latest\\n\\nnosqldata:\\nimage\", \": mongo\\n\\nbasketdata:\\nimage: redis\\n\\nrabbitmq:\\nimage: rabbitmg:3-management\\n\\nThe values in the base do\", \"cker-compose.yml file should not change because of different target\\ndeployment environments.\\n\\nIf you\", \" focus on the webmvc service definition, for instance, you can see how that information is much\\nthe \", \"same no matter what environment you might be targeting. You have the following information:\\n\\n. The s\", \"ervice name: webmvc.\\n. The container\\u2019s custom image: eshop/webmvc.\\n. The command to build the custom\", \" Docker image, indicating which Dockerfile to use.\\n\\n. Dependencies on other services, so this contai\", \"ner does not start until the other dependency\\ncontainers have started.\\n\\nYou can have additional conf\", \"iguration, but the important point is that in the base docker-\\ncompose.yml file, you just want to se\", \"t the information that is common across environments. Then in\\nthe docker-compose.override.yml or sim\", \"ilar files for production or staging, you should place\\nconfiguration that is specific for each envir\", \"onment.\\n\\nUsually, the docker-compose.override.yml is used for your development environment, as in th\", \"e\\nfollowing example from eShopOnContainers:\\n\\n#docker-compose.override.yml (Extended config for DEVEL\", \"OPMENT env. )\\nversion: '3.4'\\n\\nservices:\\n# Simplified number of services here:\\n\\nbasket-api:\\nenvironme\", \"nt:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- ConnectionString=${ES\", \"HOP_AZURE_REDIS_BASKET_DB: -basketdata}\\n- identityUrl=http://identity-api\\n- IdentityUrlExternal=http\", \"://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5105\\n\\n123 CHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET Applications\\n- EventBusConnection=${ESHOP_AZURE_SERVICE_BUS: -rabbitmq}\\n\\n\", \"- EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME }\\n\\n- EventBusPassword=${ESHOP_SERVICE_BUS PASSWORD}\\n\", \"\\n- AzureServiceBusEnabled=False\\n\\n- ApplicationInsights__InstrumentationKey=${INSTRUMENTATION_KEY}\\n- \", \"OrchestratorType=${ORCHESTRATOR_TYPE }\\n\\n- UseLoadTest=${USE_LOADTEST: -False}\\n\\nports:\\n- \\\"5103:80\\\"\\n\\nc\", \"atalog-api:\\nenvironment:\\n\\n- ASPNETCORE_ENVIRONMENT=Development\\n\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n\", \"\\n- ConnectionString=${ESHOP_AZURE_CATALOG_DB:-\\nServer=sqldata;Database=Microsoft.eShopOnContainers.S\", \"ervices.CatalogDb;User\\nId=sa;Password=[ PLACEHOLDER ] }\\n\\n- PicBaseUr1=${ESHOP_AZURE_STORAGE_CATALOG_\", \"URL: -\\nhttp: //host.docker.internal:5202/api/v1/catalog/items/[@]/pic/}\\n\\n- EventBusConnection=${ESHO\", \"P_AZURE_SERVICE_BUS: -rabbitmq}\\n\\n- EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME }\\n\\n- EventBusPasswo\", \"rd=${ESHOP_SERVICE_BUS PASSWORD}\\n\\n- AzureStorageAccountName=${ESHOP_AZURE_STORAGE_CATALOG_NAME }\\n\\n- \", \"AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_CATALOG_KEY}\\n\\n- UseCustomizationData=True\\n\\n- AzureServi\", \"ceBusEnabled=False\\n\\n- AzureStorageEnabled=False\\n\\n- ApplicationInsights__InstrumentationKey=${INSTRUM\", \"ENTATION_KEY}\\n\\n- OrchestratorType=${ORCHESTRATOR_TYPE }\\n\\nports:\\n- \\\"5101:80\\\"\\n\\nmarketing-api:\\nenvironm\", \"ent:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- ConnectionString=${E\", \"SHOP_AZURE_MARKETING_DB: -\\nServer=sqldata;Database=Microsoft.eShopOnContainers.Services.MarketingDb;\", \"User\\nId=sa;Password=[ PLACEHOLDER ] }\\n- MongoConnectionString=${ESHOP_AZURE_COSMOSDB: -mongodb: //no\", \"sqldata}\\n- MongoDatabase=MarketingDb\\n- EventBusConnection=${ESHOP_AZURE_SERVICE_BUS: -rabbitmq}\\n- Ev\", \"entBusUserName=${ESHOP_SERVICE_BUS_USERNAME }\\n- EventBusPassword=${ESHOP_SERVICE_BUS PASSWORD}\\n- ide\", \"ntityUrl=http://identity-api\\n- IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS NAME _OR_IP}:5105\\n- C\", \"ampaignDetailFunctionUri=${ESHOP_AZUREFUNC_CAMPAIGN DETAILS URI}\\n- PicBaseUrl=${ESHOP_AZURE_STORAGE_\", \"MARKETING_URL: -\\nhttp: //host.docker.internal:5110/api/v1/campaigns/[@]/pic/}\\n- AzureStorageAccountN\", \"ame=${ESHOP_AZURE_STORAGE_MARKETING_NAME}\\n- AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_MARKETING_K\", \"EY}\\n- AzureServiceBusEnabled=False\\n- AzureStorageEnabled=False\\n- ApplicationInsights__Instrumentatio\", \"nKey=${INSTRUMENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE }\\n- UseLoadTest=${USE_LOADTEST: -\", \"False}\\nports:\\n- \\\"5110:80\\\"\\n\\nwebmvc:\\n\\n124 CHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applications\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\nASPNETCORE_URLS=\", \"http://0.0.0.0:80\\n- PurchaseUrl=http: //webshoppingapigw\\n- IdentityUrl=http://10.0.75.1:5105\\n- Marke\", \"tingUrl=http://webmarketingapigw\\n- CatalogUrlHC=http://catalog-api/hc\\n- OrderingUrlHC=http://orderin\", \"g-api/hc\\n- IdentityUrlHC=http://identity-api/hc\\n- BasketUrlHC=http://basket-api/hc\\n- MarketingUrlHC=\", \"http://marketing-api/hc\\n- PaymentUrlHC=http://payment-api/hc\\n- SignalrHubUrl=http://${ESHOP_EXTERNAL\", \"_DNS_NAME_OR_IP}:5202\\n- UseCustomizationData=True\\n- ApplicationInsights__InstrumentationKey=${INSTRU\", \"MENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE}\\n- UseLoadTest=${USE_LOADTEST: -False}\\nports:\\n\", \"- \\\"510@:80\\\"\\nsqldata:\\nenvironment:\\n- SA PASSWORD=[ PLACEHOLDER ]\\n- ACCEPT _EULA=Y\\nports:\\n- \\\"5433:1433\", \"\\\"\\nnosqldata:\\nports:\\n- \\\"27017:27017\\\"\\nbasketdata:\\nports:\\n- \\\"6379:6379\\\"\\nrabbitmq:\\nports:\\n- \\\"15672:15672\", \"\\\"\\n- \\\"5672:5672\\\"\\n\\nIn this example, the development override configuration exposes some ports to the h\", \"ost, defines\\nenvironment variables with redirect URLs, and specifies connection strings for the deve\", \"lopment\\nenvironment. These settings are all just for the development environment.\\n\\nWhen you run dock\", \"er-compose up (or launch it from Visual Studio), the command reads the overrides\\nautomatically as if\", \" it were merging both files.\\n\\nSuppose that you want another Compose file for the production environm\", \"ent, with different\\nconfiguration values, ports, or connection strings. You can create another overr\", \"ide file, like file named\\ndocker-compose.prod.yml with different settings and environment variables.\", \" That file might be stored\\nin a different Git repo or managed and secured by a different team.\\n\\nHow \", \"to deploy with a specific override file\\n\\nTo use multiple override files, or an override file with a \", \"different name, you can use the -f option with\\nthe docker-compose command and specify the files. Com\", \"pose merges files in the order they are\\nspecified on the command line. The following example shows h\", \"ow to deploy with override files.\\n\\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml u\", \"p -d\\n\\n125 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicati\", \"ons\\nUsing environment variables in docker-compose files\\n\\nIt is convenient, especially in production \", \"environments, to be able to get configuration information\\nfrom environment variables, as we have sho\", \"wn in previous examples. You can reference an\\nenvironment variable in your docker-compose files usin\", \"g the syntax ${MY_VAR}. The following line\\nfrom a docker-compose.prod.yml file shows how to referenc\", \"e the value of an environment variable.\\n\\nEnvironment variables are created and initialized in differ\", \"ent ways, depending on your host\\nenvironment (Linux, Windows, Cloud cluster, etc.). However, a conve\", \"nient approach is to use an .env\\n\\nfile. The docker-compose files support declaring default environme\", \"nt variables in the .env file. These\\nvalues for the environment variables are the default values. Bu\", \"t they can be overridden by the values\\nyou might have defined in each of your environments (host OS \", \"or environment variables from your\\n\\ncluster). You place this .env file in the folder where the docke\", \"r-compose command Is executed from.\\n\\nThe following example shows an .env file like the .env file for\", \" the eshopOnContainers application.\\n\\n# .env file\\n\\nESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker. interna\", \"l\\n\\nESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP=10.121.122.92\\nDocker-compose expects each line in an .env file\", \" to be in the format <variable>=<value>.\\n\\nThe values set in the run-time environment always override\", \" the values defined inside the .env file. In a\\nsimilar way, values passed via command-line arguments\", \" also override the default values set in the .env\\nfile.\\n\\nAdditional resources\\n\\n. Overview of Docker \", \"Compose\\n\\nhttps://docs.docker.com/compose/overview/\\n\\n. Multiple Compose files\\n\\nhttps://docs.docker.co\", \"m/compose/multiple-compose-files/\\n\\nBuilding optimized ASP.NET Core Docker images\\n\\nIf you are explori\", \"ng Docker and .NET on sources on the Internet, you will find Dockerfiles that\\ndemonstrate the simpli\", \"city of building a Docker image by copying your source into a container. These\\nexamples suggest that\", \" by using a simple configuration, you can have a Docker image with the\\nenvironment packaged with you\", \"r application. The following example shows a simple Dockerfile in this\\nvein.\\n\\nFROM mcr.microsoft.com\", \"/dotnet/sdk:7.0\\nWORKDIR /app\\n\\nENV ASPNETCORE_URLS http://+:8@\\nEXPOSE 82\\n\\nCOPY .\\nRUN dotnet restore\\nE\", \"NTRYPOINT [\\\"dotnet\\\", \\\"run\\\"\\n\\n126 CHAPTER 5 | Designing and Developing Multi-Container and Microservic\", \"e-Based .NET Applications\\nA Dockerfile like this will work. However, you can substantially optimize \", \"your images, especially your\\nproduction images.\\n\\nIn the container and microservices model, you are c\", \"onstantly starting containers. The typical way of\\nusing containers does not restart a sleeping conta\", \"iner, because the container is disposable.\\nOrchestrators (like Kubernetes and Azure Service Fabric) \", \"create new instances of images. What this\\nmeans is that you would need to optimize by precompiling t\", \"he application when it is built so the\\ninstantiation process will be faster. When the container is s\", \"tarted, it should be ready to run. Don't\\nrestore and compile at run time using the dotnet restore an\", \"d dotnet build CLI commands as you may\\nsee in blog posts about .NET and Docker.\\n\\nThe .NET team has b\", \"een doing important work to make .NET and ASP.NET Core a container-optimized\\nframework. Not only is \", \".NET a lightweight framework with a small memory footprint; the team has\\nfocused on optimized Docker\", \" images for three main scenarios and published them in the Docker Hub\\nregistry at dotnet/, beginning\", \" with version 2.1:\\n\\n1. Development: The priority is the ability to quickly iterate and debug changes\", \", and where size\\nis secondary.\\n\\n2. Build: The priority is compiling the application, and the image i\", \"ncludes binaries and other\\ndependencies to optimize binaries.\\n\\n3. Production: The focus is fast depl\", \"oying and starting of containers, so these images are\\nlimited to the binaries and content needed to \", \"run the application.\\n\\nThe .NET team provides four basic variants in dotnet/ (at Docker Hub):\\n\\nsdk: f\", \"or development and build scenarios\\n\\naspnet: for ASP.NET production scenarios\\n\\nwr >\\n\\nruntime: for .NE\", \"T production scenarios\\n4. runtime-deps: for production scenarios of self-contained applications\\n\\nFor\", \" faster startup, runtime images also automatically set asonetcore_urls to port 80 and use Ngen to\\ncr\", \"eate a native image cache of assemblies.\\n\\nAdditional resources\\n\\n\\u00b0 Building Optimized Docker Images w\", \"ith ASP.NET Core\\nhttps://learn.microsoft.com/archive/blogs/stevelasker/building-optimized-docker-ima\", \"ges-\\n\\nwith-asp-net-core\\n\\u00b0 Building Docker Images for .NET Applications\\n\\nhttps://learn.microsoft.com/\", \"dotnet/core/docker/building-net-docker-images\\n\\nUse a database server running as a container\\n\\nYou can\", \" have your databases (SQL Server, PostgreSQL, MySQL, etc.) on regular standalone servers, in\\non-prem\", \"ises clusters, or in PaaS services in the cloud like Azure SQL DB. However, for development\\nand test\", \" environments, having your databases running as containers is convenient, because you don't\\n\\n127 CHA\", \"PTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nhave any \", \"external dependency and simply running the docker-compose up command starts the whole\\napplication. H\", \"aving those databases as containers is also great for integration tests, because the\\ndatabase Is sta\", \"rted in the container and is always populated with the same sample data, so tests can\\nbe more predic\", \"table.\\n\\nSQL Server running as a container with a microservice-related\\ndatabase\\n\\nIn eShopOnContainers\", \", there\\u2019s a container named sqldata, as defined in the docker-compose.yml file,\\nthat runs a SQL Serv\", \"er for Linux instance with the SQL databases for all microservices that need one.\\n\\nA key point in mi\", \"croservices is that each microservice owns its related data, so it should have its own\\ndatabase. How\", \"ever, the databases can be anywhere. In this case, they are all in the same container to\\nkeep Docker\", \" memory requirements as low as possible. Keep in mind that this is a good-enough\\nsolution for develo\", \"pment and, perhaps, testing but not for production.\\n\\nThe SQL Server container in the sample applicat\", \"ion is configured with the following YAML code in the\\ndocker-compose.yml file, which is executed whe\", \"n you run docker-compose up. Note that the YAML\\ncode has consolidated configuration information from\", \" the generic docker-compose.yml file and the\\ndocker-compose.override.yml file. (Usually you would se\", \"parate the environment settings from the\\nbase or static information related to the SQL Server image.\", \")\\n\\nsqldata:\\nimage: mcr.microsoft.com/mssql/server:2017-latest\\nenvironment:\\n\\n- SA PASSWORD=Pass@word\\n\", \"- ACCEPT _EULA=Y\\n\\nports:\\n- \\\"5434:1433\\\"\\n\\nIn a similar way, instead of using docker-compose, the follo\", \"wing docker run command can run that\\ncontainer:\\n\\nHowever, if you are deploying a multi-container app\", \"lication like eshopOnContainers, it is more\\nconvenient to use the docker-compose up command so that \", \"it deploys all the required containers for\\nthe application.\\n\\nWhen you start this SQL Server containe\", \"r for the first time, the container initializes SQL Server with the\\npassword that you provide. Once \", \"SQL Server is running as a container, you can update the database\\nby connecting through any regular \", \"SQL connection, such as from SQL Server Management Studio,\\nVisual Studio, or C# code.\\n\\nThe eShopOnCo\", \"ntainers application initializes each microservice database with sample data by\\nseeding it with data\", \" on startup, as explained in the following section.\\n\\nHaving SQL Server running as a container is not\", \" just useful for a demo where you might not have\\naccess to an instance of SQL Server. As noted, it i\", \"s also great for development and testing\\n\\n128 CHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET Applications\\nenvironments so that you can easily run integration tests st\", \"arting from a clean SQL Server image and\\nknown data by seeding new sample data.\\n\\nAdditional resource\", \"s\\n\\n\\u00b0 Run the SQL Server Docker image on Linux, Mac, or Windows\\n\\nhttps://learn.microsoft.com/sql/linu\", \"x/sql-server-linux-setup-docker\\n\\n\\u00b0 Connect and query SQL Server on Linux with sqicmd\\nhttps://learn.m\", \"icrosoft.com/sal/linux/sql-server-linux-connect-and-query-sqlcmd\\n\\nSeeding with test data on Web appl\", \"ication startup\\n\\nTo add data to the database when the application starts up, you can add code like t\", \"he following to\\nthe Main method in the Program class of the Web API project:\\n\\npublic static int Main\", \"(string[] args)\\n\\nt\\n\\nvar configuration = GetConfiguration() ;\\nLog.Logger = CreateSerilogLogger (confi\", \"guration) ;\\n\\ntry\\nt\\n\\nLog. Information(\\\"Configuring web host ({ApplicationContext})...\\\", AppName) ;\\n\\nv\", \"ar host = CreateHostBuilder(configuration, args);\\n\\nLog.Information(\\\"Applying migrations ({Applicatio\", \"nContext})...\\\", AppName) ;\\n\\nhost .MigrateDbContext<CatalogContext>((context, services) =>\\n\\n{\\nvar env\", \" = services.GetService<IWebHostEnvironment>() ;\\nvar settings = services.GetService<IOptions<CatalogS\", \"ettings>>();\\nvar logger = services.GetService<ILogger<CatalogContextSeed>>() ;\\n\\nnew CatalogContextSe\", \"ed()\\n.SeedAsync(context, env, settings, logger)\\n-Wait();\\n\\n})\\n.MigrateDbContext<IntegrationEventLogCo\", \"ntext>((_, __) => { });\\n\\nLog. Information( \\\"Starting web host ({ApplicationContext})...\\\", AppName) ;\", \"\\n\\nhost.Run();\\nreturn 0;\\ncatch (Exception ex)\\n\\nLog.Fatal(ex, \\\"Program terminated unexpectedly ({Appli\", \"cationContext})!\\\", AppName) ;\\nreturn 1;\\n\\n}\\nfinally\\n\\nLog.CloseAndFlush() ;\\n\\n129 CHAPTER 5 | Designing\", \" and Developing Multi-Container and Microservice-Based .NET Applications\\nThere's an important caveat\", \" when applying migrations and seeding a database during container\\nstartup. Since the database server\", \" might not be available for whatever reason, you must handle retries\\nwhile waiting for the server to\", \" be available. This retry logic is handled by the MigrateDbContext()\\nextension method, as shown in t\", \"he following code:\\n\\npublic static IWebHost MigrateDbContext<TContext>(\\nthis IWebHost host,\\nAction<TC\", \"ontext,\\nIServiceProvider> seeder)\\nwhere TContext : DbContext\\n\\nvar underK8s = host.IsInKubernetes() ;\", \"\\n\\nuSing (var scope = host.Services.CreateScope() )\\n\\nvar services = scope.ServiceProvider ;\\nvar logge\", \"r = services.GetRequiredService<ILogger<TContext>>();\\nvar context = services.GetService<TContext>();\", \"\\n\\ntry\\n\\n{\\nlogger.LogInformation( \\\"Migrating database associated with context\\n{DbContextName}\\\", typeof\", \" (TContext) .Name) ;\\n\\nif (underk8s)\\n{\\n\\n}\\n\\nelse\\n\\n{\\n\\nInvokeSeeder(seeder, context, services);\\n\\nvar ret\", \"ry = Policy.Handle<SqlException>()\\n.WaitAndRetry(new TimeSpan|[ ]\\n{\\nTimeSpan.FromSeconds(3),\\nTimeSpa\", \"n.FromSeconds(5),\\nTimeSpan.FromSeconds(8),\\n\\n})3\\n\\n//if the sql server container is not created on run\", \" docker compose this\\n\\n//migration can't fail for network related exception. The retry options for\\nDb\", \"Context only\\n\\n//apply to transient exceptions\\n\\n// Note that this is NOT applied when running some or\", \"chestrators (let the\\norchestrator to recreate the failing service)\\n\\nretry.Execute(() => InvokeSeeder\", \"(seeder, context, services));\\n\\n}\\n\\nlogger.LogInformation(\\\"Migrated database associated with context\\n{\", \"DbContextName}\\\", typeof (TContext) .Name) ;\\n\\n}\\n\\ncatch (Exception ex)\\n\\n{\\nlogger.LogError(ex, \\\"An erro\", \"r occurred while migrating the database used on\\ncontext {DbContextName}\\\", typeof (TContext) .Name) ;\", \"\\nif (underk8s)\\n\\n{\\n\\nthrow; // Rethrow under k8s because we rely on k8s to re-run the\\n\\n130 CHAPTER 5 |\", \" Designing and Developing Multi-Container and Microservice-Based .NET Applications\\npod\\n\\n}\\n\\nreturn ho\", \"st;\\n\\nThe following code in the custom CatalogContextSeed class populates the data.\\n\\npublic class Cat\", \"alogContextSeed\\n{\\n\\npublic static async Task SeedAsync(IApplicationBuilder applicationBuilder )\\n\\n{\\nva\", \"r context = (CatalogContext)applicationBuilder\\n.ApplicationServices.GetService(typeof(CatalogContext\", \") ) ;\\nusing (context)\\n\\ncontext .Database.Migrate() ;\\nif (!context.CatalogBrands.Any() )\\n{\\ncontext. C\", \"atalogBrands.AddRange(\\nGetPreconfiguredCatalogBrands()) ;\\nawait context.SaveChangesAsync() ;\\n\\n}\\nif (\", \"!context.CatalogTypes.Any())\\n{\\ncontext. CatalogTypes .AddRange(\\nGetPreconfiguredCatalogTypes());\\nawa\", \"it context.SaveChangesAsync() ;\\n\\n}\\n\\nStatic IEnumerable<CatalogBrand> GetPreconfiguredCatalogBrands()\", \"\\n\\nt\\n\\nreturn new List<CatalogBrand>( )\\n\\n{\\nnew CatalogBrand() { Brand = \\\"Azure\\\"},\\nnew CatalogBrand() {\", \" Brand = \\\".NET\\\" },\\nnew CatalogBrand() { Brand = \\\"Visual Studio\\\" },\\nnew CatalogBrand() { Brand = \\\"SQL\", \" Server\\\" }\\n\\n}3\\n\\n}\\n\\nstatic IEnumerable<CatalogType> GetPreconfiguredCatalogTypes()\\n{\\n\\nreturn new List\", \"<CatalogType>()\\n\\nt\\n\\nnew CatalogType() { Type = \\\"Mug\\\"},\\n\\nnew CatalogType() { Type = \\\"T-Shirt\\\" },\\n\\nnew\", \" CatalogType() { Type = \\\"Backpack\\\" },\\n\\nnew CatalogType() { Type = \\\"USB Memory Stick\\\" }\\n\\nWhen you run\", \" integration tests, having a way to generate data consistent with your integration tests is\\nuseful. \", \"Being able to create everything from scratch, including an instance of SQL Server running ona\\n\\nconta\", \"iner, is great for test environments.\\n\\n131 CHAPTER 5 | Designing and Developing Multi-Container and \", \"Microservice-Based .NET Applications\\nEF Core InMemory database versus SQL Server running as a contai\", \"ner\\n\\nAnother good choice when running tests is to use the Entity Framework InMemory database provide\", \"r.\\nYou can specify that configuration in the ConfigureServices method of the Startup class in your W\", \"eb\\nAPI project:\\n\\npublic class Startup\\n\\n// Other Startup code ...\\npublic void ConfigureServices(IServ\", \"iceCollection services)\\n\\nt\\n\\nservices.AddSingleton<IConfiguration>(Configuration) ;\\n\\n// DbContext usi\", \"ng an InMemory database provider\\nservices.AddDbContext<CatalogContext>(opt => opt.UseInMemoryDatabas\", \"e() ) ;\\n//(Alternative: DbContext using a SQL Server provider\\n\\n//services .AddDbContext<CatalogConte\", \"xt>(c =>\\n//{\\n\\n// c.UseSgqlServer(Configuration[ \\\"ConnectionString\\\" ]);\\n\\n}\\n\\n// Other Startup code ...\", \"\\n\\nThere is an important catch, though. The in-memory database does not support many constraints that\", \"\\nare specific to a particular database. For instance, you might add a unique index on a column in yo\", \"ur\\nEF Core model and write a test against your in-memory database to check that it does not let you \", \"add\\na duplicate value. But when you are using the in-memory database, you cannot handle unique index\", \"es\\non a column. Therefore, the in-memory database does not behave exactly the same as a real SQL\\nSer\", \"ver database\\u2014it does not emulate database-specific constraints.\\n\\nEven so, an in-memory database is s\", \"till useful for testing and prototyping. But if you want to create\\naccurate integration tests that t\", \"ake into account the behavior of a specific database implementation,\\nyou need to use a real database\", \" like SQL Server. For that purpose, running SQL Server in a container is\\na great choice and more acc\", \"urate than the EF Core InMemory database provider.\\n\\nUsing a Redis cache service running in a contain\", \"er\\n\\nYou can run Redis on a container, especially for development and testing and for proof-of-concep\", \"t\\nscenarios. This scenario is convenient, because you can have all your dependencies running on\\ncont\", \"ainers\\u2014not just for your local development machines, but for your testing environments in your\\nCI/CD\", \" pipelines.\\n\\nHowever, when you run Redis in production, it is better to look for a high-availability\", \" solution like\\nRedis Microsoft Azure, which runs as a PaaS (Platform as a Service). In your code, yo\", \"u just need to\\nchange your connection strings.\\n\\nRedis provides a Docker image with Redis. That image\", \" is available from Docker Hub at this URL:\\n\\nhttps://hub.docker.com/ /redis/\\n\\n132 CHAPTER 5 | Designi\", \"ng and Developing Multi-Container and Microservice-Based .NET Applications\\nYou can directly run a Do\", \"cker Redis container by executing the following Docker CLI command in your\\ncommand prompt:\\n\\ndocker r\", \"un --name some-redis -d redis\\n\\nThe Redis image includes expose:6379 (the port used by Redis), so sta\", \"ndard container linking will\\nmake it automatically available to the linked containers.\\n\\nIn eShopOnCo\", \"ntainers, the basket-api microservice uses a Redis cache running as a container. That\\nbasketdata con\", \"tainer is defined as part of the multi-container docker-compose.yml file, as shown in the\\nfollowing \", \"example:\\n\\n#docker-compose.yml file\\n#.\\n\\nbasketdata:\\n\\nimage: redis\\nexpose:\\n-_ \\\"6379\\\"\\n\\nThis code in the\", \" docker-compose.yml defines a container named basketdata based on the redis image\\nand publishing the\", \" port 6379 internally. This configuration means that it will only be accessible from\\nother container\", \"s running within the Docker host.\\n\\nFinally, in the docker-compose.override.yml file, the basket-api \", \"microservice for the\\neShopOnContainers sample defines the connection string to use for that Redis co\", \"ntainer:\\n\\nbasket-api:\\nenvironment:\\n\\n# Other data...\\n- ConnectionString=basketdata\\n- EventBusConnecti\", \"on=rabbitmgq\\n\\nAs mentioned before, the name of the microservice basketdata is resolved by Docker\\u2019s i\", \"nternal\\nnetwork DNS.\\n\\nImplementing event-based communication between\\nmicroservices (integration even\", \"ts)\\n\\nAs described earlier, when you use event-based communication, a microservice publishes an event\", \"\\nwhen something notable happens, such as when it updates a business entity. Other microservices\\nsubs\", \"cribe to those events. When a microservice receives an event, it can update its own business\\nentitie\", \"s, which might lead to more events being published. This is the essence of the eventual\\nconsistency \", \"concept. This publish/subscribe system is usually performed by using an implementation\\nof an event b\", \"us. The event bus can be designed as an interface with the API needed to subscribe and\\nunsubscribe t\", \"o events and to publish events. It can also have one or more implementations based on\\nany inter-proc\", \"ess or messaging communication, such as a messaging queue or a service bus that\\nsupports asynchronou\", \"s communication and a publish/subscribe model.\\n\\nYou can use events to implement business transaction\", \"s that soan multiple services, which give you\\neventual consistency between those services. An eventu\", \"ally consistent transaction consists of a series\\n\\n133 CHAPTER 5 | Designing and Developing Multi-Con\", \"tainer and Microservice-Based .NET Applications\\nof distributed actions. At each action, the microser\", \"vice updates a business entity and publishes an\\nevent that triggers the next action. Figure 6-18 bel\", \"ow, shows a PriceUpdated event published through\\nan event bus, so the price update is propagated to \", \"the Basket and other microservices.\\n\\nImplementing asynchronous event-driven\\ncommunication with an ev\", \"ent bus\\n\\n| Backend I\\na <i vir -- 7-57-77\\n! Basket microservice } |\\n|\\n| =\\u2014 Database as | I\\n--------+-\", \"---- PaeEteteenteieion . | Key\\u2014\\u2014- $ |\\n| / Catalog microservice \\u2018 l \\\"Sarvice F| cache ;\\nWeb API S Be \", \"|\\n| | 3] DX] PriceUpdated event > Existing basket items\\n| UpdatePrice Event bus |\\n| | command PriceU\", \"pdated event Publish/Subscribe channel)\\n| (Publish action) bX] PriceUpdated event > Other related fe\", \"atures |\\n| | DB update Event bus abstractions/interface [i Vanna\\n| ( Additional microservices... i |\", \"\\n| | Database Event bus implementations |\\n\\u2018 | Database! I\\n| ~ 7 | |\\nSS EEE Ee eS Se RabbitMQ | Servi\", \"ce } |\\nI Ve\\n\\nEventual consistency between microservices based on event-driven async communication\\n\\nF\", \"igure 6-18. Event-driven communication based on an event bus\\n\\nThis section describes how you can imp\", \"lement this type of communication with .NET by using a\\ngeneric event bus interface, as shown in Figu\", \"re 6-18. There are multiple potential implementations,\\neach using a different technology or infrastr\", \"ucture such as RabbitMQ, Azure Service Bus, or any other\\nthird-party open-source or commercial servi\", \"ce bus.\\n\\nUsing message brokers and service buses for production systems\\n\\nAs noted in the architectur\", \"e section, you can choose from multiple messaging technologies for\\nimplementing your abstract event \", \"bus. But these technologies are at different levels. For instance,\\nRabbitMQ, a messaging broker tran\", \"sport, is at a lower level than commercial products like Azure\\nService Bus, NServiceBus, MassTransit\", \", or Brighter. Most of these products can work on top of either\\nRabbitMQ or Azure Service Bus. Your \", \"choice of product depends on how many features and how\\nmuch out-of-the-box scalability you need for \", \"your application.\\n\\nFor implementing just an event bus proof-of-concept for your development environm\", \"ent, as in the\\neShopOnContainers sample, a simple implementation on top of RabbitMQ running as a con\", \"tainer\\nmight be enough. But for mission-critical and production systems that need high scalability, \", \"you\\nmight want to evaluate and use Azure Service Bus.\\n\\nIf you require high-level abstractions and ri\", \"cher features like Sagas for long-running processes that\\nmake distributed development easier, other \", \"commercial and open-source service buses like\\nNServiceBus, MassTransit, and Brighter are worth evalu\", \"ating. In this case, the abstractions and API to\\nuse would usually be directly the ones provided by \", \"those high-level service buses instead of your own\\n\\nabstractions (like the simple event bus abstract\", \"ions provided at eShopOnContainers). For that matter,\\n\\n134 CHAPTER 5 | Designing and Developing Mult\", \"i-Container and Microservice-Based .NET Applications\\nyou can research the forked eShopOnContainers u\", \"sing NServiceBus (additional derived sample\\nimplemented by Particular Software).\\n\\nOf course, you cou\", \"ld always build your own service bus features on top of lower-level technologies\\nlike RabbitMQ and D\", \"ocker, but the work needed to \\u201creinvent the wheel\\u201d might be too costly for a\\ncustom enterprise appli\", \"cation.\\n\\nTo reiterate: the sample event bus abstractions and implementation showcased in the\\neShopOn\", \"Containers sample are intended to be used only as a proof of concept. Once you have\\ndecided that you\", \" want to have asynchronous and event-driven communication, as explained in the\\ncurrent section, you \", \"should choose the service bus product that best fits your needs for production.\\n\\nIntegration events\\n\", \"\\nIntegration events are used for bringing domain state in sync across multiple microservices or exte\", \"rnal\\nsystems. This functionality is done by publishing integration events outside the microservice. \", \"When an\\nevent is published to multiple receiver microservices (to as many microservices as are subsc\", \"ribed to\\nthe integration event), the appropriate event handler in each receiver microservice handles\", \" the event.\\n\\nAn integration event is basically a data-holding class, as in the following example:\\n\\np\", \"ublic class ProductPriceChangedIintegrationEvent : IntegrationEvent\\n{\\n\\npublic int ProductId { get; p\", \"rivate set; }\\n\\npublic decimal NewPrice { get; private set; }\\n\\npublic decimal OldPrice { get; private\", \" set; }\\n\\npublic ProductPriceChangedIntegrationEvent(int productId, decimal newPrice,\\n\\ndecimal oldPri\", \"ce)\\n\\nProductId = productId;\\nNewPrice = newPrice;\\nOldPrice = oldPrice;\\n\\nThe integration events can be\", \" defined at the application level of each microservice, so they are\\ndecoupled from other microservic\", \"es, in a way comparable to how ViewModels are defined in the\\nserver and client. What is not recommen\", \"ded is sharing a common integration events library across\\nmultiple microservices; doing that would b\", \"e coupling those microservices with a single event\\ndefinition data library. You do not want to do th\", \"at for the same reasons that you do not want to share\\na common domain model across multiple microser\", \"vices: microservices must be completely\\nautonomous. For more information, see this blog post on the \", \"amount of data to put in events. Be\\ncareful not to take this too far, as this other blog post descri\", \"bes the problem data deficient messages\\ncan produce. Your design of your events should aim to be \\u201cju\", \"st right\\u201d for the needs of their\\nconsumers.\\n\\nThere are only a few kinds of libraries you should shar\", \"e across microservices. One is libraries that are\\nfinal application blocks, like the Event Bus clien\", \"t API, as in eshopOnContainers. Another Is libraries\\nthat constitute tools that could also be shared\", \" as NuGet components, like JSON serializers.\\n\\n135 CHAPTER 5 | Designing and Developing Multi-Contain\", \"er and Microservice-Based .NET Applications\\nThe event bus\\n\\nAn event bus allows publish/subscribe-sty\", \"le communication between microservices without requiring\\nthe components to explicitly be aware of ea\", \"ch other, as shown in Figure 6-19.\\n\\nMicroservice\\nB\\nMicroservice ZA\\nA Event\\nEvent Bus\\nPublish (Publis\", \"h/Subscribe Channel)\\nevent ; ;\\nEvent Mlicroservice\\nC\\n\\nFigure 6-19. Publish/subscribe basics with an \", \"event bus\\n\\nThe above diagram shows that microservice A publishes to Event Bus, which distributes to \", \"subscribing\\nmicroservices B and C, without the publisher needing to know the subscribers. The event \", \"bus is\\nrelated to the Observer pattern and the publish-subscribe pattern.\\n\\nObserver pattern\\n\\nIn the \", \"Observer pattern, your primary object (known as the Observable) notifies other interested\\nobjects (k\", \"nown as Observers) with relevant information (events).\\n\\nPublish/Subscribe (Pub/Sub) pattern\\n\\nThe pur\", \"pose of the Publish/Subscribe pattern is the same as the Observer pattern: you want to notify\\nother \", \"services when certain events take place. But there is an important difference between the\\nObserver a\", \"nd Pub/Sub patterns. In the observer pattern, the broadcast is performed directly from the\\nobservabl\", \"e to the observers, so they \\u201cknow\\u201d each other. But when using a Pub/Sub pattern, there is a\\nthird co\", \"mponent, called broker, or message broker or event bus, which is known by both the\\npublisher and sub\", \"scriber. Therefore, when using the Pub/Sub pattern the publisher and the\\nsubscribers are precisely d\", \"ecoupled thanks to the mentioned event bus or message broker.\\n\\nThe middleman or event bus\\n\\nHow do yo\", \"u achieve anonymity between publisher and subscriber? An easy way is let a middleman\\ntake care of al\", \"l the communication. An event bus is one such middleman.\\n\\nAn event bus is typically composed of two \", \"parts:\\n\\n\\u00b0 The abstraction or interface.\\n\\n. One or more implementations.\\n\\n136 CHAPTER 5 | Designing a\", \"nd Developing Multi-Container and Microservice-Based .NET Applications\\nIn Figure 6-19 you can see ho\", \"w, from an application point of view, the event bus is nothing more than\\na Pub/Sub channel. The way \", \"you implement this asynchronous communication can vary. It can have\\nmultiple implementations so that\", \" you can swap between them, depending on the environment\\nrequirements (for example, production versu\", \"s development environments).\\n\\nIn Figure 6-20, you can see an abstraction of an event bus with multip\", \"le implementations based on\\n\\ninfrastructure messaging technologies like RabbitMQ, Azure Service Bus,\", \" or another event/message\\nbroker.\\n\\nEvent bus\\n(Publish/Subscribe channel\\n\\n)\\n\\nEvent bus abstractions/i\", \"nterface\\n\\nEvent bus implementations\\n\\nOther\\nRabbitMQ message /\\n\\nevent broker\\n\\nFigure 6- 20. Multiple \", \"implementations of an event bus\\n\\nIt's good to have the event bus defined through an interface so it \", \"can be implemented with several\\ntechnologies, like RabbitMQ, Azure Service bus or others. However, a\", \"nd as mentioned previously,\\nusing your own abstractions (the event bus interface) is good only if yo\", \"u need basic event bus\\nfeatures supported by your abstractions. If you need richer service bus featu\", \"res, you should probably\\nuse the API and abstractions provided by your preferred commercial service \", \"bus instead of your own\\nabstractions.\\n\\nDefining an event bus interface\\n\\nLet's start with some implem\", \"entation code for the event bus interface and possible implementations\\nfor exploration purposes. The\", \" interface should be generic and straightforward, as in the following\\ninterface.\\n\\npublic interface I\", \"EventBus\\n\\nt\\n\\nvoid Publish(IntegrationEvent @event) ;\\nvoid Subscribe<T, TH>()\\n\\nwhere T : IntegrationE\", \"vent\\n\\nwhere TH : IIntegrationEventHandler<T>;\\nvoid SubscribeDynamic<TH>(string eventName)\\n\\nwhere TH \", \": IDynamicIntegrationEventHandler;\\n\\n137 CHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applications\\nvoid UnsubscribeDynamic<TH>(string eventName )\\nwhere TH : IDynamic\", \"IntegrationEventHandler;\\n\\nvoid Unsubscribe<T, TH>()\\nwhere TH : IIntegrationEventHandler<T>\\nwhere T :\", \" IntegrationEvent;\\n\\nThe Publish method is straightforward. The event bus will broadcast the integrat\", \"ion event passed to it\\nto any microservice, or even an external application, subscribed to that even\", \"t. This method is used by\\nthe microservice that is publishing the event.\\n\\nThe Subscribe methods (you\", \" can have several implementations depending on the arguments) are\\nused by the microservices that wan\", \"t to receive events. This method has two arguments. The first is the\\nintegration event to subscribe \", \"to (IntegrationEvent). The second argument is the integration event\\nhandler (or callback method), na\", \"med IIntegrationEventHandler<T>, to be executed when the receiver\\nmicroservice gets that integration\", \" event message.\\n\\nAdditional resources\\n\\nSome production-ready messaging solutions:\\n\\n\\u00b0 Azure Service B\", \"us\\n\\nhttps://learn.microsoft.com/azure/service-bus-messaging/\\n\\n\\u00b0 NServiceBus\\nhttps://particular.net/n\", \"servicebus\\n\\u00b0 MassTransit\\n\\nhttps://masstransit-project.com/\\n\\nImplementing an event bus with RabbitMQ \", \"for the\\ndevelopment or test environment\\n\\nWe should start by saying that if you create your custom ev\", \"ent bus based on RabbitMQ running in a\\ncontainer, as the eShopOnContainers application does, it shou\", \"ld be used only for your development\\nand test environments. Don\\u2019t use it for your production environ\", \"ment, unless you are building it as a\\npart of a production-ready service bus as described in the Add\", \"itional resources section below. A\\nsimple custom event bus might be missing many production-ready cr\", \"itical features that a commercial\\nservice bus has.\\n\\nOne of the event bus custom implementations in e\", \"shopOnContainers is basically a library using the\\nRabbitMQ API. (There's another implementation base\", \"d on Azure Service Bus.)\\n\\nThe event bus implementation with RabbitMQ lets microservices subscribe to\", \" events, publish events,\\nand receive events, as shown in Figure 6-21.\\n\\n138 CHAPTER 5 | Designing and\", \" Developing Multi-Container and Microservice-Based .NET Applications\\nMessage Message\\nSender Receiver\", \"s\\n\\nMicroservice A\\n\\n_ subscribe __\\nMicroservice Free XM) MM\\nOrigin publish key\\nKey Microservice B\\n\\nQu\", \"eue B\\n\\nKe MM rex\\n\\nFigure 6-21. RabbitMQ implementation of an event bus\\n\\nRabbitMQ functions as an int\", \"ermediary between message publisher and subscribers, to handle\\ndistribution. In the code, the EventB\", \"usRabbitMQ class implements the generic |EventBus interface.\\nThis implementation is based on Depende\", \"ncy Injection so that you can swap from this dev/test\\nversion to a production version.\\n\\npublic class\", \" EventBusRabbitMQ : IEventBus, IDisposable\\n{\\n\\n// Implementation using RabbitMQ API\\n//...\\n\\nThe Rabbit\", \"MQ implementation of a sample dev/test event bus is boilerplate code. It has to handle the\\nconnectio\", \"n to the RabbitMQ server and provide code for publishing a message event to the queues. It\\nalso has \", \"to implement a dictionary of collections of integration event handlers for each event type;\\nthese ev\", \"ent types can have a different instantiation and different subscriptions for each receiver\\nmicroserv\", \"ice, as shown in Figure 6-21.\\n\\nImplementing a simple publish method with RabbitMQ\\n\\nThe following cod\", \"e is a simplified version of an event bus implementation for RabbitMQ, to\\nshowcase the whole scenari\", \"o. You don't really handle the connection this way. To see the full\\n\\nimplementation, see the actual \", \"code in the dotnet-architecture/eShopOnContainers repository.\\n\\npublic class EventBusRabbitMQ : IEven\", \"tBus, IDisposable\\n{\\n\\n// Member objects and other methods ...\\nHi occ\\n\\npublic void Publish(Integration\", \"Event @event)\\n{\\nvar eventName = @event.GetType().Name;\\nvar factory = new ConnectionFactory() { HostN\", \"ame = _connectionString };\\nusing (var connection = factory.CreateConnection() )\\nusing (var channel =\", \" connection.CreateModel())\\n\\n139 CHAPTER 5 | Designing and Developing Multi-Container and Microservic\", \"e-Based .NET Applications\\nchannel.ExchangeDeclare(exchange: _brokerName,\\ntype: \\\"direct\\\");\\nstring mes\", \"sage = JsonConvert.SerializeObject(@event) ;\\nvar body = Encoding.UTF8.GetBytes (message) ;\\nchannel.B\", \"asicPublish(exchange: _brokerName,\\nroutingKey: eventName,\\nbasicProperties: null,\\nbody: body) ;\\n\\nThe \", \"actual code of the Publish method in the eSshopOnContainers application is improved by using a\\nPolly\", \" retry policy, which retries the task some times in case the RabbitMQ container is not ready. This\\ns\", \"cenario can occur when docker-compose is starting the containers; for example, the RabbitMQ\\ncontaine\", \"r might start more slowly than the other containers.\\n\\nAs mentioned earlier, there are many possible \", \"configurations in RabbitMQ, so this code should be\\nused only for dev/test environments.\\n\\nImplementin\", \"g the subscription code with the RabbitMQ API\\n\\nAs with the publish code, the following code is a sim\", \"plification of part of the event bus\\nimplementation for RabbitMQ. Again, you usually do not need to \", \"change it unless you are improving\\nit.\\n\\npublic class EventBusRabbitMQ : IEventBus, IDisposable\\n\\nt\\n//\", \" Member objects and other methods ...\\n\\nHi occ\\npublic void Subscribe<T, TH>()\\nwhere T : IntegrationEv\", \"ent\\nwhere TH : IIntegrationEventHandler<T>\\n\\nvar eventName = _subsManager.GetEventKey<T>();\\n\\nvar cont\", \"ainsKey = _subsManager.HasSubscriptionsForEvent(eventName) ;\\nif (!containsKey)\\n\\nif (!_persistentConn\", \"ection. IsConnected)\\n\\nt\\n}\\n\\n_persistentConnection.TryConnect();\\n\\nusing (var channel = _persistentConn\", \"ection.CreateModel () )\\n\\nchannel.QueueBind(queue: _queueName,\\nexchange: BROKER_NAME,\\nroutingKey: eve\", \"ntName) ;\\n\\n}\\n\\n_subsManager.AddSubscription<T, TH>();\\n\\n140 CHAPTER 5 | Designing and Developing Multi\", \"-Container and Microservice-Based .NET Applications\\nEach event type has a related channel to get eve\", \"nts from RabbitMQ. You can then have as many event\\nhandlers per channel and event type as needed.\\n\\nT\", \"he Subscribe method accepts an IIntegrationEventHandler object, which is like a callback method in\\nt\", \"he current microservice, plus its related IntegrationEvent object. The code then adds that event\\nhan\", \"dler to the list of event handlers that each integration event type can have per client microservice\", \".\\nIf the client code has not already been subscribed to the event, the code creates a channel for th\", \"e\\nevent type so it can receive events in a push style from RabbitMQ when that event is published fro\", \"m\\nany other service.\\n\\nAs mentioned above, the event bus implemented in eShopOnContainers has only an\", \" educational\\npurpose, since it only handles the main scenarios, so it\\u2019s not ready for production.\\n\\nF\", \"or production scenarios check the additional resources below, specific for RabbitMQ, and the\\nImpleme\", \"nting event-based communication between microservices section.\\n\\nAdditional resources\\n\\nA production-r\", \"eady solution with support for RabbitMQ.\\n\\n\\u00b0 NServiceBus - Fully-supported commercial service bus wit\", \"h advanced management and\\nmonitoring tooling for .NET\\n\\nhttps://particular.net/\\n\\n\\u00b0 EasyNetQ - Open So\", \"urce .NET API client for RabbitWQ\\nhttps://easynetg.com/\\n\\n. MassTransit - Free, open-source distribut\", \"ed application framework for .NET\\nhttps://masstransit-project.com/\\n. Rebus - Open source .NET Servic\", \"e Bus\\n\\nhttps://github.com/rebus-org/Rebus\\n\\nSubscribing to events\\n\\nThe first step for using the event\", \" bus is to subscribe the microservices to the events they want to\\nreceive. That functionality should\", \" be done in the receiver microservices.\\n\\nThe following simple code shows what each receiver microser\", \"vice needs to implement when starting\\nthe service (that is, in the Startup class) so it subscribes t\", \"o the events it needs. In this case, the basket-\\napi microservice needs to subscribe to ProductPrice\", \"ChangedIntegrationEvent and the\\nOrderStartedIntegrationEvent messages.\\n\\nFor instance, when subscribi\", \"ng to the ProductPriceChangedIntegrationEvent event, that makes the\\nbasket microservice aware of any\", \" changes to the product price and lets it warn the user about the\\nchange if that product is in the u\", \"ser's basket.\\n\\nvar eventBus = app.ApplicationServices.GetRequiredService<IEventBus>() ;\\n\\neventBus.Su\", \"bscribe<ProductPriceChangedIntegrationEvent,\\n\\n141 CHAPTER 5 | Designing and Developing Multi-Contain\", \"er and Microservice-Based .NET Applications\\nProductPriceChangedIntegrationEventHandler>() ;\\n\\neventBu\", \"s.Subscribe<OrderStartediIntegrationEvent,\\nOrderStartedIntegrationEventHandler>() ;\\n\\nAfter this code\", \" runs, the subscriber microservice will be listening through RabbitMQ channels. When\\nany message of \", \"type ProductPriceChangedIntegrationEvent arrives, the code invokes the event\\nhandler that is passed \", \"to it and processes the event.\\n\\nPublishing events through the event bus\\n\\nFinally, the message sender\", \" (origin microservice) publishes the integration events with code similar to\\nthe following example. \", \"(This approach Is a simplified example that does not take atomicity into\\naccount.) You would impleme\", \"nt similar code whenever an event must be propagated across multiple\\nmicroservices, usually right af\", \"ter committing data or transactions from the origin microservice.\\n\\nFirst, the event bus implementati\", \"on object (based on RabbitMQ or based on a service bus) would be\\ninjected at the controller construc\", \"tor, as in the following code:\\n\\n[Route(\\\"api/v1/[controller]\\\") |\\n\\npublic class CatalogController : Co\", \"ntrollerBase\\n\\n{\\nprivate readonly CatalogContext _context;\\nprivate readonly IOptionsSnapshot<Settings\", \"> _settings;\\nprivate readonly IEventBus _eventBus;\\n\\npublic CatalogController(CatalogContext context,\", \"\\nIOptionsSnapshot<Settings> settings,\\nTEventBus eventBus)\\n\\n_context = context;\\n_settings = settings;\", \"\\n_eventBus eventBus ;\\n\\nThen you use it from your controller's methods, like in the UpdateProduct met\", \"hod:\\n\\n[Route(\\\"items\\\") |\\n[HttpPost ]\\npublic async Task<IActionResult> UpdateProduct([FromBody |Catalo\", \"gItem product)\\n\\nt\\n\\nvar item = await _context.CatalogItems.SingleOrDefaultAsync(\\ni => i.Id == product\", \".Id);\\nHii 000\\nif (item.Price != product.Price)\\n{\\nvar oldPrice = item.Price;\\nitem.Price = product.Pri\", \"ce;\\n_context.CatalogItems.Update(item) ;\\nvar @event = new ProductPriceChangedIntegrationEvent(item.I\", \"d,\\nitem.Price,\\noldPrice) ;\\n// Commit changes in original transaction\\nawait _context.SaveChangesAsync\", \"() ;\\n// Publish integration event to the event bus\\n// (RabbitMQ or a service bus underneath)\\n\\n142 CH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n_eventBu\", \"s.Publish(@event) ;\\n// \\u00abs-\\n\\nIn this case, since the origin microservice is a simple CRUD microservic\", \"e, that code Is placed right into\\na Web API controller.\\n\\nIn more advanced microservices, like when u\", \"sing CQRS approaches, it can be implemented in the\\nCommandHandler class, within the Handle() method.\", \"\\n\\nDesigning atomicity and resiliency when publishing to the event bus\\n\\nWhen you publish integration \", \"events through a distributed messaging system like your event bus, you\\nhave the problem of atomicall\", \"y updating the original database and publishing an event (that is, either\\nboth operations complete o\", \"r none of them). For instance, in the simplified example shown earlier, the\\ncode commits data to the\", \" database when the product price is changed and then publishes a\\nProductPriceChangedIntegrationEvent\", \" message. Initially, it might look essential that these two\\noperations be performed atomically. Howe\", \"ver, if you are using a distributed transaction involving the\\ndatabase and the message broker, as yo\", \"u do in older systems like Microsoft Message Queuing\\n(MSMQ), this approach is not recommended for th\", \"e reasons described by the CAP theorem.\\n\\nBasically, you use microservices to build scalable and high\", \"ly available systems. Simplifying somewhat,\\nthe CAP theorem says that you cannot build a (distribute\", \"d) database (or a microservice that owns its\\nmodel) that\\u2019s continually available, strongly consisten\", \"t, and tolerant to any partition. You must choose\\ntwo of these three properties.\\n\\nIn microservices-b\", \"ased architectures, you should choose availability and tolerance, and you should\\nde-emphasize strong\", \" consistency. Therefore, in most modern microservice-based applications, you\\nusually do not want to \", \"use distributed transactions in messaging, as you do when you implement\\ndistributed transactions bas\", \"ed on the Windows Distributed Transaction Coordinator (DTC) with\\n\\nMSMQ.\\n\\nLet's go back to the initia\", \"l issue and its example. If the service crashes after the database is updated\\n(in this case, right a\", \"fter the line of code with _context.SaveChangesAsync()), but before the integration\\nevent is publish\", \"ed, the overall system could become inconsistent. This approach might be business\\ncritical, dependin\", \"g on the specific business operation you are dealing with.\\n\\nAs mentioned earlier in the architecture\", \" section, you can have several approaches for dealing with this\\nissue:\\n\\n. Using the full Event Sourc\", \"ing pattern.\\n\\u00b0 Using transaction log mining.\\n\\n\\u00b0 Using the Outbox pattern. This is a transactional ta\", \"ble to store the integration events\\n(extending the local transaction).\\n\\nFor this scenario, using the\", \" full Event Sourcing (ES) pattern is one of the best approaches, if not the\\nbest. However, in many a\", \"pplication scenarios, you might not be able to implement a full ES system. ES\\nmeans storing only dom\", \"ain events in your transactional database, instead of storing current state\\n\\n143 CHAPTER 5 | Designi\", \"ng and Developing Multi-Container and Microservice-Based .NET Applications\\ndata. Storing only domain\", \" events can have great benefits, such as having the history of your system\\navailable and being able \", \"to determine the state of your system at any moment in the past. However,\\nimplementing a full ES sys\", \"tem requires you to rearchitect most of your system and introduces many\\nother complexities and requi\", \"rements. For example, you would want to use a database specifically\\nmade for event sourcing, such as\", \" Event Store, or a document-oriented database such as Azure\\nCosmos DB, MongoDB, Cassandra, CouchDB, \", \"or RavenDB. ES is a great approach for this problem, but\\nnot the easiest solution unless you are alr\", \"eady familiar with event sourcing.\\n\\nThe option to use transaction log mining initially looks transpa\", \"rent. However, to use this approach,\\nthe microservice has to be coupled to your RDBMS transaction lo\", \"g, such as the SQL Server transaction\\nlog. This approach is probably not desirable. Another drawback\", \" is that the low-level updates recorded\\nin the transaction log might not be at the same level as you\", \"r high-level integration events. If so, the\\nprocess of reverse-engineering those transaction log ope\", \"rations can be difficult.\\n\\nA balanced approach is a mix of a transactional database table and a simp\", \"lified ES pattern. You can\\nuse a State such as \\u201cready to publish the event,\\u201d which you set in the or\", \"iginal event when you commit\\nit to the integration events table. You then try to publish the event t\", \"o the event bus. If the publish-\\nevent action succeeds, you start another transaction in the origin \", \"service and move the state from\\n\\u201cready to publish the event\\u201d to \\u201cevent already published.\\u201d\\n\\nIf the p\", \"ublish-event action in the event bus fails, the data still will not be inconsistent within the origi\", \"n\\nmicroservice\\u2014it is still marked as \\u201cready to publish the event,\\u201d and with respect to the rest of t\", \"he\\nservices, it will eventually be consistent. You can always have background jobs checking the stat\", \"e of\\nthe transactions or integration events. If the job finds an event in the \\u201cready to publish the \", \"event\\u201d\\nState, it can try to republish that event to the event bus.\\n\\nNotice that with this approach, \", \"you are persisting only the integration events for each origin\\nmicroservice, and only the events tha\", \"t you want to communicate to other microservices or external\\nsystems. In contrast, in a full ES syst\", \"em, you store all domain events as well.\\n\\nTherefore, this balanced approach is a simplified ES syste\", \"m. You need a list of integration events with\\ntheir current state (\\u201cready to publish\\u201d versus \\u201cpublis\", \"hed\\u201d). But you only need to implement these\\nstates for the integration events. And in this approach,\", \" you do not need to store all your domain data\\nas events in the transactional database, as you would\", \" in a full ES system.\\n\\nIf you are already using a relational database, you can use a transactional t\", \"able to store integration\\nevents. To achieve atomicity in your application, you use a two-step proce\", \"ss based on local\\ntransactions. Basically, you have an IntegrationEvent table in the same database w\", \"here you have your\\ndomain entities. That table works as an insurance for achieving atomicity so that\", \" you include persisted\\nintegration events into the same transactions that are committing your domain\", \" data.\\n\\nStep by step, the process goes like this:\\n\\n1. The application begins a local database transa\", \"ction.\\n\\n2. It then updates the state of your domain entities and inserts an event into the integrati\", \"on\\nevent table.\\n\\n3. Finally, it commits the transaction, so you get the desired atomicity and then\\n\\n\", \"144 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n4.\", \" You publish the event somehow (next).\\nWhen implementing the steps of publishing the events, you hav\", \"e these choices:\\n\\n. Publish the integration event right after committing the transaction and use ano\", \"ther local\\ntransaction to mark the events in the table as being published. Then, use the table just \", \"as an\\nartifact to track the integration events in case of issues in the remote microservices, and\\npe\", \"rform compensatory actions based on the stored integration events.\\n\\n. Use the table as a kind of que\", \"ue. A separate application thread or process queries the\\nintegration event table, publishes the even\", \"ts to the event bus, and then uses a local\\ntransaction to mark the events as published.\\n\\nFigure 6-22\", \" shows the architecture for the first of these approaches.\\n\\nRaise\\nUI business\\n\\u2018 warning\\n\\u2018\\\\\\n5)\\n\\\\\\nXv\\nX\", \"N\\nCatalog ProductPriceChanged event \\\\\\\\ Basket\\nmicroservice (Publish action) ProductPriceChanged \\\\.Mi\", \"croservice\\n(suscribed) \\\\\\nMX f\\\\ Event Bus \\\\ MX\\n2} (Publish/Susbcribe channel) _ |\\n\\\\Z }\\naoe ee eee eee\", \"\\nLocaltransaction | * Pont wwriree '\\nUpdate Local transaction\\n\\nproduct\\n\\nProduct Table\\n\\niD)\\nName\\nPric\", \"e\\n\\nFigure 6-22. Atomicity when publishing events to the event bus\\n\\nThe approach illustrated in Figur\", \"e 6-22 is missing an additional worker microservice that is in charge\\nof checking and confirming the\", \" success of the published integration events. In case of failure, that\\nadditional checker worker mic\", \"roservice can read events from the table and republish them, that is,\\nrepeat step number 2.\\n\\nAbout t\", \"he second approach: you use the EventLog table as a queue and always use a worker\\nmicroservice to pu\", \"blish the messages. In that case, the process is like that shown in Figure 6-23. This\\nshows an addit\", \"ional microservice, and the table is the single source when publishing events.\\n\\n145 CHAPTER 5 | Desi\", \"gning and Developing Multi-Container and Microservice-Based .NET Applications\\nRaise\\nty Ul Business\\n\\u2018\", \". warning\\n\\\\\\n\\n\\u2018\\n\\\\ Basket\\nProductPriceChanged \\u2018\\\\ microservice\\n\\n(Subscribed) \\\\\\nCatalog Event rz 4]\\n\\nmic\", \"roservice publisher 3 |\\n\\n(Worker) A\\nKD\\n\\nProductPriceChanged event Update\\nae ee ee Fe He te ee r With\", \" Retries/Ack)\\n\\nEvent Bus\\n(Publish/Subscribe Channel)\\n\\n(Publish Action\\n\\nUpdate Insert !\\n\\nProduct\\n\\na \\u2014\", \"_ = = =,\\n\\nTransaction\\n\\nProduct table EventLog table\\nID ID\\n\\nName Eventlype\\nPrice EventBody\\n//etc Stat\", \"e\\n\\nFigure 6-23. Atomicity when publishing events to the event bus with a worker microservice\\n\\nFor si\", \"mplicity, the eShopOnContainers sample uses the first approach (with no additional processes or\\nchec\", \"ker microservices) plus the event bus. However, the eshopOnContainers sample is not handling\\nall pos\", \"sible failure cases. In a real application deployed to the cloud, you must embrace the fact that\\niss\", \"ues will arise eventually, and you must implement that check and resend logic. Using the table as a\\n\", \"queue can be more effective than the first approach if you have that table as a single source of eve\", \"nts\\nwhen publishing them (with the worker) through the event bus.\\n\\nImplementing atomicity when publi\", \"shing integration events through the event\\nbus\\n\\nThe following code shows how you can create a single\", \" transaction involving multiple DoContext\\nobjects\\u2014one context related to the original data being upd\", \"ated, and the second context related to\\nthe IntegrationEventLog table.\\n\\nThe transaction in the examp\", \"le code below will not be resilient if connections to the database have\\nany issue at the time when t\", \"he code is running. This can happen in cloud-based systems like Azure\\nSQL DB, which might move datab\", \"ases across servers. For implementing resilient transactions across\\n\\nmultiple contexts, see the Impl\", \"ementing resilient Entity Framework Core SQL connections section later\\nin this guide.\\n\\nFor clarity, \", \"the following example shows the whole process in a single piece of code. However, the\\neShopOnContain\", \"ers implementation is refactored and splits this logic into multiple classes so It's\\neasier to maint\", \"ain.\\n\\n// Update Product from the Catalog microservice\\n//\\npublic async Task<IActionResult> UpdateProd\", \"uct([FromBody |CatalogItem productToUpdate)\\n{\\nvar catalogItem =\\nawait _catalogContext.CatalogItems.S\", \"ingleOrDefaultAsync(i => i.Id ==\\nproductTouUpdate.Id) ;\\n\\n146 CHAPTER 5 | Designing and Developing Mu\", \"lti-Container and Microservice-Based .NET Applications\\nif (catalogItem == null) return NotFound();\\n\\n\", \"false;\\nnull;\\n\\nbool raiseProductPriceChangedEvent\\nIntegrationEvent priceChangedEvent\\n\\nif (catalogItem\", \".Price != productToUpdate.Price)\\nraiseProductPriceChangedEvent = true;\\n\\nif (raiseProductPriceChanged\", \"Event) // Create event if price has changed\\n{\\nvar oldPrice = catalogiItem.Price;\\npriceChangedEvent =\", \" new ProductPriceChangedIntegrationEvent(catalogIitem.Id,\\nproductToUpdate. Price,\\noldPrice) ;\\n}\\n// U\", \"pdate current product\\ncatalogiItem = productToUpdate;\\n\\n// Just save the updated product if the Produ\", \"ct's Price hasn't changed.\\nif (!raiseProductPriceChangedEvent )\\n\\n{\\nawait _catalogContext.SaveChanges\", \"Async() ;\\n}\\nelse // Publish to event bus only if product price changed\\n{\\n// Achieving atomicity betw\", \"een original DB and the IntegrationEventLog\\n// with a local transaction\\nuSing (var transaction = _ca\", \"talogContext.Database.BeginTransaction() )\\n{\\n_catalogContext.CatalogItems.Update(catalogItem) ;\\nawai\", \"t _catalogContext.SaveChangesAsync() ;\\nawait _integrationEventLogService.SaveEventAsync(priceChanged\", \"Event) ;\\ntransaction. Commit() ;\\n}\\n// Publish the integration event through the event bus\\n_eventBus.\", \"Publish(priceChangedEvent) ;\\n_integrationEventLogService.MarkEventAsPublishedAsync(\\npriceChangedEven\", \"t) ;\\n}\\nreturn Ok();\\n\\n}\\n\\nAfter the ProductPriceChangedIntegrationEvent integration event is created, \", \"the transaction that\\nstores the original domain operation (update the catalog item) also includes th\", \"e persistence of the\\nevent in the EventLog table. This makes it a single transaction, and you will a\", \"lways be able to check\\nwhether event messages were sent.\\n\\nThe event log table is updated atomically \", \"with the original database operation, using a local\\ntransaction against the same database. If any of\", \" the operations fail, an exception is thrown and the\\ntransaction rolls back any completed operation,\", \" thus maintaining consistency between the domain\\noperations and the event messages saved to the tabl\", \"e.\\n\\n147 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Application\", \"s\\nReceiving messages from subscriptions: event handlers in receiver microservices\\n\\nIn addition to th\", \"e event subscription logic, you need to implement the internal code for the\\nintegration event handle\", \"rs (like a callback method). The event handler is where you specify where the\\nevent messages of a ce\", \"rtain type will be received and processed.\\n\\nAn event handler first receives an event instance from t\", \"he event bus. Then it locates the component to\\nbe processed related to that integration event, propa\", \"gating and persisting the event as a change in\\nState in the receiver microservice. For example, if a\", \" ProductPriceChanged event originates in the\\ncatalog microservice, it is handled in the basket micro\", \"service and changes the state in this receiver\\nbasket microservice as well, as shown in the followin\", \"g code.\\n\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.IntegrationEvents.EventHandling\\n\\n\", \"t\\n\\npublic class ProductPriceChangedIntegrationEventHandler :\\nTIntegrationEventHandler<ProductPriceCh\", \"angedIntegrationEvent>\\n\\nt\\n\\nprivate readonly IBasketRepository _repository;\\n\\npublic ProductPriceChang\", \"edIntegrationEventHand1ler (\\nIBasketRepository repository)\\n\\nt\\n}\\n\\n_repository = repository;\\n\\npublic a\", \"sync Task Handle(ProductPriceChangedintegrationEvent @event)\\naf\\n\\nvar userIds = await _repository.Get\", \"Users() ;\\nforeach (var id in userlIds)\\n\\nt\\n\\nvar basket = await _repository.GetBasket(id) ;\\nawait Upda\", \"tePriceInBasketItems(@event.ProductId, @event.NewPrice, basket) ;\\n\\n}\\n\\nprivate async Task UpdatePrice\", \"InBasketItems(int productId, decimal newPrice,\\nCustomerBasket basket)\\n\\nt\\n\\nvar itemsToUpdate = basket\", \"?.Items?.Where(x => int.Parse(x.ProductId) ==\\nproductId) .ToList();\\nif (itemsToUpdate != null)\\n\\nfore\", \"ach (var item in itemsToUpdate)\\n{\\nif(item.UnitPrice != newPrice)\\n{\\nvar originalPrice = item.UnitPric\", \"e;\\nitem.UnitPrice = newPrice;\\nitem.OldUnitPrice = originalPrice;\\n}\\n\\n}\\nawait _repository.UpdateBasket\", \" (basket) ;\\n\\n148 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications\\nThe event handler needs to verify whether the product exists in any of the basket instanc\", \"es. It also\\nupdates the item price for each related basket line item. Finally, it creates an alert t\", \"o be displayed to\\nthe user about the price change, as shown in Figure 6-24.\\n\\nfr) A Notsecure | host.\", \"docker.internal\\n\\non containers\\n\\n[ SHOPPING BAG ]\\n- YOUR SHOPPING BAG\\n(2 items)\\n4 N ET TOTAL $34.00\\n\\n\", \"NET BLACK & WHITE MUG .NET BLUE HOODIE\\n\\n\\u00a7 10.00 1+ $ 10.00 $1200 \\u2014- 2 + $ 24.00\\n\\nNote that the price\", \" of this article changed\\n\\nin our Catalog. The old price when you C\\u2014O\\noriginally added it to the bask\", \"et was $ 8.5\\n\\nFigure 6-24. Displaying an item price change in a basket, as communicated by integrati\", \"on events\\n\\nIdempotency in update message events\\n\\nAn important aspect of update message events is tha\", \"t a failure at any point in the communication\\nshould cause the message to be retried. Otherwise a ba\", \"ckground task might try to publish an event\\nthat has already been published, creating a race conditi\", \"on. Make sure that the updates are either\\nidempotent or that they provide enough information to ensu\", \"re that you can detect a duplicate,\\ndiscard it, and send back only one response.\\n\\nAs noted earlier, \", \"idempotency means that an operation can be performed multiple times without\\nchanging the result. In \", \"a messaging environment, as when communicating events, an event is\\nidempotent if it can be delivered\", \" multiple times without changing the result for the receiver\\nmicroservice. This may be necessary bec\", \"ause of the nature of the event itself, or because of the way\\nthe system handles the event. Message \", \"idempotency is important in any application that uses\\nmessaging, not just in applications that imple\", \"ment the event bus pattern.\\n\\nAn example of an idempotent operation is a SQL statement that inserts d\", \"ata into a table only if that\\ndata is not already in the table. It does not matter how many times yo\", \"u run that insert SQL statement;\\nthe result will be the same\\u2014the table will contain that data. Idemp\", \"otency like this can also be\\nnecessary when dealing with messages If the messages could potentially \", \"be sent and therefore\\n\\n149 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications\\nprocessed more than once. For instance, if retry logic causes a sender to send \", \"exactly the same\\nmessage more than once, you need to make sure that it is idempotent.\\n\\nIt is possibl\", \"e to design idempotent messages. For example, you can create an event that says \\u201cset the\\nproduct pri\", \"ce to $25\\u201d instead of \\u201cadd $5 to the product price.\\u201d You could safely process the first\\nmessage any \", \"number of times and the result will be the same. That is not true for the second\\nmessage. But even i\", \"n the first case, you might not want to process the first event, because the system\\ncould also have \", \"sent a newer price-change event and you would be overwriting the new price.\\n\\nAnother example might b\", \"e an order-completed event that's propagated to multiple subscribers. The\\napp has to make sure that \", \"order information is updated in other systems only once, even if there are\\nduplicated message events\", \" for the same order-completed event.\\n\\nIt is convenient to have some kind of identity per event so th\", \"at you can create logic that enforces that\\neach event is processed only once per receiver.\\n\\nSome mes\", \"sage processing Is inherently idempotent. For example, if a system generates image\\nthumbnails, it mi\", \"ght not matter how many times the message about the generated thumbnail is\\nprocessed; the outcome is\", \" that the thumbnails are generated and they are the same every time. On\\nthe other hand, operations s\", \"uch as calling a payment gateway to charge a credit card may not be\\nidempotent at all. In these case\", \"s, you need to ensure that processing a message multiple times has\\nthe effect that you expect.\\n\\nAddi\", \"tional resources\\n\\n. Honoring message idempotency\\nhttps://learn.microsoft.com/previous-versions/msp-n\", \"-p/jj591565(v=pandp.10)#honoring-\\n\\nmessage-idempotency\\n\\nDeduplicating integration event messages\\n\\nYo\", \"u can make sure that message events are sent and processed only once per subscriber at different\\nlev\", \"els. One way is to use a deduplication feature offered by the messaging infrastructure you are\\nusing\", \". Another is to implement custom logic in your destination microservice. Having validations at\\nboth \", \"the transport level and the application level is your best bet.\\n\\nDeduplicating message events at the\", \" EventHandler level\\n\\nOne way to make sure that an event is processed only once by any receiver is by\", \" implementing certain\\nlogic when processing the message events in event handlers. For example, that \", \"is the approach used\\nin the eShopOnContainers application, as you can see in the source code of the\\n\", \"UserCheckoutAcceptedIntegrationEventHandler class when it receives a\\nUserCheckoutAcceptedIntegration\", \"Event integration event. (In this case, the CreateOrderCommand is\\nwrapped with an IdentifiedCommand,\", \" using the eventMsg.Requestld as an identifier, before sending it\\nto the command handler).\\n\\n150 CHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nDeduplicat\", \"ing messages when using RabbitMQ\\n\\nWhen intermittent network failures happen, messages can be duplica\", \"ted, and the message receiver\\nmust be ready to handle these duplicated messages. If possible, receiv\", \"ers should handle messages in\\nan idempotent way, which Is better than explicitly handling them with \", \"deduplication.\\n\\nAccording to the RabbitWQ documentation, \\u201cIf a message Is delivered to a consumer an\", \"d then\\nrequeued (because it was not acknowledged before the consumer connection dropped, for example\", \")\\nthen RabbitMQ will set the redelivered flag on it when it is delivered again (whether to the same\\n\", \"consumer or a different one).\\n\\nIf the \\u201credelivered\\u201d flag is set, the receiver must take that into ac\", \"count, because the message might\\nalready have been processed. But that is not guaranteed; the messag\", \"e might never have reached the\\nreceiver after it left the message broker, perhaps because of network\", \" issues. On the other hand, if the\\n\\u201credelivered\\u201d flag is not set, it is guaranteed that the message \", \"has not been sent more than once.\\nTherefore, the receiver needs to deduplicate messages or process m\", \"essages in an idempotent way\\nonly if the \\u201credelivered\\u201d flag is set in the message.\\n\\nAdditional resou\", \"rces\\n\\n. Forked eShopOnContainers using NServiceBus (Particular Software)\\nhttps://go.particular.net/e\", \"ShopOnContainers\\n\\u00b0 Event Driven Messaging\\n\\nhttps://patterns.arcitura.com/soa-patterns/design pattern\", \"s/event driven messaging\\n\\n\\u00b0 Jimmy Bogard. Refactoring Towards Resilience: Evaluating Coupling\\n\\nhttos\", \"://jimmybogard.com/refactoring-towards-resilience-evaluating-couplin\\n\\n\\u00b0 Publish-Subscribe channel\\nht\", \"tps://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChannel.\\nhtml\\n\\n. Comm\", \"unicating Between Bounded Contexts\\n\\n. Eventual Consistency\\nhttps://en.wikipedia.org/wiki/Eventual co\", \"nsistency\\n\\u00b0 Philip Brown. Strategies for Integrating Bounded Contexts\\n\\nhttps://www.culttt.com/2014/1\", \"1/26/strategies-integrating-bounded-contexts/\\n\\n. Chris Richardson. Developing Transactional Microser\", \"vices Using Aggregates, Event\\nSourcing and CQRS - Part 2\\nhttos://www.infog.com/articles/microservice\", \"s-aggreqates-events-caqrs-part-2-richardson\\n\\n\\u00b0 Chris Richardson. Event Sourcing pattern\\n\\nhttps://mic\", \"roservices.io/patterns/data/event-sourcing.html\\n\\n\\u00b0 Introducing Event Sourcing\\n\\nhttps://learn.microso\", \"ft.com/previous-versions/msp-n-p/jj/591559(v=pandp.10\\n\\n151 CHAPTER 5 | Designing and Developing Mult\", \"i-Container and Microservice-Based .NET Applications\\nEvent Store database. Official site.\\n\\nhttps://g\", \"eteventstore.com/\\n\\nPatrick Nommensen. Event-Driven Data Management for Microservices\\n\\nhttos://dzone.\", \"com/articles/event-driven-data-manaqement-for-microservices-1\\n\\nThe CAP Theorem\\nhttps://en.wikipedia.\", \"org/wiki/CAP theorem\\n\\nWhat is CAP Theorem?\\nhttps://www.quora.com/What-Is-CAP-Theorem-1\\n\\nData Consist\", \"ency Primer\\n\\nRick Saling. The CAP Theorem: Why \\u201cEverything is Different\\u201d with the Cloud and\\nInternet\", \"\\n\\nhttps://learn.microsoft.com/archive/blogs/rickatmicrosoft/the-cap-theorem-why-everything-\\n\\nis-diff\", \"erent-with-the-cloud-and-internet/\\n\\nEric Brewer. CAP Twelve Years Later: How the \\u201cRules\\u201d Have Change\", \"d\\nhttos://www.infog.com/articles/cap-twelve-years-later-how-the-rules-have-changed\\n\\nCAP, PACELC, and\", \" Microservices\\nhttps://ardalis.com/cap-pacelc-and-microservices/\\n\\nAzure Service Bus. Brokered Messag\", \"ing: Duplicate Detection\\n\\nhttps://github.com/microsoftarchive/msdn-code-gallery-\\nmicrosoft/tree/mast\", \"er/Windows%20Azure%20Product%20Team/Brokered%20Messaging%20\\nDuplicate%20Detection\\n\\nReliability Guide\", \" (RabbitWQ documentation)\\nhttps://www.rabbitmg.com/reliability.html#consumer\\n\\nTesting ASP.NET Core s\", \"ervices and web apps\\n\\nControllers are a central part of any ASP.NET Core API service and ASP.NET MVC\", \" Web application. As\\nsuch, you should have confidence they behave as intended for your application. \", \"Automated tests can\\n\\nprovide you with this confidence and can detect errors before they reach produc\", \"tion.\\n\\nYou need to test how the controller behaves based on valid or invalid inputs, and test contro\", \"ller\\n\\nresponses based on the result of the business operation it performs. However, you should have \", \"these\\ntypes of tests for your microservices:\\n\\n152\\n\\nUnit tests. These tests ensure that individual co\", \"mponents of the application work as expected.\\nAssertions test the component API.\\n\\nIntegration tests.\", \" These tests ensure that component interactions work as expected against\\nexternal artifacts like dat\", \"abases. Assertions can test component API, UI, or the side effects of\\nactions like database |/O, log\", \"ging, etc.\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applica\", \"tions\\n. Functional tests for each microservice. These tests ensure that the application works as\\nexp\", \"ected from the user's perspective.\\n\\n\\u00b0 Service tests. These tests ensure that end-to-end service use \", \"cases, including testing multiple\\nservices at the same time, are tested. For this type of testing, y\", \"ou need to prepare the\\nenvironment first. In this case, it means starting the services (for example,\", \" by using docker-\\ncompose up).\\n\\nImplementing unit tests for ASP.NET Core Web APIs\\n\\nUnit testing invo\", \"lves testing a part of an application in isolation from its infrastructure and\\ndependencies. When yo\", \"u unit test controller logic, only the content of a single action or method is\\ntested, not the behav\", \"ior of its dependencies or of the framework itself. Unit tests do not detect issues\\nin the interacti\", \"on between components\\u2014that is the purpose of integration testing.\\n\\nAs you unit test your controller \", \"actions, make sure you focus only on their behavior. A controller unit\\ntest avoids things like filte\", \"rs, routing, or model binding (the mapping of request data to a ViewModel\\nor DTO). Because they focu\", \"s on testing just one thing, unit tests are generally simple to write and\\nquick to run. A well-writt\", \"en set of unit tests can be run frequently without much overhead.\\n\\nUnit tests are implemented based \", \"on test frameworks like xUnit.net, MSTest, Mog, or NUnit. For the\\neShopOnContainers sample applicati\", \"on, we are using xUnit.\\n\\nWhen you write a unit test for a Web API controller, you instantiate the co\", \"ntroller class directly using\\nthe new keyword in C#, so that the test will run as fast as possible. \", \"The following example shows how\\nto do this when using xUnit as the Test framework.\\n\\n[Fact |\\npublic a\", \"sync Task Get_order_detail_success()\\n{\\n\\n//Arrange\\n\\nvar fakeOrderId = \\\"12\\\";\\n\\nvar fakeOrder = GetFakeO\", \"rder() ;\\n\\nHi ooc\\n\\n//Act\\n\\nvar orderController = new OrderController(\\n_orderServiceMock.Object,\\n_baske\", \"tServiceMock.Object,\\n_identityParserMock.Object) ;\\n\\norderController.ControllerContext.HttpContext = \", \"_contextMock.Object;\\nvar actionResult = await orderController.Detail(fakeOrderId) ;\\n\\n//Assert\\nvar vi\", \"ewResult = Assert.IsType<ViewResult>(actionResult) ;\\nAssert.IsAssignableFrom<Order>(viewResult.ViewD\", \"ata.Mode1) ;\\n\\n153 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET A\", \"pplications\\nImplementing integration and functional tests for each microservice\\n\\nAs noted, integrati\", \"on tests and functional tests have different purposes and goals. However, the way\\nyou implement both\", \" when testing ASP.NET Core controllers is similar, so in this section we\\nconcentrate on integration \", \"tests.\\n\\nIntegration testing ensures that an application's components function correctly when assembl\", \"ed.\\nASP.NET Core supports integration testing using unit test frameworks and a built-in test web hos\", \"t that\\ncan be used to handle requests without network overhead.\\n\\nUnlike unit testing, integration te\", \"sts frequently involve application infrastructure concerns, such as a\\ndatabase, file system, network\", \" resources, or web requests and responses. Unit tests use fakes or mock\\nobjects in place of these co\", \"ncerns. But the purpose of integration tests is to confirm that the system\\nworks as expected with th\", \"ese systems, so for integration testing you do not use fakes or mock objects.\\nInstead, you include t\", \"he infrastructure, like database access or service invocation from other services.\\n\\nBecause integrat\", \"ion tests exercise larger segments of code than unit tests, and because integration\\ntests rely on in\", \"frastructure elements, they tend to be orders of magnitude slower than unit tests. Thus,\\nit is a goo\", \"d idea to limit how many integration tests you write and run.\\n\\nASP.NET Core includes a built-in test\", \" web host that can be used to handle HTTP requests without\\nnetwork overhead, meaning that you can ru\", \"n those tests faster than when using a real web host. The\\ntest web host (TestServer) is available in\", \" a NuGet component as Microsoft.AspNetCore.TestHost. It can\\nbe added to integration test projects an\", \"d used to host ASP.NET Core applications.\\n\\nAs you can see in the following code, when you create int\", \"egration tests for ASP.NET Core controllers,\\nyou instantiate the controllers through the test host. \", \"This functionality is comparable to an HTTP\\nrequest, but it runs faster.\\n\\npublic class PrimeWebDefau\", \"ltRequestShould\\n{\\n\\nprivate readonly TestServer _server;\\nprivate readonly HttpClient _client;\\n\\npublic\", \" PrimeWebDefaultRequestShould( )\\n{\\n\\n// Arrange\\n\\nserver = new TestServer(new WebHostBuilder()\\n.UseSta\", \"rtup<Startup>());\\n\\n_client = _server.CreateClient() ;\\n\\n}\\n\\n[Fact ]\\npublic async Task ReturnHelloWorld\", \"()\\n{\\n// Act\\nvar response = await _client.GetAsync(\\\"/\\\");\\nresponse. EnsureSuccessStatusCode() ;\\nvar re\", \"sponseString = await response.Content.ReadAsStringAsync() ;\\n// Assert\\nAssert.Equal(\\\"Hello World!\\\", r\", \"esponseString) ;\\n\\n154 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications\\nAdditional resources\\n\\n. Steve Smith. Testing controllers (ASP.NET Core)\\nhttps://lear\", \"n.microsoft.com/aspnet/core/mvc/controllers/testing\\n\\n. Steve Smith. Integration testing (ASP.NET Cor\", \"e)\\nhttps://learn.microsoft.com/aspnet/core/test/integration-tests\\n\\n\\u00b0 Unit testing in .NET using dotn\", \"et test\\n\\n\\u00b0 xUnit.net. Official site.\\n\\nhttps://xunit.net/\\n\\n\\u00b0 Unit Test Basics.\\n\\nhttps://learn.microso\", \"ft.com/visualstudio/test/unit-test-basics\\n\\n. Mog. GitHub repo.\\nhttps://github.com/moq/mogq\\n\\n\\u00b0 NUnit.\", \" Official site.\\nhttps://nunit.org/\\n\\nImplementing service tests on a multi-container application\\n\\nAs \", \"noted earlier, when you test multi-container applications, all the microservices need to be running\\n\", \"within the Docker host or container cluster. End-to-end service tests that include multiple operatio\", \"ns\\ninvolving several microservices require you to deploy and start the whole application in the Dock\", \"er\\nhost by running docker-compose up (or a comparable mechanism if you are using an orchestrator).\\nO\", \"nce the whole application and all its services is running, you can execute end-to-end integration an\", \"d\\nfunctional tests.\\n\\nThere are a few approaches you can use. In the docker-compose.yml file that you\", \" use to deploy the\\napplication at the solution level you can expand the entry point to use dotnet te\", \"st. You can also use\\nanother compose file that would run your tests in the image you are targeting. \", \"By using another\\ncompose file for integration tests that includes your microservices and databases o\", \"n containers, you\\ncan make sure that the related data is always reset to its original state before r\", \"unning the tests.\\n\\nOnce the compose application is up and running, you can take advantage of breakpo\", \"ints and\\nexceptions if you are running Visual Studio. Or you can run the integration tests automatic\", \"ally in your\\nCl pipeline in Azure DevOps Services or any other CI/CD system that supports Docker con\", \"tainers.\\n\\nTesting in eShopOnContainers\\n\\nThe reference application (eShopOnContainers) tests were rec\", \"ently restructured and now there are\\nfour categories:\\n\\n1. Unit tests, just plain old regular unit te\", \"sts, contained in the {MicroserviceName}.UnitTests\\nprojects\\n\\n155 CHAPTER 5 | Designing and Developin\", \"g Multi-Container and Microservice-Based .NET Applications\\n2.  Microservice functional/integration t\", \"ests, with test cases in\\n\\nvolving the infrastructure for\\n\\neach microservice but isolated from the ot\", \"hers and are contained in the\\n\\n{MicroserviceName}.FunctionalTests projects.\\n\\n3. Application function\", \"al/integration tests, which focus on mi\\ncases that exert several microservices. These tests are loca\", \"ted\\nApplication.FunctionalTests.\\n\\ncroservices integration, with test\\nIn project\\n\\nWhile unit and inte\", \"gration tests are organized in a test folder within the microservice project,\\n\\napplication and load \", \"tests are managed separately under the root fold\\n\\n7 Solution 'eShopOnContainers-ServicesAndWebApps' \", \"(34 of 34 projects\\n\\nb Solution Items\\nal Src\\n\\nBuildingBlocks\\n\\nServices\\n[> Basket\\n1) ail Catalog\\ni tes\", \"ts\\n\\nb af] Catalog.FunctionalTests\\n> af) Catalog.UnitTests\\n> af] Catalog.APl\\nIdentity\\nLocation\\nMarket\", \"ing\\n\\nOrdering\\n\\nPayment (3)\\nWebhooks\\nService lests\\n> af) Application.FunctionalTests\\n\\n> Se docker-com\", \"pose\\n\\nFigure 6-25. Test folder structure in eShopOnContainers\\n\\ner, as shown in Figure 6-25.\\n\\nMicrose\", \"rvice and Application functional/integration tests are run from Visual Studio, using the regular\\n\\nte\", \"sts runner, but first you need to start the required infrastructure servi\\ncompose files contained in\", \" the solution test folder:\\n\\ndocker-compose-test.yml\\n\\nversion: '3.4'\\n\\nservices:\\nredis.data:\\nimage: re\", \"dis:alpine\\nrabbitmq:\\nimage: rabbitmq:3-management-alpine\\nsqldata:\\n\\n156 CHAPTER 5 | Designing and Dev\", \"eloping Multi-Container and Mi\\n\\nces, with a set of docker-\\n\\ncroservice-Based .NET Applications\\nimage\", \": mcr.microsoft.com/mssql/server:2017-latest\\nnosqldata:\\nimage: mongo\\n\\ndocker-compose-test.override.y\", \"ml\\n\\nversion: '3.4'\\n\\nservices:\\nredis.data:\\nports:\\n- \\\"6379:6379\\\"\\nrabbitmq:\\nports:\\n- \\\"15672:15672\\\"\\n- \\\"5\", \"672:5672\\\"\\nsqldata:\\nenvironment:\\n- SA PASSWORD=Pass@word\\n- ACCEPT _EULA=Y\\nports:\\n- \\\"5433:1433\\\"\\n\\nnosql\", \"data:\\nports:\\n- \\\"27017:27017\\\"\\n\\nSo, to run the functional/integration tests you must first run this co\", \"mmand, from the solution test\\nfolder:\\n\\ndocker-compose -f docker-compose-test.yml -f docker-compose-t\", \"est.override.yml up\\nAs you can see, these docker-compose files only start the Redis, RabbitMQ, SQL S\", \"erver, and MongoDB\\n\\nmicroservices.\\n\\nAdditional resources\\n\\n\\u00b0 Unit & Integration testing on the eShopO\", \"nContainers\\n\\ntesting\\n\\n. Load testing on the eShopOnContainers\\n\\nhttps://github.com/dotnet-architectur\", \"e/eShopOnContainers/wiki/Load-testing\\n\\nImplement background tasks in microservices with\\nIHostedServi\", \"ce and the BackgroundService class\\n\\nBackground tasks and scheduled jobs are something you might need\", \" to use in any application,\\nwhether or not it follows the microservices architecture pattern. The di\", \"fference when using a\\nmicroservices architecture is that you can implement the background task in a \", \"separate\\nprocess/container for hosting so you can scale it down/up based on your need.\\n\\n157 CHAPTER \", \"5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nFrom a generic\", \" point of view, in .NET we called these type of tasks Hosted Services, because they are\\nservices/log\", \"ic that you host within your host/application/microservice. Note that in this case, the\\nhosted servi\", \"ce simply means a class with the background task logic.\\n\\nSince .NET Core 2.0, the framework provides\", \" a new interface named !HostedService helping you to\\neasily implement hosted services. The basic ide\", \"a is that you can register multiple background tasks\\n(hosted services) that run in the background wh\", \"ile your web host or host is running, as shown in the\\nimage 6-26.\\n\\nImplementing background tasks wit\", \"h IHostedService in .NET Core\\n\\n- Supported in: ae Supported only in:\\neae -NET Core 1.x and 2.x acne \", \"-NET Core 2.1 and up\\nASP.NET Core IWebHost .NET Core IHost\\n(Can be an MVC app, WebAPI service) (Simp\", \"le process/console-app)\\n\\n=\\n\\nMylHostedServiceA ? *) Background tast MylHostedServiceA 7 %) Background\", \" task\\nnN = x. -\\n\\n* Web/Http\\nfeatures MylHostedServiceB 7 ~ Background task MylHostedServiceB r*% Bac\", \"kground tas}\\n\\n* Optional MVC : a ; =\\nframework MylHostedServiceC / }) Background task MylHostedServi\", \"ceC / 4) Background task\\n\\n: = =\\nservices\\n\\nMylHostedService\\u2018n?. %) Background tas! MylHostedService \\u2018\", \"n7 *) gackground task\\n\\nx\\n\\n(*) In .NET Core: (**) Only since .NET Core 2.1\\nIWebHost implemented in Mi\", \"crosoft.AspNetCore.Hosting IHost and IHostedService are implemented\\nIHostedService implemented in Mi\", \"crosoft. Extensions.Hosting in Microsoft. Extensions.Hosting\\n\\nFigure 6-26. Using |HostedService in a\", \" WebHost vs. a Host\\n\\nASP.NET Core 1.x and 2.x support |!WebHost for background processes in web apps\", \". .NET Core 2.1 and\\nlater versions support IHost for background processes with plain console apps. N\", \"ote the difference\\nmade between WebHost and Host.\\n\\nA WebHost (base class implementing IWebHost) in A\", \"SP.NET Core 2.0 is the infrastructure artifact you\\nuse to provide HTTP server features to your proce\", \"ss, such as when you're implementing an MVC web\\napp or Web API service. It provides all the new infr\", \"astructure goodness in ASP.NET Core, enabling you\\nto use dependency injection, insert middlewares in\", \" the request pipeline, and similar. The WebHost\\nuses these very same IHostedServices for background \", \"tasks.\\n\\nA Host (base class implementing IHost) was introduced in .NET Core 2.1. Basically, a Host al\", \"lows you\\nto have a similar infrastructure than what you have with WebHost (dependency injection, hos\", \"ted\\nservices, etc.), but in this case, you just want to have a simple and lighter process as the hos\", \"t, with\\nnothing related to MVC, Web API or HTTP server features.\\n\\nTherefore, you can choose and eith\", \"er create a specialized host-process with IHost to handle the\\nhosted services and nothing else, such\", \" a microservice made just for hosting the IHostedServices, or\\nyou can alternatively extend an existi\", \"ng ASP.NET Core WebHost, such as an existing ASP.NET Core\\nWeb API or MVC app.\\n\\n158 CHAPTER 5 | Desig\", \"ning and Developing Multi-Container and Microservice-Based .NET Applications\\nEach approach has pros \", \"and cons depending on your business and scalability needs. The bottom line\\nis basically that if your\", \" background tasks have nothing to do with HTTP (IWebHost) you should use\\n[Host.\\n\\nRegistering hosted \", \"services in your WebHost or Host\\n\\nLet's drill down further on the IHostedService interface since its\", \" usage is pretty similar in a WebHost or\\nin a Host.\\n\\nSignalR is one example of an artifact using hos\", \"ted services, but you can also use it for much simpler\\nthings like:\\n\\n. A background task polling a d\", \"atabase looking for changes.\\n\\n. A scheduled task updating some cache periodically.\\n\\n\\u00b0 An implementat\", \"ion of QueueBackgroundWorklitem that allows a task to be executed ona\\nbackground thread.\\n\\n. Processi\", \"ng messages from a message queue in the background of a web app while sharing\\ncommon services such a\", \"s lLogger.\\n\\n\\u00b0 A background task started with Task.Run().\\n\\nYou can basically offload any of those act\", \"ions to a background task that implements |HostedService.\\n\\nThe way you add one or multiple IHostedSe\", \"rvices into your WebHost or Host is by registering them\\nup through the AddHostedService extension me\", \"thod in an ASP.NET Core WebHost (or in a Host in\\n.NET Core 2.1 and above). Basically, you have to re\", \"gister the hosted services within application startup\\nin Program.cs.\\n\\n//Other DI registrations;\\n\\n// \", \"Register Hosted Services\\n\\nbuilder.Services.AddHostedService<GracePeriodManagerService>() ;\\nbuilder.S\", \"ervices.AddHostedService<MyHostedServiceB>() ;\\nbuilder.Services.AddHostedService<MyHostedServiceC>()\", \" ;\\n\\nPico\\n\\nIn that code, the GracePeriodManagerService hosted service is real code from the Ordering \", \"business\\nmicroservice in eShopOnContainers, while the other two are just two additional samples.\\n\\nTh\", \"e IHostedService background task execution is coordinated with the lifetime of the application (host\", \"\\nor microservice, for that matter). You register tasks when the application starts and you have the\\n\", \"opportunity to do some graceful action or clean-up when the application is shutting down.\\n\\nWithout u\", \"sing IHostedService, you could always start a background thread to run any task. The\\ndifference is p\", \"recisely at the app\\u2019s shutdown time when that thread would simply be killed without\\nhaving the oppor\", \"tunity to run graceful clean-up actions.\\n\\nThe IHostedService interface\\n\\nWhen you register an |Hosted\", \"Service, .NET calls the StartAsync() and StopAsync() methods of your\\nIHostedService type during appl\", \"ication start and stop respectively. For more details, see\\n[HostedService interface.\\n\\n159 CHAPTER 5 \", \"| Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nAs you can imagi\", \"ne, you can create multiple implementations of I|HostedService and register each of\\nthem in Program.\", \"cs, as shown previously. All those hosted services will be started and stopped along\\nwith the applic\", \"ation/microservice.\\n\\nAs a developer, you are responsible for handling the stopping action of your se\", \"rvices when\\nStopAsync() method is triggered by the host.\\n\\nImplementing IHostedService with a custom \", \"hosted service class\\nderiving from the BackgroundService base class\\n\\nYou could go ahead and create y\", \"our custom hosted service class from scratch and implement the\\nlHostedService, as you need to do whe\", \"n using .NET Core 2.0 and later.\\n\\nHowever, since most background tasks will have similar needs in re\", \"gard to the cancellation tokens\\nmanagement and other typical operations, there is a convenient abstr\", \"act base class you can derive\\nfrom, named BackgroundService (available since .NET Core 2.1).\\n\\nThat c\", \"lass provides the main work needed to set up the background task.\\nThe next code is the abstract Back\", \"groundService base class as implemented in .NET.\\n\\n// Copyright (c) .NET Foundation. Licensed under t\", \"he Apache License, Version 2.0.\\n/// <Summary>\\n/// Base class for implementing a long running <see cr\", \"ef=\\\"IHostedService\\\"/>.\\n/// </summary>\\npublic abstract class BackgroundService : IHostedService, IDis\", \"posable\\n{\\n\\nprivate Task _executingTask;\\n\\nprivate readonly CancellationTokenSource _stoppingCts =\\n\\nne\", \"w CancellationTokenSource() ;\\n\\nprotected abstract Task ExecuteAsync(CancellationToken stoppingToken)\", \" ;\\n\\npublic virtual Task StartAsync(CancellationToken cancellationToken)\\n\\n{\\n\\n// Store the task we're \", \"executing\\n_executingTask = ExecuteAsync(_stoppingCts. Token) ;\\n\\n// If the task is completed then ret\", \"urn it,\\n// this will bubble cancellation and failure to the caller\\nif (_executingTask.IsCompleted)\\n\\n\", \"t\\n}\\n\\nreturn _executingTask;\\n\\n// Otherwise it's running\\nreturn Task.CompletedTask;\\n\\n}\\n\\npublic virtual\", \" async Task StopAsync(CancellationToken cancellationToken)\\n\\n{\\n// Stop called without start\\nif (_exec\", \"utingTask == null)\\n\\nt\\n}\\n\\nreturn;\\n\\n160 CHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications\\ntry\\n\\n{\\n// Signal cancellation to the executing method\\n_stoppingCts.C\", \"ancel();\\n}\\nfinally\\n{\\n// Wait until the task completes or the stop token triggers\\nawait Task.WhenAny(\", \"_executingTask, Task.Delay(Timeout. Infinite,\\ncancellationToken) ) ;\\n}\\n}\\npublic virtual void Dispose\", \"()\\n{\\n_stoppingCts.Cancel();\\n}\\n\\nWhen deriving from the previous abstract base class, thanks to that i\", \"nherited implementation, you just\\nneed to implement the ExecuteAsync() method in your own custom hos\", \"ted service class, as in the\\nfollowing simplified code from eShopOnContainers which is polling a dat\", \"abase and publishing\\nintegration events into the Event Bus when needed.\\n\\npublic class GracePeriodMan\", \"agerService : BackgroundService\\n\\n{\\nprivate readonly ILogger<GracePeriodManagerService> _logger;\\npriv\", \"ate readonly OrderingBackgroundSettings _settings;\\n\\nprivate readonly IEventBus _eventBus;\\n\\npublic Gr\", \"acePeriodManagerService(IOptions<OrderingBackgroundSettings> settings,\\nITEventBus eventBus,\\nILogger<\", \"GracePeriodManagerService> logger)\\n\\nt\\n}\\n\\n// Constructor's parameters validations...\\n\\nprotected overr\", \"ide async Task ExecuteAsync(CancellationToken stoppingToken)\\n\\n{\\n\\n_logger.LogDebug($\\\"GracePeriodManag\", \"erService is starting.\\\");\\n\\nstoppingToken.Register(() =>\\n_logger.LogDebug($\\\" GracePeriod background t\", \"ask is stopping.\\\"));\\n\\nwhile (!stoppingToken.IsCancellationRequested)\\n\\n{\\n_logger.LogDebug($\\\"GracePeri\", \"od task doing background work.\\\") ;\\n\\n// This eShopOnContainers method is querying a database table\\n//\", \" and publishing events into the Event Bus (RabbitMQ / ServiceBus)\\nCheckConfirmedGracePeriodOrders() \", \";\\n\\ntry {\\n\\n}\\n\\ncatch (TaskCanceledException exception) {\\n_logger.LogCritical(exception, \\\"TaskCanceledE\", \"xception Error\\u201d,\\n\\nawait Task.Delay(_settings.CheckUpdateTime, stoppingToken) ;\\n\\nexception.Message) ;\", \"\\n\\n161 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n\", \"5\\n\\n_logger.LogDebug($\\\"GracePeriod background task is stopping.\\\");\\n\\nIn this specific case for eSshopO\", \"nContainers, it's executing an application method that's querying a\\ndatabase table looking for order\", \"s with a specific state and when applying changes, it is publishing\\nintegration events through the e\", \"vent bus (underneath it can be using RabbitMQ or Azure Service Bus).\\n\\nOf course, you could run any o\", \"ther business background task, instead.\\n\\nBy default, the cancellation token is set with a 5 seconds \", \"timeout, although you can change that value\\nwhen building your WebHost using the UseShutdownTimeout \", \"extension of the |WebHostBuilder. This\\nmeans that our service is expected to cancel within 5 seconds\", \" otherwise it will be more abruptly killed.\\n\\nThe following code would be changing that time to 10 se\", \"conds.\\n\\nWebHost.CreateDefaultBuilder (args)\\n.UseShutdownTimeout (TimeSpan.FromSeconds (10) )\\n\\nSummar\", \"y class diagram\\n\\nThe following image shows a visual summary of the classes and interfaces involved w\", \"hen\\nimplementing |HostedServices.\\n\\nClass diagram with a custom |HostedService and related classes an\", \"d interfaces\\n\\nIHostedService\\ninterface\\n\\nMyHostedServiceA\\nclass = BackgroundService\\n\\nbase class (*)\\n\\n\", \"WebHost : |WebHost\\nOr\\nHost : IHost (*) r~ Background task\\n\\nRK\\u201d ExecuteAsync()\\n\\n(**) IHost and Backgr\", \"oundService are implemented\\nin Microsoft.Extensions.Hosting\\nonly since .NET Core 2.1\\n\\nFigure 6-27. C\", \"lass diagram showing the multiple classes and interfaces related to |IHostedService\\n\\nClass diagram: \", \"|WebHost and I|Host can host many services, which inherit from BackgroundService,\\nwhich implements |\", \"HostedService.\\n\\n162 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" Applications\\nDeployment considerations and takeaways\\n\\nIt is important to note that the way you depl\", \"oy your ASP.NET Core WebHost or .NET Host might\\nimpact the final solution. For instance, if you depl\", \"oy your WebHost on IIS or a regular Azure App\\nService, your host can be shut down because of app poo\", \"l recycles. But if you are deploying your host\\nas a container into an orchestrator like Kubernetes, \", \"you can control the assured number of live\\ninstances of your host. In addition, you could consider o\", \"ther approaches in the cloud especially made\\nfor these scenarios, like Azure Functions. Finally, if \", \"you need the service to be running all the time and\\nare deploying on a Windows Server you could use \", \"a Windows Service.\\n\\nBut even for a WebHost deployed into an app pool, there are scenarios like repop\", \"ulating or flushing\\napplication\\u2019s in-memory cache that would be still applicable.\\n\\nThe IHostedServic\", \"e interface provides a convenient way to start background tasks in an ASP.NET Core\\nweb application (\", \"in .NET Core 2.0 and later versions) or in any process/host (starting in .NET Core 2.1\\nwith |Host). \", \"Its main benefit is the opportunity you get with the graceful cancellation to clean-up the\\ncode of y\", \"our background tasks when the host itself is shutting down.\\n\\nAdditional resources\\n\\u00b0 Building a sched\", \"uled task in ASP.NET Core/Standard 2.0\\n\\naspnet- core-2.html\\n\\n\\u00b0 Implementing IHostedService in ASP.NE\", \"T Core 2.0\\nhttps://www.stevejgordon.co.uk/asp-net-core-2-ihostedservice\\n\\n\\u00b0 GenericHost Sample using \", \"ASP.NET Core 2.1\\nhttps://github.com/aspnet/Hosting/tree/release/2.1/samples/GenericHostSample\\n\\nImple\", \"ment API Gateways with Ocelot\\n\\nImportant\\n\\nThe reference microservice application eshopOnContainers i\", \"s currently using features provided by\\nEnvoy to implement the API Gateway instead of the earlier ref\", \"erenced Ocelot. We made this design\\nchoice because of Envoy's built-in support for the WebSocket pro\", \"tocol, required by the new gRPC\\n\\ninter-service communications implemented in eshopOnContainers. Howe\", \"ver, we've retained this\\nsection in the guide so you can consider Ocelot as a simple, capable, and l\", \"ightweight API Gateway\\nsuitable for production-grade scenarios. Also, latest Ocelot version contains\", \" a breaking change on its\\njson schema. Consider using Ocelot < v16.0.0, or use the key Routes instea\", \"d of ReRoutes.\\n\\nArchitect and design your API Gateways\\n\\nThe following architecture diagram shows how\", \" API Gateways were implemented with Ocelot in\\neShopOnContainers.\\n\\n163 CHAPTER 5 | Designing and Deve\", \"loping Multi-Container and Microservice-Based .NET Applications\\neShopOnContainers reference applicat\", \"ion\\n(Development environment architecture)\\n\\n| Docker Host poe\\n\\nre 3 ee eS\\n\\nClient apps\\n\\nPy SQL Serve\", \"r m\\u2122\\n\\ndatab.\\neShop mobile app sabes =\\n\\nXamarin.Forms\\nC#\\nxPlat. OS:\\niOS\\nAndroid\\nWindows\\n\\n(\\nI\\nI\\n|\\n|\\na \", \"ee ma ( Catalog microservice \\\\ \\\\\\n| API Gateways / BFF | | col Sener | BQ\\n| database |\\n\\nRabbitMQ\\n\\nMob\", \"ile-Shopping\\n\\n\\u2014, @@\\u00ae SQL Server\\n\\nOrdering.AP| database\\n\\nsng }UaAq\\n:[x] : F\\n\\neShop traditional Web ap\", \"p\\n~-- ee ~ |\\n\\n( eShop WebApp MVC \\\\\\n\\n|\\nKa & & I | ASP.NET Core MVC\\n\\\\\\n\\n!\\n\\nService Bus\\n\\n(jauUeYD aquosq\", \"ns/ys!|qnd)\\n\\nHTML\\neShop SPA Web app\\n\\n\\u2014\\n\\n| zh Bi\\n\\ntee, MongoDB / |\\nwey EO correc\\nw\\n\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\", \"\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n\\\\\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\nSQL Server\\n\\n| /\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n|\\n\\n}\\n\\n~~ Pn a a Y\\n\", \"Locations microservice /\\n\\n|\\n\\n\\\\\\n\\ni) +e\\u2014@\\u00b0, MongoDB/ |\\n\\nI \\u2018 J * CosmosDB_ |\\nNS , \\\\ 4\\n\\na,\\n\\n---~. ;>\\n\\nTy\", \"peScript/Angular\\n\\nI I el ee ee\\n\\nFigure 6-28. eshopOnContainers architecture with API Gateways\\n\\nThat \", \"diagram shows how the whole application is deployed into a single Docker host or development\\nPC with\", \" \\u201cDocker for Windows\\u201d or \\u201cDocker for Mac\\u201d. However, deploying into any orchestrator would\\nbe similar\", \", but any container in the diagram could be scaled out in the orchestrator.\\n\\nIn addition, the infras\", \"tructure assets such as databases, cache, and message brokers should be\\noffloaded from the orchestra\", \"tor and deployed into high available systems for infrastructure, like Azure\\nSQL Database, Azure Cosm\", \"os DB, Azure Redis, Azure Service Bus, or any HA clustering solution on-\\npremises.\\n\\nAs you can also \", \"notice in the diagram, having several API Gateways allows multiple development\\nteams to be autonomou\", \"s (in this case Marketing features vs. Shopping features) when developing and\\ndeploying their micros\", \"ervices plus their own related API Gateways.\\n\\nIf you had a single monolithic API Gateway that would \", \"mean a single point to be updated by several\\ndevelopment teams, which could couple all the microserv\", \"ices with a single part of the application.\\n\\nGoing much further in the design, sometimes a fine-grai\", \"ned AP] Gateway can also be limited to a\\nsingle business microservice depending on the chosen archit\", \"ecture. Having the API Gateway\\u2019s\\nboundaries dictated by the business or domain will help you to get \", \"a better design.\\n\\nFor instance, fine granularity in the API Gateway tier can be especially useful fo\", \"r more advanced\\ncomposite UI applications that are based on microservices, because the concept of a \", \"fine-grained API\\nGateway is similar to a Ul composition service.\\n\\nWe delve into more details in the \", \"previous section Creating composite Ul based on microservices.\\n\\nAs a key takeaway, for many medium- \", \"and large-size applications, using a custom-built AP] Gateway\\nproduct is usually a good approach, bu\", \"t not as a single monolithic aggregator or unique central\\ncustom API Gateway unless that API Gateway\", \" allows multiple independent configuration areas for the\\nseveral development teams creating autonomo\", \"us microservices.\\n\\n164 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applications\\nSample microservices/containers to reroute through the API Gateways\\n\\nAs an example,\", \" eShopOnContainers has around six internal microservice-types that have to be\\npublished through the \", \"API Gateways, as shown in the following image.\\n\\n| Services\\n\\n>b \\u00a9 Basket \\u00a9@\\nb Mi Catalog @\\nb \\u00a9 Identi\", \"ty\\n\\nb Wi Location @\\nb \\u00a9 Marketing @\\nb \\u00a9) Ordering @\\nb \\u00a9 Payment @\\n\\nFigure 6-29. Microservice folders\", \" in eShopOnContainers solution in Visual Studio\\n\\nAbout the Identity service, in the design it\\u2019s left\", \" out of the API Gateway routing because it\\u2019s the only\\ncross-cutting concern in the system, although \", \"with Ocelot it\\u2019s also possible to include it as part of the\\nrerouting lists.\\n\\nAll those services are\", \" currently implemented as ASP.NET Core Web API services, as you can tell from\\nthe code. Let's focus \", \"on one of the microservices like the Catalog microservice code.\\n\\n4a im! cat\\n\\nCP Connected Services\\n>\", \"  .ts* Dependencies\\n- Properties\\n= Controllers\\n\\na vv\\n\\nb C* CatalogController.cs\\n> = C* HomeControlle\", \"r.cs\\n> C* PicController.cs\\n\\u2122\\u00ae Extensions\\n\\u00a9 Infrastructure\\n\\u2122 IntegrationEvents\\n\\u2122 Model\\n@ Pics\\n\\u2122 Setup\", \"\\n\\u2122 ViewModel\\n\\u00a7J appsettingsjson\\n> 6C* CatalogSettings.cs\\nL) Dockerfile\\nb> =6C* Program.cs\\nREADME.md\\n\", \"b =6C* Startup.cs\\n\\u00a5_) web.config\\n\\nAU, dink ARIS\\u201d a, ees en\\n\\nFigure 6-30. Sample Web API microservice\", \" (Catalog microservice)\\n\\n165 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-B\", \"ased .NET Applications\\nYou can see that the Catalog microservice is a typical ASP.NET Core Web API p\", \"roject with several\\ncontrollers and methods like in the following code.\\n\\n[HttpGet ]\\n\\n[Route(\\\"items/{\", \"id:int}\\\") ]\\n\\n[| ProducesResponseType( (int)HttpStatusCode.BadRequest) |\\n\\n[ ProducesResponseType( (in\", \"t)HttpStatusCode.NotFound) |\\n\\n[ ProducesResponseType(typeof (CatalogItem) , (int)HttpStatusCode. OK)\", \" ]\\npublic async Task<IActionResult> GetItemById(int id)\\n\\nif (id <= 0)\\n{\\n\\n}\\n\\nvar item = await _catalo\", \"gContext.CatalogItems.\\nSingleOrDefaultAsync(ci => ci.Id == id);\\n\\nreturn BadRequest() ;\\n\\nie\\n\\nif (item\", \" != null)\\n{\\n\\n}\\n\\nreturn NotFound();\\n\\nreturn Ok(item) ;\\n\\nThe HTTP request will end up running that kin\", \"d of C# code accessing the microservice database and\\nany additional required action.\\n\\nRegarding the \", \"microservice URL, when the containers are deployed in your local development PC\\n(local Docker host),\", \" each microservice's container always has an internal port (usually port 80)\\nspecified in its docker\", \"file, as in the following dockerfile:\\n\\nFROM mcr.microsoft.com/dotnet/aspnet:7.@ AS base\\nWORKDIR /app\", \"\\n\\nEXPOSE 80\\n\\nThe port 80 shown in the code is internal within the Docker host, so it can\\u2019t be reache\", \"d by client apps.\\n\\nClient apps can access only the external ports (if any) published when deploying \", \"with docker-\\ncompose.\\n\\nThose external ports shouldn't be published when deploying to a production en\", \"vironment. For this\\nspecific reason, why you want to use the API Gateway, to avoid the direct commun\", \"ication between the\\nclient apps and the microservices.\\n\\nHowever, when developing, you want to access\", \" the microservice/container directly and run it through\\nSwagger. That\\u2019s why in eShopOnContainers, th\", \"e external ports are still specified even when they won't\\nbe used by the API Gateway or the client a\", \"pps.\\n\\nHere\\u2019s an example of the docker-compose.override.yml file for the Catalog microservice:\\n\\ncatal\", \"og-api:\\nenvironment:\\n\\n- ASPNETCORE_ENVIRONMENT=Development\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- Con\", \"nectionString=YOUR_VALUE\\n\\n- ... Other Environment Variables\\n\\n166 CHAPTER 5 | Designing and Developin\", \"g Multi-Container and Microservice-Based .NET Applications\\nports:\\n- \\\"5101:80\\\" # Important: In a prod\", \"uction environment you should remove the external\\nport (5101) kept here for microservice debugging p\", \"urposes.\\n# The API Gateway redirects and access through the internal port (8@).\\n\\nYou can see how in \", \"the docker-compose.override.yml configuration the internal port for the Catalog\\ncontainer is port 80\", \", but the port for external access is 5101. But this port shouldn't be used by the\\napplication when \", \"using an API Gateway, only to debug, run, and test just the Catalog microservice.\\n\\nNormally, you won\", \"'t be deploying with docker-compose into a production environment because the\\nright production deplo\", \"yment environment for microservices is an orchestrator like Kubernetes or\\nService Fabric. When deplo\", \"ying to those environments you use different configuration files where you\\nwon't publish directly an\", \"y external port for the microservices but, you'll always use the reverse proxy\\nfrom the API Gateway.\", \"\\n\\nRun the catalog microservice in your local Docker host. Either run the full eshopOnContainers solu\", \"tion\\nfrom Visual Studio (it runs all the services in the docker-compose files), or start the Catalog\", \"\\nmicroservice with the following docker-compose command in CMD or PowerShell positioned at the\\nfolde\", \"r where the docker-compose.yml and docker-compose.override.yml are placed.\\n\\ndocker-compose run --ser\", \"vice-ports catalog-api\\n\\nThis command only runs the catalog-api service container plus dependencies t\", \"hat are specified in the\\ndocker-compose.yml. In this case, the SQL Server container and RabbitMQ con\", \"tainer.\\n\\nThen, you can directly access the Catalog microservice and see its methods through the Swag\", \"ger UI\\naccessing directly through that \\u201cexternal\\u201d port, in this case http://host.docker.internal:510\", \"1/swagger:\\n\\n167 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET App\", \"lications\\n\\u2014 C) localhost ke > + Ll. \\\\@\\n\\neShopOnContainers - Catalog HTTP API \\u00b0\\n\\nswagger/v1/swagger.j\", \"son\\n\\n\\u2014\\n\\nThe Catalog Microservice HTTP API. This is a Data-Driven/CRUD microservice sample\\n\\nTerms of \", \"service\\n\\n\\u2018 !\\n\\nam\\nwu\\nor\\ni\\n\\u00b0\\n\\noa\\n\\nGET /api/v1/Catalog/items\\n\\nPUT /api/v1/Catalog/items\\n\\nPOST /api/v1/C\", \"atalog/items\\n\\nGET /api/v1/Catalog/items/ {id}\\n\\n/api/v1/Catalog/Items/withname/ {name}\\n\\n/api/v1/Catal\", \"og/Items/type/{catalogTypeId}/brand/{catalogBrandId}\\n\\n/api/v1/Catalog/CatalogTypes\\n\\n/api/vi1/Catalog\", \"/CatalogBrands\\n\\nDELETE /api/v1/Catalog/{id}\\n\\nFigure 6-37. Testing the Catalog microservice with its \", \"Swagger Ul\\n\\nAt this point, you could set a breakpoint in C# code in Visual Studio, test the microser\", \"vice with the\\nmethods exposed in Swagger UI, and finally clean-up everything with the docker-compose\", \" down\\ncommand.\\n\\nHowever, direct-access communication to the microservice, in this case through the e\", \"xternal port\\n5101, is precisely what you want to avoid in your application. And you can avoid that b\", \"y setting the\\nadditional level of indirection of the API Gateway (Ocelot, in this case). That way, t\", \"he client app won't\\ndirectly access the microservice.\\n\\nImplementing your API Gateways with Ocelot\\n\\nO\", \"celot is basically a set of middleware that you can apply in a specific order.\\n\\nOcelot is designed t\", \"o work with ASP.NET Core only. The latest version of the package is 18.0 which\\ntargets .NET 6 and he\", \"nce is not suitable for .NET Framework applications.\\n\\n168 CHAPTER 5 | Designing and Developing Multi\", \"-Container and Microservice-Based .NET Applications\\nYou install Ocelot and its dependencies in your \", \"ASP.NET Core project with Ocelot's NuGet package,\\nfrom Visual Studio.\\n\\nInstall-Package Ocelot\\n\\nIn eS\", \"hopOnContainers, its API Gateway implementation is a simple ASP.NET Core WebHost project,\\nand Ocelot\", \"\\u2019s middleware handles all the AP! Gateway features, as shown in the following image:\\n\\nf=! ApiGw-Base\", \"\\n4 42] OcelotApiGw\\n& Connected Services\\n40oon Dependencies\\n>b ogee Analyzers\\n4 \\u201c NuGet\\nb QR Microsof\", \"t.AspNetCore.App (2.1.2)\\nb Ocelot (8.0.7)\\n>b oS SDK\\n> a Properties\\nai wwwroot\\nag] appsettings.json\\na\", \"L) Dockerfile\\n> a \\u20ac* Program.cs\\n> a \\u20ac* Startup.cs\\n\\nFigure 6-32. The OcelotApiGw base project in esho\", \"pOnContainers\\n\\nThis ASP.NET Core WebHost project is built with two simple files: Program.cs and Star\", \"tup.cs.\\n\\nThe Program.cs just needs to create and configure the typical ASP.NET Core BuildWebHost.\\n\\nn\", \"amespace OcelotApiGw\\n\\nt\\n\\npublic class Program\\n\\nt\\n\\npublic static void Main(string[] args)\\n\\nt\\n}\\n\\npubli\", \"c static IWebHost BuildWebHost(string[] args)\\n{\\n\\nBuildWebHost(args) .Run();\\n\\nvar builder = WebHost.C\", \"reateDefaultBuilder(args) ;\\n\\nbuilder.ConfigureServices(s => s.AddSingleton(builder) )\\n. ConfigureApp\", \"Configuration (\\nic => ic.AddJsonFile(Path.Combine(\\\"configuration\\\",\\n\\u201cconfiguration. json\\\") ) )\\n\\n.UseS\", \"tartup<Startup>() ;\\nvar host = builder.Build();\\nreturn host;\\n\\n169 CHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET Applications\\nThe important point here for Ocelot is t\", \"he configurationjson file that you must provide to the builder\\nthrough the AddJsonFile() method. Tha\", \"t configuration.json is where you specify all the API Gateway\\nReRoutes, meaning the external endpoin\", \"ts with specific ports and the correlated internal endpoints,\\nusually using different ports.\\n\\n\\\"ReRou\", \"tes\\\": [],\\n\\n\\\"GlobalConfiguration\\\": {}\\n\\nThere are two sections to the configuration. An array of ReRou\", \"tes and a GlobalConfiguration. The\\nReRoutes are the objects that tell Ocelot how to treat an upstrea\", \"m request. The Global configuration\\nallows overrides of ReRoute specific settings. It's useful if yo\", \"u don't want to manage lots of ReRoute\\nspecific settings.\\n\\nHere's a simplified example of ReRoute co\", \"nfiguration file from one of the API Gateways from\\neShopOnContainers.\\n\\n\\u201cReRoutes\\\": [\\n{\\n\\u201cDownstreamPa\", \"thTemplate\\\": \\\"/api/{version}/{everything}\\\",\\n\\u201cDownstreamScheme\\\": \\\"http\\\",\\n\\u201cDownstreamHostAndPorts\\\": [\\n\", \"\\n\\\"Host\\\": \\\"\\u201ccatalog-api\\\",\\n\\\"Port\\\": 82\\n}\\n],\\n\\u201cUpstreamPathTemplate\\\": \\\"/api/{version}/c/{everything}\\\",\\n\\u201cU\", \"pstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ]|\\n\\n\\u201cDownstreamPathTemplate\\\": \\\"/api/{version}/{everything\", \"}\\\",\\n\\u201cDownstreamScheme\\\": \\\"http\\\",\\n\\u201cDownstreamHostAndPorts\\\": [\\n{\\n\\\"Host\\\": \\\"basket-api\\\",\\n\\\"Port\\\": 82\\n}\\n],\\n\", \"\\u201cUpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\",\\n\\u201cUpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\", \"\\\" ],\\n\\u201c\\\"AuthenticationOptions\\\": {\\n\\u201cAuthenticationProviderKkey\\\": \\\"IdentityApikey\\\",\\n\\\"AllowedScopes\\\": [ \", \"]\\n}\\n}\\n\\n5)\\n\\n\\\"GlobalConfiguration\\\": {\\n\\u201cRequestIidKey\\\": \\\"OcRequestid\\\",\\n\\\"AdministrationPath\\\": \\\"/administ\", \"ration\\\"\\n}\\n}\\n\\n170 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications\\nThe main functionality of an Ocelot API Gateway is to take incoming HTTP requests and for\", \"ward them\\non to a downstream service, currently as another HTTP request. Ocelot's describes the rout\", \"ing of one\\nrequest to another as a ReRoute.\\n\\nFor instance, let's focus on one of the ReRoutes in the\", \" configuration.json from above, the\\nconfiguration for the Basket microservice.\\n\\n\\u201cDownstreamPathTempl\", \"ate\\\": \\\"/api/{version}/{everything}\\\",\\n\\n\\u201cDownstreamScheme\\\": \\\"http\\\",\\n\\u201cDownstreamHostAndPorts\\\": [\\n{\\n\\n\\\"Ho\", \"st\\\": \\\"basket-api\\\",\\n\\\"Port\\\": 82\\n}\\n],\\n\\u201cUpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\",\\n\\u201cUpstrea\", \"mHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ],\\n\\u201c\\\"AuthenticationOptions\\\": {\\n\\u201cAuthenticationProviderKkey\\\": \\\"I\", \"dentityApikey\\\",\\n\\\"AllowedScopes\\\": [ ]\\n\\n}\\n\\nThe DownstreamPathTemplate, Scheme, and DownstreamHostAndPo\", \"rts make the internal\\nmicroservice URL that this request will be forwarded to.\\n\\nThe port Is the inte\", \"rnal port used by the service. When using containers, the port specified at its\\ndockerfile.\\n\\nThe Hos\", \"t is a service name that depends on the service name resolution you are using. When using\\ndocker-com\", \"pose, the services names are provided by the Docker Host, which is using the service\\nnames provided \", \"in the docker-compose files. If using an orchestrator like Kubernetes or Service\\nFabric, that name s\", \"hould be resolved by the DNS or name resolution provided by each orchestrator.\\n\\nDownstreamHostAndPor\", \"ts is an array that contains the host and port of any downstream services that\\nyou wish to forward r\", \"equests to. Usually this configuration will just contain one entry but sometimes\\nyou might want to l\", \"oad balance requests to your downstream services and Ocelot lets you add more\\nthan one entry and the\", \"n select a load balancer. But if using Azure and any orchestrator it is probably a\\nbetter idea to lo\", \"ad balance with the cloud and orchestrator infrastructure.\\n\\nThe UpstreamPathTemplate is the URL that\", \" Ocelot will use to identify which\\nDownstreamPathTemplate to use for a given request from the client\", \". Finally, the\\nUpstreamHttpMethod is used so Ocelot can distinguish between different requests (GET,\", \" POST, PUT)\\nto the same URL.\\n\\nAt this point, you could have a single Ocelot API Gateway (ASP.NET Cor\", \"e WebHost) using one or\\nmultiple merged configuration.json files or you can also store the configura\", \"tion in a Consul KV store.\\nBut as introduced in the architecture and design sections, if you really \", \"want to have autonomous\\nmicroservices, it might be better to split that single monolithic API Gatewa\", \"y into multiple API\\nGateways and/or BFF (Backend for Frontend). For that purpose, let\\u2019s see how to i\", \"mplement that\\napproach with Docker containers.\\n\\n171 CHAPTER 5 | Designing and Developing Multi-Conta\", \"iner and Microservice-Based .NET Applications\\nUsing a single Docker container image to run multiple \", \"different API Gateway / BFF\\ncontainer types\\n\\nIn eShopOnContainers, we're using a single Docker conta\", \"iner image with the Ocelot API Gateway but\\nthen, at run time, we create different services/container\", \"s for each type of API-Gateway/BFF by\\nproviding a different configurationjson file, using a docker v\", \"olume to access a different PC folder for\\neach service.\\n\\nContainers\\nAPI Gateways / BFF\\n\\n>\\n\\nconfigura\", \"tion.json \\u201cA\\u201d\\n\\nMobile-Shopping\\n\\nDocker\\nImage\\n\\nww,\\n=>\\nOcELOT\\n\\nconfiguration.json \\\"B\\\"\\u201d\\n\\nMobile-Marketi\", \"ng\\n\\n\\u2014\\n\\nconfiguration.json \\u201cC\\u201d\\n\\nGeneric\\nOcelot API Gateway\\n\\nWeb-Shopping\\n\\nKel\\n\\nWeb-Marketing\\n\\nconfigu\", \"ration.json \\\"D\\\"\\n\\nFigure 6-33. Reusing a single Ocelot Docker image across multiple AP! Gateway types\", \"\\n\\nIn eShopOnContainers, the \\u201cGeneric Ocelot API Gateway Docker Image\\u201d is created with the project\\nna\", \"med \\u2018OcelotApiGw\\u2019 and the image name \\u201ceshop/ocelotapigw\\u201d that is specified in the docker-\\ncompose.ym\", \"l file. Then, when deploying to Docker, there will be four API-Gateway containers created\\nfrom that \", \"same Docker image, as shown in the following extract from the docker-compose.yml file.\\n\\nmobileshoppi\", \"ngapigw:\\nimage: eshop/ocelotapigw:${TAG: -latest}\\n\\n172 CHAPTER 5 | Designing and Developing Multi-Co\", \"ntainer and Microservice-Based .NET Applications\\nbuild:\\ncontext:\\ndockerfile: src/ApiGateways/ApiGw-B\", \"ase/Dockerfile\\n\\nmobilemarketingapigw:\\nimage: eshop/ocelotapigw:${TAG: -latest}\\nbuild:\\ncontext:\\ndocke\", \"rfile: src/ApiGateways/ApiGw-Base/Dockerfile\\n\\nwebshoppingapigw:\\nimage: eshop/ocelotapigw:${TAG: -lat\", \"est}\\nbuild:\\ncontext:\\ndockerfile: src/ApiGateways/ApiGw-Base/Dockerfile\\n\\nwebmarketingapigw:\\nimage: es\", \"hop/ocelotapigw:${TAG: -latest}\\nbuild:\\n\\ncontext:\\ndockerfile: src/ApiGateways/ApiGw-Base/Dockerfile\\n\\n\", \"Additionally, as you can see in the following docker-compose.override.yml file, the only difference\\n\", \"between those API Gateway containers is the Ocelot configuration file, which is different for each\\ns\", \"ervice container and it\\u2019s specified at run time through a Docker volume.\\n\\nmobileshoppingapigw:\\n\\nenvi\", \"ronment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://identity-api\\n\\nports:\\n- \\\"5200:80\\\"\\n\", \"\\nvolumes:\\n- ./src/ApiGateways/Mobile.Bff.Shopping/apigw: /app/configuration\\n\\nmobilemarketingapigw:\\n\\n\", \"environment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://identity-api\\n\\nports:\\n- \\\"5201:\", \"80\\\"\\n\\nvolumes:\\n- ./src/ApiGateways/Mobile.Bff.Marketing/apigw: /app/configuration\\n\\nwebshoppingapigw:\\n\", \"\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://identity-api\\n\\nports:\\n- \\\"5202\", \":80\\\"\\n\\nvolumes:\\n- ./src/ApiGateways/Web.Bff.Shopping/apigw: /app/configuration\\n\\nwebmarketingapigw:\\nen\", \"vironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://identity-api\\nports:\\n- \\\"5203:80\\\"\", \"\\n\\n173 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\n\", \"volumes:\\n- ./src/ApiGateways/Web.Bff.Marketing/apigw: /app/configuration\\n\\nBecause of that previous c\", \"ode, and as shown in the Visual Studio Explorer below, the only file needed\\nto define each specific \", \"business/BFF API Gateway is just a configuration.json file, because the four API\\nGateways are based \", \"on the same Docker image.\\n\\n4 &) ApiGateways\\n4 &) ApiGw-Base\\nb a] OcelotApiGw\\n4 &! Mobile.Bff.Marketi\", \"ng\\nagJ configuration.json <a\\n4 &! Mobile.Bff.shopping\\nb a] Mobile.Shopping.HttpAggregator\\nagJ config\", \"uration.json a\\n4 &! Web.Bff.Marketing\\na\\u00a7J configuration.json om\\n4 &! Web.Bff.Shopping\\nb a] Web.Shopp\", \"ing.HttpAggregator\\na\\u00a7J configuration.json\\n\\nFigure 6-34. The only file needed to define each API Gate\", \"way / BFF with Ocelot is a configuration file\\n\\nBy splitting the API Gateway into multiple API Gatewa\", \"ys, different development teams focusing on\\ndifferent subsets of microservices can manage their own \", \"API Gateways by using independent Ocelot\\nconfiguration files. Plus, at the same time they can reuse \", \"the same Ocelot Docker image.\\n\\nNow, if you run eShopOnContainers with the API Gateways (included by \", \"default in VS when opening\\neShopOnContainers-ServicesAndWebApps.sIn solution or if running \\u201cdocker-c\", \"ompose up\\u201d), the\\nfollowing sample routes will be performed.\\n\\nFor instance, when visiting the upstrea\", \"m URL\\nhttp://host.docker.internal:5202/api/v1/c/catalog/items/2/ served by the webshoppingapigw API\\n\", \"Gateway, you get the same result from the internal Downstream URL http://catalog-api/api/v1/2\\nwithin\", \" the Docker host, as in the following browser.\\n\\n<e > \\u00a9 @\\u00ae localhost:5202/api/v1/c/catalog/items/2 Ww\", \" y= L. \\\\@\\n\\n{\\\"id\\\":2,\\\"name\\\":\\\".NET Black & White Mug\\\", \\\"description\\\":\\\".NET Black & White\\nMug\\\", \\u201cprice\\\":\", \"8.50,\\\"pictureFileName\\\":\\\"2.png\\\",\\\"pictureUri\\\":\\\"http://localhost:5202/api/v1/c/catalog/items/2/pic/\\\",\\\"c\", \"atalogTypeId\\\":1,\\\"catalogType\\\":null, \\u201ccatalogBrand\\nId\\\":2,\\\"catalogBrand\\\":null, \\u201cavailableStock\\\":99, \\\"r\", \"estockThreshold\\\":@, \\\"maxStockThreshold\\\":@, \\u201conReorder\\\": false}\\n\\nFigure 6-35. Accessing a microservic\", \"e through a URL provided by the API Gateway\\n\\nBecause of testing or debugging reasons, if you wanted \", \"to directly access to the Catalog Docker\\ncontainer (only at the development environment) without pas\", \"sing through the API Gateway, since\\n\\u2018catalog-api\\u2019 is a DNS resolution internal to the Docker host (s\", \"ervice discovery handled by docker-\\ncompose service names), the only way to directly access the cont\", \"ainer is through the external port\\npublished in the docker-compose.override.yml, which is provided o\", \"nly for development tests, such as\\nhttp://host.docker.internal:5101/api/v1/Catalog/items/1 in the fo\", \"llowing browser.\\n\\n174 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications\\nB&B 2 localhost xi/+ iv \\u2014 Oo x\\n<e > \\u00a9 @ localhost:5101/api/v1/Catalog/items/2 w ys L\", \". \\\\@\\n\\n{\\\"id\\\":2,\\\"name\\\":\\\".NET Black & White Mug\\\", \\\"description\\\":\\\".NET Black & White\\nMug\\\", \\\"price\\\":8.50,\", \" \\\"pictureFileName\\\":\\\"2.png\\\",\\\"pictureUri\\\":\\\"http://localhost:5202/api/v1/c/catalog/items/2/pic/\\\",\\\"catal\", \"ogTypeId\\\":1,\\\"catalogType\\\":null, \\u201ccatalogBrand\\nId\\\":2,\\\"catalogBrand\\\":null, \\u201cavailableStock\\\":99, \\\"resto\", \"ckThreshold\\\":@, \\\"maxStockThreshold\\\":@, \\u201conReorder\\\": false}\\n\\nFigure 6-36. Direct access to a microser\", \"vice for testing purposes\\n\\nBut the application is configured so it accesses all the microservices th\", \"rough the API Gateways, not\\nthrough the direct port \\u201cshortcuts\\u201d.\\n\\nThe Gateway aggregation pattern in\", \" eshopOnContainers\\n\\nAs introduced previously, a flexible way to implement requests aggregation is wi\", \"th custom services, by\\ncode. You could also implement request aggregation with the Request Aggregati\", \"on feature in Ocelot,\\nbut it might not be as flexible as you need. Therefore, the selected way to im\", \"plement aggregation in\\neShopOnContainers is with an explicit ASP.NET Core Web API service for each a\", \"ggregator.\\n\\nAccording to that approach, the API Gateway composition diagram is in reality a bit more\", \" extended\\nwhen considering the aggregator services that are not shown in the simplified global archi\", \"tecture\\ndiagram shown previously.\\n\\nIn the following diagram, you can also see how the aggregator ser\", \"vices work with their related API\\nGateways.\\n\\n\\u2014\\u2014\\u2014\\u2014 \\u2014 EE\\n\\naa  -*\\n\\nWeb-Marketing\\n\\n|\\n| |\\n\\u00a9 MongoDB/ |\\n\\nT\", \"ypeScript/Angular |\\n\\n~~ LL  l\\n\\neShopOnContainers\\n(API Gateways / BFF and Aggregator-services details\", \")\\n| Client apps ee\\n| | ( Identity microservice (sts+users) \\u2018\\nor)\\n| eShop mobile app , CO we: a )\\nXam\", \"arin.Forms OEE EE ~ Re oanla ns mmiernears TT \\u2018 \\\\\\n| CH / API Ga teways / BFF \\\\ Catalog microservice \", \"-\\n| xPlat. OS: I \\\\ | () me ia So pevves _\\ndatabase ae]\\n\\\\ _ Cc RabbitMQ\\noo oO\\nMobile-Shopping ( Order\", \"ing microservice > a [Lb\\n__- Kel Pa\\nI Aggregator Kem. fg (5 Server c sy\\n| =F\\n7 \\\\ Ordering.Background\", \"Tasks Py NY\\n| Mobile-Marketing gegen eneeneeneenaeneeneeneennennel an) hed\\n] Basket microservice z \\u2014\", \"\\n=| Azure\\nKey \\u2014 y Redis cache D Service Bus\\n4 &\\n/\\na a Web-Shopping\\nl | ed N---------8----------\\nl HT\", \"ML Marketing microservice\\n| eShop SPA Web app | Aggregator\\n| \\u2018_\\nl\\nI\\n\\nFigure 6-37. eShopOnContainers \", \"architecture with aggregator services\\n\\nZooming in further, on the \\u201cShopping\\u201d business area in the fo\", \"llowing image, you can see that\\nchattiness between the client apps and the microservices is reduced \", \"when using the aggregator\\nservices in the API Gateways.\\n\\n175 CHAPTER 5 | Designing and Developing Mu\", \"lti-Container and Microservice-Based .NET Applications\\neShopOnContainers\\n\\n(API Gateways / BFF and Ag\", \"gregator-services zoom-in)\\n\\n/ API Gateways / BFF \\u2018\\n\\n| 7 \\\\ | \\u201cShopping\\u201d\\n\\nuM ae, 3. microservices\\nobil\", \"e-Shopping\\nrex Zo\\n\\n\\u2014o: \\u00a9\\n\\n!\\n\\na\\n\\n\\u2014\\n\\nMopne ewes Z> \\u2014_ C)\\nWeb Shope W774 SS\\n\\n_\\u2014-xen~\\n\\nAggregator\\n\\n{ \\\\\\n\\n\", \"Web-Marketing\\n\\nFigure 6-38. Zoom in vision of the Aggregator services\\n\\n\\u201cMarketing\\u201d\\nmicroservices\\n\\nYo\", \"u can notice how when the diagram shows the possible requests coming from the API Gateways it\\n\\ncan g\", \"et complex. On the other hand, when you use the aggregator pattern, you can see how the\\narrows in bl\", \"ue would simplify the communication from a client app perspective. This pattern not only\\n\\nhelps to r\", \"educe the chattiness and latency in the communication, it also improves the user experience\\nsignific\", \"antly for the remote apps (mobile and SPA apps).\\n\\nIn the case of the \\u201cMarketing\\u201d business area and m\", \"icroservices, it is a simple use case so there was no\\nneed to use aggregators, but it could also be \", \"possible, if needed.\\n\\nAuthentication and authorization in Ocelot API Gateways\\n\\nIn an Ocelot API Gate\", \"way, you can sit the authentication service, such as an ASP.NET Core Web API\\nservice using IdentityS\", \"erver providing the auth token, either out or inside the API Gateway.\\n\\nSince eShopOnContainers is us\", \"ing multiple API Gateways with boundaries based on BFF and business\\nareas, the Identity/Auth service\", \" is left out of the API Gateways, as highlighted in yellow in the\\n\\nfollowing diagram.\\n\\n176 CHAPTER 5\", \" | Designing and Developing Multi-Container and Microservice-Based .NET Applications\\nrr I | ] I I I \", \"I ee ee ee ee ee ee ee ee\\n| Client apps | Docker Host I\\nI al |\\n| . | database |\\neShop mobile app ]\\nl\", \" Xamarin.Forms | I Yo I\\nC# / cay Come\\nI xPlat. OS: | | ae = ]\\nl COS eo TTT mA 9 ge c RabbitMQ\\nAndroi\", \"d | Ts ed _\\\\_/_\\u2014 | a = ]\\n| Windows ] S by\\n| m\\nl | |O Ne =\\u2014_> SQL Serve c 5 (\\n| ] | ee Us ww ae oy = \", \"or\\nif se = -*\\nI ! ! Ordering.BackgroundTasks / a = F wy 7\\neShop traditional Web app l ] | 2555555555\", \" 5555555=5555======2 9 77) a l\\n1 I | P PP | 7D Service Bus\\n' Lo | & & i J | ASP.NET Core Mvc | 2 \\u2014 ]\", \"\\nLe hand hd l \\\\ wo | OT \\\\ i\\nHTML J\\neShop SPA Web app I | Kel\\u2014\\u2014 * CosmosDB | I\\nI \\u2014 . I | ; ia SQL Ser\", \"ver | D4} I\\n| Fes Kf I | - \\u201cLocations microservi {== --=-=-\\nwhy & I ocations microservice . | l\\n| =\\u2014\", \"\\u2014 = I \\u2018 Web-Marketing i. rex\\u2014-& + 5 Mongo08 | '\\n| TypeScript/Angular I SwLU a MN /\\n\\u2014~e eee ee a\\n\\nFig\", \"ure 6-39. Position of the Identity service in eshopOnContainers\\n\\nHowever, Ocelot also supports sitti\", \"ng the Identity/Auth microservice within the API Gateway\\n\\nboundary, as in this other diagram.\\n\\nClien\", \"t\\napps API-Gateway\\n\\nAuthentication in Ocelot API Gateway\\n\\nInternal microservices\\n\\nRequest token\\n\\n) |\", \" Identity microservice\\n\\nrey Microservice A\\nKy Microservice C\\nKey Microservice C\\n\\nFigure 6-40. Authen\", \"tication in Ocelot\\n\\nAs the previous diagram shows, when the Identity microservice is beneath the API\", \" gateway (AG): 1) AG\\nrequests an auth token from identity microservice, 2) The identity microservice\", \" returns token to AG, 3-\\n4) AG requests from microservices using the auth token. Because eShopOnCont\", \"ainers application has\\nsplit the API Gateway into multiple BFF (Backend for Frontend) and business a\", \"reas API Gateways,\\nanother option would have been to create an additional API Gateway for cross-cutt\", \"ing concerns. That\\nchoice would be fair in a more complex microservice based architecture with multi\", \"ple cross-cutting\\n\\nconcerns microservices. Since there\\u2019s only one cross-cutting concern in eshopOnCo\", \"ntainers, it was\\ndecided to just handle the security service out of the API Gateway realm, for simpl\", \"icity\\u2019s sake.\\n\\n177\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" Applications\\nIn any case, If the app is secured at the API Gateway level, the authentication module\", \" of the Ocelot\\nAPI Gateway is visited at first when trying to use any secured microservice. That red\", \"irects the HTTP\\nrequest to visit the Identity or auth microservice to get the access token so you ca\", \"n visit the protected\\nservices with the access _token.\\n\\nThe way you secure with authentication any s\", \"ervice at the API Gateway level is by setting the\\nAuthenticationProviderKey in its related settings \", \"at the configuration.json.\\n\\n\\u201cDownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\",\\n\\u201cDownstreamSche\", \"me\\\": \\\"http\\\",\\n\\u201cDownstreamHostAndPorts\\\": [\\n\\n\\\"Host\\\": \\\"basket-api\\\",\\n\\\"Port\\\": 8\\n}\\n\\n],\\n\\u201cUpstreamPathTemplat\", \"e\\\": \\\"/api/{version}/b/{everything}\\\",\\n\\n\\u201c\\\"UpstreamHttpMethod\\\": [],\\n\\u201c\\\"AuthenticationOptions\\\": {\\n\\u201cAuthen\", \"ticationProviderKkey\\\": \\\"IdentityApikey\\\",\\n\\\"AllowedScopes\\\": [ ]\\n}\\n}\\n\\nWhen Ocelot runs, it will look at\", \" the ReRoutes AuthenticationOptions.AuthenticationProviderKey and\\ncheck that there is an Authenticat\", \"ion Provider registered with the given key. If there isn\\u2019t, then Ocelot\\nwill not start up. If there \", \"is, then the ReRoute will use that provider when it executes.\\n\\nBecause the Ocelot WebHost is configu\", \"red with the authenticationProviderKey = \\\"IdentityApiKey\\\",\\nthat will require authentication whenever\", \" that service has any requests without any auth token.\\n\\nnamespace OcelotApiGw\\n\\n{\\n\\npublic class Start\", \"up\\n{\\nprivate readonly IConfiguration cfg;\\npublic Startup(IConfiguration configuration) => _cfg = con\", \"figuration;\\n\\npublic void ConfigureServices(IServiceCollection services)\\n\\n{\\nvar identityUrl = _cfg.Ge\", \"tValue<string>(\\\"IdentityUr1\\\") ;\\nvar authenticationProviderKkey = \\\"IdentityApikey\\\" ;\\n//\\n\\nservices.Add\", \"Authentication()\\n.AddjJwtBearer (authenticationProviderKkey, x =>\\n{\\nx.Authority = identityUr1;\\nx.Req\", \"uireHttpsMetadata = false;\\nx.TokenValidationParameters = new\\nMicrosoft. IdentityModel.Tokens.TokenVa\", \"lidationParameters()\\n{\\nValidAudiences = new[]| { \\\"orders\\\", \\\"basket\\\", \\\"locations\\\",\\n\\u201cmarketing\\u201d, \\\"mobi\", \"leshoppingagg\\\", \\\"\\u201cwebshoppingagg\\\" }\\n\\u2019\\n})3\\nere\\n\\n178 CHAPTER 5 | Designing and Developing Multi-Contai\", \"ner and Microservice-Based .NET Applications\\n}\\n\\nThen, you also need to set authorization with the [A\", \"uthorize] attribute on any resource to be accessed\\nlike the microservices, such as in the following \", \"Basket microservice controller.\\n\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.Controlle\", \"rs\\n\\nt\\n\\n[Route(\\\"api/v1/[controller]\\\") |\\n[Authorize |\\npublic class BasketController : Controller\\n\\nt\\n}\\n\", \"\\nHoce\\n\\nThe ValidAudiences such as \\u201cbasket\\u201d are correlated with the audience defined in each microser\", \"vice\\nwith AddJwtBearer() at the ConfigureServices() of the Startup class, such as in the code below.\", \"\\n\\n// prevent from mapping \\\"sub\\\" claim to nameidentifier.\\nJwtSecurityTokenHandler .DefaultInboundClai\", \"mTypeMap.Clear() ;\\n\\nvar identityUrl = Configuration.GetValue<string>(\\\"IdentityUr1\\\") ;\\n\\nservices.AddA\", \"uthentication(options =>\\n\\n{\\noptions .DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationSch\", \"eme;\\noptions.DefaultChallengeScheme = JwtBearerDefaults .AuthenticationScheme;\\n\\n}).AddJwtBearer(opti\", \"ons =>\\n\\n{\\noptions.Authority = identityUr1;\\noptions.RequireHttpsMetadata = false;\\noptions.Audience = \", \"\\\"basket\\\";\\n\\n})5\\n\\nIf you try to access any secured microservice, like the Basket microservice with a R\", \"eRoute URL based\\non the API Gateway like http://host.docker.internal:5202/api/v1/b/basket/1, then yo\", \"u'll get a 401\\nUnauthorized unless you provide a valid token. On the other hand, if a ReRoute URL Is\", \" authenticated,\\nOcelot will invoke whatever downstream scheme is associated with it (the internal mi\", \"croservice URL).\\n\\nAuthorization at Ocelot\\u2019s ReRoutes tier. Ocelot supports claims-based authorizatio\", \"n evaluated after\\nthe authentication. You set the authorization at a route level by adding the follo\", \"wing lines to the\\nReRoute configuration.\\n\\n\\\"RouteClaimsRequirement\\\": {\\n\\\"UserType\\\": \\\"employee\\\"\\n\\n}\\n\\nIn \", \"that example, when the authorization middleware is called, Ocelot will find if the user has the clai\", \"m\\ntype \\u2018UserType\\u2019 in the token and if the value of that claim is \\u2018employee\\u2019. If it isn\\u2019t, then the u\", \"ser will not\\nbe authorized and the response will be 403 forbidden.\\n\\n179 CHAPTER 5 | Designing and De\", \"veloping Multi-Container and Microservice-Based .NET Applications\\nUsing Kubernetes Ingress plus Ocel\", \"ot API Gateways\\n\\nWhen using Kubernetes (like in an Azure Kubernetes Service cluster), you usually un\", \"ify all the HTTP\\nrequests through the Kubernetes Ingress tier based on Nginx.\\n\\nIn Kubernetes, if you\", \" don\\u2019t use any ingress approach, then your services and pods have IPs only\\nroutable by the cluster n\", \"etwork.\\n\\nBut if you use an ingress approach, you'll have a middle tier between the Internet and your\", \" services\\n(including your API Gateways), acting as a reverse proxy.\\n\\nAs a definition, an Ingress is \", \"a collection of rules that allow inbound connections to reach the cluster\\nservices. An ingress is co\", \"nfigured to provide services externally reachable URLs, load balance traffic,\\nSSL termination and mo\", \"re. Users request ingress by POSTing the Ingress resource to the API server.\\n\\nIn eShopOnContainers, \", \"when developing locally and using just your development machine as the\\nDocker host, you are not usin\", \"g any ingress but only the multiple API Gateways.\\n\\nHowever, when targeting a \\u201cproduction\\u201d environmen\", \"t based on Kubernetes, eshopOnContainers is\\nusing an ingress in front of the API gateways. That way,\", \" the clients still call the same base URL but the\\nrequests are routed to multiple AP] Gateways or BF\", \"F.\\n\\nAPI Gateways are front-ends or facades surfacing only the services but not the web applications \", \"that\\nare usually out of their scope. In addition, the AP] Gateways might hide certain internal micro\", \"services.\\n\\nThe ingress, however, is just redirecting HTTP requests but not trying to hide any micros\", \"ervice or web\\napp.\\n\\nHaving an ingress Nginx tier in Kubernetes in front of the web applications plus\", \" the several Ocelot API\\nGateways / BFF is the ideal architecture, as shown in the following diagram.\", \"\\n\\neShopOnContainers\\n(Deployment into Kubernetes environment)\\n\\nI\\nI \\u00bb Azure Kubernetes Service (AKS) I\", \"dentity microservice (st5+users) |\\nI API Gateways / BFF - Catalog microservice\\nene MB\\ndat vo\\nc Rabbi\", \"tMQ ]\\n| $F Sree erst ttt s tts s sss =- ox\\nl Mobile-Shoppin: ( Ordering microservice a\\npping > on \\\"\\n\", \"I Aggregator > y\\u2014 ae EVE 4 5 \\u00a9 .\\n=\\u2014 = i ing BackgroundTasks naiR Hut 5 2\\nrm ie | Mobile-Marketing ! \", \"= eS el CO I\\n' . ' SS WaebAa MVC Basket microservice |S 2 \\u2014 |\\neShop WebApp > = cone Bue\\n\\u2014_\\u2014\\u2014_\\u2014_\\u2014 a a\", \" I ; Web-Shopp' 9 oe & a |\\n| ea sree ___,ie | Marketing microservice \\\\ / ;\\nAggregato tae, MongoDs / \", \"|\\n\\u2014_ oo '\\nt Locations microservice ' !\\n]\\nWeb-Marketing } | tas MongoDB H\\n| |\\n\\nFigure 6-47. The ingre\", \"ss tier in eshopOnContainers when deployed into Kubernetes\\n\\nA Kubernetes Ingress acts as a reverse p\", \"roxy for all traffic to the app, including the web applications,\\nthat are out of the Api gateway sco\", \"pe. When you deploy eShopOnContainers into Kubernetes, it\\n\\n180 CHAPTER 5 | Designing and Developing \", \"Multi-Container and Microservice-Based .NET Applications\\nexposes just a few services or endpoints vi\", \"a ingress, basically the following list of postfixes on the\\n\\nURLs:\\n\\n/ for the client SPA web applica\", \"tion\\n\\n/webmvc for the client MVC web application\\n\\n/webstatus for the client web app showing the stat\", \"us/healthchecks\\n/webshoppingapigw for the web BFF and shopping business processes\\n/webmarketingapigw\", \" for the web BFF and marketing business processes\\n/mobileshoppingapigw for the mobile BFF and shoppi\", \"ng business processes\\n\\n/mobilemarketingapigw for the mobile BFF and marketing business processes\\n\\nWh\", \"en deploying to Kubernetes, each Ocelot API Gateway is using a different \\u201cconfiguration.json\\u201d file\\nf\", \"or each pod running the API Gateways. Those \\u201cconfiguration,son\\u201d files are provided by mounting\\n(orig\", \"inally with the deploy.ps1 script) a volume created based on a Kubernetes config map named\\n\\u2018ocelot\\u2019.\", \" Each container mounts its related configuration file in the container\\u2019s folder named\\n/app/configura\", \"tion.\\n\\nIn the source code files of eshopOnContainers, the original \\u201cconfiguration.json\\u201d files can be\", \" found\\nwithin the k8s/ocelot/ folder. There's one file for each BFF/APIGateway.\\n\\nAdditional cross-cu\", \"tting features in an Ocelot API Gateway\\n\\nThere are other important features to research and use, whe\", \"n using an Ocelot API Gateway, described\\nin the following links.\\n\\n181\\n\\nService discovery in the clie\", \"nt side integrating Ocelot with Consul or Eureka\\n\\nhttps://ocelot.readthedocs.io/en/latest/features/s\", \"ervicediscovery.html\\n\\nCaching at the API Gateway tier\\nhttps://ocelot.readthedocs.io/en/latest/featur\", \"es/caching.html\\n\\nLogging at the API Gateway tier\\nhttps://ocelot.readthedocs.io/en/latest/features/lo\", \"gging.html\\n\\nQuality of Service (Retries and Circuit breakers) at the API Gateway tier\\nhttps://ocelot\", \".readthedocs.io/en/latest/features/qualityofservice.html\\n\\nRate limiting\\n\\nhttps://ocelot.readthedocs.\", \"io/en/latest/features/ratelimiting.html\\n\\nSwagger for Ocelot\\n\\nhttps://github.com/Burgyn/MMLib.Swagger\", \"ForOcelot\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicat\", \"ions\\nCHAPTER 6\\n\\nTackle Business\\nComplexity in a\\nMicroservice with DDD\\nand CQRS Patterns\\n\\nDesign a do\", \"main model for each microservice or Bounded Context that reflects understanding of the\\nbusiness doma\", \"in.\\n\\nThis section focuses on more advanced microservices that you implement when you need to tackle\\n\", \"complex subsystems, or microservices derived from the knowledge of domain experts with ever-\\nchangin\", \"g business rules. The architecture patterns used in this section are based on domain-driven\\ndesign (\", \"DDD) and Command and Query Responsibility Segregation (CQRS) approaches, as illustrated\\nin Figure 7-\", \"1.\\n\\n182 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nExternal\", \" architecture Internal architecture\\noer application per microservice\\n\\n| Back end I\\nOe | \\u201cMicroservic\", \"e 1\\n{ Clientapps ; a\\n| Mobile Le a ;\\napp ( API Gateway | if Microservice 2 4\\nSPA \\u2014 { Wo } \\\\vcontaner\", \"\\n\\u201c \\u2014 / | | Web API 1\\na.\\neee NNN\\n* External microservice patterns Internal DDD patterns in addition t\", \"o\\n\\u00a2 API Gateway SOLID principles and Dependency\\n* Resilient communication Injection\\n* Pub/Sub and ev\", \"ent driven\\n\\nFigure 7-7. External microservice architecture versus internal architecture patterns for\", \" each microservice\\n\\nHowever, most of the techniques for data driven microservices, such as how to im\", \"plement an ASP.NET\\nCore Web API service or how to expose Swagger metadata with Swashbuckle or NSwag,\", \" are also\\napplicable to the more advanced microservices implemented internally with DDD patterns. Th\", \"is\\nsection Is an extension of the previous sections, because most of the practices explained earlier\", \" also\\napply here or for any kind of microservice.\\n\\nThis section first provides details on the simpli\", \"fied CQRS patterns used in the eshopOnContainers\\nreference application. Later, you will get an overv\", \"iew of the DDD techniques that enable you to find\\ncommon patterns that you can reuse in your applica\", \"tions.\\n\\nDDD is a large topic with a rich set of resources for learning. You can start with books lik\", \"e Domain-\\nDriven Design by Eric Evans and additional materials from Vaughn Vernon, Jimmy Nilsson, Gr\", \"eg\\nYoung, Udi Dahan, Jimmy Bogard, and many other DDD/CQRS experts. But most of all you need to try\\n\", \"to learn how to apply DDD techniques from the conversations, whiteboarding, and domain modeling\\nsess\", \"ions with the experts in your concrete business domain.\\n\\nAdditional resources\\n\\nDDD (Domain-Driven De\", \"sign)\\n\\n. Eric Evans. Domain Language\\n\\nhttps://domainlanguage.com/\\n\\n\\u00b0 Martin Fowler. Domain-Driven De\", \"sign\\n\\nhttps://martinfowler.com/tags/domain%20driven%20design.htm!\\n\\n. Jimmy Bogard. Strengthening you\", \"r domain: a primer\\nhttps://lostechies.com/jimmybogard/2010/02/04/strengthening-your-domain-a-primer\\n\", \"\\n183 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nDDD books\\n\\n\", \"\\u00b0 Eric Evans. Domain-Driven Design: Tackling Complexity in the Heart of Software\\nhttps://www.amazon.\", \"com/Domain-Driven-Design-Tackling-Complexity-\\n\\nSoftware/dp/0321125215/\\n\\n\\u00b0 Eric Evans. Domain-Driven \", \"Design Reference: Definitions and Pattern Summaries\\nhttos://www.amazon.com/Domain-Driven-Design-Refe\", \"rence-Definitions-2014-09-\\n\\n22/dp/BO1N8YB4ZO0/\\n\\n\\u00b0 Vaughn Vernon. Implementing Domain-Driven Design\\nh\", \"ttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\n\\nVernon/dp/0321834577/\\n\\n\\u00b0 Vaughn Ver\", \"non. Domain-Driven Design Distilled\\n\\n\\u00b0 Jimmy Nilsson. Applying Domain-Driven Design and Patterns\\nhtt\", \"ps://www.amazon.com/Applying-Domain-Driven-Design-Patterns-\\n\\nExamples/dp/0321268202/\\n\\n. Cesar de la \", \"Torre. N-Layered Domain-Oriented Architecture Guide with .NET\\nhttps://www.amazon.com/N-Layered-Domai\", \"n-Oriented-Architecture-Guide-\\n\\nNET/dp/8493903612/\\n\\n\\u00b0 Abel Avram and Floyd Marinescu. Domain-Driven \", \"Design Quickly\\nhttps://www.amazon.com/Domain-Driven-Design-Quickly-Abel-Avram/dp/1411609255\\n\\n\\u00b0 Scott\", \" Millett, Nick Tune - Patterns, Principles, and Practices of Domain-Driven Design\\n\\nhttps://www.wiley\", \".com/Patterns%2C+Principles%2C+and+Practices+of+Domain+Driven+Des\\nign-p-9781118714706\\n\\nDDD training\\n\", \"\\n\\u00b0 Julie Lerman and Steve Smith. Domain-Driven Design Fundamentals\\n\\nhttps://www.pluralsight.com/cour\", \"ses/fundamentals-domain-driven-design\\n\\nApply simplitied CQRS and DDD patterns in a\\nmicroservice\\n\\nCQR\", \"S is an architectural pattern that separates the models for reading and writing data. The related\\n\\nt\", \"erm Command Query Separation (CQS) was originally defined by Bertrand Meyer in his book Object-\\nOrie\", \"nted Software Construction. The basic idea is that you can divide a system's operations into two\\n\\nsh\", \"arply separated categories:\\n\\n. Queries. These queries return a result and don\\u2019t change the state of \", \"the system, and they're\\nfree of side effects.\\n\\n\\u00b0 Commands. These commands change the state of a syst\", \"em.\\n\\n184 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nCQS is \", \"a simple concept: it is about methods within the same object being either queries or\\ncommands. Each \", \"method either returns state or mutates state, but not both. Even a single repository\\npattern object \", \"can comply with CQS. CQS can be considered a foundational principle for CQRS.\\n\\nCommand and Query Res\", \"ponsibility Segregation (CQRS) was introduced by Greg Young and strongly\\npromoted by Udi Dahan and o\", \"thers. It's based on the CQS principle, although it's more detailed. It can\\n\\nbe considered a pattern\", \" based on commands and events plus optionally on asynchronous messages.\\nIn many cases, CQRS is relat\", \"ed to more advanced scenarios, like having a different physical database\\nfor reads (queries) than fo\", \"r writes (updates). Moreover, a more evolved CQRS system might\\nimplement Event-Sourcing (ES) for you\", \"r updates database, so you would only store events in the\\ndomain model instead of storing the curren\", \"t-state data. However, this approach is not used in this\\nguide. This guide uses the simplest CQRS ap\", \"proach, which consists of just separating the queries from\\nthe commands.\\n\\nThe separation aspect of C\", \"QRS is achieved by grouping query operations in one layer and commands\\nin another layer. Each layer \", \"has its own data model (note that we say model, not necessarily a different\\ndatabase) and is built u\", \"sing its own combination of patterns and technologies. More importantly, the\\ntwo layers can be withi\", \"n the same tier or microservice, as in the example (ordering microservice) used\\nfor this guide. Or t\", \"hey could be implemented on different microservices or processes so they can be\\noptimized and scaled\", \" out separately without affecting one another.\\n\\nCQRS means having two objects for a read/write opera\", \"tion where in other contexts there\\u2019s one. There\\nare reasons to have a denormalized reads database, w\", \"hich you can learn about in more advanced\\nCQRS literature. But we aren't using that approach here, w\", \"here the goal is to have more flexibility in\\nthe queries instead of limiting the queries with constr\", \"aints from DDD patterns like aggregates.\\n\\nAn example of this kind of service is the ordering microse\", \"rvice from the eShopOnContainers reference\\napplication. This service implements a microservice based\", \" on a simplified CQRS approach. It uses a\\nsingle data source or database, but two logical models plu\", \"s DDD patterns for the transactional\\ndomain, as shown in Figure 7-2.\\n\\n185 CHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns\\nSimplified CQRS and DDD microservice\\nHigh \", \"level design\\n\\n; ; ; | ; Pe ; Pe Pe ; Pe ; ; az ; Pe ; ==\\nDocker Host\\n\\nee\\n\\n- ~\\n\\nra Logical \\u201cOrdering\\u201d\", \" Microservice \\\\\\n\\n\\u201cOrdering\\u201d API\\n\\nContainer\\n\\nExternal IP Internal IP\\n\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\nand Port and Port\", \" \\u201cOrdering\\u201d !\\n|\\n|\\n|\\n|\\n|\\n|\\n\\n\\u2014\\u2014_\\u2014 \\u2014\\n\\nDatabase\\nCommands &\\nDomain-Model\\n\\n7\\n1 SA ~~ le a\\n\\nSQL Server\\n\\n=\\u2014\\u2014\", \" \\u2014\\n\\nmeee eee eee eee eee eee i ce\\n\\nFigure 7-2. Simplified CQRS- and DDD-based microservice\\n\\nThe Logi\", \"cal \\u201cOrdering\\u201d Microservice includes its Ordering database, which can be, but doesn't have to\\nbe, th\", \"e same Docker host. Having the database in the same Docker host is good for development, but\\nnot for\", \" production.\\n\\nThe application layer can be the Web API itself. The important design aspect here is t\", \"hat the\\nmicroservice has split the queries and ViewModels (data models especially created for the cl\", \"ient\\napplications) from the commands, domain model, and transactions following the CQRS pattern. Thi\", \"s\\napproach keeps the queries independent from restrictions and constraints coming from DDD patterns\\n\", \"that only make sense for transactions and updates, as explained in later sections.\\n\\nAdditional resou\", \"rces\\n\\n\\u00b0 Greg Young. Versioning in an Event Sourced System (Free to read online e-book)\\n\\nhttps://lean\", \"pub.com/esversioning/read\\n\\nApply CQRS and CQS approaches in a DDD\\nmicroservice In eShopOnContainers\\n\", \"\\nThe design of the ordering microservice at the eshopOnContainers reference application is based on\\n\", \"CQRS principles. However, it uses the simplest approach, which is just separating the queries from t\", \"he\\ncommands and using the same database for both actions.\\n\\nThe essence of those patterns, and the im\", \"portant point here, is that queries are idempotent: no matter\\nhow many times you query a system, the\", \" state of that system won't change. In other words, queries\\nare side-effect free.\\n\\n186 CHAPTER 6 | T\", \"ackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nTherefore, you could use a di\", \"fferent \\u201creads\\u201d data model than the transactional logic \\u201cwrites\\u201d domain\\nmodel, even though the order\", \"ing microservices are using the same database. Hence, this is a\\nsimplified CQRS approach.\\n\\nOn the ot\", \"her hand, commands, which trigger transactions and data updates, change state in the\\nsystem. With co\", \"mmands, you need to be careful when dealing with complexity and ever-changing\\nbusiness rules. This i\", \"s where you want to apply DDD techniques to have a better modeled system.\\n\\nThe DDD patterns presente\", \"d in this guide should not be applied universally. They introduce\\nconstraints on your design. Those \", \"constraints provide benefits such as higher quality over time,\\nespecially in commands and other code\", \" that modifies system state. However, those constraints add\\ncomplexity with fewer benefits for readi\", \"ng and querying data.\\n\\nOne such pattern is the Aggregate pattern, which we examine more in later sec\", \"tions. Briefly, in the\\nAggregate pattern, you treat many domain objects as a single unit as a result\", \" of their relationship in\\nthe domain. You might not always gain advantages from this pattern in quer\", \"ies; it can increase the\\ncomplexity of query logic. For read-only queries, you do not get the advant\", \"ages of treating multiple\\nobjects as a single Aggregate. You only get the complexity.\\n\\nAs shown in F\", \"igure 7-2 in the previous section, this guide suggests using DDD patterns only in the\\ntransactional/\", \"updates area of your microservice (that is, as triggered by commands). Queries can\\nfollow a simpler \", \"approach and should be separated from commands, following a CQRS approach.\\n\\nFor implementing the \\u201cqu\", \"eries side\\u201d, you can choose between many approaches, from your full-blown\\nORM like EF Core, AutoMapp\", \"er projections, stored procedures, views, materialized views or a micro\\nORM.\\n\\nIn this guide and in e\", \"ShopOnContainers (specifically the ordering microservice) we chose to\\nimplement straight queries usi\", \"ng a micro ORM like Dapper. This guide lets you implement any query\\nbased on SQL statements to get t\", \"he best performance, thanks to a light framework with little\\noverhead.\\n\\nWhen you use this approach, \", \"any updates to your model that impact how entities are persisted to a\\nSQL database also need separat\", \"e updates to SQL queries used by Dapper or any other separate (non-\\nEF) approaches to querying.\\n\\nCQR\", \"S and DDD patterns are not top-level architectures\\n\\nIt's important to understand that CQRS and most \", \"DDD patterns (like DDD layers or a domain model\\nwith aggregates) are not architectural styles, but o\", \"nly architecture patterns. Microservices, SOA, and\\nevent-driven architecture (EDA) are examples of a\", \"rchitectural styles. They describe a system of many\\ncomponents, such as many microservices. CQRS and\", \" DDD patterns describe something inside a single\\nsystem or component; in this case, something inside\", \" a microservice.\\n\\nDifferent Bounded Contexts (BCs) will employ different patterns. They have differe\", \"nt responsibilities,\\nand that leads to different solutions. It is worth emphasizing that forcing the\", \" same pattern everywhere\\nleads to failure. Do not use CQRS and DDD patterns everywhere. Many subsyst\", \"ems, BCs, or\\nmicroservices are simpler and can be implemented more easily using simple CRUD services\", \" or using\\nanother approach.\\n\\n187 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD a\", \"nd CQRS Patterns\\nThere is only one application architecture: the architecture of the system or end-t\", \"o-end application\\nyou are designing (for example, the microservices architecture). However, the desi\", \"gn of each Bounded\\nContext or microservice within that application reflects its own tradeoffs and in\", \"ternal design decisions\\nat an architecture patterns level. Do not try to apply the same architectura\", \"l patterns as CQRS or DDD\\neverywhere.\\n\\nAdditional resources\\n\\n\\u00b0 Martin Fowler. CQRS\\nhttps://martinfow\", \"ler.com/bliki/CQRS.html\\n\\n\\u00b0 Greg Young. CQRS Documents\\nhttps://cqrs.files.wordpress.com/2010/11/cqrs_\", \" documents.pdf\\n\\n\\u00b0 Udi Dahan. Clarified CQRS\\nhttps://udidahan.com/2009/12/09/clarified-cars/\\n\\nImpleme\", \"nt reads/queries in a CQRS microservice\\n\\nFor reads/queries, the ordering microservice from the eShop\", \"OnContainers reference application\\nimplements the queries independently from the DDD model and trans\", \"actional area. This\\nimplementation was done primarily because the demands for queries and for transa\", \"ctions are\\ndrastically different. Writes execute transactions that must be compliant with the domain\", \" logic.\\nQueries, on the other hand, are idempotent and can be segregated from the domain rules.\\n\\nThe\", \" approach is simple, as shown in Figure 7-3. The API interface is implemented by the Web API\\ncontrol\", \"lers using any infrastructure, such as a micro Object Relational Mapper (ORM) like Dapper, and\\nretur\", \"ning dynamic ViewModels depending on the needs of the UI applications.\\n\\nHigh level \\u201cQueries-side\\u201d in\", \" a simplified CQRS\\n\\nDynamic\\nQuery\\nQuery ViewModels\\n\\nparams\\n\\nResults\\n[=] Infrastructure Cc >\\n\\n(MicroO\", \"RM or\\nEntity Framework)\\n\\nDatabase\\n\\nFigure 7-3. The simplest approach for queries in a CQRS microserv\", \"ice\\n\\nThe simplest approach for the queries-side in a simplified CQRS approach can be implemented by\\n\", \"querying the database with a Micro-ORM like Dapper, returning dynamic ViewModels. The query\\n\\n188 CHA\", \"PTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\ndefinitions query t\", \"he database and return a dynamic ViewModel built on the fly for each query. Since\\nthe queries are id\", \"empotent, they won't change the data no matter how many times you run a query.\\nTherefore, you don't \", \"need to be restricted by any DDD pattern used in the transactional side, like\\naggregates and other p\", \"atterns, and that is why queries are separated from the transactional area. You\\nquery the database f\", \"or the data that the Ul needs and return a dynamic ViewModel that does not\\nneed to be statically def\", \"ined anywhere (no classes for the ViewModels) except in the SQL statements\\nthemselves.\\n\\nSince this a\", \"pproach is simple, the code required for the queries side (such as code using a micro ORM\\nlike Dappe\", \"r) can be implemented within the same Web API project. Figure 7-4 shows this approach.\\nThe queries a\", \"re defined in the Ordering.API microservice project within the eshopOnContainers\\nsolution.\\n\\n4 & Orde\", \"ring\\n4 8%) Ordering.APl\\n& Connected Services\\nb \\u201ca Dependencies\\n> af Properties\\n4G Application\\n> @\\u00ae B\", \"ehaviors\\n> &\\u00ae) Commands\\n> &@\\u00ae DomainEventHandlers\\n> &\\u00a9 IntegrationEvents\\nb al Models\\n4 yal] Queries\\n\", \"\\nb aC\\\" lOrderQueries.cs\\nb aC* OrderQueries.cs\\n\\nFigure 7-4. Queries in the Ordering microservice in e\", \"shopOnContainers\\n\\nUse ViewModels specifically made for client apps, independent from\\ndomain model co\", \"nstraints\\n\\nSince the queries are performed to obtain the data needed by the client applications, the\", \" returned\\ntype can be specifically made for the clients, based on the data returned by the queries. \", \"These models,\\nor Data Transfer Objects (DTOs), are called ViewModels.\\n\\nThe returned data (ViewModel)\", \" can be the result of joining data from multiple entities or tables in the\\ndatabase, or even across \", \"multiple aggregates defined in the domain model for the transactional area.\\nIn this case, because yo\", \"u are creating queries independent of the domain model, the aggregates\\nboundaries and constraints ar\", \"e ignored and you're free to query any table and column you might\\nneed. This approach provides great\", \" flexibility and productivity for the developers creating or updating\\nthe queries.\\n\\nThe ViewModels c\", \"an be static types defined in classes (as is implemented in the ordering\\nmicroservice). Or they can \", \"be created dynamically based on the queries performed, which is agile for\\ndevelopers.\\n\\nUse Dapper as\", \" a micro ORM to perform queries\\n\\nYou can use any micro ORM, Entity Framework Core, or even plain ADO\", \".NET for querying. In the\\nsample application, Dapper was selected for the ordering microservice in e\", \"shopOnContainers as a\\ngood example of a popular micro ORM. It can run plain SQL queries with great p\", \"erformance, because\\nit's a light framework. Using Dapper, you can write a SQL query that can access \", \"and join multiple\\ntables.\\n\\n189 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and\", \" CQRS Patterns\\nDapper is an open-source project (original created by Sam Saffron), and is part of th\", \"e building blocks\\nused in Stack Overflow. To use Dapper, you just need to install it through the Dap\", \"per NuGet package,\\nas shown in the following figure:\\n\\n@,\\n\\nDapper by Sam Saffron,Marc Gravell, Nick C\", \"raver \\u00a9 v1.50.5\\nA high performance Micro-ORM supporting SQL Server, MySQL, Sqlite, SqICE, Firebird e\", \"tc..\\n\\nYou also need to add a using directive so your code has access to the Dapper extension methods\", \".\\n\\nWhen you use Dapper in your code, you directly use the SgqlConnection class available in the\\nMicr\", \"osoft.Data.SqiClient namespace. Through the QueryAsync method and other extension methods\\nthat exten\", \"d the SqlConnection class, you can run queries in a straightforward and performant way.\\n\\nDynamic ver\", \"sus static ViewModels\\n\\nWhen returning ViewModels from the server-side to client apps, you can think \", \"about those\\nViewModels as DTOs (Data Transfer Objects) that can be different to the internal domain \", \"entities of\\nyour entity model because the ViewModels hold the data the way the client app needs. The\", \"refore, in\\nmany cases, you can aggregate data coming from multiple domain entities and compose the\\nV\", \"iewModels precisely according to how the client app needs that data.\\n\\nThose ViewModels or DTOs can b\", \"e defined explicitly (as data holder classes), like the OrderSummary\\nclass shown in a later code sni\", \"ppet. Or, you could just return dynamic ViewModels or dynamic DTOs\\nbased on the attributes returned \", \"by your queries as a dynamic type.\\n\\nViewModel as dynamic type\\n\\nAs shown in the following code, a Vie\", \"wModel can be directly returned by the queries by just returning\\na dynamic type that internally is b\", \"ased on the attributes returned by a query. That means that the\\nsubset of attributes to be returned \", \"is based on the query itself. Therefore, if you add a new column to\\nthe query or join, that data is \", \"dynamically added to the returned ViewModel.\\n\\nusing Dapper;\\n\\nusing Microsoft.Extensions.Configuratio\", \"n;\\nusing System.Data.SqlClient;\\n\\nusing System. Threading.Tasks;\\n\\nusing System.Dynamic;\\n\\nusing System\", \".Collections.Generic;\\n\\npublic class OrderQueries : IOrderQueries\\n\\n{\\n\\npublic async Task<IEnumerable<d\", \"ynamic>> GetOrdersAsync()\\n\\n{\\n\\nuSing (var connection = new SqlConnection(_connectionString) )\\n{\\nconne\", \"ction. Open() ;\\nreturn await connection. QueryAsync<dynamic>(\\n@\\\"SELECT o.[Id] as ordernumber,\\no.[Ord\", \"erDate] as [date]|,os.[Name] as [status],\\nSUM(oi.units*oi.unitprice) as total\\nFROM [ordering].[Order\", \"s] o\\nLEFT JOIN[ordering].[orderitems] oi ON o.Id = oi.orderid\\nLEFT JOIN[ordering].[orderstatus] os o\", \"n o.OrderStatusId = os.Id\\n\\n190 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and\", \" CQRS Patterns\\nGROUP BY o.[Id], o.[OrderDate], os.[Name]\\\");\\n\\nThe important point is that by using a \", \"dynamic type, the returned collection of data is dynamically\\nassembled as the ViewModel.\\n\\nPros: This\", \" approach reduces the need to modify static ViewModel classes whenever you update the\\nSQL sentence o\", \"f a query, making this design approach agile when coding, straightforward, and quick\\nto evolve in re\", \"gard to future changes.\\n\\nCons: In the long term, dynamic types can negatively impact the clarity and\", \" the compatibility of a\\nservice with client apps. In addition, middleware software like Swashbuckle \", \"cannot provide the same\\nlevel of documentation on returned types if using dynamic types.\\n\\nViewModel \", \"as predefined DTO classes\\n\\nPros: Having static, predefined ViewModel classes, like \\u201ccontracts\\u201d based\", \" on explicit DTO classes, is\\ndefinitely better for public APIs but also for long-term microservices,\", \" even if they are only used by the\\nsame application.\\n\\nIf you want to specify response types for Swag\", \"ger, you need to use explicit DTO classes as the return\\ntype. Therefore, predefined DTO classes allo\", \"w you to offer richer information from Swagger. That\\nimproves the API documentation and compatibilit\", \"y when consuming an API.\\n\\nCons: As mentioned earlier, when updating the code, it takes some more ste\", \"ps to update the DTO\\nclasses.\\n\\nTip based on our experience: In the queries implemented at the Orderi\", \"ng microservice in\\neShopOnContainers, we started developing by using dynamic ViewModels as it was st\", \"raightforward\\nand agile on the early development stages. But, once the development was stabilized, w\", \"e chose to\\nrefactor the APIs and use static or pre-defined DTOs for the ViewModels, because it is cl\", \"earer for the\\nmicroservice\\u2019s consumers to know explicit DTO types, used as \\u201ccontracts\\u201d.\\n\\nIn the foll\", \"owing example, you can see how the query is returning data by using an explicit ViewModel\\nDTO class:\", \" the OrderSummary class.\\n\\nusing Dapper;\\n\\nusing Microsoft.Extensions.Configuration;\\nusing System.Data\", \".SqlClient;\\n\\nusing System. Threading.Tasks;\\n\\nusing System.Dynamic;\\n\\nusing System.Collections.Generic\", \";\\n\\npublic class OrderQueries : IOrderQueries\\n\\n{\\n\\npublic async Task<IEnumerable<OrderSummary>> GetOrd\", \"ersAsync()\\n\\nuSing (var connection = new SqlConnection(_connectionString) )\\n{\\nconnection. Open() ;\\nre\", \"turn await connection. QueryAsync<OrderSummary> (\\n@\\\"SELECT o.[Id] as ordernumber,\\no.[OrderDate] as [\", \"date],os.[Name] as [status],\\n\\n191 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD \", \"and CQRS Patterns\\nSUM(oi.units*oi.unitprice) as total\\n\\nFROM [ordering].[Orders] o\\n\\nLEFT JOIN[orderin\", \"g]|.[orderitems] oi ON o.Id = oi.orderid\\n\\nLEFT JOIN[ordering]|.[orderstatus] os on o.OrderStatusId =\", \" os.Id\\nGROUP BY o.[Id], o.[OrderDate], os.[Name |\\n\\nORDER BY o.[Id]\\\");\\n\\nDescribe response types of We\", \"b APIs\\n\\nDevelopers consuming web APIs and microservices are most concerned with what is returned\\u2014\\nsp\", \"ecifically response types and error codes (if not standard). The response types are handled in the\\nX\", \"ML comments and data annotations.\\n\\nWithout proper documentation in the Swagger UI, the consumer lack\", \"s knowledge of what types are\\nbeing returned or what HTTP codes can be returned. That problem is fix\", \"ed by adding the\\n\\nMicrosoft.AsoNetCore.Mvc.ProducesResponselTypeAttribute, so Swashbuckle can genera\", \"te richer\\ninformation about the API return model and values, as shown in the following code:\\n\\nnamesp\", \"ace Microsoft.eShopOnContainers.Services.Ordering.API.Controllers\\n{\\n[Route(\\\"api/v1/[controller]\\\") |\\n\", \"[Authorize |\\npublic class OrdersController : Controller\\n{\\n//Additional code...\\n[Route(\\\"\\\") ]\\n[HttpGet\", \" ]\\n[ ProducesResponseType (typeof (IEnumerable<OrderSummary> ) ,\\n(int)HttpStatusCode.OK) |\\npublic as\", \"ync Task<IActionResult> GetOrders()\\n{\\nvar userid = _identityService.GetUserIdentity() ;\\nvar orders =\", \" await _orderQueries\\n.GetOrdersFromUserAsync(Guid.Parse(userid) ) ;\\nreturn Ok(orders) ;\\n\\nHowever, th\", \"e ProducesResponseType attribute cannot use dynamic as a type but requires to use\\nexplicit types, li\", \"ke the OrderSummary ViewModel DTO, shown in the following example:\\n\\npublic class OrderSummary\\n\\nt\\n\\npu\", \"blic int ordernumber { get; set; }\\npublic DateTime date { get; set; }\\n\\npublic string status { get; s\", \"et; }\\npublic double total { get; set; }\\n\\n}\\n// or using C# 8 record types:\\n\\npublic record OrderSummar\", \"y(int ordernumber, DateTime date, string status, double total);\\n\\n192 CHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS Patterns\\nThis is another reason why explicit returned ty\", \"pes are better than dynamic types, in the long term.\\nWhen using the ProducesResponseType attribute, \", \"you can also specify what is the expected outcome\\nregarding possible HTTP errors/codes, like 200, 40\", \"0, etc.\\n\\nIn the following image, you can see how Swagger UI shows the ResponseType information.\\n\\nt} \", \"sSWagger Ordering.API V1 wv\\nOrdering HTTP API\\u00ae\\n\\u2018Swagper/v1/swagger json\\nThe Ordering Service HTTP AP\", \"I\\nTerms of service\\nOrders v\\n\\nParameters | Try it out\\n\\nNo parameters\\n\\n401\\n\\n403\\n\\nFigure 7-5. Swagger U\", \"I showing response types and possible HTTP status codes from a Web API\\n\\nThe image shows some example\", \" values based on the ViewModel types and the possible HTTP status\\ncodes that can be returned.\\n\\nAddit\", \"ional resources\\n\\n\\u00b0 Dapper\\nhttps://github.com/StackExchange/dapper-dot-net\\n\\n\\u00b0 Julie Lerman. Data Poin\", \"ts - Dapper, Entity Framework and Hybrid Apps (MSDN\\nmagazine article)\\n\\n193 CHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns\\nframework-and-hybrid-apps\\n\\n\\u00b0 ASP.NET Core\", \" Web API Help Pages using Swagger\\n\\nswagger?tabs=visual-studio\\n. Create record types https://learn.mi\", \"crosoft.com/dotnet/csharp/whats-new/tutorials/records\\n\\nDesign a DDD-oriented microservice\\n\\nDomain-dr\", \"iven design (DDD) advocates modeling based on the reality of business as relevant to your\\nuse cases.\", \" In the context of building applications, DDD talks about problems as domains. It describes\\nindepend\", \"ent problem areas as Bounded Contexts (each Bounded Context correlates to a\\nmicroservice), and empha\", \"sizes a common language to talk about these problems. It also suggests\\nmany technical concepts and p\", \"atterns, like domain entities with rich models (no anemic-domain\\nmodel), value objects, aggregates, \", \"and aggregate root (or root entity) rules to support the internal\\nimplementation. This section intro\", \"duces the design and implementation of those internal patterns.\\n\\nSometimes these DDD technical rules\", \" and patterns are perceived as obstacles that have a steep\\nlearning curve for implementing DDD appro\", \"aches. But the important part is not the patterns\\nthemselves, but organizing the code so it Is align\", \"ed to the business problems, and using the same\\nbusiness terms (ubiquitous language). In addition, D\", \"DD approaches should be applied only if you are\\nimplementing complex microservices with significant \", \"business rules. Simpler responsibilities, like a\\nCRUD service, can be managed with simpler approache\", \"s.\\n\\nWhere to draw the boundaries is the key task when designing and defining a microservice. DDD\\npat\", \"terns help you understand the complexity in the domain. For the domain model for each Bounded\\nContex\", \"t, you identify and define the entities, value objects, and aggregates that model your domain.\\nYou b\", \"uild and refine a domain model that is contained within a boundary that defines your context.\\nAnd th\", \"at is explicit in the form of a microservice. The components within those boundaries end up\\nbeing yo\", \"ur microservices, although in some cases a BC or business microservices can be composed of\\nseveral p\", \"hysical services. DDD is about boundaries and so are microservices.\\n\\nKeep the microservice context b\", \"oundaries relatively small\\n\\nDetermining where to place boundaries between Bounded Contexts balances \", \"two competing goals.\\nFirst, you want to initially create the smallest possible microservices, althou\", \"gh that should not be the\\nmain driver; you should create a boundary around things that need cohesion\", \". Second, you want to\\navoid chatty communications between microservices. These goals can contradict \", \"one another. You\\nshould balance them by decomposing the system into as many small microservices as y\", \"ou can until\\nyou see communication boundaries growing quickly with each additional attempt to separa\", \"te a new\\nBounded Context. Cohesion is key within a single bounded context.\\n\\nIt is similar to the Ina\", \"ppropriate Intimacy code smell when implementing classes. If two microservices\\nneed to collaborate a\", \" lot with each other, they should probably be the same microservice.\\n\\n194 CHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns\\nAnother way to look at this aspect is auto\", \"nomy. If a microservice must rely on another service to\\ndirectly service a request, it is not truly \", \"autonomous.\\n\\nLayers in DDD microservices\\n\\nMost enterprise applications with significant business and\", \" technical complexity are defined by\\nmultiple layers. The layers are a logical artifact, and are not\", \" related to the deployment of the service.\\nThey exist to help developers manage the complexity in th\", \"e code. Different layers (like the domain\\nmodel layer versus the presentation layer, etc.) might hav\", \"e different types, which mandate translations\\nbetween those types.\\n\\nFor example, an entity could be \", \"loaded from the database. Then part of that information, or an\\naggregation of information including \", \"additional data from other entities, can be sent to the client UI\\nthrough a REST Web API. The point \", \"here is that the domain entity is contained within the domain\\nmodel layer and should not be propagat\", \"ed to other areas that it does not belong to, like to the\\npresentation layer.\\n\\nAdditionally, you nee\", \"d to have always-valid entities (see the Designing validations in the domain\\nmodel layer section) co\", \"ntrolled by aggregate roots (root entities). Therefore, entities should not be\\nbound to client views\", \", because at the UI level some data might still not be validated. This reason is\\nwhat the ViewModel \", \"is for. The ViewModel is a data model exclusively for presentation layer needs.\\nThe domain entities \", \"do not belong directly to the ViewModel. Instead, you need to translate between\\nViewModels and domai\", \"n entities and vice versa.\\n\\nWhen tackling complexity, it is important to have a domain model control\", \"led by aggregate roots that\\nmake sure that all the invariants and rules related to that group of ent\", \"ities (aggregate) are performed\\nthrough a single entry-point or gate, the aggregate root.\\n\\nFigure 7-\", \"5 shows how a layered design is implemented in the eShopOnContainers application.\\n\\n195 CHAPTER 6 | T\", \"ackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nLayers in a Domain-Driven Des\", \"ign Microservice\\n\\nASP.NET Web API\\nNetwork access to microservice\\nApplication layer \\u00a2 API contracts/i\", \"mplementation\\n* Commands and command handlers\\nQueries (when using an CQS approach)\\n\\nOrdering microse\", \"rvice Micro ORMSs like Dapper\\n\\naa a a a a a a a a a\\n\\n| 4 &! Ordering Domain entity model\\n\\n~ . | POCO\", \" entity classes (clean C# code\\n! b &%] Ordering.API ; entity classes ( )\\n; ; | . Domain entities wit\", \"h data + behavior\\n| b alc] Ordering.Domain\\u00a2\\u2014\\u2014\\u2014-\\u2014 Do main model layer * DDD patterns:\\n\\nou - I o D i t\", \"ity, t\\n! b alc#] Ordering.Infrastructure \\\\ | 5 Aggregate root, value object\\nNw o Repository contract\", \"s/interfaces\\n\\nData persistence infrastructure\\nRepository implementation\\nUse of ORMs or data access A\", \"PI:\\nEntity Framework Core or any ORM\\no ADO.NET\\n\\u00bb Any NoSQL database API\\no Other infrastructure imple\", \"mentation\\nused from the application layer\\nLogging, cryptography, search engine, etc.\\n\\nInfrastructure\", \" layer\\n\\nFigure 7-5. DDD layers in the ordering microservice in eShopOnContainers\\n\\nThe three layers i\", \"n a DDD microservice like Ordering. Each layer is a VS project: Application layer is\\nOrdering.API, D\", \"omain layer is Ordering.Domain and the Infrastructure layer is Ordering.Infrastructure.\\nYou want to \", \"design the system so that each layer communicates only with certain other layers. That\\napproach may \", \"be easier to enforce if layers are implemented as different class libraries, because you\\ncan clearly\", \" identify what dependencies are set between libraries. For instance, the domain model layer\\nshould n\", \"ot take a dependency on any other layer (the domain model classes should be Plain Old Class\\nObjects,\", \" or POCO, classes). As shown in Figure 7-6, the Ordering.Domain layer library has\\ndependencies only \", \"on the .NET libraries or NuGet packages, but not on any other custom library, such\\nas data library o\", \"r persistence library.\\n\\nA Ordering.Domain\\n\\n4 wm Dependencies\\n> \\u201c@\\u00ae NuGet\\n4 23 SDK\\nb & NETStandard.Li\", \"brary\\n\\nFigure 7-6. Layers implemented as libraries allow better control of dependencies between laye\", \"rs\\n\\nThe domain model layer\\n\\nEric Evans's excellent book Domain Driven Design says the following abou\", \"t the domain model layer\\nand the application layer.\\n\\nDomain Model Layer: Responsible for representin\", \"g concepts of the business, information about the\\nbusiness situation, and business rules. State that\", \" reflects the business situation is controlled and used\\nhere, even though the technical details of s\", \"toring it are delegated to the infrastructure. This layer is\\nthe heart of business software.\\n\\n196 CH\", \"APTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nThe domain model l\", \"ayer is where the business is expressed. When you implement a microservice\\ndomain model layer in .NE\", \"T, that layer is coded as a class library with the domain entities that capture\\ndata plus behavior (\", \"methods with logic).\\n\\nFollowing the Persistence Ignorance and the Infrastructure Ignorance principle\", \"s, this layer must\\ncompletely ignore data persistence details. These persistence tasks should be per\", \"formed by the\\n\\ninfrastructure layer. Therefore, this layer should not take direct dependencies on th\", \"e infrastructure,\\nwhich means that an important rule is that your domain model entity classes should\", \" be POCOs.\\n\\nDomain entities should not have any direct dependency (like deriving from a base class) \", \"on any data\\naccess infrastructure framework like Entity Framework or NHibernate. Ideally, your domai\", \"n entities\\nshould not derive from or implement any type defined in any infrastructure framework.\\n\\nMo\", \"st modern ORM frameworks like Entity Framework Core allow this approach, so that your domain\\nmodel c\", \"lasses are not coupled to the infrastructure. However, having POCO entities is not always\\npossible w\", \"hen using certain NoSQL databases and frameworks, like Actors and Reliable Collections in\\nAzure Serv\", \"ice Fabric.\\n\\nEven when it is important to follow the Persistence Ignorance principle for your Domain\", \" model, you\\nshould not ignore persistence concerns. It is still important to understand the physical\", \" data model and\\nhow it maps to your entity object model. Otherwise you can create impossible designs\", \".\\n\\nAlso, this aspect does not mean you can take a model designed for a relational database and direc\", \"tly\\nmove it to a NoSQL or document-oriented database. In some entity models, the model might fit, bu\", \"t\\nusually it does not. There are still constraints that your entity model must adhere to, based both\", \" on\\nthe storage technology and ORM technology.\\n\\nThe application layer\\nMoving on to the application l\", \"ayer, we can again cite Eric Evans\\u2019s book Domain Driven Design:\\n\\nApplication Layer: Defines the jobs\", \" the software is supposed to do and directs the expressive domain\\nobjects to work out problems. The \", \"tasks this layer is responsible for are meaningful to the business or\\nnecessary for interaction with\", \" the application layers of other systems. This layer is kept thin. It does\\nnot contain business rule\", \"s or knowledge, but only coordinates tasks and delegates work to\\ncollaborations of domain objects in\", \" the next layer down. It does not have state reflecting the business\\nsituation, but it can have stat\", \"e that reflects the progress of a task for the user or the program.\\n\\nA microservice's application la\", \"yer in .NET is commonly coded as an ASP.NET Core Web API project.\\nThe project implements the microse\", \"rvice\\u2019s interaction, remote network access, and the external Web\\nAPIs used from the UI or client app\", \"s. It includes queries if using a CQRS approach, commands\\naccepted by the microservice, and even the\", \" event-driven communication between microservices\\n(integration events). The ASP.NET Core Web API tha\", \"t represents the application layer must not contain\\nbusiness rules or domain knowledge (especially d\", \"omain rules for transactions or updates); these\\nshould be owned by the domain model class library. T\", \"he application layer must only coordinate tasks\\nand must not hold or define any domain state (domain\", \" model). It delegates the execution of business\\nrules to the domain model classes themselves (aggreg\", \"ate roots and domain entities), which will\\nultimately update the data within those domain entities.\\n\", \"\\n197 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nBasically, \", \"the application logic is where you implement all use cases that depend on a given front end.\\nFor exa\", \"mple, the implementation related to a Web API service.\\n\\nThe goal is that the domain logic in the dom\", \"ain model layer, its invariants, the data model, and\\nrelated business rules must be completely indep\", \"endent from the presentation and application layers.\\nMost of all, the domain model layer must not di\", \"rectly depend on any infrastructure framework.\\n\\nThe infrastructure layer\\n\\nThe infrastructure layer i\", \"s how the data that is initially held in domain entities (in memory) Is persisted\\nin databases or an\", \"other persistent store. An example is using Entity Framework Core code to\\nimplement the Repository p\", \"attern classes that use a DBContext to persist data in a relational\\ndatabase.\\n\\nIn accordance with th\", \"e previously mentioned Persistence Ignorance and Infrastructure Ignorance\\nprinciples, the infrastruc\", \"ture layer must not \\u201ccontaminate\\u201d the domain model layer. You must keep the\\ndomain model entity clas\", \"ses agnostic from the infrastructure that you use to persist data (EF or any\\nother framework) by not\", \" taking hard dependencies on frameworks. Your domain model layer class\\nlibrary should have only your\", \" domain code, just POCO entity classes implementing the heart of your\\nsoftware and completely decoup\", \"led from infrastructure technologies.\\n\\nThus, your layers or class libraries and projects should ulti\", \"mately depend on your domain model layer\\n(library), not vice versa, as shown in Figure 7-7.\\n\\nDepende\", \"ncies between Layers in a Domain-Driven Design service\\n\\nMicroservice\\n\\nee\\n\\n/ \\\\ * Depends on the Domai\", \"n-Model Layer so it can:\\no Use entity objects\\no Use Repository Interfaces/Contracts\\nDepends on the I\", \"nfrastructure Layer (thru Dl) so it can:\\no Use Repository implementation classes, ideally through DI\", \"\\n\\n~\\n\\nApplication\\nLayer\\n\\nN\\n\\nDomain Model\\n\\nIdeally, it must NOT take dependency on any other layer\\nIt \", \"implements:\\n\\nee ee ee ee ee ee\\n\\nLayer o Domain Entities, Aggregate-Roots and Value-Objects\\n\\u00a9 Reposit\", \"ory Contracts/Interfaces (to be used in Dl)\\nDepends on the Domain-Model Layer so it can:\\nInfrastruct\", \"ure o Use entity objects.\\nLayer \\u00a9 Like EF updating a database through mapped entities\\n\\\\ ; Direct dep\", \"endency on infrastructure frameworks like EF Core or\\n\\\\ Y any other database, cache or infrastructure\", \" API\\n\\nwe ee ee\\n\\nFigure 7-7. Dependencies between layers in DDD\\n\\nDependencies in a DDD Service, the A\", \"pplication layer depends on Domain and Infrastructure, and\\nInfrastructure depends on Domain, but Dom\", \"ain doesn't depend on any layer. This layer design should\\nbe independent for each microservice. As n\", \"oted earlier, you can implement the most complex\\nmicroservices following DDD patterns, while impleme\", \"nting simpler data-driven microservices (simple\\nCRUD in a single layer) in a simpler way.\\n\\n198 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nAdditional resources\\n\", \"\\n\\u00b0 DeviQ. Persistence Ignorance principle\\nhttps://devig.com/persistence-ignorance/\\n. Oren Eini. Infr\", \"astructure Ignorance\\n\\nhttps://ayende.com/blog/3137/infrastructure-ignorance\\n\\n\\u00b0 Angel Lopez. Layered \", \"Architecture In Domain-Driven Design\\nhttps://ajlopez.wordpress.com/2008/09/12/layered-architecture-i\", \"n-domain-driven-design\\n\\nDesign a microservice domain model\\n\\nDefine one rich domain model for each bu\", \"siness microservice or Bounded Context.\\n\\nYour goal is to create a single cohesive domain model for e\", \"ach business microservice or Bounded\\nContext (BC). Keep in mind, however, that a BC or business micr\", \"oservice could sometimes be\\ncomposed of several physical services that share a single domain model. \", \"The domain model must\\ncapture the rules, behavior, business language, and constraints of the single \", \"Bounded Context or\\nbusiness microservice that it represents.\\n\\nThe Domain Entity pattern\\n\\nEntities re\", \"present domain objects and are primarily defined by their identity, continuity, and\\npersistence over\", \" time, and not only by the attributes that comprise them. As Eric Evans says, \\u201can\\nobject primarily d\", \"efined by its identity is called an Entity.\\u201d Entities are very important in the domain\\nmodel, since \", \"they are the base for a model. Therefore, you should identify and design them carefully.\\n\\nAn entity'\", \"s identity can cross multiple microservices or Bounded Contexts.\\n\\nThe same identity (that is, the sa\", \"me Id value, although perhaps not the same domain entity) can be\\nmodeled across multiple Bounded Con\", \"texts or microservices. However, that does not imply that the\\nsame entity, with the same attributes \", \"and logic would be implemented in multiple Bounded Contexts.\\nInstead, entities in each Bounded Conte\", \"xt limit their attributes and behaviors to those required in that\\nBounded Context\\u2019s domain.\\n\\nFor ins\", \"tance, the buyer entity might have most of a person\\u2019s attributes that are defined in the user\\nentity\", \" in the profile or identity microservice, including the identity. But the buyer entity in the orderi\", \"ng\\nmicroservice might have fewer attributes, because only certain buyer data is related to the order\", \"\\nprocess. The context of each microservice or Bounded Context impacts its domain model.\\n\\nDomain enti\", \"ties must tmplement behavior in addition to implementing data attributes.\\n\\nA domain entity in DDD mu\", \"st implement the domain logic or behavior related to the entity data (the\\nobject accessed in memory)\", \". For example, as part of an order entity class you must have business logic\\nand operations implemen\", \"ted as methods for tasks such as adding an order item, data validation, and\\ntotal calculation. The e\", \"ntity's methods take care of the invariants and rules of the entity instead of\\nhaving those rules sp\", \"read across the application layer.\\n\\n199 CHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns\\nFigure 7-8 shows a domain entity that implements not only data attributes bu\", \"t operations or methods\\nwith related domain logic.\\n\\nDomain Entity pattern\\n\\nOrder entity class\\n\\nAttri\", \"butes\\nID\\nFirstName\\n\\nLastName Entity's data\\nAddress\\nOrderltems (List)\\n\\nMethods\\n\\nOrder() constructor E\", \"ntity :\\nAddOrderltem(item) Behavior\\nSetAddress(address) and logic\\n\\nFigure 7-8. Example of a domain e\", \"ntity design implementing data plus behavior\\n\\nA domain model entity implements behaviors through met\", \"hods, that Is, it\\u2019s not an \\u201canemic\\u201d model. Of\\ncourse, sometimes you can have entities that do not im\", \"plement any logic as part of the entity class.\\nThis can happen in child entities within an aggregate\", \" if the child entity does not have any special logic\\nbecause most of the logic is defined in the agg\", \"regate root. If you have a complex microservice that\\nhas logic implemented in the service classes in\", \"stead of in the domain entities, you could be falling\\ninto the anemic domain model, explained in the\", \" following section.\\n\\nRich domain model versus anemic domain model\\n\\nIn his post AnemicDomainModel, Ma\", \"rtin Fowler describes an anemic domain model this way:\\n\\nThe basic symptom of an Anemic Domain Model \", \"is that at first blush it looks like the real thing. There\\nare objects, many named after the nouns i\", \"n the domain space, and these objects are connected with\\nthe rich relationships and structure that t\", \"rue domain models have. The catch comes when you look at\\nthe behavior, and you realize that there is\", \" hardly any behavior on these objects, making them little\\nmore than bags of getters and setters.\\n\\nOf\", \" course, when you use an anemic domain model, those data models will be used from a set of\\nservice o\", \"bjects (traditionally named the business layer) which capture all the domain or business logic.\\nThe \", \"business layer sits on top of the data model and uses the data model just as data.\\n\\nThe anemic domai\", \"n model is just a procedural style design. Anemic entity objects are not real objects\\nbecause they l\", \"ack behavior (methods). They only hold data properties and thus it is not object-\\noriented design. B\", \"y putting all the behavior out into service objects (the business layer), you\\nessentially end up wit\", \"h spaghetti code or transaction scripts, and therefore you lose the advantages\\nthat a domain model p\", \"rovides.\\n\\nRegardless, if your microservice or Bounded Context is very simple (a CRUD service), the a\", \"nemic\\ndomain model in the form of entity objects with just data properties might be good enough, and\", \" it\\nmight not be worth implementing more complex DDD patterns. In that case, it will be simply a\\nper\", \"sistence model, because you have intentionally created an entity with only data for CRUD\\npurposes.\\n\\n\", \"200 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nThat is why \", \"microservices architectures are perfect for a multi-architectural approach depending on\\neach Bounded\", \" Context. For instance, in eshopOnContainers, the ordering microservice implements\\nDDD patterns, but\", \" the catalog microservice, which is a simple CRUD service, does not.\\n\\nSome people say that the anemi\", \"c domain model is an anti-pattern. It really depends on what you are\\nimplementing. If the microservi\", \"ce you are creating is simple enough (for example, a CRUD service),\\nfollowing the anemic domain mode\", \"l it is not an anti-pattern. However, if you need to tackle the\\ncomplexity of a microservice\\u2019s domai\", \"n that has a lot of ever-changing business rules, the anemic\\ndomain model might be an anti-pattern f\", \"or that microservice or Bounded Context. In that case,\\ndesigning it as a rich model with entities co\", \"ntaining data plus behavior as well as implementing\\nadditional DDD patterns (aggregates, value objec\", \"ts, etc.) might have huge benefits for the long-term\\nsuccess of such a microservice.\\n\\nAdditional res\", \"ources\\n\\n\\u00b0 DeviQ. Domain Entity\\nhttps://devig.com/entity/\\n\\n\\u00b0 Martin Fowler. The Domain Model\\nhttps://\", \"martinfowler.com/eaaCatalog/domainModel.html\\n\\u00b0 Martin Fowler. The Anemic Domain Model\\n\\nhttps://marti\", \"nfowler.com/bliki/AnemicDomainModel.html\\n\\nThe Value Object pattern\\n\\nAs Eric Evans has noted, \\u201cMany o\", \"bjects do not have conceptual identity. These objects describe\\ncertain characteristics of a thing.\\u201d\\n\", \"\\nAn entity requires an identity, but there are many objects in a system that do not, like the Value\\n\", \"Object pattern. A value object is an object with no conceptual identity that describes a domain aspe\", \"ct.\\nThese are objects that you instantiate to represent design elements that only concern you tempor\", \"arily.\\nYou care about what they are, not who they are. Examples include numbers and strings, but can\", \" also\\nbe higher-level concepts like groups of attributes.\\n\\nSomething that is an entity in a microser\", \"vice might not be an entity in another microservice, because\\nin the second case, the Bounded Context\", \" might have a different meaning. For example, an address in\\nan e-commerce application might not have\", \" an identity at all, since it might only represent a group of\\nattributes of the customer's profile f\", \"or a person or company. In this case, the address should be\\nclassified as a value object. However, i\", \"n an application for an electric power utility company, the\\ncustomer address could be important for \", \"the business domain. Therefore, the address must have an\\nidentity so the billing system can be direc\", \"tly linked to the address. In that case, an address should be\\nclassified as a domain entity.\\n\\nA pers\", \"on with a name and surname Is usually an entity because a person has identity, even if the\\nname and \", \"surname coincide with another set of values, such as if those names also refer to a different\\nperson\", \".\\n\\nValue objects are hard to manage in relational databases and ORMs like Entity Framework (EF),\\nwhe\", \"reas in document-oriented databases they are easier to implement and use.\\n\\n201 CHAPTER 6 | Tackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS Patterns\\nEF Core 2.0 and later versions includ\", \"e the Owned Entities feature that makes it easier to handle value\\nobjects, as we'll see in detail la\", \"ter on.\\n\\nAdditional resources\\n\\n. Martin Fowler. Value Object pattern\\n\\nhttps://martinfowler.com/bliki\", \"/ValueObject.html\\n\\n. Value Object\\nhttps://devig.com/value-object/\\n\\n\\u00b0 Value Objects in Test-Driven De\", \"velopment\\n\\nhttps://leanpub.com/tdd-ebook/read#leanpub-auto-value-objects\\n\\n\\u00b0 Eric Evans. Domain-Drive\", \"n Design: Tackling Complexity in the Heart of Software. (Book;\\nincludes a discussion of value object\", \"s)\\n\\nhttos://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\n\\nSoftware/dp/0321125215/\\n\\nThe A\", \"ggregate pattern\\n\\nA domain model contains clusters of different data entities and processes that can\", \" control a\\nsignificant area of functionality, such as order fulfillment or inventory. A more fine-gr\", \"ained DDD unit is\\nthe aggregate, which describes a cluster or group of entities and behaviors that c\", \"an be treated as a\\ncohesive unit.\\n\\nYou usually define an aggregate based on the transactions that yo\", \"u need. A classic example is an\\norder that also contains a list of order items. An order item will u\", \"sually be an entity. But it will be a\\nchild entity within the order aggregate, which will also conta\", \"in the order entity as its root entity,\\ntypically called an aggregate root.\\n\\nIdentifying aggregates \", \"can be hard. An aggregate is a group of objects that must be consistent\\ntogether, but you cannot jus\", \"t pick a group of objects and label them an aggregate. You must start\\nwith a domain concept and thin\", \"k about the entities that are used in the most common transactions\\nrelated to that concept. Those en\", \"tities that need to be transactionally consistent are what forms an\\naggregate. Thinking about transa\", \"ction operations is probably the best way to identify aggregates.\\n\\nThe Aggregate Root or Root Entity\", \" pattern\\n\\nAn aggregate is composed of at least one entity: the aggregate root, also called root enti\", \"ty or primary\\nentity. Additionally, it can have multiple child entities and value objects, with all \", \"entities and objects\\nworking together to implement required behavior and transactions.\\n\\nThe purpose \", \"of an aggregate root is to ensure the consistency of the aggregate; it should be the only\\nentry poin\", \"t for updates to the aggregate through methods or operations in the aggregate root class.\\nYou should\", \" make changes to entities within the aggregate only via the aggregate root. It is the\\naggregate\\u2019s co\", \"nsistency guardian, considering all the invariants and consistency rules you might need\\nto comply wi\", \"th in your aggregate. If you change a child entity or value object independently, the\\n\\n202 CHAPTER 6\", \" | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\naggregate root cannot ens\", \"ure that the aggregate is in a valid state. It would be like a table with a\\nloose leg. Maintaining c\", \"onsistency is the main purpose of the aggregate root.\\n\\nIn Figure 7-9, you can see sample aggregates \", \"like the buyer aggregate, which contains a single entity\\n(the aggregate root Buyer). The order aggre\", \"gate contains multiple entities and a value object.\\n\\nAggregate pattern\\n\\nBuyer Aggregate (One entity)\", \" Order Aggregate (Multiple entities and Value-Object)\\nrT\\n\\ncc\\n\\nAttributes Attributes\\nID Street\\nOrderD\", \"ata City\\nAttributes [BuyerlD] 7\\nID [Address]\\n\\nFullName [Orderltems]\\n[PaymentMethods] \\u201d\\n\\nMethods Attr\", \"ibutes\\nsche Order(params) constructor ID\\nBuyer(params) constructor AddOrderltem(item) ProductiD\\n- Se\", \"tAddress(address) Price\\nCalculate Total() ves\\n\\nFigure 7-9. Example of aggregates with multiple or si\", \"ngle entities\\n\\nA DDD domain model is composed from aggregates, an aggregate can have just one entity\", \" or more,\\nand can include value objects as well. Note that the Buyer aggregate could have additional\", \" child\\nentities, depending on your domain, as it does in the ordering microservice in the eshopOnCon\", \"tainers\\nreference application. Figure 7-9 just illustrates a case in which the buyer has a single en\", \"tity, as an\\nexample of an aggregate that contains only an aggregate root.\\n\\nIn order to maintain sepa\", \"ration of aggregates and keep clear boundaries between them, it is a good\\npractice ina DDD domain mo\", \"del to disallow direct navigation between aggregates and only having\\nthe foreign key (FK) field, as \", \"implemented in the Ordering microservice domain model in\\neShopOnContainers. The Order entity only ha\", \"s a foreign key field for the buyer, but not an EF Core\\nnavigation property, as shown in the followi\", \"ng code:\\n\\npublic class Order : Entity, IAggregateRoot\\n{\\nprivate DateTime _orderDate;\\npublic Address \", \"Address { get; private set; }\\nprivate int? _buyerId; // FK pointing to a different aggregate root\\n\\np\", \"ublic OrderStatus OrderStatus { get; private set; }\\n\\nprivate readonly List<OrderItem> _orderItems;\\n\\n\", \"public IReadOnlyCollection<OrderItem> OrderItems => _orderItems;\\n// ... Additional code\\n\\n203 CHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nIdentifying and working\", \" with aggregates requires research and experience. For more information, see\\nthe following Additiona\", \"l resources list.\\n\\nAdditional resources\\n\\n\\u00b0 Vaughn Vernon. Effective Aggregate Design - Part I: Model\", \"ing a Single Aggregate (from\\nhttps://dddcommunity.org/)\\nhttps://dddcommunity.org/wp-content/uploads/\", \"files/pdf articles/Vernon 2011 1.pdf\\n\\n\\u00b0 Vaughn Vernon. Effective Aggregate Design - Part II: Making \", \"Aggregates Work\\n\\nTogether (from https://dddcommunity.org/)\\nhttps://dddcommunity.org/wp-content/uploa\", \"ds/files/pdf articles/Vernon 2011 2.pdf\\n\\n\\u00b0 Vaughn Vernon. Effective Aggregate Design - Part III: Gai\", \"ning Insight Through\\n\\nDiscovery (from https://dddcommunity.org/)\\nhttps://dddcommunity.org/wp-content\", \"/uploads/files/pdf articles/Vernon 2011 3.pdf\\n\\n. Sergey Grybniak. DDD Tactical Design Patterns\\nhttps\", \"://www.codeproject.com/Articles/1164363/Domain-Driven-Design-Tactical-Design-\\n\\nPatterns-Part\\n\\n. Chri\", \"s Richardson. Developing Transactional Microservices Using Aggregates\\n\\nhttos://www.infog.com/article\", \"s/microservices-aqgregates-events-cars-part-1-richardson\\n\\n\\u00b0 DeviQ. The Aggregate pattern\\nhttps://dev\", \"ig.com/aggregate-pattern/\\n\\nImplement a microservice domain model with .NET\\n\\nIn the previous section,\", \" the fundamental design principles and patterns for designing a domain model\\nwere explained. Now it'\", \"s time to explore possible ways to implement the domain model by using .NET\\n(plain C# code) and EF C\", \"ore. Your domain model will be composed simply of your code. It will have\\njust the EF Core model req\", \"uirements, but not real dependencies on EF. You shouldn't have hard\\ndependencies or references to EF\", \" Core or any other ORM in your domain model.\\n\\nDomain model structure in a custom .NET Standard Libra\", \"ry\\n\\nThe folder organization used for the eshopOnContainers reference application demonstrates the DD\", \"D\\nmodel for the application. You might find that a different folder organization more clearly\\ncommun\", \"icates the design choices made for your application. As you can see in Figure 7-10, in the\\nordering \", \"domain model there are two aggregates, the order aggregate and the buyer aggregate. Each\\naggregate I\", \"s a group of domain entities and value objects, although you could have an aggregate\\ncomposed of a s\", \"ingle domain entity (the aggregate root or root entity) as well.\\n\\n204 CHAPTER 6 | Tackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patterns\\nOrdering Microservice/Container\\n\\nWeb API /o 4 \", \"%& Ordering aN\\n\\napplication layer \\u2014_7t\\u2014_\\u2014ses\\u2014ses\\u2014e dD a@] Ordering.API \\\\\\n\\n/ ee ae ae ae ae\\nproject/l\", \"ibrary yo 4 alc | Ordering. oe aN\\nOrdering microservice *\\\\\\n\\n/ _\\n/ b \\u201ci Dependencies gomain model lay\", \"er \\u2014\\\\\\n\\na Properties\\nat! AggregatesModel\\n4 it! BuyerAggregate\\n\\n>b aC* Buyer.cs\\n\\nb a C* CardType.cs\\n\\nb\", \" &C* |BuyerRepository.cs\\n\\nBuyer\\naggregate\\n\\nDomain model\\nstructured in b a C* PaymentMethod.cs\\n\\nsp(el\", \"es lies 4 it! OrderAggregate\\nb aC* Address.cs\\na C* |OrderRepository.cs | Order\\na C* Order.cs ee\\na C*\", \" Orderltem.cs\\n\\\\ a C* OrderStatus.cs /\\nInfrastructure layer \\\\ SA al SeedWork \\u2014\\u2014\\u2014\\u2014\\u2014Custom base classes\", \" vod\\n\\nrepos&EFcode \\\\ \\u201cstot too Tc>orrcrcrc co /\\nsroject/library re \\u2014>+b = Ordering.Infrastructure /\\n\", \"\\nVv VV YW\\n\\n|\\n|\\nly\\nI\\nI\\nI\\nI\\nI\\nI\\nI\\nI\\nI\\nI |\\nI\\nI\\nI |\\ni\\n\\n_\\u2014_\\u2014\\u2014<\\u2014 i ee ee ee ee\\n\\nFigure 7-10. Domain model \", \"structure for the ordering microservice in eshopOnContainers\\n\\nAdditionally, the domain model layer i\", \"ncludes the repository contracts (interfaces) that are the\\ninfrastructure requirements of your domai\", \"n model. In other words, these interfaces express what\\nrepositories and the methods the infrastructu\", \"re layer must implement. It\\u2019s critical that the\\nimplementation of the repositories be placed outside\", \" of the domain model layer, in the infrastructure\\nlayer library, so the domain model layer isn't \\u201cco\", \"ntaminated\\u201d by API or classes from infrastructure\\ntechnologies, like Entity Framework.\\n\\nYou can also\", \" see a SeedWork folder that contains custom base classes that you can use as a base for\\nyour domain \", \"entities and value objects, so you don't have redundant code in each domain's object\\nclass.\\n\\nStructu\", \"re aggregates in a custom .NET Standard library\\n\\nAn aggregate refers to a cluster of domain objects \", \"grouped together to match transactional\\nconsistency. Those objects could be instances of entities (o\", \"ne of which is the aggregate root or root\\nentity) plus any additional value objects.\\n\\nTransactional \", \"consistency means that an aggregate is guaranteed to be consistent and up to date at\\nthe end of a bu\", \"siness action. For example, the order aggregate from the eSshopOnContainers ordering\\nmicroservice do\", \"main model is composed as shown in Figure 7-11.\\n\\n205 CHAPTER 6 | Tackle Business Complexity in a Mic\", \"roservice with DDD and CQRS Patterns\\nOrder aggregate\\n4 it! OrderAggregate\\n\\n>b aC* Address.cs <\\u2014 Valu\", \"e object\\n\\nb aC* |OrderRepository.cs <\\u00ab\\u2014\\u2014 Repo contract/interface\\nb aC* Order.cs <\\u00ab\\u2014 Aggregate root\\n\\n\", \"> a&C* Orderltem.cs <\\u00ab\\u2014 Child entity\\n\\nb> a C* OrderStatus.cs <\\u2014 Enumeration class\\n\\nFigure 7-11. The \", \"order aggregate in Visual Studio solution\\n\\nIf you open any of the files in an aggregate folder, you \", \"can see how it's marked as either a custom\\nbase class or interface, like entity or value object, as \", \"implemented in the SeedWork folder.\\n\\nImplement domain entities as POCO classes\\n\\nYou implement a doma\", \"in model in .NET by creating POCO classes that implement your domain\\nentities. In the following exam\", \"ple, the Order class is defined as an entity and also as an aggregate\\nroot. Because the Order class \", \"derives from the Entity base class, it can reuse common code related to\\nentities. Bear in mind that \", \"these base classes and interfaces are defined by you in the domain model\\nproject, so it is your code\", \", not infrastructure code from an ORM like EF.\\n\\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE 5.0\\n// Enti\", \"ty is a custom base class with the ID\\npublic class Order : Entity, IAggregateRoot\\naf\\n\\nprivate DateTi\", \"me _orderDate;\\npublic Address Address { get; private set; }\\nprivate int? _buyerlId;\\n\\npublic OrderSta\", \"tus OrderStatus { get; private set; }\\nprivate int _orderStatusId;\\n\\nprivate string _description;\\npriv\", \"ate int? _paymentMethodId;\\n\\nprivate readonly List<OrderItem> _orderItems;\\npublic IReadOnlyCollection\", \"<OrderItem> OrderItems => _orderItems;\\n\\npublic Order(string userId, Address address, int cardTypelId\", \", string cardNumber, string\\ncardSecurityNumber,\\nstring cardHolderName, DateTime cardExpiration, int?\", \" buyerId = null, int?\\npaymentMethodId = null)\\n\\n_orderItems = new List<OrderItem>() ;\\n_buyerId = buye\", \"rId;\\n\\n_paymentMethodId = paymentMethodId;\\n_orderStatusId = OrderStatus.Submitted.Id;\\n_orderDate = Da\", \"teTime.UtcNow;\\n\\n206 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rns\\nAddress = address;\\n\\n// ..-Additional code ...\\n}\\n\\npublic void AddOrderItem(int productId, string \", \"productName,\\ndecimal unitPrice, decimal discount,\\nstring pictureUrl, int units = 1)\\n\\nI oco\\n// Domain\", \" rules/logic for adding the OrderItem to the order\\nHi 000\\n\\nvar orderItem = new OrderItem(productId, \", \"productName, unitPrice, discount,\\npictureUrl, units);\\n\\n_orderItems.Add(orderItem) ;\\n\\n}\\nHii 000\\n// Ad\", \"ditional methods with domain rules/logic related to the Order aggregate\\n\\nHi coc\\n\\nIt's important to n\", \"ote that this is a domain entity implemented as a POCO class. It doesn't have any\\ndirect dependency \", \"on Entity Framework Core or any other infrastructure framework. This\\nimplementation is as it should \", \"be in DDD, just C# code implementing a domain model.\\n\\nIn addition, the class is decorated with an in\", \"terface named IAggregateRoot. That interface is an empty\\ninterface, sometimes called a marker interf\", \"ace, that's used just to indicate that this entity class is also\\nan aggregate root.\\n\\nA marker interf\", \"ace is sometimes considered as an anti-pattern; however, it\\u2019s also a clean way to mark\\na class, espe\", \"cially when that interface might be evolving. An attribute could be the other choice for\\nthe marker,\", \" but it\\u2019s quicker to see the base class (Entity) next to the [Aggregate interface instead of\\nputting\", \" an Aggregate attribute marker above the class. It\\u2019s a matter of preferences, in any case.\\n\\nHaving a\", \"n aggregate root means that most of the code related to consistency and business rules of\\nthe aggreg\", \"ate\\u2019s entities should be implemented as methods in the Order aggregate root class (for\\nexample, AddO\", \"rderltem when adding an Orderltem object to the aggregate). You should not create\\nor update Orderlte\", \"ms objects independently or directly; the AggregateRoot class must keep control\\nand consistency of a\", \"ny update operation against its child entities.\\n\\nEncapsulate data in the Domain Entities\\n\\nA common p\", \"roblem in entity models is that they expose collection navigation properties as publicly\\naccessible \", \"list types. This allows any collaborator developer to manipulate the contents of these\\ncollection ty\", \"pes, which may bypass important business rules related to the collection, possibly leaving\\nthe objec\", \"t in an invalid state. The solution to this is to expose read-only access to related collections\\nand\", \" explicitly provide methods that define ways in which clients can manipulate them.\\n\\nIn the previous \", \"code, note that many attributes are read-only or private and are only updatable by the\\nclass methods\", \", so any update considers business domain invariants and logic specified within the class\\nmethods.\\n\\n\", \"207 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nFor example,\", \" following DDD patterns, you should not do the following from any command handler\\nmethod or applicat\", \"ion layer class (actually, it should be impossible for you to do so):\\n\\n// WRONG ACCORDING TO DDD PAT\", \"TERNS - CODE AT THE APPLICATION LAYER OR\\n\\n// COMMAND HANDLERS\\n\\n// Code in command handler methods or\", \" Web API controllers\\n\\n//... (WRONG) Some code with business logic out of the domain classes ...\\n\\nOrd\", \"erItem myNewOrderItem = new OrderItem(orderId, productId, productName,\\npictureUrl, unitPrice, discou\", \"nt, units);\\n\\n//... (WRONG) Accessing the OrderItems collection directly from the application layer /\", \"/ or\\ncommand handlers\\n\\nmyOrder.OrderItems .Add(myNewOrderItem) ;\\n\\nrr\\n\\nIn this case, the Add method i\", \"s purely an operation to add data, with direct access to the Orderltems\\ncollection. Therefore, most \", \"of the domain logic, rules, or validations related to that operation with the\\nchild entities will be\", \" spread across the application layer (command handlers and Web API controllers).\\n\\nIf you go around t\", \"he aggregate root, the aggregate root cannot guarantee its invariants, its validity, or\\nits consiste\", \"ncy. Eventually you'll have spaghetti code or transactional script code.\\n\\nTo follow DDD patterns, en\", \"tities must not have public setters in any entity property. Changes in an\\nentity should be driven by\", \" explicit methods with explicit ubiquitous language about the change\\nthey're performing in the entit\", \"y.\\n\\nFurthermore, collections within the entity (like the order items) should be read-only properties\", \" (the\\nAsReadOnly method explained later). You should be able to update it only from within the aggre\", \"gate\\nroot class methods or the child entity methods.\\n\\nAs you can see in the code for the Order aggre\", \"gate root, all setters should be private or at least read-\\nonly externally, so that any operation ag\", \"ainst the entity's data or its child entities has to be performed\\nthrough methods in the entity clas\", \"s. This maintains consistency in a controlled and object-oriented\\nway instead of implementing transa\", \"ctional script code.\\n\\nThe following code snippet shows the proper way to code the task of adding an \", \"Orderltem object to\\nthe Order aggregate.\\n\\n// RIGHT ACCORDING TO DDD--CODE AT THE APPLICATION LAYER O\", \"R COMMAND HANDLERS\\n\\n// The code in command handlers or WebAPI controllers, related only to applicati\", \"on stuff\\n// There is NO code here related to OrderItem object's business logic\\nmyOrder.AddOrderiItem\", \"(productId, productName, pictureUrl, unitPrice, discount, units);\\n\\n// The code related to OrderItem \", \"params validations or domain rules should\\n// be WITHIN the AddOrderItem method.\\n\\nUooe\\n\\nIn this snipp\", \"et, most of the validations or logic related to the creation of an Orderltem object will be\\nunder th\", \"e control of the Order aggregate root\\u2014in the AddOrderltem method\\u2014especially validations\\nand logic re\", \"lated to other elements in the aggregate. For instance, you might get the same product\\nitem as the r\", \"esult of multiple calls to AddOrderltem. In that method, you could examine the product\\nitems and con\", \"solidate the same product items into a single Orderltem object with several units.\\n\\n208 CHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nAdditionally, if there are d\", \"ifferent discount amounts but the product ID is the same, you would likely\\napply the higher discount\", \". This principle applies to any other domain logic for the Orderltem object.\\n\\nIn addition, the new O\", \"rderltem(params) operation will also be controlled and performed by the\\nAddOrderltem method from the\", \" Order aggregate root. Therefore, most of the logic or validations\\nrelated to that operation (especi\", \"ally anything that impacts the consistency between other child\\nentities) will be in a single place w\", \"ithin the aggregate root. That is the ultimate purpose of the\\naggregate root pattern.\\n\\nWhen you use \", \"Entity Framework Core 1.1 or later, a DDD entity can be better expressed because it\\nallows mapping t\", \"o fields in addition to properties. This is useful when protecting collections of child\\nentities or \", \"value objects. With this enhancement, you can use simple private fields instead of\\nproperties and yo\", \"u can implement any update to the field collection in public methods and provide\\nread-only access th\", \"rough the AsReadOnly method.\\n\\nIn DDD, you want to update the entity only through methods in the enti\", \"ty (or the constructor) in order\\nto control any invariant and the consistency of the data, so proper\", \"ties are defined only with a get\\naccessor. The properties are backed by private fields. Private memb\", \"ers can only be accessed from\\nwithin the class. However, there is one exception: EF Core needs to se\", \"t these fields as well (so it can\\nreturn the object with the proper values).\\n\\nMap properties with on\", \"ly get accessors to the fields in the database table\\n\\nMapping properties to database table columns i\", \"s not a domain responsibility but part of the\\ninfrastructure and persistence layer. We mention this \", \"here just so you're aware of the new capabilities\\nin EF Core 1.1 or later related to how you can mod\", \"el entities. Additional details on this topic are\\nexplained in the infrastructure and persistence se\", \"ction.\\n\\nWhen you use EF Core 1.0 or later, within the DoContext you need to map the properties that \", \"are\\ndefined only with getters to the actual fields in the database table. This is done with the HasF\", \"ield\\nmethod of the PropertyBuilder class.\\n\\nMap fields without properties\\n\\nWith the feature in EF Cor\", \"e 1.1 or later to map columns to fields, it\\u2019s also possible to not use\\nproperties. Instead, you can \", \"just map columns from a table to fields. A common use case for this Is\\nprivate fields for an interna\", \"l state that doesn't need to be accessed from outside the entity.\\n\\nFor example, in the preceding Ord\", \"erAggregate code example, there are several private fields, like the\\n_paymentMethodld field, that ha\", \"ve no related property for either a setter or getter. That field could\\nalso be calculated within the\", \" order's business logic and used from the order's methods, but it needs\\nto be persisted in the datab\", \"ase as well. So in EF Core (since v1.1), there\\u2019s a way to map a field without\\na related property to \", \"a column in the database. This is also explained in the Infrastructure layer section\\nof this guide.\\n\", \"\\n209 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nAdditional \", \"resources\\n\\n\\u00b0 Vaughn Vernon. Modeling Aggregates with DDD and Entity Framework. Note that this is\\n\\nno\", \"t Entity Framework Core.\\nhttos://kalele.io/blog-posts/modeling-aggregates-with-ddd-and-entity-framew\", \"ork\\n\\n. Julie Lerman. Data Points - Coding for Domain-Driven Design: Tips for Data-Focused\\n\\nDevs\\nhtto\", \"s://learn.microsoft.com/archive/msdn-magazine/2013/august/data-points-coding-for-\\n\\ndomain-driven-des\", \"ign-tips-for-data-focused-devs\\n\\n. Udi Dahan. How to create fully encapsulated Domain Models\\n\\nhttps:/\", \"/udidahan.com/2008/02/29/how-to-create-fully-encapsulated-domain-models/\\n\\n\\u00b0 Steve Smith. What is the\", \" difference between a DTO and a POCO? hitps://ardalis.com/dto-\\nor-poco/\\n\\nSeedwork (reusable base cla\", \"sses and interfaces for\\nyour domain model)\\n\\nThe solution folder contains a SeedWork folder. This fol\", \"der contains custom base classes that you can\\nuse as a base for your domain entities and value objec\", \"ts. Use these base classes so you don\\u2019t have\\nredundant code in each domain\\u2019s object class. The folde\", \"r for these types of classes is called SeedWork\\nand not something like Framework. It's called SeedWo\", \"rk because the folder contains just a small\\nsubset of reusable classes that cannot really be conside\", \"red a framework. Seedwork is a term\\nintroduced by Michael Feathers and popularized by Martin Fowler \", \"but you could also name that\\nfolder Common, SharedKernel, or similar.\\n\\nFigure 7-12 shows the classes\", \" that form the seedwork of the domain model in the ordering\\nmicroservice. It has a few custom base c\", \"lasses like Entity, ValueObject, and Enumeration, plus a few\\ninterfaces. These interfaces (IReposito\", \"ry and IUnitOfWork) inform the infrastructure layer about what\\nneeds to be implemented. Those interf\", \"aces are also used through Dependency Injection from the\\napplication layer.\\n\\n4 it! SeedWork\\n> aC* En\", \"tity.cs\\na C* Enumeration.cs\\na C* |AggregateRoot.cs\\na C* |Repository.cs\\na C* |UnitOfWork.cs\\na C* Valu\", \"eObject.cs\\n\\nVV VV YW\\n\\nFigure 7-12. A sample set of domain model \\u201cseedwork\\\" base classes and interfac\", \"es\\n\\nThis is the type of copy and paste reuse that many developers share between projects, not a form\", \"al\\nframework. You can have seedworks in any layer or library. However, if the set of classes and\\nint\", \"erfaces gets large enough, you might want to create a single class library.\\n\\n210 CHAPTER 6 | Tackle \", \"Business Complexity in a Microservice with DDD and CQRS Patterns\\nThe custom Entity base class\\n\\nThe f\", \"ollowing code is an example of an Entity base class where you can place code that can be used\\nthe sa\", \"me way by any domain entity, such as the entity ID, equality operators, a domain event list per\\nenti\", \"ty, etc.\\n\\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE (1.1 and later)\\npublic abstract class Entity\\n{\\n\\ni\", \"nt? _requestedHashCode;\\n\\nint Id;\\n\\nprivate List<INotification> _domainEvents;\\n\\npublic virtual int Id\\n\", \"\\n{\\nget\\n{\\nreturn Id;\\n}\\nprotected set\\n{\\n_Id = value;\\n}\\n}\\n\\npublic List<INotification> DomainEvents => _\", \"domainEvents;\\npublic void AddDomainEvent(INotification eventItem)\\n\\nt\\n\\n_domainEvents = _domainEvents \", \"?? new List<INotification>();\\n_domainEvents.Add(eventItem) ;\\n\\npublic void RemoveDomainEvent(INotific\", \"ation eventItem)\\n\\n{\\nif (_domainEvents is null) return;\\n_domainEvents.Remove(eventItem) ;\\n}\\npublic bo\", \"ol IsTransient()\\n{\\nreturn this.Id == default(Int32) ;\\n}\\npublic override bool Equals(object obj)\\n{\\nif\", \" (obj == null || !(obj is Entity))\\nreturn false;\\nif (Object.ReferenceEquals(this, obj) )\\nreturn true\", \";\\nif (this.GetType() != obj.GetType())\\nreturn false;\\nEntity item = (Entity)obj;\\nif (item.IsTransient\", \"() || this.IsTransient() )\\nreturn false;\\nelse\\nreturn item.Id == this.Id;\\n}\\n\\npublic override int GetH\", \"ashCode( )\\n\\nt\\nif (!IsTransient() )\\n\\n211 CHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns\\nif (! requestedHashCode.HasValue)\\n_requestedHashCode = this.Id.GetHashCode()\", \" * 31;\\n// XOR for random distribution. See:\\n// https://learn.microsoft.com/archive/blogs/ericlippert\", \"/guidelines-and-rules -\\nfor-gethashcode\\nreturn _requestedHashCode. Value;\\n}\\nelse\\nreturn base.GetHash\", \"Code() ;\\n\\n}\\npublic static bool operator ==(Entity left, Entity right)\\n\\nif (Object.Equals(left, null)\", \" )\\n\\nreturn (Object.Equals(right, null));\\nelse\\n\\nreturn left.Equals(right) ;\\n\\npublic static bool opera\", \"tor !=(Entity left, Entity right)\\n\\n{\\nreturn !(left == right);\\n\\n}\\n\\nThe previous code using a domain e\", \"vent list per entity will be explained in the next sections when\\nfocusing on domain events.\\n\\nReposit\", \"ory contracts (interfaces) in the domain model layer\\n\\nRepository contracts are simply .NET interface\", \"s that express the contract requirements of the\\nrepositories to be used for each aggregate.\\n\\nThe rep\", \"ositories themselves, with EF Core code or any other infrastructure dependencies and code\\n(Ling, SQL\", \", etc.), must not be implemented within the domain model; the repositories should only\\nimplement the\", \" interfaces you define in the domain model.\\n\\nA pattern related to this practice (placing the reposit\", \"ory interfaces in the domain model layer) is the\\nSeparated Interface pattern. As explained by Martin\", \" Fowler, \\u201cUse Separated Interface to define an\\ninterface in one package but implement it in another.\", \" This way a client that needs the dependency to\\nthe interface can be completely unaware of the imple\", \"mentation.\\u201d\\n\\nFollowing the Separated Interface pattern enables the application layer (in this case, \", \"the Web API\\nproject for the microservice) to have a dependency on the requirements defined in the do\", \"main model,\\nbut not a direct dependency to the infrastructure/persistence layer. In addition, you ca\", \"n use\\nDependency Injection to isolate the implementation, which is implemented in the infrastructure\", \"/\\npersistence layer using repositories.\\n\\nFor example, the following example with the lOrderRepositor\", \"y interface defines what operations the\\nOrderRepository class will need to implement at the infrastr\", \"ucture layer. In the current\\nimplementation of the application, the code just needs to add or update\", \" orders to the database, since\\nqueries are split following the simplified CQRS approach.\\n\\n// Defined\", \" at IOrderRepository.cs\\npublic interface IOrderRepository : IRepository<Order>\\n\\n{\\n\\n212 CHAPTER 6 | T\", \"ackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nOrder Add(Order order) ;\\nvoid\", \" Update(Order order) ;\\n\\nTask<Order> GetAsync(int orderId) ;\\n}\\n\\n// Defined at IRepository.cs (Part of\", \" the Domain Seedwork)\\npublic interface IRepository<T> where T : IAggregateRoot\\n\\n{\\nTUnitOfWork UnitOf\", \"Work { get; }\\n\\n}\\n\\nAdditional resources\\n\\n\\u00b0 Martin Fowler. Separated Interface.\\n\\nhttps://www.martinfow\", \"ler.com/eaaCatalog/separatedinterface.htm!\\n\\nImplement value objects\\n\\nAs discussed in earlier section\", \"s about entities and aggregates, identity is fundamental for entities.\\nHowever, there are many objec\", \"ts and data items in a system that do not require an identity and\\nidentity tracking, such as value o\", \"bjects.\\n\\nA value object can reference other entities. For example, in an application that generates \", \"a route that\\ndescribes how to get from one point to another, that route would be a value object. It \", \"would be a\\nsnapshot of points on a specific route, but this suggested route would not have an identi\", \"ty, even\\nthough internally it might refer to entities like City, Road, etc.\\n\\nFigure 7-13 shows the A\", \"ddress value object within the Order aggregate.\\n\\n213 CHAPTER 6 | Tackle Business Complexity in a Mic\", \"roservice with DDD and CQRS Patterns\\nValue Object within Aggregate\\n\\nAddress (Value-Object)\\n\\nAttribut\", \"es\\nStreet\\nCity\\n\\nAttributes\\nID\\nOrderDate\\n\\n[BuyerlD]\\n[Address]\\n[Orderltems]\\n\\nOrderltem (child Entity)\\n\", \"\\nMethods Attributes\\n\\nOrder(params) constructor ID\\nAddOrderltem(item) ProductID\\nSetAddress(address) P\", \"rice\\n\\nCalculate Total()\\n\\nMethods\\nPrivate methods...\\n\\nFigure 7-13. Address value object within the Or\", \"der aggregate\\n\\nAs shown in Figure 7-13, an entity is usually composed of multiple attributes. For ex\", \"ample, the Order\\nentity can be modeled as an entity with an identity and composed internally of a se\", \"t of attributes such\\nas Orderld, OrderDate, Orderltems, etc. But the address, which is simply a comp\", \"lex-value composed of\\ncountry/region, street, city, etc., and has no identity in this domain, must b\", \"e modeled and treated as a\\nvalue object.\\n\\nImportant characteristics of value objects\\n\\nThere are two \", \"main characteristics for value objects:\\n. They have no identity.\\n. They are immutable.\\n\\nThe first ch\", \"aracteristic was already discussed. Immutability is an important requirement. The values of\\na value \", \"object must be immutable once the object is created. Therefore, when the object is\\n\\n214 CHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nconstructed, you must provid\", \"e the required values, but you must not allow them to change during the\\nobject's lifetime.\\n\\nValue ob\", \"jects allow you to perform certain tricks for performance, thanks to their immutable nature.\\nThis is\", \" especially true in systems where there may be thousands of value object instances, many of\\nwhich ha\", \"ve the same values. Their immutable nature allows them to be reused; they can be\\ninterchangeable obj\", \"ects, since their values are the same and they have no identity. This type of\\noptimization can somet\", \"imes make a difference between software that runs slowly and software with\\ngood performance. Of cour\", \"se, all these cases depend on the application environment and deployment\\ncontext.\\n\\nValue object impl\", \"ementation in C#\\n\\nIn terms of implementation, you can have a value object base class that has basic \", \"utility methods like\\nequality based on the comparison between all the attributes (since a value obje\", \"ct must not be based\\non identity) and other fundamental characteristics. The following example shows\", \" a value object base\\nclass used in the ordering microservice from eShopOnContainers.\\n\\npublic abstrac\", \"t class ValueObject\\n\\naf\\nprotected static bool EqualOperator(ValueObject left, ValueObject right)\\n\\nif\", \" (ReferenceEquals(left, null) *\\u201c ReferenceEquals(right, null) )\\n{\\n\\nreturn false;\\n\\nreturn ReferenceEq\", \"uals(left, right) || left.Equals(right) ;\\n}\\n\\nprotected static bool NotEqualOperator(ValueObject left\", \", ValueObject right)\\n{\\n\\n}\\n\\nreturn !(EqualOperator(left, right));\\n\\nprotected abstract IEnumerable<obj\", \"ect> GetEqualityComponents() ;\\n\\npublic override bool Equals(object obj)\\nt\\n\\nif (obj == null || obj.Ge\", \"tType() != GetType())\\n{\\n\\n}\\n\\nreturn false;\\n\\nvar other = (ValueObject)obj;\\n\\nreturn this.GetEqualityCom\", \"ponents().SequenceEqual(other.GetEqualityComponents() );\\n}\\n\\npublic override int GetHashCode( )\\n{\\nret\", \"urn GetEqualityComponents()\\n.Select(x => x != null ? x.GetHashCode() : @)\\n-Aggregate((x, y) => x * y\", \");\\n}\\n// Other utility methods\\n\\n215 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS Patterns\\nThe ValueObject is an abstract class type, but in this example, it doesn't overlo\", \"ad the == and !=\\noperators. You could choose to do so, making comparisons delegate to the Equals ove\", \"rride. For\\nexample, consider the following operator overloads to the ValueObject type:\\n\\npublic stati\", \"c bool operator ==(ValueObject one, ValueObject two)\\n{\\n\\n}\\n\\nreturn EqualOperator(one, two);\\n\\npublic s\", \"tatic bool operator !=(ValueObject one, ValueObject two)\\n{\\n\\n}\\n\\nYou can use this class when implement\", \"ing your actual value object, as with the Address\\nvalue object shown in the following example:\\n\\npubl\", \"ic class Address : ValueObject\\n\\n{\\n\\nreturn NotEqualOperator(one, two);\\n\\npublic String Street { get; p\", \"rivate set; }\\npublic String City { get; private set; }\\npublic String State { get; private set; }\\npub\", \"lic String Country { get; private set; }\\npublic String ZipCode { get; private set; }\\n\\npublic Address\", \"() { }\\n\\npublic Address(string street, string city, string state, string country, string\\nzipcode)\\n\\nSt\", \"reet = street;\\nCity = city;\\n\\nState = state;\\nCountry = country;\\nZipCode = zipcode;\\n\\n}\\n\\nprotected over\", \"ride IEnumerable<object> GetEqualityComponents()\\n{\\n// Using a yield return statement to return each \", \"element one at a time\\nyield return Street;\\nyield return City;\\nyield return State;\\nyield return Count\", \"ry;\\nyield return ZipCode;\\n\\nThis value object implementation of Address has no identity, and therefor\", \"e no ID field is defined for it,\\neither in the Address class definition or the ValueObject class def\", \"inition.\\n\\nHaving no ID field in a class to be used by Entity Framework (EF) was not possible until E\", \"F Core 2.0,\\nwhich greatly helps to implement better value objects with no ID. That is precisely the \", \"explanation of\\nthe next section.\\n\\nIt could be argued that value objects, being immutable, should be \", \"read-only (that is, have get-only\\nproperties), and that's indeed true. However, value objects are us\", \"ually serialized and deserialized to go\\n\\n216 CHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS Patterns\\nthrough message queues, and being read-only stops the deserializer from\", \" assigning values, so you\\njust leave them as private set, which is read-only enough to be practical.\", \"\\n\\nValue object comparison semantics\\n\\nTwo instances of the Address type can be compared using all the\", \" following methods:\\n\\nvar one = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98@52\\\");\\nvar t\", \"wo = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98@52\\\");\\n\\nConsole.WriteLine(EqualityComp\", \"arer<Address>.Default.Equals(one, two)); // True\\nConsole.WriteLine(object.Equals(one, two)); // True\", \"\\nConsole.WriteLine(one.Equals(two)); // True\\n\\nConsole.WriteLine(one == two); // True\\n\\nWhen all the v\", \"alues are the same, the comparisons are correctly evaluated as true. If you didn't choose\\nto overloa\", \"d the == and != operators, then the last comparison of one == two would evaluate as false.\\n\\nFor more\", \" information, see Overload ValueObject equality operators.\\n\\nHow to persist value objects in the data\", \"base with EF Core 2.0 and later\\n\\nYou just saw how to define a value object in your domain model. But\", \" how can you actually persist it\\ninto the database using Entity Framework Core since it usually targ\", \"ets entities with identity?\\n\\nBackground and older approaches using EF Core 1.1\\n\\nAs background, a lim\", \"itation when using EF Core 1.0 and 1.1 was that you could not use complex types\\nas defined in EF 6.x\", \" in the traditional .NET Framework. Therefore, if using EF Core 1.0 or 1.1, you\\nneeded to store your\", \" value object as an EF entity with an ID field. Then, so it looked more like a value\\nobject with no \", \"identity, you could hide its ID so you make clear that the identity of a value object is\\nnot importa\", \"nt in the domain model. You could hide that ID by using the ID as a shadow property.\\nSince that conf\", \"iguration for hiding the ID in the model is set up in the EF infrastructure level, it would\\nbe kind \", \"of transparent for your domain model.\\n\\nIn the initial version of eshopOnContainers (.NET Core 1.1), \", \"the hidden ID needed by EF Core\\ninfrastructure was implemented in the following way in the DbContext\", \" level, using Fluent API at the\\ninfrastructure project. Therefore, the ID was hidden from the domain\", \" model point of view, but still\\npresent in the infrastructure.\\n\\n// Old approach with EF Core 1.1\\n// \", \"Fluent API within the OrderingContext:DbContext in the Infrastructure project\\n\\nvoid ConfigureAddress\", \"(EntityTypeBuilder<Address> addressConfiguration)\\n\\n{\\naddressConfiguration.ToTable(\\\"address\\\", DEFAULT\", \" SCHEMA) ;\\n\\naddressConfiguration.Property<int>(\\\"Id\\\") // Id is a shadow property\\n. [sRequired() ;\\nadd\", \"ressConfiguration.HasKey(\\\"Id\\\") ; // Id is a shadow property\\n\\nHowever, the persistence of that value \", \"object into the database was performed like a regular entity in\\na different table.\\n\\n217 CHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nWith EF Core 2.0 and later, \", \"there are new and better ways to persist value objects.\\n\\nPersist value objects as owned entity types\", \" in EF Core 2.0 and later\\n\\nEven with some gaps between the canonical value object pattern in DDD and\", \" the owned entity type in\\nEF Core, it\\u2019s currently the best way to persist value objects with EF Core\", \" 2.0 and later. You can see\\nlimitations at the end of this section.\\n\\nThe owned entity type feature w\", \"as added to EF Core since version 2.0.\\n\\nAn owned entity type allows you to map types that do not hav\", \"e their own identity explicitly defined in\\nthe domain model and are used as properties, such as a va\", \"lue object, within any of your entities. An\\nowned entity type shares the same CLR type with another \", \"entity type (that Is, it\\u2019s just a regular class).\\nThe entity containing the defining navigation is t\", \"he owner entity. When querying the owner, the\\nowned types are included by default.\\n\\nJust by looking \", \"at the domain model, an owned type looks like it doesn't have any identity. However,\\nunder the cover\", \"s, owned types do have the identity, but the owner navigation property is part of this\\nidentity.\\n\\nTh\", \"e identity of instances of owned types is not completely their own. It consists of three components:\", \"\\n\\n. The identity of the owner\\n. The navigation property pointing to them\\n\\n. In the case of collectio\", \"ns of owned types, an independent component (supported in EF Core\\n2.2 and later).\\n\\nFor example, in t\", \"he Ordering domain model at eShopOnContainers, as part of the Order entity, the\\nAddress value object\", \" is implemented as an owned entity type within the owner entity, which is the\\nOrder entity. Address \", \"is a type with no identity property defined in the domain model. It is used as a\\nproperty of the Ord\", \"er type to specify the shipping address for a particular order.\\n\\nBy convention, a shadow primary key\", \" is created for the owned type and it will be mapped to the same\\ntable as the owner by using table s\", \"plitting. This allows to use owned types similarly to how complex\\ntypes are used in EF6 in the tradi\", \"tional .NET Framework.\\n\\nIt is important to note that owned types are never discovered by convention \", \"in EF Core, so you have\\nto declare them explicitly.\\n\\nIn eShopOnContainers, in the OrderingContext.cs\", \" file, within the OnModelCreating() method, multiple\\ninfrastructure configurations are applied. One \", \"of them is related to the Order entity.\\n\\n// Part of the OrderingContext.cs class at the Ordering.Inf\", \"rastructure project\\n\\n//\\nprotected override void OnModelCreating(ModelBuilder modelBuilder)\\n\\n{\\nmodelB\", \"uilder .ApplyConfiguration(new ClientRequestEntityTypeConfiguration() );\\n\\nmodelBuilder .ApplyConfigu\", \"ration(new PaymentMethodEntityTypeConfiguration() );\\nmodelBuilder .ApplyConfiguration(new OrderEntit\", \"yTypeConfiguration() ) ;\\nmodelBuilder .ApplyConfiguration(new OrderItemEntityTypeConfiguration() );\\n\", \"//...Additional type configurations\\n\\n218 CHAPTER 6 | Tackle Business Complexity in a Microservice wi\", \"th DDD and CQRS Patterns\\nIn the following code, the persistence infrastructure Is defined for the Or\", \"der entity:\\n\\n// Part of the OrderEntityTypeConfiguration.cs class\\n\\n//\\npublic void Configure(EntityTy\", \"peBuilder<Order> orderConfiguration)\\n\\nt\\n\\norderConfiguration. ToTable(\\\"orders\\\", OrderingContext.DEFAU\", \"LT SCHEMA) ;\\n\\norderConfiguration.HasKey(o => o.Id);\\n\\norderConfiguration.Ignore(b => b.DomainEvents) \", \";\\n\\norderConfiguration.Property(o => o.Id)\\n.ForSqlServerUseSequenceHiLo(\\\"orderseg\\\", OrderingContext.D\", \"EFAULT SCHEMA) ;\\n\\n//Address value object persisted as owned entity in EF Core 2.0\\norderConfiguration\", \".OwnsOne(o => o.Address) ;\\n\\norderConfiguration.Property<DateTime>(\\\"OrderDate\\\") .IsRequired() ;\\n\\n//..\", \".Additional validations, constraints and code...\\n\\nHi ooc\\n\\nIn the previous code, the orderConfigurati\", \"on.OwnsOne(o => o.Address) method specifies that the\\nAddress property is an owned entity of the Orde\", \"r type.\\n\\nBy default, EF Core conventions name the database columns for the properties of the owned e\", \"ntity\\ntype as EntityProperty_OwnedEntityProperty. Therefore, the internal properties of Address will\", \" appear\\nin the Orders table with the names Address_Street, Address_City (and so on for State, Countr\", \"y, and\\nZipCode).\\n\\nYou can append the Property().HasColumnName() fluent method to rename those column\", \"s. In the\\ncase where Address is a public property, the mappings would be like the following:\\n\\norderC\", \"onfiguration.OwnsOne(p => p.Address)\\n.Property(p=>p.Street) .HasColumnName(\\\"ShippingStreet\\\" ) ;\\n\\nord\", \"erConfiguration.OwnsOne(p => p.Address)\\n.Property(p=>p.City) .HasColumnName(\\\"ShippingCity\\\") ;\\n\\nIt's \", \"possible to chain the OwnsOne method in a fluent mapping. In the following hypothetical\\nexample, Ord\", \"erDetails owns BillingAddress and ShippingAddress, which are both Address types. Then\\nOrderDetails i\", \"s owned by the Order type.\\n\\norderConfiguration.OwnsOne(p => p.OrderDetails, cb =>\\n\\n{\\ncb.OwnsOne(c =>\", \" c.BillingAddress) ;\\ncb.OwnsOne(c => c.ShippingAddress) ;\\n})3\\nrr\\n//.\\npublic class Order\\n{\\n\\npublic in\", \"t Id { get; set; }\\npublic OrderDetails OrderDetails { get; set; }\\n}\\n\\npublic class OrderDetails\\n\\n{\\npu\", \"blic Address BillingAddress { get; set; }\\n\\n219 CHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS Patterns\\npublic Address ShippingAddress { get; set; }\\n}\\n\\npublic class Address\\n\", \"\\n{\\n\\npublic string Street { get; set; }\\npublic string City { get; set; }\\n\\nAdditional details on owned\", \" entity types\\n\\n. Owned types are defined when you configure a navigation property to a particular ty\", \"pe using\\nthe OwnsOne fluent API.\\n\\n. The definition of an owned type in our metadata model is a compo\", \"site of: the owner type, the\\nnavigation property, and the CLR type of the owned type.\\n\\n. The identit\", \"y (key) of an owned type instance in our stack is a composite of the identity of the\\nowner type and \", \"the definition of the owned type.\\n\\nOwned entities capabilities\\n\\n\\u00b0 Owned types can reference other en\", \"tities, either owned (nested owned types) or non-owned\\n(regular reference navigation properties to o\", \"ther entities).\\n\\n. You can map the same CLR type as different owned types in the same owner entity t\", \"hrough\\nseparate navigation properties.\\n\\n. Table splitting is set up by convention, but you can opt o\", \"ut by mapping the owned type to a\\ndifferent table using ToTable.\\n\\n. Eager loading is performed autom\", \"atically on owned types, that is, there\\u2019s no need to call\\nInclude() on the query.\\n\\n. Can be configur\", \"ed with attribute [Owned], using EF Core 2.1 and later.\\n\\n. Can handle collections of owned types (us\", \"ing version 2.2 and later).\\n\\nOwned entities limitations\\n. You can't create a DbSet<T> of an owned ty\", \"pe (by design).\\n. You can't call ModelBuilder.Entity<T>() on owned types (currently by design).\\n\\n. N\", \"o support for optional (that is, nullable) owned types that are mapped with the owner in the\\nsame ta\", \"ble (that is, using table splitting). This is because mapping is done for each property,\\nthere is no\", \" separate sentinel for the null complex value as a whole.\\n\\n. No inheritance-mapping support for owne\", \"d types, but you should be able to map two leaf\\ntypes of the same inheritance hierarchies as differe\", \"nt owned types. EF Core will not reason\\nabout the fact that they are part of the same hierarchy.\\n\\n22\", \"0 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nMain differenc\", \"es with EF6\\u2019s complex types\\n\\nTable splitting is optional, that is, they can optionally be mapped to \", \"a separate table and still\\nbe owned types.\\n\\nAdditional resources\\n\\nMartin Fowler. ValueObject pattern\", \"\\n\\nhttps://martinfowler.com/bliki/ValueObject.html\\n\\nEric Evans. Domain-Driven Design: Tackling Comple\", \"xity in the Heart of Software. (Book;\\n\\nincludes a discussion of value objects)\\nhttos://www.amazon.co\", \"m/Domain-Driven-Design-Tackling-Complexity-\\n\\nSoftware/dp/0321125215/\\n\\nVaughn Vernon. Implementing Do\", \"main-Driven Design. (Book; includes a discussion of\\nvalue objects)\\nhttps://www.amazon.com/Implementi\", \"ng-Domain-Driven-Design-Vaughn-\\n\\nVernon/dp/0321834577/\\n\\nOwned Entity Types\\nhttps://learn.microsoft.c\", \"om/ef/core/modeling/owned-entities\\n\\nShadow Properties\\n\\nhttps://learn.microsoft.com/ef/core/modeling/\", \"shadow-properties\\n\\nComplex types and/or value objects. Discussion in the EF Core GitHub repo (Issues\", \" tab)\\n\\nhttps://github.com/dotnet/efcore/issues/246\\n\\nValueObject.cs. Base value object class in eshop\", \"OnContainers.\\n\\nhttps://github.com/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Services/Order\", \"ing/Ordering.Domain/SeedWor\\nk/ValueObject.cs\\n\\nValueObject.cs. Base value object class in CSharpFunct\", \"ionalExtensions.\\n\\nhttps://github.com/vkhorikov/CSharpFunctionalExtensions/blob/master/CSharpFunction\", \"alExte\\nnsions/ValueObject/ValueObject.cs\\n\\nAddress class. Sample value object class in eshopOnContain\", \"ers.\\n\\nhttps://github.com/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Order\", \"ing.Domain/Aggregat\\nesModel/OrderAggregate/Address.cs\\n\\nUse enumeration classes instead of enum types\", \"\\n\\nEnumerations (or enum types for short) are a thin language wrapper around an integral type. You\\nmi\", \"ght want to limit their use to when you are storing one value from a closed set of values.\\n\\nClassifi\", \"cation based on sizes (small, medium, large) is a good example. Using enums for control flow\\n\\nor mor\", \"e robust abstractions can be a code smell. This type of usage leads to fragile code with many\\n\\ncontr\", \"ol flow statements checking values of the enum.\\n\\n221\\n\\nCHAPTER 6 | Tackle Business Complexity in a Mi\", \"croservice with DDD and CQRS Patterns\\nInstead, you can create Enumeration classes that enable all th\", \"e rich features of an object-oriented\\nlanguage.\\n\\nHowever, this isn\\u2019t a critical topic and in many ca\", \"ses, for simplicity, you can still use regular enum\\ntypes if that\\u2019s your preference. The use of enum\", \"eration classes is more related to business-related\\nconcepts.\\n\\nImplement an Enumeration base class\\n\\n\", \"The ordering microservice in eshopOnContainers provides a sample Enumeration base class\\nimplementati\", \"on, as shown in the following example:\\npublic abstract class Enumeration : IComparable\\n{\\npublic stri\", \"ng Name { get; private set; }\\npublic int Id { get; private set; }\\nprotected Enumeration(int id, stri\", \"ng name) => (Id, Name) = (id, name);\\npublic override string ToString() => Name;\\npublic static IEnume\", \"rable<T> GetAl1l<T>() where T : Enumeration =>\\ntypeof (T).GetFields(BindingFlags.Public |\\nBindingFla\", \"gs.Static |\\nBindingF lags .DeclaredOnly )\\n.Select(f => \\u00a3.GetValue(null1) )\\n.Cast<T>();\\npublic overri\", \"de bool Equals(object obj)\\n\\nif (obj is not Enumeration otherValue)\\n\\nt\\n}\\n\\nreturn false;\\n\\nvar typeMatc\", \"hes = GetType().Equals(obj.GetType());\\nvar valueMatches = Id.Equals(otherValue.Id) ;\\n\\nreturn typeMat\", \"ches && valueMatches;\\n}\\n\\npublic int CompareTo(object other) => Id.CompareTo(((Enumeration)other) .Id\", \") ;\\n\\n// Other utility methods ...\\n}\\nYou can use this class as a type in any entity or value object, \", \"as for the following\\nCardType : Enumeration class:\\npublic class CardType\\n: Enumeration\\n{\\npublic stat\", \"ic CardType Amex = new(1, nameof(Amex) );\\npublic static CardType Visa = new(2, nameof(Visa));\\npublic\", \" static CardType MasterCard = new(3, nameof(MasterCard) ) ;\\n\\npublic CardType(int id, string name)\\n\\n:\", \" base(id, name)\\n\\nt\\n\\n222 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS P\", \"atterns\\nhe |\\n\\nAdditional resources\\n\\n\\u00b0 Jimmy Bogard. Enumeration classes\\n\\nhttps://lostechies.com/jimm\", \"ybogard/2008/08/12/enumeration-classes/\\n\\n\\u00b0 Steve Smith. Enum Alternatives in C#\\n\\nhttps://ardalis.com\", \"/enum-alternatives-in-c\\n\\n. Enumeration.cs. Base Enumeration class in eshopOnContainers\\n\\nhttps://gith\", \"ub.com/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\", \"\\nk/Enumeration.cs\\n\\n. CardType.cs. Sample Enumeration class in eshopOnContainers.\\n\\nhttps://github.com\", \"/dotnet-\\narchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesMo\", \"del/BuyerAggregate/CardType.cs\\n\\n. SmartEnum. Ardalis - Classes to help produce strongly typed smarte\", \"r enums in .NET.\\n\\nhttps://www.nuget.org/packages/Ardalis.SmartEnum/\\n\\nDesign validations in the domai\", \"n model layer\\n\\nIn DDD, validation rules can be thought as invariants. The main responsibility of an \", \"aggregate is to\\nenforce invariants across state changes for all the entities within that aggregate.\\n\", \"\\nDomain entities should always be valid entities. There are a certain number of invariants for an ob\", \"ject\\nthat should always be true. For example, an order item object always has to have a quantity tha\", \"t must\\nbe a positive integer, plus an article name and price. Therefore, invariants enforcement is t\", \"he\\nresponsibility of the domain entities (especially of the aggregate root) and an entity object sho\", \"uld not\\nbe able to exist without being valid. Invariant rules are simply expressed as contracts, and\", \" exceptions\\nor notifications are raised when they are violated.\\n\\nThe reasoning behind this is that m\", \"any bugs occur because objects are in a state they should never\\nhave been in.\\n\\nLet's propose we now \", \"have a SendUserCreationEmailService that takes a UserProfile ... how can we\\nrationalize in that serv\", \"ice that Name is not null? Do we check it again? Or more likely ... you just don't\\nbother to check a\", \"nd \\u201chope for the best\\u201d\\u2014you hope that someone bothered to validate it before\\nsending it to you. Of co\", \"urse, using TDD one of the first tests we should be writing is that if | send a\\ncustomer with a null\", \" name that it should raise an error. But once we start writing these kinds of tests\\nover and over ag\", \"ain we realize ... \\u201cwhat if we never allowed name to become null? we wouldn't have\\nall of these test\", \"s!\\u201d.\\n\\n223 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nImplem\", \"ent validations in the domain model layer\\n\\nValidations are usually implemented in domain entity cons\", \"tructors or in methods that can update the\\nentity. There are multiple ways to implement validations,\", \" such as verifying data and raising exceptions\\nif the validation fails. There are also more advanced\", \" patterns such as using the Specification pattern\\nfor validations, and the Notification pattern to r\", \"eturn a collection of errors instead of returning an\\nexception for each validation as it occurs.\\n\\nVa\", \"lidate conditions and throw exceptions\\n\\nThe following code example shows the simplest approach to va\", \"lidation in a domain entity by raising\\nan exception. In the references table at the end of this sect\", \"ion you can see links to more advanced\\nimplementations based on the patterns we have discussed previ\", \"ously.\\n\\npublic void SetAddress(Address address)\\n{\\n\\n}\\n\\nA better example would demonstrate the need to\", \" ensure that either the internal state did\\nnot change, or that all the mutations for a method occurr\", \"ed. For example, the following\\nimplementation would leave the object in an invalid state:\\npublic voi\", \"d SetAddress(string line1, string line2,\\n\\nstring city, string state, int zip)\\n\\n_shippingAddress = ad\", \"dress?? throw new ArgumentNullException(nameof(address) ) ;\\n\\n{\\n_shippingAddress.linel = linel ?? thr\", \"ow new ...\\n_shippingAddress.line2 = line2;\\n_shippingAddress.city = city ?? throw new ...\\n_shippingAd\", \"dress.state = (IsValid(state) ? state : throw new ...);\\n\\nIf the value of the state is invalid, the f\", \"irst address line and the city have already been changed. That\\nmight make the address invalid.\\n\\nA si\", \"milar approach can be used in the entity's constructor, raising an exception to make sure that the\\ne\", \"ntity is valid once it is created.\\n\\nUse validation attributes in the model based on data annotations\", \"\\n\\nData annotations, like the Required or MaxLength attributes, can be used to configure EF Core\\ndata\", \"base field properties, as explained in detail in the Table mapping section, but they no longer work\\n\", \"\\nfor entity validation in EF Core (neither does the |ValidatableObject.Validate method), as they hav\", \"e\\ndone since EF 4.x in .NET Framework.\\n\\nData annotations and the !ValidatableObject interface can st\", \"ill be used for model validation during\\nmodel binding, prior to the controller's actions invocation \", \"as usual, but that model is meant to be a\\nViewModel or DTO and that's an MVC or API concern not a do\", \"main model concern.\\n\\nHaving made the conceptual difference clear, you can still use data annotations\", \" and\\nIValidatableObject in the entity class for validation, if your actions receive an entity class \", \"object\\nparameter, which is not recommended. In that case, validation will occur upon model binding, \", \"just\\nbefore invoking the action and you can check the controller's ModelState.IsValid property to ch\", \"eck\\n\\n224 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nthe res\", \"ult, but then again, it happens in the controller, not before persisting the entity object in the\\nDb\", \"Context, as it had done since EF 4.x.\\n\\nYou can still implement custom validation in the entity class\", \" using data annotations and the\\nIValidatableObject.Validate method, by overriding the DbContext's Sa\", \"veChanges method.\\n\\nYou can see a sample implementation for validating IValidatableObject entities in\", \" this comment on\\nGitHub. That sample doesn't do attribute-based validations, but they should be easy\", \" to implement\\nusing reflection in the same override.\\n\\nHowever, from a DDD point of view, the domain \", \"model is best kept lean with the use of exceptions in\\nyour entity's behavior methods, or by implemen\", \"ting the Specification and Notification patterns to\\nenforce validation rules.\\n\\nIt can make sense to \", \"use data annotations at the application layer in ViewModel classes (instead of\\ndomain entities) that\", \" will accept input, to allow for model validation within the UI layer. However, this\\nshould not be d\", \"one at the exclusion of validation within the domain model.\\n\\nValidate entities by implementing the S\", \"pecification pattern and the Notification\\npattern\\nFinally, a more elaborate approach to implementing\", \" validations in the domain model is by\\n\\nimplementing the Specification pattern in conjunction with t\", \"he Notification pattern, as explained in\\nsome of the additional resources listed later.\\n\\nIt is worth\", \" mentioning that you can also use just one of those patterns\\u2014for example, validating\\nmanually with c\", \"ontrol statements, but using the Notification pattern to stack and return a list of\\nvalidation error\", \"s.\\n\\nUse deferred validation in the domain\\n\\nThere are various approaches to deal with deferred valida\", \"tions in the domain. In his book\\nImplementing Domain-Driven Design, Vaughn Vernon discusses these in\", \" the section on validation.\\n\\nTwo-step validation\\n\\nAlso consider two-step validation. Use field-level\", \" validation on your command Data Transfer Objects\\n(DTOs) and domain-level validation inside your ent\", \"ities. You can do this by returning a result object\\ninstead of exceptions in order to make it easier\", \" to deal with the validation errors.\\n\\nUsing field validation with data annotations, for example, you\", \" do not duplicate the validation\\ndefinition. The execution, though, can be both server-side and clie\", \"nt-side in the case of DTOs\\n(commands and ViewModels, for instance).\\n\\nAdditional resources\\n\\n. Rachel\", \" Appel. Introduction to model validation in ASP.NET Core MVC\\nhttps://learn.microsoft.com/aspnet/core\", \"/mvc/models/validation\\n\\n. Rick Anderson. Adding validation\\nhttps://learn.microsoft.com/aspnet/core/t\", \"utorials/first-mvc-app/validation\\n225 CHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patterns\\n\\u00b0 Martin Fowler. Replacing Throwing Exceptions with Notification in Validation\", \"s\\n\\nhttps://martinfowler.com/articles/replaceThrowWithNotification.html\\n\\n. Specification and Notifica\", \"tion Patterns\\nhttos://www.codeproject.com/Tips/790758/Specification-and-Notification-Patterns\\n\\n\\u00b0 Lev\", \" Gorodinski. Validation in Domain-Driven Design (DDD)\\nhttp://qorodinski.com/blog/2012/05/19/validati\", \"on-in-domain-driven-design-ddd\\n\\n\\u00b0 Colin Jack. Domain Model Validation\\n\\nhttps://colinjack.blogspot.co\", \"m/2008/03/domain-model-validation.html\\n\\u00b0 Jimmy Bogard. Validation i in a DDD world\\n\\nClient-side vali\", \"dation (validation in the presentation\\nlayers)\\n\\nEven when the source of truth is the domain model an\", \"d ultimately you must have validation at the\\ndomain model level, validation can still be handled at \", \"both the domain model level (server side) and\\nthe UI (client side).\\n\\nClient-side validation is a gre\", \"at convenience for users. It saves time they would otherwise spend\\nwaiting for a round trip to the s\", \"erver that might return validation errors. In business terms, even a few\\nfractions of seconds multip\", \"lied hundreds of times each day adds up to a lot of time, expense, and\\nfrustration. Straightforward \", \"and immediate validation enables users to work more efficiently and\\nproduce better quality input and\", \" output.\\n\\nJust as the view model and the domain model are different, view model validation and domai\", \"n model\\nvalidation might be similar but serve a different purpose. If you are concerned about DRY (t\", \"he Don't\\nRepeat Yourself principle), consider that in this case code reuse might also mean coupling,\", \" and in\\nenterprise applications it is more important not to couple the server side to the client sid\", \"e than to\\nfollow the DRY principle.\\n\\nEven when using client-side validation, you should always valid\", \"ate your commands or input DTOs in\\nserver code, because the server APIs are a possible attack vector\", \". Usually, doing both is your best bet\\nbecause if you have a client application, from a UX perspecti\", \"ve, it is best to be proactive and not allow\\nthe user to enter invalid information.\\n\\nTherefore, in c\", \"lient-side code you typically validate the ViewModels. You could also validate the client\\noutput DTO\", \"s or commands before you send them to the services.\\n\\nThe implementation of client-side validation de\", \"pends on what kind of client application you are\\nbuilding. It will be different if you are validatin\", \"g data in a web MVC web application with most of the\\ncode in .NET, a SPA web application with that v\", \"alidation being coded in JavaScript or TypeScript, or a\\nmobile app coded with Xamarin and C#.\\n\\n226 C\", \"HAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nAdditional resour\", \"ces\\n\\nValidation in Xamarin mobile apps\\n\\nValidate Text Input and Show Errors\\n\\nhttps://developer.xamar\", \"in.com/recipes/ios/standard controls/text field/validate input/\\n\\nValidation Callback\\n\\nhttps://develo\", \"per.xamarin.com/samples/xamarin-forms/XAML/ValidationCallback/\\n\\nValidation in ASP.NET Core apps\\n\\nRic\", \"k Anderson. Adding validation\\n\\nhttps://learn.microsoft.com/aspnet/core/tutorials/first-mvc-app/valid\", \"ation\\n\\nValidation in SPA Web apps (Angular 2, TypeScript, JavaScript, Blazor\\nWebAssembly)\\n\\nForm Vali\", \"dation\\n\\nhttps://angular.io/guide/form-validation\\n\\nValidation. Breeze documentation.\\n\\nhttps://breeze.\", \"github.io/doc-js/validation.html\\n\\nASP.NET Core Blazor forms and input components\\n\\nIn summary, these \", \"are the most important concepts in regards to validation:\\n\\nEntities and aggregates should enforce th\", \"eir own consistency and be \\u201calways valid\\u201d.\\nAggregate roots are responsible for multi-entity consiste\", \"ncy within the same aggregate.\\n\\nIf you think that an entity needs to enter an invalid state, conside\", \"r using a different object\\nmodel\\u2014for example, using a temporary DTO until you create the final domai\", \"n entity.\\n\\nIf you need to create several related objects, such as an aggregate, and they are only va\", \"lid\\nonce all of them have been created, consider using the Factory pattern.\\n\\nIn most of the cases, h\", \"aving redundant validation in the client side is good, because the\\napplication can be proactive.\\n\\nDo\", \"main events: Design and implementation\\n\\nUse domain events to explicitly implement side effects of ch\", \"anges within your domain. In other words,\\nand using DDD terminology, use domain events to explicitly\", \" implement side effects across multiple\\naggregates. Optionally, for better scalability and less impa\", \"ct in database locks, use eventual\\nconsistency between aggregates within the same domain.\\n\\n227\\n\\nCHAP\", \"TER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nWhat is a domain eve\", \"nt?\\n\\nAn event is something that has happened in the past. A domain event is, something that happened\", \" in\\nthe domain that you want other parts of the same domain (in-process) to be aware of. The notifie\", \"d\\nparts usually react somehow to the events.\\n\\nAn important benefit of domain events is that side eff\", \"ects can be expressed explicitly.\\n\\nFor example, if you're just using Entity Framework and there has \", \"to be a reaction to some event, you\\nwould probably code whatever you need close to what triggers the\", \" event. So the rule gets coupled,\\nimplicitly, to the code, and you have to look into the code to, ho\", \"pefully, realize the rule is\\nimplemented there.\\n\\nOn the other hand, using domain events makes the co\", \"ncept explicit, because there\\u2019s a DomainEvent\\nand at least one DomainEventHandler involved.\\n\\nFor exa\", \"mple, in the eshopOnContainers application, when an order is created, the user becomes a\\nbuyer, so a\", \"n OrderStartedDomainEvent is raised and handled in the\\nValidateOrAddBuyerAggregateWhenOrderStartedDo\", \"mainEventHandler, so the underlying concept is\\nevident.\\n\\nIn short, domain events help you to express\", \", explicitly, the domain rules, based in the ubiquitous\\nlanguage provided by the domain experts. Dom\", \"ain events also enable a better separation of concerns\\namong classes within the same domain.\\n\\nIt's i\", \"mportant to ensure that, just like a database transaction, either all the operations related to a\\ndo\", \"main event finish successfully or none of them do.\\n\\nDomain events are similar to messaging-style eve\", \"nts, with one important difference. With real\\nmessaging, message queuing, message brokers, or a serv\", \"ice bus using AMQP, a message is always\\nsent asynchronously and communicated across processes and ma\", \"chines. This is useful for integrating\\nmultiple Bounded Contexts, microservices, or even different a\", \"pplications. However, with domain\\nevents, you want to raise an event from the domain operation you'r\", \"e currently running, but you want\\nany side effects to occur within the same domain.\\n\\nThe domain even\", \"ts and their side effects (the actions triggered afterwards that are managed by event\\nhandlers) shou\", \"ld occur almost immediately, usually in-process, and within the same domain. Thus,\\ndomain events cou\", \"ld be synchronous or asynchronous. Integration events, however, should always be\\nasynchronous.\\n\\nDoma\", \"in events versus integration events\\n\\nSemantically, domain and integration events are the same thing:\", \" notifications about something that\\njust happened. However, their implementation must be different. \", \"Domain events are just messages\\npushed to a domain event dispatcher, which could be implemented as a\", \"n in-memory mediator based\\non an loC container or any other method.\\n\\nOn the other hand, the purpose \", \"of integration events is to propagate committed transactions and\\nupdates to additional subsystems, w\", \"hether they are other microservices, Bounded Contexts or even\\n\\n228 CHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS Patterns\\nexternal applications. Hence, they should occur o\", \"nly if the entity is successfully persisted, otherwise it\\u2019s\\nas if the entire operation never happene\", \"d.\\n\\nAs mentioned before, integration events must be based on asynchronous communication between\\nmult\", \"iple microservices (other Bounded Contexts) or even external systems/applications.\\n\\nThus, the event \", \"bus interface needs some infrastructure that allows inter-process and distributed\\ncommunication betw\", \"een potentially remote services. It can be based on a commercial service bus,\\nqueues, a shared datab\", \"ase used as a mailbox, or any other distributed and ideally push based\\nmessaging system.\\n\\nDomain eve\", \"nts as a preferred way to trigger side effects across\\nmultiple aggregates within the same domain\\n\\nIf\", \" executing a command related to one aggregate instance requires additional domain rules to be run\\non\", \" one or more additional aggregates, you should design and implement those side effects to be\\ntrigger\", \"ed by domain events. As shown in Figure 7-14, and as one of the most important use cases, a\\ndomain e\", \"vent should be used to propagate state changes across multiple aggregates within the same\\ndomain mod\", \"el.\\n\\nDomain Model\\n(Ordering microservice)\\n\\nOrder Aggregate\\naos e en OO\\n~\\n_/ a Address (value Object)\", \" \\\\\\nco Buyer Aggregate\\n| Order (Aggregate Root) <> | LY oT \\\\\\n[Data\\n] { Buyer (Aggregate Root) \\\\\\n~ ae \", \"~ | \\\\ Behavior ]\\n\\\\ \\u201cXN x Behavio | \\\\ \\u2014\\u2014 A\\n\\\\ ~ _/ K\\n\\\\ ~ /\\nN . /\\n~ Domain Event y\\n\\n~L_ Z\\n---\\u2014 OrderSta\", \"rted a\\n\\nFigure 7-14. Domain events to enforce consistency between multiple aggregates within the sam\", \"e domain\\n\\nFigure 7-14 shows how consistency between aggregates is achieved by domain events. When th\", \"e user\\ninitiates an order, the Order Aggregate sends an OrderStarted domain event. The OrderStarted\\n\", \"domain event is handled by the Buyer Aggregate to create a Buyer object in the ordering\\nmicroservice\", \", based on the original user info from the identity microservice (with information provided\\nin the C\", \"reateOrder command).\\n\\nAlternately, you can have the aggregate root subscribed for events raised by m\", \"embers of its\\naggregates (child entities). For instance, each Orderltem child entity can raise an ev\", \"ent when the item\\nprice is higher than a specific amount, or when the product item amount is too hig\", \"h. The aggregate\\nroot can then receive those events and perform a global calculation or aggregation.\", \"\\n\\n229 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nIt's impor\", \"tant to understand that this event-based communication is not implemented directly within\\nthe aggreg\", \"ates; you need to implement domain event handlers.\\n\\nHandling the domain events is an application con\", \"cern. The domain model layer should only focus on\\nthe domain logic\\u2014things that a domain expert would\", \" understand, not application infrastructure like\\nhandlers and side-effect persistence actions using \", \"repositories. Therefore, the application layer level is\\nwhere you should have domain event handlers \", \"triggering actions when a domain event is raised.\\n\\nDomain events can also be used to trigger any num\", \"ber of application actions, and what is more\\nimportant, must be open to increase that number in the \", \"future in a decoupled way. For instance, when\\nthe order is started, you might want to publish a doma\", \"in event to propagate that info to other\\naggregates or even to raise application actions like notifi\", \"cations.\\n\\nThe key point is the open number of actions to be executed when a domain event occurs. Eve\", \"ntually,\\nthe actions and rules in the domain and application will grow. The complexity or number of \", \"side-\\neffect actions when something happens will grow, but if your code were coupled with \\u201cglue\\u201d (th\", \"at is,\\ncreating specific objects with new), then every time you needed to add a new action you would\", \" also\\nneed to change working and tested code.\\n\\nThis change could result in new bugs and this approac\", \"h also goes against the Open/Closed principle\\nfrom SOLID. Not only that, the original class that was\", \" orchestrating the operations would grow and\\n\\ngrow, which goes against the Single Responsibility Pri\", \"nciple (SRP).\\n\\nOn the other hand, if you use domain events, you can create a fine-grained and decoup\", \"led\\nimplementation by segregating responsibilities using this approach:\\n\\n1. | Send a command (for ex\", \"ample, CreateOrder).\\n2. Receive the command in a command handler.\\n- Execute a single aggregate\\u2019s tra\", \"nsaction.\\n\\n\\u2014 (Optional) Raise domain events for side effects (for example,\\nOrderStarted DomainEvent)\", \".\\n\\n3. | Handle domain events (within the current process) that will execute an open number of side\\ne\", \"ffects in multiple aggregates or application actions. For example:\\n\\n\\u2014 Verify or create buyer and pay\", \"ment method.\\n\\n- Create and send a related integration event to the event bus to propagate states\\nacr\", \"oss microservices or trigger external actions like sending an email to the buyer.\\n\\n\\u2014 Handle other si\", \"de effects.\\n\\nAs shown in Figure 7-15, starting from the same domain event, you can handle multiple a\", \"ctions\\nrelated to other aggregates in the domain or additional application actions you need to perfo\", \"rm\\nacross microservices connecting with integration events and the event bus.\\n\\n230 CHAPTER 6 | Tackl\", \"e Business Complexity in a Microservice with DDD and CQRS Patterns\\nDomain Application\\n\\nEvent Handler\", \" 1\\n\\nAggregate (Order)\\n\\neos > Enforce consistency\\na - Address (value-Object) \\\\ 4 with Buyer and\\nj/ Or\", \"der (Aggregate Root) om | / Payment methods\\nenavior | /\\n] |Behavior = avior \\\\\\n\\\\ : \\\\ Orderitem (child\", \" Entity) | |\\nss. a | Event Handler 2\\n| NX | | ;\\nNL y / eee Create and publish\\n\\\\ ~~ sooo Domain Event\", \" J 0 a Integration Event to\\nee S27 Event Bus\\n\\u2014 \\u2014 \\u2014 OrderStarted S\\n\\\\ | a |\\nn\\n\\\\\\n\\\\ Event Handler \\u2018n\\u2019\\n\\na\", \"ren Any additional action\\n\\nFigure 7-15. Handling multiple actions per domain\\n\\nThere can be several h\", \"andlers for the same domain event in the Application Layer, one handler can\\nsolve consistency betwee\", \"n aggregates and another handler can publish an integration event, so other\\nmicroservices can do som\", \"ething with it. The event handlers are typically in the application layer,\\nbecause you'll use infras\", \"tructure objects like repositories or an application API for the microservice\\u2019s\\nbehavior. In that se\", \"nse, event handlers are similar to command handlers, so both are part of the\\napplication layer. The \", \"important difference is that a command should be processed only once. A\\ndomain event could be proces\", \"sed zero or n times, because it can be received by multiple receivers or\\nevent handlers with a diffe\", \"rent purpose for each handler.\\n\\nHaving an open number of handlers per domain event allows you to add\", \" as many domain rules as\\nneeded, without affecting current code. For instance, implementing the foll\", \"owing business rule might\\nbe as easy as adding a few event handlers (or even just one):\\n\\nWhen the to\", \"tal amount purchased by a customer in the store, across any number of orders, exceeds\\n$6,000, apply \", \"a 10% off discount to every new order and notify the customer with an email about that\\ndiscount for \", \"future orders.\\n\\nImplement domain events\\n\\nIn C#, a domain event is simply a data-holding structure or\", \" class, like a DTO, with all the information\\nrelated to what just happened in the domain, as shown i\", \"n the following example:\\n\\npublic class OrderStartedDomainEvent : INotification\\n\\n{\\n\\npublic string Use\", \"rId { get; }\\n\\npublic string UserName { get; }\\n\\npublic int CardTypelId { get; }\\n\\npublic string CardNu\", \"mber { get; }\\n\\npublic string CardSecurityNumber { get; }\\n\\n231 CHAPTER 6 | Tackle Business Complexity\", \" in a Microservice with DDD and CQRS Patterns\\npublic string CardHolderName { get; }\\npublic DateTime \", \"CardExpiration { get; }\\npublic Order Order { get; }\\n\\npublic OrderStartedDomainEvent(Order order, str\", \"ing userId, string userName,\\nint cardTypeId, string cardNumber,\\nstring cardSecurityNumber, string ca\", \"rdHolderName,\\nDateTime cardExpiration)\\n\\nOrder = order;\\n\\nUserId = userId;\\n\\nUserName = userName;\\n\\nCard\", \"TypelId = cardTypeld;\\n\\nCardNumber = cardNumber ;\\nCardSecurityNumber = cardSecurityNumber ;\\nCardHolde\", \"rName = cardHolderName;\\nCardExpiration = cardExpiration;\\n\\nThis is essentially a class that holds all\", \" the data related to the OrderStarted event.\\n\\nIn terms of the ubiquitous language of the domain, sin\", \"ce an event is something that happened in the\\npast, the class name of the event should be represente\", \"d as a past-tense verb, like\\nOrderStartedDomainEvent or OrderShippedDomainEvent. That's how the doma\", \"in event is\\nimplemented in the ordering microservice in eshopOnContainers.\\n\\nAs noted earlier, an imp\", \"ortant characteristic of events is that since an event is something that\\nhappened in the past, it sh\", \"ouldn't change. Therefore, it must be an immutable class. You can see in\\nthe previous code that the \", \"properties are read-only. There\\u2019s no way to update the object, you can only\\nset values when you crea\", \"te it.\\n\\nIt's important to highlight here that if domain events were to be handled asynchronously, us\", \"ing a\\nqueue that required serializing and deserializing the event objects, the properties would have\", \" to be\\n\\u201corivate set\\u201d instead of read-only, so the deserializer would be able to assign the values up\", \"on\\ndequeuing. This is not an issue in the Ordering microservice, as the domain event pub/sub is\\nimpl\", \"emented synchronously using MediatR.\\n\\nRaise domain events\\n\\nThe next question is how to raise a domai\", \"n event so it reaches its related event handlers. You can use\\nmultiple approaches.\\n\\nUdi Dahan origin\", \"ally proposed (for example, in several related posts, such as Domain Events \\u2014 Take 2)\\nusing a Static\", \" class for managing and raising the events. This might include a static class named\\nDomainEvents tha\", \"t would raise domain events immediately when it's called, using syntax like\\nDomainEvents.Raise(Event\", \" myEvent). Jimmy Bogard wrote a blog post (Strengthening your domain:\\nDomain Events) that recommends\", \" a similar approach.\\n\\nHowever, when the domain events class is static, it also dispatches to handler\", \"s immediately. This\\nmakes testing and debugging more difficult, because the event handlers with side\", \"-effects logic are\\nexecuted immediately after the event is raised. When you're testing and debugging\", \", you just want to\\nfocus on what is happening in the current aggregate classes; you don\\u2019t want to su\", \"ddenly be\\n\\n232 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nr\", \"edirected to other event handlers for side effects related to other aggregates or application logic.\", \"\\nThis is why other approaches have evolved, as explained in the next section.\\n\\nThe deferred approach\", \" to raise and dispatch events\\n\\nInstead of dispatching to a domain event handler immediately, a bette\", \"r approach is to add the\\ndomain events to a collection and then to dispatch those domain events righ\", \"t before or right after\\ncommitting the transaction (as with SaveChanges in EF). (This approach was d\", \"escribed by Jimmy\\n\\nBogard in this post A better domain events pattern.)\\n\\nDeciding if you send the do\", \"main events right before or right after committing the transaction is\\nimportant, since it determines\", \" whether you will include the side effects as part of the same transaction\\nor in different transacti\", \"ons. In the latter case, you need to deal with eventual consistency across\\nmultiple aggregates. This\", \" topic is discussed in the next section.\\n\\nThe deferred approach is what eShopOnContainers uses. Firs\", \"t, you add the events happening in your\\nentities into a collection or list of events per entity. Tha\", \"t list should be part of the entity object, or\\neven better, part of your base entity class, as shown\", \" in the following example of the Entity base class:\\n\\npublic abstract class Entity\\n\\naf\\nPoo\\nprivate Li\", \"st<INotification> _domainEvents;\\npublic List<INotification> DomainEvents => _domainEvents;\\n\\npublic v\", \"oid AddDomainEvent(INotification eventItem)\\n\\nt\\n\\n_domainEvents = _domainEvents ?? new List<INotificat\", \"ion>();\\n\\n_domainEvents.Add(eventItem) ;\\n}\\npublic void RemoveDomainEvent(INotification eventItem)\\n{\\n\\n\", \"_domainEvents?.Remove(eventItem) ;\\n\\n. Additional code\\n\\nWhen you want to raise an event, you just add\", \" it to the event collection from code at any method of\\nthe aggregate-root entity.\\n\\nThe following cod\", \"e, part of the Order aggregate-root at eShopOnContainers, shows an example:\\n\\nvar orderStartedDomainE\", \"vent = new OrderStartedDomainEvent(this, //Order object\\ncardTypeId, cardNumber,\\ncardSecurityNumber,\\n\", \"cardHolderName,\\ncardExpiration) ;\\n\\nthis .AddDomainEvent (orderStartedDomainEvent) ;\\n\\nNotice that the\", \" only thing that the AddDomainEvent method is doing is adding an event to the list.\\nNo event is disp\", \"atched yet, and no event handler is invoked yet.\\n\\n233 CHAPTER 6 | Tackle Business Complexity in a Mi\", \"croservice with DDD and CQRS Patterns\\nYou actually want to dispatch the events later on, when you co\", \"mmit the transaction to the database. If\\nyou are using Entity Framework Core, that means in the Save\", \"Changes method of your EF DbContext,\\nas in the following code:\\n\\n// EF Core DbContext\\npublic class Or\", \"deringContext : DbContext, IUnitOfWork\\n\\nt\\n\\nHii 000\\npublic async Task<bool> SaveEntitiesAsync(Cancell\", \"ationToken cancellationToken =\\ndefault(CancellationToken) )\\n\\naf\\n// Dispatch Domain Events collection\", \".\\n// Choices:\\n// A) Right BEFORE committing data (EF SaveChanges) into the DB. This makes\\n// a singl\", \"e transaction including side effects from the domain event\\n// handlers that are using the same DbCon\", \"text with Scope lifetime\\n// B) Right AFTER committing data (EF SaveChanges) into the DB. This makes\\n\", \"// multiple transactions. You will need to handle eventual consistency and\\n// compensatory actions i\", \"n case of failures.\\nawait _mediator.DispatchDomainEventsAsync(this) ;\\n\\n// After this line runs, all \", \"the changes (from the Command Handler and Domain\\n// event handlers) performed through the DbContext \", \"will be committed\\nvar result = await base.SaveChangesAsync() ;\\n\\nWith this code, you dispatch the ent\", \"ity events to their respective event handlers.\\n\\nThe overall result is that you've decoupled the rais\", \"ing of a domain event (a simple add into a list in\\nmemory) from dispatching it to an event handler. \", \"In addition, depending on what kind of dispatcher\\nyou are using, you could dispatch the events synch\", \"ronously or asynchronously.\\n\\nBe aware that transactional boundaries come into significant play here.\", \" If your unit of work and\\ntransaction can span more than one aggregate (as when using EF Core and a \", \"relational database), this\\ncan work well. But if the transaction cannot span aggregates, you have to\", \" implement additional steps\\nto achieve consistency. This is another reason why persistence ignorance\", \" is not universal; it depends\\non the storage system you use.\\n\\nSingle transaction across aggregates v\", \"ersus eventual consistency across\\naggregates\\n\\nThe question of whether to perform a single transactio\", \"n across aggregates versus relying on eventual\\nconsistency across those aggregates is a controversia\", \"l one. Many DDD authors like Eric Evans and\\nVaughn Vernon advocate the rule that one transaction = o\", \"ne aggregate and therefore argue for\\neventual consistency across aggregates. For example, in his boo\", \"k Domain-Driven Design, Eric Evans\\nsays this:\\n\\nAny rule that spans Aggregates will not be expected t\", \"o be up-to-date at all times. Through event\\nprocessing, batch processing, or other update mechanisms\", \", other dependencies can be resolved\\nwithin some specific time. (page 128)\\n\\nVaughn Vernon says the f\", \"ollowing in Effective Aggregate Design. Part Il: Making Aggregates Work\\nTogether:\\n\\n234 CHAPTER 6 | T\", \"ackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nThus, if executing a command \", \"on one aggregate instance requires that additional business rules\\nexecute on one or more aggregates,\", \" use eventual consistency [...] There is a practical way to support\\neventual consistency in a DDD mo\", \"del. An aggregate method publishes a domain event that is in time\\ndelivered to one or more asynchron\", \"ous subscribers.\\n\\nThis rationale is based on embracing fine-grained transactions instead of transact\", \"ions spanning many\\naggregates or entities. The idea is that in the second case, the number of databa\", \"se locks will be\\nsubstantial in large-scale applications with high scalability needs. Embracing the \", \"fact that highly\\nscalable applications need not have instant transactional consistency between multi\", \"ple aggregates\\nhelps with accepting the concept of eventual consistency. Atomic changes are often no\", \"t needed by\\nthe business, and it is in any case the responsibility of the domain experts to say whet\", \"her particular\\noperations need atomic transactions or not. If an operation always needs an atomic tr\", \"ansaction\\nbetween multiple aggregates, you might ask whether your aggregate should be larger or wasn\", \"'t\\ncorrectly designed.\\n\\nHowever, other developers and architects like Jimmy Bogard are okay with spa\", \"nning a single\\ntransaction across several aggregates\\u2014but only when those additional aggregates are r\", \"elated to side\\neffects for the same original command. For instance, in A better domain events patter\", \"n, Bogard says\\nthis:\\n\\nTypically, | want the side effects of a domain event to occur within the same \", \"logical transaction, but\\nnot necessarily in the same scope of raising the domain event [...] Just be\", \"fore we commit our\\ntransaction, we dispatch our events to their respective handlers.\\n\\nIf you dispatc\", \"h the domain events right before committing the original transaction, it is because you\\nwant the sid\", \"e effects of those events to be included in the same transaction. For example, if the EF\\nDbContext S\", \"aveChanges method fails, the transaction will roll back all changes, including the result of\\nany sid\", \"e effect operations implemented by the related domain event handlers. This is because the\\nDbContext \", \"life scope is by default defined as \\u201cscoped.\\u201d Therefore, the DoContext object is shared\\nacross multi\", \"ple repository objects being instantiated within the same scope or object graph. This\\ncoincides with\", \" the HttpRequest scope when developing Web API or MVC apps.\\n\\nActually, both approaches (single atomi\", \"c transaction and eventual consistency) can be right. It really\\ndepends on your domain or business r\", \"equirements and what the domain experts tell you. It also\\ndepends on how scalable you need the servi\", \"ce to be (more granular transactions have less impact\\nwith regard to database locks). And it depends\", \" on how much investment you're willing to make in\\nyour code, since eventual consistency requires mor\", \"e complex code in order to detect possible\\ninconsistencies across aggregates and the need to impleme\", \"nt compensatory actions. Consider that if\\nyou commit changes to the original aggregate and afterward\", \"s, when the events are being dispatched,\\nif there\\u2019s an issue and the event handlers cannot commit th\", \"eir side effects, you'll have inconsistencies\\nbetween aggregates.\\n\\nA way to allow compensatory actio\", \"ns would be to store the domain events in additional database\\ntables so they can be part of the orig\", \"inal transaction. Afterwards, you could have a batch process that\\ndetects inconsistencies and runs c\", \"ompensatory actions by comparing the list of events with the\\ncurrent state of the aggregates. The co\", \"mpensatory actions are part of a complex topic that will require\\ndeep analysis from your side, which\", \" includes discussing it with the business user and domain experts.\\n\\n235 CHAPTER 6 | Tackle Business \", \"Complexity in a Microservice with DDD and CQRS Patterns\\nIn any case, you can choose the approach you\", \" need. But the initial deferred approach\\u2014raising the\\nevents before committing, so you use a single t\", \"ransaction\\u2014is the simplest approach when using EF\\nCore and a relational database. It's easier to imp\", \"lement and valid in many business cases. It's also the\\napproach used in the ordering microservice in\", \" eshopOnContainers.\\n\\nBut how do you actually dispatch those events to their respective event handler\", \"s? What's the\\n_mediator object you see in the previous example? It has to do with the techniques and\", \" artifacts you\\nuse to map between events and their event handlers.\\n\\nThe domain event dispatcher: map\", \"ping from events to event handlers\\n\\nOnce you're able to dispatch or publish the events, you need som\", \"e kind of artifact that will publish the\\nevent, so that every related handler can get it and process\", \" side effects based on that event.\\n\\nOne approach is a real messaging system or even an event bus, po\", \"ssibly based on a service bus as\\nopposed to in-memory events. However, for the first case, real mess\", \"aging would be overkill for\\nprocessing domain events, since you just need to process those events wi\", \"thin the same process (that\\nis, within the same domain and application layer).\\n\\nHow to subscribe to \", \"domain events\\n\\nWhen you use MediatR, each event handler must use an event type that is provided on t\", \"he generic\\nparameter of the INotificationHandler interface, as you can see in the following code:\\n\\np\", \"ublic class ValidateOrAddBuyerAggregatewWhenOrderStartedDomainEventHandler\\n: INotificationHandler<Or\", \"derStartedDomainEvent>\\n\\nBased on the relationship between event and event handler, which can be cons\", \"idered the\\nsubscription, the MediatR artifact can discover all the event handlers for each event and\", \" trigger each\\none of those event handlers.\\n\\nHow to handle domain events\\n\\nFinally, the event handler \", \"usually implements application layer code that uses infrastructure\\nrepositories to obtain the requir\", \"ed additional aggregates and to execute side-effect domain logic. The\\n\\nfollowing domain event handle\", \"r code at eSshopOnContainers, shows an implementation example.\\n\\npublic class ValidateOrAddBuyerAggre\", \"gateWhenOrderStartedDomainEventHandler\\n: INotificationHandler<OrderStartedDomainEvent>\\n\\n{\\n\\nprivate r\", \"eadonly ILogger _logger;\\nprivate readonly IBuyerRepository _buyerRepository;\\nprivate readonly IOrder\", \"ingIntegrationEventService _orderingIntegrationEventService;\\n\\npublic ValidateOrAddBuyerAggregateWhen\", \"OrderStartedDomainEventHandler (\\nILogger<ValidateOrAddBuyerAggregatewhenOrderStartedDomainEventHandl\", \"er> logger,\\nIBuyerRepository buyerRepository,\\nTOrderingIntegrationEventService orderingIntegrationEv\", \"entService)\\n{\\n_buyerRepository = buyerRepository ?? throw new\\nArgumentNullException(nameof(buyerRepo\", \"sitory) ) ;\\n_orderingIintegrationEventService = orderingIntegrationEventService ?? throw new\\nArgumen\", \"tNullException(nameof (orderingIntegrationEventService) ) ;\\n\\n236 CHAPTER 6 | Tackle Business Complex\", \"ity in a Microservice with DDD and CQRS Patterns\\n_logger = logger ?? throw new ArgumentNullException\", \"(nameof (logger) ) ;\\n\\n}\\n\\npublic async Task Handle(\\nOrderStartedDomainEvent domainEvent, Cancellation\", \"Token cancellationToken)\\n\\n{\\nvar cardTypeId = domainEvent.CardTypeId != @ ? domainEvent.CardTypeld : \", \"1;\\nvar buyer = await _buyerRepository.FindAsync(domainEvent.UserId) ;\\nvar buyerExisted = buyer is no\", \"t null;\\nif (!buyerExisted)\\n{\\nbuyer = new Buyer(domainEvent.UserId, domainEvent.UserName) ;\\n}\\nbuyer .\", \"VerifyOrAddPaymentMethod (\\ncardTypeld,\\n$\\\"Payment Method on {DateTime.UtcNow}\\\",\\ndomainEvent.CardNumbe\", \"r,\\ndomainEvent.CardSecurityNumber ,\\ndomainEvent.CardHolderName,\\ndomainEvent.CardExpiration,\\ndomainEv\", \"ent.Order.Id) ;\\nvar buyerUpdated = buyerExisted ?\\n_buyerRepository.Update(buyer) :\\n_buyerRepository.\", \"Add(buyer) ;\\nawait _buyerRepository.UnitOfwWork\\n.SaveEntitiesAsync(cancellationToken) ;\\nvar integrat\", \"ionEvent = new OrderStatusChangedToSubmittedIntegrationEvent (\\ndomainEvent.Order.Id, domainEvent.Ord\", \"er.OrderStatus.Name, buyer.Name) ;\\nawait _orderingIntegrationEventService.AddAndSaveEventAsync(integ\", \"rationEvent) ;\\nOrderingApiTrace.LogOrderBuyerAndPaymentValidatedOrUpdated (\\n_logger, buyerUpdated.Id\", \", domainEvent.Order.Id) ;\\n}\\n\\n}\\n\\nThe previous domain event handler code is considered application lay\", \"er code because it uses\\ninfrastructure repositories, as explained in the next section on the infrast\", \"ructure-persistence layer.\\nEvent handlers could also use other infrastructure components.\\n\\nDomain ev\", \"ents can generate integration events to be published outside of the\\nmicroservice boundaries\\n\\nFinally\", \", it's important to mention that you might sometimes want to propagate events across multiple\\nmicros\", \"ervices. That propagation is an integration event, and it could be published through an event\\nbus fr\", \"om any specific domain event handler.\\n\\nConclusions on domain events\\n\\nAs stated, use domain events to\", \" explicitly implement side effects of changes within your domain. To\\nuse DDD terminology, use domain\", \" events to explicitly implement side effects across one or multiple\\naggregates. Additionally, and fo\", \"r better scalability and less impact on database locks, use eventual\\nconsistency between aggregates \", \"within the same domain.\\n\\n237 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS Patterns\\nThe reference app uses MediatR to propagate domain events synchronously across aggregat\", \"es, within\\na single transaction. However, you could also use some AMQP implementation like RabbitMQ \", \"or\\nAzure Service Bus to propagate domain events asynchronously, using eventual consistency but, as\\nm\", \"entioned above, you have to consider the need for compensatory actions in case of failures.\\n\\nAdditio\", \"nal resources\\n\\n\\u00b0 Greg Young. What is a Domain Event?\\n\\nhttps://cars.files.wordpress.com/2010/11/cqrs_\", \" documents.pdf#page=25\\n\\n\\u00b0 Jan Stenberg. Domain Events and Eventual Consistency\\n\\nhttps://www.infog.co\", \"m/news/2015/09/domain-events-consistency\\n\\n\\u00b0 Jimmy Bogard. A better domain events pattern\\n\\nhttps://lo\", \"stechies.com/jimmybogard/2014/05/13/a-better-domain-events-pattern/\\n\\n\\u00b0 Vaughn Vernon. Effective Aggr\", \"egate Design Part II: Making Aggregates Work Together\\nhttps://dddcommunity.org/wp-content/uploads/fi\", \"les/pdf _articles/Vernon 2011 2.pdf\\n\\n. Jimmy Bogard. Strengthening your domain: Domain Events\\nhttps:\", \"//lostechies.com/jimmybogard/2010/04/08/strengthening-your-domain-domain-\\n\\nevents/\\n\\n. Udi Dahan. How\", \" to create fully encapsulated Domain Models\\n\\nhttps://udidahan.com/2008/02/29/how-to-create-fully-enc\", \"apsulated-domain-models/\\n\\n\\u00b0 Udi Dahan. Domain Events \\u2014 Take 2\\n\\nhttps://udidahan.com/2008/08/25/domai\", \"n-events-take-2/\\n\\n\\u00b0 Udi Dahan. Domain Events \\u2014 Salvation\\n\\nhttps://udidahan.com/2009/06/14/domain-eve\", \"nts-salvation/\\n\\n. Cesar de la Torre. Domain Events vs. Integration Events in DDD and microservices\\na\", \"rchitectures\\n\\nhttos://devblogs.microsoft.com/cesardelatorre/domain-events-vs-integration-events-in-\\n\", \"\\ndomain-driven-design-and-microservices-architectures/\\n\\nDesign the infrastructure persistence layer\\n\", \"\\nData persistence components provide access to the data hosted within the boundaries of a\\nmicroservi\", \"ce (that is, a microservice\\u2019s database). They contain the actual implementation of\\ncomponents such a\", \"s repositories and Unit of Work classes, like custom Entity Framework (EF)\\nDbContext objects. EF DoC\", \"ontext implements both the Repository and the Unit of Work patterns.\\n\\nThe Repository pattern\\n\\nThe Re\", \"pository pattern is a Domain-Driven Design pattern intended to keep persistence concerns\\noutside of \", \"the system's domain model. One or more persistence abstractions - interfaces - are defined\\n\\n238 CHAP\", \"TER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nin the domain model,\", \" and these abstractions have implementations in the form of persistence-specific\\nadapters defined el\", \"sewhere in the application.\\n\\nRepository implementations are classes that encapsulate the logic requi\", \"red to access data sources.\\nThey centralize common data access functionality, providing better maint\", \"ainability and decoupling\\nthe infrastructure or technology used to access databases from the domain \", \"model. If you use an\\nObject-Relational Mapper (ORM) like Entity Framework, the code that must be imp\", \"lemented is\\nsimplified, thanks to LINQ and strong typing. This lets you focus on the data persistenc\", \"e logic rather\\nthan on data access plumbing.\\n\\nThe Repository pattern is a well-documented way of wor\", \"king with a data source. In the book Patterns\\nof Enterprise Application Architecture, Martin Fowler \", \"describes a repository as follows:\\n\\nA repository performs the tasks of an intermediary between the d\", \"omain model layers and data\\nmapping, acting in a similar way to a set of domain objects in memory. C\", \"lient objects declaratively\\nbuild queries and send them to the repositories for answers. Conceptuall\", \"y, a repository encapsulates a\\nset of objects stored in the database and operations that can be perf\", \"ormed on them, providing a way\\nthat is closer to the persistence layer. Repositories, also, support \", \"the purpose of separating, clearly\\nand in one direction, the dependency between the work domain and \", \"the data allocation or mapping.\\n\\nDefine one repository per aggregate\\n\\nFor each aggregate or aggregat\", \"e root, you should create one repository class. You may be able to\\nleverage C# Generics to reduce th\", \"e total number concrete classes you need to maintain (as\\ndemonstrated later in this chapter). In a m\", \"icroservice based on Domain-Driven Design (DDD) patterns,\\nthe only channel you should use to update \", \"the database should be the repositories. This is because\\nthey have a one-to-one relationship with th\", \"e aggregate root, which controls the aggregate\\u2019s\\ninvariants and transactional consistency. It's okay\", \" to query the database through other channels (as\\nyou can do following a CQRS approach), because que\", \"ries don\\u2019t change the state of the database.\\nHowever, the transactional area (that is, the updates) \", \"must always be controlled by the repositories\\nand the aggregate roots.\\n\\nBasically, a repository allo\", \"ws you to populate data in memory that comes from the database in the\\nform of the domain entities. O\", \"nce the entities are in memory, they can be changed and then persisted\\nback to the database through \", \"transactions.\\n\\nAs noted earlier, if you're using the CQS/CQRS architectural pattern, the initial que\", \"ries are performed\\nby side queries out of the domain model, performed by simple SQL statements using\", \" Dapper. This\\napproach is much more flexible than repositories because you can query and join any ta\", \"bles you\\nneed, and these queries aren't restricted by rules from the aggregates. That data goes to t\", \"he\\npresentation layer or client app.\\n\\nIf the user makes changes, the data to be updated comes from t\", \"he client app or presentation layer to\\nthe application layer (such as a Web API service). When you r\", \"eceive a command in a command\\nhandler, you use repositories to get the data you want to update from \", \"the database. You update it in\\nmemory with the data passed with the commands, and you then add or up\", \"date the data (domain\\nentities) in the database through a transaction.\\n\\n239 CHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns\\nIt's important to emphasize again that y\", \"ou should only define one repository for each aggregate root,\\nas shown in Figure 7-17. To achieve th\", \"e goal of the aggregate root to maintain transactional\\nconsistency between all the objects within th\", \"e aggregate, you should never create a repository for\\neach table in the database.\\n\\nBuyer Aggregate O\", \"rder Aggregate\\nee i 1\\nAddress (Value- Object)\\n| I a\\n| | 1 |\\n| Buyer (Aggregate Root) | | Order (Aggr\", \"egate Root) Oo |\\n: | a\\nDomain Model | | |\\nLayer | \\\\ Orderltem (child Entity) |\\n| |\\n| | n\\n| | |\\n|\\nInf\", \"rastructure- OrderRepository\\nPersistence\\nLayer\\nUnit of Work\\n----\\nl |\\nl |\\n|\\n! Buyer Table Orders Tabl\", \"e Orderltems table |\\nData | Sez |\\n. |\\nTier | |\\nl |\\n| Ordering |\\n| Database |\\n|\\n\\nFigure 7-17. The rel\", \"ationship between repositories, aggregates, and database tables\\n\\nThe above diagram shows the relatio\", \"nships between Domain and Infrastructure layers: Buyer\\nAggregate depends on the IBuyerRepository and\", \" Order Aggregate depends on the |OrderRepository\\ninterfaces, these interfaces are implemented in the\", \" Infrastructure layer by the corresponding\\nrepositories that depend on UnitOfWork, also implemented \", \"there, that accesses the tables in the Data\\ntier.\\n\\nEnforce one aggregate root per repository\\n\\nIt can\", \" be valuable to implement your repository design in such a way that it enforces the rule that only\\na\", \"ggregate roots should have repositories. You can create a generic or base repository type that\\nconst\", \"rains the type of entities it works with to ensure they have the |[AggregateRoot marker interface.\\n\\n\", \"Thus, each repository class implemented at the infrastructure layer implements its own contract or\\ni\", \"nterface, as shown in the following code:\\n\\nnamespace Microsoft.eShopOnContainers.Services.Ordering. \", \"Infrastructure. Repositories\\n\\nt\\n\\npublic class OrderRepository : IOrderRepository\\n\\nt\\nHl oo\\n\\n240 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nhe |\\n\\nEach specific r\", \"epository interface implements the generic IRepository interface:\\n\\npublic interface IOrderRepository\", \" : IRepository<Order>\\n\\nOrder Add(Order order) ;\\n// ...\\n\\nHowever, a better way to have the code enfor\", \"ce the convention that each repository is related to a\\nsingle aggregate is to implement a generic re\", \"pository type. That way, it\\u2019s explicit that you're using a\\nrepository to target a specific aggregate\", \". That can be easily done by implementing a generic\\n[Repository base interface, as in the following \", \"code:\\n\\npublic interface IRepository<T> where T : IAggregateRoot\\n{\\n\\n}\\n\\nWcoce\\n\\nThe Repository pattern \", \"makes it easier to test your application logic\\n\\nThe Repository pattern allows you to easily test you\", \"r application with unit tests. Remember that unit\\ntests only test your code, not infrastructure, so \", \"the repository abstractions make it easier to achieve\\nthat goal.\\n\\nAs noted in an earlier section, it\", \"'s recommended that you define and place the repository interfaces in\\nthe domain model layer so the \", \"application layer, such as your Web API microservice, doesn't depend\\ndirectly on the infrastructure \", \"layer where you've implemented the actual repository classes. By doing\\nthis and using Dependency Inj\", \"ection in the controllers of your Web API, you can implement mock\\nrepositories that return fake data\", \" instead of data from the database. This decoupled approach allows\\nyou to create and run unit tests \", \"that focus the logic of your application without requiring connectivity\\nto the database.\\n\\nConnection\", \"s to databases can fail and, more importantly, running hundreds of tests against a\\ndatabase is bad f\", \"or two reasons. First, it can take a long time because of the large number of tests.\\nSecond, the dat\", \"abase records might change and impact the results of your tests, especially if your\\ntests are runnin\", \"g in parallel, so that they might not be consistent. Unit tests typically can run in\\nparallel; integ\", \"ration tests may not support parallel execution depending on their implementation.\\nTesting against t\", \"he database isn't a unit test but an integration test. You should have many unit tests\\nrunning fast,\", \" but fewer integration tests against the databases.\\n\\nIn terms of separation of concerns for unit tes\", \"ts, your logic operates on domain entities in memory. It\\nassumes the repository class has delivered \", \"those. Once your logic modifies the domain entities, it\\nassumes the repository class will store them\", \" correctly. The important point here is to create unit tests\\nagainst your domain model and its domai\", \"n logic. Aggregate roots are the main consistency\\nboundaries in DDD.\\n\\nThe repositories implemented i\", \"n eShopOnContainers rely on EF Core\\u2019s DbContext implementation of\\nthe Repository and Unit of Work pa\", \"tterns using its change tracker, so they don\\u2019t duplicate this\\nfunctionality.\\n\\n241 CHAPTER 6 | Tackle\", \" Business Complexity in a Microservice with DDD and CQRS Patterns\\nThe difference between the Reposit\", \"ory pattern and the legacy Data Access class\\n(DAL class) pattern\\n\\nA typical DAL object directly perf\", \"orms data access and persistence operations against storage, often\\nat the level of a single table an\", \"d row. Simple CRUD operations implemented with a set of DAL classes\\nfrequently do not support transa\", \"ctions (though this is not always the case). Most DAL class\\napproaches make minimal use of abstracti\", \"ons, resulting in tight coupling between application or\\nBusiness Logic Layer (BLL) classes that call\", \" the DAL objects.\\n\\nWhen using repository, the implementation details of persistence are encapsulated\", \" away from the\\ndomain model. The use of an abstraction provides ease of extending behavior through p\", \"atterns like\\nDecorators or Proxies. For instance, cross-cutting concerns like caching, logging, and \", \"error handling\\ncan all be applied using these patterns rather than hard-coded in the data access cod\", \"e itself. It\\u2019s also\\ntrivial to support multiple repository adapters which may be used in different e\", \"nvironments, from\\nlocal development to shared staging environments to production.\\n\\nImplementing Unit\", \" of Work\\n\\nA unit of work refers to a single transaction that involves multiple insert, update, or de\", \"lete operations.\\nIn simple terms, it means that for a specific user action, such as a registration o\", \"n a website, all the\\ninsert, update, and delete operations are handled in a single transaction. This\", \" is more efficient than\\nhandling multiple database operations in a chattier way.\\n\\nThese multiple per\", \"sistence operations are performed later in a single action when your code from the\\napplication layer\", \" commands it. The decision about applying the in-memory changes to the actual\\ndatabase storage is ty\", \"pically based on the Unit of Work pattern. In EF, the Unit of Work pattern is\\nimplemented by a DbCon\", \"text and is executed when a call is made to SaveChanges.\\n\\nIn many cases, this pattern or way of appl\", \"ying operations against the storage can increase application\\nperformance and reduce the possibility \", \"of inconsistencies. It also reduces transaction blocking in the\\ndatabase tables, because all the int\", \"ended operations are committed as part of one transaction. This is\\nmore efficient in comparison to e\", \"xecuting many isolated operations against the database. Therefore,\\nthe selected ORM can optimize the\", \" execution against the database by grouping several update\\nactions within the same transaction, as o\", \"pposed to many small and separate transaction executions.\\n\\nThe Unit of Work pattern can be implement\", \"ed with or without using the Repository pattern.\\n\\nRepositories shouldn't be mandatory\\n\\nCustom reposi\", \"tories are useful for the reasons cited earlier, and that is the approach for the ordering\\nmicroserv\", \"ice in eShopOnContainers. However, it isn\\u2019t an essential pattern to implement in a DDD\\ndesign or eve\", \"n in general .NET development.\\n\\nFor instance, Jimmy Bogard, when providing direct feedback for this \", \"guide, said the following:\\n\\nThis'll probably be my biggest feedback. I'm really not a fan of reposit\", \"ories, mainly because they hide\\nthe important details of the underlying persistence mechanism. It's \", \"why | go for MediatR for\\ncommands, too. | can use the full power of the persistence layer, and push \", \"all that domain behavior\\ninto my aggregate roots. | don't usually want to mock my repositories \\u2014 | s\", \"till need to have that\\n\\n242 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQ\", \"RS Patterns\\nintegration test with the real thing. Going CQRS meant that we didn't really have a need\", \" for\\nrepositories any more.\\n\\nRepositories might be useful, but they are not critical for your DDD de\", \"sign in the way that the\\nAggregate pattern and a rich domain model are. Therefore, use the Repositor\", \"y pattern or not, as you\\nsee fit.\\n\\nAdditional resources\\n\\nRepository pattern\\n. Edward Hieatt and Rob \", \"Mee. Repository pattern.\\n\\nhttps://martinfowler.com/eaaCatalog/repository.htm!\\n\\n. The Repository patt\", \"ern\\nhttos://learn.microsoft.com/previous-versions/msp-n-p/ff649690(v=pandp.10\\n\\n\\u00b0 Eric Evans. Domain-\", \"Driven Design: Tackling Complexity in the Heart of Software. (Book;\\nincludes a discussion of the Rep\", \"ository pattern)\\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\n\\nSoftware/dp/03211\", \"25215/\\n\\nUnit of Work pattern\\n. Martin Fowler. Unit of Work pattern.\\n\\nhttps://martinfowler.com/eaaCat\", \"alog/unitOfWork.html\\n\\n\\u00b0 Implementing the Repository and Unit of Work Patterns in an ASP.NET MVC\\nAppl\", \"ication\\nhttps://learn.microsoft.com/aspnet/mvc/overview/older-versions/getting-started-with-ef-5-\\nus\", \"ing-mvc-4/implementing-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-\\n\\napplication\\n\\nImp\", \"lement the infrastructure persistence layer with\\nEntity Framework Core\\n\\nWhen you use relational data\", \"bases such as SQL Server, Oracle, or PostgreSQL, a recommended\\napproach is to implement the persiste\", \"nce layer based on Entity Framework (EF). EF supports LINQ and\\nprovides strongly typed objects for y\", \"our model, as well as simplified persistence into your database.\\n\\nEntity Framework has a long histor\", \"y as part of the .NET Framework. When you use .NET, you should\\nalso use Entity Framework Core, which\", \" runs on Windows or Linux in the same way as .NET. EF Core is a\\ncomplete rewrite of Entity Framework\", \" that's implemented with a much smaller footprint and\\nimportant improvements in performance.\\n\\n243 CH\", \"APTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nIntroduction to En\", \"tity Framework Core\\n\\nEntity Framework (EF) Core is a lightweight, extensible, and cross-platform ver\", \"sion of the popular\\nEntity Framework data access technology. It was introduced with .NET Core in mid\", \"-2016.\\n\\nSince an introduction to EF Core is already available in Microsoft documentation, here we si\", \"mply\\nprovide links to that information.\\n\\nAdditional resources\\n\\n\\u00b0 Entity Framework Core\\n\\nhttps://lear\", \"n.microsoft.com/ef/core/\\n\\n. Getting started with ASP.NET Core and Entity Framework Core using Visual\", \" Studio\\nhttps://learn.microsoft.com/aspnet/core/data/ef-mvc/\\n\\n\\u00b0 DbContext Class\\n\\nhttps://learn.micro\", \"soft.com/dotnet/api/microsoft.entityframeworkcore.dbcontext\\n\\n\\u00b0 Compare EF Core & EF6.x\\nhttps://learn\", \".microsoft.com/ef/efcore-and-ef6/index\\n\\nInfrastructure in Entity Framework Core from a DDD perspecti\", \"ve\\n\\nFrom a DDD point of view, an important capability of EF is the ability to use POCO domain entiti\", \"es,\\nalso known in EF terminology as POCO code-first entities. If you use POCO domain entities, your\\n\", \"domain model classes are persistence-ignorant, following the Persistence Ignorance and the\\n\\nInfrastr\", \"ucture Ignorance principles.\\n\\nPer DDD patterns, you should encapsulate domain behavior and rules wit\", \"hin the entity class itself, so\\nit can control invariants, validations, and rules when accessing any\", \" collection. Therefore, it is not a\\ngood practice in DDD to allow public access to collections of ch\", \"ild entities or value objects. Instead,\\nyou want to expose methods that control how and when your fi\", \"elds and property collections can be\\nupdated, and what behavior and actions should occur when that h\", \"appens.\\n\\nSince EF Core 1.1, to satisfy those DDD requirements, you can have plain fields in your ent\", \"ities instead\\nof public properties. If you do not want an entity field to be externally accessible, \", \"you can just create\\nthe attribute or field instead of a property. You can also use private property \", \"setters.\\n\\nIn a similar way, you can now have read-only access to collections by using a public prope\", \"rty typed as\\n[ReadOnlyCollection<T>, which is backed by a private field member for the collection (l\", \"ike a List<T>)\\nin your entity that relies on EF for persistence. Previous versions of Entity Framewo\", \"rk required\\ncollection properties to support ICollection<T>, which meant that any developer using th\", \"e parent\\nentity class could add or remove items through its property collections. That possibility w\", \"ould be\\nagainst the recommended patterns in DDD.\\n\\nYou can use a private collection while exposing a \", \"read-only IReadOnlyCollection<T> object, as shown\\nin the following code example:\\n\\npublic class Order\", \" : Entity\\n{\\n\\n244 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\", \"\\n// Using private fields, allowed since EF Core 1.1\\nprivate DateTime _orderDate;\\n// Other fields ...\", \"\\n\\nprivate readonly List<OrderItem> _orderItems;\\npublic IReadOnlyCollection<OrderItem> OrderItems => \", \"_orderItems;\\n\\nprotected Order() { }\\n\\npublic Order(int buyerId, int paymentMethodId, Address address)\", \"\\n{\\n\\n}\\n\\n// Initializations ...\\n\\npublic void AddOrderItem(int productId, string productName,\\ndecimal u\", \"nitPrice, decimal discount,\\nstring pictureUrl, int units = 1)\\n\\n// Validation logic...\\nvar orderItem \", \"= new OrderItem(productId, productName,\\n\\nunitPrice, discount,\\npictureUrl, units);\\n\\n_orderItems.Add(o\", \"rderItem) ;\\n\\nThe Orderltems property can only be accessed as read-only using IReadOnlyCollection<Ord\", \"erltem>.\\nThis type is read-only so it is protected against regular external updates.\\n\\nEF Core provid\", \"es a way to map the domain model to the physical database without \\u201ccontaminating\\u201d\\nthe domain model. \", \"It is pure .NET POCO code, because the mapping action is implemented in the\\npersistence layer. In th\", \"at mapping action, you need to configure the fields-to-database mapping. In\\nthe following example of\", \" the OnModelCreating method from OrderingContext and the\\nOrderEntityTypeConfiguration class, the cal\", \"l to SetPropertyAccessMode tells EF Core to access the\\nOrderltems property through its field.\\n\\n// At\", \" OrderingContext.cs from eShopOnContainers\\nprotected override void OnModelCreating(ModelBuilder mode\", \"lBuilder)\\n\\n{\\n(i o00\\nmodelBuilder .ApplyConfiguration(new OrderEntityTypeConfiguration() ) ;\\n// Other\", \" entities\\u2019 configuration ...\\n\\n}\\n\\n// At OrderEntityTypeConfiguration.cs from eShopOnContainers\\nclass \", \"OrderEntityTypeConfiguration : IEntityTypeConfiguration<Order>\\n{\\n\\npublic void Configure(EntityTypeBu\", \"ilder<Order> orderConfiguration)\\n\\n{\\norderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_ SC\", \"HEMA) ;\\n// Other configuration\\n\\nvar navigation =\\norderConfiguration.Metadata. FindNavigation(nameof \", \"(Order.OrderItems) ) ;\\n\\n//EF access the OrderItem collection property through its backing field\\nnavi\", \"gation.SetPropertyAccessMode(PropertyAccessMode. Field) ;\\n\\n245 CHAPTER 6 | Tackle Business Complexit\", \"y in a Microservice with DDD and CQRS Patterns\\n// Other configuration\\n\\nWhen you use fields instead o\", \"f properties, the Orderltem entity is persisted as if it had a\\nList<Orderltem> property. However, it\", \" exposes a single accessor, the AddOrderltem method, for\\nadding new items to the order. As a result,\", \" behavior and data are tied together and will be consistent\\nthroughout any application code that use\", \"s the domain model.\\n\\nImplement custom repositories with Entity Framework Core\\n\\nAt the implementation\", \" level, a repository is simply a class with data persistence code coordinated by a\\nunit of work (DBC\", \"ontext in EF Core) when performing updates, as shown in the following class:\\n\\n// using directives...\", \"\\nnamespace Microsoft.eShopOnContainers.Services.Ordering. Infrastructure. Repositories\\n\\nt\\n\\npublic cl\", \"ass BuyerRepository : IBuyerRepository\\n\\n{\\nprivate readonly OrderingContext _context;\\npublic IUnitOfW\", \"ork UnitOfWork\\n\\naf\\nget\\n\\nt\\n}\\n\\nreturn _context;\\n\\n}\\n\\npublic BuyerRepository(OrderingContext context)\\n\\nt\", \"\\n}\\n\\n_context = context ?? throw new ArgumentNullException(nameof (context) ) ;\\n\\npublic Buyer Add(Buy\", \"er buyer)\\n{\\n\\n}\\n\\nreturn _context.Buyers.Add(buyer) .Entity;\\n\\npublic async Task<Buyer> FindAsync(strin\", \"g buyerIdentityGuid)\\n{\\n\\nvar buyer = await _context.Buyers\\n.Include(b => b.Payments)\\n-.Where(b => b.F\", \"ullName == buyerIdentityGuid)\\n.SingleOrDefaultAsync();\\n\\nreturn buyer;\\n\\nThe IBuyerRepository interfac\", \"e comes from the domain model layer as a contract. However, the\\nrepository implementation is done at\", \" the persistence and infrastructure layer.\\n\\nThe EF DbContext comes through the constructor through D\", \"ependency Injection. It is shared between\\nmultiple repositories within the same HTTP request scope, \", \"thanks to its default lifetime\\n(ServiceLifetime.Scoped) in the loC container (which can also be expl\", \"icitly set with\\nservices.AddDbContext< >).\\n\\n246 CHAPTER 6 | Tackle Business Complexity in a Microser\", \"vice with DDD and CQRS Patterns\\nMethods to implement in a repository (updates or transactions versus\", \" queries)\\n\\nWithin each repository class, you should put the persistence methods that update the stat\", \"e of entities\\ncontained by its related aggregate. Remember there is one-to-one relationship between \", \"an aggregate\\nand its related repository. Consider that an aggregate root entity object might have em\", \"bedded child\\nentities within its EF graph. For example, a buyer might have multiple payment methods \", \"as related\\nchild entities.\\n\\nSince the approach for the ordering microservice in eshopOnContainers is\", \" also based on CQS/CQRS,\\nmost of the queries are not implemented in custom repositories. Developers \", \"have the freedom to\\ncreate the queries and joins they need for the presentation layer without the re\", \"strictions imposed by\\naggregates, custom repositories per aggregate, and DDD in general. Most of the\", \" custom repositories\\nsuggested by this guide have several update or transactional methods but just t\", \"he query methods\\nneeded to get data to be updated. For example, the BuyerRepository repository imple\", \"ments a\\nFindAsync method, because the application needs to know whether a particular buyer exists be\", \"fore\\ncreating a new buyer related to the order.\\n\\nHowever, the real query methods to get data to send\", \" to the presentation layer or client apps are\\nimplemented, as mentioned, in the CQRS queries based o\", \"n flexible queries using Dapper.\\n\\nUsing a custom repository versus using EF DbContext directly\\n\\nThe \", \"Entity Framework DbContext class is based on the Unit of Work and Repository patterns and can\\nbe use\", \"d directly from your code, such as from an ASP.NET Core MVC controller. The Unit of Work and\\nReposit\", \"ory patterns result in the simplest code, as in the CRUD catalog microservice in\\neShopOnContainers. \", \"In cases where you want the simplest code possible, you might want to directly\\nuse the DbContext cla\", \"ss, as many developers do.\\n\\nHowever, implementing custom repositories provides several benefits when\", \" implementing more\\ncomplex microservices or applications. The Unit of Work and Repository patterns a\", \"re intended to\\nencapsulate the infrastructure persistence layer so it is decoupled from the applicat\", \"ion and domain-\\nmodel layers. Implementing these patterns can facilitate the use of mock repositorie\", \"s simulating\\naccess to the database.\\n\\nIn Figure 7-18, you can see the differences between not using \", \"repositories (directly using the EF\\nDbContext) versus using repositories, which makes it easier to m\", \"ock those repositories.\\n\\n247 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS Patterns\\nNo Repository With Repository\\nDirect access to database from controller Abstraction lay\", \"er between controller and database context.\\nUnit tests can mock data to facilitate testing\\n\\nWeb Serv\", \"er Web Server Web Server\\n(Kestrel, IIS, etc.) (Kestrel, IIS, etc.) (Kestrel, IIS, etc.)\\n| |\\nControll\", \"er or Controller or Controller or\\nApplication Layer Application Layer Application Layer\\nDbContext\\n\\nR\", \"epository Mock Repository\\n\\nUnit of Work (DbContext)\\n\\nEntity Framework Entity Framework\\nora =\\n\\nFigure\", \" 7-18. Using custom repositories versus a plain DbContext\\n\\nFigure 7-18 shows that using a custom rep\", \"ository adds an abstraction layer that can be used to ease\\ntesting by mocking the repository. There \", \"are multiple alternatives when mocking. You could mock just\\nrepositories or you could mock a whole u\", \"nit of work. Usually mocking just the repositories is enough,\\nand the complexity to abstract and moc\", \"k a whole unit of work is usually not needed.\\n\\nLater, when we focus on the application layer, you wi\", \"ll see how Dependency Injection works in\\nASP.NET Core and how it is implemented when using repositor\", \"ies.\\n\\nIn short, custom repositories allow you to test code more easily with unit tests that are not \", \"impacted\\nby the data tier state. If you run tests that also access the actual database through the E\", \"ntity\\nFramework, they are not unit tests but integration tests, which are a lot slower.\\n\\nIf you were\", \" using DbContext directly, you would have to mock it or to run unit tests by using an in-\\nmemory SQL\", \" Server with predictable data for unit tests. But mocking the DbContext or controlling\\nfake data req\", \"uires more work than mocking at the repository level. Of course, you could always test\\nthe MVC contr\", \"ollers.\\n\\nEF DbContext and IUnitOfWork instance lifetime in your loC container\\n\\nThe DbContext object \", \"(exposed as an IUnitOfWork object) should be shared among multiple\\nrepositories within the same HTTP\", \" request scope. For example, this is true when the operation being\\nexecuted must deal with multiple \", \"aggregates, or simply because you are using multiple repository\\ninstances. It is also important to m\", \"ention that the IUnitOfWork interface is part of your domain layer,\\nnot an EF Core type.\\n\\nIn order t\", \"o do that, the instance of the DbContext object has to have its service lifetime set to\\nServiceLifet\", \"ime.Scoped. This is the default lifetime when registering a DoContext with\\nbuilder.Services.AddDbCon\", \"text in your loC container from the Program.cs file in your ASP.NET Core\\nWeb API project. The follow\", \"ing code illustrates this.\\n\\n248 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD an\", \"d CQRS Patterns\\n// Add framework services.\\nbuilder.Services.AddMvc(options =>\\n\\nt\\n\\noptions. Filters.A\", \"dd(typeof(HttpGlobalExceptionFilter) ) ;\\n}) .AddControllersAsServices();\\n\\nbuilder.Services.AddEntity\", \"FrameworkSq1Server ()\\n.AddDbContext<OrderingContext>(options =>\\n{\\noptions .UseSqlServer (Configurati\", \"on[ \\\"ConnectionString\\\" |,\\nsqlOptions =>\\nsqlOptions .MigrationsAssembly (typeof (Startup) .GetTypeInf\", \"o().\\n\\nAssembly.GetName() .Name) ) ;\\n}5\\nServiceLifetime.Scoped // Note that Scoped is the default cho\", \"ice\\n// in AddDbContext. It is shown here only for\\n// pedagogic purposes.\\n\\n);\\n\\nThe DbContext instanti\", \"ation mode should not be configured as ServiceLifetime.Transient or\\nServiceLifetime.Singleton.\\n\\nThe \", \"repository instance lifetime in your loC container\\n\\nIn a similar way, repository\\u2019s lifetime should u\", \"sually be set as scoped (InstancePerLifetimeScope in\\nAutofac). It could also be transient (InstanceP\", \"erDependency in Autofac), but your service will be more\\nefficient in regards to memory when using th\", \"e scoped lifetime.\\n\\n// Registering a Repository in Autofac IoC container\\nbuilder.RegisterType<OrderR\", \"epository>()\\n\\n.As<IOrderRepository>()\\n.InstancePerLifetimeScope() ;\\n\\nUsing the singleton lifetime fo\", \"r the repository could cause you serious concurrency problems when\\nyour DbContext is set to scoped (\", \"InstancePerLifetimeScope) lifetime (the default lifetimes for a\\nDBContext). As long as your service \", \"lifetimes for your repositories and your DboContext are both\\nScoped, you'll avoid these issues.\\n\\nAdd\", \"itional resources\\n\\n\\u00b0 Implementing the Repository and Unit of Work Patterns in an ASP.NET MVC\\nApplica\", \"tion\\nhttos://www.asp.net/mvc/overview/older-versions/getting-started-with-ef-5-using-mvc-\\n4/implemen\", \"ting-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-application\\n\\n. Jonathan Allen. Imple\", \"mentation Strategies for the Repository Pattern with Entity\\nFramework, Dapper, and Chain\\n\\nhttps://ww\", \"w.infog.com/articles/repository-implementation-strategies\\n\\n. Cesar de la Torre. Comparing ASP.NET Co\", \"re IoC container service lifetimes with Autofac\\n\\nloC container instance scopes\\nhttos://devblogs.micr\", \"osoft.com/cesardelatorre/comparing-asp-net-core-ioc-service-life-\\n\\ntimes-and-autofac-ioc-instance-sc\", \"opes/\\n\\n249 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nTable\", \" mapping\\n\\nTable mapping identifies the table data to be queried from and saved to the database. Prev\", \"iously you\\nsaw how domain entities (for example, a product or order domain) can be used to generate \", \"a related\\ndatabase schema. EF is strongly designed around the concept of conventions. Conventions ad\", \"dress\\nquestions like \\u201cWhat will the name of a table be?\\u201d or \\u201cWhat property is the primary key?\\u201d Conv\", \"entions\\nare typically based on conventional names. For example, it is typical for the primary key to\", \" be a\\nproperty that ends with Id.\\n\\nBy convention, each entity will be set up to map to a table with \", \"the same name as the DbSet<TEntity>\\nproperty that exposes the entity on the derived context. If no D\", \"bSet<TEntity> value is provided for\\nthe given entity, the class name is used.\\n\\nData Annotations vers\", \"us Fluent API\\n\\nThere are many additional EF Core conventions, and most of them can be changed by usi\", \"ng either\\ndata annotations or Fluent API, implemented within the OnModelCreating method.\\n\\nData annot\", \"ations must be used on the entity model classes themselves, which is a more intrusive way\\nfrom a DDD\", \" point of view. This is because you are contaminating your model with data annotations\\nrelated to th\", \"e infrastructure database. On the other hand, Fluent API is a convenient way to change\\nmost conventi\", \"ons and mappings within your data persistence infrastructure layer, so the entity model\\nwill be clea\", \"n and decoupled from the persistence infrastructure.\\n\\nFluent API and the OnModelCreating method\\n\\nAs \", \"mentioned, in order to change conventions and mappings, you can use the OnModelCreating\\nmethod in th\", \"e DbContext class.\\n\\nThe ordering microservice in eShopOnContainers implements explicit mapping and c\", \"onfiguration,\\nwhen needed, as shown in the following code.\\n\\n// At OrderingContext.cs from eShopOnCon\", \"tainers\\nprotected override void OnModelCreating(ModelBuilder modelBuilder)\\n\\n{\\n(i o00\\nmodelBuilder .A\", \"pplyConfiguration(new OrderEntityTypeConfiguration() ) ;\\n// Other entities\\u2019 configuration ...\\n\\n}\\n\\n//\", \" At OrderEntityTypeConfiguration.cs from eShopOnContainers\\nclass OrderEntityTypeConfiguration : IEnt\", \"ityTypeConfiguration<Order>\\n\\n{\\n\\npublic void Configure(EntityTypeBuilder<Order> orderConfiguration)\\no\", \"rderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_ SCHEMA) ;\\norderConfiguration.HasKey(o =\", \"> o.Id);\\norderConfiguration.Ignore(b => b.DomainEvents) ;\\norderConfiguration.Property(o => o.Id)\\n\\n.U\", \"seHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA) ;\\n\\n250 CHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns\\n//Address value object persisted as owned entity type supp\", \"orted since EF Core 2.0\\norderConfiguration\\n.OwnsOne(o => o.Address, a =>\\n\\n{\\n})3\\n\\na.WithOwner () ;\\n\\no\", \"rderConfiguration\\n.Property<int?>(\\\"_buyerId\\\" )\\n.UsePropertyAccessMode(PropertyAccessMode. Field)\\n.Ha\", \"sColumnName(\\\"BuyerId\\\" )\\n. lsRequired( false) ;\\n\\norderConfiguration\\n.Property<DateTime>(\\\"_orderDate\\\" \", \")\\n.UsePropertyAccessMode(PropertyAccessMode. Field)\\n.HasColumnName(\\\"OrderDate\\\" )\\n. [sRequired() ;\\n\\no\", \"rderConfiguration\\n.Property<int>(\\\"_orderStatusId\\\" )\\n.UsePropertyAccessMode(PropertyAccessMode. Field\", \")\\n.HasColumnName(\\\"OrderStatusId\\\" )\\n. [sRequired() ;\\n\\norderConfiguration\\n.Property<int?>(\\\"_paymentMet\", \"hodId\\\" )\\n.UsePropertyAccessMode(PropertyAccessMode. Field)\\n. HasColumnName(\\\"PaymentMethodId\\\" )\\n. lsR\", \"equired( false) ;\\n\\norderConfiguration.Property<string>( \\\"Description\\\" ) .IsRequired(false) ;\\n\\nvar na\", \"vigation =\\n\\norderConfiguration.Metadata. FindNavigation(nameof(Order.OrderItems ) ) ;\\n\\nthrough\\n\\n}\\n\\n/\", \"/ DDD Patterns comment:\\n\\n//Set as field (New since EF 1.1) to access the OrderItem collection proper\", \"ty\\nits field\\n\\nnavigation.SetPropertyAccessMode(PropertyAccessMode. Field) ;\\n\\norderConfiguration.HasO\", \"ne<PaymentMethod> ( )\\n\\n.WithMany ()\\n.HasForeignKkKey(\\\"_paymentMethodId\\\" )\\n. lsRequired( false)\\n\\n.OnD\", \"elete(DeleteBehavior.Restrict) ;\\n\\norderConfiguration.HasOne<Buyer>()\\n.WithMany ()\\n. lsRequired( fals\", \"e)\\n.HasForeignKkey(\\\"_ buyerId\\\") ;\\n\\norderConfiguration.HasOne(o => o.OrderStatus )\\n.WithMany ()\\n.HasF\", \"oreignKkey(\\\"_orderStatusId\\\") ;\\n\\nYou could set all the Fluent API mappings within the same OnModelCre\", \"ating method, but it\\u2019s\\nadvisable to partition that code and have multiple configuration classes, one\", \" per entity, as shown in\\n\\n251\\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and\", \" CQRS Patterns\\nthe example. Especially for large models, it is advisable to have separate configurat\", \"ion classes for\\nconfiguring different entity types.\\n\\nThe code in the example shows a few explicit de\", \"clarations and mapping. However, EF Core\\nconventions do many of those mappings automatically, so the\", \" actual code you would need in your\\ncase might be smaller.\\n\\nThe Hi/Lo algorithm in EF Core\\n\\nAn inter\", \"esting aspect of code in the preceding example is that it uses the Hi/Lo algorithm as the key\\ngenera\", \"tion strategy.\\n\\nThe Hi/Lo algorithm is useful when you need unique keys before committing changes. A\", \"s a summary,\\nthe Hi-Lo algorithm assigns unique identifiers to table rows while not depending on sto\", \"ring the row in\\nthe database immediately. This lets you start using the identifiers right away, as h\", \"appens with regular\\nsequential database IDs.\\n\\nThe Hi/Lo algorithm describes a mechanism for getting \", \"a batch of unique IDs from a related database\\nsequence. These IDs are safe to use because the databa\", \"se guarantees the uniqueness, so there will be\\nno collisions between users. This algorithm is intere\", \"sting for these reasons:\\n\\n. It does not break the Unit of Work pattern.\\n\\u00b0 It gets sequence IDs in ba\", \"tches, to minimize round trips to the database.\\n\\u00b0 It generates a human readable identifier, unlike t\", \"echniques that use GUIDs.\\n\\nEF Core supports HiLo with the UseHiLo method, as shown in the preceding \", \"example.\\n\\nMap fields instead of properties\\n\\nWith this feature, available since EF Core 1.1, you can \", \"directly map columns to fields. It is possible to\\nnot use properties in the entity class, and just t\", \"o map columns from a table to fields. A common use\\nfor that would be private fields for any internal\", \" state that do not need to be accessed from outside the\\nentity.\\n\\nYou can do this with single fields \", \"or also with collections, like a List<> field. This point was mentioned\\nearlier when we discussed mo\", \"deling the domain model classes, but here you can see how that\\nmapping is performed with the Propert\", \"yAccessMode.Field configuration highlighted in the previous\\ncode.\\n\\nUse shadow properties in EF Core,\", \" hidden at the infrastructure level\\n\\nShadow properties in EF Core are properties that do not exist i\", \"n your entity class model. The values\\nand states of these properties are maintained purely in the Ch\", \"angeTracker class at the infrastructure\\nlevel.\\n\\n252 CHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS Patterns\\nImplement the Query Specification pattern\\n\\nAs introduced earlier\", \" in the design section, the Query Specification pattern is a Domain-Driven Design\\npattern designed a\", \"s the place where you can put the definition of a query with optional sorting and\\n\\npaging logic.\\n\\nTh\", \"e Query Specification pattern defines a query in an object. For example, in order to encapsulate a\\np\", \"aged query that searches for some products you can create a PagedProduct specification that takes\\nth\", \"e necessary input parameters (pageNumber, pageSize, filter, etc.). Then, within any Repository\\nmetho\", \"d (usually a List() overload) it would accept an IQuerySpecification and run the expected query\\nbase\", \"d on that specification.\\n\\nAn example of a generic Specification interface is the following code, whi\", \"ch is similar to code used in\\nthe eShopOnWeb reference application.\\n\\n// GENERIC SPECIFICATION INTERF\", \"ACE\\n// https://github. com/dotnet-architecture/eShopOnwWeb\\n\\npublic interface ISpecification<T>\\n\\n{\\nEx\", \"pression<Func<T, bool>> Criteria { get; }\\nList<Expression<Func<T, object>>> Includes { get; }\\nList<s\", \"tring> IncludeStrings { get; }\\n\\nThen, the implementation of a generic specification base class is th\", \"e following.\\n\\n// GENERIC SPECIFICATION IMPLEMENTATION (BASE CLASS)\\n// https://github. com/dotnet-arc\", \"hitecture/eShopOnwWeb\\n\\npublic abstract class BaseSpecification<T> : ISpecification<T>\\n\\nt\\n\\npublic Bas\", \"eSpecification(Expression<Func<T, bool>> criteria)\\n\\nt\\n}\\n\\npublic Expression<Func<T, bool>> Criteria {\", \" get; }\\n\\nCriteria = criteria;\\n\\npublic List<Expression<Func<T, object>>> Includes { get; } =\\nnew List\", \"<Expression<Func<T, object>>>();\\n\\npublic List<string> IncludeStrings { get; } = new List<string>();\\n\", \"\\nprotected virtual void AddInclude(Expression<Func<T, object>> includeExpression)\\n\\nt\\n}\\n\\nIncludes.Add\", \"(includeExpression) ;\\n\\n// string-based includes allow for including children of children\\n// e.g. Bas\", \"ket. Items.Product\\nprotected virtual void AddInclude(string includeString)\\n\\nIncludeStrings .Add(incl\", \"udeString) ;\\n\\n253 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pattern\", \"s\\nThe following specification loads a single basket entity given either the basket\\u2019s ID or the ID of\", \" the\\nbuyer to whom the basket belongs. It will eagerly load the basket's Items collection.\\n\\n// SAMPL\", \"E QUERY SPECIFICATION IMPLEMENTATION\\n\\npublic class BasketWithItemsSpecification : BaseSpecification<\", \"Basket>\\n\\npublic BasketWithItemsSpecification(int basketId)\\n: base(b => b.Id == basketId)\\n\\nAddInclude\", \"(b => b.Items) ;\\n}\\n\\npublic BasketWithItemsSpecification(string buyerId)\\n: base(b => b.BuyerId == buy\", \"erlId)\\n{\\n\\n}\\n\\nAddInclude(b => b.Items) ;\\n\\nAnd finally, you can see below how a generic EF Repository \", \"can use such a specification to filter and\\neager-load data related to a given entity type T.\\n\\n// GEN\", \"ERIC EF REPOSITORY WITH SPECIFICATION\\n// https://github. com/dotnet-architecture/eShopOnwWeb\\n\\npublic\", \" IEnumerable<T> List(ISpecification<T> spec)\\n{\\n// fetch a Queryable that includes all expression-bas\", \"ed includes\\nvar queryableResultWithIncludes = spec.Includes\\n.Aggregate(_dbContext.Set<T>() .AsQuerya\", \"ble(),\\n(current, include) => current.Include(include) );\\n\\n// modify the IQueryable to include any st\", \"ring-based include statements\\nvar secondaryResult = spec.IncludeStrings\\n.Aggregate(queryableResultWi\", \"thIncludes,\\n(current, include) => current.Include(include) );\\n\\n// return the result of the query usi\", \"ng the specification's criteria expression\\nreturn secondaryResult\\n\\n.Where(spec.Criteria)\\n\\n.AsEnumera\", \"ble() ;\\n\\nIn addition to encapsulating filtering logic, the specification can specify the shape of th\", \"e data to be\\nreturned, including which properties to populate.\\n\\nAlthough we don't recommend returnin\", \"g IQueryable from a repository, it\\u2019s perfectly fine to use them\\nwithin the repository to build up a \", \"set of results. You can see this approach used in the List method\\nabove, which uses intermediate IQu\", \"eryable expressions to build up the query\\u2019s list of includes before\\nexecuting the query with the spe\", \"cification\\u2019s criteria on the last line.\\n\\nLearn how the specification pattern is applied in the eshop\", \"OnWeb sample.\\n\\n254 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patter\", \"ns\\nAdditional resources\\n\\n\\u00b0 Table Mapping\\nhttps://learn.microsoft.com/ef/core/modeling/relational/tab\", \"les\\n\\n. Use HiLo to generate keys with Entity Framework Core\\nhttos://www.talkingdotnet.com/use-hilo-t\", \"o-generate-keys-with-entity-framework-core\\n\\n\\u00b0 Backing Fields\\nhttps://learn.microsoft.com/ef/core/mod\", \"eling/backing-field\\n\\n\\u00b0 Steve Smith. Encapsulated Collections in Entity Framework Core\\n\\nhttps://ardal\", \"is.com/encapsulated-collections-in-entity-framework-core\\n\\n. Shadow Properties\\n\\nhttps://learn.microso\", \"ft.com/ef/core/modeling/shadow-properties\\n\\n\\u00b0 The Specification pattern\\n\\nhttps://devig.com/specificat\", \"ion-pattern/\\n\\nArdalis.Specification NuGet Package Used by\\neShopOnWeb. https://www.nuget.org/packages\", \"/Ardalis.Specification\\n\\nUse NoSQL databases as a persistence infrastructure\\n\\nWhen you use NoSQL data\", \"bases for your infrastructure data tier, you typically do not use an ORM like\\nEntity Framework Core.\", \" Instead you use the API provided by the NoSQL engine, such as Azure Cosmos\\nDB, MongoDB, Cassandra, \", \"RavenDB, CouchDB, or Azure Storage Tables.\\n\\nHowever, when you use a NoSQL database, especially a doc\", \"ument-oriented database like Azure\\nCosmos DB, CouchDB, or RavenDB, the way you design your model wit\", \"h DDD aggregates is partially\\nsimilar to how you can do it in EF Core, in regards to the identificat\", \"ion of aggregate roots, child entity\\nclasses, and value object classes. But, ultimately, the databas\", \"e selection will impact in your design.\\n\\nWhen you use a document-oriented database, you implement an\", \" aggregate as a single document,\\nserialized in JSON or another format. However, the use of the datab\", \"ase is transparent from a domain\\nmodel code point of view. When using a NoSQL database, you still ar\", \"e using entity classes and\\naggregate root classes, but with more flexibility than when using EF Core\", \" because the persistence is\\nnot relational.\\n\\nThe difference is in how you persist that model. If you\", \" implemented your domain model based on\\nPOCO entity classes, agnostic to the infrastructure persiste\", \"nce, it might look like you could move to a\\ndifferent persistence infrastructure, even from relation\", \"al to NoSQL. However, that should not be your\\ngoal. There are always constraints and trade-offs in t\", \"he different database technologies, so you will\\nnot be able to have the same model for relational or\", \" NoSQL databases. Changing persistence models\\nis not a trivial task, because transactions and persis\", \"tence operations will be very different.\\n\\nFor example, in a document-oriented database, it is okay f\", \"or an aggregate root to have multiple child\\ncollection properties. In a relational database, queryin\", \"g multiple child collection properties is not\\n\\n255 CHAPTER 6 | Tackle Business Complexity in a Micro\", \"service with DDD and CQRS Patterns\\neasily optimized, because you get a UNION ALL SQL statement back \", \"from EF. Having the same\\ndomain model for relational databases or NoSQL databases is not simple, and\", \" you should not try to\\ndo it. You really have to design your model with an understanding of how the \", \"data is going to be\\nused in each particular database.\\n\\nA benefit when using NoSQL databases is that \", \"the entities are more denormalized, so you do not set a\\ntable mapping. Your domain model can be more\", \" flexible than when using a relational database.\\n\\nWhen you design your domain model based on aggrega\", \"tes, moving to NoSQL and document-\\noriented databases might be even easier than using a relational d\", \"atabase, because the aggregates\\nyou design are similar to serialized documents in a document-oriente\", \"d database. Then you can\\ninclude in those \\u201cbags\\u201d all the information you might need for that aggrega\", \"te.\\n\\nFor instance, the following JSON code is a sample implementation of an order aggregate when usi\", \"ng\\na document-oriented database. It is similar to the order aggregate we implemented in the\\neShopOnC\", \"ontainers sample, but without using EF Core underneath.\\n\\n\\\"id\\\": \\\"2024001\\\",\\n\\\"\\u201corderDate\\\": \\\"2/25/2024\\\",\", \"\\n\\u201cbuyerId\\\": \\\"1234567\\\",\\n\\\"address\\\": [\\n{\\n\\\"street\\\": \\\"10@ One Microsoft Way\\\",\\n\\\"city\\\": \\\"Redmond\\\",\\n\\\"state\\\":\", \" \\\"WA\\\",\\n\\\"Zip\\\": \\\"98052\\\",\\n\\\"country\\\": \\\"U.S.\\\"\\n\\n}\\n\\n],\\n\\n\\u201corderItems\\\": [\\n{\\\"id\\\": 20240011, \\\"productId\\\": \\\"1234\", \"56\\\", \\\"\\u201cproductName\\\": \\\".NET T-Shirt\\\",\\n\\\"unitPrice\\\": 25, \\\"units\\\": 2, \\\"discount\\\": 0},\\n{\\\"id\\\": 20240012, \\\"\", \"productId\\\": \\\"123457\\\", \\\"\\u201cproductName\\\": \\\".NET Mug\\\",\\n\\\"unitPrice\\\": 15, \\\"units\\\": 1, \\\"discount\\\": 0}\\n\\nIntro\", \"duction to Azure Cosmos DB and the native Cosmos DB API\\n\\nAzure Cosmos DB is Microsoft's globally dis\", \"tributed database service for mission-critical applications.\\nAzure Cosmos DB provides turn-key globa\", \"l distribution, elastic scaling of throughput and storage\\nworldwide, single-digit millisecond latenc\", \"ies at the 99th percentile, five well-defined consistency\\nlevels, and guaranteed high availability, \", \"all backed by industry-leading SLAs. Azure Cosmos DB\\nautomatically indexes data without requiring yo\", \"u to deal with schema and index management. It is\\nmulti-model and supports document, key-value, grap\", \"h, and columnar data models.\\n\\n256 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD \", \"and CQRS Patterns\\n+.\\u00b0\\n\\nAzure Cosmos DB\\n\\nKey-Value Column-family Documents Graph\\n\\ns=3 \\u00a9-000 a = oe i\\n\", \"\\no 3 e @ \\u2014\\nGlobal distribution Elastic scale out Guaranteed low latency Five consistency models Comp\", \"rehensive SLAs\\n\\nFigure 7-19. Azure Cosmos DB global distribution\\n\\nWhen you use a C# model to impleme\", \"nt the aggregate to be used by the Azure Cosmos DB API, the\\naggregate can be similar to the C# POCO \", \"classes used with EF Core. The difference is in the way to\\nuse them from the application and infrast\", \"ructure layers, as in the following code:\\n\\n// C# EXAMPLE OF AN ORDER AGGREGATE BEING PERSISTED WITH \", \"AZURE COSMOS DB API\\n\\n// *** Domain Model Code ***\\n\\n// Aggregate: Create an Order object with its chi\", \"ld entities and/or value objects.\\n// Then, use AggregateRoot's methods to add the nested objects so \", \"invariants and\\n// logic is consistent across the nested properties (value objects and entities).\\n\\nOr\", \"der orderAggregate = new Order\\n\\n{\\nId = \\\"2024001\\\",\\nOrderDate = new DateTime(2005, 7, 1),\\nBuyerId = \\\"1\", \"234567\\\",\\nPurchaseOrderNumber = \\\"P018009186470\\\"\\n}\\nAddress address = new Address\\n{\\nStreet = \\\"100 One M\", \"icrosoft Way\\\",\\nCity = \\\"Redmond\\\",\\nState = \\\"WA\\\",\\nZip = \\\"98052\\\",\\nCountry = \\\"U.S.\\\"\\n}\\n\\norderAggregate.Upd\", \"ateAddress(address) ;\\n\\nOrderItem orderItem1 = new OrderItem\\n\\nt\\n\\n257 CHAPTER 6 | Tackle Business Comp\", \"lexity in a Microservice with DDD and CQRS Patterns\\nId = 20240011,\\n\\nProductId = \\\"123456\\\",\\nProductNam\", \"e = \\\".NET T-Shirt\\\",\\nUnitPrice = 25,\\n\\nUnits = 2,\\n\\nDiscount = @;\\n\\nPe\\n\\n//Using methods with domain logi\", \"c within the entity. No anemic-domain model\\norderAggregate.AddOrderItem(orderItem1) ;\\n// *** End of \", \"Domain Model Code ***\\n\\n// *** Infrastructure Code using Cosmos DB Client API ***\\nUri collectionUri =\", \" UriFactory.CreateDocumentCollectionUri(databaseName,\\n\\ncollectionName) ;\\n\\nawait client.CreateDocumen\", \"tAsync(collectionUri, orderAggregate) ;\\n\\n// As your app evolves, let's say your object has a new sch\", \"ema. You can insert\\n// OrderV2 objects without any changes to the database tier.\\n\\nOrder2 newOrder = \", \"GetOrderV2Sample(\\\"IdForSalesOrder2\\\") ;\\n\\nawait client.CreateDocumentAsync(collectionUri, newOrder) ;\\n\", \"\\nYou can see that the way you work with your domain model can be similar to the way you use it in\\nyo\", \"ur domain model layer when the infrastructure is EF. You still use the same aggregate root methods\\nt\", \"o ensure consistency, invariants, and validations within the aggregate.\\n\\nHowever, when you persist y\", \"our model into the NoSQL database, the code and API change\\ndramatically compared to EF Core code or \", \"any other code related to relational databases.\\n\\nImplement .NET code targeting MongoDB and Azure Cos\", \"mos DB\\n\\nUse Azure Cosmos DB from .NET containers\\n\\nYou can access Azure Cosmos DB databases from .NET\", \" code running in containers, like from any other\\n.NET application. For instance, the Locations.API a\", \"nd Marketing.API microservices in\\neShopOnContainers are implemented so they can consume Azure Cosmos\", \" DB databases.\\n\\nHowever, there's a limitation in Azure Cosmos DB from a Docker development environme\", \"nt point of\\nview. Even though there's an on-premises Azure Cosmos DB Emulator that can run in a loca\", \"l\\ndevelopment machine, it only supports Windows. Linux and macOS aren't supported.\\n\\nThere's also the\", \" possibility to run this emulator on Docker, but just on Windows Containers, not with\\nLinux Containe\", \"rs. That's an initial handicap for the development environment if your application is\\ndeployed as Li\", \"nux containers, since, currently, you can't deploy Linux and Windows Containers on\\nDocker for Window\", \"s at the same time. Either all containers being deployed have to be for Linux or for\\nWindows.\\n\\nThe i\", \"deal and more straightforward deployment for a dev/test solution is to be able to deploy your\\ndataba\", \"se systems as containers along with your custom containers so your dev/test environments are\\nalways \", \"consistent.\\n\\n258 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\", \"\\nUse MongoDB API for local dev/test Linux/Windows containers plus Azure Cosmos\\nDB\\n\\nCosmos DB databas\", \"es support MongoDB API for .NET as well as the native MongoDB wire protocol.\\nThis means that by usin\", \"g existing drivers, your application written for MongoDB can now\\ncommunicate with Cosmos DB and use \", \"Cosmos DB databases instead of MongoDB databases, as\\n\\n+.\\u00b0\\n\\nshown in Figure 7-20.\\n\\n@Q a=<=a\\u201c\\u201cs8s5 \\u00a9 s\", \"2s2528=s=8=8se8s8=8== 9\\n\\nMongoDB wire protocol\\n\\nAzure Cosmos DB:\\nAPI for MongoDB\\n\\nFigure 7-20. Using\", \" MongoDB API and protocol to access Azure Cosmos DB\\n\\nThis is a very convenient approach for proof of\", \" concepts in Docker environments with Linux\\ncontainers because the MongoDB Docker image is a multi-a\", \"rch image that supports Docker Linux\\ncontainers and Docker Windows containers.\\n\\nAs shown in the foll\", \"owing image, by using the MongoDB API, eSshopOnContainers supports MongoDB\\nLinux and Windows contain\", \"ers for the local development environment but then, you can move to a\\nscalable, PaaS cloud solution \", \"as Azure Cosmos DB by simply changing the MongoDB connection\\n\\nstring to point to Azure Cosmos DB.\\n\\n2\", \"59 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nAzure\\nCosmos \", \"DB\\n\\nMongoDB\\nwire protocol\\n\\nMongoDB\\nmongoDB container\\n\\ncontainer\\n\\nLocation microservice\\n(eShopOnConta\", \"iners)\\n\\nFigure 7-21. eShopOnContainers using MongoDB containers for dev-env or Azure Cosmos DB for p\", \"roduction\\n\\nThe production Azure Cosmos DB would be running in Azure's cloud as a PaaS and scalable s\", \"ervice.\\n\\nYour custom .NET containers can run on a local development Docker host (that is using Docke\", \"r for\\nWindows in a Windows 10 machine) or be deployed into a production environment, like Kubernetes\", \" in\\nAzure AKS or Azure Service Fabric. In this second environment, you would deploy only the .NET\\ncu\", \"stom containers but not the MongoDB container since you'd be using Azure Cosmos DB in the\\ncloud for \", \"handling the data in production.\\n\\nA clear benefit of using the MongoDB API is that your solution cou\", \"ld run in both database engines,\\nMongoDB or Azure Cosmos DB, so migrations to different environments\", \" should be easy. However,\\nsometimes it is worthwhile to use a native API (that is the native Cosmos \", \"DB API) in order to take full\\nadvantage of the capabilities of a specific database engine.\\n\\nFor furt\", \"her comparison between simply using MongoDB versus Cosmos DB in the cloud, see the\\nBenefits of using\", \" Azure Cosmos DB in this page.\\n\\nAnalyze your approach for production applications: MongoDB API vs. C\", \"osmos DB\\nAPI\\n\\nIn eShopOnContainers, we're using MongoDB API because our priority was fundamentally t\", \"o have a\\nconsistent dev/test environment using a NoSQL database that could also work with Azure Cosm\", \"os DB.\\n\\n260 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nHowe\", \"ver, if you are planning to use MongoDB API to access Azure Cosmos DB in Azure for\\nproduction applic\", \"ations, you should analyze the differences in capabilities and performance when\\nusing MongoDB API to\", \" access Azure Cosmos DB databases compared to using the native Azure\\nCosmos DB API. If it is similar\", \" you can use MongoDB API and you get the benefit of supporting two\\nNoSQL database engines at the sam\", \"e time.\\n\\nYou could also use MongoDB clusters as the production database in Azure's cloud, too, with\\n\", \"MongoDB Azure Service. But that is not a PaaS service provided by Microsoft. In this case, Azure is \", \"just\\nhosting that solution coming from MongoDB.\\n\\nBasically, this is just a disclaimer stating that y\", \"ou shouldn't always use MongoDB API against Azure\\nCosmos DB, as we did in eshopOnContainers because \", \"it was a convenient choice for Linux containers.\\nThe decision should be based on the specific needs \", \"and tests you need to do for your production\\napplication.\\n\\nThe code: Use MongoDB API in .NET applica\", \"tions\\n\\nMongoDB API for .NET is based on NuGet packages that you need to add to your projects, like i\", \"n the\\nLocations.API project shown in the following figure.\\n\\n261 CHAPTER 6 | Tackle Business Complexi\", \"ty in a Microservice with DDD and CQRS Patterns\\na]\\n\\nGe Connected Services\\n4 oon Dependencies\\n\\n>b og \", \"Analyzers\\n\\nbP =f] Frameworks\\n\\n4 \\u2018Packages\\n\\u2018@ AspNetCore.HealthChecks.AzureServiceBus (3.0.0)\\n\\u2018@ AspN\", \"etCore.HealthChecks.MongoDb (3.0.1)\\n'@ AspNetCore.HealthChecks.Rabbitmg (3.0.3)\\n\\u2018@ AspNetCore.Health\", \"Checks. Ul. Client (3.0.0)\\n\\u2018@ Autofac.Extensions.Dependencylnjection (5.0.1)\\n\\u2018@ Microsoft.Applicatio\", \"nInsights.AspNetCore (2.12.0)\\n'@ Microsoft.ApplicationInsights.DependencyCollector (2.12.0)\\n\\u2018@ Micro\", \"soft.ApplicationInsights.Kubernetes (1.1.1)\\n'@ Microsoft.AspNetCore.Authentication.JwtBearer (3.1.0)\", \"\\n\\u2018@ Microsoft.AspNetCore. Diagnostics. HealthChecks (2.2.0)\\n'@ Microsoft.AspNetCore.HealthChecks (1.\", \"0.0)\\n'@ Microsoft.AspNetCore.Mvc.Newtonsoftlson (3.1.0)\\n'@ Microsoft.Extensions.Configuration.AzureK\", \"eyVault (3.1.0)\\nF Microsoft.Extensions.Logging.AzureAppServices (3.1.0)\\n'@ MongoDB.Bson (2.10.0)\\n\\u2018@ \", \"MongoDB. Driver (2.10.0)\\n\\u2018@ MongoDB.Driver.Core (2.10.0)\\n'B Serilog.AspNetCore (3.2.0)\\nenlog.Enniche\", \"rs.Environment (2.1.3)\\nenlog. Settings. Configuration (3.1.1-dev-00216)\\nerilog.Sinks.Console (4.0.0-\", \"dev-O0834)\\nerilog.Sinks.Http (5.2.0)\\nerilog.Sinks.seq (4.1.0-dev-00166)\\nwashbuckleAspNetCore (5.0.0-\", \"rc5)\\n\\nb fF) Projects\\n> af Properties\\n\\n[i\\nb\\nit\\nf\\n[i\\n[3\\nit\\nb\\n[i\\n[3\\nb\\nb\\nb\\nf\\nb\\n[\\n[i\\nb\\nb\\n[\\n[i\\nb\\nb\\n\\nFigure\", \" 7-22. MongoDB API NuGet packages references in a .NET project\\n\\nLet's investigate the code in the fo\", \"llowing sections.\\n\\nFirst, you need to define a model that will hold the data coming from the databas\", \"e in your\\napplication's memory space. Here\\u2019s an example of the model used for Locations at\\neShopOnCo\", \"ntainers.\\n\\nMongoDB.Bson;\\nMongoDB.Bson.Serialization.Attributes ;\\nMongoDB.Driver.GeoJsonObjectModel ;\", \"\\nSystem.Collections.Generic;\\n\\nLocations\\n[BsonId]\\n[| BsonRepresentation(BsonType.ObjectId) |\\npublic s\", \"tring Id { get; set; }\\npublic int LocationId { get; set; }\\npublic string Code { get; set; }\\n[| BsonR\", \"epresentation(BsonType.ObjectId) |\\npublic string Parent_Id { get; set; }\\npublic string Description {\", \" get; set; }\\npublic double Latitude { get; set; }\\npublic double Longitude { get; set; }\\npublic GeoJs\", \"onPoint<GeoJson2DGeographicCoordinates> Location\\n\\n{ get; private set; }\\npublic GeoJsonPolygon<GeoJso\", \"n2DGeographicCoordinates> Polygon\\n\\n{ get; private set; }\\npublic void SetLocation(double lon, double \", \"lat) => SetPosition(lon, lat);\\npublic void SetArea(List<GeoJson2DGeographicCoordinates> coordinatesL\", \"ist )\\n\\n=> SetPolygon(coordinatesList) ;\\n\\nprivate void SetPosition(double lon, double lat)\\n\\n{\\nLatitud\", \"e = lat;\\nLongitude = lon;\\nLocation = new GeoJsonPoint<GeoJson2DGeographicCoordinates > (\\nnew GeoJson\", \"2DGeographicCoordinates(lon, lat));\\n}\\nprivate void SetPolygon(List<GeoJson2DGeographicCoordinates> c\", \"oordinatesList)\\n{\\nPolygon = new GeoJsonPolygon<GeoJson2DGeographicCoordinates> (\\nnew GeoJsonPolygonC\", \"oordinates<GeoJson2DGeographicCoordinates > (\\nnew GeoJsonLinearRingCoordinates<GeoJson2DGeographicCo\", \"ordinates > (\\ncoordinatesList) ));\\n}\\n\\n}\\n\\nYou can see there are a few attributes and types coming fro\", \"m the MongoDB NuGet packages.\\n\\nNoSQL databases are usually very well suited for working with non-rel\", \"ational hierarchical data. In this\\nexample, we are using MongoDB types especially made for geo-locat\", \"ions, like\\nGeoJson2DGeographicCoordinates.\\n\\nRetrieve the database and the collection\\n\\nIn eShopOnCont\", \"ainers, we have created a custom database context where we implement the code to\\nretrieve the databa\", \"se and the MongoCollections, as in the following code.\\n\\npublic class LocationsContext\\n\\nt\\n\\nprivate re\", \"adonly IMongoDatabase _database = null;\\n\\npublic LocationsContext(IOptions<LocationSettings> settings\", \")\\n\\n{\\nvar client = new MongoClient(settings.Value.ConnectionString) ;\\nif (client != null)\\n_database =\", \" client.GetDatabase(settings.Value.Database) ;\\n}\\npublic IMongoCollection<Locations> Locations\\n{\\n\\n263\", \" CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nget\\naf\\n\\nreturn \", \"database.GetCollection<Locations>(\\\"Locations\\\") ;\\n\\nRetrieve the data\\n\\nIn C# code, like Web API contro\", \"llers or custom Repositories implementation, you can write similar\\ncode to the following when queryi\", \"ng through the MongoDB API. Note that the _context object is an\\ninstance of the previous LocationsCo\", \"ntext class.\\n\\npublic async Task<Locations> GetAsync(int locationId)\\n{\\nvar filter = Builders<Location\", \"s>.Filter.Eq(\\\"LocationId\\\", locationId) ;\\nreturn await _context.Locations\\n.Find(filter)\\n.FirstOrDefau\", \"ltAsync();\\n\\nUse an env-var in the docker-compose.override.yml file for the MongoDB connection\\nstring\", \"\\n\\nWhen creating a MongoClient object, it needs a fundamental parameter which is precisely the\\nConnec\", \"tionString parameter pointing to the right database. In the case of eShopOnContainers, the\\nconnectio\", \"n string can point to a local MongoDB Docker container or to a \\u201cproduction\\u201d Azure Cosmos\\nDB database\", \". That connection string comes from the environment variables defined in the docker-\\ncompose.overrid\", \"e.yml files used when deploying with docker-compose or Visual Studio, as in the\\nfollowing yml code.\\n\", \"\\n# docker-compose.override.yml\\nversion: '3.4'\\nservices:\\n# Other services\\nlocations-api:\\nenvironment:\", \"\\n# Other settings\\n- ConnectionString=${ESHOP_AZURE_COSMOSDB: -mongodb://nosqldata}\\n\\nThe ConnectionSt\", \"ring environment variable is resolved this way: If the ESHOP_AZURE_COSMOSDB\\nglobal variable is defin\", \"ed in the .env file with the Azure Cosmos DB connection string, it will use it to\\naccess the Azure C\", \"osmos DB database in the cloud. If it\\u2019s not defined, it will take the\\nmongodb://nosqldata value and \", \"use the development MongoDB container.\\n\\nThe following code shows the .env file with the Azure Cosmos\", \" DB connection string global\\nenvironment variable, as implemented in eShopOnContainers:\\n\\n# .env file\", \", in eShopOnContainers root folder\\n# Other Docker environment variables\\n\\nESHOP_EXTERNAL_DNS_NAME_OR_\", \"IP=host.docker. internal\\nESHOP_PROD_EXTERNAL_DNS NAME_OR_IP=<YourDockerHostIP>\\n\\n#ESHOP_AZURE_COSMOSD\", \"B=< YourAzureCosmosDBConnData>\\n\\n264 CHAPTER 6 | Tackle Business Complexity in a Microservice with DD\", \"D and CQRS Patterns\\n#Other environment variables for additional Azure infrastructure assets\\n#ESHOP_A\", \"ZURE_REDIS_BASKET_DB=<YourAzureRedisBasketInfo>\\n#ESHOP_AZURE_STORAGE_CATALOG_URL=<YourAzureStorage C\", \"atalog BLOB_URL>\\n#ESHOP_AZURE_SERVICE_BUS=<YourAzureServiceBusInfo>\\n\\nUncomment the ESHOP_AZURE_COSMO\", \"SDB line and update it with your Azure Cosmos DB\\nconnection string obtained from the Azure portal as\", \" explained in Connect a MongoDB application to\\nAzure Cosmos DB.\\n\\nIf the ESHOP_AZURE_COSMOSDB global \", \"variable is empty, meaning it's commented out in the .env\\nfile, then the container uses a default Mo\", \"ngoDB connection string. This connection string points to\\nthe local MongoDB container deployed in es\", \"hopOnContainers that is named nosqidata and was\\ndefined at the docker-compose file, as shown in the \", \"following .yml code:\\n\\n# docker-compose.yml\\nversion: '3.4'\\nservices:\\n# ...Other services...\\nnosqldata\", \":\\nimage: mongo\\n\\nAdditional resources\\n\\n. Modeling document data for NoSQL databases\\nhttps://learn.mic\", \"rosoft.com/azure/cosmos-db/modeling-data\\n\\n\\u00b0 Vaughn Vernon. The Ideal Domain-Driven Design Aggregate \", \"Store?\\nhttps://kalele.io/blog-posts/the-ideal-domain-driven-design-agagregate-store\\n\\n\\u00b0 Introduction \", \"to Azure Cosmos DB: API for MongoDB\\nhttps://learn.microsoft.com/azure/cosmos-db/mongodb-introduction\", \"\\n\\n\\u00b0 Azure Cosmos DB: Build a MongoDB API web app with .NET and the Azure portal\\nhttps://learn.micros\", \"oft.com/azure/cosmos-db/create-mongodb-dotnet\\n\\n\\u00b0 Use the Azure Cosmos DB Emulator for local developm\", \"ent and testing\\n\\nhttps://learn.microsoft.com/azure/cosmos-db/local-emulator\\n\\n. Connect a MongoDB app\", \"lication to Azure Cosmos DB\\n\\nhttps://learn.microsoft.com/azure/cosmos-db/connect-mongodb-account\\n\\n\\u00b0 \", \"The Cosmos DB Emulator Docker image (Windows Container)\\n\\nhttps://hub.docker.com/r/microsoft/azure-co\", \"smosdb-emulator/\\n\\n\\u00b0 The MongoDB Docker image (Linux and Windows Container)\\n\\nhttps://hub.docker.com/_\", \"/mongo/\\n\\n\\u00b0 Use MongoChef (Studio 3T) with an Azure Cosmos DB: API for MongoDB account\\nhttps://learn.\", \"microsoft.com/azure/cosmos-db/mongodb-mongochef\\n\\n265 CHAPTER 6 | Tackle Business Complexity in a Mic\", \"roservice with DDD and CQRS Patterns\\nDesign the microservice application layer and Web\\nAPI\\n\\nUse SOLI\", \"D principles and Dependency Injection\\n\\nSOLID principles are critical techniques to be used in any mo\", \"dern and mission-critical application,\\nsuch as developing a microservice with DDD patterns. SOLID is\", \" an acronym that groups five\\nfundamental principles:\\n\\n\\u00b0 Single Responsibility principle\\n\\n. Open/clos\", \"ed principle\\n\\n. Liskov substitution principle\\n. Interface Segregation principle\\n\\u00b0 Dependency Inversi\", \"on principle\\n\\nSOLID is more about how you design your application or microservice internal layers an\", \"d about\\ndecoupling dependencies between them. It is not related to the domain, but to the applicatio\", \"n's\\ntechnical design. The final principle, the Dependency Inversion principle, allows you to decoupl\", \"e the\\ninfrastructure layer from the rest of the layers, which allows a better decoupled implementati\", \"on of the\\nDDD layers.\\n\\nDependency Injection (Dl) is one way to implement the Dependency Inversion pr\", \"inciple. It is a\\ntechnique for achieving loose coupling between objects and their dependencies. Rath\", \"er than directly\\ninstantiating collaborators, or using static references (that is, using new...), th\", \"e objects that a class\\nneeds in order to perform its actions are provided to (or \\u201cinjected into\\u201d) th\", \"e class. Most often, classes\\nwill declare their dependencies via their constructor, allowing them to\", \" follow the Explicit\\nDependencies principle. Dependency Injection is usually based on specific Inver\", \"sion of Control (loC)\\ncontainers. ASP.NET Core provides a simple built-in loC container, but you can\", \" also use your favorite\\nloC container, like Autofac or Ninject.\\n\\nBy following the SOLID principles, \", \"your classes will tend naturally to be small, well-factored, and easily\\ntested. But how can you know\", \" if too many dependencies are being injected into your classes? If you\\nuse DI through the constructo\", \"r, it will be easy to detect that by just looking at the number of\\nparameters for your constructor. \", \"If there are too many dependencies, this is generally a sign (a code\\nsmell) that your class is tryin\", \"g to do too much, and Is probably violating the Single Responsibility\\nprinciple.\\n\\nIt would take anot\", \"her guide to cover SOLID in detail. Therefore, this guide requires you to have only a\\nminimum knowle\", \"dge of these topics.\\nAdditional resources\\n\\n\\u00b0 SOLID: Fundamental OOP Principles\\nhttps://devig.com/sol\", \"id/\\n\\n266 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\n. Inver\", \"sion of Control Containers and the Dependency Injection pattern\\n\\nhttps://martinfowler.com/articles/i\", \"njection.html|\\n\\n\\u00b0 Steve Smith. New is Glue\\n\\nhttps://ardalis.com/new-is-glue\\n\\nImplement the microserv\", \"ice application layer using\\nthe Web API\\n\\nUse Dependency Injection to inject infrastructure objects i\", \"nto your\\napplication layer\\n\\nAs mentioned previously, the application layer can be implemented as par\", \"t of the artifact (assembly)\\nyou are building, such as within a Web API project or an MVC web app pr\", \"oject. In the case of a\\nmicroservice built with ASP.NET Core, the application layer will usually be \", \"your Web API library. If you\\nwant to separate what is coming from ASP.NET Core (its infrastructure p\", \"lus your controllers) from your\\ncustom application layer code, you could also place your application\", \" layer in a separate class library,\\nbut that is optional.\\n\\nFor instance, the application layer code \", \"of the ordering microservice is directly implemented as part of\\nthe Ordering.API project (an ASP.NET\", \" Core Web API project), as shown in Figure 7-23.\\n\\n4 a] Ordering.API\\nG\\u00ae> Connected Services\\nb ti\\\" Dep\", \"endencies\\n> aS Properties\\nb> a) Behaviors\\na!) Commands\\naf DomainEventHandlers\\naf IntegrationEvents\\na\", \"l Models\\nal Queries\\nb af Validations\\nal Controllers\\nafl Extensions\\naf Infrastructure\\nal Setup\\n\\nVv VV\", \" VY YT\\n\\nVv VV YW\\n\\nFigure 7-23. The application layer in the Ordering.API ASP.NET Core Web API projec\", \"t\\n\\nASP.NET Core includes a simple built-in loC container (represented by the |ServiceProvider interf\", \"ace)\\nthat supports constructor injection by default, and ASP.NET makes certain services available th\", \"rough\\nDI. ASP.NET Core uses the term service for any of the types you register that will be injected\", \" through\\nDI. You configure the built-in container\\u2019s services in your application\\u2019s Program.cs file. \", \"Your\\n\\n267 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\ndepend\", \"encies are implemented in the services that a type needs and that you register in the loC\\ncontainer.\", \"\\n\\nTypically, you want to inject dependencies that implement infrastructure objects. A typical\\ndepend\", \"ency to inject is a repository. But you could inject any other infrastructure dependency that\\nyou ma\", \"y have. For simpler implementations, you could directly inject your Unit of Work pattern object\\n(the\", \" EF DbContext object), because the DBContext is also the implementation of your infrastructure\\npersi\", \"stence objects.\\n\\nIn the following example, you can see how .NET Is injecting the required repository\", \" objects through\\nthe constructor. The class is a command handler, which will get covered in the next\", \" section.\\n\\npublic class CreateOrderCommandHandler\\n: IRequestHandler<CreateOrderCommand, bool>\\n{\\npriv\", \"ate readonly IOrderRepository _orderRepository;\\nprivate readonly IIdentityService _identityService;\\n\", \"private readonly IMediator _mediator;\\nprivate readonly IOrderingIntegrationEventService _orderingInt\", \"egrationEventService;\\nprivate readonly ILogger<CreateOrderCommandHandler> _logger;\\n\\n// Using DI to i\", \"nject infrastructure persistence Repositories\\npublic CreateOrderCommandHandler(IMediator mediator,\\nT\", \"OrderingIntegrationEventService orderingIntegrationEventService,\\nIOrderRepository orderRepository,\\nI\", \"IdentityService identityService,\\nILogger<CreateOrderCommandHandler> logger)\\n{\\n_orderRepository = ord\", \"erRepository ?? throw new\\nArgumentNullException(nameof (orderRepository) ) ;\\n_identityService = iden\", \"tityService ?? throw new\\nArgumentNullException(nameof (identityService) ) ;\\n_mediator = mediator ?? \", \"throw new ArgumentNullException(nameof(mediator) ) ;\\n_orderingIintegrationEventService = orderingInt\", \"egrationEventService ?? throw new\\nArgumentNullException(nameof (orderingIntegrationEventService) ) ;\", \"\\n_logger = logger ?? throw new ArgumentNullException(nameof (logger) ) ;\\n\\n}\\n\\npublic async Task<bool>\", \" Handle(CreateOrderCommand message, CancellationToken\\ncancellationToken)\\n{\\n// Add Integration event \", \"to clean the basket\\nvar orderStartedIntegrationEvent = new\\nOrderStartedIntegrationEvent(message.User\", \"Id) ;\\nawait\\n_orderingIntegrationEventService.AddAndSaveEventAsync (orderStartedIntegrationEvent ) ;\\n\", \"\\n// Add/Update the Buyer AggregateRoot\\n\\n// DDD patterns comment: Add child entities and value-object\", \"s through the Order\\nAggregate-Root\\n\\n// methods and constructor so validations, invariants and busine\", \"ss logic\\n\\n// make sure that consistency is preserved across the whole aggregate\\n\\nvar address = new A\", \"ddress(message.Street, message.City, message.State,\\nmessage.Country, message.ZipCode) ;\\n\\nvar order =\", \" new Order(message.UserId, message.UserName, address,\\nmessage.CardTypeld, message.CardNumber, messag\", \"e.CardSecurityNumber, message.CardHolderName,\\nmessage.CardExpiration) ;\\n\\nforeach (var item in messag\", \"e.OrderItems )\\n\\n268 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rns\\nt\\n\\norder.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice,\\nitem.Discount, item.Pict\", \"ureUrl, item.Units) ;\\n\\n}\\n\\n_logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\\n\\n\", \"_orderRepository.Add(order) ;\\n\\nreturn await _orderRepository.UnitOfWork\\n.SaveEntitiesAsync(cancellat\", \"ionToken) ;\\n\\nThe class uses the injected repositories to execute the transaction and persist the sta\", \"te changes. It\\ndoes not matter whether that class is a command handler, an ASP.NET Core Web API cont\", \"roller\\nmethod, or a DDD Application Service. It is ultimately a simple class that uses repositories,\", \" domain\\nentities, and other application coordination in a fashion similar to a command handler. Depe\", \"ndency\\nInjection works the same way for all the mentioned classes, as in the example using DI based \", \"on the\\nconstructor.\\n\\nRegister the dependency implementation types and interfaces or abstractions\\n\\nBe\", \"fore you use the objects injected through constructors, you need to know where to register the\\ninter\", \"faces and classes that produce the objects injected into your application classes through DI. (Like\\n\", \"DI based on the constructor, as shown previously.)\\n\\nUse the built-in loC container provided by ASP.N\", \"ET Core\\n\\nWhen you use the built-in loC container provided by ASP.NET Core, you register the types yo\", \"u want\\nto inject in the Program.cs file, as in the following code:\\n\\n// Register out-of-the-box frame\", \"work services.\\n\\nbuilder.Services.AddDbContext<CatalogContext>(c =>\\nc.UseSqlServer (Configuration|[ \\\"\", \"ConnectionString\\\"]),\\nServiceLifetime.Scoped) ;\\n\\nbuilder.Services.AddMvc();\\n// Register custom applic\", \"ation dependencies.\\nbuilder.Services.AddScoped<IMyCustomRepository, MyCustomSQLRepository>() ;\\n\\nThe \", \"most common pattern when registering types in an loC container is to register a pair of tyoes\\u2014an\\nint\", \"erface and its related implementation class. Then when you request an object from the loC\\ncontainer \", \"through any constructor, you request an object of a certain type of interface. For instance, in\\nthe \", \"previous example, the last line states that when any of your constructors have a dependency on\\nIMyCu\", \"stomRepository (interface or abstraction), the loC container will inject an instance of the\\nMyCustom\", \"SQLServerRepository implementation class.\\n\\nUse the Scrutor library for automatic types registration\\n\", \"\\nWhen using DI in .NET, you might want to be able to scan an assembly and automatically register its\", \"\\ntypes by convention. This feature is not currently available in ASP.NET Core. However, you can use \", \"the\\n\\n269 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nScrutor\", \" library for that. This approach is convenient when you have dozens of types that need to be\\nregiste\", \"red in your loC container.\\n\\nAdditional resources\\n\\n. Matthew King. Registering services with Scrutor\\n\", \"\\nhttps://www.mking.net/blog/registering-services-with-scrutor\\n\\n. Kristian Hellang. Scrutor. GitHub r\", \"epo.\\nhttps://github.com/khellang/Scrutor\\n\\nUse Autofac as an IoC container\\n\\nYou can also use addition\", \"al loC containers and plug them into the ASP.NET Core pipeline, as in the\\nordering microservice in e\", \"ShopOnContainers, which uses Autofac. When using Autofac you typically\\nregister the types via module\", \"s, which allow you to split the registration types between multiple files\\ndepending on where your ty\", \"pes are, just as you could have the application types distributed across\\nmultiple class libraries.\\n\\n\", \"For example, the following is the Autofac application module for the Ordering.AP| Web API project\\nwi\", \"th the types you will want to inject.\\n\\npublic class ApplicationModule : Autofac.Module\\n{\\n\\npublic str\", \"ing QueriesConnectionString { get; }\\npublic ApplicationModule(string qconstr)\\n{\\n\\n}\\n\\nQueriesConnectio\", \"nString = qconstr;\\n\\nprotected override void Load(ContainerBuilder builder)\\n{\\nbuilder.Register(c => n\", \"ew OrderQueries(QueriesConnectionString) )\\n.As<IOrderQueries>()\\n.InstancePerLifetimeScope() ;\\nbuilde\", \"r.RegisterType<BuyerRepository>()\\n.As<IBuyerRepository>()\\n.InstancePerLifetimeScope() ;\\nbuilder.Regi\", \"sterType<OrderRepository>()\\n.As<IOrderRepository>()\\n.InstancePerLifetimeScope() ;\\nbuilder.RegisterTy\", \"pe<RequestManager>()\\n.As<IRequestManager > ()\\n.InstancePerLifetimeScope() ;\\n\\nAutofac also has a feat\", \"ure to scan assemblies and register types by name conventions.\\n\\nThe registration process and concept\", \"s are very similar to the way you can register types with the built-\\nin ASP.NET Core loC container, \", \"but the syntax when using Autofac is a bit different.\\n\\nIn the example code, the abstraction |OrderRe\", \"pository is registered along with the implementation\\nclass OrderRepository. This means that whenever\", \" a constructor is declaring a dependency through the\\n\\n270 CHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns\\nlOrderRepository abstraction or interface, the loC contain\", \"er will inject an instance of the\\nOrderRepository class.\\n\\nThe instance scope type determines how an \", \"instance is shared between requests for the same service\\nor dependency. When a request is made for a\", \" dependency, the loC container can return the following:\\n\\n\\u00b0 A single instance per lifetime scope (re\", \"ferred to in the ASP.NET Core loC container as scoped).\\n\\u00b0 A new instance per dependency (referred to\", \" in the ASP.NET Core loC container as transient).\\n. A single instance shared across all objects usin\", \"g the loC container (referred to in the ASP.NET\\n\\nCore loC container as singleton).\\n\\nAdditional resou\", \"rces\\n\\n. Introduction to Dependency Injection in ASP.NET Core\\n\\nhttps://learn.microsoft.com/aspnet/cor\", \"e/fundamentals/dependency-injection\\n\\n\\u00b0 Autofac. Official documentation.\\n\\nhttps://docs.autofac.org/en\", \"/latest/\\n\\n\\u00b0 Comparing ASP.NET Core IoC container service lifetimes with Autofac loC container\\ninstan\", \"ce scopes - Cesar de la Torre.\\nhttps://devblogs.microsoft.com/cesardelatorre/comparing-asp-net-core-\", \"ioc-service-life-\\n\\ntimes-and-autofac-ioc-instance-scopes/\\n\\nImplement the Command and Command Handler\", \" patterns\\n\\nIn the Dl-through-constructor example shown in the previous section, the loC container wa\", \"s injecting\\nrepositories through a constructor in a class. But exactly where were they injected? In \", \"a simple Web\\nAPI (for example, the catalog microservice in eShopOnContainers), you inject them at th\", \"e MVC\\ncontrollers\\u2019 level, in a controller constructor, as part of the request pipeline of ASP.NET Co\", \"re. However,\\nin the initial code of this section (the CreateOrderCommandHandler class from the Order\", \"ing.API\\nservice in eShopOnContainers), the injection of dependencies is done through the constructor\", \" of a\\nparticular command handler. Let us explain what a command handler is and why you would want to\", \"\\nuse it.\\n\\nThe Command pattern is intrinsically related to the CQRS pattern that was introduced earli\", \"er in this\\nguide. CQRS has two sides. The first area is queries, using simplified queries with the D\", \"apper micro\\nORM, which was explained previously. The second area is commands, which are the starting\", \" point for\\ntransactions, and the input channel from outside the service.\\n\\nAs shown in Figure 7-24, t\", \"he pattern is based on accepting commands from the client-side,\\nprocessing them based on the domain \", \"model rules, and finally persisting the states with transactions.\\n\\n271 CHAPTER 6 | Tackle Business C\", \"omplexity in a Microservice with DDD and CQRS Patterns\\nHigh level \\u201cWrites-side\\u201d in CQRS\\n\\nCommand Com\", \"mand\\n\\nCommand\\nHandler\\n\\n\\u201ciii>\\n\\nWrites/Transactional operations flow\\u2019s direction\\n\\nFigure 7-24. High-le\", \"vel view of the commands or \\u201ctransactional side\\u201d in a CQRS pattern\\n\\nFigure 7-24 shows that the UI ap\", \"p sends a command through the API that gets to a\\nCommandHandler, that depends on the Domain model an\", \"d the Infrastructure, to update the\\ndatabase.\\n\\nThe command class\\n\\nA command is a request for the sys\", \"tem to perform an action that changes the state of the system.\\nCommands are imperative, and should b\", \"e processed just once.\\n\\nSince commands are imperatives, they are typically named with a verb in the \", \"imperative mood (for\\nexample, \\u201ccreate\\u201d or \\u201cupdate\\u201d), and they might include the aggregate type, such\", \" as\\nCreateOrderCommand. Unlike an event, a command is not a fact from the past; it is only a request\", \",\\nand thus may be refused.\\n\\nCommands can originate from the UI as a result of a user initiating a re\", \"quest, or from a process\\nmanager when the process manager Is directing an aggregate to perform an ac\", \"tion.\\n\\nAn important characteristic of a command is that it should be processed just once by a single\", \" receiver.\\nThis is because a command is a single action or transaction you want to perform in the ap\", \"plication.\\nFor example, the same order creation command should not be processed more than once. This\", \" is an\\nimportant difference between commands and events. Events may be processed multiple times,\\nbec\", \"ause many systems or microservices might be interested in the event.\\n\\nIn addition, it is important t\", \"hat a command be processed only once in case the command is not\\nidempotent. A command is idempotent \", \"if it can be executed multiple times without changing the\\nresult, either because of the nature of th\", \"e command, or because of the way the system handles the\\ncommand.\\n\\nIt is a good practice to make your\", \" commands and updates idempotent when it makes sense under\\nyour domain's business rules and invarian\", \"ts. For instance, to use the same example, if for any reason\\n(retry logic, hacking, etc.) the same C\", \"reateOrder command reaches your system multiple times, you\\nshould be able to identify it and ensure \", \"that you do not create multiple orders. To do so, you need to\\n\\n272 CHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS Patterns\\nattach some kind of identity in the operations an\", \"d identify whether the command or update was\\nalready processed.\\n\\nYou send a command to a single rece\", \"iver; you do not publish a command. Publishing is for events\\nthat state a fact\\u2014that something has ha\", \"ppened and might be interesting for event receivers. In the\\ncase of events, the publisher has no con\", \"cerns about which receivers get the event or what they do it.\\nBut domain or integration events are a\", \" different story already introduced in previous sections.\\n\\nA command is implemented with a class tha\", \"t contains data fields or collections with all the\\ninformation that is needed in order to execute th\", \"at command. A command is a special kind of Data\\nTransfer Object (DTO), one that is specifically used\", \" to request changes or transactions. The command\\nitself is based on exactly the information that is \", \"needed for processing the command, and nothing\\nmore.\\n\\nThe following example shows the simplified Cre\", \"ateOrderCommand class. This is an immutable\\ncommand that is used in the ordering microservice in esh\", \"opOnContainers.\\n\\n// DDD and CQRS patterns comment: Note that it is recommended to implement immutabl\", \"e\\nCommands\\n\\n// In this case, its immutability is achieved by having all the setters as private\\n\\n// p\", \"lus only being able to update the data just once, when creating the object through its\\nconstructor.\\n\", \"\\n// References on Immutable Commands:\\n\\n// http://cqrs.nu/Faq\\n\\n// https://docs.spine3.org/motivation/\", \"immutability.html\\n\\n// http://blog. gauffin.org/2012/06/griffin-container -introducing-command-suppor\", \"t/\\n\\n// https://learn.microsoft.com/dotnet/csharp/programming-guide/classes-and-structs/how-to-\\nimple\", \"ment -a-lightweight-class-with-auto-implemented-properties\\n\\n[DataContract |\\npublic class CreateOrder\", \"Command\\n: IRequest<bool>\\n\\n{\\n[| DataMember |\\n\\nprivate readonly List<OrderItemDTO> _orderItems;\\n\\n[| Da\", \"taMember |\\npublic string UserId { get; private set; }\\n\\n[| DataMember |\\npublic string UserName { get;\", \" private set; }\\n\\n[| DataMember |\\npublic string City { get; private set; }\\n\\n[| DataMember |\\npublic st\", \"ring Street { get; private set; }\\n\\n[| DataMember |\\npublic string State { get; private set; }\\n\\n[| Dat\", \"aMember |\\npublic string Country { get; private set; }\\n\\n[| DataMember |\\npublic string ZipCode { get; \", \"private set; }\\n\\n[| DataMember |\\n\\n273 CHAPTER 6 | Tackle Business Complexity in a Microservice with D\", \"DD and CQRS Patterns\\npublic string CardNumber { get; private set; }\\n\\n[| DataMember ]\\npublic string C\", \"ardHolderName { get; private set; }\\n\\n[| DataMember ]\\npublic DateTime CardExpiration { get; private s\", \"et; }\\n\\n[| DataMember ]\\npublic string CardSecurityNumber { get; private set; }\\n\\n[| DataMember ]\\npubli\", \"c int CardTypelId { get; private set; }\\n\\n[| DataMember ]\\npublic IEnumerable<OrderItemDTO> OrderItems\", \" => _orderItems;\\n\\npublic CreateOrderCommand( )\\n\\nt\\n}\\n\\n_orderiItems = new List<OrderItemDTO>() ;\\n\\npubl\", \"ic CreateOrderCommand(List<BasketItem> basketItems, string userId, string userName,\\nstring city, str\", \"ing street, string state, string country, string zipcode,\\nstring cardNumber, string cardHolderName, \", \"DateTime cardExpiration,\\nstring cardSecurityNumber, int cardTypeld) : this()\\n\\n_orderiItems = basketI\", \"tems.ToOrderItemsDTO().ToList() ;\\nUserId = userId;\\n\\nUserName = userName;\\n\\nCity = city;\\n\\nStreet = str\", \"eet;\\n\\nState = state;\\n\\nCountry = country;\\n\\nZipCode = zipcode;\\n\\nCardNumber = cardNumber ;\\n\\nCardHolderN\", \"ame = cardHolderName;\\nCardExpiration = cardExpiration;\\nCardSecurityNumber = cardSecurityNumber ;\\nCar\", \"dTypelId = cardTypeld;\\n\\nCardExpiration = cardExpiration;\\n\\npublic class OrderItemDTO\\n\\npublic int Prod\", \"uctId { get; set; }\\npublic string ProductName { get; set; }\\npublic decimal UnitPrice { get; set; }\\np\", \"ublic decimal Discount { get; set; }\\n\\npublic int Units { get; set; }\\n\\npublic string PictureUrl { get\", \"; set; }\\n\\n274 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nBa\", \"sically, the command class contains all the data you need for performing a business transaction by\\nu\", \"sing the domain model objects. Thus, commands are simply data structures that contain read-only\\ndata\", \", and no behavior. The command's name indicates its purpose. In many languages like C#,\\ncommands are\", \" represented as classes, but they are not true classes in the real object-oriented sense.\\n\\nAs an add\", \"itional characteristic, commands are immutable, because the expected usage Is that they are\\nprocesse\", \"d directly by the domain model. They do not need to change during their projected lifetime.\\nIn a C# \", \"class, immutability can be achieved by not having any setters or other methods that change\\nthe inter\", \"nal state.\\n\\nKeep in mind that if you intend or expect commands to go through a serializing/deseriali\", \"zing process,\\nthe properties must have a private setter, and the [DataMember] (or [JsonProperty]) at\", \"tribute.\\nOtherwise, the deserializer won't be able to reconstruct the object at the destination with\", \" the required\\nvalues. You can also use truly read-only properties if the class has a constructor wit\", \"h parameters for all\\nproperties, with the usual camelCase naming convention, and annotate the constr\", \"uctor as\\n[JsonConstructor]. However, this option requires more code.\\n\\nFor example, the command class\", \" for creating an order is probably similar in terms of data to the order\\nyou want to create, but you\", \" probably do not need the same attributes. For instance,\\nCreateOrderCcommand does not have an order \", \"ID, because the order has not been created yet.\\n\\nMany command classes can be simple, requiring only \", \"a few fields about some state that needs to be\\nchanged. That would be the case if you are just chang\", \"ing the status of an order from \\u201cin process\\u201d to\\n\\u201coaid\\u201d or \\u201cshipped\\u201d by using a command similar to th\", \"e following:\\n\\n[DataContract |\\npublic class UpdateOrderStatusCommand\\n: [Request<bool>\\n\\n{\\n\\n[| DataMemb\", \"er |\\npublic string Status { get; private set; }\\n\\n[| DataMember |\\npublic string OrderlId { get; priva\", \"te set; }\\n\\n[| DataMember |\\npublic string BuyerIdentityGuid { get; private set; }\\n\\nSome developers ma\", \"ke their Ul request objects separate from their command DTOs, but that is just a\\nmatter of preferenc\", \"e. It is a tedious separation with not much additional value, and the objects are\\nalmost exactly the\", \" same shape. For instance, in eshopOnContainers, some commands come directly\\nfrom the client-side.\\n\\n\", \"The Command handler class\\n\\nYou should implement a specific command handler class for each command. T\", \"hat is how the pattern\\nworks, and it's where you'll use the command object, the domain objects, and \", \"the infrastructure\\nrepository objects. The command handler is in fact the heart of the application l\", \"ayer in terms of CQRS\\nand DDD. However, all the domain logic should be contained in the domain class\", \"es\\u2014within the\\naggregate roots (root entities), child entities, or domain services, but not within th\", \"e command handler,\\nwhich is a class from the application layer.\\n\\n275 CHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS Patterns\\nThe command handler class offers a strong stepp\", \"ing stone in the way to achieve the Single\\nResponsibility Principle (SRP) mentioned in a previous se\", \"ction.\\n\\nA command handler receives a command and obtains a result from the aggregate that is used. T\", \"he\\nresult should be either successful execution of the command, or an exception. In the case of an\\ne\", \"xception, the system state should be unchanged.\\n\\nThe command handler usually takes the following ste\", \"ps:\\n\\n. It receives the command object, like a DTO (from the mediator or other infrastructure object)\", \".\\n\\n\\u00b0 It validates that the command is valid (if not validated by the mediator).\\n\\n\\u00b0 It instantiates t\", \"he aggregate root instance that is the target of the current command.\\n\\n. It executes the method on t\", \"he aggregate root instance, getting the required data from the\\ncommand.\\n\\n. It persists the new state\", \" of the aggregate to its related database. This last operation is the\\n\\nactual transaction.\\n\\nTypicall\", \"y, a command handler deals with a single aggregate driven by its aggregate root (root entity).\\nIf mu\", \"ltiple aggregates should be impacted by the reception of a single command, you could use\\ndomain even\", \"ts to propagate states or actions across multiple aggregates.\\n\\nThe important point here is that when\", \" a command is being processed, all the domain logic should be\\ninside the domain model (the aggregate\", \"s), fully encapsulated and ready for unit testing. The\\ncommand handler just acts as a way to get the\", \" domain model from the database, and as the final\\nstep, to tell the infrastructure layer (repositori\", \"es) to persist the changes when the model is changed.\\nThe advantage of this approach is that you can\", \" refactor the domain logic in an isolated, fully\\nencapsulated, rich, behavioral domain model without\", \" changing code in the application or\\ninfrastructure layers, which are the plumbing level (Command ha\", \"ndlers, Web API, repositories, etc.).\\n\\nWhen command handlers get complex, with too much logic, that \", \"can be a code smell. Review them,\\nand if you find domain logic, refactor the code to move that domai\", \"n behavior to the methods of the\\ndomain objects (the aggregate root and child entity).\\n\\nAs an exampl\", \"e of a command handler class, the following code shows the same\\nCreateOrderCommandHandler class that\", \" you saw at the beginning of this chapter. In this case, it also\\nhighlights the Handle method and th\", \"e operations with the domain model objects/aggregates.\\n\\npublic class CreateOrderCommandHandler\\n: IRe\", \"questHandler<CreateOrderCommand, bool>\\n{\\nprivate readonly IOrderRepository _orderRepository;\\nprivate\", \" readonly IIdentityService _identityService;\\nprivate readonly IMediator _mediator;\\nprivate readonly \", \"IOrderingIntegrationEventService _orderingIntegrationEventService;\\nprivate readonly ILogger<CreateOr\", \"derCommandHandler> _logger;\\n\\n// Using DI to inject infrastructure persistence Repositories\\n\\npublic C\", \"reateOrderCommandHandler(IMediator mediator,\\nTOrderingIntegrationEventService orderingIntegrationEve\", \"ntService,\\nIOrderRepository orderRepository,\\n\\n276 CHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns\\nIIdentityService identityService,\\nILogger<CreateOrderCommandHandle\", \"r> logger)\\n{\\n\\n_orderRepository = orderRepository ?? throw new\\nArgumentNullException(nameof (orderRep\", \"ository) ) ;\\n\\n_identityService = identityService ?? throw new\\nArgumentNullException(nameof (identity\", \"Service) ) ;\\n\\n_mediator = mediator ?? throw new ArgumentNullException(nameof(mediator) ) ;\\n\\n_orderin\", \"gIintegrationEventService = orderingIntegrationEventService ?? throw new\\nArgumentNullException(nameo\", \"f (orderingIntegrationEventService) ) ;\\n\\n_logger = logger ?? throw new ArgumentNullException(nameof \", \"(logger) ) ;\\n\\n}\\n\\npublic async Task<bool> Handle(CreateOrderCommand message, CancellationToken\\ncancel\", \"lationToken)\\n{\\n// Add Integration event to clean the basket\\nvar orderStartedIntegrationEvent = new\\nO\", \"rderStartedIntegrationEvent(message.UserId) ;\\nawait\\n_orderingIntegrationEventService.AddAndSaveEvent\", \"Async(orderStartedIntegrationEvent ) ;\\n\\n// Add/Update the Buyer AggregateRoot\\n\\n// DDD patterns comme\", \"nt: Add child entities and value-objects through the Order\\nAggregate-Root\\n\\n// methods and constructo\", \"r so validations, invariants and business logic\\n\\n// make sure that consistency is preserved across t\", \"he whole aggregate\\n\\nvar address = new Address(message.Street, message.City, message.State,\\nmessage.C\", \"ountry, message.ZipCode) ;\\n\\nvar order = new Order(message.UserId, message.UserName, address,\\nmessage\", \".CardTypeld, message.CardNumber, message.CardSecurityNumber, message.CardHolderName,\\nmessage.CardExp\", \"iration) ;\\n\\nforeach (var item in message.OrderItems )\\n\\nt\\n\\norder.AddOrderItem(item.ProductId, item.Pr\", \"oductName, item.UnitPrice,\\nitem.Discount, item.PictureUrl, item.Units) ;\\n\\n}\\n\\n_logger.LogInformation(\", \"\\\"----- Creating Order - Order: {@Order}\\\", order);\\n_orderRepository.Add(order) ;\\n\\nreturn await _order\", \"Repository.UnitOfWork\\n.SaveEntitiesAsync(cancellationToken) ;\\n\\n}\\n\\nThese are additional steps a comma\", \"nd handler should take:\\n. Use the command's data to operate with the aggregate root's methods and be\", \"havior.\\n\\n\\u00b0 Internally within the domain objects, raise domain events while the transaction is execut\", \"ed,\\nbut that is transparent from a command handler point of view.\\n\\n\\u00b0 If the aggregate\\u2019s operation re\", \"sult is successful and after the transaction is finished, raise\\nintegration events. (These might als\", \"o be raised by infrastructure classes like repositories.)\\n\\n277 CHAPTER 6 | Tackle Business Complexit\", \"y in a Microservice with DDD and CQRS Patterns\\nAdditional resources\\n\\n. Mark Seemann. At the Boundari\", \"es, Applications are Not Object-Oriented\\n\\nhttps://blog.ploeh.dk/2011/05/31/AttheBoundaries,Applicati\", \"onsareNotObject-Oriented/\\n\\n\\u00b0 Commands and events\\n\\nhttps://cgrs.nu/fag/Command%20and%20Events\\n\\n\\u00b0 What\", \" does a command handler do?\\n\\nhttps://cgrs.nu/fag/Command%20Handlers\\n\\n. Jimmy Bogard. Domain Command \", \"Patterns \\u2014 Handlers\\n\\nhttps://jimmybogard.com/domain-command-patterns-handlers/\\n\\n. Jimmy Bogard. Doma\", \"in Command Patterns - Validation\\n\\nhttps://jimmybogard.com/domain-command-patterns-validation/\\n\\nThe C\", \"ommand process pipeline: how to trigger a command handler\\n\\nThe next question is how to invoke a comm\", \"and handler. You could manually call it from each related\\nASP.NET Core controller. However, that app\", \"roach would be too coupled and is not ideal.\\n\\nThe other two main options, which are the recommended \", \"options, are:\\n. Through an in-memory Mediator pattern artifact.\\n\\n. With an asynchronous message queu\", \"e, in between controllers and handlers.\\n\\nUse the Mediator pattern (in-memory) in the command pipelin\", \"e\\n\\nAs shown in Figure 7-25, in a CQRS approach you use an intelligent mediator, similar to an in-mem\", \"ory\\nbus, which is smart enough to redirect to the right command handler based on the type of the\\ncom\", \"mand or DTO being received. The single black arrows between components represent the\\ndependencies be\", \"tween objects (in many cases, injected through DI) with their related interactions.\\n\\n278 CHAPTER 6 |\", \" Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nRunning as Microservice\\na c\", \"ontainer (Writes-side of a simplified CQRS Architecture pattern)\\n\\n| Aggregates\\n\\nCommand Command (Dom\", \"ain\\n\\nCommand\\nHandler\\n\\nayer) Repository\\n\\nMediator\\n(Application\\n\\n\\\" (Infrastructure\\nLayer) Database\\n\\nWr\", \"ites/Transactional operations flow\\u2019s direction\\n\\nFigure 7-25. Using the Mediator pattern in process i\", \"n a single CQRS microservice\\n\\nThe above diagram shows a zoom-in from image 7-24: the ASP.NET Core co\", \"ntroller sends the\\ncommand to MediatR\\u2019s command pipeline, so they get to the appropriate handler.\\n\\nT\", \"he reason that using the Mediator pattern makes sense is that in enterprise applications, the\\nproces\", \"sing requests can get complicated. You want to be able to add an open number of cross-\\ncutting conce\", \"rns like logging, validations, audit, and security. In these cases, you can rely ona\\nmediator pipeli\", \"ne (see Mediator pattern) to provide a means for these extra behaviors or cross-\\ncutting concerns.\\n\\n\", \"A mediator is an object that encapsulates the \\u201chow\\u201d of this process: it coordinates execution based \", \"on\\nstate, the way a command handler is invoked, or the payload you provide to the handler. With a\\nme\", \"diator component, you can apply cross-cutting concerns in a centralized and transparent way by\\napply\", \"ing decorators (or pipeline behaviors since MediatR 3). For more information, see the Decorator\\n\\npat\", \"tern.\\n\\nDecorators and behaviors are similar to Aspect Oriented Programming (AOP), only applied to a\\n\", \"specific process pipeline managed by the mediator component. Aspects in AOP that implement cross-\\n\\nc\", \"utting concerns are applied based on aspect weavers injected at compilation time or based on object\\n\", \"call interception. Both typical AOP approaches are sometimes said to work \\u201clike magic,\\u201d because it I\", \"s\\nnot easy to see how AOP does its work. When dealing with serious issues or bugs, AOP can be diffic\", \"ult\\nto debug. On the other hand, these decorators/behaviors are explicit and applied only in the con\", \"text\\nof the mediator, so debugging is much more predictable and easy.\\n\\nFor example, in the eshopOnCo\", \"ntainers ordering microservice, has an implementation of two sample\\nbehaviors, a LogBehavior class a\", \"nd a ValidatorBehavior class. The implementation of the behaviors is\\nexplained in the next section b\", \"y showing how eShopOnContainers uses MediatR behaviors.\\n\\n279 CHAPTER 6 | Tackle Business Complexity \", \"in a Microservice with DDD and CQRS Patterns\\nUse message queues (out-of-proc) in the command's pipel\", \"ine\\n\\nAnother choice is to use asynchronous messages based on brokers or message queues, as shown in\\n\", \"Figure 7-26. That option could also be combined with the mediator component right before the\\ncommand\", \" handler.\\n\\nWrites-side of a CQRS Architecture pattern using messaging\\n\\nRunning as Web API Command-Ha\", \"ndlers Running as\\nacontainer microservice backend microservice a container\\n\\nCommand Command |\\n\\nAggre\", \"gates\\n= i) ~=Command Layer)\\nHandler\\n\\nHA Message Queue | ayer) Repository =>\\n(External to the (Infras\", \"tructure Database\\nmicroservices) | Layer)\\n\\nWrites/Transactional operations flow\\u2019s direction\\n\\nFigure \", \"7-26. Using message queues (out of the process and inter-process communication) with CQRS commands\\n\\n\", \"Command's pipeline can also be handled by a high availability message queue to deliver the\\ncommands \", \"to the appropriate handler. Using message queues to accept the commands can further\\ncomplicate your \", \"command's pipeline, because you will probably need to split the pipeline into two\\nprocesses connecte\", \"d through the external message queue. Still, it should be used if you need to have\\nimproved scalabil\", \"ity and performance based on asynchronous messaging. Consider that in the case of\\nFigure 7-26, the c\", \"ontroller just posts the command message into the queue and returns. Then the\\ncommand handlers proce\", \"ss the messages at their own pace. That is a great benefit of queues: the\\nmessage queue can act as a\", \" buffer in cases when hyper scalability is needed, such as for stocks or any\\nother scenario with a h\", \"igh volume of ingress data.\\n\\nHowever, because of the asynchronous nature of message queues, you need\", \" to figure out how to\\ncommunicate with the client application about the success or failure of the co\", \"mmand's process. As a\\nrule, you should never use \\u201cfire and forget\\u201d commands. Every business applicat\", \"ion needs to know if a\\ncommand was processed successfully, or at least validated and accepted.\\n\\nThus\", \", being able to respond to the client after validating a command message that was submitted to\\nan as\", \"ynchronous queue adds complexity to your system, as compared to an in-process command\\nprocess that r\", \"eturns the operation's result after running the transaction. Using queues, you might\\nneed to return \", \"the result of the command process through other operation result messages, which will\\nrequire additi\", \"onal components and custom communication in your system.\\n\\n280 CHAPTER 6 | Tackle Business Complexity\", \" in a Microservice with DDD and CQRS Patterns\\nAdditionally, async commands are one-way commands, whi\", \"ch in many cases might not be needed, as\\nis explained in the following interesting exchange between \", \"Burtsev Alexey and Greg Young in an\\nonline conversation:\\n\\n[Burtsev Alexey] | find lots of code where\", \" people use async command handling or one-way command\\nmessaging without any reason to do so (they ar\", \"e not doing some long operation, they are not\\nexecuting external async code, they do not even cross-\", \"application boundary to be using message\\nbus). Why do they introduce this unnecessary complexity? An\", \"d actually, | haven't seen a CQRS code\\nexample with blocking command handlers so far, though it will\", \" work just fine in most cases.\\n\\n[Greg Young] [...] an asynchronous command doesn't exist; it\\u2019s actua\", \"lly another event. If | must accept\\nwhat you send me and raise an event if | disagree, it's no longe\", \"r you telling me to do something [that\\nis, It's not a command]. It\\u2019s you telling me something has be\", \"en done. This seems like a slight\\ndifference at first, but it has many implications.\\n\\nAsynchronous c\", \"ommands greatly increase the complexity of a system, because there is no simple way\\nto indicate fail\", \"ures. Therefore, asynchronous commands are not recommended other than when\\nscaling requirements are \", \"needed or in special cases when communicating the internal microservices\\nthrough messaging. In those\", \" cases, you must design a separate reporting and recovery system for\\nfailures.\\n\\nIn the initial versi\", \"on of eshopOnContainers, it was decided to use synchronous command processing,\\nstarted from HTTP req\", \"uests and driven by the Mediator pattern. That easily allows you to return the\\nsuccess or failure of\", \" the process, as in the CreateOrderCommandHandler implementation.\\n\\nIn any case, this should be a dec\", \"ision based on your application's or microservice\\u2019s business\\nrequirements.\\n\\nImplement the command pr\", \"ocess pipeline with a mediator pattern\\n(MediatR)\\n\\nAs a sample implementation, this guide proposes us\", \"ing the in-process pipeline based on the Mediator\\npattern to drive command ingestion and route comma\", \"nds, in memory, to the right command\\nhandlers. The guide also proposes applying behaviors in order t\", \"o separate cross-cutting concerns.\\n\\nFor implementation in .NET, there are multiple open-source libra\", \"ries available that implement the\\nMediator pattern. The library used in this guide is the MediatR op\", \"en-source library (created by Jimmy\\nBogard), but you could use another approach. MediatR is a small \", \"and simple library that allows you to\\nprocess in-memory messages like a command, while applying deco\", \"rators or behaviors.\\n\\nUsing the Mediator pattern helps you to reduce coupling and to isolate the con\", \"cerns of the requested\\nwork, while automatically connecting to the handler that performs that work\\u2014i\", \"n this case, to\\ncommand handlers.\\n\\nAnother good reason to use the Mediator pattern was explained by \", \"Jimmy Bogard when reviewing\\nthis guide:\\n\\n281 CHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS Patterns\\n| think it might be worth mentioning testing here \\u2014 it provides a nice \", \"consistent window into the\\nbehavior of your system. Request-in, response-out. We've found that aspec\", \"t quite valuable in building\\nconsistently behaving tests.\\n\\nFirst, let's look at a sample WebAPI cont\", \"roller where you actually would use the mediator object. If\\nyou weren't using the mediator object, y\", \"ou'd need to inject all the dependencies for that controller,\\nthings like a logger object and others\", \". Therefore, the constructor would be complicated. On the other\\nhand, if you use the mediator object\", \", the constructor of your controller can be a lot simpler, with just a\\nfew dependencies instead of m\", \"any dependencies if you had one per cross-cutting operation, as in the\\nfollowing example:\\n\\npublic cl\", \"ass MyMicroserviceController : Controller\\n\\nt\\n\\npublic MyMicroserviceController(IMediator mediator,\\nIM\", \"yMicroserviceQueries microserviceQueries )\\n\\nt\\n}\\n\\nHi coc\\n\\nYou can see that the mediator provides a cl\", \"ean and lean Web API controller constructor. In addition,\\nwithin the controller methods, the code to\", \" send a command to the mediator object is almost one line:\\n\\n[Route( \\\"new\\\" ) ]\\n\\n[HttpPost ]\\n\\npublic a\", \"sync Task<IActionResult> ExecuteBusinessOperation( [| FromBody |RunOpCommand\\nrunOperationCommand )\\n\\n\", \"t\\n\\nvar commandResult = await _mediator.SendAsync(runOperationCommand) ;\\n\\nreturn commandResult ? (IAc\", \"tionResult)Ok() : (IActionResult)BadRequest() ;\\n\\nImplement idempotent Commands\\n\\nIn eShopOnContainers\", \", a more advanced example than the above is submitting a\\nCreateOrderCommand object from the Ordering\", \" microservice. But since the Ordering business\\nprocess is a bit more complex and, in our case, it ac\", \"tually starts in the Basket microservice, this action\\nof submitting the CreateOrderCommand object is\", \" performed from an integration-event handler\\nnamed UserCheckoutAcceptedIntegrationEventHandler inste\", \"ad of a simple WebAPI controller called\\nfrom the client App as in the previous simpler example.\\n\\nNev\", \"ertheless, the action of submitting the Command to MediatR is pretty similar, as shown in the\\nfollow\", \"ing code.\\n\\nvar createOrderCommand = new CreateOrderCommand(eventMsg.Basket.Items,\\neventMsg.UserId, e\", \"ventMsg.City,\\neventMsg.Street, eventMsg.State,\\neventMsg.Country, eventMsg.ZipCode,\\neventMsg.CardNumb\", \"er,\\neventMsg.CardHolderName,\\neventMsg.CardExpiration,\\neventMsg.CardSecurityNumber ,\\neventMsg.CardTyp\", \"eld) ;\\n\\n282 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nvar \", \"requestCreateOrder = new IdentifiedCommand<CreateOrderCommand, bool>(createOrderCommand,\\n\\neventMsg.R\", \"equestId) ;\\nresult = await _mediator.Send(requestCreateOrder) ;\\n\\nHowever, this case is also slightly\", \" more advanced because we're also implementing idempotent\\ncommands. The CreateOrderCommand process s\", \"hould be idempotent, so if the same message comes\\nduplicated through the network, because of any rea\", \"son, like retries, the same business order will be\\nprocessed just once.\\n\\nThis is implemented by wrap\", \"ping the business command (in this case CreateOrderCommand) and\\nembedding it into a generic Identifi\", \"edCommand, which is tracked by an ID of every message coming\\nthrough the network that has to be idem\", \"potent.\\n\\nIn the code below, you can see that the IdentifiedCommand is nothing more than a DTO with a\", \"nd ID\\nplus the wrapped business command object.\\n\\npublic class IdentifiedCommand<T, R> : IRequest<R>\\n\", \"where T : IRequest<R>\\n{\\npublic T Command { get; }\\npublic Guid Id { get; }\\npublic IdentifiedCommand(T\", \" command, Guid id)\\n{\\nCommand = command;\\nId = id;\\n\\nThen the CommandHandler for the IdentifiedCommand \", \"named IdentifiedCommandHandler.cs will\\nbasically check if the ID coming as part of the message alrea\", \"dy exists in a table. If it already exists, that\\ncommand won't be processed again, so it behaves as \", \"an idempotent command. That infrastructure\\ncode is performed by the _requestManager.ExistAsync metho\", \"d call below.\\n\\n// IdentifiedCommandHandler.cs\\npublic class IdentifiedCommandHandler<T, R> : IRequest\", \"Handler<IdentifiedCommand<T, R>, R>\\nwhere T : IRequest<R>\\n\\n{\\n\\nprivate readonly IMediator _mediator;\\n\", \"private readonly IRequestManager _requestManager ;\\nprivate readonly ILogger<IdentifiedCommandHandler\", \"<T, R>> _logger;\\n\\npublic IdentifiedCommandHandler(\\nIMediator mediator,\\nIRequestManager requestManage\", \"r,\\nILogger<IdentifiedCommandHandler<T, R>> logger)\\n\\n{\\n\\n_mediator = mediator;\\n\\n_requestManager = requ\", \"estManager ;\\n\\n_logger = logger ?? throw new System.ArgumentNullException(nameof (logger) ) ;\\n}\\n\\n/// \", \"<summary>\\n\\n/// Creates the result value to return if a previous request was found\\n/// </summary>\\n\\n//\", \"/ <returns></returns>\\n\\n283 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S Patterns\\nprotected virtual R CreateResultForDuplicateRequest()\\n{\\n\\n}\\n\\nreturn default(R) ;\\n\\n/// <sum\", \"mary>\\n/// This method handles the command. It just ensures that no other request exists with\\nthe sam\", \"e ID, and if this is the case\\n/// just enqueues the original inner command.\\n/// </summary>\\n/// <para\", \"m name=\\\"message\\\">IdentifiedCommand which contains both original command &\\nrequest ID</param>\\n/// <re\", \"turns>Return value of inner command or default value if request same ID was\\nfound</returns>\\npublic a\", \"sync Task<R> Handle(IdentifiedCommand<T, R> message, CancellationToken\\ncancellationToken)\\n{\\nvar alre\", \"adyExists = await _requestManager.ExistAsync(message.Id) ;\\nif (alreadyExists)\\n\\naf\\nreturn CreateResul\", \"tForDuplicateRequest() ;\\n}\\nelse\\naf\\nawait _requestManager .CreateRequestForCommandAsync<T>(message.Id\", \") ;\\ntry\\naf\\n\\nvar command = message.Command;\\n\\nvar commandName = command.GetGenericTypeName() ;\\nvar idP\", \"roperty = string.Empty;\\n\\nvar commandid = string.Empty;\\n\\nSwitch (command)\\n\\n{\\ncase CreateOrderCommand \", \"createOrderCommand:\\nidProperty = nameof(createOrderCommand.UserId) ;\\ncommandiId = createOrderCommand\", \".UserId;\\nbreak;\\ncase CancelOrderCommand cancelOrderCommand:\\nidProperty = nameof(cancelOrderCommand.O\", \"rderNumber) ;\\ncommandid = $\\\"{cancelOrderCommand.OrderNumber }\\\" ;\\nbreak;\\ncase ShipOrderCommand shipOr\", \"derCommand:\\nidProperty = nameof(shipOrderCommand.OrderNumber ) ;\\ncommandiId = $\\\"{shipOrderCommand.Or\", \"derNumber}\\\" ;\\nbreak;\\ndefault:\\nidProperty = \\\"Id?\\\";\\ncommandid = \\\"n/a\\\";\\nbreak;\\n}\\n\\n_logger.LogInformatio\", \"n(\\n----- Sending command: {CommandName} - {IdProperty}: {CommandId}\\n({@Command})\\\",\\n\\ncommandName,\\n\\nid\", \"Property,\\n\\ncommandId,\\n\\n284 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S Patterns\\ncommand) ;\\n\\n// Send the embedded business command to mediator so it runs its related\\nComm\", \"andHandler\\nvar result = await _mediator.Send(command, cancellationToken) ;\\n\\n_logger.LogInformation(\\n\", \"\\n\\\"ao --- Command result: {@Result} - {CommandName} - {IdProperty}:\\n{CommandId} ({@Command})\\\",\\n\\nresul\", \"t,\\n\\ncommandName,\\n\\nidProperty,\\n\\ncommandId,\\n\\ncommand) ;\\n\\nreturn result;\\n\\n}\\n\\ncatch\\n\\n{\\n\\nreturn default(R\", \");\\n\\nSince the IdentifiedCommand acts like a business command's envelope, when the business command\\nn\", \"eeds to be processed because it is not a repeated ID, then it takes that inner business command and\\n\", \"resubmits it to Mediator, as in the last part of the code shown above when running\\n_mediator.Send(me\", \"ssage.Command), from the IdentifiedCommandHandler.cs.\\n\\nWhen doing that, it will link and run the bus\", \"iness command handler, in this case, the\\nCreateOrderCommandHandler, which is running transactions ag\", \"ainst the Ordering database, as shown\\nin the following code.\\n\\n// CreateOrderCommandHandler.cs\\npublic\", \" class CreateOrderCommandHandler\\n: IRequestHandler<CreateOrderCommand, bool>\\n\\n{\\n\\nprivate readonly IO\", \"rderRepository _orderRepository;\\n\\nprivate readonly IIdentityService _identityService;\\n\\nprivate reado\", \"nly IMediator _mediator;\\n\\nprivate readonly IOrderingIntegrationEventService _orderingIntegrationEven\", \"tService;\\nprivate readonly ILogger<CreateOrderCommandHandler> _logger;\\n\\n// Using DI to inject infras\", \"tructure persistence Repositories\\npublic CreateOrderCommandHandler(IMediator mediator,\\nIOrderingInte\", \"grationEventService orderingIntegrationEventService,\\nIOrderRepository orderRepository,\\nIIdentityServ\", \"ice identityService,\\nILogger<CreateOrderCommandHandler> logger)\\n{\\n_orderRepository = orderRepository\", \" ?? throw new\\nArgumentNullException(nameof (orderRepository) ) ;\\n_identityService = identityService \", \"?? throw new\\nArgumentNullException(nameof (identityService) ) ;\\n_mediator = mediator ?? throw new Ar\", \"gumentNullException(nameof(mediator) ) ;\\n_orderingIintegrationEventService = orderingIntegrationEven\", \"tService ?? throw new\\nArgumentNullException(nameof (orderingIntegrationEventService) ) ;\\n_logger = l\", \"ogger ?? throw new ArgumentNullException(nameof (logger) ) ;\\n\\n285 CHAPTER 6 | Tackle Business Comple\", \"xity in a Microservice with DDD and CQRS Patterns\\n}\\n\\npublic async Task<bool> Handle(CreateOrderComma\", \"nd message, CancellationToken\\ncancellationToken)\\n\\nt\\n// Add Integration event to clean the basket\\n\\nva\", \"r orderStartedIntegrationEvent = new\\nOrderStartedIntegrationEvent(message.UserId) ;\\n\\nawait\\n_ordering\", \"IntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent ) ;\\n\\n// Add/Update the Buy\", \"er AggregateRoot\\n// DDD patterns comment: Add child entities and value-objects through the Order\\n\\nAg\", \"gregate-Root\\n\\n// methods and constructor so validations, invariants and business logic\\n\\n// make sure\", \" that consistency is preserved across the whole aggregate\\n\\nvar address = new Address(message.Street,\", \" message.City, message.State,\\nmessage.Country, message.ZipCode) ;\\n\\nvar order = new Order(message.Use\", \"rId, message.UserName, address,\\nmessage.CardTypeld, message.CardNumber, message.CardSecurityNumber, \", \"message.CardHolderName,\\nmessage.CardExpiration) ;\\n\\nforeach (var item in message.OrderItems )\\n\\n{\\norde\", \"r.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice,\\nitem.Discount, item.PictureUrl, ite\", \"m.Units) ;\\n\\n}\\n\\n_logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\\n_orderReposi\", \"tory.Add(order) ;\\n\\nreturn await _orderRepository.UnitOfWork\\n.SaveEntitiesAsync(cancellationToken) ;\\n\", \"\\nRegister the types used by MediatR\\n\\nIn order for MediatR to be aware of your command handler classe\", \"s, you need to register the mediator\\nclasses and the command handler classes in your loC container. \", \"By default, MediatR uses Autofac as\\nthe loC container, but you can also use the built-in ASP.NET Cor\", \"e loC container or any other container\\nsupported by MediatR.\\n\\nThe following code shows how to regist\", \"er Mediator\\u2019s types and commands when using Autofac\\nmodules.\\n\\npublic class MediatorModule : Autofac.\", \"Module\\n{\\n\\nprotected override void Load(ContainerBuilder builder)\\n{\\nbuilder .RegisterAssemblyTypes (t\", \"ypeof (IMediator ) .GetTypeInfo().Assembly )\\n.AsImplementedInterfaces () ;\\n\\n// Register all the Comm\", \"and classes (they implement IRequestHandler)\\n\\n// in assembly holding the Commands\\n\\nbuilder.RegisterA\", \"ssemblyTypes (typeof (CreateOrderCommand) .GetTypeInfo() .Assembly)\\n.AsClosedTypesOf (typeof (IReque\", \"stHandler<,>));\\n\\n// Other types registration\\n\\n286 CHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns\\nThis is where \\u201cthe magic happens\\u201d with MediatR.\\n\\nAs each command h\", \"andler implements the generic IRequestHandler<T> interface, when you register\\nthe assemblies using R\", \"egisteredAssemblyTypes method all the types marked as IRequestHandler also\\ngets registered with thei\", \"r Commands. For example:\\n\\npublic class CreateOrderCommandHandler\\n\\n: [IRequestHandler<CreateOrderComm\", \"and, bool>\\n\\nt\\n\\nThat is the code that correlates commands with command handlers. The handler is just \", \"a simple class,\\nbut it inherits from RequestHandler<T>, where T is the command type, and MediatR mak\", \"es sure it is\\ninvoked with the correct payload (the command).\\n\\nApply cross-cutting concerns when pro\", \"cessing commands with the\\nBehaviors in MediatR\\n\\nThere is one more thing: being able to apply cross-c\", \"utting concerns to the mediator pipeline. You can\\nalso see at the end of the Autofac registration mo\", \"dule code how it registers a behavior type,\\nspecifically, a custom LoggingBehavior class and a Valid\", \"atorBehavior class. But you could add other\\ncustom behaviors, too.\\n\\npublic class MediatorModule : Au\", \"tofac.Module\\n{\\n\\nprotected override void Load(ContainerBuilder builder)\\n{\\nbuilder .RegisterAssemblyTy\", \"pes (typeof (IMediator ) .GetTypeInfo().Assembly )\\n.AsImplementedInterfaces () ;\\n\\n// Register all th\", \"e Command classes (they implement IRequestHandler)\\n\\n// in assembly holding the Commands\\n\\nbuilder.Reg\", \"isterAssemblyTypes (\\n\\ntypeof (CreateOrderCommand) .GetTypeInfo().Assembly).\\nAsClosedTypesOf (typeof \", \"(IRequestHandler<,>));\\n\\n// Other types registration\\n\\nHi 000\\n\\nbuilder .RegisterGeneric (typeof (Loggi\", \"ngBehavior<,>)).\\nAs(typeof(IPipelineBehavior<, >) );\\n\\nbuilder .RegisterGeneric (typeof (ValidatorBeh\", \"avior<,>)).\\nAs(typeof(IPipelineBehavior<, >) );\\n\\nThat LoggingBehavior class can be implemented as th\", \"e following code, which logs information about\\nthe command handler being executed and whether it was\", \" successful or not.\\n\\npublic class LoggingBehavior<TRequest, TResponse>\\n: IPipelineBehavior<TRequest,\", \" TResponse>\\n\\nt\\n\\nprivate readonly ILogger<LoggingBehavior<TRequest, TResponse>> _ logger;\\npublic Logg\", \"ingBehavior(ILogger<LoggingBehavior<TRequest, TResponse>> logger) =>\\n_logger = logger;\\n\\n287 CHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\npublic async Task<TRespo\", \"nse> Handle(TRequest request,\\nRequestHandlerDelegate<TResponse> next)\\n\\n{\\n\\n_logger.LogInformation($\\\"H\", \"andling {typeof(TRequest) .Name}\\\") ;\\nvar response = await next();\\n_logger.LogInformation($\\\"Handled {\", \"typeof(TResponse) .Name}\\\") ;\\nreturn response;\\n\\nJust by implementing this behavior class and by regis\", \"tering it in the pipeline (in the MediatorModule\\nabove), all the commands processed through MediatR \", \"will be logging information about the\\nexecution.\\n\\nThe eShopOnContainers ordering microservice also a\", \"pplies a second behavior for basic validations,\\nthe ValidatorBehavior class that relies on the Fluen\", \"tValidation library, as shown in the following code:\\n\\npublic class ValidatorBehavior<TRequest, TResp\", \"onse>\\n: IPipelineBehavior<TRequest, TResponse>\\n{\\nprivate readonly IValidator<TRequest>[ ] _validator\", \"s;\\npublic ValidatorBehavior(IValidator<TRequest>|[] validators) =>\\n_validators = validators;\\n\\npublic\", \" async Task<TResponse> Handle(TRequest request,\\nRequestHandlerDelegate<TResponse> next)\\n{\\nvar failur\", \"es = _validators\\n.Select(v => v.Validate(request) )\\n.SelectMany(result => result.Errors)\\n.Where(erro\", \"r => error != null)\\n.TOList();\\n\\nif (failures.Any())\\n{\\nthrow new OrderingDomainException(\\n$\\\"Command V\", \"alidation Errors for type {typeof(TRequest) .Name}\\\",\\nnew ValidationException(\\\"Validation exception\\\",\", \" failures) );\\n\\n}\\n\\nvar response = await next();\\nreturn response;\\n\\nHere the behavior Is raising an exc\", \"eption If validation fails, but you could also return a result object,\\ncontaining the command result\", \" if it succeeded or the validation messages in case it didn\\u2019t. This would\\nprobably make it easier to\", \" display validation results to the user.\\n\\nThen, based on the FluentValidation library, you would cre\", \"ate validation for the data passed with\\nCreateOrderComman4d, as in the following code:\\n\\npublic class\", \" CreateOrderCommandValidator : AbstractValidator<CreateOrderCommand>\\n\\n{\\n\\npublic CreateOrderCommandVa\", \"lidator ( )\\n\\n{\\nRuleFor(command => command.City) .NotEmpty() ;\\nRuleFor(command => command.Street) .No\", \"tEmpty() ;\\n\\n288 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\n\", \"RuleFor(command => command.State).NotEmpty() ;\\n\\nRuleFor(command => command.Country) .NotEmpty() ;\\n\\nR\", \"uleFor(command => command.ZipCode) .NotEmpty() ;\\n\\nRuleFor(command => command.CardNumber) .NotEmpty()\", \".Length(12, 19);\\n\\nRuleFor(command => command.CardHolderName) .NotEmpty() ;\\n\\nRuleFor(command =>\\ncomma\", \"nd.CardExpiration) .NotEmpty() .Must(BeValidExpirationDate) .WithMessage(\\\"Please specify\\na valid car\", \"d expiration date\\\");\\n\\nRuleFor(command => command.CardSecurityNumber ) .NotEmpty().Length(3) ;\\n\\nRuleF\", \"or(command => command.CardTypeld) .NotEmpty() ;\\n\\nRuleFor(command => command.OrderItems) .Must(Contai\", \"nOrderItems) .WithMessage(\\\"No\\norder items found\\\") ;\\n\\n}\\n\\nprivate bool BeValidExpirationDate(DateTime \", \"dateTime)\\n\\nreturn dateTime >= DateTime.UtcNow;\\n\\n}\\n\\nprivate bool ContainOrderItems(IEnumerable<OrderI\", \"temDTO> orderItems )\\nreturn orderItems.Any();\\n\\n}\\n\\nYou could create additional validations. This is a\", \" very clean and elegant way to implement your\\n\\ncommand validations.\\n\\nIn a similar way, you could imp\", \"lement other behaviors for additional aspects or cross-cutting concerns\\nthat you want to apply to co\", \"mmands when handling them.\\n\\nAdditional resources\\n\\nThe mediator pattern\\n\\u00b0 Mediator pattern\\nhttps://en\", \".wikipedia.org/wiki/Mediator pattern\\nThe decorator pattern\\n\\u00b0 Decorator pattern\\nhttps://en.wikipedia.\", \"org/wiki/Decorator pattern\\nMediatR Jimmy Bogard)\\n\\n. MediatR. GitHub repo.\\nhttps://github.com/jbogard\", \"/MediatR\\n\\n\\u00b0 CQRS with MediatR and AutoMapper\\nhttps://lostechies.com/jimmybogard/2015/05/05/cqrs-with\", \"-mediatr-and-automapper/\\n\\n. Put your controllers on a diet: POSTs and commands.\\n\\ncommands/\\n\\n289 CHAP\", \"TER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\\nTackling cross-cutti\", \"ng concerns with a mediator pipeline\\nhttps://lostechies.com/jimmybogard/2014/09/09/tackling-cross-cu\", \"tting-concerns-with-a-\\n\\nmediator-pipeline/\\n\\nCQRS and REST: the perfect match\\nhttps://lostechies.com/\", \"jimmybogard/2016/06/01/cqrs-and-rest-the-perfect-match/\\n\\nMediatR Pipeline Examples\\nhttps://lostechie\", \"s.com/jimmybogard/2016/10/13/mediatr-pipeline-examples/\\n\\nVertical Slice Test Fixtures for MediatR an\", \"d ASP.NET Core\\nhttps://lostechies.com/jimmybogard/2016/10/24/vertical-slice-test-fixtures-for-mediat\", \"r-and-\\n\\nasp-net-core/\\n\\nMediatR Extensions for Microsoft Dependency Injection Released\\nhttos://lostec\", \"hies.com/jimmybogard/2016/07/19/mediatr-extensions-for-microsoft-\\n\\ndependency-injection-released/\\n\\nF\", \"luent validation\\n\\n290\\n\\nJeremy Skinner. FluentValidation. GitHub repo.\\n\\nhttps://github.com/JeremySkin\", \"ner/FluentValidation\\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pat\", \"terns\\nCHAPTER\\n\\nImplement resilient\\napplications\\n\\nYour microservice and cloud-based applications must\", \" embrace the partial failures that will certainly\\noccur eventually. You must design your application\", \" to be resilient to those partial failures.\\n\\nResiliency is the ability to recover from failures and \", \"continue to function. It isn't about avoiding\\nfailures but accepting the fact that failures will hap\", \"pen and responding to them in a way that avoids\\ndowntime or data loss. The goal of resiliency is to \", \"return the application to a fully functioning state\\nafter a failure.\\n\\nIt's challenging enough to des\", \"ign and deploy a microservices-based application. But you also need to\\nkeep your application running\", \" in an environment where some sort of failure is certain. Therefore, your\\napplication should be resi\", \"lient. It should be designed to cope with partial failures, like network\\noutages or nodes or VMs cra\", \"shing in the cloud. Even microservices (containers) being moved to a\\ndifferent node within a cluster\", \" can cause intermittent short failures within the application.\\n\\nThe many individual components of yo\", \"ur application should also incorporate health monitoring\\nfeatures. By following the guidelines in th\", \"is chapter, you can create an application that can work\\nsmoothly in spite of transient downtime or t\", \"he normal hiccups that occur in complex and cloud-based\\ndeployments.\\n\\nImportant\\n\\neShopOnContainer ha\", \"d been using the Polly library to implement resiliency using Typed Clients up\\nuntil the release 3.0.\", \"0.\\n\\nStarting with release 3.0.0, the HTTP calls resiliency is implemented using a Linkerd mesh, that\", \" handles\\nretries in a transparent and configurable fashion, within a Kubernetes cluster, without hav\", \"ing to\\nhandle those concerns in the code.\\n\\nThe Polly library is still used to add resilience to data\", \"base connections, specially while starting up the\\nservices.\\n\\nWarning\\n\\nAll code samples and images in\", \" this section were valid before using Linkerd and are not updated to\\nreflect the current actual code\", \". So they make sense in the context of this section.\\n\\n291 CHAPTER 7 | Implement resilient applicatio\", \"ns\\nHandle partial failure\\n\\nIn distributed systems like microservices-based applications, there\\u2019s an \", \"ever-present risk of partial\\nfailure. For instance, a single microservice/container can fail or migh\", \"t not be available to respond for a\\nshort time, or a single VM or server can crash. Since clients an\", \"d services are separate processes, a\\nservice might not be able to respond in a timely way to a clien\", \"t's request. The service might be\\noverloaded and responding very slowly to requests or might simply \", \"not be accessible for a short time\\nbecause of network issues.\\n\\nFor example, consider the Order detai\", \"ls page from the eshopOnContainers sample application. If the\\nordering microservice is unresponsive \", \"when the user tries to submit an order, a bad implementation\\nof the client process (the MVC web appl\", \"ication)\\u2014for example, if the client code were to use\\nsynchronous RPCs with no timeout\\u2014would block th\", \"reads indefinitely waiting for a response. Besides\\ncreating a bad user experience, every unresponsiv\", \"e wait consumes or blocks a thread, and threads are\\nextremely valuable in highly scalable applicatio\", \"ns. If there are many blocked threads, eventually the\\napplication's runtime can run out of threads. \", \"In that case, the application can become globally\\nunresponsive instead of just partially unresponsiv\", \"e, as shown in Figure 8-1.\\n\\nPartial failures\\n\\na |\\n\\nBackend |\\n\\nee a a a a a a a ae ae ae ae es es\\n\\nAS\", \"P.NET Core\\nMVC WebApp\\n\\nRunning as\\n\\nContainer\\n\\n|\\n\\n|\\n\\n|\\n\\nThrzad 1 |\\n\\\\ Neb Serv Me Thread 3 he ap |\\n|\\n\\n\", \"|\\n\\n|\\n\\n|\\n\\nJ\\n\\nSubmit Order page\\n\\nThread 4\\n\\nThread pool\\n\\na ee\\u201d\\n\\nSe gee SS GS GD GS SG ee ee ee ee ee ee\", \" ee ee ee ee\\n\\nEventually, most threads could be blocked\\n\\nye\\n\\nPee eee ee ee ee ee ee ee ee ee\\n\\nFigure\", \" 8-1. Partial failures because of dependencies that impact service thread availability\\n\\nIn a large m\", \"icroservices-based application, any partial failure can be amplified, especially if most of\\nthe inte\", \"rnal microservices interaction is based on synchronous HTTP calls (which is considered an anti-\\npatt\", \"ern). Think about a system that receives millions of incoming calls per day. If your system has a\\nba\", \"d design that\\u2019s based on long chains of synchronous HTTP calls, these incoming calls might result in\", \"\\nmany more millions of outgoing calls (let\\u2019s suppose a ratio of 1:4) to dozens of internal microserv\", \"ices\\nas synchronous dependencies. This situation is shown in Figure 8-2, especially dependency #3, t\", \"hat\\nstarts a chain, calling dependency #4, which then calls #5.\\n\\n292 CHAPTER 7 | Implement resilient\", \" applications\\nMultiple distributed dependencies\\n\\nPe = ES ee Oe eS Oe OS Oe Oe Oe Oe ee eee eee eee e\", \"e\\n\\nBackend / Orchestrator\\n\\nCustomers\\n\\nBrowser\\n\\nWeb App\\n\\nKer\\nKey\\nKey\\n\\nwy id\\n\\na\\nKey\\n\\nSubmit Order page\", \"\\n\\nFigure 8-2. The impact of having an incorrect design featuring long chains of HTTP requests\\n\\nInter\", \"mittent failure is guaranteed in a distributed and cloud-based system, even if every dependency\\nitse\", \"lf has excellent availability. It\\u2019s a fact you need to consider.\\n\\nIf you do not design and implement\", \" techniques to ensure fault tolerance, even small downtimes can\\nbe amplified. As an example, 50 depe\", \"ndencies each with 99.99% of availability would result in several\\nhours of downtime each month becau\", \"se of this ripple effect. When a microservice dependency fails\\nwhile handling a high volume of reque\", \"sts, that failure can quickly saturate all available request threads\\nin each service and crash the w\", \"hole application.\\n\\nPartial Failure Amplified in Microservices\\n\\nPe = ES Oe Oe Oe Oe OS Oe Oe Oe Oe Oe\", \" eee eee eee SS\\n\\nBackend / Orchestrator\\nWeb App\\n\\na a a\\nea co: Ka\\na Kan\\n\\nMultiple\\n\\nBrowser\\n\\ner i\\n\\n\\u2014 |\", \" \\u2014| | \\u2014\\n\\nSubmit Order page\\n\\n\\u2014\\n\\n|\\nI\\nI\\n|\\n|\\nI\\n|\\n|\\nl\\n\\nFigure 8-3. Partial failure amplified by microserv\", \"ices with long chains of synchronous HTTP calls\\n\\n293 CHAPTER 7 | Implement resilient applications\\nTo\", \" minimize this problem, in the section Asynchronous microservice integration enforce microservice's\\n\", \"autonomy, this guide encourages you to use asynchronous communication across the internal\\n\\nmicroserv\", \"ices.\\n\\nIn addition, it's essential that you design your microservices and client applications to han\", \"dle partial\\nfailures\\u2014that is, to build resilient microservices and client applications.\\n\\nStrategies \", \"to handle partial failure\\n\\nTo deal with partial failures, use one of the strategies described here.\\n\", \"\\nUse asynchronous communication (for example, message-based communication) across\\ninternal microserv\", \"ices. It's highly advisable not to create long chains of synchronous HTTP calls\\nacross the internal \", \"microservices because that incorrect design will eventually become the main cause\\nof bad outages. On\", \" the contrary, except for the front-end communications between the client\\napplications and the first\", \" level of microservices or fine-grained API Gateways, it\\u2019s recommended to use\\nonly asynchronous (mes\", \"sage-based) communication once past the initial request/response cycle,\\nacross the internal microser\", \"vices. Eventual consistency and event-driven architectures will help to\\nminimize ripple effects. The\", \"se approaches enforce a higher level of microservice autonomy and\\ntherefore prevent against the prob\", \"lem noted here.\\n\\nUse retries with exponential backoff. This technique helps to avoid short and inter\", \"mittent failures\\nby performing call retries a certain number of times, in case the service was not a\", \"vailable only for a\\nshort time. This might occur due to intermittent network issues or when a micros\", \"ervice/container is\\nmoved to a different node in a cluster. However, if these retries are not design\", \"ed properly with circuit\\nbreakers, it can aggravate the ripple effects, ultimately even causing a De\", \"nial of Service (DoS).\\n\\nWork around network timeouts. In general, clients should be designed not to \", \"block indefinitely and\\nto always use timeouts when waiting for a response. Using timeouts ensures th\", \"at resources are never\\ntied up indefinitely.\\n\\nUse the Circuit Breaker pattern. In this approach, the\", \" client process tracks the number of failed\\nrequests. If the error rate exceeds a configured limit, \", \"a \\u201ccircuit breaker\\u201d trips so that further attempts\\nfail immediately. (If a large number of requests \", \"are failing, that suggests the service is unavailable and\\nthat sending requests is pointless.) After\", \" a timeout period, the client should try again and, if the new\\nrequests are successful, close the ci\", \"rcuit breaker.\\n\\nProvide fallbacks. In this approach, the client process performs fallback logic when\", \" a request fails,\\nsuch as returning cached data or a default value. This is an approach suitable for\", \" queries, and is more\\ncomplex for updates or commands.\\n\\nLimit the number of queued requests. Clients\", \" should also impose an upper bound on the number\\nof outstanding requests that a client microservice \", \"can send to a particular service. If the limit has been\\nreached, it's probably pointless to make add\", \"itional requests, and those attempts should fail\\nimmediately. In terms of implementation, the Polly \", \"Bulkhead Isolation policy can be used to fulfill this\\nrequirement. This approach is essentially a pa\", \"rallelization throttle with SemaphoreSlim as the\\nimplementation. It also permits a \\u201cqueue\\u201d outside t\", \"he bulkhead. You can proactively shed excess load\\neven before execution (for example, because capaci\", \"ty is deemed full). This makes its response to\\n\\n294 CHAPTER 7 | Implement resilient applications\\ncer\", \"tain failure scenarios faster than a circuit breaker would be, since the circuit breaker waits for t\", \"he\\nfailures. The BulkheadPolicy object in Polly exposes how full the bulkhead and queue are, and off\", \"ers\\nevents on overflow so can also be used to drive automated horizontal scaling.\\n\\nAdditional resour\", \"ces\\n\\n\\u00b0 Resiliency patterns\\n\\nhttps://learn.microsoft.com/azure/architecture/framework/resiliency/reli\", \"ability-patterns\\n\\n\\u00b0 Adding Resilience and Optimizing Performance\\n\\n. Bulkhead. GitHub repo. Implement\", \"ation with Polly policy.\\nhttps://github.com/App-vNext/Polly/wiki/Bulkhead\\n\\n\\u00b0 Designing resilient app\", \"lications for Azure\\n\\nhttps://learn.microsoft.com/azure/architecture/framework/resiliency/app-design\\n\", \"\\n\\u00b0 Transient fault handling\\n\\nhttps://learn.microsoft.com/azure/architecture/best-practices/transient\", \"-faults\\n\\nImplement retries with exponential backoff\\n\\nRetries with exponential backoff is a technique\", \" that retries an operation, with an exponentially\\nincreasing wait time, up to a maximum retry count \", \"has been reached (the exponential backoff). This\\n\\ntechnique embraces the fact that cloud resources m\", \"ight intermittently be unavailable for more than a\\nfew seconds for any reason. For example, an orche\", \"strator might be moving a container to another\\nnode in a cluster for load balancing. During that tim\", \"e, some requests might fail. Another example\\ncould be a database like SQL Azure, where a database ca\", \"n be moved to another server for load\\nbalancing, causing the database to be unavailable for a few se\", \"conds.\\n\\nThere are many approaches to implement retries logic with exponential backoff.\\n\\nImplement re\", \"silient Entity Framework Core SQL\\nconnections\\n\\nFor Azure SQL DB, Entity Framework (EF) Core already \", \"provides internal database connection resiliency\\nand retry logic. But you need to enable the Entity \", \"Framework execution strategy for each DbContext\\nconnection if you want to have resilient EF Core con\", \"nections.\\n\\nFor instance, the following code at the EF Core connection level enables resilient SQL co\", \"nnections that\\nare retried if the connection fails.\\n\\n// Program.cs from any ASP.NET Core Web API\\n// \", \"Other code ...\\nbuilder.Services.AddDbContext<CatalogContext>(options =>\\n\\nt\\n\\n295 CHAPTER 7 | Implemen\", \"t resilient applications\\noptions .UseSqlServer (builder .Configuration|[ \\\"ConnectionString\\\" |,\\nsqlSe\", \"rverOptionsAction: sqlOptions =>\\n\\nsqlOptions.EnableRetryOnFailure(\\nmaxRetryCount: 180,\\n\\nmaxRetryDela\", \"y: TimeSpan.FromSeconds(3@),\\nerrorNumbersToAdd: null) ;\\n\\nExecution strategies and explicit transacti\", \"ons using BeginTransaction\\nand multiple DoContexts\\n\\nWhen retries are enabled in EF Core connections,\", \" each operation you perform using EF Core becomes\\nits own retryable operation. Each query and each c\", \"all to SaveChanges will be retried as a unit if a\\ntransient failure occurs.\\n\\nHowever, if your code i\", \"nitiates a transaction using BeginTransaction, you're defining your own group\\nof operations that nee\", \"d to be treated as a unit. Everything inside the transaction has to be rolled back\\nif a failure occu\", \"rs.\\n\\nIf you try to execute that transaction when using an EF execution strategy (retry policy) and y\", \"ou call\\nSaveChanges from multiple DbContexts, you'll get an exception like this one:\\n\\nSystem.Invalid\", \"OperationException: The configured execution strategy\\n\\u2018SqlServerRetryingExecutionStrategy\\u2019 does not \", \"support user initiated transactions. Use the execution\\nstrategy returned by \\u2018DbContext.Database.Crea\", \"teExecutionStrategy()\\u2019 to execute all the operations in\\nthe transaction as a retriable unit.\\n\\nThe so\", \"lution is to manually invoke the EF execution strategy with a delegate representing everything\\nthat \", \"needs to be executed. If a transient failure occurs, the execution strategy will invoke the delegate\", \"\\nagain. For example, the following code shows how it's implemented in eShopOnContainers with two\\nmul\", \"tiple DoContexts (_catalogContext and the IntegrationEventLlogContext) when updating a product\\nand t\", \"hen saving the ProductPriceChangedIntegrationEvent object, which needs to use a different\\nDbContext.\", \"\\n\\npublic async Task<IActionResult> UpdateProduct(\\n[ FromBody |CatalogItem productToUpdate)\\n\\n{\\n// Oth\", \"er code ...\\n\\nvar oldPrice = catalogItem.Price;\\nvar raiseProductPriceChangedEvent = oldPrice != produ\", \"ctToUpdate. Price;\\n\\n// Update current product\\ncatalogItem = productToUpdate;\\n\\n// Save product's data\", \" and publish integration event through the Event Bus\\n// if price has changed\\nif (raiseProductPriceCh\", \"angedEvent )\\n\\n//Create Integration Event to be published through the Event Bus\\n\\nvar priceChangedEven\", \"t = new ProductPriceChangedIintegrationEvent (\\ncatalogItem.Id, productToUpdate.Price, oldPrice) ;\\n\\n2\", \"96 CHAPTER 7 | Implement resilient applications\\n// Achieving atomicity between original Catalog data\", \"base operation and the\\n\\n// IntegrationEventLog thanks to a local transaction\\n\\nawait _catalogIntegrat\", \"ionEventService.SaveEventAndCatalogContextChangesAsync (\\npriceChangedEvent) ;\\n\\n// Publish through th\", \"e Event Bus and mark the saved event as published\\nawait _catalogIntegrationEventService.PublishThrou\", \"ghEventBusAsync (\\npriceChangedEvent) ;\\n}\\n// Just save the updated product because the Product's Pric\", \"e hasn't changed.\\nelse\\n\\nt\\n\\nawait _catalogContext.SaveChangesAsync() ;\\n\\n}\\n\\nThe first DoContext is _ca\", \"talogContext and the second DbContext is within the\\n_catalogIntegrationEventService object. The Comm\", \"it action is performed across all DoContext objects\\nusing an EF execution strategy.\\n\\nTo achieve this\", \" multiple DoContext commit, the SaveEventAndCatalogContextChangesAsync uses a\\nResilientTransaction c\", \"lass, as shown in the following code:\\n\\npublic class CatalogIntegrationEventService : ICatalogIntegra\", \"tionEventService\\n{\\n//...\\npublic async Task SaveEventAndCatalogContextChangesAsync (\\nIntegrationEvent\", \" evt)\\n{\\n// Use of an EF Core resiliency strategy when using multiple DbContexts\\n// within an explici\", \"t BeginTransaction():\\n// https://learn.microsoft.com/ef/core/miscellaneous/connection-resiliency\\nawa\", \"it ResilientTransaction.New(_catalogContext).ExecuteAsync(async () =>\\n{\\n// Achieving atomicity betwe\", \"en original catalog database\\n// operation and the IntegrationEventLog thanks to a local transaction\\n\", \"await _catalogContext.SaveChangesAsync() ;\\nawait _eventLogService.SaveEventAsync(evt,\\n_catalogContex\", \"t.Database.CurrentTransaction.GetDbTransaction() );\\n\\nThe ResilientTransaction.ExecuteAsync method ba\", \"sically begins a transaction from the passed\\nDbContext (_catalogContext) and then makes the EventLog\", \"Service use that transaction to save\\nchanges from the IntegrationEventLogContext and then commits th\", \"e whole transaction.\\n\\npublic class ResilientTransaction\\n\\nt\\n\\nprivate DbContext _context;\\nprivate Resi\", \"lientTransaction(DbContext context) =>\\n_context = context ?? throw new ArgumentNullException(nameof \", \"(context) ) ;\\n\\npublic static ResilientTransaction New (DbContext context) =>\\nnew ResilientTransactio\", \"n(context) ;\\n\\npublic async Task ExecuteAsync(Func<Task> action)\\n\\nt\\n297 CHAPTER 7 | Implement resilie\", \"nt applications\\n// Use of an EF Core resiliency strategy when using multiple DbContexts\\n// within an\", \" explicit BeginTransaction():\\n// https://learn.microsoft.com/ef/core/miscellaneous/connection-resili\", \"ency\\n\\nvar strategy = _context.Database.CreateExecutionStrategy() ;\\nawait strategy.ExecuteAsync(async\", \" () =>\\naf\\n\\nawait using var transaction = await _context.Database.BeginTransactionAsync() ;\\nawait act\", \"ion();\\nawait transaction.CommitAsync();\\n\\n})3\\n\\nAdditional resources\\n\\n\\u00b0 Connection Resiliency and Comm\", \"and Interception with EF in an ASP.NET MVC\\n\\nApplication\\nhttps:\\nusing-mvc/connection-resiliency-and-c\", \"ommand-interception-with-the-entity-framework-in-\\n\\nlearn.microsoft.com/aspnet/mvc/overview/getting-s\", \"tarted/getting-started-with-ef-\\n\\nan-asp-net-mvc-application\\n\\n\\u00b0 Cesar de la Torre. Using Resilient En\", \"tity Framework Core SQL Connections and\\nTransactions\\nhttos://devblogs.microsoft.com/cesardelatorre/u\", \"sing-resilient-entity-framework-core-sql-\\n\\nconnections-and-transactions-retries-with-exponential-bac\", \"koff/\\n\\nUse IHttoClientFactory to implement resilient HTTP\\nrequests\\n\\n[HttpClientFactory is a contract\", \" implemented by DefaultHttpClientFactory, an opinionated factory,\\navailable since .NET Core 2.1, for\", \" creating HttpClient instances to be used in your applications.\\n\\nIssues with the original HttpClient\", \" class available in .NET\\n\\nThe original and well-known HttpClient class can be easily used, but in so\", \"me cases, it isn't being\\nproperly used by many developers.\\n\\nThough this class implements IDisposable\", \", declaring and instantiating it within a using statement is\\nnot preferred because when the HttpClie\", \"nt object gets disposed of, the underlying socket is not\\nimmediately released, which can lead to a s\", \"ocket exhaustion problem. For more information about this\\n\\nissue, see the blog post You're using Htt\", \"oClient wrong and it's destabilizing your software.\\n\\nTherefore, HttpClient is intended to be instant\", \"iated once and reused throughout the life of an\\napplication. Instantiating an HttpClient class for e\", \"very request will exhaust the number of sockets\\navailable under heavy loads. That issue will result \", \"in SocketException errors. Possible approaches to\\nsolve that problem are based on the creation of th\", \"e HttpClient object as singleton or static, as\\nexplained in this Microsoft article on HttpClient usa\", \"ge. This can be a good solution for short-lived\\nconsole apps or similar, that run a few times a day.\", \"\\n\\n298 CHAPTER 7 | Implement resilient applications\\nAnother issue that developers run into is when us\", \"ing a shared instance of HttpClient in long-running\\nprocesses. In a situation where the HttpClient i\", \"s instantiated as a singleton or a static object, it fails to\\nhandle the DNS changes as described in\", \" this issue of the dotnet/runtime GitHub repository.\\n\\nHowever, the issue isn\\u2019t really with HttpClien\", \"t per se, but with the default constructor for HttoClient,\\nbecause it creates a new concrete instanc\", \"e of HttoMessageHandler, which Is the one that has sockets\\nexhaustion and DNS changes issues mention\", \"ed above.\\n\\nTo address the issues mentioned above and to make HttpClient instances manageable, .NET C\", \"ore 2.1\\nintroduced two approaches, one of them being !HttpClientFactory. It\\u2019s an interface that's us\", \"ed to\\nconfigure and create HttpClient instances in an app through Dependency Injection (Dl). It also\", \"\\nprovides extensions for Polly-based middleware to take advantage of delegating handlers in\\nHttpClie\", \"nt.\\n\\nThe alternative is to use SocketsHttpHandler with configured PooledConnectionLifetime. This\\napp\", \"roach is applied to long-lived, static or singleton HttpClient instances. To learn more about\\n\\ndiffe\", \"rent strategies, see HttpClient guidelines for .NET.\\n\\nPolly is a transient-fault-handling library th\", \"at helps developers add resiliency to their applications, by\\nusing some pre-defined policies in a fl\", \"uent and thread-safe manner.\\n\\nBenefits of using IHttpClientFactory\\n\\nThe current implementation of |H\", \"ttpClientFactory, that also implements IHttoMessageHandlerFactory,\\noffers the following benefits:\\n\\n.\", \" Provides a central location for naming and configuring logical HttpClient objects. For\\nexample, you\", \" may configure a client (Service Agent) that\\u2019s pre-configured to access a specific\\nmicroservice.\\n\\n. \", \"Codify the concept of outgoing middleware via delegating handlers in HttpClient and\\nimplementing Pol\", \"ly-based middleware to take advantage of Polly's policies for resiliency.\\n\\n. HttpClient already has \", \"the concept of delegating handlers that could be linked together for\\noutgoing HTTP requests. You can\", \" register HTTP clients into the factory and you can use a\\nPolly handler to use Polly policies for Re\", \"try, CircuitBreakers, and so on.\\n\\n\\u00b0 Manage the lifetime of HttpMessageHandler to avoid the mentioned\", \" problems/issues that\\ncan occur when managing HttpClient lifetimes yourself.\\n\\nTip\\n\\nThe HttpClient in\", \"stances injected by DI can be disposed of safely, because the associated\\nHttpMessageHandler is manag\", \"ed by the factory. Injected HttpClient instances are Transient from a DI\\n\\nperspective, while HttpMes\", \"sageHandler instances can be regarded as Scoped. HttpMessageHandler\\ninstances have their own DI scop\", \"es, separate from the application scopes (for example, ASP.NET\\nincoming request scopes). For more in\", \"formation, see Using HttpClientFactory in .NET.\\n\\n299 CHAPTER 7 | Implement resilient applications\\nNo\", \"te\\n\\nThe implementation of IHttpClientFactory (DefaultHttpClientFactory) is tightly tied to the DI\\n\\ni\", \"mplementation in the Microsoft.Extensions.Dependencylnjection NuGet package. If you need to use\\nHttp\", \"Client without DI or with other DI implementations, consider using a static or singleton HttpClient\\n\", \"with PooledConnectionLifetime set up. For more information, see HttpClient guidelines for .NET.\\n\\nMul\", \"tiple ways to use IHttpClientFactory\\n\\nThere are several ways that you can use IHttpClientFactory in \", \"your application:\\n\\n. Basic usage\\n\\n\\u00b0 Use Named Clients\\n\\n. Use Typed Clients\\n\\n. Use Generated Clients\\n\", \"For the sake of brevity, this guidance shows the most structured way to use IHttpClientFactory, whic\", \"h\\nis to use Typed Clients (Service Agent pattern). However, all options are documented and are curre\", \"ntly\\nlisted in this article covering the IHttpClientFactory_usage.\\n\\nNote\\n\\nIf your app requires cooki\", \"es, it might be better to avoid using |HttpClientFactory in your app. For\\nalternative ways of managi\", \"ng clients, see Guidelines for using HTTP clients\\n\\nHow to use Typed Clients with IHttpClientFactory\\n\", \"\\nSo, what's a \\u201cTyped Client\\u201d? It's just an HttpClient that\\u2019s pre-configured for some specific use. T\", \"his\\nconfiguration can include specific values such as the base server, HTTP headers or time outs.\\n\\nT\", \"he following diagram shows how Typed Clients are used with |HttpClientFactory:\\n\\n300 CHAPTER 7 | Impl\", \"ement resilient applications\\nClient application/code\\n\\nIHttpClientFactory\\n\\nDependency Injection\\n\\nClie\", \"ntService\\n(i.e. CatalogService)\\n\\n| HttpMessageHandler |\\n|\\n\\n| instances Http\\n\\n| ,\\n\\nHttpClient endpoin\", \"\\n(Configured)\\n\\nPolicies\\n\\n\\\\e)\\n\\nDelegating\\nHandlers\\n\\nController or client code\\n\\nFigure 8-4. Using I|Ht\", \"tpClientFactory with Typed Client classes.\\n\\nIn the above image, a ClientService (used by a controlle\", \"r or client code) uses an HttpClient created by\\nthe registered IHttpClientFactory. This factory assi\", \"gns an HttpMessageHandler from a pool to the\\nHttpClient. The HttpClient can be configured with Polly\", \"\\u2019s policies when registering the\\n[HttpClientFactory in the DI container with the extension method Ad\", \"dHttpClient.\\n\\nTo configure the above structure, add |HttpClientFactory in your application by instal\", \"ling the\\nMicrosoft.Extensions.Http NuGet package that includes the AddHttpClient extension method fo\", \"r\\nIServiceCollection. This extension method registers the internal DefaultHttpClientFactory class to\", \" be\\nused as a singleton for the interface IHttoClientFactory. It defines a transient configuration f\", \"or the\\n\\nHttpMessageHandlerBuilder. This message handler (HttpMessageHandler object), taken from a po\", \"ol,\\nis used by the HttpClient returned from the factory.\\n\\nIn the next snippet, you can see how AddHt\", \"tpClient() can be used to register Typed Clients (Service\\nAgents) that need to use HttpClient.\\n\\n// P\", \"rogram.cs\\n//Add http client services at ConfigureServices(IServiceCollection services)\\n\\nbuilder.Serv\", \"ices.AddHttpClient<ICatalogService, CatalogService>();\\nbuilder.Services.AddHttpClient<IBasketService\", \", BasketService>();\\nbuilder.Services.AddHttpClient<IOrderingService, OrderingService>();\\n\\n301 CHAPTE\", \"R 7 | Implement resilient applications\\nRegistering the client services as shown in the previous snip\", \"pet, makes the DefaultClientFactory create\\na standard HttpClient for each service. The typed client \", \"is registered as transient with DI container. In\\nthe preceding code, AddHttpClient() registers Catal\", \"ogService, BasketService, OrderingService as\\ntransient services so they can be injected and consumed\", \" directly without any need for additional\\nregistrations.\\n\\nYou could also add instance-specific confi\", \"guration in the registration to, for example, configure the\\nbase address, and add some resiliency po\", \"licies, as shown in the following:\\n\\nbuilder.Services.AddHttpClient<ICatalogService, CatalogService>(\", \"client =>\\n\\nt\\n\\n})\\n.AddPolicyHandler(GetRetryPolicy() )\\n\\n.AddPolicyHandler(GetCircuitBreakerPolicy());\", \"\\n\\nIn this next example, you can see the configuration of one of the above policies:\\n\\nclient.BaseAddr\", \"ess = new Uri(builder.Configuration[ \\\"BaseUr1\\\"]) ;\\n\\nstatic IAsyncPolicy<HttpResponseMessage> GetRetr\", \"yPolicy()\\n{\\n\\nreturn HttpPolicyExtensions\\n.HandleTransientHttpError( )\\n\\n.OrResult(msg => msg.StatusCo\", \"de == System.Net.HttpStatusCode.NotFound)\\n.WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds\", \" (Math. Pow(2,\\nretryAttempt) ) );\\n}\\n\\nYou can find more details about using Polly in the Next article\", \".\\n\\nHttpClient lifetimes\\n\\nEach time you get an HttpClient object from the IHttpClientFactory, a new i\", \"nstance is returned. But\\neach HttpClient uses an HttpMessageHandler that\\u2019s pooled and reused by the \", \"IHttpClientFactory to\\nreduce resource consumption, as long as the HttpMessageHandler\\u2019s lifetime hasn\", \"'t expired.\\n\\nPooling of handlers is desirable as each handler typically manages its own underlying H\", \"TTP\\nconnections; creating more handlers than necessary can result in connection delays. Some handler\", \"s\\nalso keep connections open indefinitely, which can prevent the handler from reacting to DNS\\nchange\", \"s.\\n\\nThe HttpMessageHandler objects in the pool have a lifetime that\\u2019s the length of time that an\\nHtt\", \"pMessageHandler instance in the pool can be reused. The default value is two minutes, but it can\\nbe \", \"overridden per Typed Client. To override it, call SetHandlerLifetime() on the |HttpClientBuilder\\ntha\", \"t\\u2019s returned when creating the client, as shown in the following code:\\n\\n//Set 5 min as the lifetime \", \"for the HttpMessageHandler objects in the pool used for the\\nCatalog Typed Client\\n\\nbuilder.Services.A\", \"ddHttpClient<ICatalogService, CatalogService>()\\n. SetHandlerLifetime(TimeSpan.FromMinutes (5) );\\n\\nEa\", \"ch Typed Client can have its own configured handler lifetime value. Set the lifetime to\\nInfiniteTime\", \"Span to disable handler expiry.\\n\\n302 CHAPTER 7 | Implement resilient applications\\nImplement your Typ\", \"ed Client classes that use the injected and configured\\nHttpClient\\n\\nAs a previous step, you need to h\", \"ave your Typed Client classes defined, such as the classes in the\\nsample code, like \\u2018BasketService\\u2019,\", \" \\u2018CatalogService\\u2019, \\u2018OrderingService\\u2019, etc. \\u2014 A Typed Client is a class\\nthat accepts an HttpClient ob\", \"ject (injected through its constructor) and uses it to call some remote\\nHTTP service. For example:\\n\\n\", \"public class CatalogService : ICatalogService\\n\\n{\\nprivate readonly HttpClient _httpClient;\\nprivate re\", \"adonly string _remoteServiceBaseUr1;\\n\\npublic CatalogService(HttpClient httpClient)\\n{\\n\\n}\\n\\n_httpClient\", \" = httpClient;\\n\\npublic async Task<Catalog> GetCatalogItems(int page, int take,\\n\\nint? brand, int? typ\", \"e)\\n{\\nvar uri = API.Catalog.GetAllCatalogItems(_remoteServiceBaseUr1,\\n\\npage, take, brand, type);\\n\\nvar\", \" responseString = await _httpClient.GetStringAsync(uri) ;\\n\\nvar catalog = JsonConvert.DeserializeObje\", \"ct<Catalog>(responseString) ;\\nreturn catalog;\\n\\nThe Typed Client (CatalogService in the example) is a\", \"ctivated by DI (Dependency Injection), which\\nmeans it can accept any registered service in its const\", \"ructor, in addition to HttpClient.\\n\\nA Typed Client is effectively a transient object, that means a n\", \"ew instance Is created each time one is\\nneeded. It receives a new HttpClient instance each time it\\u2019s\", \" constructed. However, the\\nHttpMessageHandler objects in the pool are the objects that are reused by\", \" multiple HttpClient\\ninstances.\\n\\nUse your Typed Client classes\\n\\nFinally, once you have your typed cl\", \"asses implemented, you can have them registered and configured\\nwith AddHttpClient(). After that you \", \"can use them wherever services are injected by DI, such as in\\nRazor page code or an MVC web app cont\", \"roller, shown in the below code from eShopOnContainers:\\n\\nnamespace Microsoft.eShopOnContainers.WebMV\", \"C.Controllers\\n\\n{\\n\\npublic class CatalogController : Controller\\n\\n{\\n\\nprivate ICatalogService _catalogSv\", \"c;\\n\\npublic CatalogController(ICatalogService catalogSvc) =>\\n_catalogSvc = catalogSvc;\\n\\npublic async \", \"Task<IActionResult> Index(int? BrandFilterApplied,\\nint? TypesFilterApplied,\\n\\n303 CHAPTER 7 | Impleme\", \"nt resilient applications\\nint? page,\\n[ FromQuery |string errorMsg)\\n\\n{\\nvar itemsPage = 10;\\nvar catalo\", \"g = await _catalogSvc.GetCatalogItems(page ?? @,\\nitemsPage,\\nBrandFilterApplied,\\nTypesFilterApplied) \", \";\\n//.. Additional code\\n}\\n\\nUp to this point, the above code snippet only shows the example of perform\", \"ing regular HTTP\\n\\nrequests. But the \\u2018magic\\u2019 comes in the following sections where it shows how all t\", \"he HTTP requests\\nmade by HttpClient can have resilient policies such as retries with exponential bac\", \"koff, circuit\\nbreakers, security features using auth tokens, or even any other custom feature. And a\", \"ll of these can\\nbe done just by adding policies and delegating handlers to your registered Typed Cli\", \"ents.\\n\\nAdditional resources\\n\\n. HttpClient guidelines for .NET\\n\\nhttps://learn.microsoft.com/en-us/dot\", \"net/fundamentals/networking/http/httpclient-\\nguidelines\\n\\n. Using HttpClientFactory in .NET\\nhttps://l\", \"earn.microsoft.com/en-us/dotnet/core/extensions/httpclient-factory\\n\\n. Using HttpClientFactory in ASP\", \".NET Core\\nhttps://learn.microsoft.com/aspnet/core/fundamentals/http-requests\\n\\n\\u00b0 HttpClientFactory so\", \"urce code in the dotnet/runtime GitHub repository\\n\\nhttps://github.com/dotnet/runtime/tree/release/7.\", \"0/src/libraries/Microsoft.Extensions.Http/\\n\\n\\u00b0 Polly (.NET resilience and transient-fault-handling li\", \"brary)\\nhttps://thepollyproject.azurewebsites.net/\\n\\nImplement HTTP call retries with exponential back\", \"off\\nwith IHttoClientFactory and Polly policies\\n\\nThe recommended approach for retries with exponentia\", \"l backoff is to take advantage of more\\nadvanced .NET libraries like the open-source Polly library.\\n\\n\", \"Polly is a .NET library that provides resilience and transient-fault handling capabilities. You can\\n\", \"implement those capabilities by applying Polly policies such as Retry, Circuit Breaker, Bulkhead\\nIso\", \"lation, Timeout, and Fallback. Polly targets .NET Framework 4.x and .NET Standard 1.0, 1.1, and 2.0\\n\", \"(which supports .NET Core and later).\\n\\n304 CHAPTER 7 | Implement resilient applications\\nThe followin\", \"g steps show how you can use Http retries with Polly integrated into IHttpClientFactory,\\nwhich is ex\", \"plained in the previous section.\\n\\nInstall .NET packages\\nFirst, you will need to install the Microsof\", \"t.Extensions.Http.Polly package.\\n\\n: Install with Visual Studio\\n\\n: Install with dotnet CLI\\n\\n. Install\", \" with nuget.exe CLI\\n\\n: Install with Package Manager Console (PowerShell)\\n\\nReference the .NET 7 packa\", \"ges\\n\\nIHttpClientFactory is available since .NET Core 2.1, however, we recommend you use the latest .\", \"NET 7\\npackages from NuGet in your project. You typically also need to reference the extension packag\", \"e\\nMicrosoft.Extensions.Http.Polly.\\n\\nConfigure a client with Polly's Retry policy, in app startup\\n\\nTh\", \"e AddPolicyHandler() method is what adds policies to the HttpClient objects you'll use. In this\\ncase\", \", It's adding a Polly's policy for Http Retries with exponential backoff.\\n\\nTo have a more modular ap\", \"proach, the Http Retry Policy can be defined in a separate method within\\nthe Program.cs file, as sho\", \"wn in the following code:\\n\\nstatic IAsyncPolicy<HttpResponseMessage> GetRetryPolicy()\\n{\\n\\nreturn HttpP\", \"olicyExtensions\\n.HandleTransientHttpError( )\\n.OrResult(msg => msg.StatusCode == System.Net.HttpStatu\", \"sCode.NotFound)\\n.WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds (Math. Pow(2,\\nretryAttemp\", \"t) ));\\n\\nAs shown in previous sections, you need to define a named or typed client HttpClient configu\", \"ration in\\nyour standard Program.cs app configuration. Now you add incremental code specifying the po\", \"licy for\\nthe Http retries with exponential backoff, as follows:\\n\\n// Program.cs\\nbuilder.Services.AddH\", \"ttpClient<IBasketService, BasketService>()\\n\\n.SetHandlerLifetime(TimeSpan.FromMinutes(5)) //Set lifet\", \"ime to five minutes\\n.AddPolicyHandler(GetRetryPolicy() );\\n\\nWith Polly, you can define a Retry policy\", \" with the number of retries, the exponential backoff\\nconfiguration, and the actions to take when the\", \"re's an HTTP exception, such as logging the error. In\\nthis case, the policy is configured to try six\", \" times with an exponential retry, starting at two seconds.\\n\\nAdd a jitter strategy to the retry polic\", \"y\\n\\nA regular Retry policy can affect your system in cases of high concurrency and scalability and un\", \"der\\nhigh contention. To overcome peaks of similar retries coming from many clients in partial outage\", \"s, a\\ngood workaround is to add a jitter strategy to the retry algorithm/policy. This strategy can im\", \"prove\\nthe overall performance of the end-to-end system. As recommended in Polly: Retry with Jitter, \", \"a good\\n\\n305 CHAPTER 7 | Implement resilient applications\\njitter strategy can be implemented by smoot\", \"h and evenly distributed retry intervals applied with a\\nwell-controlled median initial retry delay o\", \"n an exponential backoff. This approach helps to spread out\\nthe spikes when the Issue arises. The pr\", \"inciple is illustrated by the following example:\\n\\nvar delay = Backoff.DecorrelatedJitterBackoffV2(me\", \"dianFirstRetryDelay:\\nTimeSpan.FromSeconds(1), retryCount: 5);\\n\\nvar retryPolicy = Policy\\n. Handle<Foo\", \"Exception>()\\n.WaitAndRetryAsync (delay) ;\\n\\nAdditional resources\\n\\u00b0 Retry pattern https://learn.micros\", \"oft.com/azure/architecture/patterns/retry\\n\\n. Polly and IHttpClientFactory https://github.com/App-vNe\", \"xt/Polly/wiki/Polly-and-\\nHttpClientFactory\\n\\n\\u00b0 Polly (.NET resilience and transient-fault-handling li\", \"brary) https://github.com/App-\\nvNext/Polly\\n\\n\\u00b0 Polly: Retry with Jitter https://github.com/App-vNext/\", \"Polly/wiki/Retry-with-jitter\\n\\n\\u00b0 Marc Brooker. Jitter: Making Things Better With Randomness\\nhttps://b\", \"rooker.co.za/blog/2015/03/21/backoff.htm!\\n\\nImplement the Circuit Breaker pattern\\n\\nAs noted earlier, \", \"you should handle faults that might take a variable amount of time to recover from,\\nas might happen \", \"when you try to connect to a remote service or resource. Handling this type of fault\\ncan improve the\", \" stability and resiliency of an application.\\n\\nIn a distributed environment, calls to remote resource\", \"s and services can fail due to transient faults,\\nsuch as slow network connections and timeouts, or i\", \"f resources are responding slowly or are\\ntemporarily unavailable. These faults typically correct the\", \"mselves after a short time, and a robust cloud\\napplication should be prepared to handle them by usin\", \"g a strategy like the \\u201cRetry pattern\\u201d.\\n\\nHowever, there can also be situations where faults are due t\", \"o unanticipated events that might take\\nmuch longer to fix. These faults can range in severity from a\", \" partial loss of connectivity to the\\ncomplete failure of a service. In these situations, it might be\", \" pointless for an application to continually\\nretry an operation that\\u2019s unlikely to succeed.\\n\\nInstead\", \", the application should be coded to accept that the operation has failed and handle the failure\\nacc\", \"ordingly.\\n\\nUsing Http retries carelessly could result in creating a Denial of Service (DoS) attack w\", \"ithin your own\\nsoftware. As a microservice fails or performs slowly, multiple clients might repeated\", \"ly retry failed\\nrequests. That creates a dangerous risk of exponentially increasing traffic targeted\", \" at the failing\\nservice.\\n\\n306 CHAPTER 7 | Implement resilient applications\\nTherefore, you need some \", \"kind of defense barrier so that excessive requests stop when it isn\\u2019t worth\\nto keep trying. That def\", \"ense barrier is precisely the circuit breaker.\\n\\nThe Circuit Breaker pattern has a different purpose \", \"than the \\u201cRetry pattern\\u201d. The \\u201cRetry pattern\\u201d\\nenables an application to retry an operation in the ex\", \"pectation that the operation will eventually\\nsucceed. The Circuit Breaker pattern prevents an applic\", \"ation from performing an operation that's\\nlikely to fail. An application can combine these two patte\", \"rns. However, the retry logic should be\\nsensitive to any exception returned by the circuit breaker, \", \"and it should abandon retry attempts if the\\ncircuit breaker indicates that a fault is not transient.\", \"\\n\\nImplement Circuit Breaker pattern with IHttpClientFactory and Polly\\n\\nAs when implementing retries,\", \" the recommended approach for circuit breakers is to take advantage of\\nproven .NET libraries like Po\", \"lly and its native integration with IHttpClientFactory.\\n\\nAdding a circuit breaker policy into your I\", \"HttpClientFactory outgoing middleware pipeline is as simple\\nas adding a single incremental piece of \", \"code to what you already have when using IHttpClientFactory.\\n\\nThe only addition here to the code use\", \"d for HTTP call retries is the code where you add the Circuit\\nBreaker policy to the list of policies\", \" to use, as shown in the following incremental code.\\n\\n// Program.cs\\nvar retryPolicy = GetRetryPolicy\", \"();\\nvar circuitBreakerPolicy = GetCircuitBreakerPolicy() ;\\n\\nbuilder.Services.AddHttpClient<IBasketSe\", \"rvice, BasketService>()\\n.SetHandlerLifetime(TimeSpan.FromMinutes(5)) // Sample: default lifetime is \", \"2\\nminutes\\n.AddHttpMessageHandler<HttpClientAuthorizationDelegatingHandler >()\\n.AddPolicyHandler(retr\", \"yPolicy)\\n.AddPolicyHandler(circuitBreakerPolicy) ;\\n\\nThe AddPolicyHandler() method is what adds polic\", \"ies to the HttpClient objects you'll use. In this case,\\nit's adding a Polly policy for a circuit bre\", \"aker.\\n\\nTo have a more modular approach, the Circuit Breaker Policy is defined in a separate method c\", \"alled\\nGetCircuitBreakerPolicy(), as shown in the following code:\\n\\n// also in Program.cs\\nstatic IAsyn\", \"cPolicy<HttpResponseMessage> GetCircuitBreakerPolicy()\\n\\nt\\n\\nreturn HttpPolicyExtensions\\n.HandleTransi\", \"entHttpError( )\\n.CircuitBreakerAsync(5, TimeSpan.FromSeconds(3@) );\\n\\nIn the code example above, the \", \"circuit breaker policy is configured so it breaks or opens the circuit\\nwhen there have been five con\", \"secutive faults when retrying the Http requests. When that happens,\\nthe circuit will break for 30 se\", \"conds: in that period, calls will be failed immediately by the circuit-\\nbreaker rather than actually\", \" be placed. The policy automatically interprets relevant exceptions and\\nHTTP status codes as faults.\", \"\\n\\nCircuit breakers should also be used to redirect requests to a fallback infrastructure if you had \", \"issues\\nin a particular resource that\\u2019s deployed in a different environment than the client applicati\", \"on or\\n\\n307 CHAPTER 7 | Implement resilient applications\\nservice that\\u2019s performing the HTTP call. Tha\", \"t way, if there\\u2019s an outage in the datacenter that impacts\\nonly your backend microservices but not y\", \"our client applications, the client applications can redirect\\nto the fallback services. Polly is pla\", \"nning a new policy to automate this failover policy scenario.\\n\\nAll those features are for cases wher\", \"e you're managing the failover from within the .NET code, as\\nopposed to having it managed automatica\", \"lly for you by Azure, with location transparency.\\n\\nFrom a usage point of view, when using HttpClient\", \", there\\u2019s no need to add anything new here\\nbecause the code is the same than when using HttpClient w\", \"ith IHttpClientFactory, as shown in\\nprevious sections.\\n\\nTest Http retries and circuit breakers in es\", \"hopOnContainers\\n\\nWhenever you start the eshopOnContainers solution in a Docker host, it needs to sta\", \"rt multiple\\ncontainers. Some of the containers are slower to start and initialize, like the SQL Serv\", \"er container. This\\nis especially true the first time you deploy the eshopOnContainers application in\", \"to Docker because it\\nneeds to set up the images and the database. The fact that some containers star\", \"t slower than others\\ncan cause the rest of the services to initially throw HTTP exceptions, even if \", \"you set dependencies\\nbetween containers at the docker-compose level, as explained in previous sectio\", \"ns. Those docker-\\ncompose dependencies between containers are just at the process level. The contain\", \"er\\u2019s entry point\\nprocess might be started, but SQL Server might not be ready for queries. The result\", \" can be a cascade\\nof errors, and the application can get an exception when trying to consume that pa\", \"rticular container.\\n\\nYou might also see this type of error on startup when the application is deploy\", \"ing to the cloud. In that\\ncase, orchestrators might be moving containers from one node or VM to anot\", \"her (that is, starting new\\ninstances) when balancing the number of containers across the cluster\\u2019s n\", \"odes.\\n\\nThe way \\u2018eShopOnContainers\\u2019 solves those issues when starting all the containers is by using \", \"the Retry\\npattern illustrated earlier.\\n\\nTest the circuit breaker in eshopOnContainers\\n\\nThere are a f\", \"ew ways you can break/open the circuit and test it with eshopOnContainers.\\n\\nOne option Is to lower t\", \"he allowed number of retries to 1 in the circuit breaker policy and redeploy\\nthe whole solution into\", \" Docker. With a single retry, there\\u2019s a good chance that an HTTP request will\\nfail during deployment\", \", the circuit breaker will open, and you get an error.\\n\\nAnother option is to use custom middleware t\", \"hat's implemented in the Basket microservice. When\\nthis middleware is enabled, it catches all HTTP r\", \"equests and returns status code 500. You can enable\\nthe middleware by making a GET request to the fa\", \"iling URI, like the following:\\n\\n\\u00b0 GET http://localhost:5103/failing\\nThis request returns the current\", \" state of the middleware. If the middleware is enabled, the\\nrequest return status code 500. If the m\", \"iddleware is disabled, there\\u2019s no response.\\n\\n. GET http://localhost:5103/failing?enable\\nThis request\", \" enables the middleware.\\n\\n308 CHAPTER 7 | Implement resilient applications\\n. GET http://localhost:51\", \"03/failing ?disable\\nThis request disables the middleware.\\n\\nFor instance, once the application is run\", \"ning, you can enable the middleware by making a request\\nusing the following URI in any browser. Note\", \" that the ordering microservice uses port 5103.\\n\\nhttp://localhost:5 103/failing?enable\\nYou can then \", \"check the status using the URI http://localhost:5103/failing, as shown in Figure 8-5.\\n\\nfF \\u00a9 \\u00a36 local\", \"host x + vv\\n\\n< 5 C) G) localhost:5103/failing Ww\\n\\nFailingMiddleware is disabled\\n\\nFigure 8-5. Checkin\", \"g the state of the \\u201cFailing\\u201d ASP.NET middleware \\u2014 In this case, disabled.\\n\\nAt this point, the Basket\", \" microservice responds with status code 500 whenever you call invoke it.\\n\\nOnce the middleware is run\", \"ning, you can try making an order from the MVC web application. Because\\nthe requests fail, the circu\", \"it will open.\\n\\nIn the following example, you can see that the MVC web application has a catch block \", \"in the logic for\\nplacing an order. If the code catches an open-circuit exception, it shows the user \", \"a friendly message\\ntelling them to wait.\\n\\npublic class CartController : Controller\\n{\\n//...\\npublic as\", \"ync Task<IActionResult> Index()\\n{\\ntry\\n{\\nvar user = _appUserParser.Parse(HttpContext.User) ;\\n//Http r\", \"equests using the Typed Client (Service Agent)\\nvar vm = await _basketSvc.GetBasket(user) ;\\nreturn Vi\", \"ew(vm) ;\\n\\ncatch (BrokenCircuitException)\\n\\n{\\n\\n// Catches error when Basket.api is in circuit-opened m\", \"ode\\nHandleBrokenCircuitException() ;\\n\\nreturn View();\\n\\n}\\n\\nprivate void HandleBrokenCircuitException()\", \"\\n\\n{\\n\\nTempData|[ \\\"BasketInoperativeMsg\\\"| = \\\"Basket Service is inoperative, please try later\\non. (Busi\", \"ness message due to Circuit-Breaker)\\\";\\n\\n}\\n\\n}\\n\\nHere\\u2019s a summary. The Retry policy tries several times\", \" to make the HTTP request and gets HTTP errors.\\nWhen the number of retries reaches the maximum numbe\", \"r set for the Circuit Breaker policy (in this\\ncase, 5), the application throws a BrokenCircuitExcept\", \"ion. The result is a friendly message, as shown in\\nFigure 8-6.\\n\\n309 CHAPTER 7 | Implement resilient \", \"applications\\noO\\nx\\n\\n& i MyCart- MicrosofteSh x i+ Vv =\\n\\n\\u20ac<\\u20ac > O \\u00ae localhost:5100/Cart x %* 4\\n\\nle] a d\", \"emouser@microsoft.com = 8 :\\n\\nD> Basket Service is inoperative, please try later on. (Business Msg Du\", \"e to Circuit-Breaker)\\n\\nFigure 8-6. Circuit breaker returning an error to the Ul!\\n\\nYou can implement \", \"different logic for when to open/break the circuit. Or you can try an HTTP request\\nagainst a differe\", \"nt back-end microservice if there's a fallback datacenter or redundant back-end\\nsystem.\\n\\nFinally, an\", \"other possibility for the CircuitBreakerPolicy is to use Isolate (which forces open and holds\\nopen t\", \"he circuit) and Reset (which closes it again). These could be used to build a utility HTTP\\nendpoint \", \"that invokes Isolate and Reset directly on the policy. Such an HTTP endpoint could also be\\nused, sui\", \"tably secured, in production for temporarily isolating a downstream system, such as when\\nyou want to\", \" upgrade it. Or it could trip the circuit manually to protect a downstream system you\\nsuspect to be \", \"faulting.\\n\\nAdditional resources\\n\\n. Circuit Breaker pattern\\n\\nhttps://learn.microsoft.com/azure/archit\", \"ecture/patterns/circuit-breaker\\n\\nHealth monitoring\\n\\nHealth monitoring can allow near-real-time infor\", \"mation about the state of your containers and\\nmicroservices. Health monitoring is critical to multip\", \"le aspects of operating microservices and Is\\nespecially important when orchestrators perform partial\", \" application upgrades in phases, as explained\\nlater.\\n\\nMicroservices-based applications often use hea\", \"rtbeats or health checks to enable their performance\\nmonitors, schedulers, and orchestrators to keep\", \" track of the multitude of services. If services cannot\\nsend some sort of \\u201cI\\u2019m alive\\u201d signal, either\", \" on demand or on a schedule, your application might face\\nrisks when you deploy updates, or it might \", \"just detect failures too late and not be able to stop\\ncascading failures that can end up in major ou\", \"tages.\\n\\nIn the typical model, services send reports about their status, and that information is aggr\", \"egated to\\nprovide an overall view of the state of health of your application. If you're using an orc\", \"hestrator, you\\ncan provide health information to your orchestrator\\u2019s cluster, so that the cluster ca\", \"n act accordingly. If\\nyou invest in high-quality health reporting that\\u2019s customized for your applica\", \"tion, you can detect and\\nfix issues for your running application much more easily.\\n\\n310 CHAPTER 7 | \", \"Implement resilient applications\\nImplement health checks in ASP.NET Core services\\n\\nWhen developing a\", \"n ASP.NET Core microservice or web application, you can use the built-in health\\nchecks feature that \", \"was released in ASP .NET Core 2.2\\n(Microsoft.Extensions.Diagnostics.HealthChecks). Like many ASP.NET\", \" Core features, health checks\\n\\ncome with a set of services and a middleware.\\n\\nHealth check services \", \"and middleware are easy to use and provide capabilities that let you validate If\\nany external resour\", \"ce needed for your application (like a SQL Server database or a remote API) is\\nworking properly. Whe\", \"n you use this feature, you can also decide what it means that the resource is\\nhealthy, as we explai\", \"n later.\\n\\nTo use this feature effectively, you need to first configure services in your microservice\", \"s. Second, you\\nneed a front-end application that queries for the health reports. That front-end appl\", \"ication could be a\\ncustom reporting application, or it could be an orchestrator itself that can reac\", \"t accordingly to the\\nhealth states.\\n\\nUse the HealthChecks feature in your back-end ASP.NET microserv\", \"ices\\n\\nIn this section, you'll learn how to implement the HealthChecks feature in a sample ASP.NET Co\", \"re 7.0\\nWeb API application when using the Microsoft.Extensions.Diagnostics.HealthChecks package. The\", \"\\nImplementation of this feature in a large-scale microservices like the eshopOnContainers is explain\", \"ed\\nin the next section.\\n\\nTo begin, you need to define what constitutes a healthy status for each mic\", \"roservice. In the sample\\napplication, we define the microservice Is healthy if its API is accessible\", \" via HTTP and its related SQL\\nServer database is also available.\\n\\nIn .NET 7, with the built-in APls,\", \" you can configure the services, add a Health Check for the\\nmicroservice and its dependent SQL Serve\", \"r database in this way:\\n\\n// Program.cs from .NET 7 Web API sample\\n\\nrr\\n// Registers required services\", \" for health checks\\nbuilder.Services.AddHealthChecks()\\n// Add a health check for a SQL Server databas\", \"e\\n. AddCheck(\\n\\u201cOrderingDB-check\\\",\\nnew SqlConnectionHealthCheck (builder .Configuration[ \\\"ConnectionS\", \"tring\\\"]),\\nHealthStatus.Unhealthy ,\\n\\nnew string[] { \\\"orderingdb\\\" });\\n\\nIn the previous code, the servi\", \"ces.AddHealthChecks() method configures a basic HTTP check that\\nreturns a status code 200 with \\u201cHeal\", \"thy\\u201d. Further, the AddCheck() extension method configures a\\ncustom SqlConnectionHealthCheck that che\", \"cks the related SQL Database\\u2019s health.\\n\\nThe AddCheck() method adds a new health check with a specifi\", \"ed name and the implementation of\\ntype IHealthCheck. You can add multiple Health Checks using AddChe\", \"ck method, so a microservice\\nwon't provide a \\u201chealthy\\u201d status until all its checks are healthy.\\n\\n311\", \" CHAPTER 7 | Implement resilient applications\\nSqiConnectionHealthCheck is a custom class that implem\", \"ents |HealthCheck, which takes a connection\\nstring as a constructor parameter and executes a simple \", \"query to check if the connection to the SQL\\ndatabase is successful. It returns HealthCheckResult.Hea\", \"lthy() if the query was executed successfully\\nand a FailureStatus with the actual exception when it \", \"fails.\\n\\n// Sample SQL Connection Health Check\\npublic class SqlConnectionHealthCheck : IHealthCheck\\n\\n\", \"{\\n\\nprivate const string DefaultTestQuery = \\\"Select 1\\\";\\npublic string ConnectionString { get; }\\npubli\", \"c string TestQuery { get; }\\n\\npublic SqlConnectionHealthCheck(string connectionString)\\n: this(connect\", \"ionString, testQuery: DefaultTestQuery )\\n\\n{\\n\\n}\\n\\npublic SqlConnectionHealthCheck(string connectionStr\", \"ing, string testQuery)\\n{\\nConnectionString = connectionString ?? throw new\\nArgumentNullException(name\", \"of (connectionString) ) ;\\nTestQuery = testQuery;\\n}\\n\\npublic async Task<HealthCheckResult> CheckHealth\", \"Async(HealthCheckContext context,\\nCancellationToken cancellationToken = default(CancellationToken) )\", \"\\n\\n{\\n\\nusing (var connection = new SqlConnection(ConnectionString ) )\\n\\n{\\n\\ntry\\naf\\n\\nawait connection.Ope\", \"nAsync(cancellationToken) ;\\n\\nif (TestQuery != null)\\n\\n{\\nvar command = connection.CreateCommand( ) ;\\nc\", \"ommand.CommandText = TestQuery;\\n\\nawait command. ExecuteNonQueryAsync(cancellationToken) ;\\n}\\n}\\ncatch \", \"(DbException ex)\\n{\\nreturn new HealthCheckResult(status: context.Registration.FailureStatus,\\nexceptio\", \"n: ex);\\n}\\n}\\n\\nreturn HealthCheckResult.Healthy() ;\\n\\nNote that in the previous code, Select 1 is the q\", \"uery used to check the Health of the database. To\\nmonitor the availability of your microservices, or\", \"chestrators like Kubernetes periodically perform\\nhealth checks by sending requests to test the micro\", \"services. It's important to keep your database\\nqueries efficient so that these operations are quick \", \"and don't result in a higher utilization of resources.\\n\\n312 CHAPTER 7 | Implement resilient applicat\", \"ions\\nFinally, add a middleware that responds to the url path /hc:\\n\\n// Program.cs from .NET 7 Web Api\", \" sample\\napp .MapHealthChecks(\\\"/hc\\\") ;\\n\\nWhen the endpoint <yourmicroservice>/hc is invoked, it runs a\", \"ll the health checks that are configured\\nin the AddHealthChecks() method in the Startup class and sh\", \"ows the result.\\n\\nHealthChecks implementation in eshopOnContainers\\n\\nMicroservices in eSshopOnContaine\", \"rs rely on multiple services to perform its task. For example, the\\nCatalog.API microservice from eSh\", \"opOnContainers depends on many services, such as Azure Blob\\nStorage, SQL Server, and RabbitMQ. There\", \"fore, it has several health checks added using the\\nAddCheck() method. For every dependent service, a\", \" custom |HealthCheck implementation that\\ndefines its respective health status would need to be added\", \".\\n\\nThe open-source project AsoNetCore.Diagnostics.HealthChecks solves this problem by providing\\ncust\", \"om health check implementations for each of these enterprise services, that are built on top of\\n.NET\", \" 7. Each health check is available as an individual NuGet package that can be easily added to the\\npr\", \"oject. eShopOnContainers uses them extensively in all its microservices.\\n\\nFor instance, in the Catal\", \"og.API microservice, the following NuGet packages were added:\\n\\n4c] Catalog.APl\\n& Connected Services\\n\", \"afl\\n\\n@ Analyzers\\n\\ne:] Frameworks\\n\\na Packages\\nb WS AspNetCore.HealthChecks.AzureServiceBus (3.0.0)\\nb \", \" S AspNetCore.HealthChecks.AzureStorage (3.0.1)\\nb QR AspNetCore.HealthChecks.Rabbitmg (3.0.3)\\nb QS A\", \"spNetCore.HealthChecks.SqlServer (3.0.0)\\nb QB AspNetCore.HealthChecks.UI.Client (3.0.0)\\n>  Autofac.E\", \"xtensions.Dependencylnjection (5.0.1)\\n[ i. Google.Protobut (3.11.2)\\nb QR Grpc.AspNetCore.Server (2.2\", \"5.0)\\n\\nFigure 8-7. Custom Health Checks implemented in Catalog.AP! using AspNetCore. Diagnostics. Hea\", \"lthChecks\\n\\nIn the following code, the health check implementations are added for each dependent serv\", \"ice and\\nthen the middleware is configured:\\n\\n// Extension method from Catalog.api microservice\\n\\n//\\npu\", \"blic static IServiceCollection AddCustomHealthCheck(this IServiceCollection services,\\n\\nIConfiguratio\", \"n configuration)\\n\\n{\\n\\nvar accountName = configuration. GetValue<string>(\\\"AzureStorageAccountName\\u201d ) ;\", \"\\nvar accountKey = configuration.GetValue<string>(\\\"AzureStorageAccountKey\\\" ) ;\\n\\nvar hcBuilder = servi\", \"ces.AddHealthChecks() ;\\n\\n313 CHAPTER 7 | Implement resilient applications\\nhcBuilder\\n.AddSqlServer (\\n\", \"configuration| \\\"ConnectionString\\\" |,\\nname: \\\"CatalogDB-check\\\",\\ntags: new string[] { \\\"catalogdb\\\" });\\n\\n\", \"if (!string.IsNullOrEmpty(accountName) && !string.IsNullOrEmpty(accountKey) )\\n\\nhcBuilder\\n.AddAzureBl\", \"obStorage(\\n\\n$\\\"DefaultEndpointsProtocol=https ;AccountName={accountName};AccountKey={accountKey}; End\", \"point\\nSuffix=core.windows.net\\\",\\n\\nname: \\\"catalog-storage-check\\\",\\n\\ntags: new string|[] { \\\"catalogstora\", \"ge\\\" });\\n\\nif (configuration. GetValue<bool>(\\\"AzureServiceBusEnabled\\\" ) )\\n\\nhcBuilder\\n.AddAzureServiceB\", \"us Topic (\\nconfiguration|[ \\\"EventBusConnection\\\" |,\\ntopicName: \\\"\\u201ceshop_event_bus\\\",\\nname: \\\"\\u201ccatalog-se\", \"rvicebus-check\\\",\\ntags: new string|[] { \\\"\\u201cservicebus\\\" });\\n\\n}\\nelse\\nhcBuilder\\n. AddRabbitMQ(\\n\\n$\\\"amqp://\", \"{configuration[ \\\"EventBusConnection\\\" ]}\\\",\\nname: \\\"\\u201ccatalog-rabbitmqbus-check\\\",\\ntags: new string|[] { \", \"\\\"rabbitmqbus\\\" });\\n\\n}\\n\\nreturn services;\\n\\n}\\n\\nFinally, add the HealthCheck middleware to listen to \\u201c/hc\", \"\\u201d endpoint:\\n\\n// HealthCheck middleware\\napp.UseHealthChecks(\\\"/hc\\\", new HealthCheckOptions()\\n\\nPredicat\", \"e = _ => true,\\nResponseWriter = UIResponseWriter.WriteHealthCheckUIResponse\\n\\n})3\\n\\nQuery your microse\", \"rvices to report about their health status\\n\\nWhen you've configured health checks as described in thi\", \"s article and you have the microservice\\nrunning in Docker, you can directly check from a browser if \", \"it's healthy. You have to publish the\\ncontainer port in the Docker host, so you can access the conta\", \"iner through the external Docker host IP\\nor through host.docker.internal, as shown in figure 8-8.\\n\\n3\", \"14 CHAPTER 7 | Implement resilient applications\\n(nr) A Not secure host.docker.internal\\n\\n\\u2018gige. statu\", \"s\\u201d: \\u201cHealthy\\u201d, \\u201ctotalDuration\\u201d :\\\"00:00:00.0035390\\\",\\\"entries\\\":{\\\"self\\\":{\\\"data\\\":\\n{}, \\\"duration\\\" :\\\"00:00\", \":00.0000017\\\", \\\"status\\\": \\\"Healthy\\\", \\u201ctags\\\":[]}, \\\"CatalogDB-check\\\":{\\\"data\\\":\\n{}, \\\"duration\\\" :\\\"00:00:00.\", \"0024642\\\", \\\"status\\\": \\\"Healthy\\\", \\\"tags\\\": [\\u201ccatalogdb\\\"]}, \\u201ccatalog-rabbitmqbus-check\\\":{\\\"\\u201cdata\\u201d\\\":\\n{}, \\\"d\", \"uration\\\" :\\\"00:00:00.0034585\\\", \\u201cstatus\\u201d: \\\"Healthy\\\", \\\"tags\\\": [\\u201crabbitmqbus\\u201d\\u2122 ]}}}\\n\\nFigure 8-8. Checkin\", \"g health status of a single service from a browser\\n\\nIn that test, you can see that the Catalog.API m\", \"icroservice (running on port 5101) is healthy, returning\\nHTTP status 200 and status information in J\", \"SON. The service also checked the health of its SQL Server\\ndatabase dependency and RabbitMQ, so the \", \"health check reported itself as healthy.\\n\\nUse watchdogs\\n\\nA watchdog is a separate service that can w\", \"atch health and load across services, and report health\\nabout the microservices by querying with the\", \" HealthChecks library introduced earlier. This can help\\nprevent errors that would not be detected ba\", \"sed on the view of a single service. Watchdogs also are a\\ngood place to host code that can perform r\", \"emediation actions for known conditions without user\\ninteraction.\\n\\nThe eShopOnContainers sample cont\", \"ains a web page that displays sample health check reports, as\\nshown in Figure 8-9. This is the simpl\", \"est watchdog you could have since it only shows the state of the\\nmicroservices and web applications \", \"in eshopOnContainers. Usually a watchdog also takes actions\\nwhen it detects unhealthy states.\\n\\nFortu\", \"nately, AsoNetCore.Diagnostics.HealthChecks also provides AspNetCore.HealthChecks.UI NuGet\\npackage t\", \"hat can be used to display the health check results from the configured URIs.\\n\\n315 CHAPTER 7 | Imple\", \"ment resilient applications\\n|\\u2014 Health Checks Ul x + = oO x\\n\\n< O @  localhost:5107/hc-ui#/healthcheck\", \"s we \\u20189 UY = mM = A &\\n\\nHealth Checks status Refresh every 10 seconds\\n2) NAME HEALTH ON STATE FROM LA\", \"ST EXECUTION\\n\\u2018&\\u00bb Health Checks + WebMVC HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\ni \", \"Webhooks + WebSPA HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n+ Web Shopping Aggregato\", \"r GW HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n+ Mobile Shopping Aggregator HTTP Che\", \"ck g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n_- Ordering HTTP Check afin g Healthy 2 minutes ag\", \"o 12/12/2019, 3:41:17 PM\\nNAME HEALTH DESCRIPTION DURATION\\nself g Healthy 00:00:00.0000031\\norderingDB\", \"-check g Healthy 00:00:00.0008153\\nordering-rabbitmqbus-check g Healthy 00:00:00.0097614\\n+ Basket HTT\", \"P Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n+ Catalog HTTP Check g Healthy 2 minutes ago \", \"12/12/2019, 3:41:17 PM\\n+ Identity HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n+ Market\", \"ing HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:17 PM\\n+ Locations HTTP Check g Healthy 2 min\", \"utes ago 12/12/2019, 3:41:18 PM\\n+ Payments HTTP Check g Healthy 2 minutes ago 12/12/2019, 3:41:18 PM\", \"\\n+ Ordering SianalRHub HTTP Check @ Healthy 2 minutes ago 12/12/2019. 3:41:18 PM\\n\\nFigure 8-9. Sample\", \" health check report in eShopOnContainers\\n\\nIn summary, this watchdog service queries each microservi\", \"ce\\u2019s \\u201c/hc\\u201d endpoint. This will execute all the\\nhealth checks defined within it and return an overall\", \" health state depending on all those checks. The\\nHealthChecksUI is easy to consume with a few config\", \"uration entries and two lines of code that needs\\nto be added into the Startup.cs of the watchdog ser\", \"vice.\\n\\nSample configuration file for health check UI:\\n\\n// Configuration\\n{\\n\\u201cHealthChecksUI\\\": {\\n\\u201c\\\"Heal\", \"thChecks\\\": [\\n\\n\\\"Name\\\": \\\"Ordering HTTP Check\\\",\\n\\\"Uri\\\": \\\"http://host.docker.internal:5102/hc\\\"\\n\\n\\\"Name\\\": \\\"\", \"Ordering HTTP Background Check\\\",\\n\\\"Uri\\\": \\\"http://host.docker.internal:5111/hc\\\"\\nhs\\nfoo\\n]}\\n\\nProgram.cs \", \"file that adds HealthChecksUI:\\n\\n316 CHAPTER 7 | Implement resilient applications\\n// Program.cs from \", \"WebStatus(Watch Dog) service\\n//\\n\\n// Registers required services for health checks\\n\\nbuilder.Services.\", \"AddHealthChecksUI() ;\\n// build the app, register other middleware\\napp.UseHealthChecksUI(config => co\", \"nfig.UIPath = \\\"/hc-ui\\\");\\n\\nHealth checks when using orchestrators\\n\\nTo monitor the availability of you\", \"r microservices, orchestrators like Kubernetes and Service Fabric\\nperiodically perform health checks\", \" by sending requests to test the microservices. When an\\norchestrator determines that a service/conta\", \"iner is unhealthy, it stops routing requests to that\\ninstance. It also usually creates a new instanc\", \"e of that container.\\n\\nFor instance, most orchestrators can use health checks to manage zero-downtime\", \" deployments. Only\\nwhen the status of a service/container changes to healthy will the orchestrator s\", \"tart routing traffic to\\nservice/container instances.\\n\\nHealth monitoring is especially important when\", \" an orchestrator performs an application upgrade.\\nSome orchestrators (like Azure Service Fabric) upd\", \"ate services in phases\\u2014for example, they might\\nupdate one-fifth of the cluster surface for each appl\", \"ication upgrade. The set of nodes that\\u2019s upgraded\\nat the same time is referred to as an upgrade doma\", \"in. After each upgrade domain has been upgraded\\nand is available to users, that upgrade domain must \", \"pass health checks before the deployment moves\\nto the next upgrade domain.\\n\\nAnother aspect of servic\", \"e health is reporting metrics from the service. This is an advanced capability of\\nthe health model o\", \"f some orchestrators, like Service Fabric. Metrics are important when using an\\norchestrator because \", \"they are used to balance resource usage. Metrics also can be an indicator of\\nsystem health. For exam\", \"ple, you might have an application that has many microservices, and each\\ninstance reports a requests\", \"-per-second (RPS) metric. If one service is using more resources (memory,\\nprocessor, etc.) than anot\", \"her service, the orchestrator could move service instances around in the\\ncluster to try to maintain \", \"even resource utilization.\\n\\nNote that Azure Service Fabric provides its own Health Monitoring model,\", \" which is more advanced\\nthan simple health checks.\\n\\nAdvanced monitoring: visualization, analysis, an\", \"d alerts\\n\\nThe final part of monitoring Is visualizing the event stream, reporting on service perform\", \"ance, and\\nalerting when an issue is detected. You can use different solutions for this aspect of mon\", \"itoring.\\n\\nYou can use simple custom applications showing the state of your services, like the custom\", \" page\\nshown when explaining the AsoNetCore.Diagnostics.HealthChecks. Or you could use more advanced\\n\", \"tools like Azure Monitor to raise alerts based on the stream of events.\\n\\nFinally, if you're storing \", \"all the event streams, you can use Microsoft Power BI or other solutions like\\nKibana or Splunk to vi\", \"sualize the data.\\n\\n317 CHAPTER 7 | Implement resilient applications\\nAdditional resources\\n\\u00b0 HealthChe\", \"cks and HealthChecks UI for ASP.NET Core\\n\\nhttps://github.com/Xabaril/AspNetCore.Diagnostics.HealthCh\", \"ecks\\n\\n. Introduction to Service Fabric health monitoring\\nhttos://learn.microsoft.com/azure/service-f\", \"abric/service-fabric-health-introduction\\n\\n\\u00b0 Azure Monitor\\n\\nhttps://azure.microsoft.com/services/moni\", \"tor/\\n\\n318 CHAPTER 7 | Implement resilient applications\\nCHAPTER\\n\\nMake secure .NET\\nMicroservices and W\", \"eb\\nApplications\\n\\nThere are so many aspects about security in microservices and web applications that\", \" the topic could\\neasily take several books like this one. So, in this section, we'll focus on authen\", \"tication, authorization,\\nand application secrets.\\n\\nImplement authentication in .NET microservices an\", \"d\\nweb applications\\n\\nIt's often necessary for resources and APIs published by a service to be limited\", \" to certain trusted users\\nor clients. The first step to making these sorts of APl-level trust decisi\", \"ons is authentication.\\nAuthentication is the process of reliably verifying a user's identity.\\n\\nIn mi\", \"croservice scenarios, authentication is typically handled centrally. If you're using an API Gateway,\", \"\\nthe gateway is a good place to authenticate, as shown in Figure 9-1. If you use this approach, make\", \"\\nsure that the individual microservices cannot be reached directly (without the API Gateway) unless\\n\", \"additional security is in place to authenticate messages whether they come from the gateway or not.\\n\", \"\\nere ee eee ee ee se eee \\u2014 lh,\\n\\nCatalog Microservice\\n\\n| Request with\\nluger information\\n\\n0 ES SS a\\n\\nF\", \"igure 9-1. Centralized authentication with an API Gateway\\n\\nWhen the API Gateway centralizes authenti\", \"cation, it adds user information when forwarding requests\\nto the microservices. If services can be a\", \"ccessed directly, an authentication service like Azure Active\\n\\n319 CHAPTER 8 | Make secure .NET Micr\", \"oservices and Web Applications\\nDirectory or a dedicated authentication microservice acting as a secu\", \"rity token service (STS) can be\\nused to authenticate users. Trust decisions are shared between servi\", \"ces with security tokens or\\ncookies. (These tokens can be shared between ASP.NET Core applications, \", \"if needed, by implementing\\ncookie sharing.) This pattern is illustrated in Figure 9-2.\\n\\n! Backend Mi\", \"croservices\\nin, | i Idantios MMicrocervice (<TC \\u00ab Uners'\\u2019\\u201d\\n\\u2018 Sign-in | Id entity Microservice (STS \\u00ab\", \" Users) |\\n\\u2014 SOL Serve I\\n\\u00ab\\u2014}__Securitytoken Kel a database\\n\\nRequest with token\\n\\nRequest with token\\n\\nF\", \"igure 9-2. Authentication by identity microservice; trust is shared using an authorization token\\n\\nWh\", \"en microservices are accessed directly, trust, that includes authentication and authorization, is\\nha\", \"ndled by a security token issued by a dedicated microservice, shared between microservices.\\n\\nAuthent\", \"icate with ASP.NET Core Identity\\n\\nThe primary mechanism in ASP.NET Core for identifying an applicati\", \"on's users is the ASP.NET Core\\nIdentity membership system. ASP.NET Core Identity stores user informa\", \"tion (including sign-in\\ninformation, roles, and claims) in a data store configured by the developer.\", \" Typically, the ASP.NET\\nCore Identity data store is an Entity Framework store provided in the\\nMicros\", \"oft.AspNetCore.|dentity.EntityFrameworkCore package. However, custom stores or other third-\\nparty pa\", \"ckages can be used to store identity information in Azure Table Storage, CosmosDB, or other\\nlocation\", \"s.\\n\\nTip\\n\\nASP.NET Core 2.1 and later provides ASP.NET Core Identity as a Razor Class Library, so you \", \"won't see\\n\\nmuch of the necessary code in your project, as was the case for previous versions. For de\", \"tails on how\\nto customize the Identity code to suit your needs, see Scaffold Identity in ASP.NET Cor\", \"e projects.\\n\\nThe following code is taken from the ASP.NET Core Web Application MVC 3.1 project templ\", \"ate with\\nindividual user account authentication selected. It shows how to configure ASP.NET Core Ide\", \"ntity\\nusing Entity Framework Core in the Program.cs file.\\n\\nrr\\nbuilder.Services.AddDbContext<Applicat\", \"ionDbContext>(options =>\\noptions.UseSqlServer (\\nbuilder .Configuration.GetConnectionString(\\\"DefaultC\", \"onnection\\\") ) ) ;\\n\\n320 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\nbuilder.Servi\", \"ces.AddDefaultIdentity<IdentityUser>(options =>\\noptions.SignIn.RequireConfirmedAccount = true)\\n.AddE\", \"ntityFrameworkStores<ApplicationDbContext>() ;\\n\\nbuilder.Services.AddRazorPages() ;\\n\\nrr\\n\\nOnce ASP.NET\", \" Core Identity is configured, you enable it by adding the\\napp.UseAuthentication() and endpoints.MapR\", \"azorPages() as shown in the following code in the\\nservice\\u2019s Program.cs file:\\n\\nrr\\napp.UseRouting();\\n\\n\", \"app.UseAuthentication() ;\\napp.UseAuthorization() ;\\n\\napp.UseEndpoints(endpoints =>\\nendpoints .MapRazo\", \"rPages() ;\\n\\n})3\\n//...\\n\\nImportant\\n\\nThe lines in the preceding code MUST BE IN THE ORDER SHOWN for Ide\", \"ntity to work correctly.\\n\\nUsing ASP.NET Core Identity enables several scenarios:\\n\\n\\u00b0 Create new user \", \"information using the UserManager type (userManager.CreateAsync).\\n\\n. Authenticate users using the Si\", \"gninManager type. You can use signInManager.SignInAsync to\\nsign in directly, or signinManager.Passwo\", \"rdSignInAsync to confirm the user's password is\\ncorrect and then sign them in.\\n\\n\\u00b0 Identify a user ba\", \"sed on information stored in a cookie (which is read by ASP.NET Core\\nIdentity middleware) so that su\", \"bsequent requests from a browser will include a signed-in\\nuser's identity and claims.\\n\\nASP.NET Core \", \"Identity also supports two-factor authentication.\\n\\nFor authentication scenarios that make use of a l\", \"ocal user data store and that persist identity between\\nrequests using cookies (as is typical for MVC\", \" web applications), ASP.NET Core Identity is a\\nrecommended solution.\\n\\nAuthenticate with external pro\", \"viders\\n\\nASP.NET Core also supports using external authentication providers to let users sign in via \", \"OAuth 2.0\\nflows. This means that users can sign in using existing authentication processes from prov\", \"iders like\\nMicrosoft, Google, Facebook, or Twitter and associate those identities with an ASP.NET Co\", \"re identity\\nin your application.\\n\\nTo use external authentication, besides including the authenticati\", \"on middleware as mentioned before,\\nusing the app.UseAuthentication() method, you also have to regist\", \"er the external provider in\\nProgram.cs as shown in the following example:\\n\\n321 CHAPTER 8 | Make secu\", \"re .NET Microservices and Web Applications\\n//...\\nservices .AddDefaultIdentity<IdentityUser>(options \", \"=> options.Signin.RequireConfirmedAccount\\n= true)\\n\\n.AddEntityFrameworkStores<ApplicationDbContext>()\", \" ;\\n\\nservices .AddAuthentication()\\n.AddMicrosoftAccount(microsoftOptions =>\\n{\\nmicrosoftOptions.Client\", \"Id =\\nbuilder.Configuration|[ \\\"Authentication:Microsoft:Clientid\\\" | ;\\nmicrosoftOptions.ClientSecret =\", \"\\nbuilder.Configuration[ \\\"Authentication:Microsoft:ClientSecret\\\" | ;\\n})\\n.AddGoogle(googleOptions => {\", \" ... })\\n.AddTwitter(twitterOptions => { ... })\\n.AddFacebook(facebookOptions => { ... });\\nHilloco\\n\\nPo\", \"pular external authentication providers and their associated NuGet packages are shown in the\\nfollowi\", \"ng table:\\n\\n| Microsoft = Microsoft.AspNetCore.Authentication.MicrosoftAccount\\n\\nMicrosoft.AspNetCore.\", \"Authentication.Google\\nMicrosoft.AspNetCore.Authentication.Facebook\\nMicrosoft.AspNetCore.Authenticati\", \"on. Twitter\\n\\nIn all cases, you must complete an application registration procedure that is vendor de\", \"pendent and\\nthat usually involves:\\n\\n1. Getting a Client Application ID.\\nGetting a Client Application\", \" Secret.\\n\\nConfiguring a redirection URL, that\\u2019s handled by the authorization middleware and the\\nregi\", \"stered provider\\n\\n4. Optionally, configuring a sign-out URL to properly handle sign out in a Single S\", \"ign On (SSO)\\nscenario.\\n\\nFor details on configuring your app for an external provider, see the Extern\", \"al provider authentication\\nin the ASP.NET Core documentation).\\n\\nTip\\n\\nAll details are handled by the \", \"authorization middleware and services previously mentioned. So, you\\n\\njust have to choose the Individ\", \"ual User Account authentication option when you create the ASP.NET\\nCore web application project in V\", \"isual Studio, as shown in Figure 9-3, besides registering the\\nauthentication providers previously me\", \"ntioned.\\n\\n322 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\nCreate a new ASP.NET C\", \"ore web application\\n\\n\\u00abNET Core ~ ASP.NET Core 5.0\\n\\n~ | ASP.NET Core Empty Authentication\\nNN\\n\\nAn empt\", \"y project template for creating an ASP.NET Core application. This template does not have any content\", \" in Individual User Accounts\\n\\n= Change\\n\\nASP.NET Core Web API\\n\\nA project template for creating an ASP\", \".NET Core application with an example Controller for a RESTful HTTP service.\\nThis template can also \", \"be used for ASP.NET Core MVC Views and Controllers.\\n\\nAdvanced\\nASP.NET Core Web App\\n\\nA project templa\", \"te for creating an ASP.NET Core application with example ASP.NET Razor Pages content. |_| Enable Doc\", \"ker Support\\n(Requires Docker Desktop)\\n\\nEnable Razor runtime compilation\\nA ASP.NET Core with Angular\\n\", \"\\nA project template for creating an ASP.NET Core application with Angular\\n\\nde ASP.NET Core with Reac\", \"t.js Author: Microsoft\\n\\nSource: Templates 5.0.0\\n\\nGet additional project templates\\n\\nFigure 9-3. Selec\", \"ting the Individual User Accounts option, for using external authentication, when creating a web\\napp\", \"lication project in Visual Studio 2079.\\n\\nIn addition to the external authentication providers listed\", \" previously, third-party packages are\\navailable that provide middleware for using many more external\", \" authentication providers. For a list,\\nsee the repository on GitHub.\\n\\nYou can also create your own e\", \"xternal authentication middleware to solve some special need.\\n\\nAuthenticating with ASP.NET Core Iden\", \"tity (or Identity plus external authentication providers) works\\nwell for many web application scenar\", \"ios in which storing user information in a cookie Is appropriate.\\nIn other scenarios, though, cookie\", \"s are not a natural means of persisting and transmitting data.\\n\\nFor example, in an ASP.NET Core Web \", \"API that exposes RESTful endpoints that might be accessed by\\nSingle Page Applications (SPAs), by nat\", \"ive clients, or even by other Web APIs, you typically want to\\nuse bearer token authentication instea\", \"d. These types of applications do not work with cookies, but\\ncan easily retrieve a bearer token and \", \"include it in the authorization header of subsequent requests.\\nTo enable token authentication, ASP.N\", \"ET Core supports several options for using and\\nAuthenticate with an OpenID Connect or OAuth 2.0 Iden\", \"tity provider\\n\\nIf user information is stored in Azure Active Directory or another identity solution \", \"that supports\\nOpenID Connect or OAuth 2.0, you can use the\\nMicrosoft.AspNetCore.Authentication.Openl\", \"dConnect package to authenticate using the OpenID\\nConnect workflow. For example, to authenticate to \", \"the Identity.Api microservice in\\neShopOnContainers, an ASP.NET Core web application can use middlewa\", \"re from that package as\\nshown in the following simplified example in Program.cs:\\n\\n// Program.cs\\n\\nvar\", \" identityUrl = builder.Configuration.GetValue<string>(\\\"IdentityUr1\\\") ;\\n\\nvar callBackUrl builder.Conf\", \"iguration.GetValue<string>(\\\"CallBackUr1\\\") ;\\n\\nvar sessionCookieLifetime = builder.Configuration.GetVa\", \"lue(\\\"SessionCookieLifetimeMinutes\\\",\\n6@);\\n\\n// Add Authentication services\\n\\nservices.AddAuthentication\", \"(options =>\\n{\\noptions.DefaultScheme = CookieAuthenticationDefaults .AuthenticationScheme ;\\noptions.D\", \"efaultChallengeScheme = JwtBearerDefaults .AuthenticationScheme;\\n})\\n.AddCookie(setup => setup.Expire\", \"TimeSpan = TimeSpan.FromMinutes(sessionCookieLifetime) )\\n.AddOpenIdConnect(options =>\\n{\\noptions.Sign\", \"InScheme = CookieAuthenticationDefaults.AuthenticationScheme ;\\noptions.Authority = identityUrl.ToStr\", \"ing();\\noptions.SignedOutRedirectUri = callBackUrl.ToString() ;\\noptions.ClientId = useLoadTest ? \\\"mvc\", \"test\\\" : \\\"mvc\\\";\\noptions.ClientSecret = \\\"secret\\\";\\noptions.ResponseType = useLoadTest ? \\\"code id_token \", \"token\\\" : \\\"code id_ token\\\";\\noptions.SaveTokens = true;\\noptions.GetClaimsFromUserInfoEndpoint = true;\\n\", \"options.RequireHttpsMetadata = false;\\noptions.Scope.Add(\\\"openid\\\") ;\\noptions.Scope.Add( \\\"profile\\\" ) ;\", \"\\noptions.Scope.Add(\\\"orders\\\") ;\\noptions.Scope.Add( \\\"basket\\\" ) ;\\noptions.Scope.Add( \\\"marketing\\\" ) ;\\nop\", \"tions.Scope.Add(\\\"locations\\\") ;\\noptions.Scope.Add(\\\"webshoppingagg\\\" ) ;\\noptions.Scope.Add(\\\"orders.sign\", \"alrhub\\\") ;\\n\\n})5\\n\\n// Build the app\\n\\n//...\\napp.UseAuthentication() ;\\n\\n//\\napp.UseEndpoints(endpoints =>\", \"\\n\\n//ue\\n})5\\n\\nWhen you use this workflow, the ASP.NET Core Identity middleware is not needed, because \", \"all user\\ninformation storage and authentication is handled by the Identity service.\\n\\n324 CHAPTER 8 |\", \" Make secure .NET Microservices and Web Applications\\nIssue security tokens from an ASP.NET Core serv\", \"ice\\n\\nIf you prefer to issue security tokens for local ASP.NET Core Identity users rather than using \", \"an\\nexternal identity provider, you can take advantage of some good third-party libraries.\\n\\nIdentityS\", \"erver4 and Openiddict are Open|ID Connect providers that integrate easily with ASP.NET Core\\nIdentity\", \" to let you issue security tokens from an ASP.NET Core service. The IdentityServer4\\ndocumentation ha\", \"s in-depth instructions for using the library. However, the basic steps to using\\nIdentityServer4 to \", \"issue tokens are as follows.\\n\\n1. You configure IdentityServer4 in Program.cs by making a call to\\nbui\", \"lder.Services.AddldentityServer.\\n\\n2. You call app.UseldentityServer in Program.cs to add IdentitySer\", \"ver4 to the application's HTTP\\nrequest processing pipeline. This lets the library serve requests to \", \"OpenID Connect and\\nOAuth2 endpoints like /connect/token.\\n\\n3. You configure identity server by settin\", \"g the following data:\\n\\u2014 The credentials to use for signing.\\n\\u2014 The Identity and API resources that us\", \"ers might request access to:\\n\\n. API resources represent protected data or functionality that a user \", \"can access\\nwith an access token. An example of an API resource would be a web API (or\\nset of APIs) t\", \"hat requires authorization.\\n\\n\\u00b0 Identity resources represent information (claims) that are given to a\", \" client to\\nidentify a user. The claims might include the user name, email address, and so\\non.\\n\\n\\u2014 The\", \" clients that will be connecting in order to request tokens.\\n\\n\\u2014 The storage mechanism for user infor\", \"mation, such as ASP.NET Core Identity or an\\nalternative.\\n\\nWhen you specify clients and resources for\", \" IdentityServer4 to use, you can pass an IEnumerable\\ncollection of the appropriate type to methods t\", \"hat take in-memory client or resource stores. Or for\\nmore complex scenarios, you can provide client \", \"or resource provider types via Dependency Injection.\\n\\nA sample configuration for IdentityServer4 to \", \"use in-memory resources and clients provided by a\\ncustom IClientStore type might look like the follo\", \"wing example:\\n\\n// Program.cs\\n\\nbuilder.Services.AddSingleton<IClientStore, CustomClientStore>() ;\\nbui\", \"lder.Services.AddIdentityServer ( )\\n\\n.AddSigningCredential(\\\"CN=sts\\\" )\\n.AddInMemoryApiResources (MyAp\", \"iResourceProvider.GetAllResources() )\\n.AddAspNetIdentity<ApplicationUser>() ;\\n\\nrr\\n\\n325 CHAPTER 8 | M\", \"ake secure .NET Microservices and Web Applications\\nConsume security tokens\\n\\nAuthenticating against a\", \"n OpenID Connect endpoint or issuing your own security tokens covers some\\nscenarios. But what about \", \"a service that simply needs to limit access to those users who have valid\\nsecurity tokens that were \", \"provided by a different service?\\n\\nFor that scenario, authentication middleware that handles JWT toke\", \"ns is available in the\\nMicrosoft.AspNetCore.Authentication.JwtBearer package. JWT stands for \\u201cJSON W\", \"eb Token\\u201d and\\nis acommon security token format (defined by RFC 7519) for communicating security clai\", \"ms. A\\nsimplified example of how to use middleware to consume such tokens might look like this code\\nf\", \"ragment, taken from the Ordering.Api microservice of eshopOnContainers.\\n\\n// Program.cs\\nvar identityU\", \"rl = builder.Configuration.GetValue<string>(\\\"IdentityUr1\\\") ;\\n// Add Authentication services\\n\\nbuilder\", \".Services.AddAuthentication(options =>\\naf\\noptions.DefaultAuthenticateScheme =\\nAspNetCore.Authenticat\", \"ion. JwtBearer. JwtBearerDefaults.AuthenticationScheme;\\noptions.DefaultChallengeScheme =\\nAspNetCore.\", \"Authentication. JwtBearer. JwtBearerDefaults.AuthenticationScheme;\\n\\n}).AddJwtBearer(options =>\\n\\n{\\nop\", \"tions.Authority = identityUr1;\\noptions.RequireHttpsMetadata = false;\\noptions.Audience = \\\"orders\\\";\\n\\n}\", \")5\\n\\n// Build the app\\n\\napp.UseAuthentication() ;\\n\\n//\\napp.UseEndpoints(endpoints =>\\n\\nHi ooc\\n\\n})5\\n\\nThe \", \"parameters in this usage are:\\n\\n. Audience represents the receiver of the incoming token or the resou\", \"rce that the token grants\\naccess to. If the value specified in this parameter does not match the par\", \"ameter in the token,\\nthe token will be rejected.\\n\\n\\u00b0 Authority is the address of the token-issuing au\", \"thentication server. The JWT bearer\\nauthentication middleware uses this URI to get the public key th\", \"at can be used to validate the\\ntoken's signature. The middleware also confirms that the iss paramete\", \"r in the token matches\\nthis URI.\\n\\nAnother parameter, RequireHttpsMetadata, is useful for testing pur\", \"poses; you set this parameter to\\nfalse so you can test in environments where you don\\u2019t have certific\", \"ates. In real-world deployments,\\nJWT bearer tokens should always be passed only over HTTPS.\\n\\n326 CHA\", \"PTER 8 | Make secure .NET Microservices and Web Applications\\nWith this middleware in place, JWT toke\", \"ns are automatically extracted from authorization headers.\\nThey are then deserialized, validated (us\", \"ing the values in the Audience and Authority parameters), and\\nstored as user information to be refer\", \"enced later by MVC actions or authorization filters.\\n\\nThe JWT bearer authentication middleware can a\", \"lso support more advanced scenarios, such as using a\\nlocal certificate to validate a token if the au\", \"thority is not available. For this scenario, you can specify a\\nTokenValidationParameters object in t\", \"he JwtBearerOptions object.\\n\\nAdditional resources\\n\\n. Sharing cookies between applications\\n\\nhttps://l\", \"earn.microsoft.com/aspnet/core/security/cookie-sharing\\n\\n. Introduction to Identity\\nhttps://learn.mic\", \"rosoft.com/aspnet/core/security/authentication/identity\\n\\u00b0 Rick Anderson. Two-factor authentication w\", \"ith SMS\\n\\nhttps://learn.microsoft.com/aspnet/core/security/authentication/2fa\\n\\n. Enabling authenticat\", \"ion using Facebook, Google and other external providers\\n\\nhttps://learn.microsoft.com/aspnet/core/sec\", \"urity/authentication/social/\\n\\n\\u00b0 Michell Anicas. An Introduction to OAuth 2\\nhttps://www.digitalocean.\", \"com/community/tutorials/an-introduction-to-oauth-2\\n\\n. AspNet.Security.OAuth.Providers (GitHub repo f\", \"or ASP.NET OAuth providers)\\nhttps://github.com/aspnet-contrib/AspNet.Security.OAuth.Providers/tree/d\", \"ev/src\\n\\n. IdentityServer4. Official documentation\\n\\nhttps://identityserver4.readthedocs.io/en/latest/\", \"\\n\\nAbout authorization in .NET microservices and web\\napplications\\n\\nAfter authentication, ASP.NET Core\", \" Web APIs need to authorize access. This process allows a service\\nto make APIs available to some aut\", \"henticated users, but not to all. Authorization can be done based\\non users\\u2019 roles or based on custom\", \" policy, which might include inspecting claims or other heuristics.\\n\\nRestricting access to an ASP.NE\", \"T Core MVC route is as easy as applying an Authorize attribute to the\\naction method (or to the contr\", \"oller's class if all the controller's actions require authorization), as\\nshown in following example:\", \"\\n\\npublic class AccountController : Controller\\n\\nt\\n\\npublic ActionResult Login()\\n\\nt\\n}\\n\\n[Authorize |\\n\\n32\", \"7 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\npublic ActionResult Logout()\\n\\nBy d\", \"efault, adding an Authorize attribute without parameters will limit access to authenticated users\\nfo\", \"r that controller or action. To further restrict an API to be available for only specific users, the\", \"\\nattribute can be expanded to specify required roles or policies that users must satisfy.\\n\\nImplement\", \" role-based authorization\\n\\nASP.NET Core Identity has a built-in concept of roles. In addition to use\", \"rs, ASP.NET Core Identity\\nstores information about different roles used by the application and keeps\", \" track of which users are\\nassigned to which roles. These assignments can be changed programmatically\", \" with the RoleManager\\ntype that updates roles in persisted storage, and the UserManager type that ca\", \"n grant or revoke roles\\nfrom users.\\n\\nIf you're authenticating with JWT bearer tokens, the ASP.NET Co\", \"re JWT bearer authentication\\nmiddleware will populate a user's roles based on role claims found in t\", \"he token. To limit access to an\\nMVC action or controller to users in specific roles, you can include\", \" a Roles parameter in the Authorize\\nannotation (attribute), as shown in the following code fragment:\", \"\\n\\n[Authorize(Roles = \\\"Administrator, PowerUser\\\" ) |\\npublic class ControlPanelController : Controller\", \"\\n{\\n\\npublic ActionResult SetTime()\\n\\n{\\n\\n}\\n\\n[Authorize(Roles = \\\"Administrator\\\" ) ]\\npublic ActionResult \", \"ShutDown()\\n\\n{\\n\\n}\\n\\nIn this example, only users in the Administrator or PowerUser roles can access API\", \"s in the\\nControlPanel controller (such as executing the SetTime action). The ShutDown API is further\", \" restricted\\nto allow access only to users in the Administrator role.\\n\\nTo require a user be in multip\", \"le roles, you use multiple Authorize attributes, as shown in the following\\nexample:\\n\\n[Authorize(Role\", \"s \\\"Administrator, PowerUser\\\" ) ]\\n[Authorize(Roles \\u201c\\\"RemoteEmployee \\\") |\\n[Authorize(Policy = \\\"CustomP\", \"olicy\\u201d\\\") ]\\n\\npublic ActionResult API1 ()\\n\\nt\\n}\\n\\nIn this example, to call API1, a user must:\\n\\u00b0 Be in th\", \"e Administrator or PowerUser role, and\\n\\n. Be in the RemoteEmployee role, and\\n\\n328 CHAPTER 8 | Make s\", \"ecure .NET Microservices and Web Applications\\n. Satisfy a custom handler for CustomPolicy authorizat\", \"ion.\\n\\nImplement policy-based authorization\\n\\nCustom authorization rules can also be written using aut\", \"horization policies. This section provides an\\noverview. For more information, see the ASP.NET Author\", \"ization Workshop.\\n\\nCustom authorization policies are registered in the Startup.ConfigureServices met\", \"hod using the\\nservice.AddAuthorization method. This method takes a delegate that configures an\\nAutho\", \"rizationOptions argument.\\n\\nservices.AddAuthorization(options =>\\n\\n{\\noptions.AddPolicy(\\\"Administrators\", \"Only\\\", policy =>\\n\\npolicy.RequireRole(\\\"Administrator\\\" ) ) ;\\n\\noptions.AddPolicy(\\\"EmployeesOnly\\\", polic\", \"y =>\\npolicy.RequireClaim(\\\"EmployeeNumber\\\" ) ) ;\\n\\noptions.AddPolicy(\\\"Over21\\\", policy =>\\npolicy.Requir\", \"ements.Add(new MinimumAgeRequirement(21)));\\n\\n})5\\n\\nAs shown in the example, policies can be associate\", \"d with different types of requirements. After the\\npolicies are registered, they can be applied to an\", \" action or controller by passing the policy's name as\\nthe Policy argument of the Authorize attribute\", \" (for example, [Authorize(Policy=\\\"EmployeesOnly\\\")])\\nPolicies can have multiple requirements, not jus\", \"t one (as shown in these examples).\\n\\nIn the previous example, the first AddPolicy call is just an al\", \"ternative way of authorizing by role. If\\n[Authorize(Policy=\\\"AdministratorsOnly\\\")] is applied to an A\", \"PI, only users in the Administrator role will\\nbe able to access it.\\n\\nThe second AddPolicy call demon\", \"strates an easy way to require that a particular claim should be\\npresent for the user. The RequireCl\", \"aim method also optionally takes expected values for the claim. If\\nvalues are specified, the require\", \"ment is met only if the user has both a claim of the correct type and\\none of the specified values. I\", \"f you're using the JWT bearer authentication middleware, all JWT\\nproperties will be available as use\", \"r claims.\\n\\nThe most interesting policy shown here is in the third AddPolicy method, because it uses \", \"a custom\\nauthorization requirement. By using custom authorization requirements, you can have a great\", \" deal of\\ncontrol over how authorization is performed. For this to work, you must implement these typ\", \"es:\\n\\n\\u00b0 A Requirements type that derives from !AuthorizationRequirement and that contains fields\\nspec\", \"ifying the details of the requirement. In the example, this is an age field for the sample\\nMinimumAg\", \"eRequirement type.\\n\\n. A handler that implements AuthorizationHandler, where T is the type of\\n[Author\", \"izationRequirement that the handler can satisfy. The handler must implement the\\nHandleReguirementAsy\", \"nc method, which checks whether a specified context that contains\\ninformation about the user satisfi\", \"es the requirement.\\n\\n329 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\nIf the user\", \" meets the requirement, a call to context.Succeed will indicate that the user is authorized. If\\nther\", \"e are multiple ways that a user might satisfy an authorization requirement, multiple handlers can\\nbe\", \" created.\\n\\nIn addition to registering custom policy requirements with AddPolicy calls, you also need\", \" to register\\ncustom requirement handlers via Dependency Injection (services.AddTransient<lAuthorizat\", \"ionHandler,\\nMinimumAgeHandler>()).\\n\\nAn example of a custom authorization requirement and handler for\", \" checking a user's age (based on a\\nDateOfBirth claim) is available in the ASP.NET Core authorization\", \" documentation.\\n\\nAuthorization and minimal apis\\n\\nASP.NET supports minimal APIs as an alternative to \", \"controller-based APls. Authorization policies are\\nthe recommended way to configure authorization for\", \" minimal APIs, as this example demonstrates:\\n\\n// Program.cs\\nbuilder.Services.AddAuthorizationBuilder\", \"()\\n.AddPolicy(\\\"admin_greetings\\\", policy =>\\npolicy\\n.RequireRole(\\\"admin\\\" )\\n.RequireScope(\\\"greetings ap\", \"i\\\") );\\n\\n// build the app\\n\\napp.MapGet(\\\"/hello\\\", () => \\\"Hello world!\\\")\\n.RequireAuthorization(\\\"admin_gr\", \"eetings\\\") ;\\n\\nAdditional resources\\n\\n\\u00b0 ASP.NET Core Authentication\\nhttps://learn.microsoft.com/aspnet/\", \"core/security/authentication/identity\\n\\n\\u00b0 ASP.NET Core Authorization\\nhttps://learn.microsoft.com/aspn\", \"et/core/security/authorization/introduction\\n\\n\\u00b0 Role-based Authorization\\n\\nhttps://learn.microsoft.com\", \"/aspnet/core/security/authorization/roles\\n\\n. Custom Policy-Based Authorization\\n\\nhttps://learn.micros\", \"oft.com/aspnet/core/security/authorization/policies\\n\\n\\u00b0 Authentication and authorization in minimal\\n\\n\", \"APIs https://learn.microsoft.com/aspnet/core/fundamentals/minimal-apis/security\\n\\nStore application s\", \"ecrets safely during development\\n\\nTo connect with protected resources and other services, ASP.NET Co\", \"re applications typically need to\\nuse connection strings, passwords, or other credentials that conta\", \"in sensitive information. These\\nsensitive pieces of information are called secrets. It's a best prac\", \"tice to not include secrets in source\\n\\n330 CHAPTER 8 | Make secure .NET Microservices and Web Applic\", \"ations\\ncode and making sure not to store secrets in source control. Instead, you should use the ASP.\", \"NET\\nCore configuration model to read the secrets from more secure locations.\\n\\nYou must separate the \", \"secrets for accessing development and staging resources from the ones used\\nfor accessing production \", \"resources, because different individuals will need access to those different\\nsets of secrets. To sto\", \"re secrets used during development, common approaches are to either store\\nsecrets in environment var\", \"iables or by using the ASP.NET Core Secret Manager tool. For more secure\\nstorage in production envir\", \"onments, microservices can store secrets in an Azure Key Vault.\\n\\nStore secrets in environment variab\", \"les\\n\\nOne way to keep secrets out of source code Is for developers to set string-based secrets as\\nenv\", \"ironment variables on their development machines. When you use environment variables to store\\nsecret\", \"s with hierarchical names, such as the ones nested in configuration sections, you must name the\\nvari\", \"ables to include the complete hierarchy of its sections, delimited with colons (:).\\n\\nFor example, se\", \"tting an environment variable Logging:LogLevel:Default to Debug value would be\\nequivalent to a confi\", \"guration value from the following JSON file:\\n\\n\\\"Logging\\\": {\\n\\u201cLogLevel\\\": {\\n\\n\\\"Default\\\": \\\"Debug\\\"\\n\\nTo acc\", \"ess these values from environment variables, the application just needs to call\\nAddEnvironmentVariab\", \"les on its ConfigurationBuilder when constructing an IConfigurationRoot\\nobject.\\n\\nNote\\n\\nEnvironment v\", \"ariables are commonly stored as plain text, so if the machine or process with the\\nenvironment variab\", \"les is compromised, the environment variable values will be visible.\\n\\nStore secrets with the ASP.NET\", \" Core Secret Manager\\n\\nThe ASP.NET Core Secret Manager tool provides another method of keeping secret\", \"s out of source\\ncode during development. To use the Secret Manager tool, install the package\\nMicroso\", \"ft.Extensions.Configuration.SecretManager in your project file. Once that dependency is\\npresent and \", \"has been restored, the dotnet user-secrets command can be used to set the value of\\nsecrets from the \", \"command line. These secrets will be stored in a JSON file in the user's profile\\ndirectory (details v\", \"ary by OS), away from source code.\\n\\nSecrets set by the Secret Manager tool are organized by the User\", \"Secretsld property of the project\\nthat's using the secrets. Therefore, you must be sure to set the U\", \"serSecretsid property in your project\\nfile, as shown in the snippet below. The default value is a GU\", \"ID assigned by Visual Studio, but the\\nactual string is not important as long as it\\u2019s unique in your \", \"computer.\\n\\n331 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\n<PropertyGroup>\\n\\n<Use\", \"rSecretsId>UniqueIdentifyingString</UserSecretsId>\\n</PropertyGroup>\\n\\nUsing secrets stored with Secre\", \"t Manager in an application is accomplished by calling\\nAddUserSecrets<T> on the ConfigurationBuilder\", \" instance to include secrets for the application in its\\nconfiguration. The generic parameter T shoul\", \"d be a type from the assembly that the UserSecretld was\\napplied to. Usually, using AddUserSecrets<St\", \"artup> is fine.\\n\\nThe AddUserSecrets <Startup>() is included in the default options for the Developme\", \"nt environment\\nwhen using the CreateDefaultBuilder method in Program.cs.\\n\\nUse Azure Key Vault to pro\", \"tect secrets at production\\ntime\\nSecrets stored as environment variables or stored by the Secret Mana\", \"ger tool are still stored locally\\n\\nand unencrypted on the machine. A more secure option for storing \", \"secrets is Azure Key Vault, which\\nprovides a secure, central location for storing keys and secrets.\\n\", \"\\nThe Azure.Extensions.AspNetCore.Configuration.Secrets package allows an ASP.NET Core\\napplication to\", \" read configuration information from Azure Key Vault. To start using secrets from an\\nAzure Key Vault\", \", you follow these steps:\\n\\n1. Register your application as an Azure AD application. (Access to key v\", \"aults is managed by\\nAzure AD.) This can be done through the Azure management portal.\\n\\nAlternatively,\", \" if you want your application to authenticate using a certificate instead of a\\npassword or client se\", \"cret, you can use the New-AzADApplication PowerShell cmdlet. The\\ncertificate that you register with \", \"Azure Key Vault needs only your public key. Your application\\nwill use the private key.\\n\\n2. Give the \", \"registered application access to the key vault by creating a new service principal. You\\ncan do this \", \"using the following PowerShell commands:\\n\\n$sp = New-AzADServicePrincipal -ApplicationId \\\"<Applicatio\", \"n ID guid>\\\"\\nSet-AzKeyVaultAccessPolicy -VaultName \\\"<VaultName>\\\" -ServicePrincipalName\\n\\n$sp.ServicePr\", \"incipalNames[@] -PermissionsToSecrets all -ResourceGroupName \\\"<KeyVault\\nResource Group>\\\"\\n\\n3. Include\", \" the key vault as a configuration source in your application by calling the\\nAzureKeyVaultConfigurati\", \"onExtensions.AddAzureKeyVault extension method when you create\\n\\nan IConfigurationRoot instance.\\n\\nNot\", \"e that calling AddAzureKeyVault requires the application ID that was registered and given access\\nto \", \"the key vault in the previous steps. Or you can firstly running the Azure CLI command: az login,\\nthe\", \"n using an overload of AddAzureKeyVault that takes a DefaultAzureCredential in place of the\\nclient.\\n\", \"\\n332 CHAPTER 8 | Make secure .NET Microservices and Web Applications\\nImportant\\n\\nWe recommend that yo\", \"u register Azure Key Vault as the last configuration provider, so it can override\\nconfiguration valu\", \"es from previous providers.\\n\\nAdditional resources\\n\\n. Using Azure Key Vault to protect application se\", \"crets\\n\\nhttps://learn.microsoft.com/azure/architecture/multitenant-identity\\n\\n. Safe storage of app se\", \"crets during development\\n\\nhttps://learn.microsoft.com/aspnet/core/security/app-secrets\\n\\n. Configurin\", \"g data protection\\n\\nhttps://learn.microsoft.com/aspnet/core/security/data-protection/configuration/ov\", \"erview\\n\\n. Data Protection key management and lifetime in ASP.NET Core\\n\\nhttps://learn.microsoft.com/a\", \"spnet/core/security/data-protection/configuration/default-\\nsettings\\n\\n333 CHAPTER 8 | Make secure .NE\", \"T Microservices and Web Applications\\nCHAPTER\\n\\nNe? Microservices\\nArchitecture key takeaways\\n\\nAs a sum\", \"mary and key takeaways, the following are the most important conclusions from this guide.\\n\\nBenefits \", \"of using containers. Container-based solutions provide important cost savings because\\nthey help redu\", \"ce deployment problems caused by failing dependencies in production environments.\\nContainers signifi\", \"cantly improve DevOps and production operations.\\n\\nContainers will be ubiquitous. Docker-based contai\", \"ners are becoming the de facto standard in the\\nindustry, supported by key vendors in the Windows and\", \" Linux ecosystems, such as Microsoft, Amazon\\nAWS, Google, and IBM. Docker will probably soon be ubiq\", \"uitous in both the cloud and on-premises\\ndatacenters.\\n\\nContainers as a unit of deployment. A Docker \", \"container is becoming the standard unit of\\ndeployment for any server-based application or service.\\n\\n\", \"Microservices. The microservices architecture is becoming the preferred approach for distributed and\", \"\\nlarge or complex mission-critical applications based on many independent subsystems in the form of\\n\", \"autonomous services. In a microservice-based architecture, the application is built as a collection \", \"of\\nservices that are developed, tested, versioned, deployed, and scaled independently. Each service \", \"can\\ninclude any related autonomous database.\\n\\nDomain-driven design and SOA. The microservices archit\", \"ecture patterns derive from service-\\noriented architecture (SOA) and domain-driven design (DDD). Whe\", \"n you design and develop\\nmicroservices for environments with evolving business needs and rules, it's\", \" important to consider DDD\\napproaches and patterns.\\n\\nMicroservices challenges. Microservices offer m\", \"any powerful capabilities, like independent\\ndeployment, strong subsystem boundaries, and technology \", \"diversity. However, they also raise many\\nnew challenges related to distributed application developme\", \"nt, such as fragmented and independent\\ndata models, resilient communication between microservices, e\", \"ventual consistency, and operational\\ncomplexity that results from aggregating logging and monitoring\", \" information from multiple\\nmicroservices. These aspects introduce a much higher complexity level tha\", \"n a traditional monolithic\\napplication. As a result, only specific scenarios are suitable for micros\", \"ervice-based applications. These\\ninclude large and complex applications with multiple evolving subsy\", \"stems. In these cases, it\\u2019s worth\\ninvesting in a more complex software architecture, because it will\", \" provide better long-term agility and\\napplication maintenance.\\n\\n334 CHAPTER 9 | .NET Microservices A\", \"rchitecture key takeaways\\nContainers for any application. Containers are convenient for microservice\", \"s, but can also be useful\\nfor monolithic applications based on the traditional .NET Framework, when \", \"using Windows\\nContainers. The benefits of using Docker, such as solving many deployment-to-productio\", \"n issues and\\nproviding state-of-the-art Dev and Test environments, apply to many different types of \", \"applications.\\n\\nCLI versus IDE. With Microsoft tools, you can develop containerized .NET applications\", \" using your\\npreferred approach. You can develop with a CLI and an editor-based environment by using \", \"the Docker\\nCLI and Visual Studio Code. Or you can use an IDE-focused approach with Visual Studio and\", \" its unique\\nfeatures for Docker, such as multi-container debugging.\\n\\nResilient cloud applications. |\", \"n cloud-based systems and distributed systems in general, there is\\nalways the risk of partial failur\", \"e. Since clients and services are separate processes (containers), a\\nservice might not be able to re\", \"spond in a timely way to a client's request. For example, a service might\\nbe down because of a parti\", \"al failure or for maintenance; the service might be overloaded and\\nresponding slowly to requests; or\", \" it might not be accessible for a short time because of network\\nissues. Therefore, a cloud-based app\", \"lication must embrace those failures and have a strategy in place\\nto respond to those failures. Thes\", \"e strategies can include retry policies (resending messages or\\nretrying requests) and implementing c\", \"ircuit-breaker patterns to avoid exponential load of repeated\\nrequests. Basically, cloud-based appli\", \"cations must have resilient mechanisms\\u2014either based on cloud\\ninfrastructure or custom, as the high-l\", \"evel ones provided by orchestrators or service buses.\\n\\nSecurity. Our modern world of containers and \", \"microservices can expose new vulnerabilities. There are\\nseveral ways to implement basic application \", \"security, based on authentication and authorization.\\nHowever, container security must consider addit\", \"ional key components that result in inherently safer\\napplications. A critical element of building sa\", \"fer apps is having a secure way of communicating with\\nother apps and systems, something that often r\", \"equires credentials, tokens, passwords, and the like,\\ncommonly referred to as application secrets. A\", \"ny secure solution must follow security best practices,\\nsuch as encrypting secrets while in transit \", \"and at rest, and preventing secrets from leaking when\\nconsumed by the final application. Those secre\", \"ts need to be stored and kept safely, as when using\\nAzure Key Vault.\\n\\nOrchestrators. Container-based\", \" orchestrators, such as Azure Kubernetes Service and Azure Service\\nFabric are key part of any signif\", \"icant microservice and container-based application. These applications\\ncarry with them high complexi\", \"ty, scalability needs, and go through constant evolution. This guide has\\nintroduced orchestrators an\", \"d their role in microservice-based and container-based solutions. If your\\napplication needs are movi\", \"ng you toward complex containerized apps, you will find it useful to seek\\nout additional resources f\", \"or learning more about orchestrators.\\n\\n335 CHAPTER 9 | .NET Microservices Architecture key takeaways\", \"\\n\"]"