"[\"EDITION v7.0 - Updated to ASP.NET Core 7.0\\nRefer changelog for the book updates and community contri\", \"butions.\\nThis guide is an introduction to developing microservices-based applications and managing t\", \"hem\\nusing containers. It discusses architectural design and implementation approaches using .NET and\", \"\\nDocker containers.\\nTo make it easier to get started, the guide focuses on a reference containerized\", \" and microservice-\\nbased application that you can explore. The reference application is available at\", \" the\\neShopOnContainers GitHub repo.\\nAction links\\n\\u2022 This e-book is also available in a PDF format (En\", \"glish version only) Download\\n\\u2022 Clone/Fork the reference application eShopOnContainers on GitHub\\n\\u2022 Wa\", \"tch the introductory video\\n\\u2022 Get to know the Microservices Architecture right away\\nIntroduction\\nEnte\", \"rprises are increasingly realizing cost savings, solving deployment problems, and improving\\nDevOps a\", \"nd production operations by using containers. Microsoft has been releasing container\\ninnovations for\", \" Windows and Linux by creating products like Azure Kubernetes Service and Azure\\nService Fabric, and \", \"by partnering with industry leaders like Docker, Mesosphere, and Kubernetes.\\nThese products deliver \", \"container solutions that help companies build and deploy applications at cloud\\nspeed and scale, what\", \"ever their choice of platform or tools.\\nDocker is becoming the de facto standard in the container in\", \"dustry, supported by the most significant\\nvendors in the Windows and Linux ecosystems. (Microsoft is\", \" one of the main cloud vendors\\nsupporting Docker). In the future, Docker will probably be ubiquitous\", \" in any datacenter in the cloud or\\non-premises.\\nIn addition, the microservices architecture is emerg\", \"ing as an important approach for distributed\\nmission-critical applications. In a microservice-based \", \"architecture, the application is built on a\\ncollection of services that can be developed, tested, de\", \"ployed, and versioned independently.\\nAbout this guide\\nThis guide is an introduction to developing mi\", \"croservices-based applications and managing them\\nusing containers. It discusses architectural design\", \" and implementation approaches using .NET and\\nDocker containers. To make it easier to get started wi\", \"th containers and microservices, the guide\\nfocuses on a reference containerized and microservice-bas\", \"ed application that you can explore. The\\nsample application is available at the eShopOnContainers Gi\", \"tHub repo.This guide provides foundational development and architectural guidance primarily at a dev\", \"elopment\\nenvironment level with a focus on two technologies: Docker and .NET. Our intention is that \", \"you read\\nthis guide when thinking about your application design without focusing on the infrastructu\", \"re (cloud\\nor on-premises) of your production environment. You will make decisions about your infrast\", \"ructure\\nlater, when you create your production-ready applications. Therefore, this guide is intended\", \" to be\\ninfrastructure agnostic and more development-environment-centric.\\nAfter you have studied this\", \" guide, your next step would be to learn about production-ready\\nmicroservices on Microsoft Azure.\\nVe\", \"rsion\\nThis guide has been revised to cover .NET 7 version along with many additional updates related\", \" to\\nthe same \\u201cwave\\u201d of technologies (that is, Azure and additional third-party technologies) coincid\", \"ing in\\ntime with the .NET 7 release. That\\u2019s why the book version has also been updated to version 7.\", \"0.\\nWhat this guide does not cover\\nThis guide does not focus on the application lifecycle, DevOps, CI\", \"/CD pipelines, or team work. The\\ncomplementary guide Containerized Docker Application Lifecycle with\", \" Microsoft Platform and Tools\\nfocuses on that subject. The current guide also does not provide imple\", \"mentation details on Azure\\ninfrastructure, such as information on specific orchestrators.\\nAdditional\", \" resources\\n\\u2022 Containerized Docker Application Lifecycle with Microsoft Platform and Tools (downloada\", \"ble\\ne-book)\\nhttps://aka.ms/dockerlifecycleebook\\nWho should use this guide\\nWe wrote this guide for de\", \"velopers and solution architects who are new to Docker-based application\\ndevelopment and to microser\", \"vices-based architecture. This guide is for you if you want to learn how\\nto architect, design, and i\", \"mplement proof-of-concept applications with Microsoft development\\ntechnologies (with special focus o\", \"n .NET) and with Docker containers.\\nYou will also find this guide useful if you are a technical deci\", \"sion maker, such as an enterprise\\narchitect, who wants an architecture and technology overview befor\", \"e you decide on what approach to\\nselect for new and modern distributed applications.\\nHow to use this\", \" guide\\nThe first part of this guide introduces Docker containers, discusses how to choose between .N\", \"ET 7 and\\nthe .NET Framework as a development framework, and provides an overview of microservices. T\", \"his\\ncontent is for architects and technical decision makers who want an overview but don\\u2019t need to f\", \"ocus\\non code implementation details.The second part of the guide starts with the Development process\", \" for Docker based applications\\nsection. It focuses on the development and microservice patterns for \", \"implementing applications using\\n.NET and Docker. This section will be of most interest to developers\", \" and architects who want to focus\\non code and on patterns and implementation details.\\nRelated micros\", \"ervice and container-based reference\\napplication: eShopOnContainers\\nThe eShopOnContainers applicatio\", \"n is an open-source reference app for .NET and microservices that\\nis designed to be deployed using D\", \"ocker containers. The application consists of multiple subsystems,\\nincluding several e-store UI fron\", \"t-ends (a Web MVC app, a Web SPA, and a native mobile app). It also\\nincludes the back-end microservi\", \"ces and containers for all required server-side operations.\\nThe purpose of the application is to sho\", \"wcase architectural patterns. IT IS NOT A PRODUCTION-\\nREADY TEMPLATE to start real-world application\", \"s. In fact, the application is in a permanent beta\\nstate, as it\\u2019s also used to test new potentially \", \"interesting technologies as they show up.\\nCredits\\nCo-Authors:\\nCesar de la Torre, Sr. PM, .NET produc\", \"t team, Microsoft Corp.\\nBill Wagner, Sr. Content Developer, C+E, Microsoft Corp.\\nMike Rousos, Princi\", \"pal Software Engineer, DevDiv CAT team, Microsoft\\nEditors:\\nMike Pope\\nSteve Hoag\\nParticipants and rev\", \"iewers:\\nJeffrey Richter, Partner Software Eng, Azure team, Microsoft\\nJimmy Bogard, Chief Architect a\", \"t Headspring\\nUdi Dahan, Founder & CEO, Particular Software\\nJimmy Nilsson, Co-founder and CEO of Fact\", \"or10\\nGlenn Condron, Sr. Program Manager, ASP.NET team\\nMark Fussell, Principal PM Lead, Azure Service\", \" Fabric team, Microsoft\\nDiego Vega, PM Lead, Entity Framework team, Microsoft\\nBarry Dorrans, Sr. Sec\", \"urity Program Manager\\nRowan Miller, Sr. Program Manager, MicrosoftAnkit Asthana, Principal PM Manage\", \"r, .NET team, Microsoft\\nScott Hunter, Partner Director PM, .NET team, Microsoft\\nNish Anil, Sr. Progr\", \"am Manager, .NET team, Microsoft\\nDylan Reisenberger, Architect and Dev Lead at Polly\\nSteve \\u201cardalis\\u201d\", \" Smith - Software Architect and Trainer - Ardalis.com\\nIan Cooper, Coding Architect at Brighter\\nUnai \", \"Zorrilla, Architect and Dev Lead at Plain Concepts\\nEduard Tomas, Dev Lead at Plain Concepts\\nRamon To\", \"mas, Developer at Plain Concepts\\nDavid Sanz, Developer at Plain Concepts\\nJavier Valero, Chief Operat\", \"ing Officer at Grupo Solutio\\nPierre Millet, Sr. Consultant, Microsoft\\nMichael Friis, Product Manager\", \", Docker Inc\\nCharles Lowell, Software Engineer, VS CAT team, Microsoft\\nMiguel Veloso, Software Devel\", \"opment Engineer at Plain Concepts\\nSumit Ghosh, Principal Consultant at Neudesic\\nCopyright\\nPUBLISHED \", \"BY\\nMicrosoft Developer Division, .NET and Visual Studio product teams\\nA division of Microsoft Corpor\", \"ation\\nOne Microsoft Way\\nRedmond, Washington 98052-6399\\nCopyright \\u00a9 2023 by Microsoft Corporation\\nAll\", \" rights reserved. No part of the contents of this book may be reproduced or transmitted in any\\nform \", \"or by any means without the written permission of the publisher.\\nThis book is provided \\u201cas-is\\u201d and e\", \"xpresses the author\\u2019s views and opinions. The views, opinions and\\ninformation expressed in this book\", \", including URL and other Internet website references, may change\\nwithout notice.\\nSome examples depi\", \"cted herein are provided for illustration only and are fictitious. No real association\\nor connection\", \" is intended or should be inferred.Microsoft and the trademarks listed at https://www.microsoft.com \", \"on the \\u201cTrademarks\\u201d webpage are\\ntrademarks of the Microsoft group of companies.\\nMac and macOS are tr\", \"ademarks of Apple Inc.\\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permi\", \"ssion.\\nAll other marks and logos are property of their respective owners.Contents\\nIntroduction to Co\", \"ntainers and Docker ................................................................................\", \" 1\\nWhat is Docker? .................................................................................\", \"....................................................................................... 2\\nComparing \", \"Docker containers with virtual machines ............................................................\", \"............................... 3\\nA simple analogy .................................................\", \"....................................................................................................\", \"............ 4\\nDocker terminology ..................................................................\", \".............................................................................................. 5\\nDoc\", \"ker containers, images, and registries .............................................................\", \"........................................................ 7\\nChoosing Between .NET and .NET Framework \", \"for Docker Containers .............................. 9\\nGeneral guidance ............................\", \"....................................................................................................\", \"..................................... 9\\nWhen to choose .NET for Docker containers ..................\", \"........................................................................................... 10\\nDevel\", \"oping and deploying cross platform .................................................................\", \"........................................... 10\\nUsing containers for new (\\u201cgreen-field\\u201d) projects ...\", \"............................................................................................ 11\\nCrea\", \"te and deploy microservices on containers ..........................................................\", \"........................................ 11\\nDeploying high density in scalable systems .............\", \"............................................................................................. 11\\nWhe\", \"n to choose .NET Framework for Docker containers ...................................................\", \".................................. 12\\nMigrating existing applications directly to a Windows Server c\", \"ontainer .................................................. 12\\nUsing third-party .NET libraries or N\", \"uGet packages not available for .NET 7 ......................................... 12\\nUsing .NET techn\", \"ologies not available for .NET 7 ...................................................................\", \"............................ 12\\nUsing a platform or API that doesn\\u2019t support .NET 7 ................\", \"........................................................................ 13\\nPorting existing ASP.NET\", \" application to .NET 7 .............................................................................\", \"...................... 13\\nDecision table: .NET implementations to use for Docker ...................\", \".................................................................. 13\\nWhat OS to target with .NET co\", \"ntainers ...........................................................................................\", \"........................... 14\\nOfficial .NET Docker images .........................................\", \"....................................................................................................\", \" 16\\n.NET and Docker image optimizations for development versus production ..........................\", \"................. 16\\nArchitecting container and microservice-based applications ....................\", \"...................... 18\\nContainer design principles ..............................................\", \"................................................................................................ 18\\n\", \"Containerizing monolithic applications .............................................................\", \".......................................................... 19\\nDeploying a monolithic application as \", \"a container ........................................................................................\", \".... 21\\nPublishing a single-container-based application to Azure App Service .......................\", \"............................. 21\\ni ContentsManage state and data in Docker applications ............\", \"............................................................................................ 22\\nServ\", \"ice-oriented architecture ..........................................................................\", \"................................................................. 25\\nMicroservices architecture ....\", \"....................................................................................................\", \"......................................... 25\\nAdditional resources ..................................\", \"....................................................................................................\", \"................. 27\\nData sovereignty per microservice .............................................\", \"................................................................................... 27\\nThe relations\", \"hip between microservices and the Bounded Context pattern ..........................................\", \". 29\\nLogical architecture versus physical architecture .............................................\", \"........................................................ 30\\nChallenges and solutions for distributed\", \" data management .............................................................................. 31\\nC\", \"hallenge #1: How to define the boundaries of each microservice .....................................\", \"....................... 31\\nChallenge #2: How to create queries that retrieve data from several micro\", \"services ............................ 32\\nChallenge #3: How to achieve consistency across multiple mi\", \"croservices ............................................... 33\\nChallenge #4: How to design communica\", \"tion across microservice boundaries .................................... 35\\nAdditional resources ...\", \"....................................................................................................\", \"................................................ 36\\nIdentify domain-model boundaries for each micros\", \"ervice .................................................................................. 36\\nThe API\", \" gateway pattern versus the Direct client-to-microservice communication ............................\", \"...... 40\\nDirect client-to-microservice communication ..............................................\", \"........................................................ 40\\nWhy consider API Gateways instead of dir\", \"ect client-to-microservice communication ....................... 41\\nWhat is the API Gateway pattern?\", \" ...................................................................................................\", \".......................... 42\\nMain features in the API Gateway pattern .............................\", \"................................................................................ 44\\nUsing products w\", \"ith API Gateway features ...........................................................................\", \"................................. 45\\nDrawbacks of the API Gateway pattern ..........................\", \"......................................................................................... 47\\nAdditio\", \"nal resources ......................................................................................\", \"................................................................. 48\\nCommunication in a microservice\", \" architecture ......................................................................................\", \".................. 48\\nCommunication types ..........................................................\", \".......................................................................................... 49\\nAsynch\", \"ronous microservice integration enforces microservice\\u2019s autonomy ...................................\", \"........ 50\\nCommunication styles ...................................................................\", \"................................................................................. 52\\nAsynchronous me\", \"ssage-based communication ..........................................................................\", \"............................. 54\\nSingle-receiver message-based communication .......................\", \"......................................................................... 55\\nMultiple-receivers mess\", \"age-based communication ............................................................................\", \".............. 56\\nAsynchronous event-driven communication ..........................................\", \".............................................................. 56\\nA note about messaging technologie\", \"s for production systems ................................................................... 57\\nResi\", \"liently publishing to the event bus ................................................................\", \"................................................... 58\\nii ContentsAdditional resources .............\", \"....................................................................................................\", \"...................................... 58\\nCreating, evolving, and versioning microservice APIs and c\", \"ontracts ............................................................... 59\\nAdditional resources ...\", \"....................................................................................................\", \"................................................ 59\\nMicroservices addressability and the service reg\", \"istry ............................................................................................ 6\", \"0\\nAdditional resources .............................................................................\", \".......................................................................... 60\\nCreating composite UI \", \"based on microservices .............................................................................\", \".......................... 60\\nAdditional resources .................................................\", \"....................................................................................................\", \".. 62\\nResiliency and high availability in microservices ............................................\", \".......................................................... 63\\nHealth management and diagnostics in m\", \"icroservices .................................................................................... 63\", \"\\nAdditional resources ..............................................................................\", \"......................................................................... 65\\nOrchestrate microservic\", \"es and multi-container applications for high scalability and availability ....... 66\\nSoftware platfo\", \"rms for container clustering, orchestration, and scheduling ........................................\", \"... 68\\nUsing container-based orchestrators in Microsoft Azure ......................................\", \".......................................... 68\\nUsing Azure Kubernetes Service .......................\", \"....................................................................................................\", \"..... 69\\nDevelopment environment for Kubernetes ....................................................\", \"....................................................... 70\\nGetting started with Azure Kubernetes Ser\", \"vice (AKS) ....................................................................................... 7\", \"0\\nDeploy with Helm charts into Kubernetes clusters .................................................\", \"............................................ 71\\nAdditional resources ...............................\", \"....................................................................................................\", \".................... 71\\nDevelopment process for Docker-based applications ..........................\", \"............................. 72\\nDevelopment environment for Docker apps ...........................\", \".................................................................................. 72\\nDevelopment to\", \"ol choices: IDE or editor ..........................................................................\", \"...................................... 72\\nAdditional resources .....................................\", \"....................................................................................................\", \".............. 73\\n.NET languages and frameworks for Docker containers ..............................\", \"......................................................... 73\\nDevelopment workflow for Docker apps ..\", \"....................................................................................................\", \"............... 73\\nWorkflow for developing Docker container-based applications .....................\", \"............................................. 73\\nStep 1. Start coding and create your initial applic\", \"ation or service baseline ............................................. 75\\nStep 2. Create a Dockerfi\", \"le related to an existing .NET base image ..........................................................\", \".. 76\\nStep 3. Create your custom Docker images and embed your application or service in them .......\", \"... 83\\nStep 4. Define your services in docker-compose.yml when building a multi-container Docker\\napp\", \"lication ...........................................................................................\", \"............................................................................... 84\\nStep 5. Build and\", \" run your Docker application .......................................................................\", \"............................. 87\\nStep 6. Test your Docker application using your local Docker host .\", \"........................................................... 89\\niii ContentsSimplified workflow when \", \"developing containers with Visual Studio ........................................................ 90\", \"\\nUsing PowerShell commands in a Dockerfile to set up Windows Containers ............................\", \"............. 91\\nDesigning and Developing Multi-Container and Microservice-Based .NET Applications\\n.\", \"....................................................................................................\", \"............................................ 93\\nDesign a microservice-oriented application .........\", \"....................................................................................................\", \". 93\\nApplication specifications ....................................................................\", \"......................................................................... 93\\nDevelopment team contex\", \"t ..................................................................................................\", \"....................................... 94\\nChoosing an architecture ................................\", \"....................................................................................................\", \".......... 94\\nBenefits of a microservice-based solution ............................................\", \"................................................................. 97\\nDownsides of a microservice-bas\", \"ed solution ........................................................................................\", \"............... 98\\nExternal versus internal architecture and design patterns........................\", \"....................................................... 99\\nThe new world: multiple architectural pat\", \"terns and polyglot microservices .......................................... 100\\nCreating a simple da\", \"ta-driven CRUD microservice ........................................................................\", \"....................... 102\\nDesigning a simple CRUD microservice ...................................\", \"............................................................................. 102\\nImplementing a sim\", \"ple CRUD microservice with ASP.NET Core ............................................................\", \"..... 103\\nThe DB connection string and environment variables used by Docker containers .............\", \"................ 109\\nGenerating Swagger description metadata from your ASP.NET Core Web API ........\", \"........................... 111\\nDefining your multi-container application with docker-compose.yml ..\", \"....................................................... 116\\nUse a database server running as a conta\", \"iner ...............................................................................................\", \"......... 127\\nSQL Server running as a container with a microservice-related database ...............\", \"............................... 128\\nSeeding with test data on Web application startup ..............\", \"........................................................................... 129\\nEF Core InMemory dat\", \"abase versus SQL Server running as a container ................................................. 132\", \"\\nUsing a Redis cache service running in a container ................................................\", \"......................................... 132\\nImplementing event-based communication between microse\", \"rvices (integration events) ................... 133\\nUsing message brokers and service buses for prod\", \"uction systems .......................................................... 134\\nIntegration events ...\", \"....................................................................................................\", \"................................................... 135\\nThe event bus ..............................\", \"....................................................................................................\", \"................................ 136\\nAdditional resources ..........................................\", \"....................................................................................................\", \"....... 138\\nImplementing an event bus with RabbitMQ for the development or test environment ........\", \"............... 138\\nImplementing a simple publish method with RabbitMQ .............................\", \".................................................. 139\\nImplementing the subscription code with the R\", \"abbitMQ API ..................................................................... 140\\nAdditional res\", \"ources .............................................................................................\", \"........................................................ 141\\niv ContentsSubscribing to events ......\", \"....................................................................................................\", \".............................................. 141\\nPublishing events through the event bus..........\", \"................................................................................................... \", \"142\\nIdempotency in update message events ...........................................................\", \"................................................... 149\\nDeduplicating integration event messages ...\", \"....................................................................................................\", \".. 150\\nTesting ASP.NET Core services and web apps ..................................................\", \"...................................................... 152\\nTesting in eShopOnContainers ............\", \"....................................................................................................\", \"................. 155\\nImplement background tasks in microservices with IHostedService and the Backgr\", \"oundService class\\n..................................................................................\", \"....................................................................................................\", \".............. 157\\nRegistering hosted services in your WebHost or Host .............................\", \"...................................................... 159\\nThe IHostedService interface ............\", \"....................................................................................................\", \"..................... 159\\nImplementing IHostedService with a custom hosted service class deriving fr\", \"om the\\nBackgroundService base class.................................................................\", \".................................................................. 160\\nAdditional resources ........\", \"....................................................................................................\", \"......................................... 163\\nImplement API Gateways with Ocelot ...................\", \"....................................................................................................\", \". 163\\nArchitect and design your API Gateways .......................................................\", \"....................................................... 163\\nImplementing your API Gateways with Ocel\", \"ot .................................................................................................\", \". 168\\nUsing Kubernetes Ingress plus Ocelot API Gateways ............................................\", \".......................................... 180\\nAdditional cross-cutting features in an Ocelot API Ga\", \"teway ....................................................................... 181\\nTackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patterns .............. 182\\nApply simplified CQRS and D\", \"DD patterns in a microservice.......................................................................\", \"...... 184\\nAdditional resources ....................................................................\", \"................................................................................. 186\\nApply CQRS and\", \" CQS approaches in a DDD microservice in eShopOnContainers ................................. 186\\nCQR\", \"S and DDD patterns are not top-level architectures .................................................\", \".............................. 187\\nImplement reads/queries in a CQRS microservice ..................\", \".............................................................................. 188\\nUse ViewModels sp\", \"ecifically made for client apps, independent from domain model constraints\\n.........................\", \"....................................................................................................\", \".................................................................. 189\\nUse Dapper as a micro ORM to \", \"perform queries ....................................................................................\", \".......... 189\\nDynamic versus static ViewModels ....................................................\", \"..................................................................... 190\\nAdditional resources .....\", \"....................................................................................................\", \"............................................ 193\\nDesign a DDD-oriented microservice ................\", \"....................................................................................................\", \"..... 194\\nKeep the microservice context boundaries relatively small ................................\", \".......................................... 194\\nLayers in DDD microservices .........................\", \"....................................................................................................\", \"........ 195\\nv ContentsDesign a microservice domain model ..........................................\", \".............................................................................. 199\\nThe Domain Entity\", \" pattern ...........................................................................................\", \".............................................. 199\\nImplement a microservice domain model with .NET .\", \"........................................................................................... 204\\nDoma\", \"in model structure in a custom .NET Standard Library ...............................................\", \"........................ 204\\nStructure aggregates in a custom .NET Standard library ................\", \"............................................................... 205\\nImplement domain entities as POC\", \"O classes ..........................................................................................\", \"........... 206\\nEncapsulate data in the Domain Entities ............................................\", \".................................................................. 207\\nSeedwork (reusable base class\", \"es and interfaces for your domain model) .................................................. 210\\nThe \", \"custom Entity base class ...........................................................................\", \".......................................................... 211\\nRepository contracts (interfaces) in \", \"the domain model layer ...................................................................... 212\\nAd\", \"ditional resources .................................................................................\", \".................................................................... 213\\nImplement value objects ...\", \"....................................................................................................\", \"........................................... 213\\nImportant characteristics of value objects .........\", \".................................................................................................. 2\", \"14\\nValue object implementation in C# ...............................................................\", \"......................................................... 215\\nHow to persist value objects in the da\", \"tabase with EF Core 2.0 and later ................................................ 217\\nPersist value\", \" objects as owned entity types in EF Core 2.0 and later ............................................\", \"............ 218\\nAdditional resources ..............................................................\", \"....................................................................................... 221\\nUse enum\", \"eration classes instead of enum types ..............................................................\", \"..................................... 221\\nImplement an Enumeration base class ......................\", \"............................................................................................ 222\\nAdd\", \"itional resources ..................................................................................\", \"................................................................... 223\\nDesign validations in the do\", \"main model layer ...................................................................................\", \".................... 223\\nImplement validations in the domain model layer ...........................\", \"................................................................ 224\\nAdditional resources ..........\", \"....................................................................................................\", \"....................................... 225\\nClient-side validation (validation in the presentation l\", \"ayers) ............................................................................ 226\\nAdditional r\", \"esources ...........................................................................................\", \".......................................................... 227\\nDomain events: Design and implementat\", \"ion ................................................................................................\", \".......... 227\\nWhat is a domain event? .............................................................\", \"................................................................................ 228\\nDomain events v\", \"ersus integration events ...........................................................................\", \"................................. 228\\nDomain events as a preferred way to trigger side effects acros\", \"s multiple aggregates within the\\nsame domain .......................................................\", \"....................................................................................................\", \"........ 229\\nImplement domain events ...............................................................\", \"........................................................................... 231\\nConclusions on domai\", \"n events ...........................................................................................\", \"...................................... 237\\nvi ContentsAdditional resources .........................\", \"....................................................................................................\", \"........................ 238\\nDesign the infrastructure persistence layer ...........................\", \"................................................................................... 238\\nThe Reposito\", \"ry pattern .........................................................................................\", \"....................................................... 238\\nAdditional resources ...................\", \"....................................................................................................\", \".............................. 243\\nImplement the infrastructure persistence layer with Entity Framew\", \"ork Core ............................................ 243\\nIntroduction to Entity Framework Core ....\", \"....................................................................................................\", \"......... 244\\nInfrastructure in Entity Framework Core from a DDD perspective .......................\", \"...................................... 244\\nImplement custom repositories with Entity Framework Core \", \"...................................................................... 246\\nEF DbContext and IUnitOfW\", \"ork instance lifetime in your IoC container ................................................. 248\\nTh\", \"e repository instance lifetime in your IoC container ...............................................\", \".................................... 249\\nTable mapping .............................................\", \"....................................................................................................\", \"............... 250\\nImplement the Query Specification pattern ......................................\", \".................................................................. 253\\nUse NoSQL databases as a pers\", \"istence infrastructure .............................................................................\", \"............ 255\\nIntroduction to Azure Cosmos DB and the native Cosmos DB API ......................\", \"..................................... 256\\nImplement .NET code targeting MongoDB and Azure Cosmos DB \", \".......................................................... 258\\nDesign the microservice application l\", \"ayer and Web API ...................................................................................\", \". 266\\nUse SOLID principles and Dependency Injection ................................................\", \".............................................. 266\\nImplement the microservice application layer usin\", \"g the Web API ................................................................. 267\\nUse Dependency I\", \"njection to inject infrastructure objects into your application layer ..................... 267\\nImpl\", \"ement the Command and Command Handler patterns .....................................................\", \".................. 271\\nThe Command process pipeline: how to trigger a command handler ..............\", \"....................................... 278\\nImplement the command process pipeline with a mediator p\", \"attern (MediatR) .................................. 281\\nApply cross-cutting concerns when processing\", \" commands with the Behaviors in MediatR .......... 287\\nImplement resilient applications ............\", \"........................................................................... 291\\nHandle partial failu\", \"re .................................................................................................\", \"........................................................ 292\\nStrategies to handle partial failure ..\", \"....................................................................................................\", \"......................... 294\\nAdditional resources .................................................\", \"....................................................................................................\", \" 295\\nImplement retries with exponential backoff ....................................................\", \"........................................................ 295\\nImplement resilient Entity Framework Co\", \"re SQL connections.......................................................................... 295\\nExe\", \"cution strategies and explicit transactions using BeginTransaction and multiple DbContexts296\\nAdditi\", \"onal resources .....................................................................................\", \"................................................................ 298\\nUse IHttpClientFactory to imple\", \"ment resilient HTTP requests .......................................................................\", \".. 298\\nvii ContentsIssues with the original HttpClient class available in .NET .....................\", \"........................................................ 298\\nBenefits of using IHttpClientFactory ..\", \"....................................................................................................\", \"................. 299\\nMultiple ways to use IHttpClientFactory ......................................\", \"......................................................................... 300\\nHow to use Typed Clien\", \"ts with IHttpClientFactory .........................................................................\", \".................. 300\\nAdditional resources ........................................................\", \"............................................................................................. 304\\nIm\", \"plement HTTP call retries with exponential backoff with IHttpClientFactory and Polly policies ... 30\", \"4\\nAdd a jitter strategy to the retry policy ........................................................\", \"......................................................... 305\\nAdditional resources .................\", \"....................................................................................................\", \"................................ 306\\nImplement the Circuit Breaker pattern .........................\", \".............................................................................................. 306\\nI\", \"mplement Circuit Breaker pattern with IHttpClientFactory and Polly .................................\", \".................... 307\\nTest Http retries and circuit breakers in eShopOnContainers ...............\", \"....................................................... 308\\nAdditional resources ...................\", \"....................................................................................................\", \".............................. 310\\nHealth monitoring ...............................................\", \"....................................................................................................\", \"........... 310\\nImplement health checks in ASP.NET Core services ...................................\", \"..................................................... 311\\nUse watchdogs ............................\", \"....................................................................................................\", \"................................ 315\\nHealth checks when using orchestrators ........................\", \"...................................................................................... 317\\nAdvanced \", \"monitoring: visualization, analysis, and alerts ....................................................\", \"........................... 317\\nAdditional resources ...............................................\", \"....................................................................................................\", \".. 318\\nMake secure .NET Microservices and Web Applications .........................................\", \"........ 319\\nImplement authentication in .NET microservices and web applications ...................\", \"................................... 319\\nAuthenticate with ASP.NET Core Identity ....................\", \"......................................................................................... 320\\nAuthen\", \"ticate with external providers .....................................................................\", \"................................................ 321\\nAuthenticate with bearer tokens ...............\", \"....................................................................................................\", \"........... 323\\nAuthenticate with an OpenID Connect or OAuth 2.0 Identity provider .................\", \".................................. 324\\nIssue security tokens from an ASP.NET Core service ..........\", \"............................................................................. 325\\nConsume security t\", \"okens ..............................................................................................\", \".............................................. 326\\nAdditional resources ............................\", \"....................................................................................................\", \".......................... 327\\nAbout authorization in .NET microservices and web applications ......\", \"............................................................ 327\\nImplement role-based authorization \", \"....................................................................................................\", \"................. 328\\nImplement policy-based authorization .........................................\", \"........................................................................ 329\\nAuthorization and minim\", \"al apis ............................................................................................\", \"................................... 330\\nAdditional resources .......................................\", \"....................................................................................................\", \".......... 330\\nviii ContentsStore application secrets safely during development ....................\", \"...................................................................... 330\\nStore secrets in environm\", \"ent variables ......................................................................................\", \"........................... 331\\nStore secrets with the ASP.NET Core Secret Manager .................\", \"................................................................... 331\\nUse Azure Key Vault to prote\", \"ct secrets at production time ......................................................................\", \"........ 332\\nAdditional resources ..................................................................\", \"................................................................................... 333\\n.NET Microse\", \"rvices Architecture key takeaways .............................................................. 334\", \"\\nix Contents1\\nCHAPTER\\nIntroduction to Containers\\nand Docker\\nContainerization is an approach to softw\", \"are development in which an application or service, its\\ndependencies, and its configuration (abstrac\", \"ted as deployment manifest files) are packaged together\\nas a container image. The containerized appl\", \"ication can be tested as a unit and deployed as a\\ncontainer image instance to the host operating sys\", \"tem (OS).\\nJust as shipping containers allow goods to be transported by ship, train, or truck regardl\", \"ess of the\\ncargo inside, software containers act as a standard unit of software deployment that can \", \"contain\\ndifferent code and dependencies. Containerizing software this way enables developers and IT\\n\", \"professionals to deploy them across environments with little or no modification.\\nContainers also iso\", \"late applications from each other on a shared OS. Containerized applications run\\non top of a contain\", \"er host that in turn runs on the OS (Linux or Windows). Containers therefore have a\\nsignificantly sm\", \"aller footprint than virtual machine (VM) images.\\nEach container can run a whole web application or \", \"a service, as shown in Figure 2-1. In this example,\\nDocker host is a container host, and App1, App2,\", \" Svc 1, and Svc 2 are containerized applications or\\nservices.\\nFigure 2-1. Multiple containers runnin\", \"g on a container host\\n1 CHAPTER 1 | Introduction to Containers and DockerAnother benefit of containe\", \"rization is scalability. You can scale out quickly by creating new containers\\nfor short-term tasks. \", \"From an application point of view, instantiating an image (creating a container) is\\nsimilar to insta\", \"ntiating a process like a service or a web app. For reliability, however, when you run\\nmultiple inst\", \"ances of the same image across multiple host servers, you typically want each container\\n(image insta\", \"nce) to run in a different host server or VM in different fault domains.\\nIn short, containers offer \", \"the benefits of isolation, portability, agility, scalability, and control across the\\nwhole applicati\", \"on lifecycle workflow. The most important benefit is the environment\\u2019s isolation\\nprovided between De\", \"v and Ops.\\nWhat is Docker?\\nDocker is an open-source project for automating the deployment of applica\", \"tions as portable, self-\\nsufficient containers that can run on the cloud or on-premises. Docker is a\", \"lso a company that\\npromotes and evolves this technology, working in collaboration with cloud, Linux,\", \" and Windows\\nvendors, including Microsoft.\\nFigure 2-2. Docker deploys containers at all layers of th\", \"e hybrid cloud.\\nDocker containers can run anywhere, on-premises in the customer datacenter, in an ex\", \"ternal service\\nprovider or in the cloud, on Azure. Docker image containers can run natively on Linux\", \" and Windows.\\nHowever, Windows images can run only on Windows hosts and Linux images can run on Linu\", \"x hosts\\nand Windows hosts (using a Hyper-V Linux VM, so far), where host means a server or a VM.\\nDev\", \"elopers can use development environments on Windows, Linux, or macOS. On the development\\ncomputer, t\", \"he developer runs a Docker host where Docker images are deployed, including the app\\nand its dependen\", \"cies. Developers who work on Linux or on macOS use a Docker host that is Linux\\nbased, and they can c\", \"reate images only for Linux containers. (Developers working on macOS can edit\\ncode or run the Docker\", \" CLI from macOS, but as of the time of this writing, containers don\\u2019t run\\n2 CHAPTER 1 | Introduction\", \" to Containers and Dockerdirectly on macOS.) Developers who work on Windows can create images for ei\", \"ther Linux or Windows\\nContainers.\\nTo host containers in development environments and provide additio\", \"nal developer tools, Docker\\nships Docker Desktop for Windows or for macOS. These products install th\", \"e necessary VM (the Docker\\nhost) to host the containers.\\nTo run Windows Containers, there are two ty\", \"pes of runtimes:\\n\\u2022 Windows Server Containers provide application isolation through process and names\", \"pace\\nisolation technology. A Windows Server Container shares a kernel with the container host and\\nwi\", \"th all containers running on the host.\\n\\u2022 Hyper-V Containers expand on the isolation provided by Wind\", \"ows Server Containers by\\nrunning each container in a highly optimized virtual machine. In this confi\", \"guration, the kernel\\nof the container host isn\\u2019t shared with the Hyper-V Containers, providing bette\", \"r isolation.\\nThe images for these containers are created the same way and function the same. The dif\", \"ference is in\\nhow the container is created from the image running a Hyper-V Container requires an ex\", \"tra\\nparameter. For details, see Hyper-V Containers.\\nComparing Docker containers with virtual machine\", \"s\\nFigure 2-3 shows a comparison between VMs and Docker containers.\\nVirtual Machines Docker Container\", \"s\\n3 CHAPTER 1 | Introduction to Containers and DockerVirtual Machines Docker Containers\\nVirtual mach\", \"ines include the application, the Containers include the application and all its\\nrequired libraries \", \"or binaries, and a full guest dependencies. However, they share the OS kernel\\noperating system. Full\", \" virtualization requires with other containers, running as isolated\\nmore resources than containeriza\", \"tion. processes in user space on the host operating\\nsystem. (Except in Hyper-V containers, where\\neac\", \"h container runs inside of a special virtual\\nmachine per container.)\\nFigure 2-3. Comparison of tradi\", \"tional virtual machines to Docker containers\\nFor VMs, there are three base layers in the host server\", \", from the bottom-up: infrastructure, Host\\nOperating System and a Hypervisor and on top of all that \", \"each VM has its own OS and all necessary\\nlibraries. For Docker, the host server only has the infrast\", \"ructure and the OS and on top of that, the\\ncontainer engine, that keeps container isolated but shari\", \"ng the base OS services.\\nBecause containers require far fewer resources (for example, they don\\u2019t nee\", \"d a full OS), they\\u2019re easy to\\ndeploy and they start fast. This allows you to have higher density, me\", \"aning that it allows you to run\\nmore services on the same hardware unit, thereby reducing costs.\\nAs \", \"a side effect of running on the same kernel, you get less isolation than VMs.\\nThe main goal of an im\", \"age is that it makes the environment (dependencies) the same across different\\ndeployments. This mean\", \"s that you can debug it on your machine and then deploy it to another\\nmachine with the same environm\", \"ent guaranteed.\\nA container image is a way to package an app or service and deploy it in a reliable \", \"and reproducible\\nway. You could say that Docker isn\\u2019t only a technology but also a philosophy and a \", \"process.\\nWhen using Docker, you won\\u2019t hear developers say, \\u201cIt works on my machine, why not in produ\", \"ction?\\u201d\\nThey can simply say, \\u201cIt runs on Docker\\u201d, because the packaged Docker application can be exe\", \"cuted\\non any supported Docker environment, and it runs the way it was intended to on all deployment\\n\", \"targets (such as Dev, QA, staging, and production).\\nA simple analogy\\nPerhaps a simple analogy can he\", \"lp getting the grasp of the core concept of Docker.\\nLet\\u2019s go back in time to the 1950s for a moment.\", \" There were no word processors, and the\\nphotocopiers were used everywhere (kind of).\\nImagine you\\u2019re \", \"responsible for quickly issuing batches of letters as required, to mail them to\\ncustomers, using rea\", \"l paper and envelopes, to be delivered physically to each customer\\u2019s address\\n(there was no email bac\", \"k then).\\nAt some point, you realize the letters are just a composition of a large set of paragraphs,\", \" which are\\npicked and arranged as needed, according to the purpose of the letter, so you devise a sy\", \"stem to\\nissue letters quickly, expecting to get a hefty raise.\\nThe system is simple:\\n1. You begin wi\", \"th a deck of transparent sheets containing one paragraph each.\\n4 CHAPTER 1 | Introduction to Contain\", \"ers and Docker2. To issue a set of letters, you pick the sheets with the paragraphs you need, then y\", \"ou stack and\\nalign them so they look and read fine.\\n3. Finally, you place the set in the photocopier\", \" and press start to produce as many letters as\\nrequired.\\nSo, simplifying, that\\u2019s the core idea of Do\", \"cker.\\nIn Docker, each layer is the resulting set of changes that happen to the filesystem after exec\", \"uting a\\ncommand, such as, installing a program.\\nSo, when you \\u201clook\\u201d at the filesystem after the laye\", \"r has been copied, you see all the files, included in\\nthe layer when the program was installed.\\nYou \", \"can think of an image as an auxiliary read-only hard disk ready to be installed in a \\u201ccomputer\\u201d\\nwher\", \"e the operating system is already installed.\\nSimilarly, you can think of a container as the \\u201ccompute\", \"r\\u201d with the image hard disk installed. The\\ncontainer, just like a computer, can be powered on or off\", \".\\nDocker terminology\\nThis section lists terms and definitions you should be familiar with before get\", \"ting deeper into Docker.\\nFor further definitions, see the extensive glossary provided by Docker.\\nCon\", \"tainer image: A package with all the dependencies and information needed to create a container.\\nAn i\", \"mage includes all the dependencies (such as frameworks) plus deployment and execution\\nconfiguration \", \"to be used by a container runtime. Usually, an image derives from multiple base images\\nthat are laye\", \"rs stacked on top of each other to form the container\\u2019s filesystem. An image is immutable\\nonce it ha\", \"s been created.\\nDockerfile: A text file that contains instructions for building a Docker image. It\\u2019s\", \" like a batch script,\\nthe first line states the base image to begin with and then follow the instruc\", \"tions to install required\\nprograms, copy files, and so on, until you get the working environment you\", \" need.\\nBuild: The action of building a container image based on the information and context provided\", \" by its\\nDockerfile, plus additional files in the folder where the image is built. You can build imag\", \"es with the\\nfollowing Docker command:\\ndocker build\\nContainer: An instance of a Docker image. A conta\", \"iner represents the execution of a single\\napplication, process, or service. It consists of the conte\", \"nts of a Docker image, an execution\\nenvironment, and a standard set of instructions. When scaling a \", \"service, you create multiple instances\\nof a container from the same image. Or a batch job can create\", \" multiple containers from the same\\nimage, passing different parameters to each instance.\\nVolumes: Of\", \"fer a writable filesystem that the container can use. Since images are read-only but most\\nprograms n\", \"eed to write to the filesystem, volumes add a writable layer, on top of the container image,\\nso the \", \"programs have access to a writable filesystem. The program doesn\\u2019t know it\\u2019s accessing a\\n5 CHAPTER 1\", \" | Introduction to Containers and Dockerlayered filesystem, it\\u2019s just the filesystem as usual. Volum\", \"es live in the host system and are managed\\nby Docker.\\nTag: A mark or label you can apply to images s\", \"o that different images or versions of the same image\\n(depending on the version number or the target\", \" environment) can be identified.\\nMulti-stage Build: Is a feature, since Docker 17.05 or higher, that\", \" helps to reduce the size of the final\\nimages. For example, a large base image, containing the SDK c\", \"an be used for compiling and\\npublishing and then a small runtime-only base image can be used to host\", \" the application.\\nRepository (repo): A collection of related Docker images, labeled with a tag that \", \"indicates the image\\nversion. Some repos contain multiple variants of a specific image, such as an im\", \"age containing SDKs\\n(heavier), an image containing only runtimes (lighter), etc. Those variants can \", \"be marked with tags. A\\nsingle repo can contain platform variants, such as a Linux image and a Window\", \"s image.\\nRegistry: A service that provides access to repositories. The default registry for most pub\", \"lic images is\\nDocker Hub (owned by Docker as an organization). A registry usually contains repositor\", \"ies from\\nmultiple teams. Companies often have private registries to store and manage images they\\u2019ve \", \"created.\\nAzure Container Registry is another example.\\nMulti-arch image: For multi-architecture (or m\", \"ulti-platform), it\\u2019s a Docker feature that simplifies the\\nselection of the appropriate image, accord\", \"ing to the platform where Docker is running. For example,\\nwhen a Dockerfile requests a base image FR\", \"OM mcr.microsoft.com/dotnet/sdk:7.0 from the\\nregistry, it actually gets 7.0-nanoserver-ltsc2022, 7.0\", \"-nanoserver-1809 or 7.0-bullseye-slim,\\ndepending on the operating system and version where Docker is\", \" running.\\nDocker Hub: A public registry to upload images and work with them. Docker Hub provides Doc\", \"ker\\nimage hosting, public or private registries, build triggers and web hooks, and integration with \", \"GitHub\\nand Bitbucket.\\nAzure Container Registry: A public resource for working with Docker images and\", \" its components in\\nAzure. This provides a registry that\\u2019s close to your deployments in Azure and tha\", \"t gives you control\\nover access, making it possible to use your Azure Active Directory groups and pe\", \"rmissions.\\nDocker Trusted Registry (DTR): A Docker registry service (from Docker) that can be instal\", \"led on-\\npremises so it lives within the organization\\u2019s datacenter and network. It\\u2019s convenient for p\", \"rivate\\nimages that should be managed within the enterprise. Docker Trusted Registry is included as p\", \"art of\\nthe Docker Datacenter product.\\nDocker Desktop: Development tools for Windows and macOS for bu\", \"ilding, running, and testing\\ncontainers locally. Docker Desktop for Windows provides development env\", \"ironments for both Linux\\nand Windows Containers. The Linux Docker host on Windows is based on a Hype\", \"r-V virtual machine.\\nThe host for Windows Containers is directly based on Windows. Docker Desktop fo\", \"r Mac is based on\\nthe Apple Hypervisor framework and the xhyve hypervisor, which provides a Linux Do\", \"cker host virtual\\nmachine on macOS. Docker Desktop for Windows and for Mac replaces Docker Toolbox, \", \"which was\\nbased on Oracle VirtualBox.\\nCompose: A command-line tool and YAML file format with metadat\", \"a for defining and running multi-\\ncontainer applications. You define a single application based on m\", \"ultiple images with one or more\\n.yml files that can override values depending on the environment. Af\", \"ter you\\u2019ve created the definitions,\\n6 CHAPTER 1 | Introduction to Containers and Dockeryou can deplo\", \"y the whole multi-container application with a single command (docker-compose up)\\nthat creates a con\", \"tainer per image on the Docker host.\\nCluster: A collection of Docker hosts exposed as if it were a s\", \"ingle virtual Docker host, so that the\\napplication can scale to multiple instances of the services s\", \"pread across multiple hosts within the\\ncluster. Docker clusters can be created with Kubernetes, Azur\", \"e Service Fabric, Docker Swarm and\\nMesosphere DC/OS.\\nOrchestrator: A tool that simplifies the manage\", \"ment of clusters and Docker hosts. Orchestrators\\nenable you to manage their images, containers, and \", \"hosts through a command-line interface (CLI) or a\\ngraphical UI. You can manage container networking,\", \" configurations, load balancing, service discovery,\\nhigh availability, Docker host configuration, an\", \"d more. An orchestrator is responsible for running,\\ndistributing, scaling, and healing workloads acr\", \"oss a collection of nodes. Typically, orchestrator\\nproducts are the same products that provide clust\", \"er infrastructure, like Kubernetes and Azure Service\\nFabric, among other offerings in the market.\\nDo\", \"cker containers, images, and registries\\nWhen using Docker, a developer creates an app or service and\", \" packages it and its dependencies into\\na container image. An image is a static representation of the\", \" app or service and its configuration and\\ndependencies.\\nTo run the app or service, the app\\u2019s image i\", \"s instantiated to create a container, which will be running\\non the Docker host. Containers are initi\", \"ally tested in a development environment or PC.\\nDevelopers should store images in a registry, which \", \"acts as a library of images and is needed when\\ndeploying to production orchestrators. Docker maintai\", \"ns a public registry via Docker Hub; other\\nvendors provide registries for different collections of i\", \"mages, including Azure Container Registry.\\nAlternatively, enterprises can have a private registry on\", \"-premises for their own Docker images.\\nFigure 2-4 shows how images and registries in Docker relate t\", \"o other components. It also shows the\\nmultiple registry offerings from vendors.\\n7 CHAPTER 1 | Introd\", \"uction to Containers and DockerFigure 2-4. Taxonomy of Docker terms and concepts\\nThe registry is lik\", \"e a bookshelf where images are stored and available to be pulled for building\\ncontainers to run serv\", \"ices or web apps. There are private Docker registries on-premises and on the\\npublic cloud. Docker Hu\", \"b is a public registry maintained by Docker, along the Docker Trusted Registry\\nan enterprise-grade s\", \"olution, Azure offers the Azure Container Registry. AWS, Google, and others also\\nhave container regi\", \"stries.\\nPutting images in a registry lets you store static and immutable application bits, including\", \" all their\\ndependencies at a framework level. Those images can then be versioned and deployed in mul\", \"tiple\\nenvironments and therefore provide a consistent deployment unit.\\nPrivate image registries, eit\", \"her hosted on-premises or in the cloud, are recommended when:\\n\\u2022 Your images must not be shared publi\", \"cly due to confidentiality.\\n\\u2022 You want to have minimum network latency between your images and your \", \"chosen\\ndeployment environment. For example, if your production environment is Azure cloud, you\\nproba\", \"bly want to store your images in Azure Container Registry so that network latency will\\nbe minimal. I\", \"n a similar way, if your production environment is on-premises, you might want\\nto have an on-premise\", \"s Docker Trusted Registry available within the same local network.\\n8 CHAPTER 1 | Introduction to Con\", \"tainers and Docker2\\nCHAPTER\\nChoosing Between .NET\\nand .NET Framework for\\nDocker Containers\\nThere are\", \" two supported frameworks for building server-side containerized Docker applications with\\n.NET: .NET\", \" Framework and .NET 7. They share many .NET platform components, and you can share\\ncode across the t\", \"wo. However, there are fundamental differences between them, and which\\nframework you use will depend\", \" on what you want to accomplish. This section provides guidance on\\nwhen to choose each framework.\\nGe\", \"neral guidance\\nThis section provides a summary of when to choose .NET 7 or .NET Framework. We provid\", \"e more\\ndetails about these choices in the sections that follow.\\nUse .NET 7, with Linux or Windows Co\", \"ntainers, for your containerized Docker server application when:\\n\\u2022 You have cross-platform needs. Fo\", \"r example, you want to use both Linux and Windows\\nContainers.\\n\\u2022 Your application architecture is bas\", \"ed on microservices.\\n\\u2022 You need to start containers fast and want a small footprint per container to\", \" achieve better\\ndensity or more containers per hardware unit in order to lower your costs.\\nIn short,\", \" when you create new containerized .NET applications, you should consider .NET 7 as the\\ndefault choi\", \"ce. It has many benefits and fits best with the containers philosophy and style of working.\\nAn extra\", \" benefit of using .NET 7 is that you can run side-by-side .NET versions for applications within\\nthe \", \"same machine. This benefit is more important for servers or VMs that do not use containers,\\nbecause \", \"containers isolate the versions of .NET that the app needs. (As long as they are compatible\\nwith the\", \" underlying OS.)\\nUse .NET Framework for your containerized Docker server application when:\\n\\u2022 Your ap\", \"plication currently uses .NET Framework and has strong dependencies on Windows.\\n9 CHAPTER 2 | Choosi\", \"ng Between .NET and .NET Framework for Docker Containers\\u2022 You need to use Windows APIs that are not \", \"supported by .NET 7.\\n\\u2022 You need to use third-party .NET libraries or NuGet packages that are not ava\", \"ilable for .NET 7.\\nUsing .NET Framework on Docker can improve your deployment experiences by minimiz\", \"ing\\ndeployment issues. This \\u201clift and shift\\u201d scenario is important for containerizing legacy applica\", \"tions that\\nwere originally developed with the traditional .NET Framework, like ASP.NET WebForms, MVC\", \" web\\napps, or WCF (Windows Communication Foundation) services.\\nAdditional resources\\n\\u2022 E-book: Modern\", \"ize existing .NET Framework applications with Azure and Windows\\nContainers\\nhttps://aka.ms/liftandshi\", \"ftwithcontainersebook\\n\\u2022 Sample apps: Modernization of legacy ASP.NET web apps by using Windows Conta\", \"iners\\nhttps://aka.ms/eshopmodernizing\\nWhen to choose .NET for Docker containers\\nThe modularity and l\", \"ightweight nature of .NET 7 makes it perfect for containers. When you deploy\\nand start a container, \", \"its image is far smaller with .NET 7 than with .NET Framework. In contrast, to use\\n.NET Framework fo\", \"r a container, you must base your image on the Windows Server Core image, which\\nis a lot heavier tha\", \"n the Windows Nano Server or Linux images that you use for .NET 7.\\nAdditionally, .NET 7 is cross-pla\", \"tform, so you can deploy server apps with Linux or Windows container\\nimages. However, if you are usi\", \"ng the traditional .NET Framework, you can only deploy images based\\non Windows Server Core.\\nThe foll\", \"owing is a more detailed explanation of why to choose .NET 7.\\nDeveloping and deploying cross platfor\", \"m\\nClearly, if your goal is to have an application (web app or service) that can run on multiple plat\", \"forms\\nsupported by Docker (Linux and Windows), the right choice is .NET 7, because .NET Framework on\", \"ly\\nsupports Windows.\\n.NET 7 also supports macOS as a development platform. However, when you deploy \", \"containers to a\\nDocker host, that host must (currently) be based on Linux or Windows. For example, i\", \"n a development\\nenvironment, you could use a Linux VM running on a Mac.\\nVisual Studio provides an in\", \"tegrated development environment (IDE) for Windows and supports\\nDocker development.\\nVisual Studio fo\", \"r Mac is an IDE, evolution of Xamarin Studio, that runs on macOS and supports\\nDocker-based applicati\", \"on development. This tool should be the preferred choice for developers\\nworking in Mac machines who \", \"also want to use a powerful IDE.\\nYou can also use Visual Studio Code on macOS, Linux, and Windows. V\", \"isual Studio Code fully\\nsupports .NET 7, including IntelliSense and debugging. Because VS Code is a \", \"lightweight editor, you\\n10 CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Container\", \"scan use it to develop containerized apps on the machine in conjunction with the Docker CLI and the\\n\", \".NET CLI. You can also target .NET 7 with most third-party editors like Sublime, Emacs, vi, and the\\n\", \"open-source OmniSharp project, which also provides IntelliSense support.\\nIn addition to the IDEs and\", \" editors, you can use the .NET CLI for all supported platforms.\\nUsing containers for new (\\u201cgreen-fie\", \"ld\\u201d) projects\\nContainers are commonly used in conjunction with a microservices architecture, althoug\", \"h they can\\nalso be used to containerize web apps or services that follow any architectural pattern. \", \"You can use\\n.NET Framework on Windows Containers, but the modularity and lightweight nature of .NET \", \"7 makes\\nit perfect for containers and microservices architectures. When you create and deploy a cont\", \"ainer, its\\nimage is far smaller with .NET 7 than with .NET Framework.\\nCreate and deploy microservice\", \"s on containers\\nYou could use the traditional .NET Framework for building microservices-based applic\", \"ations (without\\ncontainers) by using plain processes. That way, because the .NET Framework is alread\", \"y installed and\\nshared across processes, processes are light and fast to start. However, if you are \", \"using containers, the\\nimage for the traditional .NET Framework is also based on Windows Server Core \", \"and that makes it too\\nheavy for a microservices-on-containers approach. However, teams have been loo\", \"king for\\nopportunities to improve the experience for .NET Framework users as well. Recently, size of\", \" the\\nWindows Server Core container images have been reduced to >40% smaller.\\nOn the other hand, .NET\", \" 7 is the best candidate if you\\u2019re embracing a microservices-oriented system\\nthat is based on contai\", \"ners because .NET 7 is lightweight. In addition, its related container images, for\\neither Linux or W\", \"indows Nano Server, are lean and small, making containers light and fast to start.\\nA microservice is\", \" meant to be as small as possible: to be light when spinning up, to have a small\\nfootprint, to have \", \"a small Bounded Context (check DDD, Domain-Driven Design), to represent a small\\narea of concerns, an\", \"d to be able to start and stop fast. For those requirements, you will want to use\\nsmall and fast-to-\", \"instantiate container images like the .NET 7 container image.\\nA microservices architecture also allo\", \"ws you to mix technologies across a service boundary. This\\napproach enables a gradual migration to .\", \"NET 7 for new microservices that work in conjunction with\\nother microservices or with services devel\", \"oped with Node.js, Python, Java, GoLang, or other\\ntechnologies.\\nDeploying high density in scalable s\", \"ystems\\nWhen your container-based system needs the best possible density, granularity, and performanc\", \"e,\\n.NET and ASP.NET Core are your best options. ASP.NET Core is up to 10 times faster than ASP.NET i\", \"n\\nthe traditional .NET Framework, and it leads to other popular industry technologies for microservi\", \"ces,\\nsuch as Java servlets, Go, and Node.js.\\nThis approach is especially relevant for microservices \", \"architectures, where you could have hundreds of\\nmicroservices (containers) running. With ASP.NET Cor\", \"e images (based on the .NET runtime) on Linux\\nor Windows Nano, you can run your system with a much l\", \"ower number of servers or VMs, ultimately\\nsaving costs in infrastructure and hosting.\\n11 CHAPTER 2 |\", \" Choosing Between .NET and .NET Framework for Docker ContainersWhen to choose .NET Framework for Doc\", \"ker\\ncontainers\\nWhile .NET 7 offers significant benefits for new applications and application pattern\", \"s, .NET Framework\\nwill continue to be a good choice for many existing scenarios.\\nMigrating existing \", \"applications directly to a Windows Server container\\nYou might want to use Docker containers just to \", \"simplify deployment, even if you are not creating\\nmicroservices. For example, perhaps you want to im\", \"prove your DevOps workflow with Docker\\u2014\\ncontainers can give you better isolated test environments an\", \"d can also eliminate deployment issues\\ncaused by missing dependencies when you move to a production \", \"environment. In cases like these,\\neven if you are deploying a monolithic application, it makes sense\", \" to use Docker and Windows\\nContainers for your current .NET Framework applications.\\nIn most cases fo\", \"r this scenario, you will not need to migrate your existing applications to .NET 7; you\\ncan use Dock\", \"er containers that include the traditional .NET Framework. However, a recommended\\napproach is to use\", \" .NET 7 as you extend an existing application, such as writing a new service in\\nASP.NET Core.\\nUsing \", \"third-party .NET libraries or NuGet packages not available for\\n.NET 7\\nThird-party libraries are quic\", \"kly embracing .NET Standard, which enables code sharing across all .NET\\nflavors, including .NET 7. W\", \"ith .NET Standard 2.0 and later, the API surface compatibility across\\ndifferent frameworks has becom\", \"e significantly larger. Even more, .NET Core 2.x and newer applications\\ncan also directly reference \", \"existing .NET Framework libraries (see .NET Framework 4.6.1 supporting\\n.NET Standard 2.0).\\nIn additi\", \"on, the Windows Compatibility Pack extends the API surface available for .NET Standard 2.0\\non Window\", \"s. This pack allows recompiling most existing code to .NET Standard 2.x with little or no\\nmodificati\", \"on, to run on Windows.\\nHowever, even with that exceptional progression since .NET Standard 2.0 and .\", \"NET Core 2.1 or later,\\nthere might be cases where certain NuGet packages need Windows to run and mig\", \"ht not support\\n.NET Core or later. If those packages are critical for your application, then you wil\", \"l need to use .NET\\nFramework on Windows Containers.\\nUsing .NET technologies not available for .NET 7\", \"\\nSome .NET Framework technologies aren\\u2019t available in .NET 7. Some of them might become available\\nin\", \" later releases, but others don\\u2019t fit the new application patterns targeted by .NET Core and might\\nn\", \"ever be available.\\nThe following list shows most of the technologies that aren\\u2019t available in .NET 7\", \":\\n12 CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers\\u2022 ASP.NET Web Forms. \", \"This technology is only available on .NET Framework. Currently there are\\nno plans to bring ASP.NET W\", \"eb Forms to .NET or later.\\n\\u2022 Workflow-related services. Windows Workflow Foundation (WF), Workflow S\", \"ervices (WCF +\\nWF in a single service), and WCF Data Services (formerly known as ADO.NET Data Servic\", \"es)\\nare only available on .NET Framework. There are currently no plans to bring them to .NET 7.\\nIn a\", \"ddition to the technologies listed in the official .NET roadmap, other features might be ported to\\nt\", \"he new unified .NET platform. You might consider participating in the discussions on GitHub so that\\n\", \"your voice can be heard. And if you think something is missing, file a new issue in the dotnet/runti\", \"me\\nGitHub repository.\\nUsing a platform or API that doesn\\u2019t support .NET 7\\nSome Microsoft and third-p\", \"arty platforms don\\u2019t support .NET 7. For example, some Azure services\\nprovide an SDK that isn\\u2019t yet \", \"available for consumption on .NET 7 yet. Most Azure SDK should\\neventually be ported to .NET 7/.NET S\", \"tandard, but some might not for several reasons. You can see\\nthe available Azure SDKs in the Azure S\", \"DK Latest Releases page.\\nIn the meantime, if any platform or service in Azure still doesn\\u2019t support \", \".NET 7 with its client API, you\\ncan use the equivalent REST API from the Azure service or the client\", \" SDK on .NET Framework.\\nPorting existing ASP.NET application to .NET 7\\n.NET Core is a revolutionary \", \"step forward from .NET Framework. It offers a host of advantages over\\n.NET Framework across the boar\", \"d from productivity to performance, and from cross-platform support\\nto developer satisfaction. If yo\", \"u are using .NET Framework and planning to migrate your application\\nto .NET Core or .NET 5+, see Por\", \"ting Existing ASP.NET Apps to .NET Core.\\nAdditional resources\\n\\u2022 .NET fundamentals\\nhttps://learn.micr\", \"osoft.com/dotnet/fundamentals\\n\\u2022 Porting Projects to .NET 5\\nhttps://learn.microsoft.com/events/dotnet\", \"conf-2020/porting-projects-to-net-5\\n\\u2022 .NET on Docker Guide\\nhttps://learn.microsoft.com/dotnet/core/d\", \"ocker/introduction\\nDecision table: .NET implementations to use for\\nDocker\\nThe following decision tab\", \"le summarizes whether to use .NET Framework or .NET 7. Remember that\\nfor Linux containers, you need \", \"Linux-based Docker hosts (VMs or servers), and that for Windows\\nContainers, you need Windows Server-\", \"based Docker hosts (VMs or servers).\\n13 CHAPTER 2 | Choosing Between .NET and .NET Framework for Doc\", \"ker ContainersImportant\\nYour development machines will run one Docker host, either Linux or Windows.\", \" Related microservices\\nthat you want to run and test together in one solution will all need to run o\", \"n the same container\\nplatform.\\nArchitecture / App Type Linux containers Windows Containers\\nMicroserv\", \"ices on containers .NET 7 .NET 7\\nMonolithic app .NET 7 .NET Framework\\n.NET 7\\nBest-in-class performan\", \"ce and .NET 7 .NET 7\\nscalability\\nWindows Server legacy app (\\u201cbrown- \\u2013 .NET Framework\\nfield\\u201d) migrati\", \"on to containers\\nNew container-based development .NET 7 .NET 7\\n(\\u201cgreen-field\\u201d)\\nASP.NET Core .NET 7 .\", \"NET 7 (recommended)\\n.NET Framework\\nASP.NET 4 (MVC 5, Web API 2, and \\u2013 .NET Framework\\nWeb Forms)\\nSign\", \"alR services .NET Core 2.1 or higher .NET Framework\\nversion .NET Core 2.1 or higher\\nversion\\nWCF, WF,\", \" and other legacy WCF in .NET Core (client .NET Framework\\nframeworks library only) or CoreWCF WCF in\", \" .NET 7 (client library\\nonly) or CoreWCF\\nConsumption of Azure services .NET 7 .NET Framework\\n(eventu\", \"ally most Azure .NET 7\\nservices will provide client (eventually most Azure\\nSDKs for .NET 7) services\", \" will provide client\\nSDKs for .NET 7)\\nWhat OS to target with .NET containers\\nGiven the diversity of \", \"operating systems supported by Docker and the differences between .NET\\nFramework and .NET 7, you sho\", \"uld target a specific OS and specific versions depending on the\\nframework you are using.\\nFor Windows\", \", you can use Windows Server Core or Windows Nano Server. These Windows versions\\nprovide different c\", \"haracteristics (IIS in Windows Server Core versus a self-hosted web server like\\nKestrel in Nano Serv\", \"er) that might be needed by .NET Framework or .NET 7, respectively.\\nFor Linux, multiple distros are \", \"available and supported in official .NET Docker images (like Debian).\\n14 CHAPTER 2 | Choosing Betwee\", \"n .NET and .NET Framework for Docker ContainersIn Figure 3-1, you can see the possible OS version de\", \"pending on the .NET framework used.\\nFigure 3-1. Operating systems to target depending on versions of\", \" the .NET framework\\nWhen deploying legacy .NET Framework applications you have to target Windows Ser\", \"ver Core,\\ncompatible with legacy apps and IIS, but it has a larger image. When deploying .NET 7 appl\", \"ications,\\nyou can target Windows Nano Server, which is cloud optimized, uses Kestrel and is smaller \", \"and starts\\nfaster. You can also target Linux, supporting Debian, Alpine, and others.\\nYou can also cr\", \"eate your own Docker image in cases where you want to use a different Linux distro or\\nwhere you want\", \" an image with versions not provided by Microsoft. For example, you might create an\\nimage with ASP.N\", \"ET Core running on the traditional .NET Framework and Windows Server Core, which\\nis a not-so-common \", \"scenario for Docker.\\nWhen you add the image name to your Dockerfile file, you can select the operati\", \"ng system and\\nversion depending on the tag you use, as in the following examples:\\nImage Comments\\nmcr\", \".microsoft.com/dotnet/runtime:7.0 .NET 7 multi-architecture: Supports Linux and Windows\\nNano Server \", \"depending on the Docker host.\\nmcr.microsoft.com/dotnet/aspnet:7.0 ASP.NET Core 7.0 multi-architectur\", \"e: Supports Linux and\\nWindows Nano Server depending on the Docker host.\\nThe aspnetcore image has a f\", \"ew optimizations for\\nASP.NET Core.\\nmcr.microsoft.com/dotnet/aspnet:7.0- .NET 7 runtime-only on Linux\", \" Debian distro\\nbullseye-slim\\nmcr.microsoft.com/dotnet/aspnet:7.0- .NET 7 runtime-only on Windows Nan\", \"o Server (Windows\\nnanoserver-1809 Server version 1809)\\n15 CHAPTER 2 | Choosing Between .NET and .NET\", \" Framework for Docker ContainersOfficial .NET Docker images\\nThe Official .NET Docker images are Dock\", \"er images created and optimized by Microsoft. They\\u2019re\\npublicly available on Microsoft Artifact Regis\", \"try. You can search over the catalog to find all .NET image\\nrepositories, for example .NET SDK repos\", \"itory.\\nEach repository can contain multiple images, depending on .NET versions, and depending on the\", \" OS\\nand versions (Linux Debian, Linux Alpine, Windows Nano Server, Windows Server Core, and so on).\\n\", \"Image repositories provide extensive tagging to help you select not just a specific framework versio\", \"n,\\nbut also to choose an OS (Linux distribution or Windows version).\\n.NET and Docker image optimizat\", \"ions for development versus\\nproduction\\nWhen building Docker images for developers, Microsoft focused\", \" on the following main scenarios:\\n\\u2022 Images used to develop and build .NET apps.\\n\\u2022 Images used to run\", \" .NET apps.\\nWhy multiple images? When developing, building, and running containerized applications, \", \"you usually\\nhave different priorities. By providing different images for these separate tasks, Micro\", \"soft helps\\noptimize the separate processes of developing, building, and deploying apps.\\nDuring devel\", \"opment and build\\nDuring development, what is important is how fast you can iterate changes, and the \", \"ability to debug\\nthe changes. The size of the image isn\\u2019t as important as the ability to make change\", \"s to your code and\\nsee the changes quickly. Some tools and \\u201cbuild-agent containers\\u201d, use the develop\", \"ment .NET image\\n(mcr.microsoft.com/dotnet/sdk:7.0) during development and build process. When buildi\", \"ng inside a\\nDocker container, the important aspects are the elements that are needed to compile your\", \" app. This\\nincludes the compiler and any other .NET dependencies.\\nWhy is this type of build image im\", \"portant? You don\\u2019t deploy this image to production. Instead, it\\u2019s an\\nimage that you use to build the\", \" content you place into a production image. This image would be used\\nin your continuous integration \", \"(CI) environment or build environment when using Docker multi-stage\\nbuilds.\\nIn production\\nWhat is im\", \"portant in production is how fast you can deploy and start your containers based on a\\nproduction .NE\", \"T image. Therefore, the runtime-only image based on\\nmcr.microsoft.com/dotnet/aspnet:7.0 is small so \", \"that it can travel quickly across the network from your\\nDocker registry to your Docker hosts. The co\", \"ntents are ready to run, enabling the fastest time from\\nstarting the container to processing results\", \". In the Docker model, there is no need for compilation\\nfrom C# code, as there\\u2019s when you run dotnet\", \" build or dotnet publish when using the build container.\\n16 CHAPTER 2 | Choosing Between .NET and .N\", \"ET Framework for Docker ContainersIn this optimized image, you put only the binaries and other conte\", \"nt needed to run the application.\\nFor example, the content created by dotnet publish contains only t\", \"he compiled .NET binaries, images,\\n.js, and .css files. Over time, you\\u2019ll see images that contain pr\", \"e-jitted (the compilation from IL to native\\nthat occurs at run time) packages.\\nAlthough there are mu\", \"ltiple versions of the .NET and ASP.NET Core images, they all share one or more\\nlayers, including th\", \"e base layer. Therefore, the amount of disk space needed to store an image is\\nsmall; it consists onl\", \"y of the delta between your custom image and its base image. The result is that\\nit\\u2019s quick to pull t\", \"he image from your registry.\\nWhen you explore the .NET image repositories at Microsoft Artifact Regi\", \"stry, you\\u2019ll find multiple image\\nversions classified or marked with tags. These tags help to decide \", \"which one to use, depending on the\\nversion you need, like those in the following table:\\nImage Commen\", \"ts\\nmcr.microsoft.com/dotnet/aspnet:7.0 ASP.NET Core, with runtime only and ASP.NET Core\\noptimization\", \"s, on Linux and Windows (multi-arch)\\nmcr.microsoft.com/dotnet/sdk:7.0 .NET 7, with SDKs included, on\", \" Linux and Windows\\n(multi-arch)\\nYou can find all the available docker images in dotnet-docker and al\", \"so refer to the latest preview\\nreleases by using nightly build mcr.microsoft.com/dotnet/nightly/*\\n17\", \" CHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers3\\nCHAPTER\\nArchitecting co\", \"ntainer and\\nmicroservice-based\\napplications\\nMicroservices offer great benefits but also raise huge n\", \"ew challenges. Microservice architecture patterns\\nare fundamental pillars when creating a microservi\", \"ce-based application.\\nEarlier in this guide, you learned basic concepts about containers and Docker.\", \" That information was\\nthe minimum you needed to get started with containers. Even though containers \", \"are enablers of, and\\na great fit for microservices, they aren\\u2019t mandatory for a microservice archite\", \"cture. Many architectural\\nconcepts in this architecture section could be applied without containers.\", \" However, this guide focuses\\non the intersection of both due to the already introduced importance of\", \" containers.\\nEnterprise applications can be complex and are often composed of multiple services inst\", \"ead of a\\nsingle service-based application. For those cases, you need to understand other architectur\", \"al\\napproaches, such as the microservices and certain Domain-Driven Design (DDD) patterns plus\\ncontai\", \"ner orchestration concepts. Note that this chapter describes not just microservices on\\ncontainers, b\", \"ut any containerized application, as well.\\nContainer design principles\\nIn the container model, a con\", \"tainer image instance represents a single process. By defining a\\ncontainer image as a process bounda\", \"ry, you can create primitives that can be used to scale or batch\\nthe process.\\nWhen you design a cont\", \"ainer image, you\\u2019ll see an ENTRYPOINT definition in the Dockerfile. This\\ndefinition defines the proc\", \"ess whose lifetime controls the lifetime of the container. When the process\\ncompletes, the container\", \" lifecycle ends. Containers might represent long-running processes like web\\nservers, but can also re\", \"present short-lived processes like batch jobs, which formerly might have been\\nimplemented as Azure W\", \"ebJobs.\\nIf the process fails, the container ends, and the orchestrator takes over. If the orchestrat\", \"or was\\nconfigured to keep five instances running and one fails, the orchestrator will create another\", \" container\\ninstance to replace the failed process. In a batch job, the process is started with param\", \"eters. When the\\nprocess completes, the work is complete. This guidance drills-down on orchestrators,\", \" later on.\\n18 CHAPTER 3 | Architecting container and microservice-based applicationsYou might find a\", \" scenario where you want multiple processes running in a single container. For that\\nscenario, since \", \"there can be only one entry point per container, you could run a script within the\\ncontainer that la\", \"unches as many programs as needed. For example, you can use Supervisor or a\\nsimilar tool to take car\", \"e of launching multiple processes inside a single container. However, even\\nthough you can find archi\", \"tectures that hold multiple processes per container, that approach isn\\u2019t very\\ncommon.\\nContainerizing\", \" monolithic applications\\nYou might want to build a single, monolithically deployed web application o\", \"r service and deploy it as\\na container. The application itself might not be internally monolithic, b\", \"ut structured as several\\nlibraries, components, or even layers (application layer, domain layer, dat\", \"a-access layer, etc.).\\nExternally, however, it\\u2019s a single container\\u2014a single process, a single web a\", \"pplication, or a single\\nservice.\\nTo manage this model, you deploy a single container to represent th\", \"e application. To increase\\ncapacity, you scale out, that is, just add more copies with a load balanc\", \"er in front. The simplicity\\ncomes from managing a single deployment in a single container or VM.\\nFig\", \"ure 4-1. Example of the architecture of a containerized monolithic application\\nYou can include multi\", \"ple components, libraries, or internal layers in each container, as illustrated in\\nFigure 4-1. A mon\", \"olithic containerized application has most of its functionality within a single\\ncontainer, with inte\", \"rnal layers or libraries, and scales out by cloning the container on multiple\\nservers/VMs. However, \", \"this monolithic pattern might conflict with the container principle \\u201ca container\\ndoes one thing, and\", \" does it in one process\\u201d, but might be ok for some cases.\\nThe downside of this approach becomes evid\", \"ent if the application grows, requiring it to scale. If the\\nentire application can scale, it isn\\u2019t r\", \"eally a problem. However, in most cases, just a few parts of the\\napplication are the choke points th\", \"at require scaling, while other components are used less.\\nFor example, in a typical e-commerce appli\", \"cation, you likely need to scale the product information\\nsubsystem, because many more customers brow\", \"se products than purchase them. More customers use\\n19 CHAPTER 3 | Architecting container and microse\", \"rvice-based applicationstheir basket than use the payment pipeline. Fewer customers add comments or \", \"view their purchase\\nhistory. And you might have only a handful of employees that need to manage the \", \"content and\\nmarketing campaigns. If you scale the monolithic design, all the code for these differen\", \"t tasks is\\ndeployed multiple times and scaled at the same grade.\\nThere are multiple ways to scale an\", \" application-horizontal duplication, splitting different areas of the\\napplication, and partitioning \", \"similar business concepts or data. But, in addition to the problem of\\nscaling all components, change\", \"s to a single component require complete retesting of the entire\\napplication, and a complete redeplo\", \"yment of all the instances.\\nHowever, the monolithic approach is common, because the development of t\", \"he application is initially\\neasier than for microservices approaches. Thus, many organizations devel\", \"op using this architectural\\napproach. While some organizations have had good enough results, others \", \"are hitting limits. Many\\norganizations designed their applications using this model because tools an\", \"d infrastructure made it\\ntoo difficult to build service-oriented architectures (SOA) years ago, and \", \"they did not see the need-\\nuntil the application grew.\\nFrom an infrastructure perspective, each serv\", \"er can run many applications within the same host and\\nhave an acceptable ratio of efficiency in reso\", \"urces usage, as shown in Figure 4-2.\\nFigure 4-2. Monolithic approach: Host running multiple apps, ea\", \"ch app running as a container\\nMonolithic applications in Microsoft Azure can be deployed using dedic\", \"ated VMs for each instance.\\nAdditionally, using Azure virtual machine scale sets, you can easily sca\", \"le the VMs. Azure App Service\\ncan also run monolithic applications and easily scale instances withou\", \"t requiring you to manage the\\nVMs. Since 2016, Azure App Services can run single instances of Docker\", \" containers as well, simplifying\\ndeployment.\\nAs a QA environment or a limited production environment\", \", you can deploy multiple Docker host VMs\\nand balance them using the Azure balancer, as shown in Fig\", \"ure 4-3. This lets you manage scaling with\\na coarse-grain approach, because the whole application li\", \"ves within a single container.\\n20 CHAPTER 3 | Architecting container and microservice-based applicat\", \"ionsFigure 4-3. Example of multiple hosts scaling up a single container application\\nDeployment to th\", \"e various hosts can be managed with traditional deployment techniques. Docker\\nhosts can be managed w\", \"ith commands like docker run or docker-compose performed manually, or\\nthrough automation such as con\", \"tinuous delivery (CD) pipelines.\\nDeploying a monolithic application as a container\\nThere are benefit\", \"s to using containers to manage monolithic application deployments. Scaling\\ncontainer instances is f\", \"ar faster and easier than deploying additional VMs. Even if you use virtual\\nmachine scale sets, VMs \", \"take time to start. When deployed as traditional application instances instead\\nof containers, the co\", \"nfiguration of the application is managed as part of the VM, which isn\\u2019t ideal.\\nDeploying updates as\", \" Docker images is far faster and network efficient. Docker images typically start\\nin seconds, which \", \"speeds rollouts. Tearing down a Docker image instance is as easy as issuing a\\ndocker stop command, a\", \"nd typically completes in less than a second.\\nBecause containers are immutable by design, you never \", \"need to worry about corrupted VMs. In\\ncontrast, update scripts for a VM might forget to account for \", \"some specific configuration or file left on\\ndisk.\\nWhile monolithic applications can benefit from Doc\", \"ker, we\\u2019re touching only on the benefits.\\nAdditional benefits of managing containers come from deplo\", \"ying with container orchestrators, which\\nmanage the various instances and lifecycle of each containe\", \"r instance. Breaking up the monolithic\\napplication into subsystems that can be scaled, developed, an\", \"d deployed individually is your entry\\npoint into the realm of microservices.\\nPublishing a single-con\", \"tainer-based application to Azure App Service\\nWhether you want to get validation of a container depl\", \"oyed to Azure or when an application is simply\\na single-container application, Azure App Service pro\", \"vides a great way to provide scalable single-\\ncontainer-based services. Using Azure App Service is s\", \"imple. It provides great integration with Git to\\nmake it easy to take your code, build it in Visual \", \"Studio, and deploy it directly to Azure.\\n21 CHAPTER 3 | Architecting container and microservice-base\", \"d applicationsFigure 4-4. Publishing a single-container application to Azure App Service from Visual\", \" Studio 2022\\nWithout Docker, if you needed other capabilities, frameworks, or dependencies that aren\", \"\\u2019t supported\\nin Azure App Service, you had to wait until the Azure team updated those dependencies i\", \"n App\\nService. Or you had to switch to other services like Azure Cloud Services or VMs, where you ha\", \"d\\nfurther control and you could install a required component or framework for your application.\\nCont\", \"ainer support in Visual Studio 2017 and later gives you the ability to include whatever you want\\nin \", \"your application environment, as shown in Figure 4-4. Since you\\u2019re running it in a container, if you\", \"\\nadd a dependency to your application, you can include the dependency in your Dockerfile or Docker\\ni\", \"mage.\\nAs also shown in Figure 4-4, the publish flow pushes an image through a container registry. Th\", \"is can\\nbe the Azure Container Registry (a registry close to your deployments in Azure and secured by\", \" Azure\\nActive Directory groups and accounts), or any other Docker registry, like Docker Hub or an on\", \"-\\npremises registry.\\nManage state and data in Docker applications\\nIn most cases, you can think of a \", \"container as an instance of a process. A process doesn\\u2019t maintain\\npersistent state. While a containe\", \"r can write to its local storage, assuming that an instance will be\\naround indefinitely would be lik\", \"e assuming that a single location in memory will be durable. You\\n22 CHAPTER 3 | Architecting contain\", \"er and microservice-based applicationsshould assume that container images, like processes, have mult\", \"iple instances or will eventually be\\nkilled. If they\\u2019re managed with a container orchestrator, you s\", \"hould assume that they might get\\nmoved from one node or VM to another.\\nThe following solutions are u\", \"sed to manage data in Docker applications:\\nFrom the Docker host, as Docker Volumes:\\n\\u2022 Volumes are st\", \"ored in an area of the host filesystem that\\u2019s managed by Docker.\\n\\u2022 Bind mounts can map to any folder\", \" in the host filesystem, so access can\\u2019t be controlled from\\nDocker process and can pose a security r\", \"isk as a container could access sensitive OS folders.\\n\\u2022 tmpfs mounts are like virtual folders that o\", \"nly exist in the host\\u2019s memory and are never\\nwritten to the filesystem.\\nFrom remote storage:\\n\\u2022 Azure\", \" Storage, which provides geo-distributable storage, providing a good long-term\\npersistence solution \", \"for containers.\\n\\u2022 Remote relational databases like Azure SQL Database or NoSQL databases like Azure \", \"Cosmos\\nDB, or cache services like Redis.\\nFrom the Docker container:\\n\\u2022 Overlay File System. This Dock\", \"er feature implements a copy-on-write task that stores\\nupdated information to the root file system o\", \"f the container. That information is \\u201con top\\u201d of\\nthe original image on which the container is based.\", \" If the container is deleted from the\\nsystem, those changes are lost. Therefore, while it\\u2019s possible\", \" to save the state of a container\\nwithin its local storage, designing a system around this would con\", \"flict with the premise of\\ncontainer design, which by default is stateless.\\nHowever, using Docker Vol\", \"umes is now the preferred way to handle local data in Docker. If you need\\nmore information about sto\", \"rage in containers check on Docker storage drivers and About storage\\ndrivers.\\nThe following provides\", \" more detail about these options:\\nVolumes are directories mapped from the host OS to directories in \", \"containers. When code in the\\ncontainer has access to the directory, that access is actually to a dir\", \"ectory on the host OS. This\\ndirectory is not tied to the lifetime of the container itself, and the d\", \"irectory is managed by Docker and\\nisolated from the core functionality of the host machine. Thus, da\", \"ta volumes are designed to persist\\ndata independently of the life of the container. If you delete a \", \"container or an image from the Docker\\nhost, the data persisted in the data volume isn\\u2019t deleted.\\nVol\", \"umes can be named or anonymous (the default). Named volumes are the evolution of Data\\nVolume Contain\", \"ers and make it easy to share data between containers. Volumes also support\\nvolume drivers that allo\", \"w you to store data on remote hosts, among other options.\\nBind mounts are available since a long tim\", \"e ago and allow the mapping of any folder to a mount\\npoint in a container. Bind mounts have more lim\", \"itations than volumes and some important security\\nissues, so volumes are the recommended option.\\n23 \", \"CHAPTER 3 | Architecting container and microservice-based applicationstmpfs mounts are basically vir\", \"tual folders that live only in the host\\u2019s memory and are never written to\\nthe filesystem. They are f\", \"ast and secure but use memory and are only meant for temporary, non-\\npersistent data.\\nAs shown in Fi\", \"gure 4-5, regular Docker volumes can be stored outside of the containers themselves\\nbut within the p\", \"hysical boundaries of the host server or VM. However, Docker containers can\\u2019t access\\na volume from o\", \"ne host server or VM to another. In other words, with these volumes, it isn\\u2019t possible\\nto manage dat\", \"a shared between containers that run on different Docker hosts, although it could be\\nachieved with a\", \" volume driver that supports remote hosts.\\nFigure 4-5. Volumes and external data sources for contain\", \"er-based applications\\nVolumes can be shared between containers, but only in the same host, unless yo\", \"u use a remote driver\\nthat supports remote hosts. In addition, when Docker containers are managed by\", \" an orchestrator,\\ncontainers might \\u201cmove\\u201d between hosts, depending on the optimizations performed by\", \" the cluster.\\nTherefore, it isn\\u2019t recommended that you use data volumes for business data. But they\\u2019\", \"re a good\\nmechanism to work with trace files, temporal files, or similar that will not impact busine\", \"ss data\\nconsistency.\\nRemote data sources and cache tools like Azure SQL Database, Azure Cosmos DB, o\", \"r a remote cache\\nlike Redis can be used in containerized applications the same way they are used whe\", \"n developing\\nwithout containers. This is a proven way to store business application data.\\nAzure Stor\", \"age. Business data usually will need to be placed in external resources or databases, like\\nAzure Sto\", \"rage. Azure Storage, in concrete, provides the following services in the cloud:\\n\\u2022 Blob storage store\", \"s unstructured object data. A blob can be any type of text or binary data,\\nsuch as document or media\", \" files (images, audio, and video files). Blob storage is also referred\\nto as Object storage.\\n24 CHAP\", \"TER 3 | Architecting container and microservice-based applications\\u2022 File storage offers shared stora\", \"ge for legacy applications using standard SMB protocol. Azure\\nvirtual machines and cloud services ca\", \"n share file data across application components via\\nmounted shares. On-premises applications can acc\", \"ess file data in a share via the File service\\nREST API.\\n\\u2022 Table storage stores structured datasets. \", \"Table storage is a NoSQL key-attribute data store,\\nwhich allows rapid development and fast access to\", \" large quantities of data.\\nRelational databases and NoSQL databases. There are many choices for exte\", \"rnal databases, from\\nrelational databases like SQL Server, PostgreSQL, Oracle, or NoSQL databases li\", \"ke Azure Cosmos DB,\\nMongoDB, etc. These databases are not going to be explained as part of this guid\", \"e since they are in a\\ncompletely different subject.\\nService-oriented architecture\\nService-oriented a\", \"rchitecture (SOA) was an overused term and has meant different things to different\\npeople. But as a \", \"common denominator, SOA means that you structure your application by\\ndecomposing it into multiple se\", \"rvices (most commonly as HTTP services) that can be classified as\\ndifferent types like subsystems or\", \" tiers.\\nThose services can now be deployed as Docker containers, which solves deployment issues, bec\", \"ause\\nall the dependencies are included in the container image. However, when you need to scale up SO\", \"A\\napplications, you might have scalability and availability challenges if you\\u2019re deploying based on \", \"single\\nDocker hosts. This is where Docker clustering software or an orchestrator can help you, as ex\", \"plained in\\nlater sections where deployment approaches for microservices are described.\\nDocker contai\", \"ners are useful (but not required) for both traditional service-oriented architectures and\\nthe more \", \"advanced microservices architectures.\\nMicroservices derive from SOA, but SOA is different from micro\", \"services architecture. Features like\\nlarge central brokers, central orchestrators at the organizatio\", \"n level, and the Enterprise Service Bus\\n(ESB) are typical in SOA. But in most cases, these are anti-\", \"patterns in the microservice community. In\\nfact, some people argue that \\u201cThe microservice architectu\", \"re is SOA done right.\\u201d\\nThis guide focuses on microservices, because a SOA approach is less prescript\", \"ive than the\\nrequirements and techniques used in a microservice architecture. If you know how to bui\", \"ld a\\nmicroservice-based application, you also know how to build a simpler service-oriented applicati\", \"on.\\nMicroservices architecture\\nAs the name implies, a microservices architecture is an approach to b\", \"uilding a server application as a\\nset of small services. That means a microservices architecture is \", \"mainly oriented to the back-end,\\nalthough the approach is also being used for the front end. Each se\", \"rvice runs in its own process and\\ncommunicates with other processes using protocols such as HTTP/HTT\", \"PS, WebSockets, or AMQP.\\nEach microservice implements a specific end-to-end domain or business capab\", \"ility within a certain\\ncontext boundary, and each must be developed autonomously and be deployable i\", \"ndependently.\\nFinally, each microservice should own its related domain data model and domain logic (\", \"sovereignty\\n25 CHAPTER 3 | Architecting container and microservice-based applicationsand decentraliz\", \"ed data management) and could be based on different data storage technologies\\n(SQL, NoSQL) and diffe\", \"rent programming languages.\\nWhat size should a microservice be? When developing a microservice, size\", \" shouldn\\u2019t be the important\\npoint. Instead, the important point should be to create loosely coupled \", \"services so you have\\nautonomy of development, deployment, and scale, for each service. Of course, wh\", \"en identifying and\\ndesigning microservices, you should try to make them as small as possible as long\", \" as you don\\u2019t have\\ntoo many direct dependencies with other microservices. More important than the si\", \"ze of the\\nmicroservice is the internal cohesion it must have and its independence from other service\", \"s.\\nWhy a microservices architecture? In short, it provides long-term agility. Microservices enable b\", \"etter\\nmaintainability in complex, large, and highly-scalable systems by letting you create applicati\", \"ons based\\non many independently deployable services that each have granular and autonomous lifecycle\", \"s.\\nAs an additional benefit, microservices can scale out independently. Instead of having a single\\nm\", \"onolithic application that you must scale out as a unit, you can instead scale out specific\\nmicroser\", \"vices. That way, you can scale just the functional area that needs more processing power or\\nnetwork \", \"bandwidth to support demand, rather than scaling out other areas of the application that\\ndon\\u2019t need \", \"to be scaled. That means cost savings because you need less hardware.\\nFigure 4-6. Monolithic deploym\", \"ent versus the microservices approach\\nAs Figure 4-6 shows, in the traditional monolithic approach, t\", \"he application scales by cloning the\\nwhole app in several servers/VM. In the microservices approach,\", \" functionality is segregated in smaller\\nservices, so each service can scale independently. The micro\", \"services approach allows agile changes\\nand rapid iteration of each microservice, because you can cha\", \"nge specific, small areas of complex,\\nlarge, and scalable applications.\\nArchitecting fine-grained mi\", \"croservices-based applications enables continuous integration and\\ncontinuous delivery practices. It \", \"also accelerates delivery of new functions into the application. Fine-\\ngrained composition of applic\", \"ations also allows you to run and test microservices in isolation, and to\\n26 CHAPTER 3 | Architectin\", \"g container and microservice-based applicationsevolve them autonomously while maintaining clear cont\", \"racts between them. As long as you don\\u2019t\\nchange the interfaces or contracts, you can change the inte\", \"rnal implementation of any microservice or\\nadd new functionality without breaking other microservice\", \"s.\\nThe following are important aspects to enable success in going into production with a microservic\", \"es-\\nbased system:\\n\\u2022 Monitoring and health checks of the services and infrastructure.\\n\\u2022 Scalable infr\", \"astructure for the services (that is, cloud and orchestrators).\\n\\u2022 Security design and implementation\", \" at multiple levels: authentication, authorization, secrets\\nmanagement, secure communication, etc.\\n\\u2022\", \" Rapid application delivery, usually with different teams focusing on different microservices.\\n\\u2022 Dev\", \"Ops and CI/CD practices and infrastructure.\\nOf these, only the first three are covered or introduced\", \" in this guide. The last two points, which are\\nrelated to application lifecycle, are covered in the \", \"additional Containerized Docker Application\\nLifecycle with Microsoft Platform and Tools e-book.\\nAddi\", \"tional resources\\n\\u2022 Mark Russinovich. Microservices: An application revolution powered by the cloud\\nh\", \"ttps://azure.microsoft.com/blog/microservices-an-application-revolution-powered-by-the-\\ncloud/\\n\\u2022 Mar\", \"tin Fowler. Microservices\\nhttps://www.martinfowler.com/articles/microservices.html\\n\\u2022 Martin Fowler. \", \"Microservice Prerequisites\\nhttps://martinfowler.com/bliki/MicroservicePrerequisites.html\\n\\u2022 Jimmy Nil\", \"sson. Chunk Cloud Computing\\nhttps://www.infoq.com/articles/CCC-Jimmy-Nilsson\\n\\u2022 Cesar de la Torre. Co\", \"ntainerized Docker Application Lifecycle with Microsoft Platform\\nand Tools (downloadable e-book)\\nhtt\", \"ps://aka.ms/dockerlifecycleebook\\nData sovereignty per microservice\\nAn important rule for microservic\", \"es architecture is that each microservice must own its domain data\\nand logic. Just as a full applica\", \"tion owns its logic and data, so must each microservice own its logic\\nand data under an autonomous l\", \"ifecycle, with independent deployment per microservice.\\nThis means that the conceptual model of the \", \"domain will differ between subsystems or microservices.\\nConsider enterprise applications, where cust\", \"omer relationship management (CRM) applications,\\n27 CHAPTER 3 | Architecting container and microserv\", \"ice-based applicationstransactional purchase subsystems, and customer support subsystems each call o\", \"n unique customer\\nentity attributes and data, and where each employs a different Bounded Context (BC\", \").\\nThis principle is similar in Domain-driven design (DDD), where each Bounded Context or autonomous\", \"\\nsubsystem or service must own its domain model (data plus logic and behavior). Each DDD Bounded\\nCon\", \"text correlates to one business microservice (one or several services). This point about the\\nBounded\", \" Context pattern is expanded in the next section.\\nOn the other hand, the traditional (monolithic dat\", \"a) approach used in many applications is to have a\\nsingle centralized database or just a few databas\", \"es. This is often a normalized SQL database that\\u2019s\\nused for the whole application and all its intern\", \"al subsystems, as shown in Figure 4-7.\\nFigure 4-7. Data sovereignty comparison: monolithic database \", \"versus microservices\\nIn the traditional approach, there\\u2019s a single database shared across all servic\", \"es, typically in a tiered\\narchitecture. In the microservices approach, each microservice owns its mo\", \"del/data. The centralized\\ndatabase approach initially looks simpler and seems to enable reuse of ent\", \"ities in different subsystems\\nto make everything consistent. But the reality is you end up with huge\", \" tables that serve many different\\nsubsystems, and that include attributes and columns that aren\\u2019t ne\", \"eded in most cases. It\\u2019s like trying\\nto use the same physical map for hiking a short trail, taking a\", \" day-long car trip, and learning\\ngeography.\\nA monolithic application with typically a single relatio\", \"nal database has two important benefits: ACID\\ntransactions and the SQL language, both working across\", \" all the tables and data related to your\\napplication. This approach provides a way to easily write a\", \" query that combines data from multiple\\ntables.\\nHowever, data access becomes much more complicated w\", \"hen you move to a microservices\\narchitecture. Even when using ACID transactions within a microservic\", \"e or Bounded Context, it is crucial\\nto consider that the data owned by each microservice is private \", \"to that microservice and should only\\n28 CHAPTER 3 | Architecting container and microservice-based ap\", \"plicationsbe accessed either synchronously through its API endpoints(REST, gRPC, SOAP, etc) or async\", \"hronously\\nvia messaging(AMQP or similar).\\nEncapsulating the data ensures that the microservices are \", \"loosely coupled and can evolve\\nindependently of one another. If multiple services were accessing the\", \" same data, schema updates\\nwould require coordinated updates to all the services. This would break t\", \"he microservice lifecycle\\nautonomy. But distributed data structures mean that you can\\u2019t make a singl\", \"e ACID transaction across\\nmicroservices. This in turn means you must use eventual consistency when a\", \" business process spans\\nmultiple microservices. This is much harder to implement than simple SQL joi\", \"ns, because you can\\u2019t\\ncreate integrity constraints or use distributed transactions between separate \", \"databases, as we\\u2019ll\\nexplain later on. Similarly, many other relational database features aren\\u2019t avai\", \"lable across multiple\\nmicroservices.\\nGoing even further, different microservices often use different\", \" kinds of databases. Modern\\napplications store and process diverse kinds of data, and a relational d\", \"atabase isn\\u2019t always the best\\nchoice. For some use cases, a NoSQL database such as Azure CosmosDB or\", \" MongoDB might have a\\nmore convenient data model and offer better performance and scalability than a\", \" SQL database like\\nSQL Server or Azure SQL Database. In other cases, a relational database is still \", \"the best approach.\\nTherefore, microservices-based applications often use a mixture of SQL and NoSQL \", \"databases, which\\nis sometimes called the polyglot persistence approach.\\nA partitioned, polyglot-pers\", \"istent architecture for data storage has many benefits. These include\\nloosely coupled services and b\", \"etter performance, scalability, costs, and manageability. However, it can\\nintroduce some distributed\", \" data management challenges, as explained in \\u201cIdentifying domain-model\\nboundaries\\u201d later in this cha\", \"pter.\\nThe relationship between microservices and the Bounded Context\\npattern\\nThe concept of microser\", \"vice derives from the Bounded Context (BC) pattern in domain-driven design\\n(DDD). DDD deals with lar\", \"ge models by dividing them into multiple BCs and being explicit about their\\nboundaries. Each BC must\", \" have its own model and database; likewise, each microservice owns its\\nrelated data. In addition, ea\", \"ch BC usually has its own ubiquitous language to help communication\\nbetween software developers and \", \"domain experts.\\nThose terms (mainly domain entities) in the ubiquitous language can have different n\", \"ames in different\\nBounded Contexts, even when different domain entities share the same identity (tha\", \"t is, the unique ID\\nthat\\u2019s used to read the entity from storage). For instance, in a user-profile Bo\", \"unded Context, the User\\ndomain entity might share identity with the Buyer domain entity in the order\", \"ing Bounded Context.\\nA microservice is therefore like a Bounded Context, but it also specifies that \", \"it\\u2019s a distributed service.\\nIt\\u2019s built as a separate process for each Bounded Context, and it must u\", \"se the distributed protocols\\nnoted earlier, like HTTP/HTTPS, WebSockets, or AMQP. The Bounded Contex\", \"t pattern, however,\\ndoesn\\u2019t specify whether the Bounded Context is a distributed service or if it\\u2019s \", \"simply a logical\\nboundary (such as a generic subsystem) within a monolithic-deployment application.\\n\", \"It\\u2019s important to highlight that defining a service for each Bounded Context is a good place to star\", \"t.\\nBut you don\\u2019t have to constrain your design to it. Sometimes you must design a Bounded Context or\", \"\\n29 CHAPTER 3 | Architecting container and microservice-based applicationsbusiness microservice comp\", \"osed of several physical services. But ultimately, both patterns -Bounded\\nContext and microservice- \", \"are closely related.\\nDDD benefits from microservices by getting real boundaries in the form of distr\", \"ibuted microservices.\\nBut ideas like not sharing the model between microservices are what you also w\", \"ant in a Bounded\\nContext.\\nAdditional resources\\n\\u2022 Chris Richardson. Pattern: Database per service\\nhtt\", \"ps://microservices.io/patterns/data/database-per-service.html\\n\\u2022 Martin Fowler. BoundedContext\\nhttps:\", \"//martinfowler.com/bliki/BoundedContext.html\\n\\u2022 Martin Fowler. PolyglotPersistence\\nhttps://martinfowl\", \"er.com/bliki/PolyglotPersistence.html\\n\\u2022 Alberto Brandolini. Strategic Domain Driven Design with Cont\", \"ext Mapping\\nhttps://www.infoq.com/articles/ddd-contextmapping\\nLogical architecture versus physical a\", \"rchitecture\\nIt\\u2019s useful at this point to stop and discuss the distinction between logical architectu\", \"re and physical\\narchitecture, and how this applies to the design of microservice-based applications.\", \"\\nTo begin, building microservices doesn\\u2019t require the use of any specific technology. For instance,\\n\", \"Docker containers aren\\u2019t mandatory to create a microservice-based architecture. Those microservices\\n\", \"could also be run as plain processes. Microservices is a logical architecture.\\nMoreover, even when a\", \" microservice could be physically implemented as a single service, process, or\\ncontainer (for simpli\", \"city\\u2019s sake, that\\u2019s the approach taken in the initial version of eShopOnContainers),\\nthis parity bet\", \"ween business microservice and physical service or container isn\\u2019t necessarily required in\\nall cases\", \" when you build a large and complex application composed of many dozens or even\\nhundreds of services\", \".\\nThis is where there\\u2019s a difference between an application\\u2019s logical architecture and physical\\narch\", \"itecture. The logical architecture and logical boundaries of a system do not necessarily map one-\\nto\", \"-one to the physical or deployment architecture. It can happen, but it often doesn\\u2019t.\\nAlthough you m\", \"ight have identified certain business microservices or Bounded Contexts, it doesn\\u2019t\\nmean that the be\", \"st way to implement them is always by creating a single service (such as an ASP.NET\\nWeb API) or sing\", \"le Docker container for each business microservice. Having a rule saying each\\nbusiness microservice \", \"has to be implemented using a single service or container is too rigid.\\nTherefore, a business micros\", \"ervice or Bounded Context is a logical architecture that might coincide (or\\nnot) with physical archi\", \"tecture. The important point is that a business microservice or Bounded\\nContext must be autonomous b\", \"y allowing code and state to be independently versioned, deployed,\\nand scaled.\\n30 CHAPTER 3 | Archit\", \"ecting container and microservice-based applicationsAs Figure 4-8 shows, the catalog business micros\", \"ervice could be composed of several services or\\nprocesses. These could be multiple ASP.NET Web API s\", \"ervices or any other kind of services using\\nHTTP or any other protocol. More importantly, the servic\", \"es could share the same data, as long as\\nthese services are cohesive with respect to the same busine\", \"ss domain.\\nFigure 4-8. Business microservice with several physical services\\nThe services in the exam\", \"ple share the same data model because the Web API service targets the same\\ndata as the Search servic\", \"e. So, in the physical implementation of the business microservice, you\\u2019re\\nsplitting that functional\", \"ity so you can scale each of those internal services up or down as needed.\\nMaybe the Web API service\", \" usually needs more instances than the Search service, or vice versa.\\nIn short, the logical architec\", \"ture of microservices doesn\\u2019t always have to coincide with the physical\\ndeployment architecture. In \", \"this guide, whenever we mention a microservice, we mean a business or\\nlogical microservice that coul\", \"d map to one or more (physical) services. In most cases, this will be a\\nsingle service, but it might\", \" be more.\\nChallenges and solutions for distributed data\\nmanagement\\nChallenge #1: How to define the b\", \"oundaries of each microservice\\nDefining microservice boundaries is probably the first challenge anyo\", \"ne encounters. Each microservice\\nhas to be a piece of your application and each microservice should \", \"be autonomous with all the\\nbenefits and challenges that it conveys. But how do you identify those bo\", \"undaries?\\nFirst, you need to focus on the application\\u2019s logical domain models and related data. Try \", \"to identify\\ndecoupled islands of data and different contexts within the same application. Each conte\", \"xt could have\\na different business language (different business terms). The contexts should be defin\", \"ed and managed\\nindependently. The terms and entities that are used in those different contexts might\", \" sound similar,\\nbut you might discover that in a particular context, a business concept with one is \", \"used for a different\\n31 CHAPTER 3 | Architecting container and microservice-based applicationspurpos\", \"e in another context, and might even have a different name. For instance, a user can be\\nreferred as \", \"a user in the identity or membership context, as a customer in a CRM context, as a buyer in\\nan order\", \"ing context, and so forth.\\nThe way you identify boundaries between multiple application contexts wit\", \"h a different domain for\\neach context is exactly how you can identify the boundaries for each busine\", \"ss microservice and its\\nrelated domain model and data. You always attempt to minimize the coupling b\", \"etween those\\nmicroservices. This guide goes into more detail about this identification and domain mo\", \"del design in\\nthe section Identifying domain-model boundaries for each microservice later.\\nChallenge\", \" #2: How to create queries that retrieve data from several\\nmicroservices\\nA second challenge is how t\", \"o implement queries that retrieve data from several microservices, while\\navoiding chatty communicati\", \"on to the microservices from remote client apps. An example could be a\\nsingle screen from a mobile a\", \"pp that needs to show user information that\\u2019s owned by the basket,\\ncatalog, and user identity micros\", \"ervices. Another example would be a complex report involving many\\ntables located in multiple microse\", \"rvices. The right solution depends on the complexity of the queries.\\nBut in any case, you\\u2019ll need a \", \"way to aggregate information if you want to improve the efficiency in\\nthe communications of your sys\", \"tem. The most popular solutions are the following.\\nAPI Gateway. For simple data aggregation from mul\", \"tiple microservices that own different databases,\\nthe recommended approach is an aggregation microse\", \"rvice referred to as an API Gateway. However,\\nyou need to be careful about implementing this pattern\", \", because it can be a choke point in your\\nsystem, and it can violate the principle of microservice a\", \"utonomy. To mitigate this possibility, you can\\nhave multiple fined-grained API Gateways each one foc\", \"using on a vertical \\u201cslice\\u201d or business area of\\nthe system. The API Gateway pattern is explained in \", \"more detail in the API Gateway section later.\\nGraphQL Federation One option to consider if your micr\", \"oservices are already using GraphQL is\\nGraphQL Federation. Federation allows you to define \\u201csubgraph\", \"s\\u201d from other services and compose\\nthem into an aggregate \\u201csupergraph\\u201d that acts as a standalone sch\", \"ema.\\nCQRS with query/reads tables. Another solution for aggregating data from multiple microservices\", \" is\\nthe Materialized View pattern. In this approach, you generate, in advance (prepare denormalized \", \"data\\nbefore the actual queries happen), a read-only table with the data that\\u2019s owned by multiple\\nmic\", \"roservices. The table has a format suited to the client app\\u2019s needs.\\nConsider something like the scr\", \"een for a mobile app. If you have a single database, you might pull\\ntogether the data for that scree\", \"n using a SQL query that performs a complex join involving multiple\\ntables. However, when you have m\", \"ultiple databases, and each database is owned by a different\\nmicroservice, you cannot query those da\", \"tabases and create a SQL join. Your complex query becomes\\na challenge. You can address the requireme\", \"nt using a CQRS approach\\u2014you create a denormalized\\ntable in a different database that\\u2019s used just fo\", \"r queries. The table can be designed specifically for the\\ndata you need for the complex query, with \", \"a one-to-one relationship between fields needed by your\\napplication\\u2019s screen and the columns in the \", \"query table. It could also serve for reporting purposes.\\nThis approach not only solves the original \", \"problem (how to query and join across microservices), but it\\nalso improves performance considerably \", \"when compared with a complex join, because you already\\n32 CHAPTER 3 | Architecting container and mic\", \"roservice-based applicationshave the data that the application needs in the query table. Of course, \", \"using Command and Query\\nResponsibility Segregation (CQRS) with query/reads tables means additional d\", \"evelopment work, and\\nyou\\u2019ll need to embrace eventual consistency. Nonetheless, requirements on perfo\", \"rmance and high\\nscalability in collaborative scenarios (or competitive scenarios, depending on the p\", \"oint of view) are\\nwhere you should apply CQRS with multiple databases.\\n\\u201cCold data\\u201d in central databa\", \"ses. For complex reports and queries that might not require real-time\\ndata, a common approach is to \", \"export your \\u201chot data\\u201d (transactional data from the microservices) as\\n\\u201ccold data\\u201d into large databas\", \"es that are used only for reporting. That central database system can be\\na Big Data-based system, li\", \"ke Hadoop; a data warehouse like one based on Azure SQL Data\\nWarehouse; or even a single SQL databas\", \"e that\\u2019s used just for reports (if size won\\u2019t be an issue).\\nKeep in mind that this centralized datab\", \"ase would be used only for queries and reports that do not\\nneed real-time data. The original updates\", \" and transactions, as your source of truth, have to be in your\\nmicroservices data. The way you would\", \" synchronize data would be either by using event-driven\\ncommunication (covered in the next sections)\", \" or by using other database infrastructure import/export\\ntools. If you use event-driven communicatio\", \"n, that integration process would be similar to the way\\nyou propagate data as described earlier for \", \"CQRS query tables.\\nHowever, if your application design involves constantly aggregating information f\", \"rom multiple\\nmicroservices for complex queries, it might be a symptom of a bad design -a microservic\", \"e should be\\nas isolated as possible from other microservices. (This excludes reports/analytics that \", \"always should\\nuse cold-data central databases.) Having this problem often might be a reason to merge\", \"\\nmicroservices. You need to balance the autonomy of evolution and deployment of each microservice\\nwi\", \"th strong dependencies, cohesion, and data aggregation.\\nChallenge #3: How to achieve consistency acr\", \"oss multiple\\nmicroservices\\nAs stated previously, the data owned by each microservice is private to t\", \"hat microservice and can only\\nbe accessed using its microservice API. Therefore, a challenge present\", \"ed is how to implement end-to-\\nend business processes while keeping consistency across multiple micr\", \"oservices.\\nTo analyze this problem, let\\u2019s look at an example from the eShopOnContainers reference ap\", \"plication.\\nThe Catalog microservice maintains information about all the products, including the prod\", \"uct price.\\nThe Basket microservice manages temporal data about product items that users are adding t\", \"o their\\nshopping baskets, which includes the price of the items at the time they were added to the b\", \"asket.\\nWhen a product\\u2019s price is updated in the catalog, that price should also be updated in the ac\", \"tive\\nbaskets that hold that same product, plus the system should probably warn the user saying that \", \"a\\nparticular item\\u2019s price has changed since they added it to their basket.\\nIn a hypothetical monolit\", \"hic version of this application, when the price changes in the products table,\\nthe catalog subsystem\", \" could simply use an ACID transaction to update the current price in the Basket\\ntable.\\nHowever, in a\", \" microservices-based application, the Product and Basket tables are owned by their\\nrespective micros\", \"ervices. No microservice should ever include tables/storage owned by another\\nmicroservice in its own\", \" transactions, not even in direct queries, as shown in Figure 4-9.\\n33 CHAPTER 3 | Architecting conta\", \"iner and microservice-based applicationsFigure 4-9. A microservice can\\u2019t directly access a table in \", \"another microservice\\nThe Catalog microservice shouldn\\u2019t update the Basket table directly, because th\", \"e Basket table is\\nowned by the Basket microservice. To make an update to the Basket microservice, th\", \"e Catalog\\nmicroservice should use eventual consistency probably based on asynchronous communication \", \"such\\nas integration events (message and event-based communication). This is how the eShopOnContainer\", \"s\\nreference application performs this type of consistency across microservices.\\nAs stated by the CAP\", \" theorem, you need to choose between availability and ACID strong consistency.\\nMost microservice-bas\", \"ed scenarios demand availability and high scalability as opposed to strong\\nconsistency. Mission-crit\", \"ical applications must remain up and running, and developers can work\\naround strong consistency by u\", \"sing techniques for working with weak or eventual consistency. This is\\nthe approach taken by most mi\", \"croservice-based architectures.\\nMoreover, ACID-style or two-phase commit transactions are not just a\", \"gainst microservices principles;\\nmost NoSQL databases (like Azure Cosmos DB, MongoDB, etc.) do not s\", \"upport two-phase commit\\ntransactions, typical in distributed databases scenarios. However, maintaini\", \"ng data consistency across\\nservices and databases is essential. This challenge is also related to th\", \"e question of how to propagate\\nchanges across multiple microservices when certain data needs to be r\", \"edundant\\u2014for example, when\\nyou need to have the product\\u2019s name or description in the Catalog microse\", \"rvice and the Basket\\nmicroservice.\\nA good solution for this problem is to use eventual consistency b\", \"etween microservices articulated\\nthrough event-driven communication and a publish-and-subscribe syst\", \"em. These topics are covered\\nin the section Asynchronous event-driven communication later in this gu\", \"ide.\\n34 CHAPTER 3 | Architecting container and microservice-based applicationsChallenge #4: How to d\", \"esign communication across microservice\\nboundaries\\nCommunicating across microservice boundaries is a\", \" real challenge. In this context, communication\\ndoesn\\u2019t refer to what protocol you should use (HTTP \", \"and REST, AMQP, messaging, and so on). Instead,\\nit addresses what communication style you should use\", \", and especially how coupled your\\nmicroservices should be. Depending on the level of coupling, when \", \"failure occurs, the impact of that\\nfailure on your system will vary significantly.\\nIn a distributed \", \"system like a microservices-based application, with so many artifacts moving around\\nand with distrib\", \"uted services across many servers or hosts, components will eventually fail. Partial\\nfailure and eve\", \"n larger outages will occur, so you need to design your microservices and the\\ncommunication across t\", \"hem considering the common risks in this type of distributed system.\\nA popular approach is to implem\", \"ent HTTP (REST)-based microservices, due to their simplicity. An\\nHTTP-based approach is perfectly ac\", \"ceptable; the issue here is related to how you use it. If you use\\nHTTP requests and responses just t\", \"o interact with your microservices from client applications or from\\nAPI Gateways, that\\u2019s fine. But i\", \"f you create long chains of synchronous HTTP calls across microservices,\\ncommunicating across their \", \"boundaries as if the microservices were objects in a monolithic\\napplication, your application will e\", \"ventually run into problems.\\nFor instance, imagine that your client application makes an HTTP API ca\", \"ll to an individual microservice\\nlike the Ordering microservice. If the Ordering microservice in tur\", \"n calls additional microservices using\\nHTTP within the same request/response cycle, you\\u2019re creating \", \"a chain of HTTP calls. It might sound\\nreasonable initially. However, there are important points to c\", \"onsider when going down this path:\\n\\u2022 Blocking and low performance. Due to the synchronous nature of \", \"HTTP, the original request\\ndoesn\\u2019t get a response until all the internal HTTP calls are finished. Im\", \"agine if the number of\\nthese calls increases significantly and at the same time one of the intermedi\", \"ate HTTP calls to a\\nmicroservice is blocked. The result is that performance is impacted, and the ove\", \"rall scalability\\nwill be exponentially affected as additional HTTP requests increase.\\n\\u2022 Coupling mic\", \"roservices with HTTP. Business microservices shouldn\\u2019t be coupled with other\\nbusiness microservices.\", \" Ideally, they shouldn\\u2019t \\u201cknow\\u201d about the existence of other\\nmicroservices. If your application reli\", \"es on coupling microservices as in the example, achieving\\nautonomy per microservice will be almost i\", \"mpossible.\\n\\u2022 Failure in any one microservice. If you implemented a chain of microservices linked by \", \"HTTP\\ncalls, when any of the microservices fails (and eventually they will fail) the whole chain of\\nm\", \"icroservices will fail. A microservice-based system should be designed to continue to work\\nas well a\", \"s possible during partial failures. Even if you implement client logic that uses retries\\nwith expone\", \"ntial backoff or circuit breaker mechanisms, the more complex the HTTP call\\nchains are, the more com\", \"plex it is to implement a failure strategy based on HTTP.\\nIn fact, if your internal microservices ar\", \"e communicating by creating chains of HTTP requests as\\ndescribed, it could be argued that you have a\", \" monolithic application, but one based on HTTP between\\nprocesses instead of intra-process communicat\", \"ion mechanisms.\\n35 CHAPTER 3 | Architecting container and microservice-based applicationsTherefore, \", \"in order to enforce microservice autonomy and have better resiliency, you should minimize\\nthe use of\", \" chains of request/response communication across microservices. It\\u2019s recommended that\\nyou use only a\", \"synchronous interaction for inter-microservice communication, either by using\\nasynchronous message- \", \"and event-based communication, or by using (asynchronous) HTTP polling\\nindependently of the original\", \" HTTP request/response cycle.\\nThe use of asynchronous communication is explained with additional det\", \"ails later in this guide in the\\nsections Asynchronous microservice integration enforces microservice\", \"\\u2019s autonomy and Asynchronous\\nmessage-based communication.\\nAdditional resources\\n\\u2022 CAP theorem\\nhttps:/\", \"/en.wikipedia.org/wiki/CAP_theorem\\n\\u2022 Eventual consistency\\nhttps://en.wikipedia.org/wiki/Eventual_con\", \"sistency\\n\\u2022 Data Consistency Primer\\nhttps://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v=\", \"pandp.10)\\n\\u2022 Martin Fowler. CQRS (Command and Query Responsibility Segregation)\\nhttps://martinfowler.\", \"com/bliki/CQRS.html\\n\\u2022 Materialized View\\nhttps://learn.microsoft.com/azure/architecture/patterns/mate\", \"rialized-view\\n\\u2022 Charles Row. ACID vs. BASE: The Shifting pH of Database Transaction Processing\\nhttps\", \"://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transaction-\\nprocessing/\\n\\u2022 Compensat\", \"ing Transaction\\nhttps://learn.microsoft.com/azure/architecture/patterns/compensating-transaction\\n\\u2022 U\", \"di Dahan. Service Oriented Composition\\nhttps://udidahan.com/2014/07/30/service-oriented-composition-\", \"with-video/\\nIdentify domain-model boundaries for each\\nmicroservice\\nThe goal when identifying model b\", \"oundaries and size for each microservice isn\\u2019t to get to the most\\ngranular separation possible, alth\", \"ough you should tend toward small microservices if possible.\\nInstead, your goal should be to get to \", \"the most meaningful separation guided by your domain\\nknowledge. The emphasis isn\\u2019t on the size, but \", \"instead on business capabilities. In addition, if there\\u2019s\\nclear cohesion needed for a certain area o\", \"f the application based on a high number of dependencies,\\nthat indicates the need for a single micro\", \"service, too. Cohesion is a way to identify how to break apart\\n36 CHAPTER 3 | Architecting container\", \" and microservice-based applicationsor group together microservices. Ultimately, while you gain more\", \" knowledge about the domain, you\\nshould adapt the size of your microservice, iteratively. Finding th\", \"e right size isn\\u2019t a one-shot process.\\nSam Newman, a recognized promoter of microservices and author\", \" of the book Building Microservices,\\nhighlights that you should design your microservices based on t\", \"he Bounded Context (BC) pattern\\n(part of domain-driven design), as introduced earlier. Sometimes, a \", \"BC could be composed of several\\nphysical services, but not vice versa.\\nA domain model with specific \", \"domain entities applies within a concrete BC or microservice. A BC\\ndelimits the applicability of a d\", \"omain model and gives developer team members a clear and shared\\nunderstanding of what must be cohesi\", \"ve and what can be developed independently. These are the\\nsame goals for microservices.\\nAnother tool\", \" that informs your design choice is Conway\\u2019s law, which states that an application will\\nreflect the \", \"social boundaries of the organization that produced it. But sometimes the opposite is true -\\nthe com\", \"pany\\u2019s organization is formed by the software. You might need to reverse Conway\\u2019s law and\\nbuild the \", \"boundaries the way you want the company to be organized, leaning toward business\\nprocess consulting.\", \"\\nTo identify bounded contexts, you can use a DDD pattern called the Context Mapping pattern. With\\nCo\", \"ntext Mapping, you identify the various contexts in the application and their boundaries. It\\u2019s\\ncommo\", \"n to have a different context and boundary for each small subsystem, for instance. The Context\\nMap i\", \"s a way to define and make explicit those boundaries between domains. A BC is autonomous\\nand include\", \"s the details of a single domain -details like the domain entities- and defines integration\\ncontract\", \"s with other BCs. This is similar to the definition of a microservice: it\\u2019s autonomous, it\\nimplement\", \"s certain domain capability, and it must provide interfaces. This is why Context Mapping\\nand the Bou\", \"nded Context pattern are good approaches for identifying the domain model boundaries\\nof your microse\", \"rvices.\\nWhen designing a large application, you\\u2019ll see how its domain model can be fragmented - a do\", \"main\\nexpert from the catalog domain will name entities differently in the catalog and inventory doma\", \"ins\\nthan a shipping domain expert, for instance. Or the user domain entity might be different in siz\", \"e and\\nnumber of attributes when dealing with a CRM expert who wants to store every detail about the\\n\", \"customer than for an ordering domain expert who just needs partial data about the customer. It\\u2019s ver\", \"y\\nhard to disambiguate all domain terms across all the domains related to a large application. But t\", \"he\\nmost important thing is that you shouldn\\u2019t try to unify the terms. Instead, accept the difference\", \"s and\\nrichness provided by each domain. If you try to have a unified database for the whole applicat\", \"ion,\\nattempts at a unified vocabulary will be awkward and won\\u2019t sound right to any of the multiple d\", \"omain\\nexperts. Therefore, BCs (implemented as microservices) will help you to clarify where you can \", \"use\\ncertain domain terms and where you\\u2019ll need to split the system and create additional BCs with\\ndi\", \"fferent domains.\\nYou\\u2019ll know that you got the right boundaries and sizes of each BC and domain model\", \" if you have few\\nstrong relationships between domain models, and you do not usually need to merge in\", \"formation\\nfrom multiple domain models when performing typical application operations.\\nPerhaps the be\", \"st answer to the question of how large a domain model for each microservice should\\nbe is the followi\", \"ng: it should have an autonomous BC, as isolated as possible, that enables you to\\nwork without havin\", \"g to constantly switch to other contexts (other microservice\\u2019s models). In Figure 4-\\n37 CHAPTER 3 | \", \"Architecting container and microservice-based applications10, you can see how multiple microservices\", \" (multiple BCs) each has their own model and how their\\nentities can be defined, depending on the spe\", \"cific requirements for each of the identified domains in\\nyour application.\\nFigure 4-10. Identifying \", \"entities and microservice model boundaries\\nFigure 4-10 illustrates a sample scenario related to an o\", \"nline conference management system. The\\nsame entity appears as \\u201cUsers\\u201d, \\u201cBuyers\\u201d, \\u201cPayers\\u201d, and \\u201cCus\", \"tomers\\u201d depending on the bounded\\ncontext. You\\u2019ve identified several BCs that could be implemented as\", \" microservices, based on domains\\nthat domain experts defined for you. As you can see, there are enti\", \"ties that are present just in a single\\nmicroservice model, like Payments in the Payment microservice\", \". Those will be easy to implement.\\nHowever, you might also have entities that have a different shape\", \" but share the same identity across\\nthe multiple domain models from the multiple microservices. For \", \"example, the User entity is identified\\nin the Conferences Management microservice. That same user, w\", \"ith the same identity, is the one\\nnamed Buyers in the Ordering microservice, or the one named Payer \", \"in the Payment microservice, and\\neven the one named Customer in the Customer Service microservice. T\", \"his is because, depending on\\nthe ubiquitous language that each domain expert is using, a user might \", \"have a different perspective\\neven with different attributes. The user entity in the microservice mod\", \"el named Conferences\\nManagement might have most of its personal data attributes. However, that same \", \"user in the shape of\\nPayer in the microservice Payment or in the shape of Customer in the microservi\", \"ce Customer Service\\nmight not need the same list of attributes.\\nA similar approach is illustrated in\", \" Figure 4-11.\\n38 CHAPTER 3 | Architecting container and microservice-based applicationsFigure 4-11. \", \"Decomposing traditional data models into multiple domain models\\nWhen decomposing a traditional data \", \"model between bounded contexts, you can have different\\nentities that share the same identity (a buye\", \"r is also a user) with different attributes in each bounded\\ncontext. You can see how the user is pre\", \"sent in the Conferences Management microservice model as\\nthe User entity and is also present in the \", \"form of the Buyer entity in the Pricing microservice, with\\nalternate attributes or details about the\", \" user when it\\u2019s actually a buyer. Each microservice or BC might\\nnot need all the data related to a U\", \"ser entity, just part of it, depending on the problem to solve or the\\ncontext. For instance, in the \", \"Pricing microservice model, you do not need the address or the name of\\nthe user, just the ID (as ide\", \"ntity) and Status, which will have an impact on discounts when pricing the\\nseats per buyer.\\nThe Seat\", \" entity has the same name but different attributes in each domain model. However, Seat\\nshares identi\", \"ty based on the same ID, as happens with User and Buyer.\\nBasically, there\\u2019s a shared concept of a us\", \"er that exists in multiple services (domains), which all share\\nthe identity of that user. But in eac\", \"h domain model there might be additional or different details\\nabout the user entity. Therefore, ther\", \"e needs to be a way to map a user entity from one domain\\n(microservice) to another.\\nThere are severa\", \"l benefits to not sharing the same user entity with the same number of attributes\\nacross domains. On\", \"e benefit is to reduce duplication, so that microservice models do not have any\\ndata that they do no\", \"t need. Another benefit is having a primary microservice that owns a certain type\\nof data per entity\", \" so that updates and queries for that type of data are driven only by that\\nmicroservice.\\n39 CHAPTER \", \"3 | Architecting container and microservice-based applicationsThe API gateway pattern versus the Dir\", \"ect client-to-\\nmicroservice communication\\nIn a microservices architecture, each microservice exposes\", \" a set of (typically) fine-grained endpoints.\\nThis fact can impact the client-to-microservice commun\", \"ication, as explained in this section.\\nDirect client-to-microservice communication\\nA possible approa\", \"ch is to use a direct client-to-microservice communication architecture. In this\\napproach, a client \", \"app can make requests directly to some of the microservices, as shown in Figure 4-\\n12.\\nFigure 4-12. \", \"Using a direct client-to-microservice communication architecture\\nIn this approach, each microservice\", \" has a public endpoint, sometimes with a different TCP port for\\neach microservice. An example of a U\", \"RL for a particular service could be the following URL in Azure:\\nhttp://eshoponcontainers.westus.clo\", \"udapp.azure.com:88/\\nIn a production environment based on a cluster, that URL would map to the load b\", \"alancer used in the\\ncluster, which in turn distributes the requests across the microservices. In pro\", \"duction environments,\\nyou could have an Application Delivery Controller (ADC) like Azure Application\", \" Gateway between your\\nmicroservices and the Internet. This layer acts as a transparent tier that not\", \" only performs load\\nbalancing, but secures your services by offering SSL termination. This approach \", \"improves the load of\\nyour hosts by offloading CPU-intensive SSL termination and other routing duties\", \" to the Azure\\nApplication Gateway. In any case, a load balancer and ADC are transparent from a logic\", \"al application\\narchitecture point of view.\\nA direct client-to-microservice communication architectur\", \"e could be good enough for a small\\nmicroservice-based application, especially if the client app is a\", \" server-side web application like an\\nASP.NET MVC app. However, when you build large and complex micr\", \"oservice-based applications (for\\nexample, when handling dozens of microservice types), and especiall\", \"y when the client apps are\\nremote mobile apps or SPA web applications, that approach faces a few iss\", \"ues.\\n40 CHAPTER 3 | Architecting container and microservice-based applicationsConsider the following\", \" questions when developing a large application based on microservices:\\n\\u2022 How can client apps minimiz\", \"e the number of requests to the back end and reduce chatty\\ncommunication to multiple microservices?\\n\", \"Interacting with multiple microservices to build a single UI screen increases the number of round tr\", \"ips\\nacross the Internet. This approach increases latency and complexity on the UI side. Ideally, res\", \"ponses\\nshould be efficiently aggregated in the server side. This approach reduces latency, since mul\", \"tiple\\npieces of data come back in parallel and some UI can show data as soon as it\\u2019s ready.\\n\\u2022 How ca\", \"n you handle cross-cutting concerns such as authorization, data transformations, and\\ndynamic request\", \" dispatching?\\nImplementing security and cross-cutting concerns like security and authorization on ev\", \"ery\\nmicroservice can require significant development effort. A possible approach is to have those se\", \"rvices\\nwithin the Docker host or internal cluster to restrict direct access to them from the outside\", \", and to\\nimplement those cross-cutting concerns in a centralized place, like an API Gateway.\\n\\u2022 How c\", \"an client apps communicate with services that use non-Internet-friendly protocols?\\nProtocols used on\", \" the server side (like AMQP or binary protocols) are not supported in client apps.\\nTherefore, reques\", \"ts must be performed through protocols like HTTP/HTTPS and translated to the\\nother protocols afterwa\", \"rds. A man-in-the-middle approach can help in this situation.\\n\\u2022 How can you shape a facade especiall\", \"y made for mobile apps?\\nThe API of multiple microservices might not be well designed for the needs o\", \"f different client\\napplications. For instance, the needs of a mobile app might be different than the\", \" needs of a web app.\\nFor mobile apps, you might need to optimize even further so that data responses\", \" can be more\\nefficient. You might do this functionality by aggregating data from multiple microservi\", \"ces and\\nreturning a single set of data, and sometimes eliminating any data in the response that isn\\u2019\", \"t needed\\nby the mobile app. And, of course, you might compress that data. Again, a facade or API in \", \"between\\nthe mobile app and the microservices can be convenient for this scenario.\\nWhy consider API G\", \"ateways instead of direct client-to-microservice\\ncommunication\\nIn a microservices architecture, the \", \"client apps usually need to consume functionality from more than\\none microservice. If that consumpti\", \"on is performed directly, the client needs to handle multiple calls\\nto microservice endpoints. What \", \"happens when the application evolves and new microservices are\\nintroduced or existing microservices \", \"are updated? If your application has many microservices,\\nhandling so many endpoints from the client \", \"apps can be a nightmare. Since the client app would be\\ncoupled to those internal endpoints, evolving\", \" the microservices in the future can cause high impact\\nfor the client apps.\\nTherefore, having an int\", \"ermediate level or tier of indirection (Gateway) can be convenient for\\nmicroservice-based applicatio\", \"ns. If you don\\u2019t have API Gateways, the client apps must send requests\\ndirectly to the microservices\", \" and that raises problems, such as the following issues:\\n41 CHAPTER 3 | Architecting container and m\", \"icroservice-based applications\\u2022 Coupling: Without the API Gateway pattern, the client apps are coupl\", \"ed to the internal\\nmicroservices. The client apps need to know how the multiple areas of the applica\", \"tion are\\ndecomposed in microservices. When evolving and refactoring the internal microservices,\\nthos\", \"e actions impact maintenance because they cause breaking changes to the client apps\\ndue to the direc\", \"t reference to the internal microservices from the client apps. Client apps need\\nto be updated frequ\", \"ently, making the solution harder to evolve.\\n\\u2022 Too many round trips: A single page/screen in the cli\", \"ent app might require several calls to\\nmultiple services. That approach can result in multiple netwo\", \"rk round trips between the client\\nand the server, adding significant latency. Aggregation handled in\", \" an intermediate level could\\nimprove the performance and user experience for the client app.\\n\\u2022 Secur\", \"ity issues: Without a gateway, all the microservices must be exposed to the \\u201cexternal\\nworld\\u201d, making\", \" the attack surface larger than if you hide internal microservices that aren\\u2019t\\ndirectly used by the \", \"client apps. The smaller the attack surface is, the more secure your\\napplication can be.\\n\\u2022 Cross-cut\", \"ting concerns: Each publicly published microservice must handle concerns such as\\nauthorization and S\", \"SL. In many situations, those concerns could be handled in a single tier so\\nthe internal microservic\", \"es are simplified.\\nWhat is the API Gateway pattern?\\nWhen you design and build large or complex micro\", \"service-based applications with multiple client\\napps, a good approach to consider can be an API Gate\", \"way. This pattern is a service that provides a\\nsingle-entry point for certain groups of microservice\", \"s. It\\u2019s similar to the Facade pattern from object-\\noriented design, but in this case, it\\u2019s part of a\", \" distributed system. The API Gateway pattern is also\\nsometimes known as the \\u201cbackend for frontend\\u201d (\", \"BFF) because you build it while thinking about the\\nneeds of the client app.\\nTherefore, the API gatew\", \"ay sits between the client apps and the microservices. It acts as a reverse\\nproxy, routing requests \", \"from clients to services. It can also provide other cross-cutting features such\\nas authentication, S\", \"SL termination, and cache.\\nFigure 4-13 shows how a custom API Gateway can fit into a simplified micr\", \"oservice-based architecture\\nwith just a few microservices.\\n42 CHAPTER 3 | Architecting container and\", \" microservice-based applicationsFigure 4-13. Using an API Gateway implemented as a custom service\\nAp\", \"ps connect to a single endpoint, the API Gateway, that\\u2019s configured to forward requests to\\nindividua\", \"l microservices. In this example, the API Gateway would be implemented as a custom\\nASP.NET Core WebH\", \"ost service running as a container.\\nIt\\u2019s important to highlight that in that diagram, you would be u\", \"sing a single custom API Gateway\\nservice facing multiple and different client apps. That fact can be\", \" an important risk because your API\\nGateway service will be growing and evolving based on many diffe\", \"rent requirements from the client\\napps. Eventually, it will be bloated because of those different ne\", \"eds and effectively it could be similar\\nto a monolithic application or monolithic service. That\\u2019s wh\", \"y it\\u2019s very much recommended to split the\\nAPI Gateway in multiple services or multiple smaller API G\", \"ateways, one per client app form-factor\\ntype, for instance.\\nYou need to be careful when implementing\", \" the API Gateway pattern. Usually it isn\\u2019t a good idea to\\nhave a single API Gateway aggregating all \", \"the internal microservices of your application. If it does, it\\nacts as a monolithic aggregator or or\", \"chestrator and violates microservice autonomy by coupling all\\nthe microservices.\\nTherefore, the API \", \"Gateways should be segregated based on business boundaries and the client apps\\nand not act as a sing\", \"le aggregator for all the internal microservices.\\nWhen splitting the API Gateway tier into multiple \", \"API Gateways, if your application has multiple client\\napps, that can be a primary pivot when identif\", \"ying the multiple API Gateways types, so that you can\\nhave a different facade for the needs of each \", \"client app. This case is a pattern named \\u201cBackend for\\nFrontend\\u201d (BFF) where each API Gateway can pro\", \"vide a different API tailored for each client app type,\\npossibly even based on the client form facto\", \"r by implementing specific adapter code which\\nunderneath calls multiple internal microservices, as s\", \"hown in the following image:\\n43 CHAPTER 3 | Architecting container and microservice-based applicatio\", \"nsFigure 4-13.1. Using multiple custom API Gateways\\nFigure 4-13.1 shows API Gateways that are segreg\", \"ated by client type; one for mobile clients and one\\nfor web clients. A traditional web app connects \", \"to an MVC microservice that uses the web API\\nGateway. The example depicts a simplified architecture \", \"with multiple fine-grained API Gateways. In\\nthis case, the boundaries identified for each API Gatewa\", \"y are based purely on the \\u201cBackend for\\nFrontend\\u201d (BFF) pattern, hence based just on the API needed p\", \"er client app. But in larger applications\\nyou should also go further and create other API Gateways b\", \"ased on business boundaries as a second\\ndesign pivot.\\nMain features in the API Gateway pattern\\nAn AP\", \"I Gateway can offer multiple features. Depending on the product it might offer richer or simpler\\nfea\", \"tures, however, the most important and foundational features for any API Gateway are the\\nfollowing d\", \"esign patterns:\\nReverse proxy or gateway routing. The API Gateway offers a reverse proxy to redirect\", \" or route\\nrequests (layer 7 routing, usually HTTP requests) to the endpoints of the internal microse\", \"rvices. The\\ngateway provides a single endpoint or URL for the client apps and then internally maps t\", \"he requests\\nto a group of internal microservices. This routing feature helps to decouple the client \", \"apps from the\\nmicroservices but it\\u2019s also convenient when modernizing a monolithic API by sitting th\", \"e API Gateway\\nin between the monolithic API and the client apps, then you can add new APIs as new mi\", \"croservices\\nwhile still using the legacy monolithic API until it\\u2019s split into many microservices in \", \"the future. Because\\nof the API Gateway, the client apps won\\u2019t notice if the APIs being used are impl\", \"emented as internal\\nmicroservices or a monolithic API and more importantly, when evolving and refact\", \"oring the\\nmonolithic API into microservices, thanks to the API Gateway routing, client apps won\\u2019t be\", \" impacted\\nwith any URI change.\\n44 CHAPTER 3 | Architecting container and microservice-based applicat\", \"ionsFor more information, see Gateway routing pattern.\\nRequests aggregation. As part of the gateway \", \"pattern you can aggregate multiple client requests\\n(usually HTTP requests) targeting multiple intern\", \"al microservices into a single client request. This\\npattern is especially convenient when a client p\", \"age/screen needs information from several\\nmicroservices. With this approach, the client app sends a \", \"single request to the API Gateway that\\ndispatches several requests to the internal microservices and\", \" then aggregates the results and sends\\neverything back to the client app. The main benefit and goal \", \"of this design pattern is to reduce\\nchattiness between the client apps and the backend API, which is\", \" especially important for remote\\napps out of the datacenter where the microservices live, like mobil\", \"e apps or requests coming from\\nSPA apps that come from JavaScript in client remote browsers. For reg\", \"ular web apps performing the\\nrequests in the server environment (like an ASP.NET Core MVC web app), \", \"this pattern is not so\\nimportant as the latency is very much smaller than for remote client apps.\\nDe\", \"pending on the API Gateway product you use, it might be able to perform this aggregation.\\nHowever, i\", \"n many cases it\\u2019s more flexible to create aggregation microservices under the scope of the\\nAPI Gatew\", \"ay, so you define the aggregation in code (that is, C# code):\\nFor more information, see Gateway aggr\", \"egation pattern.\\nCross-cutting concerns or gateway offloading. Depending on the features offered by \", \"each API\\nGateway product, you can offload functionality from individual microservices to the gateway\", \", which\\nsimplifies the implementation of each microservice by consolidating cross-cutting concerns i\", \"nto one\\ntier. This approach is especially convenient for specialized features that can be complex to\", \" implement\\nproperly in every internal microservice, such as the following functionality:\\n\\u2022 Authentic\", \"ation and authorization\\n\\u2022 Service discovery integration\\n\\u2022 Response caching\\n\\u2022 Retry policies, circuit\", \" breaker, and QoS\\n\\u2022 Rate limiting and throttling\\n\\u2022 Load balancing\\n\\u2022 Logging, tracing, correlation\\n\\u2022 \", \"Headers, query strings, and claims transformation\\n\\u2022 IP allowlisting\\nFor more information, see Gatewa\", \"y offloading pattern.\\nUsing products with API Gateway features\\nThere can be many more cross-cutting \", \"concerns offered by the API Gateways products depending on\\neach implementation. We\\u2019ll explore here:\\n\", \"\\u2022 Azure API Management\\n\\u2022 Ocelot\\n45 CHAPTER 3 | Architecting container and microservice-based applica\", \"tionsAzure API Management\\nAzure API Management (as shown in Figure 4-14) not only solves your API Ga\", \"teway needs but\\nprovides features like gathering insights from your APIs. If you\\u2019re using an API man\", \"agement solution,\\nan API Gateway is only a component within that full API management solution.\\nFigur\", \"e 4-14. Using Azure API Management for your API Gateway\\nAzure API Management solves both your API Ga\", \"teway and Management needs like logging, security,\\nmetering, etc. In this case, when using a product\", \" like Azure API Management, the fact that you might\\nhave a single API Gateway is not so risky becaus\", \"e these kinds of API Gateways are \\u201cthinner\\u201d, meaning\\nthat you don\\u2019t implement custom C# code that co\", \"uld evolve towards a monolithic component.\\nThe API Gateway products usually act like a reverse proxy\", \" for ingress communication, where you can\\nalso filter the APIs from the internal microservices plus \", \"apply authorization to the published APIs in\\nthis single tier.\\nThe insights available from an API Ma\", \"nagement system help you get an understanding of how your\\nAPIs are being used and how they are perfo\", \"rming. They do this activity by letting you view near real-\\ntime analytics reports and identifying t\", \"rends that might impact your business. Plus, you can have logs\\nabout request and response activity f\", \"or further online and offline analysis.\\nWith Azure API Management, you can secure your APIs using a \", \"key, a token, and IP filtering. These\\nfeatures let you enforce flexible and fine-grained quotas and \", \"rate limits, modify the shape and\\nbehavior of your APIs using policies, and improve performance with\", \" response caching.\\nIn this guide and the reference sample application (eShopOnContainers), the archi\", \"tecture is limited to\\na simpler and custom-made containerized architecture in order to focus on plai\", \"n containers without\\n46 CHAPTER 3 | Architecting container and microservice-based applicationsusing \", \"PaaS products like Azure API Management. But for large microservice-based applications that\\nare depl\", \"oyed into Microsoft Azure, we encourage you to evaluate Azure API Management as the base\\nfor your AP\", \"I Gateways in production.\\nOcelot\\nOcelot is a lightweight API Gateway, recommended for simpler approa\", \"ches. Ocelot is an Open Source\\n.NET Core-based API Gateway especially made for microservices archite\", \"ctures that need unified points\\nof entry into their systems. It\\u2019s lightweight, fast, and scalable an\", \"d provides routing and authentication\\namong many other features.\\nThe main reason to choose Ocelot fo\", \"r the eShopOnContainers reference application 2.0 is because\\nOcelot is a .NET Core lightweight API G\", \"ateway that you can deploy into the same application\\ndeployment environment where you\\u2019re deploying y\", \"our microservices/containers, such as a Docker\\nHost, Kubernetes, etc. And since it\\u2019s based on .NET C\", \"ore, it\\u2019s cross-platform allowing you to deploy on\\nLinux or Windows.\\nThe previous diagrams showing c\", \"ustom API Gateways running in containers are precisely how you can\\nalso run Ocelot in a container an\", \"d microservice-based application.\\nIn addition, there are many other products in the market offering \", \"API Gateways features, such as\\nApigee, Kong, MuleSoft, WSO2, and other products like Linkerd and Ist\", \"io for service mesh ingress\\ncontroller features.\\nAfter the initial architecture and patterns explana\", \"tion sections, the next sections explain how to\\nimplement API Gateways with Ocelot.\\nDrawbacks of the\", \" API Gateway pattern\\n\\u2022 The most important drawback is that when you implement an API Gateway, you\\u2019re\", \" coupling\\nthat tier with the internal microservices. Coupling like this might introduce serious diff\", \"iculties\\nfor your application. Clemens Vaster, architect at the Azure Service Bus team, refers to th\", \"is\\npotential difficulty as \\u201cthe new ESB\\u201d in the \\u201cMessaging and Microservices\\u201d session at GOTO\\n2016.\\n\", \"\\u2022 Using a microservices API Gateway creates an additional possible single point of failure.\\n\\u2022 An API\", \" Gateway can introduce increased response time due to the additional network call.\\nHowever, this ext\", \"ra call usually has less impact than having a client interface that\\u2019s too chatty\\ndirectly calling th\", \"e internal microservices.\\n\\u2022 If not scaled out properly, the API Gateway can become a bottleneck.\\n\\u2022 A\", \"n API Gateway requires additional development cost and future maintenance if it includes\\ncustom logi\", \"c and data aggregation. Developers must update the API Gateway in order to\\nexpose each microservice\\u2019\", \"s endpoints. Moreover, implementation changes in the internal\\nmicroservices might cause code changes\", \" at the API Gateway level. However, if the API\\nGateway is just applying security, logging, and versi\", \"oning (as when using Azure API\\nManagement), this additional development cost might not apply.\\n47 CHA\", \"PTER 3 | Architecting container and microservice-based applications\\u2022 If the API Gateway is developed\", \" by a single team, there can be a development bottleneck. This\\naspect is another reason why a better\", \" approach is to have several fined-grained API Gateways\\nthat respond to different client needs. You \", \"could also segregate the API Gateway internally\\ninto multiple areas or layers that are owned by the \", \"different teams working on the internal\\nmicroservices.\\nAdditional resources\\n\\u2022 Chris Richardson. Patt\", \"ern: API Gateway / Backend for Front-End\\nhttps://microservices.io/patterns/apigateway.html\\n\\u2022 API Gat\", \"eway pattern\\nhttps://learn.microsoft.com/azure/architecture/microservices/gateway\\n\\u2022 Aggregation and \", \"composition pattern\\nhttps://microservices.io/patterns/data/api-composition.html\\n\\u2022 Azure API Manageme\", \"nt\\nhttps://azure.microsoft.com/services/api-management/\\n\\u2022 Udi Dahan. Service Oriented Composition\\nht\", \"tps://udidahan.com/2014/07/30/service-oriented-composition-with-video/\\n\\u2022 Clemens Vasters. Messaging \", \"and Microservices at GOTO 2016 (video)\\nhttps://www.youtube.com/watch?v=rXi5CLjIQ9k\\n\\u2022 API Gateway in \", \"a Nutshell (ASP.NET Core API Gateway Tutorial Series)\\nhttps://www.pogsdotnet.com/2018/08/api-gateway\", \"-in-nutshell.html\\nCommunication in a microservice architecture\\nIn a monolithic application running o\", \"n a single process, components invoke one another using\\nlanguage-level method or function calls. The\", \"se can be strongly coupled if you\\u2019re creating objects with\\ncode (for example, new ClassName()), or c\", \"an be invoked in a decoupled way if you\\u2019re using\\nDependency Injection by referencing abstractions ra\", \"ther than concrete object instances. Either way,\\nthe objects are running within the same process. Th\", \"e biggest challenge when changing from a\\nmonolithic application to a microservices-based application\", \" lies in changing the communication\\nmechanism. A direct conversion from in-process method calls into\", \" RPC calls to services will cause a\\nchatty and not efficient communication that won\\u2019t perform well i\", \"n distributed environments. The\\nchallenges of designing distributed system properly are well enough \", \"known that there\\u2019s even a canon\\nknown as the Fallacies of distributed computing that lists assumptio\", \"ns that developers often make\\nwhen moving from monolithic to distributed designs.\\nThere isn\\u2019t one so\", \"lution, but several. One solution involves isolating the business microservices as\\nmuch as possible.\", \" You then use asynchronous communication between the internal microservices and\\nreplace fine-grained\", \" communication that\\u2019s typical in intra-process communication between objects\\nwith coarser-grained co\", \"mmunication. You can do this by grouping calls, and by returning data that\\naggregates the results of\", \" multiple internal calls, to the client.\\n48 CHAPTER 3 | Architecting container and microservice-base\", \"d applicationsA microservices-based application is a distributed system running on multiple processe\", \"s or services,\\nusually even across multiple servers or hosts. Each service instance is typically a p\", \"rocess. Therefore,\\nservices must interact using an inter-process communication protocol such as HTTP\", \", AMQP, or a\\nbinary protocol like TCP, depending on the nature of each service.\\nThe microservice com\", \"munity promotes the philosophy of \\u201csmart endpoints and dumb pipes\\u201d. This\\nslogan encourages a design \", \"that\\u2019s as decoupled as possible between microservices, and as cohesive\\nas possible within a single m\", \"icroservice. As explained earlier, each microservice owns its own data and\\nits own domain logic. But\", \" the microservices composing an end-to-end application are usually simply\\nchoreographed by using RES\", \"T communications rather than complex protocols such as WS-* and\\nflexible event-driven communications\", \" instead of centralized business-process-orchestrators.\\nThe two commonly used protocols are HTTP req\", \"uest/response with resource APIs (when querying\\nmost of all), and lightweight asynchronous messaging\", \" when communicating updates across multiple\\nmicroservices. These are explained in more detail in the\", \" following sections.\\nCommunication types\\nClient and services can communicate through many different \", \"types of communication, each one\\ntargeting a different scenario and goals. Initially, those types of\", \" communications can be classified in\\ntwo axes.\\nThe first axis defines if the protocol is synchronous\", \" or asynchronous:\\n\\u2022 Synchronous protocol. HTTP is a synchronous protocol. The client sends a request\", \" and waits\\nfor a response from the service. That\\u2019s independent of the client code execution that cou\", \"ld be\\nsynchronous (thread is blocked) or asynchronous (thread isn\\u2019t blocked, and the response will\\nr\", \"each a callback eventually). The important point here is that the protocol (HTTP/HTTPS) is\\nsynchrono\", \"us and the client code can only continue its task when it receives the HTTP server\\nresponse.\\n\\u2022 Async\", \"hronous protocol. Other protocols like AMQP (a protocol supported by many operating\\nsystems and clou\", \"d environments) use asynchronous messages. The client code or message\\nsender usually doesn\\u2019t wait fo\", \"r a response. It just sends the message as when sending a\\nmessage to a RabbitMQ queue or any other m\", \"essage broker.\\nThe second axis defines if the communication has a single receiver or multiple receiv\", \"ers:\\n\\u2022 Single receiver. Each request must be processed by exactly one receiver or service. An\\nexampl\", \"e of this communication is the Command pattern.\\n\\u2022 Multiple receivers. Each request can be processed \", \"by zero to multiple receivers. This type of\\ncommunication must be asynchronous. An example is the pu\", \"blish/subscribe mechanism used\\nin patterns like Event-driven architecture. This is based on an event\", \"-bus interface or message\\nbroker when propagating data updates between multiple microservices throug\", \"h events; it\\u2019s\\nusually implemented through a service bus or similar artifact like Azure Service Bus \", \"by using\\ntopics and subscriptions.\\n49 CHAPTER 3 | Architecting container and microservice-based appl\", \"icationsA microservice-based application will often use a combination of these communication styles.\", \" The\\nmost common type is single-receiver communication with a synchronous protocol like HTTP/HTTPS\\nw\", \"hen invoking a regular Web API HTTP service. Microservices also typically use messaging protocols\\nfo\", \"r asynchronous communication between microservices.\\nThese axes are good to know so you have clarity \", \"on the possible communication mechanisms, but\\nthey\\u2019re not the important concerns when building micro\", \"services. Neither the asynchronous nature of\\nclient thread execution nor the asynchronous nature of \", \"the selected protocol are the important points\\nwhen integrating microservices. What is important is \", \"being able to integrate your microservices\\nasynchronously while maintaining the independence of micr\", \"oservices, as explained in the following\\nsection.\\nAsynchronous microservice integration enforces mic\", \"roservice\\u2019s\\nautonomy\\nAs mentioned, the important point when building a microservices-based applicati\", \"on is the way you\\nintegrate your microservices. Ideally, you should try to minimize the communicatio\", \"n between the\\ninternal microservices. The fewer communications between microservices, the better. Bu\", \"t in many\\ncases, you\\u2019ll have to somehow integrate the microservices. When you need to do that, the c\", \"ritical rule\\nhere is that the communication between the microservices should be asynchronous. That d\", \"oesn\\u2019t\\nmean that you have to use a specific protocol (for example, asynchronous messaging versus\\nsyn\", \"chronous HTTP). It just means that the communication between microservices should be done only\\nby pr\", \"opagating data asynchronously, but try not to depend on other internal microservices as part of\\nthe \", \"initial service\\u2019s HTTP request/response operation.\\nIf possible, never depend on synchronous communic\", \"ation (request/response) between multiple\\nmicroservices, not even for queries. The goal of each micr\", \"oservice is to be autonomous and available\\nto the client consumer, even if the other services that a\", \"re part of the end-to-end application are down\\nor unhealthy. If you think you need to make a call fr\", \"om one microservice to other microservices (like\\nperforming an HTTP request for a data query) to be \", \"able to provide a response to a client application,\\nyou have an architecture that won\\u2019t be resilient\", \" when some microservices fail.\\nMoreover, having HTTP dependencies between microservices, like when c\", \"reating long\\nrequest/response cycles with HTTP request chains, as shown in the first part of the Fig\", \"ure 4-15, not\\nonly makes your microservices not autonomous but also their performance is impacted as\", \" soon as\\none of the services in that chain isn\\u2019t performing well.\\nThe more you add synchronous depen\", \"dencies between microservices, such as query requests, the\\nworse the overall response time gets for \", \"the client apps.\\n50 CHAPTER 3 | Architecting container and microservice-based applicationsFigure 4-1\", \"5. Anti-patterns and patterns in communication between microservices\\nAs shown in the above diagram, \", \"in synchronous communication a \\u201cchain\\u201d of requests is created\\nbetween microservices while serving th\", \"e client request. This is an anti-pattern. In asynchronous\\ncommunication microservices use asynchron\", \"ous messages or http polling to communicate with other\\nmicroservices, but the client request is serv\", \"ed right away.\\nIf your microservice needs to raise an additional action in another microservice, if \", \"possible, do not\\nperform that action synchronously and as part of the original microservice request \", \"and reply\\noperation. Instead, do it asynchronously (using asynchronous messaging or integration even\", \"ts,\\nqueues, etc.). But, as much as possible, do not invoke the action synchronously as part of the o\", \"riginal\\nsynchronous request and reply operation.\\nAnd finally (and this is where most of the issues a\", \"rise when building microservices), if your initial\\nmicroservice needs data that\\u2019s originally owned b\", \"y other microservices, do not rely on making\\nsynchronous requests for that data. Instead, replicate \", \"or propagate that data (only the attributes you\\nneed) into the initial service\\u2019s database by using e\", \"ventual consistency (typically by using integration\\nevents, as explained in upcoming sections).\\nAs n\", \"oted earlier in the Identifying domain-model boundaries for each microservice section,\\nduplicating s\", \"ome data across several microservices isn\\u2019t an incorrect design\\u2014on the contrary, when\\ndoing that you\", \" can translate the data into the specific language or terms of that additional domain or\\nBounded Con\", \"text. For instance, in the eShopOnContainers application you have a microservice named\\nidentity-api \", \"that\\u2019s in charge of most of the user\\u2019s data with an entity named User. However, when you\\nneed to sto\", \"re data about the user within the Ordering microservice, you store it as a different entity\\nnamed Bu\", \"yer. The Buyer entity shares the same identity with the original User entity, but it might have\\nonly\", \" the few attributes needed by the Ordering domain, and not the whole user profile.\\n51 CHAPTER 3 | Ar\", \"chitecting container and microservice-based applicationsYou might use any protocol to communicate an\", \"d propagate data asynchronously across microservices\\nin order to have eventual consistency. As menti\", \"oned, you could use integration events using an event\\nbus or message broker or you could even use HT\", \"TP by polling the other services instead. It doesn\\u2019t\\nmatter. The important rule is to not create syn\", \"chronous dependencies between your microservices.\\nThe following sections explain the multiple commun\", \"ication styles you can consider using in a\\nmicroservice-based application.\\nCommunication styles\\nTher\", \"e are many protocols and choices you can use for communication, depending on the\\ncommunication type \", \"you want to use. If you\\u2019re using a synchronous request/response-based\\ncommunication mechanism, proto\", \"cols such as HTTP and REST approaches are the most common,\\nespecially if you\\u2019re publishing your serv\", \"ices outside the Docker host or microservice cluster. If you\\u2019re\\ncommunicating between services inter\", \"nally (within your Docker host or microservices cluster), you\\nmight also want to use binary format c\", \"ommunication mechanisms (like WCF using TCP and binary\\nformat). Alternatively, you can use asynchron\", \"ous, message-based communication mechanisms such as\\nAMQP.\\nThere are also multiple message formats li\", \"ke JSON or XML, or even binary formats, which can be more\\nefficient. If your chosen binary format is\", \"n\\u2019t a standard, it\\u2019s probably not a good idea to publicly\\npublish your services using that format. Y\", \"ou could use a non-standard format for internal\\ncommunication between your microservices. You might \", \"do this when communicating between\\nmicroservices within your Docker host or microservice cluster (fo\", \"r example, Docker orchestrators), or\\nfor proprietary client applications that talk to the microservi\", \"ces.\\nRequest/response communication with HTTP and REST\\nWhen a client uses request/response communica\", \"tion, it sends a request to a service, then the service\\nprocesses the request and sends back a respo\", \"nse. Request/response communication is especially well\\nsuited for querying data for a real-time UI (\", \"a live user interface) from client apps. Therefore, in a\\nmicroservice architecture you\\u2019ll probably u\", \"se this communication mechanism for most queries, as\\nshown in Figure 4-16.\\nFigure 4-16. Using HTTP r\", \"equest/response communication (synchronous or asynchronous)\\n52 CHAPTER 3 | Architecting container an\", \"d microservice-based applicationsWhen a client uses request/response communication, it assumes that \", \"the response will arrive in a\\nshort time, typically less than a second, or a few seconds at most. Fo\", \"r delayed responses, you need to\\nimplement asynchronous communication based on messaging patterns an\", \"d messaging technologies,\\nwhich is a different approach that we explain in the next section.\\nA popul\", \"ar architectural style for request/response communication is REST. This approach is based on,\\nand ti\", \"ghtly coupled to, the HTTP protocol, embracing HTTP verbs like GET, POST, and PUT. REST is the\\nmost \", \"commonly used architectural communication approach when creating services. You can\\nimplement REST se\", \"rvices when you develop ASP.NET Core Web API services.\\nThere\\u2019s additional value when using HTTP REST\", \" services as your interface definition language. For\\ninstance, if you use Swagger metadata to descri\", \"be your service API, you can use tools that generate\\nclient stubs that can directly discover and con\", \"sume your services.\\nAdditional resources\\n\\u2022 Martin Fowler. Richardson Maturity Model A description of\", \" the REST model.\\nhttps://martinfowler.com/articles/richardsonMaturityModel.html\\n\\u2022 Swagger The offici\", \"al site.\\nhttps://swagger.io/\\nPush and real-time communication based on HTTP\\nAnother possibility (usu\", \"ally for different purposes than REST) is a real-time and one-to-many\\ncommunication with higher-leve\", \"l frameworks such as ASP.NET SignalR and protocols such as\\nWebSockets.\\nAs Figure 4-17 shows, real-ti\", \"me HTTP communication means that you can have server code pushing\\ncontent to connected clients as th\", \"e data becomes available, rather than having the server wait for a\\nclient to request new data.\\n53 CH\", \"APTER 3 | Architecting container and microservice-based applicationsFigure 4-17. One-to-many real-ti\", \"me asynchronous message communication\\nSignalR is a good way to achieve real-time communication for p\", \"ushing content to the clients from a\\nback-end server. Since communication is in real time, client ap\", \"ps show the changes almost instantly.\\nThis is usually handled by a protocol such as WebSockets, usin\", \"g many WebSockets connections (one\\nper client). A typical example is when a service communicates a c\", \"hange in the score of a sports game\\nto many client web apps simultaneously.\\nAsynchronous message-bas\", \"ed communication\\nAsynchronous messaging and event-driven communication are critical when propagating\", \" changes\\nacross multiple microservices and their related domain models. As mentioned earlier in the \", \"discussion\\nmicroservices and Bounded Contexts (BCs), models (User, Customer, Product, Account, etc.)\", \" can mean\\ndifferent things to different microservices or BCs. That means that when changes occur, yo\", \"u need\\nsome way to reconcile changes across the different models. A solution is eventual consistency\", \" and\\nevent-driven communication based on asynchronous messaging.\\nWhen using messaging, processes com\", \"municate by exchanging messages asynchronously. A client\\nmakes a command or a request to a service b\", \"y sending it a message. If the service needs to reply, it\\nsends a different message back to the clie\", \"nt. Since it\\u2019s a message-based communication, the client\\nassumes that the reply won\\u2019t be received im\", \"mediately, and that there might be no response at all.\\nA message is composed by a header (metadata s\", \"uch as identification or security information) and a\\nbody. Messages are usually sent through asynchr\", \"onous protocols like AMQP.\\nThe preferred infrastructure for this type of communication in the micros\", \"ervices community is a\\nlightweight message broker, which is different than the large brokers and orc\", \"hestrators used in SOA.\\nIn a lightweight message broker, the infrastructure is typically \\u201cdumb,\\u201d act\", \"ing only as a message\\nbroker, with simple implementations such as RabbitMQ or a scalable service bus\", \" in the cloud like\\n54 CHAPTER 3 | Architecting container and microservice-based applicationsAzure Se\", \"rvice Bus. In this scenario, most of the \\u201csmart\\u201d thinking still lives in the endpoints that are\\nprod\", \"ucing and consuming messages-that is, in the microservices.\\nAnother rule you should try to follow, a\", \"s much as possible, is to use only asynchronous messaging\\nbetween the internal services, and to use \", \"synchronous communication (such as HTTP) only from the\\nclient apps to the front-end services (API Ga\", \"teways plus the first level of microservices).\\nThere are two kinds of asynchronous messaging communi\", \"cation: single receiver message-based\\ncommunication, and multiple receivers message-based communicat\", \"ion. The following sections\\nprovide details about them.\\nSingle-receiver message-based communication\\n\", \"Message-based asynchronous communication with a single receiver means there\\u2019s point-to-point\\ncommuni\", \"cation that delivers a message to exactly one of the consumers that\\u2019s reading from the\\nchannel, and \", \"that the message is processed just once. However, there are special situations. For\\ninstance, in a c\", \"loud system that tries to automatically recover from failures, the same message could\\nbe sent multip\", \"le times. Due to network or other failures, the client has to be able to retry sending\\nmessages, and\", \" the server has to implement an operation to be idempotent in order to process a\\nparticular message \", \"just once.\\nSingle-receiver message-based communication is especially well suited for sending asynchr\", \"onous\\ncommands from one microservice to another as shown in Figure 4-18 that illustrates this approa\", \"ch.\\nOnce you start sending message-based communication (either with commands or events), you should\\n\", \"avoid mixing message-based communication with synchronous HTTP communication.\\nFigure 4-18. A single \", \"microservice receiving an asynchronous message\\n55 CHAPTER 3 | Architecting container and microservic\", \"e-based applicationsWhen the commands come from client applications, they can be implemented as HTTP\", \" synchronous\\ncommands. Use message-based commands when you need higher scalability or when you\\u2019re al\", \"ready\\nin a message-based business process.\\nMultiple-receivers message-based communication\\nAs a more \", \"flexible approach, you might also want to use a publish/subscribe mechanism so that your\\ncommunicati\", \"on from the sender will be available to additional subscriber microservices or to external\\napplicati\", \"ons. Thus, it helps you to follow the open/closed principle in the sending service. That way,\\nadditi\", \"onal subscribers can be added in the future without the need to modify the sender service.\\nWhen you \", \"use a publish/subscribe communication, you might be using an event bus interface to\\npublish events t\", \"o any subscriber.\\nAsynchronous event-driven communication\\nWhen using asynchronous event-driven commu\", \"nication, a microservice publishes an integration event\\nwhen something happens within its domain and\", \" another microservice needs to be aware of it, like a\\nprice change in a product catalog microservice\", \". Additional microservices subscribe to the events so\\nthey can receive them asynchronously. When tha\", \"t happens, the receivers might update their own\\ndomain entities, which can cause more integration ev\", \"ents to be published. This publish/subscribe\\nsystem is performed by using an implementation of an ev\", \"ent bus. The event bus can be designed as\\nan abstraction or interface, with the API that\\u2019s needed to\", \" subscribe or unsubscribe to events and to\\npublish events. The event bus can also have one or more i\", \"mplementations based on any inter-process\\nand messaging broker, like a messaging queue or service bu\", \"s that supports asynchronous\\ncommunication and a publish/subscribe model.\\nIf a system uses eventual \", \"consistency driven by integration events, it\\u2019s recommended that this\\napproach is made clear to the e\", \"nd user. The system shouldn\\u2019t use an approach that mimics\\nintegration events, like SignalR or pollin\", \"g systems from the client. The end user and the business\\nowner have to explicitly embrace eventual c\", \"onsistency in the system and realize that in many cases\\nthe business doesn\\u2019t have any problem with t\", \"his approach, as long as it\\u2019s explicit. This approach is\\nimportant because users might expect to see\", \" some results immediately and this aspect might not\\nhappen with eventual consistency.\\nAs noted earli\", \"er in the Challenges and solutions for distributed data management section, you can use\\nintegration \", \"events to implement business tasks that span multiple microservices. Thus, you\\u2019ll have\\neventual cons\", \"istency between those services. An eventually consistent transaction is made up of a\\ncollection of d\", \"istributed actions. At each action, the related microservice updates a domain entity and\\npublishes a\", \"nother integration event that raises the next action within the same end-to-end business\\ntask.\\nAn im\", \"portant point is that you might want to communicate to multiple microservices that are\\nsubscribed to\", \" the same event. To do so, you can use publish/subscribe messaging based on event-\\ndriven communicat\", \"ion, as shown in Figure 4-19. This publish/subscribe mechanism isn\\u2019t exclusive to\\nthe microservice a\", \"rchitecture. It\\u2019s similar to the way Bounded Contexts in DDD should communicate,\\nor to the way you p\", \"ropagate updates from the write database to the read database in the Command\\n56 CHAPTER 3 | Architec\", \"ting container and microservice-based applicationsand Query Responsibility Segregation (CQRS) archit\", \"ecture pattern. The goal is to have eventual\\nconsistency between multiple data sources across your d\", \"istributed system.\\nFigure 4-19. Asynchronous event-driven message communication\\nIn asynchronous even\", \"t-driven communication, one microservice publishes events to an event bus and\\nmany microservices can\", \" subscribe to it, to get notified and act on it. Your implementation will\\ndetermine what protocol to\", \" use for event-driven, message-based communications. AMQP can help\\nachieve reliable queued communica\", \"tion.\\nWhen you use an event bus, you might want to use an abstraction level (like an event bus inter\", \"face)\\nbased on a related implementation in classes with code using the API from a message broker lik\", \"e\\nRabbitMQ or a service bus like Azure Service Bus with Topics. Alternatively, you might want to use\", \" a\\nhigher-level service bus like NServiceBus, MassTransit, or Brighter to articulate your event bus \", \"and\\npublish/subscribe system.\\nA note about messaging technologies for production systems\\nThe messagi\", \"ng technologies available for implementing your abstract event bus are at different levels.\\nFor inst\", \"ance, products like RabbitMQ (a messaging broker transport) and Azure Service Bus sit at a\\nlower lev\", \"el than other products like NServiceBus, MassTransit, or Brighter, which can work on top of\\nRabbitMQ\", \" and Azure Service Bus. Your choice depends on how many rich features at the application\\nlevel and o\", \"ut-of-the-box scalability you need for your application. For implementing just a proof-of-\\nconcept e\", \"vent bus for your development environment, as it was done in the eShopOnContainers\\nsample, a simple \", \"implementation on top of RabbitMQ running on a Docker container might be\\nenough.\\nHowever, for missio\", \"n-critical and production systems that need hyper-scalability, you might want to\\nevaluate Azure Serv\", \"ice Bus. For high-level abstractions and features that make the development of\\ndistributed applicati\", \"ons easier, we recommend that you evaluate other commercial and open-source\\nservice buses, such as N\", \"ServiceBus, MassTransit, and Brighter. Of course, you can build your own\\n57 CHAPTER 3 | Architecting\", \" container and microservice-based applicationsservice-bus features on top of lower-level technologie\", \"s like RabbitMQ and Docker. But that plumbing\\nwork might cost too much for a custom enterprise appli\", \"cation.\\nResiliently publishing to the event bus\\nA challenge when implementing an event-driven archit\", \"ecture across multiple microservices is how to\\natomically update state in the original microservice \", \"while resiliently publishing its related integration\\nevent into the event bus, somehow based on tran\", \"sactions. The following are a few ways to accomplish\\nthis functionality, although there could be add\", \"itional approaches as well.\\n\\u2022 Using a transactional (DTC-based) queue like MSMQ. (However, this is a\", \" legacy approach.)\\n\\u2022 Using transaction log mining.\\n\\u2022 Using full Event Sourcing pattern.\\n\\u2022 Using the \", \"Outbox pattern: a transactional database table as a message queue that will be the\\nbase for an event\", \"-creator component that would create the event and publish it.\\nFor a more complete description of th\", \"e challenges in this space, including how messages with\\npotentially incorrect data can end up being \", \"published, see Data platform for mission-critical\\nworkloads on Azure: Every message must be processe\", \"d.\\nAdditional topics to consider when using asynchronous communication are message idempotence\\nand m\", \"essage deduplication. These topics are covered in the section Implementing event-based\\ncommunication\", \" between microservices (integration events) later in this guide.\\nAdditional resources\\n\\u2022 Event Driven\", \" Messaging\\nhttps://patterns.arcitura.com/soa-patterns/design_patterns/event_driven_messaging\\n\\u2022 Publi\", \"sh/Subscribe Channel\\nhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscri\", \"beChannel.\\nhtml\\n\\u2022 Udi Dahan. Clarified CQRS\\nhttps://udidahan.com/2009/12/09/clarified-cqrs/\\n\\u2022 Comman\", \"d and Query Responsibility Segregation (CQRS)\\nhttps://learn.microsoft.com/azure/architecture/pattern\", \"s/cqrs\\n\\u2022 Communicating Between Bounded Contexts\\nhttps://learn.microsoft.com/previous-versions/msp-n-\", \"p/jj591572(v=pandp.10)\\n\\u2022 Eventual consistency\\nhttps://en.wikipedia.org/wiki/Eventual_consistency\\n\\u2022 J\", \"immy Bogard. Refactoring Towards Resilience: Evaluating Coupling\\nhttps://jimmybogard.com/refactoring\", \"-towards-resilience-evaluating-coupling/\\n58 CHAPTER 3 | Architecting container and microservice-base\", \"d applicationsCreating, evolving, and versioning microservice APIs\\nand contracts\\nA microservice API \", \"is a contract between the service and its clients. You\\u2019ll be able to evolve a\\nmicroservice independe\", \"ntly only if you do not break its API contract, which is why the contract is so\\nimportant. If you ch\", \"ange the contract, it will impact your client applications or your API Gateway.\\nThe nature of the AP\", \"I definition depends on which protocol you\\u2019re using. For instance, if you\\u2019re using\\nmessaging, like A\", \"MQP, the API consists of the message types. If you\\u2019re using HTTP and RESTful\\nservices, the API consi\", \"sts of the URLs and the request and response JSON formats.\\nHowever, even if you\\u2019re thoughtful about \", \"your initial contract, a service API will need to change over\\ntime. When that happens\\u2014and especially\", \" if your API is a public API consumed by multiple client\\napplications \\u2014 you typically can\\u2019t force al\", \"l clients to upgrade to your new API contract. You usually\\nneed to incrementally deploy new versions\", \" of a service in a way that both old and new versions of a\\nservice contract are running simultaneous\", \"ly. Therefore, it\\u2019s important to have a strategy for your\\nservice versioning.\\nWhen the API changes a\", \"re small, like if you add attributes or parameters to your API, clients that use\\nan older API should\", \" switch and work with the new version of the service. You might be able to provide\\ndefault values fo\", \"r any missing attributes that are required, and the clients might be able to ignore any\\nextra respon\", \"se attributes.\\nHowever, sometimes you need to make major and incompatible changes to a service API. \", \"Because\\nyou might not be able to force client applications or services to upgrade immediately to the\", \" new\\nversion, a service must support older versions of the API for some period. If you\\u2019re using an H\", \"TTP-\\nbased mechanism such as REST, one approach is to embed the API version number in the URL or int\", \"o\\nan HTTP header. Then you can decide between implementing both versions of the service\\nsimultaneous\", \"ly within the same service instance, or deploying different instances that each handle a\\nversion of \", \"the API. A good approach for this functionality is the Mediator pattern (for example,\\nMediatR librar\", \"y) to decouple the different implementation versions into independent handlers.\\nFinally, if you\\u2019re u\", \"sing a REST architecture, Hypermedia is the best solution for versioning your services\\nand allowing \", \"evolvable APIs.\\nAdditional resources\\n\\u2022 Scott Hanselman. ASP.NET Core RESTful Web API versioning made\", \" easy\\nhttps://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx\\n\\u2022 Versioning a R\", \"ESTful web API\\nhttps://learn.microsoft.com/azure/architecture/best-practices/api-design#versioning-a\", \"-\\nrestful-web-api\\n\\u2022 Roy Fielding. Versioning, Hypermedia, and REST\\nhttps://www.infoq.com/articles/ro\", \"y-fielding-on-versioning\\n59 CHAPTER 3 | Architecting container and microservice-based applicationsMi\", \"croservices addressability and the service registry\\nEach microservice has a unique name (URL) that\\u2019s\", \" used to resolve its location. Your microservice needs\\nto be addressable wherever it\\u2019s running. If y\", \"ou have to think about which computer is running a\\nparticular microservice, things can go bad quickl\", \"y. In the same way that DNS resolves a URL to a\\nparticular computer, your microservice needs to have\", \" a unique name so that its current location is\\ndiscoverable. Microservices need addressable names th\", \"at make them independent from the\\ninfrastructure that they\\u2019re running on. This approach implies that\", \" there\\u2019s an interaction between how\\nyour service is deployed and how it\\u2019s discovered, because there \", \"needs to be a service registry. In the\\nsame vein, when a computer fails, the registry service must b\", \"e able to indicate where the service is\\nnow running.\\nThe service registry pattern is a key part of s\", \"ervice discovery. The registry is a database containing the\\nnetwork locations of service instances. \", \"A service registry needs to be highly available and up-to-date.\\nClients could cache network location\", \"s obtained from the service registry. However, that information\\neventually goes out of date and clie\", \"nts can no longer discover service instances. So, a service registry\\nconsists of a cluster of server\", \"s that use a replication protocol to maintain consistency.\\nIn some microservice deployment environme\", \"nts (called clusters, to be covered in a later section),\\nservice discovery is built in. For example,\", \" an Azure Kubernetes Service (AKS) environment can handle\\nservice instance registration and deregist\", \"ration. It also runs a proxy on each cluster host that plays the\\nrole of server-side discovery route\", \"r.\\nAdditional resources\\n\\u2022 Chris Richardson. Pattern: Service registry\\nhttps://microservices.io/patte\", \"rns/service-registry.html\\n\\u2022 Auth0. The Service Registry\\nhttps://auth0.com/blog/an-introduction-to-mi\", \"croservices-part-3-the-service-registry/\\n\\u2022 Gabriel Schenker. Service discovery\\nhttps://lostechies.co\", \"m/gabrielschenker/2016/01/27/service-discovery/\\nCreating composite UI based on microservices\\nMicrose\", \"rvices architecture often starts with the server-side handling data and logic, but, in many\\ncases, t\", \"he UI is still handled as a monolith. However, a more advanced approach, called micro\\nfrontends, is \", \"to design your application UI based on microservices as well. That means having a\\ncomposite UI produ\", \"ced by the microservices, instead of having microservices on the server and just a\\nmonolithic client\", \" app consuming the microservices. With this approach, the microservices you build\\ncan be complete wi\", \"th both logic and visual representation.\\nFigure 4-20 shows the simpler approach of just consuming mi\", \"croservices from a monolithic client\\napplication. Of course, you could have an ASP.NET MVC service i\", \"n between producing the HTML and\\nJavaScript. The figure is a simplification that highlights that you\", \" have a single (monolithic) client UI\\n60 CHAPTER 3 | Architecting container and microservice-based a\", \"pplicationsconsuming the microservices, which just focus on logic and data and not on the UI shape (\", \"HTML and\\nJavaScript).\\nFigure 4-20. A monolithic UI application consuming back-end microservices\\nIn c\", \"ontrast, a composite UI is precisely generated and composed by the microservices themselves.\\nSome of\", \" the microservices drive the visual shape of specific areas of the UI. The key difference is that\\nyo\", \"u have client UI components (TypeScript classes, for example) based on templates, and the data-\\nshap\", \"ing-UI ViewModel for those templates comes from each microservice.\\nAt client application start-up ti\", \"me, each of the client UI components (TypeScript classes, for example)\\nregisters itself with an infr\", \"astructure microservice capable of providing ViewModels for a given\\nscenario. If the microservice ch\", \"anges the shape, the UI changes also.\\nFigure 4-21 shows a version of this composite UI approach. Thi\", \"s approach is simplified because you\\nmight have other microservices that are aggregating granular pa\", \"rts that are based on different\\ntechniques. It depends on whether you\\u2019re building a traditional web \", \"approach (ASP.NET MVC) or an\\nSPA (Single Page Application).\\n61 CHAPTER 3 | Architecting container an\", \"d microservice-based applicationsFigure 4-21. Example of a composite UI application shaped by back-e\", \"nd microservices\\nEach of those UI composition microservices would be similar to a small API Gateway.\", \" But in this case,\\neach one is responsible for a small UI area.\\nA composite UI approach that\\u2019s drive\", \"n by microservices can be more challenging or less so,\\ndepending on what UI technologies you\\u2019re usin\", \"g. For instance, you won\\u2019t use the same techniques for\\nbuilding a traditional web application that y\", \"ou use for building an SPA or for native mobile app (as\\nwhen developing Xamarin apps, which can be m\", \"ore challenging for this approach).\\nThe eShopOnContainers sample application uses the monolithic UI \", \"approach for multiple reasons.\\nFirst, it\\u2019s an introduction to microservices and containers. A compos\", \"ite UI is more advanced but also\\nrequires further complexity when designing and developing the UI. S\", \"econd, eShopOnContainers also\\nprovides a native mobile app based on Xamarin, which would make it mor\", \"e complex on the client C#\\nside.\\nHowever, we encourage you to use the following references to learn \", \"more about composite UI based\\non microservices.\\nAdditional resources\\n\\u2022 Micro Frontends (Martin Fowle\", \"r\\u2019s blog)\\nhttps://martinfowler.com/articles/micro-frontends.html\\n\\u2022 Micro Frontends (Michael Geers si\", \"te)\\nhttps://micro-frontends.org/\\n\\u2022 Composite UI using ASP.NET (Particular\\u2019s Workshop)\\nhttps://github\", \".com/Particular/Workshop/tree/master/demos/asp-net-core\\n\\u2022 Ruben Oostinga. The Monolithic Frontend in\", \" the Microservices Architecture\\nhttps://xebia.com/blog/the-monolithic-frontend-in-the-microservices-\", \"architecture/\\n62 CHAPTER 3 | Architecting container and microservice-based applications\\u2022 Mauro Servi\", \"enti. The secret of better UI composition\\nhttps://particular.net/blog/secret-of-better-ui-compositio\", \"n\\n\\u2022 Viktor Farcic. Including Front-End Web Components Into Microservices\\nhttps://technologyconversat\", \"ions.com/2015/08/09/including-front-end-web-components-\\ninto-microservices/\\n\\u2022 Managing Frontend in t\", \"he Microservices Architecture\\nhttps://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-ar\", \"chitecture.html\\nResiliency and high availability in microservices\\nDealing with unexpected failures i\", \"s one of the hardest problems to solve, especially in a distributed\\nsystem. Much of the code that de\", \"velopers write involves handling exceptions, and this is also where\\nthe most time is spent in testin\", \"g. The problem is more involved than writing code to handle failures.\\nWhat happens when the machine \", \"where the microservice is running fails? Not only do you need to\\ndetect this microservice failure (a\", \" hard problem on its own), but you also need something to restart\\nyour microservice.\\nA microservice \", \"needs to be resilient to failures and to be able to restart often on another machine for\\navailabilit\", \"y. This resiliency also comes down to the state that was saved on behalf of the microservice,\\nwhere \", \"the microservice can recover this state from, and whether the microservice can restart\\nsuccessfully.\", \" In other words, there needs to be resiliency in the compute capability (the process can\\nrestart at \", \"any time) as well as resilience in the state or data (no data loss, and the data remains\\nconsistent)\", \".\\nThe problems of resiliency are compounded during other scenarios, such as when failures occur\\nduri\", \"ng an application upgrade. The microservice, working with the deployment system, needs to\\ndetermine \", \"whether it can continue to move forward to the newer version or instead roll back to a\\nprevious vers\", \"ion to maintain a consistent state. Questions such as whether enough machines are\\navailable to keep \", \"moving forward and how to recover previous versions of the microservice need to\\nbe considered. This \", \"approach requires the microservice to emit health information so that the overall\\napplication and or\", \"chestrator can make these decisions.\\nIn addition, resiliency is related to how cloud-based systems m\", \"ust behave. As mentioned, a cloud-\\nbased system must embrace failures and must try to automatically \", \"recover from them. For instance, in\\ncase of network or container failures, client apps or client ser\", \"vices must have a strategy to retry\\nsending messages or to retry requests, since in many cases failu\", \"res in the cloud are partial. The\\nImplementing Resilient Applications section in this guide addresse\", \"s how to handle partial failure. It\\ndescribes techniques like retries with exponential backoff or th\", \"e Circuit Breaker pattern in .NET by\\nusing libraries like Polly, which offers a large variety of pol\", \"icies to handle this subject.\\nHealth management and diagnostics in microservices\\nIt may seem obvious\", \", and it\\u2019s often overlooked, but a microservice must report its health and\\ndiagnostics. Otherwise, t\", \"here\\u2019s little insight from an operations perspective. Correlating diagnostic\\nevents across a set of \", \"independent services and dealing with machine clock skews to make sense of\\n63 CHAPTER 3 | Architecti\", \"ng container and microservice-based applicationsthe event order is challenging. In the same way that\", \" you interact with a microservice over agreed-\\nupon protocols and data formats, there\\u2019s a need for s\", \"tandardization in how to log health and\\ndiagnostic events that ultimately end up in an event store f\", \"or querying and viewing. In a microservices\\napproach, it\\u2019s key that different teams agree on a singl\", \"e logging format. There needs to be a\\nconsistent approach to viewing diagnostic events in the applic\", \"ation.\\nHealth checks\\nHealth is different from diagnostics. Health is about the microservice reportin\", \"g its current state to take\\nappropriate actions. A good example is working with upgrade and deployme\", \"nt mechanisms to\\nmaintain availability. Although a service might currently be unhealthy due to a pro\", \"cess crash or\\nmachine reboot, the service might still be operational. The last thing you need is to \", \"make this worse\\nby performing an upgrade. The best approach is to do an investigation first or allow\", \" time for the\\nmicroservice to recover. Health events from a microservice help us make informed decis\", \"ions and, in\\neffect, help create self-healing services.\\nIn the Implementing health checks in ASP.NET\", \" Core services section of this guide, we explain how to\\nuse a new ASP.NET HealthChecks library in yo\", \"ur microservices so they can report their state to a\\nmonitoring service to take appropriate actions.\", \"\\nYou also have the option of using an excellent open-source library called\\nAspNetCore.Diagnostics.He\", \"althChecks, available on GitHub and as a NuGet package. This library also\\ndoes health checks, with a\", \" twist, it handles two types of checks:\\n\\u2022 Liveness: Checks if the microservice is alive, that is, if\", \" it\\u2019s able to accept requests and respond.\\n\\u2022 Readiness: Checks if the microservice\\u2019s dependencies (D\", \"atabase, queue services, etc.) are\\nthemselves ready, so the microservice can do what it\\u2019s supposed t\", \"o do.\\nUsing diagnostics and logs event streams\\nLogs provide information about how an application or \", \"service is running, including exceptions,\\nwarnings, and simple informational messages. Usually, each\", \" log is in a text format with one line per\\nevent, although exceptions also often show the stack trac\", \"e across multiple lines.\\nIn monolithic server-based applications, you can write logs to a file on di\", \"sk (a logfile) and then analyze\\nit with any tool. Since application execution is limited to a fixed \", \"server or VM, it generally isn\\u2019t too\\ncomplex to analyze the flow of events. However, in a distribute\", \"d application where multiple services\\nare executed across many nodes in an orchestrator cluster, bei\", \"ng able to correlate distributed events\\nis a challenge.\\nA microservice-based application should not \", \"try to store the output stream of events or logfiles by\\nitself, and not even try to manage the routi\", \"ng of the events to a central place. It should be\\ntransparent, meaning that each process should just\", \" write its event stream to a standard output that\\nunderneath will be collected by the execution envi\", \"ronment infrastructure where it\\u2019s running. An\\nexample of these event stream routers is Microsoft.Dia\", \"gnostic.EventFlow, which collects event streams\\nfrom multiple sources and publishes it to output sys\", \"tems. These can include simple standard output\\nfor a development environment or cloud systems like A\", \"zure Monitor and Azure Diagnostics. There are\\nalso good third-party log analysis platforms and tools\", \" that can search, alert, report, and monitor logs,\\neven in real time, like Splunk.\\n64 CHAPTER 3 | Ar\", \"chitecting container and microservice-based applicationsOrchestrators managing health and diagnostic\", \"s information\\nWhen you create a microservice-based application, you need to deal with complexity. Of\", \" course, a\\nsingle microservice is simple to deal with, but dozens or hundreds of types and thousands\", \" of\\ninstances of microservices is a complex problem. It isn\\u2019t just about building your microservice\\n\", \"architecture\\u2014you also need high availability, addressability, resiliency, health, and diagnostics if\", \" you\\nintend to have a stable and cohesive system.\\nFigure 4-22. A Microservice Platform is fundamenta\", \"l for an application\\u2019s health management\\nThe complex problems shown in Figure 4-22 are hard to solve\", \" by yourself. Development teams should\\nfocus on solving business problems and building custom applic\", \"ations with microservice-based\\napproaches. They should not focus on solving complex infrastructure p\", \"roblems; if they did, the cost of\\nany microservice-based application would be huge. Therefore, there\", \" are microservice-oriented\\nplatforms, referred to as orchestrators or microservice clusters, that tr\", \"y to solve the hard problems of\\nbuilding and running a service and using infrastructure resources ef\", \"ficiently. This approach reduces\\nthe complexities of building applications that use a microservices \", \"approach.\\nDifferent orchestrators might sound similar, but the diagnostics and health checks offered\", \" by each of\\nthem differ in features and state of maturity, sometimes depending on the OS platform, a\", \"s explained\\nin the next section.\\nAdditional resources\\n\\u2022 The Twelve-Factor App. XI. Logs: Treat logs \", \"as event streams\\nhttps://12factor.net/logs\\n\\u2022 Microsoft Diagnostic EventFlow Library GitHub repo.\\nhtt\", \"ps://github.com/Azure/diagnostics-eventflow\\n\\u2022 What is Azure Diagnostics\\nhttps://learn.microsoft.com/\", \"azure/azure-diagnostics\\n65 CHAPTER 3 | Architecting container and microservice-based applications\\u2022 C\", \"onnect Windows computers to the Azure Monitor service\\nhttps://learn.microsoft.com/azure/azure-monito\", \"r/platform/agent-windows\\n\\u2022 Logging What You Mean: Using the Semantic Logging Application Block\\nhttps\", \"://learn.microsoft.com/previous-versions/msp-n-p/dn440729(v=pandp.60)\\n\\u2022 Splunk Official site.\\nhttps:\", \"//www.splunk.com/\\n\\u2022 EventSource Class API for events tracing for Windows (ETW)\\nhttps://learn.microso\", \"ft.com/dotnet/api/system.diagnostics.tracing.eventsource\\nOrchestrate microservices and multi-contain\", \"er\\napplications for high scalability and availability\\nUsing orchestrators for production-ready appli\", \"cations is essential if your application is based on\\nmicroservices or simply split across multiple c\", \"ontainers. As introduced previously, in a microservice-\\nbased approach, each microservice owns its m\", \"odel and data so that it will be autonomous from a\\ndevelopment and deployment point of view. But eve\", \"n if you have a more traditional application that\\u2019s\\ncomposed of multiple services (like SOA), you\\u2019ll\", \" also have multiple containers or services comprising a\\nsingle business application that need to be \", \"deployed as a distributed system. These kinds of systems\\nare complex to scale out and manage; theref\", \"ore, you absolutely need an orchestrator if you want to\\nhave a production-ready and scalable multi-c\", \"ontainer application.\\nFigure 4-23 illustrates deployment into a cluster of an application composed o\", \"f multiple microservices\\n(containers).\\n66 CHAPTER 3 | Architecting container and microservice-based \", \"applicationsFigure 4-23. A cluster of containers\\nYou use one container for each service instance. Do\", \"cker containers are \\u201cunits of deployment\\u201d and a\\ncontainer is an instance of a Docker. A host handles\", \" many containers. It looks like a logical approach.\\nBut how are you handling load-balancing, routing\", \", and orchestrating these composed applications?\\nThe plain Docker Engine in single Docker hosts meet\", \"s the needs of managing single image instances\\non one host, but it falls short when it comes to mana\", \"ging multiple containers deployed on multiple\\nhosts for more complex distributed applications. In mo\", \"st cases, you need a management platform\\nthat will automatically start containers, scale out contain\", \"ers with multiple instances per image,\\nsuspend them or shut them down when needed, and ideally also \", \"control how they access resources\\nlike the network and data storage.\\nTo go beyond the management of \", \"individual containers or simple composed apps and move toward\\nlarger enterprise applications with mi\", \"croservices, you must turn to orchestration and clustering\\nplatforms.\\nFrom an architecture and devel\", \"opment point of view, if you\\u2019re building large enterprise composed of\\nmicroservices-based applicatio\", \"ns, it\\u2019s important to understand the following platforms and products\\nthat support advanced scenario\", \"s:\\nClusters and orchestrators. When you need to scale out applications across many Docker hosts, as\\n\", \"when a large microservice-based application, it\\u2019s critical to be able to manage all those hosts as a\", \"\\nsingle cluster by abstracting the complexity of the underlying platform. That\\u2019s what the container\\n\", \"clusters and orchestrators provide. Kubernetes is an example of an orchestrator, and is available in\", \"\\nAzure through Azure Kubernetes Service.\\nSchedulers. Scheduling means to have the capability for an \", \"administrator to launch containers in a\\ncluster so they also provide a UI. A cluster scheduler has s\", \"everal responsibilities: to use the cluster\\u2019s\\n67 CHAPTER 3 | Architecting container and microservice\", \"-based applicationsresources efficiently, to set the constraints provided by the user, to efficientl\", \"y load-balance containers\\nacross nodes or hosts, and to be robust against errors while providing hig\", \"h availability.\\nThe concepts of a cluster and a scheduler are closely related, so the products provi\", \"ded by different\\nvendors often provide both sets of capabilities. The following list shows the most \", \"important platform\\nand software choices you have for clusters and schedulers. These orchestrators ar\", \"e generally offered\\nin public clouds like Azure.\\nSoftware platforms for container clustering, orches\", \"tration, and\\nscheduling\\nPlatform Description\\nKubernetes Kubernetes is an open-source\\nproduct that pr\", \"ovides functionality\\nthat ranges from cluster\\ninfrastructure and container\\nscheduling to orchestrati\", \"ng\\ncapabilities. It lets you automate\\ndeployment, scaling, and\\noperations of application\\ncontainers \", \"across clusters of hosts.\\nKubernetes provides a container-\\ncentric infrastructure that groups\\napplic\", \"ation containers into logical\\nunits for easy management and\\ndiscovery.\\nKubernetes is mature in Linux\", \", less\\nmature in Windows.\\nAzure Kubernetes Service (AKS) AKS is a managed Kubernetes\\ncontainer orche\", \"stration service in\\nAzure that simplifies Kubernetes\\ncluster\\u2019s management, deployment,\\nand operation\", \"s.\\nAzure Container Apps Azure Container Apps is a managed\\nserverless container service for\\nbuilding \", \"and deploying modern\\napps at scale.\\nUsing container-based orchestrators in Microsoft Azure\\nSeveral c\", \"loud vendors offer Docker containers support plus Docker clusters and orchestration support,\\nincludi\", \"ng Microsoft Azure, Amazon EC2 Container Service, and Google Container Engine. Microsoft\\nAzure provi\", \"des Docker cluster and orchestrator support through Azure Kubernetes Service (AKS).\\n68 CHAPTER 3 | A\", \"rchitecting container and microservice-based applicationsUsing Azure Kubernetes Service\\nA Kubernetes\", \" cluster pools multiple Docker hosts and exposes them as a single virtual Docker host, so\\nyou can de\", \"ploy multiple containers into the cluster and scale-out with any number of container\\ninstances. The \", \"cluster will handle all the complex management plumbing, like scalability, health, and\\nso forth.\\nAKS\", \" provides a way to simplify the creation, configuration, and management of a cluster of virtual\\nmach\", \"ines in Azure that are preconfigured to run containerized applications. Using an optimized\\nconfigura\", \"tion of popular open-source scheduling and orchestration tools, AKS enables you to use\\nyour existing\", \" skills or draw on a large and growing body of community expertise to deploy and\\nmanage container-ba\", \"sed applications on Microsoft Azure.\\nAzure Kubernetes Service optimizes the configuration of popular\", \" Docker clustering open-source tools\\nand technologies specifically for Azure. You get an open soluti\", \"on that offers portability for both your\\ncontainers and your application configuration. You select t\", \"he size, the number of hosts, and the\\norchestrator tools, and AKS handles everything else.\\nFigure 4-\", \"24. Kubernetes cluster\\u2019s simplified structure and topology\\n69 CHAPTER 3 | Architecting container and\", \" microservice-based applicationsIn figure 4-24, you can see the structure of a Kubernetes cluster wh\", \"ere a master node (VM) controls\\nmost of the coordination of the cluster and you can deploy container\", \"s to the rest of the nodes, which\\nare managed as a single pool from an application point of view and\", \" allows you to scale to thousands\\nor even tens of thousands of containers.\\nDevelopment environment f\", \"or Kubernetes\\nIn the development environment, Docker announced in July 2018 that Kubernetes can also\", \" run in a\\nsingle development machine (Windows 10 or macOS) by installing Docker Desktop. You can lat\", \"er\\ndeploy to the cloud (AKS) for further integration tests, as shown in figure 4-25.\\nFigure 4-25. Ru\", \"nning Kubernetes in dev machine and the cloud\\nGetting started with Azure Kubernetes Service (AKS)\\nTo\", \" begin using AKS, you deploy an AKS cluster from the Azure portal or by using the CLI. For more\\ninfo\", \"rmation on deploying a Kubernetes cluster in Azure, see Deploy an Azure Kubernetes Service\\n(AKS) clu\", \"ster.\\nThere are no fees for any of the software installed by default as part of AKS. All default opt\", \"ions are\\nimplemented with open-source software. AKS is available for multiple virtual machines in Az\", \"ure.\\nYou\\u2019re charged only for the compute instances you choose, and the other underlying infrastructu\", \"re\\nresources consumed, such as storage and networking. There are no incremental charges for AKS itse\", \"lf.\\nThe default production deployment option for Kubernetes is to use Helm charts, which are introdu\", \"ced\\nin the next section.\\n70 CHAPTER 3 | Architecting container and microservice-based applicationsDe\", \"ploy with Helm charts into Kubernetes clusters\\nWhen deploying an application to a Kubernetes cluster\", \", you can use the original kubectl.exe CLI tool\\nusing deployment files based on the native format (.\", \"yaml files), as already mentioned in the previous\\nsection. However, for more complex Kubernetes appl\", \"ications such as when deploying complex\\nmicroservice-based applications, it\\u2019s recommended to use Hel\", \"m.\\nHelm Charts helps you define, version, install, share, upgrade, or rollback even the most complex\", \"\\nKubernetes application.\\nGoing further, Helm usage is also recommended because other Kubernetes envi\", \"ronments in Azure,\\nsuch as Azure Dev Spaces are also based on Helm charts.\\nHelm is maintained by the\", \" Cloud Native Computing Foundation (CNCF) - in collaboration with\\nMicrosoft, Google, Bitnami, and th\", \"e Helm contributor community.\\nFor more implementation information on Helm charts and Kubernetes, see\", \" the Using Helm Charts to\\ndeploy eShopOnContainers to AKS post.\\nAdditional resources\\n\\u2022 Getting start\", \"ed with Azure Kubernetes Service (AKS)\\nhttps://learn.microsoft.com/azure/aks/kubernetes-walkthrough-\", \"portal\\n\\u2022 Azure Dev Spaces\\nhttps://learn.microsoft.com/azure/dev-spaces/azure-dev-spaces\\n\\u2022 Kubernetes\", \" The official site.\\nhttps://kubernetes.io/\\n71 CHAPTER 3 | Architecting container and microservice-ba\", \"sed applications4\\nCHAPTER\\nDevelopment process for\\nDocker-based applications\\nDevelop containerized .N\", \"ET applications the way you like, either Integrated Development Environment\\n(IDE) focused with Visua\", \"l Studio and Visual Studio tools for Docker or CLI/Editor focused with Docker CLI\\nand Visual Studio \", \"Code.\\nDevelopment environment for Docker apps\\nDevelopment tool choices: IDE or editor\\nWhether you pr\", \"efer a full and powerful IDE or a lightweight and agile editor, Microsoft has tools that\\nyou can use\", \" for developing Docker applications.\\nVisual Studio (for Windows). Docker-based .NET 7 application de\", \"velopment with Visual Studio\\nrequires Visual Studio 2022 version 17.0 or later. Visual Studio 2022 c\", \"omes with tools for Docker\\nalready built in. The tools for Docker let you develop, run, and validate\", \" your applications directly in the\\ntarget Docker environment. You can press F5 to run and debug your\", \" application (single container or\\nmultiple containers) directly into a Docker host, or press CTRL + \", \"F5 to edit and refresh your\\napplication without having to rebuild the container. This IDE is the mos\", \"t powerful development choice\\nfor Docker-based apps.\\nVisual Studio for Mac. It\\u2019s an IDE, evolution o\", \"f Xamarin Studio, running in macOS. This tool should\\nbe the preferred choice for developers working \", \"in macOS machines who also want to use a powerful\\nIDE.\\nVisual Studio Code and Docker CLI. If you pre\", \"fer a lightweight and cross-platform editor that\\nsupports any development language, you can use Visu\", \"al Studio Code and the Docker CLI. This IDE is a\\ncross-platform development approach for macOS, Linu\", \"x, and Windows. Additionally, Visual Studio\\nCode supports extensions for Docker such as IntelliSense\", \" for Dockerfiles and shortcut tasks to run\\nDocker commands from the editor.\\nBy installing Docker Des\", \"ktop, you can use a single Docker CLI to build apps for both Windows and\\nLinux.\\n72 CHAPTER 4 | Devel\", \"opment process for Docker-based applicationsAdditional resources\\n\\u2022 Visual Studio. Official site.\\nhtt\", \"ps://visualstudio.microsoft.com/vs/\\n\\u2022 Visual Studio Code. Official site.\\nhttps://code.visualstudio.c\", \"om/download\\n\\u2022 Docker Desktop for Windows\\nhttps://hub.docker.com/editions/community/docker-ce-desktop\", \"-windows\\n\\u2022 Docker Desktop for Mac\\nhttps://hub.docker.com/editions/community/docker-ce-desktop-mac\\n.N\", \"ET languages and frameworks for Docker\\ncontainers\\nAs mentioned in earlier sections of this guide, yo\", \"u can use .NET Framework, .NET 7, or the open-\\nsource Mono project when developing Docker containeri\", \"zed .NET applications. You can develop in\\nC#, F#, or Visual Basic when targeting Linux or Windows Co\", \"ntainers, depending on which .NET\\nframework is in use. For more details about.NET languages, see the\", \" blog post The .NET Language\\nStrategy.\\nDevelopment workflow for Docker apps\\nThe application developm\", \"ent life cycle starts at your computer, as a developer, where you code the\\napplication using your pr\", \"eferred language and test it locally. With this workflow, no matter which\\nlanguage, framework, and p\", \"latform you choose, you\\u2019re always developing and testing Docker\\ncontainers, but doing so locally.\\nEa\", \"ch container (an instance of a Docker image) includes the following components:\\n\\u2022 An operating syste\", \"m selection, for example, a Linux distribution, Windows Nano Server, or\\nWindows Server Core.\\n\\u2022 Files\", \" added during development, for example, source code and application binaries.\\n\\u2022 Configuration inform\", \"ation, such as environment settings and dependencies.\\nWorkflow for developing Docker container-based\", \" applications\\nThis section describes the inner-loop development workflow for Docker container-based \", \"applications.\\nThe inner-loop workflow means it\\u2019s not considering the broader DevOps workflow, which \", \"can include\\nup to production deployment, and just focuses on the development work done on the develo\", \"per\\u2019s\\ncomputer. The initial steps to set up the environment aren\\u2019t included, since those steps are d\", \"one only\\nonce.\\n73 CHAPTER 4 | Development process for Docker-based applicationsAn application is com\", \"posed of your own services plus additional libraries (dependencies). The\\nfollowing are the basic ste\", \"ps you usually take when building a Docker application, as illustrated in\\nFigure 5-1.\\nFigure 5-1. St\", \"ep-by-step workflow for developing Docker containerized apps\\nIn this section, this whole process is \", \"detailed and every major step is explained by focusing on a Visual\\nStudio environment.\\nWhen you\\u2019re u\", \"sing an editor/CLI development approach (for example, Visual Studio Code plus Docker\\nCLI on macOS or\", \" Windows), you need to know every step, generally in more detail than if you\\u2019re using\\nVisual Studio.\", \" For more information about working in a CLI environment, see the e-book\\nContainerized Docker Applic\", \"ation lifecycle with Microsoft Platforms and Tools.\\nWhen you\\u2019re using Visual Studio 2022, many of th\", \"ose steps are handled for you, which dramatically\\nimproves your productivity. This is especially tru\", \"e when you\\u2019re using Visual Studio 2022 and targeting\\nmulti-container applications. For instance, wit\", \"h just one mouse click, Visual Studio adds the Dockerfile\\nand docker-compose.yml file to your projec\", \"ts with the configuration for your application. When you\\nrun the application in Visual Studio, it bu\", \"ilds the Docker image and runs the multi-container\\napplication directly in Docker; it even allows yo\", \"u to debug several containers at once. These features\\nwill boost your development speed.\\nHowever, ju\", \"st because Visual Studio makes those steps automatic doesn\\u2019t mean that you don\\u2019t need\\nto know what\\u2019s\", \" going on underneath with Docker. Therefore, the following guidance details every\\nstep.\\n74 CHAPTER 4\", \" | Development process for Docker-based applicationsStep 1. Start coding and create your initial app\", \"lication or service\\nbaseline\\nDeveloping a Docker application is similar to the way you develop an ap\", \"plication without Docker. The\\ndifference is that while developing for Docker, you\\u2019re deploying and t\", \"esting your application or\\nservices running within Docker containers in your local environment (eith\", \"er a Linux VM setup by\\nDocker or directly Windows if using Windows Containers).\\nSet up your local en\", \"vironment with Visual Studio\\nTo begin, make sure you have Docker Desktop for Windows for Windows ins\", \"talled, as explained in the\\nfollowing instructions:\\nGet started with Docker Desktop for Windows\\nIn a\", \"ddition, you need Visual Studio 2022 version 17.0, with the .ASP.NET and web development\\nworkload in\", \"stalled, as shown in Figure 5-2.\\nFigure 5-2. Selecting the ASP.NET and web development workload duri\", \"ng Visual Studio 2022 setup\\nYou can start coding your application in plain .NET (usually in .NET Cor\", \"e or later if you\\u2019re planning to\\nuse containers) even before enabling Docker in your application and\", \" deploying and testing in Docker.\\nHowever, it is recommended that you start working on Docker as soo\", \"n as possible, because that will\\nbe the real environment and any issues can be discovered as soon as\", \" possible. This is encouraged\\n75 CHAPTER 4 | Development process for Docker-based applicationsbecaus\", \"e Visual Studio makes it so easy to work with Docker that it almost feels transparent\\u2014the best\\nexamp\", \"le when debugging multi-container applications from Visual Studio.\\nAdditional resources\\n\\u2022 Get starte\", \"d with Docker Desktop for Windows\\nhttps://docs.docker.com/docker-for-windows/\\n\\u2022 Visual Studio 2022\\nh\", \"ttps://visualstudio.microsoft.com/downloads/\\nStep 2. Create a Dockerfile related to an existing .NET\", \" base image\\nYou need a Dockerfile for each custom image you want to build; you also need a Dockerfil\", \"e for each\\ncontainer to be deployed, whether you deploy automatically from Visual Studio or manually\", \" using the\\nDocker CLI (docker run and docker-compose commands). If your application contains a singl\", \"e custom\\nservice, you need a single Dockerfile. If your application contains multiple services (as i\", \"n a\\nmicroservices architecture), you need one Dockerfile for each service.\\nThe Dockerfile is placed \", \"in the root folder of your application or service. It contains the commands\\nthat tell Docker how to \", \"set up and run your application or service in a container. You can manually\\ncreate a Dockerfile in c\", \"ode and add it to your project along with your .NET dependencies.\\nWith Visual Studio and its tools f\", \"or Docker, this task requires only a few mouse clicks. When you\\ncreate a new project in Visual Studi\", \"o 2022, there\\u2019s an option named Enable Docker Support, as\\nshown in Figure 5-3.\\n76 CHAPTER 4 | Develo\", \"pment process for Docker-based applicationsFigure 5-3. Enabling Docker Support when creating a new A\", \"SP.NET Core project in Visual Studio 2022\\nYou can also enable Docker support on an existing ASP.NET \", \"Core web app project by right-clicking\\nthe project in Solution Explorer and selecting Add > Docker S\", \"upport\\u2026, as shown in Figure 5-4.\\nFigure 5-4. Enabling Docker support in an existing Visual Studio 20\", \"22 project\\n77 CHAPTER 4 | Development process for Docker-based applicationsThis action adds a Docker\", \"file to the project with the required configuration, and is only available on\\nASP.NET Core projects.\", \"\\nIn a similar fashion, Visual Studio can also add a docker-compose.yml file for the whole solution w\", \"ith\\nthe option Add > Container Orchestrator Support\\u2026. In step 4, we\\u2019ll explore this option in greate\", \"r\\ndetail.\\nUsing an existing official .NET Docker image\\nYou usually build a custom image for your con\", \"tainer on top of a base image you get from an official\\nrepository like the Docker Hub registry. That\", \" is precisely what happens under the covers when you\\nenable Docker support in Visual Studio. Your Do\", \"ckerfile will use an existing dotnet/core/aspnet image.\\nEarlier we explained which Docker images and\", \" repos you can use, depending on the framework and\\nOS you have chosen. For instance, if you want to \", \"use ASP.NET Core (Linux or Windows), the image to\\nuse is mcr.microsoft.com/dotnet/aspnet:7.0. Theref\", \"ore, you just need to specify what base Docker\\nimage you will use for your container. You do that by\", \" adding FROM\\nmcr.microsoft.com/dotnet/aspnet:7.0 to your Dockerfile. This will be automatically perf\", \"ormed by\\nVisual Studio, but if you were to update the version, you update this value.\\nUsing an offic\", \"ial .NET image repository from Docker Hub with a version number ensures that the same\\nlanguage featu\", \"res are available on all machines (including development, testing, and production).\\nThe following ex\", \"ample shows a sample Dockerfile for an ASP.NET Core container.\\nFROM mcr.microsoft.com/dotnet/aspnet:\", \"7.0\\nARG source\\nWORKDIR /app\\nEXPOSE 80\\nCOPY ${source:-obj/Docker/publish} .\\nENTRYPOINT [\\\"dotnet\\\", \\\" M\", \"ySingleContainerWebApp.dll \\\"]\\nIn this case, the image is based on version 7.0 of the official ASP.NE\", \"T Core Docker image (multi-arch\\nfor Linux and Windows). This is the setting FROM mcr.microsoft.com/d\", \"otnet/aspnet:7.0. (For more\\ninformation about this base image, see the ASP.NET Core Docker Image pag\", \"e.) In the Dockerfile, you\\nalso need to instruct Docker to listen on the TCP port you will use at ru\", \"ntime (in this case, port 80, as\\nconfigured with the EXPOSE setting).\\nYou can specify additional con\", \"figuration settings in the Dockerfile, depending on the language and\\nframework you\\u2019re using. For ins\", \"tance, the ENTRYPOINT line with [\\\"dotnet\\\",\\n\\\"MySingleContainerWebApp.dll\\\"] tells Docker to run a .NET\", \" application. If you\\u2019re using the SDK and\\nthe .NET CLI (dotnet CLI) to build and run the .NET applic\", \"ation, this setting would be different. The\\nbottom line is that the ENTRYPOINT line and other settin\", \"gs will be different depending on the\\nlanguage and platform you choose for your application.\\nAdditio\", \"nal resources\\n\\u2022 Building Docker Images for ASP.NET Core Applications\\nhttps://learn.microsoft.com/dot\", \"net/core/docker/building-net-docker-images\\n78 CHAPTER 4 | Development process for Docker-based appli\", \"cations\\u2022 Build your own image. In the official Docker documentation.\\nhttps://docs.docker.com/engine/\", \"tutorials/dockerimages/\\n\\u2022 Staying up-to-date with .NET Container Images\\nhttps://devblogs.microsoft.c\", \"om/dotnet/staying-up-to-date-with-net-container-images/\\n\\u2022 Using .NET and Docker Together - DockerCon\", \" 2018 Update\\nhttps://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2018-\\nupd\", \"ate/\\nUsing multi-arch image repositories\\nA single repo can contain platform variants, such as a Linu\", \"x image and a Windows image. This feature\\nallows vendors like Microsoft (base image creators) to cre\", \"ate a single repo to cover multiple platforms\\n(that is Linux and Windows). For example, the .NET rep\", \"ository available in the Docker Hub registry\\nprovides support for Linux and Windows Nano Server by u\", \"sing the same repo name.\\nIf you specify a tag, targeting a platform that is explicit like in the fol\", \"lowing cases:\\n\\u2022 mcr.microsoft.com/dotnet/aspnet:7.0-bullseye-slim\\nTargets: .NET 7 runtime-only on Li\", \"nux\\n\\u2022 mcr.microsoft.com/dotnet/aspnet:7.0-nanoserver-ltsc2022\\nTargets: .NET 7 runtime-only on Window\", \"s Nano Server\\nBut, if you specify the same image name, even with the same tag, the multi-arch images\", \" (like the\\naspnet image) will use the Linux or Windows version depending on the Docker host OS you\\u2019r\", \"e\\ndeploying, as shown in the following example:\\n\\u2022 mcr.microsoft.com/dotnet/aspnet:7.0\\nMulti-arch: .N\", \"ET 7 runtime-only on Linux or Windows Nano Server depending on the Docker\\nhost OS\\nThis way, when you\", \" pull an image from a Windows host, it will pull the Windows variant, and pulling\\nthe same image nam\", \"e from a Linux host will pull the Linux variant.\\nMulti-stage builds in Dockerfile\\nThe Dockerfile is \", \"similar to a batch script. Similar to what you would do if you had to set up the\\nmachine from the co\", \"mmand line.\\nIt starts with a base image that sets up the initial context, it\\u2019s like the startup file\", \"system, that sits on\\ntop of the host OS. It\\u2019s not an OS, but you can think of it like \\u201cthe\\u201d OS insid\", \"e the container.\\nThe execution of every command line creates a new layer on the filesystem with the \", \"changes from the\\nprevious one, so that, when combined, produce the resulting filesystem.\\nSince every\", \" new layer \\u201crests\\u201d on top of the previous one and the resulting image size increases with\\nevery comm\", \"and, images can get very large if they have to include, for example, the SDK needed to\\nbuild and pub\", \"lish an application.\\nThis is where multi-stage builds get into the plot (from Docker 17.05 and highe\", \"r) to do their magic.\\n79 CHAPTER 4 | Development process for Docker-based applicationsThe core idea \", \"is that you can separate the Dockerfile execution process in stages, where a stage is an\\ninitial ima\", \"ge followed by one or more commands, and the last stage determines the final image size.\\nIn short, m\", \"ulti-stage builds allow splitting the creation in different \\u201cphases\\u201d and then assemble the\\nfinal ima\", \"ge taking only the relevant directories from the intermediate stages. The general strategy to\\nuse th\", \"is feature is:\\n1. Use a base SDK image (doesn\\u2019t matter how large), with everything needed to build a\", \"nd\\npublish the application to a folder and then\\n2. Use a base, small, runtime-only image and copy th\", \"e publishing folder from the previous stage\\nto produce a small final image.\\nProbably the best way to\", \" understand multi-stage is going through a Dockerfile in detail, line by line,\\nso let\\u2019s begin with t\", \"he initial Dockerfile created by Visual Studio when adding Docker support to a\\nproject and will get \", \"into some optimizations later.\\nThe initial Dockerfile might look something like this:\\n1 FROM mcr.mic\", \"rosoft.com/dotnet/aspnet:7.0 AS base\\n2 WORKDIR /app\\n3 EXPOSE 80\\n4\\n5 FROM mcr.microsoft.com/dotnet/sd\", \"k:7.0 AS build\\n6 WORKDIR /src\\n7 COPY src/Services/Catalog/Catalog.API/Catalog.API.csproj \\u2026\\n8 COPY sr\", \"c/BuildingBlocks/HealthChecks/src/Microsoft.AspNetCore.HealthChecks \\u2026\\n9 COPY src/BuildingBlocks/Heal\", \"thChecks/src/Microsoft.Extensions.HealthChecks \\u2026\\n10 COPY src/BuildingBlocks/EventBus/IntegrationEven\", \"tLogEF/ \\u2026\\n11 COPY src/BuildingBlocks/EventBus/EventBus/EventBus.csproj \\u2026\\n12 COPY src/BuildingBlocks/\", \"EventBus/EventBusRabbitMQ/EventBusRabbitMQ.csproj \\u2026\\n13 COPY src/BuildingBlocks/EventBus/EventBusServ\", \"iceBus/EventBusServiceBus.csproj \\u2026\\n14 COPY src/BuildingBlocks/WebHostCustomization/WebHost.Customiza\", \"tion \\u2026\\n15 COPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions \\u2026\\n16 COPY src/BuildingBlocks\", \"/HealthChecks/src/Microsoft.Extensions \\u2026\\n17 RUN dotnet restore src/Services/Catalog/Catalog.API/Cata\", \"log.API.csproj\\n18 COPY . .\\n19 WORKDIR /src/src/Services/Catalog/Catalog.API\\n20 RUN dotnet build Cata\", \"log.API.csproj -c Release -o /app\\n21\\n22 FROM build AS publish\\n23 RUN dotnet publish Catalog.API.cspr\", \"oj -c Release -o /app\\n24\\n25 FROM base AS final\\n26 WORKDIR /app\\n27 COPY --from=publish /app .\\n28 ENTR\", \"YPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"]\\nAnd these are the details, line by line:\\n\\u2022 Line #1: Begin a sta\", \"ge with a \\u201csmall\\u201d runtime-only base image, call it base for reference.\\n\\u2022 Line #2: Create the /app di\", \"rectory in the image.\\n\\u2022 Line #3: Expose port 80.\\n80 CHAPTER 4 | Development process for Docker-based\", \" applications\\u2022 Line #5: Begin a new stage with the \\u201clarge\\u201d image for building/publishing. Call it bu\", \"ild for\\nreference.\\n\\u2022 Line #6: Create directory /src in the image.\\n\\u2022 Line #7: Up to line 16, copy ref\", \"erenced .csproj project files to be able to restore packages\\nlater.\\n\\u2022 Line #17: Restore packages for\", \" the Catalog.API project and the referenced projects.\\n\\u2022 Line #18: Copy all directory tree for the so\", \"lution (except the files/directories included in the\\n.dockerignore file) to the /src directory in th\", \"e image.\\n\\u2022 Line #19: Change the current folder to the Catalog.API project.\\n\\u2022 Line #20: Build the pro\", \"ject (and other project dependencies) and output to the /app\\ndirectory in the image.\\n\\u2022 Line #22: Beg\", \"in a new stage continuing from the build. Call it publish for reference.\\n\\u2022 Line #23: Publish the pro\", \"ject (and dependencies) and output to the /app directory in the\\nimage.\\n\\u2022 Line #25: Begin a new stage\", \" continuing from base and call it final.\\n\\u2022 Line #26: Change the current directory to /app.\\n\\u2022 Line #2\", \"7: Copy the /app directory from stage publish to the current directory.\\n\\u2022 Line #28: Define the comma\", \"nd to run when the container is started.\\nNow let\\u2019s explore some optimizations to improve the whole p\", \"rocess performance that, in the case of\\neShopOnContainers, means about 22 minutes or more to build t\", \"he complete solution in Linux\\ncontainers.\\nYou\\u2019ll take advantage of Docker\\u2019s layer cache feature, whi\", \"ch is quite simple: if the base image and the\\ncommands are the same as some previously executed, it \", \"can just use the resulting layer without the\\nneed to execute the commands, thus saving some time.\\nSo\", \", let\\u2019s focus on the build stage, lines 5-6 are mostly the same, but lines 7-17 are different for ev\", \"ery\\nservice from eShopOnContainers, so they have to execute every single time, however if you change\", \"d\\nlines 7-16 to:\\nCOPY . .\\nThen it would be just the same for every service, it would copy the whole \", \"solution and would create a\\nlarger layer but:\\n1. The copy process would only be executed the first t\", \"ime (and when rebuilding if a file is\\nchanged) and would use the cache for all other services and\\n2.\", \" Since the larger image occurs in an intermediate stage, it doesn\\u2019t affect the final image size.\\n81 \", \"CHAPTER 4 | Development process for Docker-based applicationsThe next significant optimization invol\", \"ves the restore command executed in line 17, which is also\\ndifferent for every service of eShopOnCon\", \"tainers. If you change that line to just:\\nRUN dotnet restore\\nIt would restore the packages for the w\", \"hole solution, but then again, it would do it just once, instead\\nof the 15 times with the current st\", \"rategy.\\nHowever, dotnet restore only runs if there\\u2019s a single project or solution file in the folder\", \", so achieving\\nthis is a bit more complicated and the way to solve it, without getting into too many\", \" details, is this:\\n1. Add the following lines to .dockerignore:\\n\\u2013 *.sln, to ignore all solution file\", \"s in the main folder tree\\n\\u2013 !eShopOnContainers-ServicesAndWebApps.sln, to include only this solution\", \" file.\\n2. Include the /ignoreprojectextensions:.dcproj argument to dotnet restore, so it also ignore\", \"s the\\ndocker-compose project and only restores the packages for the eShopOnContainers-\\nServicesAndWe\", \"bApps solution.\\nFor the final optimization, it just happens that line 20 is redundant, as line 23 al\", \"so builds the\\napplication and comes, in essence, right after line 20, so there goes another time-con\", \"suming\\ncommand.\\nThe resulting file is then:\\n1 FROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base\\n2 WOR\", \"KDIR /app\\n3 EXPOSE 80\\n4\\n5 FROM mcr.microsoft.com/dotnet/sdk:7.0 AS publish\\n6 WORKDIR /src\\n7 COPY . .\", \"\\n8 RUN dotnet restore /ignoreprojectextensions:.dcproj\\n9 WORKDIR /src/src/Services/Catalog/Catalog.A\", \"PI\\n10 RUN dotnet publish Catalog.API.csproj -c Release -o /app\\n11\\n12 FROM base AS final\\n13 WORKDIR /\", \"app\\n14 COPY --from=publish /app .\\n15 ENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"]\\nCreating your base ima\", \"ge from scratch\\nYou can create your own Docker base image from scratch. This scenario is not recomme\", \"nded for\\nsomeone who is starting with Docker, but if you want to set the specific bits of your own b\", \"ase image,\\nyou can do so.\\nAdditional resources\\n\\u2022 Multi-arch .NET Core images.\\nhttps://github.com/dot\", \"net/announcements/issues/14\\n82 CHAPTER 4 | Development process for Docker-based applications\\u2022 Create\", \" a base image. Official Docker documentation.\\nhttps://docs.docker.com/develop/develop-images/baseima\", \"ges/\\nStep 3. Create your custom Docker images and embed your\\napplication or service in them\\nFor each\", \" service in your application, you need to create a related image. If your application is made up\\nof \", \"a single service or web application, you just need a single image.\\nNote that the Docker images are b\", \"uilt automatically for you in Visual Studio. The following steps are\\nonly needed for the editor/CLI \", \"workflow and explained for clarity about what happens underneath.\\nYou, as a developer, need to devel\", \"op and test locally until you push a completed feature or change to\\nyour source control system (for \", \"example, to GitHub). This means that you need to create the Docker\\nimages and deploy containers to a\", \" local Docker host (Windows or Linux VM) and run, test, and debug\\nagainst those local containers.\\nTo\", \" create a custom image in your local environment by using Docker CLI and your Dockerfile, you can\\nus\", \"e the docker build command, as in Figure 5-5.\\nFigure 5-5. Creating a custom Docker image\\nOptionally,\", \" instead of directly running docker build from the project folder, you can first generate a\\ndeployab\", \"le folder with the required .NET libraries and binaries by running dotnet publish, and then\\nuse the \", \"docker build command.\\nThis will create a Docker image with the name cesardl/netcore-webapi-microserv\", \"ice-docker:first. In\\nthis case, :first is a tag that represents a specific version. You can repeat t\", \"his step for each custom\\nimage you need to create for your composed Docker application.\\nWhen an appl\", \"ication is made of multiple containers (that is, it is a multi-container application), you\\ncan also \", \"use the docker-compose up --build command to build all the related images with a single\\ncommand by u\", \"sing the metadata exposed in the related docker-compose.yml files.\\nYou can find the existing images \", \"in your local repository by using the docker images command, as\\nshown in Figure 5-6.\\n83 CHAPTER 4 | \", \"Development process for Docker-based applicationsFigure 5-6. Viewing existing images using the docke\", \"r images command\\nCreating Docker images with Visual Studio\\nWhen you use Visual Studio to create a pr\", \"oject with Docker support, you don\\u2019t explicitly create an\\nimage. Instead, the image is created for y\", \"ou when you press F5 (or Ctrl+F5) to run the dockerized\\napplication or service. This step is automat\", \"ic in Visual Studio and you won\\u2019t see it happen, but it\\u2019s\\nimportant that you know what\\u2019s going on un\", \"derneath.\\nStep 4. Define your services in docker-compose.yml when building a\\nmulti-container Docker \", \"application\\nThe docker-compose.yml file lets you define a set of related services to be deployed as \", \"a composed\\napplication with deployment commands. It also configures its dependency relations and run\", \"time\\nconfiguration.\\nTo use a docker-compose.yml file, you need to create the file in your main or ro\", \"ot solution folder, with\\ncontent similar to that in the following example:\\nversion: '3.4'\\nservices:\\n\", \"webmvc:\\nimage: eshop/web\\nenvironment:\\n- CatalogUrl=http://catalog-api\\n- OrderingUrl=http://ordering-\", \"api\\nports:\\n- \\\"80:80\\\"\\ndepends_on:\\n- catalog-api\\n- ordering-api\\ncatalog-api:\\nimage: eshop/catalog-api\\n\", \"environment:\\n- ConnectionString=Server=sqldata;Port=1433;Database=CatalogDB;\\u2026\\nports:\\n- \\\"81:80\\\"\\ndepen\", \"ds_on:\\n- sqldata\\nordering-api:\\nimage: eshop/ordering-api\\n84 CHAPTER 4 | Development process for Dock\", \"er-based applicationsenvironment:\\n- ConnectionString=Server=sqldata;Database=OrderingDb;\\u2026\\nports:\\n- \\\"\", \"82:80\\\"\\nextra_hosts:\\n- \\\"CESARDLBOOKVHD:10.0.75.1\\\"\\ndepends_on:\\n- sqldata\\nsqldata:\\nimage: mcr.microsoft\", \".com/mssql/server:latest\\nenvironment:\\n- SA_PASSWORD=Pass@word\\n- ACCEPT_EULA=Y\\nports:\\n- \\\"5433:1433\\\"\\nT\", \"his docker-compose.yml file is a simplified and merged version. It contains static configuration dat\", \"a\\nfor each container (like the name of the custom image), which is always required, and configuratio\", \"n\\ninformation that might depend on the deployment environment, like the connection string. In later\\n\", \"sections, you will learn how to split the docker-compose.yml configuration into multiple docker-\\ncom\", \"pose files and override values depending on the environment and execution type (debug or\\nrelease).\\nT\", \"he docker-compose.yml file example defines four services: the webmvc service (a web application),\\ntw\", \"o microservices (ordering-api and basket-api), and one data source container, sqldata, based on\\nSQL \", \"Server for Linux running as a container. Each service will be deployed as a container, so a Docker\\ni\", \"mage is required for each.\\nThe docker-compose.yml file specifies not only what containers are being \", \"used, but how they are\\nindividually configured. For instance, the webmvc container definition in the\", \" .yml file:\\n\\u2022 Uses a pre-built eshop/web:latest image. However, you could also configure the image t\", \"o be\\nbuilt as part of the docker-compose execution with an additional configuration based on a\\nbuild\", \": section in the docker-compose file.\\n\\u2022 Initializes two environment variables (CatalogUrl and Orderi\", \"ngUrl).\\n\\u2022 Forwards the exposed port 80 on the container to the external port 80 on the host machine.\", \"\\n\\u2022 Links the web app to the catalog and ordering service with the depends_on setting. This\\ncauses th\", \"e service to wait until those services are started.\\nWe will revisit the docker-compose.yml file in a\", \" later section when we cover how to implement\\nmicroservices and multi-container apps.\\nWorking with d\", \"ocker-compose.yml in Visual Studio 2022\\nBesides adding a Dockerfile to a project, as we mentioned be\", \"fore, Visual Studio 2017 (from version\\n15.8 on) can add orchestrator support for Docker Compose to a\", \" solution.\\nWhen you add container orchestrator support, as shown in Figure 5-7, for the first time, \", \"Visual Studio\\ncreates the Dockerfile for the project and creates a new (service section) project in \", \"your solution with\\n85 CHAPTER 4 | Development process for Docker-based applicationsseveral global do\", \"cker-compose*.yml files, and then adds the project to those files. You can then open\\nthe docker-comp\", \"ose.yml files and update them with additional features.\\nRepeat this operation for every project you \", \"want to include in the docker-compose.yml file.\\nAt the time of this writing, Visual Studio supports \", \"Docker Compose orchestrators.\\nFigure 5-7. Adding Docker support in Visual Studio 2022 by right-click\", \"ing an ASP.NET Core project\\nAfter you add orchestrator support to your solution in Visual Studio, yo\", \"u will also see a new node (in\\nthe docker-compose.dcproj project file) in Solution Explorer that con\", \"tains the added docker-\\ncompose.yml files, as shown in Figure 5-8.\\nFigure 5-8. The docker-compose tr\", \"ee node added in Visual Studio 2022 Solution Explorer\\nYou could deploy a multi-container application\", \" with a single docker-compose.yml file by using the\\ndocker-compose up command. However, Visual Studi\", \"o adds a group of them so you can override\\nvalues depending on the environment (development or produ\", \"ction) and execution type (release or\\ndebug). This capability will be explained in later sections.\\n8\", \"6 CHAPTER 4 | Development process for Docker-based applicationsStep 5. Build and run your Docker app\", \"lication\\nIf your application only has a single container, you can run it by deploying it to your Doc\", \"ker host (VM\\nor physical server). However, if your application contains multiple services, you can d\", \"eploy it as a\\ncomposed application, either using a single CLI command (docker-compose up), or with V\", \"isual Studio,\\nwhich will use that command under the covers. Let\\u2019s look at the different options.\\nOpt\", \"ion A: Running a single-container application\\nUsing Docker CLI\\nYou can run a Docker container using \", \"the docker run command, as shown in Figure 5-9:\\ndocker run -t -d -p 80:5000 cesardl/netcore-webapi-m\", \"icroservice-docker:first\\nThe above command will create a new container instance from the specified i\", \"mage, every time it\\u2019s run.\\nYou can use the --name parameter to give a name to the container and then\", \" use docker start {name}\\n(or use the container ID or automatic name) to run an existing container in\", \"stance.\\nFigure 5-9. Running a Docker container using the docker run command\\nIn this case, the comman\", \"d binds the internal port 5000 of the container to port 80 of the host\\nmachine. This means that the \", \"host is listening on port 80 and forwarding to port 5000 on the\\ncontainer.\\nThe hash shown is the con\", \"tainer ID and it\\u2019s also assigned a random readable name if the --name\\noption is not used.\\nUsing Visu\", \"al Studio\\nIf you haven\\u2019t added container orchestrator support, you can also run a single container a\", \"pp in Visual\\nStudio by pressing Ctrl+F5 and you can also use F5 to debug the application within the \", \"container. The\\ncontainer runs locally using docker run.\\nOption B: Running a multi-container applicat\", \"ion\\nIn most enterprise scenarios, a Docker application will be composed of multiple services, which \", \"means\\nyou need to run a multi-container application, as shown in Figure 5-10.\\n87 CHAPTER 4 | Develop\", \"ment process for Docker-based applicationsFigure 5-10. VM with Docker containers deployed\\nUsing Dock\", \"er CLI\\nTo run a multi-container application with the Docker CLI, you use the docker-compose up comma\", \"nd.\\nThis command uses the docker-compose.yml file that you have at the solution level to deploy a\\nmu\", \"lti-container application. Figure 5-11 shows the results when running the command from your\\nmain sol\", \"ution directory, which contains the docker-compose.yml file.\\nFigure 5-11. Example results when runni\", \"ng the docker-compose up command\\nAfter the docker-compose up command runs, the application and its r\", \"elated containers are deployed\\ninto your Docker host, as depicted in Figure 5-10.\\nUsing Visual Studi\", \"o\\nRunning a multi-container application using Visual Studio 2019 can\\u2019t get any simpler. You just pre\", \"ss\\nCtrl+F5 to run or F5 to debug, as usual, setting up the docker-compose project as the startup pro\", \"ject.\\nVisual Studio handles all needed setup, so you can create breakpoints as usual and debug what \", \"finally\\nbecome independent processes running in \\u201cremote servers\\u201d, with the debugger already attached\", \", just\\nlike that.\\nAs mentioned before, each time you add Docker solution support to a project within\", \" a solution, that\\nproject is configured in the global (solution-level) docker-compose.yml file, whic\", \"h lets you run or\\ndebug the whole solution at once. Visual Studio will start one container for each \", \"project that has\\nDocker solution support enabled, and perform all the internal steps for you (dotnet\", \" publish, docker\\nbuild, etc.).\\nIf you want to take a peek at all the drudgery, take a look at the fi\", \"le:\\n{root solution folder}\\\\obj\\\\Docker\\\\docker-compose.vs.debug.g.yml\\n88 CHAPTER 4 | Development proce\", \"ss for Docker-based applicationsThe important point here is that, as shown in Figure 5-12, in Visual\", \" Studio 2019 there is an additional\\nDocker command for the F5 key action. This option lets you run o\", \"r debug a multi-container\\napplication by running all the containers that are defined in the docker-c\", \"ompose.yml files at the\\nsolution level. The ability to debug multiple-container solutions means that\", \" you can set several\\nbreakpoints, each breakpoint in a different project (container), and while debu\", \"gging from Visual\\nStudio you will stop at breakpoints defined in different projects and running on d\", \"ifferent containers.\\nFigure 5-12. Running multi-container apps in Visual Studio 2022\\nAdditional reso\", \"urces\\n\\u2022 Deploy an ASP.NET container to a remote Docker host\\nhttps://learn.microsoft.com/visualstudio\", \"/containers/hosting-web-apps-in-docker\\nA note about testing and deploying with orchestrators\\nThe doc\", \"ker-compose up and docker run commands (or running and debugging the containers in\\nVisual Studio) ar\", \"e adequate for testing containers in your development environment. But you should\\nnot use this appro\", \"ach for production deployments, where you should target orchestrators like\\nKubernetes or Service Fab\", \"ric. If you\\u2019re using Kubernetes, you have to use pods to organize containers\\nand services to network\", \" them. You also use deployments to organize pod creation and modification.\\nStep 6. Test your Docker \", \"application using your local Docker host\\nThis step will vary depending on what your application is d\", \"oing. In a simple .NET Web application that\\nis deployed as a single container or service, you can ac\", \"cess the service by opening a browser on the\\nDocker host and navigating to that site, as shown in Fi\", \"gure 5-13. (If the configuration in the Dockerfile\\nmaps the container to a port on the host that is \", \"anything other than 80, include the host port in the\\nURL.)\\nFigure 5-13. Example of testing your Dock\", \"er application locally using localhost\\n89 CHAPTER 4 | Development process for Docker-based applicati\", \"onsIf localhost is not pointing to the Docker host IP (by default, when using Docker CE, it should),\", \" to\\nnavigate to your service, use the IP address of your machine\\u2019s network card.\\nThis URL in the bro\", \"wser uses port 80 for the particular container example being discussed. However,\\ninternally the requ\", \"ests are being redirected to port 5000, because that was how it was deployed with\\nthe docker run com\", \"mand, as explained in a previous step.\\nYou can also test the application using curl from the termina\", \"l, as shown in Figure 5-14. In a Docker\\ninstallation on Windows, the default Docker Host IP is alway\", \"s 10.0.75.1 in addition to your machine\\u2019s\\nactual IP address.\\nFigure 5-14. Example of testing your Do\", \"cker application locally using curl\\nTesting and debugging containers with Visual Studio 2022\\nWhen ru\", \"nning and debugging the containers with Visual Studio 2022, you can debug the .NET\\napplication in mu\", \"ch the same way as you would when running without containers.\\nTesting and debugging without Visual S\", \"tudio\\nIf you\\u2019re developing using the editor/CLI approach, debugging containers is more difficult and\", \" you\\u2019ll\\nprobably want to debug by generating traces.\\nAdditional resources\\n\\u2022 Quickstart: Docker in Vi\", \"sual Studio.\\nhttps://learn.microsoft.com/visualstudio/containers/container-tools\\n\\u2022 Debugging apps in\", \" a local Docker container\\nhttps://learn.microsoft.com/visualstudio/containers/edit-and-refresh\\nSimpl\", \"ified workflow when developing containers with Visual Studio\\nEffectively, the workflow when using Vi\", \"sual Studio is a lot simpler than if you use the editor/CLI\\napproach. Most of the steps required by \", \"Docker related to the Dockerfile and docker-compose.yml\\nfiles are hidden or simplified by Visual Stu\", \"dio, as shown in Figure 5-15.\\n90 CHAPTER 4 | Development process for Docker-based applicationsFigure\", \" 5-15. Simplified workflow when developing with Visual Studio\\nIn addition, you need to perform step \", \"2 (adding Docker support to your projects) just once. Therefore,\\nthe workflow is similar to your usu\", \"al development tasks when using .NET for any other development.\\nYou need to know what is going on un\", \"der the covers (the image build process, what base images\\nyou\\u2019re using, deployment of containers, et\", \"c.) and sometimes you will also need to edit the Dockerfile\\nor docker-compose.yml file to customize \", \"behaviors. But most of the work is greatly simplified by using\\nVisual Studio, making you a lot more \", \"productive.\\nUsing PowerShell commands in a Dockerfile to set up Windows\\nContainers\\nWindows Container\", \"s allow you to convert your existing Windows applications into Docker images and\\ndeploy them with th\", \"e same tools as the rest of the Docker ecosystem. To use Windows Containers,\\nyou run PowerShell comm\", \"ands in the Dockerfile, as shown in the following example:\\nFROM mcr.microsoft.com/windows/servercore\", \"\\nLABEL Description=\\\"IIS\\\" Vendor=\\\"Microsoft\\\" Version=\\\"10\\\"\\nRUN powershell -Command Add-WindowsFeature \", \"Web-Server\\nCMD [ \\\"ping\\\", \\\"localhost\\\", \\\"-t\\\" ]\\nIn this case, we are using a Windows Server Core base i\", \"mage (the FROM setting) and installing IIS with\\na PowerShell command (the RUN setting). In a similar\", \" way, you could also use PowerShell commands\\nto set up additional components like ASP.NET 4.x, .NET \", \"Framework 4.6, or any other Windows\\nsoftware. For example, the following command in a Dockerfile set\", \"s up ASP.NET 4.5:\\nRUN powershell add-windowsfeature web-asp-net45\\nAdditional resources\\n\\u2022 aspnet-dock\", \"er/Dockerfile. Example PowerShell commands to run from dockerfiles to\\ninclude Windows features.\\n91 C\", \"HAPTER 4 | Development process for Docker-based applicationshttps://github.com/Microsoft/aspnet-dock\", \"er/blob/master/4.7.1-windowsservercore-\\nltsc2016/runtime/Dockerfile\\n92 CHAPTER 4 | Development proce\", \"ss for Docker-based applications5\\nCHAPTER\\nDesigning and Developing\\nMulti-Container and\\nMicroservice-\", \"Based .NET\\nApplications\\nDeveloping containerized microservice applications means you are building mu\", \"lti-container\\napplications. However, a multi-container application could also be simpler\\u2014for example\", \", a three-tier\\napplication\\u2014and might not be built using a microservice architecture.\\nEarlier we rais\", \"ed the question \\u201cIs Docker necessary when building a microservice architecture?\\u201d The\\nanswer is a cle\", \"ar no. Docker is an enabler and can provide significant benefits, but containers and\\nDocker are not \", \"a hard requirement for microservices. As an example, you could create a\\nmicroservices-based applicat\", \"ion with or without Docker when using Azure Service Fabric, which\\nsupports microservices running as \", \"simple processes or as Docker containers.\\nHowever, if you know how to design and develop a microserv\", \"ices-based application that is also based\\non Docker containers, you will be able to design and devel\", \"op any other, simpler application model.\\nFor example, you might design a three-tier application that\", \" also requires a multi-container approach.\\nBecause of that, and because microservice architectures a\", \"re an important trend within the container\\nworld, this section focuses on a microservice architectur\", \"e implementation using Docker containers.\\nDesign a microservice-oriented application\\nThis section fo\", \"cuses on developing a hypothetical server-side enterprise application.\\nApplication specifications\\nTh\", \"e hypothetical application handles requests by executing business logic, accessing databases, and\\nth\", \"en returning HTML, JSON, or XML responses. We will say that the application must support various\\ncli\", \"ents, including desktop browsers running Single Page Applications (SPAs), traditional web apps,\\nmobi\", \"le web apps, and native mobile apps. The application might also expose an API for third parties\\n93 C\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsto consu\", \"me. It should also be able to integrate its microservices or external applications\\nasynchronously, s\", \"o that approach will help resiliency of the microservices in the case of partial failures.\\nThe appli\", \"cation will consist of these types of components:\\n\\u2022 Presentation components. These components are re\", \"sponsible for handling the UI and\\nconsuming remote services.\\n\\u2022 Domain or business logic. This compon\", \"ent is the application\\u2019s domain logic.\\n\\u2022 Database access logic. This component consists of data acce\", \"ss components responsible for\\naccessing databases (SQL or NoSQL).\\n\\u2022 Application integration logic. T\", \"his component includes a messaging channel, based on\\nmessage brokers.\\nThe application will require h\", \"igh scalability, while allowing its vertical subsystems to scale out\\nautonomously, because certain s\", \"ubsystems will require more scalability than others.\\nThe application must be able to be deployed in \", \"multiple infrastructure environments (multiple public\\nclouds and on-premises) and ideally should be \", \"cross-platform, able to move from Linux to Windows\\n(or vice versa) easily.\\nDevelopment team context\\n\", \"We also assume the following about the development process for the application:\\n\\u2022 You have multiple \", \"dev teams focusing on different business areas of the application.\\n\\u2022 New team members must become pr\", \"oductive quickly, and the application must be easy to\\nunderstand and modify.\\n\\u2022 The application will \", \"have a long-term evolution and ever-changing business rules.\\n\\u2022 You need good long-term maintainabili\", \"ty, which means having agility when implementing\\nnew changes in the future while being able to updat\", \"e multiple subsystems with minimum\\nimpact on the other subsystems.\\n\\u2022 You want to practice continuous\", \" integration and continuous deployment of the application.\\n\\u2022 You want to take advantage of emerging \", \"technologies (frameworks, programming languages,\\netc.) while evolving the application. You do not wa\", \"nt to make full migrations of the\\napplication when moving to new technologies, because that would re\", \"sult in high costs and\\nimpact the predictability and stability of the application.\\nChoosing an archi\", \"tecture\\nWhat should the application deployment architecture be? The specifications for the applicati\", \"on, along\\nwith the development context, strongly suggest that you should architect the application b\", \"y\\ndecomposing it into autonomous subsystems in the form of collaborating microservices and\\ncontainer\", \"s, where a microservice is a container.\\n94 CHAPTER 5 | Designing and Developing Multi-Container and \", \"Microservice-Based .NET ApplicationsIn this approach, each service (container) implements a set of c\", \"ohesive and narrowly related functions.\\nFor example, an application might consist of services such a\", \"s the catalog service, ordering service,\\nbasket service, user profile service, etc.\\nMicroservices co\", \"mmunicate using protocols such as HTTP (REST), but also asynchronously (for\\nexample, using AMQP) whe\", \"never possible, especially when propagating updates with integration\\nevents.\\nMicroservices are devel\", \"oped and deployed as containers independently of one another. This approach\\nmeans that a development\", \" team can be developing and deploying a certain microservice without\\nimpacting other subsystems.\\nEac\", \"h microservice has its own database, allowing it to be fully decoupled from other microservices.\\nWhe\", \"n necessary, consistency between databases from different microservices is achieved using\\napplicatio\", \"n-level integration events (through a logical event bus), as handled in Command and Query\\nResponsibi\", \"lity Segregation (CQRS). Because of that, the business constraints must embrace eventual\\nconsistency\", \" between the multiple microservices and related databases.\\neShopOnContainers: A reference applicatio\", \"n for .NET and microservices deployed\\nusing containers\\nSo that you can focus on the architecture and\", \" technologies instead of thinking about a hypothetical\\nbusiness domain that you might not know, we h\", \"ave selected a well-known business domain\\u2014namely,\\na simplified e-commerce (e-shop) application that \", \"presents a catalog of products, takes orders from\\ncustomers, verifies inventory, and performs other \", \"business functions. This container-based application\\nsource code is available in the eShopOnContaine\", \"rs GitHub repo.\\nThe application consists of multiple subsystems, including several store UI front en\", \"ds (a Web\\napplication and a native mobile app), along with the back-end microservices and containers\", \" for all the\\nrequired server-side operations with several API Gateways as consolidated entry points \", \"to the internal\\nmicroservices. Figure 6-1 shows the architecture of the reference application.\\n95 CH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsFigure 6-\", \"1. The eShopOnContainers reference application architecture for development environment\\nThe above di\", \"agram shows that Mobile and SPA clients communicate to single API gateway endpoints,\\nthat then commu\", \"nicate to microservices. Traditional web clients communicate to MVC microservice,\\nthat communicates \", \"to microservices through the API gateway.\\nHosting environment. In Figure 6-1, you see several contai\", \"ners deployed within a single Docker host.\\nThat would be the case when deploying to a single Docker \", \"host with the docker-compose up\\ncommand. However, if you are using an orchestrator or container clus\", \"ter, each container could be\\nrunning in a different host (node), and any node could be running any n\", \"umber of containers, as we\\nexplained earlier in the architecture section.\\nCommunication architecture\", \". The eShopOnContainers application uses two communication types,\\ndepending on the kind of the funct\", \"ional action (queries versus updates and transactions):\\n\\u2022 Http client-to-microservice communication \", \"through API Gateways. This approach is used for\\nqueries and when accepting update or transactional c\", \"ommands from the client apps. The\\napproach using API Gateways is explained in detail in later sectio\", \"ns.\\n\\u2022 Asynchronous event-based communication. This communication occurs through an event bus\\nto prop\", \"agate updates across microservices or to integrate with external applications. The\\nevent bus can be \", \"implemented with any messaging-broker infrastructure technology like\\nRabbitMQ, or using higher-level\", \" (abstraction-level) service buses like Azure Service Bus,\\nNServiceBus, MassTransit, or Brighter.\\nTh\", \"e application is deployed as a set of microservices in the form of containers. Client apps can\\ncommu\", \"nicate with those microservices running as containers through the public URLs published by\\nthe API G\", \"ateways.\\n96 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applica\", \"tionsData sovereignty per microservice\\nIn the sample application, each microservice owns its own dat\", \"abase or data source, although all SQL\\nServer databases are deployed as a single container. This des\", \"ign decision was made only to make it\\neasy for a developer to get the code from GitHub, clone it, an\", \"d open it in Visual Studio or Visual\\nStudio Code. Or alternatively, it makes it easy to compile the \", \"custom Docker images using the .NET\\nCLI and the Docker CLI, and then deploy and run them in a Docker\", \" development environment. Either\\nway, using containers for data sources lets developers build and de\", \"ploy in a matter of minutes without\\nhaving to provision an external database or any other data sourc\", \"e with hard dependencies on\\ninfrastructure (cloud or on-premises).\\nIn a real production environment,\", \" for high availability and for scalability, the databases should be\\nbased on database servers in the\", \" cloud or on-premises, but not in containers.\\nTherefore, the units of deployment for microservices (\", \"and even for databases in this application) are\\nDocker containers, and the reference application is \", \"a multi-container application that embraces\\nmicroservices principles.\\nAdditional resources\\n\\u2022 eShopOn\", \"Containers GitHub repo. Source code for the reference application\\nhttps://aka.ms/eShopOnContainers/\\n\", \"Benefits of a microservice-based solution\\nA microservice-based solution like this has many benefits:\", \"\\nEach microservice is relatively small\\u2014easy to manage and evolve. Specifically:\\n\\u2022 It is easy for a d\", \"eveloper to understand and get started quickly with good productivity.\\n\\u2022 Containers start fast, whic\", \"h makes developers more productive.\\n\\u2022 An IDE like Visual Studio can load smaller projects fast, maki\", \"ng developers productive.\\n\\u2022 Each microservice can be designed, developed, and deployed independently\", \" of other\\nmicroservices, which provide agility because it is easier to deploy new versions of\\nmicros\", \"ervices frequently.\\nIt is possible to scale out individual areas of the application. For instance, t\", \"he catalog service or\\nthe basket service might need to be scaled out, but not the ordering process. \", \"A microservices\\ninfrastructure will be much more efficient with regard to the resources used when sc\", \"aling out than a\\nmonolithic architecture would be.\\nYou can divide the development work between multi\", \"ple teams. Each service can be owned by a\\nsingle development team. Each team can manage, develop, de\", \"ploy, and scale their service\\nindependently of the rest of the teams.\\nIssues are more isolated. If t\", \"here is an issue in one service, only that service is initially impacted\\n(except when the wrong desi\", \"gn is used, with direct dependencies between microservices), and other\\nservices can continue to hand\", \"le requests. In contrast, one malfunctioning component in a monolithic\\n97 CHAPTER 5 | Designing and \", \"Developing Multi-Container and Microservice-Based .NET Applicationsdeployment architecture can bring\", \" down the entire system, especially when it involves resources, such\\nas a memory leak. Additionally,\", \" when an issue in a microservice is resolved, you can deploy just the\\naffected microservice without \", \"impacting the rest of the application.\\nYou can use the latest technologies. Because you can start de\", \"veloping services independently and\\nrun them side by side (thanks to containers and .NET), you can s\", \"tart using the latest technologies and\\nframeworks expediently instead of being stuck on an older sta\", \"ck or framework for the whole\\napplication.\\nDownsides of a microservice-based solution\\nA microservice\", \"-based solution like this also has some drawbacks:\\nDistributed application. Distributing the applica\", \"tion adds complexity for developers when they are\\ndesigning and building the services. For example, \", \"developers must implement inter-service\\ncommunication using protocols like HTTP or AMQP, which adds \", \"complexity for testing and exception\\nhandling. It also adds latency to the system.\\nDeployment comple\", \"xity. An application that has dozens of microservices types and needs high\\nscalability (it needs to \", \"be able to create many instances per service and balance those services across\\nmany hosts) means a h\", \"igh degree of deployment complexity for IT operations and management. If\\nyou are not using a microse\", \"rvice-oriented infrastructure (like an orchestrator and scheduler), that\\nadditional complexity can r\", \"equire far more development efforts than the business application itself.\\nAtomic transactions. Atomi\", \"c transactions between multiple microservices usually are not possible.\\nThe business requirements ha\", \"ve to embrace eventual consistency between multiple microservices.\\nIncreased global resource needs (\", \"total memory, drives, and network resources for all the servers or\\nhosts). In many cases, when you r\", \"eplace a monolithic application with a microservices approach, the\\namount of initial global resource\", \"s needed by the new microservice-based application will be larger\\nthan the infrastructure needs of t\", \"he original monolithic application. This approach is because the\\nhigher degree of granularity and di\", \"stributed services requires more global resources. However, given\\nthe low cost of resources in gener\", \"al and the benefit of being able to scale out certain areas of the\\napplication compared to long-term\", \" costs when evolving monolithic applications, the increased use of\\nresources is usually a good trade\", \"off for large, long-term applications.\\nIssues with direct client-to-microservice communication. When\", \" the application is large, with\\ndozens of microservices, there are challenges and limitations if the\", \" application requires direct client-\\nto-microservice communications. One problem is a potential mism\", \"atch between the needs of the\\nclient and the APIs exposed by each of the microservices. In certain c\", \"ases, the client application might\\nneed to make many separate requests to compose the UI, which can \", \"be inefficient over the Internet\\nand would be impractical over a mobile network. Therefore, requests\", \" from the client application to the\\nback-end system should be minimized.\\nAnother problem with direct\", \" client-to-microservice communications is that some microservices might\\nbe using protocols that are \", \"not Web-friendly. One service might use a binary protocol, while another\\nservice might use AMQP mess\", \"aging. Those protocols are not firewall-friendly and are best used\\ninternally. Usually, an applicati\", \"on should use protocols such as HTTP and WebSockets for\\ncommunication outside of the firewall.\\n98 CH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsYet anoth\", \"er drawback with this direct client-to-service approach is that it makes it difficult to refactor\\nth\", \"e contracts for those microservices. Over time developers might want to change how the system is\\npar\", \"titioned into services. For example, they might merge two services or split a service into two or\\nmo\", \"re services. However, if clients communicate directly with the services, performing this kind of\\nref\", \"actoring can break compatibility with client apps.\\nAs mentioned in the architecture section, when de\", \"signing and building a complex application based\\non microservices, you might consider the use of mul\", \"tiple fine-grained API Gateways instead of the\\nsimpler direct client-to-microservice communication a\", \"pproach.\\nPartitioning the microservices. Finally, no matter, which approach you take for your micros\", \"ervice\\narchitecture, another challenge is deciding how to partition an end-to-end application into m\", \"ultiple\\nmicroservices. As noted in the architecture section of the guide, there are several techniqu\", \"es and\\napproaches you can take. Basically, you need to identify areas of the application that are de\", \"coupled\\nfrom the other areas and that have a low number of hard dependencies. In many cases, this ap\", \"proach\\nis aligned to partitioning services by use case. For example, in our e-shop application, we h\", \"ave an\\nordering service that is responsible for all the business logic related to the order process.\", \" We also\\nhave the catalog service and the basket service that implement other capabilities. Ideally,\", \" each service\\nshould have only a small set of responsibilities. This approach is similar to the sing\", \"le responsibility\\nprinciple (SRP) applied to classes, which states that a class should only have one\", \" reason to change. But\\nin this case, it is about microservices, so the scope will be larger than a s\", \"ingle class. Most of all, a\\nmicroservice has to be autonomous, end to end, including responsibility \", \"for its own data sources.\\nExternal versus internal architecture and design patterns\\nThe external arc\", \"hitecture is the microservice architecture composed by multiple services, following the\\nprinciples d\", \"escribed in the architecture section of this guide. However, depending on the nature of\\neach microse\", \"rvice, and independently of high-level microservice architecture you choose, it is\\ncommon and someti\", \"mes advisable to have different internal architectures, each based on different\\npatterns, for differ\", \"ent microservices. The microservices can even use different technologies and\\nprogramming languages. \", \"Figure 6-2 illustrates this diversity.\\n99 CHAPTER 5 | Designing and Developing Multi-Container and M\", \"icroservice-Based .NET ApplicationsFigure 6-2. External versus internal architecture and design\\nFor \", \"instance, in our eShopOnContainers sample, the catalog, basket, and user profile microservices are\\ns\", \"imple (basically, CRUD subsystems). Therefore, their internal architecture and design is\\nstraightfor\", \"ward. However, you might have other microservices, such as the ordering microservice,\\nwhich is more \", \"complex and represents ever-changing business rules with a high degree of domain\\ncomplexity. In case\", \"s like these, you might want to implement more advanced patterns within a\\nparticular microservice, l\", \"ike the ones defined with domain-driven design (DDD) approaches, as we are\\ndoing in the eShopOnConta\", \"iners ordering microservice. (We will review these DDD patterns in the\\nsection later that explains t\", \"he implementation of the eShopOnContainers ordering microservice.)\\nAnother reason for a different te\", \"chnology per microservice might be the nature of each microservice.\\nFor example, it might be better \", \"to use a functional programming language like F#, or even a language\\nlike R if you are targeting AI \", \"and machine learning domains, instead of a more object-oriented\\nprogramming language like C#.\\nThe bo\", \"ttom line is that each microservice can have a different internal architecture based on different\\nde\", \"sign patterns. Not all microservices should be implemented using advanced DDD patterns, because\\nthat\", \" would be over-engineering them. Similarly, complex microservices with ever-changing business\\nlogic \", \"should not be implemented as CRUD components, or you can end up with low-quality code.\\nThe new world\", \": multiple architectural patterns and polyglot\\nmicroservices\\nThere are many architectural patterns u\", \"sed by software architects and developers. The following are a\\nfew (mixing architecture styles and a\", \"rchitecture patterns):\\n\\u2022 Simple CRUD, single-tier, single-layer.\\n100 CHAPTER 5 | Designing and Devel\", \"oping Multi-Container and Microservice-Based .NET Applications\\u2022 Traditional N-Layered.\\n\\u2022 Domain-Driv\", \"en Design N-layered.\\n\\u2022 Clean Architecture (as used with eShopOnWeb)\\n\\u2022 Command and Query Responsibili\", \"ty Segregation (CQRS).\\n\\u2022 Event-Driven Architecture (EDA).\\nYou can also build microservices with many\", \" technologies and languages, such as ASP.NET Core Web\\nAPIs, NancyFx, ASP.NET Core SignalR (available\", \" with .NET Core 2 or later), F#, Node.js, Python, Java,\\nC++, GoLang, and more.\\nThe important point i\", \"s that no particular architecture pattern or style, nor any particular technology, is\\nright for all \", \"situations. Figure 6-3 shows some approaches and technologies (although not in any\\nparticular order)\", \" that could be used in different microservices.\\nFigure 6-3. Multi-architectural patterns and the pol\", \"yglot microservices world\\nMulti-architectural pattern and polyglot microservices means you can mix a\", \"nd match languages and\\ntechnologies to the needs of each microservice and still have them talking to\", \" each other. As shown in\\nFigure 6-3, in applications composed of many microservices (Bounded Context\", \"s in domain-driven\\ndesign terminology, or simply \\u201csubsystems\\u201d as autonomous microservices), you migh\", \"t implement\\neach microservice in a different way. Each might have a different architecture pattern a\", \"nd use different\\nlanguages and databases depending on the application\\u2019s nature, business requirement\", \"s, and\\npriorities. In some cases, the microservices might be similar. But that is not usually the ca\", \"se, because\\neach subsystem\\u2019s context boundary and requirements are usually different.\\n101 CHAPTER 5 \", \"| Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsFor instance, for\", \" a simple CRUD maintenance application, it might not make sense to design and\\nimplement DDD patterns\", \". But for your core domain or core business, you might need to apply more\\nadvanced patterns to tackl\", \"e business complexity with ever-changing business rules.\\nEspecially when you deal with large applica\", \"tions composed by multiple subsystems, you should not\\napply a single top-level architecture based on\", \" a single architecture pattern. For instance, CQRS should\\nnot be applied as a top-level architecture\", \" for a whole application, but might be useful for a specific set\\nof services.\\nThere is no silver bul\", \"let or a right architecture pattern for every given case. You cannot have \\u201cone\\narchitecture pattern \", \"to rule them all.\\u201d Depending on the priorities of each microservice, you must\\nchoose a different app\", \"roach for each, as explained in the following sections.\\nCreating a simple data-driven CRUD microserv\", \"ice\\nThis section outlines how to create a simple microservice that performs create, read, update, an\", \"d\\ndelete (CRUD) operations on a data source.\\nDesigning a simple CRUD microservice\\nFrom a design poin\", \"t of view, this type of containerized microservice is very simple. Perhaps the\\nproblem to solve is s\", \"imple, or perhaps the implementation is only a proof of concept.\\nFigure 6-4. Internal design for sim\", \"ple CRUD microservices\\nAn example of this kind of simple data-drive service is the catalog microserv\", \"ice from the\\neShopOnContainers sample application. This type of service implements all its functiona\", \"lity in a single\\nASP.NET Core Web API project that includes classes for its data model, its business\", \" logic, and its data\\naccess code. It also stores its related data in a database running in SQL Serve\", \"r (as another container\\nfor dev/test purposes), but could also be any regular SQL Server host, as sh\", \"own in Figure 6-5.\\n102 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET ApplicationsFigure 6-5. Simple data-driven/CRUD microservice design\\nThe previous diagram shows t\", \"he logical Catalog microservice, that includes its Catalog database,\\nwhich can be or not in the same\", \" Docker host. Having the database in the same Docker host might be\\ngood for development, but not for\", \" production. When you are developing this kind of service, you only\\nneed ASP.NET Core and a data-acc\", \"ess API or ORM like Entity Framework Core. You could also\\ngenerate Swagger metadata automatically th\", \"rough Swashbuckle to provide a description of what your\\nservice offers, as explained in the next sec\", \"tion.\\nNote that running a database server like SQL Server within a Docker container is great for\\ndev\", \"elopment environments, because you can have all your dependencies up and running without\\nneeding to \", \"provision a database in the cloud or on-premises. This approach is convenient when\\nrunning integrati\", \"on tests. However, for production environments, running a database server in a\\ncontainer is not reco\", \"mmended, because you usually do not get high availability with that approach.\\nFor a production envir\", \"onment in Azure, it is recommended that you use Azure SQL DB or any other\\ndatabase technology that c\", \"an provide high availability and high scalability. For example, for a NoSQL\\napproach, you might choo\", \"se CosmosDB.\\nFinally, by editing the Dockerfile and docker-compose.yml metadata files, you can confi\", \"gure how the\\nimage of this container will be created\\u2014what base image it will use, plus design settin\", \"gs such as\\ninternal and external names and TCP ports.\\nImplementing a simple CRUD microservice with A\", \"SP.NET Core\\nTo implement a simple CRUD microservice using .NET and Visual Studio, you start by creat\", \"ing a\\nsimple ASP.NET Core Web API project (running on .NET so it can run on a Linux Docker host), as\", \"\\nshown in Figure 6-6.\\n103 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Base\", \"d .NET ApplicationsFigure 6-6. Creating an ASP.NET Core Web API project in Visual Studio 2019\\nTo cre\", \"ate an ASP.NET Core Web API Project, first select an ASP.NET Core Web Application and then\\nselect th\", \"e API type. After creating the project, you can implement your MVC controllers as you would\\nin any o\", \"ther Web API project, using the Entity Framework API or other API. In a new Web API project,\\nyou can\", \" see that the only dependency you have in that microservice is on ASP.NET Core itself.\\nInternally, w\", \"ithin the Microsoft.AspNetCore.All dependency, it is referencing Entity Framework and\\nmany other .NE\", \"T NuGet packages, as shown in Figure 6-7.\\n104 CHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET ApplicationsFigure 6-7. Dependencies in a simple CRUD Web API microservic\", \"e\\nThe API project includes references to Microsoft.AspNetCore.App NuGet package, that includes\\nrefer\", \"ences to all essential packages. It could include some other packages as well.\\nImplementing CRUD Web\", \" API services with Entity Framework Core\\nEntity Framework (EF) Core is a lightweight, extensible, an\", \"d cross-platform version of the popular\\nEntity Framework data access technology. EF Core is an objec\", \"t-relational mapper (ORM) that enables\\n.NET developers to work with a database using .NET objects.\\nT\", \"he catalog microservice uses EF and the SQL Server provider because its database is running in a\\ncon\", \"tainer with the SQL Server for Linux Docker image. However, the database could be deployed into\\n105 \", \"CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsany SQL\", \" Server, such as Windows on-premises or Azure SQL DB. The only thing you would need to\\nchange is the\", \" connection string in the ASP.NET Web API microservice.\\nThe data model\\nWith EF Core, data access is \", \"performed by using a model. A model is made up of (domain model)\\nentity classes and a derived contex\", \"t (DbContext) that represents a session with the database, allowing\\nyou to query and save data. You \", \"can generate a model from an existing database, manually code a\\nmodel to match your database, or use\", \" EF migrations technique to create a database from your model,\\nusing the code-first approach (that m\", \"akes it easy to evolve the database as your model changes over\\ntime). For the catalog microservice, \", \"the last approach has been used. You can see an example of the\\nCatalogItem entity class in the follo\", \"wing code example, which is a simple Plain Old Class Object\\n(POCO) entity class.\\npublic class Catalo\", \"gItem\\n{\\npublic int Id { get; set; }\\npublic string Name { get; set; }\\npublic string Description { get\", \"; set; }\\npublic decimal Price { get; set; }\\npublic string PictureFileName { get; set; }\\npublic strin\", \"g PictureUri { get; set; }\\npublic int CatalogTypeId { get; set; }\\npublic CatalogType CatalogType { g\", \"et; set; }\\npublic int CatalogBrandId { get; set; }\\npublic CatalogBrand CatalogBrand { get; set; }\\npu\", \"blic int AvailableStock { get; set; }\\npublic int RestockThreshold { get; set; }\\npublic int MaxStockT\", \"hreshold { get; set; }\\npublic bool OnReorder { get; set; }\\npublic CatalogItem() { }\\n// Additional co\", \"de ...\\n}\\nYou also need a DbContext that represents a session with the database. For the catalog micr\", \"oservice,\\nthe CatalogContext class derives from the DbContext base class, as shown in the following \", \"example:\\npublic class CatalogContext : DbContext\\n{\\npublic CatalogContext(DbContextOptions<CatalogCon\", \"text> options) : base(options)\\n{ }\\npublic DbSet<CatalogItem> CatalogItems { get; set; }\\npublic DbSet\", \"<CatalogBrand> CatalogBrands { get; set; }\\npublic DbSet<CatalogType> CatalogTypes { get; set; }\\n// A\", \"dditional code ...\\n}\\nYou can have additional DbContext implementations. For example, in the sample C\", \"atalog.API\\nmicroservice, there\\u2019s a second DbContext named CatalogContextSeed where it automatically\\n\", \"populates the sample data the first time it tries to access the database. This method is useful for \", \"demo\\ndata and for automated testing scenarios, as well.\\n106 CHAPTER 5 | Designing and Developing Mul\", \"ti-Container and Microservice-Based .NET ApplicationsWithin the DbContext, you use the OnModelCreati\", \"ng method to customize object/database entity\\nmappings and other EF extensibility points.\\nQuerying d\", \"ata from Web API controllers\\nInstances of your entity classes are typically retrieved from the datab\", \"ase using Language-Integrated\\nQuery (LINQ), as shown in the following example:\\n[Route(\\\"api/v1/[contr\", \"oller]\\\")]\\npublic class CatalogController : ControllerBase\\n{\\nprivate readonly CatalogContext _catalog\", \"Context;\\nprivate readonly CatalogSettings _settings;\\nprivate readonly ICatalogIntegrationEventServic\", \"e _catalogIntegrationEventService;\\npublic CatalogController(\\nCatalogContext context,\\nIOptionsSnapsho\", \"t<CatalogSettings> settings,\\nICatalogIntegrationEventService catalogIntegrationEventService)\\n{\\n_cata\", \"logContext = context ?? throw new ArgumentNullException(nameof(context));\\n_catalogIntegrationEventSe\", \"rvice = catalogIntegrationEventService\\n?? throw new ArgumentNullException(nameof(catalogIntegrationE\", \"ventService));\\n_settings = settings.Value;\\ncontext.ChangeTracker.QueryTrackingBehavior = QueryTracki\", \"ngBehavior.NoTracking;\\n}\\n// GET api/v1/[controller]/items[?pageSize=3&pageIndex=10]\\n[HttpGet]\\n[Route\", \"(\\\"items\\\")]\\n[ProducesResponseType(typeof(PaginatedItemsViewModel<CatalogItem>),\\n(int)HttpStatusCode.O\", \"K)]\\n[ProducesResponseType(typeof(IEnumerable<CatalogItem>), (int)HttpStatusCode.OK)]\\n[ProducesRespon\", \"seType((int)HttpStatusCode.BadRequest)]\\npublic async Task<IActionResult> ItemsAsync(\\n[FromQuery]int \", \"pageSize = 10,\\n[FromQuery]int pageIndex = 0,\\nstring ids = null)\\n{\\nif (!string.IsNullOrEmpty(ids))\\n{\\n\", \"var items = await GetItemsByIdsAsync(ids);\\nif (!items.Any())\\n{\\nreturn BadRequest(\\\"ids value invalid.\", \" Must be comma-separated list of\\nnumbers\\\");\\n}\\nreturn Ok(items);\\n}\\nvar totalItems = await _catalogCon\", \"text.CatalogItems\\n.LongCountAsync();\\nvar itemsOnPage = await _catalogContext.CatalogItems\\n.OrderBy(c\", \" => c.Name)\\n.Skip(pageSize * pageIndex)\\n107 CHAPTER 5 | Designing and Developing Multi-Container and\", \" Microservice-Based .NET Applications.Take(pageSize)\\n.ToListAsync();\\nitemsOnPage = ChangeUriPlacehol\", \"der(itemsOnPage);\\nvar model = new PaginatedItemsViewModel<CatalogItem>(\\npageIndex, pageSize, totalIt\", \"ems, itemsOnPage);\\nreturn Ok(model);\\n}\\n//...\\n}\\nSaving data\\nData is created, deleted, and modified in\", \" the database using instances of your entity classes. You\\ncould add code like the following hard-cod\", \"ed example (mock data, in this case) to your Web API\\ncontrollers.\\nvar catalogItem = new CatalogItem(\", \") {CatalogTypeId=2, CatalogBrandId=2,\\nName=\\\"Roslyn T-Shirt\\\", Price = 12};\\n_context.Catalog.Add(catal\", \"ogItem);\\n_context.SaveChanges();\\nDependency Injection in ASP.NET Core and Web API controllers\\nIn ASP\", \".NET Core, you can use Dependency Injection (DI) out of the box. You do not need to set up a\\nthird-p\", \"arty Inversion of Control (IoC) container, although you can plug your preferred IoC container\\ninto t\", \"he ASP.NET Core infrastructure if you want. In this case, it means that you can directly inject the\\n\", \"required EF DBContext or additional repositories through the controller constructor.\\nIn the CatalogC\", \"ontroller class mentioned earlier, CatalogContext (which inherits from DbContext) type\\nis injected a\", \"long with the other required objects in the CatalogController() constructor.\\nAn important configurat\", \"ion to set up in the Web API project is the DbContext class registration into\\nthe service\\u2019s IoC cont\", \"ainer. You typically do so in the Program.cs file by calling the\\nbuilder.Services.AddDbContext<Catal\", \"ogContext>() method, as shown in the following simplified\\nexample:\\n// Additional code...\\nbuilder.Ser\", \"vices.AddDbContext<CatalogContext>(options =>\\n{\\noptions.UseSqlServer(builder.Configuration[\\\"Connecti\", \"onString\\\"],\\nsqlServerOptionsAction: sqlOptions =>\\n{\\nsqlOptions.MigrationsAssembly(\\ntypeof(Program).G\", \"etTypeInfo().Assembly.GetName().Name);\\n//Configuring Connection Resiliency:\\nsqlOptions.\\nEnableRetryO\", \"nFailure(maxRetryCount: 5,\\nmaxRetryDelay: TimeSpan.FromSeconds(30),\\nerrorNumbersToAdd: null);\\n});\\n10\", \"8 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications// Ch\", \"anging default behavior when client evaluation occurs to throw.\\n// Default in EFCore would be to log\", \" warning when client evaluation is done.\\noptions.ConfigureWarnings(warnings => warnings.Throw(\\nRelat\", \"ionalEventId.QueryClientEvaluationWarning));\\n});\\nAdditional resources\\n\\u2022 Querying Data\\nhttps://learn.\", \"microsoft.com/ef/core/querying/index\\n\\u2022 Saving Data\\nhttps://learn.microsoft.com/ef/core/saving/index\\n\", \"The DB connection string and environment variables used by Docker\\ncontainers\\nYou can use the ASP.NET\", \" Core settings and add a ConnectionString property to your settings.json file\\nas shown in the follow\", \"ing example:\\n{\\n\\\"ConnectionString\\\": \\\"Server=tcp:127.0.0.1,5433;Initial\\nCatalog=Microsoft.eShopOnConta\", \"iners.Services.CatalogDb;User Id=sa;Password=[PLACEHOLDER]\\\",\\n\\\"ExternalCatalogBaseUrl\\\": \\\"http://host.\", \"docker.internal:5101\\\",\\n\\\"Logging\\\": {\\n\\\"IncludeScopes\\\": false,\\n\\\"LogLevel\\\": {\\n\\\"Default\\\": \\\"Debug\\\",\\n\\\"Syste\", \"m\\\": \\\"Information\\\",\\n\\\"Microsoft\\\": \\\"Information\\\"\\n}\\n}\\n}\\nThe settings.json file can have default values f\", \"or the ConnectionString property or for any other\\nproperty. However, those properties will be overri\", \"dden by the values of environment variables that\\nyou specify in the docker-compose.override.yml file\", \", when using Docker.\\nFrom your docker-compose.yml or docker-compose.override.yml files, you can init\", \"ialize those\\nenvironment variables so that Docker will set them up as OS environment variables for y\", \"ou, as shown\\nin the following docker-compose.override.yml file (the connection string and other line\", \"s wrap in this\\nexample, but it would not wrap in your own file).\\n# docker-compose.override.yml\\n#\\ncat\", \"alog-api:\\nenvironment:\\n-\\nConnectionString=Server=sqldata;Database=Microsoft.eShopOnContainers.Servic\", \"es.CatalogDb;Use\\nr Id=sa;Password=[PLACEHOLDER]\\n# Additional environment variables for this service\\n\", \"ports:\\n- \\\"5101:80\\\"\\n109 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET ApplicationsThe docker-compose.yml files at the solution level are not only more flexible than c\", \"onfiguration files\\nat the project or microservice level, but also more secure if you override the en\", \"vironment variables\\ndeclared at the docker-compose files with values set from your deployment tools,\", \" like from Azure\\nDevOps Services Docker deployment tasks.\\nFinally, you can get that value from your \", \"code by using builder.Configuration\\\\[\\\"ConnectionString\\\"\\\\], as\\nshown in an earlier code example.\\nHowe\", \"ver, for production environments, you might want to explore additional ways on how to store\\nsecrets \", \"like the connection strings. An excellent way to manage application secrets is using Azure Key\\nVault\", \".\\nAzure Key Vault helps to store and safeguard cryptographic keys and secrets used by your cloud\\napp\", \"lications and services. A secret is anything you want to keep strict control of, like API keys,\\nconn\", \"ection strings, passwords, etc. and strict control includes usage logging, setting expiration,\\nmanag\", \"ing access, among others.\\nAzure Key Vault allows a detailed control level of the application secrets\", \" usage without the need to let\\nanyone know them. The secrets can even be rotated for enhanced securi\", \"ty without disrupting\\ndevelopment or operations.\\nApplications have to be registered in the organizat\", \"ion\\u2019s Active Directory, so they can use the Key\\nVault.\\nYou can check the Key Vault Concepts document\", \"ation for more details.\\nImplementing versioning in ASP.NET Web APIs\\nAs business requirements change,\", \" new collections of resources may be added, the relationships\\nbetween resources might change, and th\", \"e structure of the data in resources might be amended.\\nUpdating a Web API to handle new requirements\", \" is a relatively straightforward process, but you must\\nconsider the effects that such changes will h\", \"ave on client applications consuming the Web API.\\nAlthough the developer designing and implementing \", \"a Web API has full control over that API, the\\ndeveloper does not have the same degree of control ove\", \"r client applications that might be built by\\nthird-party organizations operating remotely.\\nVersionin\", \"g enables a Web API to indicate the features and resources that it exposes. A client\\napplication can\", \" then submit requests to a specific version of a feature or resource. There are several\\napproaches t\", \"o implement versioning:\\n\\u2022 URI versioning\\n\\u2022 Query string versioning\\n\\u2022 Header versioning\\nQuery string \", \"and URI versioning are the simplest to implement. Header versioning is a good\\napproach. However, hea\", \"der versioning is not as explicit and straightforward as URI versioning.\\nBecause URL versioning is t\", \"he simplest and most explicit, the eShopOnContainers sample application\\nuses URI versioning.\\n110 CHA\", \"PTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsWith URI v\", \"ersioning, as in the eShopOnContainers sample application, each time you modify the Web\\nAPI or chang\", \"e the schema of resources, you add a version number to the URI for each resource.\\nExisting URIs shou\", \"ld continue to operate as before, returning resources that conform to the schema\\nthat matches the re\", \"quested version.\\nAs shown in the following code example, the version can be set by using the Route a\", \"ttribute in the\\nWeb API controller, which makes the version explicit in the URI (v1 in this case).\\n[\", \"Route(\\\"api/v1/[controller]\\\")]\\npublic class CatalogController : ControllerBase\\n{\\n// Implementation ..\", \".\\nThis versioning mechanism is simple and depends on the server routing the request to the\\nappropria\", \"te endpoint. However, for a more sophisticated versioning and the best method when using\\nREST, you s\", \"hould use hypermedia and implement HATEOAS (Hypertext as the Engine of Application\\nState).\\nAdditiona\", \"l resources\\n\\u2022 ASP.NET API Versioning https://github.com/dotnet/aspnet-api-versioning\\n\\u2022 Scott Hanselm\", \"an. ASP.NET Core RESTful Web API versioning made easy\\nhttps://www.hanselman.com/blog/ASPNETCoreRESTf\", \"ulWebAPIVersioningMadeEasy.aspx\\n\\u2022 Versioning a RESTful web API\\nhttps://learn.microsoft.com/azure/arc\", \"hitecture/best-practices/api-design#versioning-a-\\nrestful-web-api\\n\\u2022 Roy Fielding. Versioning, Hyperm\", \"edia, and REST\\nhttps://www.infoq.com/articles/roy-fielding-on-versioning\\nGenerating Swagger descript\", \"ion metadata from your ASP.NET Core\\nWeb API\\nSwagger is a commonly used open source framework backed \", \"by a large ecosystem of tools that helps\\nyou design, build, document, and consume your RESTful APIs.\", \" It is becoming the standard for the APIs\\ndescription metadata domain. You should include Swagger de\", \"scription metadata with any kind of\\nmicroservice, either data-driven microservices or more advanced \", \"domain-driven microservices (as\\nexplained in the following section).\\nThe heart of Swagger is the Swa\", \"gger specification, which is API description metadata in a JSON or\\nYAML file. The specification crea\", \"tes the RESTful contract for your API, detailing all its resources and\\noperations in both a human- a\", \"nd machine-readable format for easy development, discovery, and\\nintegration.\\nThe specification is th\", \"e basis of the OpenAPI Specification (OAS) and is developed in an open,\\ntransparent, and collaborati\", \"ve community to standardize the way RESTful interfaces are defined.\\n111 CHAPTER 5 | Designing and De\", \"veloping Multi-Container and Microservice-Based .NET ApplicationsThe specification defines the struc\", \"ture for how a service can be discovered and how its capabilities\\nunderstood. For more information, \", \"including a web editor and examples of Swagger specifications\\nfrom companies like Spotify, Uber, Sla\", \"ck, and Microsoft, see the Swagger site (https://swagger.io).\\nWhy use Swagger?\\nThe main reasons to g\", \"enerate Swagger metadata for your APIs are the following.\\nAbility for other products to automaticall\", \"y consume and integrate your APIs. Dozens of products\\nand commercial tools and many libraries and fr\", \"ameworks support Swagger. Microsoft has high-level\\nproducts and tools that can automatically consume\", \" Swagger-based APIs, such as the following:\\n\\u2022 AutoRest. You can automatically generate .NET client c\", \"lasses for calling Swagger. This tool can\\nbe used from the CLI and it also integrates with Visual St\", \"udio for easy use through the GUI.\\n\\u2022 Microsoft Flow. You can automatically use and integrate your AP\", \"I into a high-level Microsoft\\nFlow workflow, with no programming skills required.\\n\\u2022 Microsoft PowerA\", \"pps. You can automatically consume your API from PowerApps mobile apps\\nbuilt with PowerApps Studio, \", \"with no programming skills required.\\n\\u2022 Azure App Service Logic Apps. You can automatically use and i\", \"ntegrate your API into an Azure\\nApp Service Logic App, with no programming skills required.\\nAbility \", \"to automatically generate API documentation. When you create large-scale RESTful APIs,\\nsuch as compl\", \"ex microservice-based applications, you need to handle many endpoints with different\\ndata models use\", \"d in the request and response payloads. Having proper documentation and having a\\nsolid API explorer,\", \" as you get with Swagger, is key for the success of your API and adoption by\\ndevelopers.\\nSwagger\\u2019s m\", \"etadata is what Microsoft Flow, PowerApps, and Azure Logic Apps use to understand how\\nto use APIs an\", \"d connect to them.\\nThere are several options to automate Swagger metadata generation for ASP.NET Cor\", \"e REST API\\napplications, in the form of functional API help pages, based on swagger-ui.\\nProbably the\", \" best know is Swashbuckle, which is currently used in eShopOnContainers and we\\u2019ll cover\\nin some deta\", \"il in this guide but there\\u2019s also the option to use NSwag, which can generate Typescript\\nand C# API \", \"clients, as well as C# controllers, from a Swagger or OpenAPI specification and even by\\nscanning the\", \" .dll that contains the controllers, using NSwagStudio.\\nHow to automate API Swagger metadata generat\", \"ion with the Swashbuckle NuGet\\npackage\\nGenerating Swagger metadata manually (in a JSON or YAML file)\", \" can be tedious work. However, you\\ncan automate API discovery of ASP.NET Web API services by using t\", \"he Swashbuckle NuGet package to\\ndynamically generate Swagger API metadata.\\nSwashbuckle automatically\", \" generates Swagger metadata for your ASP.NET Web API projects. It\\nsupports ASP.NET Core Web API proj\", \"ects and the traditional ASP.NET Web API and any other flavor,\\n112 CHAPTER 5 | Designing and Develop\", \"ing Multi-Container and Microservice-Based .NET Applicationssuch as Azure API App, Azure Mobile App,\", \" Azure Service Fabric microservices based on ASP.NET. It\\nalso supports plain Web API deployed on con\", \"tainers, as in for the reference application.\\nSwashbuckle combines API Explorer and Swagger or swagg\", \"er-ui to provide a rich discovery and\\ndocumentation experience for your API consumers. In addition t\", \"o its Swagger metadata generator\\nengine, Swashbuckle also contains an embedded version of swagger-ui\", \", which it will automatically\\nserve up once Swashbuckle is installed.\\nThis means you can complement \", \"your API with a nice discovery UI to help developers to use your API.\\nIt requires a small amount of \", \"code and maintenance because it is automatically generated, allowing\\nyou to focus on building your A\", \"PI. The result for the API Explorer looks like Figure 6-8.\\nFigure 6-8. Swashbuckle API Explorer base\", \"d on Swagger metadata\\u2014eShopOnContainers catalog microservice\\nThe Swashbuckle generated Swagger UI AP\", \"I documentation includes all published actions. The API\\nexplorer is not the most important thing her\", \"e. Once you have a Web API that can describe itself in\\nSwagger metadata, your API can be used seamle\", \"ssly from Swagger-based tools, including client\\nproxy-class code generators that can target many pla\", \"tforms. For example, as mentioned, AutoRest\\nautomatically generates .NET client classes. But additio\", \"nal tools like swagger-codegen are also\\navailable, which allow code generation of API client librari\", \"es, server stubs, and documentation\\nautomatically.\\nCurrently, Swashbuckle consists of five internal \", \"NuGet packages under the high-level metapackage\\nSwashbuckle.AspNetCore for ASP.NET Core applications\", \".\\nAfter you have installed these NuGet packages in your Web API project, you need to configure\\nSwagg\", \"er in the Program.cs class, as in the following simplified code:\\n// Add framework services.\\nbuilder.\", \"Services.AddSwaggerGen(options =>\\n{\\n113 CHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applicationsoptions.DescribeAllEnumsAsStrings();\\noptions.SwaggerDoc(\\\"v1\\\", new O\", \"penApiInfo\\n{\\nTitle = \\\"eShopOnContainers - Catalog HTTP API\\\",\\nVersion = \\\"v1\\\",\\nDescription = \\\"The Cata\", \"log Microservice HTTP API. This is a Data-Driven/CRUD\\nmicroservice sample\\\"\\n});\\n});\\n// Other startup \", \"code...\\napp.UseSwagger()\\n.UseSwaggerUI(c =>\\n{\\nc.SwaggerEndpoint(\\\"/swagger/v1/swagger.json\\\", \\\"My API \", \"V1\\\");\\n});\\n```\\n:::\\nOnce this is done, you can start your application and browse the following Swagger\", \" JSON and\\nUI endpoints using URLs like these:\\n:::{custom-style=CodeBox}\\n```console\\nhttp://<your-root\", \"-url>/swagger/v1/swagger.json\\nhttp://<your-root-url>/swagger/\\nYou previously saw the generated UI cr\", \"eated by Swashbuckle for a URL like http://<your-root-\\nurl>/swagger. In Figure 6-9, you can also see\", \" how you can test any API method.\\n114 CHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET ApplicationsFigure 6-9. Swashbuckle UI testing the Catalog/Items API method\\nThe S\", \"wagger UI API detail shows a sample of the response and can be used to execute the real API,\\nwhich i\", \"s great for developer discovery. Figure 6-10 shows the Swagger JSON metadata generated\\nfrom the eSho\", \"pOnContainers microservice (which is what the tools use underneath) when you request\\nhttp://<your-ro\", \"ot-url>/swagger/v1/swagger.json using Postman.\\n115 CHAPTER 5 | Designing and Developing Multi-Contai\", \"ner and Microservice-Based .NET ApplicationsFigure 6-10. Swagger JSON metadata\\nIt is that simple. An\", \"d because it is automatically generated, the Swagger metadata will grow when you\\nadd more functional\", \"ity to your API.\\nAdditional resources\\n\\u2022 ASP.NET Web API Help Pages using Swagger\\nhttps://learn.micro\", \"soft.com/aspnet/core/tutorials/web-api-help-pages-using-swagger\\n\\u2022 Get started with Swashbuckle and A\", \"SP.NET Core\\nhttps://learn.microsoft.com/aspnet/core/tutorials/getting-started-with-swashbuckle\\n\\u2022 Get\", \" started with NSwag and ASP.NET Core\\nhttps://learn.microsoft.com/aspnet/core/tutorials/getting-start\", \"ed-with-nswag\\nDefining your multi-container application with\\ndocker-compose.yml\\nIn this guide, the d\", \"ocker-compose.yml file was introduced in the section Step 4. Define your services\\nin docker-compose.\", \"yml when building a multi-container Docker application. However, there are\\nadditional ways to use th\", \"e docker-compose files that are worth exploring in further detail.\\nFor example, you can explicitly d\", \"escribe how you want to deploy your multi-container application in\\nthe docker-compose.yml file. Opti\", \"onally, you can also describe how you are going to build your\\ncustom Docker images. (Custom Docker i\", \"mages can also be built with the Docker CLI.)\\n116 CHAPTER 5 | Designing and Developing Multi-Contain\", \"er and Microservice-Based .NET ApplicationsBasically, you define each of the containers you want to \", \"deploy plus certain characteristics for each\\ncontainer deployment. Once you have a multi-container d\", \"eployment description file, you can deploy\\nthe whole solution in a single action orchestrated by the\", \" docker-compose up CLI command, or you\\ncan deploy it transparently from Visual Studio. Otherwise, yo\", \"u would need to use the Docker CLI to\\ndeploy container-by-container in multiple steps by using the d\", \"ocker run command from the\\ncommand line. Therefore, each service defined in docker-compose.yml must \", \"specify exactly one\\nimage or build. Other keys are optional, and are analogous to their docker run c\", \"ommand-line\\ncounterparts.\\nThe following YAML code is the definition of a possible global but single \", \"docker-compose.yml file for\\nthe eShopOnContainers sample. This code is not the actual docker-compose\", \" file from\\neShopOnContainers. Instead, it is a simplified and consolidated version in a single file,\", \" which is not the\\nbest way to work with docker-compose files, as will be explained later.\\nversion: '\", \"3.4'\\nservices:\\nwebmvc:\\nimage: eshop/webmvc\\nenvironment:\\n- CatalogUrl=http://catalog-api\\n- OrderingUr\", \"l=http://ordering-api\\n- BasketUrl=http://basket-api\\nports:\\n- \\\"5100:80\\\"\\ndepends_on:\\n- catalog-api\\n- o\", \"rdering-api\\n- basket-api\\ncatalog-api:\\nimage: eshop/catalog-api\\nenvironment:\\n- ConnectionString=Serve\", \"r=sqldata;Initial Catalog=CatalogData;User\\nId=sa;Password=[PLACEHOLDER]\\nexpose:\\n- \\\"80\\\"\\nports:\\n- \\\"510\", \"1:80\\\"\\n#extra hosts can be used for standalone SQL Server or services at the dev PC\\nextra_hosts:\\n- \\\"C\", \"ESARDLSURFBOOK:10.0.75.1\\\"\\ndepends_on:\\n- sqldata\\nordering-api:\\nimage: eshop/ordering-api\\nenvironment:\", \"\\n- ConnectionString=Server=sqldata;Database=Services.OrderingDb;User\\nId=sa;Password=[PLACEHOLDER]\\npo\", \"rts:\\n- \\\"5102:80\\\"\\n#extra hosts can be used for standalone SQL Server or services at the dev PC\\nextra_\", \"hosts:\\n- \\\"CESARDLSURFBOOK:10.0.75.1\\\"\\ndepends_on:\\n- sqldata\\n117 CHAPTER 5 | Designing and Developing \", \"Multi-Container and Microservice-Based .NET Applicationsbasket-api:\\nimage: eshop/basket-api\\nenvironm\", \"ent:\\n- ConnectionString=sqldata\\nports:\\n- \\\"5103:80\\\"\\ndepends_on:\\n- sqldata\\nsqldata:\\nenvironment:\\n- SA_\", \"PASSWORD=[PLACEHOLDER]\\n- ACCEPT_EULA=Y\\nports:\\n- \\\"5434:1433\\\"\\nbasketdata:\\nimage: redis\\nThe root key in\", \" this file is services. Under that key, you define the services you want to deploy and run\\nwhen you \", \"execute the docker-compose up command or when you deploy from Visual Studio by using\\nthis docker-com\", \"pose.yml file. In this case, the docker-compose.yml file has multiple services defined,\\nas described\", \" in the following table.\\nService name Description\\nwebmvc Container including the ASP.NET Core MVC\\nap\", \"plication consuming the microservices from\\nserver-side C#\\ncatalog-api Container including the Catalo\", \"g ASP.NET Core\\nWeb API microservice\\nordering-api Container including the Ordering ASP.NET\\nCore Web A\", \"PI microservice\\nsqldata Container running SQL Server for Linux,\\nholding the microservices databases\\n\", \"basket-api Container with the Basket ASP.NET Core Web\\nAPI microservice\\nbasketdata Container running \", \"the REDIS cache service,\\nwith the basket database as a REDIS cache\\nA simple Web Service API containe\", \"r\\nFocusing on a single container, the catalog-api container-microservice has a straightforward\\ndefin\", \"ition:\\ncatalog-api:\\nimage: eshop/catalog-api\\nenvironment:\\n- ConnectionString=Server=sqldata;Initial \", \"Catalog=CatalogData;User\\nId=sa;Password=[PLACEHOLDER]\\nexpose:\\n118 CHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET Applications- \\\"80\\\"\\nports:\\n- \\\"5101:80\\\"\\n#extra hosts ca\", \"n be used for standalone SQL Server or services at the dev PC\\nextra_hosts:\\n- \\\"CESARDLSURFBOOK:10.0.7\", \"5.1\\\"\\ndepends_on:\\n- sqldata\\nThis containerized service has the following basic configuration:\\n\\u2022 It is\", \" based on the custom eshop/catalog-api image. For simplicity\\u2019s sake, there is no\\nbuild: key setting \", \"in the file. This means that the image must have been previously built (with\\ndocker build) or have b\", \"een downloaded (with the docker pull command) from any Docker\\nregistry.\\n\\u2022 It defines an environment \", \"variable named ConnectionString with the connection string to be\\nused by Entity Framework to access \", \"the SQL Server instance that contains the catalog data\\nmodel. In this case, the same SQL Server cont\", \"ainer is holding multiple databases. Therefore,\\nyou need less memory in your development machine for\", \" Docker. However, you could also\\ndeploy one SQL Server container for each microservice database.\\n\\u2022 T\", \"he SQL Server name is sqldata, which is the same name used for the container that is\\nrunning the SQL\", \" Server instance for Linux. This is convenient; being able to use this name\\nresolution (internal to \", \"the Docker host) will resolve the network address so you don\\u2019t need to\\nknow the internal IP for the \", \"containers you are accessing from other containers.\\nBecause the connection string is defined by an e\", \"nvironment variable, you could set that variable\\nthrough a different mechanism and at a different ti\", \"me. For example, you could set a different\\nconnection string when deploying to production in the fin\", \"al hosts, or by doing it from your CI/CD\\npipelines in Azure DevOps Services or your preferred DevOps\", \" system.\\n\\u2022 It exposes port 80 for internal access to the catalog-api service within the Docker host.\", \" The\\nhost is currently a Linux VM because it is based on a Docker image for Linux, but you could\\ncon\", \"figure the container to run on a Windows image instead.\\n\\u2022 It forwards the exposed port 80 on the con\", \"tainer to port 5101 on the Docker host machine\\n(the Linux VM).\\n\\u2022 It links the web service to the sql\", \"data service (the SQL Server instance for Linux database\\nrunning in a container). When you specify t\", \"his dependency, the catalog-api container will not\\nstart until the sqldata container has already sta\", \"rted; this aspect is important because catalog-\\napi needs to have the SQL Server database up and run\", \"ning first. However, this kind of\\ncontainer dependency is not enough in many cases, because Docker c\", \"hecks only at the\\ncontainer level. Sometimes the service (in this case SQL Server) might still not b\", \"e ready, so it is\\nadvisable to implement retry logic with exponential backoff in your client microse\", \"rvices. That\\nway, if a dependency container is not ready for a short time, the application will stil\", \"l be\\nresilient.\\n\\u2022 It is configured to allow access to external servers: the extra_hosts setting allo\", \"ws you to access\\nexternal servers or machines outside of the Docker host (that is, outside the defau\", \"lt Linux VM,\\n119 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plicationswhich is a development Docker host), such as a local SQL Server instance on your\\ndevelopme\", \"nt PC.\\nThere are also other, more advanced docker-compose.yml settings that we\\u2019ll discuss in the fol\", \"lowing\\nsections.\\nUsing docker-compose files to target multiple environments\\nThe docker-compose.*.yml\", \" files are definition files and can be used by multiple infrastructures that\\nunderstand that format.\", \" The most straightforward tool is the docker-compose command.\\nTherefore, by using the docker-compose\", \" command you can target the following main scenarios.\\nDevelopment environments\\nWhen you develop appl\", \"ications, it is important to be able to run an application in an isolated\\ndevelopment environment. Y\", \"ou can use the docker-compose CLI command to create that\\nenvironment or Visual Studio, which uses do\", \"cker-compose under the covers.\\nThe docker-compose.yml file allows you to configure and document all \", \"your application\\u2019s service\\ndependencies (other services, cache, databases, queues, etc.). Using the \", \"docker-compose CLI\\ncommand, you can create and start one or more containers for each dependency with\", \" a single\\ncommand (docker-compose up).\\nThe docker-compose.yml files are configuration files interpre\", \"ted by Docker engine but also serve as\\nconvenient documentation files about the composition of your \", \"multi-container application.\\nTesting environments\\nAn important part of any continuous deployment (CD\", \") or continuous integration (CI) process are the\\nunit tests and integration tests. These automated t\", \"ests require an isolated environment so they are\\nnot impacted by the users or any other change in th\", \"e application\\u2019s data.\\nWith Docker Compose, you can create and destroy that isolated environment very\", \" easily in a few\\ncommands from your command prompt or scripts, like the following commands:\\ndocker-c\", \"ompose -f docker-compose.yml -f docker-compose-test.override.yml up -d\\n./run_unit_tests\\ndocker-compo\", \"se -f docker-compose.yml -f docker-compose-test.override.yml down\\nProduction deployments\\nYou can als\", \"o use Compose to deploy to a remote Docker Engine. A typical case is to deploy to a\\nsingle Docker ho\", \"st instance (like a production VM or server provisioned with Docker Machine).\\nIf you are using any o\", \"ther orchestrator (Azure Service Fabric, Kubernetes, etc.), you might need to add\\nsetup and metadata\", \" configuration settings like those in docker-compose.yml, but in the format\\nrequired by the other or\", \"chestrator.\\nIn any case, docker-compose is a convenient tool and metadata format for development, te\", \"sting and\\nproduction workflows, although the production workflow might vary on the orchestrator you \", \"are\\nusing.\\n120 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appl\", \"icationsUsing multiple docker-compose files to handle several environments\\nWhen targeting different \", \"environments, you should use multiple compose files. This approach lets you\\ncreate multiple configur\", \"ation variants depending on the environment.\\nOverriding the base docker-compose file\\nYou could use a\", \" single docker-compose.yml file as in the simplified examples shown in previous\\nsections. However, t\", \"hat is not recommended for most applications.\\nBy default, Compose reads two files, a docker-compose.\", \"yml and an optional docker-\\ncompose.override.yml file. As shown in Figure 6-11, when you are using V\", \"isual Studio and enabling\\nDocker support, Visual Studio also creates an additional docker-compose.vs\", \".debug.g.yml file for\\ndebugging the application, you can take a look at this file in folder obj\\\\Dock\", \"er\\\\ in the main solution\\nfolder.\\nFigure 6-11. docker-compose files in Visual Studio 2019\\ndocker-comp\", \"ose project file structure:\\n\\u2022 .dockerignore - used to ignore files\\n\\u2022 docker-compose.yml - used to co\", \"mpose microservices\\n\\u2022 docker-compose.override.yml - used to configure microservices environment\\nYou \", \"can edit the docker-compose files with any editor, like Visual Studio Code or Sublime, and run the\\na\", \"pplication with the docker-compose up command.\\nBy convention, the docker-compose.yml file contains y\", \"our base configuration and other static\\nsettings. That means that the service configuration should n\", \"ot change depending on the deployment\\nenvironment you are targeting.\\nThe docker-compose.override.yml\", \" file, as its name suggests, contains configuration settings that\\noverride the base configuration, s\", \"uch as configuration that depends on the deployment environment.\\nYou can have multiple override file\", \"s with different names also. The override files usually contain\\nadditional information needed by the\", \" application but specific to an environment or to a deployment.\\nTargeting multiple environments\\nA ty\", \"pical use case is when you define multiple compose files so you can target multiple environments,\\nli\", \"ke production, staging, CI, or development. To support these differences, you can split your\\nCompose\", \" configuration into multiple files, as shown in Figure 6-12.\\n121 CHAPTER 5 | Designing and Developin\", \"g Multi-Container and Microservice-Based .NET ApplicationsFigure 6-12. Multiple docker-compose files\", \" overriding values in the base docker-compose.yml file\\nYou can combine multiple docker-compose*.yml \", \"files to handle different environments. You start with\\nthe base docker-compose.yml file. This base f\", \"ile contains the base or static configuration settings that\\ndo not change depending on the environme\", \"nt. For example, the eShopOnContainers app has the\\nfollowing docker-compose.yml file (simplified wit\", \"h fewer services) as the base file.\\n#docker-compose.yml (Base)\\nversion: '3.4'\\nservices:\\nbasket-api:\\n\", \"image: eshop/basket-api:${TAG:-latest}\\nbuild:\\ncontext: .\\ndockerfile: src/Services/Basket/Basket.API/\", \"Dockerfile\\ndepends_on:\\n- basketdata\\n- identity-api\\n- rabbitmq\\ncatalog-api:\\nimage: eshop/catalog-api:\", \"${TAG:-latest}\\nbuild:\\ncontext: .\\ndockerfile: src/Services/Catalog/Catalog.API/Dockerfile\\ndepends_on:\", \"\\n- sqldata\\n- rabbitmq\\nmarketing-api:\\nimage: eshop/marketing-api:${TAG:-latest}\\nbuild:\\ncontext: .\\ndoc\", \"kerfile: src/Services/Marketing/Marketing.API/Dockerfile\\ndepends_on:\\n- sqldata\\n- nosqldata\\n- identit\", \"y-api\\n- rabbitmq\\nwebmvc:\\nimage: eshop/webmvc:${TAG:-latest}\\n122 CHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applicationsbuild:\\ncontext: .\\ndockerfile: src/Web/WebMV\", \"C/Dockerfile\\ndepends_on:\\n- catalog-api\\n- ordering-api\\n- identity-api\\n- basket-api\\n- marketing-api\\nsq\", \"ldata:\\nimage: mcr.microsoft.com/mssql/server:2019-latest\\nnosqldata:\\nimage: mongo\\nbasketdata:\\nimage: \", \"redis\\nrabbitmq:\\nimage: rabbitmq:3-management\\nThe values in the base docker-compose.yml file should n\", \"ot change because of different target\\ndeployment environments.\\nIf you focus on the webmvc service de\", \"finition, for instance, you can see how that information is much\\nthe same no matter what environment\", \" you might be targeting. You have the following information:\\n\\u2022 The service name: webmvc.\\n\\u2022 The conta\", \"iner\\u2019s custom image: eshop/webmvc.\\n\\u2022 The command to build the custom Docker image, indicating which \", \"Dockerfile to use.\\n\\u2022 Dependencies on other services, so this container does not start until the othe\", \"r dependency\\ncontainers have started.\\nYou can have additional configuration, but the important point\", \" is that in the base docker-\\ncompose.yml file, you just want to set the information that is common a\", \"cross environments. Then in\\nthe docker-compose.override.yml or similar files for production or stagi\", \"ng, you should place\\nconfiguration that is specific for each environment.\\nUsually, the docker-compos\", \"e.override.yml is used for your development environment, as in the\\nfollowing example from eShopOnCon\", \"tainers:\\n#docker-compose.override.yml (Extended config for DEVELOPMENT env.)\\nversion: '3.4'\\nservices\", \":\\n# Simplified number of services here:\\nbasket-api:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Developmen\", \"t\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- ConnectionString=${ESHOP_AZURE_REDIS_BASKET_DB:-basketdata}\\n\", \"- identityUrl=http://identity-api\\n- IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5105\", \"\\n123 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications- \", \"EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq}\\n- EventBusUserName=${ESHOP_SERVICE_BUS_USERN\", \"AME}\\n- EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD}\\n- AzureServiceBusEnabled=False\\n- ApplicationIn\", \"sights__InstrumentationKey=${INSTRUMENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE}\\n- UseLoadT\", \"est=${USE_LOADTEST:-False}\\nports:\\n- \\\"5103:80\\\"\\ncatalog-api:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Dev\", \"elopment\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- ConnectionString=${ESHOP_AZURE_CATALOG_DB:-\\nServer=sq\", \"ldata;Database=Microsoft.eShopOnContainers.Services.CatalogDb;User\\nId=sa;Password=[PLACEHOLDER]}\\n- P\", \"icBaseUrl=${ESHOP_AZURE_STORAGE_CATALOG_URL:-\\nhttp://host.docker.internal:5202/api/v1/catalog/items/\", \"[0]/pic/}\\n- EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq}\\n- EventBusUserName=${ESHOP_SERVI\", \"CE_BUS_USERNAME}\\n- EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD}\\n- AzureStorageAccountName=${ESHOP_\", \"AZURE_STORAGE_CATALOG_NAME}\\n- AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_CATALOG_KEY}\\n- UseCustomi\", \"zationData=True\\n- AzureServiceBusEnabled=False\\n- AzureStorageEnabled=False\\n- ApplicationInsights__In\", \"strumentationKey=${INSTRUMENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE}\\nports:\\n- \\\"5101:80\\\"\\nm\", \"arketing-api:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n\", \"- ConnectionString=${ESHOP_AZURE_MARKETING_DB:-\\nServer=sqldata;Database=Microsoft.eShopOnContainers.\", \"Services.MarketingDb;User\\nId=sa;Password=[PLACEHOLDER]}\\n- MongoConnectionString=${ESHOP_AZURE_COSMOS\", \"DB:-mongodb://nosqldata}\\n- MongoDatabase=MarketingDb\\n- EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:\", \"-rabbitmq}\\n- EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME}\\n- EventBusPassword=${ESHOP_SERVICE_BUS_P\", \"ASSWORD}\\n- identityUrl=http://identity-api\\n- IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS_NAME_OR\", \"_IP}:5105\\n- CampaignDetailFunctionUri=${ESHOP_AZUREFUNC_CAMPAIGN_DETAILS_URI}\\n- PicBaseUrl=${ESHOP_A\", \"ZURE_STORAGE_MARKETING_URL:-\\nhttp://host.docker.internal:5110/api/v1/campaigns/[0]/pic/}\\n- AzureStor\", \"ageAccountName=${ESHOP_AZURE_STORAGE_MARKETING_NAME}\\n- AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_\", \"MARKETING_KEY}\\n- AzureServiceBusEnabled=False\\n- AzureStorageEnabled=False\\n- ApplicationInsights__Ins\", \"trumentationKey=${INSTRUMENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE}\\n- UseLoadTest=${USE_L\", \"OADTEST:-False}\\nports:\\n- \\\"5110:80\\\"\\nwebmvc:\\n124 CHAPTER 5 | Designing and Developing Multi-Container \", \"and Microservice-Based .NET Applicationsenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- ASPNETCO\", \"RE_URLS=http://0.0.0.0:80\\n- PurchaseUrl=http://webshoppingapigw\\n- IdentityUrl=http://10.0.75.1:5105\\n\", \"- MarketingUrl=http://webmarketingapigw\\n- CatalogUrlHC=http://catalog-api/hc\\n- OrderingUrlHC=http://\", \"ordering-api/hc\\n- IdentityUrlHC=http://identity-api/hc\\n- BasketUrlHC=http://basket-api/hc\\n- Marketin\", \"gUrlHC=http://marketing-api/hc\\n- PaymentUrlHC=http://payment-api/hc\\n- SignalrHubUrl=http://${ESHOP_E\", \"XTERNAL_DNS_NAME_OR_IP}:5202\\n- UseCustomizationData=True\\n- ApplicationInsights__InstrumentationKey=$\", \"{INSTRUMENTATION_KEY}\\n- OrchestratorType=${ORCHESTRATOR_TYPE}\\n- UseLoadTest=${USE_LOADTEST:-False}\\np\", \"orts:\\n- \\\"5100:80\\\"\\nsqldata:\\nenvironment:\\n- SA_PASSWORD=[PLACEHOLDER]\\n- ACCEPT_EULA=Y\\nports:\\n- \\\"5433:1\", \"433\\\"\\nnosqldata:\\nports:\\n- \\\"27017:27017\\\"\\nbasketdata:\\nports:\\n- \\\"6379:6379\\\"\\nrabbitmq:\\nports:\\n- \\\"15672:15\", \"672\\\"\\n- \\\"5672:5672\\\"\\nIn this example, the development override configuration exposes some ports to the\", \" host, defines\\nenvironment variables with redirect URLs, and specifies connection strings for the de\", \"velopment\\nenvironment. These settings are all just for the development environment.\\nWhen you run doc\", \"ker-compose up (or launch it from Visual Studio), the command reads the overrides\\nautomatically as i\", \"f it were merging both files.\\nSuppose that you want another Compose file for the production environm\", \"ent, with different\\nconfiguration values, ports, or connection strings. You can create another overr\", \"ide file, like file named\\ndocker-compose.prod.yml with different settings and environment variables.\", \" That file might be stored\\nin a different Git repo or managed and secured by a different team.\\nHow t\", \"o deploy with a specific override file\\nTo use multiple override files, or an override file with a di\", \"fferent name, you can use the -f option with\\nthe docker-compose command and specify the files. Compo\", \"se merges files in the order they are\\nspecified on the command line. The following example shows how\", \" to deploy with override files.\\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -\", \"d\\n125 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsU\", \"sing environment variables in docker-compose files\\nIt is convenient, especially in production enviro\", \"nments, to be able to get configuration information\\nfrom environment variables, as we have shown in \", \"previous examples. You can reference an\\nenvironment variable in your docker-compose files using the \", \"syntax ${MY_VAR}. The following line\\nfrom a docker-compose.prod.yml file shows how to reference the \", \"value of an environment variable.\\nIdentityUrl=http://${ESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP}:5105\\nEnvi\", \"ronment variables are created and initialized in different ways, depending on your host\\nenvironment \", \"(Linux, Windows, Cloud cluster, etc.). However, a convenient approach is to use an .env\\nfile. The do\", \"cker-compose files support declaring default environment variables in the .env file. These\\nvalues fo\", \"r the environment variables are the default values. But they can be overridden by the values\\nyou mig\", \"ht have defined in each of your environments (host OS or environment variables from your\\ncluster). Y\", \"ou place this .env file in the folder where the docker-compose command is executed from.\\nThe followi\", \"ng example shows an .env file like the .env file for the eShopOnContainers application.\\n# .env file\\n\", \"ESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker.internal\\nESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP=10.121.122.92\\n\", \"Docker-compose expects each line in an .env file to be in the format <variable>=<value>.\\nThe values \", \"set in the run-time environment always override the values defined inside the .env file. In a\\nsimila\", \"r way, values passed via command-line arguments also override the default values set in the .env\\nfil\", \"e.\\nAdditional resources\\n\\u2022 Overview of Docker Compose\\nhttps://docs.docker.com/compose/overview/\\n\\u2022 Mul\", \"tiple Compose files\\nhttps://docs.docker.com/compose/multiple-compose-files/\\nBuilding optimized ASP.N\", \"ET Core Docker images\\nIf you are exploring Docker and .NET on sources on the Internet, you will find\", \" Dockerfiles that\\ndemonstrate the simplicity of building a Docker image by copying your source into \", \"a container. These\\nexamples suggest that by using a simple configuration, you can have a Docker imag\", \"e with the\\nenvironment packaged with your application. The following example shows a simple Dockerfi\", \"le in this\\nvein.\\nFROM mcr.microsoft.com/dotnet/sdk:7.0\\nWORKDIR /app\\nENV ASPNETCORE_URLS http://+:80\\n\", \"EXPOSE 80\\nCOPY . .\\nRUN dotnet restore\\nENTRYPOINT [\\\"dotnet\\\", \\\"run\\\"]\\n126 CHAPTER 5 | Designing and Dev\", \"eloping Multi-Container and Microservice-Based .NET ApplicationsA Dockerfile like this will work. Ho\", \"wever, you can substantially optimize your images, especially your\\nproduction images.\\nIn the contain\", \"er and microservices model, you are constantly starting containers. The typical way of\\nusing contain\", \"ers does not restart a sleeping container, because the container is disposable.\\nOrchestrators (like \", \"Kubernetes and Azure Service Fabric) create new instances of images. What this\\nmeans is that you wou\", \"ld need to optimize by precompiling the application when it is built so the\\ninstantiation process wi\", \"ll be faster. When the container is started, it should be ready to run. Don\\u2019t\\nrestore and compile at\", \" run time using the dotnet restore and dotnet build CLI commands as you may\\nsee in blog posts about \", \".NET and Docker.\\nThe .NET team has been doing important work to make .NET and ASP.NET Core a contain\", \"er-optimized\\nframework. Not only is .NET a lightweight framework with a small memory footprint; the \", \"team has\\nfocused on optimized Docker images for three main scenarios and published them in the Docke\", \"r Hub\\nregistry at dotnet/, beginning with version 2.1:\\n1. Development: The priority is the ability t\", \"o quickly iterate and debug changes, and where size\\nis secondary.\\n2. Build: The priority is compilin\", \"g the application, and the image includes binaries and other\\ndependencies to optimize binaries.\\n3. P\", \"roduction: The focus is fast deploying and starting of containers, so these images are\\nlimited to th\", \"e binaries and content needed to run the application.\\nThe .NET team provides four basic variants in \", \"dotnet/ (at Docker Hub):\\n1. sdk: for development and build scenarios\\n2. aspnet: for ASP.NET producti\", \"on scenarios\\n3. runtime: for .NET production scenarios\\n4. runtime-deps: for production scenarios of \", \"self-contained applications\\nFor faster startup, runtime images also automatically set aspnetcore_url\", \"s to port 80 and use Ngen to\\ncreate a native image cache of assemblies.\\nAdditional resources\\n\\u2022 Build\", \"ing Optimized Docker Images with ASP.NET Core\\nhttps://learn.microsoft.com/archive/blogs/stevelasker/\", \"building-optimized-docker-images-\\nwith-asp-net-core\\n\\u2022 Building Docker Images for .NET Applications\\nh\", \"ttps://learn.microsoft.com/dotnet/core/docker/building-net-docker-images\\nUse a database server runni\", \"ng as a container\\nYou can have your databases (SQL Server, PostgreSQL, MySQL, etc.) on regular stand\", \"alone servers, in\\non-premises clusters, or in PaaS services in the cloud like Azure SQL DB. However,\", \" for development\\nand test environments, having your databases running as containers is convenient, b\", \"ecause you don\\u2019t\\n127 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NE\", \"T Applicationshave any external dependency and simply running the docker-compose up command starts t\", \"he whole\\napplication. Having those databases as containers is also great for integration tests, beca\", \"use the\\ndatabase is started in the container and is always populated with the same sample data, so t\", \"ests can\\nbe more predictable.\\nSQL Server running as a container with a microservice-related\\ndatabase\", \"\\nIn eShopOnContainers, there\\u2019s a container named sqldata, as defined in the docker-compose.yml file,\", \"\\nthat runs a SQL Server for Linux instance with the SQL databases for all microservices that need on\", \"e.\\nA key point in microservices is that each microservice owns its related data, so it should have i\", \"ts own\\ndatabase. However, the databases can be anywhere. In this case, they are all in the same cont\", \"ainer to\\nkeep Docker memory requirements as low as possible. Keep in mind that this is a good-enough\", \"\\nsolution for development and, perhaps, testing but not for production.\\nThe SQL Server container in \", \"the sample application is configured with the following YAML code in the\\ndocker-compose.yml file, wh\", \"ich is executed when you run docker-compose up. Note that the YAML\\ncode has consolidated configurati\", \"on information from the generic docker-compose.yml file and the\\ndocker-compose.override.yml file. (U\", \"sually you would separate the environment settings from the\\nbase or static information related to th\", \"e SQL Server image.)\\nsqldata:\\nimage: mcr.microsoft.com/mssql/server:2017-latest\\nenvironment:\\n- SA_PA\", \"SSWORD=Pass@word\\n- ACCEPT_EULA=Y\\nports:\\n- \\\"5434:1433\\\"\\nIn a similar way, instead of using docker-comp\", \"ose, the following docker run command can run that\\ncontainer:\\ndocker run -e 'ACCEPT_EULA=Y' -e 'SA_P\", \"ASSWORD=Pass@word' -p 5433:1433 -d\\nmcr.microsoft.com/mssql/server:2017-latest\\nHowever, if you are de\", \"ploying a multi-container application like eShopOnContainers, it is more\\nconvenient to use the docke\", \"r-compose up command so that it deploys all the required containers for\\nthe application.\\nWhen you st\", \"art this SQL Server container for the first time, the container initializes SQL Server with the\\npass\", \"word that you provide. Once SQL Server is running as a container, you can update the database\\nby con\", \"necting through any regular SQL connection, such as from SQL Server Management Studio,\\nVisual Studio\", \", or C# code.\\nThe eShopOnContainers application initializes each microservice database with sample d\", \"ata by\\nseeding it with data on startup, as explained in the following section.\\nHaving SQL Server run\", \"ning as a container is not just useful for a demo where you might not have\\naccess to an instance of \", \"SQL Server. As noted, it is also great for development and testing\\n128 CHAPTER 5 | Designing and Dev\", \"eloping Multi-Container and Microservice-Based .NET Applicationsenvironments so that you can easily \", \"run integration tests starting from a clean SQL Server image and\\nknown data by seeding new sample da\", \"ta.\\nAdditional resources\\n\\u2022 Run the SQL Server Docker image on Linux, Mac, or Windows\\nhttps://learn.m\", \"icrosoft.com/sql/linux/sql-server-linux-setup-docker\\n\\u2022 Connect and query SQL Server on Linux with sq\", \"lcmd\\nhttps://learn.microsoft.com/sql/linux/sql-server-linux-connect-and-query-sqlcmd\\nSeeding with te\", \"st data on Web application startup\\nTo add data to the database when the application starts up, you c\", \"an add code like the following to\\nthe Main method in the Program class of the Web API project:\\npubli\", \"c static int Main(string[] args)\\n{\\nvar configuration = GetConfiguration();\\nLog.Logger = CreateSerilo\", \"gLogger(configuration);\\ntry\\n{\\nLog.Information(\\\"Configuring web host ({ApplicationContext})...\\\", AppN\", \"ame);\\nvar host = CreateHostBuilder(configuration, args);\\nLog.Information(\\\"Applying migrations ({Appl\", \"icationContext})...\\\", AppName);\\nhost.MigrateDbContext<CatalogContext>((context, services) =>\\n{\\nvar e\", \"nv = services.GetService<IWebHostEnvironment>();\\nvar settings = services.GetService<IOptions<Catalog\", \"Settings>>();\\nvar logger = services.GetService<ILogger<CatalogContextSeed>>();\\nnew CatalogContextSee\", \"d()\\n.SeedAsync(context, env, settings, logger)\\n.Wait();\\n})\\n.MigrateDbContext<IntegrationEventLogCont\", \"ext>((_, __) => { });\\nLog.Information(\\\"Starting web host ({ApplicationContext})...\\\", AppName);\\nhost.\", \"Run();\\nreturn 0;\\n}\\ncatch (Exception ex)\\n{\\nLog.Fatal(ex, \\\"Program terminated unexpectedly ({Applicati\", \"onContext})!\\\", AppName);\\nreturn 1;\\n}\\nfinally\\n{\\nLog.CloseAndFlush();\\n}\\n}\\n129 CHAPTER 5 | Designing an\", \"d Developing Multi-Container and Microservice-Based .NET ApplicationsThere\\u2019s an important caveat whe\", \"n applying migrations and seeding a database during container\\nstartup. Since the database server mig\", \"ht not be available for whatever reason, you must handle retries\\nwhile waiting for the server to be \", \"available. This retry logic is handled by the MigrateDbContext()\\nextension method, as shown in the f\", \"ollowing code:\\npublic static IWebHost MigrateDbContext<TContext>(\\nthis IWebHost host,\\nAction<TContex\", \"t,\\nIServiceProvider> seeder)\\nwhere TContext : DbContext\\n{\\nvar underK8s = host.IsInKubernetes();\\nusin\", \"g (var scope = host.Services.CreateScope())\\n{\\nvar services = scope.ServiceProvider;\\nvar logger = ser\", \"vices.GetRequiredService<ILogger<TContext>>();\\nvar context = services.GetService<TContext>();\\ntry\\n{\\n\", \"logger.LogInformation(\\\"Migrating database associated with context\\n{DbContextName}\\\", typeof(TContext)\", \".Name);\\nif (underK8s)\\n{\\nInvokeSeeder(seeder, context, services);\\n}\\nelse\\n{\\nvar retry = Policy.Handle<\", \"SqlException>()\\n.WaitAndRetry(new TimeSpan[]\\n{\\nTimeSpan.FromSeconds(3),\\nTimeSpan.FromSeconds(5),\\nTim\", \"eSpan.FromSeconds(8),\\n});\\n//if the sql server container is not created on run docker compose this\\n//\", \"migration can't fail for network related exception. The retry options for\\nDbContext only\\n//apply to \", \"transient exceptions\\n// Note that this is NOT applied when running some orchestrators (let the\\norche\", \"strator to recreate the failing service)\\nretry.Execute(() => InvokeSeeder(seeder, context, services)\", \");\\n}\\nlogger.LogInformation(\\\"Migrated database associated with context\\n{DbContextName}\\\", typeof(TCont\", \"ext).Name);\\n}\\ncatch (Exception ex)\\n{\\nlogger.LogError(ex, \\\"An error occurred while migrating the data\", \"base used on\\ncontext {DbContextName}\\\", typeof(TContext).Name);\\nif (underK8s)\\n{\\nthrow; // Rethrow und\", \"er k8s because we rely on k8s to re-run the\\n130 CHAPTER 5 | Designing and Developing Multi-Container\", \" and Microservice-Based .NET Applicationspod\\n}\\n}\\n}\\nreturn host;\\n}\\nThe following code in the custom C\", \"atalogContextSeed class populates the data.\\npublic class CatalogContextSeed\\n{\\npublic static async Ta\", \"sk SeedAsync(IApplicationBuilder applicationBuilder)\\n{\\nvar context = (CatalogContext)applicationBuil\", \"der\\n.ApplicationServices.GetService(typeof(CatalogContext));\\nusing (context)\\n{\\ncontext.Database.Migr\", \"ate();\\nif (!context.CatalogBrands.Any())\\n{\\ncontext.CatalogBrands.AddRange(\\nGetPreconfiguredCatalogBr\", \"ands());\\nawait context.SaveChangesAsync();\\n}\\nif (!context.CatalogTypes.Any())\\n{\\ncontext.CatalogTypes\", \".AddRange(\\nGetPreconfiguredCatalogTypes());\\nawait context.SaveChangesAsync();\\n}\\n}\\n}\\nstatic IEnumerab\", \"le<CatalogBrand> GetPreconfiguredCatalogBrands()\\n{\\nreturn new List<CatalogBrand>()\\n{\\nnew CatalogBran\", \"d() { Brand = \\\"Azure\\\"},\\nnew CatalogBrand() { Brand = \\\".NET\\\" },\\nnew CatalogBrand() { Brand = \\\"Visual \", \"Studio\\\" },\\nnew CatalogBrand() { Brand = \\\"SQL Server\\\" }\\n};\\n}\\nstatic IEnumerable<CatalogType> GetPreco\", \"nfiguredCatalogTypes()\\n{\\nreturn new List<CatalogType>()\\n{\\nnew CatalogType() { Type = \\\"Mug\\\"},\\nnew Cat\", \"alogType() { Type = \\\"T-Shirt\\\" },\\nnew CatalogType() { Type = \\\"Backpack\\\" },\\nnew CatalogType() { Type =\", \" \\\"USB Memory Stick\\\" }\\n};\\n}\\n}\\nWhen you run integration tests, having a way to generate data consisten\", \"t with your integration tests is\\nuseful. Being able to create everything from scratch, including an \", \"instance of SQL Server running on a\\ncontainer, is great for test environments.\\n131 CHAPTER 5 | Desig\", \"ning and Developing Multi-Container and Microservice-Based .NET ApplicationsEF Core InMemory databas\", \"e versus SQL Server running as a container\\nAnother good choice when running tests is to use the Enti\", \"ty Framework InMemory database provider.\\nYou can specify that configuration in the ConfigureServices\", \" method of the Startup class in your Web\\nAPI project:\\npublic class Startup\\n{\\n// Other Startup code .\", \"..\\npublic void ConfigureServices(IServiceCollection services)\\n{\\nservices.AddSingleton<IConfiguration\", \">(Configuration);\\n// DbContext using an InMemory database provider\\nservices.AddDbContext<CatalogCont\", \"ext>(opt => opt.UseInMemoryDatabase());\\n//(Alternative: DbContext using a SQL Server provider\\n//serv\", \"ices.AddDbContext<CatalogContext>(c =>\\n//{\\n// c.UseSqlServer(Configuration[\\\"ConnectionString\\\"]);\\n//\\n\", \"//});\\n}\\n// Other Startup code ...\\n}\\nThere is an important catch, though. The in-memory database does\", \" not support many constraints that\\nare specific to a particular database. For instance, you might ad\", \"d a unique index on a column in your\\nEF Core model and write a test against your in-memory database \", \"to check that it does not let you add\\na duplicate value. But when you are using the in-memory databa\", \"se, you cannot handle unique indexes\\non a column. Therefore, the in-memory database does not behave \", \"exactly the same as a real SQL\\nServer database\\u2014it does not emulate database-specific constraints.\\nEv\", \"en so, an in-memory database is still useful for testing and prototyping. But if you want to create\\n\", \"accurate integration tests that take into account the behavior of a specific database implementation\", \",\\nyou need to use a real database like SQL Server. For that purpose, running SQL Server in a contain\", \"er is\\na great choice and more accurate than the EF Core InMemory database provider.\\nUsing a Redis ca\", \"che service running in a container\\nYou can run Redis on a container, especially for development and \", \"testing and for proof-of-concept\\nscenarios. This scenario is convenient, because you can have all yo\", \"ur dependencies running on\\ncontainers\\u2014not just for your local development machines, but for your tes\", \"ting environments in your\\nCI/CD pipelines.\\nHowever, when you run Redis in production, it is better t\", \"o look for a high-availability solution like\\nRedis Microsoft Azure, which runs as a PaaS (Platform a\", \"s a Service). In your code, you just need to\\nchange your connection strings.\\nRedis provides a Docker\", \" image with Redis. That image is available from Docker Hub at this URL:\\nhttps://hub.docker.com/_/red\", \"is/\\n132 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Application\", \"sYou can directly run a Docker Redis container by executing the following Docker CLI command in your\", \"\\ncommand prompt:\\ndocker run --name some-redis -d redis\\nThe Redis image includes expose:6379 (the por\", \"t used by Redis), so standard container linking will\\nmake it automatically available to the linked c\", \"ontainers.\\nIn eShopOnContainers, the basket-api microservice uses a Redis cache running as a contain\", \"er. That\\nbasketdata container is defined as part of the multi-container docker-compose.yml file, as \", \"shown in the\\nfollowing example:\\n#docker-compose.yml file\\n#...\\nbasketdata:\\nimage: redis\\nexpose:\\n- \\\"63\", \"79\\\"\\nThis code in the docker-compose.yml defines a container named basketdata based on the redis imag\", \"e\\nand publishing the port 6379 internally. This configuration means that it will only be accessible \", \"from\\nother containers running within the Docker host.\\nFinally, in the docker-compose.override.yml fi\", \"le, the basket-api microservice for the\\neShopOnContainers sample defines the connection string to us\", \"e for that Redis container:\\nbasket-api:\\nenvironment:\\n# Other data ...\\n- ConnectionString=basketdata\\n\", \"- EventBusConnection=rabbitmq\\nAs mentioned before, the name of the microservice basketdata is resolv\", \"ed by Docker\\u2019s internal\\nnetwork DNS.\\nImplementing event-based communication between\\nmicroservices (i\", \"ntegration events)\\nAs described earlier, when you use event-based communication, a microservice publ\", \"ishes an event\\nwhen something notable happens, such as when it updates a business entity. Other micr\", \"oservices\\nsubscribe to those events. When a microservice receives an event, it can update its own bu\", \"siness\\nentities, which might lead to more events being published. This is the essence of the eventua\", \"l\\nconsistency concept. This publish/subscribe system is usually performed by using an implementation\", \"\\nof an event bus. The event bus can be designed as an interface with the API needed to subscribe and\", \"\\nunsubscribe to events and to publish events. It can also have one or more implementations based on\\n\", \"any inter-process or messaging communication, such as a messaging queue or a service bus that\\nsuppor\", \"ts asynchronous communication and a publish/subscribe model.\\nYou can use events to implement busines\", \"s transactions that span multiple services, which give you\\neventual consistency between those servic\", \"es. An eventually consistent transaction consists of a series\\n133 CHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET Applicationsof distributed actions. At each action, t\", \"he microservice updates a business entity and publishes an\\nevent that triggers the next action. Figu\", \"re 6-18 below, shows a PriceUpdated event published through\\nan event bus, so the price update is pro\", \"pagated to the Basket and other microservices.\\nFigure 6-18. Event-driven communication based on an e\", \"vent bus\\nThis section describes how you can implement this type of communication with .NET by using \", \"a\\ngeneric event bus interface, as shown in Figure 6-18. There are multiple potential implementations\", \",\\neach using a different technology or infrastructure such as RabbitMQ, Azure Service Bus, or any ot\", \"her\\nthird-party open-source or commercial service bus.\\nUsing message brokers and service buses for p\", \"roduction systems\\nAs noted in the architecture section, you can choose from multiple messaging techn\", \"ologies for\\nimplementing your abstract event bus. But these technologies are at different levels. Fo\", \"r instance,\\nRabbitMQ, a messaging broker transport, is at a lower level than commercial products lik\", \"e Azure\\nService Bus, NServiceBus, MassTransit, or Brighter. Most of these products can work on top o\", \"f either\\nRabbitMQ or Azure Service Bus. Your choice of product depends on how many features and how\\n\", \"much out-of-the-box scalability you need for your application.\\nFor implementing just an event bus pr\", \"oof-of-concept for your development environment, as in the\\neShopOnContainers sample, a simple implem\", \"entation on top of RabbitMQ running as a container\\nmight be enough. But for mission-critical and pro\", \"duction systems that need high scalability, you\\nmight want to evaluate and use Azure Service Bus.\\nIf\", \" you require high-level abstractions and richer features like Sagas for long-running processes that\\n\", \"make distributed development easier, other commercial and open-source service buses like\\nNServiceBus\", \", MassTransit, and Brighter are worth evaluating. In this case, the abstractions and API to\\nuse woul\", \"d usually be directly the ones provided by those high-level service buses instead of your own\\nabstra\", \"ctions (like the simple event bus abstractions provided at eShopOnContainers). For that matter,\\n134 \", \"CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsyou can\", \" research the forked eShopOnContainers using NServiceBus (additional derived sample\\nimplemented by P\", \"articular Software).\\nOf course, you could always build your own service bus features on top of lower\", \"-level technologies\\nlike RabbitMQ and Docker, but the work needed to \\u201creinvent the wheel\\u201d might be t\", \"oo costly for a\\ncustom enterprise application.\\nTo reiterate: the sample event bus abstractions and i\", \"mplementation showcased in the\\neShopOnContainers sample are intended to be used only as a proof of c\", \"oncept. Once you have\\ndecided that you want to have asynchronous and event-driven communication, as \", \"explained in the\\ncurrent section, you should choose the service bus product that best fits your need\", \"s for production.\\nIntegration events\\nIntegration events are used for bringing domain state in sync a\", \"cross multiple microservices or external\\nsystems. This functionality is done by publishing integrati\", \"on events outside the microservice. When an\\nevent is published to multiple receiver microservices (t\", \"o as many microservices as are subscribed to\\nthe integration event), the appropriate event handler i\", \"n each receiver microservice handles the event.\\nAn integration event is basically a data-holding cla\", \"ss, as in the following example:\\npublic class ProductPriceChangedIntegrationEvent : IntegrationEvent\", \"\\n{\\npublic int ProductId { get; private set; }\\npublic decimal NewPrice { get; private set; }\\npublic d\", \"ecimal OldPrice { get; private set; }\\npublic ProductPriceChangedIntegrationEvent(int productId, deci\", \"mal newPrice,\\ndecimal oldPrice)\\n{\\nProductId = productId;\\nNewPrice = newPrice;\\nOldPrice = oldPrice;\\n}\", \"\\n}\\nThe integration events can be defined at the application level of each microservice, so they are\\n\", \"decoupled from other microservices, in a way comparable to how ViewModels are defined in the\\nserver \", \"and client. What is not recommended is sharing a common integration events library across\\nmultiple m\", \"icroservices; doing that would be coupling those microservices with a single event\\ndefinition data l\", \"ibrary. You do not want to do that for the same reasons that you do not want to share\\na common domai\", \"n model across multiple microservices: microservices must be completely\\nautonomous. For more informa\", \"tion, see this blog post on the amount of data to put in events. Be\\ncareful not to take this too far\", \", as this other blog post describes the problem data deficient messages\\ncan produce. Your design of \", \"your events should aim to be \\u201cjust right\\u201d for the needs of their\\nconsumers.\\nThere are only a few kin\", \"ds of libraries you should share across microservices. One is libraries that are\\nfinal application b\", \"locks, like the Event Bus client API, as in eShopOnContainers. Another is libraries\\nthat constitute \", \"tools that could also be shared as NuGet components, like JSON serializers.\\n135 CHAPTER 5 | Designin\", \"g and Developing Multi-Container and Microservice-Based .NET ApplicationsThe event bus\\nAn event bus \", \"allows publish/subscribe-style communication between microservices without requiring\\nthe components \", \"to explicitly be aware of each other, as shown in Figure 6-19.\\nFigure 6-19. Publish/subscribe basics\", \" with an event bus\\nThe above diagram shows that microservice A publishes to Event Bus, which distrib\", \"utes to subscribing\\nmicroservices B and C, without the publisher needing to know the subscribers. Th\", \"e event bus is\\nrelated to the Observer pattern and the publish-subscribe pattern.\\nObserver pattern\\nI\", \"n the Observer pattern, your primary object (known as the Observable) notifies other interested\\nobje\", \"cts (known as Observers) with relevant information (events).\\nPublish/Subscribe (Pub/Sub) pattern\\nThe\", \" purpose of the Publish/Subscribe pattern is the same as the Observer pattern: you want to notify\\not\", \"her services when certain events take place. But there is an important difference between the\\nObserv\", \"er and Pub/Sub patterns. In the observer pattern, the broadcast is performed directly from the\\nobser\", \"vable to the observers, so they \\u201cknow\\u201d each other. But when using a Pub/Sub pattern, there is a\\nthir\", \"d component, called broker, or message broker or event bus, which is known by both the\\npublisher and\", \" subscriber. Therefore, when using the Pub/Sub pattern the publisher and the\\nsubscribers are precise\", \"ly decoupled thanks to the mentioned event bus or message broker.\\nThe middleman or event bus\\nHow do \", \"you achieve anonymity between publisher and subscriber? An easy way is let a middleman\\ntake care of \", \"all the communication. An event bus is one such middleman.\\nAn event bus is typically composed of two\", \" parts:\\n\\u2022 The abstraction or interface.\\n\\u2022 One or more implementations.\\n136 CHAPTER 5 | Designing and\", \" Developing Multi-Container and Microservice-Based .NET ApplicationsIn Figure 6-19 you can see how, \", \"from an application point of view, the event bus is nothing more than\\na Pub/Sub channel. The way you\", \" implement this asynchronous communication can vary. It can have\\nmultiple implementations so that yo\", \"u can swap between them, depending on the environment\\nrequirements (for example, production versus d\", \"evelopment environments).\\nIn Figure 6-20, you can see an abstraction of an event bus with multiple i\", \"mplementations based on\\ninfrastructure messaging technologies like RabbitMQ, Azure Service Bus, or a\", \"nother event/message\\nbroker.\\nFigure 6- 20. Multiple implementations of an event bus\\nIt\\u2019s good to hav\", \"e the event bus defined through an interface so it can be implemented with several\\ntechnologies, lik\", \"e RabbitMQ, Azure Service bus or others. However, and as mentioned previously,\\nusing your own abstra\", \"ctions (the event bus interface) is good only if you need basic event bus\\nfeatures supported by your\", \" abstractions. If you need richer service bus features, you should probably\\nuse the API and abstract\", \"ions provided by your preferred commercial service bus instead of your own\\nabstractions.\\nDefining an\", \" event bus interface\\nLet\\u2019s start with some implementation code for the event bus interface and possi\", \"ble implementations\\nfor exploration purposes. The interface should be generic and straightforward, a\", \"s in the following\\ninterface.\\npublic interface IEventBus\\n{\\nvoid Publish(IntegrationEvent @event);\\nvo\", \"id Subscribe<T, TH>()\\nwhere T : IntegrationEvent\\nwhere TH : IIntegrationEventHandler<T>;\\nvoid Subscr\", \"ibeDynamic<TH>(string eventName)\\nwhere TH : IDynamicIntegrationEventHandler;\\n137 CHAPTER 5 | Designi\", \"ng and Developing Multi-Container and Microservice-Based .NET Applicationsvoid UnsubscribeDynamic<TH\", \">(string eventName)\\nwhere TH : IDynamicIntegrationEventHandler;\\nvoid Unsubscribe<T, TH>()\\nwhere TH :\", \" IIntegrationEventHandler<T>\\nwhere T : IntegrationEvent;\\n}\\nThe Publish method is straightforward. Th\", \"e event bus will broadcast the integration event passed to it\\nto any microservice, or even an extern\", \"al application, subscribed to that event. This method is used by\\nthe microservice that is publishing\", \" the event.\\nThe Subscribe methods (you can have several implementations depending on the arguments) \", \"are\\nused by the microservices that want to receive events. This method has two arguments. The first \", \"is the\\nintegration event to subscribe to (IntegrationEvent). The second argument is the integration \", \"event\\nhandler (or callback method), named IIntegrationEventHandler<T>, to be executed when the recei\", \"ver\\nmicroservice gets that integration event message.\\nAdditional resources\\nSome production-ready mes\", \"saging solutions:\\n\\u2022 Azure Service Bus\\nhttps://learn.microsoft.com/azure/service-bus-messaging/\\n\\u2022 NSe\", \"rviceBus\\nhttps://particular.net/nservicebus\\n\\u2022 MassTransit\\nhttps://masstransit-project.com/\\nImplement\", \"ing an event bus with RabbitMQ for the\\ndevelopment or test environment\\nWe should start by saying tha\", \"t if you create your custom event bus based on RabbitMQ running in a\\ncontainer, as the eShopOnContai\", \"ners application does, it should be used only for your development\\nand test environments. Don\\u2019t use \", \"it for your production environment, unless you are building it as a\\npart of a production-ready servi\", \"ce bus as described in the Additional resources section below. A\\nsimple custom event bus might be mi\", \"ssing many production-ready critical features that a commercial\\nservice bus has.\\nOne of the event bu\", \"s custom implementations in eShopOnContainers is basically a library using the\\nRabbitMQ API. (There\\u2019\", \"s another implementation based on Azure Service Bus.)\\nThe event bus implementation with RabbitMQ let\", \"s microservices subscribe to events, publish events,\\nand receive events, as shown in Figure 6-21.\\n13\", \"8 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsFigur\", \"e 6-21. RabbitMQ implementation of an event bus\\nRabbitMQ functions as an intermediary between messag\", \"e publisher and subscribers, to handle\\ndistribution. In the code, the EventBusRabbitMQ class impleme\", \"nts the generic IEventBus interface.\\nThis implementation is based on Dependency Injection so that yo\", \"u can swap from this dev/test\\nversion to a production version.\\npublic class EventBusRabbitMQ : IEven\", \"tBus, IDisposable\\n{\\n// Implementation using RabbitMQ API\\n//...\\n}\\nThe RabbitMQ implementation of a sa\", \"mple dev/test event bus is boilerplate code. It has to handle the\\nconnection to the RabbitMQ server \", \"and provide code for publishing a message event to the queues. It\\nalso has to implement a dictionary\", \" of collections of integration event handlers for each event type;\\nthese event types can have a diff\", \"erent instantiation and different subscriptions for each receiver\\nmicroservice, as shown in Figure 6\", \"-21.\\nImplementing a simple publish method with RabbitMQ\\nThe following code is a simplified version o\", \"f an event bus implementation for RabbitMQ, to\\nshowcase the whole scenario. You don\\u2019t really handle \", \"the connection this way. To see the full\\nimplementation, see the actual code in the dotnet-architect\", \"ure/eShopOnContainers repository.\\npublic class EventBusRabbitMQ : IEventBus, IDisposable\\n{\\n// Member\", \" objects and other methods ...\\n// ...\\npublic void Publish(IntegrationEvent @event)\\n{\\nvar eventName =\", \" @event.GetType().Name;\\nvar factory = new ConnectionFactory() { HostName = _connectionString };\\nusin\", \"g (var connection = factory.CreateConnection())\\nusing (var channel = connection.CreateModel())\\n139 C\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications{\\nchanne\", \"l.ExchangeDeclare(exchange: _brokerName,\\ntype: \\\"direct\\\");\\nstring message = JsonConvert.SerializeObje\", \"ct(@event);\\nvar body = Encoding.UTF8.GetBytes(message);\\nchannel.BasicPublish(exchange: _brokerName,\\n\", \"routingKey: eventName,\\nbasicProperties: null,\\nbody: body);\\n}\\n}\\n}\\nThe actual code of the Publish meth\", \"od in the eShopOnContainers application is improved by using a\\nPolly retry policy, which retries the\", \" task some times in case the RabbitMQ container is not ready. This\\nscenario can occur when docker-co\", \"mpose is starting the containers; for example, the RabbitMQ\\ncontainer might start more slowly than t\", \"he other containers.\\nAs mentioned earlier, there are many possible configurations in RabbitMQ, so th\", \"is code should be\\nused only for dev/test environments.\\nImplementing the subscription code with the R\", \"abbitMQ API\\nAs with the publish code, the following code is a simplification of part of the event bu\", \"s\\nimplementation for RabbitMQ. Again, you usually do not need to change it unless you are improving\\n\", \"it.\\npublic class EventBusRabbitMQ : IEventBus, IDisposable\\n{\\n// Member objects and other methods ...\", \"\\n// ...\\npublic void Subscribe<T, TH>()\\nwhere T : IntegrationEvent\\nwhere TH : IIntegrationEventHandle\", \"r<T>\\n{\\nvar eventName = _subsManager.GetEventKey<T>();\\nvar containsKey = _subsManager.HasSubscription\", \"sForEvent(eventName);\\nif (!containsKey)\\n{\\nif (!_persistentConnection.IsConnected)\\n{\\n_persistentConne\", \"ction.TryConnect();\\n}\\nusing (var channel = _persistentConnection.CreateModel())\\n{\\nchannel.QueueBind(\", \"queue: _queueName,\\nexchange: BROKER_NAME,\\nroutingKey: eventName);\\n}\\n}\\n_subsManager.AddSubscription<T\", \", TH>();\\n}\\n}\\n140 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plicationsEach event type has a related channel to get events from RabbitMQ. You can then have as ma\", \"ny event\\nhandlers per channel and event type as needed.\\nThe Subscribe method accepts an IIntegration\", \"EventHandler object, which is like a callback method in\\nthe current microservice, plus its related I\", \"ntegrationEvent object. The code then adds that event\\nhandler to the list of event handlers that eac\", \"h integration event type can have per client microservice.\\nIf the client code has not already been s\", \"ubscribed to the event, the code creates a channel for the\\nevent type so it can receive events in a \", \"push style from RabbitMQ when that event is published from\\nany other service.\\nAs mentioned above, th\", \"e event bus implemented in eShopOnContainers has only an educational\\npurpose, since it only handles \", \"the main scenarios, so it\\u2019s not ready for production.\\nFor production scenarios check the additional \", \"resources below, specific for RabbitMQ, and the\\nImplementing event-based communication between micro\", \"services section.\\nAdditional resources\\nA production-ready solution with support for RabbitMQ.\\n\\u2022 NSer\", \"viceBus - Fully-supported commercial service bus with advanced management and\\nmonitoring tooling for\", \" .NET\\nhttps://particular.net/\\n\\u2022 EasyNetQ - Open Source .NET API client for RabbitMQ\\nhttps://easynetq\", \".com/\\n\\u2022 MassTransit - Free, open-source distributed application framework for .NET\\nhttps://masstrans\", \"it-project.com/\\n\\u2022 Rebus - Open source .NET Service Bus\\nhttps://github.com/rebus-org/Rebus\\nSubscribin\", \"g to events\\nThe first step for using the event bus is to subscribe the microservices to the events t\", \"hey want to\\nreceive. That functionality should be done in the receiver microservices.\\nThe following \", \"simple code shows what each receiver microservice needs to implement when starting\\nthe service (that\", \" is, in the Startup class) so it subscribes to the events it needs. In this case, the basket-\\napi mi\", \"croservice needs to subscribe to ProductPriceChangedIntegrationEvent and the\\nOrderStartedIntegration\", \"Event messages.\\nFor instance, when subscribing to the ProductPriceChangedIntegrationEvent event, tha\", \"t makes the\\nbasket microservice aware of any changes to the product price and lets it warn the user \", \"about the\\nchange if that product is in the user\\u2019s basket.\\nvar eventBus = app.ApplicationServices.Get\", \"RequiredService<IEventBus>();\\neventBus.Subscribe<ProductPriceChangedIntegrationEvent,\\n141 CHAPTER 5 \", \"| Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsProductPriceChang\", \"edIntegrationEventHandler>();\\neventBus.Subscribe<OrderStartedIntegrationEvent,\\nOrderStartedIntegrati\", \"onEventHandler>();\\nAfter this code runs, the subscriber microservice will be listening through Rabbi\", \"tMQ channels. When\\nany message of type ProductPriceChangedIntegrationEvent arrives, the code invokes\", \" the event\\nhandler that is passed to it and processes the event.\\nPublishing events through the event\", \" bus\\nFinally, the message sender (origin microservice) publishes the integration events with code si\", \"milar to\\nthe following example. (This approach is a simplified example that does not take atomicity \", \"into\\naccount.) You would implement similar code whenever an event must be propagated across multiple\", \"\\nmicroservices, usually right after committing data or transactions from the origin microservice.\\nFi\", \"rst, the event bus implementation object (based on RabbitMQ or based on a service bus) would be\\ninje\", \"cted at the controller constructor, as in the following code:\\n[Route(\\\"api/v1/[controller]\\\")]\\npublic \", \"class CatalogController : ControllerBase\\n{\\nprivate readonly CatalogContext _context;\\nprivate readonl\", \"y IOptionsSnapshot<Settings> _settings;\\nprivate readonly IEventBus _eventBus;\\npublic CatalogControll\", \"er(CatalogContext context,\\nIOptionsSnapshot<Settings> settings,\\nIEventBus eventBus)\\n{\\n_context = con\", \"text;\\n_settings = settings;\\n_eventBus = eventBus;\\n}\\n// ...\\n}\\nThen you use it from your controller\\u2019s \", \"methods, like in the UpdateProduct method:\\n[Route(\\\"items\\\")]\\n[HttpPost]\\npublic async Task<IActionResu\", \"lt> UpdateProduct([FromBody]CatalogItem product)\\n{\\nvar item = await _context.CatalogItems.SingleOrDe\", \"faultAsync(\\ni => i.Id == product.Id);\\n// ...\\nif (item.Price != product.Price)\\n{\\nvar oldPrice = item.\", \"Price;\\nitem.Price = product.Price;\\n_context.CatalogItems.Update(item);\\nvar @event = new ProductPrice\", \"ChangedIntegrationEvent(item.Id,\\nitem.Price,\\noldPrice);\\n// Commit changes in original transaction\\naw\", \"ait _context.SaveChangesAsync();\\n// Publish integration event to the event bus\\n// (RabbitMQ or a ser\", \"vice bus underneath)\\n142 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based\", \" .NET Applications_eventBus.Publish(@event);\\n// ...\\n}\\n// ...\\n}\\nIn this case, since the origin micros\", \"ervice is a simple CRUD microservice, that code is placed right into\\na Web API controller.\\nIn more a\", \"dvanced microservices, like when using CQRS approaches, it can be implemented in the\\nCommandHandler \", \"class, within the Handle() method.\\nDesigning atomicity and resiliency when publishing to the event b\", \"us\\nWhen you publish integration events through a distributed messaging system like your event bus, y\", \"ou\\nhave the problem of atomically updating the original database and publishing an event (that is, e\", \"ither\\nboth operations complete or none of them). For instance, in the simplified example shown earli\", \"er, the\\ncode commits data to the database when the product price is changed and then publishes a\\nPro\", \"ductPriceChangedIntegrationEvent message. Initially, it might look essential that these two\\noperatio\", \"ns be performed atomically. However, if you are using a distributed transaction involving the\\ndataba\", \"se and the message broker, as you do in older systems like Microsoft Message Queuing\\n(MSMQ), this ap\", \"proach is not recommended for the reasons described by the CAP theorem.\\nBasically, you use microserv\", \"ices to build scalable and highly available systems. Simplifying somewhat,\\nthe CAP theorem says that\", \" you cannot build a (distributed) database (or a microservice that owns its\\nmodel) that\\u2019s continuall\", \"y available, strongly consistent, and tolerant to any partition. You must choose\\ntwo of these three \", \"properties.\\nIn microservices-based architectures, you should choose availability and tolerance, and \", \"you should\\nde-emphasize strong consistency. Therefore, in most modern microservice-based application\", \"s, you\\nusually do not want to use distributed transactions in messaging, as you do when you implemen\", \"t\\ndistributed transactions based on the Windows Distributed Transaction Coordinator (DTC) with\\nMSMQ.\", \"\\nLet\\u2019s go back to the initial issue and its example. If the service crashes after the database is up\", \"dated\\n(in this case, right after the line of code with _context.SaveChangesAsync()), but before the \", \"integration\\nevent is published, the overall system could become inconsistent. This approach might be\", \" business\\ncritical, depending on the specific business operation you are dealing with.\\nAs mentioned \", \"earlier in the architecture section, you can have several approaches for dealing with this\\nissue:\\n\\u2022 \", \"Using the full Event Sourcing pattern.\\n\\u2022 Using transaction log mining.\\n\\u2022 Using the Outbox pattern. T\", \"his is a transactional table to store the integration events\\n(extending the local transaction).\\nFor \", \"this scenario, using the full Event Sourcing (ES) pattern is one of the best approaches, if not the\\n\", \"best. However, in many application scenarios, you might not be able to implement a full ES system. E\", \"S\\nmeans storing only domain events in your transactional database, instead of storing current state\\n\", \"143 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsdat\", \"a. Storing only domain events can have great benefits, such as having the history of your system\\nava\", \"ilable and being able to determine the state of your system at any moment in the past. However,\\nimpl\", \"ementing a full ES system requires you to rearchitect most of your system and introduces many\\nother \", \"complexities and requirements. For example, you would want to use a database specifically\\nmade for e\", \"vent sourcing, such as Event Store, or a document-oriented database such as Azure\\nCosmos DB, MongoDB\", \", Cassandra, CouchDB, or RavenDB. ES is a great approach for this problem, but\\nnot the easiest solut\", \"ion unless you are already familiar with event sourcing.\\nThe option to use transaction log mining in\", \"itially looks transparent. However, to use this approach,\\nthe microservice has to be coupled to your\", \" RDBMS transaction log, such as the SQL Server transaction\\nlog. This approach is probably not desira\", \"ble. Another drawback is that the low-level updates recorded\\nin the transaction log might not be at \", \"the same level as your high-level integration events. If so, the\\nprocess of reverse-engineering thos\", \"e transaction log operations can be difficult.\\nA balanced approach is a mix of a transactional datab\", \"ase table and a simplified ES pattern. You can\\nuse a state such as \\u201cready to publish the event,\\u201d whi\", \"ch you set in the original event when you commit\\nit to the integration events table. You then try to\", \" publish the event to the event bus. If the publish-\\nevent action succeeds, you start another transa\", \"ction in the origin service and move the state from\\n\\u201cready to publish the event\\u201d to \\u201cevent already p\", \"ublished.\\u201d\\nIf the publish-event action in the event bus fails, the data still will not be inconsiste\", \"nt within the origin\\nmicroservice\\u2014it is still marked as \\u201cready to publish the event,\\u201d and with respe\", \"ct to the rest of the\\nservices, it will eventually be consistent. You can always have background job\", \"s checking the state of\\nthe transactions or integration events. If the job finds an event in the \\u201cre\", \"ady to publish the event\\u201d\\nstate, it can try to republish that event to the event bus.\\nNotice that wi\", \"th this approach, you are persisting only the integration events for each origin\\nmicroservice, and o\", \"nly the events that you want to communicate to other microservices or external\\nsystems. In contrast,\", \" in a full ES system, you store all domain events as well.\\nTherefore, this balanced approach is a si\", \"mplified ES system. You need a list of integration events with\\ntheir current state (\\u201cready to publis\", \"h\\u201d versus \\u201cpublished\\u201d). But you only need to implement these\\nstates for the integration events. And \", \"in this approach, you do not need to store all your domain data\\nas events in the transactional datab\", \"ase, as you would in a full ES system.\\nIf you are already using a relational database, you can use a\", \" transactional table to store integration\\nevents. To achieve atomicity in your application, you use \", \"a two-step process based on local\\ntransactions. Basically, you have an IntegrationEvent table in the\", \" same database where you have your\\ndomain entities. That table works as an insurance for achieving a\", \"tomicity so that you include persisted\\nintegration events into the same transactions that are commit\", \"ting your domain data.\\nStep by step, the process goes like this:\\n1. The application begins a local d\", \"atabase transaction.\\n2. It then updates the state of your domain entities and inserts an event into \", \"the integration\\nevent table.\\n3. Finally, it commits the transaction, so you get the desired atomicit\", \"y and then\\n144 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appl\", \"ications4. You publish the event somehow (next).\\nWhen implementing the steps of publishing the event\", \"s, you have these choices:\\n\\u2022 Publish the integration event right after committing the transaction an\", \"d use another local\\ntransaction to mark the events in the table as being published. Then, use the ta\", \"ble just as an\\nartifact to track the integration events in case of issues in the remote microservice\", \"s, and\\nperform compensatory actions based on the stored integration events.\\n\\u2022 Use the table as a kin\", \"d of queue. A separate application thread or process queries the\\nintegration event table, publishes \", \"the events to the event bus, and then uses a local\\ntransaction to mark the events as published.\\nFigu\", \"re 6-22 shows the architecture for the first of these approaches.\\nFigure 6-22. Atomicity when publis\", \"hing events to the event bus\\nThe approach illustrated in Figure 6-22 is missing an additional worker\", \" microservice that is in charge\\nof checking and confirming the success of the published integration \", \"events. In case of failure, that\\nadditional checker worker microservice can read events from the tab\", \"le and republish them, that is,\\nrepeat step number 2.\\nAbout the second approach: you use the EventLo\", \"g table as a queue and always use a worker\\nmicroservice to publish the messages. In that case, the p\", \"rocess is like that shown in Figure 6-23. This\\nshows an additional microservice, and the table is th\", \"e single source when publishing events.\\n145 CHAPTER 5 | Designing and Developing Multi-Container and\", \" Microservice-Based .NET ApplicationsFigure 6-23. Atomicity when publishing events to the event bus \", \"with a worker microservice\\nFor simplicity, the eShopOnContainers sample uses the first approach (wit\", \"h no additional processes or\\nchecker microservices) plus the event bus. However, the eShopOnContaine\", \"rs sample is not handling\\nall possible failure cases. In a real application deployed to the cloud, y\", \"ou must embrace the fact that\\nissues will arise eventually, and you must implement that check and re\", \"send logic. Using the table as a\\nqueue can be more effective than the first approach if you have tha\", \"t table as a single source of events\\nwhen publishing them (with the worker) through the event bus.\\nI\", \"mplementing atomicity when publishing integration events through the event\\nbus\\nThe following code sh\", \"ows how you can create a single transaction involving multiple DbContext\\nobjects\\u2014one context related\", \" to the original data being updated, and the second context related to\\nthe IntegrationEventLog table\", \".\\nThe transaction in the example code below will not be resilient if connections to the database hav\", \"e\\nany issue at the time when the code is running. This can happen in cloud-based systems like Azure\\n\", \"SQL DB, which might move databases across servers. For implementing resilient transactions across\\nmu\", \"ltiple contexts, see the Implementing resilient Entity Framework Core SQL connections section later\\n\", \"in this guide.\\nFor clarity, the following example shows the whole process in a single piece of code.\", \" However, the\\neShopOnContainers implementation is refactored and splits this logic into multiple cla\", \"sses so it\\u2019s\\neasier to maintain.\\n// Update Product from the Catalog microservice\\n//\\npublic async Tas\", \"k<IActionResult> UpdateProduct([FromBody]CatalogItem productToUpdate)\\n{\\nvar catalogItem =\\nawait _cat\", \"alogContext.CatalogItems.SingleOrDefaultAsync(i => i.Id ==\\nproductToUpdate.Id);\\n146 CHAPTER 5 | Desi\", \"gning and Developing Multi-Container and Microservice-Based .NET Applicationsif (catalogItem == null\", \") return NotFound();\\nbool raiseProductPriceChangedEvent = false;\\nIntegrationEvent priceChangedEvent \", \"= null;\\nif (catalogItem.Price != productToUpdate.Price)\\nraiseProductPriceChangedEvent = true;\\nif (ra\", \"iseProductPriceChangedEvent) // Create event if price has changed\\n{\\nvar oldPrice = catalogItem.Price\", \";\\npriceChangedEvent = new ProductPriceChangedIntegrationEvent(catalogItem.Id,\\nproductToUpdate.Price,\", \"\\noldPrice);\\n}\\n// Update current product\\ncatalogItem = productToUpdate;\\n// Just save the updated prod\", \"uct if the Product's Price hasn't changed.\\nif (!raiseProductPriceChangedEvent)\\n{\\nawait _catalogConte\", \"xt.SaveChangesAsync();\\n}\\nelse // Publish to event bus only if product price changed\\n{\\n// Achieving a\", \"tomicity between original DB and the IntegrationEventLog\\n// with a local transaction\\nusing (var tran\", \"saction = _catalogContext.Database.BeginTransaction())\\n{\\n_catalogContext.CatalogItems.Update(catalog\", \"Item);\\nawait _catalogContext.SaveChangesAsync();\\nawait _integrationEventLogService.SaveEventAsync(pr\", \"iceChangedEvent);\\ntransaction.Commit();\\n}\\n// Publish the integration event through the event bus\\n_ev\", \"entBus.Publish(priceChangedEvent);\\n_integrationEventLogService.MarkEventAsPublishedAsync(\\npriceChang\", \"edEvent);\\n}\\nreturn Ok();\\n}\\nAfter the ProductPriceChangedIntegrationEvent integration event is create\", \"d, the transaction that\\nstores the original domain operation (update the catalog item) also includes\", \" the persistence of the\\nevent in the EventLog table. This makes it a single transaction, and you wil\", \"l always be able to check\\nwhether event messages were sent.\\nThe event log table is updated atomicall\", \"y with the original database operation, using a local\\ntransaction against the same database. If any \", \"of the operations fail, an exception is thrown and the\\ntransaction rolls back any completed operatio\", \"n, thus maintaining consistency between the domain\\noperations and the event messages saved to the ta\", \"ble.\\n147 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicatio\", \"nsReceiving messages from subscriptions: event handlers in receiver microservices\\nIn addition to the\", \" event subscription logic, you need to implement the internal code for the\\nintegration event handler\", \"s (like a callback method). The event handler is where you specify where the\\nevent messages of a cer\", \"tain type will be received and processed.\\nAn event handler first receives an event instance from the\", \" event bus. Then it locates the component to\\nbe processed related to that integration event, propaga\", \"ting and persisting the event as a change in\\nstate in the receiver microservice. For example, if a P\", \"roductPriceChanged event originates in the\\ncatalog microservice, it is handled in the basket microse\", \"rvice and changes the state in this receiver\\nbasket microservice as well, as shown in the following \", \"code.\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.IntegrationEvents.EventHandling\\n{\\npu\", \"blic class ProductPriceChangedIntegrationEventHandler :\\nIIntegrationEventHandler<ProductPriceChanged\", \"IntegrationEvent>\\n{\\nprivate readonly IBasketRepository _repository;\\npublic ProductPriceChangedIntegr\", \"ationEventHandler(\\nIBasketRepository repository)\\n{\\n_repository = repository;\\n}\\npublic async Task Han\", \"dle(ProductPriceChangedIntegrationEvent @event)\\n{\\nvar userIds = await _repository.GetUsers();\\nforeac\", \"h (var id in userIds)\\n{\\nvar basket = await _repository.GetBasket(id);\\nawait UpdatePriceInBasketItems\", \"(@event.ProductId, @event.NewPrice, basket);\\n}\\n}\\nprivate async Task UpdatePriceInBasketItems(int pro\", \"ductId, decimal newPrice,\\nCustomerBasket basket)\\n{\\nvar itemsToUpdate = basket?.Items?.Where(x => int\", \".Parse(x.ProductId) ==\\nproductId).ToList();\\nif (itemsToUpdate != null)\\n{\\nforeach (var item in itemsT\", \"oUpdate)\\n{\\nif(item.UnitPrice != newPrice)\\n{\\nvar originalPrice = item.UnitPrice;\\nitem.UnitPrice = new\", \"Price;\\nitem.OldUnitPrice = originalPrice;\\n}\\n}\\nawait _repository.UpdateBasket(basket);\\n}\\n}\\n}\\n}\\n148 CH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsThe event\", \" handler needs to verify whether the product exists in any of the basket instances. It also\\nupdates \", \"the item price for each related basket line item. Finally, it creates an alert to be displayed to\\nth\", \"e user about the price change, as shown in Figure 6-24.\\nFigure 6-24. Displaying an item price change\", \" in a basket, as communicated by integration events\\nIdempotency in update message events\\nAn importan\", \"t aspect of update message events is that a failure at any point in the communication\\nshould cause t\", \"he message to be retried. Otherwise a background task might try to publish an event\\nthat has already\", \" been published, creating a race condition. Make sure that the updates are either\\nidempotent or that\", \" they provide enough information to ensure that you can detect a duplicate,\\ndiscard it, and send bac\", \"k only one response.\\nAs noted earlier, idempotency means that an operation can be performed multiple\", \" times without\\nchanging the result. In a messaging environment, as when communicating events, an eve\", \"nt is\\nidempotent if it can be delivered multiple times without changing the result for the receiver\\n\", \"microservice. This may be necessary because of the nature of the event itself, or because of the way\", \"\\nthe system handles the event. Message idempotency is important in any application that uses\\nmessagi\", \"ng, not just in applications that implement the event bus pattern.\\nAn example of an idempotent opera\", \"tion is a SQL statement that inserts data into a table only if that\\ndata is not already in the table\", \". It does not matter how many times you run that insert SQL statement;\\nthe result will be the same\\u2014t\", \"he table will contain that data. Idempotency like this can also be\\nnecessary when dealing with messa\", \"ges if the messages could potentially be sent and therefore\\n149 CHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applicationsprocessed more than once. For instance, if \", \"retry logic causes a sender to send exactly the same\\nmessage more than once, you need to make sure t\", \"hat it is idempotent.\\nIt is possible to design idempotent messages. For example, you can create an e\", \"vent that says \\u201cset the\\nproduct price to $25\\u201d instead of \\u201cadd $5 to the product price.\\u201d You could sa\", \"fely process the first\\nmessage any number of times and the result will be the same. That is not true\", \" for the second\\nmessage. But even in the first case, you might not want to process the first event, \", \"because the system\\ncould also have sent a newer price-change event and you would be overwriting the \", \"new price.\\nAnother example might be an order-completed event that\\u2019s propagated to multiple subscribe\", \"rs. The\\napp has to make sure that order information is updated in other systems only once, even if t\", \"here are\\nduplicated message events for the same order-completed event.\\nIt is convenient to have some\", \" kind of identity per event so that you can create logic that enforces that\\neach event is processed \", \"only once per receiver.\\nSome message processing is inherently idempotent. For example, if a system g\", \"enerates image\\nthumbnails, it might not matter how many times the message about the generated thumbn\", \"ail is\\nprocessed; the outcome is that the thumbnails are generated and they are the same every time.\", \" On\\nthe other hand, operations such as calling a payment gateway to charge a credit card may not be\\n\", \"idempotent at all. In these cases, you need to ensure that processing a message multiple times has\\nt\", \"he effect that you expect.\\nAdditional resources\\n\\u2022 Honoring message idempotency\\nhttps://learn.microso\", \"ft.com/previous-versions/msp-n-p/jj591565(v=pandp.10)#honoring-\\nmessage-idempotency\\nDeduplicating in\", \"tegration event messages\\nYou can make sure that message events are sent and processed only once per \", \"subscriber at different\\nlevels. One way is to use a deduplication feature offered by the messaging i\", \"nfrastructure you are\\nusing. Another is to implement custom logic in your destination microservice. \", \"Having validations at\\nboth the transport level and the application level is your best bet.\\nDeduplica\", \"ting message events at the EventHandler level\\nOne way to make sure that an event is processed only o\", \"nce by any receiver is by implementing certain\\nlogic when processing the message events in event han\", \"dlers. For example, that is the approach used\\nin the eShopOnContainers application, as you can see i\", \"n the source code of the\\nUserCheckoutAcceptedIntegrationEventHandler class when it receives a\\nUserCh\", \"eckoutAcceptedIntegrationEvent integration event. (In this case, the CreateOrderCommand is\\nwrapped w\", \"ith an IdentifiedCommand, using the eventMsg.RequestId as an identifier, before sending it\\nto the co\", \"mmand handler).\\n150 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" ApplicationsDeduplicating messages when using RabbitMQ\\nWhen intermittent network failures happen, m\", \"essages can be duplicated, and the message receiver\\nmust be ready to handle these duplicated message\", \"s. If possible, receivers should handle messages in\\nan idempotent way, which is better than explicit\", \"ly handling them with deduplication.\\nAccording to the RabbitMQ documentation, \\u201cIf a message is deliv\", \"ered to a consumer and then\\nrequeued (because it was not acknowledged before the consumer connection\", \" dropped, for example)\\nthen RabbitMQ will set the redelivered flag on it when it is delivered again \", \"(whether to the same\\nconsumer or a different one).\\nIf the \\u201credelivered\\u201d flag is set, the receiver mu\", \"st take that into account, because the message might\\nalready have been processed. But that is not gu\", \"aranteed; the message might never have reached the\\nreceiver after it left the message broker, perhap\", \"s because of network issues. On the other hand, if the\\n\\u201credelivered\\u201d flag is not set, it is guarante\", \"ed that the message has not been sent more than once.\\nTherefore, the receiver needs to deduplicate m\", \"essages or process messages in an idempotent way\\nonly if the \\u201credelivered\\u201d flag is set in the messag\", \"e.\\nAdditional resources\\n\\u2022 Forked eShopOnContainers using NServiceBus (Particular Software)\\nhttps://g\", \"o.particular.net/eShopOnContainers\\n\\u2022 Event Driven Messaging\\nhttps://patterns.arcitura.com/soa-patter\", \"ns/design_patterns/event_driven_messaging\\n\\u2022 Jimmy Bogard. Refactoring Towards Resilience: Evaluating\", \" Coupling\\nhttps://jimmybogard.com/refactoring-towards-resilience-evaluating-coupling/\\n\\u2022 Publish-Subs\", \"cribe channel\\nhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChann\", \"el.\\nhtml\\n\\u2022 Communicating Between Bounded Contexts\\nhttps://learn.microsoft.com/previous-versions/msp-\", \"n-p/jj591572(v=pandp.10)\\n\\u2022 Eventual Consistency\\nhttps://en.wikipedia.org/wiki/Eventual_consistency\\n\\u2022\", \" Philip Brown. Strategies for Integrating Bounded Contexts\\nhttps://www.culttt.com/2014/11/26/strateg\", \"ies-integrating-bounded-contexts/\\n\\u2022 Chris Richardson. Developing Transactional Microservices Using A\", \"ggregates, Event\\nSourcing and CQRS - Part 2\\nhttps://www.infoq.com/articles/microservices-aggregates-\", \"events-cqrs-part-2-richardson\\n\\u2022 Chris Richardson. Event Sourcing pattern\\nhttps://microservices.io/pa\", \"tterns/data/event-sourcing.html\\n\\u2022 Introducing Event Sourcing\\nhttps://learn.microsoft.com/previous-ve\", \"rsions/msp-n-p/jj591559(v=pandp.10)\\n151 CHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applications\\u2022 Event Store database. Official site.\\nhttps://geteventstore.com/\\n\\u2022\", \" Patrick Nommensen. Event-Driven Data Management for Microservices\\nhttps://dzone.com/articles/event-\", \"driven-data-management-for-microservices-1\\n\\u2022 The CAP Theorem\\nhttps://en.wikipedia.org/wiki/CAP_theor\", \"em\\n\\u2022 What is CAP Theorem?\\nhttps://www.quora.com/What-Is-CAP-Theorem-1\\n\\u2022 Data Consistency Primer\\nhttp\", \"s://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v=pandp.10)\\n\\u2022 Rick Saling. The CAP Theore\", \"m: Why \\u201cEverything is Different\\u201d with the Cloud and\\nInternet\\nhttps://learn.microsoft.com/archive/blo\", \"gs/rickatmicrosoft/the-cap-theorem-why-everything-\\nis-different-with-the-cloud-and-internet/\\n\\u2022 Eric \", \"Brewer. CAP Twelve Years Later: How the \\u201cRules\\u201d Have Changed\\nhttps://www.infoq.com/articles/cap-twel\", \"ve-years-later-how-the-rules-have-changed\\n\\u2022 CAP, PACELC, and Microservices\\nhttps://ardalis.com/cap-p\", \"acelc-and-microservices/\\n\\u2022 Azure Service Bus. Brokered Messaging: Duplicate Detection\\nhttps://github\", \".com/microsoftarchive/msdn-code-gallery-\\nmicrosoft/tree/master/Windows%20Azure%20Product%20Team/Brok\", \"ered%20Messaging%20\\nDuplicate%20Detection\\n\\u2022 Reliability Guide (RabbitMQ documentation)\\nhttps://www.r\", \"abbitmq.com/reliability.html#consumer\\nTesting ASP.NET Core services and web apps\\nControllers are a c\", \"entral part of any ASP.NET Core API service and ASP.NET MVC Web application. As\\nsuch, you should hav\", \"e confidence they behave as intended for your application. Automated tests can\\nprovide you with this\", \" confidence and can detect errors before they reach production.\\nYou need to test how the controller \", \"behaves based on valid or invalid inputs, and test controller\\nresponses based on the result of the b\", \"usiness operation it performs. However, you should have these\\ntypes of tests for your microservices:\", \"\\n\\u2022 Unit tests. These tests ensure that individual components of the application work as expected.\\nAs\", \"sertions test the component API.\\n\\u2022 Integration tests. These tests ensure that component interactions\", \" work as expected against\\nexternal artifacts like databases. Assertions can test component API, UI, \", \"or the side effects of\\nactions like database I/O, logging, etc.\\n152 CHAPTER 5 | Designing and Develo\", \"ping Multi-Container and Microservice-Based .NET Applications\\u2022 Functional tests for each microservic\", \"e. These tests ensure that the application works as\\nexpected from the user\\u2019s perspective.\\n\\u2022 Service \", \"tests. These tests ensure that end-to-end service use cases, including testing multiple\\nservices at \", \"the same time, are tested. For this type of testing, you need to prepare the\\nenvironment first. In t\", \"his case, it means starting the services (for example, by using docker-\\ncompose up).\\nImplementing un\", \"it tests for ASP.NET Core Web APIs\\nUnit testing involves testing a part of an application in isolati\", \"on from its infrastructure and\\ndependencies. When you unit test controller logic, only the content o\", \"f a single action or method is\\ntested, not the behavior of its dependencies or of the framework itse\", \"lf. Unit tests do not detect issues\\nin the interaction between components\\u2014that is the purpose of int\", \"egration testing.\\nAs you unit test your controller actions, make sure you focus only on their behavi\", \"or. A controller unit\\ntest avoids things like filters, routing, or model binding (the mapping of req\", \"uest data to a ViewModel\\nor DTO). Because they focus on testing just one thing, unit tests are gener\", \"ally simple to write and\\nquick to run. A well-written set of unit tests can be run frequently withou\", \"t much overhead.\\nUnit tests are implemented based on test frameworks like xUnit.net, MSTest, Moq, or\", \" NUnit. For the\\neShopOnContainers sample application, we are using xUnit.\\nWhen you write a unit test\", \" for a Web API controller, you instantiate the controller class directly using\\nthe new keyword in C#\", \", so that the test will run as fast as possible. The following example shows how\\nto do this when usi\", \"ng xUnit as the Test framework.\\n[Fact]\\npublic async Task Get_order_detail_success()\\n{\\n//Arrange\\nvar \", \"fakeOrderId = \\\"12\\\";\\nvar fakeOrder = GetFakeOrder();\\n//...\\n//Act\\nvar orderController = new OrderContr\", \"oller(\\n_orderServiceMock.Object,\\n_basketServiceMock.Object,\\n_identityParserMock.Object);\\norderContro\", \"ller.ControllerContext.HttpContext = _contextMock.Object;\\nvar actionResult = await orderController.D\", \"etail(fakeOrderId);\\n//Assert\\nvar viewResult = Assert.IsType<ViewResult>(actionResult);\\nAssert.IsAssi\", \"gnableFrom<Order>(viewResult.ViewData.Model);\\n}\\n153 CHAPTER 5 | Designing and Developing Multi-Conta\", \"iner and Microservice-Based .NET ApplicationsImplementing integration and functional tests for each \", \"microservice\\nAs noted, integration tests and functional tests have different purposes and goals. How\", \"ever, the way\\nyou implement both when testing ASP.NET Core controllers is similar, so in this sectio\", \"n we\\nconcentrate on integration tests.\\nIntegration testing ensures that an application\\u2019s components \", \"function correctly when assembled.\\nASP.NET Core supports integration testing using unit test framewo\", \"rks and a built-in test web host that\\ncan be used to handle requests without network overhead.\\nUnlik\", \"e unit testing, integration tests frequently involve application infrastructure concerns, such as a\\n\", \"database, file system, network resources, or web requests and responses. Unit tests use fakes or moc\", \"k\\nobjects in place of these concerns. But the purpose of integration tests is to confirm that the sy\", \"stem\\nworks as expected with these systems, so for integration testing you do not use fakes or mock o\", \"bjects.\\nInstead, you include the infrastructure, like database access or service invocation from oth\", \"er services.\\nBecause integration tests exercise larger segments of code than unit tests, and because\", \" integration\\ntests rely on infrastructure elements, they tend to be orders of magnitude slower than \", \"unit tests. Thus,\\nit is a good idea to limit how many integration tests you write and run.\\nASP.NET C\", \"ore includes a built-in test web host that can be used to handle HTTP requests without\\nnetwork overh\", \"ead, meaning that you can run those tests faster than when using a real web host. The\\ntest web host \", \"(TestServer) is available in a NuGet component as Microsoft.AspNetCore.TestHost. It can\\nbe added to \", \"integration test projects and used to host ASP.NET Core applications.\\nAs you can see in the followin\", \"g code, when you create integration tests for ASP.NET Core controllers,\\nyou instantiate the controll\", \"ers through the test host. This functionality is comparable to an HTTP\\nrequest, but it runs faster.\\n\", \"public class PrimeWebDefaultRequestShould\\n{\\nprivate readonly TestServer _server;\\nprivate readonly Ht\", \"tpClient _client;\\npublic PrimeWebDefaultRequestShould()\\n{\\n// Arrange\\n_server = new TestServer(new We\", \"bHostBuilder()\\n.UseStartup<Startup>());\\n_client = _server.CreateClient();\\n}\\n[Fact]\\npublic async Task\", \" ReturnHelloWorld()\\n{\\n// Act\\nvar response = await _client.GetAsync(\\\"/\\\");\\nresponse.EnsureSuccessStatu\", \"sCode();\\nvar responseString = await response.Content.ReadAsStringAsync();\\n// Assert\\nAssert.Equal(\\\"He\", \"llo World!\\\", responseString);\\n}\\n}\\n154 CHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET ApplicationsAdditional resources\\n\\u2022 Steve Smith. Testing controllers (ASP.NET Core\", \")\\nhttps://learn.microsoft.com/aspnet/core/mvc/controllers/testing\\n\\u2022 Steve Smith. Integration testing\", \" (ASP.NET Core)\\nhttps://learn.microsoft.com/aspnet/core/test/integration-tests\\n\\u2022 Unit testing in .NE\", \"T using dotnet test\\nhttps://learn.microsoft.com/dotnet/core/testing/unit-testing-with-dotnet-test\\n\\u2022 \", \"xUnit.net. Official site.\\nhttps://xunit.net/\\n\\u2022 Unit Test Basics.\\nhttps://learn.microsoft.com/visuals\", \"tudio/test/unit-test-basics\\n\\u2022 Moq. GitHub repo.\\nhttps://github.com/moq/moq\\n\\u2022 NUnit. Official site.\\nh\", \"ttps://nunit.org/\\nImplementing service tests on a multi-container application\\nAs noted earlier, when\", \" you test multi-container applications, all the microservices need to be running\\nwithin the Docker h\", \"ost or container cluster. End-to-end service tests that include multiple operations\\ninvolving severa\", \"l microservices require you to deploy and start the whole application in the Docker\\nhost by running \", \"docker-compose up (or a comparable mechanism if you are using an orchestrator).\\nOnce the whole appli\", \"cation and all its services is running, you can execute end-to-end integration and\\nfunctional tests.\", \"\\nThere are a few approaches you can use. In the docker-compose.yml file that you use to deploy the\\na\", \"pplication at the solution level you can expand the entry point to use dotnet test. You can also use\", \"\\nanother compose file that would run your tests in the image you are targeting. By using another\\ncom\", \"pose file for integration tests that includes your microservices and databases on containers, you\\nca\", \"n make sure that the related data is always reset to its original state before running the tests.\\nOn\", \"ce the compose application is up and running, you can take advantage of breakpoints and\\nexceptions i\", \"f you are running Visual Studio. Or you can run the integration tests automatically in your\\nCI pipel\", \"ine in Azure DevOps Services or any other CI/CD system that supports Docker containers.\\nTesting in e\", \"ShopOnContainers\\nThe reference application (eShopOnContainers) tests were recently restructured and \", \"now there are\\nfour categories:\\n1. Unit tests, just plain old regular unit tests, contained in the {M\", \"icroserviceName}.UnitTests\\nprojects\\n155 CHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applications2. Microservice functional/integration tests, with test cases invol\", \"ving the infrastructure for\\neach microservice but isolated from the others and are contained in the\\n\", \"{MicroserviceName}.FunctionalTests projects.\\n3. Application functional/integration tests, which focu\", \"s on microservices integration, with test\\ncases that exert several microservices. These tests are lo\", \"cated in project\\nApplication.FunctionalTests.\\nWhile unit and integration tests are organized in a te\", \"st folder within the microservice project,\\napplication and load tests are managed separately under t\", \"he root folder, as shown in Figure 6-25.\\nFigure 6-25. Test folder structure in eShopOnContainers\\nMic\", \"roservice and Application functional/integration tests are run from Visual Studio, using the regular\", \"\\ntests runner, but first you need to start the required infrastructure services, with a set of docke\", \"r-\\ncompose files contained in the solution test folder:\\ndocker-compose-test.yml\\nversion: '3.4'\\nservi\", \"ces:\\nredis.data:\\nimage: redis:alpine\\nrabbitmq:\\nimage: rabbitmq:3-management-alpine\\nsqldata:\\n156 CHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsimage: mcr.\", \"microsoft.com/mssql/server:2017-latest\\nnosqldata:\\nimage: mongo\\ndocker-compose-test.override.yml\\nvers\", \"ion: '3.4'\\nservices:\\nredis.data:\\nports:\\n- \\\"6379:6379\\\"\\nrabbitmq:\\nports:\\n- \\\"15672:15672\\\"\\n- \\\"5672:5672\\\"\", \"\\nsqldata:\\nenvironment:\\n- SA_PASSWORD=Pass@word\\n- ACCEPT_EULA=Y\\nports:\\n- \\\"5433:1433\\\"\\nnosqldata:\\nports\", \":\\n- \\\"27017:27017\\\"\\nSo, to run the functional/integration tests you must first run this command, from \", \"the solution test\\nfolder:\\ndocker-compose -f docker-compose-test.yml -f docker-compose-test.override.\", \"yml up\\nAs you can see, these docker-compose files only start the Redis, RabbitMQ, SQL Server, and Mo\", \"ngoDB\\nmicroservices.\\nAdditional resources\\n\\u2022 Unit & Integration testing on the eShopOnContainers\\nhttp\", \"s://github.com/dotnet-architecture/eShopOnContainers/wiki/Unit-and-integration-\\ntesting\\n\\u2022 Load testi\", \"ng on the eShopOnContainers\\nhttps://github.com/dotnet-architecture/eShopOnContainers/wiki/Load-testi\", \"ng\\nImplement background tasks in microservices with\\nIHostedService and the BackgroundService class\\nB\", \"ackground tasks and scheduled jobs are something you might need to use in any application,\\nwhether o\", \"r not it follows the microservices architecture pattern. The difference when using a\\nmicroservices a\", \"rchitecture is that you can implement the background task in a separate\\nprocess/container for hostin\", \"g so you can scale it down/up based on your need.\\n157 CHAPTER 5 | Designing and Developing Multi-Con\", \"tainer and Microservice-Based .NET ApplicationsFrom a generic point of view, in .NET we called these\", \" type of tasks Hosted Services, because they are\\nservices/logic that you host within your host/appli\", \"cation/microservice. Note that in this case, the\\nhosted service simply means a class with the backgr\", \"ound task logic.\\nSince .NET Core 2.0, the framework provides a new interface named IHostedService he\", \"lping you to\\neasily implement hosted services. The basic idea is that you can register multiple back\", \"ground tasks\\n(hosted services) that run in the background while your web host or host is running, as\", \" shown in the\\nimage 6-26.\\nFigure 6-26. Using IHostedService in a WebHost vs. a Host\\nASP.NET Core 1.x\", \" and 2.x support IWebHost for background processes in web apps. .NET Core 2.1 and\\nlater versions sup\", \"port IHost for background processes with plain console apps. Note the difference\\nmade between WebHos\", \"t and Host.\\nA WebHost (base class implementing IWebHost) in ASP.NET Core 2.0 is the infrastructure a\", \"rtifact you\\nuse to provide HTTP server features to your process, such as when you\\u2019re implementing an\", \" MVC web\\napp or Web API service. It provides all the new infrastructure goodness in ASP.NET Core, en\", \"abling you\\nto use dependency injection, insert middlewares in the request pipeline, and similar. The\", \" WebHost\\nuses these very same IHostedServices for background tasks.\\nA Host (base class implementing \", \"IHost) was introduced in .NET Core 2.1. Basically, a Host allows you\\nto have a similar infrastructur\", \"e than what you have with WebHost (dependency injection, hosted\\nservices, etc.), but in this case, y\", \"ou just want to have a simple and lighter process as the host, with\\nnothing related to MVC, Web API \", \"or HTTP server features.\\nTherefore, you can choose and either create a specialized host-process with\", \" IHost to handle the\\nhosted services and nothing else, such a microservice made just for hosting the\", \" IHostedServices, or\\nyou can alternatively extend an existing ASP.NET Core WebHost, such as an exist\", \"ing ASP.NET Core\\nWeb API or MVC app.\\n158 CHAPTER 5 | Designing and Developing Multi-Container and Mi\", \"croservice-Based .NET ApplicationsEach approach has pros and cons depending on your business and sca\", \"lability needs. The bottom line\\nis basically that if your background tasks have nothing to do with H\", \"TTP (IWebHost) you should use\\nIHost.\\nRegistering hosted services in your WebHost or Host\\nLet\\u2019s drill\", \" down further on the IHostedService interface since its usage is pretty similar in a WebHost or\\nin a\", \" Host.\\nSignalR is one example of an artifact using hosted services, but you can also use it for much\", \" simpler\\nthings like:\\n\\u2022 A background task polling a database looking for changes.\\n\\u2022 A scheduled task\", \" updating some cache periodically.\\n\\u2022 An implementation of QueueBackgroundWorkItem that allows a task\", \" to be executed on a\\nbackground thread.\\n\\u2022 Processing messages from a message queue in the background\", \" of a web app while sharing\\ncommon services such as ILogger.\\n\\u2022 A background task started with Task.R\", \"un().\\nYou can basically offload any of those actions to a background task that implements IHostedSer\", \"vice.\\nThe way you add one or multiple IHostedServices into your WebHost or Host is by registering th\", \"em\\nup through the AddHostedService extension method in an ASP.NET Core WebHost (or in a Host in\\n.NET\", \" Core 2.1 and above). Basically, you have to register the hosted services within application startup\", \"\\nin Program.cs.\\n//Other DI registrations;\\n// Register Hosted Services\\nbuilder.Services.AddHostedServ\", \"ice<GracePeriodManagerService>();\\nbuilder.Services.AddHostedService<MyHostedServiceB>();\\nbuilder.Ser\", \"vices.AddHostedService<MyHostedServiceC>();\\n//...\\nIn that code, the GracePeriodManagerService hosted\", \" service is real code from the Ordering business\\nmicroservice in eShopOnContainers, while the other \", \"two are just two additional samples.\\nThe IHostedService background task execution is coordinated wit\", \"h the lifetime of the application (host\\nor microservice, for that matter). You register tasks when t\", \"he application starts and you have the\\nopportunity to do some graceful action or clean-up when the a\", \"pplication is shutting down.\\nWithout using IHostedService, you could always start a background threa\", \"d to run any task. The\\ndifference is precisely at the app\\u2019s shutdown time when that thread would sim\", \"ply be killed without\\nhaving the opportunity to run graceful clean-up actions.\\nThe IHostedService in\", \"terface\\nWhen you register an IHostedService, .NET calls the StartAsync() and StopAsync() methods of \", \"your\\nIHostedService type during application start and stop respectively. For more details, see\\nIHost\", \"edService interface.\\n159 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based\", \" .NET ApplicationsAs you can imagine, you can create multiple implementations of IHostedService and \", \"register each of\\nthem in Program.cs, as shown previously. All those hosted services will be started \", \"and stopped along\\nwith the application/microservice.\\nAs a developer, you are responsible for handlin\", \"g the stopping action of your services when\\nStopAsync() method is triggered by the host.\\nImplementin\", \"g IHostedService with a custom hosted service class\\nderiving from the BackgroundService base class\\nY\", \"ou could go ahead and create your custom hosted service class from scratch and implement the\\nIHosted\", \"Service, as you need to do when using .NET Core 2.0 and later.\\nHowever, since most background tasks \", \"will have similar needs in regard to the cancellation tokens\\nmanagement and other typical operations\", \", there is a convenient abstract base class you can derive\\nfrom, named BackgroundService (available \", \"since .NET Core 2.1).\\nThat class provides the main work needed to set up the background task.\\nThe ne\", \"xt code is the abstract BackgroundService base class as implemented in .NET.\\n// Copyright (c) .NET F\", \"oundation. Licensed under the Apache License, Version 2.0.\\n/// <summary>\\n/// Base class for implemen\", \"ting a long running <see cref=\\\"IHostedService\\\"/>.\\n/// </summary>\\npublic abstract class BackgroundSer\", \"vice : IHostedService, IDisposable\\n{\\nprivate Task _executingTask;\\nprivate readonly CancellationToken\", \"Source _stoppingCts =\\nnew CancellationTokenSource();\\nprotected abstract Task ExecuteAsync(Cancellati\", \"onToken stoppingToken);\\npublic virtual Task StartAsync(CancellationToken cancellationToken)\\n{\\n// Sto\", \"re the task we're executing\\n_executingTask = ExecuteAsync(_stoppingCts.Token);\\n// If the task is com\", \"pleted then return it,\\n// this will bubble cancellation and failure to the caller\\nif (_executingTask\", \".IsCompleted)\\n{\\nreturn _executingTask;\\n}\\n// Otherwise it's running\\nreturn Task.CompletedTask;\\n}\\npubl\", \"ic virtual async Task StopAsync(CancellationToken cancellationToken)\\n{\\n// Stop called without start\\n\", \"if (_executingTask == null)\\n{\\nreturn;\\n}\\n160 CHAPTER 5 | Designing and Developing Multi-Container and\", \" Microservice-Based .NET Applicationstry\\n{\\n// Signal cancellation to the executing method\\n_stoppingC\", \"ts.Cancel();\\n}\\nfinally\\n{\\n// Wait until the task completes or the stop token triggers\\nawait Task.When\", \"Any(_executingTask, Task.Delay(Timeout.Infinite,\\ncancellationToken));\\n}\\n}\\npublic virtual void Dispos\", \"e()\\n{\\n_stoppingCts.Cancel();\\n}\\n}\\nWhen deriving from the previous abstract base class, thanks to that\", \" inherited implementation, you just\\nneed to implement the ExecuteAsync() method in your own custom h\", \"osted service class, as in the\\nfollowing simplified code from eShopOnContainers which is polling a d\", \"atabase and publishing\\nintegration events into the Event Bus when needed.\\npublic class GracePeriodMa\", \"nagerService : BackgroundService\\n{\\nprivate readonly ILogger<GracePeriodManagerService> _logger;\\npriv\", \"ate readonly OrderingBackgroundSettings _settings;\\nprivate readonly IEventBus _eventBus;\\npublic Grac\", \"ePeriodManagerService(IOptions<OrderingBackgroundSettings> settings,\\nIEventBus eventBus,\\nILogger<Gra\", \"cePeriodManagerService> logger)\\n{\\n// Constructor's parameters validations...\\n}\\nprotected override as\", \"ync Task ExecuteAsync(CancellationToken stoppingToken)\\n{\\n_logger.LogDebug($\\\"GracePeriodManagerServic\", \"e is starting.\\\");\\nstoppingToken.Register(() =>\\n_logger.LogDebug($\\\" GracePeriod background task is st\", \"opping.\\\"));\\nwhile (!stoppingToken.IsCancellationRequested)\\n{\\n_logger.LogDebug($\\\"GracePeriod task doi\", \"ng background work.\\\");\\n// This eShopOnContainers method is querying a database table\\n// and publishi\", \"ng events into the Event Bus (RabbitMQ / ServiceBus)\\nCheckConfirmedGracePeriodOrders();\\ntry {\\nawait \", \"Task.Delay(_settings.CheckUpdateTime, stoppingToken);\\n}\\ncatch (TaskCanceledException exception) {\\n_l\", \"ogger.LogCritical(exception, \\\"TaskCanceledException Error\\\",\\nexception.Message);\\n161 CHAPTER 5 | Desi\", \"gning and Developing Multi-Container and Microservice-Based .NET Applications}\\n}\\n_logger.LogDebug($\\\"\", \"GracePeriod background task is stopping.\\\");\\n}\\n.../...\\n}\\nIn this specific case for eShopOnContainers,\", \" it\\u2019s executing an application method that\\u2019s querying a\\ndatabase table looking for orders with a spe\", \"cific state and when applying changes, it is publishing\\nintegration events through the event bus (un\", \"derneath it can be using RabbitMQ or Azure Service Bus).\\nOf course, you could run any other business\", \" background task, instead.\\nBy default, the cancellation token is set with a 5 seconds timeout, altho\", \"ugh you can change that value\\nwhen building your WebHost using the UseShutdownTimeout extension of t\", \"he IWebHostBuilder. This\\nmeans that our service is expected to cancel within 5 seconds otherwise it \", \"will be more abruptly killed.\\nThe following code would be changing that time to 10 seconds.\\nWebHost.\", \"CreateDefaultBuilder(args)\\n.UseShutdownTimeout(TimeSpan.FromSeconds(10))\\n...\\nSummary class diagram\\nT\", \"he following image shows a visual summary of the classes and interfaces involved when\\nimplementing I\", \"HostedServices.\\nFigure 6-27. Class diagram showing the multiple classes and interfaces related to IH\", \"ostedService\\nClass diagram: IWebHost and IHost can host many services, which inherit from Background\", \"Service,\\nwhich implements IHostedService.\\n162 CHAPTER 5 | Designing and Developing Multi-Container a\", \"nd Microservice-Based .NET ApplicationsDeployment considerations and takeaways\\nIt is important to no\", \"te that the way you deploy your ASP.NET Core WebHost or .NET Host might\\nimpact the final solution. F\", \"or instance, if you deploy your WebHost on IIS or a regular Azure App\\nService, your host can be shut\", \" down because of app pool recycles. But if you are deploying your host\\nas a container into an orches\", \"trator like Kubernetes, you can control the assured number of live\\ninstances of your host. In additi\", \"on, you could consider other approaches in the cloud especially made\\nfor these scenarios, like Azure\", \" Functions. Finally, if you need the service to be running all the time and\\nare deploying on a Windo\", \"ws Server you could use a Windows Service.\\nBut even for a WebHost deployed into an app pool, there a\", \"re scenarios like repopulating or flushing\\napplication\\u2019s in-memory cache that would be still applica\", \"ble.\\nThe IHostedService interface provides a convenient way to start background tasks in an ASP.NET \", \"Core\\nweb application (in .NET Core 2.0 and later versions) or in any process/host (starting in .NET \", \"Core 2.1\\nwith IHost). Its main benefit is the opportunity you get with the graceful cancellation to \", \"clean-up the\\ncode of your background tasks when the host itself is shutting down.\\nAdditional resourc\", \"es\\n\\u2022 Building a scheduled task in ASP.NET Core/Standard 2.0\\nhttps://blog.maartenballiauw.be/post/201\", \"7/08/01/building-a-scheduled-cache-updater-in-\\naspnet-core-2.html\\n\\u2022 Implementing IHostedService in A\", \"SP.NET Core 2.0\\nhttps://www.stevejgordon.co.uk/asp-net-core-2-ihostedservice\\n\\u2022 GenericHost Sample us\", \"ing ASP.NET Core 2.1\\nhttps://github.com/aspnet/Hosting/tree/release/2.1/samples/GenericHostSample\\nIm\", \"plement API Gateways with Ocelot\\nImportant\\nThe reference microservice application eShopOnContainers \", \"is currently using features provided by\\nEnvoy to implement the API Gateway instead of the earlier re\", \"ferenced Ocelot. We made this design\\nchoice because of Envoy\\u2019s built-in support for the WebSocket pr\", \"otocol, required by the new gRPC\\ninter-service communications implemented in eShopOnContainers. Howe\", \"ver, we\\u2019ve retained this\\nsection in the guide so you can consider Ocelot as a simple, capable, and l\", \"ightweight API Gateway\\nsuitable for production-grade scenarios. Also, latest Ocelot version contains\", \" a breaking change on its\\njson schema. Consider using Ocelot < v16.0.0, or use the key Routes instea\", \"d of ReRoutes.\\nArchitect and design your API Gateways\\nThe following architecture diagram shows how A\", \"PI Gateways were implemented with Ocelot in\\neShopOnContainers.\\n163 CHAPTER 5 | Designing and Develop\", \"ing Multi-Container and Microservice-Based .NET ApplicationsFigure 6-28. eShopOnContainers architect\", \"ure with API Gateways\\nThat diagram shows how the whole application is deployed into a single Docker \", \"host or development\\nPC with \\u201cDocker for Windows\\u201d or \\u201cDocker for Mac\\u201d. However, deploying into any or\", \"chestrator would\\nbe similar, but any container in the diagram could be scaled out in the orchestrato\", \"r.\\nIn addition, the infrastructure assets such as databases, cache, and message brokers should be\\nof\", \"floaded from the orchestrator and deployed into high available systems for infrastructure, like Azur\", \"e\\nSQL Database, Azure Cosmos DB, Azure Redis, Azure Service Bus, or any HA clustering solution on-\\np\", \"remises.\\nAs you can also notice in the diagram, having several API Gateways allows multiple developm\", \"ent\\nteams to be autonomous (in this case Marketing features vs. Shopping features) when developing a\", \"nd\\ndeploying their microservices plus their own related API Gateways.\\nIf you had a single monolithic\", \" API Gateway that would mean a single point to be updated by several\\ndevelopment teams, which could \", \"couple all the microservices with a single part of the application.\\nGoing much further in the design\", \", sometimes a fine-grained API Gateway can also be limited to a\\nsingle business microservice dependi\", \"ng on the chosen architecture. Having the API Gateway\\u2019s\\nboundaries dictated by the business or domai\", \"n will help you to get a better design.\\nFor instance, fine granularity in the API Gateway tier can b\", \"e especially useful for more advanced\\ncomposite UI applications that are based on microservices, bec\", \"ause the concept of a fine-grained API\\nGateway is similar to a UI composition service.\\nWe delve into\", \" more details in the previous section Creating composite UI based on microservices.\\nAs a key takeawa\", \"y, for many medium- and large-size applications, using a custom-built API Gateway\\nproduct is usually\", \" a good approach, but not as a single monolithic aggregator or unique central\\ncustom API Gateway unl\", \"ess that API Gateway allows multiple independent configuration areas for the\\nseveral development tea\", \"ms creating autonomous microservices.\\n164 CHAPTER 5 | Designing and Developing Multi-Container and M\", \"icroservice-Based .NET ApplicationsSample microservices/containers to reroute through the API Gatewa\", \"ys\\nAs an example, eShopOnContainers has around six internal microservice-types that have to be\\npubli\", \"shed through the API Gateways, as shown in the following image.\\nFigure 6-29. Microservice folders in\", \" eShopOnContainers solution in Visual Studio\\nAbout the Identity service, in the design it\\u2019s left out\", \" of the API Gateway routing because it\\u2019s the only\\ncross-cutting concern in the system, although with\", \" Ocelot it\\u2019s also possible to include it as part of the\\nrerouting lists.\\nAll those services are curr\", \"ently implemented as ASP.NET Core Web API services, as you can tell from\\nthe code. Let\\u2019s focus on on\", \"e of the microservices like the Catalog microservice code.\\nFigure 6-30. Sample Web API microservice \", \"(Catalog microservice)\\n165 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET ApplicationsYou can see that the Catalog microservice is a typical ASP.NET Core Web API proj\", \"ect with several\\ncontrollers and methods like in the following code.\\n[HttpGet]\\n[Route(\\\"items/{id:int\", \"}\\\")]\\n[ProducesResponseType((int)HttpStatusCode.BadRequest)]\\n[ProducesResponseType((int)HttpStatusCod\", \"e.NotFound)]\\n[ProducesResponseType(typeof(CatalogItem),(int)HttpStatusCode.OK)]\\npublic async Task<IA\", \"ctionResult> GetItemById(int id)\\n{\\nif (id <= 0)\\n{\\nreturn BadRequest();\\n}\\nvar item = await _catalogCo\", \"ntext.CatalogItems.\\nSingleOrDefaultAsync(ci => ci.Id == id);\\n//\\u2026\\nif (item != null)\\n{\\nreturn Ok(item)\", \";\\n}\\nreturn NotFound();\\n}\\nThe HTTP request will end up running that kind of C# code accessing the mic\", \"roservice database and\\nany additional required action.\\nRegarding the microservice URL, when the cont\", \"ainers are deployed in your local development PC\\n(local Docker host), each microservice\\u2019s container \", \"always has an internal port (usually port 80)\\nspecified in its dockerfile, as in the following docke\", \"rfile:\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base\\nWORKDIR /app\\nEXPOSE 80\\nThe port 80 shown in \", \"the code is internal within the Docker host, so it can\\u2019t be reached by client apps.\\nClient apps can \", \"access only the external ports (if any) published when deploying with docker-\\ncompose.\\nThose externa\", \"l ports shouldn\\u2019t be published when deploying to a production environment. For this\\nspecific reason,\", \" why you want to use the API Gateway, to avoid the direct communication between the\\nclient apps and \", \"the microservices.\\nHowever, when developing, you want to access the microservice/container directly \", \"and run it through\\nSwagger. That\\u2019s why in eShopOnContainers, the external ports are still specified \", \"even when they won\\u2019t\\nbe used by the API Gateway or the client apps.\\nHere\\u2019s an example of the docker-\", \"compose.override.yml file for the Catalog microservice:\\ncatalog-api:\\nenvironment:\\n- ASPNETCORE_ENVIR\", \"ONMENT=Development\\n- ASPNETCORE_URLS=http://0.0.0.0:80\\n- ConnectionString=YOUR_VALUE\\n- ... Other Env\", \"ironment Variables\\n166 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applicationsports:\\n- \\\"5101:80\\\" # Important: In a production environment you should remove the ex\", \"ternal\\nport (5101) kept here for microservice debugging purposes.\\n# The API Gateway redirects and ac\", \"cess through the internal port (80).\\nYou can see how in the docker-compose.override.yml configuratio\", \"n the internal port for the Catalog\\ncontainer is port 80, but the port for external access is 5101. \", \"But this port shouldn\\u2019t be used by the\\napplication when using an API Gateway, only to debug, run, an\", \"d test just the Catalog microservice.\\nNormally, you won\\u2019t be deploying with docker-compose into a pr\", \"oduction environment because the\\nright production deployment environment for microservices is an orc\", \"hestrator like Kubernetes or\\nService Fabric. When deploying to those environments you use different \", \"configuration files where you\\nwon\\u2019t publish directly any external port for the microservices but, yo\", \"u\\u2019ll always use the reverse proxy\\nfrom the API Gateway.\\nRun the catalog microservice in your local D\", \"ocker host. Either run the full eShopOnContainers solution\\nfrom Visual Studio (it runs all the servi\", \"ces in the docker-compose files), or start the Catalog\\nmicroservice with the following docker-compos\", \"e command in CMD or PowerShell positioned at the\\nfolder where the docker-compose.yml and docker-comp\", \"ose.override.yml are placed.\\ndocker-compose run --service-ports catalog-api\\nThis command only runs t\", \"he catalog-api service container plus dependencies that are specified in the\\ndocker-compose.yml. In \", \"this case, the SQL Server container and RabbitMQ container.\\nThen, you can directly access the Catalo\", \"g microservice and see its methods through the Swagger UI\\naccessing directly through that \\u201cexternal\\u201d\", \" port, in this case http://host.docker.internal:5101/swagger:\\n167 CHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET ApplicationsFigure 6-31. Testing the Catalog microser\", \"vice with its Swagger UI\\nAt this point, you could set a breakpoint in C# code in Visual Studio, test\", \" the microservice with the\\nmethods exposed in Swagger UI, and finally clean-up everything with the d\", \"ocker-compose down\\ncommand.\\nHowever, direct-access communication to the microservice, in this case t\", \"hrough the external port\\n5101, is precisely what you want to avoid in your application. And you can \", \"avoid that by setting the\\nadditional level of indirection of the API Gateway (Ocelot, in this case).\", \" That way, the client app won\\u2019t\\ndirectly access the microservice.\\nImplementing your API Gateways wit\", \"h Ocelot\\nOcelot is basically a set of middleware that you can apply in a specific order.\\nOcelot is d\", \"esigned to work with ASP.NET Core only. The latest version of the package is 18.0 which\\ntargets .NET\", \" 6 and hence is not suitable for .NET Framework applications.\\n168 CHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET ApplicationsYou install Ocelot and its dependencies i\", \"n your ASP.NET Core project with Ocelot\\u2019s NuGet package,\\nfrom Visual Studio.\\nInstall-Package Ocelot\\n\", \"In eShopOnContainers, its API Gateway implementation is a simple ASP.NET Core WebHost project,\\nand O\", \"celot\\u2019s middleware handles all the API Gateway features, as shown in the following image:\\nFigure 6-3\", \"2. The OcelotApiGw base project in eShopOnContainers\\nThis ASP.NET Core WebHost project is built with\", \" two simple files: Program.cs and Startup.cs.\\nThe Program.cs just needs to create and configure the \", \"typical ASP.NET Core BuildWebHost.\\nnamespace OcelotApiGw\\n{\\npublic class Program\\n{\\npublic static void\", \" Main(string[] args)\\n{\\nBuildWebHost(args).Run();\\n}\\npublic static IWebHost BuildWebHost(string[] args\", \")\\n{\\nvar builder = WebHost.CreateDefaultBuilder(args);\\nbuilder.ConfigureServices(s => s.AddSingleton(\", \"builder))\\n.ConfigureAppConfiguration(\\nic => ic.AddJsonFile(Path.Combine(\\\"configuration\\\",\\n\\\"configurat\", \"ion.json\\\")))\\n.UseStartup<Startup>();\\nvar host = builder.Build();\\nreturn host;\\n}\\n}\\n}\\n169 CHAPTER 5 | \", \"Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsThe important point\", \" here for Ocelot is the configuration.json file that you must provide to the builder\\nthrough the Add\", \"JsonFile() method. That configuration.json is where you specify all the API Gateway\\nReRoutes, meanin\", \"g the external endpoints with specific ports and the correlated internal endpoints,\\nusually using di\", \"fferent ports.\\n{\\n\\\"ReRoutes\\\": [],\\n\\\"GlobalConfiguration\\\": {}\\n}\\nThere are two sections to the configura\", \"tion. An array of ReRoutes and a GlobalConfiguration. The\\nReRoutes are the objects that tell Ocelot \", \"how to treat an upstream request. The Global configuration\\nallows overrides of ReRoute specific sett\", \"ings. It\\u2019s useful if you don\\u2019t want to manage lots of ReRoute\\nspecific settings.\\nHere\\u2019s a simplified\", \" example of ReRoute configuration file from one of the API Gateways from\\neShopOnContainers.\\n{\\n\\\"ReRou\", \"tes\\\": [\\n{\\n\\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\",\\n\\\"DownstreamScheme\\\": \\\"http\\\",\\n\\\"Down\", \"streamHostAndPorts\\\": [\\n{\\n\\\"Host\\\": \\\"catalog-api\\\",\\n\\\"Port\\\": 80\\n}\\n],\\n\\\"UpstreamPathTemplate\\\": \\\"/api/{versi\", \"on}/c/{everything}\\\",\\n\\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ]\\n},\\n{\\n\\\"DownstreamPathTemplate\\\": \\\"\", \"/api/{version}/{everything}\\\",\\n\\\"DownstreamScheme\\\": \\\"http\\\",\\n\\\"DownstreamHostAndPorts\\\": [\\n{\\n\\\"Host\\\": \\\"bas\", \"ket-api\\\",\\n\\\"Port\\\": 80\\n}\\n],\\n\\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\",\\n\\\"UpstreamHttpMeth\", \"od\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ],\\n\\\"AuthenticationOptions\\\": {\\n\\\"AuthenticationProviderKey\\\": \\\"IdentityApiK\", \"ey\\\",\\n\\\"AllowedScopes\\\": []\\n}\\n}\\n],\\n\\\"GlobalConfiguration\\\": {\\n\\\"RequestIdKey\\\": \\\"OcRequestId\\\",\\n\\\"Administrat\", \"ionPath\\\": \\\"/administration\\\"\\n}\\n}\\n170 CHAPTER 5 | Designing and Developing Multi-Container and Microse\", \"rvice-Based .NET ApplicationsThe main functionality of an Ocelot API Gateway is to take incoming HTT\", \"P requests and forward them\\non to a downstream service, currently as another HTTP request. Ocelot\\u2019s \", \"describes the routing of one\\nrequest to another as a ReRoute.\\nFor instance, let\\u2019s focus on one of th\", \"e ReRoutes in the configuration.json from above, the\\nconfiguration for the Basket microservice.\\n{\\n\\\"D\", \"ownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\",\\n\\\"DownstreamScheme\\\": \\\"http\\\",\\n\\\"DownstreamHostAn\", \"dPorts\\\": [\\n{\\n\\\"Host\\\": \\\"basket-api\\\",\\n\\\"Port\\\": 80\\n}\\n],\\n\\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{everyt\", \"hing}\\\",\\n\\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ],\\n\\\"AuthenticationOptions\\\": {\\n\\\"AuthenticationPr\", \"oviderKey\\\": \\\"IdentityApiKey\\\",\\n\\\"AllowedScopes\\\": []\\n}\\n}\\nThe DownstreamPathTemplate, Scheme, and Downst\", \"reamHostAndPorts make the internal\\nmicroservice URL that this request will be forwarded to.\\nThe port\", \" is the internal port used by the service. When using containers, the port specified at its\\ndockerfi\", \"le.\\nThe Host is a service name that depends on the service name resolution you are using. When using\", \"\\ndocker-compose, the services names are provided by the Docker Host, which is using the service\\nname\", \"s provided in the docker-compose files. If using an orchestrator like Kubernetes or Service\\nFabric, \", \"that name should be resolved by the DNS or name resolution provided by each orchestrator.\\nDownstream\", \"HostAndPorts is an array that contains the host and port of any downstream services that\\nyou wish to\", \" forward requests to. Usually this configuration will just contain one entry but sometimes\\nyou might\", \" want to load balance requests to your downstream services and Ocelot lets you add more\\nthan one ent\", \"ry and then select a load balancer. But if using Azure and any orchestrator it is probably a\\nbetter \", \"idea to load balance with the cloud and orchestrator infrastructure.\\nThe UpstreamPathTemplate is the\", \" URL that Ocelot will use to identify which\\nDownstreamPathTemplate to use for a given request from t\", \"he client. Finally, the\\nUpstreamHttpMethod is used so Ocelot can distinguish between different reque\", \"sts (GET, POST, PUT)\\nto the same URL.\\nAt this point, you could have a single Ocelot API Gateway (ASP\", \".NET Core WebHost) using one or\\nmultiple merged configuration.json files or you can also store the c\", \"onfiguration in a Consul KV store.\\nBut as introduced in the architecture and design sections, if you\", \" really want to have autonomous\\nmicroservices, it might be better to split that single monolithic AP\", \"I Gateway into multiple API\\nGateways and/or BFF (Backend for Frontend). For that purpose, let\\u2019s see \", \"how to implement that\\napproach with Docker containers.\\n171 CHAPTER 5 | Designing and Developing Mult\", \"i-Container and Microservice-Based .NET ApplicationsUsing a single Docker container image to run mul\", \"tiple different API Gateway / BFF\\ncontainer types\\nIn eShopOnContainers, we\\u2019re using a single Docker \", \"container image with the Ocelot API Gateway but\\nthen, at run time, we create different services/cont\", \"ainers for each type of API-Gateway/BFF by\\nproviding a different configuration.json file, using a do\", \"cker volume to access a different PC folder for\\neach service.\\nFigure 6-33. Reusing a single Ocelot D\", \"ocker image across multiple API Gateway types\\nIn eShopOnContainers, the \\u201cGeneric Ocelot API Gateway \", \"Docker Image\\u201d is created with the project\\nnamed \\u2018OcelotApiGw\\u2019 and the image name \\u201ceshop/ocelotapigw\\u201d\", \" that is specified in the docker-\\ncompose.yml file. Then, when deploying to Docker, there will be fo\", \"ur API-Gateway containers created\\nfrom that same Docker image, as shown in the following extract fro\", \"m the docker-compose.yml file.\\nmobileshoppingapigw:\\nimage: eshop/ocelotapigw:${TAG:-latest}\\n172 CHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicationsbuild:\\ncont\", \"ext: .\\ndockerfile: src/ApiGateways/ApiGw-Base/Dockerfile\\nmobilemarketingapigw:\\nimage: eshop/ocelotap\", \"igw:${TAG:-latest}\\nbuild:\\ncontext: .\\ndockerfile: src/ApiGateways/ApiGw-Base/Dockerfile\\nwebshoppingap\", \"igw:\\nimage: eshop/ocelotapigw:${TAG:-latest}\\nbuild:\\ncontext: .\\ndockerfile: src/ApiGateways/ApiGw-Bas\", \"e/Dockerfile\\nwebmarketingapigw:\\nimage: eshop/ocelotapigw:${TAG:-latest}\\nbuild:\\ncontext: .\\ndockerfile\", \": src/ApiGateways/ApiGw-Base/Dockerfile\\nAdditionally, as you can see in the following docker-compose\", \".override.yml file, the only difference\\nbetween those API Gateway containers is the Ocelot configura\", \"tion file, which is different for each\\nservice container and it\\u2019s specified at run time through a Do\", \"cker volume.\\nmobileshoppingapigw:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=ht\", \"tp://identity-api\\nports:\\n- \\\"5200:80\\\"\\nvolumes:\\n- ./src/ApiGateways/Mobile.Bff.Shopping/apigw:/app/con\", \"figuration\\nmobilemarketingapigw:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=htt\", \"p://identity-api\\nports:\\n- \\\"5201:80\\\"\\nvolumes:\\n- ./src/ApiGateways/Mobile.Bff.Marketing/apigw:/app/con\", \"figuration\\nwebshoppingapigw:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://\", \"identity-api\\nports:\\n- \\\"5202:80\\\"\\nvolumes:\\n- ./src/ApiGateways/Web.Bff.Shopping/apigw:/app/configurati\", \"on\\nwebmarketingapigw:\\nenvironment:\\n- ASPNETCORE_ENVIRONMENT=Development\\n- IdentityUrl=http://identit\", \"y-api\\nports:\\n- \\\"5203:80\\\"\\n173 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-B\", \"ased .NET Applicationsvolumes:\\n- ./src/ApiGateways/Web.Bff.Marketing/apigw:/app/configuration\\nBecaus\", \"e of that previous code, and as shown in the Visual Studio Explorer below, the only file needed\\nto d\", \"efine each specific business/BFF API Gateway is just a configuration.json file, because the four API\", \"\\nGateways are based on the same Docker image.\\nFigure 6-34. The only file needed to define each API G\", \"ateway / BFF with Ocelot is a configuration file\\nBy splitting the API Gateway into multiple API Gate\", \"ways, different development teams focusing on\\ndifferent subsets of microservices can manage their ow\", \"n API Gateways by using independent Ocelot\\nconfiguration files. Plus, at the same time they can reus\", \"e the same Ocelot Docker image.\\nNow, if you run eShopOnContainers with the API Gateways (included by\", \" default in VS when opening\\neShopOnContainers-ServicesAndWebApps.sln solution or if running \\u201cdocker-\", \"compose up\\u201d), the\\nfollowing sample routes will be performed.\\nFor instance, when visiting the upstrea\", \"m URL\\nhttp://host.docker.internal:5202/api/v1/c/catalog/items/2/ served by the webshoppingapigw API\\n\", \"Gateway, you get the same result from the internal Downstream URL http://catalog-api/api/v1/2\\nwithin\", \" the Docker host, as in the following browser.\\nFigure 6-35. Accessing a microservice through a URL p\", \"rovided by the API Gateway\\nBecause of testing or debugging reasons, if you wanted to directly access\", \" to the Catalog Docker\\ncontainer (only at the development environment) without passing through the A\", \"PI Gateway, since\\n\\u2018catalog-api\\u2019 is a DNS resolution internal to the Docker host (service discovery h\", \"andled by docker-\\ncompose service names), the only way to directly access the container is through t\", \"he external port\\npublished in the docker-compose.override.yml, which is provided only for developmen\", \"t tests, such as\\nhttp://host.docker.internal:5101/api/v1/Catalog/items/1 in the following browser.\\n1\", \"74 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsFigu\", \"re 6-36. Direct access to a microservice for testing purposes\\nBut the application is configured so i\", \"t accesses all the microservices through the API Gateways, not\\nthrough the direct port \\u201cshortcuts\\u201d.\\n\", \"The Gateway aggregation pattern in eShopOnContainers\\nAs introduced previously, a flexible way to imp\", \"lement requests aggregation is with custom services, by\\ncode. You could also implement request aggre\", \"gation with the Request Aggregation feature in Ocelot,\\nbut it might not be as flexible as you need. \", \"Therefore, the selected way to implement aggregation in\\neShopOnContainers is with an explicit ASP.NE\", \"T Core Web API service for each aggregator.\\nAccording to that approach, the API Gateway composition \", \"diagram is in reality a bit more extended\\nwhen considering the aggregator services that are not show\", \"n in the simplified global architecture\\ndiagram shown previously.\\nIn the following diagram, you can \", \"also see how the aggregator services work with their related API\\nGateways.\\nFigure 6-37. eShopOnConta\", \"iners architecture with aggregator services\\nZooming in further, on the \\u201cShopping\\u201d business area in t\", \"he following image, you can see that\\nchattiness between the client apps and the microservices is red\", \"uced when using the aggregator\\nservices in the API Gateways.\\n175 CHAPTER 5 | Designing and Developin\", \"g Multi-Container and Microservice-Based .NET ApplicationsFigure 6-38. Zoom in vision of the Aggrega\", \"tor services\\nYou can notice how when the diagram shows the possible requests coming from the API Gat\", \"eways it\\ncan get complex. On the other hand, when you use the aggregator pattern, you can see how th\", \"e\\narrows in blue would simplify the communication from a client app perspective. This pattern not on\", \"ly\\nhelps to reduce the chattiness and latency in the communication, it also improves the user experi\", \"ence\\nsignificantly for the remote apps (mobile and SPA apps).\\nIn the case of the \\u201cMarketing\\u201d busines\", \"s area and microservices, it is a simple use case so there was no\\nneed to use aggregators, but it co\", \"uld also be possible, if needed.\\nAuthentication and authorization in Ocelot API Gateways\\nIn an Ocelo\", \"t API Gateway, you can sit the authentication service, such as an ASP.NET Core Web API\\nservice using\", \" IdentityServer providing the auth token, either out or inside the API Gateway.\\nSince eShopOnContain\", \"ers is using multiple API Gateways with boundaries based on BFF and business\\nareas, the Identity/Aut\", \"h service is left out of the API Gateways, as highlighted in yellow in the\\nfollowing diagram.\\n176 CH\", \"APTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET ApplicationsFigure 6-\", \"39. Position of the Identity service in eShopOnContainers\\nHowever, Ocelot also supports sitting the \", \"Identity/Auth microservice within the API Gateway\\nboundary, as in this other diagram.\\nFigure 6-40. A\", \"uthentication in Ocelot\\nAs the previous diagram shows, when the Identity microservice is beneath the\", \" API gateway (AG): 1) AG\\nrequests an auth token from identity microservice, 2) The identity microser\", \"vice returns token to AG, 3-\\n4) AG requests from microservices using the auth token. Because eShopOn\", \"Containers application has\\nsplit the API Gateway into multiple BFF (Backend for Frontend) and busine\", \"ss areas API Gateways,\\nanother option would have been to create an additional API Gateway for cross-\", \"cutting concerns. That\\nchoice would be fair in a more complex microservice based architecture with m\", \"ultiple cross-cutting\\nconcerns microservices. Since there\\u2019s only one cross-cutting concern in eShopO\", \"nContainers, it was\\ndecided to just handle the security service out of the API Gateway realm, for si\", \"mplicity\\u2019s sake.\\n177 CHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NE\", \"T ApplicationsIn any case, if the app is secured at the API Gateway level, the authentication module\", \" of the Ocelot\\nAPI Gateway is visited at first when trying to use any secured microservice. That red\", \"irects the HTTP\\nrequest to visit the Identity or auth microservice to get the access token so you ca\", \"n visit the protected\\nservices with the access_token.\\nThe way you secure with authentication any ser\", \"vice at the API Gateway level is by setting the\\nAuthenticationProviderKey in its related settings at\", \" the configuration.json.\\n{\\n\\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\",\\n\\\"DownstreamSchem\", \"e\\\": \\\"http\\\",\\n\\\"DownstreamHostAndPorts\\\": [\\n{\\n\\\"Host\\\": \\\"basket-api\\\",\\n\\\"Port\\\": 80\\n}\\n],\\n\\\"UpstreamPathTemplat\", \"e\\\": \\\"/api/{version}/b/{everything}\\\",\\n\\\"UpstreamHttpMethod\\\": [],\\n\\\"AuthenticationOptions\\\": {\\n\\\"Authentic\", \"ationProviderKey\\\": \\\"IdentityApiKey\\\",\\n\\\"AllowedScopes\\\": []\\n}\\n}\\nWhen Ocelot runs, it will look at the R\", \"eRoutes AuthenticationOptions.AuthenticationProviderKey and\\ncheck that there is an Authentication Pr\", \"ovider registered with the given key. If there isn\\u2019t, then Ocelot\\nwill not start up. If there is, th\", \"en the ReRoute will use that provider when it executes.\\nBecause the Ocelot WebHost is configured wit\", \"h the authenticationProviderKey = \\\"IdentityApiKey\\\",\\nthat will require authentication whenever that s\", \"ervice has any requests without any auth token.\\nnamespace OcelotApiGw\\n{\\npublic class Startup\\n{\\npriva\", \"te readonly IConfiguration _cfg;\\npublic Startup(IConfiguration configuration) => _cfg = configuratio\", \"n;\\npublic void ConfigureServices(IServiceCollection services)\\n{\\nvar identityUrl = _cfg.GetValue<stri\", \"ng>(\\\"IdentityUrl\\\");\\nvar authenticationProviderKey = \\\"IdentityApiKey\\\";\\n//\\u2026\\nservices.AddAuthentication\", \"()\\n.AddJwtBearer(authenticationProviderKey, x =>\\n{\\nx.Authority = identityUrl;\\nx.RequireHttpsMetadata\", \" = false;\\nx.TokenValidationParameters = new\\nMicrosoft.IdentityModel.Tokens.TokenValidationParameters\", \"()\\n{\\nValidAudiences = new[] { \\\"orders\\\", \\\"basket\\\", \\\"locations\\\",\\n\\\"marketing\\\", \\\"mobileshoppingagg\\\", \\\"we\", \"bshoppingagg\\\" }\\n};\\n});\\n//...\\n178 CHAPTER 5 | Designing and Developing Multi-Container and Microservi\", \"ce-Based .NET Applications}\\n}\\n}\\nThen, you also need to set authorization with the [Authorize] attrib\", \"ute on any resource to be accessed\\nlike the microservices, such as in the following Basket microserv\", \"ice controller.\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.Controllers\\n{\\n[Route(\\\"api/\", \"v1/[controller]\\\")]\\n[Authorize]\\npublic class BasketController : Controller\\n{\\n//...\\n}\\n}\\nThe ValidAudie\", \"nces such as \\u201cbasket\\u201d are correlated with the audience defined in each microservice\\nwith AddJwtBeare\", \"r() at the ConfigureServices() of the Startup class, such as in the code below.\\n// prevent from mapp\", \"ing \\\"sub\\\" claim to nameidentifier.\\nJwtSecurityTokenHandler.DefaultInboundClaimTypeMap.Clear();\\nvar i\", \"dentityUrl = Configuration.GetValue<string>(\\\"IdentityUrl\\\");\\nservices.AddAuthentication(options =>\\n{\\n\", \"options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;\\noptions.DefaultChallenge\", \"Scheme = JwtBearerDefaults.AuthenticationScheme;\\n}).AddJwtBearer(options =>\\n{\\noptions.Authority = id\", \"entityUrl;\\noptions.RequireHttpsMetadata = false;\\noptions.Audience = \\\"basket\\\";\\n});\\nIf you try to acce\", \"ss any secured microservice, like the Basket microservice with a ReRoute URL based\\non the API Gatewa\", \"y like http://host.docker.internal:5202/api/v1/b/basket/1, then you\\u2019ll get a 401\\nUnauthorized unless\", \" you provide a valid token. On the other hand, if a ReRoute URL is authenticated,\\nOcelot will invoke\", \" whatever downstream scheme is associated with it (the internal microservice URL).\\nAuthorization at \", \"Ocelot\\u2019s ReRoutes tier. Ocelot supports claims-based authorization evaluated after\\nthe authenticatio\", \"n. You set the authorization at a route level by adding the following lines to the\\nReRoute configura\", \"tion.\\n\\\"RouteClaimsRequirement\\\": {\\n\\\"UserType\\\": \\\"employee\\\"\\n}\\nIn that example, when the authorization m\", \"iddleware is called, Ocelot will find if the user has the claim\\ntype \\u2018UserType\\u2019 in the token and if \", \"the value of that claim is \\u2018employee\\u2019. If it isn\\u2019t, then the user will not\\nbe authorized and the res\", \"ponse will be 403 forbidden.\\n179 CHAPTER 5 | Designing and Developing Multi-Container and Microservi\", \"ce-Based .NET ApplicationsUsing Kubernetes Ingress plus Ocelot API Gateways\\nWhen using Kubernetes (l\", \"ike in an Azure Kubernetes Service cluster), you usually unify all the HTTP\\nrequests through the Kub\", \"ernetes Ingress tier based on Nginx.\\nIn Kubernetes, if you don\\u2019t use any ingress approach, then your\", \" services and pods have IPs only\\nroutable by the cluster network.\\nBut if you use an ingress approach\", \", you\\u2019ll have a middle tier between the Internet and your services\\n(including your API Gateways), ac\", \"ting as a reverse proxy.\\nAs a definition, an Ingress is a collection of rules that allow inbound con\", \"nections to reach the cluster\\nservices. An ingress is configured to provide services externally reac\", \"hable URLs, load balance traffic,\\nSSL termination and more. Users request ingress by POSTing the Ing\", \"ress resource to the API server.\\nIn eShopOnContainers, when developing locally and using just your d\", \"evelopment machine as the\\nDocker host, you are not using any ingress but only the multiple API Gatew\", \"ays.\\nHowever, when targeting a \\u201cproduction\\u201d environment based on Kubernetes, eShopOnContainers is\\nus\", \"ing an ingress in front of the API gateways. That way, the clients still call the same base URL but \", \"the\\nrequests are routed to multiple API Gateways or BFF.\\nAPI Gateways are front-ends or fa\\u00e7ades surf\", \"acing only the services but not the web applications that\\nare usually out of their scope. In additio\", \"n, the API Gateways might hide certain internal microservices.\\nThe ingress, however, is just redirec\", \"ting HTTP requests but not trying to hide any microservice or web\\napp.\\nHaving an ingress Nginx tier \", \"in Kubernetes in front of the web applications plus the several Ocelot API\\nGateways / BFF is the ide\", \"al architecture, as shown in the following diagram.\\nFigure 6-41. The ingress tier in eShopOnContaine\", \"rs when deployed into Kubernetes\\nA Kubernetes Ingress acts as a reverse proxy for all traffic to the\", \" app, including the web applications,\\nthat are out of the Api gateway scope. When you deploy eShopOn\", \"Containers into Kubernetes, it\\n180 CHAPTER 5 | Designing and Developing Multi-Container and Microser\", \"vice-Based .NET Applicationsexposes just a few services or endpoints via ingress, basically the foll\", \"owing list of postfixes on the\\nURLs:\\n\\u2022 / for the client SPA web application\\n\\u2022 /webmvc for the client\", \" MVC web application\\n\\u2022 /webstatus for the client web app showing the status/healthchecks\\n\\u2022 /webshopp\", \"ingapigw for the web BFF and shopping business processes\\n\\u2022 /webmarketingapigw for the web BFF and ma\", \"rketing business processes\\n\\u2022 /mobileshoppingapigw for the mobile BFF and shopping business processes\", \"\\n\\u2022 /mobilemarketingapigw for the mobile BFF and marketing business processes\\nWhen deploying to Kuber\", \"netes, each Ocelot API Gateway is using a different \\u201cconfiguration.json\\u201d file\\nfor each pod running t\", \"he API Gateways. Those \\u201cconfiguration.json\\u201d files are provided by mounting\\n(originally with the depl\", \"oy.ps1 script) a volume created based on a Kubernetes config map named\\n\\u2018ocelot\\u2019. Each container moun\", \"ts its related configuration file in the container\\u2019s folder named\\n/app/configuration.\\nIn the source \", \"code files of eShopOnContainers, the original \\u201cconfiguration.json\\u201d files can be found\\nwithin the k8s\", \"/ocelot/ folder. There\\u2019s one file for each BFF/APIGateway.\\nAdditional cross-cutting features in an O\", \"celot API Gateway\\nThere are other important features to research and use, when using an Ocelot API G\", \"ateway, described\\nin the following links.\\n\\u2022 Service discovery in the client side integrating Ocelot \", \"with Consul or Eureka\\nhttps://ocelot.readthedocs.io/en/latest/features/servicediscovery.html\\n\\u2022 Cachi\", \"ng at the API Gateway tier\\nhttps://ocelot.readthedocs.io/en/latest/features/caching.html\\n\\u2022 Logging a\", \"t the API Gateway tier\\nhttps://ocelot.readthedocs.io/en/latest/features/logging.html\\n\\u2022 Quality of Se\", \"rvice (Retries and Circuit breakers) at the API Gateway tier\\nhttps://ocelot.readthedocs.io/en/latest\", \"/features/qualityofservice.html\\n\\u2022 Rate limiting\\nhttps://ocelot.readthedocs.io/en/latest/features/rat\", \"elimiting.html\\n\\u2022 Swagger for Ocelot\\nhttps://github.com/Burgyn/MMLib.SwaggerForOcelot\\n181 CHAPTER 5 |\", \" Designing and Developing Multi-Container and Microservice-Based .NET Applications6\\nCHAPTER\\nTackle B\", \"usiness\\nComplexity in a\\nMicroservice with DDD\\nand CQRS Patterns\\nDesign a domain model for each micro\", \"service or Bounded Context that reflects understanding of the\\nbusiness domain.\\nThis section focuses \", \"on more advanced microservices that you implement when you need to tackle\\ncomplex subsystems, or mic\", \"roservices derived from the knowledge of domain experts with ever-\\nchanging business rules. The arch\", \"itecture patterns used in this section are based on domain-driven\\ndesign (DDD) and Command and Query\", \" Responsibility Segregation (CQRS) approaches, as illustrated\\nin Figure 7-1.\\n182 CHAPTER 6 | Tackle \", \"Business Complexity in a Microservice with DDD and CQRS PatternsFigure 7-1. External microservice ar\", \"chitecture versus internal architecture patterns for each microservice\\nHowever, most of the techniqu\", \"es for data driven microservices, such as how to implement an ASP.NET\\nCore Web API service or how to\", \" expose Swagger metadata with Swashbuckle or NSwag, are also\\napplicable to the more advanced microse\", \"rvices implemented internally with DDD patterns. This\\nsection is an extension of the previous sectio\", \"ns, because most of the practices explained earlier also\\napply here or for any kind of microservice.\", \"\\nThis section first provides details on the simplified CQRS patterns used in the eShopOnContainers\\nr\", \"eference application. Later, you will get an overview of the DDD techniques that enable you to find\\n\", \"common patterns that you can reuse in your applications.\\nDDD is a large topic with a rich set of res\", \"ources for learning. You can start with books like Domain-\\nDriven Design by Eric Evans and additiona\", \"l materials from Vaughn Vernon, Jimmy Nilsson, Greg\\nYoung, Udi Dahan, Jimmy Bogard, and many other D\", \"DD/CQRS experts. But most of all you need to try\\nto learn how to apply DDD techniques from the conve\", \"rsations, whiteboarding, and domain modeling\\nsessions with the experts in your concrete business dom\", \"ain.\\nAdditional resources\\nDDD (Domain-Driven Design)\\n\\u2022 Eric Evans. Domain Language\\nhttps://domainlan\", \"guage.com/\\n\\u2022 Martin Fowler. Domain-Driven Design\\nhttps://martinfowler.com/tags/domain%20driven%20des\", \"ign.html\\n\\u2022 Jimmy Bogard. Strengthening your domain: a primer\\nhttps://lostechies.com/jimmybogard/2010\", \"/02/04/strengthening-your-domain-a-primer/\\n183 CHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS PatternsDDD books\\n\\u2022 Eric Evans. Domain-Driven Design: Tackling Complexity in t\", \"he Heart of Software\\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/03\", \"21125215/\\n\\u2022 Eric Evans. Domain-Driven Design Reference: Definitions and Pattern Summaries\\nhttps://ww\", \"w.amazon.com/Domain-Driven-Design-Reference-Definitions-2014-09-\\n22/dp/B01N8YB4ZO/\\n\\u2022 Vaughn Vernon. \", \"Implementing Domain-Driven Design\\nhttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\nV\", \"ernon/dp/0321834577/\\n\\u2022 Vaughn Vernon. Domain-Driven Design Distilled\\nhttps://www.amazon.com/Domain-D\", \"riven-Design-Distilled-Vaughn-Vernon/dp/0134434420/\\n\\u2022 Jimmy Nilsson. Applying Domain-Driven Design a\", \"nd Patterns\\nhttps://www.amazon.com/Applying-Domain-Driven-Design-Patterns-\\nExamples/dp/0321268202/\\n\\u2022\", \" Cesar de la Torre. N-Layered Domain-Oriented Architecture Guide with .NET\\nhttps://www.amazon.com/N-\", \"Layered-Domain-Oriented-Architecture-Guide-\\nNET/dp/8493903612/\\n\\u2022 Abel Avram and Floyd Marinescu. Dom\", \"ain-Driven Design Quickly\\nhttps://www.amazon.com/Domain-Driven-Design-Quickly-Abel-Avram/dp/14116092\", \"55/\\n\\u2022 Scott Millett, Nick Tune - Patterns, Principles, and Practices of Domain-Driven Design\\nhttps:/\", \"/www.wiley.com/Patterns%2C+Principles%2C+and+Practices+of+Domain+Driven+Des\\nign-p-9781118714706\\nDDD \", \"training\\n\\u2022 Julie Lerman and Steve Smith. Domain-Driven Design Fundamentals\\nhttps://www.pluralsight.c\", \"om/courses/fundamentals-domain-driven-design\\nApply simplified CQRS and DDD patterns in a\\nmicroservic\", \"e\\nCQRS is an architectural pattern that separates the models for reading and writing data. The relat\", \"ed\\nterm Command Query Separation (CQS) was originally defined by Bertrand Meyer in his book Object-\\n\", \"Oriented Software Construction. The basic idea is that you can divide a system\\u2019s operations into two\", \"\\nsharply separated categories:\\n\\u2022 Queries. These queries return a result and don\\u2019t change the state o\", \"f the system, and they\\u2019re\\nfree of side effects.\\n\\u2022 Commands. These commands change the state of a sys\", \"tem.\\n184 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsCQS is a\", \" simple concept: it is about methods within the same object being either queries or\\ncommands. Each m\", \"ethod either returns state or mutates state, but not both. Even a single repository\\npattern object c\", \"an comply with CQS. CQS can be considered a foundational principle for CQRS.\\nCommand and Query Respo\", \"nsibility Segregation (CQRS) was introduced by Greg Young and strongly\\npromoted by Udi Dahan and oth\", \"ers. It\\u2019s based on the CQS principle, although it\\u2019s more detailed. It can\\nbe considered a pattern ba\", \"sed on commands and events plus optionally on asynchronous messages.\\nIn many cases, CQRS is related \", \"to more advanced scenarios, like having a different physical database\\nfor reads (queries) than for w\", \"rites (updates). Moreover, a more evolved CQRS system might\\nimplement Event-Sourcing (ES) for your u\", \"pdates database, so you would only store events in the\\ndomain model instead of storing the current-s\", \"tate data. However, this approach is not used in this\\nguide. This guide uses the simplest CQRS appro\", \"ach, which consists of just separating the queries from\\nthe commands.\\nThe separation aspect of CQRS \", \"is achieved by grouping query operations in one layer and commands\\nin another layer. Each layer has \", \"its own data model (note that we say model, not necessarily a different\\ndatabase) and is built using\", \" its own combination of patterns and technologies. More importantly, the\\ntwo layers can be within th\", \"e same tier or microservice, as in the example (ordering microservice) used\\nfor this guide. Or they \", \"could be implemented on different microservices or processes so they can be\\noptimized and scaled out\", \" separately without affecting one another.\\nCQRS means having two objects for a read/write operation \", \"where in other contexts there\\u2019s one. There\\nare reasons to have a denormalized reads database, which \", \"you can learn about in more advanced\\nCQRS literature. But we aren\\u2019t using that approach here, where \", \"the goal is to have more flexibility in\\nthe queries instead of limiting the queries with constraints\", \" from DDD patterns like aggregates.\\nAn example of this kind of service is the ordering microservice \", \"from the eShopOnContainers reference\\napplication. This service implements a microservice based on a \", \"simplified CQRS approach. It uses a\\nsingle data source or database, but two logical models plus DDD \", \"patterns for the transactional\\ndomain, as shown in Figure 7-2.\\n185 CHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS PatternsFigure 7-2. Simplified CQRS- and DDD-based microse\", \"rvice\\nThe Logical \\u201cOrdering\\u201d Microservice includes its Ordering database, which can be, but doesn\\u2019t \", \"have to\\nbe, the same Docker host. Having the database in the same Docker host is good for developmen\", \"t, but\\nnot for production.\\nThe application layer can be the Web API itself. The important design asp\", \"ect here is that the\\nmicroservice has split the queries and ViewModels (data models especially creat\", \"ed for the client\\napplications) from the commands, domain model, and transactions following the CQRS\", \" pattern. This\\napproach keeps the queries independent from restrictions and constraints coming from \", \"DDD patterns\\nthat only make sense for transactions and updates, as explained in later sections.\\nAddi\", \"tional resources\\n\\u2022 Greg Young. Versioning in an Event Sourced System (Free to read online e-book)\\nht\", \"tps://leanpub.com/esversioning/read\\nApply CQRS and CQS approaches in a DDD\\nmicroservice in eShopOnCo\", \"ntainers\\nThe design of the ordering microservice at the eShopOnContainers reference application is b\", \"ased on\\nCQRS principles. However, it uses the simplest approach, which is just separating the querie\", \"s from the\\ncommands and using the same database for both actions.\\nThe essence of those patterns, and\", \" the important point here, is that queries are idempotent: no matter\\nhow many times you query a syst\", \"em, the state of that system won\\u2019t change. In other words, queries\\nare side-effect free.\\n186 CHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsTherefore, you could use\", \" a different \\u201creads\\u201d data model than the transactional logic \\u201cwrites\\u201d domain\\nmodel, even though the \", \"ordering microservices are using the same database. Hence, this is a\\nsimplified CQRS approach.\\nOn th\", \"e other hand, commands, which trigger transactions and data updates, change state in the\\nsystem. Wit\", \"h commands, you need to be careful when dealing with complexity and ever-changing\\nbusiness rules. Th\", \"is is where you want to apply DDD techniques to have a better modeled system.\\nThe DDD patterns prese\", \"nted in this guide should not be applied universally. They introduce\\nconstraints on your design. Tho\", \"se constraints provide benefits such as higher quality over time,\\nespecially in commands and other c\", \"ode that modifies system state. However, those constraints add\\ncomplexity with fewer benefits for re\", \"ading and querying data.\\nOne such pattern is the Aggregate pattern, which we examine more in later s\", \"ections. Briefly, in the\\nAggregate pattern, you treat many domain objects as a single unit as a resu\", \"lt of their relationship in\\nthe domain. You might not always gain advantages from this pattern in qu\", \"eries; it can increase the\\ncomplexity of query logic. For read-only queries, you do not get the adva\", \"ntages of treating multiple\\nobjects as a single Aggregate. You only get the complexity.\\nAs shown in \", \"Figure 7-2 in the previous section, this guide suggests using DDD patterns only in the\\ntransactional\", \"/updates area of your microservice (that is, as triggered by commands). Queries can\\nfollow a simpler\", \" approach and should be separated from commands, following a CQRS approach.\\nFor implementing the \\u201cqu\", \"eries side\\u201d, you can choose between many approaches, from your full-blown\\nORM like EF Core, AutoMapp\", \"er projections, stored procedures, views, materialized views or a micro\\nORM.\\nIn this guide and in eS\", \"hopOnContainers (specifically the ordering microservice) we chose to\\nimplement straight queries usin\", \"g a micro ORM like Dapper. This guide lets you implement any query\\nbased on SQL statements to get th\", \"e best performance, thanks to a light framework with little\\noverhead.\\nWhen you use this approach, an\", \"y updates to your model that impact how entities are persisted to a\\nSQL database also need separate \", \"updates to SQL queries used by Dapper or any other separate (non-\\nEF) approaches to querying.\\nCQRS a\", \"nd DDD patterns are not top-level architectures\\nIt\\u2019s important to understand that CQRS and most DDD \", \"patterns (like DDD layers or a domain model\\nwith aggregates) are not architectural styles, but only \", \"architecture patterns. Microservices, SOA, and\\nevent-driven architecture (EDA) are examples of archi\", \"tectural styles. They describe a system of many\\ncomponents, such as many microservices. CQRS and DDD\", \" patterns describe something inside a single\\nsystem or component; in this case, something inside a m\", \"icroservice.\\nDifferent Bounded Contexts (BCs) will employ different patterns. They have different re\", \"sponsibilities,\\nand that leads to different solutions. It is worth emphasizing that forcing the same\", \" pattern everywhere\\nleads to failure. Do not use CQRS and DDD patterns everywhere. Many subsystems, \", \"BCs, or\\nmicroservices are simpler and can be implemented more easily using simple CRUD services or u\", \"sing\\nanother approach.\\n187 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S PatternsThere is only one application architecture: the architecture of the system or end-to-end a\", \"pplication\\nyou are designing (for example, the microservices architecture). However, the design of e\", \"ach Bounded\\nContext or microservice within that application reflects its own tradeoffs and internal \", \"design decisions\\nat an architecture patterns level. Do not try to apply the same architectural patte\", \"rns as CQRS or DDD\\neverywhere.\\nAdditional resources\\n\\u2022 Martin Fowler. CQRS\\nhttps://martinfowler.com/b\", \"liki/CQRS.html\\n\\u2022 Greg Young. CQRS Documents\\nhttps://cqrs.files.wordpress.com/2010/11/cqrs_documents.\", \"pdf\\n\\u2022 Udi Dahan. Clarified CQRS\\nhttps://udidahan.com/2009/12/09/clarified-cqrs/\\nImplement reads/quer\", \"ies in a CQRS microservice\\nFor reads/queries, the ordering microservice from the eShopOnContainers r\", \"eference application\\nimplements the queries independently from the DDD model and transactional area.\", \" This\\nimplementation was done primarily because the demands for queries and for transactions are\\ndra\", \"stically different. Writes execute transactions that must be compliant with the domain logic.\\nQuerie\", \"s, on the other hand, are idempotent and can be segregated from the domain rules.\\nThe approach is si\", \"mple, as shown in Figure 7-3. The API interface is implemented by the Web API\\ncontrollers using any \", \"infrastructure, such as a micro Object Relational Mapper (ORM) like Dapper, and\\nreturning dynamic Vi\", \"ewModels depending on the needs of the UI applications.\\nFigure 7-3. The simplest approach for querie\", \"s in a CQRS microservice\\nThe simplest approach for the queries-side in a simplified CQRS approach ca\", \"n be implemented by\\nquerying the database with a Micro-ORM like Dapper, returning dynamic ViewModels\", \". The query\\n188 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternsd\", \"efinitions query the database and return a dynamic ViewModel built on the fly for each query. Since\\n\", \"the queries are idempotent, they won\\u2019t change the data no matter how many times you run a query.\\nThe\", \"refore, you don\\u2019t need to be restricted by any DDD pattern used in the transactional side, like\\naggr\", \"egates and other patterns, and that is why queries are separated from the transactional area. You\\nqu\", \"ery the database for the data that the UI needs and return a dynamic ViewModel that does not\\nneed to\", \" be statically defined anywhere (no classes for the ViewModels) except in the SQL statements\\nthemsel\", \"ves.\\nSince this approach is simple, the code required for the queries side (such as code using a mic\", \"ro ORM\\nlike Dapper) can be implemented within the same Web API project. Figure 7-4 shows this approa\", \"ch.\\nThe queries are defined in the Ordering.API microservice project within the eShopOnContainers\\nso\", \"lution.\\nFigure 7-4. Queries in the Ordering microservice in eShopOnContainers\\nUse ViewModels specifi\", \"cally made for client apps, independent from\\ndomain model constraints\\nSince the queries are performe\", \"d to obtain the data needed by the client applications, the returned\\ntype can be specifically made f\", \"or the clients, based on the data returned by the queries. These models,\\nor Data Transfer Objects (D\", \"TOs), are called ViewModels.\\nThe returned data (ViewModel) can be the result of joining data from mu\", \"ltiple entities or tables in the\\ndatabase, or even across multiple aggregates defined in the domain \", \"model for the transactional area.\\nIn this case, because you are creating queries independent of the \", \"domain model, the aggregates\\nboundaries and constraints are ignored and you\\u2019re free to query any tab\", \"le and column you might\\nneed. This approach provides great flexibility and productivity for the deve\", \"lopers creating or updating\\nthe queries.\\nThe ViewModels can be static types defined in classes (as i\", \"s implemented in the ordering\\nmicroservice). Or they can be created dynamically based on the queries\", \" performed, which is agile for\\ndevelopers.\\nUse Dapper as a micro ORM to perform queries\\nYou can use \", \"any micro ORM, Entity Framework Core, or even plain ADO.NET for querying. In the\\nsample application,\", \" Dapper was selected for the ordering microservice in eShopOnContainers as a\\ngood example of a popul\", \"ar micro ORM. It can run plain SQL queries with great performance, because\\nit\\u2019s a light framework. U\", \"sing Dapper, you can write a SQL query that can access and join multiple\\ntables.\\n189 CHAPTER 6 | Tac\", \"kle Business Complexity in a Microservice with DDD and CQRS PatternsDapper is an open-source project\", \" (original created by Sam Saffron), and is part of the building blocks\\nused in Stack Overflow. To us\", \"e Dapper, you just need to install it through the Dapper NuGet package,\\nas shown in the following fi\", \"gure:\\nYou also need to add a using directive so your code has access to the Dapper extension methods\", \".\\nWhen you use Dapper in your code, you directly use the SqlConnection class available in the\\nMicros\", \"oft.Data.SqlClient namespace. Through the QueryAsync method and other extension methods\\nthat extend \", \"the SqlConnection class, you can run queries in a straightforward and performant way.\\nDynamic versus\", \" static ViewModels\\nWhen returning ViewModels from the server-side to client apps, you can think abou\", \"t those\\nViewModels as DTOs (Data Transfer Objects) that can be different to the internal domain enti\", \"ties of\\nyour entity model because the ViewModels hold the data the way the client app needs. Therefo\", \"re, in\\nmany cases, you can aggregate data coming from multiple domain entities and compose the\\nViewM\", \"odels precisely according to how the client app needs that data.\\nThose ViewModels or DTOs can be def\", \"ined explicitly (as data holder classes), like the OrderSummary\\nclass shown in a later code snippet.\", \" Or, you could just return dynamic ViewModels or dynamic DTOs\\nbased on the attributes returned by yo\", \"ur queries as a dynamic type.\\nViewModel as dynamic type\\nAs shown in the following code, a ViewModel \", \"can be directly returned by the queries by just returning\\na dynamic type that internally is based on\", \" the attributes returned by a query. That means that the\\nsubset of attributes to be returned is base\", \"d on the query itself. Therefore, if you add a new column to\\nthe query or join, that data is dynamic\", \"ally added to the returned ViewModel.\\nusing Dapper;\\nusing Microsoft.Extensions.Configuration;\\nusing \", \"System.Data.SqlClient;\\nusing System.Threading.Tasks;\\nusing System.Dynamic;\\nusing System.Collections.\", \"Generic;\\npublic class OrderQueries : IOrderQueries\\n{\\npublic async Task<IEnumerable<dynamic>> GetOrde\", \"rsAsync()\\n{\\nusing (var connection = new SqlConnection(_connectionString))\\n{\\nconnection.Open();\\nretur\", \"n await connection.QueryAsync<dynamic>(\\n@\\\"SELECT o.[Id] as ordernumber,\\no.[OrderDate] as [date],os.[\", \"Name] as [status],\\nSUM(oi.units*oi.unitprice) as total\\nFROM [ordering].[Orders] o\\nLEFT JOIN[ordering\", \"].[orderitems] oi ON o.Id = oi.orderid\\nLEFT JOIN[ordering].[orderstatus] os on o.OrderStatusId = os.\", \"Id\\n190 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsGROUP BY o\", \".[Id], o.[OrderDate], os.[Name]\\\");\\n}\\n}\\n}\\nThe important point is that by using a dynamic type, the re\", \"turned collection of data is dynamically\\nassembled as the ViewModel.\\nPros: This approach reduces the\", \" need to modify static ViewModel classes whenever you update the\\nSQL sentence of a query, making thi\", \"s design approach agile when coding, straightforward, and quick\\nto evolve in regard to future change\", \"s.\\nCons: In the long term, dynamic types can negatively impact the clarity and the compatibility of \", \"a\\nservice with client apps. In addition, middleware software like Swashbuckle cannot provide the sam\", \"e\\nlevel of documentation on returned types if using dynamic types.\\nViewModel as predefined DTO class\", \"es\\nPros: Having static, predefined ViewModel classes, like \\u201ccontracts\\u201d based on explicit DTO classes\", \", is\\ndefinitely better for public APIs but also for long-term microservices, even if they are only u\", \"sed by the\\nsame application.\\nIf you want to specify response types for Swagger, you need to use expl\", \"icit DTO classes as the return\\ntype. Therefore, predefined DTO classes allow you to offer richer inf\", \"ormation from Swagger. That\\nimproves the API documentation and compatibility when consuming an API.\\n\", \"Cons: As mentioned earlier, when updating the code, it takes some more steps to update the DTO\\nclass\", \"es.\\nTip based on our experience: In the queries implemented at the Ordering microservice in\\neShopOnC\", \"ontainers, we started developing by using dynamic ViewModels as it was straightforward\\nand agile on \", \"the early development stages. But, once the development was stabilized, we chose to\\nrefactor the API\", \"s and use static or pre-defined DTOs for the ViewModels, because it is clearer for the\\nmicroservice\\u2019\", \"s consumers to know explicit DTO types, used as \\u201ccontracts\\u201d.\\nIn the following example, you can see h\", \"ow the query is returning data by using an explicit ViewModel\\nDTO class: the OrderSummary class.\\nusi\", \"ng Dapper;\\nusing Microsoft.Extensions.Configuration;\\nusing System.Data.SqlClient;\\nusing System.Threa\", \"ding.Tasks;\\nusing System.Dynamic;\\nusing System.Collections.Generic;\\npublic class OrderQueries : IOrd\", \"erQueries\\n{\\npublic async Task<IEnumerable<OrderSummary>> GetOrdersAsync()\\n{\\nusing (var connection = \", \"new SqlConnection(_connectionString))\\n{\\nconnection.Open();\\nreturn await connection.QueryAsync<OrderS\", \"ummary>(\\n@\\\"SELECT o.[Id] as ordernumber,\\no.[OrderDate] as [date],os.[Name] as [status],\\n191 CHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsSUM(oi.units*oi.unitprice\", \") as total\\nFROM [ordering].[Orders] o\\nLEFT JOIN[ordering].[orderitems] oi ON o.Id = oi.orderid\\nLEFT \", \"JOIN[ordering].[orderstatus] os on o.OrderStatusId = os.Id\\nGROUP BY o.[Id], o.[OrderDate], os.[Name]\", \"\\nORDER BY o.[Id]\\\");\\n}\\n}\\n}\\nDescribe response types of Web APIs\\nDevelopers consuming web APIs and micr\", \"oservices are most concerned with what is returned\\u2014\\nspecifically response types and error codes (if \", \"not standard). The response types are handled in the\\nXML comments and data annotations.\\nWithout prop\", \"er documentation in the Swagger UI, the consumer lacks knowledge of what types are\\nbeing returned or\", \" what HTTP codes can be returned. That problem is fixed by adding the\\nMicrosoft.AspNetCore.Mvc.Produ\", \"cesResponseTypeAttribute, so Swashbuckle can generate richer\\ninformation about the API return model \", \"and values, as shown in the following code:\\nnamespace Microsoft.eShopOnContainers.Services.Ordering.\", \"API.Controllers\\n{\\n[Route(\\\"api/v1/[controller]\\\")]\\n[Authorize]\\npublic class OrdersController : Control\", \"ler\\n{\\n//Additional code...\\n[Route(\\\"\\\")]\\n[HttpGet]\\n[ProducesResponseType(typeof(IEnumerable<OrderSumma\", \"ry>),\\n(int)HttpStatusCode.OK)]\\npublic async Task<IActionResult> GetOrders()\\n{\\nvar userid = _identity\", \"Service.GetUserIdentity();\\nvar orders = await _orderQueries\\n.GetOrdersFromUserAsync(Guid.Parse(useri\", \"d));\\nreturn Ok(orders);\\n}\\n}\\n}\\nHowever, the ProducesResponseType attribute cannot use dynamic as a ty\", \"pe but requires to use\\nexplicit types, like the OrderSummary ViewModel DTO, shown in the following e\", \"xample:\\npublic class OrderSummary\\n{\\npublic int ordernumber { get; set; }\\npublic DateTime date { get;\", \" set; }\\npublic string status { get; set; }\\npublic double total { get; set; }\\n}\\n// or using C# 8 reco\", \"rd types:\\npublic record OrderSummary(int ordernumber, DateTime date, string status, double total);\\n1\", \"92 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsThis is anothe\", \"r reason why explicit returned types are better than dynamic types, in the long term.\\nWhen using the\", \" ProducesResponseType attribute, you can also specify what is the expected outcome\\nregarding possibl\", \"e HTTP errors/codes, like 200, 400, etc.\\nIn the following image, you can see how Swagger UI shows th\", \"e ResponseType information.\\nFigure 7-5. Swagger UI showing response types and possible HTTP status c\", \"odes from a Web API\\nThe image shows some example values based on the ViewModel types and the possibl\", \"e HTTP status\\ncodes that can be returned.\\nAdditional resources\\n\\u2022 Dapper\\nhttps://github.com/StackExch\", \"ange/dapper-dot-net\\n\\u2022 Julie Lerman. Data Points - Dapper, Entity Framework and Hybrid Apps (MSDN\\nmag\", \"azine article)\\n193 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patter\", \"nshttps://learn.microsoft.com/archive/msdn-magazine/2016/may/data-points-dapper-entity-\\nframework-an\", \"d-hybrid-apps\\n\\u2022 ASP.NET Core Web API Help Pages using Swagger\\nhttps://learn.microsoft.com/aspnet/cor\", \"e/tutorials/web-api-help-pages-using-\\nswagger?tabs=visual-studio\\n\\u2022 Create record types https://learn\", \".microsoft.com/dotnet/csharp/whats-new/tutorials/records\\nDesign a DDD-oriented microservice\\nDomain-d\", \"riven design (DDD) advocates modeling based on the reality of business as relevant to your\\nuse cases\", \". In the context of building applications, DDD talks about problems as domains. It describes\\nindepen\", \"dent problem areas as Bounded Contexts (each Bounded Context correlates to a\\nmicroservice), and emph\", \"asizes a common language to talk about these problems. It also suggests\\nmany technical concepts and \", \"patterns, like domain entities with rich models (no anemic-domain\\nmodel), value objects, aggregates,\", \" and aggregate root (or root entity) rules to support the internal\\nimplementation. This section intr\", \"oduces the design and implementation of those internal patterns.\\nSometimes these DDD technical rules\", \" and patterns are perceived as obstacles that have a steep\\nlearning curve for implementing DDD appro\", \"aches. But the important part is not the patterns\\nthemselves, but organizing the code so it is align\", \"ed to the business problems, and using the same\\nbusiness terms (ubiquitous language). In addition, D\", \"DD approaches should be applied only if you are\\nimplementing complex microservices with significant \", \"business rules. Simpler responsibilities, like a\\nCRUD service, can be managed with simpler approache\", \"s.\\nWhere to draw the boundaries is the key task when designing and defining a microservice. DDD\\npatt\", \"erns help you understand the complexity in the domain. For the domain model for each Bounded\\nContext\", \", you identify and define the entities, value objects, and aggregates that model your domain.\\nYou bu\", \"ild and refine a domain model that is contained within a boundary that defines your context.\\nAnd tha\", \"t is explicit in the form of a microservice. The components within those boundaries end up\\nbeing you\", \"r microservices, although in some cases a BC or business microservices can be composed of\\nseveral ph\", \"ysical services. DDD is about boundaries and so are microservices.\\nKeep the microservice context bou\", \"ndaries relatively small\\nDetermining where to place boundaries between Bounded Contexts balances two\", \" competing goals.\\nFirst, you want to initially create the smallest possible microservices, although \", \"that should not be the\\nmain driver; you should create a boundary around things that need cohesion. S\", \"econd, you want to\\navoid chatty communications between microservices. These goals can contradict one\", \" another. You\\nshould balance them by decomposing the system into as many small microservices as you \", \"can until\\nyou see communication boundaries growing quickly with each additional attempt to separate \", \"a new\\nBounded Context. Cohesion is key within a single bounded context.\\nIt is similar to the Inappro\", \"priate Intimacy code smell when implementing classes. If two microservices\\nneed to collaborate a lot\", \" with each other, they should probably be the same microservice.\\n194 CHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS PatternsAnother way to look at this aspect is autonomy. \", \"If a microservice must rely on another service to\\ndirectly service a request, it is not truly autono\", \"mous.\\nLayers in DDD microservices\\nMost enterprise applications with significant business and technic\", \"al complexity are defined by\\nmultiple layers. The layers are a logical artifact, and are not related\", \" to the deployment of the service.\\nThey exist to help developers manage the complexity in the code. \", \"Different layers (like the domain\\nmodel layer versus the presentation layer, etc.) might have differ\", \"ent types, which mandate translations\\nbetween those types.\\nFor example, an entity could be loaded fr\", \"om the database. Then part of that information, or an\\naggregation of information including additiona\", \"l data from other entities, can be sent to the client UI\\nthrough a REST Web API. The point here is t\", \"hat the domain entity is contained within the domain\\nmodel layer and should not be propagated to oth\", \"er areas that it does not belong to, like to the\\npresentation layer.\\nAdditionally, you need to have \", \"always-valid entities (see the Designing validations in the domain\\nmodel layer section) controlled b\", \"y aggregate roots (root entities). Therefore, entities should not be\\nbound to client views, because \", \"at the UI level some data might still not be validated. This reason is\\nwhat the ViewModel is for. Th\", \"e ViewModel is a data model exclusively for presentation layer needs.\\nThe domain entities do not bel\", \"ong directly to the ViewModel. Instead, you need to translate between\\nViewModels and domain entities\", \" and vice versa.\\nWhen tackling complexity, it is important to have a domain model controlled by aggr\", \"egate roots that\\nmake sure that all the invariants and rules related to that group of entities (aggr\", \"egate) are performed\\nthrough a single entry-point or gate, the aggregate root.\\nFigure 7-5 shows how \", \"a layered design is implemented in the eShopOnContainers application.\\n195 CHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS PatternsFigure 7-5. DDD layers in the ordering micr\", \"oservice in eShopOnContainers\\nThe three layers in a DDD microservice like Ordering. Each layer is a \", \"VS project: Application layer is\\nOrdering.API, Domain layer is Ordering.Domain and the Infrastructur\", \"e layer is Ordering.Infrastructure.\\nYou want to design the system so that each layer communicates on\", \"ly with certain other layers. That\\napproach may be easier to enforce if layers are implemented as di\", \"fferent class libraries, because you\\ncan clearly identify what dependencies are set between librarie\", \"s. For instance, the domain model layer\\nshould not take a dependency on any other layer (the domain \", \"model classes should be Plain Old Class\\nObjects, or POCO, classes). As shown in Figure 7-6, the Orde\", \"ring.Domain layer library has\\ndependencies only on the .NET libraries or NuGet packages, but not on \", \"any other custom library, such\\nas data library or persistence library.\\nFigure 7-6. Layers implemente\", \"d as libraries allow better control of dependencies between layers\\nThe domain model layer\\nEric Evans\", \"\\u2019s excellent book Domain Driven Design says the following about the domain model layer\\nand the appli\", \"cation layer.\\nDomain Model Layer: Responsible for representing concepts of the business, information\", \" about the\\nbusiness situation, and business rules. State that reflects the business situation is con\", \"trolled and used\\nhere, even though the technical details of storing it are delegated to the infrastr\", \"ucture. This layer is\\nthe heart of business software.\\n196 CHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS PatternsThe domain model layer is where the business is expressed. \", \"When you implement a microservice\\ndomain model layer in .NET, that layer is coded as a class library\", \" with the domain entities that capture\\ndata plus behavior (methods with logic).\\nFollowing the Persis\", \"tence Ignorance and the Infrastructure Ignorance principles, this layer must\\ncompletely ignore data \", \"persistence details. These persistence tasks should be performed by the\\ninfrastructure layer. Theref\", \"ore, this layer should not take direct dependencies on the infrastructure,\\nwhich means that an impor\", \"tant rule is that your domain model entity classes should be POCOs.\\nDomain entities should not have \", \"any direct dependency (like deriving from a base class) on any data\\naccess infrastructure framework \", \"like Entity Framework or NHibernate. Ideally, your domain entities\\nshould not derive from or impleme\", \"nt any type defined in any infrastructure framework.\\nMost modern ORM frameworks like Entity Framewor\", \"k Core allow this approach, so that your domain\\nmodel classes are not coupled to the infrastructure.\", \" However, having POCO entities is not always\\npossible when using certain NoSQL databases and framewo\", \"rks, like Actors and Reliable Collections in\\nAzure Service Fabric.\\nEven when it is important to foll\", \"ow the Persistence Ignorance principle for your Domain model, you\\nshould not ignore persistence conc\", \"erns. It is still important to understand the physical data model and\\nhow it maps to your entity obj\", \"ect model. Otherwise you can create impossible designs.\\nAlso, this aspect does not mean you can take\", \" a model designed for a relational database and directly\\nmove it to a NoSQL or document-oriented dat\", \"abase. In some entity models, the model might fit, but\\nusually it does not. There are still constrai\", \"nts that your entity model must adhere to, based both on\\nthe storage technology and ORM technology.\\n\", \"The application layer\\nMoving on to the application layer, we can again cite Eric Evans\\u2019s book Domain\", \" Driven Design:\\nApplication Layer: Defines the jobs the software is supposed to do and directs the e\", \"xpressive domain\\nobjects to work out problems. The tasks this layer is responsible for are meaningfu\", \"l to the business or\\nnecessary for interaction with the application layers of other systems. This la\", \"yer is kept thin. It does\\nnot contain business rules or knowledge, but only coordinates tasks and de\", \"legates work to\\ncollaborations of domain objects in the next layer down. It does not have state refl\", \"ecting the business\\nsituation, but it can have state that reflects the progress of a task for the us\", \"er or the program.\\nA microservice\\u2019s application layer in .NET is commonly coded as an ASP.NET Core W\", \"eb API project.\\nThe project implements the microservice\\u2019s interaction, remote network access, and th\", \"e external Web\\nAPIs used from the UI or client apps. It includes queries if using a CQRS approach, c\", \"ommands\\naccepted by the microservice, and even the event-driven communication between microservices\\n\", \"(integration events). The ASP.NET Core Web API that represents the application layer must not contai\", \"n\\nbusiness rules or domain knowledge (especially domain rules for transactions or updates); these\\nsh\", \"ould be owned by the domain model class library. The application layer must only coordinate tasks\\nan\", \"d must not hold or define any domain state (domain model). It delegates the execution of business\\nru\", \"les to the domain model classes themselves (aggregate roots and domain entities), which will\\nultimat\", \"ely update the data within those domain entities.\\n197 CHAPTER 6 | Tackle Business Complexity in a Mi\", \"croservice with DDD and CQRS PatternsBasically, the application logic is where you implement all use\", \" cases that depend on a given front end.\\nFor example, the implementation related to a Web API servic\", \"e.\\nThe goal is that the domain logic in the domain model layer, its invariants, the data model, and\\n\", \"related business rules must be completely independent from the presentation and application layers.\\n\", \"Most of all, the domain model layer must not directly depend on any infrastructure framework.\\nThe in\", \"frastructure layer\\nThe infrastructure layer is how the data that is initially held in domain entitie\", \"s (in memory) is persisted\\nin databases or another persistent store. An example is using Entity Fram\", \"ework Core code to\\nimplement the Repository pattern classes that use a DBContext to persist data in \", \"a relational\\ndatabase.\\nIn accordance with the previously mentioned Persistence Ignorance and Infrast\", \"ructure Ignorance\\nprinciples, the infrastructure layer must not \\u201ccontaminate\\u201d the domain model layer\", \". You must keep the\\ndomain model entity classes agnostic from the infrastructure that you use to per\", \"sist data (EF or any\\nother framework) by not taking hard dependencies on frameworks. Your domain mod\", \"el layer class\\nlibrary should have only your domain code, just POCO entity classes implementing the \", \"heart of your\\nsoftware and completely decoupled from infrastructure technologies.\\nThus, your layers \", \"or class libraries and projects should ultimately depend on your domain model layer\\n(library), not v\", \"ice versa, as shown in Figure 7-7.\\nFigure 7-7. Dependencies between layers in DDD\\nDependencies in a \", \"DDD Service, the Application layer depends on Domain and Infrastructure, and\\nInfrastructure depends \", \"on Domain, but Domain doesn\\u2019t depend on any layer. This layer design should\\nbe independent for each \", \"microservice. As noted earlier, you can implement the most complex\\nmicroservices following DDD patte\", \"rns, while implementing simpler data-driven microservices (simple\\nCRUD in a single layer) in a simpl\", \"er way.\\n198 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAddit\", \"ional resources\\n\\u2022 DevIQ. Persistence Ignorance principle\\nhttps://deviq.com/persistence-ignorance/\\n\\u2022 \", \"Oren Eini. Infrastructure Ignorance\\nhttps://ayende.com/blog/3137/infrastructure-ignorance\\n\\u2022 Angel Lo\", \"pez. Layered Architecture In Domain-Driven Design\\nhttps://ajlopez.wordpress.com/2008/09/12/layered-a\", \"rchitecture-in-domain-driven-design/\\nDesign a microservice domain model\\nDefine one rich domain model\", \" for each business microservice or Bounded Context.\\nYour goal is to create a single cohesive domain \", \"model for each business microservice or Bounded\\nContext (BC). Keep in mind, however, that a BC or bu\", \"siness microservice could sometimes be\\ncomposed of several physical services that share a single dom\", \"ain model. The domain model must\\ncapture the rules, behavior, business language, and constraints of \", \"the single Bounded Context or\\nbusiness microservice that it represents.\\nThe Domain Entity pattern\\nEn\", \"tities represent domain objects and are primarily defined by their identity, continuity, and\\npersist\", \"ence over time, and not only by the attributes that comprise them. As Eric Evans says, \\u201can\\nobject pr\", \"imarily defined by its identity is called an Entity.\\u201d Entities are very important in the domain\\nmode\", \"l, since they are the base for a model. Therefore, you should identify and design them carefully.\\nAn\", \" entity\\u2019s identity can cross multiple microservices or Bounded Contexts.\\nThe same identity (that is,\", \" the same Id value, although perhaps not the same domain entity) can be\\nmodeled across multiple Boun\", \"ded Contexts or microservices. However, that does not imply that the\\nsame entity, with the same attr\", \"ibutes and logic would be implemented in multiple Bounded Contexts.\\nInstead, entities in each Bounde\", \"d Context limit their attributes and behaviors to those required in that\\nBounded Context\\u2019s domain.\\nF\", \"or instance, the buyer entity might have most of a person\\u2019s attributes that are defined in the user\\n\", \"entity in the profile or identity microservice, including the identity. But the buyer entity in the \", \"ordering\\nmicroservice might have fewer attributes, because only certain buyer data is related to the\", \" order\\nprocess. The context of each microservice or Bounded Context impacts its domain model.\\nDomain\", \" entities must implement behavior in addition to implementing data attributes.\\nA domain entity in DD\", \"D must implement the domain logic or behavior related to the entity data (the\\nobject accessed in mem\", \"ory). For example, as part of an order entity class you must have business logic\\nand operations impl\", \"emented as methods for tasks such as adding an order item, data validation, and\\ntotal calculation. T\", \"he entity\\u2019s methods take care of the invariants and rules of the entity instead of\\nhaving those rule\", \"s spread across the application layer.\\n199 CHAPTER 6 | Tackle Business Complexity in a Microservice \", \"with DDD and CQRS PatternsFigure 7-8 shows a domain entity that implements not only data attributes \", \"but operations or methods\\nwith related domain logic.\\nFigure 7-8. Example of a domain entity design i\", \"mplementing data plus behavior\\nA domain model entity implements behaviors through methods, that is, \", \"it\\u2019s not an \\u201canemic\\u201d model. Of\\ncourse, sometimes you can have entities that do not implement any log\", \"ic as part of the entity class.\\nThis can happen in child entities within an aggregate if the child e\", \"ntity does not have any special logic\\nbecause most of the logic is defined in the aggregate root. If\", \" you have a complex microservice that\\nhas logic implemented in the service classes instead of in the\", \" domain entities, you could be falling\\ninto the anemic domain model, explained in the following sect\", \"ion.\\nRich domain model versus anemic domain model\\nIn his post AnemicDomainModel, Martin Fowler descr\", \"ibes an anemic domain model this way:\\nThe basic symptom of an Anemic Domain Model is that at first b\", \"lush it looks like the real thing. There\\nare objects, many named after the nouns in the domain space\", \", and these objects are connected with\\nthe rich relationships and structure that true domain models \", \"have. The catch comes when you look at\\nthe behavior, and you realize that there is hardly any behavi\", \"or on these objects, making them little\\nmore than bags of getters and setters.\\nOf course, when you u\", \"se an anemic domain model, those data models will be used from a set of\\nservice objects (traditional\", \"ly named the business layer) which capture all the domain or business logic.\\nThe business layer sits\", \" on top of the data model and uses the data model just as data.\\nThe anemic domain model is just a pr\", \"ocedural style design. Anemic entity objects are not real objects\\nbecause they lack behavior (method\", \"s). They only hold data properties and thus it is not object-\\noriented design. By putting all the be\", \"havior out into service objects (the business layer), you\\nessentially end up with spaghetti code or \", \"transaction scripts, and therefore you lose the advantages\\nthat a domain model provides.\\nRegardless,\", \" if your microservice or Bounded Context is very simple (a CRUD service), the anemic\\ndomain model in\", \" the form of entity objects with just data properties might be good enough, and it\\nmight not be wort\", \"h implementing more complex DDD patterns. In that case, it will be simply a\\npersistence model, becau\", \"se you have intentionally created an entity with only data for CRUD\\npurposes.\\n200 CHAPTER 6 | Tackle\", \" Business Complexity in a Microservice with DDD and CQRS PatternsThat is why microservices architect\", \"ures are perfect for a multi-architectural approach depending on\\neach Bounded Context. For instance,\", \" in eShopOnContainers, the ordering microservice implements\\nDDD patterns, but the catalog microservi\", \"ce, which is a simple CRUD service, does not.\\nSome people say that the anemic domain model is an ant\", \"i-pattern. It really depends on what you are\\nimplementing. If the microservice you are creating is s\", \"imple enough (for example, a CRUD service),\\nfollowing the anemic domain model it is not an anti-patt\", \"ern. However, if you need to tackle the\\ncomplexity of a microservice\\u2019s domain that has a lot of ever\", \"-changing business rules, the anemic\\ndomain model might be an anti-pattern for that microservice or \", \"Bounded Context. In that case,\\ndesigning it as a rich model with entities containing data plus behav\", \"ior as well as implementing\\nadditional DDD patterns (aggregates, value objects, etc.) might have hug\", \"e benefits for the long-term\\nsuccess of such a microservice.\\nAdditional resources\\n\\u2022 DevIQ. Domain En\", \"tity\\nhttps://deviq.com/entity/\\n\\u2022 Martin Fowler. The Domain Model\\nhttps://martinfowler.com/eaaCatalog\", \"/domainModel.html\\n\\u2022 Martin Fowler. The Anemic Domain Model\\nhttps://martinfowler.com/bliki/AnemicDoma\", \"inModel.html\\nThe Value Object pattern\\nAs Eric Evans has noted, \\u201cMany objects do not have conceptual \", \"identity. These objects describe\\ncertain characteristics of a thing.\\u201d\\nAn entity requires an identity\", \", but there are many objects in a system that do not, like the Value\\nObject pattern. A value object \", \"is an object with no conceptual identity that describes a domain aspect.\\nThese are objects that you \", \"instantiate to represent design elements that only concern you temporarily.\\nYou care about what they\", \" are, not who they are. Examples include numbers and strings, but can also\\nbe higher-level concepts \", \"like groups of attributes.\\nSomething that is an entity in a microservice might not be an entity in a\", \"nother microservice, because\\nin the second case, the Bounded Context might have a different meaning.\", \" For example, an address in\\nan e-commerce application might not have an identity at all, since it mi\", \"ght only represent a group of\\nattributes of the customer\\u2019s profile for a person or company. In this \", \"case, the address should be\\nclassified as a value object. However, in an application for an electric\", \" power utility company, the\\ncustomer address could be important for the business domain. Therefore, \", \"the address must have an\\nidentity so the billing system can be directly linked to the address. In th\", \"at case, an address should be\\nclassified as a domain entity.\\nA person with a name and surname is usu\", \"ally an entity because a person has identity, even if the\\nname and surname coincide with another set\", \" of values, such as if those names also refer to a different\\nperson.\\nValue objects are hard to manag\", \"e in relational databases and ORMs like Entity Framework (EF),\\nwhereas in document-oriented database\", \"s they are easier to implement and use.\\n201 CHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS PatternsEF Core 2.0 and later versions include the Owned Entities feature that ma\", \"kes it easier to handle value\\nobjects, as we\\u2019ll see in detail later on.\\nAdditional resources\\n\\u2022 Marti\", \"n Fowler. Value Object pattern\\nhttps://martinfowler.com/bliki/ValueObject.html\\n\\u2022 Value Object\\nhttps:\", \"//deviq.com/value-object/\\n\\u2022 Value Objects in Test-Driven Development\\nhttps://leanpub.com/tdd-ebook/r\", \"ead#leanpub-auto-value-objects\\n\\u2022 Eric Evans. Domain-Driven Design: Tackling Complexity in the Heart \", \"of Software. (Book;\\nincludes a discussion of value objects)\\nhttps://www.amazon.com/Domain-Driven-Des\", \"ign-Tackling-Complexity-\\nSoftware/dp/0321125215/\\nThe Aggregate pattern\\nA domain model contains clust\", \"ers of different data entities and processes that can control a\\nsignificant area of functionality, s\", \"uch as order fulfillment or inventory. A more fine-grained DDD unit is\\nthe aggregate, which describe\", \"s a cluster or group of entities and behaviors that can be treated as a\\ncohesive unit.\\nYou usually d\", \"efine an aggregate based on the transactions that you need. A classic example is an\\norder that also \", \"contains a list of order items. An order item will usually be an entity. But it will be a\\nchild enti\", \"ty within the order aggregate, which will also contain the order entity as its root entity,\\ntypicall\", \"y called an aggregate root.\\nIdentifying aggregates can be hard. An aggregate is a group of objects t\", \"hat must be consistent\\ntogether, but you cannot just pick a group of objects and label them an aggre\", \"gate. You must start\\nwith a domain concept and think about the entities that are used in the most co\", \"mmon transactions\\nrelated to that concept. Those entities that need to be transactionally consistent\", \" are what forms an\\naggregate. Thinking about transaction operations is probably the best way to iden\", \"tify aggregates.\\nThe Aggregate Root or Root Entity pattern\\nAn aggregate is composed of at least one \", \"entity: the aggregate root, also called root entity or primary\\nentity. Additionally, it can have mul\", \"tiple child entities and value objects, with all entities and objects\\nworking together to implement \", \"required behavior and transactions.\\nThe purpose of an aggregate root is to ensure the consistency of\", \" the aggregate; it should be the only\\nentry point for updates to the aggregate through methods or op\", \"erations in the aggregate root class.\\nYou should make changes to entities within the aggregate only \", \"via the aggregate root. It is the\\naggregate\\u2019s consistency guardian, considering all the invariants a\", \"nd consistency rules you might need\\nto comply with in your aggregate. If you change a child entity o\", \"r value object independently, the\\n202 CHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patternsaggregate root cannot ensure that the aggregate is in a valid state. It would b\", \"e like a table with a\\nloose leg. Maintaining consistency is the main purpose of the aggregate root.\\n\", \"In Figure 7-9, you can see sample aggregates like the buyer aggregate, which contains a single entit\", \"y\\n(the aggregate root Buyer). The order aggregate contains multiple entities and a value object.\\nFig\", \"ure 7-9. Example of aggregates with multiple or single entities\\nA DDD domain model is composed from \", \"aggregates, an aggregate can have just one entity or more,\\nand can include value objects as well. No\", \"te that the Buyer aggregate could have additional child\\nentities, depending on your domain, as it do\", \"es in the ordering microservice in the eShopOnContainers\\nreference application. Figure 7-9 just illu\", \"strates a case in which the buyer has a single entity, as an\\nexample of an aggregate that contains o\", \"nly an aggregate root.\\nIn order to maintain separation of aggregates and keep clear boundaries betwe\", \"en them, it is a good\\npractice in a DDD domain model to disallow direct navigation between aggregate\", \"s and only having\\nthe foreign key (FK) field, as implemented in the Ordering microservice domain mod\", \"el in\\neShopOnContainers. The Order entity only has a foreign key field for the buyer, but not an EF \", \"Core\\nnavigation property, as shown in the following code:\\npublic class Order : Entity, IAggregateRoo\", \"t\\n{\\nprivate DateTime _orderDate;\\npublic Address Address { get; private set; }\\nprivate int? _buyerId;\", \" // FK pointing to a different aggregate root\\npublic OrderStatus OrderStatus { get; private set; }\\np\", \"rivate readonly List<OrderItem> _orderItems;\\npublic IReadOnlyCollection<OrderItem> OrderItems => _or\", \"derItems;\\n// ... Additional code\\n}\\n203 CHAPTER 6 | Tackle Business Complexity in a Microservice with\", \" DDD and CQRS PatternsIdentifying and working with aggregates requires research and experience. For \", \"more information, see\\nthe following Additional resources list.\\nAdditional resources\\n\\u2022 Vaughn Vernon.\", \" Effective Aggregate Design - Part I: Modeling a Single Aggregate (from\\nhttps://dddcommunity.org/)\\nh\", \"ttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_1.pdf\\n\\u2022 Vaughn Vernon. Eff\", \"ective Aggregate Design - Part II: Making Aggregates Work\\nTogether (from https://dddcommunity.org/)\\n\", \"https://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf\\n\\u2022 Vaughn Vernon. Ef\", \"fective Aggregate Design - Part III: Gaining Insight Through\\nDiscovery (from https://dddcommunity.or\", \"g/)\\nhttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_3.pdf\\n\\u2022 Sergey Grybni\", \"ak. DDD Tactical Design Patterns\\nhttps://www.codeproject.com/Articles/1164363/Domain-Driven-Design-T\", \"actical-Design-\\nPatterns-Part\\n\\u2022 Chris Richardson. Developing Transactional Microservices Using Aggre\", \"gates\\nhttps://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richardson\\n\\u2022 DevIQ.\", \" The Aggregate pattern\\nhttps://deviq.com/aggregate-pattern/\\nImplement a microservice domain model wi\", \"th .NET\\nIn the previous section, the fundamental design principles and patterns for designing a doma\", \"in model\\nwere explained. Now it\\u2019s time to explore possible ways to implement the domain model by usi\", \"ng .NET\\n(plain C# code) and EF Core. Your domain model will be composed simply of your code. It will\", \" have\\njust the EF Core model requirements, but not real dependencies on EF. You shouldn\\u2019t have hard\\n\", \"dependencies or references to EF Core or any other ORM in your domain model.\\nDomain model structure \", \"in a custom .NET Standard Library\\nThe folder organization used for the eShopOnContainers reference a\", \"pplication demonstrates the DDD\\nmodel for the application. You might find that a different folder or\", \"ganization more clearly\\ncommunicates the design choices made for your application. As you can see in\", \" Figure 7-10, in the\\nordering domain model there are two aggregates, the order aggregate and the buy\", \"er aggregate. Each\\naggregate is a group of domain entities and value objects, although you could hav\", \"e an aggregate\\ncomposed of a single domain entity (the aggregate root or root entity) as well.\\n204 C\", \"HAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsFigure 7-10. Domai\", \"n model structure for the ordering microservice in eShopOnContainers\\nAdditionally, the domain model \", \"layer includes the repository contracts (interfaces) that are the\\ninfrastructure requirements of you\", \"r domain model. In other words, these interfaces express what\\nrepositories and the methods the infra\", \"structure layer must implement. It\\u2019s critical that the\\nimplementation of the repositories be placed \", \"outside of the domain model layer, in the infrastructure\\nlayer library, so the domain model layer is\", \"n\\u2019t \\u201ccontaminated\\u201d by API or classes from infrastructure\\ntechnologies, like Entity Framework.\\nYou ca\", \"n also see a SeedWork folder that contains custom base classes that you can use as a base for\\nyour d\", \"omain entities and value objects, so you don\\u2019t have redundant code in each domain\\u2019s object\\nclass.\\nSt\", \"ructure aggregates in a custom .NET Standard library\\nAn aggregate refers to a cluster of domain obje\", \"cts grouped together to match transactional\\nconsistency. Those objects could be instances of entitie\", \"s (one of which is the aggregate root or root\\nentity) plus any additional value objects.\\nTransaction\", \"al consistency means that an aggregate is guaranteed to be consistent and up to date at\\nthe end of a\", \" business action. For example, the order aggregate from the eShopOnContainers ordering\\nmicroservice \", \"domain model is composed as shown in Figure 7-11.\\n205 CHAPTER 6 | Tackle Business Complexity in a Mi\", \"croservice with DDD and CQRS PatternsFigure 7-11. The order aggregate in Visual Studio solution\\nIf y\", \"ou open any of the files in an aggregate folder, you can see how it\\u2019s marked as either a custom\\nbase\", \" class or interface, like entity or value object, as implemented in the SeedWork folder.\\nImplement d\", \"omain entities as POCO classes\\nYou implement a domain model in .NET by creating POCO classes that im\", \"plement your domain\\nentities. In the following example, the Order class is defined as an entity and \", \"also as an aggregate\\nroot. Because the Order class derives from the Entity base class, it can reuse \", \"common code related to\\nentities. Bear in mind that these base classes and interfaces are defined by \", \"you in the domain model\\nproject, so it is your code, not infrastructure code from an ORM like EF.\\n//\", \" COMPATIBLE WITH ENTITY FRAMEWORK CORE 5.0\\n// Entity is a custom base class with the ID\\npublic class\", \" Order : Entity, IAggregateRoot\\n{\\nprivate DateTime _orderDate;\\npublic Address Address { get; private\", \" set; }\\nprivate int? _buyerId;\\npublic OrderStatus OrderStatus { get; private set; }\\nprivate int _ord\", \"erStatusId;\\nprivate string _description;\\nprivate int? _paymentMethodId;\\nprivate readonly List<OrderI\", \"tem> _orderItems;\\npublic IReadOnlyCollection<OrderItem> OrderItems => _orderItems;\\npublic Order(stri\", \"ng userId, Address address, int cardTypeId, string cardNumber, string\\ncardSecurityNumber,\\nstring car\", \"dHolderName, DateTime cardExpiration, int? buyerId = null, int?\\npaymentMethodId = null)\\n{\\n_orderItem\", \"s = new List<OrderItem>();\\n_buyerId = buyerId;\\n_paymentMethodId = paymentMethodId;\\n_orderStatusId = \", \"OrderStatus.Submitted.Id;\\n_orderDate = DateTime.UtcNow;\\n206 CHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS PatternsAddress = address;\\n// ...Additional code ...\\n}\\npublic voi\", \"d AddOrderItem(int productId, string productName,\\ndecimal unitPrice, decimal discount,\\nstring pictur\", \"eUrl, int units = 1)\\n{\\n//...\\n// Domain rules/logic for adding the OrderItem to the order\\n// ...\\nvar \", \"orderItem = new OrderItem(productId, productName, unitPrice, discount,\\npictureUrl, units);\\n_orderIte\", \"ms.Add(orderItem);\\n}\\n// ...\\n// Additional methods with domain rules/logic related to the Order aggre\", \"gate\\n// ...\\n}\\nIt\\u2019s important to note that this is a domain entity implemented as a POCO class. It do\", \"esn\\u2019t have any\\ndirect dependency on Entity Framework Core or any other infrastructure framework. Thi\", \"s\\nimplementation is as it should be in DDD, just C# code implementing a domain model.\\nIn addition, t\", \"he class is decorated with an interface named IAggregateRoot. That interface is an empty\\ninterface, \", \"sometimes called a marker interface, that\\u2019s used just to indicate that this entity class is also\\nan \", \"aggregate root.\\nA marker interface is sometimes considered as an anti-pattern; however, it\\u2019s also a \", \"clean way to mark\\na class, especially when that interface might be evolving. An attribute could be t\", \"he other choice for\\nthe marker, but it\\u2019s quicker to see the base class (Entity) next to the IAggrega\", \"te interface instead of\\nputting an Aggregate attribute marker above the class. It\\u2019s a matter of pref\", \"erences, in any case.\\nHaving an aggregate root means that most of the code related to consistency an\", \"d business rules of\\nthe aggregate\\u2019s entities should be implemented as methods in the Order aggregate\", \" root class (for\\nexample, AddOrderItem when adding an OrderItem object to the aggregate). You should\", \" not create\\nor update OrderItems objects independently or directly; the AggregateRoot class must kee\", \"p control\\nand consistency of any update operation against its child entities.\\nEncapsulate data in th\", \"e Domain Entities\\nA common problem in entity models is that they expose collection navigation proper\", \"ties as publicly\\naccessible list types. This allows any collaborator developer to manipulate the con\", \"tents of these\\ncollection types, which may bypass important business rules related to the collection\", \", possibly leaving\\nthe object in an invalid state. The solution to this is to expose read-only acces\", \"s to related collections\\nand explicitly provide methods that define ways in which clients can manipu\", \"late them.\\nIn the previous code, note that many attributes are read-only or private and are only upd\", \"atable by the\\nclass methods, so any update considers business domain invariants and logic specified \", \"within the class\\nmethods.\\n207 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and \", \"CQRS PatternsFor example, following DDD patterns, you should not do the following from any command h\", \"andler\\nmethod or application layer class (actually, it should be impossible for you to do so):\\n// WR\", \"ONG ACCORDING TO DDD PATTERNS \\u2013 CODE AT THE APPLICATION LAYER OR\\n// COMMAND HANDLERS\\n// Code in comm\", \"and handler methods or Web API controllers\\n//... (WRONG) Some code with business logic out of the do\", \"main classes ...\\nOrderItem myNewOrderItem = new OrderItem(orderId, productId, productName,\\npictureUr\", \"l, unitPrice, discount, units);\\n//... (WRONG) Accessing the OrderItems collection directly from the \", \"application layer // or\\ncommand handlers\\nmyOrder.OrderItems.Add(myNewOrderItem);\\n//...\\nIn this case,\", \" the Add method is purely an operation to add data, with direct access to the OrderItems\\ncollection.\", \" Therefore, most of the domain logic, rules, or validations related to that operation with the\\nchild\", \" entities will be spread across the application layer (command handlers and Web API controllers).\\nIf\", \" you go around the aggregate root, the aggregate root cannot guarantee its invariants, its validity,\", \" or\\nits consistency. Eventually you\\u2019ll have spaghetti code or transactional script code.\\nTo follow D\", \"DD patterns, entities must not have public setters in any entity property. Changes in an\\nentity shou\", \"ld be driven by explicit methods with explicit ubiquitous language about the change\\nthey\\u2019re performi\", \"ng in the entity.\\nFurthermore, collections within the entity (like the order items) should be read-o\", \"nly properties (the\\nAsReadOnly method explained later). You should be able to update it only from wi\", \"thin the aggregate\\nroot class methods or the child entity methods.\\nAs you can see in the code for th\", \"e Order aggregate root, all setters should be private or at least read-\\nonly externally, so that any\", \" operation against the entity\\u2019s data or its child entities has to be performed\\nthrough methods in th\", \"e entity class. This maintains consistency in a controlled and object-oriented\\nway instead of implem\", \"enting transactional script code.\\nThe following code snippet shows the proper way to code the task o\", \"f adding an OrderItem object to\\nthe Order aggregate.\\n// RIGHT ACCORDING TO DDD--CODE AT THE APPLICAT\", \"ION LAYER OR COMMAND HANDLERS\\n// The code in command handlers or WebAPI controllers, related only to\", \" application stuff\\n// There is NO code here related to OrderItem object's business logic\\nmyOrder.Add\", \"OrderItem(productId, productName, pictureUrl, unitPrice, discount, units);\\n// The code related to Or\", \"derItem params validations or domain rules should\\n// be WITHIN the AddOrderItem method.\\n//...\\nIn thi\", \"s snippet, most of the validations or logic related to the creation of an OrderItem object will be\\nu\", \"nder the control of the Order aggregate root\\u2014in the AddOrderItem method\\u2014especially validations\\nand l\", \"ogic related to other elements in the aggregate. For instance, you might get the same product\\nitem a\", \"s the result of multiple calls to AddOrderItem. In that method, you could examine the product\\nitems \", \"and consolidate the same product items into a single OrderItem object with several units.\\n208 CHAPTE\", \"R 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAdditionally, if there \", \"are different discount amounts but the product ID is the same, you would likely\\napply the higher dis\", \"count. This principle applies to any other domain logic for the OrderItem object.\\nIn addition, the n\", \"ew OrderItem(params) operation will also be controlled and performed by the\\nAddOrderItem method from\", \" the Order aggregate root. Therefore, most of the logic or validations\\nrelated to that operation (es\", \"pecially anything that impacts the consistency between other child\\nentities) will be in a single pla\", \"ce within the aggregate root. That is the ultimate purpose of the\\naggregate root pattern.\\nWhen you u\", \"se Entity Framework Core 1.1 or later, a DDD entity can be better expressed because it\\nallows mappin\", \"g to fields in addition to properties. This is useful when protecting collections of child\\nentities \", \"or value objects. With this enhancement, you can use simple private fields instead of\\nproperties and\", \" you can implement any update to the field collection in public methods and provide\\nread-only access\", \" through the AsReadOnly method.\\nIn DDD, you want to update the entity only through methods in the en\", \"tity (or the constructor) in order\\nto control any invariant and the consistency of the data, so prop\", \"erties are defined only with a get\\naccessor. The properties are backed by private fields. Private me\", \"mbers can only be accessed from\\nwithin the class. However, there is one exception: EF Core needs to \", \"set these fields as well (so it can\\nreturn the object with the proper values).\\nMap properties with o\", \"nly get accessors to the fields in the database table\\nMapping properties to database table columns i\", \"s not a domain responsibility but part of the\\ninfrastructure and persistence layer. We mention this \", \"here just so you\\u2019re aware of the new capabilities\\nin EF Core 1.1 or later related to how you can mod\", \"el entities. Additional details on this topic are\\nexplained in the infrastructure and persistence se\", \"ction.\\nWhen you use EF Core 1.0 or later, within the DbContext you need to map the properties that a\", \"re\\ndefined only with getters to the actual fields in the database table. This is done with the HasFi\", \"eld\\nmethod of the PropertyBuilder class.\\nMap fields without properties\\nWith the feature in EF Core 1\", \".1 or later to map columns to fields, it\\u2019s also possible to not use\\nproperties. Instead, you can jus\", \"t map columns from a table to fields. A common use case for this is\\nprivate fields for an internal s\", \"tate that doesn\\u2019t need to be accessed from outside the entity.\\nFor example, in the preceding OrderAg\", \"gregate code example, there are several private fields, like the\\n_paymentMethodId field, that have n\", \"o related property for either a setter or getter. That field could\\nalso be calculated within the ord\", \"er\\u2019s business logic and used from the order\\u2019s methods, but it needs\\nto be persisted in the database \", \"as well. So in EF Core (since v1.1), there\\u2019s a way to map a field without\\na related property to a co\", \"lumn in the database. This is also explained in the Infrastructure layer section\\nof this guide.\\n209 \", \"CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAdditional resour\", \"ces\\n\\u2022 Vaughn Vernon. Modeling Aggregates with DDD and Entity Framework. Note that this is\\nnot Entity\", \" Framework Core.\\nhttps://kalele.io/blog-posts/modeling-aggregates-with-ddd-and-entity-framework/\\n\\u2022 J\", \"ulie Lerman. Data Points - Coding for Domain-Driven Design: Tips for Data-Focused\\nDevs\\nhttps://learn\", \".microsoft.com/archive/msdn-magazine/2013/august/data-points-coding-for-\\ndomain-driven-design-tips-f\", \"or-data-focused-devs\\n\\u2022 Udi Dahan. How to create fully encapsulated Domain Models\\nhttps://udidahan.co\", \"m/2008/02/29/how-to-create-fully-encapsulated-domain-models/\\n\\u2022 Steve Smith. What is the difference b\", \"etween a DTO and a POCO? https://ardalis.com/dto-\\nor-poco/\\nSeedwork (reusable base classes and inter\", \"faces for\\nyour domain model)\\nThe solution folder contains a SeedWork folder. This folder contains cu\", \"stom base classes that you can\\nuse as a base for your domain entities and value objects. Use these b\", \"ase classes so you don\\u2019t have\\nredundant code in each domain\\u2019s object class. The folder for these typ\", \"es of classes is called SeedWork\\nand not something like Framework. It\\u2019s called SeedWork because the \", \"folder contains just a small\\nsubset of reusable classes that cannot really be considered a framework\", \". Seedwork is a term\\nintroduced by Michael Feathers and popularized by Martin Fowler but you could a\", \"lso name that\\nfolder Common, SharedKernel, or similar.\\nFigure 7-12 shows the classes that form the s\", \"eedwork of the domain model in the ordering\\nmicroservice. It has a few custom base classes like Enti\", \"ty, ValueObject, and Enumeration, plus a few\\ninterfaces. These interfaces (IRepository and IUnitOfWo\", \"rk) inform the infrastructure layer about what\\nneeds to be implemented. Those interfaces are also us\", \"ed through Dependency Injection from the\\napplication layer.\\nFigure 7-12. A sample set of domain mode\", \"l \\u201cseedwork\\u201d base classes and interfaces\\nThis is the type of copy and paste reuse that many develope\", \"rs share between projects, not a formal\\nframework. You can have seedworks in any layer or library. H\", \"owever, if the set of classes and\\ninterfaces gets large enough, you might want to create a single cl\", \"ass library.\\n210 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns\", \"The custom Entity base class\\nThe following code is an example of an Entity base class where you can \", \"place code that can be used\\nthe same way by any domain entity, such as the entity ID, equality opera\", \"tors, a domain event list per\\nentity, etc.\\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE (1.1 and later)\\n\", \"public abstract class Entity\\n{\\nint? _requestedHashCode;\\nint _Id;\\nprivate List<INotification> _domain\", \"Events;\\npublic virtual int Id\\n{\\nget\\n{\\nreturn _Id;\\n}\\nprotected set\\n{\\n_Id = value;\\n}\\n}\\npublic List<INo\", \"tification> DomainEvents => _domainEvents;\\npublic void AddDomainEvent(INotification eventItem)\\n{\\n_do\", \"mainEvents = _domainEvents ?? new List<INotification>();\\n_domainEvents.Add(eventItem);\\n}\\npublic void\", \" RemoveDomainEvent(INotification eventItem)\\n{\\nif (_domainEvents is null) return;\\n_domainEvents.Remov\", \"e(eventItem);\\n}\\npublic bool IsTransient()\\n{\\nreturn this.Id == default(Int32);\\n}\\npublic override bool\", \" Equals(object obj)\\n{\\nif (obj == null || !(obj is Entity))\\nreturn false;\\nif (Object.ReferenceEquals(\", \"this, obj))\\nreturn true;\\nif (this.GetType() != obj.GetType())\\nreturn false;\\nEntity item = (Entity)ob\", \"j;\\nif (item.IsTransient() || this.IsTransient())\\nreturn false;\\nelse\\nreturn item.Id == this.Id;\\n}\\npub\", \"lic override int GetHashCode()\\n{\\nif (!IsTransient())\\n211 CHAPTER 6 | Tackle Business Complexity in a\", \" Microservice with DDD and CQRS Patterns{\\nif (!_requestedHashCode.HasValue)\\n_requestedHashCode = thi\", \"s.Id.GetHashCode() ^ 31;\\n// XOR for random distribution. See:\\n// https://learn.microsoft.com/archive\", \"/blogs/ericlippert/guidelines-and-rules-\\nfor-gethashcode\\nreturn _requestedHashCode.Value;\\n}\\nelse\\nret\", \"urn base.GetHashCode();\\n}\\npublic static bool operator ==(Entity left, Entity right)\\n{\\nif (Object.Equ\", \"als(left, null))\\nreturn (Object.Equals(right, null));\\nelse\\nreturn left.Equals(right);\\n}\\npublic stati\", \"c bool operator !=(Entity left, Entity right)\\n{\\nreturn !(left == right);\\n}\\n}\\nThe previous code using\", \" a domain event list per entity will be explained in the next sections when\\nfocusing on domain event\", \"s.\\nRepository contracts (interfaces) in the domain model layer\\nRepository contracts are simply .NET \", \"interfaces that express the contract requirements of the\\nrepositories to be used for each aggregate.\", \"\\nThe repositories themselves, with EF Core code or any other infrastructure dependencies and code\\n(L\", \"inq, SQL, etc.), must not be implemented within the domain model; the repositories should only\\nimple\", \"ment the interfaces you define in the domain model.\\nA pattern related to this practice (placing the \", \"repository interfaces in the domain model layer) is the\\nSeparated Interface pattern. As explained by\", \" Martin Fowler, \\u201cUse Separated Interface to define an\\ninterface in one package but implement it in a\", \"nother. This way a client that needs the dependency to\\nthe interface can be completely unaware of th\", \"e implementation.\\u201d\\nFollowing the Separated Interface pattern enables the application layer (in this \", \"case, the Web API\\nproject for the microservice) to have a dependency on the requirements defined in \", \"the domain model,\\nbut not a direct dependency to the infrastructure/persistence layer. In addition, \", \"you can use\\nDependency Injection to isolate the implementation, which is implemented in the infrastr\", \"ucture/\\npersistence layer using repositories.\\nFor example, the following example with the IOrderRepo\", \"sitory interface defines what operations the\\nOrderRepository class will need to implement at the inf\", \"rastructure layer. In the current\\nimplementation of the application, the code just needs to add or u\", \"pdate orders to the database, since\\nqueries are split following the simplified CQRS approach.\\n// Def\", \"ined at IOrderRepository.cs\\npublic interface IOrderRepository : IRepository<Order>\\n{\\n212 CHAPTER 6 |\", \" Tackle Business Complexity in a Microservice with DDD and CQRS PatternsOrder Add(Order order);\\nvoid\", \" Update(Order order);\\nTask<Order> GetAsync(int orderId);\\n}\\n// Defined at IRepository.cs (Part of the\", \" Domain Seedwork)\\npublic interface IRepository<T> where T : IAggregateRoot\\n{\\nIUnitOfWork UnitOfWork \", \"{ get; }\\n}\\nAdditional resources\\n\\u2022 Martin Fowler. Separated Interface.\\nhttps://www.martinfowler.com/e\", \"aaCatalog/separatedInterface.html\\nImplement value objects\\nAs discussed in earlier sections about ent\", \"ities and aggregates, identity is fundamental for entities.\\nHowever, there are many objects and data\", \" items in a system that do not require an identity and\\nidentity tracking, such as value objects.\\nA v\", \"alue object can reference other entities. For example, in an application that generates a route that\", \"\\ndescribes how to get from one point to another, that route would be a value object. It would be a\\ns\", \"napshot of points on a specific route, but this suggested route would not have an identity, even\\ntho\", \"ugh internally it might refer to entities like City, Road, etc.\\nFigure 7-13 shows the Address value \", \"object within the Order aggregate.\\n213 CHAPTER 6 | Tackle Business Complexity in a Microservice with\", \" DDD and CQRS PatternsFigure 7-13. Address value object within the Order aggregate\\nAs shown in Figur\", \"e 7-13, an entity is usually composed of multiple attributes. For example, the Order\\nentity can be m\", \"odeled as an entity with an identity and composed internally of a set of attributes such\\nas OrderId,\", \" OrderDate, OrderItems, etc. But the address, which is simply a complex-value composed of\\ncountry/re\", \"gion, street, city, etc., and has no identity in this domain, must be modeled and treated as a\\nvalue\", \" object.\\nImportant characteristics of value objects\\nThere are two main characteristics for value obj\", \"ects:\\n\\u2022 They have no identity.\\n\\u2022 They are immutable.\\nThe first characteristic was already discussed.\", \" Immutability is an important requirement. The values of\\na value object must be immutable once the o\", \"bject is created. Therefore, when the object is\\n214 CHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS Patternsconstructed, you must provide the required values, but you must n\", \"ot allow them to change during the\\nobject\\u2019s lifetime.\\nValue objects allow you to perform certain tri\", \"cks for performance, thanks to their immutable nature.\\nThis is especially true in systems where ther\", \"e may be thousands of value object instances, many of\\nwhich have the same values. Their immutable na\", \"ture allows them to be reused; they can be\\ninterchangeable objects, since their values are the same \", \"and they have no identity. This type of\\noptimization can sometimes make a difference between softwar\", \"e that runs slowly and software with\\ngood performance. Of course, all these cases depend on the appl\", \"ication environment and deployment\\ncontext.\\nValue object implementation in C#\\nIn terms of implementa\", \"tion, you can have a value object base class that has basic utility methods like\\nequality based on t\", \"he comparison between all the attributes (since a value object must not be based\\non identity) and ot\", \"her fundamental characteristics. The following example shows a value object base\\nclass used in the o\", \"rdering microservice from eShopOnContainers.\\npublic abstract class ValueObject\\n{\\nprotected static bo\", \"ol EqualOperator(ValueObject left, ValueObject right)\\n{\\nif (ReferenceEquals(left, null) ^ ReferenceE\", \"quals(right, null))\\n{\\nreturn false;\\n}\\nreturn ReferenceEquals(left, right) || left.Equals(right);\\n}\\np\", \"rotected static bool NotEqualOperator(ValueObject left, ValueObject right)\\n{\\nreturn !(EqualOperator(\", \"left, right));\\n}\\nprotected abstract IEnumerable<object> GetEqualityComponents();\\npublic override boo\", \"l Equals(object obj)\\n{\\nif (obj == null || obj.GetType() != GetType())\\n{\\nreturn false;\\n}\\nvar other = \", \"(ValueObject)obj;\\nreturn this.GetEqualityComponents().SequenceEqual(other.GetEqualityComponents());\\n\", \"}\\npublic override int GetHashCode()\\n{\\nreturn GetEqualityComponents()\\n.Select(x => x != null ? x.GetH\", \"ashCode() : 0)\\n.Aggregate((x, y) => x ^ y);\\n}\\n// Other utility methods\\n}\\n215 CHAPTER 6 | Tackle Busi\", \"ness Complexity in a Microservice with DDD and CQRS PatternsThe ValueObject is an abstract class typ\", \"e, but in this example, it doesn\\u2019t overload the == and !=\\noperators. You could choose to do so, maki\", \"ng comparisons delegate to the Equals override. For\\nexample, consider the following operator overloa\", \"ds to the ValueObject type:\\npublic static bool operator ==(ValueObject one, ValueObject two)\\n{\\nretur\", \"n EqualOperator(one, two);\\n}\\npublic static bool operator !=(ValueObject one, ValueObject two)\\n{\\nretu\", \"rn NotEqualOperator(one, two);\\n}\\nYou can use this class when implementing your actual value object, \", \"as with the Address\\nvalue object shown in the following example:\\npublic class Address : ValueObject\\n\", \"{\\npublic String Street { get; private set; }\\npublic String City { get; private set; }\\npublic String \", \"State { get; private set; }\\npublic String Country { get; private set; }\\npublic String ZipCode { get;\", \" private set; }\\npublic Address() { }\\npublic Address(string street, string city, string state, string\", \" country, string\\nzipcode)\\n{\\nStreet = street;\\nCity = city;\\nState = state;\\nCountry = country;\\nZipCode \", \"= zipcode;\\n}\\nprotected override IEnumerable<object> GetEqualityComponents()\\n{\\n// Using a yield retur\", \"n statement to return each element one at a time\\nyield return Street;\\nyield return City;\\nyield retur\", \"n State;\\nyield return Country;\\nyield return ZipCode;\\n}\\n}\\nThis value object implementation of Address\", \" has no identity, and therefore no ID field is defined for it,\\neither in the Address class definitio\", \"n or the ValueObject class definition.\\nHaving no ID field in a class to be used by Entity Framework \", \"(EF) was not possible until EF Core 2.0,\\nwhich greatly helps to implement better value objects with \", \"no ID. That is precisely the explanation of\\nthe next section.\\nIt could be argued that value objects,\", \" being immutable, should be read-only (that is, have get-only\\nproperties), and that\\u2019s indeed true. H\", \"owever, value objects are usually serialized and deserialized to go\\n216 CHAPTER 6 | Tackle Business \", \"Complexity in a Microservice with DDD and CQRS Patternsthrough message queues, and being read-only s\", \"tops the deserializer from assigning values, so you\\njust leave them as private set, which is read-on\", \"ly enough to be practical.\\nValue object comparison semantics\\nTwo instances of the Address type can b\", \"e compared using all the following methods:\\nvar one = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\"\", \", \\\"US\\\", \\\"98052\\\");\\nvar two = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\");\\nConsole.\", \"WriteLine(EqualityComparer<Address>.Default.Equals(one, two)); // True\\nConsole.WriteLine(object.Equa\", \"ls(one, two)); // True\\nConsole.WriteLine(one.Equals(two)); // True\\nConsole.WriteLine(one == two); //\", \" True\\nWhen all the values are the same, the comparisons are correctly evaluated as true. If you didn\", \"\\u2019t choose\\nto overload the == and != operators, then the last comparison of one == two would evaluate\", \" as false.\\nFor more information, see Overload ValueObject equality operators.\\nHow to persist value o\", \"bjects in the database with EF Core 2.0 and later\\nYou just saw how to define a value object in your \", \"domain model. But how can you actually persist it\\ninto the database using Entity Framework Core sinc\", \"e it usually targets entities with identity?\\nBackground and older approaches using EF Core 1.1\\nAs ba\", \"ckground, a limitation when using EF Core 1.0 and 1.1 was that you could not use complex types\\nas de\", \"fined in EF 6.x in the traditional .NET Framework. Therefore, if using EF Core 1.0 or 1.1, you\\nneede\", \"d to store your value object as an EF entity with an ID field. Then, so it looked more like a value\\n\", \"object with no identity, you could hide its ID so you make clear that the identity of a value object\", \" is\\nnot important in the domain model. You could hide that ID by using the ID as a shadow property.\\n\", \"Since that configuration for hiding the ID in the model is set up in the EF infrastructure level, it\", \" would\\nbe kind of transparent for your domain model.\\nIn the initial version of eShopOnContainers (.N\", \"ET Core 1.1), the hidden ID needed by EF Core\\ninfrastructure was implemented in the following way in\", \" the DbContext level, using Fluent API at the\\ninfrastructure project. Therefore, the ID was hidden f\", \"rom the domain model point of view, but still\\npresent in the infrastructure.\\n// Old approach with EF\", \" Core 1.1\\n// Fluent API within the OrderingContext:DbContext in the Infrastructure project\\nvoid Conf\", \"igureAddress(EntityTypeBuilder<Address> addressConfiguration)\\n{\\naddressConfiguration.ToTable(\\\"addres\", \"s\\\", DEFAULT_SCHEMA);\\naddressConfiguration.Property<int>(\\\"Id\\\") // Id is a shadow property\\n.IsRequired\", \"();\\naddressConfiguration.HasKey(\\\"Id\\\"); // Id is a shadow property\\n}\\nHowever, the persistence of that\", \" value object into the database was performed like a regular entity in\\na different table.\\n217 CHAPTE\", \"R 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsWith EF Core 2.0 and la\", \"ter, there are new and better ways to persist value objects.\\nPersist value objects as owned entity t\", \"ypes in EF Core 2.0 and later\\nEven with some gaps between the canonical value object pattern in DDD \", \"and the owned entity type in\\nEF Core, it\\u2019s currently the best way to persist value objects with EF C\", \"ore 2.0 and later. You can see\\nlimitations at the end of this section.\\nThe owned entity type feature\", \" was added to EF Core since version 2.0.\\nAn owned entity type allows you to map types that do not ha\", \"ve their own identity explicitly defined in\\nthe domain model and are used as properties, such as a v\", \"alue object, within any of your entities. An\\nowned entity type shares the same CLR type with another\", \" entity type (that is, it\\u2019s just a regular class).\\nThe entity containing the defining navigation is \", \"the owner entity. When querying the owner, the\\nowned types are included by default.\\nJust by looking \", \"at the domain model, an owned type looks like it doesn\\u2019t have any identity. However,\\nunder the cover\", \"s, owned types do have the identity, but the owner navigation property is part of this\\nidentity.\\nThe\", \" identity of instances of owned types is not completely their own. It consists of three components:\\n\", \"\\u2022 The identity of the owner\\n\\u2022 The navigation property pointing to them\\n\\u2022 In the case of collections \", \"of owned types, an independent component (supported in EF Core\\n2.2 and later).\\nFor example, in the O\", \"rdering domain model at eShopOnContainers, as part of the Order entity, the\\nAddress value object is \", \"implemented as an owned entity type within the owner entity, which is the\\nOrder entity. Address is a\", \" type with no identity property defined in the domain model. It is used as a\\nproperty of the Order t\", \"ype to specify the shipping address for a particular order.\\nBy convention, a shadow primary key is c\", \"reated for the owned type and it will be mapped to the same\\ntable as the owner by using table splitt\", \"ing. This allows to use owned types similarly to how complex\\ntypes are used in EF6 in the traditiona\", \"l .NET Framework.\\nIt is important to note that owned types are never discovered by convention in EF \", \"Core, so you have\\nto declare them explicitly.\\nIn eShopOnContainers, in the OrderingContext.cs file, \", \"within the OnModelCreating() method, multiple\\ninfrastructure configurations are applied. One of them\", \" is related to the Order entity.\\n// Part of the OrderingContext.cs class at the Ordering.Infrastruct\", \"ure project\\n//\\nprotected override void OnModelCreating(ModelBuilder modelBuilder)\\n{\\nmodelBuilder.App\", \"lyConfiguration(new ClientRequestEntityTypeConfiguration());\\nmodelBuilder.ApplyConfiguration(new Pay\", \"mentMethodEntityTypeConfiguration());\\nmodelBuilder.ApplyConfiguration(new OrderEntityTypeConfigurati\", \"on());\\nmodelBuilder.ApplyConfiguration(new OrderItemEntityTypeConfiguration());\\n//...Additional type\", \" configurations\\n}\\n218 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pat\", \"ternsIn the following code, the persistence infrastructure is defined for the Order entity:\\n// Part \", \"of the OrderEntityTypeConfiguration.cs class\\n//\\npublic void Configure(EntityTypeBuilder<Order> order\", \"Configuration)\\n{\\norderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_SCHEMA);\\norderConfigur\", \"ation.HasKey(o => o.Id);\\norderConfiguration.Ignore(b => b.DomainEvents);\\norderConfiguration.Property\", \"(o => o.Id)\\n.ForSqlServerUseSequenceHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA);\\n//Address valu\", \"e object persisted as owned entity in EF Core 2.0\\norderConfiguration.OwnsOne(o => o.Address);\\norderC\", \"onfiguration.Property<DateTime>(\\\"OrderDate\\\").IsRequired();\\n//...Additional validations, constraints \", \"and code...\\n//...\\n}\\nIn the previous code, the orderConfiguration.OwnsOne(o => o.Address) method spec\", \"ifies that the\\nAddress property is an owned entity of the Order type.\\nBy default, EF Core convention\", \"s name the database columns for the properties of the owned entity\\ntype as EntityProperty_OwnedEntit\", \"yProperty. Therefore, the internal properties of Address will appear\\nin the Orders table with the na\", \"mes Address_Street, Address_City (and so on for State, Country, and\\nZipCode).\\nYou can append the Pro\", \"perty().HasColumnName() fluent method to rename those columns. In the\\ncase where Address is a public\", \" property, the mappings would be like the following:\\norderConfiguration.OwnsOne(p => p.Address)\\n.Pro\", \"perty(p=>p.Street).HasColumnName(\\\"ShippingStreet\\\");\\norderConfiguration.OwnsOne(p => p.Address)\\n.Prop\", \"erty(p=>p.City).HasColumnName(\\\"ShippingCity\\\");\\nIt\\u2019s possible to chain the OwnsOne method in a fluent\", \" mapping. In the following hypothetical\\nexample, OrderDetails owns BillingAddress and ShippingAddres\", \"s, which are both Address types. Then\\nOrderDetails is owned by the Order type.\\norderConfiguration.Ow\", \"nsOne(p => p.OrderDetails, cb =>\\n{\\ncb.OwnsOne(c => c.BillingAddress);\\ncb.OwnsOne(c => c.ShippingAddr\", \"ess);\\n});\\n//...\\n//...\\npublic class Order\\n{\\npublic int Id { get; set; }\\npublic OrderDetails OrderDeta\", \"ils { get; set; }\\n}\\npublic class OrderDetails\\n{\\npublic Address BillingAddress { get; set; }\\n219 CHAP\", \"TER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternspublic Address Shippi\", \"ngAddress { get; set; }\\n}\\npublic class Address\\n{\\npublic string Street { get; set; }\\npublic string Ci\", \"ty { get; set; }\\n}\\nAdditional details on owned entity types\\n\\u2022 Owned types are defined when you confi\", \"gure a navigation property to a particular type using\\nthe OwnsOne fluent API.\\n\\u2022 The definition of an\", \" owned type in our metadata model is a composite of: the owner type, the\\nnavigation property, and th\", \"e CLR type of the owned type.\\n\\u2022 The identity (key) of an owned type instance in our stack is a compo\", \"site of the identity of the\\nowner type and the definition of the owned type.\\nOwned entities capabili\", \"ties\\n\\u2022 Owned types can reference other entities, either owned (nested owned types) or non-owned\\n(reg\", \"ular reference navigation properties to other entities).\\n\\u2022 You can map the same CLR type as differen\", \"t owned types in the same owner entity through\\nseparate navigation properties.\\n\\u2022 Table splitting is \", \"set up by convention, but you can opt out by mapping the owned type to a\\ndifferent table using ToTab\", \"le.\\n\\u2022 Eager loading is performed automatically on owned types, that is, there\\u2019s no need to call\\n.Inc\", \"lude() on the query.\\n\\u2022 Can be configured with attribute [Owned], using EF Core 2.1 and later.\\n\\u2022 Can \", \"handle collections of owned types (using version 2.2 and later).\\nOwned entities limitations\\n\\u2022 You ca\", \"n\\u2019t create a DbSet<T> of an owned type (by design).\\n\\u2022 You can\\u2019t call ModelBuilder.Entity<T>() on own\", \"ed types (currently by design).\\n\\u2022 No support for optional (that is, nullable) owned types that are m\", \"apped with the owner in the\\nsame table (that is, using table splitting). This is because mapping is \", \"done for each property,\\nthere is no separate sentinel for the null complex value as a whole.\\n\\u2022 No in\", \"heritance-mapping support for owned types, but you should be able to map two leaf\\ntypes of the same \", \"inheritance hierarchies as different owned types. EF Core will not reason\\nabout the fact that they a\", \"re part of the same hierarchy.\\n220 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS PatternsMain differences with EF6\\u2019s complex types\\n\\u2022 Table splitting is optional, that is, \", \"they can optionally be mapped to a separate table and still\\nbe owned types.\\nAdditional resources\\n\\u2022 M\", \"artin Fowler. ValueObject pattern\\nhttps://martinfowler.com/bliki/ValueObject.html\\n\\u2022 Eric Evans. Doma\", \"in-Driven Design: Tackling Complexity in the Heart of Software. (Book;\\nincludes a discussion of valu\", \"e objects)\\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/\\n\", \"\\u2022 Vaughn Vernon. Implementing Domain-Driven Design. (Book; includes a discussion of\\nvalue objects)\\nh\", \"ttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\nVernon/dp/0321834577/\\n\\u2022 Owned Entity\", \" Types\\nhttps://learn.microsoft.com/ef/core/modeling/owned-entities\\n\\u2022 Shadow Properties\\nhttps://learn\", \".microsoft.com/ef/core/modeling/shadow-properties\\n\\u2022 Complex types and/or value objects. Discussion i\", \"n the EF Core GitHub repo (Issues tab)\\nhttps://github.com/dotnet/efcore/issues/246\\n\\u2022 ValueObject.cs.\", \" Base value object class in eShopOnContainers.\\nhttps://github.com/dotnet-\\narchitecture/eShopOnContai\", \"ners/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\\nk/ValueObject.cs\\n\\u2022 ValueObject.cs. Base \", \"value object class in CSharpFunctionalExtensions.\\nhttps://github.com/vkhorikov/CSharpFunctionalExten\", \"sions/blob/master/CSharpFunctionalExte\\nnsions/ValueObject/ValueObject.cs\\n\\u2022 Address class. Sample val\", \"ue object class in eShopOnContainers.\\nhttps://github.com/dotnet-\\narchitecture/eShopOnContainers/blob\", \"/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesModel/OrderAggregate/Address.cs\\nUse enumeratio\", \"n classes instead of enum types\\nEnumerations (or enum types for short) are a thin language wrapper a\", \"round an integral type. You\\nmight want to limit their use to when you are storing one value from a c\", \"losed set of values.\\nClassification based on sizes (small, medium, large) is a good example. Using e\", \"nums for control flow\\nor more robust abstractions can be a code smell. This type of usage leads to f\", \"ragile code with many\\ncontrol flow statements checking values of the enum.\\n221 CHAPTER 6 | Tackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS PatternsInstead, you can create Enumeration cl\", \"asses that enable all the rich features of an object-oriented\\nlanguage.\\nHowever, this isn\\u2019t a critic\", \"al topic and in many cases, for simplicity, you can still use regular enum\\ntypes if that\\u2019s your pref\", \"erence. The use of enumeration classes is more related to business-related\\nconcepts.\\nImplement an En\", \"umeration base class\\nThe ordering microservice in eShopOnContainers provides a sample Enumeration ba\", \"se class\\nimplementation, as shown in the following example:\\npublic abstract class Enumeration : ICom\", \"parable\\n{\\npublic string Name { get; private set; }\\npublic int Id { get; private set; }\\nprotected Enu\", \"meration(int id, string name) => (Id, Name) = (id, name);\\npublic override string ToString() => Name;\", \"\\npublic static IEnumerable<T> GetAll<T>() where T : Enumeration =>\\ntypeof(T).GetFields(BindingFlags.\", \"Public |\\nBindingFlags.Static |\\nBindingFlags.DeclaredOnly)\\n.Select(f => f.GetValue(null))\\n.Cast<T>();\", \"\\npublic override bool Equals(object obj)\\n{\\nif (obj is not Enumeration otherValue)\\n{\\nreturn false;\\n}\\n\", \"var typeMatches = GetType().Equals(obj.GetType());\\nvar valueMatches = Id.Equals(otherValue.Id);\\nretu\", \"rn typeMatches && valueMatches;\\n}\\npublic int CompareTo(object other) => Id.CompareTo(((Enumeration)o\", \"ther).Id);\\n// Other utility methods ...\\n}\\nYou can use this class as a type in any entity or value ob\", \"ject, as for the following\\nCardType : Enumeration class:\\npublic class CardType\\n: Enumeration\\n{\\npubli\", \"c static CardType Amex = new(1, nameof(Amex));\\npublic static CardType Visa = new(2, nameof(Visa));\\np\", \"ublic static CardType MasterCard = new(3, nameof(MasterCard));\\npublic CardType(int id, string name)\\n\", \": base(id, name)\\n{\\n222 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pa\", \"tterns}\\n}\\nAdditional resources\\n\\u2022 Jimmy Bogard. Enumeration classes\\nhttps://lostechies.com/jimmybogar\", \"d/2008/08/12/enumeration-classes/\\n\\u2022 Steve Smith. Enum Alternatives in C#\\nhttps://ardalis.com/enum-al\", \"ternatives-in-c\\n\\u2022 Enumeration.cs. Base Enumeration class in eShopOnContainers\\nhttps://github.com/dot\", \"net-\\narchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\\nk/Enumera\", \"tion.cs\\n\\u2022 CardType.cs. Sample Enumeration class in eShopOnContainers.\\nhttps://github.com/dotnet-\\narc\", \"hitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesModel/BuyerAgg\", \"regate/CardType.cs\\n\\u2022 SmartEnum. Ardalis - Classes to help produce strongly typed smarter enums in .N\", \"ET.\\nhttps://www.nuget.org/packages/Ardalis.SmartEnum/\\nDesign validations in the domain model layer\\nI\", \"n DDD, validation rules can be thought as invariants. The main responsibility of an aggregate is to\\n\", \"enforce invariants across state changes for all the entities within that aggregate.\\nDomain entities \", \"should always be valid entities. There are a certain number of invariants for an object\\nthat should \", \"always be true. For example, an order item object always has to have a quantity that must\\nbe a posit\", \"ive integer, plus an article name and price. Therefore, invariants enforcement is the\\nresponsibility\", \" of the domain entities (especially of the aggregate root) and an entity object should not\\nbe able t\", \"o exist without being valid. Invariant rules are simply expressed as contracts, and exceptions\\nor no\", \"tifications are raised when they are violated.\\nThe reasoning behind this is that many bugs occur bec\", \"ause objects are in a state they should never\\nhave been in.\\nLet\\u2019s propose we now have a SendUserCrea\", \"tionEmailService that takes a UserProfile \\u2026 how can we\\nrationalize in that service that Name is not \", \"null? Do we check it again? Or more likely \\u2026 you just don\\u2019t\\nbother to check and \\u201chope for the best\\u201d\\u2014\", \"you hope that someone bothered to validate it before\\nsending it to you. Of course, using TDD one of \", \"the first tests we should be writing is that if I send a\\ncustomer with a null name that it should ra\", \"ise an error. But once we start writing these kinds of tests\\nover and over again we realize \\u2026 \\u201cwhat \", \"if we never allowed name to become null? we wouldn\\u2019t have\\nall of these tests!\\u201d.\\n223 CHAPTER 6 | Tack\", \"le Business Complexity in a Microservice with DDD and CQRS PatternsImplement validations in the doma\", \"in model layer\\nValidations are usually implemented in domain entity constructors or in methods that \", \"can update the\\nentity. There are multiple ways to implement validations, such as verifying data and \", \"raising exceptions\\nif the validation fails. There are also more advanced patterns such as using the \", \"Specification pattern\\nfor validations, and the Notification pattern to return a collection of errors\", \" instead of returning an\\nexception for each validation as it occurs.\\nValidate conditions and throw e\", \"xceptions\\nThe following code example shows the simplest approach to validation in a domain entity by\", \" raising\\nan exception. In the references table at the end of this section you can see links to more \", \"advanced\\nimplementations based on the patterns we have discussed previously.\\npublic void SetAddress(\", \"Address address)\\n{\\n_shippingAddress = address?? throw new ArgumentNullException(nameof(address));\\n}\\n\", \"A better example would demonstrate the need to ensure that either the internal state did\\nnot change,\", \" or that all the mutations for a method occurred. For example, the following\\nimplementation would le\", \"ave the object in an invalid state:\\npublic void SetAddress(string line1, string line2,\\nstring city, \", \"string state, int zip)\\n{\\n_shippingAddress.line1 = line1 ?? throw new ...\\n_shippingAddress.line2 = li\", \"ne2;\\n_shippingAddress.city = city ?? throw new ...\\n_shippingAddress.state = (IsValid(state) ? state \", \": throw new \\u2026);\\n}\\nIf the value of the state is invalid, the first address line and the city have alr\", \"eady been changed. That\\nmight make the address invalid.\\nA similar approach can be used in the entity\", \"\\u2019s constructor, raising an exception to make sure that the\\nentity is valid once it is created.\\nUse v\", \"alidation attributes in the model based on data annotations\\nData annotations, like the Required or M\", \"axLength attributes, can be used to configure EF Core\\ndatabase field properties, as explained in det\", \"ail in the Table mapping section, but they no longer work\\nfor entity validation in EF Core (neither \", \"does the IValidatableObject.Validate method), as they have\\ndone since EF 4.x in .NET Framework.\\nData\", \" annotations and the IValidatableObject interface can still be used for model validation during\\nmode\", \"l binding, prior to the controller\\u2019s actions invocation as usual, but that model is meant to be a\\nVi\", \"ewModel or DTO and that\\u2019s an MVC or API concern not a domain model concern.\\nHaving made the conceptu\", \"al difference clear, you can still use data annotations and\\nIValidatableObject in the entity class f\", \"or validation, if your actions receive an entity class object\\nparameter, which is not recommended. I\", \"n that case, validation will occur upon model binding, just\\nbefore invoking the action and you can c\", \"heck the controller\\u2019s ModelState.IsValid property to check\\n224 CHAPTER 6 | Tackle Business Complexit\", \"y in a Microservice with DDD and CQRS Patternsthe result, but then again, it happens in the controll\", \"er, not before persisting the entity object in the\\nDbContext, as it had done since EF 4.x.\\nYou can s\", \"till implement custom validation in the entity class using data annotations and the\\nIValidatableObje\", \"ct.Validate method, by overriding the DbContext\\u2019s SaveChanges method.\\nYou can see a sample implement\", \"ation for validating IValidatableObject entities in this comment on\\nGitHub. That sample doesn\\u2019t do a\", \"ttribute-based validations, but they should be easy to implement\\nusing reflection in the same overri\", \"de.\\nHowever, from a DDD point of view, the domain model is best kept lean with the use of exceptions\", \" in\\nyour entity\\u2019s behavior methods, or by implementing the Specification and Notification patterns t\", \"o\\nenforce validation rules.\\nIt can make sense to use data annotations at the application layer in Vi\", \"ewModel classes (instead of\\ndomain entities) that will accept input, to allow for model validation w\", \"ithin the UI layer. However, this\\nshould not be done at the exclusion of validation within the domai\", \"n model.\\nValidate entities by implementing the Specification pattern and the Notification\\npattern\\nFi\", \"nally, a more elaborate approach to implementing validations in the domain model is by\\nimplementing \", \"the Specification pattern in conjunction with the Notification pattern, as explained in\\nsome of the \", \"additional resources listed later.\\nIt is worth mentioning that you can also use just one of those pa\", \"tterns\\u2014for example, validating\\nmanually with control statements, but using the Notification pattern \", \"to stack and return a list of\\nvalidation errors.\\nUse deferred validation in the domain\\nThere are var\", \"ious approaches to deal with deferred validations in the domain. In his book\\nImplementing Domain-Dri\", \"ven Design, Vaughn Vernon discusses these in the section on validation.\\nTwo-step validation\\nAlso con\", \"sider two-step validation. Use field-level validation on your command Data Transfer Objects\\n(DTOs) a\", \"nd domain-level validation inside your entities. You can do this by returning a result object\\ninstea\", \"d of exceptions in order to make it easier to deal with the validation errors.\\nUsing field validatio\", \"n with data annotations, for example, you do not duplicate the validation\\ndefinition. The execution,\", \" though, can be both server-side and client-side in the case of DTOs\\n(commands and ViewModels, for i\", \"nstance).\\nAdditional resources\\n\\u2022 Rachel Appel. Introduction to model validation in ASP.NET Core MVC\\n\", \"https://learn.microsoft.com/aspnet/core/mvc/models/validation\\n\\u2022 Rick Anderson. Adding validation\\nhtt\", \"ps://learn.microsoft.com/aspnet/core/tutorials/first-mvc-app/validation\\n225 CHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns\\u2022 Martin Fowler. Replacing Throwing Excep\", \"tions with Notification in Validations\\nhttps://martinfowler.com/articles/replaceThrowWithNotificatio\", \"n.html\\n\\u2022 Specification and Notification Patterns\\nhttps://www.codeproject.com/Tips/790758/Specificati\", \"on-and-Notification-Patterns\\n\\u2022 Lev Gorodinski. Validation in Domain-Driven Design (DDD)\\nhttp://gorod\", \"inski.com/blog/2012/05/19/validation-in-domain-driven-design-ddd/\\n\\u2022 Colin Jack. Domain Model Validat\", \"ion\\nhttps://colinjack.blogspot.com/2008/03/domain-model-validation.html\\n\\u2022 Jimmy Bogard. Validation i\", \"n a DDD world\\nhttps://lostechies.com/jimmybogard/2009/02/15/validation-in-a-ddd-world/\\nClient-side v\", \"alidation (validation in the presentation\\nlayers)\\nEven when the source of truth is the domain model \", \"and ultimately you must have validation at the\\ndomain model level, validation can still be handled a\", \"t both the domain model level (server side) and\\nthe UI (client side).\\nClient-side validation is a gr\", \"eat convenience for users. It saves time they would otherwise spend\\nwaiting for a round trip to the \", \"server that might return validation errors. In business terms, even a few\\nfractions of seconds multi\", \"plied hundreds of times each day adds up to a lot of time, expense, and\\nfrustration. Straightforward\", \" and immediate validation enables users to work more efficiently and\\nproduce better quality input an\", \"d output.\\nJust as the view model and the domain model are different, view model validation and domai\", \"n model\\nvalidation might be similar but serve a different purpose. If you are concerned about DRY (t\", \"he Don\\u2019t\\nRepeat Yourself principle), consider that in this case code reuse might also mean coupling,\", \" and in\\nenterprise applications it is more important not to couple the server side to the client sid\", \"e than to\\nfollow the DRY principle.\\nEven when using client-side validation, you should always valida\", \"te your commands or input DTOs in\\nserver code, because the server APIs are a possible attack vector.\", \" Usually, doing both is your best bet\\nbecause if you have a client application, from a UX perspectiv\", \"e, it is best to be proactive and not allow\\nthe user to enter invalid information.\\nTherefore, in cli\", \"ent-side code you typically validate the ViewModels. You could also validate the client\\noutput DTOs \", \"or commands before you send them to the services.\\nThe implementation of client-side validation depen\", \"ds on what kind of client application you are\\nbuilding. It will be different if you are validating d\", \"ata in a web MVC web application with most of the\\ncode in .NET, a SPA web application with that vali\", \"dation being coded in JavaScript or TypeScript, or a\\nmobile app coded with Xamarin and C#.\\n226 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAdditional resources\\nV\", \"alidation in Xamarin mobile apps\\n\\u2022 Validate Text Input and Show Errors\\nhttps://developer.xamarin.com\", \"/recipes/ios/standard_controls/text_field/validate_input/\\n\\u2022 Validation Callback\\nhttps://developer.xa\", \"marin.com/samples/xamarin-forms/XAML/ValidationCallback/\\nValidation in ASP.NET Core apps\\n\\u2022 Rick Ande\", \"rson. Adding validation\\nhttps://learn.microsoft.com/aspnet/core/tutorials/first-mvc-app/validation\\nV\", \"alidation in SPA Web apps (Angular 2, TypeScript, JavaScript, Blazor\\nWebAssembly)\\n\\u2022 Form Validation\\n\", \"https://angular.io/guide/form-validation\\n\\u2022 Validation. Breeze documentation.\\nhttps://breeze.github.i\", \"o/doc-js/validation.html\\n\\u2022 ASP.NET Core Blazor forms and input components\\nIn summary, these are the \", \"most important concepts in regards to validation:\\n\\u2022 Entities and aggregates should enforce their own\", \" consistency and be \\u201calways valid\\u201d.\\nAggregate roots are responsible for multi-entity consistency wit\", \"hin the same aggregate.\\n\\u2022 If you think that an entity needs to enter an invalid state, consider usin\", \"g a different object\\nmodel\\u2014for example, using a temporary DTO until you create the final domain enti\", \"ty.\\n\\u2022 If you need to create several related objects, such as an aggregate, and they are only valid\\no\", \"nce all of them have been created, consider using the Factory pattern.\\n\\u2022 In most of the cases, havin\", \"g redundant validation in the client side is good, because the\\napplication can be proactive.\\nDomain \", \"events: Design and implementation\\nUse domain events to explicitly implement side effects of changes \", \"within your domain. In other words,\\nand using DDD terminology, use domain events to explicitly imple\", \"ment side effects across multiple\\naggregates. Optionally, for better scalability and less impact in \", \"database locks, use eventual\\nconsistency between aggregates within the same domain.\\n227 CHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS PatternsWhat is a domain event?\\nAn ev\", \"ent is something that has happened in the past. A domain event is, something that happened in\\nthe do\", \"main that you want other parts of the same domain (in-process) to be aware of. The notified\\nparts us\", \"ually react somehow to the events.\\nAn important benefit of domain events is that side effects can be\", \" expressed explicitly.\\nFor example, if you\\u2019re just using Entity Framework and there has to be a reac\", \"tion to some event, you\\nwould probably code whatever you need close to what triggers the event. So t\", \"he rule gets coupled,\\nimplicitly, to the code, and you have to look into the code to, hopefully, rea\", \"lize the rule is\\nimplemented there.\\nOn the other hand, using domain events makes the concept explici\", \"t, because there\\u2019s a DomainEvent\\nand at least one DomainEventHandler involved.\\nFor example, in the e\", \"ShopOnContainers application, when an order is created, the user becomes a\\nbuyer, so an OrderStarted\", \"DomainEvent is raised and handled in the\\nValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandl\", \"er, so the underlying concept is\\nevident.\\nIn short, domain events help you to express, explicitly, t\", \"he domain rules, based in the ubiquitous\\nlanguage provided by the domain experts. Domain events also\", \" enable a better separation of concerns\\namong classes within the same domain.\\nIt\\u2019s important to ensu\", \"re that, just like a database transaction, either all the operations related to a\\ndomain event finis\", \"h successfully or none of them do.\\nDomain events are similar to messaging-style events, with one imp\", \"ortant difference. With real\\nmessaging, message queuing, message brokers, or a service bus using AMQ\", \"P, a message is always\\nsent asynchronously and communicated across processes and machines. This is u\", \"seful for integrating\\nmultiple Bounded Contexts, microservices, or even different applications. Howe\", \"ver, with domain\\nevents, you want to raise an event from the domain operation you\\u2019re currently runni\", \"ng, but you want\\nany side effects to occur within the same domain.\\nThe domain events and their side \", \"effects (the actions triggered afterwards that are managed by event\\nhandlers) should occur almost im\", \"mediately, usually in-process, and within the same domain. Thus,\\ndomain events could be synchronous \", \"or asynchronous. Integration events, however, should always be\\nasynchronous.\\nDomain events versus in\", \"tegration events\\nSemantically, domain and integration events are the same thing: notifications about\", \" something that\\njust happened. However, their implementation must be different. Domain events are ju\", \"st messages\\npushed to a domain event dispatcher, which could be implemented as an in-memory mediator\", \" based\\non an IoC container or any other method.\\nOn the other hand, the purpose of integration events\", \" is to propagate committed transactions and\\nupdates to additional subsystems, whether they are other\", \" microservices, Bounded Contexts or even\\n228 CHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS Patternsexternal applications. Hence, they should occur only if the entity is su\", \"ccessfully persisted, otherwise it\\u2019s\\nas if the entire operation never happened.\\nAs mentioned before,\", \" integration events must be based on asynchronous communication between\\nmultiple microservices (othe\", \"r Bounded Contexts) or even external systems/applications.\\nThus, the event bus interface needs some \", \"infrastructure that allows inter-process and distributed\\ncommunication between potentially remote se\", \"rvices. It can be based on a commercial service bus,\\nqueues, a shared database used as a mailbox, or\", \" any other distributed and ideally push based\\nmessaging system.\\nDomain events as a preferred way to \", \"trigger side effects across\\nmultiple aggregates within the same domain\\nIf executing a command relate\", \"d to one aggregate instance requires additional domain rules to be run\\non one or more additional agg\", \"regates, you should design and implement those side effects to be\\ntriggered by domain events. As sho\", \"wn in Figure 7-14, and as one of the most important use cases, a\\ndomain event should be used to prop\", \"agate state changes across multiple aggregates within the same\\ndomain model.\\nFigure 7-14. Domain eve\", \"nts to enforce consistency between multiple aggregates within the same domain\\nFigure 7-14 shows how \", \"consistency between aggregates is achieved by domain events. When the user\\ninitiates an order, the O\", \"rder Aggregate sends an OrderStarted domain event. The OrderStarted\\ndomain event is handled by the B\", \"uyer Aggregate to create a Buyer object in the ordering\\nmicroservice, based on the original user inf\", \"o from the identity microservice (with information provided\\nin the CreateOrder command).\\nAlternately\", \", you can have the aggregate root subscribed for events raised by members of its\\naggregates (child e\", \"ntities). For instance, each OrderItem child entity can raise an event when the item\\nprice is higher\", \" than a specific amount, or when the product item amount is too high. The aggregate\\nroot can then re\", \"ceive those events and perform a global calculation or aggregation.\\n229 CHAPTER 6 | Tackle Business \", \"Complexity in a Microservice with DDD and CQRS PatternsIt\\u2019s important to understand that this event-\", \"based communication is not implemented directly within\\nthe aggregates; you need to implement domain \", \"event handlers.\\nHandling the domain events is an application concern. The domain model layer should \", \"only focus on\\nthe domain logic\\u2014things that a domain expert would understand, not application infrast\", \"ructure like\\nhandlers and side-effect persistence actions using repositories. Therefore, the applica\", \"tion layer level is\\nwhere you should have domain event handlers triggering actions when a domain eve\", \"nt is raised.\\nDomain events can also be used to trigger any number of application actions, and what \", \"is more\\nimportant, must be open to increase that number in the future in a decoupled way. For instan\", \"ce, when\\nthe order is started, you might want to publish a domain event to propagate that info to ot\", \"her\\naggregates or even to raise application actions like notifications.\\nThe key point is the open nu\", \"mber of actions to be executed when a domain event occurs. Eventually,\\nthe actions and rules in the \", \"domain and application will grow. The complexity or number of side-\\neffect actions when something ha\", \"ppens will grow, but if your code were coupled with \\u201cglue\\u201d (that is,\\ncreating specific objects with \", \"new), then every time you needed to add a new action you would also\\nneed to change working and teste\", \"d code.\\nThis change could result in new bugs and this approach also goes against the Open/Closed pri\", \"nciple\\nfrom SOLID. Not only that, the original class that was orchestrating the operations would gro\", \"w and\\ngrow, which goes against the Single Responsibility Principle (SRP).\\nOn the other hand, if you \", \"use domain events, you can create a fine-grained and decoupled\\nimplementation by segregating respons\", \"ibilities using this approach:\\n1. Send a command (for example, CreateOrder).\\n2. Receive the command \", \"in a command handler.\\n\\u2013 Execute a single aggregate\\u2019s transaction.\\n\\u2013 (Optional) Raise domain events f\", \"or side effects (for example,\\nOrderStartedDomainEvent).\\n3. Handle domain events (within the current \", \"process) that will execute an open number of side\\neffects in multiple aggregates or application acti\", \"ons. For example:\\n\\u2013 Verify or create buyer and payment method.\\n\\u2013 Create and send a related integrati\", \"on event to the event bus to propagate states\\nacross microservices or trigger external actions like \", \"sending an email to the buyer.\\n\\u2013 Handle other side effects.\\nAs shown in Figure 7-15, starting from t\", \"he same domain event, you can handle multiple actions\\nrelated to other aggregates in the domain or a\", \"dditional application actions you need to perform\\nacross microservices connecting with integration e\", \"vents and the event bus.\\n230 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS PatternsFigure 7-15. Handling multiple actions per domain\\nThere can be several handlers for the \", \"same domain event in the Application Layer, one handler can\\nsolve consistency between aggregates and\", \" another handler can publish an integration event, so other\\nmicroservices can do something with it. \", \"The event handlers are typically in the application layer,\\nbecause you\\u2019ll use infrastructure objects\", \" like repositories or an application API for the microservice\\u2019s\\nbehavior. In that sense, event handl\", \"ers are similar to command handlers, so both are part of the\\napplication layer. The important differ\", \"ence is that a command should be processed only once. A\\ndomain event could be processed zero or n ti\", \"mes, because it can be received by multiple receivers or\\nevent handlers with a different purpose for\", \" each handler.\\nHaving an open number of handlers per domain event allows you to add as many domain r\", \"ules as\\nneeded, without affecting current code. For instance, implementing the following business ru\", \"le might\\nbe as easy as adding a few event handlers (or even just one):\\nWhen the total amount purchas\", \"ed by a customer in the store, across any number of orders, exceeds\\n$6,000, apply a 10% off discount\", \" to every new order and notify the customer with an email about that\\ndiscount for future orders.\\nImp\", \"lement domain events\\nIn C#, a domain event is simply a data-holding structure or class, like a DTO, \", \"with all the information\\nrelated to what just happened in the domain, as shown in the following exam\", \"ple:\\npublic class OrderStartedDomainEvent : INotification\\n{\\npublic string UserId { get; }\\npublic str\", \"ing UserName { get; }\\npublic int CardTypeId { get; }\\npublic string CardNumber { get; }\\npublic string\", \" CardSecurityNumber { get; }\\n231 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD a\", \"nd CQRS Patternspublic string CardHolderName { get; }\\npublic DateTime CardExpiration { get; }\\npublic\", \" Order Order { get; }\\npublic OrderStartedDomainEvent(Order order, string userId, string userName,\\nin\", \"t cardTypeId, string cardNumber,\\nstring cardSecurityNumber, string cardHolderName,\\nDateTime cardExpi\", \"ration)\\n{\\nOrder = order;\\nUserId = userId;\\nUserName = userName;\\nCardTypeId = cardTypeId;\\nCardNumber =\", \" cardNumber;\\nCardSecurityNumber = cardSecurityNumber;\\nCardHolderName = cardHolderName;\\nCardExpiratio\", \"n = cardExpiration;\\n}\\n}\\nThis is essentially a class that holds all the data related to the OrderStar\", \"ted event.\\nIn terms of the ubiquitous language of the domain, since an event is something that happe\", \"ned in the\\npast, the class name of the event should be represented as a past-tense verb, like\\nOrderS\", \"tartedDomainEvent or OrderShippedDomainEvent. That\\u2019s how the domain event is\\nimplemented in the orde\", \"ring microservice in eShopOnContainers.\\nAs noted earlier, an important characteristic of events is t\", \"hat since an event is something that\\nhappened in the past, it shouldn\\u2019t change. Therefore, it must b\", \"e an immutable class. You can see in\\nthe previous code that the properties are read-only. There\\u2019s no\", \" way to update the object, you can only\\nset values when you create it.\\nIt\\u2019s important to highlight h\", \"ere that if domain events were to be handled asynchronously, using a\\nqueue that required serializing\", \" and deserializing the event objects, the properties would have to be\\n\\u201cprivate set\\u201d instead of read-\", \"only, so the deserializer would be able to assign the values upon\\ndequeuing. This is not an issue in\", \" the Ordering microservice, as the domain event pub/sub is\\nimplemented synchronously using MediatR.\\n\", \"Raise domain events\\nThe next question is how to raise a domain event so it reaches its related event\", \" handlers. You can use\\nmultiple approaches.\\nUdi Dahan originally proposed (for example, in several r\", \"elated posts, such as Domain Events \\u2013 Take 2)\\nusing a static class for managing and raising the even\", \"ts. This might include a static class named\\nDomainEvents that would raise domain events immediately \", \"when it\\u2019s called, using syntax like\\nDomainEvents.Raise(Event myEvent). Jimmy Bogard wrote a blog pos\", \"t (Strengthening your domain:\\nDomain Events) that recommends a similar approach.\\nHowever, when the d\", \"omain events class is static, it also dispatches to handlers immediately. This\\nmakes testing and deb\", \"ugging more difficult, because the event handlers with side-effects logic are\\nexecuted immediately a\", \"fter the event is raised. When you\\u2019re testing and debugging, you just want to\\nfocus on what is happe\", \"ning in the current aggregate classes; you don\\u2019t want to suddenly be\\n232 CHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS Patternsredirected to other event handlers for side \", \"effects related to other aggregates or application logic.\\nThis is why other approaches have evolved,\", \" as explained in the next section.\\nThe deferred approach to raise and dispatch events\\nInstead of dis\", \"patching to a domain event handler immediately, a better approach is to add the\\ndomain events to a c\", \"ollection and then to dispatch those domain events right before or right after\\ncommitting the transa\", \"ction (as with SaveChanges in EF). (This approach was described by Jimmy\\nBogard in this post A bette\", \"r domain events pattern.)\\nDeciding if you send the domain events right before or right after committ\", \"ing the transaction is\\nimportant, since it determines whether you will include the side effects as p\", \"art of the same transaction\\nor in different transactions. In the latter case, you need to deal with \", \"eventual consistency across\\nmultiple aggregates. This topic is discussed in the next section.\\nThe de\", \"ferred approach is what eShopOnContainers uses. First, you add the events happening in your\\nentities\", \" into a collection or list of events per entity. That list should be part of the entity object, or\\ne\", \"ven better, part of your base entity class, as shown in the following example of the Entity base cla\", \"ss:\\npublic abstract class Entity\\n{\\n//...\\nprivate List<INotification> _domainEvents;\\npublic List<INot\", \"ification> DomainEvents => _domainEvents;\\npublic void AddDomainEvent(INotification eventItem)\\n{\\n_dom\", \"ainEvents = _domainEvents ?? new List<INotification>();\\n_domainEvents.Add(eventItem);\\n}\\npublic void \", \"RemoveDomainEvent(INotification eventItem)\\n{\\n_domainEvents?.Remove(eventItem);\\n}\\n//... Additional co\", \"de\\n}\\nWhen you want to raise an event, you just add it to the event collection from code at any metho\", \"d of\\nthe aggregate-root entity.\\nThe following code, part of the Order aggregate-root at eShopOnConta\", \"iners, shows an example:\\nvar orderStartedDomainEvent = new OrderStartedDomainEvent(this, //Order obj\", \"ect\\ncardTypeId, cardNumber,\\ncardSecurityNumber,\\ncardHolderName,\\ncardExpiration);\\nthis.AddDomainEvent\", \"(orderStartedDomainEvent);\\nNotice that the only thing that the AddDomainEvent method is doing is add\", \"ing an event to the list.\\nNo event is dispatched yet, and no event handler is invoked yet.\\n233 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsYou actually want to d\", \"ispatch the events later on, when you commit the transaction to the database. If\\nyou are using Entit\", \"y Framework Core, that means in the SaveChanges method of your EF DbContext,\\nas in the following cod\", \"e:\\n// EF Core DbContext\\npublic class OrderingContext : DbContext, IUnitOfWork\\n{\\n// ...\\npublic async \", \"Task<bool> SaveEntitiesAsync(CancellationToken cancellationToken =\\ndefault(CancellationToken))\\n{\\n// \", \"Dispatch Domain Events collection.\\n// Choices:\\n// A) Right BEFORE committing data (EF SaveChanges) i\", \"nto the DB. This makes\\n// a single transaction including side effects from the domain event\\n// handl\", \"ers that are using the same DbContext with Scope lifetime\\n// B) Right AFTER committing data (EF Save\", \"Changes) into the DB. This makes\\n// multiple transactions. You will need to handle eventual consiste\", \"ncy and\\n// compensatory actions in case of failures.\\nawait _mediator.DispatchDomainEventsAsync(this)\", \";\\n// After this line runs, all the changes (from the Command Handler and Domain\\n// event handlers) p\", \"erformed through the DbContext will be committed\\nvar result = await base.SaveChangesAsync();\\n}\\n}\\nWit\", \"h this code, you dispatch the entity events to their respective event handlers.\\nThe overall result i\", \"s that you\\u2019ve decoupled the raising of a domain event (a simple add into a list in\\nmemory) from disp\", \"atching it to an event handler. In addition, depending on what kind of dispatcher\\nyou are using, you\", \" could dispatch the events synchronously or asynchronously.\\nBe aware that transactional boundaries c\", \"ome into significant play here. If your unit of work and\\ntransaction can span more than one aggregat\", \"e (as when using EF Core and a relational database), this\\ncan work well. But if the transaction cann\", \"ot span aggregates, you have to implement additional steps\\nto achieve consistency. This is another r\", \"eason why persistence ignorance is not universal; it depends\\non the storage system you use.\\nSingle t\", \"ransaction across aggregates versus eventual consistency across\\naggregates\\nThe question of whether t\", \"o perform a single transaction across aggregates versus relying on eventual\\nconsistency across those\", \" aggregates is a controversial one. Many DDD authors like Eric Evans and\\nVaughn Vernon advocate the \", \"rule that one transaction = one aggregate and therefore argue for\\neventual consistency across aggreg\", \"ates. For example, in his book Domain-Driven Design, Eric Evans\\nsays this:\\nAny rule that spans Aggre\", \"gates will not be expected to be up-to-date at all times. Through event\\nprocessing, batch processing\", \", or other update mechanisms, other dependencies can be resolved\\nwithin some specific time. (page 12\", \"8)\\nVaughn Vernon says the following in Effective Aggregate Design. Part II: Making Aggregates Work\\nT\", \"ogether:\\n234 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsThus\", \", if executing a command on one aggregate instance requires that additional business rules\\nexecute o\", \"n one or more aggregates, use eventual consistency [\\u2026] There is a practical way to support\\neventual \", \"consistency in a DDD model. An aggregate method publishes a domain event that is in time\\ndelivered t\", \"o one or more asynchronous subscribers.\\nThis rationale is based on embracing fine-grained transactio\", \"ns instead of transactions spanning many\\naggregates or entities. The idea is that in the second case\", \", the number of database locks will be\\nsubstantial in large-scale applications with high scalability\", \" needs. Embracing the fact that highly\\nscalable applications need not have instant transactional con\", \"sistency between multiple aggregates\\nhelps with accepting the concept of eventual consistency. Atomi\", \"c changes are often not needed by\\nthe business, and it is in any case the responsibility of the doma\", \"in experts to say whether particular\\noperations need atomic transactions or not. If an operation alw\", \"ays needs an atomic transaction\\nbetween multiple aggregates, you might ask whether your aggregate sh\", \"ould be larger or wasn\\u2019t\\ncorrectly designed.\\nHowever, other developers and architects like Jimmy Bog\", \"ard are okay with spanning a single\\ntransaction across several aggregates\\u2014but only when those additi\", \"onal aggregates are related to side\\neffects for the same original command. For instance, in A better\", \" domain events pattern, Bogard says\\nthis:\\nTypically, I want the side effects of a domain event to oc\", \"cur within the same logical transaction, but\\nnot necessarily in the same scope of raising the domain\", \" event [\\u2026] Just before we commit our\\ntransaction, we dispatch our events to their respective handler\", \"s.\\nIf you dispatch the domain events right before committing the original transaction, it is because\", \" you\\nwant the side effects of those events to be included in the same transaction. For example, if t\", \"he EF\\nDbContext SaveChanges method fails, the transaction will roll back all changes, including the \", \"result of\\nany side effect operations implemented by the related domain event handlers. This is becau\", \"se the\\nDbContext life scope is by default defined as \\u201cscoped.\\u201d Therefore, the DbContext object is sh\", \"ared\\nacross multiple repository objects being instantiated within the same scope or object graph. Th\", \"is\\ncoincides with the HttpRequest scope when developing Web API or MVC apps.\\nActually, both approach\", \"es (single atomic transaction and eventual consistency) can be right. It really\\ndepends on your doma\", \"in or business requirements and what the domain experts tell you. It also\\ndepends on how scalable yo\", \"u need the service to be (more granular transactions have less impact\\nwith regard to database locks)\", \". And it depends on how much investment you\\u2019re willing to make in\\nyour code, since eventual consiste\", \"ncy requires more complex code in order to detect possible\\ninconsistencies across aggregates and the\", \" need to implement compensatory actions. Consider that if\\nyou commit changes to the original aggrega\", \"te and afterwards, when the events are being dispatched,\\nif there\\u2019s an issue and the event handlers \", \"cannot commit their side effects, you\\u2019ll have inconsistencies\\nbetween aggregates.\\nA way to allow com\", \"pensatory actions would be to store the domain events in additional database\\ntables so they can be p\", \"art of the original transaction. Afterwards, you could have a batch process that\\ndetects inconsisten\", \"cies and runs compensatory actions by comparing the list of events with the\\ncurrent state of the agg\", \"regates. The compensatory actions are part of a complex topic that will require\\ndeep analysis from y\", \"our side, which includes discussing it with the business user and domain experts.\\n235 CHAPTER 6 | Ta\", \"ckle Business Complexity in a Microservice with DDD and CQRS PatternsIn any case, you can choose the\", \" approach you need. But the initial deferred approach\\u2014raising the\\nevents before committing, so you u\", \"se a single transaction\\u2014is the simplest approach when using EF\\nCore and a relational database. It\\u2019s \", \"easier to implement and valid in many business cases. It\\u2019s also the\\napproach used in the ordering mi\", \"croservice in eShopOnContainers.\\nBut how do you actually dispatch those events to their respective e\", \"vent handlers? What\\u2019s the\\n_mediator object you see in the previous example? It has to do with the te\", \"chniques and artifacts you\\nuse to map between events and their event handlers.\\nThe domain event disp\", \"atcher: mapping from events to event handlers\\nOnce you\\u2019re able to dispatch or publish the events, yo\", \"u need some kind of artifact that will publish the\\nevent, so that every related handler can get it a\", \"nd process side effects based on that event.\\nOne approach is a real messaging system or even an even\", \"t bus, possibly based on a service bus as\\nopposed to in-memory events. However, for the first case, \", \"real messaging would be overkill for\\nprocessing domain events, since you just need to process those \", \"events within the same process (that\\nis, within the same domain and application layer).\\nHow to subsc\", \"ribe to domain events\\nWhen you use MediatR, each event handler must use an event type that is provid\", \"ed on the generic\\nparameter of the INotificationHandler interface, as you can see in the following c\", \"ode:\\npublic class ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler\\n: INotificationHandl\", \"er<OrderStartedDomainEvent>\\nBased on the relationship between event and event handler, which can be \", \"considered the\\nsubscription, the MediatR artifact can discover all the event handlers for each event\", \" and trigger each\\none of those event handlers.\\nHow to handle domain events\\nFinally, the event handle\", \"r usually implements application layer code that uses infrastructure\\nrepositories to obtain the requ\", \"ired additional aggregates and to execute side-effect domain logic. The\\nfollowing domain event handl\", \"er code at eShopOnContainers, shows an implementation example.\\npublic class ValidateOrAddBuyerAggreg\", \"ateWhenOrderStartedDomainEventHandler\\n: INotificationHandler<OrderStartedDomainEvent>\\n{\\nprivate read\", \"only ILogger _logger;\\nprivate readonly IBuyerRepository _buyerRepository;\\nprivate readonly IOrdering\", \"IntegrationEventService _orderingIntegrationEventService;\\npublic ValidateOrAddBuyerAggregateWhenOrde\", \"rStartedDomainEventHandler(\\nILogger<ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler> l\", \"ogger,\\nIBuyerRepository buyerRepository,\\nIOrderingIntegrationEventService orderingIntegrationEventSe\", \"rvice)\\n{\\n_buyerRepository = buyerRepository ?? throw new\\nArgumentNullException(nameof(buyerRepositor\", \"y));\\n_orderingIntegrationEventService = orderingIntegrationEventService ?? throw new\\nArgumentNullExc\", \"eption(nameof(orderingIntegrationEventService));\\n236 CHAPTER 6 | Tackle Business Complexity in a Mic\", \"roservice with DDD and CQRS Patterns_logger = logger ?? throw new ArgumentNullException(nameof(logge\", \"r));\\n}\\npublic async Task Handle(\\nOrderStartedDomainEvent domainEvent, CancellationToken cancellation\", \"Token)\\n{\\nvar cardTypeId = domainEvent.CardTypeId != 0 ? domainEvent.CardTypeId : 1;\\nvar buyer = awai\", \"t _buyerRepository.FindAsync(domainEvent.UserId);\\nvar buyerExisted = buyer is not null;\\nif (!buyerEx\", \"isted)\\n{\\nbuyer = new Buyer(domainEvent.UserId, domainEvent.UserName);\\n}\\nbuyer.VerifyOrAddPaymentMeth\", \"od(\\ncardTypeId,\\n$\\\"Payment Method on {DateTime.UtcNow}\\\",\\ndomainEvent.CardNumber,\\ndomainEvent.CardSecu\", \"rityNumber,\\ndomainEvent.CardHolderName,\\ndomainEvent.CardExpiration,\\ndomainEvent.Order.Id);\\nvar buyer\", \"Updated = buyerExisted ?\\n_buyerRepository.Update(buyer) :\\n_buyerRepository.Add(buyer);\\nawait _buyerR\", \"epository.UnitOfWork\\n.SaveEntitiesAsync(cancellationToken);\\nvar integrationEvent = new OrderStatusCh\", \"angedToSubmittedIntegrationEvent(\\ndomainEvent.Order.Id, domainEvent.Order.OrderStatus.Name, buyer.Na\", \"me);\\nawait _orderingIntegrationEventService.AddAndSaveEventAsync(integrationEvent);\\nOrderingApiTrace\", \".LogOrderBuyerAndPaymentValidatedOrUpdated(\\n_logger, buyerUpdated.Id, domainEvent.Order.Id);\\n}\\n}\\nThe\", \" previous domain event handler code is considered application layer code because it uses\\ninfrastruct\", \"ure repositories, as explained in the next section on the infrastructure-persistence layer.\\nEvent ha\", \"ndlers could also use other infrastructure components.\\nDomain events can generate integration events\", \" to be published outside of the\\nmicroservice boundaries\\nFinally, it\\u2019s important to mention that you \", \"might sometimes want to propagate events across multiple\\nmicroservices. That propagation is an integ\", \"ration event, and it could be published through an event\\nbus from any specific domain event handler.\", \"\\nConclusions on domain events\\nAs stated, use domain events to explicitly implement side effects of c\", \"hanges within your domain. To\\nuse DDD terminology, use domain events to explicitly implement side ef\", \"fects across one or multiple\\naggregates. Additionally, and for better scalability and less impact on\", \" database locks, use eventual\\nconsistency between aggregates within the same domain.\\n237 CHAPTER 6 |\", \" Tackle Business Complexity in a Microservice with DDD and CQRS PatternsThe reference app uses Media\", \"tR to propagate domain events synchronously across aggregates, within\\na single transaction. However,\", \" you could also use some AMQP implementation like RabbitMQ or\\nAzure Service Bus to propagate domain \", \"events asynchronously, using eventual consistency but, as\\nmentioned above, you have to consider the \", \"need for compensatory actions in case of failures.\\nAdditional resources\\n\\u2022 Greg Young. What is a Doma\", \"in Event?\\nhttps://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf#page=25\\n\\u2022 Jan Stenberg. Domain\", \" Events and Eventual Consistency\\nhttps://www.infoq.com/news/2015/09/domain-events-consistency\\n\\u2022 Jimm\", \"y Bogard. A better domain events pattern\\nhttps://lostechies.com/jimmybogard/2014/05/13/a-better-doma\", \"in-events-pattern/\\n\\u2022 Vaughn Vernon. Effective Aggregate Design Part II: Making Aggregates Work Toget\", \"her\\nhttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf\\n\\u2022 Jimmy Bogard.\", \" Strengthening your domain: Domain Events\\nhttps://lostechies.com/jimmybogard/2010/04/08/strengthenin\", \"g-your-domain-domain-\\nevents/\\n\\u2022 Udi Dahan. How to create fully encapsulated Domain Models\\nhttps://ud\", \"idahan.com/2008/02/29/how-to-create-fully-encapsulated-domain-models/\\n\\u2022 Udi Dahan. Domain Events \\u2013 T\", \"ake 2\\nhttps://udidahan.com/2008/08/25/domain-events-take-2/\\n\\u2022 Udi Dahan. Domain Events \\u2013 Salvation\\nh\", \"ttps://udidahan.com/2009/06/14/domain-events-salvation/\\n\\u2022 Cesar de la Torre. Domain Events vs. Integ\", \"ration Events in DDD and microservices\\narchitectures\\nhttps://devblogs.microsoft.com/cesardelatorre/d\", \"omain-events-vs-integration-events-in-\\ndomain-driven-design-and-microservices-architectures/\\nDesign \", \"the infrastructure persistence layer\\nData persistence components provide access to the data hosted w\", \"ithin the boundaries of a\\nmicroservice (that is, a microservice\\u2019s database). They contain the actual\", \" implementation of\\ncomponents such as repositories and Unit of Work classes, like custom Entity Fram\", \"ework (EF)\\nDbContext objects. EF DbContext implements both the Repository and the Unit of Work patte\", \"rns.\\nThe Repository pattern\\nThe Repository pattern is a Domain-Driven Design pattern intended to kee\", \"p persistence concerns\\noutside of the system\\u2019s domain model. One or more persistence abstractions - \", \"interfaces - are defined\\n238 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS Patternsin the domain model, and these abstractions have implementations in the form of persiste\", \"nce-specific\\nadapters defined elsewhere in the application.\\nRepository implementations are classes t\", \"hat encapsulate the logic required to access data sources.\\nThey centralize common data access functi\", \"onality, providing better maintainability and decoupling\\nthe infrastructure or technology used to ac\", \"cess databases from the domain model. If you use an\\nObject-Relational Mapper (ORM) like Entity Frame\", \"work, the code that must be implemented is\\nsimplified, thanks to LINQ and strong typing. This lets y\", \"ou focus on the data persistence logic rather\\nthan on data access plumbing.\\nThe Repository pattern i\", \"s a well-documented way of working with a data source. In the book Patterns\\nof Enterprise Applicatio\", \"n Architecture, Martin Fowler describes a repository as follows:\\nA repository performs the tasks of \", \"an intermediary between the domain model layers and data\\nmapping, acting in a similar way to a set o\", \"f domain objects in memory. Client objects declaratively\\nbuild queries and send them to the reposito\", \"ries for answers. Conceptually, a repository encapsulates a\\nset of objects stored in the database an\", \"d operations that can be performed on them, providing a way\\nthat is closer to the persistence layer.\", \" Repositories, also, support the purpose of separating, clearly\\nand in one direction, the dependency\", \" between the work domain and the data allocation or mapping.\\nDefine one repository per aggregate\\nFor\", \" each aggregate or aggregate root, you should create one repository class. You may be able to\\nlevera\", \"ge C# Generics to reduce the total number concrete classes you need to maintain (as\\ndemonstrated lat\", \"er in this chapter). In a microservice based on Domain-Driven Design (DDD) patterns,\\nthe only channe\", \"l you should use to update the database should be the repositories. This is because\\nthey have a one-\", \"to-one relationship with the aggregate root, which controls the aggregate\\u2019s\\ninvariants and transacti\", \"onal consistency. It\\u2019s okay to query the database through other channels (as\\nyou can do following a \", \"CQRS approach), because queries don\\u2019t change the state of the database.\\nHowever, the transactional a\", \"rea (that is, the updates) must always be controlled by the repositories\\nand the aggregate roots.\\nBa\", \"sically, a repository allows you to populate data in memory that comes from the database in the\\nform\", \" of the domain entities. Once the entities are in memory, they can be changed and then persisted\\nbac\", \"k to the database through transactions.\\nAs noted earlier, if you\\u2019re using the CQS/CQRS architectural\", \" pattern, the initial queries are performed\\nby side queries out of the domain model, performed by si\", \"mple SQL statements using Dapper. This\\napproach is much more flexible than repositories because you \", \"can query and join any tables you\\nneed, and these queries aren\\u2019t restricted by rules from the aggreg\", \"ates. That data goes to the\\npresentation layer or client app.\\nIf the user makes changes, the data to\", \" be updated comes from the client app or presentation layer to\\nthe application layer (such as a Web \", \"API service). When you receive a command in a command\\nhandler, you use repositories to get the data \", \"you want to update from the database. You update it in\\nmemory with the data passed with the commands\", \", and you then add or update the data (domain\\nentities) in the database through a transaction.\\n239 C\", \"HAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsIt\\u2019s important to \", \"emphasize again that you should only define one repository for each aggregate root,\\nas shown in Figu\", \"re 7-17. To achieve the goal of the aggregate root to maintain transactional\\nconsistency between all\", \" the objects within the aggregate, you should never create a repository for\\neach table in the databa\", \"se.\\nFigure 7-17. The relationship between repositories, aggregates, and database tables\\nThe above di\", \"agram shows the relationships between Domain and Infrastructure layers: Buyer\\nAggregate depends on t\", \"he IBuyerRepository and Order Aggregate depends on the IOrderRepository\\ninterfaces, these interfaces\", \" are implemented in the Infrastructure layer by the corresponding\\nrepositories that depend on UnitOf\", \"Work, also implemented there, that accesses the tables in the Data\\ntier.\\nEnforce one aggregate root \", \"per repository\\nIt can be valuable to implement your repository design in such a way that it enforces\", \" the rule that only\\naggregate roots should have repositories. You can create a generic or base repos\", \"itory type that\\nconstrains the type of entities it works with to ensure they have the IAggregateRoot\", \" marker interface.\\nThus, each repository class implemented at the infrastructure layer implements it\", \"s own contract or\\ninterface, as shown in the following code:\\nnamespace Microsoft.eShopOnContainers.S\", \"ervices.Ordering.Infrastructure.Repositories\\n{\\npublic class OrderRepository : IOrderRepository\\n{\\n// \", \"...\\n240 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns}\\n}\\nEach \", \"specific repository interface implements the generic IRepository interface:\\npublic interface IOrderR\", \"epository : IRepository<Order>\\n{\\nOrder Add(Order order);\\n// ...\\n}\\nHowever, a better way to have the \", \"code enforce the convention that each repository is related to a\\nsingle aggregate is to implement a \", \"generic repository type. That way, it\\u2019s explicit that you\\u2019re using a\\nrepository to target a specific\", \" aggregate. That can be easily done by implementing a generic\\nIRepository base interface, as in the \", \"following code:\\npublic interface IRepository<T> where T : IAggregateRoot\\n{\\n//....\\n}\\nThe Repository p\", \"attern makes it easier to test your application logic\\nThe Repository pattern allows you to easily te\", \"st your application with unit tests. Remember that unit\\ntests only test your code, not infrastructur\", \"e, so the repository abstractions make it easier to achieve\\nthat goal.\\nAs noted in an earlier sectio\", \"n, it\\u2019s recommended that you define and place the repository interfaces in\\nthe domain model layer so\", \" the application layer, such as your Web API microservice, doesn\\u2019t depend\\ndirectly on the infrastruc\", \"ture layer where you\\u2019ve implemented the actual repository classes. By doing\\nthis and using Dependenc\", \"y Injection in the controllers of your Web API, you can implement mock\\nrepositories that return fake\", \" data instead of data from the database. This decoupled approach allows\\nyou to create and run unit t\", \"ests that focus the logic of your application without requiring connectivity\\nto the database.\\nConnec\", \"tions to databases can fail and, more importantly, running hundreds of tests against a\\ndatabase is b\", \"ad for two reasons. First, it can take a long time because of the large number of tests.\\nSecond, the\", \" database records might change and impact the results of your tests, especially if your\\ntests are ru\", \"nning in parallel, so that they might not be consistent. Unit tests typically can run in\\nparallel; i\", \"ntegration tests may not support parallel execution depending on their implementation.\\nTesting again\", \"st the database isn\\u2019t a unit test but an integration test. You should have many unit tests\\nrunning f\", \"ast, but fewer integration tests against the databases.\\nIn terms of separation of concerns for unit \", \"tests, your logic operates on domain entities in memory. It\\nassumes the repository class has deliver\", \"ed those. Once your logic modifies the domain entities, it\\nassumes the repository class will store t\", \"hem correctly. The important point here is to create unit tests\\nagainst your domain model and its do\", \"main logic. Aggregate roots are the main consistency\\nboundaries in DDD.\\nThe repositories implemented\", \" in eShopOnContainers rely on EF Core\\u2019s DbContext implementation of\\nthe Repository and Unit of Work \", \"patterns using its change tracker, so they don\\u2019t duplicate this\\nfunctionality.\\n241 CHAPTER 6 | Tackl\", \"e Business Complexity in a Microservice with DDD and CQRS PatternsThe difference between the Reposit\", \"ory pattern and the legacy Data Access class\\n(DAL class) pattern\\nA typical DAL object directly perfo\", \"rms data access and persistence operations against storage, often\\nat the level of a single table and\", \" row. Simple CRUD operations implemented with a set of DAL classes\\nfrequently do not support transac\", \"tions (though this is not always the case). Most DAL class\\napproaches make minimal use of abstractio\", \"ns, resulting in tight coupling between application or\\nBusiness Logic Layer (BLL) classes that call \", \"the DAL objects.\\nWhen using repository, the implementation details of persistence are encapsulated a\", \"way from the\\ndomain model. The use of an abstraction provides ease of extending behavior through pat\", \"terns like\\nDecorators or Proxies. For instance, cross-cutting concerns like caching, logging, and er\", \"ror handling\\ncan all be applied using these patterns rather than hard-coded in the data access code \", \"itself. It\\u2019s also\\ntrivial to support multiple repository adapters which may be used in different env\", \"ironments, from\\nlocal development to shared staging environments to production.\\nImplementing Unit of\", \" Work\\nA unit of work refers to a single transaction that involves multiple insert, update, or delete\", \" operations.\\nIn simple terms, it means that for a specific user action, such as a registration on a \", \"website, all the\\ninsert, update, and delete operations are handled in a single transaction. This is \", \"more efficient than\\nhandling multiple database operations in a chattier way.\\nThese multiple persiste\", \"nce operations are performed later in a single action when your code from the\\napplication layer comm\", \"ands it. The decision about applying the in-memory changes to the actual\\ndatabase storage is typical\", \"ly based on the Unit of Work pattern. In EF, the Unit of Work pattern is\\nimplemented by a DbContext \", \"and is executed when a call is made to SaveChanges.\\nIn many cases, this pattern or way of applying o\", \"perations against the storage can increase application\\nperformance and reduce the possibility of inc\", \"onsistencies. It also reduces transaction blocking in the\\ndatabase tables, because all the intended \", \"operations are committed as part of one transaction. This is\\nmore efficient in comparison to executi\", \"ng many isolated operations against the database. Therefore,\\nthe selected ORM can optimize the execu\", \"tion against the database by grouping several update\\nactions within the same transaction, as opposed\", \" to many small and separate transaction executions.\\nThe Unit of Work pattern can be implemented with\", \" or without using the Repository pattern.\\nRepositories shouldn\\u2019t be mandatory\\nCustom repositories ar\", \"e useful for the reasons cited earlier, and that is the approach for the ordering\\nmicroservice in eS\", \"hopOnContainers. However, it isn\\u2019t an essential pattern to implement in a DDD\\ndesign or even in gene\", \"ral .NET development.\\nFor instance, Jimmy Bogard, when providing direct feedback for this guide, sai\", \"d the following:\\nThis\\u2019ll probably be my biggest feedback. I\\u2019m really not a fan of repositories, main\", \"ly because they hide\\nthe important details of the underlying persistence mechanism. It\\u2019s why I go fo\", \"r MediatR for\\ncommands, too. I can use the full power of the persistence layer, and push all that do\", \"main behavior\\ninto my aggregate roots. I don\\u2019t usually want to mock my repositories \\u2013 I still need t\", \"o have that\\n242 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternsi\", \"ntegration test with the real thing. Going CQRS meant that we didn\\u2019t really have a need for\\nreposito\", \"ries any more.\\nRepositories might be useful, but they are not critical for your DDD design in the wa\", \"y that the\\nAggregate pattern and a rich domain model are. Therefore, use the Repository pattern or n\", \"ot, as you\\nsee fit.\\nAdditional resources\\nRepository pattern\\n\\u2022 Edward Hieatt and Rob Mee. Repository \", \"pattern.\\nhttps://martinfowler.com/eaaCatalog/repository.html\\n\\u2022 The Repository pattern\\nhttps://learn.\", \"microsoft.com/previous-versions/msp-n-p/ff649690(v=pandp.10)\\n\\u2022 Eric Evans. Domain-Driven Design: Tac\", \"kling Complexity in the Heart of Software. (Book;\\nincludes a discussion of the Repository pattern)\\nh\", \"ttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/\\nUnit of Work\", \" pattern\\n\\u2022 Martin Fowler. Unit of Work pattern.\\nhttps://martinfowler.com/eaaCatalog/unitOfWork.html\\n\", \"\\u2022 Implementing the Repository and Unit of Work Patterns in an ASP.NET MVC\\nApplication\\nhttps://learn.\", \"microsoft.com/aspnet/mvc/overview/older-versions/getting-started-with-ef-5-\\nusing-mvc-4/implementing\", \"-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-\\napplication\\nImplement the infrastructur\", \"e persistence layer with\\nEntity Framework Core\\nWhen you use relational databases such as SQL Server,\", \" Oracle, or PostgreSQL, a recommended\\napproach is to implement the persistence layer based on Entity\", \" Framework (EF). EF supports LINQ and\\nprovides strongly typed objects for your model, as well as sim\", \"plified persistence into your database.\\nEntity Framework has a long history as part of the .NET Fram\", \"ework. When you use .NET, you should\\nalso use Entity Framework Core, which runs on Windows or Linux \", \"in the same way as .NET. EF Core is a\\ncomplete rewrite of Entity Framework that\\u2019s implemented with a\", \" much smaller footprint and\\nimportant improvements in performance.\\n243 CHAPTER 6 | Tackle Business C\", \"omplexity in a Microservice with DDD and CQRS PatternsIntroduction to Entity Framework Core\\nEntity F\", \"ramework (EF) Core is a lightweight, extensible, and cross-platform version of the popular\\nEntity Fr\", \"amework data access technology. It was introduced with .NET Core in mid-2016.\\nSince an introduction \", \"to EF Core is already available in Microsoft documentation, here we simply\\nprovide links to that inf\", \"ormation.\\nAdditional resources\\n\\u2022 Entity Framework Core\\nhttps://learn.microsoft.com/ef/core/\\n\\u2022 Gettin\", \"g started with ASP.NET Core and Entity Framework Core using Visual Studio\\nhttps://learn.microsoft.co\", \"m/aspnet/core/data/ef-mvc/\\n\\u2022 DbContext Class\\nhttps://learn.microsoft.com/dotnet/api/microsoft.entity\", \"frameworkcore.dbcontext\\n\\u2022 Compare EF Core & EF6.x\\nhttps://learn.microsoft.com/ef/efcore-and-ef6/inde\", \"x\\nInfrastructure in Entity Framework Core from a DDD perspective\\nFrom a DDD point of view, an import\", \"ant capability of EF is the ability to use POCO domain entities,\\nalso known in EF terminology as POC\", \"O code-first entities. If you use POCO domain entities, your\\ndomain model classes are persistence-ig\", \"norant, following the Persistence Ignorance and the\\nInfrastructure Ignorance principles.\\nPer DDD pat\", \"terns, you should encapsulate domain behavior and rules within the entity class itself, so\\nit can co\", \"ntrol invariants, validations, and rules when accessing any collection. Therefore, it is not a\\ngood \", \"practice in DDD to allow public access to collections of child entities or value objects. Instead,\\ny\", \"ou want to expose methods that control how and when your fields and property collections can be\\nupda\", \"ted, and what behavior and actions should occur when that happens.\\nSince EF Core 1.1, to satisfy tho\", \"se DDD requirements, you can have plain fields in your entities instead\\nof public properties. If you\", \" do not want an entity field to be externally accessible, you can just create\\nthe attribute or field\", \" instead of a property. You can also use private property setters.\\nIn a similar way, you can now hav\", \"e read-only access to collections by using a public property typed as\\nIReadOnlyCollection<T>, which \", \"is backed by a private field member for the collection (like a List<T>)\\nin your entity that relies o\", \"n EF for persistence. Previous versions of Entity Framework required\\ncollection properties to suppor\", \"t ICollection<T>, which meant that any developer using the parent\\nentity class could add or remove i\", \"tems through its property collections. That possibility would be\\nagainst the recommended patterns in\", \" DDD.\\nYou can use a private collection while exposing a read-only IReadOnlyCollection<T> object, as \", \"shown\\nin the following code example:\\npublic class Order : Entity\\n{\\n244 CHAPTER 6 | Tackle Business C\", \"omplexity in a Microservice with DDD and CQRS Patterns// Using private fields, allowed since EF Core\", \" 1.1\\nprivate DateTime _orderDate;\\n// Other fields ...\\nprivate readonly List<OrderItem> _orderItems;\\n\", \"public IReadOnlyCollection<OrderItem> OrderItems => _orderItems;\\nprotected Order() { }\\npublic Order(\", \"int buyerId, int paymentMethodId, Address address)\\n{\\n// Initializations ...\\n}\\npublic void AddOrderIt\", \"em(int productId, string productName,\\ndecimal unitPrice, decimal discount,\\nstring pictureUrl, int un\", \"its = 1)\\n{\\n// Validation logic...\\nvar orderItem = new OrderItem(productId, productName,\\nunitPrice, d\", \"iscount,\\npictureUrl, units);\\n_orderItems.Add(orderItem);\\n}\\n}\\nThe OrderItems property can only be acc\", \"essed as read-only using IReadOnlyCollection<OrderItem>.\\nThis type is read-only so it is protected a\", \"gainst regular external updates.\\nEF Core provides a way to map the domain model to the physical data\", \"base without \\u201ccontaminating\\u201d\\nthe domain model. It is pure .NET POCO code, because the mapping action\", \" is implemented in the\\npersistence layer. In that mapping action, you need to configure the fields-t\", \"o-database mapping. In\\nthe following example of the OnModelCreating method from OrderingContext and \", \"the\\nOrderEntityTypeConfiguration class, the call to SetPropertyAccessMode tells EF Core to access th\", \"e\\nOrderItems property through its field.\\n// At OrderingContext.cs from eShopOnContainers\\nprotected o\", \"verride void OnModelCreating(ModelBuilder modelBuilder)\\n{\\n// ...\\nmodelBuilder.ApplyConfiguration(new\", \" OrderEntityTypeConfiguration());\\n// Other entities' configuration ...\\n}\\n// At OrderEntityTypeConfig\", \"uration.cs from eShopOnContainers\\nclass OrderEntityTypeConfiguration : IEntityTypeConfiguration<Orde\", \"r>\\n{\\npublic void Configure(EntityTypeBuilder<Order> orderConfiguration)\\n{\\norderConfiguration.ToTable\", \"(\\\"orders\\\", OrderingContext.DEFAULT_SCHEMA);\\n// Other configuration\\nvar navigation =\\norderConfigurati\", \"on.Metadata.FindNavigation(nameof(Order.OrderItems));\\n//EF access the OrderItem collection property \", \"through its backing field\\nnavigation.SetPropertyAccessMode(PropertyAccessMode.Field);\\n245 CHAPTER 6 \", \"| Tackle Business Complexity in a Microservice with DDD and CQRS Patterns// Other configuration\\n}\\n}\\n\", \"When you use fields instead of properties, the OrderItem entity is persisted as if it had a\\nList<Ord\", \"erItem> property. However, it exposes a single accessor, the AddOrderItem method, for\\nadding new ite\", \"ms to the order. As a result, behavior and data are tied together and will be consistent\\nthroughout \", \"any application code that uses the domain model.\\nImplement custom repositories with Entity Framework\", \" Core\\nAt the implementation level, a repository is simply a class with data persistence code coordin\", \"ated by a\\nunit of work (DBContext in EF Core) when performing updates, as shown in the following cla\", \"ss:\\n// using directives...\\nnamespace Microsoft.eShopOnContainers.Services.Ordering.Infrastructure.Re\", \"positories\\n{\\npublic class BuyerRepository : IBuyerRepository\\n{\\nprivate readonly OrderingContext _con\", \"text;\\npublic IUnitOfWork UnitOfWork\\n{\\nget\\n{\\nreturn _context;\\n}\\n}\\npublic BuyerRepository(OrderingCont\", \"ext context)\\n{\\n_context = context ?? throw new ArgumentNullException(nameof(context));\\n}\\npublic Buye\", \"r Add(Buyer buyer)\\n{\\nreturn _context.Buyers.Add(buyer).Entity;\\n}\\npublic async Task<Buyer> FindAsync(\", \"string buyerIdentityGuid)\\n{\\nvar buyer = await _context.Buyers\\n.Include(b => b.Payments)\\n.Where(b => \", \"b.FullName == buyerIdentityGuid)\\n.SingleOrDefaultAsync();\\nreturn buyer;\\n}\\n}\\n}\\nThe IBuyerRepository i\", \"nterface comes from the domain model layer as a contract. However, the\\nrepository implementation is \", \"done at the persistence and infrastructure layer.\\nThe EF DbContext comes through the constructor thr\", \"ough Dependency Injection. It is shared between\\nmultiple repositories within the same HTTP request s\", \"cope, thanks to its default lifetime\\n(ServiceLifetime.Scoped) in the IoC container (which can also b\", \"e explicitly set with\\nservices.AddDbContext<>).\\n246 CHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS PatternsMethods to implement in a repository (updates or transactions ver\", \"sus queries)\\nWithin each repository class, you should put the persistence methods that update the st\", \"ate of entities\\ncontained by its related aggregate. Remember there is one-to-one relationship betwee\", \"n an aggregate\\nand its related repository. Consider that an aggregate root entity object might have \", \"embedded child\\nentities within its EF graph. For example, a buyer might have multiple payment method\", \"s as related\\nchild entities.\\nSince the approach for the ordering microservice in eShopOnContainers i\", \"s also based on CQS/CQRS,\\nmost of the queries are not implemented in custom repositories. Developers\", \" have the freedom to\\ncreate the queries and joins they need for the presentation layer without the r\", \"estrictions imposed by\\naggregates, custom repositories per aggregate, and DDD in general. Most of th\", \"e custom repositories\\nsuggested by this guide have several update or transactional methods but just \", \"the query methods\\nneeded to get data to be updated. For example, the BuyerRepository repository impl\", \"ements a\\nFindAsync method, because the application needs to know whether a particular buyer exists b\", \"efore\\ncreating a new buyer related to the order.\\nHowever, the real query methods to get data to send\", \" to the presentation layer or client apps are\\nimplemented, as mentioned, in the CQRS queries based o\", \"n flexible queries using Dapper.\\nUsing a custom repository versus using EF DbContext directly\\nThe En\", \"tity Framework DbContext class is based on the Unit of Work and Repository patterns and can\\nbe used \", \"directly from your code, such as from an ASP.NET Core MVC controller. The Unit of Work and\\nRepositor\", \"y patterns result in the simplest code, as in the CRUD catalog microservice in\\neShopOnContainers. In\", \" cases where you want the simplest code possible, you might want to directly\\nuse the DbContext class\", \", as many developers do.\\nHowever, implementing custom repositories provides several benefits when im\", \"plementing more\\ncomplex microservices or applications. The Unit of Work and Repository patterns are \", \"intended to\\nencapsulate the infrastructure persistence layer so it is decoupled from the application\", \" and domain-\\nmodel layers. Implementing these patterns can facilitate the use of mock repositories s\", \"imulating\\naccess to the database.\\nIn Figure 7-18, you can see the differences between not using repo\", \"sitories (directly using the EF\\nDbContext) versus using repositories, which makes it easier to mock \", \"those repositories.\\n247 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS P\", \"atternsFigure 7-18. Using custom repositories versus a plain DbContext\\nFigure 7-18 shows that using \", \"a custom repository adds an abstraction layer that can be used to ease\\ntesting by mocking the reposi\", \"tory. There are multiple alternatives when mocking. You could mock just\\nrepositories or you could mo\", \"ck a whole unit of work. Usually mocking just the repositories is enough,\\nand the complexity to abst\", \"ract and mock a whole unit of work is usually not needed.\\nLater, when we focus on the application la\", \"yer, you will see how Dependency Injection works in\\nASP.NET Core and how it is implemented when usin\", \"g repositories.\\nIn short, custom repositories allow you to test code more easily with unit tests tha\", \"t are not impacted\\nby the data tier state. If you run tests that also access the actual database thr\", \"ough the Entity\\nFramework, they are not unit tests but integration tests, which are a lot slower.\\nIf\", \" you were using DbContext directly, you would have to mock it or to run unit tests by using an in-\\nm\", \"emory SQL Server with predictable data for unit tests. But mocking the DbContext or controlling\\nfake\", \" data requires more work than mocking at the repository level. Of course, you could always test\\nthe \", \"MVC controllers.\\nEF DbContext and IUnitOfWork instance lifetime in your IoC container\\nThe DbContext \", \"object (exposed as an IUnitOfWork object) should be shared among multiple\\nrepositories within the sa\", \"me HTTP request scope. For example, this is true when the operation being\\nexecuted must deal with mu\", \"ltiple aggregates, or simply because you are using multiple repository\\ninstances. It is also importa\", \"nt to mention that the IUnitOfWork interface is part of your domain layer,\\nnot an EF Core type.\\nIn o\", \"rder to do that, the instance of the DbContext object has to have its service lifetime set to\\nServic\", \"eLifetime.Scoped. This is the default lifetime when registering a DbContext with\\nbuilder.Services.Ad\", \"dDbContext in your IoC container from the Program.cs file in your ASP.NET Core\\nWeb API project. The \", \"following code illustrates this.\\n248 CHAPTER 6 | Tackle Business Complexity in a Microservice with D\", \"DD and CQRS Patterns// Add framework services.\\nbuilder.Services.AddMvc(options =>\\n{\\noptions.Filters.\", \"Add(typeof(HttpGlobalExceptionFilter));\\n}).AddControllersAsServices();\\nbuilder.Services.AddEntityFra\", \"meworkSqlServer()\\n.AddDbContext<OrderingContext>(options =>\\n{\\noptions.UseSqlServer(Configuration[\\\"Co\", \"nnectionString\\\"],\\nsqlOptions =>\\nsqlOptions.MigrationsAssembly(typeof(Startup).GetTypeInfo().\\nAssembl\", \"y.GetName().Name));\\n},\\nServiceLifetime.Scoped // Note that Scoped is the default choice\\n// in AddDbC\", \"ontext. It is shown here only for\\n// pedagogic purposes.\\n);\\nThe DbContext instantiation mode should \", \"not be configured as ServiceLifetime.Transient or\\nServiceLifetime.Singleton.\\nThe repository instance\", \" lifetime in your IoC container\\nIn a similar way, repository\\u2019s lifetime should usually be set as sco\", \"ped (InstancePerLifetimeScope in\\nAutofac). It could also be transient (InstancePerDependency in Auto\", \"fac), but your service will be more\\nefficient in regards to memory when using the scoped lifetime.\\n/\", \"/ Registering a Repository in Autofac IoC container\\nbuilder.RegisterType<OrderRepository>()\\n.As<IOrd\", \"erRepository>()\\n.InstancePerLifetimeScope();\\nUsing the singleton lifetime for the repository could c\", \"ause you serious concurrency problems when\\nyour DbContext is set to scoped (InstancePerLifetimeScope\", \") lifetime (the default lifetimes for a\\nDBContext). As long as your service lifetimes for your repos\", \"itories and your DbContext are both\\nScoped, you\\u2019ll avoid these issues.\\nAdditional resources\\n\\u2022 Implem\", \"enting the Repository and Unit of Work Patterns in an ASP.NET MVC\\nApplication\\nhttps://www.asp.net/mv\", \"c/overview/older-versions/getting-started-with-ef-5-using-mvc-\\n4/implementing-the-repository-and-uni\", \"t-of-work-patterns-in-an-asp-net-mvc-application\\n\\u2022 Jonathan Allen. Implementation Strategies for the\", \" Repository Pattern with Entity\\nFramework, Dapper, and Chain\\nhttps://www.infoq.com/articles/reposito\", \"ry-implementation-strategies\\n\\u2022 Cesar de la Torre. Comparing ASP.NET Core IoC container service lifet\", \"imes with Autofac\\nIoC container instance scopes\\nhttps://devblogs.microsoft.com/cesardelatorre/compar\", \"ing-asp-net-core-ioc-service-life-\\ntimes-and-autofac-ioc-instance-scopes/\\n249 CHAPTER 6 | Tackle Bus\", \"iness Complexity in a Microservice with DDD and CQRS PatternsTable mapping\\nTable mapping identifies \", \"the table data to be queried from and saved to the database. Previously you\\nsaw how domain entities \", \"(for example, a product or order domain) can be used to generate a related\\ndatabase schema. EF is st\", \"rongly designed around the concept of conventions. Conventions address\\nquestions like \\u201cWhat will the\", \" name of a table be?\\u201d or \\u201cWhat property is the primary key?\\u201d Conventions\\nare typically based on conv\", \"entional names. For example, it is typical for the primary key to be a\\nproperty that ends with Id.\\nB\", \"y convention, each entity will be set up to map to a table with the same name as the DbSet<TEntity>\\n\", \"property that exposes the entity on the derived context. If no DbSet<TEntity> value is provided for\\n\", \"the given entity, the class name is used.\\nData Annotations versus Fluent API\\nThere are many addition\", \"al EF Core conventions, and most of them can be changed by using either\\ndata annotations or Fluent A\", \"PI, implemented within the OnModelCreating method.\\nData annotations must be used on the entity model\", \" classes themselves, which is a more intrusive way\\nfrom a DDD point of view. This is because you are\", \" contaminating your model with data annotations\\nrelated to the infrastructure database. On the other\", \" hand, Fluent API is a convenient way to change\\nmost conventions and mappings within your data persi\", \"stence infrastructure layer, so the entity model\\nwill be clean and decoupled from the persistence in\", \"frastructure.\\nFluent API and the OnModelCreating method\\nAs mentioned, in order to change conventions\", \" and mappings, you can use the OnModelCreating\\nmethod in the DbContext class.\\nThe ordering microserv\", \"ice in eShopOnContainers implements explicit mapping and configuration,\\nwhen needed, as shown in the\", \" following code.\\n// At OrderingContext.cs from eShopOnContainers\\nprotected override void OnModelCrea\", \"ting(ModelBuilder modelBuilder)\\n{\\n// ...\\nmodelBuilder.ApplyConfiguration(new OrderEntityTypeConfigur\", \"ation());\\n// Other entities' configuration ...\\n}\\n// At OrderEntityTypeConfiguration.cs from eShopOnC\", \"ontainers\\nclass OrderEntityTypeConfiguration : IEntityTypeConfiguration<Order>\\n{\\npublic void Configu\", \"re(EntityTypeBuilder<Order> orderConfiguration)\\n{\\norderConfiguration.ToTable(\\\"orders\\\", OrderingConte\", \"xt.DEFAULT_SCHEMA);\\norderConfiguration.HasKey(o => o.Id);\\norderConfiguration.Ignore(b => b.DomainEve\", \"nts);\\norderConfiguration.Property(o => o.Id)\\n.UseHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA);\\n2\", \"50 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns//Address valu\", \"e object persisted as owned entity type supported since EF Core 2.0\\norderConfiguration\\n.OwnsOne(o =>\", \" o.Address, a =>\\n{\\na.WithOwner();\\n});\\norderConfiguration\\n.Property<int?>(\\\"_buyerId\\\")\\n.UsePropertyAcc\", \"essMode(PropertyAccessMode.Field)\\n.HasColumnName(\\\"BuyerId\\\")\\n.IsRequired(false);\\norderConfiguration\\n.\", \"Property<DateTime>(\\\"_orderDate\\\")\\n.UsePropertyAccessMode(PropertyAccessMode.Field)\\n.HasColumnName(\\\"Or\", \"derDate\\\")\\n.IsRequired();\\norderConfiguration\\n.Property<int>(\\\"_orderStatusId\\\")\\n.UsePropertyAccessMode(\", \"PropertyAccessMode.Field)\\n.HasColumnName(\\\"OrderStatusId\\\")\\n.IsRequired();\\norderConfiguration\\n.Propert\", \"y<int?>(\\\"_paymentMethodId\\\")\\n.UsePropertyAccessMode(PropertyAccessMode.Field)\\n.HasColumnName(\\\"Payment\", \"MethodId\\\")\\n.IsRequired(false);\\norderConfiguration.Property<string>(\\\"Description\\\").IsRequired(false);\", \"\\nvar navigation =\\norderConfiguration.Metadata.FindNavigation(nameof(Order.OrderItems));\\n// DDD Patte\", \"rns comment:\\n//Set as field (New since EF 1.1) to access the OrderItem collection property\\nthrough i\", \"ts field\\nnavigation.SetPropertyAccessMode(PropertyAccessMode.Field);\\norderConfiguration.HasOne<Payme\", \"ntMethod>()\\n.WithMany()\\n.HasForeignKey(\\\"_paymentMethodId\\\")\\n.IsRequired(false)\\n.OnDelete(DeleteBehavi\", \"or.Restrict);\\norderConfiguration.HasOne<Buyer>()\\n.WithMany()\\n.IsRequired(false)\\n.HasForeignKey(\\\"_buy\", \"erId\\\");\\norderConfiguration.HasOne(o => o.OrderStatus)\\n.WithMany()\\n.HasForeignKey(\\\"_orderStatusId\\\");\\n\", \"}\\n}\\nYou could set all the Fluent API mappings within the same OnModelCreating method, but it\\u2019s\\nadvis\", \"able to partition that code and have multiple configuration classes, one per entity, as shown in\\n251\", \" CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternsthe example. Esp\", \"ecially for large models, it is advisable to have separate configuration classes for\\nconfiguring dif\", \"ferent entity types.\\nThe code in the example shows a few explicit declarations and mapping. However,\", \" EF Core\\nconventions do many of those mappings automatically, so the actual code you would need in y\", \"our\\ncase might be smaller.\\nThe Hi/Lo algorithm in EF Core\\nAn interesting aspect of code in the prece\", \"ding example is that it uses the Hi/Lo algorithm as the key\\ngeneration strategy.\\nThe Hi/Lo algorithm\", \" is useful when you need unique keys before committing changes. As a summary,\\nthe Hi-Lo algorithm as\", \"signs unique identifiers to table rows while not depending on storing the row in\\nthe database immedi\", \"ately. This lets you start using the identifiers right away, as happens with regular\\nsequential data\", \"base IDs.\\nThe Hi/Lo algorithm describes a mechanism for getting a batch of unique IDs from a related\", \" database\\nsequence. These IDs are safe to use because the database guarantees the uniqueness, so the\", \"re will be\\nno collisions between users. This algorithm is interesting for these reasons:\\n\\u2022 It does n\", \"ot break the Unit of Work pattern.\\n\\u2022 It gets sequence IDs in batches, to minimize round trips to the\", \" database.\\n\\u2022 It generates a human readable identifier, unlike techniques that use GUIDs.\\nEF Core sup\", \"ports HiLo with the UseHiLo method, as shown in the preceding example.\\nMap fields instead of propert\", \"ies\\nWith this feature, available since EF Core 1.1, you can directly map columns to fields. It is po\", \"ssible to\\nnot use properties in the entity class, and just to map columns from a table to fields. A \", \"common use\\nfor that would be private fields for any internal state that do not need to be accessed f\", \"rom outside the\\nentity.\\nYou can do this with single fields or also with collections, like a List<> f\", \"ield. This point was mentioned\\nearlier when we discussed modeling the domain model classes, but here\", \" you can see how that\\nmapping is performed with the PropertyAccessMode.Field configuration highlight\", \"ed in the previous\\ncode.\\nUse shadow properties in EF Core, hidden at the infrastructure level\\nShadow\", \" properties in EF Core are properties that do not exist in your entity class model. The values\\nand s\", \"tates of these properties are maintained purely in the ChangeTracker class at the infrastructure\\nlev\", \"el.\\n252 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsImplement\", \" the Query Specification pattern\\nAs introduced earlier in the design section, the Query Specificatio\", \"n pattern is a Domain-Driven Design\\npattern designed as the place where you can put the definition o\", \"f a query with optional sorting and\\npaging logic.\\nThe Query Specification pattern defines a query in\", \" an object. For example, in order to encapsulate a\\npaged query that searches for some products you c\", \"an create a PagedProduct specification that takes\\nthe necessary input parameters (pageNumber, pageSi\", \"ze, filter, etc.). Then, within any Repository\\nmethod (usually a List() overload) it would accept an\", \" IQuerySpecification and run the expected query\\nbased on that specification.\\nAn example of a generic\", \" Specification interface is the following code, which is similar to code used in\\nthe eShopOnWeb refe\", \"rence application.\\n// GENERIC SPECIFICATION INTERFACE\\n// https://github.com/dotnet-architecture/eSho\", \"pOnWeb\\npublic interface ISpecification<T>\\n{\\nExpression<Func<T, bool>> Criteria { get; }\\nList<Express\", \"ion<Func<T, object>>> Includes { get; }\\nList<string> IncludeStrings { get; }\\n}\\nThen, the implementat\", \"ion of a generic specification base class is the following.\\n// GENERIC SPECIFICATION IMPLEMENTATION \", \"(BASE CLASS)\\n// https://github.com/dotnet-architecture/eShopOnWeb\\npublic abstract class BaseSpecific\", \"ation<T> : ISpecification<T>\\n{\\npublic BaseSpecification(Expression<Func<T, bool>> criteria)\\n{\\nCriter\", \"ia = criteria;\\n}\\npublic Expression<Func<T, bool>> Criteria { get; }\\npublic List<Expression<Func<T, o\", \"bject>>> Includes { get; } =\\nnew List<Expression<Func<T, object>>>();\\npublic List<string> IncludeStr\", \"ings { get; } = new List<string>();\\nprotected virtual void AddInclude(Expression<Func<T, object>> in\", \"cludeExpression)\\n{\\nIncludes.Add(includeExpression);\\n}\\n// string-based includes allow for including c\", \"hildren of children\\n// e.g. Basket.Items.Product\\nprotected virtual void AddInclude(string includeStr\", \"ing)\\n{\\nIncludeStrings.Add(includeString);\\n}\\n}\\n253 CHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS PatternsThe following specification loads a single basket entity given eith\", \"er the basket\\u2019s ID or the ID of the\\nbuyer to whom the basket belongs. It will eagerly load the baske\", \"t\\u2019s Items collection.\\n// SAMPLE QUERY SPECIFICATION IMPLEMENTATION\\npublic class BasketWithItemsSpeci\", \"fication : BaseSpecification<Basket>\\n{\\npublic BasketWithItemsSpecification(int basketId)\\n: base(b =>\", \" b.Id == basketId)\\n{\\nAddInclude(b => b.Items);\\n}\\npublic BasketWithItemsSpecification(string buyerId)\", \"\\n: base(b => b.BuyerId == buyerId)\\n{\\nAddInclude(b => b.Items);\\n}\\n}\\nAnd finally, you can see below ho\", \"w a generic EF Repository can use such a specification to filter and\\neager-load data related to a gi\", \"ven entity type T.\\n// GENERIC EF REPOSITORY WITH SPECIFICATION\\n// https://github.com/dotnet-architec\", \"ture/eShopOnWeb\\npublic IEnumerable<T> List(ISpecification<T> spec)\\n{\\n// fetch a Queryable that inclu\", \"des all expression-based includes\\nvar queryableResultWithIncludes = spec.Includes\\n.Aggregate(_dbCont\", \"ext.Set<T>().AsQueryable(),\\n(current, include) => current.Include(include));\\n// modify the IQueryabl\", \"e to include any string-based include statements\\nvar secondaryResult = spec.IncludeStrings\\n.Aggregat\", \"e(queryableResultWithIncludes,\\n(current, include) => current.Include(include));\\n// return the result\", \" of the query using the specification's criteria expression\\nreturn secondaryResult\\n.Where(spec.Crite\", \"ria)\\n.AsEnumerable();\\n}\\nIn addition to encapsulating filtering logic, the specification can specify \", \"the shape of the data to be\\nreturned, including which properties to populate.\\nAlthough we don\\u2019t reco\", \"mmend returning IQueryable from a repository, it\\u2019s perfectly fine to use them\\nwithin the repository \", \"to build up a set of results. You can see this approach used in the List method\\nabove, which uses in\", \"termediate IQueryable expressions to build up the query\\u2019s list of includes before\\nexecuting the quer\", \"y with the specification\\u2019s criteria on the last line.\\nLearn how the specification pattern is applied\", \" in the eShopOnWeb sample.\\n254 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and\", \" CQRS PatternsAdditional resources\\n\\u2022 Table Mapping\\nhttps://learn.microsoft.com/ef/core/modeling/rela\", \"tional/tables\\n\\u2022 Use HiLo to generate keys with Entity Framework Core\\nhttps://www.talkingdotnet.com/u\", \"se-hilo-to-generate-keys-with-entity-framework-core/\\n\\u2022 Backing Fields\\nhttps://learn.microsoft.com/ef\", \"/core/modeling/backing-field\\n\\u2022 Steve Smith. Encapsulated Collections in Entity Framework Core\\nhttps:\", \"//ardalis.com/encapsulated-collections-in-entity-framework-core\\n\\u2022 Shadow Properties\\nhttps://learn.mi\", \"crosoft.com/ef/core/modeling/shadow-properties\\n\\u2022 The Specification pattern\\nhttps://deviq.com/specifi\", \"cation-pattern/\\nArdalis.Specification NuGet Package Used by\\neShopOnWeb. https://www.nuget.org/packag\", \"es/Ardalis.Specification\\nUse NoSQL databases as a persistence infrastructure\\nWhen you use NoSQL data\", \"bases for your infrastructure data tier, you typically do not use an ORM like\\nEntity Framework Core.\", \" Instead you use the API provided by the NoSQL engine, such as Azure Cosmos\\nDB, MongoDB, Cassandra, \", \"RavenDB, CouchDB, or Azure Storage Tables.\\nHowever, when you use a NoSQL database, especially a docu\", \"ment-oriented database like Azure\\nCosmos DB, CouchDB, or RavenDB, the way you design your model with\", \" DDD aggregates is partially\\nsimilar to how you can do it in EF Core, in regards to the identificati\", \"on of aggregate roots, child entity\\nclasses, and value object classes. But, ultimately, the database\", \" selection will impact in your design.\\nWhen you use a document-oriented database, you implement an a\", \"ggregate as a single document,\\nserialized in JSON or another format. However, the use of the databas\", \"e is transparent from a domain\\nmodel code point of view. When using a NoSQL database, you still are \", \"using entity classes and\\naggregate root classes, but with more flexibility than when using EF Core b\", \"ecause the persistence is\\nnot relational.\\nThe difference is in how you persist that model. If you im\", \"plemented your domain model based on\\nPOCO entity classes, agnostic to the infrastructure persistence\", \", it might look like you could move to a\\ndifferent persistence infrastructure, even from relational \", \"to NoSQL. However, that should not be your\\ngoal. There are always constraints and trade-offs in the \", \"different database technologies, so you will\\nnot be able to have the same model for relational or No\", \"SQL databases. Changing persistence models\\nis not a trivial task, because transactions and persisten\", \"ce operations will be very different.\\nFor example, in a document-oriented database, it is okay for a\", \"n aggregate root to have multiple child\\ncollection properties. In a relational database, querying mu\", \"ltiple child collection properties is not\\n255 CHAPTER 6 | Tackle Business Complexity in a Microservi\", \"ce with DDD and CQRS Patternseasily optimized, because you get a UNION ALL SQL statement back from E\", \"F. Having the same\\ndomain model for relational databases or NoSQL databases is not simple, and you s\", \"hould not try to\\ndo it. You really have to design your model with an understanding of how the data i\", \"s going to be\\nused in each particular database.\\nA benefit when using NoSQL databases is that the ent\", \"ities are more denormalized, so you do not set a\\ntable mapping. Your domain model can be more flexib\", \"le than when using a relational database.\\nWhen you design your domain model based on aggregates, mov\", \"ing to NoSQL and document-\\noriented databases might be even easier than using a relational database,\", \" because the aggregates\\nyou design are similar to serialized documents in a document-oriented databa\", \"se. Then you can\\ninclude in those \\u201cbags\\u201d all the information you might need for that aggregate.\\nFor \", \"instance, the following JSON code is a sample implementation of an order aggregate when using\\na docu\", \"ment-oriented database. It is similar to the order aggregate we implemented in the\\neShopOnContainers\", \" sample, but without using EF Core underneath.\\n{\\n\\\"id\\\": \\\"2024001\\\",\\n\\\"orderDate\\\": \\\"2/25/2024\\\",\\n\\\"buyerId\", \"\\\": \\\"1234567\\\",\\n\\\"address\\\": [\\n{\\n\\\"street\\\": \\\"100 One Microsoft Way\\\",\\n\\\"city\\\": \\\"Redmond\\\",\\n\\\"state\\\": \\\"WA\\\",\\n\\\"z\", \"ip\\\": \\\"98052\\\",\\n\\\"country\\\": \\\"U.S.\\\"\\n}\\n],\\n\\\"orderItems\\\": [\\n{\\\"id\\\": 20240011, \\\"productId\\\": \\\"123456\\\", \\\"produc\", \"tName\\\": \\\".NET T-Shirt\\\",\\n\\\"unitPrice\\\": 25, \\\"units\\\": 2, \\\"discount\\\": 0},\\n{\\\"id\\\": 20240012, \\\"productId\\\": \\\"\", \"123457\\\", \\\"productName\\\": \\\".NET Mug\\\",\\n\\\"unitPrice\\\": 15, \\\"units\\\": 1, \\\"discount\\\": 0}\\n]\\n}\\nIntroduction to \", \"Azure Cosmos DB and the native Cosmos DB API\\nAzure Cosmos DB is Microsoft\\u2019s globally distributed dat\", \"abase service for mission-critical applications.\\nAzure Cosmos DB provides turn-key global distributi\", \"on, elastic scaling of throughput and storage\\nworldwide, single-digit millisecond latencies at the 9\", \"9th percentile, five well-defined consistency\\nlevels, and guaranteed high availability, all backed b\", \"y industry-leading SLAs. Azure Cosmos DB\\nautomatically indexes data without requiring you to deal wi\", \"th schema and index management. It is\\nmulti-model and supports document, key-value, graph, and colum\", \"nar data models.\\n256 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patt\", \"ernsFigure 7-19. Azure Cosmos DB global distribution\\nWhen you use a C# model to implement the aggreg\", \"ate to be used by the Azure Cosmos DB API, the\\naggregate can be similar to the C# POCO classes used \", \"with EF Core. The difference is in the way to\\nuse them from the application and infrastructure layer\", \"s, as in the following code:\\n// C# EXAMPLE OF AN ORDER AGGREGATE BEING PERSISTED WITH AZURE COSMOS D\", \"B API\\n// *** Domain Model Code ***\\n// Aggregate: Create an Order object with its child entities and/\", \"or value objects.\\n// Then, use AggregateRoot's methods to add the nested objects so invariants and\\n/\", \"/ logic is consistent across the nested properties (value objects and entities).\\nOrder orderAggregat\", \"e = new Order\\n{\\nId = \\\"2024001\\\",\\nOrderDate = new DateTime(2005, 7, 1),\\nBuyerId = \\\"1234567\\\",\\nPurchaseO\", \"rderNumber = \\\"PO18009186470\\\"\\n}\\nAddress address = new Address\\n{\\nStreet = \\\"100 One Microsoft Way\\\",\\nCit\", \"y = \\\"Redmond\\\",\\nState = \\\"WA\\\",\\nZip = \\\"98052\\\",\\nCountry = \\\"U.S.\\\"\\n}\\norderAggregate.UpdateAddress(address)\", \";\\nOrderItem orderItem1 = new OrderItem\\n{\\n257 CHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS PatternsId = 20240011,\\nProductId = \\\"123456\\\",\\nProductName = \\\".NET T-Shirt\\\",\\nUnitP\", \"rice = 25,\\nUnits = 2,\\nDiscount = 0;\\n};\\n//Using methods with domain logic within the entity. No anemi\", \"c-domain model\\norderAggregate.AddOrderItem(orderItem1);\\n// *** End of Domain Model Code ***\\n// *** I\", \"nfrastructure Code using Cosmos DB Client API ***\\nUri collectionUri = UriFactory.CreateDocumentColle\", \"ctionUri(databaseName,\\ncollectionName);\\nawait client.CreateDocumentAsync(collectionUri, orderAggrega\", \"te);\\n// As your app evolves, let's say your object has a new schema. You can insert\\n// OrderV2 objec\", \"ts without any changes to the database tier.\\nOrder2 newOrder = GetOrderV2Sample(\\\"IdForSalesOrder2\\\");\", \"\\nawait client.CreateDocumentAsync(collectionUri, newOrder);\\nYou can see that the way you work with y\", \"our domain model can be similar to the way you use it in\\nyour domain model layer when the infrastruc\", \"ture is EF. You still use the same aggregate root methods\\nto ensure consistency, invariants, and val\", \"idations within the aggregate.\\nHowever, when you persist your model into the NoSQL database, the cod\", \"e and API change\\ndramatically compared to EF Core code or any other code related to relational datab\", \"ases.\\nImplement .NET code targeting MongoDB and Azure Cosmos DB\\nUse Azure Cosmos DB from .NET contai\", \"ners\\nYou can access Azure Cosmos DB databases from .NET code running in containers, like from any ot\", \"her\\n.NET application. For instance, the Locations.API and Marketing.API microservices in\\neShopOnCont\", \"ainers are implemented so they can consume Azure Cosmos DB databases.\\nHowever, there\\u2019s a limitation \", \"in Azure Cosmos DB from a Docker development environment point of\\nview. Even though there\\u2019s an on-pr\", \"emises Azure Cosmos DB Emulator that can run in a local\\ndevelopment machine, it only supports Window\", \"s. Linux and macOS aren\\u2019t supported.\\nThere\\u2019s also the possibility to run this emulator on Docker, bu\", \"t just on Windows Containers, not with\\nLinux Containers. That\\u2019s an initial handicap for the developm\", \"ent environment if your application is\\ndeployed as Linux containers, since, currently, you can\\u2019t dep\", \"loy Linux and Windows Containers on\\nDocker for Windows at the same time. Either all containers being\", \" deployed have to be for Linux or for\\nWindows.\\nThe ideal and more straightforward deployment for a d\", \"ev/test solution is to be able to deploy your\\ndatabase systems as containers along with your custom \", \"containers so your dev/test environments are\\nalways consistent.\\n258 CHAPTER 6 | Tackle Business Comp\", \"lexity in a Microservice with DDD and CQRS PatternsUse MongoDB API for local dev/test Linux/Windows \", \"containers plus Azure Cosmos\\nDB\\nCosmos DB databases support MongoDB API for .NET as well as the nati\", \"ve MongoDB wire protocol.\\nThis means that by using existing drivers, your application written for Mo\", \"ngoDB can now\\ncommunicate with Cosmos DB and use Cosmos DB databases instead of MongoDB databases, a\", \"s\\nshown in Figure 7-20.\\nFigure 7-20. Using MongoDB API and protocol to access Azure Cosmos DB\\nThis i\", \"s a very convenient approach for proof of concepts in Docker environments with Linux\\ncontainers beca\", \"use the MongoDB Docker image is a multi-arch image that supports Docker Linux\\ncontainers and Docker \", \"Windows containers.\\nAs shown in the following image, by using the MongoDB API, eShopOnContainers sup\", \"ports MongoDB\\nLinux and Windows containers for the local development environment but then, you can m\", \"ove to a\\nscalable, PaaS cloud solution as Azure Cosmos DB by simply changing the MongoDB connection\\n\", \"string to point to Azure Cosmos DB.\\n259 CHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS PatternsFigure 7-21. eShopOnContainers using MongoDB containers for dev-env or Azure \", \"Cosmos DB for production\\nThe production Azure Cosmos DB would be running in Azure\\u2019s cloud as a PaaS \", \"and scalable service.\\nYour custom .NET containers can run on a local development Docker host (that i\", \"s using Docker for\\nWindows in a Windows 10 machine) or be deployed into a production environment, li\", \"ke Kubernetes in\\nAzure AKS or Azure Service Fabric. In this second environment, you would deploy onl\", \"y the .NET\\ncustom containers but not the MongoDB container since you\\u2019d be using Azure Cosmos DB in t\", \"he\\ncloud for handling the data in production.\\nA clear benefit of using the MongoDB API is that your \", \"solution could run in both database engines,\\nMongoDB or Azure Cosmos DB, so migrations to different \", \"environments should be easy. However,\\nsometimes it is worthwhile to use a native API (that is the na\", \"tive Cosmos DB API) in order to take full\\nadvantage of the capabilities of a specific database engin\", \"e.\\nFor further comparison between simply using MongoDB versus Cosmos DB in the cloud, see the\\nBenefi\", \"ts of using Azure Cosmos DB in this page.\\nAnalyze your approach for production applications: MongoDB\", \" API vs. Cosmos DB\\nAPI\\nIn eShopOnContainers, we\\u2019re using MongoDB API because our priority was fundam\", \"entally to have a\\nconsistent dev/test environment using a NoSQL database that could also work with A\", \"zure Cosmos DB.\\n260 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rnsHowever, if you are planning to use MongoDB API to access Azure Cosmos DB in Azure for\\nproduction\", \" applications, you should analyze the differences in capabilities and performance when\\nusing MongoDB\", \" API to access Azure Cosmos DB databases compared to using the native Azure\\nCosmos DB API. If it is \", \"similar you can use MongoDB API and you get the benefit of supporting two\\nNoSQL database engines at \", \"the same time.\\nYou could also use MongoDB clusters as the production database in Azure\\u2019s cloud, too,\", \" with\\nMongoDB Azure Service. But that is not a PaaS service provided by Microsoft. In this case, Azu\", \"re is just\\nhosting that solution coming from MongoDB.\\nBasically, this is just a disclaimer stating t\", \"hat you shouldn\\u2019t always use MongoDB API against Azure\\nCosmos DB, as we did in eShopOnContainers bec\", \"ause it was a convenient choice for Linux containers.\\nThe decision should be based on the specific n\", \"eeds and tests you need to do for your production\\napplication.\\nThe code: Use MongoDB API in .NET app\", \"lications\\nMongoDB API for .NET is based on NuGet packages that you need to add to your projects, lik\", \"e in the\\nLocations.API project shown in the following figure.\\n261 CHAPTER 6 | Tackle Business Comple\", \"xity in a Microservice with DDD and CQRS PatternsFigure 7-22. MongoDB API NuGet packages references \", \"in a .NET project\\nLet\\u2019s investigate the code in the following sections.\\nA Model used by MongoDB API\\n\", \"First, you need to define a model that will hold the data coming from the database in your\\napplicati\", \"on\\u2019s memory space. Here\\u2019s an example of the model used for Locations at\\neShopOnContainers.\\nusing Mon\", \"goDB.Bson;\\nusing MongoDB.Bson.Serialization.Attributes;\\nusing MongoDB.Driver.GeoJsonObjectModel;\\nusi\", \"ng System.Collections.Generic;\\npublic class Locations\\n{\\n262 CHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns[BsonId]\\n[BsonRepresentation(BsonType.ObjectId)]\\npublic s\", \"tring Id { get; set; }\\npublic int LocationId { get; set; }\\npublic string Code { get; set; }\\n[BsonRep\", \"resentation(BsonType.ObjectId)]\\npublic string Parent_Id { get; set; }\\npublic string Description { ge\", \"t; set; }\\npublic double Latitude { get; set; }\\npublic double Longitude { get; set; }\\npublic GeoJsonP\", \"oint<GeoJson2DGeographicCoordinates> Location\\n{ get; private set; }\\npublic GeoJsonPolygon<GeoJson2DG\", \"eographicCoordinates> Polygon\\n{ get; private set; }\\npublic void SetLocation(double lon, double lat) \", \"=> SetPosition(lon, lat);\\npublic void SetArea(List<GeoJson2DGeographicCoordinates> coordinatesList)\\n\", \"=> SetPolygon(coordinatesList);\\nprivate void SetPosition(double lon, double lat)\\n{\\nLatitude = lat;\\nL\", \"ongitude = lon;\\nLocation = new GeoJsonPoint<GeoJson2DGeographicCoordinates>(\\nnew GeoJson2DGeographic\", \"Coordinates(lon, lat));\\n}\\nprivate void SetPolygon(List<GeoJson2DGeographicCoordinates> coordinatesLi\", \"st)\\n{\\nPolygon = new GeoJsonPolygon<GeoJson2DGeographicCoordinates>(\\nnew GeoJsonPolygonCoordinates<Ge\", \"oJson2DGeographicCoordinates>(\\nnew GeoJsonLinearRingCoordinates<GeoJson2DGeographicCoordinates>(\\ncoo\", \"rdinatesList)));\\n}\\n}\\nYou can see there are a few attributes and types coming from the MongoDB NuGet \", \"packages.\\nNoSQL databases are usually very well suited for working with non-relational hierarchical \", \"data. In this\\nexample, we are using MongoDB types especially made for geo-locations, like\\nGeoJson2DG\", \"eographicCoordinates.\\nRetrieve the database and the collection\\nIn eShopOnContainers, we have created\", \" a custom database context where we implement the code to\\nretrieve the database and the MongoCollect\", \"ions, as in the following code.\\npublic class LocationsContext\\n{\\nprivate readonly IMongoDatabase _dat\", \"abase = null;\\npublic LocationsContext(IOptions<LocationSettings> settings)\\n{\\nvar client = new MongoC\", \"lient(settings.Value.ConnectionString);\\nif (client != null)\\n_database = client.GetDatabase(settings.\", \"Value.Database);\\n}\\npublic IMongoCollection<Locations> Locations\\n{\\n263 CHAPTER 6 | Tackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patternsget\\n{\\nreturn _database.GetCollection<Locations>\", \"(\\\"Locations\\\");\\n}\\n}\\n}\\nRetrieve the data\\nIn C# code, like Web API controllers or custom Repositories i\", \"mplementation, you can write similar\\ncode to the following when querying through the MongoDB API. No\", \"te that the _context object is an\\ninstance of the previous LocationsContext class.\\npublic async Task\", \"<Locations> GetAsync(int locationId)\\n{\\nvar filter = Builders<Locations>.Filter.Eq(\\\"LocationId\\\", loca\", \"tionId);\\nreturn await _context.Locations\\n.Find(filter)\\n.FirstOrDefaultAsync();\\n}\\nUse an env-var in t\", \"he docker-compose.override.yml file for the MongoDB connection\\nstring\\nWhen creating a MongoClient ob\", \"ject, it needs a fundamental parameter which is precisely the\\nConnectionString parameter pointing to\", \" the right database. In the case of eShopOnContainers, the\\nconnection string can point to a local Mo\", \"ngoDB Docker container or to a \\u201cproduction\\u201d Azure Cosmos\\nDB database. That connection string comes f\", \"rom the environment variables defined in the docker-\\ncompose.override.yml files used when deploying \", \"with docker-compose or Visual Studio, as in the\\nfollowing yml code.\\n# docker-compose.override.yml\\nve\", \"rsion: '3.4'\\nservices:\\n# Other services\\nlocations-api:\\nenvironment:\\n# Other settings\\n- ConnectionStr\", \"ing=${ESHOP_AZURE_COSMOSDB:-mongodb://nosqldata}\\nThe ConnectionString environment variable is resolv\", \"ed this way: If the ESHOP_AZURE_COSMOSDB\\nglobal variable is defined in the .env file with the Azure \", \"Cosmos DB connection string, it will use it to\\naccess the Azure Cosmos DB database in the cloud. If \", \"it\\u2019s not defined, it will take the\\nmongodb://nosqldata value and use the development MongoDB contain\", \"er.\\nThe following code shows the .env file with the Azure Cosmos DB connection string global\\nenviron\", \"ment variable, as implemented in eShopOnContainers:\\n# .env file, in eShopOnContainers root folder\\n# \", \"Other Docker environment variables\\nESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker.internal\\nESHOP_PROD_EXT\", \"ERNAL_DNS_NAME_OR_IP=<YourDockerHostIP>\\n#ESHOP_AZURE_COSMOSDB=<YourAzureCosmosDBConnData>\\n264 CHAPTE\", \"R 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns#Other environment vari\", \"ables for additional Azure infrastructure assets\\n#ESHOP_AZURE_REDIS_BASKET_DB=<YourAzureRedisBasketI\", \"nfo>\\n#ESHOP_AZURE_STORAGE_CATALOG_URL=<YourAzureStorage_Catalog_BLOB_URL>\\n#ESHOP_AZURE_SERVICE_BUS=<\", \"YourAzureServiceBusInfo>\\nUncomment the ESHOP_AZURE_COSMOSDB line and update it with your Azure Cosmo\", \"s DB\\nconnection string obtained from the Azure portal as explained in Connect a MongoDB application \", \"to\\nAzure Cosmos DB.\\nIf the ESHOP_AZURE_COSMOSDB global variable is empty, meaning it\\u2019s commented out\", \" in the .env\\nfile, then the container uses a default MongoDB connection string. This connection stri\", \"ng points to\\nthe local MongoDB container deployed in eShopOnContainers that is named nosqldata and w\", \"as\\ndefined at the docker-compose file, as shown in the following .yml code:\\n# docker-compose.yml\\nver\", \"sion: '3.4'\\nservices:\\n# ...Other services...\\nnosqldata:\\nimage: mongo\\nAdditional resources\\n\\u2022 Modeling\", \" document data for NoSQL databases\\nhttps://learn.microsoft.com/azure/cosmos-db/modeling-data\\n\\u2022 Vaugh\", \"n Vernon. The Ideal Domain-Driven Design Aggregate Store?\\nhttps://kalele.io/blog-posts/the-ideal-dom\", \"ain-driven-design-aggregate-store/\\n\\u2022 Introduction to Azure Cosmos DB: API for MongoDB\\nhttps://learn.\", \"microsoft.com/azure/cosmos-db/mongodb-introduction\\n\\u2022 Azure Cosmos DB: Build a MongoDB API web app wi\", \"th .NET and the Azure portal\\nhttps://learn.microsoft.com/azure/cosmos-db/create-mongodb-dotnet\\n\\u2022 Use\", \" the Azure Cosmos DB Emulator for local development and testing\\nhttps://learn.microsoft.com/azure/co\", \"smos-db/local-emulator\\n\\u2022 Connect a MongoDB application to Azure Cosmos DB\\nhttps://learn.microsoft.co\", \"m/azure/cosmos-db/connect-mongodb-account\\n\\u2022 The Cosmos DB Emulator Docker image (Windows Container)\\n\", \"https://hub.docker.com/r/microsoft/azure-cosmosdb-emulator/\\n\\u2022 The MongoDB Docker image (Linux and Wi\", \"ndows Container)\\nhttps://hub.docker.com/_/mongo/\\n\\u2022 Use MongoChef (Studio 3T) with an Azure Cosmos DB\", \": API for MongoDB account\\nhttps://learn.microsoft.com/azure/cosmos-db/mongodb-mongochef\\n265 CHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsDesign the microservice a\", \"pplication layer and Web\\nAPI\\nUse SOLID principles and Dependency Injection\\nSOLID principles are crit\", \"ical techniques to be used in any modern and mission-critical application,\\nsuch as developing a micr\", \"oservice with DDD patterns. SOLID is an acronym that groups five\\nfundamental principles:\\n\\u2022 Single Re\", \"sponsibility principle\\n\\u2022 Open/closed principle\\n\\u2022 Liskov substitution principle\\n\\u2022 Interface Segregati\", \"on principle\\n\\u2022 Dependency Inversion principle\\nSOLID is more about how you design your application or\", \" microservice internal layers and about\\ndecoupling dependencies between them. It is not related to t\", \"he domain, but to the application\\u2019s\\ntechnical design. The final principle, the Dependency Inversion \", \"principle, allows you to decouple the\\ninfrastructure layer from the rest of the layers, which allows\", \" a better decoupled implementation of the\\nDDD layers.\\nDependency Injection (DI) is one way to implem\", \"ent the Dependency Inversion principle. It is a\\ntechnique for achieving loose coupling between objec\", \"ts and their dependencies. Rather than directly\\ninstantiating collaborators, or using static referen\", \"ces (that is, using new\\u2026), the objects that a class\\nneeds in order to perform its actions are provid\", \"ed to (or \\u201cinjected into\\u201d) the class. Most often, classes\\nwill declare their dependencies via their \", \"constructor, allowing them to follow the Explicit\\nDependencies principle. Dependency Injection is us\", \"ually based on specific Inversion of Control (IoC)\\ncontainers. ASP.NET Core provides a simple built-\", \"in IoC container, but you can also use your favorite\\nIoC container, like Autofac or Ninject.\\nBy foll\", \"owing the SOLID principles, your classes will tend naturally to be small, well-factored, and easily\\n\", \"tested. But how can you know if too many dependencies are being injected into your classes? If you\\nu\", \"se DI through the constructor, it will be easy to detect that by just looking at the number of\\nparam\", \"eters for your constructor. If there are too many dependencies, this is generally a sign (a code\\nsme\", \"ll) that your class is trying to do too much, and is probably violating the Single Responsibility\\npr\", \"inciple.\\nIt would take another guide to cover SOLID in detail. Therefore, this guide requires you to\", \" have only a\\nminimum knowledge of these topics.\\nAdditional resources\\n\\u2022 SOLID: Fundamental OOP Princi\", \"ples\\nhttps://deviq.com/solid/\\n266 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD \", \"and CQRS Patterns\\u2022 Inversion of Control Containers and the Dependency Injection pattern\\nhttps://mart\", \"infowler.com/articles/injection.html\\n\\u2022 Steve Smith. New is Glue\\nhttps://ardalis.com/new-is-glue\\nImpl\", \"ement the microservice application layer using\\nthe Web API\\nUse Dependency Injection to inject infras\", \"tructure objects into your\\napplication layer\\nAs mentioned previously, the application layer can be i\", \"mplemented as part of the artifact (assembly)\\nyou are building, such as within a Web API project or \", \"an MVC web app project. In the case of a\\nmicroservice built with ASP.NET Core, the application layer\", \" will usually be your Web API library. If you\\nwant to separate what is coming from ASP.NET Core (its\", \" infrastructure plus your controllers) from your\\ncustom application layer code, you could also place\", \" your application layer in a separate class library,\\nbut that is optional.\\nFor instance, the applica\", \"tion layer code of the ordering microservice is directly implemented as part of\\nthe Ordering.API pro\", \"ject (an ASP.NET Core Web API project), as shown in Figure 7-23.\\nFigure 7-23. The application layer \", \"in the Ordering.API ASP.NET Core Web API project\\nASP.NET Core includes a simple built-in IoC contain\", \"er (represented by the IServiceProvider interface)\\nthat supports constructor injection by default, a\", \"nd ASP.NET makes certain services available through\\nDI. ASP.NET Core uses the term service for any o\", \"f the types you register that will be injected through\\nDI. You configure the built-in container\\u2019s se\", \"rvices in your application\\u2019s Program.cs file. Your\\n267 CHAPTER 6 | Tackle Business Complexity in a M\", \"icroservice with DDD and CQRS Patternsdependencies are implemented in the services that a type needs\", \" and that you register in the IoC\\ncontainer.\\nTypically, you want to inject dependencies that impleme\", \"nt infrastructure objects. A typical\\ndependency to inject is a repository. But you could inject any \", \"other infrastructure dependency that\\nyou may have. For simpler implementations, you could directly i\", \"nject your Unit of Work pattern object\\n(the EF DbContext object), because the DBContext is also the \", \"implementation of your infrastructure\\npersistence objects.\\nIn the following example, you can see how\", \" .NET is injecting the required repository objects through\\nthe constructor. The class is a command h\", \"andler, which will get covered in the next section.\\npublic class CreateOrderCommandHandler\\n: IReques\", \"tHandler<CreateOrderCommand, bool>\\n{\\nprivate readonly IOrderRepository _orderRepository;\\nprivate rea\", \"donly IIdentityService _identityService;\\nprivate readonly IMediator _mediator;\\nprivate readonly IOrd\", \"eringIntegrationEventService _orderingIntegrationEventService;\\nprivate readonly ILogger<CreateOrderC\", \"ommandHandler> _logger;\\n// Using DI to inject infrastructure persistence Repositories\\npublic CreateO\", \"rderCommandHandler(IMediator mediator,\\nIOrderingIntegrationEventService orderingIntegrationEventServ\", \"ice,\\nIOrderRepository orderRepository,\\nIIdentityService identityService,\\nILogger<CreateOrderCommandH\", \"andler> logger)\\n{\\n_orderRepository = orderRepository ?? throw new\\nArgumentNullException(nameof(order\", \"Repository));\\n_identityService = identityService ?? throw new\\nArgumentNullException(nameof(identityS\", \"ervice));\\n_mediator = mediator ?? throw new ArgumentNullException(nameof(mediator));\\n_orderingIntegr\", \"ationEventService = orderingIntegrationEventService ?? throw new\\nArgumentNullException(nameof(orderi\", \"ngIntegrationEventService));\\n_logger = logger ?? throw new ArgumentNullException(nameof(logger));\\n}\\n\", \"public async Task<bool> Handle(CreateOrderCommand message, CancellationToken\\ncancellationToken)\\n{\\n//\", \" Add Integration event to clean the basket\\nvar orderStartedIntegrationEvent = new\\nOrderStartedIntegr\", \"ationEvent(message.UserId);\\nawait\\n_orderingIntegrationEventService.AddAndSaveEventAsync(orderStarted\", \"IntegrationEvent);\\n// Add/Update the Buyer AggregateRoot\\n// DDD patterns comment: Add child entities\", \" and value-objects through the Order\\nAggregate-Root\\n// methods and constructor so validations, invar\", \"iants and business logic\\n// make sure that consistency is preserved across the whole aggregate\\nvar a\", \"ddress = new Address(message.Street, message.City, message.State,\\nmessage.Country, message.ZipCode);\", \"\\nvar order = new Order(message.UserId, message.UserName, address,\\nmessage.CardTypeId, message.CardNu\", \"mber, message.CardSecurityNumber, message.CardHolderName,\\nmessage.CardExpiration);\\nforeach (var item\", \" in message.OrderItems)\\n268 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQ\", \"RS Patterns{\\norder.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice,\\nitem.Discount, ite\", \"m.PictureUrl, item.Units);\\n}\\n_logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order)\", \";\\n_orderRepository.Add(order);\\nreturn await _orderRepository.UnitOfWork\\n.SaveEntitiesAsync(cancellat\", \"ionToken);\\n}\\n}\\nThe class uses the injected repositories to execute the transaction and persist the s\", \"tate changes. It\\ndoes not matter whether that class is a command handler, an ASP.NET Core Web API co\", \"ntroller\\nmethod, or a DDD Application Service. It is ultimately a simple class that uses repositorie\", \"s, domain\\nentities, and other application coordination in a fashion similar to a command handler. De\", \"pendency\\nInjection works the same way for all the mentioned classes, as in the example using DI base\", \"d on the\\nconstructor.\\nRegister the dependency implementation types and interfaces or abstractions\\nBe\", \"fore you use the objects injected through constructors, you need to know where to register the\\ninter\", \"faces and classes that produce the objects injected into your application classes through DI. (Like\\n\", \"DI based on the constructor, as shown previously.)\\nUse the built-in IoC container provided by ASP.NE\", \"T Core\\nWhen you use the built-in IoC container provided by ASP.NET Core, you register the types you \", \"want\\nto inject in the Program.cs file, as in the following code:\\n// Register out-of-the-box framewor\", \"k services.\\nbuilder.Services.AddDbContext<CatalogContext>(c =>\\nc.UseSqlServer(Configuration[\\\"Connect\", \"ionString\\\"]),\\nServiceLifetime.Scoped);\\nbuilder.Services.AddMvc();\\n// Register custom application dep\", \"endencies.\\nbuilder.Services.AddScoped<IMyCustomRepository, MyCustomSQLRepository>();\\nThe most common\", \" pattern when registering types in an IoC container is to register a pair of types\\u2014an\\ninterface and \", \"its related implementation class. Then when you request an object from the IoC\\ncontainer through any\", \" constructor, you request an object of a certain type of interface. For instance, in\\nthe previous ex\", \"ample, the last line states that when any of your constructors have a dependency on\\nIMyCustomReposit\", \"ory (interface or abstraction), the IoC container will inject an instance of the\\nMyCustomSQLServerRe\", \"pository implementation class.\\nUse the Scrutor library for automatic types registration\\nWhen using D\", \"I in .NET, you might want to be able to scan an assembly and automatically register its\\ntypes by con\", \"vention. This feature is not currently available in ASP.NET Core. However, you can use the\\n269 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsScrutor library for th\", \"at. This approach is convenient when you have dozens of types that need to be\\nregistered in your IoC\", \" container.\\nAdditional resources\\n\\u2022 Matthew King. Registering services with Scrutor\\nhttps://www.mking\", \".net/blog/registering-services-with-scrutor\\n\\u2022 Kristian Hellang. Scrutor. GitHub repo.\\nhttps://github\", \".com/khellang/Scrutor\\nUse Autofac as an IoC container\\nYou can also use additional IoC containers and\", \" plug them into the ASP.NET Core pipeline, as in the\\nordering microservice in eShopOnContainers, whi\", \"ch uses Autofac. When using Autofac you typically\\nregister the types via modules, which allow you to\", \" split the registration types between multiple files\\ndepending on where your types are, just as you \", \"could have the application types distributed across\\nmultiple class libraries.\\nFor example, the follo\", \"wing is the Autofac application module for the Ordering.API Web API project\\nwith the types you will \", \"want to inject.\\npublic class ApplicationModule : Autofac.Module\\n{\\npublic string QueriesConnectionStr\", \"ing { get; }\\npublic ApplicationModule(string qconstr)\\n{\\nQueriesConnectionString = qconstr;\\n}\\nprotect\", \"ed override void Load(ContainerBuilder builder)\\n{\\nbuilder.Register(c => new OrderQueries(QueriesConn\", \"ectionString))\\n.As<IOrderQueries>()\\n.InstancePerLifetimeScope();\\nbuilder.RegisterType<BuyerRepositor\", \"y>()\\n.As<IBuyerRepository>()\\n.InstancePerLifetimeScope();\\nbuilder.RegisterType<OrderRepository>()\\n.A\", \"s<IOrderRepository>()\\n.InstancePerLifetimeScope();\\nbuilder.RegisterType<RequestManager>()\\n.As<IReque\", \"stManager>()\\n.InstancePerLifetimeScope();\\n}\\n}\\nAutofac also has a feature to scan assemblies and regi\", \"ster types by name conventions.\\nThe registration process and concepts are very similar to the way yo\", \"u can register types with the built-\\nin ASP.NET Core IoC container, but the syntax when using Autofa\", \"c is a bit different.\\nIn the example code, the abstraction IOrderRepository is registered along with\", \" the implementation\\nclass OrderRepository. This means that whenever a constructor is declaring a dep\", \"endency through the\\n270 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS P\", \"atternsIOrderRepository abstraction or interface, the IoC container will inject an instance of the\\nO\", \"rderRepository class.\\nThe instance scope type determines how an instance is shared between requests \", \"for the same service\\nor dependency. When a request is made for a dependency, the IoC container can r\", \"eturn the following:\\n\\u2022 A single instance per lifetime scope (referred to in the ASP.NET Core IoC con\", \"tainer as scoped).\\n\\u2022 A new instance per dependency (referred to in the ASP.NET Core IoC container as\", \" transient).\\n\\u2022 A single instance shared across all objects using the IoC container (referred to in t\", \"he ASP.NET\\nCore IoC container as singleton).\\nAdditional resources\\n\\u2022 Introduction to Dependency Injec\", \"tion in ASP.NET Core\\nhttps://learn.microsoft.com/aspnet/core/fundamentals/dependency-injection\\n\\u2022 Aut\", \"ofac. Official documentation.\\nhttps://docs.autofac.org/en/latest/\\n\\u2022 Comparing ASP.NET Core IoC conta\", \"iner service lifetimes with Autofac IoC container\\ninstance scopes - Cesar de la Torre.\\nhttps://devbl\", \"ogs.microsoft.com/cesardelatorre/comparing-asp-net-core-ioc-service-life-\\ntimes-and-autofac-ioc-inst\", \"ance-scopes/\\nImplement the Command and Command Handler patterns\\nIn the DI-through-constructor exampl\", \"e shown in the previous section, the IoC container was injecting\\nrepositories through a constructor \", \"in a class. But exactly where were they injected? In a simple Web\\nAPI (for example, the catalog micr\", \"oservice in eShopOnContainers), you inject them at the MVC\\ncontrollers\\u2019 level, in a controller const\", \"ructor, as part of the request pipeline of ASP.NET Core. However,\\nin the initial code of this sectio\", \"n (the CreateOrderCommandHandler class from the Ordering.API\\nservice in eShopOnContainers), the inje\", \"ction of dependencies is done through the constructor of a\\nparticular command handler. Let us explai\", \"n what a command handler is and why you would want to\\nuse it.\\nThe Command pattern is intrinsically r\", \"elated to the CQRS pattern that was introduced earlier in this\\nguide. CQRS has two sides. The first \", \"area is queries, using simplified queries with the Dapper micro\\nORM, which was explained previously.\", \" The second area is commands, which are the starting point for\\ntransactions, and the input channel f\", \"rom outside the service.\\nAs shown in Figure 7-24, the pattern is based on accepting commands from th\", \"e client-side,\\nprocessing them based on the domain model rules, and finally persisting the states wi\", \"th transactions.\\n271 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patt\", \"ernsFigure 7-24. High-level view of the commands or \\u201ctransactional side\\u201d in a CQRS pattern\\nFigure 7-\", \"24 shows that the UI app sends a command through the API that gets to a\\nCommandHandler, that depends\", \" on the Domain model and the Infrastructure, to update the\\ndatabase.\\nThe command class\\nA command is \", \"a request for the system to perform an action that changes the state of the system.\\nCommands are imp\", \"erative, and should be processed just once.\\nSince commands are imperatives, they are typically named\", \" with a verb in the imperative mood (for\\nexample, \\u201ccreate\\u201d or \\u201cupdate\\u201d), and they might include the \", \"aggregate type, such as\\nCreateOrderCommand. Unlike an event, a command is not a fact from the past; \", \"it is only a request,\\nand thus may be refused.\\nCommands can originate from the UI as a result of a u\", \"ser initiating a request, or from a process\\nmanager when the process manager is directing an aggrega\", \"te to perform an action.\\nAn important characteristic of a command is that it should be processed jus\", \"t once by a single receiver.\\nThis is because a command is a single action or transaction you want to\", \" perform in the application.\\nFor example, the same order creation command should not be processed mo\", \"re than once. This is an\\nimportant difference between commands and events. Events may be processed m\", \"ultiple times,\\nbecause many systems or microservices might be interested in the event.\\nIn addition, \", \"it is important that a command be processed only once in case the command is not\\nidempotent. A comma\", \"nd is idempotent if it can be executed multiple times without changing the\\nresult, either because of\", \" the nature of the command, or because of the way the system handles the\\ncommand.\\nIt is a good pract\", \"ice to make your commands and updates idempotent when it makes sense under\\nyour domain\\u2019s business ru\", \"les and invariants. For instance, to use the same example, if for any reason\\n(retry logic, hacking, \", \"etc.) the same CreateOrder command reaches your system multiple times, you\\nshould be able to identif\", \"y it and ensure that you do not create multiple orders. To do so, you need to\\n272 CHAPTER 6 | Tackle\", \" Business Complexity in a Microservice with DDD and CQRS Patternsattach some kind of identity in the\", \" operations and identify whether the command or update was\\nalready processed.\\nYou send a command to \", \"a single receiver; you do not publish a command. Publishing is for events\\nthat state a fact\\u2014that som\", \"ething has happened and might be interesting for event receivers. In the\\ncase of events, the publish\", \"er has no concerns about which receivers get the event or what they do it.\\nBut domain or integration\", \" events are a different story already introduced in previous sections.\\nA command is implemented with\", \" a class that contains data fields or collections with all the\\ninformation that is needed in order t\", \"o execute that command. A command is a special kind of Data\\nTransfer Object (DTO), one that is speci\", \"fically used to request changes or transactions. The command\\nitself is based on exactly the informat\", \"ion that is needed for processing the command, and nothing\\nmore.\\nThe following example shows the sim\", \"plified CreateOrderCommand class. This is an immutable\\ncommand that is used in the ordering microser\", \"vice in eShopOnContainers.\\n// DDD and CQRS patterns comment: Note that it is recommended to implemen\", \"t immutable\\nCommands\\n// In this case, its immutability is achieved by having all the setters as priv\", \"ate\\n// plus only being able to update the data just once, when creating the object through its\\nconst\", \"ructor.\\n// References on Immutable Commands:\\n// http://cqrs.nu/Faq\\n// https://docs.spine3.org/motiva\", \"tion/immutability.html\\n// http://blog.gauffin.org/2012/06/griffin-container-introducing-command-supp\", \"ort/\\n// https://learn.microsoft.com/dotnet/csharp/programming-guide/classes-and-structs/how-to-\\nimpl\", \"ement-a-lightweight-class-with-auto-implemented-properties\\n[DataContract]\\npublic class CreateOrderCo\", \"mmand\\n: IRequest<bool>\\n{\\n[DataMember]\\nprivate readonly List<OrderItemDTO> _orderItems;\\n[DataMember]\\n\", \"public string UserId { get; private set; }\\n[DataMember]\\npublic string UserName { get; private set; }\", \"\\n[DataMember]\\npublic string City { get; private set; }\\n[DataMember]\\npublic string Street { get; priv\", \"ate set; }\\n[DataMember]\\npublic string State { get; private set; }\\n[DataMember]\\npublic string Country\", \" { get; private set; }\\n[DataMember]\\npublic string ZipCode { get; private set; }\\n[DataMember]\\n273 CHA\", \"PTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternspublic string CardNu\", \"mber { get; private set; }\\n[DataMember]\\npublic string CardHolderName { get; private set; }\\n[DataMemb\", \"er]\\npublic DateTime CardExpiration { get; private set; }\\n[DataMember]\\npublic string CardSecurityNumb\", \"er { get; private set; }\\n[DataMember]\\npublic int CardTypeId { get; private set; }\\n[DataMember]\\npubli\", \"c IEnumerable<OrderItemDTO> OrderItems => _orderItems;\\npublic CreateOrderCommand()\\n{\\n_orderItems = n\", \"ew List<OrderItemDTO>();\\n}\\npublic CreateOrderCommand(List<BasketItem> basketItems, string userId, st\", \"ring userName,\\nstring city, string street, string state, string country, string zipcode,\\nstring card\", \"Number, string cardHolderName, DateTime cardExpiration,\\nstring cardSecurityNumber, int cardTypeId) :\", \" this()\\n{\\n_orderItems = basketItems.ToOrderItemsDTO().ToList();\\nUserId = userId;\\nUserName = userName\", \";\\nCity = city;\\nStreet = street;\\nState = state;\\nCountry = country;\\nZipCode = zipcode;\\nCardNumber = ca\", \"rdNumber;\\nCardHolderName = cardHolderName;\\nCardExpiration = cardExpiration;\\nCardSecurityNumber = car\", \"dSecurityNumber;\\nCardTypeId = cardTypeId;\\nCardExpiration = cardExpiration;\\n}\\npublic class OrderItemD\", \"TO\\n{\\npublic int ProductId { get; set; }\\npublic string ProductName { get; set; }\\npublic decimal UnitP\", \"rice { get; set; }\\npublic decimal Discount { get; set; }\\npublic int Units { get; set; }\\npublic strin\", \"g PictureUrl { get; set; }\\n}\\n}\\n274 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS PatternsBasically, the command class contains all the data you need for performing a busin\", \"ess transaction by\\nusing the domain model objects. Thus, commands are simply data structures that co\", \"ntain read-only\\ndata, and no behavior. The command\\u2019s name indicates its purpose. In many languages l\", \"ike C#,\\ncommands are represented as classes, but they are not true classes in the real object-orient\", \"ed sense.\\nAs an additional characteristic, commands are immutable, because the expected usage is tha\", \"t they are\\nprocessed directly by the domain model. They do not need to change during their projected\", \" lifetime.\\nIn a C# class, immutability can be achieved by not having any setters or other methods th\", \"at change\\nthe internal state.\\nKeep in mind that if you intend or expect commands to go through a ser\", \"ializing/deserializing process,\\nthe properties must have a private setter, and the [DataMember] (or \", \"[JsonProperty]) attribute.\\nOtherwise, the deserializer won\\u2019t be able to reconstruct the object at th\", \"e destination with the required\\nvalues. You can also use truly read-only properties if the class has\", \" a constructor with parameters for all\\nproperties, with the usual camelCase naming convention, and a\", \"nnotate the constructor as\\n[JsonConstructor]. However, this option requires more code.\\nFor example, \", \"the command class for creating an order is probably similar in terms of data to the order\\nyou want t\", \"o create, but you probably do not need the same attributes. For instance,\\nCreateOrderCommand does no\", \"t have an order ID, because the order has not been created yet.\\nMany command classes can be simple, \", \"requiring only a few fields about some state that needs to be\\nchanged. That would be the case if you\", \" are just changing the status of an order from \\u201cin process\\u201d to\\n\\u201cpaid\\u201d or \\u201cshipped\\u201d by using a comman\", \"d similar to the following:\\n[DataContract]\\npublic class UpdateOrderStatusCommand\\n:IRequest<bool>\\n{\\n[\", \"DataMember]\\npublic string Status { get; private set; }\\n[DataMember]\\npublic string OrderId { get; pri\", \"vate set; }\\n[DataMember]\\npublic string BuyerIdentityGuid { get; private set; }\\n}\\nSome developers mak\", \"e their UI request objects separate from their command DTOs, but that is just a\\nmatter of preference\", \". It is a tedious separation with not much additional value, and the objects are\\nalmost exactly the \", \"same shape. For instance, in eShopOnContainers, some commands come directly\\nfrom the client-side.\\nTh\", \"e Command handler class\\nYou should implement a specific command handler class for each command. That\", \" is how the pattern\\nworks, and it\\u2019s where you\\u2019ll use the command object, the domain objects, and the\", \" infrastructure\\nrepository objects. The command handler is in fact the heart of the application laye\", \"r in terms of CQRS\\nand DDD. However, all the domain logic should be contained in the domain classes\\u2014\", \"within the\\naggregate roots (root entities), child entities, or domain services, but not within the c\", \"ommand handler,\\nwhich is a class from the application layer.\\n275 CHAPTER 6 | Tackle Business Complex\", \"ity in a Microservice with DDD and CQRS PatternsThe command handler class offers a strong stepping s\", \"tone in the way to achieve the Single\\nResponsibility Principle (SRP) mentioned in a previous section\", \".\\nA command handler receives a command and obtains a result from the aggregate that is used. The\\nres\", \"ult should be either successful execution of the command, or an exception. In the case of an\\nexcepti\", \"on, the system state should be unchanged.\\nThe command handler usually takes the following steps:\\n\\u2022 I\", \"t receives the command object, like a DTO (from the mediator or other infrastructure object).\\n\\u2022 It v\", \"alidates that the command is valid (if not validated by the mediator).\\n\\u2022 It instantiates the aggrega\", \"te root instance that is the target of the current command.\\n\\u2022 It executes the method on the aggregat\", \"e root instance, getting the required data from the\\ncommand.\\n\\u2022 It persists the new state of the aggr\", \"egate to its related database. This last operation is the\\nactual transaction.\\nTypically, a command h\", \"andler deals with a single aggregate driven by its aggregate root (root entity).\\nIf multiple aggrega\", \"tes should be impacted by the reception of a single command, you could use\\ndomain events to propagat\", \"e states or actions across multiple aggregates.\\nThe important point here is that when a command is b\", \"eing processed, all the domain logic should be\\ninside the domain model (the aggregates), fully encap\", \"sulated and ready for unit testing. The\\ncommand handler just acts as a way to get the domain model f\", \"rom the database, and as the final\\nstep, to tell the infrastructure layer (repositories) to persist \", \"the changes when the model is changed.\\nThe advantage of this approach is that you can refactor the d\", \"omain logic in an isolated, fully\\nencapsulated, rich, behavioral domain model without changing code \", \"in the application or\\ninfrastructure layers, which are the plumbing level (command handlers, Web API\", \", repositories, etc.).\\nWhen command handlers get complex, with too much logic, that can be a code sm\", \"ell. Review them,\\nand if you find domain logic, refactor the code to move that domain behavior to th\", \"e methods of the\\ndomain objects (the aggregate root and child entity).\\nAs an example of a command ha\", \"ndler class, the following code shows the same\\nCreateOrderCommandHandler class that you saw at the b\", \"eginning of this chapter. In this case, it also\\nhighlights the Handle method and the operations with\", \" the domain model objects/aggregates.\\npublic class CreateOrderCommandHandler\\n: IRequestHandler<Creat\", \"eOrderCommand, bool>\\n{\\nprivate readonly IOrderRepository _orderRepository;\\nprivate readonly IIdentit\", \"yService _identityService;\\nprivate readonly IMediator _mediator;\\nprivate readonly IOrderingIntegrati\", \"onEventService _orderingIntegrationEventService;\\nprivate readonly ILogger<CreateOrderCommandHandler>\", \" _logger;\\n// Using DI to inject infrastructure persistence Repositories\\npublic CreateOrderCommandHan\", \"dler(IMediator mediator,\\nIOrderingIntegrationEventService orderingIntegrationEventService,\\nIOrderRep\", \"ository orderRepository,\\n276 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS PatternsIIdentityService identityService,\\nILogger<CreateOrderCommandHandler> logger)\\n{\\n_orderRep\", \"ository = orderRepository ?? throw new\\nArgumentNullException(nameof(orderRepository));\\n_identityServ\", \"ice = identityService ?? throw new\\nArgumentNullException(nameof(identityService));\\n_mediator = media\", \"tor ?? throw new ArgumentNullException(nameof(mediator));\\n_orderingIntegrationEventService = orderin\", \"gIntegrationEventService ?? throw new\\nArgumentNullException(nameof(orderingIntegrationEventService))\", \";\\n_logger = logger ?? throw new ArgumentNullException(nameof(logger));\\n}\\npublic async Task<bool> Han\", \"dle(CreateOrderCommand message, CancellationToken\\ncancellationToken)\\n{\\n// Add Integration event to c\", \"lean the basket\\nvar orderStartedIntegrationEvent = new\\nOrderStartedIntegrationEvent(message.UserId);\", \"\\nawait\\n_orderingIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent);\\n// Add/U\", \"pdate the Buyer AggregateRoot\\n// DDD patterns comment: Add child entities and value-objects through \", \"the Order\\nAggregate-Root\\n// methods and constructor so validations, invariants and business logic\\n//\", \" make sure that consistency is preserved across the whole aggregate\\nvar address = new Address(messag\", \"e.Street, message.City, message.State,\\nmessage.Country, message.ZipCode);\\nvar order = new Order(mess\", \"age.UserId, message.UserName, address,\\nmessage.CardTypeId, message.CardNumber, message.CardSecurityN\", \"umber, message.CardHolderName,\\nmessage.CardExpiration);\\nforeach (var item in message.OrderItems)\\n{\\no\", \"rder.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice,\\nitem.Discount, item.PictureUrl, \", \"item.Units);\\n}\\n_logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\\n_orderReposi\", \"tory.Add(order);\\nreturn await _orderRepository.UnitOfWork\\n.SaveEntitiesAsync(cancellationToken);\\n}\\n}\", \"\\nThese are additional steps a command handler should take:\\n\\u2022 Use the command\\u2019s data to operate with \", \"the aggregate root\\u2019s methods and behavior.\\n\\u2022 Internally within the domain objects, raise domain even\", \"ts while the transaction is executed,\\nbut that is transparent from a command handler point of view.\\n\", \"\\u2022 If the aggregate\\u2019s operation result is successful and after the transaction is finished, raise\\nint\", \"egration events. (These might also be raised by infrastructure classes like repositories.)\\n277 CHAPT\", \"ER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAdditional resources\\n\\u2022\", \" Mark Seemann. At the Boundaries, Applications are Not Object-Oriented\\nhttps://blog.ploeh.dk/2011/05\", \"/31/AttheBoundaries,ApplicationsareNotObject-Oriented/\\n\\u2022 Commands and events\\nhttps://cqrs.nu/faq/Com\", \"mand%20and%20Events\\n\\u2022 What does a command handler do?\\nhttps://cqrs.nu/faq/Command%20Handlers\\n\\u2022 Jimmy\", \" Bogard. Domain Command Patterns \\u2013 Handlers\\nhttps://jimmybogard.com/domain-command-patterns-handlers\", \"/\\n\\u2022 Jimmy Bogard. Domain Command Patterns \\u2013 Validation\\nhttps://jimmybogard.com/domain-command-patter\", \"ns-validation/\\nThe Command process pipeline: how to trigger a command handler\\nThe next question is h\", \"ow to invoke a command handler. You could manually call it from each related\\nASP.NET Core controller\", \". However, that approach would be too coupled and is not ideal.\\nThe other two main options, which ar\", \"e the recommended options, are:\\n\\u2022 Through an in-memory Mediator pattern artifact.\\n\\u2022 With an asynchro\", \"nous message queue, in between controllers and handlers.\\nUse the Mediator pattern (in-memory) in the\", \" command pipeline\\nAs shown in Figure 7-25, in a CQRS approach you use an intelligent mediator, simil\", \"ar to an in-memory\\nbus, which is smart enough to redirect to the right command handler based on the \", \"type of the\\ncommand or DTO being received. The single black arrows between components represent the\\n\", \"dependencies between objects (in many cases, injected through DI) with their related interactions.\\n2\", \"78 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsFigure 7-25. U\", \"sing the Mediator pattern in process in a single CQRS microservice\\nThe above diagram shows a zoom-in\", \" from image 7-24: the ASP.NET Core controller sends the\\ncommand to MediatR\\u2019s command pipeline, so th\", \"ey get to the appropriate handler.\\nThe reason that using the Mediator pattern makes sense is that in\", \" enterprise applications, the\\nprocessing requests can get complicated. You want to be able to add an\", \" open number of cross-\\ncutting concerns like logging, validations, audit, and security. In these cas\", \"es, you can rely on a\\nmediator pipeline (see Mediator pattern) to provide a means for these extra be\", \"haviors or cross-\\ncutting concerns.\\nA mediator is an object that encapsulates the \\u201chow\\u201d of this proc\", \"ess: it coordinates execution based on\\nstate, the way a command handler is invoked, or the payload y\", \"ou provide to the handler. With a\\nmediator component, you can apply cross-cutting concerns in a cent\", \"ralized and transparent way by\\napplying decorators (or pipeline behaviors since MediatR 3). For more\", \" information, see the Decorator\\npattern.\\nDecorators and behaviors are similar to Aspect Oriented Pro\", \"gramming (AOP), only applied to a\\nspecific process pipeline managed by the mediator component. Aspec\", \"ts in AOP that implement cross-\\ncutting concerns are applied based on aspect weavers injected at com\", \"pilation time or based on object\\ncall interception. Both typical AOP approaches are sometimes said t\", \"o work \\u201clike magic,\\u201d because it is\\nnot easy to see how AOP does its work. When dealing with serious \", \"issues or bugs, AOP can be difficult\\nto debug. On the other hand, these decorators/behaviors are exp\", \"licit and applied only in the context\\nof the mediator, so debugging is much more predictable and eas\", \"y.\\nFor example, in the eShopOnContainers ordering microservice, has an implementation of two sample\\n\", \"behaviors, a LogBehavior class and a ValidatorBehavior class. The implementation of the behaviors is\", \"\\nexplained in the next section by showing how eShopOnContainers uses MediatR behaviors.\\n279 CHAPTER \", \"6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsUse message queues (out-o\", \"f-proc) in the command\\u2019s pipeline\\nAnother choice is to use asynchronous messages based on brokers or\", \" message queues, as shown in\\nFigure 7-26. That option could also be combined with the mediator compo\", \"nent right before the\\ncommand handler.\\nFigure 7-26. Using message queues (out of the process and int\", \"er-process communication) with CQRS commands\\nCommand\\u2019s pipeline can also be handled by a high availa\", \"bility message queue to deliver the\\ncommands to the appropriate handler. Using message queues to acc\", \"ept the commands can further\\ncomplicate your command\\u2019s pipeline, because you will probably need to s\", \"plit the pipeline into two\\nprocesses connected through the external message queue. Still, it should \", \"be used if you need to have\\nimproved scalability and performance based on asynchronous messaging. Co\", \"nsider that in the case of\\nFigure 7-26, the controller just posts the command message into the queue\", \" and returns. Then the\\ncommand handlers process the messages at their own pace. That is a great bene\", \"fit of queues: the\\nmessage queue can act as a buffer in cases when hyper scalability is needed, such\", \" as for stocks or any\\nother scenario with a high volume of ingress data.\\nHowever, because of the asy\", \"nchronous nature of message queues, you need to figure out how to\\ncommunicate with the client applic\", \"ation about the success or failure of the command\\u2019s process. As a\\nrule, you should never use \\u201cfire a\", \"nd forget\\u201d commands. Every business application needs to know if a\\ncommand was processed successfull\", \"y, or at least validated and accepted.\\nThus, being able to respond to the client after validating a \", \"command message that was submitted to\\nan asynchronous queue adds complexity to your system, as compa\", \"red to an in-process command\\nprocess that returns the operation\\u2019s result after running the transacti\", \"on. Using queues, you might\\nneed to return the result of the command process through other operation\", \" result messages, which will\\nrequire additional components and custom communication in your system.\\n\", \"280 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS PatternsAdditionally,\", \" async commands are one-way commands, which in many cases might not be needed, as\\nis explained in th\", \"e following interesting exchange between Burtsev Alexey and Greg Young in an\\nonline conversation:\\n[B\", \"urtsev Alexey] I find lots of code where people use async command handling or one-way command\\nmessag\", \"ing without any reason to do so (they are not doing some long operation, they are not\\nexecuting exte\", \"rnal async code, they do not even cross-application boundary to be using message\\nbus). Why do they i\", \"ntroduce this unnecessary complexity? And actually, I haven\\u2019t seen a CQRS code\\nexample with blocking\", \" command handlers so far, though it will work just fine in most cases.\\n[Greg Young] [\\u2026] an asynchron\", \"ous command doesn\\u2019t exist; it\\u2019s actually another event. If I must accept\\nwhat you send me and raise \", \"an event if I disagree, it\\u2019s no longer you telling me to do something [that\\nis, it\\u2019s not a command].\", \" It\\u2019s you telling me something has been done. This seems like a slight\\ndifference at first, but it h\", \"as many implications.\\nAsynchronous commands greatly increase the complexity of a system, because the\", \"re is no simple way\\nto indicate failures. Therefore, asynchronous commands are not recommended other\", \" than when\\nscaling requirements are needed or in special cases when communicating the internal micro\", \"services\\nthrough messaging. In those cases, you must design a separate reporting and recovery system\", \" for\\nfailures.\\nIn the initial version of eShopOnContainers, it was decided to use synchronous comman\", \"d processing,\\nstarted from HTTP requests and driven by the Mediator pattern. That easily allows you \", \"to return the\\nsuccess or failure of the process, as in the CreateOrderCommandHandler implementation.\", \"\\nIn any case, this should be a decision based on your application\\u2019s or microservice\\u2019s business\\nrequi\", \"rements.\\nImplement the command process pipeline with a mediator pattern\\n(MediatR)\\nAs a sample implem\", \"entation, this guide proposes using the in-process pipeline based on the Mediator\\npattern to drive c\", \"ommand ingestion and route commands, in memory, to the right command\\nhandlers. The guide also propos\", \"es applying behaviors in order to separate cross-cutting concerns.\\nFor implementation in .NET, there\", \" are multiple open-source libraries available that implement the\\nMediator pattern. The library used \", \"in this guide is the MediatR open-source library (created by Jimmy\\nBogard), but you could use anothe\", \"r approach. MediatR is a small and simple library that allows you to\\nprocess in-memory messages like\", \" a command, while applying decorators or behaviors.\\nUsing the Mediator pattern helps you to reduce c\", \"oupling and to isolate the concerns of the requested\\nwork, while automatically connecting to the han\", \"dler that performs that work\\u2014in this case, to\\ncommand handlers.\\nAnother good reason to use the Media\", \"tor pattern was explained by Jimmy Bogard when reviewing\\nthis guide:\\n281 CHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS PatternsI think it might be worth mentioning testing\", \" here \\u2013 it provides a nice consistent window into the\\nbehavior of your system. Request-in, response-\", \"out. We\\u2019ve found that aspect quite valuable in building\\nconsistently behaving tests.\\nFirst, let\\u2019s lo\", \"ok at a sample WebAPI controller where you actually would use the mediator object. If\\nyou weren\\u2019t us\", \"ing the mediator object, you\\u2019d need to inject all the dependencies for that controller,\\nthings like \", \"a logger object and others. Therefore, the constructor would be complicated. On the other\\nhand, if y\", \"ou use the mediator object, the constructor of your controller can be a lot simpler, with just a\\nfew\", \" dependencies instead of many dependencies if you had one per cross-cutting operation, as in the\\nfol\", \"lowing example:\\npublic class MyMicroserviceController : Controller\\n{\\npublic MyMicroserviceController\", \"(IMediator mediator,\\nIMyMicroserviceQueries microserviceQueries)\\n{\\n// ...\\n}\\n}\\nYou can see that the m\", \"ediator provides a clean and lean Web API controller constructor. In addition,\\nwithin the controller\", \" methods, the code to send a command to the mediator object is almost one line:\\n[Route(\\\"new\\\")]\\n[Http\", \"Post]\\npublic async Task<IActionResult> ExecuteBusinessOperation([FromBody]RunOpCommand\\nrunOperationC\", \"ommand)\\n{\\nvar commandResult = await _mediator.SendAsync(runOperationCommand);\\nreturn commandResult ?\", \" (IActionResult)Ok() : (IActionResult)BadRequest();\\n}\\nImplement idempotent Commands\\nIn eShopOnContai\", \"ners, a more advanced example than the above is submitting a\\nCreateOrderCommand object from the Orde\", \"ring microservice. But since the Ordering business\\nprocess is a bit more complex and, in our case, i\", \"t actually starts in the Basket microservice, this action\\nof submitting the CreateOrderCommand objec\", \"t is performed from an integration-event handler\\nnamed UserCheckoutAcceptedIntegrationEventHandler i\", \"nstead of a simple WebAPI controller called\\nfrom the client App as in the previous simpler example.\\n\", \"Nevertheless, the action of submitting the Command to MediatR is pretty similar, as shown in the\\nfol\", \"lowing code.\\nvar createOrderCommand = new CreateOrderCommand(eventMsg.Basket.Items,\\neventMsg.UserId,\", \" eventMsg.City,\\neventMsg.Street, eventMsg.State,\\neventMsg.Country, eventMsg.ZipCode,\\neventMsg.CardNu\", \"mber,\\neventMsg.CardHolderName,\\neventMsg.CardExpiration,\\neventMsg.CardSecurityNumber,\\neventMsg.CardTy\", \"peId);\\n282 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternsvar re\", \"questCreateOrder = new IdentifiedCommand<CreateOrderCommand,bool>(createOrderCommand,\\neventMsg.Reque\", \"stId);\\nresult = await _mediator.Send(requestCreateOrder);\\nHowever, this case is also slightly more a\", \"dvanced because we\\u2019re also implementing idempotent\\ncommands. The CreateOrderCommand process should b\", \"e idempotent, so if the same message comes\\nduplicated through the network, because of any reason, li\", \"ke retries, the same business order will be\\nprocessed just once.\\nThis is implemented by wrapping the\", \" business command (in this case CreateOrderCommand) and\\nembedding it into a generic IdentifiedComman\", \"d, which is tracked by an ID of every message coming\\nthrough the network that has to be idempotent.\\n\", \"In the code below, you can see that the IdentifiedCommand is nothing more than a DTO with and ID\\nplu\", \"s the wrapped business command object.\\npublic class IdentifiedCommand<T, R> : IRequest<R>\\nwhere T : \", \"IRequest<R>\\n{\\npublic T Command { get; }\\npublic Guid Id { get; }\\npublic IdentifiedCommand(T command, \", \"Guid id)\\n{\\nCommand = command;\\nId = id;\\n}\\n}\\nThen the CommandHandler for the IdentifiedCommand named I\", \"dentifiedCommandHandler.cs will\\nbasically check if the ID coming as part of the message already exis\", \"ts in a table. If it already exists, that\\ncommand won\\u2019t be processed again, so it behaves as an idem\", \"potent command. That infrastructure\\ncode is performed by the _requestManager.ExistAsync method call \", \"below.\\n// IdentifiedCommandHandler.cs\\npublic class IdentifiedCommandHandler<T, R> : IRequestHandler<\", \"IdentifiedCommand<T, R>, R>\\nwhere T : IRequest<R>\\n{\\nprivate readonly IMediator _mediator;\\nprivate re\", \"adonly IRequestManager _requestManager;\\nprivate readonly ILogger<IdentifiedCommandHandler<T, R>> _lo\", \"gger;\\npublic IdentifiedCommandHandler(\\nIMediator mediator,\\nIRequestManager requestManager,\\nILogger<I\", \"dentifiedCommandHandler<T, R>> logger)\\n{\\n_mediator = mediator;\\n_requestManager = requestManager;\\n_lo\", \"gger = logger ?? throw new System.ArgumentNullException(nameof(logger));\\n}\\n/// <summary>\\n/// Creates\", \" the result value to return if a previous request was found\\n/// </summary>\\n/// <returns></returns>\\n2\", \"83 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patternsprotected virt\", \"ual R CreateResultForDuplicateRequest()\\n{\\nreturn default(R);\\n}\\n/// <summary>\\n/// This method handles\", \" the command. It just ensures that no other request exists with\\nthe same ID, and if this is the case\", \"\\n/// just enqueues the original inner command.\\n/// </summary>\\n/// <param name=\\\"message\\\">IdentifiedCo\", \"mmand which contains both original command &\\nrequest ID</param>\\n/// <returns>Return value of inner c\", \"ommand or default value if request same ID was\\nfound</returns>\\npublic async Task<R> Handle(Identifie\", \"dCommand<T, R> message, CancellationToken\\ncancellationToken)\\n{\\nvar alreadyExists = await _requestMan\", \"ager.ExistAsync(message.Id);\\nif (alreadyExists)\\n{\\nreturn CreateResultForDuplicateRequest();\\n}\\nelse\\n{\", \"\\nawait _requestManager.CreateRequestForCommandAsync<T>(message.Id);\\ntry\\n{\\nvar command = message.Comm\", \"and;\\nvar commandName = command.GetGenericTypeName();\\nvar idProperty = string.Empty;\\nvar commandId = \", \"string.Empty;\\nswitch (command)\\n{\\ncase CreateOrderCommand createOrderCommand:\\nidProperty = nameof(cre\", \"ateOrderCommand.UserId);\\ncommandId = createOrderCommand.UserId;\\nbreak;\\ncase CancelOrderCommand cance\", \"lOrderCommand:\\nidProperty = nameof(cancelOrderCommand.OrderNumber);\\ncommandId = $\\\"{cancelOrderComman\", \"d.OrderNumber}\\\";\\nbreak;\\ncase ShipOrderCommand shipOrderCommand:\\nidProperty = nameof(shipOrderCommand\", \".OrderNumber);\\ncommandId = $\\\"{shipOrderCommand.OrderNumber}\\\";\\nbreak;\\ndefault:\\nidProperty = \\\"Id?\\\";\\nco\", \"mmandId = \\\"n/a\\\";\\nbreak;\\n}\\n_logger.LogInformation(\\n\\\"----- Sending command: {CommandName} - {IdPropert\", \"y}: {CommandId}\\n({@Command})\\\",\\ncommandName,\\nidProperty,\\ncommandId,\\n284 CHAPTER 6 | Tackle Business C\", \"omplexity in a Microservice with DDD and CQRS Patternscommand);\\n// Send the embedded business comman\", \"d to mediator so it runs its related\\nCommandHandler\\nvar result = await _mediator.Send(command, cance\", \"llationToken);\\n_logger.LogInformation(\\n\\\"----- Command result: {@Result} - {CommandName} - {IdPropert\", \"y}:\\n{CommandId} ({@Command})\\\",\\nresult,\\ncommandName,\\nidProperty,\\ncommandId,\\ncommand);\\nreturn result;\\n\", \"}\\ncatch\\n{\\nreturn default(R);\\n}\\n}\\n}\\n}\\nSince the IdentifiedCommand acts like a business command\\u2019s enve\", \"lope, when the business command\\nneeds to be processed because it is not a repeated ID, then it takes\", \" that inner business command and\\nresubmits it to Mediator, as in the last part of the code shown abo\", \"ve when running\\n_mediator.Send(message.Command), from the IdentifiedCommandHandler.cs.\\nWhen doing th\", \"at, it will link and run the business command handler, in this case, the\\nCreateOrderCommandHandler, \", \"which is running transactions against the Ordering database, as shown\\nin the following code.\\n// Crea\", \"teOrderCommandHandler.cs\\npublic class CreateOrderCommandHandler\\n: IRequestHandler<CreateOrderCommand\", \", bool>\\n{\\nprivate readonly IOrderRepository _orderRepository;\\nprivate readonly IIdentityService _ide\", \"ntityService;\\nprivate readonly IMediator _mediator;\\nprivate readonly IOrderingIntegrationEventServic\", \"e _orderingIntegrationEventService;\\nprivate readonly ILogger<CreateOrderCommandHandler> _logger;\\n// \", \"Using DI to inject infrastructure persistence Repositories\\npublic CreateOrderCommandHandler(IMediato\", \"r mediator,\\nIOrderingIntegrationEventService orderingIntegrationEventService,\\nIOrderRepository order\", \"Repository,\\nIIdentityService identityService,\\nILogger<CreateOrderCommandHandler> logger)\\n{\\n_orderRep\", \"ository = orderRepository ?? throw new\\nArgumentNullException(nameof(orderRepository));\\n_identityServ\", \"ice = identityService ?? throw new\\nArgumentNullException(nameof(identityService));\\n_mediator = media\", \"tor ?? throw new ArgumentNullException(nameof(mediator));\\n_orderingIntegrationEventService = orderin\", \"gIntegrationEventService ?? throw new\\nArgumentNullException(nameof(orderingIntegrationEventService))\", \";\\n_logger = logger ?? throw new ArgumentNullException(nameof(logger));\\n285 CHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns}\\npublic async Task<bool> Handle(CreateOrd\", \"erCommand message, CancellationToken\\ncancellationToken)\\n{\\n// Add Integration event to clean the bask\", \"et\\nvar orderStartedIntegrationEvent = new\\nOrderStartedIntegrationEvent(message.UserId);\\nawait\\n_order\", \"ingIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent);\\n// Add/Update the Buy\", \"er AggregateRoot\\n// DDD patterns comment: Add child entities and value-objects through the Order\\nAgg\", \"regate-Root\\n// methods and constructor so validations, invariants and business logic\\n// make sure th\", \"at consistency is preserved across the whole aggregate\\nvar address = new Address(message.Street, mes\", \"sage.City, message.State,\\nmessage.Country, message.ZipCode);\\nvar order = new Order(message.UserId, m\", \"essage.UserName, address,\\nmessage.CardTypeId, message.CardNumber, message.CardSecurityNumber, messag\", \"e.CardHolderName,\\nmessage.CardExpiration);\\nforeach (var item in message.OrderItems)\\n{\\norder.AddOrder\", \"Item(item.ProductId, item.ProductName, item.UnitPrice,\\nitem.Discount, item.PictureUrl, item.Units);\\n\", \"}\\n_logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\\n_orderRepository.Add(orde\", \"r);\\nreturn await _orderRepository.UnitOfWork\\n.SaveEntitiesAsync(cancellationToken);\\n}\\n}\\nRegister the\", \" types used by MediatR\\nIn order for MediatR to be aware of your command handler classes, you need to\", \" register the mediator\\nclasses and the command handler classes in your IoC container. By default, Me\", \"diatR uses Autofac as\\nthe IoC container, but you can also use the built-in ASP.NET Core IoC containe\", \"r or any other container\\nsupported by MediatR.\\nThe following code shows how to register Mediator\\u2019s t\", \"ypes and commands when using Autofac\\nmodules.\\npublic class MediatorModule : Autofac.Module\\n{\\nprotect\", \"ed override void Load(ContainerBuilder builder)\\n{\\nbuilder.RegisterAssemblyTypes(typeof(IMediator).Ge\", \"tTypeInfo().Assembly)\\n.AsImplementedInterfaces();\\n// Register all the Command classes (they implemen\", \"t IRequestHandler)\\n// in assembly holding the Commands\\nbuilder.RegisterAssemblyTypes(typeof(CreateOr\", \"derCommand).GetTypeInfo().Assembly)\\n.AsClosedTypesOf(typeof(IRequestHandler<,>));\\n// Other types reg\", \"istration\\n286 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns//.\", \"..\\n}\\n}\\nThis is where \\u201cthe magic happens\\u201d with MediatR.\\nAs each command handler implements the generi\", \"c IRequestHandler<T> interface, when you register\\nthe assemblies using RegisteredAssemblyTypes metho\", \"d all the types marked as IRequestHandler also\\ngets registered with their Commands. For example:\\npub\", \"lic class CreateOrderCommandHandler\\n: IRequestHandler<CreateOrderCommand, bool>\\n{\\nThat is the code t\", \"hat correlates commands with command handlers. The handler is just a simple class,\\nbut it inherits f\", \"rom RequestHandler<T>, where T is the command type, and MediatR makes sure it is\\ninvoked with the co\", \"rrect payload (the command).\\nApply cross-cutting concerns when processing commands with the\\nBehavior\", \"s in MediatR\\nThere is one more thing: being able to apply cross-cutting concerns to the mediator pip\", \"eline. You can\\nalso see at the end of the Autofac registration module code how it registers a behavi\", \"or type,\\nspecifically, a custom LoggingBehavior class and a ValidatorBehavior class. But you could a\", \"dd other\\ncustom behaviors, too.\\npublic class MediatorModule : Autofac.Module\\n{\\nprotected override vo\", \"id Load(ContainerBuilder builder)\\n{\\nbuilder.RegisterAssemblyTypes(typeof(IMediator).GetTypeInfo().As\", \"sembly)\\n.AsImplementedInterfaces();\\n// Register all the Command classes (they implement IRequestHand\", \"ler)\\n// in assembly holding the Commands\\nbuilder.RegisterAssemblyTypes(\\ntypeof(CreateOrderCommand).G\", \"etTypeInfo().Assembly).\\nAsClosedTypesOf(typeof(IRequestHandler<,>));\\n// Other types registration\\n//.\", \"..\\nbuilder.RegisterGeneric(typeof(LoggingBehavior<,>)).\\nAs(typeof(IPipelineBehavior<,>));\\nbuilder.Re\", \"gisterGeneric(typeof(ValidatorBehavior<,>)).\\nAs(typeof(IPipelineBehavior<,>));\\n}\\n}\\nThat LoggingBehav\", \"ior class can be implemented as the following code, which logs information about\\nthe command handler\", \" being executed and whether it was successful or not.\\npublic class LoggingBehavior<TRequest, TRespon\", \"se>\\n: IPipelineBehavior<TRequest, TResponse>\\n{\\nprivate readonly ILogger<LoggingBehavior<TRequest, TR\", \"esponse>> _logger;\\npublic LoggingBehavior(ILogger<LoggingBehavior<TRequest, TResponse>> logger) =>\\n_\", \"logger = logger;\\n287 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patt\", \"ernspublic async Task<TResponse> Handle(TRequest request,\\nRequestHandlerDelegate<TResponse> next)\\n{\\n\", \"_logger.LogInformation($\\\"Handling {typeof(TRequest).Name}\\\");\\nvar response = await next();\\n_logger.Lo\", \"gInformation($\\\"Handled {typeof(TResponse).Name}\\\");\\nreturn response;\\n}\\n}\\nJust by implementing this be\", \"havior class and by registering it in the pipeline (in the MediatorModule\\nabove), all the commands p\", \"rocessed through MediatR will be logging information about the\\nexecution.\\nThe eShopOnContainers orde\", \"ring microservice also applies a second behavior for basic validations,\\nthe ValidatorBehavior class \", \"that relies on the FluentValidation library, as shown in the following code:\\npublic class ValidatorB\", \"ehavior<TRequest, TResponse>\\n: IPipelineBehavior<TRequest, TResponse>\\n{\\nprivate readonly IValidator<\", \"TRequest>[] _validators;\\npublic ValidatorBehavior(IValidator<TRequest>[] validators) =>\\n_validators \", \"= validators;\\npublic async Task<TResponse> Handle(TRequest request,\\nRequestHandlerDelegate<TResponse\", \"> next)\\n{\\nvar failures = _validators\\n.Select(v => v.Validate(request))\\n.SelectMany(result => result.\", \"Errors)\\n.Where(error => error != null)\\n.ToList();\\nif (failures.Any())\\n{\\nthrow new OrderingDomainExce\", \"ption(\\n$\\\"Command Validation Errors for type {typeof(TRequest).Name}\\\",\\nnew ValidationException(\\\"Valid\", \"ation exception\\\", failures));\\n}\\nvar response = await next();\\nreturn response;\\n}\\n}\\nHere the behavior \", \"is raising an exception if validation fails, but you could also return a result object,\\ncontaining t\", \"he command result if it succeeded or the validation messages in case it didn\\u2019t. This would\\nprobably \", \"make it easier to display validation results to the user.\\nThen, based on the FluentValidation librar\", \"y, you would create validation for the data passed with\\nCreateOrderCommand, as in the following code\", \":\\npublic class CreateOrderCommandValidator : AbstractValidator<CreateOrderCommand>\\n{\\npublic CreateOr\", \"derCommandValidator()\\n{\\nRuleFor(command => command.City).NotEmpty();\\nRuleFor(command => command.Stre\", \"et).NotEmpty();\\n288 CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rnsRuleFor(command => command.State).NotEmpty();\\nRuleFor(command => command.Country).NotEmpty();\\nRul\", \"eFor(command => command.ZipCode).NotEmpty();\\nRuleFor(command => command.CardNumber).NotEmpty().Lengt\", \"h(12, 19);\\nRuleFor(command => command.CardHolderName).NotEmpty();\\nRuleFor(command =>\\ncommand.CardExp\", \"iration).NotEmpty().Must(BeValidExpirationDate).WithMessage(\\\"Please specify\\na valid card expiration \", \"date\\\");\\nRuleFor(command => command.CardSecurityNumber).NotEmpty().Length(3);\\nRuleFor(command => comm\", \"and.CardTypeId).NotEmpty();\\nRuleFor(command => command.OrderItems).Must(ContainOrderItems).WithMessa\", \"ge(\\\"No\\norder items found\\\");\\n}\\nprivate bool BeValidExpirationDate(DateTime dateTime)\\n{\\nreturn dateTim\", \"e >= DateTime.UtcNow;\\n}\\nprivate bool ContainOrderItems(IEnumerable<OrderItemDTO> orderItems)\\n{\\nretur\", \"n orderItems.Any();\\n}\\n}\\nYou could create additional validations. This is a very clean and elegant wa\", \"y to implement your\\ncommand validations.\\nIn a similar way, you could implement other behaviors for a\", \"dditional aspects or cross-cutting concerns\\nthat you want to apply to commands when handling them.\\nA\", \"dditional resources\\nThe mediator pattern\\n\\u2022 Mediator pattern\\nhttps://en.wikipedia.org/wiki/Mediator_p\", \"attern\\nThe decorator pattern\\n\\u2022 Decorator pattern\\nhttps://en.wikipedia.org/wiki/Decorator_pattern\\nMed\", \"iatR (Jimmy Bogard)\\n\\u2022 MediatR. GitHub repo.\\nhttps://github.com/jbogard/MediatR\\n\\u2022 CQRS with MediatR a\", \"nd AutoMapper\\nhttps://lostechies.com/jimmybogard/2015/05/05/cqrs-with-mediatr-and-automapper/\\n\\u2022 Put \", \"your controllers on a diet: POSTs and commands.\\nhttps://lostechies.com/jimmybogard/2013/12/19/put-yo\", \"ur-controllers-on-a-diet-posts-and-\\ncommands/\\n289 CHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns\\u2022 Tackling cross-cutting concerns with a mediator pipeline\\nhttps://\", \"lostechies.com/jimmybogard/2014/09/09/tackling-cross-cutting-concerns-with-a-\\nmediator-pipeline/\\n\\u2022 C\", \"QRS and REST: the perfect match\\nhttps://lostechies.com/jimmybogard/2016/06/01/cqrs-and-rest-the-perf\", \"ect-match/\\n\\u2022 MediatR Pipeline Examples\\nhttps://lostechies.com/jimmybogard/2016/10/13/mediatr-pipelin\", \"e-examples/\\n\\u2022 Vertical Slice Test Fixtures for MediatR and ASP.NET Core\\nhttps://lostechies.com/jimmy\", \"bogard/2016/10/24/vertical-slice-test-fixtures-for-mediatr-and-\\nasp-net-core/\\n\\u2022 MediatR Extensions f\", \"or Microsoft Dependency Injection Released\\nhttps://lostechies.com/jimmybogard/2016/07/19/mediatr-ext\", \"ensions-for-microsoft-\\ndependency-injection-released/\\nFluent validation\\n\\u2022 Jeremy Skinner. FluentVali\", \"dation. GitHub repo.\\nhttps://github.com/JeremySkinner/FluentValidation\\n290 CHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns7\\nCHAPTER\\nImplement resilient\\napplications\", \"\\nYour microservice and cloud-based applications must embrace the partial failures that will certainl\", \"y\\noccur eventually. You must design your application to be resilient to those partial failures.\\nResi\", \"liency is the ability to recover from failures and continue to function. It isn\\u2019t about avoiding\\nfai\", \"lures but accepting the fact that failures will happen and responding to them in a way that avoids\\nd\", \"owntime or data loss. The goal of resiliency is to return the application to a fully functioning sta\", \"te\\nafter a failure.\\nIt\\u2019s challenging enough to design and deploy a microservices-based application. \", \"But you also need to\\nkeep your application running in an environment where some sort of failure is c\", \"ertain. Therefore, your\\napplication should be resilient. It should be designed to cope with partial \", \"failures, like network\\noutages or nodes or VMs crashing in the cloud. Even microservices (containers\", \") being moved to a\\ndifferent node within a cluster can cause intermittent short failures within the \", \"application.\\nThe many individual components of your application should also incorporate health monit\", \"oring\\nfeatures. By following the guidelines in this chapter, you can create an application that can \", \"work\\nsmoothly in spite of transient downtime or the normal hiccups that occur in complex and cloud-b\", \"ased\\ndeployments.\\nImportant\\neShopOnContainer had been using the Polly library to implement resilienc\", \"y using Typed Clients up\\nuntil the release 3.0.0.\\nStarting with release 3.0.0, the HTTP calls resili\", \"ency is implemented using a Linkerd mesh, that handles\\nretries in a transparent and configurable fas\", \"hion, within a Kubernetes cluster, without having to\\nhandle those concerns in the code.\\nThe Polly li\", \"brary is still used to add resilience to database connections, specially while starting up the\\nservi\", \"ces.\\nWarning\\nAll code samples and images in this section were valid before using Linkerd and are not\", \" updated to\\nreflect the current actual code. So they make sense in the context of this section.\\n291 \", \"CHAPTER 7 | Implement resilient applicationsHandle partial failure\\nIn distributed systems like micro\", \"services-based applications, there\\u2019s an ever-present risk of partial\\nfailure. For instance, a single\", \" microservice/container can fail or might not be available to respond for a\\nshort time, or a single \", \"VM or server can crash. Since clients and services are separate processes, a\\nservice might not be ab\", \"le to respond in a timely way to a client\\u2019s request. The service might be\\noverloaded and responding \", \"very slowly to requests or might simply not be accessible for a short time\\nbecause of network issues\", \".\\nFor example, consider the Order details page from the eShopOnContainers sample application. If the\", \"\\nordering microservice is unresponsive when the user tries to submit an order, a bad implementation\\n\", \"of the client process (the MVC web application)\\u2014for example, if the client code were to use\\nsynchron\", \"ous RPCs with no timeout\\u2014would block threads indefinitely waiting for a response. Besides\\ncreating a\", \" bad user experience, every unresponsive wait consumes or blocks a thread, and threads are\\nextremely\", \" valuable in highly scalable applications. If there are many blocked threads, eventually the\\napplica\", \"tion\\u2019s runtime can run out of threads. In that case, the application can become globally\\nunresponsiv\", \"e instead of just partially unresponsive, as shown in Figure 8-1.\\nFigure 8-1. Partial failures becau\", \"se of dependencies that impact service thread availability\\nIn a large microservices-based applicatio\", \"n, any partial failure can be amplified, especially if most of\\nthe internal microservices interactio\", \"n is based on synchronous HTTP calls (which is considered an anti-\\npattern). Think about a system th\", \"at receives millions of incoming calls per day. If your system has a\\nbad design that\\u2019s based on long\", \" chains of synchronous HTTP calls, these incoming calls might result in\\nmany more millions of outgoi\", \"ng calls (let\\u2019s suppose a ratio of 1:4) to dozens of internal microservices\\nas synchronous dependenc\", \"ies. This situation is shown in Figure 8-2, especially dependency #3, that\\nstarts a chain, calling d\", \"ependency #4, which then calls #5.\\n292 CHAPTER 7 | Implement resilient applicationsFigure 8-2. The i\", \"mpact of having an incorrect design featuring long chains of HTTP requests\\nIntermittent failure is g\", \"uaranteed in a distributed and cloud-based system, even if every dependency\\nitself has excellent ava\", \"ilability. It\\u2019s a fact you need to consider.\\nIf you do not design and implement techniques to ensure\", \" fault tolerance, even small downtimes can\\nbe amplified. As an example, 50 dependencies each with 99\", \".99% of availability would result in several\\nhours of downtime each month because of this ripple eff\", \"ect. When a microservice dependency fails\\nwhile handling a high volume of requests, that failure can\", \" quickly saturate all available request threads\\nin each service and crash the whole application.\\nFig\", \"ure 8-3. Partial failure amplified by microservices with long chains of synchronous HTTP calls\\n293 C\", \"HAPTER 7 | Implement resilient applicationsTo minimize this problem, in the section Asynchronous mic\", \"roservice integration enforce microservice\\u2019s\\nautonomy, this guide encourages you to use asynchronous\", \" communication across the internal\\nmicroservices.\\nIn addition, it\\u2019s essential that you design your m\", \"icroservices and client applications to handle partial\\nfailures\\u2014that is, to build resilient microser\", \"vices and client applications.\\nStrategies to handle partial failure\\nTo deal with partial failures, u\", \"se one of the strategies described here.\\nUse asynchronous communication (for example, message-based \", \"communication) across\\ninternal microservices. It\\u2019s highly advisable not to create long chains of syn\", \"chronous HTTP calls\\nacross the internal microservices because that incorrect design will eventually \", \"become the main cause\\nof bad outages. On the contrary, except for the front-end communications betwe\", \"en the client\\napplications and the first level of microservices or fine-grained API Gateways, it\\u2019s r\", \"ecommended to use\\nonly asynchronous (message-based) communication once past the initial request/resp\", \"onse cycle,\\nacross the internal microservices. Eventual consistency and event-driven architectures w\", \"ill help to\\nminimize ripple effects. These approaches enforce a higher level of microservice autonom\", \"y and\\ntherefore prevent against the problem noted here.\\nUse retries with exponential backoff. This t\", \"echnique helps to avoid short and intermittent failures\\nby performing call retries a certain number \", \"of times, in case the service was not available only for a\\nshort time. This might occur due to inter\", \"mittent network issues or when a microservice/container is\\nmoved to a different node in a cluster. H\", \"owever, if these retries are not designed properly with circuit\\nbreakers, it can aggravate the rippl\", \"e effects, ultimately even causing a Denial of Service (DoS).\\nWork around network timeouts. In gener\", \"al, clients should be designed not to block indefinitely and\\nto always use timeouts when waiting for\", \" a response. Using timeouts ensures that resources are never\\ntied up indefinitely.\\nUse the Circuit B\", \"reaker pattern. In this approach, the client process tracks the number of failed\\nrequests. If the er\", \"ror rate exceeds a configured limit, a \\u201ccircuit breaker\\u201d trips so that further attempts\\nfail immedia\", \"tely. (If a large number of requests are failing, that suggests the service is unavailable and\\nthat \", \"sending requests is pointless.) After a timeout period, the client should try again and, if the new\\n\", \"requests are successful, close the circuit breaker.\\nProvide fallbacks. In this approach, the client \", \"process performs fallback logic when a request fails,\\nsuch as returning cached data or a default val\", \"ue. This is an approach suitable for queries, and is more\\ncomplex for updates or commands.\\nLimit the\", \" number of queued requests. Clients should also impose an upper bound on the number\\nof outstanding r\", \"equests that a client microservice can send to a particular service. If the limit has been\\nreached, \", \"it\\u2019s probably pointless to make additional requests, and those attempts should fail\\nimmediately. In \", \"terms of implementation, the Polly Bulkhead Isolation policy can be used to fulfill this\\nrequirement\", \". This approach is essentially a parallelization throttle with SemaphoreSlim as the\\nimplementation. \", \"It also permits a \\u201cqueue\\u201d outside the bulkhead. You can proactively shed excess load\\neven before exe\", \"cution (for example, because capacity is deemed full). This makes its response to\\n294 CHAPTER 7 | Im\", \"plement resilient applicationscertain failure scenarios faster than a circuit breaker would be, sinc\", \"e the circuit breaker waits for the\\nfailures. The BulkheadPolicy object in Polly exposes how full th\", \"e bulkhead and queue are, and offers\\nevents on overflow so can also be used to drive automated horiz\", \"ontal scaling.\\nAdditional resources\\n\\u2022 Resiliency patterns\\nhttps://learn.microsoft.com/azure/architec\", \"ture/framework/resiliency/reliability-patterns\\n\\u2022 Adding Resilience and Optimizing Performance\\nhttps:\", \"//learn.microsoft.com/previous-versions/msp-n-p/jj591574(v=pandp.10)\\n\\u2022 Bulkhead. GitHub repo. Implem\", \"entation with Polly policy.\\nhttps://github.com/App-vNext/Polly/wiki/Bulkhead\\n\\u2022 Designing resilient a\", \"pplications for Azure\\nhttps://learn.microsoft.com/azure/architecture/framework/resiliency/app-design\", \"\\n\\u2022 Transient fault handling\\nhttps://learn.microsoft.com/azure/architecture/best-practices/transient-\", \"faults\\nImplement retries with exponential backoff\\nRetries with exponential backoff is a technique th\", \"at retries an operation, with an exponentially\\nincreasing wait time, up to a maximum retry count has\", \" been reached (the exponential backoff). This\\ntechnique embraces the fact that cloud resources might\", \" intermittently be unavailable for more than a\\nfew seconds for any reason. For example, an orchestra\", \"tor might be moving a container to another\\nnode in a cluster for load balancing. During that time, s\", \"ome requests might fail. Another example\\ncould be a database like SQL Azure, where a database can be\", \" moved to another server for load\\nbalancing, causing the database to be unavailable for a few second\", \"s.\\nThere are many approaches to implement retries logic with exponential backoff.\\nImplement resilien\", \"t Entity Framework Core SQL\\nconnections\\nFor Azure SQL DB, Entity Framework (EF) Core already provide\", \"s internal database connection resiliency\\nand retry logic. But you need to enable the Entity Framewo\", \"rk execution strategy for each DbContext\\nconnection if you want to have resilient EF Core connection\", \"s.\\nFor instance, the following code at the EF Core connection level enables resilient SQL connection\", \"s that\\nare retried if the connection fails.\\n// Program.cs from any ASP.NET Core Web API\\n// Other cod\", \"e ...\\nbuilder.Services.AddDbContext<CatalogContext>(options =>\\n{\\n295 CHAPTER 7 | Implement resilient\", \" applicationsoptions.UseSqlServer(builder.Configuration[\\\"ConnectionString\\\"],\\nsqlServerOptionsAction:\", \" sqlOptions =>\\n{\\nsqlOptions.EnableRetryOnFailure(\\nmaxRetryCount: 10,\\nmaxRetryDelay: TimeSpan.FromSec\", \"onds(30),\\nerrorNumbersToAdd: null);\\n});\\n});\\nExecution strategies and explicit transactions using Beg\", \"inTransaction\\nand multiple DbContexts\\nWhen retries are enabled in EF Core connections, each operatio\", \"n you perform using EF Core becomes\\nits own retryable operation. Each query and each call to SaveCha\", \"nges will be retried as a unit if a\\ntransient failure occurs.\\nHowever, if your code initiates a tran\", \"saction using BeginTransaction, you\\u2019re defining your own group\\nof operations that need to be treated\", \" as a unit. Everything inside the transaction has to be rolled back\\nif a failure occurs.\\nIf you try \", \"to execute that transaction when using an EF execution strategy (retry policy) and you call\\nSaveChan\", \"ges from multiple DbContexts, you\\u2019ll get an exception like this one:\\nSystem.InvalidOperationExceptio\", \"n: The configured execution strategy\\n\\u2018SqlServerRetryingExecutionStrategy\\u2019 does not support user init\", \"iated transactions. Use the execution\\nstrategy returned by \\u2018DbContext.Database.CreateExecutionStrate\", \"gy()\\u2019 to execute all the operations in\\nthe transaction as a retriable unit.\\nThe solution is to manua\", \"lly invoke the EF execution strategy with a delegate representing everything\\nthat needs to be execut\", \"ed. If a transient failure occurs, the execution strategy will invoke the delegate\\nagain. For exampl\", \"e, the following code shows how it\\u2019s implemented in eShopOnContainers with two\\nmultiple DbContexts (\", \"_catalogContext and the IntegrationEventLogContext) when updating a product\\nand then saving the Prod\", \"uctPriceChangedIntegrationEvent object, which needs to use a different\\nDbContext.\\npublic async Task<\", \"IActionResult> UpdateProduct(\\n[FromBody]CatalogItem productToUpdate)\\n{\\n// Other code ...\\nvar oldPric\", \"e = catalogItem.Price;\\nvar raiseProductPriceChangedEvent = oldPrice != productToUpdate.Price;\\n// Upd\", \"ate current product\\ncatalogItem = productToUpdate;\\n// Save product's data and publish integration ev\", \"ent through the Event Bus\\n// if price has changed\\nif (raiseProductPriceChangedEvent)\\n{\\n//Create Inte\", \"gration Event to be published through the Event Bus\\nvar priceChangedEvent = new ProductPriceChangedI\", \"ntegrationEvent(\\ncatalogItem.Id, productToUpdate.Price, oldPrice);\\n296 CHAPTER 7 | Implement resilie\", \"nt applications// Achieving atomicity between original Catalog database operation and the\\n// Integra\", \"tionEventLog thanks to a local transaction\\nawait _catalogIntegrationEventService.SaveEventAndCatalog\", \"ContextChangesAsync(\\npriceChangedEvent);\\n// Publish through the Event Bus and mark the saved event a\", \"s published\\nawait _catalogIntegrationEventService.PublishThroughEventBusAsync(\\npriceChangedEvent);\\n}\", \"\\n// Just save the updated product because the Product's Price hasn't changed.\\nelse\\n{\\nawait _catalogC\", \"ontext.SaveChangesAsync();\\n}\\n}\\nThe first DbContext is _catalogContext and the second DbContext is wi\", \"thin the\\n_catalogIntegrationEventService object. The Commit action is performed across all DbContext\", \" objects\\nusing an EF execution strategy.\\nTo achieve this multiple DbContext commit, the SaveEventAnd\", \"CatalogContextChangesAsync uses a\\nResilientTransaction class, as shown in the following code:\\npublic\", \" class CatalogIntegrationEventService : ICatalogIntegrationEventService\\n{\\n//\\u2026\\npublic async Task Save\", \"EventAndCatalogContextChangesAsync(\\nIntegrationEvent evt)\\n{\\n// Use of an EF Core resiliency strategy\", \" when using multiple DbContexts\\n// within an explicit BeginTransaction():\\n// https://learn.microsoft\", \".com/ef/core/miscellaneous/connection-resiliency\\nawait ResilientTransaction.New(_catalogContext).Exe\", \"cuteAsync(async () =>\\n{\\n// Achieving atomicity between original catalog database\\n// operation and th\", \"e IntegrationEventLog thanks to a local transaction\\nawait _catalogContext.SaveChangesAsync();\\nawait \", \"_eventLogService.SaveEventAsync(evt,\\n_catalogContext.Database.CurrentTransaction.GetDbTransaction())\", \";\\n});\\n}\\n}\\nThe ResilientTransaction.ExecuteAsync method basically begins a transaction from the passe\", \"d\\nDbContext (_catalogContext) and then makes the EventLogService use that transaction to save\\nchange\", \"s from the IntegrationEventLogContext and then commits the whole transaction.\\npublic class Resilient\", \"Transaction\\n{\\nprivate DbContext _context;\\nprivate ResilientTransaction(DbContext context) =>\\n_contex\", \"t = context ?? throw new ArgumentNullException(nameof(context));\\npublic static ResilientTransaction \", \"New (DbContext context) =>\\nnew ResilientTransaction(context);\\npublic async Task ExecuteAsync(Func<Ta\", \"sk> action)\\n{\\n297 CHAPTER 7 | Implement resilient applications// Use of an EF Core resiliency strate\", \"gy when using multiple DbContexts\\n// within an explicit BeginTransaction():\\n// https://learn.microso\", \"ft.com/ef/core/miscellaneous/connection-resiliency\\nvar strategy = _context.Database.CreateExecutionS\", \"trategy();\\nawait strategy.ExecuteAsync(async () =>\\n{\\nawait using var transaction = await _context.Da\", \"tabase.BeginTransactionAsync();\\nawait action();\\nawait transaction.CommitAsync();\\n});\\n}\\n}\\nAdditional \", \"resources\\n\\u2022 Connection Resiliency and Command Interception with EF in an ASP.NET MVC\\nApplication\\nhtt\", \"ps://learn.microsoft.com/aspnet/mvc/overview/getting-started/getting-started-with-ef-\\nusing-mvc/conn\", \"ection-resiliency-and-command-interception-with-the-entity-framework-in-\\nan-asp-net-mvc-application\\n\", \"\\u2022 Cesar de la Torre. Using Resilient Entity Framework Core SQL Connections and\\nTransactions\\nhttps://\", \"devblogs.microsoft.com/cesardelatorre/using-resilient-entity-framework-core-sql-\\nconnections-and-tra\", \"nsactions-retries-with-exponential-backoff/\\nUse IHttpClientFactory to implement resilient HTTP\\nreque\", \"sts\\nIHttpClientFactory is a contract implemented by DefaultHttpClientFactory, an opinionated factory\", \",\\navailable since .NET Core 2.1, for creating HttpClient instances to be used in your applications.\\n\", \"Issues with the original HttpClient class available in .NET\\nThe original and well-known HttpClient c\", \"lass can be easily used, but in some cases, it isn\\u2019t being\\nproperly used by many developers.\\nThough \", \"this class implements IDisposable, declaring and instantiating it within a using statement is\\nnot pr\", \"eferred because when the HttpClient object gets disposed of, the underlying socket is not\\nimmediatel\", \"y released, which can lead to a socket exhaustion problem. For more information about this\\nissue, se\", \"e the blog post You\\u2019re using HttpClient wrong and it\\u2019s destabilizing your software.\\nTherefore, HttpC\", \"lient is intended to be instantiated once and reused throughout the life of an\\napplication. Instanti\", \"ating an HttpClient class for every request will exhaust the number of sockets\\navailable under heavy\", \" loads. That issue will result in SocketException errors. Possible approaches to\\nsolve that problem \", \"are based on the creation of the HttpClient object as singleton or static, as\\nexplained in this Micr\", \"osoft article on HttpClient usage. This can be a good solution for short-lived\\nconsole apps or simil\", \"ar, that run a few times a day.\\n298 CHAPTER 7 | Implement resilient applicationsAnother issue that d\", \"evelopers run into is when using a shared instance of HttpClient in long-running\\nprocesses. In a sit\", \"uation where the HttpClient is instantiated as a singleton or a static object, it fails to\\nhandle th\", \"e DNS changes as described in this issue of the dotnet/runtime GitHub repository.\\nHowever, the issue\", \" isn\\u2019t really with HttpClient per se, but with the default constructor for HttpClient,\\nbecause it cr\", \"eates a new concrete instance of HttpMessageHandler, which is the one that has sockets\\nexhaustion an\", \"d DNS changes issues mentioned above.\\nTo address the issues mentioned above and to make HttpClient i\", \"nstances manageable, .NET Core 2.1\\nintroduced two approaches, one of them being IHttpClientFactory. \", \"It\\u2019s an interface that\\u2019s used to\\nconfigure and create HttpClient instances in an app through Depende\", \"ncy Injection (DI). It also\\nprovides extensions for Polly-based middleware to take advantage of dele\", \"gating handlers in\\nHttpClient.\\nThe alternative is to use SocketsHttpHandler with configured PooledCo\", \"nnectionLifetime. This\\napproach is applied to long-lived, static or singleton HttpClient instances. \", \"To learn more about\\ndifferent strategies, see HttpClient guidelines for .NET.\\nPolly is a transient-f\", \"ault-handling library that helps developers add resiliency to their applications, by\\nusing some pre-\", \"defined policies in a fluent and thread-safe manner.\\nBenefits of using IHttpClientFactory\\nThe curren\", \"t implementation of IHttpClientFactory, that also implements IHttpMessageHandlerFactory,\\noffers the \", \"following benefits:\\n\\u2022 Provides a central location for naming and configuring logical HttpClient obje\", \"cts. For\\nexample, you may configure a client (Service Agent) that\\u2019s pre-configured to access a speci\", \"fic\\nmicroservice.\\n\\u2022 Codify the concept of outgoing middleware via delegating handlers in HttpClient \", \"and\\nimplementing Polly-based middleware to take advantage of Polly\\u2019s policies for resiliency.\\n\\u2022 Http\", \"Client already has the concept of delegating handlers that could be linked together for\\noutgoing HTT\", \"P requests. You can register HTTP clients into the factory and you can use a\\nPolly handler to use Po\", \"lly policies for Retry, CircuitBreakers, and so on.\\n\\u2022 Manage the lifetime of HttpMessageHandler to a\", \"void the mentioned problems/issues that\\ncan occur when managing HttpClient lifetimes yourself.\\nTip\\nT\", \"he HttpClient instances injected by DI can be disposed of safely, because the associated\\nHttpMessage\", \"Handler is managed by the factory. Injected HttpClient instances are Transient from a DI\\nperspective\", \", while HttpMessageHandler instances can be regarded as Scoped. HttpMessageHandler\\ninstances have th\", \"eir own DI scopes, separate from the application scopes (for example, ASP.NET\\nincoming request scope\", \"s). For more information, see Using HttpClientFactory in .NET.\\n299 CHAPTER 7 | Implement resilient a\", \"pplicationsNote\\nThe implementation of IHttpClientFactory (DefaultHttpClientFactory) is tightly tied \", \"to the DI\\nimplementation in the Microsoft.Extensions.DependencyInjection NuGet package. If you need \", \"to use\\nHttpClient without DI or with other DI implementations, consider using a static or singleton \", \"HttpClient\\nwith PooledConnectionLifetime set up. For more information, see HttpClient guidelines for\", \" .NET.\\nMultiple ways to use IHttpClientFactory\\nThere are several ways that you can use IHttpClientFa\", \"ctory in your application:\\n\\u2022 Basic usage\\n\\u2022 Use Named Clients\\n\\u2022 Use Typed Clients\\n\\u2022 Use Generated Cli\", \"ents\\nFor the sake of brevity, this guidance shows the most structured way to use IHttpClientFactory,\", \" which\\nis to use Typed Clients (Service Agent pattern). However, all options are documented and are \", \"currently\\nlisted in this article covering the IHttpClientFactory usage.\\nNote\\nIf your app requires co\", \"okies, it might be better to avoid using IHttpClientFactory in your app. For\\nalternative ways of man\", \"aging clients, see Guidelines for using HTTP clients\\nHow to use Typed Clients with IHttpClientFactor\", \"y\\nSo, what\\u2019s a \\u201cTyped Client\\u201d? It\\u2019s just an HttpClient that\\u2019s pre-configured for some specific use. \", \"This\\nconfiguration can include specific values such as the base server, HTTP headers or time outs.\\nT\", \"he following diagram shows how Typed Clients are used with IHttpClientFactory:\\n300 CHAPTER 7 | Imple\", \"ment resilient applicationsFigure 8-4. Using IHttpClientFactory with Typed Client classes.\\nIn the ab\", \"ove image, a ClientService (used by a controller or client code) uses an HttpClient created by\\nthe r\", \"egistered IHttpClientFactory. This factory assigns an HttpMessageHandler from a pool to the\\nHttpClie\", \"nt. The HttpClient can be configured with Polly\\u2019s policies when registering the\\nIHttpClientFactory i\", \"n the DI container with the extension method AddHttpClient.\\nTo configure the above structure, add IH\", \"ttpClientFactory in your application by installing the\\nMicrosoft.Extensions.Http NuGet package that \", \"includes the AddHttpClient extension method for\\nIServiceCollection. This extension method registers \", \"the internal DefaultHttpClientFactory class to be\\nused as a singleton for the interface IHttpClientF\", \"actory. It defines a transient configuration for the\\nHttpMessageHandlerBuilder. This message handler\", \" (HttpMessageHandler object), taken from a pool,\\nis used by the HttpClient returned from the factory\", \".\\nIn the next snippet, you can see how AddHttpClient() can be used to register Typed Clients (Servic\", \"e\\nAgents) that need to use HttpClient.\\n// Program.cs\\n//Add http client services at ConfigureServices\", \"(IServiceCollection services)\\nbuilder.Services.AddHttpClient<ICatalogService, CatalogService>();\\nbui\", \"lder.Services.AddHttpClient<IBasketService, BasketService>();\\nbuilder.Services.AddHttpClient<IOrderi\", \"ngService, OrderingService>();\\n301 CHAPTER 7 | Implement resilient applicationsRegistering the clien\", \"t services as shown in the previous snippet, makes the DefaultClientFactory create\\na standard HttpCl\", \"ient for each service. The typed client is registered as transient with DI container. In\\nthe precedi\", \"ng code, AddHttpClient() registers CatalogService, BasketService, OrderingService as\\ntransient servi\", \"ces so they can be injected and consumed directly without any need for additional\\nregistrations.\\nYou\", \" could also add instance-specific configuration in the registration to, for example, configure the\\nb\", \"ase address, and add some resiliency policies, as shown in the following:\\nbuilder.Services.AddHttpCl\", \"ient<ICatalogService, CatalogService>(client =>\\n{\\nclient.BaseAddress = new Uri(builder.Configuration\", \"[\\\"BaseUrl\\\"]);\\n})\\n.AddPolicyHandler(GetRetryPolicy())\\n.AddPolicyHandler(GetCircuitBreakerPolicy());\\nI\", \"n this next example, you can see the configuration of one of the above policies:\\nstatic IAsyncPolicy\", \"<HttpResponseMessage> GetRetryPolicy()\\n{\\nreturn HttpPolicyExtensions\\n.HandleTransientHttpError()\\n.Or\", \"Result(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound)\\n.WaitAndRetryAsync(6, retryAttem\", \"pt => TimeSpan.FromSeconds(Math.Pow(2,\\nretryAttempt)));\\n}\\nYou can find more details about using Poll\", \"y in the Next article.\\nHttpClient lifetimes\\nEach time you get an HttpClient object from the IHttpCli\", \"entFactory, a new instance is returned. But\\neach HttpClient uses an HttpMessageHandler that\\u2019s pooled\", \" and reused by the IHttpClientFactory to\\nreduce resource consumption, as long as the HttpMessageHand\", \"ler\\u2019s lifetime hasn\\u2019t expired.\\nPooling of handlers is desirable as each handler typically manages it\", \"s own underlying HTTP\\nconnections; creating more handlers than necessary can result in connection de\", \"lays. Some handlers\\nalso keep connections open indefinitely, which can prevent the handler from reac\", \"ting to DNS\\nchanges.\\nThe HttpMessageHandler objects in the pool have a lifetime that\\u2019s the length of\", \" time that an\\nHttpMessageHandler instance in the pool can be reused. The default value is two minute\", \"s, but it can\\nbe overridden per Typed Client. To override it, call SetHandlerLifetime() on the IHttp\", \"ClientBuilder\\nthat\\u2019s returned when creating the client, as shown in the following code:\\n//Set 5 min \", \"as the lifetime for the HttpMessageHandler objects in the pool used for the\\nCatalog Typed Client\\nbui\", \"lder.Services.AddHttpClient<ICatalogService, CatalogService>()\\n.SetHandlerLifetime(TimeSpan.FromMinu\", \"tes(5));\\nEach Typed Client can have its own configured handler lifetime value. Set the lifetime to\\nI\", \"nfiniteTimeSpan to disable handler expiry.\\n302 CHAPTER 7 | Implement resilient applicationsImplement\", \" your Typed Client classes that use the injected and configured\\nHttpClient\\nAs a previous step, you n\", \"eed to have your Typed Client classes defined, such as the classes in the\\nsample code, like \\u2018BasketS\", \"ervice\\u2019, \\u2018CatalogService\\u2019, \\u2018OrderingService\\u2019, etc. \\u2013 A Typed Client is a class\\nthat accepts an HttpC\", \"lient object (injected through its constructor) and uses it to call some remote\\nHTTP service. For ex\", \"ample:\\npublic class CatalogService : ICatalogService\\n{\\nprivate readonly HttpClient _httpClient;\\npriv\", \"ate readonly string _remoteServiceBaseUrl;\\npublic CatalogService(HttpClient httpClient)\\n{\\n_httpClien\", \"t = httpClient;\\n}\\npublic async Task<Catalog> GetCatalogItems(int page, int take,\\nint? brand, int? ty\", \"pe)\\n{\\nvar uri = API.Catalog.GetAllCatalogItems(_remoteServiceBaseUrl,\\npage, take, brand, type);\\nvar \", \"responseString = await _httpClient.GetStringAsync(uri);\\nvar catalog = JsonConvert.DeserializeObject<\", \"Catalog>(responseString);\\nreturn catalog;\\n}\\n}\\nThe Typed Client (CatalogService in the example) is ac\", \"tivated by DI (Dependency Injection), which\\nmeans it can accept any registered service in its constr\", \"uctor, in addition to HttpClient.\\nA Typed Client is effectively a transient object, that means a new\", \" instance is created each time one is\\nneeded. It receives a new HttpClient instance each time it\\u2019s c\", \"onstructed. However, the\\nHttpMessageHandler objects in the pool are the objects that are reused by m\", \"ultiple HttpClient\\ninstances.\\nUse your Typed Client classes\\nFinally, once you have your typed classe\", \"s implemented, you can have them registered and configured\\nwith AddHttpClient(). After that you can \", \"use them wherever services are injected by DI, such as in\\nRazor page code or an MVC web app controll\", \"er, shown in the below code from eShopOnContainers:\\nnamespace Microsoft.eShopOnContainers.WebMVC.Con\", \"trollers\\n{\\npublic class CatalogController : Controller\\n{\\nprivate ICatalogService _catalogSvc;\\npublic\", \" CatalogController(ICatalogService catalogSvc) =>\\n_catalogSvc = catalogSvc;\\npublic async Task<IActio\", \"nResult> Index(int? BrandFilterApplied,\\nint? TypesFilterApplied,\\n303 CHAPTER 7 | Implement resilient\", \" applicationsint? page,\\n[FromQuery]string errorMsg)\\n{\\nvar itemsPage = 10;\\nvar catalog = await _catal\", \"ogSvc.GetCatalogItems(page ?? 0,\\nitemsPage,\\nBrandFilterApplied,\\nTypesFilterApplied);\\n//\\u2026 Additional \", \"code\\n}\\n}\\n}\\nUp to this point, the above code snippet only shows the example of performing regular HTT\", \"P\\nrequests. But the \\u2018magic\\u2019 comes in the following sections where it shows how all the HTTP requests\", \"\\nmade by HttpClient can have resilient policies such as retries with exponential backoff, circuit\\nbr\", \"eakers, security features using auth tokens, or even any other custom feature. And all of these can\\n\", \"be done just by adding policies and delegating handlers to your registered Typed Clients.\\nAdditional\", \" resources\\n\\u2022 HttpClient guidelines for .NET\\nhttps://learn.microsoft.com/en-us/dotnet/fundamentals/ne\", \"tworking/http/httpclient-\\nguidelines\\n\\u2022 Using HttpClientFactory in .NET\\nhttps://learn.microsoft.com/e\", \"n-us/dotnet/core/extensions/httpclient-factory\\n\\u2022 Using HttpClientFactory in ASP.NET Core\\nhttps://lea\", \"rn.microsoft.com/aspnet/core/fundamentals/http-requests\\n\\u2022 HttpClientFactory source code in the dotne\", \"t/runtime GitHub repository\\nhttps://github.com/dotnet/runtime/tree/release/7.0/src/libraries/Microso\", \"ft.Extensions.Http/\\n\\u2022 Polly (.NET resilience and transient-fault-handling library)\\nhttps://thepollyp\", \"roject.azurewebsites.net/\\nImplement HTTP call retries with exponential backoff\\nwith IHttpClientFacto\", \"ry and Polly policies\\nThe recommended approach for retries with exponential backoff is to take advan\", \"tage of more\\nadvanced .NET libraries like the open-source Polly library.\\nPolly is a .NET library tha\", \"t provides resilience and transient-fault handling capabilities. You can\\nimplement those capabilitie\", \"s by applying Polly policies such as Retry, Circuit Breaker, Bulkhead\\nIsolation, Timeout, and Fallba\", \"ck. Polly targets .NET Framework 4.x and .NET Standard 1.0, 1.1, and 2.0\\n(which supports .NET Core a\", \"nd later).\\n304 CHAPTER 7 | Implement resilient applicationsThe following steps show how you can use \", \"Http retries with Polly integrated into IHttpClientFactory,\\nwhich is explained in the previous secti\", \"on.\\nInstall .NET packages\\nFirst, you will need to install the Microsoft.Extensions.Http.Polly packag\", \"e.\\n\\u2022 Install with Visual Studio\\n\\u2022 Install with dotnet CLI\\n\\u2022 Install with nuget.exe CLI\\n\\u2022 Install wit\", \"h Package Manager Console (PowerShell)\\nReference the .NET 7 packages\\nIHttpClientFactory is available\", \" since .NET Core 2.1, however, we recommend you use the latest .NET 7\\npackages from NuGet in your pr\", \"oject. You typically also need to reference the extension package\\nMicrosoft.Extensions.Http.Polly.\\nC\", \"onfigure a client with Polly\\u2019s Retry policy, in app startup\\nThe AddPolicyHandler() method is what ad\", \"ds policies to the HttpClient objects you\\u2019ll use. In this\\ncase, it\\u2019s adding a Polly\\u2019s policy for Htt\", \"p Retries with exponential backoff.\\nTo have a more modular approach, the Http Retry Policy can be de\", \"fined in a separate method within\\nthe Program.cs file, as shown in the following code:\\nstatic IAsync\", \"Policy<HttpResponseMessage> GetRetryPolicy()\\n{\\nreturn HttpPolicyExtensions\\n.HandleTransientHttpError\", \"()\\n.OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound)\\n.WaitAndRetryAsync(6, retr\", \"yAttempt => TimeSpan.FromSeconds(Math.Pow(2,\\nretryAttempt)));\\n}\\nAs shown in previous sections, you n\", \"eed to define a named or typed client HttpClient configuration in\\nyour standard Program.cs app confi\", \"guration. Now you add incremental code specifying the policy for\\nthe Http retries with exponential b\", \"ackoff, as follows:\\n// Program.cs\\nbuilder.Services.AddHttpClient<IBasketService, BasketService>()\\n.S\", \"etHandlerLifetime(TimeSpan.FromMinutes(5)) //Set lifetime to five minutes\\n.AddPolicyHandler(GetRetry\", \"Policy());\\nWith Polly, you can define a Retry policy with the number of retries, the exponential bac\", \"koff\\nconfiguration, and the actions to take when there\\u2019s an HTTP exception, such as logging the erro\", \"r. In\\nthis case, the policy is configured to try six times with an exponential retry, starting at tw\", \"o seconds.\\nAdd a jitter strategy to the retry policy\\nA regular Retry policy can affect your system i\", \"n cases of high concurrency and scalability and under\\nhigh contention. To overcome peaks of similar \", \"retries coming from many clients in partial outages, a\\ngood workaround is to add a jitter strategy t\", \"o the retry algorithm/policy. This strategy can improve\\nthe overall performance of the end-to-end sy\", \"stem. As recommended in Polly: Retry with Jitter, a good\\n305 CHAPTER 7 | Implement resilient applica\", \"tionsjitter strategy can be implemented by smooth and evenly distributed retry intervals applied wit\", \"h a\\nwell-controlled median initial retry delay on an exponential backoff. This approach helps to spr\", \"ead out\\nthe spikes when the issue arises. The principle is illustrated by the following example:\\nvar\", \" delay = Backoff.DecorrelatedJitterBackoffV2(medianFirstRetryDelay:\\nTimeSpan.FromSeconds(1), retryCo\", \"unt: 5);\\nvar retryPolicy = Policy\\n.Handle<FooException>()\\n.WaitAndRetryAsync(delay);\\nAdditional reso\", \"urces\\n\\u2022 Retry pattern https://learn.microsoft.com/azure/architecture/patterns/retry\\n\\u2022 Polly and IHtt\", \"pClientFactory https://github.com/App-vNext/Polly/wiki/Polly-and-\\nHttpClientFactory\\n\\u2022 Polly (.NET re\", \"silience and transient-fault-handling library) https://github.com/App-\\nvNext/Polly\\n\\u2022 Polly: Retry wi\", \"th Jitter https://github.com/App-vNext/Polly/wiki/Retry-with-jitter\\n\\u2022 Marc Brooker. Jitter: Making T\", \"hings Better With Randomness\\nhttps://brooker.co.za/blog/2015/03/21/backoff.html\\nImplement the Circui\", \"t Breaker pattern\\nAs noted earlier, you should handle faults that might take a variable amount of ti\", \"me to recover from,\\nas might happen when you try to connect to a remote service or resource. Handlin\", \"g this type of fault\\ncan improve the stability and resiliency of an application.\\nIn a distributed en\", \"vironment, calls to remote resources and services can fail due to transient faults,\\nsuch as slow net\", \"work connections and timeouts, or if resources are responding slowly or are\\ntemporarily unavailable.\", \" These faults typically correct themselves after a short time, and a robust cloud\\napplication should\", \" be prepared to handle them by using a strategy like the \\u201cRetry pattern\\u201d.\\nHowever, there can also be\", \" situations where faults are due to unanticipated events that might take\\nmuch longer to fix. These f\", \"aults can range in severity from a partial loss of connectivity to the\\ncomplete failure of a service\", \". In these situations, it might be pointless for an application to continually\\nretry an operation th\", \"at\\u2019s unlikely to succeed.\\nInstead, the application should be coded to accept that the operation has \", \"failed and handle the failure\\naccordingly.\\nUsing Http retries carelessly could result in creating a \", \"Denial of Service (DoS) attack within your own\\nsoftware. As a microservice fails or performs slowly,\", \" multiple clients might repeatedly retry failed\\nrequests. That creates a dangerous risk of exponenti\", \"ally increasing traffic targeted at the failing\\nservice.\\n306 CHAPTER 7 | Implement resilient applica\", \"tionsTherefore, you need some kind of defense barrier so that excessive requests stop when it isn\\u2019t \", \"worth\\nto keep trying. That defense barrier is precisely the circuit breaker.\\nThe Circuit Breaker pat\", \"tern has a different purpose than the \\u201cRetry pattern\\u201d. The \\u201cRetry pattern\\u201d\\nenables an application to\", \" retry an operation in the expectation that the operation will eventually\\nsucceed. The Circuit Break\", \"er pattern prevents an application from performing an operation that\\u2019s\\nlikely to fail. An applicatio\", \"n can combine these two patterns. However, the retry logic should be\\nsensitive to any exception retu\", \"rned by the circuit breaker, and it should abandon retry attempts if the\\ncircuit breaker indicates t\", \"hat a fault is not transient.\\nImplement Circuit Breaker pattern with IHttpClientFactory and Polly\\nAs\", \" when implementing retries, the recommended approach for circuit breakers is to take advantage of\\npr\", \"oven .NET libraries like Polly and its native integration with IHttpClientFactory.\\nAdding a circuit \", \"breaker policy into your IHttpClientFactory outgoing middleware pipeline is as simple\\nas adding a si\", \"ngle incremental piece of code to what you already have when using IHttpClientFactory.\\nThe only addi\", \"tion here to the code used for HTTP call retries is the code where you add the Circuit\\nBreaker polic\", \"y to the list of policies to use, as shown in the following incremental code.\\n// Program.cs\\nvar retr\", \"yPolicy = GetRetryPolicy();\\nvar circuitBreakerPolicy = GetCircuitBreakerPolicy();\\nbuilder.Services.A\", \"ddHttpClient<IBasketService, BasketService>()\\n.SetHandlerLifetime(TimeSpan.FromMinutes(5)) // Sample\", \": default lifetime is 2\\nminutes\\n.AddHttpMessageHandler<HttpClientAuthorizationDelegatingHandler>()\\n.\", \"AddPolicyHandler(retryPolicy)\\n.AddPolicyHandler(circuitBreakerPolicy);\\nThe AddPolicyHandler() method\", \" is what adds policies to the HttpClient objects you\\u2019ll use. In this case,\\nit\\u2019s adding a Polly polic\", \"y for a circuit breaker.\\nTo have a more modular approach, the Circuit Breaker Policy is defined in a\", \" separate method called\\nGetCircuitBreakerPolicy(), as shown in the following code:\\n// also in Progra\", \"m.cs\\nstatic IAsyncPolicy<HttpResponseMessage> GetCircuitBreakerPolicy()\\n{\\nreturn HttpPolicyExtension\", \"s\\n.HandleTransientHttpError()\\n.CircuitBreakerAsync(5, TimeSpan.FromSeconds(30));\\n}\\nIn the code examp\", \"le above, the circuit breaker policy is configured so it breaks or opens the circuit\\nwhen there have\", \" been five consecutive faults when retrying the Http requests. When that happens,\\nthe circuit will b\", \"reak for 30 seconds: in that period, calls will be failed immediately by the circuit-\\nbreaker rather\", \" than actually be placed. The policy automatically interprets relevant exceptions and\\nHTTP status co\", \"des as faults.\\nCircuit breakers should also be used to redirect requests to a fallback infrastructur\", \"e if you had issues\\nin a particular resource that\\u2019s deployed in a different environment than the cli\", \"ent application or\\n307 CHAPTER 7 | Implement resilient applicationsservice that\\u2019s performing the HTT\", \"P call. That way, if there\\u2019s an outage in the datacenter that impacts\\nonly your backend microservice\", \"s but not your client applications, the client applications can redirect\\nto the fallback services. P\", \"olly is planning a new policy to automate this failover policy scenario.\\nAll those features are for \", \"cases where you\\u2019re managing the failover from within the .NET code, as\\nopposed to having it managed \", \"automatically for you by Azure, with location transparency.\\nFrom a usage point of view, when using H\", \"ttpClient, there\\u2019s no need to add anything new here\\nbecause the code is the same than when using Htt\", \"pClient with IHttpClientFactory, as shown in\\nprevious sections.\\nTest Http retries and circuit breake\", \"rs in eShopOnContainers\\nWhenever you start the eShopOnContainers solution in a Docker host, it needs\", \" to start multiple\\ncontainers. Some of the containers are slower to start and initialize, like the S\", \"QL Server container. This\\nis especially true the first time you deploy the eShopOnContainers applica\", \"tion into Docker because it\\nneeds to set up the images and the database. The fact that some containe\", \"rs start slower than others\\ncan cause the rest of the services to initially throw HTTP exceptions, e\", \"ven if you set dependencies\\nbetween containers at the docker-compose level, as explained in previous\", \" sections. Those docker-\\ncompose dependencies between containers are just at the process level. The \", \"container\\u2019s entry point\\nprocess might be started, but SQL Server might not be ready for queries. The\", \" result can be a cascade\\nof errors, and the application can get an exception when trying to consume \", \"that particular container.\\nYou might also see this type of error on startup when the application is \", \"deploying to the cloud. In that\\ncase, orchestrators might be moving containers from one node or VM t\", \"o another (that is, starting new\\ninstances) when balancing the number of containers across the clust\", \"er\\u2019s nodes.\\nThe way \\u2018eShopOnContainers\\u2019 solves those issues when starting all the containers is by u\", \"sing the Retry\\npattern illustrated earlier.\\nTest the circuit breaker in eShopOnContainers\\nThere are \", \"a few ways you can break/open the circuit and test it with eShopOnContainers.\\nOne option is to lower\", \" the allowed number of retries to 1 in the circuit breaker policy and redeploy\\nthe whole solution in\", \"to Docker. With a single retry, there\\u2019s a good chance that an HTTP request will\\nfail during deployme\", \"nt, the circuit breaker will open, and you get an error.\\nAnother option is to use custom middleware \", \"that\\u2019s implemented in the Basket microservice. When\\nthis middleware is enabled, it catches all HTTP \", \"requests and returns status code 500. You can enable\\nthe middleware by making a GET request to the f\", \"ailing URI, like the following:\\n\\u2022 GET http://localhost:5103/failing\\nThis request returns the current\", \" state of the middleware. If the middleware is enabled, the\\nrequest return status code 500. If the m\", \"iddleware is disabled, there\\u2019s no response.\\n\\u2022 GET http://localhost:5103/failing?enable\\nThis request \", \"enables the middleware.\\n308 CHAPTER 7 | Implement resilient applications\\u2022 GET http://localhost:5103/\", \"failing?disable\\nThis request disables the middleware.\\nFor instance, once the application is running,\", \" you can enable the middleware by making a request\\nusing the following URI in any browser. Note that\", \" the ordering microservice uses port 5103.\\nhttp://localhost:5103/failing?enable\\nYou can then check t\", \"he status using the URI http://localhost:5103/failing, as shown in Figure 8-5.\\nFigure 8-5. Checking \", \"the state of the \\u201cFailing\\u201d ASP.NET middleware \\u2013 In this case, disabled.\\nAt this point, the Basket mi\", \"croservice responds with status code 500 whenever you call invoke it.\\nOnce the middleware is running\", \", you can try making an order from the MVC web application. Because\\nthe requests fail, the circuit w\", \"ill open.\\nIn the following example, you can see that the MVC web application has a catch block in th\", \"e logic for\\nplacing an order. If the code catches an open-circuit exception, it shows the user a fri\", \"endly message\\ntelling them to wait.\\npublic class CartController : Controller\\n{\\n//\\u2026\\npublic async Task\", \"<IActionResult> Index()\\n{\\ntry\\n{\\nvar user = _appUserParser.Parse(HttpContext.User);\\n//Http requests u\", \"sing the Typed Client (Service Agent)\\nvar vm = await _basketSvc.GetBasket(user);\\nreturn View(vm);\\n}\\n\", \"catch (BrokenCircuitException)\\n{\\n// Catches error when Basket.api is in circuit-opened mode\\nHandleBr\", \"okenCircuitException();\\n}\\nreturn View();\\n}\\nprivate void HandleBrokenCircuitException()\\n{\\nTempData[\\\"B\", \"asketInoperativeMsg\\\"] = \\\"Basket Service is inoperative, please try later\\non. (Business message due t\", \"o Circuit-Breaker)\\\";\\n}\\n}\\nHere\\u2019s a summary. The Retry policy tries several times to make the HTTP req\", \"uest and gets HTTP errors.\\nWhen the number of retries reaches the maximum number set for the Circuit\", \" Breaker policy (in this\\ncase, 5), the application throws a BrokenCircuitException. The result is a \", \"friendly message, as shown in\\nFigure 8-6.\\n309 CHAPTER 7 | Implement resilient applicationsFigure 8-6\", \". Circuit breaker returning an error to the UI\\nYou can implement different logic for when to open/br\", \"eak the circuit. Or you can try an HTTP request\\nagainst a different back-end microservice if there\\u2019s\", \" a fallback datacenter or redundant back-end\\nsystem.\\nFinally, another possibility for the CircuitBre\", \"akerPolicy is to use Isolate (which forces open and holds\\nopen the circuit) and Reset (which closes \", \"it again). These could be used to build a utility HTTP\\nendpoint that invokes Isolate and Reset direc\", \"tly on the policy. Such an HTTP endpoint could also be\\nused, suitably secured, in production for tem\", \"porarily isolating a downstream system, such as when\\nyou want to upgrade it. Or it could trip the ci\", \"rcuit manually to protect a downstream system you\\nsuspect to be faulting.\\nAdditional resources\\n\\u2022 Cir\", \"cuit Breaker pattern\\nhttps://learn.microsoft.com/azure/architecture/patterns/circuit-breaker\\nHealth \", \"monitoring\\nHealth monitoring can allow near-real-time information about the state of your containers\", \" and\\nmicroservices. Health monitoring is critical to multiple aspects of operating microservices and\", \" is\\nespecially important when orchestrators perform partial application upgrades in phases, as expla\", \"ined\\nlater.\\nMicroservices-based applications often use heartbeats or health checks to enable their p\", \"erformance\\nmonitors, schedulers, and orchestrators to keep track of the multitude of services. If se\", \"rvices cannot\\nsend some sort of \\u201cI\\u2019m alive\\u201d signal, either on demand or on a schedule, your applicat\", \"ion might face\\nrisks when you deploy updates, or it might just detect failures too late and not be a\", \"ble to stop\\ncascading failures that can end up in major outages.\\nIn the typical model, services send\", \" reports about their status, and that information is aggregated to\\nprovide an overall view of the st\", \"ate of health of your application. If you\\u2019re using an orchestrator, you\\ncan provide health informati\", \"on to your orchestrator\\u2019s cluster, so that the cluster can act accordingly. If\\nyou invest in high-qu\", \"ality health reporting that\\u2019s customized for your application, you can detect and\\nfix issues for you\", \"r running application much more easily.\\n310 CHAPTER 7 | Implement resilient applicationsImplement he\", \"alth checks in ASP.NET Core services\\nWhen developing an ASP.NET Core microservice or web application\", \", you can use the built-in health\\nchecks feature that was released in ASP .NET Core 2.2\\n(Microsoft.E\", \"xtensions.Diagnostics.HealthChecks). Like many ASP.NET Core features, health checks\\ncome with a set \", \"of services and a middleware.\\nHealth check services and middleware are easy to use and provide capab\", \"ilities that let you validate if\\nany external resource needed for your application (like a SQL Serve\", \"r database or a remote API) is\\nworking properly. When you use this feature, you can also decide what\", \" it means that the resource is\\nhealthy, as we explain later.\\nTo use this feature effectively, you ne\", \"ed to first configure services in your microservices. Second, you\\nneed a front-end application that \", \"queries for the health reports. That front-end application could be a\\ncustom reporting application, \", \"or it could be an orchestrator itself that can react accordingly to the\\nhealth states.\\nUse the Healt\", \"hChecks feature in your back-end ASP.NET microservices\\nIn this section, you\\u2019ll learn how to implemen\", \"t the HealthChecks feature in a sample ASP.NET Core 7.0\\nWeb API application when using the Microsoft\", \".Extensions.Diagnostics.HealthChecks package. The\\nImplementation of this feature in a large-scale mi\", \"croservices like the eShopOnContainers is explained\\nin the next section.\\nTo begin, you need to defin\", \"e what constitutes a healthy status for each microservice. In the sample\\napplication, we define the \", \"microservice is healthy if its API is accessible via HTTP and its related SQL\\nServer database is als\", \"o available.\\nIn .NET 7, with the built-in APIs, you can configure the services, add a Health Check f\", \"or the\\nmicroservice and its dependent SQL Server database in this way:\\n// Program.cs from .NET 7 Web\", \" API sample\\n//...\\n// Registers required services for health checks\\nbuilder.Services.AddHealthChecks(\", \")\\n// Add a health check for a SQL Server database\\n.AddCheck(\\n\\\"OrderingDB-check\\\",\\nnew SqlConnectionHe\", \"althCheck(builder.Configuration[\\\"ConnectionString\\\"]),\\nHealthStatus.Unhealthy,\\nnew string[] { \\\"orderi\", \"ngdb\\\" });\\nIn the previous code, the services.AddHealthChecks() method configures a basic HTTP check \", \"that\\nreturns a status code 200 with \\u201cHealthy\\u201d. Further, the AddCheck() extension method configures a\", \"\\ncustom SqlConnectionHealthCheck that checks the related SQL Database\\u2019s health.\\nThe AddCheck() metho\", \"d adds a new health check with a specified name and the implementation of\\ntype IHealthCheck. You can\", \" add multiple Health Checks using AddCheck method, so a microservice\\nwon\\u2019t provide a \\u201chealthy\\u201d statu\", \"s until all its checks are healthy.\\n311 CHAPTER 7 | Implement resilient applicationsSqlConnectionHea\", \"lthCheck is a custom class that implements IHealthCheck, which takes a connection\\nstring as a constr\", \"uctor parameter and executes a simple query to check if the connection to the SQL\\ndatabase is succes\", \"sful. It returns HealthCheckResult.Healthy() if the query was executed successfully\\nand a FailureSta\", \"tus with the actual exception when it fails.\\n// Sample SQL Connection Health Check\\npublic class SqlC\", \"onnectionHealthCheck : IHealthCheck\\n{\\nprivate const string DefaultTestQuery = \\\"Select 1\\\";\\npublic str\", \"ing ConnectionString { get; }\\npublic string TestQuery { get; }\\npublic SqlConnectionHealthCheck(strin\", \"g connectionString)\\n: this(connectionString, testQuery: DefaultTestQuery)\\n{\\n}\\npublic SqlConnectionHe\", \"althCheck(string connectionString, string testQuery)\\n{\\nConnectionString = connectionString ?? throw \", \"new\\nArgumentNullException(nameof(connectionString));\\nTestQuery = testQuery;\\n}\\npublic async Task<Heal\", \"thCheckResult> CheckHealthAsync(HealthCheckContext context,\\nCancellationToken cancellationToken = de\", \"fault(CancellationToken))\\n{\\nusing (var connection = new SqlConnection(ConnectionString))\\n{\\ntry\\n{\\nawa\", \"it connection.OpenAsync(cancellationToken);\\nif (TestQuery != null)\\n{\\nvar command = connection.Create\", \"Command();\\ncommand.CommandText = TestQuery;\\nawait command.ExecuteNonQueryAsync(cancellationToken);\\n}\", \"\\n}\\ncatch (DbException ex)\\n{\\nreturn new HealthCheckResult(status: context.Registration.FailureStatus,\", \"\\nexception: ex);\\n}\\n}\\nreturn HealthCheckResult.Healthy();\\n}\\n}\\nNote that in the previous code, Select \", \"1 is the query used to check the Health of the database. To\\nmonitor the availability of your microse\", \"rvices, orchestrators like Kubernetes periodically perform\\nhealth checks by sending requests to test\", \" the microservices. It\\u2019s important to keep your database\\nqueries efficient so that these operations \", \"are quick and don\\u2019t result in a higher utilization of resources.\\n312 CHAPTER 7 | Implement resilient\", \" applicationsFinally, add a middleware that responds to the url path /hc:\\n// Program.cs from .NET 7 \", \"Web Api sample\\napp.MapHealthChecks(\\\"/hc\\\");\\nWhen the endpoint <yourmicroservice>/hc is invoked, it ru\", \"ns all the health checks that are configured\\nin the AddHealthChecks() method in the Startup class an\", \"d shows the result.\\nHealthChecks implementation in eShopOnContainers\\nMicroservices in eShopOnContain\", \"ers rely on multiple services to perform its task. For example, the\\nCatalog.API microservice from eS\", \"hopOnContainers depends on many services, such as Azure Blob\\nStorage, SQL Server, and RabbitMQ. Ther\", \"efore, it has several health checks added using the\\nAddCheck() method. For every dependent service, \", \"a custom IHealthCheck implementation that\\ndefines its respective health status would need to be adde\", \"d.\\nThe open-source project AspNetCore.Diagnostics.HealthChecks solves this problem by providing\\ncust\", \"om health check implementations for each of these enterprise services, that are built on top of\\n.NET\", \" 7. Each health check is available as an individual NuGet package that can be easily added to the\\npr\", \"oject. eShopOnContainers uses them extensively in all its microservices.\\nFor instance, in the Catalo\", \"g.API microservice, the following NuGet packages were added:\\nFigure 8-7. Custom Health Checks implem\", \"ented in Catalog.API using AspNetCore.Diagnostics.HealthChecks\\nIn the following code, the health che\", \"ck implementations are added for each dependent service and\\nthen the middleware is configured:\\n// Ex\", \"tension method from Catalog.api microservice\\n//\\npublic static IServiceCollection AddCustomHealthChec\", \"k(this IServiceCollection services,\\nIConfiguration configuration)\\n{\\nvar accountName = configuration.\", \"GetValue<string>(\\\"AzureStorageAccountName\\\");\\nvar accountKey = configuration.GetValue<string>(\\\"AzureS\", \"torageAccountKey\\\");\\nvar hcBuilder = services.AddHealthChecks();\\n313 CHAPTER 7 | Implement resilient \", \"applicationshcBuilder\\n.AddSqlServer(\\nconfiguration[\\\"ConnectionString\\\"],\\nname: \\\"CatalogDB-check\\\",\\ntag\", \"s: new string[] { \\\"catalogdb\\\" });\\nif (!string.IsNullOrEmpty(accountName) && !string.IsNullOrEmpty(ac\", \"countKey))\\n{\\nhcBuilder\\n.AddAzureBlobStorage(\\n$\\\"DefaultEndpointsProtocol=https;AccountName={accountNa\", \"me};AccountKey={accountKey};Endpoint\\nSuffix=core.windows.net\\\",\\nname: \\\"catalog-storage-check\\\",\\ntags: \", \"new string[] { \\\"catalogstorage\\\" });\\n}\\nif (configuration.GetValue<bool>(\\\"AzureServiceBusEnabled\\\"))\\n{\\n\", \"hcBuilder\\n.AddAzureServiceBusTopic(\\nconfiguration[\\\"EventBusConnection\\\"],\\ntopicName: \\\"eshop_event_bus\", \"\\\",\\nname: \\\"catalog-servicebus-check\\\",\\ntags: new string[] { \\\"servicebus\\\" });\\n}\\nelse\\n{\\nhcBuilder\\n.AddRa\", \"bbitMQ(\\n$\\\"amqp://{configuration[\\\"EventBusConnection\\\"]}\\\",\\nname: \\\"catalog-rabbitmqbus-check\\\",\\ntags: ne\", \"w string[] { \\\"rabbitmqbus\\\" });\\n}\\nreturn services;\\n}\\nFinally, add the HealthCheck middleware to liste\", \"n to \\u201c/hc\\u201d endpoint:\\n// HealthCheck middleware\\napp.UseHealthChecks(\\\"/hc\\\", new HealthCheckOptions()\\n{\", \"\\nPredicate = _ => true,\\nResponseWriter = UIResponseWriter.WriteHealthCheckUIResponse\\n});\\nQuery your \", \"microservices to report about their health status\\nWhen you\\u2019ve configured health checks as described \", \"in this article and you have the microservice\\nrunning in Docker, you can directly check from a brows\", \"er if it\\u2019s healthy. You have to publish the\\ncontainer port in the Docker host, so you can access the\", \" container through the external Docker host IP\\nor through host.docker.internal, as shown in figure 8\", \"-8.\\n314 CHAPTER 7 | Implement resilient applicationsFigure 8-8. Checking health status of a single s\", \"ervice from a browser\\nIn that test, you can see that the Catalog.API microservice (running on port 5\", \"101) is healthy, returning\\nHTTP status 200 and status information in JSON. The service also checked \", \"the health of its SQL Server\\ndatabase dependency and RabbitMQ, so the health check reported itself a\", \"s healthy.\\nUse watchdogs\\nA watchdog is a separate service that can watch health and load across serv\", \"ices, and report health\\nabout the microservices by querying with the HealthChecks library introduced\", \" earlier. This can help\\nprevent errors that would not be detected based on the view of a single serv\", \"ice. Watchdogs also are a\\ngood place to host code that can perform remediation actions for known con\", \"ditions without user\\ninteraction.\\nThe eShopOnContainers sample contains a web page that displays sam\", \"ple health check reports, as\\nshown in Figure 8-9. This is the simplest watchdog you could have since\", \" it only shows the state of the\\nmicroservices and web applications in eShopOnContainers. Usually a w\", \"atchdog also takes actions\\nwhen it detects unhealthy states.\\nFortunately, AspNetCore.Diagnostics.Hea\", \"lthChecks also provides AspNetCore.HealthChecks.UI NuGet\\npackage that can be used to display the hea\", \"lth check results from the configured URIs.\\n315 CHAPTER 7 | Implement resilient applicationsFigure 8\", \"-9. Sample health check report in eShopOnContainers\\nIn summary, this watchdog service queries each m\", \"icroservice\\u2019s \\u201c/hc\\u201d endpoint. This will execute all the\\nhealth checks defined within it and return a\", \"n overall health state depending on all those checks. The\\nHealthChecksUI is easy to consume with a f\", \"ew configuration entries and two lines of code that needs\\nto be added into the Startup.cs of the wat\", \"chdog service.\\nSample configuration file for health check UI:\\n// Configuration\\n{\\n\\\"HealthChecksUI\\\": {\", \"\\n\\\"HealthChecks\\\": [\\n{\\n\\\"Name\\\": \\\"Ordering HTTP Check\\\",\\n\\\"Uri\\\": \\\"http://host.docker.internal:5102/hc\\\"\\n},\\n\", \"{\\n\\\"Name\\\": \\\"Ordering HTTP Background Check\\\",\\n\\\"Uri\\\": \\\"http://host.docker.internal:5111/hc\\\"\\n},\\n//...\\n]}\", \"\\n}\\nProgram.cs file that adds HealthChecksUI:\\n316 CHAPTER 7 | Implement resilient applications// Prog\", \"ram.cs from WebStatus(Watch Dog) service\\n//\\n// Registers required services for health checks\\nbuilder\", \".Services.AddHealthChecksUI();\\n// build the app, register other middleware\\napp.UseHealthChecksUI(con\", \"fig => config.UIPath = \\\"/hc-ui\\\");\\nHealth checks when using orchestrators\\nTo monitor the availability\", \" of your microservices, orchestrators like Kubernetes and Service Fabric\\nperiodically perform health\", \" checks by sending requests to test the microservices. When an\\norchestrator determines that a servic\", \"e/container is unhealthy, it stops routing requests to that\\ninstance. It also usually creates a new \", \"instance of that container.\\nFor instance, most orchestrators can use health checks to manage zero-do\", \"wntime deployments. Only\\nwhen the status of a service/container changes to healthy will the orchestr\", \"ator start routing traffic to\\nservice/container instances.\\nHealth monitoring is especially important\", \" when an orchestrator performs an application upgrade.\\nSome orchestrators (like Azure Service Fabric\", \") update services in phases\\u2014for example, they might\\nupdate one-fifth of the cluster surface for each\", \" application upgrade. The set of nodes that\\u2019s upgraded\\nat the same time is referred to as an upgrade\", \" domain. After each upgrade domain has been upgraded\\nand is available to users, that upgrade domain \", \"must pass health checks before the deployment moves\\nto the next upgrade domain.\\nAnother aspect of se\", \"rvice health is reporting metrics from the service. This is an advanced capability of\\nthe health mod\", \"el of some orchestrators, like Service Fabric. Metrics are important when using an\\norchestrator beca\", \"use they are used to balance resource usage. Metrics also can be an indicator of\\nsystem health. For \", \"example, you might have an application that has many microservices, and each\\ninstance reports a requ\", \"ests-per-second (RPS) metric. If one service is using more resources (memory,\\nprocessor, etc.) than \", \"another service, the orchestrator could move service instances around in the\\ncluster to try to maint\", \"ain even resource utilization.\\nNote that Azure Service Fabric provides its own Health Monitoring mod\", \"el, which is more advanced\\nthan simple health checks.\\nAdvanced monitoring: visualization, analysis, \", \"and alerts\\nThe final part of monitoring is visualizing the event stream, reporting on service perfor\", \"mance, and\\nalerting when an issue is detected. You can use different solutions for this aspect of mo\", \"nitoring.\\nYou can use simple custom applications showing the state of your services, like the custom\", \" page\\nshown when explaining the AspNetCore.Diagnostics.HealthChecks. Or you could use more advanced\\n\", \"tools like Azure Monitor to raise alerts based on the stream of events.\\nFinally, if you\\u2019re storing a\", \"ll the event streams, you can use Microsoft Power BI or other solutions like\\nKibana or Splunk to vis\", \"ualize the data.\\n317 CHAPTER 7 | Implement resilient applicationsAdditional resources\\n\\u2022 HealthChecks\", \" and HealthChecks UI for ASP.NET Core\\nhttps://github.com/Xabaril/AspNetCore.Diagnostics.HealthChecks\", \"\\n\\u2022 Introduction to Service Fabric health monitoring\\nhttps://learn.microsoft.com/azure/service-fabric\", \"/service-fabric-health-introduction\\n\\u2022 Azure Monitor\\nhttps://azure.microsoft.com/services/monitor/\\n31\", \"8 CHAPTER 7 | Implement resilient applications8\\nCHAPTER\\nMake secure .NET\\nMicroservices and Web\\nAppli\", \"cations\\nThere are so many aspects about security in microservices and web applications that the topi\", \"c could\\neasily take several books like this one. So, in this section, we\\u2019ll focus on authentication,\", \" authorization,\\nand application secrets.\\nImplement authentication in .NET microservices and\\nweb appl\", \"ications\\nIt\\u2019s often necessary for resources and APIs published by a service to be limited to certain\", \" trusted users\\nor clients. The first step to making these sorts of API-level trust decisions is auth\", \"entication.\\nAuthentication is the process of reliably verifying a user\\u2019s identity.\\nIn microservice s\", \"cenarios, authentication is typically handled centrally. If you\\u2019re using an API Gateway,\\nthe gateway\", \" is a good place to authenticate, as shown in Figure 9-1. If you use this approach, make\\nsure that t\", \"he individual microservices cannot be reached directly (without the API Gateway) unless\\nadditional s\", \"ecurity is in place to authenticate messages whether they come from the gateway or not.\\nFigure 9-1. \", \"Centralized authentication with an API Gateway\\nWhen the API Gateway centralizes authentication, it a\", \"dds user information when forwarding requests\\nto the microservices. If services can be accessed dire\", \"ctly, an authentication service like Azure Active\\n319 CHAPTER 8 | Make secure .NET Microservices and\", \" Web ApplicationsDirectory or a dedicated authentication microservice acting as a security token ser\", \"vice (STS) can be\\nused to authenticate users. Trust decisions are shared between services with secur\", \"ity tokens or\\ncookies. (These tokens can be shared between ASP.NET Core applications, if needed, by \", \"implementing\\ncookie sharing.) This pattern is illustrated in Figure 9-2.\\nFigure 9-2. Authentication \", \"by identity microservice; trust is shared using an authorization token\\nWhen microservices are access\", \"ed directly, trust, that includes authentication and authorization, is\\nhandled by a security token i\", \"ssued by a dedicated microservice, shared between microservices.\\nAuthenticate with ASP.NET Core Iden\", \"tity\\nThe primary mechanism in ASP.NET Core for identifying an application\\u2019s users is the ASP.NET Cor\", \"e\\nIdentity membership system. ASP.NET Core Identity stores user information (including sign-in\\ninfor\", \"mation, roles, and claims) in a data store configured by the developer. Typically, the ASP.NET\\nCore \", \"Identity data store is an Entity Framework store provided in the\\nMicrosoft.AspNetCore.Identity.Entit\", \"yFrameworkCore package. However, custom stores or other third-\\nparty packages can be used to store i\", \"dentity information in Azure Table Storage, CosmosDB, or other\\nlocations.\\nTip\\nASP.NET Core 2.1 and l\", \"ater provides ASP.NET Core Identity as a Razor Class Library, so you won\\u2019t see\\nmuch of the necessary\", \" code in your project, as was the case for previous versions. For details on how\\nto customize the Id\", \"entity code to suit your needs, see Scaffold Identity in ASP.NET Core projects.\\nThe following code i\", \"s taken from the ASP.NET Core Web Application MVC 3.1 project template with\\nindividual user account \", \"authentication selected. It shows how to configure ASP.NET Core Identity\\nusing Entity Framework Core\", \" in the Program.cs file.\\n//...\\nbuilder.Services.AddDbContext<ApplicationDbContext>(options =>\\noption\", \"s.UseSqlServer(\\nbuilder.Configuration.GetConnectionString(\\\"DefaultConnection\\\")));\\n320 CHAPTER 8 | Ma\", \"ke secure .NET Microservices and Web Applicationsbuilder.Services.AddDefaultIdentity<IdentityUser>(o\", \"ptions =>\\noptions.SignIn.RequireConfirmedAccount = true)\\n.AddEntityFrameworkStores<ApplicationDbCont\", \"ext>();\\nbuilder.Services.AddRazorPages();\\n//...\\nOnce ASP.NET Core Identity is configured, you enable\", \" it by adding the\\napp.UseAuthentication() and endpoints.MapRazorPages() as shown in the following co\", \"de in the\\nservice\\u2019s Program.cs file:\\n//...\\napp.UseRouting();\\napp.UseAuthentication();\\napp.UseAuthori\", \"zation();\\napp.UseEndpoints(endpoints =>\\n{\\nendpoints.MapRazorPages();\\n});\\n//...\\nImportant\\nThe lines i\", \"n the preceding code MUST BE IN THE ORDER SHOWN for Identity to work correctly.\\nUsing ASP.NET Core I\", \"dentity enables several scenarios:\\n\\u2022 Create new user information using the UserManager type (userMan\", \"ager.CreateAsync).\\n\\u2022 Authenticate users using the SignInManager type. You can use signInManager.Sign\", \"InAsync to\\nsign in directly, or signInManager.PasswordSignInAsync to confirm the user\\u2019s password is\\n\", \"correct and then sign them in.\\n\\u2022 Identify a user based on information stored in a cookie (which is r\", \"ead by ASP.NET Core\\nIdentity middleware) so that subsequent requests from a browser will include a s\", \"igned-in\\nuser\\u2019s identity and claims.\\nASP.NET Core Identity also supports two-factor authentication.\\n\", \"For authentication scenarios that make use of a local user data store and that persist identity betw\", \"een\\nrequests using cookies (as is typical for MVC web applications), ASP.NET Core Identity is a\\nreco\", \"mmended solution.\\nAuthenticate with external providers\\nASP.NET Core also supports using external aut\", \"hentication providers to let users sign in via OAuth 2.0\\nflows. This means that users can sign in us\", \"ing existing authentication processes from providers like\\nMicrosoft, Google, Facebook, or Twitter an\", \"d associate those identities with an ASP.NET Core identity\\nin your application.\\nTo use external auth\", \"entication, besides including the authentication middleware as mentioned before,\\nusing the app.UseAu\", \"thentication() method, you also have to register the external provider in\\nProgram.cs as shown in the\", \" following example:\\n321 CHAPTER 8 | Make secure .NET Microservices and Web Applications//...\\nservice\", \"s.AddDefaultIdentity<IdentityUser>(options => options.SignIn.RequireConfirmedAccount\\n= true)\\n.AddEnt\", \"ityFrameworkStores<ApplicationDbContext>();\\nservices.AddAuthentication()\\n.AddMicrosoftAccount(micros\", \"oftOptions =>\\n{\\nmicrosoftOptions.ClientId =\\nbuilder.Configuration[\\\"Authentication:Microsoft:ClientId\", \"\\\"];\\nmicrosoftOptions.ClientSecret =\\nbuilder.Configuration[\\\"Authentication:Microsoft:ClientSecret\\\"];\\n\", \"})\\n.AddGoogle(googleOptions => { ... })\\n.AddTwitter(twitterOptions => { ... })\\n.AddFacebook(facebook\", \"Options => { ... });\\n//...\\nPopular external authentication providers and their associated NuGet pack\", \"ages are shown in the\\nfollowing table:\\nProvider Package\\nMicrosoft Microsoft.AspNetCore.Authenticatio\", \"n.MicrosoftAccount\\nGoogle Microsoft.AspNetCore.Authentication.Google\\nFacebook Microsoft.AspNetCore.A\", \"uthentication.Facebook\\nTwitter Microsoft.AspNetCore.Authentication.Twitter\\nIn all cases, you must co\", \"mplete an application registration procedure that is vendor dependent and\\nthat usually involves:\\n1. \", \"Getting a Client Application ID.\\n2. Getting a Client Application Secret.\\n3. Configuring a redirectio\", \"n URL, that\\u2019s handled by the authorization middleware and the\\nregistered provider\\n4. Optionally, con\", \"figuring a sign-out URL to properly handle sign out in a Single Sign On (SSO)\\nscenario.\\nFor details \", \"on configuring your app for an external provider, see the External provider authentication\\nin the AS\", \"P.NET Core documentation).\\nTip\\nAll details are handled by the authorization middleware and services \", \"previously mentioned. So, you\\njust have to choose the Individual User Account authentication option \", \"when you create the ASP.NET\\nCore web application project in Visual Studio, as shown in Figure 9-3, b\", \"esides registering the\\nauthentication providers previously mentioned.\\n322 CHAPTER 8 | Make secure .N\", \"ET Microservices and Web ApplicationsFigure 9-3. Selecting the Individual User Accounts option, for \", \"using external authentication, when creating a web\\napplication project in Visual Studio 2019.\\nIn add\", \"ition to the external authentication providers listed previously, third-party packages are\\navailable\", \" that provide middleware for using many more external authentication providers. For a list,\\nsee the \", \"AspNet.Security.OAuth.Providers repository on GitHub.\\nYou can also create your own external authenti\", \"cation middleware to solve some special need.\\nAuthenticate with bearer tokens\\nAuthenticating with AS\", \"P.NET Core Identity (or Identity plus external authentication providers) works\\nwell for many web app\", \"lication scenarios in which storing user information in a cookie is appropriate.\\nIn other scenarios,\", \" though, cookies are not a natural means of persisting and transmitting data.\\nFor example, in an ASP\", \".NET Core Web API that exposes RESTful endpoints that might be accessed by\\nSingle Page Applications \", \"(SPAs), by native clients, or even by other Web APIs, you typically want to\\nuse bearer token authent\", \"ication instead. These types of applications do not work with cookies, but\\ncan easily retrieve a bea\", \"rer token and include it in the authorization header of subsequent requests.\\nTo enable token authent\", \"ication, ASP.NET Core supports several options for using OAuth 2.0 and\\nOpenID Connect.\\n323 CHAPTER 8\", \" | Make secure .NET Microservices and Web ApplicationsAuthenticate with an OpenID Connect or OAuth 2\", \".0 Identity provider\\nIf user information is stored in Azure Active Directory or another identity sol\", \"ution that supports\\nOpenID Connect or OAuth 2.0, you can use the\\nMicrosoft.AspNetCore.Authentication\", \".OpenIdConnect package to authenticate using the OpenID\\nConnect workflow. For example, to authentica\", \"te to the Identity.Api microservice in\\neShopOnContainers, an ASP.NET Core web application can use mi\", \"ddleware from that package as\\nshown in the following simplified example in Program.cs:\\n// Program.cs\", \"\\nvar identityUrl = builder.Configuration.GetValue<string>(\\\"IdentityUrl\\\");\\nvar callBackUrl = builder.\", \"Configuration.GetValue<string>(\\\"CallBackUrl\\\");\\nvar sessionCookieLifetime = builder.Configuration.Get\", \"Value(\\\"SessionCookieLifetimeMinutes\\\",\\n60);\\n// Add Authentication services\\nservices.AddAuthentication\", \"(options =>\\n{\\noptions.DefaultScheme = CookieAuthenticationDefaults.AuthenticationScheme;\\noptions.Def\", \"aultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;\\n})\\n.AddCookie(setup => setup.ExpireTim\", \"eSpan = TimeSpan.FromMinutes(sessionCookieLifetime))\\n.AddOpenIdConnect(options =>\\n{\\noptions.SignInSc\", \"heme = CookieAuthenticationDefaults.AuthenticationScheme;\\noptions.Authority = identityUrl.ToString()\", \";\\noptions.SignedOutRedirectUri = callBackUrl.ToString();\\noptions.ClientId = useLoadTest ? \\\"mvctest\\\" \", \": \\\"mvc\\\";\\noptions.ClientSecret = \\\"secret\\\";\\noptions.ResponseType = useLoadTest ? \\\"code id_token token\\\"\", \" : \\\"code id_token\\\";\\noptions.SaveTokens = true;\\noptions.GetClaimsFromUserInfoEndpoint = true;\\noptions\", \".RequireHttpsMetadata = false;\\noptions.Scope.Add(\\\"openid\\\");\\noptions.Scope.Add(\\\"profile\\\");\\noptions.Sc\", \"ope.Add(\\\"orders\\\");\\noptions.Scope.Add(\\\"basket\\\");\\noptions.Scope.Add(\\\"marketing\\\");\\noptions.Scope.Add(\\\"l\", \"ocations\\\");\\noptions.Scope.Add(\\\"webshoppingagg\\\");\\noptions.Scope.Add(\\\"orders.signalrhub\\\");\\n});\\n// Buil\", \"d the app\\n//\\u2026\\napp.UseAuthentication();\\n//\\u2026\\napp.UseEndpoints(endpoints =>\\n{\\n//...\\n});\\nWhen you use th\", \"is workflow, the ASP.NET Core Identity middleware is not needed, because all user\\ninformation storag\", \"e and authentication is handled by the Identity service.\\n324 CHAPTER 8 | Make secure .NET Microservi\", \"ces and Web ApplicationsIssue security tokens from an ASP.NET Core service\\nIf you prefer to issue se\", \"curity tokens for local ASP.NET Core Identity users rather than using an\\nexternal identity provider,\", \" you can take advantage of some good third-party libraries.\\nIdentityServer4 and OpenIddict are OpenI\", \"D Connect providers that integrate easily with ASP.NET Core\\nIdentity to let you issue security token\", \"s from an ASP.NET Core service. The IdentityServer4\\ndocumentation has in-depth instructions for usin\", \"g the library. However, the basic steps to using\\nIdentityServer4 to issue tokens are as follows.\\n1. \", \"You configure IdentityServer4 in Program.cs by making a call to\\nbuilder.Services.AddIdentityServer.\\n\", \"2. You call app.UseIdentityServer in Program.cs to add IdentityServer4 to the application\\u2019s HTTP\\nreq\", \"uest processing pipeline. This lets the library serve requests to OpenID Connect and\\nOAuth2 endpoint\", \"s like /connect/token.\\n3. You configure identity server by setting the following data:\\n\\u2013 The credent\", \"ials to use for signing.\\n\\u2013 The Identity and API resources that users might request access to:\\n\\u2022 API \", \"resources represent protected data or functionality that a user can access\\nwith an access token. An \", \"example of an API resource would be a web API (or\\nset of APIs) that requires authorization.\\n\\u2022 Identi\", \"ty resources represent information (claims) that are given to a client to\\nidentify a user. The claim\", \"s might include the user name, email address, and so\\non.\\n\\u2013 The clients that will be connecting in or\", \"der to request tokens.\\n\\u2013 The storage mechanism for user information, such as ASP.NET Core Identity o\", \"r an\\nalternative.\\nWhen you specify clients and resources for IdentityServer4 to use, you can pass an\", \" IEnumerable\\ncollection of the appropriate type to methods that take in-memory client or resource st\", \"ores. Or for\\nmore complex scenarios, you can provide client or resource provider types via Dependenc\", \"y Injection.\\nA sample configuration for IdentityServer4 to use in-memory resources and clients provi\", \"ded by a\\ncustom IClientStore type might look like the following example:\\n// Program.cs\\nbuilder.Servi\", \"ces.AddSingleton<IClientStore, CustomClientStore>();\\nbuilder.Services.AddIdentityServer()\\n.AddSignin\", \"gCredential(\\\"CN=sts\\\")\\n.AddInMemoryApiResources(MyApiResourceProvider.GetAllResources())\\n.AddAspNetId\", \"entity<ApplicationUser>();\\n//...\\n325 CHAPTER 8 | Make secure .NET Microservices and Web Applications\", \"Consume security tokens\\nAuthenticating against an OpenID Connect endpoint or issuing your own securi\", \"ty tokens covers some\\nscenarios. But what about a service that simply needs to limit access to those\", \" users who have valid\\nsecurity tokens that were provided by a different service?\\nFor that scenario, \", \"authentication middleware that handles JWT tokens is available in the\\nMicrosoft.AspNetCore.Authentic\", \"ation.JwtBearer package. JWT stands for \\u201cJSON Web Token\\u201d and\\nis a common security token format (defi\", \"ned by RFC 7519) for communicating security claims. A\\nsimplified example of how to use middleware to\", \" consume such tokens might look like this code\\nfragment, taken from the Ordering.Api microservice of\", \" eShopOnContainers.\\n// Program.cs\\nvar identityUrl = builder.Configuration.GetValue<string>(\\\"Identity\", \"Url\\\");\\n// Add Authentication services\\nbuilder.Services.AddAuthentication(options =>\\n{\\noptions.Defaul\", \"tAuthenticateScheme =\\nAspNetCore.Authentication.JwtBearer.JwtBearerDefaults.AuthenticationScheme;\\nop\", \"tions.DefaultChallengeScheme =\\nAspNetCore.Authentication.JwtBearer.JwtBearerDefaults.AuthenticationS\", \"cheme;\\n}).AddJwtBearer(options =>\\n{\\noptions.Authority = identityUrl;\\noptions.RequireHttpsMetadata = \", \"false;\\noptions.Audience = \\\"orders\\\";\\n});\\n// Build the app\\napp.UseAuthentication();\\n//\\u2026\\napp.UseEndpoin\", \"ts(endpoints =>\\n{\\n//...\\n});\\nThe parameters in this usage are:\\n\\u2022 Audience represents the receiver of \", \"the incoming token or the resource that the token grants\\naccess to. If the value specified in this p\", \"arameter does not match the parameter in the token,\\nthe token will be rejected.\\n\\u2022 Authority is the a\", \"ddress of the token-issuing authentication server. The JWT bearer\\nauthentication middleware uses thi\", \"s URI to get the public key that can be used to validate the\\ntoken\\u2019s signature. The middleware also \", \"confirms that the iss parameter in the token matches\\nthis URI.\\nAnother parameter, RequireHttpsMetada\", \"ta, is useful for testing purposes; you set this parameter to\\nfalse so you can test in environments \", \"where you don\\u2019t have certificates. In real-world deployments,\\nJWT bearer tokens should always be pas\", \"sed only over HTTPS.\\n326 CHAPTER 8 | Make secure .NET Microservices and Web ApplicationsWith this mi\", \"ddleware in place, JWT tokens are automatically extracted from authorization headers.\\nThey are then \", \"deserialized, validated (using the values in the Audience and Authority parameters), and\\nstored as u\", \"ser information to be referenced later by MVC actions or authorization filters.\\nThe JWT bearer authe\", \"ntication middleware can also support more advanced scenarios, such as using a\\nlocal certificate to \", \"validate a token if the authority is not available. For this scenario, you can specify a\\nTokenValida\", \"tionParameters object in the JwtBearerOptions object.\\nAdditional resources\\n\\u2022 Sharing cookies between\", \" applications\\nhttps://learn.microsoft.com/aspnet/core/security/cookie-sharing\\n\\u2022 Introduction to Iden\", \"tity\\nhttps://learn.microsoft.com/aspnet/core/security/authentication/identity\\n\\u2022 Rick Anderson. Two-f\", \"actor authentication with SMS\\nhttps://learn.microsoft.com/aspnet/core/security/authentication/2fa\\n\\u2022 \", \"Enabling authentication using Facebook, Google and other external providers\\nhttps://learn.microsoft.\", \"com/aspnet/core/security/authentication/social/\\n\\u2022 Michell Anicas. An Introduction to OAuth 2\\nhttps:/\", \"/www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2\\n\\u2022 AspNet.Security.OAuth.Provide\", \"rs (GitHub repo for ASP.NET OAuth providers)\\nhttps://github.com/aspnet-contrib/AspNet.Security.OAuth\", \".Providers/tree/dev/src\\n\\u2022 IdentityServer4. Official documentation\\nhttps://identityserver4.readthedoc\", \"s.io/en/latest/\\nAbout authorization in .NET microservices and web\\napplications\\nAfter authentication,\", \" ASP.NET Core Web APIs need to authorize access. This process allows a service\\nto make APIs availabl\", \"e to some authenticated users, but not to all. Authorization can be done based\\non users\\u2019 roles or ba\", \"sed on custom policy, which might include inspecting claims or other heuristics.\\nRestricting access \", \"to an ASP.NET Core MVC route is as easy as applying an Authorize attribute to the\\naction method (or \", \"to the controller\\u2019s class if all the controller\\u2019s actions require authorization), as\\nshown in follow\", \"ing example:\\npublic class AccountController : Controller\\n{\\npublic ActionResult Login()\\n{\\n}\\n[Authoriz\", \"e]\\n327 CHAPTER 8 | Make secure .NET Microservices and Web Applicationspublic ActionResult Logout()\\n{\", \"\\n}\\n}\\nBy default, adding an Authorize attribute without parameters will limit access to authenticated\", \" users\\nfor that controller or action. To further restrict an API to be available for only specific u\", \"sers, the\\nattribute can be expanded to specify required roles or policies that users must satisfy.\\nI\", \"mplement role-based authorization\\nASP.NET Core Identity has a built-in concept of roles. In addition\", \" to users, ASP.NET Core Identity\\nstores information about different roles used by the application an\", \"d keeps track of which users are\\nassigned to which roles. These assignments can be changed programma\", \"tically with the RoleManager\\ntype that updates roles in persisted storage, and the UserManager type \", \"that can grant or revoke roles\\nfrom users.\\nIf you\\u2019re authenticating with JWT bearer tokens, the ASP.\", \"NET Core JWT bearer authentication\\nmiddleware will populate a user\\u2019s roles based on role claims foun\", \"d in the token. To limit access to an\\nMVC action or controller to users in specific roles, you can i\", \"nclude a Roles parameter in the Authorize\\nannotation (attribute), as shown in the following code fra\", \"gment:\\n[Authorize(Roles = \\\"Administrator, PowerUser\\\")]\\npublic class ControlPanelController : Control\", \"ler\\n{\\npublic ActionResult SetTime()\\n{\\n}\\n[Authorize(Roles = \\\"Administrator\\\")]\\npublic ActionResult Shu\", \"tDown()\\n{\\n}\\n}\\nIn this example, only users in the Administrator or PowerUser roles can access APIs in\", \" the\\nControlPanel controller (such as executing the SetTime action). The ShutDown API is further res\", \"tricted\\nto allow access only to users in the Administrator role.\\nTo require a user be in multiple ro\", \"les, you use multiple Authorize attributes, as shown in the following\\nexample:\\n[Authorize(Roles = \\\"A\", \"dministrator, PowerUser\\\")]\\n[Authorize(Roles = \\\"RemoteEmployee \\\")]\\n[Authorize(Policy = \\\"CustomPolicy\\\"\", \")]\\npublic ActionResult API1 ()\\n{\\n}\\nIn this example, to call API1, a user must:\\n\\u2022 Be in the Administr\", \"ator or PowerUser role, and\\n\\u2022 Be in the RemoteEmployee role, and\\n328 CHAPTER 8 | Make secure .NET Mi\", \"croservices and Web Applications\\u2022 Satisfy a custom handler for CustomPolicy authorization.\\nImplement\", \" policy-based authorization\\nCustom authorization rules can also be written using authorization polic\", \"ies. This section provides an\\noverview. For more information, see the ASP.NET Authorization Workshop\", \".\\nCustom authorization policies are registered in the Startup.ConfigureServices method using the\\nser\", \"vice.AddAuthorization method. This method takes a delegate that configures an\\nAuthorizationOptions a\", \"rgument.\\nservices.AddAuthorization(options =>\\n{\\noptions.AddPolicy(\\\"AdministratorsOnly\\\", policy =>\\npo\", \"licy.RequireRole(\\\"Administrator\\\"));\\noptions.AddPolicy(\\\"EmployeesOnly\\\", policy =>\\npolicy.RequireClaim\", \"(\\\"EmployeeNumber\\\"));\\noptions.AddPolicy(\\\"Over21\\\", policy =>\\npolicy.Requirements.Add(new MinimumAgeReq\", \"uirement(21)));\\n});\\nAs shown in the example, policies can be associated with different types of requ\", \"irements. After the\\npolicies are registered, they can be applied to an action or controller by passi\", \"ng the policy\\u2019s name as\\nthe Policy argument of the Authorize attribute (for example, [Authorize(Poli\", \"cy=\\\"EmployeesOnly\\\")])\\nPolicies can have multiple requirements, not just one (as shown in these examp\", \"les).\\nIn the previous example, the first AddPolicy call is just an alternative way of authorizing by\", \" role. If\\n[Authorize(Policy=\\\"AdministratorsOnly\\\")] is applied to an API, only users in the Administr\", \"ator role will\\nbe able to access it.\\nThe second AddPolicy call demonstrates an easy way to require t\", \"hat a particular claim should be\\npresent for the user. The RequireClaim method also optionally takes\", \" expected values for the claim. If\\nvalues are specified, the requirement is met only if the user has\", \" both a claim of the correct type and\\none of the specified values. If you\\u2019re using the JWT bearer au\", \"thentication middleware, all JWT\\nproperties will be available as user claims.\\nThe most interesting p\", \"olicy shown here is in the third AddPolicy method, because it uses a custom\\nauthorization requiremen\", \"t. By using custom authorization requirements, you can have a great deal of\\ncontrol over how authori\", \"zation is performed. For this to work, you must implement these types:\\n\\u2022 A Requirements type that de\", \"rives from IAuthorizationRequirement and that contains fields\\nspecifying the details of the requirem\", \"ent. In the example, this is an age field for the sample\\nMinimumAgeRequirement type.\\n\\u2022 A handler tha\", \"t implements AuthorizationHandler, where T is the type of\\nIAuthorizationRequirement that the handler\", \" can satisfy. The handler must implement the\\nHandleRequirementAsync method, which checks whether a s\", \"pecified context that contains\\ninformation about the user satisfies the requirement.\\n329 CHAPTER 8 |\", \" Make secure .NET Microservices and Web ApplicationsIf the user meets the requirement, a call to con\", \"text.Succeed will indicate that the user is authorized. If\\nthere are multiple ways that a user might\", \" satisfy an authorization requirement, multiple handlers can\\nbe created.\\nIn addition to registering \", \"custom policy requirements with AddPolicy calls, you also need to register\\ncustom requirement handle\", \"rs via Dependency Injection (services.AddTransient<IAuthorizationHandler,\\nMinimumAgeHandler>()).\\nAn \", \"example of a custom authorization requirement and handler for checking a user\\u2019s age (based on a\\nDate\", \"OfBirth claim) is available in the ASP.NET Core authorization documentation.\\nAuthorization and minim\", \"al apis\\nASP.NET supports minimal APIs as an alternative to controller-based APIs. Authorization poli\", \"cies are\\nthe recommended way to configure authorization for minimal APIs, as this example demonstrat\", \"es:\\n// Program.cs\\nbuilder.Services.AddAuthorizationBuilder()\\n.AddPolicy(\\\"admin_greetings\\\", policy =>\", \"\\npolicy\\n.RequireRole(\\\"admin\\\")\\n.RequireScope(\\\"greetings_api\\\"));\\n// build the app\\napp.MapGet(\\\"/hello\\\",\", \" () => \\\"Hello world!\\\")\\n.RequireAuthorization(\\\"admin_greetings\\\");\\nAdditional resources\\n\\u2022 ASP.NET Core\", \" Authentication\\nhttps://learn.microsoft.com/aspnet/core/security/authentication/identity\\n\\u2022 ASP.NET C\", \"ore Authorization\\nhttps://learn.microsoft.com/aspnet/core/security/authorization/introduction\\n\\u2022 Role\", \"-based Authorization\\nhttps://learn.microsoft.com/aspnet/core/security/authorization/roles\\n\\u2022 Custom P\", \"olicy-Based Authorization\\nhttps://learn.microsoft.com/aspnet/core/security/authorization/policies\\n\\u2022 \", \"Authentication and authorization in minimal\\nAPIs https://learn.microsoft.com/aspnet/core/fundamental\", \"s/minimal-apis/security\\nStore application secrets safely during development\\nTo connect with protecte\", \"d resources and other services, ASP.NET Core applications typically need to\\nuse connection strings, \", \"passwords, or other credentials that contain sensitive information. These\\nsensitive pieces of inform\", \"ation are called secrets. It\\u2019s a best practice to not include secrets in source\\n330 CHAPTER 8 | Make\", \" secure .NET Microservices and Web Applicationscode and making sure not to store secrets in source c\", \"ontrol. Instead, you should use the ASP.NET\\nCore configuration model to read the secrets from more s\", \"ecure locations.\\nYou must separate the secrets for accessing development and staging resources from \", \"the ones used\\nfor accessing production resources, because different individuals will need access to \", \"those different\\nsets of secrets. To store secrets used during development, common approaches are to \", \"either store\\nsecrets in environment variables or by using the ASP.NET Core Secret Manager tool. For \", \"more secure\\nstorage in production environments, microservices can store secrets in an Azure Key Vaul\", \"t.\\nStore secrets in environment variables\\nOne way to keep secrets out of source code is for develope\", \"rs to set string-based secrets as\\nenvironment variables on their development machines. When you use \", \"environment variables to store\\nsecrets with hierarchical names, such as the ones nested in configura\", \"tion sections, you must name the\\nvariables to include the complete hierarchy of its sections, delimi\", \"ted with colons (:).\\nFor example, setting an environment variable Logging:LogLevel:Default to Debug \", \"value would be\\nequivalent to a configuration value from the following JSON file:\\n{\\n\\\"Logging\\\": {\\n\\\"Log\", \"Level\\\": {\\n\\\"Default\\\": \\\"Debug\\\"\\n}\\n}\\n}\\nTo access these values from environment variables, the applicatio\", \"n just needs to call\\nAddEnvironmentVariables on its ConfigurationBuilder when constructing an IConfi\", \"gurationRoot\\nobject.\\nNote\\nEnvironment variables are commonly stored as plain text, so if the machine\", \" or process with the\\nenvironment variables is compromised, the environment variable values will be v\", \"isible.\\nStore secrets with the ASP.NET Core Secret Manager\\nThe ASP.NET Core Secret Manager tool prov\", \"ides another method of keeping secrets out of source\\ncode during development. To use the Secret Mana\", \"ger tool, install the package\\nMicrosoft.Extensions.Configuration.SecretManager in your project file.\", \" Once that dependency is\\npresent and has been restored, the dotnet user-secrets command can be used \", \"to set the value of\\nsecrets from the command line. These secrets will be stored in a JSON file in th\", \"e user\\u2019s profile\\ndirectory (details vary by OS), away from source code.\\nSecrets set by the Secret Ma\", \"nager tool are organized by the UserSecretsId property of the project\\nthat\\u2019s using the secrets. Ther\", \"efore, you must be sure to set the UserSecretsId property in your project\\nfile, as shown in the snip\", \"pet below. The default value is a GUID assigned by Visual Studio, but the\\nactual string is not impor\", \"tant as long as it\\u2019s unique in your computer.\\n331 CHAPTER 8 | Make secure .NET Microservices and Web\", \" Applications<PropertyGroup>\\n<UserSecretsId>UniqueIdentifyingString</UserSecretsId>\\n</PropertyGroup>\", \"\\nUsing secrets stored with Secret Manager in an application is accomplished by calling\\nAddUserSecret\", \"s<T> on the ConfigurationBuilder instance to include secrets for the application in its\\nconfiguratio\", \"n. The generic parameter T should be a type from the assembly that the UserSecretId was\\napplied to. \", \"Usually, using AddUserSecrets<Startup> is fine.\\nThe AddUserSecrets<Startup>() is included in the def\", \"ault options for the Development environment\\nwhen using the CreateDefaultBuilder method in Program.c\", \"s.\\nUse Azure Key Vault to protect secrets at production\\ntime\\nSecrets stored as environment variables\", \" or stored by the Secret Manager tool are still stored locally\\nand unencrypted on the machine. A mor\", \"e secure option for storing secrets is Azure Key Vault, which\\nprovides a secure, central location fo\", \"r storing keys and secrets.\\nThe Azure.Extensions.AspNetCore.Configuration.Secrets package allows an \", \"ASP.NET Core\\napplication to read configuration information from Azure Key Vault. To start using secr\", \"ets from an\\nAzure Key Vault, you follow these steps:\\n1. Register your application as an Azure AD app\", \"lication. (Access to key vaults is managed by\\nAzure AD.) This can be done through the Azure manageme\", \"nt portal.\\nAlternatively, if you want your application to authenticate using a certificate instead o\", \"f a\\npassword or client secret, you can use the New-AzADApplication PowerShell cmdlet. The\\ncertificat\", \"e that you register with Azure Key Vault needs only your public key. Your application\\nwill use the p\", \"rivate key.\\n2. Give the registered application access to the key vault by creating a new service pri\", \"ncipal. You\\ncan do this using the following PowerShell commands:\\n$sp = New-AzADServicePrincipal -App\", \"licationId \\\"<Application ID guid>\\\"\\nSet-AzKeyVaultAccessPolicy -VaultName \\\"<VaultName>\\\" -ServicePrinc\", \"ipalName\\n$sp.ServicePrincipalNames[0] -PermissionsToSecrets all -ResourceGroupName \\\"<KeyVault\\nResour\", \"ce Group>\\\"\\n3. Include the key vault as a configuration source in your application by calling the\\nAzu\", \"reKeyVaultConfigurationExtensions.AddAzureKeyVault extension method when you create\\nan IConfiguratio\", \"nRoot instance.\\nNote that calling AddAzureKeyVault requires the application ID that was registered a\", \"nd given access\\nto the key vault in the previous steps. Or you can firstly running the Azure CLI com\", \"mand: az login,\\nthen using an overload of AddAzureKeyVault that takes a DefaultAzureCredential in pl\", \"ace of the\\nclient.\\n332 CHAPTER 8 | Make secure .NET Microservices and Web ApplicationsImportant\\nWe r\", \"ecommend that you register Azure Key Vault as the last configuration provider, so it can override\\nco\", \"nfiguration values from previous providers.\\nAdditional resources\\n\\u2022 Using Azure Key Vault to protect \", \"application secrets\\nhttps://learn.microsoft.com/azure/architecture/multitenant-identity\\n\\u2022 Safe stora\", \"ge of app secrets during development\\nhttps://learn.microsoft.com/aspnet/core/security/app-secrets\\n\\u2022 \", \"Configuring data protection\\nhttps://learn.microsoft.com/aspnet/core/security/data-protection/configu\", \"ration/overview\\n\\u2022 Data Protection key management and lifetime in ASP.NET Core\\nhttps://learn.microsof\", \"t.com/aspnet/core/security/data-protection/configuration/default-\\nsettings\\n333 CHAPTER 8 | Make secu\", \"re .NET Microservices and Web Applications9\\nCHAPTER\\n.NET Microservices\\nArchitecture key takeaways\\nAs\", \" a summary and key takeaways, the following are the most important conclusions from this guide.\\nBene\", \"fits of using containers. Container-based solutions provide important cost savings because\\nthey help\", \" reduce deployment problems caused by failing dependencies in production environments.\\nContainers si\", \"gnificantly improve DevOps and production operations.\\nContainers will be ubiquitous. Docker-based co\", \"ntainers are becoming the de facto standard in the\\nindustry, supported by key vendors in the Windows\", \" and Linux ecosystems, such as Microsoft, Amazon\\nAWS, Google, and IBM. Docker will probably soon be \", \"ubiquitous in both the cloud and on-premises\\ndatacenters.\\nContainers as a unit of deployment. A Dock\", \"er container is becoming the standard unit of\\ndeployment for any server-based application or service\", \".\\nMicroservices. The microservices architecture is becoming the preferred approach for distributed a\", \"nd\\nlarge or complex mission-critical applications based on many independent subsystems in the form o\", \"f\\nautonomous services. In a microservice-based architecture, the application is built as a collectio\", \"n of\\nservices that are developed, tested, versioned, deployed, and scaled independently. Each servic\", \"e can\\ninclude any related autonomous database.\\nDomain-driven design and SOA. The microservices archi\", \"tecture patterns derive from service-\\noriented architecture (SOA) and domain-driven design (DDD). Wh\", \"en you design and develop\\nmicroservices for environments with evolving business needs and rules, it\\u2019\", \"s important to consider DDD\\napproaches and patterns.\\nMicroservices challenges. Microservices offer m\", \"any powerful capabilities, like independent\\ndeployment, strong subsystem boundaries, and technology \", \"diversity. However, they also raise many\\nnew challenges related to distributed application developme\", \"nt, such as fragmented and independent\\ndata models, resilient communication between microservices, e\", \"ventual consistency, and operational\\ncomplexity that results from aggregating logging and monitoring\", \" information from multiple\\nmicroservices. These aspects introduce a much higher complexity level tha\", \"n a traditional monolithic\\napplication. As a result, only specific scenarios are suitable for micros\", \"ervice-based applications. These\\ninclude large and complex applications with multiple evolving subsy\", \"stems. In these cases, it\\u2019s worth\\ninvesting in a more complex software architecture, because it will\", \" provide better long-term agility and\\napplication maintenance.\\n334 CHAPTER 9 | .NET Microservices Ar\", \"chitecture key takeawaysContainers for any application. Containers are convenient for microservices,\", \" but can also be useful\\nfor monolithic applications based on the traditional .NET Framework, when us\", \"ing Windows\\nContainers. The benefits of using Docker, such as solving many deployment-to-production \", \"issues and\\nproviding state-of-the-art Dev and Test environments, apply to many different types of ap\", \"plications.\\nCLI versus IDE. With Microsoft tools, you can develop containerized .NET applications us\", \"ing your\\npreferred approach. You can develop with a CLI and an editor-based environment by using the\", \" Docker\\nCLI and Visual Studio Code. Or you can use an IDE-focused approach with Visual Studio and it\", \"s unique\\nfeatures for Docker, such as multi-container debugging.\\nResilient cloud applications. In cl\", \"oud-based systems and distributed systems in general, there is\\nalways the risk of partial failure. S\", \"ince clients and services are separate processes (containers), a\\nservice might not be able to respon\", \"d in a timely way to a client\\u2019s request. For example, a service might\\nbe down because of a partial f\", \"ailure or for maintenance; the service might be overloaded and\\nresponding slowly to requests; or it \", \"might not be accessible for a short time because of network\\nissues. Therefore, a cloud-based applica\", \"tion must embrace those failures and have a strategy in place\\nto respond to those failures. These st\", \"rategies can include retry policies (resending messages or\\nretrying requests) and implementing circu\", \"it-breaker patterns to avoid exponential load of repeated\\nrequests. Basically, cloud-based applicati\", \"ons must have resilient mechanisms\\u2014either based on cloud\\ninfrastructure or custom, as the high-level\", \" ones provided by orchestrators or service buses.\\nSecurity. Our modern world of containers and micro\", \"services can expose new vulnerabilities. There are\\nseveral ways to implement basic application secur\", \"ity, based on authentication and authorization.\\nHowever, container security must consider additional\", \" key components that result in inherently safer\\napplications. A critical element of building safer a\", \"pps is having a secure way of communicating with\\nother apps and systems, something that often requir\", \"es credentials, tokens, passwords, and the like,\\ncommonly referred to as application secrets. Any se\", \"cure solution must follow security best practices,\\nsuch as encrypting secrets while in transit and a\", \"t rest, and preventing secrets from leaking when\\nconsumed by the final application. Those secrets ne\", \"ed to be stored and kept safely, as when using\\nAzure Key Vault.\\nOrchestrators. Container-based orche\", \"strators, such as Azure Kubernetes Service and Azure Service\\nFabric are key part of any significant \", \"microservice and container-based application. These applications\\ncarry with them high complexity, sc\", \"alability needs, and go through constant evolution. This guide has\\nintroduced orchestrators and thei\", \"r role in microservice-based and container-based solutions. If your\\napplication needs are moving you\", \" toward complex containerized apps, you will find it useful to seek\\nout additional resources for lea\", \"rning more about orchestrators.\\n335 CHAPTER 9 | .NET Microservices Architecture key takeaways\"]"