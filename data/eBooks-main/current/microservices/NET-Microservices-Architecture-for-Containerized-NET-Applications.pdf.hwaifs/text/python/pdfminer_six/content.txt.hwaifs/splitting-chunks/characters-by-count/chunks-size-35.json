"[\" \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fEDITION v7.0 - Updated to ASP.NET Core 7.\", \"0 \\n\\nRefer changelog for the book updates and community contributions. \\n\\nThis guide is an introductio\", \"n to developing microservices-based applications and managing them \\nusing containers. It discusses a\", \"rchitectural design and implementation approaches using .NET and \\nDocker containers. \\n\\nTo make it ea\", \"sier to get started, the guide focuses on a reference containerized and microservice-\\nbased applicat\", \"ion that you can explore. The reference application is available at the \\neShopOnContainers GitHub re\", \"po. \\n\\nAction links \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThis e-book is also available in a PDF format (English version only) Do\", \"wnload \\n\\nClone/Fork the reference application eShopOnContainers on GitHub \\n\\n\\u2022  Watch the introductor\", \"y video \\n\\n\\u2022 \\n\\nGet to know the Microservices Architecture right away \\n\\nIntroduction \\n\\nEnterprises are\", \" increasingly realizing cost savings, solving deployment problems, and improving \\nDevOps and product\", \"ion operations by using containers. Microsoft has been releasing container \\ninnovations for Windows \", \"and Linux by creating products like Azure Kubernetes Service and Azure \\nService Fabric, and by partn\", \"ering with industry leaders like Docker, Mesosphere, and Kubernetes. \\nThese products deliver contain\", \"er solutions that help companies build and deploy applications at cloud \\nspeed and scale, whatever t\", \"heir choice of platform or tools. \\n\\nDocker is becoming the de facto standard in the container indust\", \"ry, supported by the most significant \\nvendors in the Windows and Linux ecosystems. (Microsoft is on\", \"e of the main cloud vendors \\nsupporting Docker). In the future, Docker will probably be ubiquitous i\", \"n any datacenter in the cloud or \\non-premises. \\n\\nIn addition, the microservices architecture is emer\", \"ging as an important approach for distributed \\nmission-critical applications. In a microservice-base\", \"d architecture, the application is built on a \\ncollection of services that can be developed, tested,\", \" deployed, and versioned independently. \\n\\nAbout this guide \\n\\nThis guide is an introduction to develo\", \"ping microservices-based applications and managing them \\nusing containers. It discusses architectura\", \"l design and implementation approaches using .NET and \\nDocker containers. To make it easier to get s\", \"tarted with containers and microservices, the guide \\nfocuses on a reference containerized and micros\", \"ervice-based application that you can explore. The \\nsample application is available at the eShopOnCo\", \"ntainers GitHub repo. \\n\\n \\n\\fThis guide provides foundational development and architectural guidance p\", \"rimarily at a development \\nenvironment level with a focus on two technologies: Docker and .NET. Our \", \"intention is that you read \\nthis guide when thinking about your application design without focusing \", \"on the infrastructure (cloud \\nor on-premises) of your production environment. You will make decision\", \"s about your infrastructure \\nlater, when you create your production-ready applications. Therefore, t\", \"his guide is intended to be \\ninfrastructure agnostic and more development-environment-centric. \\n\\nAft\", \"er you have studied this guide, your next step would be to learn about production-ready \\nmicroservic\", \"es on Microsoft Azure. \\n\\nVersion \\n\\nThis guide has been revised to cover .NET 7 version along with ma\", \"ny additional updates related to \\nthe same \\u201cwave\\u201d of technologies (that is, Azure and additional thi\", \"rd-party technologies) coinciding in \\ntime with the .NET 7 release. That\\u2019s why the book version has \", \"also been updated to version 7.0. \\n\\nWhat this guide does not cover \\n\\nThis guide does not focus on th\", \"e application lifecycle, DevOps, CI/CD pipelines, or team work. The \\ncomplementary guide Containeriz\", \"ed Docker Application Lifecycle with Microsoft Platform and Tools \\nfocuses on that subject. The curr\", \"ent guide also does not provide implementation details on Azure \\ninfrastructure, such as information\", \" on specific orchestrators. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nContainerized Docker Application Lifecycle \", \"with Microsoft Platform and Tools (downloadable \\ne-book) \\nhttps://aka.ms/dockerlifecycleebook \\n\\nWho \", \"should use this guide \\n\\nWe wrote this guide for developers and solution architects who are new to Do\", \"cker-based application \\ndevelopment and to microservices-based architecture. This guide is for you i\", \"f you want to learn how \\nto architect, design, and implement proof-of-concept applications with Micr\", \"osoft development \\ntechnologies (with special focus on .NET) and with Docker containers. \\n\\nYou will \", \"also find this guide useful if you are a technical decision maker, such as an enterprise \\narchitect,\", \" who wants an architecture and technology overview before you decide on what approach to \\nselect for\", \" new and modern distributed applications. \\n\\nHow to use this guide \\n\\nThe first part of this guide int\", \"roduces Docker containers, discusses how to choose between .NET 7 and \\nthe .NET Framework as a devel\", \"opment framework, and provides an overview of microservices. This \\ncontent is for architects and tec\", \"hnical decision makers who want an overview but don\\u2019t need to focus \\non code implementation details.\", \" \\n\\n \\n\\fThe second part of the guide starts with the Development process for Docker based applications\", \" \\nsection. It focuses on the development and microservice patterns for implementing applications usi\", \"ng \\n.NET and Docker. This section will be of most interest to developers and architects who want to \", \"focus \\non code and on patterns and implementation details. \\n\\nRelated microservice and container-base\", \"d reference \\napplication: eShopOnContainers \\n\\nThe eShopOnContainers application is an open-source re\", \"ference app for .NET and microservices that \\nis designed to be deployed using Docker containers. The\", \" application consists of multiple subsystems, \\nincluding several e-store UI front-ends (a Web MVC ap\", \"p, a Web SPA, and a native mobile app). It also \\nincludes the back-end microservices and containers \", \"for all required server-side operations. \\n\\nThe purpose of the application is to showcase architectur\", \"al patterns. IT IS NOT A PRODUCTION-\\nREADY TEMPLATE to start real-world applications. In fact, the a\", \"pplication is in a permanent beta \\nstate, as it\\u2019s also used to test new potentially interesting tech\", \"nologies as they show up. \\n\\nCredits \\n\\nCo-Authors: \\n\\nCesar de la Torre, Sr. PM, .NET product team, Mi\", \"crosoft Corp. \\n\\nBill Wagner, Sr. Content Developer, C+E, Microsoft Corp. \\n\\nMike Rousos, Principal So\", \"ftware Engineer, DevDiv CAT team, Microsoft \\n\\nEditors: \\n\\nMike Pope \\n\\nSteve Hoag \\n\\nParticipants and r\", \"eviewers: \\n\\nJeffrey Richter, Partner Software Eng, Azure team, Microsoft \\n\\nJimmy Bogard, Chief Archi\", \"tect at Headspring \\n\\nUdi Dahan, Founder & CEO, Particular Software \\n\\nJimmy Nilsson, Co-founder and C\", \"EO of Factor10 \\n\\nGlenn Condron, Sr. Program Manager, ASP.NET team \\n\\nMark Fussell, Principal PM Lead,\", \" Azure Service Fabric team, Microsoft \\n\\nDiego Vega, PM Lead, Entity Framework team, Microsoft \\n\\nBarr\", \"y Dorrans, Sr. Security Program Manager \\n\\nRowan Miller, Sr. Program Manager, Microsoft \\n\\n \\n\\fAnkit As\", \"thana, Principal PM Manager, .NET team, Microsoft \\n\\nScott Hunter, Partner Director PM, .NET team, Mi\", \"crosoft \\n\\nNish Anil, Sr. Program Manager, .NET team, Microsoft \\n\\nDylan Reisenberger, Architect and D\", \"ev Lead at Polly \\n\\nSteve \\u201cardalis\\u201d Smith - Software Architect and Trainer - Ardalis.com \\n\\nIan Cooper\", \", Coding Architect at Brighter \\n\\nUnai Zorrilla, Architect and Dev Lead at Plain Concepts \\n\\nEduard To\", \"mas, Dev Lead at Plain Concepts \\n\\nRamon Tomas, Developer at Plain Concepts \\n\\nDavid Sanz, Developer a\", \"t Plain Concepts \\n\\nJavier Valero, Chief Operating Officer at Grupo Solutio \\n\\nPierre Millet, Sr. Cons\", \"ultant, Microsoft \\n\\nMichael Friis, Product Manager, Docker Inc \\n\\nCharles Lowell, Software Engineer, \", \"VS CAT team, Microsoft \\n\\nMiguel Veloso, Software Development Engineer at Plain Concepts \\n\\nSumit Ghos\", \"h, Principal Consultant at Neudesic \\n\\nCopyright \\n\\nPUBLISHED BY \\n\\nMicrosoft Developer Division, .NET \", \"and Visual Studio product teams \\n\\nA division of Microsoft Corporation \\n\\nOne Microsoft Way \\n\\nRedmond,\", \" Washington 98052-6399 \\n\\nCopyright \\u00a9 2023 by Microsoft Corporation \\n\\nAll rights reserved. No part of\", \" the contents of this book may be reproduced or transmitted in any \\nform or by any means without the\", \" written permission of the publisher. \\n\\nThis book is provided \\u201cas-is\\u201d and expresses the author\\u2019s vie\", \"ws and opinions. The views, opinions and \\ninformation expressed in this book, including URL and othe\", \"r Internet website references, may change \\nwithout notice. \\n\\nSome examples depicted herein are provi\", \"ded for illustration only and are fictitious. No real association \\nor connection is intended or shou\", \"ld be inferred. \\n\\n \\n\\fMicrosoft and the trademarks listed at https://www.microsoft.com on the \\u201cTradem\", \"arks\\u201d webpage are \\ntrademarks of the Microsoft group of companies. \\n\\nMac and macOS are trademarks of\", \" Apple Inc. \\n\\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permission. \\n\\n\", \"All other marks and logos are property of their respective owners. \\n\\n \\n\\fContents \\n\\nIntroduction to C\", \"ontainers and Docker ...............................................................................\", \". 1 \\n\\nWhat is Docker? ..............................................................................\", \".......................................................................................... 2 \\n\\nCompa\", \"ring Docker containers with virtual machines .......................................................\", \".................................... 3 \\n\\nA simple analogy ..........................................\", \"....................................................................................................\", \"................... 4 \\n\\nDocker terminology .........................................................\", \"....................................................................................................\", \"... 5 \\n\\nDocker containers, images, and registries ..................................................\", \"................................................................... 7 \\n\\nChoosing Between .NET and .N\", \"ET Framework for Docker Containers .............................. 9 \\n\\nGeneral guidance .............\", \"....................................................................................................\", \".................................................... 9 \\n\\nWhen to choose .NET for Docker containers .\", \"....................................................................................................\", \"........ 10 \\n\\nDeveloping and deploying cross platform ..............................................\", \".............................................................. 10 \\n\\nUsing containers for new (\\u201cgreen\", \"-field\\u201d) projects ..................................................................................\", \"............. 11 \\n\\nCreate and deploy microservices on containers ...................................\", \"............................................................... 11 \\n\\nDeploying high density in scala\", \"ble systems ........................................................................................\", \".................. 11 \\n\\nWhen to choose .NET Framework for Docker containers ........................\", \"............................................................. 12 \\n\\nMigrating existing applications d\", \"irectly to a Windows Server container .................................................. 12 \\n\\nUsing \", \"third-party .NET libraries or NuGet packages not available for .NET 7 ..............................\", \"........... 12 \\n\\nUsing .NET technologies not available for .NET 7 ..................................\", \"............................................................. 12 \\n\\nUsing a platform or API that does\", \"n\\u2019t support .NET 7 .................................................................................\", \"....... 13 \\n\\nPorting existing ASP.NET application to .NET 7 ........................................\", \"........................................................... 13 \\n\\nDecision table: .NET implementation\", \"s to use for Docker ................................................................................\", \"..... 13 \\n\\nWhat OS to target with .NET containers ..................................................\", \".................................................................... 14 \\n\\nOfficial .NET Docker image\", \"s ..................................................................................................\", \"........................................... 16 \\n\\n.NET and Docker image optimizations for development\", \" versus production ........................................... 16 \\n\\nArchitecting container and micro\", \"service-based applications .......................................... 18 \\n\\nContainer design principl\", \"es .................................................................................................\", \"............................................. 18 \\n\\nContainerizing monolithic applications ..........\", \"....................................................................................................\", \"......... 19 \\n\\nDeploying a monolithic application as a container ...................................\", \"......................................................... 21 \\n\\nPublishing a single-container-based a\", \"pplication to Azure App Service .................................................... 21 \\n\\ni \\n\\nConten\", \"ts \\n\\n \\n \\n\\fManage state and data in Docker applications .............................................\", \"........................................................... 22 \\n\\nService-oriented architecture .....\", \"....................................................................................................\", \".................................. 25 \\n\\nMicroservices architecture .................................\", \"....................................................................................................\", \"............ 25 \\n\\nAdditional resources .............................................................\", \".......................................................................................... 27 \\n\\nData\", \" sovereignty per microservice ......................................................................\", \".......................................................... 27 \\n\\nThe relationship between microservic\", \"es and the Bounded Context pattern ........................................... 29 \\n\\nLogical architec\", \"ture versus physical architecture ..................................................................\", \"................................... 30 \\n\\nChallenges and solutions for distributed data management ..\", \"............................................................................ 31 \\n\\nChallenge #1: How \", \"to define the boundaries of each microservice ......................................................\", \"...... 31 \\n\\nChallenge #2: How to create queries that retrieve data from several microservices ......\", \"...................... 32 \\n\\nChallenge #3: How to achieve consistency across multiple microservices .\", \".............................................. 33 \\n\\nChallenge #4: How to design communication across\", \" microservice boundaries .................................... 35 \\n\\nAdditional resources ............\", \"....................................................................................................\", \"....................................... 36 \\n\\nIdentify domain-model boundaries for each microservice \", \".................................................................................. 36 \\n\\nThe API gate\", \"way pattern versus the Direct client-to-microservice communication .................................\", \". 40 \\n\\nDirect client-to-microservice communication .................................................\", \"..................................................... 40 \\n\\nWhy consider API Gateways instead of dire\", \"ct client-to-microservice communication ....................... 41 \\n\\nWhat is the API Gateway pattern\", \"? ..................................................................................................\", \"........................... 42 \\n\\nMain features in the API Gateway pattern ..........................\", \"................................................................................... 44 \\n\\nUsing produ\", \"cts with API Gateway features ......................................................................\", \"...................................... 45 \\n\\nDrawbacks of the API Gateway pattern ...................\", \"................................................................................................ 47 \", \"\\n\\nAdditional resources .............................................................................\", \".......................................................................... 48 \\n\\nCommunication in a m\", \"icroservice architecture ...........................................................................\", \"............................. 48 \\n\\nCommunication types .............................................\", \"....................................................................................................\", \"... 49 \\n\\nAsynchronous microservice integration enforces microservice\\u2019s autonomy ....................\", \"....................... 50 \\n\\nCommunication styles ..................................................\", \".................................................................................................. 5\", \"2 \\n\\nAsynchronous message-based communication .......................................................\", \"................................................ 54 \\n\\nSingle-receiver message-based communication ..\", \".............................................................................................. 55 \\n\\n\", \"Multiple-receivers message-based communication .....................................................\", \"..................................... 56 \\n\\nAsynchronous event-driven communication .................\", \"....................................................................................... 56 \\n\\nA note \", \"about messaging technologies for production systems ................................................\", \"................... 57 \\n\\nResiliently publishing to the event bus ...................................\", \"................................................................................ 58 \\n\\nii \\n\\nContents \", \"\\n\\n \\n\\fAdditional resources ..........................................................................\", \"............................................................................. 58 \\n\\nCreating, evolvin\", \"g, and versioning microservice APIs and contracts ..................................................\", \"............. 59 \\n\\nAdditional resources ............................................................\", \"........................................................................................... 59 \\n\\nMic\", \"roservices addressability and the service registry .................................................\", \"........................................... 60 \\n\\nAdditional resources ..............................\", \"....................................................................................................\", \"..................... 60 \\n\\nCreating composite UI based on microservices ............................\", \"........................................................................... 60 \\n\\nAdditional resource\", \"s ..................................................................................................\", \"..................................................... 62 \\n\\nResiliency and high availability in micro\", \"services ...........................................................................................\", \"........... 63 \\n\\nHealth management and diagnostics in microservices ................................\", \".................................................... 63 \\n\\nAdditional resources .....................\", \"....................................................................................................\", \".............................. 65 \\n\\nOrchestrate microservices and multi-container applications for h\", \"igh scalability and availability ....... 66 \\n\\nSoftware platforms for container clustering, orchestra\", \"tion, and scheduling ........................................... 68 \\n\\nUsing container-based orchestr\", \"ators in Microsoft Azure ...........................................................................\", \"..... 68 \\n\\nUsing Azure Kubernetes Service ..........................................................\", \"...................................................................... 69 \\n\\nDevelopment environment \", \"for Kubernetes .....................................................................................\", \"...................... 70 \\n\\nGetting started with Azure Kubernetes Service (AKS) ....................\", \"................................................................... 70 \\n\\nDeploy with Helm charts int\", \"o Kubernetes clusters ..............................................................................\", \"............... 71 \\n\\nAdditional resources ..........................................................\", \"............................................................................................. 71 \\n\\nD\", \"evelopment process for Docker-based applications ...................................................\", \".... 72 \\n\\nDevelopment environment for Docker apps ..................................................\", \"........................................................... 72 \\n\\nDevelopment tool choices: IDE or ed\", \"itor ...............................................................................................\", \"................. 72 \\n\\nAdditional resources ........................................................\", \"............................................................................................... 73 \\n\", \"\\n.NET languages and frameworks for Docker containers ...............................................\", \"........................................ 73 \\n\\nDevelopment workflow for Docker apps .................\", \"....................................................................................................\", \" 73 \\n\\nWorkflow for developing Docker container-based applications ..................................\", \"................................ 73 \\n\\nStep 1. Start coding and create your initial application or se\", \"rvice baseline ............................................. 75 \\n\\nStep 2. Create a Dockerfile relate\", \"d to an existing .NET base image ............................................................ 76 \\n\\nS\", \"tep 3. Create your custom Docker images and embed your application or service in them .......... 83 \", \"\\n\\nStep 4. Define your services in docker-compose.yml when building a multi-container Docker \\napplica\", \"tion ...............................................................................................\", \"........................................................................... 84 \\n\\nStep 5. Build and r\", \"un your Docker application .........................................................................\", \"........................... 87 \\n\\nStep 6. Test your Docker application using your local Docker host .\", \"........................................................... 89 \\n\\niii \\n\\nContents \\n\\n \\n\\fSimplified work\", \"flow when developing containers with Visual Studio .................................................\", \"....... 90 \\n\\nUsing PowerShell commands in a Dockerfile to set up Windows Containers ................\", \"......................... 91 \\n\\nDesigning and Developing Multi-Container and Microservice-Based .NET \", \"Applications\\n ......................................................................................\", \"........................................................... 93 \\n\\nDesign a microservice-oriented appl\", \"ication ............................................................................................\", \".................. 93 \\n\\nApplication specifications .................................................\", \"............................................................................................ 93 \\n\\nDe\", \"velopment team context .............................................................................\", \"............................................................ 94 \\n\\nChoosing an architecture .........\", \"....................................................................................................\", \"................................. 94 \\n\\nBenefits of a microservice-based solution ...................\", \".......................................................................................... 97 \\n\\nDown\", \"sides of a microservice-based solution .............................................................\", \".......................................... 98 \\n\\nExternal versus internal architecture and design pat\", \"terns............................................................................... 99 \\n\\nThe new wo\", \"rld: multiple architectural patterns and polyglot microservices ....................................\", \"...... 100 \\n\\nCreating a simple data-driven CRUD microservice .......................................\", \"........................................................ 102 \\n\\nDesigning a simple CRUD microservice \", \"....................................................................................................\", \"............ 102 \\n\\nImplementing a simple CRUD microservice with ASP.NET Core .......................\", \".......................................... 103 \\n\\nThe DB connection string and environment variables \", \"used by Docker containers ............................. 109 \\n\\nGenerating Swagger description metadat\", \"a from your ASP.NET Core Web API ................................... 111 \\n\\nDefining your multi-conta\", \"iner application with docker-compose.yml ......................................................... 1\", \"16 \\n\\nUse a database server running as a container ..................................................\", \"...................................................... 127 \\n\\nSQL Server running as a container with \", \"a microservice-related database .............................................. 128 \\n\\nSeeding with te\", \"st data on Web application startup .................................................................\", \"........................ 129 \\n\\nEF Core InMemory database versus SQL Server running as a container ..\", \"............................................... 132 \\n\\nUsing a Redis cache service running in a conta\", \"iner ......................................................................................... 132 \\n\", \"\\nImplementing event-based communication between microservices (integration events) .................\", \".. 133 \\n\\nUsing message brokers and service buses for production systems ............................\", \".............................. 134 \\n\\nIntegration events ............................................\", \"....................................................................................................\", \".......... 135 \\n\\nThe event bus .....................................................................\", \"............................................................................................. 136 \\n\\n\", \"Additional resources ...............................................................................\", \"...................................................................... 138 \\n\\nImplementing an event b\", \"us with RabbitMQ for the development or test environment ....................... 138 \\n\\nImplementing \", \"a simple publish method with RabbitMQ ..............................................................\", \"................. 139 \\n\\nImplementing the subscription code with the RabbitMQ API ...................\", \".................................................. 140 \\n\\nAdditional resources ......................\", \"....................................................................................................\", \"........................... 141 \\n\\niv \\n\\nContents \\n\\n \\n\\fSubscribing to events .........................\", \"....................................................................................................\", \"........................... 141 \\n\\nPublishing events through the event bus...........................\", \".................................................................................. 142 \\n\\nIdempotency\", \" in update message events ..........................................................................\", \".................................... 149 \\n\\nDeduplicating integration event messages ................\", \"......................................................................................... 150 \\n\\nTest\", \"ing ASP.NET Core services and web apps .............................................................\", \"........................................... 152 \\n\\nTesting in eShopOnContainers .....................\", \"....................................................................................................\", \"........ 155 \\n\\nImplement background tasks in microservices with IHostedService and the BackgroundSer\", \"vice class\\n ........................................................................................\", \"....................................................................................................\", \"........ 157 \\n\\nRegistering hosted services in your WebHost or Host .................................\", \".................................................. 159 \\n\\nThe IHostedService interface ..............\", \"....................................................................................................\", \"................... 159 \\n\\nImplementing IHostedService with a custom hosted service class deriving fr\", \"om the \\nBackgroundService base class................................................................\", \"................................................................... 160 \\n\\nAdditional resources .....\", \"....................................................................................................\", \"............................................ 163 \\n\\nImplement API Gateways with Ocelot ..............\", \"....................................................................................................\", \"...... 163 \\n\\nArchitect and design your API Gateways ................................................\", \".............................................................. 163 \\n\\nImplementing your API Gateways \", \"with Ocelot ........................................................................................\", \".......... 168 \\n\\nUsing Kubernetes Ingress plus Ocelot API Gateways .................................\", \"..................................................... 180 \\n\\nAdditional cross-cutting features in an \", \"Ocelot API Gateway ....................................................................... 181 \\n\\nTac\", \"kle Business Complexity in a Microservice with DDD and CQRS Patterns .............. 182 \\n\\nApply simp\", \"lified CQRS and DDD patterns in a microservice......................................................\", \"....................... 184 \\n\\nAdditional resources .................................................\", \"....................................................................................................\", \" 186 \\n\\nApply CQRS and CQS approaches in a DDD microservice in eShopOnContainers ....................\", \"............. 186 \\n\\nCQRS and DDD patterns are not top-level architectures ..........................\", \"..................................................... 187 \\n\\nImplement reads/queries in a CQRS micros\", \"ervice .............................................................................................\", \"... 188 \\n\\nUse ViewModels specifically made for client apps, independent from domain model constraint\", \"s\\n .................................................................................................\", \".............................................................................................. 189 \\n\", \"\\nUse Dapper as a micro ORM to perform queries ......................................................\", \"........................................ 189 \\n\\nDynamic versus static ViewModels ....................\", \"....................................................................................................\", \". 190 \\n\\nAdditional resources .......................................................................\", \".............................................................................. 193 \\n\\nDesign a DDD-or\", \"iented microservice ................................................................................\", \"......................................... 194 \\n\\nKeep the microservice context boundaries relatively \", \"small .......................................................................... 194 \\n\\nLayers in DDD\", \" microservices .....................................................................................\", \"................................................ 195 \\n\\nv \\n\\nContents \\n\\n \\n\\fDesign a microservice domai\", \"n model ............................................................................................\", \"............................ 199 \\n\\nThe Domain Entity pattern .......................................\", \".................................................................................................. 1\", \"99 \\n\\nImplement a microservice domain model with .NET ...............................................\", \"............................................. 204 \\n\\nDomain model structure in a custom .NET Standard\", \" Library ....................................................................... 204 \\n\\nStructure agg\", \"regates in a custom .NET Standard library ..........................................................\", \"..................... 205 \\n\\nImplement domain entities as POCO classes ..............................\", \"....................................................................... 206 \\n\\nEncapsulate data in th\", \"e Domain Entities ..................................................................................\", \"............................ 207 \\n\\nSeedwork (reusable base classes and interfaces for your domain mo\", \"del) .................................................. 210 \\n\\nThe custom Entity base class .........\", \"....................................................................................................\", \"........................ 211 \\n\\nRepository contracts (interfaces) in the domain model layer .........\", \"............................................................. 212 \\n\\nAdditional resources ...........\", \"....................................................................................................\", \"...................................... 213 \\n\\nImplement value objects ...............................\", \"....................................................................................................\", \"............... 213 \\n\\nImportant characteristics of value objects ...................................\", \"........................................................................ 214 \\n\\nValue object implemen\", \"tation in C# .......................................................................................\", \"................................. 215 \\n\\nHow to persist value objects in the database with EF Core 2.\", \"0 and later ................................................ 217 \\n\\nPersist value objects as owned en\", \"tity types in EF Core 2.0 and later ........................................................ 218 \\n\\nA\", \"dditional resources ................................................................................\", \"..................................................................... 221 \\n\\nUse enumeration classes \", \"instead of enum types ..............................................................................\", \"..................... 221 \\n\\nImplement an Enumeration base class ....................................\", \".............................................................................. 222 \\n\\nAdditional reso\", \"urces ..............................................................................................\", \"....................................................... 223 \\n\\nDesign validations in the domain model\", \" layer .............................................................................................\", \".......... 223 \\n\\nImplement validations in the domain model layer ...................................\", \"........................................................ 224 \\n\\nAdditional resources ................\", \"....................................................................................................\", \"................................. 225 \\n\\nClient-side validation (validation in the presentation layer\", \"s) ............................................................................ 226 \\n\\nAdditional res\", \"ources .............................................................................................\", \"........................................................ 227 \\n\\nDomain events: Design and implementat\", \"ion ................................................................................................\", \".......... 227 \\n\\nWhat is a domain event? ...........................................................\", \".................................................................................. 228 \\n\\nDomain even\", \"ts versus integration events .......................................................................\", \"..................................... 228 \\n\\nDomain events as a preferred way to trigger side effects\", \" across multiple aggregates within the \\nsame domain ................................................\", \"....................................................................................................\", \"............... 229 \\n\\nImplement domain events ......................................................\", \".................................................................................... 231 \\n\\nConclusio\", \"ns on domain events ................................................................................\", \"................................................. 237 \\n\\nvi \\n\\nContents \\n\\n \\n\\fAdditional resources ....\", \"....................................................................................................\", \"............................................. 238 \\n\\nDesign the infrastructure persistence layer ....\", \"....................................................................................................\", \"...... 238 \\n\\nThe Repository pattern ................................................................\", \"................................................................................ 238 \\n\\nAdditional re\", \"sources ............................................................................................\", \"......................................................... 243 \\n\\nImplement the infrastructure persist\", \"ence layer with Entity Framework Core ............................................ 243 \\n\\nIntroductio\", \"n to Entity Framework Core .........................................................................\", \"........................................ 244 \\n\\nInfrastructure in Entity Framework Core from a DDD pe\", \"rspective ............................................................. 244 \\n\\nImplement custom repos\", \"itories with Entity Framework Core .................................................................\", \"..... 246 \\n\\nEF DbContext and IUnitOfWork instance lifetime in your IoC container ...................\", \".............................. 248 \\n\\nThe repository instance lifetime in your IoC container ........\", \"........................................................................... 249 \\n\\nTable mapping ....\", \"....................................................................................................\", \"........................................................ 250 \\n\\nImplement the Query Specification pat\", \"tern ...............................................................................................\", \"......... 253 \\n\\nUse NoSQL databases as a persistence infrastructure ................................\", \"......................................................... 255 \\n\\nIntroduction to Azure Cosmos DB and \", \"the native Cosmos DB API ........................................................... 256 \\n\\nImplement\", \" .NET code targeting MongoDB and Azure Cosmos DB ...................................................\", \"....... 258 \\n\\nDesign the microservice application layer and Web API ................................\", \".................................................... 266 \\n\\nUse SOLID principles and Dependency Injec\", \"tion .............................................................................................. \", \"266 \\n\\nImplement the microservice application layer using the Web API ...............................\", \".................................. 267 \\n\\nUse Dependency Injection to inject infrastructure objects i\", \"nto your application layer ..................... 267 \\n\\nImplement the Command and Command Handler pat\", \"terns ....................................................................... 271 \\n\\nThe Command proc\", \"ess pipeline: how to trigger a command handler .....................................................\", \" 278 \\n\\nImplement the command process pipeline with a mediator pattern (MediatR) ....................\", \".............. 281 \\n\\nApply cross-cutting concerns when processing commands with the Behaviors in Med\", \"iatR .......... 287 \\n\\nImplement resilient applications .............................................\", \".......................................... 291 \\n\\nHandle partial failure ............................\", \"....................................................................................................\", \"......................... 292 \\n\\nStrategies to handle partial failure ...............................\", \"................................................................................................ 294\", \" \\n\\nAdditional resources ............................................................................\", \"......................................................................... 295 \\n\\nImplement retries wi\", \"th exponential backoff .............................................................................\", \"............................... 295 \\n\\nImplement resilient Entity Framework Core SQL connections.....\", \"..................................................................... 295 \\n\\nExecution strategies and\", \" explicit transactions using BeginTransaction and multiple DbContexts296 \\n\\nAdditional resources ....\", \"....................................................................................................\", \"............................................. 298 \\n\\nUse IHttpClientFactory to implement resilient HT\", \"TP requests ......................................................................... 298 \\n\\nvii \\n\\nCo\", \"ntents \\n\\n \\n\\fIssues with the original HttpClient class available in .NET ............................\", \"................................................. 298 \\n\\nBenefits of using IHttpClientFactory .......\", \"....................................................................................................\", \"............ 299 \\n\\nMultiple ways to use IHttpClientFactory .........................................\", \"...................................................................... 300 \\n\\nHow to use Typed Client\", \"s with IHttpClientFactory ..........................................................................\", \"................. 300 \\n\\nAdditional resources .......................................................\", \".............................................................................................. 304 \\n\", \"\\nImplement HTTP call retries with exponential backoff with IHttpClientFactory and Polly policies ...\", \" 304 \\n\\nAdd a jitter strategy to the retry policy ...................................................\", \".............................................................. 305 \\n\\nAdditional resources ..........\", \"....................................................................................................\", \"....................................... 306 \\n\\nImplement the Circuit Breaker pattern ................\", \"....................................................................................................\", \"... 306 \\n\\nImplement Circuit Breaker pattern with IHttpClientFactory and Polly ......................\", \"............................... 307 \\n\\nTest Http retries and circuit breakers in eShopOnContainers ..\", \".................................................................... 308 \\n\\nAdditional resources ....\", \"....................................................................................................\", \"............................................. 310 \\n\\nHealth monitoring ..............................\", \"....................................................................................................\", \"............................ 310 \\n\\nImplement health checks in ASP.NET Core services ................\", \"........................................................................ 311 \\n\\nUse watchdogs .......\", \"....................................................................................................\", \"..................................................... 315 \\n\\nHealth checks when using orchestrators .\", \"....................................................................................................\", \"......... 317 \\n\\nAdvanced monitoring: visualization, analysis, and alerts ...........................\", \".................................................... 317 \\n\\nAdditional resources ....................\", \"....................................................................................................\", \"............................. 318 \\n\\nMake secure .NET Microservices and Web Applications ............\", \"..................................... 319 \\n\\nImplement authentication in .NET microservices and web a\", \"pplications ...................................................... 319 \\n\\nAuthenticate with ASP.NET C\", \"ore Identity .......................................................................................\", \"...................... 320 \\n\\nAuthenticate with external providers ..................................\", \"................................................................................... 321 \\n\\nAuthentica\", \"te with bearer tokens ..............................................................................\", \"................................................ 323 \\n\\nAuthenticate with an OpenID Connect or OAuth \", \"2.0 Identity provider ................................................... 324 \\n\\nIssue security token\", \"s from an ASP.NET Core service .....................................................................\", \".................. 325 \\n\\nConsume security tokens ...................................................\", \"......................................................................................... 326 \\n\\nAddi\", \"tional resources ...................................................................................\", \"....................................................................... 327 \\n\\nAbout authorization in\", \" .NET microservices and web applications ...........................................................\", \"....... 327 \\n\\nImplement role-based authorization ...................................................\", \".................................................................. 328 \\n\\nImplement policy-based auth\", \"orization ..........................................................................................\", \"....................... 329 \\n\\nAuthorization and minimal apis .......................................\", \"........................................................................................ 330 \\n\\nAddit\", \"ional resources ....................................................................................\", \"................................................................. 330 \\n\\nviii \\n\\nContents \\n\\n \\n\\fStore a\", \"pplication secrets safely during development .......................................................\", \"................................... 330 \\n\\nStore secrets in environment variables ...................\", \".............................................................................................. 331 \\n\", \"\\nStore secrets with the ASP.NET Core Secret Manager ................................................\", \".................................... 331 \\n\\nUse Azure Key Vault to protect secrets at production time\", \" .............................................................................. 332 \\n\\nAdditional res\", \"ources .............................................................................................\", \"........................................................ 333 \\n\\n.NET Microservices Architecture key t\", \"akeaways .............................................................. 334 \\n\\nix \\n\\nContents \\n\\n \\n\\fCHA\", \"PTER  1 \\n\\nIntroduction to Containers \\nand Docker \\n\\nContainerization is an approach to software devel\", \"opment in which an application or service, its \\ndependencies, and its configuration (abstracted as d\", \"eployment manifest files) are packaged together \\nas a container image. The containerized application\", \" can be tested as a unit and deployed as a \\ncontainer image instance to the host operating system (O\", \"S). \\n\\nJust as shipping containers allow goods to be transported by ship, train, or truck regardless \", \"of the \\ncargo inside, software containers act as a standard unit of software deployment that can con\", \"tain \\ndifferent code and dependencies. Containerizing software this way enables developers and IT \\np\", \"rofessionals to deploy them across environments with little or no modification. \\n\\nContainers also is\", \"olate applications from each other on a shared OS. Containerized applications run \\non top of a conta\", \"iner host that in turn runs on the OS (Linux or Windows). Containers therefore have a \\nsignificantly\", \" smaller footprint than virtual machine (VM) images. \\n\\nEach container can run a whole web applicatio\", \"n or a service, as shown in Figure 2-1. In this example, \\nDocker host is a container host, and App1,\", \" App2, Svc 1, and Svc 2 are containerized applications or \\nservices. \\n\\nFigure 2-1. Multiple containe\", \"rs running on a container host \\n\\n1 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n \\n\\fAnot\", \"her benefit of containerization is scalability. You can scale out quickly by creating new containers\", \" \\nfor short-term tasks. From an application point of view, instantiating an image (creating a contai\", \"ner) is \\nsimilar to instantiating a process like a service or a web app. For reliability, however, w\", \"hen you run \\nmultiple instances of the same image across multiple host servers, you typically want e\", \"ach container \\n(image instance) to run in a different host server or VM in different fault domains. \", \"\\n\\nIn short, containers offer the benefits of isolation, portability, agility, scalability, and contr\", \"ol across the \\nwhole application lifecycle workflow. The most important benefit is the environment\\u2019s\", \" isolation \\nprovided between Dev and Ops. \\n\\nWhat is Docker? \\n\\nDocker is an open-source project for a\", \"utomating the deployment of applications as portable, self-\\nsufficient containers that can run on th\", \"e cloud or on-premises. Docker is also a company that \\npromotes and evolves this technology, working\", \" in collaboration with cloud, Linux, and Windows \\nvendors, including Microsoft. \\n\\nFigure 2-2. Docker\", \" deploys containers at all layers of the hybrid cloud. \\n\\nDocker containers can run anywhere, on-prem\", \"ises in the customer datacenter, in an external service \\nprovider or in the cloud, on Azure. Docker \", \"image containers can run natively on Linux and Windows. \\nHowever, Windows images can run only on Win\", \"dows hosts and Linux images can run on Linux hosts \\nand Windows hosts (using a Hyper-V Linux VM, so \", \"far), where host means a server or a VM. \\n\\nDevelopers can use development environments on Windows, L\", \"inux, or macOS. On the development \\ncomputer, the developer runs a Docker host where Docker images a\", \"re deployed, including the app \\nand its dependencies. Developers who work on Linux or on macOS use a\", \" Docker host that is Linux \\nbased, and they can create images only for Linux containers. (Developers\", \" working on macOS can edit \\ncode or run the Docker CLI from macOS, but as of the time of this writin\", \"g, containers don\\u2019t run \\n\\n2 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n \\n\\fdirectly on\", \" macOS.) Developers who work on Windows can create images for either Linux or Windows \\nContainers. \\n\", \"\\nTo host containers in development environments and provide additional developer tools, Docker \\nship\", \"s Docker Desktop for Windows or for macOS. These products install the necessary VM (the Docker \\nhost\", \") to host the containers. \\n\\nTo run Windows Containers, there are two types of runtimes: \\n\\n\\u2022  Windows\", \" Server Containers provide application isolation through process and namespace \\n\\nisolation technolog\", \"y. A Windows Server Container shares a kernel with the container host and \\nwith all containers runni\", \"ng on the host. \\n\\n\\u2022 \\n\\nHyper-V Containers expand on the isolation provided by Windows Server Containe\", \"rs by \\nrunning each container in a highly optimized virtual machine. In this configuration, the kern\", \"el \\nof the container host isn\\u2019t shared with the Hyper-V Containers, providing better isolation. \\n\\nTh\", \"e images for these containers are created the same way and function the same. The difference is in \\n\", \"how the container is created from the image running a Hyper-V Container requires an extra \\nparameter\", \". For details, see Hyper-V Containers. \\n\\nComparing Docker containers with virtual machines \\n\\nFigure \", \"2-3 shows a comparison between VMs and Docker containers. \\n\\nVirtual Machines \\n\\nDocker Containers \\n\\n3\", \" \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n \\n \\n\\fVirtual Machines \\n\\nDocker Containers\", \" \\n\\nVirtual machines include the application, the \\nrequired libraries or binaries, and a full guest \\n\", \"operating system. Full virtualization requires \\nmore resources than containerization. \\n\\nContainers i\", \"nclude the application and all its \\ndependencies. However, they share the OS kernel \\nwith other cont\", \"ainers, running as isolated \\nprocesses in user space on the host operating \\nsystem. (Except in Hyper\", \"-V containers, where \\neach container runs inside of a special virtual \\nmachine per container.) \\n\\nFig\", \"ure 2-3. Comparison of traditional virtual machines to Docker containers \\n\\nFor VMs, there are three \", \"base layers in the host server, from the bottom-up: infrastructure, Host \\nOperating System and a Hyp\", \"ervisor and on top of all that each VM has its own OS and all necessary \\nlibraries. For Docker, the \", \"host server only has the infrastructure and the OS and on top of that, the \\ncontainer engine, that k\", \"eeps container isolated but sharing the base OS services. \\n\\nBecause containers require far fewer res\", \"ources (for example, they don\\u2019t need a full OS), they\\u2019re easy to \\ndeploy and they start fast. This a\", \"llows you to have higher density, meaning that it allows you to run \\nmore services on the same hardw\", \"are unit, thereby reducing costs. \\n\\nAs a side effect of running on the same kernel, you get less iso\", \"lation than VMs. \\n\\nThe main goal of an image is that it makes the environment (dependencies) the sam\", \"e across different \\ndeployments. This means that you can debug it on your machine and then deploy it\", \" to another \\nmachine with the same environment guaranteed. \\n\\nA container image is a way to package a\", \"n app or service and deploy it in a reliable and reproducible \\nway. You could say that Docker isn\\u2019t \", \"only a technology but also a philosophy and a process. \\n\\nWhen using Docker, you won\\u2019t hear developer\", \"s say, \\u201cIt works on my machine, why not in production?\\u201d \\nThey can simply say, \\u201cIt runs on Docker\\u201d, b\", \"ecause the packaged Docker application can be executed \\non any supported Docker environment, and it \", \"runs the way it was intended to on all deployment \\ntargets (such as Dev, QA, staging, and production\", \"). \\n\\nA simple analogy \\n\\nPerhaps a simple analogy can help getting the grasp of the core concept of D\", \"ocker. \\n\\nLet\\u2019s go back in time to the 1950s for a moment. There were no word processors, and the \\nph\", \"otocopiers were used everywhere (kind of). \\n\\nImagine you\\u2019re responsible for quickly issuing batches \", \"of letters as required, to mail them to \\ncustomers, using real paper and envelopes, to be delivered \", \"physically to each customer\\u2019s address \\n(there was no email back then). \\n\\nAt some point, you realize \", \"the letters are just a composition of a large set of paragraphs, which are \\npicked and arranged as n\", \"eeded, according to the purpose of the letter, so you devise a system to \\nissue letters quickly, exp\", \"ecting to get a hefty raise. \\n\\nThe system is simple: \\n\\n1. \\n\\nYou begin with a deck of transparent she\", \"ets containing one paragraph each. \\n\\n4 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n\\f2.\", \" \\n\\n3. \\n\\nTo issue a set of letters, you pick the sheets with the paragraphs you need, then you stack \", \"and \\nalign them so they look and read fine. \\n\\nFinally, you place the set in the photocopier and pres\", \"s start to produce as many letters as \\nrequired. \\n\\nSo, simplifying, that\\u2019s the core idea of Docker. \", \"\\n\\nIn Docker, each layer is the resulting set of changes that happen to the filesystem after executin\", \"g a \\ncommand, such as, installing a program. \\n\\nSo, when you \\u201clook\\u201d at the filesystem after the layer\", \" has been copied, you see all the files, included in \\nthe layer when the program was installed. \\n\\nYo\", \"u can think of an image as an auxiliary read-only hard disk ready to be installed in a \\u201ccomputer\\u201d \\nw\", \"here the operating system is already installed. \\n\\nSimilarly, you can think of a container as the \\u201cco\", \"mputer\\u201d with the image hard disk installed. The \\ncontainer, just like a computer, can be powered on \", \"or off. \\n\\nDocker terminology \\n\\nThis section lists terms and definitions you should be familiar with \", \"before getting deeper into Docker. \\nFor further definitions, see the extensive glossary provided by \", \"Docker. \\n\\nContainer image: A package with all the dependencies and information needed to create a co\", \"ntainer. \\nAn image includes all the dependencies (such as frameworks) plus deployment and execution \", \"\\nconfiguration to be used by a container runtime. Usually, an image derives from multiple base image\", \"s \\nthat are layers stacked on top of each other to form the container\\u2019s filesystem. An image is immu\", \"table \\nonce it has been created. \\n\\nDockerfile: A text file that contains instructions for building a\", \" Docker image. It\\u2019s like a batch script, \\nthe first line states the base image to begin with and the\", \"n follow the instructions to install required \\nprograms, copy files, and so on, until you get the wo\", \"rking environment you need. \\n\\nBuild: The action of building a container image based on the informati\", \"on and context provided by its \\nDockerfile, plus additional files in the folder where the image is b\", \"uilt. You can build images with the \\nfollowing Docker command: \\n\\ndocker build \\n\\nContainer: An instan\", \"ce of a Docker image. A container represents the execution of a single \\napplication, process, or ser\", \"vice. It consists of the contents of a Docker image, an execution \\nenvironment, and a standard set o\", \"f instructions. When scaling a service, you create multiple instances \\nof a container from the same \", \"image. Or a batch job can create multiple containers from the same \\nimage, passing different paramet\", \"ers to each instance. \\n\\nVolumes: Offer a writable filesystem that the container can use. Since image\", \"s are read-only but most \\nprograms need to write to the filesystem, volumes add a writable layer, on\", \" top of the container image, \\nso the programs have access to a writable filesystem. The program does\", \"n\\u2019t know it\\u2019s accessing a \\n\\n5 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n\\flayered fil\", \"esystem, it\\u2019s just the filesystem as usual. Volumes live in the host system and are managed \\nby Dock\", \"er. \\n\\nTag: A mark or label you can apply to images so that different images or versions of the same \", \"image \\n(depending on the version number or the target environment) can be identified. \\n\\nMulti-stage \", \"Build: Is a feature, since Docker 17.05 or higher, that helps to reduce the size of the final \\nimage\", \"s. For example, a large base image, containing the SDK can be used for compiling and \\npublishing and\", \" then a small runtime-only base image can be used to host the application. \\n\\nRepository (repo): A co\", \"llection of related Docker images, labeled with a tag that indicates the image \\nversion. Some repos \", \"contain multiple variants of a specific image, such as an image containing SDKs \\n(heavier), an image\", \" containing only runtimes (lighter), etc. Those variants can be marked with tags. A \\nsingle repo can\", \" contain platform variants, such as a Linux image and a Windows image. \\n\\nRegistry: A service that pr\", \"ovides access to repositories. The default registry for most public images is \\nDocker Hub (owned by \", \"Docker as an organization). A registry usually contains repositories from \\nmultiple teams. Companies\", \" often have private registries to store and manage images they\\u2019ve created. \\nAzure Container Registry\", \" is another example. \\n\\nMulti-arch image: For multi-architecture (or multi-platform), it\\u2019s a Docker f\", \"eature that simplifies the \\nselection of the appropriate image, according to the platform where Dock\", \"er is running. For example, \\nwhen a Dockerfile requests a base image FROM mcr.microsoft.com/dotnet/s\", \"dk:7.0 from the \\nregistry, it actually gets 7.0-nanoserver-ltsc2022, 7.0-nanoserver-1809 or 7.0-bull\", \"seye-slim, \\ndepending on the operating system and version where Docker is running. \\n\\nDocker Hub: A p\", \"ublic registry to upload images and work with them. Docker Hub provides Docker \\nimage hosting, publi\", \"c or private registries, build triggers and web hooks, and integration with GitHub \\nand Bitbucket. \\n\", \"\\nAzure Container Registry: A public resource for working with Docker images and its components in \\nA\", \"zure. This provides a registry that\\u2019s close to your deployments in Azure and that gives you control \", \"\\nover access, making it possible to use your Azure Active Directory groups and permissions. \\n\\nDocker\", \" Trusted Registry (DTR): A Docker registry service (from Docker) that can be installed on-\\npremises \", \"so it lives within the organization\\u2019s datacenter and network. It\\u2019s convenient for private \\nimages th\", \"at should be managed within the enterprise. Docker Trusted Registry is included as part of \\nthe Dock\", \"er Datacenter product. \\n\\nDocker Desktop: Development tools for Windows and macOS for building, runni\", \"ng, and testing \\ncontainers locally. Docker Desktop for Windows provides development environments fo\", \"r both Linux \\nand Windows Containers. The Linux Docker host on Windows is based on a Hyper-V virtual\", \" machine. \\nThe host for Windows Containers is directly based on Windows. Docker Desktop for Mac is b\", \"ased on \\nthe Apple Hypervisor framework and the xhyve hypervisor, which provides a Linux Docker host\", \" virtual \\nmachine on macOS. Docker Desktop for Windows and for Mac replaces Docker Toolbox, which wa\", \"s \\nbased on Oracle VirtualBox. \\n\\nCompose: A command-line tool and YAML file format with metadata for\", \" defining and running multi-\\ncontainer applications. You define a single application based on multip\", \"le images with one or more \\n.yml files that can override values depending on the environment. After \", \"you\\u2019ve created the definitions, \\n\\n6 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n\\fyou c\", \"an deploy the whole multi-container application with a single command (docker-compose up) \\nthat crea\", \"tes a container per image on the Docker host. \\n\\nCluster: A collection of Docker hosts exposed as if \", \"it were a single virtual Docker host, so that the \\napplication can scale to multiple instances of th\", \"e services spread across multiple hosts within the \\ncluster. Docker clusters can be created with Kub\", \"ernetes, Azure Service Fabric, Docker Swarm and \\nMesosphere DC/OS. \\n\\nOrchestrator: A tool that simpl\", \"ifies the management of clusters and Docker hosts. Orchestrators \\nenable you to manage their images,\", \" containers, and hosts through a command-line interface (CLI) or a \\ngraphical UI. You can manage con\", \"tainer networking, configurations, load balancing, service discovery, \\nhigh availability, Docker hos\", \"t configuration, and more. An orchestrator is responsible for running, \\ndistributing, scaling, and h\", \"ealing workloads across a collection of nodes. Typically, orchestrator \\nproducts are the same produc\", \"ts that provide cluster infrastructure, like Kubernetes and Azure Service \\nFabric, among other offer\", \"ings in the market. \\n\\nDocker containers, images, and registries \\n\\nWhen using Docker, a developer cre\", \"ates an app or service and packages it and its dependencies into \\na container image. An image is a s\", \"tatic representation of the app or service and its configuration and \\ndependencies. \\n\\nTo run the app\", \" or service, the app\\u2019s image is instantiated to create a container, which will be running \\non the Do\", \"cker host. Containers are initially tested in a development environment or PC. \\n\\nDevelopers should s\", \"tore images in a registry, which acts as a library of images and is needed when \\ndeploying to produc\", \"tion orchestrators. Docker maintains a public registry via Docker Hub; other \\nvendors provide regist\", \"ries for different collections of images, including Azure Container Registry. \\nAlternatively, enterp\", \"rises can have a private registry on-premises for their own Docker images. \\n\\nFigure 2-4 shows how im\", \"ages and registries in Docker relate to other components. It also shows the \\nmultiple registry offer\", \"ings from vendors. \\n\\n7 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n \\n \\n\\fFigure 2-4. Taxono\", \"my of Docker terms and concepts \\n\\nThe registry is like a bookshelf where images are stored and avail\", \"able to be pulled for building \\ncontainers to run services or web apps. There are private Docker reg\", \"istries on-premises and on the \\npublic cloud. Docker Hub is a public registry maintained by Docker, \", \"along the Docker Trusted Registry \\nan enterprise-grade solution, Azure offers the Azure Container Re\", \"gistry. AWS, Google, and others also \\nhave container registries. \\n\\nPutting images in a registry lets\", \" you store static and immutable application bits, including all their \\ndependencies at a framework l\", \"evel. Those images can then be versioned and deployed in multiple \\nenvironments and therefore provid\", \"e a consistent deployment unit. \\n\\nPrivate image registries, either hosted on-premises or in the clou\", \"d, are recommended when: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nYour images must not be shared publicly due to confidentiality. \\n\", \"\\nYou want to have minimum network latency between your images and your chosen \\ndeployment environmen\", \"t. For example, if your production environment is Azure cloud, you \\nprobably want to store your imag\", \"es in Azure Container Registry so that network latency will \\nbe minimal. In a similar way, if your p\", \"roduction environment is on-premises, you might want \\nto have an on-premises Docker Trusted Registry\", \" available within the same local network. \\n\\n8 \\n\\nCHAPTER 1 | Introduction to Containers and Docker \\n\\n\", \" \\n \\n \\n\\fCHAPTER  2 \\n\\nChoosing Between .NET \\nand .NET Framework for \\nDocker Containers \\n\\nThere are two\", \" supported frameworks for building server-side containerized Docker applications with \\n.NET: .NET Fr\", \"amework and .NET 7. They share many .NET platform components, and you can share \\ncode across the two\", \". However, there are fundamental differences between them, and which \\nframework you use will depend \", \"on what you want to accomplish. This section provides guidance on \\nwhen to choose each framework. \\n\\n\", \"General guidance \\n\\nThis section provides a summary of when to choose .NET 7 or .NET Framework. We pr\", \"ovide more \\ndetails about these choices in the sections that follow. \\n\\nUse .NET 7, with Linux or Win\", \"dows Containers, for your containerized Docker server application when: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nYou have cross\", \"-platform needs. For example, you want to use both Linux and Windows \\nContainers. \\n\\nYour application\", \" architecture is based on microservices. \\n\\nYou need to start containers fast and want a small footpr\", \"int per container to achieve better \\ndensity or more containers per hardware unit in order to lower \", \"your costs. \\n\\nIn short, when you create new containerized .NET applications, you should consider .NE\", \"T 7 as the \\ndefault choice. It has many benefits and fits best with the containers philosophy and st\", \"yle of working. \\n\\nAn extra benefit of using .NET 7 is that you can run side-by-side .NET versions fo\", \"r applications within \\nthe same machine. This benefit is more important for servers or VMs that do n\", \"ot use containers, \\nbecause containers isolate the versions of .NET that the app needs. (As long as \", \"they are compatible \\nwith the underlying OS.) \\n\\nUse .NET Framework for your containerized Docker ser\", \"ver application when: \\n\\n\\u2022 \\n\\nYour application currently uses .NET Framework and has strong dependenci\", \"es on Windows. \\n\\n9 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n\\n \\n\", \" \\n\\f\\u2022 \\n\\n\\u2022 \\n\\nYou need to use Windows APIs that are not supported by .NET 7. \\n\\nYou need to use third-pa\", \"rty .NET libraries or NuGet packages that are not available for .NET 7. \\n\\nUsing .NET Framework on Do\", \"cker can improve your deployment experiences by minimizing \\ndeployment issues. This \\u201clift and shift\\u201d\", \" scenario is important for containerizing legacy applications that \\nwere originally developed with t\", \"he traditional .NET Framework, like ASP.NET WebForms, MVC web \\napps, or WCF (Windows Communication F\", \"oundation) services. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nE-book: Modernize existing .NET Framework appl\", \"ications with Azure and Windows \\nContainers \\nhttps://aka.ms/liftandshiftwithcontainersebook \\n\\nSample\", \" apps: Modernization of legacy ASP.NET web apps by using Windows Containers \\nhttps://aka.ms/eshopmod\", \"ernizing \\n\\nWhen to choose .NET for Docker containers \\n\\nThe modularity and lightweight nature of .NET\", \" 7 makes it perfect for containers. When you deploy \\nand start a container, its image is far smaller\", \" with .NET 7 than with .NET Framework. In contrast, to use \\n.NET Framework for a container, you must\", \" base your image on the Windows Server Core image, which \\nis a lot heavier than the Windows Nano Ser\", \"ver or Linux images that you use for .NET 7. \\n\\nAdditionally, .NET 7 is cross-platform, so you can de\", \"ploy server apps with Linux or Windows container \\nimages. However, if you are using the traditional \", \".NET Framework, you can only deploy images based \\non Windows Server Core. \\n\\nThe following is a more \", \"detailed explanation of why to choose .NET 7. \\n\\nDeveloping and deploying cross platform \\n\\nClearly, i\", \"f your goal is to have an application (web app or service) that can run on multiple platforms \\nsuppo\", \"rted by Docker (Linux and Windows), the right choice is .NET 7, because .NET Framework only \\nsupport\", \"s Windows. \\n\\n.NET 7 also supports macOS as a development platform. However, when you deploy containe\", \"rs to a \\nDocker host, that host must (currently) be based on Linux or Windows. For example, in a dev\", \"elopment \\nenvironment, you could use a Linux VM running on a Mac. \\n\\nVisual Studio provides an integr\", \"ated development environment (IDE) for Windows and supports \\nDocker development. \\n\\nVisual Studio for\", \" Mac is an IDE, evolution of Xamarin Studio, that runs on macOS and supports \\nDocker-based applicati\", \"on development. This tool should be the preferred choice for developers \\nworking in Mac machines who\", \" also want to use a powerful IDE. \\n\\nYou can also use Visual Studio Code on macOS, Linux, and Windows\", \". Visual Studio Code fully \\nsupports .NET 7, including IntelliSense and debugging. Because VS Code i\", \"s a lightweight editor, you \\n\\n10 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker C\", \"ontainers \\n\\n \\n \\n\\fcan use it to develop containerized apps on the machine in conjunction with the Doc\", \"ker CLI and the \\n.NET CLI. You can also target .NET 7 with most third-party editors like Sublime, Em\", \"acs, vi, and the \\nopen-source OmniSharp project, which also provides IntelliSense support. \\n\\nIn addi\", \"tion to the IDEs and editors, you can use the .NET CLI for all supported platforms. \\n\\nUsing containe\", \"rs for new (\\u201cgreen-field\\u201d) projects \\n\\nContainers are commonly used in conjunction with a microservic\", \"es architecture, although they can \\nalso be used to containerize web apps or services that follow an\", \"y architectural pattern. You can use \\n.NET Framework on Windows Containers, but the modularity and l\", \"ightweight nature of .NET 7 makes \\nit perfect for containers and microservices architectures. When y\", \"ou create and deploy a container, its \\nimage is far smaller with .NET 7 than with .NET Framework. \\n\\n\", \"Create and deploy microservices on containers \\n\\nYou could use the traditional .NET Framework for bui\", \"lding microservices-based applications (without \\ncontainers) by using plain processes. That way, bec\", \"ause the .NET Framework is already installed and \\nshared across processes, processes are light and f\", \"ast to start. However, if you are using containers, the \\nimage for the traditional .NET Framework is\", \" also based on Windows Server Core and that makes it too \\nheavy for a microservices-on-containers ap\", \"proach. However, teams have been looking for \\nopportunities to improve the experience for .NET Frame\", \"work users as well. Recently, size of the \\nWindows Server Core container images have been reduced to\", \" >40% smaller. \\n\\nOn the other hand, .NET 7 is the best candidate if you\\u2019re embracing a microservices\", \"-oriented system \\nthat is based on containers because .NET 7 is lightweight. In addition, its relate\", \"d container images, for \\neither Linux or Windows Nano Server, are lean and small, making containers \", \"light and fast to start. \\n\\nA microservice is meant to be as small as possible: to be light when spin\", \"ning up, to have a small \\nfootprint, to have a small Bounded Context (check DDD, Domain-Driven Desig\", \"n), to represent a small \\narea of concerns, and to be able to start and stop fast. For those require\", \"ments, you will want to use \\nsmall and fast-to-instantiate container images like the .NET 7 containe\", \"r image. \\n\\nA microservices architecture also allows you to mix technologies across a service boundar\", \"y. This \\napproach enables a gradual migration to .NET 7 for new microservices that work in conjuncti\", \"on with \\nother microservices or with services developed with Node.js, Python, Java, GoLang, or other\", \" \\ntechnologies. \\n\\nDeploying high density in scalable systems \\n\\nWhen your container-based system need\", \"s the best possible density, granularity, and performance, \\n.NET and ASP.NET Core are your best opti\", \"ons. ASP.NET Core is up to 10 times faster than ASP.NET in \\nthe traditional .NET Framework, and it l\", \"eads to other popular industry technologies for microservices, \\nsuch as Java servlets, Go, and Node.\", \"js. \\n\\nThis approach is especially relevant for microservices architectures, where you could have hun\", \"dreds of \\nmicroservices (containers) running. With ASP.NET Core images (based on the .NET runtime) o\", \"n Linux \\nor Windows Nano, you can run your system with a much lower number of servers or VMs, ultima\", \"tely \\nsaving costs in infrastructure and hosting. \\n\\n11 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET \", \"Framework for Docker Containers \\n\\n \\n \\n\\fWhen to choose .NET Framework for Docker \\ncontainers \\n\\nWhile \", \".NET 7 offers significant benefits for new applications and application patterns, .NET Framework \\nwi\", \"ll continue to be a good choice for many existing scenarios. \\n\\nMigrating existing applications direc\", \"tly to a Windows Server container \\n\\nYou might want to use Docker containers just to simplify deploym\", \"ent, even if you are not creating \\nmicroservices. For example, perhaps you want to improve your DevO\", \"ps workflow with Docker\\u2014\\ncontainers can give you better isolated test environments and can also elim\", \"inate deployment issues \\ncaused by missing dependencies when you move to a production environment. I\", \"n cases like these, \\neven if you are deploying a monolithic application, it makes sense to use Docke\", \"r and Windows \\nContainers for your current .NET Framework applications. \\n\\nIn most cases for this sce\", \"nario, you will not need to migrate your existing applications to .NET 7; you \\ncan use Docker contai\", \"ners that include the traditional .NET Framework. However, a recommended \\napproach is to use .NET 7 \", \"as you extend an existing application, such as writing a new service in \\nASP.NET Core. \\n\\nUsing third\", \"-party .NET libraries or NuGet packages not available for \\n.NET 7 \\n\\nThird-party libraries are quickl\", \"y embracing .NET Standard, which enables code sharing across all .NET \\nflavors, including .NET 7. Wi\", \"th .NET Standard 2.0 and later, the API surface compatibility across \\ndifferent frameworks has becom\", \"e significantly larger. Even more, .NET Core 2.x and newer applications \\ncan also directly reference\", \" existing .NET Framework libraries (see .NET Framework 4.6.1 supporting \\n.NET Standard 2.0). \\n\\nIn ad\", \"dition, the Windows Compatibility Pack extends the API surface available for .NET Standard 2.0 \\non W\", \"indows. This pack allows recompiling most existing code to .NET Standard 2.x with little or no \\nmodi\", \"fication, to run on Windows. \\n\\nHowever, even with that exceptional progression since .NET Standard 2\", \".0 and .NET Core 2.1 or later, \\nthere might be cases where certain NuGet packages need Windows to ru\", \"n and might not support \\n.NET Core or later. If those packages are critical for your application, th\", \"en you will need to use .NET \\nFramework on Windows Containers. \\n\\nUsing .NET technologies not availab\", \"le for .NET 7 \\n\\nSome .NET Framework technologies aren\\u2019t available in .NET 7. Some of them might beco\", \"me available \\nin later releases, but others don\\u2019t fit the new application patterns targeted by .NET \", \"Core and might \\nnever be available. \\n\\nThe following list shows most of the technologies that aren\\u2019t \", \"available in .NET 7: \\n\\n12 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containe\", \"rs \\n\\n \\n \\n\\f\\u2022 \\n\\nASP.NET Web Forms. This technology is only available on .NET Framework. Currently ther\", \"e are \\nno plans to bring ASP.NET Web Forms to .NET or later. \\n\\n\\u2022  Workflow-related services. Windows\", \" Workflow Foundation (WF), Workflow Services (WCF + \\nWF in a single service), and WCF Data Services \", \"(formerly known as ADO.NET Data Services) \\nare only available on .NET Framework. There are currently\", \" no plans to bring them to .NET 7. \\n\\nIn addition to the technologies listed in the official .NET roa\", \"dmap, other features might be ported to \\nthe new unified .NET platform. You might consider participa\", \"ting in the discussions on GitHub so that \\nyour voice can be heard. And if you think something is mi\", \"ssing, file a new issue in the dotnet/runtime \\nGitHub repository. \\n\\nUsing a platform or API that doe\", \"sn\\u2019t support .NET 7 \\n\\nSome Microsoft and third-party platforms don\\u2019t support .NET 7. For example, so\", \"me Azure services \\nprovide an SDK that isn\\u2019t yet available for consumption on .NET 7 yet. Most Azure\", \" SDK should \\neventually be ported to .NET 7/.NET Standard, but some might not for several reasons. Y\", \"ou can see \\nthe available Azure SDKs in the Azure SDK Latest Releases page. \\n\\nIn the meantime, if an\", \"y platform or service in Azure still doesn\\u2019t support .NET 7 with its client API, you \\ncan use the eq\", \"uivalent REST API from the Azure service or the client SDK on .NET Framework. \\n\\nPorting existing ASP\", \".NET application to .NET 7 \\n\\n.NET Core is a revolutionary step forward from .NET Framework. It offer\", \"s a host of advantages over \\n.NET Framework across the board from productivity to performance, and f\", \"rom cross-platform support \\nto developer satisfaction. If you are using .NET Framework and planning \", \"to migrate your application \\nto .NET Core or .NET 5+, see Porting Existing ASP.NET Apps to .NET Core\", \". \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n.NET fundamentals \\nhttps://learn.microsoft.com/dotnet/fundame\", \"ntals \\n\\nPorting Projects to .NET 5 \\nhttps://learn.microsoft.com/events/dotnetconf-2020/porting-proje\", \"cts-to-net-5 \\n\\n.NET on Docker Guide \\nhttps://learn.microsoft.com/dotnet/core/docker/introduction \\n\\nD\", \"ecision table: .NET implementations to use for \\nDocker \\n\\nThe following decision table summarizes whe\", \"ther to use .NET Framework or .NET 7. Remember that \\nfor Linux containers, you need Linux-based Dock\", \"er hosts (VMs or servers), and that for Windows \\nContainers, you need Windows Server-based Docker ho\", \"sts (VMs or servers). \\n\\n13 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Contain\", \"ers \\n\\n \\n \\n\\fImportant \\n\\nYour development machines will run one Docker host, either Linux or Windows. \", \"Related microservices \\nthat you want to run and test together in one solution will all need to run o\", \"n the same container \\nplatform. \\n\\nArchitecture / App Type \\n\\nLinux containers \\n\\nWindows Containers \\n\\n\", \"Microservices on containers \\n\\nMonolithic app \\n\\nBest-in-class performance and \\nscalability \\n\\n.NET 7 \\n\", \"\\n.NET 7 \\n\\n.NET 7 \\n\\nWindows Server legacy app (\\u201cbrown-\\nfield\\u201d) migration to containers \\n\\n\\u2013 \\n\\nNew cont\", \"ainer-based development \\n(\\u201cgreen-field\\u201d) \\n\\nASP.NET Core \\n\\n.NET 7 \\n\\n.NET 7 \\n\\nASP.NET 4 (MVC 5, Web AP\", \"I 2, and \\nWeb Forms) \\n\\n\\u2013 \\n\\nSignalR services \\n\\n.NET Core 2.1 or higher \\nversion \\n\\nWCF, WF, and other \", \"legacy \\nframeworks \\n\\nWCF in .NET Core (client \\nlibrary only) or CoreWCF \\n\\nConsumption of Azure servi\", \"ces \\n\\n.NET 7 \\n(eventually most Azure \\nservices will provide client \\nSDKs for .NET 7) \\n\\n.NET 7 \\n\\n.NET\", \" Framework \\n.NET 7 \\n\\n.NET 7 \\n\\n.NET Framework \\n\\n.NET 7 \\n\\n.NET 7 (recommended) \\n.NET Framework \\n\\n.NET \", \"Framework \\n\\n.NET Framework \\n.NET Core 2.1 or higher \\nversion \\n\\n.NET Framework \\nWCF in .NET 7 (client\", \" library \\nonly) or CoreWCF \\n\\n.NET Framework \\n.NET 7 \\n(eventually most Azure \\nservices will provide c\", \"lient \\nSDKs for .NET 7) \\n\\nWhat OS to target with .NET containers \\n\\nGiven the diversity of operating \", \"systems supported by Docker and the differences between .NET \\nFramework and .NET 7, you should targe\", \"t a specific OS and specific versions depending on the \\nframework you are using. \\n\\nFor Windows, you \", \"can use Windows Server Core or Windows Nano Server. These Windows versions \\nprovide different charac\", \"teristics (IIS in Windows Server Core versus a self-hosted web server like \\nKestrel in Nano Server) \", \"that might be needed by .NET Framework or .NET 7, respectively. \\n\\nFor Linux, multiple distros are av\", \"ailable and supported in official .NET Docker images (like Debian). \\n\\n14 \\n\\nCHAPTER 2 | Choosing Betw\", \"een .NET and .NET Framework for Docker Containers \\n\\n \\n \\n\\fIn Figure 3-1, you can see the possible OS \", \"version depending on the .NET framework used. \\n\\nFigure 3-1. Operating systems to target depending on\", \" versions of the .NET framework \\n\\nWhen deploying legacy .NET Framework applications you have to targ\", \"et Windows Server Core, \\ncompatible with legacy apps and IIS, but it has a larger image. When deploy\", \"ing .NET 7 applications, \\nyou can target Windows Nano Server, which is cloud optimized, uses Kestrel\", \" and is smaller and starts \\nfaster. You can also target Linux, supporting Debian, Alpine, and others\", \". \\n\\nYou can also create your own Docker image in cases where you want to use a different Linux distr\", \"o or \\nwhere you want an image with versions not provided by Microsoft. For example, you might create\", \" an \\nimage with ASP.NET Core running on the traditional .NET Framework and Windows Server Core, whic\", \"h \\nis a not-so-common scenario for Docker. \\n\\nWhen you add the image name to your Dockerfile file, yo\", \"u can select the operating system and \\nversion depending on the tag you use, as in the following exa\", \"mples: \\n\\nImage \\n\\nComments \\n\\nmcr.microsoft.com/dotnet/runtime:7.0 \\n\\nmcr.microsoft.com/dotnet/aspnet:7\", \".0 \\n\\nmcr.microsoft.com/dotnet/aspnet:7.0-\\nbullseye-slim \\n\\n.NET 7 multi-architecture: Supports Linux \", \"and Windows \\nNano Server depending on the Docker host. \\n\\nASP.NET Core 7.0 multi-architecture: Suppor\", \"ts Linux and \\nWindows Nano Server depending on the Docker host. \\nThe aspnetcore image has a few opti\", \"mizations for \\nASP.NET Core. \\n\\n.NET 7 runtime-only on Linux Debian distro \\n\\nmcr.microsoft.com/dotnet\", \"/aspnet:7.0-\\nnanoserver-1809 \\n\\n.NET 7 runtime-only on Windows Nano Server (Windows \\nServer version 1\", \"809) \\n\\n15 \\n\\nCHAPTER 2 | Choosing Between .NET and .NET Framework for Docker Containers \\n\\n \\n \\n \\n\\fOffi\", \"cial .NET Docker images \\n\\nThe Official .NET Docker images are Docker images created and optimized by\", \" Microsoft. They\\u2019re \\npublicly available on Microsoft Artifact Registry. You can search over the cata\", \"log to find all .NET image \\nrepositories, for example .NET SDK repository. \\n\\nEach repository can con\", \"tain multiple images, depending on .NET versions, and depending on the OS \\nand versions (Linux Debia\", \"n, Linux Alpine, Windows Nano Server, Windows Server Core, and so on). \\nImage repositories provide e\", \"xtensive tagging to help you select not just a specific framework version, \\nbut also to choose an OS\", \" (Linux distribution or Windows version). \\n\\n.NET and Docker image optimizations for development vers\", \"us \\nproduction \\n\\nWhen building Docker images for developers, Microsoft focused on the following main\", \" scenarios: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nImages used to develop and build .NET apps. \\n\\nImages used to run .NET apps. \\n\\n\", \"Why multiple images? When developing, building, and running containerized applications, you usually \", \"\\nhave different priorities. By providing different images for these separate tasks, Microsoft helps \", \"\\noptimize the separate processes of developing, building, and deploying apps. \\n\\nDuring development a\", \"nd build \\n\\nDuring development, what is important is how fast you can iterate changes, and the abilit\", \"y to debug \\nthe changes. The size of the image isn\\u2019t as important as the ability to make changes to \", \"your code and \\nsee the changes quickly. Some tools and \\u201cbuild-agent containers\\u201d, use the development\", \" .NET image \\n(mcr.microsoft.com/dotnet/sdk:7.0) during development and build process. When building \", \"inside a \\nDocker container, the important aspects are the elements that are needed to compile your a\", \"pp. This \\nincludes the compiler and any other .NET dependencies. \\n\\nWhy is this type of build image i\", \"mportant? You don\\u2019t deploy this image to production. Instead, it\\u2019s an \\nimage that you use to build t\", \"he content you place into a production image. This image would be used \\nin your continuous integrati\", \"on (CI) environment or build environment when using Docker multi-stage \\nbuilds. \\n\\nIn production \\n\\nWh\", \"at is important in production is how fast you can deploy and start your containers based on a \\nprodu\", \"ction .NET image. Therefore, the runtime-only image based on \\nmcr.microsoft.com/dotnet/aspnet:7.0 is\", \" small so that it can travel quickly across the network from your \\nDocker registry to your Docker ho\", \"sts. The contents are ready to run, enabling the fastest time from \\nstarting the container to proces\", \"sing results. In the Docker model, there is no need for compilation \\nfrom C# code, as there\\u2019s when y\", \"ou run dotnet build or dotnet publish when using the build container. \\n\\n16 \\n\\nCHAPTER 2 | Choosing Be\", \"tween .NET and .NET Framework for Docker Containers \\n\\n \\n \\n\\fIn this optimized image, you put only the\", \" binaries and other content needed to run the application. \\nFor example, the content created by dotn\", \"et publish contains only the compiled .NET binaries, images, \\n.js, and .css files. Over time, you\\u2019ll\", \" see images that contain pre-jitted (the compilation from IL to native \\nthat occurs at run time) pac\", \"kages. \\n\\nAlthough there are multiple versions of the .NET and ASP.NET Core images, they all share on\", \"e or more \\nlayers, including the base layer. Therefore, the amount of disk space needed to store an \", \"image is \\nsmall; it consists only of the delta between your custom image and its base image. The res\", \"ult is that \\nit\\u2019s quick to pull the image from your registry. \\n\\nWhen you explore the .NET image repo\", \"sitories at Microsoft Artifact Registry, you\\u2019ll find multiple image \\nversions classified or marked w\", \"ith tags. These tags help to decide which one to use, depending on the \\nversion you need, like those\", \" in the following table: \\n\\nImage \\n\\nComments \\n\\nmcr.microsoft.com/dotnet/aspnet:7.0 \\n\\nmcr.microsoft.co\", \"m/dotnet/sdk:7.0 \\n\\nASP.NET Core, with runtime only and ASP.NET Core \\noptimizations, on Linux and Win\", \"dows (multi-arch) \\n\\n.NET 7, with SDKs included, on Linux and Windows \\n(multi-arch) \\n\\nYou can find al\", \"l the available docker images in dotnet-docker and also refer to the latest preview \\nreleases by usi\", \"ng nightly build mcr.microsoft.com/dotnet/nightly/* \\n\\n17 \\n\\nCHAPTER 2 | Choosing Between .NET and .NE\", \"T Framework for Docker Containers \\n\\n \\n \\n\\fCHAPTER  3 \\n\\nArchitecting container and \\nmicroservice-based\", \" \\napplications \\n\\nMicroservices offer great benefits but also raise huge new challenges. Microservice\", \" architecture patterns \\nare fundamental pillars when creating a microservice-based application. \\n\\nEa\", \"rlier in this guide, you learned basic concepts about containers and Docker. That information was \\nt\", \"he minimum you needed to get started with containers. Even though containers are enablers of, and \\na\", \" great fit for microservices, they aren\\u2019t mandatory for a microservice architecture. Many architectu\", \"ral \\nconcepts in this architecture section could be applied without containers. However, this guide \", \"focuses \\non the intersection of both due to the already introduced importance of containers. \\n\\nEnter\", \"prise applications can be complex and are often composed of multiple services instead of a \\nsingle s\", \"ervice-based application. For those cases, you need to understand other architectural \\napproaches, s\", \"uch as the microservices and certain Domain-Driven Design (DDD) patterns plus \\ncontainer orchestrati\", \"on concepts. Note that this chapter describes not just microservices on \\ncontainers, but any contain\", \"erized application, as well. \\n\\nContainer design principles \\n\\nIn the container model, a container ima\", \"ge instance represents a single process. By defining a \\ncontainer image as a process boundary, you c\", \"an create primitives that can be used to scale or batch \\nthe process. \\n\\nWhen you design a container \", \"image, you\\u2019ll see an ENTRYPOINT definition in the Dockerfile. This \\ndefinition defines the process w\", \"hose lifetime controls the lifetime of the container. When the process \\ncompletes, the container lif\", \"ecycle ends. Containers might represent long-running processes like web \\nservers, but can also repre\", \"sent short-lived processes like batch jobs, which formerly might have been \\nimplemented as Azure Web\", \"Jobs. \\n\\nIf the process fails, the container ends, and the orchestrator takes over. If the orchestrat\", \"or was \\nconfigured to keep five instances running and one fails, the orchestrator will create anothe\", \"r container \\ninstance to replace the failed process. In a batch job, the process is started with par\", \"ameters. When the \\nprocess completes, the work is complete. This guidance drills-down on orchestrato\", \"rs, later on. \\n\\n18 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fY\", \"ou might find a scenario where you want multiple processes running in a single container. For that \\n\", \"scenario, since there can be only one entry point per container, you could run a script within the \\n\", \"container that launches as many programs as needed. For example, you can use Supervisor or a \\nsimila\", \"r tool to take care of launching multiple processes inside a single container. However, even \\nthough\", \" you can find architectures that hold multiple processes per container, that approach isn\\u2019t very \\nco\", \"mmon. \\n\\nContainerizing monolithic applications \\n\\nYou might want to build a single, monolithically de\", \"ployed web application or service and deploy it as \\na container. The application itself might not be\", \" internally monolithic, but structured as several \\nlibraries, components, or even layers (applicatio\", \"n layer, domain layer, data-access layer, etc.). \\nExternally, however, it\\u2019s a single container\\u2014a sin\", \"gle process, a single web application, or a single \\nservice. \\n\\nTo manage this model, you deploy a si\", \"ngle container to represent the application. To increase \\ncapacity, you scale out, that is, just add\", \" more copies with a load balancer in front. The simplicity \\ncomes from managing a single deployment \", \"in a single container or VM. \\n\\nFigure 4-1. Example of the architecture of a containerized monolithic\", \" application \\n\\nYou can include multiple components, libraries, or internal layers in each container,\", \" as illustrated in \\nFigure 4-1. A monolithic containerized application has most of its functionality\", \" within a single \\ncontainer, with internal layers or libraries, and scales out by cloning the contai\", \"ner on multiple \\nservers/VMs. However, this monolithic pattern might conflict with the container pri\", \"nciple \\u201ca container \\ndoes one thing, and does it in one process\\u201d, but might be ok for some cases. \\n\\n\", \"The downside of this approach becomes evident if the application grows, requiring it to scale. If th\", \"e \\nentire application can scale, it isn\\u2019t really a problem. However, in most cases, just a few parts\", \" of the \\napplication are the choke points that require scaling, while other components are used less\", \". \\n\\nFor example, in a typical e-commerce application, you likely need to scale the product informati\", \"on \\nsubsystem, because many more customers browse products than purchase them. More customers use \\n\\n\", \"19 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\ftheir basket th\", \"an use the payment pipeline. Fewer customers add comments or view their purchase \\nhistory. And you m\", \"ight have only a handful of employees that need to manage the content and \\nmarketing campaigns. If y\", \"ou scale the monolithic design, all the code for these different tasks is \\ndeployed multiple times a\", \"nd scaled at the same grade. \\n\\nThere are multiple ways to scale an application-horizontal duplicatio\", \"n, splitting different areas of the \\napplication, and partitioning similar business concepts or data\", \". But, in addition to the problem of \\nscaling all components, changes to a single component require \", \"complete retesting of the entire \\napplication, and a complete redeployment of all the instances. \\n\\nH\", \"owever, the monolithic approach is common, because the development of the application is initially \\n\", \"easier than for microservices approaches. Thus, many organizations develop using this architectural \", \"\\napproach. While some organizations have had good enough results, others are hitting limits. Many \\no\", \"rganizations designed their applications using this model because tools and infrastructure made it \\n\", \"too difficult to build service-oriented architectures (SOA) years ago, and they did not see the need\", \"-\\nuntil the application grew. \\n\\nFrom an infrastructure perspective, each server can run many applica\", \"tions within the same host and \\nhave an acceptable ratio of efficiency in resources usage, as shown \", \"in Figure 4-2. \\n\\nFigure 4-2. Monolithic approach: Host running multiple apps, each app running as a \", \"container \\n\\nMonolithic applications in Microsoft Azure can be deployed using dedicated VMs for each \", \"instance. \\nAdditionally, using Azure virtual machine scale sets, you can easily scale the VMs. Azure\", \" App Service \\ncan also run monolithic applications and easily scale instances without requiring you \", \"to manage the \\nVMs. Since 2016, Azure App Services can run single instances of Docker containers as \", \"well, simplifying \\ndeployment. \\n\\nAs a QA environment or a limited production environment, you can de\", \"ploy multiple Docker host VMs \\nand balance them using the Azure balancer, as shown in Figure 4-3. Th\", \"is lets you manage scaling with \\na coarse-grain approach, because the whole application lives within\", \" a single container. \\n\\n20 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\", \"\\n \\n \\n \\n\\fFigure 4-3. Example of multiple hosts scaling up a single container application \\n\\nDeployment\", \" to the various hosts can be managed with traditional deployment techniques. Docker \\nhosts can be ma\", \"naged with commands like docker run or docker-compose performed manually, or \\nthrough automation suc\", \"h as continuous delivery (CD) pipelines. \\n\\nDeploying a monolithic application as a container \\n\\nThere\", \" are benefits to using containers to manage monolithic application deployments. Scaling \\ncontainer i\", \"nstances is far faster and easier than deploying additional VMs. Even if you use virtual \\nmachine sc\", \"ale sets, VMs take time to start. When deployed as traditional application instances instead \\nof con\", \"tainers, the configuration of the application is managed as part of the VM, which isn\\u2019t ideal. \\n\\nDep\", \"loying updates as Docker images is far faster and network efficient. Docker images typically start \\n\", \"in seconds, which speeds rollouts. Tearing down a Docker image instance is as easy as issuing a \\ndoc\", \"ker stop command, and typically completes in less than a second. \\n\\nBecause containers are immutable \", \"by design, you never need to worry about corrupted VMs. In \\ncontrast, update scripts for a VM might \", \"forget to account for some specific configuration or file left on \\ndisk. \\n\\nWhile monolithic applicat\", \"ions can benefit from Docker, we\\u2019re touching only on the benefits. \\nAdditional benefits of managing \", \"containers come from deploying with container orchestrators, which \\nmanage the various instances and\", \" lifecycle of each container instance. Breaking up the monolithic \\napplication into subsystems that \", \"can be scaled, developed, and deployed individually is your entry \\npoint into the realm of microserv\", \"ices. \\n\\nPublishing a single-container-based application to Azure App Service \\n\\nWhether you want to g\", \"et validation of a container deployed to Azure or when an application is simply \\na single-container \", \"application, Azure App Service provides a great way to provide scalable single-\\ncontainer-based serv\", \"ices. Using Azure App Service is simple. It provides great integration with Git to \\nmake it easy to \", \"take your code, build it in Visual Studio, and deploy it directly to Azure. \\n\\n21 \\n\\nCHAPTER 3 | Archi\", \"tecting container and microservice-based applications \\n\\n \\n \\n \\n\\fFigure 4-4. Publishing a single-conta\", \"iner application to Azure App Service from Visual Studio 2022 \\n\\nWithout Docker, if you needed other \", \"capabilities, frameworks, or dependencies that aren\\u2019t supported \\nin Azure App Service, you had to wa\", \"it until the Azure team updated those dependencies in App \\nService. Or you had to switch to other se\", \"rvices like Azure Cloud Services or VMs, where you had \\nfurther control and you could install a requ\", \"ired component or framework for your application. \\n\\nContainer support in Visual Studio 2017 and late\", \"r gives you the ability to include whatever you want \\nin your application environment, as shown in F\", \"igure 4-4. Since you\\u2019re running it in a container, if you \\nadd a dependency to your application, you\", \" can include the dependency in your Dockerfile or Docker \\nimage. \\n\\nAs also shown in Figure 4-4, the \", \"publish flow pushes an image through a container registry. This can \\nbe the Azure Container Registry\", \" (a registry close to your deployments in Azure and secured by Azure \\nActive Directory groups and ac\", \"counts), or any other Docker registry, like Docker Hub or an on-\\npremises registry. \\n\\nManage state a\", \"nd data in Docker applications \\n\\nIn most cases, you can think of a container as an instance of a pro\", \"cess. A process doesn\\u2019t maintain \\npersistent state. While a container can write to its local storage\", \", assuming that an instance will be \\naround indefinitely would be like assuming that a single locati\", \"on in memory will be durable. You \\n\\n22 \\n\\nCHAPTER 3 | Architecting container and microservice-based a\", \"pplications \\n\\n \\n \\n \\n\\fshould assume that container images, like processes, have multiple instances or\", \" will eventually be \\nkilled. If they\\u2019re managed with a container orchestrator, you should assume tha\", \"t they might get \\nmoved from one node or VM to another. \\n\\nThe following solutions are used to manage\", \" data in Docker applications: \\n\\nFrom the Docker host, as Docker Volumes: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nVolumes are s\", \"tored in an area of the host filesystem that\\u2019s managed by Docker. \\n\\nBind mounts can map to any folde\", \"r in the host filesystem, so access can\\u2019t be controlled from \\nDocker process and can pose a security\", \" risk as a container could access sensitive OS folders. \\n\\ntmpfs mounts are like virtual folders that\", \" only exist in the host\\u2019s memory and are never \\nwritten to the filesystem. \\n\\nFrom remote storage: \\n\\n\", \"\\u2022 \\n\\n\\u2022 \\n\\nAzure Storage, which provides geo-distributable storage, providing a good long-term \\npersist\", \"ence solution for containers. \\n\\nRemote relational databases like Azure SQL Database or NoSQL databas\", \"es like Azure Cosmos \\nDB, or cache services like Redis. \\n\\nFrom the Docker container: \\n\\n\\u2022 \\n\\nOverlay F\", \"ile System. This Docker feature implements a copy-on-write task that stores \\nupdated information to \", \"the root file system of the container. That information is \\u201con top\\u201d of \\nthe original image on which \", \"the container is based. If the container is deleted from the \\nsystem, those changes are lost. Theref\", \"ore, while it\\u2019s possible to save the state of a container \\nwithin its local storage, designing a sys\", \"tem around this would conflict with the premise of \\ncontainer design, which by default is stateless.\", \" \\n\\nHowever, using Docker Volumes is now the preferred way to handle local data in Docker. If you nee\", \"d \\nmore information about storage in containers check on Docker storage drivers and About storage \\nd\", \"rivers. \\n\\nThe following provides more detail about these options: \\n\\nVolumes are directories mapped f\", \"rom the host OS to directories in containers. When code in the \\ncontainer has access to the director\", \"y, that access is actually to a directory on the host OS. This \\ndirectory is not tied to the lifetim\", \"e of the container itself, and the directory is managed by Docker and \\nisolated from the core functi\", \"onality of the host machine. Thus, data volumes are designed to persist \\ndata independently of the l\", \"ife of the container. If you delete a container or an image from the Docker \\nhost, the data persiste\", \"d in the data volume isn\\u2019t deleted. \\n\\nVolumes can be named or anonymous (the default). Named volumes\", \" are the evolution of Data \\nVolume Containers and make it easy to share data between containers. Vol\", \"umes also support \\nvolume drivers that allow you to store data on remote hosts, among other options.\", \" \\n\\nBind mounts are available since a long time ago and allow the mapping of any folder to a mount \\np\", \"oint in a container. Bind mounts have more limitations than volumes and some important security \\niss\", \"ues, so volumes are the recommended option. \\n\\n23 \\n\\nCHAPTER 3 | Architecting container and microservi\", \"ce-based applications \\n\\n \\n \\n\\ftmpfs mounts are basically virtual folders that live only in the host\\u2019s\", \" memory and are never written to \\nthe filesystem. They are fast and secure but use memory and are on\", \"ly meant for temporary, non-\\npersistent data. \\n\\nAs shown in Figure 4-5, regular Docker volumes can b\", \"e stored outside of the containers themselves \\nbut within the physical boundaries of the host server\", \" or VM. However, Docker containers can\\u2019t access \\na volume from one host server or VM to another. In \", \"other words, with these volumes, it isn\\u2019t possible \\nto manage data shared between containers that ru\", \"n on different Docker hosts, although it could be \\nachieved with a volume driver that supports remot\", \"e hosts. \\n\\nFigure 4-5. Volumes and external data sources for container-based applications \\n\\nVolumes \", \"can be shared between containers, but only in the same host, unless you use a remote driver \\nthat su\", \"pports remote hosts. In addition, when Docker containers are managed by an orchestrator, \\ncontainers\", \" might \\u201cmove\\u201d between hosts, depending on the optimizations performed by the cluster. \\nTherefore, it\", \" isn\\u2019t recommended that you use data volumes for business data. But they\\u2019re a good \\nmechanism to wor\", \"k with trace files, temporal files, or similar that will not impact business data \\nconsistency. \\n\\nRe\", \"mote data sources and cache tools like Azure SQL Database, Azure Cosmos DB, or a remote cache \\nlike \", \"Redis can be used in containerized applications the same way they are used when developing \\nwithout \", \"containers. This is a proven way to store business application data. \\n\\nAzure Storage. Business data \", \"usually will need to be placed in external resources or databases, like \\nAzure Storage. Azure Storag\", \"e, in concrete, provides the following services in the cloud: \\n\\n\\u2022 \\n\\nBlob storage stores unstructured\", \" object data. A blob can be any type of text or binary data, \\nsuch as document or media files (image\", \"s, audio, and video files). Blob storage is also referred \\nto as Object storage. \\n\\n24 \\n\\nCHAPTER 3 | \", \"Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\nFile storage offers shar\", \"ed storage for legacy applications using standard SMB protocol. Azure \\nvirtual machines and cloud se\", \"rvices can share file data across application components via \\nmounted shares. On-premises applicatio\", \"ns can access file data in a share via the File service \\nREST API. \\n\\nTable storage stores structured\", \" datasets. Table storage is a NoSQL key-attribute data store, \\nwhich allows rapid development and fa\", \"st access to large quantities of data. \\n\\nRelational databases and NoSQL databases. There are many ch\", \"oices for external databases, from \\nrelational databases like SQL Server, PostgreSQL, Oracle, or NoS\", \"QL databases like Azure Cosmos DB, \\nMongoDB, etc. These databases are not going to be explained as p\", \"art of this guide since they are in a \\ncompletely different subject. \\n\\nService-oriented architecture\", \" \\n\\nService-oriented architecture (SOA) was an overused term and has meant different things to differ\", \"ent \\npeople. But as a common denominator, SOA means that you structure your application by \\ndecompos\", \"ing it into multiple services (most commonly as HTTP services) that can be classified as \\ndifferent \", \"types like subsystems or tiers. \\n\\nThose services can now be deployed as Docker containers, which sol\", \"ves deployment issues, because \\nall the dependencies are included in the container image. However, w\", \"hen you need to scale up SOA \\napplications, you might have scalability and availability challenges i\", \"f you\\u2019re deploying based on single \\nDocker hosts. This is where Docker clustering software or an orc\", \"hestrator can help you, as explained in \\nlater sections where deployment approaches for microservice\", \"s are described. \\n\\nDocker containers are useful (but not required) for both traditional service-orie\", \"nted architectures and \\nthe more advanced microservices architectures. \\n\\nMicroservices derive from S\", \"OA, but SOA is different from microservices architecture. Features like \\nlarge central brokers, cent\", \"ral orchestrators at the organization level, and the Enterprise Service Bus \\n(ESB) are typical in SO\", \"A. But in most cases, these are anti-patterns in the microservice community. In \\nfact, some people a\", \"rgue that \\u201cThe microservice architecture is SOA done right.\\u201d \\n\\nThis guide focuses on microservices, \", \"because a SOA approach is less prescriptive than the \\nrequirements and techniques used in a microser\", \"vice architecture. If you know how to build a \\nmicroservice-based application, you also know how to \", \"build a simpler service-oriented application. \\n\\nMicroservices architecture \\n\\nAs the name implies, a \", \"microservices architecture is an approach to building a server application as a \\nset of small servic\", \"es. That means a microservices architecture is mainly oriented to the back-end, \\nalthough the approa\", \"ch is also being used for the front end. Each service runs in its own process and \\ncommunicates with\", \" other processes using protocols such as HTTP/HTTPS, WebSockets, or AMQP. \\nEach microservice impleme\", \"nts a specific end-to-end domain or business capability within a certain \\ncontext boundary, and each\", \" must be developed autonomously and be deployable independently. \\nFinally, each microservice should \", \"own its related domain data model and domain logic (sovereignty \\n\\n25 \\n\\nCHAPTER 3 | Architecting cont\", \"ainer and microservice-based applications \\n\\n \\n \\n\\fand decentralized data management) and could be bas\", \"ed on different data storage technologies \\n(SQL, NoSQL) and different programming languages. \\n\\nWhat \", \"size should a microservice be? When developing a microservice, size shouldn\\u2019t be the important \\npoin\", \"t. Instead, the important point should be to create loosely coupled services so you have \\nautonomy o\", \"f development, deployment, and scale, for each service. Of course, when identifying and \\ndesigning m\", \"icroservices, you should try to make them as small as possible as long as you don\\u2019t have \\ntoo many d\", \"irect dependencies with other microservices. More important than the size of the \\nmicroservice is th\", \"e internal cohesion it must have and its independence from other services. \\n\\nWhy a microservices arc\", \"hitecture? In short, it provides long-term agility. Microservices enable better \\nmaintainability in \", \"complex, large, and highly-scalable systems by letting you create applications based \\non many indepe\", \"ndently deployable services that each have granular and autonomous lifecycles. \\n\\nAs an additional be\", \"nefit, microservices can scale out independently. Instead of having a single \\nmonolithic application\", \" that you must scale out as a unit, you can instead scale out specific \\nmicroservices. That way, you\", \" can scale just the functional area that needs more processing power or \\nnetwork bandwidth to suppor\", \"t demand, rather than scaling out other areas of the application that \\ndon\\u2019t need to be scaled. That\", \" means cost savings because you need less hardware. \\n\\nFigure 4-6. Monolithic deployment versus the m\", \"icroservices approach \\n\\nAs Figure 4-6 shows, in the traditional monolithic approach, the application\", \" scales by cloning the \\nwhole app in several servers/VM. In the microservices approach, functionalit\", \"y is segregated in smaller \\nservices, so each service can scale independently. The microservices app\", \"roach allows agile changes \\nand rapid iteration of each microservice, because you can change specifi\", \"c, small areas of complex, \\nlarge, and scalable applications. \\n\\nArchitecting fine-grained microservi\", \"ces-based applications enables continuous integration and \\ncontinuous delivery practices. It also ac\", \"celerates delivery of new functions into the application. Fine-\\ngrained composition of applications \", \"also allows you to run and test microservices in isolation, and to \\n\\n26 \\n\\nCHAPTER 3 | Architecting c\", \"ontainer and microservice-based applications \\n\\n \\n \\n \\n\\fevolve them autonomously while maintaining cle\", \"ar contracts between them. As long as you don\\u2019t \\nchange the interfaces or contracts, you can change \", \"the internal implementation of any microservice or \\nadd new functionality without breaking other mic\", \"roservices. \\n\\nThe following are important aspects to enable success in going into production with a \", \"microservices-\\nbased system: \\n\\n\\u2022  Monitoring and health checks of the services and infrastructure. \\n\", \"\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nScalable infrastructure for the services (that is, cloud and orchestrators). \\n\\nSecu\", \"rity design and implementation at multiple levels: authentication, authorization, secrets \\nmanagemen\", \"t, secure communication, etc. \\n\\nRapid application delivery, usually with different teams focusing on\", \" different microservices. \\n\\nDevOps and CI/CD practices and infrastructure. \\n\\nOf these, only the firs\", \"t three are covered or introduced in this guide. The last two points, which are \\nrelated to applicat\", \"ion lifecycle, are covered in the additional Containerized Docker Application \\nLifecycle with Micros\", \"oft Platform and Tools e-book. \\n\\nAdditional resources \\n\\n\\u2022  Mark Russinovich. Microservices: An appli\", \"cation revolution powered by the cloud \\n\\nhttps://azure.microsoft.com/blog/microservices-an-applicati\", \"on-revolution-powered-by-the-\\ncloud/ \\n\\n\\u2022  Martin Fowler. Microservices \\n\\nhttps://www.martinfowler.co\", \"m/articles/microservices.html \\n\\n\\u2022  Martin Fowler. Microservice Prerequisites \\n\\nhttps://martinfowler.\", \"com/bliki/MicroservicePrerequisites.html \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nJimmy Nilsson. Chunk Cloud Computing \\nhttps://www\", \".infoq.com/articles/CCC-Jimmy-Nilsson \\n\\nCesar de la Torre. Containerized Docker Application Lifecycl\", \"e with Microsoft Platform \\nand Tools (downloadable e-book) \\nhttps://aka.ms/dockerlifecycleebook \\n\\nDa\", \"ta sovereignty per microservice \\n\\nAn important rule for microservices architecture is that each micr\", \"oservice must own its domain data \\nand logic. Just as a full application owns its logic and data, so\", \" must each microservice own its logic \\nand data under an autonomous lifecycle, with independent depl\", \"oyment per microservice. \\n\\nThis means that the conceptual model of the domain will differ between su\", \"bsystems or microservices. \\nConsider enterprise applications, where customer relationship management\", \" (CRM) applications, \\n\\n27 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\", \"\\n \\n \\n\\ftransactional purchase subsystems, and customer support subsystems each call on unique custome\", \"r \\nentity attributes and data, and where each employs a different Bounded Context (BC). \\n\\nThis princ\", \"iple is similar in Domain-driven design (DDD), where each Bounded Context or autonomous \\nsubsystem o\", \"r service must own its domain model (data plus logic and behavior). Each DDD Bounded \\nContext correl\", \"ates to one business microservice (one or several services). This point about the \\nBounded Context p\", \"attern is expanded in the next section. \\n\\nOn the other hand, the traditional (monolithic data) appro\", \"ach used in many applications is to have a \\nsingle centralized database or just a few databases. Thi\", \"s is often a normalized SQL database that\\u2019s \\nused for the whole application and all its internal sub\", \"systems, as shown in Figure 4-7. \\n\\nFigure 4-7. Data sovereignty comparison: monolithic database vers\", \"us microservices \\n\\nIn the traditional approach, there\\u2019s a single database shared across all services\", \", typically in a tiered \\narchitecture. In the microservices approach, each microservice owns its mod\", \"el/data. The centralized \\ndatabase approach initially looks simpler and seems to enable reuse of ent\", \"ities in different subsystems \\nto make everything consistent. But the reality is you end up with hug\", \"e tables that serve many different \\nsubsystems, and that include attributes and columns that aren\\u2019t \", \"needed in most cases. It\\u2019s like trying \\nto use the same physical map for hiking a short trail, takin\", \"g a day-long car trip, and learning \\ngeography. \\n\\nA monolithic application with typically a single r\", \"elational database has two important benefits: ACID \\ntransactions and the SQL language, both working\", \" across all the tables and data related to your \\napplication. This approach provides a way to easily\", \" write a query that combines data from multiple \\ntables. \\n\\nHowever, data access becomes much more co\", \"mplicated when you move to a microservices \\narchitecture. Even when using ACID transactions within a\", \" microservice or Bounded Context, it is crucial \\nto consider that the data owned by each microservic\", \"e is private to that microservice and should only \\n\\n28 \\n\\nCHAPTER 3 | Architecting container and micr\", \"oservice-based applications \\n\\n \\n \\n \\n\\fbe accessed either synchronously through its API endpoints(REST\", \", gRPC, SOAP, etc) or asynchronously \\nvia messaging(AMQP or similar). \\n\\nEncapsulating the data ensur\", \"es that the microservices are loosely coupled and can evolve \\nindependently of one another. If multi\", \"ple services were accessing the same data, schema updates \\nwould require coordinated updates to all \", \"the services. This would break the microservice lifecycle \\nautonomy. But distributed data structures\", \" mean that you can\\u2019t make a single ACID transaction across \\nmicroservices. This in turn means you mu\", \"st use eventual consistency when a business process spans \\nmultiple microservices. This is much hard\", \"er to implement than simple SQL joins, because you can\\u2019t \\ncreate integrity constraints or use distri\", \"buted transactions between separate databases, as we\\u2019ll \\nexplain later on. Similarly, many other rel\", \"ational database features aren\\u2019t available across multiple \\nmicroservices. \\n\\nGoing even further, dif\", \"ferent microservices often use different kinds of databases. Modern \\napplications store and process \", \"diverse kinds of data, and a relational database isn\\u2019t always the best \\nchoice. For some use cases, \", \"a NoSQL database such as Azure CosmosDB or MongoDB might have a \\nmore convenient data model and offe\", \"r better performance and scalability than a SQL database like \\nSQL Server or Azure SQL Database. In \", \"other cases, a relational database is still the best approach. \\nTherefore, microservices-based appli\", \"cations often use a mixture of SQL and NoSQL databases, which \\nis sometimes called the polyglot pers\", \"istence approach. \\n\\nA partitioned, polyglot-persistent architecture for data storage has many benefi\", \"ts. These include \\nloosely coupled services and better performance, scalability, costs, and manageab\", \"ility. However, it can \\nintroduce some distributed data management challenges, as explained in \\u201cIden\", \"tifying domain-model \\nboundaries\\u201d later in this chapter. \\n\\nThe relationship between microservices an\", \"d the Bounded Context \\npattern \\n\\nThe concept of microservice derives from the Bounded Context (BC) p\", \"attern in domain-driven design \\n(DDD). DDD deals with large models by dividing them into multiple BC\", \"s and being explicit about their \\nboundaries. Each BC must have its own model and database; likewise\", \", each microservice owns its \\nrelated data. In addition, each BC usually has its own ubiquitous lang\", \"uage to help communication \\nbetween software developers and domain experts. \\n\\nThose terms (mainly do\", \"main entities) in the ubiquitous language can have different names in different \\nBounded Contexts, e\", \"ven when different domain entities share the same identity (that is, the unique ID \\nthat\\u2019s used to r\", \"ead the entity from storage). For instance, in a user-profile Bounded Context, the User \\ndomain enti\", \"ty might share identity with the Buyer domain entity in the ordering Bounded Context. \\n\\nA microservi\", \"ce is therefore like a Bounded Context, but it also specifies that it\\u2019s a distributed service. \\nIt\\u2019s\", \" built as a separate process for each Bounded Context, and it must use the distributed protocols \\nno\", \"ted earlier, like HTTP/HTTPS, WebSockets, or AMQP. The Bounded Context pattern, however, \\ndoesn\\u2019t sp\", \"ecify whether the Bounded Context is a distributed service or if it\\u2019s simply a logical \\nboundary (su\", \"ch as a generic subsystem) within a monolithic-deployment application. \\n\\nIt\\u2019s important to highlight\", \" that defining a service for each Bounded Context is a good place to start. \\nBut you don\\u2019t have to c\", \"onstrain your design to it. Sometimes you must design a Bounded Context or \\n\\n29 \\n\\nCHAPTER 3 | Archit\", \"ecting container and microservice-based applications \\n\\n \\n \\n\\fbusiness microservice composed of severa\", \"l physical services. But ultimately, both patterns -Bounded \\nContext and microservice- are closely r\", \"elated. \\n\\nDDD benefits from microservices by getting real boundaries in the form of distributed micr\", \"oservices. \\nBut ideas like not sharing the model between microservices are what you also want in a B\", \"ounded \\nContext. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nChris Richardson. Pattern: Database per service \\nhttps\", \"://microservices.io/patterns/data/database-per-service.html \\n\\n\\u2022  Martin Fowler. BoundedContext \\n\\nhtt\", \"ps://martinfowler.com/bliki/BoundedContext.html \\n\\n\\u2022  Martin Fowler. PolyglotPersistence \\n\\nhttps://ma\", \"rtinfowler.com/bliki/PolyglotPersistence.html \\n\\n\\u2022 \\n\\nAlberto Brandolini. Strategic Domain Driven Desi\", \"gn with Context Mapping \\nhttps://www.infoq.com/articles/ddd-contextmapping \\n\\nLogical architecture ve\", \"rsus physical architecture \\n\\nIt\\u2019s useful at this point to stop and discuss the distinction between l\", \"ogical architecture and physical \\narchitecture, and how this applies to the design of microservice-b\", \"ased applications. \\n\\nTo begin, building microservices doesn\\u2019t require the use of any specific techno\", \"logy. For instance, \\nDocker containers aren\\u2019t mandatory to create a microservice-based architecture.\", \" Those microservices \\ncould also be run as plain processes. Microservices is a logical architecture.\", \" \\n\\nMoreover, even when a microservice could be physically implemented as a single service, process, \", \"or \\ncontainer (for simplicity\\u2019s sake, that\\u2019s the approach taken in the initial version of eShopOnCon\", \"tainers), \\nthis parity between business microservice and physical service or container isn\\u2019t necessa\", \"rily required in \\nall cases when you build a large and complex application composed of many dozens o\", \"r even \\nhundreds of services. \\n\\nThis is where there\\u2019s a difference between an application\\u2019s logical \", \"architecture and physical \\narchitecture. The logical architecture and logical boundaries of a system\", \" do not necessarily map one-\\nto-one to the physical or deployment architecture. It can happen, but i\", \"t often doesn\\u2019t. \\n\\nAlthough you might have identified certain business microservices or Bounded Cont\", \"exts, it doesn\\u2019t \\nmean that the best way to implement them is always by creating a single service (s\", \"uch as an ASP.NET \\nWeb API) or single Docker container for each business microservice. Having a rule\", \" saying each \\nbusiness microservice has to be implemented using a single service or container is too\", \" rigid. \\n\\nTherefore, a business microservice or Bounded Context is a logical architecture that might\", \" coincide (or \\nnot) with physical architecture. The important point is that a business microservice \", \"or Bounded \\nContext must be autonomous by allowing code and state to be independently versioned, dep\", \"loyed, \\nand scaled. \\n\\n30 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n\", \" \\n \\n\\fAs Figure 4-8 shows, the catalog business microservice could be composed of several services or\", \" \\nprocesses. These could be multiple ASP.NET Web API services or any other kind of services using \\nH\", \"TTP or any other protocol. More importantly, the services could share the same data, as long as \\nthe\", \"se services are cohesive with respect to the same business domain. \\n\\nFigure 4-8. Business microservi\", \"ce with several physical services \\n\\nThe services in the example share the same data model because th\", \"e Web API service targets the same \\ndata as the Search service. So, in the physical implementation o\", \"f the business microservice, you\\u2019re \\nsplitting that functionality so you can scale each of those int\", \"ernal services up or down as needed. \\nMaybe the Web API service usually needs more instances than th\", \"e Search service, or vice versa. \\n\\nIn short, the logical architecture of microservices doesn\\u2019t alway\", \"s have to coincide with the physical \\ndeployment architecture. In this guide, whenever we mention a \", \"microservice, we mean a business or \\nlogical microservice that could map to one or more (physical) s\", \"ervices. In most cases, this will be a \\nsingle service, but it might be more. \\n\\nChallenges and solut\", \"ions for distributed data \\nmanagement \\n\\nChallenge #1: How to define the boundaries of each microserv\", \"ice \\n\\nDefining microservice boundaries is probably the first challenge anyone encounters. Each micro\", \"service \\nhas to be a piece of your application and each microservice should be autonomous with all t\", \"he \\nbenefits and challenges that it conveys. But how do you identify those boundaries? \\n\\nFirst, you \", \"need to focus on the application\\u2019s logical domain models and related data. Try to identify \\ndecouple\", \"d islands of data and different contexts within the same application. Each context could have \\na dif\", \"ferent business language (different business terms). The contexts should be defined and managed \\nind\", \"ependently. The terms and entities that are used in those different contexts might sound similar, \\nb\", \"ut you might discover that in a particular context, a business concept with one is used for a differ\", \"ent \\n\\n31 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fpurpose i\", \"n another context, and might even have a different name. For instance, a user can be \\nreferred as a \", \"user in the identity or membership context, as a customer in a CRM context, as a buyer in \\nan orderi\", \"ng context, and so forth. \\n\\nThe way you identify boundaries between multiple application contexts wi\", \"th a different domain for \\neach context is exactly how you can identify the boundaries for each busi\", \"ness microservice and its \\nrelated domain model and data. You always attempt to minimize the couplin\", \"g between those \\nmicroservices. This guide goes into more detail about this identification and domai\", \"n model design in \\nthe section Identifying domain-model boundaries for each microservice later. \\n\\nCh\", \"allenge #2: How to create queries that retrieve data from several \\nmicroservices \\n\\nA second challeng\", \"e is how to implement queries that retrieve data from several microservices, while \\navoiding chatty \", \"communication to the microservices from remote client apps. An example could be a \\nsingle screen fro\", \"m a mobile app that needs to show user information that\\u2019s owned by the basket, \\ncatalog, and user id\", \"entity microservices. Another example would be a complex report involving many \\ntables located in mu\", \"ltiple microservices. The right solution depends on the complexity of the queries. \\nBut in any case,\", \" you\\u2019ll need a way to aggregate information if you want to improve the efficiency in \\nthe communicat\", \"ions of your system. The most popular solutions are the following. \\n\\nAPI Gateway. For simple data ag\", \"gregation from multiple microservices that own different databases, \\nthe recommended approach is an \", \"aggregation microservice referred to as an API Gateway. However, \\nyou need to be careful about imple\", \"menting this pattern, because it can be a choke point in your \\nsystem, and it can violate the princi\", \"ple of microservice autonomy. To mitigate this possibility, you can \\nhave multiple fined-grained API\", \" Gateways each one focusing on a vertical \\u201cslice\\u201d or business area of \\nthe system. The API Gateway p\", \"attern is explained in more detail in the API Gateway section later. \\n\\nGraphQL Federation One option\", \" to consider if your microservices are already using GraphQL is \\nGraphQL Federation. Federation allo\", \"ws you to define \\u201csubgraphs\\u201d from other services and compose \\nthem into an aggregate \\u201csupergraph\\u201d th\", \"at acts as a standalone schema. \\n\\nCQRS with query/reads tables. Another solution for aggregating dat\", \"a from multiple microservices is \\nthe Materialized View pattern. In this approach, you generate, in \", \"advance (prepare denormalized data \\nbefore the actual queries happen), a read-only table with the da\", \"ta that\\u2019s owned by multiple \\nmicroservices. The table has a format suited to the client app\\u2019s needs.\", \" \\n\\nConsider something like the screen for a mobile app. If you have a single database, you might pul\", \"l \\ntogether the data for that screen using a SQL query that performs a complex join involving multip\", \"le \\ntables. However, when you have multiple databases, and each database is owned by a different \\nmi\", \"croservice, you cannot query those databases and create a SQL join. Your complex query becomes \\na ch\", \"allenge. You can address the requirement using a CQRS approach\\u2014you create a denormalized \\ntable in a\", \" different database that\\u2019s used just for queries. The table can be designed specifically for the \\nda\", \"ta you need for the complex query, with a one-to-one relationship between fields needed by your \\napp\", \"lication\\u2019s screen and the columns in the query table. It could also serve for reporting purposes. \\n\\n\", \"This approach not only solves the original problem (how to query and join across microservices), but\", \" it \\nalso improves performance considerably when compared with a complex join, because you already \\n\", \"\\n32 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fhave the data th\", \"at the application needs in the query table. Of course, using Command and Query \\nResponsibility Segr\", \"egation (CQRS) with query/reads tables means additional development work, and \\nyou\\u2019ll need to embrac\", \"e eventual consistency. Nonetheless, requirements on performance and high \\nscalability in collaborat\", \"ive scenarios (or competitive scenarios, depending on the point of view) are \\nwhere you should apply\", \" CQRS with multiple databases. \\n\\n\\u201cCold data\\u201d in central databases. For complex reports and queries t\", \"hat might not require real-time \\ndata, a common approach is to export your \\u201chot data\\u201d (transactional\", \" data from the microservices) as \\n\\u201ccold data\\u201d into large databases that are used only for reporting.\", \" That central database system can be \\na Big Data-based system, like Hadoop; a data warehouse like on\", \"e based on Azure SQL Data \\nWarehouse; or even a single SQL database that\\u2019s used just for reports (if\", \" size won\\u2019t be an issue). \\n\\nKeep in mind that this centralized database would be used only for queri\", \"es and reports that do not \\nneed real-time data. The original updates and transactions, as your sour\", \"ce of truth, have to be in your \\nmicroservices data. The way you would synchronize data would be eit\", \"her by using event-driven \\ncommunication (covered in the next sections) or by using other database i\", \"nfrastructure import/export \\ntools. If you use event-driven communication, that integration process \", \"would be similar to the way \\nyou propagate data as described earlier for CQRS query tables. \\n\\nHoweve\", \"r, if your application design involves constantly aggregating information from multiple \\nmicroservic\", \"es for complex queries, it might be a symptom of a bad design -a microservice should be \\nas isolated\", \" as possible from other microservices. (This excludes reports/analytics that always should \\nuse cold\", \"-data central databases.) Having this problem often might be a reason to merge \\nmicroservices. You n\", \"eed to balance the autonomy of evolution and deployment of each microservice \\nwith strong dependenci\", \"es, cohesion, and data aggregation. \\n\\nChallenge #3: How to achieve consistency across multiple \\nmicr\", \"oservices \\n\\nAs stated previously, the data owned by each microservice is private to that microservic\", \"e and can only \\nbe accessed using its microservice API. Therefore, a challenge presented is how to i\", \"mplement end-to-\\nend business processes while keeping consistency across multiple microservices. \\n\\nT\", \"o analyze this problem, let\\u2019s look at an example from the eShopOnContainers reference application. \\n\", \"The Catalog microservice maintains information about all the products, including the product price. \", \"\\nThe Basket microservice manages temporal data about product items that users are adding to their \\ns\", \"hopping baskets, which includes the price of the items at the time they were added to the basket. \\nW\", \"hen a product\\u2019s price is updated in the catalog, that price should also be updated in the active \\nba\", \"skets that hold that same product, plus the system should probably warn the user saying that a \\npart\", \"icular item\\u2019s price has changed since they added it to their basket. \\n\\nIn a hypothetical monolithic \", \"version of this application, when the price changes in the products table, \\nthe catalog subsystem co\", \"uld simply use an ACID transaction to update the current price in the Basket \\ntable. \\n\\nHowever, in a\", \" microservices-based application, the Product and Basket tables are owned by their \\nrespective micro\", \"services. No microservice should ever include tables/storage owned by another \\nmicroservice in its o\", \"wn transactions, not even in direct queries, as shown in Figure 4-9. \\n\\n33 \\n\\nCHAPTER 3 | Architecting\", \" container and microservice-based applications \\n\\n \\n \\n\\fFigure 4-9. A microservice can\\u2019t directly acce\", \"ss a table in another microservice \\n\\nThe Catalog microservice shouldn\\u2019t update the Basket table dire\", \"ctly, because the Basket table is \\nowned by the Basket microservice. To make an update to the Basket\", \" microservice, the Catalog \\nmicroservice should use eventual consistency probably based on asynchron\", \"ous communication such \\nas integration events (message and event-based communication). This is how t\", \"he eShopOnContainers \\nreference application performs this type of consistency across microservices. \", \"\\n\\nAs stated by the CAP theorem, you need to choose between availability and ACID strong consistency.\", \" \\nMost microservice-based scenarios demand availability and high scalability as opposed to strong \\nc\", \"onsistency. Mission-critical applications must remain up and running, and developers can work \\naroun\", \"d strong consistency by using techniques for working with weak or eventual consistency. This is \\nthe\", \" approach taken by most microservice-based architectures. \\n\\nMoreover, ACID-style or two-phase commit\", \" transactions are not just against microservices principles; \\nmost NoSQL databases (like Azure Cosmo\", \"s DB, MongoDB, etc.) do not support two-phase commit \\ntransactions, typical in distributed databases\", \" scenarios. However, maintaining data consistency across \\nservices and databases is essential. This \", \"challenge is also related to the question of how to propagate \\nchanges across multiple microservices\", \" when certain data needs to be redundant\\u2014for example, when \\nyou need to have the product\\u2019s name or d\", \"escription in the Catalog microservice and the Basket \\nmicroservice. \\n\\nA good solution for this prob\", \"lem is to use eventual consistency between microservices articulated \\nthrough event-driven communica\", \"tion and a publish-and-subscribe system. These topics are covered \\nin the section Asynchronous event\", \"-driven communication later in this guide. \\n\\n34 \\n\\nCHAPTER 3 | Architecting container and microservic\", \"e-based applications \\n\\n \\n \\n \\n\\fChallenge #4: How to design communication across microservice \\nboundar\", \"ies \\n\\nCommunicating across microservice boundaries is a real challenge. In this context, communicati\", \"on \\ndoesn\\u2019t refer to what protocol you should use (HTTP and REST, AMQP, messaging, and so on). Inste\", \"ad, \\nit addresses what communication style you should use, and especially how coupled your \\nmicroser\", \"vices should be. Depending on the level of coupling, when failure occurs, the impact of that \\nfailur\", \"e on your system will vary significantly. \\n\\nIn a distributed system like a microservices-based appli\", \"cation, with so many artifacts moving around \\nand with distributed services across many servers or h\", \"osts, components will eventually fail. Partial \\nfailure and even larger outages will occur, so you n\", \"eed to design your microservices and the \\ncommunication across them considering the common risks in \", \"this type of distributed system. \\n\\nA popular approach is to implement HTTP (REST)-based microservice\", \"s, due to their simplicity. An \\nHTTP-based approach is perfectly acceptable; the issue here is relat\", \"ed to how you use it. If you use \\nHTTP requests and responses just to interact with your microservic\", \"es from client applications or from \\nAPI Gateways, that\\u2019s fine. But if you create long chains of syn\", \"chronous HTTP calls across microservices, \\ncommunicating across their boundaries as if the microserv\", \"ices were objects in a monolithic \\napplication, your application will eventually run into problems. \", \"\\n\\nFor instance, imagine that your client application makes an HTTP API call to an individual microse\", \"rvice \\nlike the Ordering microservice. If the Ordering microservice in turn calls additional microse\", \"rvices using \\nHTTP within the same request/response cycle, you\\u2019re creating a chain of HTTP calls. It\", \" might sound \\nreasonable initially. However, there are important points to consider when going down \", \"this path: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nBlocking and low performance. Due to the synchronous nature of HTTP, the or\", \"iginal request \\ndoesn\\u2019t get a response until all the internal HTTP calls are finished. Imagine if th\", \"e number of \\nthese calls increases significantly and at the same time one of the intermediate HTTP c\", \"alls to a \\nmicroservice is blocked. The result is that performance is impacted, and the overall scal\", \"ability \\nwill be exponentially affected as additional HTTP requests increase. \\n\\nCoupling microservic\", \"es with HTTP. Business microservices shouldn\\u2019t be coupled with other \\nbusiness microservices. Ideall\", \"y, they shouldn\\u2019t \\u201cknow\\u201d about the existence of other \\nmicroservices. If your application relies on \", \"coupling microservices as in the example, achieving \\nautonomy per microservice will be almost imposs\", \"ible. \\n\\nFailure in any one microservice. If you implemented a chain of microservices linked by HTTP \", \"\\ncalls, when any of the microservices fails (and eventually they will fail) the whole chain of \\nmicr\", \"oservices will fail. A microservice-based system should be designed to continue to work \\nas well as \", \"possible during partial failures. Even if you implement client logic that uses retries \\nwith exponen\", \"tial backoff or circuit breaker mechanisms, the more complex the HTTP call \\nchains are, the more com\", \"plex it is to implement a failure strategy based on HTTP. \\n\\nIn fact, if your internal microservices \", \"are communicating by creating chains of HTTP requests as \\ndescribed, it could be argued that you hav\", \"e a monolithic application, but one based on HTTP between \\nprocesses instead of intra-process commun\", \"ication mechanisms. \\n\\n35 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n\", \" \\n \\n\\fTherefore, in order to enforce microservice autonomy and have better resiliency, you should min\", \"imize \\nthe use of chains of request/response communication across microservices. It\\u2019s recommended th\", \"at \\nyou use only asynchronous interaction for inter-microservice communication, either by using \\nasy\", \"nchronous message- and event-based communication, or by using (asynchronous) HTTP polling \\nindepende\", \"ntly of the original HTTP request/response cycle. \\n\\nThe use of asynchronous communication is explain\", \"ed with additional details later in this guide in the \\nsections Asynchronous microservice integratio\", \"n enforces microservice\\u2019s autonomy and Asynchronous \\nmessage-based communication. \\n\\nAdditional resou\", \"rces \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCAP theorem \\nhttps://en.wikipedia.org/wiki/CAP_theorem \\n\\nEventual consistency \\nht\", \"tps://en.wikipedia.org/wiki/Eventual_consistency \\n\\nData Consistency Primer \\nhttps://learn.microsoft.\", \"com/previous-versions/msp-n-p/dn589800(v=pandp.10) \\n\\n\\u2022  Martin Fowler. CQRS (Command and Query Respo\", \"nsibility Segregation) \\n\\nhttps://martinfowler.com/bliki/CQRS.html \\n\\n\\u2022  Materialized View \\n\\nhttps://l\", \"earn.microsoft.com/azure/architecture/patterns/materialized-view \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCharles Row. ACID vs.\", \" BASE: The Shifting pH of Database Transaction Processing \\nhttps://www.dataversity.net/acid-vs-base-\", \"the-shifting-ph-of-database-transaction-\\nprocessing/ \\n\\nCompensating Transaction \\nhttps://learn.micro\", \"soft.com/azure/architecture/patterns/compensating-transaction \\n\\nUdi Dahan. Service Oriented Composit\", \"ion \\nhttps://udidahan.com/2014/07/30/service-oriented-composition-with-video/ \\n\\nIdentify domain-mode\", \"l boundaries for each \\nmicroservice \\n\\nThe goal when identifying model boundaries and size for each m\", \"icroservice isn\\u2019t to get to the most \\ngranular separation possible, although you should tend toward \", \"small microservices if possible. \\nInstead, your goal should be to get to the most meaningful separat\", \"ion guided by your domain \\nknowledge. The emphasis isn\\u2019t on the size, but instead on business capabi\", \"lities. In addition, if there\\u2019s \\nclear cohesion needed for a certain area of the application based o\", \"n a high number of dependencies, \\nthat indicates the need for a single microservice, too. Cohesion i\", \"s a way to identify how to break apart \\n\\n36 \\n\\nCHAPTER 3 | Architecting container and microservice-ba\", \"sed applications \\n\\n \\n \\n\\for group together microservices. Ultimately, while you gain more knowledge a\", \"bout the domain, you \\nshould adapt the size of your microservice, iteratively. Finding the right siz\", \"e isn\\u2019t a one-shot process. \\n\\nSam Newman, a recognized promoter of microservices and author of the b\", \"ook Building Microservices, \\nhighlights that you should design your microservices based on the Bound\", \"ed Context (BC) pattern \\n(part of domain-driven design), as introduced earlier. Sometimes, a BC coul\", \"d be composed of several \\nphysical services, but not vice versa. \\n\\nA domain model with specific doma\", \"in entities applies within a concrete BC or microservice. A BC \\ndelimits the applicability of a doma\", \"in model and gives developer team members a clear and shared \\nunderstanding of what must be cohesive\", \" and what can be developed independently. These are the \\nsame goals for microservices. \\n\\nAnother too\", \"l that informs your design choice is Conway\\u2019s law, which states that an application will \\nreflect th\", \"e social boundaries of the organization that produced it. But sometimes the opposite is true -\\nthe c\", \"ompany\\u2019s organization is formed by the software. You might need to reverse Conway\\u2019s law and \\nbuild t\", \"he boundaries the way you want the company to be organized, leaning toward business \\nprocess consult\", \"ing. \\n\\nTo identify bounded contexts, you can use a DDD pattern called the Context Mapping pattern. W\", \"ith \\nContext Mapping, you identify the various contexts in the application and their boundaries. It\\u2019\", \"s \\ncommon to have a different context and boundary for each small subsystem, for instance. The Conte\", \"xt \\nMap is a way to define and make explicit those boundaries between domains. A BC is autonomous \\na\", \"nd includes the details of a single domain -details like the domain entities- and defines integratio\", \"n \\ncontracts with other BCs. This is similar to the definition of a microservice: it\\u2019s autonomous, i\", \"t \\nimplements certain domain capability, and it must provide interfaces. This is why Context Mapping\", \" \\nand the Bounded Context pattern are good approaches for identifying the domain model boundaries \\no\", \"f your microservices. \\n\\nWhen designing a large application, you\\u2019ll see how its domain model can be f\", \"ragmented - a domain \\nexpert from the catalog domain will name entities differently in the catalog a\", \"nd inventory domains \\nthan a shipping domain expert, for instance. Or the user domain entity might b\", \"e different in size and \\nnumber of attributes when dealing with a CRM expert who wants to store ever\", \"y detail about the \\ncustomer than for an ordering domain expert who just needs partial data about th\", \"e customer. It\\u2019s very \\nhard to disambiguate all domain terms across all the domains related to a lar\", \"ge application. But the \\nmost important thing is that you shouldn\\u2019t try to unify the terms. Instead,\", \" accept the differences and \\nrichness provided by each domain. If you try to have a unified database\", \" for the whole application, \\nattempts at a unified vocabulary will be awkward and won\\u2019t sound right \", \"to any of the multiple domain \\nexperts. Therefore, BCs (implemented as microservices) will help you \", \"to clarify where you can use \\ncertain domain terms and where you\\u2019ll need to split the system and cre\", \"ate additional BCs with \\ndifferent domains. \\n\\nYou\\u2019ll know that you got the right boundaries and size\", \"s of each BC and domain model if you have few \\nstrong relationships between domain models, and you d\", \"o not usually need to merge information \\nfrom multiple domain models when performing typical applica\", \"tion operations. \\n\\nPerhaps the best answer to the question of how large a domain model for each micr\", \"oservice should \\nbe is the following: it should have an autonomous BC, as isolated as possible, that\", \" enables you to \\nwork without having to constantly switch to other contexts (other microservice\\u2019s mo\", \"dels). In Figure 4-\\n\\n37 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \", \"\\n \\n\\f10, you can see how multiple microservices (multiple BCs) each has their own model and how their\", \" \\nentities can be defined, depending on the specific requirements for each of the identified domains\", \" in \\nyour application. \\n\\nFigure 4-10. Identifying entities and microservice model boundaries \\n\\nFigur\", \"e 4-10 illustrates a sample scenario related to an online conference management system. The \\nsame en\", \"tity appears as \\u201cUsers\\u201d, \\u201cBuyers\\u201d, \\u201cPayers\\u201d, and \\u201cCustomers\\u201d depending on the bounded \\ncontext. You\\u2019\", \"ve identified several BCs that could be implemented as microservices, based on domains \\nthat domain \", \"experts defined for you. As you can see, there are entities that are present just in a single \\nmicro\", \"service model, like Payments in the Payment microservice. Those will be easy to implement. \\n\\nHowever\", \", you might also have entities that have a different shape but share the same identity across \\nthe m\", \"ultiple domain models from the multiple microservices. For example, the User entity is identified \\ni\", \"n the Conferences Management microservice. That same user, with the same identity, is the one \\nnamed\", \" Buyers in the Ordering microservice, or the one named Payer in the Payment microservice, and \\neven \", \"the one named Customer in the Customer Service microservice. This is because, depending on \\nthe ubiq\", \"uitous language that each domain expert is using, a user might have a different perspective \\neven wi\", \"th different attributes. The user entity in the microservice model named Conferences \\nManagement mig\", \"ht have most of its personal data attributes. However, that same user in the shape of \\nPayer in the \", \"microservice Payment or in the shape of Customer in the microservice Customer Service \\nmight not nee\", \"d the same list of attributes. \\n\\nA similar approach is illustrated in Figure 4-11. \\n\\n38 \\n\\nCHAPTER 3 \", \"| Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fFigure 4-11. Decomposing tradi\", \"tional data models into multiple domain models \\n\\nWhen decomposing a traditional data model between b\", \"ounded contexts, you can have different \\nentities that share the same identity (a buyer is also a us\", \"er) with different attributes in each bounded \\ncontext. You can see how the user is present in the C\", \"onferences Management microservice model as \\nthe User entity and is also present in the form of the \", \"Buyer entity in the Pricing microservice, with \\nalternate attributes or details about the user when \", \"it\\u2019s actually a buyer. Each microservice or BC might \\nnot need all the data related to a User entity\", \", just part of it, depending on the problem to solve or the \\ncontext. For instance, in the Pricing m\", \"icroservice model, you do not need the address or the name of \\nthe user, just the ID (as identity) a\", \"nd Status, which will have an impact on discounts when pricing the \\nseats per buyer. \\n\\nThe Seat enti\", \"ty has the same name but different attributes in each domain model. However, Seat \\nshares identity b\", \"ased on the same ID, as happens with User and Buyer. \\n\\nBasically, there\\u2019s a shared concept of a user\", \" that exists in multiple services (domains), which all share \\nthe identity of that user. But in each\", \" domain model there might be additional or different details \\nabout the user entity. Therefore, ther\", \"e needs to be a way to map a user entity from one domain \\n(microservice) to another. \\n\\nThere are sev\", \"eral benefits to not sharing the same user entity with the same number of attributes \\nacross domains\", \". One benefit is to reduce duplication, so that microservice models do not have any \\ndata that they \", \"do not need. Another benefit is having a primary microservice that owns a certain type \\nof data per \", \"entity so that updates and queries for that type of data are driven only by that \\nmicroservice. \\n\\n39\", \" \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fThe API gateway p\", \"attern versus the Direct client-to-\\nmicroservice communication \\n\\nIn a microservices architecture, ea\", \"ch microservice exposes a set of (typically) fine-grained endpoints. \\nThis fact can impact the clien\", \"t-to-microservice communication, as explained in this section. \\n\\nDirect client-to-microservice commu\", \"nication \\n\\nA possible approach is to use a direct client-to-microservice communication architecture.\", \" In this \\napproach, a client app can make requests directly to some of the microservices, as shown i\", \"n Figure 4-\\n12. \\n\\nFigure 4-12. Using a direct client-to-microservice communication architecture \\n\\nIn\", \" this approach, each microservice has a public endpoint, sometimes with a different TCP port for \\nea\", \"ch microservice. An example of a URL for a particular service could be the following URL in Azure: \\n\", \"\\nhttp://eshoponcontainers.westus.cloudapp.azure.com:88/ \\n\\nIn a production environment based on a clu\", \"ster, that URL would map to the load balancer used in the \\ncluster, which in turn distributes the re\", \"quests across the microservices. In production environments, \\nyou could have an Application Delivery\", \" Controller (ADC) like Azure Application Gateway between your \\nmicroservices and the Internet. This \", \"layer acts as a transparent tier that not only performs load \\nbalancing, but secures your services b\", \"y offering SSL termination. This approach improves the load of \\nyour hosts by offloading CPU-intensi\", \"ve SSL termination and other routing duties to the Azure \\nApplication Gateway. In any case, a load b\", \"alancer and ADC are transparent from a logical application \\narchitecture point of view. \\n\\nA direct c\", \"lient-to-microservice communication architecture could be good enough for a small \\nmicroservice-base\", \"d application, especially if the client app is a server-side web application like an \\nASP.NET MVC ap\", \"p. However, when you build large and complex microservice-based applications (for \\nexample, when han\", \"dling dozens of microservice types), and especially when the client apps are \\nremote mobile apps or \", \"SPA web applications, that approach faces a few issues. \\n\\n40 \\n\\nCHAPTER 3 | Architecting container an\", \"d microservice-based applications \\n\\n \\n \\n \\n\\fConsider the following questions when developing a large \", \"application based on microservices: \\n\\n\\u2022 \\n\\nHow can client apps minimize the number of requests to the\", \" back end and reduce chatty \\ncommunication to multiple microservices? \\n\\nInteracting with multiple mi\", \"croservices to build a single UI screen increases the number of round trips \\nacross the Internet. Th\", \"is approach increases latency and complexity on the UI side. Ideally, responses \\nshould be efficient\", \"ly aggregated in the server side. This approach reduces latency, since multiple \\npieces of data come\", \" back in parallel and some UI can show data as soon as it\\u2019s ready. \\n\\n\\u2022 \\n\\nHow can you handle cross-cu\", \"tting concerns such as authorization, data transformations, and \\ndynamic request dispatching? \\n\\nImpl\", \"ementing security and cross-cutting concerns like security and authorization on every \\nmicroservice \", \"can require significant development effort. A possible approach is to have those services \\nwithin th\", \"e Docker host or internal cluster to restrict direct access to them from the outside, and to \\nimplem\", \"ent those cross-cutting concerns in a centralized place, like an API Gateway. \\n\\n\\u2022 \\n\\nHow can client a\", \"pps communicate with services that use non-Internet-friendly protocols? \\n\\nProtocols used on the serv\", \"er side (like AMQP or binary protocols) are not supported in client apps. \\nTherefore, requests must \", \"be performed through protocols like HTTP/HTTPS and translated to the \\nother protocols afterwards. A \", \"man-in-the-middle approach can help in this situation. \\n\\n\\u2022 \\n\\nHow can you shape a facade especially m\", \"ade for mobile apps? \\n\\nThe API of multiple microservices might not be well designed for the needs of\", \" different client \\napplications. For instance, the needs of a mobile app might be different than the\", \" needs of a web app. \\nFor mobile apps, you might need to optimize even further so that data response\", \"s can be more \\nefficient. You might do this functionality by aggregating data from multiple microser\", \"vices and \\nreturning a single set of data, and sometimes eliminating any data in the response that i\", \"sn\\u2019t needed \\nby the mobile app. And, of course, you might compress that data. Again, a facade or API\", \" in between \\nthe mobile app and the microservices can be convenient for this scenario. \\n\\nWhy conside\", \"r API Gateways instead of direct client-to-microservice \\ncommunication \\n\\nIn a microservices architec\", \"ture, the client apps usually need to consume functionality from more than \\none microservice. If tha\", \"t consumption is performed directly, the client needs to handle multiple calls \\nto microservice endp\", \"oints. What happens when the application evolves and new microservices are \\nintroduced or existing m\", \"icroservices are updated? If your application has many microservices, \\nhandling so many endpoints fr\", \"om the client apps can be a nightmare. Since the client app would be \\ncoupled to those internal endp\", \"oints, evolving the microservices in the future can cause high impact \\nfor the client apps. \\n\\nTheref\", \"ore, having an intermediate level or tier of indirection (Gateway) can be convenient for \\nmicroservi\", \"ce-based applications. If you don\\u2019t have API Gateways, the client apps must send requests \\ndirectly \", \"to the microservices and that raises problems, such as the following issues: \\n\\n41 \\n\\nCHAPTER 3 | Arch\", \"itecting container and microservice-based applications \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCoupling: Without the \", \"API Gateway pattern, the client apps are coupled to the internal \\nmicroservices. The client apps nee\", \"d to know how the multiple areas of the application are \\ndecomposed in microservices. When evolving \", \"and refactoring the internal microservices, \\nthose actions impact maintenance because they cause bre\", \"aking changes to the client apps \\ndue to the direct reference to the internal microservices from the\", \" client apps. Client apps need \\nto be updated frequently, making the solution harder to evolve. \\n\\nTo\", \"o many round trips: A single page/screen in the client app might require several calls to \\nmultiple \", \"services. That approach can result in multiple network round trips between the client \\nand the serve\", \"r, adding significant latency. Aggregation handled in an intermediate level could \\nimprove the perfo\", \"rmance and user experience for the client app. \\n\\nSecurity issues: Without a gateway, all the microse\", \"rvices must be exposed to the \\u201cexternal \\nworld\\u201d, making the attack surface larger than if you hide i\", \"nternal microservices that aren\\u2019t \\ndirectly used by the client apps. The smaller the attack surface \", \"is, the more secure your \\napplication can be. \\n\\nCross-cutting concerns: Each publicly published micr\", \"oservice must handle concerns such as \\nauthorization and SSL. In many situations, those concerns cou\", \"ld be handled in a single tier so \\nthe internal microservices are simplified. \\n\\nWhat is the API Gate\", \"way pattern? \\n\\nWhen you design and build large or complex microservice-based applications with multi\", \"ple client \\napps, a good approach to consider can be an API Gateway. This pattern is a service that \", \"provides a \\nsingle-entry point for certain groups of microservices. It\\u2019s similar to the Facade patte\", \"rn from object-\\noriented design, but in this case, it\\u2019s part of a distributed system. The API Gatewa\", \"y pattern is also \\nsometimes known as the \\u201cbackend for frontend\\u201d (BFF) because you build it while th\", \"inking about the \\nneeds of the client app. \\n\\nTherefore, the API gateway sits between the client apps\", \" and the microservices. It acts as a reverse \\nproxy, routing requests from clients to services. It c\", \"an also provide other cross-cutting features such \\nas authentication, SSL termination, and cache. \\n\\n\", \"Figure 4-13 shows how a custom API Gateway can fit into a simplified microservice-based architecture\", \" \\nwith just a few microservices. \\n\\n42 \\n\\nCHAPTER 3 | Architecting container and microservice-based ap\", \"plications \\n\\n \\n \\n\\fFigure 4-13. Using an API Gateway implemented as a custom service \\n\\nApps connect t\", \"o a single endpoint, the API Gateway, that\\u2019s configured to forward requests to \\nindividual microserv\", \"ices. In this example, the API Gateway would be implemented as a custom \\nASP.NET Core WebHost servic\", \"e running as a container. \\n\\nIt\\u2019s important to highlight that in that diagram, you would be using a s\", \"ingle custom API Gateway \\nservice facing multiple and different client apps. That fact can be an imp\", \"ortant risk because your API \\nGateway service will be growing and evolving based on many different r\", \"equirements from the client \\napps. Eventually, it will be bloated because of those different needs a\", \"nd effectively it could be similar \\nto a monolithic application or monolithic service. That\\u2019s why it\", \"\\u2019s very much recommended to split the \\nAPI Gateway in multiple services or multiple smaller API Gate\", \"ways, one per client app form-factor \\ntype, for instance. \\n\\nYou need to be careful when implementing\", \" the API Gateway pattern. Usually it isn\\u2019t a good idea to \\nhave a single API Gateway aggregating all\", \" the internal microservices of your application. If it does, it \\nacts as a monolithic aggregator or \", \"orchestrator and violates microservice autonomy by coupling all \\nthe microservices. \\n\\nTherefore, the\", \" API Gateways should be segregated based on business boundaries and the client apps \\nand not act as \", \"a single aggregator for all the internal microservices. \\n\\nWhen splitting the API Gateway tier into m\", \"ultiple API Gateways, if your application has multiple client \\napps, that can be a primary pivot whe\", \"n identifying the multiple API Gateways types, so that you can \\nhave a different facade for the need\", \"s of each client app. This case is a pattern named \\u201cBackend for \\nFrontend\\u201d (BFF) where each API Gate\", \"way can provide a different API tailored for each client app type, \\npossibly even based on the clien\", \"t form factor by implementing specific adapter code which \\nunderneath calls multiple internal micros\", \"ervices, as shown in the following image: \\n\\n43 \\n\\nCHAPTER 3 | Architecting container and microservice\", \"-based applications \\n\\n \\n \\n \\n\\fFigure 4-13.1. Using multiple custom API Gateways \\n\\nFigure 4-13.1 shows\", \" API Gateways that are segregated by client type; one for mobile clients and one \\nfor web clients. A\", \" traditional web app connects to an MVC microservice that uses the web API \\nGateway. The example dep\", \"icts a simplified architecture with multiple fine-grained API Gateways. In \\nthis case, the boundarie\", \"s identified for each API Gateway are based purely on the \\u201cBackend for \\nFrontend\\u201d (BFF) pattern, hen\", \"ce based just on the API needed per client app. But in larger applications \\nyou should also go furth\", \"er and create other API Gateways based on business boundaries as a second \\ndesign pivot. \\n\\nMain feat\", \"ures in the API Gateway pattern \\n\\nAn API Gateway can offer multiple features. Depending on the produ\", \"ct it might offer richer or simpler \\nfeatures, however, the most important and foundational features\", \" for any API Gateway are the \\nfollowing design patterns: \\n\\nReverse proxy or gateway routing. The API\", \" Gateway offers a reverse proxy to redirect or route \\nrequests (layer 7 routing, usually HTTP reques\", \"ts) to the endpoints of the internal microservices. The \\ngateway provides a single endpoint or URL f\", \"or the client apps and then internally maps the requests \\nto a group of internal microservices. This\", \" routing feature helps to decouple the client apps from the \\nmicroservices but it\\u2019s also convenient \", \"when modernizing a monolithic API by sitting the API Gateway \\nin between the monolithic API and the \", \"client apps, then you can add new APIs as new microservices \\nwhile still using the legacy monolithic\", \" API until it\\u2019s split into many microservices in the future. Because \\nof the API Gateway, the client\", \" apps won\\u2019t notice if the APIs being used are implemented as internal \\nmicroservices or a monolithic\", \" API and more importantly, when evolving and refactoring the \\nmonolithic API into microservices, tha\", \"nks to the API Gateway routing, client apps won\\u2019t be impacted \\nwith any URI change. \\n\\n44 \\n\\nCHAPTER 3\", \" | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fFor more information, see Gat\", \"eway routing pattern. \\n\\nRequests aggregation. As part of the gateway pattern you can aggregate multi\", \"ple client requests \\n(usually HTTP requests) targeting multiple internal microservices into a single\", \" client request. This \\npattern is especially convenient when a client page/screen needs information \", \"from several \\nmicroservices. With this approach, the client app sends a single request to the API Ga\", \"teway that \\ndispatches several requests to the internal microservices and then aggregates the result\", \"s and sends \\neverything back to the client app. The main benefit and goal of this design pattern is \", \"to reduce \\nchattiness between the client apps and the backend API, which is especially important for\", \" remote \\napps out of the datacenter where the microservices live, like mobile apps or requests comin\", \"g from \\nSPA apps that come from JavaScript in client remote browsers. For regular web apps performin\", \"g the \\nrequests in the server environment (like an ASP.NET Core MVC web app), this pattern is not so\", \" \\nimportant as the latency is very much smaller than for remote client apps. \\n\\nDepending on the API \", \"Gateway product you use, it might be able to perform this aggregation. \\nHowever, in many cases it\\u2019s \", \"more flexible to create aggregation microservices under the scope of the \\nAPI Gateway, so you define\", \" the aggregation in code (that is, C# code): \\n\\nFor more information, see Gateway aggregation pattern\", \". \\n\\nCross-cutting concerns or gateway offloading. Depending on the features offered by each API \\nGat\", \"eway product, you can offload functionality from individual microservices to the gateway, which \\nsim\", \"plifies the implementation of each microservice by consolidating cross-cutting concerns into one \\nti\", \"er. This approach is especially convenient for specialized features that can be complex to implement\", \" \\nproperly in every internal microservice, such as the following functionality: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \", \"\\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAuthentication and authorization \\n\\nService discovery integration \\n\\nResponse cachin\", \"g \\n\\nRetry policies, circuit breaker, and QoS \\n\\nRate limiting and throttling \\n\\nLoad balancing \\n\\nLoggi\", \"ng, tracing, correlation \\n\\nHeaders, query strings, and claims transformation \\n\\nIP allowlisting \\n\\nFor\", \" more information, see Gateway offloading pattern. \\n\\nUsing products with API Gateway features \\n\\nTher\", \"e can be many more cross-cutting concerns offered by the API Gateways products depending on \\neach im\", \"plementation. We\\u2019ll explore here: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAzure API Management \\n\\nOcelot \\n\\n45 \\n\\nCHAPTER 3 | Archite\", \"cting container and microservice-based applications \\n\\n \\n \\n\\fAzure API Management \\n\\nAzure API Manageme\", \"nt (as shown in Figure 4-14) not only solves your API Gateway needs but \\nprovides features like gath\", \"ering insights from your APIs. If you\\u2019re using an API management solution, \\nan API Gateway is only a\", \" component within that full API management solution. \\n\\nFigure 4-14. Using Azure API Management for y\", \"our API Gateway \\n\\nAzure API Management solves both your API Gateway and Management needs like loggin\", \"g, security, \\nmetering, etc. In this case, when using a product like Azure API Management, the fact \", \"that you might \\nhave a single API Gateway is not so risky because these kinds of API Gateways are \\u201ct\", \"hinner\\u201d, meaning \\nthat you don\\u2019t implement custom C# code that could evolve towards a monolithic com\", \"ponent. \\n\\nThe API Gateway products usually act like a reverse proxy for ingress communication, where\", \" you can \\nalso filter the APIs from the internal microservices plus apply authorization to the publi\", \"shed APIs in \\nthis single tier. \\n\\nThe insights available from an API Management system help you get \", \"an understanding of how your \\nAPIs are being used and how they are performing. They do this activity\", \" by letting you view near real-\\ntime analytics reports and identifying trends that might impact your\", \" business. Plus, you can have logs \\nabout request and response activity for further online and offli\", \"ne analysis. \\n\\nWith Azure API Management, you can secure your APIs using a key, a token, and IP filt\", \"ering. These \\nfeatures let you enforce flexible and fine-grained quotas and rate limits, modify the \", \"shape and \\nbehavior of your APIs using policies, and improve performance with response caching. \\n\\nIn\", \" this guide and the reference sample application (eShopOnContainers), the architecture is limited to\", \" \\na simpler and custom-made containerized architecture in order to focus on plain containers without\", \" \\n\\n46 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fusing PaaS p\", \"roducts like Azure API Management. But for large microservice-based applications that \\nare deployed \", \"into Microsoft Azure, we encourage you to evaluate Azure API Management as the base \\nfor your API Ga\", \"teways in production. \\n\\nOcelot \\n\\nOcelot is a lightweight API Gateway, recommended for simpler approa\", \"ches. Ocelot is an Open Source \\n.NET Core-based API Gateway especially made for microservices archit\", \"ectures that need unified points \\nof entry into their systems. It\\u2019s lightweight, fast, and scalable \", \"and provides routing and authentication \\namong many other features. \\n\\nThe main reason to choose Ocel\", \"ot for the eShopOnContainers reference application 2.0 is because \\nOcelot is a .NET Core lightweight\", \" API Gateway that you can deploy into the same application \\ndeployment environment where you\\u2019re depl\", \"oying your microservices/containers, such as a Docker \\nHost, Kubernetes, etc. And since it\\u2019s based o\", \"n .NET Core, it\\u2019s cross-platform allowing you to deploy on \\nLinux or Windows. \\n\\nThe previous diagram\", \"s showing custom API Gateways running in containers are precisely how you can \\nalso run Ocelot in a \", \"container and microservice-based application. \\n\\nIn addition, there are many other products in the ma\", \"rket offering API Gateways features, such as \\nApigee, Kong, MuleSoft, WSO2, and other products like \", \"Linkerd and Istio for service mesh ingress \\ncontroller features. \\n\\nAfter the initial architecture an\", \"d patterns explanation sections, the next sections explain how to \\nimplement API Gateways with Ocelo\", \"t. \\n\\nDrawbacks of the API Gateway pattern \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThe most important drawback is that \", \"when you implement an API Gateway, you\\u2019re coupling \\nthat tier with the internal microservices. Coupl\", \"ing like this might introduce serious difficulties \\nfor your application. Clemens Vaster, architect \", \"at the Azure Service Bus team, refers to this \\npotential difficulty as \\u201cthe new ESB\\u201d in the \\u201cMessagi\", \"ng and Microservices\\u201d session at GOTO \\n2016. \\n\\nUsing a microservices API Gateway creates an addition\", \"al possible single point of failure. \\n\\nAn API Gateway can introduce increased response time due to t\", \"he additional network call. \\nHowever, this extra call usually has less impact than having a client i\", \"nterface that\\u2019s too chatty \\ndirectly calling the internal microservices. \\n\\nIf not scaled out properl\", \"y, the API Gateway can become a bottleneck. \\n\\nAn API Gateway requires additional development cost an\", \"d future maintenance if it includes \\ncustom logic and data aggregation. Developers must update the A\", \"PI Gateway in order to \\nexpose each microservice\\u2019s endpoints. Moreover, implementation changes in th\", \"e internal \\nmicroservices might cause code changes at the API Gateway level. However, if the API \\nGa\", \"teway is just applying security, logging, and versioning (as when using Azure API \\nManagement), this\", \" additional development cost might not apply. \\n\\n47 \\n\\nCHAPTER 3 | Architecting container and microser\", \"vice-based applications \\n\\n \\n \\n\\f\\u2022 \\n\\nIf the API Gateway is developed by a single team, there can be a \", \"development bottleneck. This \\naspect is another reason why a better approach is to have several fine\", \"d-grained API Gateways \\nthat respond to different client needs. You could also segregate the API Gat\", \"eway internally \\ninto multiple areas or layers that are owned by the different teams working on the \", \"internal \\nmicroservices. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nChris Richardson. Patt\", \"ern: API Gateway / Backend for Front-End \\nhttps://microservices.io/patterns/apigateway.html \\n\\nAPI Ga\", \"teway pattern \\nhttps://learn.microsoft.com/azure/architecture/microservices/gateway \\n\\nAggregation an\", \"d composition pattern \\nhttps://microservices.io/patterns/data/api-composition.html \\n\\nAzure API Manag\", \"ement \\nhttps://azure.microsoft.com/services/api-management/ \\n\\nUdi Dahan. Service Oriented Compositio\", \"n \\nhttps://udidahan.com/2014/07/30/service-oriented-composition-with-video/ \\n\\nClemens Vasters. Messa\", \"ging and Microservices at GOTO 2016 (video) \\nhttps://www.youtube.com/watch?v=rXi5CLjIQ9k \\n\\nAPI Gatew\", \"ay in a Nutshell (ASP.NET Core API Gateway Tutorial Series) \\nhttps://www.pogsdotnet.com/2018/08/api-\", \"gateway-in-nutshell.html \\n\\nCommunication in a microservice architecture \\n\\nIn a monolithic applicatio\", \"n running on a single process, components invoke one another using \\nlanguage-level method or functio\", \"n calls. These can be strongly coupled if you\\u2019re creating objects with \\ncode (for example, new Class\", \"Name()), or can be invoked in a decoupled way if you\\u2019re using \\nDependency Injection by referencing a\", \"bstractions rather than concrete object instances. Either way, \\nthe objects are running within the s\", \"ame process. The biggest challenge when changing from a \\nmonolithic application to a microservices-b\", \"ased application lies in changing the communication \\nmechanism. A direct conversion from in-process \", \"method calls into RPC calls to services will cause a \\nchatty and not efficient communication that wo\", \"n\\u2019t perform well in distributed environments. The \\nchallenges of designing distributed system proper\", \"ly are well enough known that there\\u2019s even a canon \\nknown as the Fallacies of distributed computing \", \"that lists assumptions that developers often make \\nwhen moving from monolithic to distributed design\", \"s. \\n\\nThere isn\\u2019t one solution, but several. One solution involves isolating the business microservic\", \"es as \\nmuch as possible. You then use asynchronous communication between the internal microservices \", \"and \\nreplace fine-grained communication that\\u2019s typical in intra-process communication between object\", \"s \\nwith coarser-grained communication. You can do this by grouping calls, and by returning data that\", \" \\naggregates the results of multiple internal calls, to the client. \\n\\n48 \\n\\nCHAPTER 3 | Architecting \", \"container and microservice-based applications \\n\\n \\n \\n\\fA microservices-based application is a distribu\", \"ted system running on multiple processes or services, \\nusually even across multiple servers or hosts\", \". Each service instance is typically a process. Therefore, \\nservices must interact using an inter-pr\", \"ocess communication protocol such as HTTP, AMQP, or a \\nbinary protocol like TCP, depending on the na\", \"ture of each service. \\n\\nThe microservice community promotes the philosophy of \\u201csmart endpoints and d\", \"umb pipes\\u201d. This \\nslogan encourages a design that\\u2019s as decoupled as possible between microservices, \", \"and as cohesive \\nas possible within a single microservice. As explained earlier, each microservice o\", \"wns its own data and \\nits own domain logic. But the microservices composing an end-to-end applicatio\", \"n are usually simply \\nchoreographed by using REST communications rather than complex protocols such \", \"as WS-* and \\nflexible event-driven communications instead of centralized business-process-orchestrat\", \"ors. \\n\\nThe two commonly used protocols are HTTP request/response with resource APIs (when querying \\n\", \"most of all), and lightweight asynchronous messaging when communicating updates across multiple \\nmic\", \"roservices. These are explained in more detail in the following sections. \\n\\nCommunication types \\n\\nCl\", \"ient and services can communicate through many different types of communication, each one \\ntargeting\", \" a different scenario and goals. Initially, those types of communications can be classified in \\ntwo \", \"axes. \\n\\nThe first axis defines if the protocol is synchronous or asynchronous: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nSynchronous\", \" protocol. HTTP is a synchronous protocol. The client sends a request and waits \\nfor a response from\", \" the service. That\\u2019s independent of the client code execution that could be \\nsynchronous (thread is \", \"blocked) or asynchronous (thread isn\\u2019t blocked, and the response will \\nreach a callback eventually).\", \" The important point here is that the protocol (HTTP/HTTPS) is \\nsynchronous and the client code can \", \"only continue its task when it receives the HTTP server \\nresponse. \\n\\nAsynchronous protocol. Other pr\", \"otocols like AMQP (a protocol supported by many operating \\nsystems and cloud environments) use async\", \"hronous messages. The client code or message \\nsender usually doesn\\u2019t wait for a response. It just se\", \"nds the message as when sending a \\nmessage to a RabbitMQ queue or any other message broker. \\n\\nThe se\", \"cond axis defines if the communication has a single receiver or multiple receivers: \\n\\n\\u2022 \\n\\nSingle rec\", \"eiver. Each request must be processed by exactly one receiver or service. An \\nexample of this commun\", \"ication is the Command pattern. \\n\\n\\u2022  Multiple receivers. Each request can be processed by zero to mu\", \"ltiple receivers. This type of \\n\\ncommunication must be asynchronous. An example is the publish/subsc\", \"ribe mechanism used \\nin patterns like Event-driven architecture. This is based on an event-bus inter\", \"face or message \\nbroker when propagating data updates between multiple microservices through events;\", \" it\\u2019s \\nusually implemented through a service bus or similar artifact like Azure Service Bus by using\", \" \\ntopics and subscriptions. \\n\\n49 \\n\\nCHAPTER 3 | Architecting container and microservice-based applica\", \"tions \\n\\n \\n \\n\\fA microservice-based application will often use a combination of these communication st\", \"yles. The \\nmost common type is single-receiver communication with a synchronous protocol like HTTP/H\", \"TTPS \\nwhen invoking a regular Web API HTTP service. Microservices also typically use messaging proto\", \"cols \\nfor asynchronous communication between microservices. \\n\\nThese axes are good to know so you hav\", \"e clarity on the possible communication mechanisms, but \\nthey\\u2019re not the important concerns when bui\", \"lding microservices. Neither the asynchronous nature of \\nclient thread execution nor the asynchronou\", \"s nature of the selected protocol are the important points \\nwhen integrating microservices. What is \", \"important is being able to integrate your microservices \\nasynchronously while maintaining the indepe\", \"ndence of microservices, as explained in the following \\nsection. \\n\\nAsynchronous microservice integra\", \"tion enforces microservice\\u2019s \\nautonomy \\n\\nAs mentioned, the important point when building a microserv\", \"ices-based application is the way you \\nintegrate your microservices. Ideally, you should try to mini\", \"mize the communication between the \\ninternal microservices. The fewer communications between microse\", \"rvices, the better. But in many \\ncases, you\\u2019ll have to somehow integrate the microservices. When you\", \" need to do that, the critical rule \\nhere is that the communication between the microservices should\", \" be asynchronous. That doesn\\u2019t \\nmean that you have to use a specific protocol (for example, asynchro\", \"nous messaging versus \\nsynchronous HTTP). It just means that the communication between microservices\", \" should be done only \\nby propagating data asynchronously, but try not to depend on other internal mi\", \"croservices as part of \\nthe initial service\\u2019s HTTP request/response operation. \\n\\nIf possible, never \", \"depend on synchronous communication (request/response) between multiple \\nmicroservices, not even for\", \" queries. The goal of each microservice is to be autonomous and available \\nto the client consumer, e\", \"ven if the other services that are part of the end-to-end application are down \\nor unhealthy. If you\", \" think you need to make a call from one microservice to other microservices (like \\nperforming an HTT\", \"P request for a data query) to be able to provide a response to a client application, \\nyou have an a\", \"rchitecture that won\\u2019t be resilient when some microservices fail. \\n\\nMoreover, having HTTP dependenci\", \"es between microservices, like when creating long \\nrequest/response cycles with HTTP request chains,\", \" as shown in the first part of the Figure 4-15, not \\nonly makes your microservices not autonomous bu\", \"t also their performance is impacted as soon as \\none of the services in that chain isn\\u2019t performing \", \"well. \\n\\nThe more you add synchronous dependencies between microservices, such as query requests, the\", \" \\nworse the overall response time gets for the client apps. \\n\\n50 \\n\\nCHAPTER 3 | Architecting containe\", \"r and microservice-based applications \\n\\n \\n \\n\\fFigure 4-15. Anti-patterns and patterns in communicatio\", \"n between microservices \\n\\nAs shown in the above diagram, in synchronous communication a \\u201cchain\\u201d of r\", \"equests is created \\nbetween microservices while serving the client request. This is an anti-pattern.\", \" In asynchronous \\ncommunication microservices use asynchronous messages or http polling to communica\", \"te with other \\nmicroservices, but the client request is served right away. \\n\\nIf your microservice ne\", \"eds to raise an additional action in another microservice, if possible, do not \\nperform that action \", \"synchronously and as part of the original microservice request and reply \\noperation. Instead, do it \", \"asynchronously (using asynchronous messaging or integration events, \\nqueues, etc.). But, as much as \", \"possible, do not invoke the action synchronously as part of the original \\nsynchronous request and re\", \"ply operation. \\n\\nAnd finally (and this is where most of the issues arise when building microservices\", \"), if your initial \\nmicroservice needs data that\\u2019s originally owned by other microservices, do not r\", \"ely on making \\nsynchronous requests for that data. Instead, replicate or propagate that data (only t\", \"he attributes you \\nneed) into the initial service\\u2019s database by using eventual consistency (typicall\", \"y by using integration \\nevents, as explained in upcoming sections). \\n\\nAs noted earlier in the Identi\", \"fying domain-model boundaries for each microservice section, \\nduplicating some data across several m\", \"icroservices isn\\u2019t an incorrect design\\u2014on the contrary, when \\ndoing that you can translate the data \", \"into the specific language or terms of that additional domain or \\nBounded Context. For instance, in \", \"the eShopOnContainers application you have a microservice named \\nidentity-api that\\u2019s in charge of mo\", \"st of the user\\u2019s data with an entity named User. However, when you \\nneed to store data about the use\", \"r within the Ordering microservice, you store it as a different entity \\nnamed Buyer. The Buyer entit\", \"y shares the same identity with the original User entity, but it might have \\nonly the few attributes\", \" needed by the Ordering domain, and not the whole user profile. \\n\\n51 \\n\\nCHAPTER 3 | Architecting cont\", \"ainer and microservice-based applications \\n\\n \\n \\n \\n\\fYou might use any protocol to communicate and pro\", \"pagate data asynchronously across microservices \\nin order to have eventual consistency. As mentioned\", \", you could use integration events using an event \\nbus or message broker or you could even use HTTP \", \"by polling the other services instead. It doesn\\u2019t \\nmatter. The important rule is to not create synch\", \"ronous dependencies between your microservices. \\n\\nThe following sections explain the multiple commun\", \"ication styles you can consider using in a \\nmicroservice-based application. \\n\\nCommunication styles \\n\", \"\\nThere are many protocols and choices you can use for communication, depending on the \\ncommunication\", \" type you want to use. If you\\u2019re using a synchronous request/response-based \\ncommunication mechanism\", \", protocols such as HTTP and REST approaches are the most common, \\nespecially if you\\u2019re publishing y\", \"our services outside the Docker host or microservice cluster. If you\\u2019re \\ncommunicating between servi\", \"ces internally (within your Docker host or microservices cluster), you \\nmight also want to use binar\", \"y format communication mechanisms (like WCF using TCP and binary \\nformat). Alternatively, you can us\", \"e asynchronous, message-based communication mechanisms such as \\nAMQP. \\n\\nThere are also multiple mess\", \"age formats like JSON or XML, or even binary formats, which can be more \\nefficient. If your chosen b\", \"inary format isn\\u2019t a standard, it\\u2019s probably not a good idea to publicly \\npublish your services usin\", \"g that format. You could use a non-standard format for internal \\ncommunication between your microser\", \"vices. You might do this when communicating between \\nmicroservices within your Docker host or micros\", \"ervice cluster (for example, Docker orchestrators), or \\nfor proprietary client applications that tal\", \"k to the microservices. \\n\\nRequest/response communication with HTTP and REST \\n\\nWhen a client uses req\", \"uest/response communication, it sends a request to a service, then the service \\nprocesses the reques\", \"t and sends back a response. Request/response communication is especially well \\nsuited for querying \", \"data for a real-time UI (a live user interface) from client apps. Therefore, in a \\nmicroservice arch\", \"itecture you\\u2019ll probably use this communication mechanism for most queries, as \\nshown in Figure 4-16\", \". \\n\\nFigure 4-16. Using HTTP request/response communication (synchronous or asynchronous) \\n\\n52 \\n\\nCHAP\", \"TER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fWhen a client uses reque\", \"st/response communication, it assumes that the response will arrive in a \\nshort time, typically less\", \" than a second, or a few seconds at most. For delayed responses, you need to \\nimplement asynchronous\", \" communication based on messaging patterns and messaging technologies, \\nwhich is a different approac\", \"h that we explain in the next section. \\n\\nA popular architectural style for request/response communic\", \"ation is REST. This approach is based on, \\nand tightly coupled to, the HTTP protocol, embracing HTTP\", \" verbs like GET, POST, and PUT. REST is the \\nmost commonly used architectural communication approach\", \" when creating services. You can \\nimplement REST services when you develop ASP.NET Core Web API serv\", \"ices. \\n\\nThere\\u2019s additional value when using HTTP REST services as your interface definition language\", \". For \\ninstance, if you use Swagger metadata to describe your service API, you can use tools that ge\", \"nerate \\nclient stubs that can directly discover and consume your services. \\n\\nAdditional resources \\n\\n\", \"\\u2022  Martin Fowler. Richardson Maturity Model A description of the REST model. \\n\\nhttps://martinfowler.\", \"com/articles/richardsonMaturityModel.html \\n\\n\\u2022 \\n\\nSwagger The official site. \\nhttps://swagger.io/ \\n\\nPu\", \"sh and real-time communication based on HTTP \\n\\nAnother possibility (usually for different purposes t\", \"han REST) is a real-time and one-to-many \\ncommunication with higher-level frameworks such as ASP.NET\", \" SignalR and protocols such as \\nWebSockets. \\n\\nAs Figure 4-17 shows, real-time HTTP communication mea\", \"ns that you can have server code pushing \\ncontent to connected clients as the data becomes available\", \", rather than having the server wait for a \\nclient to request new data. \\n\\n53 \\n\\nCHAPTER 3 | Architect\", \"ing container and microservice-based applications \\n\\n \\n \\n\\fFigure 4-17. One-to-many real-time asynchro\", \"nous message communication \\n\\nSignalR is a good way to achieve real-time communication for pushing co\", \"ntent to the clients from a \\nback-end server. Since communication is in real time, client apps show \", \"the changes almost instantly. \\nThis is usually handled by a protocol such as WebSockets, using many \", \"WebSockets connections (one \\nper client). A typical example is when a service communicates a change \", \"in the score of a sports game \\nto many client web apps simultaneously. \\n\\nAsynchronous message-based \", \"communication \\n\\nAsynchronous messaging and event-driven communication are critical when propagating \", \"changes \\nacross multiple microservices and their related domain models. As mentioned earlier in the \", \"discussion \\nmicroservices and Bounded Contexts (BCs), models (User, Customer, Product, Account, etc.\", \") can mean \\ndifferent things to different microservices or BCs. That means that when changes occur, \", \"you need \\nsome way to reconcile changes across the different models. A solution is eventual consiste\", \"ncy and \\nevent-driven communication based on asynchronous messaging. \\n\\nWhen using messaging, process\", \"es communicate by exchanging messages asynchronously. A client \\nmakes a command or a request to a se\", \"rvice by sending it a message. If the service needs to reply, it \\nsends a different message back to \", \"the client. Since it\\u2019s a message-based communication, the client \\nassumes that the reply won\\u2019t be re\", \"ceived immediately, and that there might be no response at all. \\n\\nA message is composed by a header \", \"(metadata such as identification or security information) and a \\nbody. Messages are usually sent thr\", \"ough asynchronous protocols like AMQP. \\n\\nThe preferred infrastructure for this type of communication\", \" in the microservices community is a \\nlightweight message broker, which is different than the large \", \"brokers and orchestrators used in SOA. \\nIn a lightweight message broker, the infrastructure is typic\", \"ally \\u201cdumb,\\u201d acting only as a message \\nbroker, with simple implementations such as RabbitMQ or a sca\", \"lable service bus in the cloud like \\n\\n54 \\n\\nCHAPTER 3 | Architecting container and microservice-based\", \" applications \\n\\n \\n \\n \\n\\fAzure Service Bus. In this scenario, most of the \\u201csmart\\u201d thinking still lives\", \" in the endpoints that are \\nproducing and consuming messages-that is, in the microservices. \\n\\nAnothe\", \"r rule you should try to follow, as much as possible, is to use only asynchronous messaging \\nbetween\", \" the internal services, and to use synchronous communication (such as HTTP) only from the \\nclient ap\", \"ps to the front-end services (API Gateways plus the first level of microservices). \\n\\nThere are two k\", \"inds of asynchronous messaging communication: single receiver message-based \\ncommunication, and mult\", \"iple receivers message-based communication. The following sections \\nprovide details about them. \\n\\nSi\", \"ngle-receiver message-based communication \\n\\nMessage-based asynchronous communication with a single r\", \"eceiver means there\\u2019s point-to-point \\ncommunication that delivers a message to exactly one of the co\", \"nsumers that\\u2019s reading from the \\nchannel, and that the message is processed just once. However, ther\", \"e are special situations. For \\ninstance, in a cloud system that tries to automatically recover from \", \"failures, the same message could \\nbe sent multiple times. Due to network or other failures, the clie\", \"nt has to be able to retry sending \\nmessages, and the server has to implement an operation to be ide\", \"mpotent in order to process a \\nparticular message just once. \\n\\nSingle-receiver message-based communi\", \"cation is especially well suited for sending asynchronous \\ncommands from one microservice to another\", \" as shown in Figure 4-18 that illustrates this approach. \\n\\nOnce you start sending message-based comm\", \"unication (either with commands or events), you should \\navoid mixing message-based communication wit\", \"h synchronous HTTP communication. \\n\\nFigure 4-18. A single microservice receiving an asynchronous mes\", \"sage \\n\\n55 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fWhen the\", \" commands come from client applications, they can be implemented as HTTP synchronous \\ncommands. Use \", \"message-based commands when you need higher scalability or when you\\u2019re already \\nin a message-based b\", \"usiness process. \\n\\nMultiple-receivers message-based communication \\n\\nAs a more flexible approach, you\", \" might also want to use a publish/subscribe mechanism so that your \\ncommunication from the sender wi\", \"ll be available to additional subscriber microservices or to external \\napplications. Thus, it helps \", \"you to follow the open/closed principle in the sending service. That way, \\nadditional subscribers ca\", \"n be added in the future without the need to modify the sender service. \\n\\nWhen you use a publish/sub\", \"scribe communication, you might be using an event bus interface to \\npublish events to any subscriber\", \". \\n\\nAsynchronous event-driven communication \\n\\nWhen using asynchronous event-driven communication, a \", \"microservice publishes an integration event \\nwhen something happens within its domain and another mi\", \"croservice needs to be aware of it, like a \\nprice change in a product catalog microservice. Addition\", \"al microservices subscribe to the events so \\nthey can receive them asynchronously. When that happens\", \", the receivers might update their own \\ndomain entities, which can cause more integration events to \", \"be published. This publish/subscribe \\nsystem is performed by using an implementation of an event bus\", \". The event bus can be designed as \\nan abstraction or interface, with the API that\\u2019s needed to subsc\", \"ribe or unsubscribe to events and to \\npublish events. The event bus can also have one or more implem\", \"entations based on any inter-process \\nand messaging broker, like a messaging queue or service bus th\", \"at supports asynchronous \\ncommunication and a publish/subscribe model. \\n\\nIf a system uses eventual c\", \"onsistency driven by integration events, it\\u2019s recommended that this \\napproach is made clear to the e\", \"nd user. The system shouldn\\u2019t use an approach that mimics \\nintegration events, like SignalR or polli\", \"ng systems from the client. The end user and the business \\nowner have to explicitly embrace eventual\", \" consistency in the system and realize that in many cases \\nthe business doesn\\u2019t have any problem wit\", \"h this approach, as long as it\\u2019s explicit. This approach is \\nimportant because users might expect to\", \" see some results immediately and this aspect might not \\nhappen with eventual consistency. \\n\\nAs note\", \"d earlier in the Challenges and solutions for distributed data management section, you can use \\ninte\", \"gration events to implement business tasks that span multiple microservices. Thus, you\\u2019ll have \\neven\", \"tual consistency between those services. An eventually consistent transaction is made up of a \\ncolle\", \"ction of distributed actions. At each action, the related microservice updates a domain entity and \\n\", \"publishes another integration event that raises the next action within the same end-to-end business \", \"\\ntask. \\n\\nAn important point is that you might want to communicate to multiple microservices that are\", \" \\nsubscribed to the same event. To do so, you can use publish/subscribe messaging based on event-\\ndr\", \"iven communication, as shown in Figure 4-19. This publish/subscribe mechanism isn\\u2019t exclusive to \\nth\", \"e microservice architecture. It\\u2019s similar to the way Bounded Contexts in DDD should communicate, \\nor\", \" to the way you propagate updates from the write database to the read database in the Command \\n\\n56 \\n\", \"\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fand Query Responsibil\", \"ity Segregation (CQRS) architecture pattern. The goal is to have eventual \\nconsistency between multi\", \"ple data sources across your distributed system. \\n\\nFigure 4-19. Asynchronous event-driven message co\", \"mmunication \\n\\nIn asynchronous event-driven communication, one microservice publishes events to an ev\", \"ent bus and \\nmany microservices can subscribe to it, to get notified and act on it. Your implementat\", \"ion will \\ndetermine what protocol to use for event-driven, message-based communications. AMQP can he\", \"lp \\nachieve reliable queued communication. \\n\\nWhen you use an event bus, you might want to use an abs\", \"traction level (like an event bus interface) \\nbased on a related implementation in classes with code\", \" using the API from a message broker like \\nRabbitMQ or a service bus like Azure Service Bus with Top\", \"ics. Alternatively, you might want to use a \\nhigher-level service bus like NServiceBus, MassTransit,\", \" or Brighter to articulate your event bus and \\npublish/subscribe system. \\n\\nA note about messaging te\", \"chnologies for production systems \\n\\nThe messaging technologies available for implementing your abstr\", \"act event bus are at different levels. \\nFor instance, products like RabbitMQ (a messaging broker tra\", \"nsport) and Azure Service Bus sit at a \\nlower level than other products like NServiceBus, MassTransi\", \"t, or Brighter, which can work on top of \\nRabbitMQ and Azure Service Bus. Your choice depends on how\", \" many rich features at the application \\nlevel and out-of-the-box scalability you need for your appli\", \"cation. For implementing just a proof-of-\\nconcept event bus for your development environment, as it \", \"was done in the eShopOnContainers \\nsample, a simple implementation on top of RabbitMQ running on a D\", \"ocker container might be \\nenough. \\n\\nHowever, for mission-critical and production systems that need h\", \"yper-scalability, you might want to \\nevaluate Azure Service Bus. For high-level abstractions and fea\", \"tures that make the development of \\ndistributed applications easier, we recommend that you evaluate \", \"other commercial and open-source \\nservice buses, such as NServiceBus, MassTransit, and Brighter. Of \", \"course, you can build your own \\n\\n57 \\n\\nCHAPTER 3 | Architecting container and microservice-based appl\", \"ications \\n\\n \\n \\n \\n\\fservice-bus features on top of lower-level technologies like RabbitMQ and Docker. \", \"But that plumbing \\nwork might cost too much for a custom enterprise application. \\n\\nResiliently publi\", \"shing to the event bus \\n\\nA challenge when implementing an event-driven architecture across multiple \", \"microservices is how to \\natomically update state in the original microservice while resiliently publ\", \"ishing its related integration \\nevent into the event bus, somehow based on transactions. The followi\", \"ng are a few ways to accomplish \\nthis functionality, although there could be additional approaches a\", \"s well. \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUsing a transactional (DTC-based) queue like MSMQ. (However, this is a leg\", \"acy approach.) \\n\\nUsing transaction log mining. \\n\\nUsing full Event Sourcing pattern. \\n\\nUsing the Outb\", \"ox pattern: a transactional database table as a message queue that will be the \\nbase for an event-cr\", \"eator component that would create the event and publish it. \\n\\nFor a more complete description of the\", \" challenges in this space, including how messages with \\npotentially incorrect data can end up being \", \"published, see Data platform for mission-critical \\nworkloads on Azure: Every message must be process\", \"ed. \\n\\nAdditional topics to consider when using asynchronous communication are message idempotence \\na\", \"nd message deduplication. These topics are covered in the section Implementing event-based \\ncommunic\", \"ation between microservices (integration events) later in this guide. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022\", \" \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEvent Driven Messaging \\nhttps://patterns.arcitura.com/soa-patterns/design_pat\", \"terns/event_driven_messaging \\n\\nPublish/Subscribe Channel \\nhttps://www.enterpriseintegrationpatterns.\", \"com/patterns/messaging/PublishSubscribeChannel.\\nhtml \\n\\nUdi Dahan. Clarified CQRS \\nhttps://udidahan.c\", \"om/2009/12/09/clarified-cqrs/ \\n\\nCommand and Query Responsibility Segregation (CQRS) \\nhttps://learn.m\", \"icrosoft.com/azure/architecture/patterns/cqrs \\n\\nCommunicating Between Bounded Contexts \\nhttps://lear\", \"n.microsoft.com/previous-versions/msp-n-p/jj591572(v=pandp.10) \\n\\nEventual consistency \\nhttps://en.wi\", \"kipedia.org/wiki/Eventual_consistency \\n\\nJimmy Bogard. Refactoring Towards Resilience: Evaluating Cou\", \"pling \\nhttps://jimmybogard.com/refactoring-towards-resilience-evaluating-coupling/ \\n\\n58 \\n\\nCHAPTER 3 \", \"| Architecting container and microservice-based applications \\n\\n \\n \\n\\fCreating, evolving, and versioni\", \"ng microservice APIs \\nand contracts \\n\\nA microservice API is a contract between the service and its c\", \"lients. You\\u2019ll be able to evolve a \\nmicroservice independently only if you do not break its API cont\", \"ract, which is why the contract is so \\nimportant. If you change the contract, it will impact your cl\", \"ient applications or your API Gateway. \\n\\nThe nature of the API definition depends on which protocol \", \"you\\u2019re using. For instance, if you\\u2019re using \\nmessaging, like AMQP, the API consists of the message t\", \"ypes. If you\\u2019re using HTTP and RESTful \\nservices, the API consists of the URLs and the request and r\", \"esponse JSON formats. \\n\\nHowever, even if you\\u2019re thoughtful about your initial contract, a service AP\", \"I will need to change over \\ntime. When that happens\\u2014and especially if your API is a public API consu\", \"med by multiple client \\napplications \\u2014 you typically can\\u2019t force all clients to upgrade to your new \", \"API contract. You usually \\nneed to incrementally deploy new versions of a service in a way that both\", \" old and new versions of a \\nservice contract are running simultaneously. Therefore, it\\u2019s important t\", \"o have a strategy for your \\nservice versioning. \\n\\nWhen the API changes are small, like if you add at\", \"tributes or parameters to your API, clients that use \\nan older API should switch and work with the n\", \"ew version of the service. You might be able to provide \\ndefault values for any missing attributes t\", \"hat are required, and the clients might be able to ignore any \\nextra response attributes. \\n\\nHowever,\", \" sometimes you need to make major and incompatible changes to a service API. Because \\nyou might not \", \"be able to force client applications or services to upgrade immediately to the new \\nversion, a servi\", \"ce must support older versions of the API for some period. If you\\u2019re using an HTTP-\\nbased mechanism \", \"such as REST, one approach is to embed the API version number in the URL or into \\nan HTTP header. Th\", \"en you can decide between implementing both versions of the service \\nsimultaneously within the same \", \"service instance, or deploying different instances that each handle a \\nversion of the API. A good ap\", \"proach for this functionality is the Mediator pattern (for example, \\nMediatR library) to decouple th\", \"e different implementation versions into independent handlers. \\n\\nFinally, if you\\u2019re using a REST arc\", \"hitecture, Hypermedia is the best solution for versioning your services \\nand allowing evolvable APIs\", \". \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nScott Hanselman. ASP.NET Core RESTful Web API versioning made\", \" easy \\nhttps://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx \\n\\nVersioning a \", \"RESTful web API \\nhttps://learn.microsoft.com/azure/architecture/best-practices/api-design#versioning\", \"-a-\\nrestful-web-api \\n\\nRoy Fielding. Versioning, Hypermedia, and REST \\nhttps://www.infoq.com/articles\", \"/roy-fielding-on-versioning \\n\\n59 \\n\\nCHAPTER 3 | Architecting container and microservice-based applica\", \"tions \\n\\n \\n \\n\\fMicroservices addressability and the service registry \\n\\nEach microservice has a unique \", \"name (URL) that\\u2019s used to resolve its location. Your microservice needs \\nto be addressable wherever \", \"it\\u2019s running. If you have to think about which computer is running a \\nparticular microservice, thing\", \"s can go bad quickly. In the same way that DNS resolves a URL to a \\nparticular computer, your micros\", \"ervice needs to have a unique name so that its current location is \\ndiscoverable. Microservices need\", \" addressable names that make them independent from the \\ninfrastructure that they\\u2019re running on. This\", \" approach implies that there\\u2019s an interaction between how \\nyour service is deployed and how it\\u2019s dis\", \"covered, because there needs to be a service registry. In the \\nsame vein, when a computer fails, the\", \" registry service must be able to indicate where the service is \\nnow running. \\n\\nThe service registry\", \" pattern is a key part of service discovery. The registry is a database containing the \\nnetwork loca\", \"tions of service instances. A service registry needs to be highly available and up-to-date. \\nClients\", \" could cache network locations obtained from the service registry. However, that information \\neventu\", \"ally goes out of date and clients can no longer discover service instances. So, a service registry \\n\", \"consists of a cluster of servers that use a replication protocol to maintain consistency. \\n\\nIn some \", \"microservice deployment environments (called clusters, to be covered in a later section), \\nservice d\", \"iscovery is built in. For example, an Azure Kubernetes Service (AKS) environment can handle \\nservice\", \" instance registration and deregistration. It also runs a proxy on each cluster host that plays the \", \"\\nrole of server-side discovery router. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nChris Richardson. Patter\", \"n: Service registry \\nhttps://microservices.io/patterns/service-registry.html \\n\\nAuth0. The Service Re\", \"gistry \\nhttps://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-registry/ \\n\\nGabri\", \"el Schenker. Service discovery \\nhttps://lostechies.com/gabrielschenker/2016/01/27/service-discovery/\", \" \\n\\nCreating composite UI based on microservices \\n\\nMicroservices architecture often starts with the s\", \"erver-side handling data and logic, but, in many \\ncases, the UI is still handled as a monolith. Howe\", \"ver, a more advanced approach, called micro \\nfrontends, is to design your application UI based on mi\", \"croservices as well. That means having a \\ncomposite UI produced by the microservices, instead of hav\", \"ing microservices on the server and just a \\nmonolithic client app consuming the microservices. With \", \"this approach, the microservices you build \\ncan be complete with both logic and visual representatio\", \"n. \\n\\nFigure 4-20 shows the simpler approach of just consuming microservices from a monolithic client\", \" \\napplication. Of course, you could have an ASP.NET MVC service in between producing the HTML and \\nJ\", \"avaScript. The figure is a simplification that highlights that you have a single (monolithic) client\", \" UI \\n\\n60 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fconsuming t\", \"he microservices, which just focus on logic and data and not on the UI shape (HTML and \\nJavaScript).\", \" \\n\\nFigure 4-20. A monolithic UI application consuming back-end microservices \\n\\nIn contrast, a compos\", \"ite UI is precisely generated and composed by the microservices themselves. \\nSome of the microservic\", \"es drive the visual shape of specific areas of the UI. The key difference is that \\nyou have client U\", \"I components (TypeScript classes, for example) based on templates, and the data-\\nshaping-UI ViewMode\", \"l for those templates comes from each microservice. \\n\\nAt client application start-up time, each of t\", \"he client UI components (TypeScript classes, for example) \\nregisters itself with an infrastructure m\", \"icroservice capable of providing ViewModels for a given \\nscenario. If the microservice changes the s\", \"hape, the UI changes also. \\n\\nFigure 4-21 shows a version of this composite UI approach. This approac\", \"h is simplified because you \\nmight have other microservices that are aggregating granular parts that\", \" are based on different \\ntechniques. It depends on whether you\\u2019re building a traditional web approac\", \"h (ASP.NET MVC) or an \\nSPA (Single Page Application). \\n\\n61 \\n\\nCHAPTER 3 | Architecting container and \", \"microservice-based applications \\n\\n \\n \\n \\n\\fFigure 4-21. Example of a composite UI application shaped b\", \"y back-end microservices \\n\\nEach of those UI composition microservices would be similar to a small AP\", \"I Gateway. But in this case, \\neach one is responsible for a small UI area. \\n\\nA composite UI approach\", \" that\\u2019s driven by microservices can be more challenging or less so, \\ndepending on what UI technologi\", \"es you\\u2019re using. For instance, you won\\u2019t use the same techniques for \\nbuilding a traditional web app\", \"lication that you use for building an SPA or for native mobile app (as \\nwhen developing Xamarin apps\", \", which can be more challenging for this approach). \\n\\nThe eShopOnContainers sample application uses \", \"the monolithic UI approach for multiple reasons. \\nFirst, it\\u2019s an introduction to microservices and c\", \"ontainers. A composite UI is more advanced but also \\nrequires further complexity when designing and \", \"developing the UI. Second, eShopOnContainers also \\nprovides a native mobile app based on Xamarin, wh\", \"ich would make it more complex on the client C# \\nside. \\n\\nHowever, we encourage you to use the follow\", \"ing references to learn more about composite UI based \\non microservices. \\n\\nAdditional resources \\n\\n\\u2022 \", \" Micro Frontends (Martin Fowler\\u2019s blog) \\n\\nhttps://martinfowler.com/articles/micro-frontends.html \\n\\n\\u2022\", \"  Micro Frontends (Michael Geers site) \\n\\nhttps://micro-frontends.org/ \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n62 \\n\\nComposite UI us\", \"ing ASP.NET (Particular\\u2019s Workshop) \\nhttps://github.com/Particular/Workshop/tree/master/demos/asp-ne\", \"t-core \\n\\nRuben Oostinga. The Monolithic Frontend in the Microservices Architecture \\nhttps://xebia.co\", \"m/blog/the-monolithic-frontend-in-the-microservices-architecture/ \\n\\nCHAPTER 3 | Architecting contain\", \"er and microservice-based applications \\n\\n \\n \\n \\n\\f\\u2022  Mauro Servienti. The secret of better UI composit\", \"ion \\n\\nhttps://particular.net/blog/secret-of-better-ui-composition \\n\\n\\u2022 \\n\\nViktor Farcic. Including Fro\", \"nt-End Web Components Into Microservices \\nhttps://technologyconversations.com/2015/08/09/including-f\", \"ront-end-web-components-\\ninto-microservices/ \\n\\n\\u2022  Managing Frontend in the Microservices Architectur\", \"e \\n\\nhttps://allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html \\n\\nResilien\", \"cy and high availability in microservices \\n\\nDealing with unexpected failures is one of the hardest p\", \"roblems to solve, especially in a distributed \\nsystem. Much of the code that developers write involv\", \"es handling exceptions, and this is also where \\nthe most time is spent in testing. The problem is mo\", \"re involved than writing code to handle failures. \\nWhat happens when the machine where the microserv\", \"ice is running fails? Not only do you need to \\ndetect this microservice failure (a hard problem on i\", \"ts own), but you also need something to restart \\nyour microservice. \\n\\nA microservice needs to be res\", \"ilient to failures and to be able to restart often on another machine for \\navailability. This resili\", \"ency also comes down to the state that was saved on behalf of the microservice, \\nwhere the microserv\", \"ice can recover this state from, and whether the microservice can restart \\nsuccessfully. In other wo\", \"rds, there needs to be resiliency in the compute capability (the process can \\nrestart at any time) a\", \"s well as resilience in the state or data (no data loss, and the data remains \\nconsistent). \\n\\nThe pr\", \"oblems of resiliency are compounded during other scenarios, such as when failures occur \\nduring an a\", \"pplication upgrade. The microservice, working with the deployment system, needs to \\ndetermine whethe\", \"r it can continue to move forward to the newer version or instead roll back to a \\nprevious version t\", \"o maintain a consistent state. Questions such as whether enough machines are \\navailable to keep movi\", \"ng forward and how to recover previous versions of the microservice need to \\nbe considered. This app\", \"roach requires the microservice to emit health information so that the overall \\napplication and orch\", \"estrator can make these decisions. \\n\\nIn addition, resiliency is related to how cloud-based systems m\", \"ust behave. As mentioned, a cloud-\\nbased system must embrace failures and must try to automatically \", \"recover from them. For instance, in \\ncase of network or container failures, client apps or client se\", \"rvices must have a strategy to retry \\nsending messages or to retry requests, since in many cases fai\", \"lures in the cloud are partial. The \\nImplementing Resilient Applications section in this guide addre\", \"sses how to handle partial failure. It \\ndescribes techniques like retries with exponential backoff o\", \"r the Circuit Breaker pattern in .NET by \\nusing libraries like Polly, which offers a large variety o\", \"f policies to handle this subject. \\n\\nHealth management and diagnostics in microservices \\n\\nIt may see\", \"m obvious, and it\\u2019s often overlooked, but a microservice must report its health and \\ndiagnostics. Ot\", \"herwise, there\\u2019s little insight from an operations perspective. Correlating diagnostic \\nevents acros\", \"s a set of independent services and dealing with machine clock skews to make sense of \\n\\n63 \\n\\nCHAPTER\", \" 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fthe event order is challengin\", \"g. In the same way that you interact with a microservice over agreed-\\nupon protocols and data format\", \"s, there\\u2019s a need for standardization in how to log health and \\ndiagnostic events that ultimately en\", \"d up in an event store for querying and viewing. In a microservices \\napproach, it\\u2019s key that differe\", \"nt teams agree on a single logging format. There needs to be a \\nconsistent approach to viewing diagn\", \"ostic events in the application. \\n\\nHealth checks \\n\\nHealth is different from diagnostics. Health is a\", \"bout the microservice reporting its current state to take \\nappropriate actions. A good example is wo\", \"rking with upgrade and deployment mechanisms to \\nmaintain availability. Although a service might cur\", \"rently be unhealthy due to a process crash or \\nmachine reboot, the service might still be operationa\", \"l. The last thing you need is to make this worse \\nby performing an upgrade. The best approach is to \", \"do an investigation first or allow time for the \\nmicroservice to recover. Health events from a micro\", \"service help us make informed decisions and, in \\neffect, help create self-healing services. \\n\\nIn the\", \" Implementing health checks in ASP.NET Core services section of this guide, we explain how to \\nuse a\", \" new ASP.NET HealthChecks library in your microservices so they can report their state to a \\nmonitor\", \"ing service to take appropriate actions. \\n\\nYou also have the option of using an excellent open-sourc\", \"e library called \\nAspNetCore.Diagnostics.HealthChecks, available on GitHub and as a NuGet package. T\", \"his library also \\ndoes health checks, with a twist, it handles two types of checks: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nLivene\", \"ss: Checks if the microservice is alive, that is, if it\\u2019s able to accept requests and respond. \\n\\nRea\", \"diness: Checks if the microservice\\u2019s dependencies (Database, queue services, etc.) are \\nthemselves r\", \"eady, so the microservice can do what it\\u2019s supposed to do. \\n\\nUsing diagnostics and logs event stream\", \"s \\n\\nLogs provide information about how an application or service is running, including exceptions, \\n\", \"warnings, and simple informational messages. Usually, each log is in a text format with one line per\", \" \\nevent, although exceptions also often show the stack trace across multiple lines. \\n\\nIn monolithic \", \"server-based applications, you can write logs to a file on disk (a logfile) and then analyze \\nit wit\", \"h any tool. Since application execution is limited to a fixed server or VM, it generally isn\\u2019t too \\n\", \"complex to analyze the flow of events. However, in a distributed application where multiple services\", \" \\nare executed across many nodes in an orchestrator cluster, being able to correlate distributed eve\", \"nts \\nis a challenge. \\n\\nA microservice-based application should not try to store the output stream of\", \" events or logfiles by \\nitself, and not even try to manage the routing of the events to a central pl\", \"ace. It should be \\ntransparent, meaning that each process should just write its event stream to a st\", \"andard output that \\nunderneath will be collected by the execution environment infrastructure where i\", \"t\\u2019s running. An \\nexample of these event stream routers is Microsoft.Diagnostic.EventFlow, which coll\", \"ects event streams \\nfrom multiple sources and publishes it to output systems. These can include simp\", \"le standard output \\nfor a development environment or cloud systems like Azure Monitor and Azure Diag\", \"nostics. There are \\nalso good third-party log analysis platforms and tools that can search, alert, r\", \"eport, and monitor logs, \\neven in real time, like Splunk. \\n\\n64 \\n\\nCHAPTER 3 | Architecting container \", \"and microservice-based applications \\n\\n \\n \\n\\fOrchestrators managing health and diagnostics information\", \" \\n\\nWhen you create a microservice-based application, you need to deal with complexity. Of course, a \", \"\\nsingle microservice is simple to deal with, but dozens or hundreds of types and thousands of \\ninsta\", \"nces of microservices is a complex problem. It isn\\u2019t just about building your microservice \\narchitec\", \"ture\\u2014you also need high availability, addressability, resiliency, health, and diagnostics if you \\nin\", \"tend to have a stable and cohesive system. \\n\\nFigure 4-22. A Microservice Platform is fundamental for\", \" an application\\u2019s health management \\n\\nThe complex problems shown in Figure 4-22 are hard to solve by\", \" yourself. Development teams should \\nfocus on solving business problems and building custom applicat\", \"ions with microservice-based \\napproaches. They should not focus on solving complex infrastructure pr\", \"oblems; if they did, the cost of \\nany microservice-based application would be huge. Therefore, there\", \" are microservice-oriented \\nplatforms, referred to as orchestrators or microservice clusters, that t\", \"ry to solve the hard problems of \\nbuilding and running a service and using infrastructure resources \", \"efficiently. This approach reduces \\nthe complexities of building applications that use a microservic\", \"es approach. \\n\\nDifferent orchestrators might sound similar, but the diagnostics and health checks of\", \"fered by each of \\nthem differ in features and state of maturity, sometimes depending on the OS platf\", \"orm, as explained \\nin the next section. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nThe Twelve-Factor App. XI. Logs\", \": Treat logs as event streams \\nhttps://12factor.net/logs \\n\\n\\u2022  Microsoft Diagnostic EventFlow Library\", \" GitHub repo. \\nhttps://github.com/Azure/diagnostics-eventflow \\n\\n\\u2022  What is Azure Diagnostics \\n\\nhttps\", \"://learn.microsoft.com/azure/azure-diagnostics \\n\\n65 \\n\\nCHAPTER 3 | Architecting container and microse\", \"rvice-based applications \\n\\n \\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nConnect Windows computers to the Azure Monitor ser\", \"vice \\nhttps://learn.microsoft.com/azure/azure-monitor/platform/agent-windows \\n\\nLogging What You Mean\", \": Using the Semantic Logging Application Block \\nhttps://learn.microsoft.com/previous-versions/msp-n-\", \"p/dn440729(v=pandp.60) \\n\\nSplunk Official site. \\nhttps://www.splunk.com/ \\n\\nEventSource Class API for \", \"events tracing for Windows (ETW) \\nhttps://learn.microsoft.com/dotnet/api/system.diagnostics.tracing.\", \"eventsource \\n\\nOrchestrate microservices and multi-container \\napplications for high scalability and a\", \"vailability \\n\\nUsing orchestrators for production-ready applications is essential if your application\", \" is based on \\nmicroservices or simply split across multiple containers. As introduced previously, in\", \" a microservice-\\nbased approach, each microservice owns its model and data so that it will be autono\", \"mous from a \\ndevelopment and deployment point of view. But even if you have a more traditional appli\", \"cation that\\u2019s \\ncomposed of multiple services (like SOA), you\\u2019ll also have multiple containers or ser\", \"vices comprising a \\nsingle business application that need to be deployed as a distributed system. Th\", \"ese kinds of systems \\nare complex to scale out and manage; therefore, you absolutely need an orchest\", \"rator if you want to \\nhave a production-ready and scalable multi-container application. \\n\\nFigure 4-2\", \"3 illustrates deployment into a cluster of an application composed of multiple microservices \\n(conta\", \"iners). \\n\\n66 \\n\\nCHAPTER 3 | Architecting container and microservice-based applications \\n\\n \\n \\n\\fFigure \", \"4-23. A cluster of containers \\n\\nYou use one container for each service instance. Docker containers a\", \"re \\u201cunits of deployment\\u201d and a \\ncontainer is an instance of a Docker. A host handles many containers\", \". It looks like a logical approach. \\nBut how are you handling load-balancing, routing, and orchestra\", \"ting these composed applications? \\n\\nThe plain Docker Engine in single Docker hosts meets the needs o\", \"f managing single image instances \\non one host, but it falls short when it comes to managing multipl\", \"e containers deployed on multiple \\nhosts for more complex distributed applications. In most cases, y\", \"ou need a management platform \\nthat will automatically start containers, scale out containers with m\", \"ultiple instances per image, \\nsuspend them or shut them down when needed, and ideally also control h\", \"ow they access resources \\nlike the network and data storage. \\n\\nTo go beyond the management of indivi\", \"dual containers or simple composed apps and move toward \\nlarger enterprise applications with microse\", \"rvices, you must turn to orchestration and clustering \\nplatforms. \\n\\nFrom an architecture and develop\", \"ment point of view, if you\\u2019re building large enterprise composed of \\nmicroservices-based application\", \"s, it\\u2019s important to understand the following platforms and products \\nthat support advanced scenario\", \"s: \\n\\nClusters and orchestrators. When you need to scale out applications across many Docker hosts, a\", \"s \\nwhen a large microservice-based application, it\\u2019s critical to be able to manage all those hosts a\", \"s a \\nsingle cluster by abstracting the complexity of the underlying platform. That\\u2019s what the contai\", \"ner \\nclusters and orchestrators provide. Kubernetes is an example of an orchestrator, and is availab\", \"le in \\nAzure through Azure Kubernetes Service. \\n\\nSchedulers. Scheduling means to have the capability\", \" for an administrator to launch containers in a \\ncluster so they also provide a UI. A cluster schedu\", \"ler has several responsibilities: to use the cluster\\u2019s \\n\\n67 \\n\\nCHAPTER 3 | Architecting container and\", \" microservice-based applications \\n\\n \\n \\n \\n\\fresources efficiently, to set the constraints provided by \", \"the user, to efficiently load-balance containers \\nacross nodes or hosts, and to be robust against er\", \"rors while providing high availability. \\n\\nThe concepts of a cluster and a scheduler are closely rela\", \"ted, so the products provided by different \\nvendors often provide both sets of capabilities. The fol\", \"lowing list shows the most important platform \\nand software choices you have for clusters and schedu\", \"lers. These orchestrators are generally offered \\nin public clouds like Azure. \\n\\nSoftware platforms f\", \"or container clustering, orchestration, and \\nscheduling \\n\\nPlatform \\n\\nKubernetes \\n\\nAzure Kubernetes S\", \"ervice (AKS) \\n\\nAzure Container Apps \\n\\nDescription \\n\\nKubernetes is an open-source \\nproduct that provi\", \"des functionality \\nthat ranges from cluster \\ninfrastructure and container \\nscheduling to orchestrati\", \"ng \\ncapabilities. It lets you automate \\ndeployment, scaling, and \\noperations of application \\ncontain\", \"ers across clusters of hosts. \\n\\nKubernetes provides a container-\\ncentric infrastructure that groups \", \"\\napplication containers into logical \\nunits for easy management and \\ndiscovery. \\n\\nKubernetes is matu\", \"re in Linux, less \\nmature in Windows. \\n\\nAKS is a managed Kubernetes \\ncontainer orchestration service\", \" in \\nAzure that simplifies Kubernetes \\ncluster\\u2019s management, deployment, \\nand operations. \\n\\nAzure Co\", \"ntainer Apps is a managed \\nserverless container service for \\nbuilding and deploying modern \\napps at \", \"scale. \\n\\nUsing container-based orchestrators in Microsoft Azure \\n\\nSeveral cloud vendors offer Docker\", \" containers support plus Docker clusters and orchestration support, \\nincluding Microsoft Azure, Amaz\", \"on EC2 Container Service, and Google Container Engine. Microsoft \\nAzure provides Docker cluster and \", \"orchestrator support through Azure Kubernetes Service (AKS). \\n\\n68 \\n\\nCHAPTER 3 | Architecting contain\", \"er and microservice-based applications \\n\\n \\n \\n \\n \\n \\n \\n \\n\\fUsing Azure Kubernetes Service \\n\\nA Kubernete\", \"s cluster pools multiple Docker hosts and exposes them as a single virtual Docker host, so \\nyou can \", \"deploy multiple containers into the cluster and scale-out with any number of container \\ninstances. T\", \"he cluster will handle all the complex management plumbing, like scalability, health, and \\nso forth.\", \" \\n\\nAKS provides a way to simplify the creation, configuration, and management of a cluster of virtua\", \"l \\nmachines in Azure that are preconfigured to run containerized applications. Using an optimized \\nc\", \"onfiguration of popular open-source scheduling and orchestration tools, AKS enables you to use \\nyour\", \" existing skills or draw on a large and growing body of community expertise to deploy and \\nmanage co\", \"ntainer-based applications on Microsoft Azure. \\n\\nAzure Kubernetes Service optimizes the configuratio\", \"n of popular Docker clustering open-source tools \\nand technologies specifically for Azure. You get a\", \"n open solution that offers portability for both your \\ncontainers and your application configuration\", \". You select the size, the number of hosts, and the \\norchestrator tools, and AKS handles everything \", \"else. \\n\\nFigure 4-24. Kubernetes cluster\\u2019s simplified structure and topology \\n\\n69 \\n\\nCHAPTER 3 | Archi\", \"tecting container and microservice-based applications \\n\\n \\n \\n \\n\\fIn figure 4-24, you can see the struc\", \"ture of a Kubernetes cluster where a master node (VM) controls \\nmost of the coordination of the clus\", \"ter and you can deploy containers to the rest of the nodes, which \\nare managed as a single pool from\", \" an application point of view and allows you to scale to thousands \\nor even tens of thousands of con\", \"tainers. \\n\\nDevelopment environment for Kubernetes \\n\\nIn the development environment, Docker announced\", \" in July 2018 that Kubernetes can also run in a \\nsingle development machine (Windows 10 or macOS) by\", \" installing Docker Desktop. You can later \\ndeploy to the cloud (AKS) for further integration tests, \", \"as shown in figure 4-25. \\n\\nFigure 4-25. Running Kubernetes in dev machine and the cloud \\n\\nGetting st\", \"arted with Azure Kubernetes Service (AKS) \\n\\nTo begin using AKS, you deploy an AKS cluster from the A\", \"zure portal or by using the CLI. For more \\ninformation on deploying a Kubernetes cluster in Azure, s\", \"ee Deploy an Azure Kubernetes Service \\n(AKS) cluster. \\n\\nThere are no fees for any of the software in\", \"stalled by default as part of AKS. All default options are \\nimplemented with open-source software. A\", \"KS is available for multiple virtual machines in Azure. \\nYou\\u2019re charged only for the compute instanc\", \"es you choose, and the other underlying infrastructure \\nresources consumed, such as storage and netw\", \"orking. There are no incremental charges for AKS itself. \\n\\nThe default production deployment option \", \"for Kubernetes is to use Helm charts, which are introduced \\nin the next section. \\n\\n70 \\n\\nCHAPTER 3 | \", \"Architecting container and microservice-based applications \\n\\n \\n \\n \\n\\fDeploy with Helm charts into Kub\", \"ernetes clusters \\n\\nWhen deploying an application to a Kubernetes cluster, you can use the original k\", \"ubectl.exe CLI tool \\nusing deployment files based on the native format (.yaml files), as already men\", \"tioned in the previous \\nsection. However, for more complex Kubernetes applications such as when depl\", \"oying complex \\nmicroservice-based applications, it\\u2019s recommended to use Helm. \\n\\nHelm Charts helps yo\", \"u define, version, install, share, upgrade, or rollback even the most complex \\nKubernetes applicatio\", \"n. \\n\\nGoing further, Helm usage is also recommended because other Kubernetes environments in Azure, \\n\", \"such as Azure Dev Spaces are also based on Helm charts. \\n\\nHelm is maintained by the Cloud Native Com\", \"puting Foundation (CNCF) - in collaboration with \\nMicrosoft, Google, Bitnami, and the Helm contribut\", \"or community. \\n\\nFor more implementation information on Helm charts and Kubernetes, see the Using Hel\", \"m Charts to \\ndeploy eShopOnContainers to AKS post. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nGetting star\", \"ted with Azure Kubernetes Service (AKS) \\nhttps://learn.microsoft.com/azure/aks/kubernetes-walkthroug\", \"h-portal \\n\\nAzure Dev Spaces \\nhttps://learn.microsoft.com/azure/dev-spaces/azure-dev-spaces \\n\\nKuberne\", \"tes The official site. \\nhttps://kubernetes.io/ \\n\\n71 \\n\\nCHAPTER 3 | Architecting container and microse\", \"rvice-based applications \\n\\n \\n \\n\\fCHAPTER  4 \\n\\nDevelopment process for \\nDocker-based applications \\n\\nDe\", \"velop containerized .NET applications the way you like, either Integrated Development Environment \\n(\", \"IDE) focused with Visual Studio and Visual Studio tools for Docker or CLI/Editor focused with Docker\", \" CLI \\nand Visual Studio Code. \\n\\nDevelopment environment for Docker apps \\n\\nDevelopment tool choices: \", \"IDE or editor \\n\\nWhether you prefer a full and powerful IDE or a lightweight and agile editor, Micros\", \"oft has tools that \\nyou can use for developing Docker applications. \\n\\nVisual Studio (for Windows). D\", \"ocker-based .NET 7 application development with Visual Studio \\nrequires Visual Studio 2022 version 1\", \"7.0 or later. Visual Studio 2022 comes with tools for Docker \\nalready built in. The tools for Docker\", \" let you develop, run, and validate your applications directly in the \\ntarget Docker environment. Yo\", \"u can press F5 to run and debug your application (single container or \\nmultiple containers) directly\", \" into a Docker host, or press CTRL + F5 to edit and refresh your \\napplication without having to rebu\", \"ild the container. This IDE is the most powerful development choice \\nfor Docker-based apps. \\n\\nVisual\", \" Studio for Mac. It\\u2019s an IDE, evolution of Xamarin Studio, running in macOS. This tool should \\nbe th\", \"e preferred choice for developers working in macOS machines who also want to use a powerful \\nIDE. \\n\\n\", \"Visual Studio Code and Docker CLI. If you prefer a lightweight and cross-platform editor that \\nsuppo\", \"rts any development language, you can use Visual Studio Code and the Docker CLI. This IDE is a \\ncros\", \"s-platform development approach for macOS, Linux, and Windows. Additionally, Visual Studio \\nCode sup\", \"ports extensions for Docker such as IntelliSense for Dockerfiles and shortcut tasks to run \\nDocker c\", \"ommands from the editor. \\n\\nBy installing Docker Desktop, you can use a single Docker CLI to build ap\", \"ps for both Windows and \\nLinux. \\n\\n72 \\n\\nCHAPTER 4 | Development process for Docker-based applications\", \" \\n\\n \\n \\n\\fAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nVisual Studio. Official site. \\nhttps://visualstudio.m\", \"icrosoft.com/vs/ \\n\\nVisual Studio Code. Official site. \\nhttps://code.visualstudio.com/download \\n\\nDock\", \"er Desktop for Windows \\nhttps://hub.docker.com/editions/community/docker-ce-desktop-windows \\n\\nDocker\", \" Desktop for Mac \\nhttps://hub.docker.com/editions/community/docker-ce-desktop-mac \\n\\n.NET languages a\", \"nd frameworks for Docker \\ncontainers \\n\\nAs mentioned in earlier sections of this guide, you can use .\", \"NET Framework, .NET 7, or the open-\\nsource Mono project when developing Docker containerized .NET ap\", \"plications. You can develop in \\nC#, F#, or Visual Basic when targeting Linux or Windows Containers, \", \"depending on which .NET \\nframework is in use. For more details about.NET languages, see the blog pos\", \"t The .NET Language \\nStrategy. \\n\\nDevelopment workflow for Docker apps \\n\\nThe application development \", \"life cycle starts at your computer, as a developer, where you code the \\napplication using your prefe\", \"rred language and test it locally. With this workflow, no matter which \\nlanguage, framework, and pla\", \"tform you choose, you\\u2019re always developing and testing Docker \\ncontainers, but doing so locally. \\n\\nE\", \"ach container (an instance of a Docker image) includes the following components: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAn op\", \"erating system selection, for example, a Linux distribution, Windows Nano Server, or \\nWindows Server\", \" Core. \\n\\nFiles added during development, for example, source code and application binaries. \\n\\nConfig\", \"uration information, such as environment settings and dependencies. \\n\\nWorkflow for developing Docker\", \" container-based applications \\n\\nThis section describes the inner-loop development workflow for Docke\", \"r container-based applications. \\nThe inner-loop workflow means it\\u2019s not considering the broader DevO\", \"ps workflow, which can include \\nup to production deployment, and just focuses on the development wor\", \"k done on the developer\\u2019s \\ncomputer. The initial steps to set up the environment aren\\u2019t included, si\", \"nce those steps are done only \\nonce. \\n\\n73 \\n\\nCHAPTER 4 | Development process for Docker-based applica\", \"tions \\n\\n \\n \\n\\fAn application is composed of your own services plus additional libraries (dependencies\", \"). The \\nfollowing are the basic steps you usually take when building a Docker application, as illust\", \"rated in \\nFigure 5-1. \\n\\nFigure 5-1. Step-by-step workflow for developing Docker containerized apps \\n\", \"\\nIn this section, this whole process is detailed and every major step is explained by focusing on a \", \"Visual \\nStudio environment. \\n\\nWhen you\\u2019re using an editor/CLI development approach (for example, Vis\", \"ual Studio Code plus Docker \\nCLI on macOS or Windows), you need to know every step, generally in mor\", \"e detail than if you\\u2019re using \\nVisual Studio. For more information about working in a CLI environmen\", \"t, see the e-book \\nContainerized Docker Application lifecycle with Microsoft Platforms and Tools. \\n\\n\", \"When you\\u2019re using Visual Studio 2022, many of those steps are handled for you, which dramatically \\ni\", \"mproves your productivity. This is especially true when you\\u2019re using Visual Studio 2022 and targetin\", \"g \\nmulti-container applications. For instance, with just one mouse click, Visual Studio adds the Doc\", \"kerfile \\nand docker-compose.yml file to your projects with the configuration for your application. W\", \"hen you \\nrun the application in Visual Studio, it builds the Docker image and runs the multi-contain\", \"er \\napplication directly in Docker; it even allows you to debug several containers at once. These fe\", \"atures \\nwill boost your development speed. \\n\\nHowever, just because Visual Studio makes those steps a\", \"utomatic doesn\\u2019t mean that you don\\u2019t need \\nto know what\\u2019s going on underneath with Docker. Therefore\", \", the following guidance details every \\nstep. \\n\\n74 \\n\\nCHAPTER 4 | Development process for Docker-base\", \"d applications \\n\\n \\n \\n \\n\\fStep 1. Start coding and create your initial application or service \\nbaselin\", \"e \\n\\nDeveloping a Docker application is similar to the way you develop an application without Docker.\", \" The \\ndifference is that while developing for Docker, you\\u2019re deploying and testing your application \", \"or \\nservices running within Docker containers in your local environment (either a Linux VM setup by \", \"\\nDocker or directly Windows if using Windows Containers). \\n\\nSet up your local environment with Visua\", \"l Studio \\n\\nTo begin, make sure you have Docker Desktop for Windows for Windows installed, as explain\", \"ed in the \\nfollowing instructions: \\n\\nGet started with Docker Desktop for Windows \\n\\nIn addition, you \", \"need Visual Studio 2022 version 17.0, with the .ASP.NET and web development \\nworkload installed, as \", \"shown in Figure 5-2. \\n\\nFigure 5-2. Selecting the ASP.NET and web development workload during Visual \", \"Studio 2022 setup \\n\\nYou can start coding your application in plain .NET (usually in .NET Core or lat\", \"er if you\\u2019re planning to \\nuse containers) even before enabling Docker in your application and deploy\", \"ing and testing in Docker. \\nHowever, it is recommended that you start working on Docker as soon as p\", \"ossible, because that will \\nbe the real environment and any issues can be discovered as soon as poss\", \"ible. This is encouraged \\n\\n75 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n\", \" \\n \\n\\fbecause Visual Studio makes it so easy to work with Docker that it almost feels transparent\\u2014the\", \" best \\nexample when debugging multi-container applications from Visual Studio. \\n\\nAdditional resource\", \"s \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nGet started with Docker Desktop for Windows \\nhttps://docs.docker.com/docker-for-windows/\", \" \\n\\nVisual Studio 2022 \\nhttps://visualstudio.microsoft.com/downloads/ \\n\\nStep 2. Create a Dockerfile r\", \"elated to an existing .NET base image \\n\\nYou need a Dockerfile for each custom image you want to buil\", \"d; you also need a Dockerfile for each \\ncontainer to be deployed, whether you deploy automatically f\", \"rom Visual Studio or manually using the \\nDocker CLI (docker run and docker-compose commands). If you\", \"r application contains a single custom \\nservice, you need a single Dockerfile. If your application c\", \"ontains multiple services (as in a \\nmicroservices architecture), you need one Dockerfile for each se\", \"rvice. \\n\\nThe Dockerfile is placed in the root folder of your application or service. It contains the\", \" commands \\nthat tell Docker how to set up and run your application or service in a container. You ca\", \"n manually \\ncreate a Dockerfile in code and add it to your project along with your .NET dependencies\", \". \\n\\nWith Visual Studio and its tools for Docker, this task requires only a few mouse clicks. When yo\", \"u \\ncreate a new project in Visual Studio 2022, there\\u2019s an option named Enable Docker Support, as \\nsh\", \"own in Figure 5-3. \\n\\n76 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n \\n\\fFig\", \"ure 5-3. Enabling Docker Support when creating a new ASP.NET Core project in Visual Studio 2022 \\n\\nYo\", \"u can also enable Docker support on an existing ASP.NET Core web app project by right-clicking \\nthe \", \"project in Solution Explorer and selecting Add > Docker Support\\u2026, as shown in Figure 5-4. \\n\\nFigure 5\", \"-4. Enabling Docker support in an existing Visual Studio 2022 project \\n\\n77 \\n\\nCHAPTER 4 | Development\", \" process for Docker-based applications \\n\\n \\n \\n \\n \\n\\fThis action adds a Dockerfile to the project with \", \"the required configuration, and is only available on \\nASP.NET Core projects. \\n\\nIn a similar fashion,\", \" Visual Studio can also add a docker-compose.yml file for the whole solution with \\nthe option Add > \", \"Container Orchestrator Support\\u2026. In step 4, we\\u2019ll explore this option in greater \\ndetail. \\n\\nUsing an\", \" existing official .NET Docker image \\n\\nYou usually build a custom image for your container on top of\", \" a base image you get from an official \\nrepository like the Docker Hub registry. That is precisely w\", \"hat happens under the covers when you \\nenable Docker support in Visual Studio. Your Dockerfile will \", \"use an existing dotnet/core/aspnet image. \\n\\nEarlier we explained which Docker images and repos you c\", \"an use, depending on the framework and \\nOS you have chosen. For instance, if you want to use ASP.NET\", \" Core (Linux or Windows), the image to \\nuse is mcr.microsoft.com/dotnet/aspnet:7.0. Therefore, you j\", \"ust need to specify what base Docker \\nimage you will use for your container. You do that by adding F\", \"ROM \\nmcr.microsoft.com/dotnet/aspnet:7.0 to your Dockerfile. This will be automatically performed by\", \" \\nVisual Studio, but if you were to update the version, you update this value. \\n\\nUsing an official .\", \"NET image repository from Docker Hub with a version number ensures that the same \\nlanguage features \", \"are available on all machines (including development, testing, and production). \\n\\nThe following exam\", \"ple shows a sample Dockerfile for an ASP.NET Core container. \\n\\nFROM mcr.microsoft.com/dotnet/aspnet:\", \"7.0 \\nARG source \\nWORKDIR /app \\nEXPOSE 80 \\nCOPY ${source:-obj/Docker/publish} . \\nENTRYPOINT [\\\"dotnet\\\"\", \", \\\" MySingleContainerWebApp.dll \\\"] \\n\\nIn this case, the image is based on version 7.0 of the official\", \" ASP.NET Core Docker image (multi-arch \\nfor Linux and Windows). This is the setting FROM mcr.microso\", \"ft.com/dotnet/aspnet:7.0. (For more \\ninformation about this base image, see the ASP.NET Core Docker \", \"Image page.) In the Dockerfile, you \\nalso need to instruct Docker to listen on the TCP port you will\", \" use at runtime (in this case, port 80, as \\nconfigured with the EXPOSE setting). \\n\\nYou can specify a\", \"dditional configuration settings in the Dockerfile, depending on the language and \\nframework you\\u2019re \", \"using. For instance, the ENTRYPOINT line with [\\\"dotnet\\\", \\n\\\"MySingleContainerWebApp.dll\\\"] tells Docke\", \"r to run a .NET application. If you\\u2019re using the SDK and \\nthe .NET CLI (dotnet CLI) to build and run\", \" the .NET application, this setting would be different. The \\nbottom line is that the ENTRYPOINT line\", \" and other settings will be different depending on the \\nlanguage and platform you choose for your ap\", \"plication. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nBuilding Docker Images for ASP.NET Core Applications \\nhttps:\", \"//learn.microsoft.com/dotnet/core/docker/building-net-docker-images \\n\\n78 \\n\\nCHAPTER 4 | Development p\", \"rocess for Docker-based applications \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nBuild your own image. In the official Docker\", \" documentation. \\nhttps://docs.docker.com/engine/tutorials/dockerimages/ \\n\\nStaying up-to-date with .N\", \"ET Container Images \\nhttps://devblogs.microsoft.com/dotnet/staying-up-to-date-with-net-container-ima\", \"ges/ \\n\\nUsing .NET and Docker Together - DockerCon 2018 Update \\nhttps://devblogs.microsoft.com/dotnet\", \"/using-net-and-docker-together-dockercon-2018-\\nupdate/ \\n\\nUsing multi-arch image repositories \\n\\nA sin\", \"gle repo can contain platform variants, such as a Linux image and a Windows image. This feature \\nall\", \"ows vendors like Microsoft (base image creators) to create a single repo to cover multiple platforms\", \" \\n(that is Linux and Windows). For example, the .NET repository available in the Docker Hub registry\", \" \\nprovides support for Linux and Windows Nano Server by using the same repo name. \\n\\nIf you specify a\", \" tag, targeting a platform that is explicit like in the following cases: \\n\\n\\u2022  mcr.microsoft.com/dotn\", \"et/aspnet:7.0-bullseye-slim \\n\\nTargets: .NET 7 runtime-only on Linux \\n\\n\\u2022  mcr.microsoft.com/dotnet/as\", \"pnet:7.0-nanoserver-ltsc2022 \\nTargets: .NET 7 runtime-only on Windows Nano Server \\n\\nBut, if you spec\", \"ify the same image name, even with the same tag, the multi-arch images (like the \\naspnet image) will\", \" use the Linux or Windows version depending on the Docker host OS you\\u2019re \\ndeploying, as shown in the\", \" following example: \\n\\n\\u2022  mcr.microsoft.com/dotnet/aspnet:7.0 \\n\\nMulti-arch: .NET 7 runtime-only on Li\", \"nux or Windows Nano Server depending on the Docker \\nhost OS \\n\\nThis way, when you pull an image from \", \"a Windows host, it will pull the Windows variant, and pulling \\nthe same image name from a Linux host\", \" will pull the Linux variant. \\n\\nMulti-stage builds in Dockerfile \\n\\nThe Dockerfile is similar to a ba\", \"tch script. Similar to what you would do if you had to set up the \\nmachine from the command line. \\n\\n\", \"It starts with a base image that sets up the initial context, it\\u2019s like the startup filesystem, that\", \" sits on \\ntop of the host OS. It\\u2019s not an OS, but you can think of it like \\u201cthe\\u201d OS inside the conta\", \"iner. \\n\\nThe execution of every command line creates a new layer on the filesystem with the changes f\", \"rom the \\nprevious one, so that, when combined, produce the resulting filesystem. \\n\\nSince every new l\", \"ayer \\u201crests\\u201d on top of the previous one and the resulting image size increases with \\nevery command, \", \"images can get very large if they have to include, for example, the SDK needed to \\nbuild and publish\", \" an application. \\n\\nThis is where multi-stage builds get into the plot (from Docker 17.05 and higher)\", \" to do their magic. \\n\\n79 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n\\fThe \", \"core idea is that you can separate the Dockerfile execution process in stages, where a stage is an \\n\", \"initial image followed by one or more commands, and the last stage determines the final image size. \", \"\\n\\nIn short, multi-stage builds allow splitting the creation in different \\u201cphases\\u201d and then assemble \", \"the \\nfinal image taking only the relevant directories from the intermediate stages. The general stra\", \"tegy to \\nuse this feature is: \\n\\n1.  Use a base SDK image (doesn\\u2019t matter how large), with everything\", \" needed to build and \\n\\npublish the application to a folder and then \\n\\n2.  Use a base, small, runtime\", \"-only image and copy the publishing folder from the previous stage \\n\\nto produce a small final image.\", \" \\n\\nProbably the best way to understand multi-stage is going through a Dockerfile in detail, line by \", \"line, \\nso let\\u2019s begin with the initial Dockerfile created by Visual Studio when adding Docker suppor\", \"t to a \\nproject and will get into some optimizations later. \\n\\nThe initial Dockerfile might look some\", \"thing like this: \\n\\n 1  FROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\n 2  WORKDIR /app \\n 3  EXPOS\", \"E 80 \\n 4 \\n 5  FROM mcr.microsoft.com/dotnet/sdk:7.0 AS build \\n 6  WORKDIR /src \\n 7  COPY src/Service\", \"s/Catalog/Catalog.API/Catalog.API.csproj \\u2026 \\n 8  COPY src/BuildingBlocks/HealthChecks/src/Microsoft.A\", \"spNetCore.HealthChecks \\u2026 \\n 9  COPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions.HealthCh\", \"ecks \\u2026 \\n10  COPY src/BuildingBlocks/EventBus/IntegrationEventLogEF/ \\u2026 \\n11  COPY src/BuildingBlocks/E\", \"ventBus/EventBus/EventBus.csproj \\u2026 \\n12  COPY src/BuildingBlocks/EventBus/EventBusRabbitMQ/EventBusRa\", \"bbitMQ.csproj \\u2026 \\n13  COPY src/BuildingBlocks/EventBus/EventBusServiceBus/EventBusServiceBus.csproj \\u2026\", \" \\n14  COPY src/BuildingBlocks/WebHostCustomization/WebHost.Customization \\u2026 \\n15  COPY src/BuildingBlo\", \"cks/HealthChecks/src/Microsoft.Extensions \\u2026 \\n16  COPY src/BuildingBlocks/HealthChecks/src/Microsoft.\", \"Extensions \\u2026 \\n17  RUN dotnet restore src/Services/Catalog/Catalog.API/Catalog.API.csproj \\n18  COPY .\", \" . \\n19  WORKDIR /src/src/Services/Catalog/Catalog.API \\n20  RUN dotnet build Catalog.API.csproj -c Re\", \"lease -o /app \\n21 \\n22  FROM build AS publish \\n23  RUN dotnet publish Catalog.API.csproj -c Release -\", \"o /app \\n24 \\n25  FROM base AS final \\n26  WORKDIR /app \\n27  COPY --from=publish /app . \\n28  ENTRYPOINT\", \" [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"] \\n\\nAnd these are the details, line by line: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n80 \\n\\nLine #1\", \": Begin a stage with a \\u201csmall\\u201d runtime-only base image, call it base for reference. \\n\\nLine #2: Creat\", \"e the /app directory in the image. \\n\\nLine #3: Expose port 80. \\n\\nCHAPTER 4 | Development process for \", \"Docker-based applications \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nLine #5: Begin \", \"a new stage with the \\u201clarge\\u201d image for building/publishing. Call it build for \\nreference. \\n\\nLine #6:\", \" Create directory /src in the image. \\n\\nLine #7: Up to line 16, copy referenced .csproj project files\", \" to be able to restore packages \\nlater. \\n\\nLine #17: Restore packages for the Catalog.API project and\", \" the referenced projects. \\n\\nLine #18: Copy all directory tree for the solution (except the files/dir\", \"ectories included in the \\n.dockerignore file) to the /src directory in the image. \\n\\nLine #19: Change\", \" the current folder to the Catalog.API project. \\n\\nLine #20: Build the project (and other project dep\", \"endencies) and output to the /app \\ndirectory in the image. \\n\\nLine #22: Begin a new stage continuing \", \"from the build. Call it publish for reference. \\n\\nLine #23: Publish the project (and dependencies) an\", \"d output to the /app directory in the \\nimage. \\n\\nLine #25: Begin a new stage continuing from base and\", \" call it final. \\n\\nLine #26: Change the current directory to /app. \\n\\nLine #27: Copy the /app director\", \"y from stage publish to the current directory. \\n\\nLine #28: Define the command to run when the contai\", \"ner is started. \\n\\nNow let\\u2019s explore some optimizations to improve the whole process performance that\", \", in the case of \\neShopOnContainers, means about 22 minutes or more to build the complete solution i\", \"n Linux \\ncontainers. \\n\\nYou\\u2019ll take advantage of Docker\\u2019s layer cache feature, which is quite simple:\", \" if the base image and the \\ncommands are the same as some previously executed, it can just use the r\", \"esulting layer without the \\nneed to execute the commands, thus saving some time. \\n\\nSo, let\\u2019s focus o\", \"n the build stage, lines 5-6 are mostly the same, but lines 7-17 are different for every \\nservice fr\", \"om eShopOnContainers, so they have to execute every single time, however if you changed \\nlines 7-16 \", \"to: \\n\\nCOPY . . \\n\\nThen it would be just the same for every service, it would copy the whole solution \", \"and would create a \\nlarger layer but: \\n\\n1. \\n\\nThe copy process would only be executed the first time \", \"(and when rebuilding if a file is \\nchanged) and would use the cache for all other services and \\n\\n2. \", \"\\n\\nSince the larger image occurs in an intermediate stage, it doesn\\u2019t affect the final image size. \\n\\n\", \"81 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n\\fThe next significant optim\", \"ization involves the restore command executed in line 17, which is also \\ndifferent for every service\", \" of eShopOnContainers. If you change that line to just: \\n\\nRUN dotnet restore \\n\\nIt would restore the \", \"packages for the whole solution, but then again, it would do it just once, instead \\nof the 15 times \", \"with the current strategy. \\n\\nHowever, dotnet restore only runs if there\\u2019s a single project or soluti\", \"on file in the folder, so achieving \\nthis is a bit more complicated and the way to solve it, without\", \" getting into too many details, is this: \\n\\n1. \\n\\nAdd the following lines to .dockerignore: \\n\\n\\u2013 \\n\\n\\u2013 \\n\\n\", \"*.sln, to ignore all solution files in the main folder tree \\n\\n!eShopOnContainers-ServicesAndWebApps.\", \"sln, to include only this solution file. \\n\\n2. \\n\\nInclude the /ignoreprojectextensions:.dcproj argumen\", \"t to dotnet restore, so it also ignores the \\ndocker-compose project and only restores the packages f\", \"or the eShopOnContainers-\\nServicesAndWebApps solution. \\n\\nFor the final optimization, it just happens\", \" that line 20 is redundant, as line 23 also builds the \\napplication and comes, in essence, right aft\", \"er line 20, so there goes another time-consuming \\ncommand. \\n\\nThe resulting file is then: \\n\\n 1  FROM \", \"mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\n 2  WORKDIR /app \\n 3  EXPOSE 80 \\n 4 \\n 5  FROM mcr.micro\", \"soft.com/dotnet/sdk:7.0 AS publish \\n 6  WORKDIR /src \\n 7  COPY . . \\n 8  RUN dotnet restore /ignorepr\", \"ojectextensions:.dcproj \\n 9  WORKDIR /src/src/Services/Catalog/Catalog.API \\n10  RUN dotnet publish C\", \"atalog.API.csproj -c Release -o /app \\n11 \\n12  FROM base AS final \\n13  WORKDIR /app \\n14  COPY --from=\", \"publish /app . \\n15  ENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"] \\n\\nCreating your base image from scratch\", \" \\n\\nYou can create your own Docker base image from scratch. This scenario is not recommended for \\nsom\", \"eone who is starting with Docker, but if you want to set the specific bits of your own base image, \\n\", \"you can do so. \\n\\nAdditional resources \\n\\n\\u2022  Multi-arch .NET Core images. \\n\\nhttps://github.com/dotnet/\", \"announcements/issues/14 \\n\\n82 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n\\f\", \"\\u2022 \\n\\nCreate a base image. Official Docker documentation. \\nhttps://docs.docker.com/develop/develop-ima\", \"ges/baseimages/ \\n\\nStep 3. Create your custom Docker images and embed your \\napplication or service in\", \" them \\n\\nFor each service in your application, you need to create a related image. If your applicatio\", \"n is made up \\nof a single service or web application, you just need a single image. \\n\\nNote that the \", \"Docker images are built automatically for you in Visual Studio. The following steps are \\nonly needed\", \" for the editor/CLI workflow and explained for clarity about what happens underneath. \\n\\nYou, as a de\", \"veloper, need to develop and test locally until you push a completed feature or change to \\nyour sour\", \"ce control system (for example, to GitHub). This means that you need to create the Docker \\nimages an\", \"d deploy containers to a local Docker host (Windows or Linux VM) and run, test, and debug \\nagainst t\", \"hose local containers. \\n\\nTo create a custom image in your local environment by using Docker CLI and \", \"your Dockerfile, you can \\nuse the docker build command, as in Figure 5-5. \\n\\nFigure 5-5. Creating a c\", \"ustom Docker image \\n\\nOptionally, instead of directly running docker build from the project folder, y\", \"ou can first generate a \\ndeployable folder with the required .NET libraries and binaries by running \", \"dotnet publish, and then \\nuse the docker build command. \\n\\nThis will create a Docker image with the n\", \"ame cesardl/netcore-webapi-microservice-docker:first. In \\nthis case, :first is a tag that represents\", \" a specific version. You can repeat this step for each custom \\nimage you need to create for your com\", \"posed Docker application. \\n\\nWhen an application is made of multiple containers (that is, it is a mul\", \"ti-container application), you \\ncan also use the docker-compose up --build command to build all the \", \"related images with a single \\ncommand by using the metadata exposed in the related docker-compose.ym\", \"l files. \\n\\nYou can find the existing images in your local repository by using the docker images comm\", \"and, as \\nshown in Figure 5-6. \\n\\n83 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\", \"\\n \\n \\n \\n \\n\\fFigure 5-6. Viewing existing images using the docker images command \\n\\nCreating Docker imag\", \"es with Visual Studio \\n\\nWhen you use Visual Studio to create a project with Docker support, you don\\u2019\", \"t explicitly create an \\nimage. Instead, the image is created for you when you press F5 (or Ctrl+F5) \", \"to run the dockerized \\napplication or service. This step is automatic in Visual Studio and you won\\u2019t\", \" see it happen, but it\\u2019s \\nimportant that you know what\\u2019s going on underneath. \\n\\nStep 4. Define your \", \"services in docker-compose.yml when building a \\nmulti-container Docker application \\n\\nThe docker-comp\", \"ose.yml file lets you define a set of related services to be deployed as a composed \\napplication wit\", \"h deployment commands. It also configures its dependency relations and runtime \\nconfiguration. \\n\\nTo \", \"use a docker-compose.yml file, you need to create the file in your main or root solution folder, wit\", \"h \\ncontent similar to that in the following example: \\n\\nversion: '3.4' \\n\\nservices: \\n\\n  webmvc: \\n    i\", \"mage: eshop/web \\n    environment: \\n      - CatalogUrl=http://catalog-api \\n      - OrderingUrl=http:/\", \"/ordering-api \\n    ports: \\n      - \\\"80:80\\\" \\n    depends_on: \\n      - catalog-api \\n      - ordering-a\", \"pi \\n\\n  catalog-api: \\n    image: eshop/catalog-api \\n    environment: \\n      - ConnectionString=Server\", \"=sqldata;Port=1433;Database=CatalogDB;\\u2026 \\n    ports: \\n      - \\\"81:80\\\" \\n    depends_on: \\n      - sqlda\", \"ta \\n\\n  ordering-api: \\n    image: eshop/ordering-api \\n\\n84 \\n\\nCHAPTER 4 | Development process for Docke\", \"r-based applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\f    environment: \\n      - ConnectionString=Server=sqldata;Da\", \"tabase=OrderingDb;\\u2026 \\n    ports: \\n      - \\\"82:80\\\" \\n    extra_hosts: \\n      - \\\"CESARDLBOOKVHD:10.0.75.\", \"1\\\" \\n    depends_on: \\n      - sqldata \\n\\n  sqldata: \\n    image: mcr.microsoft.com/mssql/server:latest \", \"\\n    environment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5433:1\", \"433\\\" \\n\\nThis docker-compose.yml file is a simplified and merged version. It contains static configura\", \"tion data \\nfor each container (like the name of the custom image), which is always required, and con\", \"figuration \\ninformation that might depend on the deployment environment, like the connection string.\", \" In later \\nsections, you will learn how to split the docker-compose.yml configuration into multiple \", \"docker-\\ncompose files and override values depending on the environment and execution type (debug or \", \"\\nrelease). \\n\\nThe docker-compose.yml file example defines four services: the webmvc service (a web ap\", \"plication), \\ntwo microservices (ordering-api and basket-api), and one data source container, sqldata\", \", based on \\nSQL Server for Linux running as a container. Each service will be deployed as a containe\", \"r, so a Docker \\nimage is required for each. \\n\\nThe docker-compose.yml file specifies not only what co\", \"ntainers are being used, but how they are \\nindividually configured. For instance, the webmvc contain\", \"er definition in the .yml file: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUses a pre-built eshop/web:latest image. However, \", \"you could also configure the image to be \\nbuilt as part of the docker-compose execution with an addi\", \"tional configuration based on a \\nbuild: section in the docker-compose file. \\n\\nInitializes two enviro\", \"nment variables (CatalogUrl and OrderingUrl). \\n\\nForwards the exposed port 80 on the container to the\", \" external port 80 on the host machine. \\n\\nLinks the web app to the catalog and ordering service with \", \"the depends_on setting. This \\ncauses the service to wait until those services are started. \\n\\nWe will\", \" revisit the docker-compose.yml file in a later section when we cover how to implement \\nmicroservice\", \"s and multi-container apps. \\n\\nWorking with docker-compose.yml in Visual Studio 2022 \\n\\nBesides adding\", \" a Dockerfile to a project, as we mentioned before, Visual Studio 2017 (from version \\n15.8 on) can a\", \"dd orchestrator support for Docker Compose to a solution. \\n\\nWhen you add container orchestrator supp\", \"ort, as shown in Figure 5-7, for the first time, Visual Studio \\ncreates the Dockerfile for the proje\", \"ct and creates a new (service section) project in your solution with \\n\\n85 \\n\\nCHAPTER 4 | Development \", \"process for Docker-based applications \\n\\n \\n \\n \\n\\fseveral global docker-compose*.yml files, and then ad\", \"ds the project to those files. You can then open \\nthe docker-compose.yml files and update them with \", \"additional features. \\n\\nRepeat this operation for every project you want to include in the docker-com\", \"pose.yml file. \\n\\nAt the time of this writing, Visual Studio supports Docker Compose orchestrators. \\n\", \"\\nFigure 5-7. Adding Docker support in Visual Studio 2022 by right-clicking an ASP.NET Core project \\n\", \"\\nAfter you add orchestrator support to your solution in Visual Studio, you will also see a new node \", \"(in \\nthe docker-compose.dcproj project file) in Solution Explorer that contains the added docker-\\nco\", \"mpose.yml files, as shown in Figure 5-8. \\n\\nFigure 5-8. The docker-compose tree node added in Visual \", \"Studio 2022 Solution Explorer \\n\\nYou could deploy a multi-container application with a single docker-\", \"compose.yml file by using the \\ndocker-compose up command. However, Visual Studio adds a group of the\", \"m so you can override \\nvalues depending on the environment (development or production) and execution\", \" type (release or \\ndebug). This capability will be explained in later sections. \\n\\n86 \\n\\nCHAPTER 4 | D\", \"evelopment process for Docker-based applications \\n\\n \\n \\n \\n \\n\\fStep 5. Build and run your Docker applic\", \"ation \\n\\nIf your application only has a single container, you can run it by deploying it to your Dock\", \"er host (VM \\nor physical server). However, if your application contains multiple services, you can d\", \"eploy it as a \\ncomposed application, either using a single CLI command (docker-compose up), or with \", \"Visual Studio, \\nwhich will use that command under the covers. Let\\u2019s look at the different options. \\n\", \"\\nOption A: Running a single-container application \\n\\nUsing Docker CLI \\n\\nYou can run a Docker containe\", \"r using the docker run command, as shown in Figure 5-9: \\n\\ndocker run -t -d -p 80:5000 cesardl/netcor\", \"e-webapi-microservice-docker:first \\n\\nThe above command will create a new container instance from the\", \" specified image, every time it\\u2019s run. \\nYou can use the --name parameter to give a name to the conta\", \"iner and then use docker start {name} \\n(or use the container ID or automatic name) to run an existin\", \"g container instance. \\n\\nFigure 5-9. Running a Docker container using the docker run command \\n\\nIn thi\", \"s case, the command binds the internal port 5000 of the container to port 80 of the host \\nmachine. T\", \"his means that the host is listening on port 80 and forwarding to port 5000 on the \\ncontainer. \\n\\nThe\", \" hash shown is the container ID and it\\u2019s also assigned a random readable name if the --name \\noption \", \"is not used. \\n\\nUsing Visual Studio \\n\\nIf you haven\\u2019t added container orchestrator support, you can al\", \"so run a single container app in Visual \\nStudio by pressing Ctrl+F5 and you can also use F5 to debug\", \" the application within the container. The \\ncontainer runs locally using docker run. \\n\\nOption B: Run\", \"ning a multi-container application \\n\\nIn most enterprise scenarios, a Docker application will be comp\", \"osed of multiple services, which means \\nyou need to run a multi-container application, as shown in F\", \"igure 5-10. \\n\\n87 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n \\n \\n\\fFigure 5\", \"-10. VM with Docker containers deployed \\n\\nUsing Docker CLI \\n\\nTo run a multi-container application wi\", \"th the Docker CLI, you use the docker-compose up command. \\nThis command uses the docker-compose.yml \", \"file that you have at the solution level to deploy a \\nmulti-container application. Figure 5-11 shows\", \" the results when running the command from your \\nmain solution directory, which contains the docker-\", \"compose.yml file. \\n\\nFigure 5-11. Example results when running the docker-compose up command \\n\\nAfter \", \"the docker-compose up command runs, the application and its related containers are deployed \\ninto yo\", \"ur Docker host, as depicted in Figure 5-10. \\n\\nUsing Visual Studio \\n\\nRunning a multi-container applic\", \"ation using Visual Studio 2019 can\\u2019t get any simpler. You just press \\nCtrl+F5 to run or F5 to debug,\", \" as usual, setting up the docker-compose project as the startup project. \\nVisual Studio handles all \", \"needed setup, so you can create breakpoints as usual and debug what finally \\nbecome independent proc\", \"esses running in \\u201cremote servers\\u201d, with the debugger already attached, just \\nlike that. \\n\\nAs mention\", \"ed before, each time you add Docker solution support to a project within a solution, that \\nproject i\", \"s configured in the global (solution-level) docker-compose.yml file, which lets you run or \\ndebug th\", \"e whole solution at once. Visual Studio will start one container for each project that has \\nDocker s\", \"olution support enabled, and perform all the internal steps for you (dotnet publish, docker \\nbuild, \", \"etc.). \\n\\nIf you want to take a peek at all the drudgery, take a look at the file: \\n\\n{root solution f\", \"older}\\\\obj\\\\Docker\\\\docker-compose.vs.debug.g.yml \\n\\n88 \\n\\nCHAPTER 4 | Development process for Docker-ba\", \"sed applications \\n\\n \\n \\n \\n \\n\\fThe important point here is that, as shown in Figure 5-12, in Visual Stu\", \"dio 2019 there is an additional \\nDocker command for the F5 key action. This option lets you run or d\", \"ebug a multi-container \\napplication by running all the containers that are defined in the docker-com\", \"pose.yml files at the \\nsolution level. The ability to debug multiple-container solutions means that \", \"you can set several \\nbreakpoints, each breakpoint in a different project (container), and while debu\", \"gging from Visual \\nStudio you will stop at breakpoints defined in different projects and running on \", \"different containers. \\n\\nFigure 5-12. Running multi-container apps in Visual Studio 2022 \\n\\nAdditional\", \" resources \\n\\n\\u2022 \\n\\nDeploy an ASP.NET container to a remote Docker host \\nhttps://learn.microsoft.com/vi\", \"sualstudio/containers/hosting-web-apps-in-docker \\n\\nA note about testing and deploying with orchestra\", \"tors \\n\\nThe docker-compose up and docker run commands (or running and debugging the containers in \\nVi\", \"sual Studio) are adequate for testing containers in your development environment. But you should \\nno\", \"t use this approach for production deployments, where you should target orchestrators like \\nKubernet\", \"es or Service Fabric. If you\\u2019re using Kubernetes, you have to use pods to organize containers \\nand s\", \"ervices to network them. You also use deployments to organize pod creation and modification. \\n\\nStep \", \"6. Test your Docker application using your local Docker host \\n\\nThis step will vary depending on what\", \" your application is doing. In a simple .NET Web application that \\nis deployed as a single container\", \" or service, you can access the service by opening a browser on the \\nDocker host and navigating to t\", \"hat site, as shown in Figure 5-13. (If the configuration in the Dockerfile \\nmaps the container to a \", \"port on the host that is anything other than 80, include the host port in the \\nURL.) \\n\\nFigure 5-13. \", \"Example of testing your Docker application locally using localhost \\n\\n89 \\n\\nCHAPTER 4 | Development pr\", \"ocess for Docker-based applications \\n\\n \\n \\n \\n \\n \\n\\fIf localhost is not pointing to the Docker host IP \", \"(by default, when using Docker CE, it should), to \\nnavigate to your service, use the IP address of y\", \"our machine\\u2019s network card. \\n\\nThis URL in the browser uses port 80 for the particular container exam\", \"ple being discussed. However, \\ninternally the requests are being redirected to port 5000, because th\", \"at was how it was deployed with \\nthe docker run command, as explained in a previous step. \\n\\nYou can \", \"also test the application using curl from the terminal, as shown in Figure 5-14. In a Docker \\ninstal\", \"lation on Windows, the default Docker Host IP is always 10.0.75.1 in addition to your machine\\u2019s \\nact\", \"ual IP address. \\n\\nFigure 5-14. Example of testing your Docker application locally using curl \\n\\nTesti\", \"ng and debugging containers with Visual Studio 2022 \\n\\nWhen running and debugging the containers with\", \" Visual Studio 2022, you can debug the .NET \\napplication in much the same way as you would when runn\", \"ing without containers. \\n\\nTesting and debugging without Visual Studio \\n\\nIf you\\u2019re developing using t\", \"he editor/CLI approach, debugging containers is more difficult and you\\u2019ll \\nprobably want to debug by\", \" generating traces. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nQuickstart: Docker in Visual Studio. \\nhttps://l\", \"earn.microsoft.com/visualstudio/containers/container-tools \\n\\nDebugging apps in a local Docker contai\", \"ner \\nhttps://learn.microsoft.com/visualstudio/containers/edit-and-refresh \\n\\nSimplified workflow when\", \" developing containers with Visual Studio \\n\\nEffectively, the workflow when using Visual Studio is a \", \"lot simpler than if you use the editor/CLI \\napproach. Most of the steps required by Docker related t\", \"o the Dockerfile and docker-compose.yml \\nfiles are hidden or simplified by Visual Studio, as shown i\", \"n Figure 5-15. \\n\\n90 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n \\n\\fFigure \", \"5-15. Simplified workflow when developing with Visual Studio \\n\\nIn addition, you need to perform step\", \" 2 (adding Docker support to your projects) just once. Therefore, \\nthe workflow is similar to your u\", \"sual development tasks when using .NET for any other development. \\nYou need to know what is going on\", \" under the covers (the image build process, what base images \\nyou\\u2019re using, deployment of containers\", \", etc.) and sometimes you will also need to edit the Dockerfile \\nor docker-compose.yml file to custo\", \"mize behaviors. But most of the work is greatly simplified by using \\nVisual Studio, making you a lot\", \" more productive. \\n\\nUsing PowerShell commands in a Dockerfile to set up Windows \\nContainers \\n\\nWindow\", \"s Containers allow you to convert your existing Windows applications into Docker images and \\ndeploy \", \"them with the same tools as the rest of the Docker ecosystem. To use Windows Containers, \\nyou run Po\", \"werShell commands in the Dockerfile, as shown in the following example: \\n\\nFROM mcr.microsoft.com/win\", \"dows/servercore \\nLABEL Description=\\\"IIS\\\" Vendor=\\\"Microsoft\\\" Version=\\\"10\\\" \\nRUN powershell -Command Ad\", \"d-WindowsFeature Web-Server \\nCMD [ \\\"ping\\\", \\\"localhost\\\", \\\"-t\\\" ] \\n\\nIn this case, we are using a Window\", \"s Server Core base image (the FROM setting) and installing IIS with \\na PowerShell command (the RUN s\", \"etting). In a similar way, you could also use PowerShell commands \\nto set up additional components l\", \"ike ASP.NET 4.x, .NET Framework 4.6, or any other Windows \\nsoftware. For example, the following comm\", \"and in a Dockerfile sets up ASP.NET 4.5: \\n\\nRUN powershell add-windowsfeature web-asp-net45 \\n\\nAdditio\", \"nal resources \\n\\n\\u2022 \\n\\naspnet-docker/Dockerfile. Example PowerShell commands to run from dockerfiles to\", \" \\ninclude Windows features. \\n\\n91 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \", \"\\n \\n \\n\\fhttps://github.com/Microsoft/aspnet-docker/blob/master/4.7.1-windowsservercore-\\nltsc2016/runti\", \"me/Dockerfile \\n\\n92 \\n\\nCHAPTER 4 | Development process for Docker-based applications \\n\\n \\n \\n\\fCHAPTER  5\", \" \\n\\nDesigning and Developing \\nMulti-Container and \\nMicroservice-Based .NET \\nApplications \\n\\nDeveloping\", \" containerized microservice applications means you are building multi-container \\napplications. Howev\", \"er, a multi-container application could also be simpler\\u2014for example, a three-tier \\napplication\\u2014and m\", \"ight not be built using a microservice architecture. \\n\\nEarlier we raised the question \\u201cIs Docker nec\", \"essary when building a microservice architecture?\\u201d The \\nanswer is a clear no. Docker is an enabler a\", \"nd can provide significant benefits, but containers and \\nDocker are not a hard requirement for micro\", \"services. As an example, you could create a \\nmicroservices-based application with or without Docker \", \"when using Azure Service Fabric, which \\nsupports microservices running as simple processes or as Doc\", \"ker containers. \\n\\nHowever, if you know how to design and develop a microservices-based application t\", \"hat is also based \\non Docker containers, you will be able to design and develop any other, simpler a\", \"pplication model. \\nFor example, you might design a three-tier application that also requires a multi\", \"-container approach. \\nBecause of that, and because microservice architectures are an important trend\", \" within the container \\nworld, this section focuses on a microservice architecture implementation usi\", \"ng Docker containers. \\n\\nDesign a microservice-oriented application \\n\\nThis section focuses on develop\", \"ing a hypothetical server-side enterprise application. \\n\\nApplication specifications \\n\\nThe hypothetic\", \"al application handles requests by executing business logic, accessing databases, and \\nthen returnin\", \"g HTML, JSON, or XML responses. We will say that the application must support various \\nclients, incl\", \"uding desktop browsers running Single Page Applications (SPAs), traditional web apps, \\nmobile web ap\", \"ps, and native mobile apps. The application might also expose an API for third parties \\n\\n93 \\n\\nCHAPTE\", \"R 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fto co\", \"nsume. It should also be able to integrate its microservices or external applications \\nasynchronousl\", \"y, so that approach will help resiliency of the microservices in the case of partial failures. \\n\\nThe\", \" application will consist of these types of components: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nPresentation components. T\", \"hese components are responsible for handling the UI and \\nconsuming remote services. \\n\\nDomain or busi\", \"ness logic. This component is the application\\u2019s domain logic. \\n\\nDatabase access logic. This componen\", \"t consists of data access components responsible for \\naccessing databases (SQL or NoSQL). \\n\\nApplicat\", \"ion integration logic. This component includes a messaging channel, based on \\nmessage brokers. \\n\\nThe\", \" application will require high scalability, while allowing its vertical subsystems to scale out \\naut\", \"onomously, because certain subsystems will require more scalability than others. \\n\\nThe application m\", \"ust be able to be deployed in multiple infrastructure environments (multiple public \\nclouds and on-p\", \"remises) and ideally should be cross-platform, able to move from Linux to Windows \\n(or vice versa) e\", \"asily. \\n\\nDevelopment team context \\n\\nWe also assume the following about the development process for t\", \"he application: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nYou have multiple dev teams focusing on different business\", \" areas of the application. \\n\\nNew team members must become productive quickly, and the application mu\", \"st be easy to \\nunderstand and modify. \\n\\nThe application will have a long-term evolution and ever-cha\", \"nging business rules. \\n\\nYou need good long-term maintainability, which means having agility when imp\", \"lementing \\nnew changes in the future while being able to update multiple subsystems with minimum \\nim\", \"pact on the other subsystems. \\n\\nYou want to practice continuous integration and continuous deploymen\", \"t of the application. \\n\\nYou want to take advantage of emerging technologies (frameworks, programming\", \" languages, \\netc.) while evolving the application. You do not want to make full migrations of the \\na\", \"pplication when moving to new technologies, because that would result in high costs and \\nimpact the \", \"predictability and stability of the application. \\n\\nChoosing an architecture \\n\\nWhat should the applic\", \"ation deployment architecture be? The specifications for the application, along \\nwith the developmen\", \"t context, strongly suggest that you should architect the application by \\ndecomposing it into autono\", \"mous subsystems in the form of collaborating microservices and \\ncontainers, where a microservice is \", \"a container. \\n\\n94 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" Applications \\n\\n \\n \\n\\fIn this approach, each service (container) implements a set of cohesive and nar\", \"rowly related functions. \\nFor example, an application might consist of services such as the catalog \", \"service, ordering service, \\nbasket service, user profile service, etc. \\n\\nMicroservices communicate u\", \"sing protocols such as HTTP (REST), but also asynchronously (for \\nexample, using AMQP) whenever poss\", \"ible, especially when propagating updates with integration \\nevents. \\n\\nMicroservices are developed an\", \"d deployed as containers independently of one another. This approach \\nmeans that a development team \", \"can be developing and deploying a certain microservice without \\nimpacting other subsystems. \\n\\nEach m\", \"icroservice has its own database, allowing it to be fully decoupled from other microservices. \\nWhen \", \"necessary, consistency between databases from different microservices is achieved using \\napplication\", \"-level integration events (through a logical event bus), as handled in Command and Query \\nResponsibi\", \"lity Segregation (CQRS). Because of that, the business constraints must embrace eventual \\nconsistenc\", \"y between the multiple microservices and related databases. \\n\\neShopOnContainers: A reference applica\", \"tion for .NET and microservices deployed \\nusing containers \\n\\nSo that you can focus on the architectu\", \"re and technologies instead of thinking about a hypothetical \\nbusiness domain that you might not kno\", \"w, we have selected a well-known business domain\\u2014namely, \\na simplified e-commerce (e-shop) applicati\", \"on that presents a catalog of products, takes orders from \\ncustomers, verifies inventory, and perfor\", \"ms other business functions. This container-based application \\nsource code is available in the eShop\", \"OnContainers GitHub repo. \\n\\nThe application consists of multiple subsystems, including several store\", \" UI front ends (a Web \\napplication and a native mobile app), along with the back-end microservices a\", \"nd containers for all the \\nrequired server-side operations with several API Gateways as consolidated\", \" entry points to the internal \\nmicroservices. Figure 6-1 shows the architecture of the reference app\", \"lication. \\n\\n95 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications \\n\\n \\n \\n\\fFigure 6-1. The eShopOnContainers reference application architecture for developme\", \"nt environment \\n\\nThe above diagram shows that Mobile and SPA clients communicate to single API gatew\", \"ay endpoints, \\nthat then communicate to microservices. Traditional web clients communicate to MVC mi\", \"croservice, \\nthat communicates to microservices through the API gateway. \\n\\nHosting environment. In F\", \"igure 6-1, you see several containers deployed within a single Docker host. \\nThat would be the case \", \"when deploying to a single Docker host with the docker-compose up \\ncommand. However, if you are usin\", \"g an orchestrator or container cluster, each container could be \\nrunning in a different host (node),\", \" and any node could be running any number of containers, as we \\nexplained earlier in the architectur\", \"e section. \\n\\nCommunication architecture. The eShopOnContainers application uses two communication ty\", \"pes, \\ndepending on the kind of the functional action (queries versus updates and transactions): \\n\\n\\u2022 \", \"\\n\\n\\u2022 \\n\\nHttp client-to-microservice communication through API Gateways. This approach is used for \\nque\", \"ries and when accepting update or transactional commands from the client apps. The \\napproach using A\", \"PI Gateways is explained in detail in later sections. \\n\\nAsynchronous event-based communication. This\", \" communication occurs through an event bus \\nto propagate updates across microservices or to integrat\", \"e with external applications. The \\nevent bus can be implemented with any messaging-broker infrastruc\", \"ture technology like \\nRabbitMQ, or using higher-level (abstraction-level) service buses like Azure S\", \"ervice Bus, \\nNServiceBus, MassTransit, or Brighter. \\n\\nThe application is deployed as a set of micros\", \"ervices in the form of containers. Client apps can \\ncommunicate with those microservices running as \", \"containers through the public URLs published by \\nthe API Gateways. \\n\\n96 \\n\\nCHAPTER 5 | Designing and \", \"Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fData sovereignty per mi\", \"croservice \\n\\nIn the sample application, each microservice owns its own database or data source, alth\", \"ough all SQL \\nServer databases are deployed as a single container. This design decision was made onl\", \"y to make it \\neasy for a developer to get the code from GitHub, clone it, and open it in Visual Stud\", \"io or Visual \\nStudio Code. Or alternatively, it makes it easy to compile the custom Docker images us\", \"ing the .NET \\nCLI and the Docker CLI, and then deploy and run them in a Docker development environme\", \"nt. Either \\nway, using containers for data sources lets developers build and deploy in a matter of m\", \"inutes without \\nhaving to provision an external database or any other data source with hard dependen\", \"cies on \\ninfrastructure (cloud or on-premises). \\n\\nIn a real production environment, for high availab\", \"ility and for scalability, the databases should be \\nbased on database servers in the cloud or on-pre\", \"mises, but not in containers. \\n\\nTherefore, the units of deployment for microservices (and even for d\", \"atabases in this application) are \\nDocker containers, and the reference application is a multi-conta\", \"iner application that embraces \\nmicroservices principles. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\neShopOnContai\", \"ners GitHub repo. Source code for the reference application \\nhttps://aka.ms/eShopOnContainers/ \\n\\nBen\", \"efits of a microservice-based solution \\n\\nA microservice-based solution like this has many benefits: \", \"\\n\\nEach microservice is relatively small\\u2014easy to manage and evolve. Specifically: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nI\", \"t is easy for a developer to understand and get started quickly with good productivity. \\n\\nContainers\", \" start fast, which makes developers more productive. \\n\\nAn IDE like Visual Studio can load smaller pr\", \"ojects fast, making developers productive. \\n\\nEach microservice can be designed, developed, and deplo\", \"yed independently of other \\nmicroservices, which provide agility because it is easier to deploy new \", \"versions of \\nmicroservices frequently. \\n\\nIt is possible to scale out individual areas of the applica\", \"tion. For instance, the catalog service or \\nthe basket service might need to be scaled out, but not \", \"the ordering process. A microservices \\ninfrastructure will be much more efficient with regard to the\", \" resources used when scaling out than a \\nmonolithic architecture would be. \\n\\nYou can divide the deve\", \"lopment work between multiple teams. Each service can be owned by a \\nsingle development team. Each t\", \"eam can manage, develop, deploy, and scale their service \\nindependently of the rest of the teams. \\n\\n\", \"Issues are more isolated. If there is an issue in one service, only that service is initially impact\", \"ed \\n(except when the wrong design is used, with direct dependencies between microservices), and othe\", \"r \\nservices can continue to handle requests. In contrast, one malfunctioning component in a monolith\", \"ic \\n\\n97 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicati\", \"ons \\n\\n \\n \\n\\fdeployment architecture can bring down the entire system, especially when it involves res\", \"ources, such \\nas a memory leak. Additionally, when an issue in a microservice is resolved, you can d\", \"eploy just the \\naffected microservice without impacting the rest of the application. \\n\\nYou can use t\", \"he latest technologies. Because you can start developing services independently and \\nrun them side b\", \"y side (thanks to containers and .NET), you can start using the latest technologies and \\nframeworks \", \"expediently instead of being stuck on an older stack or framework for the whole \\napplication. \\n\\nDown\", \"sides of a microservice-based solution \\n\\nA microservice-based solution like this also has some drawb\", \"acks: \\n\\nDistributed application. Distributing the application adds complexity for developers when th\", \"ey are \\ndesigning and building the services. For example, developers must implement inter-service \\nc\", \"ommunication using protocols like HTTP or AMQP, which adds complexity for testing and exception \\nhan\", \"dling. It also adds latency to the system. \\n\\nDeployment complexity. An application that has dozens o\", \"f microservices types and needs high \\nscalability (it needs to be able to create many instances per \", \"service and balance those services across \\nmany hosts) means a high degree of deployment complexity \", \"for IT operations and management. If \\nyou are not using a microservice-oriented infrastructure (like\", \" an orchestrator and scheduler), that \\nadditional complexity can require far more development effort\", \"s than the business application itself. \\n\\nAtomic transactions. Atomic transactions between multiple \", \"microservices usually are not possible. \\nThe business requirements have to embrace eventual consiste\", \"ncy between multiple microservices. \\n\\nIncreased global resource needs (total memory, drives, and net\", \"work resources for all the servers or \\nhosts). In many cases, when you replace a monolithic applicat\", \"ion with a microservices approach, the \\namount of initial global resources needed by the new microse\", \"rvice-based application will be larger \\nthan the infrastructure needs of the original monolithic app\", \"lication. This approach is because the \\nhigher degree of granularity and distributed services requir\", \"es more global resources. However, given \\nthe low cost of resources in general and the benefit of be\", \"ing able to scale out certain areas of the \\napplication compared to long-term costs when evolving mo\", \"nolithic applications, the increased use of \\nresources is usually a good tradeoff for large, long-te\", \"rm applications. \\n\\nIssues with direct client-to-microservice communication. When the application is \", \"large, with \\ndozens of microservices, there are challenges and limitations if the application requir\", \"es direct client-\\nto-microservice communications. One problem is a potential mismatch between the ne\", \"eds of the \\nclient and the APIs exposed by each of the microservices. In certain cases, the client a\", \"pplication might \\nneed to make many separate requests to compose the UI, which can be inefficient ov\", \"er the Internet \\nand would be impractical over a mobile network. Therefore, requests from the client\", \" application to the \\nback-end system should be minimized. \\n\\nAnother problem with direct client-to-mi\", \"croservice communications is that some microservices might \\nbe using protocols that are not Web-frie\", \"ndly. One service might use a binary protocol, while another \\nservice might use AMQP messaging. Thos\", \"e protocols are not firewall-friendly and are best used \\ninternally. Usually, an application should \", \"use protocols such as HTTP and WebSockets for \\ncommunication outside of the firewall. \\n\\n98 \\n\\nCHAPTER\", \" 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fYet an\", \"other drawback with this direct client-to-service approach is that it makes it difficult to refactor\", \" \\nthe contracts for those microservices. Over time developers might want to change how the system is\", \" \\npartitioned into services. For example, they might merge two services or split a service into two \", \"or \\nmore services. However, if clients communicate directly with the services, performing this kind \", \"of \\nrefactoring can break compatibility with client apps. \\n\\nAs mentioned in the architecture section\", \", when designing and building a complex application based \\non microservices, you might consider the \", \"use of multiple fine-grained API Gateways instead of the \\nsimpler direct client-to-microservice comm\", \"unication approach. \\n\\nPartitioning the microservices. Finally, no matter, which approach you take fo\", \"r your microservice \\narchitecture, another challenge is deciding how to partition an end-to-end appl\", \"ication into multiple \\nmicroservices. As noted in the architecture section of the guide, there are s\", \"everal techniques and \\napproaches you can take. Basically, you need to identify areas of the applica\", \"tion that are decoupled \\nfrom the other areas and that have a low number of hard dependencies. In ma\", \"ny cases, this approach \\nis aligned to partitioning services by use case. For example, in our e-shop\", \" application, we have an \\nordering service that is responsible for all the business logic related to\", \" the order process. We also \\nhave the catalog service and the basket service that implement other ca\", \"pabilities. Ideally, each service \\nshould have only a small set of responsibilities. This approach i\", \"s similar to the single responsibility \\nprinciple (SRP) applied to classes, which states that a clas\", \"s should only have one reason to change. But \\nin this case, it is about microservices, so the scope \", \"will be larger than a single class. Most of all, a \\nmicroservice has to be autonomous, end to end, i\", \"ncluding responsibility for its own data sources. \\n\\nExternal versus internal architecture and design\", \" patterns \\n\\nThe external architecture is the microservice architecture composed by multiple services\", \", following the \\nprinciples described in the architecture section of this guide. However, depending \", \"on the nature of \\neach microservice, and independently of high-level microservice architecture you c\", \"hoose, it is \\ncommon and sometimes advisable to have different internal architectures, each based on\", \" different \\npatterns, for different microservices. The microservices can even use different technolo\", \"gies and \\nprogramming languages. Figure 6-2 illustrates this diversity. \\n\\n99 \\n\\nCHAPTER 5 | Designing\", \" and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fFigure 6-2. External\", \" versus internal architecture and design \\n\\nFor instance, in our eShopOnContainers sample, the catalo\", \"g, basket, and user profile microservices are \\nsimple (basically, CRUD subsystems). Therefore, their\", \" internal architecture and design is \\nstraightforward. However, you might have other microservices, \", \"such as the ordering microservice, \\nwhich is more complex and represents ever-changing business rule\", \"s with a high degree of domain \\ncomplexity. In cases like these, you might want to implement more ad\", \"vanced patterns within a \\nparticular microservice, like the ones defined with domain-driven design (\", \"DDD) approaches, as we are \\ndoing in the eShopOnContainers ordering microservice. (We will review th\", \"ese DDD patterns in the \\nsection later that explains the implementation of the eShopOnContainers ord\", \"ering microservice.) \\n\\nAnother reason for a different technology per microservice might be the natur\", \"e of each microservice. \\nFor example, it might be better to use a functional programming language li\", \"ke F#, or even a language \\nlike R if you are targeting AI and machine learning domains, instead of a\", \" more object-oriented \\nprogramming language like C#. \\n\\nThe bottom line is that each microservice can\", \" have a different internal architecture based on different \\ndesign patterns. Not all microservices s\", \"hould be implemented using advanced DDD patterns, because \\nthat would be over-engineering them. Simi\", \"larly, complex microservices with ever-changing business \\nlogic should not be implemented as CRUD co\", \"mponents, or you can end up with low-quality code. \\n\\nThe new world: multiple architectural patterns \", \"and polyglot \\nmicroservices \\n\\nThere are many architectural patterns used by software architects and \", \"developers. The following are a \\nfew (mixing architecture styles and architecture patterns): \\n\\n\\u2022 \\n\\nS\", \"imple CRUD, single-tier, single-layer. \\n\\n100 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container \", \"and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nTraditional N-Layered. \\n\\nDomai\", \"n-Driven Design N-layered. \\n\\nClean Architecture (as used with eShopOnWeb) \\n\\nCommand and Query Respon\", \"sibility Segregation (CQRS). \\n\\nEvent-Driven Architecture (EDA). \\n\\nYou can also build microservices w\", \"ith many technologies and languages, such as ASP.NET Core Web \\nAPIs, NancyFx, ASP.NET Core SignalR (\", \"available with .NET Core 2 or later), F#, Node.js, Python, Java, \\nC++, GoLang, and more. \\n\\nThe impor\", \"tant point is that no particular architecture pattern or style, nor any particular technology, is \\nr\", \"ight for all situations. Figure 6-3 shows some approaches and technologies (although not in any \\npar\", \"ticular order) that could be used in different microservices. \\n\\nFigure 6-3. Multi-architectural patt\", \"erns and the polyglot microservices world \\n\\nMulti-architectural pattern and polyglot microservices m\", \"eans you can mix and match languages and \\ntechnologies to the needs of each microservice and still h\", \"ave them talking to each other. As shown in \\nFigure 6-3, in applications composed of many microservi\", \"ces (Bounded Contexts in domain-driven \\ndesign terminology, or simply \\u201csubsystems\\u201d as autonomous mic\", \"roservices), you might implement \\neach microservice in a different way. Each might have a different \", \"architecture pattern and use different \\nlanguages and databases depending on the application\\u2019s natur\", \"e, business requirements, and \\npriorities. In some cases, the microservices might be similar. But th\", \"at is not usually the case, because \\neach subsystem\\u2019s context boundary and requirements are usually \", \"different. \\n\\n101 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET \", \"Applications \\n\\n \\n \\n \\n\\fFor instance, for a simple CRUD maintenance application, it might not make sen\", \"se to design and \\nimplement DDD patterns. But for your core domain or core business, you might need \", \"to apply more \\nadvanced patterns to tackle business complexity with ever-changing business rules. \\n\\n\", \"Especially when you deal with large applications composed by multiple subsystems, you should not \\nap\", \"ply a single top-level architecture based on a single architecture pattern. For instance, CQRS shoul\", \"d \\nnot be applied as a top-level architecture for a whole application, but might be useful for a spe\", \"cific set \\nof services. \\n\\nThere is no silver bullet or a right architecture pattern for every given \", \"case. You cannot have \\u201cone \\narchitecture pattern to rule them all.\\u201d Depending on the priorities of e\", \"ach microservice, you must \\nchoose a different approach for each, as explained in the following sect\", \"ions. \\n\\nCreating a simple data-driven CRUD microservice \\n\\nThis section outlines how to create a simp\", \"le microservice that performs create, read, update, and \\ndelete (CRUD) operations on a data source. \", \"\\n\\nDesigning a simple CRUD microservice \\n\\nFrom a design point of view, this type of containerized mic\", \"roservice is very simple. Perhaps the \\nproblem to solve is simple, or perhaps the implementation is \", \"only a proof of concept. \\n\\nFigure 6-4. Internal design for simple CRUD microservices \\n\\nAn example of\", \" this kind of simple data-drive service is the catalog microservice from the \\neShopOnContainers samp\", \"le application. This type of service implements all its functionality in a single \\nASP.NET Core Web \", \"API project that includes classes for its data model, its business logic, and its data \\naccess code.\", \" It also stores its related data in a database running in SQL Server (as another container \\nfor dev/\", \"test purposes), but could also be any regular SQL Server host, as shown in Figure 6-5. \\n\\n102 \\n\\nCHAPT\", \"ER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fFi\", \"gure 6-5. Simple data-driven/CRUD microservice design \\n\\nThe previous diagram shows the logical Catal\", \"og microservice, that includes its Catalog database, \\nwhich can be or not in the same Docker host. H\", \"aving the database in the same Docker host might be \\ngood for development, but not for production. W\", \"hen you are developing this kind of service, you only \\nneed ASP.NET Core and a data-access API or OR\", \"M like Entity Framework Core. You could also \\ngenerate Swagger metadata automatically through Swashb\", \"uckle to provide a description of what your \\nservice offers, as explained in the next section. \\n\\nNot\", \"e that running a database server like SQL Server within a Docker container is great for \\ndevelopment\", \" environments, because you can have all your dependencies up and running without \\nneeding to provisi\", \"on a database in the cloud or on-premises. This approach is convenient when \\nrunning integration tes\", \"ts. However, for production environments, running a database server in a \\ncontainer is not recommend\", \"ed, because you usually do not get high availability with that approach. \\nFor a production environme\", \"nt in Azure, it is recommended that you use Azure SQL DB or any other \\ndatabase technology that can \", \"provide high availability and high scalability. For example, for a NoSQL \\napproach, you might choose\", \" CosmosDB. \\n\\nFinally, by editing the Dockerfile and docker-compose.yml metadata files, you can confi\", \"gure how the \\nimage of this container will be created\\u2014what base image it will use, plus design setti\", \"ngs such as \\ninternal and external names and TCP ports. \\n\\nImplementing a simple CRUD microservice wi\", \"th ASP.NET Core \\n\\nTo implement a simple CRUD microservice using .NET and Visual Studio, you start by\", \" creating a \\nsimple ASP.NET Core Web API project (running on .NET so it can run on a Linux Docker ho\", \"st), as \\nshown in Figure 6-6. \\n\\n103 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications \\n\\n \\n \\n \\n\\fFigure 6-6. Creating an ASP.NET Core Web API project in Vis\", \"ual Studio 2019 \\n\\nTo create an ASP.NET Core Web API Project, first select an ASP.NET Core Web Applic\", \"ation and then \\nselect the API type. After creating the project, you can implement your MVC controll\", \"ers as you would \\nin any other Web API project, using the Entity Framework API or other API. In a ne\", \"w Web API project, \\nyou can see that the only dependency you have in that microservice is on ASP.NET\", \" Core itself. \\nInternally, within the Microsoft.AspNetCore.All dependency, it is referencing Entity \", \"Framework and \\nmany other .NET NuGet packages, as shown in Figure 6-7. \\n\\n104 \\n\\nCHAPTER 5 | Designing\", \" and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fFigure 6-7. Depend\", \"encies in a simple CRUD Web API microservice \\n\\nThe API project includes references to Microsoft.AspN\", \"etCore.App NuGet package, that includes \\nreferences to all essential packages. It could include some\", \" other packages as well. \\n\\nImplementing CRUD Web API services with Entity Framework Core \\n\\nEntity Fr\", \"amework (EF) Core is a lightweight, extensible, and cross-platform version of the popular \\nEntity Fr\", \"amework data access technology. EF Core is an object-relational mapper (ORM) that enables \\n.NET deve\", \"lopers to work with a database using .NET objects. \\n\\nThe catalog microservice uses EF and the SQL Se\", \"rver provider because its database is running in a \\ncontainer with the SQL Server for Linux Docker i\", \"mage. However, the database could be deployed into \\n\\n105 \\n\\nCHAPTER 5 | Designing and Developing Mult\", \"i-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fany SQL Server, such as Windows on-pre\", \"mises or Azure SQL DB. The only thing you would need to \\nchange is the connection string in the ASP.\", \"NET Web API microservice. \\n\\nThe data model \\n\\nWith EF Core, data access is performed by using a model\", \". A model is made up of (domain model) \\nentity classes and a derived context (DbContext) that repres\", \"ents a session with the database, allowing \\nyou to query and save data. You can generate a model fro\", \"m an existing database, manually code a \\nmodel to match your database, or use EF migrations techniqu\", \"e to create a database from your model, \\nusing the code-first approach (that makes it easy to evolve\", \" the database as your model changes over \\ntime). For the catalog microservice, the last approach has\", \" been used. You can see an example of the \\nCatalogItem entity class in the following code example, w\", \"hich is a simple Plain Old Class Object \\n(POCO) entity class. \\n\\npublic class CatalogItem \\n{ \\n    pub\", \"lic int Id { get; set; } \\n    public string Name { get; set; } \\n    public string Description { get;\", \" set; } \\n    public decimal Price { get; set; } \\n    public string PictureFileName { get; set; } \\n  \", \"  public string PictureUri { get; set; } \\n    public int CatalogTypeId { get; set; } \\n    public Cat\", \"alogType CatalogType { get; set; } \\n    public int CatalogBrandId { get; set; } \\n    public CatalogB\", \"rand CatalogBrand { get; set; } \\n    public int AvailableStock { get; set; } \\n    public int Restock\", \"Threshold { get; set; } \\n    public int MaxStockThreshold { get; set; } \\n\\n    public bool OnReorder \", \"{ get; set; } \\n    public CatalogItem() { } \\n\\n    // Additional code ... \\n} \\n\\nYou also need a DbCont\", \"ext that represents a session with the database. For the catalog microservice, \\nthe CatalogContext c\", \"lass derives from the DbContext base class, as shown in the following example: \\n\\npublic class Catalo\", \"gContext : DbContext \\n{ \\n    public CatalogContext(DbContextOptions<CatalogContext> options) : base(\", \"options) \\n    { } \\n    public DbSet<CatalogItem> CatalogItems { get; set; } \\n    public DbSet<Catalo\", \"gBrand> CatalogBrands { get; set; } \\n    public DbSet<CatalogType> CatalogTypes { get; set; } \\n\\n    \", \"// Additional code ... \\n} \\n\\nYou can have additional DbContext implementations. For example, in the s\", \"ample Catalog.API \\nmicroservice, there\\u2019s a second DbContext named CatalogContextSeed where it automa\", \"tically \\npopulates the sample data the first time it tries to access the database. This method is us\", \"eful for demo \\ndata and for automated testing scenarios, as well. \\n\\n106 \\n\\nCHAPTER 5 | Designing and \", \"Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\fWithin the DbContex\", \"t, you use the OnModelCreating method to customize object/database entity \\nmappings and other EF ext\", \"ensibility points. \\n\\nQuerying data from Web API controllers \\n\\nInstances of your entity classes are t\", \"ypically retrieved from the database using Language-Integrated \\nQuery (LINQ), as shown in the follow\", \"ing example: \\n\\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class CatalogController : ControllerBase \\n{ \\n \", \"   private readonly CatalogContext _catalogContext; \\n    private readonly CatalogSettings _settings;\", \" \\n    private readonly ICatalogIntegrationEventService _catalogIntegrationEventService; \\n\\n    public\", \" CatalogController( \\n        CatalogContext context, \\n        IOptionsSnapshot<CatalogSettings> sett\", \"ings, \\n        ICatalogIntegrationEventService catalogIntegrationEventService) \\n    { \\n        _cata\", \"logContext = context ?? throw new ArgumentNullException(nameof(context)); \\n        _catalogIntegrati\", \"onEventService = catalogIntegrationEventService \\n            ?? throw new ArgumentNullException(name\", \"of(catalogIntegrationEventService)); \\n\\n        _settings = settings.Value; \\n        context.ChangeTr\", \"acker.QueryTrackingBehavior = QueryTrackingBehavior.NoTracking; \\n    } \\n\\n    // GET api/v1/[controll\", \"er]/items[?pageSize=3&pageIndex=10] \\n    [HttpGet] \\n    [Route(\\\"items\\\")] \\n    [ProducesResponseType(\", \"typeof(PaginatedItemsViewModel<CatalogItem>), \\n(int)HttpStatusCode.OK)] \\n    [ProducesResponseType(t\", \"ypeof(IEnumerable<CatalogItem>), (int)HttpStatusCode.OK)] \\n    [ProducesResponseType((int)HttpStatus\", \"Code.BadRequest)] \\n    public async Task<IActionResult> ItemsAsync( \\n        [FromQuery]int pageSize\", \" = 10, \\n        [FromQuery]int pageIndex = 0, \\n        string ids = null) \\n    { \\n        if (!strin\", \"g.IsNullOrEmpty(ids)) \\n        { \\n            var items = await GetItemsByIdsAsync(ids); \\n\\n         \", \"   if (!items.Any()) \\n            { \\n                return BadRequest(\\\"ids value invalid. Must be c\", \"omma-separated list of \\nnumbers\\\"); \\n            } \\n\\n            return Ok(items); \\n        } \\n\\n     \", \"   var totalItems = await _catalogContext.CatalogItems \\n            .LongCountAsync(); \\n\\n        var\", \" itemsOnPage = await _catalogContext.CatalogItems \\n            .OrderBy(c => c.Name) \\n            .S\", \"kip(pageSize * pageIndex) \\n\\n107 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microserv\", \"ice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\f            .Take(pageSize) \\n            .ToListAsy\", \"nc(); \\n\\n        itemsOnPage = ChangeUriPlaceholder(itemsOnPage); \\n\\n        var model = new Paginated\", \"ItemsViewModel<CatalogItem>( \\n            pageIndex, pageSize, totalItems, itemsOnPage); \\n\\n        r\", \"eturn Ok(model); \\n    } \\n    //... \\n} \\n\\nSaving data \\n\\nData is created, deleted, and modified in the \", \"database using instances of your entity classes. You \\ncould add code like the following hard-coded e\", \"xample (mock data, in this case) to your Web API \\ncontrollers. \\n\\nvar catalogItem = new CatalogItem()\", \" {CatalogTypeId=2, CatalogBrandId=2, \\n                                     Name=\\\"Roslyn T-Shirt\\\", Pr\", \"ice = 12}; \\n_context.Catalog.Add(catalogItem); \\n_context.SaveChanges(); \\n\\nDependency Injection in AS\", \"P.NET Core and Web API controllers \\n\\nIn ASP.NET Core, you can use Dependency Injection (DI) out of t\", \"he box. You do not need to set up a \\nthird-party Inversion of Control (IoC) container, although you \", \"can plug your preferred IoC container \\ninto the ASP.NET Core infrastructure if you want. In this cas\", \"e, it means that you can directly inject the \\nrequired EF DBContext or additional repositories throu\", \"gh the controller constructor. \\n\\nIn the CatalogController class mentioned earlier, CatalogContext (w\", \"hich inherits from DbContext) type \\nis injected along with the other required objects in the Catalog\", \"Controller() constructor. \\n\\nAn important configuration to set up in the Web API project is the DbCon\", \"text class registration into \\nthe service\\u2019s IoC container. You typically do so in the Program.cs fil\", \"e by calling the \\nbuilder.Services.AddDbContext<CatalogContext>() method, as shown in the following \", \"simplified \\nexample: \\n\\n// Additional code... \\n\\nbuilder.Services.AddDbContext<CatalogContext>(options\", \" => \\n{ \\n    options.UseSqlServer(builder.Configuration[\\\"ConnectionString\\\"], \\n    sqlServerOptionsAct\", \"ion: sqlOptions => \\n    { \\n        sqlOptions.MigrationsAssembly( \\n            typeof(Program).GetTy\", \"peInfo().Assembly.GetName().Name); \\n\\n        //Configuring Connection Resiliency: \\n        sqlOption\", \"s. \\n            EnableRetryOnFailure(maxRetryCount: 5, \\n            maxRetryDelay: TimeSpan.FromSeco\", \"nds(30), \\n            errorNumbersToAdd: null); \\n    }); \\n\\n108 \\n\\nCHAPTER 5 | Designing and Developin\", \"g Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\f    // Changing defaul\", \"t behavior when client evaluation occurs to throw. \\n    // Default in EFCore would be to log warning\", \" when client evaluation is done. \\n    options.ConfigureWarnings(warnings => warnings.Throw( \\n       \", \" RelationalEventId.QueryClientEvaluationWarning)); \\n}); \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nQuerying Da\", \"ta \\nhttps://learn.microsoft.com/ef/core/querying/index \\n\\nSaving Data \\nhttps://learn.microsoft.com/ef\", \"/core/saving/index \\n\\nThe DB connection string and environment variables used by Docker \\ncontainers \\n\", \"\\nYou can use the ASP.NET Core settings and add a ConnectionString property to your settings.json fil\", \"e \\nas shown in the following example: \\n\\n{ \\n    \\\"ConnectionString\\\": \\\"Server=tcp:127.0.0.1,5433;Initia\", \"l \\nCatalog=Microsoft.eShopOnContainers.Services.CatalogDb;User Id=sa;Password=[PLACEHOLDER]\\\", \\n    \\\"\", \"ExternalCatalogBaseUrl\\\": \\\"http://host.docker.internal:5101\\\", \\n    \\\"Logging\\\": { \\n        \\\"IncludeScop\", \"es\\\": false, \\n        \\\"LogLevel\\\": { \\n            \\\"Default\\\": \\\"Debug\\\", \\n            \\\"System\\\": \\\"Informat\", \"ion\\\", \\n            \\\"Microsoft\\\": \\\"Information\\\" \\n        } \\n    } \\n} \\n\\nThe settings.json file can have\", \" default values for the ConnectionString property or for any other \\nproperty. However, those propert\", \"ies will be overridden by the values of environment variables that \\nyou specify in the docker-compos\", \"e.override.yml file, when using Docker. \\n\\nFrom your docker-compose.yml or docker-compose.override.ym\", \"l files, you can initialize those \\nenvironment variables so that Docker will set them up as OS envir\", \"onment variables for you, as shown \\nin the following docker-compose.override.yml file (the connectio\", \"n string and other lines wrap in this \\nexample, but it would not wrap in your own file). \\n\\n# docker-\", \"compose.override.yml \\n\\n# \\ncatalog-api: \\n  environment: \\n    - \\nConnectionString=Server=sqldata;Datab\", \"ase=Microsoft.eShopOnContainers.Services.CatalogDb;Use\\nr Id=sa;Password=[PLACEHOLDER] \\n    # Additio\", \"nal environment variables for this service \\n  ports: \\n    - \\\"5101:80\\\" \\n\\n109 \\n\\nCHAPTER 5 | Designing \", \"and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fThe docker-compose.\", \"yml files at the solution level are not only more flexible than configuration files \\nat the project \", \"or microservice level, but also more secure if you override the environment variables \\ndeclared at t\", \"he docker-compose files with values set from your deployment tools, like from Azure \\nDevOps Services\", \" Docker deployment tasks. \\n\\nFinally, you can get that value from your code by using builder.Configur\", \"ation\\\\[\\\"ConnectionString\\\"\\\\], as \\nshown in an earlier code example. \\n\\nHowever, for production environ\", \"ments, you might want to explore additional ways on how to store \\nsecrets like the connection string\", \"s. An excellent way to manage application secrets is using Azure Key \\nVault. \\n\\nAzure Key Vault helps\", \" to store and safeguard cryptographic keys and secrets used by your cloud \\napplications and services\", \". A secret is anything you want to keep strict control of, like API keys, \\nconnection strings, passw\", \"ords, etc. and strict control includes usage logging, setting expiration, \\nmanaging access, among ot\", \"hers. \\n\\nAzure Key Vault allows a detailed control level of the application secrets usage without the\", \" need to let \\nanyone know them. The secrets can even be rotated for enhanced security without disrup\", \"ting \\ndevelopment or operations. \\n\\nApplications have to be registered in the organization\\u2019s Active D\", \"irectory, so they can use the Key \\nVault. \\n\\nYou can check the Key Vault Concepts documentation for m\", \"ore details. \\n\\nImplementing versioning in ASP.NET Web APIs \\n\\nAs business requirements change, new co\", \"llections of resources may be added, the relationships \\nbetween resources might change, and the stru\", \"cture of the data in resources might be amended. \\nUpdating a Web API to handle new requirements is a\", \" relatively straightforward process, but you must \\nconsider the effects that such changes will have \", \"on client applications consuming the Web API. \\nAlthough the developer designing and implementing a W\", \"eb API has full control over that API, the \\ndeveloper does not have the same degree of control over \", \"client applications that might be built by \\nthird-party organizations operating remotely. \\n\\nVersioni\", \"ng enables a Web API to indicate the features and resources that it exposes. A client \\napplication c\", \"an then submit requests to a specific version of a feature or resource. There are several \\napproache\", \"s to implement versioning: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nURI versioning \\n\\nQuery string versioning \\n\\nHeader versionin\", \"g \\n\\nQuery string and URI versioning are the simplest to implement. Header versioning is a good \\nappr\", \"oach. However, header versioning is not as explicit and straightforward as URI versioning. \\nBecause \", \"URL versioning is the simplest and most explicit, the eShopOnContainers sample application \\nuses URI\", \" versioning. \\n\\n110 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NE\", \"T Applications \\n\\n \\n \\n\\fWith URI versioning, as in the eShopOnContainers sample application, each time\", \" you modify the Web \\nAPI or change the schema of resources, you add a version number to the URI for \", \"each resource. \\nExisting URIs should continue to operate as before, returning resources that conform\", \" to the schema \\nthat matches the requested version. \\n\\nAs shown in the following code example, the ve\", \"rsion can be set by using the Route attribute in the \\nWeb API controller, which makes the version ex\", \"plicit in the URI (v1 in this case). \\n\\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class CatalogControlle\", \"r : ControllerBase \\n{ \\n    // Implementation ... \\n\\nThis versioning mechanism is simple and depends o\", \"n the server routing the request to the \\nappropriate endpoint. However, for a more sophisticated ver\", \"sioning and the best method when using \\nREST, you should use hypermedia and implement HATEOAS (Hyper\", \"text as the Engine of Application \\nState). \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nASP.NET API Vers\", \"ioning  https://github.com/dotnet/aspnet-api-versioning \\n\\nScott Hanselman. ASP.NET Core RESTful Web \", \"API versioning made easy \\nhttps://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.a\", \"spx \\n\\nVersioning a RESTful web API \\nhttps://learn.microsoft.com/azure/architecture/best-practices/ap\", \"i-design#versioning-a-\\nrestful-web-api \\n\\nRoy Fielding. Versioning, Hypermedia, and REST \\nhttps://www\", \".infoq.com/articles/roy-fielding-on-versioning \\n\\nGenerating Swagger description metadata from your A\", \"SP.NET Core \\nWeb API \\n\\nSwagger is a commonly used open source framework backed by a large ecosystem \", \"of tools that helps \\nyou design, build, document, and consume your RESTful APIs. It is becoming the \", \"standard for the APIs \\ndescription metadata domain. You should include Swagger description metadata \", \"with any kind of \\nmicroservice, either data-driven microservices or more advanced domain-driven micr\", \"oservices (as \\nexplained in the following section). \\n\\nThe heart of Swagger is the Swagger specificat\", \"ion, which is API description metadata in a JSON or \\nYAML file. The specification creates the RESTfu\", \"l contract for your API, detailing all its resources and \\noperations in both a human- and machine-re\", \"adable format for easy development, discovery, and \\nintegration. \\n\\nThe specification is the basis of\", \" the OpenAPI Specification (OAS) and is developed in an open, \\ntransparent, and collaborative commun\", \"ity to standardize the way RESTful interfaces are defined. \\n\\n111 \\n\\nCHAPTER 5 | Designing and Develop\", \"ing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fThe specification defines the st\", \"ructure for how a service can be discovered and how its capabilities \\nunderstood. For more informati\", \"on, including a web editor and examples of Swagger specifications \\nfrom companies like Spotify, Uber\", \", Slack, and Microsoft, see the Swagger site (https://swagger.io). \\n\\nWhy use Swagger? \\n\\nThe main rea\", \"sons to generate Swagger metadata for your APIs are the following. \\n\\nAbility for other products to a\", \"utomatically consume and integrate your APIs. Dozens of products \\nand commercial tools and many libr\", \"aries and frameworks support Swagger. Microsoft has high-level \\nproducts and tools that can automati\", \"cally consume Swagger-based APIs, such as the following: \\n\\n\\u2022 \\n\\nAutoRest. You can automatically gener\", \"ate .NET client classes for calling Swagger. This tool can \\nbe used from the CLI and it also integra\", \"tes with Visual Studio for easy use through the GUI. \\n\\n\\u2022  Microsoft Flow. You can automatically use \", \"and integrate your API into a high-level Microsoft \\n\\nFlow workflow, with no programming skills requi\", \"red. \\n\\n\\u2022  Microsoft PowerApps. You can automatically consume your API from PowerApps mobile apps \\n\\nb\", \"uilt with PowerApps Studio, with no programming skills required. \\n\\n\\u2022 \\n\\nAzure App Service Logic Apps.\", \" You can automatically use and integrate your API into an Azure \\nApp Service Logic App, with no prog\", \"ramming skills required. \\n\\nAbility to automatically generate API documentation. When you create larg\", \"e-scale RESTful APIs, \\nsuch as complex microservice-based applications, you need to handle many endp\", \"oints with different \\ndata models used in the request and response payloads. Having proper documenta\", \"tion and having a \\nsolid API explorer, as you get with Swagger, is key for the success of your API a\", \"nd adoption by \\ndevelopers. \\n\\nSwagger\\u2019s metadata is what Microsoft Flow, PowerApps, and Azure Logic \", \"Apps use to understand how \\nto use APIs and connect to them. \\n\\nThere are several options to automate\", \" Swagger metadata generation for ASP.NET Core REST API \\napplications, in the form of functional API \", \"help pages, based on swagger-ui. \\n\\nProbably the best know is Swashbuckle, which is currently used in\", \" eShopOnContainers and we\\u2019ll cover \\nin some detail in this guide but there\\u2019s also the option to use \", \"NSwag, which can generate Typescript \\nand C# API clients, as well as C# controllers, from a Swagger \", \"or OpenAPI specification and even by \\nscanning the .dll that contains the controllers, using NSwagSt\", \"udio. \\n\\nHow to automate API Swagger metadata generation with the Swashbuckle NuGet \\npackage \\n\\nGenera\", \"ting Swagger metadata manually (in a JSON or YAML file) can be tedious work. However, you \\ncan autom\", \"ate API discovery of ASP.NET Web API services by using the Swashbuckle NuGet package to \\ndynamically\", \" generate Swagger API metadata. \\n\\nSwashbuckle automatically generates Swagger metadata for your ASP.\", \"NET Web API projects. It \\nsupports ASP.NET Core Web API projects and the traditional ASP.NET Web API\", \" and any other flavor, \\n\\n112 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice\", \"-Based .NET Applications \\n\\n \\n \\n\\fsuch as Azure API App, Azure Mobile App, Azure Service Fabric micros\", \"ervices based on ASP.NET. It \\nalso supports plain Web API deployed on containers, as in for the refe\", \"rence application. \\n\\nSwashbuckle combines API Explorer and Swagger or swagger-ui to provide a rich d\", \"iscovery and \\ndocumentation experience for your API consumers. In addition to its Swagger metadata g\", \"enerator \\nengine, Swashbuckle also contains an embedded version of swagger-ui, which it will automat\", \"ically \\nserve up once Swashbuckle is installed. \\n\\nThis means you can complement your API with a nice\", \" discovery UI to help developers to use your API. \\nIt requires a small amount of code and maintenanc\", \"e because it is automatically generated, allowing \\nyou to focus on building your API. The result for\", \" the API Explorer looks like Figure 6-8. \\n\\nFigure 6-8. Swashbuckle API Explorer based on Swagger met\", \"adata\\u2014eShopOnContainers catalog microservice \\n\\nThe Swashbuckle generated Swagger UI API documentatio\", \"n includes all published actions. The API \\nexplorer is not the most important thing here. Once you h\", \"ave a Web API that can describe itself in \\nSwagger metadata, your API can be used seamlessly from Sw\", \"agger-based tools, including client \\nproxy-class code generators that can target many platforms. For\", \" example, as mentioned, AutoRest \\nautomatically generates .NET client classes. But additional tools \", \"like swagger-codegen are also \\navailable, which allow code generation of API client libraries, serve\", \"r stubs, and documentation \\nautomatically. \\n\\nCurrently, Swashbuckle consists of five internal NuGet \", \"packages under the high-level metapackage \\nSwashbuckle.AspNetCore for ASP.NET Core applications. \\n\\nA\", \"fter you have installed these NuGet packages in your Web API project, you need to configure \\nSwagger\", \" in the Program.cs class, as in the following simplified code: \\n\\n// Add framework services. \\n\\nbuilde\", \"r.Services.AddSwaggerGen(options => \\n{ \\n\\n113 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container \", \"and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\f    options.DescribeAllEnumsAsStrings(); \\n    \", \"options.SwaggerDoc(\\\"v1\\\", new OpenApiInfo \\n    { \\n        Title = \\\"eShopOnContainers - Catalog HTTP A\", \"PI\\\", \\n        Version = \\\"v1\\\", \\n        Description = \\\"The Catalog Microservice HTTP API. This is a D\", \"ata-Driven/CRUD \\nmicroservice sample\\\" \\n    }); \\n}); \\n\\n// Other startup code... \\n\\napp.UseSwagger() \\n \", \"   .UseSwaggerUI(c => \\n    { \\n        c.SwaggerEndpoint(\\\"/swagger/v1/swagger.json\\\", \\\"My API V1\\\"); \\n \", \"   }); \\n    ``` \\n    ::: \\n\\nOnce this is done, you can start your application and browse the followin\", \"g Swagger JSON and \\nUI endpoints using URLs like these: \\n\\n:::{custom-style=CodeBox} \\n```console \\n  h\", \"ttp://<your-root-url>/swagger/v1/swagger.json \\n\\n  http://<your-root-url>/swagger/ \\n\\nYou previously s\", \"aw the generated UI created by Swashbuckle for a URL like http://<your-root-\\nurl>/swagger. In Figure\", \" 6-9, you can also see how you can test any API method. \\n\\n114 \\n\\nCHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n\\fFigure 6-9. Swashbuckle U\", \"I testing the Catalog/Items API method \\n\\nThe Swagger UI API detail shows a sample of the response an\", \"d can be used to execute the real API, \\nwhich is great for developer discovery. Figure 6-10 shows th\", \"e Swagger JSON metadata generated \\nfrom the eShopOnContainers microservice (which is what the tools \", \"use underneath) when you request \\nhttp://<your-root-url>/swagger/v1/swagger.json using Postman. \\n\\n11\", \"5 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n\", \" \\n \\n \\n\\fFigure 6-10. Swagger JSON metadata \\n\\nIt is that simple. And because it is automatically gener\", \"ated, the Swagger metadata will grow when you \\nadd more functionality to your API. \\n\\nAdditional reso\", \"urces \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nASP.NET Web API Help Pages using Swagger \\nhttps://learn.microsoft.com/aspnet/cor\", \"e/tutorials/web-api-help-pages-using-swagger \\n\\nGet started with Swashbuckle and ASP.NET Core \\nhttps:\", \"//learn.microsoft.com/aspnet/core/tutorials/getting-started-with-swashbuckle \\n\\nGet started with NSwa\", \"g and ASP.NET Core \\nhttps://learn.microsoft.com/aspnet/core/tutorials/getting-started-with-nswag \\n\\nD\", \"efining your multi-container application with \\ndocker-compose.yml \\n\\nIn this guide, the docker-compos\", \"e.yml file was introduced in the section Step 4. Define your services \\nin docker-compose.yml when bu\", \"ilding a multi-container Docker application. However, there are \\nadditional ways to use the docker-c\", \"ompose files that are worth exploring in further detail. \\n\\nFor example, you can explicitly describe \", \"how you want to deploy your multi-container application in \\nthe docker-compose.yml file. Optionally,\", \" you can also describe how you are going to build your \\ncustom Docker images. (Custom Docker images \", \"can also be built with the Docker CLI.) \\n\\n116 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container\", \" and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fBasically, you define each of the containers you \", \"want to deploy plus certain characteristics for each \\ncontainer deployment. Once you have a multi-co\", \"ntainer deployment description file, you can deploy \\nthe whole solution in a single action orchestra\", \"ted by the docker-compose up CLI command, or you \\ncan deploy it transparently from Visual Studio. Ot\", \"herwise, you would need to use the Docker CLI to \\ndeploy container-by-container in multiple steps by\", \" using the docker run command from the \\ncommand line. Therefore, each service defined in docker-comp\", \"ose.yml must specify exactly one \\nimage or build. Other keys are optional, and are analogous to thei\", \"r docker run command-line \\ncounterparts. \\n\\nThe following YAML code is the definition of a possible g\", \"lobal but single docker-compose.yml file for \\nthe eShopOnContainers sample. This code is not the act\", \"ual docker-compose file from \\neShopOnContainers. Instead, it is a simplified and consolidated versio\", \"n in a single file, which is not the \\nbest way to work with docker-compose files, as will be explain\", \"ed later. \\n\\nversion: '3.4' \\n\\nservices: \\n  webmvc: \\n    image: eshop/webmvc \\n    environment: \\n      \", \"- CatalogUrl=http://catalog-api \\n      - OrderingUrl=http://ordering-api \\n      - BasketUrl=http://b\", \"asket-api \\n    ports: \\n      - \\\"5100:80\\\" \\n    depends_on: \\n      - catalog-api \\n      - ordering-api\", \" \\n      - basket-api \\n\\n  catalog-api: \\n    image: eshop/catalog-api \\n    environment: \\n      - Conne\", \"ctionString=Server=sqldata;Initial Catalog=CatalogData;User \\nId=sa;Password=[PLACEHOLDER] \\n    expos\", \"e: \\n      - \\\"80\\\" \\n    ports: \\n      - \\\"5101:80\\\" \\n    #extra hosts can be used for standalone SQL Ser\", \"ver or services at the dev PC \\n    extra_hosts: \\n      - \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on\", \": \\n      - sqldata \\n\\n  ordering-api: \\n    image: eshop/ordering-api \\n    environment: \\n      - Conne\", \"ctionString=Server=sqldata;Database=Services.OrderingDb;User \\nId=sa;Password=[PLACEHOLDER] \\n    port\", \"s: \\n      - \\\"5102:80\\\" \\n    #extra hosts can be used for standalone SQL Server or services at the dev\", \" PC \\n    extra_hosts: \\n      - \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on: \\n      - sqldata \\n\\n117 \\n\", \"\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \", \"\\n \\n \\n \\n\\f  basket-api: \\n    image: eshop/basket-api \\n    environment: \\n      - ConnectionString=sqlda\", \"ta \\n    ports: \\n      - \\\"5103:80\\\" \\n    depends_on: \\n      - sqldata \\n\\n  sqldata: \\n    environment: \\n\", \"      - SA_PASSWORD=[PLACEHOLDER] \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5434:1433\\\" \\n\\n  basket\", \"data: \\n    image: redis \\n\\nThe root key in this file is services. Under that key, you define the serv\", \"ices you want to deploy and run \\nwhen you execute the docker-compose up command or when you deploy f\", \"rom Visual Studio by using \\nthis docker-compose.yml file. In this case, the docker-compose.yml file \", \"has multiple services defined, \\nas described in the following table. \\n\\nService name \\n\\nDescription \\n\\n\", \"webmvc \\n\\ncatalog-api \\n\\nordering-api \\n\\nsqldata \\n\\nbasket-api \\n\\nbasketdata \\n\\nContainer including the AS\", \"P.NET Core MVC \\napplication consuming the microservices from \\nserver-side C# \\n\\nContainer including t\", \"he Catalog ASP.NET Core \\nWeb API microservice \\n\\nContainer including the Ordering ASP.NET \\nCore Web A\", \"PI microservice \\n\\nContainer running SQL Server for Linux, \\nholding the microservices databases \\n\\nCon\", \"tainer with the Basket ASP.NET Core Web \\nAPI microservice \\n\\nContainer running the REDIS cache servic\", \"e, \\nwith the basket database as a REDIS cache \\n\\nA simple Web Service API container \\n\\nFocusing on a s\", \"ingle container, the catalog-api container-microservice has a straightforward \\ndefinition: \\n\\n  catal\", \"og-api: \\n    image: eshop/catalog-api \\n    environment: \\n      - ConnectionString=Server=sqldata;Ini\", \"tial Catalog=CatalogData;User \\nId=sa;Password=[PLACEHOLDER] \\n    expose: \\n\\n118 \\n\\nCHAPTER 5 | Designi\", \"ng and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\f      - \\\"80\\\"\", \" \\n    ports: \\n      - \\\"5101:80\\\" \\n    #extra hosts can be used for standalone SQL Server or services \", \"at the dev PC \\n    extra_hosts: \\n      - \\\"CESARDLSURFBOOK:10.0.75.1\\\" \\n    depends_on: \\n      - sqlda\", \"ta \\n\\nThis containerized service has the following basic configuration: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nIt is based on \", \"the custom eshop/catalog-api image. For simplicity\\u2019s sake, there is no \\nbuild: key setting in the fi\", \"le. This means that the image must have been previously built (with \\ndocker build) or have been down\", \"loaded (with the docker pull command) from any Docker \\nregistry. \\n\\nIt defines an environment variabl\", \"e named ConnectionString with the connection string to be \\nused by Entity Framework to access the SQ\", \"L Server instance that contains the catalog data \\nmodel. In this case, the same SQL Server container\", \" is holding multiple databases. Therefore, \\nyou need less memory in your development machine for Doc\", \"ker. However, you could also \\ndeploy one SQL Server container for each microservice database. \\n\\nThe \", \"SQL Server name is sqldata, which is the same name used for the container that is \\nrunning the SQL S\", \"erver instance for Linux. This is convenient; being able to use this name \\nresolution (internal to t\", \"he Docker host) will resolve the network address so you don\\u2019t need to \\nknow the internal IP for the \", \"containers you are accessing from other containers. \\n\\nBecause the connection string is defined by an\", \" environment variable, you could set that variable \\nthrough a different mechanism and at a different\", \" time. For example, you could set a different \\nconnection string when deploying to production in the\", \" final hosts, or by doing it from your CI/CD \\npipelines in Azure DevOps Services or your preferred D\", \"evOps system. \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nIt exposes port 80 for internal access to the catalog-api service within\", \" the Docker host. The \\nhost is currently a Linux VM because it is based on a Docker image for Linux,\", \" but you could \\nconfigure the container to run on a Windows image instead. \\n\\nIt forwards the exposed\", \" port 80 on the container to port 5101 on the Docker host machine \\n(the Linux VM). \\n\\nIt links the we\", \"b service to the sqldata service (the SQL Server instance for Linux database \\nrunning in a container\", \"). When you specify this dependency, the catalog-api container will not \\nstart until the sqldata con\", \"tainer has already started; this aspect is important because catalog-\\napi needs to have the SQL Serv\", \"er database up and running first. However, this kind of \\ncontainer dependency is not enough in many \", \"cases, because Docker checks only at the \\ncontainer level. Sometimes the service (in this case SQL S\", \"erver) might still not be ready, so it is \\nadvisable to implement retry logic with exponential backo\", \"ff in your client microservices. That \\nway, if a dependency container is not ready for a short time,\", \" the application will still be \\nresilient. \\n\\n\\u2022 \\n\\nIt is configured to allow access to external server\", \"s: the extra_hosts setting allows you to access \\nexternal servers or machines outside of the Docker \", \"host (that is, outside the default Linux VM, \\n\\n119 \\n\\nCHAPTER 5 | Designing and Developing Multi-Cont\", \"ainer and Microservice-Based .NET Applications \\n\\n \\n \\n\\fwhich is a development Docker host), such as a\", \" local SQL Server instance on your \\ndevelopment PC. \\n\\nThere are also other, more advanced docker-com\", \"pose.yml settings that we\\u2019ll discuss in the following \\nsections. \\n\\nUsing docker-compose files to tar\", \"get multiple environments \\n\\nThe docker-compose.*.yml files are definition files and can be used by m\", \"ultiple infrastructures that \\nunderstand that format. The most straightforward tool is the docker-co\", \"mpose command. \\n\\nTherefore, by using the docker-compose command you can target the following main sc\", \"enarios. \\n\\nDevelopment environments \\n\\nWhen you develop applications, it is important to be able to r\", \"un an application in an isolated \\ndevelopment environment. You can use the docker-compose CLI comman\", \"d to create that \\nenvironment or Visual Studio, which uses docker-compose under the covers. \\n\\nThe do\", \"cker-compose.yml file allows you to configure and document all your application\\u2019s service \\ndependenc\", \"ies (other services, cache, databases, queues, etc.). Using the docker-compose CLI \\ncommand, you can\", \" create and start one or more containers for each dependency with a single \\ncommand (docker-compose \", \"up). \\n\\nThe docker-compose.yml files are configuration files interpreted by Docker engine but also se\", \"rve as \\nconvenient documentation files about the composition of your multi-container application. \\n\\n\", \"Testing environments \\n\\nAn important part of any continuous deployment (CD) or continuous integration\", \" (CI) process are the \\nunit tests and integration tests. These automated tests require an isolated e\", \"nvironment so they are \\nnot impacted by the users or any other change in the application\\u2019s data. \\n\\nW\", \"ith Docker Compose, you can create and destroy that isolated environment very easily in a few \\ncomma\", \"nds from your command prompt or scripts, like the following commands: \\n\\ndocker-compose -f docker-com\", \"pose.yml -f docker-compose-test.override.yml up -d \\n./run_unit_tests \\ndocker-compose -f docker-compo\", \"se.yml -f docker-compose-test.override.yml down \\n\\nProduction deployments \\n\\nYou can also use Compose \", \"to deploy to a remote Docker Engine. A typical case is to deploy to a \\nsingle Docker host instance (\", \"like a production VM or server provisioned with Docker Machine). \\n\\nIf you are using any other orches\", \"trator (Azure Service Fabric, Kubernetes, etc.), you might need to add \\nsetup and metadata configura\", \"tion settings like those in docker-compose.yml, but in the format \\nrequired by the other orchestrato\", \"r. \\n\\nIn any case, docker-compose is a convenient tool and metadata format for development, testing a\", \"nd \\nproduction workflows, although the production workflow might vary on the orchestrator you are \\nu\", \"sing. \\n\\n120 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appli\", \"cations \\n\\n \\n \\n\\fUsing multiple docker-compose files to handle several environments \\n\\nWhen targeting d\", \"ifferent environments, you should use multiple compose files. This approach lets you \\ncreate multipl\", \"e configuration variants depending on the environment. \\n\\nOverriding the base docker-compose file \\n\\nY\", \"ou could use a single docker-compose.yml file as in the simplified examples shown in previous \\nsecti\", \"ons. However, that is not recommended for most applications. \\n\\nBy default, Compose reads two files, \", \"a docker-compose.yml and an optional docker-\\ncompose.override.yml file. As shown in Figure 6-11, whe\", \"n you are using Visual Studio and enabling \\nDocker support, Visual Studio also creates an additional\", \" docker-compose.vs.debug.g.yml file for \\ndebugging the application, you can take a look at this file\", \" in folder obj\\\\Docker\\\\ in the main solution \\nfolder. \\n\\nFigure 6-11. docker-compose files in Visual S\", \"tudio 2019 \\n\\ndocker-compose project file structure: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n.dockerignore - used to ignore fil\", \"es \\n\\ndocker-compose.yml - used to compose microservices \\n\\ndocker-compose.override.yml - used to conf\", \"igure microservices environment \\n\\nYou can edit the docker-compose files with any editor, like Visual\", \" Studio Code or Sublime, and run the \\napplication with the docker-compose up command. \\n\\nBy conventio\", \"n, the docker-compose.yml file contains your base configuration and other static \\nsettings. That mea\", \"ns that the service configuration should not change depending on the deployment \\nenvironment you are\", \" targeting. \\n\\nThe docker-compose.override.yml file, as its name suggests, contains configuration set\", \"tings that \\noverride the base configuration, such as configuration that depends on the deployment en\", \"vironment. \\nYou can have multiple override files with different names also. The override files usual\", \"ly contain \\nadditional information needed by the application but specific to an environment or to a \", \"deployment. \\n\\nTargeting multiple environments \\n\\nA typical use case is when you define multiple compo\", \"se files so you can target multiple environments, \\nlike production, staging, CI, or development. To \", \"support these differences, you can split your \\nCompose configuration into multiple files, as shown i\", \"n Figure 6-12. \\n\\n121 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .\", \"NET Applications \\n\\n \\n \\n \\n\\fFigure 6-12. Multiple docker-compose files overriding values in the base d\", \"ocker-compose.yml file \\n\\nYou can combine multiple docker-compose*.yml files to handle different envi\", \"ronments. You start with \\nthe base docker-compose.yml file. This base file contains the base or stat\", \"ic configuration settings that \\ndo not change depending on the environment. For example, the eShopOn\", \"Containers app has the \\nfollowing docker-compose.yml file (simplified with fewer services) as the ba\", \"se file. \\n\\n#docker-compose.yml (Base) \\nversion: '3.4' \\nservices: \\n  basket-api: \\n    image: eshop/ba\", \"sket-api:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfile: src/Services/Basket/Basket.\", \"API/Dockerfile \\n    depends_on: \\n      - basketdata \\n      - identity-api \\n      - rabbitmq \\n\\n  cata\", \"log-api: \\n    image: eshop/catalog-api:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfil\", \"e: src/Services/Catalog/Catalog.API/Dockerfile \\n    depends_on: \\n      - sqldata \\n      - rabbitmq \\n\", \"\\n  marketing-api: \\n    image: eshop/marketing-api:${TAG:-latest} \\n    build: \\n      context: . \\n    \", \"  dockerfile: src/Services/Marketing/Marketing.API/Dockerfile \\n    depends_on: \\n      - sqldata \\n   \", \"   - nosqldata \\n      - identity-api \\n      - rabbitmq \\n\\n  webmvc: \\n    image: eshop/webmvc:${TAG:-l\", \"atest} \\n\\n122 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appl\", \"ications \\n\\n \\n \\n \\n \\n \\n \\n\\f    build: \\n      context: . \\n      dockerfile: src/Web/WebMVC/Dockerfile \\n \", \"   depends_on: \\n      - catalog-api \\n      - ordering-api \\n      - identity-api \\n      - basket-api \", \"\\n      - marketing-api \\n\\n  sqldata: \\n    image: mcr.microsoft.com/mssql/server:2019-latest \\n\\n  nosql\", \"data: \\n    image: mongo \\n\\n  basketdata: \\n    image: redis \\n\\n  rabbitmq: \\n    image: rabbitmq:3-manag\", \"ement \\n\\nThe values in the base docker-compose.yml file should not change because of different target\", \" \\ndeployment environments. \\n\\nIf you focus on the webmvc service definition, for instance, you can se\", \"e how that information is much \\nthe same no matter what environment you might be targeting. You have\", \" the following information: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThe service name: webmvc. \\n\\nThe container\\u2019s custom ima\", \"ge: eshop/webmvc. \\n\\nThe command to build the custom Docker image, indicating which Dockerfile to use\", \". \\n\\nDependencies on other services, so this container does not start until the other dependency \\ncon\", \"tainers have started. \\n\\nYou can have additional configuration, but the important point is that in th\", \"e base docker-\\ncompose.yml file, you just want to set the information that is common across environm\", \"ents. Then in \\nthe docker-compose.override.yml or similar files for production or staging, you shoul\", \"d place \\nconfiguration that is specific for each environment. \\n\\nUsually, the docker-compose.override\", \".yml is used for your development environment, as in the \\nfollowing example from eShopOnContainers: \", \"\\n\\n#docker-compose.override.yml (Extended config for DEVELOPMENT env.) \\nversion: '3.4' \\n\\nservices: \\n#\", \" Simplified number of services here: \\n\\n  basket-api: \\n    environment: \\n      - ASPNETCORE_ENVIRONME\", \"NT=Development \\n      - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - ConnectionString=${ESHOP_AZURE_RE\", \"DIS_BASKET_DB:-basketdata} \\n      - identityUrl=http://identity-api \\n      - IdentityUrlExternal=htt\", \"p://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5105 \\n\\n123 \\n\\nCHAPTER 5 | Designing and Developing Multi-Contain\", \"er and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\f      - EventBusConnection=${ESHOP_AZ\", \"URE_SERVICE_BUS:-rabbitmq} \\n      - EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} \\n      - EventBus\", \"Password=${ESHOP_SERVICE_BUS_PASSWORD} \\n      - AzureServiceBusEnabled=False \\n      - ApplicationIns\", \"ights__InstrumentationKey=${INSTRUMENTATION_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n   \", \"   - UseLoadTest=${USE_LOADTEST:-False} \\n\\n    ports: \\n      - \\\"5103:80\\\" \\n\\n  catalog-api: \\n    enviro\", \"nment: \\n      - ASPNETCORE_ENVIRONMENT=Development \\n      - ASPNETCORE_URLS=http://0.0.0.0:80 \\n     \", \" - ConnectionString=${ESHOP_AZURE_CATALOG_DB:-\\nServer=sqldata;Database=Microsoft.eShopOnContainers.S\", \"ervices.CatalogDb;User \\nId=sa;Password=[PLACEHOLDER]} \\n      - PicBaseUrl=${ESHOP_AZURE_STORAGE_CATA\", \"LOG_URL:-\\nhttp://host.docker.internal:5202/api/v1/catalog/items/[0]/pic/} \\n      - EventBusConnectio\", \"n=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq} \\n      - EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} \\n    \", \"  - EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD} \\n      - AzureStorageAccountName=${ESHOP_AZURE_ST\", \"ORAGE_CATALOG_NAME} \\n      - AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_CATALOG_KEY} \\n      - UseC\", \"ustomizationData=True \\n      - AzureServiceBusEnabled=False \\n      - AzureStorageEnabled=False \\n    \", \"  - ApplicationInsights__InstrumentationKey=${INSTRUMENTATION_KEY} \\n      - OrchestratorType=${ORCHE\", \"STRATOR_TYPE} \\n    ports: \\n      - \\\"5101:80\\\" \\n\\n  marketing-api: \\n    environment: \\n      - ASPNETCOR\", \"E_ENVIRONMENT=Development \\n      - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - ConnectionString=${ESH\", \"OP_AZURE_MARKETING_DB:-\\nServer=sqldata;Database=Microsoft.eShopOnContainers.Services.MarketingDb;Use\", \"r \\nId=sa;Password=[PLACEHOLDER]} \\n      - MongoConnectionString=${ESHOP_AZURE_COSMOSDB:-mongodb://no\", \"sqldata} \\n      - MongoDatabase=MarketingDb \\n      - EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-r\", \"abbitmq} \\n      - EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} \\n      - EventBusPassword=${ESHOP_S\", \"ERVICE_BUS_PASSWORD} \\n      - identityUrl=http://identity-api \\n      - IdentityUrlExternal=http://${\", \"ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5105 \\n      - CampaignDetailFunctionUri=${ESHOP_AZUREFUNC_CAMPAIGN_DE\", \"TAILS_URI} \\n      - PicBaseUrl=${ESHOP_AZURE_STORAGE_MARKETING_URL:-\\nhttp://host.docker.internal:511\", \"0/api/v1/campaigns/[0]/pic/} \\n      - AzureStorageAccountName=${ESHOP_AZURE_STORAGE_MARKETING_NAME} \", \"\\n      - AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_MARKETING_KEY} \\n      - AzureServiceBusEnabled\", \"=False \\n      - AzureStorageEnabled=False \\n      - ApplicationInsights__InstrumentationKey=${INSTRUM\", \"ENTATION_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n      - UseLoadTest=${USE_LOADTEST:-Fa\", \"lse} \\n    ports: \\n      - \\\"5110:80\\\" \\n\\n  webmvc: \\n\\n124 \\n\\nCHAPTER 5 | Designing and Developing Multi-C\", \"ontainer and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n\\f    environment: \\n      - ASPNETCOR\", \"E_ENVIRONMENT=Development \\n      - ASPNETCORE_URLS=http://0.0.0.0:80 \\n      - PurchaseUrl=http://web\", \"shoppingapigw \\n      - IdentityUrl=http://10.0.75.1:5105 \\n      - MarketingUrl=http://webmarketingap\", \"igw \\n      - CatalogUrlHC=http://catalog-api/hc \\n      - OrderingUrlHC=http://ordering-api/hc \\n     \", \" - IdentityUrlHC=http://identity-api/hc \\n      - BasketUrlHC=http://basket-api/hc \\n      - Marketing\", \"UrlHC=http://marketing-api/hc \\n      - PaymentUrlHC=http://payment-api/hc \\n      - SignalrHubUrl=htt\", \"p://${ESHOP_EXTERNAL_DNS_NAME_OR_IP}:5202 \\n      - UseCustomizationData=True \\n      - ApplicationIns\", \"ights__InstrumentationKey=${INSTRUMENTATION_KEY} \\n      - OrchestratorType=${ORCHESTRATOR_TYPE} \\n   \", \"   - UseLoadTest=${USE_LOADTEST:-False} \\n    ports: \\n      - \\\"5100:80\\\" \\n  sqldata: \\n    environment:\", \" \\n      - SA_PASSWORD=[PLACEHOLDER] \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5433:1433\\\" \\n  nosql\", \"data: \\n    ports: \\n      - \\\"27017:27017\\\" \\n  basketdata: \\n    ports: \\n      - \\\"6379:6379\\\" \\n  rabbitmq\", \": \\n    ports: \\n      - \\\"15672:15672\\\" \\n      - \\\"5672:5672\\\" \\n\\nIn this example, the development overrid\", \"e configuration exposes some ports to the host, defines \\nenvironment variables with redirect URLs, a\", \"nd specifies connection strings for the development \\nenvironment. These settings are all just for th\", \"e development environment. \\n\\nWhen you run docker-compose up (or launch it from Visual Studio), the c\", \"ommand reads the overrides \\nautomatically as if it were merging both files. \\n\\nSuppose that you want \", \"another Compose file for the production environment, with different \\nconfiguration values, ports, or\", \" connection strings. You can create another override file, like file named \\ndocker-compose.prod.yml \", \"with different settings and environment variables. That file might be stored \\nin a different Git rep\", \"o or managed and secured by a different team. \\n\\nHow to deploy with a specific override file \\n\\nTo use\", \" multiple override files, or an override file with a different name, you can use the -f option with \", \"\\nthe docker-compose command and specify the files. Compose merges files in the order they are \\nspeci\", \"fied on the command line. The following example shows how to deploy with override files. \\n\\ndocker-co\", \"mpose -f docker-compose.yml -f docker-compose.prod.yml up -d \\n\\n125 \\n\\nCHAPTER 5 | Designing and Devel\", \"oping Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fUsing environment variables in\", \" docker-compose files \\n\\nIt is convenient, especially in production environments, to be able to get c\", \"onfiguration information \\nfrom environment variables, as we have shown in previous examples. You can\", \" reference an \\nenvironment variable in your docker-compose files using the syntax ${MY_VAR}. The fol\", \"lowing line \\nfrom a docker-compose.prod.yml file shows how to reference the value of an environment \", \"variable. \\n\\nIdentityUrl=http://${ESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP}:5105 \\n\\nEnvironment variables ar\", \"e created and initialized in different ways, depending on your host \\nenvironment (Linux, Windows, Cl\", \"oud cluster, etc.). However, a convenient approach is to use an .env \\nfile. The docker-compose files\", \" support declaring default environment variables in the .env file. These \\nvalues for the environment\", \" variables are the default values. But they can be overridden by the values \\nyou might have defined \", \"in each of your environments (host OS or environment variables from your \\ncluster). You place this .\", \"env file in the folder where the docker-compose command is executed from. \\n\\nThe following example sh\", \"ows an .env file like the .env file for the eShopOnContainers application. \\n\\n# .env file \\n\\nESHOP_EXT\", \"ERNAL_DNS_NAME_OR_IP=host.docker.internal \\n\\nESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP=10.121.122.92 \\n\\nDocke\", \"r-compose expects each line in an .env file to be in the format <variable>=<value>. \\n\\nThe values set\", \" in the run-time environment always override the values defined inside the .env file. In a \\nsimilar \", \"way, values passed via command-line arguments also override the default values set in the .env \\nfile\", \". \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nOverview of Docker Compose \\nhttps://docs.docker.com/compose/overview/\", \" \\n\\n\\u2022  Multiple Compose files \\n\\nhttps://docs.docker.com/compose/multiple-compose-files/ \\n\\nBuilding op\", \"timized ASP.NET Core Docker images \\n\\nIf you are exploring Docker and .NET on sources on the Internet\", \", you will find Dockerfiles that \\ndemonstrate the simplicity of building a Docker image by copying y\", \"our source into a container. These \\nexamples suggest that by using a simple configuration, you can h\", \"ave a Docker image with the \\nenvironment packaged with your application. The following example shows\", \" a simple Dockerfile in this \\nvein. \\n\\nFROM mcr.microsoft.com/dotnet/sdk:7.0 \\nWORKDIR /app \\nENV ASPNE\", \"TCORE_URLS http://+:80 \\nEXPOSE 80 \\nCOPY . . \\nRUN dotnet restore \\nENTRYPOINT [\\\"dotnet\\\", \\\"run\\\"] \\n\\n126 \", \"\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n\", \" \\n \\n \\n\\fA Dockerfile like this will work. However, you can substantially optimize your images, especi\", \"ally your \\nproduction images. \\n\\nIn the container and microservices model, you are constantly startin\", \"g containers. The typical way of \\nusing containers does not restart a sleeping container, because th\", \"e container is disposable. \\nOrchestrators (like Kubernetes and Azure Service Fabric) create new inst\", \"ances of images. What this \\nmeans is that you would need to optimize by precompiling the application\", \" when it is built so the \\ninstantiation process will be faster. When the container is started, it sh\", \"ould be ready to run. Don\\u2019t \\nrestore and compile at run time using the dotnet restore and dotnet bui\", \"ld CLI commands as you may \\nsee in blog posts about .NET and Docker. \\n\\nThe .NET team has been doing \", \"important work to make .NET and ASP.NET Core a container-optimized \\nframework. Not only is .NET a li\", \"ghtweight framework with a small memory footprint; the team has \\nfocused on optimized Docker images \", \"for three main scenarios and published them in the Docker Hub \\nregistry at dotnet/, beginning with v\", \"ersion 2.1: \\n\\n1.  Development: The priority is the ability to quickly iterate and debug changes, and\", \" where size \\n\\nis secondary. \\n\\n2. \\n\\n3. \\n\\nBuild: The priority is compiling the application, and the im\", \"age includes binaries and other \\ndependencies to optimize binaries. \\n\\nProduction: The focus is fast \", \"deploying and starting of containers, so these images are \\nlimited to the binaries and content neede\", \"d to run the application. \\n\\nThe .NET team provides four basic variants in dotnet/ (at Docker Hub): \\n\", \"\\n1. \\n\\n2. \\n\\n3. \\n\\n4. \\n\\nsdk: for development and build scenarios \\n\\naspnet: for ASP.NET production scena\", \"rios \\n\\nruntime: for .NET production scenarios \\n\\nruntime-deps: for production scenarios of self-conta\", \"ined applications \\n\\nFor faster startup, runtime images also automatically set aspnetcore_urls to por\", \"t 80 and use Ngen to \\ncreate a native image cache of assemblies. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nBu\", \"ilding Optimized Docker Images with ASP.NET Core \\nhttps://learn.microsoft.com/archive/blogs/stevelas\", \"ker/building-optimized-docker-images-\\nwith-asp-net-core \\n\\nBuilding Docker Images for .NET Applicatio\", \"ns \\nhttps://learn.microsoft.com/dotnet/core/docker/building-net-docker-images \\n\\nUse a database serve\", \"r running as a container \\n\\nYou can have your databases (SQL Server, PostgreSQL, MySQL, etc.) on regu\", \"lar standalone servers, in \\non-premises clusters, or in PaaS services in the cloud like Azure SQL DB\", \". However, for development \\nand test environments, having your databases running as containers is co\", \"nvenient, because you don\\u2019t \\n\\n127 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microse\", \"rvice-Based .NET Applications \\n\\n \\n \\n\\fhave any external dependency and simply running the docker-comp\", \"ose up command starts the whole \\napplication. Having those databases as containers is also great for\", \" integration tests, because the \\ndatabase is started in the container and is always populated with t\", \"he same sample data, so tests can \\nbe more predictable. \\n\\nSQL Server running as a container with a m\", \"icroservice-related \\ndatabase \\n\\nIn eShopOnContainers, there\\u2019s a container named sqldata, as defined \", \"in the docker-compose.yml file, \\nthat runs a SQL Server for Linux instance with the SQL databases fo\", \"r all microservices that need one. \\n\\nA key point in microservices is that each microservice owns its\", \" related data, so it should have its own \\ndatabase. However, the databases can be anywhere. In this \", \"case, they are all in the same container to \\nkeep Docker memory requirements as low as possible. Kee\", \"p in mind that this is a good-enough \\nsolution for development and, perhaps, testing but not for pro\", \"duction. \\n\\nThe SQL Server container in the sample application is configured with the following YAML \", \"code in the \\ndocker-compose.yml file, which is executed when you run docker-compose up. Note that th\", \"e YAML \\ncode has consolidated configuration information from the generic docker-compose.yml file and\", \" the \\ndocker-compose.override.yml file. (Usually you would separate the environment settings from th\", \"e \\nbase or static information related to the SQL Server image.) \\n\\n  sqldata: \\n    image: mcr.microso\", \"ft.com/mssql/server:2017-latest \\n    environment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEPT_EUL\", \"A=Y \\n    ports: \\n      - \\\"5434:1433\\\" \\n\\nIn a similar way, instead of using docker-compose, the follow\", \"ing docker run command can run that \\ncontainer: \\n\\ndocker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=Pass\", \"@word' -p 5433:1433 -d \\nmcr.microsoft.com/mssql/server:2017-latest \\n\\nHowever, if you are deploying a\", \" multi-container application like eShopOnContainers, it is more \\nconvenient to use the docker-compos\", \"e up command so that it deploys all the required containers for \\nthe application. \\n\\nWhen you start t\", \"his SQL Server container for the first time, the container initializes SQL Server with the \\npassword\", \" that you provide. Once SQL Server is running as a container, you can update the database \\nby connec\", \"ting through any regular SQL connection, such as from SQL Server Management Studio, \\nVisual Studio, \", \"or C# code. \\n\\nThe eShopOnContainers application initializes each microservice database with sample d\", \"ata by \\nseeding it with data on startup, as explained in the following section. \\n\\nHaving SQL Server \", \"running as a container is not just useful for a demo where you might not have \\naccess to an instance\", \" of SQL Server. As noted, it is also great for development and testing \\n\\n128 \\n\\nCHAPTER 5 | Designing\", \" and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fenvironments so that\", \" you can easily run integration tests starting from a clean SQL Server image and \\nknown data by seed\", \"ing new sample data. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nRun the SQL Server Docker image on Linux, Mac,\", \" or Windows \\nhttps://learn.microsoft.com/sql/linux/sql-server-linux-setup-docker \\n\\nConnect and query\", \" SQL Server on Linux with sqlcmd \\nhttps://learn.microsoft.com/sql/linux/sql-server-linux-connect-and\", \"-query-sqlcmd \\n\\nSeeding with test data on Web application startup \\n\\nTo add data to the database when\", \" the application starts up, you can add code like the following to \\nthe Main method in the Program c\", \"lass of the Web API project: \\n\\npublic static int Main(string[] args) \\n{ \\n    var configuration = Get\", \"Configuration(); \\n\\n    Log.Logger = CreateSerilogLogger(configuration); \\n\\n    try \\n    { \\n        Lo\", \"g.Information(\\\"Configuring web host ({ApplicationContext})...\\\", AppName); \\n        var host = Create\", \"HostBuilder(configuration, args); \\n\\n        Log.Information(\\\"Applying migrations ({ApplicationContex\", \"t})...\\\", AppName); \\n        host.MigrateDbContext<CatalogContext>((context, services) => \\n        { \", \"\\n            var env = services.GetService<IWebHostEnvironment>(); \\n            var settings = servi\", \"ces.GetService<IOptions<CatalogSettings>>(); \\n            var logger = services.GetService<ILogger<C\", \"atalogContextSeed>>(); \\n\\n            new CatalogContextSeed() \\n                .SeedAsync(context, e\", \"nv, settings, logger) \\n                .Wait(); \\n        }) \\n        .MigrateDbContext<IntegrationEv\", \"entLogContext>((_, __) => { }); \\n\\n        Log.Information(\\\"Starting web host ({ApplicationContext}).\", \"..\\\", AppName); \\n        host.Run(); \\n\\n        return 0; \\n    } \\n    catch (Exception ex) \\n    { \\n   \", \"     Log.Fatal(ex, \\\"Program terminated unexpectedly ({ApplicationContext})!\\\", AppName); \\n        ret\", \"urn 1; \\n    } \\n    finally \\n    { \\n        Log.CloseAndFlush(); \\n    } \\n} \\n\\n129 \\n\\nCHAPTER 5 | Design\", \"ing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\fThere\", \"\\u2019s an important caveat when applying migrations and seeding a database during container \\nstartup. Si\", \"nce the database server might not be available for whatever reason, you must handle retries \\nwhile w\", \"aiting for the server to be available. This retry logic is handled by the MigrateDbContext() \\nextens\", \"ion method, as shown in the following code: \\n\\npublic static IWebHost MigrateDbContext<TContext>( \\n  \", \"  this IWebHost host, \\n    Action<TContext, \\n    IServiceProvider> seeder) \\n      where TContext : D\", \"bContext \\n{ \\n    var underK8s = host.IsInKubernetes(); \\n\\n    using (var scope = host.Services.Create\", \"Scope()) \\n    { \\n        var services = scope.ServiceProvider; \\n\\n        var logger = services.GetRe\", \"quiredService<ILogger<TContext>>(); \\n\\n        var context = services.GetService<TContext>(); \\n\\n     \", \"   try \\n        { \\n            logger.LogInformation(\\\"Migrating database associated with context \\n{D\", \"bContextName}\\\", typeof(TContext).Name); \\n\\n            if (underK8s) \\n            { \\n                \", \"InvokeSeeder(seeder, context, services); \\n            } \\n            else \\n            { \\n          \", \"      var retry = Policy.Handle<SqlException>() \\n                    .WaitAndRetry(new TimeSpan[] \\n \", \"                   { \\n                    TimeSpan.FromSeconds(3), \\n                    TimeSpan.Fro\", \"mSeconds(5), \\n                    TimeSpan.FromSeconds(8), \\n                    }); \\n\\n              \", \"  //if the sql server container is not created on run docker compose this \\n                //migrati\", \"on can't fail for network related exception. The retry options for \\nDbContext only \\n                \", \"//apply to transient exceptions \\n                // Note that this is NOT applied when running some \", \"orchestrators (let the \\norchestrator to recreate the failing service) \\n                retry.Execute\", \"(() => InvokeSeeder(seeder, context, services)); \\n            } \\n\\n            logger.LogInformation(\", \"\\\"Migrated database associated with context \\n{DbContextName}\\\", typeof(TContext).Name); \\n        } \\n  \", \"      catch (Exception ex) \\n        { \\n            logger.LogError(ex, \\\"An error occurred while migr\", \"ating the database used on \\ncontext {DbContextName}\\\", typeof(TContext).Name); \\n            if (under\", \"K8s) \\n            { \\n                throw;          // Rethrow under k8s because we rely on k8s to \", \"re-run the \\n\\n130 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET \", \"Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fpod \\n            } \\n        } \\n    } \\n\\n    return host; \\n} \\n\\nThe f\", \"ollowing code in the custom CatalogContextSeed class populates the data. \\n\\npublic class CatalogConte\", \"xtSeed \\n{ \\n    public static async Task SeedAsync(IApplicationBuilder applicationBuilder) \\n    { \\n  \", \"      var context = (CatalogContext)applicationBuilder \\n            .ApplicationServices.GetService(\", \"typeof(CatalogContext)); \\n        using (context) \\n        { \\n            context.Database.Migrate()\", \"; \\n            if (!context.CatalogBrands.Any()) \\n            { \\n                context.CatalogBran\", \"ds.AddRange( \\n                    GetPreconfiguredCatalogBrands()); \\n                await context.S\", \"aveChangesAsync(); \\n            } \\n            if (!context.CatalogTypes.Any()) \\n            { \\n    \", \"            context.CatalogTypes.AddRange( \\n                    GetPreconfiguredCatalogTypes()); \\n  \", \"              await context.SaveChangesAsync(); \\n            } \\n        } \\n    } \\n\\n    static IEnume\", \"rable<CatalogBrand> GetPreconfiguredCatalogBrands() \\n    { \\n        return new List<CatalogBrand>() \", \"\\n       { \\n           new CatalogBrand() { Brand = \\\"Azure\\\"}, \\n           new CatalogBrand() { Brand \", \"= \\\".NET\\\" }, \\n           new CatalogBrand() { Brand = \\\"Visual Studio\\\" }, \\n           new CatalogBrand\", \"() { Brand = \\\"SQL Server\\\" } \\n       }; \\n    } \\n\\n    static IEnumerable<CatalogType> GetPreconfigured\", \"CatalogTypes() \\n    { \\n        return new List<CatalogType>() \\n        { \\n            new CatalogTyp\", \"e() { Type = \\\"Mug\\\"}, \\n            new CatalogType() { Type = \\\"T-Shirt\\\" }, \\n            new CatalogTy\", \"pe() { Type = \\\"Backpack\\\" }, \\n            new CatalogType() { Type = \\\"USB Memory Stick\\\" } \\n        };\", \" \\n    } \\n} \\n\\nWhen you run integration tests, having a way to generate data consistent with your inte\", \"gration tests is \\nuseful. Being able to create everything from scratch, including an instance of SQL\", \" Server running on a \\ncontainer, is great for test environments. \\n\\n131 \\n\\nCHAPTER 5 | Designing and D\", \"eveloping Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\fEF Core InMemory dat\", \"abase versus SQL Server running as a container \\n\\nAnother good choice when running tests is to use th\", \"e Entity Framework InMemory database provider. \\nYou can specify that configuration in the ConfigureS\", \"ervices method of the Startup class in your Web \\nAPI project: \\n\\npublic class Startup \\n{ \\n    // Othe\", \"r Startup code ... \\n    public void ConfigureServices(IServiceCollection services) \\n    { \\n        s\", \"ervices.AddSingleton<IConfiguration>(Configuration); \\n        // DbContext using an InMemory databas\", \"e provider \\n        services.AddDbContext<CatalogContext>(opt => opt.UseInMemoryDatabase()); \\n      \", \"  //(Alternative: DbContext using a SQL Server provider \\n        //services.AddDbContext<CatalogCont\", \"ext>(c => \\n        //{ \\n            // c.UseSqlServer(Configuration[\\\"ConnectionString\\\"]); \\n         \", \"   // \\n        //}); \\n    } \\n\\n    // Other Startup code ... \\n} \\n\\nThere is an important catch, though\", \". The in-memory database does not support many constraints that \\nare specific to a particular databa\", \"se. For instance, you might add a unique index on a column in your \\nEF Core model and write a test a\", \"gainst your in-memory database to check that it does not let you add \\na duplicate value. But when yo\", \"u are using the in-memory database, you cannot handle unique indexes \\non a column. Therefore, the in\", \"-memory database does not behave exactly the same as a real SQL \\nServer database\\u2014it does not emulate\", \" database-specific constraints. \\n\\nEven so, an in-memory database is still useful for testing and pro\", \"totyping. But if you want to create \\naccurate integration tests that take into account the behavior \", \"of a specific database implementation, \\nyou need to use a real database like SQL Server. For that pu\", \"rpose, running SQL Server in a container is \\na great choice and more accurate than the EF Core InMem\", \"ory database provider. \\n\\nUsing a Redis cache service running in a container \\n\\nYou can run Redis on a\", \" container, especially for development and testing and for proof-of-concept \\nscenarios. This scenari\", \"o is convenient, because you can have all your dependencies running on \\ncontainers\\u2014not just for your\", \" local development machines, but for your testing environments in your \\nCI/CD pipelines. \\n\\nHowever, \", \"when you run Redis in production, it is better to look for a high-availability solution like \\nRedis \", \"Microsoft Azure, which runs as a PaaS (Platform as a Service). In your code, you just need to \\nchang\", \"e your connection strings. \\n\\nRedis provides a Docker image with Redis. That image is available from \", \"Docker Hub at this URL: \\n\\nhttps://hub.docker.com/_/redis/ \\n\\n132 \\n\\nCHAPTER 5 | Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fYou can directly run a Docker R\", \"edis container by executing the following Docker CLI command in your \\ncommand prompt: \\n\\ndocker run -\", \"-name some-redis -d redis \\n\\nThe Redis image includes expose:6379 (the port used by Redis), so standa\", \"rd container linking will \\nmake it automatically available to the linked containers. \\n\\nIn eShopOnCon\", \"tainers, the basket-api microservice uses a Redis cache running as a container. That \\nbasketdata con\", \"tainer is defined as part of the multi-container docker-compose.yml file, as shown in the \\nfollowing\", \" example: \\n\\n#docker-compose.yml file \\n#... \\n  basketdata: \\n    image: redis \\n    expose: \\n      - \\\"6\", \"379\\\" \\n\\nThis code in the docker-compose.yml defines a container named basketdata based on the redis i\", \"mage \\nand publishing the port 6379 internally. This configuration means that it will only be accessi\", \"ble from \\nother containers running within the Docker host. \\n\\nFinally, in the docker-compose.override\", \".yml file, the basket-api microservice for the \\neShopOnContainers sample defines the connection stri\", \"ng to use for that Redis container: \\n\\n  basket-api: \\n    environment: \\n      # Other data ... \\n     \", \" - ConnectionString=basketdata \\n      - EventBusConnection=rabbitmq \\n\\nAs mentioned before, the name \", \"of the microservice basketdata is resolved by Docker\\u2019s internal \\nnetwork DNS. \\n\\nImplementing event-b\", \"ased communication between \\nmicroservices (integration events) \\n\\nAs described earlier, when you use \", \"event-based communication, a microservice publishes an event \\nwhen something notable happens, such a\", \"s when it updates a business entity. Other microservices \\nsubscribe to those events. When a microser\", \"vice receives an event, it can update its own business \\nentities, which might lead to more events be\", \"ing published. This is the essence of the eventual \\nconsistency concept. This publish/subscribe syst\", \"em is usually performed by using an implementation \\nof an event bus. The event bus can be designed a\", \"s an interface with the API needed to subscribe and \\nunsubscribe to events and to publish events. It\", \" can also have one or more implementations based on \\nany inter-process or messaging communication, s\", \"uch as a messaging queue or a service bus that \\nsupports asynchronous communication and a publish/su\", \"bscribe model. \\n\\nYou can use events to implement business transactions that span multiple services, \", \"which give you \\neventual consistency between those services. An eventually consistent transaction co\", \"nsists of a series \\n\\n133 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications \\n\\n \\n \\n\\fof distributed actions. At each action, the microservice updates a busin\", \"ess entity and publishes an \\nevent that triggers the next action. Figure 6-18 below, shows a PriceUp\", \"dated event published through \\nan event bus, so the price update is propagated to the Basket and oth\", \"er microservices. \\n\\nFigure 6-18. Event-driven communication based on an event bus \\n\\nThis section des\", \"cribes how you can implement this type of communication with .NET by using a \\ngeneric event bus inte\", \"rface, as shown in Figure 6-18. There are multiple potential implementations, \\neach using a differen\", \"t technology or infrastructure such as RabbitMQ, Azure Service Bus, or any other \\nthird-party open-s\", \"ource or commercial service bus. \\n\\nUsing message brokers and service buses for production systems \\n\\n\", \"As noted in the architecture section, you can choose from multiple messaging technologies for \\nimple\", \"menting your abstract event bus. But these technologies are at different levels. For instance, \\nRabb\", \"itMQ, a messaging broker transport, is at a lower level than commercial products like Azure \\nService\", \" Bus, NServiceBus, MassTransit, or Brighter. Most of these products can work on top of either \\nRabbi\", \"tMQ or Azure Service Bus. Your choice of product depends on how many features and how \\nmuch out-of-t\", \"he-box scalability you need for your application. \\n\\nFor implementing just an event bus proof-of-conc\", \"ept for your development environment, as in the \\neShopOnContainers sample, a simple implementation o\", \"n top of RabbitMQ running as a container \\nmight be enough. But for mission-critical and production s\", \"ystems that need high scalability, you \\nmight want to evaluate and use Azure Service Bus. \\n\\nIf you r\", \"equire high-level abstractions and richer features like Sagas for long-running processes that \\nmake \", \"distributed development easier, other commercial and open-source service buses like \\nNServiceBus, Ma\", \"ssTransit, and Brighter are worth evaluating. In this case, the abstractions and API to \\nuse would u\", \"sually be directly the ones provided by those high-level service buses instead of your own \\nabstract\", \"ions (like the simple event bus abstractions provided at eShopOnContainers). For that matter, \\n\\n134 \", \"\\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n\", \" \\n \\n\\fyou can research the forked eShopOnContainers using NServiceBus (additional derived sample \\nimp\", \"lemented by Particular Software). \\n\\nOf course, you could always build your own service bus features \", \"on top of lower-level technologies \\nlike RabbitMQ and Docker, but the work needed to \\u201creinvent the w\", \"heel\\u201d might be too costly for a \\ncustom enterprise application. \\n\\nTo reiterate: the sample event bus\", \" abstractions and implementation showcased in the \\neShopOnContainers sample are intended to be used \", \"only as a proof of concept. Once you have \\ndecided that you want to have asynchronous and event-driv\", \"en communication, as explained in the \\ncurrent section, you should choose the service bus product th\", \"at best fits your needs for production. \\n\\nIntegration events \\n\\nIntegration events are used for bring\", \"ing domain state in sync across multiple microservices or external \\nsystems. This functionality is d\", \"one by publishing integration events outside the microservice. When an \\nevent is published to multip\", \"le receiver microservices (to as many microservices as are subscribed to \\nthe integration event), th\", \"e appropriate event handler in each receiver microservice handles the event. \\n\\nAn integration event \", \"is basically a data-holding class, as in the following example: \\n\\npublic class ProductPriceChangedIn\", \"tegrationEvent : IntegrationEvent \\n{ \\n    public int ProductId { get; private set; } \\n    public dec\", \"imal NewPrice { get; private set; } \\n    public decimal OldPrice { get; private set; } \\n\\n    public \", \"ProductPriceChangedIntegrationEvent(int productId, decimal newPrice, \\n        decimal oldPrice) \\n   \", \" { \\n        ProductId = productId; \\n        NewPrice = newPrice; \\n        OldPrice = oldPrice; \\n    \", \"} \\n} \\n\\nThe integration events can be defined at the application level of each microservice, so they \", \"are \\ndecoupled from other microservices, in a way comparable to how ViewModels are defined in the \\ns\", \"erver and client. What is not recommended is sharing a common integration events library across \\nmul\", \"tiple microservices; doing that would be coupling those microservices with a single event \\ndefinitio\", \"n data library. You do not want to do that for the same reasons that you do not want to share \\na com\", \"mon domain model across multiple microservices: microservices must be completely \\nautonomous. For mo\", \"re information, see this blog post on the amount of data to put in events. Be \\ncareful not to take t\", \"his too far, as this other blog post describes the problem data deficient messages \\ncan produce. You\", \"r design of your events should aim to be \\u201cjust right\\u201d for the needs of their \\nconsumers. \\n\\nThere are\", \" only a few kinds of libraries you should share across microservices. One is libraries that are \\nfin\", \"al application blocks, like the Event Bus client API, as in eShopOnContainers. Another is libraries \", \"\\nthat constitute tools that could also be shared as NuGet components, like JSON serializers. \\n\\n135 \\n\", \"\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \", \"\\n \\n\\fThe event bus \\n\\nAn event bus allows publish/subscribe-style communication between microservices \", \"without requiring \\nthe components to explicitly be aware of each other, as shown in Figure 6-19. \\n\\nF\", \"igure 6-19. Publish/subscribe basics with an event bus \\n\\nThe above diagram shows that microservice A\", \" publishes to Event Bus, which distributes to subscribing \\nmicroservices B and C, without the publis\", \"her needing to know the subscribers. The event bus is \\nrelated to the Observer pattern and the publi\", \"sh-subscribe pattern. \\n\\nObserver pattern \\n\\nIn the Observer pattern, your primary object (known as th\", \"e Observable) notifies other interested \\nobjects (known as Observers) with relevant information (eve\", \"nts). \\n\\nPublish/Subscribe (Pub/Sub) pattern \\n\\nThe purpose of the Publish/Subscribe pattern is the sa\", \"me as the Observer pattern: you want to notify \\nother services when certain events take place. But t\", \"here is an important difference between the \\nObserver and Pub/Sub patterns. In the observer pattern,\", \" the broadcast is performed directly from the \\nobservable to the observers, so they \\u201cknow\\u201d each othe\", \"r. But when using a Pub/Sub pattern, there is a \\nthird component, called broker, or message broker o\", \"r event bus, which is known by both the \\npublisher and subscriber. Therefore, when using the Pub/Sub\", \" pattern the publisher and the \\nsubscribers are precisely decoupled thanks to the mentioned event bu\", \"s or message broker. \\n\\nThe middleman or event bus \\n\\nHow do you achieve anonymity between publisher a\", \"nd subscriber? An easy way is let a middleman \\ntake care of all the communication. An event bus is o\", \"ne such middleman. \\n\\nAn event bus is typically composed of two parts: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThe abstraction or i\", \"nterface. \\n\\nOne or more implementations. \\n\\n136 \\n\\nCHAPTER 5 | Designing and Developing Multi-Containe\", \"r and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fIn Figure 6-19 you can see how, from an applicat\", \"ion point of view, the event bus is nothing more than \\na Pub/Sub channel. The way you implement this\", \" asynchronous communication can vary. It can have \\nmultiple implementations so that you can swap bet\", \"ween them, depending on the environment \\nrequirements (for example, production versus development en\", \"vironments). \\n\\nIn Figure 6-20, you can see an abstraction of an event bus with multiple implementati\", \"ons based on \\ninfrastructure messaging technologies like RabbitMQ, Azure Service Bus, or another eve\", \"nt/message \\nbroker. \\n\\nFigure 6- 20. Multiple implementations of an event bus \\n\\nIt\\u2019s good to have the\", \" event bus defined through an interface so it can be implemented with several \\ntechnologies, like Ra\", \"bbitMQ, Azure Service bus or others. However, and as mentioned previously, \\nusing your own abstracti\", \"ons (the event bus interface) is good only if you need basic event bus \\nfeatures supported by your a\", \"bstractions. If you need richer service bus features, you should probably \\nuse the API and abstracti\", \"ons provided by your preferred commercial service bus instead of your own \\nabstractions. \\n\\nDefining \", \"an event bus interface \\n\\nLet\\u2019s start with some implementation code for the event bus interface and p\", \"ossible implementations \\nfor exploration purposes. The interface should be generic and straightforwa\", \"rd, as in the following \\ninterface. \\n\\npublic interface IEventBus \\n{ \\n    void Publish(IntegrationEve\", \"nt @event); \\n\\n    void Subscribe<T, TH>() \\n        where T : IntegrationEvent \\n        where TH : II\", \"ntegrationEventHandler<T>; \\n\\n    void SubscribeDynamic<TH>(string eventName) \\n        where TH : IDy\", \"namicIntegrationEventHandler; \\n\\n137 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n\\f    void UnsubscribeDynamic<TH>(string eventName) \\n  \", \"      where TH : IDynamicIntegrationEventHandler; \\n\\n    void Unsubscribe<T, TH>() \\n        where TH \", \": IIntegrationEventHandler<T> \\n        where T : IntegrationEvent; \\n} \\n\\nThe Publish method is straig\", \"htforward. The event bus will broadcast the integration event passed to it \\nto any microservice, or \", \"even an external application, subscribed to that event. This method is used by \\nthe microservice tha\", \"t is publishing the event. \\n\\nThe Subscribe methods (you can have several implementations depending o\", \"n the arguments) are \\nused by the microservices that want to receive events. This method has two arg\", \"uments. The first is the \\nintegration event to subscribe to (IntegrationEvent). The second argument \", \"is the integration event \\nhandler (or callback method), named IIntegrationEventHandler<T>, to be exe\", \"cuted when the receiver \\nmicroservice gets that integration event message. \\n\\nAdditional resources \\n\\n\", \"Some production-ready messaging solutions: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAzure Service Bus \\nhttps://learn.microsoft.com/\", \"azure/service-bus-messaging/ \\n\\nNServiceBus \\nhttps://particular.net/nservicebus \\n\\n\\u2022  MassTransit \\n\\nht\", \"tps://masstransit-project.com/ \\n\\nImplementing an event bus with RabbitMQ for the \\ndevelopment or tes\", \"t environment \\n\\nWe should start by saying that if you create your custom event bus based on RabbitMQ\", \" running in a \\ncontainer, as the eShopOnContainers application does, it should be used only for your\", \" development \\nand test environments. Don\\u2019t use it for your production environment, unless you are bu\", \"ilding it as a \\npart of a production-ready service bus as described in the Additional resources sect\", \"ion below. A \\nsimple custom event bus might be missing many production-ready critical features that \", \"a commercial \\nservice bus has. \\n\\nOne of the event bus custom implementations in eShopOnContainers is\", \" basically a library using the \\nRabbitMQ API. (There\\u2019s another implementation based on Azure Service\", \" Bus.) \\n\\nThe event bus implementation with RabbitMQ lets microservices subscribe to events, publish \", \"events, \\nand receive events, as shown in Figure 6-21. \\n\\n138 \\n\\nCHAPTER 5 | Designing and Developing M\", \"ulti-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fFigure 6-21. RabbitMQ implementatio\", \"n of an event bus \\n\\nRabbitMQ functions as an intermediary between message publisher and subscribers,\", \" to handle \\ndistribution. In the code, the EventBusRabbitMQ class implements the generic IEventBus i\", \"nterface. \\nThis implementation is based on Dependency Injection so that you can swap from this dev/t\", \"est \\nversion to a production version. \\n\\npublic class EventBusRabbitMQ : IEventBus, IDisposable \\n{ \\n \", \"   // Implementation using RabbitMQ API \\n    //... \\n} \\n\\nThe RabbitMQ implementation of a sample dev/\", \"test event bus is boilerplate code. It has to handle the \\nconnection to the RabbitMQ server and prov\", \"ide code for publishing a message event to the queues. It \\nalso has to implement a dictionary of col\", \"lections of integration event handlers for each event type; \\nthese event types can have a different \", \"instantiation and different subscriptions for each receiver \\nmicroservice, as shown in Figure 6-21. \", \"\\n\\nImplementing a simple publish method with RabbitMQ \\n\\nThe following code is a simplified version of\", \" an event bus implementation for RabbitMQ, to \\nshowcase the whole scenario. You don\\u2019t really handle \", \"the connection this way. To see the full \\nimplementation, see the actual code in the dotnet-architec\", \"ture/eShopOnContainers repository. \\n\\npublic class EventBusRabbitMQ : IEventBus, IDisposable \\n{ \\n    \", \"// Member objects and other methods ... \\n    // ... \\n\\n    public void Publish(IntegrationEvent @even\", \"t) \\n    { \\n        var eventName = @event.GetType().Name; \\n        var factory = new ConnectionFacto\", \"ry() { HostName = _connectionString }; \\n        using (var connection = factory.CreateConnection()) \", \"\\n        using (var channel = connection.CreateModel()) \\n\\n139 \\n\\nCHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n\\f        { \\n            channel.\", \"ExchangeDeclare(exchange: _brokerName, \\n                type: \\\"direct\\\"); \\n            string message\", \" = JsonConvert.SerializeObject(@event); \\n            var body = Encoding.UTF8.GetBytes(message); \\n  \", \"          channel.BasicPublish(exchange: _brokerName, \\n                routingKey: eventName, \\n     \", \"           basicProperties: null, \\n                body: body); \\n       } \\n    } \\n} \\n\\nThe actual cod\", \"e of the Publish method in the eShopOnContainers application is improved by using a \\nPolly retry pol\", \"icy, which retries the task some times in case the RabbitMQ container is not ready. This \\nscenario c\", \"an occur when docker-compose is starting the containers; for example, the RabbitMQ \\ncontainer might \", \"start more slowly than the other containers. \\n\\nAs mentioned earlier, there are many possible configu\", \"rations in RabbitMQ, so this code should be \\nused only for dev/test environments. \\n\\nImplementing the\", \" subscription code with the RabbitMQ API \\n\\nAs with the publish code, the following code is a simplif\", \"ication of part of the event bus \\nimplementation for RabbitMQ. Again, you usually do not need to cha\", \"nge it unless you are improving \\nit. \\n\\npublic class EventBusRabbitMQ : IEventBus, IDisposable \\n{ \\n  \", \"  // Member objects and other methods ... \\n    // ... \\n\\n    public void Subscribe<T, TH>() \\n        \", \"where T : IntegrationEvent \\n        where TH : IIntegrationEventHandler<T> \\n    { \\n        var event\", \"Name = _subsManager.GetEventKey<T>(); \\n\\n        var containsKey = _subsManager.HasSubscriptionsForEv\", \"ent(eventName); \\n        if (!containsKey) \\n        { \\n            if (!_persistentConnection.IsConn\", \"ected) \\n            { \\n                _persistentConnection.TryConnect(); \\n            } \\n\\n        \", \"    using (var channel = _persistentConnection.CreateModel()) \\n            { \\n                channe\", \"l.QueueBind(queue: _queueName, \\n                                    exchange: BROKER_NAME, \\n        \", \"                            routingKey: eventName); \\n            } \\n        } \\n\\n        _subsManager\", \".AddSubscription<T, TH>(); \\n    } \\n} \\n\\n140 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container an\", \"d Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n\\fEach event type has a related channel to get e\", \"vents from RabbitMQ. You can then have as many event \\nhandlers per channel and event type as needed.\", \" \\n\\nThe Subscribe method accepts an IIntegrationEventHandler object, which is like a callback method \", \"in \\nthe current microservice, plus its related IntegrationEvent object. The code then adds that even\", \"t \\nhandler to the list of event handlers that each integration event type can have per client micros\", \"ervice. \\nIf the client code has not already been subscribed to the event, the code creates a channel\", \" for the \\nevent type so it can receive events in a push style from RabbitMQ when that event is publi\", \"shed from \\nany other service. \\n\\nAs mentioned above, the event bus implemented in eShopOnContainers h\", \"as only an educational \\npurpose, since it only handles the main scenarios, so it\\u2019s not ready for pro\", \"duction. \\n\\nFor production scenarios check the additional resources below, specific for RabbitMQ, and\", \" the \\nImplementing event-based communication between microservices section. \\n\\nAdditional resources \\n\", \"\\nA production-ready solution with support for RabbitMQ. \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nNServiceBus - Fully-supported comm\", \"ercial service bus with advanced management and \\nmonitoring tooling for .NET \\nhttps://particular.net\", \"/ \\n\\nEasyNetQ - Open Source .NET API client for RabbitMQ \\nhttps://easynetq.com/ \\n\\n\\u2022  MassTransit - Fr\", \"ee, open-source distributed application framework for .NET \\n\\nhttps://masstransit-project.com/ \\n\\n\\u2022 \\n\\n\", \"Rebus - Open source .NET Service Bus \\nhttps://github.com/rebus-org/Rebus \\n\\nSubscribing to events \\n\\nT\", \"he first step for using the event bus is to subscribe the microservices to the events they want to \\n\", \"receive. That functionality should be done in the receiver microservices. \\n\\nThe following simple cod\", \"e shows what each receiver microservice needs to implement when starting \\nthe service (that is, in t\", \"he Startup class) so it subscribes to the events it needs. In this case, the basket-\\napi microservic\", \"e needs to subscribe to ProductPriceChangedIntegrationEvent and the \\nOrderStartedIntegrationEvent me\", \"ssages. \\n\\nFor instance, when subscribing to the ProductPriceChangedIntegrationEvent event, that make\", \"s the \\nbasket microservice aware of any changes to the product price and lets it warn the user about\", \" the \\nchange if that product is in the user\\u2019s basket. \\n\\nvar eventBus = app.ApplicationServices.GetRe\", \"quiredService<IEventBus>(); \\n\\neventBus.Subscribe<ProductPriceChangedIntegrationEvent, \\n\\n141 \\n\\nCHAPTE\", \"R 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\f   \", \"                ProductPriceChangedIntegrationEventHandler>(); \\n\\neventBus.Subscribe<OrderStartedInte\", \"grationEvent, \\n                   OrderStartedIntegrationEventHandler>(); \\n\\nAfter this code runs, th\", \"e subscriber microservice will be listening through RabbitMQ channels. When \\nany message of type Pro\", \"ductPriceChangedIntegrationEvent arrives, the code invokes the event \\nhandler that is passed to it a\", \"nd processes the event. \\n\\nPublishing events through the event bus \\n\\nFinally, the message sender (ori\", \"gin microservice) publishes the integration events with code similar to \\nthe following example. (Thi\", \"s approach is a simplified example that does not take atomicity into \\naccount.) You would implement \", \"similar code whenever an event must be propagated across multiple \\nmicroservices, usually right afte\", \"r committing data or transactions from the origin microservice. \\n\\nFirst, the event bus implementatio\", \"n object (based on RabbitMQ or based on a service bus) would be \\ninjected at the controller construc\", \"tor, as in the following code: \\n\\n[Route(\\\"api/v1/[controller]\\\")] \\npublic class CatalogController : Co\", \"ntrollerBase \\n{ \\n    private readonly CatalogContext _context; \\n    private readonly IOptionsSnapsho\", \"t<Settings> _settings; \\n    private readonly IEventBus _eventBus; \\n\\n    public CatalogController(Cat\", \"alogContext context, \\n        IOptionsSnapshot<Settings> settings, \\n        IEventBus eventBus) \\n   \", \" { \\n        _context = context; \\n        _settings = settings; \\n        _eventBus = eventBus; \\n    }\", \" \\n    // ... \\n} \\n\\nThen you use it from your controller\\u2019s methods, like in the UpdateProduct method: \", \"\\n\\n[Route(\\\"items\\\")] \\n[HttpPost] \\npublic async Task<IActionResult> UpdateProduct([FromBody]CatalogItem\", \" product) \\n{ \\n    var item = await _context.CatalogItems.SingleOrDefaultAsync( \\n        i => i.Id ==\", \" product.Id); \\n    // ... \\n    if (item.Price != product.Price) \\n    { \\n        var oldPrice = item.\", \"Price; \\n        item.Price = product.Price; \\n        _context.CatalogItems.Update(item); \\n        va\", \"r @event = new ProductPriceChangedIntegrationEvent(item.Id, \\n            item.Price, \\n            ol\", \"dPrice); \\n        // Commit changes in original transaction \\n        await _context.SaveChangesAsync\", \"(); \\n        // Publish integration event to the event bus \\n        // (RabbitMQ or a service bus un\", \"derneath) \\n\\n142 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET A\", \"pplications \\n\\n \\n \\n \\n \\n\\f        _eventBus.Publish(@event); \\n        // ... \\n    } \\n    // ... \\n} \\n\\nIn\", \" this case, since the origin microservice is a simple CRUD microservice, that code is placed right i\", \"nto \\na Web API controller. \\n\\nIn more advanced microservices, like when using CQRS approaches, it can\", \" be implemented in the \\nCommandHandler class, within the Handle() method. \\n\\nDesigning atomicity and \", \"resiliency when publishing to the event bus \\n\\nWhen you publish integration events through a distribu\", \"ted messaging system like your event bus, you \\nhave the problem of atomically updating the original \", \"database and publishing an event (that is, either \\nboth operations complete or none of them). For in\", \"stance, in the simplified example shown earlier, the \\ncode commits data to the database when the pro\", \"duct price is changed and then publishes a \\nProductPriceChangedIntegrationEvent message. Initially, \", \"it might look essential that these two \\noperations be performed atomically. However, if you are usin\", \"g a distributed transaction involving the \\ndatabase and the message broker, as you do in older syste\", \"ms like Microsoft Message Queuing \\n(MSMQ), this approach is not recommended for the reasons describe\", \"d by the CAP theorem. \\n\\nBasically, you use microservices to build scalable and highly available syst\", \"ems. Simplifying somewhat, \\nthe CAP theorem says that you cannot build a (distributed) database (or \", \"a microservice that owns its \\nmodel) that\\u2019s continually available, strongly consistent, and tolerant\", \" to any partition. You must choose \\ntwo of these three properties. \\n\\nIn microservices-based architec\", \"tures, you should choose availability and tolerance, and you should \\nde-emphasize strong consistency\", \". Therefore, in most modern microservice-based applications, you \\nusually do not want to use distrib\", \"uted transactions in messaging, as you do when you implement \\ndistributed transactions based on the \", \"Windows Distributed Transaction Coordinator (DTC) with \\nMSMQ. \\n\\nLet\\u2019s go back to the initial issue a\", \"nd its example. If the service crashes after the database is updated \\n(in this case, right after the\", \" line of code with _context.SaveChangesAsync()), but before the integration \\nevent is published, the\", \" overall system could become inconsistent. This approach might be business \\ncritical, depending on t\", \"he specific business operation you are dealing with. \\n\\nAs mentioned earlier in the architecture sect\", \"ion, you can have several approaches for dealing with this \\nissue: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUsing the full Even\", \"t Sourcing pattern. \\n\\nUsing transaction log mining. \\n\\nUsing the Outbox pattern. This is a transactio\", \"nal table to store the integration events \\n(extending the local transaction). \\n\\nFor this scenario, u\", \"sing the full Event Sourcing (ES) pattern is one of the best approaches, if not the \\nbest. However, \", \"in many application scenarios, you might not be able to implement a full ES system. ES \\nmeans storin\", \"g only domain events in your transactional database, instead of storing current state \\n\\n143 \\n\\nCHAPTE\", \"R 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fdata.\", \" Storing only domain events can have great benefits, such as having the history of your system \\navai\", \"lable and being able to determine the state of your system at any moment in the past. However, \\nimpl\", \"ementing a full ES system requires you to rearchitect most of your system and introduces many \\nother\", \" complexities and requirements. For example, you would want to use a database specifically \\nmade for\", \" event sourcing, such as Event Store, or a document-oriented database such as Azure \\nCosmos DB, Mong\", \"oDB, Cassandra, CouchDB, or RavenDB. ES is a great approach for this problem, but \\nnot the easiest s\", \"olution unless you are already familiar with event sourcing. \\n\\nThe option to use transaction log min\", \"ing initially looks transparent. However, to use this approach, \\nthe microservice has to be coupled \", \"to your RDBMS transaction log, such as the SQL Server transaction \\nlog. This approach is probably no\", \"t desirable. Another drawback is that the low-level updates recorded \\nin the transaction log might n\", \"ot be at the same level as your high-level integration events. If so, the \\nprocess of reverse-engine\", \"ering those transaction log operations can be difficult. \\n\\nA balanced approach is a mix of a transac\", \"tional database table and a simplified ES pattern. You can \\nuse a state such as \\u201cready to publish th\", \"e event,\\u201d which you set in the original event when you commit \\nit to the integration events table. Y\", \"ou then try to publish the event to the event bus. If the publish-\\nevent action succeeds, you start \", \"another transaction in the origin service and move the state from \\n\\u201cready to publish the event\\u201d to \\u201c\", \"event already published.\\u201d \\n\\nIf the publish-event action in the event bus fails, the data still will \", \"not be inconsistent within the origin \\nmicroservice\\u2014it is still marked as \\u201cready to publish the even\", \"t,\\u201d and with respect to the rest of the \\nservices, it will eventually be consistent. You can always \", \"have background jobs checking the state of \\nthe transactions or integration events. If the job finds\", \" an event in the \\u201cready to publish the event\\u201d \\nstate, it can try to republish that event to the even\", \"t bus. \\n\\nNotice that with this approach, you are persisting only the integration events for each ori\", \"gin \\nmicroservice, and only the events that you want to communicate to other microservices or extern\", \"al \\nsystems. In contrast, in a full ES system, you store all domain events as well. \\n\\nTherefore, thi\", \"s balanced approach is a simplified ES system. You need a list of integration events with \\ntheir cur\", \"rent state (\\u201cready to publish\\u201d versus \\u201cpublished\\u201d). But you only need to implement these \\nstates for\", \" the integration events. And in this approach, you do not need to store all your domain data \\nas eve\", \"nts in the transactional database, as you would in a full ES system. \\n\\nIf you are already using a re\", \"lational database, you can use a transactional table to store integration \\nevents. To achieve atomic\", \"ity in your application, you use a two-step process based on local \\ntransactions. Basically, you hav\", \"e an IntegrationEvent table in the same database where you have your \\ndomain entities. That table wo\", \"rks as an insurance for achieving atomicity so that you include persisted \\nintegration events into t\", \"he same transactions that are committing your domain data. \\n\\nStep by step, the process goes like thi\", \"s: \\n\\n1. \\n\\n2. \\n\\nThe application begins a local database transaction. \\n\\nIt then updates the state of y\", \"our domain entities and inserts an event into the integration \\nevent table. \\n\\n3. \\n\\nFinally, it commi\", \"ts the transaction, so you get the desired atomicity and then \\n\\n144 \\n\\nCHAPTER 5 | Designing and Deve\", \"loping Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\f4. \\n\\nYou publish the event so\", \"mehow (next). \\n\\nWhen implementing the steps of publishing the events, you have these choices: \\n\\n\\u2022 \\n\\n\", \"\\u2022 \\n\\nPublish the integration event right after committing the transaction and use another local \\ntran\", \"saction to mark the events in the table as being published. Then, use the table just as an \\nartifact\", \" to track the integration events in case of issues in the remote microservices, and \\nperform compens\", \"atory actions based on the stored integration events. \\n\\nUse the table as a kind of queue. A separate\", \" application thread or process queries the \\nintegration event table, publishes the events to the eve\", \"nt bus, and then uses a local \\ntransaction to mark the events as published. \\n\\nFigure 6-22 shows the \", \"architecture for the first of these approaches. \\n\\nFigure 6-22. Atomicity when publishing events to t\", \"he event bus \\n\\nThe approach illustrated in Figure 6-22 is missing an additional worker microservice \", \"that is in charge \\nof checking and confirming the success of the published integration events. In ca\", \"se of failure, that \\nadditional checker worker microservice can read events from the table and repub\", \"lish them, that is, \\nrepeat step number 2. \\n\\nAbout the second approach: you use the EventLog table a\", \"s a queue and always use a worker \\nmicroservice to publish the messages. In that case, the process i\", \"s like that shown in Figure 6-23. This \\nshows an additional microservice, and the table is the singl\", \"e source when publishing events. \\n\\n145 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Mi\", \"croservice-Based .NET Applications \\n\\n \\n \\n \\n\\fFigure 6-23. Atomicity when publishing events to the eve\", \"nt bus with a worker microservice \\n\\nFor simplicity, the eShopOnContainers sample uses the first appr\", \"oach (with no additional processes or \\nchecker microservices) plus the event bus. However, the eShop\", \"OnContainers sample is not handling \\nall possible failure cases. In a real application deployed to t\", \"he cloud, you must embrace the fact that \\nissues will arise eventually, and you must implement that \", \"check and resend logic. Using the table as a \\nqueue can be more effective than the first approach if\", \" you have that table as a single source of events \\nwhen publishing them (with the worker) through th\", \"e event bus. \\n\\nImplementing atomicity when publishing integration events through the event \\nbus \\n\\nTh\", \"e following code shows how you can create a single transaction involving multiple DbContext \\nobjects\", \"\\u2014one context related to the original data being updated, and the second context related to \\nthe Inte\", \"grationEventLog table. \\n\\nThe transaction in the example code below will not be resilient if connecti\", \"ons to the database have \\nany issue at the time when the code is running. This can happen in cloud-b\", \"ased systems like Azure \\nSQL DB, which might move databases across servers. For implementing resilie\", \"nt transactions across \\nmultiple contexts, see the Implementing resilient Entity Framework Core SQL \", \"connections section later \\nin this guide. \\n\\nFor clarity, the following example shows the whole proce\", \"ss in a single piece of code. However, the \\neShopOnContainers implementation is refactored and split\", \"s this logic into multiple classes so it\\u2019s \\neasier to maintain. \\n\\n// Update Product from the Catalog\", \" microservice \\n// \\npublic async Task<IActionResult> UpdateProduct([FromBody]CatalogItem productToUpd\", \"ate) \\n{ \\n  var catalogItem = \\n       await _catalogContext.CatalogItems.SingleOrDefaultAsync(i => i.\", \"Id == \\n                                                               productToUpdate.Id); \\n\\n146 \\n\\nC\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \", \"\\n\\f  if (catalogItem == null) return NotFound(); \\n\\n  bool raiseProductPriceChangedEvent = false; \\n  I\", \"ntegrationEvent priceChangedEvent = null; \\n\\n  if (catalogItem.Price != productToUpdate.Price) \\n     \", \"     raiseProductPriceChangedEvent = true; \\n\\n  if (raiseProductPriceChangedEvent) // Create event if\", \" price has changed \\n  { \\n      var oldPrice = catalogItem.Price; \\n      priceChangedEvent = new Prod\", \"uctPriceChangedIntegrationEvent(catalogItem.Id, \\n                                                   \", \"               productToUpdate.Price, \\n                                                             \", \"     oldPrice); \\n  } \\n  // Update current product \\n  catalogItem = productToUpdate; \\n\\n  // Just save\", \" the updated product if the Product's Price hasn't changed. \\n  if (!raiseProductPriceChangedEvent) \\n\", \"  { \\n      await _catalogContext.SaveChangesAsync(); \\n  } \\n  else  // Publish to event bus only if p\", \"roduct price changed \\n  { \\n        // Achieving atomicity between original DB and the IntegrationEve\", \"ntLog \\n        // with a local transaction \\n        using (var transaction = _catalogContext.Databas\", \"e.BeginTransaction()) \\n        { \\n           _catalogContext.CatalogItems.Update(catalogItem); \\n    \", \"       await _catalogContext.SaveChangesAsync(); \\n\\n           await _integrationEventLogService.Save\", \"EventAsync(priceChangedEvent); \\n\\n           transaction.Commit(); \\n        } \\n\\n      // Publish the \", \"integration event through the event bus \\n      _eventBus.Publish(priceChangedEvent); \\n\\n      _integr\", \"ationEventLogService.MarkEventAsPublishedAsync( \\n                                                pri\", \"ceChangedEvent); \\n  } \\n\\n  return Ok(); \\n} \\n\\nAfter the ProductPriceChangedIntegrationEvent integratio\", \"n event is created, the transaction that \\nstores the original domain operation (update the catalog i\", \"tem) also includes the persistence of the \\nevent in the EventLog table. This makes it a single trans\", \"action, and you will always be able to check \\nwhether event messages were sent. \\n\\nThe event log tabl\", \"e is updated atomically with the original database operation, using a local \\ntransaction against the\", \" same database. If any of the operations fail, an exception is thrown and the \\ntransaction rolls bac\", \"k any completed operation, thus maintaining consistency between the domain \\noperations and the event\", \" messages saved to the table. \\n\\n147 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Micro\", \"service-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fReceiving messages from subscriptions: even\", \"t handlers in receiver microservices \\n\\nIn addition to the event subscription logic, you need to impl\", \"ement the internal code for the \\nintegration event handlers (like a callback method). The event hand\", \"ler is where you specify where the \\nevent messages of a certain type will be received and processed.\", \" \\n\\nAn event handler first receives an event instance from the event bus. Then it locates the compone\", \"nt to \\nbe processed related to that integration event, propagating and persisting the event as a cha\", \"nge in \\nstate in the receiver microservice. For example, if a ProductPriceChanged event originates i\", \"n the \\ncatalog microservice, it is handled in the basket microservice and changes the state in this \", \"receiver \\nbasket microservice as well, as shown in the following code. \\n\\nnamespace Microsoft.eShopOn\", \"Containers.Services.Basket.API.IntegrationEvents.EventHandling \\n{ \\n    public class ProductPriceChan\", \"gedIntegrationEventHandler : \\n        IIntegrationEventHandler<ProductPriceChangedIntegrationEvent> \", \"\\n    { \\n        private readonly IBasketRepository _repository; \\n\\n        public ProductPriceChanged\", \"IntegrationEventHandler( \\n            IBasketRepository repository) \\n        { \\n            _reposit\", \"ory = repository; \\n        } \\n\\n        public async Task Handle(ProductPriceChangedIntegrationEvent \", \"@event) \\n        { \\n            var userIds = await _repository.GetUsers(); \\n            foreach (va\", \"r id in userIds) \\n            { \\n                var basket = await _repository.GetBasket(id); \\n    \", \"            await UpdatePriceInBasketItems(@event.ProductId, @event.NewPrice, basket); \\n            \", \"} \\n        } \\n\\n        private async Task UpdatePriceInBasketItems(int productId, decimal newPrice, \", \"\\n            CustomerBasket basket) \\n        { \\n            var itemsToUpdate = basket?.Items?.Where\", \"(x => int.Parse(x.ProductId) == \\n                productId).ToList(); \\n            if (itemsToUpdate\", \" != null) \\n            { \\n                foreach (var item in itemsToUpdate) \\n                { \\n  \", \"                  if(item.UnitPrice != newPrice) \\n                    { \\n                        var\", \" originalPrice = item.UnitPrice; \\n                        item.UnitPrice = newPrice; \\n              \", \"          item.OldUnitPrice = originalPrice; \\n                    } \\n                } \\n            \", \"    await _repository.UpdateBasket(basket); \\n            } \\n        } \\n    } \\n} \\n\\n148 \\n\\nCHAPTER 5 | \", \"Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\fThe e\", \"vent handler needs to verify whether the product exists in any of the basket instances. It also \\nupd\", \"ates the item price for each related basket line item. Finally, it creates an alert to be displayed \", \"to \\nthe user about the price change, as shown in Figure 6-24. \\n\\nFigure 6-24. Displaying an item pric\", \"e change in a basket, as communicated by integration events \\n\\nIdempotency in update message events \\n\", \"\\nAn important aspect of update message events is that a failure at any point in the communication \\ns\", \"hould cause the message to be retried. Otherwise a background task might try to publish an event \\nth\", \"at has already been published, creating a race condition. Make sure that the updates are either \\nide\", \"mpotent or that they provide enough information to ensure that you can detect a duplicate, \\ndiscard \", \"it, and send back only one response. \\n\\nAs noted earlier, idempotency means that an operation can be \", \"performed multiple times without \\nchanging the result. In a messaging environment, as when communica\", \"ting events, an event is \\nidempotent if it can be delivered multiple times without changing the resu\", \"lt for the receiver \\nmicroservice. This may be necessary because of the nature of the event itself, \", \"or because of the way \\nthe system handles the event. Message idempotency is important in any applica\", \"tion that uses \\nmessaging, not just in applications that implement the event bus pattern. \\n\\nAn examp\", \"le of an idempotent operation is a SQL statement that inserts data into a table only if that \\ndata i\", \"s not already in the table. It does not matter how many times you run that insert SQL statement; \\nth\", \"e result will be the same\\u2014the table will contain that data. Idempotency like this can also be \\nneces\", \"sary when dealing with messages if the messages could potentially be sent and therefore \\n\\n149 \\n\\nCHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fp\", \"rocessed more than once. For instance, if retry logic causes a sender to send exactly the same \\nmess\", \"age more than once, you need to make sure that it is idempotent. \\n\\nIt is possible to design idempote\", \"nt messages. For example, you can create an event that says \\u201cset the \\nproduct price to $25\\u201d instead \", \"of \\u201cadd $5 to the product price.\\u201d You could safely process the first \\nmessage any number of times an\", \"d the result will be the same. That is not true for the second \\nmessage. But even in the first case,\", \" you might not want to process the first event, because the system \\ncould also have sent a newer pri\", \"ce-change event and you would be overwriting the new price. \\n\\nAnother example might be an order-comp\", \"leted event that\\u2019s propagated to multiple subscribers. The \\napp has to make sure that order informat\", \"ion is updated in other systems only once, even if there are \\nduplicated message events for the same\", \" order-completed event. \\n\\nIt is convenient to have some kind of identity per event so that you can c\", \"reate logic that enforces that \\neach event is processed only once per receiver. \\n\\nSome message proce\", \"ssing is inherently idempotent. For example, if a system generates image \\nthumbnails, it might not m\", \"atter how many times the message about the generated thumbnail is \\nprocessed; the outcome is that th\", \"e thumbnails are generated and they are the same every time. On \\nthe other hand, operations such as \", \"calling a payment gateway to charge a credit card may not be \\nidempotent at all. In these cases, you\", \" need to ensure that processing a message multiple times has \\nthe effect that you expect. \\n\\nAddition\", \"al resources \\n\\n\\u2022 \\n\\nHonoring message idempotency \\nhttps://learn.microsoft.com/previous-versions/msp-n\", \"-p/jj591565(v=pandp.10)#honoring-\\nmessage-idempotency \\n\\nDeduplicating integration event messages \\n\\nY\", \"ou can make sure that message events are sent and processed only once per subscriber at different \\nl\", \"evels. One way is to use a deduplication feature offered by the messaging infrastructure you are \\nus\", \"ing. Another is to implement custom logic in your destination microservice. Having validations at \\nb\", \"oth the transport level and the application level is your best bet. \\n\\nDeduplicating message events a\", \"t the EventHandler level \\n\\nOne way to make sure that an event is processed only once by any receiver\", \" is by implementing certain \\nlogic when processing the message events in event handlers. For example\", \", that is the approach used \\nin the eShopOnContainers application, as you can see in the source code\", \" of the \\nUserCheckoutAcceptedIntegrationEventHandler class when it receives a \\nUserCheckoutAcceptedI\", \"ntegrationEvent integration event. (In this case, the CreateOrderCommand is \\nwrapped with an Identif\", \"iedCommand, using the eventMsg.RequestId as an identifier, before sending it \\nto the command handler\", \"). \\n\\n150 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applicat\", \"ions \\n\\n \\n \\n\\fDeduplicating messages when using RabbitMQ \\n\\nWhen intermittent network failures happen, \", \"messages can be duplicated, and the message receiver \\nmust be ready to handle these duplicated messa\", \"ges. If possible, receivers should handle messages in \\nan idempotent way, which is better than expli\", \"citly handling them with deduplication. \\n\\nAccording to the RabbitMQ documentation, \\u201cIf a message is \", \"delivered to a consumer and then \\nrequeued (because it was not acknowledged before the consumer conn\", \"ection dropped, for example) \\nthen RabbitMQ will set the redelivered flag on it when it is delivered\", \" again (whether to the same \\nconsumer or a different one). \\n\\nIf the \\u201credelivered\\u201d flag is set, the r\", \"eceiver must take that into account, because the message might \\nalready have been processed. But tha\", \"t is not guaranteed; the message might never have reached the \\nreceiver after it left the message br\", \"oker, perhaps because of network issues. On the other hand, if the \\n\\u201credelivered\\u201d flag is not set, i\", \"t is guaranteed that the message has not been sent more than once. \\nTherefore, the receiver needs to\", \" deduplicate messages or process messages in an idempotent way \\nonly if the \\u201credelivered\\u201d flag is se\", \"t in the message. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nForked eShopOnCon\", \"tainers using NServiceBus (Particular Software) \\nhttps://go.particular.net/eShopOnContainers \\n\\nEvent\", \" Driven Messaging \\nhttps://patterns.arcitura.com/soa-patterns/design_patterns/event_driven_messaging\", \" \\n\\nJimmy Bogard. Refactoring Towards Resilience: Evaluating Coupling \\nhttps://jimmybogard.com/refact\", \"oring-towards-resilience-evaluating-coupling/ \\n\\nPublish-Subscribe channel \\nhttps://www.enterpriseint\", \"egrationpatterns.com/patterns/messaging/PublishSubscribeChannel.\\nhtml \\n\\nCommunicating Between Bounde\", \"d Contexts \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/jj591572(v=pandp.10) \\n\\nEventual Co\", \"nsistency \\nhttps://en.wikipedia.org/wiki/Eventual_consistency \\n\\nPhilip Brown. Strategies for Integra\", \"ting Bounded Contexts \\nhttps://www.culttt.com/2014/11/26/strategies-integrating-bounded-contexts/ \\n\\n\", \"Chris Richardson. Developing Transactional Microservices Using Aggregates, Event \\nSourcing and CQRS \", \"- Part 2 \\nhttps://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-2-richardson \\n\\nCh\", \"ris Richardson. Event Sourcing pattern \\nhttps://microservices.io/patterns/data/event-sourcing.html \\n\", \"\\nIntroducing Event Sourcing \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/jj591559(v=pandp.\", \"10) \\n\\n151 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applica\", \"tions \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEvent Store database. Official site. \\nhttps://geteventstore.com/ \\n\\nPatrick \", \"Nommensen. Event-Driven Data Management for Microservices \\nhttps://dzone.com/articles/event-driven-d\", \"ata-management-for-microservices-1 \\n\\nThe CAP Theorem \\nhttps://en.wikipedia.org/wiki/CAP_theorem \\n\\n\\u2022 \", \" What is CAP Theorem? \\n\\nhttps://www.quora.com/What-Is-CAP-Theorem-1 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nData C\", \"onsistency Primer \\nhttps://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v=pandp.10) \\n\\nRick\", \" Saling. The CAP Theorem: Why \\u201cEverything is Different\\u201d with the Cloud and \\nInternet \\nhttps://learn.\", \"microsoft.com/archive/blogs/rickatmicrosoft/the-cap-theorem-why-everything-\\nis-different-with-the-cl\", \"oud-and-internet/ \\n\\nEric Brewer. CAP Twelve Years Later: How the \\u201cRules\\u201d Have Changed \\nhttps://www.i\", \"nfoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed \\n\\nCAP, PACELC, and Microservices\", \" \\nhttps://ardalis.com/cap-pacelc-and-microservices/ \\n\\nAzure Service Bus. Brokered Messaging: Duplica\", \"te Detection \\nhttps://github.com/microsoftarchive/msdn-code-gallery-\\nmicrosoft/tree/master/Windows%2\", \"0Azure%20Product%20Team/Brokered%20Messaging%20\\nDuplicate%20Detection \\n\\nReliability Guide (RabbitMQ \", \"documentation) \\nhttps://www.rabbitmq.com/reliability.html#consumer \\n\\nTesting ASP.NET Core services a\", \"nd web apps \\n\\nControllers are a central part of any ASP.NET Core API service and ASP.NET MVC Web app\", \"lication. As \\nsuch, you should have confidence they behave as intended for your application. Automat\", \"ed tests can \\nprovide you with this confidence and can detect errors before they reach production. \\n\", \"\\nYou need to test how the controller behaves based on valid or invalid inputs, and test controller \\n\", \"responses based on the result of the business operation it performs. However, you should have these \", \"\\ntypes of tests for your microservices: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUnit tests. These tests ensure that individual com\", \"ponents of the application work as expected. \\nAssertions test the component API. \\n\\nIntegration tests\", \". These tests ensure that component interactions work as expected against \\nexternal artifacts like d\", \"atabases. Assertions can test component API, UI, or the side effects of \\nactions like database I/O, \", \"logging, etc. \\n\\n152 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .N\", \"ET Applications \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\nFunctional tests for each microservice. These tests ensure that the a\", \"pplication works as \\nexpected from the user\\u2019s perspective. \\n\\nService tests. These tests ensure that \", \"end-to-end service use cases, including testing multiple \\nservices at the same time, are tested. For\", \" this type of testing, you need to prepare the \\nenvironment first. In this case, it means starting t\", \"he services (for example, by using docker-\\ncompose up). \\n\\nImplementing unit tests for ASP.NET Core W\", \"eb APIs \\n\\nUnit testing involves testing a part of an application in isolation from its infrastructur\", \"e and \\ndependencies. When you unit test controller logic, only the content of a single action or met\", \"hod is \\ntested, not the behavior of its dependencies or of the framework itself. Unit tests do not d\", \"etect issues \\nin the interaction between components\\u2014that is the purpose of integration testing. \\n\\nAs\", \" you unit test your controller actions, make sure you focus only on their behavior. A controller uni\", \"t \\ntest avoids things like filters, routing, or model binding (the mapping of request data to a View\", \"Model \\nor DTO). Because they focus on testing just one thing, unit tests are generally simple to wri\", \"te and \\nquick to run. A well-written set of unit tests can be run frequently without much overhead. \", \"\\n\\nUnit tests are implemented based on test frameworks like xUnit.net, MSTest, Moq, or NUnit. For the\", \" \\neShopOnContainers sample application, we are using xUnit. \\n\\nWhen you write a unit test for a Web A\", \"PI controller, you instantiate the controller class directly using \\nthe new keyword in C#, so that t\", \"he test will run as fast as possible. The following example shows how \\nto do this when using xUnit a\", \"s the Test framework. \\n\\n[Fact] \\npublic async Task Get_order_detail_success() \\n{ \\n    //Arrange \\n    \", \"var fakeOrderId = \\\"12\\\"; \\n    var fakeOrder = GetFakeOrder(); \\n\\n    //... \\n\\n    //Act \\n    var orderC\", \"ontroller = new OrderController( \\n        _orderServiceMock.Object, \\n        _basketServiceMock.Obje\", \"ct, \\n        _identityParserMock.Object); \\n\\n    orderController.ControllerContext.HttpContext = _con\", \"textMock.Object; \\n    var actionResult = await orderController.Detail(fakeOrderId); \\n\\n    //Assert \\n\", \"    var viewResult = Assert.IsType<ViewResult>(actionResult); \\n    Assert.IsAssignableFrom<Order>(vi\", \"ewResult.ViewData.Model); \\n} \\n\\n153 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Micros\", \"ervice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n\\fImplementing integration and functional tests for each\", \" microservice \\n\\nAs noted, integration tests and functional tests have different purposes and goals. \", \"However, the way \\nyou implement both when testing ASP.NET Core controllers is similar, so in this se\", \"ction we \\nconcentrate on integration tests. \\n\\nIntegration testing ensures that an application\\u2019s comp\", \"onents function correctly when assembled. \\nASP.NET Core supports integration testing using unit test\", \" frameworks and a built-in test web host that \\ncan be used to handle requests without network overhe\", \"ad. \\n\\nUnlike unit testing, integration tests frequently involve application infrastructure concerns,\", \" such as a \\ndatabase, file system, network resources, or web requests and responses. Unit tests use \", \"fakes or mock \\nobjects in place of these concerns. But the purpose of integration tests is to confir\", \"m that the system \\nworks as expected with these systems, so for integration testing you do not use f\", \"akes or mock objects. \\nInstead, you include the infrastructure, like database access or service invo\", \"cation from other services. \\n\\nBecause integration tests exercise larger segments of code than unit t\", \"ests, and because integration \\ntests rely on infrastructure elements, they tend to be orders of magn\", \"itude slower than unit tests. Thus, \\nit is a good idea to limit how many integration tests you write\", \" and run. \\n\\nASP.NET Core includes a built-in test web host that can be used to handle HTTP requests \", \"without \\nnetwork overhead, meaning that you can run those tests faster than when using a real web ho\", \"st. The \\ntest web host (TestServer) is available in a NuGet component as Microsoft.AspNetCore.TestHo\", \"st. It can \\nbe added to integration test projects and used to host ASP.NET Core applications. \\n\\nAs y\", \"ou can see in the following code, when you create integration tests for ASP.NET Core controllers, \\ny\", \"ou instantiate the controllers through the test host. This functionality is comparable to an HTTP \\nr\", \"equest, but it runs faster. \\n\\npublic class PrimeWebDefaultRequestShould \\n{ \\n    private readonly Tes\", \"tServer _server; \\n    private readonly HttpClient _client; \\n\\n    public PrimeWebDefaultRequestShould\", \"() \\n    { \\n        // Arrange \\n        _server = new TestServer(new WebHostBuilder() \\n           .Us\", \"eStartup<Startup>()); \\n        _client = _server.CreateClient(); \\n    } \\n\\n    [Fact] \\n    public asy\", \"nc Task ReturnHelloWorld() \\n    { \\n        // Act \\n        var response = await _client.GetAsync(\\\"/\\\"\", \"); \\n        response.EnsureSuccessStatusCode(); \\n        var responseString = await response.Content\", \".ReadAsStringAsync(); \\n        // Assert \\n        Assert.Equal(\\\"Hello World!\\\", responseString); \\n   \", \" } \\n} \\n\\n154 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appli\", \"cations \\n\\n \\n \\n \\n \\n\\fAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nSteve Smith. Testing controllers (ASP.\", \"NET Core) \\nhttps://learn.microsoft.com/aspnet/core/mvc/controllers/testing \\n\\nSteve Smith. Integratio\", \"n testing (ASP.NET Core) \\nhttps://learn.microsoft.com/aspnet/core/test/integration-tests \\n\\nUnit test\", \"ing in .NET using dotnet test \\nhttps://learn.microsoft.com/dotnet/core/testing/unit-testing-with-dot\", \"net-test \\n\\nxUnit.net. Official site. \\nhttps://xunit.net/ \\n\\nUnit Test Basics. \\nhttps://learn.microsof\", \"t.com/visualstudio/test/unit-test-basics \\n\\n\\u2022  Moq. GitHub repo. \\n\\nhttps://github.com/moq/moq \\n\\n\\u2022 \\n\\nN\", \"Unit. Official site. \\nhttps://nunit.org/ \\n\\nImplementing service tests on a multi-container applicati\", \"on \\n\\nAs noted earlier, when you test multi-container applications, all the microservices need to be \", \"running \\nwithin the Docker host or container cluster. End-to-end service tests that include multiple\", \" operations \\ninvolving several microservices require you to deploy and start the whole application i\", \"n the Docker \\nhost by running docker-compose up (or a comparable mechanism if you are using an orche\", \"strator). \\nOnce the whole application and all its services is running, you can execute end-to-end in\", \"tegration and \\nfunctional tests. \\n\\nThere are a few approaches you can use. In the docker-compose.yml\", \" file that you use to deploy the \\napplication at the solution level you can expand the entry point t\", \"o use dotnet test. You can also use \\nanother compose file that would run your tests in the image you\", \" are targeting. By using another \\ncompose file for integration tests that includes your microservice\", \"s and databases on containers, you \\ncan make sure that the related data is always reset to its origi\", \"nal state before running the tests. \\n\\nOnce the compose application is up and running, you can take a\", \"dvantage of breakpoints and \\nexceptions if you are running Visual Studio. Or you can run the integra\", \"tion tests automatically in your \\nCI pipeline in Azure DevOps Services or any other CI/CD system tha\", \"t supports Docker containers. \\n\\nTesting in eShopOnContainers \\n\\nThe reference application (eShopOnCon\", \"tainers) tests were recently restructured and now there are \\nfour categories: \\n\\n1.  Unit tests, just\", \" plain old regular unit tests, contained in the {MicroserviceName}.UnitTests \\n\\nprojects \\n\\n155 \\n\\nCHAP\", \"TER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\f2. \", \" Microservice functional/integration tests, with test cases involving the infrastructure for \\n\\neach \", \"microservice but isolated from the others and are contained in the \\n{MicroserviceName}.FunctionalTes\", \"ts projects. \\n\\n3.  Application functional/integration tests, which focus on microservices integratio\", \"n, with test \\n\\ncases that exert several microservices. These tests are located in project \\nApplicati\", \"on.FunctionalTests. \\n\\nWhile unit and integration tests are organized in a test folder within the mic\", \"roservice project, \\napplication and load tests are managed separately under the root folder, as show\", \"n in Figure 6-25. \\n\\nFigure 6-25. Test folder structure in eShopOnContainers \\n\\nMicroservice and Appli\", \"cation functional/integration tests are run from Visual Studio, using the regular \\ntests runner, but\", \" first you need to start the required infrastructure services, with a set of docker-\\ncompose files c\", \"ontained in the solution test folder: \\n\\ndocker-compose-test.yml \\n\\nversion: '3.4' \\n\\nservices: \\n  redi\", \"s.data: \\n    image: redis:alpine \\n  rabbitmq: \\n    image: rabbitmq:3-management-alpine \\n  sqldata: \\n\", \"\\n156 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications\", \" \\n\\n \\n \\n \\n \\n\\f    image: mcr.microsoft.com/mssql/server:2017-latest \\n  nosqldata: \\n    image: mongo \\n\\n\", \"docker-compose-test.override.yml \\n\\nversion: '3.4' \\n\\nservices: \\n  redis.data: \\n    ports: \\n      - \\\"6\", \"379:6379\\\" \\n  rabbitmq: \\n    ports: \\n      - \\\"15672:15672\\\" \\n      - \\\"5672:5672\\\" \\n  sqldata: \\n    envi\", \"ronment: \\n      - SA_PASSWORD=Pass@word \\n      - ACCEPT_EULA=Y \\n    ports: \\n      - \\\"5433:1433\\\" \\n  n\", \"osqldata: \\n    ports: \\n      - \\\"27017:27017\\\" \\n\\nSo, to run the functional/integration tests you must \", \"first run this command, from the solution test \\nfolder: \\n\\ndocker-compose -f docker-compose-test.yml \", \"-f docker-compose-test.override.yml up \\n\\nAs you can see, these docker-compose files only start the R\", \"edis, RabbitMQ, SQL Server, and MongoDB \\nmicroservices. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUnit & Inte\", \"gration testing on the eShopOnContainers \\nhttps://github.com/dotnet-architecture/eShopOnContainers/w\", \"iki/Unit-and-integration-\\ntesting \\n\\nLoad testing on the eShopOnContainers \\nhttps://github.com/dotnet\", \"-architecture/eShopOnContainers/wiki/Load-testing \\n\\nImplement background tasks in microservices with\", \" \\nIHostedService and the BackgroundService class \\n\\nBackground tasks and scheduled jobs are something\", \" you might need to use in any application, \\nwhether or not it follows the microservices architecture\", \" pattern. The difference when using a \\nmicroservices architecture is that you can implement the back\", \"ground task in a separate \\nprocess/container for hosting so you can scale it down/up based on your n\", \"eed. \\n\\n157 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applic\", \"ations \\n\\n \\n \\n \\n\\fFrom a generic point of view, in .NET we called these type of tasks Hosted Services,\", \" because they are \\nservices/logic that you host within your host/application/microservice. Note that\", \" in this case, the \\nhosted service simply means a class with the background task logic. \\n\\nSince .NET\", \" Core 2.0, the framework provides a new interface named IHostedService helping you to \\neasily implem\", \"ent hosted services. The basic idea is that you can register multiple background tasks \\n(hosted serv\", \"ices) that run in the background while your web host or host is running, as shown in the \\nimage 6-26\", \". \\n\\nFigure 6-26. Using IHostedService in a WebHost vs. a Host \\n\\nASP.NET Core 1.x and 2.x support IWe\", \"bHost for background processes in web apps. .NET Core 2.1 and \\nlater versions support IHost for back\", \"ground processes with plain console apps. Note the difference \\nmade between WebHost and Host. \\n\\nA We\", \"bHost (base class implementing IWebHost) in ASP.NET Core 2.0 is the infrastructure artifact you \\nuse\", \" to provide HTTP server features to your process, such as when you\\u2019re implementing an MVC web \\napp o\", \"r Web API service. It provides all the new infrastructure goodness in ASP.NET Core, enabling you \\nto\", \" use dependency injection, insert middlewares in the request pipeline, and similar. The WebHost \\nuse\", \"s these very same IHostedServices for background tasks. \\n\\nA Host (base class implementing IHost) was\", \" introduced in .NET Core 2.1. Basically, a Host allows you \\nto have a similar infrastructure than wh\", \"at you have with WebHost (dependency injection, hosted \\nservices, etc.), but in this case, you just \", \"want to have a simple and lighter process as the host, with \\nnothing related to MVC, Web API or HTTP\", \" server features. \\n\\nTherefore, you can choose and either create a specialized host-process with IHos\", \"t to handle the \\nhosted services and nothing else, such a microservice made just for hosting the IHo\", \"stedServices, or \\nyou can alternatively extend an existing ASP.NET Core WebHost, such as an existing\", \" ASP.NET Core \\nWeb API or MVC app. \\n\\n158 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and \", \"Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fEach approach has pros and cons depending on your busi\", \"ness and scalability needs. The bottom line \\nis basically that if your background tasks have nothing\", \" to do with HTTP (IWebHost) you should use \\nIHost. \\n\\nRegistering hosted services in your WebHost or \", \"Host \\n\\nLet\\u2019s drill down further on the IHostedService interface since its usage is pretty similar in\", \" a WebHost or \\nin a Host. \\n\\nSignalR is one example of an artifact using hosted services, but you can\", \" also use it for much simpler \\nthings like: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nA background task polling a databa\", \"se looking for changes. \\n\\nA scheduled task updating some cache periodically. \\n\\nAn implementation of \", \"QueueBackgroundWorkItem that allows a task to be executed on a \\nbackground thread. \\n\\nProcessing mess\", \"ages from a message queue in the background of a web app while sharing \\ncommon services such as ILog\", \"ger. \\n\\nA background task started with Task.Run(). \\n\\nYou can basically offload any of those actions t\", \"o a background task that implements IHostedService. \\n\\nThe way you add one or multiple IHostedService\", \"s into your WebHost or Host is by registering them \\nup through the AddHostedService extension method\", \" in an ASP.NET Core WebHost (or in a Host in \\n.NET Core 2.1 and above). Basically, you have to regis\", \"ter the hosted services within application startup \\nin Program.cs. \\n\\n//Other DI registrations; \\n\\n// \", \"Register Hosted Services \\nbuilder.Services.AddHostedService<GracePeriodManagerService>(); \\nbuilder.S\", \"ervices.AddHostedService<MyHostedServiceB>(); \\nbuilder.Services.AddHostedService<MyHostedServiceC>()\", \"; \\n//... \\n\\nIn that code, the GracePeriodManagerService hosted service is real code from the Ordering\", \" business \\nmicroservice in eShopOnContainers, while the other two are just two additional samples. \\n\", \"\\nThe IHostedService background task execution is coordinated with the lifetime of the application (h\", \"ost \\nor microservice, for that matter). You register tasks when the application starts and you have \", \"the \\nopportunity to do some graceful action or clean-up when the application is shutting down. \\n\\nWit\", \"hout using IHostedService, you could always start a background thread to run any task. The \\ndifferen\", \"ce is precisely at the app\\u2019s shutdown time when that thread would simply be killed without \\nhaving t\", \"he opportunity to run graceful clean-up actions. \\n\\nThe IHostedService interface \\n\\nWhen you register \", \"an IHostedService, .NET calls the StartAsync() and StopAsync() methods of your \\nIHostedService type \", \"during application start and stop respectively. For more details, see \\nIHostedService interface. \\n\\n1\", \"59 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\", \"\\n \\n \\n \\n\\fAs you can imagine, you can create multiple implementations of IHostedService and register e\", \"ach of \\nthem in Program.cs, as shown previously. All those hosted services will be started and stopp\", \"ed along \\nwith the application/microservice. \\n\\nAs a developer, you are responsible for handling the \", \"stopping action of your services when \\nStopAsync() method is triggered by the host. \\n\\nImplementing I\", \"HostedService with a custom hosted service class \\nderiving from the BackgroundService base class \\n\\nY\", \"ou could go ahead and create your custom hosted service class from scratch and implement the \\nIHoste\", \"dService, as you need to do when using .NET Core 2.0 and later. \\n\\nHowever, since most background tas\", \"ks will have similar needs in regard to the cancellation tokens \\nmanagement and other typical operat\", \"ions, there is a convenient abstract base class you can derive \\nfrom, named BackgroundService (avail\", \"able since .NET Core 2.1). \\n\\nThat class provides the main work needed to set up the background task.\", \" \\n\\nThe next code is the abstract BackgroundService base class as implemented in .NET. \\n\\n// Copyright\", \" (c) .NET Foundation. Licensed under the Apache License, Version 2.0. \\n/// <summary> \\n/// Base class\", \" for implementing a long running <see cref=\\\"IHostedService\\\"/>. \\n/// </summary> \\npublic abstract clas\", \"s BackgroundService : IHostedService, IDisposable \\n{ \\n    private Task _executingTask; \\n    private \", \"readonly CancellationTokenSource _stoppingCts = \\n                                                   \", \"new CancellationTokenSource(); \\n\\n    protected abstract Task ExecuteAsync(CancellationToken stopping\", \"Token); \\n\\n    public virtual Task StartAsync(CancellationToken cancellationToken) \\n    { \\n        //\", \" Store the task we're executing \\n        _executingTask = ExecuteAsync(_stoppingCts.Token); \\n\\n      \", \"  // If the task is completed then return it, \\n        // this will bubble cancellation and failure \", \"to the caller \\n        if (_executingTask.IsCompleted) \\n        { \\n            return _executingTask\", \"; \\n        } \\n\\n        // Otherwise it's running \\n        return Task.CompletedTask; \\n    } \\n\\n    pu\", \"blic virtual async Task StopAsync(CancellationToken cancellationToken) \\n    { \\n        // Stop calle\", \"d without start \\n        if (_executingTask == null) \\n        { \\n            return; \\n        } \\n\\n16\", \"0 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n\", \" \\n \\n \\n \\n \\n \\n \\n \\n\\f        try \\n        { \\n            // Signal cancellation to the executing method \", \"\\n            _stoppingCts.Cancel(); \\n        } \\n        finally \\n        { \\n            // Wait unti\", \"l the task completes or the stop token triggers \\n            await Task.WhenAny(_executingTask, Task\", \".Delay(Timeout.Infinite, \\n                                                          cancellationToke\", \"n)); \\n        } \\n\\n    } \\n\\n    public virtual void Dispose() \\n    { \\n        _stoppingCts.Cancel(); \\n\", \"    } \\n} \\n\\nWhen deriving from the previous abstract base class, thanks to that inherited implementat\", \"ion, you just \\nneed to implement the ExecuteAsync() method in your own custom hosted service class, \", \"as in the \\nfollowing simplified code from eShopOnContainers which is polling a database and publishi\", \"ng \\nintegration events into the Event Bus when needed. \\n\\npublic class GracePeriodManagerService : Ba\", \"ckgroundService \\n{ \\n    private readonly ILogger<GracePeriodManagerService> _logger; \\n    private re\", \"adonly OrderingBackgroundSettings _settings; \\n\\n    private readonly IEventBus _eventBus; \\n\\n    publi\", \"c GracePeriodManagerService(IOptions<OrderingBackgroundSettings> settings, \\n                        \", \"             IEventBus eventBus, \\n                                     ILogger<GracePeriodManagerSer\", \"vice> logger) \\n    { \\n        // Constructor's parameters validations... \\n    } \\n\\n    protected over\", \"ride async Task ExecuteAsync(CancellationToken stoppingToken) \\n    { \\n        _logger.LogDebug($\\\"Gra\", \"cePeriodManagerService is starting.\\\"); \\n\\n        stoppingToken.Register(() => \\n            _logger.L\", \"ogDebug($\\\" GracePeriod background task is stopping.\\\")); \\n\\n        while (!stoppingToken.IsCancellati\", \"onRequested) \\n        { \\n            _logger.LogDebug($\\\"GracePeriod task doing background work.\\\"); \\n\", \"\\n            // This eShopOnContainers method is querying a database table \\n            // and publi\", \"shing events into the Event Bus (RabbitMQ / ServiceBus) \\n            CheckConfirmedGracePeriodOrders\", \"(); \\n\\n            try { \\n                    await Task.Delay(_settings.CheckUpdateTime, stoppingTok\", \"en); \\n                } \\n            catch (TaskCanceledException exception) { \\n                    \", \"_logger.LogCritical(exception, \\\"TaskCanceledException Error\\\", \\nexception.Message); \\n\\n161 \\n\\nCHAPTER 5\", \" | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \", \"\\n \\n \\n \\n \\n\\f                } \\n        } \\n\\n        _logger.LogDebug($\\\"GracePeriod background task is s\", \"topping.\\\"); \\n    } \\n\\n    .../... \\n} \\n\\nIn this specific case for eShopOnContainers, it\\u2019s executing an\", \" application method that\\u2019s querying a \\ndatabase table looking for orders with a specific state and w\", \"hen applying changes, it is publishing \\nintegration events through the event bus (underneath it can \", \"be using RabbitMQ or Azure Service Bus). \\n\\nOf course, you could run any other business background ta\", \"sk, instead. \\n\\nBy default, the cancellation token is set with a 5 seconds timeout, although you can \", \"change that value \\nwhen building your WebHost using the UseShutdownTimeout extension of the IWebHost\", \"Builder. This \\nmeans that our service is expected to cancel within 5 seconds otherwise it will be mo\", \"re abruptly killed. \\n\\nThe following code would be changing that time to 10 seconds. \\n\\nWebHost.Create\", \"DefaultBuilder(args) \\n    .UseShutdownTimeout(TimeSpan.FromSeconds(10)) \\n    ... \\n\\nSummary class dia\", \"gram \\n\\nThe following image shows a visual summary of the classes and interfaces involved when \\nimple\", \"menting IHostedServices. \\n\\nFigure 6-27. Class diagram showing the multiple classes and interfaces re\", \"lated to IHostedService \\n\\nClass diagram: IWebHost and IHost can host many services, which inherit fr\", \"om BackgroundService, \\nwhich implements IHostedService. \\n\\n162 \\n\\nCHAPTER 5 | Designing and Developing\", \" Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\fDeployment considerations and\", \" takeaways \\n\\nIt is important to note that the way you deploy your ASP.NET Core WebHost or .NET Host \", \"might \\nimpact the final solution. For instance, if you deploy your WebHost on IIS or a regular Azure\", \" App \\nService, your host can be shut down because of app pool recycles. But if you are deploying you\", \"r host \\nas a container into an orchestrator like Kubernetes, you can control the assured number of l\", \"ive \\ninstances of your host. In addition, you could consider other approaches in the cloud especiall\", \"y made \\nfor these scenarios, like Azure Functions. Finally, if you need the service to be running al\", \"l the time and \\nare deploying on a Windows Server you could use a Windows Service. \\n\\nBut even for a \", \"WebHost deployed into an app pool, there are scenarios like repopulating or flushing \\napplication\\u2019s \", \"in-memory cache that would be still applicable. \\n\\nThe IHostedService interface provides a convenient\", \" way to start background tasks in an ASP.NET Core \\nweb application (in .NET Core 2.0 and later versi\", \"ons) or in any process/host (starting in .NET Core 2.1 \\nwith IHost). Its main benefit is the opportu\", \"nity you get with the graceful cancellation to clean-up the \\ncode of your background tasks when the \", \"host itself is shutting down. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nBuilding a scheduled task in ASP.\", \"NET Core/Standard 2.0 \\nhttps://blog.maartenballiauw.be/post/2017/08/01/building-a-scheduled-cache-up\", \"dater-in-\\naspnet-core-2.html \\n\\nImplementing IHostedService in ASP.NET Core 2.0 \\nhttps://www.stevejgo\", \"rdon.co.uk/asp-net-core-2-ihostedservice \\n\\nGenericHost Sample using ASP.NET Core 2.1 \\nhttps://github\", \".com/aspnet/Hosting/tree/release/2.1/samples/GenericHostSample \\n\\nImplement API Gateways with Ocelot \", \"\\n\\nImportant \\n\\nThe reference microservice application eShopOnContainers is currently using features p\", \"rovided by \\nEnvoy to implement the API Gateway instead of the earlier referenced Ocelot. We made thi\", \"s design \\nchoice because of Envoy\\u2019s built-in support for the WebSocket protocol, required by the new\", \" gRPC \\ninter-service communications implemented in eShopOnContainers. However, we\\u2019ve retained this \\n\", \"section in the guide so you can consider Ocelot as a simple, capable, and lightweight API Gateway \\ns\", \"uitable for production-grade scenarios. Also, latest Ocelot version contains a breaking change on it\", \"s \\njson schema. Consider using Ocelot < v16.0.0, or use the key Routes instead of ReRoutes. \\n\\nArchit\", \"ect and design your API Gateways \\n\\nThe following architecture diagram shows how API Gateways were im\", \"plemented with Ocelot in \\neShopOnContainers. \\n\\n163 \\n\\nCHAPTER 5 | Designing and Developing Multi-Cont\", \"ainer and Microservice-Based .NET Applications \\n\\n \\n \\n\\fFigure 6-28. eShopOnContainers architecture wi\", \"th API Gateways \\n\\nThat diagram shows how the whole application is deployed into a single Docker host\", \" or development \\nPC with \\u201cDocker for Windows\\u201d or \\u201cDocker for Mac\\u201d. However, deploying into any orche\", \"strator would \\nbe similar, but any container in the diagram could be scaled out in the orchestrator.\", \" \\n\\nIn addition, the infrastructure assets such as databases, cache, and message brokers should be \\no\", \"ffloaded from the orchestrator and deployed into high available systems for infrastructure, like Azu\", \"re \\nSQL Database, Azure Cosmos DB, Azure Redis, Azure Service Bus, or any HA clustering solution on-\", \"\\npremises. \\n\\nAs you can also notice in the diagram, having several API Gateways allows multiple deve\", \"lopment \\nteams to be autonomous (in this case Marketing features vs. Shopping features) when develop\", \"ing and \\ndeploying their microservices plus their own related API Gateways. \\n\\nIf you had a single mo\", \"nolithic API Gateway that would mean a single point to be updated by several \\ndevelopment teams, whi\", \"ch could couple all the microservices with a single part of the application. \\n\\nGoing much further in\", \" the design, sometimes a fine-grained API Gateway can also be limited to a \\nsingle business microser\", \"vice depending on the chosen architecture. Having the API Gateway\\u2019s \\nboundaries dictated by the busi\", \"ness or domain will help you to get a better design. \\n\\nFor instance, fine granularity in the API Gat\", \"eway tier can be especially useful for more advanced \\ncomposite UI applications that are based on mi\", \"croservices, because the concept of a fine-grained API \\nGateway is similar to a UI composition servi\", \"ce. \\n\\nWe delve into more details in the previous section Creating composite UI based on microservice\", \"s. \\n\\nAs a key takeaway, for many medium- and large-size applications, using a custom-built API Gatew\", \"ay \\nproduct is usually a good approach, but not as a single monolithic aggregator or unique central \", \"\\ncustom API Gateway unless that API Gateway allows multiple independent configuration areas for the \", \"\\nseveral development teams creating autonomous microservices. \\n\\n164 \\n\\nCHAPTER 5 | Designing and Deve\", \"loping Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fSample microservices/contai\", \"ners to reroute through the API Gateways \\n\\nAs an example, eShopOnContainers has around six internal \", \"microservice-types that have to be \\npublished through the API Gateways, as shown in the following im\", \"age. \\n\\nFigure 6-29. Microservice folders in eShopOnContainers solution in Visual Studio \\n\\nAbout the \", \"Identity service, in the design it\\u2019s left out of the API Gateway routing because it\\u2019s the only \\ncros\", \"s-cutting concern in the system, although with Ocelot it\\u2019s also possible to include it as part of th\", \"e \\nrerouting lists. \\n\\nAll those services are currently implemented as ASP.NET Core Web API services,\", \" as you can tell from \\nthe code. Let\\u2019s focus on one of the microservices like the Catalog microservi\", \"ce code. \\n\\nFigure 6-30. Sample Web API microservice (Catalog microservice) \\n\\n165 \\n\\nCHAPTER 5 | Desig\", \"ning and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n\\fYou can see \", \"that the Catalog microservice is a typical ASP.NET Core Web API project with several \\ncontrollers an\", \"d methods like in the following code. \\n\\n[HttpGet] \\n[Route(\\\"items/{id:int}\\\")] \\n[ProducesResponseType(\", \"(int)HttpStatusCode.BadRequest)] \\n[ProducesResponseType((int)HttpStatusCode.NotFound)] \\n[ProducesRes\", \"ponseType(typeof(CatalogItem),(int)HttpStatusCode.OK)] \\npublic async Task<IActionResult> GetItemById\", \"(int id) \\n{ \\n    if (id <= 0) \\n    { \\n        return BadRequest(); \\n    } \\n    var item = await _cat\", \"alogContext.CatalogItems. \\n                                          SingleOrDefaultAsync(ci => ci.I\", \"d == id); \\n    //\\u2026 \\n\\n    if (item != null) \\n    { \\n        return Ok(item); \\n    } \\n    return NotFo\", \"und(); \\n} \\n\\nThe HTTP request will end up running that kind of C# code accessing the microservice dat\", \"abase and \\nany additional required action. \\n\\nRegarding the microservice URL, when the containers are\", \" deployed in your local development PC \\n(local Docker host), each microservice\\u2019s container always ha\", \"s an internal port (usually port 80) \\nspecified in its dockerfile, as in the following dockerfile: \\n\", \"\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 AS base \\nWORKDIR /app \\nEXPOSE 80 \\n\\nThe port 80 shown in th\", \"e code is internal within the Docker host, so it can\\u2019t be reached by client apps. \\n\\nClient apps can \", \"access only the external ports (if any) published when deploying with docker-\\ncompose. \\n\\nThose exter\", \"nal ports shouldn\\u2019t be published when deploying to a production environment. For this \\nspecific reas\", \"on, why you want to use the API Gateway, to avoid the direct communication between the \\nclient apps \", \"and the microservices. \\n\\nHowever, when developing, you want to access the microservice/container dir\", \"ectly and run it through \\nSwagger. That\\u2019s why in eShopOnContainers, the external ports are still spe\", \"cified even when they won\\u2019t \\nbe used by the API Gateway or the client apps. \\n\\nHere\\u2019s an example of t\", \"he docker-compose.override.yml file for the Catalog microservice: \\n\\ncatalog-api: \\n  environment: \\n  \", \"  - ASPNETCORE_ENVIRONMENT=Development \\n    - ASPNETCORE_URLS=http://0.0.0.0:80 \\n    - ConnectionStr\", \"ing=YOUR_VALUE \\n    - ... Other Environment Variables \\n\\n166 \\n\\nCHAPTER 5 | Designing and Developing M\", \"ulti-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\f  ports: \\n    - \\\"5101:80\\\"   # Impor\", \"tant: In a production environment you should remove the external \\nport (5101) kept here for microser\", \"vice debugging purposes. \\n                  # The API Gateway redirects and access through the inter\", \"nal port (80). \\n\\nYou can see how in the docker-compose.override.yml configuration the internal port \", \"for the Catalog \\ncontainer is port 80, but the port for external access is 5101. But this port shoul\", \"dn\\u2019t be used by the \\napplication when using an API Gateway, only to debug, run, and test just the Ca\", \"talog microservice. \\n\\nNormally, you won\\u2019t be deploying with docker-compose into a production environ\", \"ment because the \\nright production deployment environment for microservices is an orchestrator like \", \"Kubernetes or \\nService Fabric. When deploying to those environments you use different configuration \", \"files where you \\nwon\\u2019t publish directly any external port for the microservices but, you\\u2019ll always u\", \"se the reverse proxy \\nfrom the API Gateway. \\n\\nRun the catalog microservice in your local Docker host\", \". Either run the full eShopOnContainers solution \\nfrom Visual Studio (it runs all the services in th\", \"e docker-compose files), or start the Catalog \\nmicroservice with the following docker-compose comman\", \"d in CMD or PowerShell positioned at the \\nfolder where the docker-compose.yml and docker-compose.ove\", \"rride.yml are placed. \\n\\ndocker-compose run --service-ports catalog-api \\n\\nThis command only runs the \", \"catalog-api service container plus dependencies that are specified in the \\ndocker-compose.yml. In th\", \"is case, the SQL Server container and RabbitMQ container. \\n\\nThen, you can directly access the Catalo\", \"g microservice and see its methods through the Swagger UI \\naccessing directly through that \\u201cexternal\", \"\\u201d port, in this case http://host.docker.internal:5101/swagger: \\n\\n167 \\n\\nCHAPTER 5 | Designing and Dev\", \"eloping Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n\\fFigure 6-31. Testing the Cat\", \"alog microservice with its Swagger UI \\n\\nAt this point, you could set a breakpoint in C# code in Visu\", \"al Studio, test the microservice with the \\nmethods exposed in Swagger UI, and finally clean-up every\", \"thing with the docker-compose down \\ncommand. \\n\\nHowever, direct-access communication to the microserv\", \"ice, in this case through the external port \\n5101, is precisely what you want to avoid in your appli\", \"cation. And you can avoid that by setting the \\nadditional level of indirection of the API Gateway (O\", \"celot, in this case). That way, the client app won\\u2019t \\ndirectly access the microservice. \\n\\nImplementi\", \"ng your API Gateways with Ocelot \\n\\nOcelot is basically a set of middleware that you can apply in a s\", \"pecific order. \\n\\nOcelot is designed to work with ASP.NET Core only. The latest version of the packag\", \"e is 18.0 which \\ntargets .NET 6 and hence is not suitable for .NET Framework applications. \\n\\n168 \\n\\nC\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \", \"\\n\\fYou install Ocelot and its dependencies in your ASP.NET Core project with Ocelot\\u2019s NuGet package, \", \"\\nfrom Visual Studio. \\n\\nInstall-Package Ocelot \\n\\nIn eShopOnContainers, its API Gateway implementation\", \" is a simple ASP.NET Core WebHost project, \\nand Ocelot\\u2019s middleware handles all the API Gateway feat\", \"ures, as shown in the following image: \\n\\nFigure 6-32. The OcelotApiGw base project in eShopOnContain\", \"ers \\n\\nThis ASP.NET Core WebHost project is built with two simple files: Program.cs and Startup.cs. \\n\", \"\\nThe Program.cs just needs to create and configure the typical ASP.NET Core BuildWebHost. \\n\\nnamespac\", \"e OcelotApiGw \\n{ \\n    public class Program \\n    { \\n        public static void Main(string[] args) \\n \", \"       { \\n            BuildWebHost(args).Run(); \\n        } \\n\\n        public static IWebHost BuildWeb\", \"Host(string[] args) \\n        { \\n            var builder = WebHost.CreateDefaultBuilder(args); \\n\\n    \", \"        builder.ConfigureServices(s => s.AddSingleton(builder)) \\n                    .ConfigureAppCo\", \"nfiguration( \\n                          ic => ic.AddJsonFile(Path.Combine(\\\"configuration\\\", \\n        \", \"                                                    \\\"configuration.json\\\"))) \\n                    .Us\", \"eStartup<Startup>(); \\n            var host = builder.Build(); \\n            return host; \\n        } \\n\", \"    } \\n} \\n\\n169 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Ap\", \"plications \\n\\n \\n \\n \\n \\n \\n\\fThe important point here for Ocelot is the configuration.json file that you \", \"must provide to the builder \\nthrough the AddJsonFile() method. That configuration.json is where you \", \"specify all the API Gateway \\nReRoutes, meaning the external endpoints with specific ports and the co\", \"rrelated internal endpoints, \\nusually using different ports. \\n\\n{ \\n    \\\"ReRoutes\\\": [], \\n    \\\"GlobalCo\", \"nfiguration\\\": {} \\n} \\n\\nThere are two sections to the configuration. An array of ReRoutes and a Global\", \"Configuration. The \\nReRoutes are the objects that tell Ocelot how to treat an upstream request. The \", \"Global configuration \\nallows overrides of ReRoute specific settings. It\\u2019s useful if you don\\u2019t want t\", \"o manage lots of ReRoute \\nspecific settings. \\n\\nHere\\u2019s a simplified example of ReRoute configuration \", \"file from one of the API Gateways from \\neShopOnContainers. \\n\\n{ \\n  \\\"ReRoutes\\\": [ \\n    { \\n      \\\"Downs\", \"treamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"Downst\", \"reamHostAndPorts\\\": [ \\n        { \\n          \\\"Host\\\": \\\"catalog-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n\", \"      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/api/{version}/c/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\"\", \": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ] \\n    }, \\n    { \\n      \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everythi\", \"ng}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"DownstreamHostAndPorts\\\": [ \\n        { \\n          \\\"H\", \"ost\\\": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/api/\", \"{version}/b/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\n      \\\"Authentica\", \"tionOptions\\\": { \\n        \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\": []\", \" \\n      } \\n    } \\n\\n  ], \\n    \\\"GlobalConfiguration\\\": { \\n      \\\"RequestIdKey\\\": \\\"OcRequestId\\\", \\n      \\\"\", \"AdministrationPath\\\": \\\"/administration\\\" \\n    } \\n  } \\n\\n170 \\n\\nCHAPTER 5 | Designing and Developing Mult\", \"i-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fThe main functionality of an Ocelot AP\", \"I Gateway is to take incoming HTTP requests and forward them \\non to a downstream service, currently \", \"as another HTTP request. Ocelot\\u2019s describes the routing of one \\nrequest to another as a ReRoute. \\n\\nF\", \"or instance, let\\u2019s focus on one of the ReRoutes in the configuration.json from above, the \\nconfigura\", \"tion for the Basket microservice. \\n\\n{ \\n      \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\"\", \", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"DownstreamHostAndPorts\\\": [ \\n        { \\n          \\\"Host\\\"\", \": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n      ], \\n      \\\"UpstreamPathTemplate\\\": \\\"/api/{ver\", \"sion}/b/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\n      \\\"Authentication\", \"Options\\\": { \\n        \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\": [] \\n  \", \"    } \\n} \\n\\nThe DownstreamPathTemplate, Scheme, and DownstreamHostAndPorts make the internal \\nmicrose\", \"rvice URL that this request will be forwarded to. \\n\\nThe port is the internal port used by the servic\", \"e. When using containers, the port specified at its \\ndockerfile. \\n\\nThe Host is a service name that d\", \"epends on the service name resolution you are using. When using \\ndocker-compose, the services names \", \"are provided by the Docker Host, which is using the service \\nnames provided in the docker-compose fi\", \"les. If using an orchestrator like Kubernetes or Service \\nFabric, that name should be resolved by th\", \"e DNS or name resolution provided by each orchestrator. \\n\\nDownstreamHostAndPorts is an array that co\", \"ntains the host and port of any downstream services that \\nyou wish to forward requests to. Usually t\", \"his configuration will just contain one entry but sometimes \\nyou might want to load balance requests\", \" to your downstream services and Ocelot lets you add more \\nthan one entry and then select a load bal\", \"ancer. But if using Azure and any orchestrator it is probably a \\nbetter idea to load balance with th\", \"e cloud and orchestrator infrastructure. \\n\\nThe UpstreamPathTemplate is the URL that Ocelot will use \", \"to identify which \\nDownstreamPathTemplate to use for a given request from the client. Finally, the \\n\", \"UpstreamHttpMethod is used so Ocelot can distinguish between different requests (GET, POST, PUT) \\nto\", \" the same URL. \\n\\nAt this point, you could have a single Ocelot API Gateway (ASP.NET Core WebHost) us\", \"ing one or \\nmultiple merged configuration.json files or you can also store the configuration in a Co\", \"nsul KV store. \\n\\nBut as introduced in the architecture and design sections, if you really want to ha\", \"ve autonomous \\nmicroservices, it might be better to split that single monolithic API Gateway into mu\", \"ltiple API \\nGateways and/or BFF (Backend for Frontend). For that purpose, let\\u2019s see how to implement\", \" that \\napproach with Docker containers. \\n\\n171 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container\", \" and Microservice-Based .NET Applications \\n\\n \\n \\n\\fUsing a single Docker container image to run multip\", \"le different API Gateway / BFF \\ncontainer types \\n\\nIn eShopOnContainers, we\\u2019re using a single Docker \", \"container image with the Ocelot API Gateway but \\nthen, at run time, we create different services/con\", \"tainers for each type of API-Gateway/BFF by \\nproviding a different configuration.json file, using a \", \"docker volume to access a different PC folder for \\neach service. \\n\\nFigure 6-33. Reusing a single Oce\", \"lot Docker image across multiple API Gateway types \\n\\nIn eShopOnContainers, the \\u201cGeneric Ocelot API G\", \"ateway Docker Image\\u201d is created with the project \\nnamed \\u2018OcelotApiGw\\u2019 and the image name \\u201ceshop/ocel\", \"otapigw\\u201d that is specified in the docker-\\ncompose.yml file. Then, when deploying to Docker, there wi\", \"ll be four API-Gateway containers created \\nfrom that same Docker image, as shown in the following ex\", \"tract from the docker-compose.yml file. \\n\\n  mobileshoppingapigw: \\n    image: eshop/ocelotapigw:${TAG\", \":-latest} \\n\\n172 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET A\", \"pplications \\n\\n \\n \\n \\n\\f    build: \\n      context: . \\n      dockerfile: src/ApiGateways/ApiGw-Base/Dock\", \"erfile \\n\\n  mobilemarketingapigw: \\n    image: eshop/ocelotapigw:${TAG:-latest} \\n    build: \\n      con\", \"text: . \\n      dockerfile: src/ApiGateways/ApiGw-Base/Dockerfile \\n\\n  webshoppingapigw: \\n    image: e\", \"shop/ocelotapigw:${TAG:-latest} \\n    build: \\n      context: . \\n      dockerfile: src/ApiGateways/Api\", \"Gw-Base/Dockerfile \\n\\n  webmarketingapigw: \\n    image: eshop/ocelotapigw:${TAG:-latest} \\n    build: \\n\", \"      context: . \\n      dockerfile: src/ApiGateways/ApiGw-Base/Dockerfile \\n\\nAdditionally, as you can\", \" see in the following docker-compose.override.yml file, the only difference \\nbetween those API Gatew\", \"ay containers is the Ocelot configuration file, which is different for each \\nservice container and i\", \"t\\u2019s specified at run time through a Docker volume. \\n\\nmobileshoppingapigw: \\n  environment: \\n    - ASP\", \"NETCORE_ENVIRONMENT=Development \\n    - IdentityUrl=http://identity-api \\n  ports: \\n    - \\\"5200:80\\\" \\n \", \" volumes: \\n    - ./src/ApiGateways/Mobile.Bff.Shopping/apigw:/app/configuration \\n\\nmobilemarketingapi\", \"gw: \\n  environment: \\n    - ASPNETCORE_ENVIRONMENT=Development \\n    - IdentityUrl=http://identity-api\", \" \\n  ports: \\n    - \\\"5201:80\\\" \\n  volumes: \\n    - ./src/ApiGateways/Mobile.Bff.Marketing/apigw:/app/con\", \"figuration \\n\\nwebshoppingapigw: \\n  environment: \\n    - ASPNETCORE_ENVIRONMENT=Development \\n    - Iden\", \"tityUrl=http://identity-api \\n  ports: \\n    - \\\"5202:80\\\" \\n  volumes: \\n    - ./src/ApiGateways/Web.Bff.\", \"Shopping/apigw:/app/configuration \\n\\nwebmarketingapigw: \\n  environment: \\n    - ASPNETCORE_ENVIRONMENT\", \"=Development \\n    - IdentityUrl=http://identity-api \\n  ports: \\n    - \\\"5203:80\\\" \\n\\n173 \\n\\nCHAPTER 5 | D\", \"esigning and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\f\", \"  volumes: \\n    - ./src/ApiGateways/Web.Bff.Marketing/apigw:/app/configuration \\n\\nBecause of that pre\", \"vious code, and as shown in the Visual Studio Explorer below, the only file needed \\nto define each s\", \"pecific business/BFF API Gateway is just a configuration.json file, because the four API \\nGateways a\", \"re based on the same Docker image. \\n\\nFigure 6-34. The only file needed to define each API Gateway / \", \"BFF with Ocelot is a configuration file \\n\\nBy splitting the API Gateway into multiple API Gateways, d\", \"ifferent development teams focusing on \\ndifferent subsets of microservices can manage their own API \", \"Gateways by using independent Ocelot \\nconfiguration files. Plus, at the same time they can reuse the\", \" same Ocelot Docker image. \\n\\nNow, if you run eShopOnContainers with the API Gateways (included by de\", \"fault in VS when opening \\neShopOnContainers-ServicesAndWebApps.sln solution or if running \\u201cdocker-co\", \"mpose up\\u201d), the \\nfollowing sample routes will be performed. \\n\\nFor instance, when visiting the upstre\", \"am URL \\nhttp://host.docker.internal:5202/api/v1/c/catalog/items/2/ served by the webshoppingapigw AP\", \"I \\nGateway, you get the same result from the internal Downstream URL http://catalog-api/api/v1/2 \\nwi\", \"thin the Docker host, as in the following browser. \\n\\nFigure 6-35. Accessing a microservice through a\", \" URL provided by the API Gateway \\n\\nBecause of testing or debugging reasons, if you wanted to directl\", \"y access to the Catalog Docker \\ncontainer (only at the development environment) without passing thro\", \"ugh the API Gateway, since \\n\\u2018catalog-api\\u2019 is a DNS resolution internal to the Docker host (service d\", \"iscovery handled by docker-\\ncompose service names), the only way to directly access the container is\", \" through the external port \\npublished in the docker-compose.override.yml, which is provided only for\", \" development tests, such as \\nhttp://host.docker.internal:5101/api/v1/Catalog/items/1 in the followin\", \"g browser. \\n\\n174 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET \", \"Applications \\n\\n \\n \\n \\n \\n\\fFigure 6-36. Direct access to a microservice for testing purposes \\n\\nBut the \", \"application is configured so it accesses all the microservices through the API Gateways, not \\nthroug\", \"h the direct port \\u201cshortcuts\\u201d. \\n\\nThe Gateway aggregation pattern in eShopOnContainers \\n\\nAs introduce\", \"d previously, a flexible way to implement requests aggregation is with custom services, by \\ncode. Yo\", \"u could also implement request aggregation with the Request Aggregation feature in Ocelot, \\nbut it m\", \"ight not be as flexible as you need. Therefore, the selected way to implement aggregation in \\neShopO\", \"nContainers is with an explicit ASP.NET Core Web API service for each aggregator. \\n\\nAccording to tha\", \"t approach, the API Gateway composition diagram is in reality a bit more extended \\nwhen considering \", \"the aggregator services that are not shown in the simplified global architecture \\ndiagram shown prev\", \"iously. \\n\\nIn the following diagram, you can also see how the aggregator services work with their rel\", \"ated API \\nGateways. \\n\\nFigure 6-37. eShopOnContainers architecture with aggregator services \\n\\nZooming\", \" in further, on the \\u201cShopping\\u201d business area in the following image, you can see that \\nchattiness be\", \"tween the client apps and the microservices is reduced when using the aggregator \\nservices in the AP\", \"I Gateways. \\n\\n175 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET\", \" Applications \\n\\n \\n \\n \\n \\n\\fFigure 6-38. Zoom in vision of the Aggregator services \\n\\nYou can notice how\", \" when the diagram shows the possible requests coming from the API Gateways it \\ncan get complex. On t\", \"he other hand, when you use the aggregator pattern, you can see how the \\narrows in blue would simpli\", \"fy the communication from a client app perspective. This pattern not only \\nhelps to reduce the chatt\", \"iness and latency in the communication, it also improves the user experience \\nsignificantly for the \", \"remote apps (mobile and SPA apps). \\n\\nIn the case of the \\u201cMarketing\\u201d business area and microservices,\", \" it is a simple use case so there was no \\nneed to use aggregators, but it could also be possible, if\", \" needed. \\n\\nAuthentication and authorization in Ocelot API Gateways \\n\\nIn an Ocelot API Gateway, you c\", \"an sit the authentication service, such as an ASP.NET Core Web API \\nservice using IdentityServer pro\", \"viding the auth token, either out or inside the API Gateway. \\n\\nSince eShopOnContainers is using mult\", \"iple API Gateways with boundaries based on BFF and business \\nareas, the Identity/Auth service is lef\", \"t out of the API Gateways, as highlighted in yellow in the \\nfollowing diagram. \\n\\n176 \\n\\nCHAPTER 5 | D\", \"esigning and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \\n\\fFigure 6-3\", \"9. Position of the Identity service in eShopOnContainers \\n\\nHowever, Ocelot also supports sitting the\", \" Identity/Auth microservice within the API Gateway \\nboundary, as in this other diagram. \\n\\nFigure 6-4\", \"0. Authentication in Ocelot \\n\\nAs the previous diagram shows, when the Identity microservice is benea\", \"th the API gateway (AG): 1) AG \\nrequests an auth token from identity microservice, 2) The identity m\", \"icroservice returns token to AG, 3-\\n4) AG requests from microservices using the auth token. Because \", \"eShopOnContainers application has \\nsplit the API Gateway into multiple BFF (Backend for Frontend) an\", \"d business areas API Gateways, \\nanother option would have been to create an additional API Gateway f\", \"or cross-cutting concerns. That \\nchoice would be fair in a more complex microservice based architect\", \"ure with multiple cross-cutting \\nconcerns microservices. Since there\\u2019s only one cross-cutting concer\", \"n in eShopOnContainers, it was \\ndecided to just handle the security service out of the API Gateway r\", \"ealm, for simplicity\\u2019s sake. \\n\\n177 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Micros\", \"ervice-Based .NET Applications \\n\\n \\n \\n \\n \\n\\fIn any case, if the app is secured at the API Gateway leve\", \"l, the authentication module of the Ocelot \\nAPI Gateway is visited at first when trying to use any s\", \"ecured microservice. That redirects the HTTP \\nrequest to visit the Identity or auth microservice to \", \"get the access token so you can visit the protected \\nservices with the access_token. \\n\\nThe way you s\", \"ecure with authentication any service at the API Gateway level is by setting the \\nAuthenticationProv\", \"iderKey in its related settings at the configuration.json. \\n\\n    { \\n      \\\"DownstreamPathTemplate\\\": \", \"\\\"/api/{version}/{everything}\\\", \\n      \\\"DownstreamScheme\\\": \\\"http\\\", \\n      \\\"DownstreamHostAndPorts\\\": [\", \" \\n        { \\n          \\\"Host\\\": \\\"basket-api\\\", \\n          \\\"Port\\\": 80 \\n        } \\n      ], \\n      \\\"Upst\", \"reamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\", \\n      \\\"UpstreamHttpMethod\\\": [], \\n      \\\"Authent\", \"icationOptions\\\": { \\n        \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\n        \\\"AllowedScopes\\\":\", \" [] \\n      } \\n    } \\n\\nWhen Ocelot runs, it will look at the ReRoutes AuthenticationOptions.Authentic\", \"ationProviderKey and \\ncheck that there is an Authentication Provider registered with the given key. \", \"If there isn\\u2019t, then Ocelot \\nwill not start up. If there is, then the ReRoute will use that provider\", \" when it executes. \\n\\nBecause the Ocelot WebHost is configured with the authenticationProviderKey = \\\"\", \"IdentityApiKey\\\", \\nthat will require authentication whenever that service has any requests without an\", \"y auth token. \\n\\nnamespace OcelotApiGw \\n{ \\n    public class Startup \\n    { \\n        private readonly \", \"IConfiguration _cfg; \\n\\n        public Startup(IConfiguration configuration) => _cfg = configuration;\", \" \\n\\n        public void ConfigureServices(IServiceCollection services) \\n        { \\n            var id\", \"entityUrl = _cfg.GetValue<string>(\\\"IdentityUrl\\\"); \\n            var authenticationProviderKey = \\\"Iden\", \"tityApiKey\\\"; \\n                         //\\u2026 \\n            services.AddAuthentication() \\n              \", \"  .AddJwtBearer(authenticationProviderKey, x => \\n                { \\n                    x.Authority \", \"= identityUrl; \\n                    x.RequireHttpsMetadata = false; \\n                    x.TokenVali\", \"dationParameters = new \\nMicrosoft.IdentityModel.Tokens.TokenValidationParameters() \\n                \", \"    { \\n                        ValidAudiences = new[] { \\\"orders\\\", \\\"basket\\\", \\\"locations\\\", \\n\\\"marketing\", \"\\\", \\\"mobileshoppingagg\\\", \\\"webshoppingagg\\\" } \\n                    }; \\n                }); \\n           \", \" //... \\n\\n178 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Appl\", \"ications \\n\\n \\n \\n \\n \\n\\f        } \\n    } \\n} \\n\\nThen, you also need to set authorization with the [Authori\", \"ze] attribute on any resource to be accessed \\nlike the microservices, such as in the following Baske\", \"t microservice controller. \\n\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.Controllers \\n\", \"{ \\n    [Route(\\\"api/v1/[controller]\\\")] \\n    [Authorize] \\n    public class BasketController : Controll\", \"er \\n    { \\n      //... \\n    } \\n} \\n\\nThe ValidAudiences such as \\u201cbasket\\u201d are correlated with the audie\", \"nce defined in each microservice \\nwith AddJwtBearer() at the ConfigureServices() of the Startup clas\", \"s, such as in the code below. \\n\\n// prevent from mapping \\\"sub\\\" claim to nameidentifier. \\nJwtSecurityT\", \"okenHandler.DefaultInboundClaimTypeMap.Clear(); \\n\\nvar identityUrl = Configuration.GetValue<string>(\\\"\", \"IdentityUrl\\\"); \\n\\nservices.AddAuthentication(options => \\n{ \\n    options.DefaultAuthenticateScheme = J\", \"wtBearerDefaults.AuthenticationScheme; \\n    options.DefaultChallengeScheme = JwtBearerDefaults.Authe\", \"nticationScheme; \\n\\n}).AddJwtBearer(options => \\n{ \\n    options.Authority = identityUrl; \\n    options.\", \"RequireHttpsMetadata = false; \\n    options.Audience = \\\"basket\\\"; \\n}); \\n\\nIf you try to access any secu\", \"red microservice, like the Basket microservice with a ReRoute URL based \\non the API Gateway like htt\", \"p://host.docker.internal:5202/api/v1/b/basket/1, then you\\u2019ll get a 401 \\nUnauthorized unless you prov\", \"ide a valid token. On the other hand, if a ReRoute URL is authenticated, \\nOcelot will invoke whateve\", \"r downstream scheme is associated with it (the internal microservice URL). \\n\\nAuthorization at Ocelot\", \"\\u2019s ReRoutes tier. Ocelot supports claims-based authorization evaluated after \\nthe authentication. Yo\", \"u set the authorization at a route level by adding the following lines to the \\nReRoute configuration\", \". \\n\\n\\\"RouteClaimsRequirement\\\": { \\n    \\\"UserType\\\": \\\"employee\\\" \\n} \\n\\nIn that example, when the authoriza\", \"tion middleware is called, Ocelot will find if the user has the claim \\ntype \\u2018UserType\\u2019 in the token \", \"and if the value of that claim is \\u2018employee\\u2019. If it isn\\u2019t, then the user will not \\nbe authorized and\", \" the response will be 403 forbidden. \\n\\n179 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container an\", \"d Microservice-Based .NET Applications \\n\\n \\n \\n \\n \\n \\n\\fUsing Kubernetes Ingress plus Ocelot API Gateway\", \"s \\n\\nWhen using Kubernetes (like in an Azure Kubernetes Service cluster), you usually unify all the H\", \"TTP \\nrequests through the Kubernetes Ingress tier based on Nginx. \\n\\nIn Kubernetes, if you don\\u2019t use \", \"any ingress approach, then your services and pods have IPs only \\nroutable by the cluster network. \\n\\n\", \"But if you use an ingress approach, you\\u2019ll have a middle tier between the Internet and your services\", \" \\n(including your API Gateways), acting as a reverse proxy. \\n\\nAs a definition, an Ingress is a colle\", \"ction of rules that allow inbound connections to reach the cluster \\nservices. An ingress is configur\", \"ed to provide services externally reachable URLs, load balance traffic, \\nSSL termination and more. U\", \"sers request ingress by POSTing the Ingress resource to the API server. \\n\\nIn eShopOnContainers, when\", \" developing locally and using just your development machine as the \\nDocker host, you are not using a\", \"ny ingress but only the multiple API Gateways. \\n\\nHowever, when targeting a \\u201cproduction\\u201d environment \", \"based on Kubernetes, eShopOnContainers is \\nusing an ingress in front of the API gateways. That way, \", \"the clients still call the same base URL but the \\nrequests are routed to multiple API Gateways or BF\", \"F. \\n\\nAPI Gateways are front-ends or fa\\u00e7ades surfacing only the services but not the web applications\", \" that \\nare usually out of their scope. In addition, the API Gateways might hide certain internal mic\", \"roservices. \\n\\nThe ingress, however, is just redirecting HTTP requests but not trying to hide any mic\", \"roservice or web \\napp. \\n\\nHaving an ingress Nginx tier in Kubernetes in front of the web applications\", \" plus the several Ocelot API \\nGateways / BFF is the ideal architecture, as shown in the following di\", \"agram. \\n\\nFigure 6-41. The ingress tier in eShopOnContainers when deployed into Kubernetes \\n\\nA Kubern\", \"etes Ingress acts as a reverse proxy for all traffic to the app, including the web applications, \\nth\", \"at are out of the Api gateway scope. When you deploy eShopOnContainers into Kubernetes, it \\n\\n180 \\n\\nC\", \"HAPTER 5 | Designing and Developing Multi-Container and Microservice-Based .NET Applications \\n\\n \\n \\n \", \"\\n\\fexposes just a few services or endpoints via ingress, basically the following list of postfixes on\", \" the \\nURLs: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n/ for the client SPA web application \\n\\n/webmvc for the cli\", \"ent MVC web application \\n\\n/webstatus for the client web app showing the status/healthchecks \\n\\n/websh\", \"oppingapigw for the web BFF and shopping business processes \\n\\n/webmarketingapigw for the web BFF and\", \" marketing business processes \\n\\n/mobileshoppingapigw for the mobile BFF and shopping business proces\", \"ses \\n\\n/mobilemarketingapigw for the mobile BFF and marketing business processes \\n\\nWhen deploying to \", \"Kubernetes, each Ocelot API Gateway is using a different \\u201cconfiguration.json\\u201d file \\nfor each pod run\", \"ning the API Gateways. Those \\u201cconfiguration.json\\u201d files are provided by mounting \\n(originally with t\", \"he deploy.ps1 script) a volume created based on a Kubernetes config map named \\n\\u2018ocelot\\u2019. Each contai\", \"ner mounts its related configuration file in the container\\u2019s folder named \\n/app/configuration. \\n\\nIn \", \"the source code files of eShopOnContainers, the original \\u201cconfiguration.json\\u201d files can be found \\nwi\", \"thin the k8s/ocelot/ folder. There\\u2019s one file for each BFF/APIGateway. \\n\\nAdditional cross-cutting fe\", \"atures in an Ocelot API Gateway \\n\\nThere are other important features to research and use, when using\", \" an Ocelot API Gateway, described \\nin the following links. \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nService discove\", \"ry in the client side integrating Ocelot with Consul or Eureka \\nhttps://ocelot.readthedocs.io/en/lat\", \"est/features/servicediscovery.html \\n\\nCaching at the API Gateway tier \\nhttps://ocelot.readthedocs.io/\", \"en/latest/features/caching.html \\n\\nLogging at the API Gateway tier \\nhttps://ocelot.readthedocs.io/en/\", \"latest/features/logging.html \\n\\nQuality of Service (Retries and Circuit breakers) at the API Gateway \", \"tier \\nhttps://ocelot.readthedocs.io/en/latest/features/qualityofservice.html \\n\\nRate limiting \\nhttps:\", \"//ocelot.readthedocs.io/en/latest/features/ratelimiting.html \\n\\nSwagger for Ocelot \\nhttps://github.co\", \"m/Burgyn/MMLib.SwaggerForOcelot \\n\\n181 \\n\\nCHAPTER 5 | Designing and Developing Multi-Container and Mic\", \"roservice-Based .NET Applications \\n\\n \\n \\n\\fCHAPTER  6 \\n\\nTackle Business \\nComplexity in a \\nMicroservice\", \" with DDD \\nand CQRS Patterns \\n\\nDesign a domain model for each microservice or Bounded Context that r\", \"eflects understanding of the \\nbusiness domain. \\n\\nThis section focuses on more advanced microservices\", \" that you implement when you need to tackle \\ncomplex subsystems, or microservices derived from the k\", \"nowledge of domain experts with ever-\\nchanging business rules. The architecture patterns used in thi\", \"s section are based on domain-driven \\ndesign (DDD) and Command and Query Responsibility Segregation \", \"(CQRS) approaches, as illustrated \\nin Figure 7-1. \\n\\n182 \\n\\nCHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-1. External microservice architecture vers\", \"us internal architecture patterns for each microservice \\n\\nHowever, most of the techniques for data d\", \"riven microservices, such as how to implement an ASP.NET \\nCore Web API service or how to expose Swag\", \"ger metadata with Swashbuckle or NSwag, are also \\napplicable to the more advanced microservices impl\", \"emented internally with DDD patterns. This \\nsection is an extension of the previous sections, becaus\", \"e most of the practices explained earlier also \\napply here or for any kind of microservice. \\n\\nThis s\", \"ection first provides details on the simplified CQRS patterns used in the eShopOnContainers \\nreferen\", \"ce application. Later, you will get an overview of the DDD techniques that enable you to find \\ncommo\", \"n patterns that you can reuse in your applications. \\n\\nDDD is a large topic with a rich set of resour\", \"ces for learning. You can start with books like Domain-\\nDriven Design by Eric Evans and additional m\", \"aterials from Vaughn Vernon, Jimmy Nilsson, Greg \\nYoung, Udi Dahan, Jimmy Bogard, and many other DDD\", \"/CQRS experts. But most of all you need to try \\nto learn how to apply DDD techniques from the conver\", \"sations, whiteboarding, and domain modeling \\nsessions with the experts in your concrete business dom\", \"ain. \\n\\nAdditional resources \\n\\nDDD (Domain-Driven Design) \\n\\n\\u2022 \\n\\nEric Evans. Domain Language \\nhttps://\", \"domainlanguage.com/ \\n\\n\\u2022  Martin Fowler. Domain-Driven Design \\n\\nhttps://martinfowler.com/tags/domain%\", \"20driven%20design.html \\n\\n\\u2022 \\n\\nJimmy Bogard. Strengthening your domain: a primer \\nhttps://lostechies.c\", \"om/jimmybogard/2010/02/04/strengthening-your-domain-a-primer/ \\n\\n183 \\n\\nCHAPTER 6 | Tackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fDDD books \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022\", \" \\n\\n\\u2022 \\n\\nEric Evans. Domain-Driven Design: Tackling Complexity in the Heart of Software \\nhttps://www.a\", \"mazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/ \\n\\nEric Evans. Domain-Dri\", \"ven Design Reference: Definitions and Pattern Summaries \\nhttps://www.amazon.com/Domain-Driven-Design\", \"-Reference-Definitions-2014-09-\\n22/dp/B01N8YB4ZO/ \\n\\nVaughn Vernon. Implementing Domain-Driven Design\", \" \\nhttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\nVernon/dp/0321834577/ \\n\\nVaughn Ve\", \"rnon. Domain-Driven Design Distilled \\nhttps://www.amazon.com/Domain-Driven-Design-Distilled-Vaughn-V\", \"ernon/dp/0134434420/ \\n\\nJimmy Nilsson. Applying Domain-Driven Design and Patterns \\nhttps://www.amazon\", \".com/Applying-Domain-Driven-Design-Patterns-\\nExamples/dp/0321268202/ \\n\\nCesar de la Torre. N-Layered \", \"Domain-Oriented Architecture Guide with .NET \\nhttps://www.amazon.com/N-Layered-Domain-Oriented-Archi\", \"tecture-Guide-\\nNET/dp/8493903612/ \\n\\nAbel Avram and Floyd Marinescu. Domain-Driven Design Quickly \\nht\", \"tps://www.amazon.com/Domain-Driven-Design-Quickly-Abel-Avram/dp/1411609255/ \\n\\nScott Millett, Nick Tu\", \"ne - Patterns, Principles, and Practices of Domain-Driven Design \\nhttps://www.wiley.com/Patterns%2C+\", \"Principles%2C+and+Practices+of+Domain+Driven+Des\\nign-p-9781118714706 \\n\\nDDD training \\n\\n\\u2022 \\n\\nJulie Lerm\", \"an and Steve Smith. Domain-Driven Design Fundamentals \\nhttps://www.pluralsight.com/courses/fundament\", \"als-domain-driven-design \\n\\nApply simplified CQRS and DDD patterns in a \\nmicroservice \\n\\nCQRS is an ar\", \"chitectural pattern that separates the models for reading and writing data. The related \\nterm Comman\", \"d Query Separation (CQS) was originally defined by Bertrand Meyer in his book Object-\\nOriented Softw\", \"are Construction. The basic idea is that you can divide a system\\u2019s operations into two \\nsharply sepa\", \"rated categories: \\n\\n\\u2022 \\n\\nQueries. These queries return a result and don\\u2019t change the state of the sys\", \"tem, and they\\u2019re \\nfree of side effects. \\n\\n\\u2022 \\n\\nCommands. These commands change the state of a system.\", \" \\n\\n184 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\f\", \"CQS is a simple concept: it is about methods within the same object being either queries or \\ncommand\", \"s. Each method either returns state or mutates state, but not both. Even a single repository \\npatter\", \"n object can comply with CQS. CQS can be considered a foundational principle for CQRS. \\n\\nCommand and\", \" Query Responsibility Segregation (CQRS) was introduced by Greg Young and strongly \\npromoted by Udi \", \"Dahan and others. It\\u2019s based on the CQS principle, although it\\u2019s more detailed. It can \\nbe considere\", \"d a pattern based on commands and events plus optionally on asynchronous messages. \\nIn many cases, C\", \"QRS is related to more advanced scenarios, like having a different physical database \\nfor reads (que\", \"ries) than for writes (updates). Moreover, a more evolved CQRS system might \\nimplement Event-Sourcin\", \"g (ES) for your updates database, so you would only store events in the \\ndomain model instead of sto\", \"ring the current-state data. However, this approach is not used in this \\nguide. This guide uses the \", \"simplest CQRS approach, which consists of just separating the queries from \\nthe commands. \\n\\nThe sepa\", \"ration aspect of CQRS is achieved by grouping query operations in one layer and commands \\nin another\", \" layer. Each layer has its own data model (note that we say model, not necessarily a different \\ndata\", \"base) and is built using its own combination of patterns and technologies. More importantly, the \\ntw\", \"o layers can be within the same tier or microservice, as in the example (ordering microservice) used\", \" \\nfor this guide. Or they could be implemented on different microservices or processes so they can b\", \"e \\noptimized and scaled out separately without affecting one another. \\n\\nCQRS means having two object\", \"s for a read/write operation where in other contexts there\\u2019s one. There \\nare reasons to have a denor\", \"malized reads database, which you can learn about in more advanced \\nCQRS literature. But we aren\\u2019t u\", \"sing that approach here, where the goal is to have more flexibility in \\nthe queries instead of limit\", \"ing the queries with constraints from DDD patterns like aggregates. \\n\\nAn example of this kind of ser\", \"vice is the ordering microservice from the eShopOnContainers reference \\napplication. This service im\", \"plements a microservice based on a simplified CQRS approach. It uses a \\nsingle data source or databa\", \"se, but two logical models plus DDD patterns for the transactional \\ndomain, as shown in Figure 7-2. \", \"\\n\\n185 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fF\", \"igure 7-2. Simplified CQRS- and DDD-based microservice \\n\\nThe Logical \\u201cOrdering\\u201d Microservice include\", \"s its Ordering database, which can be, but doesn\\u2019t have to \\nbe, the same Docker host. Having the dat\", \"abase in the same Docker host is good for development, but \\nnot for production. \\n\\nThe application la\", \"yer can be the Web API itself. The important design aspect here is that the \\nmicroservice has split \", \"the queries and ViewModels (data models especially created for the client \\napplications) from the co\", \"mmands, domain model, and transactions following the CQRS pattern. This \\napproach keeps the queries \", \"independent from restrictions and constraints coming from DDD patterns \\nthat only make sense for tra\", \"nsactions and updates, as explained in later sections. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nGreg Young. Vers\", \"ioning in an Event Sourced System (Free to read online e-book) \\nhttps://leanpub.com/esversioning/rea\", \"d \\n\\nApply CQRS and CQS approaches in a DDD \\nmicroservice in eShopOnContainers \\n\\nThe design of the or\", \"dering microservice at the eShopOnContainers reference application is based on \\nCQRS principles. How\", \"ever, it uses the simplest approach, which is just separating the queries from the \\ncommands and usi\", \"ng the same database for both actions. \\n\\nThe essence of those patterns, and the important point here\", \", is that queries are idempotent: no matter \\nhow many times you query a system, the state of that sy\", \"stem won\\u2019t change. In other words, queries \\nare side-effect free. \\n\\n186 \\n\\nCHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fTherefore, you could use a differ\", \"ent \\u201creads\\u201d data model than the transactional logic \\u201cwrites\\u201d domain \\nmodel, even though the ordering\", \" microservices are using the same database. Hence, this is a \\nsimplified CQRS approach. \\n\\nOn the oth\", \"er hand, commands, which trigger transactions and data updates, change state in the \\nsystem. With co\", \"mmands, you need to be careful when dealing with complexity and ever-changing \\nbusiness rules. This \", \"is where you want to apply DDD techniques to have a better modeled system. \\n\\nThe DDD patterns presen\", \"ted in this guide should not be applied universally. They introduce \\nconstraints on your design. Tho\", \"se constraints provide benefits such as higher quality over time, \\nespecially in commands and other \", \"code that modifies system state. However, those constraints add \\ncomplexity with fewer benefits for \", \"reading and querying data. \\n\\nOne such pattern is the Aggregate pattern, which we examine more in lat\", \"er sections. Briefly, in the \\nAggregate pattern, you treat many domain objects as a single unit as a\", \" result of their relationship in \\nthe domain. You might not always gain advantages from this pattern\", \" in queries; it can increase the \\ncomplexity of query logic. For read-only queries, you do not get t\", \"he advantages of treating multiple \\nobjects as a single Aggregate. You only get the complexity. \\n\\nAs\", \" shown in Figure 7-2 in the previous section, this guide suggests using DDD patterns only in the \\ntr\", \"ansactional/updates area of your microservice (that is, as triggered by commands). Queries can \\nfoll\", \"ow a simpler approach and should be separated from commands, following a CQRS approach. \\n\\nFor implem\", \"enting the \\u201cqueries side\\u201d, you can choose between many approaches, from your full-blown \\nORM like EF\", \" Core, AutoMapper projections, stored procedures, views, materialized views or a micro \\nORM. \\n\\nIn th\", \"is guide and in eShopOnContainers (specifically the ordering microservice) we chose to \\nimplement st\", \"raight queries using a micro ORM like Dapper. This guide lets you implement any query \\nbased on SQL \", \"statements to get the best performance, thanks to a light framework with little \\noverhead. \\n\\nWhen yo\", \"u use this approach, any updates to your model that impact how entities are persisted to a \\nSQL data\", \"base also need separate updates to SQL queries used by Dapper or any other separate (non-\\nEF) approa\", \"ches to querying. \\n\\nCQRS and DDD patterns are not top-level architectures \\n\\nIt\\u2019s important to unders\", \"tand that CQRS and most DDD patterns (like DDD layers or a domain model \\nwith aggregates) are not ar\", \"chitectural styles, but only architecture patterns. Microservices, SOA, and \\nevent-driven architectu\", \"re (EDA) are examples of architectural styles. They describe a system of many \\ncomponents, such as m\", \"any microservices. CQRS and DDD patterns describe something inside a single \\nsystem or component; in\", \" this case, something inside a microservice. \\n\\nDifferent Bounded Contexts (BCs) will employ differen\", \"t patterns. They have different responsibilities, \\nand that leads to different solutions. It is wort\", \"h emphasizing that forcing the same pattern everywhere \\nleads to failure. Do not use CQRS and DDD pa\", \"tterns everywhere. Many subsystems, BCs, or \\nmicroservices are simpler and can be implemented more e\", \"asily using simple CRUD services or using \\nanother approach. \\n\\n187 \\n\\nCHAPTER 6 | Tackle Business Com\", \"plexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fThere is only one application architectu\", \"re: the architecture of the system or end-to-end application \\nyou are designing (for example, the mi\", \"croservices architecture). However, the design of each Bounded \\nContext or microservice within that \", \"application reflects its own tradeoffs and internal design decisions \\nat an architecture patterns le\", \"vel. Do not try to apply the same architectural patterns as CQRS or DDD \\neverywhere. \\n\\nAdditional re\", \"sources \\n\\n\\u2022  Martin Fowler. CQRS \\n\\nhttps://martinfowler.com/bliki/CQRS.html \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nGreg Young. CQ\", \"RS Documents \\nhttps://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf \\n\\nUdi Dahan. Clarified CQR\", \"S \\nhttps://udidahan.com/2009/12/09/clarified-cqrs/ \\n\\nImplement reads/queries in a CQRS microservice \", \"\\n\\nFor reads/queries, the ordering microservice from the eShopOnContainers reference application \\nimp\", \"lements the queries independently from the DDD model and transactional area. This \\nimplementation wa\", \"s done primarily because the demands for queries and for transactions are \\ndrastically different. Wr\", \"ites execute transactions that must be compliant with the domain logic. \\nQueries, on the other hand,\", \" are idempotent and can be segregated from the domain rules. \\n\\nThe approach is simple, as shown in F\", \"igure 7-3. The API interface is implemented by the Web API \\ncontrollers using any infrastructure, su\", \"ch as a micro Object Relational Mapper (ORM) like Dapper, and \\nreturning dynamic ViewModels dependin\", \"g on the needs of the UI applications. \\n\\nFigure 7-3. The simplest approach for queries in a CQRS mic\", \"roservice \\n\\nThe simplest approach for the queries-side in a simplified CQRS approach can be implemen\", \"ted by \\nquerying the database with a Micro-ORM like Dapper, returning dynamic ViewModels. The query \", \"\\n\\n188 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\", \"\\fdefinitions query the database and return a dynamic ViewModel built on the fly for each query. Sinc\", \"e \\nthe queries are idempotent, they won\\u2019t change the data no matter how many times you run a query. \", \"\\nTherefore, you don\\u2019t need to be restricted by any DDD pattern used in the transactional side, like \", \"\\naggregates and other patterns, and that is why queries are separated from the transactional area. Y\", \"ou \\nquery the database for the data that the UI needs and return a dynamic ViewModel that does not \\n\", \"need to be statically defined anywhere (no classes for the ViewModels) except in the SQL statements \", \"\\nthemselves. \\n\\nSince this approach is simple, the code required for the queries side (such as code u\", \"sing a micro ORM \\nlike Dapper) can be implemented within the same Web API project. Figure 7-4 shows \", \"this approach. \\nThe queries are defined in the Ordering.API microservice project within the eShopOnC\", \"ontainers \\nsolution. \\n\\nFigure 7-4. Queries in the Ordering microservice in eShopOnContainers \\n\\nUse V\", \"iewModels specifically made for client apps, independent from \\ndomain model constraints \\n\\nSince the \", \"queries are performed to obtain the data needed by the client applications, the returned \\ntype can b\", \"e specifically made for the clients, based on the data returned by the queries. These models, \\nor Da\", \"ta Transfer Objects (DTOs), are called ViewModels. \\n\\nThe returned data (ViewModel) can be the result\", \" of joining data from multiple entities or tables in the \\ndatabase, or even across multiple aggregat\", \"es defined in the domain model for the transactional area. \\nIn this case, because you are creating q\", \"ueries independent of the domain model, the aggregates \\nboundaries and constraints are ignored and y\", \"ou\\u2019re free to query any table and column you might \\nneed. This approach provides great flexibility a\", \"nd productivity for the developers creating or updating \\nthe queries. \\n\\nThe ViewModels can be static\", \" types defined in classes (as is implemented in the ordering \\nmicroservice). Or they can be created \", \"dynamically based on the queries performed, which is agile for \\ndevelopers. \\n\\nUse Dapper as a micro \", \"ORM to perform queries \\n\\nYou can use any micro ORM, Entity Framework Core, or even plain ADO.NET for\", \" querying. In the \\nsample application, Dapper was selected for the ordering microservice in eShopOnC\", \"ontainers as a \\ngood example of a popular micro ORM. It can run plain SQL queries with great perform\", \"ance, because \\nit\\u2019s a light framework. Using Dapper, you can write a SQL query that can access and j\", \"oin multiple \\ntables. \\n\\n189 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and \", \"CQRS Patterns \\n\\n \\n \\n \\n\\fDapper is an open-source project (original created by Sam Saffron), and is pa\", \"rt of the building blocks \\nused in Stack Overflow. To use Dapper, you just need to install it throug\", \"h the Dapper NuGet package, \\nas shown in the following figure: \\n\\nYou also need to add a using direct\", \"ive so your code has access to the Dapper extension methods. \\n\\nWhen you use Dapper in your code, you\", \" directly use the SqlConnection class available in the \\nMicrosoft.Data.SqlClient namespace. Through \", \"the QueryAsync method and other extension methods \\nthat extend the SqlConnection class, you can run \", \"queries in a straightforward and performant way. \\n\\nDynamic versus static ViewModels \\n\\nWhen returning\", \" ViewModels from the server-side to client apps, you can think about those \\nViewModels as DTOs (Data\", \" Transfer Objects) that can be different to the internal domain entities of \\nyour entity model becau\", \"se the ViewModels hold the data the way the client app needs. Therefore, in \\nmany cases, you can agg\", \"regate data coming from multiple domain entities and compose the \\nViewModels precisely according to \", \"how the client app needs that data. \\n\\nThose ViewModels or DTOs can be defined explicitly (as data ho\", \"lder classes), like the OrderSummary \\nclass shown in a later code snippet. Or, you could just return\", \" dynamic ViewModels or dynamic DTOs \\nbased on the attributes returned by your queries as a dynamic t\", \"ype. \\n\\nViewModel as dynamic type \\n\\nAs shown in the following code, a ViewModel can be directly retur\", \"ned by the queries by just returning \\na dynamic type that internally is based on the attributes retu\", \"rned by a query. That means that the \\nsubset of attributes to be returned is based on the query itse\", \"lf. Therefore, if you add a new column to \\nthe query or join, that data is dynamically added to the \", \"returned ViewModel. \\n\\nusing Dapper; \\nusing Microsoft.Extensions.Configuration; \\nusing System.Data.Sq\", \"lClient; \\nusing System.Threading.Tasks; \\nusing System.Dynamic; \\nusing System.Collections.Generic; \\n\\n\", \"public class OrderQueries : IOrderQueries \\n{ \\n    public async Task<IEnumerable<dynamic>> GetOrdersA\", \"sync() \\n    { \\n        using (var connection = new SqlConnection(_connectionString)) \\n        { \\n   \", \"         connection.Open(); \\n            return await connection.QueryAsync<dynamic>( \\n             \", \"   @\\\"SELECT o.[Id] as ordernumber, \\n                o.[OrderDate] as [date],os.[Name] as [status], \\n\", \"                SUM(oi.units*oi.unitprice) as total \\n                FROM [ordering].[Orders] o \\n   \", \"             LEFT JOIN[ordering].[orderitems] oi ON o.Id = oi.orderid \\n                LEFT JOIN[ord\", \"ering].[orderstatus] os on o.OrderStatusId = os.Id \\n\\n190 \\n\\nCHAPTER 6 | Tackle Business Complexity in\", \" a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\f                GROUP BY o.[Id], o.[OrderDate]\", \", os.[Name]\\\"); \\n        } \\n    } \\n} \\n\\nThe important point is that by using a dynamic type, the retur\", \"ned collection of data is dynamically \\nassembled as the ViewModel. \\n\\nPros: This approach reduces the\", \" need to modify static ViewModel classes whenever you update the \\nSQL sentence of a query, making th\", \"is design approach agile when coding, straightforward, and quick \\nto evolve in regard to future chan\", \"ges. \\n\\nCons: In the long term, dynamic types can negatively impact the clarity and the compatibility\", \" of a \\nservice with client apps. In addition, middleware software like Swashbuckle cannot provide th\", \"e same \\nlevel of documentation on returned types if using dynamic types. \\n\\nViewModel as predefined D\", \"TO classes \\n\\nPros: Having static, predefined ViewModel classes, like \\u201ccontracts\\u201d based on explicit D\", \"TO classes, is \\ndefinitely better for public APIs but also for long-term microservices, even if they\", \" are only used by the \\nsame application. \\n\\nIf you want to specify response types for Swagger, you ne\", \"ed to use explicit DTO classes as the return \\ntype. Therefore, predefined DTO classes allow you to o\", \"ffer richer information from Swagger. That \\nimproves the API documentation and compatibility when co\", \"nsuming an API. \\n\\nCons: As mentioned earlier, when updating the code, it takes some more steps to up\", \"date the DTO \\nclasses. \\n\\nTip based on our experience: In the queries implemented at the Ordering mic\", \"roservice in \\neShopOnContainers, we started developing by using dynamic ViewModels as it was straigh\", \"tforward \\nand agile on the early development stages. But, once the development was stabilized, we ch\", \"ose to \\nrefactor the APIs and use static or pre-defined DTOs for the ViewModels, because it is clear\", \"er for the \\nmicroservice\\u2019s consumers to know explicit DTO types, used as \\u201ccontracts\\u201d. \\n\\nIn the follo\", \"wing example, you can see how the query is returning data by using an explicit ViewModel \\nDTO class:\", \" the OrderSummary class. \\n\\nusing Dapper; \\nusing Microsoft.Extensions.Configuration; \\nusing System.Da\", \"ta.SqlClient; \\nusing System.Threading.Tasks; \\nusing System.Dynamic; \\nusing System.Collections.Generi\", \"c; \\n\\npublic class OrderQueries : IOrderQueries \\n{ \\n  public async Task<IEnumerable<OrderSummary>> Ge\", \"tOrdersAsync() \\n    { \\n        using (var connection = new SqlConnection(_connectionString)) \\n      \", \"  { \\n            connection.Open(); \\n            return await connection.QueryAsync<OrderSummary>( \\n\", \"                  @\\\"SELECT o.[Id] as ordernumber, \\n                  o.[OrderDate] as [date],os.[Nam\", \"e] as [status], \\n\\n191 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS P\", \"atterns \\n\\n \\n \\n \\n\\f                  SUM(oi.units*oi.unitprice) as total \\n                  FROM [orde\", \"ring].[Orders] o \\n                  LEFT JOIN[ordering].[orderitems] oi ON  o.Id = oi.orderid \\n     \", \"             LEFT JOIN[ordering].[orderstatus] os on o.OrderStatusId = os.Id \\n                  GROU\", \"P BY o.[Id], o.[OrderDate], os.[Name] \\n                  ORDER BY o.[Id]\\\"); \\n        } \\n    } \\n} \\n\\nD\", \"escribe response types of Web APIs \\n\\nDevelopers consuming web APIs and microservices are most concer\", \"ned with what is returned\\u2014\\nspecifically response types and error codes (if not standard). The respon\", \"se types are handled in the \\nXML comments and data annotations. \\n\\nWithout proper documentation in th\", \"e Swagger UI, the consumer lacks knowledge of what types are \\nbeing returned or what HTTP codes can \", \"be returned. That problem is fixed by adding the \\nMicrosoft.AspNetCore.Mvc.ProducesResponseTypeAttri\", \"bute, so Swashbuckle can generate richer \\ninformation about the API return model and values, as show\", \"n in the following code: \\n\\nnamespace Microsoft.eShopOnContainers.Services.Ordering.API.Controllers \\n\", \"{ \\n    [Route(\\\"api/v1/[controller]\\\")] \\n    [Authorize] \\n    public class OrdersController : Controll\", \"er \\n    { \\n        //Additional code... \\n        [Route(\\\"\\\")] \\n        [HttpGet] \\n        [ProducesRe\", \"sponseType(typeof(IEnumerable<OrderSummary>), \\n            (int)HttpStatusCode.OK)] \\n        public \", \"async Task<IActionResult> GetOrders() \\n        { \\n            var userid = _identityService.GetUserI\", \"dentity(); \\n            var orders = await _orderQueries \\n                .GetOrdersFromUserAsync(Gu\", \"id.Parse(userid)); \\n            return Ok(orders); \\n        } \\n    } \\n} \\n\\nHowever, the ProducesRespo\", \"nseType attribute cannot use dynamic as a type but requires to use \\nexplicit types, like the OrderSu\", \"mmary ViewModel DTO, shown in the following example: \\n\\npublic class OrderSummary \\n{ \\n    public int \", \"ordernumber { get; set; } \\n    public DateTime date { get; set; } \\n    public string status { get; s\", \"et; } \\n    public double total { get; set; } \\n} \\n// or using C# 8 record types: \\npublic record Order\", \"Summary(int ordernumber, DateTime date, string status, double total); \\n\\n192 \\n\\nCHAPTER 6 | Tackle Bus\", \"iness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fThis is another reason why expl\", \"icit returned types are better than dynamic types, in the long term. \\nWhen using the ProducesRespons\", \"eType attribute, you can also specify what is the expected outcome \\nregarding possible HTTP errors/c\", \"odes, like 200, 400, etc. \\n\\nIn the following image, you can see how Swagger UI shows the ResponseTyp\", \"e information. \\n\\nFigure 7-5. Swagger UI showing response types and possible HTTP status codes from a\", \" Web API \\n\\nThe image shows some example values based on the ViewModel types and the possible HTTP st\", \"atus \\ncodes that can be returned. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nDapper \\nhttps://github.com/StackE\", \"xchange/dapper-dot-net \\n\\nJulie Lerman. Data Points - Dapper, Entity Framework and Hybrid Apps (MSDN \", \"\\nmagazine article) \\n\\n193 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S Patterns \\n\\n \\n \\n \\n\\fhttps://learn.microsoft.com/archive/msdn-magazine/2016/may/data-points-dapper-en\", \"tity-\\nframework-and-hybrid-apps \\n\\n\\u2022 \\n\\nASP.NET Core Web API Help Pages using Swagger \\nhttps://learn.m\", \"icrosoft.com/aspnet/core/tutorials/web-api-help-pages-using-\\nswagger?tabs=visual-studio \\n\\n\\u2022 \\n\\nCreate\", \" record types https://learn.microsoft.com/dotnet/csharp/whats-new/tutorials/records \\n\\nDesign a DDD-o\", \"riented microservice \\n\\nDomain-driven design (DDD) advocates modeling based on the reality of busines\", \"s as relevant to your \\nuse cases. In the context of building applications, DDD talks about problems \", \"as domains. It describes \\nindependent problem areas as Bounded Contexts (each Bounded Context correl\", \"ates to a \\nmicroservice), and emphasizes a common language to talk about these problems. It also sug\", \"gests \\nmany technical concepts and patterns, like domain entities with rich models (no anemic-domain\", \" \\nmodel), value objects, aggregates, and aggregate root (or root entity) rules to support the intern\", \"al \\nimplementation. This section introduces the design and implementation of those internal patterns\", \". \\n\\nSometimes these DDD technical rules and patterns are perceived as obstacles that have a steep \\nl\", \"earning curve for implementing DDD approaches. But the important part is not the patterns \\nthemselve\", \"s, but organizing the code so it is aligned to the business problems, and using the same \\nbusiness t\", \"erms (ubiquitous language). In addition, DDD approaches should be applied only if you are \\nimplement\", \"ing complex microservices with significant business rules. Simpler responsibilities, like a \\nCRUD se\", \"rvice, can be managed with simpler approaches. \\n\\nWhere to draw the boundaries is the key task when d\", \"esigning and defining a microservice. DDD \\npatterns help you understand the complexity in the domain\", \". For the domain model for each Bounded \\nContext, you identify and define the entities, value object\", \"s, and aggregates that model your domain. \\nYou build and refine a domain model that is contained wit\", \"hin a boundary that defines your context. \\nAnd that is explicit in the form of a microservice. The c\", \"omponents within those boundaries end up \\nbeing your microservices, although in some cases a BC or b\", \"usiness microservices can be composed of \\nseveral physical services. DDD is about boundaries and so \", \"are microservices. \\n\\nKeep the microservice context boundaries relatively small \\n\\nDetermining where t\", \"o place boundaries between Bounded Contexts balances two competing goals. \\nFirst, you want to initia\", \"lly create the smallest possible microservices, although that should not be the \\nmain driver; you sh\", \"ould create a boundary around things that need cohesion. Second, you want to \\navoid chatty communica\", \"tions between microservices. These goals can contradict one another. You \\nshould balance them by dec\", \"omposing the system into as many small microservices as you can until \\nyou see communication boundar\", \"ies growing quickly with each additional attempt to separate a new \\nBounded Context. Cohesion is key\", \" within a single bounded context. \\n\\nIt is similar to the Inappropriate Intimacy code smell when impl\", \"ementing classes. If two microservices \\nneed to collaborate a lot with each other, they should proba\", \"bly be the same microservice. \\n\\n194 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patterns \\n\\n \\n \\n\\fAnother way to look at this aspect is autonomy. If a microservice must \", \"rely on another service to \\ndirectly service a request, it is not truly autonomous. \\n\\nLayers in DDD \", \"microservices \\n\\nMost enterprise applications with significant business and technical complexity are \", \"defined by \\nmultiple layers. The layers are a logical artifact, and are not related to the deploymen\", \"t of the service. \\nThey exist to help developers manage the complexity in the code. Different layers\", \" (like the domain \\nmodel layer versus the presentation layer, etc.) might have different types, whic\", \"h mandate translations \\nbetween those types. \\n\\nFor example, an entity could be loaded from the datab\", \"ase. Then part of that information, or an \\naggregation of information including additional data from\", \" other entities, can be sent to the client UI \\nthrough a REST Web API. The point here is that the do\", \"main entity is contained within the domain \\nmodel layer and should not be propagated to other areas \", \"that it does not belong to, like to the \\npresentation layer. \\n\\nAdditionally, you need to have always\", \"-valid entities (see the Designing validations in the domain \\nmodel layer section) controlled by agg\", \"regate roots (root entities). Therefore, entities should not be \\nbound to client views, because at t\", \"he UI level some data might still not be validated. This reason is \\nwhat the ViewModel is for. The V\", \"iewModel is a data model exclusively for presentation layer needs. \\nThe domain entities do not belon\", \"g directly to the ViewModel. Instead, you need to translate between \\nViewModels and domain entities \", \"and vice versa. \\n\\nWhen tackling complexity, it is important to have a domain model controlled by agg\", \"regate roots that \\nmake sure that all the invariants and rules related to that group of entities (ag\", \"gregate) are performed \\nthrough a single entry-point or gate, the aggregate root. \\n\\nFigure 7-5 shows\", \" how a layered design is implemented in the eShopOnContainers application. \\n\\n195 \\n\\nCHAPTER 6 | Tackl\", \"e Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-5. DDD layers in \", \"the ordering microservice in eShopOnContainers \\n\\nThe three layers in a DDD microservice like Orderin\", \"g. Each layer is a VS project: Application layer is \\nOrdering.API, Domain layer is Ordering.Domain a\", \"nd the Infrastructure layer is Ordering.Infrastructure. \\nYou want to design the system so that each \", \"layer communicates only with certain other layers. That \\napproach may be easier to enforce if layers\", \" are implemented as different class libraries, because you \\ncan clearly identify what dependencies a\", \"re set between libraries. For instance, the domain model layer \\nshould not take a dependency on any \", \"other layer (the domain model classes should be Plain Old Class \\nObjects, or POCO, classes). As show\", \"n in Figure 7-6, the Ordering.Domain layer library has \\ndependencies only on the .NET libraries or N\", \"uGet packages, but not on any other custom library, such \\nas data library or persistence library. \\n\\n\", \"Figure 7-6. Layers implemented as libraries allow better control of dependencies between layers \\n\\nTh\", \"e domain model layer \\n\\nEric Evans\\u2019s excellent book Domain Driven Design says the following about the\", \" domain model layer \\nand the application layer. \\n\\nDomain Model Layer: Responsible for representing c\", \"oncepts of the business, information about the \\nbusiness situation, and business rules. State that r\", \"eflects the business situation is controlled and used \\nhere, even though the technical details of st\", \"oring it are delegated to the infrastructure. This layer is \\nthe heart of business software. \\n\\n196 \\n\", \"\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\fThe \", \"domain model layer is where the business is expressed. When you implement a microservice \\ndomain mod\", \"el layer in .NET, that layer is coded as a class library with the domain entities that capture \\ndata\", \" plus behavior (methods with logic). \\n\\nFollowing the Persistence Ignorance and the Infrastructure Ig\", \"norance principles, this layer must \\ncompletely ignore data persistence details. These persistence t\", \"asks should be performed by the \\ninfrastructure layer. Therefore, this layer should not take direct \", \"dependencies on the infrastructure, \\nwhich means that an important rule is that your domain model en\", \"tity classes should be POCOs. \\n\\nDomain entities should not have any direct dependency (like deriving\", \" from a base class) on any data \\naccess infrastructure framework like Entity Framework or NHibernate\", \". Ideally, your domain entities \\nshould not derive from or implement any type defined in any infrast\", \"ructure framework. \\n\\nMost modern ORM frameworks like Entity Framework Core allow this approach, so t\", \"hat your domain \\nmodel classes are not coupled to the infrastructure. However, having POCO entities \", \"is not always \\npossible when using certain NoSQL databases and frameworks, like Actors and Reliable \", \"Collections in \\nAzure Service Fabric. \\n\\nEven when it is important to follow the Persistence Ignoranc\", \"e principle for your Domain model, you \\nshould not ignore persistence concerns. It is still importan\", \"t to understand the physical data model and \\nhow it maps to your entity object model. Otherwise you \", \"can create impossible designs. \\n\\nAlso, this aspect does not mean you can take a model designed for a\", \" relational database and directly \\nmove it to a NoSQL or document-oriented database. In some entity \", \"models, the model might fit, but \\nusually it does not. There are still constraints that your entity \", \"model must adhere to, based both on \\nthe storage technology and ORM technology. \\n\\nThe application la\", \"yer \\n\\nMoving on to the application layer, we can again cite Eric Evans\\u2019s book Domain Driven Design: \", \"\\n\\nApplication Layer: Defines the jobs the software is supposed to do and directs the expressive doma\", \"in \\nobjects to work out problems. The tasks this layer is responsible for are meaningful to the busi\", \"ness or \\nnecessary for interaction with the application layers of other systems. This layer is kept \", \"thin. It does \\nnot contain business rules or knowledge, but only coordinates tasks and delegates wor\", \"k to \\ncollaborations of domain objects in the next layer down. It does not have state reflecting the\", \" business \\nsituation, but it can have state that reflects the progress of a task for the user or the\", \" program. \\n\\nA microservice\\u2019s application layer in .NET is commonly coded as an ASP.NET Core Web API \", \"project. \\nThe project implements the microservice\\u2019s interaction, remote network access, and the exte\", \"rnal Web \\nAPIs used from the UI or client apps. It includes queries if using a CQRS approach, comman\", \"ds \\naccepted by the microservice, and even the event-driven communication between microservices \\n(in\", \"tegration events). The ASP.NET Core Web API that represents the application layer must not contain \\n\", \"business rules or domain knowledge (especially domain rules for transactions or updates); these \\nsho\", \"uld be owned by the domain model class library. The application layer must only coordinate tasks \\nan\", \"d must not hold or define any domain state (domain model). It delegates the execution of business \\nr\", \"ules to the domain model classes themselves (aggregate roots and domain entities), which will \\nultim\", \"ately update the data within those domain entities. \\n\\n197 \\n\\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fBasically, the application logic is where you imp\", \"lement all use cases that depend on a given front end. \\nFor example, the implementation related to a\", \" Web API service. \\n\\nThe goal is that the domain logic in the domain model layer, its invariants, the\", \" data model, and \\nrelated business rules must be completely independent from the presentation and ap\", \"plication layers. \\nMost of all, the domain model layer must not directly depend on any infrastructur\", \"e framework. \\n\\nThe infrastructure layer \\n\\nThe infrastructure layer is how the data that is initially\", \" held in domain entities (in memory) is persisted \\nin databases or another persistent store. An exam\", \"ple is using Entity Framework Core code to \\nimplement the Repository pattern classes that use a DBCo\", \"ntext to persist data in a relational \\ndatabase. \\n\\nIn accordance with the previously mentioned Persi\", \"stence Ignorance and Infrastructure Ignorance \\nprinciples, the infrastructure layer must not \\u201ccontam\", \"inate\\u201d the domain model layer. You must keep the \\ndomain model entity classes agnostic from the infr\", \"astructure that you use to persist data (EF or any \\nother framework) by not taking hard dependencies\", \" on frameworks. Your domain model layer class \\nlibrary should have only your domain code, just POCO \", \"entity classes implementing the heart of your \\nsoftware and completely decoupled from infrastructure\", \" technologies. \\n\\nThus, your layers or class libraries and projects should ultimately depend on your \", \"domain model layer \\n(library), not vice versa, as shown in Figure 7-7. \\n\\nFigure 7-7. Dependencies be\", \"tween layers in DDD \\n\\nDependencies in a DDD Service, the Application layer depends on Domain and Inf\", \"rastructure, and \\nInfrastructure depends on Domain, but Domain doesn\\u2019t depend on any layer. This lay\", \"er design should \\nbe independent for each microservice. As noted earlier, you can implement the most\", \" complex \\nmicroservices following DDD patterns, while implementing simpler data-driven microservices\", \" (simple \\nCRUD in a single layer) in a simpler way. \\n\\n198 \\n\\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nDevIQ. Persi\", \"stence Ignorance principle \\nhttps://deviq.com/persistence-ignorance/ \\n\\nOren Eini. Infrastructure Ign\", \"orance \\nhttps://ayende.com/blog/3137/infrastructure-ignorance \\n\\nAngel Lopez. Layered Architecture In\", \" Domain-Driven Design \\nhttps://ajlopez.wordpress.com/2008/09/12/layered-architecture-in-domain-drive\", \"n-design/ \\n\\nDesign a microservice domain model \\n\\nDefine one rich domain model for each business micr\", \"oservice or Bounded Context. \\n\\nYour goal is to create a single cohesive domain model for each busine\", \"ss microservice or Bounded \\nContext (BC). Keep in mind, however, that a BC or business microservice \", \"could sometimes be \\ncomposed of several physical services that share a single domain model. The doma\", \"in model must \\ncapture the rules, behavior, business language, and constraints of the single Bounded\", \" Context or \\nbusiness microservice that it represents. \\n\\nThe Domain Entity pattern \\n\\nEntities repres\", \"ent domain objects and are primarily defined by their identity, continuity, and \\npersistence over ti\", \"me, and not only by the attributes that comprise them. As Eric Evans says, \\u201can \\nobject primarily def\", \"ined by its identity is called an Entity.\\u201d Entities are very important in the domain \\nmodel, since t\", \"hey are the base for a model. Therefore, you should identify and design them carefully. \\n\\nAn entity\\u2019\", \"s identity can cross multiple microservices or Bounded Contexts. \\n\\nThe same identity (that is, the s\", \"ame Id value, although perhaps not the same domain entity) can be \\nmodeled across multiple Bounded C\", \"ontexts or microservices. However, that does not imply that the \\nsame entity, with the same attribut\", \"es and logic would be implemented in multiple Bounded Contexts. \\nInstead, entities in each Bounded C\", \"ontext limit their attributes and behaviors to those required in that \\nBounded Context\\u2019s domain. \\n\\nF\", \"or instance, the buyer entity might have most of a person\\u2019s attributes that are defined in the user \", \"\\nentity in the profile or identity microservice, including the identity. But the buyer entity in the\", \" ordering \\nmicroservice might have fewer attributes, because only certain buyer data is related to t\", \"he order \\nprocess. The context of each microservice or Bounded Context impacts its domain model. \\n\\nD\", \"omain entities must implement behavior in addition to implementing data attributes. \\n\\nA domain entit\", \"y in DDD must implement the domain logic or behavior related to the entity data (the \\nobject accesse\", \"d in memory). For example, as part of an order entity class you must have business logic \\nand operat\", \"ions implemented as methods for tasks such as adding an order item, data validation, and \\ntotal calc\", \"ulation. The entity\\u2019s methods take care of the invariants and rules of the entity instead of \\nhaving\", \" those rules spread across the application layer. \\n\\n199 \\n\\nCHAPTER 6 | Tackle Business Complexity in \", \"a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-8 shows a domain entity that implements no\", \"t only data attributes but operations or methods \\nwith related domain logic. \\n\\nFigure 7-8. Example o\", \"f a domain entity design implementing data plus behavior \\n\\nA domain model entity implements behavior\", \"s through methods, that is, it\\u2019s not an \\u201canemic\\u201d model. Of \\ncourse, sometimes you can have entities \", \"that do not implement any logic as part of the entity class. \\nThis can happen in child entities with\", \"in an aggregate if the child entity does not have any special logic \\nbecause most of the logic is de\", \"fined in the aggregate root. If you have a complex microservice that \\nhas logic implemented in the s\", \"ervice classes instead of in the domain entities, you could be falling \\ninto the anemic domain model\", \", explained in the following section. \\n\\nRich domain model versus anemic domain model \\n\\nIn his post A\", \"nemicDomainModel, Martin Fowler describes an anemic domain model this way: \\n\\nThe basic symptom of an\", \" Anemic Domain Model is that at first blush it looks like the real thing. There \\nare objects, many n\", \"amed after the nouns in the domain space, and these objects are connected with \\nthe rich relationshi\", \"ps and structure that true domain models have. The catch comes when you look at \\nthe behavior, and y\", \"ou realize that there is hardly any behavior on these objects, making them little \\nmore than bags of\", \" getters and setters. \\n\\nOf course, when you use an anemic domain model, those data models will be us\", \"ed from a set of \\nservice objects (traditionally named the business layer) which capture all the dom\", \"ain or business logic. \\nThe business layer sits on top of the data model and uses the data model jus\", \"t as data. \\n\\nThe anemic domain model is just a procedural style design. Anemic entity objects are no\", \"t real objects \\nbecause they lack behavior (methods). They only hold data properties and thus it is \", \"not object-\\noriented design. By putting all the behavior out into service objects (the business laye\", \"r), you \\nessentially end up with spaghetti code or transaction scripts, and therefore you lose the a\", \"dvantages \\nthat a domain model provides. \\n\\nRegardless, if your microservice or Bounded Context is ve\", \"ry simple (a CRUD service), the anemic \\ndomain model in the form of entity objects with just data pr\", \"operties might be good enough, and it \\nmight not be worth implementing more complex DDD patterns. In\", \" that case, it will be simply a \\npersistence model, because you have intentionally created an entity\", \" with only data for CRUD \\npurposes. \\n\\n200 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fThat is why microservices architectures are perfect for a multi\", \"-architectural approach depending on \\neach Bounded Context. For instance, in eShopOnContainers, the \", \"ordering microservice implements \\nDDD patterns, but the catalog microservice, which is a simple CRUD\", \" service, does not. \\n\\nSome people say that the anemic domain model is an anti-pattern. It really dep\", \"ends on what you are \\nimplementing. If the microservice you are creating is simple enough (for examp\", \"le, a CRUD service), \\nfollowing the anemic domain model it is not an anti-pattern. However, if you n\", \"eed to tackle the \\ncomplexity of a microservice\\u2019s domain that has a lot of ever-changing business ru\", \"les, the anemic \\ndomain model might be an anti-pattern for that microservice or Bounded Context. In \", \"that case, \\ndesigning it as a rich model with entities containing data plus behavior as well as impl\", \"ementing \\nadditional DDD patterns (aggregates, value objects, etc.) might have huge benefits for the\", \" long-term \\nsuccess of such a microservice. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nDevIQ. Domain Entity \\nhttps\", \"://deviq.com/entity/ \\n\\n\\u2022  Martin Fowler. The Domain Model \\n\\nhttps://martinfowler.com/eaaCatalog/doma\", \"inModel.html \\n\\n\\u2022  Martin Fowler. The Anemic Domain Model \\n\\nhttps://martinfowler.com/bliki/AnemicDoma\", \"inModel.html \\n\\nThe Value Object pattern \\n\\nAs Eric Evans has noted, \\u201cMany objects do not have concept\", \"ual identity. These objects describe \\ncertain characteristics of a thing.\\u201d \\n\\nAn entity requires an i\", \"dentity, but there are many objects in a system that do not, like the Value \\nObject pattern. A value\", \" object is an object with no conceptual identity that describes a domain aspect. \\nThese are objects \", \"that you instantiate to represent design elements that only concern you temporarily. \\nYou care about\", \" what they are, not who they are. Examples include numbers and strings, but can also \\nbe higher-leve\", \"l concepts like groups of attributes. \\n\\nSomething that is an entity in a microservice might not be a\", \"n entity in another microservice, because \\nin the second case, the Bounded Context might have a diff\", \"erent meaning. For example, an address in \\nan e-commerce application might not have an identity at a\", \"ll, since it might only represent a group of \\nattributes of the customer\\u2019s profile for a person or c\", \"ompany. In this case, the address should be \\nclassified as a value object. However, in an applicatio\", \"n for an electric power utility company, the \\ncustomer address could be important for the business d\", \"omain. Therefore, the address must have an \\nidentity so the billing system can be directly linked to\", \" the address. In that case, an address should be \\nclassified as a domain entity. \\n\\nA person with a n\", \"ame and surname is usually an entity because a person has identity, even if the \\nname and surname co\", \"incide with another set of values, such as if those names also refer to a different \\nperson. \\n\\nValue\", \" objects are hard to manage in relational databases and ORMs like Entity Framework (EF), \\nwhereas in\", \" document-oriented databases they are easier to implement and use. \\n\\n201 \\n\\nCHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fEF Core 2.0 and later versions inc\", \"lude the Owned Entities feature that makes it easier to handle value \\nobjects, as we\\u2019ll see in detai\", \"l later on. \\n\\nAdditional resources \\n\\n\\u2022  Martin Fowler. Value Object pattern \\n\\nhttps://martinfowler.c\", \"om/bliki/ValueObject.html \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nValue Object \\nhttps://deviq.com/value-object/ \\n\\nValue Object\", \"s in Test-Driven Development \\nhttps://leanpub.com/tdd-ebook/read#leanpub-auto-value-objects \\n\\nEric E\", \"vans. Domain-Driven Design: Tackling Complexity in the Heart of Software. (Book; \\nincludes a discuss\", \"ion of value objects) \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/\", \"0321125215/ \\n\\nThe Aggregate pattern \\n\\nA domain model contains clusters of different data entities an\", \"d processes that can control a \\nsignificant area of functionality, such as order fulfillment or inve\", \"ntory. A more fine-grained DDD unit is \\nthe aggregate, which describes a cluster or group of entitie\", \"s and behaviors that can be treated as a \\ncohesive unit. \\n\\nYou usually define an aggregate based on \", \"the transactions that you need. A classic example is an \\norder that also contains a list of order it\", \"ems. An order item will usually be an entity. But it will be a \\nchild entity within the order aggreg\", \"ate, which will also contain the order entity as its root entity, \\ntypically called an aggregate roo\", \"t. \\n\\nIdentifying aggregates can be hard. An aggregate is a group of objects that must be consistent \", \"\\ntogether, but you cannot just pick a group of objects and label them an aggregate. You must start \\n\", \"with a domain concept and think about the entities that are used in the most common transactions \\nre\", \"lated to that concept. Those entities that need to be transactionally consistent are what forms an \\n\", \"aggregate. Thinking about transaction operations is probably the best way to identify aggregates. \\n\\n\", \"The Aggregate Root or Root Entity pattern \\n\\nAn aggregate is composed of at least one entity: the agg\", \"regate root, also called root entity or primary \\nentity. Additionally, it can have multiple child en\", \"tities and value objects, with all entities and objects \\nworking together to implement required beha\", \"vior and transactions. \\n\\nThe purpose of an aggregate root is to ensure the consistency of the aggreg\", \"ate; it should be the only \\nentry point for updates to the aggregate through methods or operations i\", \"n the aggregate root class. \\nYou should make changes to entities within the aggregate only via the a\", \"ggregate root. It is the \\naggregate\\u2019s consistency guardian, considering all the invariants and consi\", \"stency rules you might need \\nto comply with in your aggregate. If you change a child entity or value\", \" object independently, the \\n\\n202 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS Patterns \\n\\n \\n \\n\\faggregate root cannot ensure that the aggregate is in a valid state. It wo\", \"uld be like a table with a \\nloose leg. Maintaining consistency is the main purpose of the aggregate \", \"root. \\n\\nIn Figure 7-9, you can see sample aggregates like the buyer aggregate, which contains a sing\", \"le entity \\n(the aggregate root Buyer). The order aggregate contains multiple entities and a value ob\", \"ject. \\n\\nFigure 7-9. Example of aggregates with multiple or single entities \\n\\nA DDD domain model is c\", \"omposed from aggregates, an aggregate can have just one entity or more, \\nand can include value objec\", \"ts as well. Note that the Buyer aggregate could have additional child \\nentities, depending on your d\", \"omain, as it does in the ordering microservice in the eShopOnContainers \\nreference application. Figu\", \"re 7-9 just illustrates a case in which the buyer has a single entity, as an \\nexample of an aggregat\", \"e that contains only an aggregate root. \\n\\nIn order to maintain separation of aggregates and keep cle\", \"ar boundaries between them, it is a good \\npractice in a DDD domain model to disallow direct navigati\", \"on between aggregates and only having \\nthe foreign key (FK) field, as implemented in the Ordering mi\", \"croservice domain model in \\neShopOnContainers. The Order entity only has a foreign key field for the\", \" buyer, but not an EF Core \\nnavigation property, as shown in the following code: \\n\\npublic class Orde\", \"r : Entity, IAggregateRoot \\n{ \\n    private DateTime _orderDate; \\n    public Address Address { get; p\", \"rivate set; } \\n    private int? _buyerId; // FK pointing to a different aggregate root \\n    public O\", \"rderStatus OrderStatus { get; private set; } \\n    private readonly List<OrderItem> _orderItems; \\n   \", \" public IReadOnlyCollection<OrderItem> OrderItems => _orderItems; \\n    // ... Additional code \\n} \\n\\n2\", \"03 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fId\", \"entifying and working with aggregates requires research and experience. For more information, see \\nt\", \"he following Additional resources list. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nVaughn Vern\", \"on. Effective Aggregate Design - Part I: Modeling a Single Aggregate (from \\nhttps://dddcommunity.org\", \"/) \\nhttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_1.pdf \\n\\nVaughn Vernon\", \". Effective Aggregate Design - Part II: Making Aggregates Work \\nTogether (from https://dddcommunity.\", \"org/) \\nhttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf \\n\\nVaughn Ver\", \"non. Effective Aggregate Design - Part III: Gaining Insight Through \\nDiscovery (from https://dddcomm\", \"unity.org/) \\nhttps://dddcommunity.org/wp-content/uploads/files/pdf_articles/Vernon_2011_3.pdf \\n\\nSerg\", \"ey Grybniak. DDD Tactical Design Patterns \\nhttps://www.codeproject.com/Articles/1164363/Domain-Drive\", \"n-Design-Tactical-Design-\\nPatterns-Part \\n\\nChris Richardson. Developing Transactional Microservices U\", \"sing Aggregates \\nhttps://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richards\", \"on \\n\\nDevIQ. The Aggregate pattern \\nhttps://deviq.com/aggregate-pattern/ \\n\\nImplement a microservice d\", \"omain model with .NET \\n\\nIn the previous section, the fundamental design principles and patterns for \", \"designing a domain model \\nwere explained. Now it\\u2019s time to explore possible ways to implement the do\", \"main model by using .NET \\n(plain C# code) and EF Core. Your domain model will be composed simply of \", \"your code. It will have \\njust the EF Core model requirements, but not real dependencies on EF. You s\", \"houldn\\u2019t have hard \\ndependencies or references to EF Core or any other ORM in your domain model. \\n\\nD\", \"omain model structure in a custom .NET Standard Library \\n\\nThe folder organization used for the eShop\", \"OnContainers reference application demonstrates the DDD \\nmodel for the application. You might find t\", \"hat a different folder organization more clearly \\ncommunicates the design choices made for your appl\", \"ication. As you can see in Figure 7-10, in the \\nordering domain model there are two aggregates, the \", \"order aggregate and the buyer aggregate. Each \\naggregate is a group of domain entities and value obj\", \"ects, although you could have an aggregate \\ncomposed of a single domain entity (the aggregate root o\", \"r root entity) as well. \\n\\n204 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD an\", \"d CQRS Patterns \\n\\n \\n \\n\\fFigure 7-10. Domain model structure for the ordering microservice in eShopOnC\", \"ontainers \\n\\nAdditionally, the domain model layer includes the repository contracts (interfaces) that\", \" are the \\ninfrastructure requirements of your domain model. In other words, these interfaces express\", \" what \\nrepositories and the methods the infrastructure layer must implement. It\\u2019s critical that the \", \"\\nimplementation of the repositories be placed outside of the domain model layer, in the infrastructu\", \"re \\nlayer library, so the domain model layer isn\\u2019t \\u201ccontaminated\\u201d by API or classes from infrastruct\", \"ure \\ntechnologies, like Entity Framework. \\n\\nYou can also see a SeedWork folder that contains custom \", \"base classes that you can use as a base for \\nyour domain entities and value objects, so you don\\u2019t ha\", \"ve redundant code in each domain\\u2019s object \\nclass. \\n\\nStructure aggregates in a custom .NET Standard l\", \"ibrary \\n\\nAn aggregate refers to a cluster of domain objects grouped together to match transactional \", \"\\nconsistency. Those objects could be instances of entities (one of which is the aggregate root or ro\", \"ot \\nentity) plus any additional value objects. \\n\\nTransactional consistency means that an aggregate i\", \"s guaranteed to be consistent and up to date at \\nthe end of a business action. For example, the orde\", \"r aggregate from the eShopOnContainers ordering \\nmicroservice domain model is composed as shown in F\", \"igure 7-11. \\n\\n205 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rns \\n\\n \\n \\n \\n\\fFigure 7-11. The order aggregate in Visual Studio solution \\n\\nIf you open any of the fil\", \"es in an aggregate folder, you can see how it\\u2019s marked as either a custom \\nbase class or interface, \", \"like entity or value object, as implemented in the SeedWork folder. \\n\\nImplement domain entities as P\", \"OCO classes \\n\\nYou implement a domain model in .NET by creating POCO classes that implement your doma\", \"in \\nentities. In the following example, the Order class is defined as an entity and also as an aggre\", \"gate \\nroot. Because the Order class derives from the Entity base class, it can reuse common code rel\", \"ated to \\nentities. Bear in mind that these base classes and interfaces are defined by you in the dom\", \"ain model \\nproject, so it is your code, not infrastructure code from an ORM like EF. \\n\\n// COMPATIBLE\", \" WITH ENTITY FRAMEWORK CORE 5.0 \\n// Entity is a custom base class with the ID \\npublic class Order : \", \"Entity, IAggregateRoot \\n{ \\n    private DateTime _orderDate; \\n    public Address Address { get; priva\", \"te set; } \\n    private int? _buyerId; \\n\\n    public OrderStatus OrderStatus { get; private set; } \\n  \", \"  private int _orderStatusId; \\n\\n    private string _description; \\n    private int? _paymentMethodId;\", \" \\n\\n    private readonly List<OrderItem> _orderItems; \\n    public IReadOnlyCollection<OrderItem> Orde\", \"rItems => _orderItems; \\n\\n    public Order(string userId, Address address, int cardTypeId, string car\", \"dNumber, string \\ncardSecurityNumber, \\n            string cardHolderName, DateTime cardExpiration, in\", \"t? buyerId = null, int? \\npaymentMethodId = null) \\n    { \\n        _orderItems = new List<OrderItem>()\", \"; \\n        _buyerId = buyerId; \\n        _paymentMethodId = paymentMethodId; \\n        _orderStatusId \", \"= OrderStatus.Submitted.Id; \\n        _orderDate = DateTime.UtcNow; \\n\\n206 \\n\\nCHAPTER 6 | Tackle Busine\", \"ss Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\f        Address = addres\", \"s; \\n\\n        // ...Additional code ... \\n    } \\n\\n    public void AddOrderItem(int productId, string p\", \"roductName, \\n                            decimal unitPrice, decimal discount, \\n                     \", \"       string pictureUrl, int units = 1) \\n    { \\n        //... \\n        // Domain rules/logic for ad\", \"ding the OrderItem to the order \\n        // ... \\n\\n        var orderItem = new OrderItem(productId, p\", \"roductName, unitPrice, discount, \\npictureUrl, units); \\n\\n        _orderItems.Add(orderItem); \\n\\n    } \", \"\\n    // ... \\n    // Additional methods with domain rules/logic related to the Order aggregate \\n    /\", \"/ ... \\n} \\n\\nIt\\u2019s important to note that this is a domain entity implemented as a POCO class. It doesn\", \"\\u2019t have any \\ndirect dependency on Entity Framework Core or any other infrastructure framework. This \", \"\\nimplementation is as it should be in DDD, just C# code implementing a domain model. \\n\\nIn addition, \", \"the class is decorated with an interface named IAggregateRoot. That interface is an empty \\ninterface\", \", sometimes called a marker interface, that\\u2019s used just to indicate that this entity class is also \\n\", \"an aggregate root. \\n\\nA marker interface is sometimes considered as an anti-pattern; however, it\\u2019s al\", \"so a clean way to mark \\na class, especially when that interface might be evolving. An attribute coul\", \"d be the other choice for \\nthe marker, but it\\u2019s quicker to see the base class (Entity) next to the I\", \"Aggregate interface instead of \\nputting an Aggregate attribute marker above the class. It\\u2019s a matter\", \" of preferences, in any case. \\n\\nHaving an aggregate root means that most of the code related to cons\", \"istency and business rules of \\nthe aggregate\\u2019s entities should be implemented as methods in the Orde\", \"r aggregate root class (for \\nexample, AddOrderItem when adding an OrderItem object to the aggregate)\", \". You should not create \\nor update OrderItems objects independently or directly; the AggregateRoot c\", \"lass must keep control \\nand consistency of any update operation against its child entities. \\n\\nEncaps\", \"ulate data in the Domain Entities \\n\\nA common problem in entity models is that they expose collection\", \" navigation properties as publicly \\naccessible list types. This allows any collaborator developer to\", \" manipulate the contents of these \\ncollection types, which may bypass important business rules relat\", \"ed to the collection, possibly leaving \\nthe object in an invalid state. The solution to this is to e\", \"xpose read-only access to related collections \\nand explicitly provide methods that define ways in wh\", \"ich clients can manipulate them. \\n\\nIn the previous code, note that many attributes are read-only or \", \"private and are only updatable by the \\nclass methods, so any update considers business domain invari\", \"ants and logic specified within the class \\nmethods. \\n\\n207 \\n\\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\fFor example, following DDD patterns, yo\", \"u should not do the following from any command handler \\nmethod or application layer class (actually,\", \" it should be impossible for you to do so): \\n\\n// WRONG ACCORDING TO DDD PATTERNS \\u2013 CODE AT THE APPLI\", \"CATION LAYER OR \\n// COMMAND HANDLERS \\n// Code in command handler methods or Web API controllers \\n//.\", \".. (WRONG) Some code with business logic out of the domain classes ... \\nOrderItem myNewOrderItem = n\", \"ew OrderItem(orderId, productId, productName, \\n    pictureUrl, unitPrice, discount, units); \\n\\n//... \", \"(WRONG) Accessing the OrderItems collection directly from the application layer // or \\ncommand handl\", \"ers \\nmyOrder.OrderItems.Add(myNewOrderItem); \\n//... \\n\\nIn this case, the Add method is purely an oper\", \"ation to add data, with direct access to the OrderItems \\ncollection. Therefore, most of the domain l\", \"ogic, rules, or validations related to that operation with the \\nchild entities will be spread across\", \" the application layer (command handlers and Web API controllers). \\n\\nIf you go around the aggregate \", \"root, the aggregate root cannot guarantee its invariants, its validity, or \\nits consistency. Eventua\", \"lly you\\u2019ll have spaghetti code or transactional script code. \\n\\nTo follow DDD patterns, entities must\", \" not have public setters in any entity property. Changes in an \\nentity should be driven by explicit \", \"methods with explicit ubiquitous language about the change \\nthey\\u2019re performing in the entity. \\n\\nFurt\", \"hermore, collections within the entity (like the order items) should be read-only properties (the \\nA\", \"sReadOnly method explained later). You should be able to update it only from within the aggregate \\nr\", \"oot class methods or the child entity methods. \\n\\nAs you can see in the code for the Order aggregate \", \"root, all setters should be private or at least read-\\nonly externally, so that any operation against\", \" the entity\\u2019s data or its child entities has to be performed \\nthrough methods in the entity class. T\", \"his maintains consistency in a controlled and object-oriented \\nway instead of implementing transacti\", \"onal script code. \\n\\nThe following code snippet shows the proper way to code the task of adding an Or\", \"derItem object to \\nthe Order aggregate. \\n\\n// RIGHT ACCORDING TO DDD--CODE AT THE APPLICATION LAYER O\", \"R COMMAND HANDLERS \\n// The code in command handlers or WebAPI controllers, related only to applicati\", \"on stuff \\n// There is NO code here related to OrderItem object's business logic \\nmyOrder.AddOrderIte\", \"m(productId, productName, pictureUrl, unitPrice, discount, units); \\n\\n// The code related to OrderIte\", \"m params validations or domain rules should \\n// be WITHIN the AddOrderItem method. \\n\\n//... \\n\\nIn this\", \" snippet, most of the validations or logic related to the creation of an OrderItem object will be \\nu\", \"nder the control of the Order aggregate root\\u2014in the AddOrderItem method\\u2014especially validations \\nand \", \"logic related to other elements in the aggregate. For instance, you might get the same product \\nitem\", \" as the result of multiple calls to AddOrderItem. In that method, you could examine the product \\nite\", \"ms and consolidate the same product items into a single OrderItem object with several units. \\n\\n208 \\n\", \"\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n\\fAd\", \"ditionally, if there are different discount amounts but the product ID is the same, you would likely\", \" \\napply the higher discount. This principle applies to any other domain logic for the OrderItem obje\", \"ct. \\n\\nIn addition, the new OrderItem(params) operation will also be controlled and performed by the \", \"\\nAddOrderItem method from the Order aggregate root. Therefore, most of the logic or validations \\nrel\", \"ated to that operation (especially anything that impacts the consistency between other child \\nentiti\", \"es) will be in a single place within the aggregate root. That is the ultimate purpose of the \\naggreg\", \"ate root pattern. \\n\\nWhen you use Entity Framework Core 1.1 or later, a DDD entity can be better expr\", \"essed because it \\nallows mapping to fields in addition to properties. This is useful when protecting\", \" collections of child \\nentities or value objects. With this enhancement, you can use simple private \", \"fields instead of \\nproperties and you can implement any update to the field collection in public met\", \"hods and provide \\nread-only access through the AsReadOnly method. \\n\\nIn DDD, you want to update the e\", \"ntity only through methods in the entity (or the constructor) in order \\nto control any invariant and\", \" the consistency of the data, so properties are defined only with a get \\naccessor. The properties ar\", \"e backed by private fields. Private members can only be accessed from \\nwithin the class. However, th\", \"ere is one exception: EF Core needs to set these fields as well (so it can \\nreturn the object with t\", \"he proper values). \\n\\nMap properties with only get accessors to the fields in the database table \\n\\nMa\", \"pping properties to database table columns is not a domain responsibility but part of the \\ninfrastru\", \"cture and persistence layer. We mention this here just so you\\u2019re aware of the new capabilities \\nin E\", \"F Core 1.1 or later related to how you can model entities. Additional details on this topic are \\nexp\", \"lained in the infrastructure and persistence section. \\n\\nWhen you use EF Core 1.0 or later, within th\", \"e DbContext you need to map the properties that are \\ndefined only with getters to the actual fields \", \"in the database table. This is done with the HasField \\nmethod of the PropertyBuilder class. \\n\\nMap fi\", \"elds without properties \\n\\nWith the feature in EF Core 1.1 or later to map columns to fields, it\\u2019s al\", \"so possible to not use \\nproperties. Instead, you can just map columns from a table to fields. A comm\", \"on use case for this is \\nprivate fields for an internal state that doesn\\u2019t need to be accessed from \", \"outside the entity. \\n\\nFor example, in the preceding OrderAggregate code example, there are several p\", \"rivate fields, like the \\n_paymentMethodId field, that have no related property for either a setter o\", \"r getter. That field could \\nalso be calculated within the order\\u2019s business logic and used from the o\", \"rder\\u2019s methods, but it needs \\nto be persisted in the database as well. So in EF Core (since v1.1), t\", \"here\\u2019s a way to map a field without \\na related property to a column in the database. This is also ex\", \"plained in the Infrastructure layer section \\nof this guide. \\n\\n209 \\n\\nCHAPTER 6 | Tackle Business Comp\", \"lexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nVa\", \"ughn Vernon. Modeling Aggregates with DDD and Entity Framework. Note that this is \\nnot Entity Framew\", \"ork Core. \\nhttps://kalele.io/blog-posts/modeling-aggregates-with-ddd-and-entity-framework/ \\n\\nJulie L\", \"erman. Data Points - Coding for Domain-Driven Design: Tips for Data-Focused \\nDevs \\nhttps://learn.mic\", \"rosoft.com/archive/msdn-magazine/2013/august/data-points-coding-for-\\ndomain-driven-design-tips-for-d\", \"ata-focused-devs \\n\\nUdi Dahan. How to create fully encapsulated Domain Models \\nhttps://udidahan.com/2\", \"008/02/29/how-to-create-fully-encapsulated-domain-models/ \\n\\nSteve Smith. What is the difference betw\", \"een a DTO and a POCO?  https://ardalis.com/dto-\\nor-poco/ \\n\\nSeedwork (reusable base classes and inter\", \"faces for \\nyour domain model) \\n\\nThe solution folder contains a SeedWork folder. This folder contains\", \" custom base classes that you can \\nuse as a base for your domain entities and value objects. Use the\", \"se base classes so you don\\u2019t have \\nredundant code in each domain\\u2019s object class. The folder for thes\", \"e types of classes is called SeedWork \\nand not something like Framework. It\\u2019s called SeedWork becaus\", \"e the folder contains just a small \\nsubset of reusable classes that cannot really be considered a fr\", \"amework. Seedwork is a term \\nintroduced by Michael Feathers and popularized by Martin Fowler but you\", \" could also name that \\nfolder Common, SharedKernel, or similar. \\n\\nFigure 7-12 shows the classes that\", \" form the seedwork of the domain model in the ordering \\nmicroservice. It has a few custom base class\", \"es like Entity, ValueObject, and Enumeration, plus a few \\ninterfaces. These interfaces (IRepository \", \"and IUnitOfWork) inform the infrastructure layer about what \\nneeds to be implemented. Those interfac\", \"es are also used through Dependency Injection from the \\napplication layer. \\n\\nFigure 7-12. A sample s\", \"et of domain model \\u201cseedwork\\u201d base classes and interfaces \\n\\nThis is the type of copy and paste reuse\", \" that many developers share between projects, not a formal \\nframework. You can have seedworks in any\", \" layer or library. However, if the set of classes and \\ninterfaces gets large enough, you might want \", \"to create a single class library. \\n\\n210 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice w\", \"ith DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fThe custom Entity base class \\n\\nThe following code is an example o\", \"f an Entity base class where you can place code that can be used \\nthe same way by any domain entity,\", \" such as the entity ID, equality operators, a domain event list per \\nentity, etc. \\n\\n// COMPATIBLE WI\", \"TH ENTITY FRAMEWORK CORE (1.1 and later) \\npublic abstract class Entity \\n{ \\n    int? _requestedHashCo\", \"de; \\n    int _Id; \\n    private List<INotification> _domainEvents; \\n    public virtual int Id \\n    { \", \"\\n        get \\n        { \\n            return _Id; \\n        } \\n        protected set \\n        { \\n     \", \"       _Id = value; \\n        } \\n    } \\n\\n    public List<INotification> DomainEvents => _domainEvents\", \"; \\n    public void AddDomainEvent(INotification eventItem) \\n    { \\n        _domainEvents = _domainEv\", \"ents ?? new List<INotification>(); \\n        _domainEvents.Add(eventItem); \\n    } \\n    public void Re\", \"moveDomainEvent(INotification eventItem) \\n    { \\n        if (_domainEvents is null) return; \\n       \", \" _domainEvents.Remove(eventItem); \\n    } \\n\\n    public bool IsTransient() \\n    { \\n        return this\", \".Id == default(Int32); \\n    } \\n\\n    public override bool Equals(object obj) \\n    { \\n        if (obj \", \"== null || !(obj is Entity)) \\n            return false; \\n        if (Object.ReferenceEquals(this, ob\", \"j)) \\n            return true; \\n        if (this.GetType() != obj.GetType()) \\n            return fals\", \"e; \\n        Entity item = (Entity)obj; \\n        if (item.IsTransient() || this.IsTransient()) \\n     \", \"       return false; \\n        else \\n            return item.Id == this.Id; \\n    } \\n\\n    public overr\", \"ide int GetHashCode() \\n    { \\n        if (!IsTransient()) \\n\\n211 \\n\\nCHAPTER 6 | Tackle Business Comple\", \"xity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\f        { \\n            if (!_reques\", \"tedHashCode.HasValue) \\n                _requestedHashCode = this.Id.GetHashCode() ^ 31; \\n           \", \" // XOR for random distribution. See: \\n            // https://learn.microsoft.com/archive/blogs/eric\", \"lippert/guidelines-and-rules-\\nfor-gethashcode \\n            return _requestedHashCode.Value; \\n       \", \" } \\n        else \\n            return base.GetHashCode(); \\n    } \\n    public static bool operator ==(\", \"Entity left, Entity right) \\n    { \\n        if (Object.Equals(left, null)) \\n            return (Objec\", \"t.Equals(right, null)); \\n        else \\n            return left.Equals(right); \\n    } \\n    public sta\", \"tic bool operator !=(Entity left, Entity right) \\n    { \\n        return !(left == right); \\n    } \\n} \\n\", \"\\nThe previous code using a domain event list per entity will be explained in the next sections when \", \"\\nfocusing on domain events. \\n\\nRepository contracts (interfaces) in the domain model layer \\n\\nReposito\", \"ry contracts are simply .NET interfaces that express the contract requirements of the \\nrepositories \", \"to be used for each aggregate. \\n\\nThe repositories themselves, with EF Core code or any other infrast\", \"ructure dependencies and code \\n(Linq, SQL, etc.), must not be implemented within the domain model; t\", \"he repositories should only \\nimplement the interfaces you define in the domain model. \\n\\nA pattern re\", \"lated to this practice (placing the repository interfaces in the domain model layer) is the \\nSeparat\", \"ed Interface pattern. As explained by Martin Fowler, \\u201cUse Separated Interface to define an \\ninterfac\", \"e in one package but implement it in another. This way a client that needs the dependency to \\nthe in\", \"terface can be completely unaware of the implementation.\\u201d \\n\\nFollowing the Separated Interface patter\", \"n enables the application layer (in this case, the Web API \\nproject for the microservice) to have a \", \"dependency on the requirements defined in the domain model, \\nbut not a direct dependency to the infr\", \"astructure/persistence layer. In addition, you can use \\nDependency Injection to isolate the implemen\", \"tation, which is implemented in the infrastructure/ \\npersistence layer using repositories. \\n\\nFor exa\", \"mple, the following example with the IOrderRepository interface defines what operations the \\nOrderRe\", \"pository class will need to implement at the infrastructure layer. In the current \\nimplementation of\", \" the application, the code just needs to add or update orders to the database, since \\nqueries are sp\", \"lit following the simplified CQRS approach. \\n\\n// Defined at IOrderRepository.cs \\npublic interface IO\", \"rderRepository : IRepository<Order> \\n{ \\n\\n212 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS Patterns \\n\\n \\n \\n\\f    Order Add(Order order); \\n\\n    void Update(Order order); \\n\\n\", \"    Task<Order> GetAsync(int orderId); \\n} \\n\\n// Defined at IRepository.cs (Part of the Domain Seedwor\", \"k) \\npublic interface IRepository<T> where T : IAggregateRoot \\n{ \\n    IUnitOfWork UnitOfWork { get; }\", \" \\n} \\n\\nAdditional resources \\n\\n\\u2022  Martin Fowler. Separated Interface. \\n\\nhttps://www.martinfowler.com/e\", \"aaCatalog/separatedInterface.html \\n\\nImplement value objects \\n\\nAs discussed in earlier sections about\", \" entities and aggregates, identity is fundamental for entities. \\nHowever, there are many objects and\", \" data items in a system that do not require an identity and \\nidentity tracking, such as value object\", \"s. \\n\\nA value object can reference other entities. For example, in an application that generates a ro\", \"ute that \\ndescribes how to get from one point to another, that route would be a value object. It wou\", \"ld be a \\nsnapshot of points on a specific route, but this suggested route would not have an identity\", \", even \\nthough internally it might refer to entities like City, Road, etc. \\n\\nFigure 7-13 shows the A\", \"ddress value object within the Order aggregate. \\n\\n213 \\n\\nCHAPTER 6 | Tackle Business Complexity in a \", \"Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n\\fFigure 7-13. Address value object within the Or\", \"der aggregate \\n\\nAs shown in Figure 7-13, an entity is usually composed of multiple attributes. For e\", \"xample, the Order \\nentity can be modeled as an entity with an identity and composed internally of a \", \"set of attributes such \\nas OrderId, OrderDate, OrderItems, etc. But the address, which is simply a c\", \"omplex-value composed of \\ncountry/region, street, city, etc., and has no identity in this domain, mu\", \"st be modeled and treated as a \\nvalue object. \\n\\nImportant characteristics of value objects \\n\\nThere a\", \"re two main characteristics for value objects: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThey have no identity. \\n\\nThey are immutable\", \". \\n\\nThe first characteristic was already discussed. Immutability is an important requirement. The va\", \"lues of \\na value object must be immutable once the object is created. Therefore, when the object is \", \"\\n\\n214 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\", \"\\fconstructed, you must provide the required values, but you must not allow them to change during the\", \" \\nobject\\u2019s lifetime. \\n\\nValue objects allow you to perform certain tricks for performance, thanks to \", \"their immutable nature. \\nThis is especially true in systems where there may be thousands of value ob\", \"ject instances, many of \\nwhich have the same values. Their immutable nature allows them to be reused\", \"; they can be \\ninterchangeable objects, since their values are the same and they have no identity. T\", \"his type of \\noptimization can sometimes make a difference between software that runs slowly and soft\", \"ware with \\ngood performance. Of course, all these cases depend on the application environment and de\", \"ployment \\ncontext. \\n\\nValue object implementation in C# \\n\\nIn terms of implementation, you can have a \", \"value object base class that has basic utility methods like \\nequality based on the comparison betwee\", \"n all the attributes (since a value object must not be based \\non identity) and other fundamental cha\", \"racteristics. The following example shows a value object base \\nclass used in the ordering microservi\", \"ce from eShopOnContainers. \\n\\npublic abstract class ValueObject \\n{ \\n    protected static bool EqualOp\", \"erator(ValueObject left, ValueObject right) \\n    { \\n        if (ReferenceEquals(left, null) ^ Refere\", \"nceEquals(right, null)) \\n        { \\n            return false; \\n        } \\n        return ReferenceEq\", \"uals(left, right) || left.Equals(right); \\n    } \\n\\n    protected static bool NotEqualOperator(ValueOb\", \"ject left, ValueObject right) \\n    { \\n        return !(EqualOperator(left, right)); \\n    } \\n\\n    pro\", \"tected abstract IEnumerable<object> GetEqualityComponents(); \\n\\n    public override bool Equals(objec\", \"t obj) \\n    { \\n        if (obj == null || obj.GetType() != GetType()) \\n        { \\n            return\", \" false; \\n        } \\n\\n        var other = (ValueObject)obj; \\n\\n        return this.GetEqualityComponen\", \"ts().SequenceEqual(other.GetEqualityComponents()); \\n    } \\n\\n    public override int GetHashCode() \\n \", \"   { \\n        return GetEqualityComponents() \\n            .Select(x => x != null ? x.GetHashCode() :\", \" 0) \\n            .Aggregate((x, y) => x ^ y); \\n    } \\n    // Other utility methods \\n} \\n\\n215 \\n\\nCHAPTE\", \"R 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\fThe\", \" ValueObject is an abstract class type, but in this example, it doesn\\u2019t overload the == and != \\noper\", \"ators. You could choose to do so, making comparisons delegate to the Equals override. For \\nexample, \", \"consider the following operator overloads to the ValueObject type: \\n\\npublic static bool operator ==(\", \"ValueObject one, ValueObject two) \\n{ \\n    return EqualOperator(one, two); \\n} \\n\\npublic static bool op\", \"erator !=(ValueObject one, ValueObject two) \\n{ \\n    return NotEqualOperator(one, two); \\n} \\nYou can u\", \"se this class when implementing your actual value object, as with the Address \\nvalue object shown in\", \" the following example: \\npublic class Address : ValueObject \\n{ \\n    public String Street { get; priv\", \"ate set; } \\n    public String City { get; private set; } \\n    public String State { get; private set\", \"; } \\n    public String Country { get; private set; } \\n    public String ZipCode { get; private set; \", \"} \\n\\n    public Address() { } \\n\\n    public Address(string street, string city, string state, string c\", \"ountry, string \\nzipcode) \\n    { \\n        Street = street; \\n        City = city; \\n        State = sta\", \"te; \\n        Country = country; \\n        ZipCode = zipcode; \\n    } \\n\\n    protected override IEnumera\", \"ble<object> GetEqualityComponents() \\n    { \\n        // Using a yield return statement to return each\", \" element one at a time \\n        yield return Street; \\n        yield return City; \\n        yield retu\", \"rn State; \\n        yield return Country; \\n        yield return ZipCode; \\n    } \\n} \\n\\nThis value objec\", \"t implementation of Address has no identity, and therefore no ID field is defined for it, \\neither in\", \" the Address class definition or the ValueObject class definition. \\n\\nHaving no ID field in a class t\", \"o be used by Entity Framework (EF) was not possible until EF Core 2.0, \\nwhich greatly helps to imple\", \"ment better value objects with no ID. That is precisely the explanation of \\nthe next section. \\n\\nIt c\", \"ould be argued that value objects, being immutable, should be read-only (that is, have get-only \\npro\", \"perties), and that\\u2019s indeed true. However, value objects are usually serialized and deserialized to \", \"go \\n\\n216 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \", \"\\n \\n \\n \\n \\n \\n\\fthrough message queues, and being read-only stops the deserializer from assigning values\", \", so you \\njust leave them as private set, which is read-only enough to be practical. \\n\\nValue object \", \"comparison semantics \\n\\nTwo instances of the Address type can be compared using all the following met\", \"hods: \\n\\nvar one = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); \\nvar two = new Add\", \"ress(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); \\n\\nConsole.WriteLine(EqualityComparer<Addres\", \"s>.Default.Equals(one, two)); // True \\nConsole.WriteLine(object.Equals(one, two)); // True \\nConsole.\", \"WriteLine(one.Equals(two)); // True \\nConsole.WriteLine(one == two); // True \\n\\nWhen all the values ar\", \"e the same, the comparisons are correctly evaluated as true. If you didn\\u2019t choose \\nto overload the =\", \"= and != operators, then the last comparison of one == two would evaluate as false. \\nFor more inform\", \"ation, see Overload ValueObject equality operators. \\n\\nHow to persist value objects in the database w\", \"ith EF Core 2.0 and later \\n\\nYou just saw how to define a value object in your domain model. But how \", \"can you actually persist it \\ninto the database using Entity Framework Core since it usually targets \", \"entities with identity? \\n\\nBackground and older approaches using EF Core 1.1 \\n\\nAs background, a limit\", \"ation when using EF Core 1.0 and 1.1 was that you could not use complex types \\nas defined in EF 6.x \", \"in the traditional .NET Framework. Therefore, if using EF Core 1.0 or 1.1, you \\nneeded to store your\", \" value object as an EF entity with an ID field. Then, so it looked more like a value \\nobject with no\", \" identity, you could hide its ID so you make clear that the identity of a value object is \\nnot impor\", \"tant in the domain model. You could hide that ID by using the ID as a shadow property. \\nSince that c\", \"onfiguration for hiding the ID in the model is set up in the EF infrastructure level, it would \\nbe k\", \"ind of transparent for your domain model. \\n\\nIn the initial version of eShopOnContainers (.NET Core 1\", \".1), the hidden ID needed by EF Core \\ninfrastructure was implemented in the following way in the DbC\", \"ontext level, using Fluent API at the \\ninfrastructure project. Therefore, the ID was hidden from the\", \" domain model point of view, but still \\npresent in the infrastructure. \\n\\n// Old approach with EF Cor\", \"e 1.1 \\n// Fluent API within the OrderingContext:DbContext in the Infrastructure project \\nvoid Config\", \"ureAddress(EntityTypeBuilder<Address> addressConfiguration) \\n{ \\n    addressConfiguration.ToTable(\\\"ad\", \"dress\\\", DEFAULT_SCHEMA); \\n\\n    addressConfiguration.Property<int>(\\\"Id\\\")  // Id is a shadow property \", \"\\n        .IsRequired(); \\n    addressConfiguration.HasKey(\\\"Id\\\");   // Id is a shadow property \\n} \\n\\nHo\", \"wever, the persistence of that value object into the database was performed like a regular entity in\", \" \\na different table. \\n\\n217 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and C\", \"QRS Patterns \\n\\n \\n \\n \\n \\n\\fWith EF Core 2.0 and later, there are new and better ways to persist value o\", \"bjects. \\n\\nPersist value objects as owned entity types in EF Core 2.0 and later \\n\\nEven with some gaps\", \" between the canonical value object pattern in DDD and the owned entity type in \\nEF Core, it\\u2019s curre\", \"ntly the best way to persist value objects with EF Core 2.0 and later. You can see \\nlimitations at t\", \"he end of this section. \\n\\nThe owned entity type feature was added to EF Core since version 2.0. \\n\\nAn\", \" owned entity type allows you to map types that do not have their own identity explicitly defined in\", \" \\nthe domain model and are used as properties, such as a value object, within any of your entities. \", \"An \\nowned entity type shares the same CLR type with another entity type (that is, it\\u2019s just a regula\", \"r class). \\nThe entity containing the defining navigation is the owner entity. When querying the owne\", \"r, the \\nowned types are included by default. \\n\\nJust by looking at the domain model, an owned type lo\", \"oks like it doesn\\u2019t have any identity. However, \\nunder the covers, owned types do have the identity,\", \" but the owner navigation property is part of this \\nidentity. \\n\\nThe identity of instances of owned t\", \"ypes is not completely their own. It consists of three components: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nThe identity of the\", \" owner \\n\\nThe navigation property pointing to them \\n\\nIn the case of collections of owned types, an in\", \"dependent component (supported in EF Core \\n2.2 and later). \\n\\nFor example, in the Ordering domain mod\", \"el at eShopOnContainers, as part of the Order entity, the \\nAddress value object is implemented as an\", \" owned entity type within the owner entity, which is the \\nOrder entity. Address is a type with no id\", \"entity property defined in the domain model. It is used as a \\nproperty of the Order type to specify \", \"the shipping address for a particular order. \\n\\nBy convention, a shadow primary key is created for th\", \"e owned type and it will be mapped to the same \\ntable as the owner by using table splitting. This al\", \"lows to use owned types similarly to how complex \\ntypes are used in EF6 in the traditional .NET Fram\", \"ework. \\n\\nIt is important to note that owned types are never discovered by convention in EF Core, so \", \"you have \\nto declare them explicitly. \\n\\nIn eShopOnContainers, in the OrderingContext.cs file, within\", \" the OnModelCreating() method, multiple \\ninfrastructure configurations are applied. One of them is r\", \"elated to the Order entity. \\n\\n// Part of the OrderingContext.cs class at the Ordering.Infrastructure\", \" project \\n// \\nprotected override void OnModelCreating(ModelBuilder modelBuilder) \\n{ \\n    modelBuilde\", \"r.ApplyConfiguration(new ClientRequestEntityTypeConfiguration()); \\n    modelBuilder.ApplyConfigurati\", \"on(new PaymentMethodEntityTypeConfiguration()); \\n    modelBuilder.ApplyConfiguration(new OrderEntity\", \"TypeConfiguration()); \\n    modelBuilder.ApplyConfiguration(new OrderItemEntityTypeConfiguration()); \", \"\\n    //...Additional type configurations \\n} \\n\\n218 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Micr\", \"oservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fIn the following code, the persistence infrastructure is \", \"defined for the Order entity: \\n\\n// Part of the OrderEntityTypeConfiguration.cs class \\n// \\npublic voi\", \"d Configure(EntityTypeBuilder<Order> orderConfiguration) \\n{ \\n    orderConfiguration.ToTable(\\\"orders\\\"\", \", OrderingContext.DEFAULT_SCHEMA); \\n    orderConfiguration.HasKey(o => o.Id); \\n    orderConfiguratio\", \"n.Ignore(b => b.DomainEvents); \\n    orderConfiguration.Property(o => o.Id) \\n        .ForSqlServerUse\", \"SequenceHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA); \\n\\n    //Address value object persisted as \", \"owned entity in EF Core 2.0 \\n    orderConfiguration.OwnsOne(o => o.Address); \\n\\n    orderConfiguratio\", \"n.Property<DateTime>(\\\"OrderDate\\\").IsRequired(); \\n\\n    //...Additional validations, constraints and c\", \"ode... \\n    //... \\n} \\n\\nIn the previous code, the orderConfiguration.OwnsOne(o => o.Address) method s\", \"pecifies that the \\nAddress property is an owned entity of the Order type. \\n\\nBy default, EF Core conv\", \"entions name the database columns for the properties of the owned entity \\ntype as EntityProperty_Own\", \"edEntityProperty. Therefore, the internal properties of Address will appear \\nin the Orders table wit\", \"h the names Address_Street, Address_City (and so on for State, Country, and \\nZipCode). \\n\\nYou can app\", \"end the Property().HasColumnName() fluent method to rename those columns. In the \\ncase where Address\", \" is a public property, the mappings would be like the following: \\n\\norderConfiguration.OwnsOne(p => p\", \".Address) \\n                            .Property(p=>p.Street).HasColumnName(\\\"ShippingStreet\\\"); \\n\\nord\", \"erConfiguration.OwnsOne(p => p.Address) \\n                            .Property(p=>p.City).HasColumnN\", \"ame(\\\"ShippingCity\\\"); \\n\\nIt\\u2019s possible to chain the OwnsOne method in a fluent mapping. In the followi\", \"ng hypothetical \\nexample, OrderDetails owns BillingAddress and ShippingAddress, which are both Addre\", \"ss types. Then \\nOrderDetails is owned by the Order type. \\n\\norderConfiguration.OwnsOne(p => p.OrderDe\", \"tails, cb => \\n    { \\n        cb.OwnsOne(c => c.BillingAddress); \\n        cb.OwnsOne(c => c.ShippingA\", \"ddress); \\n    }); \\n//... \\n//... \\npublic class Order \\n{ \\n    public int Id { get; set; } \\n    public \", \"OrderDetails OrderDetails { get; set; } \\n} \\n\\npublic class OrderDetails \\n{ \\n    public Address Billin\", \"gAddress { get; set; } \\n\\n219 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and\", \" CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\f    public Address ShippingAddress { get; set; } \\n} \\n\\npublic class A\", \"ddress \\n{ \\n    public string Street { get; set; } \\n    public string City { get; set; } \\n} \\n\\nAdditio\", \"nal details on owned entity types \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nOwned types are defined when you configure a navigat\", \"ion property to a particular type using \\nthe OwnsOne fluent API. \\n\\nThe definition of an owned type i\", \"n our metadata model is a composite of: the owner type, the \\nnavigation property, and the CLR type o\", \"f the owned type. \\n\\nThe identity (key) of an owned type instance in our stack is a composite of the \", \"identity of the \\nowner type and the definition of the owned type. \\n\\nOwned entities capabilities \\n\\n\\u2022 \", \"\\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nOwned types can reference other entities, either owned (nested owned types) or\", \" non-owned \\n(regular reference navigation properties to other entities). \\n\\nYou can map the same CLR \", \"type as different owned types in the same owner entity through \\nseparate navigation properties. \\n\\nTa\", \"ble splitting is set up by convention, but you can opt out by mapping the owned type to a \\ndifferent\", \" table using ToTable. \\n\\nEager loading is performed automatically on owned types, that is, there\\u2019s no\", \" need to call \\n.Include() on the query. \\n\\nCan be configured with attribute [Owned], using EF Core 2.\", \"1 and later. \\n\\nCan handle collections of owned types (using version 2.2 and later). \\n\\nOwned entities\", \" limitations \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nYou can\\u2019t create a DbSet<T> of an owned type (by design). \\n\\nYou can\\u2019t\", \" call ModelBuilder.Entity<T>() on owned types (currently by design). \\n\\nNo support for optional (that\", \" is, nullable) owned types that are mapped with the owner in the \\nsame table (that is, using table s\", \"plitting). This is because mapping is done for each property, \\nthere is no separate sentinel for the\", \" null complex value as a whole. \\n\\nNo inheritance-mapping support for owned types, but you should be \", \"able to map two leaf \\ntypes of the same inheritance hierarchies as different owned types. EF Core wi\", \"ll not reason \\nabout the fact that they are part of the same hierarchy. \\n\\n220 \\n\\nCHAPTER 6 | Tackle B\", \"usiness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fMain differences with EF6\\u2019s\", \" complex types \\n\\n\\u2022 \\n\\nTable splitting is optional, that is, they can optionally be mapped to a separa\", \"te table and still \\nbe owned types. \\n\\nAdditional resources \\n\\n\\u2022  Martin Fowler. ValueObject pattern \\n\", \"\\nhttps://martinfowler.com/bliki/ValueObject.html \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEric Evans. Domai\", \"n-Driven Design: Tackling Complexity in the Heart of Software. (Book; \\nincludes a discussion of valu\", \"e objects) \\nhttps://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/\", \" \\n\\nVaughn Vernon. Implementing Domain-Driven Design. (Book; includes a discussion of \\nvalue objects)\", \" \\nhttps://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-\\nVernon/dp/0321834577/ \\n\\nOwned Ent\", \"ity Types \\nhttps://learn.microsoft.com/ef/core/modeling/owned-entities \\n\\nShadow Properties \\nhttps://\", \"learn.microsoft.com/ef/core/modeling/shadow-properties \\n\\nComplex types and/or value objects. Discuss\", \"ion in the EF Core GitHub repo (Issues tab) \\nhttps://github.com/dotnet/efcore/issues/246 \\n\\nValueObje\", \"ct.cs. Base value object class in eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/eShopO\", \"nContainers/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\\nk/ValueObject.cs \\n\\nValueObject.cs\", \". Base value object class in CSharpFunctionalExtensions. \\nhttps://github.com/vkhorikov/CSharpFunctio\", \"nalExtensions/blob/master/CSharpFunctionalExte\\nnsions/ValueObject/ValueObject.cs \\n\\nAddress class. Sa\", \"mple value object class in eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/eShopOnContai\", \"ners/blob/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesModel/OrderAggregate/Address.cs \\n\\nUse\", \" enumeration classes instead of enum types \\n\\nEnumerations (or enum types for short) are a thin langu\", \"age wrapper around an integral type. You \\nmight want to limit their use to when you are storing one \", \"value from a closed set of values. \\nClassification based on sizes (small, medium, large) is a good e\", \"xample. Using enums for control flow \\nor more robust abstractions can be a code smell. This type of \", \"usage leads to fragile code with many \\ncontrol flow statements checking values of the enum. \\n\\n221 \\n\\n\", \"CHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fInstead, \", \"you can create Enumeration classes that enable all the rich features of an object-oriented \\nlanguage\", \". \\n\\nHowever, this isn\\u2019t a critical topic and in many cases, for simplicity, you can still use regula\", \"r enum \\ntypes if that\\u2019s your preference. The use of enumeration classes is more related to business-\", \"related \\nconcepts. \\n\\nImplement an Enumeration base class \\n\\nThe ordering microservice in eShopOnConta\", \"iners provides a sample Enumeration base class \\nimplementation, as shown in the following example: \\n\", \"\\npublic abstract class Enumeration : IComparable \\n{ \\n    public string Name { get; private set; } \\n\\n\", \"    public int Id { get; private set; } \\n\\n    protected Enumeration(int id, string name) => (Id, Nam\", \"e) = (id, name); \\n\\n    public override string ToString() => Name; \\n\\n    public static IEnumerable<T>\", \" GetAll<T>() where T : Enumeration => \\n        typeof(T).GetFields(BindingFlags.Public | \\n          \", \"                  BindingFlags.Static | \\n                            BindingFlags.DeclaredOnly) \\n   \", \"              .Select(f => f.GetValue(null)) \\n                 .Cast<T>(); \\n\\n    public override boo\", \"l Equals(object obj) \\n    { \\n        if (obj is not Enumeration otherValue) \\n        { \\n            \", \"return false; \\n        } \\n\\n        var typeMatches = GetType().Equals(obj.GetType()); \\n        var v\", \"alueMatches = Id.Equals(otherValue.Id); \\n\\n        return typeMatches && valueMatches; \\n    } \\n\\n    p\", \"ublic int CompareTo(object other) => Id.CompareTo(((Enumeration)other).Id); \\n\\n    // Other utility m\", \"ethods ... \\n} \\nYou can use this class as a type in any entity or value object, as for the following \", \"\\nCardType : Enumeration class: \\npublic class CardType \\n    : Enumeration \\n{ \\n    public static CardT\", \"ype Amex = new(1, nameof(Amex)); \\n    public static CardType Visa = new(2, nameof(Visa)); \\n    publi\", \"c static CardType MasterCard = new(3, nameof(MasterCard)); \\n\\n    public CardType(int id, string name\", \") \\n        : base(id, name) \\n    { \\n\\n222 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice \", \"with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\f    } \\n} \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\", \"\\u2022 \\n\\n\\u2022 \\n\\nJimmy Bogard. Enumeration classes \\nhttps://lostechies.com/jimmybogard/2008/08/12/enumeration\", \"-classes/ \\n\\nSteve Smith. Enum Alternatives in C# \\nhttps://ardalis.com/enum-alternatives-in-c \\n\\nEnume\", \"ration.cs. Base Enumeration class in eShopOnContainers \\nhttps://github.com/dotnet-\\narchitecture/eSho\", \"pOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/SeedWor\\nk/Enumeration.cs \\n\\nCardType.cs.\", \" Sample Enumeration class in eShopOnContainers. \\nhttps://github.com/dotnet-\\narchitecture/eShopOnCont\", \"ainers/blob/dev/src/Services/Ordering/Ordering.Domain/Aggregat\\nesModel/BuyerAggregate/CardType.cs \\n\\n\", \"SmartEnum. Ardalis - Classes to help produce strongly typed smarter enums in .NET. \\nhttps://www.nuge\", \"t.org/packages/Ardalis.SmartEnum/ \\n\\nDesign validations in the domain model layer \\n\\nIn DDD, validatio\", \"n rules can be thought as invariants. The main responsibility of an aggregate is to \\nenforce invaria\", \"nts across state changes for all the entities within that aggregate. \\n\\nDomain entities should always\", \" be valid entities. There are a certain number of invariants for an object \\nthat should always be tr\", \"ue. For example, an order item object always has to have a quantity that must \\nbe a positive integer\", \", plus an article name and price. Therefore, invariants enforcement is the \\nresponsibility of the do\", \"main entities (especially of the aggregate root) and an entity object should not \\nbe able to exist w\", \"ithout being valid. Invariant rules are simply expressed as contracts, and exceptions \\nor notificati\", \"ons are raised when they are violated. \\n\\nThe reasoning behind this is that many bugs occur because o\", \"bjects are in a state they should never \\nhave been in. \\n\\nLet\\u2019s propose we now have a SendUserCreatio\", \"nEmailService that takes a UserProfile \\u2026 how can we \\nrationalize in that service that Name is not nu\", \"ll? Do we check it again? Or more likely \\u2026 you just don\\u2019t \\nbother to check and \\u201chope for the best\\u201d\\u2014y\", \"ou hope that someone bothered to validate it before \\nsending it to you. Of course, using TDD one of \", \"the first tests we should be writing is that if I send a \\ncustomer with a null name that it should r\", \"aise an error. But once we start writing these kinds of tests \\nover and over again we realize \\u2026 \\u201cwha\", \"t if we never allowed name to become null? we wouldn\\u2019t have \\nall of these tests!\\u201d. \\n\\n223 \\n\\nCHAPTER 6\", \" | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fImplement validati\", \"ons in the domain model layer \\n\\nValidations are usually implemented in domain entity constructors or\", \" in methods that can update the \\nentity. There are multiple ways to implement validations, such as v\", \"erifying data and raising exceptions \\nif the validation fails. There are also more advanced patterns\", \" such as using the Specification pattern \\nfor validations, and the Notification pattern to return a \", \"collection of errors instead of returning an \\nexception for each validation as it occurs. \\n\\nValidate\", \" conditions and throw exceptions \\n\\nThe following code example shows the simplest approach to validat\", \"ion in a domain entity by raising \\nan exception. In the references table at the end of this section \", \"you can see links to more advanced \\nimplementations based on the patterns we have discussed previous\", \"ly. \\n\\npublic void SetAddress(Address address) \\n{ \\n    _shippingAddress = address?? throw new Argumen\", \"tNullException(nameof(address)); \\n} \\nA better example would demonstrate the need to ensure that eith\", \"er the internal state did \\nnot change, or that all the mutations for a method occurred. For example,\", \" the following \\nimplementation would leave the object in an invalid state: \\npublic void SetAddress(s\", \"tring line1, string line2, \\n    string city, string state, int zip) \\n{ \\n    _shippingAddress.line1 =\", \" line1 ?? throw new ... \\n    _shippingAddress.line2 = line2; \\n    _shippingAddress.city = city ?? th\", \"row new ... \\n    _shippingAddress.state = (IsValid(state) ? state : throw new \\u2026); \\n} \\n\\nIf the value \", \"of the state is invalid, the first address line and the city have already been changed. That \\nmight \", \"make the address invalid. \\n\\nA similar approach can be used in the entity\\u2019s constructor, raising an e\", \"xception to make sure that the \\nentity is valid once it is created. \\n\\nUse validation attributes in t\", \"he model based on data annotations \\n\\nData annotations, like the Required or MaxLength attributes, ca\", \"n be used to configure EF Core \\ndatabase field properties, as explained in detail in the Table mappi\", \"ng section, but they no longer work \\nfor entity validation in EF Core (neither does the IValidatable\", \"Object.Validate method), as they have \\ndone since EF 4.x in .NET Framework. \\n\\nData annotations and t\", \"he IValidatableObject interface can still be used for model validation during \\nmodel binding, prior \", \"to the controller\\u2019s actions invocation as usual, but that model is meant to be a \\nViewModel or DTO a\", \"nd that\\u2019s an MVC or API concern not a domain model concern. \\n\\nHaving made the conceptual difference \", \"clear, you can still use data annotations and \\nIValidatableObject in the entity class for validation\", \", if your actions receive an entity class object \\nparameter, which is not recommended. In that case,\", \" validation will occur upon model binding, just \\nbefore invoking the action and you can check the co\", \"ntroller\\u2019s ModelState.IsValid property to check \\n\\n224 \\n\\nCHAPTER 6 | Tackle Business Complexity in a \", \"Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fthe result, but then again, it happens in the control\", \"ler, not before persisting the entity object in the \\nDbContext, as it had done since EF 4.x. \\n\\nYou c\", \"an still implement custom validation in the entity class using data annotations and the \\nIValidatabl\", \"eObject.Validate method, by overriding the DbContext\\u2019s SaveChanges method. \\n\\nYou can see a sample im\", \"plementation for validating IValidatableObject entities in this comment on \\nGitHub. That sample does\", \"n\\u2019t do attribute-based validations, but they should be easy to implement \\nusing reflection in the sa\", \"me override. \\n\\nHowever, from a DDD point of view, the domain model is best kept lean with the use of\", \" exceptions in \\nyour entity\\u2019s behavior methods, or by implementing the Specification and Notificatio\", \"n patterns to \\nenforce validation rules. \\n\\nIt can make sense to use data annotations at the applicat\", \"ion layer in ViewModel classes (instead of \\ndomain entities) that will accept input, to allow for mo\", \"del validation within the UI layer. However, this \\nshould not be done at the exclusion of validation\", \" within the domain model. \\n\\nValidate entities by implementing the Specification pattern and the Noti\", \"fication \\npattern \\n\\nFinally, a more elaborate approach to implementing validations in the domain mod\", \"el is by \\nimplementing the Specification pattern in conjunction with the Notification pattern, as ex\", \"plained in \\nsome of the additional resources listed later. \\n\\nIt is worth mentioning that you can als\", \"o use just one of those patterns\\u2014for example, validating \\nmanually with control statements, but usin\", \"g the Notification pattern to stack and return a list of \\nvalidation errors. \\n\\nUse deferred validati\", \"on in the domain \\n\\nThere are various approaches to deal with deferred validations in the domain. In \", \"his book \\nImplementing Domain-Driven Design, Vaughn Vernon discusses these in the section on validat\", \"ion. \\n\\nTwo-step validation \\n\\nAlso consider two-step validation. Use field-level validation on your c\", \"ommand Data Transfer Objects \\n(DTOs) and domain-level validation inside your entities. You can do th\", \"is by returning a result object \\ninstead of exceptions in order to make it easier to deal with the v\", \"alidation errors. \\n\\nUsing field validation with data annotations, for example, you do not duplicate \", \"the validation \\ndefinition. The execution, though, can be both server-side and client-side in the ca\", \"se of DTOs \\n(commands and ViewModels, for instance). \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nRachel Appel. \", \"Introduction to model validation in ASP.NET Core MVC \\nhttps://learn.microsoft.com/aspnet/core/mvc/mo\", \"dels/validation \\n\\nRick Anderson. Adding validation \\nhttps://learn.microsoft.com/aspnet/core/tutorial\", \"s/first-mvc-app/validation \\n\\n225 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD\", \" and CQRS Patterns \\n\\n \\n \\n\\f\\u2022  Martin Fowler. Replacing Throwing Exceptions with Notification in Valid\", \"ations \\n\\nhttps://martinfowler.com/articles/replaceThrowWithNotification.html \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nSpeci\", \"fication and Notification Patterns \\nhttps://www.codeproject.com/Tips/790758/Specification-and-Notifi\", \"cation-Patterns \\n\\nLev Gorodinski. Validation in Domain-Driven Design (DDD) \\nhttp://gorodinski.com/bl\", \"og/2012/05/19/validation-in-domain-driven-design-ddd/ \\n\\nColin Jack. Domain Model Validation \\nhttps:/\", \"/colinjack.blogspot.com/2008/03/domain-model-validation.html \\n\\nJimmy Bogard. Validation in a DDD wor\", \"ld \\nhttps://lostechies.com/jimmybogard/2009/02/15/validation-in-a-ddd-world/ \\n\\nClient-side validatio\", \"n (validation in the presentation \\nlayers) \\n\\nEven when the source of truth is the domain model and u\", \"ltimately you must have validation at the \\ndomain model level, validation can still be handled at bo\", \"th the domain model level (server side) and \\nthe UI (client side). \\n\\nClient-side validation is a gre\", \"at convenience for users. It saves time they would otherwise spend \\nwaiting for a round trip to the \", \"server that might return validation errors. In business terms, even a few \\nfractions of seconds mult\", \"iplied hundreds of times each day adds up to a lot of time, expense, and \\nfrustration. Straightforwa\", \"rd and immediate validation enables users to work more efficiently and \\nproduce better quality input\", \" and output. \\n\\nJust as the view model and the domain model are different, view model validation and \", \"domain model \\nvalidation might be similar but serve a different purpose. If you are concerned about \", \"DRY (the Don\\u2019t \\nRepeat Yourself principle), consider that in this case code reuse might also mean co\", \"upling, and in \\nenterprise applications it is more important not to couple the server side to the cl\", \"ient side than to \\nfollow the DRY principle. \\n\\nEven when using client-side validation, you should al\", \"ways validate your commands or input DTOs in \\nserver code, because the server APIs are a possible at\", \"tack vector. Usually, doing both is your best bet \\nbecause if you have a client application, from a \", \"UX perspective, it is best to be proactive and not allow \\nthe user to enter invalid information. \\n\\nT\", \"herefore, in client-side code you typically validate the ViewModels. You could also validate the cli\", \"ent \\noutput DTOs or commands before you send them to the services. \\n\\nThe implementation of client-si\", \"de validation depends on what kind of client application you are \\nbuilding. It will be different if \", \"you are validating data in a web MVC web application with most of the \\ncode in .NET, a SPA web appli\", \"cation with that validation being coded in JavaScript or TypeScript, or a \\nmobile app coded with Xam\", \"arin and C#. \\n\\n226 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patt\", \"erns \\n\\n \\n \\n\\fAdditional resources \\n\\nValidation in Xamarin mobile apps \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nValidate Text Input a\", \"nd Show Errors \\nhttps://developer.xamarin.com/recipes/ios/standard_controls/text_field/validate_inpu\", \"t/ \\n\\nValidation Callback \\nhttps://developer.xamarin.com/samples/xamarin-forms/XAML/ValidationCallbac\", \"k/ \\n\\nValidation in ASP.NET Core apps \\n\\n\\u2022 \\n\\nRick Anderson. Adding validation \\nhttps://learn.microsoft\", \".com/aspnet/core/tutorials/first-mvc-app/validation \\n\\nValidation in SPA Web apps (Angular 2, TypeScr\", \"ipt, JavaScript, Blazor \\nWebAssembly) \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nForm Validation \\nhttps://angular.io/guide/form-valid\", \"ation \\n\\nValidation. Breeze documentation. \\nhttps://breeze.github.io/doc-js/validation.html \\n\\n\\u2022 \\n\\nASP\", \".NET Core Blazor forms and input components   \\n\\nIn summary, these are the most important concepts in\", \" regards to validation: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEntities and aggregates should enforce their own consisten\", \"cy and be \\u201calways valid\\u201d. \\nAggregate roots are responsible for multi-entity consistency within the s\", \"ame aggregate. \\n\\nIf you think that an entity needs to enter an invalid state, consider using a diffe\", \"rent object \\nmodel\\u2014for example, using a temporary DTO until you create the final domain entity. \\n\\nIf\", \" you need to create several related objects, such as an aggregate, and they are only valid \\nonce all\", \" of them have been created, consider using the Factory pattern. \\n\\nIn most of the cases, having redun\", \"dant validation in the client side is good, because the \\napplication can be proactive. \\n\\nDomain even\", \"ts: Design and implementation \\n\\nUse domain events to explicitly implement side effects of changes wi\", \"thin your domain. In other words, \\nand using DDD terminology, use domain events to explicitly implem\", \"ent side effects across multiple \\naggregates. Optionally, for better scalability and less impact in \", \"database locks, use eventual \\nconsistency between aggregates within the same domain. \\n\\n227 \\n\\nCHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fWhat is a domain\", \" event? \\n\\nAn event is something that has happened in the past. A domain event is, something that hap\", \"pened in \\nthe domain that you want other parts of the same domain (in-process) to be aware of. The n\", \"otified \\nparts usually react somehow to the events. \\n\\nAn important benefit of domain events is that \", \"side effects can be expressed explicitly. \\n\\nFor example, if you\\u2019re just using Entity Framework and t\", \"here has to be a reaction to some event, you \\nwould probably code whatever you need close to what tr\", \"iggers the event. So the rule gets coupled, \\nimplicitly, to the code, and you have to look into the \", \"code to, hopefully, realize the rule is \\nimplemented there. \\n\\nOn the other hand, using domain events\", \" makes the concept explicit, because there\\u2019s a DomainEvent \\nand at least one DomainEventHandler invo\", \"lved. \\n\\nFor example, in the eShopOnContainers application, when an order is created, the user become\", \"s a \\nbuyer, so an OrderStartedDomainEvent is raised and handled in the \\nValidateOrAddBuyerAggregateW\", \"henOrderStartedDomainEventHandler, so the underlying concept is \\nevident. \\n\\nIn short, domain events \", \"help you to express, explicitly, the domain rules, based in the ubiquitous \\nlanguage provided by the\", \" domain experts. Domain events also enable a better separation of concerns \\namong classes within the\", \" same domain. \\n\\nIt\\u2019s important to ensure that, just like a database transaction, either all the oper\", \"ations related to a \\ndomain event finish successfully or none of them do. \\n\\nDomain events are simila\", \"r to messaging-style events, with one important difference. With real \\nmessaging, message queuing, m\", \"essage brokers, or a service bus using AMQP, a message is always \\nsent asynchronously and communicat\", \"ed across processes and machines. This is useful for integrating \\nmultiple Bounded Contexts, microse\", \"rvices, or even different applications. However, with domain \\nevents, you want to raise an event fro\", \"m the domain operation you\\u2019re currently running, but you want \\nany side effects to occur within the \", \"same domain. \\n\\nThe domain events and their side effects (the actions triggered afterwards that are m\", \"anaged by event \\nhandlers) should occur almost immediately, usually in-process, and within the same \", \"domain. Thus, \\ndomain events could be synchronous or asynchronous. Integration events, however, shou\", \"ld always be \\nasynchronous. \\n\\nDomain events versus integration events \\n\\nSemantically, domain and int\", \"egration events are the same thing: notifications about something that \\njust happened. However, thei\", \"r implementation must be different. Domain events are just messages \\npushed to a domain event dispat\", \"cher, which could be implemented as an in-memory mediator based \\non an IoC container or any other me\", \"thod. \\n\\nOn the other hand, the purpose of integration events is to propagate committed transactions \", \"and \\nupdates to additional subsystems, whether they are other microservices, Bounded Contexts or eve\", \"n \\n\\n228 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\", \"\\fexternal applications. Hence, they should occur only if the entity is successfully persisted, other\", \"wise it\\u2019s \\nas if the entire operation never happened. \\n\\nAs mentioned before, integration events must\", \" be based on asynchronous communication between \\nmultiple microservices (other Bounded Contexts) or \", \"even external systems/applications. \\n\\nThus, the event bus interface needs some infrastructure that a\", \"llows inter-process and distributed \\ncommunication between potentially remote services. It can be ba\", \"sed on a commercial service bus, \\nqueues, a shared database used as a mailbox, or any other distribu\", \"ted and ideally push based \\nmessaging system. \\n\\nDomain events as a preferred way to trigger side eff\", \"ects across \\nmultiple aggregates within the same domain \\n\\nIf executing a command related to one aggr\", \"egate instance requires additional domain rules to be run \\non one or more additional aggregates, you\", \" should design and implement those side effects to be \\ntriggered by domain events. As shown in Figur\", \"e 7-14, and as one of the most important use cases, a \\ndomain event should be used to propagate stat\", \"e changes across multiple aggregates within the same \\ndomain model. \\n\\nFigure 7-14. Domain events to \", \"enforce consistency between multiple aggregates within the same domain \\n\\nFigure 7-14 shows how consi\", \"stency between aggregates is achieved by domain events. When the user \\ninitiates an order, the Order\", \" Aggregate sends an OrderStarted domain event. The OrderStarted \\ndomain event is handled by the Buye\", \"r Aggregate to create a Buyer object in the ordering \\nmicroservice, based on the original user info \", \"from the identity microservice (with information provided \\nin the CreateOrder command). \\n\\nAlternatel\", \"y, you can have the aggregate root subscribed for events raised by members of its \\naggregates (child\", \" entities). For instance, each OrderItem child entity can raise an event when the item \\nprice is hig\", \"her than a specific amount, or when the product item amount is too high. The aggregate \\nroot can the\", \"n receive those events and perform a global calculation or aggregation. \\n\\n229 \\n\\nCHAPTER 6 | Tackle B\", \"usiness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fIt\\u2019s important to understan\", \"d that this event-based communication is not implemented directly within \\nthe aggregates; you need t\", \"o implement domain event handlers. \\n\\nHandling the domain events is an application concern. The domai\", \"n model layer should only focus on \\nthe domain logic\\u2014things that a domain expert would understand, n\", \"ot application infrastructure like \\nhandlers and side-effect persistence actions using repositories.\", \" Therefore, the application layer level is \\nwhere you should have domain event handlers triggering a\", \"ctions when a domain event is raised. \\n\\nDomain events can also be used to trigger any number of appl\", \"ication actions, and what is more \\nimportant, must be open to increase that number in the future in \", \"a decoupled way. For instance, when \\nthe order is started, you might want to publish a domain event \", \"to propagate that info to other \\naggregates or even to raise application actions like notifications.\", \" \\n\\nThe key point is the open number of actions to be executed when a domain event occurs. Eventually\", \", \\nthe actions and rules in the domain and application will grow. The complexity or number of side-\\n\", \"effect actions when something happens will grow, but if your code were coupled with \\u201cglue\\u201d (that is,\", \" \\ncreating specific objects with new), then every time you needed to add a new action you would also\", \" \\nneed to change working and tested code. \\n\\nThis change could result in new bugs and this approach a\", \"lso goes against the Open/Closed principle \\nfrom SOLID. Not only that, the original class that was o\", \"rchestrating the operations would grow and \\ngrow, which goes against the Single Responsibility Princ\", \"iple (SRP). \\n\\nOn the other hand, if you use domain events, you can create a fine-grained and decoupl\", \"ed \\nimplementation by segregating responsibilities using this approach: \\n\\n1. \\n\\n2. \\n\\nSend a command (\", \"for example, CreateOrder). \\n\\nReceive the command in a command handler. \\n\\n\\u2013 \\n\\n\\u2013 \\n\\nExecute a single ag\", \"gregate\\u2019s transaction. \\n\\n(Optional) Raise domain events for side effects (for example, \\nOrderStarted\", \"DomainEvent). \\n\\n3.  Handle domain events (within the current process) that will execute an open numb\", \"er of side \\n\\neffects in multiple aggregates or application actions. For example: \\n\\n\\u2013 \\n\\n\\u2013 \\n\\n\\u2013 \\n\\nVerif\", \"y or create buyer and payment method. \\n\\nCreate and send a related integration event to the event bus\", \" to propagate states \\nacross microservices or trigger external actions like sending an email to the \", \"buyer. \\n\\nHandle other side effects. \\n\\nAs shown in Figure 7-15, starting from the same domain event, \", \"you can handle multiple actions \\nrelated to other aggregates in the domain or additional application\", \" actions you need to perform \\nacross microservices connecting with integration events and the event \", \"bus. \\n\\n230 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \", \"\\n \\n\\fFigure 7-15. Handling multiple actions per domain \\n\\nThere can be several handlers for the same d\", \"omain event in the Application Layer, one handler can \\nsolve consistency between aggregates and anot\", \"her handler can publish an integration event, so other \\nmicroservices can do something with it. The \", \"event handlers are typically in the application layer, \\nbecause you\\u2019ll use infrastructure objects li\", \"ke repositories or an application API for the microservice\\u2019s \\nbehavior. In that sense, event handler\", \"s are similar to command handlers, so both are part of the \\napplication layer. The important differe\", \"nce is that a command should be processed only once. A \\ndomain event could be processed zero or n ti\", \"mes, because it can be received by multiple receivers or \\nevent handlers with a different purpose fo\", \"r each handler. \\n\\nHaving an open number of handlers per domain event allows you to add as many domai\", \"n rules as \\nneeded, without affecting current code. For instance, implementing the following busines\", \"s rule might \\nbe as easy as adding a few event handlers (or even just one): \\n\\nWhen the total amount \", \"purchased by a customer in the store, across any number of orders, exceeds \\n$6,000, apply a 10% off \", \"discount to every new order and notify the customer with an email about that \\ndiscount for future or\", \"ders. \\n\\nImplement domain events \\n\\nIn C#, a domain event is simply a data-holding structure or class,\", \" like a DTO, with all the information \\nrelated to what just happened in the domain, as shown in the \", \"following example: \\n\\npublic class OrderStartedDomainEvent : INotification \\n{ \\n    public string User\", \"Id { get; } \\n    public string UserName { get; } \\n    public int CardTypeId { get; } \\n    public str\", \"ing CardNumber { get; } \\n    public string CardSecurityNumber { get; } \\n\\n231 \\n\\nCHAPTER 6 | Tackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\f    public string CardHolder\", \"Name { get; } \\n    public DateTime CardExpiration { get; } \\n    public Order Order { get; } \\n\\n    pu\", \"blic OrderStartedDomainEvent(Order order, string userId, string userName, \\n                         \", \"          int cardTypeId, string cardNumber, \\n                                   string cardSecurity\", \"Number, string cardHolderName, \\n                                   DateTime cardExpiration) \\n    { \\n\", \"        Order = order; \\n        UserId = userId; \\n        UserName = userName; \\n        CardTypeId =\", \" cardTypeId; \\n        CardNumber = cardNumber; \\n        CardSecurityNumber = cardSecurityNumber; \\n  \", \"      CardHolderName = cardHolderName; \\n        CardExpiration = cardExpiration; \\n    } \\n} \\n\\nThis is\", \" essentially a class that holds all the data related to the OrderStarted event. \\n\\nIn terms of the ub\", \"iquitous language of the domain, since an event is something that happened in the \\npast, the class n\", \"ame of the event should be represented as a past-tense verb, like \\nOrderStartedDomainEvent or OrderS\", \"hippedDomainEvent. That\\u2019s how the domain event is \\nimplemented in the ordering microservice in eShop\", \"OnContainers. \\n\\nAs noted earlier, an important characteristic of events is that since an event is so\", \"mething that \\nhappened in the past, it shouldn\\u2019t change. Therefore, it must be an immutable class. Y\", \"ou can see in \\nthe previous code that the properties are read-only. There\\u2019s no way to update the obj\", \"ect, you can only \\nset values when you create it. \\n\\nIt\\u2019s important to highlight here that if domain \", \"events were to be handled asynchronously, using a \\nqueue that required serializing and deserializing\", \" the event objects, the properties would have to be \\n\\u201cprivate set\\u201d instead of read-only, so the dese\", \"rializer would be able to assign the values upon \\ndequeuing. This is not an issue in the Ordering mi\", \"croservice, as the domain event pub/sub is \\nimplemented synchronously using MediatR. \\n\\nRaise domain \", \"events \\n\\nThe next question is how to raise a domain event so it reaches its related event handlers. \", \"You can use \\nmultiple approaches. \\n\\nUdi Dahan originally proposed (for example, in several related p\", \"osts, such as Domain Events \\u2013 Take 2) \\nusing a static class for managing and raising the events. Thi\", \"s might include a static class named \\nDomainEvents that would raise domain events immediately when i\", \"t\\u2019s called, using syntax like \\nDomainEvents.Raise(Event myEvent). Jimmy Bogard wrote a blog post (St\", \"rengthening your domain: \\nDomain Events) that recommends a similar approach. \\n\\nHowever, when the dom\", \"ain events class is static, it also dispatches to handlers immediately. This \\nmakes testing and debu\", \"gging more difficult, because the event handlers with side-effects logic are \\nexecuted immediately a\", \"fter the event is raised. When you\\u2019re testing and debugging, you just want to \\nfocus on what is happ\", \"ening in the current aggregate classes; you don\\u2019t want to suddenly be \\n\\n232 \\n\\nCHAPTER 6 | Tackle Bus\", \"iness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fredirected to other event han\", \"dlers for side effects related to other aggregates or application logic. \\nThis is why other approach\", \"es have evolved, as explained in the next section. \\n\\nThe deferred approach to raise and dispatch eve\", \"nts \\n\\nInstead of dispatching to a domain event handler immediately, a better approach is to add the \", \"\\ndomain events to a collection and then to dispatch those domain events right before or right after \", \"\\ncommitting the transaction (as with SaveChanges in EF). (This approach was described by Jimmy \\nBoga\", \"rd in this post A better domain events pattern.) \\n\\nDeciding if you send the domain events right befo\", \"re or right after committing the transaction is \\nimportant, since it determines whether you will inc\", \"lude the side effects as part of the same transaction \\nor in different transactions. In the latter c\", \"ase, you need to deal with eventual consistency across \\nmultiple aggregates. This topic is discussed\", \" in the next section. \\n\\nThe deferred approach is what eShopOnContainers uses. First, you add the eve\", \"nts happening in your \\nentities into a collection or list of events per entity. That list should be \", \"part of the entity object, or \\neven better, part of your base entity class, as shown in the followin\", \"g example of the Entity base class: \\n\\npublic abstract class Entity \\n{ \\n     //... \\n     private List\", \"<INotification> _domainEvents; \\n     public List<INotification> DomainEvents => _domainEvents; \\n\\n   \", \"  public void AddDomainEvent(INotification eventItem) \\n     { \\n         _domainEvents = _domainEvent\", \"s ?? new List<INotification>(); \\n         _domainEvents.Add(eventItem); \\n     } \\n\\n     public void R\", \"emoveDomainEvent(INotification eventItem) \\n     { \\n         _domainEvents?.Remove(eventItem); \\n     \", \"} \\n     //... Additional code \\n} \\n\\nWhen you want to raise an event, you just add it to the event col\", \"lection from code at any method of \\nthe aggregate-root entity. \\n\\nThe following code, part of the Ord\", \"er aggregate-root at eShopOnContainers, shows an example: \\n\\nvar orderStartedDomainEvent = new OrderS\", \"tartedDomainEvent(this, //Order object \\n                                                          ca\", \"rdTypeId, cardNumber, \\n                                                          cardSecurityNumber,\", \" \\n                                                          cardHolderName, \\n                       \", \"                                   cardExpiration); \\nthis.AddDomainEvent(orderStartedDomainEvent); \\n\", \"\\nNotice that the only thing that the AddDomainEvent method is doing is adding an event to the list. \", \"\\nNo event is dispatched yet, and no event handler is invoked yet. \\n\\n233 \\n\\nCHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\fYou actually want to dispatch t\", \"he events later on, when you commit the transaction to the database. If \\nyou are using Entity Framew\", \"ork Core, that means in the SaveChanges method of your EF DbContext, \\nas in the following code: \\n\\n//\", \" EF Core DbContext \\npublic class OrderingContext : DbContext, IUnitOfWork \\n{ \\n    // ... \\n    public\", \" async Task<bool> SaveEntitiesAsync(CancellationToken cancellationToken = \\ndefault(CancellationToken\", \")) \\n    { \\n        // Dispatch Domain Events collection. \\n        // Choices: \\n        // A) Right B\", \"EFORE committing data (EF SaveChanges) into the DB. This makes \\n        // a single transaction incl\", \"uding side effects from the domain event \\n        // handlers that are using the same DbContext with\", \" Scope lifetime \\n        // B) Right AFTER committing data (EF SaveChanges) into the DB. This makes \", \"\\n        // multiple transactions. You will need to handle eventual consistency and \\n        // comp\", \"ensatory actions in case of failures. \\n        await _mediator.DispatchDomainEventsAsync(this); \\n\\n  \", \"      // After this line runs, all the changes (from the Command Handler and Domain \\n        // even\", \"t handlers) performed through the DbContext will be committed \\n        var result = await base.SaveC\", \"hangesAsync(); \\n    } \\n} \\n\\nWith this code, you dispatch the entity events to their respective event \", \"handlers. \\n\\nThe overall result is that you\\u2019ve decoupled the raising of a domain event (a simple add \", \"into a list in \\nmemory) from dispatching it to an event handler. In addition, depending on what kind\", \" of dispatcher \\nyou are using, you could dispatch the events synchronously or asynchronously. \\n\\nBe a\", \"ware that transactional boundaries come into significant play here. If your unit of work and \\ntransa\", \"ction can span more than one aggregate (as when using EF Core and a relational database), this \\ncan \", \"work well. But if the transaction cannot span aggregates, you have to implement additional steps \\nto\", \" achieve consistency. This is another reason why persistence ignorance is not universal; it depends \", \"\\non the storage system you use. \\n\\nSingle transaction across aggregates versus eventual consistency a\", \"cross \\naggregates \\n\\nThe question of whether to perform a single transaction across aggregates versus\", \" relying on eventual \\nconsistency across those aggregates is a controversial one. Many DDD authors l\", \"ike Eric Evans and \\nVaughn Vernon advocate the rule that one transaction = one aggregate and therefo\", \"re argue for \\neventual consistency across aggregates. For example, in his book Domain-Driven Design,\", \" Eric Evans \\nsays this: \\n\\nAny rule that spans Aggregates will not be expected to be up-to-date at al\", \"l times. Through event \\nprocessing, batch processing, or other update mechanisms, other dependencies\", \" can be resolved \\nwithin some specific time. (page 128) \\n\\nVaughn Vernon says the following in Effect\", \"ive Aggregate Design. Part II: Making Aggregates Work \\nTogether: \\n\\n234 \\n\\nCHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fThus, if executing a command on on\", \"e aggregate instance requires that additional business rules \\nexecute on one or more aggregates, use\", \" eventual consistency [\\u2026] There is a practical way to support \\neventual consistency in a DDD model. \", \"An aggregate method publishes a domain event that is in time \\ndelivered to one or more asynchronous \", \"subscribers. \\n\\nThis rationale is based on embracing fine-grained transactions instead of transaction\", \"s spanning many \\naggregates or entities. The idea is that in the second case, the number of database\", \" locks will be \\nsubstantial in large-scale applications with high scalability needs. Embracing the f\", \"act that highly \\nscalable applications need not have instant transactional consistency between multi\", \"ple aggregates \\nhelps with accepting the concept of eventual consistency. Atomic changes are often n\", \"ot needed by \\nthe business, and it is in any case the responsibility of the domain experts to say wh\", \"ether particular \\noperations need atomic transactions or not. If an operation always needs an atomic\", \" transaction \\nbetween multiple aggregates, you might ask whether your aggregate should be larger or \", \"wasn\\u2019t \\ncorrectly designed. \\n\\nHowever, other developers and architects like Jimmy Bogard are okay wi\", \"th spanning a single \\ntransaction across several aggregates\\u2014but only when those additional aggregate\", \"s are related to side \\neffects for the same original command. For instance, in A better domain event\", \"s pattern, Bogard says \\nthis: \\n\\nTypically, I want the side effects of a domain event to occur within\", \" the same logical transaction, but \\nnot necessarily in the same scope of raising the domain event [\\u2026\", \"] Just before we commit our \\ntransaction, we dispatch our events to their respective handlers. \\n\\nIf \", \"you dispatch the domain events right before committing the original transaction, it is because you \\n\", \"want the side effects of those events to be included in the same transaction. For example, if the EF\", \" \\nDbContext SaveChanges method fails, the transaction will roll back all changes, including the resu\", \"lt of \\nany side effect operations implemented by the related domain event handlers. This is because \", \"the \\nDbContext life scope is by default defined as \\u201cscoped.\\u201d Therefore, the DbContext object is shar\", \"ed \\nacross multiple repository objects being instantiated within the same scope or object graph. Thi\", \"s \\ncoincides with the HttpRequest scope when developing Web API or MVC apps. \\n\\nActually, both approa\", \"ches (single atomic transaction and eventual consistency) can be right. It really \\ndepends on your d\", \"omain or business requirements and what the domain experts tell you. It also \\ndepends on how scalabl\", \"e you need the service to be (more granular transactions have less impact \\nwith regard to database l\", \"ocks). And it depends on how much investment you\\u2019re willing to make in \\nyour code, since eventual co\", \"nsistency requires more complex code in order to detect possible \\ninconsistencies across aggregates \", \"and the need to implement compensatory actions. Consider that if \\nyou commit changes to the original\", \" aggregate and afterwards, when the events are being dispatched, \\nif there\\u2019s an issue and the event \", \"handlers cannot commit their side effects, you\\u2019ll have inconsistencies \\nbetween aggregates. \\n\\nA way \", \"to allow compensatory actions would be to store the domain events in additional database \\ntables so \", \"they can be part of the original transaction. Afterwards, you could have a batch process that \\ndetec\", \"ts inconsistencies and runs compensatory actions by comparing the list of events with the \\ncurrent s\", \"tate of the aggregates. The compensatory actions are part of a complex topic that will require \\ndeep\", \" analysis from your side, which includes discussing it with the business user and domain experts. \\n\\n\", \"235 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fIn \", \"any case, you can choose the approach you need. But the initial deferred approach\\u2014raising the \\nevent\", \"s before committing, so you use a single transaction\\u2014is the simplest approach when using EF \\nCore an\", \"d a relational database. It\\u2019s easier to implement and valid in many business cases. It\\u2019s also the \\na\", \"pproach used in the ordering microservice in eShopOnContainers. \\n\\nBut how do you actually dispatch t\", \"hose events to their respective event handlers? What\\u2019s the \\n_mediator object you see in the previous\", \" example? It has to do with the techniques and artifacts you \\nuse to map between events and their ev\", \"ent handlers. \\n\\nThe domain event dispatcher: mapping from events to event handlers \\n\\nOnce you\\u2019re abl\", \"e to dispatch or publish the events, you need some kind of artifact that will publish the \\nevent, so\", \" that every related handler can get it and process side effects based on that event. \\n\\nOne approach \", \"is a real messaging system or even an event bus, possibly based on a service bus as \\nopposed to in-m\", \"emory events. However, for the first case, real messaging would be overkill for \\nprocessing domain e\", \"vents, since you just need to process those events within the same process (that \\nis, within the sam\", \"e domain and application layer). \\n\\nHow to subscribe to domain events \\n\\nWhen you use MediatR, each ev\", \"ent handler must use an event type that is provided on the generic \\nparameter of the INotificationHa\", \"ndler interface, as you can see in the following code: \\n\\npublic class ValidateOrAddBuyerAggregateWhe\", \"nOrderStartedDomainEventHandler \\n  : INotificationHandler<OrderStartedDomainEvent> \\n\\nBased on the re\", \"lationship between event and event handler, which can be considered the \\nsubscription, the MediatR a\", \"rtifact can discover all the event handlers for each event and trigger each \\none of those event hand\", \"lers. \\n\\nHow to handle domain events \\n\\nFinally, the event handler usually implements application laye\", \"r code that uses infrastructure \\nrepositories to obtain the required additional aggregates and to ex\", \"ecute side-effect domain logic. The \\nfollowing domain event handler code at eShopOnContainers, shows\", \" an implementation example. \\n\\npublic class ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHan\", \"dler \\n    : INotificationHandler<OrderStartedDomainEvent> \\n{ \\n    private readonly ILogger _logger; \", \"\\n    private readonly IBuyerRepository _buyerRepository; \\n    private readonly IOrderingIntegrationE\", \"ventService _orderingIntegrationEventService; \\n\\n    public ValidateOrAddBuyerAggregateWhenOrderStart\", \"edDomainEventHandler( \\n        ILogger<ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler\", \"> logger, \\n        IBuyerRepository buyerRepository, \\n        IOrderingIntegrationEventService order\", \"ingIntegrationEventService) \\n    { \\n        _buyerRepository = buyerRepository ?? throw new \\nArgumen\", \"tNullException(nameof(buyerRepository)); \\n        _orderingIntegrationEventService = orderingIntegra\", \"tionEventService ?? throw new \\nArgumentNullException(nameof(orderingIntegrationEventService)); \\n\\n236\", \" \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\f    \", \"    _logger = logger ?? throw new ArgumentNullException(nameof(logger)); \\n    } \\n\\n    public async T\", \"ask Handle( \\n        OrderStartedDomainEvent domainEvent, CancellationToken cancellationToken) \\n    \", \"{ \\n        var cardTypeId = domainEvent.CardTypeId != 0 ? domainEvent.CardTypeId : 1; \\n        var b\", \"uyer = await _buyerRepository.FindAsync(domainEvent.UserId); \\n        var buyerExisted = buyer is no\", \"t null; \\n\\n        if (!buyerExisted) \\n        { \\n            buyer = new Buyer(domainEvent.UserId, d\", \"omainEvent.UserName); \\n        } \\n\\n        buyer.VerifyOrAddPaymentMethod( \\n            cardTypeId, \", \"\\n            $\\\"Payment Method on {DateTime.UtcNow}\\\", \\n            domainEvent.CardNumber, \\n         \", \"   domainEvent.CardSecurityNumber, \\n            domainEvent.CardHolderName, \\n            domainEvent\", \".CardExpiration, \\n            domainEvent.Order.Id); \\n\\n        var buyerUpdated = buyerExisted ? \\n  \", \"          _buyerRepository.Update(buyer) : \\n            _buyerRepository.Add(buyer); \\n\\n        await\", \" _buyerRepository.UnitOfWork \\n            .SaveEntitiesAsync(cancellationToken); \\n\\n        var integ\", \"rationEvent = new OrderStatusChangedToSubmittedIntegrationEvent( \\n            domainEvent.Order.Id, \", \"domainEvent.Order.OrderStatus.Name, buyer.Name); \\n        await _orderingIntegrationEventService.Add\", \"AndSaveEventAsync(integrationEvent); \\n\\n        OrderingApiTrace.LogOrderBuyerAndPaymentValidatedOrUp\", \"dated( \\n            _logger, buyerUpdated.Id, domainEvent.Order.Id); \\n    } \\n} \\n\\nThe previous domain\", \" event handler code is considered application layer code because it uses \\ninfrastructure repositorie\", \"s, as explained in the next section on the infrastructure-persistence layer. \\nEvent handlers could a\", \"lso use other infrastructure components. \\n\\nDomain events can generate integration events to be publi\", \"shed outside of the \\nmicroservice boundaries \\n\\nFinally, it\\u2019s important to mention that you might som\", \"etimes want to propagate events across multiple \\nmicroservices. That propagation is an integration e\", \"vent, and it could be published through an event \\nbus from any specific domain event handler. \\n\\nConc\", \"lusions on domain events \\n\\nAs stated, use domain events to explicitly implement side effects of chan\", \"ges within your domain. To \\nuse DDD terminology, use domain events to explicitly implement side effe\", \"cts across one or multiple \\naggregates. Additionally, and for better scalability and less impact on \", \"database locks, use eventual \\nconsistency between aggregates within the same domain. \\n\\n237 \\n\\nCHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fTh\", \"e reference app uses MediatR to propagate domain events synchronously across aggregates, within \\na s\", \"ingle transaction. However, you could also use some AMQP implementation like RabbitMQ or \\nAzure Serv\", \"ice Bus to propagate domain events asynchronously, using eventual consistency but, as \\nmentioned abo\", \"ve, you have to consider the need for compensatory actions in case of failures. \\n\\nAdditional resourc\", \"es \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nGreg Young. What is a Domain Event? \\nhttps://cqrs.files.wor\", \"dpress.com/2010/11/cqrs_documents.pdf#page=25 \\n\\nJan Stenberg. Domain Events and Eventual Consistency\", \" \\nhttps://www.infoq.com/news/2015/09/domain-events-consistency \\n\\nJimmy Bogard. A better domain event\", \"s pattern \\nhttps://lostechies.com/jimmybogard/2014/05/13/a-better-domain-events-pattern/ \\n\\nVaughn Ve\", \"rnon. Effective Aggregate Design Part II: Making Aggregates Work Together \\nhttps://dddcommunity.org/\", \"wp-content/uploads/files/pdf_articles/Vernon_2011_2.pdf \\n\\nJimmy Bogard. Strengthening your domain: D\", \"omain Events \\nhttps://lostechies.com/jimmybogard/2010/04/08/strengthening-your-domain-domain-\\nevents\", \"/ \\n\\nUdi Dahan. How to create fully encapsulated Domain Models \\nhttps://udidahan.com/2008/02/29/how-t\", \"o-create-fully-encapsulated-domain-models/ \\n\\nUdi Dahan. Domain Events \\u2013 Take 2 \\nhttps://udidahan.com\", \"/2008/08/25/domain-events-take-2/ \\n\\nUdi Dahan. Domain Events \\u2013 Salvation \\nhttps://udidahan.com/2009/\", \"06/14/domain-events-salvation/ \\n\\nCesar de la Torre. Domain Events vs. Integration Events in DDD and \", \"microservices \\narchitectures \\nhttps://devblogs.microsoft.com/cesardelatorre/domain-events-vs-integra\", \"tion-events-in-\\ndomain-driven-design-and-microservices-architectures/ \\n\\nDesign the infrastructure pe\", \"rsistence layer \\n\\nData persistence components provide access to the data hosted within the boundarie\", \"s of a \\nmicroservice (that is, a microservice\\u2019s database). They contain the actual implementation of\", \" \\ncomponents such as repositories and Unit of Work classes, like custom Entity Framework (EF) \\nDbCon\", \"text objects. EF DbContext implements both the Repository and the Unit of Work patterns. \\n\\nThe Repos\", \"itory pattern \\n\\nThe Repository pattern is a Domain-Driven Design pattern intended to keep persistenc\", \"e concerns \\noutside of the system\\u2019s domain model. One or more persistence abstractions - interfaces \", \"- are defined \\n\\n238 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pat\", \"terns \\n\\n \\n \\n\\fin the domain model, and these abstractions have implementations in the form of persist\", \"ence-specific \\nadapters defined elsewhere in the application. \\n\\nRepository implementations are class\", \"es that encapsulate the logic required to access data sources. \\nThey centralize common data access f\", \"unctionality, providing better maintainability and decoupling \\nthe infrastructure or technology used\", \" to access databases from the domain model. If you use an \\nObject-Relational Mapper (ORM) like Entit\", \"y Framework, the code that must be implemented is \\nsimplified, thanks to LINQ and strong typing. Thi\", \"s lets you focus on the data persistence logic rather \\nthan on data access plumbing. \\n\\nThe Repositor\", \"y pattern is a well-documented way of working with a data source. In the book Patterns \\nof Enterpris\", \"e Application Architecture, Martin Fowler describes a repository as follows: \\n\\nA repository performs\", \" the tasks of an intermediary between the domain model layers and data \\nmapping, acting in a similar\", \" way to a set of domain objects in memory. Client objects declaratively \\nbuild queries and send them\", \" to the repositories for answers. Conceptually, a repository encapsulates a \\nset of objects stored i\", \"n the database and operations that can be performed on them, providing a way \\nthat is closer to the \", \"persistence layer. Repositories, also, support the purpose of separating, clearly \\nand in one direct\", \"ion, the dependency between the work domain and the data allocation or mapping. \\n\\nDefine one reposit\", \"ory per aggregate \\n\\nFor each aggregate or aggregate root, you should create one repository class. Yo\", \"u may be able to \\nleverage C# Generics to reduce the total number concrete classes you need to maint\", \"ain (as \\ndemonstrated later in this chapter). In a microservice based on Domain-Driven Design (DDD) \", \"patterns, \\nthe only channel you should use to update the database should be the repositories. This i\", \"s because \\nthey have a one-to-one relationship with the aggregate root, which controls the aggregate\", \"\\u2019s \\ninvariants and transactional consistency. It\\u2019s okay to query the database through other channels\", \" (as \\nyou can do following a CQRS approach), because queries don\\u2019t change the state of the database.\", \" \\nHowever, the transactional area (that is, the updates) must always be controlled by the repositori\", \"es \\nand the aggregate roots. \\n\\nBasically, a repository allows you to populate data in memory that co\", \"mes from the database in the \\nform of the domain entities. Once the entities are in memory, they can\", \" be changed and then persisted \\nback to the database through transactions. \\n\\nAs noted earlier, if yo\", \"u\\u2019re using the CQS/CQRS architectural pattern, the initial queries are performed \\nby side queries ou\", \"t of the domain model, performed by simple SQL statements using Dapper. This \\napproach is much more \", \"flexible than repositories because you can query and join any tables you \\nneed, and these queries ar\", \"en\\u2019t restricted by rules from the aggregates. That data goes to the \\npresentation layer or client ap\", \"p. \\n\\nIf the user makes changes, the data to be updated comes from the client app or presentation lay\", \"er to \\nthe application layer (such as a Web API service). When you receive a command in a command \\nh\", \"andler, you use repositories to get the data you want to update from the database. You update it in \", \"\\nmemory with the data passed with the commands, and you then add or update the data (domain \\nentitie\", \"s) in the database through a transaction. \\n\\n239 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Micros\", \"ervice with DDD and CQRS Patterns \\n\\n \\n \\n\\fIt\\u2019s important to emphasize again that you should only defi\", \"ne one repository for each aggregate root, \\nas shown in Figure 7-17. To achieve the goal of the aggr\", \"egate root to maintain transactional \\nconsistency between all the objects within the aggregate, you \", \"should never create a repository for \\neach table in the database. \\n\\nFigure 7-17. The relationship be\", \"tween repositories, aggregates, and database tables \\n\\nThe above diagram shows the relationships betw\", \"een Domain and Infrastructure layers: Buyer \\nAggregate depends on the IBuyerRepository and Order Agg\", \"regate depends on the IOrderRepository \\ninterfaces, these interfaces are implemented in the Infrastr\", \"ucture layer by the corresponding \\nrepositories that depend on UnitOfWork, also implemented there, t\", \"hat accesses the tables in the Data \\ntier. \\n\\nEnforce one aggregate root per repository \\n\\nIt can be v\", \"aluable to implement your repository design in such a way that it enforces the rule that only \\naggre\", \"gate roots should have repositories. You can create a generic or base repository type that \\nconstrai\", \"ns the type of entities it works with to ensure they have the IAggregateRoot marker interface. \\n\\nThu\", \"s, each repository class implemented at the infrastructure layer implements its own contract or \\nint\", \"erface, as shown in the following code: \\n\\nnamespace Microsoft.eShopOnContainers.Services.Ordering.In\", \"frastructure.Repositories \\n{ \\n    public class OrderRepository : IOrderRepository \\n    { \\n      // .\", \".. \\n\\n240 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \", \"\\n \\n\\f    } \\n} \\n\\nEach specific repository interface implements the generic IRepository interface: \\n\\npu\", \"blic interface IOrderRepository : IRepository<Order> \\n{ \\n    Order Add(Order order); \\n    // ... \\n} \", \"\\n\\nHowever, a better way to have the code enforce the convention that each repository is related to a\", \" \\nsingle aggregate is to implement a generic repository type. That way, it\\u2019s explicit that you\\u2019re us\", \"ing a \\nrepository to target a specific aggregate. That can be easily done by implementing a generic \", \"\\nIRepository base interface, as in the following code: \\n\\npublic interface IRepository<T> where T : I\", \"AggregateRoot \\n{ \\n    //.... \\n} \\n\\nThe Repository pattern makes it easier to test your application lo\", \"gic \\n\\nThe Repository pattern allows you to easily test your application with unit tests. Remember th\", \"at unit \\ntests only test your code, not infrastructure, so the repository abstractions make it easie\", \"r to achieve \\nthat goal. \\n\\nAs noted in an earlier section, it\\u2019s recommended that you define and plac\", \"e the repository interfaces in \\nthe domain model layer so the application layer, such as your Web AP\", \"I microservice, doesn\\u2019t depend \\ndirectly on the infrastructure layer where you\\u2019ve implemented the ac\", \"tual repository classes. By doing \\nthis and using Dependency Injection in the controllers of your We\", \"b API, you can implement mock \\nrepositories that return fake data instead of data from the database.\", \" This decoupled approach allows \\nyou to create and run unit tests that focus the logic of your appli\", \"cation without requiring connectivity \\nto the database. \\n\\nConnections to databases can fail and, mor\", \"e importantly, running hundreds of tests against a \\ndatabase is bad for two reasons. First, it can t\", \"ake a long time because of the large number of tests. \\nSecond, the database records might change and\", \" impact the results of your tests, especially if your \\ntests are running in parallel, so that they m\", \"ight not be consistent. Unit tests typically can run in \\nparallel; integration tests may not support\", \" parallel execution depending on their implementation. \\nTesting against the database isn\\u2019t a unit te\", \"st but an integration test. You should have many unit tests \\nrunning fast, but fewer integration tes\", \"ts against the databases. \\n\\nIn terms of separation of concerns for unit tests, your logic operates o\", \"n domain entities in memory. It \\nassumes the repository class has delivered those. Once your logic m\", \"odifies the domain entities, it \\nassumes the repository class will store them correctly. The importa\", \"nt point here is to create unit tests \\nagainst your domain model and its domain logic. Aggregate roo\", \"ts are the main consistency \\nboundaries in DDD. \\n\\nThe repositories implemented in eShopOnContainers \", \"rely on EF Core\\u2019s DbContext implementation of \\nthe Repository and Unit of Work patterns using its ch\", \"ange tracker, so they don\\u2019t duplicate this \\nfunctionality. \\n\\n241 \\n\\nCHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fThe difference between the Repository patt\", \"ern and the legacy Data Access class \\n(DAL class) pattern \\n\\nA typical DAL object directly performs d\", \"ata access and persistence operations against storage, often \\nat the level of a single table and row\", \". Simple CRUD operations implemented with a set of DAL classes \\nfrequently do not support transactio\", \"ns (though this is not always the case). Most DAL class \\napproaches make minimal use of abstractions\", \", resulting in tight coupling between application or \\nBusiness Logic Layer (BLL) classes that call t\", \"he DAL objects. \\n\\nWhen using repository, the implementation details of persistence are encapsulated \", \"away from the \\ndomain model. The use of an abstraction provides ease of extending behavior through p\", \"atterns like \\nDecorators or Proxies. For instance, cross-cutting concerns like caching, logging, and\", \" error handling \\ncan all be applied using these patterns rather than hard-coded in the data access c\", \"ode itself. It\\u2019s also \\ntrivial to support multiple repository adapters which may be used in differen\", \"t environments, from \\nlocal development to shared staging environments to production. \\n\\nImplementing\", \" Unit of Work \\n\\nA unit of work refers to a single transaction that involves multiple insert, update,\", \" or delete operations. \\nIn simple terms, it means that for a specific user action, such as a registr\", \"ation on a website, all the \\ninsert, update, and delete operations are handled in a single transacti\", \"on. This is more efficient than \\nhandling multiple database operations in a chattier way. \\n\\nThese mu\", \"ltiple persistence operations are performed later in a single action when your code from the \\napplic\", \"ation layer commands it. The decision about applying the in-memory changes to the actual \\ndatabase s\", \"torage is typically based on the Unit of Work pattern. In EF, the Unit of Work pattern is \\nimplement\", \"ed by a DbContext and is executed when a call is made to SaveChanges. \\n\\nIn many cases, this pattern \", \"or way of applying operations against the storage can increase application \\nperformance and reduce t\", \"he possibility of inconsistencies. It also reduces transaction blocking in the \\ndatabase tables, bec\", \"ause all the intended operations are committed as part of one transaction. This is \\nmore efficient i\", \"n comparison to executing many isolated operations against the database. Therefore, \\nthe selected OR\", \"M can optimize the execution against the database by grouping several update \\nactions within the sam\", \"e transaction, as opposed to many small and separate transaction executions. \\n\\nThe Unit of Work patt\", \"ern can be implemented with or without using the Repository pattern. \\n\\nRepositories shouldn\\u2019t be man\", \"datory \\n\\nCustom repositories are useful for the reasons cited earlier, and that is the approach for \", \"the ordering \\nmicroservice in eShopOnContainers. However, it isn\\u2019t an essential pattern to implement\", \" in a DDD \\ndesign or even in general .NET development. \\n\\nFor instance, Jimmy Bogard, when providing \", \"direct feedback for this guide, said the following: \\n\\nThis\\u2019ll probably be my biggest feedback. I\\u2019m r\", \"eally not a fan of repositories, mainly because they hide \\nthe important details of the underlying p\", \"ersistence mechanism. It\\u2019s why I go for MediatR for \\ncommands, too. I can use the full power of the \", \"persistence layer, and push all that domain behavior \\ninto my aggregate roots. I don\\u2019t usually want \", \"to mock my repositories \\u2013 I still need to have that \\n\\n242 \\n\\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fintegration test with the real thing. Going CQRS \", \"meant that we didn\\u2019t really have a need for \\nrepositories any more. \\n\\nRepositories might be useful, \", \"but they are not critical for your DDD design in the way that the \\nAggregate pattern and a rich doma\", \"in model are. Therefore, use the Repository pattern or not, as you \\nsee fit. \\n\\nAdditional resources \", \"\\n\\nRepository pattern \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEdward Hieatt and Rob Mee. Repository pattern. \\nhttps://martinfow\", \"ler.com/eaaCatalog/repository.html \\n\\nThe Repository pattern \\nhttps://learn.microsoft.com/previous-ve\", \"rsions/msp-n-p/ff649690(v=pandp.10) \\n\\nEric Evans. Domain-Driven Design: Tackling Complexity in the H\", \"eart of Software. (Book; \\nincludes a discussion of the Repository pattern) \\nhttps://www.amazon.com/D\", \"omain-Driven-Design-Tackling-Complexity-\\nSoftware/dp/0321125215/ \\n\\nUnit of Work pattern \\n\\n\\u2022  Martin \", \"Fowler. Unit of Work pattern. \\n\\nhttps://martinfowler.com/eaaCatalog/unitOfWork.html \\n\\n\\u2022 \\n\\nImplementi\", \"ng the Repository and Unit of Work Patterns in an ASP.NET MVC \\nApplication \\nhttps://learn.microsoft.\", \"com/aspnet/mvc/overview/older-versions/getting-started-with-ef-5-\\nusing-mvc-4/implementing-the-repos\", \"itory-and-unit-of-work-patterns-in-an-asp-net-mvc-\\napplication \\n\\nImplement the infrastructure persis\", \"tence layer with \\nEntity Framework Core \\n\\nWhen you use relational databases such as SQL Server, Orac\", \"le, or PostgreSQL, a recommended \\napproach is to implement the persistence layer based on Entity Fra\", \"mework (EF). EF supports LINQ and \\nprovides strongly typed objects for your model, as well as simpli\", \"fied persistence into your database. \\n\\nEntity Framework has a long history as part of the .NET Frame\", \"work. When you use .NET, you should \\nalso use Entity Framework Core, which runs on Windows or Linux \", \"in the same way as .NET. EF Core is a \\ncomplete rewrite of Entity Framework that\\u2019s implemented with \", \"a much smaller footprint and \\nimportant improvements in performance. \\n\\n243 \\n\\nCHAPTER 6 | Tackle Busi\", \"ness Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fIntroduction to Entity Framework\", \" Core \\n\\nEntity Framework (EF) Core is a lightweight, extensible, and cross-platform version of the p\", \"opular \\nEntity Framework data access technology. It was introduced with .NET Core in mid-2016. \\n\\nSin\", \"ce an introduction to EF Core is already available in Microsoft documentation, here we simply \\nprovi\", \"de links to that information. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nEntity Framework Core \\nhttps:\", \"//learn.microsoft.com/ef/core/ \\n\\nGetting started with ASP.NET Core and Entity Framework Core using V\", \"isual Studio \\nhttps://learn.microsoft.com/aspnet/core/data/ef-mvc/ \\n\\nDbContext Class \\nhttps://learn.\", \"microsoft.com/dotnet/api/microsoft.entityframeworkcore.dbcontext \\n\\nCompare EF Core & EF6.x \\nhttps://\", \"learn.microsoft.com/ef/efcore-and-ef6/index \\n\\nInfrastructure in Entity Framework Core from a DDD per\", \"spective \\n\\nFrom a DDD point of view, an important capability of EF is the ability to use POCO domain\", \" entities, \\nalso known in EF terminology as POCO code-first entities. If you use POCO domain entitie\", \"s, your \\ndomain model classes are persistence-ignorant, following the Persistence Ignorance and the \", \"\\nInfrastructure Ignorance principles. \\n\\nPer DDD patterns, you should encapsulate domain behavior and\", \" rules within the entity class itself, so \\nit can control invariants, validations, and rules when ac\", \"cessing any collection. Therefore, it is not a \\ngood practice in DDD to allow public access to colle\", \"ctions of child entities or value objects. Instead, \\nyou want to expose methods that control how and\", \" when your fields and property collections can be \\nupdated, and what behavior and actions should occ\", \"ur when that happens. \\n\\nSince EF Core 1.1, to satisfy those DDD requirements, you can have plain fie\", \"lds in your entities instead \\nof public properties. If you do not want an entity field to be externa\", \"lly accessible, you can just create \\nthe attribute or field instead of a property. You can also use \", \"private property setters. \\n\\nIn a similar way, you can now have read-only access to collections by us\", \"ing a public property typed as \\nIReadOnlyCollection<T>, which is backed by a private field member fo\", \"r the collection (like a List<T>) \\nin your entity that relies on EF for persistence. Previous versio\", \"ns of Entity Framework required \\ncollection properties to support ICollection<T>, which meant that a\", \"ny developer using the parent \\nentity class could add or remove items through its property collectio\", \"ns. That possibility would be \\nagainst the recommended patterns in DDD. \\n\\nYou can use a private coll\", \"ection while exposing a read-only IReadOnlyCollection<T> object, as shown \\nin the following code exa\", \"mple: \\n\\npublic class Order : Entity \\n{ \\n\\n244 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microserv\", \"ice with DDD and CQRS Patterns \\n\\n \\n \\n\\f    // Using private fields, allowed since EF Core 1.1 \\n    pr\", \"ivate DateTime _orderDate; \\n    // Other fields ... \\n\\n    private readonly List<OrderItem> _orderIte\", \"ms; \\n    public IReadOnlyCollection<OrderItem> OrderItems => _orderItems; \\n\\n    protected Order() { \", \"} \\n\\n    public Order(int buyerId, int paymentMethodId, Address address) \\n    { \\n        // Initializ\", \"ations ... \\n    } \\n\\n    public void AddOrderItem(int productId, string productName, \\n               \", \"              decimal unitPrice, decimal discount, \\n                             string pictureUrl, \", \"int units = 1) \\n    { \\n        // Validation logic... \\n\\n        var orderItem = new OrderItem(produc\", \"tId, productName, \\n                                      unitPrice, discount, \\n                     \", \"                 pictureUrl, units); \\n        _orderItems.Add(orderItem); \\n    } \\n} \\n\\nThe OrderItems\", \" property can only be accessed as read-only using IReadOnlyCollection<OrderItem>. \\nThis type is read\", \"-only so it is protected against regular external updates. \\n\\nEF Core provides a way to map the domai\", \"n model to the physical database without \\u201ccontaminating\\u201d \\nthe domain model. It is pure .NET POCO cod\", \"e, because the mapping action is implemented in the \\npersistence layer. In that mapping action, you \", \"need to configure the fields-to-database mapping. In \\nthe following example of the OnModelCreating m\", \"ethod from OrderingContext and the \\nOrderEntityTypeConfiguration class, the call to SetPropertyAcces\", \"sMode tells EF Core to access the \\nOrderItems property through its field. \\n\\n// At OrderingContext.cs\", \" from eShopOnContainers \\nprotected override void OnModelCreating(ModelBuilder modelBuilder) \\n{ \\n   /\", \"/ ... \\n   modelBuilder.ApplyConfiguration(new OrderEntityTypeConfiguration()); \\n   // Other entities\", \"' configuration ... \\n} \\n\\n// At OrderEntityTypeConfiguration.cs from eShopOnContainers \\nclass OrderEn\", \"tityTypeConfiguration : IEntityTypeConfiguration<Order> \\n{ \\n    public void Configure(EntityTypeBuil\", \"der<Order> orderConfiguration) \\n    { \\n        orderConfiguration.ToTable(\\\"orders\\\", OrderingContext.\", \"DEFAULT_SCHEMA); \\n        // Other configuration \\n\\n        var navigation = \\n              orderConf\", \"iguration.Metadata.FindNavigation(nameof(Order.OrderItems)); \\n\\n        //EF access the OrderItem col\", \"lection property through its backing field \\n        navigation.SetPropertyAccessMode(PropertyAccessM\", \"ode.Field); \\n\\n245 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patte\", \"rns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\f        // Other configuration \\n    } \\n} \\n\\nWhen you use fields instead \", \"of properties, the OrderItem entity is persisted as if it had a \\nList<OrderItem> property. However, \", \"it exposes a single accessor, the AddOrderItem method, for \\nadding new items to the order. As a resu\", \"lt, behavior and data are tied together and will be consistent \\nthroughout any application code that\", \" uses the domain model. \\n\\nImplement custom repositories with Entity Framework Core \\n\\nAt the implemen\", \"tation level, a repository is simply a class with data persistence code coordinated by a \\nunit of wo\", \"rk (DBContext in EF Core) when performing updates, as shown in the following class: \\n\\n// using direc\", \"tives... \\nnamespace Microsoft.eShopOnContainers.Services.Ordering.Infrastructure.Repositories \\n{ \\n  \", \"  public class BuyerRepository : IBuyerRepository \\n    { \\n        private readonly OrderingContext _\", \"context; \\n        public IUnitOfWork UnitOfWork \\n        { \\n            get \\n            { \\n        \", \"        return _context; \\n            } \\n        } \\n\\n        public BuyerRepository(OrderingContext \", \"context) \\n        { \\n            _context = context ?? throw new ArgumentNullException(nameof(contex\", \"t)); \\n        } \\n\\n        public Buyer Add(Buyer buyer) \\n        { \\n            return _context.Buye\", \"rs.Add(buyer).Entity; \\n        } \\n\\n        public async Task<Buyer> FindAsync(string buyerIdentityGu\", \"id) \\n        { \\n            var buyer = await _context.Buyers \\n                .Include(b => b.Payme\", \"nts) \\n                .Where(b => b.FullName == buyerIdentityGuid) \\n                .SingleOrDefault\", \"Async(); \\n\\n            return buyer; \\n        } \\n    } \\n} \\n\\nThe IBuyerRepository interface comes fro\", \"m the domain model layer as a contract. However, the \\nrepository implementation is done at the persi\", \"stence and infrastructure layer. \\n\\nThe EF DbContext comes through the constructor through Dependency\", \" Injection. It is shared between \\nmultiple repositories within the same HTTP request scope, thanks t\", \"o its default lifetime \\n(ServiceLifetime.Scoped) in the IoC container (which can also be explicitly \", \"set with \\nservices.AddDbContext<>). \\n\\n246 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\fMethods to implement in a repository (updates or transact\", \"ions versus queries) \\n\\nWithin each repository class, you should put the persistence methods that upd\", \"ate the state of entities \\ncontained by its related aggregate. Remember there is one-to-one relation\", \"ship between an aggregate \\nand its related repository. Consider that an aggregate root entity object\", \" might have embedded child \\nentities within its EF graph. For example, a buyer might have multiple p\", \"ayment methods as related \\nchild entities. \\n\\nSince the approach for the ordering microservice in eSh\", \"opOnContainers is also based on CQS/CQRS, \\nmost of the queries are not implemented in custom reposit\", \"ories. Developers have the freedom to \\ncreate the queries and joins they need for the presentation l\", \"ayer without the restrictions imposed by \\naggregates, custom repositories per aggregate, and DDD in \", \"general. Most of the custom repositories \\nsuggested by this guide have several update or transaction\", \"al methods but just the query methods \\nneeded to get data to be updated. For example, the BuyerRepos\", \"itory repository implements a \\nFindAsync method, because the application needs to know whether a par\", \"ticular buyer exists before \\ncreating a new buyer related to the order. \\n\\nHowever, the real query me\", \"thods to get data to send to the presentation layer or client apps are \\nimplemented, as mentioned, i\", \"n the CQRS queries based on flexible queries using Dapper. \\n\\nUsing a custom repository versus using \", \"EF DbContext directly \\n\\nThe Entity Framework DbContext class is based on the Unit of Work and Reposi\", \"tory patterns and can \\nbe used directly from your code, such as from an ASP.NET Core MVC controller.\", \" The Unit of Work and \\nRepository patterns result in the simplest code, as in the CRUD catalog micro\", \"service in \\neShopOnContainers. In cases where you want the simplest code possible, you might want to\", \" directly \\nuse the DbContext class, as many developers do. \\n\\nHowever, implementing custom repositori\", \"es provides several benefits when implementing more \\ncomplex microservices or applications. The Unit\", \" of Work and Repository patterns are intended to \\nencapsulate the infrastructure persistence layer s\", \"o it is decoupled from the application and domain-\\nmodel layers. Implementing these patterns can fac\", \"ilitate the use of mock repositories simulating \\naccess to the database. \\n\\nIn Figure 7-18, you can s\", \"ee the differences between not using repositories (directly using the EF \\nDbContext) versus using re\", \"positories, which makes it easier to mock those repositories. \\n\\n247 \\n\\nCHAPTER 6 | Tackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-18. Using custom repositories \", \"versus a plain DbContext \\n\\nFigure 7-18 shows that using a custom repository adds an abstraction laye\", \"r that can be used to ease \\ntesting by mocking the repository. There are multiple alternatives when \", \"mocking. You could mock just \\nrepositories or you could mock a whole unit of work. Usually mocking j\", \"ust the repositories is enough, \\nand the complexity to abstract and mock a whole unit of work is usu\", \"ally not needed. \\n\\nLater, when we focus on the application layer, you will see how Dependency Inject\", \"ion works in \\nASP.NET Core and how it is implemented when using repositories. \\n\\nIn short, custom rep\", \"ositories allow you to test code more easily with unit tests that are not impacted \\nby the data tier\", \" state. If you run tests that also access the actual database through the Entity \\nFramework, they ar\", \"e not unit tests but integration tests, which are a lot slower. \\n\\nIf you were using DbContext direct\", \"ly, you would have to mock it or to run unit tests by using an in-\\nmemory SQL Server with predictabl\", \"e data for unit tests. But mocking the DbContext or controlling \\nfake data requires more work than m\", \"ocking at the repository level. Of course, you could always test \\nthe MVC controllers. \\n\\nEF DbContex\", \"t and IUnitOfWork instance lifetime in your IoC container \\n\\nThe DbContext object (exposed as an IUni\", \"tOfWork object) should be shared among multiple \\nrepositories within the same HTTP request scope. Fo\", \"r example, this is true when the operation being \\nexecuted must deal with multiple aggregates, or si\", \"mply because you are using multiple repository \\ninstances. It is also important to mention that the \", \"IUnitOfWork interface is part of your domain layer, \\nnot an EF Core type. \\n\\nIn order to do that, the\", \" instance of the DbContext object has to have its service lifetime set to \\nServiceLifetime.Scoped. T\", \"his is the default lifetime when registering a DbContext with \\nbuilder.Services.AddDbContext in your\", \" IoC container from the Program.cs file in your ASP.NET Core \\nWeb API project. The following code il\", \"lustrates this. \\n\\n248 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS P\", \"atterns \\n\\n \\n \\n \\n\\f// Add framework services. \\nbuilder.Services.AddMvc(options => \\n{ \\n    options.Filt\", \"ers.Add(typeof(HttpGlobalExceptionFilter)); \\n}).AddControllersAsServices(); \\n\\nbuilder.Services.AddEn\", \"tityFrameworkSqlServer() \\n    .AddDbContext<OrderingContext>(options => \\n    { \\n        options.UseS\", \"qlServer(Configuration[\\\"ConnectionString\\\"], \\n                            sqlOptions => \\nsqlOptions.M\", \"igrationsAssembly(typeof(Startup).GetTypeInfo(). \\n\\nAssembly.GetName().Name)); \\n    }, \\n    ServiceLi\", \"fetime.Scoped // Note that Scoped is the default choice \\n                            // in AddDbCont\", \"ext. It is shown here only for \\n                            // pedagogic purposes. \\n    ); \\n\\nThe DbC\", \"ontext instantiation mode should not be configured as ServiceLifetime.Transient or \\nServiceLifetime.\", \"Singleton. \\n\\nThe repository instance lifetime in your IoC container \\n\\nIn a similar way, repository\\u2019s\", \" lifetime should usually be set as scoped (InstancePerLifetimeScope in \\nAutofac). It could also be t\", \"ransient (InstancePerDependency in Autofac), but your service will be more \\nefficient in regards to \", \"memory when using the scoped lifetime. \\n\\n// Registering a Repository in Autofac IoC container \\nbuild\", \"er.RegisterType<OrderRepository>() \\n    .As<IOrderRepository>() \\n    .InstancePerLifetimeScope(); \\n\\n\", \"Using the singleton lifetime for the repository could cause you serious concurrency problems when \\ny\", \"our DbContext is set to scoped (InstancePerLifetimeScope) lifetime (the default lifetimes for a \\nDBC\", \"ontext). As long as your service lifetimes for your repositories and your DbContext are both \\nScoped\", \", you\\u2019ll avoid these issues. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nImplementing the Repository and Un\", \"it of Work Patterns in an ASP.NET MVC \\nApplication \\nhttps://www.asp.net/mvc/overview/older-versions/\", \"getting-started-with-ef-5-using-mvc-\\n4/implementing-the-repository-and-unit-of-work-patterns-in-an-a\", \"sp-net-mvc-application \\n\\nJonathan Allen. Implementation Strategies for the Repository Pattern with E\", \"ntity \\nFramework, Dapper, and Chain \\nhttps://www.infoq.com/articles/repository-implementation-strate\", \"gies \\n\\nCesar de la Torre. Comparing ASP.NET Core IoC container service lifetimes with Autofac \\nIoC c\", \"ontainer instance scopes \\nhttps://devblogs.microsoft.com/cesardelatorre/comparing-asp-net-core-ioc-s\", \"ervice-life-\\ntimes-and-autofac-ioc-instance-scopes/ \\n\\n249 \\n\\nCHAPTER 6 | Tackle Business Complexity i\", \"n a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n                                                \", \"                                \\n\\fTable mapping \\n\\nTable mapping identifies the table data to be quer\", \"ied from and saved to the database. Previously you \\nsaw how domain entities (for example, a product \", \"or order domain) can be used to generate a related \\ndatabase schema. EF is strongly designed around \", \"the concept of conventions. Conventions address \\nquestions like \\u201cWhat will the name of a table be?\\u201d \", \"or \\u201cWhat property is the primary key?\\u201d Conventions \\nare typically based on conventional names. For e\", \"xample, it is typical for the primary key to be a \\nproperty that ends with Id. \\n\\nBy convention, each\", \" entity will be set up to map to a table with the same name as the DbSet<TEntity> \\nproperty that exp\", \"oses the entity on the derived context. If no DbSet<TEntity> value is provided for \\nthe given entity\", \", the class name is used. \\n\\nData Annotations versus Fluent API \\n\\nThere are many additional EF Core c\", \"onventions, and most of them can be changed by using either \\ndata annotations or Fluent API, impleme\", \"nted within the OnModelCreating method. \\n\\nData annotations must be used on the entity model classes \", \"themselves, which is a more intrusive way \\nfrom a DDD point of view. This is because you are contami\", \"nating your model with data annotations \\nrelated to the infrastructure database. On the other hand, \", \"Fluent API is a convenient way to change \\nmost conventions and mappings within your data persistence\", \" infrastructure layer, so the entity model \\nwill be clean and decoupled from the persistence infrast\", \"ructure. \\n\\nFluent API and the OnModelCreating method \\n\\nAs mentioned, in order to change conventions \", \"and mappings, you can use the OnModelCreating \\nmethod in the DbContext class. \\n\\nThe ordering microse\", \"rvice in eShopOnContainers implements explicit mapping and configuration, \\nwhen needed, as shown in \", \"the following code. \\n\\n// At OrderingContext.cs from eShopOnContainers \\nprotected override void OnMod\", \"elCreating(ModelBuilder modelBuilder) \\n{ \\n   // ... \\n   modelBuilder.ApplyConfiguration(new OrderEnt\", \"ityTypeConfiguration()); \\n   // Other entities' configuration ... \\n} \\n\\n// At OrderEntityTypeConfigur\", \"ation.cs from eShopOnContainers \\nclass OrderEntityTypeConfiguration : IEntityTypeConfiguration<Order\", \"> \\n{ \\n    public void Configure(EntityTypeBuilder<Order> orderConfiguration) \\n    { \\n        orderCo\", \"nfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_SCHEMA); \\n\\n        orderConfiguration.HasKey(o\", \" => o.Id); \\n\\n        orderConfiguration.Ignore(b => b.DomainEvents); \\n\\n        orderConfiguration.Pr\", \"operty(o => o.Id) \\n            .UseHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA); \\n\\n250 \\n\\nCHAPTER\", \" 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\f      \", \"  //Address value object persisted as owned entity type supported since EF Core 2.0 \\n        orderCo\", \"nfiguration \\n            .OwnsOne(o => o.Address, a => \\n            { \\n                a.WithOwner()\", \"; \\n            }); \\n\\n        orderConfiguration \\n            .Property<int?>(\\\"_buyerId\\\") \\n          \", \"  .UsePropertyAccessMode(PropertyAccessMode.Field) \\n            .HasColumnName(\\\"BuyerId\\\") \\n         \", \"   .IsRequired(false); \\n\\n        orderConfiguration \\n            .Property<DateTime>(\\\"_orderDate\\\") \\n\", \"            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n            .HasColumnName(\\\"OrderDate\\\"\", \") \\n            .IsRequired(); \\n\\n        orderConfiguration \\n            .Property<int>(\\\"_orderStatus\", \"Id\\\") \\n            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n            .HasColumnName(\\\"Orde\", \"rStatusId\\\") \\n            .IsRequired(); \\n\\n        orderConfiguration \\n            .Property<int?>(\\\"_\", \"paymentMethodId\\\") \\n            .UsePropertyAccessMode(PropertyAccessMode.Field) \\n            .HasCol\", \"umnName(\\\"PaymentMethodId\\\") \\n            .IsRequired(false); \\n\\n        orderConfiguration.Property<st\", \"ring>(\\\"Description\\\").IsRequired(false); \\n\\n        var navigation = \\norderConfiguration.Metadata.Find\", \"Navigation(nameof(Order.OrderItems)); \\n\\n        // DDD Patterns comment: \\n        //Set as field (Ne\", \"w since EF 1.1) to access the OrderItem collection property \\nthrough its field \\n        navigation.S\", \"etPropertyAccessMode(PropertyAccessMode.Field); \\n\\n        orderConfiguration.HasOne<PaymentMethod>()\", \" \\n            .WithMany() \\n            .HasForeignKey(\\\"_paymentMethodId\\\") \\n            .IsRequired(f\", \"alse) \\n            .OnDelete(DeleteBehavior.Restrict); \\n\\n        orderConfiguration.HasOne<Buyer>() \", \"\\n            .WithMany() \\n            .IsRequired(false) \\n            .HasForeignKey(\\\"_buyerId\\\"); \\n\\n\", \"        orderConfiguration.HasOne(o => o.OrderStatus) \\n            .WithMany() \\n            .HasFore\", \"ignKey(\\\"_orderStatusId\\\"); \\n    } \\n} \\n\\nYou could set all the Fluent API mappings within the same OnMo\", \"delCreating method, but it\\u2019s \\nadvisable to partition that code and have multiple configuration class\", \"es, one per entity, as shown in \\n\\n251 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice wit\", \"h DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fthe example. Especially for large models, it is a\", \"dvisable to have separate configuration classes for \\nconfiguring different entity types. \\n\\nThe code \", \"in the example shows a few explicit declarations and mapping. However, EF Core \\nconventions do many \", \"of those mappings automatically, so the actual code you would need in your \\ncase might be smaller. \\n\", \"\\nThe Hi/Lo algorithm in EF Core \\n\\nAn interesting aspect of code in the preceding example is that it \", \"uses the Hi/Lo algorithm as the key \\ngeneration strategy. \\n\\nThe Hi/Lo algorithm is useful when you n\", \"eed unique keys before committing changes. As a summary, \\nthe Hi-Lo algorithm assigns unique identif\", \"iers to table rows while not depending on storing the row in \\nthe database immediately. This lets yo\", \"u start using the identifiers right away, as happens with regular \\nsequential database IDs. \\n\\nThe Hi\", \"/Lo algorithm describes a mechanism for getting a batch of unique IDs from a related database \\nseque\", \"nce. These IDs are safe to use because the database guarantees the uniqueness, so there will be \\nno \", \"collisions between users. This algorithm is interesting for these reasons: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nIt does not\", \" break the Unit of Work pattern. \\n\\nIt gets sequence IDs in batches, to minimize round trips to the d\", \"atabase. \\n\\nIt generates a human readable identifier, unlike techniques that use GUIDs. \\n\\nEF Core sup\", \"ports HiLo with the UseHiLo method, as shown in the preceding example. \\n\\nMap fields instead of prope\", \"rties \\n\\nWith this feature, available since EF Core 1.1, you can directly map columns to fields. It i\", \"s possible to \\nnot use properties in the entity class, and just to map columns from a table to field\", \"s. A common use \\nfor that would be private fields for any internal state that do not need to be acce\", \"ssed from outside the \\nentity. \\n\\nYou can do this with single fields or also with collections, like a\", \" List<> field. This point was mentioned \\nearlier when we discussed modeling the domain model classes\", \", but here you can see how that \\nmapping is performed with the PropertyAccessMode.Field configuratio\", \"n highlighted in the previous \\ncode. \\n\\nUse shadow properties in EF Core, hidden at the infrastructur\", \"e level \\n\\nShadow properties in EF Core are properties that do not exist in your entity class model. \", \"The values \\nand states of these properties are maintained purely in the ChangeTracker class at the i\", \"nfrastructure \\nlevel. \\n\\n252 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and \", \"CQRS Patterns \\n\\n \\n \\n\\fImplement the Query Specification pattern \\n\\nAs introduced earlier in the design\", \" section, the Query Specification pattern is a Domain-Driven Design \\npattern designed as the place w\", \"here you can put the definition of a query with optional sorting and \\npaging logic. \\n\\nThe Query Spec\", \"ification pattern defines a query in an object. For example, in order to encapsulate a \\npaged query \", \"that searches for some products you can create a PagedProduct specification that takes \\nthe necessar\", \"y input parameters (pageNumber, pageSize, filter, etc.). Then, within any Repository \\nmethod (usuall\", \"y a List() overload) it would accept an IQuerySpecification and run the expected query \\nbased on tha\", \"t specification. \\n\\nAn example of a generic Specification interface is the following code, which is s\", \"imilar to code used in \\nthe eShopOnWeb reference application. \\n\\n// GENERIC SPECIFICATION INTERFACE \\n\", \"// https://github.com/dotnet-architecture/eShopOnWeb \\n\\npublic interface ISpecification<T> \\n{ \\n    Ex\", \"pression<Func<T, bool>> Criteria { get; } \\n    List<Expression<Func<T, object>>> Includes { get; } \\n\", \"    List<string> IncludeStrings { get; } \\n} \\n\\nThen, the implementation of a generic specification ba\", \"se class is the following. \\n\\n// GENERIC SPECIFICATION IMPLEMENTATION (BASE CLASS) \\n// https://github\", \".com/dotnet-architecture/eShopOnWeb \\n\\npublic abstract class BaseSpecification<T> : ISpecification<T>\", \" \\n{ \\n    public BaseSpecification(Expression<Func<T, bool>> criteria) \\n    { \\n        Criteria = cri\", \"teria; \\n    } \\n    public Expression<Func<T, bool>> Criteria { get; } \\n\\n    public List<Expression<F\", \"unc<T, object>>> Includes { get; } = \\n                                           new List<Expression\", \"<Func<T, object>>>(); \\n\\n    public List<string> IncludeStrings { get; } = new List<string>(); \\n\\n    \", \"protected virtual void AddInclude(Expression<Func<T, object>> includeExpression) \\n    { \\n        Inc\", \"ludes.Add(includeExpression); \\n    } \\n\\n    // string-based includes allow for including children of \", \"children \\n    // e.g. Basket.Items.Product \\n    protected virtual void AddInclude(string includeStri\", \"ng) \\n    { \\n        IncludeStrings.Add(includeString); \\n    } \\n} \\n\\n253 \\n\\nCHAPTER 6 | Tackle Business\", \" Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\fThe following specificat\", \"ion loads a single basket entity given either the basket\\u2019s ID or the ID of the \\nbuyer to whom the ba\", \"sket belongs. It will eagerly load the basket\\u2019s Items collection. \\n\\n// SAMPLE QUERY SPECIFICATION IM\", \"PLEMENTATION \\n\\npublic class BasketWithItemsSpecification : BaseSpecification<Basket> \\n{ \\n    public \", \"BasketWithItemsSpecification(int basketId) \\n        : base(b => b.Id == basketId) \\n    { \\n        Ad\", \"dInclude(b => b.Items); \\n    } \\n\\n    public BasketWithItemsSpecification(string buyerId) \\n        : \", \"base(b => b.BuyerId == buyerId) \\n    { \\n        AddInclude(b => b.Items); \\n    } \\n} \\n\\nAnd finally, y\", \"ou can see below how a generic EF Repository can use such a specification to filter and \\neager-load \", \"data related to a given entity type T. \\n\\n// GENERIC EF REPOSITORY WITH SPECIFICATION \\n// https://git\", \"hub.com/dotnet-architecture/eShopOnWeb \\n\\npublic IEnumerable<T> List(ISpecification<T> spec) \\n{ \\n    \", \"// fetch a Queryable that includes all expression-based includes \\n    var queryableResultWithInclude\", \"s = spec.Includes \\n        .Aggregate(_dbContext.Set<T>().AsQueryable(), \\n            (current, incl\", \"ude) => current.Include(include)); \\n\\n    // modify the IQueryable to include any string-based includ\", \"e statements \\n    var secondaryResult = spec.IncludeStrings \\n        .Aggregate(queryableResultWithI\", \"ncludes, \\n            (current, include) => current.Include(include)); \\n\\n    // return the result of\", \" the query using the specification's criteria expression \\n    return secondaryResult \\n              \", \"      .Where(spec.Criteria) \\n                    .AsEnumerable(); \\n} \\n\\nIn addition to encapsulating \", \"filtering logic, the specification can specify the shape of the data to be \\nreturned, including whic\", \"h properties to populate. \\n\\nAlthough we don\\u2019t recommend returning IQueryable from a repository, it\\u2019s\", \" perfectly fine to use them \\nwithin the repository to build up a set of results. You can see this ap\", \"proach used in the List method \\nabove, which uses intermediate IQueryable expressions to build up th\", \"e query\\u2019s list of includes before \\nexecuting the query with the specification\\u2019s criteria on the last\", \" line. \\n\\nLearn how the specification pattern is applied in the eShopOnWeb sample. \\n\\n254 \\n\\nCHAPTER 6 \", \"| Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\fAdditiona\", \"l resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nTable Mapping \\nhttps://learn.microsoft.com/ef/core/modeling/re\", \"lational/tables \\n\\nUse HiLo to generate keys with Entity Framework Core \\nhttps://www.talkingdotnet.co\", \"m/use-hilo-to-generate-keys-with-entity-framework-core/ \\n\\nBacking Fields \\nhttps://learn.microsoft.co\", \"m/ef/core/modeling/backing-field \\n\\nSteve Smith. Encapsulated Collections in Entity Framework Core \\nh\", \"ttps://ardalis.com/encapsulated-collections-in-entity-framework-core \\n\\nShadow Properties \\nhttps://le\", \"arn.microsoft.com/ef/core/modeling/shadow-properties \\n\\nThe Specification pattern \\nhttps://deviq.com/\", \"specification-pattern/ \\n\\nArdalis.Specification NuGet Package Used by \\neShopOnWeb.  https://www.nuget\", \".org/packages/Ardalis.Specification \\n\\nUse NoSQL databases as a persistence infrastructure \\n\\nWhen you\", \" use NoSQL databases for your infrastructure data tier, you typically do not use an ORM like \\nEntity\", \" Framework Core. Instead you use the API provided by the NoSQL engine, such as Azure Cosmos \\nDB, Mon\", \"goDB, Cassandra, RavenDB, CouchDB, or Azure Storage Tables. \\n\\nHowever, when you use a NoSQL database\", \", especially a document-oriented database like Azure \\nCosmos DB, CouchDB, or RavenDB, the way you de\", \"sign your model with DDD aggregates is partially \\nsimilar to how you can do it in EF Core, in regard\", \"s to the identification of aggregate roots, child entity \\nclasses, and value object classes. But, ul\", \"timately, the database selection will impact in your design. \\n\\nWhen you use a document-oriented data\", \"base, you implement an aggregate as a single document, \\nserialized in JSON or another format. Howeve\", \"r, the use of the database is transparent from a domain \\nmodel code point of view. When using a NoSQ\", \"L database, you still are using entity classes and \\naggregate root classes, but with more flexibilit\", \"y than when using EF Core because the persistence is \\nnot relational. \\n\\nThe difference is in how you\", \" persist that model. If you implemented your domain model based on \\nPOCO entity classes, agnostic to\", \" the infrastructure persistence, it might look like you could move to a \\ndifferent persistence infra\", \"structure, even from relational to NoSQL. However, that should not be your \\ngoal. There are always c\", \"onstraints and trade-offs in the different database technologies, so you will \\nnot be able to have t\", \"he same model for relational or NoSQL databases. Changing persistence models \\nis not a trivial task,\", \" because transactions and persistence operations will be very different. \\n\\nFor example, in a documen\", \"t-oriented database, it is okay for an aggregate root to have multiple child \\ncollection properties.\", \" In a relational database, querying multiple child collection properties is not \\n\\n255 \\n\\nCHAPTER 6 | \", \"Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n  \\n\\feasily optimized, \", \"because you get a UNION ALL SQL statement back from EF. Having the same \\ndomain model for relational\", \" databases or NoSQL databases is not simple, and you should not try to \\ndo it. You really have to de\", \"sign your model with an understanding of how the data is going to be \\nused in each particular databa\", \"se. \\n\\nA benefit when using NoSQL databases is that the entities are more denormalized, so you do not\", \" set a \\ntable mapping. Your domain model can be more flexible than when using a relational database.\", \" \\n\\nWhen you design your domain model based on aggregates, moving to NoSQL and document-\\noriented dat\", \"abases might be even easier than using a relational database, because the aggregates \\nyou design are\", \" similar to serialized documents in a document-oriented database. Then you can \\ninclude in those \\u201cba\", \"gs\\u201d all the information you might need for that aggregate. \\n\\nFor instance, the following JSON code i\", \"s a sample implementation of an order aggregate when using \\na document-oriented database. It is simi\", \"lar to the order aggregate we implemented in the \\neShopOnContainers sample, but without using EF Cor\", \"e underneath. \\n\\n{ \\n    \\\"id\\\": \\\"2024001\\\", \\n    \\\"orderDate\\\": \\\"2/25/2024\\\", \\n    \\\"buyerId\\\": \\\"1234567\\\", \\n \", \"   \\\"address\\\": [ \\n        { \\n        \\\"street\\\": \\\"100 One Microsoft Way\\\", \\n        \\\"city\\\": \\\"Redmond\\\", \\n\", \"        \\\"state\\\": \\\"WA\\\", \\n        \\\"zip\\\": \\\"98052\\\", \\n        \\\"country\\\": \\\"U.S.\\\" \\n        } \\n    ], \\n    \\\"\", \"orderItems\\\": [ \\n        {\\\"id\\\": 20240011, \\\"productId\\\": \\\"123456\\\", \\\"productName\\\": \\\".NET T-Shirt\\\", \\n    \", \"    \\\"unitPrice\\\": 25, \\\"units\\\": 2, \\\"discount\\\": 0}, \\n        {\\\"id\\\": 20240012, \\\"productId\\\": \\\"123457\\\", \\\"p\", \"roductName\\\": \\\".NET Mug\\\", \\n        \\\"unitPrice\\\": 15, \\\"units\\\": 1, \\\"discount\\\": 0} \\n    ] \\n} \\n\\nIntroducti\", \"on to Azure Cosmos DB and the native Cosmos DB API \\n\\nAzure Cosmos DB is Microsoft\\u2019s globally distrib\", \"uted database service for mission-critical applications. \\nAzure Cosmos DB provides turn-key global d\", \"istribution, elastic scaling of throughput and storage \\nworldwide, single-digit millisecond latencie\", \"s at the 99th percentile, five well-defined consistency \\nlevels, and guaranteed high availability, a\", \"ll backed by industry-leading SLAs. Azure Cosmos DB \\nautomatically indexes data without requiring yo\", \"u to deal with schema and index management. It is \\nmulti-model and supports document, key-value, gra\", \"ph, and columnar data models. \\n\\n256 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with \", \"DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-19. Azure Cosmos DB global distribution \\n\\nWhen you use a C# mo\", \"del to implement the aggregate to be used by the Azure Cosmos DB API, the \\naggregate can be similar \", \"to the C# POCO classes used with EF Core. The difference is in the way to \\nuse them from the applica\", \"tion and infrastructure layers, as in the following code: \\n\\n// C# EXAMPLE OF AN ORDER AGGREGATE BEIN\", \"G PERSISTED WITH AZURE COSMOS DB API \\n// *** Domain Model Code *** \\n// Aggregate: Create an Order ob\", \"ject with its child entities and/or value objects. \\n// Then, use AggregateRoot's methods to add the \", \"nested objects so invariants and \\n// logic is consistent across the nested properties (value objects\", \" and entities). \\n\\nOrder orderAggregate = new Order \\n{ \\n    Id = \\\"2024001\\\", \\n    OrderDate = new Date\", \"Time(2005, 7, 1), \\n    BuyerId = \\\"1234567\\\", \\n    PurchaseOrderNumber = \\\"PO18009186470\\\" \\n} \\n\\nAddress \", \"address = new Address \\n{ \\n    Street = \\\"100 One Microsoft Way\\\", \\n    City = \\\"Redmond\\\", \\n    State = \", \"\\\"WA\\\", \\n    Zip = \\\"98052\\\", \\n    Country = \\\"U.S.\\\" \\n} \\n\\norderAggregate.UpdateAddress(address); \\n\\nOrderI\", \"tem orderItem1 = new OrderItem \\n{ \\n\\n257 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice w\", \"ith DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n\\f    Id = 20240011, \\n    ProductId = \\\"123456\\\", \\n    Produc\", \"tName = \\\".NET T-Shirt\\\", \\n    UnitPrice = 25, \\n    Units = 2, \\n    Discount = 0; \\n}; \\n\\n//Using method\", \"s with domain logic within the entity. No anemic-domain model \\norderAggregate.AddOrderItem(orderItem\", \"1); \\n// *** End of Domain Model Code *** \\n\\n// *** Infrastructure Code using Cosmos DB Client API ***\", \" \\nUri collectionUri = UriFactory.CreateDocumentCollectionUri(databaseName, \\n    collectionName); \\n\\na\", \"wait client.CreateDocumentAsync(collectionUri, orderAggregate); \\n\\n// As your app evolves, let's say \", \"your object has a new schema. You can insert \\n// OrderV2 objects without any changes to the database\", \" tier. \\nOrder2 newOrder = GetOrderV2Sample(\\\"IdForSalesOrder2\\\"); \\nawait client.CreateDocumentAsync(co\", \"llectionUri, newOrder); \\n\\nYou can see that the way you work with your domain model can be similar to\", \" the way you use it in \\nyour domain model layer when the infrastructure is EF. You still use the sam\", \"e aggregate root methods \\nto ensure consistency, invariants, and validations within the aggregate. \\n\", \"\\nHowever, when you persist your model into the NoSQL database, the code and API change \\ndramatically\", \" compared to EF Core code or any other code related to relational databases. \\n\\nImplement .NET code t\", \"argeting MongoDB and Azure Cosmos DB \\n\\nUse Azure Cosmos DB from .NET containers \\n\\nYou can access Azu\", \"re Cosmos DB databases from .NET code running in containers, like from any other \\n.NET application. \", \"For instance, the Locations.API and Marketing.API microservices in \\neShopOnContainers are implemente\", \"d so they can consume Azure Cosmos DB databases. \\n\\nHowever, there\\u2019s a limitation in Azure Cosmos DB \", \"from a Docker development environment point of \\nview. Even though there\\u2019s an on-premises Azure Cosmo\", \"s DB Emulator that can run in a local \\ndevelopment machine, it only supports Windows. Linux and macO\", \"S aren\\u2019t supported. \\n\\nThere\\u2019s also the possibility to run this emulator on Docker, but just on Windo\", \"ws Containers, not with \\nLinux Containers. That\\u2019s an initial handicap for the development environmen\", \"t if your application is \\ndeployed as Linux containers, since, currently, you can\\u2019t deploy Linux and\", \" Windows Containers on \\nDocker for Windows at the same time. Either all containers being deployed ha\", \"ve to be for Linux or for \\nWindows. \\n\\nThe ideal and more straightforward deployment for a dev/test s\", \"olution is to be able to deploy your \\ndatabase systems as containers along with your custom containe\", \"rs so your dev/test environments are \\nalways consistent. \\n\\n258 \\n\\nCHAPTER 6 | Tackle Business Complex\", \"ity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\fUse MongoDB API for local dev/test L\", \"inux/Windows containers plus Azure Cosmos \\nDB \\n\\nCosmos DB databases support MongoDB API for .NET as \", \"well as the native MongoDB wire protocol. \\nThis means that by using existing drivers, your applicati\", \"on written for MongoDB can now \\ncommunicate with Cosmos DB and use Cosmos DB databases instead of Mo\", \"ngoDB databases, as \\nshown in Figure 7-20. \\n\\nFigure 7-20. Using MongoDB API and protocol to access A\", \"zure Cosmos DB \\n\\nThis is a very convenient approach for proof of concepts in Docker environments wit\", \"h Linux \\ncontainers because the MongoDB Docker image is a multi-arch image that supports Docker Linu\", \"x \\ncontainers and Docker Windows containers. \\n\\nAs shown in the following image, by using the MongoDB\", \" API, eShopOnContainers supports MongoDB \\nLinux and Windows containers for the local development env\", \"ironment but then, you can move to a \\nscalable, PaaS cloud solution as Azure Cosmos DB by simply cha\", \"nging the MongoDB connection \\nstring to point to Azure Cosmos DB. \\n\\n259 \\n\\nCHAPTER 6 | Tackle Busines\", \"s Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fFigure 7-21. eShopOnContainers us\", \"ing MongoDB containers for dev-env or Azure Cosmos DB for production \\n\\nThe production Azure Cosmos D\", \"B would be running in Azure\\u2019s cloud as a PaaS and scalable service. \\n\\nYour custom .NET containers ca\", \"n run on a local development Docker host (that is using Docker for \\nWindows in a Windows 10 machine)\", \" or be deployed into a production environment, like Kubernetes in \\nAzure AKS or Azure Service Fabric\", \". In this second environment, you would deploy only the .NET \\ncustom containers but not the MongoDB \", \"container since you\\u2019d be using Azure Cosmos DB in the \\ncloud for handling the data in production. \\n\\n\", \"A clear benefit of using the MongoDB API is that your solution could run in both database engines, \\n\", \"MongoDB or Azure Cosmos DB, so migrations to different environments should be easy. However, \\nsometi\", \"mes it is worthwhile to use a native API (that is the native Cosmos DB API) in order to take full \\na\", \"dvantage of the capabilities of a specific database engine. \\n\\nFor further comparison between simply \", \"using MongoDB versus Cosmos DB in the cloud, see the \\nBenefits of using Azure Cosmos DB in this page\", \". \\n\\nAnalyze your approach for production applications: MongoDB API vs. Cosmos DB \\nAPI \\n\\nIn eShopOnCo\", \"ntainers, we\\u2019re using MongoDB API because our priority was fundamentally to have a \\nconsistent dev/t\", \"est environment using a NoSQL database that could also work with Azure Cosmos DB. \\n\\n260 \\n\\nCHAPTER 6 \", \"| Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fHowever, if you a\", \"re planning to use MongoDB API to access Azure Cosmos DB in Azure for \\nproduction applications, you \", \"should analyze the differences in capabilities and performance when \\nusing MongoDB API to access Azu\", \"re Cosmos DB databases compared to using the native Azure \\nCosmos DB API. If it is similar you can u\", \"se MongoDB API and you get the benefit of supporting two \\nNoSQL database engines at the same time. \\n\", \"\\nYou could also use MongoDB clusters as the production database in Azure\\u2019s cloud, too, with \\nMongoDB\", \" Azure Service. But that is not a PaaS service provided by Microsoft. In this case, Azure is just \\nh\", \"osting that solution coming from MongoDB. \\n\\nBasically, this is just a disclaimer stating that you sh\", \"ouldn\\u2019t always use MongoDB API against Azure \\nCosmos DB, as we did in eShopOnContainers because it w\", \"as a convenient choice for Linux containers. \\nThe decision should be based on the specific needs and\", \" tests you need to do for your production \\napplication. \\n\\nThe code: Use MongoDB API in .NET applicat\", \"ions \\n\\nMongoDB API for .NET is based on NuGet packages that you need to add to your projects, like i\", \"n the \\nLocations.API project shown in the following figure. \\n\\n261 \\n\\nCHAPTER 6 | Tackle Business Comp\", \"lexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-22. MongoDB API NuGet packages r\", \"eferences in a .NET project \\n\\nLet\\u2019s investigate the code in the following sections. \\n\\nA Model used b\", \"y MongoDB API \\n\\nFirst, you need to define a model that will hold the data coming from the database i\", \"n your \\napplication\\u2019s memory space. Here\\u2019s an example of the model used for Locations at \\neShopOnCon\", \"tainers. \\n\\nusing MongoDB.Bson; \\nusing MongoDB.Bson.Serialization.Attributes; \\nusing MongoDB.Driver.G\", \"eoJsonObjectModel; \\nusing System.Collections.Generic; \\n\\npublic class Locations \\n{ \\n\\n262 \\n\\nCHAPTER 6 \", \"| Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\f    [BsonId] \\n \", \"   [BsonRepresentation(BsonType.ObjectId)] \\n    public string Id { get; set; } \\n    public int Locat\", \"ionId { get; set; } \\n    public string Code { get; set; } \\n    [BsonRepresentation(BsonType.ObjectId\", \")] \\n    public string Parent_Id { get; set; } \\n    public string Description { get; set; } \\n    publ\", \"ic double Latitude { get; set; } \\n    public double Longitude { get; set; } \\n    public GeoJsonPoint\", \"<GeoJson2DGeographicCoordinates> Location \\n                                                         \", \"    { get; private set; } \\n    public GeoJsonPolygon<GeoJson2DGeographicCoordinates> Polygon \\n      \", \"                                                       { get; private set; } \\n    public void SetLoc\", \"ation(double lon, double lat) => SetPosition(lon, lat); \\n    public void SetArea(List<GeoJson2DGeogr\", \"aphicCoordinates> coordinatesList) \\n                                                    => SetPolygo\", \"n(coordinatesList); \\n\\n    private void SetPosition(double lon, double lat) \\n    { \\n        Latitude \", \"= lat; \\n        Longitude = lon; \\n        Location = new GeoJsonPoint<GeoJson2DGeographicCoordinates\", \">( \\n            new GeoJson2DGeographicCoordinates(lon, lat)); \\n    } \\n\\n    private void SetPolygon(\", \"List<GeoJson2DGeographicCoordinates> coordinatesList) \\n    { \\n        Polygon = new GeoJsonPolygon<G\", \"eoJson2DGeographicCoordinates>( \\n                  new GeoJsonPolygonCoordinates<GeoJson2DGeographic\", \"Coordinates>( \\n                  new GeoJsonLinearRingCoordinates<GeoJson2DGeographicCoordinates>( \\n\", \"                                                                 coordinatesList))); \\n    } \\n} \\n\\nYou\", \" can see there are a few attributes and types coming from the MongoDB NuGet packages. \\n\\nNoSQL databa\", \"ses are usually very well suited for working with non-relational hierarchical data. In this \\nexample\", \", we are using MongoDB types especially made for geo-locations, like \\nGeoJson2DGeographicCoordinates\", \". \\n\\nRetrieve the database and the collection \\n\\nIn eShopOnContainers, we have created a custom databa\", \"se context where we implement the code to \\nretrieve the database and the MongoCollections, as in the\", \" following code. \\n\\npublic class LocationsContext \\n{ \\n    private readonly IMongoDatabase _database =\", \" null; \\n\\n    public LocationsContext(IOptions<LocationSettings> settings) \\n    { \\n        var client\", \" = new MongoClient(settings.Value.ConnectionString); \\n        if (client != null) \\n            _data\", \"base = client.GetDatabase(settings.Value.Database); \\n    } \\n\\n    public IMongoCollection<Locations> \", \"Locations \\n    { \\n\\n263 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS \", \"Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\f        get \\n        { \\n            return _database.GetCollection<Locations\", \">(\\\"Locations\\\"); \\n        } \\n    } \\n} \\n\\nRetrieve the data \\n\\nIn C# code, like Web API controllers or c\", \"ustom Repositories implementation, you can write similar \\ncode to the following when querying throug\", \"h the MongoDB API. Note that the _context object is an \\ninstance of the previous LocationsContext cl\", \"ass. \\n\\npublic async Task<Locations> GetAsync(int locationId) \\n{ \\n    var filter = Builders<Locations\", \">.Filter.Eq(\\\"LocationId\\\", locationId); \\n    return await _context.Locations \\n                       \", \"     .Find(filter) \\n                            .FirstOrDefaultAsync(); \\n} \\n\\nUse an env-var in the d\", \"ocker-compose.override.yml file for the MongoDB connection \\nstring \\n\\nWhen creating a MongoClient obj\", \"ect, it needs a fundamental parameter which is precisely the \\nConnectionString parameter pointing to\", \" the right database. In the case of eShopOnContainers, the \\nconnection string can point to a local M\", \"ongoDB Docker container or to a \\u201cproduction\\u201d Azure Cosmos \\nDB database. That connection string comes\", \" from the environment variables defined in the docker-\\ncompose.override.yml files used when deployin\", \"g with docker-compose or Visual Studio, as in the \\nfollowing yml code. \\n\\n# docker-compose.override.y\", \"ml \\nversion: '3.4' \\nservices: \\n  # Other services \\n  locations-api: \\n    environment: \\n      # Other\", \" settings \\n      - ConnectionString=${ESHOP_AZURE_COSMOSDB:-mongodb://nosqldata} \\n\\nThe ConnectionStr\", \"ing environment variable is resolved this way: If the ESHOP_AZURE_COSMOSDB \\nglobal variable is defin\", \"ed in the .env file with the Azure Cosmos DB connection string, it will use it to \\naccess the Azure \", \"Cosmos DB database in the cloud. If it\\u2019s not defined, it will take the \\nmongodb://nosqldata value an\", \"d use the development MongoDB container. \\n\\nThe following code shows the .env file with the Azure Cos\", \"mos DB connection string global \\nenvironment variable, as implemented in eShopOnContainers: \\n\\n# .env\", \" file, in eShopOnContainers root folder \\n# Other Docker environment variables \\n\\nESHOP_EXTERNAL_DNS_N\", \"AME_OR_IP=host.docker.internal \\nESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP=<YourDockerHostIP> \\n\\n#ESHOP_AZURE\", \"_COSMOSDB=<YourAzureCosmosDBConnData> \\n\\n264 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservi\", \"ce with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\f#Other environment variables for additional Azure infrastru\", \"cture assets \\n#ESHOP_AZURE_REDIS_BASKET_DB=<YourAzureRedisBasketInfo> \\n#ESHOP_AZURE_STORAGE_CATALOG_\", \"URL=<YourAzureStorage_Catalog_BLOB_URL> \\n#ESHOP_AZURE_SERVICE_BUS=<YourAzureServiceBusInfo> \\n\\nUncomm\", \"ent the ESHOP_AZURE_COSMOSDB line and update it with your Azure Cosmos DB \\nconnection string obtaine\", \"d from the Azure portal as explained in Connect a MongoDB application to \\nAzure Cosmos DB. \\n\\nIf the \", \"ESHOP_AZURE_COSMOSDB global variable is empty, meaning it\\u2019s commented out in the .env \\nfile, then th\", \"e container uses a default MongoDB connection string. This connection string points to \\nthe local Mo\", \"ngoDB container deployed in eShopOnContainers that is named nosqldata and was \\ndefined at the docker\", \"-compose file, as shown in the following .yml code: \\n\\n# docker-compose.yml \\nversion: '3.4' \\nservices\", \": \\n  # ...Other services... \\n  nosqldata: \\n    image: mongo \\n\\nAdditional resources \\n\\n\\u2022  Modeling doc\", \"ument data for NoSQL databases \\n\\nhttps://learn.microsoft.com/azure/cosmos-db/modeling-data \\n\\n\\u2022 \\n\\n\\u2022 \\n\", \"\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nVaughn Vernon. The Ideal Domain-Driven Design Aggregate Store? \\nhttps://kal\", \"ele.io/blog-posts/the-ideal-domain-driven-design-aggregate-store/ \\n\\nIntroduction to Azure Cosmos DB:\", \" API for MongoDB \\nhttps://learn.microsoft.com/azure/cosmos-db/mongodb-introduction \\n\\nAzure Cosmos DB\", \": Build a MongoDB API web app with .NET and the Azure portal \\nhttps://learn.microsoft.com/azure/cosm\", \"os-db/create-mongodb-dotnet \\n\\nUse the Azure Cosmos DB Emulator for local development and testing \\nht\", \"tps://learn.microsoft.com/azure/cosmos-db/local-emulator \\n\\nConnect a MongoDB application to Azure Co\", \"smos DB \\nhttps://learn.microsoft.com/azure/cosmos-db/connect-mongodb-account \\n\\nThe Cosmos DB Emulato\", \"r Docker image (Windows Container) \\nhttps://hub.docker.com/r/microsoft/azure-cosmosdb-emulator/ \\n\\nTh\", \"e MongoDB Docker image (Linux and Windows Container) \\nhttps://hub.docker.com/_/mongo/ \\n\\nUse MongoChe\", \"f (Studio 3T) with an Azure Cosmos DB: API for MongoDB account \\nhttps://learn.microsoft.com/azure/co\", \"smos-db/mongodb-mongochef \\n\\n265 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD \", \"and CQRS Patterns \\n\\n \\n \\n \\n\\fDesign the microservice application layer and Web \\nAPI \\n\\nUse SOLID princi\", \"ples and Dependency Injection \\n\\nSOLID principles are critical techniques to be used in any modern an\", \"d mission-critical application, \\nsuch as developing a microservice with DDD patterns. SOLID is an ac\", \"ronym that groups five \\nfundamental principles: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nSingle Responsibility principl\", \"e \\n\\nOpen/closed principle \\n\\nLiskov substitution principle \\n\\nInterface Segregation principle \\n\\nDepend\", \"ency Inversion principle \\n\\nSOLID is more about how you design your application or microservice inter\", \"nal layers and about \\ndecoupling dependencies between them. It is not related to the domain, but to \", \"the application\\u2019s \\ntechnical design. The final principle, the Dependency Inversion principle, allows\", \" you to decouple the \\ninfrastructure layer from the rest of the layers, which allows a better decoup\", \"led implementation of the \\nDDD layers. \\n\\nDependency Injection (DI) is one way to implement the Depen\", \"dency Inversion principle. It is a \\ntechnique for achieving loose coupling between objects and their\", \" dependencies. Rather than directly \\ninstantiating collaborators, or using static references (that i\", \"s, using new\\u2026), the objects that a class \\nneeds in order to perform its actions are provided to (or \", \"\\u201cinjected into\\u201d) the class. Most often, classes \\nwill declare their dependencies via their construct\", \"or, allowing them to follow the Explicit \\nDependencies principle. Dependency Injection is usually ba\", \"sed on specific Inversion of Control (IoC) \\ncontainers. ASP.NET Core provides a simple built-in IoC \", \"container, but you can also use your favorite \\nIoC container, like Autofac or Ninject. \\n\\nBy followin\", \"g the SOLID principles, your classes will tend naturally to be small, well-factored, and easily \\ntes\", \"ted. But how can you know if too many dependencies are being injected into your classes? If you \\nuse\", \" DI through the constructor, it will be easy to detect that by just looking at the number of \\nparame\", \"ters for your constructor. If there are too many dependencies, this is generally a sign (a code \\nsme\", \"ll) that your class is trying to do too much, and is probably violating the Single Responsibility \\np\", \"rinciple. \\n\\nIt would take another guide to cover SOLID in detail. Therefore, this guide requires you\", \" to have only a \\nminimum knowledge of these topics. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nSOLID: Fundamental \", \"OOP Principles \\nhttps://deviq.com/solid/ \\n\\n266 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microse\", \"rvice with DDD and CQRS Patterns \\n\\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\nInversion of Control Containers and the Dependency I\", \"njection pattern \\nhttps://martinfowler.com/articles/injection.html \\n\\nSteve Smith. New is Glue \\nhttps\", \"://ardalis.com/new-is-glue \\n\\nImplement the microservice application layer using \\nthe Web API \\n\\nUse D\", \"ependency Injection to inject infrastructure objects into your \\napplication layer \\n\\nAs mentioned pre\", \"viously, the application layer can be implemented as part of the artifact (assembly) \\nyou are buildi\", \"ng, such as within a Web API project or an MVC web app project. In the case of a \\nmicroservice built\", \" with ASP.NET Core, the application layer will usually be your Web API library. If you \\nwant to sepa\", \"rate what is coming from ASP.NET Core (its infrastructure plus your controllers) from your \\ncustom a\", \"pplication layer code, you could also place your application layer in a separate class library, \\nbut\", \" that is optional. \\n\\nFor instance, the application layer code of the ordering microservice is direct\", \"ly implemented as part of \\nthe Ordering.API project (an ASP.NET Core Web API project), as shown in F\", \"igure 7-23. \\n\\nFigure 7-23. The application layer in the Ordering.API ASP.NET Core Web API project \\n\\n\", \"ASP.NET Core includes a simple built-in IoC container (represented by the IServiceProvider interface\", \") \\nthat supports constructor injection by default, and ASP.NET makes certain services available thro\", \"ugh \\nDI. ASP.NET Core uses the term service for any of the types you register that will be injected \", \"through \\nDI. You configure the built-in container\\u2019s services in your application\\u2019s Program.cs file. \", \"Your \\n\\n267 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \", \"\\n \\n \\n\\fdependencies are implemented in the services that a type needs and that you register in the Io\", \"C \\ncontainer. \\n\\nTypically, you want to inject dependencies that implement infrastructure objects. A \", \"typical \\ndependency to inject is a repository. But you could inject any other infrastructure depende\", \"ncy that \\nyou may have. For simpler implementations, you could directly inject your Unit of Work pat\", \"tern object \\n(the EF DbContext object), because the DBContext is also the implementation of your inf\", \"rastructure \\npersistence objects. \\n\\nIn the following example, you can see how .NET is injecting the \", \"required repository objects through \\nthe constructor. The class is a command handler, which will get\", \" covered in the next section. \\n\\npublic class CreateOrderCommandHandler \\n        : IRequestHandler<Cr\", \"eateOrderCommand, bool> \\n{ \\n    private readonly IOrderRepository _orderRepository; \\n    private rea\", \"donly IIdentityService _identityService; \\n    private readonly IMediator _mediator; \\n    private rea\", \"donly IOrderingIntegrationEventService _orderingIntegrationEventService; \\n    private readonly ILogg\", \"er<CreateOrderCommandHandler> _logger; \\n\\n    // Using DI to inject infrastructure persistence Reposi\", \"tories \\n    public CreateOrderCommandHandler(IMediator mediator, \\n        IOrderingIntegrationEventS\", \"ervice orderingIntegrationEventService, \\n        IOrderRepository orderRepository, \\n        IIdentit\", \"yService identityService, \\n        ILogger<CreateOrderCommandHandler> logger) \\n    { \\n        _order\", \"Repository = orderRepository ?? throw new \\nArgumentNullException(nameof(orderRepository)); \\n        \", \"_identityService = identityService ?? throw new \\nArgumentNullException(nameof(identityService)); \\n  \", \"      _mediator = mediator ?? throw new ArgumentNullException(nameof(mediator)); \\n        _orderingI\", \"ntegrationEventService = orderingIntegrationEventService ?? throw new \\nArgumentNullException(nameof(\", \"orderingIntegrationEventService)); \\n        _logger = logger ?? throw new ArgumentNullException(name\", \"of(logger)); \\n    } \\n\\n    public async Task<bool> Handle(CreateOrderCommand message, CancellationTok\", \"en \\ncancellationToken) \\n    { \\n        // Add Integration event to clean the basket \\n        var ord\", \"erStartedIntegrationEvent = new \\nOrderStartedIntegrationEvent(message.UserId); \\n        await \\n_orde\", \"ringIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent); \\n\\n        // Add/Upd\", \"ate the Buyer AggregateRoot \\n        // DDD patterns comment: Add child entities and value-objects t\", \"hrough the Order \\nAggregate-Root \\n        // methods and constructor so validations, invariants and \", \"business logic \\n        // make sure that consistency is preserved across the whole aggregate \\n     \", \"   var address = new Address(message.Street, message.City, message.State, \\nmessage.Country, message.\", \"ZipCode); \\n        var order = new Order(message.UserId, message.UserName, address, \\nmessage.CardTyp\", \"eId, message.CardNumber, message.CardSecurityNumber, message.CardHolderName, \\nmessage.CardExpiration\", \"); \\n\\n        foreach (var item in message.OrderItems) \\n\\n268 \\n\\nCHAPTER 6 | Tackle Business Complexity\", \" in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\f        { \\n            order.AddOrderIt\", \"em(item.ProductId, item.ProductName, item.UnitPrice, \\nitem.Discount, item.PictureUrl, item.Units); \\n\", \"        } \\n\\n        _logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order); \\n\\n     \", \"   _orderRepository.Add(order); \\n\\n        return await _orderRepository.UnitOfWork \\n            .Sav\", \"eEntitiesAsync(cancellationToken); \\n    } \\n} \\n\\nThe class uses the injected repositories to execute t\", \"he transaction and persist the state changes. It \\ndoes not matter whether that class is a command ha\", \"ndler, an ASP.NET Core Web API controller \\nmethod, or a DDD Application Service. It is ultimately a \", \"simple class that uses repositories, domain \\nentities, and other application coordination in a fashi\", \"on similar to a command handler. Dependency \\nInjection works the same way for all the mentioned clas\", \"ses, as in the example using DI based on the \\nconstructor. \\n\\nRegister the dependency implementation \", \"types and interfaces or abstractions \\n\\nBefore you use the objects injected through constructors, you\", \" need to know where to register the \\ninterfaces and classes that produce the objects injected into y\", \"our application classes through DI. (Like \\nDI based on the constructor, as shown previously.) \\n\\nUse \", \"the built-in IoC container provided by ASP.NET Core \\n\\nWhen you use the built-in IoC container provid\", \"ed by ASP.NET Core, you register the types you want \\nto inject in the Program.cs file, as in the fol\", \"lowing code: \\n\\n// Register out-of-the-box framework services. \\nbuilder.Services.AddDbContext<Catalog\", \"Context>(c => \\n    c.UseSqlServer(Configuration[\\\"ConnectionString\\\"]), \\n    ServiceLifetime.Scoped); \", \"\\n\\nbuilder.Services.AddMvc(); \\n// Register custom application dependencies. \\nbuilder.Services.AddScop\", \"ed<IMyCustomRepository, MyCustomSQLRepository>(); \\n\\nThe most common pattern when registering types i\", \"n an IoC container is to register a pair of types\\u2014an \\ninterface and its related implementation class\", \". Then when you request an object from the IoC \\ncontainer through any constructor, you request an ob\", \"ject of a certain type of interface. For instance, in \\nthe previous example, the last line states th\", \"at when any of your constructors have a dependency on \\nIMyCustomRepository (interface or abstraction\", \"), the IoC container will inject an instance of the \\nMyCustomSQLServerRepository implementation clas\", \"s. \\n\\nUse the Scrutor library for automatic types registration \\n\\nWhen using DI in .NET, you might wan\", \"t to be able to scan an assembly and automatically register its \\ntypes by convention. This feature i\", \"s not currently available in ASP.NET Core. However, you can use the \\n\\n269 \\n\\nCHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\fScrutor library for that.\", \" This approach is convenient when you have dozens of types that need to be \\nregistered in your IoC c\", \"ontainer. \\n\\nAdditional resources \\n\\n\\u2022  Matthew King. Registering services with Scrutor \\n\\nhttps://www.\", \"mking.net/blog/registering-services-with-scrutor \\n\\n\\u2022 \\n\\nKristian Hellang. Scrutor. GitHub repo. \\nhttp\", \"s://github.com/khellang/Scrutor \\n\\nUse Autofac as an IoC container \\n\\nYou can also use additional IoC \", \"containers and plug them into the ASP.NET Core pipeline, as in the \\nordering microservice in eShopOn\", \"Containers, which uses Autofac. When using Autofac you typically \\nregister the types via modules, wh\", \"ich allow you to split the registration types between multiple files \\ndepending on where your types \", \"are, just as you could have the application types distributed across \\nmultiple class libraries. \\n\\nFo\", \"r example, the following is the Autofac application module for the Ordering.API Web API project \\nwit\", \"h the types you will want to inject. \\n\\npublic class ApplicationModule : Autofac.Module \\n{ \\n    publi\", \"c string QueriesConnectionString { get; } \\n    public ApplicationModule(string qconstr) \\n    { \\n    \", \"    QueriesConnectionString = qconstr; \\n    } \\n\\n    protected override void Load(ContainerBuilder bu\", \"ilder) \\n    { \\n        builder.Register(c => new OrderQueries(QueriesConnectionString)) \\n           \", \" .As<IOrderQueries>() \\n            .InstancePerLifetimeScope(); \\n        builder.RegisterType<BuyerR\", \"epository>() \\n            .As<IBuyerRepository>() \\n            .InstancePerLifetimeScope(); \\n       \", \" builder.RegisterType<OrderRepository>() \\n            .As<IOrderRepository>() \\n            .Instance\", \"PerLifetimeScope(); \\n        builder.RegisterType<RequestManager>() \\n            .As<IRequestManager\", \">() \\n            .InstancePerLifetimeScope(); \\n   } \\n} \\n\\nAutofac also has a feature to scan assembli\", \"es and register types by name conventions. \\n\\nThe registration process and concepts are very similar \", \"to the way you can register types with the built-\\nin ASP.NET Core IoC container, but the syntax when\", \" using Autofac is a bit different. \\n\\nIn the example code, the abstraction IOrderRepository is regist\", \"ered along with the implementation \\nclass OrderRepository. This means that whenever a constructor is\", \" declaring a dependency through the \\n\\n270 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice\", \" with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fIOrderRepository abstraction or interface, the IoC container wi\", \"ll inject an instance of the \\nOrderRepository class. \\n\\nThe instance scope type determines how an ins\", \"tance is shared between requests for the same service \\nor dependency. When a request is made for a d\", \"ependency, the IoC container can return the following: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nA single instance per lifetime \", \"scope (referred to in the ASP.NET Core IoC container as scoped). \\n\\nA new instance per dependency (re\", \"ferred to in the ASP.NET Core IoC container as transient). \\n\\nA single instance shared across all obj\", \"ects using the IoC container (referred to in the ASP.NET \\nCore IoC container as singleton). \\n\\nAdditi\", \"onal resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nIntroduction to Dependency Injection in ASP.NET Core \\nhttps://learn.mic\", \"rosoft.com/aspnet/core/fundamentals/dependency-injection \\n\\nAutofac. Official documentation. \\nhttps:/\", \"/docs.autofac.org/en/latest/ \\n\\nComparing ASP.NET Core IoC container service lifetimes with Autofac I\", \"oC container \\ninstance scopes - Cesar de la Torre. \\nhttps://devblogs.microsoft.com/cesardelatorre/co\", \"mparing-asp-net-core-ioc-service-life-\\ntimes-and-autofac-ioc-instance-scopes/ \\n\\nImplement the Comman\", \"d and Command Handler patterns \\n\\nIn the DI-through-constructor example shown in the previous section\", \", the IoC container was injecting \\nrepositories through a constructor in a class. But exactly where \", \"were they injected? In a simple Web \\nAPI (for example, the catalog microservice in eShopOnContainers\", \"), you inject them at the MVC \\ncontrollers\\u2019 level, in a controller constructor, as part of the reque\", \"st pipeline of ASP.NET Core. However, \\nin the initial code of this section (the CreateOrderCommandHa\", \"ndler class from the Ordering.API \\nservice in eShopOnContainers), the injection of dependencies is d\", \"one through the constructor of a \\nparticular command handler. Let us explain what a command handler \", \"is and why you would want to \\nuse it. \\n\\nThe Command pattern is intrinsically related to the CQRS pat\", \"tern that was introduced earlier in this \\nguide. CQRS has two sides. The first area is queries, usin\", \"g simplified queries with the Dapper micro \\nORM, which was explained previously. The second area is \", \"commands, which are the starting point for \\ntransactions, and the input channel from outside the ser\", \"vice. \\n\\nAs shown in Figure 7-24, the pattern is based on accepting commands from the client-side, \\np\", \"rocessing them based on the domain model rules, and finally persisting the states with transactions.\", \" \\n\\n271 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\\f\", \"Figure 7-24. High-level view of the commands or \\u201ctransactional side\\u201d in a CQRS pattern \\n\\nFigure 7-24\", \" shows that the UI app sends a command through the API that gets to a \\nCommandHandler, that depends \", \"on the Domain model and the Infrastructure, to update the \\ndatabase. \\n\\nThe command class \\n\\nA command\", \" is a request for the system to perform an action that changes the state of the system. \\nCommands ar\", \"e imperative, and should be processed just once. \\n\\nSince commands are imperatives, they are typicall\", \"y named with a verb in the imperative mood (for \\nexample, \\u201ccreate\\u201d or \\u201cupdate\\u201d), and they might incl\", \"ude the aggregate type, such as \\nCreateOrderCommand. Unlike an event, a command is not a fact from t\", \"he past; it is only a request, \\nand thus may be refused. \\n\\nCommands can originate from the UI as a r\", \"esult of a user initiating a request, or from a process \\nmanager when the process manager is directi\", \"ng an aggregate to perform an action. \\n\\nAn important characteristic of a command is that it should b\", \"e processed just once by a single receiver. \\nThis is because a command is a single action or transac\", \"tion you want to perform in the application. \\nFor example, the same order creation command should no\", \"t be processed more than once. This is an \\nimportant difference between commands and events. Events \", \"may be processed multiple times, \\nbecause many systems or microservices might be interested in the e\", \"vent. \\n\\nIn addition, it is important that a command be processed only once in case the command is no\", \"t \\nidempotent. A command is idempotent if it can be executed multiple times without changing the \\nre\", \"sult, either because of the nature of the command, or because of the way the system handles the \\ncom\", \"mand. \\n\\nIt is a good practice to make your commands and updates idempotent when it makes sense under\", \" \\nyour domain\\u2019s business rules and invariants. For instance, to use the same example, if for any rea\", \"son \\n(retry logic, hacking, etc.) the same CreateOrder command reaches your system multiple times, y\", \"ou \\nshould be able to identify it and ensure that you do not create multiple orders. To do so, you n\", \"eed to \\n\\n272 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\", \"\\n \\n \\n \\n\\fattach some kind of identity in the operations and identify whether the command or update wa\", \"s \\nalready processed. \\n\\nYou send a command to a single receiver; you do not publish a command. Publi\", \"shing is for events \\nthat state a fact\\u2014that something has happened and might be interesting for even\", \"t receivers. In the \\ncase of events, the publisher has no concerns about which receivers get the eve\", \"nt or what they do it. \\nBut domain or integration events are a different story already introduced in\", \" previous sections. \\n\\nA command is implemented with a class that contains data fields or collections\", \" with all the \\ninformation that is needed in order to execute that command. A command is a special k\", \"ind of Data \\nTransfer Object (DTO), one that is specifically used to request changes or transactions\", \". The command \\nitself is based on exactly the information that is needed for processing the command,\", \" and nothing \\nmore. \\n\\nThe following example shows the simplified CreateOrderCommand class. This is a\", \"n immutable \\ncommand that is used in the ordering microservice in eShopOnContainers. \\n\\n// DDD and CQ\", \"RS patterns comment: Note that it is recommended to implement immutable \\nCommands \\n// In this case, \", \"its immutability is achieved by having all the setters as private \\n// plus only being able to update\", \" the data just once, when creating the object through its \\nconstructor. \\n// References on Immutable \", \"Commands: \\n// http://cqrs.nu/Faq \\n// https://docs.spine3.org/motivation/immutability.html \\n// http:/\", \"/blog.gauffin.org/2012/06/griffin-container-introducing-command-support/ \\n// https://learn.microsoft\", \".com/dotnet/csharp/programming-guide/classes-and-structs/how-to-\\nimplement-a-lightweight-class-with-\", \"auto-implemented-properties \\n\\n[DataContract] \\npublic class CreateOrderCommand \\n    : IRequest<bool> \", \"\\n{ \\n    [DataMember] \\n    private readonly List<OrderItemDTO> _orderItems; \\n\\n    [DataMember] \\n    p\", \"ublic string UserId { get; private set; } \\n\\n    [DataMember] \\n    public string UserName { get; priv\", \"ate set; } \\n\\n    [DataMember] \\n    public string City { get; private set; } \\n\\n    [DataMember] \\n    \", \"public string Street { get; private set; } \\n\\n    [DataMember] \\n    public string State { get; privat\", \"e set; } \\n\\n    [DataMember] \\n    public string Country { get; private set; } \\n\\n    [DataMember] \\n   \", \" public string ZipCode { get; private set; } \\n\\n    [DataMember] \\n\\n273 \\n\\nCHAPTER 6 | Tackle Business \", \"Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\f    public string C\", \"ardNumber { get; private set; } \\n\\n    [DataMember] \\n    public string CardHolderName { get; private \", \"set; } \\n\\n    [DataMember] \\n    public DateTime CardExpiration { get; private set; } \\n\\n    [DataMembe\", \"r] \\n    public string CardSecurityNumber { get; private set; } \\n\\n    [DataMember] \\n    public int Ca\", \"rdTypeId { get; private set; } \\n\\n    [DataMember] \\n    public IEnumerable<OrderItemDTO> OrderItems =\", \"> _orderItems; \\n\\n    public CreateOrderCommand() \\n    { \\n        _orderItems = new List<OrderItemDTO\", \">(); \\n    } \\n\\n    public CreateOrderCommand(List<BasketItem> basketItems, string userId, string user\", \"Name, \\nstring city, string street, string state, string country, string zipcode, \\n        string car\", \"dNumber, string cardHolderName, DateTime cardExpiration, \\n        string cardSecurityNumber, int car\", \"dTypeId) : this() \\n    { \\n        _orderItems = basketItems.ToOrderItemsDTO().ToList(); \\n        Use\", \"rId = userId; \\n        UserName = userName; \\n        City = city; \\n        Street = street; \\n       \", \" State = state; \\n        Country = country; \\n        ZipCode = zipcode; \\n        CardNumber = cardNu\", \"mber; \\n        CardHolderName = cardHolderName; \\n        CardExpiration = cardExpiration; \\n        C\", \"ardSecurityNumber = cardSecurityNumber; \\n        CardTypeId = cardTypeId; \\n        CardExpiration = \", \"cardExpiration; \\n    } \\n\\n    public class OrderItemDTO \\n    { \\n        public int ProductId { get; s\", \"et; } \\n\\n        public string ProductName { get; set; } \\n\\n        public decimal UnitPrice { get; se\", \"t; } \\n\\n        public decimal Discount { get; set; } \\n\\n        public int Units { get; set; } \\n\\n    \", \"    public string PictureUrl { get; set; } \\n    } \\n} \\n\\n274 \\n\\nCHAPTER 6 | Tackle Business Complexity \", \"in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fBasically, the comma\", \"nd class contains all the data you need for performing a business transaction by \\nusing the domain m\", \"odel objects. Thus, commands are simply data structures that contain read-only \\ndata, and no behavio\", \"r. The command\\u2019s name indicates its purpose. In many languages like C#, \\ncommands are represented as\", \" classes, but they are not true classes in the real object-oriented sense. \\n\\nAs an additional charac\", \"teristic, commands are immutable, because the expected usage is that they are \\nprocessed directly by\", \" the domain model. They do not need to change during their projected lifetime. \\nIn a C# class, immut\", \"ability can be achieved by not having any setters or other methods that change \\nthe internal state. \", \"\\n\\nKeep in mind that if you intend or expect commands to go through a serializing/deserializing proce\", \"ss, \\nthe properties must have a private setter, and the [DataMember] (or [JsonProperty]) attribute. \", \"\\nOtherwise, the deserializer won\\u2019t be able to reconstruct the object at the destination with the req\", \"uired \\nvalues. You can also use truly read-only properties if the class has a constructor with param\", \"eters for all \\nproperties, with the usual camelCase naming convention, and annotate the constructor \", \"as \\n[JsonConstructor]. However, this option requires more code. \\n\\nFor example, the command class for\", \" creating an order is probably similar in terms of data to the order \\nyou want to create, but you pr\", \"obably do not need the same attributes. For instance, \\nCreateOrderCommand does not have an order ID,\", \" because the order has not been created yet. \\n\\nMany command classes can be simple, requiring only a \", \"few fields about some state that needs to be \\nchanged. That would be the case if you are just changi\", \"ng the status of an order from \\u201cin process\\u201d to \\n\\u201cpaid\\u201d or \\u201cshipped\\u201d by using a command similar to th\", \"e following: \\n\\n[DataContract] \\npublic class UpdateOrderStatusCommand \\n    :IRequest<bool> \\n{ \\n    [D\", \"ataMember] \\n    public string Status { get; private set; } \\n\\n    [DataMember] \\n    public string Ord\", \"erId { get; private set; } \\n\\n    [DataMember] \\n    public string BuyerIdentityGuid { get; private se\", \"t; } \\n} \\n\\nSome developers make their UI request objects separate from their command DTOs, but that i\", \"s just a \\nmatter of preference. It is a tedious separation with not much additional value, and the o\", \"bjects are \\nalmost exactly the same shape. For instance, in eShopOnContainers, some commands come di\", \"rectly \\nfrom the client-side. \\n\\nThe Command handler class \\n\\nYou should implement a specific command \", \"handler class for each command. That is how the pattern \\nworks, and it\\u2019s where you\\u2019ll use the comman\", \"d object, the domain objects, and the infrastructure \\nrepository objects. The command handler is in \", \"fact the heart of the application layer in terms of CQRS \\nand DDD. However, all the domain logic sho\", \"uld be contained in the domain classes\\u2014within the \\naggregate roots (root entities), child entities, \", \"or domain services, but not within the command handler, \\nwhich is a class from the application layer\", \". \\n\\n275 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n\", \" \\n \\n\\fThe command handler class offers a strong stepping stone in the way to achieve the Single \\nResp\", \"onsibility Principle (SRP) mentioned in a previous section. \\n\\nA command handler receives a command a\", \"nd obtains a result from the aggregate that is used. The \\nresult should be either successful executi\", \"on of the command, or an exception. In the case of an \\nexception, the system state should be unchang\", \"ed. \\n\\nThe command handler usually takes the following steps: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nIt receives the c\", \"ommand object, like a DTO (from the mediator or other infrastructure object). \\n\\nIt validates that th\", \"e command is valid (if not validated by the mediator). \\n\\nIt instantiates the aggregate root instance\", \" that is the target of the current command. \\n\\nIt executes the method on the aggregate root instance,\", \" getting the required data from the \\ncommand. \\n\\nIt persists the new state of the aggregate to its re\", \"lated database. This last operation is the \\nactual transaction. \\n\\nTypically, a command handler deals\", \" with a single aggregate driven by its aggregate root (root entity). \\nIf multiple aggregates should \", \"be impacted by the reception of a single command, you could use \\ndomain events to propagate states o\", \"r actions across multiple aggregates. \\n\\nThe important point here is that when a command is being pro\", \"cessed, all the domain logic should be \\ninside the domain model (the aggregates), fully encapsulated\", \" and ready for unit testing. The \\ncommand handler just acts as a way to get the domain model from th\", \"e database, and as the final \\nstep, to tell the infrastructure layer (repositories) to persist the c\", \"hanges when the model is changed. \\nThe advantage of this approach is that you can refactor the domai\", \"n logic in an isolated, fully \\nencapsulated, rich, behavioral domain model without changing code in \", \"the application or \\ninfrastructure layers, which are the plumbing level (command handlers, Web API, \", \"repositories, etc.). \\n\\nWhen command handlers get complex, with too much logic, that can be a code sm\", \"ell. Review them, \\nand if you find domain logic, refactor the code to move that domain behavior to t\", \"he methods of the \\ndomain objects (the aggregate root and child entity). \\n\\nAs an example of a comman\", \"d handler class, the following code shows the same \\nCreateOrderCommandHandler class that you saw at \", \"the beginning of this chapter. In this case, it also \\nhighlights the Handle method and the operation\", \"s with the domain model objects/aggregates. \\n\\npublic class CreateOrderCommandHandler \\n        : IReq\", \"uestHandler<CreateOrderCommand, bool> \\n{ \\n    private readonly IOrderRepository _orderRepository; \\n \", \"   private readonly IIdentityService _identityService; \\n    private readonly IMediator _mediator; \\n \", \"   private readonly IOrderingIntegrationEventService _orderingIntegrationEventService; \\n    private \", \"readonly ILogger<CreateOrderCommandHandler> _logger; \\n\\n    // Using DI to inject infrastructure pers\", \"istence Repositories \\n    public CreateOrderCommandHandler(IMediator mediator, \\n        IOrderingInt\", \"egrationEventService orderingIntegrationEventService, \\n        IOrderRepository orderRepository, \\n\\n2\", \"76 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\f  \", \"      IIdentityService identityService, \\n        ILogger<CreateOrderCommandHandler> logger) \\n    { \\n\", \"        _orderRepository = orderRepository ?? throw new \\nArgumentNullException(nameof(orderRepositor\", \"y)); \\n        _identityService = identityService ?? throw new \\nArgumentNullException(nameof(identity\", \"Service)); \\n        _mediator = mediator ?? throw new ArgumentNullException(nameof(mediator)); \\n    \", \"    _orderingIntegrationEventService = orderingIntegrationEventService ?? throw new \\nArgumentNullExc\", \"eption(nameof(orderingIntegrationEventService)); \\n        _logger = logger ?? throw new ArgumentNull\", \"Exception(nameof(logger)); \\n    } \\n\\n    public async Task<bool> Handle(CreateOrderCommand message, C\", \"ancellationToken \\ncancellationToken) \\n    { \\n        // Add Integration event to clean the basket \\n \", \"       var orderStartedIntegrationEvent = new \\nOrderStartedIntegrationEvent(message.UserId); \\n      \", \"  await \\n_orderingIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent); \\n\\n    \", \"    // Add/Update the Buyer AggregateRoot \\n        // DDD patterns comment: Add child entities and v\", \"alue-objects through the Order \\nAggregate-Root \\n        // methods and constructor so validations, i\", \"nvariants and business logic \\n        // make sure that consistency is preserved across the whole ag\", \"gregate \\n        var address = new Address(message.Street, message.City, message.State, \\nmessage.Cou\", \"ntry, message.ZipCode); \\n        var order = new Order(message.UserId, message.UserName, address, \\nm\", \"essage.CardTypeId, message.CardNumber, message.CardSecurityNumber, message.CardHolderName, \\nmessage.\", \"CardExpiration); \\n\\n        foreach (var item in message.OrderItems) \\n        { \\n            order.Ad\", \"dOrderItem(item.ProductId, item.ProductName, item.UnitPrice, \\nitem.Discount, item.PictureUrl, item.U\", \"nits); \\n        } \\n\\n        _logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\", \" \\n\\n        _orderRepository.Add(order); \\n\\n        return await _orderRepository.UnitOfWork \\n        \", \"    .SaveEntitiesAsync(cancellationToken); \\n    } \\n} \\n\\nThese are additional steps a command handler \", \"should take: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUse the command\\u2019s data to operate with the aggregate root\\u2019s methods and b\", \"ehavior. \\n\\nInternally within the domain objects, raise domain events while the transaction is execut\", \"ed, \\nbut that is transparent from a command handler point of view. \\n\\nIf the aggregate\\u2019s operation re\", \"sult is successful and after the transaction is finished, raise \\nintegration events. (These might al\", \"so be raised by infrastructure classes like repositories.) \\n\\n277 \\n\\nCHAPTER 6 | Tackle Business Compl\", \"exity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\fAdditional resources \\n\\n\\u2022  Mark\", \" Seemann. At the Boundaries, Applications are Not Object-Oriented \\n\\nhttps://blog.ploeh.dk/2011/05/31\", \"/AttheBoundaries,ApplicationsareNotObject-Oriented/ \\n\\n\\u2022 \\n\\nCommands and events \\nhttps://cqrs.nu/faq/C\", \"ommand%20and%20Events \\n\\n\\u2022  What does a command handler do? \\n\\nhttps://cqrs.nu/faq/Command%20Handlers \", \"\\n\\n\\u2022 \\n\\n\\u2022 \\n\\nJimmy Bogard. Domain Command Patterns \\u2013 Handlers \\nhttps://jimmybogard.com/domain-command-p\", \"atterns-handlers/ \\n\\nJimmy Bogard. Domain Command Patterns \\u2013 Validation \\nhttps://jimmybogard.com/doma\", \"in-command-patterns-validation/ \\n\\nThe Command process pipeline: how to trigger a command handler \\n\\nT\", \"he next question is how to invoke a command handler. You could manually call it from each related \\nA\", \"SP.NET Core controller. However, that approach would be too coupled and is not ideal. \\n\\nThe other tw\", \"o main options, which are the recommended options, are: \\n\\n\\u2022 \\n\\nThrough an in-memory Mediator pattern \", \"artifact. \\n\\n\\u2022  With an asynchronous message queue, in between controllers and handlers. \\n\\nUse the Me\", \"diator pattern (in-memory) in the command pipeline \\n\\nAs shown in Figure 7-25, in a CQRS approach you\", \" use an intelligent mediator, similar to an in-memory \\nbus, which is smart enough to redirect to the\", \" right command handler based on the type of the \\ncommand or DTO being received. The single black arr\", \"ows between components represent the \\ndependencies between objects (in many cases, injected through \", \"DI) with their related interactions. \\n\\n278 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservic\", \"e with DDD and CQRS Patterns \\n\\n \\n \\n\\fFigure 7-25. Using the Mediator pattern in process in a single C\", \"QRS microservice \\n\\nThe above diagram shows a zoom-in from image 7-24: the ASP.NET Core controller se\", \"nds the \\ncommand to MediatR\\u2019s command pipeline, so they get to the appropriate handler. \\n\\nThe reason\", \" that using the Mediator pattern makes sense is that in enterprise applications, the \\nprocessing req\", \"uests can get complicated. You want to be able to add an open number of cross-\\ncutting concerns like\", \" logging, validations, audit, and security. In these cases, you can rely on a \\nmediator pipeline (se\", \"e Mediator pattern) to provide a means for these extra behaviors or cross-\\ncutting concerns. \\n\\nA med\", \"iator is an object that encapsulates the \\u201chow\\u201d of this process: it coordinates execution based on \\ns\", \"tate, the way a command handler is invoked, or the payload you provide to the handler. With a \\nmedia\", \"tor component, you can apply cross-cutting concerns in a centralized and transparent way by \\napplyin\", \"g decorators (or pipeline behaviors since MediatR 3). For more information, see the Decorator \\npatte\", \"rn. \\n\\nDecorators and behaviors are similar to Aspect Oriented Programming (AOP), only applied to a \\n\", \"specific process pipeline managed by the mediator component. Aspects in AOP that implement cross-\\ncu\", \"tting concerns are applied based on aspect weavers injected at compilation time or based on object \\n\", \"call interception. Both typical AOP approaches are sometimes said to work \\u201clike magic,\\u201d because it i\", \"s \\nnot easy to see how AOP does its work. When dealing with serious issues or bugs, AOP can be diffi\", \"cult \\nto debug. On the other hand, these decorators/behaviors are explicit and applied only in the c\", \"ontext \\nof the mediator, so debugging is much more predictable and easy. \\n\\nFor example, in the eShop\", \"OnContainers ordering microservice, has an implementation of two sample \\nbehaviors, a LogBehavior cl\", \"ass and a ValidatorBehavior class. The implementation of the behaviors is \\nexplained in the next sec\", \"tion by showing how eShopOnContainers uses MediatR behaviors. \\n\\n279 \\n\\nCHAPTER 6 | Tackle Business Co\", \"mplexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fUse message queues (out-of-proc) in t\", \"he command\\u2019s pipeline \\n\\nAnother choice is to use asynchronous messages based on brokers or message q\", \"ueues, as shown in \\nFigure 7-26. That option could also be combined with the mediator component righ\", \"t before the \\ncommand handler. \\n\\nFigure 7-26. Using message queues (out of the process and inter-pro\", \"cess communication) with CQRS commands \\n\\nCommand\\u2019s pipeline can also be handled by a high availabili\", \"ty message queue to deliver the \\ncommands to the appropriate handler. Using message queues to accept\", \" the commands can further \\ncomplicate your command\\u2019s pipeline, because you will probably need to spl\", \"it the pipeline into two \\nprocesses connected through the external message queue. Still, it should b\", \"e used if you need to have \\nimproved scalability and performance based on asynchronous messaging. Co\", \"nsider that in the case of \\nFigure 7-26, the controller just posts the command message into the queu\", \"e and returns. Then the \\ncommand handlers process the messages at their own pace. That is a great be\", \"nefit of queues: the \\nmessage queue can act as a buffer in cases when hyper scalability is needed, s\", \"uch as for stocks or any \\nother scenario with a high volume of ingress data. \\n\\nHowever, because of t\", \"he asynchronous nature of message queues, you need to figure out how to \\ncommunicate with the client\", \" application about the success or failure of the command\\u2019s process. As a \\nrule, you should never use\", \" \\u201cfire and forget\\u201d commands. Every business application needs to know if a \\ncommand was processed su\", \"ccessfully, or at least validated and accepted. \\n\\nThus, being able to respond to the client after va\", \"lidating a command message that was submitted to \\nan asynchronous queue adds complexity to your syst\", \"em, as compared to an in-process command \\nprocess that returns the operation\\u2019s result after running \", \"the transaction. Using queues, you might \\nneed to return the result of the command process through o\", \"ther operation result messages, which will \\nrequire additional components and custom communication i\", \"n your system. \\n\\n280 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Pa\", \"tterns \\n\\n \\n \\n \\n\\fAdditionally, async commands are one-way commands, which in many cases might not be \", \"needed, as \\nis explained in the following interesting exchange between Burtsev Alexey and Greg Young\", \" in an \\nonline conversation: \\n\\n[Burtsev Alexey] I find lots of code where people use async command h\", \"andling or one-way command \\nmessaging without any reason to do so (they are not doing some long oper\", \"ation, they are not \\nexecuting external async code, they do not even cross-application boundary to b\", \"e using message \\nbus). Why do they introduce this unnecessary complexity? And actually, I haven\\u2019t se\", \"en a CQRS code \\nexample with blocking command handlers so far, though it will work just fine in most\", \" cases. \\n\\n[Greg Young] [\\u2026] an asynchronous command doesn\\u2019t exist; it\\u2019s actually another event. If I \", \"must accept \\nwhat you send me and raise an event if I disagree, it\\u2019s no longer you telling me to do \", \"something [that \\nis, it\\u2019s not a command]. It\\u2019s you telling me something has been done. This seems li\", \"ke a slight \\ndifference at first, but it has many implications. \\n\\nAsynchronous commands greatly incr\", \"ease the complexity of a system, because there is no simple way \\nto indicate failures. Therefore, as\", \"ynchronous commands are not recommended other than when \\nscaling requirements are needed or in speci\", \"al cases when communicating the internal microservices \\nthrough messaging. In those cases, you must \", \"design a separate reporting and recovery system for \\nfailures. \\n\\nIn the initial version of eShopOnCo\", \"ntainers, it was decided to use synchronous command processing, \\nstarted from HTTP requests and driv\", \"en by the Mediator pattern. That easily allows you to return the \\nsuccess or failure of the process,\", \" as in the CreateOrderCommandHandler implementation. \\n\\nIn any case, this should be a decision based \", \"on your application\\u2019s or microservice\\u2019s business \\nrequirements. \\n\\nImplement the command process pipe\", \"line with a mediator pattern \\n(MediatR) \\n\\nAs a sample implementation, this guide proposes using the \", \"in-process pipeline based on the Mediator \\npattern to drive command ingestion and route commands, in\", \" memory, to the right command \\nhandlers. The guide also proposes applying behaviors in order to sepa\", \"rate cross-cutting concerns. \\n\\nFor implementation in .NET, there are multiple open-source libraries \", \"available that implement the \\nMediator pattern. The library used in this guide is the MediatR open-s\", \"ource library (created by Jimmy \\nBogard), but you could use another approach. MediatR is a small and\", \" simple library that allows you to \\nprocess in-memory messages like a command, while applying decora\", \"tors or behaviors. \\n\\nUsing the Mediator pattern helps you to reduce coupling and to isolate the conc\", \"erns of the requested \\nwork, while automatically connecting to the handler that performs that work\\u2014i\", \"n this case, to \\ncommand handlers. \\n\\nAnother good reason to use the Mediator pattern was explained b\", \"y Jimmy Bogard when reviewing \\nthis guide: \\n\\n281 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Micro\", \"service with DDD and CQRS Patterns \\n\\n \\n \\n\\fI think it might be worth mentioning testing here \\u2013 it pro\", \"vides a nice consistent window into the \\nbehavior of your system. Request-in, response-out. We\\u2019ve fo\", \"und that aspect quite valuable in building \\nconsistently behaving tests. \\n\\nFirst, let\\u2019s look at a sa\", \"mple WebAPI controller where you actually would use the mediator object. If \\nyou weren\\u2019t using the m\", \"ediator object, you\\u2019d need to inject all the dependencies for that controller, \\nthings like a logger\", \" object and others. Therefore, the constructor would be complicated. On the other \\nhand, if you use \", \"the mediator object, the constructor of your controller can be a lot simpler, with just a \\nfew depen\", \"dencies instead of many dependencies if you had one per cross-cutting operation, as in the \\nfollowin\", \"g example: \\n\\npublic class MyMicroserviceController : Controller \\n{ \\n    public MyMicroserviceControl\", \"ler(IMediator mediator, \\n                                    IMyMicroserviceQueries microserviceQuer\", \"ies) \\n    { \\n        // ... \\n    } \\n} \\n\\nYou can see that the mediator provides a clean and lean Web \", \"API controller constructor. In addition, \\nwithin the controller methods, the code to send a command \", \"to the mediator object is almost one line: \\n\\n[Route(\\\"new\\\")] \\n[HttpPost] \\npublic async Task<IActionRe\", \"sult> ExecuteBusinessOperation([FromBody]RunOpCommand \\n                                             \", \"                  runOperationCommand) \\n{ \\n    var commandResult = await _mediator.SendAsync(runOper\", \"ationCommand); \\n\\n    return commandResult ? (IActionResult)Ok() : (IActionResult)BadRequest(); \\n} \\n\\n\", \"Implement idempotent Commands \\n\\nIn eShopOnContainers, a more advanced example than the above is subm\", \"itting a \\nCreateOrderCommand object from the Ordering microservice. But since the Ordering business \", \"\\nprocess is a bit more complex and, in our case, it actually starts in the Basket microservice, this\", \" action \\nof submitting the CreateOrderCommand object is performed from an integration-event handler \", \"\\nnamed UserCheckoutAcceptedIntegrationEventHandler instead of a simple WebAPI controller called \\nfro\", \"m the client App as in the previous simpler example. \\n\\nNevertheless, the action of submitting the Co\", \"mmand to MediatR is pretty similar, as shown in the \\nfollowing code. \\n\\nvar createOrderCommand = new \", \"CreateOrderCommand(eventMsg.Basket.Items, \\n                                                eventMsg.\", \"UserId, eventMsg.City, \\n                                                eventMsg.Street, eventMsg.St\", \"ate, \\n                                                eventMsg.Country, eventMsg.ZipCode, \\n         \", \"                                       eventMsg.CardNumber, \\n                                       \", \"         eventMsg.CardHolderName, \\n                                                eventMsg.CardExpi\", \"ration, \\n                                                eventMsg.CardSecurityNumber, \\n             \", \"                                   eventMsg.CardTypeId); \\n\\n282 \\n\\nCHAPTER 6 | Tackle Business Complex\", \"ity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\fvar requestCreateOrder = new IdentifiedCom\", \"mand<CreateOrderCommand,bool>(createOrderCommand, \\n\\neventMsg.RequestId); \\nresult = await _mediator.S\", \"end(requestCreateOrder); \\n\\nHowever, this case is also slightly more advanced because we\\u2019re also impl\", \"ementing idempotent \\ncommands. The CreateOrderCommand process should be idempotent, so if the same m\", \"essage comes \\nduplicated through the network, because of any reason, like retries, the same business\", \" order will be \\nprocessed just once. \\n\\nThis is implemented by wrapping the business command (in this\", \" case CreateOrderCommand) and \\nembedding it into a generic IdentifiedCommand, which is tracked by an\", \" ID of every message coming \\nthrough the network that has to be idempotent. \\n\\nIn the code below, you\", \" can see that the IdentifiedCommand is nothing more than a DTO with and ID \\nplus the wrapped busines\", \"s command object. \\n\\npublic class IdentifiedCommand<T, R> : IRequest<R> \\n    where T : IRequest<R> \\n{\", \" \\n    public T Command { get; } \\n    public Guid Id { get; } \\n    public IdentifiedCommand(T command\", \", Guid id) \\n    { \\n        Command = command; \\n        Id = id; \\n    } \\n} \\n\\nThen the CommandHandler \", \"for the IdentifiedCommand named IdentifiedCommandHandler.cs will \\nbasically check if the ID coming a\", \"s part of the message already exists in a table. If it already exists, that \\ncommand won\\u2019t be proces\", \"sed again, so it behaves as an idempotent command. That infrastructure \\ncode is performed by the _re\", \"questManager.ExistAsync method call below. \\n\\n// IdentifiedCommandHandler.cs \\npublic class Identified\", \"CommandHandler<T, R> : IRequestHandler<IdentifiedCommand<T, R>, R> \\n        where T : IRequest<R> \\n{\", \" \\n    private readonly IMediator _mediator; \\n    private readonly IRequestManager _requestManager; \\n\", \"    private readonly ILogger<IdentifiedCommandHandler<T, R>> _logger; \\n\\n    public IdentifiedCommand\", \"Handler( \\n        IMediator mediator, \\n        IRequestManager requestManager, \\n        ILogger<Iden\", \"tifiedCommandHandler<T, R>> logger) \\n    { \\n        _mediator = mediator; \\n        _requestManager =\", \" requestManager; \\n        _logger = logger ?? throw new System.ArgumentNullException(nameof(logger))\", \"; \\n    } \\n\\n    /// <summary> \\n    /// Creates the result value to return if a previous request was f\", \"ound \\n    /// </summary> \\n    /// <returns></returns> \\n\\n283 \\n\\nCHAPTER 6 | Tackle Business Complexity\", \" in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n                                              \", \"                          \\n \\n \\n\\f    protected virtual R CreateResultForDuplicateRequest() \\n    { \\n  \", \"      return default(R); \\n    } \\n\\n    /// <summary> \\n    /// This method handles the command. It jus\", \"t ensures that no other request exists with \\nthe same ID, and if this is the case \\n    /// just enqu\", \"eues the original inner command. \\n    /// </summary> \\n    /// <param name=\\\"message\\\">IdentifiedComman\", \"d which contains both original command & \\nrequest ID</param> \\n    /// <returns>Return value of inner\", \" command or default value if request same ID was \\nfound</returns> \\n    public async Task<R> Handle(I\", \"dentifiedCommand<T, R> message, CancellationToken \\ncancellationToken) \\n    { \\n        var alreadyExi\", \"sts = await _requestManager.ExistAsync(message.Id); \\n        if (alreadyExists) \\n        { \\n        \", \"    return CreateResultForDuplicateRequest(); \\n        } \\n        else \\n        { \\n            await\", \" _requestManager.CreateRequestForCommandAsync<T>(message.Id); \\n            try \\n            { \\n     \", \"           var command = message.Command; \\n                var commandName = command.GetGenericTypeN\", \"ame(); \\n                var idProperty = string.Empty; \\n                var commandId = string.Empty\", \"; \\n\\n                switch (command) \\n                { \\n                    case CreateOrderCommand\", \" createOrderCommand: \\n                        idProperty = nameof(createOrderCommand.UserId); \\n     \", \"                   commandId = createOrderCommand.UserId; \\n                        break; \\n\\n        \", \"            case CancelOrderCommand cancelOrderCommand: \\n                        idProperty = nameof\", \"(cancelOrderCommand.OrderNumber); \\n                        commandId = $\\\"{cancelOrderCommand.OrderNu\", \"mber}\\\"; \\n                        break; \\n\\n                    case ShipOrderCommand shipOrderCommand\", \": \\n                        idProperty = nameof(shipOrderCommand.OrderNumber); \\n                     \", \"   commandId = $\\\"{shipOrderCommand.OrderNumber}\\\"; \\n                        break; \\n\\n                \", \"    default: \\n                        idProperty = \\\"Id?\\\"; \\n                        commandId = \\\"n/a\\\"\", \"; \\n                        break; \\n                } \\n\\n                _logger.LogInformation( \\n    \", \"                \\\"----- Sending command: {CommandName} - {IdProperty}: {CommandId} \\n({@Command})\\\", \\n \", \"                   commandName, \\n                    idProperty, \\n                    commandId, \\n\\n2\", \"84 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \", \"\\n \\n \\n \\n\\f                    command); \\n\\n                // Send the embedded business command to med\", \"iator so it runs its related \\nCommandHandler \\n                var result = await _mediator.Send(comm\", \"and, cancellationToken); \\n\\n                _logger.LogInformation( \\n                    \\\"----- Comma\", \"nd result: {@Result} - {CommandName} - {IdProperty}: \\n{CommandId} ({@Command})\\\", \\n                  \", \"  result, \\n                    commandName, \\n                    idProperty, \\n                    co\", \"mmandId, \\n                    command); \\n\\n                return result; \\n            } \\n           \", \" catch \\n            { \\n                return default(R); \\n            } \\n        } \\n    } \\n} \\n\\nSinc\", \"e the IdentifiedCommand acts like a business command\\u2019s envelope, when the business command \\nneeds to\", \" be processed because it is not a repeated ID, then it takes that inner business command and \\nresubm\", \"its it to Mediator, as in the last part of the code shown above when running \\n_mediator.Send(message\", \".Command), from the IdentifiedCommandHandler.cs. \\n\\nWhen doing that, it will link and run the busines\", \"s command handler, in this case, the \\nCreateOrderCommandHandler, which is running transactions again\", \"st the Ordering database, as shown \\nin the following code. \\n\\n// CreateOrderCommandHandler.cs \\npublic\", \" class CreateOrderCommandHandler \\n        : IRequestHandler<CreateOrderCommand, bool> \\n{ \\n    privat\", \"e readonly IOrderRepository _orderRepository; \\n    private readonly IIdentityService _identityServic\", \"e; \\n    private readonly IMediator _mediator; \\n    private readonly IOrderingIntegrationEventService\", \" _orderingIntegrationEventService; \\n    private readonly ILogger<CreateOrderCommandHandler> _logger;\", \" \\n\\n    // Using DI to inject infrastructure persistence Repositories \\n    public CreateOrderCommandH\", \"andler(IMediator mediator, \\n        IOrderingIntegrationEventService orderingIntegrationEventService\", \", \\n        IOrderRepository orderRepository, \\n        IIdentityService identityService, \\n        ILo\", \"gger<CreateOrderCommandHandler> logger) \\n    { \\n        _orderRepository = orderRepository ?? throw \", \"new \\nArgumentNullException(nameof(orderRepository)); \\n        _identityService = identityService ?? \", \"throw new \\nArgumentNullException(nameof(identityService)); \\n        _mediator = mediator ?? throw ne\", \"w ArgumentNullException(nameof(mediator)); \\n        _orderingIntegrationEventService = orderingInteg\", \"rationEventService ?? throw new \\nArgumentNullException(nameof(orderingIntegrationEventService)); \\n  \", \"      _logger = logger ?? throw new ArgumentNullException(nameof(logger)); \\n\\n285 \\n\\nCHAPTER 6 | Tackl\", \"e Business Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\f    } \\n\\n    public\", \" async Task<bool> Handle(CreateOrderCommand message, CancellationToken \\ncancellationToken) \\n    { \\n \", \"       // Add Integration event to clean the basket \\n        var orderStartedIntegrationEvent = new \", \"\\nOrderStartedIntegrationEvent(message.UserId); \\n        await \\n_orderingIntegrationEventService.AddA\", \"ndSaveEventAsync(orderStartedIntegrationEvent); \\n\\n        // Add/Update the Buyer AggregateRoot \\n   \", \"     // DDD patterns comment: Add child entities and value-objects through the Order \\nAggregate-Root\", \" \\n        // methods and constructor so validations, invariants and business logic \\n        // make \", \"sure that consistency is preserved across the whole aggregate \\n        var address = new Address(mes\", \"sage.Street, message.City, message.State, \\nmessage.Country, message.ZipCode); \\n        var order = n\", \"ew Order(message.UserId, message.UserName, address, \\nmessage.CardTypeId, message.CardNumber, message\", \".CardSecurityNumber, message.CardHolderName, \\nmessage.CardExpiration); \\n\\n        foreach (var item i\", \"n message.OrderItems) \\n        { \\n            order.AddOrderItem(item.ProductId, item.ProductName, i\", \"tem.UnitPrice, \\nitem.Discount, item.PictureUrl, item.Units); \\n        } \\n\\n        _logger.LogInforma\", \"tion(\\\"----- Creating Order - Order: {@Order}\\\", order); \\n\\n        _orderRepository.Add(order); \\n\\n    \", \"    return await _orderRepository.UnitOfWork \\n            .SaveEntitiesAsync(cancellationToken); \\n  \", \"  } \\n} \\n\\nRegister the types used by MediatR \\n\\nIn order for MediatR to be aware of your command handl\", \"er classes, you need to register the mediator \\nclasses and the command handler classes in your IoC c\", \"ontainer. By default, MediatR uses Autofac as \\nthe IoC container, but you can also use the built-in \", \"ASP.NET Core IoC container or any other container \\nsupported by MediatR. \\n\\nThe following code shows \", \"how to register Mediator\\u2019s types and commands when using Autofac \\nmodules. \\n\\npublic class MediatorMo\", \"dule : Autofac.Module \\n{ \\n    protected override void Load(ContainerBuilder builder) \\n    { \\n       \", \" builder.RegisterAssemblyTypes(typeof(IMediator).GetTypeInfo().Assembly) \\n            .AsImplemented\", \"Interfaces(); \\n\\n        // Register all the Command classes (they implement IRequestHandler) \\n      \", \"  // in assembly holding the Commands \\n        builder.RegisterAssemblyTypes(typeof(CreateOrderComma\", \"nd).GetTypeInfo().Assembly) \\n                .AsClosedTypesOf(typeof(IRequestHandler<,>)); \\n        \", \"// Other types registration \\n\\n286 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DD\", \"D and CQRS Patterns \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\f        //... \\n    } \\n} \\n\\nThis is where \\u201cthe magic happens\\u201d\", \" with MediatR. \\n\\nAs each command handler implements the generic IRequestHandler<T> interface, when y\", \"ou register \\nthe assemblies using RegisteredAssemblyTypes method all the types marked as IRequestHan\", \"dler also \\ngets registered with their Commands. For example: \\n\\npublic class CreateOrderCommandHandle\", \"r \\n  : IRequestHandler<CreateOrderCommand, bool> \\n{ \\n\\nThat is the code that correlates commands with\", \" command handlers. The handler is just a simple class, \\nbut it inherits from RequestHandler<T>, wher\", \"e T is the command type, and MediatR makes sure it is \\ninvoked with the correct payload (the command\", \"). \\n\\nApply cross-cutting concerns when processing commands with the \\nBehaviors in MediatR \\n\\nThere is\", \" one more thing: being able to apply cross-cutting concerns to the mediator pipeline. You can \\nalso \", \"see at the end of the Autofac registration module code how it registers a behavior type, \\nspecifical\", \"ly, a custom LoggingBehavior class and a ValidatorBehavior class. But you could add other \\ncustom be\", \"haviors, too. \\n\\npublic class MediatorModule : Autofac.Module \\n{ \\n    protected override void Load(Co\", \"ntainerBuilder builder) \\n    { \\n        builder.RegisterAssemblyTypes(typeof(IMediator).GetTypeInfo(\", \").Assembly) \\n            .AsImplementedInterfaces(); \\n\\n        // Register all the Command classes (\", \"they implement IRequestHandler) \\n        // in assembly holding the Commands \\n        builder.Regist\", \"erAssemblyTypes( \\n                              typeof(CreateOrderCommand).GetTypeInfo().Assembly). \", \"\\n                                   AsClosedTypesOf(typeof(IRequestHandler<,>)); \\n        // Other t\", \"ypes registration \\n        //... \\n        builder.RegisterGeneric(typeof(LoggingBehavior<,>)). \\n    \", \"                                               As(typeof(IPipelineBehavior<,>)); \\n        builder.Re\", \"gisterGeneric(typeof(ValidatorBehavior<,>)). \\n                                                   As(\", \"typeof(IPipelineBehavior<,>)); \\n    } \\n} \\n\\nThat LoggingBehavior class can be implemented as the foll\", \"owing code, which logs information about \\nthe command handler being executed and whether it was succ\", \"essful or not. \\n\\npublic class LoggingBehavior<TRequest, TResponse> \\n         : IPipelineBehavior<TRe\", \"quest, TResponse> \\n{ \\n    private readonly ILogger<LoggingBehavior<TRequest, TResponse>> _logger; \\n \", \"   public LoggingBehavior(ILogger<LoggingBehavior<TRequest, TResponse>> logger) => \\n                \", \"                                                  _logger = logger; \\n\\n287 \\n\\nCHAPTER 6 | Tackle Busin\", \"ess Complexity in a Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n\\f    public async Task<TResponse\", \"> Handle(TRequest request, \\n                                        RequestHandlerDelegate<TResponse\", \"> next) \\n    { \\n        _logger.LogInformation($\\\"Handling {typeof(TRequest).Name}\\\"); \\n        var re\", \"sponse = await next(); \\n        _logger.LogInformation($\\\"Handled {typeof(TResponse).Name}\\\"); \\n      \", \"  return response; \\n    } \\n} \\n\\nJust by implementing this behavior class and by registering it in the\", \" pipeline (in the MediatorModule \\nabove), all the commands processed through MediatR will be logging\", \" information about the \\nexecution. \\n\\nThe eShopOnContainers ordering microservice also applies a seco\", \"nd behavior for basic validations, \\nthe ValidatorBehavior class that relies on the FluentValidation \", \"library, as shown in the following code: \\n\\npublic class ValidatorBehavior<TRequest, TResponse> \\n    \", \"     : IPipelineBehavior<TRequest, TResponse> \\n{ \\n    private readonly IValidator<TRequest>[] _valid\", \"ators; \\n    public ValidatorBehavior(IValidator<TRequest>[] validators) => \\n                        \", \"                                 _validators = validators; \\n\\n    public async Task<TResponse> Handle\", \"(TRequest request, \\n                                        RequestHandlerDelegate<TResponse> next) \", \"\\n    { \\n        var failures = _validators \\n            .Select(v => v.Validate(request)) \\n         \", \"   .SelectMany(result => result.Errors) \\n            .Where(error => error != null) \\n            .To\", \"List(); \\n\\n        if (failures.Any()) \\n        { \\n            throw new OrderingDomainException( \\n  \", \"              $\\\"Command Validation Errors for type {typeof(TRequest).Name}\\\", \\n                      \", \"  new ValidationException(\\\"Validation exception\\\", failures)); \\n        } \\n\\n        var response = aw\", \"ait next(); \\n        return response; \\n    } \\n} \\n\\nHere the behavior is raising an exception if valid\", \"ation fails, but you could also return a result object, \\ncontaining the command result if it succeed\", \"ed or the validation messages in case it didn\\u2019t. This would \\nprobably make it easier to display vali\", \"dation results to the user. \\n\\nThen, based on the FluentValidation library, you would create validati\", \"on for the data passed with \\nCreateOrderCommand, as in the following code: \\n\\npublic class CreateOrde\", \"rCommandValidator : AbstractValidator<CreateOrderCommand> \\n{ \\n    public CreateOrderCommandValidator\", \"() \\n    { \\n        RuleFor(command => command.City).NotEmpty(); \\n        RuleFor(command => command.\", \"Street).NotEmpty(); \\n\\n288 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQ\", \"RS Patterns \\n\\n \\n \\n \\n \\n \\n \\n\\f        RuleFor(command => command.State).NotEmpty(); \\n        RuleFor(co\", \"mmand => command.Country).NotEmpty(); \\n        RuleFor(command => command.ZipCode).NotEmpty(); \\n    \", \"    RuleFor(command => command.CardNumber).NotEmpty().Length(12, 19); \\n        RuleFor(command => co\", \"mmand.CardHolderName).NotEmpty(); \\n        RuleFor(command => \\ncommand.CardExpiration).NotEmpty().Mu\", \"st(BeValidExpirationDate).WithMessage(\\\"Please specify \\na valid card expiration date\\\"); \\n        Rule\", \"For(command => command.CardSecurityNumber).NotEmpty().Length(3); \\n        RuleFor(command => command\", \".CardTypeId).NotEmpty(); \\n        RuleFor(command => command.OrderItems).Must(ContainOrderItems).Wit\", \"hMessage(\\\"No \\norder items found\\\"); \\n    } \\n\\n    private bool BeValidExpirationDate(DateTime dateTime\", \") \\n    { \\n        return dateTime >= DateTime.UtcNow; \\n    } \\n\\n    private bool ContainOrderItems(IE\", \"numerable<OrderItemDTO> orderItems) \\n    { \\n        return orderItems.Any(); \\n    } \\n} \\n\\nYou could c\", \"reate additional validations. This is a very clean and elegant way to implement your \\ncommand valida\", \"tions. \\n\\nIn a similar way, you could implement other behaviors for additional aspects or cross-cutti\", \"ng concerns \\nthat you want to apply to commands when handling them. \\n\\nAdditional resources \\n\\nThe med\", \"iator pattern \\n\\n\\u2022  Mediator pattern \\n\\nhttps://en.wikipedia.org/wiki/Mediator_pattern \\n\\nThe decorator\", \" pattern \\n\\n\\u2022 \\n\\nDecorator pattern \\nhttps://en.wikipedia.org/wiki/Decorator_pattern \\n\\nMediatR (Jimmy B\", \"ogard) \\n\\n\\u2022  MediatR. GitHub repo. \\n\\nhttps://github.com/jbogard/MediatR \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCQRS with MediatR a\", \"nd AutoMapper \\nhttps://lostechies.com/jimmybogard/2015/05/05/cqrs-with-mediatr-and-automapper/ \\n\\nPut\", \" your controllers on a diet: POSTs and commands. \\nhttps://lostechies.com/jimmybogard/2013/12/19/put-\", \"your-controllers-on-a-diet-posts-and-\\ncommands/ \\n\\n289 \\n\\nCHAPTER 6 | Tackle Business Complexity in a \", \"Microservice with DDD and CQRS Patterns \\n\\n \\n \\n \\n \\n\\f\\u2022 \\n\\n\\u2022 \\n\\nTackling cross-cutting concerns with a me\", \"diator pipeline \\nhttps://lostechies.com/jimmybogard/2014/09/09/tackling-cross-cutting-concerns-with-\", \"a-\\nmediator-pipeline/ \\n\\nCQRS and REST: the perfect match \\nhttps://lostechies.com/jimmybogard/2016/06\", \"/01/cqrs-and-rest-the-perfect-match/ \\n\\n\\u2022  MediatR Pipeline Examples \\n\\nhttps://lostechies.com/jimmybo\", \"gard/2016/10/13/mediatr-pipeline-examples/ \\n\\n\\u2022 \\n\\nVertical Slice Test Fixtures for MediatR and ASP.NE\", \"T Core \\nhttps://lostechies.com/jimmybogard/2016/10/24/vertical-slice-test-fixtures-for-mediatr-and-\\n\", \"asp-net-core/ \\n\\n\\u2022  MediatR Extensions for Microsoft Dependency Injection Released \\n\\nhttps://lostechi\", \"es.com/jimmybogard/2016/07/19/mediatr-extensions-for-microsoft-\\ndependency-injection-released/ \\n\\nFlu\", \"ent validation \\n\\n\\u2022 \\n\\nJeremy Skinner. FluentValidation. GitHub repo. \\nhttps://github.com/JeremySkinne\", \"r/FluentValidation \\n\\n290 \\n\\nCHAPTER 6 | Tackle Business Complexity in a Microservice with DDD and CQR\", \"S Patterns \\n\\n \\n \\n\\fCHAPTER  7 \\n\\nImplement resilient \\napplications \\n\\nYour microservice and cloud-based\", \" applications must embrace the partial failures that will certainly \\noccur eventually. You must desi\", \"gn your application to be resilient to those partial failures. \\n\\nResiliency is the ability to recove\", \"r from failures and continue to function. It isn\\u2019t about avoiding \\nfailures but accepting the fact t\", \"hat failures will happen and responding to them in a way that avoids \\ndowntime or data loss. The goa\", \"l of resiliency is to return the application to a fully functioning state \\nafter a failure. \\n\\nIt\\u2019s c\", \"hallenging enough to design and deploy a microservices-based application. But you also need to \\nkeep\", \" your application running in an environment where some sort of failure is certain. Therefore, your \\n\", \"application should be resilient. It should be designed to cope with partial failures, like network \\n\", \"outages or nodes or VMs crashing in the cloud. Even microservices (containers) being moved to a \\ndif\", \"ferent node within a cluster can cause intermittent short failures within the application. \\n\\nThe man\", \"y individual components of your application should also incorporate health monitoring \\nfeatures. By \", \"following the guidelines in this chapter, you can create an application that can work \\nsmoothly in s\", \"pite of transient downtime or the normal hiccups that occur in complex and cloud-based \\ndeployments.\", \" \\n\\nImportant \\n\\neShopOnContainer had been using the Polly library to implement resiliency using Typed\", \" Clients up \\nuntil the release 3.0.0. \\n\\nStarting with release 3.0.0, the HTTP calls resiliency is im\", \"plemented using a Linkerd mesh, that handles \\nretries in a transparent and configurable fashion, wit\", \"hin a Kubernetes cluster, without having to \\nhandle those concerns in the code. \\n\\nThe Polly library \", \"is still used to add resilience to database connections, specially while starting up the \\nservices. \", \"\\n\\nWarning \\n\\nAll code samples and images in this section were valid before using Linkerd and are not \", \"updated to \\nreflect the current actual code. So they make sense in the context of this section. \\n\\n29\", \"1 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n\\fHandle partial failure \\n\\nIn distributed \", \"systems like microservices-based applications, there\\u2019s an ever-present risk of partial \\nfailure. For\", \" instance, a single microservice/container can fail or might not be available to respond for a \\nshor\", \"t time, or a single VM or server can crash. Since clients and services are separate processes, a \\nse\", \"rvice might not be able to respond in a timely way to a client\\u2019s request. The service might be \\nover\", \"loaded and responding very slowly to requests or might simply not be accessible for a short time \\nbe\", \"cause of network issues. \\n\\nFor example, consider the Order details page from the eShopOnContainers s\", \"ample application. If the \\nordering microservice is unresponsive when the user tries to submit an or\", \"der, a bad implementation \\nof the client process (the MVC web application)\\u2014for example, if the clien\", \"t code were to use \\nsynchronous RPCs with no timeout\\u2014would block threads indefinitely waiting for a \", \"response. Besides \\ncreating a bad user experience, every unresponsive wait consumes or blocks a thre\", \"ad, and threads are \\nextremely valuable in highly scalable applications. If there are many blocked t\", \"hreads, eventually the \\napplication\\u2019s runtime can run out of threads. In that case, the application \", \"can become globally \\nunresponsive instead of just partially unresponsive, as shown in Figure 8-1. \\n\\n\", \"Figure 8-1. Partial failures because of dependencies that impact service thread availability \\n\\nIn a \", \"large microservices-based application, any partial failure can be amplified, especially if most of \\n\", \"the internal microservices interaction is based on synchronous HTTP calls (which is considered an an\", \"ti-\\npattern). Think about a system that receives millions of incoming calls per day. If your system \", \"has a \\nbad design that\\u2019s based on long chains of synchronous HTTP calls, these incoming calls might \", \"result in \\nmany more millions of outgoing calls (let\\u2019s suppose a ratio of 1:4) to dozens of internal\", \" microservices \\nas synchronous dependencies. This situation is shown in Figure 8-2, especially depen\", \"dency #3, that \\nstarts a chain, calling dependency #4, which then calls #5. \\n\\n292 \\n\\nCHAPTER 7 | Impl\", \"ement resilient applications \\n\\n \\n \\n \\n\\fFigure 8-2. The impact of having an incorrect design featuring\", \" long chains of HTTP requests \\n\\nIntermittent failure is guaranteed in a distributed and cloud-based \", \"system, even if every dependency \\nitself has excellent availability. It\\u2019s a fact you need to conside\", \"r. \\n\\nIf you do not design and implement techniques to ensure fault tolerance, even small downtimes c\", \"an \\nbe amplified. As an example, 50 dependencies each with 99.99% of availability would result in se\", \"veral \\nhours of downtime each month because of this ripple effect. When a microservice dependency fa\", \"ils \\nwhile handling a high volume of requests, that failure can quickly saturate all available reque\", \"st threads \\nin each service and crash the whole application. \\n\\nFigure 8-3. Partial failure amplified\", \" by microservices with long chains of synchronous HTTP calls \\n\\n293 \\n\\nCHAPTER 7 | Implement resilient\", \" applications \\n\\n \\n \\n \\n \\n\\fTo minimize this problem, in the section Asynchronous microservice integrat\", \"ion enforce microservice\\u2019s \\nautonomy, this guide encourages you to use asynchronous communication ac\", \"ross the internal \\nmicroservices. \\n\\nIn addition, it\\u2019s essential that you design your microservices a\", \"nd client applications to handle partial \\nfailures\\u2014that is, to build resilient microservices and cli\", \"ent applications. \\n\\nStrategies to handle partial failure \\n\\nTo deal with partial failures, use one of\", \" the strategies described here. \\n\\nUse asynchronous communication (for example, message-based communi\", \"cation) across \\ninternal microservices. It\\u2019s highly advisable not to create long chains of synchrono\", \"us HTTP calls \\nacross the internal microservices because that incorrect design will eventually becom\", \"e the main cause \\nof bad outages. On the contrary, except for the front-end communications between t\", \"he client \\napplications and the first level of microservices or fine-grained API Gateways, it\\u2019s reco\", \"mmended to use \\nonly asynchronous (message-based) communication once past the initial request/respon\", \"se cycle, \\nacross the internal microservices. Eventual consistency and event-driven architectures wi\", \"ll help to \\nminimize ripple effects. These approaches enforce a higher level of microservice autonom\", \"y and \\ntherefore prevent against the problem noted here. \\n\\nUse retries with exponential backoff. Thi\", \"s technique helps to avoid short and intermittent failures \\nby performing call retries a certain num\", \"ber of times, in case the service was not available only for a \\nshort time. This might occur due to \", \"intermittent network issues or when a microservice/container is \\nmoved to a different node in a clus\", \"ter. However, if these retries are not designed properly with circuit \\nbreakers, it can aggravate th\", \"e ripple effects, ultimately even causing a Denial of Service (DoS). \\n\\nWork around network timeouts.\", \" In general, clients should be designed not to block indefinitely and \\nto always use timeouts when w\", \"aiting for a response. Using timeouts ensures that resources are never \\ntied up indefinitely. \\n\\nUse \", \"the Circuit Breaker pattern. In this approach, the client process tracks the number of failed \\nreque\", \"sts. If the error rate exceeds a configured limit, a \\u201ccircuit breaker\\u201d trips so that further attempt\", \"s \\nfail immediately. (If a large number of requests are failing, that suggests the service is unavai\", \"lable and \\nthat sending requests is pointless.) After a timeout period, the client should try again \", \"and, if the new \\nrequests are successful, close the circuit breaker. \\n\\nProvide fallbacks. In this ap\", \"proach, the client process performs fallback logic when a request fails, \\nsuch as returning cached d\", \"ata or a default value. This is an approach suitable for queries, and is more \\ncomplex for updates o\", \"r commands. \\n\\nLimit the number of queued requests. Clients should also impose an upper bound on the \", \"number \\nof outstanding requests that a client microservice can send to a particular service. If the \", \"limit has been \\nreached, it\\u2019s probably pointless to make additional requests, and those attempts sho\", \"uld fail \\nimmediately. In terms of implementation, the Polly Bulkhead Isolation policy can be used t\", \"o fulfill this \\nrequirement. This approach is essentially a parallelization throttle with SemaphoreS\", \"lim as the \\nimplementation. It also permits a \\u201cqueue\\u201d outside the bulkhead. You can proactively shed\", \" excess load \\neven before execution (for example, because capacity is deemed full). This makes its r\", \"esponse to \\n\\n294 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\\fcertain failure scenarios fas\", \"ter than a circuit breaker would be, since the circuit breaker waits for the \\nfailures. The Bulkhead\", \"Policy object in Polly exposes how full the bulkhead and queue are, and offers \\nevents on overflow s\", \"o can also be used to drive automated horizontal scaling. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022\", \" \\n\\nResiliency patterns \\nhttps://learn.microsoft.com/azure/architecture/framework/resiliency/reliabil\", \"ity-patterns \\n\\nAdding Resilience and Optimizing Performance \\nhttps://learn.microsoft.com/previous-ve\", \"rsions/msp-n-p/jj591574(v=pandp.10) \\n\\nBulkhead. GitHub repo. Implementation with Polly policy. \\nhttp\", \"s://github.com/App-vNext/Polly/wiki/Bulkhead \\n\\nDesigning resilient applications for Azure \\nhttps://l\", \"earn.microsoft.com/azure/architecture/framework/resiliency/app-design \\n\\nTransient fault handling \\nht\", \"tps://learn.microsoft.com/azure/architecture/best-practices/transient-faults \\n\\nImplement retries wit\", \"h exponential backoff \\n\\nRetries with exponential backoff is a technique that retries an operation, w\", \"ith an exponentially \\nincreasing wait time, up to a maximum retry count has been reached (the expone\", \"ntial backoff). This \\ntechnique embraces the fact that cloud resources might intermittently be unava\", \"ilable for more than a \\nfew seconds for any reason. For example, an orchestrator might be moving a c\", \"ontainer to another \\nnode in a cluster for load balancing. During that time, some requests might fai\", \"l. Another example \\ncould be a database like SQL Azure, where a database can be moved to another ser\", \"ver for load \\nbalancing, causing the database to be unavailable for a few seconds. \\n\\nThere are many \", \"approaches to implement retries logic with exponential backoff. \\n\\nImplement resilient Entity Framewo\", \"rk Core SQL \\nconnections \\n\\nFor Azure SQL DB, Entity Framework (EF) Core already provides internal da\", \"tabase connection resiliency \\nand retry logic. But you need to enable the Entity Framework execution\", \" strategy for each DbContext \\nconnection if you want to have resilient EF Core connections. \\n\\nFor in\", \"stance, the following code at the EF Core connection level enables resilient SQL connections that \\na\", \"re retried if the connection fails. \\n\\n// Program.cs from any ASP.NET Core Web API \\n// Other code ...\", \" \\nbuilder.Services.AddDbContext<CatalogContext>(options => \\n    { \\n\\n295 \\n\\nCHAPTER 7 | Implement resi\", \"lient applications \\n\\n \\n \\n\\f        options.UseSqlServer(builder.Configuration[\\\"ConnectionString\\\"], \\n \", \"       sqlServerOptionsAction: sqlOptions => \\n        { \\n            sqlOptions.EnableRetryOnFailure\", \"( \\n            maxRetryCount: 10, \\n            maxRetryDelay: TimeSpan.FromSeconds(30), \\n           \", \" errorNumbersToAdd: null); \\n        }); \\n    }); \\n\\nExecution strategies and explicit transactions us\", \"ing BeginTransaction \\nand multiple DbContexts \\n\\nWhen retries are enabled in EF Core connections, eac\", \"h operation you perform using EF Core becomes \\nits own retryable operation. Each query and each call\", \" to SaveChanges will be retried as a unit if a \\ntransient failure occurs. \\n\\nHowever, if your code in\", \"itiates a transaction using BeginTransaction, you\\u2019re defining your own group \\nof operations that nee\", \"d to be treated as a unit. Everything inside the transaction has to be rolled back \\nif a failure occ\", \"urs. \\n\\nIf you try to execute that transaction when using an EF execution strategy (retry policy) and\", \" you call \\nSaveChanges from multiple DbContexts, you\\u2019ll get an exception like this one: \\n\\nSystem.Inv\", \"alidOperationException: The configured execution strategy \\n\\u2018SqlServerRetryingExecutionStrategy\\u2019 does\", \" not support user initiated transactions. Use the execution \\nstrategy returned by \\u2018DbContext.Databas\", \"e.CreateExecutionStrategy()\\u2019 to execute all the operations in \\nthe transaction as a retriable unit. \", \"\\n\\nThe solution is to manually invoke the EF execution strategy with a delegate representing everythi\", \"ng \\nthat needs to be executed. If a transient failure occurs, the execution strategy will invoke the\", \" delegate \\nagain. For example, the following code shows how it\\u2019s implemented in eShopOnContainers wi\", \"th two \\nmultiple DbContexts (_catalogContext and the IntegrationEventLogContext) when updating a pro\", \"duct \\nand then saving the ProductPriceChangedIntegrationEvent object, which needs to use a different\", \" \\nDbContext. \\n\\npublic async Task<IActionResult> UpdateProduct( \\n    [FromBody]CatalogItem productToU\", \"pdate) \\n{ \\n    // Other code ... \\n\\n    var oldPrice = catalogItem.Price; \\n    var raiseProductPriceC\", \"hangedEvent = oldPrice != productToUpdate.Price; \\n\\n    // Update current product \\n    catalogItem = \", \"productToUpdate; \\n\\n    // Save product's data and publish integration event through the Event Bus \\n \", \"   // if price has changed \\n    if (raiseProductPriceChangedEvent) \\n    { \\n        //Create Integrat\", \"ion Event to be published through the Event Bus \\n        var priceChangedEvent = new ProductPriceCha\", \"ngedIntegrationEvent( \\n          catalogItem.Id, productToUpdate.Price, oldPrice); \\n\\n296 \\n\\nCHAPTER 7\", \" | Implement resilient applications \\n\\n \\n \\n \\n \\n \\n\\f       // Achieving atomicity between original Cata\", \"log database operation and the \\n       // IntegrationEventLog thanks to a local transaction \\n       \", \"await _catalogIntegrationEventService.SaveEventAndCatalogContextChangesAsync( \\n           priceChang\", \"edEvent); \\n\\n       // Publish through the Event Bus and mark the saved event as published \\n       aw\", \"ait _catalogIntegrationEventService.PublishThroughEventBusAsync( \\n           priceChangedEvent); \\n  \", \"  } \\n    // Just save the updated product because the Product's Price hasn't changed. \\n    else \\n   \", \" { \\n        await _catalogContext.SaveChangesAsync(); \\n    } \\n} \\n\\nThe first DbContext is _catalogCon\", \"text and the second DbContext is within the \\n_catalogIntegrationEventService object. The Commit acti\", \"on is performed across all DbContext objects \\nusing an EF execution strategy. \\n\\nTo achieve this mult\", \"iple DbContext commit, the SaveEventAndCatalogContextChangesAsync uses a \\nResilientTransaction class\", \", as shown in the following code: \\n\\npublic class CatalogIntegrationEventService : ICatalogIntegratio\", \"nEventService \\n{ \\n    //\\u2026 \\n    public async Task SaveEventAndCatalogContextChangesAsync( \\n        In\", \"tegrationEvent evt) \\n    { \\n        // Use of an EF Core resiliency strategy when using multiple DbC\", \"ontexts \\n        // within an explicit BeginTransaction(): \\n        // https://learn.microsoft.com/e\", \"f/core/miscellaneous/connection-resiliency \\n        await ResilientTransaction.New(_catalogContext).\", \"ExecuteAsync(async () => \\n        { \\n            // Achieving atomicity between original catalog dat\", \"abase \\n            // operation and the IntegrationEventLog thanks to a local transaction \\n         \", \"   await _catalogContext.SaveChangesAsync(); \\n            await _eventLogService.SaveEventAsync(evt,\", \" \\n                _catalogContext.Database.CurrentTransaction.GetDbTransaction()); \\n        }); \\n   \", \" } \\n} \\n\\nThe ResilientTransaction.ExecuteAsync method basically begins a transaction from the passed \", \"\\nDbContext (_catalogContext) and then makes the EventLogService use that transaction to save \\nchange\", \"s from the IntegrationEventLogContext and then commits the whole transaction. \\n\\npublic class Resilie\", \"ntTransaction \\n{ \\n    private DbContext _context; \\n    private ResilientTransaction(DbContext contex\", \"t) => \\n        _context = context ?? throw new ArgumentNullException(nameof(context)); \\n\\n    public \", \"static ResilientTransaction New (DbContext context) => \\n        new ResilientTransaction(context); \\n\", \"\\n    public async Task ExecuteAsync(Func<Task> action) \\n    { \\n\\n297 \\n\\nCHAPTER 7 | Implement resilien\", \"t applications \\n\\n \\n \\n \\n \\n \\n \\n\\f        // Use of an EF Core resiliency strategy when using multiple D\", \"bContexts \\n        // within an explicit BeginTransaction(): \\n        // https://learn.microsoft.com\", \"/ef/core/miscellaneous/connection-resiliency \\n        var strategy = _context.Database.CreateExecuti\", \"onStrategy(); \\n        await strategy.ExecuteAsync(async () => \\n        { \\n            await using v\", \"ar transaction = await _context.Database.BeginTransactionAsync(); \\n            await action(); \\n    \", \"        await transaction.CommitAsync(); \\n        }); \\n    } \\n} \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCon\", \"nection Resiliency and Command Interception with EF in an ASP.NET MVC \\nApplication \\nhttps://learn.mi\", \"crosoft.com/aspnet/mvc/overview/getting-started/getting-started-with-ef-\\nusing-mvc/connection-resili\", \"ency-and-command-interception-with-the-entity-framework-in-\\nan-asp-net-mvc-application \\n\\nCesar de la\", \" Torre. Using Resilient Entity Framework Core SQL Connections and \\nTransactions \\nhttps://devblogs.mi\", \"crosoft.com/cesardelatorre/using-resilient-entity-framework-core-sql-\\nconnections-and-transactions-r\", \"etries-with-exponential-backoff/ \\n\\nUse IHttpClientFactory to implement resilient HTTP \\nrequests \\n\\nIH\", \"ttpClientFactory is a contract implemented by DefaultHttpClientFactory, an opinionated factory, \\nava\", \"ilable since .NET Core 2.1, for creating HttpClient instances to be used in your applications. \\n\\nIss\", \"ues with the original HttpClient class available in .NET \\n\\nThe original and well-known HttpClient cl\", \"ass can be easily used, but in some cases, it isn\\u2019t being \\nproperly used by many developers. \\n\\nThoug\", \"h this class implements IDisposable, declaring and instantiating it within a using statement is \\nnot\", \" preferred because when the HttpClient object gets disposed of, the underlying socket is not \\nimmedi\", \"ately released, which can lead to a socket exhaustion problem. For more information about this \\nissu\", \"e, see the blog post You\\u2019re using HttpClient wrong and it\\u2019s destabilizing your software. \\n\\nTherefore\", \", HttpClient is intended to be instantiated once and reused throughout the life of an \\napplication. \", \"Instantiating an HttpClient class for every request will exhaust the number of sockets \\navailable un\", \"der heavy loads. That issue will result in SocketException errors. Possible approaches to \\nsolve tha\", \"t problem are based on the creation of the HttpClient object as singleton or static, as \\nexplained i\", \"n this Microsoft article on HttpClient usage. This can be a good solution for short-lived \\nconsole a\", \"pps or similar, that run a few times a day. \\n\\n298 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \", \"\\n \\n\\fAnother issue that developers run into is when using a shared instance of HttpClient in long-run\", \"ning \\nprocesses. In a situation where the HttpClient is instantiated as a singleton or a static obje\", \"ct, it fails to \\nhandle the DNS changes as described in this issue of the dotnet/runtime GitHub repo\", \"sitory. \\n\\nHowever, the issue isn\\u2019t really with HttpClient per se, but with the default constructor f\", \"or HttpClient, \\nbecause it creates a new concrete instance of HttpMessageHandler, which is the one t\", \"hat has sockets \\nexhaustion and DNS changes issues mentioned above. \\n\\nTo address the issues mentione\", \"d above and to make HttpClient instances manageable, .NET Core 2.1 \\nintroduced two approaches, one o\", \"f them being IHttpClientFactory. It\\u2019s an interface that\\u2019s used to \\nconfigure and create HttpClient i\", \"nstances in an app through Dependency Injection (DI). It also \\nprovides extensions for Polly-based m\", \"iddleware to take advantage of delegating handlers in \\nHttpClient. \\n\\nThe alternative is to use Socke\", \"tsHttpHandler with configured PooledConnectionLifetime. This \\napproach is applied to long-lived, sta\", \"tic or singleton HttpClient instances. To learn more about \\ndifferent strategies, see HttpClient gui\", \"delines for .NET. \\n\\nPolly is a transient-fault-handling library that helps developers add resiliency\", \" to their applications, by \\nusing some pre-defined policies in a fluent and thread-safe manner. \\n\\nBe\", \"nefits of using IHttpClientFactory \\n\\nThe current implementation of IHttpClientFactory, that also imp\", \"lements IHttpMessageHandlerFactory, \\noffers the following benefits: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nProvides a central\", \" location for naming and configuring logical HttpClient objects. For \\nexample, you may configure a c\", \"lient (Service Agent) that\\u2019s pre-configured to access a specific \\nmicroservice. \\n\\nCodify the concept\", \" of outgoing middleware via delegating handlers in HttpClient and \\nimplementing Polly-based middlewa\", \"re to take advantage of Polly\\u2019s policies for resiliency. \\n\\nHttpClient already has the concept of del\", \"egating handlers that could be linked together for \\noutgoing HTTP requests. You can register HTTP cl\", \"ients into the factory and you can use a \\nPolly handler to use Polly policies for Retry, CircuitBrea\", \"kers, and so on. \\n\\n\\u2022  Manage the lifetime of HttpMessageHandler to avoid the mentioned problems/issu\", \"es that \\n\\ncan occur when managing HttpClient lifetimes yourself. \\n\\nTip \\n\\nThe HttpClient instances in\", \"jected by DI can be disposed of safely, because the associated \\nHttpMessageHandler is managed by the\", \" factory. Injected HttpClient instances are Transient from a DI \\nperspective, while HttpMessageHandl\", \"er instances can be regarded as Scoped. HttpMessageHandler \\ninstances have their own DI scopes, sepa\", \"rate from the application scopes (for example, ASP.NET \\nincoming request scopes). For more informati\", \"on, see Using HttpClientFactory in .NET. \\n\\n299 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\", \" \\n \\n\\fNote \\n\\nThe implementation of IHttpClientFactory (DefaultHttpClientFactory) is tightly tied to t\", \"he DI \\nimplementation in the Microsoft.Extensions.DependencyInjection NuGet package. If you need to \", \"use \\nHttpClient without DI or with other DI implementations, consider using a static or singleton Ht\", \"tpClient \\nwith PooledConnectionLifetime set up. For more information, see HttpClient guidelines for \", \".NET. \\n\\nMultiple ways to use IHttpClientFactory \\n\\nThere are several ways that you can use IHttpClien\", \"tFactory in your application: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nBasic usage \\n\\nUse Named Clients \\n\\nUse Typed Clients \", \"\\n\\nUse Generated Clients \\n\\nFor the sake of brevity, this guidance shows the most structured way to us\", \"e IHttpClientFactory, which \\nis to use Typed Clients (Service Agent pattern). However, all options a\", \"re documented and are currently \\nlisted in this article covering the IHttpClientFactory usage. \\n\\nNot\", \"e \\n\\nIf your app requires cookies, it might be better to avoid using IHttpClientFactory in your app. \", \"For \\nalternative ways of managing clients, see Guidelines for using HTTP clients \\n\\nHow to use Typed \", \"Clients with IHttpClientFactory \\n\\nSo, what\\u2019s a \\u201cTyped Client\\u201d? It\\u2019s just an HttpClient that\\u2019s pre-co\", \"nfigured for some specific use. This \\nconfiguration can include specific values such as the base ser\", \"ver, HTTP headers or time outs. \\n\\nThe following diagram shows how Typed Clients are used with IHttpC\", \"lientFactory: \\n\\n300 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\\fFigure 8-4. Using IHttpCli\", \"entFactory with Typed Client classes. \\n\\nIn the above image, a ClientService (used by a controller or\", \" client code) uses an HttpClient created by \\nthe registered IHttpClientFactory. This factory assigns\", \" an HttpMessageHandler from a pool to the \\nHttpClient. The HttpClient can be configured with Polly\\u2019s\", \" policies when registering the \\nIHttpClientFactory in the DI container with the extension method Add\", \"HttpClient. \\n\\nTo configure the above structure, add IHttpClientFactory in your application by instal\", \"ling the \\nMicrosoft.Extensions.Http NuGet package that includes the AddHttpClient extension method f\", \"or \\nIServiceCollection. This extension method registers the internal DefaultHttpClientFactory class \", \"to be \\nused as a singleton for the interface IHttpClientFactory. It defines a transient configuratio\", \"n for the \\nHttpMessageHandlerBuilder. This message handler (HttpMessageHandler object), taken from a\", \" pool, \\nis used by the HttpClient returned from the factory. \\n\\nIn the next snippet, you can see how \", \"AddHttpClient() can be used to register Typed Clients (Service \\nAgents) that need to use HttpClient.\", \" \\n\\n// Program.cs \\n//Add http client services at ConfigureServices(IServiceCollection services) \\nbuil\", \"der.Services.AddHttpClient<ICatalogService, CatalogService>(); \\nbuilder.Services.AddHttpClient<IBask\", \"etService, BasketService>(); \\nbuilder.Services.AddHttpClient<IOrderingService, OrderingService>(); \\n\", \"\\n301 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n\\fRegistering the client services as show\", \"n in the previous snippet, makes the DefaultClientFactory create \\na standard HttpClient for each ser\", \"vice. The typed client is registered as transient with DI container. In \\nthe preceding code, AddHttp\", \"Client() registers CatalogService, BasketService, OrderingService as \\ntransient services so they can\", \" be injected and consumed directly without any need for additional \\nregistrations. \\n\\nYou could also \", \"add instance-specific configuration in the registration to, for example, configure the \\nbase address\", \", and add some resiliency policies, as shown in the following: \\n\\nbuilder.Services.AddHttpClient<ICat\", \"alogService, CatalogService>(client => \\n{ \\n    client.BaseAddress = new Uri(builder.Configuration[\\\"B\", \"aseUrl\\\"]); \\n}) \\n    .AddPolicyHandler(GetRetryPolicy()) \\n    .AddPolicyHandler(GetCircuitBreakerPoli\", \"cy()); \\n\\nIn this next example, you can see the configuration of one of the above policies: \\n\\nstatic \", \"IAsyncPolicy<HttpResponseMessage> GetRetryPolicy() \\n{ \\n    return HttpPolicyExtensions \\n        .Han\", \"dleTransientHttpError() \\n        .OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFou\", \"nd) \\n        .WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, \\nretryAttempt)))\", \"; \\n} \\n\\nYou can find more details about using Polly in the Next article. \\n\\nHttpClient lifetimes \\n\\nEac\", \"h time you get an HttpClient object from the IHttpClientFactory, a new instance is returned. But \\nea\", \"ch HttpClient uses an HttpMessageHandler that\\u2019s pooled and reused by the IHttpClientFactory to \\nredu\", \"ce resource consumption, as long as the HttpMessageHandler\\u2019s lifetime hasn\\u2019t expired. \\n\\nPooling of h\", \"andlers is desirable as each handler typically manages its own underlying HTTP \\nconnections; creatin\", \"g more handlers than necessary can result in connection delays. Some handlers \\nalso keep connections\", \" open indefinitely, which can prevent the handler from reacting to DNS \\nchanges. \\n\\nThe HttpMessageHa\", \"ndler objects in the pool have a lifetime that\\u2019s the length of time that an \\nHttpMessageHandler inst\", \"ance in the pool can be reused. The default value is two minutes, but it can \\nbe overridden per Type\", \"d Client. To override it, call SetHandlerLifetime() on the IHttpClientBuilder \\nthat\\u2019s returned when \", \"creating the client, as shown in the following code: \\n\\n//Set 5 min as the lifetime for the HttpMessa\", \"geHandler objects in the pool used for the \\nCatalog Typed Client \\nbuilder.Services.AddHttpClient<ICa\", \"talogService, CatalogService>() \\n    .SetHandlerLifetime(TimeSpan.FromMinutes(5)); \\n\\nEach Typed Clie\", \"nt can have its own configured handler lifetime value. Set the lifetime to \\nInfiniteTimeSpan to disa\", \"ble handler expiry. \\n\\n302 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\\fImplement your Typed\", \" Client classes that use the injected and configured \\nHttpClient \\n\\nAs a previous step, you need to h\", \"ave your Typed Client classes defined, such as the classes in the \\nsample code, like \\u2018BasketService\\u2019\", \", \\u2018CatalogService\\u2019, \\u2018OrderingService\\u2019, etc. \\u2013 A Typed Client is a class \\nthat accepts an HttpClient \", \"object (injected through its constructor) and uses it to call some remote \\nHTTP service. For example\", \": \\n\\npublic class CatalogService : ICatalogService \\n{ \\n    private readonly HttpClient _httpClient; \\n\", \"    private readonly string _remoteServiceBaseUrl; \\n\\n    public CatalogService(HttpClient httpClient\", \") \\n    { \\n        _httpClient = httpClient; \\n    } \\n\\n    public async Task<Catalog> GetCatalogItems(\", \"int page, int take, \\n                                               int? brand, int? type) \\n    { \\n \", \"       var uri = API.Catalog.GetAllCatalogItems(_remoteServiceBaseUrl, \\n                            \", \"                     page, take, brand, type); \\n\\n        var responseString = await _httpClient.GetS\", \"tringAsync(uri); \\n\\n        var catalog = JsonConvert.DeserializeObject<Catalog>(responseString); \\n  \", \"      return catalog; \\n    } \\n} \\n\\nThe Typed Client (CatalogService in the example) is activated by D\", \"I (Dependency Injection), which \\nmeans it can accept any registered service in its constructor, in a\", \"ddition to HttpClient. \\n\\nA Typed Client is effectively a transient object, that means a new instance\", \" is created each time one is \\nneeded. It receives a new HttpClient instance each time it\\u2019s construct\", \"ed. However, the \\nHttpMessageHandler objects in the pool are the objects that are reused by multiple\", \" HttpClient \\ninstances. \\n\\nUse your Typed Client classes \\n\\nFinally, once you have your typed classes \", \"implemented, you can have them registered and configured \\nwith AddHttpClient(). After that you can u\", \"se them wherever services are injected by DI, such as in \\nRazor page code or an MVC web app controll\", \"er, shown in the below code from eShopOnContainers: \\n\\nnamespace Microsoft.eShopOnContainers.WebMVC.C\", \"ontrollers \\n{ \\n    public class CatalogController : Controller \\n    { \\n        private ICatalogServi\", \"ce _catalogSvc; \\n\\n        public CatalogController(ICatalogService catalogSvc) => \\n                 \", \"                                          _catalogSvc = catalogSvc; \\n\\n        public async Task<IAct\", \"ionResult> Index(int? BrandFilterApplied, \\n                                               int? Types\", \"FilterApplied, \\n\\n303 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\f             \", \"                                  int? page, \\n                                               [FromQu\", \"ery]string errorMsg) \\n        { \\n            var itemsPage = 10; \\n            var catalog = await _c\", \"atalogSvc.GetCatalogItems(page ?? 0, \\n                                                            it\", \"emsPage, \\n                                                            BrandFilterApplied, \\n         \", \"                                                   TypesFilterApplied); \\n            //\\u2026 Additional \", \"code \\n        } \\n\\n        } \\n} \\n\\nUp to this point, the above code snippet only shows the example of \", \"performing regular HTTP \\nrequests. But the \\u2018magic\\u2019 comes in the following sections where it shows ho\", \"w all the HTTP requests \\nmade by HttpClient can have resilient policies such as retries with exponen\", \"tial backoff, circuit \\nbreakers, security features using auth tokens, or even any other custom featu\", \"re. And all of these can \\nbe done just by adding policies and delegating handlers to your registered\", \" Typed Clients. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nHttpClient guidelines for .NET \\nhttps:/\", \"/learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient-\\nguidelines \\n\\nUsing HttpCl\", \"ientFactory in .NET \\nhttps://learn.microsoft.com/en-us/dotnet/core/extensions/httpclient-factory \\n\\nU\", \"sing HttpClientFactory in ASP.NET Core \\nhttps://learn.microsoft.com/aspnet/core/fundamentals/http-re\", \"quests \\n\\nHttpClientFactory source code in the dotnet/runtime GitHub repository \\nhttps://github.com/d\", \"otnet/runtime/tree/release/7.0/src/libraries/Microsoft.Extensions.Http/ \\n\\nPolly (.NET resilience and\", \" transient-fault-handling library) \\nhttps://thepollyproject.azurewebsites.net/ \\n\\nImplement HTTP call\", \" retries with exponential backoff \\nwith IHttpClientFactory and Polly policies \\n\\nThe recommended appr\", \"oach for retries with exponential backoff is to take advantage of more \\nadvanced .NET libraries like\", \" the open-source Polly library. \\n\\nPolly is a .NET library that provides resilience and transient-fau\", \"lt handling capabilities. You can \\nimplement those capabilities by applying Polly policies such as R\", \"etry, Circuit Breaker, Bulkhead \\nIsolation, Timeout, and Fallback. Polly targets .NET Framework 4.x \", \"and .NET Standard 1.0, 1.1, and 2.0 \\n(which supports .NET Core and later). \\n\\n304 \\n\\nCHAPTER 7 | Imple\", \"ment resilient applications \\n\\n \\n \\n \\n\\fThe following steps show how you can use Http retries with Poll\", \"y integrated into IHttpClientFactory, \\nwhich is explained in the previous section. \\n\\nInstall .NET pa\", \"ckages \\n\\nFirst, you will need to install the Microsoft.Extensions.Http.Polly package. \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\", \"\\u2022 \\n\\nInstall with Visual Studio \\n\\nInstall with dotnet CLI \\n\\nInstall with nuget.exe CLI \\n\\nInstall with\", \" Package Manager Console (PowerShell) \\n\\nReference the .NET 7 packages \\n\\nIHttpClientFactory is availa\", \"ble since .NET Core 2.1, however, we recommend you use the latest .NET 7 \\npackages from NuGet in you\", \"r project. You typically also need to reference the extension package \\nMicrosoft.Extensions.Http.Pol\", \"ly. \\n\\nConfigure a client with Polly\\u2019s Retry policy, in app startup \\n\\nThe AddPolicyHandler() method i\", \"s what adds policies to the HttpClient objects you\\u2019ll use. In this \\ncase, it\\u2019s adding a Polly\\u2019s poli\", \"cy for Http Retries with exponential backoff. \\n\\nTo have a more modular approach, the Http Retry Poli\", \"cy can be defined in a separate method within \\nthe Program.cs file, as shown in the following code: \", \"\\n\\nstatic IAsyncPolicy<HttpResponseMessage> GetRetryPolicy() \\n{ \\n    return HttpPolicyExtensions \\n   \", \"     .HandleTransientHttpError() \\n        .OrResult(msg => msg.StatusCode == System.Net.HttpStatusCo\", \"de.NotFound) \\n        .WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, \\n      \", \"                                                              retryAttempt))); \\n} \\n\\nAs shown in prev\", \"ious sections, you need to define a named or typed client HttpClient configuration in \\nyour standard\", \" Program.cs app configuration. Now you add incremental code specifying the policy for \\nthe Http retr\", \"ies with exponential backoff, as follows: \\n\\n// Program.cs \\nbuilder.Services.AddHttpClient<IBasketSer\", \"vice, BasketService>() \\n        .SetHandlerLifetime(TimeSpan.FromMinutes(5))  //Set lifetime to five\", \" minutes \\n        .AddPolicyHandler(GetRetryPolicy()); \\n\\nWith Polly, you can define a Retry policy w\", \"ith the number of retries, the exponential backoff \\nconfiguration, and the actions to take when ther\", \"e\\u2019s an HTTP exception, such as logging the error. In \\nthis case, the policy is configured to try six\", \" times with an exponential retry, starting at two seconds. \\n\\nAdd a jitter strategy to the retry poli\", \"cy \\n\\nA regular Retry policy can affect your system in cases of high concurrency and scalability and \", \"under \\nhigh contention. To overcome peaks of similar retries coming from many clients in partial out\", \"ages, a \\ngood workaround is to add a jitter strategy to the retry algorithm/policy. This strategy ca\", \"n improve \\nthe overall performance of the end-to-end system. As recommended in Polly: Retry with Jit\", \"ter, a good \\n\\n305 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\\fjitter strategy can be imple\", \"mented by smooth and evenly distributed retry intervals applied with a \\nwell-controlled median initi\", \"al retry delay on an exponential backoff. This approach helps to spread out \\nthe spikes when the iss\", \"ue arises. The principle is illustrated by the following example: \\n\\nvar delay = Backoff.Decorrelated\", \"JitterBackoffV2(medianFirstRetryDelay: \\nTimeSpan.FromSeconds(1), retryCount: 5); \\n\\nvar retryPolicy =\", \" Policy \\n    .Handle<FooException>() \\n    .WaitAndRetryAsync(delay); \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \", \"\\n\\n\\u2022 \\n\\nRetry pattern https://learn.microsoft.com/azure/architecture/patterns/retry \\n\\nPolly and IHttpC\", \"lientFactory https://github.com/App-vNext/Polly/wiki/Polly-and-\\nHttpClientFactory \\n\\nPolly (.NET resi\", \"lience and transient-fault-handling library) https://github.com/App-\\nvNext/Polly \\n\\n\\u2022 \\n\\nPolly: Retry \", \"with Jitter https://github.com/App-vNext/Polly/wiki/Retry-with-jitter \\n\\n\\u2022  Marc Brooker. Jitter: Mak\", \"ing Things Better With Randomness \\n\\nhttps://brooker.co.za/blog/2015/03/21/backoff.html \\n\\nImplement t\", \"he Circuit Breaker pattern \\n\\nAs noted earlier, you should handle faults that might take a variable a\", \"mount of time to recover from, \\nas might happen when you try to connect to a remote service or resou\", \"rce. Handling this type of fault \\ncan improve the stability and resiliency of an application. \\n\\nIn a\", \" distributed environment, calls to remote resources and services can fail due to transient faults, \\n\", \"such as slow network connections and timeouts, or if resources are responding slowly or are \\ntempora\", \"rily unavailable. These faults typically correct themselves after a short time, and a robust cloud \\n\", \"application should be prepared to handle them by using a strategy like the \\u201cRetry pattern\\u201d. \\n\\nHoweve\", \"r, there can also be situations where faults are due to unanticipated events that might take \\nmuch l\", \"onger to fix. These faults can range in severity from a partial loss of connectivity to the \\ncomplet\", \"e failure of a service. In these situations, it might be pointless for an application to continually\", \" \\nretry an operation that\\u2019s unlikely to succeed. \\n\\nInstead, the application should be coded to accep\", \"t that the operation has failed and handle the failure \\naccordingly. \\n\\nUsing Http retries carelessly\", \" could result in creating a Denial of Service (DoS) attack within your own \\nsoftware. As a microserv\", \"ice fails or performs slowly, multiple clients might repeatedly retry failed \\nrequests. That creates\", \" a dangerous risk of exponentially increasing traffic targeted at the failing \\nservice. \\n\\n306 \\n\\nCHAP\", \"TER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n\\fTherefore, you need some kind of defense barrier\", \" so that excessive requests stop when it isn\\u2019t worth \\nto keep trying. That defense barrier is precis\", \"ely the circuit breaker. \\n\\nThe Circuit Breaker pattern has a different purpose than the \\u201cRetry patte\", \"rn\\u201d. The \\u201cRetry pattern\\u201d \\nenables an application to retry an operation in the expectation that the o\", \"peration will eventually \\nsucceed. The Circuit Breaker pattern prevents an application from performi\", \"ng an operation that\\u2019s \\nlikely to fail. An application can combine these two patterns. However, the \", \"retry logic should be \\nsensitive to any exception returned by the circuit breaker, and it should aba\", \"ndon retry attempts if the \\ncircuit breaker indicates that a fault is not transient. \\n\\nImplement Cir\", \"cuit Breaker pattern with IHttpClientFactory and Polly \\n\\nAs when implementing retries, the recommend\", \"ed approach for circuit breakers is to take advantage of \\nproven .NET libraries like Polly and its n\", \"ative integration with IHttpClientFactory. \\n\\nAdding a circuit breaker policy into your IHttpClientFa\", \"ctory outgoing middleware pipeline is as simple \\nas adding a single incremental piece of code to wha\", \"t you already have when using IHttpClientFactory. \\n\\nThe only addition here to the code used for HTTP\", \" call retries is the code where you add the Circuit \\nBreaker policy to the list of policies to use, \", \"as shown in the following incremental code. \\n\\n// Program.cs \\nvar retryPolicy = GetRetryPolicy(); \\nva\", \"r circuitBreakerPolicy = GetCircuitBreakerPolicy(); \\n\\nbuilder.Services.AddHttpClient<IBasketService,\", \" BasketService>() \\n        .SetHandlerLifetime(TimeSpan.FromMinutes(5))  // Sample: default lifetime\", \" is 2 \\nminutes \\n        .AddHttpMessageHandler<HttpClientAuthorizationDelegatingHandler>() \\n        \", \".AddPolicyHandler(retryPolicy) \\n        .AddPolicyHandler(circuitBreakerPolicy); \\n\\nThe AddPolicyHand\", \"ler() method is what adds policies to the HttpClient objects you\\u2019ll use. In this case, \\nit\\u2019s adding \", \"a Polly policy for a circuit breaker. \\n\\nTo have a more modular approach, the Circuit Breaker Policy \", \"is defined in a separate method called \\nGetCircuitBreakerPolicy(), as shown in the following code: \\n\", \"\\n// also in Program.cs \\nstatic IAsyncPolicy<HttpResponseMessage> GetCircuitBreakerPolicy() \\n{ \\n    r\", \"eturn HttpPolicyExtensions \\n        .HandleTransientHttpError() \\n        .CircuitBreakerAsync(5, Tim\", \"eSpan.FromSeconds(30)); \\n} \\n\\nIn the code example above, the circuit breaker policy is configured so \", \"it breaks or opens the circuit \\nwhen there have been five consecutive faults when retrying the Http \", \"requests. When that happens, \\nthe circuit will break for 30 seconds: in that period, calls will be f\", \"ailed immediately by the circuit-\\nbreaker rather than actually be placed. The policy automatically i\", \"nterprets relevant exceptions and \\nHTTP status codes as faults. \\n\\nCircuit breakers should also be us\", \"ed to redirect requests to a fallback infrastructure if you had issues \\nin a particular resource tha\", \"t\\u2019s deployed in a different environment than the client application or \\n\\n307 \\n\\nCHAPTER 7 | Implement\", \" resilient applications \\n\\n \\n \\n \\n\\fservice that\\u2019s performing the HTTP call. That way, if there\\u2019s an ou\", \"tage in the datacenter that impacts \\nonly your backend microservices but not your client application\", \"s, the client applications can redirect \\nto the fallback services. Polly is planning a new policy to\", \" automate this failover policy scenario. \\n\\nAll those features are for cases where you\\u2019re managing th\", \"e failover from within the .NET code, as \\nopposed to having it managed automatically for you by Azur\", \"e, with location transparency. \\n\\nFrom a usage point of view, when using HttpClient, there\\u2019s no need \", \"to add anything new here \\nbecause the code is the same than when using HttpClient with IHttpClientFa\", \"ctory, as shown in \\nprevious sections. \\n\\nTest Http retries and circuit breakers in eShopOnContainers\", \" \\n\\nWhenever you start the eShopOnContainers solution in a Docker host, it needs to start multiple \\nc\", \"ontainers. Some of the containers are slower to start and initialize, like the SQL Server container.\", \" This \\nis especially true the first time you deploy the eShopOnContainers application into Docker be\", \"cause it \\nneeds to set up the images and the database. The fact that some containers start slower th\", \"an others \\ncan cause the rest of the services to initially throw HTTP exceptions, even if you set de\", \"pendencies \\nbetween containers at the docker-compose level, as explained in previous sections. Those\", \" docker-\\ncompose dependencies between containers are just at the process level. The container\\u2019s entr\", \"y point \\nprocess might be started, but SQL Server might not be ready for queries. The result can be \", \"a cascade \\nof errors, and the application can get an exception when trying to consume that particula\", \"r container. \\n\\nYou might also see this type of error on startup when the application is deploying to\", \" the cloud. In that \\ncase, orchestrators might be moving containers from one node or VM to another (\", \"that is, starting new \\ninstances) when balancing the number of containers across the cluster\\u2019s nodes\", \". \\n\\nThe way \\u2018eShopOnContainers\\u2019 solves those issues when starting all the containers is by using the\", \" Retry \\npattern illustrated earlier. \\n\\nTest the circuit breaker in eShopOnContainers \\n\\nThere are a f\", \"ew ways you can break/open the circuit and test it with eShopOnContainers. \\n\\nOne option is to lower \", \"the allowed number of retries to 1 in the circuit breaker policy and redeploy \\nthe whole solution in\", \"to Docker. With a single retry, there\\u2019s a good chance that an HTTP request will \\nfail during deploym\", \"ent, the circuit breaker will open, and you get an error. \\n\\nAnother option is to use custom middlewa\", \"re that\\u2019s implemented in the Basket microservice. When \\nthis middleware is enabled, it catches all H\", \"TTP requests and returns status code 500. You can enable \\nthe middleware by making a GET request to \", \"the failing URI, like the following: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n308 \\n\\nGET http://localhost:5103/failing \\nThis request\", \" returns the current state of the middleware. If the middleware is enabled, the \\nrequest return stat\", \"us code 500. If the middleware is disabled, there\\u2019s no response. \\n\\nGET http://localhost:5103/failing\", \"?enable \\nThis request enables the middleware. \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n\\f\", \"\\u2022 \\n\\nGET http://localhost:5103/failing?disable \\nThis request disables the middleware. \\n\\nFor instance,\", \" once the application is running, you can enable the middleware by making a request \\nusing the follo\", \"wing URI in any browser. Note that the ordering microservice uses port 5103. \\n\\nhttp://localhost:5103\", \"/failing?enable \\n\\nYou can then check the status using the URI http://localhost:5103/failing, as show\", \"n in Figure 8-5. \\n\\nFigure 8-5. Checking the state of the \\u201cFailing\\u201d ASP.NET middleware \\u2013 In this case\", \", disabled. \\n\\nAt this point, the Basket microservice responds with status code 500 whenever you call\", \" invoke it. \\n\\nOnce the middleware is running, you can try making an order from the MVC web applicati\", \"on. Because \\nthe requests fail, the circuit will open. \\n\\nIn the following example, you can see that \", \"the MVC web application has a catch block in the logic for \\nplacing an order. If the code catches an\", \" open-circuit exception, it shows the user a friendly message \\ntelling them to wait. \\n\\npublic class \", \"CartController : Controller \\n{ \\n    //\\u2026 \\n    public async Task<IActionResult> Index() \\n    { \\n      \", \"  try \\n        { \\n            var user = _appUserParser.Parse(HttpContext.User); \\n            //Http\", \" requests using the Typed Client (Service Agent) \\n            var vm = await _basketSvc.GetBasket(us\", \"er); \\n            return View(vm); \\n        } \\n        catch (BrokenCircuitException) \\n        { \\n  \", \"          // Catches error when Basket.api is in circuit-opened mode \\n            HandleBrokenCircui\", \"tException(); \\n        } \\n        return View(); \\n    } \\n\\n    private void HandleBrokenCircuitExcept\", \"ion() \\n    { \\n        TempData[\\\"BasketInoperativeMsg\\\"] = \\\"Basket Service is inoperative, please try \", \"later \\non. (Business message due to Circuit-Breaker)\\\"; \\n    } \\n} \\n\\nHere\\u2019s a summary. The Retry polic\", \"y tries several times to make the HTTP request and gets HTTP errors. \\nWhen the number of retries rea\", \"ches the maximum number set for the Circuit Breaker policy (in this \\ncase, 5), the application throw\", \"s a BrokenCircuitException. The result is a friendly message, as shown in \\nFigure 8-6. \\n\\n309 \\n\\nCHAPT\", \"ER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n\\fFigure 8-6. Circuit breaker returning an error to\", \" the UI \\n\\nYou can implement different logic for when to open/break the circuit. Or you can try an HT\", \"TP request \\nagainst a different back-end microservice if there\\u2019s a fallback datacenter or redundant \", \"back-end \\nsystem. \\n\\nFinally, another possibility for the CircuitBreakerPolicy is to use Isolate (whi\", \"ch forces open and holds \\nopen the circuit) and Reset (which closes it again). These could be used t\", \"o build a utility HTTP \\nendpoint that invokes Isolate and Reset directly on the policy. Such an HTTP\", \" endpoint could also be \\nused, suitably secured, in production for temporarily isolating a downstrea\", \"m system, such as when \\nyou want to upgrade it. Or it could trip the circuit manually to protect a d\", \"ownstream system you \\nsuspect to be faulting. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\nCircuit Breaker pattern \\n\", \"https://learn.microsoft.com/azure/architecture/patterns/circuit-breaker \\n\\nHealth monitoring \\n\\nHealth\", \" monitoring can allow near-real-time information about the state of your containers and \\nmicroservic\", \"es. Health monitoring is critical to multiple aspects of operating microservices and is \\nespecially \", \"important when orchestrators perform partial application upgrades in phases, as explained \\nlater. \\n\\n\", \"Microservices-based applications often use heartbeats or health checks to enable their performance \\n\", \"monitors, schedulers, and orchestrators to keep track of the multitude of services. If services cann\", \"ot \\nsend some sort of \\u201cI\\u2019m alive\\u201d signal, either on demand or on a schedule, your application might \", \"face \\nrisks when you deploy updates, or it might just detect failures too late and not be able to st\", \"op \\ncascading failures that can end up in major outages. \\n\\nIn the typical model, services send repor\", \"ts about their status, and that information is aggregated to \\nprovide an overall view of the state o\", \"f health of your application. If you\\u2019re using an orchestrator, you \\ncan provide health information t\", \"o your orchestrator\\u2019s cluster, so that the cluster can act accordingly. If \\nyou invest in high-quali\", \"ty health reporting that\\u2019s customized for your application, you can detect and \\nfix issues for your \", \"running application much more easily. \\n\\n310 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n\\f\", \"Implement health checks in ASP.NET Core services \\n\\nWhen developing an ASP.NET Core microservice or w\", \"eb application, you can use the built-in health \\nchecks feature that was released in ASP .NET Core 2\", \".2 \\n(Microsoft.Extensions.Diagnostics.HealthChecks). Like many ASP.NET Core features, health checks \", \"\\ncome with a set of services and a middleware. \\n\\nHealth check services and middleware are easy to us\", \"e and provide capabilities that let you validate if \\nany external resource needed for your applicati\", \"on (like a SQL Server database or a remote API) is \\nworking properly. When you use this feature, you\", \" can also decide what it means that the resource is \\nhealthy, as we explain later. \\n\\nTo use this fea\", \"ture effectively, you need to first configure services in your microservices. Second, you \\nneed a fr\", \"ont-end application that queries for the health reports. That front-end application could be a \\ncust\", \"om reporting application, or it could be an orchestrator itself that can react accordingly to the \\nh\", \"ealth states. \\n\\nUse the HealthChecks feature in your back-end ASP.NET microservices \\n\\nIn this sectio\", \"n, you\\u2019ll learn how to implement the HealthChecks feature in a sample ASP.NET Core 7.0 \\nWeb API appl\", \"ication when using the Microsoft.Extensions.Diagnostics.HealthChecks package. The \\nImplementation of\", \" this feature in a large-scale microservices like the eShopOnContainers is explained \\nin the next se\", \"ction. \\n\\nTo begin, you need to define what constitutes a healthy status for each microservice. In th\", \"e sample \\napplication, we define the microservice is healthy if its API is accessible via HTTP and i\", \"ts related SQL \\nServer database is also available. \\n\\nIn .NET 7, with the built-in APIs, you can conf\", \"igure the services, add a Health Check for the \\nmicroservice and its dependent SQL Server database i\", \"n this way: \\n\\n// Program.cs from .NET 7 Web API sample \\n\\n//... \\n// Registers required services for h\", \"ealth checks \\nbuilder.Services.AddHealthChecks() \\n    // Add a health check for a SQL Server databas\", \"e \\n    .AddCheck( \\n        \\\"OrderingDB-check\\\", \\n        new SqlConnectionHealthCheck(builder.Configu\", \"ration[\\\"ConnectionString\\\"]), \\n        HealthStatus.Unhealthy, \\n        new string[] { \\\"orderingdb\\\" }\", \"); \\n\\nIn the previous code, the services.AddHealthChecks() method configures a basic HTTP check that \", \"\\nreturns a status code 200 with \\u201cHealthy\\u201d. Further, the AddCheck() extension method configures a \\ncu\", \"stom SqlConnectionHealthCheck that checks the related SQL Database\\u2019s health. \\n\\nThe AddCheck() method\", \" adds a new health check with a specified name and the implementation of \\ntype IHealthCheck. You can\", \" add multiple Health Checks using AddCheck method, so a microservice \\nwon\\u2019t provide a \\u201chealthy\\u201d stat\", \"us until all its checks are healthy. \\n\\n311 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n\\fS\", \"qlConnectionHealthCheck is a custom class that implements IHealthCheck, which takes a connection \\nst\", \"ring as a constructor parameter and executes a simple query to check if the connection to the SQL \\nd\", \"atabase is successful. It returns HealthCheckResult.Healthy() if the query was executed successfully\", \" \\nand a FailureStatus with the actual exception when it fails. \\n\\n// Sample SQL Connection Health Che\", \"ck \\npublic class SqlConnectionHealthCheck : IHealthCheck \\n{ \\n    private const string DefaultTestQue\", \"ry = \\\"Select 1\\\"; \\n\\n    public string ConnectionString { get; } \\n\\n    public string TestQuery { get; \", \"} \\n\\n    public SqlConnectionHealthCheck(string connectionString) \\n        : this(connectionString, t\", \"estQuery: DefaultTestQuery) \\n    { \\n    } \\n\\n    public SqlConnectionHealthCheck(string connectionStr\", \"ing, string testQuery) \\n    { \\n        ConnectionString = connectionString ?? throw new \\nArgumentNul\", \"lException(nameof(connectionString)); \\n        TestQuery = testQuery; \\n    } \\n\\n    public async Task\", \"<HealthCheckResult> CheckHealthAsync(HealthCheckContext context, \\nCancellationToken cancellationToke\", \"n = default(CancellationToken)) \\n    { \\n        using (var connection = new SqlConnection(Connection\", \"String)) \\n        { \\n            try \\n            { \\n                await connection.OpenAsync(canc\", \"ellationToken); \\n\\n                if (TestQuery != null) \\n                { \\n                    var\", \" command = connection.CreateCommand(); \\n                    command.CommandText = TestQuery; \\n\\n     \", \"               await command.ExecuteNonQueryAsync(cancellationToken); \\n                } \\n          \", \"  } \\n            catch (DbException ex) \\n            { \\n                return new HealthCheckResult\", \"(status: context.Registration.FailureStatus, \\nexception: ex); \\n            } \\n        } \\n\\n        re\", \"turn HealthCheckResult.Healthy(); \\n    } \\n} \\n\\nNote that in the previous code, Select 1 is the query \", \"used to check the Health of the database. To \\nmonitor the availability of your microservices, orches\", \"trators like Kubernetes periodically perform \\nhealth checks by sending requests to test the microser\", \"vices. It\\u2019s important to keep your database \\nqueries efficient so that these operations are quick an\", \"d don\\u2019t result in a higher utilization of resources. \\n\\n312 \\n\\nCHAPTER 7 | Implement resilient applica\", \"tions \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\fFinally, add a middleware that responds to the url path /hc: \\n\\n// Progr\", \"am.cs from .NET 7 Web Api sample \\n\\napp.MapHealthChecks(\\\"/hc\\\"); \\n\\nWhen the endpoint <yourmicroservice\", \">/hc is invoked, it runs all the health checks that are configured \\nin the AddHealthChecks() method \", \"in the Startup class and shows the result. \\n\\nHealthChecks implementation in eShopOnContainers \\n\\nMicr\", \"oservices in eShopOnContainers rely on multiple services to perform its task. For example, the \\nCata\", \"log.API microservice from eShopOnContainers depends on many services, such as Azure Blob \\nStorage, S\", \"QL Server, and RabbitMQ. Therefore, it has several health checks added using the \\nAddCheck() method.\", \" For every dependent service, a custom IHealthCheck implementation that \\ndefines its respective heal\", \"th status would need to be added. \\n\\nThe open-source project AspNetCore.Diagnostics.HealthChecks solv\", \"es this problem by providing \\ncustom health check implementations for each of these enterprise servi\", \"ces, that are built on top of \\n.NET 7. Each health check is available as an individual NuGet package\", \" that can be easily added to the \\nproject. eShopOnContainers uses them extensively in all its micros\", \"ervices. \\n\\nFor instance, in the Catalog.API microservice, the following NuGet packages were added: \\n\", \"\\nFigure 8-7. Custom Health Checks implemented in Catalog.API using AspNetCore.Diagnostics.HealthChec\", \"ks \\n\\nIn the following code, the health check implementations are added for each dependent service an\", \"d \\nthen the middleware is configured: \\n\\n// Extension method from Catalog.api microservice \\n// \\npubli\", \"c static IServiceCollection AddCustomHealthCheck(this IServiceCollection services, \\nIConfiguration c\", \"onfiguration) \\n{ \\n    var accountName = configuration.GetValue<string>(\\\"AzureStorageAccountName\\\"); \\n\", \"    var accountKey = configuration.GetValue<string>(\\\"AzureStorageAccountKey\\\"); \\n\\n    var hcBuilder =\", \" services.AddHealthChecks(); \\n\\n313 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n \\n\\f    h\", \"cBuilder \\n        .AddSqlServer( \\n            configuration[\\\"ConnectionString\\\"], \\n            name: \", \"\\\"CatalogDB-check\\\", \\n            tags: new string[] { \\\"catalogdb\\\" }); \\n\\n    if (!string.IsNullOrEmpty\", \"(accountName) && !string.IsNullOrEmpty(accountKey)) \\n    { \\n        hcBuilder \\n            .AddAzure\", \"BlobStorage( \\n\\n$\\\"DefaultEndpointsProtocol=https;AccountName={accountName};AccountKey={accountKey};En\", \"dpoint\\nSuffix=core.windows.net\\\", \\n                name: \\\"catalog-storage-check\\\", \\n                ta\", \"gs: new string[] { \\\"catalogstorage\\\" }); \\n    } \\n    if (configuration.GetValue<bool>(\\\"AzureServiceBu\", \"sEnabled\\\")) \\n    { \\n        hcBuilder \\n            .AddAzureServiceBusTopic( \\n                config\", \"uration[\\\"EventBusConnection\\\"], \\n                topicName: \\\"eshop_event_bus\\\", \\n                name:\", \" \\\"catalog-servicebus-check\\\", \\n                tags: new string[] { \\\"servicebus\\\" }); \\n    } \\n    else\", \" \\n    { \\n        hcBuilder \\n            .AddRabbitMQ( \\n                $\\\"amqp://{configuration[\\\"Even\", \"tBusConnection\\\"]}\\\", \\n                name: \\\"catalog-rabbitmqbus-check\\\", \\n                tags: new s\", \"tring[] { \\\"rabbitmqbus\\\" }); \\n    } \\n\\n    return services; \\n} \\n\\nFinally, add the HealthCheck middlewa\", \"re to listen to \\u201c/hc\\u201d endpoint: \\n\\n// HealthCheck middleware \\napp.UseHealthChecks(\\\"/hc\\\", new HealthCh\", \"eckOptions() \\n{ \\n    Predicate = _ => true, \\n    ResponseWriter = UIResponseWriter.WriteHealthCheckU\", \"IResponse \\n}); \\n\\nQuery your microservices to report about their health status \\n\\nWhen you\\u2019ve configur\", \"ed health checks as described in this article and you have the microservice \\nrunning in Docker, you \", \"can directly check from a browser if it\\u2019s healthy. You have to publish the \\ncontainer port in the Do\", \"cker host, so you can access the container through the external Docker host IP \\nor through host.dock\", \"er.internal, as shown in figure 8-8. \\n\\n314 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n \\n\", \"                \\n \\n\\fFigure 8-8. Checking health status of a single service from a browser \\n\\nIn that \", \"test, you can see that the Catalog.API microservice (running on port 5101) is healthy, returning \\nHT\", \"TP status 200 and status information in JSON. The service also checked the health of its SQL Server \", \"\\ndatabase dependency and RabbitMQ, so the health check reported itself as healthy. \\n\\nUse watchdogs \\n\", \"\\nA watchdog is a separate service that can watch health and load across services, and report health \", \"\\nabout the microservices by querying with the HealthChecks library introduced earlier. This can help\", \" \\nprevent errors that would not be detected based on the view of a single service. Watchdogs also ar\", \"e a \\ngood place to host code that can perform remediation actions for known conditions without user \", \"\\ninteraction. \\n\\nThe eShopOnContainers sample contains a web page that displays sample health check r\", \"eports, as \\nshown in Figure 8-9. This is the simplest watchdog you could have since it only shows th\", \"e state of the \\nmicroservices and web applications in eShopOnContainers. Usually a watchdog also tak\", \"es actions \\nwhen it detects unhealthy states. \\n\\nFortunately, AspNetCore.Diagnostics.HealthChecks als\", \"o provides AspNetCore.HealthChecks.UI NuGet \\npackage that can be used to display the health check re\", \"sults from the configured URIs. \\n\\n315 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \\n \\n \\n\\fFigure\", \" 8-9. Sample health check report in eShopOnContainers \\n\\nIn summary, this watchdog service queries ea\", \"ch microservice\\u2019s \\u201c/hc\\u201d endpoint. This will execute all the \\nhealth checks defined within it and ret\", \"urn an overall health state depending on all those checks. The \\nHealthChecksUI is easy to consume wi\", \"th a few configuration entries and two lines of code that needs \\nto be added into the Startup.cs of \", \"the watchdog service. \\n\\nSample configuration file for health check UI: \\n\\n// Configuration \\n{ \\n  \\\"Hea\", \"lthChecksUI\\\": { \\n    \\\"HealthChecks\\\": [ \\n      { \\n        \\\"Name\\\": \\\"Ordering HTTP Check\\\", \\n        \\\"Ur\", \"i\\\": \\\"http://host.docker.internal:5102/hc\\\" \\n      }, \\n      { \\n        \\\"Name\\\": \\\"Ordering HTTP Backgro\", \"und Check\\\", \\n        \\\"Uri\\\": \\\"http://host.docker.internal:5111/hc\\\" \\n      }, \\n      //... \\n    ]} \\n} \", \"\\n\\nProgram.cs file that adds HealthChecksUI: \\n\\n316 \\n\\nCHAPTER 7 | Implement resilient applications \\n\\n \", \"\\n \\n \\n\\f// Program.cs from WebStatus(Watch Dog) service \\n// \\n// Registers required services for health\", \" checks \\nbuilder.Services.AddHealthChecksUI(); \\n// build the app, register other middleware \\napp.Use\", \"HealthChecksUI(config => config.UIPath = \\\"/hc-ui\\\"); \\n\\nHealth checks when using orchestrators \\n\\nTo mo\", \"nitor the availability of your microservices, orchestrators like Kubernetes and Service Fabric \\nperi\", \"odically perform health checks by sending requests to test the microservices. When an \\norchestrator \", \"determines that a service/container is unhealthy, it stops routing requests to that \\ninstance. It al\", \"so usually creates a new instance of that container. \\n\\nFor instance, most orchestrators can use heal\", \"th checks to manage zero-downtime deployments. Only \\nwhen the status of a service/container changes \", \"to healthy will the orchestrator start routing traffic to \\nservice/container instances. \\n\\nHealth mon\", \"itoring is especially important when an orchestrator performs an application upgrade. \\nSome orchestr\", \"ators (like Azure Service Fabric) update services in phases\\u2014for example, they might \\nupdate one-fift\", \"h of the cluster surface for each application upgrade. The set of nodes that\\u2019s upgraded \\nat the same\", \" time is referred to as an upgrade domain. After each upgrade domain has been upgraded \\nand is avail\", \"able to users, that upgrade domain must pass health checks before the deployment moves \\nto the next \", \"upgrade domain. \\n\\nAnother aspect of service health is reporting metrics from the service. This is an\", \" advanced capability of \\nthe health model of some orchestrators, like Service Fabric. Metrics are im\", \"portant when using an \\norchestrator because they are used to balance resource usage. Metrics also ca\", \"n be an indicator of \\nsystem health. For example, you might have an application that has many micros\", \"ervices, and each \\ninstance reports a requests-per-second (RPS) metric. If one service is using more\", \" resources (memory, \\nprocessor, etc.) than another service, the orchestrator could move service inst\", \"ances around in the \\ncluster to try to maintain even resource utilization. \\n\\nNote that Azure Service\", \" Fabric provides its own Health Monitoring model, which is more advanced \\nthan simple health checks.\", \" \\n\\nAdvanced monitoring: visualization, analysis, and alerts \\n\\nThe final part of monitoring is visual\", \"izing the event stream, reporting on service performance, and \\nalerting when an issue is detected. Y\", \"ou can use different solutions for this aspect of monitoring. \\n\\nYou can use simple custom applicatio\", \"ns showing the state of your services, like the custom page \\nshown when explaining the AspNetCore.Di\", \"agnostics.HealthChecks. Or you could use more advanced \\ntools like Azure Monitor to raise alerts bas\", \"ed on the stream of events. \\n\\nFinally, if you\\u2019re storing all the event streams, you can use Microsof\", \"t Power BI or other solutions like \\nKibana or Splunk to visualize the data. \\n\\n317 \\n\\nCHAPTER 7 | Impl\", \"ement resilient applications \\n\\n \\n \\n\\fAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nHealthChecks and HealthChecks\", \" UI for ASP.NET Core \\nhttps://github.com/Xabaril/AspNetCore.Diagnostics.HealthChecks \\n\\nIntroduction \", \"to Service Fabric health monitoring \\nhttps://learn.microsoft.com/azure/service-fabric/service-fabric\", \"-health-introduction \\n\\nAzure Monitor \\nhttps://azure.microsoft.com/services/monitor/ \\n\\n318 \\n\\nCHAPTER \", \"7 | Implement resilient applications \\n\\n \\n \\n\\fCHAPTER  8 \\n\\nMake secure .NET \\nMicroservices and Web \\nAp\", \"plications \\n\\nThere are so many aspects about security in microservices and web applications that the\", \" topic could \\neasily take several books like this one. So, in this section, we\\u2019ll focus on authentic\", \"ation, authorization, \\nand application secrets. \\n\\nImplement authentication in .NET microservices and\", \" \\nweb applications \\n\\nIt\\u2019s often necessary for resources and APIs published by a service to be limite\", \"d to certain trusted users \\nor clients. The first step to making these sorts of API-level trust deci\", \"sions is authentication. \\nAuthentication is the process of reliably verifying a user\\u2019s identity. \\n\\nI\", \"n microservice scenarios, authentication is typically handled centrally. If you\\u2019re using an API Gate\", \"way, \\nthe gateway is a good place to authenticate, as shown in Figure 9-1. If you use this approach,\", \" make \\nsure that the individual microservices cannot be reached directly (without the API Gateway) u\", \"nless \\nadditional security is in place to authenticate messages whether they come from the gateway o\", \"r not. \\n\\nFigure 9-1. Centralized authentication with an API Gateway \\n\\nWhen the API Gateway centraliz\", \"es authentication, it adds user information when forwarding requests \\nto the microservices. If servi\", \"ces can be accessed directly, an authentication service like Azure Active \\n\\n319 \\n\\nCHAPTER 8 | Make s\", \"ecure .NET Microservices and Web Applications \\n\\n \\n \\n \\n\\fDirectory or a dedicated authentication micro\", \"service acting as a security token service (STS) can be \\nused to authenticate users. Trust decisions\", \" are shared between services with security tokens or \\ncookies. (These tokens can be shared between A\", \"SP.NET Core applications, if needed, by implementing \\ncookie sharing.) This pattern is illustrated i\", \"n Figure 9-2. \\n\\nFigure 9-2. Authentication by identity microservice; trust is shared using an author\", \"ization token \\n\\nWhen microservices are accessed directly, trust, that includes authentication and au\", \"thorization, is \\nhandled by a security token issued by a dedicated microservice, shared between micr\", \"oservices. \\n\\nAuthenticate with ASP.NET Core Identity \\n\\nThe primary mechanism in ASP.NET Core for ide\", \"ntifying an application\\u2019s users is the ASP.NET Core \\nIdentity membership system. ASP.NET Core Identi\", \"ty stores user information (including sign-in \\ninformation, roles, and claims) in a data store confi\", \"gured by the developer. Typically, the ASP.NET \\nCore Identity data store is an Entity Framework stor\", \"e provided in the \\nMicrosoft.AspNetCore.Identity.EntityFrameworkCore package. However, custom stores\", \" or other third-\\nparty packages can be used to store identity information in Azure Table Storage, Co\", \"smosDB, or other \\nlocations. \\n\\nTip \\n\\nASP.NET Core 2.1 and later provides ASP.NET Core Identity as a \", \"Razor Class Library, so you won\\u2019t see \\nmuch of the necessary code in your project, as was the case f\", \"or previous versions. For details on how \\nto customize the Identity code to suit your needs, see Sca\", \"ffold Identity in ASP.NET Core projects. \\n\\nThe following code is taken from the ASP.NET Core Web App\", \"lication MVC 3.1 project template with \\nindividual user account authentication selected. It shows ho\", \"w to configure ASP.NET Core Identity \\nusing Entity Framework Core in the Program.cs file. \\n\\n//... \\nb\", \"uilder.Services.AddDbContext<ApplicationDbContext>(options => \\n    options.UseSqlServer( \\n        bu\", \"ilder.Configuration.GetConnectionString(\\\"DefaultConnection\\\"))); \\n\\n320 \\n\\nCHAPTER 8 | Make secure .NET\", \" Microservices and Web Applications \\n\\n \\n \\n \\n \\n\\fbuilder.Services.AddDefaultIdentity<IdentityUser>(opt\", \"ions => \\n    options.SignIn.RequireConfirmedAccount = true) \\n        .AddEntityFrameworkStores<Appli\", \"cationDbContext>(); \\n\\nbuilder.Services.AddRazorPages(); \\n//... \\nOnce ASP.NET Core Identity is config\", \"ured, you enable it by adding the \\napp.UseAuthentication() and endpoints.MapRazorPages() as shown in\", \" the following code in the \\nservice\\u2019s Program.cs file: \\n//... \\napp.UseRouting(); \\n\\napp.UseAuthentica\", \"tion(); \\napp.UseAuthorization(); \\n\\napp.UseEndpoints(endpoints => \\n{ \\n    endpoints.MapRazorPages(); \", \"\\n}); \\n//... \\n\\nImportant \\n\\nThe lines in the preceding code MUST BE IN THE ORDER SHOWN for Identity to\", \" work correctly. \\n\\nUsing ASP.NET Core Identity enables several scenarios: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nCreate new u\", \"ser information using the UserManager type (userManager.CreateAsync). \\n\\nAuthenticate users using the\", \" SignInManager type. You can use signInManager.SignInAsync to \\nsign in directly, or signInManager.Pa\", \"sswordSignInAsync to confirm the user\\u2019s password is \\ncorrect and then sign them in. \\n\\nIdentify a use\", \"r based on information stored in a cookie (which is read by ASP.NET Core \\nIdentity middleware) so th\", \"at subsequent requests from a browser will include a signed-in \\nuser\\u2019s identity and claims. \\n\\nASP.NE\", \"T Core Identity also supports two-factor authentication. \\n\\nFor authentication scenarios that make us\", \"e of a local user data store and that persist identity between \\nrequests using cookies (as is typica\", \"l for MVC web applications), ASP.NET Core Identity is a \\nrecommended solution. \\n\\nAuthenticate with e\", \"xternal providers \\n\\nASP.NET Core also supports using external authentication providers to let users \", \"sign in via OAuth 2.0 \\nflows. This means that users can sign in using existing authentication proces\", \"ses from providers like \\nMicrosoft, Google, Facebook, or Twitter and associate those identities with\", \" an ASP.NET Core identity \\nin your application. \\n\\nTo use external authentication, besides including \", \"the authentication middleware as mentioned before, \\nusing the app.UseAuthentication() method, you al\", \"so have to register the external provider in \\nProgram.cs as shown in the following example: \\n\\n321 \\n\\n\", \"CHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n\\f//... \\nservices.Add\", \"DefaultIdentity<IdentityUser>(options => options.SignIn.RequireConfirmedAccount \\n= true) \\n    .AddEn\", \"tityFrameworkStores<ApplicationDbContext>(); \\n\\nservices.AddAuthentication() \\n    .AddMicrosoftAccoun\", \"t(microsoftOptions => \\n    { \\n        microsoftOptions.ClientId = \\nbuilder.Configuration[\\\"Authentica\", \"tion:Microsoft:ClientId\\\"]; \\n        microsoftOptions.ClientSecret = \\nbuilder.Configuration[\\\"Authenti\", \"cation:Microsoft:ClientSecret\\\"]; \\n    }) \\n    .AddGoogle(googleOptions => { ... }) \\n    .AddTwitter(\", \"twitterOptions => { ... }) \\n    .AddFacebook(facebookOptions => { ... }); \\n//... \\n\\nPopular external \", \"authentication providers and their associated NuGet packages are shown in the \\nfollowing table: \\n\\nPr\", \"ovider \\n\\nPackage \\n\\nMicrosoft \\n\\nMicrosoft.AspNetCore.Authentication.MicrosoftAccount \\n\\nGoogle \\n\\nMicro\", \"soft.AspNetCore.Authentication.Google \\n\\nFacebook \\n\\nMicrosoft.AspNetCore.Authentication.Facebook \\n\\nTw\", \"itter \\n\\nMicrosoft.AspNetCore.Authentication.Twitter \\n\\nIn all cases, you must complete an application\", \" registration procedure that is vendor dependent and \\nthat usually involves: \\n\\n1. \\n\\n2. \\n\\n3. \\n\\nGettin\", \"g a Client Application ID. \\n\\nGetting a Client Application Secret. \\n\\nConfiguring a redirection URL, t\", \"hat\\u2019s handled by the authorization middleware and the \\nregistered provider \\n\\n4.  Optionally, configu\", \"ring a sign-out URL to properly handle sign out in a Single Sign On (SSO) \\n\\nscenario. \\n\\nFor details \", \"on configuring your app for an external provider, see the External provider authentication \\nin the A\", \"SP.NET Core documentation). \\n\\nTip \\n\\nAll details are handled by the authorization middleware and serv\", \"ices previously mentioned. So, you \\njust have to choose the Individual User Account authentication o\", \"ption when you create the ASP.NET \\nCore web application project in Visual Studio, as shown in Figure\", \" 9-3, besides registering the \\nauthentication providers previously mentioned. \\n\\n322 \\n\\nCHAPTER 8 | Ma\", \"ke secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n\\fFigure 9-3. Selecting the Individual User\", \" Accounts option, for using external authentication, when creating a web \\napplication project in Vis\", \"ual Studio 2019. \\n\\nIn addition to the external authentication providers listed previously, third-par\", \"ty packages are \\navailable that provide middleware for using many more external authentication provi\", \"ders. For a list, \\nsee the AspNet.Security.OAuth.Providers repository on GitHub. \\n\\nYou can also crea\", \"te your own external authentication middleware to solve some special need. \\n\\nAuthenticate with beare\", \"r tokens \\n\\nAuthenticating with ASP.NET Core Identity (or Identity plus external authentication provi\", \"ders) works \\nwell for many web application scenarios in which storing user information in a cookie i\", \"s appropriate. \\nIn other scenarios, though, cookies are not a natural means of persisting and transm\", \"itting data. \\n\\nFor example, in an ASP.NET Core Web API that exposes RESTful endpoints that might be \", \"accessed by \\nSingle Page Applications (SPAs), by native clients, or even by other Web APIs, you typi\", \"cally want to \\nuse bearer token authentication instead. These types of applications do not work with\", \" cookies, but \\ncan easily retrieve a bearer token and include it in the authorization header of subs\", \"equent requests. \\nTo enable token authentication, ASP.NET Core supports several options for using OA\", \"uth 2.0 and \\nOpenID Connect. \\n\\n323 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications\", \" \\n\\n \\n \\n \\n\\fAuthenticate with an OpenID Connect or OAuth 2.0 Identity provider \\n\\nIf user information i\", \"s stored in Azure Active Directory or another identity solution that supports \\nOpenID Connect or OAu\", \"th 2.0, you can use the \\nMicrosoft.AspNetCore.Authentication.OpenIdConnect package to authenticate u\", \"sing the OpenID \\nConnect workflow. For example, to authenticate to the Identity.Api microservice in \", \"\\neShopOnContainers, an ASP.NET Core web application can use middleware from that package as \\nshown i\", \"n the following simplified example in Program.cs: \\n\\n// Program.cs \\n\\nvar identityUrl = builder.Config\", \"uration.GetValue<string>(\\\"IdentityUrl\\\"); \\nvar callBackUrl = builder.Configuration.GetValue<string>(\\\"\", \"CallBackUrl\\\"); \\nvar sessionCookieLifetime = builder.Configuration.GetValue(\\\"SessionCookieLifetimeMin\", \"utes\\\", \\n60); \\n\\n// Add Authentication services \\n\\nservices.AddAuthentication(options => \\n{ \\n    option\", \"s.DefaultScheme = CookieAuthenticationDefaults.AuthenticationScheme; \\n    options.DefaultChallengeSc\", \"heme = JwtBearerDefaults.AuthenticationScheme; \\n}) \\n.AddCookie(setup => setup.ExpireTimeSpan = TimeS\", \"pan.FromMinutes(sessionCookieLifetime)) \\n.AddOpenIdConnect(options => \\n{ \\n    options.SignInScheme =\", \" CookieAuthenticationDefaults.AuthenticationScheme; \\n    options.Authority = identityUrl.ToString();\", \" \\n    options.SignedOutRedirectUri = callBackUrl.ToString(); \\n    options.ClientId = useLoadTest ? \\\"\", \"mvctest\\\" : \\\"mvc\\\"; \\n    options.ClientSecret = \\\"secret\\\"; \\n    options.ResponseType = useLoadTest ? \\\"c\", \"ode id_token token\\\" : \\\"code id_token\\\"; \\n    options.SaveTokens = true; \\n    options.GetClaimsFromUse\", \"rInfoEndpoint = true; \\n    options.RequireHttpsMetadata = false; \\n    options.Scope.Add(\\\"openid\\\"); \\n\", \"    options.Scope.Add(\\\"profile\\\"); \\n    options.Scope.Add(\\\"orders\\\"); \\n    options.Scope.Add(\\\"basket\\\")\", \"; \\n    options.Scope.Add(\\\"marketing\\\"); \\n    options.Scope.Add(\\\"locations\\\"); \\n    options.Scope.Add(\\\"\", \"webshoppingagg\\\"); \\n    options.Scope.Add(\\\"orders.signalrhub\\\"); \\n}); \\n\\n// Build the app \\n//\\u2026 \\napp.Use\", \"Authentication(); \\n//\\u2026 \\napp.UseEndpoints(endpoints => \\n{ \\n    //... \\n}); \\n\\nWhen you use this workflo\", \"w, the ASP.NET Core Identity middleware is not needed, because all user \\ninformation storage and aut\", \"hentication is handled by the Identity service. \\n\\n324 \\n\\nCHAPTER 8 | Make secure .NET Microservices a\", \"nd Web Applications \\n\\n \\n \\n \\n \\n \\n \\n\\fIssue security tokens from an ASP.NET Core service \\n\\nIf you prefe\", \"r to issue security tokens for local ASP.NET Core Identity users rather than using an \\nexternal iden\", \"tity provider, you can take advantage of some good third-party libraries. \\n\\nIdentityServer4 and Open\", \"Iddict are OpenID Connect providers that integrate easily with ASP.NET Core \\nIdentity to let you iss\", \"ue security tokens from an ASP.NET Core service. The IdentityServer4 \\ndocumentation has in-depth ins\", \"tructions for using the library. However, the basic steps to using \\nIdentityServer4 to issue tokens \", \"are as follows. \\n\\n1. \\n\\n2. \\n\\nYou configure IdentityServer4 in Program.cs by making a call to \\nbuilder\", \".Services.AddIdentityServer. \\n\\nYou call app.UseIdentityServer in Program.cs to add IdentityServer4 t\", \"o the application\\u2019s HTTP \\nrequest processing pipeline. This lets the library serve requests to OpenI\", \"D Connect and \\nOAuth2 endpoints like /connect/token. \\n\\n3. \\n\\nYou configure identity server by setting\", \" the following data: \\n\\n\\u2013 \\n\\n\\u2013 \\n\\n\\u2013 \\n\\n\\u2013 \\n\\nThe credentials to use for signing. \\n\\nThe Identity and API re\", \"sources that users might request access to: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAPI resources represent protected data or func\", \"tionality that a user can access \\nwith an access token. An example of an API resource would be a web\", \" API (or \\nset of APIs) that requires authorization. \\n\\nIdentity resources represent information (clai\", \"ms) that are given to a client to \\nidentify a user. The claims might include the user name, email ad\", \"dress, and so \\non. \\n\\nThe clients that will be connecting in order to request tokens. \\n\\nThe storage m\", \"echanism for user information, such as ASP.NET Core Identity or an \\nalternative. \\n\\nWhen you specify \", \"clients and resources for IdentityServer4 to use, you can pass an IEnumerable \\ncollection of the app\", \"ropriate type to methods that take in-memory client or resource stores. Or for \\nmore complex scenari\", \"os, you can provide client or resource provider types via Dependency Injection. \\n\\nA sample configura\", \"tion for IdentityServer4 to use in-memory resources and clients provided by a \\ncustom IClientStore t\", \"ype might look like the following example: \\n\\n// Program.cs \\n\\nbuilder.Services.AddSingleton<IClientSt\", \"ore, CustomClientStore>(); \\nbuilder.Services.AddIdentityServer() \\n    .AddSigningCredential(\\\"CN=sts\\\"\", \") \\n    .AddInMemoryApiResources(MyApiResourceProvider.GetAllResources()) \\n    .AddAspNetIdentity<App\", \"licationUser>(); \\n//... \\n\\n325 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n\", \" \\n \\n\\fConsume security tokens \\n\\nAuthenticating against an OpenID Connect endpoint or issuing your own\", \" security tokens covers some \\nscenarios. But what about a service that simply needs to limit access \", \"to those users who have valid \\nsecurity tokens that were provided by a different service? \\n\\nFor that\", \" scenario, authentication middleware that handles JWT tokens is available in the \\nMicrosoft.AspNetCo\", \"re.Authentication.JwtBearer package. JWT stands for \\u201cJSON Web Token\\u201d and \\nis a common security token\", \" format (defined by RFC 7519) for communicating security claims. A \\nsimplified example of how to use\", \" middleware to consume such tokens might look like this code \\nfragment, taken from the Ordering.Api \", \"microservice of eShopOnContainers. \\n\\n// Program.cs \\n\\nvar identityUrl = builder.Configuration.GetValu\", \"e<string>(\\\"IdentityUrl\\\"); \\n\\n// Add Authentication services \\n\\nbuilder.Services.AddAuthentication(opti\", \"ons => \\n{ \\n    options.DefaultAuthenticateScheme = \\nAspNetCore.Authentication.JwtBearer.JwtBearerDef\", \"aults.AuthenticationScheme; \\n    options.DefaultChallengeScheme = \\nAspNetCore.Authentication.JwtBear\", \"er.JwtBearerDefaults.AuthenticationScheme; \\n\\n}).AddJwtBearer(options => \\n{ \\n    options.Authority = \", \"identityUrl; \\n    options.RequireHttpsMetadata = false; \\n    options.Audience = \\\"orders\\\"; \\n}); \\n\\n// \", \"Build the app \\n\\napp.UseAuthentication(); \\n//\\u2026 \\napp.UseEndpoints(endpoints => \\n{ \\n    //... \\n}); \\n\\nTh\", \"e parameters in this usage are: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAudience represents the receiver of the incoming token or \", \"the resource that the token grants \\naccess to. If the value specified in this parameter does not mat\", \"ch the parameter in the token, \\nthe token will be rejected. \\n\\nAuthority is the address of the token-\", \"issuing authentication server. The JWT bearer \\nauthentication middleware uses this URI to get the pu\", \"blic key that can be used to validate the \\ntoken\\u2019s signature. The middleware also confirms that the \", \"iss parameter in the token matches \\nthis URI. \\n\\nAnother parameter, RequireHttpsMetadata, is useful f\", \"or testing purposes; you set this parameter to \\nfalse so you can test in environments where you don\\u2019\", \"t have certificates. In real-world deployments, \\nJWT bearer tokens should always be passed only over\", \" HTTPS. \\n\\n326 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\fW\", \"ith this middleware in place, JWT tokens are automatically extracted from authorization headers. \\nTh\", \"ey are then deserialized, validated (using the values in the Audience and Authority parameters), and\", \" \\nstored as user information to be referenced later by MVC actions or authorization filters. \\n\\nThe J\", \"WT bearer authentication middleware can also support more advanced scenarios, such as using a \\nlocal\", \" certificate to validate a token if the authority is not available. For this scenario, you can speci\", \"fy a \\nTokenValidationParameters object in the JwtBearerOptions object. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\", \"\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nSharing cookies between applications \\nhttps://learn.microsoft.com/aspnet/core/security/c\", \"ookie-sharing \\n\\nIntroduction to Identity \\nhttps://learn.microsoft.com/aspnet/core/security/authentic\", \"ation/identity \\n\\nRick Anderson. Two-factor authentication with SMS \\nhttps://learn.microsoft.com/aspn\", \"et/core/security/authentication/2fa \\n\\nEnabling authentication using Facebook, Google and other exter\", \"nal providers \\nhttps://learn.microsoft.com/aspnet/core/security/authentication/social/ \\n\\n\\u2022  Michell \", \"Anicas. An Introduction to OAuth 2 \\n\\nhttps://www.digitalocean.com/community/tutorials/an-introductio\", \"n-to-oauth-2 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nAspNet.Security.OAuth.Providers (GitHub repo for ASP.NET OAuth providers) \\nht\", \"tps://github.com/aspnet-contrib/AspNet.Security.OAuth.Providers/tree/dev/src \\n\\nIdentityServer4. Offi\", \"cial documentation \\nhttps://identityserver4.readthedocs.io/en/latest/ \\n\\nAbout authorization in .NET \", \"microservices and web \\napplications \\n\\nAfter authentication, ASP.NET Core Web APIs need to authorize \", \"access. This process allows a service \\nto make APIs available to some authenticated users, but not t\", \"o all. Authorization can be done based \\non users\\u2019 roles or based on custom policy, which might inclu\", \"de inspecting claims or other heuristics. \\n\\nRestricting access to an ASP.NET Core MVC route is as ea\", \"sy as applying an Authorize attribute to the \\naction method (or to the controller\\u2019s class if all the\", \" controller\\u2019s actions require authorization), as \\nshown in following example: \\n\\npublic class Account\", \"Controller : Controller \\n{ \\n    public ActionResult Login() \\n    { \\n    } \\n\\n    [Authorize] \\n\\n327 \\n\\n\", \"CHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n\\f    public ActionResult Log\", \"out() \\n    { \\n    } \\n} \\n\\nBy default, adding an Authorize attribute without parameters will limit acc\", \"ess to authenticated users \\nfor that controller or action. To further restrict an API to be availabl\", \"e for only specific users, the \\nattribute can be expanded to specify required roles or policies that\", \" users must satisfy. \\n\\nImplement role-based authorization \\n\\nASP.NET Core Identity has a built-in con\", \"cept of roles. In addition to users, ASP.NET Core Identity \\nstores information about different roles\", \" used by the application and keeps track of which users are \\nassigned to which roles. These assignme\", \"nts can be changed programmatically with the RoleManager \\ntype that updates roles in persisted stora\", \"ge, and the UserManager type that can grant or revoke roles \\nfrom users. \\n\\nIf you\\u2019re authenticating \", \"with JWT bearer tokens, the ASP.NET Core JWT bearer authentication \\nmiddleware will populate a user\\u2019\", \"s roles based on role claims found in the token. To limit access to an \\nMVC action or controller to \", \"users in specific roles, you can include a Roles parameter in the Authorize \\nannotation (attribute),\", \" as shown in the following code fragment: \\n\\n[Authorize(Roles = \\\"Administrator, PowerUser\\\")] \\npublic \", \"class ControlPanelController : Controller \\n{ \\n    public ActionResult SetTime() \\n    { \\n    } \\n\\n    \", \"[Authorize(Roles = \\\"Administrator\\\")] \\n    public ActionResult ShutDown() \\n    { \\n    } \\n} \\n\\nIn this \", \"example, only users in the Administrator or PowerUser roles can access APIs in the \\nControlPanel con\", \"troller (such as executing the SetTime action). The ShutDown API is further restricted \\nto allow acc\", \"ess only to users in the Administrator role. \\n\\nTo require a user be in multiple roles, you use multi\", \"ple Authorize attributes, as shown in the following \\nexample: \\n\\n[Authorize(Roles = \\\"Administrator, P\", \"owerUser\\\")] \\n[Authorize(Roles = \\\"RemoteEmployee \\\")] \\n[Authorize(Policy = \\\"CustomPolicy\\\")] \\npublic Ac\", \"tionResult API1 () \\n{ \\n} \\n\\nIn this example, to call API1, a user must: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n328 \\n\\nBe in the Adm\", \"inistrator or PowerUser role, and \\n\\nBe in the RemoteEmployee role, and \\n\\nCHAPTER 8 | Make secure .NE\", \"T Microservices and Web Applications \\n\\n \\n \\n \\n\\f\\u2022 \\n\\nSatisfy a custom handler for CustomPolicy authoriz\", \"ation. \\n\\nImplement policy-based authorization \\n\\nCustom authorization rules can also be written using\", \" authorization policies. This section provides an \\noverview. For more information, see the ASP.NET A\", \"uthorization Workshop. \\n\\nCustom authorization policies are registered in the Startup.ConfigureServic\", \"es method using the \\nservice.AddAuthorization method. This method takes a delegate that configures a\", \"n \\nAuthorizationOptions argument. \\n\\nservices.AddAuthorization(options => \\n{ \\n    options.AddPolicy(\\\"\", \"AdministratorsOnly\\\", policy => \\n        policy.RequireRole(\\\"Administrator\\\")); \\n\\n    options.AddPolic\", \"y(\\\"EmployeesOnly\\\", policy => \\n        policy.RequireClaim(\\\"EmployeeNumber\\\")); \\n\\n    options.AddPolic\", \"y(\\\"Over21\\\", policy => \\n        policy.Requirements.Add(new MinimumAgeRequirement(21))); \\n}); \\n\\nAs sh\", \"own in the example, policies can be associated with different types of requirements. After the \\npoli\", \"cies are registered, they can be applied to an action or controller by passing the policy\\u2019s name as \", \"\\nthe Policy argument of the Authorize attribute (for example, [Authorize(Policy=\\\"EmployeesOnly\\\")]) \\n\", \"Policies can have multiple requirements, not just one (as shown in these examples). \\n\\nIn the previou\", \"s example, the first AddPolicy call is just an alternative way of authorizing by role. If \\n[Authoriz\", \"e(Policy=\\\"AdministratorsOnly\\\")] is applied to an API, only users in the Administrator role will \\nbe \", \"able to access it. \\n\\nThe second AddPolicy call demonstrates an easy way to require that a particular\", \" claim should be \\npresent for the user. The RequireClaim method also optionally takes expected value\", \"s for the claim. If \\nvalues are specified, the requirement is met only if the user has both a claim \", \"of the correct type and \\none of the specified values. If you\\u2019re using the JWT bearer authentication \", \"middleware, all JWT \\nproperties will be available as user claims. \\n\\nThe most interesting policy show\", \"n here is in the third AddPolicy method, because it uses a custom \\nauthorization requirement. By usi\", \"ng custom authorization requirements, you can have a great deal of \\ncontrol over how authorization i\", \"s performed. For this to work, you must implement these types: \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nA Requirements type that de\", \"rives from IAuthorizationRequirement and that contains fields \\nspecifying the details of the require\", \"ment. In the example, this is an age field for the sample \\nMinimumAgeRequirement type. \\n\\nA handler t\", \"hat implements AuthorizationHandler, where T is the type of \\nIAuthorizationRequirement that the hand\", \"ler can satisfy. The handler must implement the \\nHandleRequirementAsync method, which checks whether\", \" a specified context that contains \\ninformation about the user satisfies the requirement. \\n\\n329 \\n\\nCH\", \"APTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n \\n\\fIf the user meets the requi\", \"rement, a call to context.Succeed will indicate that the user is authorized. If \\nthere are multiple \", \"ways that a user might satisfy an authorization requirement, multiple handlers can \\nbe created. \\n\\nIn\", \" addition to registering custom policy requirements with AddPolicy calls, you also need to register \", \"\\ncustom requirement handlers via Dependency Injection (services.AddTransient<IAuthorizationHandler, \", \"\\nMinimumAgeHandler>()). \\n\\nAn example of a custom authorization requirement and handler for checking \", \"a user\\u2019s age (based on a \\nDateOfBirth claim) is available in the ASP.NET Core authorization document\", \"ation. \\n\\nAuthorization and minimal apis \\n\\nASP.NET supports minimal APIs as an alternative to control\", \"ler-based APIs. Authorization policies are \\nthe recommended way to configure authorization for minim\", \"al APIs, as this example demonstrates: \\n\\n// Program.cs \\nbuilder.Services.AddAuthorizationBuilder() \\n\", \"  .AddPolicy(\\\"admin_greetings\\\", policy => \\n        policy \\n            .RequireRole(\\\"admin\\\") \\n      \", \"      .RequireScope(\\\"greetings_api\\\")); \\n\\n// build the app \\n\\napp.MapGet(\\\"/hello\\\", () => \\\"Hello world!\", \"\\\") \\n  .RequireAuthorization(\\\"admin_greetings\\\"); \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nASP.NET\", \" Core Authentication \\nhttps://learn.microsoft.com/aspnet/core/security/authentication/identity \\n\\nASP\", \".NET Core Authorization \\nhttps://learn.microsoft.com/aspnet/core/security/authorization/introduction\", \" \\n\\nRole-based Authorization \\nhttps://learn.microsoft.com/aspnet/core/security/authorization/roles \\n\\n\", \"Custom Policy-Based Authorization \\nhttps://learn.microsoft.com/aspnet/core/security/authorization/po\", \"licies \\n\\nAuthentication and authorization in minimal \\nAPIs  https://learn.microsoft.com/aspnet/core/\", \"fundamentals/minimal-apis/security \\n\\nStore application secrets safely during development \\n\\nTo connec\", \"t with protected resources and other services, ASP.NET Core applications typically need to \\nuse conn\", \"ection strings, passwords, or other credentials that contain sensitive information. These \\nsensitive\", \" pieces of information are called secrets. It\\u2019s a best practice to not include secrets in source \\n\\n3\", \"30 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n \\n\\fcode and making sure\", \" not to store secrets in source control. Instead, you should use the ASP.NET \\nCore configuration mod\", \"el to read the secrets from more secure locations. \\n\\nYou must separate the secrets for accessing dev\", \"elopment and staging resources from the ones used \\nfor accessing production resources, because diffe\", \"rent individuals will need access to those different \\nsets of secrets. To store secrets used during \", \"development, common approaches are to either store \\nsecrets in environment variables or by using the\", \" ASP.NET Core Secret Manager tool. For more secure \\nstorage in production environments, microservice\", \"s can store secrets in an Azure Key Vault. \\n\\nStore secrets in environment variables \\n\\nOne way to kee\", \"p secrets out of source code is for developers to set string-based secrets as \\nenvironment variables\", \" on their development machines. When you use environment variables to store \\nsecrets with hierarchic\", \"al names, such as the ones nested in configuration sections, you must name the \\nvariables to include\", \" the complete hierarchy of its sections, delimited with colons (:). \\n\\nFor example, setting an enviro\", \"nment variable Logging:LogLevel:Default to Debug value would be \\nequivalent to a configuration value\", \" from the following JSON file: \\n\\n{ \\n    \\\"Logging\\\": { \\n        \\\"LogLevel\\\": { \\n            \\\"Default\\\": \", \"\\\"Debug\\\" \\n        } \\n    } \\n} \\n\\nTo access these values from environment variables, the application ju\", \"st needs to call \\nAddEnvironmentVariables on its ConfigurationBuilder when constructing an IConfigur\", \"ationRoot \\nobject. \\n\\nNote \\n\\nEnvironment variables are commonly stored as plain text, so if the machi\", \"ne or process with the \\nenvironment variables is compromised, the environment variable values will b\", \"e visible. \\n\\nStore secrets with the ASP.NET Core Secret Manager \\n\\nThe ASP.NET Core Secret Manager to\", \"ol provides another method of keeping secrets out of source \\ncode during development. To use the Sec\", \"ret Manager tool, install the package \\nMicrosoft.Extensions.Configuration.SecretManager in your proj\", \"ect file. Once that dependency is \\npresent and has been restored, the dotnet user-secrets command ca\", \"n be used to set the value of \\nsecrets from the command line. These secrets will be stored in a JSON\", \" file in the user\\u2019s profile \\ndirectory (details vary by OS), away from source code. \\n\\nSecrets set by\", \" the Secret Manager tool are organized by the UserSecretsId property of the project \\nthat\\u2019s using th\", \"e secrets. Therefore, you must be sure to set the UserSecretsId property in your project \\nfile, as s\", \"hown in the snippet below. The default value is a GUID assigned by Visual Studio, but the \\nactual st\", \"ring is not important as long as it\\u2019s unique in your computer. \\n\\n331 \\n\\nCHAPTER 8 | Make secure .NET \", \"Microservices and Web Applications \\n\\n \\n \\n\\f<PropertyGroup> \\n    <UserSecretsId>UniqueIdentifyingStrin\", \"g</UserSecretsId> \\n</PropertyGroup> \\n\\nUsing secrets stored with Secret Manager in an application is \", \"accomplished by calling \\nAddUserSecrets<T> on the ConfigurationBuilder instance to include secrets f\", \"or the application in its \\nconfiguration. The generic parameter T should be a type from the assembly\", \" that the UserSecretId was \\napplied to. Usually, using AddUserSecrets<Startup> is fine. \\n\\nThe AddUse\", \"rSecrets<Startup>() is included in the default options for the Development environment \\nwhen using t\", \"he CreateDefaultBuilder method in Program.cs. \\n\\nUse Azure Key Vault to protect secrets at production\", \" \\ntime \\n\\nSecrets stored as environment variables or stored by the Secret Manager tool are still stor\", \"ed locally \\nand unencrypted on the machine. A more secure option for storing secrets is Azure Key Va\", \"ult, which \\nprovides a secure, central location for storing keys and secrets. \\n\\nThe Azure.Extensions\", \".AspNetCore.Configuration.Secrets package allows an ASP.NET Core \\napplication to read configuration \", \"information from Azure Key Vault. To start using secrets from an \\nAzure Key Vault, you follow these \", \"steps: \\n\\n1. \\n\\nRegister your application as an Azure AD application. (Access to key vaults is managed\", \" by \\nAzure AD.) This can be done through the Azure management portal. \\n\\nAlternatively, if you want y\", \"our application to authenticate using a certificate instead of a \\npassword or client secret, you can\", \" use the New-AzADApplication PowerShell cmdlet. The \\ncertificate that you register with Azure Key Va\", \"ult needs only your public key. Your application \\nwill use the private key. \\n\\n2. \\n\\nGive the register\", \"ed application access to the key vault by creating a new service principal. You \\ncan do this using t\", \"he following PowerShell commands: \\n\\n$sp = New-AzADServicePrincipal -ApplicationId \\\"<Application ID g\", \"uid>\\\" \\nSet-AzKeyVaultAccessPolicy -VaultName \\\"<VaultName>\\\" -ServicePrincipalName \\n$sp.ServicePrincip\", \"alNames[0] -PermissionsToSecrets all -ResourceGroupName \\\"<KeyVault \\nResource Group>\\\" \\n\\n3. \\n\\nInclude \", \"the key vault as a configuration source in your application by calling the \\nAzureKeyVaultConfigurati\", \"onExtensions.AddAzureKeyVault extension method when you create \\nan IConfigurationRoot instance. \\n\\nNo\", \"te that calling AddAzureKeyVault requires the application ID that was registered and given access \\nt\", \"o the key vault in the previous steps. Or you can firstly running the Azure CLI command: az login, \\n\", \"then using an overload of AddAzureKeyVault that takes a DefaultAzureCredential in place of the \\nclie\", \"nt. \\n\\n332 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n \\n  \\n\\fImportant \\n\\n\", \"We recommend that you register Azure Key Vault as the last configuration provider, so it can overrid\", \"e \\nconfiguration values from previous providers. \\n\\nAdditional resources \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\n\\u2022 \\n\\nUsing Azur\", \"e Key Vault to protect application secrets \\nhttps://learn.microsoft.com/azure/architecture/multitena\", \"nt-identity \\n\\nSafe storage of app secrets during development \\nhttps://learn.microsoft.com/aspnet/cor\", \"e/security/app-secrets \\n\\nConfiguring data protection \\nhttps://learn.microsoft.com/aspnet/core/securi\", \"ty/data-protection/configuration/overview \\n\\nData Protection key management and lifetime in ASP.NET C\", \"ore \\nhttps://learn.microsoft.com/aspnet/core/security/data-protection/configuration/default-\\nsetting\", \"s \\n\\n333 \\n\\nCHAPTER 8 | Make secure .NET Microservices and Web Applications \\n\\n \\n \\n\\fCHAPTER  9 \\n\\n.NET M\", \"icroservices \\nArchitecture key takeaways \\n\\nAs a summary and key takeaways, the following are the mos\", \"t important conclusions from this guide. \\n\\nBenefits of using containers. Container-based solutions p\", \"rovide important cost savings because \\nthey help reduce deployment problems caused by failing depend\", \"encies in production environments. \\nContainers significantly improve DevOps and production operation\", \"s. \\n\\nContainers will be ubiquitous. Docker-based containers are becoming the de facto standard in th\", \"e \\nindustry, supported by key vendors in the Windows and Linux ecosystems, such as Microsoft, Amazon\", \" \\nAWS, Google, and IBM. Docker will probably soon be ubiquitous in both the cloud and on-premises \\nd\", \"atacenters. \\n\\nContainers as a unit of deployment. A Docker container is becoming the standard unit o\", \"f \\ndeployment for any server-based application or service. \\n\\nMicroservices. The microservices archit\", \"ecture is becoming the preferred approach for distributed and \\nlarge or complex mission-critical app\", \"lications based on many independent subsystems in the form of \\nautonomous services. In a microservic\", \"e-based architecture, the application is built as a collection of \\nservices that are developed, test\", \"ed, versioned, deployed, and scaled independently. Each service can \\ninclude any related autonomous \", \"database. \\n\\nDomain-driven design and SOA. The microservices architecture patterns derive from servic\", \"e-\\noriented architecture (SOA) and domain-driven design (DDD). When you design and develop \\nmicroser\", \"vices for environments with evolving business needs and rules, it\\u2019s important to consider DDD \\nappro\", \"aches and patterns. \\n\\nMicroservices challenges. Microservices offer many powerful capabilities, like\", \" independent \\ndeployment, strong subsystem boundaries, and technology diversity. However, they also \", \"raise many \\nnew challenges related to distributed application development, such as fragmented and in\", \"dependent \\ndata models, resilient communication between microservices, eventual consistency, and ope\", \"rational \\ncomplexity that results from aggregating logging and monitoring information from multiple \", \"\\nmicroservices. These aspects introduce a much higher complexity level than a traditional monolithic\", \" \\napplication. As a result, only specific scenarios are suitable for microservice-based applications\", \". These \\ninclude large and complex applications with multiple evolving subsystems. In these cases, i\", \"t\\u2019s worth \\ninvesting in a more complex software architecture, because it will provide better long-te\", \"rm agility and \\napplication maintenance. \\n\\n334 \\n\\nCHAPTER 9 | .NET Microservices Architecture key tak\", \"eaways \\n\\n \\n \\n\\fContainers for any application. Containers are convenient for microservices, but can a\", \"lso be useful \\nfor monolithic applications based on the traditional .NET Framework, when using Windo\", \"ws \\nContainers. The benefits of using Docker, such as solving many deployment-to-production issues a\", \"nd \\nproviding state-of-the-art Dev and Test environments, apply to many different types of applicati\", \"ons. \\n\\nCLI versus IDE. With Microsoft tools, you can develop containerized .NET applications using y\", \"our \\npreferred approach. You can develop with a CLI and an editor-based environment by using the Doc\", \"ker \\nCLI and Visual Studio Code. Or you can use an IDE-focused approach with Visual Studio and its u\", \"nique \\nfeatures for Docker, such as multi-container debugging. \\n\\nResilient cloud applications. In cl\", \"oud-based systems and distributed systems in general, there is \\nalways the risk of partial failure. \", \"Since clients and services are separate processes (containers), a \\nservice might not be able to resp\", \"ond in a timely way to a client\\u2019s request. For example, a service might \\nbe down because of a partia\", \"l failure or for maintenance; the service might be overloaded and \\nresponding slowly to requests; or\", \" it might not be accessible for a short time because of network \\nissues. Therefore, a cloud-based ap\", \"plication must embrace those failures and have a strategy in place \\nto respond to those failures. Th\", \"ese strategies can include retry policies (resending messages or \\nretrying requests) and implementin\", \"g circuit-breaker patterns to avoid exponential load of repeated \\nrequests. Basically, cloud-based a\", \"pplications must have resilient mechanisms\\u2014either based on cloud \\ninfrastructure or custom, as the h\", \"igh-level ones provided by orchestrators or service buses. \\n\\nSecurity. Our modern world of container\", \"s and microservices can expose new vulnerabilities. There are \\nseveral ways to implement basic appli\", \"cation security, based on authentication and authorization. \\nHowever, container security must consid\", \"er additional key components that result in inherently safer \\napplications. A critical element of bu\", \"ilding safer apps is having a secure way of communicating with \\nother apps and systems, something th\", \"at often requires credentials, tokens, passwords, and the like, \\ncommonly referred to as application\", \" secrets. Any secure solution must follow security best practices, \\nsuch as encrypting secrets while\", \" in transit and at rest, and preventing secrets from leaking when \\nconsumed by the final application\", \". Those secrets need to be stored and kept safely, as when using \\nAzure Key Vault. \\n\\nOrchestrators. \", \"Container-based orchestrators, such as Azure Kubernetes Service and Azure Service \\nFabric are key pa\", \"rt of any significant microservice and container-based application. These applications \\ncarry with t\", \"hem high complexity, scalability needs, and go through constant evolution. This guide has \\nintroduce\", \"d orchestrators and their role in microservice-based and container-based solutions. If your \\napplica\", \"tion needs are moving you toward complex containerized apps, you will find it useful to seek \\nout ad\", \"ditional resources for learning more about orchestrators. \\n\\n335 \\n\\nCHAPTER 9 | .NET Microservices Arc\", \"hitecture key takeaways \\n\\n \\n \\n\\f\"]"