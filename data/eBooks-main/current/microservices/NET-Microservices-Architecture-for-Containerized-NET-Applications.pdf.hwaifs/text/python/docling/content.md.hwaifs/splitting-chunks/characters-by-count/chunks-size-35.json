"[\"<!-- image -->\\n\\n## Architecture for Containerized NET Applications\\n\\n<!-- image -->\\n\\nCesar de la Torr\", \"e Bill Wagner Mike Rousos\\n\\nMicrosoft Corporation\\n\\nEDITION v7.0 - Updated to ASP.NET Core 7.0\\n\\nRefer \", \"changelog for the book updates and community contributions.\\n\\nThis guide is an introduction to develo\", \"ping microservices-based applications and managing them using containers. It discusses architectural\", \" design and implementation approaches using .NET and Docker containers.\\n\\nTo make it easier to get st\", \"arted, the guide focuses on a reference containerized and microservicebased application that you can\", \" explore. The reference application is available at the eShopOnContainers GitHub repo.\\n\\n## Action li\", \"nks\\n\\n- This e-book is also available in a PDF format (English version only) Download\\n- Clone/Fork th\", \"e reference application eShopOnContainers on GitHub\\n- Watch the introductory video\\n- Get to know the\", \" Microservices Architecture right away\\n\\n## Introduction\\n\\nEnterprises are increasingly realizing cost\", \" savings, solving deployment problems, and improving DevOps and production operations by using conta\", \"iners. Microsoft has been releasing container innovations for Windows and Linux by creating products\", \" like Azure Kubernetes Service and Azure Service Fabric, and by partnering with industry leaders lik\", \"e Docker, Mesosphere, and Kubernetes. These products deliver container solutions that help companies\", \" build and deploy applications at cloud speed and scale, whatever their choice of platform or tools.\", \"\\n\\nDocker is becoming the de facto standard in the container industry, supported by the most signific\", \"ant vendors in the Windows and Linux ecosystems. (Microsoft is one of the main cloud vendors support\", \"ing Docker). In the future, Docker will probably be ubiquitous in any datacenter in the cloud or on-\", \"premises.\\n\\nIn addition, the microservices architecture is emerging as an important approach for dist\", \"ributed mission-critical applications. In a microservice-based architecture, the application is buil\", \"t on a collection of services that can be developed, tested, deployed, and versioned independently.\\n\", \"\\n## About this guide\\n\\nThis guide is an introduction to developing microservices-based applications a\", \"nd managing them using containers. It discusses architectural design and implementation approaches u\", \"sing .NET and Docker containers. To make it easier to get started with containers and microservices,\", \" the guide focuses on a reference containerized and microservice-based application that you can expl\", \"ore. The sample application is available at the eShopOnContainers GitHub repo.\\n\\n<!-- image -->\\n\\n<!--\", \" image -->\\n\\nThis guide provides foundational development and architectural guidance primarily at a d\", \"evelopment environment level with a focus on two technologies: Docker and .NET. Our intention is tha\", \"t you read this guide when thinking about your application design without focusing on the infrastruc\", \"ture (cloud or on-premises) of your production environment. You will make decisions about your infra\", \"structure later, when you create your production-ready applications. Therefore, this guide is intend\", \"ed to be infrastructure agnostic and more development-environment-centric.\\n\\nAfter you have studied t\", \"his guide, your next step would be to learn about production-ready microservices on Microsoft Azure.\", \"\\n\\n## Version\\n\\nThis guide has been revised to cover .NET 7 version along with many additional updates\", \" related to the same 'wave' of technologies (that is, Azure and additional third -party technologies\", \") coinciding in time with the .NET 7 release. That's why the book version has also been updated to v\", \"ersion 7.0 .\\n\\n## What this guide does not cover\\n\\nThis guide does not focus on the application lifecy\", \"cle, DevOps, CI/CD pipelines, or team work. The complementary guide Containerized Docker Application\", \" Lifecycle with Microsoft Platform and Tools focuses on that subject. The current guide also does no\", \"t provide implementation details on Azure infrastructure, such as information on specific orchestrat\", \"ors.\\n\\n## Additional resources\\n\\n- Containerized Docker Application Lifecycle with Microsoft Platform \", \"and Tools (downloadable e-book) https://aka.ms/dockerlifecycleebook\\n\\n## Who should use this guide\\n\\nW\", \"e wrote this guide for developers and solution architects who are new to Docker-based application de\", \"velopment and to microservices-based architecture. This guide is for you if you want to learn how to\", \" architect, design, and implement proof-of-concept applications with Microsoft development technolog\", \"ies (with special focus on .NET) and with Docker containers.\\n\\nYou will also find this guide useful i\", \"f you are a technical decision maker, such as an enterprise architect, who wants an architecture and\", \" technology overview before you decide on what approach to select for new and modern distributed app\", \"lications.\\n\\n## How to use this guide\\n\\nThe first part of this guide introduces Docker containers, dis\", \"cusses how to choose between .NET 7 and the .NET Framework as a development framework, and provides \", \"an overview of microservices. This content is for architects and technical decision makers who want \", \"an overview but don't need to focus on code implementation details.\\n\\n<!-- image -->\\n\\nThe second part\", \" of the guide starts with the Development process for Docker based applications section. It focuses \", \"on the development and microservice patterns for implementing applications using .NET and Docker. Th\", \"is section will be of most interest to developers and architects who want to focus on code and on pa\", \"tterns and implementation details.\\n\\n## Related microservice and container-based reference applicatio\", \"n: eShopOnContainers\\n\\nThe eShopOnContainers application is an open-source reference app for .NET and\", \" microservices that is designed to be deployed using Docker containers. The application consists of \", \"multiple subsystems, including several e-store UI front-ends (a Web MVC app, a Web SPA, and a native\", \" mobile app). It also includes the back-end microservices and containers for all required server-sid\", \"e operations.\\n\\nThe purpose of the application is to showcase architectural patterns. IT IS NOT A PRO\", \"DUCTIONREADY TEMPLATE to start real-world applications. In fact, the application is in a permanent b\", \"eta state, as it's also used to test new potentially interesting technologies as they show up.\\n\\n## C\", \"redits\\n\\nCo-Authors:\\n\\nCesar de la Torre , Sr. PM, .NET product team, Microsoft Corp.\\n\\nBill Wagner , S\", \"r. Content Developer, C+E, Microsoft Corp.\\n\\nMike Rousos , Principal Software Engineer, DevDiv CAT te\", \"am, Microsoft\\n\\nEditors:\\n\\nMike Pope\\n\\nSteve Hoag\\n\\nParticipants and reviewers:\\n\\nJeffrey Richter , Partn\", \"er Software Eng, Azure team, Microsoft\\n\\nJimmy Bogard , Chief Architect at Headspring\\n\\nUdi Dahan , Fo\", \"under &amp; CEO, Particular Software\\n\\nJimmy Nilsson , Co-founder and CEO of Factor10\\n\\nGlenn Condron \", \", Sr. Program Manager, ASP.NET team\\n\\nMark Fussell , Principal PM Lead, Azure Service Fabric team, Mi\", \"crosoft\\n\\nDiego Vega , PM Lead, Entity Framework team, Microsoft\\n\\nBarry Dorrans , Sr. Security Progra\", \"m Manager\\n\\nRowan Miller , Sr. Program Manager, Microsoft\\n\\nAnkit Asthana , Principal PM Manager, .NET\", \" team, Microsoft\\n\\nScott Hunter , Partner Director PM, .NET team, Microsoft\\n\\nNish Anil , Sr. Program \", \"Manager, .NET team, Microsoft\\n\\nDylan Reisenberger , Architect and Dev Lead at Polly\\n\\nSteve 'ardalis'\", \" Smith - Software Architect and Trainer - Ardalis.com\\n\\nIan Cooper , Coding Architect at Brighter\\n\\nUn\", \"ai Zorrilla , Architect and Dev Lead at Plain Concepts\\n\\nEduard Tomas , Dev Lead at Plain Concepts\\n\\nR\", \"amon Tomas , Developer at Plain Concepts\\n\\nDavid Sanz , Developer at Plain Concepts\\n\\nJavier Valero , \", \"Chief Operating Officer at Grupo Solutio\\n\\nPierre Millet , Sr. Consultant, Microsoft\\n\\nMichael Friis ,\", \" Product Manager, Docker Inc\\n\\nCharles Lowell , Software Engineer, VS CAT team, Microsoft\\n\\nMiguel Vel\", \"oso , Software Development Engineer at Plain Concepts\\n\\nSumit Ghosh , Principal Consultant at Neudesi\", \"c\\n\\n## Copyright\\n\\nPUBLISHED BY\\n\\nMicrosoft Developer Division, .NET and Visual Studio product teams\\n\\nA\", \" division of Microsoft Corporation\\n\\nOne Microsoft Way\\n\\nRedmond, Washington 98052-6399\\n\\nCopyright \\u00a9 2\", \"023 by Microsoft Corporation\\n\\nAll rights reserved. No part of the contents of this book may be repro\", \"duced or transmitted in any form or by any means without the written permission of the publisher.\\n\\nT\", \"his book is provided 'as -is' and expresses the author's views and opinions. The views, opinions and\", \" information expressed in this book, including URL and other Internet website references, may change\", \" without notice.\\n\\nSome examples depicted herein are provided for illustration only and are fictitiou\", \"s. No real association or connection is intended or should be inferred.\\n\\n<!-- image -->\\n\\n<!-- image \", \"-->\\n\\nMicrosoft and the trademarks listed at https://www.microsoft.com on the 'Trademarks' webpage ar\", \"e trademarks of the Microsoft group of companies.\\n\\nMac and macOS are trademarks of Apple Inc.\\n\\nThe D\", \"ocker whale logo is a registered trademark of Docker, Inc. Used by permission.\\n\\nAll other marks and \", \"logos are property of their respective owners.\\n\\n## Contents\\n\\n| Introduction to Containers and Docker\", \"................................................................................ 1                  \", \"                                                |\\n|-------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"-------------------------------------|\\n| What is Docker?............................................\", \"....................................................................................................\", \"........................2 |\\n| Comparing Docker containers with virtual machines.....................\", \"......................................................................3                             \", \"               |\\n| A simple analogy.................................................................\", \"................................................................................................4   \", \"    |\\n| Docker terminology..........................................................................\", \"......................................................................................5      |\\n| Doc\", \"ker containers, images, and registries .............................................................\", \"........................................................7                         |\\n| Choosing Betwe\", \"en .NET and .NET Framework for Docker Containers.............................. 9                    \", \"                                                                       |\\n| General guidance.........\", \"....................................................................................................\", \"........................................................9   |\\n| When to choose .NET for Docker conta\", \"iners...............................................................................................\", \".............. 10                                |\\n| Developing and deploying cross platform .......\", \"....................................................................................................\", \".10                                   |\\n| Using containers for new ('green - field') projects ......\", \".........................................................................................11         \", \"                           |\\n| Create and deploy microservices on containers........................\", \"..........................................................................11                        \", \"                |\\n| Deploying high density in scalable systems......................................\", \"....................................................................11                              \", \"     |\\n| When to choose .NET Framework for Docker containers........................................\", \"............................................. 12                                              |\\n| Us\", \"ing third-party .NET libraries or NuGet packages not available for .NET 7 ..........................\", \"...............12                                                                  |\\n| Using .NET te\", \"chnologies not available for .NET 7.................................................................\", \"..............................12                                        |\\n| Using a platform or API \", \"that doesn't support .NET 7 ........................................................................\", \"................13                                           |\\n| Porting existing ASP.NET applicatio\", \"n to .NET 7.........................................................................................\", \"..........13                                      |\\n| Decision table: .NET implementations to use fo\", \"r Docker ..................................................................................... 13   \", \"                                       |\\n| What OS to target with .NET containers...................\", \"................................................................................................... \", \"14                          |\\n| Official .NET Docker images ........................................\", \"....................................................................................................\", \". 16             |\\n| Container design principles ...................................................\", \"........................................................................................... 18      \", \"      |\\n| Containerizing monolithic applications ...................................................\", \".................................................................... 19                        |\\n| D\", \"eploying a monolithic application as a container....................................................\", \"........................................21                                          |\\n| Publishing a\", \" single-container-based application to Azure App Service............................................\", \"........21                                                               |\\n\\n| Manage state and data \", \"in Docker applications .............................................................................\", \"...........................                         | 22                                            \", \"                                                                        |\\n|-------------------------\", \"----------------------------------------------------------------------------------------------------\", \"--------------------------------------------------|-------------------------------------------------\", \"----------------------------------------------------------------------|\\n| Service-oriented architect\", \"ure.................................................................................................\", \"..........................................      | 25                                                \", \"                                                                    |\\n| Microservices architecture..\", \"....................................................................................................\", \"...........................................   | 25                                                  \", \"                                                                  |\\n| Additional resources..........\", \"....................................................................................................\", \".........................................27 |                                                       \", \"                                                                |\\n| Data sovereignty per microservic\", \"e ..................................................................................................\", \"..............................            | 27                                                      \", \"                                                              |\\n| The relationship between microserv\", \"ices and the Bounded Context pattern...........................................29                   \", \"                                        |                                                           \", \"                                                            |\\n| Logical architecture versus physical\", \" architecture.......................................................................................\", \"..............                        | 30                                                          \", \"                                                          |\\n| Challenges and solutions for distribut\", \"ed data management..............................................................................    \", \"                                    | 31                                                            \", \"                                                        |\\n| Challenge #1: How to define the boundari\", \"es of each microservice............................................................31               \", \"                                  |                                                                 \", \"                                                      |\\n| Challenge #2: How to create queries that r\", \"etrieve data from several microservices............................32                               \", \"                                |                                                                   \", \"                                                    |\\n| Challenge #3: How to achieve consistency acr\", \"oss multiple microservices...............................................33                         \", \"                              |                                                                     \", \"                                                  |\\n| Challenge #4: How to design communication acro\", \"ss microservice boundaries ....................................35                                   \", \"                            |                                                                       \", \"                                                |\\n| Additional resources............................\", \"....................................................................................................\", \".......................36 |                                                                         \", \"                                              |\\n| Identify domain-model boundaries for each microser\", \"vice..................................................................................              \", \"                        | 36                                                                        \", \"                                            |\\n| The API gateway pattern versus the Direct client-to-\", \"microservice communication..................................                                        \", \"                      | 40                                                                          \", \"                                          |\\n| Direct client-to-microservice communication...........\", \"...........................................................................................40       \", \"                    |                                                                               \", \"                                        |\\n| Why consider API Gateways instead of direct client-to-mi\", \"croservice communication .......................41                                                  \", \"                  |                                                                                 \", \"                                      |\\n| What is the API Gateway pattern?..........................\", \"...................................................................................................4\", \"2               |                                                                                   \", \"                                    |\\n| Main features in the API Gateway pattern ...................\", \"..........................................................................................44        \", \"              |                                                                                     \", \"                                  |\\n| Using products with API Gateway features......................\", \"......................................................................................45            \", \"            |                                                                                       \", \"                                |\\n| Drawbacks of the API Gateway pattern............................\", \".......................................................................................47           \", \"          |                                                                                         \", \"                              |\\n| Additional resources..............................................\", \"....................................................................................................\", \".....48 |                                                                                           \", \"                            |\\n| Communication in a microservice architecture .......................\", \".................................................................................                   \", \"      | 48                                                                                          \", \"                          |\\n| Communication types ..................................................\", \"..................................................................................................49\", \"    |                                                                                               \", \"                        |\\n| Asynchronous microservice integration enforces microservice's autonomy .\", \"..........................................50                                                        \", \"  |                                                                                                 \", \"                      |\\n| Communication styles......................................................\", \"..............................................................................................52    \", \"|                                                                                                   \", \"                    |\\n| Asynchronous message-based communication....................................\", \"...................................................................                               | \", \"54                                                                                                  \", \"                  |\\n| Single-receiver message-based communication ..................................\", \"..............................................................55                                |   \", \"                                                                                                    \", \"                |\\n| Multiple-receivers message-based communication..................................\", \"........................................................56                                    |     \", \"                                                                                                    \", \"              |\\n| Asynchronous event-driven communication...........................................\", \".............................................................56                             |       \", \"                                                                                                    \", \"            |\\n| A note about messaging technologies for production systems .........................\", \"..........................................57                                              |         \", \"                                                                                                    \", \"          |\\n| Resiliently publishing to the event bus                                               \", \"                                                                                        | ..........\", \"....................................................................................................\", \".....58 |\\n\\n| Additional resources...................................................................\", \"....................................................................................58              \", \"                                                                                        |    |\\n|----\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"------------------------------------------------------------------------|----|\\n| Creating, evolving,\", \" and versioning microservice APIs and contracts.....................................................\", \"..........                                                                                          \", \"                                                        | 59 |\\n| Additional resources...............\", \"....................................................................................................\", \"....................................59                                                              \", \"                                        |    |\\n| Microservices addressability and the service regist\", \"ry ............................................................................................     \", \"                                                                                                    \", \"                        | 60 |\\n| Additional resources...............................................\", \"....................................................................................................\", \"....60                                                                                              \", \"        |    |\\n| Creating composite UI based on microservices ......................................\", \".................................................................                                   \", \"                                                                                            | 60 |\\n|\", \" Additional resources...............................................................................\", \"........................................................................62                          \", \"                                                                            |    |\\n| Resiliency and \", \"high availability in microservices..................................................................\", \"....................................                                                                \", \"                                                            | 63 |\\n| Health management and diagnosti\", \"cs in microservices ................................................................................\", \"....63                                                                                              \", \"                                            |    |\\n| Additional resources...........................\", \"....................................................................................................\", \"........................65                                                                          \", \"                            |    |\\n| Orchestrate microservices and multi-container applications for \", \"high scalability and availability .......                                                           \", \"                                                                                                    \", \"            | 66 |\\n| Software platforms for container clustering, orchestration, and scheduling.....\", \"......................................68                                                            \", \"                                                                                                |   \", \" |\\n| Using container-based orchestrators in Microsoft Azure.........................................\", \".......................................68                                                           \", \"                                                                                |    |\\n| Using Azure\", \" Kubernetes Service ................................................................................\", \"................................................69                                                  \", \"                                                                |    |\\n| Development environment for\", \" Kubernetes.........................................................................................\", \"..................70                                                                                \", \"                                                |    |\\n| Getting started with Azure Kubernetes Servi\", \"ce (AKS) .......................................................................................70  \", \"                                                                                                    \", \"                                |    |\\n| Deploy with Helm charts into Kubernetes clusters...........\", \"..................................................................................71                \", \"                                                                                                    \", \"                |    |\\n| Additional resources.......................................................\", \"................................................................................................71  \", \"                                                                                                    \", \"|    |\\n| Development process for Docker-based applications..........................................\", \".............                                                                                       \", \"                                                                                    | 72 |\\n| Develop\", \"ment environment for Docker apps....................................................................\", \".........................................                                                           \", \"                                                                    | 72 |\\n| Development tool choice\", \"s: IDE or editor....................................................................................\", \"............................72                                                                      \", \"                                                    |    |\\n| Additional resources...................\", \"....................................................................................................\", \"................................73                                                                  \", \"                                    |    |\\n| .NET languages and frameworks for Docker containers ...\", \"....................................................................................                \", \"                                                                                                    \", \"                    | 73 |\\n| Development workflow for Docker apps...................................\", \"..................................................................................                  \", \"                                                                                                    \", \"    | 73 |\\n| Workflow for developing Docker container-based applications ...........................\", \".......................................73                                                           \", \"                                                                                        |    |\\n| Ste\", \"p 1. Start coding and create your initial application or service baseline...........................\", \"..................75                                                                                \", \"                                                                        |    |\\n| Step 2. Create a Do\", \"ckerfile related to an existing .NET base image.....................................................\", \".......76                                                                                           \", \"                                                        |    |\\n| Step 3. Create your custom Docker i\", \"mages and embed your application or service in them..........83                                     \", \"                                                                                                    \", \"                                        |    |\\n| Step 4. Define your services in docker-compose.yml \", \"when building a multi-container Docker application .................................................\", \"....................................................................................................\", \".....................84 |    |\\n| Step 5. Build and run your Docker application .....................\", \"...............................................................................87                   \", \"                                                                                                    \", \"        |    |\\n| Step 6. Test your Docker application using your local Docker host..................\", \"..........................................89                                                        \", \"                                                                                            |    |\\n\\n\", \"| Simplified workflow when developing containers with Visual Studio ................................\", \"........................90                                                                          \", \"                                 |                                                                  \", \"                                                                                                    \", \"                                                                  |\\n|-------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"-|--------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------|\\n| Using PowerShell commands in a Dockerfile to set up Windows Co\", \"ntainers.........................................91                                                 \", \"                                                                     |                              \", \"                                                                                                    \", \"                                                                                                    \", \"  |\\n| Designing and Developing Multi-Container and Microservice-Based .NET Applications ............\", \"....................................................................................................\", \"................................. 93 | Designing and Developing Multi-Container and Microservice-Bas\", \"ed .NET Applications ...............................................................................\", \".................................................................. 93 |\\n| Design a microservice-orie\", \"nted application ...................................................................................\", \"...........................                                                                         \", \"     | 93                                                                                           \", \"                                                                                                    \", \"                                      |\\n| Application specifications................................\", \"....................................................................................................\", \".........93                                                              |                          \", \"                                                                                                    \", \"                                                                                                    \", \"      |\\n| Development team context .................................................................\", \"........................................................................94                          \", \"                                         |                                                          \", \"                                                                                                    \", \"                                                                          |\\n| Choosing an architectu\", \"re..................................................................................................\", \"............................................94                                                      \", \"         |                                                                                          \", \"                                                                                                    \", \"                                          |\\n| Benefits of a microservice-based solution ............\", \".................................................................................................97 \", \"                                                                             |                      \", \"                                                                                                    \", \"                                                                                                    \", \"          |\\n| Downsides of a microservice-based solution ...........................................\", \"............................................................98                                      \", \"                                             |                                                      \", \"                                                                                                    \", \"                                                                              |\\n| External versus in\", \"ternal architecture and design patterns.............................................................\", \"..................99                                                                                \", \"             |                                                                                      \", \"                                                                                                    \", \"                                              |\\n| The new world: multiple architectural patterns and\", \" polyglot microservices..........................................100                                \", \"                                                                                 |                  \", \"                                                                                                    \", \"                                                                                                    \", \"              |\\n| Creating a simple data-driven CRUD microservice ..................................\", \".............................................................102                                    \", \"                                                 |                                                  \", \"                                                                                                    \", \"                                                                                  |\\n| Designing a si\", \"mple CRUD microservice..............................................................................\", \"..................................102                                                               \", \"                 |                                                                                  \", \"                                                                                                    \", \"                                                  |\\n| Implementing a simple CRUD microservice with A\", \"SP.NET Core.................................................................103                     \", \"                                                                                     |              \", \"                                                                                                    \", \"                                                                                                    \", \"                  |\\n| The DB connection string and environment variables used by Docker containers..\", \"...........................109                                                                      \", \"                                                     |                                              \", \"                                                                                                    \", \"                                                                                      |\\n| Generating\", \" Swagger description metadata from your ASP.NET Core Web API...................................111  \", \"                                                                                                    \", \"                     |                                                                              \", \"                                                                                                    \", \"                                                      |\\n| Defining your multi-container application \", \"with docker-compose.yml .........................................................116                \", \"                                                                                         |          \", \"                                                                                                    \", \"                                                                                                    \", \"                      |\\n| Use a database server running as a container .............................\", \"...........................................................................127                      \", \"                                                         |                                          \", \"                                                                                                    \", \"                                                                                          |\\n| SQL Se\", \"rver running as a container with a microservice-related database....................................\", \"..........128                                                                                       \", \"                         |                                                                          \", \"                                                                                                    \", \"                                                          |\\n| Seeding with test data on Web applicat\", \"ion startup.........................................................................................\", \"129                                                                                          |      \", \"                                                                                                    \", \"                                                                                                    \", \"                          |\\n| EF Core InMemory database versus SQL Server running as a container ...\", \"..............................................132                                                   \", \"                                                             |                                      \", \"                                                                                                    \", \"                                                                                              |\\n| Us\", \"ing a Redis cache service running in a container....................................................\", \".....................................132                                                            \", \"                             |                                                                      \", \"                                                                                                    \", \"                                                              |\\n| Implementing event-based communica\", \"tion between microservices (integration events) ...................133                              \", \"                                                                                                 |  \", \"                                                                                                    \", \"                                                                                                    \", \"                              |\\n| Using message brokers and service buses for production systems ...\", \".......................................................134                                          \", \"                                                                 |                                  \", \"                                                                                                    \", \"                                                                                                  |\\n\", \"| Integration events................................................................................\", \"..........................................................................135                       \", \"                                 |                                                                  \", \"                                                                                                    \", \"                                                                  |\\n| The event bus ................\", \"....................................................................................................\", \"..............................................136                                                   \", \" |                                                                                                  \", \"                                                                                                    \", \"                                  |\\n| Additional resources..........................................\", \"....................................................................................................\", \".......138                                                           |                              \", \"                                                                                                    \", \"                                                                                                    \", \"  |\\n| Implementing an event bus with RabbitMQ for the development or test environment...............\", \"........138                                                                                         \", \"                                     |                                                              \", \"                                                                                                    \", \"                                                                      |\\n| Implementing a simple publ\", \"ish method with RabbitMQ............................................................................\", \"...139                                                                                              \", \"     |                                                                                              \", \"                                                                                                    \", \"                                      |\\n| Implementing the subscription code with the RabbitMQ API..\", \"...................................................................140                              \", \"                                                                         |                          \", \"                                                                                                    \", \"                                                                                                    \", \"      |\\n| Additional resources......................................................................\", \"...............................................................................141                  \", \"                                         |                                                          \", \"                                                                                                    \", \"                                                                          |\\n\\n| Subscribing to events\", \"....................................................................................................\", \"....................................................141                                             \", \"                                                                     |                              \", \"                                                                                                    \", \"           |\\n|--------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"-----|----------------------------------------------------------------------------------------------\", \"-----------------------------------------------|\\n| Publishing events through the event bus..........\", \"...................................................................................................1\", \"42                                                                                                  \", \"                                         |                                                          \", \"                                                                                   |\\n| Idempotency i\", \"n update message events.............................................................................\", \".................................149                                                                \", \"                                                                             |                      \", \"                                                                                                    \", \"                   |\\n| Deduplicating integration event messages.....................................\", \"....................................................................150                             \", \"                                                                                                    \", \"             |                                                                                      \", \"                                                       |\\n| Testing ASP.NET Core services and web app\", \"s ..................................................................................................\", \"......152                                                                                           \", \"                                                 |                                                  \", \"                                                                                           |\\n| Testi\", \"ng in eShopOnContainers.............................................................................\", \"....................................................155                                             \", \"                                                                                     |              \", \"                                                                                                    \", \"                           |\\n| Implement background tasks in microservices with IHostedService and t\", \"he BackgroundService ...............................................................................\", \"....................................................................................................\", \".................157 | class                                                                        \", \"                                                               |\\n| Registering hosted services in yo\", \"ur WebHost or Host .................................................................................\", \"..159                                                                                               \", \"                                                         |                                          \", \"                                                                                                   |\", \"\\n| The IHostedService interface.....................................................................\", \"................................................................159                                 \", \"                                                                                             |      \", \"                                                                                                    \", \"                                   |\\n| Implementing IHostedService with a custom hosted service clas\", \"s deriving from the BackgroundService base                                                          \", \"                                                                                                    \", \"                             | class................................................................\", \"...................................................................160 |\\n| Additional resources.....\", \"....................................................................................................\", \"............................................163                                                     \", \"                                                                 |                                  \", \"                                                                                                    \", \"       |\\n| Implement API Gateways with Ocelot.......................................................\", \".................................................................163                                \", \"                                                                                                    \", \" |                                                                                                  \", \"                                           |\\n| Architect and design your API Gateways...............\", \"...............................................................................................163  \", \"                                                                                                    \", \"                                     |                                                              \", \"                                                                               |\\n| Implementing your\", \" API Gateways with Ocelot ..........................................................................\", \"........................168                                                                         \", \"                                                                         |                          \", \"                                                                                                    \", \"               |\\n| Using Kubernetes Ingress plus Ocelot API Gateways................................\", \"......................................................180                                           \", \"                                                                                                    \", \"         |                                                                                          \", \"                                                   |\\n| Additional cross-cutting features in an Ocelo\", \"t API Gateway .......................................................................181            \", \"                                                                                                    \", \"                                             |                                                      \", \"                                                                                       |\\n| Tackle Bu\", \"siness Complexity in a Microservice with DDD and CQRS Patterns ..............182                    \", \"                                                                                                    \", \"                                                                                 |                  \", \"                                                                                                    \", \"                       |\\n| Apply simplified CQRS and DDD patterns in a microservice.................\", \"............................................................184                                     \", \"                                                                                                    \", \"                 |                                                                                  \", \"                                                           |\\n| Additional resources.................\", \"....................................................................................................\", \"................................186                                                                 \", \"                                                     |                                              \", \"                                                                                               |\\n| A\", \"pply CQRS and CQS approaches in a DDD microservice in eShopOnContainers ............................\", \".....186                                                                                            \", \"                                                                                         |          \", \"                                                                                                    \", \"                               |\\n| CQRS and DDD patterns are not top-level architectures............\", \"...................................................................187                              \", \"                                                                                                    \", \"                         |                                                                          \", \"                                                                   |\\n| Implement reads/queries in a \", \"CQRS microservice ..................................................................................\", \"..............188                                                                                   \", \"                                                             |                                      \", \"                                                                                                    \", \"   |\\n| Use ViewModels specifically made for client apps, independent from domain model constraints .\", \"....................................................................................................\", \"..........................................................................................189    |  \", \"                                                                                                    \", \"                                       |\\n| Use Dapper as a micro ORM to perform queries.............\", \".................................................................................189                \", \"                                                                                                    \", \"                                 |                                                                  \", \"                                                                           |\\n| Dynamic versus static\", \" ViewModels.........................................................................................\", \"................................190                                                                 \", \"                                                                     |                              \", \"                                                                                                    \", \"           |\\n| Additional resources.................................................................\", \"....................................................................................193             \", \"                                                                                                    \", \"     |                                                                                              \", \"                                               |\\n| Design a DDD-oriented microservice ..............\", \"....................................................................................................\", \".......194                                                                                          \", \"                                         |                                                          \", \"                                                                                   |\\n| Keep the micr\", \"oservice context boundaries relatively small .......................................................\", \"...................194                                                                              \", \"                                                                             |                      \", \"                                                                                                    \", \"                   |\\n| Layers in DDD microservices                                                  \", \"                                                                                                    \", \"                                                                                                    \", \"             | .....................................................................................\", \"................................................195    |\\n\\n| Design a microservice domain model......\", \"....................................................................................................\", \"..............199                                                                                   \", \"                                  |\\n|---------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"------------|\\n| The Domain Entity pattern ..........................................................\", \"...............................................................................199                  \", \"                                                                                          |\\n| Implem\", \"ent a microservice domain model with .NET...........................................................\", \".................................204                                                                \", \"                                                                    |\\n| Domain model structure in a \", \"custom .NET Standard Library .......................................................................\", \"204                                                                                                 \", \"                                              |\\n| Structure aggregates in a custom .NET Standard lib\", \"rary ...............................................................................205             \", \"                                                                                                    \", \"                        |\\n| Implement domain entities as POCO classes ..............................\", \".......................................................................206                          \", \"                                                                                                    \", \"  |\\n| Encapsulate data in the Domain Entities ......................................................\", \"........................................................207                                         \", \"                                                                                |\\n| Seedwork (reusab\", \"le base classes and interfaces for your domain model)...............................................\", \"...210                                                                                              \", \"                                                          |\\n| The custom Entity base class..........\", \"....................................................................................................\", \".......................211                                                                          \", \"                                    |\\n| Repository contracts (interfaces) in the domain model layer \", \"......................................................................212                           \", \"                                                                                                    \", \"              |\\n| Additional resources..............................................................\", \".......................................................................................213          \", \"                                                                                            |\\n| Impl\", \"ement value objects.................................................................................\", \".................................................................213                                \", \"                                                                      |\\n| Important characteristics \", \"of value objects ...................................................................................\", \"........................214                                                                         \", \"                                                |\\n| Value object implementation in C#...............\", \"....................................................................................................\", \".....215                                                                                            \", \"                          |\\n| How to persist value objects in the database with EF Core 2.0 and late\", \"r................................................217                                                \", \"                                                                                                    \", \"    |\\n| Persist value objects as owned entity types in EF Core 2.0 and later........................\", \"................................218                                                                 \", \"                                                                                  |\\n| Additional res\", \"ources..............................................................................................\", \".......................................................221                                          \", \"                                                            |\\n| Use enumeration classes instead of e\", \"num types...........................................................................................\", \"........221                                                                                         \", \"                                      |\\n| Implement an Enumeration base class.......................\", \"...........................................................................................222      \", \"                                                                                                    \", \"                |\\n| Additional resources............................................................\", \".........................................................................................223        \", \"                                                                                              |\\n| De\", \"sign validations in the domain model layer .........................................................\", \"..............................................223                                                   \", \"                                                                        |\\n| Implement validations in\", \" the domain model layer.............................................................................\", \"..............224                                                                                   \", \"                                                  |\\n| Additional resources..........................\", \"....................................................................................................\", \".......................225                                                                          \", \"                            |\\n| Client-side validation (validation in the presentation layers)......\", \"......................................................................226                           \", \"                                                                                                    \", \"      |\\n| Additional resources......................................................................\", \"...............................................................................227                  \", \"                                                                                    |\\n| Domain event\", \"s: Design and implementation........................................................................\", \"..................................227                                                               \", \"                                                              |\\n| What is a domain event?...........\", \"....................................................................................................\", \"..............................228                                                                   \", \"                                        |\\n| Domain events versus integration events ................\", \"............................................................................................228     \", \"                                                                                                    \", \"                  |\\n| Domain events as a preferred way to trigger side effects across multiple aggre\", \"gates within the same domain .......................................................................\", \"............................................................................................229 |\\n| \", \"Implement domain events.............................................................................\", \".............................................................231                                    \", \"                                                                          |\\n| Conclusions on domain \", \"events..............................................................................................\", \"...................................237                                                              \", \"                                                    |\\n\\n| Additional resources.......................\", \"....................................................................................................\", \"..........................238       |                                                               \", \"                                                                                                    \", \"  |\\n|-----------------------------------------------------------------------------------------------\", \"-------------------------------------------------------------------------------------|--------------\", \"----------------------------------------------------------------------------------------------------\", \"---------------------------------------------------|\\n| Design the infrastructure persistence layer..\", \"....................................................................................................\", \"........238                       |                                                                 \", \"                                                                                                    \", \"|\\n| The Repository pattern .........................................................................\", \".......................................................................238         |                \", \"                                                                                                    \", \"                                                 |\\n| Additional resources...........................\", \"....................................................................................................\", \"......................243       |                                                                   \", \"                                                                                                  |\\n\", \"| Implement the infrastructure persistence layer with Entity Framework Core ........................\", \"....................243                                                          |                  \", \"                                                                                                    \", \"                                               |\\n| Introduction to Entity Framework Core............\", \"....................................................................................................\", \".244                          |                                                                     \", \"                                                                                                |\\n| \", \"Infrastructure in Entity Framework Core from a DDD perspective......................................\", \".......................244                                                     |                    \", \"                                                                                                    \", \"                                             |\\n| Implement custom repositories with Entity Framework\", \" Core......................................................................246                      \", \"                            |                                                                       \", \"                                                                                              |\\n| EF\", \" DbContext and IUnitOfWork instance lifetime in your IoC container..................................\", \"...............248                                                           |                      \", \"                                                                                                    \", \"                                           |\\n| The repository instance lifetime in your IoC containe\", \"r...................................................................................249             \", \"                          |                                                                         \", \"                                                                                            |\\n| Tabl\", \"e mapping                                                                                           \", \"                                                                           | .......................\", \"....................................................................................................\", \".....................................250 |\\n| Implement the Query Specification pattern..............\", \"..........................................................................................253       \", \"                        |                                                                           \", \"                                                                                          |\\n| Use No\", \"SQL databases as a persistence infrastructure.......................................................\", \"..................................255                                    |                          \", \"                                                                                                    \", \"                                       |\\n| Introduction to Azure Cosmos DB and the native Cosmos DB \", \"API ...........................................................256                                  \", \"                      |                                                                             \", \"                                                                                        |\\n| Implemen\", \"t .NET code targeting MongoDB and Azure Cosmos DB ..................................................\", \"........258                                                            |                            \", \"                                                                                                    \", \"                                     |\\n| Design the microservice application layer and Web API .....\", \"...............................................................................266                  \", \"                    |                                                                               \", \"                                                                                      |\\n| Use SOLID \", \"principles and Dependency Injection.................................................................\", \".............................266                                     |                              \", \"                                                                                                    \", \"                                   |\\n| Implement the microservice application layer using the Web AP\", \"I.................................................................267                               \", \"                  |                                                                                 \", \"                                                                                    |\\n| Use Dependen\", \"cy Injection to inject infrastructure objects into your application layer.....................267   \", \"                                                                   |                                \", \"                                                                                                    \", \"                                 |\\n| Implement the Command and Command Handler patterns ............\", \"...........................................................271                                      \", \"                |                                                                                   \", \"                                                                                  |\\n| The Command pr\", \"ocess pipeline: how to trigger a command handler....................................................\", \".278                                                             |                                  \", \"                                                                                                    \", \"                               |\\n| Implement the command process pipeline with a mediator pattern (M\", \"ediatR) ..................................281                                                       \", \"              |                                                                                     \", \"                                                                                |\\n| Apply cross-cutt\", \"ing concerns when processing commands with the Behaviors in MediatR                                 \", \"                                                               | ..........287                      \", \"                                                                                                    \", \"                             |\\n| Implement resilient applications ..................................\", \".....................................................291                                            \", \"            |                                                                                       \", \"                                                                              |\\n| Handle partial fai\", \"lure................................................................................................\", \".........................................................292 |                                      \", \"                                                                                                    \", \"                           |\\n| Strategies to handle partial failure.................................\", \"..............................................................................................294   \", \"          |                                                                                         \", \"                                                                            |\\n| Additional resources\", \"....................................................................................................\", \".................................................295       |                                        \", \"                                                                                                    \", \"                         |\\n| Implement retries with exponential backoff ............................\", \"................................................................................295                 \", \"        |                                                                                           \", \"                                                                          |\\n| Implement resilient En\", \"tity Framework Core SQL connections.................................................................\", \".........295                                             |                                          \", \"                                                                                                    \", \"                       |\\n| Execution strategies and explicit transactions using BeginTransaction and\", \" multiple DbContexts296                                                                             \", \"      |                                                                                             \", \"                                                                        |\\n| Additional resources....\", \"....................................................................................................\", \".............................................298       |                                            \", \"                                                                                                    \", \"                     |\\n| Use IHttpClientFactory to implement resilient HTTP requests                \", \"                                                                                                    \", \"    | .........................................................................298                  \", \"                                                                      |\\n\\n| Issues with the original \", \"HttpClient class available in .NET..................................................................\", \"...........298                                        |        |\\n|----------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------|--------|\\n| Benefits of using IHttpClientFactory.....\", \"....................................................................................................\", \"..............299                     |        |\\n| Multiple ways to use IHttpClientFactory..........\", \"....................................................................................................\", \".300                          |        |\\n| How to use Typed Clients with IHttpClientFactory.........\", \"..................................................................................300               \", \"                      |        |\\n| Additional resources.............................................\", \"....................................................................................................\", \"....304       |        |\\n| Implement HTTP call retries with exponential backoff with IHttpClientFact\", \"ory and Polly policies                                                                              \", \"      | ...304 |\\n| Add a jitter strategy to the retry policy........................................\", \".........................................................................305                      | \", \"       |\\n| Additional resources.....................................................................\", \"................................................................................306       |        |\", \"\\n| Implement the Circuit Breaker pattern............................................................\", \"...........................................................306                    |        |\\n| Imple\", \"ment Circuit Breaker pattern with IHttpClientFactory and Polly .....................................\", \"................307                                                       |        |\\n| Test Http ret\", \"ries and circuit breakers in eShopOnContainers......................................................\", \"................308                                               |        |\\n| Additional resources.\", \"....................................................................................................\", \"................................................310       |        |\\n| Health monitoring............\", \"....................................................................................................\", \"..............................................310 |        |\\n| Implement health checks in ASP.NET Co\", \"re services ........................................................................................\", \"311                                       |        |\\n| Use watchdogs................................\", \"....................................................................................................\", \"............................315   |        |\\n| Health checks when using orchestrators...............\", \"...............................................................................................317  \", \"                          |        |\\n| Advanced monitoring: visualization, analysis, and alerts ....\", \"...........................................................................317                      \", \"                  |        |\\n| Additional resources.................................................\", \"....................................................................................................\", \"318       |        |\\n| secure .NET Microservices and Web Applications...............................\", \"..................319                                                                               \", \"  |        |\\n| Implement authentication in .NET microservices and web applications .................\", \".....................................319                                                      |     \", \"   |\\n| Authenticate with ASP.NET Core Identity......................................................\", \".......................................................320                            |        |\\n| A\", \"uthenticate with external providers.................................................................\", \"....................................................321                       |        |\\n| Authentic\", \"ate with bearer tokens..............................................................................\", \"................................................323                   |        |\\n| Authenticate with\", \" an OpenID Connect or OAuth 2.0 Identity provider...................................................\", \"324                                                           |        |\\n| Issue security tokens fro\", \"m an ASP.NET Core service ..........................................................................\", \".............325                                      |        |\\n| Consume security tokens..........\", \"....................................................................................................\", \"..............................326             |        |\\n| Additional resources.....................\", \"....................................................................................................\", \".................................327  |        |\\n| About authorization in .NET microservices and web\", \" applications..................................................................327                  \", \"                              |        |\\n| Implement role-based authorization ......................\", \"...............................................................................................328  \", \"                      |        |\\n| Implement policy-based authorization ............................\", \".....................................................................................329            \", \"              |        |\\n| Authorization and minimal apis ..........................................\", \".....................................................................................330            \", \"      |        |\\n| Additional resources.............................................................\", \"........................................................................................330       | \", \"       |\\n\\n| Store application secrets safely during development.....................................\", \".....................................................330                             |\\n|------------\", \"----------------------------------------------------------------------------------------------------\", \"--------------------------------------------------------------|\\n| Store secrets in environment varia\", \"bles ...............................................................................................\", \"..................331                  |\\n| Store secrets with the ASP.NET Core Secret Manager.......\", \".............................................................................331                    \", \"                |\\n| Use Azure Key Vault to protect secrets at production time ......................\", \"........................................................332                                  |\\n| Add\", \"itional resources...................................................................................\", \"..................................................................333 |\\n| .NET Microservices Archite\", \"cture key takeaways..............................................................334                \", \"                                               |\\n\\nDocker Host\\n\\nApp 1\\n\\nApp 2\\n\\n## Introduction to Cont\", \"ainers and Docker\\n\\nContainerization is an approach to software development in which an application o\", \"r service, its dependencies, and its configuration (abstracted as deployment manifest files) are pac\", \"kaged together as a container image. The containerized application can be tested as a unit and deplo\", \"yed as a container image instance to the host operating system (OS).\\n\\nJust as shipping containers al\", \"low goods to be transported by ship, train, or truck regardless of the cargo inside, software contai\", \"ners act as a standard unit of software deployment that can contain different code and dependencies.\", \" Containerizing software this way enables developers and IT professionals to deploy them across envi\", \"ronments with little or no modification.\\n\\nContainers also isolate applications from each other on a \", \"shared OS. Containerized applications run on top of a container host that in turn runs on the OS (Li\", \"nux or Windows). Containers therefore have a significantly smaller footprint than virtual machine (V\", \"M) images.\\n\\nEach container can run a whole web application or a service, as shown in Figure 2-1. In \", \"this example, Docker host is a container host, and App1, App2, Svc 1, and Svc 2 are containerized ap\", \"plications or services.\\n\\nFigure 2-1. Multiple containers running on a container host\\n\\n<!-- image -->\", \"\\n\\nCustomer\\n\\nDatacenter\\n\\nAnother benefit of containerization is scalability. You can scale out quickl\", \"y by creating new containers for short-term tasks. From an application point of view, instantiating \", \"an image (creating a container) is similar to instantiating a process like a service or a web app. F\", \"or reliability, however, when you run multiple instances of the same image across multiple host serv\", \"ers, you typically want each container (image instance) to run in a different host server or VM in d\", \"ifferent fault domains.\\n\\nIn short, containers offer the benefits of isolation, portability, agility,\", \" scalability, and control across the whole application lifecycle workflow. The most important benefi\", \"t is the environment's isolation provided between Dev and Ops. Azure Provider\\n\\nDocker\\n\\n## What is Do\", \"cker?\\n\\nDocker is an open-source project for automating the deployment of applications as portable, s\", \"elfsufficient containers that can run on the cloud or on-premises. Docker is also a company that pro\", \"motes and evolves this technology, working in collaboration with cloud, Linux, and Windows vendors, \", \"including Microsoft.\\n\\nFigure 2-2. Docker deploys containers at all layers of the hybrid cloud.\\n\\n<!--\", \" image -->\\n\\nDocker containers can run anywhere, on-premises in the customer datacenter, in an extern\", \"al service provider or in the cloud, on Azure. Docker image containers can run natively on Linux and\", \" Windows. However, Windows images can run only on Windows hosts and Linux images can run on Linux ho\", \"sts and Windows hosts (using a Hyper-V Linux VM, so far), where host means a server or a VM.\\n\\nDevelo\", \"pers can use development environments on Windows, Linux, or macOS. On the development computer, the \", \"developer runs a Docker host where Docker images are deployed, including the app and its dependencie\", \"s. Developers who work on Linux or on macOS use a Docker host that is Linux based, and they can crea\", \"te images only for Linux containers. (Developers working on macOS can edit code or run the Docker CL\", \"I from macOS, but as of the time of this writing, containers don't run\\n\\nApp 1\\n\\nBins/Libs\\n\\nGuest OS\\n\\n\", \"App 2\\n\\nBins/Libs\\n\\nApp 3\\n\\nBins/Libs\\n\\nApp 1\\n\\nBins/Libs\\n\\nApp 2\\n\\nBins/Libs\\n\\nApp 3\\n\\nBins/Libs directly on\", \" macOS.) Developers who work on Windows can create images for either Linux or Windows Containers.\\n\\nT\", \"o host containers in development environments and provide additional developer tools, Docker ships D\", \"ocker Desktop for Windows or for macOS. These products install the necessary VM (the Docker host) to\", \" host the containers.\\n\\nTo run Windows Containers, there are two types of runtimes:\\n\\n- Windows Server\", \" Containers provide application isolation through process and namespace isolation technology. A Wind\", \"ows Server Container shares a kernel with the container host and with all containers running on the \", \"host.\\n- Hyper-V Containers expand on the isolation provided by Windows Server Containers by running \", \"each container in a highly optimized virtual machine. In this configuration, the kernel of the conta\", \"iner host isn't shared with the Hyper -V Containers, providing better isolation.\\n\\nThe images for the\", \"se containers are created the same way and function the same. The difference is in how the container\", \" is created from the image running a Hyper-V Container requires an extra parameter. For details, see\", \" Hyper-V Containers.\\n\\n## Comparing Docker containers with virtual machines\\n\\nFigure 2-3 shows a compa\", \"rison between VMs and Docker containers.\\n\\n<!-- image -->\\n\\nFigure 2-3. Comparison of traditional virt\", \"ual machines to Docker containers\\n\\n| Virtual Machines                                               \", \"                                                                                                    \", \"                 | Docker Containers                                                                \", \"                                                                                                    \", \"                                                                                                    \", \"                    |\\n|-----------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----|-----------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"-------|\\n| Virtual machines include the application, the required libraries or binaries, and a full \", \"guest operating system. Full virtualization requires more resources than containerization. | Contain\", \"ers include the application and all its dependencies. However, they share the OS kernel with other c\", \"ontainers, running as isolated processes in user space on the host operating system. (Except in Hype\", \"r-V containers, where each container runs inside of a special virtual machine per container.) |\\n\\nFor\", \" VMs, there are three base layers in the host server, from the bottom-up: infrastructure, Host Opera\", \"ting System and a Hypervisor and on top of all that each VM has its own OS and all necessary librari\", \"es. For Docker, the host server only has the infrastructure and the OS and on top of that, the conta\", \"iner engine, that keeps container isolated but sharing the base OS services.\\n\\nBecause containers req\", \"uire far fewer resources (for example, they don't need a full OS), they're easy to deploy and they s\", \"tart fast. This allows you to have higher density, meaning that it allows you to run more services o\", \"n the same hardware unit, thereby reducing costs.\\n\\nAs a side effect of running on the same kernel, y\", \"ou get less isolation than VMs.\\n\\nThe main goal of an image is that it makes the environment (depende\", \"ncies) the same across different deployments. This means that you can debug it on your machine and t\", \"hen deploy it to another machine with the same environment guaranteed.\\n\\nA container image is a way t\", \"o package an app or service and deploy it in a reliable and reproducible way. You could say that Doc\", \"ker isn't only a technology but also a philosophy and a process.\\n\\nWhen using Docker, you won't hear \", \"developers say, 'It works on my machine, why not in production?' They can simply say, 'It runs on Do\", \"cker', because the packaged Docker application can be executed on any supported Docker environment, \", \"and it runs the way it was intended to on all deployment targets (such as Dev, QA, staging, and prod\", \"uction).\\n\\n## A simple analogy\\n\\nPerhaps a simple analogy can help getting the grasp of the core conce\", \"pt of Docker.\\n\\nLet's go back in time to the 1950s for a moment. There were no word processors, and t\", \"he photocopiers were used everywhere (kind of).\\n\\nImagine you're responsible for quickly issuing batc\", \"hes of letters as required, to mail them to customers, using real paper and envelopes, to be deliver\", \"ed physically to each customer's address (there was no email back then).\\n\\nAt some point, you realize\", \" the letters are just a composition of a large set of paragraphs, which are picked and arranged as n\", \"eeded, according to the purpose of the letter, so you devise a system to issue letters quickly, expe\", \"cting to get a hefty raise.\\n\\nThe system is simple:\\n\\n1. You begin with a deck of transparent sheets c\", \"ontaining one paragraph each.\\n\\n2. To issue a set of letters, you pick the sheets with the paragraphs\", \" you need, then you stack and align them so they look and read fine.\\n3. Finally, you place the set i\", \"n the photocopier and press start to produce as many letters as required.\\n\\nSo, simplifying, that's t\", \"he core idea of Docker.\\n\\nIn Docker, each layer is the resulting set of changes that happen to the fi\", \"lesystem after executing a command, such as, installing a program.\\n\\nSo, when you 'look' at the files\", \"ystem after the layer has been copied, you see all the files, included in the layer when the program\", \" was installed.\\n\\nYou can think of an image as an auxiliary readonly hard disk ready to be installed \", \"in a 'computer' where the operating system is already installed.\\n\\nSimilarly, you can think of a cont\", \"ainer as the 'computer' with the image hard disk installed. The container, just like a computer, can\", \" be powered on or off.\\n\\n## Docker terminology\\n\\nThis section lists terms and definitions you should b\", \"e familiar with before getting deeper into Docker. For further definitions, see the extensive glossa\", \"ry provided by Docker.\\n\\nContainer image : A package with all the dependencies and information needed\", \" to create a container. An image includes all the dependencies (such as frameworks) plus deployment \", \"and execution configuration to be used by a container runtime. Usually, an image derives from multip\", \"le base images that are layers stacked on top of each other to form the container's filesystem. An i\", \"mage is immutable once it has been created.\\n\\nDockerfile : A text file that contains instructions for\", \" building a Docker image. It's like a batch script, the first line states the base image to begin wi\", \"th and then follow the instructions to install required programs, copy files, and so on, until you g\", \"et the working environment you need.\\n\\nBuild : The action of building a container image based on the \", \"information and context provided by its Dockerfile, plus additional files in the folder where the im\", \"age is built. You can build images with the following Docker command:\\n\\ndocker build\\n\\nContainer : An \", \"instance of a Docker image. A container represents the execution of a single application, process, o\", \"r service. It consists of the contents of a Docker image, an execution environment, and a standard s\", \"et of instructions. When scaling a service, you create multiple instances of a container from the sa\", \"me image. Or a batch job can create multiple containers from the same image, passing different param\", \"eters to each instance.\\n\\nVolumes : Offer a writable filesystem that the container can use. Since ima\", \"ges are read-only but most programs need to write to the filesystem, volumes add a writable layer, o\", \"n top of the container image, so the programs have access to a writable filesystem. The p rogram doe\", \"sn't know it's accessing a\\n\\nlayered filesystem, it's just the filesystem as usual. Volumes live in t\", \"he host system and are managed by Docker.\\n\\nTag : A mark or label you can apply to images so that dif\", \"ferent images or versions of the same image (depending on the version number or the target environme\", \"nt) can be identified.\\n\\nMulti-stage Build : Is a feature, since Docker 17.05 or higher, that helps t\", \"o reduce the size of the final images. For example, a large base image, containing the SDK can be us\", \"ed for compiling and publishing and then a small runtime-only base image can be used to host the app\", \"lication.\\n\\nRepository (repo) : A collection of related Docker images, labeled with a tag that indica\", \"tes the image version. Some repos contain multiple variants of a specific image, such as an image co\", \"ntaining SDKs (heavier), an image containing only runtimes (lighter), etc. Those variants can be mar\", \"ked with tags. A single repo can contain platform variants, such as a Linux image and a Windows imag\", \"e.\\n\\nRegistry : A service that provides access to repositories. The default registry for most public \", \"images is Docker Hub (owned by Docker as an organization). A registry usually contains repositories \", \"from multiple teams. Companies often have private registries to store and manage images they've crea\", \"ted. Azure Container Registry is another example.\\n\\nMulti-arch image : For multi-architecture (or mul\", \"ti-platform ), it's a Docker feature that simplifies the selection of the appropriate image, accordi\", \"ng to the platform where Docker is running. For example, when a Dockerfile requests a base image FRO\", \"M mcr.microsoft.com/dotnet/sdk:7.0 from the registry, it actually gets 7.0-nanoserver-ltsc2022 , 7.0\", \"-nanoserver-1809 or 7.0-bullseye-slim , depending on the operating system and version where Docker i\", \"s running.\\n\\nDocker Hub : A public registry to upload images and work with them. Docker Hub provides \", \"Docker image hosting, public or private registries, build triggers and web hooks, and integration wi\", \"th GitHub and Bitbucket.\\n\\nAzure Container Registry : A public resource for working with Docker image\", \"s and its components in Azure. This provides a registry that's close to your deployments in Azure an\", \"d that gives you control over access, making it possible to use your Azure Active Directory groups a\", \"nd permissions.\\n\\nDocker Trusted Registry (DTR) : A Docker registry service (from Docker) that can be\", \" installed onpremises so it lives within the organization's datacenter and network. It's convenient \", \"for private images that should be managed within the enterprise. Docker Trusted Registry is included\", \" as part of the Docker Datacenter product.\\n\\nDocker Desktop : Development tools for Windows and macOS\", \" for building, running, and testing containers locally. Docker Desktop for Windows provides developm\", \"ent environments for both Linux and Windows Containers. The Linux Docker host on Windows is based on\", \" a Hyper-V virtual machine. The host for Windows Containers is directly based on Windows. Docker Des\", \"ktop for Mac is based on the Apple Hypervisor framework and the xhyve hypervisor, which provides a L\", \"inux Docker host virtual machine on macOS. Docker Desktop for Windows and for Mac replaces Docker To\", \"olbox, which was based on Oracle VirtualBox.\\n\\nCompose : A command-line tool and YAML file format wit\", \"h metadata for defining and running multicontainer applications. You define a single application bas\", \"ed on multiple images with one or more .yml files that can override values depending on the environm\", \"ent. Afte r you've created the definitions,\\n\\nyou can deploy the whole multi-container application wi\", \"th a single command (docker-compose up) that creates a container per image on the Docker host.\\n\\nClus\", \"ter : A collection of Docker hosts exposed as if it were a single virtual Docker host, so that the a\", \"pplication can scale to multiple instances of the services spread across multiple hosts within the c\", \"luster. Docker clusters can be created with Kubernetes, Azure Service Fabric, Docker Swarm and Mesos\", \"phere DC/OS.\\n\\nOrchestrator : A tool that simplifies the management of clusters and Docker hosts. Orc\", \"hestrators enable you to manage their images, containers, and hosts through a command-line interface\", \" (CLI) or a graphical UI. You can manage container networking, configurations, load balancing, servi\", \"ce discovery, high availability, Docker host configuration, and more. An orchestrator is responsible\", \" for running, distributing, scaling, and healing workloads across a collection of nodes. Typically, \", \"orchestrator products are the same products that provide cluster infrastructure, like Kubernetes and\", \" Azure Service Fabric, among other offerings in the market.\\n\\n## Docker containers, images, and regis\", \"tries\\n\\nWhen using Docker, a developer creates an app or service and packages it and its dependencies\", \" into a container image. An image is a static representation of the app or service and its configura\", \"tion and dependencies.\\n\\nTo run the app or service, the app's image is instantiated to create a conta\", \"iner, which will be running on the Docker host. Containers are initially tested in a development env\", \"ironment or PC.\\n\\nDevelopers should store images in a registry, which acts as a library of images and\", \" is needed when deploying to production orchestrators. Docker maintains a public registry via Docker\", \" Hub; other vendors provide registries for different collections of images, including Azure Containe\", \"r Registry. Alternatively, enterprises can have a private registry on-premises for their own Docker \", \"images.\\n\\nFigure 2-4 shows how images and registries in Docker relate to other components. It also sh\", \"ows the multiple registry offerings from vendors.\\n\\nBasic taxonomy in Docker\\n\\nRegistry\\n\\nHosted Docker\", \"\\n\\nRegistry\\n\\nDocker Trusted\\n\\nRegistry on-prem.\\n\\nI'n' private organizations)\\n\\nFigure 2-4. Taxonomy of \", \"Docker terms and concepts\\n\\n<!-- image -->\\n\\nThe registry is like a bookshelf where images are stored \", \"and available to be pulled for building containers to run services or web apps. There are private Do\", \"cker registries on-premises and on the public cloud. Docker Hub is a public registry maintained by D\", \"ocker, along the Docker Trusted Registry an enterprise-grade solution, Azure offers the Azure Contai\", \"ner Registry. AWS, Google, and others also have container registries.\\n\\nPutting images in a registry \", \"lets you store static and immutable application bits, including all their dependencies at a framewor\", \"k level. Those images can then be versioned and deployed in multiple environments and therefore prov\", \"ide a consistent deployment unit.\\n\\nPrivate image registries, either hosted on-premises or in the clo\", \"ud, are recommended when:\\n\\n- Your images must not be shared publicly due to confidentiality.\\n- You w\", \"ant to have minimum network latency between your images and your chosen deployment environment. For \", \"example, if your production environment is Azure cloud, you probably want to store your images in Az\", \"ure Container Registry so that network latency will be minimal. In a similar way, if your production\", \" environment is on-premises, you might want to have an on-premises Docker Trusted Registry available\", \" within the same local network.\\n\\nOn-premises\\n\\n## Choosing Between .NET and .NET Framework for Docker\", \" Containers\\n\\nThere are two supported frameworks for building server-side containerized Docker applic\", \"ations with .NET: .NET Framework and .NET 7. They share many .NET platform components, and you can s\", \"hare code across the two. However, there are fundamental differences between them, and which framewo\", \"rk you use will depend on what you want to accomplish. This section provides guidance on when to cho\", \"ose each framework.\\n\\n## General guidance\\n\\nThis section provides a summary of when to choose .NET 7 o\", \"r .NET Framework. We provide more details about these choices in the sections that follow.\\n\\nUse .NET\", \" 7, with Linux or Windows Containers, for your containerized Docker server application when:\\n\\n- You \", \"have cross-platform needs. For example, you want to use both Linux and Windows Containers.\\n- Your ap\", \"plication architecture is based on microservices.\\n- You need to start containers fast and want a sma\", \"ll footprint per container to achieve better density or more containers per hardware unit in order t\", \"o lower your costs.\\n\\nIn short, when you create new containerized .NET applications, you should consi\", \"der .NET 7 as the default choice. It has many benefits and fits best with the containers philosophy \", \"and style of working.\\n\\nAn extra benefit of using .NET 7 is that you can run side-by-side .NET versio\", \"ns for applications within the same machine. This benefit is more important for servers or VMs that \", \"do not use containers, because containers isolate the versions of .NET that the app needs. (As long \", \"as they are compatible with the underlying OS.)\\n\\nUse .NET Framework for your containerized Docker se\", \"rver application when:\\n\\n- Your application currently uses .NET Framework and has strong dependencies\", \" on Windows.\\n\\n- You need to use Windows APIs that are not supported by .NET 7.\\n- You need to use thi\", \"rd-party .NET libraries or NuGet packages that are not available for .NET 7.\\n\\nUsing .NET Framework o\", \"n Docker can improve your deployment experiences by minimizing deployment issues. This 'lift and shi\", \"ft' scenario is important for containerizing legacy applications that were originally developed with\", \" the traditional .NET Framework, like ASP.NET WebForms, MVC web apps, or WCF (Windows Communication \", \"Foundation) services.\\n\\n## Additional resources\\n\\n- E-book: Modernize existing .NET Framework applicat\", \"ions with Azure and Windows Containers https://aka.ms/liftandshiftwithcontainersebook\\n- Sample apps:\", \" Modernization of legacy ASP.NET web apps by using Windows Containers https://aka.ms/eshopmodernizin\", \"g\\n\\n## When to choose .NET for Docker containers\\n\\nThe modularity and lightweight nature of .NET 7 mak\", \"es it perfect for containers. When you deploy and start a container, its image is far smaller with .\", \"NET 7 than with .NET Framework. In contrast, to use .NET Framework for a container, you must base yo\", \"ur image on the Windows Server Core image, which is a lot heavier than the Windows Nano Server or Li\", \"nux images that you use for .NET 7.\\n\\nAdditionally, .NET 7 is cross-platform, so you can deploy serve\", \"r apps with Linux or Windows container images. However, if you are using the traditional .NET Framew\", \"ork, you can only deploy images based on Windows Server Core.\\n\\nThe following is a more detailed expl\", \"anation of why to choose .NET 7.\\n\\n## Developing and deploying cross platform\\n\\nClearly, if your goal \", \"is to have an application (web app or service) that can run on multiple platforms supported by Docke\", \"r (Linux and Windows), the right choice is .NET 7, because .NET Framework only supports Windows.\\n\\n.N\", \"ET 7 also supports macOS as a development platform. However, when you deploy containers to a Docker \", \"host, that host must (currently) be based on Linux or Windows. For example, in a development environ\", \"ment, you could use a Linux VM running on a Mac.\\n\\nVisual Studio provides an integrated development e\", \"nvironment (IDE) for Windows and supports Docker development.\\n\\nVisual Studio for Mac is an IDE, evol\", \"ution of Xamarin Studio, that runs on macOS and supports Docker-based application development. This \", \"tool should be the preferred choice for developers working in Mac machines who also want to use a po\", \"werful IDE.\\n\\nYou can also use Visual Studio Code on macOS, Linux, and Windows. Visual Studio Code fu\", \"lly supports .NET 7, including IntelliSense and debugging. Because VS Code is a lightweight editor, \", \"you\\n\\ncan use it to develop containerized apps on the machine in conjunction with the Docker CLI and \", \"the .NET CLI. You can also target .NET 7 with most third-party editors like Sublime, Emacs, vi, and \", \"the open-source OmniSharp project, which also provides IntelliSense support.\\n\\nIn addition to the IDE\", \"s and editors, you can use the .NET CLI for all supported platforms.\\n\\n## Using containers for new ('\", \"green -field') projects\\n\\nContainers are commonly used in conjunction with a microservices architectu\", \"re, although they can also be used to containerize web apps or services that follow any architectura\", \"l pattern. You can use .NET Framework on Windows Containers, but the modularity and lightweight natu\", \"re of .NET 7 makes it perfect for containers and microservices architectures. When you create and de\", \"ploy a container, its image is far smaller with .NET 7 than with .NET Framework.\\n\\n## Create and depl\", \"oy microservices on containers\\n\\nYou could use the traditional .NET Framework for building microservi\", \"ces-based applications (without containers) by using plain processes. That way, because the .NET Fra\", \"mework is already installed and shared across processes, processes are light and fast to start. Howe\", \"ver, if you are using containers, the image for the traditional .NET Framework is also based on Wind\", \"ows Server Core and that makes it too heavy for a microservices-on-containers approach. However, tea\", \"ms have been looking for opportunities to improve the experience for .NET Framework users as well. R\", \"ecently, size of the Windows Server Core container images have been reduced to &gt;40% smaller.\\n\\nOn \", \"the other hand, .NET 7 is the best candidate if you're embracing a microservices -oriented system th\", \"at is based on containers because .NET 7 is lightweight. In addition, its related container images, \", \"for either Linux or Windows Nano Server, are lean and small, making containers light and fast to sta\", \"rt.\\n\\nA microservice is meant to be as small as possible: to be light when spinning up, to have a sma\", \"ll footprint, to have a small Bounded Context (check DDD, Domain-Driven Design), to represent a smal\", \"l area of concerns, and to be able to start and stop fast. For those requirements, you will want to \", \"use small and fast-to-instantiate container images like the .NET 7 container image.\\n\\nA microservices\", \" architecture also allows you to mix technologies across a service boundary. This approach enables a\", \" gradual migration to .NET 7 for new microservices that work in conjunction with other microservices\", \" or with services developed with Node.js, Python, Java, GoLang, or other technologies.\\n\\n## Deploying\", \" high density in scalable systems\\n\\nWhen your container-based system needs the best possible density,\", \" granularity, and performance, .NET and ASP.NET Core are your best options. ASP.NET Core is up to 10\", \" times faster than ASP.NET in the traditional .NET Framework, and it leads to other popular industry\", \" technologies for microservices, such as Java servlets, Go, and Node.js.\\n\\nThis approach is especiall\", \"y relevant for microservices architectures, where you could have hundreds of microservices (containe\", \"rs) running. With ASP.NET Core images (based on the .NET runtime) on Linux or Windows Nano, you can \", \"run your system with a much lower number of servers or VMs, ultimately saving costs in infrastructur\", \"e and hosting.\\n\\n## When to choose .NET Framework for Docker containers\\n\\nWhile .NET 7 offers signific\", \"ant benefits for new applications and application patterns, .NET Framework will continue to be a goo\", \"d choice for many existing scenarios.\\n\\n## Migrating existing applications directly to a Windows Serv\", \"er container\\n\\nYou might want to use Docker containers just to simplify deployment, even if you are n\", \"ot creating microservices. For example, perhaps you want to improve your DevOps workflow with Docker\", \" -containers can give you better isolated test environments and can also eliminate deployment issues\", \" caused by missing dependencies when you move to a production environment. In cases like these, even\", \" if you are deploying a monolithic application, it makes sense to use Docker and Windows Containers \", \"for your current .NET Framework applications.\\n\\nIn most cases for this scenario, you will not need to\", \" migrate your existing applications to .NET 7; you can use Docker containers that include the tradit\", \"ional .NET Framework. However, a recommended approach is to use .NET 7 as you extend an existing app\", \"lication, such as writing a new service in ASP.NET Core.\\n\\n## Using third-party .NET libraries or NuG\", \"et packages not available for .NET 7\\n\\nThird-party libraries are quickly embracing .NET Standard, whi\", \"ch enables code sharing across all .NET flavors, including .NET 7. With .NET Standard 2.0 and later,\", \" the API surface compatibility across different frameworks has become significantly larger. Even mor\", \"e, .NET Core 2.x and newer applications can also directly reference existing .NET Framework librarie\", \"s (see .NET Framework 4.6.1 supporting .NET Standard 2.0).\\n\\nIn addition, the Windows Compatibility P\", \"ack extends the API surface available for .NET Standard 2.0 on Windows. This pack allows recompiling\", \" most existing code to .NET Standard 2.x with little or no modification, to run on Windows.\\n\\nHowever\", \", even with that exceptional progression since .NET Standard 2.0 and .NET Core 2.1 or later, there m\", \"ight be cases where certain NuGet packages need Windows to run and might not support .NET Core or la\", \"ter. If those packages are critical for your application, then you will need to use .NET Framework o\", \"n Windows Containers.\\n\\n## Using .NET technologies not available for .NET 7\\n\\nSome .NET Framework tech\", \"nologies aren't available in .NET 7. Some of them might become available in later releases, but othe\", \"rs don't fit the new application patterns targeted by .NET Core and might never be available.\\n\\nThe f\", \"ollowing list shows most of the technologies that aren't available in .NET 7:\\n\\n- ASP.NET Web Forms. \", \"This technology is only available on .NET Framework. Currently there are no plans to bring ASP.NET W\", \"eb Forms to .NET or later.\\n- Workflow-related services. Windows Workflow Foundation (WF), Workflow S\", \"ervices (WCF + WF in a single service), and WCF Data Services (formerly known as ADO.NET Data Servic\", \"es) are only available on .NET Framework. There are currently no plans to bring them to .NET 7.\\n\\nIn \", \"addition to the technologies listed in the official .NET roadmap, other features might be ported to \", \"the new unified .NET platform. You might consider participating in the discussions on GitHub so that\", \" your voice can be heard. And if you think something is missing, file a new issue in the dotnet/runt\", \"ime GitHub repository.\\n\\n## Using a platform or API that doesn't support .NET 7\\n\\nSome Microsoft and t\", \"hirdparty platforms don't support .NET 7. For example, some Azure services provide an SDK that isn't\", \" yet available for consumption on .NET 7 yet. Most Azure SDK should eventually be ported to .NET 7/.\", \"NET Standard, but some might not for several reasons. You can see the available Azure SDKs in the Az\", \"ure SDK Latest Releases page.\\n\\nIn the meantime, if any platform or service in Azure still doesn't su\", \"pport .NET 7 with its client API, you can use the equivalent REST API from the Azure service or the \", \"client SDK on .NET Framework.\\n\\n## Porting existing ASP.NET application to .NET 7\\n\\n.NET Core is a rev\", \"olutionary step forward from .NET Framework. It offers a host of advantages over .NET Framework acro\", \"ss the board from productivity to performance, and from cross-platform support to developer satisfac\", \"tion. If you are using .NET Framework and planning to migrate your application to .NET Core or .NET \", \"5+, see Porting Existing ASP.NET Apps to .NET Core.\\n\\n## Additional resources\\n\\n- .NET fundamentals ht\", \"tps://learn.microsoft.com/dotnet/fundamentals\\n- Porting Projects to .NET 5 https://learn.microsoft.c\", \"om/events/dotnetconf-2020/porting-projects-to-net-5\\n- .NET on Docker Guide\\n\\nhttps://learn.microsoft.\", \"com/dotnet/core/docker/introduction\\n\\n## Decision table: .NET implementations to use for Docker\\n\\nThe \", \"following decision table summarizes whether to use .NET Framework or .NET 7. Remember that for Linux\", \" containers, you need Linux-based Docker hosts (VMs or servers), and that for Windows Containers, yo\", \"u need Windows Server-based Docker hosts (VMs or servers).\\n\\n## Important\\n\\nYour development machines \", \"will run one Docker host, either Linux or Windows. Related microservices that you want to run and te\", \"st together in one solution will all need to run on the same container platform.\\n\\n| Architecture / A\", \"pp Type                                             | Linux containers                              \", \"                              | Windows Containers                                                  \", \"                       |\\n|---------------------------------------------------------------------|----\", \"-------------------------------------------------------------------------|--------------------------\", \"------------------------------------------------------------------|\\n| Microservices on containers   \", \"                                      | .NET 7                                                      \", \"                | .NET 7                                                                            \", \"         |\\n| Monolithic app                                                      | .NET 7           \", \"                                                           | .NET Framework .NET 7                  \", \"                                                    |\\n| Best-in-class performance and scalability   \", \"                        | .NET 7                                                                    \", \"  | .NET 7                                                                                     |\\n| W\", \"indows Server legacy app ('brown - field') migration to containers | -                              \", \"                                             | .NET Framework                                       \", \"                                      |\\n| New container-based development ('green - field')         \", \"          | .NET 7                                                                      | .NET 7    \", \"                                                                                 |\\n| ASP.NET Core   \", \"                                                     | .NET 7                                       \", \"                               | .NET 7 (recommended) .NET Framework                                \", \"                        |\\n| ASP.NET 4 (MVC 5, Web API 2, and Web Forms)                         | - \", \"                                                                          | .NET Framework          \", \"                                                                   |\\n| SignalR services             \", \"                                       | .NET Core 2.1 or higher version                            \", \"                 | .NET Framework .NET Core 2.1 or higher version                                   \", \"          |\\n| WCF, WF, and other legacy frameworks                                | WCF in .NET Core\", \" (client library only) or CoreWCF                           | .NET Framework WCF in .NET 7 (client l\", \"ibrary only) or CoreWCF                              |\\n| Consumption of Azure services              \", \"                         | .NET 7 (eventually most Azure services will provide client SDKs for .NET \", \"7) | .NET Framework .NET 7 (eventually most Azure services will provide client SDKs for .NET 7) |\\n\\n#\", \"# What OS to target with .NET containers\\n\\nGiven the diversity of operating systems supported by Dock\", \"er and the differences between .NET Framework and .NET 7, you should target a specific OS and specif\", \"ic versions depending on the framework you are using.\\n\\nFor Windows, you can use Windows Server Core \", \"or Windows Nano Server. These Windows versions provide different characteristics (IIS in Windows Ser\", \"ver Core versus a self-hosted web server like Kestrel in Nano Server) that might be needed by .NET F\", \"ramework or .NET 7, respectively.\\n\\nFor Linux, multiple distros are available and supported in offici\", \"al .NET Docker images (like Debian).\\n\\nExisting\\n\\n\\u2022NET\\n\\napps\\n\\nWhat OS to target with .NET containers\\n\\n\", \"In Figure 3-1, you can see the possible OS version depending on the .NET framework used.\\n\\n3.5, 4.x\\n\\n\", \"Server Core\\n\\nIIS\\n\\nLarger Image\\n\\nFigure 3-1. Operating systems to target depending on versions of the\", \" .NET framework\\n\\n<!-- image -->\\n\\nWhen deploying legacy .NET Framework applications you have to targe\", \"t Windows Server Core, compatible with legacy apps and IIS, but it has a larger image. When deployin\", \"g .NET 7 applications, you can target Windows Nano Server, which is cloud optimized, uses Kestrel an\", \"d is smaller and starts faster. You can also target Linux, supporting Debian, Alpine, and others.\\n\\nY\", \"ou can also create your own Docker image in cases where you want to use a different Linux distro or \", \"where you want an image with versions not provided by Microsoft. For example, you might create an im\", \"age with ASP.NET Core running on the traditional .NET Framework and Windows Server Core, which is a \", \"not-so-common scenario for Docker.\\n\\nWhen you add the image name to your Dockerfile file, you can sel\", \"ect the operating system and version depending on the tag you use, as in the following examples:\\n\\n| \", \"Image                                                | Comments                                     \", \"                                                                                                    \", \"                        |\\n|------------------------------------------------------|------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------|\\n| mcr.microsoft.com/dotnet/runtime:7.0        \", \"         | .NET 7 multi-architecture: Supports Linux and Windows Nano Server depending on the Docker\", \" host.                                                                          |\\n| mcr.microsoft.co\", \"m/dotnet/aspnet:7.0                  | ASP.NET Core 7.0 multi-architecture: Supports Linux and Windo\", \"ws Nano Server depending on the Docker host. The aspnetcore image has a few optimizations for ASP.NE\", \"T Core. |\\n| mcr.microsoft.com/dotnet/aspnet:7.0- bullseye-slim   | .NET 7 runtime-only on Linux Debi\", \"an distro                                                                                           \", \"                                    |\\n| mcr.microsoft.com/dotnet/aspnet:7.0- nanoserver-1809 | .NET \", \"7 runtime-only on Windows Nano Server (Windows Server version 1809)                                 \", \"                                                                |\\n\\n## Official .NET Docker images\\n\\nT\", \"he Official .NET Docker images are Docker images created and optimized by Microsoft. They're publicl\", \"y available on Microsoft Artifact Registry. You can search over the catalog to find all .NET image r\", \"epositories, for example .NET SDK repository.\\n\\nEach repository can contain multiple images, dependin\", \"g on .NET versions, and depending on the OS and versions (Linux Debian, Linux Alpine, Windows Nano S\", \"erver, Windows Server Core, and so on). Image repositories provide extensive tagging to help you sel\", \"ect not just a specific framework version, but also to choose an OS (Linux distribution or Windows v\", \"ersion).\\n\\n## .NET and Docker image optimizations for development versus production\\n\\nWhen building Do\", \"cker images for developers, Microsoft focused on the following main scenarios:\\n\\n- Images used to dev\", \"elop and build .NET apps.\\n- Images used to run .NET apps.\\n\\nWhy multiple images? When developing, bui\", \"lding, and running containerized applications, you usually have different priorities. By providing d\", \"ifferent images for these separate tasks, Microsoft helps optimize the separate processes of develop\", \"ing, building, and deploying apps.\\n\\n## During development and build\\n\\nDuring development, what is imp\", \"ortant is how fast you can iterate changes, and the ability to debug the changes. The size of the im\", \"age isn't as important as the ability to make changes to your code and see the changes quickly. Some\", \" tools and 'build -agent c ontainers', use the development .NET image ( mcr.microsoft.com/dotnet/sdk\", \":7.0 ) during development and build process. When building inside a Docker container, the important \", \"aspects are the elements that are needed to compile your app. This includes the compiler and any oth\", \"er .NET dependencies.\\n\\nWhy is this type of build image important? You don't deploy this image to pro\", \"duction. Instead, it's an image that you use to build the content you place into a production image.\", \" This image would be used in your continuous integration (CI) environment or build environment when \", \"using Docker multi-stage builds.\\n\\n## In production\\n\\nWhat is important in production is how fast you \", \"can deploy and start your containers based on a production .NET image. Therefore, the runtime-only i\", \"mage based on mcr.microsoft.com/dotnet/aspnet:7.0 is small so that it can travel quickly across the \", \"network from your Docker registry to your Docker hosts. The contents are ready to run, enabling the \", \"fastest time from starting the container to processing results. In the Docker model, there is no nee\", \"d for compilation from C# code, as there's when you run dotnet b uild or dotnet publish when using t\", \"he build container.\\n\\nIn this optimized image, you put only the binaries and other content needed to \", \"run the application. For example, the content created by dotnet publish contains only the compiled .\", \"NET binaries, images, .js, and .css files. Over time, you'll see images that contain pre-jitted (the\", \" compilation from IL to native that occurs at run time) packages.\\n\\nAlthough there are multiple versi\", \"ons of the .NET and ASP.NET Core images, they all share one or more layers, including the base layer\", \". Therefore, the amount of disk space needed to store an image is small; it consists only of the del\", \"ta between your custom image and its base image. The result is that it's quick to pull the image fro\", \"m your registry.\\n\\nWhen you explore the .NET image repositories at Microsoft Artifact Registry, you'l\", \"l find multiple image versions classified or marked with tags. These tags help to decide which one t\", \"o use, depending on the version you need, like those in the following table:\\n\\n| Image               \", \"                 | Comments                                                                         \", \"                 |\\n|--------------------------------------|-----------------------------------------\", \"----------------------------------------------------------|\\n| mcr.microsoft.com/dotnet/aspnet: 7.0 |\", \" ASP.NET Core, with runtime only and ASP.NET Core optimizations, on Linux and Windows (multi-arch) |\", \"\\n| mcr.microsoft.com/dotnet/sdk: 7.0    | .NET 7, with SDKs included, on Linux and Windows (multi-ar\", \"ch)                                     |\\n\\nYou can find all the available docker images in dotnet-do\", \"cker and also refer to the latest preview releases by using nightly build mcr.microsoft.com/dotnet/n\", \"ightly/*\\n\\n## Architecting container and microservice-based applications\\n\\nMicroservices offer great b\", \"enefits but also raise huge new challenges. Microservice architecture patterns are fundamental pilla\", \"rs when creating a microservice-based application.\\n\\nEarlier in this guide, you learned basic concept\", \"s about containers and Docker. That information was the minimum you needed to get started with conta\", \"iners. Even though containers are enablers of, and a great fit for microservices, they aren't mandat\", \"ory for a microservice architecture. Many architectural concepts in this architecture section could \", \"be applied without containers. However, this guide focuses on the intersection of both due to the al\", \"ready introduced importance of containers.\\n\\nEnterprise applications can be complex and are often com\", \"posed of multiple services instead of a single service-based application. For those cases, you need \", \"to understand other architectural approaches, such as the microservices and certain Domain-Driven De\", \"sign (DDD) patterns plus container orchestration concepts. Note that this chapter describes not just\", \" microservices on containers, but any containerized application, as well.\\n\\n## Container design princ\", \"iples\\n\\nIn the container model, a container image instance represents a single process. By defining a\", \" container image as a process boundary, you can create primitives that can be used to scale or batch\", \" the process.\\n\\nWhen you design a container image, you'll see an ENTRYPOINT definition in the Dockerf\", \"ile. This definition defines the process whose lifetime controls the lifetime of the container. When\", \" the process completes, the container lifecycle ends. Containers might represent long-running proces\", \"ses like web servers, but can also represent short-lived processes like batch jobs, which formerly m\", \"ight have been implemented as Azure WebJobs.\\n\\nIf the process fails, the container ends, and the orch\", \"estrator takes over. If the orchestrator was configured to keep five instances running and one fails\", \", the orchestrator will create another container instance to replace the failed process. In a batch \", \"job, the process is started with parameters. When the process completes, the work is complete. This \", \"guidance drills-down on orchestrators, later on.\\n\\nMonolithic Containerized application\\n\\nApp 1 = 1 Co\", \"ntainer\\n\\nA monolithic application has most of its functionality within\\n\\na single process/container t\", \"hat is componentized with internal\\n\\nYou might find a scenario where you want multiple processes runn\", \"ing in a single container. For that scenario, since there can be only one entry point per container,\", \" you could run a script within the container that launches as many programs as needed. For example, \", \"you can use Supervisor or a similar tool to take care of launching multiple processes inside a singl\", \"e container. However, even though you can find architectures that hold multiple processes per contai\", \"ner, that approach isn't very common.\\n\\n## Containerizing monolithic applications\\n\\nYou might want to \", \"build a single, monolithically deployed web application or service and deploy it as a container. The\", \" application itself might not be internally monolithic, but structured as several libraries, compone\", \"nts, or even layers (application layer, domain layer, data-access layer, etc.). Externally, however,\", \" it's a single containera single process, a single web application, or a single service.\\n\\nTo manage \", \"this model, you deploy a single container to represent the application. To increase capacity, you sc\", \"ale out, that is, just add more copies with a load balancer in front. The simplicity comes from mana\", \"ging a single deployment in a single container or VM.\\n\\nFigure 4-1. Example of the architecture of a \", \"containerized monolithic application\\n\\n<!-- image -->\\n\\nYou can include multiple components, libraries\", \", or internal layers in each container, as illustrated in Figure 4-1. A monolithic containerized app\", \"lication has most of its functionality within a single container, with internal layers or libraries,\", \" and scales out by cloning the container on multiple servers/VMs. However, this monolithic pattern m\", \"ight conflict with the container principle 'a container does one thing, and does it in one process',\", \" but might be ok for some cases.\\n\\nThe downside of this approach becomes evident if the application g\", \"rows, requiring it to scale. If the entire application can scale, it isn't really a problem. However\", \", in most cases, just a few parts of the application are the choke points that require scaling, whil\", \"e other components are used less.\\n\\nFor example, in a typical e-commerce application, you likely need\", \" to scale the product information subsystem, because many more customers browse products than purcha\", \"se them. More customers use\\n\\nHost 1\\n\\n(Server/VM)\\n\\nHost 2\\n\\n(Server/VM)\\n\\nHost 3\\n\\n(Server/VM)\\n\\nHost run\", \"ning multiple apps/containers their basket than use the payment pipeline. Fewer customers add commen\", \"ts or view their purchase history. And you might have only a handful of employees that need to manag\", \"e the content and marketing campaigns. If you scale the monolithic design, all the code for these di\", \"fferent tasks is deployed multiple times and scaled at the same grade.\\n\\nThere are multiple ways to s\", \"cale an application-horizontal duplication, splitting different areas of the application, and partit\", \"ioning similar business concepts or data. But, in addition to the problem of scaling all components,\", \" changes to a single component require complete retesting of the entire application, and a complete \", \"redeployment of all the instances.\\n\\nHowever, the monolithic approach is common, because the developm\", \"ent of the application is initially easier than for microservices approaches. Thus, many organizatio\", \"ns develop using this architectural approach. While some organizations have had good enough results,\", \" others are hitting limits. Many organizations designed their applications using this model because \", \"tools and infrastructure made it too difficult to build service-oriented architectures (SOA) years a\", \"go, and they did not see the needuntil the application grew.\\n\\nFrom an infrastructure perspective, ea\", \"ch server can run many applications within the same host and have an acceptable ratio of efficiency \", \"in resources usage, as shown in Figure 4-2.\\n\\nFigure 4-2. Monolithic approach: Host running multiple \", \"apps, each app running as a container\\n\\n<!-- image -->\\n\\nMonolithic applications in Microsoft Azure ca\", \"n be deployed using dedicated VMs for each instance. Additionally, using Azure virtual machine scale\", \" sets, you can easily scale the VMs. Azure App Service can also run monolithic applications and easi\", \"ly scale instances without requiring you to manage the VMs. Since 2016, Azure App Services can run s\", \"ingle instances of Docker containers as well, simplifying deployment.\\n\\nAs a QA environment or a limi\", \"ted production environment, you can deploy multiple Docker host VMs and balance them using the Azure\", \" balancer, as shown in Figure 4-3. This lets you manage scaling with a coarse-grain approach, becaus\", \"e the whole application lives within a single container.\\n\\nBrowser or\\n\\nClient app\\n\\nArchitecture in Do\", \"cker infrastructure for monolithic applications\\n\\nMicrosoft\\n\\nAzure\\n\\n\\u2022 i\\n\\n## Host 1 (VM) A or\\n\\nFigure \", \"4-3. Example of multiple hosts scaling up a single container application\\n\\n<!-- image -->\\n\\nDeployment\", \" to the various hosts can be managed with traditional deployment techniques. Docker hosts can be man\", \"aged with commands like docker run or docker-compose performed manually, or through automation such \", \"as continuous delivery (CD) pipelines.\\n\\n## Deploying a monolithic application as a container\\n\\nThere \", \"are benefits to using containers to manage monolithic application deployments. Scaling container ins\", \"tances is far faster and easier than deploying additional VMs. Even if you use virtual machine scale\", \" sets, VMs take time to start. When deployed as traditional application instances instead of contain\", \"ers, the configuration of the application is managed as part of the VM, which isn't ideal.\\n\\nDeployin\", \"g updates as Docker images is far faster and network efficient. Docker images typically start in sec\", \"onds, which speeds rollouts. Tearing down a Docker image instance is as easy as issuing a docker sto\", \"p command, and typically completes in less than a second.\\n\\nBecause containers are immutable by desig\", \"n, you never need to worry about corrupted VMs. In contrast, update scripts for a VM might forget to\", \" account for some specific configuration or file left on disk.\\n\\nWhile monolithic applications can be\", \"nefit from Docker, we're touching only on the benefits. Additional benefits of managing containers c\", \"ome from deploying with container orchestrators, which manage the various instances and lifecycle of\", \" each container instance. Breaking up the monolithic application into subsystems that can be scaled,\", \" developed, and deployed individually is your entry point into the realm of microservices.\\n\\n## Publi\", \"shing a single-container-based application to Azure App Service\\n\\nWhether you want to get validation \", \"of a container deployed to Azure or when an application is simply a single-container application, Az\", \"ure App Service provides a great way to provide scalable singlecontainer-based services. Using Azure\", \" App Service is simple. It provides great integration with Git to make it easy to take your code, bu\", \"ild it in Visual Studio, and deploy it directly to Azure.\\n\\nPublish\\n\\nSelect existing or cre\\n\\nTarget\\n\\n\", \"Specific target\\n\\nApp Service\\n\\nContainer Registry\\n\\nAPI Management\\n\\nFigure 4-4. Publishing a single-co\", \"ntainer application to Azure App Service from Visual Studio 2022\\n\\n<!-- image -->\\n\\nWithout Docker, if\", \" you needed other capabilities, frameworks, or dependencies that aren't supported in Azure App Servi\", \"ce, you had to wait until the Azure team updated those dependencies in App Service. Or you had to sw\", \"itch to other services like Azure Cloud Services or VMs, where you had further control and you could\", \" install a required component or framework for your application.\\n\\nContainer support in Visual Studio\", \" 2017 and later gives you the ability to include whatever you want in your application environment, \", \"as shown in Figure 44. Since you're running it in a container, if you add a dependency to your appli\", \"cation, you can include the dependency in your Dockerfile or Docker image.\\n\\nAs also shown in Figure \", \"4-4, the publish flow pushes an image through a container registry. This can be the Azure Container \", \"Registry (a registry close to your deployments in Azure and secured by Azure Active Directory groups\", \" and accounts), or any other Docker registry, like Docker Hub or an onpremises registry.\\n\\n## Manage \", \"state and data in Docker applications\\n\\nIn most cases, you can think of a container as an instance of\", \" a process. A process doesn't maintain persistent state. While a container can write to its local st\", \"orage, assuming that an instance will be around indefinitely would be like assuming that a single lo\", \"cation in memory will be durable. You\\n\\nAzure Container Registry\\n\\nCreate new\\n\\nshould assume that cont\", \"ainer images, like processes, have multiple instances or will eventually be killed. If they're manag\", \"ed with a container orchestrator, you should assume that they might get moved from one node or VM to\", \" another.\\n\\nThe following solutions are used to manage data in Docker applications:\\n\\nFrom the Docker \", \"host, as Docker Volumes:\\n\\n- Volumes are stored in an area of the host filesystem that's managed by D\", \"ocker.\\n- Bind mounts can map to any folder in the host filesystem, so access can't be controlled fro\", \"m Docker process and can pose a security risk as a container could access sensitive OS folders.\\n- tm\", \"pfs mounts are like virtual folders that only exist in the host's memory and are never written to th\", \"e filesystem.\\n\\n## From remote storage:\\n\\n- Azure Storage, which provides geo-distributable storage, p\", \"roviding a good long-term persistence solution for containers.\\n- Remote relational databases like Az\", \"ure SQL Database or NoSQL databases like Azure Cosmos DB, or cache services like Redis.\\n\\n## From the\", \" Docker container:\\n\\n- Overlay File System . This Docker feature implements a copy-on-write task that\", \" stores updated information to the root file system of the container. That information is 'on top' o\", \"f the original image on which the container is based. If the container is deleted from the system, t\", \"hose changes are lost. Therefore, while it's possible to save the state of a container within its lo\", \"cal storage, designing a system around this would conflict with the premise of container design, whi\", \"ch by default is stateless.\\n\\nHowever, using Docker Volumes is now the preferred way to handle local \", \"data in Docker. If you need more information about storage in containers check on Docker storage dri\", \"vers and About storage drivers.\\n\\nThe following provides more detail about these options:\\n\\nVolumes ar\", \"e directories mapped from the host OS to directories in containers. When code in the container has a\", \"ccess to the directory, that access is actually to a directory on the host OS. This directory is not\", \" tied to the lifetime of the container itself, and the directory is managed by Docker and isolated f\", \"rom the core functionality of the host machine. Thus, data volumes are designed to persist data inde\", \"pendently of the life of the container. If you delete a container or an image from the Docker host, \", \"th e data persisted in the data volume isn't deleted.\\n\\nVolumes can be named or anonymous (the defaul\", \"t). Named volumes are the evolution of Data Volume Containers and make it easy to share data between\", \" containers. Volumes also support volume drivers that allow you to store data on remote hosts, among\", \" other options.\\n\\nBind mounts are available since a long time ago and allow the mapping of any folder\", \" to a mount point in a container. Bind mounts have more limitations than volumes and some important \", \"security issues, so volumes are the recommended option.\\n\\nBrowser or \\u00b0\\n\\nClient app\\n\\nData Volume and D\", \"ata Volume Container\\n\\nMicrosoft\\n\\nAzure tmpfs mounts are basically virtual folders that live only in \", \"the host's memory and are never written to the filesystem. They are fast and secure but use memory a\", \"nd are only meant for temporary, nonpersistent data.\\n\\nAs shown in Figure 4-5, regular Docker volumes\", \" can be stored outside of the containers themselves but within the physical boundaries of the host s\", \"erver or VM. However, Docker containers can't access a volume from one host server or VM to another.\", \" In other words, with these volumes, it isn't possible to manage data shared between containers that\", \" run on different Docker hosts, although it could be achieved with a volume driver that supports rem\", \"ote hosts.\\n\\nData Volume Container\\n\\n## Stateless container\\n\\nFigure 4-5. Volumes and external data sou\", \"rces for container-based applications\\n\\n<!-- image -->\\n\\nVolumes can be shared between containers, but\", \" only in the same host, unless you use a remote driver that supports remote hosts. In addition, when\", \" Docker containers are managed by an orchestrator, containers might 'move' between hosts, depending \", \"on the opti mizations performed by the cluster. Therefore, it isn't recommended that you use data vo\", \"lumes for business data. But they're a good mechanism to work with trace files, temporal files, or s\", \"imilar that will not impact business data consistency.\\n\\nRemote data sources and cache tools like Azu\", \"re SQL Database, Azure Cosmos DB, or a remote cache like Redis can be used in containerized applicat\", \"ions the same way they are used when developing without containers. This is a proven way to store bu\", \"siness application data.\\n\\nAzure Storage. Business data usually will need to be placed in external re\", \"sources or databases, like Azure Storage. Azure Storage, in concrete, provides the following service\", \"s in the cloud:\\n\\n- Blob storage stores unstructured object data. A blob can be any type of text or b\", \"inary data, such as document or media files (images, audio, and video files). Blob storage is also r\", \"eferred to as Object storage.\\n\\n- File storage offers shared storage for legacy applications using st\", \"andard SMB protocol. Azure virtual machines and cloud services can share file data across applicatio\", \"n components via mounted shares. On-premises applications can access file data in a share via the Fi\", \"le service REST API.\\n- Table storage stores structured datasets. Table storage is a NoSQL key-attrib\", \"ute data store, which allows rapid development and fast access to large quantities of data.\\n\\nRelatio\", \"nal databases and NoSQL databases. There are many choices for external databases, from relational da\", \"tabases like SQL Server, PostgreSQL, Oracle, or NoSQL databases like Azure Cosmos DB, MongoDB, etc. \", \"These databases are not going to be explained as part of this guide since they are in a completely d\", \"ifferent subject.\\n\\n## Service-oriented architecture\\n\\nService-oriented architecture (SOA) was an over\", \"used term and has meant different things to different people. But as a common denominator, SOA means\", \" that you structure your application by decomposing it into multiple services (most commonly as HTTP\", \" services) that can be classified as different types like subsystems or tiers.\\n\\nThose services can n\", \"ow be deployed as Docker containers, which solves deployment issues, because all the dependencies ar\", \"e included in the container image. However, when you need to scale up SOA applications, you might ha\", \"ve scalability and availability chal lenges if you're deploying based on single Docker hosts. This i\", \"s where Docker clustering software or an orchestrator can help you, as explained in later sections w\", \"here deployment approaches for microservices are described.\\n\\nDocker containers are useful (but not r\", \"equired) for both traditional service-oriented architectures and the more advanced microservices arc\", \"hitectures.\\n\\nMicroservices derive from SOA, but SOA is different from microservices architecture. Fe\", \"atures like large central brokers, central orchestrators at the organization level, and the Enterpri\", \"se Service Bus (ESB) are typical in SOA. But in most cases, these are anti-patterns in the microserv\", \"ice community. In fact, some people argue that 'The microservice architecture is SOA done right.'\\n\\nT\", \"his guide focuses on microservices, because a SOA approach is less prescriptive than the requirement\", \"s and techniques used in a microservice architecture. If you know how to build a microservice-based \", \"application, you also know how to build a simpler service-oriented application.\\n\\n## Microservices ar\", \"chitecture\\n\\nAs the name implies, a microservices architecture is an approach to building a server ap\", \"plication as a set of small services. That means a microservices architecture is mainly oriented to \", \"the back-end, although the approach is also being used for the front end. Each service runs in its o\", \"wn process and communicates with other processes using protocols such as HTTP/HTTPS, WebSockets, or \", \"AMQP. Each microservice implements a specific end-to-end domain or business capability within a cert\", \"ain context boundary, and each must be developed autonomously and be deployable independently. Final\", \"ly, each microservice should own its related domain data model and domain logic (sovereignty\\n\\nMonoli\", \"thic deployment approach\\n\\n\\u2022 A traditional application has most of its functionality within a\\n\\nfew pr\", \"ocesses that are libraries.\\n\\nMicroservices application approach\\n\\n\\u2022 A microservice application segreg\", \"ates functionality into\\n\\nseparate smaller services.\\n\\nand decentralized data management) and could be\", \" based on different data storage technologies (SQL, NoSQL) and different programming languages.\\n\\nWha\", \"t size should a microservice be? When developing a microservice, size shouldn't be the important poi\", \"nt. Instead, the important point should be to create loosely coupled services so you have autonomy o\", \"f development, deployment, and scale, for each service. Of course, when identifying and designing mi\", \"croservices, you should try to make them as small as possible as long as you don't have too many dir\", \"ect dependencies with other microservices. More important than the size of the microservice is the i\", \"nternal cohesion it must have and its independence from other services.\\n\\nWhy a microservices archite\", \"cture? In short, it provides long-term agility. Microservices enable better maintainability in compl\", \"ex, large, and highly-scalable systems by letting you create applications based on many independentl\", \"y deployable services that each have granular and autonomous lifecycles.\\n\\nAs an additional benefit, \", \"microservices can scale out independently. Instead of having a single monolithic application that yo\", \"u must scale out as a unit, you can instead scale out specific microservices. That way, you can scal\", \"e just the functional area that needs more processing power or network bandwidth to support demand, \", \"rather than scaling out other areas of the application that don't need to be scaled. That means cost\", \" savings because you need less hardware.\\n\\nFigure 4-6. Monolithic deployment versus the microservices\", \" approach\\n\\n<!-- image -->\\n\\nAs Figure 4-6 shows, in the traditional monolithic approach, the applicat\", \"ion scales by cloning the whole app in several servers/VM. In the microservices approach, functional\", \"ity is segregated in smaller services, so each service can scale independently. The microservices ap\", \"proach allows agile changes and rapid iteration of each microservice, because you can change specifi\", \"c, small areas of complex, large, and scalable applications.\\n\\nArchitecting fine-grained microservice\", \"s-based applications enables continuous integration and continuous delivery practices. It also accel\", \"erates delivery of new functions into the application. Finegrained composition of applications also \", \"allows you to run and test microservices in isolation, and to\\n\\nApp 1\\n\\nApp 2\\n\\nApp 1\\n\\nevolve them auto\", \"nomously while maintaining clear contracts between them. As long as you don't change the interfaces \", \"or contracts, you can change the internal implementation of any microservice or add new functionalit\", \"y without breaking other microservices.\\n\\nThe following are important aspects to enable success in go\", \"ing into production with a microservicesbased system:\\n\\n- Monitoring and health checks of the service\", \"s and infrastructure.\\n- Scalable infrastructure for the services (that is, cloud and orchestrators).\", \"\\n- Security design and implementation at multiple levels: authentication, authorization, secrets man\", \"agement, secure communication, etc.\\n- Rapid application delivery, usually with different teams focus\", \"ing on different microservices.\\n- DevOps and CI/CD practices and infrastructure.\\n\\nOf these, only the\", \" first three are covered or introduced in this guide. The last two points, which are related to appl\", \"ication lifecycle, are covered in the additional Containerized Docker Application Lifecycle with Mic\", \"rosoft Platform and Tools e-book.\\n\\n## Additional resources\\n\\n- Mark Russinovich. Microservices: An ap\", \"plication revolution powered by the cloud https://azure.microsoft.com/blog/microservices-an-applicat\", \"ion-revolution-powered-by-thecloud/\\n- Martin Fowler. Microservices https://www.martinfowler.com/arti\", \"cles/microservices.html\\n- Martin Fowler. Microservice Prerequisites https://martinfowler.com/bliki/M\", \"icroservicePrerequisites.html\\n- Jimmy Nilsson. Chunk Cloud Computing https://www.infoq.com/articles/\", \"CCC-Jimmy-Nilsson\\n- Cesar de la Torre. Containerized Docker Application Lifecycle with Microsoft Pla\", \"tform and Tools (downloadable e-book) https://aka.ms/dockerlifecycleebook\\n\\n## Data sovereignty per m\", \"icroservice\\n\\nAn important rule for microservices architecture is that each microservice must own its\", \" domain data and logic. Just as a full application owns its logic and data, so must each microservic\", \"e own its logic and data under an autonomous lifecycle, with independent deployment per microservice\", \".\\n\\nThis means that the conceptual model of the domain will differ between subsystems or microservice\", \"s. Consider enterprise applications, where customer relationship management (CRM) applications,\\n\\nDat\", \"a in Traditional approach\\n\\n: Single monolithic database\\n\\nTiers of specific technologies\\n\\nWeb Tier\\n\\nS\", \"ervices Tier\\n\\nCache Tier\\n\\nData Tier\\n\\nData in Microservices approach\\n\\n\\u2022 Graph of interconnected micro\", \"services\\n\\nState typically scoped to the microservice transactional purchase subsystems, and customer\", \" support subsystems each call on unique customer entity attributes and data, and where each employs \", \"a different Bounded Context (BC).\\n\\nMy Web Application 1 =\\n\\nThis principle is similar in Domain-drive\", \"n design (DDD), where each Bounded Context or autonomous subsystem or service must own its domain mo\", \"del (data plus logic and behavior). Each DDD Bounded Context correlates to one business microservice\", \" (one or several services). This point about the Bounded Context pattern is expanded in the next sec\", \"tion. services\\n\\nOn the other hand, the traditional (monolithic data) approach used in many applicati\", \"ons is to have a single centralized database or just a few databases. This is often a normalized SQL\", \" database that's used for the whole application and all its internal subsystems, as shown in Figure \", \"4-7.\\n\\nNo-SQL\\n\\nMonolithic Databases are shared across services.\\n\\nStateful services\\n\\n## , SQL\\n\\nStatele\", \"ss services with\\n\\nseparate store\\n\\n<!-- image -->\\n\\nEach microservice owns its model/data!\\n\\nFigure 4-7\", \". Data sovereignty comparison: monolithic database versus microservices\\n\\n<!-- image -->\\n\\nIn the trad\", \"itional approach, there's a single database shared across all services, typically in a tiered archit\", \"ecture. In the microservices approach, each microservice owns its model/data. The centralized databa\", \"se approach initially looks simpler and seems to enable reuse of entities in different subsystems to\", \" make everything consistent. But the reality is you end up with huge tables that serve many differen\", \"t subsystems, and that include attributes and columns that aren't needed in most cases. It's like tr\", \"y ing to use the same physical map for hiking a short trail, taking a day-long car trip, and learnin\", \"g geography.\\n\\nA monolithic application with typically a single relational database has two important\", \" benefits: ACID transactions and the SQL language, both working across all the tables and data relat\", \"ed to your application. This approach provides a way to easily write a query that combines data from\", \" multiple tables.\\n\\nHowever, data access becomes much more complicated when you move to a microservic\", \"es architecture. Even when using ACID transactions within a microservice or Bounded Context, it is c\", \"rucial to consider that the data owned by each microservice is private to that microservice and shou\", \"ld only\\n\\nbe accessed either synchronously through its API endpoints(REST, gRPC, SOAP, etc) or asynch\", \"ronously via messaging(AMQP or similar).\\n\\nEncapsulating the data ensures that the microservices are \", \"loosely coupled and can evolve independently of one another. If multiple services were accessing the\", \" same data, schema updates would require coordinated updates to all the services. This would break t\", \"he microservice lifecycle autonomy. But distributed data structures mean that you can't make a singl\", \"e ACID transaction across microservices. This in turn means you must use eventual consistency when a\", \" business process spans multiple microservices. This i s much harder to implement than simple SQL jo\", \"ins, because you can't create integrity constraints or use distributed transactions between separate\", \" databases, as we'll explain later on. Similarly, many other relational database features aren't ava\", \"ilable acro ss multiple microservices.\\n\\nGoing even further, different microservices often use differ\", \"ent kinds of databases. Modern applications store and process diverse kinds of data, and a relationa\", \"l database isn't always the best choice. For some use cases, a NoSQL database such as Azure CosmosDB\", \" or MongoDB might have a more convenient data model and offer better performance and scalability tha\", \"n a SQL database like SQL Server or Azure SQL Database. In other cases, a relational database is sti\", \"ll the best approach. Therefore, microservices-based applications often use a mixture of SQL and NoS\", \"QL databases, which is sometimes called the polyglot persistence approach.\\n\\nA partitioned, polyglot-\", \"persistent architecture for data storage has many benefits. These include loosely coupled services a\", \"nd better performance, scalability, costs, and manageability. However, it can introduce some distrib\", \"uted data management challenges, as explained in ' Identifying domain-model boundaries ' later in th\", \"is chapter.\\n\\n## The relationship between microservices and the Bounded Context pattern\\n\\nThe concept \", \"of microservice derives from the Bounded Context (BC) pattern in domain-driven design (DDD). DDD dea\", \"ls with large models by dividing them into multiple BCs and being explicit about their boundaries. E\", \"ach BC must have its own model and database; likewise, each microservice owns its related data. In a\", \"ddition, each BC usually has its own ubiquitous language to help communication between software deve\", \"lopers and domain experts.\\n\\nThose terms (mainly domain entities) in the ubiquitous language can have\", \" different names in different Bounded Contexts, even when different domain entities share the same i\", \"dentity (that is, the unique ID that's used to read the entity from storage). For in stance, in a us\", \"er-profile Bounded Context, the User domain entity might share identity with the Buyer domain entity\", \" in the ordering Bounded Context.\\n\\nA microservice is therefore like a Bounded Context, but it also s\", \"pecifies that it's a distributed service. It's built as a separate process for each Bounded Context,\", \" and it must use the distributed protocols noted earlier, like HTTP/HTTPS, WebSockets, or AMQP. The \", \"Bounded Context pattern, however, doesn't specify whether the Bounded Context is a distributed servi\", \"ce or if it's simply a logical boundary (such as a generic subsystem) within a monolithic-deployment\", \" application.\\n\\nIt's important to highlight that defining a service for each Bounded Context is a goo\", \"d place to start. But you don't have to constrain your design to it. Sometimes you must design a Bou\", \"nded Context or\\n\\nbusiness microservice composed of several physical services. But ultimately, both p\", \"atterns -Bounded Context and microservice- are closely related.\\n\\nDDD benefits from microservices by \", \"getting real boundaries in the form of distributed microservices. But ideas like not sharing the mod\", \"el between microservices are what you also want in a Bounded Context.\\n\\n## Additional resources\\n\\n- Ch\", \"ris Richardson. Pattern: Database per service https://microservices.io/patterns/data/database-per-se\", \"rvice.html\\n- Martin Fowler. BoundedContext https://martinfowler.com/bliki/BoundedContext.html\\n- Mart\", \"in Fowler. PolyglotPersistence https://martinfowler.com/bliki/PolyglotPersistence.html\\n- Alberto Bra\", \"ndolini. Strategic Domain Driven Design with Context Mapping https://www.infoq.com/articles/ddd-cont\", \"extmapping\\n\\n## Logical architecture versus physical architecture\\n\\nIt's useful at this point to stop \", \"and discuss the distinction between logical architecture and physical architecture, and how this app\", \"lies to the design of microservice-based applications.\\n\\nTo begin, building microservices doesn't req\", \"uire the use of any specific technology. For instance, Docker containers aren't mandatory to create \", \"a microservice -based architecture. Those microservices could also be run as plain processes. Micros\", \"ervices is a logical architecture.\\n\\nMoreover, even when a microservice could be physically implement\", \"ed as a single service, process, or container (for simplicity's sake, that's the approach taken in t\", \"he initial version of eShopOnContainers), this parity between business microservice and physical ser\", \"vice or container isn't necessarily required in all cases when you build a large and complex applica\", \"tion composed of many dozens or even hundreds of services.\\n\\nThis is where there's a difference betwe\", \"en an application's logical architecture and physical architecture. The logical architecture and log\", \"ical boundaries of a system do not necessarily map oneto-one to the physical or deployment architect\", \"ure. It can hap pen, but it often doesn't.\\n\\nAlthough you might have identified certain business micr\", \"oservices or Bounded Contexts, it doesn't mean that the best way to implement them is always by crea\", \"ting a single service (such as an ASP.NET Web API) or single Docker container for each business micr\", \"oservice. Having a rule saying each business microservice has to be implemented using a single servi\", \"ce or container is too rigid.\\n\\nTherefore, a business microservice or Bounded Context is a logical ar\", \"chitecture that might coincide (or not) with physical architecture. The important point is that a bu\", \"siness microservice or Bounded Context must be autonomous by allowing code and state to be independe\", \"ntly versioned, deployed, and scaled.\\n\\n\\u2022 -\\n\\n-\\n\\nCatalog business microservice\\n\\nWeb API\\n\\nAs Figure 4-8\", \" shows, the catalog business microservice could be composed of several services or processes. These \", \"could be multiple ASP.NET Web API services or any other kind of services using HTTP or any other pro\", \"tocol. More importantly, the services could share the same data, as long as these services are cohes\", \"ive with respect to the same business domain.\\n\\nSearch\\n\\nService\\n\\nFigure 4-8. Business microservice wi\", \"th several physical services\\n\\n<!-- image -->\\n\\nThe services in the example share the same data model \", \"because the Web API service targets the same data as the Search service. So, in the physical impleme\", \"ntation of the business microservice, you're splitting that functionality so you can scale each of t\", \"hose internal services up or down as needed. Maybe the Web API service usually needs more instances \", \"than the Search service, or vice versa.\\n\\nIn short, the logical architecture of microservices doesn't\", \" always have to coincide with the physical deployment architecture. In this guide, whenever we menti\", \"on a microservice, we mean a business or logical microservice that could map to one or more (physica\", \"l) services. In most cases, this will be a single service, but it might be more.\\n\\n## Challenges and \", \"solutions for distributed data management\\n\\n## Challenge #1: How to define the boundaries of each mic\", \"roservice\\n\\nDefining microservice boundaries is probably the first challenge anyone encounters. Each \", \"microservice has to be a piece of your application and each microservice should be autonomous with a\", \"ll the benefits and challenges that it conveys. But how do you identify those boundaries?\\n\\nFirst, yo\", \"u need to focus on the application's logical domain models and related data. Try to identify decoupl\", \"ed islands of data and different contexts within the same application. Each context could have a dif\", \"ferent business language (different business terms). The contexts should be defined and managed inde\", \"pendently. The terms and entities that are used in those different contexts might sound similar, but\", \" you might discover that in a particular context, a business concept with one is used for a differen\", \"t\\n\\npurpose in another context, and might even have a different name. For instance, a user can be ref\", \"erred as a user in the identity or membership context, as a customer in a CRM context, as a buyer in\", \" an ordering context, and so forth.\\n\\nThe way you identify boundaries between multiple application co\", \"ntexts with a different domain for each context is exactly how you can identify the boundaries for e\", \"ach business microservice and its related domain model and data. You always attempt to minimize the \", \"coupling between those microservices. This guide goes into more detail about this identification and\", \" domain model design in the section Identifying domain-model boundaries for each microservice later.\", \"\\n\\n## Challenge #2: How to create queries that retrieve data from several microservices\\n\\nA second cha\", \"llenge is how to implement queries that retrieve data from several microservices, while avoiding cha\", \"tty communication to the microservices from remote client apps. An example could be a single screen \", \"from a mobile app that needs to show user information that's owned by the basket, catalog, and user \", \"identity microservices. Another example would be a complex report involving many tables located in m\", \"ultiple microservices. The right solution depends on the complexity of the queries. But in any case,\", \" you'll need a way to aggregate information if you want to improve the efficiency in the communicati\", \"ons of your system. The most popular solutions are the following.\\n\\nAPI Gateway. For simple data aggr\", \"egation from multiple microservices that own different databases, the recommended approach is an agg\", \"regation microservice referred to as an API Gateway. However, you need to be careful about implement\", \"ing this pattern, because it can be a choke point in your system, and it can violate the principle o\", \"f microservice autonomy. To mitigate this possibility, you can have multiple finedgrained API Gatewa\", \"ys each one focusing on a vertical 'slice' or business area of the system. The API Gateway pattern i\", \"s explained in more detail in the API Gateway section later.\\n\\nGraphQL Federation One option to consi\", \"der if your microservices are already using GraphQL is GraphQL Federation . Federation allows you to\", \" define 'subgraphs' from other services and compose them into an aggregate 'supergraph' that acts as\", \" a standalone schema.\\n\\nCQRS with query/reads tables. Another solution for aggregating data from mult\", \"iple microservices is the Materialized View pattern. In this approach, you generate, in advance (pre\", \"pare denormalized data before the actual queries happen), a readonly table with the data that's owne\", \"d by multiple microservices. The table has a format suited to the client app's needs.\\n\\nConsider some\", \"thing like the screen for a mobile app. If you have a single database, you might pull together the d\", \"ata for that screen using a SQL query that performs a complex join involving multiple tables. Howeve\", \"r, when you have multiple databases, and each database is owned by a different microservice, you can\", \"not query those databases and create a SQL join. Your complex query becomes a challenge. You can add\", \"ress the requirement using a CQRS approach -you create a denormalized table in a different database \", \"that's used just for queries. The table can be designed specifically for the data you need for the c\", \"omplex query, with a one-to-one relationship between fields needed by your application's screen and \", \"the columns in the query table. It could also serve for reporting purposes.\\n\\nThis approach not only \", \"solves the original problem (how to query and join across microservices), but it also improves perfo\", \"rmance considerably when compared with a complex join, because you already\\n\\nhave the data that the a\", \"pplication needs in the query table. Of course, using Command and Query Responsibility Segregation (\", \"CQRS) with query/reads tables means additional development work, and you'll need to embrace eventual\", \" consistency. Nonetheless, requi rements on performance and high scalability in collaborative scenar\", \"ios (or competitive scenarios, depending on the point of view) are where you should apply CQRS with \", \"multiple databases.\\n\\n'Cold data' in central databases. For complex reports and queries that might no\", \"t require real-time data, a common approach is to export your 'hot data' (transactional data from th\", \"e microservices) as 'cold data' into large databases that are used only for reporting. That central \", \"database s ystem can be a Big Data-based system, like Hadoop; a data warehouse like one based on Azu\", \"re SQL Data Warehouse; or even a single SQL database that's used just for reports (if size won't be \", \"an issue).\\n\\nKeep in mind that this centralized database would be used only for queries and reports t\", \"hat do not need real-time data. The original updates and transactions, as your source of truth, have\", \" to be in your microservices data. The way you would synchronize data would be either by using event\", \"-driven communication (covered in the next sections) or by using other database infrastructure impor\", \"t/export tools. If you use event-driven communication, that integration process would be similar to \", \"the way you propagate data as described earlier for CQRS query tables.\\n\\nHowever, if your application\", \" design involves constantly aggregating information from multiple microservices for complex queries,\", \" it might be a symptom of a bad design -a microservice should be as isolated as possible from other \", \"microservices. (This excludes reports/analytics that always should use cold-data central databases.)\", \" Having this problem often might be a reason to merge microservices. You need to balance the autonom\", \"y of evolution and deployment of each microservice with strong dependencies, cohesion, and data aggr\", \"egation.\\n\\n## Challenge #3: How to achieve consistency across multiple microservices\\n\\nAs stated previ\", \"ously, the data owned by each microservice is private to that microservice and can only be accessed \", \"using its microservice API. Therefore, a challenge presented is how to implement end-toend business \", \"processes while keeping consistency across multiple microservices.\\n\\nTo analyze this problem, let's l\", \"ook at an example from the eShopOnContainers reference application. The Catalog microservice maintai\", \"ns information about all the products, including the product price. The Basket microservice manages \", \"temporal data about product items that users are adding to their shopping baskets, which includes th\", \"e price of the items at the time they were added to the basket. When a product's price is updated in\", \" the catalog, that price should also be updated in the active baskets that hold that same product, p\", \"lus the system should probably warn the user saying that a particular item's p rice has changed sinc\", \"e they added it to their basket.\\n\\nIn a hypothetical monolithic version of this application, when the\", \" price changes in the products table, the catalog subsystem could simply use an ACID transaction to \", \"update the current price in the Basket table.\\n\\nHowever, in a microservices-based application, the Pr\", \"oduct and Basket tables are owned by their respective microservices. No microservice should ever inc\", \"lude tables/storage owned by another microservice in its own transactions, not even in direct querie\", \"s, as shown in Figure 4-9.\\n\\nCatalog microservice\\n\\nCatalog.APl\\n\\nID\\n\\nProdPrice in Catalog DB\\n\\nEventual\", \" consistency\\n\\nBasket microservice\\n\\nBasket.API\\n\\nFigure 4-9 . A microservice can't directly access a t\", \"able in another microservice\\n\\n<!-- image -->\\n\\nThe Catalog microservice shouldn't update the Basket t\", \"able directly, because the Basket table is owned by the Basket microservice. To make an update to th\", \"e Basket microservice, the Catalog microservice should use eventual consistency probably based on as\", \"ynchronous communication such as integration events (message and event-based communication). This is\", \" how the eShopOnContainers reference application performs this type of consistency across microservi\", \"ces.\\n\\nAs stated by the CAP theorem, you need to choose between availability and ACID strong consiste\", \"ncy. Most microservice-based scenarios demand availability and high scalability as opposed to strong\", \" consistency. Mission-critical applications must remain up and running, and developers can work arou\", \"nd strong consistency by using techniques for working with weak or eventual consistency. This is the\", \" approach taken by most microservice-based architectures.\\n\\nMoreover, ACID-style or two-phase commit \", \"transactions are not just against microservices principles; most NoSQL databases (like Azure Cosmos \", \"DB, MongoDB, etc.) do not support two-phase commit transactions, typical in distributed databases sc\", \"enarios. However, maintaining data consistency across services and databases is essential. This chal\", \"lenge is also related to the question of how to propagate changes across multiple microservices when\", \" certain data needs to be redundant -for example, when you need to have the product's name or descri\", \"ption in the Catalog microservice and the Basket microservice.\\n\\nA good solution for this problem is \", \"to use eventual consistency between microservices articulated through event-driven communication and\", \" a publish-and-subscribe system. These topics are covered in the section Asynchronous event-driven c\", \"ommunication later in this guide.\\n\\n## Challenge #4: How to design communication across microservice \", \"boundaries\\n\\nCommunicating across microservice boundaries is a real challenge. In this context, commu\", \"nication doesn't refer to what protocol you should use (HTTP and REST, AMQP, messaging, and so on). \", \"Instead, it addresses what communication style you should use, and especially how coupled your micro\", \"services should be. Depending on the level of coupling, when failure occurs, the impact of that fail\", \"ure on your system will vary significantly.\\n\\nIn a distributed system like a microservices-based appl\", \"ication, with so many artifacts moving around and with distributed services across many servers or h\", \"osts, components will eventually fail. Partial failure and even larger outages will occur, so you ne\", \"ed to design your microservices and the communication across them considering the common risks in th\", \"is type of distributed system.\\n\\nA popular approach is to implement HTTP (REST)-based microservices, \", \"due to their simplicity. An HTTP-based approach is perfectly acceptable; the issue here is related t\", \"o how you use it. If you use HTTP requests and responses just to interact with your microservices fr\", \"om client applications or from API Gateways, that's fine. But if you create long chains of synchrono\", \"us HTTP calls across microservices, communicating across their boundaries as if the microservices we\", \"re objects in a monolithic application, your application will eventually run into problems.\\n\\nFor ins\", \"tance, imagine that your client application makes an HTTP API call to an individual microservice lik\", \"e the Ordering microservice. If the Ordering microservice in turn calls additional microservices usi\", \"ng HTTP within the same request/response cycle, y ou're creating a chain of HTTP calls. It might sou\", \"nd reasonable initially. However, there are important points to consider when going down this path:\\n\", \"\\n- Blocking and low performance. Due to the synchronous nature of HTTP, the original request doesn't\", \" get a response until all the internal HTTP calls are finished. Imagine if the number of these calls\", \" increases significantly and at the same time one of the intermediate HTTP calls to a microservice i\", \"s blocked. The result is that performance is impacted, and the overall scalability will be exponenti\", \"ally affected as additional HTTP requests increase.\\n- Coupling microservices with HTTP. Business mic\", \"roservices shouldn't be coupled with other business microservices. Ideally, they shouldn't 'know' ab\", \"out the existence of other microservices. If your application relies on coupling microservices as in\", \" the example, achieving autonomy per microservice will be almost impossible.\\n- Failure in any one mi\", \"croservice. If you implemented a chain of microservices linked by HTTP calls, when any of the micros\", \"ervices fails (and eventually they will fail) the whole chain of microservices will fail. A microser\", \"vice-based system should be designed to continue to work as well as possible during partial failures\", \". Even if you implement client logic that uses retries with exponential backoff or circuit breaker m\", \"echanisms, the more complex the HTTP call chains are, the more complex it is to implement a failure \", \"strategy based on HTTP.\\n\\nIn fact, if your internal microservices are communicating by creating chain\", \"s of HTTP requests as described, it could be argued that you have a monolithic application, but one \", \"based on HTTP between processes instead of intra-process communication mechanisms.\\n\\nTherefore, in or\", \"der to enforce microservice autonomy and have better resiliency, you should minimize the use of chai\", \"ns of request/response communication across microservices. It's recommended that you use only asynch\", \"ronous interaction for inter-microservice communication, either by using asynchronous message- and e\", \"vent-based communication, or by using (asynchronous) HTTP polling independently of the original HTTP\", \" request/response cycle.\\n\\nThe use of asynchronous communication is explained with additional details\", \" later in this guide in the sections Asynchronous microservice integration enforces microservice's a\", \"utonomy and Asynchronous message-based communication.\\n\\n## Additional resources\\n\\n- CAP theorem https:\", \"//en.wikipedia.org/wiki/CAP\\\\_theorem\\n- Eventual consistency https://en.wikipedia.org/wiki/Eventual\\\\_\", \"consistency\\n- Data Consistency Primer https://learn.microsoft.com/previous-versions/msp-n-p/dn589800\", \"(v=pandp.10)\\n- Martin Fowler. CQRS (Command and Query Responsibility Segregation) https://martinfowl\", \"er.com/bliki/CQRS.html\\n- Materialized View https://learn.microsoft.com/azure/architecture/patterns/m\", \"aterialized-view\\n- Charles Row. ACID vs. BASE: The Shifting pH of Database Transaction Processing ht\", \"tps://www.dataversity.net/acid-vs-base-the-shifting-ph-of-database-transactionprocessing/\\n- Compensa\", \"ting Transaction https://learn.microsoft.com/azure/architecture/patterns/compensating-transaction\\n- \", \"Udi Dahan. Service Oriented Composition https://udidahan.com/2014/07/30/service-oriented-composition\", \"-with-video/\\n\\n## Identify domain-model boundaries for each microservice\\n\\nThe goal when identifying m\", \"odel boundaries and size for each microservice isn't to get to the most granular separation possible\", \", although you should tend toward small microservices if possible. Instead, your goal should be to g\", \"et to the most meaningful separation guided by your domain knowledge. The emphasis isn't on the size\", \", but instead on business capabilities. In addition, if there's clear cohesion needed for a certain \", \"area of the application based on a high number of dependencies, that indicates the need for a single\", \" microservice, too. Cohesion is a way to identify how to break apart\\n\\nor group together microservice\", \"s. Ultimately, while you gain more knowledge about the domain, you should adapt the size of your mic\", \"roservice, iteratively. Finding the right size isn't a one -shot process.\\n\\nSam Newman, a recognized \", \"promoter of microservices and author of the book Building Microservices, highlights that you should \", \"design your microservices based on the Bounded Context (BC) pattern (part of domain-driven design), \", \"as introduced earlier. Sometimes, a BC could be composed of several physical services, but not vice \", \"versa.\\n\\nA domain model with specific domain entities applies within a concrete BC or microservice. A\", \" BC delimits the applicability of a domain model and gives developer team members a clear and shared\", \" understanding of what must be cohesive and what can be developed independently. These are the same \", \"goals for microservices.\\n\\nAnother tool that informs your design choice is Conway's law , which state\", \"s that an application will reflect the social boundaries of the organization that produced it. But s\", \"ometimes the opposite is true the company's organization is formed by the software. You might need t\", \"o reverse Conway's law and build the boundaries the way you want the company to be organized, leanin\", \"g toward business process consulting.\\n\\nTo identify bounded contexts, you can use a DDD pattern calle\", \"d the Context Mapping pattern. With Context Mapping, you identify the various contexts in the applic\", \"ation and their boundaries. It's common to have a different context and boundary for each small subs\", \"ystem, for instance. The Context Map is a way to define and make explicit those boundaries between d\", \"omains. A BC is autonomous and includes the details of a single domain -details like the domain enti\", \"ties- and defines integration contracts with other BCs. This is similar to the definition of a micro\", \"service: it's autonomous, it implements certain domain capability, and it must provide interfaces. T\", \"his is why Context Mapping and the Bounded Context pattern are good approaches for identifying the d\", \"omain model boundaries of your microservices.\\n\\nWhen designing a large application, you'll see how it\", \"s domain model can be fragmented - a domain expert from the catalog domain will name entities differ\", \"ently in the catalog and inventory domains than a shipping domain expert, for instance. Or the user \", \"domain entity might be different in size and number of attributes when dealing with a CRM expert who\", \" wants to store every detail about the customer than for an ordering domain expert who just needs pa\", \"rtial data about the customer. It's very hard to disambiguate all domain terms across all the domain\", \"s related to a large application. But the most important thing is that you shouldn't try to unify th\", \"e terms. Instead, accept the differences and richness provided by each domain. If you try to have a \", \"unified database for the whole application, attempts at a unified vocabulary will be awkward and won\", \"'t sound right to any of the multiple domain experts. Therefore, BCs (implemented as microservices) \", \"will help you to clarify where you can use certain domain terms and whe re you'll need to split the \", \"system and create additional BCs with different domains.\\n\\nYou'll know that you got the right boundar\", \"ies and sizes of each BC and domain model if you have few strong relationships between domain models\", \", and you do not usually need to merge information from multiple domain models when performing typic\", \"al application operations.\\n\\nPerhaps the best answer to the question of how large a domain model for \", \"each microservice should be is the following: it should have an autonomous BC, as isolated as possib\", \"le, that enables you to work without having to constantly switch to other contexts ( other microserv\", \"ice's models). In Figure 4 -\\n\\nIdentifying a Domain Model per Microservice or Bounded Context\\n\\nConfer\", \"ences Management\\n\\nOrders and Registration\\n\\n10, you can see how multiple microservices (multiple BCs)\", \" each has their own model and how their entities can be defined, depending on the specific requireme\", \"nts for each of the identified domains in your application.\\n\\nCompanies\\n\\nUsers\\n\\nPricing and Marketing\", \"\\n\\nConferences\\n\\nPromotions\\n\\nSeats\\n\\nOrders\\n\\n## Attendees Seat\\n\\nassignments\\n\\nFigure 4-10. Identifying e\", \"ntities and microservice model boundaries\\n\\n<!-- image -->\\n\\nFigure 4-10 illustrates a sample scenario\", \" related to an online conference management system. The same entity appears as 'Users', 'Buyers', 'P\", \"ayers', and 'Customers' depending on the bounded context. You've identified several BCs that could b\", \"e implemented a s microservices, based on domains that domain experts defined for you. As you can se\", \"e, there are entities that are present just in a single microservice model, like Payments in the Pay\", \"ment microservice. Those will be easy to implement.\\n\\nHowever, you might also have entities that have\", \" a different shape but share the same identity across the multiple domain models from the multiple m\", \"icroservices. For example, the User entity is identified in the Conferences Management microservice.\", \" That same user, with the same identity, is the one named Buyers in the Ordering microservice, or th\", \"e one named Payer in the Payment microservice, and even the one named Customer in the Customer Servi\", \"ce microservice. This is because, depending on the ubiquitous language that each domain expert is us\", \"ing, a user might have a different perspective even with different attributes. The user entity in th\", \"e microservice model named Conferences Management might have most of its personal data attributes. H\", \"owever, that same user in the shape of Payer in the microservice Payment or in the shape of Customer\", \" in the microservice Customer Service might not need the same list of attributes.\\n\\nA similar approac\", \"h is illustrated in Figure 4-11.\\n\\nReservations\\n\\nDecomposing a traditional data model into multiple d\", \"omain models\\n\\n(One domain model per microservice or Bounded-Context)\\n\\npublic class User\\n\\nConferences\", \"\\n\\nManagement\\n\\n\\u2192 User\\n\\nStatus FirstName LastName\\n\\n## FirstName LastName ID\\n\\n<!-- image -->\\n\\nTradition\", \"al\\n\\nEntities with \\\"All\\n\\npossible\\\"\\n\\nattributes\\n\\nFigure 4-11. Decomposing traditional data models into\", \" multiple domain models\\n\\nWhen decomposing a traditional data model between bounded contexts, you can\", \" have different entities that share the same identity (a buyer is also a user) with different attrib\", \"utes in each bounded context. You can see how the user is present in the Conferences Management micr\", \"oservice model as the User entity and is also present in the form of the Buyer entity in the Pricing\", \" microservice, with alternate attributes or details about the user when it's actually a buyer. Each \", \"microservice or BC might not need all the data related to a User entity, just part of it, depending \", \"on the problem to solve or the context. For instance, in the Pricing microservice model, you do not \", \"need the address or the name of the user, just the ID (as identity) and Status, which will have an i\", \"mpact on discounts when pricing the seats per buyer.\\n\\nThe Seat entity has the same name but differen\", \"t attributes in each domain model. However, Seat shares identity based on the same ID, as happens wi\", \"th User and Buyer.\\n\\nBasically, there's a shared concept of a user that exists in multiple services (\", \"domains), which all share the identity of that user. But in each domain model there might be additio\", \"nal or different details about the user entity. Therefore, there needs to be a way to map a user ent\", \"ity from one domain (microservice) to another.\\n\\nThere are several benefits to not sharing the same u\", \"ser entity with the same number of attributes across domains. One benefit is to reduce duplication, \", \"so that microservice models do not have any data that they do not need. Another benefit is having a \", \"primary microservice that owns a certain type of data per entity so that updates and queries for tha\", \"t type of data are driven only by that microservice.\\n\\nDirect Client-To-Microservice communication\\n\\nA\", \"rchitecture\\n\\nMicroservices\\n\\n## The API gateway pattern versus the Direct client-tomicroservice commu\", \"nication Microservice\\n\\nIn a microservices architecture, each microservice exposes a set of (typicall\", \"y) fine-grained endpoints. This fact can impact the client-to-microservice communication, as explain\", \"ed in this section.\\n\\n## Direct client-to-microservice communication\\n\\nA possible approach is to use a\", \" direct client-to-microservice communication architecture. In this approach, a client app can make r\", \"equests directly to some of the microservices, as shown in Figure 412.\\n\\nFigure 4-12. Using a direct \", \"client-to-microservice communication architecture\\n\\n<!-- image -->\\n\\nIn this approach, each microservi\", \"ce has a public endpoint, sometimes with a different TCP port for each microservice. An example of a\", \" URL for a particular service could be the following URL in Azure:\\n\\nhttp://eshoponcontainers.westus.\", \"cloudapp.azure.com:88/\\n\\nIn a production environment based on a cluster, that URL would map to the lo\", \"ad balancer used in the cluster, which in turn distributes the requests across the microservices. In\", \" production environments, you could have an Application Delivery Controller (ADC) like Azure Applica\", \"tion Gateway between your microservices and the Internet. This layer acts as a transparent tier that\", \" not only performs load balancing, but secures your services by offering SSL termination. This appro\", \"ach improves the load of your hosts by offloading CPU-intensive SSL termination and other routing du\", \"ties to the Azure Application Gateway. In any case, a load balancer and ADC are transparent from a l\", \"ogical application architecture point of view.\\n\\nA direct client-to-microservice communication archit\", \"ecture could be good enough for a small microservice-based application, especially if the client app\", \" is a server-side web application like an ASP.NET MVC app. However, when you build large and complex\", \" microservice-based applications (for example, when handling dozens of microservice types), and espe\", \"cially when the client apps are remote mobile apps or SPA web applications, that approach faces a fe\", \"w issues.\\n\\nClient Apps\\n\\nMobile\\n\\nApp\\n\\nWeb\\n\\nApp\\n\\nConsider the following questions when developing a la\", \"rge application based on microservices:\\n\\n- How can client apps minimize the number of requests to th\", \"e back end and reduce chatty communication to multiple microservices?\\n\\nInteracting with multiple mic\", \"roservices to build a single UI screen increases the number of round trips across the Internet. This\", \" approach increases latency and complexity on the UI side. Ideally, responses should be efficiently \", \"aggregated in the server side. This approach reduces latency, since multiple pieces of data come bac\", \"k in parallel and some UI can show data as soon as it's ready.\\n\\n- How can you handle cross-cutting c\", \"oncerns such as authorization, data transformations, and dynamic request dispatching?\\n\\nImplementing \", \"security and cross-cutting concerns like security and authorization on every microservice can requir\", \"e significant development effort. A possible approach is to have those services within the Docker ho\", \"st or internal cluster to restrict direct access to them from the outside, and to implement those cr\", \"oss-cutting concerns in a centralized place, like an API Gateway.\\n\\n- How can client apps communicate\", \" with services that use non-Internet-friendly protocols?\\n\\nProtocols used on the server side (like AM\", \"QP or binary protocols) are not supported in client apps. Therefore, requests must be performed thro\", \"ugh protocols like HTTP/HTTPS and translated to the other protocols afterwards. A man-in-the-middle \", \"approach can help in this situation.\\n\\n- How can you shape a facade especially made for mobile apps?\\n\", \"\\nThe API of multiple microservices might not be well designed for the needs of different client appl\", \"ications. For instance, the needs of a mobile app might be different than the needs of a web app. Fo\", \"r mobile apps, you might need to optimize even further so that data responses can be more efficient.\", \" You might do this functionality by aggregating data from multiple microservices and returning a sin\", \"gle set of data, and sometimes eliminating any data in the response that isn't needed by the mobile \", \"app. And, of course, you might compress that data. Again, a facade or API in between the mobile app \", \"and the microservices can be convenient for this scenario.\\n\\n## Why consider API Gateways instead of \", \"direct client-to-microservice communication\\n\\nIn a microservices architecture, the client apps usuall\", \"y need to consume functionality from more than one microservice. If that consumption is performed di\", \"rectly, the client needs to handle multiple calls to microservice endpoints. What happens when the a\", \"pplication evolves and new microservices are introduced or existing microservices are updated? If yo\", \"ur application has many microservices, handling so many endpoints from the client apps can be a nigh\", \"tmare. Since the client app would be coupled to those internal endpoints, evolving the microservices\", \" in the future can cause high impact for the client apps.\\n\\nTherefore, having an intermediate level o\", \"r tier of indirection (Gateway) can be convenient for microservicebased applications. If you don't h\", \"ave API Gateways, the client apps must send requests directly to the microservices and that raises p\", \"roblems, such as the following issues:\\n\\n- Coupling : Without the API Gateway pattern, the client app\", \"s are coupled to the internal microservices. The client apps need to know how the multiple areas of \", \"the application are decomposed in microservices. When evolving and refactoring the internal microser\", \"vices, those actions impact maintenance because they cause breaking changes to the client apps due t\", \"o the direct reference to the internal microservices from the client apps. Client apps need to be up\", \"dated frequently, making the solution harder to evolve.\\n- Too many round trips : A single page/scree\", \"n in the client app might require several calls to multiple services. That approach can result in mu\", \"ltiple network round trips between the client and the server, adding significant latency. Aggregatio\", \"n handled in an intermediate level could improve the performance and user experience for the client \", \"app.\\n- Security issues : Without a gateway, all the microservices must be exposed to the 'external w\", \"orld', making the attack surface larger than if you hide internal microservices that aren't directly\", \" used by the client apps. The smaller the attack surface is, the more secure your application can be\", \".\\n- Cross-cutting concerns : Each publicly published microservice must handle concerns such as autho\", \"rization and SSL. In many situations, those concerns could be handled in a single tier so the intern\", \"al microservices are simplified.\\n\\n## What is the API Gateway pattern?\\n\\nWhen you design and build lar\", \"ge or complex microservice-based applications with multiple client apps, a good approach to consider\", \" can be an API Gateway. This pattern is a service that provides a singleentry point for certain grou\", \"ps of microservices. It's similar to the Facade pattern from objectoriented design, but in this case\", \", it's part of a distributed system. The API Gateway pattern is also sometimes known as the 'backend\", \" for frontend' ( BFF) because you build it while thinking about the needs of the client app.\\n\\nTheref\", \"ore, the API gateway sits between the client apps and the microservices. It acts as a reverse proxy,\", \" routing requests from clients to services. It can also provide other cross-cutting features such as\", \" authentication, SSL termination, and cache.\\n\\nFigure 4-13 shows how a custom API Gateway can fit int\", \"o a simplified microservice-based architecture with just a few microservices.\\n\\nUsing a single custom\", \" API Gateway service\\n\\nClient mobile app\\n\\nJSON\\n\\nClient SPA Web app\\n\\nJavaScript/Angularjs\\n\\nTraditional\", \" Web app\\n\\nBrowser +\\n\\nHTML\\n\\n## Microservice 1 Web API\\n\\nontaine\\n\\nFigure 4-13. Using an API Gateway imp\", \"lemented as a custom service\\n\\n<!-- image -->\\n\\nApps connect to a single endpoint, the API Gateway, th\", \"at's configured to forward requests to individual microservices. In this example, the API Gateway wo\", \"uld be implemented as a custom ASP.NET Core WebHost service running as a container.\\n\\nIt's important \", \"to highlight that in that diagram, you would be using a single custom API Gateway service facing mul\", \"tiple and different client apps. That fact can be an important risk because your API Gateway service\", \" will be growing and evolving based on many different requirements from the client apps. Eventually,\", \" it will be bloated because of those different needs and effectively it could be similar to a monoli\", \"thic application or monolithic service. That's why it's very much recommended to split the API Gatew\", \"ay in multiple services or multiple smaller API Gateways, one per client app form-factor type, for i\", \"nstance.\\n\\nYou need to be careful when implementing the API Gateway pattern. Usually it isn't a good \", \"idea to have a single API Gateway aggregating all the internal microservices of your application. If\", \" it does, it acts as a monolithic aggregator or orchestrator and violates microservice autonomy by c\", \"oupling all the microservices.\\n\\nTherefore, the API Gateways should be segregated based on business b\", \"oundaries and the client apps and not act as a single aggregator for all the internal microservices.\", \"\\n\\nWhen splitting the API Gateway tier into multiple API Gateways, if your application has multiple c\", \"lient apps, that can be a primary pivot when identifying the multiple API Gateways types, so that yo\", \"u can have a different facade for the needs of each client app. This case is a pattern named 'Backen\", \"d for Frontend' ( BFF) where each API Gateway can provide a different API tailored for each client a\", \"pp type, possibly even based on the client form factor by implementing specific adapter code which u\", \"nderneath calls multiple internal microservices, as shown in the following image:\\n\\n--\\n\\nBack end\\n\\n-\\n\\n\", \"Client mobile app\\n\\nJSON\\n\\nClient SPA Web app\\n\\nJavaScript/Angular.js\\n\\nTraditional Web app\\n\\nBrowser\\n\\nHT\", \"ML\\n\\n+\\n\\ncontainer\\n\\nFigure 4-13.1. Using multiple custom API Gateways\\n\\n<!-- image -->\\n\\nFigure 4-13.1 s\", \"hows API Gateways that are segregated by client type; one for mobile clients and one for web clients\", \". A traditional web app connects to an MVC microservice that uses the web API Gateway. The example d\", \"epicts a simplified architecture with multiple fine-grained API Gateways. In this case, the boundari\", \"es identified for each API Gateway are based purely on the 'Backend for Frontend' ( BFF) pattern, he\", \"nce based just on the API needed per client app. But in larger applications you should also go furth\", \"er and create other API Gateways based on business boundaries as a second design pivot.\\n\\n## Main fea\", \"tures in the API Gateway pattern\\n\\nAn API Gateway can offer multiple features. Depending on the produ\", \"ct it might offer richer or simpler features, however, the most important and foundational features \", \"for any API Gateway are the following design patterns:\\n\\nReverse proxy or gateway routing. The API Ga\", \"teway offers a reverse proxy to redirect or route requests (layer 7 routing, usually HTTP requests) \", \"to the endpoints of the internal microservices. The gateway provides a single endpoint or URL for th\", \"e client apps and then internally maps the requests to a group of internal microservices. This routi\", \"ng feature helps to decouple the client apps from the microservices but it's also convenient when mo\", \"dernizing a monolithic API by sitting the API Gateway in between the monolithic API and the client a\", \"pps, then you can add new APIs as new microservices while still using the legacy monolithic API unti\", \"l it's split into many microservices in the future. Because of the API Gateway, the client apps won'\", \"t notice if the APIs bei ng used are implemented as internal microservices or a monolithic API and m\", \"ore importantly, when evolving and refactoring the monolithic API into microservices, thanks to the \", \"API Gateway routing, client apps won't be impacted with any URI change.\\n\\nUsing multiple API Gateways\", \" / BFF\\n\\n- \\u2014\\n\\nBack end\\n\\n## Microservice 1 Web AP API Gateway - Mobile\\n\\n| ASPNET Core\\n\\nWebHost\\n\\nFor mo\", \"re information, see Gateway routing pattern.\\n\\nRequests aggregation. As part of the gateway pattern y\", \"ou can aggregate multiple client requests (usually HTTP requests) targeting multiple internal micros\", \"ervices into a single client request. This pattern is especially convenient when a client page/scree\", \"n needs information from several microservices. With this approach, the client app sends a single re\", \"quest to the API Gateway that dispatches several requests to the internal microservices and then agg\", \"regates the results and sends everything back to the client app. The main benefit and goal of this d\", \"esign pattern is to reduce chattiness between the client apps and the backend API, which is especial\", \"ly important for remote apps out of the datacenter where the microservices live, like mobile apps or\", \" requests coming from SPA apps that come from JavaScript in client remote browsers. For regular web \", \"apps performing the requests in the server environment (like an ASP.NET Core MVC web app), this patt\", \"ern is not so important as the latency is very much smaller than for remote client apps.\\n\\nDepending \", \"on the API Gateway product you use, it might be able to perform this aggregation. However, in many c\", \"ases it's more flexible to create aggregation microservices under the scope of the API Gateway, so y\", \"ou define the aggregation in code (that is, C# code):\\n\\nFor more information, see Gateway aggregation\", \" pattern.\\n\\nCross-cutting concerns or gateway offloading. Depending on the features offered by each A\", \"PI Gateway product, you can offload functionality from individual microservices to the gateway, whic\", \"h simplifies the implementation of each microservice by consolidating cross-cutting concerns into on\", \"e tier. This approach is especially convenient for specialized features that can be complex to imple\", \"ment properly in every internal microservice, such as the following functionality:\\n\\n- Authentication\", \" and authorization\\n- Service discovery integration\\n- Response caching\\n- Retry policies, circuit brea\", \"ker, and QoS\\n- Rate limiting and throttling\\n- Load balancing\\n- Logging, tracing, correlation\\n- Heade\", \"rs, query strings, and claims transformation\\n- IP allowlisting\\n\\nFor more information, see Gateway of\", \"floading pattern.\\n\\n## Using products with API Gateway features\\n\\nThere can be many more cross-cutting\", \" concerns offered by the API Gateways products depending on each implementation. We'll explore here:\", \"\\n\\n- Azure API Management\\n- Ocelot\\n\\nAP! Gateway with Azure API Management\\n\\nArchitecture\\n\\n------\\n\\n## A\", \"zure API Management\\n\\nAzure API Management\\n\\nAzure API Management (as shown in Figure 4-14) not only s\", \"olves your API Gateway needs but provides features like gathering insights from your APIs. If you're\", \" using an API management solution, an API Gateway is only a component within that full API managemen\", \"t solution.\\n\\nDeveloper container\\n\\n## portal Microservice 2\\n\\nWeb AP\\n\\ncontainer\\n\\n<!-- image -->\\n\\nClien\", \"t SPA Web app\\n\\nJavaScript/Angularjs\\n\\nTraditional Web app\\n\\nBrowser\\n\\nHTML\\n\\nFigure 4-14. Using Azure AP\", \"I Management for your API Gateway\\n\\nAzure API Management solves both your API Gateway and Management \", \"needs like logging, security, metering, etc. In this case, when using a product like Azure API Manag\", \"ement, the fact that you might have a single API Gateway is not so risky because these kind s of API\", \" Gateways are 'thinner', meaning that you don't implement custom C# code that could evolve towards a\", \" monolithic component.\\n\\nThe API Gateway products usually act like a reverse proxy for ingress commun\", \"ication, where you can also filter the APIs from the internal microservices plus apply authorization\", \" to the published APIs in this single tier.\\n\\nThe insights available from an API Management system he\", \"lp you get an understanding of how your APIs are being used and how they are performing. They do thi\", \"s activity by letting you view near realtime analytics reports and identifying trends that might imp\", \"act your business. Plus, you can have logs about request and response activity for further online an\", \"d offline analysis.\\n\\nWith Azure API Management, you can secure your APIs using a key, a token, and I\", \"P filtering. These features let you enforce flexible and fine-grained quotas and rate limits, modify\", \" the shape and behavior of your APIs using policies, and improve performance with response caching.\\n\", \"\\nIn this guide and the reference sample application (eShopOnContainers), the architecture is limited\", \" to a simpler and custom-made containerized architecture in order to focus on plain containers witho\", \"ut\\n\\nAPI Gateway\\n\\nusing PaaS products like Azure API Management. But for large microservice-based app\", \"lications that are deployed into Microsoft Azure, we encourage you to evaluate Azure API Management \", \"as the base for your API Gateways in production.\\n\\n## Ocelot\\n\\nOcelot is a lightweight API Gateway, re\", \"commended for simpler approaches. Ocelot is an Open Source .NET Core-based API Gateway especially ma\", \"de for microservices architectures that need unified points of entry into their systems. It's lightw\", \"eight, fast, and scalab le and provides routing and authentication among many other features.\\n\\nThe m\", \"ain reason to choose Ocelot for the eShopOnContainers reference application 2.0 is because Ocelot is\", \" a .NET Core lightweight API Gateway that you can deploy into the same application deployment enviro\", \"nment where you're deploying your microservices/containers, such as a Docker Host, Kubernetes, etc. \", \"And since it's based on .NET Core, it's cross -platform allowing you to deploy on Linux or Windows.\\n\", \"\\nThe previous diagrams showing custom API Gateways running in containers are precisely how you can a\", \"lso run Ocelot in a container and microservice-based application.\\n\\nIn addition, there are many other\", \" products in the market offering API Gateways features, such as Apigee, Kong, MuleSoft, WSO2, and ot\", \"her products like Linkerd and Istio for service mesh ingress controller features.\\n\\nAfter the initial\", \" architecture and patterns explanation sections, the next sections explain how to implement API Gate\", \"ways with Ocelot.\\n\\n## Drawbacks of the API Gateway pattern\\n\\n- The most important drawback is that wh\", \"en you implement an API Gateway, you're coupling that tier with the internal microservices. Coupling\", \" like this might introduce serious difficulties for your application. Clemens Vaster, architect at t\", \"he Azure Service Bus team, refers to this potential difficulty as 'the new ESB' in the ' Messaging a\", \"nd Microservices ' session at GOTO 2016.\\n- Using a microservices API Gateway creates an additional p\", \"ossible single point of failure.\\n- An API Gateway can introduce increased response time due to the a\", \"dditional network call. However, this extra call usually has less impact than having a client interf\", \"ace that's too chatty directly calling the internal microservices.\\n- If not scaled out properly, the\", \" API Gateway can become a bottleneck.\\n- An API Gateway requires additional development cost and futu\", \"re maintenance if it includes custom logic and data aggregation. Developers must update the API Gate\", \"way in order to expose each microservice's endpoints. Moreover, implementation changes in the in ter\", \"nal microservices might cause code changes at the API Gateway level. However, if the API Gateway is \", \"just applying security, logging, and versioning (as when using Azure API Management), this additiona\", \"l development cost might not apply.\\n\\n- If the API Gateway is developed by a single team, there can b\", \"e a development bottleneck. This aspect is another reason why a better approach is to have several f\", \"ined-grained API Gateways that respond to different client needs. You could also segregate the API G\", \"ateway internally into multiple areas or layers that are owned by the different teams working on the\", \" internal microservices.\\n\\n## Additional resources\\n\\n- Chris Richardson. Pattern: API Gateway / Backen\", \"d for Front-End https://microservices.io/patterns/apigateway.html\\n- API Gateway pattern https://lear\", \"n.microsoft.com/azure/architecture/microservices/gateway\\n- Aggregation and composition pattern https\", \"://microservices.io/patterns/data/api-composition.html\\n- Azure API Management https://azure.microsof\", \"t.com/services/api-management/\\n- Udi Dahan. Service Oriented Composition https://udidahan.com/2014/0\", \"7/30/service-oriented-composition-with-video/\\n- Clemens Vasters. Messaging and Microservices at GOTO\", \" 2016 (video) https://www.youtube.com/watch?v=rXi5CLjIQ9k\\n- API Gateway in a Nutshell (ASP.NET Core \", \"API Gateway Tutorial Series) https://www.pogsdotnet.com/2018/08/api-gateway-in-nutshell.html\\n\\n## Com\", \"munication in a microservice architecture\\n\\nIn a monolithic application running on a single process, \", \"components invoke one another using languagelevel method or function calls. These can be strongly co\", \"upled if you're creating objects with code (for example, new ClassName()), or can be invoked in a de\", \"coupled way if you're using Dependency Injection by referencing abstractions rather than concrete ob\", \"ject instances. Either way, the objects are running within the same process. The biggest challenge w\", \"hen changing from a monolithic application to a microservices-based application lies in changing the\", \" communication mechanism. A direct conversion from in-process method calls into RPC calls to service\", \"s will cause a chatty and not efficient communication that won't perform well in distributed environ\", \"ments. The challenges of designing distributed system properly are well enough known that there's ev\", \"en a canon known as the Fallacies of distributed computing that lists assumptions that developers of\", \"ten make when moving from monolithic to distributed designs.\\n\\nThere isn't one solution, but several.\", \" One solution involves isolating the business microservices as much as possible. You then use asynch\", \"ronous communication between the internal microservices and replace finegrained communication that's\", \" typical in intra -process communication between objects with coarser-grained communication. You can\", \" do this by grouping calls, and by returning data that aggregates the results of multiple internal c\", \"alls, to the client.\\n\\nA microservices-based application is a distributed system running on multiple \", \"processes or services, usually even across multiple servers or hosts. Each service instance is typic\", \"ally a process. Therefore, services must interact using an inter-process communication protocol such\", \" as HTTP, AMQP, or a binary protocol like TCP, depending on the nature of each service.\\n\\nThe microse\", \"rvice community promotes the philosophy of ' smart endpoints and dumb pipes '. This slogan encourage\", \"s a design that's as decoupled as possible between microservices, and as cohesive as possible within\", \" a single microservice. As explained earlier, each microservice owns its own data and its own domain\", \" logic. But the microservices composing an end-to-end application are usually simply choreographed b\", \"y using REST communications rather than complex protocols such as WS-* and flexible event-driven com\", \"munications instead of centralized business-process-orchestrators.\\n\\nThe two commonly used protocols \", \"are HTTP request/response with resource APIs (when querying most of all), and lightweight asynchrono\", \"us messaging when communicating updates across multiple microservices. These are explained in more d\", \"etail in the following sections.\\n\\n## Communication types\\n\\nClient and services can communicate throug\", \"h many different types of communication, each one targeting a different scenario and goals. Initiall\", \"y, those types of communications can be classified in two axes.\\n\\nThe first axis defines if the proto\", \"col is synchronous or asynchronous:\\n\\n- Synchronous protocol. HTTP is a synchronous protocol. The cli\", \"ent sends a request and waits for a response from the service. That's independent of the client code\", \" execution that could be synchronous (thread is blocked) or asynchronous (thread isn't blocked, and \", \"the response will reach a callback eventually). The important point here is that the protocol (HTTP/\", \"HTTPS) is synchronous and the client code can only continue its task when it receives the HTTP serve\", \"r response.\\n- Asynchronous protocol. Other protocols like AMQP (a protocol supported by many operati\", \"ng systems and cloud environments) use asynchronous messages. The client code or message sender usua\", \"lly doesn't wait for a response. It just sends the message as when sen ding a message to a RabbitMQ \", \"queue or any other message broker.\\n\\nThe second axis defines if the communication has a single receiv\", \"er or multiple receivers:\\n\\n- Single receiver. Each request must be processed by exactly one receiver\", \" or service. An example of this communication is the Command pattern.\\n- Multiple receivers. Each req\", \"uest can be processed by zero to multiple receivers. This type of communication must be asynchronous\", \". An example is the publish/subscribe mechanism used in patterns like Event-driven architecture. Thi\", \"s is based on an event-bus interface or message broker when propagating data updates between multipl\", \"e microservices through events; it's usually implemented through a service bus or similar artifact l\", \"ike Azure Service Bus by using topics and subscriptions.\\n\\nA microservice-based application will ofte\", \"n use a combination of these communication styles. The most common type is single-receiver communica\", \"tion with a synchronous protocol like HTTP/HTTPS when invoking a regular Web API HTTP service. Micro\", \"services also typically use messaging protocols for asynchronous communication between microservices\", \".\\n\\nThese axes are good to know so you have clarity on the possible communication mechanisms, but the\", \"y're not the important concerns when building microservices. Neither the asynchronous nature of clie\", \"nt thread execution nor the asynchronous nature of the selected protocol are the important points wh\", \"en integrating microservices. What is important is being able to integrate your microservices asynch\", \"ronously while maintaining the independence of microservices, as explained in the following section.\", \"\\n\\n## Asynchronous microservice integration enforces microservice's autonomy\\n\\nAs mentioned, the impor\", \"tant point when building a microservices-based application is the way you integrate your microservic\", \"es. Ideally, you should try to minimize the communication between the internal microservices. The fe\", \"wer communications between microservices, the better. But in many cases, you'll have to somehow inte\", \"grate the microservices. When you need to do that, the critical rule here is that the communication \", \"between the microservices should be asynchronous. That doesn't mean that you have to use a specific \", \"protocol (for example, asynchronous messaging versus synchronous HTTP). It just means that the commu\", \"nication between microservices should be done only by propagating data asynchronously, but try not t\", \"o depend on other internal microservices as part of the initial service's HTTP request/response oper\", \"ation.\\n\\nIf possible, never depend on synchronous communication (request/response) between multiple m\", \"icroservices, not even for queries. The goal of each microservice is to be autonomous and available \", \"to the client consumer, even if the other services that are part of the end-to-end application are d\", \"own or unhealthy. If you think you need to make a call from one microservice to other microservices \", \"(like performing an HTTP request for a data query) to be able to provide a response to a client appl\", \"ication, you have an architecture that won't be resilient when some microservices fail.\\n\\nMoreover, h\", \"aving HTTP dependencies between microservices, like when creating long request/response cycles with \", \"HTTP request chains, as shown in the first part of the Figure 4-15, not only makes your microservice\", \"s not autonomous but also their performance is impacted as soon as one of the services in that chain\", \" isn't performing well.\\n\\nThe more you add synchronous dependencies between microservices, such as qu\", \"ery requests, the worse the overall response time gets for the client apps.\\n\\nSynchronous vs. async c\", \"ommunication across microservices\\n\\nAnti-pattern\\n\\nSynchronous all request/response\\n\\ncycle\\n\\nAsynchrono\", \"us\\n\\nComm. across internal microservices\\n\\n(EventBus: like AMQP)\\n\\n\\\"Asynchronous\\\"\\n\\nComm. across interna\", \"l microservices\\n\\n(Polling: Http)\\n\\nClient\\n\\nHttp sync.\\n\\nrequest\\n\\nHttp sync.\\n\\nrequest\\n\\nHttp sync.\\n\\nrequ\", \"est\\n\\nHttp sync.\\n\\nrequest\\n\\nBasket\\n\\nOrdering\\n\\nCatalog\\n\\n## Such as MVC app Http sync. response Http syn\", \"c. Http sync. response response Http sync. response\\n\\nAPI Gateway\\n\\nSame http request/response cycle!\\n\", \"\\nFigure 4-15. Anti-patterns and patterns in communication between microservices\\n\\n<!-- image -->\\n\\nAs \", \"shown in the above diagram, in synchronous communication a 'chain' of requests is created between mi\", \"croservices while serving the client request. This is an anti-pattern. In asynchronous communication\", \" microservices use asynchronous messages or http polling to communicate with other microservices, bu\", \"t the client request is served right away.\\n\\nIf your microservice needs to raise an additional action\", \" in another microservice, if possible, do not perform that action synchronously and as part of the o\", \"riginal microservice request and reply operation. Instead, do it asynchronously (using asynchronous \", \"messaging or integration events, queues, etc.). But, as much as possible, do not invoke the action s\", \"ynchronously as part of the original synchronous request and reply operation.\\n\\nAnd finally (and this\", \" is where most of the issues arise when building microservices), if your initial microservice needs \", \"data that's originally owned by other microservices, do not rely on making synchronous requests for \", \"that data. Instead, replicate or propagate that data (only the attributes you need) into the initial\", \" service's database by using eventual consistency (typically by using integration events, as explain\", \"ed in upcoming sections).\\n\\nAs noted earlier in the Identifying domain-model boundaries for each micr\", \"oservice section, duplicating some data across several microservices isn't an incorrect designon the\", \" contrary, when doing that you can translate the data into the specific language or terms of that ad\", \"ditional domain or Bounded Context. For instance, in the eShopOnContainers application you have a mi\", \"croservice named identityapi that's in charge of most of the user's data with an entity named User. \", \"However, when you need to store data about the user within the Ordering microservice, you store it a\", \"s a different entity named Buyer. The Buyer entity shares the same identity with the original User e\", \"ntity, but it might have only the few attributes needed by the Ordering domain, and not the whole us\", \"er profile.\\n\\nOther\\n\\nRequest/response communication for live queries and updates\\n\\nHTTP-based Services\", \"\\n\\nYou might use any protocol to communicate and propagate data asynchronously across microservices i\", \"n order to have eventual consistency. As mentioned, you could use integration events using an event \", \"bus or message broker or you could even use HTTP by pollin g the other services instead. It doesn't \", \"matter. The important rule is to not create synchronous dependencies between your microservices. eb \", \"API\\n\\nrequest/response\\n\\nWeb API\\n\\nThe following sections explain the multiple communication styles you\", \" can consider using in a microservice-based application. Redis cache\\n\\nCg\\n\\n## Communication styles\\n\\nT\", \"here are many protocols and choices you can use for communication, depending on the communication ty\", \"pe you want to use. If you're using a synchronous request/response -based communication mechanism, p\", \"rotocols such as HTTP and REST approaches are the most common, especially if you're publishing your \", \"services outside the Docker host or microservice cluster. If you're communicating between services i\", \"nternally (within your Docker host or microservices cluster), you might also want to use binary form\", \"at communication mechanisms (like WCF using TCP and binary format). Alternatively, you can use async\", \"hronous, message-based communication mechanisms such as AMQP.\\n\\nThere are also multiple message forma\", \"ts like JSON or XML, or even binary formats, which can be more efficient. If your chosen binary form\", \"at isn't a standard, it's probably not a good idea to publicly publish your services using that form\", \"at. You could use a non-standard format for internal communication between your microservices. You m\", \"ight do this when communicating between microservices within your Docker host or microservice cluste\", \"r (for example, Docker orchestrators), or for proprietary client applications that talk to the micro\", \"services.\\n\\n## Request/response communication with HTTP and REST\\n\\nWhen a client uses request/response\", \" communication, it sends a request to a service, then the service processes the request and sends ba\", \"ck a response. Request/response communication is especially well suited for querying data for a real\", \"-time UI (a live user interface) from client apps. Therefore, in a microservice architecture you'll \", \"probably use this communication mechanism for most queries, as shown in Figure 4-16.\\n\\nFigure 4-16. U\", \"sing HTTP request/response communication (synchronous or asynchronous)\\n\\n<!-- image -->\\n\\nWhen a clien\", \"t uses request/response communication, it assumes that the response will arrive in a short time, typ\", \"ically less than a second, or a few seconds at most. For delayed responses, you need to implement as\", \"ynchronous communication based on messaging patterns and messaging technologies, which is a differen\", \"t approach that we explain in the next section.\\n\\nA popular architectural style for request/response \", \"communication is REST. This approach is based on, and tightly coupled to, the HTTP protocol, embraci\", \"ng HTTP verbs like GET, POST, and PUT. REST is the most commonly used architectural communication ap\", \"proach when creating services. You can implement REST services when you develop ASP.NET Core Web API\", \" services.\\n\\nThere's additional value when using HTTP REST services as your interface definition lang\", \"uage. For instance, if you use Swagger metadata to describe your service API, you can use tools that\", \" generate client stubs that can directly discover and consume your services.\\n\\n## Additional resource\", \"s\\n\\n- Martin Fowler. Richardson Maturity Model A description of the REST model. https://martinfowler.\", \"com/articles/richardsonMaturityModel.html\\n- Swagger The official site. https://swagger.io/\\n\\n## Push \", \"and real-time communication based on HTTP\\n\\nAnother possibility (usually for different purposes than \", \"REST) is a real-time and one-to-many communication with higher-level frameworks such as ASP.NET Sign\", \"alR and protocols such as WebSockets.\\n\\nAs Figure 4-17 shows, real-time HTTP communication means that\", \" you can have server code pushing content to connected clients as the data becomes available, rather\", \" than having the server wait for a client to request new data.\\n\\nPush and real-time communication bas\", \"ed on HTTP\\n\\nOne-to-many communication\\n\\nClient-1 WebApp SPA\\n\\nJavaScript / Angular.js\\n\\nClient-2 WebApp\", \" SPA \\\\\\n\\nJavaScript / Angular.js\\n\\n## 1 Back end\\n\\nFigure 4-17. One-to-many real-time asynchronous mess\", \"age communication\\n\\n<!-- image -->\\n\\nSignalR is a good way to achieve real-time communication for push\", \"ing content to the clients from a back-end server. Since communication is in real time, client apps \", \"show the changes almost instantly. This is usually handled by a protocol such as WebSockets, using m\", \"any WebSockets connections (one per client). A typical example is when a service communicates a chan\", \"ge in the score of a sports game to many client web apps simultaneously.\\n\\n## Asynchronous message-ba\", \"sed communication\\n\\nAsynchronous messaging and event-driven communication are critical when propagati\", \"ng changes across multiple microservices and their related domain models. As mentioned earlier in th\", \"e discussion microservices and Bounded Contexts (BCs), models (User, Customer, Product, Account, etc\", \".) can mean different things to different microservices or BCs. That means that when changes occur, \", \"you need some way to reconcile changes across the different models. A solution is eventual consisten\", \"cy and event-driven communication based on asynchronous messaging.\\n\\nWhen using messaging, processes \", \"communicate by exchanging messages asynchronously. A client makes a command or a request to a servic\", \"e by sending it a message. If the service needs to reply, it sends a different message back to the c\", \"lient. Since it's a mess age-based communication, the client assumes that the reply won't be receive\", \"d immediately, and that there might be no response at all.\\n\\nA message is composed by a header (metad\", \"ata such as identification or security information) and a body. Messages are usually sent through as\", \"ynchronous protocols like AMQP.\\n\\nThe preferred infrastructure for this type of communication in the \", \"microservices community is a lightweight message broker, which is different than the large brokers a\", \"nd orchestrators used in SOA. In a lightweight message broker, the infrastructure is typi cally 'dum\", \"b,' acting only as a message broker, with simple implementations such as RabbitMQ or a scalable serv\", \"ice bus in the cloud like\\n\\nBack end\\n\\n(1)\\n\\ncommand\\n\\nJ\\n\\nSingle receiver message-based communication\\n\\n(\", \"i.e. Message-based Commands)\\n\\n-\\n\\n--\\n\\n-\\n\\nAzure Service Bus. In this scenario, most of the 'smart' thi\", \"nking still lives in the endpoints that are producing and consuming messages-that is, in the microse\", \"rvices.\\n\\nAnother rule you should try to follow, as much as possible, is to use only asynchronous mes\", \"saging between the internal services, and to use synchronous communication (such as HTTP) only from \", \"the client apps to the front-end services (API Gateways plus the first level of microservices).\\n\\nThe\", \"re are two kinds of asynchronous messaging communication: single receiver message-based communicatio\", \"n, and multiple receivers message-based communication. The following sections provide details about \", \"them.\\n\\nCache\\n\\nDatabase\\n\\n## Single-receiver message-based communication\\n\\nMessagebased asynchronous co\", \"mmunication with a single receiver means there's point -to-point communication that delivers a messa\", \"ge to exactly one of the consumers that's reading from the channel, and that the message is processe\", \"d just once. However, there are special situations. For instance, in a cloud system that tries to au\", \"tomatically recover from failures, the same message could be sent multiple times. Due to network or \", \"other failures, the client has to be able to retry sending messages, and the server has to implement\", \" an operation to be idempotent in order to process a particular message just once.\\n\\nSingle-receiver \", \"message-based communication is especially well suited for sending asynchronous commands from one mic\", \"roservice to another as shown in Figure 4-18 that illustrates this approach.\\n\\nOnce you start sending\", \" message-based communication (either with commands or events), you should avoid mixing message-based\", \" communication with synchronous HTTP communication.\\n\\nFigure 4-18. A single microservice receiving an\", \" asynchronous message\\n\\n<!-- image -->\\n\\nWhen the commands come from client applications, they can be \", \"implemented as HTTP synchronous commands. Use messagebased commands when you need higher scalability\", \" or when you're already in a message-based business process.\\n\\n## Multiple-receivers message-based co\", \"mmunication\\n\\nAs a more flexible approach, you might also want to use a publish/subscribe mechanism s\", \"o that your communication from the sender will be available to additional subscriber microservices o\", \"r to external applications. Thus, it helps you to follow the open/closed principle in the sending se\", \"rvice. That way, additional subscribers can be added in the future without the need to modify the se\", \"nder service.\\n\\nWhen you use a publish/subscribe communication, you might be using an event bus inter\", \"face to publish events to any subscriber.\\n\\n## Asynchronous event-driven communication\\n\\nWhen using as\", \"ynchronous event-driven communication, a microservice publishes an integration event when something \", \"happens within its domain and another microservice needs to be aware of it, like a price change in a\", \" product catalog microservice. Additional microservices subscribe to the events so they can receive \", \"them asynchronously. When that happens, the receivers might update their own domain entities, which \", \"can cause more integration events to be published. This publish/subscribe system is performed by usi\", \"ng an implementation of an event bus. The event bus can be designed as an abstraction or interface, \", \"with the API that's needed to subscribe or unsubscribe to events and to publish events. The event bu\", \"s can also have one or more implementations based on any inter-process and messaging broker, like a \", \"messaging queue or service bus that supports asynchronous communication and a publish/subscribe mode\", \"l.\\n\\nIf a system uses eventual consistency driven by integration events, it's recommended that this a\", \"pproach is made clear to the end user. The system shouldn't use an approach that mimics integration \", \"events, like SignalR or polling systems from the client. The end user and the business owner have to\", \" explicitly embrace eventual consistency in the system and realize that in many cases the business d\", \"oesn't have any problem with this approach, as long as it's explicit. This approach is important bec\", \"ause users might expect to see some results immediately and this aspect might not happen with eventu\", \"al consistency.\\n\\nAs noted earlier in the Challenges and solutions for distributed data management se\", \"ction, you can use integration events to implement business tasks that span multiple microservices. \", \"Thus, you'll have eventual consistency between those services. An eventually consistent transaction \", \"is made up of a collection of distributed actions. At each action, the related microservice updates \", \"a domain entity and publishes another integration event that raises the next action within the same \", \"end-to-end business task.\\n\\nAn important point is that you might want to communicate to multiple micr\", \"oservices that are subscribed to the same event. To do so, you can use publish/subscribe messaging b\", \"ased on eventdriven communication, as shown in Figure 4-19. This publish/subscribe mechanism isn't e\", \"xclusive to the microservice architecture. It's similar to the way Bounded Contexts in DDD should co\", \"mmunicate, or to the way you propagate updates from the write database to the read database in the C\", \"ommand\\n\\nAsynchronous event-driven communication\\n\\nMultiple receivers\\n\\n--\\n\\n---\\n\\n-\\n\\nand Query Responsib\", \"ility Segregation (CQRS) architecture pattern. The goal is to have eventual consistency between mult\", \"iple data sources across your distributed system.\\n\\nBack end\\n\\nUser-Profile Microservice\\n\\n1\\n\\nWeb API S\", \"ervice\\n\\nUpdateUser command\\n\\n## Service X UserUpdated event \\u2192 Buyer info 3 Event Bus\\n\\nUserUpdated eve\", \"nt!\\n\\n(Publish Action)\\n\\n<!-- image -->\\n\\n2\\n\\nDatabase\\n\\nEventual consistency across\\n\\nFigure 4-19. Asynch\", \"ronous event-driven message communication\\n\\nIn asynchronous event-driven communication, one microserv\", \"ice publishes events to an event bus and many microservices can subscribe to it, to get notified and\", \" act on it. Your implementation will determine what protocol to use for event-driven, message-based \", \"communications. AMQP can help achieve reliable queued communication.\\n\\nWhen you use an event bus, you\", \" might want to use an abstraction level (like an event bus interface) based on a related implementat\", \"ion in classes with code using the API from a message broker like RabbitMQ or a service bus like Azu\", \"re Service Bus with Topics. Alternatively, you might want to use a higher-level service bus like NSe\", \"rviceBus, MassTransit, or Brighter to articulate your event bus and publish/subscribe system.\\n\\n## A \", \"note about messaging technologies for production systems\\n\\nThe messaging technologies available for i\", \"mplementing your abstract event bus are at different levels. For instance, products like RabbitMQ (a\", \" messaging broker transport) and Azure Service Bus sit at a lower level than other products like NSe\", \"rviceBus, MassTransit, or Brighter, which can work on top of RabbitMQ and Azure Service Bus. Your ch\", \"oice depends on how many rich features at the application level and out-of-the-box scalability you n\", \"eed for your application. For implementing just a proof-ofconcept event bus for your development env\", \"ironment, as it was done in the eShopOnContainers sample, a simple implementation on top of RabbitMQ\", \" running on a Docker container might be enough.\\n\\nHowever, for mission-critical and production system\", \"s that need hyper-scalability, you might want to evaluate Azure Service Bus. For high-level abstract\", \"ions and features that make the development of distributed applications easier, we recommend that yo\", \"u evaluate other commercial and open-source service buses, such as NServiceBus, MassTransit, and Bri\", \"ghter. Of course, you can build your own\\n\\nCache\\n\\n(Publish/subscribe channel) 4 X UserUpdated event \\u2192\", \" Buyer info\\n\\nservice-bus features on top of lower-level technologies like RabbitMQ and Docker. But t\", \"hat plumbing work might cost too much for a custom enterprise application.\\n\\n## Resiliently publishin\", \"g to the event bus\\n\\nA challenge when implementing an event-driven architecture across multiple micro\", \"services is how to atomically update state in the original microservice while resiliently publishing\", \" its related integration event into the event bus, somehow based on transactions. The following are \", \"a few ways to accomplish this functionality, although there could be additional approaches as well.\\n\", \"\\n- Using a transactional (DTC-based) queue like MSMQ. (However, this is a legacy approach.)\\n- Using \", \"transaction log mining.\\n- Using full Event Sourcing pattern.\\n- Using the Outbox pattern: a transacti\", \"onal database table as a message queue that will be the base for an event-creator component that wou\", \"ld create the event and publish it.\\n\\nFor a more complete description of the challenges in this space\", \", including how messages with potentially incorrect data can end up being published, see Data platfo\", \"rm for mission-critical workloads on Azure: Every message must be processed.\\n\\nAdditional topics to c\", \"onsider when using asynchronous communication are message idempotence and message deduplication. The\", \"se topics are covered in the section Implementing event-based communication between microservices (i\", \"ntegration events) later in this guide.\\n\\n## Additional resources\\n\\n- Event Driven Messaging https://p\", \"atterns.arcitura.com/soa-patterns/design\\\\_patterns/event\\\\_driven\\\\_messaging\\n- Publish/Subscribe Chan\", \"nel https://www.enterpriseintegrationpatterns.com/patterns/messaging/PublishSubscribeChannel. html\\n-\", \" Udi Dahan. Clarified CQRS https://udidahan.com/2009/12/09/clarified-cqrs/\\n- Command and Query Respo\", \"nsibility Segregation (CQRS) https://learn.microsoft.com/azure/architecture/patterns/cqrs\\n- Communic\", \"ating Between Bounded Contexts https://learn.microsoft.com/previous-versions/msp-n-p/jj591572(v=pand\", \"p.10)\\n- Eventual consistency https://en.wikipedia.org/wiki/Eventual\\\\_consistency\\n- Jimmy Bogard. Ref\", \"actoring Towards Resilience: Evaluating Coupling https://jimmybogard.com/refactoring-towards-resilie\", \"nce-evaluating-coupling/\\n\\n## Creating, evolving, and versioning microservice APIs and contracts\\n\\nA m\", \"icroservice API is a contract between the service and its clients. You'll be able to evolve a micros\", \"ervice independently only if you do not break its API contract, which is why the contract is so impo\", \"rtant. If you change the contract, it will impact your client applications or your API Gateway.\\n\\nThe\", \" nature of the API definition depends on which protocol you're using. For instance, if you're using \", \"messaging, like AMQP, the API consists of the message types. If you're using HTTP and RESTful servic\", \"es, the API consists of the URLs and the request and response JSON formats.\\n\\nHowever, even if you're\", \" thoughtful about your initial contract, a service API will need to change over time. When that happ\", \"ens -and especially if your API is a public API consumed by multiple client applications -you typica\", \"lly can't force all clients to up grade to your new API contract. You usually need to incrementally \", \"deploy new versions of a service in a way that both old and new versions of a service contract are r\", \"unning simultaneously. Therefore, it's important to have a strategy for your service versioning.\\n\\nWh\", \"en the API changes are small, like if you add attributes or parameters to your API, clients that use\", \" an older API should switch and work with the new version of the service. You might be able to provi\", \"de default values for any missing attributes that are required, and the clients might be able to ign\", \"ore any extra response attributes.\\n\\nHowever, sometimes you need to make major and incompatible chang\", \"es to a service API. Because you might not be able to force client applications or services to upgra\", \"de immediately to the new version, a service must support older versions of the API for some period.\", \" If you're using an HTTP -based mechanism such as REST, one approach is to embed the API version num\", \"ber in the URL or into an HTTP header. Then you can decide between implementing both versions of the\", \" service simultaneously within the same service instance, or deploying different instances that each\", \" handle a version of the API. A good approach for this functionality is the Mediator pattern (for ex\", \"ample, MediatR library) to decouple the different implementation versions into independent handlers.\", \"\\n\\nFinally, if you're using a REST architecture, Hypermedia is the best solution for versioning your \", \"services and allowing evolvable APIs.\\n\\n## Additional resources\\n\\n- Scott Hanselman. ASP.NET Core REST\", \"ful Web API versioning made easy https://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMad\", \"eEasy.aspx\\n- Versioning a RESTful web API https://learn.microsoft.com/azure/architecture/best-practi\", \"ces/api-design#versioning-arestful-web-api\\n- Roy Fielding. Versioning, Hypermedia, and REST https://\", \"www.infoq.com/articles/roy-fielding-on-versioning\\n\\n## Microservices addressability and the service r\", \"egistry\\n\\nEach microservice has a unique name (URL) that's used to resolve its location. Your microse\", \"rvice needs to be addressable wherever it's running. If you have to think about which computer is ru\", \"nning a particular microservice, things can go bad quickly. In the same way that DNS resolves a URL \", \"to a particular computer, your microservice needs to have a unique name so that its current location\", \" is discoverable. Microservices need addressable names that make them independent from the infrastru\", \"cture that they're running on. This approach implies that there's an interaction between how your se\", \"rvice is deployed and how it's discovered, because there needs to be a service registry. In the same\", \" vein, when a computer fails, the registry service must be able to indicate where the service is now\", \" running.\\n\\nThe service registry pattern is a key part of service discovery. The registry is a databa\", \"se containing the network locations of service instances. A service registry needs to be highly avai\", \"lable and up-to-date. Clients could cache network locations obtained from the service registry. Howe\", \"ver, that information eventually goes out of date and clients can no longer discover service instanc\", \"es. So, a service registry consists of a cluster of servers that use a replication protocol to maint\", \"ain consistency.\\n\\nIn some microservice deployment environments (called clusters, to be covered in a \", \"later section), service discovery is built in. For example, an Azure Kubernetes Service (AKS) enviro\", \"nment can handle service instance registration and deregistration. It also runs a proxy on each clus\", \"ter host that plays the role of server-side discovery router.\\n\\n## Additional resources\\n\\n- Chris Rich\", \"ardson. Pattern: Service registry https://microservices.io/patterns/service-registry.html\\n- Auth0. T\", \"he Service Registry https://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-regis\", \"try/\\n- Gabriel Schenker. Service discovery\\n\\nhttps://lostechies.com/gabrielschenker/2016/01/27/servic\", \"e-discovery/\\n\\n## Creating composite UI based on microservices\\n\\nMicroservices architecture often star\", \"ts with the server-side handling data and logic, but, in many cases, the UI is still handled as a mo\", \"nolith. However, a more advanced approach, called micro frontends, is to design your application UI \", \"based on microservices as well. That means having a composite UI produced by the microservices, inst\", \"ead of having microservices on the server and just a monolithic client app consuming the microservic\", \"es. With this approach, the microservices you build can be complete with both logic and visual repre\", \"sentation.\\n\\nFigure 4-20 shows the simpler approach of just consuming microservices from a monolithic\", \" client application. Of course, you could have an ASP.NET MVC service in between producing the HTML \", \"and JavaScript. The figure is a simplification that highlights that you have a single (monolithic) c\", \"lient UI\\n\\nMonolithic Ul consuming microservices\\n\\n- --\\n\\nMonolithic Ul: Visual layout, shapes and styl\", \"es are defined in\\n\\nthe client app, and don't depend\\n\\n\\u00bf on the microservices\\n\\nMicroservices consuming\", \" the microservices, which just focus on logic and data and not on the UI shape (HTML and JavaScript)\", \". Web API\\n\\n## Data container Microservice 2\\n\\nFigure 4-20. A monolithic UI application consuming back\", \"-end microservices\\n\\n<!-- image -->\\n\\nIn contrast, a composite UI is precisely generated and composed \", \"by the microservices themselves. Some of the microservices drive the visual shape of specific areas \", \"of the UI. The key difference is that you have client UI components (TypeScript classes, for example\", \") based on templates, and the datashaping-UI ViewModel for those templates comes from each microserv\", \"ice.\\n\\nAt client application start-up time, each of the client UI components (TypeScript classes, for\", \" example) registers itself with an infrastructure microservice capable of providing ViewModels for a\", \" given scenario. If the microservice changes the shape, the UI changes also.\\n\\nFigure 4-21 shows a ve\", \"rsion of this composite UI approach. This approach is simplified because you might have other micros\", \"ervices that are aggregating granular parts that are based on different techniques. It depends on wh\", \"ether you're building a traditiona l web approach (ASP.NET MVC) or an SPA (Single Page Application).\", \"\\n\\nData\\n\\namazon\\n\\nComposite Ul generated by microservices\\n\\n\\u0413\\n\\n-\\n\\nBackend Microservices\\n\\nJSON\\n\\nThe East\", \"er Shop\\n\\n## Try Primed composed ViewModel DTOs Microservice 1 Ul Composition Microservice 2\\n\\nCompose\", \"d\\n\\nUl Composition\\n\\nContainer\\n\\n<!-- image -->\\n\\nComposite Ul\\n\\nBooks at Amazon\\n\\nAward winners\\n\\nMore fro\", \"m the Amazon Book Editors\\n\\nFigure 4-21. Example of a composite UI application shaped by back-end mic\", \"roservices\\n\\nEach of those UI composition microservices would be similar to a small API Gateway. But \", \"in this case, each one is responsible for a small UI area.\\n\\nA composite UI approach that's driven by\", \" microservices can be more challenging or less so, depending on what UI technologies you're using. F\", \"or instance, you won't use the same techniques for building a traditional web application that you u\", \"se for building an SPA or for native mobile app (as when developing Xamarin apps, which can be more \", \"challenging for this approach).\\n\\nThe eShopOnContainers sample application uses the monolithic UI app\", \"roach for multiple reasons. First, it's an introduction to microservices and containers. A composite\", \" UI is more advanced but also requires further complexity when designing and developing the UI. Seco\", \"nd, eShopOnContainers also provides a native mobile app based on Xamarin, which would make it more c\", \"omplex on the client C# side.\\n\\nHowever, we encourage you to use the following references to learn mo\", \"re about composite UI based on microservices.\\n\\n## Additional resources\\n\\n- Micro Frontends (Martin Fo\", \"wler's blog) https://martinfowler.com/articles/micro-frontends.html\\n- Micro Frontends (Michael Geers\", \" site) https://micro-frontends.org/\\n- Composite UI using ASP.NET (Particular's Workshop) https://git\", \"hub.com/Particular/Workshop/tree/master/demos/asp-net-core\\n- Ruben Oostinga. The Monolithic Frontend\", \" in the Microservices Architecture https://xebia.com/blog/the-monolithic-frontend-in-the-microservic\", \"es-architecture/\\n\\n- -\\n\\n-\\n\\n- Mauro Servienti. The secret of better UI composition https://particular.\", \"net/blog/secret-of-better-ui-composition\\n- Viktor Farcic. Including Front-End Web Components Into Mi\", \"croservices https://technologyconversations.com/2015/08/09/including-front-end-web-componentsinto-mi\", \"croservices/\\n- Managing Frontend in the Microservices Architecture https://allegro.tech/2016/03/Mana\", \"ging-Frontend-in-the-microservices-architecture.html\\n\\n## Resiliency and high availability in microse\", \"rvices\\n\\nDealing with unexpected failures is one of the hardest problems to solve, especially in a di\", \"stributed system. Much of the code that developers write involves handling exceptions, and this is a\", \"lso where the most time is spent in testing. The problem is more involved than writing code to handl\", \"e failures. What happens when the machine where the microservice is running fails? Not only do you n\", \"eed to detect this microservice failure (a hard problem on its own), but you also need something to \", \"restart your microservice.\\n\\nA microservice needs to be resilient to failures and to be able to resta\", \"rt often on another machine for availability. This resiliency also comes down to the state that was \", \"saved on behalf of the microservice, where the microservice can recover this state from, and whether\", \" the microservice can restart successfully. In other words, there needs to be resiliency in the comp\", \"ute capability (the process can restart at any time) as well as resilience in the state or data (no \", \"data loss, and the data remains consistent).\\n\\nThe problems of resiliency are compounded during other\", \" scenarios, such as when failures occur during an application upgrade. The microservice, working wit\", \"h the deployment system, needs to determine whether it can continue to move forward to the newer ver\", \"sion or instead roll back to a previous version to maintain a consistent state. Questions such as wh\", \"ether enough machines are available to keep moving forward and how to recover previous versions of t\", \"he microservice need to be considered. This approach requires the microservice to emit health inform\", \"ation so that the overall application and orchestrator can make these decisions.\\n\\nIn addition, resil\", \"iency is related to how cloud-based systems must behave. As mentioned, a cloudbased system must embr\", \"ace failures and must try to automatically recover from them. For instance, in case of network or co\", \"ntainer failures, client apps or client services must have a strategy to retry sending messages or t\", \"o retry requests, since in many cases failures in the cloud are partial. The Implementing Resilient \", \"Applications section in this guide addresses how to handle partial failure. It describes techniques \", \"like retries with exponential backoff or the Circuit Breaker pattern in .NET by using libraries like\", \" Polly, which offers a large variety of policies to handle this subject.\\n\\n## Health management and d\", \"iagnostics in microservices\\n\\nIt may seem obvious, and it's often overlooked, but a microservice must\", \" report its health and diagnostics. Otherwise, there's little insight from an operations perspective\", \". Correlating diagnostic events across a set of independent services and dealing with machine clock \", \"skews to make sense of\\n\\nthe event order is challenging. In the same way that you interact with a mic\", \"roservice over agreedupon protocols and data formats, there's a need for standardization in how to l\", \"og health and diagnostic events that ultimately end up in an event store for querying and viewing. I\", \"n a microservices approach, it's key that different teams agree on a single logging format. There ne\", \"eds to be a consistent approach to viewing diagnostic events in the application.\\n\\n## Health checks\\n\\n\", \"Health is different from diagnostics. Health is about the microservice reporting its current state t\", \"o take appropriate actions. A good example is working with upgrade and deployment mechanisms to main\", \"tain availability. Although a service might currently be unhealthy due to a process crash or machine\", \" reboot, the service might still be operational. The last thing you need is to make this worse by pe\", \"rforming an upgrade. The best approach is to do an investigation first or allow time for the microse\", \"rvice to recover. Health events from a microservice help us make informed decisions and, in effect, \", \"help create self-healing services.\\n\\nIn the Implementing health checks in ASP.NET Core services secti\", \"on of this guide, we explain how to use a new ASP.NET HealthChecks library in your microservices so \", \"they can report their state to a monitoring service to take appropriate actions.\\n\\nYou also have the \", \"option of using an excellent open-source library called AspNetCore.Diagnostics.HealthChecks, availab\", \"le on GitHub and as a NuGet package. This library also does health checks, with a twist, it handles \", \"two types of checks:\\n\\n- Liveness : Checks if the microservice is alive, that is, if it's able to acc\", \"ept requests and respond.\\n- Readiness : Checks if the microservice's dependencies (Database, queue s\", \"ervices, etc.) are themselves ready, so the microservice can do what it's supposed to do.\\n\\n## Using \", \"diagnostics and logs event streams\\n\\nLogs provide information about how an application or service is \", \"running, including exceptions, warnings, and simple informational messages. Usually, each log is in \", \"a text format with one line per event, although exceptions also often show the stack trace across mu\", \"ltiple lines.\\n\\nIn monolithic server-based applications, you can write logs to a file on disk (a logf\", \"ile) and then analyze it with any tool. Since application execution is limited to a fixed server or \", \"VM, it generally isn't too complex to analyze the flow of events. However, in a distributed applicat\", \"ion where multiple services are executed across many nodes in an orchestrator cluster, being able to\", \" correlate distributed events is a challenge.\\n\\nA microservice-based application should not try to st\", \"ore the output stream of events or logfiles by itself, and not even try to manage the routing of the\", \" events to a central place. It should be transparent, meaning that each process should just write it\", \"s event stream to a standard output that underneath will be collected by the execution environment i\", \"nfrastructure where it's running. An example of these event stream routers is Microsoft.Diagnostic.E\", \"ventFlow, which collects event streams from multiple sources and publishes it to output systems. The\", \"se can include simple standard output for a development environment or cloud systems like Azure Moni\", \"tor and Azure Diagnostics. There are also good third-party log analysis platforms and tools that can\", \" search, alert, report, and monitor logs, even in real time, like Splunk.\\n\\nLifecycle\\n\\nMgmt\\n\\nYour mic\", \"roservices\\n\\n## Orchestrators managing health and diagnostics information\\n\\nWhen you create a microser\", \"vice-based application, you need to deal with complexity. Of course, a single microservice is simple\", \" to deal with, but dozens or hundreds of types and thousands of instances of microservices is a comp\", \"lex problem. It isn't just abo ut building your microservice architecture -you also need high availa\", \"bility, addressability, resiliency, health, and diagnostics if you intend to have a stable and cohes\", \"ive system.\\n\\n## (Orchestrators/Clusters)\\n\\nFigure 4-22 . A Microservice Platform is fundamental for a\", \"n application's health management\\n\\n<!-- image -->\\n\\nThe complex problems shown in Figure 4-22 are har\", \"d to solve by yourself. Development teams should focus on solving business problems and building cus\", \"tom applications with microservice-based approaches. They should not focus on solving complex infras\", \"tructure problems; if they did, the cost of any microservice-based application would be huge. Theref\", \"ore, there are microservice-oriented platforms, referred to as orchestrators or microservice cluster\", \"s, that try to solve the hard problems of building and running a service and using infrastructure re\", \"sources efficiently. This approach reduces the complexities of building applications that use a micr\", \"oservices approach.\\n\\nDifferent orchestrators might sound similar, but the diagnostics and health che\", \"cks offered by each of them differ in features and state of maturity, sometimes depending on the OS \", \"platform, as explained in the next section.\\n\\n## Additional resources\\n\\n- The Twelve-Factor App. XI. L\", \"ogs: Treat logs as event streams https://12factor.net/logs\\n- Microsoft Diagnostic EventFlow Library \", \"GitHub repo. https://github.com/Azure/diagnostics-eventflow\\n- What is Azure Diagnostics https://lear\", \"n.microsoft.com/azure/azure-diagnostics\\n\\n- Connect Windows computers to the Azure Monitor service ht\", \"tps://learn.microsoft.com/azure/azure-monitor/platform/agent-windows\\n- Logging What You Mean: Using \", \"the Semantic Logging Application Block https://learn.microsoft.com/previous-versions/msp-n-p/dn44072\", \"9(v=pandp.60)\\n- Splunk Official site. https://www.splunk.com/\\n- EventSource Class API for events tra\", \"cing for Windows (ETW) https://learn.microsoft.com/dotnet/api/system.diagnostics.tracing.eventsource\", \"\\n\\n## Orchestrate microservices and multi-container applications for high scalability and availabilit\", \"y\\n\\nUsing orchestrators for production-ready applications is essential if your application is based o\", \"n microservices or simply split across multiple containers. As introduced previously, in a microserv\", \"icebased approach, each microservice owns its model and data so that it will be autonomous from a de\", \"velopment and deployment point of view. But even if you have a more traditional application that's c\", \"omposed of multiple services (like SOA), you'll also have multiple containers or services comprising\", \" a single business application that need to be deployed as a distributed system. These kinds of syst\", \"ems are complex to scale out and manage; therefore, you absolutely need an orchestrator if you want \", \"to have a production-ready and scalable multi-container application.\\n\\nFigure 4-23 illustrates deploy\", \"ment into a cluster of an application composed of multiple microservices (containers).\\n\\nComposed Doc\", \"ker Applications in a Cluster\\n\\n\\u2022 For each service instance you use one container\\n\\n\\u2022 Docker images/co\", \"ntainers are \\\"units of deployment\\\"\\n\\nA container is an instance of a Docker Image\\n\\n## \\u2022 A host (VM/se\", \"rver) handles many containers\\n\\nFigure 4-23. A cluster of containers\\n\\n<!-- image -->\\n\\nYou use one con\", \"tainer for each service instance. Docker containers are 'units of deployment' and a container is an \", \"instance of a Docker. A host handles many containers. It looks like a logical approach. But how are \", \"you handling load-balancing, routing, and orchestrating these composed applications?\\n\\nThe plain Dock\", \"er Engine in single Docker hosts meets the needs of managing single image instances on one host, but\", \" it falls short when it comes to managing multiple containers deployed on multiple hosts for more co\", \"mplex distributed applications. In most cases, you need a management platform that will automaticall\", \"y start containers, scale out containers with multiple instances per image, suspend them or shut the\", \"m down when needed, and ideally also control how they access resources like the network and data sto\", \"rage.\\n\\nTo go beyond the management of individual containers or simple composed apps and move toward \", \"larger enterprise applications with microservices, you must turn to orchestration and clustering pla\", \"tforms.\\n\\nFrom an architecture and development point of view, if you're building large enterprise com\", \"posed of microservicesbased applications, it's important to understand the following platforms and p\", \"roducts that support advanced scenarios:\\n\\nClusters and orchestrators. When you need to scale out app\", \"lications across many Docker hosts, as when a large microservicebased application, it's critical to \", \"be able to manage all those hosts as a single cluster by abstracting the complexity of the underlyin\", \"g platform. That's what the container clusters and orchestrators provide. Kubernetes is an example o\", \"f an orchestrator, and is available in Azure through Azure Kubernetes Service.\\n\\nSchedulers. Scheduli\", \"ng means to have the capability for an administrator to launch containers in a cluster so they also \", \"provide a UI. A cluster scheduler has several responsibilities: to use the cluster's\\n\\nApp 1\\n\\nApp?\\n\\nS\", \"ervices\\n\\nMy Docker Images\\n\\nresources efficiently, to set the constraints provided by the user, to ef\", \"ficiently load-balance containers across nodes or hosts, and to be robust against errors while provi\", \"ding high availability.\\n\\nThe concepts of a cluster and a scheduler are closely related, so the produ\", \"cts provided by different vendors often provide both sets of capabilities. The following list shows \", \"the most important platform and software choices you have for clusters and schedulers. These orchest\", \"rators are generally offered in public clouds like Azure.\\n\\n## Software platforms for container clust\", \"ering, orchestration, and scheduling\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n| Platform    \", \"                   | Description                                                                    \", \"                                                                                                    \", \"                                                                                                    \", \"                                                                                                    \", \"                                                                                           |\\n|------\", \"--------------------------|-------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"--------------------------------------------------------------------------------------------------|\\n\", \"| Kubernetes                     | Kubernetes is an open-source product that provides functionality \", \"that ranges from cluster infrastructure and container scheduling to orchestrating capabilities. It l\", \"ets you automate deployment, scaling, and operations of application containers across clusters of ho\", \"sts. Kubernetes provides a container- centric infrastructure that groups application containers into\", \" logical units for easy management and discovery. Kubernetes is mature in Linux, less mature in Wind\", \"ows. |\\n| Azure Kubernetes Service (AKS) | AKS is a managed Kubernetes container orchestration servic\", \"e in Azure that simplifies Kubernetes cluster's management, deployment, and operations.             \", \"                                                                                                    \", \"                                                                                                    \", \"                                                                                                    \", \"            |\\n| Azure Container Apps           | Azure Container Apps is a managed serverless contai\", \"ner service for building and deploying modern apps at scale.                                        \", \"                                                                                                    \", \"                                                                                                    \", \"                                                                                                    \", \"                   |\\n\\n## Using container-based orchestrators in Microsoft Azure\\n\\nSeveral cloud vendo\", \"rs offer Docker containers support plus Docker clusters and orchestration support, including Microso\", \"ft Azure, Amazon EC2 Container Service, and Google Container Engine. Microsoft Azure provides Docker\", \" cluster and orchestrator support through Azure Kubernetes Service (AKS).\\n\\nAKS\\n\\nKubernetes\\n\\nNode\\n\\nNo\", \"de\\n\\nMaster Node\\n\\n## Using Azure Kubernetes Service DNS\\n\\nA Kubernetes cluster pools multiple Docker h\", \"osts and exposes them as a single virtual Docker host, so you can deploy multiple containers into th\", \"e cluster and scale-out with any number of container instances. The cluster will handle all the comp\", \"lex management plumbing, like scalability, health, and so forth.\\n\\nAKS provides a way to simplify the\", \" creation, configuration, and management of a cluster of virtual machines in Azure that are preconfi\", \"gured to run containerized applications. Using an optimized configuration of popular open-source sch\", \"eduling and orchestration tools, AKS enables you to use your existing skills or draw on a large and \", \"growing body of community expertise to deploy and manage container-based applications on Microsoft A\", \"zure.\\n\\nAzure Kubernetes Service optimizes the configuration of popular Docker clustering open-source\", \" tools and technologies specifically for Azure. You get an open solution that offers portability for\", \" both your containers and your application configuration. You select the size, the number of hosts, \", \"and the orchestrator tools, and AKS handles everything else.\\n\\nFigure 4-24 . Kubernetes cluster's sim\", \"plified structure and topology\\n\\n<!-- image -->\\n\\nPC/Development Environment\\n\\nWindows 10 or macOS\\n\\nDoc\", \"ker Registry\\n\\nDocker Hub\\n\\nOr ACR\\n\\nIn figure 4-24, you can see the structure of a Kubernetes cluster \", \"where a master node (VM) controls most of the coordination of the cluster and you can deploy contain\", \"ers to the rest of the nodes, which are managed as a single pool from an application point of view a\", \"nd allows you to scale to thousands or even tens of thousands of containers. Schedulee\\n\\nRepository\\n\\n\", \"## Development environment for Kubernetes\\n\\nKubernetes cluster\\n\\nIn the development environment, Docke\", \"r announced in July 2018 that Kubernetes can also run in a single development machine (Windows 10 or\", \" macOS) by installing Docker Desktop. You can later deploy to the cloud (AKS) for further integratio\", \"n tests, as shown in figure 4-25.\\n\\nFigure 4-25. Running Kubernetes in dev machine and the cloud\\n\\n<!-\", \"- image -->\\n\\n## Getting started with Azure Kubernetes Service (AKS)\\n\\nTo begin using AKS, you deploy \", \"an AKS cluster from the Azure portal or by using the CLI. For more information on deploying a Kubern\", \"etes cluster in Azure, see Deploy an Azure Kubernetes Service (AKS) cluster.\\n\\nThere are no fees for \", \"any of the software installed by default as part of AKS. All default options are implemented with op\", \"en-source software. AKS is available for multiple virtual machines in Azure. You're charged only for\", \" the compute instances you choose, and the other underlying infrastructure resources consumed, such \", \"as storage and networking. There are no incremental charges for AKS itself.\\n\\nThe default production \", \"deployment option for Kubernetes is to use Helm charts, which are introduced in the next section.\\n\\nN\", \"ode\\n\\nA Azure\\n\\nAzure Kubernetes Service (AKS)\\n\\n\\\"Managed Kubernetes\\\" for production\\n\\n## Deploy with He\", \"lm charts into Kubernetes clusters\\n\\nWhen deploying an application to a Kubernetes cluster, you can u\", \"se the original kubectl.exe CLI tool using deployment files based on the native format (.yaml files)\", \", as already mentioned in the previous section. However, for more complex Kubernetes applications su\", \"ch as when deploying complex microservicebased applications, it's recommended to use Helm.\\n\\nHelm Cha\", \"rts helps you define, version, install, share, upgrade, or rollback even the most complex Kubernetes\", \" application.\\n\\nGoing further, Helm usage is also recommended because other Kubernetes environments i\", \"n Azure, such as Azure Dev Spaces are also based on Helm charts.\\n\\nHelm is maintained by the Cloud Na\", \"tive Computing Foundation (CNCF) - in collaboration with Microsoft, Google, Bitnami, and the Helm co\", \"ntributor community.\\n\\nFor more implementation information on Helm charts and Kubernetes, see the Usi\", \"ng Helm Charts to deploy eShopOnContainers to AKS post.\\n\\n## Additional resources\\n\\n- Getting started \", \"with Azure Kubernetes Service (AKS) https://learn.microsoft.com/azure/aks/kubernetes-walkthrough-por\", \"tal\\n- Azure Dev Spaces https://learn.microsoft.com/azure/dev-spaces/azure-dev-spaces\\n- Kubernetes Th\", \"e official site. https://kubernetes.io/\\n\\n## Development process for Docker-based applications\\n\\nDevel\", \"op containerized .NET applications the way you like, either Integrated Development Environment (IDE)\", \" focused with Visual Studio and Visual Studio tools for Docker or CLI/Editor focused with Docker CLI\", \" and Visual Studio Code.\\n\\n## Development environment for Docker apps\\n\\n## Development tool choices: I\", \"DE or editor\\n\\nWhether you prefer a full and powerful IDE or a lightweight and agile editor, Microsof\", \"t has tools that you can use for developing Docker applications.\\n\\nVisual Studio (for Windows). Docke\", \"r-based .NET 7 application development with Visual Studio requires Visual Studio 2022 version 17.0 o\", \"r later. Visual Studio 2022 comes with tools for Docker already built in. The tools for Docker let y\", \"ou develop, run, and validate your applications directly in the target Docker environment. You can p\", \"ress F5 to run and debug your application (single container or multiple containers) directly into a \", \"Docker host, or press CTRL + F5 to edit and refresh your application without having to rebuild the c\", \"ontainer. This IDE is the most powerful development choice for Docker-based apps.\\n\\nVisual Studio for\", \" Mac. It's an IDE, evolution of Xamarin Studio, running in macOS. This tool should be the preferred \", \"choice for developers working in macOS machines who also want to use a powerful IDE.\\n\\nVisual Studio \", \"Code and Docker CLI . If you prefer a lightweight and cross-platform editor that supports any develo\", \"pment language, you can use Visual Studio Code and the Docker CLI. This IDE is a cross-platform deve\", \"lopment approach for macOS, Linux, and Windows. Additionally, Visual Studio Code supports extensions\", \" for Docker such as IntelliSense for Dockerfiles and shortcut tasks to run Docker commands from the \", \"editor.\\n\\nBy installing Docker Desktop, you can use a single Docker CLI to build apps for both Window\", \"s and Linux.\\n\\n## Additional resources\\n\\n- Visual Studio . Official site. https://visualstudio.microso\", \"ft.com/vs/\\n- Visual Studio Code . Official site. https://code.visualstudio.com/download\\n- Docker Des\", \"ktop for Windows https://hub.docker.com/editions/community/docker-ce-desktop-windows\\n- Docker Deskto\", \"p for Mac https://hub.docker.com/editions/community/docker-ce-desktop-mac\\n\\n## .NET languages and fra\", \"meworks for Docker containers\\n\\nAs mentioned in earlier sections of this guide, you can use .NET Fram\", \"ework, .NET 7, or the opensource Mono project when developing Docker containerized .NET applications\", \". You can develop in C#, F#, or Visual Basic when targeting Linux or Windows Containers, depending o\", \"n which .NET framework is in use. For more details about.NET languages, see the blog post The .NET L\", \"anguage Strategy.\\n\\n## Development workflow for Docker apps\\n\\nThe application development life cycle s\", \"tarts at your computer, as a developer, where you code the application using your preferred language\", \" and test it locally. With this workflow, no matter which language, framework, and platform you choo\", \"se, you're always developing and testing Docker containers, but doing so locally.\\n\\nEach container (a\", \"n instance of a Docker image) includes the following components:\\n\\n- An operating system selection, f\", \"or example, a Linux distribution, Windows Nano Server, or Windows Server Core.\\n- Files added during \", \"development, for example, source code and application binaries.\\n- Configuration information, such as\", \" environment settings and dependencies.\\n\\n## Workflow for developing Docker container-based applicati\", \"ons\\n\\nThis section describes the inner-loop development workflow for Docker container-based applicati\", \"ons. The innerloop workflow means it's not considering the broader DevOps workflow, which can includ\", \"e up to production deployment, and just focuses on the development work done on the developer's c om\", \"puter. The initial steps to set up the environment aren't included, since those steps are done only \", \"once.\\n\\nInner-Loop development workflow for Docker apps\\n\\n3\\n\\nCreate Images detined at\\n\\nWrite\\n\\nDockerfi\", \"le/s\\n\\n4. (Opt.in)\\n\\nDefine services by writing\\n\\nRun\\n\\nContainers /\\n\\nTest\\n\\nAn application is composed o\", \"f your own services plus additional libraries (dependencies). The following are the basic steps you \", \"usually take when building a Docker application, as illustrated in Figure 5-1. docker build f docker\", \" run / Docker-compose up http access... VM\\n\\n## Base Images My Images My Container 2 Container 2)\\n\\nRe\", \"mote\\n\\nDocker Registry\\n\\nLocal\\n\\nDocker\\n\\n<!-- image -->\\n\\nCode your app\\n\\n=\\n\\ngit push\\n\\n7.\\n\\nPush or\\n\\nConti\", \"nue developing\\n\\nFigure 5-1. Step-by-step workflow for developing Docker containerized apps\\n\\nIn this \", \"section, this whole process is detailed and every major step is explained by focusing on a Visual St\", \"udio environment.\\n\\nWhen you're using an editor/CLI development approach (for example, Visual Studio \", \"Code plus Docker CLI on macOS or Windows), you need to know every step, generally in more detail tha\", \"n if you're using Visual Studio. For more information about working in a CLI environment, see the e-\", \"book Containerized Docker Application lifecycle with Microsoft Platforms and Tools.\\n\\nWhen you're usi\", \"ng Visual Studio 2022, many of those steps are handled for you, which dramatically improves your pro\", \"ductivity. This is especially true when you're using Visual Studio 2022 and targeting multi-containe\", \"r applications. For instance, with just one mouse click, Visual Studio adds the Dockerfile and docke\", \"r-compose.yml file to your projects with the configuration for your application. When you run the ap\", \"plication in Visual Studio, it builds the Docker image and runs the multi-container application dire\", \"ctly in Docker; it even allows you to debug several containers at once. These features will boost yo\", \"ur development speed.\\n\\nHowever, just because Visual Studio makes those steps automatic doesn't mean \", \"that you don't need to know what's going on underneath with Docker. Therefore, the following guidanc\", \"e details every step.\\n\\nLiAuAl ChuA:\\n\\nLand\\n\\nInstalling - Visual Studio Enterprise 2022 - 17.0.1\\n\\nCode\", \"\\n\\nWorkloads your app\\n\\nIndividual components\\n\\nLanguage packs\\n\\nWeb &amp; Cloud (4)\\n\\nASP.NET and web de\", \"velopment\\n\\nBuild web applications using ASP.NET Core, ASP.NET,\\n\\nHTML/JavaScript, and Containers incl\", \"uding Docker supp...\\n\\nPython development\\n\\nEditing, debugging, interactive development and source con\", \"trol for Python.\\n\\n<!-- image -->\\n\\nDesktop &amp; Mobile (5)\\n\\n## Step 1. Start coding and create your \", \"initial application or service baseline\\n\\nDesktop development with C++\\n\\nUniversal Windows Platform de\", \"velopment\\n\\nDeveloping a Docker application is similar to the way you develop an application without \", \"Docker. The difference is that while developing for Docker, you're deploying and testing your applic\", \"ation or services running within Docker containers in your local environment (either a Linux VM setu\", \"p by Docker or directly Windows if using Windows Containers). Install while downloadingInstall\\n\\n## S\", \"et up your local environment with Visual Studio\\n\\nTo begin, make sure you have Docker Desktop for Win\", \"dows for Windows installed, as explained in the following instructions:\\n\\n## Get started with Docker \", \"Desktop for Windows\\n\\nIn addition, you need Visual Studio 2022 version 17.0, with the .ASP.NET and we\", \"b development workload installed, as shown in Figure 5-2.\\n\\nFigure 5-2. Selecting the ASP.NET and web\", \" development workload during Visual Studio 2022 setup\\n\\n<!-- image -->\\n\\nYou can start coding your app\", \"lication in plain .NET (usually in .NET Core or later if you're planning to use containers) even bef\", \"ore enabling Docker in your application and deploying and testing in Docker. However, it is recommen\", \"ded that you start working on Docker as soon as possible, because that will be the real environment \", \"and any issues can be discovered as soon as possible. This is encouraged\\n\\nLocation\\n\\nInstallation loc\", \"ations\\n\\nAzure development\\n\\nAzure SKs, tools, and projects for developing cloud apps and creating res\", \"ources using .NET and .NET Framework.....\\n\\nNode.js development\\n\\nBuild scalable network applications \", \"using Node.js, an asynchronous event-driven JavaScript runtime.\\n\\n*\\n\\nInstallation details\\n\\n\\u2022 Visual S\", \"tudio core editor\\n\\n\\u2022 ASP.NET and web development\\n\\n\\u2022 Individual components\\n\\nNET 6.0 Runtime\\n\\n- \\u2022\\n\\nX\\n\\n\", \"because Visual Studio makes it so easy to work with Docker that it almost feels transparent -the bes\", \"t example when debugging multi-container applications from Visual Studio.\\n\\n## Additional resources\\n\\n\", \"- Get started with Docker Desktop for Windows https://docs.docker.com/docker-for-windows/\\n- Visual S\", \"tudio 2022 https://visualstudio.microsoft.com/downloads/\\n\\n<!-- image -->\\n\\n## Step 2. Create a Docker\", \"file related to an existing .NET base image\\n\\nYou need a Dockerfile for each custom image you want to\", \" build; you also need a Dockerfile for each container to be deployed, whether you deploy automatical\", \"ly from Visual Studio or manually using the Docker CLI (docker run and docker-compose commands). If \", \"your application contains a single custom service, you need a single Dockerfile. If your application\", \" contains multiple services (as in a microservices architecture), you need one Dockerfile for each s\", \"ervice.\\n\\nThe Dockerfile is placed in the root folder of your application or service. It contains the\", \" commands that tell Docker how to set up and run your application or service in a container. You can\", \" manually create a Dockerfile in code and add it to your project along with your .NET dependencies.\\n\", \"\\nWith Visual Studio and its tools for Docker, this task requires only a few mouse clicks. When you c\", \"reate a new project in Visual Studio 2022, there's an option named Enable Docker Support , as shown \", \"in Figure 5-3.\\n\\nNew Item...\\n\\nAdditional information\\n\\nExisting Item...\\n\\nNew Scaffolded Item...\\n\\nASP.N\", \"ET Core Web API\\n\\nNew Folder\\n\\nFramework\\n\\nContainer Orchestrator Support...\\n\\n\\u2022NET 6.0 (Long-term suppo\", \"rt)\\n\\nDocker Support...\\n\\nAuthentication type\\n\\nNone\\n\\nApplication Insights Telemetry...\\n\\n\\u2022 Configure fo\", \"r HTTPS O\\n\\nClient-Side Library...\\n\\nL Enable Docker O\\n\\nDocker OS O\\n\\nNew Azure WebJob Project\\n\\nExistin\", \"g Project as Azure WebJob\\n\\nLinux\\n\\nI Use controllers (uncheck to use minimal APIs) O\\n\\nReference...\\n\\nE\", \"nable OpenAPI support O\\n\\nService Reference...\\n\\nConnected Service\\n\\nClass...\\n\\nC#\\n\\nLinux macos\\n\\nCtrl+Sh\", \"ift+A\\n\\nShift+Alt+A\\n\\nWindows\\n\\nCloud\\n\\nAdd\\n\\nManage NuGet Packages...\\n\\nManage Client-Side Libraries...\\n\\n\", \"Service\\n\\nWeb\\n\\nManage User Secrets\\n\\nFigure 5-3. Enabling Docker Support when creating a new ASP.NET C\", \"ore project in Visual Studio 2022\\n\\n<!-- image -->\\n\\nYou can also enable Docker support on an existing\", \" ASP.NET Core web app project by right-clicking the project in Solution Explorer and selecting Add &\", \"gt; Docker Support\\u2026 , as shown in Figure 5-4.\\n\\nFigure 5-4. Enabling Docker support in an existing Vi\", \"sual Studio 2022 project\\n\\n<!-- image -->\\n\\nThis action adds a Dockerfile to the project with the requ\", \"ired configuration, and is only available on ASP.NET Core projects.\\n\\nIn a similar fashion, Visual St\", \"udio can also add a docker-compose.yml file for the whole solution with the option Add &gt; Containe\", \"r Orchestrator Support\\u2026 . In step 4, we'll explore this option in greater detail.\\n\\n## Using an exist\", \"ing official .NET Docker image\\n\\nYou usually build a custom image for your container on top of a base\", \" image you get from an official repository like the Docker Hub registry. That is precisely what happ\", \"ens under the covers when you enable Docker support in Visual Studio. Your Dockerfile will use an ex\", \"isting dotnet/core/aspnet image.\\n\\nEarlier we explained which Docker images and repos you can use, de\", \"pending on the framework and OS you have chosen. For instance, if you want to use ASP.NET Core (Linu\", \"x or Windows), the image to use is mcr.microsoft.com/dotnet/aspnet:7.0. Therefore, you just need to \", \"specify what base Docker image you will use for your container. You do that by adding FROM\\n\\nmcr.micr\", \"osoft.com/dotnet/aspnet:7.0 to your Dockerfile. This will be automatically performed by Visual Studi\", \"o, but if you were to update the version, you update this value.\\n\\nUsing an official .NET image repos\", \"itory from Docker Hub with a version number ensures that the same language features are available on\", \" all machines (including development, testing, and production).\\n\\nThe following example shows a sampl\", \"e Dockerfile for an ASP.NET Core container.\\n\\n```\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0 ARG source\", \" WORKDIR /app EXPOSE 80 COPY ${source:-obj/Docker/publish} . ENTRYPOINT [\\\"dotnet\\\", \\\" MySingleContain\", \"erWebApp.dll \\\"]\\n```\\n\\nIn this case, the image is based on version 7.0 of the official ASP.NET Core Do\", \"cker image (multi-arch for Linux and Windows). This is the setting FROM mcr.microsoft.com/dotnet/asp\", \"net:7.0. (For more information about this base image, see the ASP.NET Core Docker Image page.) In th\", \"e Dockerfile, you also need to instruct Docker to listen on the TCP port you will use at runtime (in\", \" this case, port 80, as configured with the EXPOSE setting).\\n\\nYou can specify additional configurati\", \"on settings in the Dockerfile, depending on the language and framework you're using. For instance, t\", \"he ENTRYPOINT line with [\\\"dotnet\\\",\\n\\n\\\"MySingleContainerWebApp.dll\\\"] tells Docker to run a .NET applic\", \"ation. If you're us ing the SDK and the .NET CLI (dotnet CLI) to build and run the .NET application,\", \" this setting would be different. The bottom line is that the ENTRYPOINT line and other settings wil\", \"l be different depending on the language and platform you choose for your application.\\n\\n## Additiona\", \"l resources\\n\\n- Building Docker Images for ASP.NET Core Applications\\n\\nhttps://learn.microsoft.com/dot\", \"net/core/docker/building-net-docker-images\\n\\n- Build your own image . In the official Docker document\", \"ation. https://docs.docker.com/engine/tutorials/dockerimages/\\n- Staying up-to-date with .NET Contain\", \"er Images https://devblogs.microsoft.com/dotnet/staying-up-to-date-with-net-container-images/\\n- Usin\", \"g .NET and Docker Together - DockerCon 2018 Update https://devblogs.microsoft.com/dotnet/using-net-a\", \"nd-docker-together-dockercon-2018update/\\n\\n## Using multi-arch image repositories\\n\\nA single repo can \", \"contain platform variants, such as a Linux image and a Windows image. This feature allows vendors li\", \"ke Microsoft (base image creators) to create a single repo to cover multiple platforms (that is Linu\", \"x and Windows). For example, the .NET repository available in the Docker Hub registry provides suppo\", \"rt for Linux and Windows Nano Server by using the same repo name.\\n\\nIf you specify a tag, targeting a\", \" platform that is explicit like in the following cases:\\n\\n- mcr.microsoft.com/dotnet/aspnet:7.0-bulls\", \"eye-slim Targets: .NET 7 runtime-only on Linux\\n- mcr.microsoft.com/dotnet/aspnet:7.0-nanoserver-ltsc\", \"2022 Targets: .NET 7 runtime-only on Windows Nano Server\\n\\nBut, if you specify the same image name, e\", \"ven with the same tag, the multi-arch images (like the aspnet image) will use the Linux or Windows v\", \"ersion depending on the Docker host OS you're deploying, as shown in the following example:\\n\\n- mcr.m\", \"icrosoft.com/dotnet/aspnet:7.0 Multi-arch: .NET 7 runtime-only on Linux or Windows Nano Server depen\", \"ding on the Docker host OS\\n\\nThis way, when you pull an image from a Windows host, it will pull the W\", \"indows variant, and pulling the same image name from a Linux host will pull the Linux variant.\\n\\n## M\", \"ulti-stage builds in Dockerfile\\n\\nThe Dockerfile is similar to a batch script. Similar to what you wo\", \"uld do if you had to set up the machine from the command line.\\n\\nIt starts with a base image that set\", \"s up the initial context, it's like the startup filesystem, that sits on top of the host OS. It's no\", \"t an OS, but you can think of it like 'the' OS inside the container.\\n\\nThe execution of every command\", \" line creates a new layer on the filesystem with the changes from the previous one, so that, when co\", \"mbined, produce the resulting filesystem.\\n\\nSince every new layer 'rests' on top of the previous one \", \"and the resulting image size increases with every command, images can get very large if they have to\", \" include, for example, the SDK needed to build and publish an application.\\n\\nThis is where multi-stag\", \"e builds get into the plot (from Docker 17.05 and higher) to do their magic.\\n\\nThe core idea is that \", \"you can separate the Dockerfile execution process in stages, where a stage is an initial image follo\", \"wed by one or more commands, and the last stage determines the final image size.\\n\\nIn short, multista\", \"ge builds allow splitting the creation in different 'phases' and then assemble the final image takin\", \"g only the relevant directories from the intermediate stages. The general strategy to use this featu\", \"re is:\\n\\n1. Use a base SDK image (doesn't matter how large), with everything needed to build and publ\", \"ish the application to a folder and then\\n2. Use a base, small, runtime-only image and copy the publi\", \"shing folder from the previous stage to produce a small final image.\\n\\nProbably the best way to under\", \"stand multi-stage is going through a Dockerfile in detail, line by line, so let's begin with the ini\", \"tial Dockerfile created by Visual Studio when adding Docker support to a project and will get into s\", \"ome optimizations later.\\n\\nThe initial Dockerfile might look something like this:\\n\\n```\\n1 FROM mcr.mic\", \"rosoft.com/dotnet/aspnet:7.0 AS base 2 WORKDIR /app 3 EXPOSE 80 4 5 FROM mcr.microsoft.com/dotnet/sd\", \"k:7.0 AS build 6 WORKDIR /src 7 COPY src/Services/Catalog/Catalog.API/Catalog.API.csproj \\u2026 8 COPY sr\", \"c/BuildingBlocks/HealthChecks/src/Microsoft.AspNetCore.HealthChecks \\u2026 9 COPY src/BuildingBlocks/Heal\", \"thChecks/src/Microsoft.Extensions.HealthChecks \\u2026 10 COPY src/BuildingBlocks/EventBus/IntegrationEven\", \"tLogEF/ \\u2026 11 COPY src/BuildingBlocks/EventBus/EventBus/EventBus.csproj \\u2026 12 COPY src/BuildingBlocks/\", \"EventBus/EventBusRabbitMQ/EventBusRabbitMQ.csproj \\u2026 13 COPY src/BuildingBlocks/EventBus/EventBusServ\", \"iceBus/EventBusServiceBus.csproj \\u2026 14 COPY src/BuildingBlocks/WebHostCustomization/WebHost.Customiza\", \"tion \\u2026 15 COPY src/BuildingBlocks/HealthChecks/src/Microsoft.Extensions \\u2026 16 COPY src/BuildingBlocks\", \"/HealthChecks/src/Microsoft.Extensions \\u2026 17 RUN dotnet restore src/Services/Catalog/Catalog.API/Cata\", \"log.API.csproj 18 COPY . . 19 WORKDIR /src/src/Services/Catalog/Catalog.API 20 RUN dotnet build Cata\", \"log.API.csproj -c Release -o /app 21 22 FROM build AS publish 23 RUN dotnet publish Catalog.API.cspr\", \"oj -c Release -o /app 24 25 FROM base AS final 26 WORKDIR /app 27 COPY --from=publish /app . 28 ENTR\", \"YPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"]\\n```\\n\\nAnd these are the details, line by line:\\n\\n- Line #1: Begin\", \" a stage with a 'small' runtime -only base image, call it base for reference.\\n- Line #2: Create the \", \"/app directory in the image.\\n- Line #3: Expose port 80 .\\n\\n- Line #5: Begin a new stage with the 'lar\", \"ge' image for building/publishing. Call it build for reference.\\n- Line #6: Create directory /src in \", \"the image.\\n- Line #7: Up to line 16, copy referenced .csproj project files to be able to restore pac\", \"kages later.\\n- Line #17: Restore packages for the Catalog.API project and the referenced projects.\\n-\", \" Line #18: Copy all directory tree for the solution (except the files/directories included in the .d\", \"ockerignore file) to the /src directory in the image.\\n- Line #19: Change the current folder to the C\", \"atalog.API project.\\n- Line #20: Build the project (and other project dependencies) and output to the\", \" /app directory in the image.\\n- Line #22: Begin a new stage continuing from the build. Call it publi\", \"sh for reference.\\n- Line #23: Publish the project (and dependencies) and output to the /app director\", \"y in the image.\\n- Line #25: Begin a new stage continuing from base and call it final .\\n- Line #26: C\", \"hange the current directory to /app .\\n- Line #27: Copy the /app directory from stage publish to the \", \"current directory.\\n- Line #28: Define the command to run when the container is started.\\n\\nNow let's e\", \"xplore some optimizations to improve the whole process performance that, in the case of eShopOnConta\", \"iners, means about 22 minutes or more to build the complete solution in Linux containers.\\n\\nYou'll ta\", \"ke advantage of Docker's layer cache feature, which is quite simple: if the base image and the comma\", \"nds are the same as some previously executed, it can just use the resulting layer without the need t\", \"o execute the commands, thus saving some time.\\n\\nSo, let's focus on the build stage, lines 5-6 are mo\", \"stly the same, but lines 7-17 are different for every service from eShopOnContainers, so they have t\", \"o execute every single time, however if you changed lines 7-16 to:\\n\\n## COPY . .\\n\\nThen it would be ju\", \"st the same for every service, it would copy the whole solution and would create a larger layer but:\", \"\\n\\n1. The copy process would only be executed the first time (and when rebuilding if a file is change\", \"d) and would use the cache for all other services and\\n2. Since the larger image occurs in an interme\", \"diate stage, it doesn't affect the final image size.\\n\\nThe next significant optimization involves the\", \" restore command executed in line 17, which is also different for every service of eShopOnContainers\", \". If you change that line to just:\\n\\nRUN dotnet restore\\n\\nIt would restore the packages for the whole \", \"solution, but then again, it would do it just once, instead of the 15 times with the current strateg\", \"y.\\n\\nHowever, dotnet restore only runs if there's a single project or solution file in the folder, so\", \" achieving this is a bit more complicated and the way to solve it, without getting into too many det\", \"ails, is this:\\n\\n1. Add the following lines to .dockerignore :\\n2. -*.sln, to ignore all solution file\", \"s in the main folder tree\\n3. -!eShopOnContainers-ServicesAndWebApps.sln, to include only this soluti\", \"on file.\\n2. Include the /ignoreprojectextensions:.dcproj argument to dotnet restore, so it also igno\", \"res the docker-compose project and only restores the packages for the eShopOnContainersServicesAndWe\", \"bApps solution.\\n\\nFor the final optimization, it just happens that line 20 is redundant, as line 23 a\", \"lso builds the application and comes, in essence, right after line 20, so there goes another time-co\", \"nsuming command.\\n\\nThe resulting file is then:\\n\\n```\\n1 FROM mcr.microsoft.com/dotnet/aspnet:7.0 AS bas\", \"e 2 WORKDIR /app 3 EXPOSE 80 4 5 FROM mcr.microsoft.com/dotnet/sdk:7.0 AS publish 6 WORKDIR /src 7 C\", \"OPY . . 8 RUN dotnet restore /ignoreprojectextensions:.dcproj 9 WORKDIR /src/src/Services/Catalog/Ca\", \"talog.API 10 RUN dotnet publish Catalog.API.csproj -c Release -o /app 11 12 FROM base AS final 13 WO\", \"RKDIR /app 14 COPY --from=publish /app . 15 ENTRYPOINT [\\\"dotnet\\\", \\\"Catalog.API.dll\\\"]\\n```\\n\\n## Creatin\", \"g your base image from scratch\\n\\nYou can create your own Docker base image from scratch. This scenari\", \"o is not recommended for someone who is starting with Docker, but if you want to set the specific bi\", \"ts of your own base image, you can do so.\\n\\n## Additional resources\\n\\n- Multi-arch .NET Core images\\n- \", \".\\n\\nhttps://github.com/dotnet/announcements/issues/14\\n\\n3.\\n\\nStep 1 : FROM microsoft/dotnet: latest\\n\\nSe\", \"nding build context to Docker\\\\_daemon 1.148 MB\\n\\nlatest: Pulling from microsoft/dotnet\\n\\n5c90d4a2d1a8:\", \" Downloading\\n\\nCreate Images ab30c63719b1: Downloading\\n\\ndefined at c6072700a242: Downloading\\n\\nDockerf\", \"ile/s eb57cf4f29ee: Waiting\\n\\n121d7eef6c20: waiting b2c5ae2d325b: waiting\\n\\n- Create a base image . Of\", \"ficial Docker documentation. https://docs.docker.com/develop/develop-images/baseimages/\\n\\n<!-- image \", \"-->\\n\\n## Step 3. Create your custom Docker images and embed your application or service in them\\n\\nFor \", \"each service in your application, you need to create a related image. If your application is made up\", \" of a single service or web application, you just need a single image.\\n\\nNote that the Docker images \", \"are built automatically for you in Visual Studio. The following steps are only needed for the editor\", \"/CLI workflow and explained for clarity about what happens underneath.\\n\\nYou, as a developer, need to\", \" develop and test locally until you push a completed feature or change to your source control system\", \" (for example, to GitHub). This means that you need to create the Docker images and deploy container\", \"s to a local Docker host (Windows or Linux VM) and run, test, and debug against those local containe\", \"rs.\\n\\nTo create a custom image in your local environment by using Docker CLI and your Dockerfile, you\", \" can use the docker build command, as in Figure 5-5.\\n\\nFigure 5-5. Creating a custom Docker image\\n\\n<!\", \"-- image -->\\n\\nOptionally, instead of directly running docker build from the project folder, you can \", \"first generate a deployable folder with the required .NET libraries and binaries by running dotnet p\", \"ublish, and then use the docker build command.\\n\\nThis will create a Docker image with the name cesard\", \"l/netcore-webapi-microservice-docker:first. In this case, :first is a tag that represents a specific\", \" version. You can repeat this step for each custom image you need to create for your composed Docker\", \" application.\\n\\nWhen an application is made of multiple containers (that is, it is a multi-container \", \"application), you can also use the docker-compose up --build command to build all the related images\", \" with a single command by using the metadata exposed in the related docker-compose.yml files.\\n\\nYou c\", \"an find the existing images in your local repository by using the docker images command, as shown in\", \" Figure 5-6.\\n\\n===&gt;\\n\\n18.34 MB/51.35\\n\\n18.34 MB/42.53\\n\\n18.48 MB/18.55\\n\\nMB\\n\\nMB\\n\\nREPOSITORY\\n\\n4. (opt)\\n\", \"\\nmicrosoft/dotnet cesardl/netcore-webapi-microservice-docker\\n\\nubuntu\\n\\nDefine services hello-world\\n\\nb\", \"y writing docker-compose.yml\\n\\nTAG\\n\\nfirst latest\\n\\nlatest latest\\n\\nIMAGE ID\\n\\n384c4ac1809b\\n\\n49aaf5daa850\", \"\\n\\nc54a2cc56cbb cf62323 fa025\\n\\nCREATED\\n\\n30 hours ago\\n\\n4 minutes ago ago\\n\\n12 days ago\\n\\n5 days\\n\\nSIZE\\n\\n5\", \"48.6 MB\\n\\n579.8 MB\\n\\n125 MB\\n\\n1.848 kB\\n\\nFigure 5-6. Viewing existing images using the docker images com\", \"mand\\n\\n<!-- image -->\\n\\n## Creating Docker images with Visual Studio\\n\\nWhen you use Visual Studio to cr\", \"eate a project with Docker support, you don't explicitly create an image. Instead, the image is crea\", \"ted for you when you press F5 (or Ctrl+F5) to run the dockerized application or service. This step i\", \"s automatic in Visual St udio and you won't see it happen, but it's important that you know what's g\", \"oing on underneath.\\n\\n<!-- image -->\\n\\n## Step 4. Define your services in docker-compose.yml when buil\", \"ding a multi-container Docker application\\n\\nThe docker-compose.yml file lets you define a set of rela\", \"ted services to be deployed as a composed application with deployment commands. It also configures i\", \"ts dependency relations and runtime configuration.\\n\\nTo use a docker-compose.yml file, you need to cr\", \"eate the file in your main or root solution folder, with content similar to that in the following ex\", \"ample:\\n\\n```\\nversion : '3.4' services : webmvc : image : eshop/web environment : -CatalogUrl=http://c\", \"atalog-api -OrderingUrl=http://ordering-api ports : -\\\"80:80\\\" depends_on : -catalog-api -ordering-api\", \" catalog-api : image : eshop/catalog-api environment : -ConnectionString=Server=sqldata;Port=1433;Da\", \"tabase=CatalogDB;\\u2026 ports : -\\\"81:80\\\" depends_on : -sqldata ordering-api : image : eshop/ordering-api\\n\", \"```\\n\\n```\\nenvironment : -ConnectionString=Server=sqldata;Database=OrderingDb;\\u2026 ports : -\\\"82:80\\\" extra\", \"_hosts : -\\\"CESARDLBOOKVHD:10.0.75.1\\\" depends_on : -sqldata sqldata : image : mcr.microsoft.com/mssql\", \"/server:latest environment : -SA_PASSWORD=Pass@word -ACCEPT_EULA=Y ports : -\\\"5433:1433\\\"\\n```\\n\\nThis do\", \"cker-compose.yml file is a simplified and merged version. It contains static configuration data for \", \"each container (like the name of the custom image), which is always required, and configuration info\", \"rmation that might depend on the deployment environment, like the connection string. In later sectio\", \"ns, you will learn how to split the docker-compose.yml configuration into multiple dockercompose fil\", \"es and override values depending on the environment and execution type (debug or release).\\n\\nThe dock\", \"er-compose.yml file example defines four services: the webmvc service (a web application), two micro\", \"services (ordering-api and basket-api), and one data source container, sqldata, based on SQL Server \", \"for Linux running as a container. Each service will be deployed as a container, so a Docker image is\", \" required for each.\\n\\nThe docker-compose.yml file specifies not only what containers are being used, \", \"but how they are individually configured. For instance, the webmvc container definition in the .yml \", \"file:\\n\\n- Uses a pre-built eshop/web:latest image. However, you could also configure the image to be \", \"built as part of the docker-compose execution with an additional configuration based on a build: sec\", \"tion in the docker-compose file.\\n- Initializes two environment variables (CatalogUrl and OrderingUrl\", \").\\n- Forwards the exposed port 80 on the container to the external port 80 on the host machine.\\n- Li\", \"nks the web app to the catalog and ordering service with the depends\\\\_on setting. This causes the se\", \"rvice to wait until those services are started.\\n\\nWe will revisit the docker-compose.yml file in a la\", \"ter section when we cover how to implement microservices and multi-container apps.\\n\\n## Working with \", \"docker-compose.yml in Visual Studio 2022\\n\\nBesides adding a Dockerfile to a project, as we mentioned \", \"before, Visual Studio 2017 (from version 15.8 on) can add orchestrator support for Docker Compose to\", \" a solution.\\n\\nWhen you add container orchestrator support, as shown in Figure 5-7, for the first tim\", \"e, Visual Studio creates the Dockerfile for the project and creates a new (service section) project \", \"in your solution with\\n\\n1 E docker-compose\\n\\n\\u2022 .dockerignore\\n\\nNew Item...\\n\\nExisting Item...\\n\\nVi docker\", \"-compose.yml\\n\\nNew Scaffolded Item...\\n\\nCtrI+Shift+A\\n\\nShift+Alt+A\\n\\n\\u2022 docker-compose.override.yml\\n\\nNew \", \"Folder\\n\\n1\\n\\nAdd\\n\\nManage NuGet Package\\n\\nManage Client-Side Libraries...\\n\\nseveral global docker-compose\", \"*.yml files, and then adds the project to those files. You can then open the docker-compose.yml file\", \"s and update them with additional features.\\n\\nRepeat this operation for every project you want to inc\", \"lude in the docker-compose.yml file.\\n\\nCut\\n\\nCtrI+X\\n\\nAt the time of this writing, Visual Studio suppor\", \"ts Docker Compose orchestrators.\\n\\nClient-Side Library..\\n\\nNew Azure Weblob Project\\n\\nExisting Project \", \"as Azure WebJob\\n\\nReference...\\n\\nService Reference...\\n\\nConnected Service\\n\\nClass...\\n\\nFigure 5-7. Adding\", \" Docker support in Visual Studio 2022 by right-clicking an ASP.NET Core project\\n\\n<!-- image -->\\n\\nAft\", \"er you add orchestrator support to your solution in Visual Studio, you will also see a new node (in \", \"the docker-compose.dcproj project file) in Solution Explorer that contains the added dockercompose.y\", \"ml files, as shown in Figure 5-8.\\n\\nFigure 5-8. The docker-compose tree node added in Visual Studio 2\", \"022 Solution Explorer\\n\\n<!-- image -->\\n\\nYou could deploy a multi-container application with a single \", \"docker-compose.yml file by using the docker-compose up command. However, Visual Studio adds a group \", \"of them so you can override values depending on the environment (development or production) and exec\", \"ution type (release or debug). This capability will be explained in later sections.\\n\\nPS C: dev netco\", \"re-webapi-microservice-docker\\u00bb docker run -t -d i\\n\\nRun\\n\\n5.\\n\\nd96975a683b0a9411595816f63be6c135801878b\", \"8a85181a4d86dc848ea4ca6\\\"P 80:5000 cesardl/netcore-webapi-microservice-docker:first\\n\\nContainers /\\n\\nCo\", \"mpose app\\n\\n<!-- image -->\\n\\n## Step 5. Build and run your Docker application\\n\\nIf your application onl\", \"y has a single container, you can run it by deploying it to your Docker host (VM or physical server)\", \". However, if your application contains multiple services, you can deploy it as a composed applicati\", \"on, either using a single CLI command (docker-compose up), or with Visual Studio, which will use tha\", \"t command under the covers. Let's look at the different options.\\n\\n## Option A: Running a single-cont\", \"ainer application\\n\\n## Using Docker CLI\\n\\nYou can run a Docker container using the docker run command,\", \" as shown in Figure 5-9:\\n\\ndocker run -t -d -p 80:5000 cesardl/netcore-webapi-microservice-docker:fir\", \"st\\n\\nThe above command will create a new container instance from the specified image, every time it's\", \" run. You can use the --name parameter to give a name to the container and then use docker start {na\", \"me} (or use the container ID or automatic name) to run an existing container instance.\\n\\nFigure 5-9. \", \"Running a Docker container using the docker run command\\n\\nIn this case, the command binds the interna\", \"l port 5000 of the container to port 80 of the host machine. This means that the host is listening o\", \"n port 80 and forwarding to port 5000 on the container.\\n\\nThe hash shown is the container ID and it's\", \" also assigned a random readable name if the --name option is not used.\\n\\n## Using Visual Studio\\n\\nIf \", \"you haven't added container orchestrator support, you can also run a single container app in Visual \", \"Studio by pressing Ctrl+F5 and you can also use F5 to debug the application within the container. Th\", \"e container runs locally using docker run.\\n\\n## Option B: Running a multi-container application\\n\\nIn m\", \"ost enterprise scenarios, a Docker application will be composed of multiple services, which means yo\", \"u need to run a multi-container application, as shown in Figure 5-10.\\n\\nRecreating webapplication\\\\_we\", \"bapplication\\\\_1\\n\\nAttaching to webapplication\\\\_webapplication\\\\_1\\n\\nwebapplication\\\\_1\\n\\nwebapplication\\\\_\", \"1\\n\\nwebapplication\\\\_1\\n\\nVM\\n\\nhosting environment: Production\\n\\nContent root path: /app\\n\\nApplication star\", \"ted. Press Ctrl+C to shut down.\\n\\nNow listening on: http://*:80\\n\\nMy webapplication\\\\_1\\n\\n<!-- image -->\", \"\\n\\nContainer | Container 2\\n\\nFigure 5-10. VM with Docker containers deployed\\n\\n## Using Docker CLI\\n\\nTo \", \"run a multi-container application with the Docker CLI, you use the docker-compose up command. This c\", \"ommand uses the docker-compose.yml file that you have at the solution level to deploy a multi-contai\", \"ner application. Figure 5-11 shows the results when running the command from your main solution dire\", \"ctory, which contains the docker-compose.yml file.\\n\\nFigure 5-11. Example results when running the do\", \"cker-compose up command\\n\\n<!-- image -->\\n\\nAfter the docker-compose up command runs, the application a\", \"nd its related containers are deployed into your Docker host, as depicted in Figure 5-10.\\n\\n## Using \", \"Visual Studio\\n\\nRunning a multicontainer application using Visual Studio 2019 can't get any simpler. \", \"You just press Ctrl+F5 to run or F5 to debug, as usual, setting up the docker-compose project as the\", \" startup project. Visual Studio handles all needed setup, so you can create breakpoints as usual and\", \" debug what finally become independent processes running in 'remote servers', with the debugger alre\", \"ady attached, just like that.\\n\\nAs mentioned before, each time you add Docker solution support to a p\", \"roject within a solution, that project is configured in the global (solution-level) docker-compose.y\", \"ml file, which lets you run or debug the whole solution at once. Visual Studio will start one contai\", \"ner for each project that has Docker solution support enabled, and perform all the internal steps fo\", \"r you (dotnet publish, docker build, etc.).\\n\\nIf you want to take a peek at all the drudgery, take a \", \"look at the file:\\n\\n{root solution folder}\\\\obj\\\\Docker\\\\docker-compose.vs.debug.g.yml\\n\\nToolbo\\n\\nFILE EDI\", \"T VIEW PROJECT BUILD DEBUG\\n\\n\\u2022 -\\n\\nTEST\\n\\nANALYZE\\n\\n0 \\u2039 \\u2039\\n\\nTest\\n\\nC\\n\\nyour appor microservices\\n\\nDebug\\n\\nAny\", \" CPU\\n\\nB localhost/API/values docker-compose.yml \\u2192 \\u00d7 docker-compose.override.yml\\n\\n1 Mercian.\\n\\nThe imp\", \"ortant point here is that, as shown in Figure 5-12, in Visual Studio 2019 there is an additional Doc\", \"ker command for the F5 key action. This option lets you run or debug a multi-container application b\", \"y running all the containers that are defined in the docker-compose.yml files at the solution level.\", \" The ability to debug multiple-container solutions means that you can set several breakpoints, each \", \"breakpoint in a different project (container), and while debugging from Visual Studio you will stop \", \"at breakpoints defined in different projects and running on different containers.\\n\\nFigure 5-12. Runn\", \"ing multi-container apps in Visual Studio 2022\\n\\n<!-- image -->\\n\\n## Additional resources\\n\\n- Deploy an\", \" ASP.NET container to a remote Docker host\\n\\nhttps://learn.microsoft.com/visualstudio/containers/host\", \"ing-web-apps-in-docker\\n\\n## A note about testing and deploying with orchestrators\\n\\nThe docker-compose\", \" up and docker run commands (or running and debugging the containers in Visual Studio) are adequate \", \"for testing containers in your development environment. But you should not use this approach for pro\", \"duction deployments, where you should target orchestrators like Kubernetes or Service Fabric . If yo\", \"u're using Kubernetes, you have to use pods to organize containers and services to network them. You\", \" also use deployments to organize pod creation and modification.\\n\\n<!-- image -->\\n\\n## Step 6. Test yo\", \"ur Docker application using your local Docker host\\n\\nThis step will vary depending on what your appli\", \"cation is doing. In a simple .NET Web application that is deployed as a single container or service,\", \" you can access the service by opening a browser on the Docker host and navigating to that site, as \", \"shown in Figure 5-13. (If the configuration in the Dockerfile maps the container to a port on the ho\", \"st that is anything other than 80, include the host port in the URL.)\\n\\nFigure 5-13. Example of testi\", \"ng your Docker application locally using localhost\\n\\n<!-- image -->\\n\\nTOOLS\\n\\nEXTENSIONS\\n\\ndocker-compos\", \"e\\n\\nWINDOW HELP\\n\\nSearch (CtrI+Q)\\n\\n- \\u2022 Docker Compose\\n\\nStatusCode\\n\\nContent\\n\\nStatusDescription : oK\\n\\n: \", \"200\\n\\n: [\\\"Howdy!\\\", \\\"Cheers mate!\\\"]\\n\\nRaContent\\n\\n: HTTP/1.1 200 OK\\n\\nIf localhost is not pointing to the\", \" Docker host IP (by default, when using Docker CE, it should), to navigate to your service, use the \", \"IP address of your machine's network card.\\n\\nThis URL in the browser uses port 80 for the particular \", \"container example being discussed. However, internally the requests are being redirected to port 500\", \"0, because that was how it was deployed with the docker run command, as explained in a previous step\", \".\\n\\nYou can also test the application using curl from the terminal, as shown in Figure 5-14. In a Doc\", \"ker installation on Windows, the default Docker Host IP is always 10.0.75.1 in addition to your mach\", \"ine's actual IP address.\\n\\nFigure 5-14. Example of testing your Docker application locally using curl\", \"\\n\\n<!-- image -->\\n\\n## Testing and debugging containers with Visual Studio 2022\\n\\nWhen running and debu\", \"gging the containers with Visual Studio 2022, you can debug the .NET application in much the same wa\", \"y as you would when running without containers.\\n\\n## Testing and debugging without Visual Studio\\n\\nIf \", \"you're developing using the editor/CLI approach, debugging containers is more difficult and you'll p\", \"robably want to debug by generating traces.\\n\\n## Additional resources\\n\\n- Quickstart: Docker in Visual\", \" Studio. https://learn.microsoft.com/visualstudio/containers/container-tools\\n- Debugging apps in a l\", \"ocal Docker container https://learn.microsoft.com/visualstudio/containers/edit-and-refresh\\n\\n## Simpl\", \"ified workflow when developing containers with Visual Studio\\n\\nEffectively, the workflow when using V\", \"isual Studio is a lot simpler than if you use the editor/CLI approach. Most of the steps required by\", \" Docker related to the Dockerfile and docker-compose.yml files are hidden or simplified by Visual St\", \"udio, as shown in Figure 5-15.\\n\\nForms\\n\\nHeaders\\n\\nImages\\n\\nLinks\\n\\nInputFields\\n\\nParsedHtml\\n\\nVS developme\", \"nt workflow for Docker apps\\n\\n1.\\n\\nCode your app\\n\\ngit push\\n\\n5.\\n\\nPush or\\n\\nContinue developing\\n\\n2. (Once\", \")\\n\\nAdd Docker\\n\\nRun/Debug\\n\\nContainers /\\n\\n4.\\n\\nTest\\n\\n## support to projects Compose app your appor micr\", \"oservices\\n\\nMy\\n\\nContainers\\n\\nFigure 5-15. Simplified workflow when developing with Visual Studio\\n\\n<!--\", \" image -->\\n\\nIn addition, you need to perform step 2 (adding Docker support to your projects) just on\", \"ce. Therefore, the workflow is similar to your usual development tasks when using .NET for any other\", \" development. You need to know what is going on under the covers (the image build process, what base\", \" images you're using, deployment of containers, etc.) and sometimes you will also need to edit the D\", \"ockerfile or docker-compose.yml file to customize behaviors. But most of the work is greatly simplif\", \"ied by using Visual Studio, making you a lot more productive.\\n\\n## Using PowerShell commands in a Doc\", \"kerfile to set up Windows Containers\\n\\nWindows Containers allow you to convert your existing Windows \", \"applications into Docker images and deploy them with the same tools as the rest of the Docker ecosys\", \"tem. To use Windows Containers, you run PowerShell commands in the Dockerfile, as shown in the follo\", \"wing example:\\n\\n```\\nFROM mcr.microsoft.com/windows/servercore LABEL Description=\\\"IIS\\\" Vendor=\\\"Microso\", \"ft\\\" Version=\\\"10\\\" RUN powershell -Command Add-WindowsFeature Web-Server CMD [ \\\"ping\\\", \\\"localhost\\\", \\\"-\", \"t\\\" ]\\n```\\n\\nIn this case, we are using a Windows Server Core base image (the FROM setting) and install\", \"ing IIS with a PowerShell command (the RUN setting). In a similar way, you could also use PowerShell\", \" commands to set up additional components like ASP.NET 4.x, .NET Framework 4.6, or any other Windows\", \" software. For example, the following command in a Dockerfile sets up ASP.NET 4.5:\\n\\nRUN powershell a\", \"dd-windowsfeature web-asp-net45\\n\\n## Additional resources\\n\\n- aspnet-docker/Dockerfile. Example PowerS\", \"hell commands to run from dockerfiles to include Windows features.\\n\\nhttps://github.com/Microsoft/asp\", \"net-docker/blob/master/4.7.1-windowsservercoreltsc2016/runtime/Dockerfile\\n\\n## Designing and Developi\", \"ng Multi-Container and Microservice-Based .NET Applications\\n\\nDeveloping containerized microservice a\", \"pplications means you are building multi-container applications. However, a multi-container applicat\", \"ion could also be simpler -for example, a three-tier application -and might not be built using a mic\", \"roservice architecture.\\n\\nEarlier we raised the question 'Is Docker necessary when building a microse\", \"rvice architecture?' The answer is a clear no. Docker is an enabler and can provide significant bene\", \"fits, but containers and Docker are not a hard requirement for microservices. As an example, you cou\", \"ld create a microservices-based application with or without Docker when using Azure Service Fabric, \", \"which supports microservices running as simple processes or as Docker containers.\\n\\nHowever, if you k\", \"now how to design and develop a microservices-based application that is also based on Docker contain\", \"ers, you will be able to design and develop any other, simpler application model. For example, you m\", \"ight design a three-tier application that also requires a multi-container approach. Because of that,\", \" and because microservice architectures are an important trend within the container world, this sect\", \"ion focuses on a microservice architecture implementation using Docker containers.\\n\\n## Design a micr\", \"oservice-oriented application\\n\\nThis section focuses on developing a hypothetical server-side enterpr\", \"ise application.\\n\\n## Application specifications\\n\\nThe hypothetical application handles requests by ex\", \"ecuting business logic, accessing databases, and then returning HTML, JSON, or XML responses. We wil\", \"l say that the application must support various clients, including desktop browsers running Single P\", \"age Applications (SPAs), traditional web apps, mobile web apps, and native mobile apps. The applicat\", \"ion might also expose an API for third parties\\n\\nto consume. It should also be able to integrate its \", \"microservices or external applications asynchronously, so that approach will help resiliency of the \", \"microservices in the case of partial failures.\\n\\nThe application will consist of these types of compo\", \"nents:\\n\\n- Presentation components. These components are responsible for handling the UI and consumin\", \"g remote services.\\n- Domain or business logic. This component is the application's domain logic.\\n- D\", \"atabase access logic. This component consists of data access components responsible for accessing da\", \"tabases (SQL or NoSQL).\\n- Application integration logic. This component includes a messaging channel\", \", based on message brokers.\\n\\nThe application will require high scalability, while allowing its verti\", \"cal subsystems to scale out autonomously, because certain subsystems will require more scalability t\", \"han others.\\n\\nThe application must be able to be deployed in multiple infrastructure environments (mu\", \"ltiple public clouds and on-premises) and ideally should be cross-platform, able to move from Linux \", \"to Windows (or vice versa) easily.\\n\\n## Development team context\\n\\nWe also assume the following about \", \"the development process for the application:\\n\\n- You have multiple dev teams focusing on different bu\", \"siness areas of the application.\\n- New team members must become productive quickly, and the applicat\", \"ion must be easy to understand and modify.\\n- The application will have a long-term evolution and eve\", \"r-changing business rules.\\n- You need good long-term maintainability, which means having agility whe\", \"n implementing new changes in the future while being able to update multiple subsystems with minimum\", \" impact on the other subsystems.\\n- You want to practice continuous integration and continuous deploy\", \"ment of the application.\\n- You want to take advantage of emerging technologies (frameworks, programm\", \"ing languages, etc.) while evolving the application. You do not want to make full migrations of the \", \"application when moving to new technologies, because that would result in high costs and impact the \", \"predictability and stability of the application.\\n\\n## Choosing an architecture\\n\\nWhat should the appli\", \"cation deployment architecture be? The specifications for the application, along with the developmen\", \"t context, strongly suggest that you should architect the application by decomposing it into autonom\", \"ous subsystems in the form of collaborating microservices and containers, where a microservice is a \", \"container.\\n\\nIn this approach, each service (container) implements a set of cohesive and narrowly rel\", \"ated functions. For example, an application might consist of services such as the catalog service, o\", \"rdering service, basket service, user profile service, etc.\\n\\nMicroservices communicate using protoco\", \"ls such as HTTP (REST), but also asynchronously (for example, using AMQP) whenever possible, especia\", \"lly when propagating updates with integration events.\\n\\nMicroservices are developed and deployed as c\", \"ontainers independently of one another. This approach means that a development team can be developin\", \"g and deploying a certain microservice without impacting other subsystems.\\n\\nEach microservice has it\", \"s own database, allowing it to be fully decoupled from other microservices. When necessary, consiste\", \"ncy between databases from different microservices is achieved using application-level integration e\", \"vents (through a logical event bus), as handled in Command and Query Responsibility Segregation (CQR\", \"S). Because of that, the business constraints must embrace eventual consistency between the multiple\", \" microservices and related databases.\\n\\n## eShopOnContainers: A reference application for .NET and mi\", \"croservices deployed using containers\\n\\nSo that you can focus on the architecture and technologies in\", \"stead of thinking about a hypothetical business domain that you might not know, we have selected a w\", \"ell-known business domain -namely, a simplified e-commerce (e-shop) application that presents a cata\", \"log of products, takes orders from customers, verifies inventory, and performs other business functi\", \"ons. This container-based application source code is available in the eShopOnContainers GitHub repo.\", \"\\n\\nThe application consists of multiple subsystems, including several store UI front ends (a Web appl\", \"ication and a native mobile app), along with the back-end microservices and containers for all the r\", \"equired server-side operations with several API Gateways as consolidated entry points to the interna\", \"l microservices. Figure 6-1 shows the architecture of the reference application.\\n\\n\\u0433 -\\n\\nClient apps e\", \"Shop mobile app\\n\\nXamarin.Forms\\n\\nC#\\n\\nxPlat. OS:\\n\\niOS\\n\\nAndroid\\n\\nWindows eShop traditional Web app\\n\\nK\\n\\n\", \"eShop SPA Web app\\n\\nTypeScript/Angular 2\\n\\nIdentity microservice (STS+users)\\n\\n\\u2022\\n\\nSQL Server database\\n\\n\", \"Figure 6-1. The eShopOnContainers reference application architecture for development environment\\n\\n<!\", \"-- image -->\\n\\nThe above diagram shows that Mobile and SPA clients communicate to single API gateway \", \"endpoints, that then communicate to microservices. Traditional web clients communicate to MVC micros\", \"ervice, that communicates to microservices through the API gateway.\\n\\nHosting environment . In Figure\", \" 6-1, you see several containers deployed within a single Docker host. That would be the case when d\", \"eploying to a single Docker host with the docker-compose up command. However, if you are using an or\", \"chestrator or container cluster, each container could be running in a different host (node), and any\", \" node could be running any number of containers, as we explained earlier in the architecture section\", \".\\n\\nCommunication architecture . The eShopOnContainers application uses two communication types, depe\", \"nding on the kind of the functional action (queries versus updates and transactions):\\n\\n- Http client\", \"-to-microservice communication through API Gateways. This approach is used for queries and when acce\", \"pting update or transactional commands from the client apps. The approach using API Gateways is expl\", \"ained in detail in later sections.\\n- Asynchronous event-based communication. This communication occu\", \"rs through an event bus to propagate updates across microservices or to integrate with external appl\", \"ications. The event bus can be implemented with any messaging-broker infrastructure technology like \", \"RabbitMQ, or using higher-level (abstraction-level) service buses like Azure Service Bus, NServiceBu\", \"s, MassTransit, or Brighter.\\n\\nThe application is deployed as a set of microservices in the form of c\", \"ontainers. Client apps can communicate with those microservices running as containers through the pu\", \"blic URLs published by the API Gateways.\\n\\neShopOnContainers reference application\\n\\n(Development envi\", \"ronment architecture)\\n\\n-\\n\\n\\u2022 Docker Host\\n\\nAPI Gateways/BFF\\n\\n## Data sovereignty per microservice\\n\\nIn \", \"the sample application, each microservice owns its own database or data source, although all SQL Ser\", \"ver databases are deployed as a single container. This design decision was made only to make it easy\", \" for a developer to get the code from GitHub, clone it, and open it in Visual Studio or Visual Studi\", \"o Code. Or alternatively, it makes it easy to compile the custom Docker images using the .NET CLI an\", \"d the Docker CLI, and then deploy and run them in a Docker development environment. Either way, usin\", \"g containers for data sources lets developers build and deploy in a matter of minutes without having\", \" to provision an external database or any other data source with hard dependencies on infrastructure\", \" (cloud or on-premises).\\n\\nIn a real production environment, for high availability and for scalabilit\", \"y, the databases should be based on database servers in the cloud or on-premises, but not in contain\", \"ers.\\n\\nTherefore, the units of deployment for microservices (and even for databases in this applicati\", \"on) are Docker containers, and the reference application is a multi-container application that embra\", \"ces microservices principles.\\n\\n## Additional resources\\n\\n- eShopOnContainers GitHub repo. Source code\", \" for the reference application https://aka.ms/eShopOnContainers/\\n\\n## Benefits of a microservice-base\", \"d solution\\n\\nA microservice-based solution like this has many benefits:\\n\\nEach microservice is relativ\", \"ely small -easy to manage and evolve . Specifically:\\n\\n- It is easy for a developer to understand and\", \" get started quickly with good productivity.\\n- Containers start fast, which makes developers more pr\", \"oductive.\\n- An IDE like Visual Studio can load smaller projects fast, making developers productive.\\n\", \"- Each microservice can be designed, developed, and deployed independently of other microservices, w\", \"hich provide agility because it is easier to deploy new versions of microservices frequently.\\n\\nIt is\", \" possible to scale out individual areas of the application . For instance, the catalog service or th\", \"e basket service might need to be scaled out, but not the ordering process. A microservices infrastr\", \"ucture will be much more efficient with regard to the resources used when scaling out than a monolit\", \"hic architecture would be.\\n\\nYou can divide the development work between multiple teams . Each servic\", \"e can be owned by a single development team. Each team can manage, develop, deploy, and scale their \", \"service independently of the rest of the teams.\\n\\nIssues are more isolated . If there is an issue in \", \"one service, only that service is initially impacted (except when the wrong design is used, with dir\", \"ect dependencies between microservices), and other services can continue to handle requests. In cont\", \"rast, one malfunctioning component in a monolithic\\n\\ndeployment architecture can bring down the entir\", \"e system, especially when it involves resources, such as a memory leak. Additionally, when an issue \", \"in a microservice is resolved, you can deploy just the affected microservice without impacting the r\", \"est of the application.\\n\\nYou can use the latest technologies . Because you can start developing serv\", \"ices independently and run them side by side (thanks to containers and .NET), you can start using th\", \"e latest technologies and frameworks expediently instead of being stuck on an older stack or framewo\", \"rk for the whole application.\\n\\n## Downsides of a microservice-based solution\\n\\nA microservice-based s\", \"olution like this also has some drawbacks:\\n\\nDistributed application . Distributing the application a\", \"dds complexity for developers when they are designing and building the services. For example, develo\", \"pers must implement inter-service communication using protocols like HTTP or AMQP, which adds comple\", \"xity for testing and exception handling. It also adds latency to the system.\\n\\nDeployment complexity \", \". An application that has dozens of microservices types and needs high scalability (it needs to be a\", \"ble to create many instances per service and balance those services across many hosts) means a high \", \"degree of deployment complexity for IT operations and management. If you are not using a microservic\", \"e-oriented infrastructure (like an orchestrator and scheduler), that additional complexity can requi\", \"re far more development efforts than the business application itself.\\n\\nAtomic transactions . Atomic \", \"transactions between multiple microservices usually are not possible. The business requirements have\", \" to embrace eventual consistency between multiple microservices.\\n\\nIncreased global resource needs (t\", \"otal memory, drives, and network resources for all the servers or hosts). In many cases, when you re\", \"place a monolithic application with a microservices approach, the amount of initial global resources\", \" needed by the new microservice-based application will be larger than the infrastructure needs of th\", \"e original monolithic application. This approach is because the higher degree of granularity and dis\", \"tributed services requires more global resources. However, given the low cost of resources in genera\", \"l and the benefit of being able to scale out certain areas of the application compared to long-term \", \"costs when evolving monolithic applications, the increased use of resources is usually a good tradeo\", \"ff for large, long-term applications.\\n\\nIssues with direct client-to-microservice communication . Whe\", \"n the application is large, with dozens of microservices, there are challenges and limitations if th\", \"e application requires direct clientto-microservice communications. One problem is a potential misma\", \"tch between the needs of the client and the APIs exposed by each of the microservices. In certain ca\", \"ses, the client application might need to make many separate requests to compose the UI, which can b\", \"e inefficient over the Internet and would be impractical over a mobile network. Therefore, requests \", \"from the client application to the back-end system should be minimized.\\n\\nAnother problem with direct\", \" client-to-microservice communications is that some microservices might be using protocols that are \", \"not Web-friendly. One service might use a binary protocol, while another service might use AMQP mess\", \"aging. Those protocols are not firewall-friendly and are best used internally. Usually, an applicati\", \"on should use protocols such as HTTP and WebSockets for communication outside of the firewall.\\n\\nYet \", \"another drawback with this direct client-to-service approach is that it makes it difficult to refact\", \"or the contracts for those microservices. Over time developers might want to change how the system i\", \"s partitioned into services. For example, they might merge two services or split a service into two \", \"or more services. However, if clients communicate directly with the services, performing this kind o\", \"f refactoring can break compatibility with client apps.\\n\\nAs mentioned in the architecture section, w\", \"hen designing and building a complex application based on microservices, you might consider the use \", \"of multiple fine-grained API Gateways instead of the simpler direct client-to-microservice communica\", \"tion approach.\\n\\nPartitioning the microservices . Finally, no matter, which approach you take for you\", \"r microservice architecture, another challenge is deciding how to partition an end-to-end applicatio\", \"n into multiple microservices. As noted in the architecture section of the guide, there are several \", \"techniques and approaches you can take. Basically, you need to identify areas of the application tha\", \"t are decoupled from the other areas and that have a low number of hard dependencies. In many cases,\", \" this approach is aligned to partitioning services by use case. For example, in our e-shop applicati\", \"on, we have an ordering service that is responsible for all the business logic related to the order \", \"process. We also have the catalog service and the basket service that implement other capabilities. \", \"Ideally, each service should have only a small set of responsibilities. This approach is similar to \", \"the single responsibility principle (SRP) applied to classes, which states that a class should only \", \"have one reason to change. But in this case, it is about microservices, so the scope will be larger \", \"than a single class. Most of all, a microservice has to be autonomous, end to end, including respons\", \"ibility for its own data sources.\\n\\n## External versus internal architecture and design patterns\\n\\nThe\", \" external architecture is the microservice architecture composed by multiple services, following the\", \" principles described in the architecture section of this guide. However, depending on the nature of\", \" each microservice, and independently of high-level microservice architecture you choose, it is comm\", \"on and sometimes advisable to have different internal architectures, each based on different pattern\", \"s, for different microservices. The microservices can even use different technologies and programmin\", \"g languages. Figure 6-2 illustrates this diversity.\\n\\nExternal architecture per application\\n\\nBack end\", \"\\n\\n## Microservice 1\\n\\nFigure 6-2. External versus internal architecture and design\\n\\n<!-- image -->\\n\\nF\", \"or instance, in our eShopOnContainers sample, the catalog, basket, and user profile microservices ar\", \"e simple (basically, CRUD subsystems). Therefore, their internal architecture and design is straight\", \"forward. However, you might have other microservices, such as the ordering microservice, which is mo\", \"re complex and represents ever-changing business rules with a high degree of domain complexity. In c\", \"ases like these, you might want to implement more advanced patterns within a particular microservice\", \", like the ones defined with domain-driven design (DDD) approaches, as we are doing in the eShopOnCo\", \"ntainers ordering microservice. (We will review these DDD patterns in the section later that explain\", \"s the implementation of the eShopOnContainers ordering microservice.)\\n\\nAnother reason for a differen\", \"t technology per microservice might be the nature of each microservice. For example, it might be bet\", \"ter to use a functional programming language like F#, or even a language like R if you are targeting\", \" AI and machine learning domains, instead of a more object-oriented programming language like C#.\\n\\nT\", \"he bottom line is that each microservice can have a different internal architecture based on differe\", \"nt design patterns. Not all microservices should be implemented using advanced DDD patterns, because\", \" that would be over-engineering them. Similarly, complex microservices with ever-changing business l\", \"ogic should not be implemented as CRUD components, or you can end up with low-quality code.\\n\\n## The \", \"new world: multiple architectural patterns and polyglot microservices\\n\\nThere are many architectural \", \"patterns used by software architects and developers. The following are a few (mixing architecture st\", \"yles and architecture patterns):\\n\\n- Simple CRUD, single-tier, single-layer.\\n\\nClient apps\\n\\nMobile app\", \"\\n\\nSPA\\n\\nWeb app\\n\\nInternal architecture per microservice\\n\\nThe Multi-Architectural-Patterns and polyglo\", \"t microservices world\\n\\nMicroservice 1\\n\\nContainer\\n\\n\\u2022 ASP.NET Core\\n\\n\\u2022 Simple CRUD Design\\n\\nEntity Frame\", \"work Core\\n\\nMicroservice 4\\n\\nContainer\\n\\nNancyFX (.NET Core)\\n\\nSimple CRUD Design\\n\\nMassive\\n\\nMicroservice\", \" 7\\n\\nContainer\\n\\nPython\\n\\nContainer\\n\\nSQL Server database\\n\\n- Traditional N-Layered.\\n\\nDDD &amp; CQRS patt\", \"erns\\n\\n' Microservice 3\\n\\nContainer\\n\\n\\u2022\\n\\nASP.NET Core\\n\\nQueries projection\\n\\n- Domain-Driven Design N-lay\", \"ered.\\n\\nDocDB/MongoDB API\\n\\n- Clean Architecture (as used with eShopOnWeb)\\n- Command and Query Respons\", \"ibility Segregation (CQRS).\\n\\nASP.NET Core\\n\\n- Event-Driven Architecture (EDA).\\n\\n\\u2022 Simple CRUD Design\\n\", \"\\nYou can also build microservices with many technologies and languages, such as ASP.NET Core Web API\", \"s, NancyFx, ASP.NET Core SignalR (available with .NET Core 2 or later), F#, Node.js, Python, Java, C\", \"++, GoLang, and more. database Container\\n\\nJava\\n\\n\\u2022 ASP.NET Core\\n\\nThe important point is that no parti\", \"cular architecture pattern or style, nor any particular technology, is right for all situations. Fig\", \"ure 6-3 shows some approaches and technologies (although not in any particular order) that could be \", \"used in different microservices. \\u00b7 GoLang\\n\\n\\u2022 Hub for Real Time comm.\\n\\n\\u2022 i.e. Calculus focused\\n\\n## Co\", \"ntainer Container\\n\\n\\u2022 Stateless process\\n\\nFigure 6-3. Multi-architectural patterns and the polyglot mi\", \"croservices world\\n\\n<!-- image -->\\n\\nMulti-architectural pattern and polyglot microservices means you \", \"can mix and match languages and technologies to the needs of each microservice and still have them t\", \"alking to each other. As shown in Figure 6-3, in applications composed of many microservices (Bounde\", \"d Contexts in domain-driven design terminology, or simply 'subsystems' as autonomous microservices),\", \" you might implement each microservice in a different way. Each might have a different architecture \", \"pattern and use different languages and databas es depending on the application's nature, business r\", \"equirements, and priorities. In some cases, the microservices might be similar. But that is not usua\", \"lly the case, because each subsystem's context boundary and requirements are usually different.\\n\\n\\u2022 N\", \"ode.js\\n\\nMicroservice 2\\n\\nSQL Server database\\n\\n\\u2022 (}\\n\\nDocDB /\\n\\nMongoDB\\n\\n\\u2022 MySql\\n\\n\\u2022 database\\n\\nClient app\", \"s\\n\\nMobile app\\n\\nSPA\\n\\nWeb app\\n\\nBack end\\n\\nAPI Gateway\\n\\nMicroservice 1\\n\\nWeb AP!\\n\\nMicroservice 2\\n\\nWeb API\", \"\\n\\nSimple CRUD\\n\\nFor instance, for a simple CRUD maintenance application, it might not make sense to d\", \"esign and implement DDD patterns. But for your core domain or core business, you might need to apply\", \" more advanced patterns to tackle business complexity with ever-changing business rules.\\n\\nEspecially\", \" when you deal with large applications composed by multiple subsystems, you should not apply a singl\", \"e top-level architecture based on a single architecture pattern. For instance, CQRS should not be ap\", \"plied as a top-level architecture for a whole application, but might be useful for a specific set of\", \" services.\\n\\nThere is no silver bullet or a right architecture pattern for every given case. You cann\", \"ot have 'one architecture pattern to rule them all.' Depending on the priorities of each microservic\", \"e, you must choose a different approach for each, as explained in the following sections.\\n\\n## Creati\", \"ng a simple data-driven CRUD microservice\\n\\nThis section outlines how to create a simple microservice\", \" that performs create, read, update, and delete (CRUD) operations on a data source.\\n\\n## Designing a \", \"simple CRUD microservice\\n\\nFrom a design point of view, this type of containerized microservice is ve\", \"ry simple. Perhaps the problem to solve is simple, or perhaps the implementation is only a proof of \", \"concept.\\n\\nFigure 6-4. Internal design for simple CRUD microservices\\n\\n<!-- image -->\\n\\nAn example of t\", \"his kind of simple data-drive service is the catalog microservice from the eShopOnContainers sample \", \"application. This type of service implements all its functionality in a single ASP.NET Core Web API \", \"project that includes classes for its data model, its business logic, and its data access code. It a\", \"lso stores its related data in a database running in SQL Server (as another container for dev/test p\", \"urposes), but could also be any regular SQL Server host, as shown in Figure 6-5.\\n\\nData-Driven/CRUD m\", \"icroservice container\\n\\nDocker Host\\n\\n## Logical \\\"Catalog\\\" Microservice \\\"Catalog\\\" API\\n\\nFigure 6-5. Sim\", \"ple data-driven/CRUD microservice design\\n\\n<!-- image -->\\n\\nThe previous diagram shows the logical Cat\", \"alog microservice, that includes its Catalog database, which can be or not in the same Docker host. \", \"Having the database in the same Docker host might be good for development, but not for production. W\", \"hen you are developing this kind of service, you only need ASP.NET Core and a data-access API or ORM\", \" like Entity Framework Core. You could also generate Swagger metadata automatically through Swashbuc\", \"kle to provide a description of what your service offers, as explained in the next section.\\n\\nNote th\", \"at running a database server like SQL Server within a Docker container is great for development envi\", \"ronments, because you can have all your dependencies up and running without needing to provision a d\", \"atabase in the cloud or on-premises. This approach is convenient when running integration tests. How\", \"ever, for production environments, running a database server in a container is not recommended, beca\", \"use you usually do not get high availability with that approach. For a production environment in Azu\", \"re, it is recommended that you use Azure SQL DB or any other database technology that can provide hi\", \"gh availability and high scalability. For example, for a NoSQL approach, you might choose CosmosDB.\\n\", \"\\nFinally, by editing the Dockerfile and docker-compose.yml metadata files, you can configure how the\", \" image of this container will be created -what base image it will use, plus design settings such as \", \"internal and external names and TCP ports.\\n\\n## Implementing a simple CRUD microservice with ASP.NET \", \"Core\\n\\nTo implement a simple CRUD microservice using .NET and Visual Studio, you start by creating a \", \"simple ASP.NET Core Web API project (running on .NET so it can run on a Linux Docker host), as shown\", \" in Figure 6-6.\\n\\nExternal IP, and Port\\n\\nCreate a new project\\n\\nRecent project templates\\n\\nASP.NET Core\", \" Web Application\\n\\n\\u2022 Windows Forms App (.NET)\\n\\n0 gRPC Service\\n\\nConsole App (.NET Core)\\n\\nxUnit Test Pr\", \"oject (.NET Core)\\n\\n&amp; Class Library (.NET Core)\\n\\nSearch for templates (Alt+S)\\n\\nAll languages\\n\\nAll\", \" platforms\\n\\nASP.NET Core Web Application\\n\\nProject templates for creating ASP.NET Core web apps and w\", \"eb APls for Windows, Linux and macOS using .NET Core or.NET Framework. Create web apps with\\n\\nRazor D\", \"anac MVC or Sinnla Dana Anne /SDA)ncinn Annular React or React + Radi\\n\\nFigure 6-6. Creating an ASP.N\", \"ET Core Web API project in Visual Studio 2019\\n\\n<!-- image -->\\n\\nTo create an ASP.NET Core Web API Pro\", \"ject, first select an ASP.NET Core Web Application and then select the API type. After creating the \", \"project, you can implement your MVC controllers as you would in any other Web API project, using the\", \" Entity Framework API or other API. In a new Web API project, you can see that the only dependency y\", \"ou have in that microservice is on ASP.NET Core itself. Internally, within the Microsoft.AspNetCore.\", \"All dependency, it is referencing Entity Framework and many other .NET NuGet packages, as shown in F\", \"igure 6-7.\\n\\nP-\\n\\nAll project types\\n\\nCatalog.API\\n\\nC Connected Services\\n\\n#* Dependencies\\n\\nAnalyzers\\n\\nFr\", \"ameworks\\n\\nFigure 6-7. Dependencies in a simple CRUD Web API microservice\\n\\n<!-- image -->\\n\\nThe API pr\", \"oject includes references to Microsoft.AspNetCore.App NuGet package, that includes references to all\", \" essential packages. It could include some other packages as well.\\n\\n## Implementing CRUD Web API ser\", \"vices with Entity Framework Core\\n\\nEntity Framework (EF) Core is a lightweight, extensible, and cross\", \"-platform version of the popular Entity Framework data access technology. EF Core is an object-relat\", \"ional mapper (ORM) that enables .NET developers to work with a database using .NET objects.\\n\\nThe cat\", \"alog microservice uses EF and the SQL Server provider because its database is running in a container\", \" with the SQL Server for Linux Docker image. However, the database could be deployed into\\n\\nany SQL S\", \"erver, such as Windows on-premises or Azure SQL DB. The only thing you would need to change is the c\", \"onnection string in the ASP.NET Web API microservice.\\n\\n## The data model\\n\\nWith EF Core, data access \", \"is performed by using a model. A model is made up of (domain model) entity classes and a derived con\", \"text (DbContext) that represents a session with the database, allowing you to query and save data. Y\", \"ou can generate a model from an existing database, manually code a model to match your database, or \", \"use EF migrations technique to create a database from your model, using the code-first approach (tha\", \"t makes it easy to evolve the database as your model changes over time). For the catalog microservic\", \"e, the last approach has been used. You can see an example of the CatalogItem entity class in the fo\", \"llowing code example, which is a simple Plain Old Class Object (POCO) entity class.\\n\\n```\\npublic clas\", \"s CatalogItem { public int Id { get ; set ; } public string Name { get ; set ; } public string Descr\", \"iption { get ; set ; } public decimal Price { get ; set ; } public string PictureFileName { get ; se\", \"t ; } public string PictureUri { get ; set ; } public int CatalogTypeId { get ; set ; } public Catal\", \"ogType CatalogType { get ; set ; } public int CatalogBrandId { get ; set ; } public CatalogBrand Cat\", \"alogBrand { get ; set ; } public int AvailableStock { get ; set ; } public int RestockThreshold { ge\", \"t ; set ; } public int MaxStockThreshold { get ; set ; } public bool OnReorder { get ; set ; } publi\", \"c CatalogItem() { } // Additional code ... }\\n```\\n\\nYou also need a DbContext that represents a sessio\", \"n with the database. For the catalog microservice, the CatalogContext class derives from the DbConte\", \"xt base class, as shown in the following example:\\n\\n```\\npublic class CatalogContext : DbContext { pub\", \"lic CatalogContext(DbContextOptions<CatalogContext> options) : base (options) { } public DbSet<Catal\", \"ogItem> CatalogItems { get ; set ; } public DbSet<CatalogBrand> CatalogBrands { get ; set ; } public\", \" DbSet<CatalogType> CatalogTypes { get ; set ; } // Additional code ... }\\n```\\n\\nYou can have addition\", \"al DbContext implementations. For example, in the sample Catalog.API microservice, there's a second \", \"DbContext named CatalogContextSeed where it automatically populates the sample data the first time i\", \"t tries to access the database. This method is useful for demo data and for automated testing scenar\", \"ios, as well.\\n\\nWithin the DbContext, you use the OnModelCreating method to customize object/database\", \" entity mappings and other EF extensibility points.\\n\\n## Querying data from Web API controllers\\n\\nInst\", \"ances of your entity classes are typically retrieved from the database using Language-Integrated Que\", \"ry (LINQ), as shown in the following example:\\n\\n```\\n[Route(\\\"api/v1/[controller]\\\")] public class Catal\", \"ogController : ControllerBase { private readonly CatalogContext _catalogContext; private readonly Ca\", \"talogSettings _settings; private readonly ICatalogIntegrationEventService _catalogIntegrationEventSe\", \"rvice; public CatalogController( CatalogContext context, IOptionsSnapshot<CatalogSettings> settings,\", \" ICatalogIntegrationEventService catalogIntegrationEventService) { _catalogContext = context ?? thro\", \"w new ArgumentNullException(nameof(context)); _catalogIntegrationEventService = catalogIntegrationEv\", \"entService ?? throw new ArgumentNullException(nameof(catalogIntegrationEventService)); _settings = s\", \"ettings.Value; context.ChangeTracker.QueryTrackingBehavior = QueryTrackingBehavior.NoTracking; } // \", \"GET api/v1/[controller]/items[?pageSize=3&pageIndex=10] [HttpGet] [Route(\\\"items\\\")] [ProducesResponse\", \"Type( typeof (PaginatedItemsViewModel<CatalogItem>), (int)HttpStatusCode.OK)] [ProducesResponseType(\", \" typeof (IEnumerable<CatalogItem>), (int)HttpStatusCode.OK)] [ProducesResponseType((int)HttpStatusCo\", \"de.BadRequest)] public async Task<IActionResult> ItemsAsync( [FromQuery]int pageSize = 10, [FromQuer\", \"y]int pageIndex = 0, string ids = null ) { if (!string.IsNullOrEmpty(ids)) { var items = await GetIt\", \"emsByIdsAsync(ids); if (!items.Any()) { return BadRequest(\\\"ids value invalid. Must be comma-separate\", \"d list of numbers\\\"); } return Ok(items); } var totalItems = await _catalogContext.CatalogItems .Long\", \"CountAsync(); var itemsOnPage = await _catalogContext.CatalogItems .OrderBy(c => c.Name) .Skip(pageS\", \"ize * pageIndex)\\n```\\n\\n```\\n.Take(pageSize) .ToListAsync(); itemsOnPage = ChangeUriPlaceholder(itemsOn\", \"Page); var model = new PaginatedItemsViewModel<CatalogItem>( pageIndex, pageSize, totalItems, itemsO\", \"nPage); return Ok(model); } //... }\\n```\\n\\n## Saving data\\n\\nData is created, deleted, and modified in t\", \"he database using instances of your entity classes. You could add code like the following hard-coded\", \" example (mock data, in this case) to your Web API controllers.\\n\\n```\\nvar catalogItem = new CatalogIt\", \"em() {CatalogTypeId=2, CatalogBrandId=2, Name=\\\"Roslyn T-Shirt\\\", Price = 12}; _context.Catalog.Add(ca\", \"talogItem); _context.SaveChanges();\\n```\\n\\n## Dependency Injection in ASP.NET Core and Web API control\", \"lers\\n\\nIn ASP.NET Core, you can use Dependency Injection (DI) out of the box. You do not need to set \", \"up a third-party Inversion of Control (IoC) container, although you can plug your preferred IoC cont\", \"ainer into the ASP.NET Core infrastructure if you want. In this case, it means that you can directly\", \" inject the required EF DBContext or additional repositories through the controller constructor.\\n\\nIn\", \" the CatalogController class mentioned earlier, CatalogContext (which inherits from DbContext) type \", \"is injected along with the other required objects in the CatalogController() constructor.\\n\\nAn import\", \"ant configuration to set up in the Web API project is the DbContext class registration into the serv\", \"ice's IoC container. You typically do so in the Program.cs file by calling the builder.Services.AddD\", \"bContext&lt;CatalogContext&gt;() method, as shown in the following simplified example:\\n\\n```\\n// Addit\", \"ional code... builder.Services.AddDbContext<CatalogContext>(options => { options.UseSqlServer(builde\", \"r.Configuration[\\\"ConnectionString\\\"], sqlServerOptionsAction: sqlOptions => { sqlOptions.MigrationsAs\", \"sembly( typeof (Program).GetTypeInfo().Assembly.GetName().Name); //Configuring Connection Resiliency\", \": sqlOptions. EnableRetryOnFailure(maxRetryCount: 5, maxRetryDelay: TimeSpan.FromSeconds(30), errorN\", \"umbersToAdd: null ); });\\n```\\n\\n```\\n// Changing default behavior when client evaluation occurs to thro\", \"w. // Default in EFCore would be to log warning when client evaluation is done. options.ConfigureWar\", \"nings(warnings => warnings.Throw( RelationalEventId.QueryClientEvaluationWarning)); });\\n```\\n\\n## Addi\", \"tional resources\\n\\n- \\u2022\\n- Querying Data https://learn.microsoft.com/ef/core/querying/index\\n- \\u2022\\n- Savin\", \"g Data https://learn.microsoft.com/ef/core/saving/index\\n\\n## The DB connection string and environment\", \" variables used by Docker containers\\n\\nYou can use the ASP.NET Core settings and add a ConnectionStri\", \"ng property to your settings.json file as shown in the following example:\\n\\n```\\n{ \\\"ConnectionString\\\":\", \" \\\"Server=tcp:127.0.0.1,5433;Initial Catalog=Microsoft.eShopOnContainers.Services.CatalogDb;User Id=s\", \"a;Password=[PLACEHOLDER]\\\", \\\"ExternalCatalogBaseUrl\\\": \\\"http://host.docker.internal:5101\\\", \\\"Logging\\\": \", \"{ \\\"IncludeScopes\\\": false , \\\"LogLevel\\\": { \\\"Default\\\": \\\"Debug\\\", \\\"System\\\": \\\"Information\\\", \\\"Microsoft\\\": \\\"\", \"Information\\\" } } }\\n```\\n\\nThe settings.json file can have default values for the ConnectionString prop\", \"erty or for any other property. However, those properties will be overridden by the values of enviro\", \"nment variables that you specify in the docker-compose.override.yml file, when using Docker.\\n\\nFrom y\", \"our docker-compose.yml or docker-compose.override.yml files, you can initialize those environment va\", \"riables so that Docker will set them up as OS environment variables for you, as shown in the followi\", \"ng docker-compose.override.yml file (the connection string and other lines wrap in this example, but\", \" it would not wrap in your own file).\\n\\n```\\n# docker-compose.override.yml # catalog-api : environment\", \" : -ConnectionString=Server=sqldata;Database=Microsoft.eShopOnContainers.Services.CatalogDb;Use r Id\", \"=sa;Password=[PLACEHOLDER] # Additional environment variables for this service ports : -\\\"5101:80\\\"\\n``\", \"`\\n\\nThe docker-compose.yml files at the solution level are not only more flexible than configuration \", \"files at the project or microservice level, but also more secure if you override the environment var\", \"iables declared at the docker-compose files with values set from your deployment tools, like from Az\", \"ure DevOps Services Docker deployment tasks.\\n\\nFinally, you can get that value from your code by usin\", \"g builder.Configuration\\\\[\\\"ConnectionString\\\"\\\\], as shown in an earlier code example.\\n\\nHowever, for pr\", \"oduction environments, you might want to explore additional ways on how to store secrets like the co\", \"nnection strings. An excellent way to manage application secrets is using Azure Key Vault.\\n\\nAzure Ke\", \"y Vault helps to store and safeguard cryptographic keys and secrets used by your cloud applications \", \"and services. A secret is anything you want to keep strict control of, like API keys, connection str\", \"ings, passwords, etc. and strict control includes usage logging, setting expiration, managing access\", \", among others .\\n\\nAzure Key Vault allows a detailed control level of the application secrets usage w\", \"ithout the need to let anyone know them. The secrets can even be rotated for enhanced security witho\", \"ut disrupting development or operations.\\n\\nApplications have to be registered in the organization's A\", \"ctive Directory, so they can use the Key Vault.\\n\\nYou can check the Key Vault Concepts documentation \", \"for more details.\\n\\n## Implementing versioning in ASP.NET Web APIs\\n\\nAs business requirements change, \", \"new collections of resources may be added, the relationships between resources might change, and the\", \" structure of the data in resources might be amended. Updating a Web API to handle new requirements \", \"is a relatively straightforward process, but you must consider the effects that such changes will ha\", \"ve on client applications consuming the Web API. Although the developer designing and implementing a\", \" Web API has full control over that API, the developer does not have the same degree of control over\", \" client applications that might be built by third-party organizations operating remotely.\\n\\nVersionin\", \"g enables a Web API to indicate the features and resources that it exposes. A client application can\", \" then submit requests to a specific version of a feature or resource. There are several approaches t\", \"o implement versioning:\\n\\n- URI versioning\\n- Query string versioning\\n- Header versioning\\n\\nQuery strin\", \"g and URI versioning are the simplest to implement. Header versioning is a good approach. However, h\", \"eader versioning is not as explicit and straightforward as URI versioning. Because URL versioning is\", \" the simplest and most explicit, the eShopOnContainers sample application uses URI versioning.\\n\\nWith\", \" URI versioning, as in the eShopOnContainers sample application, each time you modify the Web API or\", \" change the schema of resources, you add a version number to the URI for each resource. Existing URI\", \"s should continue to operate as before, returning resources that conform to the schema that matches \", \"the requested version.\\n\\nAs shown in the following code example, the version can be set by using the \", \"Route attribute in the Web API controller, which makes the version explicit in the URI (v1 in this c\", \"ase).\\n\\n```\\n[Route(\\\"api/v1/[controller]\\\")] public class CatalogController : ControllerBase { // Imple\", \"mentation ...\\n```\\n\\nThis versioning mechanism is simple and depends on the server routing the request\", \" to the appropriate endpoint. However, for a more sophisticated versioning and the best method when \", \"using REST, you should use hypermedia and implement HATEOAS (Hypertext as the Engine of Application \", \"State).\\n\\n## Additional resources\\n\\n- ASP.NET API Versioning https://github.com/dotnet/aspnet-api-vers\", \"ioning\\n- Scott Hanselman. ASP.NET Core RESTful Web API versioning made easy https://www.hanselman.co\", \"m/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx\\n- Versioning a RESTful web API https://learn.m\", \"icrosoft.com/azure/architecture/best-practices/api-design#versioning-arestful-web-api\\n- Roy Fielding\", \". Versioning, Hypermedia, and REST https://www.infoq.com/articles/roy-fielding-on-versioning\\n\\n## Gen\", \"erating Swagger description metadata from your ASP.NET Core Web API\\n\\nSwagger is a commonly used open\", \" source framework backed by a large ecosystem of tools that helps you design, build, document, and c\", \"onsume your RESTful APIs. It is becoming the standard for the APIs description metadata domain. You \", \"should include Swagger description metadata with any kind of microservice, either data-driven micros\", \"ervices or more advanced domain-driven microservices (as explained in the following section).\\n\\nThe h\", \"eart of Swagger is the Swagger specification, which is API description metadata in a JSON or YAML fi\", \"le. The specification creates the RESTful contract for your API, detailing all its resources and ope\", \"rations in both a human- and machine-readable format for easy development, discovery, and integratio\", \"n.\\n\\nThe specification is the basis of the OpenAPI Specification (OAS) and is developed in an open, t\", \"ransparent, and collaborative community to standardize the way RESTful interfaces are defined.\\n\\nThe \", \"specification defines the structure for how a service can be discovered and how its capabilities und\", \"erstood. For more information, including a web editor and examples of Swagger specifications from co\", \"mpanies like Spotify, Uber, Slack, and Microsoft, see the Swagger site (https://swagger.io).\\n\\n## Why\", \" use Swagger?\\n\\nThe main reasons to generate Swagger metadata for your APIs are the following.\\n\\nAbili\", \"ty for other products to automatically consume and integrate your APIs . Dozens of products and comm\", \"ercial tools and many libraries and frameworks support Swagger. Microsoft has high-level products an\", \"d tools that can automatically consume Swagger-based APIs, such as the following:\\n\\n- AutoRest. You c\", \"an automatically generate .NET client classes for calling Swagger. This tool can be used from the CL\", \"I and it also integrates with Visual Studio for easy use through the GUI.\\n- Microsoft Flow. You can \", \"automatically use and integrate your API into a high-level Microsoft Flow workflow, with no programm\", \"ing skills required.\\n- Microsoft PowerApps. You can automatically consume your API from PowerApps mo\", \"bile apps built with PowerApps Studio, with no programming skills required.\\n- Azure App Service Logi\", \"c Apps. You can automatically use and integrate your API into an Azure App Service Logic App, with n\", \"o programming skills required.\\n\\nAbility to automatically generate API documentation . When you creat\", \"e large-scale RESTful APIs, such as complex microservice-based applications, you need to handle many\", \" endpoints with different data models used in the request and response payloads. Having proper docum\", \"entation and having a solid API explorer, as you get with Swagger, is key for the success of your AP\", \"I and adoption by developers.\\n\\nSwagger's metadata is what Microsoft Flow, PowerApps, and Azure Logic\", \" Apps use to understand how to use APIs and connect to them.\\n\\nThere are several options to automate \", \"Swagger metadata generation for ASP.NET Core REST API applications, in the form of functional API he\", \"lp pages, based on swagger-ui .\\n\\nProbably the best know is Swashbuckle, which is currently used in e\", \"ShopOnContainers and we'll cover in some detail in this guide but there's also the option to use NSw\", \"ag, which can generate Typescript and C# API clients, as well as C# controllers, from a Swagger or O\", \"penAPI specification and even by scanning the .dll that contains the controllers, using NSwagStudio.\", \"\\n\\n## How to automate API Swagger metadata generation with the Swashbuckle NuGet package\\n\\nGenerating \", \"Swagger metadata manually (in a JSON or YAML file) can be tedious work. However, you can automate AP\", \"I discovery of ASP.NET Web API services by using the Swashbuckle NuGet package to dynamically genera\", \"te Swagger API metadata.\\n\\nSwashbuckle automatically generates Swagger metadata for your ASP.NET Web \", \"API projects. It supports ASP.NET Core Web API projects and the traditional ASP.NET Web API and any \", \"other flavor,\\n\\n\\u2022 \\u2022 Swagger UI\\n\\n+\\n\\nA Not secure I hot docker intermal:101/wager/nde.tml\\n\\n6) Swagger.\\n\", \"\\nwindly SMARTBEAR\\n\\nServers\\n\\n/catalog-api v\\n\\nCatalog\\n\\nSelect a definition\\n\\nCatalog.AP| V1\\n\\nsuch as Az\", \"ure API App, Azure Mobile App, Azure Service Fabric microservices based on ASP.NET. It also supports\", \" plain Web API deployed on containers, as in for the reference application.\\n\\nSwashbuckle combines AP\", \"I Explorer and Swagger or swagger-ui to provide a rich discovery and documentation experience for yo\", \"ur API consumers. In addition to its Swagger metadata generator engine, Swashbuckle also contains an\", \" embedded version of swagger-ui, which it will automatically serve up once Swashbuckle is installed.\", \"\\n\\nGET\\n\\nPUT\\n\\nPOST\\n\\n/api/v1/Catalog/items\\n\\nV\\n\\nThis means you can complement your API with a nice disco\", \"very UI to help developers to use your API. It requires a small amount of code and maintenance becau\", \"se it is automatically generated, allowing you to focus on building your API. The result for the API\", \" Explorer looks like Figure 6-8.\\n\\nGET /api/v1/Catalog/items/{id}\\n\\nGET\\n\\n/api/v1/Catalog/items/withnam\", \"e/{name}\\n\\nFigure 6-8. Swashbuckle API Explorer based on Swagger metadata -eShopOnContainers catalog \", \"microservice\\n\\n<!-- image -->\\n\\nThe Swashbuckle generated Swagger UI API documentation includes all pu\", \"blished actions. The API explorer is not the most important thing here. Once you have a Web API that\", \" can describe itself in Swagger metadata, your API can be used seamlessly from Swagger-based tools, \", \"including client proxy-class code generators that can target many platforms. For example, as mention\", \"ed, AutoRest automatically generates .NET client classes. But additional tools like swagger-codegen \", \"are also available, which allow code generation of API client libraries, server stubs, and documenta\", \"tion automatically.\\n\\nCurrently, Swashbuckle consists of five internal NuGet packages under the high-\", \"level metapackage Swashbuckle.AspNetCore for ASP.NET Core applications.\\n\\nAfter you have installed th\", \"ese NuGet packages in your Web API project, you need to configure Swagger in the Program.cs class, a\", \"s in the following simplified code:\\n\\n```\\n// Add framework services. builder.Services.AddSwaggerGen(o\", \"ptions => {\\n```\\n\\nInPrivate g\\n\\n```\\noptions.DescribeAllEnumsAsStrings(); options.SwaggerDoc(\\\"v1\\\", new \", \"OpenApiInfo { Title = \\\"eShopOnContainers - Catalog HTTP API\\\", Version = \\\"v1\\\", Description = \\\"The Cat\", \"alog Microservice HTTP API. This is a Data-Driven/CRUD microservice sample\\\" }); }); // Other startup\", \" code... app.UseSwagger() .UseSwaggerUI(c => { c.SwaggerEndpoint(\\\"/swagger/v1/swagger.json\\\", \\\"My API\", \" V1\\\"); }); ``` ::: Once this is done, you can start your application and browse the following Swagge\", \"r JSON and UI endpoints using URLs like these: :::{custom-style=CodeBox} ```console http://<your-roo\", \"t-url>/swagger/v1/swagger.json http://<your-root-url>/swagger/\\n```\\n\\nYou previously saw the generated\", \" UI created by Swashbuckle for a URL like http://&lt;your-rooturl&gt;/swagger. In Figure 6-9, you ca\", \"n also see how you can test any API method.\\n\\n&lt; \\u2192\\n\\nCatalog\\n\\nGET\\n\\nParameters\\n\\nName pageSize\\n\\nintege\", \"r\\n\\n(query)\\n\\nids string\\n\\n(query)\\n\\nResponses\\n\\nCurl curl -X GET \\\"http://localhost:5101/spi/v1/Catalog/i\", \"tens?pogeSize=12&amp;pogeIndex=0\\\" -H \\\"accept: text/plain\\\"\\n\\nRequest URL\\n\\nhttp://locelhost:5101/spi/v1\", \"/Catalog/itens7pageSize=12&amp;pageIndex=0\\n\\nServer response\\n\\nCode\\n\\n200\\n\\nSwagger Ul\\n\\n\\u00d7 + V\\n\\nlocalhost\", \":5101/swagger/|\\n\\n/api/v1/Catalog/items\\n\\n-\\n\\nV\\n\\nFigure 6-9. Swashbuckle UI testing the Catalog/Items A\", \"PI method\\n\\n<!-- image -->\\n\\nThe Swagger UI API detail shows a sample of the response and can be used \", \"to execute the real API, which is great for developer discovery. Figure 6-10 shows the Swagger JSON \", \"metadata generated from the eShopOnContainers microservice (which is what the tools use underneath) \", \"when you request http://&lt;your-root-url&gt;/swagger/v1/swagger.json using Postman.\\n\\nX\\n\\nRunner\\n\\nFil\", \"ter\\n\\nHistory\\n\\nCollections\\n\\nToday\\n\\nGET http://localhost:5101/swagger/v1/swagl ger.json\\n\\nNovember 8\\n\\nG\", \"ET http://10.120.158.69:8740/api/vehicle s/?tenantid=CDLTLL\\n\\nGET http://10.106.144.95:8740/api/vehic\", \"le s/?tenantid=CDLTLL|\\n\\nGET http://myworld-cluster.westus.cloudap p.azure.com:8740/api/vehicles/?ten\", \"ant\\n\\nid=CDLTLL|\\n\\nNovember 6\\n\\nGET http://myworld-cluster.westus.cloudap p.azure.com:8740/api/vehicles\", \"/\\n\\nSYNC OFF\\n\\nNo Environment\\n\\nParams\\n\\nSave\\n\\nFigure 6-10. Swagger JSON metadata\\n\\n<!-- image -->\\n\\nIt is\", \" that simple. And because it is automatically generated, the Swagger metadata will grow when you add\", \" more functionality to your API.\\n\\n## Additional resources\\n\\n- ASP.NET Web API Help Pages using Swagge\", \"r https://learn.microsoft.com/aspnet/core/tutorials/web-api-help-pages-using-swagger\\n- Get started w\", \"ith Swashbuckle and ASP.NET Core https://learn.microsoft.com/aspnet/core/tutorials/getting-started-w\", \"ith-swashbuckle\\n- Get started with NSwag and ASP.NET Core https://learn.microsoft.com/aspnet/core/tu\", \"torials/getting-started-with-nswag\\n\\n## Defining your multi-container application with docker-compose\", \".yml\\n\\nIn this guide, the docker-compose.yml file was introduced in the section Step 4. Define your s\", \"ervices in docker-compose.yml when building a multi-container Docker application. However, there are\", \" additional ways to use the docker-compose files that are worth exploring in further detail.\\n\\nFor ex\", \"ample, you can explicitly describe how you want to deploy your multi-container application in the do\", \"cker-compose.yml file. Optionally, you can also describe how you are going to build your custom Dock\", \"er images. (Custom Docker images can also be built with the Docker CLI.)\\n\\nSend\\n\\nImport http://localh\", \"ost:5101/ X\\n\\nBuilder\\n\\nTeam Library\\n\\n+\\n\\nGET Y\\n\\nhttp://localhost:5101/swagger/v1/swagger.json\\n\\nSign In\", \"\\n\\n-\\n\\nX\\n\\nBasically, you define each of the containers you want to deploy plus certain characteristics\", \" for each container deployment. Once you have a multi-container deployment description file, you can\", \" deploy the whole solution in a single action orchestrated by the docker-compose up CLI command, or \", \"you can deploy it transparently from Visual Studio. Otherwise, you would need to use the Docker CLI \", \"to deploy container-by-container in multiple steps by using the docker run command from the command \", \"line. Therefore, each service defined in docker-compose.yml must specify exactly one image or build.\", \" Other keys are optional, and are analogous to their docker run command-line counterparts.\\n\\nThe foll\", \"owing YAML code is the definition of a possible global but single docker-compose.yml file for the eS\", \"hopOnContainers sample. This code is not the actual docker-compose file from eShopOnContainers. Inst\", \"ead, it is a simplified and consolidated version in a single file, which is not the best way to work\", \" with docker-compose files, as will be explained later.\\n\\n```\\nversion : '3.4' services : webmvc : ima\", \"ge : eshop/webmvc environment : -CatalogUrl=http://catalog-api -OrderingUrl=http://ordering-api -Bas\", \"ketUrl=http://basket-api ports : -\\\"5100:80\\\" depends_on : -catalog-api -ordering-api -basket-api cata\", \"log-api : image : eshop/catalog-api environment : -ConnectionString=Server=sqldata;Initial Catalog=C\", \"atalogData;User Id=sa;Password=[PLACEHOLDER] expose : -\\\"80\\\" ports : -\\\"5101:80\\\" #extra hosts can be u\", \"sed for standalone SQL Server or services at the dev PC extra_hosts : -\\\"CESARDLSURFBOOK:10.0.75.1\\\" d\", \"epends_on : -sqldata ordering-api : image : eshop/ordering-api environment : -ConnectionString=Serve\", \"r=sqldata;Database=Services.OrderingDb;User Id=sa;Password=[PLACEHOLDER] ports : -\\\"5102:80\\\" #extra h\", \"osts can be used for standalone SQL Server or services at the dev PC extra_hosts : -\\\"CESARDLSURFBOOK\", \":10.0.75.1\\\" depends_on : -sqldata\\n```\\n\\n```\\nbasket-api : image : eshop/basket-api environment : -Conn\", \"ectionString=sqldata ports : -\\\"5103:80\\\" depends_on : -sqldata sqldata : environment : -SA_PASSWORD=[\", \"PLACEHOLDER] -ACCEPT_EULA=Y ports : -\\\"5434:1433\\\" basketdata : image : redis\\n```\\n\\nThe root key in thi\", \"s file is services. Under that key, you define the services you want to deploy and run when you exec\", \"ute the docker-compose up command or when you deploy from Visual Studio by using this docker-compose\", \".yml file. In this case, the docker-compose.yml file has multiple services defined, as described in \", \"the following table.\\n\\n| Service name   | Description                                                \", \"                                          |\\n|----------------|--------------------------------------\", \"----------------------------------------------------------------|\\n| webmvc         | Container inclu\", \"ding the ASP.NET Core MVC application consuming the microservices from server-side C# |\\n| catalog-ap\", \"i    | Container including the Catalog ASP.NET Core Web API microservice                            \", \"        |\\n| ordering-api   | Container including the Ordering ASP.NET Core Web API microservice     \", \"                              |\\n| sqldata        | Container running SQL Server for Linux, holding t\", \"he microservices databases                          |\\n| basket-api     | Container with the Basket A\", \"SP.NET Core Web API microservice                                          |\\n| basketdata     | Conta\", \"iner running the REDIS cache service, with the basket database as a REDIS cache                 |\\n\\n#\", \"# A simple Web Service API container\\n\\nFocusing on a single container, the catalog-api container-micr\", \"oservice has a straightforward definition:\\n\\n```\\ncatalog-api : image : eshop/catalog-api environment \", \": -ConnectionString=Server=sqldata;Initial Catalog=CatalogData;User Id=sa;Password=[PLACEHOLDER] exp\", \"ose :\\n```\\n\\n```\\n-\\\"80\\\" ports : -\\\"5101:80\\\" #extra hosts can be used for standalone SQL Server or servic\", \"es at the dev PC extra_hosts : -\\\"CESARDLSURFBOOK:10.0.75.1\\\" depends_on : -sqldata\\n```\\n\\nThis containe\", \"rized service has the following basic configuration:\\n\\n- It is based on the custom eshop/catalog-api \", \"image. For simplicity's sake, there is no build: key setting in the file. This means that the image \", \"must have been previously built (with docker build) or have been downloaded (with the docker pull co\", \"mmand) from any Docker registry.\\n- It defines an environment variable named ConnectionString with th\", \"e connection string to be used by Entity Framework to access the SQL Server instance that contains t\", \"he catalog data model. In this case, the same SQL Server container is holding multiple databases. Th\", \"erefore, you need less memory in your development machine for Docker. However, you could also deploy\", \" one SQL Server container for each microservice database.\\n- The SQL Server name is sqldata , which i\", \"s the same name used for the container that is running the SQL Server instance for Linux. This is co\", \"nvenient; being able to use this name resolution (internal to the Docker host) will resolve the netw\", \"ork address so you don't need to know the internal IP for the containers you are accessing from othe\", \"r containers.\\n\\nBecause the connection string is defined by an environment variable, you could set th\", \"at variable through a different mechanism and at a different time. For example, you could set a diff\", \"erent connection string when deploying to production in the final hosts, or by doing it from your CI\", \"/CD pipelines in Azure DevOps Services or your preferred DevOps system.\\n\\n- It exposes port 80 for in\", \"ternal access to the catalog-api service within the Docker host. The host is currently a Linux VM be\", \"cause it is based on a Docker image for Linux, but you could configure the container to run on a Win\", \"dows image instead.\\n- It forwards the exposed port 80 on the container to port 5101 on the Docker ho\", \"st machine (the Linux VM).\\n- It links the web service to the sqldata service (the SQL Server instanc\", \"e for Linux database running in a container). When you specify this dependency, the catalog-api cont\", \"ainer will not start until the sqldata container has already started; this aspect is important becau\", \"se catalogapi needs to have the SQL Server database up and running first. However, this kind of cont\", \"ainer dependency is not enough in many cases, because Docker checks only at the container level. Som\", \"etimes the service (in this case SQL Server) might still not be ready, so it is advisable to impleme\", \"nt retry logic with exponential backoff in your client microservices. That way, if a dependency cont\", \"ainer is not ready for a short time, the application will still be resilient.\\n- It is configured to \", \"allow access to external servers: the extra\\\\_hosts setting allows you to access external servers or \", \"machines outside of the Docker host (that is, outside the default Linux VM,\\n\\nwhich is a development \", \"Docker host), such as a local SQL Server instance on your development PC.\\n\\nThere are also other, mor\", \"e advanced dockercompose.yml settings that we'll discuss in the following sections.\\n\\n## Using docker\", \"-compose files to target multiple environments\\n\\nThe docker-compose.*.yml files are definition files \", \"and can be used by multiple infrastructures that understand that format. The most straightforward to\", \"ol is the docker-compose command.\\n\\nTherefore, by using the docker-compose command you can target the\", \" following main scenarios.\\n\\n## Development environments\\n\\nWhen you develop applications, it is import\", \"ant to be able to run an application in an isolated development environment. You can use the docker-\", \"compose CLI command to create that environment or Visual Studio, which uses docker-compose under the\", \" covers.\\n\\nThe dockercompose.yml file allows you to configure and document all your application's ser\", \"vice dependencies (other services, cache, databases, queues, etc.). Using the docker-compose CLI com\", \"mand, you can create and start one or more containers for each dependency with a single command (doc\", \"ker-compose up).\\n\\nThe docker-compose.yml files are configuration files interpreted by Docker engine \", \"but also serve as convenient documentation files about the composition of your multi-container appli\", \"cation.\\n\\n## Testing environments\\n\\nAn important part of any continuous deployment (CD) or continuous \", \"integration (CI) process are the unit tests and integration tests. These automated tests require an \", \"isolated environment so they are not impacted by the users or any other change in the appl ication's\", \" data.\\n\\nWith Docker Compose, you can create and destroy that isolated environment very easily in a f\", \"ew commands from your command prompt or scripts, like the following commands:\\n\\ndocker-compose -f doc\", \"ker-compose.yml -f docker-compose-test.override.yml up -d ./run\\\\_unit\\\\_tests docker-compose -f docke\", \"r-compose.yml -f docker-compose-test.override.yml down\\n\\n## Production deployments\\n\\nYou can also use \", \"Compose to deploy to a remote Docker Engine. A typical case is to deploy to a single Docker host ins\", \"tance (like a production VM or server provisioned with Docker Machine).\\n\\nIf you are using any other \", \"orchestrator (Azure Service Fabric, Kubernetes, etc.), you might need to add setup and metadata conf\", \"iguration settings like those in docker-compose.yml, but in the format required by the other orchest\", \"rator.\\n\\nIn any case, docker-compose is a convenient tool and metadata format for development, testin\", \"g and production workflows, although the production workflow might vary on the orchestrator you are \", \"using.\\n\\n## Using multiple docker-compose files to handle several environments\\n\\nWhen targeting differ\", \"ent environments, you should use multiple compose files. This approach lets you create multiple conf\", \"iguration variants depending on the environment.\\n\\n## Overriding the base docker-compose file\\n\\nYou co\", \"uld use a single docker-compose.yml file as in the simplified examples shown in previous sections. H\", \"owever, that is not recommended for most applications.\\n\\nBy default, Compose reads two files, a docke\", \"r-compose.yml and an optional dockercompose.override.yml file. As shown in Figure 6-11, when you are\", \" using Visual Studio and enabling Docker support, Visual Studio also creates an additional docker-co\", \"mpose.vs.debug.g.yml file for debugging the application, you can take a look at this file in folder \", \"obj\\\\Docker\\\\ in the main solution folder.\\n\\nFigure 6-11. docker-compose files in Visual Studio 2019\\n\\n<\", \"!-- image -->\\n\\ndocker-compose project file structure:\\n\\n- .dockerignore - used to ignore files\\n- dock\", \"er-compose.yml - used to compose microservices\\n- docker-compose.override.yml - used to configure mic\", \"roservices environment\\n\\nYou can edit the docker-compose files with any editor, like Visual Studio Co\", \"de or Sublime, and run the application with the docker-compose up command.\\n\\nBy convention, the docke\", \"r-compose.yml file contains your base configuration and other static settings. That means that the s\", \"ervice configuration should not change depending on the deployment environment you are targeting.\\n\\nT\", \"he docker-compose.override.yml file, as its name suggests, contains configuration settings that over\", \"ride the base configuration, such as configuration that depends on the deployment environment. You c\", \"an have multiple override files with different names also. The override files usually contain additi\", \"onal information needed by the application but specific to an environment or to a deployment.\\n\\n## Ta\", \"rgeting multiple environments\\n\\nA typical use case is when you define multiple compose files so you c\", \"an target multiple environments, like production, staging, CI, or development. To support these diff\", \"erences, you can split your Compose configuration into multiple files, as shown in Figure 6-12.\\n\\nMul\", \"tiple docker-compose files docker-compose.override.yml\\n\\ndocker-compose.prod.yml docker-compose.stagi\", \"ng.yml\\n\\nFigure 6-12. Multiple docker-compose files overriding values in the base docker-compose.yml \", \"file\\n\\n<!-- image -->\\n\\nYou can combine multiple docker-compose*.yml files to handle different environ\", \"ments. You start with the base docker-compose.yml file. This base file contains the base or static c\", \"onfiguration settings that do not change depending on the environment. For example, the eShopOnConta\", \"iners app has the following docker-compose.yml file (simplified with fewer services) as the base fil\", \"e.\\n\\n```\\n#docker-compose.yml (Base) version : '3.4' services : basket-api : image : eshop/basket-api:\", \"${TAG:-latest} build : context : . dockerfile : src/Services/Basket/Basket.API/Dockerfile depends_on\", \" : -basketdata -identity-api -rabbitmq catalog-api : image : eshop/catalog-api:${TAG:-latest} build \", \": context : . dockerfile : src/Services/Catalog/Catalog.API/Dockerfile depends_on : -sqldata -rabbit\", \"mq marketing-api : image : eshop/marketing-api:${TAG:-latest} build : context : . dockerfile : src/S\", \"ervices/Marketing/Marketing.API/Dockerfile depends_on : -sqldata -nosqldata -identity-api -rabbitmq \", \"webmvc : image : eshop/webmvc:${TAG:-latest}\\n```\\n\\n```\\nbuild : context : . dockerfile : src/Web/WebMV\", \"C/Dockerfile depends_on : -catalog-api -ordering-api -identity-api -basket-api -marketing-api sqldat\", \"a : image : mcr.microsoft.com/mssql/server:2019-latest nosqldata : image : mongo basketdata : image \", \": redis rabbitmq : image : rabbitmq:3-management\\n```\\n\\nThe values in the base docker-compose.yml file\", \" should not change because of different target deployment environments.\\n\\nIf you focus on the webmvc \", \"service definition, for instance, you can see how that information is much the same no matter what e\", \"nvironment you might be targeting. You have the following information:\\n\\n- The service name: webmvc.\\n\", \"- The container's custom image: eshop/webmvc.\\n- The command to build the custom Docker image, indica\", \"ting which Dockerfile to use.\\n- Dependencies on other services, so this container does not start unt\", \"il the other dependency containers have started.\\n\\nYou can have additional configuration, but the imp\", \"ortant point is that in the base dockercompose.yml file, you just want to set the information that i\", \"s common across environments. Then in the docker-compose.override.yml or similar files for productio\", \"n or staging, you should place configuration that is specific for each environment.\\n\\nUsually, the do\", \"cker-compose.override.yml is used for your development environment, as in the following example from\", \" eShopOnContainers:\\n\\n```\\n#docker-compose.override.yml (Extended config for DEVELOPMENT env.) version\", \" : '3.4' services : # Simplified number of services here: basket-api : environment : -ASPNETCORE_ENV\", \"IRONMENT=Development -ASPNETCORE_URLS=http://0.0.0.0:80 -ConnectionString=${ESHOP_AZURE_REDIS_BASKET\", \"_DB:-basketdata} -identityUrl=http://identity-api -IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS_N\", \"AME_OR_IP}:5105\\n```\\n\\n```\\n-EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq} -EventBusUserName=\", \"${ESHOP_SERVICE_BUS_USERNAME} -EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD} -AzureServiceBusEnable\", \"d=False -ApplicationInsights__InstrumentationKey=${INSTRUMENTATION_KEY} -OrchestratorType=${ORCHESTR\", \"ATOR_TYPE} -UseLoadTest=${USE_LOADTEST:-False} ports : -\\\"5103:80\\\" catalog-api : environment : -ASPNE\", \"TCORE_ENVIRONMENT=Development -ASPNETCORE_URLS=http://0.0.0.0:80 -ConnectionString=${ESHOP_AZURE_CAT\", \"ALOG_DB:-Server=sqldata;Database=Microsoft.eShopOnContainers.Services.CatalogDb;User Id=sa;Password=\", \"[PLACEHOLDER]} -PicBaseUrl=${ESHOP_AZURE_STORAGE_CATALOG_URL:-http://host.docker.internal:5202/api/v\", \"1/catalog/items/[0]/pic/} -EventBusConnection=${ESHOP_AZURE_SERVICE_BUS:-rabbitmq} -EventBusUserName\", \"=${ESHOP_SERVICE_BUS_USERNAME} -EventBusPassword=${ESHOP_SERVICE_BUS_PASSWORD} -AzureStorageAccountN\", \"ame=${ESHOP_AZURE_STORAGE_CATALOG_NAME} -AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_CATALOG_KEY} -\", \"UseCustomizationData=True -AzureServiceBusEnabled=False -AzureStorageEnabled=False -ApplicationInsig\", \"hts__InstrumentationKey=${INSTRUMENTATION_KEY} -OrchestratorType=${ORCHESTRATOR_TYPE} ports : -\\\"5101\", \":80\\\" marketing-api : environment : -ASPNETCORE_ENVIRONMENT=Development -ASPNETCORE_URLS=http://0.0.0\", \".0:80 -ConnectionString=${ESHOP_AZURE_MARKETING_DB:-Server=sqldata;Database=Microsoft.eShopOnContain\", \"ers.Services.MarketingDb;User Id=sa;Password=[PLACEHOLDER]} -MongoConnectionString=${ESHOP_AZURE_COS\", \"MOSDB:-mongodb://nosqldata} -MongoDatabase=MarketingDb -EventBusConnection=${ESHOP_AZURE_SERVICE_BUS\", \":-rabbitmq} -EventBusUserName=${ESHOP_SERVICE_BUS_USERNAME} -EventBusPassword=${ESHOP_SERVICE_BUS_PA\", \"SSWORD} -identityUrl=http://identity-api -IdentityUrlExternal=http://${ESHOP_EXTERNAL_DNS_NAME_OR_IP\", \"}:5105 -CampaignDetailFunctionUri=${ESHOP_AZUREFUNC_CAMPAIGN_DETAILS_URI} -PicBaseUrl=${ESHOP_AZURE_\", \"STORAGE_MARKETING_URL:-http://host.docker.internal:5110/api/v1/campaigns/[0]/pic/} -AzureStorageAcco\", \"untName=${ESHOP_AZURE_STORAGE_MARKETING_NAME} -AzureStorageAccountKey=${ESHOP_AZURE_STORAGE_MARKETIN\", \"G_KEY} -AzureServiceBusEnabled=False -AzureStorageEnabled=False -ApplicationInsights__Instrumentatio\", \"nKey=${INSTRUMENTATION_KEY} -OrchestratorType=${ORCHESTRATOR_TYPE} -UseLoadTest=${USE_LOADTEST:-Fals\", \"e} ports : -\\\"5110:80\\\" webmvc :\\n```\\n\\n```\\nenvironment : -ASPNETCORE_ENVIRONMENT=Development -ASPNETCOR\", \"E_URLS=http://0.0.0.0:80 -PurchaseUrl=http://webshoppingapigw -IdentityUrl=http://10.0.75.1:5105 -Ma\", \"rketingUrl=http://webmarketingapigw -CatalogUrlHC=http://catalog-api/hc -OrderingUrlHC=http://orderi\", \"ng-api/hc -IdentityUrlHC=http://identity-api/hc -BasketUrlHC=http://basket-api/hc -MarketingUrlHC=ht\", \"tp://marketing-api/hc -PaymentUrlHC=http://payment-api/hc -SignalrHubUrl=http://${ESHOP_EXTERNAL_DNS\", \"_NAME_OR_IP}:5202 -UseCustomizationData=True -ApplicationInsights__InstrumentationKey=${INSTRUMENTAT\", \"ION_KEY} -OrchestratorType=${ORCHESTRATOR_TYPE} -UseLoadTest=${USE_LOADTEST:-False} ports : -\\\"5100:8\", \"0\\\" sqldata : environment : -SA_PASSWORD=[PLACEHOLDER] -ACCEPT_EULA=Y ports : -\\\"5433:1433\\\" nosqldata \", \": ports : -\\\"27017:27017\\\" basketdata : ports : -\\\"6379:6379\\\" rabbitmq : ports : -\\\"15672:15672\\\" -\\\"5672:\", \"5672\\\"\\n```\\n\\nIn this example, the development override configuration exposes some ports to the host, d\", \"efines environment variables with redirect URLs, and specifies connection strings for the developmen\", \"t environment. These settings are all just for the development environment.\\n\\nWhen you run docker-com\", \"pose up (or launch it from Visual Studio), the command reads the overrides automatically as if it we\", \"re merging both files.\\n\\nSuppose that you want another Compose file for the production environment, w\", \"ith different configuration values, ports, or connection strings. You can create another override fi\", \"le, like file named docker-compose.prod.yml with different settings and environment variables. That \", \"file might be stored in a different Git repo or managed and secured by a different team.\\n\\n## How to \", \"deploy with a specific override file\\n\\nTo use multiple override files, or an override file with a dif\", \"ferent name, you can use the -f option with the docker-compose command and specify the files. Compos\", \"e merges files in the order they are specified on the command line. The following example shows how \", \"to deploy with override files.\\n\\n```\\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml \", \"up -d\\n```\\n\\n## Using environment variables in docker-compose files\\n\\nIt is convenient, especially in p\", \"roduction environments, to be able to get configuration information from environment variables, as w\", \"e have shown in previous examples. You can reference an environment variable in your docker-compose \", \"files using the syntax ${MY\\\\_VAR}. The following line from a docker-compose.prod.yml file shows how \", \"to reference the value of an environment variable.\\n\\n```\\nIdentityUrl=http://${ESHOP_PROD_EXTERNAL_DNS\", \"_NAME_OR_IP}:5105\\n```\\n\\nEnvironment variables are created and initialized in different ways, dependin\", \"g on your host environment (Linux, Windows, Cloud cluster, etc.). However, a convenient approach is \", \"to use an .env file. The docker-compose files support declaring default environment variables in the\", \" .env file. These values for the environment variables are the default values. But they can be overr\", \"idden by the values you might have defined in each of your environments (host OS or environment vari\", \"ables from your cluster). You place this .env file in the folder where the docker-compose command is\", \" executed from.\\n\\nThe following example shows an .env file like the .env file for the eShopOnContaine\", \"rs application.\\n\\n```\\n# .env file ESHOP_EXTERNAL_DNS_NAME_OR_IP=host.docker.internal ESHOP_PROD_EXTER\", \"NAL_DNS_NAME_OR_IP=10.121.122.92\\n```\\n\\nDocker-compose expects each line in an .env file to be in the \", \"format &lt;variable&gt;=&lt;value&gt;.\\n\\nThe values set in the run-time environment always override t\", \"he values defined inside the .env file. In a similar way, values passed via command-line arguments a\", \"lso override the default values set in the .env file.\\n\\n## Additional resources\\n\\n- \\u2022\\n- Overview of Do\", \"cker Compose https://docs.docker.com/compose/overview/\\n- \\u2022\\n- Multiple Compose files https://docs.doc\", \"ker.com/compose/multiple-compose-files/\\n\\n## Building optimized ASP.NET Core Docker images\\n\\nIf you ar\", \"e exploring Docker and .NET on sources on the Internet, you will find Dockerfiles that demonstrate t\", \"he simplicity of building a Docker image by copying your source into a container. These examples sug\", \"gest that by using a simple configuration, you can have a Docker image with the environment packaged\", \" with your application. The following example shows a simple Dockerfile in this vein.\\n\\n```\\nFROM mcr.\", \"microsoft.com/dotnet/sdk:7.0 WORKDIR /app ENV ASPNETCORE_URLS http://+:80 EXPOSE 80 COPY . . RUN dot\", \"net restore ENTRYPOINT [\\\"dotnet\\\", \\\"run\\\"]\\n```\\n\\nA Dockerfile like this will work. However, you can sub\", \"stantially optimize your images, especially your production images.\\n\\nIn the container and microservi\", \"ces model, you are constantly starting containers. The typical way of using containers does not rest\", \"art a sleeping container, because the container is disposable. Orchestrators (like Kubernetes and Az\", \"ure Service Fabric) create new instances of images. What this means is that you would need to optimi\", \"ze by precompiling the application when it is built so the instantiation process will be faster. Whe\", \"n the container is started, it should be ready to run. Don't restore and compile at run time using t\", \"he dotnet restore and dotnet build CLI commands as you may see in blog posts about .NET and Docker.\\n\", \"\\nThe .NET team has been doing important work to make .NET and ASP.NET Core a container-optimized fra\", \"mework. Not only is .NET a lightweight framework with a small memory footprint; the team has focused\", \" on optimized Docker images for three main scenarios and published them in the Docker Hub registry a\", \"t dotnet/ , beginning with version 2.1:\\n\\n1. Development : The priority is the ability to quickly ite\", \"rate and debug changes, and where size is secondary.\\n2. Build : The priority is compiling the applic\", \"ation, and the image includes binaries and other dependencies to optimize binaries.\\n3. Production : \", \"The focus is fast deploying and starting of containers, so these images are limited to the binaries \", \"and content needed to run the application.\\n\\nThe .NET team provides four basic variants in dotnet/ (a\", \"t Docker Hub):\\n\\n1. sdk : for development and build scenarios\\n2. aspnet : for ASP.NET production scen\", \"arios\\n3. runtime : for .NET production scenarios\\n4. runtime-deps : for production scenarios of self-\", \"contained applications\\n\\nFor faster startup, runtime images also automatically set aspnetcore\\\\_urls t\", \"o port 80 and use Ngen to create a native image cache of assemblies.\\n\\n## Additional resources\\n\\n- Bui\", \"lding Optimized Docker Images with ASP.NET Core\\n\\nhttps://learn.microsoft.com/archive/blogs/stevelask\", \"er/building-optimized-docker-imageswith-asp-net-core\\n\\n- Building Docker Images for .NET Applications\", \"\\n\\nhttps://learn.microsoft.com/dotnet/core/docker/building-net-docker-images\\n\\n## Use a database serve\", \"r running as a container\\n\\nYou can have your databases (SQL Server, PostgreSQL, MySQL, etc.) on regul\", \"ar standalone servers, in on-premises clusters, or in PaaS services in the cloud like Azure SQL DB. \", \"However, for development and test environments, having your databases running as c ontainers is conv\", \"enient, because you don't\\n\\nhave any external dependency and simply running the docker-compose up com\", \"mand starts the whole application. Having those databases as containers is also great for integratio\", \"n tests, because the database is started in the container and is always populated with the same samp\", \"le data, so tests can be more predictable.\\n\\n## SQL Server running as a container with a microservice\", \"-related database\\n\\nIn eShopOnContainers, there's a container named sqldata, as defined in the docker\", \"-compose.yml file, that runs a SQL Server for Linux instance with the SQL databases for all microser\", \"vices that need one.\\n\\nA key point in microservices is that each microservice owns its related data, \", \"so it should have its own database. However, the databases can be anywhere. In this case, they are a\", \"ll in the same container to keep Docker memory requirements as low as possible. Keep in mind that th\", \"is is a good-enough solution for development and, perhaps, testing but not for production.\\n\\nThe SQL \", \"Server container in the sample application is configured with the following YAML code in the docker-\", \"compose.yml file, which is executed when you run docker-compose up. Note that the YAML code has cons\", \"olidated configuration information from the generic docker-compose.yml file and the docker-compose.o\", \"verride.yml file. (Usually you would separate the environment settings from the base or static infor\", \"mation related to the SQL Server image.)\\n\\n```\\nsqldata : image : mcr.microsoft.com/mssql/server:2017-\", \"latest environment : -SA_PASSWORD=Pass@word -ACCEPT_EULA=Y ports : -\\\"5434:1433\\\"\\n```\\n\\nIn a similar wa\", \"y, instead of using docker-compose, the following docker run command can run that container:\\n\\n```\\ndo\", \"cker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=Pass@word' -p 5433:1433 -d mcr.microsoft.com/mssql/serve\", \"r:2017-latest\\n```\\n\\nHowever, if you are deploying a multi-container application like eShopOnContainer\", \"s, it is more convenient to use the docker-compose up command so that it deploys all the required co\", \"ntainers for the application.\\n\\nWhen you start this SQL Server container for the first time, the cont\", \"ainer initializes SQL Server with the password that you provide. Once SQL Server is running as a con\", \"tainer, you can update the database by connecting through any regular SQL connection, such as from S\", \"QL Server Management Studio, Visual Studio, or C# code.\\n\\nThe eShopOnContainers application initializ\", \"es each microservice database with sample data by seeding it with data on startup, as explained in t\", \"he following section.\\n\\nHaving SQL Server running as a container is not just useful for a demo where \", \"you might not have access to an instance of SQL Server. As noted, it is also great for development a\", \"nd testing\\n\\nenvironments so that you can easily run integration tests starting from a clean SQL Serv\", \"er image and known data by seeding new sample data.\\n\\n## Additional resources\\n\\n- Run the SQL Server D\", \"ocker image on Linux, Mac, or Windows\\n\\nhttps://learn.microsoft.com/sql/linux/sql-server-linux-setup-\", \"docker\\n\\n- Connect and query SQL Server on Linux with sqlcmd\\n- https://learn.microsoft.com/sql/linux/\", \"sql-server-linux-connect-and-query-sqlcmd\\n\\n## Seeding with test data on Web application startup\\n\\nTo \", \"add data to the database when the application starts up, you can add code like the following to the \", \"Main method in the Program class of the Web API project:\\n\\n```\\npublic static int Main(string[] args) \", \"{ var configuration = GetConfiguration(); Log.Logger = CreateSerilogLogger(configuration); try { Log\", \".Information(\\\"Configuring web host ({ApplicationContext})...\\\", AppName); var host = CreateHostBuilde\", \"r(configuration, args); Log.Information(\\\"Applying migrations ({ApplicationContext})...\\\", AppName); h\", \"ost.MigrateDbContext<CatalogContext>((context, services) => { var env = services.GetService<IWebHost\", \"Environment>(); var settings = services.GetService<IOptions<CatalogSettings>>(); var logger = servic\", \"es.GetService<ILogger<CatalogContextSeed>>(); new CatalogContextSeed() .SeedAsync(context, env, sett\", \"ings, logger) .Wait(); }) .MigrateDbContext<IntegrationEventLogContext>((_, __) => { }); Log.Informa\", \"tion(\\\"Starting web host ({ApplicationContext})...\\\", AppName); host.Run(); return 0; } catch (Excepti\", \"on ex) { Log.Fatal(ex, \\\"Program terminated unexpectedly ({ApplicationContext})!\\\", AppName); return 1\", \"; } finally { Log.CloseAndFlush(); } }\\n```\\n\\nThere's an important caveat when applying migrations and\", \" seeding a database during container startup. Since the database server might not be available for w\", \"hatever reason, you must handle retries while waiting for the server to be available. This retry log\", \"ic is handled by the MigrateDbContext() extension method, as shown in the following code:\\n\\n```\\npubli\", \"c static IWebHost MigrateDbContext<TContext>( this IWebHost host, Action<TContext, IServiceProvider>\", \" seeder) where TContext : DbContext { var underK8s = host.IsInKubernetes(); using (var scope = host.\", \"Services.CreateScope()) { var services = scope.ServiceProvider; var logger = services.GetRequiredSer\", \"vice<ILogger<TContext>>(); var context = services.GetService<TContext>(); try { logger.LogInformatio\", \"n(\\\"Migrating database associated with context {DbContextName}\\\", typeof (TContext).Name); if (underK8\", \"s) { InvokeSeeder(seeder, context, services); } else { var retry = Policy.Handle<SqlException>() .Wa\", \"itAndRetry( new TimeSpan[] { TimeSpan.FromSeconds(3), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(\", \"8), }); //if the sql server container is not created on run docker compose this //migration can't fa\", \"il for network related exception. The retry options for DbContext only //apply to transient exceptio\", \"ns // Note that this is NOT applied when running some orchestrators (let the orchestrator to recreat\", \"e the failing service) retry.Execute(() => InvokeSeeder(seeder, context, services)); } logger.LogInf\", \"ormation(\\\"Migrated database associated with context {DbContextName}\\\", typeof (TContext).Name); } cat\", \"ch (Exception ex) { logger.LogError(ex, \\\"An error occurred while migrating the database used on cont\", \"ext {DbContextName}\\\", typeof (TContext).Name); if (underK8s) { throw ;          // Rethrow under k8s\", \" because we rely on k8s to re-run the\\n```\\n\\n```\\npod } } } return host; }\\n```\\n\\nThe following code in t\", \"he custom CatalogContextSeed class populates the data.\\n\\n```\\npublic class CatalogContextSeed { public\", \" static async Task SeedAsync(IApplicationBuilder applicationBuilder) { var context = (CatalogContext\", \")applicationBuilder .ApplicationServices.GetService( typeof (CatalogContext)); using (context) { con\", \"text.Database.Migrate(); if (!context.CatalogBrands.Any()) { context.CatalogBrands.AddRange( GetPrec\", \"onfiguredCatalogBrands()); await context.SaveChangesAsync(); } if (!context.CatalogTypes.Any()) { co\", \"ntext.CatalogTypes.AddRange( GetPreconfiguredCatalogTypes()); await context.SaveChangesAsync(); } } \", \"} static IEnumerable<CatalogBrand> GetPreconfiguredCatalogBrands() { return new List<CatalogBrand>()\", \" { new CatalogBrand() { Brand = \\\"Azure\\\"}, new CatalogBrand() { Brand = \\\".NET\\\" }, new CatalogBrand() \", \"{ Brand = \\\"Visual Studio\\\" }, new CatalogBrand() { Brand = \\\"SQL Server\\\" } }; } static IEnumerable<Cat\", \"alogType> GetPreconfiguredCatalogTypes() { return new List<CatalogType>() { new CatalogType() { Type\", \" = \\\"Mug\\\"}, new CatalogType() { Type = \\\"T-Shirt\\\" }, new CatalogType() { Type = \\\"Backpack\\\" }, new Cata\", \"logType() { Type = \\\"USB Memory Stick\\\" } }; } }\\n```\\n\\nWhen you run integration tests, having a way to \", \"generate data consistent with your integration tests is useful. Being able to create everything from\", \" scratch, including an instance of SQL Server running on a container, is great for test environments\", \".\\n\\n## EF Core InMemory database versus SQL Server running as a container\\n\\nAnother good choice when r\", \"unning tests is to use the Entity Framework InMemory database provider.\\n\\nYou can specify that config\", \"uration in the ConfigureServices method of the Startup class in your Web API project:\\n\\n```\\npublic cl\", \"ass Startup { // Other Startup code ... public void ConfigureServices(IServiceCollection services) {\", \" services.AddSingleton<IConfiguration>(Configuration); // DbContext using an InMemory database provi\", \"der services.AddDbContext<CatalogContext>(opt => opt.UseInMemoryDatabase()); //(Alternative: DbConte\", \"xt using a SQL Server provider //services.AddDbContext<CatalogContext>(c => //{ // c.UseSqlServer(Co\", \"nfiguration[\\\"ConnectionString\\\"]); // //}); } // Other Startup code ... }\\n```\\n\\nThere is an important \", \"catch, though. The in-memory database does not support many constraints that are specific to a parti\", \"cular database. For instance, you might add a unique index on a column in your EF Core model and wri\", \"te a test against your in-memory database to check that it does not let you add a duplicate value. B\", \"ut when you are using the in-memory database, you cannot handle unique indexes on a column. Therefor\", \"e, the in-memory database does not behave exactly the same as a real SQL Server database -it does no\", \"t emulate database-specific constraints.\\n\\nEven so, an in-memory database is still useful for testing\", \" and prototyping. But if you want to create accurate integration tests that take into account the be\", \"havior of a specific database implementation, you need to use a real database like SQL Server. For t\", \"hat purpose, running SQL Server in a container is a great choice and more accurate than the EF Core \", \"InMemory database provider.\\n\\n## Using a Redis cache service running in a container\\n\\nYou can run Redi\", \"s on a container, especially for development and testing and for proof-of-concept scenarios. This sc\", \"enario is convenient, because you can have all your dependencies running on containers -not just for\", \" your local development machines, but for your testing environments in your CI/CD pipelines.\\n\\nHoweve\", \"r, when you run Redis in production, it is better to look for a high-availability solution like Redi\", \"s Microsoft Azure, which runs as a PaaS (Platform as a Service). In your code, you just need to chan\", \"ge your connection strings.\\n\\nRedis provides a Docker image with Redis. That image is available from \", \"Docker Hub at this URL:\\n\\nhttps://hub.docker.com/\\\\_/redis/\\n\\nYou can directly run a Docker Redis conta\", \"iner by executing the following Docker CLI command in your command prompt:\\n\\n```\\ndocker run --name so\", \"me-redis -d redis\\n```\\n\\nThe Redis image includes expose:6379 (the port used by Redis), so standard co\", \"ntainer linking will make it automatically available to the linked containers.\\n\\nIn eShopOnContainers\", \", the basket-api microservice uses a Redis cache running as a container. That basketdata container i\", \"s defined as part of the multi-container docker-compose.yml file, as shown in the following example:\", \"\\n\\n```\\n#docker-compose.yml file #... basketdata : image : redis expose : -\\\"6379\\\"\\n```\\n\\nThis code in th\", \"e docker-compose.yml defines a container named basketdata based on the redis image and publishing th\", \"e port 6379 internally. This configuration means that it will only be accessible from other containe\", \"rs running within the Docker host.\\n\\nFinally, in the docker-compose.override.yml file, the basket-api\", \" microservice for the eShopOnContainers sample defines the connection string to use for that Redis c\", \"ontainer:\\n\\n```\\nbasket-api : environment : # Other data ... -ConnectionString=basketdata -EventBusCon\", \"nection=rabbitmq\\n```\\n\\nAs mentioned before, the name of the microservice basketdata is resolved by Do\", \"cker's internal network DNS.\\n\\n## Implementing event-based communication between microservices (integ\", \"ration events)\\n\\nAs described earlier, when you use event-based communication, a microservice publish\", \"es an event when something notable happens, such as when it updates a business entity. Other microse\", \"rvices subscribe to those events. When a microservice receives an event, it can update its own busin\", \"ess entities, which might lead to more events being published. This is the essence of the eventual c\", \"onsistency concept. This publish/subscribe system is usually performed by using an implementation of\", \" an event bus. The event bus can be designed as an interface with the API needed to subscribe and un\", \"subscribe to events and to publish events. It can also have one or more implementations based on any\", \" inter-process or messaging communication, such as a messaging queue or a service bus that supports \", \"asynchronous communication and a publish/subscribe model.\\n\\nYou can use events to implement business \", \"transactions that span multiple services, which give you eventual consistency between those services\", \". An eventually consistent transaction consists of a series\\n\\nImplementing asynchronous event-driven \", \"communication with an event bus\\n\\n- -\\n\\n1\\n\\nof distributed actions. At each action, the microservice up\", \"dates a business entity and publishes an event that triggers the next action. Figure 6-18 below, sho\", \"ws a PriceUpdated event published through an event bus, so the price update is propagated to the Bas\", \"ket and other microservices.\\n\\nBackend\\n\\nCatalog microservice\\n\\n1\\n\\nWeb API Service\\n\\nUpdatePrice command\", \"\\n\\nService\\n\\n## 3 Event bus PriceUpdated event ! * (Publish/Subscribe channel) (Publish action) Event \", \"bus abstractions/interface \\u00b7 PriceUpdated event \\u2192 Existing basket items 4 \\u00b7 PriceUpdated event \\u2192 Oth\", \"er related features\\n\\nDatabase\\n\\nDB update\\n\\nFigure 6-18. Event-driven communication based on an event \", \"bus\\n\\n<!-- image -->\\n\\nThis section describes how you can implement this type of communication with .N\", \"ET by using a generic event bus interface, as shown in Figure 6-18. There are multiple potential imp\", \"lementations, each using a different technology or infrastructure such as RabbitMQ, Azure Service Bu\", \"s, or any other third-party open-source or commercial service bus.\\n\\n## Using message brokers and ser\", \"vice buses for production systems\\n\\nAs noted in the architecture section, you can choose from multipl\", \"e messaging technologies for implementing your abstract event bus. But these technologies are at dif\", \"ferent levels. For instance, RabbitMQ, a messaging broker transport, is at a lower level than commer\", \"cial products like Azure Service Bus, NServiceBus, MassTransit, or Brighter. Most of these products \", \"can work on top of either RabbitMQ or Azure Service Bus. Your choice of product depends on how many \", \"features and how much out-of-the-box scalability you need for your application.\\n\\nFor implementing ju\", \"st an event bus proof-of-concept for your development environment, as in the eShopOnContainers sampl\", \"e, a simple implementation on top of RabbitMQ running as a container might be enough. But for missio\", \"n-critical and production systems that need high scalability, you might want to evaluate and use Azu\", \"re Service Bus.\\n\\nIf you require high-level abstractions and richer features like Sagas for long-runn\", \"ing processes that make distributed development easier, other commercial and open-source service bus\", \"es like NServiceBus, MassTransit, and Brighter are worth evaluating. In this case, the abstractions \", \"and API to use would usually be directly the ones provided by those high-level service buses instead\", \" of your own abstractions (like the simple event bus abstractions provided at eShopOnContainers). Fo\", \"r that matter,\\n\\nyou can research the forked eShopOnContainers using NServiceBus (additional derived \", \"sample implemented by Particular Software).\\n\\nOf course, you could always build your own service bus \", \"features on top of lower-level technologies like RabbitMQ and Docker, but the work needed to 'reinve\", \"nt the wheel' might be too costly for a custom enterprise application.\\n\\nTo reiterate: the sample eve\", \"nt bus abstractions and implementation showcased in the eShopOnContainers sample are intended to be \", \"used only as a proof of concept. Once you have decided that you want to have asynchronous and event-\", \"driven communication, as explained in the current section, you should choose the service bus product\", \" that best fits your needs for production.\\n\\n## Integration events\\n\\nIntegration events are used for b\", \"ringing domain state in sync across multiple microservices or external systems. This functionality i\", \"s done by publishing integration events outside the microservice. When an event is published to mult\", \"iple receiver microservices (to as many microservices as are subscribed to the integration event), t\", \"he appropriate event handler in each receiver microservice handles the event.\\n\\nAn integration event \", \"is basically a data-holding class, as in the following example:\\n\\n```\\npublic class ProductPriceChange\", \"dIntegrationEvent : IntegrationEvent { public int ProductId { get ; private set ; } public decimal N\", \"ewPrice { get ; private set ; } public decimal OldPrice { get ; private set ; } public ProductPriceC\", \"hangedIntegrationEvent(int productId, decimal newPrice, decimal oldPrice) { ProductId = productId; N\", \"ewPrice = newPrice; OldPrice = oldPrice; } }\\n```\\n\\nThe integration events can be defined at the appli\", \"cation level of each microservice, so they are decoupled from other microservices, in a way comparab\", \"le to how ViewModels are defined in the server and client. What is not recommended is sharing a comm\", \"on integration events library across multiple microservices; doing that would be coupling those micr\", \"oservices with a single event definition data library. You do not want to do that for the same reaso\", \"ns that you do not want to share a common domain model across multiple microservices: microservices \", \"must be completely autonomous. For more information, see this blog post on the amount of data to put\", \" in events. Be careful not to take this too far, as this other blog post describes the problem data \", \"deficient messages can produce . Your design of your events should aim to be 'just right' for the ne\", \"eds of their consumers.\\n\\nThere are only a few kinds of libraries you should share across microservic\", \"es. One is libraries that are final application blocks, like the Event Bus client API, as in eShopOn\", \"Containers. Another is libraries that constitute tools that could also be shared as NuGet components\", \", like JSON serializers.\\n\\n## The event bus\\n\\nEvent Bus\\n\\nEvent\\n\\nAn event bus allows publish/subscribe-\", \"style communication between microservices without requiring the components to explicitly be aware of\", \" each other, as shown in Figure 6-19.\\n\\nFigure 6-19. Publish/subscribe basics with an event bus\\n\\n<!--\", \" image -->\\n\\nThe above diagram shows that microservice A publishes to Event Bus, which distributes to\", \" subscribing microservices B and C, without the publisher needing to know the subscribers. The event\", \" bus is related to the Observer pattern and the publish-subscribe pattern.\\n\\n## Observer pattern\\n\\nIn \", \"the Observer pattern, your primary object (known as the Observable) notifies other interested object\", \"s (known as Observers) with relevant information (events).\\n\\n## Publish/Subscribe (Pub/Sub) pattern\\n\\n\", \"The purpose of the Publish/Subscribe pattern is the same as the Observer pattern: you want to notify\", \" other services when certain events take place. But there is an important difference between the Obs\", \"erver and Pub/Sub patterns. In the observer pattern, the broadcast is performed directly from the ob\", \" servable to the observers, so they 'know' each other. But when using a Pub/Sub pattern, there is a \", \"third component, called broker, or message broker or event bus, which is known by both the publisher\", \" and subscriber. Therefore, when using the Pub/Sub pattern the publisher and the subscribers are pre\", \"cisely decoupled thanks to the mentioned event bus or message broker.\\n\\n## The middleman or event bus\", \"\\n\\nHow do you achieve anonymity between publisher and subscriber? An easy way is let a middleman take\", \" care of all the communication. An event bus is one such middleman.\\n\\nAn event bus is typically compo\", \"sed of two parts:\\n\\n- The abstraction or interface.\\n- One or more implementations.\\n\\nMicroservice\\n\\nB\\n\\n\", \"Event bus\\n\\nLupublish/subscribe channel\\n\\nIn Figure 6-19 you can see how, from an application point of\", \" view, the event bus is nothing more than a Pub/Sub channel. The way you implement this asynchronous\", \" communication can vary. It can have multiple implementations so that you can swap between them, dep\", \"ending on the environment requirements (for example, production versus development environments).\\n\\nI\", \"n Figure 6-20, you can see an abstraction of an event bus with multiple implementations based on inf\", \"rastructure messaging technologies like RabbitMQ, Azure Service Bus, or another event/message broker\", \". Service message /\\n\\nBus event broker\\n\\nFigure 6- 20. Multiple implementations of an event bus\\n\\n<!-- \", \"image -->\\n\\nIt's good to have the event bus defined through an interface so it can be implemented wit\", \"h several technologies, like RabbitMQ, Azure Service bus or others. However, and as mentioned previo\", \"usly, using your own abstractions (the event bus interface) is good only if you need basic event bus\", \" features supported by your abstractions. If you need richer service bus features, you should probab\", \"ly use the API and abstractions provided by your preferred commercial service bus instead of your ow\", \"n abstractions.\\n\\n## Defining an event bus interface\\n\\nLet's start with some implementation code for t\", \"he event bus interface and possible implementations for exploration purposes. The interface should b\", \"e generic and straightforward, as in the following interface.\\n\\n```\\npublic interface IEventBus { void\", \" Publish(IntegrationEvent @event); void Subscribe<T, TH>() where T : IntegrationEvent where TH : IIn\", \"tegrationEventHandler<T>; void SubscribeDynamic<TH>(string eventName) where TH : IDynamicIntegration\", \"EventHandler;\\n```\\n\\n```\\nvoid UnsubscribeDynamic<TH>(string eventName) where TH : IDynamicIntegrationE\", \"ventHandler; void Unsubscribe<T, TH>() where TH : IIntegrationEventHandler<T> where T : IntegrationE\", \"vent; }\\n```\\n\\nThe Publish method is straightforward. The event bus will broadcast the integration eve\", \"nt passed to it to any microservice, or even an external application, subscribed to that event. This\", \" method is used by the microservice that is publishing the event.\\n\\nThe Subscribe methods (you can ha\", \"ve several implementations depending on the arguments) are used by the microservices that want to re\", \"ceive events. This method has two arguments. The first is the integration event to subscribe to (Int\", \"egrationEvent). The second argument is the integration event handler (or callback method), named IIn\", \"tegrationEventHandler&lt;T&gt;, to be executed when the receiver microservice gets that integration \", \"event message.\\n\\n## Additional resources\\n\\nSome production-ready messaging solutions:\\n\\n- Azure Service\", \" Bus https://learn.microsoft.com/azure/service-bus-messaging/\\n- NServiceBus\\n\\nhttps://particular.net/\", \"nservicebus\\n\\n- MassTransit https://masstransit-project.com/\\n\\n## Implementing an event bus with Rabbi\", \"tMQ for the development or test environment\\n\\nWe should start by saying that if you create your custo\", \"m event bus based on RabbitMQ running in a container, as the eShopOnContainers application does, it \", \"should be used only for your development and test environments. Don't use it for your production env\", \"ironment, unless you are building it as a part of a production-ready service bus as described in the\", \" Additional resources section below. A simple custom event bus might be missing many production-read\", \"y critical features that a commercial service bus has.\\n\\nOne of the event bus custom implementations \", \"in eShopOnContainers is basically a library using the RabbitMQ API. (There's another implementation \", \"based on Azure Service Bus.)\\n\\nThe event bus implementation with RabbitMQ lets microservices subscrib\", \"e to events, publish events, and receive events, as shown in Figure 6-21.\\n\\nMessage\\n\\nSender\\n\\nMicroser\", \"vice\\n\\nOrigin\\n\\nRabbitMQ\\n\\n(Server/Container)\\n\\nFigure 6-21. RabbitMQ implementation of an event bus\\n\\n<!\", \"-- image -->\\n\\nRabbitMQ functions as an intermediary between message publisher and subscribers, to ha\", \"ndle distribution. In the code, the EventBusRabbitMQ class implements the generic IEventBus interfac\", \"e. This implementation is based on Dependency Injection so that you can swap from this dev/test vers\", \"ion to a production version.\\n\\n```\\npublic class EventBusRabbitMQ : IEventBus, IDisposable { // Implem\", \"entation using RabbitMQ API //... }\\n```\\n\\nThe RabbitMQ implementation of a sample dev/test event bus \", \"is boilerplate code. It has to handle the connection to the RabbitMQ server and provide code for pub\", \"lishing a message event to the queues. It also has to implement a dictionary of collections of integ\", \"ration event handlers for each event type; these event types can have a different instantiation and \", \"different subscriptions for each receiver microservice, as shown in Figure 6-21.\\n\\n## Implementing a \", \"simple publish method with RabbitMQ\\n\\nThe following code is a simplified version of an event bus impl\", \"ementation for RabbitMQ, to showcase the whole scenario. You don't really handle the connection this\", \" way. To see the full implementation, see the actual code in the dotnet-architecture/eShopOnContaine\", \"rs repository.\\n\\n```\\npublic class EventBusRabbitMQ : IEventBus, IDisposable { // Member objects and o\", \"ther methods ... // ... public void Publish(IntegrationEvent @event) { var eventName = @event.GetTyp\", \"e().Name; var factory = new ConnectionFactory() { HostName = _connectionString }; using (var connect\", \"ion = factory.CreateConnection()) using (var channel = connection.CreateModel())\\n```\\n\\nMessage\\n\\nRecei\", \"vers\\n\\nMicroservice A\\n\\n```\\n{ channel.ExchangeDeclare(exchange: _brokerName, type: \\\"direct\\\"); string m\", \"essage = JsonConvert.SerializeObject(@event); var body = Encoding.UTF8.GetBytes(message); channel.Ba\", \"sicPublish(exchange: _brokerName, routingKey: eventName, basicProperties: null , body: body); } } }\\n\", \"```\\n\\nThe actual code of the Publish method in the eShopOnContainers application is improved by using\", \" a Polly retry policy, which retries the task some times in case the RabbitMQ container is not ready\", \". This scenario can occur when docker-compose is starting the containers; for example, the RabbitMQ \", \"container might start more slowly than the other containers.\\n\\nAs mentioned earlier, there are many p\", \"ossible configurations in RabbitMQ, so this code should be used only for dev/test environments.\\n\\n## \", \"Implementing the subscription code with the RabbitMQ API\\n\\nAs with the publish code, the following co\", \"de is a simplification of part of the event bus implementation for RabbitMQ. Again, you usually do n\", \"ot need to change it unless you are improving it.\\n\\n```\\npublic class EventBusRabbitMQ : IEventBus, ID\", \"isposable { // Member objects and other methods ... // ... public void Subscribe<T, TH>() where T : \", \"IntegrationEvent where TH : IIntegrationEventHandler<T> { var eventName = _subsManager.GetEventKey<T\", \">(); var containsKey = _subsManager.HasSubscriptionsForEvent(eventName); if (!containsKey) { if (!_p\", \"ersistentConnection.IsConnected) { _persistentConnection.TryConnect(); } using (var channel = _persi\", \"stentConnection.CreateModel()) { channel.QueueBind(queue: _queueName, exchange: BROKER_NAME, routing\", \"Key: eventName); } } _subsManager.AddSubscription<T, TH>(); } }\\n```\\n\\nEach event type has a related c\", \"hannel to get events from RabbitMQ. You can then have as many event handlers per channel and event t\", \"ype as needed.\\n\\nThe Subscribe method accepts an IIntegrationEventHandler object, which is like a cal\", \"lback method in the current microservice, plus its related IntegrationEvent object. The code then ad\", \"ds that event handler to the list of event handlers that each integration event type can have per cl\", \"ient microservice. If the client code has not already been subscribed to the event, the code creates\", \" a channel for the event type so it can receive events in a push style from RabbitMQ when that event\", \" is published from any other service.\\n\\nAs mentioned above, the event bus implemented in eShopOnConta\", \"iners has only an educational purpose, since it only handles the main scenarios, so it's not ready f\", \"or production.\\n\\nFor production scenarios check the additional resources below, specific for RabbitMQ\", \", and the Implementing event-based communication between microservices section.\\n\\n## Additional resou\", \"rces\\n\\nA production-ready solution with support for RabbitMQ.\\n\\n- NServiceBus - Fully-supported commer\", \"cial service bus with advanced management and monitoring tooling for .NET https://particular.net/\\n- \", \"EasyNetQ - Open Source .NET API client for RabbitMQ https://easynetq.com/\\n- MassTransit - Free, open\", \"-source distributed application framework for .NET https://masstransit-project.com/\\n- Rebus - Open s\", \"ource .NET Service Bus https://github.com/rebus-org/Rebus\\n\\n## Subscribing to events\\n\\nThe first step \", \"for using the event bus is to subscribe the microservices to the events they want to receive. That f\", \"unctionality should be done in the receiver microservices.\\n\\nThe following simple code shows what eac\", \"h receiver microservice needs to implement when starting the service (that is, in the Startup class)\", \" so it subscribes to the events it needs. In this case, the basketapi microservice needs to subscrib\", \"e to ProductPriceChangedIntegrationEvent and the OrderStartedIntegrationEvent messages.\\n\\nFor instanc\", \"e, when subscribing to the ProductPriceChangedIntegrationEvent event, that makes the basket microser\", \"vice aware of any changes to the product price and lets it warn the user about the change if that pr\", \"oduct is in the user's basket.\\n\\n```\\nvar eventBus = app.ApplicationServices.GetRequiredService<IEvent\", \"Bus>(); eventBus.Subscribe<ProductPriceChangedIntegrationEvent,\\n```\\n\\n```\\nProductPriceChangedIntegrat\", \"ionEventHandler>(); eventBus.Subscribe<OrderStartedIntegrationEvent, OrderStartedIntegrationEventHan\", \"dler>();\\n```\\n\\nAfter this code runs, the subscriber microservice will be listening through RabbitMQ c\", \"hannels. When any message of type ProductPriceChangedIntegrationEvent arrives, the code invokes the \", \"event handler that is passed to it and processes the event.\\n\\n## Publishing events through the event \", \"bus\\n\\nFinally, the message sender (origin microservice) publishes the integration events with code si\", \"milar to the following example. (This approach is a simplified example that does not take atomicity \", \"into account.) You would implement similar code whenever an event must be propagated across multiple\", \" microservices, usually right after committing data or transactions from the origin microservice.\\n\\nF\", \"irst, the event bus implementation object (based on RabbitMQ or based on a service bus) would be inj\", \"ected at the controller constructor, as in the following code:\\n\\n```\\n[Route(\\\"api/v1/[controller]\\\")] p\", \"ublic class CatalogController : ControllerBase { private readonly CatalogContext _context; private r\", \"eadonly IOptionsSnapshot<Settings> _settings; private readonly IEventBus _eventBus; public CatalogCo\", \"ntroller(CatalogContext context, IOptionsSnapshot<Settings> settings, IEventBus eventBus) { _context\", \" = context; _settings = settings; _eventBus = eventBus; } // ... }\\n```\\n\\nThen you use it from your co\", \"ntroller's methods, like in the UpdateProduct method:\\n\\n```\\n[Route(\\\"items\\\")] [HttpPost] public async \", \"Task<IActionResult> UpdateProduct([FromBody]CatalogItem product) { var item = await _context.Catalog\", \"Items.SingleOrDefaultAsync( i => i.Id == product.Id); // ... if (item.Price != product.Price) { var \", \"oldPrice = item.Price; item.Price = product.Price; _context.CatalogItems.Update(item); var @event = \", \"new ProductPriceChangedIntegrationEvent(item.Id, item.Price, oldPrice); // Commit changes in origina\", \"l transaction await _context.SaveChangesAsync(); // Publish integration event to the event bus // (R\", \"abbitMQ or a service bus underneath)\\n```\\n\\n```\\n_eventBus.Publish(@event); // ... } // ... }\\n```\\n\\nIn t\", \"his case, since the origin microservice is a simple CRUD microservice, that code is placed right int\", \"o a Web API controller.\\n\\nIn more advanced microservices, like when using CQRS approaches, it can be \", \"implemented in the CommandHandler class, within the Handle() method.\\n\\n## Designing atomicity and res\", \"iliency when publishing to the event bus\\n\\nWhen you publish integration events through a distributed \", \"messaging system like your event bus, you have the problem of atomically updating the original datab\", \"ase and publishing an event (that is, either both operations complete or none of them). For instance\", \", in the simplified example shown earlier, the code commits data to the database when the product pr\", \"ice is changed and then publishes a ProductPriceChangedIntegrationEvent message. Initially, it might\", \" look essential that these two operations be performed atomically. However, if you are using a distr\", \"ibuted transaction involving the database and the message broker, as you do in older systems like Mi\", \"crosoft Message Queuing (MSMQ), this approach is not recommended for the reasons described by the CA\", \"P theorem.\\n\\nBasically, you use microservices to build scalable and highly available systems. Simplif\", \"ying somewhat, the CAP theorem says that you cannot build a (distributed) database (or a microservic\", \"e that owns its model) that's continually available, strongly consis tent, and tolerant to any parti\", \"tion. You must choose two of these three properties.\\n\\nIn microservices-based architectures, you shou\", \"ld choose availability and tolerance, and you should de-emphasize strong consistency. Therefore, in \", \"most modern microservice-based applications, you usually do not want to use distributed transactions\", \" in messaging, as you do when you implement distributed transactions based on the Windows Distribute\", \"d Transaction Coordinator (DTC) with MSMQ.\\n\\nLet's go back to the initial issue and its example. If t\", \"he service crashes after the database is updated (in this case, right after the line of code with \\\\_\", \"context.SaveChangesAsync()), but before the integration event is published, the overall system could\", \" become inconsistent. This approach might be business critical, depending on the specific business o\", \"peration you are dealing with.\\n\\nAs mentioned earlier in the architecture section, you can have sever\", \"al approaches for dealing with this issue:\\n\\n- Using the full Event Sourcing pattern.\\n- Using transac\", \"tion log mining.\\n- Using the Outbox pattern. This is a transactional table to store the integration \", \"events (extending the local transaction).\\n\\nFor this scenario, using the full Event Sourcing (ES) pat\", \"tern is one of the best approaches, if not the best. However, in many application scenarios, you mig\", \"ht not be able to implement a full ES system. ES means storing only domain events in your transactio\", \"nal database, instead of storing current state\\n\\ndata. Storing only domain events can have great bene\", \"fits, such as having the history of your system available and being able to determine the state of y\", \"our system at any moment in the past. However, implementing a full ES system requires you to rearchi\", \"tect most of your system and introduces many other complexities and requirements. For example, you w\", \"ould want to use a database specifically made for event sourcing, such as Event Store, or a document\", \"-oriented database such as Azure Cosmos DB, MongoDB, Cassandra, CouchDB, or RavenDB. ES is a great a\", \"pproach for this problem, but not the easiest solution unless you are already familiar with event so\", \"urcing.\\n\\nThe option to use transaction log mining initially looks transparent. However, to use this \", \"approach, the microservice has to be coupled to your RDBMS transaction log, such as the SQL Server t\", \"ransaction log. This approach is probably not desirable. Another drawback is that the low-level upda\", \"tes recorded in the transaction log might not be at the same level as your high-level integration ev\", \"ents. If so, the process of reverse-engineering those transaction log operations can be difficult.\\n\\n\", \"A balanced approach is a mix of a transactional database table and a simplified ES pattern. You can \", \"use a state such as 'ready to publish the event,' which you set in the original event when you commi\", \"t it to the integration events table. You then try to publish the event to the event bus. If the pub\", \"lishevent action succeeds, you start another transaction in the origin service and move the state fr\", \"om 'ready to publish the event' to 'event already published.'\\n\\nIf the publish-event action in the ev\", \"ent bus fails, the data still will not be inconsistent within the origin microservice -it is still m\", \"arked as 'ready to publish the event,' and with respect to the rest of the services, it will eventua\", \"lly be consistent. You can always have background jobs checking the state of the transactions or int\", \"egration events. If the job finds an event in the 'ready to publish the event' state, it can try to \", \"republish that event to the event bus.\\n\\nNotice that with this approach, you are persisting only the \", \"integration events for each origin microservice, and only the events that you want to communicate to\", \" other microservices or external systems. In contrast, in a full ES system, you store all domain eve\", \"nts as well.\\n\\nTherefore, this balanced approach is a simplified ES system. You need a list of integr\", \"ation events with their current state ('ready to publish' versus 'published'). But you only need to \", \"implement these states for the integration events. And in this approach, you do not need to store al\", \"l your domain data as events in the transactional database, as you would in a full ES system.\\n\\nIf yo\", \"u are already using a relational database, you can use a transactional table to store integration ev\", \"ents. To achieve atomicity in your application, you use a two-step process based on local transactio\", \"ns. Basically, you have an IntegrationEvent table in the same database where you have your domain en\", \"tities. That table works as an insurance for achieving atomicity so that you include persisted integ\", \"ration events into the same transactions that are committing your domain data.\\n\\nStep by step, the pr\", \"ocess goes like this:\\n\\n1. The application begins a local database transaction.\\n2. It then updates th\", \"e state of your domain entities and inserts an event into the integration event table.\\n3. Finally, i\", \"t commits the transaction, so you get the desired atomicity and then\\n\\nUpdate product\\n\\nProductPriceCh\", \"anged\\n\\nRaise\\n\\nUl business warning\\n\\n5\\n\\nBasket\\n\\n, microservice\\n\\nWhen implementing the steps of publish\", \"ing the events, you have these choices:\\n\\n(Publish/Susbcribe channel)\\n\\n- Publish the integration even\", \"t right after committing the transaction and use another local transaction to mark the events in the\", \" table as being published. Then, use the table just as an artifact to track the integration events i\", \"n case of issues in the remote microservices, and perform compensatory actions based on the stored i\", \"ntegration events. ----\\n\\nProduct Table\\n\\nID\\n\\nName\\n\\nPrice\\n\\n//etc.\\n\\nEventLog Table\\n\\n- Use the table as \", \"a kind of queue. A separate application thread or process queries the integration event table, publi\", \"shes the events to the event bus, and then uses a local transaction to mark the events as published.\", \"\\n\\nFigure 6-22 shows the architecture for the first of these approaches.\\n\\nFigure 6-22. Atomicity when\", \" publishing events to the event bus\\n\\n<!-- image -->\\n\\nThe approach illustrated in Figure 6-22 is miss\", \"ing an additional worker microservice that is in charge of checking and confirming the success of th\", \"e published integration events. In case of failure, that additional checker worker microservice can \", \"read events from the table and republish them, that is, repeat step number 2.\\n\\nAbout the second appr\", \"oach: you use the EventLog table as a queue and always use a worker microservice to publish the mess\", \"ages. In that case, the process is like that shown in Figure 6-23. This shows an additional microser\", \"vice, and the table is the single source when publishing events.\\n\\n4. You publish the event somehow (\", \"next).\\n\\nUpdate\\n\\nProduct\\n\\nProduct table\\n\\nID\\n\\nName\\n\\nPrice\\n\\n//etc\\n\\nK\\n\\nRaise r, Ul Business\\n\\nwarning\\n\\nBa\", \"sket\\n\\nFigure 6-23. Atomicity when publishing events to the event bus with a worker microservice\\n\\n<!-\", \"- image -->\\n\\nFor simplicity, the eShopOnContainers sample uses the first approach (with no additiona\", \"l processes or checker microservices) plus the event bus. However, the eShopOnContainers sample is n\", \"ot handling all possible failure cases. In a real application deployed to the cloud, you must embrac\", \"e the fact that issues will arise eventually, and you must implement that check and resend logic. Us\", \"ing the table as a queue can be more effective than the first approach if you have that table as a s\", \"ingle source of events when publishing them (with the worker) through the event bus.\\n\\n## Implementin\", \"g atomicity when publishing integration events through the event bus\\n\\nThe following code shows how y\", \"ou can create a single transaction involving multiple DbContext objects -one context related to the \", \"original data being updated, and the second context related to the IntegrationEventLog table.\\n\\nThe t\", \"ransaction in the example code below will not be resilient if connections to the database have any i\", \"ssue at the time when the code is running. This can happen in cloud-based systems like Azure SQL DB,\", \" which might move databases across servers. For implementing resilient transactions across multiple \", \"contexts, see the Implementing resilient Entity Framework Core SQL connections section later in this\", \" guide.\\n\\nFor clarity, the following example shows the whole process in a single piece of code. Howev\", \"er, the eShopOnContainers implementation is refactored and splits this logic into multiple classes s\", \"o it's easier to maintain.\\n\\n```\\n// Update Product from the Catalog microservice // public async Task\", \"<IActionResult> UpdateProduct([FromBody]CatalogItem productToUpdate) { var catalogItem = await _cata\", \"logContext.CatalogItems.SingleOrDefaultAsync(i => i.Id == productToUpdate.Id);\\n```\\n\\n```\\nif (catalogI\", \"tem == null ) return NotFound(); bool raiseProductPriceChangedEvent = false ; IntegrationEvent price\", \"ChangedEvent = null ; if (catalogItem.Price != productToUpdate.Price) raiseProductPriceChangedEvent \", \"= true ; if (raiseProductPriceChangedEvent) // Create event if price has changed { var oldPrice = ca\", \"talogItem.Price; priceChangedEvent = new ProductPriceChangedIntegrationEvent(catalogItem.Id, product\", \"ToUpdate.Price, oldPrice); } // Update current product catalogItem = productToUpdate; // Just save t\", \"he updated product if the Product's Price hasn't changed. if (!raiseProductPriceChangedEvent) { awai\", \"t _catalogContext.SaveChangesAsync(); } else // Publish to event bus only if product price changed {\", \" // Achieving atomicity between original DB and the IntegrationEventLog // with a local transaction \", \"using (var transaction = _catalogContext.Database.BeginTransaction()) { _catalogContext.CatalogItems\", \".Update(catalogItem); await _catalogContext.SaveChangesAsync(); await _integrationEventLogService.Sa\", \"veEventAsync(priceChangedEvent); transaction.Commit(); } // Publish the integration event through th\", \"e event bus _eventBus.Publish(priceChangedEvent); _integrationEventLogService.MarkEventAsPublishedAs\", \"ync( priceChangedEvent); } return Ok(); }\\n```\\n\\nAfter the ProductPriceChangedIntegrationEvent integra\", \"tion event is created, the transaction that stores the original domain operation (update the catalog\", \" item) also includes the persistence of the event in the EventLog table. This makes it a single tran\", \"saction, and you will always be able to check whether event messages were sent.\\n\\nThe event log table\", \" is updated atomically with the original database operation, using a local transaction against the s\", \"ame database. If any of the operations fail, an exception is thrown and the transaction rolls back a\", \"ny completed operation, thus maintaining consistency between the domain operations and the event mes\", \"sages saved to the table.\\n\\n## Receiving messages from subscriptions: event handlers in receiver micr\", \"oservices\\n\\nIn addition to the event subscription logic, you need to implement the internal code for \", \"the integration event handlers (like a callback method). The event handler is where you specify wher\", \"e the event messages of a certain type will be received and processed.\\n\\nAn event handler first recei\", \"ves an event instance from the event bus. Then it locates the component to be processed related to t\", \"hat integration event, propagating and persisting the event as a change in state in the receiver mic\", \"roservice. For example, if a ProductPriceChanged event originates in the catalog microservice, it is\", \" handled in the basket microservice and changes the state in this receiver basket microservice as we\", \"ll, as shown in the following code.\\n\\n```\\nnamespace Microsoft.eShopOnContainers.Services.Basket.API.I\", \"ntegrationEvents.EventHandling { public class ProductPriceChangedIntegrationEventHandler : IIntegrat\", \"ionEventHandler<ProductPriceChangedIntegrationEvent> { private readonly IBasketRepository _repositor\", \"y; public ProductPriceChangedIntegrationEventHandler( IBasketRepository repository) { _repository = \", \"repository; } public async Task Handle(ProductPriceChangedIntegrationEvent @event) { var userIds = a\", \"wait _repository.GetUsers(); foreach (var id in userIds) { var basket = await _repository.GetBasket(\", \"id); await UpdatePriceInBasketItems(@event.ProductId, @event.NewPrice, basket); } } private async Ta\", \"sk UpdatePriceInBasketItems(int productId, decimal newPrice, CustomerBasket basket) { var itemsToUpd\", \"ate = basket?.Items?.Where(x => int.Parse(x.ProductId) == productId).ToList(); if (itemsToUpdate != \", \"null ) { foreach (var item in itemsToUpdate) { if (item.UnitPrice != newPrice) { var originalPrice =\", \" item.UnitPrice; item.UnitPrice = newPrice; item.OldUnitPrice = originalPrice; } } await _repository\", \".UpdateBasket(basket); } } } }\\n```\\n\\n- \\u2192\\n\\nA Not secure host.docker.internal:5104/basket\\n\\n[eShop]\\n\\non \", \"containers\\n\\n+\\n\\nThe event handler needs to verify whether the product exists in any of the basket ins\", \"tances. It also updates the item price for each related basket line item. Finally, it creates an ale\", \"rt to be displayed to the user about the price change, as shown in Figure 6-24.\\n\\n[ SHOPPING BAG ]\\n\\n.\", \"NET BLACK &amp; WHITE MUG\\n\\nS10.00 - 1 +\\n\\nNote that the price of this article changed in our Catalog.\", \" The old price when you\\n\\noriginally added it to the basket was S 8.5\\n\\nFigure 6-24. Displaying an ite\", \"m price change in a basket, as communicated by integration events\\n\\n<!-- image -->\\n\\n## Idempotency in\", \" update message events\\n\\nAn important aspect of update message events is that a failure at any point \", \"in the communication should cause the message to be retried. Otherwise a background task might try t\", \"o publish an event that has already been published, creating a race condition. Make sure that the up\", \"dates are either idempotent or that they provide enough information to ensure that you can detect a \", \"duplicate, discard it, and send back only one response.\\n\\nAs noted earlier, idempotency means that an\", \" operation can be performed multiple times without changing the result. In a messaging environment, \", \"as when communicating events, an event is idempotent if it can be delivered multiple times without c\", \"hanging the result for the receiver microservice. This may be necessary because of the nature of the\", \" event itself, or because of the way the system handles the event. Message idempotency is important \", \"in any application that uses messaging, not just in applications that implement the event bus patter\", \"n.\\n\\nAn example of an idempotent operation is a SQL statement that inserts data into a table only if \", \"that data is not already in the table. It does not matter how many times you run that insert SQL sta\", \"tement; the result will be the same -the table will contain that data. Idempotency like this can als\", \"o be necessary when dealing with messages if the messages could potentially be sent and therefore eS\", \"hopOnContainers - SPA\\n\\ndemouser@microsoft.com\\n\\n0\\n\\nprocessed more than once. For instance, if retry l\", \"ogic causes a sender to send exactly the same message more than once, you need to make sure that it \", \"is idempotent.\\n\\nIt is possible to design idempotent messages. For example, you can create an event t\", \"hat says 'set the product price to $25' instead of 'add $5 to the product price.' You could safely p\", \"rocess the first message any number of times and the result will be the same. That is not true for t\", \"he second message. But even in the first case, you might not want to process the first event, becaus\", \"e the system could also have sent a newer price-change event and you would be overwriting the new pr\", \"ice.\\n\\nAnother example might be an ordercompleted event that's propagated to multiple subscribers. Th\", \"e app has to make sure that order information is updated in other systems only once, even if there a\", \"re duplicated message events for the same order-completed event.\\n\\nIt is convenient to have some kind\", \" of identity per event so that you can create logic that enforces that each event is processed only \", \"once per receiver.\\n\\nSome message processing is inherently idempotent. For example, if a system gener\", \"ates image thumbnails, it might not matter how many times the message about the generated thumbnail \", \"is processed; the outcome is that the thumbnails are generated and they are the same every time. On \", \"the other hand, operations such as calling a payment gateway to charge a credit card may not be idem\", \"potent at all. In these cases, you need to ensure that processing a message multiple times has the e\", \"ffect that you expect.\\n\\n## Additional resources\\n\\n- Honoring message idempotency https://learn.micros\", \"oft.com/previous-versions/msp-n-p/jj591565(v=pandp.10)#honoringmessage-idempotency\\n\\n## Deduplicating\", \" integration event messages\\n\\nYou can make sure that message events are sent and processed only once \", \"per subscriber at different levels. One way is to use a deduplication feature offered by the messagi\", \"ng infrastructure you are using. Another is to implement custom logic in your destination microservi\", \"ce. Having validations at both the transport level and the application level is your best bet.\\n\\n## D\", \"eduplicating message events at the EventHandler level\\n\\nOne way to make sure that an event is process\", \"ed only once by any receiver is by implementing certain logic when processing the message events in \", \"event handlers. For example, that is the approach used in the eShopOnContainers application, as you \", \"can see in the source code of the\\n\\nUserCheckoutAcceptedIntegrationEventHandler class when it receive\", \"s a\\n\\nUserCheckoutAcceptedIntegrationEvent integration event. (In this case, the CreateOrderCommand i\", \"s wrapped with an IdentifiedCommand, using the eventMsg.RequestId as an identifier, before sending i\", \"t to the command handler).\\n\\n## Deduplicating messages when using RabbitMQ\\n\\nWhen intermittent network\", \" failures happen, messages can be duplicated, and the message receiver must be ready to handle these\", \" duplicated messages. If possible, receivers should handle messages in an idempotent way, which is b\", \"etter than explicitly handling them with deduplication.\\n\\nAccording to the RabbitMQ documentation , '\", \"If a message is delivered to a consumer and then requeued (because it was not acknowledged before th\", \"e consumer connection dropped, for example) then RabbitMQ will set the redelivered flag on it when i\", \"t is delivered again (whether to the same consumer or a different one).\\n\\nIf the 'redelivered' flag i\", \"s set, the receiver must take that into account, because the message might already have been process\", \"ed. But that is not guaranteed; the message might never have reached the receiver after it left the \", \"message broker, perhaps because of network issues. On the other hand, if the 'redelivered' flag is n\", \"ot set, it is guaranteed that the message has not been sent more than once. Therefore, the receiver \", \"needs to deduplicate messages or process messages in an idempotent way only if the 'redelivered' fla\", \"g is set in the message.\\n\\n## Additional resources\\n\\n- Forked eShopOnContainers using NServiceBus (Par\", \"ticular Software) https://go.particular.net/eShopOnContainers\\n- Event Driven Messaging https://patte\", \"rns.arcitura.com/soa-patterns/design\\\\_patterns/event\\\\_driven\\\\_messaging\\n- Jimmy Bogard. Refactoring \", \"Towards Resilience: Evaluating Coupling https://jimmybogard.com/refactoring-towards-resilience-evalu\", \"ating-coupling/\\n- Publish-Subscribe channel https://www.enterpriseintegrationpatterns.com/patterns/m\", \"essaging/PublishSubscribeChannel. html\\n- Communicating Between Bounded Contexts https://learn.micros\", \"oft.com/previous-versions/msp-n-p/jj591572(v=pandp.10)\\n\\n\\u2022\\n\\nEventual Consistency https://en.wikipedia\", \".org/wiki/Eventual\\\\_consistency\\n\\n- Philip Brown. Strategies for Integrating Bounded Contexts https:/\", \"/www.culttt.com/2014/11/26/strategies-integrating-bounded-contexts/\\n- Chris Richardson. Developing T\", \"ransactional Microservices Using Aggregates, Event Sourcing and CQRS - Part 2 https://www.infoq.com/\", \"articles/microservices-aggregates-events-cqrs-part-2-richardson\\n- Chris Richardson. Event Sourcing p\", \"attern https://microservices.io/patterns/data/event-sourcing.html\\n- Introducing Event Sourcing https\", \"://learn.microsoft.com/previous-versions/msp-n-p/jj591559(v=pandp.10)\\n\\n- Event Store database . Offi\", \"cial site. https://geteventstore.com/\\n- Patrick Nommensen. Event-Driven Data Management for Microser\", \"vices https://dzone.com/articles/event-driven-data-management-for-microservices-1\\n- The CAP Theorem \", \"https://en.wikipedia.org/wiki/CAP\\\\_theorem\\n- What is CAP Theorem? https://www.quora.com/What-Is-CAP-\", \"Theorem-1\\n- Data Consistency Primer https://learn.microsoft.com/previous-versions/msp-n-p/dn589800(v\", \"=pandp.10)\\n- Rick Saling. The CAP Theorem: Why 'Everything is Different' with the Cloud and Internet\", \" https://learn.microsoft.com/archive/blogs/rickatmicrosoft/the-cap-theorem-why-everythingis-differen\", \"t-with-the-cloud-and-internet/\\n- Eric Brewer. CAP Twelve Years Later: How the 'Rules' Have Changed h\", \"ttps://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed\\n- CAP, PACELC, and M\", \"icroservices https://ardalis.com/cap-pacelc-and-microservices/\\n- Azure Service Bus. Brokered Messagi\", \"ng: Duplicate Detection https://github.com/microsoftarchive/msdn-code-gallerymicrosoft/tree/master/W\", \"indows%20Azure%20Product%20Team/Brokered%20Messaging%20 Duplicate%20Detection\\n- Reliability Guide (R\", \"abbitMQ documentation) https://www.rabbitmq.com/reliability.html#consumer\\n\\n## Testing ASP.NET Core s\", \"ervices and web apps\\n\\nControllers are a central part of any ASP.NET Core API service and ASP.NET MVC\", \" Web application. As such, you should have confidence they behave as intended for your application. \", \"Automated tests can provide you with this confidence and can detect errors before they reach product\", \"ion.\\n\\nYou need to test how the controller behaves based on valid or invalid inputs, and test control\", \"ler responses based on the result of the business operation it performs. However, you should have th\", \"ese types of tests for your microservices:\\n\\n- Unit tests. These tests ensure that individual compone\", \"nts of the application work as expected. Assertions test the component API.\\n- Integration tests. The\", \"se tests ensure that component interactions work as expected against external artifacts like databas\", \"es. Assertions can test component API, UI, or the side effects of actions like database I/O, logging\", \", etc.\\n\\n- Functional tests for each microservice. These tests ensure that the application works as e\", \"xpected from the user's perspective.\\n- Service tests. These tests ensure that end-to-end service use\", \" cases, including testing multiple services at the same time, are tested. For this type of testing, \", \"you need to prepare the environment first. In this case, it means starting the services (for example\", \", by using dockercompose up).\\n\\n## Implementing unit tests for ASP.NET Core Web APIs\\n\\nUnit testing in\", \"volves testing a part of an application in isolation from its infrastructure and dependencies. When \", \"you unit test controller logic, only the content of a single action or method is tested, not the beh\", \"avior of its dependencies or of the framework itself. Unit tests do not detect issues in the interac\", \"tion between components -that is the purpose of integration testing.\\n\\nAs you unit test your controll\", \"er actions, make sure you focus only on their behavior. A controller unit test avoids things like fi\", \"lters, routing, or model binding (the mapping of request data to a ViewModel or DTO). Because they f\", \"ocus on testing just one thing, unit tests are generally simple to write and quick to run. A well-wr\", \"itten set of unit tests can be run frequently without much overhead.\\n\\nUnit tests are implemented bas\", \"ed on test frameworks like xUnit.net, MSTest, Moq, or NUnit. For the eShopOnContainers sample applic\", \"ation, we are using xUnit.\\n\\nWhen you write a unit test for a Web API controller, you instantiate the\", \" controller class directly using the new keyword in C#, so that the test will run as fast as possibl\", \"e. The following example shows how to do this when using xUnit as the Test framework.\\n\\n```\\n[Fact] pu\", \"blic async Task Get_order_detail_success() { //Arrange var fakeOrderId = \\\"12\\\"; var fakeOrder = GetFa\", \"keOrder(); //... //Act var orderController = new OrderController( _orderServiceMock.Object, _basketS\", \"erviceMock.Object, _identityParserMock.Object); orderController.ControllerContext.HttpContext = _con\", \"textMock.Object; var actionResult = await orderController.Detail(fakeOrderId); //Assert var viewResu\", \"lt = Assert.IsType<ViewResult>(actionResult); Assert.IsAssignableFrom<Order>(viewResult.ViewData.Mod\", \"el); }\\n```\\n\\n## Implementing integration and functional tests for each microservice\\n\\nAs noted, integr\", \"ation tests and functional tests have different purposes and goals. However, the way you implement b\", \"oth when testing ASP.NET Core controllers is similar, so in this section we concentrate on integrati\", \"on tests.\\n\\nIntegration testing ensures that an application's components function correctly when asse\", \"mbled. ASP.NET Core supports integration testing using unit test frameworks and a built-in test web \", \"host that can be used to handle requests without network overhead.\\n\\nUnlike unit testing, integration\", \" tests frequently involve application infrastructure concerns, such as a database, file system, netw\", \"ork resources, or web requests and responses. Unit tests use fakes or mock objects in place of these\", \" concerns. But the purpose of integration tests is to confirm that the system works as expected with\", \" these systems, so for integration testing you do not use fakes or mock objects. Instead, you includ\", \"e the infrastructure, like database access or service invocation from other services.\\n\\nBecause integ\", \"ration tests exercise larger segments of code than unit tests, and because integration tests rely on\", \" infrastructure elements, they tend to be orders of magnitude slower than unit tests. Thus, it is a \", \"good idea to limit how many integration tests you write and run.\\n\\nASP.NET Core includes a built-in t\", \"est web host that can be used to handle HTTP requests without network overhead, meaning that you can\", \" run those tests faster than when using a real web host. The test web host (TestServer) is available\", \" in a NuGet component as Microsoft.AspNetCore.TestHost. It can be added to integration test projects\", \" and used to host ASP.NET Core applications.\\n\\nAs you can see in the following code, when you create \", \"integration tests for ASP.NET Core controllers, you instantiate the controllers through the test hos\", \"t. This functionality is comparable to an HTTP request, but it runs faster.\\n\\n```\\npublic class PrimeW\", \"ebDefaultRequestShould { private readonly TestServer _server; private readonly HttpClient _client; p\", \"ublic PrimeWebDefaultRequestShould() { // Arrange _server = new TestServer( new WebHostBuilder() .Us\", \"eStartup<Startup>()); _client = _server.CreateClient(); } [Fact] public async Task ReturnHelloWorld(\", \") { // Act var response = await _client.GetAsync(\\\"/\\\"); response.EnsureSuccessStatusCode(); var respo\", \"nseString = await response.Content.ReadAsStringAsync(); // Assert Assert.Equal(\\\"Hello World!\\\", respo\", \"nseString); } }\\n```\\n\\n## Additional resources\\n\\n- Steve Smith. Testing controllers (ASP.NET Core) http\", \"s://learn.microsoft.com/aspnet/core/mvc/controllers/testing\\n- Steve Smith. Integration testing (ASP.\", \"NET Core) https://learn.microsoft.com/aspnet/core/test/integration-tests\\n- Unit testing in .NET usin\", \"g dotnet test https://learn.microsoft.com/dotnet/core/testing/unit-testing-with-dotnet-test\\n- xUnit.\", \"net . Official site. https://xunit.net/\\n- Unit Test Basics. https://learn.microsoft.com/visualstudio\", \"/test/unit-test-basics\\n- Moq . GitHub repo. https://github.com/moq/moq\\n- NUnit . Official site. http\", \"s://nunit.org/\\n\\n## Implementing service tests on a multi-container application\\n\\nAs noted earlier, wh\", \"en you test multi-container applications, all the microservices need to be running within the Docker\", \" host or container cluster. End-to-end service tests that include multiple operations involving seve\", \"ral microservices require you to deploy and start the whole application in the Docker host by runnin\", \"g docker-compose up (or a comparable mechanism if you are using an orchestrator). Once the whole app\", \"lication and all its services is running, you can execute end-to-end integration and functional test\", \"s.\\n\\nThere are a few approaches you can use. In the docker-compose.yml file that you use to deploy th\", \"e application at the solution level you can expand the entry point to use dotnet test. You can also \", \"use another compose file that would run your tests in the image you are targeting. By using another \", \"compose file for integration tests that includes your microservices and databases on containers, you\", \" can make sure that the related data is always reset to its original state before running the tests.\", \"\\n\\nOnce the compose application is up and running, you can take advantage of breakpoints and exceptio\", \"ns if you are running Visual Studio. Or you can run the integration tests automatically in your CI p\", \"ipeline in Azure DevOps Services or any other CI/CD system that supports Docker containers.\\n\\n## Test\", \"ing in eShopOnContainers\\n\\nThe reference application (eShopOnContainers) tests were recently restruct\", \"ured and now there are four categories:\\n\\n1. Unit tests, just plain old regular unit tests, contained\", \" in the {MicroserviceName}.UnitTests projects\\n\\n1\\n\\nSolution 'eShopOnContainers-ServicesAndWebApps' (3\", \"4 of 34 projects)\\n\\nSolution Items\\n\\nSrC\\n\\nApiGateways\\n\\n2. Microservice functional/integration tests , \", \"with test cases involving the infrastructure for each microservice but isolated from the others and \", \"are contained in the {MicroserviceName}.FunctionalTests projects. Basket Catalog\\n3. Application func\", \"tional/integration tests , which focus on microservices integration, with test cases that exert seve\", \"ral microservices. These tests are located in project Application.FunctionalTests .\\n\\nWhile unit and \", \"integration tests are organized in a test folder within the microservice project, application and lo\", \"ad tests are managed separately under the root folder, as shown in Figure 6-25.\\n\\nMarketing\\n\\n5 Orderi\", \"ng\\n\\n\\u2022 Web Apps tests\\n\\nServiceTests docker-compose\\n\\nFigure 6-25. Test folder structure in eShopOnCont\", \"ainers\\n\\n<!-- image -->\\n\\nMicroservice and Application functional/integration tests are run from Visua\", \"l Studio, using the regular tests runner, but first you need to start the required infrastructure se\", \"rvices, with a set of dockercompose files contained in the solution test folder:\\n\\n## docker-compose-\", \"test.yml\\n\\n```\\nversion : '3.4' services : redis.data : image : redis:alpine rabbitmq : image : rabbit\", \"mq:3-management-alpine sqldata :\\n```\\n\\nP\\n\\nP\\n\\n```\\nimage : mcr.microsoft.com/mssql/server:2017-latest n\", \"osqldata : image : mongo\\n```\\n\\n## docker-compose-test.override.yml\\n\\n```\\nversion : '3.4' services : re\", \"dis.data : ports : -\\\"6379:6379\\\" rabbitmq : ports : -\\\"15672:15672\\\" -\\\"5672:5672\\\" sqldata : environment\", \" : -SA_PASSWORD=Pass@word -ACCEPT_EULA=Y ports : -\\\"5433:1433\\\" nosqldata : ports : -\\\"27017:27017\\\"\\n```\", \"\\n\\nSo, to run the functional/integration tests you must first run this command, from the solution tes\", \"t folder:\\n\\ndocker-compose -f docker-compose-test.yml -f docker-compose-test.override.yml up\\n\\nAs you \", \"can see, these docker-compose files only start the Redis, RabbitMQ, SQL Server, and MongoDB microser\", \"vices.\\n\\n## Additional resources\\n\\n- Unit &amp; Integration testing on the eShopOnContainers https://g\", \"ithub.com/dotnet-architecture/eShopOnContainers/wiki/Unit-and-integrationtesting\\n- Load testing on t\", \"he eShopOnContainers https://github.com/dotnet-architecture/eShopOnContainers/wiki/Load-testing\\n\\n## \", \"Implement background tasks in microservices with IHostedService and the BackgroundService class\\n\\nBac\", \"kground tasks and scheduled jobs are something you might need to use in any application, whether or \", \"not it follows the microservices architecture pattern. The difference when using a microservices arc\", \"hitecture is that you can implement the background task in a separate process/container for hosting \", \"so you can scale it down/up based on your need.\\n\\nImplementing background tasks with HostedService in\", \" NET Core\\n\\nAs optional container\\n\\nFrom a generic point of view, in .NET we called these type of task\", \"s Hosted Services , because they are services/logic that you host within your host/application/micro\", \"service. Note that in this case, the hosted service simply means a class with the background task lo\", \"gic.\\n\\nHttp\\n\\n(*) In\\n\\n. NET Core:\\n\\nIwebHost implemented in Microsoft. AspNetCore.Hosting\\n\\nHostedServic\", \"e implemented in Microsoft. Extensions.Hosting\\n\\nSince .NET Core 2.0, the framework provides a new in\", \"terface named IHostedService helping you to easily implement hosted services. The basic idea is that\", \" you can register multiple background tasks (hosted services) that run in the background while your \", \"web host or host is running, as shown in the image 6-26. MylHostedServiceC 2 Background task\\n\\nMylHos\", \"tedService 'n? Background task\\n\\nMylHostedService 'n? / Background task\\n\\nFigure 6-26. Using IHostedSe\", \"rvice in a WebHost vs. a Host\\n\\n<!-- image -->\\n\\nASP.NET Core 1.x and 2.x support IWebHost for backgro\", \"und processes in web apps. .NET Core 2.1 and later versions support IHost for background processes w\", \"ith plain console apps. Note the difference made between WebHost and Host.\\n\\nA WebHost (base class im\", \"plementing IWebHost) in ASP.NET Core 2.0 is the infrastructure artifact you use to provide HTTP serv\", \"er features to your process, such as when you're implementing an MVC web app or Web API service. It \", \"provides all the new infrastructure goodness in ASP.NET Core, enabling you to use dependency injecti\", \"on, insert middlewares in the request pipeline, and similar. The WebHost uses these very same IHoste\", \"dServices for background tasks.\\n\\nA Host (base class implementing IHost) was introduced in .NET Core \", \"2.1. Basically, a Host allows you to have a similar infrastructure than what you have with WebHost (\", \"dependency injection, hosted services, etc.), but in this case, you just want to have a simple and l\", \"ighter process as the host, with nothing related to MVC, Web API or HTTP server features.\\n\\nTherefore\", \", you can choose and either create a specialized host-process with IHost to handle the hosted servic\", \"es and nothing else, such a microservice made just for hosting the IHostedServices, or you can alter\", \"natively extend an existing ASP.NET Core WebHost, such as an existing ASP.NET Core Web API or MVC ap\", \"p.\\n\\nEach approach has pros and cons depending on your business and scalability needs. The bottom lin\", \"e is basically that if your background tasks have nothing to do with HTTP (IWebHost) you should use \", \"IHost.\\n\\n## Registering hosted services in your WebHost or Host\\n\\nLet's drill down further on the IHos\", \"tedService interface since its usage is pretty similar in a WebHost or in a Host.\\n\\nSignalR is one ex\", \"ample of an artifact using hosted services, but you can also use it for much simpler things like:\\n\\n-\", \" A background task polling a database looking for changes.\\n- A scheduled task updating some cache pe\", \"riodically.\\n- An implementation of QueueBackgroundWorkItem that allows a task to be executed on a ba\", \"ckground thread.\\n- Processing messages from a message queue in the background of a web app while sha\", \"ring common services such as ILogger.\\n- A background task started with Task.Run().\\n\\nYou can basicall\", \"y offload any of those actions to a background task that implements IHostedService.\\n\\nThe way you add\", \" one or multiple IHostedServices into your WebHost or Host is by registering them up through the Add\", \"HostedService extension method in an ASP.NET Core WebHost (or in a Host in .NET Core 2.1 and above).\", \" Basically, you have to register the hosted services within application startup in Program.cs .\\n\\n```\", \"\\n//Other DI registrations; // Register Hosted Services builder.Services.AddHostedService<GracePeriod\", \"ManagerService>(); builder.Services.AddHostedService<MyHostedServiceB>(); builder.Services.AddHosted\", \"Service<MyHostedServiceC>(); //...\\n```\\n\\nIn that code, the GracePeriodManagerService hosted service i\", \"s real code from the Ordering business microservice in eShopOnContainers, while the other two are ju\", \"st two additional samples.\\n\\nThe IHostedService background task execution is coordinated with the lif\", \"etime of the application (host or microservice, for that matter). You register tasks when the applic\", \"ation starts and you have the opportunity to do some graceful action or clean-up when the applicatio\", \"n is shutting down.\\n\\nWithout using IHostedService, you could always start a background thread to run\", \" any task. The difference is precisely at the app's shutdown time when that thread would simply be k\", \"illed without having the opportunity to run graceful clean-up actions.\\n\\n## The IHostedService interf\", \"ace\\n\\nWhen you register an IHostedService, .NET calls the StartAsync() and StopAsync() methods of you\", \"r IHostedService type during application start and stop respectively. For more details, see IHostedS\", \"ervice interface.\\n\\nAs you can imagine, you can create multiple implementations of IHostedService and\", \" register each of them in Program.cs , as shown previously. All those hosted services will be starte\", \"d and stopped along with the application/microservice.\\n\\nAs a developer, you are responsible for hand\", \"ling the stopping action of your services when StopAsync() method is triggered by the host.\\n\\n## Impl\", \"ementing IHostedService with a custom hosted service class deriving from the BackgroundService base \", \"class\\n\\nYou could go ahead and create your custom hosted service class from scratch and implement the\", \" IHostedService, as you need to do when using .NET Core 2.0 and later.\\n\\nHowever, since most backgrou\", \"nd tasks will have similar needs in regard to the cancellation tokens management and other typical o\", \"perations, there is a convenient abstract base class you can derive from, named BackgroundService (a\", \"vailable since .NET Core 2.1).\\n\\nThat class provides the main work needed to set up the background ta\", \"sk.\\n\\nThe next code is the abstract BackgroundService base class as implemented in .NET.\\n\\n```\\n// Copy\", \"right (c) .NET Foundation. Licensed under the Apache License, Version 2.0. /// <summary> /// Base cl\", \"ass for implementing a long running <see cref=\\\"IHostedService\\\" /> . /// </summary> public abstract c\", \"lass BackgroundService : IHostedService, IDisposable { private Task _executingTask; private readonly\", \" CancellationTokenSource _stoppingCts = new CancellationTokenSource(); protected abstract Task Execu\", \"teAsync(CancellationToken stoppingToken); public virtual Task StartAsync(CancellationToken cancellat\", \"ionToken) { // Store the task we're executing _executingTask = ExecuteAsync(_stoppingCts.Token); // \", \"If the task is completed then return it, // this will bubble cancellation and failure to the caller \", \"if (_executingTask.IsCompleted) { return _executingTask; } // Otherwise it's running return Task.Com\", \"pletedTask; } public virtual async Task StopAsync(CancellationToken cancellationToken) { // Stop cal\", \"led without start if (_executingTask == null ) { return ; }\\n```\\n\\n```\\ntry { // Signal cancellation to\", \" the executing method _stoppingCts.Cancel(); } finally { // Wait until the task completes or the sto\", \"p token triggers await Task.WhenAny(_executingTask, Task.Delay(Timeout.Infinite, cancellationToken))\", \"; } } public virtual void Dispose() { _stoppingCts.Cancel(); } }\\n```\\n\\nWhen deriving from the previou\", \"s abstract base class, thanks to that inherited implementation, you just need to implement the Execu\", \"teAsync() method in your own custom hosted service class, as in the following simplified code from e\", \"ShopOnContainers which is polling a database and publishing integration events into the Event Bus wh\", \"en needed.\\n\\n```\\npublic class GracePeriodManagerService : BackgroundService { private readonly ILogge\", \"r<GracePeriodManagerService> _logger; private readonly OrderingBackgroundSettings _settings; private\", \" readonly IEventBus _eventBus; public GracePeriodManagerService(IOptions<OrderingBackgroundSettings>\", \" settings, IEventBus eventBus, ILogger<GracePeriodManagerService> logger) { // Constructor's paramet\", \"ers validations... } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { _\", \"logger.LogDebug($\\\"GracePeriodManagerService is starting.\\\"); stoppingToken.Register(() => _logger.Log\", \"Debug($\\\" GracePeriod background task is stopping.\\\")); while (!stoppingToken.IsCancellationRequested)\", \" { _logger.LogDebug($\\\"GracePeriod task doing background work.\\\"); // This eShopOnContainers method is\", \" querying a database table // and publishing events into the Event Bus (RabbitMQ / ServiceBus) Check\", \"ConfirmedGracePeriodOrders(); try { await Task.Delay(_settings.CheckUpdateTime, stoppingToken); } ca\", \"tch (TaskCanceledException exception) { _logger.LogCritical(exception, \\\"TaskCanceledException Error\\\"\", \", exception.Message);\\n```\\n\\nClass diagram with a custom HostedService and related classes and interfa\", \"ces\\n\\n```\\n} } _logger.LogDebug($\\\"GracePeriod background task is stopping.\\\"); } .../... } MyHostedServ\", \"iceA class Background task |HostedService interface \\u00b7 BackgroundService base class (*)\\n```\\n\\nIn this \", \"specific case for eShopOnContainers, it's executing an application method that's querying a database\", \" table looking for orders with a specific state and when applying changes, it is publishing integrat\", \"ion events through the event bus (underneath it can be using RabbitMQ or Azure Service Bus).\\n\\n(**) I\", \"Host and BackgroundService are implemented\\n\\nOf course, you could run any other business background t\", \"ask, instead.\\n\\nBy default, the cancellation token is set with a 5 seconds timeout, although you can \", \"change that value when building your WebHost using the UseShutdownTimeout extension of the IWebHostB\", \"uilder. This means that our service is expected to cancel within 5 seconds otherwise it will be more\", \" abruptly killed.\\n\\nThe following code would be changing that time to 10 seconds.\\n\\n```\\nWebHost.Create\", \"DefaultBuilder(args) .UseShutdownTimeout(TimeSpan.FromSeconds(10))\\n```\\n\\n...\\n\\n## Summary class diagra\", \"m\\n\\nThe following image shows a visual summary of the classes and interfaces involved when implementi\", \"ng IHostedServices.\\n\\nFigure 6-27. Class diagram showing the multiple classes and interfaces related \", \"to IHostedService\\n\\n<!-- image -->\\n\\nClass diagram: IWebHost and IHost can host many services, which i\", \"nherit from BackgroundService, which implements IHostedService.\\n\\n## Deployment considerations and ta\", \"keaways\\n\\nIt is important to note that the way you deploy your ASP.NET Core WebHost or .NET Host migh\", \"t impact the final solution. For instance, if you deploy your WebHost on IIS or a regular Azure App \", \"Service, your host can be shut down because of app pool recycles. But if you are deploying your host\", \" as a container into an orchestrator like Kubernetes, you can control the assured number of live ins\", \"tances of your host. In addition, you could consider other approaches in the cloud especially made f\", \"or these scenarios, like Azure Functions. Finally, if you need the service to be running all the tim\", \"e and are deploying on a Windows Server you could use a Windows Service.\\n\\nBut even for a WebHost dep\", \"loyed into an app pool, there are scenarios like repopulating or flushing application's in -memory c\", \"ache that would be still applicable.\\n\\nThe IHostedService interface provides a convenient way to star\", \"t background tasks in an ASP.NET Core web application (in .NET Core 2.0 and later versions) or in an\", \"y process/host (starting in .NET Core 2.1 with IHost). Its main benefit is the opportunity you get w\", \"ith the graceful cancellation to clean-up the code of your background tasks when the host itself is \", \"shutting down.\\n\\n## Additional resources\\n\\n- Building a scheduled task in ASP.NET Core/Standard 2.0 ht\", \"tps://blog.maartenballiauw.be/post/2017/08/01/building-a-scheduled-cache-updater-inaspnet-core-2.htm\", \"l\\n- Implementing IHostedService in ASP.NET Core 2.0\\n\\nhttps://www.stevejgordon.co.uk/asp-net-core-2-i\", \"hostedservice\\n\\n- GenericHost Sample using ASP.NET Core 2.1\\n\\nhttps://github.com/aspnet/Hosting/tree/r\", \"elease/2.1/samples/GenericHostSample\\n\\n## Implement API Gateways with Ocelot\\n\\n## Important\\n\\nThe refer\", \"ence microservice application eShopOnContainers is currently using features provided by Envoy to imp\", \"lement the API Gateway instead of the earlier referenced Ocelot. We made this design choice because \", \"of Envoy's built -in support for the WebSocket protocol, required by the new gRPC interservice commu\", \"nications implemented in eShopOnContainers. However, we've retained this section in the guide so you\", \" can consider Ocelot as a simple, capable, and lightweight API Gateway suitable for production-grade\", \" scenarios. Also, latest Ocelot version contains a breaking change on its json schema. Consider usin\", \"g Ocelot &lt; v16.0.0, or use the key Routes instead of ReRoutes.\\n\\n## Architect and design your API \", \"Gateways\\n\\nThe following architecture diagram shows how API Gateways were implemented with Ocelot in \", \"eShopOnContainers.\\n\\nF--\\n\\n- \\u2014\\u2014\\n\\nClient apps eShop mobile app\\n\\nXamarin.Forms\\n\\nC#\\n\\nxPlat. OS:\\n\\niOS\\n\\nAnd\", \"roid\\n\\nWindows eShop traditional Web app\\n\\neShop SPA Web app\\n\\nTypeScript/Angular eShopOnContainers ref\", \"erence application\\n\\n(Development environment architecture)\\n\\nDocker Host\\n\\nIdentity microservice (STS+\", \" users)\\n\\nSQL Server database\\n\\n## Catalog microservice\\n\\n\\u00b7 0SQL Server database\\n\\nRabbitMQ\\n\\nFigure 6-28\", \". eShopOnContainers architecture with API Gateways\\n\\n<!-- image -->\\n\\nThat diagram shows how the whole\", \" application is deployed into a single Docker host or development PC with 'Docker for Windows' or 'D\", \"ocker for Mac'. However, deploying into any orchestrator would be similar, but any container in the \", \"diagram could be scaled out in the orchestrator.\\n\\nIn addition, the infrastructure assets such as dat\", \"abases, cache, and message brokers should be offloaded from the orchestrator and deployed into high \", \"available systems for infrastructure, like Azure SQL Database, Azure Cosmos DB, Azure Redis, Azure S\", \"ervice Bus, or any HA clustering solution onpremises.\\n\\nAs you can also notice in the diagram, having\", \" several API Gateways allows multiple development teams to be autonomous (in this case Marketing fea\", \"tures vs. Shopping features) when developing and deploying their microservices plus their own relate\", \"d API Gateways.\\n\\nIf you had a single monolithic API Gateway that would mean a single point to be upd\", \"ated by several development teams, which could couple all the microservices with a single part of th\", \"e application.\\n\\nGoing much further in the design, sometimes a fine-grained API Gateway can also be l\", \"imited to a single business microservice depending on the chosen architecture. Having the API Gatewa\", \"y's boundaries dictated by the business or domain will help you to get a better design.\\n\\nFor instanc\", \"e, fine granularity in the API Gateway tier can be especially useful for more advanced composite UI \", \"applications that are based on microservices, because the concept of a fine-grained API Gateway is s\", \"imilar to a UI composition service.\\n\\nWe delve into more details in the previous section Creating com\", \"posite UI based on microservices.\\n\\nAs a key takeaway, for many medium- and large-size applications, \", \"using a custom-built API Gateway product is usually a good approach, but not as a single monolithic \", \"aggregator or unique central custom API Gateway unless that API Gateway allows multiple independent \", \"configuration areas for the several development teams creating autonomous microservices.\\n\\nAPI Gatewa\", \"ys / BFF\\n\\n(Publish/Subscribe\\n\\n\\u2022\\n\\nServices\\n\\nCatalog\\n\\nBasket\\n\\nCatalog\\n\\nCatalog API\\n\\nC Connected Servic\", \"es\\n\\nIdentity\\n\\nLocation\\n\\nDependencies\\n\\n## Sample microservices/containers to reroute through the API \", \"Gateways\\n\\nAs an example, eShopOnContainers has around six internal microservice-types that have to b\", \"e published through the API Gateways, as shown in the following image.\\n\\nFigure 6-29. Microservice fo\", \"lders in eShopOnContainers solution in Visual Studio\\n\\n<!-- image -->\\n\\nAbout the Identity service, in\", \" the design it's left out of the API Gateway routing because it's the only crosscutting concern in t\", \"he system, although with Ocelot it's also possible to include it as part of the rerouting lists.\\n\\nAl\", \"l those services are currently implemented as ASP.NET Core Web API services, as you can tell from th\", \"e code. Let's focus on one of the microservices like the Catalog microservice code.\\n\\nD\\n\\nC*\\n\\nFigure 6\", \"-30. Sample Web API microservice (Catalog microservice)\\n\\n<!-- image -->\\n\\nYou can see that the Catalo\", \"g microservice is a typical ASP.NET Core Web API project with several controllers and methods like i\", \"n the following code.\\n\\n```\\n[HttpGet] [Route(\\\"items/{id:int}\\\")] [ProducesResponseType((int)HttpStatus\", \"Code.BadRequest)] [ProducesResponseType((int)HttpStatusCode.NotFound)] [ProducesResponseType( typeof\", \" (CatalogItem),(int)HttpStatusCode.OK)] public async Task<IActionResult> GetItemById(int id) { if (i\", \"d <= 0) { return BadRequest(); } var item = await _catalogContext.CatalogItems. SingleOrDefaultAsync\", \"(ci => ci.Id == id); //\\u2026 if (item != null ) { return Ok(item); } return NotFound(); }\\n```\\n\\nThe HTTP \", \"request will end up running that kind of C# code accessing the microservice database and any additio\", \"nal required action.\\n\\nRegarding the microservice URL, when the containers are deployed in your local\", \" development PC (local Docker host), each microservice's container always has an internal port (usua\", \"lly port 80) specified in its dockerfile, as in the following dockerfile:\\n\\n```\\nFROM mcr.microsoft.co\", \"m/dotnet/aspnet:7.0 AS base WORKDIR /app EXPOSE 80\\n```\\n\\nThe port 80 shown in the code is internal wi\", \"thin the Docker host, so it can't be reached by client apps.\\n\\nClient apps can access only the extern\", \"al ports (if any) published when deploying with dockercompose.\\n\\nThose external ports shouldn't be pu\", \"blished when deploying to a production environment. For this specific reason, why you want to use th\", \"e API Gateway, to avoid the direct communication between the client apps and the microservices.\\n\\nHow\", \"ever, when developing, you want to access the microservice/container directly and run it through Swa\", \"gger. That's why in eShopOnContainers, the external ports are still specified even when they won't b\", \"e used by the API Gateway or the client apps.\\n\\nHere's an example of the docker -compose.override.yml\", \" file for the Catalog microservice:\\n\\n```\\ncatalog-api : environment : -ASPNETCORE_ENVIRONMENT=Develop\", \"ment -ASPNETCORE_URLS=http://0.0.0.0:80 -ConnectionString=YOUR_VALUE -... Other Environment Variable\", \"s\\n```\\n\\n```\\nports : -\\\"5101:80\\\"   # Important: In a production environment you should remove the exter\", \"nal port (5101) kept here for microservice debugging purposes. # The API Gateway redirects and acces\", \"s through the internal port (80).\\n```\\n\\nYou can see how in the docker-compose.override.yml configurat\", \"ion the internal port for the Catalog container is port 80, but the port for external access is 5101\", \". But this port shouldn't be used by the application when using an API Gateway, only to debug, run, \", \"and test just the Catalog microservice.\\n\\nNormally, you won't be deploying with docker -compose into \", \"a production environment because the right production deployment environment for microservices is an\", \" orchestrator like Kubernetes or Service Fabric. When deploying to those environments you use differ\", \"ent configuration files where you won't publish directly any external port for the microservices but\", \", you'll always use the reverse proxy from the API Gateway.\\n\\nRun the catalog microservice in your lo\", \"cal Docker host. Either run the full eShopOnContainers solution from Visual Studio (it runs all the \", \"services in the docker-compose files), or start the Catalog microservice with the following docker-c\", \"ompose command in CMD or PowerShell positioned at the folder where the docker-compose.yml and docker\", \"-compose.override.yml are placed.\\n\\n```\\ndocker-compose run --service-ports catalog-api\\n```\\n\\nThis comm\", \"and only runs the catalog-api service container plus dependencies that are specified in the docker-c\", \"ompose.yml. In this case, the SQL Server container and RabbitMQ container.\\n\\nThen, you can directly a\", \"ccess the Catalog microservice and see its methods through the Swagger UI accessing directly through\", \" that 'external' port, in this case http://host.docker.internal:5101/swagger:\\n\\n&lt; \\u2192 localhost:5101\", \"/swagger/\\n\\nswagger\\n\\nSelect a spec eShoponContainers - Catalog HTTP API\\u00b0\\n\\n/swagger/v1/swagger.ison\\n\\nT\", \"he Catalog Microservice HTTP API. This is a Data-Driven/CRUD microservice sample\\n\\nTerms of service\\n\\n\", \"Catalog\\n\\nGET\\n\\nPUT\\n\\nPOST\\n\\nGET\\n\\nGET\\n\\nGET\\n\\nGET\\n\\nGET\\n\\nDELETE\\n\\n/api/v1/Catalog/items\\n\\n/api/v1/Catalog/ite\", \"ms\\n\\n/api/v1/Catalog/items\\n\\n/api/v1/Catalog/items/{id}\\n\\n/api/v1/Catalog/CatalogTypes\\n\\n/api/v1/Catalog\", \"/CatalogBrands\\n\\n/api/v1/Catalog/{id}\\n\\nCatalog.API V1\\n\\nFigure 6-31. Testing the Catalog microservice \", \"with its Swagger UI\\n\\n<!-- image -->\\n\\nAt this point, you could set a breakpoint in C# code in Visual \", \"Studio, test the microservice with the methods exposed in Swagger UI, and finally clean-up everythin\", \"g with the docker-compose down command.\\n\\nHowever, direct-access communication to the microservice, i\", \"n this case through the external port 5101, is precisely what you want to avoid in your application.\", \" And you can avoid that by setting the additional level of indirection of the API Gateway (Ocelot , \", \"in this case). That way, the client app won't directly access the microservice.\\n\\n## Implementing you\", \"r API Gateways with Ocelot\\n\\nOcelot is basically a set of middleware that you can apply in a specific\", \" order.\\n\\nOcelot is designed to work with ASP.NET Core only. The latest version of the package is 18.\", \"0 which targets .NET 6 and hence is not suitable for .NET Framework applications.\\n\\nApiGw-Base\\n\\n\\u2022 -e \", \"OcelotApiGw\\n\\n\\u2022- Connected Services\\n\\n* Dependencies\\n\\nYou install Ocelot and its dependencies in your \", \"ASP.NET Core project with Ocelot's NuGet package , from Visual Studio.\\n\\n## Install-Package Ocelot\\n\\nS\", \"DK\\n\\nIn eShopOnContainers, its API Gateway implementation is a simple ASP.NET Core WebHost project, a\", \"nd Ocelot's middleware handles all the API Gateway features, as shown in the following image:\\n\\nadJ a\", \"ppsettings.json aL Dockerfile\\n\\nD a C* Program.cs\\n\\nD G C# Startup.cs\\n\\nFigure 6-32. The OcelotApiGw ba\", \"se project in eShopOnContainers\\n\\n<!-- image -->\\n\\nThis ASP.NET Core WebHost project is built with two\", \" simple files: Program.cs and Startup.cs.\\n\\nThe Program.cs just needs to create and configure the typ\", \"ical ASP.NET Core BuildWebHost.\\n\\n```\\nnamespace OcelotApiGw { public class Program { public static vo\", \"id Main(string[] args) { BuildWebHost(args).Run(); } public static IWebHost BuildWebHost(string[] ar\", \"gs) { var builder = WebHost.CreateDefaultBuilder(args); builder.ConfigureServices(s => s.AddSingleto\", \"n(builder)) .ConfigureAppConfiguration( ic => ic.AddJsonFile(Path.Combine(\\\"configuration\\\", \\\"configur\", \"ation.json\\\"))) .UseStartup<Startup>(); var host = builder.Build(); return host; } } }\\n```\\n\\nThe impor\", \"tant point here for Ocelot is the configuration.json file that you must provide to the builder throu\", \"gh the AddJsonFile() method. That configuration.json is where you specify all the API Gateway ReRout\", \"es, meaning the external endpoints with specific ports and the correlated internal endpoints, usuall\", \"y using different ports.\\n\\n```\\n{ \\\"ReRoutes\\\": [], \\\"GlobalConfiguration\\\": {} }\\n```\\n\\nThere are two secti\", \"ons to the configuration. An array of ReRoutes and a GlobalConfiguration. The ReRoutes are the objec\", \"ts that tell Ocelot how to treat an upstream request. The Global configuration allows overrides of R\", \"eRoute specific settings. It's useful if you don't want to manage lots of ReRoute specific settings.\", \"\\n\\nHere's a simplified example of ReRoute configuration file from one of the API Gateways from eShopO\", \"nContainers.\\n\\n```\\n{ \\\"ReRoutes\\\": [ { \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\\"Downst\", \"reamScheme\\\": \\\"http\\\", \\\"DownstreamHostAndPorts\\\": [ { \\\"Host\\\": \\\"catalog-api\\\", \\\"Port\\\": 80 } ], \\\"UpstreamP\", \"athTemplate\\\": \\\"/api/{version}/c/{everything}\\\", \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ] }, { \\\"\", \"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\\"DownstreamScheme\\\": \\\"http\\\", \\\"DownstreamHostA\", \"ndPorts\\\": [ { \\\"Host\\\": \\\"basket-api\\\", \\\"Port\\\": 80 } ], \\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{every\", \"thing}\\\", \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\\"AuthenticationOptions\\\": { \\\"AuthenticationP\", \"roviderKey\\\": \\\"IdentityApiKey\\\", \\\"AllowedScopes\\\": [] } } ], \\\"GlobalConfiguration\\\": { \\\"RequestIdKey\\\": \\\"\", \"OcRequestId\\\", \\\"AdministrationPath\\\": \\\"/administration\\\" } }\\n```\\n\\nThe main functionality of an Ocelot A\", \"PI Gateway is to take incoming HTTP requests and forward them on to a downstream service, currently \", \"as another HTTP request. Ocelot's describes the routing of one request to another as a ReRoute.\\n\\nFor\", \" instance, let's focus on one of the ReRoutes in the configuration.json from above, the configuratio\", \"n for the Basket microservice.\\n\\n```\\n{ \\\"DownstreamPathTemplate\\\": \\\"/api/{version}/{everything}\\\", \\\"Down\", \"streamScheme\\\": \\\"http\\\", \\\"DownstreamHostAndPorts\\\": [ { \\\"Host\\\": \\\"basket-api\\\", \\\"Port\\\": 80 } ], \\\"Upstream\", \"PathTemplate\\\": \\\"/api/{version}/b/{everything}\\\", \\\"UpstreamHttpMethod\\\": [ \\\"POST\\\", \\\"PUT\\\", \\\"GET\\\" ], \\\"Aut\", \"henticationOptions\\\": { \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\\"AllowedScopes\\\": [] } }\\n```\\n\\nT\", \"he DownstreamPathTemplate, Scheme, and DownstreamHostAndPorts make the internal microservice URL tha\", \"t this request will be forwarded to.\\n\\nThe port is the internal port used by the service. When using \", \"containers, the port specified at its dockerfile.\\n\\nThe Host is a service name that depends on the se\", \"rvice name resolution you are using. When using docker-compose, the services names are provided by t\", \"he Docker Host, which is using the service names provided in the docker-compose files. If using an o\", \"rchestrator like Kubernetes or Service Fabric, that name should be resolved by the DNS or name resol\", \"ution provided by each orchestrator.\\n\\nDownstreamHostAndPorts is an array that contains the host and \", \"port of any downstream services that you wish to forward requests to. Usually this configuration wil\", \"l just contain one entry but sometimes you might want to load balance requests to your downstream se\", \"rvices and Ocelot lets you add more than one entry and then select a load balancer. But if using Azu\", \"re and any orchestrator it is probably a better idea to load balance with the cloud and orchestrator\", \" infrastructure.\\n\\nThe UpstreamPathTemplate is the URL that Ocelot will use to identify which Downstr\", \"eamPathTemplate to use for a given request from the client. Finally, the UpstreamHttpMethod is used \", \"so Ocelot can distinguish between different requests (GET, POST, PUT) to the same URL.\\n\\nAt this poin\", \"t, you could have a single Ocelot API Gateway (ASP.NET Core WebHost) using one or multiple merged co\", \"nfiguration.json files or you can also store the configuration in a Consul KV store.\\n\\nBut as introdu\", \"ced in the architecture and design sections, if you really want to have autonomous microservices, it\", \" might be better to split that single monolithic API Gateway into multiple API Gateways and/or BFF (\", \"Backend for Frontend). For that purpose, let's see how to implement that approach with Docker contai\", \"ners.\\n\\nContainers\\n\\nAPI Gateways / BFF\\n\\n## Using a single Docker container image to run multiple diff\", \"erent API Gateway / BFF container types\\n\\nIn eShopOnContainers, we're using a single Docker container\", \" image with the Ocelot API Gateway but then, at run time, we create different services/containers fo\", \"r each type of API-Gateway/BFF by providing a different configuration.json file, using a docker volu\", \"me to access a different PC folder for each service.\\n\\nImage\\n\\nOCELOT\\n\\nGeneric\\n\\nOcelot API Gateway\\n\\nFi\", \"gure 6-33. Reusing a single Ocelot Docker image across multiple API Gateway types\\n\\n<!-- image -->\\n\\nI\", \"n eShopOnContainers, the 'Generic Ocelot API Gateway Docker Image' is created with the project named\", \" 'OcelotApiGw' and the image name 'eshop/ocelotapigw' that is specified in the docker -compose.yml f\", \"ile. Then, when deploying to Docker, there will be four API-Gateway containers created from that sam\", \"e Docker image, as shown in the following extract from the docker-compose.yml file.\\n\\nmobileshoppinga\", \"pigw : image\\n\\n: eshop/ocelotapigw:${TAG:-latest}\\n\\n```\\nbuild : context : . dockerfile : src/ApiGatewa\", \"ys/ApiGw-Base/Dockerfile mobilemarketingapigw : image : eshop/ocelotapigw:${TAG:-latest} build : con\", \"text : . dockerfile : src/ApiGateways/ApiGw-Base/Dockerfile webshoppingapigw : image : eshop/ocelota\", \"pigw:${TAG:-latest} build : context : . dockerfile : src/ApiGateways/ApiGw-Base/Dockerfile webmarket\", \"ingapigw : image : eshop/ocelotapigw:${TAG:-latest} build : context : . dockerfile : src/ApiGateways\", \"/ApiGw-Base/Dockerfile\\n```\\n\\nAdditionally, as you can see in the following docker-compose.override.ym\", \"l file, the only difference between those API Gateway containers is the Ocelot configuration file, w\", \"hich is different for each service container and it's specified at run time through a Docker volume.\", \"\\n\\n```\\nmobileshoppingapigw : environment : -ASPNETCORE_ENVIRONMENT=Development -IdentityUrl=http://id\", \"entity-api ports : -\\\"5200:80\\\" volumes : -./src/ApiGateways/Mobile.Bff.Shopping/apigw:/app/configurat\", \"ion mobilemarketingapigw : environment : -ASPNETCORE_ENVIRONMENT=Development -IdentityUrl=http://ide\", \"ntity-api ports : -\\\"5201:80\\\" volumes : -./src/ApiGateways/Mobile.Bff.Marketing/apigw:/app/configurat\", \"ion webshoppingapigw : environment : -ASPNETCORE_ENVIRONMENT=Development -IdentityUrl=http://identit\", \"y-api ports : -\\\"5202:80\\\" volumes : -./src/ApiGateways/Web.Bff.Shopping/apigw:/app/configuration webm\", \"arketingapigw : environment : -ASPNETCORE_ENVIRONMENT=Development -IdentityUrl=http://identity-api p\", \"orts : -\\\"5203:80\\\"\\n```\\n\\nlocalhost\\n\\nApiGateways x + v\\n\\n&lt; &gt; 0\\n\\nApiGw-Base\\n\\n\\u2022 localhost:5202/api/v\", \"1/c/catalog/items/2/\\n\\n(\\\"id\\\": 2, \\\"name\\\": \\\".NET Black &amp; White Mug\\\", \\\"description\\\": \\\".NET Black &am\", \"p; White\\n\\nD a@] OcelotApiGw\\n\\nId\\\": 2, \\\"catalogBrand\\\": nul1, \\\"availableStock\\\":99, \\\"restockThreshold\\\": \", \"0, \\\"maxStockThreshold\\\": 0, \\\"onReorder\\\": false)\\n\\n- \\u2022 \\u00d7\\n\\n* 2 &lt; ...\\n\\nMug\\\", \\\"price\\\": 8.50, \\\"pictureFi\", \"leName\\\": \\\"2.png\\\", \\\"pictureUri\\\":\\\"http://localhost:5202/api/v1/c/catalog/items/2/pic/\\\",\\\"catalogTypeId\\\"\", \":1, \\\"catalogType\\\": null, \\\"catalogBrand\\n\\nMobile. Bff.Marketing\\n\\n<!-- image -->\\n\\nBecause of that previ\", \"ous code, and as shown in the Visual Studio Explorer below, the only file needed to define each spec\", \"ific business/BFF API Gateway is just a configuration.json file, because the four API Gateways are b\", \"ased on the same Docker image.\\n\\n\\u2022 Web.Bff.Shopping\\n\\nD a\\u00a9] Web.Shopping.HttpAggregator foJ configurat\", \"ion.json\\n\\nFigure 6-34. The only file needed to define each API Gateway / BFF with Ocelot is a config\", \"uration file\\n\\n<!-- image -->\\n\\nBy splitting the API Gateway into multiple API Gateways, different dev\", \"elopment teams focusing on different subsets of microservices can manage their own API Gateways by u\", \"sing independent Ocelot configuration files. Plus, at the same time they can reuse the same Ocelot D\", \"ocker image.\\n\\nNow, if you run eShopOnContainers with the API Gateways (included by default in VS whe\", \"n opening eShopOnContainersServicesAndWebApps.sln solution or if running 'docker -compose up'), the \", \"following sample routes will be performed.\\n\\nFor instance, when visiting the upstream URL\\n\\nhttp://hos\", \"t.docker.internal:5202/api/v1/c/catalog/items/2/ served by the webshoppingapigw API Gateway, you get\", \" the same result from the internal Downstream URL http://catalog-api/api/v1/2 within the Docker host\", \", as in the following browser.\\n\\nFigure 6-35. Accessing a microservice through a URL provided by the \", \"API Gateway\\n\\n<!-- image -->\\n\\nBecause of testing or debugging reasons, if you wanted to directly acce\", \"ss to the Catalog Docker container (only at the development environment) without passing through the\", \" API Gateway, since 'catalog -api' is a DNS resolution internal to the Docker host (se rvice discove\", \"ry handled by dockercompose service names), the only way to directly access the container is through\", \" the external port published in the docker-compose.override.yml, which is provided only for developm\", \"ent tests, such as http://host.docker.internal:5101/api/v1/Catalog/items/1 in the following browser.\", \"\\n\\n|\\n\\nlocalhost\\n\\n&lt; &gt; 0\\n\\nx + v eShopOnContainers\\n\\n\\u2022 localhost:5101/api/v1/Catalog/items/2|\\n\\n(API\", \" Gateways / BFF and Aggregator-services details)\\n\\n(\\\"id\\\":2,\\\"name\\\":\\\" NET Black &amp; White Mug\\\", \\\"desc\", \"ription\\\":\\\".NET Black &amp; White\\n\\nClient apps eShop mobile app\\n\\nXamarin Forms\\n\\nC#\\n\\nxPlat. OS:\\n\\niOS\\n\\n\", \"Android\\n\\nWindows eShop SPA Web app\\n\\nTypeScript/Angular\\n\\nId\\\": 2, \\\"catalogBrand\\\": nul1, \\\"availableStoc\", \"k\\\": 99, \\\"restockThreshold\\\": 0, \\\"maxStockThreshold\\\": 0, \\\"onReorder\\\": false)\\n\\n- \\u2022 X\\n\\n# R E\\n\\nMug\\\", \\\"pri\", \"ce\\\":8.50, \\\"pictureFileName\\\": \\\"2.png\\\",\\\"pictureUri\\\":\\\"http://localhost:5202/api/v1/c/catalog/items/2/pi\", \"c/\\\",\\\"catalogTypeId\\\":1,\\\"catalogType\\\":nu1l, \\\"catalogBrand\\n\\nIdentity microservice (STS+users)\\n\\nSQL Serv\", \"er database\\n\\nFigure 6-36. Direct access to a microservice for testing purposes\\n\\n<!-- image -->\\n\\nEven\", \"t Bus\\n\\nAzure\\n\\nService Bus\\n\\nBut the application is configured so it accesses all the microservices th\", \"rough the API Gateways, not through the direct port 'shortcuts'. Marketing microservice MongoDB\\n\\n\\u2022 C\", \"osmosDB\\n\\n## The Gateway aggregation pattern in eShopOnContainers SQL Server\\n\\nWeb-Marketing\\n\\nMongoDB,\", \"\\n\\nAs introduced previously, a flexible way to implement requests aggregation is with custom services\", \", by code. You could also implement request aggregation with the Request Aggregation feature in Ocel\", \"ot, but it might not be as flexible as you need. Therefore, the selected way to implement aggregatio\", \"n in eShopOnContainers is with an explicit ASP.NET Core Web API service for each aggregator.\\n\\nAccord\", \"ing to that approach, the API Gateway composition diagram is in reality a bit more extended when con\", \"sidering the aggregator services that are not shown in the simplified global architecture diagram sh\", \"own previously.\\n\\nIn the following diagram, you can also see how the aggregator services work with th\", \"eir related API Gateways.\\n\\nFigure 6-37. eShopOnContainers architecture with aggregator services\\n\\n<!-\", \"- image -->\\n\\nZooming in further, on the 'Shopping' business area in the following image, you can see\", \" that chattiness between the client apps and the microservices is reduced when using the aggregator \", \"services in the API Gateways.\\n\\neShopOnContainers\\n\\n(API Gateways / BFF and Aggregator-services zoom-i\", \"n)\\n\\nAPI Gateways / BFF\\n\\nMobile-Shopping\\n\\nAggregator\\n\\nMobile-Marketing\\n\\nWeb-Shopping\\n\\nAggregator\\n\\nWeb\", \"-Marketing\\n\\nFigure 6-38. Zoom in vision of the Aggregator services\\n\\n<!-- image -->\\n\\nYou can notice h\", \"ow when the diagram shows the possible requests coming from the API Gateways it can get complex. On \", \"the other hand, when you use the aggregator pattern, you can see how the arrows in blue would simpli\", \"fy the communication from a client app perspective. This pattern not only helps to reduce the chatti\", \"ness and latency in the communication, it also improves the user experience significantly for the re\", \"mote apps (mobile and SPA apps).\\n\\nIn the case of the 'Marketing' business area and microservices, it\", \" is a simple use case so there was no need to use aggregators, but it could also be possible, if nee\", \"ded.\\n\\n## Authentication and authorization in Ocelot API Gateways\\n\\nIn an Ocelot API Gateway, you can \", \"sit the authentication service, such as an ASP.NET Core Web API service using IdentityServer providi\", \"ng the auth token, either out or inside the API Gateway.\\n\\nSince eShopOnContainers is using multiple \", \"API Gateways with boundaries based on BFF and business areas, the Identity/Auth service is left out \", \"of the API Gateways, as highlighted in yellow in the following diagram.\\n\\n## \\\"Shopping\\\"\\n\\nmicroservice\", \"s\\n\\nClient apps eShop mobile app\\n\\nAuthentication in Ocelot API Gateway\\n\\nXamarin.Forms\\n\\nC#\\n\\nxPlat. OS:\", \"\\n\\niOS\\n\\nAndroid\\n\\nWindows eShop traditional Web app\\n\\nClient apps\\n\\neShop SPA Web app\\n\\nTypeScript/Angula\", \"r\\n\\nIdentity microservice (STS+users)\\n\\nSQL Server database\\n\\nCatalog microservice\\n\\n\\u2022 0-\\n\\nSQL Server da\", \"tabase\\n\\nFigure 6-39. Position of the Identity service in eShopOnContainers\\n\\n<!-- image -->\\n\\nHowever,\", \" Ocelot also supports sitting the Identity/Auth microservice within the API Gateway boundary, as in \", \"this other diagram.\\n\\nFigure 6-40. Authentication in Ocelot\\n\\n<!-- image -->\\n\\nAs the previous diagram \", \"shows, when the Identity microservice is beneath the API gateway (AG): 1) AG requests an auth token \", \"from identity microservice, 2) The identity microservice returns token to AG, 34) AG requests from m\", \"icroservices using the auth token. Because eShopOnContainers application has split the API Gateway i\", \"nto multiple BFF (Backend for Frontend) and business areas API Gateways, another option would have b\", \"een to create an additional API Gateway for cross-cutting concerns. That choice would be fair in a m\", \"ore complex microservice based architecture with multiple cross-cutting concerns microservices. Sinc\", \"e there's only one cross -cutting concern in eShopOnContainers, it was decided to just handle the se\", \"curity service out of the API Gateway realm, for simplicity' s sake.\\n\\nAPI Gateways / BFF\\n\\n\\u2022 0\\n\\nInter\", \"nal microservices\\n\\nDocker Host\\n\\nRabbitMO\\n\\nIn any case, if the app is secured at the API Gateway leve\", \"l, the authentication module of the Ocelot API Gateway is visited at first when trying to use any se\", \"cured microservice. That redirects the HTTP request to visit the Identity or auth microservice to ge\", \"t the access token so you can visit the protected services with the access\\\\_token.\\n\\nThe way you secu\", \"re with authentication any service at the API Gateway level is by setting the AuthenticationProvider\", \"Key in its related settings at the configuration.json.\\n\\n```\\n{ \\\"DownstreamPathTemplate\\\": \\\"/api/{versi\", \"on}/{everything}\\\", \\\"DownstreamScheme\\\": \\\"http\\\", \\\"DownstreamHostAndPorts\\\": [ { \\\"Host\\\": \\\"basket-api\\\", \\\"\", \"Port\\\": 80 } ], \\\"UpstreamPathTemplate\\\": \\\"/api/{version}/b/{everything}\\\", \\\"UpstreamHttpMethod\\\": [], \\\"A\", \"uthenticationOptions\\\": { \\\"AuthenticationProviderKey\\\": \\\"IdentityApiKey\\\", \\\"AllowedScopes\\\": [] } }\\n```\\n\", \"\\nWhen Ocelot runs, it will look at the ReRoutes AuthenticationOptions.AuthenticationProviderKey and \", \"check that there is an Authentication Provider registered with the given key. If there isn't, then O\", \"celot will not start up. If there is, then the ReRoute will use that provider when it executes.\\n\\nBec\", \"ause the Ocelot WebHost is configured with the authenticationProviderKey = \\\"IdentityApiKey\\\", that wi\", \"ll require authentication whenever that service has any requests without any auth token.\\n\\n```\\nnamesp\", \"ace OcelotApiGw { public class Startup { private readonly IConfiguration _cfg; public Startup(IConfi\", \"guration configuration) => _cfg = configuration; public void ConfigureServices(IServiceCollection se\", \"rvices) { var identityUrl = _cfg.GetValue<string>(\\\"IdentityUrl\\\"); var authenticationProviderKey = \\\"I\", \"dentityApiKey\\\"; //\\u2026 services.AddAuthentication() .AddJwtBearer(authenticationProviderKey, x => { x.A\", \"uthority = identityUrl; x.RequireHttpsMetadata = false ; x.TokenValidationParameters = new Microsoft\", \".IdentityModel.Tokens.TokenValidationParameters() { ValidAudiences = new [] { \\\"orders\\\", \\\"basket\\\", \\\"l\", \"ocations\\\", \\\"marketing\\\", \\\"mobileshoppingagg\\\", \\\"webshoppingagg\\\" } }; }); //...\\n```\\n\\n```\\n} } }\\n```\\n\\nThe\", \"n, you also need to set authorization with the [Authorize] attribute on any resource to be accessed \", \"like the microservices, such as in the following Basket microservice controller.\\n\\n```\\nnamespace Micr\", \"osoft.eShopOnContainers.Services.Basket.API.Controllers { [Route(\\\"api/v1/[controller]\\\")] [Authorize]\", \" public class BasketController : Controller { //... } }\\n```\\n\\nThe ValidAudiences such as 'basket' are\", \" correlated with the audience defined in each microservice with AddJwtBearer() at the ConfigureServi\", \"ces() of the Startup class, such as in the code below.\\n\\n```\\n// prevent from mapping \\\"sub\\\" claim to n\", \"ameidentifier. JwtSecurityTokenHandler.DefaultInboundClaimTypeMap.Clear(); var identityUrl = Configu\", \"ration.GetValue<string>(\\\"IdentityUrl\\\"); services.AddAuthentication(options => { options.DefaultAuthe\", \"nticateScheme = JwtBearerDefaults.AuthenticationScheme; options.DefaultChallengeScheme = JwtBearerDe\", \"faults.AuthenticationScheme; }).AddJwtBearer(options => { options.Authority = identityUrl; options.R\", \"equireHttpsMetadata = false ; options.Audience = \\\"basket\\\"; });\\n```\\n\\nIf you try to access any secured\", \" microservice, like the Basket microservice with a ReRoute URL based on the API Gateway like http://\", \"host.docker.internal:5202/api/v1/b/basket/1, then you'll get a 401 Unauthorized unless you provide a\", \" valid token. On the other hand, if a ReRoute URL is authenticated, Ocelot will invoke whatever down\", \"stream scheme is associated with it (the internal microservice URL).\\n\\nAuthorization at Ocelot's ReRo\", \"utes tier. Ocelot supports claims-based authorization evaluated after the authentication. You set th\", \"e authorization at a route level by adding the following lines to the ReRoute configuration.\\n\\n```\\n\\\"R\", \"outeClaimsRequirement\\\": { \\\"UserType\\\": \\\"employee\\\" }\\n```\\n\\nIn that example, when the authorization midd\", \"leware is called, Ocelot will find if the user has the claim type 'UserType' in the token and if the\", \" value of that claim is 'employee'. If it isn't, then the user will not be authorized and the respon\", \"se will be 403 forbidden.\\n\\nClient apps eShopOnContainers\\n\\n(Deployment into Kubernetes environment)\\n\\n\", \"Azure Kubernetes Service (AKS)\\n\\nIdentity microservice (STS+ users)\\n\\nSQL Server database\\n\\n## Using Ku\", \"bernetes Ingress plus Ocelot API Gateways\\n\\nRabbitMQl\\n\\nWhen using Kubernetes (like in an Azure Kubern\", \"etes Service cluster), you usually unify all the HTTP requests through the Kubernetes Ingress tier b\", \"ased on Nginx . Ordering API\\n\\nMobile-Marketing\\n\\nIn Kubernetes, if you don't use any ingress approach\", \", then your services and pods have IPs only routable by the cluster network. Web-Shopping Aggregator\", \" Marketing microservice Azure\\n\\n\\u2022 CosmosDB\\n\\nBut if you use an ingress approach, you'll have a middle \", \"tier between the Internet and your services (including your API Gateways), acting as a reverse proxy\", \". Locations microservice MongoDB CosmosDB\\n\\nAs a definition, an Ingress is a collection of rules that\", \" allow inbound connections to reach the cluster services. An ingress is configured to provide servic\", \"es externally reachable URLs, load balance traffic, SSL termination and more. Users request ingress \", \"by POSTing the Ingress resource to the API server.\\n\\nIn eShopOnContainers, when developing locally an\", \"d using just your development machine as the Docker host, you are not using any ingress but only the\", \" multiple API Gateways.\\n\\nHowever, when targeting a 'production' environment based on Kubernetes, eSh\", \"opOnContainers is using an ingress in front of the API gateways. That way, the clients still call th\", \"e same base URL but the requests are routed to multiple API Gateways or BFF.\\n\\nAPI Gateways are front\", \"-ends or fa\\u00e7ades surfacing only the services but not the web applications that are usually out of th\", \"eir scope. In addition, the API Gateways might hide certain internal microservices.\\n\\nThe ingress, ho\", \"wever, is just redirecting HTTP requests but not trying to hide any microservice or web app.\\n\\nHaving\", \" an ingress Nginx tier in Kubernetes in front of the web applications plus the several Ocelot API Ga\", \"teways / BFF is the ideal architecture, as shown in the following diagram.\\n\\nFigure 6-41. The ingress\", \" tier in eShopOnContainers when deployed into Kubernetes\\n\\n<!-- image -->\\n\\nA Kubernetes Ingress acts \", \"as a reverse proxy for all traffic to the app, including the web applications, that are out of the A\", \"pi gateway scope. When you deploy eShopOnContainers into Kubernetes, it\\n\\nBasket microservice\\n\\nexpose\", \"s just a few services or endpoints via ingress , basically the following list of postfixes on the UR\", \"Ls:\\n\\n- / for the client SPA web application\\n- /webmvc for the client MVC web application\\n- /webstatu\", \"s for the client web app showing the status/healthchecks\\n- /webshoppingapigw for the web BFF and sho\", \"pping business processes\\n- /webmarketingapigw for the web BFF and marketing business processes\\n- /mo\", \"bileshoppingapigw for the mobile BFF and shopping business processes\\n- /mobilemarketingapigw for the\", \" mobile BFF and marketing business processes\\n\\nWhen deploying to Kubernetes, each Ocelot API Gateway \", \"is using a different 'configuration.json' file for each pod running the API Gateways. Those 'configu\", \"ration.json' files are provided by mounting (originally with the deploy.ps1 script) a volume created\", \" based on a Kubernetes config map named 'ocelot'. Each container mounts its related configuration fi\", \"le in the container's folder named /app/configuration.\\n\\nIn the source code files of eShopOnContainer\", \"s, the original 'configuration.json' files can be found within the k8s/ocelot/ folder. There's one f\", \"ile for each BFF/APIGateway.\\n\\n## Additional cross-cutting features in an Ocelot API Gateway\\n\\nThere a\", \"re other important features to research and use, when using an Ocelot API Gateway, described in the \", \"following links.\\n\\n- Service discovery in the client side integrating Ocelot with Consul or Eureka ht\", \"tps://ocelot.readthedocs.io/en/latest/features/servicediscovery.html\\n- Caching at the API Gateway ti\", \"er https://ocelot.readthedocs.io/en/latest/features/caching.html\\n- Logging at the API Gateway tier h\", \"ttps://ocelot.readthedocs.io/en/latest/features/logging.html\\n- Quality of Service (Retries and Circu\", \"it breakers) at the API Gateway tier https://ocelot.readthedocs.io/en/latest/features/qualityofservi\", \"ce.html\\n- Rate limiting https://ocelot.readthedocs.io/en/latest/features/ratelimiting.html\\n- Swagger\", \" for Ocelot\\n\\nhttps://github.com/Burgyn/MMLib.SwaggerForOcelot\\n\\n## Tackle Business Complexity in a Mi\", \"croservice with DDD and CQRS Patterns\\n\\nDesign a domain model for each microservice or Bounded Contex\", \"t that reflects understanding of the business domain.\\n\\nThis section focuses on more advanced microse\", \"rvices that you implement when you need to tackle complex subsystems, or microservices derived from \", \"the knowledge of domain experts with everchanging business rules. The architecture patterns used in \", \"this section are based on domain-driven design (DDD) and Command and Query Responsibility Segregatio\", \"n (CQRS) approaches, as illustrated in Figure 7-1.\\n\\nExternal architecture per application\\n\\nBack end\\n\", \"\\n## Microservice 1\\n\\nMicroservice 2]\\n\\nAPI Gateway\\n\\nInternal architecture per microservice\\n\\nDDD\\n\\nCQRS \", \"and\\n\\nDomain Events\\n\\nFigure 7-1. External microservice architecture versus internal architecture patt\", \"erns for each microservice\\n\\n<!-- image -->\\n\\nHowever, most of the techniques for data driven microser\", \"vices, such as how to implement an ASP.NET Core Web API service or how to expose Swagger metadata wi\", \"th Swashbuckle or NSwag, are also applicable to the more advanced microservices implemented internal\", \"ly with DDD patterns. This section is an extension of the previous sections, because most of the pra\", \"ctices explained earlier also apply here or for any kind of microservice.\\n\\nThis section first provid\", \"es details on the simplified CQRS patterns used in the eShopOnContainers reference application. Late\", \"r, you will get an overview of the DDD techniques that enable you to find common patterns that you c\", \"an reuse in your applications.\\n\\nDDD is a large topic with a rich set of resources for learning. You \", \"can start with books like DomainDriven Design by Eric Evans and additional materials from Vaughn Ver\", \"non, Jimmy Nilsson, Greg Young, Udi Dahan, Jimmy Bogard, and many other DDD/CQRS experts. But most o\", \"f all you need to try to learn how to apply DDD techniques from the conversations, whiteboarding, an\", \"d domain modeling sessions with the experts in your concrete business domain.\\n\\n## Additional resourc\", \"es\\n\\n## DDD (Domain-Driven Design)\\n\\n- Eric Evans. Domain Language https://domainlanguage.com/\\n- Marti\", \"n Fowler. Domain-Driven Design https://martinfowler.com/tags/domain%20driven%20design.html\\n- Jimmy B\", \"ogard. Strengthening your domain: a primer https://lostechies.com/jimmybogard/2010/02/04/strengtheni\", \"ng-your-domain-a-primer/\\n\\nClient apps\\n\\nMobile app\\n\\nSPA\\n\\nWeb app\\n\\n## DDD books\\n\\n- Eric Evans. Domain-\", \"Driven Design: Tackling Complexity in the Heart of Software https://www.amazon.com/Domain-Driven-Des\", \"ign-Tackling-ComplexitySoftware/dp/0321125215/\\n- Eric Evans. Domain-Driven Design Reference: Definit\", \"ions and Pattern Summaries https://www.amazon.com/Domain-Driven-Design-Reference-Definitions-2014-09\", \"22/dp/B01N8YB4ZO/\\n- Vaughn Vernon. Implementing Domain-Driven Design https://www.amazon.com/Implemen\", \"ting-Domain-Driven-Design-VaughnVernon/dp/0321834577/\\n- Vaughn Vernon. Domain-Driven Design Distille\", \"d https://www.amazon.com/Domain-Driven-Design-Distilled-Vaughn-Vernon/dp/0134434420/\\n- Jimmy Nilsson\", \". Applying Domain-Driven Design and Patterns https://www.amazon.com/Applying-Domain-Driven-Design-Pa\", \"tternsExamples/dp/0321268202/\\n- Cesar de la Torre. N-Layered Domain-Oriented Architecture Guide with\", \" .NET https://www.amazon.com/N-Layered-Domain-Oriented-Architecture-GuideNET/dp/8493903612/\\n- Abel A\", \"vram and Floyd Marinescu. Domain-Driven Design Quickly https://www.amazon.com/Domain-Driven-Design-Q\", \"uickly-Abel-Avram/dp/1411609255/\\n- Scott Millett, Nick Tune - Patterns, Principles, and Practices of\", \" Domain-Driven Design https://www.wiley.com/Patterns%2C+Principles%2C+and+Practices+of+Domain+Driven\", \"+Des ign-p-9781118714706\\n\\n## DDD training\\n\\n- Julie Lerman and Steve Smith. Domain-Driven Design Fund\", \"amentals https://www.pluralsight.com/courses/fundamentals-domain-driven-design\\n\\n## Apply simplified \", \"CQRS and DDD patterns in a microservice\\n\\nCQRS is an architectural pattern that separates the models \", \"for reading and writing data. The related term Command Query Separation (CQS) was originally defined\", \" by Bertrand Meyer in his book ObjectOriented Software Construction . The basic idea is that you can\", \" divide a system's operations into two sharply separated categories:\\n\\n- Queries. These queries retur\", \"n a result and don't change the state of the system, and they're free of side effects.\\n- Commands. T\", \"hese commands change the state of a system.\\n\\nCQS is a simple concept: it is about methods within the\", \" same object being either queries or commands. Each method either returns state or mutates state, bu\", \"t not both. Even a single repository pattern object can comply with CQS. CQS can be considered a fou\", \"ndational principle for CQRS.\\n\\nCommand and Query Responsibility Segregation (CQRS) was introduced by\", \" Greg Young and strongly promoted by Udi Dahan and others. It's based on the CQS principle, although\", \" it's more detailed. It can be considered a pattern based on commands and events plus optionally on \", \"asynchronous messages. In many cases, CQRS is related to more advanced scenarios, like having a diff\", \"erent physical database for reads (queries) than for writes (updates). Moreover, a more evolved CQRS\", \" system might implement Event-Sourcing (ES) for your updates database, so you would only store event\", \"s in the domain model instead of storing the current-state data. However, this approach is not used \", \"in this guide. This guide uses the simplest CQRS approach, which consists of just separating the que\", \"ries from the commands.\\n\\nThe separation aspect of CQRS is achieved by grouping query operations in o\", \"ne layer and commands in another layer. Each layer has its own data model (note that we say model, n\", \"ot necessarily a different database) and is built using its own combination of patterns and technolo\", \"gies. More importantly, the two layers can be within the same tier or microservice, as in the exampl\", \"e (ordering microservice) used for this guide. Or they could be implemented on different microservic\", \"es or processes so they can be optimized and scaled out separately without affecting one another.\\n\\nC\", \"QRS means having two objects for a read/write operation where in other contexts there's one. There a\", \"re reasons to have a denormalized reads database, which you can learn about in more advanced CQRS li\", \"terature. But we aren't using that approach here, where the goal is to have more flexibility in the \", \"queries instead of limiting the queries with constraints from DDD patterns like aggregates.\\n\\nAn exam\", \"ple of this kind of service is the ordering microservice from the eShopOnContainers reference applic\", \"ation. This service implements a microservice based on a simplified CQRS approach. It uses a single \", \"data source or database, but two logical models plus DDD patterns for the transactional domain, as s\", \"hown in Figure 7-2.\\n\\n\\u0413\\n\\nExternal IP\\n\\nand Port |\\n\\nSimplified CQRS and DDD microservice\\n\\nHigh level de\", \"sign\\n\\n-\\n\\n- - -\\n\\nDocker Host\\n\\nLogical \\\"Ordering\\\" Microservice\\n\\n<!-- image -->\\n\\n-\\n\\nFigure 7-2. Simplif\", \"ied CQRS- and DDD-based microservice\\n\\nThe Logical 'Ordering' Microservice includes its Ordering data\", \"base, which can be, but doesn't have to be, the same Docker host. Having the database in the same Do\", \"cker host is good for development, but not for production.\\n\\nThe application layer can be the Web API\", \" itself. The important design aspect here is that the microservice has split the queries and ViewMod\", \"els (data models especially created for the client applications) from the commands, domain model, an\", \"d transactions following the CQRS pattern. This approach keeps the queries independent from restrict\", \"ions and constraints coming from DDD patterns that only make sense for transactions and updates, as \", \"explained in later sections.\\n\\n## Additional resources\\n\\n- Greg Young. Versioning in an Event Sourced \", \"System (Free to read online e-book) https://leanpub.com/esversioning/read\\n\\n## Apply CQRS and CQS app\", \"roaches in a DDD microservice in eShopOnContainers\\n\\nThe design of the ordering microservice at the e\", \"ShopOnContainers reference application is based on CQRS principles. However, it uses the simplest ap\", \"proach, which is just separating the queries from the commands and using the same database for both \", \"actions.\\n\\nThe essence of those patterns, and the important point here, is that queries are idempoten\", \"t: no matter how many times you query a system, the state of that system won't change. In other word\", \"s, queries are side-effect free.\\n\\nTherefore, you could use a different 'reads' data model than the t\", \"ransactional logic 'writes' domain model, even though the ordering microservices are using the same \", \"database. Hence, this is a simplified CQRS approach.\\n\\nOn the other hand, commands, which trigger tra\", \"nsactions and data updates, change state in the system. With commands, you need to be careful when d\", \"ealing with complexity and ever-changing business rules. This is where you want to apply DDD techniq\", \"ues to have a better modeled system.\\n\\nThe DDD patterns presented in this guide should not be applied\", \" universally. They introduce constraints on your design. Those constraints provide benefits such as \", \"higher quality over time, especially in commands and other code that modifies system state. However,\", \" those constraints add complexity with fewer benefits for reading and querying data.\\n\\nOne such patte\", \"rn is the Aggregate pattern, which we examine more in later sections. Briefly, in the Aggregate patt\", \"ern, you treat many domain objects as a single unit as a result of their relationship in the domain.\", \" You might not always gain advantages from this pattern in queries; it can increase the complexity o\", \"f query logic. For read-only queries, you do not get the advantages of treating multiple objects as \", \"a single Aggregate. You only get the complexity.\\n\\nAs shown in Figure 7-2 in the previous section, th\", \"is guide suggests using DDD patterns only in the transactional/updates area of your microservice (th\", \"at is, as triggered by commands). Queries can follow a simpler approach and should be separated from\", \" commands, following a CQRS approach.\\n\\nFor implementing the 'queries side', you can choose between m\", \"any approaches, from your full -blown ORM like EF Core, AutoMapper projections, stored procedures, v\", \"iews, materialized views or a micro ORM.\\n\\nIn this guide and in eShopOnContainers (specifically the o\", \"rdering microservice) we chose to implement straight queries using a micro ORM like Dapper. This gui\", \"de lets you implement any query based on SQL statements to get the best performance, thanks to a lig\", \"ht framework with little overhead.\\n\\nWhen you use this approach, any updates to your model that impac\", \"t how entities are persisted to a SQL database also need separate updates to SQL queries used by Dap\", \"per or any other separate (nonEF) approaches to querying.\\n\\n## CQRS and DDD patterns are not top-leve\", \"l architectures\\n\\nIt's important to understand that CQRS and most DDD patterns (like DDD layers or a \", \"domain model with aggregates) are not architectural styles, but only architecture patterns. Microser\", \"vices, SOA, and event-driven architecture (EDA) are examples of architectural styles. They describe \", \"a system of many components, such as many microservices. CQRS and DDD patterns describe something in\", \"side a single system or component; in this case, something inside a microservice.\\n\\nDifferent Bounded\", \" Contexts (BCs) will employ different patterns. They have different responsibilities, and that leads\", \" to different solutions. It is worth emphasizing that forcing the same pattern everywhere leads to f\", \"ailure. Do not use CQRS and DDD patterns everywhere. Many subsystems, BCs, or microservices are simp\", \"ler and can be implemented more easily using simple CRUD services or using another approach.\\n\\nUl app\", \"\\n\\nThere is only one application architecture: the architecture of the system or end-to-end applicati\", \"on you are designing (for example, the microservices architecture). However, the design of each Boun\", \"ded Context or microservice within that application reflects its own tradeoffs and internal design d\", \"ecisions at an architecture patterns level. Do not try to apply the same architectural patterns as C\", \"QRS or DDD everywhere.\\n\\n## Additional resources\\n\\nInfrastructure\\n\\n(MicroORM or\\n\\n- Martin Fowler. CQRS\", \"\\n\\nEntity Framework)\\n\\nhttps://martinfowler.com/bliki/CQRS.html\\n\\n- Greg Young. CQRS Documents\\n\\nhttps:/\", \"/cqrs.files.wordpress.com/2010/11/cqrs\\\\_documents.pdf\\n\\n- Udi Dahan. Clarified CQRS\\n\\nhttps://udidahan\", \".com/2009/12/09/clarified-cqrs/\\n\\n## Implement reads/queries in a CQRS microservice\\n\\nFor reads/querie\", \"s, the ordering microservice from the eShopOnContainers reference application implements the queries\", \" independently from the DDD model and transactional area. This implementation was done primarily bec\", \"ause the demands for queries and for transactions are drastically different. Writes execute transact\", \"ions that must be compliant with the domain logic. Queries, on the other hand, are idempotent and ca\", \"n be segregated from the domain rules.\\n\\nThe approach is simple, as shown in Figure 7-3. The API inte\", \"rface is implemented by the Web API controllers using any infrastructure, such as a micro Object Rel\", \"ational Mapper (ORM) like Dapper, and returning dynamic ViewModels depending on the needs of the UI \", \"applications.\\n\\nFigure 7-3. The simplest approach for queries in a CQRS microservice\\n\\n<!-- image -->\\n\", \"\\nThe simplest approach for the queries-side in a simplified CQRS approach can be implemented by quer\", \"ying the database with a Micro-ORM like Dapper, returning dynamic ViewModels. The query\\n\\nDatabase\\n\\nd\", \"efinitions query the database and return a dynamic ViewModel built on the fly for each query. Since \", \"the queries are idempotent, they won't change the data no matter how many times you run a query. The\", \"refore, you don't need to be restricted by any DDD patt ern used in the transactional side, like agg\", \"regates and other patterns, and that is why queries are separated from the transactional area. You q\", \"uery the database for the data that the UI needs and return a dynamic ViewModel that does not need t\", \"o be statically defined anywhere (no classes for the ViewModels) except in the SQL statements themse\", \"lves.\\n\\nSince this approach is simple, the code required for the queries side (such as code using a m\", \"icro ORM like Dapper) can be implemented within the same Web API project. Figure 7-4 shows this appr\", \"oach. The queries are defined in the Ordering.API microservice project within the eShopOnContainers \", \"solution.\\n\\nFigure 7-4. Queries in the Ordering microservice in eShopOnContainers\\n\\n<!-- image -->\\n\\n##\", \" Use ViewModels specifically made for client apps, independent from domain model constraints\\n\\nSince \", \"the queries are performed to obtain the data needed by the client applications, the returned type ca\", \"n be specifically made for the clients, based on the data returned by the queries. These models, or \", \"Data Transfer Objects (DTOs), are called ViewModels.\\n\\nThe returned data (ViewModel) can be the resul\", \"t of joining data from multiple entities or tables in the database, or even across multiple aggregat\", \"es defined in the domain model for the transactional area. In this case, because you are creating qu\", \"eries independent of the domain model, the aggregates boundaries and constraints are ignored and you\", \"'re free to query any table and column you might need. This approach provides great flexibility and \", \"productivity for the developers creating or updating the queries.\\n\\nThe ViewModels can be static type\", \"s defined in classes (as is implemented in the ordering microservice). Or they can be created dynami\", \"cally based on the queries performed, which is agile for developers.\\n\\n## Use Dapper as a micro ORM t\", \"o perform queries\\n\\nYou can use any micro ORM, Entity Framework Core, or even plain ADO.NET for query\", \"ing. In the sample application, Dapper was selected for the ordering microservice in eShopOnContaine\", \"rs as a good example of a popular micro ORM. It can run plain SQL queries with great performance, be\", \"cause it's a light framework. Using Dapper, you can write a SQL query that can access and join multi\", \"ple tables.\\n\\n\\u2022\\n\\nDapper by Sam Saffron, Marc Gravell, Nick Craver\\n\\nA high performance Micro-ORM suppo\", \"rting SQL Server, MySQL, Sqlite, SqICE, Firebird etc...\\n\\nDapper is an open-source project (original \", \"created by Sam Saffron), and is part of the building blocks used in Stack Overflow. To use Dapper, y\", \"ou just need to install it through the Dapper NuGet package, as shown in the following figure:\\n\\n<!--\", \" image -->\\n\\nYou also need to add a using directive so your code has access to the Dapper extension m\", \"ethods.\\n\\nWhen you use Dapper in your code, you directly use the SqlConnection class available in the\", \" Microsoft.Data.SqlClient namespace. Through the QueryAsync method and other extension methods that \", \"extend the SqlConnection class, you can run queries in a straightforward and performant way.\\n\\n## Dyn\", \"amic versus static ViewModels\\n\\nWhen returning ViewModels from the server-side to client apps, you ca\", \"n think about those ViewModels as DTOs (Data Transfer Objects) that can be different to the internal\", \" domain entities of your entity model because the ViewModels hold the data the way the client app ne\", \"eds. Therefore, in many cases, you can aggregate data coming from multiple domain entities and compo\", \"se the ViewModels precisely according to how the client app needs that data.\\n\\nThose ViewModels or DT\", \"Os can be defined explicitly (as data holder classes), like the OrderSummary class shown in a later \", \"code snippet. Or, you could just return dynamic ViewModels or dynamic DTOs based on the attributes r\", \"eturned by your queries as a dynamic type.\\n\\n## ViewModel as dynamic type\\n\\nAs shown in the following \", \"code, a ViewModel can be directly returned by the queries by just returning a dynamic type that inte\", \"rnally is based on the attributes returned by a query. That means that the subset of attributes to b\", \"e returned is based on the query itself. Therefore, if you add a new column to the query or join, th\", \"at data is dynamically added to the returned ViewModel.\\n\\n```\\nusing Dapper; using Microsoft.Extension\", \"s.Configuration; using System.Data.SqlClient; using System.Threading.Tasks; using System.Dynamic; us\", \"ing System.Collections.Generic; public class OrderQueries : IOrderQueries { public async Task<IEnume\", \"rable<dynamic>> GetOrdersAsync() { using (var connection = new SqlConnection(_connectionString)) { c\", \"onnection.Open(); return await connection.QueryAsync<dynamic>( @\\\"SELECT o.[Id] as ordernumber, o.[Or\", \"derDate] as [date],os.[Name] as [status], SUM(oi.units*oi.unitprice) as total FROM [ordering].[Order\", \"s] o LEFT JOIN[ordering].[orderitems] oi ON o.Id = oi.orderid LEFT JOIN[ordering].[orderstatus] os o\", \"n o.OrderStatusId = os.Id\\n```\\n\\n\\u2022 v1.50.5\\n\\n```\\nGROUP BY o.[Id], o.[OrderDate], os.[Name]\\\"); } } }\\n```\", \"\\n\\nThe important point is that by using a dynamic type, the returned collection of data is dynamicall\", \"y assembled as the ViewModel.\\n\\nPros: This approach reduces the need to modify static ViewModel class\", \"es whenever you update the SQL sentence of a query, making this design approach agile when coding, s\", \"traightforward, and quick to evolve in regard to future changes.\\n\\nCons: In the long term, dynamic ty\", \"pes can negatively impact the clarity and the compatibility of a service with client apps. In additi\", \"on, middleware software like Swashbuckle cannot provide the same level of documentation on returned \", \"types if using dynamic types.\\n\\n## ViewModel as predefined DTO classes\\n\\nPros : Having static, predefi\", \"ned ViewModel classes, like 'contracts' based on explicit DTO classes, is definitely better for publ\", \"ic APIs but also for long-term microservices, even if they are only used by the same application.\\n\\nI\", \"f you want to specify response types for Swagger, you need to use explicit DTO classes as the return\", \" type. Therefore, predefined DTO classes allow you to offer richer information from Swagger. That im\", \"proves the API documentation and compatibility when consuming an API.\\n\\nCons : As mentioned earlier, \", \"when updating the code, it takes some more steps to update the DTO classes.\\n\\nTip based on our experi\", \"ence : In the queries implemented at the Ordering microservice in eShopOnContainers, we started deve\", \"loping by using dynamic ViewModels as it was straightforward and agile on the early development stag\", \"es. But, once the development was stabilized, we chose to refactor the APIs and use static or pre-de\", \"fined DTOs for the ViewModels, because it is clearer for the microservice's consumers to know explic\", \"it DTO types, used as 'contracts'.\\n\\nIn the following example, you can see how the query is returning\", \" data by using an explicit ViewModel DTO class: the OrderSummary class.\\n\\n```\\nusing Dapper; using Mic\", \"rosoft.Extensions.Configuration; using System.Data.SqlClient; using System.Threading.Tasks; using Sy\", \"stem.Dynamic; using System.Collections.Generic; public class OrderQueries : IOrderQueries { public a\", \"sync Task<IEnumerable<OrderSummary>> GetOrdersAsync() { using (var connection = new SqlConnection(_c\", \"onnectionString)) { connection.Open(); return await connection.QueryAsync<OrderSummary>( @\\\"SELECT o.\", \"[Id] as ordernumber, o.[OrderDate] as [date],os.[Name] as [status],\\n```\\n\\n```\\nSUM(oi.units*oi.unitpri\", \"ce) as total FROM [ordering].[Orders] o LEFT JOIN[ordering].[orderitems] oi ON  o.Id = oi.orderid LE\", \"FT JOIN[ordering].[orderstatus] os on o.OrderStatusId = os.Id GROUP BY o.[Id], o.[OrderDate], os.[Na\", \"me] ORDER BY o.[Id]\\\"); } } }\\n```\\n\\n## Describe response types of Web APIs\\n\\nDevelopers consuming web A\", \"PIs and microservices are most concerned with what is returned -specifically response types and erro\", \"r codes (if not standard). The response types are handled in the XML comments and data annotations.\\n\", \"\\nWithout proper documentation in the Swagger UI, the consumer lacks knowledge of what types are bein\", \"g returned or what HTTP codes can be returned. That problem is fixed by adding the Microsoft.AspNetC\", \"ore.Mvc.ProducesResponseTypeAttribute, so Swashbuckle can generate richer information about the API \", \"return model and values, as shown in the following code:\\n\\n```\\nnamespace Microsoft.eShopOnContainers.\", \"Services.Ordering.API.Controllers { [Route(\\\"api/v1/[controller]\\\")] [Authorize] public class OrdersCo\", \"ntroller : Controller { //Additional code... [Route(\\\"\\\")] [HttpGet] [ProducesResponseType( typeof (IE\", \"numerable<OrderSummary>), (int)HttpStatusCode.OK)] public async Task<IActionResult> GetOrders() { va\", \"r userid = _identityService.GetUserIdentity(); var orders = await _orderQueries .GetOrdersFromUserAs\", \"ync(Guid.Parse(userid)); return Ok(orders); } } }\\n```\\n\\nHowever, the ProducesResponseType attribute c\", \"annot use dynamic as a type but requires to use explicit types, like the OrderSummary ViewModel DTO,\", \" shown in the following example:\\n\\n```\\npublic class OrderSummary { public int ordernumber { get ; set\", \" ; } public DateTime date { get ; set ; } public string status { get ; set ; } public double total {\", \" get ; set ; } } // or using C# 8 record types: public record OrderSummary(int ordernumber, DateTime\", \" date, string status, double total);\\n```\\n\\n1- swagger\\n\\nOrdering HTTP API\\u00ae\\n\\nswasger/v1/swagser.ison\\n\\nT\", \"he Ordering Service HTTP API\\n\\nTerms of service\\n\\nThis is another reason why explicit returned types a\", \"re better than dynamic types, in the long term. When using the ProducesResponseType attribute, you c\", \"an also specify what is the expected outcome regarding possible HTTP errors/codes, like 200, 400, et\", \"c. Authorize |\\n\\nIn the following image, you can see how Swagger UI shows the ResponseType informatio\", \"n.\\n\\nV\\n\\nFigure 7-5. Swagger UI showing response types and possible HTTP status codes from a Web API\\n\\n\", \"<!-- image -->\\n\\nThe image shows some example values based on the ViewModel types and the possible HT\", \"TP status codes that can be returned.\\n\\n## Additional resources\\n\\n- Dapper\\n\\nhttps://github.com/StackEx\", \"change/dapper-dot-net\\n\\n- Julie Lerman. Data Points - Dapper, Entity Framework and Hybrid Apps (MSDN \", \"magazine article)\\n\\nOrders\\n\\nPUT\\n\\nPUT\\n\\nGET\\n\\nGET\\n\\n/api/v1/Orders/cancel\\n\\n/api/v1/Orders/ship\\n\\n/api/v1/O\", \"rders/{orderId}\\n\\n/api/v1/Orders\\n\\nParameters\\n\\nNo parameters\\n\\nResponses\\n\\nCode\\n\\n200\\n\\n401\\n\\n403\\n\\nSelect a\", \" spec\\n\\nOrdering.API V1\\n\\nhttps://learn.microsoft.com/archive/msdn-magazine/2016/may/data-points-dappe\", \"r-entityframework-and-hybrid-apps\\n\\n- ASP.NET Core Web API Help Pages using Swagger https://learn.mic\", \"rosoft.com/aspnet/core/tutorials/web-api-help-pages-usingswagger?tabs=visual-studio\\n- Create record \", \"types https://learn.microsoft.com/dotnet/csharp/whats-new/tutorials/records\\n\\n## Design a DDD-oriente\", \"d microservice\\n\\nDomain-driven design (DDD) advocates modeling based on the reality of business as re\", \"levant to your use cases. In the context of building applications, DDD talks about problems as domai\", \"ns. It describes independent problem areas as Bounded Contexts (each Bounded Context correlates to a\", \" microservice), and emphasizes a common language to talk about these problems. It also suggests many\", \" technical concepts and patterns, like domain entities with rich models (no anemic-domain model), va\", \"lue objects, aggregates, and aggregate root (or root entity) rules to support the internal implement\", \"ation. This section introduces the design and implementation of those internal patterns.\\n\\nSometimes \", \"these DDD technical rules and patterns are perceived as obstacles that have a steep learning curve f\", \"or implementing DDD approaches. But the important part is not the patterns themselves, but organizin\", \"g the code so it is aligned to the business problems, and using the same business terms (ubiquitous \", \"language). In addition, DDD approaches should be applied only if you are implementing complex micros\", \"ervices with significant business rules. Simpler responsibilities, like a CRUD service, can be manag\", \"ed with simpler approaches.\\n\\nWhere to draw the boundaries is the key task when designing and definin\", \"g a microservice. DDD patterns help you understand the complexity in the domain. For the domain mode\", \"l for each Bounded Context, you identify and define the entities, value objects, and aggregates that\", \" model your domain. You build and refine a domain model that is contained within a boundary that def\", \"ines your context. And that is explicit in the form of a microservice. The components within those b\", \"oundaries end up being your microservices, although in some cases a BC or business microservices can\", \" be composed of several physical services. DDD is about boundaries and so are microservices.\\n\\n## Kee\", \"p the microservice context boundaries relatively small\\n\\nDetermining where to place boundaries betwee\", \"n Bounded Contexts balances two competing goals. First, you want to initially create the smallest po\", \"ssible microservices, although that should not be the main driver; you should create a boundary arou\", \"nd things that need cohesion. Second, you want to avoid chatty communications between microservices.\", \" These goals can contradict one another. You should balance them by decomposing the system into as m\", \"any small microservices as you can until you see communication boundaries growing quickly with each \", \"additional attempt to separate a new Bounded Context. Cohesion is key within a single bounded contex\", \"t.\\n\\nIt is similar to the Inappropriate Intimacy code smell when implementing classes. If two microse\", \"rvices need to collaborate a lot with each other, they should probably be the same microservice.\\n\\nAn\", \"other way to look at this aspect is autonomy. If a microservice must rely on another service to dire\", \"ctly service a request, it is not truly autonomous.\\n\\n## Layers in DDD microservices\\n\\nMost enterprise\", \" applications with significant business and technical complexity are defined by multiple layers. The\", \" layers are a logical artifact, and are not related to the deployment of the service. They exist to \", \"help developers manage the complexity in the code. Different layers (like the domain model layer ver\", \"sus the presentation layer, etc.) might have different types, which mandate translations between tho\", \"se types.\\n\\nFor example, an entity could be loaded from the database. Then part of that information, \", \"or an aggregation of information including additional data from other entities, can be sent to the c\", \"lient UI through a REST Web API. The point here is that the domain entity is contained within the do\", \"main model layer and should not be propagated to other areas that it does not belong to, like to the\", \" presentation layer.\\n\\nAdditionally, you need to have always-valid entities (see the Designing valida\", \"tions in the domain model layer section) controlled by aggregate roots (root entities). Therefore, e\", \"ntities should not be bound to client views, because at the UI level some data might still not be va\", \"lidated. This reason is what the ViewModel is for. The ViewModel is a data model exclusively for pre\", \"sentation layer needs. The domain entities do not belong directly to the ViewModel. Instead, you nee\", \"d to translate between ViewModels and domain entities and vice versa.\\n\\nWhen tackling complexity, it \", \"is important to have a domain model controlled by aggregate roots that make sure that all the invari\", \"ants and rules related to that group of entities (aggregate) are performed through a single entry-po\", \"int or gate, the aggregate root.\\n\\nFigure 7-5 shows how a layered design is implemented in the eShopO\", \"nContainers application.\\n\\nOrdering.Domain\\n\\n\\u2022 i Dependencies\\n\\nLayers in a Domain-Driven Design Micros\", \"ervice\\n\\n\\u2022 '\\u00ae NuGet\\n\\n\\u2022 SDK\\n\\nNETStandard.Library\\n\\nOrdering microservice\\n\\nOrdering\\n\\n\\u2022 aQ] Ordering.API\\n\", \"\\n\\u2022 a|c# Ordering.Domain +\\n\\nD all Ordering Infrastructure\\n\\nASP.NET Web API\\n\\nNetwork access to microse\", \"rvice\\n\\n## Application layer API contracts/implementation Commands and command handlers Queries (when\", \" using an CQS approach)\\n\\nMicro ORMs like Dapper\\n\\nFigure 7-5. DDD layers in the ordering microservice\", \" in eShopOnContainers\\n\\n<!-- image -->\\n\\nThe three layers in a DDD microservice like Ordering. Each la\", \"yer is a VS project: Application layer is Ordering.API, Domain layer is Ordering.Domain and the Infr\", \"astructure layer is Ordering.Infrastructure. You want to design the system so that each layer commun\", \"icates only with certain other layers. That approach may be easier to enforce if layers are implemen\", \"ted as different class libraries, because you can clearly identify what dependencies are set between\", \" libraries. For instance, the domain model layer should not take a dependency on any other layer (th\", \"e domain model classes should be Plain Old Class Objects, or POCO, classes). As shown in Figure 7-6,\", \" the Ordering.Domain layer library has dependencies only on the .NET libraries or NuGet packages, bu\", \"t not on any other custom library, such as data library or persistence library.\\n\\nFigure 7-6. Layers \", \"implemented as libraries allow better control of dependencies between layers\\n\\n<!-- image -->\\n\\n## The\", \" domain model layer\\n\\nEric Evans's excellent book Domain Driven Design says the following about the d\", \"omain model layer and the application layer.\\n\\nDomain Model Layer : Responsible for representing conc\", \"epts of the business, information about the business situation, and business rules. State that refle\", \"cts the business situation is controlled and used here, even though the technical details of storing\", \" it are delegated to the infrastructure. This layer is the heart of business software.\\n\\n\\u2022\\n\\nThe domai\", \"n model layer is where the business is expressed. When you implement a microservice domain model lay\", \"er in .NET, that layer is coded as a class library with the domain entities that capture data plus b\", \"ehavior (methods with logic).\\n\\nFollowing the Persistence Ignorance and the Infrastructure Ignorance \", \"principles, this layer must completely ignore data persistence details. These persistence tasks shou\", \"ld be performed by the infrastructure layer. Therefore, this layer should not take direct dependenci\", \"es on the infrastructure, which means that an important rule is that your domain model entity classe\", \"s should be POCOs.\\n\\nDomain entities should not have any direct dependency (like deriving from a base\", \" class) on any data access infrastructure framework like Entity Framework or NHibernate. Ideally, yo\", \"ur domain entities should not derive from or implement any type defined in any infrastructure framew\", \"ork.\\n\\nMost modern ORM frameworks like Entity Framework Core allow this approach, so that your domain\", \" model classes are not coupled to the infrastructure. However, having POCO entities is not always po\", \"ssible when using certain NoSQL databases and frameworks, like Actors and Reliable Collections in Az\", \"ure Service Fabric.\\n\\nEven when it is important to follow the Persistence Ignorance principle for you\", \"r Domain model, you should not ignore persistence concerns. It is still important to understand the \", \"physical data model and how it maps to your entity object model. Otherwise you can create impossible\", \" designs.\\n\\nAlso, this aspect does not mean you can take a model designed for a relational database a\", \"nd directly move it to a NoSQL or document-oriented database. In some entity models, the model might\", \" fit, but usually it does not. There are still constraints that your entity model must adhere to, ba\", \"sed both on the storage technology and ORM technology.\\n\\n## The application layer\\n\\nMoving on to the a\", \"pplication layer, we can again cite Eric Evans's book Domain Driven Design:\\n\\nApplication Layer: Defi\", \"nes the jobs the software is supposed to do and directs the expressive domain objects to work out pr\", \"oblems. The tasks this layer is responsible for are meaningful to the business or necessary for inte\", \"raction with the application layers of other systems. This layer is kept thin. It does not contain b\", \"usiness rules or knowledge, but only coordinates tasks and delegates work to collaborations of domai\", \"n objects in the next layer down. It does not have state reflecting the business situation, but it c\", \"an have state that reflects the progress of a task for the user or the program.\\n\\nA microservice's ap\", \"plication layer in .NET is commonly coded as an ASP.NET Core Web API project. The project implements\", \" the microservice's interaction, remote network access, and the external Web APIs used from the UI o\", \"r client apps. It includes queries if using a CQRS approach, commands accepted by the microservice, \", \"and even the event-driven communication between microservices (integration events). The ASP.NET Core\", \" Web API that represents the application layer must not contain business rules or domain knowledge (\", \"especially domain rules for transactions or updates); these should be owned by the domain model clas\", \"s library. The application layer must only coordinate tasks and must not hold or define any domain s\", \"tate (domain model). It delegates the execution of business rules to the domain model classes themse\", \"lves (aggregate roots and domain entities), which will ultimately update the data within those domai\", \"n entities.\\n\\nMicroservice\\n\\nApplication\\n\\nLayer\\n\\nDepends on the Domain-Model Layer so it can:\\n\\n\\u2022 Use e\", \"ntity objects\\n\\n\\u2022 Use Repository Interfaces/Contracts\\n\\nBasically, the application logic is where you \", \"implement all use cases that depend on a given front end. For example, the implementation related to\", \" a Web API service. Depends on the Infrastructure Layer (thru DI) so it can:\\n\\nIdeally, it must NOT t\", \"ake dependency on any other layer\\n\\nThe goal is that the domain logic in the domain model layer, its \", \"invariants, the data model, and related business rules must be completely independent from the prese\", \"ntation and application layers. Most of all, the domain model layer must not directly depend on any \", \"infrastructure framework.\\n\\nInfrastructure\\n\\nLayer\\n\\n## The infrastructure layer \\u00b7 Use entity objects.\\n\", \"\\nThe infrastructure layer is how the data that is initially held in domain entities (in memory) is p\", \"ersisted in databases or another persistent store. An example is using Entity Framework Core code to\", \" implement the Repository pattern classes that use a DBContext to persist data in a relational datab\", \"ase.\\n\\nIn accordance with the previously mentioned Persistence Ignorance and Infrastructure Ignorance\", \" principles, the infrastructure layer must not 'contaminate' the domain model layer. You must keep t\", \"he domain model entity classes agnostic from the infrastructure that you use to persist data (EF or \", \"any other framework) by not taking hard dependencies on frameworks. Your domain model layer class li\", \"brary should have only your domain code, just POCO entity classes implementing the heart of your sof\", \"tware and completely decoupled from infrastructure technologies.\\n\\nThus, your layers or class librari\", \"es and projects should ultimately depend on your domain model layer (library), not vice versa, as sh\", \"own in Figure 7-7.\\n\\nFigure 7-7. Dependencies between layers in DDD\\n\\n<!-- image -->\\n\\nDependencies in \", \"a DDD Service, the Application layer depends on Domain and Infrastructure, and Infrastructure depend\", \"s on Domain, but Domain doesn't depend on any layer. This layer design should be independent for eac\", \"h microservice. As noted earlier, you can implement the most complex microservices following DDD pat\", \"terns, while implementing simpler data-driven microservices (simple CRUD in a single layer) in a sim\", \"pler way.\\n\\n\\u2022 Depends on the Domain-Model Layer so it can:\\n\\n\\u2022\\n\\n## Additional resources\\n\\n- DevIQ. Pers\", \"istence Ignorance principle https://deviq.com/persistence-ignorance/\\n- Oren Eini. Infrastructure Ign\", \"orance https://ayende.com/blog/3137/infrastructure-ignorance\\n- Angel Lopez. Layered Architecture In \", \"Domain-Driven Design https://ajlopez.wordpress.com/2008/09/12/layered-architecture-in-domain-driven-\", \"design/\\n\\n## Design a microservice domain model\\n\\nDefine one rich domain model for each business micro\", \"service or Bounded Context.\\n\\nYour goal is to create a single cohesive domain model for each business\", \" microservice or Bounded Context (BC). Keep in mind, however, that a BC or business microservice cou\", \"ld sometimes be composed of several physical services that share a single domain model. The domain m\", \"odel must capture the rules, behavior, business language, and constraints of the single Bounded Cont\", \"ext or business microservice that it represents.\\n\\n## The Domain Entity pattern\\n\\nEntities represent d\", \"omain objects and are primarily defined by their identity, continuity, and persistence over time, an\", \"d not only by the attributes that comprise them. As Eric Evans says, 'an object primarily defined by\", \" its identity is called an Entity.' Entities are very important in the domain model, since they are \", \"the base for a model. Therefore, you should identify and design them carefully.\\n\\nAn entity's identit\", \"y can cross multiple microservices or Bounded Contexts.\\n\\nThe same identity (that is, the same Id val\", \"ue, although perhaps not the same domain entity) can be modeled across multiple Bounded Contexts or \", \"microservices. However, that does not imply that the same entity, with the same attributes and logic\", \" would be implemented in multiple Bounded Contexts. Instead, entities in each Bounded Context limit \", \"their attributes and behaviors to those required in that Bounded Context's domain.\\n\\nFor instance, th\", \"e buyer entity might have most of a person's attributes that are defined in the user entity in the p\", \"rofile or identity microservice, including the identity. But the buyer entity in the ordering micros\", \"ervice might have fewer attributes, because only certain buyer data is related to the order process.\", \" The context of each microservice or Bounded Context impacts its domain model.\\n\\nDomain entities must\", \" implement behavior in addition to implementing data attributes.\\n\\nA domain entity in DDD must implem\", \"ent the domain logic or behavior related to the entity data (the object accessed in memory). For exa\", \"mple, as part of an order entity class you must have business logic and operations implemented as me\", \"thods for tasks such as adding an order item, data validation, and total calculation. The entity's m\", \"ethods take care of the invariants and rules of the entity instead of having those rules spread acro\", \"ss the application layer.\\n\\nOrder entity class\\n\\nAttributes\\n\\nID\\n\\nFirstName\\n\\nLastName\\n\\nAddress\\n\\nOrderlt\", \"ems (List)\\n\\nFigure 7-8 shows a domain entity that implements not only data attributes but operations\", \" or methods with related domain logic.\\n\\nMethods\\n\\nOrder constructor\\n\\nAddOrderltem(item)\\n\\nSetAddress(a\", \"ddress)\\n\\n## Entity's\\n\\nBehavior\\n\\nFigure 7-8. Example of a domain entity design implementing data plus\", \" behavior\\n\\n<!-- image -->\\n\\nA domain model entity implements behaviors through methods, that is, it's\", \" not an 'anemic' model. Of course, sometimes you can have entities that do not implement any logic a\", \"s part of the entity class. This can happen in child entities within an aggregate if the child entit\", \"y does not have any special logic because most of the logic is defined in the aggregate root. If you\", \" have a complex microservice that has logic implemented in the service classes instead of in the dom\", \"ain entities, you could be falling into the anemic domain model, explained in the following section.\", \"\\n\\n## Rich domain model versus anemic domain model\\n\\nIn his post AnemicDomainModel, Martin Fowler desc\", \"ribes an anemic domain model this way:\\n\\nThe basic symptom of an Anemic Domain Model is that at first\", \" blush it looks like the real thing. There are objects, many named after the nouns in the domain spa\", \"ce, and these objects are connected with the rich relationships and structure that true domain model\", \"s have. The catch comes when you look at the behavior, and you realize that there is hardly any beha\", \"vior on these objects, making them little more than bags of getters and setters.\\n\\nOf course, when yo\", \"u use an anemic domain model, those data models will be used from a set of service objects (traditio\", \"nally named the business layer ) which capture all the domain or business logic. The business layer \", \"sits on top of the data model and uses the data model just as data.\\n\\nThe anemic domain model is just\", \" a procedural style design. Anemic entity objects are not real objects because they lack behavior (m\", \"ethods). They only hold data properties and thus it is not objectoriented design. By putting all the\", \" behavior out into service objects (the business layer), you essentially end up with spaghetti code \", \"or transaction scripts, and therefore you lose the advantages that a domain model provides.\\n\\nRegardl\", \"ess, if your microservice or Bounded Context is very simple (a CRUD service), the anemic domain mode\", \"l in the form of entity objects with just data properties might be good enough, and it might not be \", \"worth implementing more complex DDD patterns. In that case, it will be simply a persistence model, b\", \"ecause you have intentionally created an entity with only data for CRUD purposes.\\n\\nThat is why micro\", \"services architectures are perfect for a multi-architectural approach depending on each Bounded Cont\", \"ext. For instance, in eShopOnContainers, the ordering microservice implements DDD patterns, but the \", \"catalog microservice, which is a simple CRUD service, does not.\\n\\nSome people say that the anemic dom\", \"ain model is an anti-pattern. It really depends on what you are implementing. If the microservice yo\", \"u are creating is simple enough (for example, a CRUD service), following the anemic domain model it \", \"is not an anti-pattern. However, if you need to tackle the complexity of a microservice's domain tha\", \"t has a lot of ever -changing business rules, the anemic domain model might be an anti-pattern for t\", \"hat microservice or Bounded Context. In that case, designing it as a rich model with entities contai\", \"ning data plus behavior as well as implementing additional DDD patterns (aggregates, value objects, \", \"etc.) might have huge benefits for the long-term success of such a microservice.\\n\\n## Additional reso\", \"urces\\n\\n- DevIQ. Domain Entity https://deviq.com/entity/\\n- Martin Fowler. The Domain Model https://ma\", \"rtinfowler.com/eaaCatalog/domainModel.html\\n- Martin Fowler. The Anemic Domain Model https://martinfo\", \"wler.com/bliki/AnemicDomainModel.html\\n\\n## The Value Object pattern\\n\\nAs Eric Evans has noted, 'Many o\", \"bjects do not have conceptual identity. These objects describe certain characteristics of a thing.'\\n\", \"\\nAn entity requires an identity, but there are many objects in a system that do not, like the Value \", \"Object pattern. A value object is an object with no conceptual identity that describes a domain aspe\", \"ct. These are objects that you instantiate to represent design elements that only concern you tempor\", \"arily. You care about what they are, not who they are. Examples include numbers and strings, but can\", \" also be higher-level concepts like groups of attributes.\\n\\nSomething that is an entity in a microser\", \"vice might not be an entity in another microservice, because in the second case, the Bounded Context\", \" might have a different meaning. For example, an address in an e-commerce application might not have\", \" an identity at all, since it might only represent a group of attributes of the customer's profile f\", \"or a person or company. In this case, the address should be classified as a value object. However, i\", \"n an application for an electric power utility company, the customer address could be important for \", \"the business domain. Therefore, the address must have an identity so the billing system can be direc\", \"tly linked to the address. In that case, an address should be classified as a domain entity.\\n\\nA pers\", \"on with a name and surname is usually an entity because a person has identity, even if the name and \", \"surname coincide with another set of values, such as if those names also refer to a different person\", \".\\n\\nValue objects are hard to manage in relational databases and ORMs like Entity Framework (EF), whe\", \"reas in document-oriented databases they are easier to implement and use.\\n\\nEF Core 2.0 and later ver\", \"sions include the Owned Entities feature that makes it easier to handle value objects, as we'll see \", \"in detail later on.\\n\\n## Additional resources\\n\\n- Martin Fowler. Value Object pattern\\n\\nhttps://martinf\", \"owler.com/bliki/ValueObject.html\\n\\n- Value Object\\n\\nhttps://deviq.com/value-object/\\n\\n- Value Objects i\", \"n Test-Driven Development\\n\\nhttps://leanpub.com/tdd-ebook/read#leanpub-auto-value-objects\\n\\n- Eric Eva\", \"ns. Domain-Driven Design: Tackling Complexity in the Heart of Software. (Book; includes a discussion\", \" of value objects) https://www.amazon.com/Domain-Driven-Design-Tackling-ComplexitySoftware/dp/032112\", \"5215/\\n\\n## The Aggregate pattern\\n\\nA domain model contains clusters of different data entities and pro\", \"cesses that can control a significant area of functionality, such as order fulfillment or inventory.\", \" A more fine-grained DDD unit is the aggregate, which describes a cluster or group of entities and b\", \"ehaviors that can be treated as a cohesive unit.\\n\\nYou usually define an aggregate based on the trans\", \"actions that you need. A classic example is an order that also contains a list of order items. An or\", \"der item will usually be an entity. But it will be a child entity within the order aggregate, which \", \"will also contain the order entity as its root entity, typically called an aggregate root.\\n\\nIdentify\", \"ing aggregates can be hard. An aggregate is a group of objects that must be consistent together, but\", \" you cannot just pick a group of objects and label them an aggregate. You must start with a domain c\", \"oncept and think about the entities that are used in the most common transactions related to that co\", \"ncept. Those entities that need to be transactionally consistent are what forms an aggregate. Thinki\", \"ng about transaction operations is probably the best way to identify aggregates.\\n\\n## The Aggregate R\", \"oot or Root Entity pattern\\n\\nAn aggregate is composed of at least one entity: the aggregate root, als\", \"o called root entity or primary entity. Additionally, it can have multiple child entities and value \", \"objects, with all entities and objects working together to implement required behavior and transacti\", \"ons.\\n\\nThe purpose of an aggregate root is to ensure the consistency of the aggregate; it should be t\", \"he only entry point for updates to the aggregate through methods or operations in the aggregate root\", \" class. You should make changes to entities within the aggregate only via the aggregate root. It is \", \"the aggregate's consistency guardian, considering all the invariants and consistency rules you might\", \" need to comply with in your aggregate. If you change a child entity or value object independently, \", \"the\\n\\nAggregate pattern\\n\\nBuyer Aggregate (One entity)\\n\\nOrder Aggregate (Multiple entities and Value-O\", \"bject)\\n\\naggregate root cannot ensure that the aggregate is in a valid state. It would be like a tabl\", \"e with a loose leg. Maintaining consistency is the main purpose of the aggregate root.\\n\\nID\\n\\nIn Figur\", \"e 7-9, you can see sample aggregates like the buyer aggregate, which contains a single entity (the a\", \"ggregate root Buyer). The order aggregate contains multiple entities and a value object.\\n\\nFullName\\n\\n\", \"[PaymentMethods]\\n\\nMethods\\n\\nBuyer (params) constructor\\n\\n## [Orderitems] 1 Orderltem (Child Entity)\\n\\nM\", \"ethods\\n\\nAttributes\\n\\nID\\n\\nFigure 7-9. Example of aggregates with multiple or single entities\\n\\n<!-- ima\", \"ge -->\\n\\nA DDD domain model is composed from aggregates, an aggregate can have just one entity or mor\", \"e, and can include value objects as well. Note that the Buyer aggregate could have additional child \", \"entities, depending on your domain, as it does in the ordering microservice in the eShopOnContainers\", \" reference application. Figure 7-9 just illustrates a case in which the buyer has a single entity, a\", \"s an example of an aggregate that contains only an aggregate root.\\n\\nIn order to maintain separation \", \"of aggregates and keep clear boundaries between them, it is a good practice in a DDD domain model to\", \" disallow direct navigation between aggregates and only having the foreign key (FK) field, as implem\", \"ented in the Ordering microservice domain model in eShopOnContainers. The Order entity only has a fo\", \"reign key field for the buyer, but not an EF Core navigation property, as shown in the following cod\", \"e:\\n\\n```\\npublic class Order : Entity, IAggregateRoot { private DateTime _orderDate; public Address Ad\", \"dress { get ; private set ; } private int? _buyerId; // FK pointing to a different aggregate root pu\", \"blic OrderStatus OrderStatus { get ; private set ; } private readonly List<OrderItem> _orderItems; p\", \"ublic IReadOnlyCollection<OrderItem> OrderItems => _orderItems; // ... Additional code }\\n```\\n\\n1\\n\\n&lt\", \";-1\\n\\nIdentifying and working with aggregates requires research and experience. For more information,\", \" see the following Additional resources list.\\n\\n## Additional resources\\n\\n- Vaughn Vernon. Effective A\", \"ggregate Design - Part I: Modeling a Single Aggregate (from https://dddcommunity.org/) https://dddco\", \"mmunity.org/wp-content/uploads/files/pdf\\\\_articles/Vernon\\\\_2011\\\\_1.pdf\\n- Vaughn Vernon. Effective Ag\", \"gregate Design - Part II: Making Aggregates Work Together (from https://dddcommunity.org/) https://d\", \"ddcommunity.org/wp-content/uploads/files/pdf\\\\_articles/Vernon\\\\_2011\\\\_2.pdf\\n- Vaughn Vernon. Effectiv\", \"e Aggregate Design - Part III: Gaining Insight Through Discovery (from https://dddcommunity.org/) ht\", \"tps://dddcommunity.org/wp-content/uploads/files/pdf\\\\_articles/Vernon\\\\_2011\\\\_3.pdf\\n- Sergey Grybniak.\", \" DDD Tactical Design Patterns https://www.codeproject.com/Articles/1164363/Domain-Driven-Design-Tact\", \"ical-DesignPatterns-Part\\n- Chris Richardson. Developing Transactional Microservices Using Aggregates\", \" https://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richardson\\n- DevIQ. The \", \"Aggregate pattern https://deviq.com/aggregate-pattern/\\n\\n## Implement a microservice domain model wit\", \"h .NET\\n\\nIn the previous section, the fundamental design principles and patterns for designing a doma\", \"in model were explained. Now it's time to explore possible ways to implement the domain model by usi\", \"ng .NET (plain C# code) and EF Core. Your domain model will be composed simply of your code. It will\", \" have just the EF Core model requirements, but not real dependencies on EF. You shouldn't have hard \", \"dependencies or references to EF Core or any other ORM in your domain model.\\n\\n## Domain model struct\", \"ure in a custom .NET Standard Library\\n\\nThe folder organization used for the eShopOnContainers refere\", \"nce application demonstrates the DDD model for the application. You might find that a different fold\", \"er organization more clearly communicates the design choices made for your application. As you can s\", \"ee in Figure 7-10, in the ordering domain model there are two aggregates, the order aggregate and th\", \"e buyer aggregate. Each aggregate is a group of domain entities and value objects, although you coul\", \"d have an aggregate composed of a single domain entity (the aggregate root or root entity) as well.\\n\", \"\\nWeb API\\n\\napplication layer project/library\\n\\nInfrastructure layer project/library\\n\\nOrdering Microser\", \"vice/Container\\n\\nOrdering\\n\\n\\u2192 \\u2022 6\\u0424] Ordering.API\\n\\n4 a C# Ordering. Domain\\n\\nFigure 7-10. Domain model s\", \"tructure for the ordering microservice in eShopOnContainers\\n\\n<!-- image -->\\n\\nAdditionally, the domai\", \"n model layer includes the repository contracts (interfaces) that are the infrastructure requirement\", \"s of your domain model. In other words, these interfaces express what repositories and the methods t\", \"he infrastructure layer must impl ement. It's critical that the implementation of the repositories b\", \"e placed outside of the domain model layer, in the infrastructure layer library, so the domain model\", \" layer isn't 'contaminated' by API or classes from infrastructure technologies, like Entity Framewor\", \"k.\\n\\nYou can also see a SeedWork folder that contains custom base classes that you can use as a base \", \"for your domain entities and value objects, so you don't have redundant code in each domain's object\", \" class.\\n\\n## Structure aggregates in a custom .NET Standard library\\n\\nAn aggregate refers to a cluster\", \" of domain objects grouped together to match transactional consistency. Those objects could be insta\", \"nces of entities (one of which is the aggregate root or root entity) plus any additional value objec\", \"ts.\\n\\nTransactional consistency means that an aggregate is guaranteed to be consistent and up to date\", \" at the end of a business action. For example, the order aggregate from the eShopOnContainers orderi\", \"ng microservice domain model is composed as shown in Figure 7-11.\\n\\nrepos &amp; EF code\\n\\n-=----\\n\\nOrde\", \"ring microservice\\n\\nOrder aggregate\\n\\n4 a\\u2264 OrderAggregate\\n\\n\\u2022 a C# Address.cs\\n\\n\\u2022 a C# Order.cs\\n\\n\\u2022 a C# \", \"Orderltem.cs\\n\\n\\u2022 a C# OrderStatus.cs\\n\\nFigure 7-11. The order aggregate in Visual Studio solution\\n\\n<!-\", \"- image -->\\n\\nIf you open any of the files in an aggregate folder, you can see how it's marked as eit\", \"her a custom base class or interface, like entity or value object, as implemented in the SeedWork fo\", \"lder.\\n\\n## Implement domain entities as POCO classes\\n\\nYou implement a domain model in .NET by creatin\", \"g POCO classes that implement your domain entities. In the following example, the Order class is def\", \"ined as an entity and also as an aggregate root. Because the Order class derives from the Entity bas\", \"e class, it can reuse common code related to entities. Bear in mind that these base classes and inte\", \"rfaces are defined by you in the domain model project, so it is your code, not infrastructure code f\", \"rom an ORM like EF.\\n\\n```\\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE 5.0 // Entity is a custom base cla\", \"ss with the ID public class Order : Entity, IAggregateRoot { private DateTime _orderDate; public Add\", \"ress Address { get ; private set ; } private int? _buyerId; public OrderStatus OrderStatus { get ; p\", \"rivate set ; } private int _orderStatusId; private string _description; private int? _paymentMethodI\", \"d; private readonly List<OrderItem> _orderItems; public IReadOnlyCollection<OrderItem> OrderItems =>\", \" _orderItems; public Order(string userId, Address address, int cardTypeId, string cardNumber, string\", \" cardSecurityNumber, string cardHolderName, DateTime cardExpiration, int? buyerId = null , int? paym\", \"entMethodId = null ) { _orderItems = new List<OrderItem>(); _buyerId = buyerId; _paymentMethodId = p\", \"aymentMethodId; _orderStatusId = OrderStatus.Submitted.Id; _orderDate = DateTime.UtcNow;\\n```\\n\\n```\\nAd\", \"dress = address; // ...Additional code ... } public void AddOrderItem(int productId, string productN\", \"ame, decimal unitPrice, decimal discount, string pictureUrl, int units = 1) { //... // Domain rules/\", \"logic for adding the OrderItem to the order // ... var orderItem = new OrderItem(productId, productN\", \"ame, unitPrice, discount, pictureUrl, units); _orderItems.Add(orderItem); } // ... // Additional met\", \"hods with domain rules/logic related to the Order aggregate // ... }\\n```\\n\\nIt's important to note tha\", \"t this is a domain entity implemented as a POCO class. It doesn't have any direct dependency on Enti\", \"ty Framework Core or any other infrastructure framework. This implementation is as it should be in D\", \"DD, just C# code implementing a domain model.\\n\\nIn addition, the class is decorated with an interface\", \" named IAggregateRoot. That interface is an empty interface, sometimes called a marker interface , t\", \"hat's used just to indicate that this entity class is also an aggregate root.\\n\\nA marker interface is\", \" sometimes considered as an antipattern; however, it's also a clean way to mark a class, especially \", \"when that interface might be evolving. An attribute could be the other choice for the marker, but it\", \"'s quicker to see the base class (Entity) n ext to the IAggregate interface instead of putting an Ag\", \"gregate attribute marker above the class. It's a matter of preferences, in any case.\\n\\nHaving an aggr\", \"egate root means that most of the code related to consistency and business rules of the aggregate's \", \"entities should be implemented as methods in the Order aggregate root class (for example, AddOrderIt\", \"em when adding an OrderItem object to the aggregate). You should not create or update OrderItems obj\", \"ects independently or directly; the AggregateRoot class must keep control and consistency of any upd\", \"ate operation against its child entities.\\n\\n## Encapsulate data in the Domain Entities\\n\\nA common prob\", \"lem in entity models is that they expose collection navigation properties as publicly accessible lis\", \"t types. This allows any collaborator developer to manipulate the contents of these collection types\", \", which may bypass important business rules related to the collection, possibly leaving the object i\", \"n an invalid state. The solution to this is to expose read-only access to related collections and ex\", \"plicitly provide methods that define ways in which clients can manipulate them.\\n\\nIn the previous cod\", \"e, note that many attributes are read-only or private and are only updatable by the class methods, s\", \"o any update considers business domain invariants and logic specified within the class methods.\\n\\nFor\", \" example, following DDD patterns, you should not do the following from any command handler method or\", \" application layer class (actually, it should be impossible for you to do so):\\n\\n```\\n// WRONG ACCORDI\", \"NG TO DDD PATTERNS -CODE AT THE APPLICATION LAYER OR // COMMAND HANDLERS // Code in command handler \", \"methods or Web API controllers //... (WRONG) Some code with business logic out of the domain classes\", \" ... OrderItem myNewOrderItem = new OrderItem(orderId, productId, productName, pictureUrl, unitPrice\", \", discount, units); //... (WRONG) Accessing the OrderItems collection directly from the application \", \"layer // or command handlers myOrder.OrderItems.Add(myNewOrderItem); //...\\n```\\n\\nIn this case, the Ad\", \"d method is purely an operation to add data, with direct access to the OrderItems collection. Theref\", \"ore, most of the domain logic, rules, or validations related to that operation with the child entiti\", \"es will be spread across the application layer (command handlers and Web API controllers).\\n\\nIf you g\", \"o around the aggregate root, the aggregate root cannot guarantee its invariants, its validity, or it\", \"s consistency. Eventually you'll have spaghetti code or transactional script code.\\n\\nTo follow DDD pa\", \"tterns, entities must not have public setters in any entity property. Changes in an entity should be\", \" driven by explicit methods with explicit ubiquitous language about the change they're performing in\", \" the entity.\\n\\nFurthermore, collections within the entity (like the order items) should be read-only \", \"properties (the AsReadOnly method explained later). You should be able to update it only from within\", \" the aggregate root class methods or the child entity methods.\\n\\nAs you can see in the code for the O\", \"rder aggregate root, all setters should be private or at least readonly externally, so that any oper\", \"ation against the entity's data or its child entities has to be performed through methods in the ent\", \"ity class. This maintains consistency in a controlled and object-oriented way instead of implementin\", \"g transactional script code.\\n\\nThe following code snippet shows the proper way to code the task of ad\", \"ding an OrderItem object to the Order aggregate.\\n\\n```\\n// RIGHT ACCORDING TO DDD--CODE AT THE APPLICA\", \"TION LAYER OR COMMAND HANDLERS // The code in command handlers or WebAPI controllers, related only t\", \"o application stuff // There is NO code here related to OrderItem object's business logic myOrder.Ad\", \"dOrderItem(productId, productName, pictureUrl, unitPrice, discount, units); // The code related to O\", \"rderItem params validations or domain rules should // be WITHIN the AddOrderItem method. //...\\n```\\n\\n\", \"In this snippet, most of the validations or logic related to the creation of an OrderItem object wil\", \"l be under the control of the Order aggregate root -in the AddOrderItem method -especially validatio\", \"ns and logic related to other elements in the aggregate. For instance, you might get the same produc\", \"t item as the result of multiple calls to AddOrderItem. In that method, you could examine the produc\", \"t items and consolidate the same product items into a single OrderItem object with several units.\\n\\nA\", \"dditionally, if there are different discount amounts but the product ID is the same, you would likel\", \"y apply the higher discount. This principle applies to any other domain logic for the OrderItem obje\", \"ct.\\n\\nIn addition, the new OrderItem(params) operation will also be controlled and performed by the A\", \"ddOrderItem method from the Order aggregate root. Therefore, most of the logic or validations relate\", \"d to that operation (especially anything that impacts the consistency between other child entities) \", \"will be in a single place within the aggregate root. That is the ultimate purpose of the aggregate r\", \"oot pattern.\\n\\nWhen you use Entity Framework Core 1.1 or later, a DDD entity can be better expressed \", \"because it allows mapping to fields in addition to properties. This is useful when protecting collec\", \"tions of child entities or value objects. With this enhancement, you can use simple private fields i\", \"nstead of properties and you can implement any update to the field collection in public methods and \", \"provide read-only access through the AsReadOnly method.\\n\\nIn DDD, you want to update the entity only \", \"through methods in the entity (or the constructor) in order to control any invariant and the consist\", \"ency of the data, so properties are defined only with a get accessor. The properties are backed by p\", \"rivate fields. Private members can only be accessed from within the class. However, there is one exc\", \"eption: EF Core needs to set these fields as well (so it can return the object with the proper value\", \"s).\\n\\n## Map properties with only get accessors to the fields in the database table\\n\\nMapping properti\", \"es to database table columns is not a domain responsibility but part of the infrastructure and persi\", \"stence layer. We mention this here just so you're aware of the new capabilities in EF Core 1.1 or la\", \"ter related to how you can model entities. Additional details on this topic are explained in the inf\", \"rastructure and persistence section.\\n\\nWhen you use EF Core 1.0 or later, within the DbContext you ne\", \"ed to map the properties that are defined only with getters to the actual fields in the database tab\", \"le. This is done with the HasField method of the PropertyBuilder class.\\n\\n## Map fields without prope\", \"rties\\n\\nWith the feature in EF Core 1.1 or later to map columns to fields, it's also possible to not \", \"use properties. Instead, you can just map columns from a table to fields. A common use case for this\", \" is private fields for an internal state that doesn't need to b e accessed from outside the entity.\\n\", \"\\nFor example, in the preceding OrderAggregate code example, there are several private fields, like t\", \"he \\\\_paymentMethodId field, that have no related property for either a setter or getter. That field \", \"could also be calculated within the order's business logic and used from the order's methods, but it\", \" needs to be persisted in the database as well. So in EF Core (since v1.1), there's a way to map a f\", \"ield without a related property to a column in the database. This is also explained in the Infrastru\", \"cture layer section of this guide.\\n\\n## Additional resources\\n\\n- Vaughn Vernon. Modeling Aggregates wi\", \"th DDD and Entity Framework. Note that this is not Entity Framework Core. https://kalele.io/blog-pos\", \"ts/modeling-aggregates-with-ddd-and-entity-framework/\\n- Julie Lerman. Data Points - Coding for Domai\", \"n-Driven Design: Tips for Data-Focused Devs\\n\\nhttps://learn.microsoft.com/archive/msdn-magazine/2013/\", \"august/data-points-coding-fordomain-driven-design-tips-for-data-focused-devs\\n\\n- Udi Dahan. How to cr\", \"eate fully encapsulated Domain Models https://udidahan.com/2008/02/29/how-to-create-fully-encapsulat\", \"ed-domain-models/\\n- Steve Smith. What is the difference between a DTO and a POCO? https://ardalis.co\", \"m/dtoor-poco/\\n\\n## Seedwork (reusable base classes and interfaces for your domain model)\\n\\nThe solutio\", \"n folder contains a SeedWork folder. This folder contains custom base classes that you can use as a \", \"base for your domain entities and value objects. Use these base classes so you don't have redundant \", \"code in each domain's object class. The folder for these types of classes is called SeedWork and not\", \" something like Framework . It's called SeedWork because the folder contains just a small subset of \", \"reusable classes that cannot really be considered a framework. Seedwork is a term introduced by Mich\", \"ael Feathers and popularized by Martin Fowler but you could also name that folder Common, SharedKern\", \"el, or similar.\\n\\nFigure 7-12 shows the classes that form the seedwork of the domain model in the ord\", \"ering microservice. It has a few custom base classes like Entity, ValueObject, and Enumeration, plus\", \" a few interfaces. These interfaces (IRepository and IUnitOfWork) inform the infrastructure layer ab\", \"out what needs to be implemented. Those interfaces are also used through Dependency Injection from t\", \"he application layer.\\n\\nFigure 7-12 . A sample set of domain model 'seedwork' base classes and interf\", \"aces\\n\\n<!-- image -->\\n\\nThis is the type of copy and paste reuse that many developers share between pr\", \"ojects, not a formal framework. You can have seedworks in any layer or library. However, if the set \", \"of classes and interfaces gets large enough, you might want to create a single class library.\\n\\n## Th\", \"e custom Entity base class\\n\\nThe following code is an example of an Entity base class where you can p\", \"lace code that can be used the same way by any domain entity, such as the entity ID, equality operat\", \"ors, a domain event list per entity, etc.\\n\\n```\\n// COMPATIBLE WITH ENTITY FRAMEWORK CORE (1.1 and lat\", \"er) public abstract class Entity { int? _requestedHashCode; int _Id; private List<INotification> _do\", \"mainEvents; public virtual int Id { get { return _Id; } protected set { _Id = value; } } public List\", \"<INotification> DomainEvents => _domainEvents; public void AddDomainEvent(INotification eventItem) {\", \" _domainEvents = _domainEvents ?? new List<INotification>(); _domainEvents.Add(eventItem); } public \", \"void RemoveDomainEvent(INotification eventItem) { if (_domainEvents is null ) return ; _domainEvents\", \".Remove(eventItem); } public bool IsTransient() { return this .Id == default (Int32); } public overr\", \"ide bool Equals(object obj) { if (obj == null || !(obj is Entity)) return false ; if (Object.Referen\", \"ceEquals( this , obj)) return true ; if ( this .GetType() != obj.GetType()) return false ; Entity it\", \"em = (Entity)obj; if (item.IsTransient() || this .IsTransient()) return false ; else return item.Id \", \"== this .Id; } public override int GetHashCode() { if (!IsTransient())\\n```\\n\\n```\\n{ if (!_requestedHas\", \"hCode.HasValue) _requestedHashCode = this .Id.GetHashCode() ^ 31; // XOR for random distribution. Se\", \"e: // https://learn.microsoft.com/archive/blogs/ericlippert/guidelines-and-rulesfor-gethashcode retu\", \"rn _requestedHashCode.Value; } else return base .GetHashCode(); } public static bool operator ==(Ent\", \"ity left, Entity right) { if (Object.Equals(left, null )) return (Object.Equals(right, null )); else\", \" return left.Equals(right); } public static bool operator !=(Entity left, Entity right) { return !(l\", \"eft == right); } }\\n```\\n\\nThe previous code using a domain event list per entity will be explained in \", \"the next sections when focusing on domain events.\\n\\n## Repository contracts (interfaces) in the domai\", \"n model layer\\n\\nRepository contracts are simply .NET interfaces that express the contract requirement\", \"s of the repositories to be used for each aggregate.\\n\\nThe repositories themselves, with EF Core code\", \" or any other infrastructure dependencies and code (Linq, SQL, etc.), must not be implemented within\", \" the domain model; the repositories should only implement the interfaces you define in the domain mo\", \"del.\\n\\nA pattern related to this practice (placing the repository interfaces in the domain model laye\", \"r) is the Separated Interface pattern. As explained by Martin Fowler, 'Use Separated Interface to de\", \"fine an interface in one package but implement it in another. This way a client that needs the depen\", \"dency to the interface can be completely unaware of the implementation.'\\n\\nFollowing the Separated In\", \"terface pattern enables the application layer (in this case, the Web API project for the microservic\", \"e) to have a dependency on the requirements defined in the domain model, but not a direct dependency\", \" to the infrastructure/persistence layer. In addition, you can use Dependency Injection to isolate t\", \"he implementation, which is implemented in the infrastructure/ persistence layer using repositories.\", \"\\n\\nFor example, the following example with the IOrderRepository interface defines what operations the\", \" OrderRepository class will need to implement at the infrastructure layer. In the current implementa\", \"tion of the application, the code just needs to add or update orders to the database, since queries \", \"are split following the simplified CQRS approach.\\n\\n```\\n// Defined at IOrderRepository.cs public inte\", \"rface IOrderRepository : IRepository<Order> {\\n```\\n\\n```\\nOrder Add(Order order); void Update(Order ord\", \"er); Task<Order> GetAsync(int orderId); } // Defined at IRepository.cs (Part of the Domain Seedwork)\", \" public interface IRepository<T> where T : IAggregateRoot { IUnitOfWork UnitOfWork { get ; } }\\n```\\n\\n\", \"## Additional resources\\n\\n- Martin Fowler. Separated Interface.\\n\\nhttps://www.martinfowler.com/eaaCata\", \"log/separatedInterface.html\\n\\n## Implement value objects\\n\\nAs discussed in earlier sections about enti\", \"ties and aggregates, identity is fundamental for entities. However, there are many objects and data \", \"items in a system that do not require an identity and identity tracking, such as value objects.\\n\\nA v\", \"alue object can reference other entities. For example, in an application that generates a route that\", \" describes how to get from one point to another, that route would be a value object. It would be a s\", \"napshot of points on a specific route, but this suggested route would not have an identity, even tho\", \"ugh internally it might refer to entities like City, Road, etc.\\n\\nFigure 7-13 shows the Address value\", \" object within the Order aggregate.\\n\\nValue Object within Aggregate\\n\\n## Order Aggregate (Multiple ent\", \"ities and Value-Object)\\n\\nOrder (Aggregate Root)\\n\\nAttributes\\n\\nID\\n\\nOrderDate\\n\\n[BuyerID]\\n\\n[Address]\\n\\n[O\", \"rderitems]\\n\\n\\u2022.\\u2022\\n\\nMethods\\n\\nOrder (params) constructor\\n\\nAddOrderltem(item)\\n\\nSetAddress(address)\\n\\nCalcu\", \"late TotalO\\n\\nAddress (Value-Object)\\n\\n## 1 Attributes\\n\\nFigure 7-13. Address value object within the O\", \"rder aggregate\\n\\n<!-- image -->\\n\\nAs shown in Figure 7-13, an entity is usually composed of multiple a\", \"ttributes. For example, the Order entity can be modeled as an entity with an identity and composed i\", \"nternally of a set of attributes such as OrderId, OrderDate, OrderItems, etc. But the address, which\", \" is simply a complex-value composed of country/region, street, city, etc., and has no identity in th\", \"is domain, must be modeled and treated as a value object.\\n\\n## Important characteristics of value obj\", \"ects\\n\\nThere are two main characteristics for value objects:\\n\\n- They have no identity.\\n- They are imm\", \"utable.\\n\\nThe first characteristic was already discussed. Immutability is an important requirement. T\", \"he values of a value object must be immutable once the object is created. Therefore, when the object\", \" is\\n\\n1\\n\\nconstructed, you must provide the required values, but you must not allow them to change dur\", \"ing the object's lifetime.\\n\\nValue objects allow you to perform certain tricks for performance, thank\", \"s to their immutable nature. This is especially true in systems where there may be thousands of valu\", \"e object instances, many of which have the same values. Their immutable nature allows them to be reu\", \"sed; they can be interchangeable objects, since their values are the same and they have no identity.\", \" This type of optimization can sometimes make a difference between software that runs slowly and sof\", \"tware with good performance. Of course, all these cases depend on the application environment and de\", \"ployment context.\\n\\n## Value object implementation in C#\\n\\nIn terms of implementation, you can have a \", \"value object base class that has basic utility methods like equality based on the comparison between\", \" all the attributes (since a value object must not be based on identity) and other fundamental chara\", \"cteristics. The following example shows a value object base class used in the ordering microservice \", \"from eShopOnContainers.\\n\\n```\\npublic abstract class ValueObject { protected static bool EqualOperator\", \"(ValueObject left, ValueObject right) { if (ReferenceEquals(left, null ) ^ ReferenceEquals(right, nu\", \"ll )) { return false ; } return ReferenceEquals(left, right) || left.Equals(right); } protected stat\", \"ic bool NotEqualOperator(ValueObject left, ValueObject right) { return !(EqualOperator(left, right))\", \"; } protected abstract IEnumerable<object> GetEqualityComponents(); public override bool Equals(obje\", \"ct obj) { if (obj == null || obj.GetType() != GetType()) { return false ; } var other = (ValueObject\", \")obj; return this .GetEqualityComponents().SequenceEqual(other.GetEqualityComponents()); } public ov\", \"erride int GetHashCode() { return GetEqualityComponents() .Select(x => x != null ? x.GetHashCode() :\", \" 0) .Aggregate((x, y) => x ^ y); } // Other utility methods }\\n```\\n\\nThe ValueObject is an abstract cl\", \"ass type, but in this example, it doesn't overload the == and != operators. You could choose to do s\", \"o, making comparisons delegate to the Equals override. For example, consider the following operator \", \"overloads to the ValueObject type:\\n\\n```\\npublic static bool operator ==(ValueObject one, ValueObject \", \"two) { return EqualOperator(one, two); } public static bool operator !=(ValueObject one, ValueObject\", \" two) { return NotEqualOperator(one, two); } You can use this class when implementing your actual va\", \"lue object, as with the Address value object shown in the following example: public class Address : \", \"ValueObject { public String Street { get ; private set ; } public String City { get ; private set ; \", \"} public String State { get ; private set ; } public String Country { get ; private set ; } public S\", \"tring ZipCode { get ; private set ; } public Address() { } public Address(string street, string city\", \", string state, string country, string zipcode) { Street = street; City = city; State = state; Count\", \"ry = country; ZipCode = zipcode; } protected override IEnumerable<object> GetEqualityComponents() { \", \"// Using a yield return statement to return each element one at a time yield return Street; yield re\", \"turn City; yield return State; yield return Country; yield return ZipCode; } }\\n```\\n\\nThis value objec\", \"t implementation of Address has no identity, and therefore no ID field is defined for it, either in \", \"the Address class definition or the ValueObject class definition.\\n\\nHaving no ID field in a class to \", \"be used by Entity Framework (EF) was not possible until EF Core 2.0, which greatly helps to implemen\", \"t better value objects with no ID. That is precisely the explanation of the next section.\\n\\nIt could \", \"be argued that value objects, being immutable, should be read-only (that is, have get-only propertie\", \"s), and that's indeed true. However, value objects are usually serialized and deserialized to go\\n\\nth\", \"rough message queues, and being read-only stops the deserializer from assigning values, so you just \", \"leave them as private set, which is read-only enough to be practical.\\n\\n## Value object comparison se\", \"mantics\\n\\nTwo instances of the Address type can be compared using all the following methods:\\n\\n```\\nvar\", \" one = new Address(\\\"1 Microsoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); var two = new Address(\\\"1 Micr\", \"osoft Way\\\", \\\"Redmond\\\", \\\"WA\\\", \\\"US\\\", \\\"98052\\\"); Console.WriteLine(EqualityComparer<Address>.Default.Equ\", \"als(one, two)); // True Console.WriteLine(object.Equals(one, two)); // True Console.WriteLine(one.Eq\", \"uals(two)); // True Console.WriteLine(one == two); // True\\n```\\n\\nWhen all the values are the same, th\", \"e comparisons are correctly evaluated as true. If you didn't choose to overload the == and != operat\", \"ors, then the last comparison of one == two would evaluate as false. For more information, see Overl\", \"oad ValueObject equality operators.\\n\\n## How to persist value objects in the database with EF Core 2.\", \"0 and later\\n\\nYou just saw how to define a value object in your domain model. But how can you actuall\", \"y persist it into the database using Entity Framework Core since it usually targets entities with id\", \"entity?\\n\\n## Background and older approaches using EF Core 1.1\\n\\nAs background, a limitation when usin\", \"g EF Core 1.0 and 1.1 was that you could not use complex types as defined in EF 6.x in the tradition\", \"al .NET Framework. Therefore, if using EF Core 1.0 or 1.1, you needed to store your value object as \", \"an EF entity with an ID field. Then, so it looked more like a value object with no identity, you cou\", \"ld hide its ID so you make clear that the identity of a value object is not important in the domain \", \"model. You could hide that ID by using the ID as a shadow property. Since that configuration for hid\", \"ing the ID in the model is set up in the EF infrastructure level, it would be kind of transparent fo\", \"r your domain model.\\n\\nIn the initial version of eShopOnContainers (.NET Core 1.1), the hidden ID nee\", \"ded by EF Core infrastructure was implemented in the following way in the DbContext level, using Flu\", \"ent API at the infrastructure project. Therefore, the ID was hidden from the domain model point of v\", \"iew, but still present in the infrastructure.\\n\\n```\\n// Old approach with EF Core 1.1 // Fluent API wi\", \"thin the OrderingContext:DbContext in the Infrastructure project void ConfigureAddress(EntityTypeBui\", \"lder<Address> addressConfiguration) { addressConfiguration.ToTable(\\\"address\\\", DEFAULT_SCHEMA); addre\", \"ssConfiguration.Property<int>(\\\"Id\\\")  // Id is a shadow property .IsRequired(); addressConfiguration.\", \"HasKey(\\\"Id\\\");   // Id is a shadow property }\\n```\\n\\nHowever, the persistence of that value object into\", \" the database was performed like a regular entity in a different table.\\n\\nWith EF Core 2.0 and later,\", \" there are new and better ways to persist value objects.\\n\\n## Persist value objects as owned entity t\", \"ypes in EF Core 2.0 and later\\n\\nEven with some gaps between the canonical value object pattern in DDD\", \" and the owned entity type in EF Core, it's currently the best way to persist value objects with EF \", \"Core 2.0 and later. You can see limitations at the end of this section.\\n\\nThe owned entity type featu\", \"re was added to EF Core since version 2.0.\\n\\nAn owned entity type allows you to map types that do not\", \" have their own identity explicitly defined in the domain model and are used as properties, such as \", \"a value object, within any of your entities. An owned entity type shares the same CLR type with anot\", \" her entity type (that is, it's just a regular class). The entity containing the defining navigation\", \" is the owner entity. When querying the owner, the owned types are included by default.\\n\\nJust by loo\", \"king at the domain model, an owned type looks like it doesn't have any identity. However, under the \", \"covers, owned types do have the identity, but the owner navigation property is part of this identity\", \".\\n\\nThe identity of instances of owned types is not completely their own. It consists of three compon\", \"ents:\\n\\n- The identity of the owner\\n- The navigation property pointing to them\\n- In the case of colle\", \"ctions of owned types, an independent component (supported in EF Core 2.2 and later).\\n\\nFor example, \", \"in the Ordering domain model at eShopOnContainers, as part of the Order entity, the Address value ob\", \"ject is implemented as an owned entity type within the owner entity, which is the Order entity. Addr\", \"ess is a type with no identity property defined in the domain model. It is used as a property of the\", \" Order type to specify the shipping address for a particular order.\\n\\nBy convention, a shadow primary\", \" key is created for the owned type and it will be mapped to the same table as the owner by using tab\", \"le splitting. This allows to use owned types similarly to how complex types are used in EF6 in the t\", \"raditional .NET Framework.\\n\\nIt is important to note that owned types are never discovered by convent\", \"ion in EF Core, so you have to declare them explicitly.\\n\\nIn eShopOnContainers, in the OrderingContex\", \"t.cs file, within the OnModelCreating() method, multiple infrastructure configurations are applied. \", \"One of them is related to the Order entity.\\n\\n```\\n// Part of the OrderingContext.cs class at the Orde\", \"ring.Infrastructure project // protected override void OnModelCreating(ModelBuilder modelBuilder) { \", \"modelBuilder.ApplyConfiguration( new ClientRequestEntityTypeConfiguration()); modelBuilder.ApplyConf\", \"iguration( new PaymentMethodEntityTypeConfiguration()); modelBuilder.ApplyConfiguration( new OrderEn\", \"tityTypeConfiguration()); modelBuilder.ApplyConfiguration( new OrderItemEntityTypeConfiguration()); \", \"//...Additional type configurations }\\n```\\n\\nIn the following code, the persistence infrastructure is \", \"defined for the Order entity:\\n\\n```\\n// Part of the OrderEntityTypeConfiguration.cs class // public vo\", \"id Configure(EntityTypeBuilder<Order> orderConfiguration) { orderConfiguration.ToTable(\\\"orders\\\", Ord\", \"eringContext.DEFAULT_SCHEMA); orderConfiguration.HasKey(o => o.Id); orderConfiguration.Ignore(b => b\", \".DomainEvents); orderConfiguration.Property(o => o.Id) .ForSqlServerUseSequenceHiLo(\\\"orderseq\\\", Orde\", \"ringContext.DEFAULT_SCHEMA); //Address value object persisted as owned entity in EF Core 2.0 orderCo\", \"nfiguration.OwnsOne(o => o.Address); orderConfiguration.Property<DateTime>(\\\"OrderDate\\\").IsRequired()\", \"; //...Additional validations, constraints and code... //... }\\n```\\n\\nIn the previous code, the orderC\", \"onfiguration.OwnsOne(o =&gt; o.Address) method specifies that the Address property is an owned entit\", \"y of the Order type.\\n\\nBy default, EF Core conventions name the database columns for the properties o\", \"f the owned entity type as EntityProperty\\\\_OwnedEntityProperty. Therefore, the internal properties o\", \"f Address will appear in the Orders table with the names Address\\\\_Street, Address\\\\_City (and so on f\", \"or State, Country, and ZipCode).\\n\\nYou can append the Property().HasColumnName() fluent method to ren\", \"ame those columns. In the case where Address is a public property, the mappings would be like the fo\", \"llowing:\\n\\n```\\norderConfiguration.OwnsOne(p => p.Address) .Property(p=>p.Street).HasColumnName(\\\"Shipp\", \"ingStreet\\\"); orderConfiguration.OwnsOne(p => p.Address) .Property(p=>p.City).HasColumnName(\\\"Shipping\", \"City\\\");\\n```\\n\\nIt's possible to chain the OwnsOne method in a fluent mapping. In the following hypothe\", \"tical example, OrderDetails owns BillingAddress and ShippingAddress, which are both Address types. T\", \"hen OrderDetails is owned by the Order type.\\n\\n```\\norderConfiguration.OwnsOne(p => p.OrderDetails, cb\", \" => { cb.OwnsOne(c => c.BillingAddress); cb.OwnsOne(c => c.ShippingAddress); }); //... //... public \", \"class Order { public int Id { get ; set ; } public OrderDetails OrderDetails { get ; set ; } } publi\", \"c class OrderDetails { public Address BillingAddress { get ; set ; }\\n```\\n\\n```\\npublic Address Shippin\", \"gAddress { get ; set ; } } public class Address { public string Street { get ; set ; } public string\", \" City { get ; set ; } }\\n```\\n\\n## Additional details on owned entity types\\n\\n- Owned types are defined \", \"when you configure a navigation property to a particular type using the OwnsOne fluent API.\\n- The de\", \"finition of an owned type in our metadata model is a composite of: the owner type, the navigation pr\", \"operty, and the CLR type of the owned type.\\n- The identity (key) of an owned type instance in our st\", \"ack is a composite of the identity of the owner type and the definition of the owned type.\\n\\n## Owned\", \" entities capabilities\\n\\n- Owned types can reference other entities, either owned (nested owned types\", \") or non-owned (regular reference navigation properties to other entities).\\n- You can map the same C\", \"LR type as different owned types in the same owner entity through separate navigation properties.\\n- \", \"Table splitting is set up by convention, but you can opt out by mapping the owned type to a differen\", \"t table using ToTable.\\n- Eager loading is performed automatically on owned types, that is, there's n\", \"o need to call .Include() on the query.\\n- Can be configured with attribute [Owned], using EF Core 2.\", \"1 and later.\\n- Can handle collections of owned types (using version 2.2 and later).\\n\\n## Owned entiti\", \"es limitations\\n\\n- You can't create a DbSet&lt;T&gt; of an owned type (by design).\\n- You can't call M\", \"odelBuilder.Entity&lt;T&gt;() on owned types (currently by design).\\n- No support for optional (that \", \"is, nullable) owned types that are mapped with the owner in the same table (that is, using table spl\", \"itting). This is because mapping is done for each property, there is no separate sentinel for the nu\", \"ll complex value as a whole.\\n- No inheritance-mapping support for owned types, but you should be abl\", \"e to map two leaf types of the same inheritance hierarchies as different owned types. EF Core will n\", \"ot reason about the fact that they are part of the same hierarchy.\\n\\n## Main differences with EF6's c\", \"omplex types\\n\\n- Table splitting is optional, that is, they can optionally be mapped to a separate ta\", \"ble and still be owned types.\\n\\n## Additional resources\\n\\n- Martin Fowler. ValueObject pattern\\n\\nhttps:\", \"//martinfowler.com/bliki/ValueObject.html\\n\\n- Eric Evans. Domain-Driven Design: Tackling Complexity i\", \"n the Heart of Software. (Book; includes a discussion of value objects) https://www.amazon.com/Domai\", \"n-Driven-Design-Tackling-ComplexitySoftware/dp/0321125215/\\n- Vaughn Vernon. Implementing Domain-Driv\", \"en Design. (Book; includes a discussion of value objects)\\n- https://www.amazon.com/Implementing-Doma\", \"in-Driven-Design-VaughnVernon/dp/0321834577/\\n- Owned Entity Types\\n\\nhttps://learn.microsoft.com/ef/co\", \"re/modeling/owned-entities\\n\\n- Shadow Properties\\n\\nhttps://learn.microsoft.com/ef/core/modeling/shadow\", \"-properties\\n\\n- Complex types and/or value objects . Discussion in the EF Core GitHub repo (Issues ta\", \"b) https://github.com/dotnet/efcore/issues/246\\n- ValueObject.cs. Base value object class in eShopOnC\", \"ontainers. https://github.com/dotnetarchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Or\", \"dering.Domain/SeedWor k/ValueObject.cs\\n- ValueObject.cs. Base value object class in CSharpFunctional\", \"Extensions. https://github.com/vkhorikov/CSharpFunctionalExtensions/blob/master/CSharpFunctionalExte\", \" nsions/ValueObject/ValueObject.cs\\n- Address class. Sample value object class in eShopOnContainers. \", \"https://github.com/dotnetarchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Doma\", \"in/Aggregat esModel/OrderAggregate/Address.cs\\n\\nUse enumeration classes instead of enum types\\n\\nEnumer\", \"ations (or enum types for short) are a thin language wrapper around an integral type. You might want\", \" to limit their use to when you are storing one value from a closed set of values. Classification ba\", \"sed on sizes (small, medium, large) is a good example. Using enums for control flow or more robust a\", \"bstractions can be a code smell. This type of usage leads to fragile code with many control flow sta\", \"tements checking values of the enum.\\n\\nInstead, you can create Enumeration classes that enable all th\", \"e rich features of an object-oriented language.\\n\\nHowever, this isn't a critical topic and in many ca\", \"ses, for simplicity, you can still use regular enum types if that's your preference. The use of enum\", \"eration classes is more related to business -related concepts.\\n\\n## Implement an Enumeration base cla\", \"ss\\n\\nThe ordering microservice in eShopOnContainers provides a sample Enumeration base class implemen\", \"tation, as shown in the following example:\\n\\n```\\npublic abstract class Enumeration : IComparable { pu\", \"blic string Name { get ; private set ; } public int Id { get ; private set ; } protected Enumeration\", \"(int id, string name) => (Id, Name) = (id, name); public override string ToString() => Name; public \", \"static IEnumerable<T> GetAll<T>() where T : Enumeration => typeof (T).GetFields(BindingFlags.Public \", \"| BindingFlags.Static | BindingFlags.DeclaredOnly) .Select(f => f.GetValue( null )) .Cast<T>(); publ\", \"ic override bool Equals(object obj) { if (obj is not Enumeration otherValue) { return false ; } var \", \"typeMatches = GetType().Equals(obj.GetType()); var valueMatches = Id.Equals(otherValue.Id); return t\", \"ypeMatches && valueMatches; } public int CompareTo(object other) => Id.CompareTo(((Enumeration)other\", \").Id); // Other utility methods ... } You can use this class as a type in any entity or value object\", \", as for the following CardType : Enumeration class: public class CardType : Enumeration { public st\", \"atic CardType Amex = new (1, nameof(Amex)); public static CardType Visa = new (2, nameof(Visa)); pub\", \"lic static CardType MasterCard = new (3, nameof(MasterCard)); public CardType(int id, string name) :\", \" base (id, name) {\\n```\\n\\n}\\n\\n}\\n\\n## Additional resources\\n\\n- Jimmy Bogard. Enumeration classes\\n\\nhttps://\", \"lostechies.com/jimmybogard/2008/08/12/enumeration-classes/\\n\\n- Steve Smith. Enum Alternatives in C#\\n\\n\", \"https://ardalis.com/enum-alternatives-in-c\\n\\n- Enumeration.cs. Base Enumeration class in eShopOnConta\", \"iners https://github.com/dotnetarchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Orderin\", \"g.Domain/SeedWor k/Enumeration.cs\\n- CardType.cs . Sample Enumeration class in eShopOnContainers. htt\", \"ps://github.com/dotnetarchitecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.Domain/\", \"Aggregat esModel/BuyerAggregate/CardType.cs\\n- SmartEnum . Ardalis - Classes to help produce strongly\", \" typed smarter enums in .NET. https://www.nuget.org/packages/Ardalis.SmartEnum/\\n\\n## Design validatio\", \"ns in the domain model layer\\n\\nIn DDD, validation rules can be thought as invariants. The main respon\", \"sibility of an aggregate is to enforce invariants across state changes for all the entities within t\", \"hat aggregate.\\n\\nDomain entities should always be valid entities. There are a certain number of invar\", \"iants for an object that should always be true. For example, an order item object always has to have\", \" a quantity that must be a positive integer, plus an article name and price. Therefore, invariants e\", \"nforcement is the responsibility of the domain entities (especially of the aggregate root) and an en\", \"tity object should not be able to exist without being valid. Invariant rules are simply expressed as\", \" contracts, and exceptions or notifications are raised when they are violated.\\n\\nThe reasoning behind\", \" this is that many bugs occur because objects are in a state they should never have been in.\\n\\nLet's \", \"propose we now have a SendUserCreationEmailService that takes a UserProfile \\u2026 how can we rationalize\", \" in that service that Name is not null? Do we check it again? Or more likely \\u2026 you just don't bother\", \" to check and 'hope for the best'you hope that someone bothered to validate it before sending it to \", \"you. Of course, using TDD one of the first tests we should be writing is that if I send a customer w\", \"ith a null name that it should raise an error. But once we start writing these kinds of tests over a\", \"nd ov er again we realize \\u2026 'what if we never allowed name to become null? we wouldn't have all of t\", \"hese tests!'.\\n\\n## Implement validations in the domain model layer\\n\\nValidations are usually implement\", \"ed in domain entity constructors or in methods that can update the entity. There are multiple ways t\", \"o implement validations, such as verifying data and raising exceptions if the validation fails. Ther\", \"e are also more advanced patterns such as using the Specification pattern for validations, and the N\", \"otification pattern to return a collection of errors instead of returning an exception for each vali\", \"dation as it occurs.\\n\\n## Validate conditions and throw exceptions\\n\\nThe following code example shows \", \"the simplest approach to validation in a domain entity by raising an exception. In the references ta\", \"ble at the end of this section you can see links to more advanced implementations based on the patte\", \"rns we have discussed previously.\\n\\n```\\npublic void SetAddress(Address address) { _shippingAddress = \", \"address?? throw new ArgumentNullException(nameof(address)); } A better example would demonstrate the\", \" need to ensure that either the internal state did not change, or that all the mutations for a metho\", \"d occurred. For example, the following implementation would leave the object in an invalid state: pu\", \"blic void SetAddress(string line1, string line2, string city, string state, int zip) { _shippingAddr\", \"ess.line1 = line1 ?? throw new ... _shippingAddress.line2 = line2; _shippingAddress.city = city ?? t\", \"hrow new ... _shippingAddress.state = (IsValid(state) ? state : throw new \\u2026 ); }\\n```\\n\\nIf the value o\", \"f the state is invalid, the first address line and the city have already been changed. That might ma\", \"ke the address invalid.\\n\\nA similar approach can be used in the entity's constructor, raising an exce\", \"ption to make sure that the entity is valid once it is created.\\n\\n## Use validation attributes in the\", \" model based on data annotations\\n\\nData annotations, like the Required or MaxLength attributes, can b\", \"e used to configure EF Core database field properties, as explained in detail in the Table mapping s\", \"ection, but they no longer work for entity validation in EF Core (neither does the IValidatableObjec\", \"t.Validate method), as they have done since EF 4.x in .NET Framework.\\n\\nData annotations and the IVal\", \"idatableObject interface can still be used for model validation during model binding, prior to the c\", \"ontroller's actions invocation as usual, but that model is meant to be a ViewModel or DTO and that's\", \" an MVC or API concern not a domain model concern.\\n\\nHaving made the conceptual difference clear, you\", \" can still use data annotations and IValidatableObject in the entity class for validation, if your a\", \"ctions receive an entity class object parameter, which is not recommended. In that case, validation \", \"will occur upon model binding, just before invoking the action and you can check the controller's Mo\", \"delState.IsValid property to check\\n\\nthe result, but then again, it happens in the controller, not be\", \"fore persisting the entity object in the DbContext, as it had done since EF 4.x.\\n\\nYou can still impl\", \"ement custom validation in the entity class using data annotations and the IValidatableObject.Valida\", \"te method, by overriding the DbContext's SaveChanges method.\\n\\nYou can see a sample implementation fo\", \"r validating IValidatableObject entities in this comment on GitHub . That sample doesn't do attribut\", \"e -based validations, but they should be easy to implement using reflection in the same override.\\n\\nH\", \"owever, from a DDD point of view, the domain model is best kept lean with the use of exceptions in y\", \"our entity's behavior methods, or by implementing the Specification and Notification patterns to enf\", \"orce validation rules.\\n\\nIt can make sense to use data annotations at the application layer in ViewMo\", \"del classes (instead of domain entities) that will accept input, to allow for model validation withi\", \"n the UI layer. However, this should not be done at the exclusion of validation within the domain mo\", \"del.\\n\\n## Validate entities by implementing the Specification pattern and the Notification pattern\\n\\nF\", \"inally, a more elaborate approach to implementing validations in the domain model is by implementing\", \" the Specification pattern in conjunction with the Notification pattern, as explained in some of the\", \" additional resources listed later.\\n\\nIt is worth mentioning that you can also use just one of those \", \"patterns -for example, validating manually with control statements, but using the Notification patte\", \"rn to stack and return a list of validation errors.\\n\\n## Use deferred validation in the domain\\n\\nThere\", \" are various approaches to deal with deferred validations in the domain. In his book Implementing Do\", \"main-Driven Design, Vaughn Vernon discusses these in the section on validation.\\n\\n## Two-step validat\", \"ion\\n\\nAlso consider two-step validation. Use field-level validation on your command Data Transfer Obj\", \"ects (DTOs) and domain-level validation inside your entities. You can do this by returning a result \", \"object instead of exceptions in order to make it easier to deal with the validation errors.\\n\\nUsing f\", \"ield validation with data annotations, for example, you do not duplicate the validation definition. \", \"The execution, though, can be both server-side and client-side in the case of DTOs (commands and Vie\", \"wModels, for instance).\\n\\n## Additional resources\\n\\n- Rachel Appel. Introduction to model validation i\", \"n ASP.NET Core MVC https://learn.microsoft.com/aspnet/core/mvc/models/validation\\n- Rick Anderson. Ad\", \"ding validation\\n\\nhttps://learn.microsoft.com/aspnet/core/tutorials/first-mvc-app/validation\\n\\n- Marti\", \"n Fowler. Replacing Throwing Exceptions with Notification in Validations https://martinfowler.com/ar\", \"ticles/replaceThrowWithNotification.html\\n- Specification and Notification Patterns https://www.codep\", \"roject.com/Tips/790758/Specification-and-Notification-Patterns\\n- Lev Gorodinski. Validation in Domai\", \"n-Driven Design (DDD) http://gorodinski.com/blog/2012/05/19/validation-in-domain-driven-design-ddd/\\n\", \"- Colin Jack. Domain Model Validation https://colinjack.blogspot.com/2008/03/domain-model-validation\", \".html\\n- Jimmy Bogard. Validation in a DDD world https://lostechies.com/jimmybogard/2009/02/15/valida\", \"tion-in-a-ddd-world/\\n\\n## Client-side validation (validation in the presentation layers)\\n\\nEven when t\", \"he source of truth is the domain model and ultimately you must have validation at the domain model l\", \"evel, validation can still be handled at both the domain model level (server side) and the UI (clien\", \"t side).\\n\\nClient-side validation is a great convenience for users. It saves time they would otherwis\", \"e spend waiting for a round trip to the server that might return validation errors. In business term\", \"s, even a few fractions of seconds multiplied hundreds of times each day adds up to a lot of time, e\", \"xpense, and frustration. Straightforward and immediate validation enables users to work more efficie\", \"ntly and produce better quality input and output.\\n\\nJust as the view model and the domain model are d\", \"ifferent, view model validation and domain model validation might be similar but serve a different p\", \"urpose. If you are concerned about DRY (the Don't Repeat Yourself principle), consider that in this \", \"case code reuse might also mean coupling, and in enterprise applications it is more important not to\", \" couple the server side to the client side than to follow the DRY principle.\\n\\nEven when using client\", \"-side validation, you should always validate your commands or input DTOs in server code, because the\", \" server APIs are a possible attack vector. Usually, doing both is your best bet because if you have \", \"a client application, from a UX perspective, it is best to be proactive and not allow the user to en\", \"ter invalid information.\\n\\nTherefore, in client-side code you typically validate the ViewModels. You \", \"could also validate the client output DTOs or commands before you send them to the services.\\n\\nThe im\", \"plementation of client-side validation depends on what kind of client application you are building. \", \"It will be different if you are validating data in a web MVC web application with most of the code i\", \"n .NET, a SPA web application with that validation being coded in JavaScript or TypeScript, or a mob\", \"ile app coded with Xamarin and C#.\\n\\n## Additional resources\\n\\n## Validation in Xamarin mobile apps\\n\\n-\", \" Validate Text Input and Show Errors\\n\\nhttps://developer.xamarin.com/recipes/ios/standard\\\\_controls/t\", \"ext\\\\_field/validate\\\\_input/\\n\\n- Validation Callback https://developer.xamarin.com/samples/xamarin-for\", \"ms/XAML/ValidationCallback/\\n\\n## Validation in ASP.NET Core apps\\n\\n- Rick Anderson. Adding validation \", \"https://learn.microsoft.com/aspnet/core/tutorials/first-mvc-app/validation\\n\\n## Validation in SPA Web\", \" apps (Angular 2, TypeScript, JavaScript, Blazor WebAssembly)\\n\\n- Form Validation\\n\\nhttps://angular.io\", \"/guide/form-validation\\n\\n- Validation. Breeze documentation.\\n\\nhttps://breeze.github.io/doc-js/validat\", \"ion.html\\n\\n- ASP.NET Core Blazor forms and input components\\n\\nIn summary, these are the most important\", \" concepts in regards to validation:\\n\\n- Entities and aggregates should enforce their own consistency \", \"and be 'always valid'. Aggregate roots are responsible for multi-entity consistency within the same \", \"aggregate.\\n- If you think that an entity needs to enter an invalid state, consider using a different\", \" object model -for example, using a temporary DTO until you create the final domain entity.\\n- If you\", \" need to create several related objects, such as an aggregate, and they are only valid once all of t\", \"hem have been created, consider using the Factory pattern.\\n- In most of the cases, having redundant \", \"validation in the client side is good, because the application can be proactive.\\n\\n## Domain events: \", \"Design and implementation\\n\\nUse domain events to explicitly implement side effects of changes within \", \"your domain. In other words, and using DDD terminology, use domain events to explicitly implement si\", \"de effects across multiple aggregates. Optionally, for better scalability and less impact in databas\", \"e locks, use eventual consistency between aggregates within the same domain.\\n\\n## What is a domain ev\", \"ent?\\n\\nAn event is something that has happened in the past. A domain event is, something that happene\", \"d in the domain that you want other parts of the same domain (in-process) to be aware of. The notifi\", \"ed parts usually react somehow to the events.\\n\\nAn important benefit of domain events is that side ef\", \"fects can be expressed explicitly.\\n\\nFor example, if you're just using Entity Framework and there has\", \" to be a reaction to some event, you would probably code whatever you need close to what triggers th\", \"e event. So the rule gets coupled, implicitly, to the code, and you have to look into the code to, h\", \"opefully, realize the rule is implemented there.\\n\\nOn the other hand, using domain events makes the c\", \"oncept explicit, because there's a DomainEvent and at least one DomainEventHandler involved.\\n\\nFor ex\", \"ample, in the eShopOnContainers application, when an order is created, the user becomes a buyer, so \", \"an OrderStartedDomainEvent is raised and handled in the\\n\\nValidateOrAddBuyerAggregateWhenOrderStarted\", \"DomainEventHandler, so the underlying concept is evident.\\n\\nIn short, domain events help you to expre\", \"ss, explicitly, the domain rules, based in the ubiquitous language provided by the domain experts. D\", \"omain events also enable a better separation of concerns among classes within the same domain.\\n\\nIt's\", \" important to ensure that, just like a database transaction, either all the operations related to a \", \"domain event finish successfully or none of them do.\\n\\nDomain events are similar to messaging-style e\", \"vents, with one important difference. With real messaging, message queuing, message brokers, or a se\", \"rvice bus using AMQP, a message is always sent asynchronously and communicated across processes and \", \"machines. This is useful for integrating multiple Bounded Contexts, microservices, or even different\", \" applications. However, with domain events, you want to raise an event from the domain operation you\", \"'re currently running, but you want any side effects to occur within the same domain.\\n\\nThe domain ev\", \"ents and their side effects (the actions triggered afterwards that are managed by event handlers) sh\", \"ould occur almost immediately, usually in-process, and within the same domain. Thus, domain events c\", \"ould be synchronous or asynchronous. Integration events, however, should always be asynchronous.\\n\\n##\", \" Domain events versus integration events\\n\\nSemantically, domain and integration events are the same t\", \"hing: notifications about something that just happened. However, their implementation must be differ\", \"ent. Domain events are just messages pushed to a domain event dispatcher, which could be implemented\", \" as an in-memory mediator based on an IoC container or any other method.\\n\\nOn the other hand, the pur\", \"pose of integration events is to propagate committed transactions and updates to additional subsyste\", \"ms, whether they are other microservices, Bounded Contexts or even\\n\\nData\\n\\nBehavior\\n\\nOrder Aggregate \", \"external applications. Hence, they should occur only if the entity is successfully persisted, otherw\", \"ise it's as if the entire operation never happened. Buyer Aggregate --\\n\\nAs mentioned before, integra\", \"tion events must be based on asynchronous communication between multiple microservices (other Bounde\", \"d Contexts) or even external systems/applications. Behavior\\n\\nThus, the event bus interface needs som\", \"e infrastructure that allows inter-process and distributed communication between potentially remote \", \"services. It can be based on a commercial service bus, queues, a shared database used as a mailbox, \", \"or any other distributed and ideally push based messaging system.\\n\\n## Domain events as a preferred w\", \"ay to trigger side effects across multiple aggregates within the same domain\\n\\nIf executing a command\", \" related to one aggregate instance requires additional domain rules to be run on one or more additio\", \"nal aggregates, you should design and implement those side effects to be triggered by domain events.\", \" As shown in Figure 7-14, and as one of the most important use cases, a domain event should be used \", \"to propagate state changes across multiple aggregates within the same domain model.\\n\\nFigure 7-14. Do\", \"main events to enforce consistency between multiple aggregates within the same domain\\n\\n<!-- image --\", \">\\n\\nFigure 7-14 shows how consistency between aggregates is achieved by domain events. When the user \", \"initiates an order, the Order Aggregate sends an OrderStarted domain event. The OrderStarted domain \", \"event is handled by the Buyer Aggregate to create a Buyer object in the ordering microservice, based\", \" on the original user info from the identity microservice (with information provided in the CreateOr\", \"der command).\\n\\nAlternately, you can have the aggregate root subscribed for events raised by members \", \"of its aggregates (child entities). For instance, each OrderItem child entity can raise an event whe\", \"n the item price is higher than a specific amount, or when the product item amount is too high. The \", \"aggregate root can then receive those events and perform a global calculation or aggregation.\\n\\nDomai\", \"n Model\\n\\n(Ordering microservice)\\n\\nIt's important to understand that this event -based communication \", \"is not implemented directly within the aggregates; you need to implement domain event handlers.\\n\\nHan\", \"dling the domain events is an application concern. The domain model layer should only focus on the d\", \"omain logic -things that a domain expert would understand, not application infrastructure like handl\", \"ers and side-effect persistence actions using repositories. Therefore, the application layer level i\", \"s where you should have domain event handlers triggering actions when a domain event is raised.\\n\\nDom\", \"ain events can also be used to trigger any number of application actions, and what is more important\", \", must be open to increase that number in the future in a decoupled way. For instance, when the orde\", \"r is started, you might want to publish a domain event to propagate that info to other aggregates or\", \" even to raise application actions like notifications.\\n\\nThe key point is the open number of actions \", \"to be executed when a domain event occurs. Eventually, the actions and rules in the domain and appli\", \"cation will grow. The complexity or number of sideeffect actions when something happens will grow, b\", \"ut if your code were coupled with 'glue' (that is, creating specific objects with new), then every t\", \"ime you needed to add a new action you would also need to change working and tested code.\\n\\nThis chan\", \"ge could result in new bugs and this approach also goes against the Open/Closed principle from SOLID\", \". Not only that, the original class that was orchestrating the operations would grow and grow, which\", \" goes against the Single Responsibility Principle (SRP).\\n\\nOn the other hand, if you use domain event\", \"s, you can create a fine-grained and decoupled implementation by segregating responsibilities using \", \"this approach:\\n\\n1. Send a command (for example, CreateOrder).\\n2. Receive the command in a command ha\", \"ndler.\\n3. -Execute a single aggregate's transaction.\\n4. -(Optional) Raise domain events for side eff\", \"ects (for example, OrderStartedDomainEvent).\\n3. Handle domain events (within the current process) th\", \"at will execute an open number of side effects in multiple aggregates or application actions. For ex\", \"ample:\\n6. -Verify or create buyer and payment method.\\n7. -Create and send a related integration even\", \"t to the event bus to propagate states across microservices or trigger external actions like sending\", \" an email to the buyer.\\n8. -Handle other side effects.\\n\\nAs shown in Figure 7-15, starting from the s\", \"ame domain event, you can handle multiple actions related to other aggregates in the domain or addit\", \"ional application actions you need to perform across microservices connecting with integration event\", \"s and the event bus.\\n\\nDomain\\n\\nAggregate (Order)\\n\\nOrder (Aggregate Root)\\n\\nData\\n\\nBehavior\\n\\nApplication\", \"\\n\\nEvent Handler 1\\n\\nFigure 7-15. Handling multiple actions per domain\\n\\n<!-- image -->\\n\\nThere can be s\", \"everal handlers for the same domain event in the Application Layer, one handler can solve consistenc\", \"y between aggregates and another handler can publish an integration event, so other microservices ca\", \"n do something with it. The event handlers are typically in the application layer, because you'll us\", \"e infrastructure objects like repositories or an application API for the microservice's behavior. In\", \" that sense, event handlers are similar to command handlers, so both are part of the application lay\", \"er. The important difference is that a command should be processed only once. A domain event could b\", \"e processed zero or n times, because it can be received by multiple receivers or event handlers with\", \" a different purpose for each handler.\\n\\nHaving an open number of handlers per domain event allows yo\", \"u to add as many domain rules as needed, without affecting current code. For instance, implementing \", \"the following business rule might be as easy as adding a few event handlers (or even just one):\\n\\nWhe\", \"n the total amount purchased by a customer in the store, across any number of orders, exceeds $6,000\", \", apply a 10% off discount to every new order and notify the customer with an email about that disco\", \"unt for future orders.\\n\\n## Implement domain events\\n\\nIn C#, a domain event is simply a data-holding s\", \"tructure or class, like a DTO, with all the information related to what just happened in the domain,\", \" as shown in the following example:\\n\\n```\\npublic class OrderStartedDomainEvent : INotification { publ\", \"ic string UserId { get ; } public string UserName { get ; } public int CardTypeId { get ; } public s\", \"tring CardNumber { get ; } public string CardSecurityNumber { get ; }\\n```\\n\\n```\\npublic string CardHol\", \"derName { get ; } public DateTime CardExpiration { get ; } public Order Order { get ; } public Order\", \"StartedDomainEvent(Order order, string userId, string userName, int cardTypeId, string cardNumber, s\", \"tring cardSecurityNumber, string cardHolderName, DateTime cardExpiration) { Order = order; UserId = \", \"userId; UserName = userName; CardTypeId = cardTypeId; CardNumber = cardNumber; CardSecurityNumber = \", \"cardSecurityNumber; CardHolderName = cardHolderName; CardExpiration = cardExpiration; } }\\n```\\n\\nThis \", \"is essentially a class that holds all the data related to the OrderStarted event.\\n\\nIn terms of the u\", \"biquitous language of the domain, since an event is something that happened in the past, the class n\", \"ame of the event should be represented as a past-tense verb, like OrderStartedDomainEvent or OrderSh\", \"ippedDomainEvent. That's how the domain event is implemented in the ordering microservice in eShopOn\", \"Containers.\\n\\nAs noted earlier, an important characteristic of events is that since an event is somet\", \"hing that happened in the past, it shouldn't change. Therefore, it must be an immutable class. You c\", \"an see in the previous code that the properties are readonly. There' s no way to update the object, \", \"you can only set values when you create it.\\n\\nIt's important to highlight here that if domain events \", \"were to be handled asynchronously, using a queue that required serializing and deserializing the eve\", \"nt objects, the properties would have to be 'private set' instead of read -only, so the deserializer\", \" would be able to assign the values upon dequeuing. This is not an issue in the Ordering microservic\", \"e, as the domain event pub/sub is implemented synchronously using MediatR.\\n\\n## Raise domain events\\n\\n\", \"The next question is how to raise a domain event so it reaches its related event handlers. You can u\", \"se multiple approaches.\\n\\nUdi Dahan originally proposed (for example, in several related posts, such \", \"as Domain Events -Take 2) using a static class for managing and raising the events. This might inclu\", \"de a static class named DomainEvents that would raise domain events immediately when it's called, us\", \"ing syntax like DomainEvents.Raise(Event myEvent). Jimmy Bogard wrote a blog post (Strengthening you\", \"r domain: Domain Events) that recommends a similar approach.\\n\\nHowever, when the domain events class \", \"is static, it also dispatches to handlers immediately. This makes testing and debugging more difficu\", \"lt, because the event handlers with side-effects logic are executed immediately after the event is r\", \"aised. When you're testing and debugging, you just want to focus on what is happening in the current\", \" aggregate classes; you don't want to suddenly be\\n\\nredirected to other event handlers for side effec\", \"ts related to other aggregates or application logic. This is why other approaches have evolved, as e\", \"xplained in the next section.\\n\\n## The deferred approach to raise and dispatch events\\n\\nInstead of dis\", \"patching to a domain event handler immediately, a better approach is to add the domain events to a c\", \"ollection and then to dispatch those domain events right before or right after committing the transa\", \"ction (as with SaveChanges in EF). (This approach was described by Jimmy Bogard in this post A bette\", \"r domain events pattern.)\\n\\nDeciding if you send the domain events right before or right after commit\", \"ting the transaction is important, since it determines whether you will include the side effects as \", \"part of the same transaction or in different transactions. In the latter case, you need to deal with\", \" eventual consistency across multiple aggregates. This topic is discussed in the next section.\\n\\nThe \", \"deferred approach is what eShopOnContainers uses. First, you add the events happening in your entiti\", \"es into a collection or list of events per entity. That list should be part of the entity object, or\", \" even better, part of your base entity class, as shown in the following example of the Entity base c\", \"lass:\\n\\n```\\npublic abstract class Entity { //... private List<INotification> _domainEvents; public Li\", \"st<INotification> DomainEvents => _domainEvents; public void AddDomainEvent(INotification eventItem)\", \" { _domainEvents = _domainEvents ?? new List<INotification>(); _domainEvents.Add(eventItem); } publi\", \"c void RemoveDomainEvent(INotification eventItem) { _domainEvents?.Remove(eventItem); } //... Additi\", \"onal code }\\n```\\n\\nWhen you want to raise an event, you just add it to the event collection from code \", \"at any method of the aggregate-root entity.\\n\\nThe following code, part of the Order aggregate-root at\", \" eShopOnContainers, shows an example:\\n\\n```\\nvar orderStartedDomainEvent = new OrderStartedDomainEvent\", \"( this , //Order object cardTypeId, cardNumber, cardSecurityNumber, cardHolderName, cardExpiration);\", \" this .AddDomainEvent(orderStartedDomainEvent);\\n```\\n\\nNotice that the only thing that the AddDomainEv\", \"ent method is doing is adding an event to the list. No event is dispatched yet, and no event handler\", \" is invoked yet.\\n\\nYou actually want to dispatch the events later on, when you commit the transaction\", \" to the database. If you are using Entity Framework Core, that means in the SaveChanges method of yo\", \"ur EF DbContext, as in the following code:\\n\\n```\\n// EF Core DbContext public class OrderingContext : \", \"DbContext, IUnitOfWork { // ... public async Task<bool> SaveEntitiesAsync(CancellationToken cancella\", \"tionToken = default (CancellationToken)) { // Dispatch Domain Events collection. // Choices: // A) R\", \"ight BEFORE committing data (EF SaveChanges) into the DB. This makes // a single transaction includi\", \"ng side effects from the domain event // handlers that are using the same DbContext with Scope lifet\", \"ime // B) Right AFTER committing data (EF SaveChanges) into the DB. This makes // multiple transacti\", \"ons. You will need to handle eventual consistency and // compensatory actions in case of failures. a\", \"wait _mediator.DispatchDomainEventsAsync( this ); // After this line runs, all the changes (from the\", \" Command Handler and Domain // event handlers) performed through the DbContext will be committed var\", \" result = await base .SaveChangesAsync(); } }\\n```\\n\\nWith this code, you dispatch the entity events to\", \" their respective event handlers.\\n\\nThe overall result is that you've decoupled the raising of a doma\", \"in event (a simple add into a list in memory) from dispatching it to an event handler. In addition, \", \"depending on what kind of dispatcher you are using, you could dispatch the events synchronously or a\", \"synchronously.\\n\\nBe aware that transactional boundaries come into significant play here. If your unit\", \" of work and transaction can span more than one aggregate (as when using EF Core and a relational da\", \"tabase), this can work well. But if the transaction cannot span aggregates, you have to implement ad\", \"ditional steps to achieve consistency. This is another reason why persistence ignorance is not unive\", \"rsal; it depends on the storage system you use.\\n\\n## Single transaction across aggregates versus even\", \"tual consistency across aggregates\\n\\nThe question of whether to perform a single transaction across a\", \"ggregates versus relying on eventual consistency across those aggregates is a controversial one. Man\", \"y DDD authors like Eric Evans and Vaughn Vernon advocate the rule that one transaction = one aggrega\", \"te and therefore argue for eventual consistency across aggregates. For example, in his book Domain-D\", \"riven Design , Eric Evans says this:\\n\\nAny rule that spans Aggregates will not be expected to be up-t\", \"o-date at all times. Through event processing, batch processing, or other update mechanisms, other d\", \"ependencies can be resolved within some specific time. (page 128)\\n\\nVaughn Vernon says the following \", \"in Effective Aggregate Design. Part II: Making Aggregates Work Together:\\n\\nThus, if executing a comma\", \"nd on one aggregate instance requires that additional business rules execute on one or more aggregat\", \"es, use eventual consistency [\\u2026] There is a practical way to support eventual consistency in a DDD m\", \"odel. An aggregate method publishes a domain event that is in time delivered to one or more asynchro\", \"nous subscribers.\\n\\nThis rationale is based on embracing fine-grained transactions instead of transac\", \"tions spanning many aggregates or entities. The idea is that in the second case, the number of datab\", \"ase locks will be substantial in large-scale applications with high scalability needs. Embracing the\", \" fact that highly scalable applications need not have instant transactional consistency between mult\", \"iple aggregates helps with accepting the concept of eventual consistency. Atomic changes are often n\", \"ot needed by the business, and it is in any case the responsibility of the domain experts to say whe\", \"ther particular operations need atomic transactions or not. If an operation always needs an atomic t\", \"ransaction between multiple aggregates, you might ask whether your aggregate should be larger or was\", \"n't correctly designed.\\n\\nHowever, other developers and architects like Jimmy Bogard are okay with sp\", \"anning a single transaction across several aggregates -but only when those additional aggregates are\", \" related to side effects for the same original command. For instance, in A better domain events patt\", \"ern, Bogard says this:\\n\\nTypically, I want the side effects of a domain event to occur within the sam\", \"e logical transaction, but not necessarily in the same scope of raising the domain event [\\u2026] Just be\", \"fore we commit our transaction, we dispatch our events to their respective handlers.\\n\\nIf you dispatc\", \"h the domain events right before committing the original transaction, it is because you want the sid\", \"e effects of those events to be included in the same transaction. For example, if the EF DbContext S\", \"aveChanges method fails, the transaction will roll back all changes, including the result of any sid\", \"e effect operations implemented by the related domain event handlers. This is because the DbContext \", \"life scope is by default defined as 'scoped.' Therefore, the DbContext object is shared across multi\", \"ple repository objects being instantiated within the same scope or object graph. This coincides with\", \" the HttpRequest scope when developing Web API or MVC apps.\\n\\nActually, both approaches (single atomi\", \"c transaction and eventual consistency) can be right. It really depends on your domain or business r\", \"equirements and what the domain experts tell you. It also depends on how scalable you need the servi\", \"ce to be (more granular transactions have less impact with regard to database locks). And it depends\", \" on how much investment you're willing to make in your code, since eventual consistency requires mor\", \"e complex code in order to detect possible inconsistencies across aggregates and the need to impleme\", \"nt compensatory actions. Consider that if you commit changes to the original aggregate and afterward\", \"s, when the events are being dispatched, if there's an issue and the event handlers cannot commit th\", \"eir side effects, you'll have inconsistencies between aggregates.\\n\\nA way to allow compensatory actio\", \"ns would be to store the domain events in additional database tables so they can be part of the orig\", \"inal transaction. Afterwards, you could have a batch process that detects inconsistencies and runs c\", \"ompensatory actions by comparing the list of events with the current state of the aggregates. The co\", \"mpensatory actions are part of a complex topic that will require deep analysis from your side, which\", \" includes discussing it with the business user and domain experts.\\n\\nIn any case, you can choose the \", \"approach you need. But the initial deferred approach -raising the events before committing, so you u\", \"se a single transaction -is the simplest approach when using EF Core and a relational database. It's\", \" easier to implement and valid in many business cases. It's also the approach used in the ordering m\", \"icroservice in eShopOnContainers.\\n\\nBut how do you actually dispatch those events to their respective\", \" event handlers? What's the \\\\_mediator object you see in the previous example? It has to do with the\", \" techniques and artifacts you use to map between events and their event handlers.\\n\\n## The domain eve\", \"nt dispatcher: mapping from events to event handlers\\n\\nOnce you're able to dispatch or publish the ev\", \"ents, you need some kind of artifact that will publish the event, so that every related handler can \", \"get it and process side effects based on that event.\\n\\nOne approach is a real messaging system or eve\", \"n an event bus, possibly based on a service bus as opposed to in-memory events. However, for the fir\", \"st case, real messaging would be overkill for processing domain events, since you just need to proce\", \"ss those events within the same process (that is, within the same domain and application layer).\\n\\n##\", \" How to subscribe to domain events\\n\\nWhen you use MediatR, each event handler must use an event type \", \"that is provided on the generic parameter of the INotificationHandler interface, as you can see in t\", \"he following code:\\n\\n```\\npublic class ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler :\", \" INotificationHandler<OrderStartedDomainEvent>\\n```\\n\\nBased on the relationship between event and even\", \"t handler, which can be considered the subscription, the MediatR artifact can discover all the event\", \" handlers for each event and trigger each one of those event handlers.\\n\\n## How to handle domain even\", \"ts\\n\\nFinally, the event handler usually implements application layer code that uses infrastructure re\", \"positories to obtain the required additional aggregates and to execute side-effect domain logic. The\", \" following domain event handler code at eShopOnContainers, shows an implementation example.\\n\\n```\\npub\", \"lic class ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler : INotificationHandler<Order\", \"StartedDomainEvent> { private readonly ILogger _logger; private readonly IBuyerRepository _buyerRepo\", \"sitory; private readonly IOrderingIntegrationEventService _orderingIntegrationEventService; public V\", \"alidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler( ILogger<ValidateOrAddBuyerAggregateWhe\", \"nOrderStartedDomainEventHandler> logger, IBuyerRepository buyerRepository, IOrderingIntegrationEvent\", \"Service orderingIntegrationEventService) { _buyerRepository = buyerRepository ?? throw new ArgumentN\", \"ullException(nameof(buyerRepository)); _orderingIntegrationEventService = orderingIntegrationEventSe\", \"rvice ?? throw new ArgumentNullException(nameof(orderingIntegrationEventService));\\n```\\n\\n```\\n_logger \", \"= logger ?? throw new ArgumentNullException(nameof(logger)); } public async Task Handle( OrderStarte\", \"dDomainEvent domainEvent, CancellationToken cancellationToken) { var cardTypeId = domainEvent.CardTy\", \"peId != 0 ? domainEvent.CardTypeId : 1; var buyer = await _buyerRepository.FindAsync(domainEvent.Use\", \"rId); var buyerExisted = buyer is not null ; if (!buyerExisted) { buyer = new Buyer(domainEvent.User\", \"Id, domainEvent.UserName); } buyer.VerifyOrAddPaymentMethod( cardTypeId, $\\\"Payment Method on {DateTi\", \"me.UtcNow}\\\", domainEvent.CardNumber, domainEvent.CardSecurityNumber, domainEvent.CardHolderName, dom\", \"ainEvent.CardExpiration, domainEvent.Order.Id); var buyerUpdated = buyerExisted ? _buyerRepository.U\", \"pdate(buyer) : _buyerRepository.Add(buyer); await _buyerRepository.UnitOfWork .SaveEntitiesAsync(can\", \"cellationToken); var integrationEvent = new OrderStatusChangedToSubmittedIntegrationEvent( domainEve\", \"nt.Order.Id, domainEvent.Order.OrderStatus.Name, buyer.Name); await _orderingIntegrationEventService\", \".AddAndSaveEventAsync(integrationEvent); OrderingApiTrace.LogOrderBuyerAndPaymentValidatedOrUpdated(\", \" _logger, buyerUpdated.Id, domainEvent.Order.Id); } }\\n```\\n\\nThe previous domain event handler code is\", \" considered application layer code because it uses infrastructure repositories, as explained in the \", \"next section on the infrastructure-persistence layer. Event handlers could also use other infrastruc\", \"ture components.\\n\\n## Domain events can generate integration events to be published outside of the mi\", \"croservice boundaries\\n\\nFinally, it's important to mention that you might sometimes want to propagate\", \" events across multiple microservices. That propagation is an integration event, and it could be pub\", \"lished through an event bus from any specific domain event handler.\\n\\n## Conclusions on domain events\", \"\\n\\nAs stated, use domain events to explicitly implement side effects of changes within your domain. T\", \"o use DDD terminology, use domain events to explicitly implement side effects across one or multiple\", \" aggregates. Additionally, and for better scalability and less impact on database locks, use eventua\", \"l consistency between aggregates within the same domain.\\n\\nThe reference app uses MediatR to propagat\", \"e domain events synchronously across aggregates, within a single transaction. However, you could als\", \"o use some AMQP implementation like RabbitMQ or Azure Service Bus to propagate domain events asynchr\", \"onously, using eventual consistency but, as mentioned above, you have to consider the need for compe\", \"nsatory actions in case of failures.\\n\\n## Additional resources\\n\\n- Greg Young. What is a Domain Event?\", \" https://cqrs.files.wordpress.com/2010/11/cqrs\\\\_documents.pdf#page=25\\n- Jan Stenberg. Domain Events \", \"and Eventual Consistency https://www.infoq.com/news/2015/09/domain-events-consistency\\n- Jimmy Bogard\", \". A better domain events pattern https://lostechies.com/jimmybogard/2014/05/13/a-better-domain-event\", \"s-pattern/\\n- Vaughn Vernon. Effective Aggregate Design Part II: Making Aggregates Work Together http\", \"s://dddcommunity.org/wp-content/uploads/files/pdf\\\\_articles/Vernon\\\\_2011\\\\_2.pdf\\n- Jimmy Bogard. Stre\", \"ngthening your domain: Domain Events https://lostechies.com/jimmybogard/2010/04/08/strengthening-you\", \"r-domain-domainevents/\\n- Udi Dahan. How to create fully encapsulated Domain Models https://udidahan.\", \"com/2008/02/29/how-to-create-fully-encapsulated-domain-models/\\n- Udi Dahan. Domain Events -Take 2 ht\", \"tps://udidahan.com/2008/08/25/domain-events-take-2/\\n- Udi Dahan. Domain Events -Salvation https://ud\", \"idahan.com/2009/06/14/domain-events-salvation/\\n- Cesar de la Torre. Domain Events vs. Integration Ev\", \"ents in DDD and microservices architectures\\n\\nhttps://devblogs.microsoft.com/cesardelatorre/domain-ev\", \"ents-vs-integration-events-indomain-driven-design-and-microservices-architectures/\\n\\n## Design the in\", \"frastructure persistence layer\\n\\nData persistence components provide access to the data hosted within\", \" the boundaries of a microservice (that is, a microservice's database). They contain the actual impl\", \"ementation of components such as repositories and Unit of Work classes, like custom Entity Framework\", \" (EF) DbContext objects. EF DbContext implements both the Repository and the Unit of Work patterns.\\n\", \"\\n## The Repository pattern\\n\\nThe Repository pattern is a Domain-Driven Design pattern intended to kee\", \"p persistence concerns outside of the system's domain model. One or more persistence abstractions - \", \"interfaces - are defined\\n\\nin the domain model, and these abstractions have implementations in the fo\", \"rm of persistence-specific adapters defined elsewhere in the application.\\n\\nRepository implementation\", \"s are classes that encapsulate the logic required to access data sources. They centralize common dat\", \"a access functionality, providing better maintainability and decoupling the infrastructure or techno\", \"logy used to access databases from the domain model. If you use an Object-Relational Mapper (ORM) li\", \"ke Entity Framework, the code that must be implemented is simplified, thanks to LINQ and strong typi\", \"ng. This lets you focus on the data persistence logic rather than on data access plumbing.\\n\\nThe Repo\", \"sitory pattern is a well-documented way of working with a data source. In the book Patterns of Enter\", \"prise Application Architecture, Martin Fowler describes a repository as follows:\\n\\nA repository perfo\", \"rms the tasks of an intermediary between the domain model layers and data mapping, acting in a simil\", \"ar way to a set of domain objects in memory. Client objects declaratively build queries and send the\", \"m to the repositories for answers. Conceptually, a repository encapsulates a set of objects stored i\", \"n the database and operations that can be performed on them, providing a way that is closer to the p\", \"ersistence layer. Repositories, also, support the purpose of separating, clearly and in one directio\", \"n, the dependency between the work domain and the data allocation or mapping.\\n\\n## Define one reposit\", \"ory per aggregate\\n\\nFor each aggregate or aggregate root, you should create one repository class. You\", \" may be able to leverage C# Generics to reduce the total number concrete classes you need to maintai\", \"n (as demonstrated later in this chapter). In a microservice based on Domain-Driven Design (DDD) pat\", \"terns, the only channel you should use to update the database should be the repositories. This is be\", \"cause they have a one-toone relationship with the aggregate root, which controls the aggregate's inv\", \"ariants and transactional consistency. It's okay to query the database through other channels (as yo\", \"u can do following a CQRS approach), because queries don't change the state of the database. However\", \", the transactional area (that is, the updates) must always be controlled by the repositories and th\", \"e aggregate roots.\\n\\nBasically, a repository allows you to populate data in memory that comes from th\", \"e database in the form of the domain entities. Once the entities are in memory, they can be changed \", \"and then persisted back to the database through transactions.\\n\\nAs noted earlier, if you're using the\", \" CQS/CQRS architectural pattern, the initial queries are performed by side queries out of the domain\", \" model, performed by simple SQL statements using Dapper. This approach is much more flexible than re\", \"positories because you can query and join any tables you need, and these queries aren't restricted b\", \"y rules from the aggregates. That data goes to the presentation layer or client app.\\n\\nIf the user ma\", \"kes changes, the data to be updated comes from the client app or presentation layer to the applicati\", \"on layer (such as a Web API service). When you receive a command in a command handler, you use repos\", \"itories to get the data you want to update from the database. You update it in memory with the data \", \"passed with the commands, and you then add or update the data (domain entities) in the database thro\", \"ugh a transaction.\\n\\nLayer\\n\\nBuyer Aggregate\\n\\nBuyer (Aggregate Root)\\n\\nData\\n\\nOrder (Aggregate Root)\\n\\nDa\", \"ta\\n\\nIt's important to emphasize again that you should only define one repository for each aggregate \", \"root, as shown in Figure 7-17. To achieve the goal of the aggregate root to maintain transactional c\", \"onsistency between all the objects within the aggregate, you should never create a repository for ea\", \"ch table in the database.\\n\\nInfrastructure-\\n\\nPersistence\\n\\nLayer\\n\\nData\\n\\nTier\\n\\nFigure 7-17. The relatio\", \"nship between repositories, aggregates, and database tables\\n\\n<!-- image -->\\n\\nThe above diagram shows\", \" the relationships between Domain and Infrastructure layers: Buyer Aggregate depends on the IBuyerRe\", \"pository and Order Aggregate depends on the IOrderRepository interfaces, these interfaces are implem\", \"ented in the Infrastructure layer by the corresponding repositories that depend on UnitOfWork, also \", \"implemented there, that accesses the tables in the Data tier.\\n\\n## Enforce one aggregate root per rep\", \"ository\\n\\nIt can be valuable to implement your repository design in such a way that it enforces the r\", \"ule that only aggregate roots should have repositories. You can create a generic or base repository \", \"type that constrains the type of entities it works with to ensure they have the IAggregateRoot marke\", \"r interface.\\n\\nThus, each repository class implemented at the infrastructure layer implements its own\", \" contract or interface, as shown in the following code:\\n\\n```\\nnamespace Microsoft.eShopOnContainers.S\", \"ervices.Ordering.Infrastructure.Repositories { public class OrderRepository : IOrderRepository { // \", \"...\\n```\\n\\nOrder Aggregate\\n\\nAddress (Value-Object)\\n\\nData\\n\\nBehavior\\n\\n```\\n} }\\n```\\n\\nEach specific reposit\", \"ory interface implements the generic IRepository interface:\\n\\n```\\npublic interface IOrderRepository :\", \" IRepository<Order> { Order Add(Order order); // ... }\\n```\\n\\nHowever, a better way to have the code e\", \"nforce the convention that each repository is related to a single aggregate is to implement a generi\", \"c repository type. That way, it's explicit that you're using a repository to target a specific aggre\", \"gate. That can be easily done by implementing a generic IRepository base interface, as in the follow\", \"ing code:\\n\\n```\\npublic interface IRepository<T> where T : IAggregateRoot { //.... }\\n```\\n\\n## The Repos\", \"itory pattern makes it easier to test your application logic\\n\\nThe Repository pattern allows you to e\", \"asily test your application with unit tests. Remember that unit tests only test your code, not infra\", \"structure, so the repository abstractions make it easier to achieve that goal.\\n\\nAs noted in an earli\", \"er section, it's recommended that you define and place the repository interfaces in the domain model\", \" layer so the application layer, such as your Web API microservice, doesn't depend directly on the i\", \"nfrastructure layer where you've imp lemented the actual repository classes. By doing this and using\", \" Dependency Injection in the controllers of your Web API, you can implement mock repositories that r\", \"eturn fake data instead of data from the database. This decoupled approach allows you to create and \", \"run unit tests that focus the logic of your application without requiring connectivity to the databa\", \"se.\\n\\nConnections to databases can fail and, more importantly, running hundreds of tests against a da\", \"tabase is bad for two reasons. First, it can take a long time because of the large number of tests. \", \"Second, the database records might change and impact the results of your tests, especially if your t\", \"ests are running in parallel, so that they might not be consistent. Unit tests typically can run in \", \"parallel; integration tests may not support parallel execution depending on their implementation. Te\", \"sting against the database isn't a unit test but an integration test. You should have many unit test\", \"s running fast, but fewer integration tests against the databases.\\n\\nIn terms of separation of concer\", \"ns for unit tests, your logic operates on domain entities in memory. It assumes the repository class\", \" has delivered those. Once your logic modifies the domain entities, it assumes the repository class \", \"will store them correctly. The important point here is to create unit tests against your domain mode\", \"l and its domain logic. Aggregate roots are the main consistency boundaries in DDD.\\n\\nThe repositorie\", \"s implemented in eShopOnContainers rely on EF Core's DbContext implementation of the Repository and \", \"Unit of Work patterns using its change tracker, so they don't duplicate this functionality.\\n\\n## The \", \"difference between the Repository pattern and the legacy Data Access class (DAL class) pattern\\n\\nA ty\", \"pical DAL object directly performs data access and persistence operations against storage, often at \", \"the level of a single table and row. Simple CRUD operations implemented with a set of DAL classes fr\", \"equently do not support transactions (though this is not always the case). Most DAL class approaches\", \" make minimal use of abstractions, resulting in tight coupling between application or Business Logic\", \" Layer (BLL) classes that call the DAL objects.\\n\\nWhen using repository, the implementation details o\", \"f persistence are encapsulated away from the domain model. The use of an abstraction provides ease o\", \"f extending behavior through patterns like Decorators or Proxies. For instance, cross-cutting concer\", \"ns like caching, logging, and error handling can all be applied using these patterns rather than har\", \"dcoded in the data access code itself. It's also trivial to support multiple repository adapters whi\", \"ch may be used in different environments, from local development to shared staging environments to p\", \"roduction.\\n\\n## Implementing Unit of Work\\n\\nA unit of work refers to a single transaction that involve\", \"s multiple insert, update, or delete operations. In simple terms, it means that for a specific user \", \"action, such as a registration on a website, all the insert, update, and delete operations are handl\", \"ed in a single transaction. This is more efficient than handling multiple database operations in a c\", \"hattier way.\\n\\nThese multiple persistence operations are performed later in a single action when your\", \" code from the application layer commands it. The decision about applying the in-memory changes to t\", \"he actual database storage is typically based on the Unit of Work pattern. In EF, the Unit of Work p\", \"attern is implemented by a DbContext and is executed when a call is made to SaveChanges.\\n\\nIn many ca\", \"ses, this pattern or way of applying operations against the storage can increase application perform\", \"ance and reduce the possibility of inconsistencies. It also reduces transaction blocking in the data\", \"base tables, because all the intended operations are committed as part of one transaction. This is m\", \"ore efficient in comparison to executing many isolated operations against the database. Therefore, t\", \"he selected ORM can optimize the execution against the database by grouping several update actions w\", \"ithin the same transaction, as opposed to many small and separate transaction executions.\\n\\nThe Unit \", \"of Work pattern can be implemented with or without using the Repository pattern.\\n\\n## Repositories sh\", \"ouldn't be mandatory\\n\\nCustom repositories are useful for the reasons cited earlier, and that is the \", \"approach for the ordering microservice in eShopOnContainers. However, it isn't an essential pattern \", \"to implement in a DDD design or even in general .NET development.\\n\\nFor instance, Jimmy Bogard, when \", \"providing direct feedback for this guide, said the following:\\n\\nThis'll probably be my biggest feedba\", \"ck. I'm really not a fan of repositories, mainly because they hide the important details of the unde\", \"rlying persistence mechanism. It's why I go for MediatR for commands, too. I can use the full power \", \"of the persistence layer, and push all that domain behavior into my aggregate roots. I don't usually\", \" want to mock my repositories I still need to have that\\n\\nintegration test with the real thing. Going\", \" CQRS meant that we didn't really have a need for repositories any more.\\n\\nRepositories might be usef\", \"ul, but they are not critical for your DDD design in the way that the Aggregate pattern and a rich d\", \"omain model are. Therefore, use the Repository pattern or not, as you see fit.\\n\\n## Additional resour\", \"ces\\n\\n## Repository pattern\\n\\n- Edward Hieatt and Rob Mee. Repository pattern.\\n\\nhttps://martinfowler.c\", \"om/eaaCatalog/repository.html\\n\\n- The Repository pattern\\n\\nhttps://learn.microsoft.com/previous-versio\", \"ns/msp-n-p/ff649690(v=pandp.10)\\n\\n- Eric Evans. Domain-Driven Design: Tackling Complexity in the Hear\", \"t of Software. (Book; includes a discussion of the Repository pattern) https://www.amazon.com/Domain\", \"-Driven-Design-Tackling-ComplexitySoftware/dp/0321125215/\\n\\n## Unit of Work pattern\\n\\n- Martin Fowler.\", \" Unit of Work pattern.\\n\\nhttps://martinfowler.com/eaaCatalog/unitOfWork.html\\n\\n- Implementing the Repo\", \"sitory and Unit of Work Patterns in an ASP.NET MVC\\n- Application\\n\\nhttps://learn.microsoft.com/aspnet\", \"/mvc/overview/older-versions/getting-started-with-ef-5using-mvc-4/implementing-the-repository-and-un\", \"it-of-work-patterns-in-an-asp-net-mvcapplication\\n\\n## Implement the infrastructure persistence layer \", \"with Entity Framework Core\\n\\nWhen you use relational databases such as SQL Server, Oracle, or Postgre\", \"SQL, a recommended approach is to implement the persistence layer based on Entity Framework (EF). EF\", \" supports LINQ and provides strongly typed objects for your model, as well as simplified persistence\", \" into your database.\\n\\nEntity Framework has a long history as part of the .NET Framework. When you us\", \"e .NET, you should also use Entity Framework Core, which runs on Windows or Linux in the same way as\", \" .NET. EF Core is a complete rewrite of Entity Framework that's implemented wi th a much smaller foo\", \"tprint and important improvements in performance.\\n\\n## Introduction to Entity Framework Core\\n\\nEntity \", \"Framework (EF) Core is a lightweight, extensible, and cross-platform version of the popular Entity F\", \"ramework data access technology. It was introduced with .NET Core in mid-2016.\\n\\nSince an introductio\", \"n to EF Core is already available in Microsoft documentation, here we simply provide links to that i\", \"nformation.\\n\\n## Additional resources\\n\\n- Entity Framework Core https://learn.microsoft.com/ef/core/\\n-\", \" Getting started with ASP.NET Core and Entity Framework Core using Visual Studio https://learn.micro\", \"soft.com/aspnet/core/data/ef-mvc/\\n- DbContext Class https://learn.microsoft.com/dotnet/api/microsoft\", \".entityframeworkcore.dbcontext\\n- Compare EF Core &amp; EF6.x https://learn.microsoft.com/ef/efcore-a\", \"nd-ef6/index\\n\\n## Infrastructure in Entity Framework Core from a DDD perspective\\n\\nFrom a DDD point of\", \" view, an important capability of EF is the ability to use POCO domain entities, also known in EF te\", \"rminology as POCO code-first entities . If you use POCO domain entities, your domain model classes a\", \"re persistence-ignorant, following the Persistence Ignorance and the Infrastructure Ignorance princi\", \"ples.\\n\\nPer DDD patterns, you should encapsulate domain behavior and rules within the entity class it\", \"self, so it can control invariants, validations, and rules when accessing any collection. Therefore,\", \" it is not a good practice in DDD to allow public access to collections of child entities or value o\", \"bjects. Instead, you want to expose methods that control how and when your fields and property colle\", \"ctions can be updated, and what behavior and actions should occur when that happens.\\n\\nSince EF Core \", \"1.1, to satisfy those DDD requirements, you can have plain fields in your entities instead of public\", \" properties. If you do not want an entity field to be externally accessible, you can just create the\", \" attribute or field instead of a property. You can also use private property setters.\\n\\nIn a similar \", \"way, you can now have read-only access to collections by using a public property typed as IReadOnlyC\", \"ollection&lt;T&gt;, which is backed by a private field member for the collection (like a List&lt;T&g\", \"t;) in your entity that relies on EF for persistence. Previous versions of Entity Framework required\", \" collection properties to support ICollection&lt;T&gt;, which meant that any developer using the par\", \"ent entity class could add or remove items through its property collections. That possibility would \", \"be against the recommended patterns in DDD.\\n\\nYou can use a private collection while exposing a read-\", \"only IReadOnlyCollection&lt;T&gt; object, as shown in the following code example:\\n\\n```\\npublic class \", \"Order : Entity {\\n```\\n\\n```\\n// Using private fields, allowed since EF Core 1.1 private DateTime _order\", \"Date; // Other fields ... private readonly List<OrderItem> _orderItems; public IReadOnlyCollection<O\", \"rderItem> OrderItems => _orderItems; protected Order() { } public Order(int buyerId, int paymentMeth\", \"odId, Address address) { // Initializations ... } public void AddOrderItem(int productId, string pro\", \"ductName, decimal unitPrice, decimal discount, string pictureUrl, int units = 1) { // Validation log\", \"ic... var orderItem = new OrderItem(productId, productName, unitPrice, discount, pictureUrl, units);\", \" _orderItems.Add(orderItem); } }\\n```\\n\\nThe OrderItems property can only be accessed as read-only usin\", \"g IReadOnlyCollection&lt;OrderItem&gt;. This type is read-only so it is protected against regular ex\", \"ternal updates.\\n\\nEF Core provides a way to map the domain model to the physical database without 'co\", \"ntaminating' the domain model. It is pure .NET POCO code, because the mapping action is implemented \", \"in the persistence layer. In that mapping action, you need to configure the fields-to-database mappi\", \"ng. In the following example of the OnModelCreating method from OrderingContext and the OrderEntityT\", \"ypeConfiguration class, the call to SetPropertyAccessMode tells EF Core to access the OrderItems pro\", \"perty through its field.\\n\\n```\\n// At OrderingContext.cs from eShopOnContainers protected override voi\", \"d OnModelCreating(ModelBuilder modelBuilder) { // ... modelBuilder.ApplyConfiguration( new OrderEnti\", \"tyTypeConfiguration()); // Other entities' configuration ... } // At OrderEntityTypeConfiguration.cs\", \" from eShopOnContainers class OrderEntityTypeConfiguration : IEntityTypeConfiguration<Order> { publi\", \"c void Configure(EntityTypeBuilder<Order> orderConfiguration) { orderConfiguration.ToTable(\\\"orders\\\",\", \" OrderingContext.DEFAULT_SCHEMA); // Other configuration var navigation = orderConfiguration.Metadat\", \"a.FindNavigation(nameof(Order.OrderItems)); //EF access the OrderItem collection property through it\", \"s backing field navigation.SetPropertyAccessMode(PropertyAccessMode.Field);\\n```\\n\\n```\\n// Other config\", \"uration } }\\n```\\n\\nWhen you use fields instead of properties, the OrderItem entity is persisted as if \", \"it had a List&lt;OrderItem&gt; property. However, it exposes a single accessor, the AddOrderItem met\", \"hod, for adding new items to the order. As a result, behavior and data are tied together and will be\", \" consistent throughout any application code that uses the domain model.\\n\\n## Implement custom reposit\", \"ories with Entity Framework Core\\n\\nAt the implementation level, a repository is simply a class with d\", \"ata persistence code coordinated by a unit of work (DBContext in EF Core) when performing updates, a\", \"s shown in the following class:\\n\\n```\\n// using directives... namespace Microsoft.eShopOnContainers.Se\", \"rvices.Ordering.Infrastructure.Repositories { public class BuyerRepository : IBuyerRepository { priv\", \"ate readonly OrderingContext _context; public IUnitOfWork UnitOfWork { get { return _context; } } pu\", \"blic BuyerRepository(OrderingContext context) { _context = context ?? throw new ArgumentNullExceptio\", \"n(nameof(context)); } public Buyer Add(Buyer buyer) { return _context.Buyers.Add(buyer).Entity; } pu\", \"blic async Task<Buyer> FindAsync(string buyerIdentityGuid) { var buyer = await _context.Buyers .Incl\", \"ude(b => b.Payments) .Where(b => b.FullName == buyerIdentityGuid) .SingleOrDefaultAsync(); return bu\", \"yer; } } }\\n```\\n\\nThe IBuyerRepository interface comes from the domain model layer as a contract. Howe\", \"ver, the repository implementation is done at the persistence and infrastructure layer.\\n\\nThe EF DbCo\", \"ntext comes through the constructor through Dependency Injection. It is shared between multiple repo\", \"sitories within the same HTTP request scope, thanks to its default lifetime (ServiceLifetime.Scoped)\", \" in the IoC container (which can also be explicitly set with services.AddDbContext&lt;&gt;).\\n\\n## Met\", \"hods to implement in a repository (updates or transactions versus queries)\\n\\nWithin each repository c\", \"lass, you should put the persistence methods that update the state of entities contained by its rela\", \"ted aggregate. Remember there is one-to-one relationship between an aggregate and its related reposi\", \"tory. Consider that an aggregate root entity object might have embedded child entities within its EF\", \" graph. For example, a buyer might have multiple payment methods as related child entities.\\n\\nSince t\", \"he approach for the ordering microservice in eShopOnContainers is also based on CQS/CQRS, most of th\", \"e queries are not implemented in custom repositories. Developers have the freedom to create the quer\", \"ies and joins they need for the presentation layer without the restrictions imposed by aggregates, c\", \"ustom repositories per aggregate, and DDD in general. Most of the custom repositories suggested by t\", \"his guide have several update or transactional methods but just the query methods needed to get data\", \" to be updated. For example, the BuyerRepository repository implements a FindAsync method, because t\", \"he application needs to know whether a particular buyer exists before creating a new buyer related t\", \"o the order.\\n\\nHowever, the real query methods to get data to send to the presentation layer or clien\", \"t apps are implemented, as mentioned, in the CQRS queries based on flexible queries using Dapper.\\n\\n#\", \"# Using a custom repository versus using EF DbContext directly\\n\\nThe Entity Framework DbContext class\", \" is based on the Unit of Work and Repository patterns and can be used directly from your code, such \", \"as from an ASP.NET Core MVC controller. The Unit of Work and Repository patterns result in the simpl\", \"est code, as in the CRUD catalog microservice in eShopOnContainers. In cases where you want the simp\", \"lest code possible, you might want to directly use the DbContext class, as many developers do.\\n\\nHowe\", \"ver, implementing custom repositories provides several benefits when implementing more complex micro\", \"services or applications. The Unit of Work and Repository patterns are intended to encapsulate the i\", \"nfrastructure persistence layer so it is decoupled from the application and domainmodel layers. Impl\", \"ementing these patterns can facilitate the use of mock repositories simulating access to the databas\", \"e.\\n\\nIn Figure 7-18, you can see the differences between not using repositories (directly using the E\", \"F DbContext) versus using repositories, which makes it easier to mock those repositories.\\n\\nNo Reposi\", \"tory\\n\\nDirect access to database from controller\\n\\nWeb Server\\n\\n(Kestrel, IIS, etc.)\\n\\nController or\\n\\nAp\", \"plication Layer\\n\\nDbContext\\n\\nEntity Framework\\n\\nDatabase\\n\\nAbstraction layer between controller and dat\", \"abase context.\\n\\nWith Repository\\n\\nUnit tests can mock data to facilitate testing\\n\\nWeb Server\\n\\n(Kestre\", \"l, IIS, etc.)\\n\\nWeb Server\\n\\n(Kestrel, IIS, etc.)\\n\\nFigure 7-18. Using custom repositories versus a pla\", \"in DbContext\\n\\n<!-- image -->\\n\\nFigure 7-18 shows that using a custom repository adds an abstraction l\", \"ayer that can be used to ease testing by mocking the repository. There are multiple alternatives whe\", \"n mocking. You could mock just repositories or you could mock a whole unit of work. Usually mocking \", \"just the repositories is enough, and the complexity to abstract and mock a whole unit of work is usu\", \"ally not needed.\\n\\nLater, when we focus on the application layer, you will see how Dependency Injecti\", \"on works in ASP.NET Core and how it is implemented when using repositories.\\n\\nIn short, custom reposi\", \"tories allow you to test code more easily with unit tests that are not impacted by the data tier sta\", \"te. If you run tests that also access the actual database through the Entity Framework, they are not\", \" unit tests but integration tests, which are a lot slower.\\n\\nIf you were using DbContext directly, yo\", \"u would have to mock it or to run unit tests by using an inmemory SQL Server with predictable data f\", \"or unit tests. But mocking the DbContext or controlling fake data requires more work than mocking at\", \" the repository level. Of course, you could always test the MVC controllers.\\n\\n## EF DbContext and IU\", \"nitOfWork instance lifetime in your IoC container\\n\\nThe DbContext object (exposed as an IUnitOfWork o\", \"bject) should be shared among multiple repositories within the same HTTP request scope. For example,\", \" this is true when the operation being executed must deal with multiple aggregates, or simply becaus\", \"e you are using multiple repository instances. It is also important to mention that the IUnitOfWork \", \"interface is part of your domain layer, not an EF Core type.\\n\\nIn order to do that, the instance of t\", \"he DbContext object has to have its service lifetime set to ServiceLifetime.Scoped. This is the defa\", \"ult lifetime when registering a DbContext with builder.Services.AddDbContext in your IoC container f\", \"rom the Program.cs file in your ASP.NET Core Web API project. The following code illustrates this.\\n\\n\", \"```\\n// Add framework services. builder.Services.AddMvc(options => { options.Filters.Add( typeof (Htt\", \"pGlobalExceptionFilter)); }).AddControllersAsServices(); builder.Services.AddEntityFrameworkSqlServe\", \"r() .AddDbContext<OrderingContext>(options => { options.UseSqlServer(Configuration[\\\"ConnectionString\", \"\\\"], sqlOptions => sqlOptions.MigrationsAssembly( typeof (Startup).GetTypeInfo(). Assembly.GetName().\", \"Name)); }, ServiceLifetime.Scoped // Note that Scoped is the default choice // in AddDbContext. It i\", \"s shown here only for // pedagogic purposes. );\\n```\\n\\nThe DbContext instantiation mode should not be \", \"configured as ServiceLifetime.Transient or ServiceLifetime.Singleton.\\n\\n## The repository instance li\", \"fetime in your IoC container\\n\\nIn a similar way, repository's lifetime should usually be set as scope\", \"d (InstancePerLifetimeScope in Autofac). It could also be transient (InstancePerDependency in Autofa\", \"c), but your service will be more efficient in regards to memory when using the scoped lifetime.\\n\\n``\", \"`\\n// Registering a Repository in Autofac IoC container builder.RegisterType<OrderRepository>() .As<I\", \"OrderRepository>() .InstancePerLifetimeScope();\\n```\\n\\nUsing the singleton lifetime for the repository\", \" could cause you serious concurrency problems when your DbContext is set to scoped (InstancePerLifet\", \"imeScope) lifetime (the default lifetimes for a DBContext). As long as your service lifetimes for yo\", \"ur repositories and your DbContext are both Scoped, you'll avoid these issues.\\n\\n## Additional resour\", \"ces\\n\\n- Implementing the Repository and Unit of Work Patterns in an ASP.NET MVC Application\\n\\nhttps://\", \"www.asp.net/mvc/overview/older-versions/getting-started-with-ef-5-using-mvc4/implementing-the-reposi\", \"tory-and-unit-of-work-patterns-in-an-asp-net-mvc-application\\n\\n- Jonathan Allen. Implementation Strat\", \"egies for the Repository Pattern with Entity Framework, Dapper, and Chain https://www.infoq.com/arti\", \"cles/repository-implementation-strategies\\n- Cesar de la Torre. Comparing ASP.NET Core IoC container \", \"service lifetimes with Autofac IoC container instance scopes\\n\\nhttps://devblogs.microsoft.com/cesarde\", \"latorre/comparing-asp-net-core-ioc-service-lifetimes-and-autofac-ioc-instance-scopes/\\n\\n## Table mapp\", \"ing\\n\\nTable mapping identifies the table data to be queried from and saved to the database. Previousl\", \"y you saw how domain entities (for example, a product or order domain) can be used to generate a rel\", \"ated database schema. EF is strongly designed around the concept of conventions . Conventions addres\", \"s questions like 'What will the name of a table be?' or 'What property is the primary key?' Conventi\", \"ons are typically based on conventional names. For example, it is typical for the primary key to be \", \"a property that ends with Id.\\n\\nBy convention, each entity will be set up to map to a table with the \", \"same name as the DbSet&lt;TEntity&gt; property that exposes the entity on the derived context. If no\", \" DbSet&lt;TEntity&gt; value is provided for the given entity, the class name is used.\\n\\n## Data Annot\", \"ations versus Fluent API\\n\\nThere are many additional EF Core conventions, and most of them can be cha\", \"nged by using either data annotations or Fluent API, implemented within the OnModelCreating method.\\n\", \"\\nData annotations must be used on the entity model classes themselves, which is a more intrusive way\", \" from a DDD point of view. This is because you are contaminating your model with data annotations re\", \"lated to the infrastructure database. On the other hand, Fluent API is a convenient way to change mo\", \"st conventions and mappings within your data persistence infrastructure layer, so the entity model w\", \"ill be clean and decoupled from the persistence infrastructure.\\n\\n## Fluent API and the OnModelCreati\", \"ng method\\n\\nAs mentioned, in order to change conventions and mappings, you can use the OnModelCreatin\", \"g method in the DbContext class.\\n\\nThe ordering microservice in eShopOnContainers implements explicit\", \" mapping and configuration, when needed, as shown in the following code.\\n\\n```\\n// At OrderingContext.\", \"cs from eShopOnContainers protected override void OnModelCreating(ModelBuilder modelBuilder) { // ..\", \". modelBuilder.ApplyConfiguration( new OrderEntityTypeConfiguration()); // Other entities' configura\", \"tion ... } // At OrderEntityTypeConfiguration.cs from eShopOnContainers class OrderEntityTypeConfigu\", \"ration : IEntityTypeConfiguration<Order> { public void Configure(EntityTypeBuilder<Order> orderConfi\", \"guration) { orderConfiguration.ToTable(\\\"orders\\\", OrderingContext.DEFAULT_SCHEMA); orderConfiguration\", \".HasKey(o => o.Id); orderConfiguration.Ignore(b => b.DomainEvents); orderConfiguration.Property(o =>\", \" o.Id) .UseHiLo(\\\"orderseq\\\", OrderingContext.DEFAULT_SCHEMA);\\n```\\n\\n```\\n//Address value object persist\", \"ed as owned entity type supported since EF Core 2.0 orderConfiguration .OwnsOne(o => o.Address, a =>\", \" { a.WithOwner(); }); orderConfiguration .Property<int?>(\\\"_buyerId\\\") .UsePropertyAccessMode(Property\", \"AccessMode.Field) .HasColumnName(\\\"BuyerId\\\") .IsRequired( false ); orderConfiguration .Property<DateT\", \"ime>(\\\"_orderDate\\\") .UsePropertyAccessMode(PropertyAccessMode.Field) .HasColumnName(\\\"OrderDate\\\") .IsR\", \"equired(); orderConfiguration .Property<int>(\\\"_orderStatusId\\\") .UsePropertyAccessMode(PropertyAccess\", \"Mode.Field) .HasColumnName(\\\"OrderStatusId\\\") .IsRequired(); orderConfiguration .Property<int?>(\\\"_paym\", \"entMethodId\\\") .UsePropertyAccessMode(PropertyAccessMode.Field) .HasColumnName(\\\"PaymentMethodId\\\") .Is\", \"Required( false ); orderConfiguration.Property<string>(\\\"Description\\\").IsRequired( false ); var navig\", \"ation = orderConfiguration.Metadata.FindNavigation(nameof(Order.OrderItems)); // DDD Patterns commen\", \"t: //Set as field (New since EF 1.1) to access the OrderItem collection property through its field n\", \"avigation.SetPropertyAccessMode(PropertyAccessMode.Field); orderConfiguration.HasOne<PaymentMethod>(\", \") .WithMany() .HasForeignKey(\\\"_paymentMethodId\\\") .IsRequired( false ) .OnDelete(DeleteBehavior.Restr\", \"ict); orderConfiguration.HasOne<Buyer>() .WithMany() .IsRequired( false ) .HasForeignKey(\\\"_buyerId\\\")\", \"; orderConfiguration.HasOne(o => o.OrderStatus) .WithMany() .HasForeignKey(\\\"_orderStatusId\\\"); } }\\n``\", \"`\\n\\nYou could set all the Fluent API mappings within the same OnModelCreating method, but it's advisa\", \"ble to partition that code and have multiple configuration classes, one per entity, as shown in\\n\\nthe\", \" example. Especially for large models, it is advisable to have separate configuration classes for co\", \"nfiguring different entity types.\\n\\nThe code in the example shows a few explicit declarations and map\", \"ping. However, EF Core conventions do many of those mappings automatically, so the actual code you w\", \"ould need in your case might be smaller.\\n\\n## The Hi/Lo algorithm in EF Core\\n\\nAn interesting aspect o\", \"f code in the preceding example is that it uses the Hi/Lo algorithm as the key generation strategy.\\n\", \"\\nThe Hi/Lo algorithm is useful when you need unique keys before committing changes. As a summary, th\", \"e Hi-Lo algorithm assigns unique identifiers to table rows while not depending on storing the row in\", \" the database immediately. This lets you start using the identifiers right away, as happens with reg\", \"ular sequential database IDs.\\n\\nThe Hi/Lo algorithm describes a mechanism for getting a batch of uniq\", \"ue IDs from a related database sequence. These IDs are safe to use because the database guarantees t\", \"he uniqueness, so there will be no collisions between users. This algorithm is interesting for these\", \" reasons:\\n\\n- It does not break the Unit of Work pattern.\\n- It gets sequence IDs in batches, to minim\", \"ize round trips to the database.\\n- It generates a human readable identifier, unlike techniques that \", \"use GUIDs.\\n\\nEF Core supports HiLo with the UseHiLo method, as shown in the preceding example.\\n\\n## Ma\", \"p fields instead of properties\\n\\nWith this feature, available since EF Core 1.1, you can directly map\", \" columns to fields. It is possible to not use properties in the entity class, and just to map column\", \"s from a table to fields. A common use for that would be private fields for any internal state that \", \"do not need to be accessed from outside the entity.\\n\\nYou can do this with single fields or also with\", \" collections, like a List&lt;&gt; field. This point was mentioned earlier when we discussed modeling\", \" the domain model classes, but here you can see how that mapping is performed with the PropertyAcces\", \"sMode.Field configuration highlighted in the previous code.\\n\\n## Use shadow properties in EF Core, hi\", \"dden at the infrastructure level\\n\\nShadow properties in EF Core are properties that do not exist in y\", \"our entity class model. The values and states of these properties are maintained purely in the Chang\", \"eTracker class at the infrastructure level.\\n\\n## Implement the Query Specification pattern\\n\\nAs introd\", \"uced earlier in the design section, the Query Specification pattern is a Domain-Driven Design patter\", \"n designed as the place where you can put the definition of a query with optional sorting and paging\", \" logic.\\n\\nThe Query Specification pattern defines a query in an object. For example, in order to enca\", \"psulate a paged query that searches for some products you can create a PagedProduct specification th\", \"at takes the necessary input parameters (pageNumber, pageSize, filter, etc.). Then, within any Repos\", \"itory method (usually a List() overload) it would accept an IQuerySpecification and run the expected\", \" query based on that specification.\\n\\nAn example of a generic Specification interface is the followin\", \"g code, which is similar to code used in the eShopOnWeb reference application.\\n\\n```\\n// GENERIC SPECI\", \"FICATION INTERFACE // https://github.com/dotnet-architecture/eShopOnWeb public interface ISpecificat\", \"ion<T> { Expression<Func<T, bool>> Criteria { get ; } List<Expression<Func<T, object>>> Includes { g\", \"et ; } List<string> IncludeStrings { get ; } }\\n```\\n\\nThen, the implementation of a generic specificat\", \"ion base class is the following.\\n\\n```\\n// GENERIC SPECIFICATION IMPLEMENTATION (BASE CLASS) // https:\", \"//github.com/dotnet-architecture/eShopOnWeb public abstract class BaseSpecification<T> : ISpecificat\", \"ion<T> { public BaseSpecification(Expression<Func<T, bool>> criteria) { Criteria = criteria; } publi\", \"c Expression<Func<T, bool>> Criteria { get ; } public List<Expression<Func<T, object>>> Includes { g\", \"et ; } = new List<Expression<Func<T, object>>>(); public List<string> IncludeStrings { get ; } = new\", \" List<string>(); protected virtual void AddInclude(Expression<Func<T, object>> includeExpression) { \", \"Includes.Add(includeExpression); } // string-based includes allow for including children of children\", \" // e.g. Basket.Items.Product protected virtual void AddInclude(string includeString) { IncludeStrin\", \"gs.Add(includeString); } }\\n```\\n\\nThe following specification loads a single basket entity given eithe\", \"r the basket's ID or the ID of the buyer to whom the basket belongs. It will eagerly load the basket\", \"'s Items collection.\\n\\n```\\n// SAMPLE QUERY SPECIFICATION IMPLEMENTATION public class BasketWithItemsS\", \"pecification : BaseSpecification<Basket> { public BasketWithItemsSpecification(int basketId) : base \", \"(b => b.Id == basketId) { AddInclude(b => b.Items); } public BasketWithItemsSpecification(string buy\", \"erId) : base (b => b.BuyerId == buyerId) { AddInclude(b => b.Items); } }\\n```\\n\\nAnd finally, you can s\", \"ee below how a generic EF Repository can use such a specification to filter and eager-load data rela\", \"ted to a given entity type T.\\n\\n```\\n// GENERIC EF REPOSITORY WITH SPECIFICATION // https://github.com\", \"/dotnet-architecture/eShopOnWeb public IEnumerable<T> List(ISpecification<T> spec) { // fetch a Quer\", \"yable that includes all expression-based includes var queryableResultWithIncludes = spec.Includes .A\", \"ggregate(_dbContext.Set<T>().AsQueryable(), (current, include) => current.Include(include)); // modi\", \"fy the IQueryable to include any string-based include statements var secondaryResult = spec.IncludeS\", \"trings .Aggregate(queryableResultWithIncludes, (current, include) => current.Include(include)); // r\", \"eturn the result of the query using the specification's criteria expression return secondaryResult .\", \"Where(spec.Criteria) .AsEnumerable(); }\\n```\\n\\nIn addition to encapsulating filtering logic, the speci\", \"fication can specify the shape of the data to be returned, including which properties to populate.\\n\\n\", \"Although we don't recommend returning IQueryable from a repository, it's perfectly fine to use them \", \"within the repository to build up a set of results. You can see this approach used in the List metho\", \"d above, which uses intermediate IQueryable expressions to build up the query's list of includes bef\", \"ore executing the query with the specification's criteria on the last line.\\n\\nLearn how the specifica\", \"tion pattern is applied in the eShopOnWeb sample.\\n\\n## Additional resources\\n\\n- Table Mapping\\n\\nhttps:/\", \"/learn.microsoft.com/ef/core/modeling/relational/tables\\n\\n- Use HiLo to generate keys with Entity Fra\", \"mework Core https://www.talkingdotnet.com/use-hilo-to-generate-keys-with-entity-framework-core/\\n- Ba\", \"cking Fields https://learn.microsoft.com/ef/core/modeling/backing-field\\n- Steve Smith. Encapsulated \", \"Collections in Entity Framework Core https://ardalis.com/encapsulated-collections-in-entity-framewor\", \"k-core\\n- Shadow Properties https://learn.microsoft.com/ef/core/modeling/shadow-properties\\n- The Spec\", \"ification pattern https://deviq.com/specification-pattern/\\n\\nArdalis.Specification NuGet Package Used\", \" by eShopOnWeb.  https://www.nuget.org/packages/Ardalis.Specification\\n\\n## Use NoSQL databases as a p\", \"ersistence infrastructure\\n\\nWhen you use NoSQL databases for your infrastructure data tier, you typic\", \"ally do not use an ORM like Entity Framework Core. Instead you use the API provided by the NoSQL eng\", \"ine, such as Azure Cosmos DB, MongoDB, Cassandra, RavenDB, CouchDB, or Azure Storage Tables.\\n\\nHoweve\", \"r, when you use a NoSQL database, especially a document-oriented database like Azure Cosmos DB, Couc\", \"hDB, or RavenDB, the way you design your model with DDD aggregates is partially similar to how you c\", \"an do it in EF Core, in regards to the identification of aggregate roots, child entity classes, and \", \"value object classes. But, ultimately, the database selection will impact in your design.\\n\\nWhen you \", \"use a document-oriented database, you implement an aggregate as a single document, serialized in JSO\", \"N or another format. However, the use of the database is transparent from a domain model code point \", \"of view. When using a NoSQL database, you still are using entity classes and aggregate root classes,\", \" but with more flexibility than when using EF Core because the persistence is not relational.\\n\\nThe d\", \"ifference is in how you persist that model. If you implemented your domain model based on POCO entit\", \"y classes, agnostic to the infrastructure persistence, it might look like you could move to a differ\", \"ent persistence infrastructure, even from relational to NoSQL. However, that should not be your goal\", \". There are always constraints and trade-offs in the different database technologies, so you will no\", \"t be able to have the same model for relational or NoSQL databases. Changing persistence models is n\", \"ot a trivial task, because transactions and persistence operations will be very different.\\n\\nFor exam\", \"ple, in a document-oriented database, it is okay for an aggregate root to have multiple child collec\", \"tion properties. In a relational database, querying multiple child collection properties is not\\n\\neas\", \"ily optimized, because you get a UNION ALL SQL statement back from EF. Having the same domain model \", \"for relational databases or NoSQL databases is not simple, and you should not try to do it. You real\", \"ly have to design your model with an understanding of how the data is going to be used in each parti\", \"cular database.\\n\\nA benefit when using NoSQL databases is that the entities are more denormalized, so\", \" you do not set a table mapping. Your domain model can be more flexible than when using a relational\", \" database.\\n\\nWhen you design your domain model based on aggregates, moving to NoSQL and documentorien\", \"ted databases might be even easier than using a relational database, because the aggregates you desi\", \"gn are similar to serialized documents in a document-oriented database. Then you can include in thos\", \"e 'bags' all the information you might need for that aggregate.\\n\\nFor instance, the following JSON co\", \"de is a sample implementation of an order aggregate when using a document-oriented database. It is s\", \"imilar to the order aggregate we implemented in the eShopOnContainers sample, but without using EF C\", \"ore underneath.\\n\\n```\\n{ \\\"id\\\": \\\"2024001\\\", \\\"orderDate\\\": \\\"2/25/2024\\\", \\\"buyerId\\\": \\\"1234567\\\", \\\"address\\\": [\", \" { \\\"street\\\": \\\"100 One Microsoft Way\\\", \\\"city\\\": \\\"Redmond\\\", \\\"state\\\": \\\"WA\\\", \\\"zip\\\": \\\"98052\\\", \\\"country\\\": \\\"\", \"U.S.\\\" } ], \\\"orderItems\\\": [ {\\\"id\\\": 20240011, \\\"productId\\\": \\\"123456\\\", \\\"productName\\\": \\\".NET T-Shirt\\\", \\\"u\", \"nitPrice\\\": 25, \\\"units\\\": 2, \\\"discount\\\": 0}, {\\\"id\\\": 20240012, \\\"productId\\\": \\\"123457\\\", \\\"productName\\\": \\\".\", \"NET Mug\\\", \\\"unitPrice\\\": 15, \\\"units\\\": 1, \\\"discount\\\": 0} ] }\\n```\\n\\n## Introduction to Azure Cosmos DB an\", \"d the native Cosmos DB API\\n\\nAzure Cosmos DB is Microsoft's globally distributed database service for\", \" mission -critical applications. Azure Cosmos DB provides turn-key global distribution, elastic scal\", \"ing of throughput and storage worldwide, single-digit millisecond latencies at the 99th percentile, \", \"five well-defined consistency levels, and guaranteed high availability, all backed by industry-leadi\", \"ng SLAs. Azure Cosmos DB automatically indexes data without requiring you to deal with schema and in\", \"dex management. It is multi-model and supports document, key-value, graph, and columnar data models.\", \"\\n\\nGlobal distribution\\n\\nAzure Cosmos DB\\n\\nKey-Value\\n\\n:\\n\\nElastic scale out\\n\\n<!-- image -->\\n\\nComprehensi\", \"ve SLAs\\n\\nFigure 7-19. Azure Cosmos DB global distribution\\n\\n<!-- image -->\\n\\nWhen you use a C# model t\", \"o implement the aggregate to be used by the Azure Cosmos DB API, the aggregate can be similar to the\", \" C# POCO classes used with EF Core. The difference is in the way to use them from the application an\", \"d infrastructure layers, as in the following code:\\n\\n```\\n// C# EXAMPLE OF AN ORDER AGGREGATE BEING PE\", \"RSISTED WITH AZURE COSMOS DB API // *** Domain Model Code *** // Aggregate: Create an Order object w\", \"ith its child entities and/or value objects. // Then, use AggregateRoot's methods to add the nested \", \"objects so invariants and // logic is consistent across the nested properties (value objects and ent\", \"ities). Order orderAggregate = new Order { Id = \\\"2024001\\\", OrderDate = new DateTime(2005, 7, 1), Buy\", \"erId = \\\"1234567\\\", PurchaseOrderNumber = \\\"PO18009186470\\\" } Address address = new Address { Street = \\\"\", \"100 One Microsoft Way\\\", City = \\\"Redmond\\\", State = \\\"WA\\\", Zip = \\\"98052\\\", Country = \\\"U.S.\\\" } orderAggre\", \"gate.UpdateAddress(address); OrderItem orderItem1 = new OrderItem {\\n```\\n\\n```\\nId = 20240011, ProductI\", \"d = \\\"123456\\\", ProductName = \\\".NET T-Shirt\\\", UnitPrice = 25, Units = 2, Discount = 0; }; //Using meth\", \"ods with domain logic within the entity. No anemic-domain model orderAggregate.AddOrderItem(orderIte\", \"m1); // *** End of Domain Model Code *** // *** Infrastructure Code using Cosmos DB Client API *** U\", \"ri collectionUri = UriFactory.CreateDocumentCollectionUri(databaseName, collectionName); await clien\", \"t.CreateDocumentAsync(collectionUri, orderAggregate); // As your app evolves, let's say your object \", \"has a new schema. You can insert // OrderV2 objects without any changes to the database tier. Order2\", \" newOrder = GetOrderV2Sample(\\\"IdForSalesOrder2\\\"); await client.CreateDocumentAsync(collectionUri, ne\", \"wOrder);\\n```\\n\\nYou can see that the way you work with your domain model can be similar to the way you\", \" use it in your domain model layer when the infrastructure is EF. You still use the same aggregate r\", \"oot methods to ensure consistency, invariants, and validations within the aggregate.\\n\\nHowever, when \", \"you persist your model into the NoSQL database, the code and API change dramatically compared to EF \", \"Core code or any other code related to relational databases.\\n\\n## Implement .NET code targeting Mongo\", \"DB and Azure Cosmos DB\\n\\n## Use Azure Cosmos DB from .NET containers\\n\\nYou can access Azure Cosmos DB \", \"databases from .NET code running in containers, like from any other .NET application. For instance, \", \"the Locations.API and Marketing.API microservices in eShopOnContainers are implemented so they can c\", \"onsume Azure Cosmos DB databases.\\n\\nHowever, there's a limitation in Azure Cosmos DB from a Docker de\", \"velopment environment point of view. Even though there's an on -premises Azure Cosmos DB Emulator th\", \"at can run in a local development machine, it only supports Windows. Linux and macOS aren't supporte\", \"d.\\n\\nThere's also the possibility to run this emulator on Docker, but just on Windows Containers, not\", \" with Linux Containers. That's an initial handicap for the development environment if your applicati\", \"on is deployed as Linux containers, since, currently, you ca n't deploy Linux and Windows Containers\", \" on Docker for Windows at the same time. Either all containers being deployed have to be for Linux o\", \"r for Windows.\\n\\nThe ideal and more straightforward deployment for a dev/test solution is to be able \", \"to deploy your database systems as containers along with your custom containers so your dev/test env\", \"ironments are always consistent.\\n\\nnodeo\\n\\nMicrosoft\\n\\n~ python\\\"\\n\\n## Use MongoDB API for local dev/test\", \" Linux/Windows containers plus Azure Cosmos DB Azure Cosmos DB:\\n\\nNET\\n\\nRuby\\n\\nCosmos DB databases supp\", \"ort MongoDB API for .NET as well as the native MongoDB wire protocol. This means that by using exist\", \"ing drivers, your application written for MongoDB can now communicate with Cosmos DB and use Cosmos \", \"DB databases instead of MongoDB databases, as shown in Figure 7-20.\\n\\nFigure 7-20. Using MongoDB API \", \"and protocol to access Azure Cosmos DB\\n\\n<!-- image -->\\n\\nThis is a very convenient approach for proof\", \" of concepts in Docker environments with Linux containers because the MongoDB Docker image is a mult\", \"i-arch image that supports Docker Linux containers and Docker Windows containers.\\n\\nAs shown in the f\", \"ollowing image, by using the MongoDB API, eShopOnContainers supports MongoDB Linux and Windows conta\", \"iners for the local development environment but then, you can move to a scalable, PaaS cloud solutio\", \"n as Azure Cosmos DB by simply changing the MongoDB connection string to point to Azure Cosmos DB.\\n\\n\", \"| Docker Host\\n\\nMicrosott\\n\\nAzure\\n\\nFigure 7-21. eShopOnContainers using MongoDB containers for dev-env\", \" or Azure Cosmos DB for production\\n\\n<!-- image -->\\n\\nThe production Azure Cosmos DB would be running \", \"in Azure's cloud as a PaaS and scalable service.\\n\\nYour custom .NET containers can run on a local dev\", \"elopment Docker host (that is using Docker for Windows in a Windows 10 machine) or be deployed into \", \"a production environment, like Kubernetes in Azure AKS or Azure Service Fabric. In this second envir\", \"onment, you would deploy only the .NET custom containers but not the MongoDB container since you'd b\", \"e using Azure Cosmos DB in the cloud for handling the data in production.\\n\\nA clear benefit of using \", \"the MongoDB API is that your solution could run in both database engines, MongoDB or Azure Cosmos DB\", \", so migrations to different environments should be easy. However, sometimes it is worthwhile to use\", \" a native API (that is the native Cosmos DB API) in order to take full advantage of the capabilities\", \" of a specific database engine.\\n\\nFor further comparison between simply using MongoDB versus Cosmos D\", \"B in the cloud, see the Benefits of using Azure Cosmos DB in this page.\\n\\n## Analyze your approach fo\", \"r production applications: MongoDB API vs. Cosmos DB API\\n\\nIn eShopOnContainers, we're using MongoDB \", \"API because our priority was fundamentally to have a consistent dev/test environment using a NoSQL d\", \"atabase that could also work with Azure Cosmos DB.\\n\\nHowever, if you are planning to use MongoDB API \", \"to access Azure Cosmos DB in Azure for production applications, you should analyze the differences i\", \"n capabilities and performance when using MongoDB API to access Azure Cosmos DB databases compared t\", \"o using the native Azure Cosmos DB API. If it is similar you can use MongoDB API and you get the ben\", \"efit of supporting two NoSQL database engines at the same time.\\n\\nYou could also use MongoDB clusters\", \" as the production database in Azure's cloud, too, with MongoDB Azure Service. But that is not a Paa\", \"S service provided by Microsoft. In this case, Azure is just hosting that solution coming from Mongo\", \"DB.\\n\\nBasically, this is just a disclaimer stating that you shouldn't always use MongoDB API against \", \"Azure Cosmos DB, as we did in eShopOnContainers because it was a convenient choice for Linux contain\", \"ers. The decision should be based on the specific needs and tests you need to do for your production\", \" application.\\n\\n## The code: Use MongoDB API in .NET applications\\n\\nMongoDB API for .NET is based on N\", \"uGet packages that you need to add to your projects, like in the Locations.API project shown in the \", \"following figure.\\n\\nLocations.API\\n\\nConnected Services\\n\\n#\\u2022 Dependencies\\n\\nF Analyzers\\n\\nFrameworks\\n\\n*.\\n\\n\", \"*.\\n\\n<!-- image -->\\n\\nP\\n\\nP\\n\\nP\\n\\nP\\n\\nP\\n\\nP\\n\\nP\\n\\nP\\n\\n\\u2022.\\n\\n\\u2022 Projects\\n\\nProperties\\n\\nFigure 7-22. MongoDB API NuG\", \"et packages references in a .NET project\\n\\nLet's investigate the code in the following sections.\\n\\n## \", \"A Model used by MongoDB API\\n\\nFirst, you need to define a model that will hold the data coming from t\", \"he database in your application's memory space. Here's an example of the model used for Locations at\", \" eShopOnContainers.\\n\\n```\\nusing MongoDB.Bson; using MongoDB.Bson.Serialization.Attributes; using Mong\", \"oDB.Driver.GeoJsonObjectModel; using System.Collections.Generic; public class Locations {\\n```\\n\\n```\\n[\", \"BsonId] [BsonRepresentation(BsonType.ObjectId)] public string Id { get ; set ; } public int Location\", \"Id { get ; set ; } public string Code { get ; set ; } [BsonRepresentation(BsonType.ObjectId)] public\", \" string Parent_Id { get ; set ; } public string Description { get ; set ; } public double Latitude {\", \" get ; set ; } public double Longitude { get ; set ; } public GeoJsonPoint<GeoJson2DGeographicCoordi\", \"nates> Location { get ; private set ; } public GeoJsonPolygon<GeoJson2DGeographicCoordinates> Polygo\", \"n { get ; private set ; } public void SetLocation(double lon, double lat) => SetPosition(lon, lat); \", \"public void SetArea(List<GeoJson2DGeographicCoordinates> coordinatesList) => SetPolygon(coordinatesL\", \"ist); private void SetPosition(double lon, double lat) { Latitude = lat; Longitude = lon; Location =\", \" new GeoJsonPoint<GeoJson2DGeographicCoordinates>( new GeoJson2DGeographicCoordinates(lon, lat)); } \", \"private void SetPolygon(List<GeoJson2DGeographicCoordinates> coordinatesList) { Polygon = new GeoJso\", \"nPolygon<GeoJson2DGeographicCoordinates>( new GeoJsonPolygonCoordinates<GeoJson2DGeographicCoordinat\", \"es>( new GeoJsonLinearRingCoordinates<GeoJson2DGeographicCoordinates>( coordinatesList))); } }\\n```\\n\\n\", \"You can see there are a few attributes and types coming from the MongoDB NuGet packages.\\n\\nNoSQL data\", \"bases are usually very well suited for working with non-relational hierarchical data. In this exampl\", \"e, we are using MongoDB types especially made for geo-locations, like GeoJson2DGeographicCoordinates\", \".\\n\\n## Retrieve the database and the collection\\n\\nIn eShopOnContainers, we have created a custom datab\", \"ase context where we implement the code to retrieve the database and the MongoCollections, as in the\", \" following code.\\n\\n```\\npublic class LocationsContext { private readonly IMongoDatabase _database = nu\", \"ll ; public LocationsContext(IOptions<LocationSettings> settings) { var client = new MongoClient(set\", \"tings.Value.ConnectionString); if (client != null ) _database = client.GetDatabase(settings.Value.Da\", \"tabase); } public IMongoCollection<Locations> Locations {\\n```\\n\\n```\\nget { return _database.GetCollect\", \"ion<Locations>(\\\"Locations\\\"); } } }\\n```\\n\\n## Retrieve the data\\n\\nIn C# code, like Web API controllers o\", \"r custom Repositories implementation, you can write similar code to the following when querying thro\", \"ugh the MongoDB API. Note that the \\\\_context object is an instance of the previous LocationsContext \", \"class.\\n\\n```\\npublic async Task<Locations> GetAsync(int locationId) { var filter = Builders<Locations>\", \".Filter.Eq(\\\"LocationId\\\", locationId); return await _context.Locations .Find(filter) .FirstOrDefaultA\", \"sync(); }\\n```\\n\\n## Use an env-var in the docker-compose.override.yml file for the MongoDB connection \", \"string\\n\\nWhen creating a MongoClient object, it needs a fundamental parameter which is precisely the \", \"ConnectionString parameter pointing to the right database. In the case of eShopOnContainers, the con\", \"nection string can point to a local MongoDB Docker container or to a 'production' Azure Cosmos DB da\", \"tabase. That connection string comes from the environment variables defined in the dockercompose.ove\", \"rride.yml files used when deploying with docker-compose or Visual Studio, as in the following yml co\", \"de.\\n\\n```\\n# docker-compose.override.yml version : '3.4' services : # Other services locations-api : e\", \"nvironment : # Other settings -ConnectionString=${ESHOP_AZURE_COSMOSDB:-mongodb://nosqldata}\\n```\\n\\nTh\", \"e ConnectionString environment variable is resolved this way: If the ESHOP\\\\_AZURE\\\\_COSMOSDB global v\", \"ariable is defined in the .env file with the Azure Cosmos DB connection string, it will use it to ac\", \"cess the Azure Cosmos DB database in the cloud. If it's not defined, it will take the mongodb://nosq\", \"ldata value and use the development MongoDB container.\\n\\nThe following code shows the .env file with \", \"the Azure Cosmos DB connection string global environment variable, as implemented in eShopOnContaine\", \"rs:\\n\\n```\\n# .env file, in eShopOnContainers root folder # Other Docker environment variables ESHOP_EX\", \"TERNAL_DNS_NAME_OR_IP=host.docker.internal ESHOP_PROD_EXTERNAL_DNS_NAME_OR_IP=<YourDockerHostIP> #ES\", \"HOP_AZURE_COSMOSDB=<YourAzureCosmosDBConnData>\\n```\\n\\n```\\n#Other environment variables for additional \", \"Azure infrastructure assets #ESHOP_AZURE_REDIS_BASKET_DB=<YourAzureRedisBasketInfo> #ESHOP_AZURE_STO\", \"RAGE_CATALOG_URL=<YourAzureStorage_Catalog_BLOB_URL> #ESHOP_AZURE_SERVICE_BUS=<YourAzureServiceBusIn\", \"fo>\\n```\\n\\nUncomment the ESHOP\\\\_AZURE\\\\_COSMOSDB line and update it with your Azure Cosmos DB connectio\", \"n string obtained from the Azure portal as explained in Connect a MongoDB application to Azure Cosmo\", \"s DB.\\n\\nIf the ESHOP\\\\_AZURE\\\\_COSMOSDB global variable is empty, meaning it's commented out in the .en\", \"v file, then the container uses a default MongoDB connection string. This connection string points t\", \"o the local MongoDB container deployed in eShopOnContainers that is named nosqldata and was defined \", \"at the docker-compose file, as shown in the following .yml code:\\n\\n```\\n# docker-compose.yml version :\", \" '3.4' services : # ...Other services... nosqldata : image : mongo\\n```\\n\\n## Additional resources\\n\\n- M\", \"odeling document data for NoSQL databases https://learn.microsoft.com/azure/cosmos-db/modeling-data\\n\", \"- Vaughn Vernon. The Ideal Domain-Driven Design Aggregate Store? https://kalele.io/blog-posts/the-id\", \"eal-domain-driven-design-aggregate-store/\\n- Introduction to Azure Cosmos DB: API for MongoDB https:/\", \"/learn.microsoft.com/azure/cosmos-db/mongodb-introduction\\n- Azure Cosmos DB: Build a MongoDB API web\", \" app with .NET and the Azure portal https://learn.microsoft.com/azure/cosmos-db/create-mongodb-dotne\", \"t\\n- Use the Azure Cosmos DB Emulator for local development and testing https://learn.microsoft.com/a\", \"zure/cosmos-db/local-emulator\\n- Connect a MongoDB application to Azure Cosmos DB https://learn.micro\", \"soft.com/azure/cosmos-db/connect-mongodb-account\\n- The Cosmos DB Emulator Docker image (Windows Cont\", \"ainer) https://hub.docker.com/r/microsoft/azure-cosmosdb-emulator/\\n- The MongoDB Docker image (Linux\", \" and Windows Container) https://hub.docker.com/\\\\_/mongo/\\n- Use MongoChef (Studio 3T) with an Azure C\", \"osmos DB: API for MongoDB account https://learn.microsoft.com/azure/cosmos-db/mongodb-mongochef\\n\\n## \", \"Design the microservice application layer and Web API\\n\\n## Use SOLID principles and Dependency Inject\", \"ion\\n\\nSOLID principles are critical techniques to be used in any modern and mission-critical applicat\", \"ion, such as developing a microservice with DDD patterns. SOLID is an acronym that groups five funda\", \"mental principles:\\n\\n- Single Responsibility principle\\n- Open/closed principle\\n- Liskov substitution \", \"principle\\n- Interface Segregation principle\\n- Dependency Inversion principle\\n\\nSOLID is more about ho\", \"w you design your application or microservice internal layers and about decoupling dependencies betw\", \"een them. It is not related to the domain, but to the application's technical design. The final prin\", \"ciple, the Dependency Inversion principle, allows you to decouple the infrastructure layer from the \", \"rest of the layers, which allows a better decoupled implementation of the DDD layers.\\n\\nDependency In\", \"jection (DI) is one way to implement the Dependency Inversion principle. It is a technique for achie\", \"ving loose coupling between objects and their dependencies. Rather than directly instantiating colla\", \"borators, or using static references (that is, using new\\u2026), the objects that a class needs in order \", \"to perform its actions are provided to (or 'injected into') the class. Most often, classes will decl\", \"are their dependencies via their constructor, allowing them to follow the Explicit Dependencies prin\", \"ciple. Dependency Injection is usually based on specific Inversion of Control (IoC) containers. ASP.\", \"NET Core provides a simple built-in IoC container, but you can also use your favorite IoC container,\", \" like Autofac or Ninject.\\n\\nBy following the SOLID principles, your classes will tend naturally to be\", \" small, well-factored, and easily tested. But how can you know if too many dependencies are being in\", \"jected into your classes? If you use DI through the constructor, it will be easy to detect that by j\", \"ust looking at the number of parameters for your constructor. If there are too many dependencies, th\", \"is is generally a sign (a code smell) that your class is trying to do too much, and is probably viol\", \"ating the Single Responsibility principle.\\n\\nIt would take another guide to cover SOLID in detail. Th\", \"erefore, this guide requires you to have only a minimum knowledge of these topics.\\n\\n## Additional re\", \"sources\\n\\n- SOLID: Fundamental OOP Principles https://deviq.com/solid/\\n\\n4 &amp;O] Ordering.API\\n\\n$ Con\", \"nected Services\\n\\n\\u2022 .: Dependencies\\n\\n\\u2022 &amp;\\n\\nProperties\\n\\n\\u2022 &amp;\\n\\n\\u2022 &amp;|\\n\\n- Inversion of Control C\", \"ontainers and the Dependency Injection pattern https://martinfowler.com/articles/injection.html\\n\\n\\u2022 \\u00e2\", \"|\\n\\n- Steve Smith. New is Glue\\n\\nhttps://ardalis.com/new-is-glue\\n\\n\\u2022 6[\\n\\nModels\\n\\n\\u2022 a 1 Queries\\n\\n\\u2022 a\\n\\n\\u2022 \", \"&amp;\\n\\n\\u2022 a\\n\\n## Implement the microservice application layer using the Web API\\n\\n\\u2022 a\\n\\n## Use Dependenc\", \"y Injection to inject infrastructure objects into your application layer\\n\\nAs mentioned previously, t\", \"he application layer can be implemented as part of the artifact (assembly) you are building, such as\", \" within a Web API project or an MVC web app project. In the case of a microservice built with ASP.NE\", \"T Core, the application layer will usually be your Web API library. If you want to separate what is \", \"coming from ASP.NET Core (its infrastructure plus your controllers) from your custom application lay\", \"er code, you could also place your application layer in a separate class library, but that is option\", \"al.\\n\\nFor instance, the application layer code of the ordering microservice is directly implemented a\", \"s part of the Ordering.API project (an ASP.NET Core Web API project), as shown in Figure 7-23.\\n\\nFigu\", \"re 7-23. The application layer in the Ordering.API ASP.NET Core Web API project\\n\\n<!-- image -->\\n\\nASP\", \".NET Core includes a simple built-in IoC container (represented by the IServiceProvider interface) t\", \"hat supports constructor injection by default, and ASP.NET makes certain services available through \", \"DI. ASP.NET Core uses the term service for any of the types you register that will be injected throu\", \"gh DI. You configure the builtin container's services in your application's Program.cs file. Your\\n\\nd\", \"ependencies are implemented in the services that a type needs and that you register in the IoC conta\", \"iner.\\n\\nTypically, you want to inject dependencies that implement infrastructure objects. A typical d\", \"ependency to inject is a repository. But you could inject any other infrastructure dependency that y\", \"ou may have. For simpler implementations, you could directly inject your Unit of Work pattern object\", \" (the EF DbContext object), because the DBContext is also the implementation of your infrastructure \", \"persistence objects.\\n\\nIn the following example, you can see how .NET is injecting the required repos\", \"itory objects through the constructor. The class is a command handler, which will get covered in the\", \" next section.\\n\\n```\\npublic class CreateOrderCommandHandler : IRequestHandler<CreateOrderCommand, boo\", \"l> { private readonly IOrderRepository _orderRepository; private readonly IIdentityService _identity\", \"Service; private readonly IMediator _mediator; private readonly IOrderingIntegrationEventService _or\", \"deringIntegrationEventService; private readonly ILogger<CreateOrderCommandHandler> _logger; // Using\", \" DI to inject infrastructure persistence Repositories public CreateOrderCommandHandler(IMediator med\", \"iator, IOrderingIntegrationEventService orderingIntegrationEventService, IOrderRepository orderRepos\", \"itory, IIdentityService identityService, ILogger<CreateOrderCommandHandler> logger) { _orderReposito\", \"ry = orderRepository ?? throw new ArgumentNullException(nameof(orderRepository)); _identityService =\", \" identityService ?? throw new ArgumentNullException(nameof(identityService)); _mediator = mediator ?\", \"? throw new ArgumentNullException(nameof(mediator)); _orderingIntegrationEventService = orderingInte\", \"grationEventService ?? throw new ArgumentNullException(nameof(orderingIntegrationEventService)); _lo\", \"gger = logger ?? throw new ArgumentNullException(nameof(logger)); } public async Task<bool> Handle(C\", \"reateOrderCommand message, CancellationToken cancellationToken) { // Add Integration event to clean \", \"the basket var orderStartedIntegrationEvent = new OrderStartedIntegrationEvent(message.UserId); awai\", \"t _orderingIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEvent); // Add/Update\", \" the Buyer AggregateRoot // DDD patterns comment: Add child entities and value-objects through the O\", \"rder Aggregate-Root // methods and constructor so validations, invariants and business logic // make\", \" sure that consistency is preserved across the whole aggregate var address = new Address(message.Str\", \"eet, message.City, message.State, message.Country, message.ZipCode); var order = new Order(message.U\", \"serId, message.UserName, address, message.CardTypeId, message.CardNumber, message.CardSecurityNumber\", \", message.CardHolderName, message.CardExpiration); foreach (var item in message.OrderItems)\\n```\\n\\n```\", \"\\n{ order.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice, item.Discount, item.PictureU\", \"rl, item.Units); } _logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order); _orderRe\", \"pository.Add(order); return await _orderRepository.UnitOfWork .SaveEntitiesAsync(cancellationToken);\", \" } }\\n```\\n\\nThe class uses the injected repositories to execute the transaction and persist the state \", \"changes. It does not matter whether that class is a command handler, an ASP.NET Core Web API control\", \"ler method, or a DDD Application Service. It is ultimately a simple class that uses repositories, do\", \"main entities, and other application coordination in a fashion similar to a command handler. Depende\", \"ncy Injection works the same way for all the mentioned classes, as in the example using DI based on \", \"the constructor.\\n\\n## Register the dependency implementation types and interfaces or abstractions\\n\\nBe\", \"fore you use the objects injected through constructors, you need to know where to register the inter\", \"faces and classes that produce the objects injected into your application classes through DI. (Like \", \"DI based on the constructor, as shown previously.)\\n\\n## Use the built-in IoC container provided by AS\", \"P.NET Core\\n\\nWhen you use the built-in IoC container provided by ASP.NET Core, you register the types\", \" you want to inject in the Program.cs file, as in the following code:\\n\\n```\\n// Register out-of-the-bo\", \"x framework services. builder.Services.AddDbContext<CatalogContext>(c => c.UseSqlServer(Configuratio\", \"n[\\\"ConnectionString\\\"]), ServiceLifetime.Scoped); builder.Services.AddMvc(); // Register custom appli\", \"cation dependencies. builder.Services.AddScoped<IMyCustomRepository, MyCustomSQLRepository>();\\n```\\n\\n\", \"The most common pattern when registering types in an IoC container is to register a pair of types -a\", \"n interface and its related implementation class. Then when you request an object from the IoC conta\", \"iner through any constructor, you request an object of a certain type of interface. For instance, in\", \" the previous example, the last line states that when any of your constructors have a dependency on \", \"IMyCustomRepository (interface or abstraction), the IoC container will inject an instance of the MyC\", \"ustomSQLServerRepository implementation class.\\n\\n## Use the Scrutor library for automatic types regis\", \"tration\\n\\nWhen using DI in .NET, you might want to be able to scan an assembly and automatically regi\", \"ster its types by convention. This feature is not currently available in ASP.NET Core. However, you \", \"can use the\\n\\nScrutor library for that. This approach is convenient when you have dozens of types tha\", \"t need to be registered in your IoC container.\\n\\n## Additional resources\\n\\n- Matthew King. Registering\", \" services with Scrutor https://www.mking.net/blog/registering-services-with-scrutor\\n- GitHub repo.\\n-\", \" Kristian Hellang. Scrutor. https://github.com/khellang/Scrutor\\n\\n## Use Autofac as an IoC container\\n\", \"\\nYou can also use additional IoC containers and plug them into the ASP.NET Core pipeline, as in the \", \"ordering microservice in eShopOnContainers, which uses Autofac. When using Autofac you typically reg\", \"ister the types via modules, which allow you to split the registration types between multiple files \", \"depending on where your types are, just as you could have the application types distributed across m\", \"ultiple class libraries.\\n\\nFor example, the following is the Autofac application module for the Order\", \"ing.API Web API project with the types you will want to inject.\\n\\n```\\npublic class ApplicationModule \", \": Autofac.Module { public string QueriesConnectionString { get ; } public ApplicationModule(string q\", \"constr) { QueriesConnectionString = qconstr; } protected override void Load(ContainerBuilder builder\", \") { builder.Register(c => new OrderQueries(QueriesConnectionString)) .As<IOrderQueries>() .InstanceP\", \"erLifetimeScope(); builder.RegisterType<BuyerRepository>() .As<IBuyerRepository>() .InstancePerLifet\", \"imeScope(); builder.RegisterType<OrderRepository>() .As<IOrderRepository>() .InstancePerLifetimeScop\", \"e(); builder.RegisterType<RequestManager>() .As<IRequestManager>() .InstancePerLifetimeScope(); } }\\n\", \"```\\n\\nAutofac also has a feature to scan assemblies and register types by name conventions.\\n\\nThe regi\", \"stration process and concepts are very similar to the way you can register types with the builtin AS\", \"P.NET Core IoC container, but the syntax when using Autofac is a bit different.\\n\\nIn the example code\", \", the abstraction IOrderRepository is registered along with the implementation class OrderRepository\", \". This means that whenever a constructor is declaring a dependency through the\\n\\nIOrderRepository abs\", \"traction or interface, the IoC container will inject an instance of the OrderRepository class.\\n\\nThe \", \"instance scope type determines how an instance is shared between requests for the same service or de\", \"pendency. When a request is made for a dependency, the IoC container can return the following:\\n\\n- A \", \"single instance per lifetime scope (referred to in the ASP.NET Core IoC container as scoped ).\\n- A n\", \"ew instance per dependency (referred to in the ASP.NET Core IoC container as transient ).\\n- A single\", \" instance shared across all objects using the IoC container (referred to in the ASP.NET Core IoC con\", \"tainer as singleton ).\\n\\n## Additional resources\\n\\n- Introduction to Dependency Injection in ASP.NET C\", \"ore https://learn.microsoft.com/aspnet/core/fundamentals/dependency-injection\\n- Autofac. Official do\", \"cumentation. https://docs.autofac.org/en/latest/\\n- Comparing ASP.NET Core IoC container service life\", \"times with Autofac IoC container instance scopes - Cesar de la Torre. https://devblogs.microsoft.com\", \"/cesardelatorre/comparing-asp-net-core-ioc-service-lifetimes-and-autofac-ioc-instance-scopes/\\n\\n## Im\", \"plement the Command and Command Handler patterns\\n\\nIn the DI-through-constructor example shown in the\", \" previous section, the IoC container was injecting repositories through a constructor in a class. Bu\", \"t exactly where were they injected? In a simple Web API (for example, the catalog microservice in eS\", \"hopOnContainers), you inject them at the MVC controllers' level, in a controller constructor, as par\", \"t of the request pipeline of ASP.NET Core. However, in the initial code of this section (the CreateO\", \"rderCommandHandler class from the Ordering.API service in eShopOnContainers), the injection of depen\", \"dencies is done through the constructor of a particular command handler. Let us explain what a comma\", \"nd handler is and why you would want to use it.\\n\\nThe Command pattern is intrinsically related to the\", \" CQRS pattern that was introduced earlier in this guide. CQRS has two sides. The first area is queri\", \"es, using simplified queries with the Dapper micro ORM, which was explained previously. The second a\", \"rea is commands, which are the starting point for transactions, and the input channel from outside t\", \"he service.\\n\\nAs shown in Figure 7-24, the pattern is based on accepting commands from the client-sid\", \"e, processing them based on the domain model rules, and finally persisting the states with transacti\", \"ons.\\n\\nUl app\\n\\nCommand\\n\\nHigh level \\\"Writes-side\\\" in CQRS\\n\\nDomain\\n\\n## Command Model\\n\\nAPI\\n\\ninterface\\n\\nC\", \"ommand\\n\\nHandler\\n\\nFigure 7-24. Highlevel view of the commands or 'transactional side' in a CQRS patte\", \"rn\\n\\n<!-- image -->\\n\\nFigure 7-24 shows that the UI app sends a command through the API that gets to a\", \" CommandHandler, that depends on the Domain model and the Infrastructure, to update the database.\\n\\n#\", \"# The command class\\n\\nA command is a request for the system to perform an action that changes the sta\", \"te of the system. Commands are imperative, and should be processed just once.\\n\\nSince commands are im\", \"peratives, they are typically named with a verb in the imperative mood (for example, 'create' or 'up\", \"date'), and they might include the aggregate type, such as CreateOrderCommand. Unlike an event, a co\", \"mmand is not a fact from the past; it is only a request, and thus may be refused.\\n\\nCommands can orig\", \"inate from the UI as a result of a user initiating a request, or from a process manager when the pro\", \"cess manager is directing an aggregate to perform an action.\\n\\nAn important characteristic of a comma\", \"nd is that it should be processed just once by a single receiver. This is because a command is a sin\", \"gle action or transaction you want to perform in the application. For example, the same order creati\", \"on command should not be processed more than once. This is an important difference between commands \", \"and events. Events may be processed multiple times, because many systems or microservices might be i\", \"nterested in the event.\\n\\nIn addition, it is important that a command be processed only once in case \", \"the command is not idempotent. A command is idempotent if it can be executed multiple times without \", \"changing the result, either because of the nature of the command, or because of the way the system h\", \"andles the command.\\n\\nIt is a good practice to make your commands and updates idempotent when it make\", \"s sense under your domain's business rules and invariants. For instance, to use the same example, if\", \" for any reason (retry logic, hacking, etc.) the same CreateOrder command reaches your system multip\", \"le times, you should be able to identify it and ensure that you do not create multiple orders. To do\", \" so, you need to\\n\\nattach some kind of identity in the operations and identify whether the command or\", \" update was already processed.\\n\\nYou send a command to a single receiver; you do not publish a comman\", \"d. Publishing is for events that state a fact -that something has happened and might be interesting \", \"for event receivers. In the case of events, the publisher has no concerns about which receivers get \", \"the event or what they do it. But domain or integration events are a different story already introdu\", \"ced in previous sections.\\n\\nA command is implemented with a class that contains data fields or collec\", \"tions with all the information that is needed in order to execute that command. A command is a speci\", \"al kind of Data Transfer Object (DTO), one that is specifically used to request changes or transacti\", \"ons. The command itself is based on exactly the information that is needed for processing the comman\", \"d, and nothing more.\\n\\nThe following example shows the simplified CreateOrderCommand class. This is a\", \"n immutable command that is used in the ordering microservice in eShopOnContainers.\\n\\n```\\n// DDD and \", \"CQRS patterns comment: Note that it is recommended to implement immutable Commands // In this case, \", \"its immutability is achieved by having all the setters as private // plus only being able to update \", \"the data just once, when creating the object through its constructor. // References on Immutable Com\", \"mands: // http://cqrs.nu/Faq // https://docs.spine3.org/motivation/immutability.html // http://blog.\", \"gauffin.org/2012/06/griffin-container-introducing-command-support/ // https://learn.microsoft.com/do\", \"tnet/csharp/programming-guide/classes-and-structs/how-toimplement-a-lightweight-class-with-auto-impl\", \"emented-properties [DataContract] public class CreateOrderCommand : IRequest<bool> { [DataMember] pr\", \"ivate readonly List<OrderItemDTO> _orderItems; [DataMember] public string UserId { get ; private set\", \" ; } [DataMember] public string UserName { get ; private set ; } [DataMember] public string City { g\", \"et ; private set ; } [DataMember] public string Street { get ; private set ; } [DataMember] public s\", \"tring State { get ; private set ; } [DataMember] public string Country { get ; private set ; } [Data\", \"Member] public string ZipCode { get ; private set ; } [DataMember]\\n```\\n\\n```\\npublic string CardNumber\", \" { get ; private set ; } [DataMember] public string CardHolderName { get ; private set ; } [DataMemb\", \"er] public DateTime CardExpiration { get ; private set ; } [DataMember] public string CardSecurityNu\", \"mber { get ; private set ; } [DataMember] public int CardTypeId { get ; private set ; } [DataMember]\", \" public IEnumerable<OrderItemDTO> OrderItems => _orderItems; public CreateOrderCommand() { _orderIte\", \"ms = new List<OrderItemDTO>(); } public CreateOrderCommand(List<BasketItem> basketItems, string user\", \"Id, string userName, string city, string street, string state, string country, string zipcode, strin\", \"g cardNumber, string cardHolderName, DateTime cardExpiration, string cardSecurityNumber, int cardTyp\", \"eId) : this () { _orderItems = basketItems.ToOrderItemsDTO().ToList(); UserId = userId; UserName = u\", \"serName; City = city; Street = street; State = state; Country = country; ZipCode = zipcode; CardNumb\", \"er = cardNumber; CardHolderName = cardHolderName; CardExpiration = cardExpiration; CardSecurityNumbe\", \"r = cardSecurityNumber; CardTypeId = cardTypeId; CardExpiration = cardExpiration; } public class Ord\", \"erItemDTO { public int ProductId { get ; set ; } public string ProductName { get ; set ; } public de\", \"cimal UnitPrice { get ; set ; } public decimal Discount { get ; set ; } public int Units { get ; set\", \" ; } public string PictureUrl { get ; set ; } } }\\n```\\n\\nBasically, the command class contains all the\", \" data you need for performing a business transaction by using the domain model objects. Thus, comman\", \"ds are simply data structures that contain read-only data, and no behavior. The command's name indic\", \"ates its purpose. In many languages like C#, commands are represented as classes, but they are not t\", \"rue classes in the real object-oriented sense.\\n\\nAs an additional characteristic, commands are immuta\", \"ble, because the expected usage is that they are processed directly by the domain model. They do not\", \" need to change during their projected lifetime. In a C# class, immutability can be achieved by not \", \"having any setters or other methods that change the internal state.\\n\\nKeep in mind that if you intend\", \" or expect commands to go through a serializing/deserializing process, the properties must have a pr\", \"ivate setter, and the [DataMember] (or [JsonProperty]) attribute. Otherwise, the deserializer won't \", \"be able to reconstruct th e object at the destination with the required values. You can also use tru\", \"ly read-only properties if the class has a constructor with parameters for all properties, with the \", \"usual camelCase naming convention, and annotate the constructor as [JsonConstructor]. However, this \", \"option requires more code.\\n\\nFor example, the command class for creating an order is probably similar\", \" in terms of data to the order you want to create, but you probably do not need the same attributes.\", \" For instance, CreateOrderCommand does not have an order ID, because the order has not been created \", \"yet.\\n\\nMany command classes can be simple, requiring only a few fields about some state that needs to\", \" be changed. That would be the case if you are just changing the status of an order from 'in process\", \"' to 'paid' or 'shipped' by using a command similar to the fol lowing:\\n\\n```\\n[DataContract] public cl\", \"ass UpdateOrderStatusCommand :IRequest<bool> { [DataMember] public string Status { get ; private set\", \" ; } [DataMember] public string OrderId { get ; private set ; } [DataMember] public string BuyerIden\", \"tityGuid { get ; private set ; } }\\n```\\n\\nSome developers make their UI request objects separate from \", \"their command DTOs, but that is just a matter of preference. It is a tedious separation with not muc\", \"h additional value, and the objects are almost exactly the same shape. For instance, in eShopOnConta\", \"iners, some commands come directly from the client-side.\\n\\n## The Command handler class\\n\\nYou should i\", \"mplement a specific command handler class for each command. That is how the pattern works, and it's \", \"where you'll use the command object, the domain objects, and the infrastructure repository objects. \", \"The command handler is in fact the heart of the application layer in terms of CQRS and DDD. However,\", \" all the domain logic should be contained in the domain classes -within the aggregate roots (root en\", \"tities), child entities, or domain services, but not within the command handler, which is a class fr\", \"om the application layer.\\n\\nThe command handler class offers a strong stepping stone in the way to ac\", \"hieve the Single Responsibility Principle (SRP) mentioned in a previous section.\\n\\nA command handler \", \"receives a command and obtains a result from the aggregate that is used. The result should be either\", \" successful execution of the command, or an exception. In the case of an exception, the system state\", \" should be unchanged.\\n\\nThe command handler usually takes the following steps:\\n\\n- It receives the com\", \"mand object, like a DTO (from the mediator or other infrastructure object).\\n- It validates that the \", \"command is valid (if not validated by the mediator).\\n- It instantiates the aggregate root instance t\", \"hat is the target of the current command.\\n- It executes the method on the aggregate root instance, g\", \"etting the required data from the command.\\n- It persists the new state of the aggregate to its relat\", \"ed database. This last operation is the actual transaction.\\n\\nTypically, a command handler deals with\", \" a single aggregate driven by its aggregate root (root entity). If multiple aggregates should be imp\", \"acted by the reception of a single command, you could use domain events to propagate states or actio\", \"ns across multiple aggregates.\\n\\nThe important point here is that when a command is being processed, \", \"all the domain logic should be inside the domain model (the aggregates), fully encapsulated and read\", \"y for unit testing. The command handler just acts as a way to get the domain model from the database\", \", and as the final step, to tell the infrastructure layer (repositories) to persist the changes when\", \" the model is changed. The advantage of this approach is that you can refactor the domain logic in a\", \"n isolated, fully encapsulated, rich, behavioral domain model without changing code in the applicati\", \"on or infrastructure layers, which are the plumbing level (command handlers, Web API, repositories, \", \"etc.).\\n\\nWhen command handlers get complex, with too much logic, that can be a code smell. Review the\", \"m, and if you find domain logic, refactor the code to move that domain behavior to the methods of th\", \"e domain objects (the aggregate root and child entity).\\n\\nAs an example of a command handler class, t\", \"he following code shows the same CreateOrderCommandHandler class that you saw at the beginning of th\", \"is chapter. In this case, it also highlights the Handle method and the operations with the domain mo\", \"del objects/aggregates.\\n\\n```\\npublic class CreateOrderCommandHandler : IRequestHandler<CreateOrderCom\", \"mand, bool> { private readonly IOrderRepository _orderRepository; private readonly IIdentityService \", \"_identityService; private readonly IMediator _mediator; private readonly IOrderingIntegrationEventSe\", \"rvice _orderingIntegrationEventService; private readonly ILogger<CreateOrderCommandHandler> _logger;\", \" // Using DI to inject infrastructure persistence Repositories public CreateOrderCommandHandler(IMed\", \"iator mediator, IOrderingIntegrationEventService orderingIntegrationEventService, IOrderRepository o\", \"rderRepository,\\n```\\n\\n```\\nIIdentityService identityService, ILogger<CreateOrderCommandHandler> logger\", \") { _orderRepository = orderRepository ?? throw new ArgumentNullException(nameof(orderRepository)); \", \"_identityService = identityService ?? throw new ArgumentNullException(nameof(identityService)); _med\", \"iator = mediator ?? throw new ArgumentNullException(nameof(mediator)); _orderingIntegrationEventServ\", \"ice = orderingIntegrationEventService ?? throw new ArgumentNullException(nameof(orderingIntegrationE\", \"ventService)); _logger = logger ?? throw new ArgumentNullException(nameof(logger)); } public async T\", \"ask<bool> Handle(CreateOrderCommand message, CancellationToken cancellationToken) { // Add Integrati\", \"on event to clean the basket var orderStartedIntegrationEvent = new OrderStartedIntegrationEvent(mes\", \"sage.UserId); await _orderingIntegrationEventService.AddAndSaveEventAsync(orderStartedIntegrationEve\", \"nt); // Add/Update the Buyer AggregateRoot // DDD patterns comment: Add child entities and value-obj\", \"ects through the Order Aggregate-Root // methods and constructor so validations, invariants and busi\", \"ness logic // make sure that consistency is preserved across the whole aggregate var address = new A\", \"ddress(message.Street, message.City, message.State, message.Country, message.ZipCode); var order = n\", \"ew Order(message.UserId, message.UserName, address, message.CardTypeId, message.CardNumber, message.\", \"CardSecurityNumber, message.CardHolderName, message.CardExpiration); foreach (var item in message.Or\", \"derItems) { order.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice, item.Discount, item\", \".PictureUrl, item.Units); } _logger.LogInformation(\\\"----- Creating Order - Order: {@Order}\\\", order);\", \" _orderRepository.Add(order); return await _orderRepository.UnitOfWork .SaveEntitiesAsync(cancellati\", \"onToken); } }\\n```\\n\\nThese are additional steps a command handler should take:\\n\\n- Use the command's da\", \"ta to operate with the aggregate root's methods and behavior.\\n- Internally within the domain objects\", \", raise domain events while the transaction is executed, but that is transparent from a command hand\", \"ler point of view.\\n- If the aggregate's operation result is successful and after the transaction is \", \"finished, raise integration events. (These might also be raised by infrastructure classes like repos\", \"itories.)\\n\\n## Additional resources\\n\\n- Mark Seemann. At the Boundaries, Applications are Not Object-O\", \"riented https://blog.ploeh.dk/2011/05/31/AttheBoundaries,ApplicationsareNotObject-Oriented/\\n- Comman\", \"ds and events https://cqrs.nu/faq/Command%20and%20Events\\n- What does a command handler do? https://c\", \"qrs.nu/faq/Command%20Handlers\\n- Jimmy Bogard. Domain Command Patterns -Handlers https://jimmybogard.\", \"com/domain-command-patterns-handlers/\\n- Jimmy Bogard. Domain Command Patterns -Validation https://ji\", \"mmybogard.com/domain-command-patterns-validation/\\n\\n## The Command process pipeline: how to trigger a\", \" command handler\\n\\nThe next question is how to invoke a command handler. You could manually call it f\", \"rom each related ASP.NET Core controller. However, that approach would be too coupled and is not ide\", \"al.\\n\\nThe other two main options, which are the recommended options, are:\\n\\n- Through an in-memory Med\", \"iator pattern artifact.\\n- With an asynchronous message queue, in between controllers and handlers.\\n\\n\", \"## Use the Mediator pattern (in-memory) in the command pipeline\\n\\nAs shown in Figure 7-25, in a CQRS \", \"approach you use an intelligent mediator, similar to an in-memory bus, which is smart enough to redi\", \"rect to the right command handler based on the type of the command or DTO being received. The single\", \" black arrows between components represent the dependencies between objects (in many cases, injected\", \" through DI) with their related interactions.\\n\\nRunning as a container\\n\\nASP.NET Core\\n\\nController\\n\\n(Ap\", \"plication\\n\\nLayer)\\n\\nAggregates\\n\\nFigure 7-25. Using the Mediator pattern in process in a single CQRS m\", \"icroservice\\n\\n<!-- image -->\\n\\nThe above diagram shows a zoom-in from image 7-24: the ASP.NET Core con\", \"troller sends the command to MediatR's command pipeline, so they get to the appropriate handler.\\n\\nTh\", \"e reason that using the Mediator pattern makes sense is that in enterprise applications, the process\", \"ing requests can get complicated. You want to be able to add an open number of crosscutting concerns\", \" like logging, validations, audit, and security. In these cases, you can rely on a mediator pipeline\", \" (see Mediator pattern) to provide a means for these extra behaviors or crosscutting concerns.\\n\\nA me\", \"diator is an object that encapsulates the 'how' of this process: it coordinates execution based on s\", \"tate, the way a command handler is invoked, or the payload you provide to the handler. With a mediat\", \"or component, you can apply cross-cutting concerns in a centralized and transparent way by applying \", \"decorators (or pipeline behaviors since MediatR 3). For more information, see the Decorator pattern.\", \"\\n\\nDecorators and behaviors are similar to Aspect Oriented Programming (AOP), only applied to a speci\", \"fic process pipeline managed by the mediator component. Aspects in AOP that implement crosscutting c\", \"oncerns are applied based on aspect weavers injected at compilation time or based on object call int\", \"erception. Both typical AOP approaches are sometimes said to work 'like magic,' because it is not ea\", \"sy to see how AOP does its work. When dealing with serious issues or bugs, AOP can be difficult to d\", \"ebug. On the other hand, these decorators/behaviors are explicit and applied only in the context of \", \"the mediator, so debugging is much more predictable and easy.\\n\\nFor example, in the eShopOnContainers\", \" ordering microservice, has an implementation of two sample behaviors, a LogBehavior class and a Val\", \"idatorBehavior class. The implementation of the behaviors is explained in the next section by showin\", \"g how eShopOnContainers uses MediatR behaviors.\\n\\nMicroservice\\n\\n(Writes-side of a simplified CQRS Arc\", \"hitecture pattern)\\n\\nCommand\\n\\nCommand\\n\\n(Domain Model\\n\\nRunning as a container I\\n\\nWrites-side of a CQRS\", \" Architecture pattern using messaging\\n\\nWeb API\\n\\nmicroservice\\n\\nCommand-Handlers backend microservice\\n\", \"\\nRunning as a container\\n\\n## Use message queues (out-ofproc) in the command's pipeline\\n\\nAnother choic\", \"e is to use asynchronous messages based on brokers or message queues, as shown in Figure 7-26. That \", \"option could also be combined with the mediator component right before the command handler. Handler\\n\", \"\\n(Application\\n\\nLayer)\\n\\n-\\n\\n(Application\\n\\n## Layer) HA Message Queue (External to the Repository (Infr\", \"astructure\\n\\nmicroservices)\\n\\nLayer)\\n\\nDatabase\\n\\nFigure 7-26. Using message queues (out of the process \", \"and inter-process communication) with CQRS commands\\n\\n<!-- image -->\\n\\nCommand's pipeline can also be \", \"handled by a high availability message queue to deliver the commands to the appropriate handler. Usi\", \"ng message queues to accept the commands can further complicate your command's pipeline, because you\", \" will probably need to sp lit the pipeline into two processes connected through the external message\", \" queue. Still, it should be used if you need to have improved scalability and performance based on a\", \"synchronous messaging. Consider that in the case of Figure 7-26, the controller just posts the comma\", \"nd message into the queue and returns. Then the command handlers process the messages at their own p\", \"ace. That is a great benefit of queues: the message queue can act as a buffer in cases when hyper sc\", \"alability is needed, such as for stocks or any other scenario with a high volume of ingress data.\\n\\nH\", \"owever, because of the asynchronous nature of message queues, you need to figure out how to communic\", \"ate with the client application about the success or failure of the command's process. As a rule, yo\", \"u should never use 'fire and forget' commands. Every bu siness application needs to know if a comman\", \"d was processed successfully, or at least validated and accepted.\\n\\nThus, being able to respond to th\", \"e client after validating a command message that was submitted to an asynchronous queue adds complex\", \"ity to your system, as compared to an in-process command process that returns the operation's result\", \" after running the tran saction. Using queues, you might need to return the result of the command pr\", \"ocess through other operation result messages, which will require additional components and custom c\", \"ommunication in your system.\\n\\nAdditionally, async commands are one-way commands, which in many cases\", \" might not be needed, as is explained in the following interesting exchange between Burtsev Alexey a\", \"nd Greg Young in an online conversation:\\n\\n[Burtsev Alexey] I find lots of code where people use asyn\", \"c command handling or one-way command messaging without any reason to do so (they are not doing some\", \" long operation, they are not executing external async code, they do not even cross-application boun\", \"dary to be using message bus). Why do they introduce this unnecessary complexity? And actually, I ha\", \"ven't seen a CQRS code example with blocking command handlers so far, though it will work just fine \", \"in most cases.\\n\\n[Greg Young] [\\u2026] an asynchronous command doesn't exist; it's actually another event.\", \" If I must accept what you send me and raise an event if I disagree, it's no longer you telling me t\", \"o do something [that is, it's not a command]. It's you telling me someth ing has been done. This see\", \"ms like a slight difference at first, but it has many implications.\\n\\nAsynchronous commands greatly i\", \"ncrease the complexity of a system, because there is no simple way to indicate failures. Therefore, \", \"asynchronous commands are not recommended other than when scaling requirements are needed or in spec\", \"ial cases when communicating the internal microservices through messaging. In those cases, you must \", \"design a separate reporting and recovery system for failures.\\n\\nIn the initial version of eShopOnCont\", \"ainers, it was decided to use synchronous command processing, started from HTTP requests and driven \", \"by the Mediator pattern. That easily allows you to return the success or failure of the process, as \", \"in the CreateOrderCommandHandler implementation.\\n\\nIn any case, this should be a decision based on yo\", \"ur application's or microservice's business requirements.\\n\\n## Implement the command process pipeline\", \" with a mediator pattern (MediatR)\\n\\nAs a sample implementation, this guide proposes using the in-pro\", \"cess pipeline based on the Mediator pattern to drive command ingestion and route commands, in memory\", \", to the right command handlers. The guide also proposes applying behaviors in order to separate cro\", \"ss-cutting concerns.\\n\\nFor implementation in .NET, there are multiple open-source libraries available\", \" that implement the Mediator pattern. The library used in this guide is the MediatR open-source libr\", \"ary (created by Jimmy Bogard), but you could use another approach. MediatR is a small and simple lib\", \"rary that allows you to process in-memory messages like a command, while applying decorators or beha\", \"viors.\\n\\nUsing the Mediator pattern helps you to reduce coupling and to isolate the concerns of the r\", \"equested work, while automatically connecting to the handler that performs that work -in this case, \", \"to command handlers.\\n\\nAnother good reason to use the Mediator pattern was explained by Jimmy Bogard \", \"when reviewing this guide:\\n\\nI think it might be worth mentioning testing here -it provides a nice co\", \"nsistent window into the behavior of your system. Request-in, responseout. We've found that aspect q\", \"uite valuable in building consistently behaving tests.\\n\\nFirst, let's look at a sample WebAPI control\", \"ler where you actually would use the mediator object. If you weren't using the mediator object, you'\", \"d need to inject all the dependencies for that controller, things like a logger object and others. T\", \"herefore, the constructor would be complicated. On the other hand, if you use the mediator object, t\", \"he constructor of your controller can be a lot simpler, with just a few dependencies instead of many\", \" dependencies if you had one per cross-cutting operation, as in the following example:\\n\\n```\\npublic c\", \"lass MyMicroserviceController : Controller { public MyMicroserviceController(IMediator mediator, IMy\", \"MicroserviceQueries microserviceQueries) { // ... } }\\n```\\n\\nYou can see that the mediator provides a \", \"clean and lean Web API controller constructor. In addition, within the controller methods, the code \", \"to send a command to the mediator object is almost one line:\\n\\n```\\n[Route(\\\"new\\\")] [HttpPost] public a\", \"sync Task<IActionResult> ExecuteBusinessOperation([FromBody]RunOpCommand runOperationCommand) { var \", \"commandResult = await _mediator.SendAsync(runOperationCommand); return commandResult ? (IActionResul\", \"t)Ok() : (IActionResult)BadRequest(); }\\n```\\n\\n## Implement idempotent Commands\\n\\nIn eShopOnContainers \", \", a more advanced example than the above is submitting a CreateOrderCommand object from the Ordering\", \" microservice. But since the Ordering business process is a bit more complex and, in our case, it ac\", \"tually starts in the Basket microservice, this action of submitting the CreateOrderCommand object is\", \" performed from an integration-event handler named UserCheckoutAcceptedIntegrationEventHandler inste\", \"ad of a simple WebAPI controller called from the client App as in the previous simpler example.\\n\\nNev\", \"ertheless, the action of submitting the Command to MediatR is pretty similar, as shown in the follow\", \"ing code.\\n\\n```\\nvar createOrderCommand = new CreateOrderCommand(eventMsg.Basket.Items, eventMsg.UserI\", \"d, eventMsg.City, eventMsg.Street, eventMsg.State, eventMsg.Country, eventMsg.ZipCode, eventMsg.Card\", \"Number, eventMsg.CardHolderName, eventMsg.CardExpiration, eventMsg.CardSecurityNumber, eventMsg.Card\", \"TypeId);\\n```\\n\\n```\\nvar requestCreateOrder = new IdentifiedCommand<CreateOrderCommand,bool>(createOrde\", \"rCommand, eventMsg.RequestId); result = await _mediator.Send(requestCreateOrder);\\n```\\n\\nHowever, this\", \" case is also slightly more advanced because we're also implementing idempotent commands. The Create\", \"OrderCommand process should be idempotent, so if the same message comes duplicated through the netwo\", \"rk, because of any reason, like retries, the same business order will be processed just once.\\n\\nThis \", \"is implemented by wrapping the business command (in this case CreateOrderCommand) and embedding it i\", \"nto a generic IdentifiedCommand, which is tracked by an ID of every message coming through the netwo\", \"rk that has to be idempotent.\\n\\nIn the code below, you can see that the IdentifiedCommand is nothing \", \"more than a DTO with and ID plus the wrapped business command object.\\n\\n```\\npublic class IdentifiedCo\", \"mmand<T, R> : IRequest<R> where T : IRequest<R> { public T Command { get ; } public Guid Id { get ; \", \"} public IdentifiedCommand(T command, Guid id) { Command = command; Id = id; } }\\n```\\n\\nThen the Comma\", \"ndHandler for the IdentifiedCommand named IdentifiedCommandHandler.cs will basically check if the ID\", \" coming as part of the message already exists in a table. If it already exists, that command won't b\", \"e processed again, so it behaves as an idempotent command. That infrastructure code is performed by \", \"the \\\\_requestManager.ExistAsync method call below.\\n\\n```\\n// IdentifiedCommandHandler.cs public class \", \"IdentifiedCommandHandler<T, R> : IRequestHandler<IdentifiedCommand<T, R>, R> where T : IRequest<R> {\", \" private readonly IMediator _mediator; private readonly IRequestManager _requestManager; private rea\", \"donly ILogger<IdentifiedCommandHandler<T, R>> _logger; public IdentifiedCommandHandler( IMediator me\", \"diator, IRequestManager requestManager, ILogger<IdentifiedCommandHandler<T, R>> logger) { _mediator \", \"= mediator; _requestManager = requestManager; _logger = logger ?? throw new System.ArgumentNullExcep\", \"tion(nameof(logger)); } /// <summary> /// Creates the result value to return if a previous request w\", \"as found /// </summary> /// <returns></returns>\\n```\\n\\n```\\nprotected virtual R CreateResultForDuplicat\", \"eRequest() { return default (R); } /// <summary> /// This method handles the command. It just ensure\", \"s that no other request exists with the same ID, and if this is the case /// just enqueues the origi\", \"nal inner command. /// </summary> /// <param name=\\\"message\\\" > IdentifiedCommand which contains both \", \"original command & request ID </param> /// <returns> Return value of inner command or default value \", \"if request same ID was found </returns> public async Task<R> Handle(IdentifiedCommand<T, R> message,\", \" CancellationToken cancellationToken) { var alreadyExists = await _requestManager.ExistAsync(message\", \".Id); if (alreadyExists) { return CreateResultForDuplicateRequest(); } else { await _requestManager.\", \"CreateRequestForCommandAsync<T>(message.Id); try { var command = message.Command; var commandName = \", \"command.GetGenericTypeName(); var idProperty = string.Empty; var commandId = string.Empty; switch (c\", \"ommand) { case CreateOrderCommand createOrderCommand: idProperty = nameof(createOrderCommand.UserId)\", \"; commandId = createOrderCommand.UserId; break ; case CancelOrderCommand cancelOrderCommand: idPrope\", \"rty = nameof(cancelOrderCommand.OrderNumber); commandId = $\\\"{cancelOrderCommand.OrderNumber}\\\"; break\", \" ; case ShipOrderCommand shipOrderCommand: idProperty = nameof(shipOrderCommand.OrderNumber); comman\", \"dId = $\\\"{shipOrderCommand.OrderNumber}\\\"; break ; default : idProperty = \\\"Id?\\\"; commandId = \\\"n/a\\\"; br\", \"eak ; } _logger.LogInformation( \\\"----- Sending command: {CommandName} - {IdProperty}: {CommandId} ({\", \"@Command})\\\", commandName, idProperty, commandId,\\n```\\n\\n```\\ncommand); // Send the embedded business co\", \"mmand to mediator so it runs its related CommandHandler var result = await _mediator.Send(command, c\", \"ancellationToken); _logger.LogInformation( \\\"----- Command result: {@Result} - {CommandName} - {IdPro\", \"perty}: {CommandId} ({@Command})\\\", result, commandName, idProperty, commandId, command); return resu\", \"lt; } catch { return default (R); } } } }\\n```\\n\\nSince the IdentifiedCommand acts like a business comm\", \"and's envelope, when the business command needs to be processed because it is not a repeated ID, the\", \"n it takes that inner business command and resubmits it to Mediator, as in the last part of the code\", \" shown above when running \\\\_mediator.Send(message.Command), from the IdentifiedCommandHandler.cs.\\n\\nW\", \"hen doing that, it will link and run the business command handler, in this case, the CreateOrderComm\", \"andHandler, which is running transactions against the Ordering database, as shown in the following c\", \"ode.\\n\\n```\\n// CreateOrderCommandHandler.cs public class CreateOrderCommandHandler : IRequestHandler<C\", \"reateOrderCommand, bool> { private readonly IOrderRepository _orderRepository; private readonly IIde\", \"ntityService _identityService; private readonly IMediator _mediator; private readonly IOrderingInteg\", \"rationEventService _orderingIntegrationEventService; private readonly ILogger<CreateOrderCommandHand\", \"ler> _logger; // Using DI to inject infrastructure persistence Repositories public CreateOrderComman\", \"dHandler(IMediator mediator, IOrderingIntegrationEventService orderingIntegrationEventService, IOrde\", \"rRepository orderRepository, IIdentityService identityService, ILogger<CreateOrderCommandHandler> lo\", \"gger) { _orderRepository = orderRepository ?? throw new ArgumentNullException(nameof(orderRepository\", \")); _identityService = identityService ?? throw new ArgumentNullException(nameof(identityService)); \", \"_mediator = mediator ?? throw new ArgumentNullException(nameof(mediator)); _orderingIntegrationEvent\", \"Service = orderingIntegrationEventService ?? throw new ArgumentNullException(nameof(orderingIntegrat\", \"ionEventService)); _logger = logger ?? throw new ArgumentNullException(nameof(logger));\\n```\\n\\n```\\n} p\", \"ublic async Task<bool> Handle(CreateOrderCommand message, CancellationToken cancellationToken) { // \", \"Add Integration event to clean the basket var orderStartedIntegrationEvent = new OrderStartedIntegra\", \"tionEvent(message.UserId); await _orderingIntegrationEventService.AddAndSaveEventAsync(orderStartedI\", \"ntegrationEvent); // Add/Update the Buyer AggregateRoot // DDD patterns comment: Add child entities \", \"and value-objects through the Order Aggregate-Root // methods and constructor so validations, invari\", \"ants and business logic // make sure that consistency is preserved across the whole aggregate var ad\", \"dress = new Address(message.Street, message.City, message.State, message.Country, message.ZipCode); \", \"var order = new Order(message.UserId, message.UserName, address, message.CardTypeId, message.CardNum\", \"ber, message.CardSecurityNumber, message.CardHolderName, message.CardExpiration); foreach (var item \", \"in message.OrderItems) { order.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice, item.D\", \"iscount, item.PictureUrl, item.Units); } _logger.LogInformation(\\\"----- Creating Order - Order: {@Ord\", \"er}\\\", order); _orderRepository.Add(order); return await _orderRepository.UnitOfWork .SaveEntitiesAsy\", \"nc(cancellationToken); } }\\n```\\n\\n## Register the types used by MediatR\\n\\nIn order for MediatR to be aw\", \"are of your command handler classes, you need to register the mediator classes and the command handl\", \"er classes in your IoC container. By default, MediatR uses Autofac as the IoC container, but you can\", \" also use the built-in ASP.NET Core IoC container or any other container supported by MediatR.\\n\\nThe \", \"following code shows how to register Mediator's types and commands when using Autofac modules.\\n\\n```\\n\", \"public class MediatorModule : Autofac.Module { protected override void Load(ContainerBuilder builder\", \") { builder.RegisterAssemblyTypes( typeof (IMediator).GetTypeInfo().Assembly) .AsImplementedInterfac\", \"es(); // Register all the Command classes (they implement IRequestHandler) // in assembly holding th\", \"e Commands builder.RegisterAssemblyTypes( typeof (CreateOrderCommand).GetTypeInfo().Assembly) .AsClo\", \"sedTypesOf( typeof (IRequestHandler<,>)); // Other types registration\\n```\\n\\n```\\n//... } }\\n```\\n\\nThis i\", \"s where 'the magic happens' with MediatR.\\n\\nAs each command handler implements the generic IRequestHa\", \"ndler&lt;T&gt; interface, when you register the assemblies using RegisteredAssemblyTypes method all \", \"the types marked as IRequestHandler also gets registered with their Commands. For example:\\n\\n```\\npubl\", \"ic class CreateOrderCommandHandler : IRequestHandler<CreateOrderCommand, bool> {\\n```\\n\\nThat is the co\", \"de that correlates commands with command handlers. The handler is just a simple class, but it inheri\", \"ts from RequestHandler&lt;T&gt;, where T is the command type, and MediatR makes sure it is invoked w\", \"ith the correct payload (the command).\\n\\n## Apply cross-cutting concerns when processing commands wit\", \"h the Behaviors in MediatR\\n\\nThere is one more thing: being able to apply cross-cutting concerns to t\", \"he mediator pipeline. You can also see at the end of the Autofac registration module code how it reg\", \"isters a behavior type, specifically, a custom LoggingBehavior class and a ValidatorBehavior class. \", \"But you could add other custom behaviors, too.\\n\\n```\\npublic class MediatorModule : Autofac.Module { p\", \"rotected override void Load(ContainerBuilder builder) { builder.RegisterAssemblyTypes( typeof (IMedi\", \"ator).GetTypeInfo().Assembly) .AsImplementedInterfaces(); // Register all the Command classes (they \", \"implement IRequestHandler) // in assembly holding the Commands builder.RegisterAssemblyTypes( typeof\", \" (CreateOrderCommand).GetTypeInfo().Assembly). AsClosedTypesOf( typeof (IRequestHandler<,>)); // Oth\", \"er types registration //... builder.RegisterGeneric( typeof (LoggingBehavior<,>)). As( typeof (IPipe\", \"lineBehavior<,>)); builder.RegisterGeneric( typeof (ValidatorBehavior<,>)). As( typeof (IPipelineBeh\", \"avior<,>)); } }\\n```\\n\\nThat LoggingBehavior class can be implemented as the following code, which logs\", \" information about the command handler being executed and whether it was successful or not.\\n\\n```\\npub\", \"lic class LoggingBehavior<TRequest, TResponse> : IPipelineBehavior<TRequest, TResponse> { private re\", \"adonly ILogger<LoggingBehavior<TRequest, TResponse>> _logger; public LoggingBehavior(ILogger<Logging\", \"Behavior<TRequest, TResponse>> logger) => _logger = logger;\\n```\\n\\n```\\npublic async Task<TResponse> Ha\", \"ndle(TRequest request, RequestHandlerDelegate<TResponse> next) { _logger.LogInformation($\\\"Handling {\", \"typeof(TRequest).Name}\\\"); var response = await next(); _logger.LogInformation($\\\"Handled {typeof(TRes\", \"ponse).Name}\\\"); return response; } }\\n```\\n\\nJust by implementing this behavior class and by registerin\", \"g it in the pipeline (in the MediatorModule above), all the commands processed through MediatR will \", \"be logging information about the execution.\\n\\nThe eShopOnContainers ordering microservice also applie\", \"s a second behavior for basic validations, the ValidatorBehavior class that relies on the FluentVali\", \"dation library, as shown in the following code:\\n\\n```\\npublic class ValidatorBehavior<TRequest, TRespo\", \"nse> : IPipelineBehavior<TRequest, TResponse> { private readonly IValidator<TRequest>[] _validators;\", \" public ValidatorBehavior(IValidator<TRequest>[] validators) => _validators = validators; public asy\", \"nc Task<TResponse> Handle(TRequest request, RequestHandlerDelegate<TResponse> next) { var failures =\", \" _validators .Select(v => v.Validate(request)) .SelectMany(result => result.Errors) .Where(error => \", \"error != null ) .ToList(); if (failures.Any()) { throw new OrderingDomainException( $\\\"Command Valida\", \"tion Errors for type {typeof(TRequest).Name}\\\", new ValidationException(\\\"Validation exception\\\", failu\", \"res)); } var response = await next(); return response; } }\\n```\\n\\nHere the behavior is raising an exce\", \"ption if validation fails, but you could also return a result object, containing the command result \", \"if it succeeded or the validation messages in case it didn't. This would probably make it easier to \", \"display validation results to the user.\\n\\nThen, based on the FluentValidation library, you would crea\", \"te validation for the data passed with CreateOrderCommand, as in the following code:\\n\\n```\\npublic cla\", \"ss CreateOrderCommandValidator : AbstractValidator<CreateOrderCommand> { public CreateOrderCommandVa\", \"lidator() { RuleFor(command => command.City).NotEmpty(); RuleFor(command => command.Street).NotEmpty\", \"();\\n```\\n\\n```\\nRuleFor(command => command.State).NotEmpty(); RuleFor(command => command.Country).NotEm\", \"pty(); RuleFor(command => command.ZipCode).NotEmpty(); RuleFor(command => command.CardNumber).NotEmp\", \"ty().Length(12, 19); RuleFor(command => command.CardHolderName).NotEmpty(); RuleFor(command => comma\", \"nd.CardExpiration).NotEmpty().Must(BeValidExpirationDate).WithMessage(\\\"Please specify a valid card e\", \"xpiration date\\\"); RuleFor(command => command.CardSecurityNumber).NotEmpty().Length(3); RuleFor(comma\", \"nd => command.CardTypeId).NotEmpty(); RuleFor(command => command.OrderItems).Must(ContainOrderItems)\", \".WithMessage(\\\"No order items found\\\"); } private bool BeValidExpirationDate(DateTime dateTime) { retu\", \"rn dateTime >= DateTime.UtcNow; } private bool ContainOrderItems(IEnumerable<OrderItemDTO> orderItem\", \"s) { return orderItems.Any(); } }\\n```\\n\\nYou could create additional validations. This is a very clean\", \" and elegant way to implement your command validations.\\n\\nIn a similar way, you could implement other\", \" behaviors for additional aspects or cross-cutting concerns that you want to apply to commands when \", \"handling them.\\n\\n## Additional resources\\n\\n## The mediator pattern\\n\\n- \\u2022\\n- Mediator pattern https://en.\", \"wikipedia.org/wiki/Mediator\\\\_pattern\\n\\n## The decorator pattern\\n\\n- \\u2022\\n- Decorator pattern https://en.w\", \"ikipedia.org/wiki/Decorator\\\\_pattern\\n\\n## MediatR (Jimmy Bogard)\\n\\n- MediatR.\\n- GitHub repo. https://g\", \"ithub.com/jbogard/MediatR\\n- CQRS with MediatR and AutoMapper\\n\\nhttps://lostechies.com/jimmybogard/201\", \"5/05/05/cqrs-with-mediatr-and-automapper/\\n\\n- \\u2022\\n- Put your controllers on a diet: POSTs and commands.\", \"\\n\\nhttps://lostechies.com/jimmybogard/2013/12/19/put-your-controllers-on-a-diet-posts-andcommands/\\n\\n-\", \" Tackling cross-cutting concerns with a mediator pipeline https://lostechies.com/jimmybogard/2014/09\", \"/09/tackling-cross-cutting-concerns-with-amediator-pipeline/\\n- CQRS and REST: the perfect match http\", \"s://lostechies.com/jimmybogard/2016/06/01/cqrs-and-rest-the-perfect-match/\\n- MediatR Pipeline Exampl\", \"es https://lostechies.com/jimmybogard/2016/10/13/mediatr-pipeline-examples/\\n- Vertical Slice Test Fi\", \"xtures for MediatR and ASP.NET Core https://lostechies.com/jimmybogard/2016/10/24/vertical-slice-tes\", \"t-fixtures-for-mediatr-andasp-net-core/\\n- MediatR Extensions for Microsoft Dependency Injection Rele\", \"ased https://lostechies.com/jimmybogard/2016/07/19/mediatr-extensions-for-microsoftdependency-inject\", \"ion-released/\\n\\n## Fluent validation\\n\\n- Jeremy Skinner. FluentValidation. GitHub repo. https://github\", \".com/JeremySkinner/FluentValidation\\n\\n## Implement resilient applications\\n\\nYour microservice and clou\", \"d-based applications must embrace the partial failures that will certainly occur eventually. You mus\", \"t design your application to be resilient to those partial failures.\\n\\nResiliency is the ability to r\", \"ecover from failures and continue to function. It isn't about avoiding failures but accepting the fa\", \"ct that failures will happen and responding to them in a way that avoids downtime or data loss. The \", \"goal of resiliency is to return the application to a fully functioning state after a failure.\\n\\nIt's \", \"challenging enough to design and deploy a microservices -based application. But you also need to kee\", \"p your application running in an environment where some sort of failure is certain. Therefore, your \", \"application should be resilient. It should be designed to cope with partial failures, like network o\", \"utages or nodes or VMs crashing in the cloud. Even microservices (containers) being moved to a diffe\", \"rent node within a cluster can cause intermittent short failures within the application.\\n\\nThe many i\", \"ndividual components of your application should also incorporate health monitoring features. By foll\", \"owing the guidelines in this chapter, you can create an application that can work smoothly in spite \", \"of transient downtime or the normal hiccups that occur in complex and cloud-based deployments.\\n\\n## I\", \"mportant\\n\\neShopOnContainer had been using the Polly library to implement resiliency using Typed Clie\", \"nts up until the release 3.0.0.\\n\\nStarting with release 3.0.0, the HTTP calls resiliency is implement\", \"ed using a Linkerd mesh, that handles retries in a transparent and configurable fashion, within a Ku\", \"bernetes cluster, without having to handle those concerns in the code.\\n\\nThe Polly library is still u\", \"sed to add resilience to database connections, specially while starting up the services.\\n\\n## Warning\", \"\\n\\nAll code samples and images in this section were valid before using Linkerd and are not updated to\", \" reflect the current actual code. So they make sense in the context of this section.\\n\\nMultiple\\n\\nCust\", \"omers\\n\\nBrowser\\n\\nSubmit Order page r - -\\n\\n| Backend\\n\\n## Handle partial failure\\n\\nASP.NET Core\\n\\nRunning\", \" as\\n\\nIn distributed systems like microservicesbased applications, there's an ever -present risk of p\", \"artial failure. For instance, a single microservice/container can fail or might not be available to \", \"respond for a short time, or a single VM or server can crash. Since clients and services are separat\", \"e processes, a service might not be able to respond in a timely way to a client's request. The servi\", \"ce might be overloaded and responding very slowly to requests or might simply not be accessible for \", \"a short time because of network issues. self hosted ad n Container\\n\\nFor example, consider the Order \", \"details page from the eShopOnContainers sample application. If the ordering microservice is unrespon\", \"sive when the user tries to submit an order, a bad implementation of the client process (the MVC web\", \" application) -for example, if the client code were to use synchronous RPCs with no timeout -would b\", \"lock threads indefinitely waiting for a response. Besides creating a bad user experience, every unre\", \"sponsive wait consumes or blocks a thread, and threads are extremely valuable in highly scalable app\", \"lications. If there are many blocked threads, eventually the application's runtime can run out of th\", \"reads. In that case, the application can become globally unresponsive instead of just partially unre\", \"sponsive, as shown in Figure 8-1.\\n\\nFigure 8-1. Partial failures because of dependencies that impact \", \"service thread availability\\n\\n<!-- image -->\\n\\nIn a large microservices-based application, any partial\", \" failure can be amplified, especially if most of the internal microservices interaction is based on \", \"synchronous HTTP calls (which is considered an antipattern). Think about a system that receives mill\", \"ions of incoming calls per day. If your system has a bad design that's based on long chains of synch\", \"ronous HTTP calls, these incoming calls might result in many more millions of outgoing calls (let's \", \"suppose a ratio of 1:4) to dozens of internal microservi ces as synchronous dependencies. This situa\", \"tion is shown in Figure 8-2, especially dependency #3, that starts a chain, calling dependency #4, w\", \"hich then calls #5.\\n\\nPartial failures\\n\\nRunning as\\n\\nContainer\\n\\nMultiple\\n\\nCustomers\\n\\nMultiple\\n\\nCustome\", \"rs\\n\\nBrowser\\n\\nBrowser\\n\\nSubmit Order page\\n\\nSubmit Order page\\n\\nMultiple distributed dependencies\\n\\nParti\", \"al Failure Amplified in Microservices\\n\\n- -\\n\\n| Backend / Orchestrator\\n\\n| Backend / Orchestrator\\n\\nWeb \", \"App\\n\\n<!-- image -->\\n\\nDependency\\n\\nDependency\\n\\nFigure 8-2. The impact of having an incorrect design fe\", \"aturing long chains of HTTP requests\\n\\nIntermittent failure is guaranteed in a distributed and cloud-\", \"based system, even if every dependency itself has excellent availability. It's a fact you need to co\", \"nsider.\\n\\nIf you do not design and implement techniques to ensure fault tolerance, even small downtim\", \"es can be amplified. As an example, 50 dependencies each with 99.99% of availability would result in\", \" several hours of downtime each month because of this ripple effect. When a microservice dependency \", \"fails while handling a high volume of requests, that failure can quickly saturate all available requ\", \"est threads in each service and crash the whole application.\\n\\nFigure 8-3. Partial failure amplified \", \"by microservices with long chains of synchronous HTTP calls\\n\\n<!-- image -->\\n\\nTo minimize this proble\", \"m, in the section Asynchronous microservice integration enforce microservice's autonomy, this guide \", \"encourages you to use asynchronous communication across the internal microservices.\\n\\nIn addition, it\", \"'s essential that you design your microservices and client applications to handle partial failures -\", \"that is, to build resilient microservices and client applications.\\n\\n## Strategies to handle partial \", \"failure\\n\\nTo deal with partial failures, use one of the strategies described here.\\n\\nUse asynchronous \", \"communication (for example, message-based communication) across internal microservices . It's highly\", \" advisable not to create long chains of synchronous HTTP calls across the internal microservices bec\", \"ause that incorrect design will eventually become the main cause of bad outages. On the contrary, ex\", \"cept for the front-end communications between the client applications and the first level of microse\", \"rvices or finegrained API Gateways, it's recommended to use only asynchronous (message-based) commun\", \"ication once past the initial request/response cycle, across the internal microservices. Eventual co\", \"nsistency and event-driven architectures will help to minimize ripple effects. These approaches enfo\", \"rce a higher level of microservice autonomy and therefore prevent against the problem noted here.\\n\\nU\", \"se retries with exponential backoff . This technique helps to avoid short and intermittent failures \", \"by performing call retries a certain number of times, in case the service was not available only for\", \" a short time. This might occur due to intermittent network issues or when a microservice/container \", \"is moved to a different node in a cluster. However, if these retries are not designed properly with \", \"circuit breakers, it can aggravate the ripple effects, ultimately even causing a Denial of Service (\", \"DoS).\\n\\nWork around network timeouts . In general, clients should be designed not to block indefinite\", \"ly and to always use timeouts when waiting for a response. Using timeouts ensures that resources are\", \" never tied up indefinitely.\\n\\nUse the Circuit Breaker pattern . In this approach, the client process\", \" tracks the number of failed requests. If the error rate exceeds a configured limit, a 'circuit brea\", \"ker' trips so that further attempts fail immediately. (If a large number of requests are failing, th\", \"at suggests the service is unavailable and that sending requests is pointless.) After a timeout peri\", \"od, the client should try again and, if the new requests are successful, close the circuit breaker.\\n\", \"\\nProvide fallbacks . In this approach, the client process performs fallback logic when a request fai\", \"ls, such as returning cached data or a default value. This is an approach suitable for queries, and \", \"is more complex for updates or commands.\\n\\nLimit the number of queued requests . Clients should also \", \"impose an upper bound on the number of outstanding requests that a client microservice can send to a\", \" particular service. If the limit has been reached, it's probably pointless to make additional reque\", \"sts, and those attempts should fai l immediately. In terms of implementation, the Polly Bulkhead Iso\", \"lation policy can be used to fulfill this requirement. This approach is essentially a parallelizatio\", \"n throttle with SemaphoreSlim as the implementation. It also permits a 'queue' outside the bulkhead.\", \" You can proactively shed excess load even before execution (for example, because capacity is deemed\", \" full). This makes its response to\\n\\ncertain failure scenarios faster than a circuit breaker would be\", \", since the circuit breaker waits for the failures. The BulkheadPolicy object in Polly exposes how f\", \"ull the bulkhead and queue are, and offers events on overflow so can also be used to drive automated\", \" horizontal scaling.\\n\\n## Additional resources\\n\\n- Resiliency patterns\\n\\nhttps://learn.microsoft.com/az\", \"ure/architecture/framework/resiliency/reliability-patterns\\n\\n- Adding Resilience and Optimizing Perfo\", \"rmance\\n\\nhttps://learn.microsoft.com/previous-versions/msp-n-p/jj591574(v=pandp.10)\\n\\n- Bulkhead. GitH\", \"ub repo. Implementation with Polly policy. https://github.com/App-vNext/Polly/wiki/Bulkhead\\n- Design\", \"ing resilient applications for Azure https://learn.microsoft.com/azure/architecture/framework/resili\", \"ency/app-design\\n- Transient fault handling https://learn.microsoft.com/azure/architecture/best-pract\", \"ices/transient-faults\\n\\n## Implement retries with exponential backoff\\n\\nRetries with exponential backo\", \"ff is a technique that retries an operation, with an exponentially increasing wait time, up to a max\", \"imum retry count has been reached (the exponential backoff). This technique embraces the fact that c\", \"loud resources might intermittently be unavailable for more than a few seconds for any reason. For e\", \"xample, an orchestrator might be moving a container to another node in a cluster for load balancing.\", \" During that time, some requests might fail. Another example could be a database like SQL Azure, whe\", \"re a database can be moved to another server for load balancing, causing the database to be unavaila\", \"ble for a few seconds.\\n\\nThere are many approaches to implement retries logic with exponential backof\", \"f.\\n\\n## Implement resilient Entity Framework Core SQL connections\\n\\nFor Azure SQL DB, Entity Framework\", \" (EF) Core already provides internal database connection resiliency and retry logic. But you need to\", \" enable the Entity Framework execution strategy for each DbContext connection if you want to have re\", \"silient EF Core connections.\\n\\nFor instance, the following code at the EF Core connection level enabl\", \"es resilient SQL connections that are retried if the connection fails.\\n\\n```\\n// Program.cs from any A\", \"SP.NET Core Web API // Other code ... builder.Services.AddDbContext<CatalogContext>(options => {\\n```\", \"\\n\\n```\\noptions.UseSqlServer(builder.Configuration[\\\"ConnectionString\\\"], sqlServerOptionsAction: sqlOpt\", \"ions => { sqlOptions.EnableRetryOnFailure( maxRetryCount: 10, maxRetryDelay: TimeSpan.FromSeconds(30\", \"), errorNumbersToAdd: null ); }); });\\n```\\n\\n## Execution strategies and explicit transactions using B\", \"eginTransaction and multiple DbContexts\\n\\nWhen retries are enabled in EF Core connections, each opera\", \"tion you perform using EF Core becomes its own retryable operation. Each query and each call to Save\", \"Changes will be retried as a unit if a transient failure occurs.\\n\\nHowever, if your code initiates a \", \"transaction using BeginTransaction, you're defining your own group of operations that need to be tre\", \"ated as a unit. Everything inside the transaction has to be rolled back if a failure occurs.\\n\\nIf you\", \" try to execute that transaction when using an EF execution strategy (retry policy) and you call Sav\", \"eChanges from multiple DbContexts, you'll get an exception like this one:\\n\\nSystem.InvalidOperationEx\", \"ception: The configured execution strategy\\n\\n'SqlServerRetryingExecutionStrategy' does not support us\", \"er initiated transactions. Use the execution strategy returned by 'DbContext.Database.CreateExecutio\", \"nStrategy()' to execute all the operations in the transaction as a retriable unit.\\n\\nThe solution is \", \"to manually invoke the EF execution strategy with a delegate representing everything that needs to b\", \"e executed. If a transient failure occurs, the execution strategy will invoke the delegate again. Fo\", \"r example, the following code shows how it's implemented in eShopOnContainers with two multiple DbCo\", \"ntexts (\\\\_catalogContext and the IntegrationEventLogContext) when updating a product and then saving\", \" the ProductPriceChangedIntegrationEvent object, which needs to use a different DbContext.\\n\\n```\\npubl\", \"ic async Task<IActionResult> UpdateProduct( [FromBody]CatalogItem productToUpdate) { // Other code .\", \".. var oldPrice = catalogItem.Price; var raiseProductPriceChangedEvent = oldPrice != productToUpdate\", \".Price; // Update current product catalogItem = productToUpdate; // Save product's data and publish \", \"integration event through the Event Bus // if price has changed if (raiseProductPriceChangedEvent) {\", \" //Create Integration Event to be published through the Event Bus var priceChangedEvent = new Produc\", \"tPriceChangedIntegrationEvent( catalogItem.Id, productToUpdate.Price, oldPrice);\\n```\\n\\n```\\n// Achievi\", \"ng atomicity between original Catalog database operation and the // IntegrationEventLog thanks to a \", \"local transaction await _catalogIntegrationEventService.SaveEventAndCatalogContextChangesAsync( pric\", \"eChangedEvent); // Publish through the Event Bus and mark the saved event as published await _catalo\", \"gIntegrationEventService.PublishThroughEventBusAsync( priceChangedEvent); } // Just save the updated\", \" product because the Product's Price hasn't changed. else { await _catalogContext.SaveChangesAsync()\", \"; } }\\n```\\n\\nThe first DbContext is \\\\_catalogContext and the second DbContext is within the \\\\_catalogI\", \"ntegrationEventService object. The Commit action is performed across all DbContext objects using an \", \"EF execution strategy.\\n\\nTo achieve this multiple DbContext commit, the SaveEventAndCatalogContextCha\", \"ngesAsync uses a ResilientTransaction class, as shown in the following code:\\n\\n```\\npublic class Catal\", \"ogIntegrationEventService : ICatalogIntegrationEventService { //\\u2026 public async Task SaveEventAndCata\", \"logContextChangesAsync( IntegrationEvent evt) { // Use of an EF Core resiliency strategy when using \", \"multiple DbContexts // within an explicit BeginTransaction(): // https://learn.microsoft.com/ef/core\", \"/miscellaneous/connection-resiliency await ResilientTransaction.New(_catalogContext).ExecuteAsync(as\", \"ync () => { // Achieving atomicity between original catalog database // operation and the Integratio\", \"nEventLog thanks to a local transaction await _catalogContext.SaveChangesAsync(); await _eventLogSer\", \"vice.SaveEventAsync(evt, _catalogContext.Database.CurrentTransaction.GetDbTransaction()); }); } }\\n``\", \"`\\n\\nThe ResilientTransaction.ExecuteAsync method basically begins a transaction from the passed DbCon\", \"text (\\\\_catalogContext) and then makes the EventLogService use that transaction to save changes from\", \" the IntegrationEventLogContext and then commits the whole transaction.\\n\\n```\\npublic class ResilientT\", \"ransaction { private DbContext _context; private ResilientTransaction(DbContext context) => _context\", \" = context ?? throw new ArgumentNullException(nameof(context)); public static ResilientTransaction N\", \"ew (DbContext context) => new ResilientTransaction(context); public async Task ExecuteAsync(Func<Tas\", \"k> action) {\\n```\\n\\n```\\n// Use of an EF Core resiliency strategy when using multiple DbContexts // wit\", \"hin an explicit BeginTransaction(): // https://learn.microsoft.com/ef/core/miscellaneous/connection-\", \"resiliency var strategy = _context.Database.CreateExecutionStrategy(); await strategy.ExecuteAsync(a\", \"sync () => { await using var transaction = await _context.Database.BeginTransactionAsync(); await ac\", \"tion(); await transaction.CommitAsync(); }); } }\\n```\\n\\n## Additional resources\\n\\n- Connection Resilien\", \"cy and Command Interception with EF in an ASP.NET MVC Application\\n\\nhttps://learn.microsoft.com/aspne\", \"t/mvc/overview/getting-started/getting-started-with-efusing-mvc/connection-resiliency-and-command-in\", \"terception-with-the-entity-framework-inan-asp-net-mvc-application\\n\\n- Cesar de la Torre. Using Resili\", \"ent Entity Framework Core SQL Connections and Transactions\\n\\nhttps://devblogs.microsoft.com/cesardela\", \"torre/using-resilient-entity-framework-core-sqlconnections-and-transactions-retries-with-exponential\", \"-backoff/\\n\\n## Use IHttpClientFactory to implement resilient HTTP requests\\n\\nIHttpClientFactory is a c\", \"ontract implemented by DefaultHttpClientFactory, an opinionated factory, available since .NET Core 2\", \".1, for creating HttpClient instances to be used in your applications.\\n\\n## Issues with the original \", \"HttpClient class available in .NET\\n\\nThe original and well-known HttpClient class can be easily used,\", \" but in some cases, it isn't being properly used by many developers.\\n\\nThough this class implements I\", \"Disposable, declaring and instantiating it within a using statement is not preferred because when th\", \"e HttpClient object gets disposed of, the underlying socket is not immediately released, which can l\", \"ead to a socket exhaustion problem. For more information about this issue, see the blog post You're \", \"using HttpClient wrong and it's destabilizing your software .\\n\\nTherefore, HttpClient is intended to \", \"be instantiated once and reused throughout the life of an application. Instantiating an HttpClient c\", \"lass for every request will exhaust the number of sockets available under heavy loads. That issue wi\", \"ll result in SocketException errors. Possible approaches to solve that problem are based on the crea\", \"tion of the HttpClient object as singleton or static, as explained in this Microsoft article on Http\", \"Client usage. This can be a good solution for short-lived console apps or similar, that run a few ti\", \"mes a day.\\n\\nAnother issue that developers run into is when using a shared instance of HttpClient in \", \"long-running processes. In a situation where the HttpClient is instantiated as a singleton or a stat\", \"ic object, it fails to handle the DNS changes as described in this issue of the dotnet/runtime GitHu\", \"b repository.\\n\\nHowever, the issue isn't really with HttpClient per se, but with the default construc\", \"tor for HttpClient, because it creates a new concrete instance of HttpMessageHandler, which is the o\", \"ne that has sockets exhaustion and DNS changes issues mentioned above.\\n\\nTo address the issues mentio\", \"ned above and to make HttpClient instances manageable, .NET Core 2.1 introduced two approaches, one \", \"of them being IHttpClientFactory . It's an interface that's used to configure and create HttpClient \", \"instances in an app through Dependency Injection (DI). It also provides extensions for Polly-based m\", \"iddleware to take advantage of delegating handlers in HttpClient.\\n\\nThe alternative is to use Sockets\", \"HttpHandler with configured PooledConnectionLifetime. This approach is applied to long-lived, static\", \" or singleton HttpClient instances. To learn more about different strategies, see HttpClient guideli\", \"nes for .NET.\\n\\nPolly is a transient-fault-handling library that helps developers add resiliency to t\", \"heir applications, by using some pre-defined policies in a fluent and thread-safe manner.\\n\\n## Benefi\", \"ts of using IHttpClientFactory\\n\\nThe current implementation of IHttpClientFactory, that also implemen\", \"ts IHttpMessageHandlerFactory, offers the following benefits:\\n\\n- Provides a central location for nam\", \"ing and configuring logical HttpClient objects. For example, you may configure a client (Service Age\", \"nt) that's pre -configured to access a specific microservice.\\n- Codify the concept of outgoing middl\", \"eware via delegating handlers in HttpClient and implementing Pollybased middleware to take advantage\", \" of Polly's policies for resiliency.\\n- HttpClient already has the concept of delegating handlers tha\", \"t could be linked together for outgoing HTTP requests. You can register HTTP clients into the factor\", \"y and you can use a Polly handler to use Polly policies for Retry, CircuitBreakers, and so on.\\n- Man\", \"age the lifetime of HttpMessageHandler to avoid the mentioned problems/issues that can occur when ma\", \"naging HttpClient lifetimes yourself.\\n\\n## Tip\\n\\nThe HttpClient instances injected by DI can be dispos\", \"ed of safely, because the associated HttpMessageHandler is managed by the factory. Injected HttpClie\", \"nt instances are Transient from a DI perspective, while HttpMessageHandler instances can be regarded\", \" as Scoped . HttpMessageHandler instances have their own DI scopes, separate from the application sc\", \"opes (for example, ASP.NET incoming request scopes). For more information, see Using HttpClientFacto\", \"ry in .NET.\\n\\n## Note\\n\\nThe implementation of IHttpClientFactory (DefaultHttpClientFactory) is tightly\", \" tied to the DI implementation in the Microsoft.Extensions.DependencyInjection NuGet package. If you\", \" need to use HttpClient without DI or with other DI implementations, consider using a static or sing\", \"leton HttpClient with PooledConnectionLifetime set up. For more information, see HttpClient guidelin\", \"es for .NET.\\n\\n## Multiple ways to use IHttpClientFactory\\n\\nThere are several ways that you can use IH\", \"ttpClientFactory in your application:\\n\\n- Basic usage\\n- Use Named Clients\\n- Use Typed Clients\\n- Use G\", \"enerated Clients\\n\\nFor the sake of brevity, this guidance shows the most structured way to use IHttpC\", \"lientFactory, which is to use Typed Clients (Service Agent pattern). However, all options are docume\", \"nted and are currently listed in this article covering the IHttpClientFactory usage.\\n\\n## Note\\n\\nIf yo\", \"ur app requires cookies, it might be better to avoid using IHttpClientFactory in your app. For alter\", \"native ways of managing clients, see Guidelines for using HTTP clients\\n\\n## How to use Typed Clients \", \"with IHttpClientFactory\\n\\nSo, what's a 'Typed Client'? It's just an HttpClient that's pre -configured\", \" for some specific use. This configuration can include specific values such as the base server, HTTP\", \" headers or time outs.\\n\\nThe following diagram shows how Typed Clients are used with IHttpClientFacto\", \"ry:\\n\\nClient application/code\\n\\nDependency Injection\\n\\nU\\n\\nController or client cod\\n\\nFigure 8-4. Using I\", \"HttpClientFactory with Typed Client classes.\\n\\n<!-- image -->\\n\\nIn the above image, a ClientService (u\", \"sed by a controller or client code) uses an HttpClient created by the registered IHttpClientFactory.\", \" This factory assigns an HttpMessageHandler from a pool to the HttpClient. The HttpClient can be con\", \"figured with Polly 's policies when registering the IHttpClientFactory in the DI container with the \", \"extension method AddHttpClient.\\n\\nTo configure the above structure, add IHttpClientFactory in your ap\", \"plication by installing the Microsoft.Extensions.Http NuGet package that includes the AddHttpClient \", \"extension method for IServiceCollection. This extension method registers the internal DefaultHttpCli\", \"entFactory class to be used as a singleton for the interface IHttpClientFactory. It defines a transi\", \"ent configuration for the HttpMessageHandlerBuilder. This message handler (HttpMessageHandler object\", \"), taken from a pool, is used by the HttpClient returned from the factory.\\n\\nIn the next snippet, you\", \" can see how AddHttpClient() can be used to register Typed Clients (Service Agents) that need to use\", \" HttpClient.\\n\\n```\\n// Program.cs //Add http client services at ConfigureServices(IServiceCollection s\", \"ervices) builder.Services.AddHttpClient<ICatalogService, CatalogService>(); builder.Services.AddHttp\", \"Client<IBasketService, BasketService>(); builder.Services.AddHttpClient<IOrderingService, OrderingSe\", \"rvice>();\\n```\\n\\nRegistering the client services as shown in the previous snippet, makes the DefaultCl\", \"ientFactory create a standard HttpClient for each service. The typed client is registered as transie\", \"nt with DI container. In the preceding code, AddHttpClient() registers CatalogService , BasketServic\", \"e , OrderingService as transient services so they can be injected and consumed directly without any \", \"need for additional registrations.\\n\\nYou could also add instance-specific configuration in the regist\", \"ration to, for example, configure the base address, and add some resiliency policies, as shown in th\", \"e following:\\n\\n```\\nbuilder.Services.AddHttpClient<ICatalogService, CatalogService>(client => { client\", \".BaseAddress = new Uri(builder.Configuration[\\\"BaseUrl\\\"]); }) .AddPolicyHandler(GetRetryPolicy()) .Ad\", \"dPolicyHandler(GetCircuitBreakerPolicy());\\n```\\n\\nIn this next example, you can see the configuration \", \"of one of the above policies:\\n\\n```\\nstatic IAsyncPolicy<HttpResponseMessage> GetRetryPolicy() { retur\", \"n HttpPolicyExtensions .HandleTransientHttpError() .OrResult(msg => msg.StatusCode == System.Net.Htt\", \"pStatusCode.NotFound) .WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAt\", \"tempt))); }\\n```\\n\\nYou can find more details about using Polly in the Next article.\\n\\n## HttpClient lif\", \"etimes\\n\\nEach time you get an HttpClient object from the IHttpClientFactory, a new instance is return\", \"ed. But each HttpClient uses an HttpMessageHandler that's pooled and reused by the IHttpClientFactor\", \"y to reduce resource consumption, as long as the HttpMessageHand ler's lifetime hasn't expired.\\n\\nPoo\", \"ling of handlers is desirable as each handler typically manages its own underlying HTTP connections;\", \" creating more handlers than necessary can result in connection delays. Some handlers also keep conn\", \"ections open indefinitely, which can prevent the handler from reacting to DNS changes.\\n\\nThe HttpMess\", \"ageHandler objects in the pool have a lifetime that's the length of time that an HttpMessageHandler \", \"instance in the pool can be reused. The default value is two minutes, but it can be overridden per T\", \"yped Client. To override it, call SetHandlerLifetime() on the IHttpClientBuilder that's returned whe\", \"n creating the client, as shown in the following code:\\n\\n```\\n//Set 5 min as the lifetime for the Http\", \"MessageHandler objects in the pool used for the Catalog Typed Client builder.Services.AddHttpClient<\", \"ICatalogService, CatalogService>() .SetHandlerLifetime(TimeSpan.FromMinutes(5));\\n```\\n\\nEach Typed Cli\", \"ent can have its own configured handler lifetime value. Set the lifetime to InfiniteTimeSpan to disa\", \"ble handler expiry.\\n\\n## Implement your Typed Client classes that use the injected and configured Htt\", \"pClient\\n\\nAs a previous step, you need to have your Typed Client classes defined, such as the classes\", \" in the sample code, like 'BasketService', 'CatalogService', 'OrderingService', etc. A Typed Client \", \"is a class that accepts an HttpClient object (injected through its constructor) and uses it to call \", \"some remote HTTP service. For example:\\n\\n```\\npublic class CatalogService : ICatalogService { private \", \"readonly HttpClient _httpClient; private readonly string _remoteServiceBaseUrl; public CatalogServic\", \"e(HttpClient httpClient) { _httpClient = httpClient; } public async Task<Catalog> GetCatalogItems(in\", \"t page, int take, int? brand, int? type) { var uri = API.Catalog.GetAllCatalogItems(_remoteServiceBa\", \"seUrl, page, take, brand, type); var responseString = await _httpClient.GetStringAsync(uri); var cat\", \"alog = JsonConvert.DeserializeObject<Catalog>(responseString); return catalog; } }\\n```\\n\\nThe Typed Cl\", \"ient (CatalogService in the example) is activated by DI (Dependency Injection), which means it can a\", \"ccept any registered service in its constructor, in addition to HttpClient.\\n\\nA Typed Client is effec\", \"tively a transient object, that means a new instance is created each time one is needed. It receives\", \" a new HttpClient instance each time it's constructed. However, the HttpMessageHandler objects in th\", \"e pool are the objects that are reused by multiple HttpClient instances.\\n\\n## Use your Typed Client c\", \"lasses\\n\\nFinally, once you have your typed classes implemented, you can have them registered and conf\", \"igured with AddHttpClient(). After that you can use them wherever services are injected by DI, such \", \"as in Razor page code or an MVC web app controller, shown in the below code from eShopOnContainers:\\n\", \"\\n```\\nnamespace Microsoft.eShopOnContainers.WebMVC.Controllers { public class CatalogController : Con\", \"troller { private ICatalogService _catalogSvc; public CatalogController(ICatalogService catalogSvc) \", \"=> _catalogSvc = catalogSvc; public async Task<IActionResult> Index(int? BrandFilterApplied, int? Ty\", \"pesFilterApplied,\\n```\\n\\n```\\nint? page, [FromQuery]string errorMsg) { var itemsPage = 10; var catalog \", \"= await _catalogSvc.GetCatalogItems(page ?? 0, itemsPage, BrandFilterApplied, TypesFilterApplied); /\", \"/\\u2026 Additional code } } }\\n```\\n\\nUp to this point, the above code snippet only shows the example of per\", \"forming regular HTTP requests. But the 'magic' comes in the following sections where it shows how al\", \"l the HTTP requests made by HttpClient can have resilient policies such as retries with exponential \", \"backoff, circuit breakers, security features using auth tokens, or even any other custom feature. An\", \"d all of these can be done just by adding policies and delegating handlers to your registered Typed \", \"Clients.\\n\\n## Additional resources\\n\\n- HttpClient guidelines for .NET\\n- https://learn.microsoft.com/en\", \"-us/dotnet/fundamentals/networking/http/httpclientguidelines\\n- Using HttpClientFactory in .NET\\n\\nhttp\", \"s://learn.microsoft.com/en-us/dotnet/core/extensions/httpclient-factory\\n\\n- Using HttpClientFactory i\", \"n ASP.NET Core\\n\\nhttps://learn.microsoft.com/aspnet/core/fundamentals/http-requests\\n\\n- HttpClientFact\", \"ory source code in the dotnet/runtime GitHub repository https://github.com/dotnet/runtime/tree/relea\", \"se/7.0/src/libraries/Microsoft.Extensions.Http/\\n- Polly (.NET resilience and transient-fault-handlin\", \"g library)\\n- https://thepollyproject.azurewebsites.net/\\n\\n## Implement HTTP call retries with exponen\", \"tial backoff with IHttpClientFactory and Polly policies\\n\\nThe recommended approach for retries with e\", \"xponential backoff is to take advantage of more advanced .NET libraries like the open-source Polly l\", \"ibrary.\\n\\nPolly is a .NET library that provides resilience and transient-fault handling capabilities.\", \" You can implement those capabilities by applying Polly policies such as Retry, Circuit Breaker, Bul\", \"khead Isolation, Timeout, and Fallback. Polly targets .NET Framework 4.x and .NET Standard 1.0, 1.1,\", \" and 2.0 (which supports .NET Core and later).\\n\\nThe following steps show how you can use Http retrie\", \"s with Polly integrated into IHttpClientFactory, which is explained in the previous section.\\n\\n## Ins\", \"tall .NET packages\\n\\nFirst, you will need to install the Microsoft.Extensions.Http.Polly package.\\n\\n- \", \"Install with Visual Studio\\n- Install with dotnet CLI\\n- Install with nuget.exe CLI\\n- Install with Pac\", \"kage Manager Console (PowerShell)\\n\\n## Reference the .NET 7 packages\\n\\nIHttpClientFactory is available\", \" since .NET Core 2.1, however, we recommend you use the latest .NET 7 packages from NuGet in your pr\", \"oject. You typically also need to reference the extension package Microsoft.Extensions.Http.Polly.\\n\\n\", \"## Configure a client with Polly's Retry policy, in app startup\\n\\nThe AddPolicyHandler() method is wh\", \"at adds policies to the HttpClient objects you'll use. In this case, it's adding a Polly's policy fo\", \"r Http Retries with exponential backoff.\\n\\nTo have a more modular approach, the Http Retry Policy can\", \" be defined in a separate method within the Program.cs file, as shown in the following code:\\n\\n```\\nst\", \"atic IAsyncPolicy<HttpResponseMessage> GetRetryPolicy() { return HttpPolicyExtensions .HandleTransie\", \"ntHttpError() .OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound) .WaitAndRetryAs\", \"ync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt))); }\\n```\\n\\nAs shown in previous\", \" sections, you need to define a named or typed client HttpClient configuration in your standard Prog\", \"ram.cs app configuration. Now you add incremental code specifying the policy for the Http retries wi\", \"th exponential backoff, as follows:\\n\\n```\\n// Program.cs builder.Services.AddHttpClient<IBasketService\", \", BasketService>() .SetHandlerLifetime(TimeSpan.FromMinutes(5))  //Set lifetime to five minutes .Add\", \"PolicyHandler(GetRetryPolicy());\\n```\\n\\nWith Polly, you can define a Retry policy with the number of r\", \"etries, the exponential backoff configuration, and the actions to take when there's an HTTP exceptio\", \"n, such as logging the error. In this case, the policy is configured to try six times with an expone\", \"ntial retry, starting at two seconds.\\n\\n## Add a jitter strategy to the retry policy\\n\\nA regular Retry\", \" policy can affect your system in cases of high concurrency and scalability and under high contentio\", \"n. To overcome peaks of similar retries coming from many clients in partial outages, a good workarou\", \"nd is to add a jitter strategy to the retry algorithm/policy. This strategy can improve the overall \", \"performance of the end-to-end system. As recommended in Polly: Retry with Jitter, a good\\n\\njitter str\", \"ategy can be implemented by smooth and evenly distributed retry intervals applied with a well-contro\", \"lled median initial retry delay on an exponential backoff. This approach helps to spread out the spi\", \"kes when the issue arises. The principle is illustrated by the following example:\\n\\n```\\nvar delay = B\", \"ackoff.DecorrelatedJitterBackoffV2(medianFirstRetryDelay: TimeSpan.FromSeconds(1), retryCount: 5); v\", \"ar retryPolicy = Policy .Handle<FooException>() .WaitAndRetryAsync(delay);\\n```\\n\\n## Additional resour\", \"ces\\n\\n- Retry pattern https://learn.microsoft.com/azure/architecture/patterns/retry\\n- Polly and IHttp\", \"ClientFactory https://github.com/App-vNext/Polly/wiki/Polly-andHttpClientFactory\\n- Polly (.NET resil\", \"ience and transient-fault-handling library) https://github.com/AppvNext/Polly\\n- Polly: Retry with Ji\", \"tter https://github.com/App-vNext/Polly/wiki/Retry-with-jitter\\n- Marc Brooker. Jitter: Making Things\", \" Better With Randomness https://brooker.co.za/blog/2015/03/21/backoff.html\\n\\n## Implement the Circuit\", \" Breaker pattern\\n\\nAs noted earlier, you should handle faults that might take a variable amount of ti\", \"me to recover from, as might happen when you try to connect to a remote service or resource. Handlin\", \"g this type of fault can improve the stability and resiliency of an application.\\n\\nIn a distributed e\", \"nvironment, calls to remote resources and services can fail due to transient faults, such as slow ne\", \"twork connections and timeouts, or if resources are responding slowly or are temporarily unavailable\", \". These faults typically correct themselves after a short time, and a robust cloud application shoul\", \"d be prepared to handle them by using a strategy like the 'Retry pattern'.\\n\\nHowever, there can also \", \"be situations where faults are due to unanticipated events that might take much longer to fix. These\", \" faults can range in severity from a partial loss of connectivity to the complete failure of a servi\", \"ce. In these situations, it might be pointless for an application to continually retry an operation \", \"that's unlikely to succeed.\\n\\nInstead, the application should be coded to accept that the operation h\", \"as failed and handle the failure accordingly.\\n\\nUsing Http retries carelessly could result in creatin\", \"g a Denial of Service (DoS) attack within your own software. As a microservice fails or performs slo\", \"wly, multiple clients might repeatedly retry failed requests. That creates a dangerous risk of expon\", \"entially increasing traffic targeted at the failing service.\\n\\nTherefore, you need some kind of defen\", \"se barrier so that excessive requests stop when it isn't worth to keep trying. That defense barrier \", \"is precisely the circuit breaker.\\n\\nThe Circuit Breaker pattern has a different purpose than the 'Ret\", \"ry pattern'. The 'Retry pattern' enables an application to retry an operation in the expectation tha\", \"t the operation will eventually succeed. The Circuit Breaker pattern prevents an applicatio n from p\", \"erforming an operation that's likely to fail. An application can combine these two patterns. However\", \", the retry logic should be sensitive to any exception returned by the circuit breaker, and it shoul\", \"d abandon retry attempts if the circuit breaker indicates that a fault is not transient.\\n\\n## Impleme\", \"nt Circuit Breaker pattern with IHttpClientFactory and Polly\\n\\nAs when implementing retries, the reco\", \"mmended approach for circuit breakers is to take advantage of proven .NET libraries like Polly and i\", \"ts native integration with IHttpClientFactory.\\n\\nAdding a circuit breaker policy into your IHttpClien\", \"tFactory outgoing middleware pipeline is as simple as adding a single incremental piece of code to w\", \"hat you already have when using IHttpClientFactory.\\n\\nThe only addition here to the code used for HTT\", \"P call retries is the code where you add the Circuit Breaker policy to the list of policies to use, \", \"as shown in the following incremental code.\\n\\n```\\n// Program.cs var retryPolicy = GetRetryPolicy(); v\", \"ar circuitBreakerPolicy = GetCircuitBreakerPolicy(); builder.Services.AddHttpClient<IBasketService, \", \"BasketService>() .SetHandlerLifetime(TimeSpan.FromMinutes(5))  // Sample: default lifetime is 2 minu\", \"tes .AddHttpMessageHandler<HttpClientAuthorizationDelegatingHandler>() .AddPolicyHandler(retryPolicy\", \") .AddPolicyHandler(circuitBreakerPolicy);\\n```\\n\\nThe AddPolicyHandler() method is what adds policies \", \"to the HttpClient objects you'll use. In this case, it's adding a Polly policy for a circuit breaker\", \".\\n\\nTo have a more modular approach, the Circuit Breaker Policy is defined in a separate method calle\", \"d GetCircuitBreakerPolicy(), as shown in the following code:\\n\\n```\\n// also in Program.cs static IAsyn\", \"cPolicy<HttpResponseMessage> GetCircuitBreakerPolicy() { return HttpPolicyExtensions .HandleTransien\", \"tHttpError() .CircuitBreakerAsync(5, TimeSpan.FromSeconds(30)); }\\n```\\n\\nIn the code example above, th\", \"e circuit breaker policy is configured so it breaks or opens the circuit when there have been five c\", \"onsecutive faults when retrying the Http requests. When that happens, the circuit will break for 30 \", \"seconds: in that period, calls will be failed immediately by the circuitbreaker rather than actually\", \" be placed. The policy automatically interprets relevant exceptions and HTTP status codes as faults.\", \"\\n\\nCircuit breakers should also be used to redirect requests to a fallback infrastructure if you had \", \"issues in a particular resource that's deployed in a different environment than the client applicati\", \"on or\\n\\nservice that's performing the HTTP call. That way, if there's an outage in the datacenter tha\", \"t impacts only your backend microservices but not your client applications, the client applications \", \"can redirect to the fallback services. Polly is planning a new policy to automate this failover poli\", \"cy scenario.\\n\\nAll those features are for cases where you're managing the failover from within the .N\", \"ET code, as opposed to having it managed automatically for you by Azure, with location transparency.\", \"\\n\\nFrom a usage point of view, when using HttpClient, there's no need to add anything new here becaus\", \"e the code is the same than when using HttpClient with IHttpClientFactory, as shown in previous sect\", \"ions.\\n\\n## Test Http retries and circuit breakers in eShopOnContainers\\n\\nWhenever you start the eShopO\", \"nContainers solution in a Docker host, it needs to start multiple containers. Some of the containers\", \" are slower to start and initialize, like the SQL Server container. This is especially true the firs\", \"t time you deploy the eShopOnContainers application into Docker because it needs to set up the image\", \"s and the database. The fact that some containers start slower than others can cause the rest of the\", \" services to initially throw HTTP exceptions, even if you set dependencies between containers at the\", \" docker-compose level, as explained in previous sections. Those dockercompose dependencies between c\", \"ontainers are just at the process level. The container's entry point process might be started, but S\", \"QL Server might not be ready for queries. The result can be a cascade of errors, and the application\", \" can get an exception when trying to consume that particular container.\\n\\nYou might also see this typ\", \"e of error on startup when the application is deploying to the cloud. In that case, orchestrators mi\", \"ght be moving containers from one node or VM to another (that is, starting new instances) when balan\", \"cing the number of containers across the cluster's nodes.\\n\\nThe way 'eShopOnContainers' solves those \", \"issues when starting all the containers is by using the Retry pattern illustrated earlier.\\n\\n## Test \", \"the circuit breaker in eShopOnContainers\\n\\nThere are a few ways you can break/open the circuit and te\", \"st it with eShopOnContainers.\\n\\nOne option is to lower the allowed number of retries to 1 in the circ\", \"uit breaker policy and redeploy the whole solution into Docker. With a single retry, there's a good \", \"chance that an HTTP request will fail during deployment, the circuit breaker will open, and you get \", \"an error.\\n\\nAnother option is to use custom middleware that's implemented in the Basket microservice.\", \" When this middleware is enabled, it catches all HTTP requests and returns status code 500. You can \", \"enable the middleware by making a GET request to the failing URI, like the following:\\n\\n- GET http://\", \"localhost:5103/failing This request returns the current state of the middleware. If the middleware i\", \"s enabled, the request return status code 500. If the middleware is disabled, there's no response.\\n-\", \" GET http://localhost:5103/failing?enable This request enables the middleware.\\n\\n- GET http://localho\", \"st:5103/failing?disable This request disables the middleware.\\n\\nFor instance, once the application is\", \" running, you can enable the middleware by making a request using the following URI in any browser. \", \"Note that the ordering microservice uses port 5103.\\n\\nhttp://localhost:5103/failing?enable\\n\\nYou can t\", \"hen check the status using the URI http://localhost:5103/failing, as shown in Figure 8-5.\\n\\nFigure 8-\", \"5 . Checking the state of the 'Failing' ASP.NET middleware In this case, disabled.\\n\\n<!-- image -->\\n\\n\", \"At this point, the Basket microservice responds with status code 500 whenever you call invoke it.\\n\\nO\", \"nce the middleware is running, you can try making an order from the MVC web application. Because the\", \" requests fail, the circuit will open.\\n\\nIn the following example, you can see that the MVC web appli\", \"cation has a catch block in the logic for placing an order. If the code catches an open-circuit exce\", \"ption, it shows the user a friendly message telling them to wait.\\n\\n```\\npublic class CartController :\", \" Controller { //\\u2026 public async Task<IActionResult> Index() { try { var user = _appUserParser.Parse(H\", \"ttpContext.User); //Http requests using the Typed Client (Service Agent) var vm = await _basketSvc.G\", \"etBasket(user); return View(vm); } catch (BrokenCircuitException) { // Catches error when Basket.api\", \" is in circuit-opened mode HandleBrokenCircuitException(); } return View(); } private void HandleBro\", \"kenCircuitException() { TempData[\\\"BasketInoperativeMsg\\\"] = \\\"Basket Service is inoperative, please tr\", \"y later on. (Business message due to Circuit-Breaker)\\\"; } }\\n```\\n\\nHere's a summary. The Retry policy \", \"tries several times to make the HTTP request and gets HTTP errors. When the number of retries reache\", \"s the maximum number set for the Circuit Breaker policy (in this case, 5), the application throws a \", \"BrokenCircuitException. The result is a friendly message, as shown in Figure 8-6.\\n\\nMy Cart - Microso\", \"ft.eSh X\\n\\n+ v\\n\\n\\u2022 localhost:5100/Cart\\n\\ne\\n\\neSHOP\\n\\nonCONTAINERS\\n\\nBACK TO CATALOG\\n\\nBasket Service is ino\", \"perative, please try later on. (Business Msg Due to Circuit-Breaker)\\n\\n\\u2022 *\\n\\ndemouser@microsoft.com sa\", \"\\n\\nFigure 8-6. Circuit breaker returning an error to the UI\\n\\n<!-- image -->\\n\\nYou can implement differ\", \"ent logic for when to open/break the circuit. Or you can try an HTTP request against a different bac\", \"k-end microservice if there's a fallback datacenter or redundant back -end system.\\n\\nFinally, another\", \" possibility for the CircuitBreakerPolicy is to use Isolate (which forces open and holds open the ci\", \"rcuit) and Reset (which closes it again). These could be used to build a utility HTTP endpoint that \", \"invokes Isolate and Reset directly on the policy. Such an HTTP endpoint could also be used, suitably\", \" secured, in production for temporarily isolating a downstream system, such as when you want to upgr\", \"ade it. Or it could trip the circuit manually to protect a downstream system you suspect to be fault\", \"ing.\\n\\n## Additional resources\\n\\n- Circuit Breaker pattern\\n- https://learn.microsoft.com/azure/archite\", \"cture/patterns/circuit-breaker\\n\\n## Health monitoring\\n\\nHealth monitoring can allow near-real-time inf\", \"ormation about the state of your containers and microservices. Health monitoring is critical to mult\", \"iple aspects of operating microservices and is especially important when orchestrators perform parti\", \"al application upgrades in phases, as explained later.\\n\\nMicroservices-based applications often use h\", \"eartbeats or health checks to enable their performance monitors, schedulers, and orchestrators to ke\", \"ep track of the multitude of services. If services cannot send some sort of 'I'm alive' signal, eith\", \"er on demand or on a schedule, your application might face risks when you deploy updates, or it migh\", \"t just detect failures too late and not be able to stop cascading failures that can end up in major \", \"outages.\\n\\nIn the typical model, services send reports about their status, and that information is ag\", \"gregated to provide an overall view of the state of health of your application. If you're using an o\", \"rchestrator, you can provide health information to your orchestrat or's cluster, so that the cluster\", \" can act accordingly. If you invest in highquality health reporting that's customized for your appli\", \"cation, you can detect and fix issues for your running application much more easily.\\n\\n-\\n\\n## Implemen\", \"t health checks in ASP.NET Core services\\n\\nWhen developing an ASP.NET Core microservice or web applic\", \"ation, you can use the built-in health checks feature that was released in ASP .NET Core 2.2 (Micros\", \"oft.Extensions.Diagnostics.HealthChecks). Like many ASP.NET Core features, health checks come with a\", \" set of services and a middleware.\\n\\nHealth check services and middleware are easy to use and provide\", \" capabilities that let you validate if any external resource needed for your application (like a SQL\", \" Server database or a remote API) is working properly. When you use this feature, you can also decid\", \"e what it means that the resource is healthy, as we explain later.\\n\\nTo use this feature effectively,\", \" you need to first configure services in your microservices. Second, you need a front-end applicatio\", \"n that queries for the health reports. That front-end application could be a custom reporting applic\", \"ation, or it could be an orchestrator itself that can react accordingly to the health states.\\n\\n## Us\", \"e the HealthChecks feature in your back-end ASP.NET microservices\\n\\nIn this section, you'll learn how\", \" to implement the HealthChecks feature in a sample ASP.NET Core 7.0 Web API application when using t\", \"he Microsoft.Extensions.Diagnostics.HealthChecks package. The Implementation of this feature in a la\", \"rge-scale microservices like the eShopOnContainers is explained in the next section.\\n\\nTo begin, you \", \"need to define what constitutes a healthy status for each microservice. In the sample application, w\", \"e define the microservice is healthy if its API is accessible via HTTP and its related SQL Server da\", \"tabase is also available.\\n\\nIn .NET 7, with the built-in APIs, you can configure the services, add a \", \"Health Check for the microservice and its dependent SQL Server database in this way:\\n\\n```\\n// Program\", \".cs from .NET 7 Web API sample //... // Registers required services for health checks builder.Servic\", \"es.AddHealthChecks() // Add a health check for a SQL Server database .AddCheck( \\\"OrderingDB-check\\\", \", \"new SqlConnectionHealthCheck(builder.Configuration[\\\"ConnectionString\\\"]), HealthStatus.Unhealthy, new\", \" string[] { \\\"orderingdb\\\" });\\n```\\n\\nIn the previous code, the services.AddHealthChecks() method config\", \"ures a basic HTTP check that returns a status code 200 with 'Healthy'. Further, the AddCheck() exten\", \"sion method configures a custom SqlConnectionHealthCheck that checks the related SQL Database's heal\", \"th.\\n\\nThe AddCheck() method adds a new health check with a specified name and the implementation of t\", \"ype IHealthCheck. You can add multiple Health Checks using AddCheck method, so a microservice won't \", \"provide a 'healthy' status until all its checks are healthy.\\n\\nSqlConnectionHealthCheck is a custom c\", \"lass that implements IHealthCheck, which takes a connection string as a constructor parameter and ex\", \"ecutes a simple query to check if the connection to the SQL database is successful. It returns Healt\", \"hCheckResult.Healthy() if the query was executed successfully and a FailureStatus with the actual ex\", \"ception when it fails.\\n\\n```\\n// Sample SQL Connection Health Check public class SqlConnectionHealthCh\", \"eck : IHealthCheck { private const string DefaultTestQuery = \\\"Select 1\\\"; public string ConnectionStr\", \"ing { get ; } public string TestQuery { get ; } public SqlConnectionHealthCheck(string connectionStr\", \"ing) : this (connectionString, testQuery: DefaultTestQuery) { } public SqlConnectionHealthCheck(stri\", \"ng connectionString, string testQuery) { ConnectionString = connectionString ?? throw new ArgumentNu\", \"llException(nameof(connectionString)); TestQuery = testQuery; } public async Task<HealthCheckResult>\", \" CheckHealthAsync(HealthCheckContext context, CancellationToken cancellationToken = default (Cancell\", \"ationToken)) { using (var connection = new SqlConnection(ConnectionString)) { try { await connection\", \".OpenAsync(cancellationToken); if (TestQuery != null ) { var command = connection.CreateCommand(); c\", \"ommand.CommandText = TestQuery; await command.ExecuteNonQueryAsync(cancellationToken); } } catch (Db\", \"Exception ex) { return new HealthCheckResult(status: context.Registration.FailureStatus, exception: \", \"ex); } } return HealthCheckResult.Healthy(); } }\\n```\\n\\nNote that in the previous code, Select 1 is th\", \"e query used to check the Health of the database. To monitor the availability of your microservices,\", \" orchestrators like Kubernetes periodically perform health checks by sending requests to test the mi\", \"croservices. It's important to keep your d atabase queries efficient so that these operations are qu\", \"ick and don't result in a higher utilization of resources.\\n\\nCatalog.API\\n\\n\\u2022 Connected Services\\n\\n** De\", \"pendencies\\n\\ni\\n\\nAnalyzers\\n\\nFinally, add a middleware that responds to the url path /hc:\\n\\n```\\n// Progr\", \"am.cs from .NET 7 Web Api sample app.MapHealthChecks(\\\"/hc\\\");\\n```\\n\\nWhen the endpoint &lt;yourmicroser\", \"vice&gt;/hc is invoked, it runs all the health checks that are configured in the AddHealthChecks() m\", \"ethod in the Startup class and shows the result.\\n\\nAutofac.Extensions.Dependencylnjection (5.0.1)\\n\\n##\", \" HealthChecks implementation in eShopOnContainers\\n\\n\\u2022 Grpc.AspNetCore.Server (2.25.0)\\n\\nMicroservices \", \"in eShopOnContainers rely on multiple services to perform its task. For example, the Catalog.API mic\", \"roservice from eShopOnContainers depends on many services, such as Azure Blob Storage, SQL Server, a\", \"nd RabbitMQ. Therefore, it has several health checks added using the AddCheck() method. For every de\", \"pendent service, a custom IHealthCheck implementation that defines its respective health status woul\", \"d need to be added.\\n\\nThe open-source project AspNetCore.Diagnostics.HealthChecks solves this problem\", \" by providing custom health check implementations for each of these enterprise services, that are bu\", \"ilt on top of .NET 7. Each health check is available as an individual NuGet package that can be easi\", \"ly added to the project. eShopOnContainers uses them extensively in all its microservices.\\n\\nFor inst\", \"ance, in the Catalog.API microservice, the following NuGet packages were added:\\n\\nFigure 8-7. Custom \", \"Health Checks implemented in Catalog.API using AspNetCore.Diagnostics.HealthChecks\\n\\n<!-- image -->\\n\\n\", \"In the following code, the health check implementations are added for each dependent service and the\", \"n the middleware is configured:\\n\\n```\\n// Extension method from Catalog.api microservice // public sta\", \"tic IServiceCollection AddCustomHealthCheck( this IServiceCollection services, IConfiguration config\", \"uration) { var accountName = configuration.GetValue<string>(\\\"AzureStorageAccountName\\\"); var accountK\", \"ey = configuration.GetValue<string>(\\\"AzureStorageAccountKey\\\"); var hcBuilder = services.AddHealthChe\", \"cks();\\n```\\n\\nP\\n\\n```\\nhcBuilder .AddSqlServer( configuration[\\\"ConnectionString\\\"], name: \\\"CatalogDB-chec\", \"k\\\", tags: new string[] { \\\"catalogdb\\\" }); if (!string.IsNullOrEmpty(accountName) && !string.IsNullOrE\", \"mpty(accountKey)) { hcBuilder .AddAzureBlobStorage( $\\\"DefaultEndpointsProtocol=https;AccountName={ac\", \"countName};AccountKey={accountKey};Endpoint Suffix=core.windows.net\\\", name: \\\"catalog-storage-check\\\",\", \" tags: new string[] { \\\"catalogstorage\\\" }); } if (configuration.GetValue<bool>(\\\"AzureServiceBusEnable\", \"d\\\")) { hcBuilder .AddAzureServiceBusTopic( configuration[\\\"EventBusConnection\\\"], topicName: \\\"eshop_ev\", \"ent_bus\\\", name: \\\"catalog-servicebus-check\\\", tags: new string[] { \\\"servicebus\\\" }); } else { hcBuilder\", \" .AddRabbitMQ( $\\\"amqp://{configuration[\\\"EventBusConnection\\\"]}\\\", name: \\\"catalog-rabbitmqbus-check\\\", t\", \"ags: new string[] { \\\"rabbitmqbus\\\" }); } return services; }\\n```\\n\\nFinally, add the HealthCheck middlew\", \"are to listen to '/hc' endpoint:\\n\\n```\\n// HealthCheck middleware app.UseHealthChecks(\\\"/hc\\\", new Healt\", \"hCheckOptions() { Predicate = _ => true , ResponseWriter = UIResponseWriter.WriteHealthCheckUIRespon\", \"se });\\n```\\n\\n## Query your microservices to report about their health status\\n\\nWhen you've configured \", \"health checks as described in this article and you have the microservice running in Docker, you can \", \"directly check from a browser if it's healthy. You have to publish the container port in the Docker \", \"host, so you can access the container through the external Docker host IP or through host.docker.int\", \"ernal, as shown in figure 8-8.\\n\\n&lt; \\u2192\\n\\nL host.docker.internal:5101/hc\\n\\nA Notsecure | host.docker.in\", \"ternal:5101/hc\\n\\n\\u2022 (\\\"status\\\": \\\"Healthy\\\", \\\"totalDuration\\\": \\\"00:00:00.0035390\\\", \\\"entries\\\": (\\\"self\\\": (\\\"d\", \"ata\\\":\\n\\n{), \\\"duration\\\": \\\"00:00:00.0000017\\\"\\n\\n0), \\\"duration\\\": \\\"00:00:00.0034585\\\".\\n\\n\\\"duration\\\" 0: 09:90.\", \" 0024642 status Healthy tags\\\": *load-Cacklegrabbiembus-sheck\\\": (\\\"data\\\":\\n\\nFigure 8-8. Checking health\", \" status of a single service from a browser\\n\\n<!-- image -->\\n\\nIn that test, you can see that the Catal\", \"og.API microservice (running on port 5101) is healthy, returning HTTP status 200 and status informat\", \"ion in JSON. The service also checked the health of its SQL Server database dependency and RabbitMQ,\", \" so the health check reported itself as healthy.\\n\\n## Use watchdogs\\n\\nA watchdog is a separate service\", \" that can watch health and load across services, and report health about the microservices by queryi\", \"ng with the HealthChecks library introduced earlier. This can help prevent errors that would not be \", \"detected based on the view of a single service. Watchdogs also are a good place to host code that ca\", \"n perform remediation actions for known conditions without user interaction.\\n\\nThe eShopOnContainers \", \"sample contains a web page that displays sample health check reports, as shown in Figure 8-9. This i\", \"s the simplest watchdog you could have since it only shows the state of the microservices and web ap\", \"plications in eShopOnContainers. Usually a watchdog also takes actions when it detects unhealthy sta\", \"tes.\\n\\nFortunately, AspNetCore.Diagnostics.HealthChecks also provides AspNetCore.HealthChecks.UI NuGe\", \"t package that can be used to display the health check results from the configured URIs.\\n\\n|- Health \", \"Checks UI\\n\\n+\\n\\n&lt; lcalhost:5107/hc-ui#/healthchecks\\n\\nE\\n\\n&amp; Health Checks\\n\\n\\u2022 Webhooks\\n\\nHealth Che\", \"cks status\\n\\n(=)\\n\\nRefresh every\\n\\nm\\n\\n10\\n\\n-\\n\\na\\n\\nseconds\\n\\nChange\\n\\nFigure 8-9. Sample health check report\", \" in eShopOnContainers\\n\\n<!-- image -->\\n\\nIn summary, this watchdog service queries each microservice's\", \" '/hc' endpoint. This will execute all the health checks defined within it and return an overall hea\", \"lth state depending on all those checks. The HealthChecksUI is easy to consume with a few configurat\", \"ion entries and two lines of code that needs to be added into the Startup.cs of the watchdog service\", \".\\n\\nSample configuration file for health check UI:\\n\\n```\\n// Configuration { \\\"HealthChecksUI\\\": { \\\"Healt\", \"hChecks\\\": [ { \\\"Name\\\": \\\"Ordering HTTP Check\\\", \\\"Uri\\\": \\\"http://host.docker.internal:5102/hc\\\" }, { \\\"Name\", \"\\\": \\\"Ordering HTTP Background Check\\\", \\\"Uri\\\": \\\"http://host.docker.internal:5111/hc\\\" }, //... ]} }\\n```\\n\", \"\\nProgram.cs file that adds HealthChecksUI:\\n\\n```\\n// Program.cs from WebStatus(Watch Dog) service // /\", \"/ Registers required services for health checks builder.Services.AddHealthChecksUI(); // build the a\", \"pp, register other middleware app.UseHealthChecksUI(config => config.UIPath = \\\"/hc-ui\\\");\\n```\\n\\n## Hea\", \"lth checks when using orchestrators\\n\\nTo monitor the availability of your microservices, orchestrator\", \"s like Kubernetes and Service Fabric periodically perform health checks by sending requests to test \", \"the microservices. When an orchestrator determines that a service/container is unhealthy, it stops r\", \"outing requests to that instance. It also usually creates a new instance of that container.\\n\\nFor ins\", \"tance, most orchestrators can use health checks to manage zero-downtime deployments. Only when the s\", \"tatus of a service/container changes to healthy will the orchestrator start routing traffic to servi\", \"ce/container instances.\\n\\nHealth monitoring is especially important when an orchestrator performs an \", \"application upgrade. Some orchestrators (like Azure Service Fabric) update services in phases -for e\", \"xample, they might update one-fifth of the cluster surface for each application up grade. The set of\", \" nodes that's upgraded at the same time is referred to as an upgrade domain . After each upgrade dom\", \"ain has been upgraded and is available to users, that upgrade domain must pass health checks before \", \"the deployment moves to the next upgrade domain.\\n\\nAnother aspect of service health is reporting metr\", \"ics from the service. This is an advanced capability of the health model of some orchestrators, like\", \" Service Fabric. Metrics are important when using an orchestrator because they are used to balance r\", \"esource usage. Metrics also can be an indicator of system health. For example, you might have an app\", \"lication that has many microservices, and each instance reports a requests-per-second (RPS) metric. \", \"If one service is using more resources (memory, processor, etc.) than another service, the orchestra\", \"tor could move service instances around in the cluster to try to maintain even resource utilization.\", \"\\n\\nNote that Azure Service Fabric provides its own Health Monitoring model, which is more advanced th\", \"an simple health checks.\\n\\n## Advanced monitoring: visualization, analysis, and alerts\\n\\nThe final par\", \"t of monitoring is visualizing the event stream, reporting on service performance, and alerting when\", \" an issue is detected. You can use different solutions for this aspect of monitoring.\\n\\nYou can use s\", \"imple custom applications showing the state of your services, like the custom page shown when explai\", \"ning the AspNetCore.Diagnostics.HealthChecks. Or you could use more advanced tools like Azure Monito\", \"r to raise alerts based on the stream of events.\\n\\nFinally, if you're storing all the event streams, \", \"you can use Microsoft Power BI or other solutions like Kibana or Splunk to visualize the data.\\n\\n## A\", \"dditional resources\\n\\n- HealthChecks and HealthChecks UI for ASP.NET Core https://github.com/Xabaril/\", \"AspNetCore.Diagnostics.HealthChecks\\n- Introduction to Service Fabric health monitoring https://learn\", \".microsoft.com/azure/service-fabric/service-fabric-health-introduction\\n- Azure Monitor https://azure\", \".microsoft.com/services/monitor/\\n\\nClient Mobile App\\n\\n| Backend\\n\\nJ HTTP Request\\n\\nSign-in\\n\\nAPI Gateway\", \"\\n\\nASPNET Core\\n\\nWeb API\\n\\nRequest with user information\\n\\nBasket Microservice\\n\\n101\\u2022\\n\\nSQL Server conta n\", \"er\\n\\nRedis cache\\n\\n## Make secure .NET Microservices and Web Applications\\n\\nThere are so many aspects a\", \"bout security in microservices and web applications that the topic could easily take several books l\", \"ike this one. So, in this section, we'll focus on authentication, authorization, and application sec\", \"rets.\\n\\n## Implement authentication in .NET microservices and web applications\\n\\nIt's often necessary \", \"for resources and APIs published by a service to be limited to certain trusted users or clients. The\", \" first step to making these sorts of API-level trust decisions is authentication. Authentication is \", \"the process of reliably verifying a user's identity.\\n\\nIn microservice scenarios, authentication is t\", \"ypically handled centrally. If you're using an API Gateway, the gateway is a good place to authentic\", \"ate, as shown in Figure 9-1. If you use this approach, make sure that the individual microservices c\", \"annot be reached directly (without the API Gateway) unless additional security is in place to authen\", \"ticate messages whether they come from the gateway or not.\\n\\nFigure 9-1. Centralized authentication w\", \"ith an API Gateway\\n\\n<!-- image -->\\n\\nWhen the API Gateway centralizes authentication, it adds user in\", \"formation when forwarding requests to the microservices. If services can be accessed directly, an au\", \"thentication service like Azure Active\\n\\nCatalog Microservice\\n\\nClient Apps\\n\\nMobile\\n\\nApp\\n\\nWeb\\n\\nApp\\n\\nBa\", \"ckend Microservices\\n\\nSign-in\\n\\nSecurity token\\n\\nIdentity Microservice (STS + Users)\\n\\nSQL Server databa\", \"se\\n\\nDirectory or a dedicated authentication microservice acting as a security token service (STS) ca\", \"n be used to authenticate users. Trust decisions are shared between services with security tokens or\", \" cookies. (These tokens can be shared between ASP.NET Core applications, if needed, by implementing \", \"cookie sharing.) This pattern is illustrated in Figure 9-2. database\\n\\nFigure 9-2. Authentication by \", \"identity microservice; trust is shared using an authorization token\\n\\n<!-- image -->\\n\\nWhen microservi\", \"ces are accessed directly, trust, that includes authentication and authorization, is handled by a se\", \"curity token issued by a dedicated microservice, shared between microservices.\\n\\n## Authenticate with\", \" ASP.NET Core Identity\\n\\nThe primary mechanism in ASP.NET Core for identifying an application's users\", \" is the ASP.NET Core Identity membership system. ASP.NET Core Identity stores user information (incl\", \"uding sign-in information, roles, and claims) in a data store configured by the developer. Typically\", \", the ASP.NET Core Identity data store is an Entity Framework store provided in the\\n\\nMicrosoft.AspNe\", \"tCore.Identity.EntityFrameworkCore package. However, custom stores or other thirdparty packages can \", \"be used to store identity information in Azure Table Storage, CosmosDB, or other locations.\\n\\n## Tip\\n\", \"\\nASP.NET Core 2.1 and later provides ASP.NET Core Identity as a Razor Class Library , so you won't s\", \"ee much of the necessary code in your project, as was the case for previous versions. For details on\", \" how to customize the Identity code to suit your needs, see Scaffold Identity in ASP.NET Core projec\", \"ts.\\n\\nThe following code is taken from the ASP.NET Core Web Application MVC 3.1 project template with\", \" individual user account authentication selected. It shows how to configure ASP.NET Core Identity us\", \"ing Entity Framework Core in the Program.cs file.\\n\\n```\\n//... builder.Services.AddDbContext<Applicati\", \"onDbContext>(options => options.UseSqlServer( builder.Configuration.GetConnectionString(\\\"DefaultConn\", \"ection\\\")));\\n```\\n\\n```\\nbuilder.Services.AddDefaultIdentity<IdentityUser>(options => options.SignIn.Req\", \"uireConfirmedAccount = true ) .AddEntityFrameworkStores<ApplicationDbContext>(); builder.Services.Ad\", \"dRazorPages(); //... Once ASP.NET Core Identity is configured, you enable it by adding the app.UseAu\", \"thentication() and endpoints.MapRazorPages() as shown in the following code in the service's Program\", \".cs file: //... app.UseRouting(); app.UseAuthentication(); app.UseAuthorization(); app.UseEndpoints(\", \"endpoints => { endpoints.MapRazorPages(); }); //...\\n```\\n\\n## Important\\n\\nThe lines in the preceding co\", \"de MUST BE IN THE ORDER SHOWN for Identity to work correctly.\\n\\nUsing ASP.NET Core Identity enables s\", \"everal scenarios:\\n\\n- Create new user information using the UserManager type (userManager.CreateAsync\", \").\\n- Authenticate users using the SignInManager type. You can use signInManager.SignInAsync to sign \", \"in directly, or signInManager.PasswordSignInAsync to confirm the user's password is correct and then\", \" sign them in.\\n- Identify a user based on information stored in a cookie (which is read by ASP.NET C\", \"ore Identity middleware) so that subsequent requests from a browser will include a signed-in user's \", \"identity and claims.\\n\\nASP.NET Core Identity also supports two-factor authentication.\\n\\nFor authentica\", \"tion scenarios that make use of a local user data store and that persist identity between requests u\", \"sing cookies (as is typical for MVC web applications), ASP.NET Core Identity is a recommended soluti\", \"on.\\n\\n## Authenticate with external providers\\n\\nASP.NET Core also supports using external authenticati\", \"on providers to let users sign in via OAuth 2.0 flows. This means that users can sign in using exist\", \"ing authentication processes from providers like Microsoft, Google, Facebook, or Twitter and associa\", \"te those identities with an ASP.NET Core identity in your application.\\n\\nTo use external authenticati\", \"on, besides including the authentication middleware as mentioned before, using the app.UseAuthentica\", \"tion() method, you also have to register the external provider in Program.cs as shown in the followi\", \"ng example:\\n\\n```\\n//... services.AddDefaultIdentity<IdentityUser>(options => options.SignIn.RequireCo\", \"nfirmedAccount = true ) .AddEntityFrameworkStores<ApplicationDbContext>(); services.AddAuthenticatio\", \"n() .AddMicrosoftAccount(microsoftOptions => { microsoftOptions.ClientId = builder.Configuration[\\\"Au\", \"thentication:Microsoft:ClientId\\\"]; microsoftOptions.ClientSecret = builder.Configuration[\\\"Authentica\", \"tion:Microsoft:ClientSecret\\\"]; }) .AddGoogle(googleOptions => { ... }) .AddTwitter(twitterOptions =>\", \" { ... }) .AddFacebook(facebookOptions => { ... }); //...\\n```\\n\\nPopular external authentication provi\", \"ders and their associated NuGet packages are shown in the following table:\\n\\n| Provider   | Package  \", \"                                            |\\n|------------|----------------------------------------\", \"--------------|\\n| Microsoft  | Microsoft.AspNetCore.Authentication.MicrosoftAccount |\\n| Google     |\", \" Microsoft.AspNetCore.Authentication.Google           |\\n| Facebook   | Microsoft.AspNetCore.Authenti\", \"cation.Facebook         |\\n| Twitter    | Microsoft.AspNetCore.Authentication.Twitter          |\\n\\nIn \", \"all cases, you must complete an application registration procedure that is vendor dependent and that\", \" usually involves:\\n\\n1. Getting a Client Application ID.\\n2. Getting a Client Application Secret.\\n3. C\", \"onfiguring a redirection URL, that's handled by the authorization middleware and the registered prov\", \"ider\\n4. Optionally, configuring a sign-out URL to properly handle sign out in a Single Sign On (SSO)\", \" scenario.\\n\\nFor details on configuring your app for an external provider, see the External provider \", \"authentication in the ASP.NET Core documentation).\\n\\n## Tip\\n\\nAll details are handled by the authoriza\", \"tion middleware and services previously mentioned. So, you just have to choose the Individual User A\", \"ccount authentication option when you create the ASP.NET Core web application project in Visual Stud\", \"io, as shown in Figure 9-3, besides registering the authentication providers previously mentioned.\\n\\n\", \"Create a new ASP.NET Core web application\\n\\n.NET Core\\n\\nASP.NET Core Empty it.\\n\\nASP.NET Core Web API\\n\\n\", \"ASP.NET Core Web App\\n\\nASP.NET Core with Angular\\n\\nD\\n\\nASP.NET Core with React.js\\n\\nGet additional proje\", \"ct templates\\n\\nFigure 9-3. Selecting the Individual User Accounts option, for using external authenti\", \"cation, when creating a web application project in Visual Studio 2019.\\n\\n<!-- image -->\\n\\nIn addition \", \"to the external authentication providers listed previously, third-party packages are available that \", \"provide middleware for using many more external authentication providers. For a list, see the AspNet\", \".Security.OAuth.Providers repository on GitHub.\\n\\nYou can also create your own external authenticatio\", \"n middleware to solve some special need.\\n\\n## Authenticate with bearer tokens\\n\\nAuthenticating with AS\", \"P.NET Core Identity (or Identity plus external authentication providers) works well for many web app\", \"lication scenarios in which storing user information in a cookie is appropriate. In other scenarios,\", \" though, cookies are not a natural means of persisting and transmitting data.\\n\\nFor example, in an AS\", \"P.NET Core Web API that exposes RESTful endpoints that might be accessed by Single Page Applications\", \" (SPAs), by native clients, or even by other Web APIs, you typically want to use bearer token authen\", \"tication instead. These types of applications do not work with cookies, but can easily retrieve a be\", \"arer token and include it in the authorization header of subsequent requests. To enable token authen\", \"tication, ASP.NET Core supports several options for using OAuth 2.0 and OpenID Connect.\\n\\n## Authenti\", \"cate with an OpenID Connect or OAuth 2.0 Identity provider\\n\\nIf user information is stored in Azure A\", \"ctive Directory or another identity solution that supports OpenID Connect or OAuth 2.0, you can use \", \"the\\n\\nMicrosoft.AspNetCore.Authentication.OpenIdConnect package to authenticate using the OpenID Conn\", \"ect workflow. For example, to authenticate to the Identity.Api microservice in eShopOnContainers, an\", \" ASP.NET Core web application can use middleware from that package as shown in the following simplif\", \"ied example in Program.cs :\\n\\n```\\n// Program.cs var identityUrl = builder.Configuration.GetValue<stri\", \"ng>(\\\"IdentityUrl\\\"); var callBackUrl = builder.Configuration.GetValue<string>(\\\"CallBackUrl\\\"); var ses\", \"sionCookieLifetime = builder.Configuration.GetValue(\\\"SessionCookieLifetimeMinutes\\\", 60); // Add Auth\", \"entication services services.AddAuthentication(options => { options.DefaultScheme = CookieAuthentica\", \"tionDefaults.AuthenticationScheme; options.DefaultChallengeScheme = JwtBearerDefaults.Authentication\", \"Scheme; }) .AddCookie(setup => setup.ExpireTimeSpan = TimeSpan.FromMinutes(sessionCookieLifetime)) .\", \"AddOpenIdConnect(options => { options.SignInScheme = CookieAuthenticationDefaults.AuthenticationSche\", \"me; options.Authority = identityUrl.ToString(); options.SignedOutRedirectUri = callBackUrl.ToString(\", \"); options.ClientId = useLoadTest ? \\\"mvctest\\\" : \\\"mvc\\\"; options.ClientSecret = \\\"secret\\\"; options.Resp\", \"onseType = useLoadTest ? \\\"code id_token token\\\" : \\\"code id_token\\\"; options.SaveTokens = true ; option\", \"s.GetClaimsFromUserInfoEndpoint = true ; options.RequireHttpsMetadata = false ; options.Scope.Add(\\\"o\", \"penid\\\"); options.Scope.Add(\\\"profile\\\"); options.Scope.Add(\\\"orders\\\"); options.Scope.Add(\\\"basket\\\"); opt\", \"ions.Scope.Add(\\\"marketing\\\"); options.Scope.Add(\\\"locations\\\"); options.Scope.Add(\\\"webshoppingagg\\\"); op\", \"tions.Scope.Add(\\\"orders.signalrhub\\\"); }); // Build the app //\\u2026 app.UseAuthentication(); //\\u2026 app.UseE\", \"ndpoints(endpoints => { //... });\\n```\\n\\nWhen you use this workflow, the ASP.NET Core Identity middlew\", \"are is not needed, because all user information storage and authentication is handled by the Identit\", \"y service.\\n\\n## Issue security tokens from an ASP.NET Core service\\n\\nIf you prefer to issue security t\", \"okens for local ASP.NET Core Identity users rather than using an external identity provider, you can\", \" take advantage of some good third-party libraries.\\n\\nIdentityServer4 and OpenIddict are OpenID Conne\", \"ct providers that integrate easily with ASP.NET Core Identity to let you issue security tokens from \", \"an ASP.NET Core service. The IdentityServer4 documentation has in-depth instructions for using the l\", \"ibrary. However, the basic steps to using IdentityServer4 to issue tokens are as follows.\\n\\n1. You co\", \"nfigure IdentityServer4 in Program.cs by making a call to builder.Services.AddIdentityServer.\\n2. You\", \" call app.UseIdentityServer in Program.cs to add IdentityServer4 to the application's HTTP request p\", \"rocessing pipeline. This lets the library serve requests to OpenID Connect and OAuth2 endpoints like\", \" /connect/token.\\n3. You configure identity server by setting the following data:\\n4. -The credentials\", \" to use for signing.\\n5. -The Identity and API resources that users might request access to:\\n- API re\", \"sources represent protected data or functionality that a user can access with an access token. An ex\", \"ample of an API resource would be a web API (or set of APIs) that requires authorization.\\n- Identity\", \" resources represent information (claims) that are given to a client to identify a user. The claims \", \"might include the user name, email address, and so on.\\n8. -The clients that will be connecting in or\", \"der to request tokens.\\n9. -The storage mechanism for user information, such as ASP.NET Core Identity\", \" or an alternative.\\n\\nWhen you specify clients and resources for IdentityServer4 to use, you can pass\", \" an IEnumerable collection of the appropriate type to methods that take in-memory client or resource\", \" stores. Or for more complex scenarios, you can provide client or resource provider types via Depend\", \"ency Injection.\\n\\nA sample configuration for IdentityServer4 to use in-memory resources and clients p\", \"rovided by a custom IClientStore type might look like the following example:\\n\\n```\\n// Program.cs buil\", \"der.Services.AddSingleton<IClientStore, CustomClientStore>(); builder.Services.AddIdentityServer() .\", \"AddSigningCredential(\\\"CN=sts\\\") .AddInMemoryApiResources(MyApiResourceProvider.GetAllResources()) .Ad\", \"dAspNetIdentity<ApplicationUser>(); //...\\n```\\n\\n## Consume security tokens\\n\\nAuthenticating against an\", \" OpenID Connect endpoint or issuing your own security tokens covers some scenarios. But what about a\", \" service that simply needs to limit access to those users who have valid security tokens that were p\", \"rovided by a different service?\\n\\nFor that scenario, authentication middleware that handles JWT token\", \"s is available in the Microsoft.AspNetCore.Authentication.JwtBearer package. JWT stands for ' JSON W\", \"eb Token ' and is a common security token format (defined by RFC 7519) for communicating security cl\", \"aims. A simplified example of how to use middleware to consume such tokens might look like this code\", \" fragment, taken from the Ordering.Api microservice of eShopOnContainers.\\n\\n```\\n// Program.cs var ide\", \"ntityUrl = builder.Configuration.GetValue<string>(\\\"IdentityUrl\\\"); // Add Authentication services bui\", \"lder.Services.AddAuthentication(options => { options.DefaultAuthenticateScheme = AspNetCore.Authenti\", \"cation.JwtBearer.JwtBearerDefaults.AuthenticationScheme; options.DefaultChallengeScheme = AspNetCore\", \".Authentication.JwtBearer.JwtBearerDefaults.AuthenticationScheme; }).AddJwtBearer(options => { optio\", \"ns.Authority = identityUrl; options.RequireHttpsMetadata = false ; options.Audience = \\\"orders\\\"; }); \", \"// Build the app app.UseAuthentication(); //\\u2026 app.UseEndpoints(endpoints => { //... });\\n```\\n\\nThe par\", \"ameters in this usage are:\\n\\n- Audience represents the receiver of the incoming token or the resource\", \" that the token grants access to. If the value specified in this parameter does not match the parame\", \"ter in the token, the token will be rejected.\\n- Authority is the address of the token-issuing authen\", \"tication server. The JWT bearer authentication middleware uses this URI to get the public key that c\", \"an be used to validate the token's signature. The middleware also confirms that the iss parameter in\", \" the token matches this URI.\\n\\nAnother parameter, RequireHttpsMetadata, is useful for testing purpose\", \"s; you set this parameter to false so you can test in environments where you don't have certificates\", \". In real -world deployments, JWT bearer tokens should always be passed only over HTTPS.\\n\\nWith this \", \"middleware in place, JWT tokens are automatically extracted from authorization headers. They are the\", \"n deserialized, validated (using the values in the Audience and Authority parameters), and stored as\", \" user information to be referenced later by MVC actions or authorization filters.\\n\\nThe JWT bearer au\", \"thentication middleware can also support more advanced scenarios, such as using a local certificate \", \"to validate a token if the authority is not available. For this scenario, you can specify a TokenVal\", \"idationParameters object in the JwtBearerOptions object.\\n\\n## Additional resources\\n\\n- Sharing cookies\", \" between applications https://learn.microsoft.com/aspnet/core/security/cookie-sharing\\n- Introduction\", \" to Identity https://learn.microsoft.com/aspnet/core/security/authentication/identity\\n- Rick Anderso\", \"n. Two-factor authentication with SMS https://learn.microsoft.com/aspnet/core/security/authenticatio\", \"n/2fa\\n- Enabling authentication using Facebook, Google and other external providers https://learn.mi\", \"crosoft.com/aspnet/core/security/authentication/social/\\n- Michell Anicas. An Introduction to OAuth 2\", \" https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2\\n- AspNet.Security.OAuth\", \".Providers (GitHub repo for ASP.NET OAuth providers) https://github.com/aspnet-contrib/AspNet.Securi\", \"ty.OAuth.Providers/tree/dev/src\\n- IdentityServer4. Official documentation https://identityserver4.re\", \"adthedocs.io/en/latest/\\n\\n## About authorization in .NET microservices and web applications\\n\\nAfter au\", \"thentication, ASP.NET Core Web APIs need to authorize access. This process allows a service to make \", \"APIs available to some authenticated users, but not to all. Authorization can be done based on users\", \"' roles or based on custom policy, which might include inspecting claims or other heuristics.\\n\\nRestr\", \"icting access to an ASP.NET Core MVC route is as easy as applying an Authorize attribute to the acti\", \"on method (or to the controller's class if all the controller's actions require authorization), as s\", \"hown in following example:\\n\\n```\\npublic class AccountController : Controller { public ActionResult Lo\", \"gin() { } [Authorize]\\n```\\n\\n```\\npublic ActionResult Logout() { } }\\n```\\n\\nBy default, adding an Authori\", \"ze attribute without parameters will limit access to authenticated users for that controller or acti\", \"on. To further restrict an API to be available for only specific users, the attribute can be expande\", \"d to specify required roles or policies that users must satisfy.\\n\\n## Implement role-based authorizat\", \"ion\\n\\nASP.NET Core Identity has a built-in concept of roles. In addition to users, ASP.NET Core Ident\", \"ity stores information about different roles used by the application and keeps track of which users \", \"are assigned to which roles. These assignments can be changed programmatically with the RoleManager \", \"type that updates roles in persisted storage, and the UserManager type that can grant or revoke role\", \"s from users.\\n\\nIf you're authenticating with JWT bearer tokens, the ASP.NET Core JWT bearer authenti\", \"cation middleware will populate a user's roles based on role claims found in the token. To limit acc\", \"ess to an MVC action or controller to users in specific roles, you can include a Roles parameter in \", \"the Authorize annotation (attribute), as shown in the following code fragment:\\n\\n```\\n[Authorize(Roles\", \" = \\\"Administrator, PowerUser\\\")] public class ControlPanelController : Controller { public ActionResu\", \"lt SetTime() { } [Authorize(Roles = \\\"Administrator\\\")] public ActionResult ShutDown() { } }\\n```\\n\\nIn t\", \"his example, only users in the Administrator or PowerUser roles can access APIs in the ControlPanel \", \"controller (such as executing the SetTime action). The ShutDown API is further restricted to allow a\", \"ccess only to users in the Administrator role.\\n\\nTo require a user be in multiple roles, you use mult\", \"iple Authorize attributes, as shown in the following example:\\n\\n```\\n[Authorize(Roles = \\\"Administrator\", \", PowerUser\\\")] [Authorize(Roles = \\\"RemoteEmployee \\\")] [Authorize(Policy = \\\"CustomPolicy\\\")] public Ac\", \"tionResult API1 () { }\\n```\\n\\nIn this example, to call API1, a user must:\\n\\n- Be in the Administrator o\", \"r PowerUser role, and\\n- Be in the RemoteEmployee role, and\\n\\n- Satisfy a custom handler for CustomPol\", \"icy authorization.\\n\\n## Implement policy-based authorization\\n\\nCustom authorization rules can also be \", \"written using authorization policies. This section provides an overview. For more information, see t\", \"he ASP.NET Authorization Workshop.\\n\\nCustom authorization policies are registered in the Startup.Conf\", \"igureServices method using the service.AddAuthorization method. This method takes a delegate that co\", \"nfigures an AuthorizationOptions argument.\\n\\n```\\nservices.AddAuthorization(options => { options.AddPo\", \"licy(\\\"AdministratorsOnly\\\", policy => policy.RequireRole(\\\"Administrator\\\")); options.AddPolicy(\\\"Employ\", \"eesOnly\\\", policy => policy.RequireClaim(\\\"EmployeeNumber\\\")); options.AddPolicy(\\\"Over21\\\", policy => po\", \"licy.Requirements.Add( new MinimumAgeRequirement(21))); });\\n```\\n\\nAs shown in the example, policies c\", \"an be associated with different types of requirements. After the policies are registered, they can b\", \"e applied to an action or controller by passing the policy's name as the Policy argument of the Auth\", \"orize attribute (for example, [Authorize(Policy=\\\"EmployeesOnly\\\")]) Policies can have multiple requir\", \"ements, not just one (as shown in these examples).\\n\\nIn the previous example, the first AddPolicy cal\", \"l is just an alternative way of authorizing by role. If [Authorize(Policy=\\\"AdministratorsOnly\\\")] is \", \"applied to an API, only users in the Administrator role will be able to access it.\\n\\nThe second AddPo\", \"licy call demonstrates an easy way to require that a particular claim should be present for the user\", \". The RequireClaim method also optionally takes expected values for the claim. If values are specifi\", \"ed, the requirement is met only if the user has both a claim of the correct type and one of the spec\", \"ified values. If you're using the JWT bearer authentication middleware, al l JWT properties will be \", \"available as user claims.\\n\\nThe most interesting policy shown here is in the third AddPolicy method, \", \"because it uses a custom authorization requirement. By using custom authorization requirements, you \", \"can have a great deal of control over how authorization is performed. For this to work, you must imp\", \"lement these types:\\n\\n- A Requirements type that derives from IAuthorizationRequirement and that cont\", \"ains fields specifying the details of the requirement. In the example, this is an age field for the \", \"sample MinimumAgeRequirement type.\\n- A handler that implements AuthorizationHandler, where T is the \", \"type of IAuthorizationRequirement that the handler can satisfy. The handler must implement the Handl\", \"eRequirementAsync method, which checks whether a specified context that contains information about t\", \"he user satisfies the requirement.\\n\\nIf the user meets the requirement, a call to context.Succeed wil\", \"l indicate that the user is authorized. If there are multiple ways that a user might satisfy an auth\", \"orization requirement, multiple handlers can be created.\\n\\nIn addition to registering custom policy r\", \"equirements with AddPolicy calls, you also need to register custom requirement handlers via Dependen\", \"cy Injection (services.AddTransient&lt;IAuthorizationHandler, MinimumAgeHandler&gt;()).\\n\\nAn example \", \"of a custom authorization requirement and handler for checking a user's age (based on a DateOfBirth \", \"claim) is available in the ASP.NET Core authorization documentation.\\n\\n## Authorization and minimal a\", \"pis\\n\\nASP.NET supports minimal APIs as an alternative to controller-based APIs. Authorization policie\", \"s are the recommended way to configure authorization for minimal APIs, as this example demonstrates:\", \"\\n\\n```\\n// Program.cs builder.Services.AddAuthorizationBuilder() .AddPolicy(\\\"admin_greetings\\\", policy \", \"=> policy .RequireRole(\\\"admin\\\") .RequireScope(\\\"greetings_api\\\")); // build the app app.MapGet(\\\"/hello\", \"\\\", () => \\\"Hello world!\\\") .RequireAuthorization(\\\"admin_greetings\\\");\\n```\\n\\n## Additional resources\\n\\n- A\", \"SP.NET Core Authentication\\n\\nhttps://learn.microsoft.com/aspnet/core/security/authentication/identity\", \"\\n\\n- ASP.NET Core Authorization https://learn.microsoft.com/aspnet/core/security/authorization/introd\", \"uction\\n- Role-based Authorization https://learn.microsoft.com/aspnet/core/security/authorization/rol\", \"es\\n- Custom Policy-Based Authorization https://learn.microsoft.com/aspnet/core/security/authorizatio\", \"n/policies\\n- Authentication and authorization in minimal APIs\\n\\nhttps://learn.microsoft.com/aspnet/co\", \"re/fundamentals/minimal-apis/security\\n\\n## Store application secrets safely during development\\n\\nTo co\", \"nnect with protected resources and other services, ASP.NET Core applications typically need to use c\", \"onnection strings, passwords, or other credentials that contain sensitive information. These sensiti\", \"ve pieces of information are called secrets . It's a best practice to not include secrets in source\\n\", \"\\ncode and making sure not to store secrets in source control. Instead, you should use the ASP.NET Co\", \"re configuration model to read the secrets from more secure locations.\\n\\nYou must separate the secret\", \"s for accessing development and staging resources from the ones used for accessing production resour\", \"ces, because different individuals will need access to those different sets of secrets. To store sec\", \"rets used during development, common approaches are to either store secrets in environment variables\", \" or by using the ASP.NET Core Secret Manager tool. For more secure storage in production environment\", \"s, microservices can store secrets in an Azure Key Vault.\\n\\n## Store secrets in environment variables\", \"\\n\\nOne way to keep secrets out of source code is for developers to set string-based secrets as enviro\", \"nment variables on their development machines. When you use environment variables to store secrets w\", \"ith hierarchical names, such as the ones nested in configuration sections, you must name the variabl\", \"es to include the complete hierarchy of its sections, delimited with colons (:).\\n\\nFor example, setti\", \"ng an environment variable Logging:LogLevel:Default to Debug value would be equivalent to a configur\", \"ation value from the following JSON file:\\n\\n```\\n{ \\\"Logging\\\": { \\\"LogLevel\\\": { \\\"Default\\\": \\\"Debug\\\" } } }\", \"\\n```\\n\\nTo access these values from environment variables, the application just needs to call AddEnvir\", \"onmentVariables on its ConfigurationBuilder when constructing an IConfigurationRoot object.\\n\\n## Note\", \"\\n\\nEnvironment variables are commonly stored as plain text, so if the machine or process with the env\", \"ironment variables is compromised, the environment variable values will be visible.\\n\\n## Store secret\", \"s with the ASP.NET Core Secret Manager\\n\\nThe ASP.NET Core Secret Manager tool provides another method\", \" of keeping secrets out of source code during development . To use the Secret Manager tool, install \", \"the package Microsoft.Extensions.Configuration.SecretManager in your project file. Once that depende\", \"ncy is present and has been restored, the dotnet user-secrets command can be used to set the value o\", \"f secrets from the command line. These secrets will be stored in a JSON file in the user's profile d\", \"irectory (details vary by OS), away from source code.\\n\\nSecrets set by the Secret Manager tool are or\", \"ganized by the UserSecretsId property of the project that's using the secrets. Therefore, you must b\", \"e sure to set the UserSecretsId property in your project file, as shown in the snippet below. The de\", \"fault value is a GUID assigned by Visual Studio, but the actual string is not important as long as i\", \"t's unique in your computer.\\n\\n&lt; PropertyGroup &gt; &lt; UserSecretsId &gt;UniqueIdentifyingString\", \"&lt;/ UserSecretsId\\n\\n```\\n> </ PropertyGroup >\\n```\\n\\nUsing secrets stored with Secret Manager in an ap\", \"plication is accomplished by calling AddUserSecrets&lt;T&gt; on the ConfigurationBuilder instance to\", \" include secrets for the application in its configuration. The generic parameter T should be a type \", \"from the assembly that the UserSecretId was applied to. Usually, using AddUserSecrets&lt;Startup&gt;\", \" is fine.\\n\\nThe AddUserSecrets&lt;Startup&gt;() is included in the default options for the Developmen\", \"t environment when using the CreateDefaultBuilder method in Program.cs .\\n\\n## Use Azure Key Vault to \", \"protect secrets at production time\\n\\nSecrets stored as environment variables or stored by the Secret \", \"Manager tool are still stored locally and unencrypted on the machine. A more secure option for stori\", \"ng secrets is Azure Key Vault, which provides a secure, central location for storing keys and secret\", \"s.\\n\\nThe Azure.Extensions.AspNetCore.Configuration.Secrets package allows an ASP.NET Core application\", \" to read configuration information from Azure Key Vault. To start using secrets from an Azure Key Va\", \"ult, you follow these steps:\\n\\n1. Register your application as an Azure AD application. (Access to ke\", \"y vaults is managed by Azure AD.) This can be done through the Azure management portal.\\n\\nAlternative\", \"ly, if you want your application to authenticate using a certificate instead of a password or client\", \" secret, you can use the New-AzADApplication PowerShell cmdlet. The certificate that you register wi\", \"th Azure Key Vault needs only your public key. Your application will use the private key.\\n\\n2. Give t\", \"he registered application access to the key vault by creating a new service principal. You can do th\", \"is using the following PowerShell commands:\\n\\n$sp = New-AzADServicePrincipal -ApplicationId \\\"&lt;Appl\", \"ication ID guid&gt;\\\" Set-AzKeyVaultAccessPolicy -VaultName \\\"&lt;VaultName&gt;\\\" -ServicePrincipalName\", \"\\n\\n```\\n$sp.ServicePrincipalNames[0] -PermissionsToSecrets all -ResourceGroupName \\\"<KeyVault Resource \", \"Group>\\\"\\n```\\n\\n3. Include the key vault as a configuration source in your application by calling the A\", \"zureKeyVaultConfigurationExtensions.AddAzureKeyVault extension method when you create an IConfigurat\", \"ionRoot instance.\\n\\nNote that calling AddAzureKeyVault requires the application ID that was registere\", \"d and given access to the key vault in the previous steps. Or you can firstly running the Azure CLI \", \"command: az login, then using an overload of AddAzureKeyVault that takes a DefaultAzureCredential in\", \" place of the client.\\n\\n## Important\\n\\nWe recommend that you register Azure Key Vault as the last conf\", \"iguration provider, so it can override configuration values from previous providers.\\n\\n## Additional \", \"resources\\n\\n- Using Azure Key Vault to protect application secrets https://learn.microsoft.com/azure/\", \"architecture/multitenant-identity\\n- Safe storage of app secrets during development https://learn.mic\", \"rosoft.com/aspnet/core/security/app-secrets\\n- Configuring data protection https://learn.microsoft.co\", \"m/aspnet/core/security/data-protection/configuration/overview\\n- Data Protection key management and l\", \"ifetime in ASP.NET Core https://learn.microsoft.com/aspnet/core/security/data-protection/configurati\", \"on/defaultsettings\\n\\n## .NET Microservices Architecture key takeaways\\n\\nAs a summary and key takeaways\", \", the following are the most important conclusions from this guide.\\n\\nBenefits of using containers. C\", \"ontainer-based solutions provide important cost savings because they help reduce deployment problems\", \" caused by failing dependencies in production environments. Containers significantly improve DevOps \", \"and production operations.\\n\\nContainers will be ubiquitous. Docker-based containers are becoming the \", \"de facto standard in the industry, supported by key vendors in the Windows and Linux ecosystems, suc\", \"h as Microsoft, Amazon AWS, Google, and IBM. Docker will probably soon be ubiquitous in both the clo\", \"ud and on-premises datacenters.\\n\\nContainers as a unit of deployment. A Docker container is becoming \", \"the standard unit of deployment for any server-based application or service.\\n\\nMicroservices. The mic\", \"roservices architecture is becoming the preferred approach for distributed and large or complex miss\", \"ion-critical applications based on many independent subsystems in the form of autonomous services. I\", \"n a microservice-based architecture, the application is built as a collection of services that are d\", \"eveloped, tested, versioned, deployed, and scaled independently. Each service can include any relate\", \"d autonomous database.\\n\\nDomain-driven design and SOA. The microservices architecture patterns derive\", \" from serviceoriented architecture (SOA) and domain-driven design (DDD). When you design and develop\", \" microservices for environments with evolving business needs and rules, it's important to consider D\", \"DD approaches and patterns.\\n\\nMicroservices challenges. Microservices offer many powerful capabilitie\", \"s, like independent deployment, strong subsystem boundaries, and technology diversity. However, they\", \" also raise many new challenges related to distributed application development, such as fragmented a\", \"nd independent data models, resilient communication between microservices, eventual consistency, and\", \" operational complexity that results from aggregating logging and monitoring information from multip\", \"le microservices. These aspects introduce a much higher complexity level than a traditional monolith\", \"ic application. As a result, only specific scenarios are suitable for microservice-based application\", \"s. These include large and complex applications with multiple evolving subsystems. In these cases , \", \"it's worth investing in a more complex software architecture, because it will provide better long-te\", \"rm agility and application maintenance.\\n\\nContainers for any application. Containers are convenient f\", \"or microservices, but can also be useful for monolithic applications based on the traditional .NET F\", \"ramework, when using Windows Containers. The benefits of using Docker, such as solving many deployme\", \"nt-to-production issues and providing state-of-the-art Dev and Test environments, apply to many diff\", \"erent types of applications.\\n\\nCLI versus IDE. With Microsoft tools, you can develop containerized .N\", \"ET applications using your preferred approach. You can develop with a CLI and an editor-based enviro\", \"nment by using the Docker CLI and Visual Studio Code. Or you can use an IDE-focused approach with Vi\", \"sual Studio and its unique features for Docker, such as multi-container debugging.\\n\\nResilient cloud \", \"applications. In cloud-based systems and distributed systems in general, there is always the risk of\", \" partial failure. Since clients and services are separate processes (containers), a service might no\", \"t be able to respond in a timely way to a client's request. For examp le, a service might be down be\", \"cause of a partial failure or for maintenance; the service might be overloaded and responding slowly\", \" to requests; or it might not be accessible for a short time because of network issues. Therefore, a\", \" cloud-based application must embrace those failures and have a strategy in place to respond to thos\", \"e failures. These strategies can include retry policies (resending messages or retrying requests) an\", \"d implementing circuit-breaker patterns to avoid exponential load of repeated requests. Basically, c\", \"loud-based applications must have resilient mechanisms -either based on cloud infrastructure or cust\", \"om, as the high-level ones provided by orchestrators or service buses.\\n\\nSecurity. Our modern world o\", \"f containers and microservices can expose new vulnerabilities. There are several ways to implement b\", \"asic application security, based on authentication and authorization. However, container security mu\", \"st consider additional key components that result in inherently safer applications. A critical eleme\", \"nt of building safer apps is having a secure way of communicating with other apps and systems, somet\", \"hing that often requires credentials, tokens, passwords, and the like, commonly referred to as appli\", \"cation secrets. Any secure solution must follow security best practices, such as encrypting secrets \", \"while in transit and at rest, and preventing secrets from leaking when consumed by the final applica\", \"tion. Those secrets need to be stored and kept safely, as when using Azure Key Vault.\\n\\nOrchestrators\", \". Container-based orchestrators, such as Azure Kubernetes Service and Azure Service Fabric are key p\", \"art of any significant microservice and container-based application. These applications carry with t\", \"hem high complexity, scalability needs, and go through constant evolution. This guide has introduced\", \" orchestrators and their role in microservice-based and container-based solutions. If your applicati\", \"on needs are moving you toward complex containerized apps, you will find it useful to seek out addit\", \"ional resources for learning more about orchestrators.\"]"