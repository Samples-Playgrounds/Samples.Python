{"1": {"Foreword - Dapr for .NET Developers": "With the wave of cloud adoption underway, there is a major shift happening towards \u201ccloud native\u201d\ndevelopment, often built with microservice-architectures. These microservices are both stateless and\nstateful, and run on the cloud and edge, embracing the diversity of languages and frameworks\navailable today. This enterprise shift is driven by both the market forces of faster time to market, and\nthe scale and efficiencies of building services for the cloud. Even before COVID-19, cloud adoption\nwas accelerating for enterprises, and developers were being asked to do even more to deliver on\nbuilding these distributed system applications. That has only accelerated since COVID-19. Developers\nin enterprises seek to focus on business logic, while leaning on platforms to imbue their applications\nwith scale, resiliency, maintainability, elasticity, and the other attributes of cloud-native architectures,\nwhich is why there is also shift towards serverless platforms that hide the underlying infrastructure.\nDevelopers should not be expected to become distributed systems experts. This is where Dapr steps\nin to help you, whether you are building on infrastructure such as Kubernetes, or on a serverless\nplatform.\n\nDapr is designed as an enterprise, developer-focused, microservices programming model platform\nwith the mantra \u201cany language, any framework, run anywhere\u201d. It makes building distributed\napplications easy and portable across any infrastructure, from public-cloud, through hierarchical edge,\nand even down to single node IoT devices. It emerged from both our experiences building services in\nAzure and time spent working with customers building applications on Azure Kubernetes Service and\nAzure Service Fabric. Over and over, we saw common problems that they had to address. It became\nclear that there was a need to provide a \u201clibrary\u201d of common microservice best practices that\ndevelopers could use, not only in new green field applications, but also to aid in the modernization of\nexisting applications. In the containerized, distributed, and networked cloud native world, the sidecar\nmodel has emerged as the preferred approach, in the same way DLLs are preferred in the client/server\ngeneration. Using Dapr\u2019s sidecar and APIs give you, as a developer, all the power of distributed\nsystems functionality, with the ease of a single HTTP or gRPC local call.\n\nTo address the wide range of scenarios that developers face, Dapr provides features such as state\nmanagement, service-to-service invocation, pub/sub, and integration to external systems with I/O\nbindings, which are based on the triggers and bindings of Azure Functions. These in turn take\nadvantage of Dapr\u2019s component model, which allows you to \u201cswap out\u201d, say different underlying state\nstores, without having to change any code. This component model makes code more portable, more\nflexible, and allows for experimentation of what best suits your needs. Developers don\u2019t need to learn\n\n1 CHAPTER 1 | Foreword - Dapr for .NET Developers\n\nand incorporate service SDKs into their code, or worry about authentication, secret management,\nretries, or conditional code that targets specific deployment environments.\n\nThis book shows how Dapr reduces your development time and overall code maintenance by\nincrementally \u201cDaperizing\u201d the canonical .NET reference application, eShop. For example, in the\noriginal eShop implementation, significant amounts of code were written to abstract between Azure\nService Bus and RabbitMQ for publishing events between services. All this code can be discarded and\nsimply replaced with Dapr\u2019s pub/sub API and component model, which had an even wider range of\npub/sub brokers, rather than just two. Dapr\u2019s actor model, when used in the reworked eShop\napplication, shows the ease of building long running, stateful, event driven, workflow applications with\nall the difficulties of concurrency and multi-threading removed. By the end of this book, you will see\nthe drastic simplification that Dapr brings to your application development, and I firmly believe all\ndevelopers embarking on a cloud native app building journey should use Dapr.\n\nWe publicly announced Dapr with the v0.1 release in Oct 2019 and now, a year and half later, I am\nthrilled to say that Dapr is ready for production usage with the v1.0 release. Getting Dapr to v1.0 has\ntruly been a community effort. It has been amazing to see the open-source community coalesce\naround Dapr and grow since it was first announced \u2013 from 114 contributors in October 2019 to over\n700 in early 2021 - a six-fold increase in 16 months! Contributions to the project have gone to every\nDapr repo and have ranged from opening issues, commenting on feature proposals, providing\nsamples, and, of course, contributing code. The parts of the project community members have\ncontributed to the most include the Dapr runtime, docs, CLI, SDKs, and the creation of a rich\necosystem of components. Maintaining this openness is critical to Dapr\u2019s future.\n\nDapr is just getting started, though, and you should expect to see more Dapr capabilities and more\nsupport for Dapr in Azure services. I hope that you will take advantage of Dapr to enable you to focus\non your core business logic and accelerate your microservices development. I am excited to have you\n[join us in the Dapr community on this journey at https://github.com/dapr/](https://github.com/dapr/) and on Discord\n[https://aka.ms/dapr-discord.](https://aka.ms/dapr-discord)\n\nModern distributed systems are complex. You start with small, loosely coupled, independently\ndeployable services. These services cross process and server boundaries. They then consume different\nkinds of infrastructure backing services (databases, message brokers, key vaults). Finally, these\ndisparate pieces compose together to form an application.\n\n_Mark Russinovich_ _Azure CTO and Technical Fellow_ _Microsoft_\n\n2 CHAPTER 1 | Foreword - Dapr for .NET Developers\n\n**CHAPTER**"}, "2": {"The world is distributed": {"Summary": "In this chapter, we discussed the adoption of distributed applications. We contrasted a monolithic\nsystem approach with that of distributed services. We pointed out many of the common challenges\nwhen considering a distributed approach.\n\nNow, sit back, relax, and let us introduce you the new world of Dapr.\n\n7 CHAPTER 2 | The world is distributed\n\n**CHAPTER**"}}, "3": {"Dapr at 20,000 feet": {"Dapr and the problem it solves": "Dapr addresses a large challenge inherent in modern distributed applications: **Complexity** .\n\nThrough an architecture of pluggable components, Dapr greatly simplifies the plumbing behind\ndistributed applications. It provides a **dynamic glue** that binds your application with infrastructure\ncapabilities from the Dapr runtime.\n\nConsider a requirement to make one of your services stateful? What would be your design. You could\nwrite custom code that targets a state store such as Redis Cache. However, Dapr provides state\nmanagement capabilities out-of-the-box. Your service invokes the Dapr state management **building**\n**block** that dynamically binds to a state store **component** via a Dapr **component configuration** yaml\nfile. Dapr ships with several pre-built state store components, including Redis. With this model, your\nservice delegates state management to the Dapr runtime. Your service has no SDK, library, or direct\nreference to the underlying component. You can even change state stores, say, from Redis to MySQL\nor Cassandra, with no code changes.\n\nFigure 2-1 shows Dapr from 20,000 feet.\n\n8 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-1. Dapr at 20,000 feet._\n\nIn the top row of the figure, note how Dapr provides language-specific SDKs for popular development\nplatforms. Dapr v1.0 includes support for Go, Node.js, Python, .NET, Java, and JavaScript. This book\nfocuses on the Dapr .NET SDK, which also provides direct support for ASP.NET Core integration.\n\nWhile language-specific SDKs enhance the developer experience, Dapr is platform agnostic. Under the\nhood, Dapr\u2019s programming model exposes capabilities through standard HTTP/gRPC communication\nprotocols. Any programming platform can call Dapr via its native HTTP and gRPC APIs.\n\nThe blue boxes across the center of the figure represent the Dapr building blocks. Each exposes a\ndistributed application capability that your application can consume.\n\nThe bottom row highlights the portability of Dapr and the diverse environments across which it can\nrun.", "Dapr architecture": {"**Building blocks**": "From the new perspective, you see a more detailed view of the Dapr **building blocks** .\n\nA building block encapsulates a distributed infrastructure capability. You can access the functionality\nthrough the HTTP or gRPC APIs. Figure 2-2 shows the available blocks for Dapr v 1.0.\n\n9 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-2. Dapr building blocks._\n\nThe following table describes the infrastructure services provided by each block.\n\n|Building block|Description|\n|---|---|\n|State management|Support contextual information for long running stateful services.|\n|Service invocation|Invoke direct, secure service-to-service calls using platform agnostic protocols<br>and well-known endpoints.|\n|Publish and<br>subscribe|Implement secure, scalable pub/sub messaging between services.|\n\n10 CHAPTER 3 | Dapr at 20,000 feet\n\n|Building block|Description|\n|---|---|\n|Bindings|Trigger code from events raised by external resources with bi-directional<br>communication.|\n|Observability|Monitor and measure message calls across networked services.|\n|Secrets|Securely access external secret stores.|\n|Actors|Encapsulate logic and data in reusable actor objects.|\n\nBuilding blocks abstract the implementation of distributed application capabilities from your services.\nFigure 2-3 shows this interaction.\n\n_Figure 2-3. Dapr building block integration._\n\nBuilding blocks invoke Dapr components that provide the concrete implementation for each resource.\nThe code for your service is only aware of the building block. It takes no dependencies on external\nSDKs or libraries - Dapr handles the plumbing for you. Each building block is independent. You can\nuse one, some, or all of them in your application. As a value-add, Dapr building blocks bake in\nindustry best practices including comprehensive observability.\n\nWe provide detailed explanation and code samples for each Dapr building block in the upcoming\nchapters. At this point, the jet descends even more. From the new perspective, you now have a closer\nlook at the Dapr components layer.", "**Components**": "While building blocks expose an API to invoke distributed application capabilities, Dapr components\nprovide the concrete implementation to make it happen.\n\n11 CHAPTER 3 | Dapr at 20,000 feet\n\nConsider, the Dapr **state store** component. It provides a uniform way to manage state for CRUD\noperations. Without any change to your service code, you could switch between any of the following\nDapr state components:\n\n['AWS DynamoDB', 'Aerospike', 'Azure Blob Storage', 'Azure CosmosDB', 'Azure Table Storage', 'Cassandra', 'Cloud Firestore (Datastore mode)', 'CloudState', 'Couchbase', 'Etcd', 'HashiCorp Consul', 'Hazelcast', 'Memcached', 'MongoDB', 'PostgreSQL', 'Redis', 'RethinkDB', 'SQL Server', 'Zookeeper']\n\nEach component provides the necessary implementation through a common state management\ninterface:\n\nPerhaps you start with Azure Redis Cache as your state store. You specify it with the following\nconfiguration:\n\n12 CHAPTER 3 | Dapr at 20,000 feet\n\n:::{custom-style=CodeBox} yaml apiVersion: dapr.io/v1alpha1 kind: Component metadata:  name:\nstatestore  namespace: default spec:  type: state.redis  version: v1  metadata:  - name: redisHost\nvalue: <HOST>  - name: redisPassword   value: <PASSWORD>  - name: enableTLS   value:\n<bool> # Optional. Allowed: true, false.  - name: failover   value: <bool> # Optional. Allowed: true,\nfalse. :::\n\nIn the **spec** section, you configure Dapr to use the Redis Cache for state management. The section\nalso contains component-specific metadata. In this case, you can use it to configure additional Redis\nsettings.\n\nAt a later time, the application is ready to go to production. For the production environment, you may\nwant to change your state management to Azure Table Storage. Azure Table Storage provides state\nmanagement capabilities that are affordable and highly durable.\n\nAt the time of this writing, the following component types are provided by Dapr:\n\n|Component|Description|\n|---|---|\n|Service<br>discovery|Used by the service invocation building block to integrate with the hosting<br>environment to provide service-to-service discovery.|\n|State|Provides a uniform interface to interact with a wide variety of state store<br>implementations.|\n|Pub/sub|Provides a uniform interface to interact with a wide variety of message bus<br>implementations.|\n|Bindings|Provides a uniform interface to trigger application events from external systems and<br>invoke external systems with optional data payloads.|\n|Middleware|Allows custom middleware to plug into the request processing pipeline and invoke<br>additional actions on a request or response.|\n|Secret stores|Provides a uniform interface to interact with external secret stores, including cloud,<br>edge, commercial, open-source services.|\n\nAs the jet completes its fly over of Dapr, you look back once more and can see how it connects\ntogether.", "**Sidecar architecture**": "[Dapr exposes its building blocks and components through a sidecar architecture. A sidecar enables](https://docs.microsoft.com/azure/architecture/patterns/sidecar)\nDapr to run in a separate memory process or separate container alongside your service. Sidecars\nprovide isolation and encapsulation as they aren\u2019t part of the service, but connected to it. This\nseparation enables each to have its own runtime environment and be built upon different\nprogramming platforms. Figure 2-4 shows a sidecar pattern.\n\n13 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-4. Sidecar architecture._\n\nThis pattern is named Sidecar because it resembles a sidecar attached to a motorcycle. In the previous\nfigure, note how the Dapr sidecar is attached to your service to provide distributed application\ncapabilities.", "**Hosting environments**": "Dapr has cross-platform support and can run in many different environments. These environments\ninclude Kubernetes, a group of VMs, or edge environments such as Azure IoT Edge.\n\n[For local development, the easiest way to get started is with self-hosted mode. In self-hosted mode,](https://docs.dapr.io/concepts/overview/#self-hosted)\nthe microservices and Dapr sidecars run in separate local processes without a container orchestrator\n[such as Kubernetes. For more information, see download and install the Dapr CLI.](https://docs.dapr.io/getting-started/install-dapr-cli/)\n\nFigure 2-5 shows an application and Dapr hosted in two separate memory processes communicating\nvia HTTP or gRPC.\n\n14 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-5. Self-hosted Dapr sidecar._\n\nBy default, Dapr installs Docker containers for Redis and Zipkin to provide default state management\n[and observability. If you don\u2019t want to install Docker on your local machine, you can even run Dapr in](https://docs.dapr.io/operations/hosting/self-hosted/self-hosted-no-docker/)\n[self-hosted mode without any Docker containers. However, you must install default components such](https://docs.dapr.io/operations/hosting/self-hosted/self-hosted-no-docker/)\nas Redis for state management and pub/sub manually.\n\n[Dapr also runs in containerized environments, such as Kubernetes. Figure 2-6 shows Dapr running in a](https://docs.dapr.io/concepts/overview/#kubernetes-hosted)\nseparate side-car container along with the application container in the same Kubernetes pod.\n\n_Figure 2-6. Kubernetes-hosted Dapr sidecar._"}, "Dapr performance considerations": "As you\u2019ve seen, Dapr exposes a sidecar architecture to decouple your application from distributed\napplication capabilities. Invoking a Dapr operation requires at least one out-of-process network call.\nFigure 2-7 presents an example of a Dapr traffic pattern.\n\n15 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-7. Dapr traffic patterns._\n\nLooking at the previous figure, one might question the latency and overhead incurred for each call.\n\nThe Dapr team has invested heavily in performance. A tremendous amount of engineering effort has\ngone into making Dapr efficient. Calls between Dapr sidecars are always made with gRPC, which\ndelivers high performance and small binary payloads. In most cases, the additional overhead should\nbe sub-millisecond.\n\nTo increase performance, developers can call the Dapr building blocks with gRPC.\n\n[gRPC is a modern, high-performance framework that evolves the age-old remote procedure call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call)\nprotocol. gRPC uses HTTP/2 for its transport protocol, which provides significant performance\nenhancements over HTTP RESTFul service, including:\n\n['Multiplexing support for sending multiple parallel requests over the same connection - HTTP 1.1\\nlimits processing to one request/response message at a time.', 'Bidirectional full-duplex communication for sending both client requests and server responses\\nsimultaneously.', 'Built-in streaming enabling requests and responses to asynchronously stream large data sets.']\n\n[To learn more, check out the gRPC overview](https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/grpc#what-is-grpc) [from the Architecting Cloud-Native .NET Apps for Azure](https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/)\neBook.", "Dapr and service meshes": "Service mesh is another rapidly evolving technology for distributed applications.\n\nA service mesh is a configurable infrastructure layer with built-in capabilities to handle service-toservice communication, resiliency, load balancing, and telemetry capture. It moves the responsibility\nfor these concerns out of the services and into the service mesh layer. Like Dapr, a service mesh also\nfollows a sidecar architecture.\n\nFigure 2-8 shows an application that implements service mesh technology.\n\n16 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-8. Service mesh with a side car._\n\nThe previous figure shows how messages are intercepted by a sidecar proxy that runs alongside each\nservice. Each proxy can be configured with traffic rules specific to the service. It understands messages\nand can route them across your services and the outside world.\n\nSo the question becomes, \u201cIs Dapr a service mesh?\u201d.\n\nWhile both use a sidecar architecture, each technology has a different purpose. Dapr provides\ndistributed application features. A service mesh provides a dedicated network infrastructure layer.\n\nAs each works at a different level, both can work together in the same application. For example, a\nservice mesh could provide networking communication between services. Dapr could provide\napplication services such as state management or actor services.\n\nFigure 2-9 shows an application that implements both Dapr and service mesh technology.\n\n17 CHAPTER 3 | Dapr at 20,000 feet\n\n_Figure 2-9. Dapr and service mesh together._\n\n[The Dapr online documentation cover Dapr and service mesh integration.](https://docs.dapr.io/concepts/faq/#networking-and-service-meshes)", "Summary": {"**References**": ["[Dapr documentation](https://dapr.io/)", "[Learning Dapr](https://www.amazon.com/Learning-Dapr-Building-Distributed-Applications/dp/1492072427/ref=sr_1_1?dchild=1&keywords=dapr&qid=1604794794&sr=8-1)", "[.NET Microservices: Architecture for Containerized .NET applications](https://dotnet.microsoft.com/download/thank-you/microservices-architecture-ebook)", "[Architecting Cloud-Native .NET Apps for Azure](https://dotnet.microsoft.com/download/e-book/cloud-native-azure/pdf)"]}}}, "4": {"Get started with Dapr": {"Install Dapr into your local environment": "You\u2019ll start by installing Dapr on your development computer. Once complete, you can build and run\n[Dapr applications in self-hosted mode.](https://docs.dapr.io/operations/hosting/self-hosted/self-hosted-overview/)\n\n['[Install the Dapr CLI. It enables you to launch, run, and manage Dapr instances. It also provides](https://docs.dapr.io/getting-started/install-dapr-cli/)\\ndebugging support.']\n\n['[Install Docker Desktop. If you\u2019re running on Windows, make sure that](https://docs.docker.com/get-docker/) **Docker Desktop for**\\n**Windows** is configured to use Linux containers.']\n\n[!NOTE] By default, Dapr uses Docker containers to provide you the best out-of-the-box\nexperience. To run Dapr outside of Docker, you can skip this step and execute a _[slim](https://docs.dapr.io/operations/hosting/self-hosted/self-hosted-no-docker/)_\n[initialization. The examples in this chapter require you use Docker containers.](https://docs.dapr.io/operations/hosting/self-hosted/self-hosted-no-docker/)\n\n['[Initialize Dapr. This step sets up your development environment by installing the latest Dapr](https://docs.dapr.io/getting-started/install-dapr-selfhost/)\\nbinaries and container images.']\n\n['[Install the .NET 7 SDK.](https://dotnet.microsoft.com/download/dotnet/7.0)']\n\nNow that Dapr is installed, it\u2019s time to build your first Dapr application!", "Build your first Dapr application": {"**Create the application**": ["Open up the command shell or terminal of your choice. You might consider the terminal\n[capabilities in Visual Studio Code. Navigate to the root folder in which you want to build your](https://code.visualstudio.com/)\napplication. Once there, enter the following command to create a new .NET Console application:"]}, "Component configuration files": "When you first initialized Dapr for your local environment, it automatically provisioned a Redis\ncontainer. Dapr then configured the Redis container as the default state store component with a\ncomponent configuration file, entitled `statestore.yaml` . Here\u2019s a look at its contents:\n\nNote the format of the previous component configuration file:\n\n['Each component has a name. In the sample above, the component is named `statestore` . We\\nused that name in our first code example to tell the Dapr sidecar which component to use.', 'Each component configuration file has a `spec` section. It contains a `type` field that specifies the\\ncomponent type. The `version` field specifies the component version. The `metadata` field']\n\n21 CHAPTER 4 | Get started with Dapr\n\ncontains information that the component requires, such as connection details and other settings.\nThe metadata values will vary for the different types of components.\n\nA Dapr sidecar can consume any Dapr component configured in your application. But, what if you had\nan architectural justification to limit the accessibility of a component? How could you restrict the Redis\ncomponent to Dapr sidecars running only in a production environment?\n\nTo do so, you could define a `namespace` for the production environment. You might name it\n\nthat match the namespace. For Kubernetes deployments, the Kubernetes namespace determines the\ncomponents that are loaded. The following sample shows the Redis component placed in a\n\n`production` namespace. Note the `namespace` declaration in the `metadata` element:\n\nIf needed, you could further restrict a component to a particular application. Within the `production`\nnamespace, you may want to limit access of the Redis cache to only the `DaprCounter` application. You\n\nnamespace:\n\n22 CHAPTER 4 | Get started with Dapr", "Build a multi-container Dapr application": {"**Create the application**": ["In Visual Studio 2022, create an **ASP.NET Core Web App** project:"], "**Add container support**": "In the final part of this example, you\u2019ll add container support and run the solution using Docker\nCompose.\n\n['Right-click the `MyFrontEnd` project, and choose **Add** - **Container Orchestrator Support\u2026** . The\\n**Add Container Orchestrator Support** dialog appears:']\n\n```\nChoose **Docker Compose**.\n\n```\n\n['In the next dialog, select **Linux** as the Target OS:']\n\n29 CHAPTER 4 | Get started with Dapr\n\n```\nVisual Studio creates a *docker-compose.yml*file and a *.dockerignore* file in the\n**docker-compose** folder in the solution:\n\n```\n\n30 CHAPTER 4 | Get started with Dapr\n\n```\nThe *docker-compose.yml* file has the following content:\n\nThe *.dockerignore* file contains file types and extensions that you don't want Docker\nto include in the container. These files are associated with the development\nenvironment and source control and not the app or service you're deploying.\n\n```\n\n31 CHAPTER 4 | Get started with Dapr\n\n```\nIn the root of the *MyFrontEnd* project directory, a new *Dockerfile* was created. A\n*Dockerfile* is a sequence of commands that are used to build an image. For more\ninformation, see [Dockerfile\nreference](https://docs.docker.com/engine/reference/builder).\n\nThe *Dockerfile* contains the following commands:\n\nThe preceding *Dockerfile* sequentially performs the following steps when invoked:\n\n1. Pulls the [`mcr.microsoft.com/dotnet/aspnet:7.0`]{custom-style=Code} image and\nnames it [`base`]{custom-style=Code}.\n2. Sets the working directory to */app*.\n3. Exposes port [`80`]{custom-style=Code} and [`443`]{custom-style=Code}.\n4. Pulls the [`mcr.microsoft.com/dotnet/sdk:7.0`]{custom-style=Code} image and names\nit [`build`]{custom-style=Code}.\n5. Sets the working directory to */src*.\n6. Copies the _MyFrontEnd/MyFrontEnd.csproj_ to a new directory named *MyFrontEnd/*.\n7. Calls [[`dotnet restore`]{custom-style=Code}](https://docs.microsoft.com/enus/dotnet/core/tools/dotnet-restore) on the project.\n8. Copies everything from the root directory into the image's root.\n9. Sets the working directory to _/src/MyFrontEnd_.\n10. Calls [[`dotnet build`]{custom-style=Code}](https://docs.microsoft.com/enus/dotnet/core/tools/dotnet-build) on the project.\n- Targeting the **Release** configuration and outputs to */app/build*.\n11. Initializes a new build stage from the existing [`build`]{custom-style=Code} base\nimage and names it [`publish`]{custom-style=Code}.\n12. Calls [`dotnet publish`]{custom-style=Code} on the project.\n- Targeting the **Release** configuration and outputs to */app/publish*.\n13. Initializes a new build stage from the existing [`publish`]{custom-style=Code}\nbase image and names it [`final`]{custom-style=Code}.\n14. Sets the working directory to */app*.\n15. Copies the [`/app/publish`]{custom-style=Code} directory from the\n[`publish`]{custom-style=Code} image into the root of the [`final`]{custom-style=Code}\nimage.\n16. Sets the entry point as the image to [`dotnet`]{custom-style=Code} and passes the\n[`MyFrontEnd.dll`]{custom-style=Code} as an arg.\n\n```\n\n32 CHAPTER 4 | Get started with Dapr\n\n['In the `MyBackEnd` web API project, right-click on the project node, and choose **Add** - **Container**\\n**Orchestrator Support\u2026** . Choose **Docker Compose**, and then select **Linux** again as the target\\nOS.']\n\nIn the root of the _MyBackEnd_ project directory, a new _Dockerfile_ was created. The _Dockerfile_\ncontains the following commands:\n\n```\nOpen the *docker-compose.yml* file again and examine its contents. Visual Studio has\nupdated the **Docker Compose** file. Now both services are included:\n\n```\n\n['To use Dapr building blocks from inside a containerized application, you\u2019ll need to add the Dapr\\nsidecars containers to your Compose file. Carefully update the content of the _docker-_\\n_compose.yml_ file to match the following example. Pay close attention to the formatting and\\nspacing and don\u2019t use tabs.']\n\n33 CHAPTER 4 | Get started with Dapr\n\n```\nIn the updated file, we've added [`myfrontend-dapr`]{custom-style=Code} and\n[`mybackend-dapr`]{custom-style=Code} sidecars for the [`myfrontend`]{customstyle=Code} and [`mybackend`]{custom-style=Code} services respectively. In the updated\nfile, pay close attention to the following changes:\n\n- The sidecars use the [`daprio/daprd:latest`]{custom-style=Code} container image. The\nuse of the [`latest`]{custom-style=Code} tag isn't recommended for production\nscenarios. For production, it's better to use a specific version number.\n- Each service defined in the Compose file has its own network namespace for network\nisolation purposes. The sidecars use [`network_mode: \"service:...\"`]{customstyle=Code} to ensure they run in the same network namespace as the application. Doing\nso allows the sidecar and the application to communicate using [`localhost`]{customstyle=Code}.\n- The ports on which the Dapr sidecars are listening for gRPC communication (by\ndefault 50001) must be exposed to allow the sidecars to communicate with each other.\n\n```\n\n['Run the solution (F5 or Ctrl+F5) to verify that it works as expected. If everything is configured\\ncorrectly, you should see the weather forecast data:']\n\n34 CHAPTER 4 | Get started with Dapr\n\n```\nRunning locally with Docker Compose and Visual Studio, you can set breakpoints and\ndebug into the application. For production scenarios, it's recommended to host your\napplication in Kubernetes. This book includes an accompanying reference application,\n[eShopOnDapr](https://github.com/dotnet-architecture/eShopOnDapr), that contains\nscripts to deploy to Kubernetes.\n\nTo learn more about the Dapr service invocation building block used in this\nwalkthrough, refer to [chapter 6](#the-dapr-service-invocation-building-blo).\n\n### Summary\n\n```\n\nIn this chapter, you had an opportunity to _test drive_ Dapr. Using the Dapr .NET SDK, you saw how\nDapr integrates with the .NET application platform.\n\nThe first example was a simple, stateful, .NET Console application that used the Dapr state\nmanagement building block.\n\nThe second example involved a multi-container application running in Docker. By using Visual Studio\nwith Docker Compose, you experienced the familiar _F5 debugging experience_ available across all .NET\napps.\n\nYou also got a closer look at Dapr component configuration files. They configure the actual\ninfrastructure implementation used by the Dapr building blocks. You can use namespaces and scopes\nto restrict component access to particular environments and applications.\n\nIn the upcoming chapters, you\u2019ll dive deep into the building blocks offered by Dapr.", "**References**": ["[Dapr documentation - Getting started](https://docs.dapr.io/getting-started)", "[eShopOnDapr](https://github.com/dotnet-architecture/eShopOnDapr)"]}}}, "5": {"Traffic Control sample application": {"Using Dapr building blocks": "One of the goals of Dapr is to provide cloud-native capabilities for microservices applications. The\nTraffic Control application uses Dapr building blocks to increase robustness and mitigate the design\ndrawbacks described in the previous paragraph. Figure 4.shows a Dapr-enabled version of the traffic\ncontrol application:\n\n_Figure 4-3. Traffic Control application with Dapr building blocks._\n\n['**Service invocation** The Dapr service invocation building block handles request/response\\ncommunication between the FineCollectionService and the VehicleRegistrationService. Because\\nthe call is a query to retrieve required data to complete the operation, a synchronous call is\\nacceptable here. The service invocation building block provides service discovery. The\\nFineCollection service no longer has to know where the VehicleRegistration service lives. It also\\nimplements automatic retries if the VehicleRegistration service is off-line.', '**Publish & subscribe** The publish and subscribe building block handles asynchronous messaging\\nfor sending speeding violations from the TrafficControl service to the FineCollectionService. This\\nimplementation decouples the TrafficControl and FineCollection service. If the\\nFineCollectionService were to become temporarily unavailable, data would accumulate in the\\nqueue and resume processing at a later time. RabbitMQ is the current message broker that\\ntransports messages from the producers to the consumers. As the Dapr pub/sub building block\\nabstracts the message broker, developers don\u2019t need to learn the details of the RabbitMQ client\\nlibrary. Switching to another message broker doesn\u2019t require code changes, only configuration.']\n\n['**State management** The TrafficControl service uses the state management building block to\\npersist vehicle state outside of the service in a Redis cache. As with pub/sub, developers don\u2019t\\nneed to learn Redis specific APIs. Switching to another data store requires no code changes.', '**Output binding** The FineCollection service sends fines to the owners of speeding vehicles by\\nemail. The Dapr output binding for SMTP abstracts the email transmission using the SMTP\\nprotocol.', '**Input binding** The CameraSimulation sends messages with simulated car info to the\\nTrafficControl service using the MQTT protocol. It uses a .NET MQTT library for sending\\nmessages to Mosquitto - a lightweight MQTT broker. The TrafficControl service uses the Dapr\\ninput binding for MQTT to subscribe to the MQTT broker and receive messages.', '**Secrets management** The FineCollectionService needs credentials for connecting to the smtp\\nserver and a license-key for a fine calculator component it uses internally. It uses the secrets\\nmanagement building block to obtain the credentials and the license-key.']\n\n39 CHAPTER 5 | Traffic Control sample application\n\n['**Actors** The TrafficControlService has an alternative implementation based on Dapr actors. In this\\nimplementation, the TrafficControl service creates a new actor for every vehicle that is registered\\nby the entry camera. The license number of the vehicle forms the unique actor Id. The actor\\nencapsulates the vehicle state, which it persists in the Redis cache. When a vehicle is registered\\nby the exit camera, it invokes the actor. The actor then calculate the average speed and possibly\\nissue a speeding violation.']\n\nFigure 4.4 shows a sequence diagram of the flow of the simulation with all the Dapr building blocks in\nplace:\n\n_Figure 4-4. Sequence diagram of simulation flow with Dapr building blocks._\n\nThe rest of this book features a chapter for each of the Dapr building blocks. Each chapter explains in\ndetail how the building block works, its configuration, and how to use it. Each chapter explains how\nthe Traffic Control sample application uses the building block.", "Hosting": {"**Self-hosted mode**": "The sample repository contains PowerShell scripts to start the infrastructure services (Redis,\nRabbitMQ, and Mosquitto) as Docker containers on your machine. They\u2019re located in the\n\n`src/Infrastructure` folder. For every application service in the solution, the repository contains a\nseparate folder. Each of these folders contains a `start-selfhosted.ps1` PowerShell script to start the\nservice with Dapr.\n\n40 CHAPTER 5 | Traffic Control sample application", "**Kubernetes**": "The `src/k8s` folder in the sample repository contains the Kubernetes manifest files to run the\napplication (including the infrastructure services) with Dapr in Kubernetes. This folder also contains a"}, "Summary": {"**References**": ["[Dapr Traffic Control Sample](https://github.com/EdwinVW/dapr-traffic-control)"]}}}, "6": {"The Dapr state management building block": {"What it solves": "Tracking state in a distributed application can be challenging. For example:\n\n['The application may require different types of data stores.', 'Different consistency levels may be required for accessing and updating data.', 'Multiple users may update data at the same time, requiring conflict resolution.', '[Services must retry any short-lived transient errors](https://docs.microsoft.com/aspnet/aspnet/overview/developing-apps-with-windows-azure/building-real-world-cloud-apps-with-windows-azure/transient-fault-handling) that occur while interacting with the data\\nstore.']\n\nThe Dapr state management building block addresses these challenges. It streamlines tracking state\nwithout dependencies or a learning curve on third-party storage SDKs.\n\n42 CHAPTER 6 | The Dapr state management building block", "How it works": {"**Consistency**": "[The CAP theorem](https://en.wikipedia.org/wiki/CAP_theorem) is a set of principles that apply to distributed systems that store state. Figure 5-2\nshows the three properties of the CAP theorem.\n\n43 CHAPTER 6 | The Dapr state management building block\n\n:::image type=\u201ccontent\u201d source=\u201c./media/state-management/cap-theorem.png\u201d alt-text=\u201cThe CAP\ntheorem.\u201d:::\n\n_Figure 5-2. The CAP theorem._\n\nThe theorem states that distributed data systems offer a trade-off between consistency, availability,\nand partition tolerance. And, that any datastore can only _guarantee two of the three properties_ :\n\n['_Consistency_ ( **C** ). Every node in the cluster responds with the most recent data, even if the system\\nmust block the request until all replicas update. If you query a \u201cconsistent system\u201d for an item\\nthat is currently updating, you won\u2019t get a response until all replicas successfully update.\\nHowever, you\u2019ll always receive the most current data.']\n\n['_Availability_ ( **A** ). Every node returns an immediate response, even if that response isn\u2019t the most\\nrecent data. If you query an \u201cavailable system\u201d for an item that is updating, you\u2019ll get the best\\npossible answer the service can provide at that moment.']\n\n['_Partition Tolerance_ ( **P** ). Guarantees the system continues to operate even if a replicated data\\nnode fails or loses connectivity with other replicated data nodes.']\n\nDistributed applications must handle the **P** property. As services communicate among each other with\nnetwork calls, network disruptions ( **P** ) will occur. With that in mind, distributed applications must\neither be **AP** or **CP** .\n\n**AP** applications choose availability over consistency. Dapr supports this choice with its **eventual**\n**consistency** strategy. Consider an underlying data store, such as Azure CosmosDB, which stores\nredundant data on multiple replicas. With eventual consistency, the state store writes the update to\none replica and completes the write request with the client. After this time, the store will\nasynchronously update its replicas. Read requests can return data from any of the replicas, including\nthose replicas that haven\u2019t yet received the latest update.\n\n**CP** applications choose consistency over availability. Dapr supports this choice with its **strong**\n**consistency** strategy. In this scenario, the state store will synchronously update _all_ (or, in some cases,\na _quorum_ of) required replicas _before_ completing the write request. Read operations will return the\nmost up-to-date data consistently across replicas.\n\nThe consistency level for a state operation is specified by attaching a _consistency hint_ to the operation.\nThe following _curl_ command writes a `Hello=World` key/value pair to a state store using a strong\nconsistency hint:\n\n44 CHAPTER 6 | The Dapr state management building block", "**Concurrency**": "In a multi-user application, there\u2019s a chance that multiple users will update the same data concurrently\n(at the same time). Dapr supports optimistic concurrency control (OCC) to manage conflicts. OCC is\nbased on an assumption that update conflicts are uncommon because users work on different parts of\nthe data. It\u2019s more efficient to assume an update will succeed and retry if it doesn\u2019t. The alternative,\nimplementing pessimistic locking, can affect performance with long-running locking causing data\ncontention.\n\nDapr supports optimistic concurrency control (OCC) using ETags. An ETag is a value associated with a\nspecific version of a stored key/value pair. Each time a key/value pair updates, the ETag value updates\nas well. When a client retrieves a key/value pair, the response includes the current ETag value. When a\nclient updates or deletes a key/value pair, it must send that ETag value back in the request body. If\nanother client has updated the data in the meantime, the ETags won\u2019t match and the request will fail.\nAt this point, the client must retrieve the updated data, make the change again, and resubmit the\nupdate. This strategy is called **first-write-wins** .\n\nDapr also supports a **last-write-wins** strategy. With this approach, the client doesn\u2019t attach an ETag\nto the write request. The state store component will always allow the update, even if the underlying\nvalue has changed during the session. Last-write-wins is useful for high-throughput write scenarios\nwith low data contention. As well, overwriting an occasional user update can be tolerated.", "**Transactions**": "Dapr can write _multi-item changes_ to a data store as a single operation implemented as a transaction.\n[This functionality is only available for data stores that support ACID](https://en.wikipedia.org/wiki/ACID) transactions. At the time of this\nwriting, these stores include Redis, MongoDB, PostgreSQL, SQL Server, and Azure CosmosDB.\n\nIn the example below, a multi-item operation is sent to the state store in a single transaction. All\noperations must succeed for the transaction to commit. If one or more of the operations fail, the\nentire transaction rolls back.\n\n45 CHAPTER 6 | The Dapr state management building block\n\nFor data stores that don\u2019t support transactions, multiple keys can still be sent as a single request. The\nfollowing example shows a **bulk** write operation:\n\nFor bulk operations, Dapr will submit each key/value pair update as a separate request to the data\nstore."}, "Use the Dapr .NET SDK": {"**ASP.NET Core integration**": "Dapr also supports ASP.NET Core, a cross-platform framework for building modern cloud-based web\n[applications. The Dapr SDK integrates state management capabilities directly into the ASP.NET Core](https://docs.microsoft.com/aspnet/core/mvc/models/model-binding)\n[model binding](https://docs.microsoft.com/aspnet/core/mvc/models/model-binding) capabilities. Configuration is simple. In the `Program.cs` file, call the following extension\nmethod on the `WebApplication` builder:\n\nOnce configured, Dapr can inject a key/value pair directly into a controller action using the ASP.NET\nCore `FromState` attribute. Referencing the `DaprClient` object is no longer necessary. The next\nexample shows a Web API that returns the weather forecast for a given city:\n\nIn the example, the controller loads the weather forecast using the `FromState` attribute. The first\nattribute parameter is the state store, `statestore` . The second attribute parameter, `city`, is the name\n[of the route template variable to get the state key. If you omit the second parameter, the name of the](https://docs.microsoft.com/aspnet/core/mvc/controllers/routing#route-templates)\nbound method parameter ( `forecast` ) is used to look up the route template variable.\n\ncontrol (OCC) strategy. The class also provides methods to delete or update retrieved key/value data\nwithout requiring a `DaprClient` instance. In the next example, the `TrySaveAsync` method is used to\nupdate the retrieved weather forecast using OCC."}, "State store components": {"**Configuration**": "When initialized for local, self-hosted development, Dapr registers Redis as the default state store.\nHere\u2019s an example of the default state store configuration. Note the default name, `statestore` :\n\n48 CHAPTER 6 | The Dapr state management building block\n\n[!NOTE] Many state stores can be registered to a single application each with a different name.\n\nThe Redis state store requires `redisHost` and `redisPassword` metadata to connect to the Redis\ninstance. In the example above, the Redis password (which is an empty string by default) is stored as a\nplain string. The best practice is to avoid clear-text strings and always use secret references. To learn\nmore about secret management, see chapter 10.\n\nThe other metadata field, `actorStateStore`, indicates whether the state store can be consumed by\nthe actors building block.", "**Key prefix strategies**": "State store components enable different strategies to store key/value pairs in the underlying store.\nRecall the earlier example of a shopping basket service storing items a customer wishes to purchase:\n\nUsing the Redis Console tool, look inside the Redis cache to see how the Redis state store component\npersisted the data:\n\nconvention enables multiple Dapr instances to share the same data store without key name collisions.\nFor the developer, it\u2019s critical always to specify the same `application id` when running the\napplication with Dapr. If omitted, Dapr will generate a unique application ID. If the `application id`\nchanges, the application can no longer access the state stored with the previous key prefix.\n\nThat said, it\u2019s possible to configure a _constant value_ for the key prefix in the `keyPrefix` metadata field\nin the state store component file. Consider the following example:\n\n49 CHAPTER 6 | The Dapr state management building block\n\nA constant key prefix enables the state store to be accessed across multiple Dapr applications. What\u2019s\nmore, setting the `keyPrefix` to `none` omits the prefix completely."}, "Sample application: Dapr Traffic Control": "In the Dapr Traffic Control sample app, the TrafficControl service uses the Dapr state management\nbuilding block to persist the entry and exit timestamps of each passing vehicle. Figure 5-3 shows the\nconceptual architecture of the Dapr Traffic Control sample application. The Dapr state management\nbuilding block is used in flows marked with number 3 in the diagram:\n\n:::image type=\u201ccontent\u201d source=\u201c./media/state-management/dapr-solution-state-management.png\u201d\nalt-text=\u201cConceptual architecture of the Dapr Traffic Control sample application.\u201d:::\n\n_Figure 5-3. Conceptual architecture of the Dapr Traffic Control sample application._\n\nEntry and exit event logic is handled by the `TrafficController` class, an ordinary ASP.NET Controller.\nThe `TrafficController.VehicleEntry` method accepts an incoming `VehicleRegistered` message\nand saves the enclosed vehicle state:\n\n50 CHAPTER 6 | The Dapr state management building block\n\nto save the state to the configured Dapr state store. It uses the vehicle\u2019s license number as the key.\nThe application can retrieve the saved state by calling the `GetVehicleStateAsync` method.\n\nThe TrafficControl service uses Redis as its underlying data store. Looking at the code, you\u2019d never\nknow it. A service consuming the Dapr state management building block doesn\u2019t directly reference\nany state components. Instead, a Dapr component configuration file specifies the store:\n\nThe `type` element in the configuration, `state.redis` instructs the building block to manage state with\nDapr Redis component.\n\nThe `scopes` element in the configuration _constrains_ application access to the state store component.\nOnly the TrafficControl service can access the state store.", "Summary": {"**References**": ["[Dapr supported state stores](https://docs.dapr.io/reference/components-reference/supported-state-stores/)"]}}}, "7": {"The Dapr service invocation building block": {"What it solves": "Making calls between services in a distributed application may appear easy, but there are many\nchallenges involved. For example:\n\n['Where the other services are located.', 'How to call a service securely, given the service address.', '[How to handle retries when short-lived transient errors](https://docs.microsoft.com/aspnet/aspnet/overview/developing-apps-with-windows-azure/building-real-world-cloud-apps-with-windows-azure/transient-fault-handling) occur.']\n\nLastly, as distributed applications compose many different services, capturing insights across service\ncall graphs are critical to diagnosing production issues.\n\n[The service invocation building block addresses these challenges by using a Dapr sidecar as a reverse](https://kemptechnologies.com/reverse-proxy/reverse-proxy/)\n[proxy](https://kemptechnologies.com/reverse-proxy/reverse-proxy/) for your service.", "How it works": "Let\u2019s start with an example. Consider two services, \u201cService A\u201d and \u201cService B\u201d. Service A needs to call\nthe `catalog/items` API on Service B. While Service A could take a dependency on Service B and make\na direct call to it, Service A instead invokes the service invocation API on the Dapr sidecar. Figure 6-1\nshows the operation.\n\n53 CHAPTER 7 | The Dapr service invocation building block\n\n_Figure 6-1. How Dapr service invocation works._\n\nNote the steps from the previous figure:\n\n['Service A makes a call to the `catalog/items` endpoint in Service B by invoking the service\\ninvocation API on the Service A sidecar.']\n\n[!NOTE] The sidecar uses a pluggable name resolution component to resolve the address of\n[Service B. In self-hosted mode, Dapr uses mDNS](https://www.ionos.com/digitalguide/server/know-how/multicast-dns/) to find it. When running in Kubernetes mode,\nthe Kubernetes DNS service determines the address.\n\n['The Service A sidecar forwards the request to the Service B sidecar.']\n\n['The Service B sidecar makes the actual `catalog/items` request against the Service B API.']\n\n['Service B executes the request and returns a response back to its sidecar.']\n\n['The Service B sidecar forwards the response back to the Service A sidecar.']\n\n['The Service A sidecar returns the response back to Service A.']\n\nBecause the calls flow through sidecars, Dapr can inject some useful cross-cutting behaviors:\n\n['Automatically retry calls upon failure.', 'Make calls between services secure with mutual (mTLS) authentication, including automatic\\ncertificate rollover.', 'Control what operations clients can do using access control policies.', 'Capture traces and metrics for all calls between services to provide insights and diagnostics.']\n\n54 CHAPTER 7 | The Dapr service invocation building block\n\nAny application can invoke a Dapr sidecar by using the native **invoke** API built into Dapr. The API can\nbe called with either HTTP or gRPC. Use the following URL to call the HTTP API:\n\n```\nhttp://localhost:<dapr-port>/v1.0/invoke/<application-id>/method/<method-name>\n\n```\n\nIn the following example, a _curl_ call is made to the `catalog/items` \u2018GET\u2019 endpoint of `Service B` :\n\n```\ncurl http://localhost:3500/v1.0/invoke/serviceb/method/catalog/items\n\n```\n\nIn the next section, you\u2019ll learn how to use the .NET SDK to simplify service invocation calls.", "Use the Dapr .NET SDK": {"**Invoke HTTP services using HttpClient**": "rewrites URIs of outgoing requests. The host name is interpreted as the application ID of the service to\ncall. The rewritten request that\u2019s actually being called is:\n\n```\nhttp://127.0.0.1:3500/v1/invoke/orderservice/method/submit\n\n```\n\n55 CHAPTER 7 | The Dapr service invocation building block\n\nAlternatively, you can configure a custom endpoint in the call to\n\n`DaprClient.CreateInvokeHttpClient` :\n\n```\nvar httpClient = DaprClient.CreateInvokeHttpClient(daprEndpoint: \"localhost:4000\");\n\n```\n\nYou can also directly set the base address by specifying the application ID. Doing so enables relative\nURIs when making a call:\n\nreuses a Dapr `HttpClient` instance:\n\nIn the snippet above, the `OrderServiceClient` is registered as a singleton with the ASP.NET Core\n\nwill be reused for the lifetime of the application.\n\nThe `OrderServiceClient` itself has no Dapr-specific code. Even though Dapr service invocation is\nused under the hood, you can treat the Dapr HttpClient like any other HttpClient:\n\nUsing the HttpClient class with Dapr service invocation has many benefits:\n\n['HttpClient is a well-known class that many developers already use in their code. Using HttpClient\\nfor Dapr service invocation allows developers to reuse their existing skills.', 'HttpClient supports advanced scenarios, such as custom headers, and full control over request\\nand response messages.', 'In .NET 5, HttpClient supports automatic serialization and deserialization using System.Text.Json.', '[HttpClient integrates with many existing frameworks and libraries, such as Refit, RestSharp, and](https://github.com/reactiveui/refit)\\n[Polly.](https://github.com/App-vNext/Polly)']\n\n56 CHAPTER 7 | The Dapr service invocation building block", "**Invoke HTTP services using DaprClient**": "While HttpClient is the preferred way to invoke services using HTTP semantics, you can also use the\n\nThe third argument, an `order` object, is serialized internally (with `System.Text.JsonSerializer` ) and\nsent as the request payload. The .NET SDK takes care of the call to the sidecar. It also deserializes the\nresponse to an `OrderConfirmation` object. Because no HTTP method is specified, the request is\nexecuted as an HTTP POST.\n\nThe next example demonstrates how you can make an HTTP GET request by specifying the\n\n`HttpMethod` :\n\nFor some scenarios, you may require more control over the request message. For example, when you\nneed to specify request headers, or you want to use a custom serializer for the payload.\n\n`DaprClient.CreateInvokeMethodRequest` creates an `HttpRequestMessage` . The following example\ndemonstrates how to add an HTTP authorization header to a request message:\n\nThe `HttpRequestMessage` now has the following properties set:\n\n['Url = `http://127.0.0.1:3500/v1.0/invoke/orderservice/method/submit`', 'HttpMethod = POST', 'Content = `JsonContent` object containing the JSON-serialized `order`', 'Headers.Authorization = \u201cbearer <token>\u201d']\n\nOnce you\u2019ve got the request set up the way you want, use `DaprClient.InvokeMethodAsync` to send it:\n\n```\nvar orderConfirmation = await daprClient.InvokeMethodAsync<OrderConfirmation>(request);\n\n```\n\n57 CHAPTER 7 | The Dapr service invocation building block", "**Invoke gRPC services using DaprClient**": "DaprClient provides a family of `InvokeMethodGrpcAsync` methods for calling gRPC endpoints. The\nmain difference with the HTTP methods is the use of a Protobuf serializer instead of JSON. The\nfollowing example invokes the `submitOrder` method of the `orderservice` over gRPC.\n\nIn the example above, DaprClient serializes the given `order` [object using Protobuf](https://developers.google.com/protocol-buffers) and uses the result\nas the gRPC request body. Likewise, the response body is Protobuf deserialized and returned to the\ncaller. Protobuf typically provides better performance than the JSON payloads used in HTTP service\ninvocation."}, "Name resolution components": {"**Configuration**": "To use a non-default name resolution component, add a `nameResolution` spec to the application\u2019s\nDapr configuration file. Here\u2019s an example of a Dapr configuration file that enables HashiCorp Consul\nname resolution:\n\n58 CHAPTER 7 | The Dapr service invocation building block"}, "Sample application: Dapr Traffic Control": "In Dapr Traffic Control sample app, the FineCollection service uses the Dapr service invocation\nbuilding block to retrieve vehicle and owner information from the VehicleRegistration service. Figure\n6-2 shows the conceptual architecture of the Dapr Traffic Control sample application. The Dapr service\ninvocation building block is used in flows marked with number 1 in the diagram:\n\n:::image type=\u201ccontent\u201d source=\u201c./media/service-invocation/dapr-solution-service-invocation.png\u201d\nalt-text=\u201cConceptual architecture of the Dapr Traffic Control sample application.\u201d:::\n\n_Figure 6-2. Conceptual architecture of the Dapr Traffic Control sample application._\n\nservice invocation building block to call to the VehicleRegistration service. The code snippet is\npresented below.\n\n:::{custom-style=CodeBox} ```csharp [Topic(\u201cpubsub\u201d, \u201cspeedingviolations\u201d)] [Route(\u201ccollectfine\u201d)]\n\n[HttpPost] public async Task CollectFine(SpeedingViolation speedingViolation, [FromServices]\nDaprClient daprClient) { // \u2026\n\n```\n// get owner info (Dapr service invocation)\nvar vehicleInfo =\n_vehicleRegistrationService.GetVehicleInfo(speedingViolation.VehicleId).Result;\n\n// ...\n\n```\n\n} ``` :::\n\nThe code uses a proxy of type `VehicleRegistrationService` to call the VehicleRegistration service.\nASP.NET Core injects an instance of the service proxy using constructor injection:\n\n:::{custom-style=CodeBox} csharp public CollectionController(   ILogger<CollectionController>\nlogger,   IFineCalculator fineCalculator,   VehicleRegistrationService vehicleRegistrationService,\nDaprClient daprClient) {   // ... } :::\n\n:::{custom-style=CodeBox} ```csharp public class VehicleRegistrationService { private HttpClient\n_httpClient; public VehicleRegistrationService(HttpClient httpClient) { _httpClient = httpClient; }\n\n```\npublic async Task<VehicleInfo> GetVehicleInfo(string licenseNumber)\n{\nreturn await _httpClient.GetFromJsonAsync<VehicleInfo>(\n\n```\n\n59 CHAPTER 7 | The Dapr service invocation building block\n\n```\n$\"vehicleinfo/{licenseNumber}\");\n}\n\n```\n\n} ``` :::\n\nThe code doesn\u2019t depend on any Dapr classes directly. It instead leverages the Dapr ASP.NET Core\n\nThe `DaprClient.CreateInvokeHttpClient` creates an `HttpClient` instance that calls the\nVehicleRegistration service using the service invocation building block under the covers. It expects\n\nsidecar.\n\nUsing Dapr service invocation in the Traffic Control sample application provides several benefits:\n\n['Decouples the location of the target service.', 'Adds resiliency with automatic retry features.', 'Ability to reuse an existing `HttpClient` based proxy (offered by the ASP.NET Core integration).']", "Summary": {"**References**": ["[Dapr service invocation building block](https://docs.dapr.io/developing-applications/building-blocks/service-invocation/)"]}}}, "8": {"The Dapr publish & subscribe building block": {"What it solves": "The primary advantage of the Publish-Subscribe pattern is **loose coupling**, sometimes referred to as\n[temporal decoupling. The pattern decouples services that send messages (the](https://docs.microsoft.com/azure/architecture/guide/technology-choices/messaging#decoupling) **publishers** ) from\nservices that consume messages (the **subscribers** ). Both publishers and subscribers are unaware of\neach other - both are dependent on a centralized **message broker** that distributes the messages.\n\nFigure 7-1 shows the high-level architecture of the pub/sub pattern.\n\n_Figure 7-1. The pub/sub pattern._\n\nFrom the previous figure, note the steps of the pattern:\n\n['Publishers send messages to the message broker.', 'Subscribers bind to a subscription on the message broker.']\n\n61 CHAPTER 8 | The Dapr publish & subscribe building block\n\n['The message broker forwards a copy of the message to interested subscriptions.', 'Subscribers consume messages from their subscriptions.']\n\nMost message brokers encapsulate a queueing mechanism that can persist messages once received.\nWith it, the message broker guarantees **durability** by storing the message. Subscribers don\u2019t need to\nbe immediately available or even online when a publisher sends a message. Once available, the\nsubscriber receives and processes the message. Dapr guarantees **At-Least-Once** semantics for\nmessage delivery. Once a message is published, it will be delivered at least once to any interested\nsubscriber.\n\nThere are several message broker products available - both commercially and open-source. Each has\nadvantages and drawbacks. Your job is to match your system requirements to the appropriate broker.\nOnce selected, it\u2019s a best practice to decouple your application from message broker plumbing. You\nachieve this functionality by wrapping the broker inside an _abstraction_ . The abstraction encapsulates\nthe message plumbing and exposes generic pub/sub operations to your code. Your code\ncommunicates with the abstraction, not the actual message broker. While a wise decision, you\u2019ll have\nto write and maintain the abstraction and its underlying implementation. This approach requires\ncustom code that can be complex, repetitive, and error-prone.\n\nThe Dapr publish & subscribe building block provides the messaging abstraction and implementation\nout-of-the-box. The custom code you would have had to write is prebuilt and encapsulated inside the\nDapr building block. You bind to it and consume it. Instead of writing messaging plumbing code, you\nand your team focus on creating business functionality that adds value to your customers.", "How it works": {"**Competing consumers**": "When scaling out an application that subscribes to a topic, you have to deal with competing\nconsumers. Only one application instance should handle a message sent to the topic. Luckily, Dapr\nhandles that problem. When multiple instances of a service with the same application-id subscribe to\na topic, Dapr delivers each message to only one of them."}, "Use the Dapr .NET SDK": "and easy to use.\n\nTo publish a message, the `DaprClient` exposes a `PublishEventAsync` method.\n\n['The first argument `pubsub` is the name of the Dapr component that provides the message broker\\nimplementation. We\u2019ll address components later in this chapter.', 'The second argument `neworder` provides the name of the topic to send the message to.', 'The third argument is the payload of the message.', 'You can specify the .NET type of the message using the generic type parameter of the method.']\n\n66 CHAPTER 8 | The Dapr publish & subscribe building block\n\nTo receive messages, you bind an endpoint to a subscription for a registered topic. The AspNetCore\nlibrary for Dapr makes this trivial. Assume, for example, that you have an existing ASP.NET WebAPI\naction method entitled `CreateOrder` :\n\nTo bind this action method to a topic, you decorate it with the `Topic` attribute:\n\nYou specify two key elements with this attribute:\n\n['The Dapr pub/sub component to target (in this case `pubsub` ).', 'The topic to subscribe to (in this case `newOrder` ).']\n\nDapr then invokes that action method as it receives messages for that topic.\n\nYou\u2019ll also need to enable ASP.NET Core to use Dapr. The Dapr .NET SDK provides several extension\nmethods that can be used to do this.\n\nIn the `Program.cs` file, you must call the following extension method on the `WebApplication` builder\nto register Dapr:\n\nAppending the `AddDapr` extension method to the `AddControllers` extension method registers the\nnecessary services to integrate Dapr into the MVC pipeline. It also registers a `DaprClient` instance\ninto the dependency injection container, which then can be injected anywhere into your service.\n\nAfter the `WebApplication` has been created, you must add the following middleware components to\nenable Dapr:\n\nThe call to `UseCloudEvents` adds **CloudEvents** middleware into to the ASP.NET Core middleware\npipeline. This middleware will unwrap requests that use the CloudEvents structured format, so the\nreceiving method can read the event payload directly.\n\n67 CHAPTER 8 | The Dapr publish & subscribe building block\n\nThe call to `MapSubscribeHandler` in the endpoint routing configuration will add a Dapr subscribe\nendpoint to the application. This endpoint will respond to requests on `/dapr/subscribe` . When this\nendpoint is called, it will automatically find all WebAPI action methods decorated with the `Topic`\nattribute and instruct Dapr to create subscriptions for them.", "Pub/sub components": {"**Configuration**": "Using a Dapr configuration file, you can specify the pub/sub component(s) to use. This configuration\ncontains several fields. The `name` field specifies the pub/sub component that you want to use. When\nsending or receiving a message, you need to specify this name (as you saw earlier in the\n\n`PublishEventAsync` method signature).\n\n68 CHAPTER 8 | The Dapr publish & subscribe building block\n\nBelow you see an example of a Dapr configuration file for configuring a RabbitMQ message broker\ncomponent:\n\nIn this example, you can see that you can specify any message broker-specific configuration in the\n\n`metadata` block. In this case, RabbitMQ is configured to create durable queues. But the RabbitMQ\ncomponent has more configuration options. Each of the components\u2019 configuration will have its own\n[set of possible fields. You can read which fields are available in the documentation of each pub/sub](https://docs.dapr.io/operations/components/setup-pubsub/supported-pubsub/)\n[component.](https://docs.dapr.io/operations/components/setup-pubsub/supported-pubsub/)\n\nNext to the programmatic way of subscribing to a topic from code, Dapr pub/sub also provides a\ndeclarative way of subscribing to a topic. This approach removes the Dapr dependency from the\napplication code. Therefore, it also enables an existing application to subscribe to topics without any\nchanges to the code. The following example shows a Dapr configuration file for configuring a\nsubscription:\n\nYou have to specify several elements with every subscription:\n\n['The name of the Dapr pub/sub component you want to use (in this case `pubsub` ).', 'The name of the topic to subscribe to (in this case `newOrder` ).', 'The API operation that needs to be called for this topic (in this case `/orders` ).', '[The scope](https://docs.dapr.io/developing-applications/building-blocks/pubsub/pubsub-scopes/) can specify which services can publish and subscribe to a topic.']"}, "Sample application: Dapr Traffic Control": "In Dapr Traffic Control sample app, the TrafficControl service uses the Dapr pub/sub building block to\nsend speeding violations to the FineCollection service. Figure 7-4 shows the conceptual architecture\n\n69 CHAPTER 8 | The Dapr publish & subscribe building block\n\nof the Dapr Traffic Control sample application. The Dapr pub/sub building block is used in flows\nmarked with number 2 in the diagram:\n\n:::image type=\u201ccontent\u201d source=\u201c./media/publish-subscribe/dapr-solution-pub-sub.png\u201d alttext=\u201cConceptual architecture of the Dapr Traffic Control sample application.\u201d:::\n\n_Figure 7-4. Conceptual architecture of the Dapr Traffic Control sample application._\n\nevent messages:\n\nThe method is decorated with the Dapr `Topic` attribute. It specifies that the pub/sub component\nnamed `pubsub` should be used to subscribe to messages sent to the `speedingviolations` topic.\n\nusing the pub/sub building block:\n\nWhile the Traffic Control app uses RabbitMQ as the message broker, it never directly references\nRabbitMQ. Instead, the accompanying Dapr component configuration file named `pubsub.yaml` in the\n\n`/dapr/components` folder specifies the message broker:\n\n70 CHAPTER 8 | The Dapr publish & subscribe building block\n\nThe `type` element in the configuration, `pubsub.rabbitmq` instructs the building block to use the Dapr\nRabbitMQ component.\n\nThe `scopes` element in the configuration _constrains_ application access to the RabbitMQ component.\nOnly the TrafficControl and FineCollection services can consume it.\n\nUsing Dapr pub/sub in the Traffic Control sample application offers the following benefits:\n\n['No infrastructural abstraction of a message broker to maintain.', 'Services are temporally decoupled, which increases robustness.', 'Publisher and subscribers are unaware of each other. This means that additional services could\\nbe introduced that will react to speeding violations in the future, without the need to change the\\nTrafficControl service.']", "Summary": {"**References**": ["[Dapr supported pub/sub brokers](https://docs.dapr.io/reference/components-reference/supported-pubsub/)"]}}}, "9": {"The Dapr bindings building block": {"What it solves": "Dapr resource bindings enable your services to integrate business operations across external\nresources outside of the immediate application. An event from an external system could trigger an\noperation in your service passing in contextual information. Your service could then expand the\noperation by triggering an event in another external system, passing in contextual payload\ninformation. Your service communicates without coupling or awareness of the external resource. The\nplumbing is encapsulated inside pre-defined Dapr components. The Dapr component to use can be\neasily swapped at run time without code changes.\n\nConsider, for example, a Twitter account that triggers an event whenever a user tweets a keyword.\nYour service exposes an event handler that receives and processes the tweet. Once complete, your\nservice triggers an event that invokes an external Twilio service. Twilio sends an SMS message that\nincludes the tweet. Figure 8-1 show the conceptual architecture of this operation:\n\n_Figure 8-1. Conceptual architecture of a Dapr resource binding._\n\nAt first glance, resource binding behavior may appear similar to the Publish/Subscribe pattern\ndescribed earlier in this book. While they share similarities, there are differences. Publish/subscribe\n\n72 CHAPTER 9 | The Dapr bindings building block\n\nfocuses on asynchronous communication between Dapr services. Resource binding has a much wider\nscope. It focuses on system interoperability across software platforms. Exchanging information\nbetween disparate applications, datastores, and services outside your microservice application.", "How it works": {"**Input bindings**": "Input bindings trigger your code with incoming events from external resources. To receive events and\ndata, you register a public endpoint from your service that becomes the _event handler_ . Figure 8-2\nshows the flow:\n\n_Figure 8-2. Dapr input binding flow._\n\nFigure 8.2 describes the steps for receiving events from an external Twitter account:\n\n73 CHAPTER 9 | The Dapr bindings building block\n\n['The Dapr sidecar reads the binding configuration file and subscribes to the event specified for\\nthe external resource. In the example, the event source is a Twitter account.', 'When a matching Tweet is published on Twitter, the binding component running in the Dapr\\nsidecar picks it up and triggers an event.', 'The Dapr sidecar invokes the endpoint (that is, event handler) configured for the binding. In the\\nexample, the service listens for an HTTP POST on the `/tweet` endpoint on port 6000. Because it\u2019s\\nan HTTP POST operation, the JSON payload for the event is passed in the request body.', 'After handling the event, the service returns an HTTP status code `200 OK` .']\n\nThe following ASP.NET Core controller provides an example of handling an event triggered by the\nTwitter binding:\n\nIf the operation should error, you would return the appropriate 400 or 500 level HTTP status code. For\nbindings that feature _at-least-once_ delivery guarantees, the Dapr sidecar will retry the trigger. Check\n[out Dapr documentation for resource bindings to see whether they offer](https://docs.dapr.io/operations/components/setup-bindings/supported-bindings) _at-least-once_ or _exactly-once_\ndelivery guarantees.", "**Output bindings**": "Dapr also includes _output binding_ capabilities. They enable your service to trigger an event that\ninvokes an external resource. Again, you start by configuring a binding configuration YAML file that\ndescribes the output binding. Once in place, you trigger an event that invokes the bindings API on the\nDapr sidecar of your application. Figure 8-3 shows the flow of an output binding:\n\n74 CHAPTER 9 | The Dapr bindings building block\n\n_Figure 8-3. Dapr output binding flow._\n\n['The Dapr sidecar reads the binding configuration file with the information on how to connect to\\nthe external resource. In the example, the external resource is a Twilio SMS account.', 'Your application invokes the `/v1.0/bindings/sms` endpoint on the Dapr sidecar. In this case, it\\nuses an HTTP POST to invoke the API. It\u2019s also possible to use gRPC.', 'The binding component running in the Dapr sidecar calls the external messaging system to send\\nthe message. The message will contain the payload passed in the POST request.']\n\nAs an example, you can invoke an output binding by invoking the Dapr API using curl:\n\nNote that the HTTP port is the same as used by the Dapr sidecar (in this case, the default Dapr HTTP\nport `3500` ).\n\nThe structure of the payload (that is, message sent) will vary per binding. In the example above, the\npayload contains a `data` element with a message. Bindings to other types of external resources can be\ndifferent, especially for the metadata that is sent. Each payload must also contain an `operation` field,\n\n75 CHAPTER 9 | The Dapr bindings building block\n\nthat defines the operation the binding will execute. The above example specifies a `create` operation\nthat creates the SMS message. Common operations include:\n\n['create', 'get', 'delete', 'list']\n\nIt\u2019s up to the author of the binding which operations the binding supports. The documentation for\neach binding describes the available operations and how to invoke them."}, "Use the Dapr .NET SDK": "The Dapr .NET SDK provides language-specific support for .NET developers. In the following example,\nthe call to the `HttpClient.PostAsync()` is replaced with the `DaprClient.InvokeBindingAsync()`\nmethod. This specialized method simplifies invoking a configured output binding:\n\nThe method expects the `metadata` and `message` values.\n\nWhen used to invoke a binding, the `DaprClient` uses gRPC to call the Dapr API on the Dapr sidecar.", "Binding components": {"**Cron binding**": "Pay close attention to Dapr\u2019s Cron binding. It doesn\u2019t subscribe to events from an external system.\nInstead, this binding uses a configurable interval schedule to trigger your application. The binding\nprovides a simple way to implement a background worker to wake up and do some work at a regular\ninterval, without the need to implement an endless loop with a configurable delay. Here\u2019s an example\nof a Cron binding configuration:\n\n77 CHAPTER 9 | The Dapr bindings building block\n\n[see the Cron binding documentation.](https://docs.dapr.io/operations/components/setup-bindings/supported-bindings/cron/)"}, "Sample application: Dapr Traffic Control": {"**MQTT input binding**": "MQTT is a lightweight pub/sub messaging protocol, often used in IoT scenarios. Producers sent MQTT\nmessages to a topic; subscribers then retrieve messages from the topic. There are several MQTT\n[message broker products available. The Traffic Control sample application uses Eclipse Mosquitto.](https://mosquitto.org/)\n\n[The CameraSimulation doesn\u2019t depend on any Dapr building blocks. It uses the System.Net.Mqtt](https://www.nuget.org/packages/System.Net.Mqtt)\nlibrary to send MQTT messages:\n\n:::{custom-style=CodeBox} csharp public CameraSimulation(int camNumber, ITrafficControlService\ntrafficControlService) {   _camNumber = camNumber;   _trafficControlService = trafficControlService;\n} :::\n\ntopics respectively:\n\nThe constructor sets up the MQTT client to send messages to the MQTT broker (Mosquitto) running\non port 1883.\n\nOn the other end, the TrafficControl service uses the MQTT input binding to receive\n\n`VehicleRegistered` messages sent by the CameraSimulation. For each subscribed topic, there\u2019s a\n\n79 CHAPTER 9 | The Dapr bindings building block\n\nseparate component configuration file in the `/dapr/components` folder. The first one is\n\n`entrycam.yaml` :\n\nThe configuration specifies the binding type: `bindings.mqtt` . It also specifies that the broker runs on\n\nWhen the TrafficControl service starts, the Dapr sidecar automatically subscribes to the\n\n`trafficcontrol/entrycam` MQTT topic specified in the component configuration. When messages\narrive on the topic, the Dapr sidecar invokes an HTTP endpoint on your service. The sidecar\n\nno code needs to be added to support the endpoint:\n\nThe `exitcam.yaml` component configuration file configures everything for the `exitcam` endpoint:\n\n80 CHAPTER 9 | The Dapr bindings building block", "**SMTP output binding**": "The FineCollection service uses the Dapr SMTP output binding to send emails. Figure 8-5 shows the\nconceptual architecture of the Dapr Traffic Control sample application. The Dapr input binding is used\nin flows marked with number 4 in the diagram:\n\n_Figure 8-5. Conceptual architecture of the Dapr Traffic Control sample application._\n\nThe `CollectFine` method on the CollectionController in the FineCollection service contains code that\nuses the Dapr client to invoke the output binding:\n\n81 CHAPTER 9 | The Dapr bindings building block\n\nThe code uses a simple utility class to create an HTML email body containing the necessary\ninformation. It also creates a dictionary with metadata specific to the SMTP binding. This binding\ncomponent interprets the metadata when invoked.\n\nThe following arguments are required to invoke the binding:\n\n['The body of the message to send. In this case, the HTML email body.', 'The metadata for sending the email.']\n\nThe Dapr output binding named `sendmail` is configured in the `email.yaml` component configuration\nfile in the `/dapr/components` folder:\n\nThe configuration specifies the binding type: `bindings.smtp` .\n\n[The metadata section contains the information for connecting to the SMTP server. See the binding\u2019s](https://docs.dapr.io/reference/components-reference/supported-bindings/smtp/)\n[documentation](https://docs.dapr.io/reference/components-reference/supported-bindings/smtp/) for specific metadata required for this binding. The username and password to\nconnect to the SMTP server are retrieved from a secrets store. See the Secrets management building\nblock chapter for more information on how this works.\n\nThe `scopes` element specifies that only the service with app-id `finecollectonservice` can access this\nbinding.\n\n82 CHAPTER 9 | The Dapr bindings building block\n\n[The Traffic Control sample application uses MailDev. MailDev is a development SMTP server that](https://github.com/maildev/maildev)\ndoesn\u2019t actually send out emails (by default). Instead, it collects emails and presents them in an inbox\nweb application. MailDev is extremely useful for dev/test and demo scenarios.\n\nUsing Dapr bindings in the Traffic Control sample application provides the following benefits:\n\n['Using MQTT messaging and SMTP without the need to learn this protocol or a specific MQTT\\nAPI.', 'Using SMTP to send an email without the need to learn this protocol or a specific SMTP API.']"}, "Summary": {"**References**": ["[Dapr documentation for resource bindings](https://docs.dapr.io/operations/components/setup-bindings/supported-bindings/)", "[Mosquitto MQTT broker](https://mosquitto.org/)", "[MailDev development SMTP server](https://github.com/maildev/maildev)"]}}}, "10": {"The Dapr actors building block": {"What it solves": "Actor model implementations are usually tied to a specific language or platform. With the Dapr actors\nbuilding block however, you can leverage the actor model from any language or platform.\n\n[Dapr\u2019s implementation is based on the virtual actor pattern introduced by Project \u201cOrleans\u201d. With the](https://www.microsoft.com/research/project/orleans-virtual-actors/)\nvirtual actor pattern, you don\u2019t need to explicitly create actors. Actors are activated implicitly and\nplaced on a node in the cluster the first time a message is sent to the actor. When not executing\noperations, actors are silently unloaded from memory. If a node fails, Dapr automatically moves\nactivated actors to healthy nodes. Besides sending messages between actors, the Dapr actor model\nalso support scheduling future work using timers and reminders.\n\nWhile the actor model can provide great benefits, it\u2019s important to carefully consider the actor design.\nFor example, having many clients call the same actor will result in poor performance because the actor\noperations execute serially. Here are some criteria to check if a scenario is a good fit for Dapr actors:\n\n['Your problem space involves concurrency. Without actors, you\u2019d have to introduce explicit\\nlocking mechanisms in your code.']\n\n84 CHAPTER 10 | The Dapr actors building block\n\n['Your problem space can be partitioned into small, independent, and isolated units of state and\\nlogic.', 'You don\u2019t need low-latency reads of the actor state. Low-latency reads cannot be guaranteed\\nbecause actor operations execute serially.', 'You don\u2019t need to query state across a set of actors. Querying across actors is inefficient because\\neach actor\u2019s state needs to be read individually and can introduce unpredictable latencies.']\n\n[One design pattern that fits these criteria quite well is the orchestration-based saga](https://docs.microsoft.com/azure/architecture/reference-architectures/saga/saga) or _process_\n_manager_ design pattern. A saga manages a sequence of steps that must be taken to reach some\noutcome. The saga (or process manager) maintains the current state of the sequence and triggers the\nnext step. If a step fails, the saga can execute compensating actions. Actors make it easy to deal with\nconcurrency in the saga and to keep track of the current state. The eShopOnDapr reference\napplication uses the saga pattern and Dapr actors to implement the Ordering process.", "How it works": {"**Turn-based access model**": "The turn-based access model ensures that at any time there\u2019s at most one thread active inside an\nactor instance. To understand why this is useful, consider the following example of a method that\nincrements a counter value:\n\nLet\u2019s assume that the current value returned by the `GetValue` method is `1` . When two threads call the\n\n`Increment` method at the same time, there\u2019s a risk of both of them calling the `GetValue` method\nbefore one of them calls `SaveValue` . This results in both threads starting with the same initial value ( `1` ).\nThe threads then increment the value to `2` and return it to the caller. The resulting value after the two\ncalls is now `2` instead of `3` which it should be. This is a simple example to illustrate the kind of issues\nthat can slip into your code when working with multiple threads, and is easy to solve. In real world\napplications however, concurrent and parallel scenarios can become very complex.\n\nIn traditional programming models, you can solve this problem by introducing locking mechanisms.\nFor example:\n\nUnfortunately, using explicit locking mechanisms is error-prone. They can easily lead to deadlocks and\ncan have serious impact on performance.\n\nThanks to the turn-based access model, you don\u2019t need to worry about multiple threads with actors,\nmaking it much easier to write concurrent systems. The following actor example closely mirrors the\ncode from the previous sample, but doesn\u2019t require any locking mechanisms to be correct:\n\n88 CHAPTER 10 | The Dapr actors building block", "**Timers and reminders**": "Actors can use timers and reminders to schedule calls to themselves. Both concepts support the\nconfiguration of a due time. The difference lies in the lifetime of the callback registrations:\n\n['Timers will only stay active as long as the actor is activated. Timers _will not_ reset the idle-timer,\\nso they cannot keep an actor active on their own.', 'Reminders outlive actor activations. If an actor is deactivated, a reminder will re-activate the\\nactor. Reminders _will_ reset the idle-timer.']\n\nTimers are registered by making a call to the actor API. In the following example, a timer is registered\nwith a due time of 0 and a period of 10 seconds.\n\nBecause the due time is 0, the timer will fire immediately. After a timer callback has finished, the timer\nwill wait 10 seconds before firing again.\n\nReminders are registered in a similar way. The following example shows a reminder registration with a\ndue time of 5 minutes, and an empty period:\n\nThis reminder will fire in 5 minutes. Because the given period is empty, this will be a one-time\nreminder.", "**State persistence**": "Actor state is persisted using the Dapr state management building block. Because actors can execute\nmultiple state operations in a single turn, the state store component must support multi-item\ntransactions. At the time of writing, the following state stores support multi-item transactions:\n\n89 CHAPTER 10 | The Dapr actors building block\n\n['Azure Cosmos DB', 'MongoDB', 'MySQL', 'PostgreSQL', 'Redis', 'RethinkDB', 'SQL Server']\n\nTo configure a state store component for use with actors, you need to append the following metadata\nto the state store configuration:\n\nHere\u2019s a complete example for a Redis state store:"}, "Use the Dapr .NET SDK": {"**Call actors from ASP.NET Core clients**": "The console client example in the previous section uses the static `ActorProxy.Create` method directly\nto get an actor proxy instance. If the client application is an ASP.NET Core application, you should use\nthe `IActorProxyFactory` interface to create actor proxies. The main benefit is that it allows you to\nmanage configuration in one place. The `AddActors` extension method on `IServiceCollection` takes\na delegate that allows you to specify actor runtime options, such as the HTTP endpoint of the Dapr\nsidecar. The following example specifies custom `JsonSerializerOptions` to use for actor state\npersistence and message deserialization:\n\nexample calls an actor method from an ASP.NET Core controller class:\n\n93 CHAPTER 10 | The Dapr actors building block\n\nActors can also call other actors directly. The `Actor` base class exposes an `IActorProxyFactory` class\n\ninvokes operations on two other actors:", "**Call non-.NET actors**": "So far, the examples used strongly-typed actor proxies based on .NET interfaces to illustrate actor\ninvocations. This works great when both the actor host and client are .NET applications. However, if\nthe actor host is not a .NET application, you don\u2019t have an actor interface to create a strongly-typed\nproxy. In these cases, you can use a weakly-typed proxy.\n\nYou create weakly-typed proxies in a similar way to strongly-typed proxies. Instead of relying on a\n.NET interface, you need to pass in the actor method name as a string.\n\n94 CHAPTER 10 | The Dapr actors building block", "**Timers and reminders**": "start a timer that repeatedly writes a given text to the log output.\n\nThe `StartTimerAsync` method calls `RegisterTimerAsync` to schedule the timer. `RegisterTimerAsync`\ntakes five arguments:\n\n['The name of the timer.', 'The name of the method to call when the timer fires.', 'The state to pass to the callback method.', 'The amount of time to wait before the callback method is first invoked.', 'The time interval between callback method invocations. You can specify\\n`TimeSpan.FromMilliseconds(-1)` to disable periodic signaling.']\n\nThe `TimerCallbackAsync` method receives the user state in binary form. In the example, the callback\ndecodes the state back to a `string` before writing it to the log.\n\nTimers can be stopped by calling `UnregisterTimerAsync` :\n\n95 CHAPTER 10 | The Dapr actors building block\n\nRemember that timers do not reset the actor idle timer. When no other calls are made on the actor, it\nmay be deactivated and the timer will be stopped automatically. To schedule work that does reset the\nidle timer, use reminders which we\u2019ll look at next.\n\nTo use reminders in an actor, your actor class must implement the `IRemindable` interface:\n\nThe `ReceiveReminderAsync` method is called when a reminder is fired. It takes 4 arguments:\n\n['The name of the reminder.', 'The user state provided during registration.', 'The invocation due time provided during registration.', 'The invocation period provided during registration.']\n\nTo register a reminder, use the `RegisterReminderAsync` method of the actor base class. The following\nexample sets a reminder to fire a single time with a due time of three minutes.\n\n96 CHAPTER 10 | The Dapr actors building block\n\nThe `RegisterReminderAsync` method is similar to `RegisterTimerAsync` but you don\u2019t have to specify\na callback method explicitly. As the above example shows, you implement\n\n`IRemindable.ReceiveReminderAsync` to handle fired reminders.\n\nReminders both reset the idle timer and are persistent. Even if your actor is deactivated, it will be\nreactivated at the moment a reminder fires. To stop a reminder from firing, call\n\n`UnregisterReminderAsync` ."}, "Sample application: Dapr Traffic Control": "The default version of Dapr Traffic Control does not use the actor model. However, it does contain an\nalternative actor-based implementation of the TrafficControl service that you can enable. To make use\nof actors in the TrafficControl service, open up the\n\n```\n#define USE_ACTORMODEL\n\n```\n\nWhen the actor model is enabled, the application uses actors to represent vehicles. The operations\nthat can be invoked on the vehicle actors are defined in an `IVehicleActor` interface:\n\nThe (simulated) entry cameras call the `RegisterEntryAsync` method when a new vehicle is first\ndetected in the lane. The only responsibility of this method is storing the entry timestamp in the actor\nstate:\n\nWhen the vehicle reaches the end of the speed camera zone, the exit camera calls the\n\n`RegisterExitAsync` method. The `RegisterExitAsync` method first gets the current states and\nupdates it to include the exit timestamp:\n\n97 CHAPTER 10 | The Dapr actors building block\n\nallows the actor to publish messages using the Dapr pub/sub building block.\n\nBoth dependencies are registered in the _Program.cs_ class and injected into the actor using constructor\ndependency injection:\n\nThe actor based implementation no longer uses the Dapr state management building block directly.\nInstead, the state is automatically persisted after each operation is executed.", "Summary": {"**References**": ["[Dapr supported state stores](https://docs.dapr.io/operations/components/setup-state-store/supported-state-stores/)"]}}}, "11": {"The Dapr observability building block": {"What it solves": "The Dapr observability building block decouples observability from the application. It automatically\ncaptures traffic generated by Dapr sidecars and Dapr system services that make up the Dapr control\nplane. The block correlates traffic from a single operation that spans multiple services. It also exposes\nperformance metrics, resource utilization, and the health of the system. Telemetry is published in\nopen-standard formats enabling information to be fed into your monitoring back end of choice.\nThere, the information can be visualized, queried, and analyzed.\n\nAs Dapr abstracts away the plumbing, the application is unaware of how observability is implemented.\nThere\u2019s no need to reference libraries or implement custom instrumentation code. Dapr allows the\ndeveloper to focus on building business logic instead of observability plumbing. Observability is\nconfigured at the Dapr system level and is consistent across services, even when created by different\nteams, and built with different technology stacks.", "How it works": {"**Distributed tracing**": "Distributed tracing provides insight into traffic that flows across services in a distributed application.\nThe logs of exchanged request and response messages are a source of invaluable information for\ntroubleshooting issues. The hard part is _correlating messages_ that belong to the same business\ntransaction.\n\n[Dapr uses the W3C Trace Context to correlate related messages. It injects the same context](https://www.w3.org/TR/trace-context)\ninformation into requests and responses that form a unique operation. Figure 10-2 shows how\ncorrelation works:\n\n_Figure 10-2. W3C Trace Context example._\n\n['Service A invokes an operation on Service B. As Service A starts the call, Dapr creates a unique\\ntrace context and injects it into the request.', 'Service B receives the request and invokes an operation on Service C. Dapr detects that the\\nincoming request contains a trace context and propagates it by injecting it into the outgoing\\nrequest to Service C.', 'Service C receives the request and handles it. Dapr detects that the incoming request contains a\\ntrace context and propagates it by injecting it into the outgoing response back to Service B.', 'Service B receives the response and handles it. It then creates a new response and propagates\\nthe trace context by injecting it into the outgoing response back to Service A.']\n\nA set of requests and responses that belong together is called a _trace_ . Figure 10-3 shows a trace:\n\n102 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-3. Traces and spans._\n\nIn the figure, note how the trace represents a unique application transaction that takes place across\nmany services. A trace is a collection of _spans_ . Each span represents a single operation or unit of work\ndone within the trace. Spans are the requests and responses that are sent between services that\nimplement the unique transaction.\n\nThe next sections discuss how to inspect tracing telemetry by publishing it to a monitoring back end.\n\n**Use a Zipkin monitoring back end**\n\n[Zipkin](https://zipkin.io/) is an open-source distributed tracing system. It can ingest and visualize telemetry data. Dapr\noffers default support for Zipkin. The following example demonstrates how to configure Zipkin to\nvisualize Dapr telemetry.\n\n**Enable and configure tracing**\n\nTo start, tracing must be enabled for the Dapr runtime using a Dapr configuration file. Here\u2019s an\nexample of a configuration file named `dapr-config.yaml` that enables tracing:\n\nendpoint on a Zipkin server running in a Kubernetes cluster. The default port for Zipkin is `9411` . The\nconfiguration must be applied to the Kubernetes cluster using the Kubernetes CLI:\n\n```\nkubectl apply -f dapr-config.yaml\n\n```\n\n103 CHAPTER 11 | The Dapr observability building block\n\n**Install the Zipkin server**\n\nWhen installing Dapr in self-hosted mode, a Zipkin server is automatically installed and tracing is\nenabled in the default configuration file located in `$HOME/.dapr/config.yaml` or\n\n`%USERPROFILE%\\.dapr\\config.yaml` on Windows.\n\nWhen installing Dapr on a Kubernetes cluster, Zipkin must be deployed manually. Use the following\nKubernetes manifest file entitled `zipkin.yaml` to deploy a standard Zipkin server to a Kubernetes\ncluster:\n\nThe deployment uses the standard `openzipkin/zipkin-slim` container image. The Zipkin service\nexposes the Zipkin web front end, which you can use to view the telemetry on port `32411` . Use the\n\n104 CHAPTER 11 | The Dapr observability building block\n\nKubernetes CLI to apply the Zipkin manifest file to the Kubernetes cluster and deploy the Zipkin\nserver:\n\n```\nkubectl apply -f zipkin.yaml\n\n```\n\n**Configure the services to use the tracing configuration**\n\nNow everything is set up correctly to start publishing telemetry. Every Dapr sidecar that is deployed as\npart of the application must be instructed to emit telemetry when started. To do that, add a\n\n`dapr.io/config` annotation that references the `dapr-config` configuration to the deployment of\neach service. Here\u2019s an example of the Traffic Control FineCollection service\u2019s manifest file containing\nthe annotation:\n\n**Inspect the telemetry in Zipkin**\n\nOnce the application is started, the Dapr sidecars will emit telemetry to the Zipkin server. To inspect\nthis telemetry, point a web-browser to `http://localhost:32411` . You\u2019ll see the Zipkin web front end:\n\n105 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-4. Zipkin front end._\n\nOn the _Find a trace_ tab, you can query traces. Pressing the _RUN QUERY_ button without specifying any\nrestrictions will show all the ingested _traces_ :\n\n_Figure 10-5. Zipkin traces overview._\n\nClicking the _SHOW_ button next to a specific trace, will show the details of that trace:\n\n106 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-6. Zipkin trace details._\n\nEach item on the details page, is a span that represents a request that is part of the selected trace.\n\n**Inspect the dependencies between services**\n\nBecause Dapr sidecars handle traffic between services, Zipkin can use the trace information to\ndetermine the dependencies between the services. To see it in action, go to the _Dependencies_ tab on\nthe Zipkin web page and select the button with the magnifying glass. Zipkin will show an overview of\nthe services and their dependencies:\n\n107 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-7. Zipkin dependencies._\n\nThe animated dots on the lines between the services represent requests and move from source to\ndestination. Red dots indicate a failed request.\n\n**Use a Jaeger or New Relic monitoring back end**\n\nBeyond Zipkin, other monitoring back-end software can also ingest telemetry with the Zipkin format.\n[Jaeger](https://www.jaegertracing.io/) is an open source tracing system created by Uber Technologies. It\u2019s used to trace transactions\n[between distributed services and troubleshoot complex microservices environments. New Relic](https://newrelic.com/) is a\n_full-stack_ observability platform. It links relevant data from a distributed application to provide a\ncomplete picture of your system. To try them out, specify an `endpointAddress` pointing to either a\nJaeger or New Relic server in the Dapr configuration file. Here\u2019s an example of a configuration file that\nconfigures Dapr to send telemetry to a Jaeger server. The URL for Jaeger is identical to the URL for the\nZipkin. The only difference is the number of the port on which the server runs:\n\n:::{custom-style=CodeBox} yaml apiVersion: dapr.io/v1alpha1 kind: Configuration metadata:  name:\ndapr-config  namespace: default spec:  tracing:   samplingRate: \"1\"   zipkin:\nendpointAddress: \"http://localhost:9415/api/v2/spans\" :::\n\nTo try out New Relic, specify the endpoint of the New Relic API. Here\u2019s an example of a configuration\nfile for New Relic:\n\n:::{custom-style=CodeBox} yaml apiVersion: dapr.io/v1alpha1 kind: Configuration metadata:  name:\ndapr-config  namespace: default spec:  tracing:   samplingRate: \"1\"   zipkin:\nendpointAddress: \"https://trace-api.newrelic.com/trace/v1?Api-Key=<NR-API-KEY>&DataFormat=zipkin&Data-Format-Version=2\" :::\n\n108 CHAPTER 11 | The Dapr observability building block\n\nCheck out the Jaeger and New Relic websites for more information on how to use them.", "**Metrics**": "Metrics provide insight into performance and resource consumption. Under the hood, Dapr emits a\n\nendpoint at a predefined interval to collect metrics. The scraper sends metric values to a monitoring\nback end. Figure 10-8 shows the scraping process:\n\n_Figure 10-8. Scraping Prometheus metrics._\n\nEach sidecar and system service exposes a metric endpoint that listens on port 9090. The Prometheus\nMetrics Scrapper captures metrics from each endpoint and published the information to the\nmonitoring back end.\n\n**Service discovery**\n\nYou might wonder how the metrics scraper knows where to collect metrics. Prometheus can integrate\nwith discovery mechanisms built into target deployment environments. For example, when running in\nKubernetes, Prometheus can integrate with the Kubernetes API to find all available Kubernetes\nresources running in the environment.\n\n**Metrics list**\n\nDapr generates a large set of metrics for Dapr system services and its runtime. Some examples\ninclude:\n\n109 CHAPTER 11 | The Dapr observability building block\n\n|Metric|Source|Description|\n|---|---|---|\n|dapr_operator_service_created_total|System|The total number of Dapr services created<br>by the Dapr Operator service.|\n|dapr_injector_sidecar_injection/requests_total|System|The total number of sidecar injection<br>requests received by the Dapr Sidecar-<br>Injector service.|\n|dapr_placement_runtimes_total|System|The total number of hosts reported to the<br>Dapr Placement service.|\n|dapr_sentry_cert_sign_request_received_total|System|The number of certificate signing requests<br>(CRSs) received by the Dapr Sentry service.|\n|dapr_runtime_component_loaded|Runtime|The number of successfully loaded Dapr<br>components.|\n|dapr_grpc_io_server_completed_rpcs|Runtime|Count of gRPC calls by method and status.|\n|dapr_http_server_request_count|Runtime|Number of HTTP requests started in an<br>HTTP server.|\n|dapr_http/client/sent_bytes|Runtime|Total bytes sent in request body (not<br>including headers) by an HTTP client.|\n\n[For more information on available metrics, see the Dapr metrics documentation.](https://docs.dapr.io/operations/monitoring/metrics/)\n\n**Configure Dapr metrics**\n\nAt run time, you can disable the metrics collection endpoint by including the `--enable-`\n\n`metrics=false` argument in the Dapr command. Or, you can also change the default port for the\nendpoint with the `--metrics-port 9090` argument.\n\nYou can also use a Dapr configuration file to statically enable or disable runtime metrics collection:\n\n**Visualize Dapr metrics**\n\nWith the Prometheus scraper collecting and publishing metrics into the monitoring back end, how do\n[you make sense of the raw data? A popular visualization tool for analyzing metrics is Grafana. With](https://grafana.com/grafana/)\nGrafana, you can create dashboards from the available metrics. Here\u2019s an example of a dashboard\ndisplaying Dapr system services metrics:\n\n110 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-9. Grafana dashboard._\n\n[The Dapr documentation includes a tutorial for installing Prometheus and Grafana.](https://docs.dapr.io/operations/monitoring/metrics/grafana/)", "**Logging**": "Logging provides insight into what is happening with a service at run time. When running an\napplication, Dapr automatically emits log entries from Dapr sidecars and Dapr system services.\nHowever, logging entries instrumented in your application code **aren\u2019t** automatically included. To\n[emit logging from application code, you can import a specific SDK like OpenTelemetry SDK for .NET.](https://opentelemetry.io/docs/net/)\nLogging application code is covered later in this chapter in the section _Using the Dapr .NET SDK_ .\n\n**Log entry structure**\n\nDapr emits structured logging. Each log entry has the following format:\n\n|Field|Description|Example|\n|---|---|---|\n|time|ISO8601 formatted timestamp|`2021-01-10T14:19:31.000Z`|\n|level|Level of the entry (`debug`, `info`, `warn`, or`error`)|`info`|\n|type|Log Type|`log`|\n|msg|Log Message|`metrics server started on :62408/`|\n|scope|Logging Scope|`dapr.runtime`|\n|instance|Hostname where Dapr runs|TSTSRV01|\n\n111 CHAPTER 11 | The Dapr observability building block\n\n|Field|Description|Example|\n|---|---|---|\n|app_id|Dapr App ID|finecollectionservice|\n|ver|Dapr Runtime Version|`1.0`|\n\nWhen searching through logging entries in a troubleshooting scenario, the `time` and `level` fields are\nespecially helpful. The time field orders log entries so that you can pinpoint specific time periods.\nWhen troubleshooting, log entries at the _debug level_ provide more information on the behavior of the\ncode.\n\n**Plain text versus JSON format**\n\nBy default, Dapr emits structured logging in plain-text format. Every log entry is formatted as a string\ncontaining key/value pairs. Here\u2019s an example of logging in plain text:\n\nWhile simple, this format is difficult to parse. If viewing log entries with a monitoring tool, you\u2019ll want\nto enable JSON formatted logging. With JSON entries, a monitoring tool can index and query\nindividual fields. Here\u2019s the same log entries in JSON format:\n\nTo enable JSON formatting, you need to configure each Dapr sidecar. In self-hosted mode, you can\nspecify the flag `--log-as-json` on the command line:\n\n```\ndapr run --app-id finecollectionservice --log-level info --log-as-json dotnet run\n\n```\n\nIn Kubernetes, you can add a `dapr.io/log-as-json` annotation to each deployment for the\napplication:\n\nWhen you install Dapr in a Kubernetes cluster using Helm, you can enable JSON formatted logging for\nall the Dapr system services:\n\n112 CHAPTER 11 | The Dapr observability building block\n\n**Collect logs**\n\nThe logs emitted by Dapr can be fed into a monitoring back end for analysis. A log collector is a\ncomponent that collects logs from a system and sends them to a monitoring back end. A popular log\n[collector is Fluentd. Check out the How-To: Set up Fluentd, Elastic search and Kibana in Kubernetes](https://www.fluentd.org/) in\nthe Dapr documentation. This article contains instructions for setting up Fluentd as log collector and\n[the ELK Stack](https://www.elastic.co/elastic-stack) (Elastic Search and Kibana) as a monitoring back end.", "**Health status**": "The health status of a service provides insight into its availability. Each Dapr sidecar exposes a health\nAPI that can be used by the hosting environment to determine the health of the sidecar. The API has\none operation:\n\n```\nGET http://localhost:3500/v1.0/healthz\n\n```\n\nThe operation returns two HTTP status codes:\n\n['204: When the sidecar is healthy', '500: when the sidecar isn\u2019t healthy']\n\nWhen running in self-hosted mode, the health API isn\u2019t automatically invoked. You can invoke the API\nthough from application code or a health monitoring tool.\n\nWhen running in Kubernetes, the Dapr sidecar-injector automatically configures Kubernetes to use the\nhealth API for executing _liveness probes_ and _readiness probes_ .\n\nKubernetes uses liveness probes to determine whether a container is up and running. If a liveness\nprobe returns a failure code, Kubernetes will assume the container is dead and automatically restart it.\nThis feature increases the overall availability of your application.\n\nKubernetes uses readiness probes to determine whether a container is ready to start accepting traffic.\nA pod is considered ready when all of its containers are ready. Readiness determines whether a\nKubernetes service can direct traffic to a pod in a load-balancing scenario. Pods that aren\u2019t ready are\nautomatically removed from the load-balancer.\n\nLiveness and readiness probes have several configurable parameters. Both are configured in the\ncontainer spec section of a pod\u2019s manifest file. By default, Dapr uses the following configuration for\neach sidecar container:\n\n113 CHAPTER 11 | The Dapr observability building block\n\nThe following parameters are available for the probes:\n\nprobing a container for the first time.\n\nthe API before timing out. A timeout is interpreted as a failure.\n\n['The `failureThreshold` specifies the number of failed status code Kubernetes will accept before\\nconsidering the container not alive or not ready.']", "**Dapr dashboard**": "Dapr offers a dashboard that presents status information on Dapr applications, components, and\nconfigurations. Use the Dapr CLI to start the dashboard as a web-application on the local machine on\nport 8080:\n\n```\ndapr dashboard\n\n```\n\nFor Dapr application running in Kubernetes, use the following command:\n\n```\ndapr dashboard -k\n\n```\n\nThe dashboard opens with an overview of all services in your application that have a Dapr sidecar. The\nfollowing screenshot shows the Dapr dashboard for the Traffic Control sample application running in\nKubernetes:\n\n:::image type=\u201ccontent\u201d source=\u201c./media/observability/dapr-dashboard-overview.png\u201d alt-text=\u201cDapr\ndashboard overview\u201d:::\n\n_Figure 10-10. Dapr dashboard overview._\n\nThe Dapr dashboard is invaluable when troubleshooting a Dapr application. It provides information\nabout Dapr sidecars and system services. You can drill down into the configuration of each service,\nincluding the logging entries.\n\nThe dashboard also shows the configured components (and their configuration) for an application:\n\n:::image type=\u201ccontent\u201d source=\u201c./media/observability/dapr-dashboard-components.png\u201d alttext=\u201cDapr dashboard components\u201d:::\n\n_Figure 10-11. Dapr dashboard components._\n\n114 CHAPTER 11 | The Dapr observability building block\n\nThere\u2019s a large amount of information available through the dashboard. You can discover it by\nrunning a Dapr application and browsing the dashboard.\n\n[Check out the Dapr dashboard CLI command reference](https://docs.dapr.io/reference/cli/dapr-dashboard/) in the Dapr docs for more information on the\nDapr dashboard commands."}, "Use the Dapr .NET SDK": "The Dapr .NET SDK doesn\u2019t contain any specific observability features. All observability features are\noffered at the Dapr level.\n\nIf you want to emit telemetry from your .NET application code, you should consider the\n[OpenTelemetry SDK for .NET. The Open Telemetry project is cross-platform, open source, and vendor](https://opentelemetry.io/docs/net/)\nagnostic. It provides an end-to-end implementation to generate, emit, collect, process, and export\ntelemetry data. There\u2019s a single instrumentation library per language that supports automatic and\nmanual instrumentation. Telemetry is published using the Open Telemetry standard. The project has\nbroad industry support and adoption from cloud providers, vendors, and end users.", "Sample application: Dapr Traffic Control": "Because the Traffic Control sample application runs with Dapr, all the telemetry described in this\nchapter is available. If you run the application and open the Zipkin web front end, you\u2019ll see end-toend tracing. Figure 10-12 shows an example:\n\n_Figure 10-12. Zipkin end-to-end tracing example._\n\nThis trace shows the communication that occurs when a speeding violation has been detected:\n\n115 CHAPTER 11 | The Dapr observability building block\n\n['An exiting vehicle triggers the MQTT input binding that sends a message containing the vehicle\\nlicense number, lane, and timestamp.', 'The MQTT input binding invokes the TrafficControl service with the message.', 'The TrafficControl service retrieves the state for the vehicle, appends the entry, and saves the\\nupdated vehicle state back to the state store.', 'The TrafficControl service publishes the speeding violation using pub/sub to the\\n`speedingviolations` topic.', 'The FineCollection service receives the speeding violation using a pub/sub subscription on the\\n`speedingviolations` topic.', 'The FineCollection service invokes the `vehicleinfo` endpoint of the VehicleRegistration service\\nusing service invocation.', 'The FineCollection service invokes an output binding for sending the email.']\n\nClick any trace line (span) to see more details. If you click on the last line, you\u2019ll see the `sendmail`\nbinding component invoked to send the driver a violation notice.\n\n116 CHAPTER 11 | The Dapr observability building block\n\n_Figure 10-13. Output binding trace details._", "Summary": "Detailed observability is critical to running a distributed system in production.\n\nDapr provides different types of telemetry, including distributed tracing, logging, metrics, and health\nstatus.\n\nDapr only produces telemetry for the Dapr system services and sidecars. Telemetry from your\napplication code isn\u2019t automatically included. You can however use a specific SDK like the\nOpenTelemetry SDK for .NET to emit telemetry from your application code.\n\n117 CHAPTER 11 | The Dapr observability building block\n\nDapr telemetry is produced in an open-standards based format so that it can be ingested by a large\nset of available monitoring tools. Examples include Zipkin, Azure Application Insights, the ELK Stack,\n[New Relic, and Grafana. See Monitor your application with Dapr](https://docs.dapr.io/operations/monitoring/) in the Dapr documentation for\ntutorials on how to monitor your Dapr applications with specific monitoring back ends.\n\nYou\u2019ll need a telemetry scraper that ingests telemetry and publishes it to the monitoring back end.\n\nDapr can be configured to emit structured logging. Structured logging is favored as it can be indexed\nby back-end monitoring tools. Indexed logging enables users to execute rich queries when searching\nthrough the logging.\n\nDapr offers a dashboard that presents information about the Dapr services and configuration.", "References": ["[Azure Application Insights](https://docs.microsoft.com/azure/azure-monitor/app/app-insights-overview/)", "[Open Telemetry](https://opentelemetry.io/)", "[Zipkin](https://zipkin.io/)", "[W3C Trace Context](https://www.w3.org/TR/trace-context/)", "[Jaeger](https://www.jaegertracing.io/)", "[New Relic](https://newrelic.com/)", "[Prometheus](https://prometheus.io/)", "[Grafana](https://grafana.com/grafana/)", "[Open Telemetry SDK for .NET](https://opentelemetry.io/docs/net/)", "[Fluentd](https://www.fluentd.org/)", "[ELK stack](https://www.elastic.co/elastic-stack)", "[Seq](https://datalust.co/seq)", "[Serilog](https://serilog.net/)"]}}, "12": {"The Dapr secrets management building block": {"What it solves": "[The Dapr secrets management building block abstracts away the complexity of working with secrets](https://docs.dapr.io/developing-applications/building-blocks/secrets/secrets-overview/)\nand secret management tools.\n\n119 CHAPTER 12 | The Dapr secrets management building block\n\n['It hides the underlying plumbing through a unified interface.', 'It supports various _pluggable_ secret store components, which can vary between development\\nand production.', 'Applications don\u2019t require direct dependencies on secret store libraries.', 'Developers don\u2019t require detailed knowledge of each secret store.']\n\nDapr handles all of the above concerns.\n\nAccess to the secrets is secured through authentication and authorization. Only an application with\nsufficient rights can access secrets. Applications running in Kubernetes can also use its built-in secrets\nmanagement mechanism.", "How it works": "Applications use the secrets management building block in two ways:\n\n['Retrieve a secret directly from the building block.', 'Reference a secret indirectly from a Dapr component configuration.']\n\nRetrieving secrets directly is covered first. Referencing a secret from a Dapr component configuration\nfile is addressed in a later section.\n\nThe application interacts with a Dapr sidecar when using the secrets management building block. The\nsidecar exposes the secrets API. The API can be called with either HTTP or gRPC. Use the following\nURL to call the HTTP API:\n\n```\nhttp://localhost:<dapr-port>/v1.0/secrets/<store-name>/<name>?<metadata>\n\n```\n\nThe URL contains the following segments:\n\nmetadata properties differ per secret store. For more information on metadata properties, see\nthe [secrets API reference] **[INTERNAL-LINK:(Secrets API reference | Dapr Docs](https://docs.dapr.io/reference/api/secrets_api/)** ).\n\n[!NOTE] The above URL represents the native Dapr API call available to any development platform that\nsupports HTTP or gRPC. Popular platforms like .NET, Java, and Go have their own custom APIs.\n\nThe JSON response contains the key and value of the secret.\n\nFigure 11-1 shows how Dapr handles a request for the secrets API:\n\n120 CHAPTER 12 | The Dapr secrets management building block\n\n_Figure 11-1. Retrieving a secret with the Dapr secrets API._\n\n['The service calls the Dapr secrets API, along with the name of the secret store, and secret to\\nretrieve.', 'The Dapr sidecar retrieves the specified secret from the secret store.', 'The Dapr sidecar returns the secret information back to the service.']\n\nSome secret stores support storing multiple key/value pairs in a single secret. For those scenarios, the\nresponse would contain multiple key/value pairs in a single JSON response as in the following\nexample:\n\n```\nGET http://localhost:3500/v1.0/secrets/secret-store/interestRates?metadata.version_id=3\n\n```\n\nThe Dapr secrets API also offers an operation to retrieve all the secrets the application has access to:\n\n```\nhttp://localhost:<dapr-port>/v1.0/secrets/<store-name>/bulk\n\n### Use the Dapr .NET SDK\n\n```\n\nFor .NET developers, the Dapr .NET SDK streamlines Dapr secret management. Consider the\n\n`DaprClient.GetSecretAsync` method. It enables you to retrieve a secret directly from any Dapr secret\nstore with minimal effort. Here\u2019s an example of fetching a connection string secret for a SQL Server\ndatabase:\n\n121 CHAPTER 12 | The Dapr secrets management building block\n\nArguments for the `GetSecretAsync` method include:\n\n['The name of the Dapr secret store component (\u2018secret-store\u2019)', 'The secret to retrieve (\u2018eshopsecrets\u2019)', 'Optional metadata key/value pairs (\u2018version_id=3\u2019)']\n\nThe method responds with a dictionary object as a secret can contain multiple key/value pairs. In the\nexample above, the secret named `customerdb` is referenced from the collection to return a connection\nstring.\n\nThe Dapr .NET SDK also features a .NET configuration provider. It loads specified secrets into the\n\nThe above example loads the `eshopsecrets` secrets collection into the .NET configuration system at\nstartup. Registering the provider requires an instance of `DaprClient` to invoke the secrets API on the\nDapr sidecar. The other arguments include the name of the secret store and a `DaprSecretDescriptor`\nobject with the name of the secret.\n\nOnce loaded, you can retrieve secrets directly from application code:", "Secret store components": {"**Configuration**": "You configure a secret store using a Dapr component configuration file. The typical structure of the\nfile is shown below:\n\nAll Dapr component configuration files require a `name` along with an optional `namespace` value.", "**Indirectly consume Dapr secrets**": "As mentioned earlier in this chapter, applications can also consume secrets by referencing them in\ncomponent configuration files. Consider a state management component that uses Redis cache for\nstoring state:\n\n123 CHAPTER 12 | The Dapr secrets management building block\n\nThe above configuration file contains a **clear-text** password for connecting to the Redis server.\n**Hardcoded** passwords are always a bad idea. Pushing this configuration file to a public repository\nwould expose the password. Storing the password in a secret store would dramatically improve this\nscenario.\n\nThe following examples demonstrate this using several different secret stores.", "**Local file**": "The local file component is designed for development scenarios. It stores secrets on the local\nfilesystem inside a JSON file. Here\u2019s an example named `eshop-secrets.json` . It contains a single\nsecret - a password for Redis:\n\nYou place this file in a `components` folder that you specify when running the Dapr application.\n\nThe following secret store configuration file consumes the JSON file as a secret store. It\u2019s also placed\nin the `components` folder:\n\nThe component type is `secretstore.local.file` . The `secretsFile` metadata element specifies the\npath to the secrets file.\n\nFrom the application folder, start the Dapr application specifying the `components` path as a commandline argument:\n\n```\ndapr run --app-id basket-api --components-path ./components dotnet run\n\n```\n\n124 CHAPTER 12 | The Dapr secrets management building block\n\nThe `nestedSeparator` in a Dapr configuration file specifies a character to _flatten_ a JSON hierarchy.\nConsider the following snippet:\n\nUsing a colon as a separator, you can retrieve the `customerdb` connection-string using the key\n\n`connectionStrings:customerdb` .\n\nIn the next example, a state management configuration file references the local secret store\ncomponent to obtain the password for connecting to the Redis server:\n\nThe `secretKeyRef` element references the secret containing the password. It replaces the earlier _clear-_\n\nelement.\n\nYou might wonder why `eShopRedisPassword` is identical for both the name and key in the secret\nreference. In the local file secret store, secrets aren\u2019t identified with a separate name. The scenario will\nbe different in the next example using Kubernetes secrets.\n\n125 CHAPTER 12 | The Dapr secrets management building block", "**Kubernetes secret**": "This second example focuses on a Dapr application running in Kubernetes. It uses the standard secrets\nmechanism that Kubernetes offers. Use the Kubernetes CLI ( `kubectl` ) to create a secret named `eshop-`\n\n`redis-secret` that contains the password:\n\nOnce created, you can reference the secret in the component configuration file for state management:\n\nKubernetes secrets management component.\n\nIn a production setting, secrets are typically created as part of an automated CI/CD pipeline. Doing so\nensures only people with sufficient permissions can access and change the secrets. Developers create\nconfiguration files without knowing the actual value of the secrets.", "**Azure Key Vault**": "The next example is geared toward a real-world production scenario. It uses **Azure Key Vault** as the\nsecret store. Azure Key Vault is a managed Azure service that enables secrets to be stored securely in\nthe cloud.\n\nFor this example to work, the following prerequisites must be satisfied:\n\n['You\u2019ve secured administrative access to an Azure subscription.', 'You\u2019ve provisioned an Azure Key Vault named `eshopkv` that holds a secret named\\n`redisPassword` that contains the password for connecting to the Redis server.', '[You\u2019ve created service principal in Azure Active Directory.](https://docs.microsoft.com/azure/active-directory/develop/howto-create-service-principal-portal)']\n\n126 CHAPTER 12 | The Dapr secrets management building block\n\n['You\u2019ve installed an X509 certificate for this service principal (containing both the public and\\nprivate key) on the local filesystem.']\n\n[The Dapr Azure Key Vault secret store documentation provides step-by-step instructions to create](https://docs.dapr.io/operations/components/setup-secret-store/supported-secret-stores/azure-keyvault/)\nand configure a Key Vault environment.\n\n**Use Key Vault when running in self-hosted mode**\n\nUsing Azure Key Vault in Dapr self-hosted mode requires the following component configuration file:\n\nThe secret store type is `secretstores.azure.keyvault` . The `metadata` element provides access to the\nKey Vault with the following properties:\n\nKey Vault.\n\n['The `spnClientId` contains the _app ID_ of the service principal used to authenticate against the\\nKey Vault.', 'The `spnCertificateFile` contains the path to the certificate file for the service principal to\\nauthenticate against the Key Vault.']\n\nNow the application can retrieve the Redis password from the Azure Key Vault.\n\n127 CHAPTER 12 | The Dapr secrets management building block\n\n**Use Key Vault when running on Kubernetes**\n\nConsuming Azure Key Vault with Dapr and Kubernetes also requires a service principal to authenticate\nagainst the Azure Key Vault.\n\nFirst, create a _Kubernetes secret_ that contains a certificate file using the kubectl CLI tool:\n\nThe command requires two command-line arguments:\n\nOnce created, you can reference the Kubernetes secret in the secret store component configuration\nfile:\n\nAt this point, an application running in Kubernetes can retrieve the Redis password from the Azure\nKey Vault.\n\n128 CHAPTER 12 | The Dapr secrets management building block\n\n[When running in Azure Kubernetes Service (AKS), it\u2019s preferable to use an Azure Managed Identity for](https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview)\nauthenticating against Azure Key Vault. Managed identities are outside of the scope of this book, but\n[explained in the Azure Key Vault with managed identities](https://docs.dapr.io/operations/components/setup-secret-store/supported-secret-stores/azure-keyvault-managed-identity/) documentation.", "**Scope secrets**": "Secret scopes allow you to control which secrets your application can access. You configure scopes in\n[a Dapr sidecar configuration file. The Dapr configuration documentation](https://docs.dapr.io/operations/configuration/configuration-overview/) provides instructions for\nscoping secrets.\n\nHere\u2019s an example of a Dapr sidecar configuration file that contains secret scopes:\n\nYou specify scopes per secret store. In the above example, the secret store is named `eshop-azurekv-`\n\n`secret-store` . You configure access to secrets using the following properties:\n\n|Property|Value|Description|\n|---|---|---|\n|`defaultAccess`|`allow` or<br>`deny`|Allows or denies access to_all_ secrets in the specified secret store.<br>This property is optional with a default value of`allow`.|\n|`allowedSecrets`|List of<br>secret keys|Secrets specified in the array will be accessible. This property is<br>optional.|\n|`deniedSecrets`|List of<br>secret keys|Secrets specified in the array will NOT be accessible. This property is<br>optional.|"}, "Sample application: Dapr Traffic Control": {"**Secrets**": "Examine the `secrets-file.yaml` component configuration file in the `dapr/components` folder:\n\nhosted mode, use a Local file component. The path must be relatively specified from the folder from\nwhich the service starts. The secrets file contains a JSON representation of the secrets:\n\nIn the sample application the Redis server is used without a password. To connect to the SMTP server,\nthe credentials are `_username` and `_password` . The license key for the FineCalculator license key is a\nrandomly generated string.\n\nWhile secrets are stored at nested levels, the secrets management building block flattens this\nhierarchy when the file is read. It uses a period as a level separator (as specified in the\n\n`nestedSeparator` field in the component configuration file). This construct enables you to reference\nsecrets with a flattened name, for example: `smtp.user` .\n\nWhen running in Kubernetes, the secrets are specified using the built-in Kubernetes secrets store.\nExamine the following `secrets.yaml` Kubernetes manifest file in the `k8s` folder:\n\n131 CHAPTER 12 | The Dapr secrets management building block\n\nThe component is also named `trafficcontrol-secrets` . Secrets are stored as Base64 encoded\nstrings.\n\nThe following paragraphs describe how secrets are used in the Traffic Control sample application.", "**SMTP server credentials**": "Examine the `email.yaml` component configuration file located in the `dapr/components` folder:\n\nWhen running in Kubernetes, the built-in Kubernetes secrets store is used. The `email.yaml` manifest\nfile found in the `k8s` folder references the Kubernetes secret for retrieving the credentials for\nconnecting to the smtp server:\n\n132 CHAPTER 12 | The Dapr secrets management building block\n\nUnlike the local secrets store, the Kubernetes store doesn\u2019t explicitly specify a secrets management\ncomponent to use with the `auth` section. Instead, the default is the built-in Kubernetes secrets store.", "**Redis server credentials**": "Next, examine the `statestore.yaml` component configuration file in the `dapr/components` folder:\n\n133 CHAPTER 12 | The Dapr secrets management building block", "**FineCalculator component license key**": "The FineCollection service uses a component that calculates the fine based on the information of a\nspeeding violation. This component is implemented as a domain service and is abstracted by the\n\n`IFineCalculator` interface:\n\nThe `CalculateFine` method expects a string containing a `licenseKey` as its first argument. This key\nunlocks the third-party component used by the implementation. To keep the example simple, the\n\nThe implementation simulates a check on the `licenseKey` that is passed in. The\n\nmanagement building block that is exposed by the Dapr client in the Dapr SDK for .NET. If you\nexamine the constructor of the `CollectionController`, you can see the call:\n\n134 CHAPTER 12 | The Dapr secrets management building block\n\nThe code determines whether the service is running in Kubernetes or self-hosted mode. This check is\nnecessary because a different secrets management component must be used for each situation. The\nfirst argument of the `GetSecretAsync` method is the name of the Dapr component. The second\nargument is the name of the secret. The `metadata` passed in as the third argument specifies the\nnamespace that contains the secret. The value of the `finecalculator.licensekey` secret is stored in\na private field for later use.\n\nUsing Dapr secrets management offers several benefits:\n\n['No sensitive information is stored in code or application configuration files.', 'No need to learn any new API for interacting with a secrets store.']"}, "Summary": "The Dapr secrets management building block provides capabilities for storing and retrieving sensitive\nconfiguration settings like passwords and connection-strings. It keeps secrets private and prevents\nthem from being accidentally disclosed.\n\nThe building block supports several different secret stores and hides their complexity with the Dapr\nsecrets API.\n\nThe Dapr .NET SDK provides a `DaprClient` object to retrieve secrets. It also includes a .NET\nconfiguration provider that adds secrets to the .NET configuration system. Once loaded, you can\nconsume these secrets in your .NET code.\n\nYou can use secret scopes to control access to specific secrets.", "References": ["[Beyond the Twelve-Factor Application](https://tanzu.vmware.com/content/blog/beyond-the-twelve-factor-app)"]}}, "13": {"Dapr reference application": {"eShopOnContainers": "Several years ago, Microsoft, in partnership with leading community experts, released a popular\n[guidance book, entitled .NET Microservices for Containerized .NET Applications. Figure 12-1 shows the](https://dotnet.microsoft.com/download/e-book/microservices-architecture/pdf)\nbook:\n\n_Figure 12-1. .NET Microservices: Architecture for Containerized .NET Applications._\n\nThe book dove deep into the principles, patterns, and best practices for building distributed\napplications. It included a full-featured microservice reference application that showcased the\n[architectural concepts. Entitled, eShopOnContainers, the application hosts an e-Commerce storefront](https://github.com/dotnet-architecture/eShopOnContainers)\nthat sells various items, including clothing and coffee mugs. Built in .NET, the application is crossplatform and can run in either Linux or Windows containers. Figure 12-2 shows the original eShop\narchitecture.\n\n137 CHAPTER 13 | Dapr reference application\n\n_Figure 12-2. Original ShopOnContainers reference application._\n\nAs you can see, eShopOnContainers includes many moving parts:\n\n['Three different frontend clients.', 'An application gateway to abstract backend services from the frontend.', 'Several backend core microservices.', 'An event bus component that enables asynchronous pub/sub messaging.']\n\nThe eShopOnContainers reference application has been widely accepted across the .NET community\nand used to model many large commercial microservice applications.", "eShopOnDapr": "[An updated version of eShop accompanies this book. It\u2019s called eShopOnDapr. The update evolves](https://github.com/dotnet-architecture/eShopOnDapr)\nthe earlier eShopOnContainers application by integrating Dapr building blocks. Figure 12-3 shows the\nnew solution architecture:\n\n[eShopOnDapr reference application architecture](#g\ufffd\ufffd\ufffdr&\ufffd<\ufffd\ufffdp\ufffd\ufffdr\ufffdm\u0433z\ufffd!c(*\ufffd\u03ce\ufffd9\ufffd\ufffd\ufffd\ufffd>4)\n\n_Figure 12-3. eShopOnDapr reference application architecture._\n\nWhile eShopOnDapr focuses on Dapr, the architecture has also been streamlined and simplified.\n\n['[A Single Page Application running on Blazor WebAssembly sends user requests to an API](https://docs.microsoft.com/archive/msdn-magazine/2013/november/asp-net-single-page-applications-build-modern-responsive-web-apps-with-asp-net)\\ngateway.']\n\n['The API gateway abstracts the backend core microservices from the frontend client. It\u2019s\\n[implemented using Envoy, a high performant, open-source service proxy. Envoy routes incoming](https://www.envoyproxy.io/)']\n\n138 CHAPTER 13 | Dapr reference application\n\nrequests to backend microservices. Most requests are simple CRUD operations (for example, get\nthe list of brands from the catalog) and handled by a direct call to a backend microservice.\n\n['Other requests are more logically complex and require multiple microservice calls to work\\n[together. For these cases, eShopOnDapr implements an aggregator microservice that](https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/service-to-service-communication#service-aggregator-pattern)\\norchestrates a workflow across those microservices needed to complete the operation.']\n\n['The core backend microservices implement the required functionality for an e-Commerce store.\\nEach is self-contained and independent of the others. Following widely accepted domain\\ndecomposition patterns, each microservice isolates a specific _business capability_ :']\n\n- The basket service manages the customer\u2019s shopping basket experience.\n\n- The catalog service manages product items available for sale.\n\n- The identity service manages authentication and identity.\n\n- The ordering service handles all aspects of placing and managing orders.\n\n- The payment service transacts the customer\u2019s payment.\n\n\n\n['[Adhering to best practices, each microservice maintains its own persistent storage. The](https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/distributed-data#database-per-microservice-why)\\napplication doesn\u2019t share a single datastore.']\n\n['Finally, the event bus wraps the Dapr publish/subscribe components. It enables asynchronous\\npublish/subscribe messaging across microservices. Developers can plug in any Dapr-supported\\nmessage broker component.']", "Application of Dapr building blocks": {"**State management**": "In eShopOnDapr, the Basket service uses the state management building block to persist the contents\nof the customer\u2019s shopping basket. The original eShopOnContainers architecture used an\n\nTo compare and contrast, the original eShopOnContainers implementation is presented below:\n\n140 CHAPTER 13 | Dapr reference application\n\nThis code uses the third party `StackExchange.Redis` NuGet package. The following steps are required\nto load the shopping basket for a given customer:\n\n['Inject a Redis `ConnectionMultiplexer` into the constructor. The `ConnectionMultiplexer` is\\nregistered with the dependency injection framework in the _Program.cs_ file:']\n\n['Use the `ConnectionMultiplexer` to create an `IDatabase` instance in each consuming class.']\n\n['Use the `IDatabase` instance to execute a Redis StringGet call using the given `customerId` as the\\nkey.']\n\n['Check if data is loaded from Redis; if not, return `null` .']\n\n['Deserialize the data from Redis to a `CustomerBasket` object and return the result.']\n\nThe updated code uses the Dapr .NET SDK to read and write data using the state management\nbuilding block. The new steps to load the basket for a customer are dramatically simplified:\n\n['Inject a `DaprClient` into the constructor. The `DaprClient` is registered with the dependency\\ninjection framework in the _Program.cs_ `_ file.', 'Use the `DaprClient.GetStateAsync` method to load the customer\u2019s shopping basket items from\\nthe configured state store and return the result.']\n\nThe updated implementation still uses Redis as the underlying data store. But, note how Dapr\nabstracts the `StackExchange.Redis` references and complexity from the application. The application\nno longer requires a direct dependency on Redis. A Dapr configuration file is all that\u2019s needed:\n\n141 CHAPTER 13 | Dapr reference application\n\nThe Dapr implementation also simplifies changing the underlying data store. Switching to Azure Table\nStorage, for example, requires only changing the contents of the configuration file. No code changes\nare necessary.", "**Service invocation**": "The original eShopOnContainers used a mix of HTTP/REST and gRPC services. The use of gRPC was\n[limited to communication between an aggregator service](https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/service-to-service-communication#service-aggregator-pattern) and core backend services. Figure 12-5\nshows the original architecture:\n\n_Figure 12-5. gRPC and HTTP/REST calls in eShopOnContainers._\n\nNote the steps from the previous figure:\n\n['[The frontend calls the API gateway](https://docs.microsoft.com/azure/architecture/microservices/design/gateway) using HTTP/REST.']\n\n142 CHAPTER 13 | Dapr reference application\n\n['[The API gateway forwards simple CRUD](https://www.sumologic.com/glossary/crud/) (Create, Read, Update, Delete) requests directly to a core\\nbackend service using HTTP/REST.']\n\n['The API gateway forwards complex requests that involve coordinated backend service calls to\\nthe web shopping aggregator service.']\n\n['The aggregator service uses gRPC to call core backend services.']\n\nIn the updated eShopOnDapr implementation, Dapr sidecars are added to the services and API\ngateway. Figure 12-6 show the updated architecture:\n\n_Figure 12-6. Updated eShop architecture using Dapr._\n\nNote the updated steps from the previous figure:\n\n['The frontend still uses HTTP/REST to call the API gateway.']\n\n['The API gateway forwards HTTP requests to its Dapr sidecar.']\n\n['The API gateway sidecar sends the request to the sidecar of the aggregator or backend service.']\n\n['The aggregator service uses the Dapr .NET SDK to call backend services through their sidecar\\narchitecture.']\n\nDapr implements calls between sidecars with gRPC. So even if you\u2019re invoking a remote service with\nHTTP/REST semantics, a part of the transport is implemented using gRPC.\n\nThe eShopOnDapr reference application benefits from the Dapr service invocation building block. The\nbenefits also include service discovery, automatic mTLS, and built-in observability.\n\n**Forward HTTP requests using Envoy and Dapr**\n\n[Both the original and updated eShop application leverage the Envoy proxy](https://www.envoyproxy.io/) as an API gateway. Envoy\nis an open-source proxy and communication bus that is popular across modern distributed\n[applications. Originating from Lyft, Envoy is owned and maintained by the Cloud-Native Computing](https://www.cncf.io/)\n[Foundation.](https://www.cncf.io/)\n\n143 CHAPTER 13 | Dapr reference application\n\nIn the original eShopOnContainers implementation, the Envoy API gateway forwarded incoming HTTP\nrequests directly to aggregator or backend services. In the new eShopOnDapr, the Envoy proxy\nforwards the request to a Dapr sidecar.\n\nEnvoy is configured using a YAML definition file to control the proxy\u2019s behavior. To enable Envoy to\nforward HTTP requests to a Dapr sidecar container, a `dapr` cluster is added to the configuration. The\ncluster configuration contains a host that points to the HTTP port on which the Dapr sidecar is\nlistening:\n\nThe Envoy route configuration is updated to rewrite incoming requests as calls to the Dapr sidecar\n(pay close attention to the `prefix_rewrite` key/value pair):\n\nConsider a scenario where the frontend client wants to retrieve a list of catalog items. The Catalog API\nprovides an endpoint for getting the catalog items:\n\nFirst, the frontend makes a direct HTTP call to the Envoy API gateway.\n\n```\nGET http://<api-gateway>/c/api/v1/catalog/items\n\n```\n\nThe Envoy proxy matches the route, rewrites the HTTP request, and forwards it to the `invoke` API of its\nDapr sidecar:\n\n```\nGET http://127.0.0.1:3500/v1.0/invoke/catalog-api/method/api/v1/catalog/items\n\n```\n\n144 CHAPTER 13 | Dapr reference application\n\nThe sidecar handles service discovery and routes the request to the Catalog API sidecar. Finally, the\nsidecar calls the Catalog API to execute the request, fetch catalog items, and return a response:\n\n```\nGET http://localhost/api/v1/catalog/items\n\n```\n\n**Make aggregated service calls using the .NET SDK**\n\nMost calls from the eShop frontend are simple CRUD calls. The API gateway forwards them to a single\nservice for processing. Some scenarios, however, require multiple backend services to work together\nto complete a request. For the more complex calls, the web shopping aggregator service mediates the\ncross service workflow. Figure 12-7 show the processing sequence of adding an item to your\nshopping basket:\n\n_Figure 12-7. Backend call requiring multiple services._\n\nThe aggregator service first retrieves catalog items from the Catalog API. It then validates item\navailability and pricing. Finally, the aggregator service updates the shopping basket by calling the\nBasket API.\n\nThe aggregator service contains a `BasketController` that provides an endpoint for updating the\nshopping basket:\n\n145 CHAPTER 13 | Dapr reference application\n\nprotected backend services.\n\nAfter receiving a request to update the basket, the aggregator service calls the Catalog API to get the\nitem details. The Basket controller uses an injected `ICatalogService` object to make that call and\ncommunicate with the Catalog API. The original implementation of the interface used gRPC to make\nthe call. The updated implementation uses Dapr service invocation with HttpClient support:\n\n146 CHAPTER 13 | Dapr reference application\n\nNotice how no Dapr-specific code is required to make the service invocation call. All communication is\ndone using the standard HttpClient object.\n\nThe Dapr HttpClient is configured for the `CatalogService` class on program startup:\n\nThe other call made by the aggregator service is to the Basket API. It only allows authorized requests.\nThe access token is passed along in an _Authorization_ request header to ensure the call succeeds:\n\nIn this example too, only standard HttpClient functionality is used to call the service. This allows\ndevelopers who are already familiar with HttpClient to reuse their existing skills. It even enables\nexisting HttpClient code to use Dapr service invocation without making any changes.", "**Publish & subscribe**": "[Both eShopOnContainers and eShopOnDapr use the pub/sub pattern for communicating integration](https://devblogs.microsoft.com/cesardelatorre/domain-events-vs-integration-events-in-domain-driven-design-and-microservices-architectures/#integration-events)\n[events](https://devblogs.microsoft.com/cesardelatorre/domain-events-vs-integration-events-in-domain-driven-design-and-microservices-architectures/#integration-events) across microservices. Integration events include:\n\n['When a user checks-out a shopping basket.', 'When a payment for an order has succeeded.', 'When the grace-period of a purchase has expired.']\n\nEventing in eShopOnContainers is based on the following `IEventBus` interface:\n\n147 CHAPTER 13 | Dapr reference application\n\nConcrete implementations of this interface for both RabbitMQ and Azure Service Bus are found in\neShopOnContainers. Each implementation included a large amount of custom plumbing code that\nwas complex to understand and difficult to maintain.\n\nThe newer eShopOnDapr significantly simplifies pub/sub behavior by using Dapr. To start, the\n\n`IEventBus` interface was reduced to a single method:\n\n**Publish events**\n\nIn eShopOnDapr, a single `DaprEventBus` implementation can support any Dapr-supported message\nbroker. The following code block shows the simplified Publish method. Note how the `PublishAsync`\nmethod uses the Dapr client to publish an event:\n\nAs you can see in the code snippet, the topic name is derived from event type\u2019s name. Because all\neShop services use the `IEventBus` abstraction, retrofitting Dapr required _absolutely no change_ to the\nmainline application code.\n\n148 CHAPTER 13 | Dapr reference application\n\nWith Dapr, pub/sub infrastructure code is **dramatically simplified** . The application doesn\u2019t need to\ndistinguish between message brokers. Dapr provides this abstraction for you. If needed, you can easily\nswap out message brokers or configure multiple message broker components with no code changes.\n\n**Subscribe to events**\n\nThe earlier eShopOnContainers app contains _SubscriptionManagers_ to handle the subscription\nimplementation for each message broker. Each manager contains complex message broker-specific\ncode for handling subscription events. To receive events, each service has to explicitly register a\nhandler for each event-type.\n\neShopOnDapr streamlines the plumbing for event subscriptions by using Dapr ASP.NET Core\nintegration. Each event is handled by an action method in a controller. A `Topic` attribute decorates the\naction method with the name of the corresponding topic. Here\u2019s a code snippet taken from the\n\n`PaymentService` :\n\nIn the `Topic` attribute, the name of the .NET type of the event is used as the topic name. For handling\nthe event, an event handler that already existed in the earlier eShopOnContainers code base is\nresolved using dependency injection and invoked. In the previous example, messages received from\n\nimplements the underlying plumbing for subscriptions and message brokers, a large amount of\noriginal code became obsolete and was removed from the code-base. Much of this code was complex\nto understand and challenging to maintain.\n\n149 CHAPTER 13 | Dapr reference application\n\n**Use pub/sub components**\n\nspecifies the Dapr pub/sub component that the application will use for pub/sub behavior. As you saw\n\nThe configuration specifies RabbitMQ as the underlying infrastructure. To change message brokers,\nyou need only to configure a different message broker, such as NATS or Azure Service Bus and update\nthe yaml file. With Dapr, there are no changes to your mainline service code when switching message\nbrokers.\n\nYou can also easily use multiple message brokers in a single application. Many times a system will\nhandle workloads with different characteristics. One event may occur 10 times a day, but another\nevent occurs 5,000 times per second. You may benefit by partitioning messaging traffic to different\nmessage brokers. With Dapr, you can add multiple pub/sub component configurations, each with a\ndifferent name.", "**Bindings**": "eShopOnDapr uses the bindings building block for sending e-mails. When a user places an order, the\n[application sends an order confirmation e-mail using the SMTP](https://docs.dapr.io/reference/components-reference/supported-bindings/smtp) output binding. You can find this\nbinding in the `eshop-email.yaml` file in the components folder:\n\n150 CHAPTER 13 | Dapr reference application\n\nDapr gets the username and password for connecting to the SMTP server from a secret reference. This\napproach keeps secrets outside of the configuration file. To learn more about Dapr secrets, read the\nsecrets building block chapter.\n\nThe binding configuration specifies a binding component that can be invoked using the `/sendmail`\nendpoint on the Dapr sidecar. Here\u2019s a code snippet in which an email is sent whenever an order is\nstarted:\n\noperation is `create` . The `metadata` specifies the email sender, recipient, and subject for the email\nmessage. If these values are static, they can also be included in the metadata fields in the\nconfiguration file.\n\n151 CHAPTER 13 | Dapr reference application", "**Actors**": "In the original eShopOnContainers solution, the Ordering service provides a great example of how to\nuse DDD design patterns in a .NET microservice. As the updated eShopOnDapr focuses on Dapr, the\nOrdering service now uses the actors building block to implement its business logic.\n\nThe ordering process consists of the following steps:\n\n['The customer submits the order. There\u2019s a grace period before any further processing occurs.\\nDuring the grace period, the customer can cancel the order.', 'The system checks that there\u2019s available stock.', 'The system processes the payment.', 'The system ships the order.']\n\nThe process is implemented using a single `OrderingProcessActor` actor type. Here\u2019s the interface for\nthe actor:\n\nThe process is started when a customer checks out some products. Upon checkout, the Basket service\npublishes a `UserCheckoutAcceptedIntegrationEvent` message using the Dapr pub/sub building\nblock. The Ordering service handles the message in the `OrderingProcessEventController` class and\ncalls the `SubmitAsync` method of the actor:\n\n152 CHAPTER 13 | Dapr reference application\n\nIn the example above, the Ordering service first uses the original request ID from the\n\n153 CHAPTER 13 | Dapr reference application\n\nThere\u2019s a lot going on in the `Submit` method:\n\n['The method takes the given arguments to create an `OrderState` object and saves it in the actor\\nstate.', 'The method saves the current status of the process ( `OrderStatus.Submitted` ) in the actor state.', 'The method registers a reminder to signal the end of the grace period. Order processing is\\ndelayed until the end of the grace period to deal with customers changing their mind.', 'Lastly, the method publishes an `OrderStatusChangedToSubmittedIntegrationEvent` to notify\\nother services of the status change.']\n\nWhen the reminder for the grace period ending fires, the actor runtime calls the\n\n`ReceiveReminderAsync` method:\n\nAs shown in the snippet above, the `ReceiveReminderAsync` method handles not just the grace period\nreminder. The actor also uses reminders to simulate background work and introduce some delays in\nthe ordering process. This makes the process easier to follow in the eShopOnDapr UI where\nnotifications are shown for each status update. The `ReceiveReminderAsync` method uses the\nreminder name to determine which method handles the reminder. The grace period reminder is\nhandled by the `OnGracePeriodElapsedAsync` method:\n\n154 CHAPTER 13 | Dapr reference application\n\nservice of the status change. For example, the Category service subscribes to this event to check the\navailable stock.\n\nLet\u2019s look at the `TryUpdateOrderStatusAsync` method to see under which circumstances it may fail to\nupdate the order status:\n\nFirst, the `TryUpdateOrderStatusAsync` method checks whether there even is a current order status. If\nthere isn\u2019t, the order doesn\u2019t exist. This is a fail-safe that should not happen with normal application\nusage. Then, the method checks whether the current order status is the status that we expected.\nRemember that the ordering process is driven by events using the Dapr pub/sub building block. Event\ndelivery uses at-least-once semantics, so a single message could be received multiple times. The order\nstatus check ensures that even when the same message is received multiple times, it is only processed\nonce.\n\nThe other steps in the ordering process are all implemented in a very similar way to the grace period\nstep. In the next sections, we\u2019ll look at some other aspects of the ordering process, namely\ncancellation and viewing order details.\n\n155 CHAPTER 13 | Dapr reference application\n\n**Order cancellation**\n\nCustomers are allowed to cancel any order that has not been paid or shipped yet. The\n\nThe `CancelAsync` method consists of the following steps:\n\n['First, the method ensures that the order exists by retrieving the current order status.', 'If the order exists, the method checks whether it\u2019s eligible for cancellation. Any order not in the\\n`Paid` or `Shipped` state can be cancelled.', 'If the order can be cancelled, the order status is changed to `Cancelled` .', 'Lastly, the order details are retrieved from state and used to publish an\\n`OrderStatusChangedToCancelledIntegrationEvent` to inform the other services.']\n\nThe `CancelAsync` method is a great example of the usefulness of the turn-based access model of\nactors. Nowhere in the method do we need to worry about multiple threads running at the same time.\nTherefore, the method does not require any explicit locking mechanisms to be correct.\n\n156 CHAPTER 13 | Dapr reference application\n\n**Order details**\n\nCustomers can check the status and details of their order in the eShopOnDapr UI. They can also view\na complete history of past orders. Directly querying actor instances for this information is a bad idea\nbecause of two reasons:\n\n['Low-latency reads cannot be guaranteed because actor operations execute serially.', 'Querying across actors is inefficient because each actor\u2019s state needs to be read individually and\\ncan introduce more unpredictable latencies.']\n\nTo fix this issue, eShopOnDapr uses a separate read model for any queries on order data. The read\nmodel is stored in a separate SQL database. An ASP.NET Core controller class named\n\nto inform the customer of order status updates.\n\nThe following snippet shows the code for handling the\n\n`OrderStatusChangedToSubmittedIntegrationEvent` message:\n\nThe handler contains the code for all the actions that must occur after an order is submitted\nsuccessfully. Because the events originate from the `OrderingProcessActor`, we can be sure that any\nvalidations performed by the actor have succeeded.\n\nThe handler performs the following steps:\n\n157 CHAPTER 13 | Dapr reference application\n\n['First, the method creates an actor proxy and uses it to retrieve the order details from the actor\\ninstance.', 'The method maps the order details to the read model and stores it in the database. Due to the\\nat-least-once semantics of the Dapr pub/sub building block, the order may already exist in the\\ndatabase. In that case, it will not be overwritten.', 'The method publishes a push notification for the status update using SignalR.', 'Lastly, if enabled, the method sends a confirmation e-mail to the customer.']\n\nSubsequent order status updates are all handled equally to each other. The following snippet shows\nwhat happens when the order status is updated to `AwaitingStockValidation` :\n\nIn the snippet, the handler calls the `UpdateReadModelAndSendNotificationAsync` helper method to\nhandle the status update:\n\n['The helper method first loads the current order from the database.', 'If that succeeds, it updates the `OrderStatus` and `Description` fields and saves the updated\\nmodel back to the database.', 'Lastly, it sends a push notification to notify the client UI.']", "**Observability**": "[eShopOnDapr uses Zipkin to visualize distributed traces collected by Dapr. Seq](https://zipkin.io/) aggregates the\n[eShopOnDapr application logs. The various services emit structured logging using the SeriLog](https://serilog.net/) logging\nlibrary. Serilog publishes log events to a construct called a **sink** . A sink is simply a target platform to\n[which Serilog writes its logging events. Many Serilog sinks are available, including one for Seq. Seq is](https://github.com/serilog/serilog/wiki/Provided-Sinks)\nthe Serilog sink used in eShopOnDapr.\n\n158 CHAPTER 13 | Dapr reference application\n\neShopOnDapr also includes a custom health dashboard that gives insight into the health of the eShop\n[services. This dashboard uses the built-in health checks mechanism](https://docs.microsoft.com/aspnet/core/host-and-deploy/health-checks) of ASP.NET Core. The dashboard\nnot only provides the health status of the services, but also the health of the dependencies of the\nservices, including the Dapr sidecars.", "**Secrets**": "The eShopOnDapr reference application uses the secrets building block for various secrets:\n\n['The password for connecting to the Redis cache.', 'The username and password for the SMTP server.', 'The connection strings for the SQL databases.']\n\nWhen running the application using Docker Compose, the **local file** secret store is used. The\ncomponent configuration file `eshop-secretstore.yaml` is found in the `dapr/components` folder of\nthe eShopOnDapr repository:\n\nThe configuration file references the local store file `eshop-secretstore.json` located in the same\nfolder:\n\nThe `components` folder is specified in the command-line and mounted as a local folder inside the Dapr\nsidecar container. Here\u2019s a snippet from the `docker-compose.override.yml` file in the repository root\nthat specifies the volume mount:\n\n159 CHAPTER 13 | Dapr reference application\n\nOnce configured, other component configuration files can also reference the secrets. Here\u2019s an\nexample of the state store component configuration consuming secrets:"}, "Benefits of applying Dapr to eShop": "In general, the use of Dapr building blocks adds observability and flexibility to the application:\n\n['Observability: By using the Dapr building blocks, you gain rich distributed tracing for calls\\nbetween services and to Dapr components without having to write any code. In\\neShopOnContainers, a large amount of custom logging is used to provide insight.', 'Flexibility: You can now _swap out_ infrastructure simply by changing a component configuration\\nfile. No code changes are necessary.']\n\nHere are some more examples of benefits offered by specific building blocks:\n\n['**Service Invocation**', ['[With Dapr\u2019s support for mTLS, services now communicate through encrypted channels.](https://blog.cloudflare.com/introducing-tls-client-auth/)', 'When transient errors occur, service calls are automatically retried.']]\n\n160 CHAPTER 13 | Dapr reference application\n\n- Automatic service discovery reduces the amount of configuration needed for services to\n\nfind each other.\n\n['**Publish/Subscribe**', ['eShopOnContainers included a large amount of custom code to support both Azure\\nService Bus and RabbitMQ. Developers used Azure Service Bus for production and\\nRabbitMQ for local development and testing. An `IEventBus` abstraction layer was\\ncreated to enable swapping between these message brokers. This layer consisted of\\napproximately _700 lines of error-prone code_ . The updated implementation with Dapr\\nrequires only _35 lines of code_ . That\u2019s **5%** of the original lines of code! More importantly,\\nthe implementation is straightforward and easy to understand.', 'eShopOnDapr uses Dapr\u2019s rich ASP.NET Core integration to use pub/sub. You add `Topic`\\nattributes to ASP.NET Core controller methods to subscribe to messages. Therefore,\\nthere\u2019s no need to write a separate message handler loop for each message broker.', 'Messages routed to the service as HTTP calls enable the use of ASP.NET Core\\nmiddleware to add functionality, without introducing new concepts or SDKs to learn.'], '**Bindings**', ['The eShopOnContainers solution contained a _to-do_ item for e-mailing an order\\nconfirmation to the customer. With Dapr, implementing email notification was as easy as\\nconfiguring a resource binding.'], '**Actors**', ['The actors building block makes it easy to create long running, stateful workflows.\\nThanks to the turn-based access model, there\u2019s no need for explicit locking mechanisms.', 'The complexity of the grace period implementation is greatly reduced by using actor\\nreminders instead of polling on the database.']]", "Summary": {"**References**": ["[eShopOnDapr](https://github.com/dotnet-architecture/eShopOnDapr)"]}}}, "14": {"Summary and the road ahead": {"The road ahead": "Looking forward, Dapr has the potential to have a profound impact on distributed application\ndevelopment. What can you expect from the Dapr team and its open-source contributors?\n\nAt the time of writing, the list of proposed enhancements for Dapr include:\n\n['Feature enhancements to existing building blocks:', ['Query capabilities in state management enabling you to retrieve multiple values.', 'Topic filtering in pub/sub enabling you to filter topics based on their content.', 'An application tracing API in observability that provides tracing in the application\\ndirectly without having to bind to specific libraries.', 'Binding and pub/sub support for actors providing event driven capabilities to the actor\\nprogramming model. Bound components will trigger events and messages invoke\\nmethods in the actor.'], 'New building blocks:', ['Configuration API building block for reading and writing configuration data. The block\\nwill bind to providers that include Azure Configuration Manager or GCP Configuration\\nManagement.', 'Http scale-to-zero autoscale.', 'Leader election building block to provide singleton instances and locking semantic\\ncapabilities.', 'Transparent proxying building block for service invocation, enabling you to route\\nmessages based on URLs or DNS addresses at the network level.', 'Resiliency building block (circuit breakers, bulkheads & timeouts).'], 'Integration with frameworks and cloud native technologies. Some examples include:', ['Django', 'Nodejs', 'Express', 'Kyma', 'Midway'], 'New language SDKs:', ['JavaScript', 'RUST', 'C++']]\n\n165 CHAPTER 14 | Summary and the road ahead\n\n['New hosting platforms:', ['VMs', 'Azure IoT Edge', 'Azure Stack Edge', 'Azure Service Fabric'], 'Developer and operator productivity tooling:', ['VS Code extension.', 'Remote Dev Containers for local debugging a DevOps pipeline development.', 'Dapr operational dashboard enhancements that will provide deeper visibility into the\\noperational concerns of managing Dapr applications.']]\n\nDapr version 1.0 provides developers with a compelling toolbox for building distributed applications.\nAs the proposed enhancement list shows, Dapr is under active development with many new\n[capabilities to come. Stay tuned to the Dapr site](https://dapr.io/) [and Dapr announcement blog](https://cloudblogs.microsoft.com/opensource/2019/10/16/announcing-dapr-open-source-project-build-microservice-applications/) for future updates.\n\n166 CHAPTER 14 | Summary and the road ahead"}}}