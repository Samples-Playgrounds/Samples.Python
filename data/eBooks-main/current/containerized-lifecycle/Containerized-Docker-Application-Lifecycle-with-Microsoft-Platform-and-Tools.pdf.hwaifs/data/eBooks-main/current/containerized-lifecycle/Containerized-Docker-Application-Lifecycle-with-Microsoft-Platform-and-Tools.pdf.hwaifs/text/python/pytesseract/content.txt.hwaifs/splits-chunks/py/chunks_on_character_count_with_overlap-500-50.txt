['Containerized Doc\nApplication Litecycle\nMicrosoft Platform an\nTools\n\nCesar de la Torre\nMicrosoft Corp.\n\nEDITION v6.0.0 - Updated to ASP.NET Core 6.0\n\nRefer changelog for the book updates and community contributions.\n\nThis guide is a general overview for developing and deploying containerized ASP.NET Core\n\napplications with Docker, using the Microsoft platform and tools. The guide includes a high-level\nintroduction to Azure DevOps, for implementin', 'g CI/CD pipelines, as well as Azure Container Registry\n\n(ACR) and Azure Kubernetes Services AKS for deployment.\n\nFor low-level, development-related details you can see the .NET Microservices: Architecture for\nContainerized .NET Applications guide and it related reference application eShopOnContainers.\n\nCredits\n\nAuthor:\n\nCesar de la Torre, Sr. PM, .NET product team, Microsoft Corp.\nAcquisitions Editor:\n\nJanine Patrick\n\nDevelopmental Editor:\n\nBob R', 'ussell, Solutions Professional at Microsoft\n\nOctal Publishing, Inc.\n\nEditorial Production:\n\nDianne Russell\n\nOctal Publishing, Inc.\n\nCopyeditor:\n\nBob Russell, Solutions Professional at Microsoft\n\nParticipants and reviewers:\n\nNish Anil, Sr. Program Manager, .NET team, Microsoft\nMiguel Veloso, Software Development Engineer at Plain Concepts\nSumit Ghosh, Principal Consultant at Neudesic\n\nColin Dembovsky, DevOps Practice Lead, Cognizant Microsoft Busi', 'ness Group\n\nCopyright\nPUBLISHED BY\n\nMicrosoft Developer Division, .NET and Visual Studio product teams\n\nA division of Microsoft Corporation\nOne Microsoft Way\nRedmond, Washington 98052-6399\nCopyright © 2022 by Microsoft Corporation\n\nAll rights reserved. No part of the contents of this book may be reproduced or transmitted in any\nform or by any means without the written permission of the publisher.\n\nThis book is provided “as-is” and expresses the a', "uthor's views and opinions. The views, opinions, and\ninformation expressed in this book, including URL and other Internet website references, may change\nwithout notice.\n\nSome examples depicted herein are provided for illustration only and are fictitious. No real association\nor connection is intended or should be inferred.\n\nMicrosoft and the trademarks listed at https://www.microsoft.com on the “Trademarks” webpage are\ntrademarks of the Microsoft ", 'group of companies.\n\nMac and macOS are trademarks of Apple Inc.\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permission.\n\nAll other marks and logos are property of their respective owners.\nContents\n\nOverview of Containers and Docket ...................ccccccccsssssssscssscscssscsssssscccccccsscsssssssssssssssssseoeees 1\nLearn DOCKED oe eeeeceesessessesseseesessessesessecuesucsessesucsscsesucsscsecsecucsucsesuesscsecsesu', 'csucsesuesucsessesuesucsessesucsecsesuesscsecnesucaessecucaesaeeneaeaeeneeneasens 2\nComparing Docker containers with Virtlal MACHINES uu... cesesessesessecessecessecessesessecessessssesessecessesesseeesseetsseseeseeess 3\n\nA SIMPIE ANALOGY... eseesessesessesessesessesessesessesessesessesssesssesussesussesessesussesssesussesscsesusssscsesecsesussssessesesnssesuesesessecesseensseeesseeeeseeeees 4\nLearn Docker Specific ter MiINOlOGIe@ ......cccesssse', 'ssessessesessessesscsessessesussessecsssessessecussessesussussessecussessecucsussessecucsesseeuessseeseensseess 4\nLearn docker Containers, IMAGES, ANC FEGIStIieS .......ceesessessesessesessesesscsessesessesessesessesessesseseseesssessesesseseeseseeseseeseseeneens 6\nRoad to MOderNn applications DaSed ON CONTAINETS ou... .ecesessessessssssessesesscsesssssssesessesessesecsssessesessesesseseesesesseseeseaseneens 8\nIntroduction to the Docker applicati', 'on life cycle ......................cccccccccssssssssssssccsssssssssssccsssees 9\nContainers as the foundation for DevOps CONADOrAatION ou... eee esessessesessesscsessessecessessecscsssesseeesseeseesssesseeneeeses 9\nChallenges in the application life cycle WHEN USING DOCKED. ......cecesesssssssesssssesessessesesessecsssessesseessesseeneaeaes 10\nIntroduction to a generic end-to-end Docker application life cycle WOrkfIOW ou... ccesesessesteseeseetee', 'eesee 11\nBenefits of DevOps for CONntaINEriZEd APPLICATIONS oo... ceceesessessesesesseesecsesesseesesecsessecsssesseeseseeseeseeneseeseeneeeeses 12\nIntroduction to the Microsoft platform and tools for containerized apps..................... 13\nDesigning and developing containerized apps using Docker and Microsoft Azure ...... 17\nDeSIGN Docker Applications uu... eccessessssesessessssessssessssessssesessesssesussesesesussessssesussesessesessesesses', 'essesessesessesessesessesesseseeseaeeneess 17\nCOMMON CONtAINEr GESIGN PFINCIPlOS.......ececessesesecsssesessecessesessesessesessesessessssessssesussesussessssesesseesseeesseseeseeesseeesseeesseeess 18\nCONtaiNer EQUAIS A PLFOCESS uu... eeeececssssssessesessesessesessesessssessesessesssesessesessesessesecsesessesessesecsesssseseesesessesesseseeseseeseaeenesneseess 18\nMOMNOIithic APPliCAatiON uu... escesessesessessssesessecsssesesseseesecsssessssess', 'ssessssesussesussessssesussessssesessesussesssesecsesessesessesessesessesesseaeeneens 18\nMonolithic application deployed aS a CONTAINED uc. .eeesecsesssssssesessesssesessesessesesscsesecsecessecseseseesesesseceeseeesseeneseenees 21\nPublish a single Docker container app to AZUre App SEPVICE uu... eesesessssesessssessesssecscsesessecscsesessessseeneseenees 21\nState and data In Docker applications... ceecessessssessssecsssssessessssscessecssecssecss', 'ecssesesseeessesssesessesesseeessesesseessseeesseees 22\nService-Ori@Nted APPLICATIONS ou... eccesesessesessesesseseesesssesessecsesecsssesessessssesussecsesecsesessesesussecussessesesusseesseeesseeesseetsseeneseeess 25\n\nOrchestrating microservices and multi-container applications for high scalability and availability... 25\n\nSoftware platforms for container clustering, orchestration, ANd SCHECUIING uu... cccccsesesecseeesseeseeeeseens 27\nUsing con', 'tainer-based orchestrators in AZULC......cceecesssssssssssscsesscsssssesecsssscsesscsessesecessessesesessesusseeesseeesseeeseenees 28\nUsing AZUre KUbernetes Service .....cccessssssssssssesssssssssessssssesscsessssessesessssessssessssessssesussesessecussecsssesesseseesecesseeesseensseenses 29\nDevelopment environment fOr KUDErNeteS uu... cccecessessssessessesessessecsesessessecsssesseesesessessecessesseeseseeseeseeeseeseeneeesses 30\nGet started wit', 'h Azure Kubernetes Service (AKS) wc ccscsscscscsscscsssscscscssscssscsscscsssscsssssscsssssscsssesscasscseeaees 31\n\ni Contents\nDeploy with Helm charts into Kubernetes ClUStErS...... ce ecesssssssesessesessssessssssssssecsecessecsssesesseeessecesseeesseensseeeees 31\nACditional reSOULCES ......cessesessessessessesessessessesessecscsecsessesscsessecuescsecuesucsessessesecsesuessesessesuesessecueseesesuecusseeseeueaeeaeeneeeeaeeneenenees 32\nUSING AZU', 're S@rViCe Fabric... eeessesessesssesssscsessesessesessesessesessesessesessesessesessssessesessesessssesussecsssessesecessesussecesseeesseeeeseenees 32\nStateless versus StatefUl MICFOSEVICES .......cecsessessessessessecsessecsessssscsscssssusssecucsucsucsucsucsucscsecsecsecseeseeseeseeseeaeeseeneeneeneens 35\nUsing AZUre Service Fabric MOSHI... esecsessssessessssssssesssscsesscsesscsesscsessesessssessssessesessssesessecessecuesesesseseesecesseeess', 'eensseenees 36\nCHOOSING Orchestrators IN AZUL oo. .ccececsesssssssesessessssssessesessesessesessesessesessesessesessesessesessessssesessesesseseeseaeeseseeseseeneseeseess 37\nDeploy to Azure Kubernetes Service (AKS) ....c.ccesssssssesssssessesssscsessessssesessesessesessesessesessesessesessesessesessesessesessesesseseeseess 38\nCreate the AKS envirOnMent IN AZULEC uu... ecessesessesseseseesessessesecsecucsuesessecucsessecucsucsecsesuesessecuesecsec', 'seseseeseeneateneeneaseass 38\nCreate the AKS CUSTOM... ee ecesesssssessesessessessecsesessecucsessesuesussessesnescsesuesucsessecucsessesucsucsessecucsecsesuesecsecuecussesseeneneeneeneaneass 38\nDevelopment environment for DOCKEr APPS «0... ecesessessessessessssessesesssssecucsessecscsucsessecussessecsesussessecucsesseencsesseeseeeeseess 40\nDevelopment tools Choices: IDE OF CCItOP ne eeesessessssessesessssssscsessesessesessesessesesseseseesecesse', 'csesecesseesesecnsseeesseeneaeenees 40\nLanguage and framework CHOICES ......cccecessessessesessessessssessesscsessessecussessecscsessessecussessecucsussessecessesseeuesessesseeneseeseeneeeeaess 41\nInner-loop development workflow for DOCKEr APPS uu... cceeesessesessssseseesessecscsessessecuesessecsesessessesucsesseesessseeneensssess 41\nBuilding a single app within a Docker container using Visual Studio Code and Docker CLI............. 42\nUse Docke', 'r Tools in Visual Studio ON WINKOWS.......eecessessessessesesseseeseesessesscsecsecucsessecueneseesecucsecsecucseeaeenesueaeeneeneasens 52\nConfigure YOUr lOCal ENVIFONMENE .......eccesecsessessecessessesscsesseesecsssessecscsussessesucsessecussusseesesucsessecuesesseeussusseesecusseeseeneaneaes 52\nDocker SUPPOrt IN VisUal StUCIO oo. cessssessesessesessessssssessesesscsssscsesscsessssessesessssessssesessecussessssesesseeessecnsseeesseensseenees 52', '\nCONFIGUrE DOCKEr COIS... eeeccessssessessesessessecscsssessecussessesucsussessecussssecucsussessecussssecussussesuesussessecucsussesuesussessecucsesseeneaneass 55\n\nUsing Windows PowerShell commands in a DockerFile to set up Windows Containers (Docker\n\nStANAL DASE) woe scscscsssscscscsssscscsssscscscsscscscsscscsssscscsssscscsssscscscsscscsssscscsesscsescscscscsavscseacacsssscscsasscacsasscsssecaeacsasacaseeeees 56\nBuild ASP.NET Core applications', ' deployed as Linux containers into an AKS/Kubernetes orchestrator\nsaseuscuscuecuccuccuccucsucsucsucsucsscsscsscsscsucsucsucssssscsscuessecussussuccucsucaucsucsussussucsucsucsucsucsucsucsscsessessecsecnecuecuscuecuccucsucsucsucsucsuesucaeaeeaeeateaeeaeeaeeneensens 57\nCreating the ASP.NET Core Project USINg Visual StUCGIO 2022... esessessesessesessesessesessesessesessesesseseeneseeseees 5/\nRegister the Solution in an Azure Container Registry (ACR) ', '.....cccccssssssssssssssssssecsssessesesesessesessecsseeesseeneseenees 66\nDocker application DevOps workflow with Microsoft tools...................s:ccccccccsssssssssseccees 74\nSteps in the outer-loop DevOps workflow for a Docker application ......c.cceesccsessesessesessesesesseesesesseeseeeseees 15\nStep 1: Inner-loOOp develoPMeENt WOrKFOW uu... cccessessesesessessecscsessessesssessecscsessessesessessecscsucseesesessesseeessesseeseeneseess 76\n\nS', 'tep 2: Source-Code Control integration and management with Azure DevOps Services and Git 76\n\nStep 3: Build, Cl, Integrate, and Test with Azure DevOps Services/GitHub and Docker’... 76\nStep 4: CD, Deploy wu. ee ecesssssssessssessssessssesessesessesessesessesssesussessssesussesussesussesussessssesussesessesusseeussesussesessecusseceeseeeeseaneseesees 83\nStep 5: RUN ANd MANAGE... esessessessssessssessssesessessssessssesussesussesussesussesuesesssses', 'ussesussesussesussesussecusseaussecesseaseseensseeeeseansaeesees 89\nStep 6: MONItOL AN GlAGNOSE wu... eeesessessesessessssesessessssesssesssesussessesesussessesesussessssessssesussessssessssecessesesseaesseeseseensseenees 89\n\nContents\n\nmE Microsoft\nmE Microsoft\n\nCreate CI/CD pipelines in Azure DevOps Services for a .NET application on Containers and\n\nCeploying to a Kubernetes CIUSter ue ccessesessessssessssessssesessesessessssesessesssessssesssse', 'sssesssesesseseesesssesesseseeseeesseeesseeeeseeess 89\nRun, manage, and monitor Docker production environments ...............sssssscccccccccccccceeees 93\nRun composed and microservices-based applications in production EnvirOnMeNt ........ccceseeseeeeees 93\nIntroduction to orchestrators, schedulers, and Container CIUSTELS .......eesesesessesesseceesessseceeseceeseeteseeeseenees 93\nManage production Docker EnvirOnMe nt .......cccssessssessssesssse', 'ssssessssessssesessesessessssesessesessesessesessesessesessesessesessesesseseeseens 94\nContainer Service ANd MANAGEMEN tOOIS 0... ecesessssessesessesessesessesessesessesessesessesessesessesesseseesesesseseeseseeseseeseseeseess 94\nAZUre Service Fabric... escesessesseseseesessessesessessecucsessessesscsessesuesecsecsesussessessesecsesuesscsessesussessesucseesessesusseeseseeneeseeneeesseeneenenees 95\nMonitor ContaineriZed application SErVICES ......', '.escesessesessesessesessesessesessesessesessesessesessesessesessesessesessesessesessesesseseeseseeseess 96\nAV AU] C28 \\V/ [0] 0] <0) ee eee 96\nSECUrIty ANA DACKUP SEFVICES........eecesscsessesessesessesessessssessssesssessssesussessssesussesussessssesussesucsesusseensseaussesessesussecesseeesseaneseenees 96\nContainerized Docker Application Lifecycle key takeaway.......................cccccssssssssesssssseees 98\n\niil Contents\nCHAPTER\n\nOverview of ', 'Containers\nand Docker\n\nContainerization ts an approach to software development in which an application or service, tts\ndependencies, and its configuration (abstracted as deployment manifest files) are packaged together as\na container image. You then can test the containerized application as a unit and deploy it as a container\nimage instance to the host operating system (OS).\n\nJust as shipping containers allow goods to be transported by ship, trai', 'n, or truck regardless of the\ncargo inside, software containers act as a standard unit of software deployment that can contain\ndifferent code and dependencies. Containerizing software this way enables developers and IT\nprofessionals to deploy them across environments with little or no modification.\n\nContainers also isolate applications from each other on a shared OS. Containerized applications run\non top of a container host that in turn runs on t', 'he OS (Linux or Windows). Containers therefore have a\nmuch smaller footprint than virtual machine (VM) images.\n\nEach container can run a whole web application or a service, as shown in Figure 1-1. In this example,\nDocker host is a container host, and App1, App2, Svc1, and Svc2 are containerized applications or\nservices.\n\nDocker Host\n\nwv ©\nw~®’\n\nOS ona VM or a server\n\nFigure 1-1. Multiple containers running on a container host\n\nAnother benefit you', ' can derive from containerization is scalability. You can scale out quickly by\ncreating new containers for short-term tasks. From an application point of view, instantiating an\nimage (creating a container) is similar to instantiating a process like a service or web app. For\nreliability, however, when you run multiple instances of the same image across multiple host servers,\nyou typically want each container (image instance) to run in a different ', 'host server or VM in different\nfault domains.\n\nIn short, containers offer the benefits of isolation, portability, agility, scalability, and control across the\nentire application lifecycle workflow. The most important benefit is the environment isolation\nprovided between Dev and Ops.\n\n1 CHAPTER 1 | Overview of Containers and Docker\nLearn Docker\n\nDocker is an Open-source project for automating the deployment of applications as portable, self-\nsuffi', 'cient containers that can run on the cloud or on-premises. Docker is also a company that\npromotes and evolves this technology, working in collaboration with cloud, Linux, and Windows\nvendors, including Microsoft.\n\ni\n\nService\nProvider\n\nDocker\n\nFigure 1-2. Docker deploys containers at all layers of the hybrid cloud\n\nAs shown in the above diagram, Docker containers can run anywhere, on-premises in the customer\ndatacenter, in an external service prov', 'ider or in the cloud, on Azure. Docker image containers can also\nrun natively on Linux and Windows. However, Windows images can run only on Windows hosts and\nLinux images can run on Linux hosts and Windows hosts (using a Hyper-V Linux VM, so far), where\nhost means a server or a VM.\n\nDevelopers can use development environments on Windows, Linux, or macOS. On the development\ncomputer, the developer runs a Docker host where Docker images are deploye', "d, including the app\nand its dependencies. Developers who work on Linux or on the Mac, use a Docker host that’s Linux-\nbased, and they can only create images for Linux containers. (Developers working on the Mac can edit\ncode or run the Docker command-line interface (CLI) from macOS, but as of this writing, containers\ndon't run directly on macOS.) Developers who work on Windows can create images for either Linux or\nWindows Containers.\n\nTo host con", 'tainers in development environments and provide additional developer tools, Docker\nships Docker Desktop for Windows or for macOS. These products install the necessary VM (the Docker\nhost) to host the containers.\n\nTo run Windows Containers, there are two types of runtimes:\n\n. Windows Server Containers provide application isolation through process and namespace\nisolation technology. A Windows Server Container shares a kernel with the container host', ' and\nwith all containers running on the host.\n\n. Hyper-V Containers expand on the isolation provided by Windows Server Containers by\nrunning each container in a highly optimized virtual machine. In this configuration, the kernel\nof the container host isn’t shared with the Hyper-V Containers, providing better isolation.\n\n2 CHAPTER 1 | Overview of Containers and Docker\nThe images for these containers are created and work just the same way. The diff', 'erence is in how the\ncontainer is created from the image—running a Hyper-V Container requires an extra parameter. For\n\ndetails, see Hyper-V Containers.\n\nComparing Docker containers with virtual machines\n\nFigure 1-3 shows a comparison between VMs and Docker containers.\n\nVMs\n\n;\n\nHost OS Infrastructure\n\nInfrastructure S &\nS C xe Containers include the application and all\n\nof its dependencies but share the OS\nkernel with other containers, running as\n', '\nContainers\n\nAppl App2 App3\nBins/Libs Bins/Libs Bins/Libs\n\nContainer Engine\n\nVMs include the application, the required isolated processes in user space on the\nlibraries and binaries, and a full guest OS. host OS (except in Hyper-V Containers,\nFull virtualization is much heavier than in which each container runs within a\ncontainerization. special VM per container).\n\nFigure 1-3. Comparison of traditional virtual machines to Docker containers\n\nAs sh', "own in the above diagram, for VMs, there are three base layers in the host server. From the\nbottom-up: Infrastructure, Host Operating System, and a Hypervisor. On top of all that, each VM has\nits own OS and all necessary libraries. On the other hand, for Docker, the host server only has the\nInfrastructure and the OS. On top of that, the container engine keeps containers isolated, but lets\nthem share the single base OS's services.\n\nBecause contain", "ers require far fewer resources (for example, they don’t need a full OS), they're easy to\ndeploy and they start fast. This allows you to have higher density, meaning that it allows you to run\nmore services on the same hardware unit, thereby reducing costs.\n\nAs a side effect of running on the same kernel, you get less isolation than VMs.\n\nThe main goal of an image is to ensure the same environment (dependencies) across different\ndeployments. This ", "means that you can debug it on your machine and then deploy it to another\nmachine, the same environment guaranteed.\n\nA container image is a way to package an app or service and deploy it in a reliable and reproducible\nway. You could say that Docker isn't only a technology but also a philosophy and a process.\n\n3 CHAPTER 1 | Overview of Containers and Docker\nWhen using Docker, you won't hear developers say, “It works on my machine, why not in produ", 'ction?”\nThey can just say, “It runs on Docker", because the packaged Docker application can be executed on\nany supported Docker environment, and it runs the way it was intended to on all deployment targets\n(such as Dev, QA, staging, and production).\n\nA simple analogy\nPerhaps a simple analogy can help getting the grasp of the core concept of Docker.\n\nLet\'s go back in time to the 1950s for a moment. There were no word processors, and the\nphotocopie', "rs were used everywhere (well, kind of).\n\nImagine you're responsible for quickly issuing batches of letters as required, to mail them to\ncustomers, using real paper and envelopes, to be delivered physically to each customer's address\n(there was no email back then).\n\nAt some point, you realize the letters are just a composition of a large set of paragraphs, which are\npicked and arranged as needed, according to the purpose of the letter, so you dev", 'ise a system to\nissue letters quickly, expecting to get a hefty raise.\n\nThe system Is simple:\n\n1. You begin with a deck of transparent sheets containing one paragraph each.\n\n2. To issue a set of letters, you pick the sheets with the paragraphs you need, then you stack and\nalign them so they look and read fine.\n\n3. Finally, you place the set in the photocopier and press start to produce as many letters as\nrequired.\n\nSo, simplifying, that’s the cor', 'e idea of Docker.\n\nIn Docker, each layer is the resulting set of changes that happen to the filesystem after executing a\ncommand, such as, installing a program.\n\nSo, when you “look” at the filesystem after the layer has been copied, you see all the files, included the\nlayer when the program was installed.\n\nYou can think of an image as an auxiliary read-only hard disk ready to be installed in a “computer”\nwhere the operating system is already inst', 'alled.\n\nSimilarly, you can think of a container as the “computer” with the image hard disk installed. The\ncontainer, just like a computer, can be powered on or off.\n\nLearn Docker specific terminologies\n\nThis section lists terms and definitions you should be familiar with before getting deeper into Docker.\nFor further definitions, see the extensive glossary provided by Docker.\n\nContainer image: A package with all the dependencies and information n', 'eeded to create a container.\nAn image includes all the dependencies (such as frameworks) plus deployment and execution\n\n4 CHAPTER 1 | Overview of Containers and Docker\nconfiguration to be used by a container runtime. Usually, an image derives from multiple base images\nthat are layers stacked on top of each other to form the container’s filesystem. An image is immutable\nonce it has been created.\n\nDockerfile: A text file that contains instructions ', 'for building a Docker image. It’s like a batch script,\nthe first line states the base image to begin with and then follow the instructions to install required\nprograms, copy files, and so on, until you get the working environment you need.\n\nBuild: The action of building a container image based on the information and context provided by its\nDockerfile, plus additional files in the folder where the image is built. You can build images with the\nfoll', 'owing Docker command:\n\ndocker build\n\nContainer: An instance of a Docker image. A container represents the execution of a single\napplication, process, or service. It consists of the contents of a Docker image, an execution\nenvironment, and a standard set of instructions. When scaling a service, you create multiple instances\nof a container from the same image. Or a batch job can create multiple containers from the same\nimage, passing different para', "meters to each instance.\n\nVolumes: Offer a writable filesystem that the container can use. Since images are read-only but most\nprograms need to write to the filesystem, volumes add a writable layer, on top of the container image,\nso the programs have access to a writable filesystem. The program doesn’t know it's accessing a\nlayered filesystem, it’s just the filesystem as usual. Volumes live in the host system and are managed\nby Docker.\n\nTag: A ma", 'rk or label you can apply to images so that different images or versions of the same image\n(depending on the version number or the target environment) can be identified.\n\nMulti-stage Build: Is a feature, since Docker 17.05 or higher, that helps to reduce the size of the final\nimages. For example, a large base image, containing the SDK can be used for compiling and\npublishing and then a small runtime-only base image can be used to host the applica', 'tion.\n\nRepository (repo): A collection of related Docker images, labeled with a tag that indicates the image\nversion. Some repos contain multiple variants of a specific image, such as an image containing SDKs\n\n(heavier), an image containing only runtimes (lighter), etc. Those variants can be marked with tags. A\nsingle repo can contain platform variants, such as a Linux image and a Windows image.\n\nRegistry: A service that provides access to reposi', "tories. The default registry for most public images is\nDocker Hub (owned by Docker as an organization). A registry usually contains repositories from\nmultiple teams. Companies often have private registries to store and manage images they've created.\nAzure Container Registry is another example.\n\nMulti-arch image: For multi-architecture, it’s a feature that simplifies the selection of the appropriate\nimage, according to the platform where Docker is", ' running. For example, when a Dockerfile requests a\nbase image FROM mcr.microsoft.com/dotnet/sdk:6.0 from the registry, it actually gets 6.0-\nnanoserver-20H2, 6.0-nanoserver-1809 or 6.0-bullseye-slim, depending on the operating system\nand version where Docker is running.\n\n5 CHAPTER 1 | Overview of Containers and Docker\nDocker Hub: A public registry to upload images and work with them. Docker Hub provides Docker\nimage hosting, public or private re', 'gistries, build triggers and web hooks, and integration with GitHub\nand Bitbucket.\n\nAzure Container Registry: A public resource for working with Docker images and its components in\nAzure. This provides a registry that’s close to your deployments in Azure and that gives you control\nover access, making it possible to use your Azure Active Directory groups and permissions.\n\nDocker Trusted Registry (DTR): A Docker registry service (from Docker) that ', "can be installed on-\npremises so it lives within the organization's datacenter and network. It’s convenient for private\nimages that should be managed within the enterprise. Docker Trusted Registry is included as part of\nthe Docker Datacenter product.\n\nDocker Desktop: Development tools for Windows and macOS for building, running, and testing\ncontainers locally. Docker Desktop for Windows provides development environments for both Linux\nand Windows", ' Containers. The Linux Docker host on Windows is based on a Hyper-V virtual machine.\nThe host for Windows Containers is directly based on Windows. Docker Desktop for Mac is based on\nthe Apple Hypervisor framework and the xhyve hypervisor, which provides a Linux Docker host virtual\nmachine on macOS. Docker Desktop for Windows and for Mac replaces Docker Toolbox, which was\nbased on Oracle VirtualBox.\n\nCompose: A command-line tool and YAML file form', "at with metadata for defining and running multi-\ncontainer applications. You define a single application based on multiple images with one or more\nyml files that can override values depending on the environment. After you've created the definitions,\nyou can deploy the whole multi-container application with a single command (docker-compose up)\nthat creates a container per image on the Docker host.\n\nCluster: A collection of Docker hosts exposed as ", 'if it were a single virtual Docker host, so that the\napplication can scale to multiple instances of the services spread across multiple hosts within the\ncluster. Docker clusters can be created with Kubernetes, Azure Service Fabric, Docker Swarm and\n\nMesosphere DC/OS.\n\nOrchestrator: A tool that simplifies the management of clusters and Docker hosts. Orchestrators\nenable you to manage their images, containers, and hosts through a command-line inter', 'face (CLI) or a\ngraphical Ul. You can manage container networking, configurations, load balancing, service discovery,\nhigh availability, Docker host configuration, and more. An orchestrator is responsible for running,\ndistributing, scaling, and healing workloads across a collection of nodes. Typically, orchestrator\nproducts are the same products that provide cluster infrastructure, like Kubernetes and Azure Service\nFabric, among other offerings i', 'n the market.\n\nLearn docker containers, images, and registries\n\nWhen using Docker, you create an app or service and package it and its dependencies into a\ncontainer image. An image is a static representation of the app or service and its configuration and\ndependencies.\n\nTo run the app or service, the app’s image is instantiated to create a container, which will be running\non the Docker host. Containers are initially tested in a development enviro', 'nment or PC.\n\n6 CHAPTER 1 | Overview of Containers and Docker\nYou store images in a registry that acts as a library of images. You need a registry when deploying to\nproduction orchestrators. Docker maintains a public registry via Docker Hub; other vendors provide\nregistries for different collections of images, including Azure Container Registry. Alternatively,\nenterprises can have a private registry on-premises for their own Docker images.\n\nFigur', 'e 1-4 shows how images and registries in Docker relate to other components. It also shows the\nmultiple registry offerings from vendors.\n\nRegistry\nStores many static images\n\nHosted Docker\nRegistr\naa On-Premises\nDocker Trusted (“n" private organizations)\nRegistry\nOn-Premises\n\nHosted Hub\nRegistry\n\nDocker Trusted\nRegistry\nOn-Cloud\n\nAzure Container\nRegistry Public Cloud\n\nAWS Container (specific vendors)\nRegistry\n\nImages A\nStatic, persisted container i', 'mage PP |\n\n2\n\nNode Microsoft .NET\n\n|\n\nGoogle Container\nRegistry\n\nQuay Registry\n\nOther Cloud\n\nContainer\nImage instance running an\napp process (service/web)\n\nFigure 1-4. Taxonomy of Docker terms and concepts\n\nThe registry is like a bookshelf where images are stored and available to be pulled for building\ncontainers to run services or web apps. There are private Docker registries on-premises and on the\npublic cloud. Docker Hub is a public registry m', 'aintained by Docker, along the Docker Trusted Registry\nan enterprise-grade solution, Azure offers the Azure Container Registry. AWS, Google and others also\nhave container registries.\n\nBy putting images in a registry, you can store static and immutable application bits, including all\nof their dependencies, at a framework level. You then can version and deploy images in multiple\nenvironments and thus provide a consistent deployment unit.\n\n7 CHAPTER', ' 1 | Overview of Containers and Docker\nPrivate image registries, either hosted on-premises or in the cloud, are recommended when:\n\n. Your images must not be shared publicly due to confidentiality.\n\n. You want to have minimum network latency between your images and your chosen\ndeployment environment. For example, if your production environment is Azure, you probably\nwant to store your images in Azure Container Registry so that network latency is m', "inimal. In a\nsimilar way, if your production environment is on-premises, you might want to have an on-\npremises Docker Trusted Registry available within the same local network.\n\nRoad to modern applications based on containers\n\nYou're probably reading this book because you're planning the development of new applications or\nyou're assessing the impact of using Docker, Containers, and new approaches like Microservices in\nyour company.\n\nThe adoption ", 'of new development paradigms must be taken with caution before starting a project, to\nassess the impact on your dev teams, your budget, or your infrastructure.\n\nMicrosoft has been working on rich guidance, sample applications, and a suite of e-books that can\nhelp you make an informed decision and guide your team through a successful development,\ndeployment, and operations of your new applications.\n\nThis book belongs to a Microsoft suite of guides', " that cover many of the needs and challenges you'll\nface during the process of developing new modern applications based on containers.\n\nYou can find additional Microsoft e-books related to Docker containers in the list below:\n\n. -NET Microservices: Architecture for Containerized .NET Applications\n\nhttps://learn.microsoft.com/dotnet/architecture/microservices/\n\n. Modernize existing .NET applications with Azure cloud and Windows Containers\n\nhttps:/", '/learn.microsoft.com/dotnet/architecture/modernize-with-azure-containers/\n\n8 CHAPTER 1 | Overview of Containers and Docker\nCHAPTER\n\nIntroduction to the Docker\napplication lite cycle\n\nThe life cycle of containerized applications ts a journey that begins with the developer. The developer\nchooses to implement containers and Docker because it eliminates frictions in deployments and IT\noperations, which ultimately helps everyone to be more agile, more', ' productive end-to-end, and faster.\n\nContainers as the foundation tor DevOps\ncollaboration\n\nBy the very nature of the containers and Docker technology, developers can share their software and\ndependencies easily with IT operations and production environments while eliminating the typical “it\nworks on my machine” excuse. Containers solve application conflicts between different environments.\nIndirectly, containers and Docker bring developers and IT', " operations closer together, making it easier\nfor them to collaborate effectively. Adopting the container workflow provides many customers\n\nwith the DevOps continuity they've sought but previously had to implement via more complex\nconfiguration for release and build pipelines. Containers simplify the build/test/deploy pipelines\n\nin DevOps.\n\nDevelopers and\nArchitects ——————> Collaboration <———_ IT Op erations\n\nPlatform for DevOps for Management\n\nD", "ocker Apps Docker Apps and Monitoring\n\nDevelop/Design Run/Monitor/Manage\n\nFigure 2-1. Main workloads per “personas” in the life cycle for containerized Docker applications\n\nWith Docker containers, developers own what's within the container (application and service, and\ndependencies to frameworks and components) and how the containers and services behave together\nas an application composed by a collection of services. The interdependencies of the ", 'multiple\ncontainers are defined in a docker-compose.yml file, or what could be called a deployment manifest.\nMeanwhile, IT operations teams (IT professionals and management) can focus on the management\n\n9 CHAPTER 2 | Introduction to the Docker application life cycle\nof production environments; infrastructure; scalability; monitoring; and, ultimately, ensuring that the\napplications are delivering properly for the end users, without having to know ', 'the contents of the\nvarious containers. Hence, the name “container,” recalling the analogy to real-world shipping\ncontainers. Thus, the owners of a container’s content need not concern themselves with how the\ncontainer will be shipped, and the shipping company transports a container from its point of origin\nto its destination without knowing or caring about the contents. In a similar manner, developers can\ncreate and own the contents within a Doc', 'ker container without the need to concern themselves with\nthe “transport” mechanisms.\n\nIn the pillar on the left side of Figure 2-1, developers write and run code locally in Docker containers\nby using Docker for Windows or Mac. They define the operating environment for the code by using a\nDockerfile that specifies the base operating system to run as well as the build steps for building their\ncode into a Docker image. The developers define how one', ' or more images will interoperate using the\naforementioned docker-compose.yml file deployment manifest. As they complete their local\ndevelopment, they push their application code plus the Docker configuration files to the code\nrepository of their choice (that is, Git repository).\n\nThe DevOps pillar defines the build—Continuous Integration (Cl) pipelines using the Dockerfile\nprovided in the code repository. The Cl system pulls the base container i', 'mages from the selected\nDocker registry and builds the custom Docker images for the application. The images then are\nvalidated and pushed to the Docker registry used for the deployments to multiple environments.\n\nIn the pillar on the right, operations teams manage deployed applications and infrastructure in\nproduction while monitoring the environment and applications so that they can provide feedback and\ninsights to the development team about how', ' the application might be improved. Container apps are\ntypically run in production using container orchestrators like Kubernetes, where usually Helm charts\nare used to configure deployment units, instead of docker-compose files.\n\nThe two teams are collaborating through a foundational platform (Docker containers) that provides\na separation of concerns as a contract, while greatly improving the two teams’ collaboration in the\napplication life cycle', '. The developers own the container contents, its operating environment, and the\ncontainer interdependencies, whereas the operations teams take the built images along with the\nmanifest and runs them in their orchestration system.\n\nChallenges in the application life cycle when using Docker.\n\nThere are many reasons that will increase the number of containerized applications in the upcoming\nyears, and one of these reasons Is the creation of applicati', "ons based on microservices.\n\nDuring the last 15 years, the use of web services has been the base of thousands of applications, and\nprobably, after a few years, you'll find the same situation with microservice-based applications\nrunning on Docker containers.\n\nIt is also worth to mention that you can also use Docker containers for monolithic applications and\nyou still get most of the benefits of Docker. Containers are not targeting only microservic", 'es.\n\nThe use of Docker containerization and microservices causes new challenges in the development\nprocess of your organizations and therefore, you need a solid strategy to maintain many containers\n\n10 CHAPTER 2 | Introduction to the Docker application life cycle\nand microservices running on production systems. Eventually, enterprise applications will have\nhundreds or thousands of containers/instances running in production.\n\nThese challenges crea', "te new demands when using DevOps tools, so you'll have to define new\nprocesses in your DevOps activities, and find answers for the following type of questions:\n\n. Which tools can | use for development, Cl/CD, management and operations??\n\n° How can my company manage errors in containers when running in production?\n. How can we change pieces of our software in production with minimum downtime?\n. How can we scale and monitor our production system?\n\n", ". How can we include the testing and deployment of containers in our release pipeline?\n. How can we use Open Source tools/platforms for containers in Microsoft Azure?\nIf you can answer all those questions, you'll be better prepared to move your applications (existing or\n\nnew apps) to Docker containers.\n\nIntroduction to a generic end-to-end Docker application life cycle\nworkflow\n\nFigure 2-2 presents a more detailed workflow for a Docker applicatio", 'n life cycle, focusing in this\ninstance on specific DevOps activities and assets.\n\n01 y\n\n10\n\nB\n\nProduction\nEnvironments\n\ndocker push wy)\n\nCode Push\n2 Docker Registry\n\n[\n\nInner Loop outer |\nuter Loop\n\nFigure 2-2. High-level workflow for the Docker containerized application life cycle\n\nEverything begins with the developer, who starts writing code in the inner-loop workflow. The inner-\nloop stage is where developers define everything that happens be', "fore pushing code into the code\nrepository (for example, a source control system such as Git). After it’s committed, the repository\ntriggers Continuous Integration (Cl) and the rest of the workflow.\n\n11 CHAPTER 2 | Introduction to the Docker application life cycle\nmeu\n\nThe inner loop consists of typical steps like “code,” “run,” “test,” and “debug,” plus the additional steps\nneeded right before running the app locally. This is the developer's pro", 'cess to run and test the app as\na Docker container. The inner-loop workflow will be explained in the sections that follow.\n\nTaking a step back to look at the end-to-end workflow, the DevOps workflow is more than a\ntechnology or a tool set, it’s a mindset that requires cultural evolution. It’s people, processes, and the\nappropriate tools to make your application life cycle faster and more predictable. Enterprises that\nadopt a containerized workflo', 'w typically restructure their organizations to represent people and\nprocesses that match the containerized workflow.\n\nPracticing DevOps can help teams respond faster together to competitive pressures by replacing\nerror-prone manual processes with automation, which results in improved traceability and repeatable\nworkflows. Organizations also can manage environments more efficiently and realize cost savings with\na combination of on-premises and clo', "ud resources as well as tightly integrated tooling.\n\nWhen implementing your DevOps workflow for Docker applications, you'll see that Docker\ntechnologies are present in almost every stage of the workflow, from your development box while\nworking in the inner loop (code, run, debug), the build-test-Cl phase, and, finally, the deployment of\nthose containers to the staging and production environments.\n\nImprovement of quality practices helps to identif", 'y defects early in the development cycle, which\nreduces the cost of fixing them. By including the environment and dependencies in the image and\nadopting a philosophy of deploying the same image across multiple environments, you promote a\ndiscipline of extracting the environment-specific configurations making deployments more reliable.\n\nRich data obtained through effective instrumentation (monitoring and diagnostics) provides insight\ninto performa', 'nce Issues and user behavior to guide future priorities and investments.\n\nDevOps should be considered a journey, not a destination. It should be implemented incrementally\nthrough appropriately scoped projects from which you can demonstrate success, learn, and evolve.\n\nBenefits of DevOps for containerized applications\n\nHere are some of the most important benefits provided by a solid DevOps workflow:\n\n. Deliver better-quality software, faster and w', 'ith better compliance.\n. Drive continuous improvement and adjustments earlier and more economically.\n. Increase transparency and collaboration among stakeholders involved in delivering and\n\noperating software.\n\n. Control costs and utilize provisioned resources more effectively while minimizing security\nrisks.\n° Plug and play well with many of your existing DevOps investments, including investments in\n\nOpen-Source.\n\n12 CHAPTER 2 | Introduction to ', 'the Docker application life cycle\nCHAPTER 3\n\nIntroduction to the\nMicrosoft plattorm\nand tools for containerized\n\napps\n\nVision: Create an adaptable, enterprise-grade, containerized application life cycle that spans your\ndevelopment, IT operations, and production management.\n\nFigure 3-1 shows the main pillars in the life cycle of Docker apps classified by the type of work\ndelivered by multiple teams (app-development, DevOps infrastructure processes', ', and IT management\nand operations). Usually, in the enterprise, the profiles of “the persona” responsible for each area are\ndifferent. So are their skills.\n\n13 CHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\nDevelopers and\n\nArchitects ———. Collaboration <——————_1T Operations\n\nPlatform for DevOps for\nDocker Apps Docker Apps\n\nManagement\nand Monitoring\n\nDocker Engine\nVS and VS Code Azure DevOps\n.NET Core / Docker', " CLI\nOther Azure\nAzure Kubernetes\nKubernetes Service\nService\n\nAzure Monitor\nApplication\nInsights\nAzure Portal\n\nDevelop/Design Run/Monitor/Manage\n\nFigure 3-1. Main pillars in the life cycle for containerized Docker applications with Microsoft platform and tools\n\nA containerized Docker life-cycle workflow can be initially prescriptive based on “by-default product\nchoices,” making it easier for developers to get started faster, but it's fundamental ", 'that under the\nhood there must be an open framework so that it will be a flexible workflow capable of adjusting to\nthe different contexts from each organization or enterprise. The workflow infrastructure (components\nand products) must be flexible enough to cover the environment that each company will have in the\nfuture, even being capable of swapping development or DevOps products to others. This flexibility,\nopenness, and the broad choice of tec', 'hnologies in the platform and infrastructure are precisely the\nMicrosoft priorities for containerized Docker applications, as explained in the chapters that follow.\n\nTable 3-1 demonstrates that the intention of the Azure DevOps for containerized Docker applications\nis to provide an open DevOps workflow so that you can choose what products to use for each phase\n(Microsoft or third-party) while providing a simplified workflow that provides “by-defa', 'ult-products”\nalready connected; thus, you can quickly get started with your enterprise-level DevOps workflow for\nDocker apps.\n\nTable 3-1. DevOps workflows, open to any technology\n\n| Host Microsoft technologies Third-party (Azure pluggable)\n\nPlatform for ¢ Microsoft Visual Studio and ¢ Any code editor (for example, Sublime)\nDocker apps Visual Studio Code « Any language (Nodes, Java, Go, etc.)\n\n¢ NET ¢ Any orchestrator and scheduler\n« Microsoft Az', 'ure Kubernetes | * Any Docker registry\\\n\nService (AKS)\n\n¢ Azure Container Registry\\\n\n14 CHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\n| Host Microsoft technologies Third-party (Azure pluggable)\n\nDevOps for ¢ Azure DevOps Services ¢ GitHub, Git, Subversion, etc.\n\nDocker apps ¢ Microsoft Team Foundation ¢ Jenkins, Chef, Puppet, Velocity, CircleCl,\nServer TravisCl, etc.\n¢ GitHub ¢ On-premises Docker Datacenter, ', 'Kubernetes,\n¢ Azure Kubernetes Service Mesos DC/OS, etc.\\\n(AKS)\\\n\nManagement | * Azure Monitor ¢ Marathon, Chronos, etc.\\\nand\nmonitoring\n\nThe Microsoft platform and tools for containerized Docker apps, as defined in Table 3-1, comprise the\nfollowing components:\n\n. Platform for Docker Apps development The development of a service, or collection of\nservices that make up an “app.” The development platform provides all the work developers\nrequires pr', 'ior to pushing their code to a shared code repository. Developing services,\ndeployed as containers, are similar to the development of the same apps or services without\nDocker. You continue to use your preferred language (.NET, Node,js, Go, etc.) and preferred\neditor or IDE like Visual Studio or Visual Studio Code. However, rather than consider Docker a\ndeployment destination, you develop your services in the Docker environment. You build, run,\nte', 'st, and debug your code in containers locally, providing the destination environment at\ndevelopment time. By providing the destination environment locally, Docker containers set up\nwhat will drastically help you improve your DevOps life cycle. Visual Studio and Visual Studio\nCode have extensions to integrate Docker containers within your development process.\n\n. DevOps for Docker Apps Developers creating Docker applications can use Azure DevOps,\nG', 'itHub or any other third-party product, like Jenkins, to build out a comprehensive\nautomated application life-cycle management (ALM).\n\nWith Azure DevOps and/or GitHub, developers can create container-focused DevOps for a\nfast, iterative process that covers source-code control from anywhere (Azure DevOps-Git,\nGitHub, any remote Git repository, or Subversion), Continuous Integration (Cl), internal unit\ntests, inter-container/service integration tes', 'ts, Continuous Delivery (CD), and release\nmanagement (RM). Developers also can automate their Docker application releases into Azure\nKubernetes Service (AKS), from development to staging and production environments.\n\n. Management and Monitoring IT can manage and monitor production applications and\nservices in several ways, integrating both perspectives in a consolidated experience.\n\n— Azure portal Azure Kubernetes Service (AKS) helps you to set u', "p and maintain your\nDocker environments. You can also use other orchestrators to visualize and configure\nyour cluster.\n\n- Docker tools You can manage your container applications using familiar tools.\nThere's no need to change your existing Docker management practices to move\ncontainer workloads to the cloud. Use the application management tools you're\n\n15 CHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\nalready ", "familiar with and connect via the standard API endpoints for the orchestrator\nof your choice. You also can use other third-party tools to manage your Docker\napplications or even CLI Docker tools.\n\nEven if you're familiar with Linux commands, you can manage your container\napplications using Microsoft Windows and PowerShell with a Linux Subsystem\ncommand line and the products (Docker, Kubernetes...) clients running on this Linux\nSubsystem capabilit", "y. You'll learn more about using these tools under Linux\nSubsystem using your favorite Microsoft Windows OS later in this book.\n\n— Open-source tools Because AKS exposes the standard API endpoints for the\norchestration engine, the most popular tools are compatible with AKS and, in most\ncases, will work out of the box—including visualizers, monitoring, command-line\ntools, and even future tools as they become available.\n\n— GitHub Advanced Security G", "itHub Advanced Security offers a suite of tools for\nsecuring the software supply chain that can seamlessly integrate security into the\ndaily workflow of teams developing containerized applications.\n\n—- Azure Monitor Is Azure's solution to monitor every angle of your production\nenvironment. You can monitor production Docker applications by just setting up its\nSDK into your services so that you can get system-generated log data from the\napplication", "s.\n\nThus, Microsoft offers a complete foundation for an end-to-end containerized Docker application life\ncycle. However, it's a collection of products and technologies that allow you to optionally select and\nintegrate with existing tools and processes. The flexibility in a broad approach along with the strength\nin the depth of capabilities place Microsoft in a strong position for containerized Docker application\ndevelopment.\n\n16 CHAPTER 3 | Intro", 'duction to the Microsoft platform and tools for containerized apps\nCHAPTER\n\nDesigning and developing\ncontainerized apps using\nDocker and Microsort\nAzure\n\nVision: Design and develop scalable solutions with Docker in mind.\n\nThere are many great-fit use cases for containers, not just for microservices-oriented architectures, but\nalso when you simply have regular services or web applications to run and you want to reduce frictions\nbetween development', ' and production environment deployments.\n\nDesign Docker applications\n\nChapter 1 introduced the fundamental concepts regarding containers and Docker. That information is\nthe basic level of information you need to get started. But, enterprise applications can be complex and\ncomposed of multiple services instead of a single service or container. For those optional use cases,\nyou need to know additional approaches to design, such as Service-Oriented ', 'Architecture (SOA) and\nthe more advanced microservices concepts and container orchestration concepts. The scope of this\ndocument is not limited to microservices but to any Docker application life cycle, therefore, it does\nnot explore microservices architecture in depth because you can also use containers and Docker with\nregular SOA, background tasks or jobs, or even with monolithic application deployment approaches.\n\nMore info To learn more about', " enterprise applications and microservices architecture in depth, read\n\nthe guide NET Microservices: Architecture for Containerized .NET Applications that you can also\ndownload from https://aka.ms/MicroservicesEbook,.\n\nHowever, before you get into the application life cycle and DevOps, it’s important to know how you're\ngoing to design and construct your application and what are your design choices.\n\n17 CHAPTER 4 | Designing and developing contain", 'erized apps using Docker and Microsoft Azure\nCommon container design principles\n\nAhead of getting into the development process there are a few basic concepts worth mentioning with\nregard to how you use containers.\n\nContainer equals a process\n\nIn the container model, a container represents a single process. By defining a container as a process\nboundary, you begin to create the primitives used to scale, or batch-off, processes. When you run a\nDocke', "r container, you'll see an ENTRYPOINT definition. This defines the process and the lifetime of\nthe container. When the process completes, the container life-cycle ends. There are long-running\nprocesses, such as web servers, and short-lived processes, such as batch jobs, which might have\n\nbeen implemented as Microsoft Azure WebJobs. If the process fails, the container ends, and the\norchestrator takes over. If the orchestrator was instructed to kee", 'p five instances running and one fails,\nthe orchestrator will create another container to replace the failed process. In a batch job, the process\nis started with parameters. When the process completes, the work is complete.\n\nYou might find a scenario in which you want multiple processes running in a single container. In any\narchitecture document, there’s never a “never,” nor is there always an “always.” For scenarios requiring\nmultiple processes,', " a common pattern is to use Supervisor.\n\nMonolithic applications\n\nIn this scenario, you're building a single and monolithic web application or service and deploying it as\na container. Within the application, the structure might not be monolithic; it might comprise several\nlibraries, components, or even layers (application layer, domain layer, data access layer, etc.).\nExternally, it's a single container, like a single process, single web applicat", 'ion, or single service.\n\nTo manage this model, you deploy a single container to represent the application. To scale it, just add\na few more copies with a load balancer in front. The simplicity comes from managing a single\ndeployment in a single container or virtual machine (VM).\n\nFollowing the principal that a container does one thing only, and does it in one process, the\nmonolithic pattern is in conflict. You can include multiple components/libr', 'aries or internal layers\nwithin each container, as illustrated in Figure 4-1.\n\n18 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nApp 1 = 1 Container 4 onolithic app has most\n\nof its functionality within a\nsingle process/container\nthat is componentized with\ninternal layers or libraries.\n\nHost 1\n(Server/VM)\nScales out by cloning\nHost 2 the app/container on\n(Server/VM) multiple servers/VMs\nHost 3\n(Server/VM)', '\n\nNeed to deploy Course-grained\nthe full app density of apps\n\nFigure 4-1. An example of monolithic application architecture\n\nA monolithic app has all or most of its functionality within a single process or container and it’s\ncomponentized in internal layers or libraries. The downside to this approach comes if or when the\napplication grows, requiring it to scale. If the entire application scaled, it’s not really a problem.\nHowever, in most cases, ', 'a few parts of the application are the choke points that require scaling,\nwhereas other components are used less.\n\nUsing the typical e-commerce example, what you likely need is to scale the product information\ncomponent. Many more customers browse products than purchase them. More customers use their\nbasket than use the payment pipeline. Fewer customers add comments or view their purchase history.\nAnd you likely have only a handful of employees, ', 'in a single region, that need to manage the content\nand marketing campaigns. By scaling the monolithic design, all of the code is deployed multiple times.\n\nIn addition to the “scale-everything” problem, changes to a single component require complete\nretesting of the entire application as well as a complete redeployment of all the instances.\n\nThe monolithic approach is common, and many organizations are developing with this architectural\nmethod. M', "any enjoy good enough results, whereas others encounter limits. Many designed their\napplications in this model because the tools and infrastructure were too difficult to build SOAs, and\nthey didn't see the need—until the app grew.\n\nFrom an infrastructure perspective, each server can run many applications within the same host and\nhave an acceptable ratio of efficiency in your resources usage, as shown in Figure 4-2.\n\n19 CHAPTER 4 | Designing and d", 'eveloping containerized apps using Docker and Microsoft Azure\nHost\n\nFigure 4-2. A host running multiple apps/containers\n\nFinally, from an availability perspective, monolithic applications must be deployed as a whole; that\nmeans that in case you must stop and start, all functionality and all users will be affected during the\ndeployment window. In certain situations, the use of Azure and containers can minimize these\nsituations and reduce the proba', 'bility of downtime of your application, as you can see in Figure 4-3.\n\nYou can deploy monolithic applications in Azure by using dedicated VMs for each instance. Using\nAzure VM Scale Sets, you can scale the VMs easily.\n\nYou can also use Azure App Services to run monolithic applications and easily scale instances without\nhaving to manage the VMs. Azure App Services can run single instances of Docker containers, as well,\nsimplifying the deployment.\n', '\nYou can deploy multiple VMs as Docker hosts and run any number of containers per VM. Then, by\nusing an Azure Load Balancer, as illustrated in the Figure 4-3, you can manage scaling.\n\nj ~~\n~~\n\nBrowser or\nClient App\n\nFigure 4-3. Multiple hosts scaling out a single Docker application\n\nYou can manage the deployment of the hosts themselves via traditional deployment techniques.\n\nYou can manage Docker containers from the command line by using commands', ' like docker run and\ndocker-compose up, and you can also automate it in Continuous Delivery (CD) pipelines and deploy\nto Docker hosts from Azure DevOps Services, for instance.\n\n20 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nMonolithic application deployed as a container\n\nThere are benefits to using containers to manage monolithic deployments. Scaling the instances of\ncontainers is far faster and easier', ' than deploying additional VMs.\n\nDeploying updates as Docker images is far faster and network efficient. Docker containers typically\nstart in seconds, speeding rollouts. Tearing down a Docker container is as easy as invoking the docker\nstop command, typically completing in less than a second.\n\nBecause containers are inherently immutable, by design, you never need to worry about corrupted\nVMs because an update script forgot to account for some spe', "cific configuration or file left on disk.\n\nAlthough monolithic apps can benefit from Docker, we're touching on only the tips of the benefits.\nThe larger benefits of managing containers come from deploying with container orchestrators that\nmanage the various instances and life cycle of each container instance. Breaking up the monolithic\napplication into subsystems that can be scaled, developed, and deployed individually is your entry\npoint into th", 'e realm of microservices.\n\nTo learn about how to “lift and shift” monolithic applications with containers and how you can\nmodernize your applications, you can read this additional Microsoft guide, Modernize existing .NET\n\napplications with Azure cloud and Windows Containers, which you can also download as PDF from\nhttps://aka.ms/LiftAndShiftWithContainersEbook.\n\nPublish a single Docker container app to Azure App Service\n\nEither because you want t', 'o get a quick validation of a container deployed to Azure or because the\napp is simply a single-container app, Azure App Services provides a great way to provide scalable\nsingle-container services.\n\nUsing Azure App Service is intuitive and you can get up and running quickly because it provides great\nGit integration to take your code, build it in Microsoft Visual Studio, and directly deploy it to Azure.\nBut, traditionally (with no Docker), if you ', "needed other capabilities, frameworks, or dependencies that\naren't supported in App Services, you needed to wait for it until the Azure team updates those\ndependencies in App Service or switched to other services like Service Fabric, Cloud Services, or even\nplain VMs, for which you have further control and can install a required component or framework for\nyour application.\n\nNow, as shown in Figure 4-4, when using Visual Studio 2022, container sup", "port in Azure App Service\ngives you the ability to include whatever you want in your app environment. If you added a\ndependency to your app, because you're running it in a container, you get the capability of including\nthose dependencies in your Dockerfile or Docker image.\n\n21 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nPublish\n\nSelect existing or create a new Azure Container Registry\n\nSubscription nam", 'e\nTarget\n\nSpecific target\nView\n\nApp Service Resource group\n\nContainer Registry Search\n\nFrontEndWebSiteASPNETCore\n\nContainer registries\n\n|_| NetworkWatcherRG\n\n© FrontEndWebsiteASPNETCore\n\nFinish Cancel\n\nFigure 4-4. Publishing a container to Azure App Service from Visual Studio apps/containers\n\nFigure 4-4 also shows that the publish flow pushes an image through a Container Registry, which can\nbe the Azure Container Registry (a registry near to your', ' deployments in Azure and secured by Azure\nActive Directory groups and accounts) or any other Docker Registry like Docker Hub or on-premises\nregistries.\n\nIn most cases, you can think of a container as an instance of a process. A process does not maintain\npersistent state. While a container can write to its local storage, assuming that an instance will be\naround indefinitely is like assuming that a single location in memory will be durable. Contai', "ner\nimages, like processes, should be assumed to have multiple instances and that they will eventually be\nkilled; if they're managed with a container orchestrator, it should be assumed that they might get\nmoved from one node or VM to another.\n\nThe following solutions are used to manage persistent data in Docker applications:\nFrom the Docker host, as\n\n. Volumes are stored in an area of the host filesystem that's managed by Docker.\n\n. Bind mounts c", 'an map to any folder in the host filesystem, so access can’t be controlled from\na Docker process and can pose a security risk as a container could access sensitive OS folders.\n. tmpfs mounts are like virtual folders that only exist in the host’s memory and are never\nwritten to the filesystem.\n\nFrom remote storage:\n\n. Azure Storage provides geo-distributable storage, providing a good long-term persistence\nsolution for containers.\n\n° Remote relatio', 'nal databases like Azure SOL Database, NoSQL databases like Azure Cosmos\nDB, or cache services like Redis.\n\nFrom the Docker container:\n\n. Docker provides a feature named the overlay file system. This feature implements a copy-on-\nwrite task that stores updated information to the root file system of the container. That\ninformation “lays on top of" the original image on which the container is based. If the\ncontainer is deleted from the system, thos', "e changes are lost. Therefore, while it's possible to\nsave the state of a container within its local storage, designing a system based on this feature\nwould conflict with the premise of container design, which by default is stateless.\n\n. However, Docker Volumes is now the preferred way to handle local data in Docker. If you\nneed more information about storage in containers, check on Docker storage drivers and\n\nAbout images, containers, and storag", 'e drivers.\n\nThe following provides additional detail about these options.\n\nVolumes are directories mapped from the host OS to directories in containers. When code in the\ncontainer has access to the directory, that access is actually to a directory on the host OS. This\ndirectory is not tied to the lifetime of the container itself, and the directory is managed by Docker and\nisolated from the core functionality of the host machine. Thus, data volume', 's are designed to persist\ndata independently of the life of the container. If you delete a container or an image from the Docker\nhost, the data persisted in the data volume is not deleted.\n\nVolumes can be named or anonymous (the default). Named volumes are the evolution of Data\nVolume Containers and make it easy to share data between containers. Volumes also support\nvolume drivers that allow you to store data on remote hosts, among other options.', "\n\nBind mounts have been available for a long time and allow the mapping of any folder to a mount\npoint in a container. Bind mounts have more limitations than volumes and some important security\nissues, SO volumes are the recommended option.\n\ntmpfs mounts are virtual folders that live only in the host's memory and are never written to the\nfilesystem. They are fast and secure but use memory and are only meant for non-persistent data.\n\nAs shown in F", "igure 4-5, regular Docker volumes can be stored outside of the containers themselves\nbut within the physical boundaries of the host server or VM. However, Docker containers cannot\naccess a volume from one host server or VM to another. In other words, with these volumes, it isn't\npossible to manage data shared between containers that run on different Docker hosts, although it\ncould be achieved with a volume driver that supports remote hosts.\n\n23 C", 'HAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nAzure\n\n>\n\nif SQL Database\n\nAzure\nLoad Balancer\n\nBrowser or\n\nClient App | DocumentDB\n\nData Volume\nContainer\n\nFigure 4-5. Volumes and external data sources for container-based applications\n\nIn addition, when Docker containers are managed by an orchestrator, containers might “move”\nbetween hosts, depending on the optimizations performed by the cluster. Therefore,', " it isn't\nrecommended that you use data volumes for business data. But they are a good mechanism to work\nwith trace files, temporal files, or similar, that will not impact business data consistency.\n\nRemote data sources and cache tools like Azure SQL Database, Azure Cosmos DB, or a remote cache\nlike Redis can be used in containerized applications the same way they are used when developing\nwithout containers. This is a proven way to store business", ' application data.\n\nAzure Storage. Business data usually needs to be placed in external resources or databases, like\nAzure Storage. Azure Storage provides the following services in the cloud:\n\n. Blob storage stores unstructured object data. A blob can be any type of text or binary data,\nsuch as document or media files (images, audio, and video files). Blob storage is also referred\nto as Object storage.\n\n. File storage offers shared storage for le', 'gacy applications using the standard SMB protocol.\nAzure virtual machines and cloud services can share file data across application components\nvia mounted shares. On-premises applications can access file data in a share via the File\nService REST API.\n\n. Table storage stores structured datasets. Table storage is a NoSQL key-attribute data store,\nwhich allows rapid development and fast access to large quantities of data.\n\nRelational databases and N', 'oSQL databases. There are many choices for external databases, from\nrelational databases like SQL Server, PostgreSQL, Oracle, or NoSQL databases like Azure Cosmos DB,\nMongoDB, etc. These databases are not going to be explained as part of this guide since they are a\ndifferent topic altogether.\n\n24 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nService-oriented applications\n\nService-Oriented Architecture (S', 'OA) was an overused term that meant many different things to\ndifferent people. But as a common denominator, SOA means that you structure the architecture of\nyour application by decomposing it into several services (most commonly as HTTP services) that can\nbe classified in different types like subsystems or, in other cases, as tiers.\n\nToday, you can deploy those services as Docker containers, which solve deployment-related issues\nbecause all of th', "e dependencies are included in the container image. However, when you need to\nscale out SOAs, you might encounter challenges if you're deploying based on single instances. This\nchallenge can be handled using Docker clustering software or an orchestrator. You'll get to look at\norchestrators in greater detail in the next section, when you explore microservices approaches.\n\nDocker containers are useful (but not required) for both traditional service", '-oriented architectures and\nthe more advanced microservices architectures.\n\nAt the end of the day, the container clustering solutions are useful for both a traditional SOA\narchitecture and for a more advanced microservices architecture in which each microservice owns its\ndata model. And thanks to multiple databases, you can also scale out the data tier instead of working\nwith monolithic databases shared by the SOA services. However, the discussio', 'n about splitting the\ndata is purely about architecture and design.\n\nOrchestrating microservices and multi-container\napplications for high scalability and availability\n\nUsing orchestrators for production-ready applications is essential if your application is based on\nmicroservices or split across multiple containers. As introduced previously, in a microservice-based\napproach, each microservice owns its model and data so that it will be autonomous', " from a\ndevelopment and deployment point of view. But even if you have a more traditional application that's\ncomposed of multiple services (like SOA), you'll also have multiple containers or services comprising a\nsingle business application that need to be deployed as a distributed system. These kinds of systems\nare complex to scale out and manage; therefore, you absolutely need an orchestrator if you want to\nhave a production-ready and scalable ", 'multi-container application.\n\nFigure 4-6 illustrates deployment into a cluster of an application composed of multiple microservices\n(containers).\n\n25 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n* For each service instance, you use one container App 1 App 2 © Docker ©\n* Docker images/containers are units of deployment penance.\n* A container is an instance of a docker image\n* A host (VM/server) handles m', 'any containers\n\nane\n\nfficial Docker Images\nhttps://hub.docker.com\n\nCluster of\nContainers\n\nFigure 4-6. A cluster of containers\n\nIt looks like a logical approach. But how are you handling load balancing, routing, and orchestrating\nthese composed applications?\n\nThe Docker CLI meets the needs of managing one container on one host, but it falls short when it\ncomes to managing multiple containers deployed on multiple hosts for more complex distributed\n', 'applications. In most cases, you need a management platform that will automatically start containers,\nscale out containers with multiple instances per image, suspend them, or shut them down when\nneeded, and ideally also control how they access resources like the network and data storage.\n\nTo go beyond the management of individual containers or simple composed apps and move toward\nlarger enterprise applications with microservices, you must turn to', " orchestration and clustering\nplatforms.\n\nFrom an architecture and development point of view, if you're building large, enterprise,\nmicroservices-based, applications, it’s important to understand the following platforms and products\nthat support advanced scenarios:\n\n. Clusters and orchestrators. When you need to scale out applications across many Docker\nhosts, such as with a large microservices-based application, it's critical to be able to manag", "e\nall of those hosts as a single cluster by abstracting the complexity of the underlying platform.\nThat's what the container clusters and orchestrators provide. Examples of orchestrators are\nAzure Service Fabric and Kubernetes. Kubernetes is available in Azure through Azure\nKubernetes Service.\n\n26 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n. Schedulers. Scheduling means to have the capability for an a", 'dministrator to launch containers\nin a cluster, so schedulers also provide a user interface for doing so. A cluster scheduler has\nseveral responsibilities: to use the cluster’s resources efficiently, to set the constraints\nprovided by the user, to efficiently load-balance containers across nodes or hosts, and to be\nrobust against errors while providing high availability.\n\nThe concepts of a cluster and a scheduler are closely related, so the produ', 'cts provided by different\nvendors often provide both sets of capabilities. The section below shows the most important platform\nand software choices you have for clusters and schedulers. These orchestrators are widely offered in\npublic clouds like Azure.\n\nSoftware platforms for container clustering, orchestration, and\n\nscheduling\n\nKubernetes Kubernetes is an open-source product that\nprovides functionality that ranges from\ncluster infrastructure an', 'd container\nscheduling to orchestrating capabilities. It\nlets you automate deployment, scaling,\nand operations of application containers\nacross clusters of hosts.\n\nKubernetes provides a container-centric\ninfrastructure that groups application\n\ncontainers into logical units for easy\nmanagement and discovery.\n\nKubernetes is mature in Linux, less mature\nin Windows.\n\nService (AKS) Azure Kubernetes Service (AKS) is a\nPG managed Kubernetes container\n(b', "p Lp orchestration service in Azure that\nsimplifies Kubernetes cluster’s\nmanagement, deployment, and\noperations.\n\n27 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nAzure Service Fabric Service Fabric is a Microsoft microservices\nplatform for building applications. It's an\norchestrator of services and creates\nclusters of machines. Service Fabric can\ndeploy services as containers or as plain\nprocesses. It c", 'an even mix services in\nprocesses with services in containers\nwithin the same application and cluster.\n\nService Fabric clusters can be deployed in\nAzure, on-premises or in any cloud.\n\nHowever, deployment in Azure is\nsimplified with a managed approach.\n\nService Fabric provides additional and\noptional prescriptive Service Fabric\n\nprogramming models like stateful services\nand Reliable Actors.\n\nService Fabric is mature in Windows (years\nevolving in W', "indows), less mature in Linux.\n\nBoth Linux and Windows containers are\nsupported in Service Fabric since 2017.\n\nAzure Service Fabric Mesh | Azure Service Fabric Mesh offers the same reliability, mission-\ncritical performance and scale as Service Fabric, but also offers a fully managed and serverless\nplatform. You don’t need to manage a cluster, VMs, storage or networking configuration. You just\nfocus on your application's development. Service Fabr", 'ic Mesh supports both Windows and Linux\ncontainers, allowing you to develop with any programming language and framework of your choice.\n\nAzure Container Apps | Azure Container Apps is a\n\nmanaged serverless container service for building and deploying modern apps at scale. |\n\nUsing container-based orchestrators in Azure\n\nSeveral cloud vendors offer Docker containers support plus Docker clusters and orchestration support,\nincluding Azure, Amazon EC', '2 Container Service, and Google Container Engine. Azure provides Docker\n\n28 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\ncluster and orchestrator support through Azure Kubernetes Service (AKS), Azure Service Fabric, and\nAzure Service Fabric Mesh.\n\nUsing Azure Kubernetes Service\n\nA Kubernetes cluster pools several Docker hosts and exposes them as a single virtual Docker host, so\nyou can deploy multiple c', 'ontainers into the cluster and scale-out with any number of container\ninstances. The cluster will handle all the complex management plumbing, like scalability, health, and\nso forth.\n\nAKS provides a way to simplify the creation, configuration, and management of a cluster of virtual\nmachines in Azure that are preconfigured to run containerized applications. Using an optimized\nconfiguration of popular open-source scheduling and orchestration tools, ', 'AKS enables you to use\nyour existing skills or draw on a large and growing body of community expertise to deploy and\nmanage container-based applications on Microsoft Azure.\n\nAzure Kubernetes Service optimizes the configuration of popular Docker clustering open-source tools\nand technologies specifically for Azure. You get an open solution that offers portability for both your\ncontainers and your application configuration. You select the size, the ', 'number of hosts, and the\norchestrator tools, and AKS handles everything else.\n\n29 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n/ fou |\n\n‘1 fo\n\nwav\nWw\n\nMaster Node\n\n- DNS\n\n- Scheduler\n\n- Proxy ‘wal\n\n- Ete. =\n\nKubernetes\ncluster\n\nFigure 4-7. Kubernetes cluster’s simplified structure and topology\n\nFigure 4-7 shows the structure of a Kubernetes cluster where a master node (VM) controls most of the\ncoordinat', 'ion of the cluster, and you can deploy containers to the rest of the nodes that are managed\nas a single pool from an application point of view. This allows you to scale to thousands or even tens\nof thousands of containers.\n\nDevelopment environment for Kubernetes\n\nIn the development environment that Docker announced in July 2018, Kubernetes can also run ina\nsingle development machine (Windows 10 or macOS) by just installing Docker Desktop. You can', ' later\ndeploy to the cloud (AKS) for further integration tests, as shown in figure 4-8.\n\n30 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nDocker Registry\n\nMA Azure\n\nAzure Kubernetes Service (AKS)\n\nPC/Development Environment Docker Hub “Managed Kubernetes” for production\nWindows 10 or macOS Or AER\n‘Docker Desktop’ with : . a\nlocal-dev Kubernetes cluster or fe\n\nPo | AKS Kubernetes\n\ndocker build\n\nImages doc', 'ker push\n\n= : —_\nee Redon\npoms\n=a\n\n=<"\n\nLocal\nDocker Image\n© Repository\n\nLocal-dev\nSB Kubernetes cluster\n\nFigure 4-8. Running Kubernetes in dev machine and the cloud\n\nGet started with Azure Kubernetes Service (AKS)\n\nTo begin using AKS, you deploy an AKS cluster from the Azure portal or by using the CLI. For more\ninformation on deploying a Kubernetes cluster to Azure, see Deploy an Azure Kubernetes Service\n(AKS) cluster.\n\nThere are no fees for any', " of the software installed by default as part of AKS. All default options are\nimplemented with open-source software. AKS is available for multiple virtual machines in Azure.\nYou're charged only for the compute instances you choose, as well as the other underlying\ninfrastructure resources consumed, such as storage and networking. There are no incremental charges\nfor AKS itself.\n\nFor further implementation information on deployment to Kubernetes ba", 'sed on kubectl and original\n\n.yaml files, see Deploy to Azure Kubernetes Service (AKS).\n\nDeploy with Helm charts into Kubernetes clusters\n\nWhen deploying an application to a Kubernetes cluster, you can use the original kubectl.exe CLI tool\nusing deployment files based on the native format (.yaml files), as already mentioned in the previous\nsection. However, for more complex Kubernetes applications such as when deploying complex\nmicroservice-based', " applications, it's recommended to use Helm.\n\nHelm Charts helps you define, version, install, share, upgrade, or rollback even the most complex\nKubernetes application. Helm is maintained by the Cloud Native Computing Foundation (CNCF) in\ncollaboration with Microsoft, Google, Bitnami, and the Helm contributor community.\n\nFor further implementation information on Helm charts and Kubernetes, see the section called Install\neShopOnContainers using Hel", "m.\n\n31 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nAdditional resources\n\n. Getting started with Azure Kubernetes Service (AKS)\nhttps://learn.microsoft.com/azure/aks/kubernetes-walkthrough-portal\n\n° Kubernetes. The official site.\n\nhttps://kubernetes.io/\n\nUsing Azure Service Fabric\n\nAzure Service Fabric arose from Microsoft's transition from delivering “box” products, which were\ntypically monolithic in s", 'tyle, to delivering services. The experience of building and operating large\nservices at scale, such as Azure SQL Database, Azure Cosmos DB, Azure Service Bus, or Cortana’s\nBackend, shaped Service Fabric. The platform evolved over time as more and more services adopted\nit. Importantly, Service Fabric had to run not only in Azure but also in standalone Windows Server\ndeployments.\n\nThe aim of Service Fabric is to solve the hard problems of building', ' and running a service and utilizing\ninfrastructure resources efficiently, so that teams can solve business problems using a microservices\napproach.\n\nService Fabric provides two broad areas to help you build applications that use a microservices\napproach:\n\n. A platform that provides system services to deploy, scale, upgrade, detect, and restart failed\nservices, discover service location, manage state, and monitor health. These system services in\n', 'effect enable many of the characteristics of microservices described previously.\n\n. Programming APIs, or frameworks, to help you build applications as microservices: reliable\nactors and reliable services. You can choose any code to build your microservice, but these\nAPIs make the job more straightforward, and they integrate with the platform at a deeper\nlevel. This way you can get health and diagnostics information, or you can take advantage of\nr', "eliable state management.\n\nService Fabric is agnostic with respect to how you build your service, and you can use any technology.\nHowever, it provides built-in programming APIs that make it easier to build microservices.\n\nAs shown in Figure 4-10, you can create and run microservices in Service Fabric either as simple\nprocesses or as Docker containers. It's also possible to mix container-based microservices with\nprocess-based microservices within ", 'the same Service Fabric cluster.\n\n32 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nAzure Service Fabric — Types of clusters\n\nService Fabric cluster Service Fabric with Docker cluster |.»\nSS 2S\n\n_roiker.\nwexKoy, rex,\nvo) en = rex cox\n\ncoo Ka se waa KON =\nre\nrelked\n\nMicroservices as processes Microservices as containers\n\nFigure 4-10. Deploying microservices as processes or as containers in Azure Service Fa', 'bric\n\nIn the first image, you see microservices as processes, where each node runs one process for each\nmicroservice. In the second image, you see microservices as containers, where each node runs Docker\nwith several containers, one container per microservice. Service Fabric clusters based on Linux and\nWindows hosts can run Docker Linux containers and Windows Containers, respectively.\n\nFor up-to-date information about containers support in Azure ', 'Service Fabric, see Service Fabric and\ncontainers.\n\nService Fabric is a good example of a platform where you can define a different logical architecture\n(business microservices or Bounded Contexts) than the physical implementation. For example, if you\nimplement Stateful Reliable Services in Azure Service Fabric, which are introduced in the next section,\n\n“Stateless versus stateful microservices,” you have a business microservice concept with mult', 'iple\nphysical services.\n\nAs shown in Figure 4-10, and thinking from a logical/business microservice perspective, when\nimplementing a Service Fabric Stateful Reliable Service, you usually will need to implement two tiers\nof services. The first is the back-end stateful reliable service, which handles multiple partitions (each\npartition is a stateful service). The second is the front-end service, or Gateway service, in charge of\nrouting and data agg', "regation across multiple partitions or stateful service instances. That Gateway\nservice also handles client-side communication with retry loops accessing the back-end service. It's\ncalled a Gateway service if you implement your custom service, or alternatively you can also use the\nout-of-the-box Service Fabric reverse proxy.\n\n33 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nBusiness/logical\nmicroservice\n", '(Using Azure Service Fabric\nStateful Reliable Services)\n\n\\\n| |\n| Gateway |\n| service :\n| |\n| |\n| |\n| aw Cl\n| Stateful ee |\n| Partition 32M" partition |\n\\ A partitions =, }\n\n*s i\nhe ra\n\nFigure 4-17. Business microservice with several stateful service instances and a custom gateway front end\n\nIn any case, when you use Service Fabric Stateful Reliable Services, you also have a logical or business\nmicroservice (Bounded Context) that’s composed of mul', 'tiple physical services. Each of them, the\nGateway service, and Partition service could be implemented as ASP.NET Web API services, as shown\nin Figure 4-11. Service Fabric has prescription to support several stateful reliable services in containers.\n\nIn Service Fabric, you can group and deploy groups of services as a Service Fabric Application, which is\nthe unit of packaging and deployment for the orchestrator or cluster. Therefore, the Service F', 'abric\nApplication could be mapped to this autonomous business and logical microservice boundary or\nBounded Context, as well, so you could deploy these services autonomously.\n\nService Fabric and containers\n\nWith regard to containers in Service Fabric, you can also deploy services in container images within a\nService Fabric cluster. As Figure 4-12 shows, most of the time there will only be one container per\nservice.\n\nBusiness/Logical Microservice\n(', 'Using Azure Service Fabric and Containers)\n\nfa A\nService Fabric Application |\n\nLogica Zou ary OT\n\nBusiness Micraservice\n\nSOL Server\ndatabase\n\n\\ /\n\nFigure 4-12. Business microservice with several services (containers) in Service Fabric\n\n34 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nA Service Fabric application can run several containers accessing an external database and the whole\nset would be the logi', 'cal boundary of a Business Microservice. However, so-called “sidecar” containers\n(two containers that must be deployed together as part of a logical service) are also possible in\nService Fabric. The important thing is that a business microservice is the logical boundary around\nseveral cohesive elements. In many cases, it might be a single service with a single data model, but in\nsome other cases you might have several physical services as well.\n\n', 'Note that you can mix services in processes, and services in containers, in the same Service Fabric\napplication, as shown in Figure 4-13.\n\nBusiness/Logical Microservice\n(Using Azure Service Fabric and Containers)\n\n/ Service Fabric Application \\\n\nContainer / Guest service\n\nLogical Boundary of\n\n____ |\nStateful 6\n\nservice I\n\\ partitions /\n\n@8\n\nce cc ce ce es es ee ee ee ee ee ee ee ee ee ee ee oe\n\nFigure 4-13. Business microservice mapped to a Servi', 'ce Fabric application with containers and stateful services\n\nFor more information about container support in Azure Service Fabric, see Service Fabric and\ncontainers.\n\nStateless versus stateful microservices\n\nAs mentioned earlier, each microservice (logical Bounded Context) must own its domain model (data\nand logic). In the case of stateless microservices, the databases will be external, employing relational\noptions like SQL Server, or NoSQL optio', 'ns like Azure Cosmos DB or MongoDB.\n\nBut the services themselves can also be stateful in Service Fabric, which means that the data resides\nwithin the microservice. This data might exist not just on the same server, but within the microservice\nprocess, in memory and persisted on hard drives and replicated to other nodes. Figure 4-14 shows the\ndifferent approaches.\n\n35 CHAPTER 4 | Designing and developing containerized apps using Docker and Microso', 'ft Azure\nStateless Services Stateful Services\n\nBusiness Business\nmicroservice A microservice B\n\nSy\nEJ Stateless a Gateway \\\nservice service\n|\n|\noY oY\n‘ai Stateful 6\n\nservice i\n\nJ \\ partitions WA\n\n= ~\n\nSQL DB or\nNoSQL DB\n\nFigure 4-14. Stateless versus stateful microservices\n\nIn stateless services, the state (persistence, database) is kept out of the microservice. In stateful\nservices, state is kept inside the microservice. A stateless approach is ', "perfectly valid and is easier to\nimplement than stateful microservices, since the approach is similar to traditional and well-known\npatterns. But stateless microservices impose latency between the process and data sources. They also\ninvolve more moving pieces when you're trying to improve performance with additional cache and\nqueues. The result is that you can end up with complex architectures that have too many tiers.\n\nIn contrast, stateful micr", "oservices can excel in advanced scenarios, because there's no latency between\nthe domain logic and data. Heavy data processing, gaming back ends, databases as a service, and\nother low-latency scenarios all benefit from stateful services, which enable local state for faster access.\n\nStateless and stateful services are complementary. For instance, as you can see in the right diagram in\nFigure 4-14, a stateful service can be split into multiple part", 'itions. To access those partitions, you\nmight need a stateless service acting as a gateway service that knows how to address each partition\nbased on partition keys.\n\nStateful services do have drawbacks. They impose a high complexity level to be scaled out.\nFunctionality that would usually be implemented by external database systems must be addressed for\ntasks such as data replication across stateful microservices and data partitioning. However, t', 'his is one\nof the areas where an orchestrator like Azure Service Fabric with its stateful reliable services can help\nthe most—by simplifying the development and lifecycle of stateful microservices using the Reliable\nServices API and Reliable Actors.\n\nOther microservice frameworks that allow stateful services, support the Actor pattern, and improve\nfault tolerance and latency between business logic and data are Microsoft Orleans, from Microsoft\nRe', 'search, and Akka.NET. Both frameworks are currently improving their support for Docker.\n\nRemember that Docker containers are themselves stateless. If you want to implement a stateful\nservice, you need one of the additional prescriptive and higher-level frameworks noted earlier.\n\nUsing Azure Service Fabric Mesh\n\nAzure Service Fabric Mesh is a fully managed service that enables developers to build and deploy\nmission critical applications without ma', 'naging any infrastructure. Use Service Fabric Mesh to build\nand run secure, distributed microservices applications that scale on demand.\n\n36 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nAs shown in figure 4-15, applications hosted on Service Fabric Mesh run and scale without you\nworrying about the infrastructure powering it.\n\nDocker Registry\n[] MA Azure\n3 Azure Service Fabric Mesh\nPC/Development Environ', 'ment (codename “SeaBreeze”)\nWindows 10 or macOS\n‘Docker Desktop’ with Docker Hub\n\nor\nlocal-dev Kubernetes cluster Aaure Container Registry\n\n“Infrastructure is transparent"\naz. Visual Studio\nor\n\ndocker build docker push c fT deployment\n\nLocal\nDocker Image\n\nRepository\n\n| fet\n| fey\n\nFigure 4-15. Deploying a microservice/containers application to Service Fabric Mesh\n\nUnder the covers, Service Fabric Mesh consists of clusters of thousands of machines.', ' All cluster\noperations are hidden from the developer. You simply need to upload your containers and specify\nresources you need, availability requirements, and resource limits. Service Fabric Mesh automatically\nallocates the infrastructure requested by your application deployment and also handles infrastructure\nfailures, making sure your applications are highly available. You only need to care about the health\nand responsiveness of your applicati', "on, not the infrastructure.\n\nFor further information, see the Service Fabric Mesh documentation.\n\nChoosing orchestrators in Azure\n\nThe following table provides guidance on what orchestrator to use depending on workloads and OS\nfocus.\n\nAzure Product Orchestrator Description Good for Common workloads\n\nKubernetes is an open-source platform for Microservices based on\nIt's an OSS ecosystem\n\nAzure Kubernetes Service\n\nKubernetes automating deployment, s", "caling, and containers\n(AKS) operations of application containers across\ni clusters of hosts. . More mature: A\ni AKS: You pay for VMsin cluster\nat ACS Engine: \\aaS container infrastructure Less mature: ea\nAzure Service Fabric Azure Service Fabric is a distributed systems It's a Microsoftecosystem = 4) ~Microservices based on\nClust d Mes Service Fabric platform that makes it easy to package, and OSS containers\ndeploy, and manage scalable and relia", 'ble More mature: 4 b) Microservices based on\nmicroservices.\nQ <> ¢y Mesh: PaaS/Serverless platform Less mature: A plain Processes\nCluster. You pay for VMsin cluster = c) Stateful services\n\nFigure 4-16. Orchestrator selection in Azure guidance\n\n37 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nDeploy to Azure Kubernetes Service (AKS)\n\nYou can interact with AKS using your preferred client operating system (', 'Windows, macOS, or Linux)\nwith Azure command-line interface (Azure CLI) installed. For more details, refer Azure CLI\ndocumentation and Installation guide for the available environments.\n\nCreate the AKS environment in Azure\n\nThere are several ways to create the AKS Environment. It can be done by using Azure CLI commands\nor by using the Azure portal.\n\nHere you can explore some examples using the Azure CLI to create the cluster and the Azure portal ', 'to\nreview the results. You also need to have Kubectl and Docker in your development machine.\n\nCreate the AKS cluster\nCreate the AKS cluster using this command (the resource group must exist):\n\naz aks create --resource-group explore-docker-aks-rg --name explore-docker-aks --node-\nvm-size Standard _B2s --node-count 1 --generate-ssh-keys --location westeurope\n\nNote\n\nThe --node-vm-size and --node-count parameter values are good enough for a sample/de', 'v\napplication.\n\nAfter the creation job finishes, you can see:\n\n. The AKS cluster created in the initial resource group\n\n. A new, related resource group, containing the resources related to the AKS cluster, as show in\nthe following images.\n\nThe initial resource group, with the AKS cluster:\n\n38 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nMicrosoft Azure\n\nHome > Resource groups > explore-docker-aks-rg\n\nRe', 'source groups < xX  (g) explore-docker-aks-rg x xX\n+ Add £3 Manage view v *"" . + Add == Edit columns Of Delete resource group oO Refresh —> Move Lv Export to CSV Assign tags Delete Export template QD) Feedback\n_ Subscription (change) : Demo subscription Deployments : No deployments\noKS\nSubscription ID\nName *t\nTags (change) : Click here to add tags\n\n#) explore-docker-aks-rg\n\n(6) McC_explore-docker-aks-rg_explore-doc-. ***\n\nFilter by name Type == ', 'all © Location == all @ +> Add filter\nShowing 1 to 1 of 1 records. Show hidden types © No grouping Vv\nName 7 Type Ty Location Ty\nane explore-docker-aks Kubernetes service West Europe\nPage| 1 ~Y |ofl Page | 1 “lofi\n\nFigure 4-17. AKS Resource Group view from Azure.\n\nThe AKS cluster resource group:\n\nMicrosoft Azure\n\nHome > Resource groups > MC_explore-docker-aks-rg_explore-docker-aks_westeurope\n\nResource groups <X fs) MC_explore-docker-aks-rg_explor', 'e-docker-aks_westeurope x xX\n+ Add £3 Manage view v *"" ’ + Add == Edit columns Of Delete resource group oO Refresh —> Move Lv Export to CSV Assign tags Delete Export template Q) Feedback\niption (change) : Demo subscription Deployments : 1 Succeeded\n\nSubscription ID\nName *\nTags (change) : Click here to add tags\n(6) explore-docker-aks-rg\n(8) MC_explore-docker-aks-rg_explore-doc-.. ***\nFilter by name... ype ==all © Location ==all @ ty Add filter\nSh', 'owing 1 to 6 of 6 records. Show hidden types © No grouping Vv\nName * Type Ty Location Ty\nES 2fedadef-68e1-4f8c-bc14-5019bc2c3ab5 Public IP address West Europe\nL_| “a aks-agentpool-41297266-nsg Network security group West Europe\n‘2 aks-agentpool-41297266-routetable Route table West Europe\na aks-nodepool1-41297266-vmss Virtual machine scale set West Europe\n¢> aks-vnet-41297266 Virtual network West Europe\n} kubernetes Load balancer West Europe\nPage|', " 1 ~“ |of1 Page | 1 ™ |of1\n\nFigure 4-18. AKS view from Azure.\n\nImportant\n\nIn general, you shouldn't need to modify the resources in the AKS cluster resource group. For\nexample, the resource group is deleted when you delete the AKS cluster.\n\nYou can also view the node created using Azure CLI and Kubectl.\n\nFirst, getting the credentials:\n\naz aks get-credentials --resource-group explore-docker-aks-rg --name explore-docker-\naks\n\n39 CHAPTER 4 | Design", 'ing and developing containerized apps using Docker and Microsoft Azure\n$ az aks get-credentials --resource-group explore-docker-aks-rg --name explore-docker-aks\n\nMerged "explore-docker-aks" as current context in /home/miguel/.kube/config\n\n$\n\nFigure 4-19. aks get-credentials command result.\n\nAnd then, getting nodes from Kubectl:\n\nkubectl get nodes\n\n: nodes\nNWAME ‘O AGE VERSION\n\n36m w1l.15.16\n\nFigure 4-20. kubectl get nodes command result.\n\nDevelop', 'ment environment for Docker apps\n\nDevelopment tools choices: IDE or editor\n\nNo matter if you prefer a full and powerful IDE or a lightweight and agile editor, Microsoft has you\ncovered when it comes to developing Docker applications.\n\nVisual Studio Code and Docker CLI (cross-platform tools for Mac, Linux, and\nWindows)\n\nIf you prefer a lightweight, cross-platform editor supporting any development language, you can use\nVisual Studio Code and Docker', ' CLI. These products provide a simple yet robust experience, which is\ncritical for streamlining the developer workflow. By installing “Docker for Mac” or “Docker for\nWindows” (development environment), Docker developers can use a single Docker CLI to build apps\nfor both Windows or Linux (runtime environment). Plus, Visual Studio Code supports extensions for\nDocker with Intellisense for Dockerfiles and shortcut-tasks to run Docker commands from th', "e editor.\n\nNote\n\nTo download Visual Studio Code, go to https://code.visualstudio.com/download.\nTo download Docker for Mac and Windows, go to https://www.docker.com/products/docker.\n\nVisual Studio with Docker Tools (Windows development machine)\n\nIt's recommended that you use Visual Studio 2022 or later with the built-in Docker Tools enabled.\nWith Visual Studio, you can develop, run, and validate your applications directly in the chosen Docker\nenvi", 'ronment. Press F5 to debug your application (single container or multiple containers) directly in a\nDocker host, or press Ctrl+F5 to edit and refresh your app without having to rebuild the container. It’s\nthe simplest and most powerful choice for Windows developers to create Docker containers for Linux\nor Windows.\n\n40 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nVisual Studio for Mac (Mac development ma', "chine)\n\nYou can use Visual Studio for Mac when developing Docker-based applications. Visual Studio for Mac\noffers a richer IDE when compared to Visual Studio Code for Mac.\n\nLanguage and framework choices\n\nYou can develop Docker applications using Microsoft tools with most modern languages. The\nfollowing is an initial list, but you're not limited to it:\n\n° .NET and ASP.NET Core\n\n. Node,js\n. Go\n\n° Java\n\n. Ruby\n\n° Python\n\nBasically, you can use any ", "modern language supported by Docker in Linux or Windows.\n\nInner-loop develooment workflow for Docker apps\n\nBefore triggering the outer-loop workflow spanning the entire DevOps cycle, it all begins on each\ndeveloper's machine, coding the app itself, using their preferred languages or platforms, and testing it\nlocally (Figure 4-21). But in every case, you'll have an important point in common, no matter what\nlanguage, framework, or platforms you cho", "ose. In this specific workflow, you're always developing and\ntesting Docker containers in no other environments, but locally.\n\noO\n\nInner Loop\n\nFigure 4-21. Inner-loop development context\nThe container or instance of a Docker image will contain these components:\n. An operating system selection (for example, a Linux distribution or Windows)\n. Files added by the developer (for example, app binaries)\n. Configuration (for example, environment settings", ' and dependencies)\n. Instructions for what processes to run by Docker\n\nYou can set up the inner-loop development workflow that utilizes Docker as the process (described in\nthe next section). Consider that the initial steps to set up the environment are not included, because\nyou only need to do it once.\n\n41 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nBuilding a single app within a Docker container using', ' Visual Studio\nCode and Docker CLI\n\nApps are made up from your own services plus additional libraries (dependencies).\n\nFigure 4-22 shows the basic steps that you usually need to carry out when building a Docker app,\nfollowed by detailed descriptions of each step.\n\nhttp\naccess...\n\ndocker run\ndocker-compose up\n\ndocker build\n\nMy My\nContainer 1 Container 2\n\nra)\n\nRemote ae\n\nDocker Registry\n(i.e., Docker Hub)\n\nLocal Docker\nRepository\n\nBase\nImages\n\ngit ', "push\n\nFigure 4-22. High-level workflow for the life cycle for Docker containerized applications using Docker CLI\n\nStep 1: Start coding in Visual Studio Code and create your initial app/service\nbaseline\n\nThe way you develop your application is similar to the way you do It without Docker. The difference is\nthat while developing, you're deploying and testing your application or services running within Docker\ncontainers placed in your local environme", "nt (like a Linux VM or Windows).\n\nSetting up your local environment\n\nWith the latest versions of Docker Desktop for Mac and Windows, it's easier than ever to develop\nDocker applications, and the setup Is straightforward.\n\nTip\n\nFor instructions on setting up Docker Desktop for Windows, go to https://docs.docker.com/docker-\n\nfor-windows/.\n\nFor instructions on setting up Docker Desktop for Mac, go to https://docs.docker.com/docker-for-\nmac/.\n\nIn add", "ition, you'll need a code editor so that you can actually develop your application while using\nDocker CLI.\n\n42 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nMicrosoft provides Visual Studio Code, which is a lightweight code editor that's supported on\nWindows, Linux, and macOS, and provides Intellisense with support for many languages (JavaScript,\n.NET, Go, Java, Ruby, Python, and most modern languages), ", 'debugging, integration with Git and\nextensions support. This editor is a great fit for macOS and Linux developers. In Windows, you also\ncan use Visual Studio.\n\nTip\n\nFor instructions on installing Visual Studio Code for Windows, Linux, or macOS, go to\n\nhttps://code.visualstudio.com/docs/setup/setup-overview/.\nFor instructions on setting up Docker for Mac, go to https://docs.docker.com/docker-for-mac/.\n\nYou can work with Docker CLI and write your c', 'ode using any code editor, but using Visual Studio\nCode with the Docker extension makes it easy to author Dockerfile and docker-compose.yml files in\nyour workspace. You can also run tasks and scripts from the Visual Studio Code IDE to execute Docker\ncommands using the Docker CLI underneath.\n\nThe Docker extension for VS Code provides the following features:\n. Automatic Dockerfile and docker-compose.yml file generation\n. Syntax highlighting and hov', 'er tips for docker-compose.yml and Dockerfile files\n. Intellisense (completions) for Dockerfile and docker-compose.yml files\n. Linting (errors and warnings) for Dockerrfile files\n. Command Palette (F1) integration for the most common Docker commands\n. Explorer integration for managing Images and Containers\n. Deploy images from DockerHub and Azure Container Registries to Azure App Service\n\nTo install the Docker extension, press Ctrl+Shift+P, type ', 'ext install, and then run the Install Extension\ncommand to bring up the Marketplace extension list. Next, type docker to filter the results, and then\nselect the Docker Support extension, as depicted in Figure 4-23.\n\n() Extension: Docker »\n\nDocker\nDocker 1.0.0 42M #45 crosof «4284613 Repository a\nMakes it easy to create, manage, and debug containerized ap... Microsoft A AE Speeliey! 512s\n\nMicrosoft install Makes it easy to create, manage, and debu', "g containerized applications.\n\ndocker\n\nInstall\n\nI IT i a\nnaed based on the files you recently opened. ignore Reco (\n\nFigure 4-23. Installing the Docker Extension in Visual Studio Code\n\n43 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nStep 2: Create a DockerFile related to an existing image (plain OS or dev\nenvironments like .NET, Node.js, and Ruby)\n\nYou'll need a DockerFile per custom image to be built a", "nd per container to be deployed. If your app is\nmade up of single custom service, you'll need a single DockerFile. But if your app is composed of\nmultiple services (as in a microservices architecture), you'll need one Dockerfile per service.\n\nThe DockerFile is commonly placed in the root folder of your app or service and contains the required\ncommands so that Docker knows how to set up and run that app or service. You can create your\nDockerFile a", "nd add it to your project along with your code (nodes, .NET, etc.), or, if you're new to the\nenvironment, take a look at the following Tip.\n\nTip\n\nYou can use the Docker extension to guide you when using the Dockerfile and docker-compose.yml\n\nfiles related to your Docker containers. Eventually, you'll probably write these kinds of files without\nthis tool, but using the Docker extension is a good starting point that will accelerate your learning\ncu", 'rve.\n\nIn Figure 4-24, you can see the steps to add the docker files to a project by using the Docker\nExtension for VS Code:\n\nOpen the command palette, type “docker” and select “Add Docker Files to Workspace”.\nSelect Application Platform (ASP.NET Core)\n\nSelect Operating System (Linux)\n\nInclude optional Docker Compose files\n\nEnter ports to publish (80, 443)\n\nSelect the project\n\nAu fF WN >\n\n44 CHAPTER 4 | Designing and developing containerized apps ', 'using Docker and Microsoft Azure\nexplore-docker-vscode - Visual Studio Code\n\n>docker\n\n: Add Docker Files to Workspace...\n\nct Application Platiorm\n\nWindows\n\nWhat port(s) does your app listen on? Enter a comma-separated list, or empty for no exposed port.\n(Press ‘Enter’ to confirm or ‘Escape’ to cancel)\n\nsrc/WebApi/WebApi.csproj GB)\n\nsrc/WebApp/WebApp.cspro]\n\nFigure 4-24. Docker files added using the Add Docker files to Workspace command\n\nWhen you ', "add a DockerFile, you specify what base Docker image you'll be using (like using FROM\nmcr.microsoft.com/dotnet/aspnet). You'll usually build your custom image on top of a base image\nthat you get from any official repository at the Docker Hub registry (like an image for .NET or the one\n\nfor Node.js).\nTip\n\nYou'll have to repeat this procedure for every project in your application. However, the extension will\n\nask to overwrite the generated docker-c", 'ompose file after the first time. You should reply to not\noverwrite it, so the extension creates separate docker-compose files, that you can then merge by\nhand, prior to running docker-compose.\n\nUse an existing official Docker image\n\nUsing an official repository of a language stack with a version number ensures that the same language\nfeatures are available on all machines (including development, testing, and production).\n\nThe following is a sampl', 'e DockerFile for a .NET container:\n\n45 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nFROM mcr.microsoft.com/dotnet/aspnet:6.@ AS base\nWORKDIR /app\n\nEXPOSE 80\n\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:6.0@ AS build\n\nWORKDIR /src\n\nCOPY ["src/WebApi/WebApi.csproj", "“src/WebApi/" ]\n\nRUN dotnet restore "src/WebApi/WebApi.csproj"\n\nCOPY .\n\nWORKDIR "/src/src/WebApi"\n\nRUN dotnet build "WebApi.csproj" -c Rel', 'ease -o /app/build\n\nFROM build AS publish\nRUN dotnet publish "WebApi.csproj" -c Release -o /app/publish\n\nFROM base AS final\n\nWORKDIR /app\n\nCOPY --from=publish /app/publish .\nENTRYPOINT ["dotnet", "WebApi.d11"]\n\nIn this case, the image is based on version 6.0 of the official ASP.NET Core Docker image (multi-arch\nfor Linux and Windows), as per the line FROM mcr.microsoft.com/dotnet/aspnet:6.0. (For more\ninformation about this topic, see the ASP.NET', ' Core Docker Image page and the .NET Docker Image\n\npage).\n\nIn the DockerFile, you can also instruct Docker to listen to the TCP port that you\'ll use at run time\n(such as port 80 or 443).\n\nYou can specify additional configuration settings in the Dockerfile, depending on the language and\nframework you\'re using. For instance, the ENTRYPOINT line with ["dotnet", "WebMvcApplication.dll"]\ntells Docker to run a .NET application. If you\'re using the SDK ', 'and the .NET CLI (dotnet CLI) to build\nand run the .NET application, this setting would be different. The key point here is that the\nENTRYPOINT line and other settings depend on the language and platform you choose for your\napplication.\n\nTip\n\nFor more information about building Docker images for .NET applications, see\n\nhttps://learn.microsoft.com/dotnet/core/docker/build-container.\n\nTo learn more about building your own images, go to\n\nhttps://doc', 's.docker.com/engine/tutorials/dockerimages/.\n\nUse multi-arch image repositories\n\nA single image name in a repo can contain platform variants, such as a Linux image and a Windows\nimage. This feature allows vendors like Microsoft (base image creators) to create a single repo to\ncover multiple platforms (that is, Linux and Windows). For example, the dotnet/aspnet repository\navailable in the Docker Hub registry provides support for Linux and Windows ', 'Nano Server by using\nthe same image name.\n\nPulling the dotnet/aspnet image from a Windows host pulls the Windows variant, whereas pulling the\nSame image name from a Linux host pulls the Linux variant.\n\n46 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nCreate your base image from scratch\n\nYou can create your own Docker base image from scratch as explained in this article from Docker. This\nscenario is proba', "bly not the best for you if you're just starting with Docker, but if you want to set the\n\nspecific bits of your own base image, you can do it.\n\nStep 3: Create your custom Docker images embedding your service in it\n\nFor each custom service that comprises your app, you'll need to create a related image. If your app is\nmade up of a single service or web app, you'll need just a single image.\n\nNote\n\nWhen taking into account the “outer-loop DevOps work", 'flow”, the images will be created by an\nautomated build process whenever you push your source code to a Git repository (Continuous\nIntegration), so the images will be created in that global environment from your source code.\n\nBut before you consider going to that outer-loop route, you need to ensure that the Docker\napplication is actually working properly so that they don’t push code that might not work properly to\nthe source control system (Git,', ' etc.).\n\nTherefore, each developer first needs to do the entire inner-loop process to test locally and continue\ndeveloping until they want to push a complete feature or change to the source control system.\n\nTo create an image in your local environment and using the DockerFile, you can use the docker build\ncommand, as shown in Figure 4-25, because it already tags the image for you and builds the images\nfor all services in the application with a si', 'mple command.\n\n> build webapi: Latest src/WebApi/Dockerfile .\n[+] Building 73.9s (8/17)\n\n=> [build 1/7] FROM mcr.microsoft.com/dotnet/sdk:5.0@sha256:b77£3a3dc3db717405b1c98c2917al4dbeedcdd19b36c2d7b4u77d7596F6uuF3cd\n\n> > extracting sha256:1d922f93bc4ub6f84ub3a260dd70d8e60020cbaf2b576e55ede53b5033d370d59\n\nFigure 4-25. Running docker build\n\nOptionally, instead of directly running docker build from the project folder, you first can generate a\ndeploy', 'able folder with the .NET libraries needed by using the run dotnet publish command, and then\nrun docker build.\n\nThis example creates a Docker image with the name webapi:latest (:latest is a tag, like a specific\nversion). You can take this step for each custom image you need to create for your composed Docker\n\n47 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\napplication with several containers. However, w', "e'll see in the next section that it's easier to do this\nusing docker-compose.\n\nYou can find the existing images in your local repository (your development machine) by using the\ndocker images command, as illustrated in Figure 4-26.\n\n> images\n\nREPOSITORY TAG IMAGE ID CREATED\nwebapp Latest luafabc6c82d 5 minutes ago\n\nwebapi Latest faa96bdeee9c 5 minutes ago\nmcr.microsoft.com/dotnet/sdk 5.8 acc2e9a7698d 28 hours ago\nmcr.microsoft.com/dotnet/aspnet 5", '.8 66792fe28528 28 hours ago\n\nFigure 4-26. Viewing existing images using docker images\nStep 4: Define your services in docker-compose.yml when building a composed\n\nDocker app with multiple services\n\nWith the docker-compose.yml file, you can define a set of related services to be deployed as a\ncomposed application with the deployment commands explained in the next step section.\n\nCreate that file in your main or root solution folder; it should have', ' content similar to that shown in this\ndocker-compose.yml file:\n\nversion: "3.4"\n\nservices:\nwebapi:\nimage: webapi\nbuild:\ncontext:\ndockerfile: src/WebApi/Dockerfile\nports:\n- 51080:80\ndepends_on:\n- redis\nenvironment:\n- ASPNETCORE_ENVIRONMENT=Development\n- ASPNETCORE_URLS=http://+:80\n\nwebapp:\nimage: webapp\nbuild:\ncontext:\ndockerfile: src/WebApp/Dockerfile\nports:\n- 50080: 80\nenvironment:\n- ASPNETCORE_ENVIRONMENT=Development\n- ASPNETCORE_URLS=http://+:', '80\n- WebApiBaseAddress=http: //webapi\n\nredis:\nimage: redis\n\nIn this particular case, this file defines three services: the web API service (your custom service), a web\napplication, and the Redis service (a popular cache service). Each service will be deployed as a\ncontainer, so you need to use a concrete Docker image for each. For this particular application:\n\n48 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft A', 'zure\n. The web API service is built from the DockerFile in the src/WebApi/Dockerfile directory.\n\n. The host port 51080 is forwarded to the exposed port 80 on the webapi container.\n\n. The web API service depends on the Redis service\n\n. The web application accesses the web API service using the internal address: http://webapi.\n\n. The Redis service uses the latest public redis image pulled from the Docker Hub registry.\nRedis is a popular cache syste', "m for server-side applications.\n\nStep 5: Build and run your Docker app\n\nIf your app has only a single container, you just need to run it by deploying it to your Docker Host\n(VM or physical server). However, if your app is made up of multiple services, you need to compose it,\ntoo. Let's see the different options.\n\nOption A: Run a single container or service\nYou can run the Docker image by using the docker run command, as shown here:\n\ndocker run -t", " -d -p 50080:80 webapp:latest\n\nFor this particular deployment, we'll be redirecting requests sent to port 50080 on the host to the\ninternal port 80.\n\nOption B: Compose and run a multiple-container application\n\nIn most enterprise scenarios, a Docker application will be composed of multiple services. For these\ncases, you can run the docker-compose up command (Figure 4-27), which will use the docker-\ncompose.yml file that you created previously. Run", 'ning this command builds all custom images and\ndeploys the composed application with all of its related containers.\n\n49 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n> up\nCreating expLlLore-docker-vscode_webapi_1\nCreating expLlore-docker-vscode_webapp_1\nAttaching to expLore-docker-vscode_webapp_1, expLore-docker-vscode_webapi_1\nMicrosoft.AspNetCore.DataProtection. Repositories .FileSystemxXmLRepository[6', "0]\nStoring keys in a directory '/root/.aspnet/DataProtection-Keys' that may not be J\nected data will be unavailable when container is destroyed.\nMicrosoft .AspNetCore.DataProtection.keyManagement.XmLKeyManager[35]\nNo XML encryptor configured. Key {19eedc7c-d3d6-d4u3-af35-93d4d078119c} may be pe\n\nMicrosoft.Hosting.Lifetime[6]\n\nNow Listening on: http://[::]:80\nMicrosoft.Hosting.Lifetime[6]\n\nApplication started. Press Ctrl+C to shut down.\nMicrosoft.", 'Hosting.Lifetime[6]\n\nHosting environment: Development\nMicrosoft.Hosting.Lifetime[6]\n\nContent root path: /app\nMicrosoft.Hosting.Lifetime[6]\n\nNow Listening on: http://[::]:80\nMicrosoft.Hosting.Lifetime[6]\n\nApplication started. Press Ctrl+C to shut down.\nMicrosoft.Hosting.Lifetime[6]\n\nHosting environment: Development\nMicrosoft.Hosting.Lifetime[6]\n\nContent root path: /app\n\nFigure 4-27. Results of running the “docker-compose up” command\n\nAfter you run', ' docker-compose up, you deploy your application and its related container(s) into your\nDocker Host, as illustrated in Figure 4-28, in the VM representation.\n\nMy My\nContainer 1 Container 2\n\na\n\na\n\nFigure 4-28. VM with Docker containers deployed\n\nStep 6: Test your Docker application (locally, in your local CD VM)\nThis step will vary depending on what your app is doing.\n\nIn a simple .NET Web API “Hello World” deployed as a single container or service', ", you'd just need to\naccess the service by providing the TCP port specified in the DockerFile.\n\nOn the Docker host, open a browser and navigate to that site; you should see your app/service\nrunning, as demonstrated in Figure 4-29.\n\n50 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n|- Weather Forecast - WebApp x | +\n\n= © fn) @ localhost:50080/WeatherForecast iA\n\nyg\nq\n3\nl=\nfe)\n©\nir\nzal\n2]\n@Q\n\nWebApp Home Pr", 'ivacy\n\nWeather Forecast\n\nData from: http://webapi/WeatherForecast\n\nDate Summary\n2020-04-22 17:32:17 43 109 Chilly\n2020-04-23 17:32:17 13 55 Cool\n2020-04-24 17:32:17 49 120 Bracing\n2020-04-25 17:32:17 -20 -3 Cool\n2020-04-26 17:32:17 2 35 Bracing\n\nBack to Home page\n© 2020 - WebApp - Privacy\n\nFigure 4-29. Testing your Docker application locally by using the browser\n\nNote that it’s using port 50080, but internally it’s being redirected to port 80, be', 'cause that\'s how it\nwas deployed with docker compose, as explained earlier.\n\nYou can test this by using the browser using CURL from the terminal, as depicted in Figure 4-30.\n\nhttp :// LocaLhost:51080/WeatherForecast\n\nStatusCode : 200\nStatusDescription : OK\nContent : [{"date":"2621-01-06T12:13:43.7721387+00:00", "temperatureC":42,"temperatureF":107, "Summary": "Chilly"}, {"date":"2621-01-97T12:\nry":"Bracing...\nRawContent : HTTP/1.1 200 OK\nTransfer', '-Encoding: chunked\nContent-Type: application/json; charset=utf-8\nDate: Tue, 85 Jan 2021 12:13:43 GMT\nServer: Kestrel\n\n[{"date":"2021-01-06T12:13:43.7721387+00:00", "temper ...\nForms : {}\nHeaders : {[Transfer-Encoding, chunked], [Content-Type, application/json; charset=utf-8], [Date, Tue, 95 Jan 2021 12:13:43 GMT], [Serve\nImages\nInputFields\nLinks :\nParsedHtml : mshtmL.HTMLDocumentClass\n\nRawContentLength : 512\n\nFigure 4-30. Testing a Docker applica', "tion locally by using CURL\n\nDebugging a container running on Docker\n\nVisual Studio Code supports debugging Docker if you're using Node.js and other platforms like .NET\ncontainers.\n\n51 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nYou also can debug .NET or .NET Framework containers in Docker when using Visual Studio for\nWindows or Mac, as described in the next section.\n\nTip\n\nTo learn more about debugging", " Node.js Docker containers, see\n\ndebugging-updates-rich-object-hover-conditional-breakpoints-node-js-mono-more.\n\nUse Docker Tools in Visual Studio on Windows\n\nThe developer workflow when using the Docker Tools included in Visual Studio 2022 version 17.0 and\nlater, is similar to using Visual Studio Code and Docker CLI (in fact, it's based on the same Docker CLI),\nbut it’s easier to get started, simplifies the process, and provides greater producti", 'vity for the build,\nrun, and compose tasks. It can also run and debug your containers via the usual F5 and Ctrl+F5keys\nfrom Visual Studio. You can even debug a whole solution if its containers are defined in the same\ndocker-compose.yml file at the solution level.\n\nConfigure your local environment\n\nWith the latest versions of Docker for Windows, it’s easier than ever to develop Docker applications\nbecause the setup Is straightforward, as explained', " in the following references.\n\nTip\n\nTo learn more about installing Docker for Windows, go to (https://docs.docker.com/docker-for-\nwindows/).\n\nDocker support in Visual Studio\n\nThere are two levels of Docker support you can add to a project. In ASP.NET Core projects, you can\njust add a Dockerfile file to the project by enabling Docker support. The next level is container\norchestration support, which adds a Dockerfile to the project (if it doesn't a", 'lready exist) and a docker-\ncompose.yml file at the solution level. Container orchestration support, via Docker Compose, is\navailable in Visual Studio 2022 versions 17.0. Container orchestration support is an opt-in feature in\nVisual Studio 2022 versions 17.0 or later. Visual Studio 2022 also supports Kubernetes/Helm\ndeployment.\n\nThe Add > Docker Support and Add > Container Orchestrator Support commands are located on\nthe right-click menu (or con', "text menu) of the project node for an ASP.NET Core project in Solution\nExplorer, as shown in Figure 4-31:\n\n52 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\noN\n\nSolution Explorer © ncn A\n\nTCSII\n\n‘b\n4\nSut\n\nC\na\n\nolution 'docs-vs-images' (4 of 4 projects)\n\nube\n\nSrc\n> +) DockerizedMvcApplication\n> am] MSSampleAKSApplication\n\n4+@F docker-compose Rebuild\n\n| 2195\n\naL) .dockerignore\nClean\n\nb +47 docker-compose.yr", '\nAnalyze and Code Cleanup\nPack\nPublish...\n\nCleanup Selected Code\n\nPower Commands\ni.) Ver EW\n\nScope to This\nNew Solution Explorer View\n\nFile Nesting\nEdit Project File\nBuild Dependencies\n\nNew Iter... Ctrl+ Shift+Ah Add\nExisting Item... Shitt+Alt+aA Manage NuGet Packages...\nNew Scaffolded Item... 2 Manage Client-Side Libraries...\n\nNew Folder Manage User Secrets\n\nApplication Insights Telemetry... Set as Startup Project\n\n: : - Debuc\nContainer Orchestr', 'ator Support... od\n\nDocker Support... Source Control\n\nClient-Side Library... Cut\n\nFigure 4-31. Adding Docker support to a Visual Studio project\n\nBesides the option to add Docker support to an existing application, as shown in the previous section,\nyou can also enable Docker support during project creation by selecting Enable Docker Support in\nthe New ASP.NET Core Web Application dialog box that opens after you click OK in the New\nProject dialog b', 'ox, as shown in Figure 4-32.\nAdditional information\n\nASP.NET Core Web App GC Linux = =macOS = Windows == Cloud ~— Service. © Web\nFramework @\n\n-NET 6.0 (Long-term support)\nAuthentication type @\n\nNone\n\n|¥| Configure for HTTPS @\n\nDocker OS @\n\nLinux\n\nCreate\n\nFigure 4-32. Enable Docker support during project creation in Visual Studio\n\nWhen you add or enable Docker support, Visual Studio adds a Dockerfile file to the project, that\nincludes references t', "o all required project from the solution.\n\nWhen you want to compose a multi-container solution, add container orchestration support to your\nprojects. This lets you run and debug a group of containers (a whole solution) at the same time if\nthey're defined in the same docker-compose.yml file.\n\nTo add container orchestration support, right-click on the project node in Solution Explorer, and\nchoose Add > Container Orchestration Support. Then choose D", "ocker Compose to manage the\ncontainers.\n\nAfter you add container orchestration support to your project, you see a Dockerfile added to the\nproject and a docker-compose folder added to the solution in Solution Explorer, as shown in Figure\n4-33:\nSolution Explorer\n\naia] [|- =\n\nSolution 'docs-vs-images' (4 of 4 projects)\nSrc\n&] DockerzedMycApplication\n=] MSSampleAKSApplication\nfy] WebMycéA pplication\n\n& Connected Services\n\nen Dependencies\nJ Properties", '\n\n& wwwre\n\nControllers\nData\nModels\nDockerfile\nProgram.cs\nStartup.cs\n4+@? docker-compose\n[4 .dockerignore\nb +05 docker-compose.yml\n\nFigure 4-33. Docker files in Solution Explorer in Visual Studio\nIf docker-compose.yml already exists, Visual Studio just adds the required lines of configuration code\n\nto it.\n\nConfigure Docker tools\n\nFrom the main menu, choose Tools > Options, and expand Container Tools > Settings. The\ncontainer tools settings appear.', '\n\n55 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nOptions ? x\n\nSearch Options (Ctrl+E) PP ™ General\n> Azure Service Authentication A Prompt me ~\n4 Container Tools Start Docker Desktop if needed Always\n\nGeneral Trust ASP.NET Core SSL certificate | Prompt me\n\nSingle Project\nContainers Tool Window\nDocker Compose\n\n> Cross Platform\n\n> Database Tools\n\n> F# Tools\n\n> Intellicode\n\n> Kubernetes Debugging Tools\n\n>', ' Live Share\n\n> NuGet Package Manager\n\n> Service Fabric Tools\n\n> SQL Server Tools\n\n> Test Install Docker Desktop if needed\n> Text Templating Install Docker Desktop if needed\n> Web Forms Designer v\n\nFigure 4-34. Docker Tools Options\nFor more detailed configurations refer to Container Tools settings\nTip\n\nFor further details on the services implementation and use of Visual Studio Tools for Docker, read the\nfollowing articles:\n\nUse the Containers tool', ' window to view container details such as the filesystem, logs, environment,\nports, and more: https://learn.microsoft.com/visualstudio/containers/view-and-diagnose-containers\n\nDebug apps in a local Docker container: https://learn.microsoft.com/visualstudio/containers/edit-and-\n\nrefresh\n\nDeploy an ASP.NET container to a container registry using Visual Studio:\nhttps://learn.microsoft.com/visualstudio/containers/hosting-web-apps-in-docker\n\nUsing Win', 'dows PowerShell commands in a\nDockerFile to set up Windows Containers (Docker\nstandard based)\n\nWith Windows Containers, you can convert your existing Windows applications to Docker images and\ndeploy them with the same tools as the rest of the Docker ecosystem.\n\n56 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nTo use Windows Containers, you just need to write Windows PowerShell commands in the DockerFile,', '\nas demonstrated in the following example:\n\nFROM mcr.microsoft.com/windows/servercore: 1tsc2019\nLABEL Description="IIS" Vendor="Microsoft" Version="10"\nRUN powershell Get-WindowsFeature web-server\n\nRUN powershell Install-windowsfeature web-server\nRUN powershell add-windowsfeature web-asp-net45\nCMD [ "ping", "localhost", "-t" ]\n\nIn this case, we\'re using Windows PowerShell to install a Windows Server Core base image as well\nas IIS.\n\nIn a similar w', "ay, you also could use Windows PowerShell commands to set up additional components\nlike the traditional ASP.NET 4.x and .NET Framework 4.6 or any other Windows software, as shown\nhere:\n\nRUN powershell add-windowsfeature web-asp-net45\n\nBuild ASP.NET Core applications deployed as Linux\ncontainers into an AKS/Kubernetes orchestrator\n\nAzure Kubernetes Services (AKS) is Azure's managed Kubernetes orchestrations services that simplify\ncontainer deploym", 'ent and management.\n\nThe main features of AKS are:\n\n. An Azure-hosted control plane.\n\n. Automated upgrades.\n\n. Self-healing.\n\n. User-configurable scaling.\n\n. Simpler user experience for both developers and cluster operators.\n\nThe following examples explore the creation of an ASP.NET Core 6.0 application that runs on Linux\nand deploys to an AKS Cluster in Azure. Development is done using Visual Studio 2022 version 17.0.\n\nCreating the ASP.NET Core ', "Project using Visual Studio 2022\n\nASP.NET Core is a general-purpose development platform maintained by Microsoft and the .NET\ncommunity on GitHub. It's cross-platform, supporting Windows, macOS and Linux, and can be used in\ndevice, cloud, and embedded/IoT scenarios.\n\nThis example uses a couple of simple projects based on Visual Studio templates, so you don’t need\nmuch additional knowledge to create the sample. You only have to create the project ", 'using a\nstandard template that includes all the elements to run a small project with a REST API and a Web\nApp with Razor pages, using ASP.NET Core 6.0 technology.\n\nFor reference, you can download the sample from .NET Application Architecture’s repo explore-\ndocker.\n\n57 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nRecent project templates All languages All platforms\n\n| ASP.NET Core Web API\n\n[=o] ASP.NET ', 'Core Web API\nA project template for creating an ASP.NET Core application with an example\n\n2) ASP.NET Core Web App Controller for a RESTful HTTP service. This template can also be used for ASP.NET\nCore MVC Views and Controllers.\n\n\\J ASP.NET Core Empty C# Linux macOS Windows Cloud Service Web\nASP.NET Core gRPC Service\nA project template for creating a gRPC ASP.NET Core service.\nC# Linux macOS Windows Cloud Service Web\nASP.NET Core with Angular\nA pr', 'oject template for creating an ASP.NET Core application with Angular\nC# Linux macOS Windows Cloud Service Web\nASP.NET Core with Reacts\nA project template for creating an ASP.NET Core application with React.js\n\nC# Linux macOS Windows Cloud Service Web\n\nASP.NET Core with Reactjs and Redux\n\nf NET\n\nFigure 4-35. Creating an ASP.NET Core Web Application in Visual Studio 2022.\n\nTo create the sample project in Visual Studio, select File > New > Project, ', 'select the Web project\ntype and then the ASP.NET Core Web Api template. You can also search for the template if you need\nit.\n\nThen enter the application name and location as shown in the next image.\n\n58 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nConfigure your new project\n\nASP.NET Core Web API C# Linux macOS Windows Cloud Service Web WebAPI\nProject name\n\nWebApi\nLocation\n\nC:\\src\\explore-docker\n\nSolutio', "n name @\n\nexplore-docker\n\nPlace solution and project in the same directory\n\nFigure 4-36. Enter the project name and location in Visual Studio 2022.\n\nVerify that you've selected ASP.NET Core 6.0 as the framework. .NET 6 is included in the latest release\nof Visual Studio 2022 and is automatically installed and configured for you when you install Visual\nStudio.\nAdditional information\n\nASP.NET Core Web API C# Linux = macOS Windows Cloud Service Web\nF", "ramework @\n\n-NET 6.0 (Long-term support)\nAuthentication type @\n\nNone\n\n|¥] Configure for HTTPS @\n|_| Enable Docker @\n@\n\n|v] Use controllers (uncheck to use minimal APIs) @\n\n|v] Enable OpenAPI support @\n\nCreate\n\nFigure 4-37. Selecting ASP.NET CORE 6.0 and Web API project type\n\nNotice Docker support is not enabled now. You'll do that in the next step after the project creation.\nYou'll also notice that by default controller option is checked. You can", " uncheck that if you want to\n\nTo show you can “Dockerize” your project at any time, you'll add Docker support now. So right-click\non the project node in Solution Explorer and select Add > Docker support on the context menu.\na i |ty|- & =\n\nSolution 'explore-docker' (1 of 1 project)\nF\n\nare\n\nBuild\nRebuild\n\nPublish...\n\nCleanup Selected Code\nCollapse Recursively\n\nPower Commands\nOverview\n\nScope to This\n\nNew Solution Explorer View\nFile Nesting\n\nEdit Pro", 'ject File\n\nNew Iter... Ctrl+Shift+A Add\nExisting Item... Shift+Alt+A Manage NuGet Packages...\n\nNew Scaffolded Item... ‘ Manage Client-Side Libraries...\n\nNew Folder Manage User Secrets\n\nhe\n_\n\nApplication Insights Telemetry... Set as Startup Project\nJebuc\nContainer Orchestrator Support... , ebug\n\nDocker Support... Cut\n\nFigure 4-38. Adding Docker support to an existing project\n\nTo complete adding Docker support, you can choose Windows or Linux. In t', 'his case, select Linux.\n\nDocker File Options om\n\nTarget O%:\n(®) Linux\n\nC) Windows\n\nox\n\nFigure 4-39. Selecting Linux containers.\nWith these simple steps, you have your ASP.NET Core 6.0 application running on a Linux container.\n\nIn a similar way, you can also add a very simple WebApp project (Figure 4-40) to consume the web\nAPI endpoint, although the details can be seen in the code\n\nAfter that, you add orchestrator support for your WebApi project a', 's shown next, in image 4-40.\n\nBuild\n\nRebuild\n\nClean\n\nAnalyze and Code Cleanup\nPack\n\nPublish...\n\nCleanup Selected Code\n\nPower Commands\nOverview\nScope to This\nNew Solution Explorer View\nFile Nesting\nEdit Project File\nBuild Dependencies\nNew Item... Ctrl+Shift+A Add\nExisting Item... Shift+Alt+A Manage NuGet Packages...\nNew Scatfolded ltern... S Manage Client-Side Libraries...\n\n| EW F o | d Er Mi ana q E Ls er Secrets\n\nApplication Insights Telemetry..', ". Set as Startup Project\n\nDebug\n\nContainer Orchestrator Support...\n\nDocker Support... Source Control\n\nFigure 4-40. Adding orchestrator support to WebApi project.\n\nWhen you choose the Docker Compose option, which is fine for local development, Visual Studio\nadds the docker-compose project, with the docker-compose files as shown in image 4-41.\nSolution Explorer\n\nSolution 'explore-docker' (3 of 3 projects)\nSrc\n> fy] WebApi\n4d +o docker-compose\n[) .d", 'ockerignore\n4+") docker-compose.ym\nL) docker-compose.override\n\nFigure 4-4]. Adding orchestrator support to WebApi project.\n\nThe initial files added are similar to these ones:\ndocker-compose.yml\nversion: "3.4"\n\nservices:\nwebapi:\nimage: ${DOCKER_REGISTRY- }webapi\nbuild:\ncontext:\ndockerfile: WebApi/Dockerfile\n\nwebapp:\nimage: ${DOCKER_REGISTRY- }webapp\nbuild:\ncontext:\ndockerfile: WebApp/Dockerfile\n\ndocker-compose.override.yml\n\nversion: "3.4"\n\nservice', 's:\nwebapi:\nenvironment:\n- ASPNETCORE_ENVIRONMENT=Development\n- ASPNETCORE_URLS=https://+:443;http://+:80\nports:\n- "8Q"\n- "443"\nvolumes:\n- ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro\n- £${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro\nwebapp:\nenvironment:\n- ASPNETCORE_ENVIRONMENT=Development\n- ASPNETCORE_URLS=https://+:443;http://+:80\nports:\n- "8Q"\n- "443"\n\n63 CHAPTER 4 | Designing and developing containerized apps using Docker', ' and Microsoft Azure\nvolumes:\n- ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro\n- £${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro\n\nTo run your app with Docker Compose, you just have to make a few tweaks to docker-\ncompose.override.yml.\n\nservices:\nwebapi:\n#...\nports:\n- "51080:80"\n- "51443 :443"\n#...\nwebapp:\nenvironment:\n#...\n- WebApiBaseAddress=http: //webapi\nports:\n- "50080: 80"\n- "50443 :443"\n\nNow you can run your application w', 'ith the F5 key, or by using the Play button, or the Ctrl+F5 key,\nselecting the docker-compose project, as shown in image 4-42.\n\nD DEBUG TEST ANALYZE TOOLS EXTENSIONS WINDOW HELP\n\nDebug ~ Any CPU ~ docker-compose llocker Compose ~\n\nFigure 4-42. Adding orchestrator support to WebApi project.\n\nWhen running the docker-compose application as explained, you get:\n\n1. The images built and containers created as per the docker-compose file.\n\n2. The browser', ' open in the address configured in the “Properties” dialog for the docker-\ncompose project.\n\n3. | The Container window open (in Visual Studio 2022 version 17.0 and later).\n\n4. Debugger support for all projects in the solution, as shown in the following images.\n\nBrowser opened:\n\n64 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n| Weather Forecast - WebApp x\n\n€ O fh\n\n|) https://localhost:50443/weatherforeca', 'st Ve Y {=} m G Oo oO y= fot g “oO\n\nWebApp Home Privacy\n\nWeather Forecast\n\nData from: http://webapi/WeatherForecast\n\nDate °C ad Summary\n2020-04-23 15:35:35 5 40 Chilly\n2020-04-24 15:35:35 12 53 Sweltering\n2020-04-25 15:35:35 -4 25 Sweltering\n2020-04-26 15:35:35 -7 20 Mild\n2020-04-27 15:35:35 -7 20 Cool\n\nBack to Home page\n\n© 2020 - WebApp - Privacy\n\nFigure 4-43. Browser window with an application running on multiple containers.\n\nContainers window:', '\n\nContainers 4 X\nContainers Images Environment Ports Logs Files\n\non\n\na [EB = Stream Logs\n\n‘C) WebApi\n\n(>) WebApp\n\nde_webapi_1\nwebapp_1\n\nntroller_nginx-ingress-controller-7fcf8df75d-jsj8v_ingress-nc\n\nFigure 4-44. Visual Studio “Containers” window\n\nThe Containers window lets you view running containers, browse available images, view environment\nvariables, logs, and port mappings, inspect the filesystem, attach a debugger, or open a terminal\nwindow ', "inside the container environment.\n\nAs you can see, the integration between Visual Studio 2022 and Docker is completely oriented to the\ndeveloper's productivity.\n\nOf course, you can also list the images using the docker images command. You should see the webapi\nand webapp images with the dev tags created by the automatic deployment of our project with Visual\nStudio 2022.\n\ndocker images\n\n65 CHAPTER 4 | Designing and developing containerized apps us", 'ing Docker and Microsoft Azure\nminutes ago\nminutes ago\nicrosoft.com/dotnet/sdk 5S hours ago\n\nicrosoft.com/dotnet/aspnet\n\nCREATED\n5\n5\n\n5 hours ago\n\nFigure 4-45. View of Docker images\n\nRegister the Solution in an Azure Container Registry (ACR)\n\nYou can upload the images to the Azure Container Registry (ACR), but you could also use Docker Hub\nor any other registry, so the images can be deployed to the AKS cluster from that registry.\n\nCreate an ACR i', "nstance\n\nRun the following command from the az cli:\n\naz acr create --name exploredocker --resource-group explore-docker-aks-rg --sku basic\n--admin-enabled\n\nNote\n\nThe container registry name (for example, exploredocker) must be unique within Azure and contain 5-\n50 alphanumeric characters. For more details, see Create a container registry.\n\nCreate the image in Release mode\nYou'll now create the image in Release mode (ready for production) by chang", "ing to Release, as\nshown in Figure 4-46, and running the application as you did before.\n\nDQ Fle EDIT VIEW PROJECT BUILD DEBUG TEST ANALYZE TOOLS EXTENSIONS WINDOW HELP\n\nTy Debug = Any CPU Docker [a]\n\nDebua\n\nConfiguration Manager...\n\nFigure 4-46. Selecting Release Mode\nIf you execute the docker images command, you'll see both images created, one for debug (dev) and\n\nthe other for release (latest) mode.\n\nCreate a new Tag for the Image\n\nEach contain", 'er image needs to be tagged with the loginServer name of the registry. This tag is used\nfor routing when pushing container images to an image registry.\n\nYou can view the loginServer name from the Azure portal, taking the information from the Azure\nContainer Registry\n\n66 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n“A exploredocker - Microsoft Azure x | +\n\n< oO GC https://portal.azure.com/#@bb9b4755-8a8a', '-4... ¥% ih 90 » mM G OC @ yr for 8 “9\n\nMicrosoft Azure P Search resources, services, and docs (G+/) ly\n\nHome > Microsoft.ContainerRegistry | Overview > exploredocker\n\nGh exploredocker x xX\n\nContainer registry\n\nD Bearch (Ctri+/) « — Move [i] Delete 3 Update\n\n@ Overview Resource group (change)\nexplore-docker-aks-rg\n\nf@ Activity log\nLocation Creation date\n\nPo Access control (IAM) West Europe 22/4/2020 17:36 WEST\nSubscription (change) SKU\n\nTags ee\n6', ' 9 Demo subscription Standard\n® Quick start Subscription ID Provisioning state\nSucceeded\n* Events\n\nFigure 4-47. View of the name of the Registry\n\nOr by running the following command:\n\naz acr list --resource-group <resource-group-name>\n"[ ].{acrLoginServer: loginServer}" --output table\n\nPS: [Miguel]> explore-docker-aks-rg\n\nAcrLoginServer\n\nexploredocker.azurecr.io\n\nFigure 4-48. Get the name of the registry using az cli\n\nIn both cases, you\'ll obtain', ' the name. In our example, exploredocker.azurecr.io.\n\nNow you can tag the image, taking the latest image (the Release image), with the command:\n\ndocker tag <image-name>: latest <login-server-name>/<image-name>:v1\n\nAfter running the docker tag command, list the images with the docker images command, and you\nshould see the image with the new tag.\n\nPS: [Miguel]> images\n\nREPOSITORY TAG IMAGE ID CREATED SIZE\nwebapp latest 11#2a7d7718c 4 minutes 213MB\n', 'exploredocker.azurecr.io/webapp v1 11#2a7d7718c 4 minutes 213MB\n\nwebapi latest db9979d4cfef A minutes 208MB\nexploredocker.azurecr.io/webapi v1 db9979d4cfef 4 minutes 208MB\nwebapp dev cba194e20cb9 About an hour ago 207MB\nwebapi dev ed6ea5466cb4 About an hour ago 207MB\n\nFigure 4-49. View of tagged images\n\nPush the image into the Azure ACR\n\nLog in to the Azure Container Registry\n\naz acr login --name exploredocker\n\nPush the image into the Azure ACR, ', 'using the following command:\n\ndocker push <login-server-name>/<image-name>:v1\n\n67 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nThis command takes a while uploading the images but gives you feedback in the process. In the\nfollowing image, you can see the output from one image completed and another in progress.\n\nPS: [Miguel ]> push exploredocker.azurecr.io/webapi:v1\n\nThe push refers to repository [explore', 'docker.azurecr.io/webapi |\n\n35e6bc6eeb8d: Pushed\n\n1754f2ec3ala: Pushed\n\n8957624a4d9d: Pushed\n\nb21b@b2df887: Pushed\n\n77362d5ab4dc: Pushed\n\n974ff534c026: Pushed\n\nb6GeS5c3bcef2: Pushed\n\nvil: digest: sha256:0f9415358734702a89084b8461eed3c50047c5c347093c311leb&d32d15ad@fda size: 1791\nPS: [Miguel ]> push exploredocker.azurecr.io/webapp:v1\n\nThe push refers to repository [exploredocker.azurecr.io/webapp ]\n\n33e7f8019853: Pushing [ .322MB\n1754f2ec3ala: Pre', 'paring\n\n8957624a4d9d: Preparing\n\nb21b@b2df887: Preparing\n\n77362d5ab4dc: Preparing\n\n974f*534c026: Waitingng\n\nb6Ge5c3bcef2: Waiting\n\nFigure 4-50. Console output from the push command.\n\nTo deploy your multi-container app into your AKS cluster you need some manifest .yaml files that\nhave, most of the properties taken from the docker-compose.yml and docker-compose.override.yml\nfiles.\n\ndeploy-webapi.yml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nn', 'ame: webapi\nlabels:\napp: weather-forecast\nspec:\nreplicas: 1\nselector:\nmatchLabels:\nservice: webapi\ntemplate:\nmetadata:\nlabels:\napp: weather-forecast\nservice: webapi\nspec:\ncontainers:\n- name: webapi\nimage: exploredocker.azurecr.io/webapi:v1\nimagePullPolicy: IfNotPresent\nports:\n- containerPort: 80\nprotocol: TCP\nenv:\n- name: ASPNETCORE_URLS\nvalue: http://+:80\n\n68 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azur', 'e\napiVersion: v1\nkind: Service\nmetadata:\nname: webapi\nlabels:\napp: weather-forecast\nservice: webapi\nspec:\nports:\n- port: 80\ntargetPort: 80\nprotocol: TCP\nselector:\nservice: webapi\ndeploy-webapp. yml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: webapp\nlabels:\napp: weather-forecast\nspec:\nreplicas: 1\nselector:\nmatchLabels:\nservice: webapp\ntemplate:\nmetadata:\nlabels:\napp: weather-forecast\nservice: webapp\nspec:\ncontainers:\n- name: webapp\nimage:', ' exploredocker.azurecr.io/webapp:v1\nimagePullPolicy: IfNotPresent\nports:\n- containerPort: 8@\nprotocol: TCP\nenv:\n- name: ASPNETCORE_URLS\nvalue: http://+:80\n- name: WebApiBaseAddress\nvalue: http://webapi\napiVersion: v1\nkind: Service\nmetadata:\nname: webapp\nlabels:\napp: weather-forecast\nservice: webapp\nspec:\ntype: LoadBalancer\nports:\n- port: 80\ntargetPort: 80\nprotocol: TCP\nselector:\nservice: webapp\n\n69 CHAPTER 4 | Designing and developing containeriz', "ed apps using Docker and Microsoft Azure\nNote\n\nThe previous .yml files only enable the HTTP ports, using the ASPNETCORE_URLS parameter, to avoid\nissues with the missing certificate in the sample app.\n\nTip\n\nYou can see how to create the AKS Cluster for this sample in section Deploy to Azure Kubernetes\nService (AKS) on this guide.\n\nNow you're almost ready to deploy using kubectl, but first you must get the credentials from the AKS\nCluster with this", ' command:\n\nPS: [Miguel]> aks get-credentials explore-docker-aks-rg exp lore-docker-aks\n\nMerged "“explore-docker-aks" as current context in C:\\Users\\Miguel\\.kube\\config\n\nFigure 4-51. Getting credentials from AKS into the kubectl environment.\n\nYou also have to allow the AKS cluster to pull images from the ACR, using this command:\n\naz aks update --name explore-docker-aks --resource-group explore-docker-aks-rg --attach-acr\nexploredocker\n\nThe previous', ' command might take a couple of minutes to complete. Then, use the kubectl apply\ncommand to launch the deployments, and then kubectl get all to list the cluster objects.\n\nkubectl apply -f deploy-webapi.yml\nkubectl apply -f deploy-webapp.yml\n\nkubectl get all\n\n70 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nPS: [Miguel]>kubectl apply deploy-webapi.yml\n\ndeployment.apps/webapi created\n\nservice/webapi create', 'd\n\nPS: [Miguel]>kubectl apply deploy-webapp. yml\n\ndeployment.apps/webapp created\n\nservice/webapp created\n\nPS: [Miguel]>kubectl get all\n\nNAME READY STATUS RESTARTS AGE\npod/webapi-67646/7cfc&-wqge5s a/1 ContainerCreating 8 15s\npod/webapp-56cfc/fdb5-cnxsd a/1 ContainerCreating 8 7s\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(5) AGE\nservice/kubernetes ClusterIP 16.6.0.1 <none> AA3/TCP Ah33m\nservice/webapi ClusterIP 16.6.97.189 ‘ p> 80/TCP 15s\nservice/weba', "pp LoadBalancer 10.0.74.46 ‘pending> 86:31349/TCP 7s\n\nNAME READY UP-TO-DATE AVATLABLE AGE\ndeployment.apps/webapi 8/1 1 8 15s\ndeployment.apps/webapp e/1 1 8 7s\n\nNAME DESTRED CURRENT READY\nreplicaset.apps/webapi-6/7646/cfc8 1 1 ‘\n\nreplicaset.apps/webapp-56cfc/fdb5 1 1\n\nFigure 4-52. Deployment to Kubernetes\n\nYou'll have to wait a while until the load balancer gets the external IP, checking with kubectl get\nservices, and then the application should b", 'e available at that address, as shown in the next image:\n\n71 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n= oO x\n| Weather Forecast - WebApp x P+\n\n< Oo tf @ Not secure | 13.95.149.3/WeatherForecast i B® Vv m © O QB y= for 8\n\nWebApp Home Privacy\n\nWeather Forecast\n\nData from: http://webapi/WeatherForecast\n\nDate °C id Summary\n2020-04-24 12:04:18 -11 13 Mild\n2020-04-25 12:04:18 45 112 Sweltering\n2020-04-26 ', '12:04:18 -9 16 Bracing\n2020-04-27 12:04:18 49 120 Cool\n2020-04-28 12:04:18 54 129 Warm\n\nBack to Home page\n\n© 2020 - WebApp - Privacy\n\nFigure 4-53. Deployment to Kubernetes\n\nWhen the deployment completes, you can access the Kubernetes Web UI with a local proxy, using an\nssh tunnel.\n\nFirst you must create a ClusterRoleBinding with the following command:\n\nkubectl create clusterrolebinding kubernetes-dashboard --clusterrole=cluster-admin --\n\nservicea', 'ccount=kube-system: kubernetes-dashboard\n\nAnd then this command to start the proxy:\n\naz aks browse --resource-group exploredocker-aks-rg --name explore-docker-aks\n\nA browser window should open at http://127.0.0.1:8001 with a view similar to this one:\n\n72 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\n| Weather Forecast - WebApp x | © Overview - Kubernetes Dashbos X | =F\n\n€ O tf @ > 127.0.0.1:8001/api/v1/n', 'amespaces/kube-sy.. % HJ OU «& m Oo @ I for g\nkubernetes Q__ Search + CREATE\n= Overview\nCluster Workloads\n\nNamespaces\n\nNodes Workloads Statuses\n\nPersistent Volumes\nRoles\n\nStorage Classes\n\nNamespace\n\ndefault ~¥ Deployments Pods Replica Sets\n\nOverview\n\nDeployments =\n\nWorkloads\nCron Jobs Name + Labels Pods Age + Images\nDaemon Sets g webapp app: weather-forecas 1/1 20 minutes exploredocker.azure... :\nDeployments .\ng webapi app: weather-forecas 1/1 20', ' minutes exploredocker.azure... :\nJobs\nPods\nPods =\nReplica Sets\nReplication Controllers Name + Node Status * Restarts Age +\n\nStateful Sets aks-nodepool1-\n\n@ _webapp-56cfc7fdb5-cnxsd 41297266-0\n\nRunning 0 20 minutes\n\nDiscovery and Load Balancing\naks-nodepool1-\n\ng webapi-676467cfc8-wqg5s 41297266-0\n\nRunning 0 20 minutes\n\nIngresses\n\nFigure 4-54. View Kubernetes cluster information\n\nNow you have your ASP.NET Core application, running in Linux contain', 'ers, and deployed to an AKS\ncluster on Azure.\n\nNote\n\nFor more information on deployment with Kubernetes see:\n\nhttps://kubernetes.io/docs/reference/kubectl/cheatsheet/\n\n73 CHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\nCHAPTER\n\nDocker application\nDevOps worktlow with\nMicrosott tools\n\nMicrosoft Visual Studio, Azure DevOps Services and/or GitHub, Team Foundation Server, and Azure\nMonitor provide a comprehens', 'ive ecosystem for development and IT operations that give your team the\ntools to manage projects and rapidly build, test, and deploy containerized applications.\n\nTeams can choose which tools and platforms they want to use for end to end DevOps. With Visual\nStudio and Azure DevOps Services in the cloud, along with Team Foundation Server on-premises,\ndevelopment teams can productively build, test, and release containerized applications that target\n', 'either Windows or Linux. Alternatively, teams can also use Visual Studio Code and GitHub. Teams can\neven use combinations: for example, storing source code in GitHub and using Azure Boards for work\nitem tracking and Azure Pipelines for CI/CD.\n\nMicrosoft tools can automate the pipeline for specific implementations of containerized\napplications—Docker, .NET, or any combination with other platforms—from global builds and\nContinuous Integration (Cl) ', 'and tests with Azure DevOps Services, Team Foundation Server or GitHub,\nto Continuous Deployment (CD) to Docker environments (Development, Staging, Production), and to\ntransmit analytics information about the services to the development team through Azure Monitor.\nEvery code commit can initiate a build (Cl) and automatically deploy the services to specific\ncontainerized environments (CD).\n\nDevelopers and testers can easily and quickly provision p', 'roduction-like development and test\nenvironments based on Docker by using templates in Microsoft Azure.\n\nThe complexity of containerized application development increases steadily depending on the\nbusiness complexity and scalability needs. A good example of this complexity are applications based\non microservices architectures. To succeed in such an environment, your project must automate the\nentire life cycle—not only the build and deployment, bu', 't it also must manage versions along with\nthe collection of telemetry. Azure DevOps Services, GitHub and Azure offer the following capabilities:\n\n. Azure DevOps Services/Team Foundation Server source code management (based on Git or\nTeam Foundation Version Control), Agile planning (Agile, Scrum, and CMMI are supported),\nCl, release management, and other tools for Agile teams.\n\n74 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools', '\n. Azure DevOps Services and Team Foundation Server include a powerful and growing\necosystem of first and third-party extensions with which you easily can construct a Cl, build,\ntest, delivery, and release management pipeline for microservices.\n\n. GitHub or GitHub Enterprise Server offer similar capabilities, with source control based on Git,\nProjects and Issues for project tracking, GitHub Actions for automating workflows including\nCI/CD, and Gi', 'tHub Advanced Security for dependency, secret and vulnerability scanning.\n\n. Run automated tests as part of your build pipeline in Azure DevOps Services or through\nGitHub Actions\n\n. Azure DevOps Services/GitHub can tighten the DevOps life cycle with delivery to multiple\nenvironments, not just for production environments, but also for testing, including A/B\nexperimentation, canary releases, and so on.\n\n. Organizations easily can provision Docker c', "ontainers from private images stored in Azure\nContainer Registry along with any dependency on Azure components (Data, PaaS, etc.) using\nAzure Resource Manager templates with tools they're already comfortable with.\n\nSteps in the outer-loop DevOps workflow for a\nDocker application\n\nFigure 5-1 presents an end-to-end depiction of the steps comprising the DevOps outer-loop\nworkflow. It shows the “outer loop” of DevOps. When code is pushed to the repo,", ' a Cl pipeline is\nstarted, then begins the CD pipeline, where the application gets deployed. Metrics collected from\ndeployed applications are fed back into the development workload, where the “inner loop” occurs, so\ndevelopment teams have actual data to respond to user and business needs.\n\nong\n\nContainer Service\n\nService Fabric\n\nad\n\nApp Services\n\ndocker push ‘Ss\n\nAzure\nContainer\nRegistry\nAzure Key\nVault Outer\nLoop\n\niN\n\nDev Environment\n\nFigure 5-1', ". DevOps outer-loop workflow for Docker applications with Microsoft tools\n\nNow, let's examine each of these steps in greater detail.\n\n15 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nStep 1: Inner-loop development workflow\n\nThis step is explained in detail in Chapter 4, but, to recap, here is where the outer-loop begins, the\nmoment at which a developer pushes code to the source control management system (like Git)\ninitiating", " Cl pipeline actions.\n\nStep 2: Source-Code Control integration and management with Azure\nDevOps Services and Git\n\nAt this step, you need to have a version-control system to gather a consolidated version of all the\ncode coming from the different developers in the team.\n\nEven though source-code control (SCC) and source-code management might seem second-nature to\nmost developers, when creating Docker applications in a DevOps life cycle, it's critica", "l to emphasize\nthat you must not submit the Docker images with the application directly to the global Docker\nRegistry (like Azure Container Registry or Docker Hub) from the developer's machine. On the contrary,\nthe Docker images to be released and deployed to production environments must be created solely\non the source code that's being integrated in your global build or Cl pipeline based on your source-\ncode repository (like Git).\n\nThe local ima", "ges, generated by developers, should just be used by them when testing within their\nown machines. That's why it's critical to have the DevOps pipeline activated from the SCC code.\n\nAzure DevOps Services and Team Foundation Server support Git and Team Foundation Version\nControl. You can choose between them and use it for an end-to-end Microsoft experience. However,\nyou can also manage your code in external repositories (like GitHub, on-premises Gi", 't repositories, or\nSubversion) and still be able to connect to it and get the code as the starting point for your DevOps Cl\npipeline. You can also use GitHub Actions for CI/CD pipelines.\n\nStep 3: Build, Cl, Integrate, and Test with Azure DevOps\nServices/GitHub and Docker\n\nCl has emerged as a standard for modern software testing and delivery. The Docker solution\nmaintains a clear separation of concerns between the development and operations teams.', " The\nimmutability of Docker images ensures a repeatable deployment between what's developed, tested\nthrough Cl, and run in production. Docker Engine deployed across the developer laptops and test\ninfrastructure makes the containers portable across environments.\n\nAt this point, after you have a version-control system with the correct code submitted, you need a\nbuild service to pick up the code and run the global build and tests.\n\nThe internal work", 'flow for this step (Cl, build, test) is about the construction of a Cl pipeline consisting\nof your code repository (Git, etc.), your build server (Azure DevOps Services/GitHub), Docker Engine,\nand a Docker Registry.\n\nYou can use Azure DevOps Services as the foundation for building your applications and setting your\nCl pipeline, and for publishing the built “artifacts” to an “artifacts repository,” which is explained in the\nnext step. Alternativel', 'y, you can use GitHub to implement the same workflow.\n\n76 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nWhen using Docker for the deployment, the “final artifacts” to be deployed are Docker images with\nyour application or services embedded within them. Those images are pushed or published to a\nDocker Registry (a private repository like the ones you can have in Azure Container Registry, or a\npublic one like Docker Hub Registr', 'y or GitHub Container Registry, which is commonly used for official\nbase images).\n\nHere is the basic concept: The Cl pipeline will be kicked-off by a commit to an SCC repository like Git.\nThe commit will cause Azure DevOps Services/GitHub to run a build job within a Docker container\nand, upon successful completion of that job, push a Docker image to the Docker Registry, as\nillustrated in Figure 5-2. The first part of the outer loop involves steps', ' 1 to 3, from code, run, debug\nand validate, then the code repo up to the build and test Cl step.\n\ndocker\n\nAzure\nContainer\nRegistry\n\nAzure Key\nVault\n\nDev Environment\n\nFigure 5-2. The steps involved in Cl\n\nHere are the basic Cl workflow steps with Docker and Azure DevOps Services:\n\n77 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\n1. | The developer pushes a commit to an SCC repository (Git/Azure DevOps Services, GitHub,\netc.)', ".\n\n2. If you’re using Azure DevOps Services or Git, Cl is built in, which means that it's as simple as\nselecting a check box in Azure DevOps Services. If you're using an external SCC (like GitHub),\na webhook will notify Azure DevOps Services of the update or push to Git/GitHub.\n\n3. Azure DevOps Services pulls the SCC repository, including the Dockerfile describing the\nimage, as well as the application and test code.\n\n4. Azure DevOps Services buil", 'ds a Docker image and labels it with a build number.\n\n5. Azure DevOps Services instantiates the Docker container within the provisioned Docker Host,\nand runs the appropriate tests.\n\n6. If the tests are successful, the image is first relabeled to a meaningful name so that you know\nit\'s a “blessed build” (like “/1.0.0" or any other label), and then pushed up to your Docker\nRegistry (Docker Hub, Azure Container Registry, DTR, etc.)\n\nHere are the bas', 'ic Cl workflow steps with Docker and GitHub:\n\nThe developer pushes a commit to a GitHub repo.\nCl is built in, so Actions will trigger base on the event filters.\n\nGitHub pulls the SCC repository, including the Dockerfile describing the image, as well as the\napplication and test code.\n\n4. GitHub builds a Docker image and labels it with a build number.\nGitHub instantiates the Docker container within the provisioned Docker Host, and runs the\nappropri', 'ate tests.\n\n6. If the tests are successful, the image is first relabeled to a meaningful name so that you know\nit\'s a “blessed build” (like “/1.0.0" or any other label), and then pushed up to your Docker\nRegistry (Docker Hub, Azure Container Registry, DTR, etc.)\n\nImplement a Cl pipeline with Azure DevOps Services and the Docker extension for\nAzure DevOps Services\n\nVisual Studio Azure DevOps Services contains Build & Release Templates that you can', ' use in your\nCI/CD pipeline with which you can build Docker images, push Docker images to an authenticated\nDocker registry, run Docker images, or run other operations offered by the Docker CLI. It also adds a\nDocker Compose task that you can use to build, push, and run multi-container Docker applications, or\nrun other operations offered by the Docker Compose CLI, as shown in Figure 5-3.\n\n78 CHAPTER 5 | Docker application DevOps workflow with Micr', 'osoft tools\n09 BikeSharing360 Y Home Code\n\nBuilds Releases Task Groups Explorer\n\nBuild Definitions / Multicontainer Build\n\nBuild Options Repository Variables Triggers General\nirae\n\n+ Add build step...\nRun a specific service x\n; eect Docker Compose\n\nRun a specific service\nsce ~=Docker Compose\n\nBuild services\nsoceey Docker Compose\n\nPublish Test Results **/TEST-*.xml\nPublish Test Results\n\nPush services\nsce ~=Docker Compose\n\nWrite service image diges', 'ts\nwe Docker Compose\n\nCombine configuration\nsocter ~=Docker Compose\n\nCopy Files to: $(Build.StagingDirectory)\nCopy Files\n\n+ Publish Artifact: docker-compose\nPublish Build Artifacts\n\nFigure 5-3. The Docker Cl pipeline in Azure DevOps Services including Build & Release Templates and associated tasks.\n\nYou can use these templates and tasks to construct your CI/CD artifacts to Build / Test and Deploy in\nAzure Service Fabric, Azure Kubernetes Service,', ' and similar offerings.\n\nWith these Visual Studio Team Services tasks, a build Linux-Docker Host/VM provisioned in Azure and\nyour preferred Docker registry (Azure Container Registry, Docker Hub, private Docker DTR, or any\nother Docker registry) you can assemble your Docker Cl pipeline in a very consistent way.\n\nRequirements:\n\n. Azure DevOps Services, or for on-premises installations, Team Foundation Server 2015\nUpdate 3 or later.\n\n. An Azure DevO', 'ps Services agent that has the Docker binaries.\n\nAn easy way to create one of these agents is to use Docker to run a container based on the\nAzure DevOps Services agent Docker image.\n\nTip\n\nTo read more about assembling an Azure DevOps Services Docker Cl pipeline and view the\nwalkthroughs, visit these sites:\n\n. Running a Visual Studio Team Services (Now Azure DevOps Services) agent as a Docker\ncontainer:\nhttps://hub.docker.com/ /microsoft-azure-pip', 'elines-vsts-agent\n\n79 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\n° Building .NET Linux Docker images with Azure DevOps Services:\nhttps://learn.microsoft.com/archive/blogs/stevelasker/building-net-core-linux-docker-\n\nimages-with-visual-studio-team-services\n\n. Building a Linux-based Visual Studio Team Service build machine with Docker support:\nhttps://www.donovanbrown.com/post/Building-a-Linux-Based-Visual-Studio-Team-Servi', 'ce-\n\nBuild-Machine-with-Docker-Support\n\nImplement a Cl pipeline with GitHub Actions\n\nGitHub Actions allow you to create automation scripts that can build Docker images, push Docker\nimages to an authenticated Docker registry, run Docker images, or run other operations offered by\nthe Docker CLI.\n\nYou can use public Actions (such as Azure Login) and run (shell) commands to construct your Cl/CD\nartifacts to Build / Test and Deploy in Azure Service Fa', 'bric, Azure Kubernetes Service, and similar\nofferings.\n\nWith these Actions, a build Linux-Docker Host/VM provisioned in Azure and your preferred Docker\nregistry (Azure Container Registry, Docker Hub, private Docker DTR, or any other Docker registry) you\ncan assemble your Docker Cl pipeline in a very consistent way.\n\nIntegrate, test, and validate multi-container Docker applications\n\nTypically, most Docker applications are composed of multiple cont', "ainers rather than a single\ncontainer. A good example is a microservices-oriented application for which you would have one\ncontainer per microservice. But, even without strictly following the microservices approach patterns,\nit's probable that your Docker application would be composed of multiple containers or services.\n\nTherefore, after building the application containers in the Cl pipeline, you also need to deploy,\nintegrate, and test the appli", "cation as a whole with all of its containers within an integration Docker\nhost or even into a test cluster to which your containers are distributed.\n\nIf you're using a single host, you can use Docker commands such as docker-compose to build and\ndeploy related containers to test and validate the Docker environment in a single VM. But, if you're\nworking with an orchestrator cluster like DC/OS, Kubernetes, or Docker Swarm, you need to deploy\nyour co", 'ntainers through a different mechanism or orchestrator, depending on your selected\ncluster/scheduler.\n\nThe following are several types of tests that you can run against Docker containers:\n\n. Unit tests for Docker containers\n. Testing groups of interrelated applications or microservices\n. Test in production and “canary” releases\n\nThe important point is that when running integration and functional tests, you must run those tests\nfrom outside of the', " containers. Tests are not contained or run in the containers you're deploying,\nbecause the containers are based on static images that should be exactly like the ones you'll be\ndeploying to production.\n\n80 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nA practical option when testing more advanced scenarios, like including several clusters (test cluster,\nstaging cluster, and production cluster) is to publish the images to a r", "egistry, so it can be tested In\nvarious clusters.\n\nPush the custom application Docker image into your global Docker Registry\n\nAfter the Docker images have been tested and validated, you'll want to tag and publish them to your\nDocker registry. The Docker registry is a critical piece in the Docker application life cycle because it’s\n\nthe central place where you store your custom test (also known as “blessed images”) to be deployed\ninto QA and produ", 'ction environments.\n\nSimilar to how the application code stored in your SCC repository (Git, etc.) is your “source of truth,”\nthe Docker registry is your “source of truth” for your binary application or bits to be deployed to the\nQA or production environments.\n\nTypically, you might want to have your private repositories for your custom images either in a private\n\nrepository in Azure Container Registry or in an on-premises registry like Docker Tru', "sted Registry, or in\na public-cloud registry with restricted access (like Docker Hub), although in this last case if your code\n\nis not open source, you must trust the vendor's security. Either way, the method you use is similar and\nis based on the docker push command, as shown in Figure 5-4.\n\n81 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\ndocker push\n\nAzure\nContainer\nRegistry\n\nAzure Key\nVault\n\nFigure 5-4. Publishing custom", ' images to Docker Registry\n\n82 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nIn step 3, for building integration and testing (Cl) you might publish the resulting docker images to a\nprivate or public registry. There are multiple offerings of Docker registries from cloud vendors like\nAzure Container Registry, Amazon Web Services Container Registry, Google Container Registry,\nGitHub Container Registry, Quay Registry, and so on.', '\n\nUsing the Docker tasks, you can push a set of service images defined by a docker-compose.yml file,\nwith multiple tags, to an authenticated Docker registry (like Azure Container Registry), as shown in\nFigure 5-5.\n\nJ BikeSharing360 Home Code Build & Release\n\nBuilds Releases Task Groups Explorer\n\nBuild Definitions / Multicontainer Build not built —] Summary # Queue newbuild © Security @® Help\n\nBuild : Options : Repository Variables Triggers Genera', 'l Retention History\n\n+ Add build step... Push services #\n\nDocker Registry Connection . .\nRun a specific service gis") bikesharingtest YG Manage ©\n\nDocker Compose\n\nDocker Compose File **/docker-compose.yml ©\n\nRun a specific service\nDocker Compose\n\naeatons Docker Compose docker-compose.ci.yml >\niles\n\nBuild services\n\nA Docker Compose Environment Variables\n©\nPublish Test Results **/TEST-*.xml\nul Publish Test Results Project Name $(Build.Repository.Na', 'me)\nf ve Push services Qualify Image Names\n% eocter Docker Compose x Acti\n53 ction . ‘\n. Push service images Vv\nWrite service image digests -. .\n+ Docker Compose Additional Image Tags $(Build.Buildid) >\n$(Build.SourceBranchName)\n+ Soe ee commguration Include Source Tags ©\nInclude Latest Tag ©\n\nCopy Files to: $(Build.StagingDirectory)\n\nCopy Files » Advanced Options\n\nPublish Artifact: docker-compose\n\nPublish Build Artifacts 4 Contro! Options\n\nFigur', "e 5-5. Using Azure DevOps Services to publishing custom images to a Docker Registry\n\nTip\n\nFor more information about Azure Container Registry, see https://aka.ms/azurecontainerregistry.\n\nStep 4: CD, Deploy\n\nThe immutability of Docker images ensures a repeatable deployment with what's developed, tested\nthrough Cl, and run in production. After you have the application Docker images published in your\nDocker registry (either private or public), you c", "an deploy them to the several environments that you\nmight have (production, QA, staging, etc.) from your CD pipeline by using Azure DevOps Services\npipeline tasks, Azure DevOps Services Release Management or GitHub Actions.\n\n83 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nHowever, at this point it depends on what kind of Docker application you're deploying. Deploying a\nsimple application (from a composition and deployment p", "oint of view) like a monolithic application\ncomprising a few containers or services and deployed to a few servers or VMs is different from\ndeploying a more complex application like a microservices-oriented application with hyperscale\ncapabilities. These two scenarios are explained in the following sections.\n\nDeploying composed Docker applications to multiple Docker environments\n\nLet's look first at the less-complex scenario: deploying to simple D", 'ocker hosts (VMs or servers) in a\nsingle environment or multiple environments (QA, staging, and production). In this scenario, internally\nyour CD pipeline can use docker-compose (from your Azure DevOps Services deployment tasks) to\ndeploy the Docker applications with its related set of containers or services, as illustrated in Figure 5-6.\n\n4 C\ni ; Host\n(VM/Server)\nStaging 6\n# , Host\n(VM/Server)\nProduction 6\n# , Host\n(VM/Server)\n\nFigure 5-7 highli', "ghts how you can connect your build Cl to QA/test environments via Azure DevOps\nServices by clicking Docker Compose in the Add Task dialog box. However, when deploying to staging\nor production environments, you would usually use Release Management features handling multiple\nenvironments (like QA, staging, and production). If you're deploying to single Docker hosts, it is using\nthe Azure DevOps Services “Docker Compose” task (which is invoking the", " docker-compose up\ncommand under the hood). If you're deploying to Azure Kubernetes Service (AKS), it uses the Docker\n\nAzure\nContainer\nRegistry\n\nDocker\nRegistry\n\nFigure 5-6. Deploying application containers to simple Docker host environments registry\n\n84 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nDeployment task, as explained in the section that follows. Similar steps can be built for deployment\nusing GitHub Actions.\n\nMI ", 'cop \\ TES x\nDefinitions Explorer Add tasks |\nBuild Definitions / Plain Build ¢ Azurenivi WED App Vepioyment\n\nAll Deploy the web project to the AzureRM Web App Add A\nBuild Iptions Repository Variables using Web Deploy\nBuild\nLs Utility Create Octopus Release\na Create a Release in Octopus Deploy Add\nTest\nF Add build step. Package Deploy Octopus Release\na] ploy ?\nDeploy Deploy an Octopus Deploy Release Add\ni) NuGet restore **\\*.sIn Docker Compose\nNuc', 'er ineiier + Define and run multi-container applications with\n- q Docker Compose\nog Build solution **\\*.sIn\nVisual Studio Build HockeyApp\nTest Assemblies **\\$(BuildCc ee alpha and beta builds of mobile apps to Add\nVisual Studio Test eee\n= Publish syn bols path PowerShell on Target Machines\n4 fm $ : ‘ nae ra ee - ™ Add\not Index Sources & Publish Symbols | 2 | Execute PowerShell scripts on remote machine(s)\nCopy Files to: $(build.artifact Promote: ', 'Octopus: Relence Add\nCopy Files Promote an Octopus release from one environment\n\nto another\n\nPublish Artifact: drop\nPublish Build Artifacts Windows Machine File Copy\ngs Copy files to remote machine(s)\n\nFigure 5-7. Adding a Docker Compose task in an Azure DevOps Services pipeline or GitHub workflow\n\nWhen you create a release in Azure DevOps Services, it takes a set of input artifacts. These artifacts are\nintended to be immutable for the lifetime o', 'f the release, across all environments. When you introduce\ncontainers, the input artifacts identify images in a registry to deploy. Depending on how these images\nare identified, they are not guaranteed to remain the same throughout the duration of the release, the\nmost obvious case being when you reference myimage:latest from a docker-compose file.\n\nThe Azure DevOps Services templates give you the ability to generate build artifacts that contain\n', 'specific registry image digests that are guaranteed to uniquely identify the same image binary. These\nare what you really want to use as input to a release. You can invoke docker-compose in a run step\ninside GitHub Actions to accomplish the same goal.\n\nManaging releases to Docker environments by using Azure DevOps Services\nRelease Management or GitHub Actions\n\nThrough the Azure DevOps Services templates, you can build a new image, publish it to a', ' Docker\nregistry, run it on Linux or Windows hosts, and use commands such as docker-compose to deploy\nmultiple containers as an entire application, all through the Azure DevOps Services Release\nManagement capabilities intended for multiple environments, as shown in Figure 5-8.\n\n85 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\n+ Add environme... ~ F Add tasks | ~ Deploy to QA/Test with Docker-Compose up #\n\nun on agent ocker R', 'eaistry Connectic .\n\nProduction ACS... *** = ees BikeSharing Images Registy YY G Add | Manage\nI i \\\n\nos Has oy to QA/Test with Docker-Compose up x\n\n1/ 1 tasks enabled **/docker-compose.yml\n\nOA YR\n\nQA Test Docker e..:"*\n\n1/1 tasks enabled\n\nof | &\n\n$(Build.Repository.Name)\n\nRun a Docker Compose comm “\n\ndocker-compose up\n\nFigure 5-8. Configuring Azure DevOps Services Docker Compose tasks from Azure DevOps Services Release\nManagement\n\nHowever, keep i', "n mind that the scenario shown in Figure 5-6 and implemented in Figure 5-8 is a\nsimple one (it's deploying to single Docker hosts and VMs, and there will be a single container or\ninstance per image) and probably should be used only for development or test scenarios. In most\nenterprise production scenarios, you would want to have High Availability (HA) and easy-to-manage\nscalability by load balancing across multiple nodes, servers, and VMs, plus “", 'intelligent failovers” so if a\nserver or node fails, its services and containers will be moved to another host server or VM. In that\ncase, you need more advanced technologies such as container clusters, orchestrators, and schedulers.\nThus, the way to deploy to those clusters is by handling the advanced scenarios explained in the next\nsection.\n\nGitHub Actions can be used in the same manner, including the use of environments for approvals.\n\nDeployi', 'ng Docker applications to Docker clusters\n\nThe nature of distributed applications requires compute resources that are also distributed. To have\nproduction-scale capabilities, you need to have clustering capabilities that provide high scalability and\nhigh availability based on pooled resources.\n\nYou could deploy containers manually to those clusters from a CLI tool or a web UI, but you should\nreserve that kind of manual work to spot deployment tes', 'ting or management purposes like scaling-\nout or monitoring.\n\nFrom a CD point of view, you can use Azure DevOps Services or GitHub Actions to run specially made\ndeployment tasks from your environments that will deploy your containerized applications to\ndistributed clusters in Container Service, as illustrated in Figure 5-9.\n\n86 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\na\n\nAzure\nContainer\nService\n\nDC/OS\n\nStaging\n\n=\n\nProdu', 'ction\n\nFigure 5-9. Deploying distributed applications to Container Service\n\nDocker\nSwarm\n\nKubernetes\n\nAzure\nContainer\nRegistry\n\nDocker\nRegistry\n\nInitially, when deploying to certain clusters or orchestrators, you would traditionally use specific\ndeployment scripts and mechanisms per each orchestrator (that is, Kubernetes and Service Fabric\nhave different deployment mechanisms) instead of the simpler and easy-to-use docker-compose tool\nbased on th', 'e docker-compose.yml definition file. However, thanks to the Azure DevOps Services\nDocker Deploy task, shown in Figure 5-10, now you can also deploy to the supported orchestrators by\njust using your familiar docker-compose.yml file because the tool performs that “translation” for you\n(from your docker-compose.yml file to the format needed by the orchestrator).\n\n87 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nAll pipelines >', ' * New release pipeline\n\nPipeline Tasks Variables Retention Options History\nStage 1\nAgent job\n\nSave\n\nPY kuber\n\nAdd tasks C) Refresh\n\nDeploy to Kubernetes\n\nDeploy, configure, update your Kubernetes\ncluster in Azure Container Service by running\nkubectl commands.\n\nDeploy Kubernetes manifests\n\nUse Kubernetes manifest files to deploy to\n\nFigure 5-10. Adding the Deploy to Kubernetes task to your Environment\n\nFigure 5-11 demonstrates how you can edit th', 'e Deploy to Kubernetes task with the sections available\nfor configuration. This is the task that will retrieve your ready-to-use custom Docker images to be\n\ndeployed as containers in the cluster.\n\nAll pipelines > ™ New release pipeline\n\nPipeline Tasks Variables Retention Options History\n\nStage 1\n\nAgent jo +\n\nBy kubectl @ 3\nFD Deploy to Kubernetes 3\n\nSave\n\nDeploy to Kubernetes @ [A View YAML [li] Remove\nfo Task version Q.* v\nDisplay name *\nkubectl', '\nKubernetes service connection (i) | Manage &\nv ©) + New\n\nNamespace (i)\n\nCommands v\nSecrets Vv\nConfigMaps v\nAdvanced v\nOutput v\n\nControl Options v\n\nOutput Variables v\n\nFigure 5-11. Docker Deploy task definition deploying to ACS DC/OS\n\n88 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nTip\n\nTo read more about the CD pipeline with Azure DevOps Services and Docker, visit\n\nhttps://azure.microsoft.com/services/devops/pipelines\n\nTip', '\n\nTo see GitHub Actions workflows for Cl, visit https://github.com/dotnet-\n\narchitecture/eShopOnContainers/wiki/GitHub-Actions. For a walkthrough of GitHub Actions\nperforming deployment to an Azure Kubernetes environment, visit https://github.com/dotnet-\n\narchitecture/eShopOnContainers/wiki/Deployment-With-GitHub-Actions.\n\nStep 5: Run and manage\n\nBecause running and managing applications at enterprise-production level is a major subject in and of', '\nitself, and due to the type of operations and people working at that level (IT operations) as well as the\nlarge scope of this area, the entire next chapter is devoted to explaining it.\n\nStep 6: Monitor and diagnose\n\nThis topic also is covered in the next chapter as part of the tasks that IT performs in production\nsystems; however, is important to highlight that the insights obtained in this step must feed back to\nthe development team so that the', ' application is constantly improved. From that point of view, it’s also\npart of DevOps, although the tasks and operations are commonly performed by IT.\n\nOnly when monitoring and diagnostics are 100% within the realm of DevOps are the monitoring\nprocesses and analytics performed by the development team against testing or beta environments.\nThis is done either by performing load testing or by monitoring beta or QA environments, where beta\ntesters a', 're trying the new versions.\n\nCreate CI/CD pipelines in Azure DevOps Services for\na .NET application on Containers and deploying to a\nKubernetes cluster\n\nIn Figure 5-12 you can see the end-to-end DevOps scenario covering the code management, code\ncompilation, Docker images build, Docker images push to a Docker registry and finally the\ndeployment to a Kubernetes cluster in Azure.\n\n89 CHAPTER 5 | Docker application DevOps workflow with Microsoft too', 'ls\nScenario: Deploy to Kubernetes through CI/CD pipelines\nww oe m Container Service -\n\nKubemetes\n\nrg 4.\nApplication\ncode repo\n\n(SCC)\n\n3.\n\nBuild, Cl\n\ndocker push\n— ; =\n—\nCode\n\nPush ee\n\nCD, deploy\n\n-\n\nlam\n\n*\nDocker Hub (internet)\nor\nAzure Container Registry (Azure)\n\n2\n\n=f}\n\nCustom\nimage\n\ngit push\n\nInner loop\n\nrun\ndebug\n\nDev environment\n\nFigure 5-12. CI/CD scenario creating Docker images and deploying to a Kubernetes cluster in Azure\n\nIt is importan', 't to highlight that the two pipelines, build/Cl, and release/CD, are connected through the\nDocker Registry (such as Docker Hub or Azure Container Registry). The Docker registry is one of the\nmain differences compared to a traditional Cl/CD process without Docker.\n\nAs shown in Figure 5-13, the first phase is the build/Cl pipeline. In Azure DevOps Services you can\ncreate build/Cl pipelines that will compile the code, create the Docker images, and p', 'ush them to a\nDocker Registry like Docker Hub or Azure Container Registry.\n\n90 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\na eShopModernizing\n\nDashboards Code\n\nWork\n\nBuild and Release Test Wiki Wiki &\n\n1 ject O | + Ld\nBuilds Releases Library Task Groups Deployment Groups*\nw «> eShopModernizingMVC Save & queue ? Discard = Summary\nTasks Variables Triggers Options Retention History\nProcess Version 0." v\nBuild process\n== Get s', 'ources ‘enlany °\n©) dotnet-archhecture/eShopiModernzing I max Display name\nBuild images\nPhase 1 Container Registry Type* ©\n& kun t\nContainer Registry v\n7 NuGet restore\nNuG Docker Registry Connection @ | Manage ©\ndi@DockerHub v €) +e\na) Build project eShopModemizedMVC.csproj arEoenerrns = ow\nVisual Studio Build\nDocker Compose File* ©\n— ve\neo a images eShopModernizedMvVCSolution/docker-compose.yml\nAdditional Docker Compose Files ©\nS. Push services\n', "= Docker Compose eShopModernizedMVCSolution/docker-compose.override.yml\nEnvironment Variables 'o)\nDOCKER_BUILD_SOURCE=\nProject Name @\n$(Build.Repository.Name)\niv | Qualify Image Names @\nAction* @\nBuild service images v\n\nFigure 5-13. Build/Cl pipeline in Azure DevOps building Docker images and pushing images to a Docker registry\n\nThe second phase is to create a deployment/release pipeline. In Azure DevOps Services, you can easily\n\ncreate a deploym", 'ent pipeline targeting a Kubernetes cluster by using the Kubernetes tasks for Azure\nDevOps Services, as shown in Figure 5-14.\n\na | eShopModermizng\n\nDashboards Code\n\nWork\n\nBuiki and Release\n\nBuilds Releases Library TaskGroups Deployment Groups*\n- A r=)\nPipeline = Tasks Veriadles Retention Options History\n\nPROD eShopModernizing Kubernetes\n\nDeployment process\n\nAgent phase\n\nB ince\n\nDeploy SQL container\nDegicy tc Cbersetes\n\nDeploy MVC app container\n\nD', 'eploy to Kubernetes\n\nRefresh MVC pod\nDeploy to Kuberneras\n\neShopModernizingMVC-Kubernetes-PROD-ENV\n\nDeploy to Kubernetes © x Remo\n\nVersion G*\n\nDisplay name *\nOepicy MVC app container\nKubernetes Service Connection @\n\nps\nPROD Kubemetes Conn Prod-Environment - © + New\n\nContainer Registry Details ~\nContainer Registry type *\nContainer Registry\nDocker Registry Connection Manage i°\ncesaro|@DockerHub © +New\n\nSecret name ©\n\nForce update secret (\n\nCommands', " “\nCommand * G\n\nadply\na Use Configuration files\nConfiguration File* ©\n\nS(System.DefaultWorkingDirectory)/dotnet-architecture_eShopModern'zing/Kubernetes/eSnopModernizedMVC-KEs/ServiceDeployments/eshop-\nmodernized-mv¢-k8s-services-cepioyment ym\n\nFigure 5-14. Release/CD pipeline in Azure DevOps Services deploying to a Kubernetes cluster\n\n[!Walkthrough] Deploying eShopModernized to Kubernetes:\n\n91\n\nCHAPTER 5 | Docker application DevOps workflow with", ' Microsoft tools\nFor a detailed walkthrough of Azure DevOps CI/CD pipelines deploying to Kubernetes, see this post:\n\ns-into-Kubernetes-in-Azure-Container-Service-(Including-Cl-CD\n\nContainers-based-a\n\n92 CHAPTER 5 | Docker application DevOps workflow with Microsoft tools\nCHAPTER 6\n\nRun, Manage, and monitor\nDocker production\nenvironments\n\nVision: Enterprise applications need to run with high availability and high scalability; IT operations\nneed to ', 'be able to manage and monitor the environments and the applications themselves.\n\nThis last pillar in the containerized Docker applications life cycle is centered on how you can run,\nmanage, and monitor your applications in scalable, high availability (HA) production environments.\n\nThe way you run your containerized applications in production (infrastructure architecture and\nplatform technologies) is very much related and based on the chosen archi', 'tecture and development\nplatforms discussed in Chapter 1 of this e-book.\n\nThis chapter examines specific products and technologies from Microsoft and other vendors that you\ncan use to effectively run scalable, HA distributed applications plus how you can manage and monitor\nthem from the IT perspective.\n\nRun composed and microservices-based\napplications in production environments\n\nApplications composed by multiple microservices do need to be deplo', 'yed into orchestrator clusters in\norder to simplify the complexity of deployment and make it viable from an IT point of view. Without\nan orchestrator cluster, it would be difficult to deploy and scale out a complex microservices\napplication.\n\nIntroduction to orchestrators, schedulers, and container clusters\n\nEarlier in this e-book, clusters and schedulers were introduced as part of the discussion on software\narchitecture and development. Kubernet', "es and Service Fabric are examples of Docker clusters. Both of\nthese orchestrators can run as a part of the infrastructure provided by Microsoft Azure Kubernetes\nService.\n\n93 CHAPTER 6 | Run, manage, and monitor Docker production environments\nWhen applications are scaled-out across multiple host systems, the ability to manage each host\nsystem and abstract away the complexity of the underlying platform becomes attractive. That's\nprecisely what orc", "hestrators and schedulers provide. Let's take a brief look at them here:\n\n. Schedulers. “Scheduling” refers to the ability for an administrator to load a service file onto\na host system that establishes how to run a specific container. Launching containers in a\nDocker cluster tends to be known as scheduling. Although scheduling refers to the specific act\nof loading the service definition, in a more general sense, schedulers are responsible for\nho", "oking into a host's init system to manage services in whatever capacity needed.\n\nA cluster scheduler has multiple goals: using the cluster’s resources efficiently, working with\nuser-supplied placement constraints, scheduling applications rapidly to not leave them in a\npending state, having a degree of “fairness,” being robust to errors, and always be available.\n\n. Orchestrators. Platforms extend life-cycle management capabilities to complex, mult", "i-\ncontainer workloads deployed on a cluster of hosts. By abstracting the host infrastructure,\norchestration tools give users a way to treat the entire cluster as a single deployment target.\n\nThe process of orchestration involves tooling and a platform that can automate all aspects of\napplication management from initial placement or deployment per container; moving\ncontainers to different hosts depending on its host's health or performance; versi", 'oning and\nrolling updates and health monitoring functions that support scaling and failover; and many\nmore.\n\nOrchestration is a broad term that refers to container scheduling, cluster management, and\npossibly the provisioning of additional hosts.\n\nThe capabilities provided by orchestrators and schedulers are complex to develop and create from\nscratch, therefore you usually would want to use orchestration solutions offered by vendors.\n\nManage prod', 'uction Docker environments\n\nCluster management and orchestration is the process of controlling a group of hosts. This can involve\nadding and removing hosts from a cluster, getting information about the current state of hosts and\ncontainers, and starting and stopping processes. Cluster management and orchestration are closely\ntied to scheduling because the scheduler must have access to each host in the cluster in order to\nschedule services. For th', 'is reason, the same tool is often used for both purposes.\n\nContainer Service and management tools\n\nContainer Service provides rapid deployment of popular open-source container clustering and\norchestration solutions. It uses Docker images to ensure that your application containers are fully\nportable. By using Container Service, you can deploy DC/OS (powered by Mesosphere and Apache\nMesos) and Docker Swarm clusters with Azure Resource Manager templ', 'ates or the Azure portal to\nensure that you can scale these applications to thousands—even tens of thousands—of containers.\n\nYou deploy these clusters by using Azure Virtual Machine Scale Sets, and the clusters take advantage\nof Azure networking and storage offerings. To access Container Service, you need an Azure\n\n94 CHAPTER 6 | Run, manage, and monitor Docker production environments\nsubscription. With Container Service, you can take advantage o', 'f the enterprise-grade features of\nAzure while still maintaining application portability, including at the orchestration layers.\n\nTable 6-1 lists common management tools related to their orchestrators, schedulers, and clustering\nplatform.\n\nTable 6-1. Docker management tools\n\nManagement tools Related orchestrators\n\nAzure Monitor for Containers Azure dedicated Azure Kubernetes Services (AKS)\nKubernetes\nmanagement tool\n\nKubernetes Web UI Kubernetes ', 'Azure Kubernetes Service (AKS)\n(dashboard) management tool, Local Kubernetes\n\ncan monitor and\n\nmanage local\n\nKubernetes cluster\n\nAzure portal for Service Fabric | Online and desktop Azure Service Fabric\nAzure Service Fabric Explorer version for managing\n\nService Fabric\nclusters, on Azure, on\npremises, local\ndevelopment, and\nother clouds\n\nContainer Monitoring (Azure General container Azure Service Fabric\n\nMonitor) management y Azure Kubernetes Ser', 'vice (AKS)\nmonitoring solution. Mesosphere DC/OS and others.\nCan manage\nKubernetes clusters\nthrough Azure\nMonitor for\nContainers.\n\nAzure Service Fabric\n\nAnother choice for cluster-deployment and management is Azure Service Fabric. Service Fabric is a\nMicrosoft microservices platform that includes container orchestration as well as developer\nprogramming models to build highly scalable microservices applications. Service Fabric supports\nDocker in L', 'inux and Windows Containers and can run in Windows and Linux servers.\n\nThe following are Service Fabric management tools:\n\n. Azure portal for Service Fabric cluster-related operations (create/update/delete) a cluster or\nconfigure its infrastructure (VMs, load balancer, networking, etc.)\n\n. Azure Service Fabric Explorer is a specialized web UI and desktop multi-platform tool that\nprovides insights and certain operations on the Service Fabric clust', "er, from the nodes/VMs\npoint of view and from the application and services point of view.\n\n95 CHAPTER 6 | Run, manage, and monitor Docker production environments\nMonitor containerized application services\n\nIt's critical for applications split into multiple containers and microservices to have a way to monitor\nand analyze the behavior of the whole application.\n\nAzure Monitor\n\nAzure Monitor is an extensible analytics service that monitors your live", ' application. It helps you to\ndetect and diagnose performance issues and to understand what users actually do with your app. It’s\ndesigned for developers, with the intent of helping you to continuously improve the performance and\nusability of your services or applications. Azure Monitor works with both web/services and standalone\napps on a wide variety of platforms like .NET, Java, Node.js and many other platforms, hosted on-\npremises or in the c', 'loud.\n\nAdditional resources\n\n° Overview of Azure Monitor\n\nhttps://learn.microsoft.com/azure/azure-monitor/overview\n\n. What is Application Insights?\n\nhttps://learn.microsoft.com/azure/azure-monitor/a app-insights-overview\n\n° What is Azure Monitor Metrics?\n\nhttps://learn.microsoft.com/azure/azure-monitor/platform/data-platform-metrics\n\n° Container Monitoring solution in Azure Monitor\n\nhttps://learn.microsoft.com/azure/azure-monitor/insights/contain', 'ers\n\nSecurity and backup services\n\nThere are many support chores with lots of details that you have to handle to ensure your applications\nand infrastructure are in top notch condition to support business needs, and the situation becomes\nmore complicated in the microservices realm, so you need a way to have both high-level and detailed\nviews when you need to take action.\n\nAzure has the tools to manage and provide a unified view of four critical as', 'pects of both your cloud\nand on-premises resources:\n\n. Security. With Azure Security Center.\n- Get full visibility and control over the security of your virtual machines, apps, and\nworkloads.\n\n- Centralize the management of your security policies and integrate existing processes\nand tools.\n\n- Detect real threats with advanced analytics.\n. Backup. With Azure Backup.\n\n— Avoid costly business disruptions, meet compliance goals, and protect your data', '\nagainst ransomware and human errors.\n\n- Keep your backup data encrypted in transit and at rest.\n\n96 CHAPTER 6 | Run, manage, and monitor Docker production environments\n97\n\n- Ensure access based on multifactor authentication to prevent unauthorized use.\n\nOn-premises resources. With hybrid cloud solutions.\n\nCHAPTER 6 | Run, manage, and monitor Docker production environments\nCHAPTER\n\nContainerized Docker\nApplication Litecycle key\ntakeaways\n\n. Conta', 'iner-based solutions provide important cost-saving benefits because containers solve\ndeployment problems caused by dependency failures in production environments, thereby\nimproving DevOps and production operations significantly.\n\n. Docker has become the de facto standard in the container industry and is supported by the\nmost significant vendors in the Linux and Windows ecosystems, including Microsoft. In the\nfuture, Docker will be ubiquitous in a', 'ny datacenter in the cloud or on-premises.\n\n. A Docker container is becoming the standard unit of deployment for any server-based\napplication or service.\n\n° Docker orchestrators like the ones provided in Azure Kubernetes Service (AKS) and Azure\nService Fabric are fundamental and indispensable for any microservices-based or multi-\ncontainer applications that have significant complexity and scalability needs.\n\n. An end-to-end DevOps environment tha', 't supports Continuous Integration/Continuous\nDeployment (CI/CD) and connects to the production Docker environments can provide agility\nand ultimately improve the time to market of your applications.\n\n. Azure DevOps Services greatly simplifies your DevOps environment by deploying to Docker\nenvironments from your CI/CD pipelines. This statement applies to simple Docker\nenvironments as well as to advanced microservice and container orchestrators bas', 'ed on\nAzure.\n\n98 CHAPTER 7 | Containerized Docker Application Lifecycle key takeaways\n']