{"Summary 37 Queue new build": {"Tip": "For more information about Azure Container Registry, see https://aka.ms/azurecontainerregistry .", "Step 4: CD, Deploy": "The immutability of Docker images ensures a repeatable deployment with what's developed, tested through CI, and run in production. After you have the application Docker images published in your Docker registry (either private or public), you can deploy them to the several environments that you might have (production, QA, staging, etc.) from your CD pipeline by using Azure DevOps Services pipeline tasks, Azure DevOps Services Release Management or GitHub Actions.\n\nEnvironment Variables\n\nAzure\n\nContainer\n\nRegistry\n\nDocker\n\nRegistry\n\nQA\n\nHowever, at this point it depends on what kind of Docker application you're deploying. Deploying a simple application (from a composition and deployment point of view) like a monolithic application comprising a few containers or services and deployed to a few servers or VMs is different from deploying a more complex application like a microservices-oriented application with hyperscale capabilities. These two scenarios are explained in the following sections.", "Deploying composed Docker applications to multiple Docker environments": "Let's look first at the less -complex scenario: deploying to simple Docker hosts (VMs or servers) in a single environment or multiple environments (QA, staging, and production). In this scenario, internally your CD pipeline can use docker-compose (from your Azure DevOps Services deployment tasks) to deploy the Docker applications with its related set of containers or services, as illustrated in Figure 5-6.\n\nFigure 5 -6. Deploying application containers to simple Docker host environments registry\n\n<!-- image -->\n\nFigure 5-7 highlights how you can connect your build CI to QA/test environments via Azure DevOps Services by clicking Docker Compose in the Add Task dialog box. However, when deploying to staging or production environments, you would usually use Release Management features handling multiple environments (like QA, staging, and production). If you're deploying to single Docker hosts, it is using the Azure DevOps Services \"Docker Compose\" task (which is invoking the docker-compose up command under the hood). If you're deploying to Azure Kubernetes Service (AKS), it uses the Docker\n\n5\n\nRun, Manage\n\n['Team Services / DockerPoC']\n\nHOME\n\nCODE WORK\n\nBUILD\n\nTES\n\nDefinitions\n\nExplorer\n\nBuild Definitions / Plain Build e\n\nBuild\n\nOptions\n\nRepository\n\nVariables\n\n\u2022 Save\n\n2 Undo\n\n['Add build ste....']\n\nNuGet restore **)*.sin\n\nNuGet instoller\n\nBuild solution **|*.sin\n\nVisual Studio Build\n\nTest Assemblies **\\(BuildCc\n\nVisual Studio Test\n\nPublish symbols path:\n\nIndex Sources &amp; Publish Symbols\n\nCopy Files to: S(build.artifact\n\nCopy Files\n\nPublish Artifact: drop\n\nPublish Build Artifacts\n\nAdd tasks\n\nAll\n\nBuild\n\nUtility\n\nTest\n\nAzureni wed App wepioyment\n\nDeploy the web project to the AzureRM Web App using Web Deploy\n\nCreate Octopus Release\n\nCreate a Release in Octopus Deploy\n\nDeployment task, as explained in the section that follows. Similar steps can be built for deployment using GitHub Actions. Add\n\nDocker Compose\n\nFigure 5 -7. Adding a Docker Compose task in an Azure DevOps Services pipeline or GitHub workflow\n\n<!-- image -->\n\nWhen you create a release in Azure DevOps Services, it takes a set of input artifacts. These artifacts are intended to be immutable for the lifetime of the release, across all environments. When you introduce containers, the input artifacts identify images in a registry to deploy. Depending on how these images are identified, they are not guaranteed to remain the same throughout the duration of the release, the most obvious case being when you reference myimage:latest from a docker-compose file.\n\nThe Azure DevOps Services templates give you the ability to generate build artifacts that contain specific registry image digests that are guaranteed to uniquely identify the same image binary. These are what you really want to use as input to a release. You can invoke docker-compose in a run step inside GitHub Actions to accomplish the same goal.", "Managing releases to Docker environments by using Azure DevOps Services Release Management or GitHub Actions": "Through the Azure DevOps Services templates, you can build a new image, publish it to a Docker registry, run it on Linux or Windows hosts, and use commands such as docker-compose to deploy multiple containers as an entire application, all through the Azure DevOps Services Release Management capabilities intended for multiple environments, as shown in Figure 5-8.\n\nSearch\n\nAdd\n\nAdd\n\nDefinition: Multicontainer Docker Releases PoC \u00d8 | Releases\n\nEnvironments\n\nArtifacts Variables Triggers General Retention History\n\nU Save 1 + Release =\n\n['Add environme.....']\n\n[]\n\nProduction ACS... ***\n\n1/1 tasks enabled\n\nQA Test Docker e...**\n\n1 / 1 tasks enabled\n\n081 S\n\n['Add tasks']\n\nRun on agent\n\nDeploy to QA/Test with Docker-Compose up\n\nDocker Compose\n\nDeploy to QA/Test with Docker-Compose up /\n\nDocker Registry Connection\n\nBikeSharing Images Registry\n\nDocker Compose File\n\n<!-- image -->\n\n**/docker-compose.yml\n\nFigure 5 -8. Configuring Azure DevOps Services Docker Compose tasks from Azure DevOps Services Release Management\n\nHowever, keep in mind that the scenario shown in Figure 5-6 and implemented in Figure 5-8 is a simple one (it's deploying to single Docker hosts and VMs, and there will be a single container or instance per image) and probably should be used only for development or test scenarios. In most enterprise production scenarios, you would want to have High Availability (HA) and easy-to-manage scalability by load balancing across multiple nodes, servers, and VMs, plus \"intelligent failovers\" so if a server or node fails, its services and containers will be moved to another host server or VM. In that case, you need more advanced technologies such as container clusters, orchestrators, and schedulers. Thus, the way to deploy to those clusters is by handling the advanced scenarios explained in the next section.\n\nGitHub Actions can be used in the same manner, including the use of environments for approvals.", "Deploying Docker applications to Docker clusters": "The nature of distributed applications requires compute resources that are also distributed. To have production-scale capabilities, you need to have clustering capabilities that provide high scalability and high availability based on pooled resources.\n\nYou could deploy containers manually to those clusters from a CLI tool or a web UI, but you should reserve that kind of manual work to spot deployment testing or management purposes like scalingout or monitoring.\n\nFrom a CD point of view, you can use Azure DevOps Services or GitHub Actions to run specially made deployment tasks from your environments that will deploy your containerized applications to distributed clusters in Container Service, as illustrated in Figure 5-9.\n\nAdd | Manage O\n\nAzure\n\nContainer\n\nRegistry\n\nDocker\n\nRegistry\n\nCD, Deploy\n\nQA\n\nFigure 5 -9. Deploying distributed applications to Container Service\n\n<!-- image -->\n\nInitially, when deploying to certain clusters or orchestrators, you would traditionally use specific deployment scripts and mechanisms per each orchestrator (that is, Kubernetes and Service Fabric have different deployment mechanisms) instead of the simpler and easy-to-use docker-compose tool based on the docker -compose.yml definition file. However, thanks to the Azure DevOps Services Docker Deploy task, shown in Figure 5-10, now you can also deploy to the supported orchestrators by just using your familiar docker-compose.yml file because the tool performs that \"translation\" for you (from your docker-compose.yml file to the format needed by the orchestrator).\n\n5\n\nRun, Manage\n\nAll pipelines \u203a \"* New release pipeline\n\nAll pipelines \u00bb *** New release pipeline\n\nPipeline\n\nPipeline\n\nTasks v\n\nVariables\n\nTasks V\n\nVariables\n\nStage 1\n\nStage 1\n\nDeployment process\n\nDeployment process\n\nAgent job\n\nAgent job\n\n= Run on agent"}, "Run on agent kubectl": "Fo Deploy to Kubernetes\n\nHistory\n\nHistory\n\n...\n\nDeploy to Kubernetes O\n\nAdd tasks\n\n\u00a9 Refresh\n\n\u2014 Release V ..\u2022\n\n\u2022 Save + Release v ...\n\n\u2022 View YAML W Remove\n\nFigure 5 -10. Adding the Deploy to Kubernetes task to your Environment\n\n<!-- image -->\n\nOutput V\n\nFigure 5-11 demonstrates how you can edit the Deploy to Kubernetes task with the sections available for configuration. This is the task that will retrieve your ready-to-use custom Docker images to be deployed as containers in the cluster.\n\nFigure 5 -11. Docker Deploy task definition deploying to ACS DC/OS\n\n<!-- image -->\n\nO kuber\n\nRetention Options\n\nRetention Options", "Save": {"Tip": "To see GitHub Actions workflows for CI, visit https://github.com/dotnetarchitecture/eShopOnContainers/wiki/GitHub-Actions. For a walkthrough of GitHub Actions performing deployment to an Azure Kubernetes environment, visit https://github.com/dotnetarchitecture/eShopOnContainers/wiki/Deployment-With-GitHub-Actions .", "Step 5: Run and manage": "Because running and managing applications at enterprise-production level is a major subject in and of itself, and due to the type of operations and people working at that level (IT operations) as well as the large scope of this area, the entire next chapter is devoted to explaining it.", "Step 6: Monitor and diagnose": "This topic also is covered in the next chapter as part of the tasks that IT performs in production systems; however, is important to highlight that the insights obtained in this step must feed back to the development team so that the application is constantly improved. From that point of view, it's also part of DevOps, although the tasks and operations are commonly performed by IT.\n\nOnly when monitoring and diagnostics are 100% within the realm of DevOps are the monitoring processes and analytics performed by the development team against testing or beta environments. This is done either by performing load testing or by monitoring beta or QA environments, where beta testers are trying the new versions.", "Create CI/CD pipelines in Azure DevOps Services for a .NET application on Containers and deploying to a Kubernetes cluster": "In Figure 5-12 you can see the end-to-end DevOps scenario covering the code management, code compilation, Docker images build, Docker images push to a Docker registry and finally the deployment to a Kubernetes cluster in Azure.\n\nScenario: Deploy to Kubernetes through CI/CD pipelines\n\nAZur\n\nContainer Service -\n\nKubernetes\n\nCode.\n\nrun, debug\n\n[]\n\nApplication code repo\n\n(SCC)\n\n<!-- image -->\n\nCode\n\nPush git push\n\nInner loop\n\n[]\n\nDev environment\n\nFigure 5 -12. CI/CD scenario creating Docker images and deploying to a Kubernetes cluster in Azure\n\nIt is important to highlight that the two pipelines, build/CI, and release/CD, are connected through the Docker Registry (such as Docker Hub or Azure Container Registry). The Docker registry is one of the main differences compared to a traditional CI/CD process without Docker.\n\nAs shown in Figure 5-13, the first phase is the build/CI pipeline. In Azure DevOps Services you can create build/CI pipelines that will compile the code, create the Docker images, and push them to a Docker Registry like Docker Hub or Azure Container Registry.\n\n[]", "Build, CI CD, deploy": "eShopModernizing v Dashboards Code Work Build and Release Test Wiki Wiki /\n\n\u2022 ShopModerizing v Dashboards Code Work Build and Release Test Wik* Wik | @\n\nBuilds Releases Library Task Groups Deployment Groups*\n\nBuilds Releases Library Task Groups Deployment Groups*\n\n['All definitions &gt; eShopModernizingMVC-Kubernetes-PROD-ENV']\n\ni ... &gt; eShopModernizingMVC\n\nPipeline Tasks ~ Variables Retention Options History\n\nTasks\n\nVariables Triggers Options\n\nRetention\n\nPROD eShopModernizing Kubernetes\n\nProcess\n\nDeploymant process\n\nBuild process\n\nAgent phase\n\n== Get sources\n\nIE Run on agent\n\n\u2022 dotnet-architecture/eShopModernizing\n\n$ Deploy SQl containe\n\nDeploy to Kubernati\n\nPhase 1\n\nE Run on agent\n\n\u0e3f Deploy MVC app containe\n\nDeploy to Kubernet\n\nNuGet\n\nNucet restore\n\nDeploy to Kubarnates\n\nBudsproject eShopModernizedMVC.csproj\n\nBuild images\n\nDocker Compose\n\nPush services\n\nDocker Compose\n\nVersion\n\n0.-\n\nDeploy to Kubernetes O\n\nSearch code in this project V \" ..\n\nE Save &amp; queue V Discard\n\n= Summary\n\n\u2022 Queue\n\nX Remove\n\nFigure 5 -13. Build/CI pipeline in Azure DevOps building Docker images and pushing images to a Docker registry\n\n<!-- image -->\n\nThe second phase is to create a deployment/release pipeline. In Azure DevOps Services, you can easily create a deployment pipeline targeting a Kubernetes cluster by using the Kubernetes tasks for Azure DevOps Services, as shown in Figure 5-14.\n\nFigure 5 -14. Release/CD pipeline in Azure DevOps Services deploying to a Kubernetes cluster\n\n<!-- image -->\n\n[!Walkthrough] Deploying eShopModernized to Kubernetes:\n\nHistory\n\nFor a detailed walkthrough of Azure DevOps CI/CD pipelines deploying to Kubernetes, see this post: https://github.com/dotnet-architecture/eShopModernizing/wiki/04.-How-to-deploy-your-WindowsContainers -based -apps -into -Kubernetes -in -Azure -Container -Service -(Including-CI-CD)", "Run, manage, and monitor Docker production environments": "Vision: Enterprise applications need to run with high availability and high scalability; IT operations need to be able to manage and monitor the environments and the applications themselves.\n\nThis last pillar in the containerized Docker applications life cycle is centered on how you can run, manage, and monitor your applications in scalable, high availability (HA) production environments.\n\nThe way you run your containerized applications in production (infrastructure architecture and platform technologies) is very much related and based on the chosen architecture and development platforms discussed in Chapter 1 of this e-book.\n\nThis chapter examines specific products and technologies from Microsoft and other vendors that you can use to effectively run scalable, HA distributed applications plus how you can manage and monitor them from the IT perspective.", "Run composed and microservices -based applications in production environments": "Applications composed by multiple microservices do need to be deployed into orchestrator clusters in order to simplify the complexity of deployment and make it viable from an IT point of view. Without an orchestrator cluster, it would be difficult to deploy and scale out a complex microservices application.", "Introduction to orchestrators, schedulers, and container clusters": "Earlier in this e -book, clusters and schedulers were introduced as part of the discussion on software architecture and development. Kubernetes and Service Fabric are examples of Docker clusters. Both of these orchestrators can run as a part of the infrastructure provided by Microsoft Azure Kubernetes Service.\n\nWhen applications are scaled-out across multiple host systems, the ability to manage each host system and abstract away the complexity of the underlying platform becomes attractive. That's precisely what orchestrators and schedulers provide. Let's take a brief look at them here:\n\n['Schedulers . \"Scheduling\" refers to the ability for an administrator to load a service file onto a host system that establishes how to run a specific container. Launching containers in a Docker cluster tends to be known as scheduling. Although scheduling refers to the specific act of loading the service definition, in a more general sense, schedulers are responsible for hooking into a host\\'s init system to manage services in whatever capacity needed.']\n\nA cluster scheduler has multiple goals: using the cluster's resources efficiently, working with user-supplied placement constraints, scheduling applications rapidly to not leave them in a pending state, having a degree of \"fairness,\" being robust to errors, and always be available.\n\n['Orchestrators . Platforms extend life -cycle management capabilities to complex, multicontainer workloads deployed on a cluster of hosts. By abstracting the host infrastructure, orchestration tools give users a way to treat the entire cluster as a single deployment target.']\n\nThe process of orchestration involves tooling and a platform that can automate all aspects of application management from initial placement or deployment per container; moving containers to different hosts depending on its host's health or performance; versioning and rolling updates and health monitoring functions that support scaling and failover; and many more.\n\nOrchestration is a broad term that refers to container scheduling, cluster management, and possibly the provisioning of additional hosts.\n\nThe capabilities provided by orchestrators and schedulers are complex to develop and create from scratch, therefore you usually would want to use orchestration solutions offered by vendors.", "Manage production Docker environments": "Cluster management and orchestration is the process of controlling a group of hosts. This can involve adding and removing hosts from a cluster, getting information about the current state of hosts and containers, and starting and stopping processes. Cluster management and orchestration are closely tied to scheduling because the scheduler must have access to each host in the cluster in order to schedule services. For this reason, the same tool is often used for both purposes.", "Container Service and management tools": "Container Service provides rapid deployment of popular open-source container clustering and orchestration solutions. It uses Docker images to ensure that your application containers are fully portable. By using Container Service, you can deploy DC/OS (powered by Mesosphere and Apache Mesos) and Docker Swarm clusters with Azure Resource Manager templates or the Azure portal to ensure that you can scale these applications to thousands\u2014even tens of thousands\u2014of containers.\n\nYou deploy these clusters by using Azure Virtual Machine Scale Sets, and the clusters take advantage of Azure networking and storage offerings. To access Container Service, you need an Azure\n\nsubscription. With Container Service, you can take advantage of the enterprise-grade features of Azure while still maintaining application portability, including at the orchestration layers.\n\nTable 6 -1 lists common management tools related to their orchestrators, schedulers, and clustering platform.\n\nTable 6 -1. Docker management tools\n\n| Management tools                                              | Description                                                                                                                 | Related orchestrators                                                            |\n|---------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n| Azure Monitor for Containers                                  | Azure dedicated Kubernetes management tool                                                                                  | Azure Kubernetes Services (AKS)                                                  |\n| Kubernetes Web UI (dashboard)                                 | Kubernetes management tool, can monitor and manage local Kubernetes cluster                                                 | Azure Kubernetes Service (AKS) Local Kubernetes                                  |\n| Azure portal for Service Fabric Azure Service Fabric Explorer | Online and desktop version for managing Service Fabric clusters, on Azure, on premises, local development, and other clouds | Azure Service Fabric                                                             |\n| Container Monitoring (Azure Monitor)                          | General container management y monitoring solution. Can manage Kubernetes clusters through Azure Monitor for Containers .   | Azure Service Fabric Azure Kubernetes Service (AKS) Mesosphere DC/OS and others. |", "Azure Service Fabric": "Another choice for cluster -deployment and management is Azure Service Fabric. Service Fabric is a Microsoft microservices platform that includes container orchestration as well as developer programming models to build highly scalable microservices applications. Service Fabric supports Docker in Linux and Windows Containers and can run in Windows and Linux servers.\n\nThe following are Service Fabric management tools:\n\n['Azure portal for Service Fabric cluster-related operations (create/update/delete) a cluster or configure its infrastructure (VMs, load balancer, networking, etc.)', 'Azure Service Fabric Explorer is a specialized web UI and desktop multi-platform tool that provides insights and certain operations on the Service Fabric cluster, from the nodes/VMs point of view and from the application and services point of view.']", "Monitor containerized application services": "It's critical for applications split into multiple containers and microservices to have a way to monitor and analyze the behavior of the whole application.", "Azure Monitor": "Azure Monitor is an extensible analytics service that monitors your live application. It helps you to detect and diagnose performance issues and to understand what users actually do with your app. It's designed for developers, with the intent of helping you to continuously improve the performance and usability of your services or applications. Azure Monitor works with both web/services and standalone apps on a wide variety of platforms like .NET, Java, Node.js and many other platforms, hosted onpremises or in the cloud .", "Additional resources": ["Overview of Azure Monitor https://learn.microsoft.com/azure/azure-monitor/overview", "What is Application Insights? https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview", "What is Azure Monitor Metrics? https://learn.microsoft.com/azure/azure-monitor/platform/data-platform-metrics", "Container Monitoring solution in Azure Monitor https://learn.microsoft.com/azure/azure-monitor/insights/containers"], "Security and backup services": "There are many support chores with lots of details that you have to handle to ensure your applications and infrastructure are in top notch condition to support business needs, and the situation becomes more complicated in the microservices realm, so you need a way to have both high-level and detailed views when you need to take action.\n\nAzure has the tools to manage and provide a unified view of four critical aspects of both your cloud and on -premises resources:\n\n['Security. With Azure Security Center .', '\u2013 Get full visibility and control over the security of your virtual machines, apps, and workloads.', '\u2013 Centralize the management of your security policies and integrate existing processes and tools.', '\u2013 Detect real threats with advanced analytics.', 'Backup. With Azure Backup .', '\u2013 Avoid costly business disruptions, meet compliance goals, and protect your data against ransomware and human errors.', '\u2013 Keep your backup data encrypted in transit and at rest.', '\u2013 Ensure access based on multifactor authentication to prevent unauthorized use.', 'On -premises resources. With hybrid cloud solutions .']", "Containerized Docker Application Lifecycle key takeaways": ["Container -based solutions provide important cost-saving benefits because containers solve deployment problems caused by dependency failures in production environments, thereby improving DevOps and production operations significantly.", "Docker has become the de facto standard in the container industry and is supported by the most significant vendors in the Linux and Windows ecosystems, including Microsoft. In the future, Docker will be ubiquitous in any datacenter in the cloud or on-premises.", "A Docker container is becoming the standard unit of deployment for any server-based application or service.", "Docker orchestrators like the ones provided in Azure Kubernetes Service (AKS) and Azure Service Fabric are fundamental and indispensable for any microservices-based or multicontainer applications that have significant complexity and scalability needs.", "An end -to -end DevOps environment that supports Continuous Integration/Continuous Deployment (CI/CD) and connects to the production Docker environments can provide agility and ultimately improve the time to market of your applications.", "Azure DevOps Services greatly simplifies your DevOps environment by deploying to Docker environments from your CI/CD pipelines. This statement applies to simple Docker environments as well as to advanced microservice and container orchestrators based on Azure."]}}