"[\"EDITION v6.0.0 - Updated to ASP.NET Core 6.0\\n\\nRefer changelog for the book updates and community contributions.\\n\\nThis guide is a general overview for developing and deploying containerized ASP.NET Core applications with Docker, using the Microsoft platform and tools. The guide includes a high-level introduction to Azure DevOps, for implementing CI/CD pipelines, as well as Azure Container Registry (ACR) and Azure Kubernetes Services AKS for deploy\", \"ment.\\n\\nFor low-level, development-related details you can see the .NET Microservices: Architecture for Containerized .NET Applications guide and it related reference application eShopOnContainers.\\n\\nCredits\\n\\nAuthor:\\n\\nCesar de la Torre, Sr. PM, .NET product team, Microsoft Corp.\\n\\nAcquisitions Editor:\\n\\nJanine Patrick\\n\\nDevelopmental Editor:\\n\\nBob Russell, Solutions Professional at Microsoft\\n\\nOctal Publishing, Inc.\\n\\nEditorial Production:\\n\\nDianne Russel\", \"l\\n\\nOctal Publishing, Inc.\\n\\nCopyeditor:\\n\\nBob Russell, Solutions Professional at Microsoft\\n\\nParticipants and reviewers:\\n\\nNish Anil, Sr. Program Manager, .NET team, Microsoft\\n\\nMiguel Veloso, Software Development Engineer at Plain Concepts\\n\\nSumit Ghosh, Principal Consultant at Neudesic\\n\\nColin Dembovsky, DevOps Practice Lead, Cognizant Microsoft Business Group\\n\\nCopyright\\n\\nPUBLISHED BY\\n\\nMicrosoft Developer Division, .NET and Visual Studio product teams\", \"\\n\\nA division of Microsoft Corporation\\n\\nOne Microsoft Way\\n\\nRedmond, Washington 98052-6399\\n\\nCopyright \\u00a9 2022 by Microsoft Corporation\\n\\nAll rights reserved. No part of the contents of this book may be reproduced or transmitted in any form or by any means without the written permission of the publisher.\\n\\nThis book is provided \\u201cas-is\\u201d and expresses the author\\u2019s views and opinions. The views, opinions, and information expressed in this book, including \", \"URL and other Internet website references, may change without notice.\\n\\nSome examples depicted herein are provided for illustration only and are fictitious. No real association or connection is intended or should be inferred.\\n\\nMicrosoft and the trademarks listed at https://www.microsoft.com on the \\u201cTrademarks\\u201d webpage are trademarks of the Microsoft group of companies.\\n\\nMac and macOS are trademarks of Apple Inc.\\n\\nThe Docker whale logo is a registe\", \"red trademark of Docker, Inc. Used by permission.\\n\\nAll other marks and logos are property of their respective owners.\\n\\nContents\\n\\nOverview of Containers and Docker ...................................................................................... 1\\n\\nLearn Docker .............................................................................................................................................................................. 2\\n\\nCompar\", \"ing Docker containers with virtual machines ........................................................................................... 3\\n\\nA simple analogy ................................................................................................................................................................. 4\\n\\nLearn Docker specific terminologies .............................................................................................\", \"................................... 4\\n\\nLearn docker containers, images, and registries ......................................................................................................... 6\\n\\nRoad to modern applications based on containers ................................................................................................... 8\\n\\nIntroduction to the Docker application life cycle .....................................................\", \"........... 9\\n\\nContainers as the foundation for DevOps collaboration ......................................................................................... 9\\n\\nChallenges in the application life cycle when using Docker. .......................................................................... 10\\n\\nIntroduction to a generic end-to-end Docker application life cycle workflow ....................................... 11\\n\\nBenefits of DevOps for contai\", \"nerized applications ............................................................................................ 12\\n\\nIntroduction to the Microsoft platform and tools for containerized apps ..................... 13\\n\\nDesigning and developing containerized apps using Docker and Microsoft Azure ...... 17\\n\\nDesign Docker applications .......................................................................................................................\", \"....................... 17\\n\\nCommon container design principles ........................................................................................................................... 18\\n\\nContainer equals a process .......................................................................................................................................... 18\\n\\nMonolithic applications .................................................................\", \"..................................................................................... 18\\n\\nMonolithic application deployed as a container ................................................................................................. 21\\n\\nPublish a single Docker container app to Azure App Service ........................................................................ 21\\n\\nState and data in Docker applications......................................\", \".................................................................................... 22\\n\\nService-oriented applications .......................................................................................................................................... 25\\n\\nOrchestrating microservices and multi-container applications for high scalability and availability.... 25\\n\\nSoftware platforms for container clustering, orchestration, and scheduling ......\", \"..................................... 27\\n\\nUsing container-based orchestrators in Azure ..................................................................................................... 28\\n\\nUsing Azure Kubernetes Service ................................................................................................................................ 29\\n\\nDevelopment environment for Kubernetes ......................................................\", \"..................................................... 30\\n\\nGet started with Azure Kubernetes Service (AKS) ............................................................................................... 31\\n\\ni\\n\\nContents\\n\\nDeploy with Helm charts into Kubernetes clusters ............................................................................................. 31\\n\\nAdditional resources ...............................................................\", \"........................................................................................ 32\\n\\nUsing Azure Service Fabric ........................................................................................................................................... 32\\n\\nStateless versus stateful microservices .................................................................................................................... 35\\n\\nUsing Azure Service Fabri\", \"c Mesh ............................................................................................................................... 36\\n\\nChoosing orchestrators in Azure ............................................................................................................................... 37\\n\\nDeploy to Azure Kubernetes Service (AKS) ..........................................................................................................\", \"...... 38\\n\\nCreate the AKS environment in Azure ..................................................................................................................... 38\\n\\nCreate the AKS cluster .................................................................................................................................................... 38\\n\\nDevelopment environment for Docker apps .................................................................\", \"............................................ 40\\n\\nDevelopment tools choices: IDE or editor .............................................................................................................. 40\\n\\nLanguage and framework choices ............................................................................................................................ 41\\n\\nInner-loop development workflow for Docker apps .....................................\", \"......................................................... 41\\n\\nBuilding a single app within a Docker container using Visual Studio Code and Docker CLI............. 42\\n\\nUse Docker Tools in Visual Studio on Windows ....................................................................................................... 52\\n\\nConfigure your local environment .................................................................................................\", \"........................... 52\\n\\nDocker support in Visual Studio ................................................................................................................................ 52\\n\\nConfigure Docker tools .................................................................................................................................................. 55\\n\\nUsing Windows PowerShell commands in a DockerFile to set up Windows Containers \", \"(Docker standard based) ..................................................................................................................................................................... 56\\n\\nBuild ASP.NET Core applications deployed as Linux containers into an AKS/Kubernetes orchestrator ...............................................................................................................................................................\", \"....................................... 57\\n\\nCreating the ASP.NET Core Project using Visual Studio 2022........................................................................ 57\\n\\nRegister the Solution in an Azure Container Registry (ACR) .......................................................................... 66\\n\\nDocker application DevOps workflow with Microsoft tools ............................................. 74\\n\\nSteps in the outer-loop Dev\", \"Ops workflow for a Docker application ............................................................... 75\\n\\nStep 1: Inner-loop development workflow ............................................................................................................ 76\\n\\nStep 2: Source-Code Control integration and management with Azure DevOps Services and Git 76\\n\\nStep 3: Build, CI, Integrate, and Test with Azure DevOps Services/GitHub and Docker .............\", \"......... 76\\n\\nStep 4: CD, Deploy ........................................................................................................................................................... 83\\n\\nStep 5: Run and manage ............................................................................................................................................... 89\\n\\nStep 6: Monitor and diagnose .........................................................\", \"........................................................................... 89\\n\\nii\\n\\nContents\\n\\nCreate CI/CD pipelines in Azure DevOps Services for a .NET application on Containers and deploying to a Kubernetes cluster ................................................................................................................................. 89\\n\\nRun, manage, and monitor Docker production environments ........................................ 93\", \"\\n\\nRun composed and microservices-based applications in production environments ............................... 93\\n\\nIntroduction to orchestrators, schedulers, and container clusters ............................................................... 93\\n\\nManage production Docker environments ................................................................................................................ 94\\n\\nContainer Service and management tools .......\", \"...................................................................................................... 94\\n\\nAzure Service Fabric ........................................................................................................................................................ 95\\n\\nMonitor containerized application services ............................................................................................................... 96\\n\\nAzure \", \"Monitor ................................................................................................................................................................... 96\\n\\nSecurity and backup services....................................................................................................................................... 96\\n\\nContainerized Docker Application Lifecycle key takeaways ............................................. 98\\n\", \"\\niii\\n\\nContents\\n\\nCHAPTER 1\\n\\nOverview of Containers and Docker\\n\\nContainerization is an approach to software development in which an application or service, its dependencies, and its configuration (abstracted as deployment manifest files) are packaged together as a container image. You then can test the containerized application as a unit and deploy it as a container image instance to the host operating system (OS).\\n\\nJust as shipping containers allo\", \"w goods to be transported by ship, train, or truck regardless of the cargo inside, software containers act as a standard unit of software deployment that can contain different code and dependencies. Containerizing software this way enables developers and IT professionals to deploy them across environments with little or no modification.\\n\\nContainers also isolate applications from each other on a shared OS. Containerized applications run on top of \", \"a container host that in turn runs on the OS (Linux or Windows). Containers therefore have a much smaller footprint than virtual machine (VM) images.\\n\\nEach container can run a whole web application or a service, as shown in Figure 1-1. In this example, Docker host is a container host, and App1, App2, Svc1, and Svc2 are containerized applications or services.\\n\\nFigure 1-1. Multiple containers running on a container host\\n\\nAnother benefit you can der\", \"ive from containerization is scalability. You can scale out quickly by creating new containers for short-term tasks. From an application point of view, instantiating an image (creating a container) is similar to instantiating a process like a service or web app. For reliability, however, when you run multiple instances of the same image across multiple host servers, you typically want each container (image instance) to run in a different host ser\", \"ver or VM in different fault domains.\\n\\nIn short, containers offer the benefits of isolation, portability, agility, scalability, and control across the entire application lifecycle workflow. The most important benefit is the environment isolation provided between Dev and Ops.\\n\\n1\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nLearn Docker\\n\\nDocker is an open-source project for automating the deployment of applications as portable, self- sufficient \", \"containers that can run on the cloud or on-premises. Docker is also a company that promotes and evolves this technology, working in collaboration with cloud, Linux, and Windows vendors, including Microsoft.\\n\\nFigure 1-2. Docker deploys containers at all layers of the hybrid cloud\\n\\nAs shown in the above diagram, Docker containers can run anywhere, on-premises in the customer datacenter, in an external service provider or in the cloud, on Azure. Doc\", \"ker image containers can also run natively on Linux and Windows. However, Windows images can run only on Windows hosts and Linux images can run on Linux hosts and Windows hosts (using a Hyper-V Linux VM, so far), where host means a server or a VM.\\n\\nDevelopers can use development environments on Windows, Linux, or macOS. On the development computer, the developer runs a Docker host where Docker images are deployed, including the app and its depend\", \"encies. Developers who work on Linux or on the Mac, use a Docker host that\\u2019s Linux- based, and they can only create images for Linux containers. (Developers working on the Mac can edit code or run the Docker command-line interface (CLI) from macOS, but as of this writing, containers don\\u2019t run directly on macOS.) Developers who work on Windows can create images for either Linux or Windows Containers.\\n\\nTo host containers in development environments\", \" and provide additional developer tools, Docker ships Docker Desktop for Windows or for macOS. These products install the necessary VM (the Docker host) to host the containers.\\n\\nTo run Windows Containers, there are two types of runtimes:\\n\\nWindows Server Containers provide application isolation through process and namespace\\n\\nisolation technology. A Windows Server Container shares a kernel with the container host and with all containers running on \", \"the host.\\n\\n\\n\\nHyper-V Containers expand on the isolation provided by Windows Server Containers by running each container in a highly optimized virtual machine. In this configuration, the kernel of the container host isn\\u2019t shared with the Hyper-V Containers, providing better isolation.\\n\\n2\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nThe images for these containers are created and work just the same way. The difference is in how the container is \", \"created from the image\\u2014running a Hyper-V Container requires an extra parameter. For details, see Hyper-V Containers.\\n\\nComparing Docker containers with virtual machines\\n\\nFigure 1-3 shows a comparison between VMs and Docker containers.\\n\\nFigure 1-3. Comparison of traditional virtual machines to Docker containers\\n\\nAs shown in the above diagram, for VMs, there are three base layers in the host server. From the bottom-up: Infrastructure, Host Operating\", \" System, and a Hypervisor. On top of all that, each VM has its own OS and all necessary libraries. On the other hand, for Docker, the host server only has the Infrastructure and the OS. On top of that, the container engine keeps containers isolated, but lets them share the single base OS\\u2019s services.\\n\\nBecause containers require far fewer resources (for example, they don\\u2019t need a full OS), they\\u2019re easy to deploy and they start fast. This allows you\", \" to have higher density, meaning that it allows you to run more services on the same hardware unit, thereby reducing costs.\\n\\nAs a side effect of running on the same kernel, you get less isolation than VMs.\\n\\nThe main goal of an image is to ensure the same environment (dependencies) across different deployments. This means that you can debug it on your machine and then deploy it to another machine, the same environment guaranteed.\\n\\nA container imag\", \"e is a way to package an app or service and deploy it in a reliable and reproducible way. You could say that Docker isn\\u2019t only a technology but also a philosophy and a process.\\n\\n3\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nWhen using Docker, you won\\u2019t hear developers say, \\u201cIt works on my machine, why not in production?\\u201d They can just say, \\u201cIt runs on Docker\\u201d, because the packaged Docker application can be executed on any supported Docker env\", \"ironment, and it runs the way it was intended to on all deployment targets (such as Dev, QA, staging, and production).\\n\\nA simple analogy\\n\\nPerhaps a simple analogy can help getting the grasp of the core concept of Docker.\\n\\nLet\\u2019s go back in time to the 1950s for a moment. There were no word processors, and the photocopiers were used everywhere (well, kind of).\\n\\nImagine you\\u2019re responsible for quickly issuing batches of letters as required, to mail t\", \"hem to customers, using real paper and envelopes, to be delivered physically to each customer\\u2019s address (there was no email back then).\\n\\nAt some point, you realize the letters are just a composition of a large set of paragraphs, which are picked and arranged as needed, according to the purpose of the letter, so you devise a system to issue letters quickly, expecting to get a hefty raise.\\n\\nThe system is simple:\\n\\n1.\\n\\nYou begin with a deck of transp\", \"arent sheets containing one paragraph each.\\n\\n2.\\n\\nTo issue a set of letters, you pick the sheets with the paragraphs you need, then you stack and align them so they look and read fine.\\n\\n3.\\n\\nFinally, you place the set in the photocopier and press start to produce as many letters as required.\\n\\nSo, simplifying, that\\u2019s the core idea of Docker.\\n\\nIn Docker, each layer is the resulting set of changes that happen to the filesystem after executing a comman\", \"d, such as, installing a program.\\n\\nSo, when you \\u201clook\\u201d at the filesystem after the layer has been copied, you see all the files, included the layer when the program was installed.\\n\\nYou can think of an image as an auxiliary read-only hard disk ready to be installed in a \\u201ccomputer\\u201d where the operating system is already installed.\\n\\nSimilarly, you can think of a container as the \\u201ccomputer\\u201d with the image hard disk installed. The container, just like \", \"a computer, can be powered on or off.\\n\\nLearn Docker specific terminologies\\n\\nThis section lists terms and definitions you should be familiar with before getting deeper into Docker. For further definitions, see the extensive glossary provided by Docker.\\n\\nContainer image: A package with all the dependencies and information needed to create a container. An image includes all the dependencies (such as frameworks) plus deployment and execution\\n\\n4\\n\\nCHAP\", \"TER 1 | Overview of Containers and Docker\\n\\nconfiguration to be used by a container runtime. Usually, an image derives from multiple base images that are layers stacked on top of each other to form the container\\u2019s filesystem. An image is immutable once it has been created.\\n\\nDockerfile: A text file that contains instructions for building a Docker image. It\\u2019s like a batch script, the first line states the base image to begin with and then follow the\", \" instructions to install required programs, copy files, and so on, until you get the working environment you need.\\n\\nBuild: The action of building a container image based on the information and context provided by its Dockerfile, plus additional files in the folder where the image is built. You can build images with the following Docker command:\\n\\ndocker build\\n\\nContainer: An instance of a Docker image. A container represents the execution of a sing\", \"le application, process, or service. It consists of the contents of a Docker image, an execution environment, and a standard set of instructions. When scaling a service, you create multiple instances of a container from the same image. Or a batch job can create multiple containers from the same image, passing different parameters to each instance.\\n\\nVolumes: Offer a writable filesystem that the container can use. Since images are read-only but mos\", \"t programs need to write to the filesystem, volumes add a writable layer, on top of the container image, so the programs have access to a writable filesystem. The program doesn\\u2019t know it\\u2019s accessing a layered filesystem, it\\u2019s just the filesystem as usual. Volumes live in the host system and are managed by Docker.\\n\\nTag: A mark or label you can apply to images so that different images or versions of the same image (depending on the version number o\", \"r the target environment) can be identified.\\n\\nMulti-stage Build: Is a feature, since Docker 17.05 or higher, that helps to reduce the size of the final images. For example, a large base image, containing the SDK can be used for compiling and publishing and then a small runtime-only base image can be used to host the application.\\n\\nRepository (repo): A collection of related Docker images, labeled with a tag that indicates the image version. Some re\", \"pos contain multiple variants of a specific image, such as an image containing SDKs (heavier), an image containing only runtimes (lighter), etc. Those variants can be marked with tags. A single repo can contain platform variants, such as a Linux image and a Windows image.\\n\\nRegistry: A service that provides access to repositories. The default registry for most public images is Docker Hub (owned by Docker as an organization). A registry usually con\", \"tains repositories from multiple teams. Companies often have private registries to store and manage images they\\u2019ve created. Azure Container Registry is another example.\\n\\nMulti-arch image: For multi-architecture, it\\u2019s a feature that simplifies the selection of the appropriate image, according to the platform where Docker is running. For example, when a Dockerfile requests a base image FROM mcr.microsoft.com/dotnet/sdk:6.0 from the registry, it act\", \"ually gets 6.0- nanoserver-20H2, 6.0-nanoserver-1809 or 6.0-bullseye-slim, depending on the operating system and version where Docker is running.\\n\\n5\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nDocker Hub: A public registry to upload images and work with them. Docker Hub provides Docker image hosting, public or private registries, build triggers and web hooks, and integration with GitHub and Bitbucket.\\n\\nAzure Container Registry: A public resou\", \"rce for working with Docker images and its components in Azure. This provides a registry that\\u2019s close to your deployments in Azure and that gives you control over access, making it possible to use your Azure Active Directory groups and permissions.\\n\\nDocker Trusted Registry (DTR): A Docker registry service (from Docker) that can be installed on- premises so it lives within the organization\\u2019s datacenter and network. It\\u2019s convenient for private imag\", \"es that should be managed within the enterprise. Docker Trusted Registry is included as part of the Docker Datacenter product.\\n\\nDocker Desktop: Development tools for Windows and macOS for building, running, and testing containers locally. Docker Desktop for Windows provides development environments for both Linux and Windows Containers. The Linux Docker host on Windows is based on a Hyper-V virtual machine. The host for Windows Containers is dire\", \"ctly based on Windows. Docker Desktop for Mac is based on the Apple Hypervisor framework and the xhyve hypervisor, which provides a Linux Docker host virtual machine on macOS. Docker Desktop for Windows and for Mac replaces Docker Toolbox, which was based on Oracle VirtualBox.\\n\\nCompose: A command-line tool and YAML file format with metadata for defining and running multi- container applications. You define a single application based on multiple i\", \"mages with one or more .yml files that can override values depending on the environment. After you\\u2019ve created the definitions, you can deploy the whole multi-container application with a single command (docker-compose up) that creates a container per image on the Docker host.\\n\\nCluster: A collection of Docker hosts exposed as if it were a single virtual Docker host, so that the application can scale to multiple instances of the services spread acr\", \"oss multiple hosts within the cluster. Docker clusters can be created with Kubernetes, Azure Service Fabric, Docker Swarm and Mesosphere DC/OS.\\n\\nOrchestrator: A tool that simplifies the management of clusters and Docker hosts. Orchestrators enable you to manage their images, containers, and hosts through a command-line interface (CLI) or a graphical UI. You can manage container networking, configurations, load balancing, service discovery, high a\", \"vailability, Docker host configuration, and more. An orchestrator is responsible for running, distributing, scaling, and healing workloads across a collection of nodes. Typically, orchestrator products are the same products that provide cluster infrastructure, like Kubernetes and Azure Service Fabric, among other offerings in the market.\\n\\nLearn docker containers, images, and registries\\n\\nWhen using Docker, you create an app or service and package \", \"it and its dependencies into a container image. An image is a static representation of the app or service and its configuration and dependencies.\\n\\nTo run the app or service, the app\\u2019s image is instantiated to create a container, which will be running on the Docker host. Containers are initially tested in a development environment or PC.\\n\\n6\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nYou store images in a registry that acts as a library of ima\", \"ges. You need a registry when deploying to production orchestrators. Docker maintains a public registry via Docker Hub; other vendors provide registries for different collections of images, including Azure Container Registry. Alternatively, enterprises can have a private registry on-premises for their own Docker images.\\n\\nFigure 1-4 shows how images and registries in Docker relate to other components. It also shows the multiple registry offerings \", \"from vendors.\\n\\nFigure 1-4. Taxonomy of Docker terms and concepts\\n\\nThe registry is like a bookshelf where images are stored and available to be pulled for building containers to run services or web apps. There are private Docker registries on-premises and on the public cloud. Docker Hub is a public registry maintained by Docker, along the Docker Trusted Registry an enterprise-grade solution, Azure offers the Azure Container Registry. AWS, Google a\", \"nd others also have container registries.\\n\\nBy putting images in a registry, you can store static and immutable application bits, including all of their dependencies, at a framework level. You then can version and deploy images in multiple environments and thus provide a consistent deployment unit.\\n\\n7\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nPrivate image registries, either hosted on-premises or in the cloud, are recommended when:\\n\\n\\n\\nYour i\", \"mages must not be shared publicly due to confidentiality.\\n\\n\\n\\nYou want to have minimum network latency between your images and your chosen deployment environment. For example, if your production environment is Azure, you probably want to store your images in Azure Container Registry so that network latency is minimal. In a similar way, if your production environment is on-premises, you might want to have an on- premises Docker Trusted Registry ava\", \"ilable within the same local network.\\n\\nRoad to modern applications based on containers\\n\\nYou\\u2019re probably reading this book because you\\u2019re planning the development of new applications or you\\u2019re assessing the impact of using Docker, Containers, and new approaches like Microservices in your company.\\n\\nThe adoption of new development paradigms must be taken with caution before starting a project, to assess the impact on your dev teams, your budget, or \", \"your infrastructure.\\n\\nMicrosoft has been working on rich guidance, sample applications, and a suite of e-books that can help you make an informed decision and guide your team through a successful development, deployment, and operations of your new applications.\\n\\nThis book belongs to a Microsoft suite of guides that cover many of the needs and challenges you\\u2019ll face during the process of developing new modern applications based on containers.\\n\\nYou\", \" can find additional Microsoft e-books related to Docker containers in the list below:\\n\\n\\n\\n.NET Microservices: Architecture for Containerized .NET Applications https://learn.microsoft.com/dotnet/architecture/microservices/\\n\\nModernize existing .NET applications with Azure cloud and Windows Containers\\n\\nhttps://learn.microsoft.com/dotnet/architecture/modernize-with-azure-containers/\\n\\n8\\n\\nCHAPTER 1 | Overview of Containers and Docker\\n\\nCHAPTER 2\\n\\nIntrod\", \"uction to the Docker application life cycle\\n\\nThe life cycle of containerized applications is a journey that begins with the developer. The developer chooses to implement containers and Docker because it eliminates frictions in deployments and IT operations, which ultimately helps everyone to be more agile, more productive end-to-end, and faster.\\n\\nContainers as the foundation for DevOps collaboration\\n\\nBy the very nature of the containers and Docke\", \"r technology, developers can share their software and dependencies easily with IT operations and production environments while eliminating the typical \\u201cit works on my machine\\u201d excuse. Containers solve application conflicts between different environments. Indirectly, containers and Docker bring developers and IT operations closer together, making it easier for them to collaborate effectively. Adopting the container workflow provides many customers\", \" with the DevOps continuity they\\u2019ve sought but previously had to implement via more complex configuration for release and build pipelines. Containers simplify the build/test/deploy pipelines in DevOps.\\n\\nFigure 2-1. Main workloads per \\u201cpersonas\\u201d in the life cycle for containerized Docker applications\\n\\nWith Docker containers, developers own what\\u2019s within the container (application and service, and dependencies to frameworks and components) and how \", \"the containers and services behave together as an application composed by a collection of services. The interdependencies of the multiple containers are defined in a docker-compose.yml file, or what could be called a deployment manifest. Meanwhile, IT operations teams (IT professionals and management) can focus on the management\\n\\n9\\n\\nCHAPTER 2 | Introduction to the Docker application life cycle\\n\\nof production environments; infrastructure; scalabil\", \"ity; monitoring; and, ultimately, ensuring that the applications are delivering properly for the end users, without having to know the contents of the various containers. Hence, the name \\u201ccontainer,\\u201d recalling the analogy to real-world shipping containers. Thus, the owners of a container\\u2019s content need not concern themselves with how the container will be shipped, and the shipping company transports a container from its point of origin to its des\", \"tination without knowing or caring about the contents. In a similar manner, developers can create and own the contents within a Docker container without the need to concern themselves with the \\u201ctransport\\u201d mechanisms.\\n\\nIn the pillar on the left side of Figure 2-1, developers write and run code locally in Docker containers by using Docker for Windows or Mac. They define the operating environment for the code by using a Dockerfile that specifies the\", \" base operating system to run as well as the build steps for building their code into a Docker image. The developers define how one or more images will interoperate using the aforementioned docker-compose.yml file deployment manifest. As they complete their local development, they push their application code plus the Docker configuration files to the code repository of their choice (that is, Git repository).\\n\\nThe DevOps pillar defines the build\\u2013C\", \"ontinuous Integration (CI) pipelines using the Dockerfile provided in the code repository. The CI system pulls the base container images from the selected Docker registry and builds the custom Docker images for the application. The images then are validated and pushed to the Docker registry used for the deployments to multiple environments.\\n\\nIn the pillar on the right, operations teams manage deployed applications and infrastructure in production\", \" while monitoring the environment and applications so that they can provide feedback and insights to the development team about how the application might be improved. Container apps are typically run in production using container orchestrators like Kubernetes, where usually Helm charts are used to configure deployment units, instead of docker-compose files.\\n\\nThe two teams are collaborating through a foundational platform (Docker containers) that \", \"provides a separation of concerns as a contract, while greatly improving the two teams\\u2019 collaboration in the application life cycle. The developers own the container contents, its operating environment, and the container interdependencies, whereas the operations teams take the built images along with the manifest and runs them in their orchestration system.\\n\\nChallenges in the application life cycle when using Docker.\\n\\nThere are many reasons that \", \"will increase the number of containerized applications in the upcoming years, and one of these reasons is the creation of applications based on microservices.\\n\\nDuring the last 15 years, the use of web services has been the base of thousands of applications, and probably, after a few years, you\\u2019ll find the same situation with microservice-based applications running on Docker containers.\\n\\nIt is also worth to mention that you can also use Docker con\", \"tainers for monolithic applications and you still get most of the benefits of Docker. Containers are not targeting only microservices.\\n\\nThe use of Docker containerization and microservices causes new challenges in the development process of your organizations and therefore, you need a solid strategy to maintain many containers\\n\\n10\\n\\nCHAPTER 2 | Introduction to the Docker application life cycle\\n\\nand microservices running on production systems. Even\", \"tually, enterprise applications will have hundreds or thousands of containers/instances running in production.\\n\\nThese challenges create new demands when using DevOps tools, so you\\u2019ll have to define new processes in your DevOps activities, and find answers for the following type of questions:\\n\\nWhich tools can I use for development, CI/CD, management and operations??\\n\\n\\n\\nHow can my company manage errors in containers when running in production?\\n\\n\\n\\nH\", \"ow can we change pieces of our software in production with minimum downtime?\\n\\n\\n\\nHow can we scale and monitor our production system?\\n\\n\\n\\nHow can we include the testing and deployment of containers in our release pipeline?\\n\\n\\n\\nHow can we use Open Source tools/platforms for containers in Microsoft Azure?\\n\\nIf you can answer all those questions, you\\u2019ll be better prepared to move your applications (existing or new apps) to Docker containers.\\n\\nIntroductio\", \"n to a generic end-to-end Docker application life cycle workflow\\n\\nFigure 2-2 presents a more detailed workflow for a Docker application life cycle, focusing in this instance on specific DevOps activities and assets.\\n\\nFigure 2-2. High-level workflow for the Docker containerized application life cycle\\n\\nEverything begins with the developer, who starts writing code in the inner-loop workflow. The inner- loop stage is where developers define everythin\", \"g that happens before pushing code into the code repository (for example, a source control system such as Git). After it\\u2019s committed, the repository triggers Continuous Integration (CI) and the rest of the workflow.\\n\\n11\\n\\nCHAPTER 2 | Introduction to the Docker application life cycle\\n\\nThe inner loop consists of typical steps like \\u201ccode,\\u201d \\u201crun,\\u201d \\u201ctest,\\u201d and \\u201cdebug,\\u201d plus the additional steps needed right before running the app locally. This is the d\", \"eveloper\\u2019s process to run and test the app as a Docker container. The inner-loop workflow will be explained in the sections that follow.\\n\\nTaking a step back to look at the end-to-end workflow, the DevOps workflow is more than a technology or a tool set, it\\u2019s a mindset that requires cultural evolution. It\\u2019s people, processes, and the appropriate tools to make your application life cycle faster and more predictable. Enterprises that adopt a contain\", \"erized workflow typically restructure their organizations to represent people and processes that match the containerized workflow.\\n\\nPracticing DevOps can help teams respond faster together to competitive pressures by replacing error-prone manual processes with automation, which results in improved traceability and repeatable workflows. Organizations also can manage environments more efficiently and realize cost savings with a combination of on-pr\", \"emises and cloud resources as well as tightly integrated tooling.\\n\\nWhen implementing your DevOps workflow for Docker applications, you\\u2019ll see that Docker technologies are present in almost every stage of the workflow, from your development box while working in the inner loop (code, run, debug), the build-test-CI phase, and, finally, the deployment of those containers to the staging and production environments.\\n\\nImprovement of quality practices he\", \"lps to identify defects early in the development cycle, which reduces the cost of fixing them. By including the environment and dependencies in the image and adopting a philosophy of deploying the same image across multiple environments, you promote a discipline of extracting the environment-specific configurations making deployments more reliable.\\n\\nRich data obtained through effective instrumentation (monitoring and diagnostics) provides insight\", \" into performance issues and user behavior to guide future priorities and investments.\\n\\nDevOps should be considered a journey, not a destination. It should be implemented incrementally through appropriately scoped projects from which you can demonstrate success, learn, and evolve.\\n\\nBenefits of DevOps for containerized applications\\n\\nHere are some of the most important benefits provided by a solid DevOps workflow:\\n\\n\\n\\nDeliver better-quality software\", \", faster and with better compliance.\\n\\n\\n\\nDrive continuous improvement and adjustments earlier and more economically.\\n\\n\\n\\nIncrease transparency and collaboration among stakeholders involved in delivering and operating software.\\n\\n\\n\\nControl costs and utilize provisioned resources more effectively while minimizing security risks.\\n\\n\\n\\nPlug and play well with many of your existing DevOps investments, including investments in open-source.\\n\\n12\\n\\nCHAPTER 2 | \", \"Introduction to the Docker application life cycle\\n\\nCHAPTER 3\\n\\nIntroduction to the Microsoft platform and tools for containerized apps\\n\\nVision: Create an adaptable, enterprise-grade, containerized application life cycle that spans your development, IT operations, and production management.\\n\\nFigure 3-1 shows the main pillars in the life cycle of Docker apps classified by the type of work delivered by multiple teams (app-development, DevOps infrastr\", \"ucture processes, and IT management and operations). Usually, in the enterprise, the profiles of \\u201cthe persona\\u201d responsible for each area are different. So are their skills.\\n\\n13\\n\\nCHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\\n\\nFigure 3-1. Main pillars in the life cycle for containerized Docker applications with Microsoft platform and tools\\n\\nA containerized Docker life-cycle workflow can be initially prescriptiv\", \"e based on \\u201cby-default product choices,\\u201d making it easier for developers to get started faster, but it\\u2019s fundamental that under the hood there must be an open framework so that it will be a flexible workflow capable of adjusting to the different contexts from each organization or enterprise. The workflow infrastructure (components and products) must be flexible enough to cover the environment that each company will have in the future, even being \", \"capable of swapping development or DevOps products to others. This flexibility, openness, and the broad choice of technologies in the platform and infrastructure are precisely the Microsoft priorities for containerized Docker applications, as explained in the chapters that follow.\\n\\nTable 3-1 demonstrates that the intention of the Azure DevOps for containerized Docker applications is to provide an open DevOps workflow so that you can choose what p\", \"roducts to use for each phase (Microsoft or third-party) while providing a simplified workflow that provides \\u201cby-default-products\\u201d already connected; thus, you can quickly get started with your enterprise-level DevOps workflow for Docker apps.\\n\\nTable 3-1. DevOps workflows, open to any technology\\n\\nHost\\n\\nMicrosoft technologies\\n\\nThird-party (Azure pluggable)\\n\\nPlatform for Docker apps\\n\\nMicrosoft Visual Studio and Visual Studio Code \\u2022 .NET \\u2022 Microsoft\", \" Azure Kubernetes Service (AKS) \\u2022 Azure Container Registry\\\\\\n\\nAny code editor (for example, Sublime) \\u2022 Any language (Node.js, Java, Go, etc.) \\u2022 Any orchestrator and scheduler \\u2022 Any Docker registry\\\\\\n\\n14\\n\\nCHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\\n\\nHost\\n\\nMicrosoft technologies\\n\\nThird-party (Azure pluggable)\\n\\nDevOps for Docker apps\\n\\nAzure DevOps Services \\u2022 Microsoft Team Foundation Server \\u2022 GitHub \\u2022 Azure Kube\", \"rnetes Service (AKS)\\\\\\n\\nGitHub, Git, Subversion, etc. \\u2022 Jenkins, Chef, Puppet, Velocity, CircleCI, TravisCI, etc. \\u2022 On-premises Docker Datacenter, Kubernetes, Mesos DC/OS, etc.\\\\\\n\\nManagement and monitoring\\n\\nAzure Monitor\\n\\nMarathon, Chronos, etc.\\\\\\n\\nThe Microsoft platform and tools for containerized Docker apps, as defined in Table 3-1, comprise the following components:\\n\\n\\n\\nPlatform for Docker Apps development The development of a service, or collect\", \"ion of services that make up an \\u201capp.\\u201d The development platform provides all the work developers requires prior to pushing their code to a shared code repository. Developing services, deployed as containers, are similar to the development of the same apps or services without Docker. You continue to use your preferred language (.NET, Node.js, Go, etc.) and preferred editor or IDE like Visual Studio or Visual Studio Code. However, rather than consi\", \"der Docker a deployment destination, you develop your services in the Docker environment. You build, run, test, and debug your code in containers locally, providing the destination environment at development time. By providing the destination environment locally, Docker containers set up what will drastically help you improve your DevOps life cycle. Visual Studio and Visual Studio Code have extensions to integrate Docker containers within your de\", \"velopment process.\\n\\n\\n\\nDevOps for Docker Apps Developers creating Docker applications can use Azure DevOps, GitHub or any other third-party product, like Jenkins, to build out a comprehensive automated application life-cycle management (ALM).\\n\\nWith Azure DevOps and/or GitHub, developers can create container-focused DevOps for a\\n\\nfast, iterative process that covers source-code control from anywhere (Azure DevOps-Git, GitHub, any remote Git reposito\", \"ry, or Subversion), Continuous Integration (CI), internal unit tests, inter-container/service integration tests, Continuous Delivery (CD), and release management (RM). Developers also can automate their Docker application releases into Azure Kubernetes Service (AKS), from development to staging and production environments.\\n\\nManagement and Monitoring IT can manage and monitor production applications and services in several ways, integrating both p\", \"erspectives in a consolidated experience.\\n\\n\\u2013\\n\\nAzure portal Azure Kubernetes Service (AKS) helps you to set up and maintain your Docker environments. You can also use other orchestrators to visualize and configure your cluster.\\n\\n\\u2013\\n\\nDocker tools You can manage your container applications using familiar tools. There\\u2019s no need to change your existing Docker management practices to move container workloads to the cloud. Use the application management \", \"tools you\\u2019re\\n\\n15\\n\\nCHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\\n\\nalready familiar with and connect via the standard API endpoints for the orchestrator of your choice. You also can use other third-party tools to manage your Docker applications or even CLI Docker tools.\\n\\nEven if you\\u2019re familiar with Linux commands, you can manage your container applications using Microsoft Windows and PowerShell with a Linux Su\", \"bsystem command line and the products (Docker, Kubernetes\\u2026) clients running on this Linux Subsystem capability. You\\u2019ll learn more about using these tools under Linux Subsystem using your favorite Microsoft Windows OS later in this book.\\n\\n\\u2013\\n\\nOpen-source tools Because AKS exposes the standard API endpoints for the orchestration engine, the most popular tools are compatible with AKS and, in most cases, will work out of the box\\u2014including visualizers,\", \" monitoring, command-line tools, and even future tools as they become available.\\n\\n\\u2013\\n\\nGitHub Advanced Security GitHub Advanced Security offers a suite of tools for securing the software supply chain that can seamlessly integrate security into the daily workflow of teams developing containerized applications.\\n\\n\\u2013\\n\\nAzure Monitor Is Azure\\u2019s solution to monitor every angle of your production environment. You can monitor production Docker applications b\", \"y just setting up its SDK into your services so that you can get system-generated log data from the applications.\\n\\nThus, Microsoft offers a complete foundation for an end-to-end containerized Docker application life cycle. However, it\\u2019s a collection of products and technologies that allow you to optionally select and integrate with existing tools and processes. The flexibility in a broad approach along with the strength in the depth of capabiliti\", \"es place Microsoft in a strong position for containerized Docker application development.\\n\\n16\\n\\nCHAPTER 3 | Introduction to the Microsoft platform and tools for containerized apps\\n\\nCHAPTER 4\\n\\nDesigning and developing containerized apps using Docker and Microsoft Azure\\n\\nVision: Design and develop scalable solutions with Docker in mind.\\n\\nThere are many great-fit use cases for containers, not just for microservices-oriented architectures, but also wh\", \"en you simply have regular services or web applications to run and you want to reduce frictions between development and production environment deployments.\\n\\nDesign Docker applications\\n\\nChapter 1 introduced the fundamental concepts regarding containers and Docker. That information is the basic level of information you need to get started. But, enterprise applications can be complex and composed of multiple services instead of a single service or c\", \"ontainer. For those optional use cases, you need to know additional approaches to design, such as Service-Oriented Architecture (SOA) and the more advanced microservices concepts and container orchestration concepts. The scope of this document is not limited to microservices but to any Docker application life cycle, therefore, it does not explore microservices architecture in depth because you can also use containers and Docker with regular SOA, \", \"background tasks or jobs, or even with monolithic application deployment approaches.\\n\\nMore info To learn more about enterprise applications and microservices architecture in depth, read the guide NET Microservices: Architecture for Containerized .NET Applications that you can also download from https://aka.ms/MicroservicesEbook.\\n\\nHowever, before you get into the application life cycle and DevOps, it\\u2019s important to know how you\\u2019re going to design \", \"and construct your application and what are your design choices.\\n\\n17\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nCommon container design principles\\n\\nAhead of getting into the development process there are a few basic concepts worth mentioning with regard to how you use containers.\\n\\nContainer equals a process\\n\\nIn the container model, a container represents a single process. By defining a container as \", \"a process boundary, you begin to create the primitives used to scale, or batch-off, processes. When you run a Docker container, you\\u2019ll see an ENTRYPOINT definition. This defines the process and the lifetime of the container. When the process completes, the container life-cycle ends. There are long-running processes, such as web servers, and short-lived processes, such as batch jobs, which might have been implemented as Microsoft Azure WebJobs. If\", \" the process fails, the container ends, and the orchestrator takes over. If the orchestrator was instructed to keep five instances running and one fails, the orchestrator will create another container to replace the failed process. In a batch job, the process is started with parameters. When the process completes, the work is complete.\\n\\nYou might find a scenario in which you want multiple processes running in a single container. In any architectu\", \"re document, there\\u2019s never a \\u201cnever,\\u201d nor is there always an \\u201calways.\\u201d For scenarios requiring multiple processes, a common pattern is to use Supervisor.\\n\\nMonolithic applications\\n\\nIn this scenario, you\\u2019re building a single and monolithic web application or service and deploying it as a container. Within the application, the structure might not be monolithic; it might comprise several libraries, components, or even layers (application layer, domai\", \"n layer, data access layer, etc.). Externally, it\\u2019s a single container, like a single process, single web application, or single service.\\n\\nTo manage this model, you deploy a single container to represent the application. To scale it, just add a few more copies with a load balancer in front. The simplicity comes from managing a single deployment in a single container or virtual machine (VM).\\n\\nFollowing the principal that a container does one thing\", \" only, and does it in one process, the monolithic pattern is in conflict. You can include multiple components/libraries or internal layers within each container, as illustrated in Figure 4-1.\\n\\n18\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-1. An example of monolithic application architecture\\n\\nA monolithic app has all or most of its functionality within a single process or container and it\\u2019s \", \"componentized in internal layers or libraries. The downside to this approach comes if or when the application grows, requiring it to scale. If the entire application scaled, it\\u2019s not really a problem. However, in most cases, a few parts of the application are the choke points that require scaling, whereas other components are used less.\\n\\nUsing the typical e-commerce example, what you likely need is to scale the product information component. Many\", \" more customers browse products than purchase them. More customers use their basket than use the payment pipeline. Fewer customers add comments or view their purchase history. And you likely have only a handful of employees, in a single region, that need to manage the content and marketing campaigns. By scaling the monolithic design, all of the code is deployed multiple times.\\n\\nIn addition to the \\u201cscale-everything\\u201d problem, changes to a single co\", \"mponent require complete retesting of the entire application as well as a complete redeployment of all the instances.\\n\\nThe monolithic approach is common, and many organizations are developing with this architectural method. Many enjoy good enough results, whereas others encounter limits. Many designed their applications in this model because the tools and infrastructure were too difficult to build SOAs, and they didn\\u2019t see the need\\u2014until the app \", \"grew.\\n\\nFrom an infrastructure perspective, each server can run many applications within the same host and have an acceptable ratio of efficiency in your resources usage, as shown in Figure 4-2.\\n\\n19\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-2. A host running multiple apps/containers\\n\\nFinally, from an availability perspective, monolithic applications must be deployed as a whole; that means t\", \"hat in case you must stop and start, all functionality and all users will be affected during the deployment window. In certain situations, the use of Azure and containers can minimize these situations and reduce the probability of downtime of your application, as you can see in Figure 4-3.\\n\\nYou can deploy monolithic applications in Azure by using dedicated VMs for each instance. Using Azure VM Scale Sets, you can scale the VMs easily.\\n\\nYou can al\", \"so use Azure App Services to run monolithic applications and easily scale instances without having to manage the VMs. Azure App Services can run single instances of Docker containers, as well, simplifying the deployment.\\n\\nYou can deploy multiple VMs as Docker hosts and run any number of containers per VM. Then, by using an Azure Load Balancer, as illustrated in the Figure 4-3, you can manage scaling.\\n\\nFigure 4-3. Multiple hosts scaling out a sing\", \"le Docker application\\n\\nYou can manage the deployment of the hosts themselves via traditional deployment techniques.\\n\\nYou can manage Docker containers from the command line by using commands like docker run and docker-compose up, and you can also automate it in Continuous Delivery (CD) pipelines and deploy to Docker hosts from Azure DevOps Services, for instance.\\n\\n20\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microso\", \"ft Azure\\n\\nMonolithic application deployed as a container\\n\\nThere are benefits to using containers to manage monolithic deployments. Scaling the instances of containers is far faster and easier than deploying additional VMs.\\n\\nDeploying updates as Docker images is far faster and network efficient. Docker containers typically start in seconds, speeding rollouts. Tearing down a Docker container is as easy as invoking the docker stop command, typically\", \" completing in less than a second.\\n\\nBecause containers are inherently immutable, by design, you never need to worry about corrupted VMs because an update script forgot to account for some specific configuration or file left on disk.\\n\\nAlthough monolithic apps can benefit from Docker, we\\u2019re touching on only the tips of the benefits. The larger benefits of managing containers come from deploying with container orchestrators that manage the various i\", \"nstances and life cycle of each container instance. Breaking up the monolithic application into subsystems that can be scaled, developed, and deployed individually is your entry point into the realm of microservices.\\n\\nTo learn about how to \\u201clift and shift\\u201d monolithic applications with containers and how you can modernize your applications, you can read this additional Microsoft guide, Modernize existing .NET applications with Azure cloud and Wind\", \"ows Containers, which you can also download as PDF from https://aka.ms/LiftAndShiftWithContainersEbook.\\n\\nPublish a single Docker container app to Azure App Service\\n\\nEither because you want to get a quick validation of a container deployed to Azure or because the app is simply a single-container app, Azure App Services provides a great way to provide scalable single-container services.\\n\\nUsing Azure App Service is intuitive and you can get up and r\", \"unning quickly because it provides great Git integration to take your code, build it in Microsoft Visual Studio, and directly deploy it to Azure. But, traditionally (with no Docker), if you needed other capabilities, frameworks, or dependencies that aren\\u2019t supported in App Services, you needed to wait for it until the Azure team updates those dependencies in App Service or switched to other services like Service Fabric, Cloud Services, or even pl\", \"ain VMs, for which you have further control and can install a required component or framework for your application.\\n\\nNow, as shown in Figure 4-4, when using Visual Studio 2022, container support in Azure App Service gives you the ability to include whatever you want in your app environment. If you added a dependency to your app, because you\\u2019re running it in a container, you get the capability of including those dependencies in your Dockerfile or \", \"Docker image.\\n\\n21\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-4. Publishing a container to Azure App Service from Visual Studio apps/containers\\n\\nFigure 4-4 also shows that the publish flow pushes an image through a Container Registry, which can be the Azure Container Registry (a registry near to your deployments in Azure and secured by Azure Active Directory groups and accounts) or any other\", \" Docker Registry like Docker Hub or on-premises registries.\\n\\nState and data in Docker applications\\n\\nIn most cases, you can think of a container as an instance of a process. A process does not maintain persistent state. While a container can write to its local storage, assuming that an instance will be around indefinitely is like assuming that a single location in memory will be durable. Container images, like processes, should be assumed to have \", \"multiple instances and that they will eventually be killed; if they\\u2019re managed with a container orchestrator, it should be assumed that they might get moved from one node or VM to another.\\n\\nThe following solutions are used to manage persistent data in Docker applications:\\n\\nFrom the Docker host, as Docker Volumes:\\n\\n\\n\\nVolumes are stored in an area of the host filesystem that\\u2019s managed by Docker.\\n\\n\\n\\nBind mounts can map to any folder in the host file\", \"system, so access can\\u2019t be controlled from a Docker process and can pose a security risk as a container could access sensitive OS folders.\\n\\n22\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\n\\n\\ntmpfs mounts are like virtual folders that only exist in the host\\u2019s memory and are never written to the filesystem.\\n\\nFrom remote storage:\\n\\n\\n\\nAzure Storage provides geo-distributable storage, providing a good long-t\", \"erm persistence solution for containers.\\n\\n\\n\\nRemote relational databases like Azure SQL Database, NoSQL databases like Azure Cosmos DB, or cache services like Redis.\\n\\nFrom the Docker container:\\n\\n\\n\\nDocker provides a feature named the overlay file system. This feature implements a copy-on- write task that stores updated information to the root file system of the container. That information \\u201clays on top of\\u201d the original image on which the container i\", \"s based. If the container is deleted from the system, those changes are lost. Therefore, while it\\u2019s possible to save the state of a container within its local storage, designing a system based on this feature would conflict with the premise of container design, which by default is stateless.\\n\\n\\n\\nHowever, Docker Volumes is now the preferred way to handle local data in Docker. If you need more information about storage in containers, check on Docker\", \" storage drivers and About images, containers, and storage drivers.\\n\\nThe following provides additional detail about these options.\\n\\nVolumes are directories mapped from the host OS to directories in containers. When code in the container has access to the directory, that access is actually to a directory on the host OS. This directory is not tied to the lifetime of the container itself, and the directory is managed by Docker and isolated from the \", \"core functionality of the host machine. Thus, data volumes are designed to persist data independently of the life of the container. If you delete a container or an image from the Docker host, the data persisted in the data volume is not deleted.\\n\\nVolumes can be named or anonymous (the default). Named volumes are the evolution of Data Volume Containers and make it easy to share data between containers. Volumes also support volume drivers that allo\", \"w you to store data on remote hosts, among other options.\\n\\nBind mounts have been available for a long time and allow the mapping of any folder to a mount point in a container. Bind mounts have more limitations than volumes and some important security issues, so volumes are the recommended option.\\n\\ntmpfs mounts are virtual folders that live only in the host\\u2019s memory and are never written to the filesystem. They are fast and secure but use memory a\", \"nd are only meant for non-persistent data.\\n\\nAs shown in Figure 4-5, regular Docker volumes can be stored outside of the containers themselves but within the physical boundaries of the host server or VM. However, Docker containers cannot access a volume from one host server or VM to another. In other words, with these volumes, it isn\\u2019t possible to manage data shared between containers that run on different Docker hosts, although it could be achiev\", \"ed with a volume driver that supports remote hosts.\\n\\n23\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-5. Volumes and external data sources for container-based applications\\n\\nIn addition, when Docker containers are managed by an orchestrator, containers might \\u201cmove\\u201d between hosts, depending on the optimizations performed by the cluster. Therefore, it isn\\u2019t recommended that you use data volumes f\", \"or business data. But they are a good mechanism to work with trace files, temporal files, or similar, that will not impact business data consistency.\\n\\nRemote data sources and cache tools like Azure SQL Database, Azure Cosmos DB, or a remote cache like Redis can be used in containerized applications the same way they are used when developing without containers. This is a proven way to store business application data.\\n\\nAzure Storage. Business data \", \"usually needs to be placed in external resources or databases, like Azure Storage. Azure Storage provides the following services in the cloud:\\n\\n\\n\\nBlob storage stores unstructured object data. A blob can be any type of text or binary data, such as document or media files (images, audio, and video files). Blob storage is also referred to as Object storage.\\n\\n\\n\\nFile storage offers shared storage for legacy applications using the standard SMB protocol\", \". Azure virtual machines and cloud services can share file data across application components via mounted shares. On-premises applications can access file data in a share via the File Service REST API.\\n\\n\\n\\nTable storage stores structured datasets. Table storage is a NoSQL key-attribute data store, which allows rapid development and fast access to large quantities of data.\\n\\nRelational databases and NoSQL databases. There are many choices for extern\", \"al databases, from relational databases like SQL Server, PostgreSQL, Oracle, or NoSQL databases like Azure Cosmos DB, MongoDB, etc. These databases are not going to be explained as part of this guide since they are a different topic altogether.\\n\\n24\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nService-oriented applications\\n\\nService-Oriented Architecture (SOA) was an overused term that meant many differ\", \"ent things to different people. But as a common denominator, SOA means that you structure the architecture of your application by decomposing it into several services (most commonly as HTTP services) that can be classified in different types like subsystems or, in other cases, as tiers.\\n\\nToday, you can deploy those services as Docker containers, which solve deployment-related issues because all of the dependencies are included in the container im\", \"age. However, when you need to scale out SOAs, you might encounter challenges if you\\u2019re deploying based on single instances. This challenge can be handled using Docker clustering software or an orchestrator. You\\u2019ll get to look at orchestrators in greater detail in the next section, when you explore microservices approaches.\\n\\nDocker containers are useful (but not required) for both traditional service-oriented architectures and the more advanced m\", \"icroservices architectures.\\n\\nAt the end of the day, the container clustering solutions are useful for both a traditional SOA architecture and for a more advanced microservices architecture in which each microservice owns its data model. And thanks to multiple databases, you can also scale out the data tier instead of working with monolithic databases shared by the SOA services. However, the discussion about splitting the data is purely about arch\", \"itecture and design.\\n\\nOrchestrating microservices and multi-container applications for high scalability and availability\\n\\nUsing orchestrators for production-ready applications is essential if your application is based on microservices or split across multiple containers. As introduced previously, in a microservice-based approach, each microservice owns its model and data so that it will be autonomous from a development and deployment point of vie\", \"w. But even if you have a more traditional application that\\u2019s composed of multiple services (like SOA), you\\u2019ll also have multiple containers or services comprising a single business application that need to be deployed as a distributed system. These kinds of systems are complex to scale out and manage; therefore, you absolutely need an orchestrator if you want to have a production-ready and scalable multi-container application.\\n\\nFigure 4-6 illust\", \"rates deployment into a cluster of an application composed of multiple microservices (containers).\\n\\n25\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-6. A cluster of containers\\n\\nIt looks like a logical approach. But how are you handling load balancing, routing, and orchestrating these composed applications?\\n\\nThe Docker CLI meets the needs of managing one container on one host, but it falls shor\", \"t when it comes to managing multiple containers deployed on multiple hosts for more complex distributed applications. In most cases, you need a management platform that will automatically start containers, scale out containers with multiple instances per image, suspend them, or shut them down when needed, and ideally also control how they access resources like the network and data storage.\\n\\nTo go beyond the management of individual containers or \", \"simple composed apps and move toward larger enterprise applications with microservices, you must turn to orchestration and clustering platforms.\\n\\nFrom an architecture and development point of view, if you\\u2019re building large, enterprise, microservices-based, applications, it\\u2019s important to understand the following platforms and products that support advanced scenarios:\\n\\n\\n\\nClusters and orchestrators. When you need to scale out applications across ma\", \"ny Docker hosts, such as with a large microservices-based application, it\\u2019s critical to be able to manage all of those hosts as a single cluster by abstracting the complexity of the underlying platform. That\\u2019s what the container clusters and orchestrators provide. Examples of orchestrators are Azure Service Fabric and Kubernetes. Kubernetes is available in Azure through Azure Kubernetes Service.\\n\\n26\\n\\nCHAPTER 4 | Designing and developing container\", \"ized apps using Docker and Microsoft Azure\\n\\n\\n\\nSchedulers. Scheduling means to have the capability for an administrator to launch containers in a cluster, so schedulers also provide a user interface for doing so. A cluster scheduler has several responsibilities: to use the cluster\\u2019s resources efficiently, to set the constraints provided by the user, to efficiently load-balance containers across nodes or hosts, and to be robust against errors while\", \" providing high availability.\\n\\nThe concepts of a cluster and a scheduler are closely related, so the products provided by different vendors often provide both sets of capabilities. The section below shows the most important platform and software choices you have for clusters and schedulers. These orchestrators are widely offered in public clouds like Azure.\\n\\nSoftware platforms for container clustering, orchestration, and scheduling\\n\\nPlatform\\n\\nCom\", \"ments\\n\\nKubernetes\\n\\nKubernetes is an open-source product that provides functionality that ranges from cluster infrastructure and container scheduling to orchestrating capabilities. It lets you automate deployment, scaling, and operations of application containers across clusters of hosts.\\n\\nKubernetes provides a container-centric infrastructure that groups application containers into logical units for easy management and discovery.\\n\\nKubernetes is m\", \"ature in Linux, less mature in Windows.\\n\\nAzure Kubernetes Service (AKS)\\n\\nAzure Kubernetes Service (AKS) is a managed Kubernetes container orchestration service in Azure that simplifies Kubernetes cluster\\u2019s management, deployment, and operations.\\n\\n27\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nPlatform\\n\\nComments\\n\\nAzure Service Fabric\\n\\nService Fabric is a Microsoft microservices platform for building a\", \"pplications. It\\u2019s an orchestrator of services and creates clusters of machines. Service Fabric can deploy services as containers or as plain processes. It can even mix services in processes with services in containers within the same application and cluster.\\n\\nService Fabric clusters can be deployed in Azure, on-premises or in any cloud. However, deployment in Azure is simplified with a managed approach.\\n\\nService Fabric provides additional and opt\", \"ional prescriptive Service Fabric programming models like stateful services and Reliable Actors.\\n\\nService Fabric is mature in Windows (years evolving in Windows), less mature in Linux.\\n\\nBoth Linux and Windows containers are supported in Service Fabric since 2017.\\n\\nAzure Service Fabric Mesh critical performance and scale as Service Fabric, but also offers a fully managed and serverless platform. You don\\u2019t need to manage a cluster, VMs, storage or \", \"networking configuration. You just focus on your application\\u2019s development. Service Fabric Mesh supports both Windows and Linux containers, allowing you to develop with any programming language and framework of your choice.\\n\\n| Azure Service Fabric Mesh offers the same reliability, mission-\\n\\nAzure Container Apps managed serverless container service for building and deploying modern apps at scale. |\\n\\n| Azure Container Apps is a\\n\\nUsing container-bas\", \"ed orchestrators in Azure\\n\\nSeveral cloud vendors offer Docker containers support plus Docker clusters and orchestration support, including Azure, Amazon EC2 Container Service, and Google Container Engine. Azure provides Docker\\n\\n28\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\ncluster and orchestrator support through Azure Kubernetes Service (AKS), Azure Service Fabric, and Azure Service Fabric Mesh.\\n\\nU\", \"sing Azure Kubernetes Service\\n\\nA Kubernetes cluster pools several Docker hosts and exposes them as a single virtual Docker host, so you can deploy multiple containers into the cluster and scale-out with any number of container instances. The cluster will handle all the complex management plumbing, like scalability, health, and so forth.\\n\\nAKS provides a way to simplify the creation, configuration, and management of a cluster of virtual machines in\", \" Azure that are preconfigured to run containerized applications. Using an optimized configuration of popular open-source scheduling and orchestration tools, AKS enables you to use your existing skills or draw on a large and growing body of community expertise to deploy and manage container-based applications on Microsoft Azure.\\n\\nAzure Kubernetes Service optimizes the configuration of popular Docker clustering open-source tools and technologies sp\", \"ecifically for Azure. You get an open solution that offers portability for both your containers and your application configuration. You select the size, the number of hosts, and the orchestrator tools, and AKS handles everything else.\\n\\n29\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-7. Kubernetes cluster\\u2019s simplified structure and topology\\n\\nFigure 4-7 shows the structure of a Kubernetes clust\", \"er where a master node (VM) controls most of the coordination of the cluster, and you can deploy containers to the rest of the nodes that are managed as a single pool from an application point of view. This allows you to scale to thousands or even tens of thousands of containers.\\n\\nDevelopment environment for Kubernetes\\n\\nIn the development environment that Docker announced in July 2018, Kubernetes can also run in a single development machine (Wind\", \"ows 10 or macOS) by just installing Docker Desktop. You can later deploy to the cloud (AKS) for further integration tests, as shown in figure 4-8.\\n\\n30\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-8. Running Kubernetes in dev machine and the cloud\\n\\nGet started with Azure Kubernetes Service (AKS)\\n\\nTo begin using AKS, you deploy an AKS cluster from the Azure portal or by using the CLI. For more \", \"information on deploying a Kubernetes cluster to Azure, see Deploy an Azure Kubernetes Service (AKS) cluster.\\n\\nThere are no fees for any of the software installed by default as part of AKS. All default options are implemented with open-source software. AKS is available for multiple virtual machines in Azure. You\\u2019re charged only for the compute instances you choose, as well as the other underlying infrastructure resources consumed, such as storage\", \" and networking. There are no incremental charges for AKS itself.\\n\\nFor further implementation information on deployment to Kubernetes based on kubectl and original .yaml files, see Deploy to Azure Kubernetes Service (AKS).\\n\\nDeploy with Helm charts into Kubernetes clusters\\n\\nWhen deploying an application to a Kubernetes cluster, you can use the original kubectl.exe CLI tool using deployment files based on the native format (.yaml files), as already\", \" mentioned in the previous section. However, for more complex Kubernetes applications such as when deploying complex microservice-based applications, it\\u2019s recommended to use Helm.\\n\\nHelm Charts helps you define, version, install, share, upgrade, or rollback even the most complex Kubernetes application. Helm is maintained by the Cloud Native Computing Foundation (CNCF) in collaboration with Microsoft, Google, Bitnami, and the Helm contributor commu\", \"nity.\\n\\nFor further implementation information on Helm charts and Kubernetes, see the section called Install eShopOnContainers using Helm.\\n\\n31\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nAdditional resources\\n\\n\\n\\nGetting started with Azure Kubernetes Service (AKS) https://learn.microsoft.com/azure/aks/kubernetes-walkthrough-portal\\n\\n\\n\\nKubernetes. The official site. https://kubernetes.io/\\n\\nUsing Azure Ser\", \"vice Fabric\\n\\nAzure Service Fabric arose from Microsoft\\u2019s transition from delivering \\u201cbox\\u201d products, which were typically monolithic in style, to delivering services. The experience of building and operating large services at scale, such as Azure SQL Database, Azure Cosmos DB, Azure Service Bus, or Cortana\\u2019s Backend, shaped Service Fabric. The platform evolved over time as more and more services adopted it. Importantly, Service Fabric had to run n\", \"ot only in Azure but also in standalone Windows Server deployments.\\n\\nThe aim of Service Fabric is to solve the hard problems of building and running a service and utilizing infrastructure resources efficiently, so that teams can solve business problems using a microservices approach.\\n\\nService Fabric provides two broad areas to help you build applications that use a microservices approach:\\n\\n\\n\\nA platform that provides system services to deploy, sca\", \"le, upgrade, detect, and restart failed services, discover service location, manage state, and monitor health. These system services in effect enable many of the characteristics of microservices described previously.\\n\\n\\n\\nProgramming APIs, or frameworks, to help you build applications as microservices: reliable actors and reliable services. You can choose any code to build your microservice, but these APIs make the job more straightforward, and the\", \"y integrate with the platform at a deeper level. This way you can get health and diagnostics information, or you can take advantage of reliable state management.\\n\\nService Fabric is agnostic with respect to how you build your service, and you can use any technology. However, it provides built-in programming APIs that make it easier to build microservices.\\n\\nAs shown in Figure 4-10, you can create and run microservices in Service Fabric either as si\", \"mple processes or as Docker containers. It\\u2019s also possible to mix container-based microservices with process-based microservices within the same Service Fabric cluster.\\n\\n32\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-10. Deploying microservices as processes or as containers in Azure Service Fabric\\n\\nIn the first image, you see microservices as processes, where each node runs one process for e\", \"ach microservice. In the second image, you see microservices as containers, where each node runs Docker with several containers, one container per microservice. Service Fabric clusters based on Linux and Windows hosts can run Docker Linux containers and Windows Containers, respectively.\\n\\nFor up-to-date information about containers support in Azure Service Fabric, see Service Fabric and containers.\\n\\nService Fabric is a good example of a platform w\", \"here you can define a different logical architecture (business microservices or Bounded Contexts) than the physical implementation. For example, if you implement Stateful Reliable Services in Azure Service Fabric, which are introduced in the next section, \\u201cStateless versus stateful microservices,\\u201d you have a business microservice concept with multiple physical services.\\n\\nAs shown in Figure 4-10, and thinking from a logical/business microservice p\", \"erspective, when implementing a Service Fabric Stateful Reliable Service, you usually will need to implement two tiers of services. The first is the back-end stateful reliable service, which handles multiple partitions (each partition is a stateful service). The second is the front-end service, or Gateway service, in charge of routing and data aggregation across multiple partitions or stateful service instances. That Gateway service also handles \", \"client-side communication with retry loops accessing the back-end service. It\\u2019s called a Gateway service if you implement your custom service, or alternatively you can also use the out-of-the-box Service Fabric reverse proxy.\\n\\n33\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-11. Business microservice with several stateful service instances and a custom gateway front end\\n\\nIn any case, when you \", \"use Service Fabric Stateful Reliable Services, you also have a logical or business microservice (Bounded Context) that\\u2019s composed of multiple physical services. Each of them, the Gateway service, and Partition service could be implemented as ASP.NET Web API services, as shown in Figure 4-11. Service Fabric has prescription to support several stateful reliable services in containers.\\n\\nIn Service Fabric, you can group and deploy groups of services \", \"as a Service Fabric Application, which is the unit of packaging and deployment for the orchestrator or cluster. Therefore, the Service Fabric Application could be mapped to this autonomous business and logical microservice boundary or Bounded Context, as well, so you could deploy these services autonomously.\\n\\nService Fabric and containers\\n\\nWith regard to containers in Service Fabric, you can also deploy services in container images within a Servi\", \"ce Fabric cluster. As Figure 4-12 shows, most of the time there will only be one container per service.\\n\\nFigure 4-12. Business microservice with several services (containers) in Service Fabric\\n\\n34\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nA Service Fabric application can run several containers accessing an external database and the whole set would be the logical boundary of a Business Microservice.\", \" However, so-called \\u201csidecar\\u201d containers (two containers that must be deployed together as part of a logical service) are also possible in Service Fabric. The important thing is that a business microservice is the logical boundary around several cohesive elements. In many cases, it might be a single service with a single data model, but in some other cases you might have several physical services as well.\\n\\nNote that you can mix services in proces\", \"ses, and services in containers, in the same Service Fabric application, as shown in Figure 4-13.\\n\\nFigure 4-13. Business microservice mapped to a Service Fabric application with containers and stateful services\\n\\nFor more information about container support in Azure Service Fabric, see Service Fabric and containers.\\n\\nStateless versus stateful microservices\\n\\nAs mentioned earlier, each microservice (logical Bounded Context) must own its domain model\", \" (data and logic). In the case of stateless microservices, the databases will be external, employing relational options like SQL Server, or NoSQL options like Azure Cosmos DB or MongoDB.\\n\\nBut the services themselves can also be stateful in Service Fabric, which means that the data resides within the microservice. This data might exist not just on the same server, but within the microservice process, in memory and persisted on hard drives and repl\", \"icated to other nodes. Figure 4-14 shows the different approaches.\\n\\n35\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-14. Stateless versus stateful microservices\\n\\nIn stateless services, the state (persistence, database) is kept out of the microservice. In stateful services, state is kept inside the microservice. A stateless approach is perfectly valid and is easier to implement than stateful mi\", \"croservices, since the approach is similar to traditional and well-known patterns. But stateless microservices impose latency between the process and data sources. They also involve more moving pieces when you\\u2019re trying to improve performance with additional cache and queues. The result is that you can end up with complex architectures that have too many tiers.\\n\\nIn contrast, stateful microservices can excel in advanced scenarios, because there\\u2019s \", \"no latency between the domain logic and data. Heavy data processing, gaming back ends, databases as a service, and other low-latency scenarios all benefit from stateful services, which enable local state for faster access.\\n\\nStateless and stateful services are complementary. For instance, as you can see in the right diagram in Figure 4-14, a stateful service can be split into multiple partitions. To access those partitions, you might need a statel\", \"ess service acting as a gateway service that knows how to address each partition based on partition keys.\\n\\nStateful services do have drawbacks. They impose a high complexity level to be scaled out. Functionality that would usually be implemented by external database systems must be addressed for tasks such as data replication across stateful microservices and data partitioning. However, this is one of the areas where an orchestrator like Azure Se\", \"rvice Fabric with its stateful reliable services can help the most\\u2014by simplifying the development and lifecycle of stateful microservices using the Reliable Services API and Reliable Actors.\\n\\nOther microservice frameworks that allow stateful services, support the Actor pattern, and improve fault tolerance and latency between business logic and data are Microsoft Orleans, from Microsoft Research, and Akka.NET. Both frameworks are currently improvi\", \"ng their support for Docker.\\n\\nRemember that Docker containers are themselves stateless. If you want to implement a stateful service, you need one of the additional prescriptive and higher-level frameworks noted earlier.\\n\\nUsing Azure Service Fabric Mesh\\n\\nAzure Service Fabric Mesh is a fully managed service that enables developers to build and deploy mission critical applications without managing any infrastructure. Use Service Fabric Mesh to build\", \" and run secure, distributed microservices applications that scale on demand.\\n\\n36\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nAs shown in figure 4-15, applications hosted on Service Fabric Mesh run and scale without you worrying about the infrastructure powering it.\\n\\nFigure 4-15. Deploying a microservice/containers application to Service Fabric Mesh\\n\\nUnder the covers, Service Fabric Mesh consists of \", \"clusters of thousands of machines. All cluster operations are hidden from the developer. You simply need to upload your containers and specify resources you need, availability requirements, and resource limits. Service Fabric Mesh automatically allocates the infrastructure requested by your application deployment and also handles infrastructure failures, making sure your applications are highly available. You only need to care about the health an\", \"d responsiveness of your application, not the infrastructure.\\n\\nFor further information, see the Service Fabric Mesh documentation.\\n\\nChoosing orchestrators in Azure\\n\\nThe following table provides guidance on what orchestrator to use depending on workloads and OS focus.\\n\\nFigure 4-16. Orchestrator selection in Azure guidance\\n\\n37\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nDeploy to Azure Kubernetes Servi\", \"ce (AKS)\\n\\nYou can interact with AKS using your preferred client operating system (Windows, macOS, or Linux) with Azure command-line interface (Azure CLI) installed. For more details, refer Azure CLI documentation and Installation guide for the available environments.\\n\\nCreate the AKS environment in Azure\\n\\nThere are several ways to create the AKS Environment. It can be done by using Azure CLI commands or by using the Azure portal.\\n\\nHere you can exp\", \"lore some examples using the Azure CLI to create the cluster and the Azure portal to review the results. You also need to have Kubectl and Docker in your development machine.\\n\\nCreate the AKS cluster\\n\\nCreate the AKS cluster using this command (the resource group must exist):\\n\\naz aks create --resource-group explore-docker-aks-rg --name explore-docker-aks --node- vm-size Standard_B2s --node-count 1 --generate-ssh-keys --location westeurope\\n\\nNote\\n\\nTh\", \"e --node-vm-size and --node-count parameter values are good enough for a sample/dev application.\\n\\nAfter the creation job finishes, you can see:\\n\\n\\n\\nThe AKS cluster created in the initial resource group\\n\\n\\n\\nA new, related resource group, containing the resources related to the AKS cluster, as show in the following images.\\n\\nThe initial resource group, with the AKS cluster:\\n\\n38\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and \", \"Microsoft Azure\\n\\nFigure 4-17. AKS Resource Group view from Azure.\\n\\nThe AKS cluster resource group:\\n\\nFigure 4-18. AKS view from Azure.\\n\\nImportant\\n\\nIn general, you shouldn\\u2019t need to modify the resources in the AKS cluster resource group. For example, the resource group is deleted when you delete the AKS cluster.\\n\\nYou can also view the node created using Azure CLI and Kubectl.\\n\\nFirst, getting the credentials:\\n\\naz aks get-credentials --resource-group\", \" explore-docker-aks-rg --name explore-docker- aks\\n\\n39\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-19. aks get-credentials command result.\\n\\nAnd then, getting nodes from Kubectl:\\n\\nkubectl get nodes\\n\\nFigure 4-20. kubectl get nodes command result.\\n\\nDevelopment environment for Docker apps\\n\\nDevelopment tools choices: IDE or editor\\n\\nNo matter if you prefer a full and powerful IDE or a lightweight a\", \"nd agile editor, Microsoft has you covered when it comes to developing Docker applications.\\n\\nVisual Studio Code and Docker CLI (cross-platform tools for Mac, Linux, and Windows)\\n\\nIf you prefer a lightweight, cross-platform editor supporting any development language, you can use Visual Studio Code and Docker CLI. These products provide a simple yet robust experience, which is critical for streamlining the developer workflow. By installing \\u201cDocker \", \"for Mac\\u201d or \\u201cDocker for Windows\\u201d (development environment), Docker developers can use a single Docker CLI to build apps for both Windows or Linux (runtime environment). Plus, Visual Studio Code supports extensions for Docker with IntelliSense for Dockerfiles and shortcut-tasks to run Docker commands from the editor.\\n\\nNote\\n\\nTo download Visual Studio Code, go to https://code.visualstudio.com/download.\\n\\nTo download Docker for Mac and Windows, go to \", \"https://www.docker.com/products/docker.\\n\\nVisual Studio with Docker Tools (Windows development machine)\\n\\nIt\\u2019s recommended that you use Visual Studio 2022 or later with the built-in Docker Tools enabled. With Visual Studio, you can develop, run, and validate your applications directly in the chosen Docker environment. Press F5 to debug your application (single container or multiple containers) directly in a Docker host, or press Ctrl+F5 to edit and\", \" refresh your app without having to rebuild the container. It\\u2019s the simplest and most powerful choice for Windows developers to create Docker containers for Linux or Windows.\\n\\n40\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nVisual Studio for Mac (Mac development machine)\\n\\nYou can use Visual Studio for Mac when developing Docker-based applications. Visual Studio for Mac offers a richer IDE when compare\", \"d to Visual Studio Code for Mac.\\n\\nLanguage and framework choices\\n\\nYou can develop Docker applications using Microsoft tools with most modern languages. The following is an initial list, but you\\u2019re not limited to it:\\n\\n\\n\\n.NET and ASP.NET Core\\n\\n\\n\\nNode.js\\n\\n\\n\\nGo\\n\\n\\n\\nJava\\n\\n\\n\\nRuby\\n\\n\\n\\nPython\\n\\nBasically, you can use any modern language supported by Docker in Linux or Windows.\\n\\nInner-loop development workflow for Docker apps\\n\\nBefore triggering the outer-loo\", \"p workflow spanning the entire DevOps cycle, it all begins on each developer\\u2019s machine, coding the app itself, using their preferred languages or platforms, and testing it locally (Figure 4-21). But in every case, you\\u2019ll have an important point in common, no matter what language, framework, or platforms you choose. In this specific workflow, you\\u2019re always developing and testing Docker containers in no other environments, but locally.\\n\\nFigure 4-21\", \". Inner-loop development context\\n\\nThe container or instance of a Docker image will contain these components:\\n\\n\\n\\nAn operating system selection (for example, a Linux distribution or Windows)\\n\\n\\n\\nFiles added by the developer (for example, app binaries)\\n\\n\\n\\nConfiguration (for example, environment settings and dependencies)\\n\\n\\n\\nInstructions for what processes to run by Docker\\n\\nYou can set up the inner-loop development workflow that utilizes Docker as the\", \" process (described in the next section). Consider that the initial steps to set up the environment are not included, because you only need to do it once.\\n\\n41\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nBuilding a single app within a Docker container using Visual Studio Code and Docker CLI\\n\\nApps are made up from your own services plus additional libraries (dependencies).\\n\\nFigure 4-22 shows the basic \", \"steps that you usually need to carry out when building a Docker app, followed by detailed descriptions of each step.\\n\\nFigure 4-22. High-level workflow for the life cycle for Docker containerized applications using Docker CLI\\n\\nStep 1: Start coding in Visual Studio Code and create your initial app/service baseline\\n\\nThe way you develop your application is similar to the way you do it without Docker. The difference is that while developing, you\\u2019re de\", \"ploying and testing your application or services running within Docker containers placed in your local environment (like a Linux VM or Windows).\\n\\nSetting up your local environment\\n\\nWith the latest versions of Docker Desktop for Mac and Windows, it\\u2019s easier than ever to develop Docker applications, and the setup is straightforward.\\n\\nTip\\n\\nFor instructions on setting up Docker Desktop for Windows, go to https://docs.docker.com/docker- for-windows/.\\n\", \"\\nFor instructions on setting up Docker Desktop for Mac, go to https://docs.docker.com/docker-for- mac/.\\n\\nIn addition, you\\u2019ll need a code editor so that you can actually develop your application while using Docker CLI.\\n\\n42\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nMicrosoft provides Visual Studio Code, which is a lightweight code editor that\\u2019s supported on Windows, Linux, and macOS, and provides Int\", \"elliSense with support for many languages (JavaScript, .NET, Go, Java, Ruby, Python, and most modern languages), debugging, integration with Git and extensions support. This editor is a great fit for macOS and Linux developers. In Windows, you also can use Visual Studio.\\n\\nTip\\n\\nFor instructions on installing Visual Studio Code for Windows, Linux, or macOS, go to https://code.visualstudio.com/docs/setup/setup-overview/.\\n\\nFor instructions on setting\", \" up Docker for Mac, go to https://docs.docker.com/docker-for-mac/.\\n\\nYou can work with Docker CLI and write your code using any code editor, but using Visual Studio Code with the Docker extension makes it easy to author Dockerfile and docker-compose.yml files in your workspace. You can also run tasks and scripts from the Visual Studio Code IDE to execute Docker commands using the Docker CLI underneath.\\n\\nThe Docker extension for VS Code provides th\", \"e following features:\\n\\n\\n\\nAutomatic Dockerfile and docker-compose.yml file generation\\n\\n\\n\\nSyntax highlighting and hover tips for docker-compose.yml and Dockerfile files\\n\\n\\n\\nIntelliSense (completions) for Dockerfile and docker-compose.yml files\\n\\n\\n\\nLinting (errors and warnings) for Dockerfile files\\n\\n\\n\\nCommand Palette (F1) integration for the most common Docker commands\\n\\n\\n\\nExplorer integration for managing Images and Containers\\n\\n\\n\\nDeploy images from Do\", \"ckerHub and Azure Container Registries to Azure App Service\\n\\nTo install the Docker extension, press Ctrl+Shift+P, type ext install, and then run the Install Extension command to bring up the Marketplace extension list. Next, type docker to filter the results, and then select the Docker Support extension, as depicted in Figure 4-23.\\n\\nFigure 4-23. Installing the Docker Extension in Visual Studio Code\\n\\n43\\n\\nCHAPTER 4 | Designing and developing contai\", \"nerized apps using Docker and Microsoft Azure\\n\\nStep 2: Create a DockerFile related to an existing image (plain OS or dev environments like .NET, Node.js, and Ruby)\\n\\nYou\\u2019ll need a DockerFile per custom image to be built and per container to be deployed. If your app is made up of single custom service, you\\u2019ll need a single DockerFile. But if your app is composed of multiple services (as in a microservices architecture), you\\u2019ll need one Dockerfile p\", \"er service.\\n\\nThe DockerFile is commonly placed in the root folder of your app or service and contains the required commands so that Docker knows how to set up and run that app or service. You can create your DockerFile and add it to your project along with your code (node.js, .NET, etc.), or, if you\\u2019re new to the environment, take a look at the following Tip.\\n\\nTip\\n\\nYou can use the Docker extension to guide you when using the Dockerfile and docker\", \"-compose.yml files related to your Docker containers. Eventually, you\\u2019ll probably write these kinds of files without this tool, but using the Docker extension is a good starting point that will accelerate your learning curve.\\n\\nIn Figure 4-24, you can see the steps to add the docker files to a project by using the Docker Extension for VS Code:\\n\\n1. Open the command palette, type \\u201cdocker\\u201d and select \\u201cAdd Docker Files to Workspace\\u201d.\\n\\n2.\\n\\nSelect Appli\", \"cation Platform (ASP.NET Core)\\n\\n3.\\n\\nSelect Operating System (Linux)\\n\\n4.\\n\\nInclude optional Docker Compose files\\n\\n5.\\n\\nEnter ports to publish (80, 443)\\n\\n6.\\n\\nSelect the project\\n\\n44\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-24. Docker files added using the Add Docker files to Workspace command\\n\\nWhen you add a DockerFile, you specify what base Docker image you\\u2019ll be using (like using FROM mcr.mi\", \"crosoft.com/dotnet/aspnet). You\\u2019ll usually build your custom image on top of a base image that you get from any official repository at the Docker Hub registry (like an image for .NET or the one for Node.js).\\n\\nTip\\n\\nYou\\u2019ll have to repeat this procedure for every project in your application. However, the extension will ask to overwrite the generated docker-compose file after the first time. You should reply to not overwrite it, so the extension crea\", \"tes separate docker-compose files, that you can then merge by hand, prior to running docker-compose.\\n\\nUse an existing official Docker image\\n\\nUsing an official repository of a language stack with a version number ensures that the same language features are available on all machines (including development, testing, and production).\\n\\nThe following is a sample DockerFile for a .NET container:\\n\\n45\\n\\nCHAPTER 4 | Designing and developing containerized ap\", \"ps using Docker and Microsoft Azure\\n\\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base WORKDIR /app EXPOSE 80 EXPOSE 443\\n\\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build WORKDIR /src COPY [\\\"src/WebApi/WebApi.csproj\\\", \\\"src/WebApi/\\\"] RUN dotnet restore \\\"src/WebApi/WebApi.csproj\\\" COPY . . WORKDIR \\\"/src/src/WebApi\\\" RUN dotnet build \\\"WebApi.csproj\\\" -c Release -o /app/build\\n\\nFROM build AS publish RUN dotnet publish \\\"WebApi.csproj\\\" -c Release -o /app/publ\", \"ish\\n\\nFROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\\\"dotnet\\\", \\\"WebApi.dll\\\"]\\n\\nIn this case, the image is based on version 6.0 of the official ASP.NET Core Docker image (multi-arch for Linux and Windows), as per the line FROM mcr.microsoft.com/dotnet/aspnet:6.0. (For more information about this topic, see the ASP.NET Core Docker Image page and the .NET Docker Image page).\\n\\nIn the DockerFile, you can also instruct Doc\", \"ker to listen to the TCP port that you\\u2019ll use at run time (such as port 80 or 443).\\n\\nYou can specify additional configuration settings in the Dockerfile, depending on the language and framework you\\u2019re using. For instance, the ENTRYPOINT line with [\\\"dotnet\\\", \\\"WebMvcApplication.dll\\\"] tells Docker to run a .NET application. If you\\u2019re using the SDK and the .NET CLI (dotnet CLI) to build and run the .NET application, this setting would be different. T\", \"he key point here is that the ENTRYPOINT line and other settings depend on the language and platform you choose for your application.\\n\\nTip\\n\\nFor more information about building Docker images for .NET applications, see https://learn.microsoft.com/dotnet/core/docker/build-container.\\n\\nTo learn more about building your own images, go to https://docs.docker.com/engine/tutorials/dockerimages/.\\n\\nUse multi-arch image repositories\\n\\nA single image name in a\", \" repo can contain platform variants, such as a Linux image and a Windows image. This feature allows vendors like Microsoft (base image creators) to create a single repo to cover multiple platforms (that is, Linux and Windows). For example, the dotnet/aspnet repository available in the Docker Hub registry provides support for Linux and Windows Nano Server by using the same image name.\\n\\nPulling the dotnet/aspnet image from a Windows host pulls the \", \"Windows variant, whereas pulling the same image name from a Linux host pulls the Linux variant.\\n\\n46\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nCreate your base image from scratch\\n\\nYou can create your own Docker base image from scratch as explained in this article from Docker. This scenario is probably not the best for you if you\\u2019re just starting with Docker, but if you want to set the specific bits \", \"of your own base image, you can do it.\\n\\nStep 3: Create your custom Docker images embedding your service in it\\n\\nFor each custom service that comprises your app, you\\u2019ll need to create a related image. If your app is made up of a single service or web app, you\\u2019ll need just a single image.\\n\\nNote\\n\\nWhen taking into account the \\u201couter-loop DevOps workflow\\u201d, the images will be created by an automated build process whenever you push your source code to a \", \"Git repository (Continuous Integration), so the images will be created in that global environment from your source code.\\n\\nBut before you consider going to that outer-loop route, you need to ensure that the Docker application is actually working properly so that they don\\u2019t push code that might not work properly to the source control system (Git, etc.).\\n\\nTherefore, each developer first needs to do the entire inner-loop process to test locally and c\", \"ontinue developing until they want to push a complete feature or change to the source control system.\\n\\nTo create an image in your local environment and using the DockerFile, you can use the docker build command, as shown in Figure 4-25, because it already tags the image for you and builds the images for all services in the application with a simple command.\\n\\nFigure 4-25. Running docker build\\n\\nOptionally, instead of directly running docker build f\", \"rom the project folder, you first can generate a deployable folder with the .NET libraries needed by using the run dotnet publish command, and then run docker build.\\n\\nThis example creates a Docker image with the name webapi:latest (:latest is a tag, like a specific version). You can take this step for each custom image you need to create for your composed Docker\\n\\n47\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microso\", \"ft Azure\\n\\napplication with several containers. However, we\\u2019ll see in the next section that it\\u2019s easier to do this using docker-compose.\\n\\nYou can find the existing images in your local repository (your development machine) by using the docker images command, as illustrated in Figure 4-26.\\n\\nFigure 4-26. Viewing existing images using docker images\\n\\nStep 4: Define your services in docker-compose.yml when building a composed Docker app with multiple s\", \"ervices\\n\\nWith the docker-compose.yml file, you can define a set of related services to be deployed as a composed application with the deployment commands explained in the next step section.\\n\\nCreate that file in your main or root solution folder; it should have content similar to that shown in this docker-compose.yml file:\\n\\nversion: \\\"3.4\\\"\\n\\nservices: webapi: image: webapi build: context: . dockerfile: src/WebApi/Dockerfile ports: - 51080:80 depends\", \"_on: - redis environment: - ASPNETCORE_ENVIRONMENT=Development - ASPNETCORE_URLS=http://+:80\\n\\nwebapp: image: webapp build: context: . dockerfile: src/WebApp/Dockerfile ports: - 50080:80 environment: - ASPNETCORE_ENVIRONMENT=Development - ASPNETCORE_URLS=http://+:80 - WebApiBaseAddress=http://webapi\\n\\nredis: image: redis\\n\\nIn this particular case, this file defines three services: the web API service (your custom service), a web application, and the\", \" Redis service (a popular cache service). Each service will be deployed as a container, so you need to use a concrete Docker image for each. For this particular application:\\n\\n48\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\n\\n\\nThe web API service is built from the DockerFile in the src/WebApi/Dockerfile directory.\\n\\n\\n\\nThe host port 51080 is forwarded to the exposed port 80 on the webapi container.\\n\\n\\n\\nThe\", \" web API service depends on the Redis service\\n\\n\\n\\nThe web application accesses the web API service using the internal address: http://webapi.\\n\\n\\n\\nThe Redis service uses the latest public redis image pulled from the Docker Hub registry. Redis is a popular cache system for server-side applications.\\n\\nStep 5: Build and run your Docker app\\n\\nIf your app has only a single container, you just need to run it by deploying it to your Docker Host (VM or physic\", \"al server). However, if your app is made up of multiple services, you need to compose it, too. Let\\u2019s see the different options.\\n\\nOption A: Run a single container or service\\n\\nYou can run the Docker image by using the docker run command, as shown here:\\n\\ndocker run -t -d -p 50080:80 webapp:latest\\n\\nFor this particular deployment, we\\u2019ll be redirecting requests sent to port 50080 on the host to the internal port 80.\\n\\nOption B: Compose and run a multipl\", \"e-container application\\n\\nIn most enterprise scenarios, a Docker application will be composed of multiple services. For these cases, you can run the docker-compose up command (Figure 4-27), which will use the docker- compose.yml file that you created previously. Running this command builds all custom images and deploys the composed application with all of its related containers.\\n\\n49\\n\\nCHAPTER 4 | Designing and developing containerized apps using Do\", \"cker and Microsoft Azure\\n\\nFigure 4-27. Results of running the \\u201cdocker-compose up\\u201d command\\n\\nAfter you run docker-compose up, you deploy your application and its related container(s) into your Docker Host, as illustrated in Figure 4-28, in the VM representation.\\n\\nFigure 4-28. VM with Docker containers deployed\\n\\nStep 6: Test your Docker application (locally, in your local CD VM)\\n\\nThis step will vary depending on what your app is doing.\\n\\nIn a simple \", \".NET Web API \\u201cHello World\\u201d deployed as a single container or service, you\\u2019d just need to access the service by providing the TCP port specified in the DockerFile.\\n\\nOn the Docker host, open a browser and navigate to that site; you should see your app/service running, as demonstrated in Figure 4-29.\\n\\n50\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-29. Testing your Docker application locally by \", \"using the browser\\n\\nNote that it\\u2019s using port 50080, but internally it\\u2019s being redirected to port 80, because that\\u2019s how it was deployed with docker compose, as explained earlier.\\n\\nYou can test this by using the browser using CURL from the terminal, as depicted in Figure 4-30.\\n\\nFigure 4-30. Testing a Docker application locally by using CURL\\n\\nDebugging a container running on Docker\\n\\nVisual Studio Code supports debugging Docker if you\\u2019re using Node.\", \"js and other platforms like .NET containers.\\n\\n51\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nYou also can debug .NET or .NET Framework containers in Docker when using Visual Studio for Windows or Mac, as described in the next section.\\n\\nTip\\n\\nTo learn more about debugging Node.js Docker containers, see https://learn.microsoft.com/archive/blogs/user_ed/visual-studio-code-new-features-13-big- debugging-u\", \"pdates-rich-object-hover-conditional-breakpoints-node-js-mono-more.\\n\\nUse Docker Tools in Visual Studio on Windows\\n\\nThe developer workflow when using the Docker Tools included in Visual Studio 2022 version 17.0 and later, is similar to using Visual Studio Code and Docker CLI (in fact, it\\u2019s based on the same Docker CLI), but it\\u2019s easier to get started, simplifies the process, and provides greater productivity for the build, run, and compose tasks. \", \"It can also run and debug your containers via the usual F5 and Ctrl+F5keys from Visual Studio. You can even debug a whole solution if its containers are defined in the same docker-compose.yml file at the solution level.\\n\\nConfigure your local environment\\n\\nWith the latest versions of Docker for Windows, it\\u2019s easier than ever to develop Docker applications because the setup is straightforward, as explained in the following references.\\n\\nTip\\n\\nTo learn\", \" more about installing Docker for Windows, go to (https://docs.docker.com/docker-for- windows/).\\n\\nDocker support in Visual Studio\\n\\nThere are two levels of Docker support you can add to a project. In ASP.NET Core projects, you can just add a Dockerfile file to the project by enabling Docker support. The next level is container orchestration support, which adds a Dockerfile to the project (if it doesn\\u2019t already exist) and a docker- compose.yml file\", \" at the solution level. Container orchestration support, via Docker Compose, is available in Visual Studio 2022 versions 17.0. Container orchestration support is an opt-in feature in Visual Studio 2022 versions 17.0 or later. Visual Studio 2022 also supports Kubernetes/Helm deployment.\\n\\nThe Add > Docker Support and Add > Container Orchestrator Support commands are located on the right-click menu (or context menu) of the project node for an ASP.NE\", \"T Core project in Solution Explorer, as shown in Figure 4-31:\\n\\n52\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-31. Adding Docker support to a Visual Studio project\\n\\nAdd Docker support\\n\\nBesides the option to add Docker support to an existing application, as shown in the previous section, you can also enable Docker support during project creation by selecting Enable Docker Support in the New AS\", \"P.NET Core Web Application dialog box that opens after you click OK in the New Project dialog box, as shown in Figure 4-32.\\n\\n53\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-32. Enable Docker support during project creation in Visual Studio\\n\\nWhen you add or enable Docker support, Visual Studio adds a Dockerfile file to the project, that includes references to all required project from the solu\", \"tion.\\n\\nAdd container orchestration support\\n\\nWhen you want to compose a multi-container solution, add container orchestration support to your projects. This lets you run and debug a group of containers (a whole solution) at the same time if they\\u2019re defined in the same docker-compose.yml file.\\n\\nTo add container orchestration support, right-click on the project node in Solution Explorer, and choose Add > Container Orchestration Support. Then choose \", \"Docker Compose to manage the containers.\\n\\nAfter you add container orchestration support to your project, you see a Dockerfile added to the project and a docker-compose folder added to the solution in Solution Explorer, as shown in Figure 4-33:\\n\\n54\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-33. Docker files in Solution Explorer in Visual Studio\\n\\nIf docker-compose.yml already exists, Visual S\", \"tudio just adds the required lines of configuration code to it.\\n\\nConfigure Docker tools\\n\\nFrom the main menu, choose Tools > Options, and expand Container Tools > Settings. The container tools settings appear.\\n\\n55\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-34. Docker Tools Options\\n\\nFor more detailed configurations refer to Container Tools settings\\n\\nTip\\n\\nFor further details on the services im\", \"plementation and use of Visual Studio Tools for Docker, read the following articles:\\n\\nUse the Containers tool window to view container details such as the filesystem, logs, environment, ports, and more: https://learn.microsoft.com/visualstudio/containers/view-and-diagnose-containers Debug apps in a local Docker container: https://learn.microsoft.com/visualstudio/containers/edit-and- refresh\\n\\nDeploy an ASP.NET container to a container registry usi\", \"ng Visual Studio: https://learn.microsoft.com/visualstudio/containers/hosting-web-apps-in-docker\\n\\nUsing Windows PowerShell commands in a DockerFile to set up Windows Containers (Docker standard based)\\n\\nWith Windows Containers, you can convert your existing Windows applications to Docker images and deploy them with the same tools as the rest of the Docker ecosystem.\\n\\n56\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Micr\", \"osoft Azure\\n\\nTo use Windows Containers, you just need to write Windows PowerShell commands in the DockerFile, as demonstrated in the following example:\\n\\nFROM mcr.microsoft.com/windows/servercore:ltsc2019 LABEL Description=\\\"IIS\\\" Vendor=\\\"Microsoft\\\" Version=\\\"10\\\" RUN powershell Get-WindowsFeature web-server RUN powershell Install-windowsfeature web-server RUN powershell add-windowsfeature web-asp-net45 CMD [ \\\"ping\\\", \\\"localhost\\\", \\\"-t\\\" ]\\n\\nIn this case,\", \" we\\u2019re using Windows PowerShell to install a Windows Server Core base image as well as IIS.\\n\\nIn a similar way, you also could use Windows PowerShell commands to set up additional components like the traditional ASP.NET 4.x and .NET Framework 4.6 or any other Windows software, as shown here:\\n\\nRUN powershell add-windowsfeature web-asp-net45\\n\\nBuild ASP.NET Core applications deployed as Linux containers into an AKS/Kubernetes orchestrator\\n\\nAzure Kube\", \"rnetes Services (AKS) is Azure\\u2019s managed Kubernetes orchestrations services that simplify container deployment and management.\\n\\nThe main features of AKS are:\\n\\n\\n\\nAn Azure-hosted control plane.\\n\\n\\n\\nAutomated upgrades.\\n\\n\\n\\nSelf-healing.\\n\\n\\n\\nUser-configurable scaling.\\n\\n\\n\\nSimpler user experience for both developers and cluster operators.\\n\\nThe following examples explore the creation of an ASP.NET Core 6.0 application that runs on Linux and deploys to an A\", \"KS Cluster in Azure. Development is done using Visual Studio 2022 version 17.0.\\n\\nCreating the ASP.NET Core Project using Visual Studio 2022\\n\\nASP.NET Core is a general-purpose development platform maintained by Microsoft and the .NET community on GitHub. It\\u2019s cross-platform, supporting Windows, macOS and Linux, and can be used in device, cloud, and embedded/IoT scenarios.\\n\\nThis example uses a couple of simple projects based on Visual Studio templa\", \"tes, so you don\\u2019t need much additional knowledge to create the sample. You only have to create the project using a standard template that includes all the elements to run a small project with a REST API and a Web App with Razor pages, using ASP.NET Core 6.0 technology.\\n\\nFor reference, you can download the sample from .NET Application Architecture\\u2019s repo explore- docker.\\n\\n57\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and\", \" Microsoft Azure\\n\\nFigure 4-35. Creating an ASP.NET Core Web Application in Visual Studio 2022.\\n\\nTo create the sample project in Visual Studio, select File > New > Project, select the Web project type and then the ASP.NET Core Web Api template. You can also search for the template if you need it.\\n\\nThen enter the application name and location as shown in the next image.\\n\\n58\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and M\", \"icrosoft Azure\\n\\nFigure 4-36. Enter the project name and location in Visual Studio 2022.\\n\\nVerify that you\\u2019ve selected ASP.NET Core 6.0 as the framework. .NET 6 is included in the latest release of Visual Studio 2022 and is automatically installed and configured for you when you install Visual Studio.\\n\\n59\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-37. Selecting ASP.NET CORE 6.0 and Web API pr\", \"oject type\\n\\nNotice Docker support is not enabled now. You\\u2019ll do that in the next step after the project creation. You\\u2019ll also notice that by default controller option is checked. You can uncheck that if you want to Create a minimal web API with ASP.NET Core.\\n\\nTo show you can \\u201cDockerize\\u201d your project at any time, you\\u2019ll add Docker support now. So right-click on the project node in Solution Explorer and select Add > Docker support on the context me\", \"nu.\\n\\n60\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-38. Adding Docker support to an existing project\\n\\nTo complete adding Docker support, you can choose Windows or Linux. In this case, select Linux.\\n\\nFigure 4-39. Selecting Linux containers.\\n\\n61\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nWith these simple steps, you have your ASP.NET Core 6.0 app\", \"lication running on a Linux container.\\n\\nIn a similar way, you can also add a very simple WebApp project (Figure 4-40) to consume the web API endpoint, although the details can be seen in the code repo.\\n\\nAfter that, you add orchestrator support for your WebApi project as shown next, in image 4-40.\\n\\nFigure 4-40. Adding orchestrator support to WebApi project.\\n\\nWhen you choose the Docker Compose option, which is fine for local development, Visual Stu\", \"dio adds the docker-compose project, with the docker-compose files as shown in image 4-41.\\n\\n62\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-41. Adding orchestrator support to WebApi project.\\n\\nThe initial files added are similar to these ones:\\n\\ndocker-compose.yml\\n\\nversion: \\\"3.4\\\"\\n\\nservices: webapi: image: ${DOCKER_REGISTRY-}webapi build: context: . dockerfile: WebApi/Dockerfile\\n\\nwebapp: image: \", \"${DOCKER_REGISTRY-}webapp build: context: . dockerfile: WebApp/Dockerfile\\n\\ndocker-compose.override.yml\\n\\nversion: \\\"3.4\\\"\\n\\nservices: webapi: environment: - ASPNETCORE_ENVIRONMENT=Development - ASPNETCORE_URLS=https://+:443;http://+:80 ports: - \\\"80\\\" - \\\"443\\\" volumes: - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro - ${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro webapp: environment: - ASPNETCORE_ENVIRONMENT=Development - ASPNETCORE\", \"_URLS=https://+:443;http://+:80 ports: - \\\"80\\\" - \\\"443\\\"\\n\\n63\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nvolumes: - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro - ${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro\\n\\nTo run your app with Docker Compose, you just have to make a few tweaks to docker- compose.override.yml.\\n\\nservices: webapi: #... ports: - \\\"51080:80\\\" - \\\"51443:443\\\" #... webapp\", \": environment: #... - WebApiBaseAddress=http://webapi ports: - \\\"50080:80\\\" - \\\"50443:443\\\" #...\\n\\nNow you can run your application with the F5 key, or by using the Play button, or the Ctrl+F5 key, selecting the docker-compose project, as shown in image 4-42.\\n\\nFigure 4-42. Adding orchestrator support to WebApi project.\\n\\nWhen running the docker-compose application as explained, you get:\\n\\n1.\\n\\nThe images built and containers created as per the docker-com\", \"pose file.\\n\\n2.\\n\\nThe browser open in the address configured in the \\u201cProperties\\u201d dialog for the docker- compose project.\\n\\n3.\\n\\nThe Container window open (in Visual Studio 2022 version 17.0 and later).\\n\\n4. Debugger support for all projects in the solution, as shown in the following images.\\n\\nBrowser opened:\\n\\n64\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-43. Browser window with an application run\", \"ning on multiple containers.\\n\\nContainers window:\\n\\nFigure 4-44. Visual Studio \\u201cContainers\\u201d window\\n\\nThe Containers window lets you view running containers, browse available images, view environment variables, logs, and port mappings, inspect the filesystem, attach a debugger, or open a terminal window inside the container environment.\\n\\nAs you can see, the integration between Visual Studio 2022 and Docker is completely oriented to the developer\\u2019s pr\", \"oductivity.\\n\\nOf course, you can also list the images using the docker images command. You should see the webapi and webapp images with the dev tags created by the automatic deployment of our project with Visual Studio 2022.\\n\\ndocker images\\n\\n65\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-45. View of Docker images\\n\\nRegister the Solution in an Azure Container Registry (ACR)\\n\\nYou can upload the i\", \"mages to the Azure Container Registry (ACR), but you could also use Docker Hub or any other registry, so the images can be deployed to the AKS cluster from that registry.\\n\\nCreate an ACR instance\\n\\nRun the following command from the az cli:\\n\\naz acr create --name exploredocker --resource-group explore-docker-aks-rg --sku basic --admin-enabled\\n\\nNote\\n\\nThe container registry name (for example, exploredocker) must be unique within Azure and contain 5- 5\", \"0 alphanumeric characters. For more details, see Create a container registry.\\n\\nCreate the image in Release mode\\n\\nYou\\u2019ll now create the image in Release mode (ready for production) by changing to Release, as shown in Figure 4-46, and running the application as you did before.\\n\\nFigure 4-46. Selecting Release Mode\\n\\nIf you execute the docker images command, you\\u2019ll see both images created, one for debug (dev) and the other for release (latest) mode.\\n\\n\", \"Create a new Tag for the Image\\n\\nEach container image needs to be tagged with the loginServer name of the registry. This tag is used for routing when pushing container images to an image registry.\\n\\nYou can view the loginServer name from the Azure portal, taking the information from the Azure Container Registry\\n\\n66\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-47. View of the name of the Registr\", \"y\\n\\nOr by running the following command:\\n\\naz acr list --resource-group <resource-group-name> --query \\\"[].{acrLoginServer:loginServer}\\\" --output table\\n\\nFigure 4-48. Get the name of the registry using az cli\\n\\nIn both cases, you\\u2019ll obtain the name. In our example, exploredocker.azurecr.io.\\n\\nNow you can tag the image, taking the latest image (the Release image), with the command:\\n\\ndocker tag <image-name>:latest <login-server-name>/<image-name>:v1\\n\\nAft\", \"er running the docker tag command, list the images with the docker images command, and you should see the image with the new tag.\\n\\nFigure 4-49. View of tagged images\\n\\nPush the image into the Azure ACR\\n\\nLog in to the Azure Container Registry\\n\\naz acr login --name exploredocker\\n\\nPush the image into the Azure ACR, using the following command:\\n\\ndocker push <login-server-name>/<image-name>:v1\\n\\n67\\n\\nCHAPTER 4 | Designing and developing containerized apps\", \" using Docker and Microsoft Azure\\n\\nThis command takes a while uploading the images but gives you feedback in the process. In the following image, you can see the output from one image completed and another in progress.\\n\\nFigure 4-50. Console output from the push command.\\n\\nTo deploy your multi-container app into your AKS cluster you need some manifest .yaml files that have, most of the properties taken from the docker-compose.yml and docker-compose\", \".override.yml files.\\n\\ndeploy-webapi.yml\\n\\napiVersion: apps/v1 kind: Deployment metadata: name: webapi labels: app: weather-forecast spec: replicas: 1 selector: matchLabels: service: webapi template: metadata: labels: app: weather-forecast service: webapi spec: containers: - name: webapi image: exploredocker.azurecr.io/webapi:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 protocol: TCP env: - name: ASPNETCORE_URLS value: http://+:80\\n\\n6\", \"8\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\n--- apiVersion: v1 kind: Service metadata: name: webapi labels: app: weather-forecast service: webapi spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: service: webapi deploy-webapp.yml apiVersion: apps/v1 kind: Deployment metadata: name: webapp labels: app: weather-forecast spec: replicas: 1 selector: matchLabels: service: webapp template: m\", \"etadata: labels: app: weather-forecast service: webapp spec: containers: - name: webapp image: exploredocker.azurecr.io/webapp:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 protocol: TCP env: - name: ASPNETCORE_URLS value: http://+:80 - name: WebApiBaseAddress value: http://webapi --- apiVersion: v1 kind: Service metadata: name: webapp labels: app: weather-forecast service: webapp spec: type: LoadBalancer ports: - port: 80 targetPor\", \"t: 80 protocol: TCP selector: service: webapp\\n\\n69\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nNote\\n\\nThe previous .yml files only enable the HTTP ports, using the ASPNETCORE_URLS parameter, to avoid issues with the missing certificate in the sample app.\\n\\nTip\\n\\nYou can see how to create the AKS Cluster for this sample in section Deploy to Azure Kubernetes Service (AKS) on this guide.\\n\\nNow you\\u2019re almost \", \"ready to deploy using kubectl, but first you must get the credentials from the AKS Cluster with this command:\\n\\naz aks get-credentials --resource-group explore-docker-aks-rg --name explore-docker-aks\\n\\nFigure 4-51. Getting credentials from AKS into the kubectl environment.\\n\\nYou also have to allow the AKS cluster to pull images from the ACR, using this command:\\n\\naz aks update --name explore-docker-aks --resource-group explore-docker-aks-rg --attach-\", \"acr exploredocker\\n\\nThe previous command might take a couple of minutes to complete. Then, use the kubectl apply command to launch the deployments, and then kubectl get all to list the cluster objects.\\n\\nkubectl apply -f deploy-webapi.yml kubectl apply -f deploy-webapp.yml\\n\\nkubectl get all\\n\\n70\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-52. Deployment to Kubernetes\\n\\nYou\\u2019ll have to wait a while\", \" until the load balancer gets the external IP, checking with kubectl get services, and then the application should be available at that address, as shown in the next image:\\n\\n71\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nFigure 4-53. Deployment to Kubernetes\\n\\nWhen the deployment completes, you can access the Kubernetes Web UI with a local proxy, using an ssh tunnel.\\n\\nFirst you must create a ClusterRo\", \"leBinding with the following command:\\n\\nkubectl create clusterrolebinding kubernetes-dashboard --clusterrole=cluster-admin -- serviceaccount=kube-system:kubernetes-dashboard\\n\\nAnd then this command to start the proxy:\\n\\naz aks browse --resource-group exploredocker-aks-rg --name explore-docker-aks\\n\\nA browser window should open at http://127.0.0.1:8001 with a view similar to this one:\\n\\n72\\n\\nCHAPTER 4 | Designing and developing containerized apps using \", \"Docker and Microsoft Azure\\n\\nFigure 4-54. View Kubernetes cluster information\\n\\nNow you have your ASP.NET Core application, running in Linux containers, and deployed to an AKS cluster on Azure.\\n\\nNote\\n\\nFor more information on deployment with Kubernetes see: https://kubernetes.io/docs/reference/kubectl/cheatsheet/\\n\\n73\\n\\nCHAPTER 4 | Designing and developing containerized apps using Docker and Microsoft Azure\\n\\nCHAPTER 5\\n\\nDocker application DevOps workfl\", \"ow with Microsoft tools\\n\\nMicrosoft Visual Studio, Azure DevOps Services and/or GitHub, Team Foundation Server, and Azure Monitor provide a comprehensive ecosystem for development and IT operations that give your team the tools to manage projects and rapidly build, test, and deploy containerized applications.\\n\\nTeams can choose which tools and platforms they want to use for end to end DevOps. With Visual Studio and Azure DevOps Services in the clou\", \"d, along with Team Foundation Server on-premises, development teams can productively build, test, and release containerized applications that target either Windows or Linux. Alternatively, teams can also use Visual Studio Code and GitHub. Teams can even use combinations: for example, storing source code in GitHub and using Azure Boards for work item tracking and Azure Pipelines for CI/CD.\\n\\nMicrosoft tools can automate the pipeline for specific im\", \"plementations of containerized applications\\u2014Docker, .NET, or any combination with other platforms\\u2014from global builds and Continuous Integration (CI) and tests with Azure DevOps Services, Team Foundation Server or GitHub, to Continuous Deployment (CD) to Docker environments (Development, Staging, Production), and to transmit analytics information about the services to the development team through Azure Monitor. Every code commit can initiate a bui\", \"ld (CI) and automatically deploy the services to specific containerized environments (CD).\\n\\nDevelopers and testers can easily and quickly provision production-like development and test environments based on Docker by using templates in Microsoft Azure.\\n\\nThe complexity of containerized application development increases steadily depending on the business complexity and scalability needs. A good example of this complexity are applications based on m\", \"icroservices architectures. To succeed in such an environment, your project must automate the entire life cycle\\u2014not only the build and deployment, but it also must manage versions along with the collection of telemetry. Azure DevOps Services, GitHub and Azure offer the following capabilities:\\n\\n\\n\\nAzure DevOps Services/Team Foundation Server source code management (based on Git or Team Foundation Version Control), Agile planning (Agile, Scrum, and \", \"CMMI are supported), CI, release management, and other tools for Agile teams.\\n\\n74\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\n\\n\\nAzure DevOps Services and Team Foundation Server include a powerful and growing ecosystem of first and third-party extensions with which you easily can construct a CI, build, test, delivery, and release management pipeline for microservices.\\n\\n\\n\\nGitHub or GitHub Enterprise Server offer similar ca\", \"pabilities, with source control based on Git, Projects and Issues for project tracking, GitHub Actions for automating workflows including CI/CD, and GitHub Advanced Security for dependency, secret and vulnerability scanning.\\n\\n\\n\\nRun automated tests as part of your build pipeline in Azure DevOps Services or through GitHub Actions\\n\\n\\n\\nAzure DevOps Services/GitHub can tighten the DevOps life cycle with delivery to multiple environments, not just for p\", \"roduction environments, but also for testing, including A/B experimentation, canary releases, and so on.\\n\\n\\n\\nOrganizations easily can provision Docker containers from private images stored in Azure Container Registry along with any dependency on Azure components (Data, PaaS, etc.) using Azure Resource Manager templates with tools they\\u2019re already comfortable with.\\n\\nSteps in the outer-loop DevOps workflow for a Docker application\\n\\nFigure 5-1 present\", \"s an end-to-end depiction of the steps comprising the DevOps outer-loop workflow. It shows the \\u201couter loop\\u201d of DevOps. When code is pushed to the repo, a CI pipeline is started, then begins the CD pipeline, where the application gets deployed. Metrics collected from deployed applications are fed back into the development workload, where the \\u201cinner loop\\u201d occurs, so development teams have actual data to respond to user and business needs.\\n\\nFigure 5\", \"-1. DevOps outer-loop workflow for Docker applications with Microsoft tools\\n\\nNow, let\\u2019s examine each of these steps in greater detail.\\n\\n75\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nStep 1: Inner-loop development workflow\\n\\nThis step is explained in detail in Chapter 4, but, to recap, here is where the outer-loop begins, the moment at which a developer pushes code to the source control management system (like Git) initia\", \"ting CI pipeline actions.\\n\\nStep 2: Source-Code Control integration and management with Azure DevOps Services and Git\\n\\nAt this step, you need to have a version-control system to gather a consolidated version of all the code coming from the different developers in the team.\\n\\nEven though source-code control (SCC) and source-code management might seem second-nature to most developers, when creating Docker applications in a DevOps life cycle, it\\u2019s cri\", \"tical to emphasize that you must not submit the Docker images with the application directly to the global Docker Registry (like Azure Container Registry or Docker Hub) from the developer\\u2019s machine. On the contrary, the Docker images to be released and deployed to production environments must be created solely on the source code that\\u2019s being integrated in your global build or CI pipeline based on your source- code repository (like Git).\\n\\nThe local\", \" images, generated by developers, should just be used by them when testing within their own machines. That\\u2019s why it\\u2019s critical to have the DevOps pipeline activated from the SCC code.\\n\\nAzure DevOps Services and Team Foundation Server support Git and Team Foundation Version Control. You can choose between them and use it for an end-to-end Microsoft experience. However, you can also manage your code in external repositories (like GitHub, on-premise\", \"s Git repositories, or Subversion) and still be able to connect to it and get the code as the starting point for your DevOps CI pipeline. You can also use GitHub Actions for CI/CD pipelines.\\n\\nStep 3: Build, CI, Integrate, and Test with Azure DevOps Services/GitHub and Docker\\n\\nCI has emerged as a standard for modern software testing and delivery. The Docker solution maintains a clear separation of concerns between the development and operations te\", \"ams. The immutability of Docker images ensures a repeatable deployment between what\\u2019s developed, tested through CI, and run in production. Docker Engine deployed across the developer laptops and test infrastructure makes the containers portable across environments.\\n\\nAt this point, after you have a version-control system with the correct code submitted, you need a build service to pick up the code and run the global build and tests.\\n\\nThe internal \", \"workflow for this step (CI, build, test) is about the construction of a CI pipeline consisting of your code repository (Git, etc.), your build server (Azure DevOps Services/GitHub), Docker Engine, and a Docker Registry.\\n\\nYou can use Azure DevOps Services as the foundation for building your applications and setting your CI pipeline, and for publishing the built \\u201cartifacts\\u201d to an \\u201cartifacts repository,\\u201d which is explained in the next step. Alternat\", \"ively, you can use GitHub to implement the same workflow.\\n\\n76\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nWhen using Docker for the deployment, the \\u201cfinal artifacts\\u201d to be deployed are Docker images with your application or services embedded within them. Those images are pushed or published to a Docker Registry (a private repository like the ones you can have in Azure Container Registry, or a public one like Docker Hub R\", \"egistry or GitHub Container Registry, which is commonly used for official base images).\\n\\nHere is the basic concept: The CI pipeline will be kicked-off by a commit to an SCC repository like Git. The commit will cause Azure DevOps Services/GitHub to run a build job within a Docker container and, upon successful completion of that job, push a Docker image to the Docker Registry, as illustrated in Figure 5-2. The first part of the outer loop involves\", \" steps 1 to 3, from code, run, debug and validate, then the code repo up to the build and test CI step.\\n\\nFigure 5-2. The steps involved in CI\\n\\nHere are the basic CI workflow steps with Docker and Azure DevOps Services:\\n\\n77\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\n1.\\n\\nThe developer pushes a commit to an SCC repository (Git/Azure DevOps Services, GitHub, etc.).\\n\\n2.\\n\\nIf you\\u2019re using Azure DevOps Services or Git, CI is bu\", \"ilt in, which means that it\\u2019s as simple as selecting a check box in Azure DevOps Services. If you\\u2019re using an external SCC (like GitHub), a webhook will notify Azure DevOps Services of the update or push to Git/GitHub.\\n\\n3.\\n\\nAzure DevOps Services pulls the SCC repository, including the Dockerfile describing the image, as well as the application and test code.\\n\\n4.\\n\\nAzure DevOps Services builds a Docker image and labels it with a build number.\\n\\n5.\\n\\n\", \"Azure DevOps Services instantiates the Docker container within the provisioned Docker Host, and runs the appropriate tests.\\n\\n6.\\n\\nIf the tests are successful, the image is first relabeled to a meaningful name so that you know it\\u2019s a \\u201cblessed build\\u201d (like \\u201c/1.0.0\\u201d or any other label), and then pushed up to your Docker Registry (Docker Hub, Azure Container Registry, DTR, etc.)\\n\\nHere are the basic CI workflow steps with Docker and GitHub:\\n\\n1.\\n\\nThe de\", \"veloper pushes a commit to a GitHub repo.\\n\\n2.\\n\\nCI is built in, so Actions will trigger base on the event filters.\\n\\n3.\\n\\nGitHub pulls the SCC repository, including the Dockerfile describing the image, as well as the application and test code.\\n\\n4.\\n\\nGitHub builds a Docker image and labels it with a build number.\\n\\n5.\\n\\nGitHub instantiates the Docker container within the provisioned Docker Host, and runs the appropriate tests.\\n\\n6.\\n\\nIf the tests are succ\", \"essful, the image is first relabeled to a meaningful name so that you know it\\u2019s a \\u201cblessed build\\u201d (like \\u201c/1.0.0\\u201d or any other label), and then pushed up to your Docker Registry (Docker Hub, Azure Container Registry, DTR, etc.)\\n\\nImplement a CI pipeline with Azure DevOps Services and the Docker extension for Azure DevOps Services\\n\\nVisual Studio Azure DevOps Services contains Build & Release Templates that you can use in your CI/CD pipeline with whi\", \"ch you can build Docker images, push Docker images to an authenticated Docker registry, run Docker images, or run other operations offered by the Docker CLI. It also adds a Docker Compose task that you can use to build, push, and run multi-container Docker applications, or run other operations offered by the Docker Compose CLI, as shown in Figure 5-3.\\n\\n78\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-3. The Docker\", \" CI pipeline in Azure DevOps Services including Build & Release Templates and associated tasks.\\n\\nYou can use these templates and tasks to construct your CI/CD artifacts to Build / Test and Deploy in Azure Service Fabric, Azure Kubernetes Service, and similar offerings.\\n\\nWith these Visual Studio Team Services tasks, a build Linux-Docker Host/VM provisioned in Azure and your preferred Docker registry (Azure Container Registry, Docker Hub, private D\", \"ocker DTR, or any other Docker registry) you can assemble your Docker CI pipeline in a very consistent way.\\n\\nRequirements:\\n\\n\\n\\nAzure DevOps Services, or for on-premises installations, Team Foundation Server 2015 Update 3 or later.\\n\\n\\n\\nAn Azure DevOps Services agent that has the Docker binaries.\\n\\nAn easy way to create one of these agents is to use Docker to run a container based on the Azure DevOps Services agent Docker image.\\n\\nTip\\n\\nTo read more abo\", \"ut assembling an Azure DevOps Services Docker CI pipeline and view the walkthroughs, visit these sites:\\n\\n\\n\\nRunning a Visual Studio Team Services (Now Azure DevOps Services) agent as a Docker container: https://hub.docker.com/_/microsoft-azure-pipelines-vsts-agent\\n\\n79\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\n\\n\\nBuilding .NET Linux Docker images with Azure DevOps Services: https://learn.microsoft.com/archive/blogs/stevel\", \"asker/building-net-core-linux-docker- images-with-visual-studio-team-services\\n\\n\\n\\nBuilding a Linux-based Visual Studio Team Service build machine with Docker support: https://www.donovanbrown.com/post/Building-a-Linux-Based-Visual-Studio-Team-Service- Build-Machine-with-Docker-Support\\n\\nImplement a CI pipeline with GitHub Actions\\n\\nGitHub Actions allow you to create automation scripts that can build Docker images, push Docker images to an authentica\", \"ted Docker registry, run Docker images, or run other operations offered by the Docker CLI.\\n\\nYou can use public Actions (such as Azure Login) and run (shell) commands to construct your CI/CD artifacts to Build / Test and Deploy in Azure Service Fabric, Azure Kubernetes Service, and similar offerings.\\n\\nWith these Actions, a build Linux-Docker Host/VM provisioned in Azure and your preferred Docker registry (Azure Container Registry, Docker Hub, priv\", \"ate Docker DTR, or any other Docker registry) you can assemble your Docker CI pipeline in a very consistent way.\\n\\nIntegrate, test, and validate multi-container Docker applications\\n\\nTypically, most Docker applications are composed of multiple containers rather than a single container. A good example is a microservices-oriented application for which you would have one container per microservice. But, even without strictly following the microservice\", \"s approach patterns, it\\u2019s probable that your Docker application would be composed of multiple containers or services.\\n\\nTherefore, after building the application containers in the CI pipeline, you also need to deploy, integrate, and test the application as a whole with all of its containers within an integration Docker host or even into a test cluster to which your containers are distributed.\\n\\nIf you\\u2019re using a single host, you can use Docker comm\", \"ands such as docker-compose to build and deploy related containers to test and validate the Docker environment in a single VM. But, if you\\u2019re working with an orchestrator cluster like DC/OS, Kubernetes, or Docker Swarm, you need to deploy your containers through a different mechanism or orchestrator, depending on your selected cluster/scheduler.\\n\\nThe following are several types of tests that you can run against Docker containers:\\n\\n\\n\\nUnit tests fo\", \"r Docker containers\\n\\n\\n\\nTesting groups of interrelated applications or microservices\\n\\n\\n\\nTest in production and \\u201ccanary\\u201d releases\\n\\nThe important point is that when running integration and functional tests, you must run those tests from outside of the containers. Tests are not contained or run in the containers you\\u2019re deploying, because the containers are based on static images that should be exactly like the ones you\\u2019ll be deploying to production.\\n\", \"\\n80\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nA practical option when testing more advanced scenarios, like including several clusters (test cluster, staging cluster, and production cluster) is to publish the images to a registry, so it can be tested in various clusters.\\n\\nPush the custom application Docker image into your global Docker Registry\\n\\nAfter the Docker images have been tested and validated, you\\u2019ll want to tag\", \" and publish them to your Docker registry. The Docker registry is a critical piece in the Docker application life cycle because it\\u2019s the central place where you store your custom test (also known as \\u201cblessed images\\u201d) to be deployed into QA and production environments.\\n\\nSimilar to how the application code stored in your SCC repository (Git, etc.) is your \\u201csource of truth,\\u201d the Docker registry is your \\u201csource of truth\\u201d for your binary application o\", \"r bits to be deployed to the QA or production environments.\\n\\nTypically, you might want to have your private repositories for your custom images either in a private repository in Azure Container Registry or in an on-premises registry like Docker Trusted Registry, or in a public-cloud registry with restricted access (like Docker Hub), although in this last case if your code is not open source, you must trust the vendor\\u2019s security. Either way, the m\", \"ethod you use is similar and is based on the docker push command, as shown in Figure 5-4.\\n\\n81\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-4. Publishing custom images to Docker Registry\\n\\n82\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nIn step 3, for building integration and testing (CI) you might publish the resulting docker images to a private or public registry. There are multiple offer\", \"ings of Docker registries from cloud vendors like Azure Container Registry, Amazon Web Services Container Registry, Google Container Registry, GitHub Container Registry, Quay Registry, and so on.\\n\\nUsing the Docker tasks, you can push a set of service images defined by a docker-compose.yml file, with multiple tags, to an authenticated Docker registry (like Azure Container Registry), as shown in Figure 5-5.\\n\\nFigure 5-5. Using Azure DevOps Services \", \"to publishing custom images to a Docker Registry\\n\\nTip\\n\\nFor more information about Azure Container Registry, see https://aka.ms/azurecontainerregistry.\\n\\nStep 4: CD, Deploy\\n\\nThe immutability of Docker images ensures a repeatable deployment with what\\u2019s developed, tested through CI, and run in production. After you have the application Docker images published in your Docker registry (either private or public), you can deploy them to the several envir\", \"onments that you might have (production, QA, staging, etc.) from your CD pipeline by using Azure DevOps Services pipeline tasks, Azure DevOps Services Release Management or GitHub Actions.\\n\\n83\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nHowever, at this point it depends on what kind of Docker application you\\u2019re deploying. Deploying a simple application (from a composition and deployment point of view) like a monolithic a\", \"pplication comprising a few containers or services and deployed to a few servers or VMs is different from deploying a more complex application like a microservices-oriented application with hyperscale capabilities. These two scenarios are explained in the following sections.\\n\\nDeploying composed Docker applications to multiple Docker environments\\n\\nLet\\u2019s look first at the less-complex scenario: deploying to simple Docker hosts (VMs or servers) in a\", \" single environment or multiple environments (QA, staging, and production). In this scenario, internally your CD pipeline can use docker-compose (from your Azure DevOps Services deployment tasks) to deploy the Docker applications with its related set of containers or services, as illustrated in Figure 5-6.\\n\\nFigure 5-6. Deploying application containers to simple Docker host environments registry\\n\\nFigure 5-7 highlights how you can connect your buil\", \"d CI to QA/test environments via Azure DevOps Services by clicking Docker Compose in the Add Task dialog box. However, when deploying to staging or production environments, you would usually use Release Management features handling multiple environments (like QA, staging, and production). If you\\u2019re deploying to single Docker hosts, it is using the Azure DevOps Services \\u201cDocker Compose\\u201d task (which is invoking the docker-compose up command under t\", \"he hood). If you\\u2019re deploying to Azure Kubernetes Service (AKS), it uses the Docker\\n\\n84\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nDeployment task, as explained in the section that follows. Similar steps can be built for deployment using GitHub Actions.\\n\\nFigure 5-7. Adding a Docker Compose task in an Azure DevOps Services pipeline or GitHub workflow\\n\\nWhen you create a release in Azure DevOps Services, it takes a set of \", \"input artifacts. These artifacts are intended to be immutable for the lifetime of the release, across all environments. When you introduce containers, the input artifacts identify images in a registry to deploy. Depending on how these images are identified, they are not guaranteed to remain the same throughout the duration of the release, the most obvious case being when you reference myimage:latest from a docker-compose file.\\n\\nThe Azure DevOps S\", \"ervices templates give you the ability to generate build artifacts that contain specific registry image digests that are guaranteed to uniquely identify the same image binary. These are what you really want to use as input to a release. You can invoke docker-compose in a run step inside GitHub Actions to accomplish the same goal.\\n\\nManaging releases to Docker environments by using Azure DevOps Services Release Management or GitHub Actions\\n\\nThrough\", \" the Azure DevOps Services templates, you can build a new image, publish it to a Docker registry, run it on Linux or Windows hosts, and use commands such as docker-compose to deploy multiple containers as an entire application, all through the Azure DevOps Services Release Management capabilities intended for multiple environments, as shown in Figure 5-8.\\n\\n85\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-8. Config\", \"uring Azure DevOps Services Docker Compose tasks from Azure DevOps Services Release Management\\n\\nHowever, keep in mind that the scenario shown in Figure 5-6 and implemented in Figure 5-8 is a simple one (it\\u2019s deploying to single Docker hosts and VMs, and there will be a single container or instance per image) and probably should be used only for development or test scenarios. In most enterprise production scenarios, you would want to have High Ava\", \"ilability (HA) and easy-to-manage scalability by load balancing across multiple nodes, servers, and VMs, plus \\u201cintelligent failovers\\u201d so if a server or node fails, its services and containers will be moved to another host server or VM. In that case, you need more advanced technologies such as container clusters, orchestrators, and schedulers. Thus, the way to deploy to those clusters is by handling the advanced scenarios explained in the next sec\", \"tion.\\n\\nGitHub Actions can be used in the same manner, including the use of environments for approvals.\\n\\nDeploying Docker applications to Docker clusters\\n\\nThe nature of distributed applications requires compute resources that are also distributed. To have production-scale capabilities, you need to have clustering capabilities that provide high scalability and high availability based on pooled resources.\\n\\nYou could deploy containers manually to tho\", \"se clusters from a CLI tool or a web UI, but you should reserve that kind of manual work to spot deployment testing or management purposes like scaling- out or monitoring.\\n\\nFrom a CD point of view, you can use Azure DevOps Services or GitHub Actions to run specially made deployment tasks from your environments that will deploy your containerized applications to distributed clusters in Container Service, as illustrated in Figure 5-9.\\n\\n86\\n\\nCHAPTER \", \"5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-9. Deploying distributed applications to Container Service\\n\\nInitially, when deploying to certain clusters or orchestrators, you would traditionally use specific deployment scripts and mechanisms per each orchestrator (that is, Kubernetes and Service Fabric have different deployment mechanisms) instead of the simpler and easy-to-use docker-compose tool based on the docker-compos\", \"e.yml definition file. However, thanks to the Azure DevOps Services Docker Deploy task, shown in Figure 5-10, now you can also deploy to the supported orchestrators by just using your familiar docker-compose.yml file because the tool performs that \\u201ctranslation\\u201d for you (from your docker-compose.yml file to the format needed by the orchestrator).\\n\\n87\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-10. Adding the Depl\", \"oy to Kubernetes task to your Environment\\n\\nFigure 5-11 demonstrates how you can edit the Deploy to Kubernetes task with the sections available for configuration. This is the task that will retrieve your ready-to-use custom Docker images to be deployed as containers in the cluster.\\n\\nFigure 5-11. Docker Deploy task definition deploying to ACS DC/OS\\n\\n88\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nTip\\n\\nTo read more about the\", \" CD pipeline with Azure DevOps Services and Docker, visit https://azure.microsoft.com/services/devops/pipelines\\n\\nTip\\n\\nTo see GitHub Actions workflows for CI, visit https://github.com/dotnet- architecture/eShopOnContainers/wiki/GitHub-Actions. For a walkthrough of GitHub Actions performing deployment to an Azure Kubernetes environment, visit https://github.com/dotnet- architecture/eShopOnContainers/wiki/Deployment-With-GitHub-Actions.\\n\\nStep 5: Run\", \" and manage\\n\\nBecause running and managing applications at enterprise-production level is a major subject in and of itself, and due to the type of operations and people working at that level (IT operations) as well as the large scope of this area, the entire next chapter is devoted to explaining it.\\n\\nStep 6: Monitor and diagnose\\n\\nThis topic also is covered in the next chapter as part of the tasks that IT performs in production systems; however, is\", \" important to highlight that the insights obtained in this step must feed back to the development team so that the application is constantly improved. From that point of view, it\\u2019s also part of DevOps, although the tasks and operations are commonly performed by IT.\\n\\nOnly when monitoring and diagnostics are 100% within the realm of DevOps are the monitoring processes and analytics performed by the development team against testing or beta environme\", \"nts. This is done either by performing load testing or by monitoring beta or QA environments, where beta testers are trying the new versions.\\n\\nCreate CI/CD pipelines in Azure DevOps Services for a .NET application on Containers and deploying to a Kubernetes cluster\\n\\nIn Figure 5-12 you can see the end-to-end DevOps scenario covering the code management, code compilation, Docker images build, Docker images push to a Docker registry and finally the \", \"deployment to a Kubernetes cluster in Azure.\\n\\n89\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-12. CI/CD scenario creating Docker images and deploying to a Kubernetes cluster in Azure\\n\\nIt is important to highlight that the two pipelines, build/CI, and release/CD, are connected through the Docker Registry (such as Docker Hub or Azure Container Registry). The Docker registry is one of the main differences compared t\", \"o a traditional CI/CD process without Docker.\\n\\nAs shown in Figure 5-13, the first phase is the build/CI pipeline. In Azure DevOps Services you can create build/CI pipelines that will compile the code, create the Docker images, and push them to a Docker Registry like Docker Hub or Azure Container Registry.\\n\\n90\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nFigure 5-13. Build/CI pipeline in Azure DevOps building Docker images\", \" and pushing images to a Docker registry\\n\\nThe second phase is to create a deployment/release pipeline. In Azure DevOps Services, you can easily create a deployment pipeline targeting a Kubernetes cluster by using the Kubernetes tasks for Azure DevOps Services, as shown in Figure 5-14.\\n\\nFigure 5-14. Release/CD pipeline in Azure DevOps Services deploying to a Kubernetes cluster\\n\\n[!Walkthrough] Deploying eShopModernized to Kubernetes:\\n\\n91\\n\\nCHAPTER 5\", \" | Docker application DevOps workflow with Microsoft tools\\n\\nFor a detailed walkthrough of Azure DevOps CI/CD pipelines deploying to Kubernetes, see this post: https://github.com/dotnet-architecture/eShopModernizing/wiki/04.-How-to-deploy-your-Windows- Containers-based-apps-into-Kubernetes-in-Azure-Container-Service-(Including-CI-CD)\\n\\n92\\n\\nCHAPTER 5 | Docker application DevOps workflow with Microsoft tools\\n\\nCHAPTER 6\\n\\nRun, manage, and monitor Docke\", \"r production environments\\n\\nVision: Enterprise applications need to run with high availability and high scalability; IT operations need to be able to manage and monitor the environments and the applications themselves.\\n\\nThis last pillar in the containerized Docker applications life cycle is centered on how you can run, manage, and monitor your applications in scalable, high availability (HA) production environments.\\n\\nThe way you run your container\", \"ized applications in production (infrastructure architecture and platform technologies) is very much related and based on the chosen architecture and development platforms discussed in Chapter 1 of this e-book.\\n\\nThis chapter examines specific products and technologies from Microsoft and other vendors that you can use to effectively run scalable, HA distributed applications plus how you can manage and monitor them from the IT perspective.\\n\\nRun com\", \"posed and microservices-based applications in production environments\\n\\nApplications composed by multiple microservices do need to be deployed into orchestrator clusters in order to simplify the complexity of deployment and make it viable from an IT point of view. Without an orchestrator cluster, it would be difficult to deploy and scale out a complex microservices application.\\n\\nIntroduction to orchestrators, schedulers, and container clusters\\n\\nEa\", \"rlier in this e-book, clusters and schedulers were introduced as part of the discussion on software architecture and development. Kubernetes and Service Fabric are examples of Docker clusters. Both of these orchestrators can run as a part of the infrastructure provided by Microsoft Azure Kubernetes Service.\\n\\n93\\n\\nCHAPTER 6 | Run, manage, and monitor Docker production environments\\n\\nWhen applications are scaled-out across multiple host systems, the \", \"ability to manage each host system and abstract away the complexity of the underlying platform becomes attractive. That\\u2019s precisely what orchestrators and schedulers provide. Let\\u2019s take a brief look at them here:\\n\\n\\n\\nSchedulers. \\u201cScheduling\\u201d refers to the ability for an administrator to load a service file onto a host system that establishes how to run a specific container. Launching containers in a Docker cluster tends to be known as scheduling. \", \"Although scheduling refers to the specific act of loading the service definition, in a more general sense, schedulers are responsible for hooking into a host\\u2019s init system to manage services in whatever capacity needed.\\n\\nA cluster scheduler has multiple goals: using the cluster\\u2019s resources efficiently, working with user-supplied placement constraints, scheduling applications rapidly to not leave them in a pending state, having a degree of \\u201cfairne\", \"ss,\\u201d being robust to errors, and always be available.\\n\\n\\n\\nOrchestrators. Platforms extend life-cycle management capabilities to complex, multi- container workloads deployed on a cluster of hosts. By abstracting the host infrastructure, orchestration tools give users a way to treat the entire cluster as a single deployment target.\\n\\nThe process of orchestration involves tooling and a platform that can automate all aspects of application management f\", \"rom initial placement or deployment per container; moving containers to different hosts depending on its host\\u2019s health or performance; versioning and rolling updates and health monitoring functions that support scaling and failover; and many more.\\n\\nOrchestration is a broad term that refers to container scheduling, cluster management, and possibly the provisioning of additional hosts.\\n\\nThe capabilities provided by orchestrators and schedulers are \", \"complex to develop and create from scratch, therefore you usually would want to use orchestration solutions offered by vendors.\\n\\nManage production Docker environments\\n\\nCluster management and orchestration is the process of controlling a group of hosts. This can involve adding and removing hosts from a cluster, getting information about the current state of hosts and containers, and starting and stopping processes. Cluster management and orchestra\", \"tion are closely tied to scheduling because the scheduler must have access to each host in the cluster in order to schedule services. For this reason, the same tool is often used for both purposes.\\n\\nContainer Service and management tools\\n\\nContainer Service provides rapid deployment of popular open-source container clustering and orchestration solutions. It uses Docker images to ensure that your application containers are fully portable. By using \", \"Container Service, you can deploy DC/OS (powered by Mesosphere and Apache Mesos) and Docker Swarm clusters with Azure Resource Manager templates or the Azure portal to ensure that you can scale these applications to thousands\\u2014even tens of thousands\\u2014of containers.\\n\\nYou deploy these clusters by using Azure Virtual Machine Scale Sets, and the clusters take advantage of Azure networking and storage offerings. To access Container Service, you need an \", \"Azure\\n\\n94\\n\\nCHAPTER 6 | Run, manage, and monitor Docker production environments\\n\\nsubscription. With Container Service, you can take advantage of the enterprise-grade features of Azure while still maintaining application portability, including at the orchestration layers.\\n\\nTable 6-1 lists common management tools related to their orchestrators, schedulers, and clustering platform.\\n\\nTable 6-1. Docker management tools\\n\\nManagement tools\\n\\nDescription\\n\\nR\", \"elated orchestrators\\n\\nAzure Monitor for Containers\\n\\nAzure dedicated Kubernetes management tool\\n\\nAzure Kubernetes Services (AKS)\\n\\nKubernetes Web UI (dashboard)\\n\\nKubernetes management tool, can monitor and manage local Kubernetes cluster\\n\\nAzure Kubernetes Service (AKS) Local Kubernetes\\n\\nAzure portal for Service Fabric Azure Service Fabric Explorer\\n\\nOnline and desktop version for managing Service Fabric clusters, on Azure, on premises, local develop\", \"ment, and other clouds\\n\\nAzure Service Fabric\\n\\nContainer Monitoring (Azure Monitor)\\n\\nGeneral container management y monitoring solution. Can manage Kubernetes clusters through Azure Monitor for Containers.\\n\\nAzure Service Fabric Azure Kubernetes Service (AKS) Mesosphere DC/OS and others.\\n\\nAzure Service Fabric\\n\\nAnother choice for cluster-deployment and management is Azure Service Fabric. Service Fabric is a Microsoft microservices platform that incl\", \"udes container orchestration as well as developer programming models to build highly scalable microservices applications. Service Fabric supports Docker in Linux and Windows Containers and can run in Windows and Linux servers.\\n\\nThe following are Service Fabric management tools:\\n\\n\\n\\nAzure portal for Service Fabric cluster-related operations (create/update/delete) a cluster or configure its infrastructure (VMs, load balancer, networking, etc.)\\n\\n\\n\\nAz\", \"ure Service Fabric Explorer is a specialized web UI and desktop multi-platform tool that provides insights and certain operations on the Service Fabric cluster, from the nodes/VMs point of view and from the application and services point of view.\\n\\n95\\n\\nCHAPTER 6 | Run, manage, and monitor Docker production environments\\n\\nMonitor containerized application services\\n\\nIt\\u2019s critical for applications split into multiple containers and microservices to ha\", \"ve a way to monitor and analyze the behavior of the whole application.\\n\\nAzure Monitor\\n\\nAzure Monitor is an extensible analytics service that monitors your live application. It helps you to detect and diagnose performance issues and to understand what users actually do with your app. It\\u2019s designed for developers, with the intent of helping you to continuously improve the performance and usability of your services or applications. Azure Monitor wor\", \"ks with both web/services and standalone apps on a wide variety of platforms like .NET, Java, Node.js and many other platforms, hosted on- premises or in the cloud.\\n\\nAdditional resources\\n\\n\\n\\nOverview of Azure Monitor https://learn.microsoft.com/azure/azure-monitor/overview\\n\\nWhat is Application Insights?\\n\\nhttps://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview\\n\\nWhat is Azure Monitor Metrics?\\n\\nhttps://learn.microsoft.com/azure/azur\", \"e-monitor/platform/data-platform-metrics\\n\\n\\n\\nContainer Monitoring solution in Azure Monitor https://learn.microsoft.com/azure/azure-monitor/insights/containers\\n\\nSecurity and backup services\\n\\nThere are many support chores with lots of details that you have to handle to ensure your applications and infrastructure are in top notch condition to support business needs, and the situation becomes more complicated in the microservices realm, so you need a\", \" way to have both high-level and detailed views when you need to take action.\\n\\nAzure has the tools to manage and provide a unified view of four critical aspects of both your cloud and on-premises resources:\\n\\n\\n\\nSecurity. With Azure Security Center.\\n\\n\\u2013\\n\\nGet full visibility and control over the security of your virtual machines, apps, and workloads.\\n\\n\\u2013\\n\\nCentralize the management of your security policies and integrate existing processes and tools.\\n\\n\", \"\\u2013\\n\\nDetect real threats with advanced analytics.\\n\\n\\n\\nBackup. With Azure Backup.\\n\\n\\u2013\\n\\nAvoid costly business disruptions, meet compliance goals, and protect your data against ransomware and human errors.\\n\\n\\u2013\\n\\nKeep your backup data encrypted in transit and at rest.\\n\\n96\\n\\nCHAPTER 6 | Run, manage, and monitor Docker production environments\\n\\n\\u2013\\n\\nEnsure access based on multifactor authentication to prevent unauthorized use.\\n\\n\\n\\nOn-premises resources. With hybr\", \"id cloud solutions.\\n\\n97\\n\\nCHAPTER 6 | Run, manage, and monitor Docker production environments\\n\\nCHAPTER 7\\n\\nContainerized Docker Application Lifecycle key takeaways\\n\\n\\n\\nContainer-based solutions provide important cost-saving benefits because containers solve deployment problems caused by dependency failures in production environments, thereby improving DevOps and production operations significantly.\\n\\n\\n\\nDocker has become the de facto standard in the c\", \"ontainer industry and is supported by the most significant vendors in the Linux and Windows ecosystems, including Microsoft. In the future, Docker will be ubiquitous in any datacenter in the cloud or on-premises.\\n\\n\\n\\nA Docker container is becoming the standard unit of deployment for any server-based application or service.\\n\\n\\n\\nDocker orchestrators like the ones provided in Azure Kubernetes Service (AKS) and Azure Service Fabric are fundamental and \", \"indispensable for any microservices-based or multi- container applications that have significant complexity and scalability needs.\\n\\n\\n\\nAn end-to-end DevOps environment that supports Continuous Integration/Continuous Deployment (CI/CD) and connects to the production Docker environments can provide agility and ultimately improve the time to market of your applications.\\n\\n\\n\\nAzure DevOps Services greatly simplifies your DevOps environment by deploying \", \"to Docker environments from your CI/CD pipelines. This statement applies to simple Docker environments as well as to advanced microservice and container orchestrators based on Azure.\\n\\n98\\n\\nCHAPTER 7 | Containerized Docker Application Lifecycle key takeaways\"]"