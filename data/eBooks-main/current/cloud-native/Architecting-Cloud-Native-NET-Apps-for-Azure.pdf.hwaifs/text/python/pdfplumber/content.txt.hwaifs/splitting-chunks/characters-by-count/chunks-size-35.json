"[\"EDITION v1.0.3\\nRefer changelog for the book updates and community contributions.\\nPUBLISHED BY\\nMicros\", \"oft Developer Division, .NET, and Visual Studio product teams\\nA division of Microsoft Corporation\\nOn\", \"e Microsoft Way\\nRedmond, Washington 98052-6399\\nCopyright \\u00a9 2023 by Microsoft Corporation\\nAll rights \", \"reserved. No part of the contents of this book may be reproduced or transmitted in any\\nform or by an\", \"y means without the written permission of the publisher.\\nThis book is provided \\u201cas-is\\u201d and expresses\", \" the author\\u2019s views and opinions. The views, opinions, and\\ninformation expressed in this book, inclu\", \"ding URL and other Internet website references, may change\\nwithout notice.\\nSome examples depicted he\", \"rein are provided for illustration only and are fictitious. No real association\\nor connection is int\", \"ended or should be inferred.\\nMicrosoft and the trademarks listed at https://www.microsoft.com on the\", \" \\u201cTrademarks\\u201d webpage are\\ntrademarks of the Microsoft group of companies.\\nMac and macOS are trademar\", \"ks of Apple Inc.\\nThe Docker whale logo is a registered trademark of Docker, Inc. Used by permission.\", \"\\nAll other marks and logos are property of their respective owners.\\nAuthors:\\nRob Vettor, Principal M\", \"TC (Microsoft Technology Center) Architect for Cloud App Innovation -\\nthinkingincloudnative.com, Mic\", \"rosoft\\nSteve \\u201cardalis\\u201d Smith, Software Architect and Trainer - Ardalis.com\\nParticipants and Reviewer\", \"s:\\nCesar De la Torre, Principal Program Manager, .NET team, Microsoft\\nNish Anil, Senior Program Mana\", \"ger, .NET team, Microsoft\\nJeremy Likness, Senior Program Manager, .NET team, Microsoft\\nCecil Phillip\", \", Senior Cloud Advocate, Microsoft\\nSumit Ghosh, Principal Consultant at Neudesic\\nEditors:\\nMaira Wenz\", \"el, Program Manager, .NET team, MicrosoftDavid Pine, Senior Content Developer, .NET docs, Microsoft\\n\", \"Version\\nThis guide has been written to cover .NET 7 version along with many additional updates relat\", \"ed to\\nthe same \\u201cwave\\u201d of technologies (that is, Azure and additional third-party technologies) coinc\", \"iding in\\ntime with the .NET 7 release.\\nWho should use this guide\\nThe audience for this guide is main\", \"ly developers, development leads, and architects who are\\ninterested in learning how to build applica\", \"tions designed for the cloud.\\nA secondary audience is technical decision-makers who plan to choose w\", \"hether to build their\\napplications using a cloud-native approach.\\nHow you can use this guide\\nThis gu\", \"ide begins by defining cloud native and introducing a reference application built using cloud-\\nnativ\", \"e principles and technologies. Beyond these first two chapters, the rest of the book is broken up\\nin\", \"to specific chapters focused on topics common to most cloud-native applications. You can jump to\\nany\", \" of these chapters to learn about cloud-native approaches to:\\n\\u2022 Data and data access\\n\\u2022 Communication\", \" patterns\\n\\u2022 Scaling and scalability\\n\\u2022 Application resiliency\\n\\u2022 Monitoring and health\\n\\u2022 Identity and \", \"security\\n\\u2022 DevOps\\nThis guide is available both in PDF form and online. Feel free to forward this doc\", \"ument or links to its\\nonline version to your team to help ensure common understanding of these topic\", \"s. Most of these\\ntopics benefit from a consistent understanding of the underlying principles and pat\", \"terns, as well as\\nthe trade-offs involved in decisions related to these topics. Our goal with this d\", \"ocument is to equip\\nteams and their leaders with the information they need to make well-informed dec\", \"isions for their\\napplications\\u2019 architecture, development, and hosting.Contents\\nIntroduction to cloud\", \"-native applications ............................................................................ 1\\n\", \"Cloud-native computing .............................................................................\", \"..................................................................... 3\\nWhat is Cloud Native? ......\", \"....................................................................................................\", \".................................................. 4\\nThe pillars of cloud native ...................\", \"....................................................................................................\", \"......................... 5\\nThe cloud ..............................................................\", \"....................................................................................................\", \".............. 5\\nModern design .....................................................................\", \"................................................................................................ 6\\nM\", \"icroservices .......................................................................................\", \"................................................................................. 9\\nContainers .....\", \"....................................................................................................\", \".................................................................. 12\\nBacking services .............\", \"....................................................................................................\", \"............................................... 15\\nAutomation ......................................\", \"....................................................................................................\", \"............................... 17\\nCandidate apps for cloud native .................................\", \"....................................................................................................\", \" 19\\nModernizing legacy apps ........................................................................\", \"...................................................................... 19\\nSummary ..................\", \"....................................................................................................\", \"........................................................ 21\\nIntroducing eShopOnContainers reference \", \"app ................................................................ 22\\nFeatures and requirements ..\", \"....................................................................................................\", \"......................................... 23\\nOverview of the code ..................................\", \"....................................................................................................\", \".................... 25\\nUnderstanding microservices ................................................\", \"........................................................................................... 27\\nMappi\", \"ng eShopOnContainers to Azure Services .............................................................\", \"........................................ 27\\nContainer orchestration and clustering .................\", \".................................................................................................. 2\", \"8\\nAPI Gateway ......................................................................................\", \"................................................................................. 28\\nData ..........\", \"....................................................................................................\", \"......................................................................... 29\\nEvent Bus .............\", \"....................................................................................................\", \"............................................................ 30\\nResiliency .........................\", \"....................................................................................................\", \"................................................ 30\\nDeploying eShopOnContainers to Azure ...........\", \"....................................................................................................\", \"..... 30\\nAzure Kubernetes Service ..................................................................\", \"........................................................................... 30\\nDeploying to Azure Ku\", \"bernetes Service using Helm ........................................................................\", \"................. 30\\nAzure Functions and Logic Apps (Serverless) ...................................\", \".................................................................... 32\\nCentralized configuration ..\", \"....................................................................................................\", \"............................................ 33\\ni ContentsAzure App Configuration ..................\", \"....................................................................................................\", \"........................ 33\\nAzure Key Vault ........................................................\", \"....................................................................................................\", \"..... 34\\nConfiguration in eShop ....................................................................\", \".............................................................................. 34\\nReferences .......\", \"....................................................................................................\", \"................................................................ 34\\nScaling cloud-native application\", \"s ........................................................................................ 36\\nLevera\", \"ging containers and orchestrators ..................................................................\", \".................................................. 36\\nChallenges with monolithic deployments .......\", \"....................................................................................................\", \"... 36\\nWhat are the benefits of containers and orchestrators? ......................................\", \"............................................ 38\\nWhat are the scaling benefits? .....................\", \"....................................................................................................\", \"........... 40\\nWhat scenarios are ideal for containers and orchestrators?...........................\", \"................................................ 42\\nWhen should you avoid using containers and orche\", \"strators? ....................................................................... 42\\nDevelopment res\", \"ources .............................................................................................\", \".................................................... 42\\nLeveraging serverless functions ............\", \"....................................................................................................\", \"...................... 46\\nWhat is serverless? ......................................................\", \"....................................................................................................\", \". 47\\nWhat challenges are solved by serverless? .....................................................\", \"....................................................... 47\\nWhat is the difference between a microser\", \"vice and a serverless function? ............................................. 47\\nWhat scenarios are \", \"appropriate for serverless? ........................................................................\", \"........................... 47\\nWhen should you avoid serverless? ...................................\", \"....................................................................................... 48\\nCombining\", \" containers and serverless approaches ..............................................................\", \".................................... 49\\nWhen does it make sense to use containers with serverless? .\", \"....................................................................... 49\\nWhen should you avoid usi\", \"ng containers with Azure Functions? ................................................................\", \" 49\\nHow to combine serverless and Docker containers ................................................\", \"........................................... 49\\nHow to combine serverless and Kubernetes with KEDA ..\", \"................................................................................ 50\\nDeploying contai\", \"ners in Azure ......................................................................................\", \".................................................. 50\\nAzure Container Registry .....................\", \"....................................................................................................\", \"..................... 50\\nACR Tasks .................................................................\", \"....................................................................................................\", \"....... 52\\nAzure Kubernetes Service ................................................................\", \"............................................................................. 52\\nAzure Bridge to Kub\", \"ernetes ............................................................................................\", \"............................................. 53\\nScaling containers and serverless applications ....\", \"....................................................................................................\", \". 53\\nThe simple solution: scaling up ...............................................................\", \"................................................................... 53\\nScaling out cloud-native apps\", \" ...................................................................................................\", \"................................. 54\\nOther container deployment options ............................\", \"............................................................................................... 55\\ni\", \"i ContentsWhen does it make sense to deploy to App Service for Containers? .........................\", \"................................ 55\\nHow to deploy to App Service for Containers ....................\", \".................................................................................. 55\\nWhen does it m\", \"ake sense to deploy to Azure Container Instances? ..................................................\", \"........ 55\\nHow to deploy an app to Azure Container Instances ......................................\", \".................................................. 55\\nReferences ...................................\", \"....................................................................................................\", \".................................... 56\\nCloud-native communication patterns ........................\", \"....................................................... 58\\nCommunication considerations ............\", \"....................................................................................................\", \"...................... 58\\nFront-end client communication ...........................................\", \"......................................................................................... 60\\nSimple \", \"Gateways ...........................................................................................\", \"................................................................... 62\\nAzure Application Gateway ...\", \"....................................................................................................\", \"................................... 63\\nAzure API Management ........................................\", \"....................................................................................................\", \"..... 63\\nReal-time communication ...................................................................\", \"......................................................................... 66\\nService-to-service comm\", \"unication ..........................................................................................\", \"...................................... 67\\nQueries ..................................................\", \"....................................................................................................\", \"........................... 68\\nCommands ............................................................\", \"....................................................................................................\", \".......... 71\\nEvents ...............................................................................\", \"....................................................................................................\", \". 74\\ngRPC ..........................................................................................\", \"................................................................................................. 80\", \"\\nWhat is gRPC? .....................................................................................\", \".............................................................................. 80\\ngRPC Benefits ....\", \"....................................................................................................\", \"............................................................ 80\\nProtocol Buffers ...................\", \"....................................................................................................\", \"......................................... 81\\ngRPC support in .NET ..................................\", \"....................................................................................................\", \"............... 81\\ngRPC usage ......................................................................\", \"................................................................................................... \", \"82\\ngRPC implementation .............................................................................\", \"....................................................................... 83\\nLooking ahead ...........\", \"....................................................................................................\", \".................................................... 85\\nService Mesh communication infrastructure ..\", \"....................................................................................................\", \"....... 85\\nSummary .................................................................................\", \"............................................................................................. 86\\nClo\", \"ud-native data patterns ............................................................................\", \"...................... 88\\nDatabase-per-microservice, why? ..........................................\", \"........................................................................................ 89\\nCross-se\", \"rvice queries ......................................................................................\", \"..................................................................... 90\\nDistributed transactions ..\", \"....................................................................................................\", \"............................................... 91\\nHigh volume data ................................\", \"....................................................................................................\", \"............................. 93\\nCQRS ..............................................................\", \"....................................................................................................\", \"................... 93\\niii ContentsEvent sourcing ..................................................\", \"....................................................................................................\", \"............. 94\\nRelational vs. NoSQL data .........................................................\", \"........................................................................................ 96\\nThe CAP \", \"theorem ............................................................................................\", \"................................................................. 97\\nConsiderations for relational v\", \"s. NoSQL systems ...................................................................................\", \"............. 99\\nDatabase as a Service .............................................................\", \"........................................................................................ 99\\nAzure re\", \"lational databases .................................................................................\", \"........................................................ 100\\nAzure SQL Database.....................\", \"....................................................................................................\", \"............................. 100\\nOpen-source databases in Azure ...................................\", \".......................................................................................... 101\\nNoSQL\", \" data in Azure .....................................................................................\", \"............................................................... 102\\nNewSQL databases ...............\", \"....................................................................................................\", \"..................................... 106\\nData migration to the cloud ..............................\", \"....................................................................................................\", \".... 108\\nCaching in a cloud-native app .............................................................\", \".......................................................................... 108\\nWhy? ................\", \"....................................................................................................\", \"................................................................ 108\\nCaching architecture ..........\", \"....................................................................................................\", \"....................................... 109\\nAzure Cache for Redis ..................................\", \"....................................................................................................\", \"............ 110\\nElasticsearch in a cloud-native app ...............................................\", \".............................................................................. 110\\nSummary .........\", \"....................................................................................................\", \"............................................................... 111\\nCloud-native resiliency ........\", \"............................................................................................... 113\\n\", \"Application resiliency patterns ....................................................................\", \".................................................................. 114\\nCircuit breaker pattern .....\", \"....................................................................................................\", \"........................................ 116\\nTesting for resiliency ................................\", \"....................................................................................................\", \"................. 117\\nAzure platform resiliency ....................................................\", \"............................................................................................. 117\\nDe\", \"sign with resiliency ...............................................................................\", \".................................................................... 118\\nDesign with redundancy.....\", \"....................................................................................................\", \"..................................... 118\\nDesign for scalability ...................................\", \"....................................................................................................\", \".............. 120\\nBuilt-in retry in services ......................................................\", \"......................................................................................... 121\\nResili\", \"ent communications .................................................................................\", \"............................................................... 122\\nService mesh ...................\", \"....................................................................................................\", \"............................................. 123\\nIstio and Envoy ..................................\", \"....................................................................................................\", \".......................... 124\\nIntegration with Azure Kubernetes Services ..........................\", \"............................................................................. 125\\nMonitoring and hea\", \"lth ................................................................................................\", \"........ 126\\nObservability patterns ................................................................\", \"....................................................................................... 126\\niv Conte\", \"ntsWhen to use logging .............................................................................\", \"....................................................................... 126\\nChallenges with detectin\", \"g and responding to potential app health issues ........................................... 130\\nChal\", \"lenges with reacting to critical problems in cloud-native apps .....................................\", \"..................... 130\\nLogging with Elastic Stack ...............................................\", \"................................................................................................ 131\", \"\\nElastic Stack .....................................................................................\", \"................................................................................. 131\\nWhat are the a\", \"dvantages of Elastic Stack? ........................................................................\", \".................................. 132\\nLogstash ....................................................\", \"....................................................................................................\", \"..................... 132\\nElasticsearch ............................................................\", \"....................................................................................................\", \"..... 133\\nVisualizing information with Kibana web dashboards .......................................\", \"............................................. 133\\nInstalling Elastic Stack on Azure ................\", \"....................................................................................................\", \"........... 134\\nReferences .........................................................................\", \"................................................................................................ 134\", \"\\nMonitoring in Azure Kubernetes Services ...........................................................\", \"...................................................... 134\\nAzure Monitor for Containers ............\", \"....................................................................................................\", \"................... 134\\nLog.Finalize() .............................................................\", \"....................................................................................................\", \"... 136\\nAzure Monitor ..............................................................................\", \"........................................................................................ 136\\nGatheri\", \"ng logs and metrics ................................................................................\", \"........................................................ 137\\nReporting data ........................\", \"....................................................................................................\", \".................................... 137\\nDashboards ................................................\", \"....................................................................................................\", \"................... 138\\nAlerts .....................................................................\", \"....................................................................................................\", \".......... 140\\nReferences ..........................................................................\", \"............................................................................................... 141\\n\", \"Cloud-native identity ..............................................................................\", \"............................ 142\\nReferences ........................................................\", \"....................................................................................................\", \"................. 142\\nAuthentication and authorization in cloud-native apps ........................\", \"............................................................. 142\\nReferences .......................\", \"....................................................................................................\", \".............................................. 143\\nAzure Active Directory ..........................\", \"....................................................................................................\", \"........................ 143\\nReferences ............................................................\", \"....................................................................................................\", \"......... 143\\nIdentityServer for cloud-native applications .........................................\", \"................................................................... 144\\nCommon web app scenarios ...\", \"....................................................................................................\", \".............................. 144\\nGetting started .................................................\", \"....................................................................................................\", \"........... 145\\nConfiguration ......................................................................\", \"............................................................................................. 145\\nJa\", \"vaScript clients ...................................................................................\", \"......................................................................... 146\\nReferences ...........\", \"....................................................................................................\", \".......................................................... 146\\nv ContentsCloud-native security .....\", \"....................................................................................................\", \". 147\\nAzure security for cloud-native apps .........................................................\", \"................................................................. 147\\nThreat modeling ..............\", \"....................................................................................................\", \"........................................... 148\\nPrinciple of least privilege .......................\", \"....................................................................................................\", \"................ 148\\nPenetration testing ...........................................................\", \"............................................................................................. 149\\nMo\", \"nitoring ...........................................................................................\", \"............................................................................. 149\\nSecuring the build\", \" ...................................................................................................\", \"....................................................... 149\\nBuilding secure code ...................\", \"....................................................................................................\", \"............................. 150\\nBuilt-in security ................................................\", \"....................................................................................................\", \"........... 150\\nAzure network infrastructure .......................................................\", \".............................................................................. 150\\nRole-based access\", \" control for restricting access to Azure resources..................................................\", \"...... 152\\nSecurity Principals .....................................................................\", \"..................................................................................... 152\\nRoles ....\", \"....................................................................................................\", \"............................................................................ 153\\nScopes ............\", \"....................................................................................................\", \"................................................................ 154\\nDeny ..........................\", \"....................................................................................................\", \"...................................................... 154\\nChecking access .........................\", \"....................................................................................................\", \"................................. 154\\nSecuring secrets .............................................\", \"....................................................................................................\", \"............. 155\\nAzure Key Vault ..................................................................\", \"............................................................................................. 155\\nKu\", \"bernetes ...........................................................................................\", \"............................................................................. 155\\nEncryption in tran\", \"sit and at rest ....................................................................................\", \"........................................... 156\\nKeeping secure .....................................\", \"....................................................................................................\", \"....................... 160\\nDevOps .................................................................\", \"................................................................ 161\\nAzure DevOps ..................\", \"....................................................................................................\", \"................................................. 162\\nGitHub Actions ...............................\", \"....................................................................................................\", \".................................. 163\\nSource control ..............................................\", \"....................................................................................................\", \".................... 163\\nRepository per microservice ...............................................\", \"....................................................................................... 164\\nSingle r\", \"epository ..........................................................................................\", \".................................................................. 166\\nStandard directory structure \", \"....................................................................................................\", \".................................. 167\\nTask management .............................................\", \"....................................................................................................\", \"............. 167\\nCI/CD pipelines ..................................................................\", \".................................................................................................. 1\", \"69\\nAzure Builds ....................................................................................\", \".................................................................................. 170\\nAzure DevOps \", \"releases ...........................................................................................\", \"..................................................... 172\\nvi ContentsEverybody gets a build pipeline\", \" ...................................................................................................\", \"............................ 173\\nVersioning releases ...............................................\", \"....................................................................................................\", \"..... 173\\nFeature flags ............................................................................\", \"............................................................................................. 173\\nIm\", \"plementing feature flags ...........................................................................\", \"............................................................. 174\\nInfrastructure as code ...........\", \"....................................................................................................\", \"........................................ 175\\nAzure Resource Manager templates ......................\", \"................................................................................................ 175\", \"\\nTerraform .........................................................................................\", \".................................................................................. 176\\nAzure CLI Scr\", \"ipts and Tasks......................................................................................\", \".................................................. 177\\nCloud Native Application Bundles ............\", \"....................................................................................................\", \"............... 178\\nDevOps Decisions ...............................................................\", \"........................................................................................... 180\\nRefe\", \"rences .............................................................................................\", \"............................................................................ 180\\nSummary: Architecti\", \"ng cloud-native apps ....................................................................... 181\\nvii\", \" Contents1\\nCHAPTER\\nIntroduction to cloud-\\nnative applications\\nAnother day, at the office, working on\", \" \\u201cthe next big thing.\\u201d\\nYour cellphone rings. It\\u2019s your friendly recruiter - the one who calls daily \", \"with exciting new\\nopportunities.\\nBut this time it\\u2019s different: Start-up, equity, and plenty of fundi\", \"ng.\\nThe mention of the cloud, microservices, and cutting-edge technology pushes you over the edge.\\nF\", \"ast forward a few weeks and you\\u2019re now a new employee in a design session architecting a major\\neComm\", \"erce application. You\\u2019re going to compete with the leading eCommerce sites.\\nHow will you build it?\\nI\", \"f you follow the guidance from past 15 years, you\\u2019ll most likely build the system shown in Figure 1.\", \"1.\\nFigure 1-1. Traditional monolithic design\\nYou construct a large core application containing all o\", \"f your domain logic. It includes modules such as\\nIdentity, Catalog, Ordering, and more. They directl\", \"y communicate with each other within a single\\nserver process. The modules share a large relational d\", \"atabase. The core exposes functionality via an\\nHTML interface and a mobile app.\\nCongratulations! You\", \" just created a monolithic application.\\nNot all is bad. Monoliths offer some distinct advantages. Fo\", \"r example, they\\u2019re straightforward to\\u2026\\n1 CHAPTER 1 | Introduction to cloud-native applications\\u2022 buil\", \"d\\n\\u2022 test\\n\\u2022 deploy\\n\\u2022 troubleshoot\\n\\u2022 vertically scale\\nMany successful apps that exist today were creat\", \"ed as monoliths. The app is a hit and continues to\\nevolve, iteration after iteration, adding more fu\", \"nctionality.\\nAt some point, however, you begin to feel uncomfortable. You find yourself losing contr\", \"ol of the\\napplication. As time goes on, the feeling becomes more intense, and you eventually enter a\", \" state\\nknown as the Fear Cycle:\\n\\u2022 The app has become so overwhelmingly complicated that no single pe\", \"rson understands it.\\n\\u2022 You fear making changes - each change has unintended and costly side effects.\", \"\\n\\u2022 New features/fixes become tricky, time-consuming, and expensive to implement.\\n\\u2022 Each release beco\", \"mes as small as possible and requires a full deployment of the entire\\napplication.\\n\\u2022 One unstable co\", \"mponent can crash the entire system.\\n\\u2022 New technologies and frameworks aren\\u2019t an option.\\n\\u2022 It\\u2019s diff\", \"icult to implement agile delivery methodologies.\\n\\u2022 Architectural erosion sets in as the code base de\", \"teriorates with never-ending \\u201cquick fixes.\\u201d\\n\\u2022 Finally, the consultants come in and tell you to rewri\", \"te it.\\nSound familiar?\\nMany organizations have addressed this monolithic fear cycle by adopting a cl\", \"oud-native approach to\\nbuilding systems. Figure 1-2 shows the same system built applying cloud-nativ\", \"e techniques and\\npractices.\\n2 CHAPTER 1 | Introduction to cloud-native applicationsFigure 1-2. Cloud\", \"-native design\\nNote how the application is decomposed across a set of small isolated microservices. \", \"Each service is\\nself-contained and encapsulates its own code, data, and dependencies. Each is deploy\", \"ed in a software\\ncontainer and managed by a container orchestrator. Instead of a large relational da\", \"tabase, each\\nservice owns it own datastore, the type of which vary based upon the data needs. Note h\", \"ow some\\nservices depend on a relational database, but other on NoSQL databases. One service stores i\", \"ts state\\nin a distributed cache. Note how all traffic routes through an API Gateway service that is \", \"responsible\\nfor routing traffic to the core back-end services and enforcing many cross-cutting conce\", \"rns. Most\\nimportantly, the application takes full advantage of the scalability, availability, and re\", \"siliency features\\nfound in modern cloud platforms.\\nCloud-native computing\\nHmm\\u2026 We just used the term\", \", Cloud Native. Your first thought might be, \\u201cWhat exactly does that\\nmean?\\u201d Another industry buzzwor\", \"d concocted by software vendors to market more stuff?\\u201d\\nFortunately it\\u2019s far different, and hopefully\", \" this book will help convince you.\\nWithin a short time, cloud native has become a driving trend in t\", \"he software industry. It\\u2019s a new way\\nto construct large, complex systems. The approach takes full ad\", \"vantage of modern software\\ndevelopment practices, technologies, and cloud infrastructure. Cloud nati\", \"ve changes the way you\\ndesign, implement, deploy, and operationalize systems.\\nUnlike the continuous \", \"hype that drives our industry, cloud native is for-real. Consider the Cloud Native\\nComputing Foundat\", \"ion (CNCF), a consortium of over 400 major corporations. Its charter is to make\\n3 CHAPTER 1 | Introd\", \"uction to cloud-native applicationscloud-native computing ubiquitous across technology and cloud sta\", \"cks. As one of the most influential\\nopen-source groups, it hosts many of the fastest-growing open so\", \"urce-projects in GitHub. These\\nprojects include Kubernetes, Prometheus, Helm, Envoy, and gRPC.\\nThe C\", \"NCF fosters an ecosystem of open-source and vendor-neutrality. Following that lead, this book\\npresen\", \"ts cloud-native principles, patterns, and best practices that are technology agnostic. At the\\nsame t\", \"ime, we discuss the services and infrastructure available in the Microsoft Azure cloud for\\nconstruct\", \"ing cloud-native systems.\\nSo, what exactly is Cloud Native? Sit back, relax, and let us help you exp\", \"lore this new world.\\nWhat is Cloud Native?\\nStop what you\\u2019re doing and ask your colleagues to define \", \"the term \\u201cCloud Native\\u201d. There\\u2019s a good\\nchance you\\u2019ll get several different answers.\\nLet\\u2019s start wit\", \"h a simple definition:\\nCloud-native architecture and technologies are an approach to designing, cons\", \"tructing, and operating\\nworkloads that are built in the cloud and take full advantage of the cloud c\", \"omputing model.\\nThe Cloud Native Computing Foundation provides the official definition:\\nCloud-native\", \" technologies empower organizations to build and run scalable applications in modern,\\ndynamic enviro\", \"nments such as public, private, and hybrid clouds. Containers, service meshes,\\nmicroservices, immuta\", \"ble infrastructure, and declarative APIs exemplify this approach.\\nThese techniques enable loosely co\", \"upled systems that are resilient, manageable, and observable.\\nCombined with robust automation, they \", \"allow engineers to make high-impact changes frequently and\\npredictably with minimal toil.\\nCloud nati\", \"ve is about speed and agility. Business systems are evolving from enabling business\\ncapabilities to \", \"weapons of strategic transformation that accelerate business velocity and growth. It\\u2019s\\nimperative to\", \" get new ideas to market immediately.\\nAt the same time, business systems have also become increasing\", \"ly complex with users demanding\\nmore. They expect rapid responsiveness, innovative features, and zer\", \"o downtime. Performance\\nproblems, recurring errors, and the inability to move fast are no longer acc\", \"eptable. Your users will visit\\nyour competitor. Cloud-native systems are designed to embrace rapid c\", \"hange, large scale, and\\nresilience.\\nHere are some companies who have implemented cloud-native techni\", \"ques. Think about the speed,\\nagility, and scalability they\\u2019ve achieved.\\nCompany Experience\\nNetflix H\", \"as 600+ services in production. Deploys 100\\ntimes per day.\\nUber Has 1,000+ services in production. D\", \"eploys\\nseveral thousand times each week.\\n4 CHAPTER 1 | Introduction to cloud-native applicationsComp\", \"any Experience\\nWeChat Has 3,000+ services in production. Deploys\\n1,000 times a day.\\nAs you can see, \", \"Netflix, Uber, and, WeChat expose cloud-native systems that consist of many\\nindependent services. Th\", \"is architectural style enables them to rapidly respond to market conditions.\\nThey instantaneously up\", \"date small areas of a live, complex application, without a full redeployment.\\nThey individually scal\", \"e services as needed.\\nThe pillars of cloud native\\nThe speed and agility of cloud native derive from \", \"many factors. Foremost is cloud infrastructure. But\\nthere\\u2019s more: Five other foundational pillars sh\", \"own in Figure 1-3 also provide the bedrock for cloud-\\nnative systems.\\nFigure 1-3. Cloud-native found\", \"ational pillars\\nLet\\u2019s take some time to better understand the significance of each pillar.\\nThe cloud\", \"\\nCloud-native systems take full advantage of the cloud service model.\\nDesigned to thrive in a dynami\", \"c, virtualized cloud environment, these systems make extensive use of\\nPlatform as a Service (PaaS) c\", \"ompute infrastructure and managed services. They treat the underlying\\ninfrastructure as disposable -\", \" provisioned in minutes and resized, scaled, or destroyed on demand \\u2013\\nvia automation.\\nConsider the w\", \"idely accepted DevOps concept of Pets vs. Cattle. In a traditional data center, servers\\nare treated \", \"as Pets: a physical machine, given a meaningful name, and cared for. You scale by adding\\nmore resour\", \"ces to the same machine (scaling up). If the server becomes sick, you nurse it back to\\nhealth. Shoul\", \"d the server become unavailable, everyone notices.\\nThe Cattle service model is different. You provis\", \"ion each instance as a virtual machine or container.\\nThey\\u2019re identical and assigned a system identif\", \"ier such as Service-01, Service-02, and so on. You scale\\nby creating more of them (scaling out). Whe\", \"n one becomes unavailable, nobody notices.\\n5 CHAPTER 1 | Introduction to cloud-native applicationsTh\", \"e cattle model embraces immutable infrastructure. Servers aren\\u2019t repaired or modified. If one fails \", \"or\\nrequires updating, it\\u2019s destroyed and a new one is provisioned \\u2013 all done via automation.\\nCloud-n\", \"ative systems embrace the Cattle service model. They continue to run as the infrastructure\\nscales in\", \" or out with no regard to the machines upon which they\\u2019re running.\\nThe Azure cloud platform supports\", \" this type of highly elastic infrastructure with automatic scaling,\\nself-healing, and monitoring cap\", \"abilities.\\nModern design\\nHow would you design a cloud-native app? What would your architecture look \", \"like? To what\\nprinciples, patterns, and best practices would you adhere? What infrastructure and ope\", \"rational\\nconcerns would be important?\\nThe Twelve-Factor Application\\nA widely accepted methodology fo\", \"r constructing cloud-based applications is the Twelve-Factor\\nApplication. It describes a set of prin\", \"ciples and practices that developers follow to construct\\napplications optimized for modern cloud env\", \"ironments. Special attention is given to portability across\\nenvironments and declarative automation.\", \"\\nWhile applicable to any web-based application, many practitioners consider Twelve-Factor a solid\\nfo\", \"undation for building cloud-native apps. Systems built upon these principles can deploy and scale\\nra\", \"pidly and add features to react quickly to market changes.\\nThe following table highlights the Twelve\", \"-Factor methodology:\\nFactor Explanation\\n1 - Code Base A single code base for each microservice, stor\", \"ed\\nin its own repository. Tracked with version\\ncontrol, it can deploy to multiple environments\\n(QA, \", \"Staging, Production).\\n2 - Dependencies Each microservice isolates and packages its own\\ndependencies,\", \" embracing changes without\\nimpacting the entire system.\\n3 - Configurations Configuration information\", \" is moved out of the\\nmicroservice and externalized through a\\nconfiguration management tool outside o\", \"f the\\ncode. The same deployment can propagate\\nacross environments with the correct\\nconfiguration app\", \"lied.\\n4 - Backing Services Ancillary resources (data stores, caches,\\nmessage brokers) should be expo\", \"sed via an\\naddressable URL. Doing so decouples the\\nresource from the application, enabling it to be\\n\", \"interchangeable.\\n6 CHAPTER 1 | Introduction to cloud-native applicationsFactor Explanation\\n5 - Build\", \", Release, Run Each release must enforce a strict separation\\nacross the build, release, and run stag\", \"es. Each\\nshould be tagged with a unique ID and support\\nthe ability to roll back. Modern CI/CD system\", \"s\\nhelp fulfill this principle.\\n6 - Processes Each microservice should execute in its own\\nprocess, is\", \"olated from other running services.\\nExternalize required state to a backing service\\nsuch as a distri\", \"buted cache or data store.\\n7 - Port Binding Each microservice should be self-contained with\\nits inte\", \"rfaces and functionality exposed on its\\nown port. Doing so provides isolation from\\nother microservic\", \"es.\\n8 - Concurrency When capacity needs to increase, scale out\\nservices horizontally across multiple\", \" identical\\nprocesses (copies) as opposed to scaling-up a\\nsingle large instance on the most powerful\\n\", \"machine available. Develop the application to be\\nconcurrent making scaling out in cloud\\nenvironments\", \" seamless.\\n9 - Disposability Service instances should be disposable. Favor\\nfast startup to increase \", \"scalability opportunities\\nand graceful shutdowns to leave the system in a\\ncorrect state. Docker cont\", \"ainers along with an\\norchestrator inherently satisfy this requirement.\\n10 - Dev/Prod Parity Keep env\", \"ironments across the application\\nlifecycle as similar as possible, avoiding costly\\nshortcuts. Here, \", \"the adoption of containers can\\ngreatly contribute by promoting the same\\nexecution environment.\\n11 - \", \"Logging Treat logs generated by microservices as event\\nstreams. Process them with an event\\naggregato\", \"r. Propagate log data to data-\\nmining/log management tools like Azure\\nMonitor or Splunk and eventual\", \"ly to long-term\\narchival.\\n12 - Admin Processes Run administrative/management tasks, such as\\ndata cle\", \"anup or computing analytics, as one-off\\nprocesses. Use independent tools to invoke\\nthese tasks from \", \"the production environment,\\nbut separately from the application.\\n7 CHAPTER 1 | Introduction to cloud\", \"-native applicationsIn the book, Beyond the Twelve-Factor App, author Kevin Hoffman details each of \", \"the original 12\\nfactors (written in 2011). Additionally, he discusses three extra factors that refle\", \"ct today\\u2019s modern\\ncloud application design.\\nNew Factor Explanation\\n13 - API First Make everything a \", \"service. Assume your code\\nwill be consumed by a front-end client, gateway,\\nor another service.\\n14 - \", \"Telemetry On a workstation, you have deep visibility into\\nyour application and its behavior. In the \", \"cloud,\\nyou don\\u2019t. Make sure your design includes the\\ncollection of monitoring, domain-specific, and\\n\", \"health/system data.\\n15 - Authentication/ Authorization Implement identity from the start. Consider\\nR\", \"BAC (role-based access control) features\\navailable in public clouds.\\nWe\\u2019ll refer to many of the 12+ \", \"factors in this chapter and throughout the book.\\nAzure Well-Architected Framework\\nDesigning and depl\", \"oying cloud-based workloads can be challenging, especially when implementing\\ncloud-native architectu\", \"re. Microsoft provides industry standard best practices to help you and your\\nteam deliver robust clo\", \"ud solutions.\\nThe Microsoft Well-Architected Framework provides a set of guiding tenets that can be \", \"used to\\nimprove the quality of a cloud-native workload. The framework consists of five pillars of ar\", \"chitecture\\nexcellence:\\nTenets Description\\nCost management Focus on generating incremental value earl\", \"y.\\nApply Build-Measure-Learn principles to\\naccelerate time to market while avoiding\\ncapital-intensiv\", \"e solutions. Using a pay-as-you-\\ngo strategy, invest as you scale out, rather than\\ndelivering a larg\", \"e investment up front.\\nOperational excellence Automate the environment and operations to\\nincrease sp\", \"eed and reduce human error. Roll\\nproblem updates back or forward quickly.\\nImplement monitoring and d\", \"iagnostics from the\\nstart.\\nPerformance efficiency Efficiently meet demands placed on your\\nworkloads.\", \" Favor horizontal scaling (scaling out)\\nand design it into your systems. Continually\\nconduct perform\", \"ance and load testing to\\nidentify potential bottlenecks.\\n8 CHAPTER 1 | Introduction to cloud-native \", \"applicationsTenets Description\\nReliability Build workloads that are both resilient and\\navailable. Re\", \"siliency enables workloads to\\nrecover from failures and continue functioning.\\nAvailability ensures u\", \"sers access to your\\nworkload at all times. Design applications to\\nexpect failures and recover from t\", \"hem.\\nSecurity Implement security across the entire lifecycle of\\nan application, from design and impl\", \"ementation\\nto deployment and operations. Pay close\\nattention to identity management, infrastructure\\n\", \"access, application security, and data\\nsovereignty and encryption.\\nTo get started, Microsoft provide\", \"s a set of online assessments to help you assess your current cloud\\nworkloads against the five well-\", \"architected pillars.\\nMicroservices\\nCloud-native systems embrace microservices, a popular architectur\", \"al style for constructing modern\\napplications.\\nBuilt as a distributed set of small, independent serv\", \"ices that interact through a shared fabric,\\nmicroservices share the following characteristics:\\n\\u2022 Eac\", \"h implements a specific business capability within a larger domain context.\\n\\u2022 Each is developed auto\", \"nomously and can be deployed independently.\\n\\u2022 Each is self-contained encapsulating its own data stor\", \"age technology, dependencies, and\\nprogramming platform.\\n\\u2022 Each runs in its own process and communica\", \"tes with others using standard communication\\nprotocols such as HTTP/HTTPS, gRPC, WebSockets, or AMQP\", \".\\n\\u2022 They compose together to form an application.\\nFigure 1-4 contrasts a monolithic application appr\", \"oach with a microservices approach. Note how the\\nmonolith is composed of a layered architecture, whi\", \"ch executes in a single process. It typically\\nconsumes a relational database. The microservice appro\", \"ach, however, segregates functionality into\\nindependent services, each with its own logic, state, an\", \"d data. Each microservice hosts its own\\ndatastore.\\n9 CHAPTER 1 | Introduction to cloud-native applic\", \"ationsFigure 1-4. Monolithic versus microservices architecture\\nNote how microservices promote the Pr\", \"ocesses principle from the Twelve-Factor Application,\\ndiscussed earlier in the chapter.\\nFactor #6 sp\", \"ecifies \\u201cEach microservice should execute in its own process, isolated from other running\\nservices.\\u201d\", \"\\nWhy microservices?\\nMicroservices provide agility.\\nEarlier in the chapter, we compared an eCommerce \", \"application built as a monolith to that with\\nmicroservices. In the example, we saw some clear benefi\", \"ts:\\n\\u2022 Each microservice has an autonomous lifecycle and can evolve independently and deploy\\nfrequent\", \"ly. You don\\u2019t have to wait for a quarterly release to deploy a new feature or update.\\nYou can update\", \" a small area of a live application with less risk of disrupting the entire system.\\nThe update can b\", \"e made without a full redeployment of the application.\\n\\u2022 Each microservice can scale independently. \", \"Instead of scaling the entire application as a single\\nunit, you scale out only those services that r\", \"equire more processing power to meet desired\\nperformance levels and service-level agreements. Fine-g\", \"rained scaling provides for greater\\ncontrol of your system and helps reduce overall costs as you sca\", \"le portions of your system,\\nnot everything.\\nAn excellent reference guide for understanding microserv\", \"ices is .NET Microservices: Architecture for\\nContainerized .NET Applications. The book deep dives in\", \"to microservices design and architecture. It\\u2019s\\na companion for a full-stack microservice reference a\", \"rchitecture available as a free download from\\nMicrosoft.\\nDeveloping microservices\\nMicroservices can \", \"be created upon any modern development platform.\\n10 CHAPTER 1 | Introduction to cloud-native applica\", \"tionsThe Microsoft .NET platform is an excellent choice. Free and open source, it has many built-in \", \"features\\nthat simplify microservice development. .NET is cross-platform. Applications can be built a\", \"nd run on\\nWindows, macOS, and most flavors of Linux.\\n.NET is highly performant and has scored well i\", \"n comparison to Node.js and other competing\\nplatforms. Interestingly, TechEmpower conducted an exten\", \"sive set of performance benchmarks across\\nmany web application platforms and frameworks. .NET scored\", \" in the top 10 - well above Node.js and\\nother competing platforms.\\n.NET is maintained by Microsoft a\", \"nd the .NET community on GitHub.\\nMicroservice challenges\\nWhile distributed cloud-native microservice\", \"s can provide immense agility and speed, they present\\nmany challenges:\\nCommunication\\nHow will front-\", \"end client applications communicate with backed-end core microservices? Will you\\nallow direct commun\", \"ication? Or, might you abstract the back-end microservices with a gateway\\nfacade that provides flexi\", \"bility, control, and security?\\nHow will back-end core microservices communicate with each other? Wil\", \"l you allow direct HTTP calls\\nthat can increase coupling and impact performance and agility? Or migh\", \"t you consider decoupled\\nmessaging with queue and topic technologies?\\nCommunication is covered in th\", \"e Cloud-native communication patterns chapter.\\nResiliency\\nA microservices architecture moves your sy\", \"stem from in-process to out-of-process network\\ncommunication. In a distributed architecture, what ha\", \"ppens when Service B isn\\u2019t responding to a\\nnetwork call from Service A? Or, what happens when Servic\", \"e C becomes temporarily unavailable and\\nother services calling it become blocked?\\nResiliency is cove\", \"red in the Cloud-native resiliency chapter.\\nDistributed Data\\nBy design, each microservice encapsulat\", \"es its own data, exposing operations via its public interface. If\\nso, how do you query data or imple\", \"ment a transaction across multiple services?\\nDistributed data is covered in the Cloud-native data pa\", \"tterns chapter.\\nSecrets\\nHow will your microservices securely store and manage secrets and sensitive \", \"configuration data?\\nSecrets are covered in detail Cloud-native security.\\n11 CHAPTER 1 | Introduction\", \" to cloud-native applicationsManage Complexity with Dapr\\nDapr is a distributed, open-source applicat\", \"ion runtime. Through an architecture of pluggable\\ncomponents, it dramatically simplifies the plumbin\", \"g behind distributed applications. It provides a\\ndynamic glue that binds your application with pre-b\", \"uilt infrastructure capabilities and components\\nfrom the Dapr runtime. Figure 1-5 shows Dapr from 20\", \",000 feet.\\nFigure 1-5. Dapr at 20,000 feet.\\nIn the top row of the figure, note how Dapr provides lan\", \"guage-specific SDKs for popular development\\nplatforms. Dapr v1 includes support for .NET, Go, Node.j\", \"s, Python, PHP, Java, and JavaScript.\\nWhile language-specific SDKs enhance the developer experience,\", \" Dapr is platform agnostic. Under the\\nhood, Dapr\\u2019s programming model exposes capabilities through st\", \"andard HTTP/gRPC communication\\nprotocols. Any programming platform can call Dapr via its native HTTP\", \" and gRPC APIs.\\nThe blue boxes across the center of the figure represent the Dapr building blocks. E\", \"ach exposes pre-\\nbuilt plumbing code for a distributed application capability that your application \", \"can consume.\\nThe components row represents a large set of pre-defined infrastructure components that\", \" your\\napplication can consume. Think of components as infrastructure code you don\\u2019t have to write.\\nT\", \"he bottom row highlights the portability of Dapr and the diverse environments across which it can\\nru\", \"n.\\nMicrosoft features a free ebook Dapr for .NET Developers for learning Dapr.\\nLooking ahead, Dapr h\", \"as the potential to have a profound impact on cloud-native application\\ndevelopment.\\nContainers\\nIt\\u2019s \", \"natural to hear the term container mentioned in any cloud native conversation. In the book, Cloud\\nNa\", \"tive Patterns, author Cornelia Davis observes that, \\u201cContainers are a great enabler of cloud-native\\n\", \"12 CHAPTER 1 | Introduction to cloud-native applicationssoftware.\\u201d The Cloud Native Computing Founda\", \"tion places microservice containerization as the first\\nstep in their Cloud-Native Trail Map - guidan\", \"ce for enterprises beginning their cloud-native journey.\\nContainerizing a microservice is simple and\", \" straightforward. The code, its dependencies, and runtime\\nare packaged into a binary called a contai\", \"ner image. Images are stored in a container registry, which\\nacts as a repository or library for imag\", \"es. A registry can be located on your development computer, in\\nyour data center, or in a public clou\", \"d. Docker itself maintains a public registry via Docker Hub. The\\nAzure cloud features a private cont\", \"ainer registry to store container images close to the cloud\\napplications that will run them.\\nWhen an\", \" application starts or scales, you transform the container image into a running container\\ninstance. \", \"The instance runs on any computer that has a container runtime engine installed. You can\\nhave as man\", \"y instances of the containerized service as needed.\\nFigure 1-6 shows three different microservices, \", \"each in its own container, all running on a single host.\\nFigure 1-6. Multiple containers running on \", \"a container host\\nNote how each container maintains its own set of dependencies and runtime, which ca\", \"n be different\\nfrom one another. Here, we see different versions of the Product microservice running\", \" on the same\\nhost. Each container shares a slice of the underlying host operating system, memory, an\", \"d processor,\\nbut is isolated from one another.\\nNote how well the container model embraces the Depend\", \"encies principle from the Twelve-Factor\\nApplication.\\nFactor #2 specifies that \\u201cEach microservice iso\", \"lates and packages its own dependencies, embracing\\nchanges without impacting the entire system.\\u201d\\nCon\", \"tainers support both Linux and Windows workloads. The Azure cloud openly embraces both.\\nInterestingl\", \"y, it\\u2019s Linux, not Windows Server, that has become the more popular operating system in\\nAzure.\\n13 CH\", \"APTER 1 | Introduction to cloud-native applicationsWhile several container vendors exist, Docker has\", \" captured the lion\\u2019s share of the market. The\\ncompany has been driving the software container moveme\", \"nt. It has become the de facto standard for\\npackaging, deploying, and running cloud-native applicati\", \"ons.\\nWhy containers?\\nContainers provide portability and guarantee consistency across environments. B\", \"y encapsulating\\neverything into a single package, you isolate the microservice and its dependencies \", \"from the\\nunderlying infrastructure.\\nYou can deploy the container in any environment that hosts the D\", \"ocker runtime engine. Containerized\\nworkloads also eliminate the expense of pre-configuring each env\", \"ironment with frameworks, software\\nlibraries, and runtime engines.\\nBy sharing the underlying operati\", \"ng system and host resources, a container has a much smaller\\nfootprint than a full virtual machine. \", \"The smaller size increases the density, or number of\\nmicroservices, that a given host can run at one\", \" time.\\nContainer orchestration\\nWhile tools such as Docker create images and run containers, you also\", \" need tools to manage them.\\nContainer management is done with a special software program called a co\", \"ntainer orchestrator.\\nWhen operating at scale with many independent running containers, orchestratio\", \"n is essential.\\nFigure 1-7 shows management tasks that container orchestrators automate.\\nFigure 1-7.\", \" What container orchestrators do\\nThe following table describes common orchestration tasks.\\nTasks Exp\", \"lanation\\nScheduling Automatically provision container instances.\\nAffinity/anti-affinity Provision co\", \"ntainers nearby or far apart from\\neach other, helping availability and\\nperformance.\\nHealth monitorin\", \"g Automatically detect and correct failures.\\nFailover Automatically reprovision a failed instance to\", \" a\\nhealthy machine.\\n14 CHAPTER 1 | Introduction to cloud-native applicationsTasks Explanation\\nScalin\", \"g Automatically add or remove a container\\ninstance to meet demand.\\nNetworking Manage a networking ov\", \"erlay for container\\ncommunication.\\nService Discovery Enable containers to locate each other.\\nRolling\", \" Upgrades Coordinate incremental upgrades with zero\\ndowntime deployment. Automatically roll back\\npro\", \"blematic changes.\\nNote how container orchestrators embrace the Disposability and Concurrency princip\", \"les from the\\nTwelve-Factor Application.\\nFactor #9 specifies that \\u201cService instances should be dispos\", \"able, favoring fast startups to increase\\nscalability opportunities and graceful shutdowns to leave t\", \"he system in a correct state.\\u201d Docker\\ncontainers along with an orchestrator inherently satisfy this \", \"requirement.\\u201d\\nFactor #8 specifies that \\u201cServices scale out across a large number of small identical \", \"processes (copies) as\\nopposed to scaling-up a single large instance on the most powerful machine ava\", \"ilable.\\u201d\\nWhile several container orchestrators exist, Kubernetes has become the de facto standard fo\", \"r the\\ncloud-native world. It\\u2019s a portable, extensible, open-source platform for managing containeriz\", \"ed\\nworkloads.\\nYou could host your own instance of Kubernetes, but then you\\u2019d be responsible for prov\", \"isioning and\\nmanaging its resources - which can be complex. The Azure cloud features Kubernetes as a\", \" managed\\nservice. Both Azure Kubernetes Service (AKS) and Azure Red Hat OpenShift (ARO) enable you t\", \"o fully\\nleverage the features and power of Kubernetes as a managed service, without having to instal\", \"l and\\nmaintain it.\\nContainer orchestration is covered in detail in Scaling Cloud-Native Applications\", \".\\nBacking services\\nCloud-native systems depend upon many different ancillary resources, such as data\", \" stores, message\\nbrokers, monitoring, and identity services. These services are known as backing ser\", \"vices.\\nFigure 1-8 shows many common backing services that cloud-native systems consume.\\n15 CHAPTER 1\", \" | Introduction to cloud-native applicationsFigure 1-8. Common backing services\\nYou could host your \", \"own backing services, but then you\\u2019d be responsible for licensing, provisioning,\\nand managing those \", \"resources.\\nCloud providers offer a rich assortment of managed backing services. Instead of owning th\", \"e service,\\nyou simply consume it. The cloud provider operates the resource at scale and bears the re\", \"sponsibility\\nfor performance, security, and maintenance. Monitoring, redundancy, and availability ar\", \"e built into the\\nservice. Providers guarantee service level performance and fully support their mana\", \"ged services -\\nopen a ticket and they fix your issue.\\nCloud-native systems favor managed backing ser\", \"vices from cloud vendors. The savings in time and\\nlabor can be significant. The operational risk of \", \"hosting your own and experiencing trouble can get\\nexpensive fast.\\nA best practice is to treat a back\", \"ing service as an attached resource, dynamically bound to a\\nmicroservice with configuration informat\", \"ion (a URL and credentials) stored in an external\\nconfiguration. This guidance is spelled out in the\", \" Twelve-Factor Application, discussed earlier in the\\nchapter.\\nFactor #4 specifies that backing servi\", \"ces \\u201cshould be exposed via an addressable URL. Doing so\\ndecouples the resource from the application,\", \" enabling it to be interchangeable.\\u201d\\nFactor #3 specifies that \\u201cConfiguration information is moved ou\", \"t of the microservice and externalized\\nthrough a configuration management tool outside of the code.\\u201d\", \"\\nWith this pattern, a backing service can be attached and detached without code changes. You might\\np\", \"romote a microservice from QA to a staging environment. You update the microservice\\nconfiguration to\", \" point to the backing services in staging and inject the settings into your container\\nthrough an env\", \"ironment variable.\\n16 CHAPTER 1 | Introduction to cloud-native applicationsCloud vendors provide API\", \"s for you to communicate with their proprietary backing services. These\\nlibraries encapsulate the pr\", \"oprietary plumbing and complexity. However, communicating directly with\\nthese APIs will tightly coup\", \"le your code to that specific backing service. It\\u2019s a widely accepted practice\\nto insulate the imple\", \"mentation details of the vendor API. Introduce an intermediation layer, or\\nintermediate API, exposin\", \"g generic operations to your service code and wrap the vendor code inside\\nit. This loose coupling en\", \"ables you to swap out one backing service for another or move your code to\\na different cloud environ\", \"ment without having to make changes to the mainline service code. Dapr,\\ndiscussed earlier, follows t\", \"his model with its set of prebuilt building blocks.\\nOn a final thought, backing services also promot\", \"e the Statelessness principle from the Twelve-Factor\\nApplication, discussed earlier in the chapter.\\n\", \"Factor #6 specifies that, \\u201cEach microservice should execute in its own process, isolated from other\\n\", \"running services. Externalize required state to a backing service such as a distributed cache or dat\", \"a\\nstore.\\u201d\\nBacking services are discussed in Cloud-native data patterns and Cloud-native communicatio\", \"n\\npatterns.\\nAutomation\\nAs you\\u2019ve seen, cloud-native systems embrace microservices, containers, and m\", \"odern system design\\nto achieve speed and agility. But, that\\u2019s only part of the story. How do you pro\", \"vision the cloud\\nenvironments upon which these systems run? How do you rapidly deploy app features a\", \"nd updates?\\nHow do you round out the full picture?\\nEnter the widely accepted practice of Infrastruct\", \"ure as Code, or IaC.\\nWith IaC, you automate platform provisioning and application deployment. You es\", \"sentially apply\\nsoftware engineering practices such as testing and versioning to your DevOps practic\", \"es. Your\\ninfrastructure and deployments are automated, consistent, and repeatable.\\nAutomating infras\", \"tructure\\nTools like Azure Resource Manager, Azure Bicep, Terraform from HashiCorp, and the Azure CLI\", \", enable\\nyou to declaratively script the cloud infrastructure you require. Resource names, locations\", \", capacities,\\nand secrets are parameterized and dynamic. The script is versioned and checked into so\", \"urce control\\nas an artifact of your project. You invoke the script to provision a consistent and rep\", \"eatable\\ninfrastructure across system environments, such as QA, staging, and production.\\nUnder the ho\", \"od, IaC is idempotent, meaning that you can run the same script over and over without\\nside effects. \", \"If the team needs to make a change, they edit and rerun the script. Only the updated\\nresources are a\", \"ffected.\\nIn the article, What is Infrastructure as Code, Author Sam Guckenheimer describes how, \\u201cTea\", \"ms who\\nimplement IaC can deliver stable environments rapidly and at scale. They avoid manual configu\", \"ration\\nof environments and enforce consistency by representing the desired state of their environmen\", \"ts via\\ncode. Infrastructure deployments with IaC are repeatable and prevent runtime issues caused by\", \"\\nconfiguration drift or missing dependencies. DevOps teams can work together with a unified set of\\n1\", \"7 CHAPTER 1 | Introduction to cloud-native applicationspractices and tools to deliver applications a\", \"nd their supporting infrastructure rapidly, reliably, and at\\nscale.\\u201d\\nAutomating deployments\\nThe Twel\", \"ve-Factor Application, discussed earlier, calls for separate steps when transforming\\ncompleted code \", \"into a running application.\\nFactor #5 specifies that \\u201cEach release must enforce a strict separation \", \"across the build, release and run\\nstages. Each should be tagged with a unique ID and support the abi\", \"lity to roll back.\\u201d\\nModern CI/CD systems help fulfill this principle. They provide separate build an\", \"d delivery steps that\\nhelp ensure consistent and quality code that\\u2019s readily available to users.\\nFig\", \"ure 1-9 shows the separation across the deployment process.\\nFigure 1-9. Deployment steps in a CI/CD \", \"Pipeline\\nIn the previous figure, pay special attention to separation of tasks:\\n1. The developer cons\", \"tructs a feature in their development environment, iterating through what\\nis called the \\u201cinner loop\\u201d\", \" of code, run, and debug.\\n2. When complete, that code is pushed into a code repository, such as GitH\", \"ub, Azure DevOps, or\\nBitBucket.\\n3. The push triggers a build stage that transforms the code into a b\", \"inary artifact. The work is\\nimplemented with a Continuous Integration (CI) pipeline. It automaticall\", \"y builds, tests, and\\npackages the application.\\n4. The release stage picks up the binary artifact, ap\", \"plies external application and environment\\nconfiguration information, and produces an immutable rele\", \"ase. The release is deployed to a\\nspecified environment. The work is implemented with a Continuous D\", \"elivery (CD) pipeline.\\nEach release should be identifiable. You can say, \\u201cThis deployment is running\", \" Release 2.1.1 of\\nthe application.\\u201d\\n18 CHAPTER 1 | Introduction to cloud-native applications5. Final\", \"ly, the released feature is run in the target execution environment. Releases are\\nimmutable meaning \", \"that any change must create a new release.\\nApplying these practices, organizations have radically ev\", \"olved how they ship software. Many have\\nmoved from quarterly releases to on-demand updates. The goal\", \" is to catch problems early in the\\ndevelopment cycle when they\\u2019re less expensive to fix. The longer \", \"the duration between integrations,\\nthe more expensive problems become to resolve. With consistency i\", \"n the integration process, teams\\ncan commit code changes more frequently, leading to better collabor\", \"ation and software quality.\\nInfrastructure as code and deployment automation, along with GitHub and \", \"Azure DevOps are\\ndiscussed in detail in DevOps.\\nCandidate apps for cloud native\\nThink about the apps\", \" your organization needs to build. Then, look at the existing apps in your\\nportfolio. How many of th\", \"em warrant a cloud-native architecture? All of them? Perhaps some?\\nApplying cost/benefit analysis, t\", \"here\\u2019s a good chance some wouldn\\u2019t support the effort. The cost of\\nbecoming cloud native would far e\", \"xceed the business value of the application.\\nWhat type of application might be a candidate for cloud\", \" native?\\n\\u2022 Strategic enterprise systems that need to constantly evolve business capabilities/feature\", \"s\\n\\u2022 An application that requires a high release velocity - with high confidence\\n\\u2022 A system where ind\", \"ividual features must release without a full redeployment of the entire\\nsystem\\n\\u2022 An application deve\", \"loped by teams with expertise in different technology stacks\\n\\u2022 An application with components that m\", \"ust scale independently\\nSmaller, less impactful line-of-business applications might fare well with a\", \" simple monolithic\\narchitecture hosted in a Cloud PaaS environment.\\nThen there are legacy systems. W\", \"hile we\\u2019d all like to build new applications, we\\u2019re often responsible\\nfor modernizing legacy workloa\", \"ds that are critical to the business.\\nModernizing legacy apps\\nThe free Microsoft e-book Modernize ex\", \"isting .NET applications with Azure cloud and Windows\\nContainers provides guidance about migrating o\", \"n-premises workloads into cloud. Figure 1-10 shows\\nthat there isn\\u2019t a single, one-size-fits-all stra\", \"tegy for modernizing legacy applications.\\n19 CHAPTER 1 | Introduction to cloud-native applicationsFi\", \"gure 1-10. Strategies for migrating legacy workloads\\nMonolithic apps that are non-critical might ben\", \"efit from a quick lift-and-shift (Cloud Infrastructure-\\nReady) migration. Here, the on-premises work\", \"load is rehosted to a cloud-based VM, without changes.\\nThis approach uses the IaaS (Infrastructure a\", \"s a Service) model. Azure includes several tools such as\\nAzure Migrate, Azure Site Recovery, and Azu\", \"re Database Migration Service to help streamline the\\nmove. While this strategy can yield some cost s\", \"avings, such applications typically weren\\u2019t designed to\\nunlock and leverage the benefits of cloud co\", \"mputing.\\nLegacy apps that are critical to the business often benefit from an enhanced Cloud Optimize\", \"d\\nmigration. This approach includes deployment optimizations that enable key cloud services - withou\", \"t\\nchanging the core architecture of the application. For example, you might containerize the applica\", \"tion\\nand deploy it to a container orchestrator, like Azure Kubernetes Services, discussed later in t\", \"his book.\\nOnce in the cloud, the application can consume cloud backing services such as databases, m\", \"essage\\nqueues, monitoring, and distributed caching.\\nFinally, monolithic apps that provide strategic \", \"enterprise functions might best benefit from a Cloud-\\nNative approach, the subject of this book. Thi\", \"s approach provides agility and velocity. But, it comes at\\na cost of replatforming, rearchitecting, \", \"and rewriting code. Over time, a legacy application could be\\ndecomposed into microservices, containe\", \"rized, and ultimately replatformed into a cloud-native\\narchitecture.\\nIf you and your team believe a \", \"cloud-native approach is appropriate, it behooves you to rationalize\\nthe decision with your organiza\", \"tion. What exactly is the business problem that a cloud-native\\napproach will solve? How would it ali\", \"gn with business needs?\\n\\u2022 Rapid releases of features with increased confidence?\\n\\u2022 Fine-grained scala\", \"bility - more efficient usage of resources?\\n20 CHAPTER 1 | Introduction to cloud-native applications\", \"\\u2022 Improved system resiliency?\\n\\u2022 Improved system performance?\\n\\u2022 More visibility into operations?\\n\\u2022 Bl\", \"end development platforms and data stores to arrive at the best tool for the job?\\n\\u2022 Future-proof app\", \"lication investment?\\nThe right migration strategy depends on organizational priorities and the syste\", \"ms you\\u2019re targeting.\\nFor many, it may be more cost effective to cloud-optimize a monolithic applicat\", \"ion or add coarse-\\ngrained services to an N-Tier app. In these cases, you can still make full use of\", \" cloud PaaS capabilities\\nlike the ones offered by Azure App Service.\\nSummary\\nIn this chapter, we int\", \"roduced cloud-native computing. We provided a definition along with the key\\ncapabilities that drive \", \"a cloud-native application. We looked at the types of applications that might\\njustify this investmen\", \"t and effort.\\nWith the introduction behind, we now dive into a much more detailed look at cloud nati\", \"ve.\\nReferences\\n\\u2022 Cloud Native Computing Foundation\\n\\u2022 .NET Microservices: Architecture for Containeri\", \"zed .NET applications\\n\\u2022 Microsoft Azure Well-Architected Framework\\n\\u2022 Modernize existing .NET applica\", \"tions with Azure cloud and Windows Containers\\n\\u2022 Cloud Native Patterns by Cornelia Davis\\n\\u2022 Cloud nati\", \"ve applications: Ship faster, reduce risk, and grow your business\\n\\u2022 Dapr for .NET Developers\\n\\u2022 Dapr \", \"documents\\n\\u2022 Beyond the Twelve-Factor Application\\n\\u2022 What is Infrastructure as Code\\n\\u2022 Uber Engineering\", \"\\u2019s Micro Deploy: Deploying Daily with Confidence\\n\\u2022 How Netflix Deploys Code\\n\\u2022 Overload Control for S\", \"caling WeChat Microservices\\n21 CHAPTER 1 | Introduction to cloud-native applications2\\nCHAPTER\\nIntrod\", \"ucing\\neShopOnContainers\\nreference app\\nMicrosoft, in partnership with leading community experts, has \", \"produced a full-featured cloud-native\\nmicroservices reference application, eShopOnContainers. This a\", \"pplication is built to showcase using\\n.NET and Docker, and optionally Azure, Kubernetes, and Visual \", \"Studio, to build an online storefront.\\nFigure 2-1. eShopOnContainers Sample App Screenshot.\\n22 CHAPT\", \"ER 2 | Introducing eShopOnContainers reference appBefore starting this chapter, we recommend that yo\", \"u download the eShopOnContainers reference\\napplication. If you do so, it should be easier for you to\", \" follow along with the information presented.\\nFeatures and requirements\\nLet\\u2019s start with a review of\", \" the application\\u2019s features and requirements. The eShopOnContainers\\napplication represents an online\", \" store that sells various physical products like t-shirts and coffee\\nmugs. If you\\u2019ve bought anything\", \" online before, the experience of using the store should be relatively\\nfamiliar. Here are some of th\", \"e basic features the store implements:\\n\\u2022 List catalog items\\n\\u2022 Filter items by type\\n\\u2022 Filter items by\", \" brand\\n\\u2022 Add items to the shopping basket\\n\\u2022 Edit or remove items from the basket\\n\\u2022 Checkout\\n\\u2022 Regist\", \"er an account\\n\\u2022 Sign in\\n\\u2022 Sign out\\n\\u2022 Review orders\\nThe application also has the following non-functi\", \"onal requirements:\\n\\u2022 It needs to be highly available and it must scale automatically to meet increas\", \"ed traffic (and\\nscale back down once traffic subsides).\\n\\u2022 It should provide easy-to-use monitoring o\", \"f its health and diagnostic logs to help\\ntroubleshoot any issues it encounters.\\n\\u2022 It should support \", \"an agile development process, including support for continuous integration\\nand deployment (CI/CD).\\n\\u2022\", \" In addition to the two web front ends (traditional and Single Page Application), the\\napplication mu\", \"st also support mobile client apps running different kinds of operating\\nsystems.\\n\\u2022 It should support\", \" cross-platform hosting and cross-platform development.\\n23 CHAPTER 2 | Introducing eShopOnContainers\", \" reference appFigure 2-2. eShopOnContainers reference application development architecture.\\nThe eSho\", \"pOnContainers application is accessible from web or mobile clients that access the\\napplication over \", \"HTTPS targeting either the ASP.NET Core MVC server application or an appropriate\\nAPI Gateway. API Ga\", \"teways offer several advantages, such as decoupling back-end services from\\nindividual front-end clie\", \"nts and providing better security. The application also makes use of a related\\npattern known as Back\", \"ends-for-Frontends (BFF), which recommends creating separate API gateways\\nfor each front-end client.\", \" The reference architecture demonstrates breaking up the API gateways\\nbased on whether the request i\", \"s coming from a web or mobile client.\\nThe application\\u2019s functionality is broken up into many distinc\", \"t microservices. There are services\\nresponsible for authentication and identity, listing items from \", \"the product catalog, managing users\\u2019\\nshopping baskets, and placing orders. Each of these separate se\", \"rvices has its own persistent storage.\\nThere\\u2019s no single primary data store with which all services \", \"interact. Instead, coordination and\\ncommunication between the services is done on an as-needed basis\", \" and by using a message bus.\\nEach of the different microservices is designed differently, based on t\", \"heir individual requirements. This\\naspect means their technology stack may differ, although they\\u2019re \", \"all built using .NET and designed for\\nthe cloud. Simpler services provide basic Create-Read-Update-D\", \"elete (CRUD) access to the underlying\\ndata stores, while more advanced services use Domain-Driven De\", \"sign approaches and patterns to\\nmanage business complexity.\\n24 CHAPTER 2 | Introducing eShopOnContai\", \"ners reference appFigure 2-3. Different kinds of microservices.\\nOverview of the code\\nBecause it uses\", \" microservices, the eShopOnContainers app includes quite a few separate projects and\\nsolutions in it\", \"s GitHub repository. In addition to separate solutions and executable files, the various\\nservices ar\", \"e designed to run inside their own containers, both during local development and at run\\ntime in prod\", \"uction. Figure 2-4 shows the full Visual Studio solution, in which the various different\\nprojects ar\", \"e organized.\\n25 CHAPTER 2 | Introducing eShopOnContainers reference app26 CHAPTER 2 | Introducing eS\", \"hopOnContainers reference appFigure 2-4. Projects in Visual Studio solution.\\nThe code is organized t\", \"o support the different microservices, and within each microservice, the code is\\nbroken up into doma\", \"in logic, infrastructure concerns, and user interface or service endpoint. In many\\ncases, each servi\", \"ce\\u2019s dependencies can be fulfilled by Azure services in production, and alternative\\noptions for loca\", \"l development. Let\\u2019s examine how the application\\u2019s requirements map to Azure\\nservices.\\nUnderstanding\", \" microservices\\nThis book focuses on cloud-native applications built using Azure technology. To learn\", \" more about\\nmicroservices best practices and how to architect microservice-based applications, read \", \"the\\ncompanion book, .NET Microservices: Architecture for Containerized .NET Applications.\\nMapping eS\", \"hopOnContainers to Azure Services\\nAlthough not required, Azure is well-suited to supporting the eSho\", \"pOnContainers because the project\\nwas built to be a cloud-native application. The application is bui\", \"lt with .NET, so it can run on Linux or\\nWindows containers depending on the Docker host. The applica\", \"tion is made up of multiple\\nautonomous microservices, each with its own data. The different microser\", \"vices showcase different\\napproaches, ranging from simple CRUD operations to more complex DDD and CQR\", \"S patterns.\\nMicroservices communicate with clients over HTTP and with one another via message-based\\n\", \"communication. The application supports multiple platforms for clients as well, since it adopts HTTP\", \"\\nas a standard communication protocol and includes ASP.NET Core and Xamarin mobile apps that run\\non \", \"Android, iOS, and Windows platforms.\\nThe application\\u2019s architecture is shown in Figure 2-5. On the l\", \"eft are the client apps, broken up into\\nmobile, traditional Web, and Web Single Page Application (SP\", \"A) flavors. On the right are the server-\\nside components that make up the system, each of which can \", \"be hosted in Docker containers and\\nKubernetes clusters. The traditional web app is powered by the AS\", \"P.NET Core MVC application shown\\nin yellow. This app and the mobile and web SPA applications communi\", \"cate with the individual\\nmicroservices through one or more API gateways. The API gateways follow the\", \" \\u201cbackends for front\\nends\\u201d (BFF) pattern, meaning that each gateway is designed to support a given f\", \"ront-end client. The\\nindividual microservices are listed to the right of the API gateways and includ\", \"e both business logic\\nand some kind of persistence store. The different services make use of SQL Ser\", \"ver databases, Redis\\ncache instances, and MongoDB/CosmosDB stores. On the far right is the system\\u2019s \", \"Event Bus, which is\\nused for communication between the microservices.\\n27 CHAPTER 2 | Introducing eSh\", \"opOnContainers reference appFigure 2-5. The eShopOnContainers Architecture.\\nThe server-side componen\", \"ts of this architecture all map easily to Azure services.\\nContainer orchestration and clustering\\nThe\", \" application\\u2019s container-hosted services, from ASP.NET Core MVC apps to individual Catalog and\\nOrder\", \"ing microservices, can be hosted and managed in Azure Kubernetes Service (AKS). The\\napplication can \", \"run locally on Docker and Kubernetes, and the same containers can then be deployed\\nto staging and pr\", \"oduction environments hosted in AKS. This process can be automated as we\\u2019ll see in\\nthe next section.\", \"\\nAKS provides management services for individual clusters of containers. The application will deploy\", \"\\nseparate containers for each microservice in the AKS cluster, as shown in the architecture diagram\\n\", \"above. This approach allows each individual service to scale independently according to its resource\", \"\\ndemands. Each microservice can also be deployed independently, and ideally such deployments\\nshould \", \"incur zero system downtime.\\nAPI Gateway\\nThe eShopOnContainers application has multiple front-end cli\", \"ents and multiple different back-end\\nservices. There\\u2019s no one-to-one correspondence between the clie\", \"nt applications and the microservices\\nthat support them. In such a scenario, there may be a great de\", \"al of complexity when writing client\\nsoftware to interface with the various back-end services in a s\", \"ecure manner. Each client would need to\\naddress this complexity on its own, resulting in duplication\", \" and many places in which to make updates\\nas services change or new policies are implemented.\\nAzure \", \"API Management (APIM) helps organizations publish APIs in a consistent, manageable fashion.\\nAPIM con\", \"sists of three components: the API Gateway, and administration portal (the Azure portal),\\nand a deve\", \"loper portal.\\n28 CHAPTER 2 | Introducing eShopOnContainers reference appThe API Gateway accepts API \", \"calls and routes them to the appropriate back-end API. It can also\\nprovide additional services like \", \"verification of API keys or JWT tokens and API transformation on the\\nfly without code modifications \", \"(for instance, to accommodate clients expecting an older interface).\\nThe Azure portal is where you d\", \"efine the API schema and package different APIs into products. You\\nalso configure user access, view \", \"reports, and configure policies for quotas or transformations.\\nThe developer portal serves as the ma\", \"in resource for developers. It provides developers with API\\ndocumentation, an interactive test conso\", \"le, and reports on their own usage. Developers also use the\\nportal to create and manage their own ac\", \"counts, including subscription and API key support.\\nUsing APIM, applications can expose several diff\", \"erent groups of services, each providing a back end\\nfor a particular front-end client. APIM is recom\", \"mended for complex scenarios. For simpler needs, the\\nlightweight API Gateway Ocelot can be used. The\", \" eShopOnContainers app uses Ocelot because of its\\nsimplicity and because it can be deployed into the\", \" same application environment as the application\\nitself. Learn more about eShopOnContainers, APIM, a\", \"nd Ocelot.\\nAnother option if your application is using AKS is to deploy the Azure Gateway Ingress Co\", \"ntroller as a\\npod within your AKS cluster. This approach allows your cluster to integrate with an Az\", \"ure Application\\nGateway, allowing the gateway to load-balance traffic to the AKS pods. Learn more ab\", \"out the Azure\\nGateway Ingress Controller for AKS.\\nData\\nThe various back-end services used by eShopOn\", \"Containers have different storage requirements.\\nSeveral microservices use SQL Server databases. The \", \"Basket microservice leverages a Redis cache for\\nits persistence. The Locations microservice expects \", \"a MongoDB API for its data. Azure supports each\\nof these data formats.\\nFor SQL Server database suppo\", \"rt, Azure has products for everything from single databases up to\\nhighly scalable SQL Database elast\", \"ic pools. Individual microservices can be configured to\\ncommunicate with their own individual SQL Se\", \"rver databases quickly and easily. These databases can\\nbe scaled as needed to support each separate \", \"microservice according to its needs.\\nThe eShopOnContainers application stores the user\\u2019s current sho\", \"pping basket between requests. This\\naspect is managed by the Basket microservice that stores the dat\", \"a in a Redis cache. In development,\\nthis cache can be deployed in a container, while in production i\", \"t can utilize Azure Cache for Redis.\\nAzure Cache for Redis is a fully managed service offering high \", \"performance and reliability without the\\nneed to deploy and manage Redis instances or containers on y\", \"our own.\\nThe Locations microservice uses a MongoDB NoSQL database for its persistence. During\\ndevelo\", \"pment, the database can be deployed in its own container, while in production the service can\\nlevera\", \"ge Azure Cosmos DB\\u2019s API for MongoDB. One of the benefits of Azure Cosmos DB is its ability\\nto lever\", \"age multiple different communication protocols, including a SQL API and common NoSQL\\nAPIs including \", \"MongoDB, Cassandra, Gremlin, and Azure Table Storage. Azure Cosmos DB offers a\\nfully managed and glo\", \"bally distributed database as a service that can scale to meet the needs of the\\nservices that use it\", \".\\nDistributed data in cloud-native applications is covered in more detail in chapter 5.\\n29 CHAPTER 2\", \" | Introducing eShopOnContainers reference appEvent Bus\\nThe application uses events to communicate c\", \"hanges between different services. This functionality can\\nbe implemented with various implementation\", \"s, and locally the eShopOnContainers application uses\\nRabbitMQ. When hosted in Azure, the applicatio\", \"n would leverage Azure Service Bus for its messaging.\\nAzure Service Bus is a fully managed integrati\", \"on message broker that allows applications and services\\nto communicate with one another in a decoupl\", \"ed, reliable, asynchronous manner. Azure Service Bus\\nsupports individual queues as well as separate \", \"topics to support publisher-subscriber scenarios. The\\neShopOnContainers application would leverage t\", \"opics with Azure Service Bus to support distributing\\nmessages from one microservice to any other mic\", \"roservice that needed to react to a given message.\\nResiliency\\nOnce deployed to production, the eShop\", \"OnContainers application would be able to take advantage\\nof several Azure services available to impr\", \"ove its resiliency. The application publishes health checks,\\nwhich can be integrated with Applicatio\", \"n Insights to provide reporting and alerts based on the app\\u2019s\\navailability. Azure resources also pro\", \"vide diagnostic logs that can be used to identify and correct bugs\\nand performance issues. Resource \", \"logs provide detailed information on when and how different Azure\\nresources are used by the applicat\", \"ion. You\\u2019ll learn more about cloud-native resiliency features in\\nchapter 6.\\nDeploying eShopOnContain\", \"ers to Azure\\nThe eShopOnContainers application can be deployed to various Azure platforms. The recom\", \"mended\\napproach is to deploy the application to Azure Kubernetes Services (AKS). Helm, a Kubernetes\\n\", \"deployment tool, is available to reduce deployment complexity. Optionally, developers may\\nimplement \", \"Azure Dev Spaces for Kubernetes to streamline their development process.\\nAzure Kubernetes Service\\nTo\", \" host eShop in AKS, the first step is to create an AKS cluster. To do so, you might use the Azure\\npo\", \"rtal, which will walk you through the required steps. You could also create a cluster from the Azure\", \"\\nCLI, taking care to enable Role-Based Access Control (RBAC) and application routing. The\\neShopOnCon\", \"tainers\\u2019 documentation details the steps for creating your own AKS cluster. Once created,\\nyou can ac\", \"cess and manage the cluster from the Kubernetes dashboard.\\nYou can now deploy the eShop application \", \"to the cluster using Helm.\\nDeploying to Azure Kubernetes Service using Helm\\nHelm is an application p\", \"ackage manager tool that works directly with Kubernetes. It helps you define,\\ninstall, and upgrade K\", \"ubernetes applications. While simple apps can be deployed to AKS with custom\\nCLI scripts or simple d\", \"eployment files, complex apps can contain many Kubernetes objects and benefit\\nfrom Helm.\\nUsing Helm,\", \" applications include text-based configuration files, called Helm charts, which declaratively\\ndescri\", \"be the application and configuration in Helm packages. Charts use standard YAML-formatted\\n30 CHAPTER\", \" 2 | Introducing eShopOnContainers reference appfiles to describe a related set of Kubernetes resour\", \"ces. They\\u2019re versioned alongside the application\\ncode they describe. Helm Charts range from simple t\", \"o complex depending on the requirements of the\\ninstallation they describe.\\nHelm is composed of a com\", \"mand-line client tool, which consumes helm charts and launches\\ncommands to a server component named,\", \" Tiller. Tiller communicates with the Kubernetes API to\\nensure the correct provisioning of your cont\", \"ainerized workloads. Helm is maintained by the Cloud-\\nnative Computing Foundation.\\nThe following yam\", \"l file presents a Helm template:\\napiVersion: v1\\nkind: Service\\nmetadata:\\nname: {{ .Values.app.svc.mar\", \"keting }}\\nlabels:\\napp: {{ template \\\"marketing-api.name\\\" . }}\\nchart: {{ template \\\"marketing-api.chart\", \"\\\" . }}\\nrelease: {{ .Release.Name }}\\nheritage: {{ .Release.Service }}\\nspec:\\ntype: {{ .Values.service.\", \"type }}\\nports:\\n- port: {{ .Values.service.port }}\\ntargetPort: http\\nprotocol: TCP\\nname: http\\nselector\", \":\\napp: {{ template \\\"marketing-api.name\\\" . }}\\nrelease: {{ .Release.Name }}\\nNote how the template desc\", \"ribes a dynamic set of key/value pairs. When the template is invoked,\\nvalues that enclosed in curly \", \"braces are pulled in from other yaml-based configuration files.\\nYou\\u2019ll find the eShopOnContainers he\", \"lm charts in the /k8s/helm folder. Figure 2-6 shows how the\\ndifferent components of the application \", \"are organized into a folder structure used by helm to define\\nand managed deployments.\\n31 CHAPTER 2 |\", \" Introducing eShopOnContainers reference appFigure 2-6. The eShopOnContainers helm folder.\\nEach indi\", \"vidual component is installed using a helm install command. eShop includes a \\u201cdeploy all\\u201d\\nscript tha\", \"t loops through and installs the components using their respective helm charts. The result is\\na repe\", \"atable process, versioned with the application in source control, that anyone on the team can\\ndeploy\", \" to an AKS cluster with a one-line script command.\\nNote that version 3 of Helm officially removes th\", \"e need for the Tiller server component. More\\ninformation on this enhancement can be found here.\\nAzur\", \"e Functions and Logic Apps (Serverless)\\nThe eShopOnContainers sample includes support for tracking o\", \"nline marketing campaigns. An Azure\\nFunction is used to track marketing campaign details for a given\", \" campaign ID. Rather than creating a\\n32 CHAPTER 2 | Introducing eShopOnContainers reference appfull \", \"microservice, a single Azure Function is simpler and sufficient. Azure Functions have a simple build\", \"\\nand deployment model, especially when configured to run in Kubernetes. Deploying the function is\\nsc\", \"ripted using Azure Resource Manager (ARM) templates and the Azure CLI. This campaign service\\nisn\\u2019t c\", \"ustomer-facing and invokes a single operation, making it a great candidate for Azure Functions.\\nThe \", \"function requires minimal configuration, including a database connection string data and image\\nbase \", \"URI settings. You configure Azure Functions in the Azure portal.\\nCentralized configuration\\nUnlike a \", \"monolithic app in which everything runs within a single instance, a cloud-native application\\nconsist\", \"s of independent services distributed across virtual machines, containers, and geographic\\nregions. M\", \"anaging configuration settings for dozens of interdependent services can be challenging.\\nDuplicate c\", \"opies of configuration settings across different locations are error prone and difficult to\\nmanage. \", \"Centralized configuration is a critical requirement for distributed cloud-native applications.\\nAs di\", \"scussed in Chapter 1, the Twelve-Factor App recommendations require strict separation between\\ncode a\", \"nd configuration. Configuration must be stored externally from the application and read-in as\\nneeded\", \". Storing configuration values as constants or literal values in code is a violation. The same\\nconfi\", \"guration values are often be used by many services in the same application. Additionally, we\\nmust su\", \"pport the same values across multiple environments, such as dev, testing, and production. The\\nbest p\", \"ractice is store them in a centralized configuration store.\\nThe Azure cloud presents several great o\", \"ptions.\\nAzure App Configuration\\nAzure App Configuration is a fully managed Azure service that stores\", \" non-secret configuration\\nsettings in a secure, centralized location. Stored values can be shared am\", \"ong multiple services and\\napplications.\\nThe service is simple to use and provides several benefits:\\n\", \"\\u2022 Flexible key/value representations and mappings\\n\\u2022 Tagging with Azure labels\\n\\u2022 Dedicated UI for man\", \"agement\\n\\u2022 Encryption of sensitive information\\n\\u2022 Querying and batch retrieval\\nAzure App Configuration\", \" maintains changes made to key-value settings for seven days. The point-in-\\ntime snapshot feature en\", \"ables you to reconstruct the history of a setting and even rollback for a failed\\ndeployment.\\nApp Con\", \"figuration automatically caches each setting to avoid excessive calls to the configuration\\nstore. Th\", \"e refresh operation waits until the cached value of a setting expires to update that setting,\\neven w\", \"hen its value changes in the configuration store. The default cache expiration time is 30\\nseconds. Y\", \"ou can override the expiration time.\\n33 CHAPTER 2 | Introducing eShopOnContainers reference appApp C\", \"onfiguration encrypts all configuration values in transit and at rest. Key names and labels are\\nused\", \" as indexes for retrieving configuration data and aren\\u2019t encrypted.\\nAlthough App Configuration provi\", \"des hardened security, Azure Key Vault is still the best place for\\nstoring application secrets. Key \", \"Vault provides hardware-level encryption, granular access policies, and\\nmanagement operations such a\", \"s certificate rotation. You can create App Configuration values that\\nreference secrets stored in a K\", \"ey Vault.\\nAzure Key Vault\\nKey Vault is a managed service for securely storing and accessing secrets.\", \" A secret is anything that you\\nwant to tightly control access to, such as API keys, passwords, or ce\", \"rtificates. A vault is a logical group\\nof secrets.\\nKey Vault greatly reduces the chances that secret\", \"s may be accidentally leaked. When using Key Vault,\\napplication developers no longer need to store s\", \"ecurity information in their application. This practice\\neliminates the need to store this informatio\", \"n inside your code. For example, an application may need\\nto connect to a database. Instead of storin\", \"g the connection string in the app\\u2019s code, you can store it\\nsecurely in Key Vault.\\nYour applications\", \" can securely access the information they need by using URIs. These URIs allow the\\napplications to r\", \"etrieve specific versions of a secret. There\\u2019s no need to write custom code to protect\\nany of the se\", \"cret information stored in Key Vault.\\nAccess to Key Vault requires proper caller authentication and \", \"authorization. Typically, each cloud-\\nnative microservice uses a ClientId/ClientSecret combination. \", \"It\\u2019s important to keep these credentials\\noutside source control. A best practice is to set them in t\", \"he application\\u2019s environment. Direct access to\\nKey Vault from AKS can be achieved using Key Vault Fl\", \"exVolume.\\nConfiguration in eShop\\nThe eShopOnContainers application includes local application settin\", \"gs files with each microservice.\\nThese files are checked into source control, but don\\u2019t include prod\", \"uction secrets such as connection\\nstrings or API keys. In production, individual settings may be ove\", \"rwritten with per-service environment\\nvariables. Injecting secrets in environment variables is a com\", \"mon practice for hosted applications, but\\ndoesn\\u2019t provide a central configuration store. To support \", \"centralized management of configuration\\nsettings, each microservice includes a setting to toggle bet\", \"ween its use of local settings or Azure Key\\nVault settings.\\nReferences\\n\\u2022 The eShopOnContainers Archi\", \"tecture\\n\\u2022 Orchestrating microservices and multi-container applications for high scalability and\\navai\", \"lability\\n\\u2022 Azure API Management\\n\\u2022 Azure SQL Database Overview\\n\\u2022 Azure Cache for Redis\\n\\u2022 Azure Cosmos\", \" DB\\u2019s API for MongoDB\\n34 CHAPTER 2 | Introducing eShopOnContainers reference app\\u2022 Azure Service Bus\\n\", \"\\u2022 Azure Monitor overview\\n\\u2022 eShopOnContainers: Create Kubernetes cluster in AKS\\n\\u2022 eShopOnContainers: \", \"Azure Dev Spaces\\n\\u2022 Azure Dev Spaces\\n35 CHAPTER 2 | Introducing eShopOnContainers reference app3\\nCHAP\", \"TER\\nScaling cloud-native\\napplications\\nOne of the most-often touted advantages of moving to a cloud h\", \"osting environment is scalability.\\nScalability, or the ability for an application to accept addition\", \"al user load without compromising\\nperformance for each user. It\\u2019s most often achieved by breaking up\", \" an application into small pieces\\nthat can each be given whatever resources they require. Cloud vend\", \"ors enable massive scalability\\nanytime and anywhere in the world.\\nIn this chapter, we discuss techno\", \"logies that enable cloud-native applications to scale to meet user\\ndemand. These technologies includ\", \"e:\\n\\u2022 Containers\\n\\u2022 Orchestrators\\n\\u2022 Serverless computing\\nLeveraging containers and orchestrators\\nConta\", \"iners and orchestrators are designed to solve problems common to monolithic deployment\\napproaches.\\nC\", \"hallenges with monolithic deployments\\nTraditionally, most applications have been deployed as a singl\", \"e unit. Such applications are referred to\\nas a monolith. This general approach of deploying applicat\", \"ions as single units even if they\\u2019re\\ncomposed of multiple modules or assemblies is known as monolith\", \"ic architecture, as shown in Figure\\n3-1.\\n36 CHAPTER 3 | Scaling cloud-native applicationsFigure 3-1.\", \" Monolithic architecture.\\nAlthough they have the benefit of simplicity, monolithic architectures fac\", \"e many challenges:\\nDeployment\\nAdditionally, they require a restart of the application, which may tem\", \"porarily impact availability if\\nzero-downtime techniques are not applied while deploying.\\nScaling\\nA \", \"monolithic application is hosted entirely on a single machine instance, often requiring high-\\ncapabi\", \"lity hardware. If any part of the monolith requires scaling, another copy of the entire application\\n\", \"must be deployed to another machine. With a monolith, you can\\u2019t scale application components\\nindivid\", \"ually - it\\u2019s all or nothing. Scaling components that don\\u2019t require scaling results in inefficient an\", \"d\\ncostly resource usage.\\nEnvironment\\nMonolithic applications are typically deployed to a hosting env\", \"ironment with a pre-installed operating\\nsystem, runtime, and library dependencies. This environment \", \"may not match that upon which the\\napplication was developed or tested. Inconsistencies across applic\", \"ation environments are a common\\nsource of problems for monolithic deployments.\\nCoupling\\nA monolithic\", \" application is likely to experience high coupling across its functional components.\\nWithout hard bo\", \"undaries, system changes often result in unintended and costly side effects. New\\nfeatures/fixes beco\", \"me tricky, time-consuming, and expensive to implement. Updates require extensive\\ntesting. Coupling a\", \"lso makes it difficult to refactor components or swap in alternative\\nimplementations. Even when cons\", \"tructed with a strict separation of concerns, architectural erosion\\nsets in as the monolithic code b\", \"ase deteriorates with never-ending \\u201cspecial cases.\\u201d\\n37 CHAPTER 3 | Scaling cloud-native applications\", \"Platform lock-in\\nA monolithic application is constructed with a single technology stack. While offer\", \"ing uniformity, this\\ncommitment can become a barrier to innovation. New features and components will\", \" be built using\\nthe application\\u2019s current stack - even when more modern technologies may be a better\", \" choice. A\\nlonger-term risk is your technology stack becoming outdated and obsolete. Rearchitecting \", \"an entire\\napplication to a new, more modern platform is at best expensive and risky.\\nWhat are the be\", \"nefits of containers and orchestrators?\\nWe introduced containers in Chapter 1. We highlighted how th\", \"e Cloud Native Computing Foundation\\n(CNCF) ranks containerization as the first step in their Cloud-N\", \"ative Trail Map - guidance for\\nenterprises beginning their cloud-native journey. In this section, we\", \" discuss the benefits of containers.\\nDocker is the most popular container management platform. It wo\", \"rks with containers on both Linux or\\nWindows. Containers provide separate but reproducible applicati\", \"on environments that run the same\\nway on any system. This aspect makes them perfect for developing a\", \"nd hosting cloud-native services.\\nContainers are isolated from one another. Two containers on the sa\", \"me host hardware can have\\ndifferent versions of software, without causing conflicts.\\nContainers are \", \"defined by simple text-based files that become project artifacts and are checked into\\nsource control\", \". While full servers and virtual machines require manual effort to update, containers are\\neasily ver\", \"sion-controlled. Apps built to run in containers can be developed, tested, and deployed\\nusing automa\", \"ted tools as part of a build pipeline.\\nContainers are immutable. Once you define a container, you ca\", \"n recreate and run it exactly the same\\nway. This immutability lends itself to component-based design\", \". If some parts of an application evolve\\ndifferently than others, why redeploy the entire app when y\", \"ou can just deploy the parts that change\\nmost frequently? Different features and cross-cutting conce\", \"rns of an app can be broken up into\\nseparate units. Figure 3-2 shows how a monolithic app can take a\", \"dvantage of containers and\\nmicroservices by delegating certain features or functionality. The remain\", \"ing functionality in the app\\nitself has also been containerized.\\n38 CHAPTER 3 | Scaling cloud-native\", \" applicationsFigure 3-2. Decomposing a monolithic app to embrace microservices.\\nEach cloud-native se\", \"rvice is built and deployed in a separate container. Each can update as needed.\\nIndividual services \", \"can be hosted on nodes with resources appropriate to each service. The\\nenvironment each service runs\", \" in is immutable, shared across dev, test, and production environments,\\nand easily versioned. Coupli\", \"ng between different areas of the application occurs explicitly as calls or\\nmessages between service\", \"s, not compile-time dependencies within the monolith. You can also choose\\nthe technology that best s\", \"uites a given capability without requiring changes to the rest of the app.\\nContainerized services re\", \"quire automated management. It wouldn\\u2019t be feasible to manually administer\\na large set of independen\", \"tly deployed containers. For example, consider the following tasks:\\n\\u2022 How will container instances b\", \"e provisioned across a cluster of many machines?\\n\\u2022 Once deployed, how will containers discover and c\", \"ommunicate with each other?\\n\\u2022 How can containers scale in or out on-demand?\\n\\u2022 How do you monitor the\", \" health of each container?\\n\\u2022 How do you protect a container against hardware and software failures?\\n\", \"\\u2022 How do upgrade containers for a live application with zero downtime?\\nContainer orchestrators addre\", \"ss and automate these and other concerns.\\nIn the cloud-native eco-system, Kubernetes has become the \", \"de facto container orchestrator. It\\u2019s an\\nopen-source platform managed by the Cloud Native Computing \", \"Foundation (CNCF). Kubernetes\\nautomates the deployment, scaling, and operational concerns of contain\", \"erized workloads across a\\nmachine cluster. However, installing and managing Kubernetes is notoriousl\", \"y complex.\\n39 CHAPTER 3 | Scaling cloud-native applicationsA much better approach is to leverage Kub\", \"ernetes as a managed service from a cloud vendor. The\\nAzure cloud features a fully managed Kubernete\", \"s platform entitled Azure Kubernetes Service (AKS).\\nAKS abstracts the complexity and operational ove\", \"rhead of managing Kubernetes. You consume\\nKubernetes as a cloud service; Microsoft takes responsibil\", \"ity for managing and supporting it. AKS also\\ntightly integrates with other Azure services and dev to\", \"ols.\\nAKS is a cluster-based technology. A pool of federated virtual machines, or nodes, is deployed \", \"to the\\nAzure cloud. Together they form a highly available environment, or cluster. The cluster appea\", \"rs as a\\nseamless, single entity to your cloud-native application. Under the hood, AKS deploys your\\nc\", \"ontainerized services across these nodes following a predefined strategy that evenly distributes the\", \"\\nload.\\nWhat are the scaling benefits?\\nServices built on containers can leverage scaling benefits pro\", \"vided by orchestration tools like\\nKubernetes. By design containers only know about themselves. Once \", \"you have multiple containers\\nthat need to work together, you should organize them at a higher level.\", \" Organizing large numbers of\\ncontainers and their shared dependencies, such as network configuration\", \", is where orchestration tools\\ncome in to save the day! Kubernetes creates an abstraction layer over\", \" groups of containers and\\norganizes them into pods. Pods run on worker machines referred to as nodes\", \". This organized structure\\nis referred to as a cluster. Figure 3-3 shows the different components of\", \" a Kubernetes cluster.\\nFigure 3-3. Kubernetes cluster components.\\nScaling containerized workloads is\", \" a key feature of container orchestrators. AKS supports automatic\\nscaling across two dimensions: Con\", \"tainer instances and compute nodes. Together they give AKS the\\nability to quickly and efficiently re\", \"spond to spikes in demand and add additional resources. We\\ndiscuss scaling in AKS later in this chap\", \"ter.\\n40 CHAPTER 3 | Scaling cloud-native applicationsDeclarative versus imperative\\nKubernetes suppor\", \"ts both declarative and imperative configuration. The imperative approach involves\\nrunning various c\", \"ommands that tell Kubernetes what to do each step of the way. Run this image.\\nDelete this pod. Expos\", \"e this port. With the declarative approach, you create a configuration file, called\\na manifest, to d\", \"escribe what you want instead of what to do. Kubernetes reads the manifest and\\ntransforms your desir\", \"ed end state into actual end state.\\nImperative commands are great for learning and interactive exper\", \"imentation. However, you\\u2019ll want to\\ndeclaratively create Kubernetes manifest files to embrace an inf\", \"rastructure as code approach,\\nproviding for reliable and repeatable deployments. The manifest file b\", \"ecomes a project artifact and is\\nused in your CI/CD pipeline for automating Kubernetes deployments.\\n\", \"If you\\u2019ve already configured your cluster using imperative commands, you can export a declarative\\nma\", \"nifest by using kubectl get svc SERVICENAME -o yaml > service.yaml. This command produces a\\nmanifest\", \" similar to one shown below:\\napiVersion: v1\\nkind: Service\\nmetadata:\\ncreationTimestamp: \\\"2019-09-13T1\", \"3:58:47Z\\\"\\nlabels:\\ncomponent: apiserver\\nprovider: kubernetes\\nname: kubernetes\\nnamespace: default\\nreso\", \"urceVersion: \\\"153\\\"\\nselfLink: /api/v1/namespaces/default/services/kubernetes\\nuid: 9b1fac62-d62e-11e9-\", \"8968-00155d38010d\\nspec:\\nclusterIP: 10.96.0.1\\nports:\\n- name: https\\nport: 443\\nprotocol: TCP\\ntargetPort\", \": 6443\\nsessionAffinity: None\\ntype: ClusterIP\\nstatus:\\nloadBalancer: {}\\nWhen using declarative configu\", \"ration, you can preview the changes that will be made before\\ncommitting them by using kubectl diff -\", \"f FOLDERNAME against the folder where your configuration\\nfiles are located. Once you\\u2019re sure you wan\", \"t to apply the changes, run kubectl apply -f FOLDERNAME.\\nAdd -R to recursively process a folder hier\", \"archy.\\nYou can also use declarative configuration with other Kubernetes features, one of which being\", \"\\ndeployments. Declarative deployments help manage releases, updates, and scaling. They instruct the\\n\", \"Kubernetes deployment controller on how to deploy new changes, scale out load, or roll back to a\\npre\", \"vious revision. If a cluster is unstable, a declarative deployment will automatically return the clu\", \"ster\\nback to a desired state. For example, if a node should crash, the deployment mechanism will red\", \"eploy\\na replacement to achieve your desired state\\n41 CHAPTER 3 | Scaling cloud-native applicationsUs\", \"ing declarative configuration allows infrastructure to be represented as code that can be checked in\", \"\\nand versioned alongside the application code. It provides improved change control and better\\nsuppor\", \"t for continuous deployment using a build and deploy pipeline.\\nWhat scenarios are ideal for containe\", \"rs and orchestrators?\\nThe following scenarios are ideal for using containers and orchestrators.\\nAppl\", \"ications requiring high uptime and scalability\\nIndividual applications that have high uptime and sca\", \"lability requirements are ideal candidates for\\ncloud-native architectures using microservices, conta\", \"iners, and orchestrators. They can be developed\\nin containers, tested across versioned environments,\", \" and deployed into production with zero\\ndowntime. The use of Kubernetes clusters ensures such apps c\", \"an also scale on demand and recover\\nautomatically from node failures.\\nLarge numbers of applications\\n\", \"Organizations that deploy and maintain large numbers of applications benefit from containers and\\norc\", \"hestrators. The up front effort of setting up containerized environments and Kubernetes clusters is\\n\", \"primarily a fixed cost. Deploying, maintaining, and updating individual applications has a cost that\", \"\\nvaries with the number of applications. Beyond a few applications, the complexity of maintaining\\ncu\", \"stom applications manually exceeds the cost of implementing a solution using containers and\\norchestr\", \"ators.\\nWhen should you avoid using containers and orchestrators?\\nIf you\\u2019re unable to build your appl\", \"ication following the Twelve-Factor App principles, you should\\nconsider avoiding containers and orch\", \"estrators. In these cases, consider a VM-based hosting platform,\\nor possibly some hybrid system. Wit\", \"h it, you can always spin off certain pieces of functionality into\\nseparate containers or even serve\", \"rless functions.\\nDevelopment resources\\nThis section shows a short list of development resources that\", \" may help you get started using\\ncontainers and orchestrators for your next application. If you\\u2019re lo\", \"oking for guidance on how to\\ndesign your cloud-native microservices architecture app, read this book\", \"\\u2019s companion, .NET\\nMicroservices: Architecture for Containerized .NET Applications.\\nLocal Kubernetes\", \" Development\\nKubernetes deployments provide great value in production environments, but can also run\", \" locally on\\nyour development machine. While you may work on individual microservices independently, \", \"there\\nmay be times when you\\u2019ll need to run the entire system locally - just as it will run when depl\", \"oyed to\\nproduction. There are several tools that can help: Minikube and Docker Desktop. Visual Studi\", \"o also\\nprovides tooling for Docker development.\\n42 CHAPTER 3 | Scaling cloud-native applicationsMini\", \"kube\\nWhat is Minikube? The Minikube project says \\u201cMinikube implements a local Kubernetes cluster on\\n\", \"macOS, Linux, and Windows.\\u201d Its primary goals are \\u201cto be the best tool for local Kubernetes\\napplicat\", \"ion development and to support all Kubernetes features that fit.\\u201d Installing Minikube is\\nseparate fr\", \"om Docker, but Minikube supports different hypervisors than Docker Desktop supports.\\nThe following K\", \"ubernetes features are currently supported by Minikube:\\n\\u2022 DNS\\n\\u2022 NodePorts\\n\\u2022 ConfigMaps and secrets\\n\\u2022\", \" Dashboards\\n\\u2022 Container runtimes: Docker, rkt, CRI-O, and containerd\\n\\u2022 Enabling Container Network In\", \"terface (CNI)\\n\\u2022 Ingress\\nAfter installing Minikube, you can quickly start using it by running the min\", \"ikube start command, which\\ndownloads an image and start the local Kubernetes cluster. Once the clust\", \"er is started, you interact\\nwith it using the standard Kubernetes kubectl commands.\\nDocker Desktop\\nY\", \"ou can also work with Kubernetes directly from Docker Desktop on Windows. It is your only option if\\n\", \"you\\u2019re using Windows Containers, and is a great choice for non-Windows containers as well. Figure 3-\", \"\\n4 shows how to enable local Kubernetes support when running Docker Desktop.\\nFigure 3-4. Configuring\", \" Kubernetes in Docker Desktop.\\n43 CHAPTER 3 | Scaling cloud-native applicationsDocker Desktop is the\", \" most popular tool for configuring and running containerized apps locally.\\nWhen you work with Docker\", \" Desktop, you can develop locally against the exact same set of Docker\\ncontainer images that you\\u2019ll \", \"deploy to production. Docker Desktop is designed to \\u201cbuild, test, and\\nship\\u201d containerized apps local\", \"ly. It supports both Linux and Windows containers. Once you push your\\nimages to an image registry, l\", \"ike Azure Container Registry or Docker Hub, AKS can pull and deploy\\nthem to production.\\nVisual Studi\", \"o Docker Tooling\\nVisual Studio supports Docker development for web-based applications. When you crea\", \"te a new\\nASP.NET Core application, you have an option to configure it with Docker support, as shown \", \"in Figure\\n3-5.\\nFigure 3-5. Visual Studio Enable Docker Support\\nWhen this option is selected, the pro\", \"ject is created with a Dockerfile in its root, which can be used to\\nbuild and host the app in a Dock\", \"er container. An example Dockerfile is shown in Figure 3-6.\\nFROM mcr.microsoft.com/dotnet/aspnet:7.0\", \" AS base\\nWORKDIR /app\\nEXPOSE 80\\nEXPOSE 443\\nFROM mcr.microsoft.com/dotnet/sdk:7.0 AS build\\nWORKDIR /s\", \"rc\\nCOPY [\\\"eShopWeb/eShopWeb.csproj\\\", \\\"eShopWeb/\\\"]\\nRUN dotnet restore \\\"eShopWeb/eShopWeb.csproj\\\"\\nCOPY\", \" . .\\nWORKDIR \\\"/src/eShopWeb\\\"\\nRUN dotnet build \\\"eShopWeb.csproj\\\" -c Release -o /app/build\\nFROM build \", \"AS publish\\nRUN dotnet publish \\\"eShopWeb.csproj\\\" -c Release -o /app/publish\\n44 CHAPTER 3 | Scaling cl\", \"oud-native applicationsFROM base AS final\\nWORKDIR /app\\nCOPY --from=publish /app/publish .\\nENTRYPOINT\", \" [\\\"dotnet\\\", \\\"eShopWeb.dll\\\"]\\nFigure 3-6. Visual Studio generated Dockerfile\\nOnce support is added, yo\", \"u can run your application in a Docker container in Visual Studio. Figure 3-7\\nshows the different ru\", \"n options available from a new ASP.NET Core project created with Docker\\nsupport added.\\nFigure 3-7. V\", \"isual Studio Docker Run Options\\nAlso, at any time you can add Docker support to an existing ASP.NET \", \"Core application. From the\\nVisual Studio Solution Explorer, right-click on the project and select Ad\", \"d > Docker Support, as shown\\nin Figure 3-8.\\n45 CHAPTER 3 | Scaling cloud-native applicationsFigure 3\", \"-8. Adding Docker support to Visual Studio\\nVisual Studio Code Docker Tooling\\nThere are many extensio\", \"ns available for Visual Studio Code that support Docker development.\\nMicrosoft provides the Docker f\", \"or Visual Studio Code extension. This extension simplifies the process\\nof adding container support t\", \"o applications. It scaffolds required files, builds Docker images, and\\nenables you to debug your app\", \" inside a container. The extension features a visual explorer that makes\\nit easy to take actions on \", \"containers and images such as start, stop, inspect, remove, and more. The\\nextension also supports Do\", \"cker Compose enabling you to manage multiple running containers as a\\nsingle unit.\\nLeveraging serverl\", \"ess functions\\nIn the spectrum from managing physical machines to leveraging cloud capabilities, serv\", \"erless lives at\\nthe extreme end. Your only responsibility is your code, and you only pay when your c\", \"ode runs. Azure\\nFunctions provides a way to build serverless capabilities into your cloud-native app\", \"lications.\\n46 CHAPTER 3 | Scaling cloud-native applicationsWhat is serverless?\\nServerless is a relat\", \"ively new service model of cloud computing. It doesn\\u2019t mean that servers are\\noptional - your code st\", \"ill runs on a server somewhere. The distinction is that the application team no\\nlonger concerns itse\", \"lf with managing server infrastructure. Instead, the cloud vendor own this\\nresponsibility. The devel\", \"opment team increases its productivity by delivering business solutions to\\ncustomers, not plumbing.\\n\", \"Serverless computing uses event-triggered stateless containers to host your services. They can scale\", \"\\nout and in to meet demand as-needed. Serverless platforms like Azure Functions have tight\\nintegrati\", \"on with other Azure services like queues, events, and storage.\\nWhat challenges are solved by serverl\", \"ess?\\nServerless platforms address many time-consuming and expensive concerns:\\n\\u2022 Purchasing machines \", \"and software licenses\\n\\u2022 Housing, securing, configuring, and maintaining the machines and their netwo\", \"rking, power,\\nand A/C requirements\\n\\u2022 Patching and upgrading operating systems and software\\n\\u2022 Configu\", \"ring web servers or machine services to host application software\\n\\u2022 Configuring application software\", \" within its platform\\nMany companies allocate large budgets to support hardware infrastructure concer\", \"ns. Moving to the\\ncloud can help reduce these costs; shifting applications to serverless can help el\", \"iminate them.\\nWhat is the difference between a microservice and a serverless\\nfunction?\\nTypically, a \", \"microservice encapsulates a business capability, such as a shopping cart for an online\\neCommerce sit\", \"e. It exposes multiple operations that enable a user to manage their shopping\\nexperience. A function\", \", however, is a small, lightweight block of code that executes a single-purpose\\noperation in respons\", \"e to an event. Microservices are typically constructed to respond to requests,\\noften from an interfa\", \"ce. Requests can be HTTP Rest- or gRPC-based. Serverless services respond to\\nevents. Its event-drive\", \"n architecture is ideal for processing short-running, background tasks.\\nWhat scenarios are appropria\", \"te for serverless?\\nServerless exposes individual short-running functions that are invoked in respons\", \"e to a trigger. This\\nmakes them ideal for processing background tasks.\\nAn application might need to \", \"send an email as a step in a workflow. Instead of sending the\\nnotification as part of a microservice\", \" request, place the message details onto a queue. An Azure\\nFunction can dequeue the message and asyn\", \"chronously send the email. Doing so could improve the\\nperformance and scalability of the microservic\", \"e. Queue-based load leveling can be implemented to\\navoid bottlenecks related to sending the emails. \", \"Additionally, this stand-alone service could be reused\\nas a utility across many different applicatio\", \"ns.\\n47 CHAPTER 3 | Scaling cloud-native applicationsAsynchronous messaging from queues and topics is\", \" a common pattern to trigger serverless functions.\\nHowever, Azure Functions can be triggered by othe\", \"r events, such as changes to Azure Blob Storage. A\\nservice that supports image uploads could have an\", \" Azure Function responsible for optimizing the\\nimage size. The function could be triggered directly \", \"by inserts into Azure Blob Storage, keeping\\ncomplexity out of the microservice operations.\\nMany serv\", \"ices have long-running processes as part of their workflows. Often these tasks are done as\\npart of t\", \"he user\\u2019s interaction with the application. These tasks can force the user to wait, negatively\\nimpac\", \"ting their experience. Serverless computing provides a great way to move slower tasks outside\\nof the\", \" user interaction loop. These tasks can scale with demand without requiring the entire\\napplication t\", \"o scale.\\nWhen should you avoid serverless?\\nServerless solutions provision and scale on demand. When \", \"a new instance is invoked, cold starts are a\\ncommon issue. A cold start is the period of time it tak\", \"es to provision this instance. Normally, this delay\\nmight be a few seconds, but can be longer depend\", \"ing on various factors. Once provisioned, a single\\ninstance is kept alive as long as it receives per\", \"iodic requests. But, if a service is called less frequently,\\nAzure may remove it from memory and req\", \"uire a cold start when reinvoked. Cold starts are also\\nrequired when a function scales out to a new \", \"instance.\\nFigure 3-9 shows a cold-start pattern. Note the extra steps required when the app is cold.\", \"\\nFigure 3-9. Cold start versus warm start.\\nTo avoid cold starts entirely, you might switch from a co\", \"nsumption plan to a dedicated plan. You can\\nalso configure one or more pre-warmed instances with the\", \" premium plan upgrade. In these cases,\\nwhen you need to add another instance, it\\u2019s already up and re\", \"ady to go. These options can help\\nmitigate the cold start issue associated with serverless computing\", \".\\n48 CHAPTER 3 | Scaling cloud-native applicationsCloud providers bill for serverless based on compu\", \"te execution time and consumed memory. Long\\nrunning operations or high memory consumption workloads \", \"aren\\u2019t always the best candidates for\\nserverless. Serverless functions favor small chunks of work th\", \"at can complete quickly. Most serverless\\nplatforms require individual functions to complete within a\", \" few minutes. Azure Functions defaults to a\\n5-minute time-out duration, which can be configured up t\", \"o 10 minutes. The Azure Functions premium\\nplan can mitigate this issue as well, defaulting time-outs\", \" to 30 minutes with an unbounded higher\\nlimit that can be configured. Compute time isn\\u2019t calendar ti\", \"me. More advanced functions using the\\nAzure Durable Functions framework may pause execution over a c\", \"ourse of several days. The billing is\\nbased on actual execution time - when the function wakes up an\", \"d resumes processing.\\nFinally, leveraging Azure Functions for application tasks adds complexity. It\\u2019\", \"s wise to first architect\\nyour application with a modular, loosely coupled design. Then, identify if\", \" there are benefits serverless\\nwould offer that justify the additional complexity.\\nCombining contain\", \"ers and serverless approaches\\nCloud-native applications typically implement services leveraging cont\", \"ainers and orchestration. There\\nare often opportunities to expose some of the application\\u2019s services\", \" as Azure Functions. However,\\nwith a cloud-native app deployed to Kubernetes, it would be nice to le\", \"verage Azure Functions within\\nthis same toolset. Fortunately, you can wrap Azure Functions inside Do\", \"cker containers and deploy\\nthem using the same processes and tools as the rest of your Kubernetes-ba\", \"sed app.\\nWhen does it make sense to use containers with serverless?\\nYour Azure Function has no knowl\", \"edge of the platform on which it\\u2019s deployed. For some scenarios,\\nyou may have specific requirements \", \"and need to customize the environment on which your function\\ncode will run. You\\u2019ll need a custom ima\", \"ge that supports dependencies or a configuration not\\nsupported by the default image. In these cases,\", \" it makes sense to deploy your function in a custom\\nDocker container.\\nWhen should you avoid using co\", \"ntainers with Azure Functions?\\nIf you want to use consumption billing, you can\\u2019t run your function i\", \"n a container. What\\u2019s more, if you\\ndeploy your function to a Kubernetes cluster, you\\u2019ll no longer be\", \"nefit from the built-in scaling\\nprovided by Azure Functions. You\\u2019ll need to use Kubernetes\\u2019 scaling \", \"features, described earlier in this\\nchapter.\\nHow to combine serverless and Docker containers\\nTo wrap\", \" an Azure Function in a Docker container, install the Azure Functions Core Tools and then run\\nthe fo\", \"llowing command:\\nfunc init ProjectName --worker-runtime dotnet --docker\\nWhen the project is created,\", \" it will include a Dockerfile and the worker runtime configured to dotnet.\\nNow, you can create and t\", \"est your function locally. Build and run it using the docker build and docker\\n49 CHAPTER 3 | Scaling\", \" cloud-native applicationsrun commands. For detailed steps to get started building Azure Functions w\", \"ith Docker support, see\\nthe Create a function on Linux using a custom image tutorial.\\nHow to combine\", \" serverless and Kubernetes with KEDA\\nIn this chapter, you\\u2019ve seen that the Azure Functions\\u2019 platform\", \" automatically scales out to meet\\ndemand. When deploying containerized functions to AKS, however, yo\", \"u lose the built-in scaling\\nfunctionality. To the rescue comes Kubernetes-based Event Driven (KEDA).\", \" It enables fine-grained\\nautoscaling for event-driven Kubernetes workloads, including containerized \", \"functions.\\nKEDA provides event-driven scaling functionality to the Functions\\u2019 runtime in a Docker co\", \"ntainer.\\nKEDA can scale from zero instances (when no events are occurring) out to n instances, based\", \" on load.\\nIt enables autoscaling by exposing custom metrics to the Kubernetes autoscaler (Horizontal\", \" Pod\\nAutoscaler). Using Functions containers with KEDA makes it possible to replicate serverless fun\", \"ction\\ncapabilities in any Kubernetes cluster.\\nIt\\u2019s worth noting that the KEDA project is now managed\", \" by the Cloud Native Computing Foundation\\n(CNCF).\\nDeploying containers in Azure\\nWe\\u2019ve discussed cont\", \"ainers in this chapter and in chapter 1. We\\u2019ve seen that containers provide many\\nbenefits to cloud-n\", \"ative applications, including portability. In the Azure cloud, you can deploy the\\nsame containerized\", \" services across staging and production environments. Azure provides several\\noptions for hosting the\", \"se containerized workloads:\\n\\u2022 Azure Kubernetes Services (AKS)\\n\\u2022 Azure Container Instance (ACI)\\n\\u2022 Azu\", \"re Web Apps for Containers\\nAzure Container Registry\\nWhen containerizing a microservice, you first bu\", \"ild a container \\u201cimage.\\u201d The image is a binary\\nrepresentation of the service code, dependencies, and\", \" runtime. While you can manually create an\\nimage using the Docker Build command from the Docker API,\", \" a better approach is to create it as part\\nof an automated build process.\\nOnce created, container im\", \"ages are stored in container registries. They enable you to build, store, and\\nmanage container image\", \"s. There are many registries available, both public and private. Azure\\nContainer Registry (ACR) is a\", \" fully managed container registry service in the Azure cloud. It persists\\nyour images inside the Azu\", \"re network, reducing the time to deploy them to Azure container hosts.\\nYou can also secure them usin\", \"g the same security and identity procedures that you use for other\\nAzure resources.\\nYou create an Az\", \"ure Container Registry using the Azure portal, Azure CLI, or PowerShell tools.\\nCreating a registry i\", \"n Azure is simple. It requires an Azure subscription, resource group, and a unique\\n50 CHAPTER 3 | Sc\", \"aling cloud-native applicationsname. Figure 3-10 shows the basic options for creating a registry, wh\", \"ich will be hosted at\\nregistryname.azurecr.io.\\nFigure 3-10. Create container registry\\nOnce you\\u2019ve cr\", \"eated the registry, you\\u2019ll need to authenticate with it before you can use it. Typically,\\nyou\\u2019ll log\", \" into the registry using the Azure CLI command:\\naz acr login --name *registryname*\\nOnce authenticate\", \"d, you can use docker commands to push container images to it. Before you can do\\nso, however, you mu\", \"st tag your image with the fully qualified name (URL) of your ACR login server. It\\nwill have the for\", \"mat registryname.azurecr.io.\\ndocker tag mycontainer myregistry.azurecr.io/mycontainer:v1\\nAfter you\\u2019v\", \"e tagged the image, you use the docker push command to push the image to your ACR\\ninstance.\\ndocker p\", \"ush myregistry.azurecr.io/mycontainer:v1\\n51 CHAPTER 3 | Scaling cloud-native applicationsAfter you p\", \"ush an image to the registry, it\\u2019s a good idea to remove the image from your local Docker\\nenvironmen\", \"t, using this command:\\ndocker rmi myregistry.azurecr.io/mycontainer:v1\\nAs a best practice, you shoul\", \"dn\\u2019t manually push images to a container registry. Instead, use a build\\npipeline defined in a tool l\", \"ike GitHub or Azure DevOps. Learn more in the Cloud-Native DevOps\\nchapter.\\nACR Tasks\\nACR Tasks is a \", \"set of features available from the Azure Container Registry. It extends your inner-loop\\ndevelopment \", \"cycle by building and managing container images in the Azure cloud. Instead of\\ninvoking a docker bui\", \"ld and docker push locally on your development machine, they\\u2019re automatically\\nhandled by ACR Tasks i\", \"n the cloud.\\nThe following AZ CLI command both builds a container image and pushes it to ACR:\\n# crea\", \"te a container registry\\naz acr create --resource-group myResourceGroup --name myContainerRegistry008\", \" --sku\\nBasic\\n# build container image in ACR and push it into your container registry\\naz acr build --\", \"image sample/hello-world:v1 --registry myContainerRegistry008 --file\\nDockerfile .\\nAs you can see fro\", \"m the previous command block, there\\u2019s no need to install Docker Desktop on your\\ndevelopment machine.\", \" Additionally, you can configure ACR Task triggers to rebuild containers images\\non both source code \", \"and base image updates.\\nAzure Kubernetes Service\\nWe discussed Azure Kubernetes Service (AKS) at leng\", \"th in this chapter. We\\u2019ve seen that it\\u2019s the de\\nfacto container orchestrator managing containerized \", \"cloud-native applications.\\nOnce you deploy an image to a registry, such as ACR, you can configure AK\", \"S to automatically pull and\\ndeploy it. With a CI/CD pipeline in place, you might configure a canary \", \"release strategy to minimize\\nthe risk involved when rapidly deploying updates. The new version of th\", \"e app is initially configured in\\nproduction with no traffic routed to it. Then, the system will rout\", \"e a small percentage of users to the\\nnewly deployed version. As the team gains confidence in the new\", \" version, it can roll out more\\ninstances and retire the old. AKS easily supports this style of deplo\", \"yment.\\nAs with most resources in Azure, you can create an Azure Kubernetes Service cluster using the\", \" portal,\\ncommand-line, or automation tools like Helm or Terraform. To get started with a new cluster\", \", you\\nneed to provide the following information:\\n\\u2022 Azure subscription\\n\\u2022 Resource group\\n\\u2022 Kubernetes \", \"cluster name\\n\\u2022 Region\\n52 CHAPTER 3 | Scaling cloud-native applications\\u2022 Kubernetes version\\n\\u2022 DNS nam\", \"e prefix\\n\\u2022 Node size\\n\\u2022 Node count\\nThis information is sufficient to get started. As part of the crea\", \"tion process in the Azure portal, you can\\nalso configure options for the following features of your \", \"cluster:\\n\\u2022 Scale\\n\\u2022 Authentication\\n\\u2022 Networking\\n\\u2022 Monitoring\\n\\u2022 Tags\\nThis quickstart walks through dep\", \"loying an AKS cluster using the Azure portal.\\nAzure Bridge to Kubernetes\\nCloud-native applications c\", \"an grow large and complex, requiring significant compute resources to\\nrun. In these scenarios, the e\", \"ntire application can\\u2019t be hosted on a development machine (especially a\\nlaptop). Azure Bridge to Ku\", \"bernetes addresses the shortcoming. It enables developers to work with a\\nlocal version of their serv\", \"ice while hosting the entire application in an AKS development cluster.\\nWhen ready, developers test \", \"their changes locally while running against the full application in the AKS\\ncluster - without replic\", \"ating dependencies. Under the hood, the bridge merges code from the local\\nmachine with services in A\", \"KS. Developers can rapidly iterate and debug code directly in Kubernetes\\nusing Visual Studio or Visu\", \"al Studio Code.\\nGabe Monroy, former VP of Product Management at Microsoft, describes it well:\\nImagin\", \"e you\\u2019re a new employee trying to fix a bug in a complex microservices application consisting\\nof doz\", \"ens of components, each with their own configuration and backing services. To get started, you\\nmust \", \"configure your local development environment so that it can mimic production including setting\\nup yo\", \"ur IDE, building tool chain, containerized service dependencies, a local Kubernetes environment,\\nmoc\", \"ks for backing services, and more. With all the time involved setting up your development\\nenvironmen\", \"t, fixing that first bug could take days! Or you could just use Bridge to Kubernetes and\\nAKS.\\nScalin\", \"g containers and serverless applications\\nThere are two ways to scale an application: up or out. The \", \"former refers to adding capacity to a single\\nresource, while the latter refers to adding more resour\", \"ces to increase capacity.\\nThe simple solution: scaling up\\nUpgrading an existing host server with inc\", \"reased CPU, memory, disk I/O speed, and network I/O\\nspeed is known as scaling up. Scaling up a cloud\", \"-native application involves choosing more capable\\n53 CHAPTER 3 | Scaling cloud-native applicationsr\", \"esources from the cloud vendor. For example, you can create a new node pool with larger VMs in\\nyour \", \"Kubernetes cluster. Then, migrate your containerized services to the new pool.\\nServerless apps scale\", \" up by choosing the premium Functions plan or premium instance sizes from a\\ndedicated app service pl\", \"an.\\nScaling out cloud-native apps\\nCloud-native applications often experience large fluctuations in d\", \"emand and require scale on a\\nmoment\\u2019s notice. They favor scaling out. Scaling out is done horizontal\", \"ly by adding additional\\nmachines (called nodes) or application instances to an existing cluster. In \", \"Kubernetes, you can scale\\nmanually by adjusting configuration settings for the app (for example, sca\", \"ling a node pool), or\\nthrough autoscaling.\\nAKS clusters can autoscale in one of two ways:\\nFirst, the\", \" Horizontal Pod Autoscaler monitors resource demand and automatically scales your POD\\nreplicas to me\", \"et it. When traffic increases, additional replicas are automatically provisioned to scale\\nout your s\", \"ervices. Likewise, when demand decreases, they\\u2019re removed to scale-in your services. You\\ndefine the \", \"metric on which to scale, for example, CPU usage. You can also specify the minimum and\\nmaximum numbe\", \"r of replicas to run. AKS monitors that metric and scales accordingly.\\nNext, the AKS Cluster Autosca\", \"ler feature enables you to automatically scale compute nodes across a\\nKubernetes cluster to meet dem\", \"and. With it, you can automatically add new VMs to the underlying\\nAzure Virtual Machine Scale Set wh\", \"enever more compute capacity of is required. It also removes\\nnodes when no longer required.\\nFigure 3\", \"-11 shows the relationship between these two scaling services.\\nFigure 3-11. Scaling out an App Servi\", \"ce plan.\\n54 CHAPTER 3 | Scaling cloud-native applicationsWorking together, both ensure an optimal nu\", \"mber of container instances and compute nodes to\\nsupport fluctuating demand. The horizontal pod auto\", \"scaler optimizes the number of pods required.\\nThe cluster autoscaler optimizes the number of nodes r\", \"equired.\\nScaling Azure Functions\\nAzure Functions automatically scale out upon demand. Server resourc\", \"es are dynamically allocated and\\nremoved based on the number of triggered events. You\\u2019re only charge\", \"d for compute resources\\nconsumed when your functions run. Billing is based upon the number of execut\", \"ions, execution time,\\nand memory used.\\nWhile the default consumption plan provides an economical and\", \" scalable solution for most apps, the\\npremium option allows developers flexibility for custom Azure \", \"Functions requirements. Upgrading to\\nthe premium plan provides control over instance sizes, pre-warm\", \"ed instances (to avoid cold start\\ndelays), and dedicated VMs.\\nOther container deployment options\\nAsi\", \"de from Azure Kubernetes Service (AKS), you can also deploy containers to Azure App Service for\\nCont\", \"ainers and Azure Container Instances.\\nWhen does it make sense to deploy to App Service for Container\", \"s?\\nSimple production applications that don\\u2019t require orchestration are well suited to Azure App Serv\", \"ice\\nfor Containers.\\nHow to deploy to App Service for Containers\\nTo deploy to Azure App Service for C\", \"ontainers, you\\u2019ll need an Azure Container Registry (ACR) instance\\nand credentials to access it. Push\", \" your container image to the ACR repository so that your Azure App\\nService can pull it when needed. \", \"Once complete, you can configure the app for Continuous\\nDeployment. Doing so will automatically depl\", \"oy updates whenever the image changes in ACR.\\nWhen does it make sense to deploy to Azure Container I\", \"nstances?\\nAzure Container Instances (ACI) enables you to run Docker containers in a managed, serverl\", \"ess cloud\\nenvironment, without having to set up virtual machines or clusters. It\\u2019s a great solution \", \"for short-\\nrunning workloads that can run in an isolated container. Consider ACI for simple services\", \", testing\\nscenarios, task automation, and build jobs. ACI spins-up a container instance, performs th\", \"e task, and\\nthen spins it down.\\nHow to deploy an app to Azure Container Instances\\nTo deploy to Azure\", \" Container Instances (ACI), you need an Azure Container Registry (ACR) and\\ncredentials for accessing\", \" it. Once you push your container image to the repository, it\\u2019s available to pull\\ninto ACI. You can \", \"work with ACI using the Azure portal or command-line interface. ACR provides tight\\nintegration with \", \"ACI. Figure 3-12 shows how to push an individual container image to ACR.\\n55 CHAPTER 3 | Scaling clou\", \"d-native applicationsFigure 3-12. Azure Container Registry Run Instance\\nCreating an instance in ACI \", \"can be done quickly. Specify the image registry, Azure resource group\\ninformation, the amount of mem\", \"ory to allocate, and the port on which to listen. This quickstart shows\\nhow to deploy a container in\", \"stance to ACI using the Azure portal.\\nOnce the deployment completes, find the newly deployed contain\", \"er\\u2019s IP address and communicate\\nwith it over the port you specified.\\nAzure Container Instances offer\", \"s the fastest way to run simple container workloads in Azure. You don\\u2019t\\nneed to configure an app ser\", \"vice, orchestrator, or virtual machine. For scenarios where you require full\\ncontainer orchestration\", \", service discovery, automatic scaling, or coordinated upgrades, we\\nrecommend Azure Kubernetes Servi\", \"ce (AKS).\\nReferences\\n\\u2022 What is Kubernetes?\\n\\u2022 Installing Kubernetes with Minikube\\n\\u2022 MiniKube vs Docke\", \"r Desktop\\n\\u2022 Visual Studio Tools for Docker\\n56 CHAPTER 3 | Scaling cloud-native applications\\u2022 Underst\", \"anding serverless cold start\\n\\u2022 Pre-warmed Azure Functions instances\\n\\u2022 Create a function on Linux usi\", \"ng a custom image\\n\\u2022 Run Azure Functions in a Docker Container\\n\\u2022 Create a function on Linux using a c\", \"ustom image\\n\\u2022 Azure Functions with Kubernetes Event Driven Autoscaling\\n\\u2022 Canary Release\\n\\u2022 Azure Dev \", \"Spaces with VS Code\\n\\u2022 Azure Dev Spaces with Visual Studio\\n\\u2022 AKS Multiple Node Pools\\n\\u2022 AKS Cluster Au\", \"toscaler\\n\\u2022 Tutorial: Scale applications in AKS\\n\\u2022 Azure Functions scale and hosting\\n\\u2022 Azure Container\", \" Instances Docs\\n\\u2022 Deploy Container Instance from ACR\\n57 CHAPTER 3 | Scaling cloud-native application\", \"s4\\nCHAPTER\\nCloud-native\\ncommunication patterns\\nWhen constructing a cloud-native system, communicatio\", \"n becomes a significant design decision. How\\ndoes a front-end client application communicate with a \", \"back-end microservice? How do back-end\\nmicroservices communicate with each other? What are the princ\", \"iples, patterns, and best practices to\\nconsider when implementing communication in cloud-native appl\", \"ications?\\nCommunication considerations\\nIn a monolithic application, communication is straightforward\", \". The code modules execute together in\\nthe same executable space (process) on a server. This approac\", \"h can have performance advantages as\\neverything runs together in shared memory, but results in tight\", \"ly coupled code that becomes difficult\\nto maintain, evolve, and scale.\\nCloud-native systems implemen\", \"t a microservice-based architecture with many small, independent\\nmicroservices. Each microservice ex\", \"ecutes in a separate process and typically runs inside a container\\nthat is deployed to a cluster.\\nA \", \"cluster groups a pool of virtual machines together to form a highly available environment. They\\u2019re\\nm\", \"anaged with an orchestration tool, which is responsible for deploying and managing the\\ncontainerized\", \" microservices. Figure 4-1 shows a Kubernetes cluster deployed into the Azure cloud\\nwith the fully m\", \"anaged Azure Kubernetes Services.\\n58 CHAPTER 4 | Cloud-native communication patternsFigure 4-1. A Ku\", \"bernetes cluster in Azure\\nAcross the cluster, microservices communicate with each other through APIs\", \" and messaging\\ntechnologies.\\nWhile they provide many benefits, microservices are no free lunch. Loca\", \"l in-process method calls\\nbetween components are now replaced with network calls. Each microservice \", \"must communicate over\\na network protocol, which adds complexity to your system:\\n\\u2022 Network congestion\", \", latency, and transient faults are a constant concern.\\n\\u2022 Resiliency (that is, retrying failed reque\", \"sts) is essential.\\n\\u2022 Some calls must be idempotent as to keep consistent state.\\n\\u2022 Each microservice \", \"must authenticate and authorize calls.\\n\\u2022 Each message must be serialized and then deserialized - whi\", \"ch can be expensive.\\n\\u2022 Message encryption/decryption becomes important.\\nThe book .NET Microservices:\", \" Architecture for Containerized .NET Applications, available for free from\\nMicrosoft, provides an in\", \"-depth coverage of communication patterns for microservice applications. In\\nthis chapter, we provide\", \" a high-level overview of these patterns along with implementation options\\navailable in the Azure cl\", \"oud.\\nIn this chapter, we\\u2019ll first address communication between front-end applications and back-end\\n\", \"microservices. We\\u2019ll then look at back-end microservices communicate with each other. We\\u2019ll explore\\n\", \"59 CHAPTER 4 | Cloud-native communication patternsthe up and gRPC communication technology. Finally,\", \" we\\u2019ll look new innovative communication\\npatterns using service mesh technology. We\\u2019ll also see how \", \"the Azure cloud provides different kinds\\nof backing services to support cloud-native communication.\\n\", \"Front-end client communication\\nIn a cloud-native system, front-end clients (mobile, web, and desktop\", \" applications) require a\\ncommunication channel to interact with independent back-end microservices.\\n\", \"What are the options?\\nTo keep things simple, a front-end client could directly communicate with the \", \"back-end microservices,\\nshown in Figure 4-2.\\nFigure 4-2. Direct client to service communication\\nWith\", \" this approach, each microservice has a public endpoint that is accessible by front-end clients. In\\n\", \"a production environment, you\\u2019d place a load balancer in front of the microservices, routing traffic\", \"\\nproportionately.\\nWhile simple to implement, direct client communication would be acceptable only fo\", \"r simple\\nmicroservice applications. This pattern tightly couples front-end clients to core back-end \", \"services,\\nopening the door for many problems, including:\\n\\u2022 Client susceptibility to back-end service\", \" refactoring.\\n\\u2022 A wider attack surface as core back-end services are directly exposed.\\n\\u2022 Duplication\", \" of cross-cutting concerns across each microservice.\\n\\u2022 Overly complex client code - clients must kee\", \"p track of multiple endpoints and handle failures\\nin a resilient way.\\n60 CHAPTER 4 | Cloud-native co\", \"mmunication patternsInstead, a widely accepted cloud design pattern is to implement an API Gateway S\", \"ervice between the\\nfront-end applications and back-end services. The pattern is shown in Figure 4-3.\", \"\\nFigure 4-3. API gateway pattern\\nIn the previous figure, note how the API Gateway service abstracts \", \"the back-end core microservices.\\nImplemented as a web API, it acts as a reverse proxy, routing incom\", \"ing traffic to the internal\\nmicroservices.\\nThe gateway insulates the client from internal service pa\", \"rtitioning and refactoring. If you change a\\nback-end service, you accommodate for it in the gateway \", \"without breaking the client. It\\u2019s also your\\nfirst line of defense for cross-cutting concerns, such a\", \"s identity, caching, resiliency, metering, and\\nthrottling. Many of these cross-cutting concerns can \", \"be off-loaded from the back-end core services to\\nthe gateway, simplifying the back-end services.\\nCar\", \"e must be taken to keep the API Gateway simple and fast. Typically, business logic is kept out of\\nth\", \"e gateway. A complex gateway risks becoming a bottleneck and eventually a monolith itself. Larger\\nsy\", \"stems often expose multiple API Gateways segmented by client type (mobile, web, desktop) or\\nback-end\", \" functionality. The Backend for Frontends pattern provides direction for implementing\\nmultiple gatew\", \"ays. The pattern is shown in Figure 4-4.\\n61 CHAPTER 4 | Cloud-native communication patternsFigure 4-\", \"4. Backend for frontend pattern\\nNote in the previous figure how incoming traffic is sent to a specif\", \"ic API gateway - based upon client\\ntype: web, mobile, or desktop app. This approach makes sense as t\", \"he capabilities of each device differ\\nsignificantly across form factor, performance, and display lim\", \"itations. Typically mobile applications\\nexpose less functionality than a browser or desktop applicat\", \"ions. Each gateway can be optimized to\\nmatch the capabilities and functionality of the corresponding\", \" device.\\nSimple Gateways\\nTo start, you could build your own API Gateway service. A quick search of G\", \"itHub will provide many\\nexamples.\\nFor simple .NET cloud-native applications, you might consider the \", \"Ocelot Gateway. Open source and\\ncreated for .NET microservices, it\\u2019s lightweight, fast, scalable. Li\", \"ke any API Gateway, its primary\\nfunctionality is to forward incoming HTTP requests to downstream ser\", \"vices. Additionally, it supports a\\nwide variety of capabilities that are configurable in a .NET midd\", \"leware pipeline.\\nYARP (Yet Another Reverse proxy) is another open source reverse proxy led by a grou\", \"p of Microsoft\\nproduct teams. Downloadable as a NuGet package, YARP plugs into the ASP.NET framework\", \" as\\nmiddleware and is highly customizable. You\\u2019ll find YARP well-documented with various usage\\nexamp\", \"les.\\nFor enterprise cloud-native applications, there are several managed Azure services that can hel\", \"p\\njump-start your efforts.\\n62 CHAPTER 4 | Cloud-native communication patternsAzure Application Gatew\", \"ay\\nFor simple gateway requirements, you may consider Azure Application Gateway. Available as an Azur\", \"e\\nPaaS service, it includes basic gateway features such as URL routing, SSL termination, and a Web\\nA\", \"pplication Firewall. The service supports Layer-7 load balancing capabilities. With Layer 7, you can\", \"\\nroute requests based on the actual content of an HTTP message, not just low-level TCP network\\npacke\", \"ts.\\nThroughout this book, we evangelize hosting cloud-native systems in Kubernetes. A container\\norch\", \"estrator, Kubernetes automates the deployment, scaling, and operational concerns of\\ncontainerized wo\", \"rkloads. Azure Application Gateway can be configured as an API gateway for Azure\\nKubernetes Service \", \"cluster.\\nThe Application Gateway Ingress Controller enables Azure Application Gateway to work direct\", \"ly with\\nAzure Kubernetes Service. Figure 4.5 shows the architecture.\\nFigure 4-5. Application Gateway\", \" Ingress Controller\\nKubernetes includes a built-in feature that supports HTTP (Level 7) load balanci\", \"ng, called Ingress.\\nIngress defines a set of rules for how microservice instances inside AKS can be \", \"exposed to the outside\\nworld. In the previous image, the ingress controller interprets the ingress r\", \"ules configured for the\\ncluster and automatically configures the Azure Application Gateway. Based on\", \" those rules, the\\nApplication Gateway routes traffic to microservices running inside AKS. The ingres\", \"s controller listens\\nfor changes to ingress rules and makes the appropriate changes to the Azure App\", \"lication Gateway.\\nAzure API Management\\nFor moderate to large-scale cloud-native systems, you may con\", \"sider Azure API Management. It\\u2019s a\\ncloud-based service that not only solves your API Gateway needs, \", \"but provides a full-featured\\ndeveloper and administrative experience. API Management is shown in Fig\", \"ure 4-6.\\n63 CHAPTER 4 | Cloud-native communication patternsFigure 4-6. Azure API Management\\nTo start\", \", API Management exposes a gateway server that allows controlled access to back-end\\nservices based u\", \"pon configurable rules and policies. These services can be in the Azure cloud, your\\non-prem data cen\", \"ter, or other public clouds. API keys and JWT tokens determine who can do what. All\\ntraffic is logge\", \"d for analytical purposes.\\nFor developers, API Management offers a developer portal that provides ac\", \"cess to services,\\ndocumentation, and sample code for invoking them. Developers can use Swagger/Open \", \"API to\\ninspect service endpoints and analyze their usage. The service works across the major develop\", \"ment\\nplatforms: .NET, Java, Golang, and more.\\nThe publisher portal exposes a management dashboard wh\", \"ere administrators expose APIs and\\nmanage their behavior. Service access can be granted, service hea\", \"lth monitored, and service telemetry\\ngathered. Administrators apply policies to each endpoint to aff\", \"ect behavior. Policies are pre-built\\nstatements that execute sequentially for each service call. Pol\", \"icies are configured for an inbound call,\\noutbound call, or invoked upon an error. Policies can be a\", \"pplied at different service scopes as to\\nenable deterministic ordering when combining policies. The \", \"product ships with a large number of\\nprebuilt policies.\\nHere are examples of how policies can affect\", \" the behavior of your cloud-native services:\\n\\u2022 Restrict service access.\\n\\u2022 Enforce authentication.\\n\\u2022 \", \"Throttle calls from a single source, if necessary.\\n\\u2022 Enable caching.\\n\\u2022 Block calls from specific IP \", \"addresses.\\n64 CHAPTER 4 | Cloud-native communication patterns\\u2022 Control the flow of the service.\\n\\u2022 Co\", \"nvert requests from SOAP to REST or between different data formats, such as from XML to\\nJSON.\\nAzure \", \"API Management can expose back-end services that are hosted anywhere \\u2013 in the cloud or your\\ndata cen\", \"ter. For legacy services that you may expose in your cloud-native systems, it supports both\\nREST and\", \" SOAP APIs. Even other Azure services can be exposed through API Management. You could\\nplace a manag\", \"ed API on top of an Azure backing service like Azure Service Bus or Azure Logic Apps.\\nAzure API Mana\", \"gement doesn\\u2019t include built-in load-balancing support and should be used in\\nconjunction with a load\", \"-balancing service.\\nAzure API Management is available across four different tiers:\\n\\u2022 Developer\\n\\u2022 Bas\", \"ic\\n\\u2022 Standard\\n\\u2022 Premium\\nThe Developer tier is meant for non-production workloads and evaluation. The\", \" other tiers offer\\nprogressively more power, features, and higher service level agreements (SLAs). T\", \"he Premium tier\\nprovides Azure Virtual Network and multi-region support. All tiers have a fixed pric\", \"e per hour.\\nThe Azure cloud also offers a serverless tier for Azure API Management. Referred to as t\", \"he\\nconsumption pricing tier, the service is a variant of API Management designed around the serverle\", \"ss\\ncomputing model. Unlike the \\u201cpre-allocated\\u201d pricing tiers previously shown, the consumption tier\\n\", \"provides instant provisioning and pay-per-action pricing.\\nIt enables API Gateway features for the fo\", \"llowing use cases:\\n\\u2022 Microservices implemented using serverless technologies such as Azure Functions\", \" and Azure\\nLogic Apps.\\n\\u2022 Azure backing service resources such as Service Bus queues and topics, Azur\", \"e storage, and\\nothers.\\n\\u2022 Microservices where traffic has occasional large spikes but remains low mos\", \"t the time.\\nThe consumption tier uses the same underlying service API Management components, but emp\", \"loys\\nan entirely different architecture based on dynamically allocated resources. It aligns perfectl\", \"y with the\\nserverless computing model:\\n\\u2022 No infrastructure to manage.\\n\\u2022 No idle capacity.\\n\\u2022 High-ava\", \"ilability.\\n\\u2022 Automatic scaling.\\n\\u2022 Cost is based on actual usage.\\nThe new consumption tier is a great\", \" choice for cloud-native systems that expose serverless resources\\nas APIs.\\n65 CHAPTER 4 | Cloud-nati\", \"ve communication patternsReal-time communication\\nReal-time, or push, communication is another option\", \" for front-end applications that communicate\\nwith back-end cloud-native systems over HTTP. Applicati\", \"ons, such as financial-tickers, online\\neducation, gaming, and job-progress updates, require instanta\", \"neous, real-time responses from the\\nback-end. With normal HTTP communication, there\\u2019s no way for the\", \" client to know when new data is\\navailable. The client must continually poll or send requests to the\", \" server. With real-time\\ncommunication, the server can push new data to the client at any time.\\nReal-\", \"time systems are often characterized by high-frequency data flows and large numbers of\\nconcurrent cl\", \"ient connections. Manually implementing real-time connectivity can quickly become\\ncomplex, requiring\", \" non-trivial infrastructure to ensure scalability and reliable messaging to connected\\nclients. You c\", \"ould find yourself managing an instance of Azure Redis Cache and a set of load\\nbalancers configured \", \"with sticky sessions for client affinity.\\nAzure SignalR Service is a fully managed Azure service tha\", \"t simplifies real-time communication for\\nyour cloud-native applications. Technical implementation de\", \"tails like capacity provisioning, scaling,\\nand persistent connections are abstracted away. They\\u2019re h\", \"andled for you with a 99.9% service-level\\nagreement. You focus on application features, not infrastr\", \"ucture plumbing.\\nOnce enabled, a cloud-based HTTP service can push content updates directly to conne\", \"cted clients,\\nincluding browser, mobile and desktop applications. Clients are updated without the ne\", \"ed to poll the\\nserver. Azure SignalR abstracts the transport technologies that create real-time conn\", \"ectivity, including\\nWebSockets, Server-Side Events, and Long Polling. Developers focus on sending me\", \"ssages to all or\\nspecific subsets of connected clients.\\nFigure 4-7 shows a set of HTTP Clients conne\", \"cting to a Cloud-native application with Azure SignalR\\nenabled.\\n66 CHAPTER 4 | Cloud-native communic\", \"ation patternsFigure 4-7. Azure SignalR\\nAnother advantage of Azure SignalR Service comes with implem\", \"enting Serverless cloud-native\\nservices. Perhaps your code is executed on demand with Azure Function\", \"s triggers. This scenario can\\nbe tricky because your code doesn\\u2019t maintain long connections with cli\", \"ents. Azure SignalR Service can\\nhandle this situation since the service already manages connections \", \"for you.\\nAzure SignalR Service closely integrates with other Azure services, such as Azure SQL Datab\", \"ase,\\nService Bus, or Redis Cache, opening up many possibilities for your cloud-native applications.\\n\", \"Service-to-service communication\\nMoving from the front-end client, we now address back-end microserv\", \"ices communicate with each\\nother.\\nWhen constructing a cloud-native application, you\\u2019ll want to be se\", \"nsitive to how back-end services\\ncommunicate with each other. Ideally, the less inter-service commun\", \"ication, the better. However,\\navoidance isn\\u2019t always possible as back-end services often rely on one\", \" another to complete an\\noperation.\\nThere are several widely accepted approaches to implementing cros\", \"s-service communication. The type\\nof communication interaction will often determine the best approac\", \"h.\\nConsider the following interaction types:\\n\\u2022 Query \\u2013 when a calling microservice requires a respon\", \"se from a called microservice, such as,\\n\\u201cHey, give me the buyer information for a given customer Id.\", \"\\u201d\\n67 CHAPTER 4 | Cloud-native communication patterns\\u2022 Command \\u2013 when the calling microservice needs \", \"another microservice to execute an action\\nbut doesn\\u2019t require a response, such as, \\u201cHey, just ship t\", \"his order.\\u201d\\n\\u2022 Event \\u2013 when a microservice, called the publisher, raises an event that state has chan\", \"ged or an\\naction has occurred. Other microservices, called subscribers, who are interested, can reac\", \"t to\\nthe event appropriately. The publisher and the subscribers aren\\u2019t aware of each other.\\nMicroser\", \"vice systems typically use a combination of these interaction types when executing\\noperations that r\", \"equire cross-service interaction. Let\\u2019s take a close look at each and how you might\\nimplement them.\\n\", \"Queries\\nMany times, one microservice might need to query another, requiring an immediate response to\", \"\\ncomplete an operation. A shopping basket microservice may need product information and a price to\\na\", \"dd an item to its basket. There are many approaches for implementing query operations.\\nRequest/Respo\", \"nse Messaging\\nOne option for implementing this scenario is for the calling back-end microservice to \", \"make direct\\nHTTP requests to the microservices it needs to query, shown in Figure 4-8.\\nFigure 4-8. D\", \"irect HTTP communication\\nWhile direct HTTP calls between microservices are relatively simple to impl\", \"ement, care should be\\ntaken to minimize this practice. To start, these calls are always synchronous \", \"and will block the\\noperation until a result is returned or the request times outs. What were once se\", \"lf-contained,\\nindependent services, able to evolve independently and deploy frequently, now become c\", \"oupled to\\neach other. As coupling among microservices increase, their architectural benefits diminis\", \"h.\\n68 CHAPTER 4 | Cloud-native communication patternsExecuting an infrequent request that makes a si\", \"ngle direct HTTP call to another microservice might be\\nacceptable for some systems. However, high-vo\", \"lume calls that invoke direct HTTP calls to multiple\\nmicroservices aren\\u2019t advisable. They can increa\", \"se latency and negatively impact the performance,\\nscalability, and availability of your system. Even\", \" worse, a long series of direct HTTP communication can\\nlead to deep and complex chains of synchronou\", \"s microservices calls, shown in Figure 4-9:\\nFigure 4-9. Chaining HTTP queries\\nYou can certainly imag\", \"ine the risk in the design shown in the previous image. What happens if Step\\n#3 fails? Or Step #8 fa\", \"ils? How do you recover? What if Step #6 is slow because the underlying service\\nis busy? How do you \", \"continue? Even if all works correctly, think of the latency this call would incur,\\nwhich is the sum \", \"of the latency of each step.\\nThe large degree of coupling in the previous image suggests the service\", \"s weren\\u2019t optimally modeled.\\nIt would behoove the team to revisit their design.\\nMaterialized View pa\", \"ttern\\nA popular option for removing microservice coupling is the Materialized View pattern. With thi\", \"s\\npattern, a microservice stores its own local, denormalized copy of data that\\u2019s owned by other serv\", \"ices.\\nInstead of the Shopping Basket microservice querying the Product Catalog and Pricing microserv\", \"ices,\\nit maintains its own local copy of that data. This pattern eliminates unnecessary coupling and\", \"\\nimproves reliability and response time. The entire operation executes inside a single process. We\\ne\", \"xplore this pattern and other data concerns in Chapter 5.\\nService Aggregator Pattern\\nAnother option \", \"for eliminating microservice-to-microservice coupling is an Aggregator microservice,\\nshown in purple\", \" in Figure 4-10.\\n69 CHAPTER 4 | Cloud-native communication patternsFigure 4-10. Aggregator microserv\", \"ice\\nThe pattern isolates an operation that makes calls to multiple back-end microservices, centraliz\", \"ing its\\nlogic into a specialized microservice. The purple checkout aggregator microservice in the pr\", \"evious\\nfigure orchestrates the workflow for the Checkout operation. It includes calls to several bac\", \"k-end\\nmicroservices in a sequenced order. Data from the workflow is aggregated and returned to the c\", \"aller.\\nWhile it still implements direct HTTP calls, the aggregator microservice reduces direct depen\", \"dencies\\namong back-end microservices.\\nRequest/Reply Pattern\\nAnother approach for decoupling synchron\", \"ous HTTP messages is a Request-Reply Pattern, which uses\\nqueuing communication. Communication using \", \"a queue is always a one-way channel, with a producer\\nsending the message and consumer receiving it. \", \"With this pattern, both a request queue and response\\nqueue are implemented, shown in Figure 4-11.\\n70\", \" CHAPTER 4 | Cloud-native communication patternsFigure 4-11. Request-reply pattern\\nHere, the message\", \" producer creates a query-based message that contains a unique correlation ID and\\nplaces it into a r\", \"equest queue. The consuming service dequeues the messages, processes it and places\\nthe response into\", \" the response queue with the same correlation ID. The producer service dequeues\\nthe message, matches\", \" it with the correlation ID and continues processing. We cover queues in detail\\nin the next section.\", \"\\nCommands\\nAnother type of communication interaction is a command. A microservice may need another\\nmi\", \"croservice to perform an action. The Ordering microservice may need the Shipping microservice to\\ncre\", \"ate a shipment for an approved order. In Figure 4-12, one microservice, called a Producer, sends a\\nm\", \"essage to another microservice, the Consumer, commanding it to do something.\\n71 CHAPTER 4 | Cloud-na\", \"tive communication patternsFigure 4-12. Command interaction with a queue\\nMost often, the Producer do\", \"esn\\u2019t require a response and can fire-and-forget the message. If a reply is\\nneeded, the Consumer sen\", \"ds a separate message back to Producer on another channel. A command\\nmessage is best sent asynchrono\", \"usly with a message queue. supported by a lightweight message\\nbroker. In the previous diagram, note \", \"how a queue separates and decouples both services.\\nA message queue is an intermediary construct thro\", \"ugh which a producer and consumer pass a\\nmessage. Queues implement an asynchronous, point-to-point m\", \"essaging pattern. The Producer\\nknows where a command needs to be sent and routes appropriately. The \", \"queue guarantees that a\\nmessage is processed by exactly one of the consumer instances that are readi\", \"ng from the channel. In\\nthis scenario, either the producer or consumer service can scale out without\", \" affecting the other. As\\nwell, technologies can be disparate on each side, meaning that we might hav\", \"e a Java microservice\\ncalling a Golang microservice.\\nIn chapter 1, we talked about backing services.\", \" Backing services are ancillary resources upon which\\ncloud-native systems depend. Message queues are\", \" backing services. The Azure cloud supports two\\ntypes of message queues that your cloud-native syste\", \"ms can consume to implement command\\nmessaging: Azure Storage Queues and Azure Service Bus Queues.\\nAz\", \"ure Storage Queues\\nAzure storage queues offer a simple queueing infrastructure that is fast, afforda\", \"ble, and backed by\\nAzure storage accounts.\\nAzure Storage Queues feature a REST-based queuing mechani\", \"sm with reliable and persistent\\nmessaging. They provide a minimal feature set, but are inexpensive a\", \"nd store millions of messages.\\nTheir capacity ranges up to 500 TB. A single message can be up to 64 \", \"KB in size.\\nYou can access messages from anywhere in the world via authenticated calls using HTTP or\", \" HTTPS.\\nStorage queues can scale out to large numbers of concurrent clients to handle traffic spikes\", \".\\n72 CHAPTER 4 | Cloud-native communication patternsThat said, there are limitations with the servic\", \"e:\\n\\u2022 Message order isn\\u2019t guaranteed.\\n\\u2022 A message can only persist for seven days before it\\u2019s automat\", \"ically removed.\\n\\u2022 Support for state management, duplicate detection, or transactions isn\\u2019t available\", \".\\nFigure 4-13 shows the hierarchy of an Azure Storage Queue.\\nFigure 4-13. Storage queue hierarchy\\nIn\", \" the previous figure, note how storage queues store their messages in the underlying Azure Storage\\na\", \"ccount.\\nFor developers, Microsoft provides several client and server-side libraries for Storage queu\", \"e\\nprocessing. Most major platforms are supported including .NET, Java, JavaScript, Ruby, Python, and\", \"\\nGo. Developers should never communicate directly with these libraries. Doing so will tightly couple\", \"\\nyour microservice code to the Azure Storage Queue service. It\\u2019s a better practice to insulate the\\ni\", \"mplementation details of the API. Introduce an intermediation layer, or intermediate API, that expos\", \"es\\ngeneric operations and encapsulates the concrete library. This loose coupling enables you to swap\", \" out\\none queuing service for another without having to make changes to the mainline service code.\\nAz\", \"ure Storage queues are an economical option to implement command messaging in your cloud-\\nnative app\", \"lications. Especially when a queue size will exceed 80 GB, or a simple feature set is\\nacceptable. Yo\", \"u only pay for the storage of the messages; there are no fixed hourly charges.\\nAzure Service Bus Que\", \"ues\\nFor more complex messaging requirements, consider Azure Service Bus queues.\\nSitting atop a robus\", \"t message infrastructure, Azure Service Bus supports a brokered messaging model.\\nMessages are reliab\", \"ly stored in a broker (the queue) until received by the consumer. The queue\\nguarantees First-In/Firs\", \"t-Out (FIFO) message delivery, respecting the order in which messages were\\nadded to the queue.\\nThe s\", \"ize of a message can be much larger, up to 256 KB. Messages are persisted in the queue for an\\nunlimi\", \"ted period of time. Service Bus supports not only HTTP-based calls, but also provides full\\n73 CHAPTE\", \"R 4 | Cloud-native communication patternssupport for the AMQP protocol. AMQP is an open-standard acr\", \"oss vendors that supports a binary\\nprotocol and higher degrees of reliability.\\nService Bus provides \", \"a rich set of features, including transaction support and a duplicate detection\\nfeature. The queue g\", \"uarantees \\u201cat most once delivery\\u201d per message. It automatically discards a\\nmessage that has already \", \"been sent. If a producer is in doubt, it can resend the same message, and\\nService Bus guarantees tha\", \"t only one copy will be processed. Duplicate detection frees you from\\nhaving to build additional inf\", \"rastructure plumbing.\\nTwo more enterprise features are partitioning and sessions. A conventional Ser\", \"vice Bus queue is\\nhandled by a single message broker and stored in a single message store. But, Serv\", \"ice Bus Partitioning\\nspreads the queue across multiple message brokers and message stores. The overa\", \"ll throughput is no\\nlonger limited by the performance of a single message broker or messaging store.\", \" A temporary\\noutage of a messaging store doesn\\u2019t render a partitioned queue unavailable.\\nService Bus\", \" Sessions provide a way to group-related messages. Imagine a workflow scenario where\\nmessages must b\", \"e processed together and the operation completed at the end. To take advantage,\\nsessions must be exp\", \"licitly enabled for the queue and each related messaged must contain the same\\nsession ID.\\nHowever, t\", \"here are some important caveats: Service Bus queues size is limited to 80 GB, which is much\\nsmaller \", \"than what\\u2019s available from store queues. Additionally, Service Bus queues incur a base cost\\nand char\", \"ge per operation.\\nFigure 4-14 outlines the high-level architecture of a Service Bus queue.\\nFigure 4-\", \"14. Service Bus queue\\nIn the previous figure, note the point-to-point relationship. Two instances of\", \" the same provider are\\nenqueuing messages into a single Service Bus queue. Each message is consumed \", \"by only one of three\\nconsumer instances on the right. Next, we discuss how to implement messaging wh\", \"ere different\\nconsumers may all be interested the same message.\\nEvents\\nMessage queuing is an effecti\", \"ve way to implement communication where a producer can\\nasynchronously send a consumer a message. How\", \"ever, what happens when many different consumers\\n74 CHAPTER 4 | Cloud-native communication patternsa\", \"re interested in the same message? A dedicated message queue for each consumer wouldn\\u2019t scale\\nwell a\", \"nd would become difficult to manage.\\nTo address this scenario, we move to the third type of message \", \"interaction, the event. One\\nmicroservice announces that an action had occurred. Other microservices,\", \" if interested, react to the\\naction, or event. This is also known as the event-driven architectural \", \"style.\\nEventing is a two-step process. For a given state change, a microservice publishes an event t\", \"o a\\nmessage broker, making it available to any other interested microservice. The interested microse\", \"rvice\\nis notified by subscribing to the event in the message broker. You use the Publish/Subscribe p\", \"attern\\nto implement event-based communication.\\nFigure 4-15 shows a shopping basket microservice publ\", \"ishing an event with two other microservices\\nsubscribing to it.\\nFigure 4-15. Event-Driven messaging\\n\", \"Note the event bus component that sits in the middle of the communication channel. It\\u2019s a custom\\ncla\", \"ss that encapsulates the message broker and decouples it from the underlying application. The\\norderi\", \"ng and inventory microservices independently operate the event with no knowledge of each\\nother, nor \", \"the shopping basket microservice. When the registered event is published to the event bus,\\nthey act \", \"upon it.\\nWith eventing, we move from queuing technology to topics. A topic is similar to a queue, bu\", \"t supports\\na one-to-many messaging pattern. One microservice publishes a message. Multiple subscribi\", \"ng\\nmicroservices can choose to receive and act upon that message. Figure 4-16 shows a topic\\narchitec\", \"ture.\\n75 CHAPTER 4 | Cloud-native communication patternsFigure 4-16. Topic architecture\\nIn the previ\", \"ous figure, publishers send messages to the topic. At the end, subscribers receive\\nmessages from sub\", \"scriptions. In the middle, the topic forwards messages to subscriptions based on a\\nset of rules, sho\", \"wn in dark blue boxes. Rules act as a filter that forward specific messages to a\\nsubscription. Here,\", \" a \\u201cGetPrice\\u201d event would be sent to the price and logging subscriptions as the\\nlogging subscription\", \" has chosen to receive all messages. A \\u201cGetInformation\\u201d event would be sent to\\nthe information and l\", \"ogging subscriptions.\\nThe Azure cloud supports two different topic services: Azure Service Bus Topic\", \"s and Azure EventGrid.\\nAzure Service Bus Topics\\nSitting on top of the same robust brokered message m\", \"odel of Azure Service Bus queues are Azure\\nService Bus Topics. A topic can receive messages from mul\", \"tiple independent publishers and send\\nmessages to up to 2,000 subscribers. Subscriptions can be dyna\", \"mically added or removed at run time\\nwithout stopping the system or recreating the topic.\\nMany advan\", \"ced features from Azure Service Bus queues are also available for topics, including\\nDuplicate Detect\", \"ion and Transaction support. By default, Service Bus topics are handled by a single\\nmessage broker a\", \"nd stored in a single message store. But, Service Bus Partitioning scales a topic by\\nspreading it ac\", \"ross many message brokers and message stores.\\nScheduled Message Delivery tags a message with a speci\", \"fic time for processing. The message won\\u2019t\\nappear in the topic before that time. Message Deferral en\", \"ables you to defer a retrieval of a message\\nto a later time. Both are commonly used in workflow proc\", \"essing scenarios where operations are\\nprocessed in a particular order. You can postpone processing o\", \"f received messages until prior work\\nhas been completed.\\nService Bus topics are a robust and proven \", \"technology for enabling publish/subscribe communication\\nin your cloud-native systems.\\nAzure Event Gr\", \"id\\nWhile Azure Service Bus is a battle-tested messaging broker with a full set of enterprise feature\", \"s,\\nAzure Event Grid is the new kid on the block.\\n76 CHAPTER 4 | Cloud-native communication patternsA\", \"t first glance, Event Grid may look like just another topic-based messaging system. However, it\\u2019s\\ndi\", \"fferent in many ways. Focused on event-driven workloads, it enables real-time event processing,\\ndeep\", \" Azure integration, and an open-platform - all on serverless infrastructure. It\\u2019s designed for\\nconte\", \"mporary cloud-native and serverless applications\\nAs a centralized eventing backplane, or pipe, Event\", \" Grid reacts to events inside Azure resources and\\nfrom your own services.\\nEvent notifications are pu\", \"blished to an Event Grid Topic, which, in turn, routes each event to a\\nsubscription. Subscribers map\", \" to subscriptions and consume the events. Like Service Bus, Event Grid\\nsupports a filtered subscribe\", \"r model where a subscription sets rule for the events it wishes to receive.\\nEvent Grid provides fast\", \" throughput with a guarantee of 10 million events per second enabling near\\nreal-time delivery - far \", \"more than what Azure Service Bus can generate.\\nA sweet spot for Event Grid is its deep integration i\", \"nto the fabric of Azure infrastructure. An Azure\\nresource, such as Cosmos DB, can publish built-in e\", \"vents directly to other interested Azure resources -\\nwithout the need for custom code. Event Grid ca\", \"n publish events from an Azure Subscription,\\nResource Group, or Service, giving developers fine-grai\", \"ned control over the lifecycle of cloud\\nresources. However, Event Grid isn\\u2019t limited to Azure. It\\u2019s \", \"an open platform that can consume custom\\nHTTP events published from applications or third-party serv\", \"ices and route events to external\\nsubscribers.\\nWhen publishing and subscribing to native events from\", \" Azure resources, no coding is required. With\\nsimple configuration, you can integrate events from on\", \"e Azure resource to another leveraging built-in\\nplumbing for Topics and Subscriptions. Figure 4-17 s\", \"hows the anatomy of Event Grid.\\nFigure 4-17. Event Grid anatomy\\n77 CHAPTER 4 | Cloud-native communic\", \"ation patternsA major difference between EventGrid and Service Bus is the underlying message exchang\", \"e pattern.\\nService Bus implements an older style pull model in which the downstream subscriber activ\", \"ely polls\\nthe topic subscription for new messages. On the upside, this approach gives the subscriber\", \" full control\\nof the pace at which it processes messages. It controls when and how many messages to \", \"process at\\nany given time. Unread messages remain in the subscription until processed. A significant\", \"\\nshortcoming is the latency between the time the event is generated and the polling operation that\\np\", \"ulls that message to the subscriber for processing. Also, the overhead of constant polling for the\\nn\", \"ext event consumes resources and money.\\nEventGrid, however, is different. It implements a push model\", \" in which events are sent to the\\nEventHandlers as received, giving near real-time event delivery. It\", \" also reduces cost as the service is\\ntriggered only when it\\u2019s needed to consume an event \\u2013 not conti\", \"nually as with polling. That said, an\\nevent handler must handle the incoming load and provide thrott\", \"ling mechanisms to protect itself\\nfrom becoming overwhelmed. Many Azure services that consume these \", \"events, such as Azure\\nFunctions and Logic Apps provide automatic autoscaling capabilities to handle \", \"increased loads.\\nEvent Grid is a fully managed serverless cloud service. It dynamically scales based\", \" on your traffic and\\ncharges you only for your actual usage, not pre-purchased capacity. The first 1\", \"00,000 operations per\\nmonth are free \\u2013 operations being defined as event ingress (incoming event not\", \"ifications),\\nsubscription delivery attempts, management calls, and filtering by subject. With 99.99%\", \" availability,\\nEventGrid guarantees the delivery of an event within a 24-hour period, with built-in \", \"retry functionality\\nfor unsuccessful delivery. Undelivered messages can be moved to a \\u201cdead-letter\\u201d \", \"queue for resolution.\\nUnlike Azure Service Bus, Event Grid is tuned for fast performance and doesn\\u2019t\", \" support features like\\nordered messaging, transactions, and sessions.\\nStreaming messages in the Azur\", \"e cloud\\nAzure Service Bus and Event Grid provide great support for applications that expose single, \", \"discrete\\nevents like a new document has been inserted into a Cosmos DB. But, what if your cloud-nati\", \"ve\\nsystem needs to process a stream of related events? Event streams are more complex. They\\u2019re typic\", \"ally\\ntime-ordered, interrelated, and must be processed as a group.\\nAzure Event Hub is a data streami\", \"ng platform and event ingestion service that collects, transforms,\\nand stores events. It\\u2019s fine-tune\", \"d to capture streaming data, such as continuous event notifications\\nemitted from a telemetry context\", \". The service is highly scalable and can store and process millions of\\nevents per second. Shown in F\", \"igure 4-18, it\\u2019s often a front door for an event pipeline, decoupling\\ningest stream from event consu\", \"mption.\\n78 CHAPTER 4 | Cloud-native communication patternsFigure 4-18. Azure Event Hub\\nEvent Hub sup\", \"ports low latency and configurable time retention. Unlike queues and topics, Event\\nHubs keep event d\", \"ata after it\\u2019s been read by a consumer. This feature enables other data analytic\\nservices, both inte\", \"rnal and external, to replay the data for further analysis. Events stored in event hub\\nare only dele\", \"ted upon expiration of the retention period, which is one day by default, but\\nconfigurable.\\nEvent Hu\", \"b supports common event publishing protocols including HTTPS and AMQP. It also supports\\nKafka 1.0. E\", \"xisting Kafka applications can communicate with Event Hub using the Kafka protocol\\nproviding an alte\", \"rnative to managing large Kafka clusters. Many open-source cloud-native systems\\nembrace Kafka.\\nEvent\", \" Hubs implements message streaming through a partitioned consumer model in which each\\nconsumer only \", \"reads a specific subset, or partition, of the message stream. This pattern enables\\ntremendous horizo\", \"ntal scale for event processing and provides other stream-focused features that are\\nunavailable in q\", \"ueues and topics. A partition is an ordered sequence of events that is held in an event\\nhub. As newe\", \"r events arrive, they\\u2019re added to the end of this sequence. Figure 4-19 shows partitioning\\nin an Eve\", \"nt Hub.\\nFigure 4-19. Event Hub partitioning\\nInstead of reading from the same resource, each consumer\", \" group reads across a subset, or partition,\\nof the message stream.\\n79 CHAPTER 4 | Cloud-native commu\", \"nication patternsFor cloud-native applications that must stream large numbers of events, Azure Event\", \" Hub can be a\\nrobust and affordable solution.\\ngRPC\\nSo far in this book, we\\u2019ve focused on REST-based \", \"communication. We\\u2019ve seen that REST is a flexible\\narchitectural style that defines CRUD-based operat\", \"ions against entity resources. Clients interact with\\nresources across HTTP with a request/response c\", \"ommunication model. While REST is widely\\nimplemented, a newer communication technology, gRPC, has ga\", \"ined tremendous momentum across\\nthe cloud-native community.\\nWhat is gRPC?\\ngRPC is a modern, high-per\", \"formance framework that evolves the age-old remote procedure call (RPC)\\nprotocol. At the application\", \" level, gRPC streamlines messaging between clients and back-end services.\\nOriginating from Google, g\", \"RPC is open source and part of the Cloud Native Computing Foundation\\n(CNCF) ecosystem of cloud-nativ\", \"e offerings. CNCF considers gRPC an incubating project. Incubating\\nmeans end users are using the tec\", \"hnology in production applications, and the project has a healthy\\nnumber of contributors.\\nA typical \", \"gRPC client app will expose a local, in-process function that implements a business\\noperation. Under\", \" the covers, that local function invokes another function on a remote machine. What\\nappears to be a \", \"local call essentially becomes a transparent out-of-process call to a remote service.\\nThe RPC plumbi\", \"ng abstracts the point-to-point networking communication, serialization, and\\nexecution between compu\", \"ters.\\nIn cloud-native applications, developers often work across programming languages, frameworks, \", \"and\\ntechnologies. This interoperability complicates message contracts and the plumbing required for\\n\", \"cross-platform communication. gRPC provides a \\u201cuniform horizontal layer\\u201d that abstracts these\\nconcer\", \"ns. Developers code in their native platform focused on business functionality, while gRPC\\nhandles c\", \"ommunication plumbing.\\ngRPC offers comprehensive support across most popular development stacks, inc\", \"luding Java,\\nJavaScript, C#, Go, Swift, and NodeJS.\\ngRPC Benefits\\ngRPC uses HTTP/2 for its transport\", \" protocol. While compatible with HTTP 1.1, HTTP/2 features many\\nadvanced capabilities:\\n\\u2022 A binary fr\", \"aming protocol for data transport - unlike HTTP 1.1, which is text based.\\n\\u2022 Multiplexing support for\", \" sending multiple parallel requests over the same connection - HTTP\\n1.1 limits processing to one req\", \"uest/response message at a time.\\n\\u2022 Bidirectional full-duplex communication for sending both client r\", \"equests and server responses\\nsimultaneously.\\n\\u2022 Built-in streaming enabling requests and responses to\", \" asynchronously stream large data sets.\\n\\u2022 Header compression that reduces network usage.\\n80 CHAPTER \", \"4 | Cloud-native communication patternsgRPC is lightweight and highly performant. It can be up to 8x\", \" faster than JSON serialization with\\nmessages 60-80% smaller. In Microsoft Windows Communication Fou\", \"ndation (WCF) parlance, gRPC\\nperformance exceeds the speed and efficiency of the highly optimized Ne\", \"tTCP bindings. Unlike\\nNetTCP, which favors the Microsoft stack, gRPC is cross-platform.\\nProtocol Buf\", \"fers\\ngRPC embraces an open-source technology called Protocol Buffers. They provide a highly efficien\", \"t\\nand platform-neutral serialization format for serializing structured messages that services send t\", \"o\\neach other. Using a cross-platform Interface Definition Language (IDL), developers define a servic\", \"e\\ncontract for each microservice. The contract, implemented as a text-based .proto file, describes t\", \"he\\nmethods, inputs, and outputs for each service. The same contract file can be used for gRPC client\", \"s and\\nservices built on different development platforms.\\nUsing the proto file, the Protobuf compiler\", \", protoc, generates both client and service code for your\\ntarget platform. The code includes the fol\", \"lowing components:\\n\\u2022 Strongly typed objects, shared by the client and service, that represent the se\", \"rvice operations\\nand data elements for a message.\\n\\u2022 A strongly typed base class with the required ne\", \"twork plumbing that the remote gRPC service\\ncan inherit and extend.\\n\\u2022 A client stub that contains th\", \"e required plumbing to invoke the remote gRPC service.\\nAt run time, each message is serialized as a \", \"standard Protobuf representation and exchanged between\\nthe client and remote service. Unlike JSON or\", \" XML, Protobuf messages are serialized as compiled\\nbinary bytes.\\nThe book, gRPC for WCF Developers, \", \"available from the Microsoft Architecture site, provides in-depth\\ncoverage of gRPC and Protocol Buff\", \"ers.\\ngRPC support in .NET\\ngRPC is integrated into .NET Core 3.0 SDK and later. The following tools s\", \"upport it:\\n\\u2022 Visual Studio 2022 with the ASP.NET and web development workload installed\\n\\u2022 Visual Stu\", \"dio Code\\n\\u2022 The dotnet CLI\\nThe SDK includes tooling for endpoint routing, built-in IoC, and logging. \", \"The open-source Kestrel web\\nserver supports HTTP/2 connections. Figure 4-20 shows a Visual Studio 20\", \"22 template that scaffolds a\\nskeleton project for a gRPC service. Note how .NET fully supports Windo\", \"ws, Linux, and macOS.\\n81 CHAPTER 4 | Cloud-native communication patternsFigure 4-20. gRPC support in\", \" Visual Studio 2022\\nFigure 4-21 shows the skeleton gRPC service generated from the built-in scaffold\", \"ing included in\\nVisual Studio 2022.\\nFigure 4-21. gRPC project in Visual Studio 2022\\nIn the previous \", \"figure, note the proto description file and service code. As you\\u2019ll see shortly, Visual\\nStudio gener\", \"ates additional configuration in both the Startup class and underlying project file.\\ngRPC usage\\nFavo\", \"r gRPC for the following scenarios:\\n\\u2022 Synchronous backend microservice-to-microservice communication\", \" where an immediate\\nresponse is required to continue processing.\\n\\u2022 Polyglot environments that need t\", \"o support mixed programming platforms.\\n\\u2022 Low latency and high throughput communication where perform\", \"ance is critical.\\n\\u2022 Point-to-point real-time communication - gRPC can push messages in real time wit\", \"hout\\npolling and has excellent support for bi-directional streaming.\\n82 CHAPTER 4 | Cloud-native com\", \"munication patterns\\u2022 Network constrained environments \\u2013 binary gRPC messages are always smaller than\", \" an\\nequivalent text-based JSON message.\\nAt the time, of this writing, gRPC is primarily used with ba\", \"ckend services. Modern browsers can\\u2019t\\nprovide the level of HTTP/2 control required to support a fron\", \"t-end gRPC client. That said, there\\u2019s\\nsupport for gRPC-Web with .NET that enables gRPC communication\", \" from browser-based apps built\\nwith JavaScript or Blazor WebAssembly technologies. gRPC-Web enables \", \"an ASP.NET Core gRPC app\\nto support gRPC features in browser apps:\\n\\u2022 Strongly typed, code-generated \", \"clients\\n\\u2022 Compact Protobuf messages\\n\\u2022 Server streaming\\ngRPC implementation\\nThe microservice referenc\", \"e architecture, eShop on Containers, from Microsoft, shows how to\\nimplement gRPC services in .NET ap\", \"plications. Figure 4-22 presents the back-end architecture.\\nFigure 4-22. Backend architecture for eS\", \"hop on Containers\\nIn the previous figure, note how eShop embraces the Backend for Frontends pattern \", \"(BFF) by\\nexposing multiple API gateways. We discussed the BFF pattern earlier in this chapter. Pay c\", \"lose\\n83 CHAPTER 4 | Cloud-native communication patternsattention to the Aggregator microservice (in \", \"gray) that sits between the Web-Shopping API Gateway\\nand backend Shopping microservices. The Aggrega\", \"tor receives a single request from a client,\\ndispatches it to various microservices, aggregates the \", \"results, and sends them back to the requesting\\nclient. Such operations typically require synchronous\", \" communication as to produce an immediate\\nresponse. In eShop, backend calls from the Aggregator are \", \"performed using gRPC as shown in Figure\\n4-23.\\nFigure 4-23. gRPC in eShop on Containers\\ngRPC communic\", \"ation requires both client and server components. In the previous figure, note how\\nthe Shopping Aggr\", \"egator implements a gRPC client. The client makes synchronous gRPC calls (in red)\\nto backend microse\", \"rvices, each of which implement a gRPC server. Both the client and server take\\nadvantage of the buil\", \"t-in gRPC plumbing from the .NET SDK. Client-side stubs provide the plumbing\\nto invoke remote gRPC c\", \"alls. Server-side components provide gRPC plumbing that custom service\\nclasses can inherit and consu\", \"me.\\nMicroservices that expose both a RESTful API and gRPC communication require multiple endpoints t\", \"o\\nmanage traffic. You would open an endpoint that listens for HTTP traffic for the RESTful calls and\", \"\\nanother for gRPC calls. The gRPC endpoint must be configured for the HTTP/2 protocol that is\\nrequir\", \"ed for gRPC communication.\\nWhile we strive to decouple microservices with asynchronous communication\", \" patterns, some\\noperations require direct calls. gRPC should be the primary choice for direct synchr\", \"onous\\ncommunication between microservices. Its high-performance communication protocol, based on\\nHTT\", \"P/2 and protocol buffers, make it a perfect choice.\\n84 CHAPTER 4 | Cloud-native communication patter\", \"nsLooking ahead\\nLooking ahead, gRPC will continue to gain traction for cloud-native systems. The per\", \"formance\\nbenefits and ease of development are compelling. However, REST will likely be around for a \", \"long time.\\nIt excels for publicly exposed APIs and for backward compatibility reasons.\\nService Mesh \", \"communication infrastructure\\nThroughout this chapter, we\\u2019ve explored the challenges of microservice \", \"communication. We said that\\ndevelopment teams need to be sensitive to how back-end services communic\", \"ate with each other.\\nIdeally, the less inter-service communication, the better. However, avoidance i\", \"sn\\u2019t always possible as\\nback-end services often rely on one another to complete operations.\\nWe explo\", \"red different approaches for implementing synchronous HTTP communication and\\nasynchronous messaging.\", \" In each of the cases, the developer is burdened with implementing\\ncommunication code. Communication\", \" code is complex and time intensive. Incorrect decisions can\\nlead to significant performance issues.\", \"\\nA more modern approach to microservice communication centers around a new and rapidly evolving\\ntech\", \"nology entitled Service Mesh. A service mesh is a configurable infrastructure layer with built-in\\nca\", \"pabilities to handle service-to-service communication, resiliency, and many cross-cutting concerns.\\n\", \"It moves the responsibility for these concerns out of the microservices and into service mesh layer.\", \"\\nCommunication is abstracted away from your microservices.\\nA key component of a service mesh is a pr\", \"oxy. In a cloud-native application, an instance of a proxy is\\ntypically colocated with each microser\", \"vice. While they execute in separate processes, the two are\\nclosely linked and share the same lifecy\", \"cle. This pattern, known as the Sidecar pattern, and is shown in\\nFigure 4-24.\\nFigure 4-24. Service m\", \"esh with a side car\\n85 CHAPTER 4 | Cloud-native communication patternsNote in the previous figure ho\", \"w messages are intercepted by a proxy that runs alongside each\\nmicroservice. Each proxy can be confi\", \"gured with traffic rules specific to the microservice. It\\nunderstands messages and can route them ac\", \"ross your services and the outside world.\\nAlong with managing service-to-service communication, the \", \"Service Mesh provides support for\\nservice discovery and load balancing.\\nOnce configured, a service m\", \"esh is highly functional. The mesh retrieves a corresponding pool of\\ninstances from a service discov\", \"ery endpoint. It sends a request to a specific service instance, recording\\nthe latency and response \", \"type of the result. It chooses the instance most likely to return a fast\\nresponse based on different\", \" factors, including the observed latency for recent requests.\\nA service mesh manages traffic, commun\", \"ication, and networking concerns at the application level. It\\nunderstands messages and requests. A s\", \"ervice mesh typically integrates with a container orchestrator.\\nKubernetes supports an extensible ar\", \"chitecture in which a service mesh can be added.\\nIn chapter 6, we deep-dive into Service Mesh techno\", \"logies including a discussion on its architecture\\nand available open-source implementations.\\nSummary\", \"\\nIn this chapter, we discussed cloud-native communication patterns. We started by examining how\\nfron\", \"t-end clients communicate with back-end microservices. Along the way, we talked about API\\nGateway pl\", \"atforms and real-time communication. We then looked at how microservices communicate\\nwith other back\", \"-end services. We looked at both synchronous HTTP communication and\\nasynchronous messaging across se\", \"rvices. We covered gRPC, an upcoming technology in the cloud-\\nnative world. Finally, we introduced a\", \" new and rapidly evolving technology entitled Service Mesh that\\ncan streamline microservice communic\", \"ation.\\nSpecial emphasis was on managed Azure services that can help implement communication in cloud\", \"-\\nnative systems:\\n\\u2022 Azure Application Gateway\\n\\u2022 Azure API Management\\n\\u2022 Azure SignalR Service\\n\\u2022 Azure\", \" Storage Queues\\n\\u2022 Azure Service Bus\\n\\u2022 Azure Event Grid\\n\\u2022 Azure Event Hub\\nWe next move to distributed\", \" data in cloud-native systems and the benefits and challenges that it\\npresents.\\nReferences\\n\\u2022 .NET Mi\", \"croservices: Architecture for Containerized .NET applications\\n\\u2022 Designing Interservice Communication\", \" for Microservices\\n\\u2022 Azure SignalR Service, a fully managed service to add real-time functionality\\n8\", \"6 CHAPTER 4 | Cloud-native communication patterns\\u2022 Azure API Gateway Ingress Controller\\n\\u2022 gRPC Docum\", \"entation\\n\\u2022 gRPC for WCF Developers\\n\\u2022 Comparing gRPC Services with HTTP APIs\\n\\u2022 Building gRPC Services\", \" with .NET video\\n87 CHAPTER 4 | Cloud-native communication patterns5\\nCHAPTER\\nCloud-native data patte\", \"rns\\nAs we\\u2019ve seen throughout this book, a cloud-native approach changes the way you design, deploy,\\n\", \"and manage applications. It also changes the way you manage and store data.\\nFigure 5-1 contrasts the\", \" differences.\\nFigure 5-1. Data management in cloud-native applications\\nExperienced developers will e\", \"asily recognize the architecture on the left-side of figure 5-1. In this\\nmonolithic application, bus\", \"iness service components collocate together in a shared services tier,\\nsharing data from a single re\", \"lational database.\\nIn many ways, a single database keeps data management simple. Querying data acros\", \"s multiple tables\\nis straightforward. Changes to data update together or they all rollback. ACID tra\", \"nsactions guarantee\\nstrong and immediate consistency.\\nDesigning for cloud-native, we take a differen\", \"t approach. On the right-side of Figure 5-1, note how\\nbusiness functionality segregates into small, \", \"independent microservices. Each microservice\\nencapsulates a specific business capability and its own\", \" data. The monolithic database decomposes\\n88 CHAPTER 5 | Cloud-native data patternsinto a distribute\", \"d data model with many smaller databases, each aligning with a microservice. When\\nthe smoke clears, \", \"we emerge with a design that exposes a database per microservice.\\nDatabase-per-microservice, why?\\nTh\", \"is database per microservice provides many benefits, especially for systems that must evolve rapidly\", \"\\nand support massive scale. With this model\\u2026\\n\\u2022 Domain data is encapsulated within the service\\n\\u2022 Data\", \" schema can evolve without directly impacting other services\\n\\u2022 Each data store can independently sca\", \"le\\n\\u2022 A data store failure in one service won\\u2019t directly impact other services\\nSegregating data also \", \"enables each microservice to implement the data store type that is best\\noptimized for its workload, \", \"storage needs, and read/write patterns. Choices include relational,\\ndocument, key-value, and even gr\", \"aph-based data stores.\\nFigure 5-2 presents the principle of polyglot persistence in a cloud-native s\", \"ystem.\\nFigure 5-2. Polyglot data persistence\\nNote in the previous figure how each microservice suppo\", \"rts a different type of data store.\\n\\u2022 The product catalog microservice consumes a relational databas\", \"e to accommodate the rich\\nrelational structure of its underlying data.\\n\\u2022 The shopping cart microserv\", \"ice consumes a distributed cache that supports its simple, key-\\nvalue data store.\\n\\u2022 The ordering mic\", \"roservice consumes both a NoSql document database for write operations\\nalong with a highly denormali\", \"zed key/value store to accommodate high-volumes of read\\noperations.\\n89 CHAPTER 5 | Cloud-native data\", \" patternsWhile relational databases remain relevant for microservices with complex data, NoSQL datab\", \"ases\\nhave gained considerable popularity. They provide massive scale and high availability. Their\\nsc\", \"hemaless nature allows developers to move away from an architecture of typed data classes and\\nORMs t\", \"hat make change expensive and time-consuming. We cover NoSQL databases later in this\\nchapter.\\nWhile \", \"encapsulating data into separate microservices can increase agility, performance, and scalability,\\ni\", \"t also presents many challenges. In the next section, we discuss these challenges along with pattern\", \"s\\nand practices to help overcome them.\\nCross-service queries\\nWhile microservices are independent and\", \" focus on specific functional capabilities, like inventory,\\nshipping, or ordering, they frequently r\", \"equire integration with other microservices. Often the\\nintegration involves one microservice queryin\", \"g another for data. Figure 5-3 shows the scenario.\\nFigure 5-3. Querying across microservices\\nIn the \", \"preceding figure, we see a shopping basket microservice that adds an item to a user\\u2019s shopping\\nbaske\", \"t. While the data store for this microservice contains basket and line item data, it doesn\\u2019t\\nmaintai\", \"n product or pricing data. Instead, those data items are owned by the catalog and pricing\\nmicroservi\", \"ces. This aspect presents a problem. How can the shopping basket microservice add a\\nproduct to the u\", \"ser\\u2019s shopping basket when it doesn\\u2019t have product nor pricing data in its database?\\nOne option disc\", \"ussed in Chapter 4 is a direct HTTP call from the shopping basket to the catalog and\\npricing microse\", \"rvices. However, in chapter 4, we said synchronous HTTP calls couple microservices\\ntogether, reducin\", \"g their autonomy and diminishing their architectural benefits.\\nWe could also implement a request-rep\", \"ly pattern with separate inbound and outbound queues for\\neach service. However, this pattern is comp\", \"licated and requires plumbing to correlate request and\\nresponse messages. While it does decouple the\", \" backend microservice calls, the calling service must\\nstill synchronously wait for the call to compl\", \"ete. Network congestion, transient faults, or an\\noverloaded microservice and can result in long-runn\", \"ing and even failed operations.\\n90 CHAPTER 5 | Cloud-native data patternsInstead, a widely accepted \", \"pattern for removing cross-service dependencies is the Materialized View\\nPattern, shown in Figure 5-\", \"4.\\nFigure 5-4. Materialized View Pattern\\nWith this pattern, you place a local data table (known as a\", \" read model) in the shopping basket service.\\nThis table contains a denormalized copy of the data nee\", \"ded from the product and pricing\\nmicroservices. Copying the data directly into the shopping basket m\", \"icroservice eliminates the need for\\nexpensive cross-service calls. With the data local to the servic\", \"e, you improve the service\\u2019s response\\ntime and reliability. Additionally, having its own copy of the\", \" data makes the shopping basket service\\nmore resilient. If the catalog service should become unavail\", \"able, it wouldn\\u2019t directly impact the\\nshopping basket service. The shopping basket can continue oper\", \"ating with the data from its own\\nstore.\\nThe catch with this approach is that you now have duplicate \", \"data in your system. However,\\nstrategically duplicating data in cloud-native systems is an establish\", \"ed practice and not considered an\\nanti-pattern, or bad practice. Keep in mind that one and only one \", \"service can own a data set and have\\nauthority over it. You\\u2019ll need to synchronize the read models wh\", \"en the system of record is updated.\\nSynchronization is typically implemented via asynchronous messag\", \"ing with a publish/subscribe\\npattern, as shown in Figure 5.4.\\nDistributed transactions\\nWhile queryin\", \"g data across microservices is difficult, implementing a transaction across several\\nmicroservices is\", \" even more complex. The inherent challenge of maintaining data consistency across\\nindependent data s\", \"ources in different microservices can\\u2019t be understated. The lack of distributed\\ntransactions in clou\", \"d-native applications means that you must manage distributed transactions\\nprogrammatically. You move\", \" from a world of immediate consistency to that of eventual consistency.\\nFigure 5-5 shows the problem\", \".\\n91 CHAPTER 5 | Cloud-native data patternsFigure 5-5. Implementing a transaction across microservic\", \"es\\nIn the preceding figure, five independent microservices participate in a distributed transaction \", \"that\\ncreates an order. Each microservice maintains its own data store and implements a local transac\", \"tion\\nfor its store. To create the order, the local transaction for each individual microservice must\", \" succeed,\\nor all must abort and roll back the operation. While built-in transactional support is ava\", \"ilable inside\\neach of the microservices, there\\u2019s no support for a distributed transaction that would\", \" span across all\\nfive services to keep data consistent.\\nInstead, you must construct this distributed\", \" transaction programmatically.\\nA popular pattern for adding distributed transactional support is the\", \" Saga pattern. It\\u2019s implemented\\nby grouping local transactions together programmatically and sequent\", \"ially invoking each one. If any\\nof the local transactions fail, the Saga aborts the operation and in\", \"vokes a set of compensating\\ntransactions. The compensating transactions undo the changes made by the\", \" preceding local\\ntransactions and restore data consistency. Figure 5-6 shows a failed transaction wi\", \"th the Saga pattern.\\nFigure 5-6. Rolling back a transaction\\n92 CHAPTER 5 | Cloud-native data pattern\", \"sIn the previous figure, the Update Inventory operation has failed in the Inventory microservice. Th\", \"e\\nSaga invokes a set of compensating transactions (in red) to adjust the inventory counts, cancel th\", \"e\\npayment and the order, and return the data for each microservice back to a consistent state.\\nSaga \", \"patterns are typically choreographed as a series of related events, or orchestrated as a set of\\nrela\", \"ted commands. In Chapter 4, we discussed the service aggregator pattern that would be the\\nfoundation\", \" for an orchestrated saga implementation. We also discussed eventing along with Azure\\nService Bus an\", \"d Azure Event Grid topics that would be a foundation for a choreographed saga\\nimplementation.\\nHigh v\", \"olume data\\nLarge cloud-native applications often support high-volume data requirements. In these sce\", \"narios,\\ntraditional data storage techniques can cause bottlenecks. For complex systems that deploy o\", \"n a large\\nscale, both Command and Query Responsibility Segregation (CQRS) and Event Sourcing may imp\", \"rove\\napplication performance.\\nCQRS\\nCQRS, is an architectural pattern that can help maximize performa\", \"nce, scalability, and security. The\\npattern separates operations that read data from those operation\", \"s that write data.\\nFor normal scenarios, the same entity model and data repository object are used f\", \"or both read and\\nwrite operations.\\nHowever, a high volume data scenario can benefit from separate mo\", \"dels and data tables for reads\\nand writes. To improve performance, the read operation could query ag\", \"ainst a highly denormalized\\nrepresentation of the data to avoid expensive repetitive table joins and\", \" table locks. The write\\noperation, known as a command, would update against a fully normalized repre\", \"sentation of the data\\nthat would guarantee consistency. You then need to implement a mechanism to ke\", \"ep both\\nrepresentations in sync. Typically, whenever the write table is modified, it publishes an ev\", \"ent that\\nreplicates the modification to the read table.\\nFigure 5-7 shows an implementation of the CQ\", \"RS pattern.\\nFigure 5-7. CQRS implementation\\n93 CHAPTER 5 | Cloud-native data patternsIn the previous\", \" figure, separate command and query models are implemented. Each data write\\noperation is saved to th\", \"e write store and then propagated to the read store. Pay close attention to\\nhow the data propagation\", \" process operates on the principle of eventual consistency. The read model\\neventually synchronizes w\", \"ith the write model, but there may be some lag in the process. We discuss\\neventual consistency in th\", \"e next section.\\nThis separation enables reads and writes to scale independently. Read operations use\", \" a schema\\noptimized for queries, while the writes use a schema optimized for updates. Read queries g\", \"o against\\ndenormalized data, while complex business logic can be applied to the write model. As well\", \", you\\nmight impose tighter security on write operations than those exposing reads.\\nImplementing CQRS\", \" can improve application performance for cloud-native services. However, it does\\nresult in a more co\", \"mplex design. Apply this principle carefully and strategically to those sections of\\nyour cloud-nativ\", \"e application that will benefit from it. For more on CQRS, see the Microsoft book .NET\\nMicroservices\", \": Architecture for Containerized .NET Applications.\\nEvent sourcing\\nAnother approach to optimizing hi\", \"gh volume data scenarios involves Event Sourcing.\\nA system typically stores the current state of a d\", \"ata entity. If a user changes their phone number, for\\nexample, the customer record is updated with t\", \"he new number. We always know the current state of a\\ndata entity, but each update overwrites the pre\", \"vious state.\\nIn most cases, this model works fine. In high volume systems, however, overhead from tr\", \"ansactional\\nlocking and frequent update operations can impact database performance, responsiveness, \", \"and limit\\nscalability.\\nEvent Sourcing takes a different approach to capturing data. Each operation t\", \"hat affects data is\\npersisted to an event store. Instead of updating the state of a data record, we \", \"append each change to\\na sequential list of past events - similar to an accountant\\u2019s ledger. The Even\", \"t Store becomes the\\nsystem of record for the data. It\\u2019s used to propagate various materialized views\", \" within the bounded\\ncontext of a microservice. Figure 5.8 shows the pattern.\\n94 CHAPTER 5 | Cloud-na\", \"tive data patternsFigure 5-8. Event Sourcing\\nIn the previous figure, note how each entry (in blue) f\", \"or a user\\u2019s shopping cart is appended to an\\nunderlying event store. In the adjoining materialized vi\", \"ew, the system projects the current state by\\nreplaying all the events associated with each shopping \", \"cart. This view, or read model, is then exposed\\nback to the UI. Events can also be integrated with e\", \"xternal systems and applications or queried to\\ndetermine the current state of an entity. With this a\", \"pproach, you maintain history. You know not only\\nthe current state of an entity, but also how you re\", \"ached this state.\\nMechanically speaking, event sourcing simplifies the write model. There are no upd\", \"ates or deletes.\\nAppending each data entry as an immutable event minimizes contention, locking, and \", \"concurrency\\nconflicts associated with relational databases. Building read models with the materializ\", \"ed view pattern\\nenables you to decouple the view from the write model and choose the best data store\", \" to optimize\\nthe needs of your application UI.\\nFor this pattern, consider a data store that directly\", \" supports event sourcing. Azure Cosmos DB,\\nMongoDB, Cassandra, CouchDB, and RavenDB are good candida\", \"tes.\\nAs with all patterns and technologies, implement strategically and when needed. While event sou\", \"rcing\\ncan provide increased performance and scalability, it comes at the expense of complexity and a\", \"\\nlearning curve.\\n95 CHAPTER 5 | Cloud-native data patternsRelational vs. NoSQL data\\nRelational and N\", \"oSQL are two types of database systems commonly implemented in cloud-native\\napps. They\\u2019re built diff\", \"erently, store data differently, and accessed differently. In this section, we\\u2019ll look\\nat both. Late\", \"r in this chapter, we\\u2019ll look at an emerging database technology called NewSQL.\\nRelational databases\", \" have been a prevalent technology for decades. They\\u2019re mature, proven, and\\nwidely implemented. Compe\", \"ting database products, tooling, and expertise abound. Relational\\ndatabases provide a store of relat\", \"ed data tables. These tables have a fixed schema, use SQL\\n(Structured Query Language) to manage data\", \", and support ACID guarantees.\\nNo-SQL databases refer to high-performance, non-relational data store\", \"s. They excel in their ease-of-\\nuse, scalability, resilience, and availability characteristics. Inst\", \"ead of joining tables of normalized data,\\nNoSQL stores unstructured or semi-structured data, often i\", \"n key-value pairs or JSON documents. No-\\nSQL databases typically don\\u2019t provide ACID guarantees beyon\", \"d the scope of a single database\\npartition. High volume services that require sub second response ti\", \"me favor NoSQL datastores.\\nThe impact of NoSQL technologies for distributed cloud-native systems can\", \"\\u2019t be overstated. The\\nproliferation of new data technologies in this space has disrupted solutions t\", \"hat once exclusively\\nrelied on relational databases.\\nNoSQL databases include several different model\", \"s for accessing and managing data, each suited to\\nspecific use cases. Figure 5-9 presents four commo\", \"n models.\\nFigure 5-9: Data models for NoSQL databases\\nModel Characteristics\\nDocument Store Data and \", \"metadata are stored hierarchically in\\nJSON-based documents inside the database.\\nKey Value Store The \", \"simplest of the NoSQL databases, data is\\nrepresented as a collection of key-value pairs.\\nWide-Column\", \" Store Related data is stored as a set of nested-\\nkey/value pairs within a single column.\\nGraph Stor\", \"e Data is stored in a graph structure as node,\\nedge, and data properties.\\n96 CHAPTER 5 | Cloud-nativ\", \"e data patternsThe CAP theorem\\nAs a way to understand the differences between these types of databas\", \"es, consider the CAP theorem,\\na set of principles applied to distributed systems that store state. F\", \"igure 5-10 shows the three\\nproperties of the CAP theorem.\\nFigure 5-10. The CAP theorem\\nThe theorem s\", \"tates that distributed data systems will offer a trade-off between consistency,\\navailability, and pa\", \"rtition tolerance. And, that any database can only guarantee two of the three\\nproperties:\\n\\u2022 Consiste\", \"ncy. Every node in the cluster responds with the most recent data, even if the system\\nmust block the\", \" request until all replicas update. If you query a \\u201cconsistent system\\u201d for an item\\nthat is currently\", \" updating, you\\u2019ll wait for that response until all replicas successfully update.\\nHowever, you\\u2019ll rec\", \"eive the most current data.\\n\\u2022 Availability. Every node returns an immediate response, even if that r\", \"esponse isn\\u2019t the most\\nrecent data. If you query an \\u201cavailable system\\u201d for an item that is updating,\", \" you\\u2019ll get the best\\npossible answer the service can provide at that moment.\\n\\u2022 Partition Tolerance. \", \"Guarantees the system continues to operate even if a replicated data\\nnode fails or loses connectivit\", \"y with other replicated data nodes.\\nCAP theorem explains the tradeoffs associated with managing cons\", \"istency and availability during a\\nnetwork partition; however tradeoffs with respect to consistency a\", \"nd performance also exist with the\\nabsence of a network partition. CAP theorem is often further exte\", \"nded to PACELC to explain the\\ntradeoffs more comprehensively.\\nRelational databases typically provide\", \" consistency and availability, but not partition tolerance. They\\u2019re\\ntypically provisioned to a singl\", \"e server and scale vertically by adding more resources to the machine.\\n97 CHAPTER 5 | Cloud-native d\", \"ata patternsMany relational database systems support built-in replication features where copies of t\", \"he primary\\ndatabase can be made to other secondary server instances. Write operations are made to th\", \"e primary\\ninstance and replicated to each of the secondaries. Upon a failure, the primary instance c\", \"an fail over\\nto a secondary to provide high availability. Secondaries can also be used to distribute\", \" read operations.\\nWhile writes operations always go against the primary replica, read operations can\", \" be routed to any of\\nthe secondaries to reduce system load.\\nData can also be horizontally partitione\", \"d across multiple nodes, such as with sharding. But, sharding\\ndramatically increases operational ove\", \"rhead by spitting data across many pieces that cannot easily\\ncommunicate. It can be costly and time \", \"consuming to manage. Relational features that include table\\njoins, transactions, and referential int\", \"egrity require steep performance penalties in sharded\\ndeployments.\\nReplication consistency and recov\", \"ery point objectives can be tuned by configuring whether replication\\noccurs synchronously or asynchr\", \"onously. If data replicas were to lose network connectivity in a \\u201chighly\\nconsistent\\u201d or synchronous \", \"relational database cluster, you wouldn\\u2019t be able to write to the database.\\nThe system would reject \", \"the write operation as it can\\u2019t replicate that change to the other data replica.\\nEvery data replica \", \"has to update before the transaction can complete.\\nNoSQL databases typically support high availabili\", \"ty and partition tolerance. They scale out\\nhorizontally, often across commodity servers. This approa\", \"ch provides tremendous availability, both\\nwithin and across geographical regions at a reduced cost. \", \"You partition and replicate data across\\nthese machines, or nodes, providing redundancy and fault tol\", \"erance. Consistency is typically tuned\\nthrough consensus protocols or quorum mechanisms. They provid\", \"e more control when navigating\\ntradeoffs between tuning synchronous versus asynchronous replication \", \"in relational systems.\\nIf data replicas were to lose connectivity in a \\u201chighly available\\u201d NoSQL data\", \"base cluster, you could still\\ncomplete a write operation to the database. The database cluster would\", \" allow the write operation and\\nupdate each data replica as it becomes available. NoSQL databases tha\", \"t support multiple writable\\nreplicas can further strengthen high availability by avoiding the need f\", \"or failover when optimizing\\nrecovery time objective.\\nModern NoSQL databases typically implement part\", \"itioning capabilities as a feature of their system\\ndesign. Partition management is often built-in to\", \" the database, and routing is achieved through\\nplacement hints - often called partition keys. A flex\", \"ible data models enables the NoSQL databases to\\nlower the burden of schema management and improve av\", \"ailability when deploying application\\nupdates that require data model changes.\\nHigh availability and\", \" massive scalability are often more critical to the business than relational table\\njoins and referen\", \"tial integrity. Developers can implement techniques and patterns such as Sagas,\\nCQRS, and asynchrono\", \"us messaging to embrace eventual consistency.\\nNowadays, care must be taken when considering the CAP \", \"theorem constraints. A new type of\\ndatabase, called NewSQL, has emerged which extends the relational\", \" database engine to support both\\nhorizontal scalability and the scalable performance of NoSQL system\", \"s.\\n98 CHAPTER 5 | Cloud-native data patternsConsiderations for relational vs. NoSQL systems\\nBased up\", \"on specific data requirements, a cloud-native-based microservice can implement a relational,\\nNoSQL d\", \"atastore or both.\\nConsider a NoSQL datastore when: Consider a relational database when:\\nYou have hig\", \"h volume workloads that require Your workload volume generally fits within\\npredictable latency at la\", \"rge scale (for example, thousands of transactions per second\\nlatency measured in milliseconds while\\n\", \"performing millions of transactions per second)\\nYour data is dynamic and frequently changes Your dat\", \"a is highly structured and requires\\nreferential integrity\\nRelationships can be de-normalized data Re\", \"lationships are expressed through table joins\\nmodels on normalized data models\\nData retrieval is sim\", \"ple and expressed without You work with complex queries and reports\\ntable joins\\nData is typically re\", \"plicated across geographies Data is typically centralized, or can be replicated\\nand requires finer c\", \"ontrol over consistency, regions asynchronously\\navailability, and performance\\nYour application will \", \"be deployed to commodity Your application will be deployed to large, high-\\nhardware, such as with pu\", \"blic clouds end hardware\\nIn the next sections, we\\u2019ll explore the options available in the Azure clou\", \"d for storing and managing\\nyour cloud-native data.\\nDatabase as a Service\\nTo start, you could provisi\", \"on an Azure virtual machine and install your database of choice for each\\nservice. While you\\u2019d have f\", \"ull control over the environment, you\\u2019d forgo many built-in features of the\\ncloud platform. You\\u2019d al\", \"so be responsible for managing the virtual machine and database for each\\nservice. This approach coul\", \"d quickly become time-consuming and expensive.\\nInstead, cloud-native applications favor data service\", \"s exposed as a Database as a Service (DBaaS).\\nFully managed by a cloud vendor, these services provid\", \"e built-in security, scalability, and monitoring.\\nInstead of owning the service, you simply consume \", \"it as a backing service. The provider operates the\\nresource at scale and bears the responsibility fo\", \"r performance and maintenance.\\nThey can be configured across cloud availability zones and regions to\", \" achieve high availability. They\\nall support just-in-time capacity and a pay-as-you-go model. Azure \", \"features different kinds of\\nmanaged data service options, each with specific benefits.\\nWe\\u2019ll first l\", \"ook at relational DBaaS services available in Azure. You\\u2019ll see that Microsoft\\u2019s flagship SQL\\nServer\", \" database is available along with several open-source options. Then, we\\u2019ll talk about the NoSQL\\ndata\", \" services in Azure.\\n99 CHAPTER 5 | Cloud-native data patternsAzure relational databases\\nFor cloud-na\", \"tive microservices that require relational data, Azure offers four managed relational\\ndatabases as a\", \" service (DBaaS) offerings, shown in Figure 5-11.\\nFigure 5-11. Managed relational databases availabl\", \"e in Azure\\nIn the previous figure, note how each sits upon a common DBaaS infrastructure which featu\", \"res key\\ncapabilities at no additional cost.\\nThese features are especially important to organizations\", \" who provision large numbers of databases,\\nbut have limited resources to administer them. You can pr\", \"ovision an Azure database in minutes by\\nselecting the amount of processing cores, memory, and underl\", \"ying storage. You can scale the\\ndatabase on-the-fly and dynamically adjust resources with little to \", \"no downtime.\\nAzure SQL Database\\nDevelopment teams with expertise in Microsoft SQL Server should cons\", \"ider Azure SQL Database. It\\u2019s a\\nfully managed relational database-as-a-service (DBaaS) based on the \", \"Microsoft SQL Server Database\\nEngine. The service shares many features found in the on-premises vers\", \"ion of SQL Server and runs the\\nlatest stable version of the SQL Server Database Engine.\\nFor use with\", \" a cloud-native microservice, Azure SQL Database is available with three deployment\\noptions:\\n\\u2022 A Sin\", \"gle Database represents a fully managed SQL Database running on an Azure SQL\\nDatabase server in the \", \"Azure cloud. The database is considered contained as it has no\\nconfiguration dependencies on the und\", \"erlying database server.\\n\\u2022 A Managed Instance is a fully managed instance of the Microsoft SQL Serve\", \"r Database Engine\\nthat provides near-100% compatibility with an on-premises SQL Server. This option \", \"supports\\nlarger databases, up to 35 TB and is placed in an Azure Virtual Network for better isolatio\", \"n.\\n100 CHAPTER 5 | Cloud-native data patterns\\u2022 Azure SQL Database serverless is a compute tier for a\", \" single database that automatically\\nscales based on workload demand. It bills only for the amount of\", \" compute used per second.\\nThe service is well suited for workloads with intermittent, unpredictable \", \"usage patterns,\\ninterspersed with periods of inactivity. The serverless compute tier also automatica\", \"lly pauses\\ndatabases during inactive periods so that only storage charges are billed. It automatical\", \"ly\\nresumes when activity returns.\\nBeyond the traditional Microsoft SQL Server stack, Azure also feat\", \"ures managed versions of three\\npopular open-source databases.\\nOpen-source databases in Azure\\nOpen-so\", \"urce relational databases have become a popular choice for cloud-native applications. Many\\nenterpris\", \"es favor them over commercial database products, especially for cost savings. Many\\ndevelopment teams\", \" enjoy their flexibility, community-backed development, and ecosystem of tools\\nand extensions. Open-\", \"source databases can be deployed across multiple cloud providers, helping\\nminimize the concern of \\u201cv\", \"endor lock-in.\\u201d\\nDevelopers can easily self-host any open-source database on an Azure VM. While provi\", \"ding full\\ncontrol, this approach puts you on the hook for the management, monitoring, and maintenanc\", \"e of\\nthe database and VM.\\nHowever, Microsoft continues its commitment to keeping Azure an \\u201copen plat\", \"form\\u201d by offering\\nseveral popular open-source databases as fully managed DBaaS services.\\nAzure Datab\", \"ase for MySQL\\nMySQL is an open-source relational database and a pillar for applications built on the\", \" LAMP software\\nstack. Widely chosen for read heavy workloads, it\\u2019s used by many large organizations,\", \" including\\nFacebook, Twitter, and YouTube. The community edition is available for free, while the en\", \"terprise\\nedition requires a license purchase. Originally created in 1995, the product was purchased \", \"by Sun\\nMicrosystems in 2008. Oracle acquired Sun and MySQL in 2010.\\nAzure Database for MySQL is a ma\", \"naged relational database service based on the open-source\\nMySQL Server engine. It uses the MySQL Co\", \"mmunity edition. The Azure MySQL server is the\\nadministrative point for the service. It\\u2019s the same M\", \"ySQL server engine used for on-premises\\ndeployments. The engine can create a single database per ser\", \"ver or multiple databases per server that\\nshare resources. You can continue to manage data using the\", \" same open-source tools without having\\nto learn new skills or manage virtual machines.\\nAzure Databas\", \"e for MariaDB\\nMariaDB Server is another popular open-source database server. It was created as a for\", \"k of MySQL\\nwhen Oracle purchased Sun Microsystems, who owned MySQL. The intent was to ensure that Ma\", \"riaDB\\nremained open-source. As MariaDB is a fork of MySQL, the data and table definitions are compat\", \"ible,\\nand the client protocols, structures, and APIs, are close-knit.\\n101 CHAPTER 5 | Cloud-native d\", \"ata patternsMariaDB has a strong community and is used by many large enterprises. While Oracle conti\", \"nues to\\nmaintain, enhance, and support MySQL, the MariaDB foundation manages MariaDB, allowing publi\", \"c\\ncontributions to the product and documentation.\\nAzure Database for MariaDB is a fully managed rela\", \"tional database as a service in the Azure cloud. The\\nservice is based on the MariaDB community editi\", \"on server engine. It can handle mission-critical\\nworkloads with predictable performance and dynamic \", \"scalability.\\nAzure Database for PostgreSQL\\nPostgreSQL is an open-source relational database with ove\", \"r 30 years of active development.\\nPostgreSQL has a strong reputation for reliability and data integr\", \"ity. It\\u2019s feature rich, SQL compliant,\\nand considered more performant than MySQL - especially for wo\", \"rkloads with complex queries and\\nheavy writes. Many large enterprises including Apple, Red Hat, and \", \"Fujitsu have built products using\\nPostgreSQL.\\nAzure Database for PostgreSQL is a fully managed relat\", \"ional database service, based on the open-\\nsource Postgres database engine. The service supports man\", \"y development platforms, including C++,\\nJava, Python, Node, C#, and PHP. You can migrate PostgreSQL \", \"databases to it using the command-\\nline interface tool or Azure Data Migration Service.\\nAzure Databa\", \"se for PostgreSQL is available with two deployment options:\\n\\u2022 The Single Server deployment option is\", \" a central administrative point for multiple databases\\nto which you can deploy many databases. The p\", \"ricing is structured per-server based upon\\ncores and storage.\\n\\u2022 The Hyperscale (Citus) option is pow\", \"ered by Citus Data technology. It enables high\\nperformance by horizontally scaling a single database\", \" across hundreds of nodes to deliver fast\\nperformance and scale. This option allows the engine to fi\", \"t more data in memory, parallelize\\nqueries across hundreds of nodes, and index data faster.\\nNoSQL da\", \"ta in Azure\\nCosmos DB is a fully managed, globally distributed NoSQL database service in the Azure c\", \"loud. It has\\nbeen adopted by many large companies across the world, including Coca-Cola, Skype, Exxo\", \"nMobil,\\nand Liberty Mutual.\\nIf your services require fast response from anywhere in the world, high \", \"availability, or elastic\\nscalability, Cosmos DB is a great choice. Figure 5-12 shows Cosmos DB.\\n102 \", \"CHAPTER 5 | Cloud-native data patternsFigure 5-12: Overview of Azure Cosmos DB\\nThe previous figure p\", \"resents many of the built-in cloud-native capabilities available in Cosmos DB. In\\nthis section, we\\u2019l\", \"l take a closer look at them.\\nGlobal support\\nCloud-native applications often have a global audience \", \"and require global scale.\\nYou can distribute Cosmos databases across regions or around the world, pl\", \"acing data close to your\\nusers, improving response time, and reducing latency. You can add or remove\", \" a database from a\\nregion without pausing or redeploying your services. In the background, Cosmos DB\", \" transparently\\nreplicates the data to each of the configured regions.\\nCosmos DB supports active/acti\", \"ve clustering at the global level, enabling you to configure any of your\\ndatabase regions to support\", \" both writes and reads.\\nThe Multi-region write protocol is an important feature in Cosmos DB that en\", \"ables the following\\nfunctionality:\\n\\u2022 Unlimited elastic write and read scalability.\\n\\u2022 99.999% read an\", \"d write availability all around the world.\\n\\u2022 Guaranteed reads and writes served in less than 10 mill\", \"iseconds at the 99th percentile.\\nWith the Cosmos DB Multi-Homing APIs, your microservice is automati\", \"cally aware of the nearest\\nAzure region and sends requests to it. The nearest region is identified b\", \"y Cosmos DB without any\\nconfiguration changes. Should a region become unavailable, the Multi-Homing \", \"feature will\\nautomatically route requests to the next nearest available region.\\nMulti-model support\\n\", \"When replatforming monolithic applications to a cloud-native architecture, development teams\\nsometim\", \"es have to migrate open-source, NoSQL data stores. Cosmos DB can help you preserve your\\n103 CHAPTER \", \"5 | Cloud-native data patternsinvestment in these NoSQL datastores with its multi-model data platfor\", \"m. The following table shows\\nthe supported NoSQL compatibility APIs.\\nProvider Description\\nNoSQL API \", \"API for NoSQL stores data in document format\\nMongo DB API Supports Mongo DB APIs and JSON documents\\n\", \"Gremlin API Supports Gremlin API with graph-based nodes\\nand edge data representations\\nCassandra API \", \"Supports Casandra API for wide-column data\\nrepresentations\\nTable API Supports Azure Table Storage wi\", \"th premium\\nenhancements\\nPostgreSQL API Managed service for running PostgreSQL at any\\nscale\\nDevelopme\", \"nt teams can migrate existing Mongo, Gremlin, or Cassandra databases into Cosmos DB\\nwith minimal cha\", \"nges to data or code. For new apps, development teams can choose among open-\\nsource options or the b\", \"uilt-in SQL API model.\\nInternally, Cosmos stores the data in a simple struct format made up of primi\", \"tive data types. For each\\nrequest, the database engine translates the primitive data into the model \", \"representation you\\u2019ve\\nselected.\\nIn the previous table, note the Table API option. This API is an evo\", \"lution of Azure Table Storage. Both\\nshare the same underlying table model, but the Cosmos DB Table A\", \"PI adds premium enhancements\\nnot available in the Azure Storage API. The following table contrasts t\", \"he features.\\nFeature Azure Table Storage Azure Cosmos DB\\nLatency Fast Single-digit millisecond laten\", \"cy for reads and\\nwrites anywhere in the world\\nThroughp Limit of 20,000 operations per table Unlimite\", \"d operations per table\\nut\\nGlobal Single region with optional single Turnkey distributions to all reg\", \"ions with\\nDistributio secondary read region automatic failover\\nn\\nIndexing Available for partition an\", \"d row key Automatic indexing of all properties\\nproperties only\\nPricing Optimized for cold workloads \", \"(low Optimized for hot workloads (high\\nthroughput : storage ratio) throughput : storage ratio)\\nMicro\", \"services that consume Azure Table storage can easily migrate to the Cosmos DB Table API. No\\ncode cha\", \"nges are required.\\n104 CHAPTER 5 | Cloud-native data patternsTunable consistency\\nEarlier in the Rela\", \"tional vs. NoSQL section, we discussed the subject of data consistency. Data\\nconsistency refers to t\", \"he integrity of your data. Cloud-native services with distributed data rely on\\nreplication and must \", \"make a fundamental tradeoff between read consistency, availability, and latency.\\nMost distributed da\", \"tabases allow developers to choose between two consistency\\nmodels: strong consistency and eventual c\", \"onsistency. Strong consistency is the gold standard of data\\nprogrammability. It guarantees that a qu\", \"ery will always return the most current data - even if the\\nsystem must incur latency waiting for an \", \"update to replicate across all database copies. While a\\ndatabase configured for eventual consistency\", \" will return data immediately, even if that data isn\\u2019t the\\nmost current copy. The latter option enab\", \"les higher availability, greater scale, and increased\\nperformance.\\nAzure Cosmos DB offers five well-\", \"defined consistency models shown in Figure 5-13.\\nFigure 5-13: Cosmos DB Consistency Levels\\nThese opt\", \"ions enable you to make precise choices and granular tradeoffs for consistency, availability,\\nand th\", \"e performance for your data. The levels are presented in the following table.\\nConsistency Level Desc\", \"ription\\nEventual No ordering guarantee for reads. Replicas will\\neventually converge.\\nConstant Prefix\", \" Reads are still eventual, but data is returned in\\nthe ordering in which it is written.\\nSession Guar\", \"antees you can read any data written\\nduring the current session. It is the default\\nconsistency level\", \".\\nBounded Staleness Reads trail writes by interval that you specify.\\nStrong Reads are guaranteed to \", \"return most recent\\ncommitted version of an item. A client never\\nsees an uncommitted or partial read.\", \"\\nIn the article Getting Behind the 9-Ball: Cosmos DB Consistency Levels Explained, Microsoft Program\", \"\\nManager Jeremy Likness provides an excellent explanation of the five models.\\nPartitioning\\nAzure Cos\", \"mos DB embraces automatic partitioning to scale a database to meet the performance\\nneeds of your clo\", \"ud-native services.\\nYou manage data in Cosmos DB data by creating databases, containers, and items.\\n\", \"105 CHAPTER 5 | Cloud-native data patternsContainers live in a Cosmos DB database and represent a sc\", \"hema-agnostic grouping of items. Items\\nare the data that you add to the container. They\\u2019re represent\", \"ed as documents, rows, nodes, or edges.\\nAll items added to a container are automatically indexed.\\nTo\", \" partition the container, items are divided into distinct subsets called logical partitions. Logical\", \"\\npartitions are populated based on the value of a partition key that is associated with each item in\", \" a\\ncontainer. Figure 5-14 shows two containers each with a logical partition based on a partition ke\", \"y\\nvalue.\\nFigure 5-14: Cosmos DB partitioning mechanics\\nNote in the previous figure how each item inc\", \"ludes a partition key of either \\u2018city\\u2019 or \\u2018airport\\u2019. The key\\ndetermines the item\\u2019s logical partition\", \". Items with a city code are assigned to the container on the left,\\nand items with an airport code, \", \"to the container on the right. Combining the partition key value with\\nthe ID value creates an item\\u2019s\", \" index, which uniquely identifies the item.\\nInternally, Cosmos DB automatically manages the placemen\", \"t of logical partitions on physical\\npartitions to satisfy the scalability and performance needs of t\", \"he container. As application throughput\\nand storage requirements increase, Azure Cosmos DB redistrib\", \"utes logical partitions across a greater\\nnumber of servers. Redistribution operations are managed by\", \" Cosmos DB and invoked without\\ninterruption or downtime.\\nNewSQL databases\\nNewSQL is an emerging data\", \"base technology that combines the distributed scalability of NoSQL with\\nthe ACID guarantees of a rel\", \"ational database. NewSQL databases are important for business systems\\nthat must process high-volumes\", \" of data, across distributed environments, with full transactional\\nsupport and ACID compliance. Whil\", \"e a NoSQL database can provide massive scalability, it does not\\nguarantee data consistency. Intermit\", \"tent problems from inconsistent data can place a burden on the\\ndevelopment team. Developers must con\", \"struct safeguards into their microservice code to manage\\nproblems caused by inconsistent data.\\nThe C\", \"loud Native Computing Foundation (CNCF) features several NewSQL database projects.\\n106 CHAPTER 5 | C\", \"loud-native data patternsProject Characteristics\\nCockroach DB An ACID-compliant, relational database\", \" that\\nscales globally. Add a new node to a cluster and\\nCockroachDB takes care of balancing the data\\n\", \"across instances and geographies. It creates,\\nmanages, and distributes replicas to ensure\\nreliabilit\", \"y. It\\u2019s open source and freely available.\\nTiDB An open-source database that supports Hybrid\\nTransact\", \"ional and Analytical Processing (HTAP)\\nworkloads. It is MySQL-compatible and features\\nhorizontal sca\", \"lability, strong consistency, and\\nhigh availability. TiDB acts like a MySQL server.\\nYou can continue\", \" to use existing MySQL client\\nlibraries, without requiring extensive code\\nchanges to your applicatio\", \"n.\\nYugabyteDB An open source, high-performance, distributed\\nSQL database. It supports low query late\", \"ncy,\\nresilience against failures, and global data\\ndistribution. YugabyteDB is PostgreSQL-\\ncompatible\", \" and handles scale-out RDBMS and\\ninternet-scale OLTP workloads. The product also\\nsupports NoSQL and \", \"is compatible with\\nCassandra.\\nVitess Vitess is a database solution for deploying,\\nscaling, and manag\", \"ing large clusters of MySQL\\ninstances. It can run in a public or private cloud\\narchitecture. Vitess \", \"combines and extends many\\nimportant MySQL features and features both\\nvertical and horizontal shardin\", \"g support.\\nOriginated by YouTube, Vitess has been serving\\nall YouTube database traffic since 2011.\\nT\", \"he open-source projects in the previous figure are available from the Cloud Native Computing\\nFoundat\", \"ion. Three of the offerings are full database products, which include .NET support. The other,\\nVites\", \"s, is a database clustering system that horizontally scales large clusters of MySQL instances.\\nA key\", \" design goal for NewSQL databases is to work natively in Kubernetes, taking advantage of the\\nplatfor\", \"m\\u2019s resiliency and scalability.\\nNewSQL databases are designed to thrive in ephemeral cloud environme\", \"nts where underlying virtual\\nmachines can be restarted or rescheduled at a moment\\u2019s notice. The data\", \"bases are designed to\\nsurvive node failures without data loss nor downtime. CockroachDB, for example\", \", is able to survive a\\nmachine loss by maintaining three consistent replicas of any data across the \", \"nodes in a cluster.\\nKubernetes uses a Services construct to allow a client to address a group of ide\", \"ntical NewSQL\\ndatabases processes from a single DNS entry. By decoupling the database instances from\", \" the address\\n107 CHAPTER 5 | Cloud-native data patternsof the service with which it\\u2019s associated, we\", \" can scale without disrupting existing application instances.\\nSending a request to any service at a \", \"given time will always yield the same result.\\nIn this scenario, all database instances are equal. Th\", \"ere are no primary or secondary relationships.\\nTechniques like consensus replication found in Cockro\", \"achDB allow any database node to handle any\\nrequest. If the node that receives a load-balanced reque\", \"st has the data it needs locally, it responds\\nimmediately. If not, the node becomes a gateway and fo\", \"rwards the request to the appropriate nodes\\nto get the correct answer. From the client\\u2019s perspective\", \", every database node is the same: They appear\\nas a single logical database with the consistency gua\", \"rantees of a single-machine system, despite\\nhaving dozens or even hundreds of nodes that are working\", \" behind the scenes.\\nFor a detailed look at the mechanics behind NewSQL databases, see the DASH: Four\", \" Properties of\\nKubernetes-Native Databases article.\\nData migration to the cloud\\nOne of the more time\", \"-consuming tasks is migrating data from one data platform to another. The\\nAzure Data Migration Servi\", \"ce can help expedite such efforts. It can migrate data from several external\\ndatabase sources into A\", \"zure Data platforms with minimal downtime. Target platforms include the\\nfollowing services:\\n\\u2022 Azure \", \"SQL Database\\n\\u2022 Azure Database for MySQL\\n\\u2022 Azure Database for MariaDB\\n\\u2022 Azure Database for PostgreSQL\", \"\\n\\u2022 Azure Cosmos DB\\nThe service provides recommendations to guide you through the changes required to\", \" execute a\\nmigration, both small or large.\\nCaching in a cloud-native app\\nThe benefits of caching are\", \" well understood. The technique works by temporarily copying frequently\\naccessed data from a backend\", \" data store to fast storage that\\u2019s located closer to the application.\\nCaching is often implemented w\", \"here\\u2026\\n\\u2022 Data remains relatively static.\\n\\u2022 Data access is slow, especially compared to the speed of t\", \"he cache.\\n\\u2022 Data is subject to high levels of contention.\\nWhy?\\nAs discussed in the Microsoft caching\", \" guidance, caching can increase performance, scalability, and\\navailability for individual microservi\", \"ces and the system as a whole. It reduces the latency and\\ncontention of handling large volumes of co\", \"ncurrent requests to a data store. As data volume and the\\nnumber of users increase, the greater the \", \"benefits of caching become.\\n108 CHAPTER 5 | Cloud-native data patternsCaching is most effective when\", \" a client repeatedly reads data that is immutable or that changes\\ninfrequently. Examples include ref\", \"erence information such as product and pricing information, or\\nshared static resources that are cost\", \"ly to construct.\\nWhile microservices should be stateless, a distributed cache can support concurrent\", \" access to session\\nstate data when absolutely required.\\nAlso consider caching to avoid repetitive co\", \"mputations. If an operation transforms data or performs a\\ncomplicated calculation, cache the result \", \"for subsequent requests.\\nCaching architecture\\nCloud native applications typically implement a distri\", \"buted caching architecture. The cache is hosted\\nas a cloud-based backing service, separate from the \", \"microservices. Figure 5-15 shows the architecture.\\nFigure 5-15: Caching in a cloud native app\\nIn the\", \" previous figure, note how the cache is independent of and shared by the microservices. In this\\nscen\", \"ario, the cache is invoked by the API Gateway. As discussed in chapter 4, the gateway serves as a\\nfr\", \"ont end for all incoming requests. The distributed cache increases system responsiveness by\\nreturnin\", \"g cached data whenever possible. Additionally, separating the cache from the services allows\\nthe cac\", \"he to scale up or out independently to meet increased traffic demands.\\nThe previous figure presents \", \"a common caching pattern known as the cache-aside pattern. For an\\nincoming request, you first query \", \"the cache (step #1) for a response. If found, the data is returned\\nimmediately. If the data doesn\\u2019t \", \"exist in the cache (known as a cache miss), it\\u2019s retrieved from a local\\ndatabase in a downstream ser\", \"vice (step #2). It\\u2019s then written to the cache for future requests (step #3),\\nand returned to the ca\", \"ller. Care must be taken to periodically evict cached data so that the system\\nremains timely and con\", \"sistent.\\nAs a shared cache grows, it might prove beneficial to partition its data across multiple no\", \"des. Doing\\nso can help minimize contention and improve scalability. Many Caching services support th\", \"e ability to\\n109 CHAPTER 5 | Cloud-native data patternsdynamically add and remove nodes and rebalanc\", \"e data across partitions. This approach typically\\ninvolves clustering. Clustering exposes a collecti\", \"on of federated nodes as a seamless, single cache.\\nInternally, however, the data is dispersed across\", \" the nodes following a predefined distribution strategy\\nthat balances the load evenly.\\nAzure Cache f\", \"or Redis\\nAzure Cache for Redis is a secure data caching and messaging broker service, fully managed \", \"by\\nMicrosoft. Consumed as a Platform as a Service (PaaS) offering, it provides high throughput and l\", \"ow-\\nlatency access to data. The service is accessible to any application within or outside of Azure.\", \"\\nThe Azure Cache for Redis service manages access to open-source Redis servers hosted across Azure\\nd\", \"ata centers. The service acts as a facade providing management, access control, and security. The\\nse\", \"rvice natively supports a rich set of data structures, including strings, hashes, lists, and sets. I\", \"f your\\napplication already uses Redis, it will work as-is with Azure Cache for Redis.\\nAzure Cache fo\", \"r Redis is more than a simple cache server. It can support a number of scenarios to\\nenhance a micros\", \"ervices architecture:\\n\\u2022 An in-memory data store\\n\\u2022 A distributed non-relational database\\n\\u2022 A message \", \"broker\\n\\u2022 A configuration or discovery server\\nFor advanced scenarios, a copy of the cached data can b\", \"e persisted to disk. If a catastrophic event\\ndisables both the primary and replica caches, the cache\", \" is reconstructed from the most recent\\nsnapshot.\\nAzure Redis Cache is available across a number of p\", \"redefined configurations and pricing tiers. The\\nPremium tier features many enterprise-level features\", \" such as clustering, data persistence, geo-\\nreplication, and virtual-network isolation.\\nElasticsearc\", \"h in a cloud-native app\\nElasticsearch is a distributed search and analytics system that enables comp\", \"lex search capabilities\\nacross diverse types of data. It\\u2019s open source and widely popular. Consider \", \"how the following\\ncompanies integrate Elasticsearch into their application:\\n\\u2022 Wikipedia for full-tex\", \"t and incremental (search as you type) searching.\\n\\u2022 GitHub to index and expose over 8 million code r\", \"epositories.\\n\\u2022 Docker for making its container library discoverable.\\nElasticsearch is built on top o\", \"f the Apache Lucene full-text search engine. Lucene provides high-\\nperformance document indexing and\", \" querying. It indexes data with an inverted indexing scheme \\u2013\\ninstead of mapping pages to keywords, \", \"it maps keywords to pages just like a glossary at the end of a\\nbook. Lucene has powerful query synta\", \"x capabilities and can query data by:\\n110 CHAPTER 5 | Cloud-native data patterns\\u2022 Term (a full word)\", \"\\n\\u2022 Prefix (starts-with word)\\n\\u2022 Wildcard (using \\u201c*\\u201d or \\u201c?\\u201d filters)\\n\\u2022 Phrase (a sequence of text in a\", \" document)\\n\\u2022 Boolean value (complex searches combining queries)\\nWhile Lucene provides low-level plum\", \"bing for searching, Elasticsearch provides the server that sits on\\ntop of Lucene. Elasticsearch adds\", \" higher-level functionality to simplify working Lucene, including a\\nRESTful API to access Lucene\\u2019s i\", \"ndexing and searching functionality. It also provides a distributed\\ninfrastructure capable of massiv\", \"e scalability, fault tolerance, and high availability.\\nFor larger cloud-native applications with com\", \"plex search requirements, Elasticsearch is available as\\nmanaged service in Azure. The Microsoft Azur\", \"e Marketplace features preconfigured templates which\\ndevelopers can use to deploy an Elasticsearch c\", \"luster on Azure.\\nFrom the Microsoft Azure Marketplace, developers can use preconfigured templates bu\", \"ilt to quickly\\ndeploy an Elasticsearch cluster on Azure. Using the Azure-managed offering, you can d\", \"eploy up to 50\\ndata nodes, 20 coordinating nodes, and three dedicated master nodes.\\nSummary\\nThis cha\", \"pter presented a detailed look at data in cloud-native systems. We started by contrasting data\\nstora\", \"ge in monolithic applications with data storage patterns in cloud-native systems. We looked at\\ndata \", \"patterns implemented in cloud-native systems, including cross-service queries, distributed\\ntransacti\", \"ons, and patterns to deal with high-volume systems. We contrasted SQL with NoSQL data.\\nWe looked at \", \"data storage options available in Azure that include both Microsoft-centric and open-\\nsource options\", \". Finally, we discussed caching and Elasticsearch in a cloud-native application.\\nReferences\\n\\u2022 Comman\", \"d and Query Responsibility Segregation (CQRS) pattern\\n\\u2022 Event Sourcing pattern\\n\\u2022 Why isn\\u2019t RDBMS Par\", \"tition Tolerant in CAP Theorem and why is it Available?\\n\\u2022 Materialized View\\n\\u2022 All you really need to\", \" know about open source databases\\n\\u2022 Compensating Transaction pattern\\n\\u2022 Saga Pattern\\n\\u2022 Saga Patterns \", \"| How to implement business transactions using microservices\\n\\u2022 Compensating Transaction pattern\\n\\u2022 Ge\", \"tting Behind the 9-Ball: Cosmos DB Consistency Levels Explained\\n\\u2022 On RDBMS, NoSQL and NewSQL databas\", \"es. Interview with John Ryan\\n111 CHAPTER 5 | Cloud-native data patterns\\u2022 SQL vs NoSQL vs NewSQL: The\", \" Full Comparison\\n\\u2022 DASH: Four Properties of Kubernetes-Native Databases\\n\\u2022 CockroachDB\\n\\u2022 TiDB\\n\\u2022 Yugab\", \"yteDB\\n\\u2022 Vitess\\n\\u2022 Elasticsearch: The Definitive Guide\\n\\u2022 Introduction to Apache Lucene\\n112 CHAPTER 5 |\", \" Cloud-native data patterns6\\nCHAPTER\\nCloud-native resiliency\\nResiliency is the ability of your syste\", \"m to react to failure and still remain functional. It\\u2019s not about\\navoiding failure, but accepting fa\", \"ilure and constructing your cloud-native services to respond to it.\\nYou want to return to a fully fu\", \"nctioning state quickly as possible.\\nUnlike traditional monolithic applications, where everything ru\", \"ns together in a single process, cloud-\\nnative systems embrace a distributed architecture as shown i\", \"n Figure 6-1:\\nFigure 6-1. Distributed cloud-native environment\\nIn the previous figure, each microser\", \"vice and cloud-based backing service execute in a separate\\nprocess, across server infrastructure, co\", \"mmunicating via network-based calls.\\nOperating in this environment, a service must be sensitive to m\", \"any different challenges:\\n\\u2022 Unexpected network latency - the time for a service request to travel to\", \" the receiver and back.\\n\\u2022 Transient faults - short-lived network connectivity errors.\\n\\u2022 Blockage by \", \"a long-running synchronous operation.\\n\\u2022 A host process that has crashed and is being restarted or mo\", \"ved.\\n\\u2022 An overloaded microservice that can\\u2019t respond for a short time.\\n\\u2022 An in-flight orchestrator o\", \"peration such as a rolling upgrade or moving a service from one\\nnode to another.\\n113 CHAPTER 6 | Clo\", \"ud-native resiliency\\u2022 Hardware failures.\\nCloud platforms can detect and mitigate many of these infra\", \"structure issues. It may restart, scale out,\\nand even redistribute your service to a different node.\", \" However, to take full advantage of this built-in\\nprotection, you must design your services to react\", \" to it and thrive in this dynamic environment.\\nIn the following sections, we\\u2019ll explore defensive te\", \"chniques that your service and managed cloud\\nresources can leverage to minimize downtime and disrupt\", \"ion.\\nApplication resiliency patterns\\nThe first line of defense is application resiliency.\\nWhile you \", \"could invest considerable time writing your own resiliency framework, such products\\nalready exist. P\", \"olly is a comprehensive .NET resilience and transient-fault-handling library that allows\\ndevelopers \", \"to express resiliency policies in a fluent and thread-safe manner. Polly targets applications\\nbuilt \", \"with either .NET Framework or .NET 7. The following table describes the resiliency features, called\\n\", \"policies, available in the Polly Library. They can be applied individually or grouped together.\\nPoli\", \"cy Experience\\nRetry Configures retry operations on designated\\noperations.\\nCircuit Breaker Blocks req\", \"uested operations for a predefined\\nperiod when faults exceed a configured\\nthreshold\\nTimeout Places l\", \"imit on the duration for which a caller\\ncan wait for a response.\\nBulkhead Constrains actions to fixe\", \"d-size resource pool to\\nprevent failing calls from swamping a resource.\\nCache Stores responses autom\", \"atically.\\nFallback Defines structured behavior upon a failure.\\nNote how in the previous figure the r\", \"esiliency policies apply to request messages, whether coming\\nfrom an external client or back-end ser\", \"vice. The goal is to compensate the request for a service that\\nmight be momentarily unavailable. The\", \"se short-lived interruptions typically manifest themselves with\\nthe HTTP status codes shown in the f\", \"ollowing table.\\nHTTP Status Code Cause\\n404 Not Found\\n408 Request timeout\\n429 Too many requests (you\\u2019\", \"ve most likely been throttled)\\n502 Bad gateway\\n503 Service unavailable\\n114 CHAPTER 6 | Cloud-native \", \"resiliencyHTTP Status Code Cause\\n504 Gateway timeout\\nQuestion: Would you retry an HTTP Status Code o\", \"f 403 - Forbidden? No. Here, the system is\\nfunctioning properly, but informing the caller that they \", \"aren\\u2019t authorized to perform the requested\\noperation. Care must be taken to retry only those operati\", \"ons caused by failures.\\nAs recommended in Chapter 1, Microsoft developers constructing cloud-native \", \"applications should\\ntarget the .NET platform. Version 2.1 introduced the HTTPClientFactory library f\", \"or creating HTTP Client\\ninstances for interacting with URL-based resources. Superseding the original\", \" HTTPClient class, the\\nfactory class supports many enhanced features, one of which is tight integrat\", \"ion with the Polly\\nresiliency library. With it, you can easily define resiliency policies in the app\", \"lication Startup class to\\nhandle partial failures and connectivity issues.\\nNext, let\\u2019s expand on ret\", \"ry and circuit breaker patterns.\\nRetry pattern\\nIn a distributed cloud-native environment, calls to s\", \"ervices and cloud resources can fail because of\\ntransient (short-lived) failures, which typically co\", \"rrect themselves after a brief period of time.\\nImplementing a retry strategy helps a cloud-native se\", \"rvice mitigate these scenarios.\\nThe Retry pattern enables a service to retry a failed request operat\", \"ion a (configurable) number of\\ntimes with an exponentially increasing wait time. Figure 6-2 shows a \", \"retry in action.\\nFigure 6-2. Retry pattern in action\\nIn the previous figure, a retry pattern has bee\", \"n implemented for a request operation. It\\u2019s configured to\\nallow up to four retries before failing wi\", \"th a backoff interval (wait time) starting at two seconds, which\\nexponentially doubles for each subs\", \"equent attempt.\\n\\u2022 The first invocation fails and returns an HTTP status code of 500. The application\", \" waits for two\\nseconds and retries the call.\\n115 CHAPTER 6 | Cloud-native resiliency\\u2022 The second inv\", \"ocation also fails and returns an HTTP status code of 500. The application now\\ndoubles the backoff i\", \"nterval to four seconds and retries the call.\\n\\u2022 Finally, the third call succeeds.\\n\\u2022 In this scenario\", \", the retry operation would have attempted up to four retries while doubling\\nthe backoff duration be\", \"fore failing the call.\\n\\u2022 Had the 4th retry attempt failed, a fallback policy would be invoked to gra\", \"cefully handle the\\nproblem.\\nIt\\u2019s important to increase the backoff period before retrying the call t\", \"o allow the service time to self-\\ncorrect. It\\u2019s a best practice to implement an exponentially increa\", \"sing backoff (doubling the period on\\neach retry) to allow adequate correction time.\\nCircuit breaker \", \"pattern\\nWhile the retry pattern can help salvage a request entangled in a partial failure, there are\", \" situations\\nwhere failures can be caused by unanticipated events that will require longer periods of\", \" time to\\nresolve. These faults can range in severity from a partial loss of connectivity to the comp\", \"lete failure of\\na service. In these situations, it\\u2019s pointless for an application to continually ret\", \"ry an operation that is\\nunlikely to succeed.\\nTo make things worse, executing continual retry operati\", \"ons on a non-responsive service can move\\nyou into a self-imposed denial of service scenario where yo\", \"u flood your service with continual calls\\nexhausting resources such as memory, threads and database \", \"connections, causing failure in unrelated\\nparts of the system that use the same resources.\\nIn these \", \"situations, it would be preferable for the operation to fail immediately and only attempt to\\ninvoke \", \"the service if it\\u2019s likely to succeed.\\nThe Circuit Breaker pattern can prevent an application from r\", \"epeatedly trying to execute an operation\\nthat\\u2019s likely to fail. After a pre-defined number of failed\", \" calls, it blocks all traffic to the service.\\nPeriodically, it will allow a trial call to determine \", \"whether the fault has resolved. Figure 6-3 shows the\\nCircuit Breaker pattern in action.\\n116 CHAPTER \", \"6 | Cloud-native resiliencyFigure 6-3. Circuit breaker pattern in action\\nIn the previous figure, a C\", \"ircuit Breaker pattern has been added to the original retry pattern. Note how\\nafter 100 failed reque\", \"sts, the circuit breakers opens and no longer allows calls to the service. The\\nCheckCircuit value, s\", \"et at 30 seconds, specifies how often the library allows one request to proceed to\\nthe service. If t\", \"hat call succeeds, the circuit closes and the service is once again available to traffic.\\nKeep in mi\", \"nd that the intent of the Circuit Breaker pattern is different than that of the Retry pattern.\\nThe R\", \"etry pattern enables an application to retry an operation in the expectation that it will succeed.\\nT\", \"he Circuit Breaker pattern prevents an application from doing an operation that is likely to fail.\\nT\", \"ypically, an application will combine these two patterns by using the Retry pattern to invoke an\\nope\", \"ration through a circuit breaker.\\nTesting for resiliency\\nTesting for resiliency cannot always be don\", \"e the same way that you test application functionality (by\\nrunning unit tests, integration tests, an\", \"d so on). Instead, you must test how the end-to-end workload\\nperforms under failure conditions, whic\", \"h only occur intermittently. For example: inject failures by\\ncrashing processes, expired certificate\", \"s, make dependent services unavailable etc. Frameworks like\\nchaos-monkey can be used for such chaos \", \"testing.\\nApplication resiliency is a must for handling problematic requested operations. But, it\\u2019s o\", \"nly half of the\\nstory. Next, we cover resiliency features available in the Azure cloud.\\nAzure platfo\", \"rm resiliency\\nBuilding a reliable application in the cloud is different from traditional on-premises\", \" application\\ndevelopment. While historically you purchased higher-end hardware to scale up, in a clo\", \"ud\\nenvironment you scale out. Instead of trying to prevent failures, the goal is to minimize their e\", \"ffects\\nand keep the system stable.\\n117 CHAPTER 6 | Cloud-native resiliencyThat said, reliable cloud \", \"applications display distinct characteristics:\\n\\u2022 They\\u2019re resilient, recover gracefully from problems\", \", and continue to function.\\n\\u2022 They\\u2019re highly available (HA) and run as designed in a healthy state w\", \"ith no significant\\ndowntime.\\nUnderstanding how these characteristics work together - and how they af\", \"fect cost - is essential to\\nbuilding a reliable cloud-native application. We\\u2019ll next look at ways th\", \"at you can build resiliency and\\navailability into your cloud-native applications leveraging features\", \" from the Azure cloud.\\nDesign with resiliency\\nWe\\u2019ve said resiliency enables your application to reac\", \"t to failure and still remain functional. The\\nwhitepaper, Resilience in Azure whitepaper, provides g\", \"uidance for achieving resilience in the Azure\\nplatform. Here are some key recommendations:\\n\\u2022 Hardwar\", \"e failure. Build redundancy into the application by deploying components across\\ndifferent fault doma\", \"ins. For example, ensure that Azure VMs are placed in different racks by\\nusing Availability Sets.\\n\\u2022 \", \"Datacenter failure. Build redundancy into the application with fault isolation zones across\\ndatacent\", \"ers. For example, ensure that Azure VMs are placed in different fault-isolated\\ndatacenters by using \", \"Azure Availability Zones.\\n\\u2022 Regional failure. Replicate the data and components into another region \", \"so that applications\\ncan be quickly recovered. For example, use Azure Site Recovery to replicate Azu\", \"re VMs to\\nanother Azure region.\\n\\u2022 Heavy load. Load balance across instances to handle spikes in usag\", \"e. For example, put two or\\nmore Azure VMs behind a load balancer to distribute traffic to all VMs.\\n\\u2022\", \" Accidental data deletion or corruption. Back up data so it can be restored if there\\u2019s any\\ndeletion \", \"or corruption. For example, use Azure Backup to periodically back up your Azure\\nVMs.\\nDesign with red\", \"undancy\\nFailures vary in scope of impact. A hardware failure, such as a failed disk, can affect a si\", \"ngle node in a\\ncluster. A failed network switch could affect an entire server rack. Less common fail\", \"ures, such as loss of\\npower, could disrupt a whole datacenter. Rarely, an entire region becomes unav\", \"ailable.\\nRedundancy is one way to provide application resilience. The exact level of redundancy need\", \"ed\\ndepends upon your business requirements and will affect both the cost and complexity of your\\nsyst\", \"em. For example, a multi-region deployment is more expensive and more complex to manage\\nthan a singl\", \"e-region deployment. You\\u2019ll need operational procedures to manage failover and failback.\\nThe additio\", \"nal cost and complexity might be justified for some business scenarios, but not others.\\nTo architect\", \" redundancy, you need to identify the critical paths in your application, and then\\ndetermine if ther\", \"e\\u2019s redundancy at each point in the path? If a subsystem should fail, will the\\napplication fail over\", \" to something else? Finally, you need a clear understanding of those features built\\n118 CHAPTER 6 | \", \"Cloud-native resiliencyinto the Azure cloud platform that you can leverage to meet your redundancy r\", \"equirements. Here are\\nrecommendations for architecting redundancy:\\n\\u2022 Deploy multiple instances of se\", \"rvices. If your application depends on a single instance of a\\nservice, it creates a single point of \", \"failure. Provisioning multiple instances improves both\\nresiliency and scalability. When hosting in A\", \"zure Kubernetes Service, you can declaratively\\nconfigure redundant instances (replica sets) in the K\", \"ubernetes manifest file. The replica count\\nvalue can be managed programmatically, in the portal, or \", \"through autoscaling features.\\n\\u2022 Leveraging a load balancer. Load-balancing distributes your applicat\", \"ion\\u2019s requests to healthy\\nservice instances and automatically removes unhealthy instances from rotat\", \"ion. When\\ndeploying to Kubernetes, load balancing can be specified in the Kubernetes manifest file i\", \"n\\nthe Services section.\\n\\u2022 Plan for multiregion deployment. If you deploy your application to a singl\", \"e region, and that\\nregion becomes unavailable, your application will also become unavailable. This m\", \"ay be\\nunacceptable under the terms of your application\\u2019s service level agreements. Instead, consider\", \"\\ndeploying your application and its services across multiple regions. For example, an Azure\\nKubernet\", \"es Service (AKS) cluster is deployed to a single region. To protect your system from a\\nregional fail\", \"ure, you might deploy your application to multiple AKS clusters across different\\nregions and use the\", \" Paired Regions feature to coordinate platform updates and prioritize\\nrecovery efforts.\\n\\u2022 Enable geo\", \"-replication. Geo-replication for services such as Azure SQL Database and Cosmos\\nDB will create seco\", \"ndary replicas of your data across multiple regions. While both services will\\nautomatically replicat\", \"e data within the same region, geo-replication protects you against a\\nregional outage by enabling yo\", \"u to fail over to a secondary region. Another best practice for\\ngeo-replication centers around stori\", \"ng container images. To deploy a service in AKS, you\\nneed to store and pull the image from a reposit\", \"ory. Azure Container Registry integrates with\\nAKS and can securely store container images. To improv\", \"e performance and availability,\\nconsider geo-replicating your images to a registry in each region wh\", \"ere you have an AKS\\ncluster. Each AKS cluster then pulls container images from the local container r\", \"egistry in its\\nregion as shown in Figure 6-4:\\nFigure 6-4. Replicated resources across regions\\n119 CH\", \"APTER 6 | Cloud-native resiliency\\u2022 Implement a DNS traffic load balancer. Azure Traffic Manager prov\", \"ides high-availability for\\ncritical applications by load-balancing at the DNS level. It can route tr\", \"affic to different regions\\nbased on geography, cluster response time, and even application endpoint \", \"health. For\\nexample, Azure Traffic Manager can direct customers to the closest AKS cluster and\\nappli\", \"cation instance. If you have multiple AKS clusters in different regions, use Traffic\\nManager to cont\", \"rol how traffic flows to the applications that run in each cluster. Figure 6-5\\nshows this scenario.\\n\", \"Figure 6-5. AKS and Azure Traffic Manager\\nDesign for scalability\\nThe cloud thrives on scaling. The a\", \"bility to increase/decrease system resources to address\\nincreasing/decreasing system load is a key t\", \"enet of the Azure cloud. But, to effectively scale an\\napplication, you need an understanding of the \", \"scaling features of each Azure service that you include\\nin your application. Here are recommendation\", \"s for effectively implementing scaling in your system.\\n\\u2022 Design for scaling. An application must be \", \"designed for scaling. To start, services should be\\nstateless so that requests can be routed to any i\", \"nstance. Having stateless services also means\\nthat adding or removing an instance doesn\\u2019t adversely \", \"impact current users.\\n\\u2022 Partition workloads. Decomposing domains into independent, self-contained mi\", \"croservices\\nenable each service to scale independently of others. Typically, services will have diff\", \"erent\\nscalability needs and requirements. Partitioning enables you to scale only what needs to be\\nsc\", \"aled without the unnecessary cost of scaling an entire application.\\n\\u2022 Favor scale-out. Cloud-based a\", \"pplications favor scaling out resources as opposed to scaling\\nup. Scaling out (also known as horizon\", \"tal scaling) involves adding more service resources to\\nan existing system to meet and share a desire\", \"d level of performance. Scaling up (also known\\n120 CHAPTER 6 | Cloud-native resiliencyas vertical sc\", \"aling) involves replacing existing resources with more powerful hardware (more\\ndisk, memory, and pro\", \"cessing cores). Scaling out can be invoked automatically with the\\nautoscaling features available in \", \"some Azure cloud resources. Scaling out across multiple\\nresources also adds redundancy to the overal\", \"l system. Finally scaling up a single resource is\\ntypically more expensive than scaling out across m\", \"any smaller resources. Figure 6-6 shows the\\ntwo approaches:\\nFigure 6-6. Scale up versus scale out\\n\\u2022 \", \"Scale proportionally. When scaling a service, think in terms of resource sets. If you were to\\ndramat\", \"ically scale out a specific service, what impact would that have on back-end data\\nstores, caches and\", \" dependent services? Some resources such as Cosmos DB can scale out\\nproportionally, while many other\", \"s can\\u2019t. You want to ensure that you don\\u2019t scale out a\\nresource to a point where it will exhaust oth\", \"er associated resources.\\n\\u2022 Avoid affinity. A best practice is to ensure a node doesn\\u2019t require local\", \" affinity, often referred\\nto as a sticky session. A request should be able to route to any instance.\", \" If you need to persist\\nstate, it should be saved to a distributed cache, such as Azure Redis cache.\", \"\\n\\u2022 Take advantage of platform autoscaling features. Use built-in autoscaling features whenever\\npossi\", \"ble, rather than custom or third-party mechanisms. Where possible, use scheduled\\nscaling rules to en\", \"sure that resources are available without a startup delay, but add reactive\\nautoscaling to the rules\", \" as appropriate, to cope with unexpected changes in demand. For\\nmore information, see Autoscaling gu\", \"idance.\\n\\u2022 Scale out aggressively. A final practice would be to scale out aggressively so that you ca\", \"n\\nquickly meet immediate spikes in traffic without losing business. And, then scale in (that is,\\nrem\", \"ove unneeded instances) conservatively to keep the system stable. A simple way to\\nimplement this is \", \"to set the cool down period, which is the time to wait between scaling\\noperations, to five minutes f\", \"or adding resources and up to 15 minutes for removing instances.\\nBuilt-in retry in services\\nWe encou\", \"raged the best practice of implementing programmatic retry operations in an earlier section.\\nKeep in\", \" mind that many Azure services and their corresponding client SDKs also include retry\\n121 CHAPTER 6 \", \"| Cloud-native resiliencymechanisms. The following list summarizes retry features in the many of the\", \" Azure services that are\\ndiscussed in this book:\\n\\u2022 Azure Cosmos DB. The DocumentClient class from th\", \"e client API automatically retires failed\\nattempts. The number of retries and maximum wait time are \", \"configurable. Exceptions thrown\\nby the client API are either requests that exceed the retry policy o\", \"r non-transient errors.\\n\\u2022 Azure Redis Cache. The Redis StackExchange client uses a connection manage\", \"r class that\\nincludes retries on failed attempts. The number of retries, specific retry policy and w\", \"ait time\\nare all configurable.\\n\\u2022 Azure Service Bus. The Service Bus client exposes a RetryPolicy cla\", \"ss that can be configured\\nwith a back-off interval, retry count, and TerminationTimeBuffer, which sp\", \"ecifies the maximum\\ntime an operation can take. The default policy is nine maximum retry attempts wi\", \"th a 30-\\nsecond backoff period between attempts.\\n\\u2022 Azure SQL Database. Retry support is provided whe\", \"n using the Entity Framework Core library.\\n\\u2022 Azure Storage. The storage client library support retry\", \" operations. The strategies vary across\\nAzure storage tables, blobs, and queues. As well, alternate \", \"retries switch between primary and\\nsecondary storage services locations when the geo-redundancy feat\", \"ure is enabled.\\n\\u2022 Azure Event Hubs. The Event Hub client library features a RetryPolicy property, wh\", \"ich includes\\na configurable exponential backoff feature.\\nResilient communications\\nThroughout this bo\", \"ok, we\\u2019ve embraced a microservice-based architectural approach. While such an\\narchitecture provides \", \"important benefits, it presents many challenges:\\n\\u2022 Out-of-process network communication. Each micros\", \"ervice communicates over a network\\nprotocol that introduces network congestion, latency, and transie\", \"nt faults.\\n\\u2022 Service discovery. How do microservices discover and communicate with each other when\\nr\", \"unning across a cluster of machines with their own IP addresses and ports?\\n\\u2022 Resiliency. How do you \", \"manage short-lived failures and keep the system stable?\\n\\u2022 Load balancing. How does inbound traffic g\", \"et distributed across multiple instances of a\\nmicroservice?\\n\\u2022 Security. How are security concerns su\", \"ch as transport-level encryption and certificate\\nmanagement enforced?\\n\\u2022 Distributed Monitoring. - Ho\", \"w do you correlate and capture traceability and monitoring for a\\nsingle request across multiple cons\", \"uming microservices?\\nYou can address these concerns with different libraries and frameworks, but the\", \" implementation can\\nbe expensive, complex, and time-consuming. You also end up with infrastructure c\", \"oncerns coupled to\\nbusiness logic.\\n122 CHAPTER 6 | Cloud-native resiliencyService mesh\\nA better appr\", \"oach is an evolving technology entitled Service Mesh. A service mesh is a configurable\\ninfrastructur\", \"e layer with built-in capabilities to handle service communication and the other\\nchallenges mentione\", \"d above. It decouples these concerns by moving them into a service proxy. The\\nproxy is deployed into\", \" a separate process (called a sidecar) to provide isolation from business code.\\nHowever, the sidecar\", \" is linked to the service - it\\u2019s created with it and shares its lifecycle. Figure 6-7\\nshows this sce\", \"nario.\\nFigure 6-7. Service mesh with a side car\\nIn the previous figure, note how the proxy intercept\", \"s and manages communication among the\\nmicroservices and the cluster.\\nA service mesh is logically spl\", \"it into two disparate components: A data plane and control plane. Figure\\n6-8 shows these components \", \"and their responsibilities.\\n123 CHAPTER 6 | Cloud-native resiliencyFigure 6-8. Service mesh control \", \"and data plane\\nOnce configured, a service mesh is highly functional. It can retrieve a corresponding\", \" pool of instances\\nfrom a service discovery endpoint. The mesh can then send a request to a specific\", \" instance, recording\\nthe latency and response type of the result. A mesh can choose the instance mos\", \"t likely to return a\\nfast response based on many factors, including its observed latency for recent \", \"requests.\\nIf an instance is unresponsive or fails, the mesh will retry the request on another instan\", \"ce. If it returns\\nerrors, a mesh will evict the instance from the load-balancing pool and restate it\", \" after it heals. If a\\nrequest times out, a mesh can fail and then retry the request. A mesh captures\", \" and emits metrics and\\ndistributed tracing to a centralized metrics system.\\nIstio and Envoy\\nWhile a \", \"few service mesh options currently exist, Istio is the most popular at the time of this writing.\\nIst\", \"io is a joint venture from IBM, Google, and Lyft. It\\u2019s an open-source offering that can be integrate\", \"d\\ninto a new or existing distributed application. The technology provides a consistent and complete\\n\", \"solution to secure, connect, and monitor microservices. Its features include:\\n\\u2022 Secure service-to-se\", \"rvice communication in a cluster with strong identity-based\\nauthentication and authorization.\\n\\u2022 Auto\", \"matic load balancing for HTTP, gRPC, WebSocket, and TCP traffic.\\n\\u2022 Fine-grained control of traffic b\", \"ehavior with rich routing rules, retries, failovers, and fault\\ninjection.\\n\\u2022 A pluggable policy layer\", \" and configuration API supporting access controls, rate limits, and\\nquotas.\\n\\u2022 Automatic metrics, log\", \"s, and traces for all traffic within a cluster, including cluster ingress and\\negress.\\nA key componen\", \"t for an Istio implementation is a proxy service entitled the Envoy proxy. It runs\\nalongside each se\", \"rvice and provides a platform-agnostic foundation for the following features:\\n\\u2022 Dynamic service disc\", \"overy.\\n\\u2022 Load balancing.\\n124 CHAPTER 6 | Cloud-native resiliency\\u2022 TLS termination.\\n\\u2022 HTTP and gRPC p\", \"roxies.\\n\\u2022 Circuit breaker resiliency.\\n\\u2022 Health checks.\\n\\u2022 Rolling updates with canary deployments.\\nAs\", \" previously discussed, Envoy is deployed as a sidecar to each microservice in the cluster.\\nIntegrati\", \"on with Azure Kubernetes Services\\nThe Azure cloud embraces Istio and provides direct support for it \", \"within Azure Kubernetes Services.\\nThe following links can help you get started:\\n\\u2022 Installing Istio i\", \"n AKS\\n\\u2022 Using AKS and Istio\\nReferences\\n\\u2022 Polly\\n\\u2022 Retry pattern\\n\\u2022 Circuit Breaker pattern\\n\\u2022 Resilienc\", \"e in Azure whitepaper\\n\\u2022 network latency\\n\\u2022 Redundancy\\n\\u2022 geo-replication\\n\\u2022 Azure Traffic Manager\\n\\u2022 Aut\", \"oscaling guidance\\n\\u2022 Istio\\n\\u2022 Envoy proxy\\n125 CHAPTER 6 | Cloud-native resiliency7\\nCHAPTER\\nMonitoring \", \"and health\\nMicroservices and cloud-native applications go hand in hand with good DevOps practices. D\", \"evOps is\\nmany things to many people but perhaps one of the better definitions comes from cloud advoc\", \"ate\\nand DevOps evangelist Donovan Brown:\\n\\u201cDevOps is the union of people, process, and products to en\", \"able continuous delivery of value to our\\nend users.\\u201d\\nUnfortunately, with terse definitions, there\\u2019s \", \"always room to say more things. One of the key\\ncomponents of DevOps is ensuring that the application\", \"s running in production are functioning\\nproperly and efficiently. To gauge the health of the applica\", \"tion in production, it\\u2019s necessary to monitor\\nthe various logs and metrics being produced from the s\", \"ervers, hosts, and the application proper. The\\nnumber of different services running in support of a \", \"cloud-native application makes monitoring the\\nhealth of individual components and the application as\", \" a whole a critical challenge.\\nObservability patterns\\nJust as patterns have been developed to aid in\", \" the layout of code in applications, there are patterns\\nfor operating applications in a reliable way\", \". Three useful patterns in maintaining applications have\\nemerged: logging, monitoring, and alerts.\\nW\", \"hen to use logging\\nNo matter how careful we are, applications almost always behave in unexpected way\", \"s in production.\\nWhen users report problems with an application, it\\u2019s useful to be able to see what \", \"was going on with\\nthe app when the problem occurred. One of the most tried and true ways of capturin\", \"g information\\nabout what an application is doing while it\\u2019s running is to have the application write\", \" down what it\\u2019s\\ndoing. This process is known as logging. Anytime failures or problems occur in produ\", \"ction, the goal\\nshould be to reproduce the conditions under which the failures occurred, in a non-pr\", \"oduction\\nenvironment. Having good logging in place provides a roadmap for developers to follow in or\", \"der to\\nduplicate problems in an environment that can be tested and experimented with.\\nChallenges whe\", \"n logging with cloud-native applications\\nIn traditional applications, log files are typically stored\", \" on the local machine. In fact, on Unix-like\\noperating systems, there\\u2019s a folder structure defined t\", \"o hold any logs, typically under /var/log.\\n126 CHAPTER 7 | Monitoring and healthFigure 7-1. Logging \", \"to a file in a monolithic app.\\nThe usefulness of logging to a flat file on a single machine is vastl\", \"y reduced in a cloud environment.\\nApplications producing logs may not have access to the local disk \", \"or the local disk may be highly\\ntransient as containers are shuffled around physical machines. Even \", \"simple scaling up of monolithic\\napplications across multiple nodes can make it challenging to locate\", \" the appropriate file-based log\\nfile.\\nFigure 7-2. Logging to files in a scaled monolithic app.\\nCloud\", \"-native applications developed using a microservices architecture also pose some challenges for\\nfile\", \"-based loggers. User requests may now span multiple services that are run on different machines\\n127 \", \"CHAPTER 7 | Monitoring and healthand may include serverless functions with no access to a local file\", \" system at all. It would be very\\nchallenging to correlate the logs from a user or a session across t\", \"hese many services and machines.\\nFigure 7-3. Logging to local files in a microservices app.\\nFinally,\", \" the number of users in some cloud-native applications is high. Imagine that each user\\ngenerates a h\", \"undred lines of log messages when they log into an application. In isolation, that is\\nmanageable, bu\", \"t multiply that over 100,000 users and the volume of logs becomes large enough that\\nspecialized tool\", \"s are needed to support effective use of the logs.\\nLogging in cloud-native applications\\nEvery progra\", \"mming language has tooling that permits writing logs, and typically the overhead for\\nwriting these l\", \"ogs is low. Many of the logging libraries provide logging different kinds of criticalities,\\nwhich ca\", \"n be tuned at run time. For instance, the Serilog library is a popular structured logging library\\nfo\", \"r .NET that provides the following logging levels:\\n\\u2022 Verbose\\n\\u2022 Debug\\n\\u2022 Information\\n\\u2022 Warning\\n\\u2022 Error\", \"\\n\\u2022 Fatal\\nThese different log levels provide granularity in logging. When the application is function\", \"ing properly\\nin production, it may be configured to only log important messages. When the applicatio\", \"n is\\n128 CHAPTER 7 | Monitoring and healthmisbehaving, then the log level can be increased so more v\", \"erbose logs are gathered. This balances\\nperformance against ease of debugging.\\nThe high performance \", \"of logging tools and the tunability of verbosity should encourage developers to\\nlog frequently. Many\", \" favor a pattern of logging the entry and exit of each method. This approach may\\nsound like overkill\", \", but it\\u2019s infrequent that developers will wish for less logging. In fact, it\\u2019s not\\nuncommon to perf\", \"orm deployments for the sole purpose of adding logging around a problematic\\nmethod. Err on the side \", \"of too much logging and not on too little. Some tools can be used to\\nautomatically provide this kind\", \" of logging.\\nBecause of the challenges associated with using file-based logs in cloud-native apps, c\", \"entralized logs\\nare preferred. Logs are collected by the applications and shipped to a central loggi\", \"ng application\\nwhich indexes and stores the logs. This class of system can ingest tens of gigabytes \", \"of logs every day.\\nIt\\u2019s also helpful to follow some standard practices when building logging that sp\", \"ans many services.\\nFor instance, generating a correlation ID at the start of a lengthy interaction, \", \"and then logging it in\\neach message that is related to that interaction, makes it easier to search f\", \"or all related messages. One\\nneed only find a single message and extract the correlation ID to find \", \"all the related messages.\\nAnother example is ensuring that the log format is the same for every serv\", \"ice, whatever the language\\nor logging library it uses. This standardization makes reading logs much \", \"easier. Figure 7-4\\ndemonstrates how a microservices architecture can leverage centralized logging as\", \" part of its\\nworkflow.\\nFigure 7-4. Logs from various sources are ingested into a centralized log sto\", \"re.\\n129 CHAPTER 7 | Monitoring and healthChallenges with detecting and responding to potential app h\", \"ealth\\nissues\\nSome applications aren\\u2019t mission critical. Maybe they\\u2019re only used internally, and when\", \" a problem\\noccurs, the user can contact the team responsible and the application can be restarted. H\", \"owever,\\ncustomers often have higher expectations for the applications they consume. You should know \", \"when\\nproblems occur with your application before users do, or before users notify you. Otherwise, th\", \"e first\\nyou know about a problem may be when you notice an angry deluge of social media posts deridi\", \"ng\\nyour application or even your organization.\\nSome scenarios you may need to consider include:\\n\\u2022 On\", \"e service in your application keeps failing and restarting, resulting in intermittent slow\\nresponses\", \".\\n\\u2022 At some times of the day, your application\\u2019s response time is slow.\\n\\u2022 After a recent deployment,\", \" load on the database has tripled.\\nImplemented properly, monitoring can let you know about condition\", \"s that will lead to problems,\\nletting you address underlying conditions before they result in any si\", \"gnificant user impact.\\nMonitoring cloud-native apps\\nSome centralized logging systems take on an addi\", \"tional role of collecting telemetry outside of pure\\nlogs. They can collect metrics, such as time to \", \"run a database query, average response time from a\\nweb server, and even CPU load averages and memory\", \" pressure as reported by the operating system.\\nIn conjunction with the logs, these systems can provi\", \"de a holistic view of the health of nodes in the\\nsystem and the application as a whole.\\nThe metric-g\", \"athering capabilities of the monitoring tools can also be fed manually from within the\\napplication. \", \"Business flows that are of particular interest such as new users signing up or orders being\\nplaced, \", \"may be instrumented such that they increment a counter in the central monitoring system.\\nThis aspect\", \" unlocks the monitoring tools to not only monitor the health of the application but the\\nhealth of th\", \"e business.\\nQueries can be constructed in the log aggregation tools to look for certain statistics o\", \"r patterns, which\\ncan then be displayed in graphical form, on custom dashboards. Frequently, teams w\", \"ill invest in large,\\nwall-mounted displays that rotate through the statistics related to an applicat\", \"ion. This way, it\\u2019s simple\\nto see the problems as they occur.\\nCloud-native monitoring tools provide \", \"real-time telemetry and insight into apps regardless of whether\\nthey\\u2019re single-process monolithic ap\", \"plications or distributed microservice architectures. They include\\ntools that allow collection of da\", \"ta from the app as well as tools for querying and displaying\\ninformation about the app\\u2019s health.\\nCha\", \"llenges with reacting to critical problems in cloud-native apps\\nIf you need to react to problems wit\", \"h your application, you need some way to alert the right\\npersonnel. This is the third cloud-native a\", \"pplication observability pattern and depends on logging and\\nmonitoring. Your application needs to ha\", \"ve logging in place to allow problems to be diagnosed, and\\n130 CHAPTER 7 | Monitoring and healthin s\", \"ome cases to feed into monitoring tools. It needs monitoring to aggregate application metrics and\\nhe\", \"alth data in one place. Once this has been established, rules can be created that will trigger alert\", \"s\\nwhen certain metrics fall outside of acceptable levels.\\nGenerally, alerts are layered on top of mo\", \"nitoring such that certain conditions trigger appropriate\\nalerts to notify team members of urgent pr\", \"oblems. Some scenarios that may require alerts include:\\n\\u2022 One of your application\\u2019s services is not \", \"responding after 1 minute of downtime.\\n\\u2022 Your application is returning unsuccessful HTTP responses t\", \"o more than 1% of requests.\\n\\u2022 Your application\\u2019s average response time for key endpoints exceeds 200\", \"0 ms.\\nAlerts in cloud-native apps\\nYou can craft queries against the monitoring tools to look for kno\", \"wn failure conditions. For instance,\\nqueries could search through the incoming logs for indications \", \"of HTTP status code 500, which\\nindicates a problem on a web server. As soon as one of these is detec\", \"ted, then an e-mail or an SMS\\ncould be sent to the owner of the originating service who can begin to\", \" investigate.\\nTypically, though, a single 500 error isn\\u2019t enough to determine that a problem has occ\", \"urred. It could\\nmean that a user mistyped their password or entered some malformed data. The alert q\", \"ueries can be\\ncrafted to only fire when a larger than average number of 500 errors are detected.\\nOne\", \" of the most damaging patterns in alerting is to fire too many alerts for humans to investigate.\\nSer\", \"vice owners will rapidly become desensitized to errors that they\\u2019ve previously investigated and\\nfoun\", \"d to be benign. Then, when true errors occur, they\\u2019ll be lost in the noise of hundreds of false\\nposi\", \"tives. The parable of the Boy Who Cried Wolf is frequently told to children to warn them of this\\nver\", \"y danger. It\\u2019s important to ensure that the alerts that do fire are indicative of a real problem.\\nLo\", \"gging with Elastic Stack\\nThere are many good centralized logging tools and they vary in cost from be\", \"ing free, open-source\\ntools, to more expensive options. In many cases, the free tools are as good as\", \" or better than the paid\\nofferings. One such tool is a combination of three open-source components: \", \"Elasticsearch, Logstash,\\nand Kibana.\\nCollectively these tools are known as the Elastic Stack or ELK \", \"stack.\\nElastic Stack\\nThe Elastic Stack is a powerful option for gathering information from a Kuberne\", \"tes cluster. Kubernetes\\nsupports sending logs to an Elasticsearch endpoint, and for the most part, a\", \"ll you need to get started\\nis to set the environment variables as shown in Figure 7-5:\\nKUBE_LOGGING_\", \"DESTINATION=elasticsearch\\nKUBE_ENABLE_NODE_LOGGING=true\\nFigure 7-5. Configuration variables for Kube\", \"rnetes\\nThis step will install Elasticsearch on the cluster and target sending all the cluster logs t\", \"o it.\\n131 CHAPTER 7 | Monitoring and healthFigure 7-6. An example of a Kibana dashboard showing the \", \"results of a query against logs that are ingested from\\nKubernetes\\nWhat are the advantages of Elastic\", \" Stack?\\nElastic Stack provides centralized logging in a low-cost, scalable, cloud-friendly manner. I\", \"ts user\\ninterface streamlines data analysis so you can spend your time gleaning insights from your d\", \"ata\\ninstead of fighting with a clunky interface. It supports a wide variety of inputs so as your dis\", \"tributed\\napplication spans more and different kinds of services, you can expect to continue to be ab\", \"le to feed\\nlog and metric data into the system. The Elastic Stack also supports fast searches even a\", \"cross large\\ndata sets, making it possible even for large applications to log detailed data and still\", \" be able to have\\nvisibility into it in a performant fashion.\\nLogstash\\nThe first component is Logstas\", \"h. This tool is used to gather log information from a large variety of\\ndifferent sources. For instan\", \"ce, Logstash can read logs from disk and also receive messages from\\nlogging libraries like Serilog. \", \"Logstash can do some basic filtering and expansion on the logs as they\\narrive. For instance, if your\", \" logs contain IP addresses then Logstash may be configured to do a\\ngeographical lookup and obtain a \", \"country/region or even city of origin for that message.\\nSerilog is a logging library for .NET langua\", \"ges, which allows for parameterized logging. Instead of\\ngenerating a textual log message that embeds\", \" fields, parameters are kept separate. This library allows\\nfor more intelligent filtering and search\", \"ing. A sample Serilog configuration for writing to Logstash\\nappears in Figure 7-7.\\nvar log = new Log\", \"gerConfiguration()\\n.WriteTo.Http(\\\"http://localhost:8080\\\")\\n.CreateLogger();\\nFigure 7-7. Serilog confi\", \"g for writing log information directly to logstash over HTTP\\nLogstash would use a configuration like\", \" the one shown in Figure 7-8.\\n132 CHAPTER 7 | Monitoring and healthinput {\\nhttp {\\n#default host 0.0.\", \"0.0:8080\\ncodec => json\\n}\\n}\\noutput {\\nelasticsearch {\\nhosts => \\\"elasticsearch:9200\\\"\\nindex=>\\\"sales-%{+x\", \"xxx.ww}\\\"\\n}\\n}\\nFigure 7-8. A Logstash configuration for consuming logs from Serilog\\nFor scenarios wher\", \"e extensive log manipulation isn\\u2019t needed there\\u2019s an alternative to Logstash known\\nas Beats. Beats i\", \"s a family of tools that can gather a wide variety of data from logs to network data\\nand uptime info\", \"rmation. Many applications will use both Logstash and Beats.\\nOnce the logs have been gathered by Log\", \"stash, it needs somewhere to put them. While Logstash\\nsupports many different outputs, one of the mo\", \"re exciting ones is Elasticsearch.\\nElasticsearch\\nElasticsearch is a powerful search engine that can \", \"index logs as they arrive. It makes running queries\\nagainst the logs quick. Elasticsearch can handle\", \" huge quantities of logs and, in extreme cases, can be\\nscaled out across many nodes.\\nLog messages th\", \"at have been crafted to contain parameters or that have had parameters split from\\nthem through Logst\", \"ash processing, can be queried directly as Elasticsearch preserves this information.\\nA query that se\", \"arches for the top 10 pages visited by jill@example.com, appears in Figure 7-9.\\n\\\"query\\\": {\\n\\\"match\\\": \", \"{\\n\\\"user\\\": \\\"jill@example.com\\\"\\n}\\n},\\n\\\"aggregations\\\": {\\n\\\"top_10_pages\\\": {\\n\\\"terms\\\": {\\n\\\"field\\\": \\\"page\\\",\\n\\\"s\", \"ize\\\": 10\\n}\\n}\\n}\\nFigure 7-9. An Elasticsearch query for finding top 10 pages visited by a user\\nVisuali\", \"zing information with Kibana web dashboards\\nThe final component of the stack is Kibana. This tool is\", \" used to provide interactive visualizations in a\\nweb dashboard. Dashboards may be crafted even by us\", \"ers who are non-technical. Most data that is\\nresident in the Elasticsearch index, can be included in\", \" the Kibana dashboards. Individual users may\\n133 CHAPTER 7 | Monitoring and healthhave different das\", \"hboard desires and Kibana enables this customization through allowing user-\\nspecific dashboards.\\nIns\", \"talling Elastic Stack on Azure\\nThe Elastic stack can be installed on Azure in many ways. As always, \", \"it\\u2019s possible to provision virtual\\nmachines and install Elastic Stack on them directly. This option \", \"is preferred by some experienced users\\nas it offers the highest degree of customizability. Deploying\", \" on infrastructure as a service introduces\\nsignificant management overhead forcing those who take th\", \"at path to take ownership of all the tasks\\nassociated with infrastructure as a service such as secur\", \"ing the machines and keeping up-to-date with\\npatches.\\nAn option with less overhead is to make use of\", \" one of the many Docker containers on which the\\nElastic Stack has already been configured. These con\", \"tainers can be dropped into an existing\\nKubernetes cluster and run alongside application code. The s\", \"ebp/elk container is a well-documented\\nand tested Elastic Stack container.\\nAnother option is a recen\", \"tly announced ELK-as-a-service offering.\\nReferences\\n\\u2022 Install Elastic Stack on Azure\\nMonitoring in A\", \"zure Kubernetes Services\\nThe built-in logging in Kubernetes is primitive. However, there are some gr\", \"eat options for getting the\\nlogs out of Kubernetes and into a place where they can be properly analy\", \"zed. If you need to monitor\\nyour AKS clusters, configuring Elastic Stack for Kubernetes is a great s\", \"olution.\\nAzure Monitor for Containers\\nAzure Monitor for Containers supports consuming logs from not \", \"just Kubernetes but also from other\\norchestration engines such as DC/OS, Docker Swarm, and Red Hat O\", \"penShift.\\n134 CHAPTER 7 | Monitoring and healthFigure 7-10. Consuming logs from various containers\\nP\", \"rometheus is a popular open source metric monitoring solution. It is part of the Cloud Native\\nComput\", \"e Foundation. Typically, using Prometheus requires managing a Prometheus server with its\\nown store. \", \"However, Azure Monitor for Containers provides direct integration with Prometheus\\nmetrics endpoints,\", \" so a separate server is not required.\\nLog and metric information is gathered not just from the cont\", \"ainers running in the cluster but also\\nfrom the cluster hosts themselves. It allows correlating log \", \"information from the two making it much\\neasier to track down an error.\\nInstalling the log collectors\", \" differs on Windows and Linux clusters. But in both cases the log collection\\nis implemented as a Kub\", \"ernetes DaemonSet, meaning that the log collector is run as a container on\\neach of the nodes.\\nNo mat\", \"ter which orchestrator or operating system is running the Azure Monitor daemon, the log\\ninformation \", \"is forwarded to the same Azure Monitor tools with which users are familiar. This approach\\nensures a \", \"parallel experience in environments that mix different log sources such as a hybrid\\nKubernetes/Azure\", \" Functions environment.\\n135 CHAPTER 7 | Monitoring and healthFigure 7-11. A sample dashboard showing\", \" logging and metric information from many running containers.\\nLog.Finalize()\\nLogging is one of the m\", \"ost overlooked and yet most important parts of deploying any application at\\nscale. As the size and c\", \"omplexity of applications increase, then so does the difficulty of debugging\\nthem. Having top qualit\", \"y logs available makes debugging much easier and moves it from the realm of\\n\\u201cnearly impossible\\u201d to \\u201c\", \"a pleasant experience\\u201d.\\nAzure Monitor\\nNo other cloud provider has as mature of a cloud application m\", \"onitoring solution than that found in\\nAzure. Azure Monitor is an umbrella name for a collection of t\", \"ools designed to provide visibility into\\nthe state of your system. It helps you understand how your \", \"cloud-native services are performing and\\nproactively identifies issues affecting them. Figure 7-12 p\", \"resents a high level of view of Azure Monitor.\\n136 CHAPTER 7 | Monitoring and healthFigure 7-12. Hig\", \"h-level view of Azure Monitor.\\nGathering logs and metrics\\nThe first step in any monitoring solution \", \"is to gather as much data as possible. The more data\\ngathered, the deeper the insights. Instrumentin\", \"g systems has traditionally been difficult. Simple\\nNetwork Management Protocol (SNMP) was the gold s\", \"tandard protocol for collecting machine level\\ninformation, but it required a great deal of knowledge\", \" and configuration. Fortunately, much of this\\nhard work has been eliminated as the most common metri\", \"cs are gathered automatically by Azure\\nMonitor.\\nApplication level metrics and events aren\\u2019t possible\", \" to instrument automatically because they\\u2019re\\nspecific to the application being deployed. In order to\", \" gather these metrics, there are SDKs and APIs\\navailable to directly report such information, such a\", \"s when a customer signs up or completes an order.\\nExceptions can also be captured and reported back \", \"into Azure Monitor via Application Insights. The\\nSDKs support most every language found in Cloud Nat\", \"ive Applications including Go, Python,\\nJavaScript, and the .NET languages.\\nThe ultimate goal of gath\", \"ering information about the state of your application is to ensure that your\\nend users have a good e\", \"xperience. What better way to tell if users are experiencing issues than doing\\noutside-in web tests?\", \" These tests can be as simple as pinging your website from locations around the\\nworld or as involved\", \" as having agents log into the site and simulate user actions.\\nReporting data\\nOnce the data is gathe\", \"red, it can be manipulated, summarized, and plotted into charts, which allow\\nusers to instantly see \", \"when there are problems. These charts can be gathered into dashboards or into\\nWorkbooks, a multi-pag\", \"e report designed to tell a story about some aspect of the system.\\n137 CHAPTER 7 | Monitoring and he\", \"althNo modern application would be complete without some artificial intelligence or machine learning\", \". To\\nthis end, data can be passed to the various machine learning tools in Azure to allow you to ext\", \"ract\\ntrends and information that would otherwise be hidden.\\nApplication Insights provides a powerful\", \" (SQL-like) query language called Kusto that can query\\nrecords, summarize them, and even plot charts\", \". For example, the following query will locate all records\\nfor the month of November 2007, group the\", \"m by state, and plot the top 10 as a pie chart.\\nStormEvents\\n| where StartTime >= datetime(2007-11-01\", \") and StartTime < datetime(2007-12-01)\\n| summarize count() by State\\n| top 10 by count_\\n| render piec\", \"hart\\nFigure 7-13 shows the results of this Application Insights Query.\\nFigure 7-13. Application Insi\", \"ghts query results.\\nThere is a playground for experimenting with Kusto queries. Reading sample queri\", \"es can also be\\ninstructive.\\nDashboards\\nThere are several different dashboard technologies that may b\", \"e used to surface the information from\\nAzure Monitor. Perhaps the simplest is to just run queries in\", \" Application Insights and plot the data\\ninto a chart.\\n138 CHAPTER 7 | Monitoring and healthFigure 7-\", \"14. An example of Application Insights charts embedded in the main Azure Dashboard.\\nThese charts can\", \" then be embedded in the Azure portal proper through use of the dashboard feature.\\nFor users with mo\", \"re exacting requirements, such as being able to drill down into several tiers of data,\\nAzure Monitor\", \" data is available to Power BI. Power BI is an industry-leading, enterprise class, business\\nintellig\", \"ence tool that can aggregate data from many different data sources.\\n139 CHAPTER 7 | Monitoring and h\", \"ealthFigure 7-15. An example Power BI dashboard.\\nAlerts\\nSometimes, having data dashboards is insuffi\", \"cient. If nobody is awake to watch the dashboards, then\\nit can still be many hours before a problem \", \"is addressed, or even detected. To this end, Azure Monitor\\nalso provides a top notch alerting soluti\", \"on. Alerts can be triggered by a wide range of conditions\\nincluding:\\n\\u2022 Metric values\\n\\u2022 Log search qu\", \"eries\\n\\u2022 Activity Log events\\n\\u2022 Health of the underlying Azure platform\\n\\u2022 Tests for web site availabil\", \"ity\\nWhen triggered, the alerts can perform a wide variety of tasks. On the simple side, the alerts m\", \"ay just\\nsend an e-mail notification to a mailing list or a text message to an individual. More invol\", \"ved alerts\\n140 CHAPTER 7 | Monitoring and healthmight trigger a workflow in a tool such as PagerDuty\", \", which is aware of who is on call for a particular\\napplication. Alerts can trigger actions in Micro\", \"soft Flow unlocking near limitless possibilities for\\nworkflows.\\nAs common causes of alerts are ident\", \"ified, the alerts can be enhanced with details about the common\\ncauses of the alerts and the steps t\", \"o take to resolve them. Highly mature cloud-native application\\ndeployments may opt to kick off self-\", \"healing tasks, which perform actions such as removing failing\\nnodes from a scale set or triggering a\", \"n autoscaling activity. Eventually it may no longer be necessary\\nto wake up on-call personnel at 2AM\", \" to resolve a live-site issue as the system will be able to adjust\\nitself to compensate or at least \", \"limp along until somebody arrives at work the next morning.\\nAzure Monitor automatically leverages ma\", \"chine learning to understand the normal operating\\nparameters of deployed applications. This approach\", \" enables it to detect services that are operating\\noutside of their normal parameters. For instance, \", \"the typical weekday traffic on the site might be\\n10,000 requests per minute. And then, on a given we\", \"ek, suddenly the number of requests hits a highly\\nunusual 20,000 requests per minute. Smart Detectio\", \"n will notice this deviation from the norm and\\ntrigger an alert. At the same time, the trend analysi\", \"s is smart enough to avoid firing false positives\\nwhen the traffic load is expected.\\nReferences\\n\\u2022 Az\", \"ure Monitor\\n141 CHAPTER 7 | Monitoring and health8\\nCHAPTER\\nCloud-native identity\\nMost software appli\", \"cations need to have some knowledge of the user or process that is calling them.\\nThe user or process\", \" interacting with an application is known as a security principal, and the process of\\nauthenticating\", \" and authorizing these principals is known as identity management, or simply identity.\\nSimple applic\", \"ations may include all of their identity management within the application, but this\\napproach doesn\\u2019\", \"t scale well with many applications and many kinds of security principals. Windows\\nsupports the use \", \"of Active Directory to provide centralized authentication and authorization.\\nWhile this solution is \", \"effective within corporate networks, it isn\\u2019t designed for use by users or\\napplications that are out\", \"side of the AD domain. With the growth of Internet-based applications and\\nthe rise of cloud-native a\", \"pps, security models have evolved.\\nIn today\\u2019s cloud-native identity model, architecture is assumed t\", \"o be distributed. Apps can be\\ndeployed anywhere and may communicate with other apps anywhere. Client\", \"s may communicate with\\nthese apps from anywhere, and in fact, clients may consist of any combination\", \" of platforms and\\ndevices. Cloud-native identity solutions use open standards to achieve secure appl\", \"ication access from\\nclients. These clients range from human users on PCs or phones, to other apps ho\", \"sted anywhere\\nonline, to set-top boxes and IOT devices running any software platform anywhere in the\", \" world.\\nModern cloud-native identity solutions typically use access tokens that are issued by a secu\", \"re token\\nservice/server (STS) to a security principal once their identity is determined. The access \", \"token, typically\\na JSON Web Token (JWT), includes claims about the security principal. These claims \", \"will minimally\\ninclude the user\\u2019s identity but may also include other claims that can be used by app\", \"lications to\\ndetermine the level of access to grant the principal.\\nTypically, the STS is only respon\", \"sible for authenticating the principal. Determining their level of access\\nto resources is left to ot\", \"her parts of the application.\\nReferences\\n\\u2022 Microsoft identity platform\\nAuthentication and authorizat\", \"ion in cloud-native\\napps\\nAuthentication is the process of determining the identity of a security pri\", \"ncipal. Authorization is the act\\nof granting an authenticated principal permission to perform an act\", \"ion or access a resource.\\nSometimes authentication is shortened to AuthN and authorization is shorte\", \"ned to AuthZ. Cloud-\\n142 CHAPTER 8 | Cloud-native identitynative applications need to rely on open H\", \"TTP-based protocols to authenticate security principals\\nsince both clients and applications could be\", \" running anywhere in the world on any platform or device.\\nThe only common factor is HTTP.\\nMany organ\", \"izations still rely on local authentication services like Active Directory Federation Services\\n(ADFS\", \"). While this approach has traditionally served organizations well for on premises authentication\\nne\", \"eds, cloud-native applications benefit from systems designed specifically for the cloud. A recent\\n20\", \"19 United Kingdom National Cyber Security Centre (NCSC) advisory states that \\u201corganizations using\\nAz\", \"ure AD as their primary authentication source will actually lower their risk compared to ADFS.\\u201d\\nSome\", \" reasons outlined in this analysis include:\\n\\u2022 Access to full set of Microsoft credential protection \", \"technologies.\\n\\u2022 Most organizations are already relying on Azure AD to some extent.\\n\\u2022 Double hashing \", \"of NTLM hashes ensures compromise won\\u2019t allow credentials that work in\\nlocal Active Directory.\\nRefer\", \"ences\\n\\u2022 Authentication basics\\n\\u2022 Access tokens and claims\\n\\u2022 It may be time to ditch your on premises \", \"authentication services\\nAzure Active Directory\\nMicrosoft Azure Active Directory (Azure AD) offers id\", \"entity and access management as a service.\\nCustomers use it to configure and maintain who users are,\", \" what information to store about them, who\\ncan access that information, who can manage it, and what \", \"apps can access it. AAD can authenticate\\nusers for applications configured to use it, providing a si\", \"ngle sign-on (SSO) experience. It can be used\\non its own or be integrated with Windows AD running on\", \" premises.\\nAzure AD is built for the cloud. It\\u2019s truly a cloud-native identity solution that uses a \", \"REST-based Graph\\nAPI and OData syntax for queries, unlike Windows AD, which uses LDAP. On premises A\", \"ctive Directory\\ncan sync user attributes to the cloud using Identity Sync Services, allowing all aut\", \"hentication to take\\nplace in the cloud using Azure AD. Alternately, authentication can be configured\", \" via Connect to pass\\nback to local Active Directory via ADFS to be completed by Windows AD on premis\", \"es.\\nAzure AD supports company branded sign-in screens, multi-factory authentication, and cloud-based\", \"\\napplication proxies that are used to provide SSO for applications hosted on premises. It offers\\ndif\", \"ferent kinds of security reporting and alert capabilities.\\nReferences\\n\\u2022 Microsoft identity platform\\n\", \"143 CHAPTER 8 | Cloud-native identityIdentityServer for cloud-native applications\\nIdentityServer is \", \"an authentication server that implements OpenID Connect (OIDC) and OAuth 2.0\\nstandards for ASP.NET C\", \"ore. It\\u2019s designed to provide a common way to authenticate requests to all of\\nyour applications, whe\", \"ther they\\u2019re web, native, mobile, or API endpoints. IdentityServer can be used to\\nimplement Single S\", \"ign-On (SSO) for multiple applications and application types. It can be used to\\nauthenticate actual \", \"users via sign-in forms and similar user interfaces as well as service-based\\nauthentication that typ\", \"ically involves token issuance, verification, and renewal without any user\\ninterface. IdentityServer\", \" is designed to be a customizable solution. Each instance is typically\\ncustomized to suit an individ\", \"ual organization and/or set of applications\\u2019 needs.\\nCommon web app scenarios\\nTypically, applications\", \" need to support some or all of the following scenarios:\\n\\u2022 Human users accessing web applications wi\", \"th a browser.\\n\\u2022 Human users accessing back-end Web APIs from browser-based apps.\\n\\u2022 Human users on mo\", \"bile/native clients accessing back-end Web APIs.\\n\\u2022 Other applications accessing back-end Web APIs (w\", \"ithout an active user or user interface).\\n\\u2022 Any application may need to interact with other Web APIs\", \", using its own identity or\\ndelegating to the user\\u2019s identity.\\nFigure 8-1. Application types and sce\", \"narios.\\nIn each of these scenarios, the exposed functionality needs to be secured against unauthoriz\", \"ed use. At\\na minimum, this typically requires authenticating the user or principal making a request \", \"for a resource.\\nThis authentication may use one of several common protocols such as SAML2p, WS-Fed, \", \"or OpenID\\nConnect. Communicating with APIs typically uses the OAuth2 protocol and its support for se\", \"curity\\ntokens. Separating these critical cross-cutting security concerns and their implementation de\", \"tails from\\nthe applications themselves ensures consistency and improves security and maintainability\", \".\\n144 CHAPTER 8 | Cloud-native identityOutsourcing these concerns to a dedicated product like Identi\", \"tyServer helps the requirement for every\\napplication to solve these problems itself.\\nIdentityServer \", \"provides middleware that runs within an ASP.NET Core application and adds support\\nfor OpenID Connect\", \" and OAuth2 (see supported specifications). Organizations would create their own\\nASP.NET Core app us\", \"ing IdentityServer middleware to act as the STS for all of their token-based\\nsecurity protocols. The\", \" IdentityServer middleware exposes endpoints to support standard\\nfunctionality, including:\\n\\u2022 Authori\", \"ze (authenticate the end user)\\n\\u2022 Token (request a token programmatically)\\n\\u2022 Discovery (metadata abou\", \"t the server)\\n\\u2022 User Info (get user information with a valid access token)\\n\\u2022 Device Authorization (u\", \"sed to start device flow authorization)\\n\\u2022 Introspection (token validation)\\n\\u2022 Revocation (token revoc\", \"ation)\\n\\u2022 End Session (trigger single sign-out across all apps)\\nGetting started\\nIdentityServer4 is av\", \"ailable under dual license:\\n\\u2022 RPL - lets you use the IdentityServer4 free if used in open-source wor\", \"k\\n\\u2022 Paid - lets you use the IdentityServer4 in a commercial scenario\\nFor more information about pric\", \"ing, see the official product\\u2019s pricing page.\\nYou can add it to your applications using its NuGet pa\", \"ckages. The main package is IdentityServer4,\\nwhich has been downloaded over four million times. The \", \"base package doesn\\u2019t include any user\\ninterface code and only supports in-memory configuration. To u\", \"se it with a database, you\\u2019ll also want\\na data provider like IdentityServer4.EntityFramework, which \", \"uses Entity Framework Core to store\\nconfiguration and operational data for IdentityServer. For user \", \"interface, you can copy files from the\\nQuickstart UI repository into your ASP.NET Core MVC applicati\", \"on to add support for sign in and sign\\nout using IdentityServer middleware.\\nConfiguration\\nIdentitySe\", \"rver supports different kinds of protocols and social authentication providers that can be\\nconfigure\", \"d as part of each custom installation. This is typically done in the ASP.NET Core application\\u2019s\\nProg\", \"ram class (or in the Startup class in the ConfigureServices method). The configuration involves\\nspec\", \"ifying the supported protocols and the paths to the servers and endpoints that will be used.\\nFigure \", \"8-2 shows an example configuration taken from the IdentityServer4 Quickstart UI project:\\npublic clas\", \"s Startup\\n{\\npublic void ConfigureServices(IServiceCollection services)\\n{\\nservices.AddMvc();\\n145 CHAP\", \"TER 8 | Cloud-native identity// some details omitted\\nservices.AddIdentityServer();\\nservices.AddAuthe\", \"ntication()\\n.AddGoogle(\\\"Google\\\", options =>\\n{\\noptions.SignInScheme =\\nIdentityServerConstants.Externa\", \"lCookieAuthenticationScheme;\\noptions.ClientId = \\\"<insert here>\\\";\\noptions.ClientSecret = \\\"<insert her\", \"e>\\\";\\n})\\n.AddOpenIdConnect(\\\"demoidsrv\\\", \\\"IdentityServer\\\", options =>\\n{\\noptions.SignInScheme =\\nIdentit\", \"yServerConstants.ExternalCookieAuthenticationScheme;\\noptions.SignOutScheme = IdentityServerConstants\", \".SignoutScheme;\\noptions.Authority = \\\"https://demo.identityserver.io/\\\";\\noptions.ClientId = \\\"implicit\\\"\", \";\\noptions.ResponseType = \\\"id_token\\\";\\noptions.SaveTokens = true;\\noptions.CallbackPath = new PathStrin\", \"g(\\\"/signin-idsrv\\\");\\noptions.SignedOutCallbackPath = new PathString(\\\"/signout-callback-idsrv\\\");\\noptio\", \"ns.RemoteSignOutPath = new PathString(\\\"/signout-idsrv\\\");\\noptions.TokenValidationParameters = new Tok\", \"enValidationParameters\\n{\\nNameClaimType = \\\"name\\\",\\nRoleClaimType = \\\"role\\\"\\n};\\n});\\n}\\n}\\nFigure 8-2. Confi\", \"guring IdentityServer.\\nJavaScript clients\\nMany cloud-native applications use server-side APIs and ri\", \"ch client single page applications (SPAs) on\\nthe front end. IdentityServer ships a JavaScript client\", \" (oidc-client.js) via NPM that can be added to\\nSPAs to enable them to use IdentityServer for sign in\", \", sign out, and token-based authentication of\\nweb APIs.\\nReferences\\n\\u2022 IdentityServer documentation\\n\\u2022 \", \"Application types\\n\\u2022 JavaScript OIDC client\\n146 CHAPTER 8 | Cloud-native identity9\\nCHAPTER\\nCloud-nati\", \"ve security\\nNot a day goes by where the news doesn\\u2019t contain some story about a company being hacked\", \" or\\nsomehow losing their customers\\u2019 data. Even countries/regions aren\\u2019t immune to the problems creat\", \"ed\\nby treating security as an afterthought. For years, companies have treated the security of custom\", \"er\\ndata and, in fact, their entire networks as something of a \\u201cnice to have\\u201d. Windows servers were l\", \"eft\\nunpatched, ancient versions of PHP kept running, and MongoDB databases left wide open to the\\nwor\", \"ld.\\nHowever, there are starting to be real-world consequences for not maintaining a security mindset\", \"\\nwhen building and deploying applications. Many companies learned the hard way what can happen\\nwhen \", \"servers and desktops aren\\u2019t patched during the 2017 outbreak of NotPetya. The cost of these\\nattacks \", \"has easily reached into the billions, with some estimates putting the losses from this single\\nattack\", \" at 10 billion US dollars.\\nEven governments aren\\u2019t immune to hacking incidents. The city of Baltimor\", \"e was held ransom by\\ncriminals making it impossible for citizens to pay their bills or use city serv\", \"ices.\\nThere has also been an increase in legislation that mandates certain data protections for pers\", \"onal\\ndata. In Europe, GDPR has been in effect for more than a year and, more recently, California pa\", \"ssed\\ntheir own version called CCDA, which comes into effect January 1, 2020. The fines under GDPR ca\", \"n be\\nso punishing as to put companies out of business. Google has already been fined 50 million Euro\", \"s for\\nviolations, but that\\u2019s just a drop in the bucket compared with the potential fines.\\nIn short, \", \"security is serious business.\\nAzure security for cloud-native apps\\nCloud-native applications can be \", \"both easier and more difficult to secure than traditional applications.\\nOn the downside, you need to\", \" secure more smaller applications and dedicate more energy to build\\nout the security infrastructure.\", \" The heterogeneous nature of programming languages and styles in\\nmost service deployments also means\", \" you need to pay more attention to security bulletins from many\\ndifferent providers.\\nOn the flip sid\", \"e, smaller services, each with their own data store, limit the scope of an attack. If an\\nattacker co\", \"mpromises one system, it\\u2019s probably more difficult for the attacker to make the jump to\\nanother syst\", \"em than it is in a monolithic application. Process boundaries are strong boundaries. Also,\\nif a data\", \"base backup gets exposed, then the damage is more limited, as that database contains only a\\nsubset o\", \"f data and is unlikely to contain personal data.\\n147 CHAPTER 9 | Cloud-native securityThreat modelin\", \"g\\nNo matter if the advantages outweigh the disadvantages of cloud-native applications, the same\\nholi\", \"stic security mindset must be followed. Security and secure thinking must be part of every step of\\nt\", \"he development and operations story. When planning an application ask questions like:\\n\\u2022 What would b\", \"e the impact of this data being lost?\\n\\u2022 How can we limit the damage from bad data being injected int\", \"o this service?\\n\\u2022 Who should have access to this data?\\n\\u2022 Are there auditing policies in place around\", \" the development and release process?\\nAll these questions are part of a process called threat modeli\", \"ng. This process tries to answer the\\nquestion of what threats there are to the system, how likely th\", \"e threats are, and the potential damage\\nfrom them.\\nOnce the list of threats has been established, yo\", \"u need to decide whether they\\u2019re worth mitigating.\\nSometimes a threat is so unlikely and expensive t\", \"o plan for that it isn\\u2019t worth spending energy on it.\\nFor instance, some state level actor could inj\", \"ect changes into the design of a process that is used by\\nmillions of devices. Now, instead of runnin\", \"g a certain piece of code in Ring 3, that code is run in Ring\\n0. This process allows an exploit that\", \" can bypass the hypervisor and run the attack code on the bare\\nmetal machines, allowing attacks on a\", \"ll the virtual machines that are running on that hardware.\\nThe altered processors are difficult to d\", \"etect without a microscope and advanced knowledge of the on\\nsilicon design of that processor. This s\", \"cenario is unlikely to happen and expensive to mitigate, so\\nprobably no threat model would recommend\", \" building exploit protection for it.\\nMore likely threats, such as broken access controls permitting \", \"Id incrementing attacks (replacing Id=2\\nwith Id=3 in the URL) or SQL injection, are more attractive \", \"to build protections against. The\\nmitigations for these threats are quite reasonable to build and pr\", \"event embarrassing security holes\\nthat smear the company\\u2019s reputation.\\nPrinciple of least privilege\\n\", \"One of the founding ideas in computer security is the Principle of Least Privilege (POLP). It\\u2019s actu\", \"ally a\\nfoundational idea in most any form of security be it digital or physical. In short, the princ\", \"iple is that\\nany user or process should have the smallest number of rights possible to execute its t\", \"ask.\\nAs an example, think of the tellers at a bank: accessing the safe is an uncommon activity. So, \", \"the\\naverage teller can\\u2019t open the safe themselves. To gain access, they need to escalate their reque\", \"st\\nthrough a bank manager, who performs additional security checks.\\nIn a computer system, a fantasti\", \"c example is the rights of a user connecting to a database. In many\\ncases, there\\u2019s a single user acc\", \"ount used to both build the database structure and run the application.\\nExcept in extreme cases, the\", \" account running the application doesn\\u2019t need the ability to update\\nschema information. There should\", \" be several accounts that provide different levels of privilege. The\\napplication should only use the\", \" permission level that grants read and writes access to the data in the\\ntables. This kind of protect\", \"ion would eliminate attacks that aimed to drop database tables or\\nintroduce malicious triggers.\\n148 \", \"CHAPTER 9 | Cloud-native securityAlmost every part of building a cloud-native application can benefi\", \"t from remembering the principle\\nof least privilege. You can find it at play when setting up firewal\", \"ls, network security groups, roles, and\\nscopes in Role-based access control (RBAC).\\nPenetration test\", \"ing\\nAs applications become more complicated the number of attack vectors increases at an alarming ra\", \"te.\\nThreat modeling is flawed in that it tends to be executed by the same people building the system\", \". In\\nthe same way that many developers have trouble envisioning user interactions and then build\\nunu\", \"sable user interfaces, most developers have difficulty seeing every attack vector. It\\u2019s also possibl\", \"e\\nthat the developers building the system aren\\u2019t well versed in attack methodologies and miss\\nsometh\", \"ing crucial.\\nPenetration testing or \\u201cpen testing\\u201d involves bringing in external actors to attempt to\", \" attack the\\nsystem. These attackers may be an external consulting company or other developers with g\", \"ood\\nsecurity knowledge from another part of the business. They\\u2019re given carte blanche to attempt to\\n\", \"subvert the system. Frequently, they\\u2019ll find extensive security holes that need to be patched.\\nSomet\", \"imes the attack vector will be something totally unexpected like exploiting a phishing attack\\nagains\", \"t the CEO.\\nAzure itself is constantly undergoing attacks from a team of hackers inside Microsoft. Ov\", \"er the years,\\nthey\\u2019ve been the first to find dozens of potentially catastrophic attack vectors, clos\", \"ing them before\\nthey can be exploited externally. The more tempting a target, the more likely that e\", \"ternal actors will\\nattempt to exploit it and there are a few targets in the world more tempting than\", \" Azure.\\nMonitoring\\nShould an attacker attempt to penetrate an application, there should be some warn\", \"ing of it.\\nFrequently, attacks can be spotted by examining the logs from services. Attacks leave tel\", \"ltale signs\\nthat can be spotted before they succeed. For instance, an attacker attempting to guess a\", \" password\\nwill make many requests to a login system. Monitoring around the login system can detect w\", \"eird\\npatterns that are out of line with the typical access pattern. This monitoring can be turned in\", \"to an\\nalert that can, in turn, alert an operations person to activate some sort of countermeasure. A\", \" highly\\nmature monitoring system might even take action based on these deviations proactively adding\", \" rules\\nto block requests or throttle responses.\\nSecuring the build\\nOne place where security is often\", \" overlooked is around the build process. Not only should the build\\nrun security checks, such as scan\", \"ning for insecure code or checked-in credentials, but the build itself\\nshould be secure. If the buil\", \"d server is compromised, then it provides a fantastic vector for introducing\\narbitrary code into the\", \" product.\\nImagine that an attacker is looking to steal the passwords of people signing into a web ap\", \"plication.\\nThey could introduce a build step that modifies the checked-out code to mirror any login \", \"request to\\nanother server. The next time code goes through the build, it\\u2019s silently updated. The sou\", \"rce code\\nvulnerability scanning won\\u2019t catch this vulnerability as it runs before the build. Equally,\", \" nobody will\\n149 CHAPTER 9 | Cloud-native securitycatch it in a code review because the build steps \", \"live on the build server. The exploited code will go to\\nproduction where it can harvest passwords. P\", \"robably there\\u2019s no audit log of the build process\\nchanges, or at least nobody monitoring the audit.\\n\", \"This scenario is a perfect example of a seemingly low-value target that can be used to break into th\", \"e\\nsystem. Once an attacker breaches the perimeter of the system, they can start working on finding\\nw\", \"ays to elevate their permissions to the point that they can cause real harm anywhere they like.\\nBuil\", \"ding secure code\\n.NET Framework is already a quite secure framework. It avoids some of the pitfalls \", \"of unmanaged\\ncode, such as walking off the ends of arrays. Work is actively done to fix security hol\", \"es as they\\u2019re\\ndiscovered. There\\u2019s even a bug bounty program that pays researchers to find issues in \", \"the framework\\nand report them instead of exploiting them.\\nThere are many ways to make .NET code more\", \" secure. Following guidelines such as the Secure coding\\nguidelines for .NET article is a reasonable \", \"step to take to ensure that the code is secure from the\\nground up. The OWASP top 10 is another inval\", \"uable guide to build secure code.\\nThe build process is a good place to put scanning tools to detect \", \"problems in source code before they\\nmake it into production. Most every project has dependencies on \", \"some other packages. A tool that\\ncan scan for outdated packages will catch problems in a nightly bui\", \"ld. Even when building Docker\\nimages, it\\u2019s useful to check and make sure that the base image doesn\\u2019t\", \" have known vulnerabilities.\\nAnother thing to check is that nobody has accidentally checked in crede\", \"ntials.\\nBuilt-in security\\nAzure is designed to balance usability and security for most users. Differ\", \"ent users are going to have\\ndifferent security requirements, so they need to fine-tune their approac\", \"h to cloud security. Microsoft\\npublishes a great deal of security information in the Trust Center. T\", \"his resource should be the first\\nstop for those professionals interested in understanding how the bu\", \"ilt-in attack mitigation\\ntechnologies work.\\nWithin the Azure portal, the Azure Advisor is a system t\", \"hat is constantly scanning an environment and\\nmaking recommendations. Some of these recommendations \", \"are designed to save users money, but\\nothers are designed to identify potentially insecure configura\", \"tions, such as having a storage container\\nopen to the world and not protected by a Virtual Network.\\n\", \"Azure network infrastructure\\nIn an on-premises deployment environment, a great deal of energy is ded\", \"icated to setting up\\nnetworking. Setting up routers, switches, and the such is complicated work. Net\", \"works allow certain\\nresources to talk to other resources and prevent access in some cases. A frequen\", \"t network rule is to\\nrestrict access to the production environment from the development environment \", \"on the off chance\\nthat a half-developed piece of code runs awry and deletes a swath of data.\\nOut of \", \"the box, most PaaS Azure resources have only the most basic and permissive networking setup.\\nFor ins\", \"tance, anybody on the Internet can access an app service. New SQL Server instances typically\\n150 CHA\", \"PTER 9 | Cloud-native securitycome restricted, so that external parties can\\u2019t access them, but the I\", \"P address ranges used by Azure\\nitself are permitted through. So, while the SQL server is protected f\", \"rom external threats, an attacker\\nonly needs to set up an Azure bridgehead from where they can launc\", \"h attacks against all SQL\\ninstances on Azure.\\nFortunately, most Azure resources can be placed into a\", \"n Azure Virtual Network that allows fine-\\ngrained access control. Similar to the way that on-premise\", \"s networks establish private networks that\\nare protected from the wider world, virtual networks are \", \"islands of private IP addresses that are\\nlocated within the Azure network.\\nFigure 9-1. A virtual net\", \"work in Azure.\\nIn the same way that on-premises networks have a firewall governing access to the net\", \"work, you can\\nestablish a similar firewall at the boundary of the virtual network. By default, all t\", \"he resources on a\\nvirtual network can still talk to the Internet. It\\u2019s only incoming connections tha\", \"t require some form of\\nexplicit firewall exception.\\nWith the network established, internal resources\", \" like storage accounts can be set up to only allow for\\naccess by resources that are also on the Virt\", \"ual Network. This firewall provides an extra level of\\nsecurity, should the keys for that storage acc\", \"ount be leaked, attackers wouldn\\u2019t be able to connect to\\nit to exploit the leaked keys. This scenari\", \"o is another example of the principle of least privilege.\\nThe nodes in an Azure Kubernetes cluster c\", \"an participate in a virtual network just like other resources\\nthat are more native to Azure. This fu\", \"nctionality is called Azure Container Networking Interface. In\\neffect, it allocates a subnet within \", \"the virtual network on which virtual machines and container images\\nare allocated.\\nContinuing down th\", \"e path of illustrating the principle of least privilege, not every resource within a\\nVirtual Network\", \" needs to talk to every other resource. For instance, in an application that provides a\\n151 CHAPTER \", \"9 | Cloud-native securityweb API over a storage account and a SQL database, it\\u2019s unlikely that the d\", \"atabase and the storage\\naccount need to talk to one another. Any data sharing between them would go \", \"through the web\\napplication. So, a network security group (NSG) could be used to deny traffic betwee\", \"n the two\\nservices.\\nA policy of denying communication between resources can be annoying to implement\", \", especially\\ncoming from a background of using Azure without traffic restrictions. On some other clo\", \"uds, the\\nconcept of network security groups is much more prevalent. For instance, the default policy\", \" on AWS is\\nthat resources can\\u2019t communicate among themselves until enabled by rules in an NSG. While\", \" slower\\nto develop this, a more restrictive environment provides a more secure default. Making use o\", \"f proper\\nDevOps practices, especially using Azure Resource Manager or Terraform to manage permission\", \"s can\\nmake controlling the rules easier.\\nVirtual Networks can also be useful when setting up communi\", \"cation between on-premises and cloud\\nresources. A virtual private network can be used to seamlessly \", \"attach the two networks together. This\\napproach allows running a virtual network without any sort of\", \" gateway for scenarios where all the\\nusers are on-site. There are a number of technologies that can \", \"be used to establish this network. The\\nsimplest is to use a site-to-site VPN that can be established\", \" between many routers and Azure. Traffic\\nis encrypted and tunneled over the Internet at the same cos\", \"t per byte as any other traffic. For\\nscenarios where more bandwidth or more security is desirable, A\", \"zure offers a service called Express\\nRoute that uses a private circuit between an on-premises networ\", \"k and Azure. It\\u2019s more costly and\\ndifficult to establish but also more secure.\\nRole-based access con\", \"trol for restricting access to Azure resources\\nRBAC is a system that provides an identity to applica\", \"tions running in Azure. Applications can access\\nresources using this identity instead of or in addit\", \"ion to using keys or passwords.\\nSecurity Principals\\nThe first component in RBAC is a security princi\", \"pal. A security principal can be a user, group, service\\nprincipal, or managed identity.\\nFigure 9-2. \", \"Different types of security principals.\\n\\u2022 User - Any user who has an account in Azure Active Directo\", \"ry is a user.\\n\\u2022 Group - A collection of users from Azure Active Directory. As a member of a group, a\", \" user\\ntakes on the roles of that group in addition to their own.\\n\\u2022 Service principal - A security id\", \"entity under which services or applications run.\\n152 CHAPTER 9 | Cloud-native security\\u2022 Managed iden\", \"tity - An Azure Active Directory identity managed by Azure. Managed identities\\nare typically used wh\", \"en developing cloud applications that manage the credentials for\\nauthenticating to Azure services.\\nT\", \"he security principal can be applied to most any resource. This aspect means that it\\u2019s possible to\\na\", \"ssign a security principal to a container running within Azure Kubernetes, allowing it to access sec\", \"rets\\nstored in Key Vault. An Azure Function could take on a permission allowing it to talk to an Act\", \"ive\\nDirectory instance to validate a JWT for a calling user. Once services are enabled with a servic\", \"e\\nprincipal, their permissions can be managed granularly using roles and scopes.\\nRoles\\nA security pr\", \"incipal can take on many roles or, using a more sartorial analogy, wear many hats. Each\\nrole defines\", \" a series of permissions such as \\u201cRead messages from Azure Service Bus endpoint\\u201d. The\\neffective perm\", \"ission set of a security principal is the combination of all the permissions assigned to all\\nthe rol\", \"es that a security principal has. Azure has a large number of built-in roles and users can define\\nth\", \"eir own roles.\\nFigure 9-3. RBAC role definitions.\\nBuilt into Azure are also a number of high-level r\", \"oles such as Owner, Contributor, Reader, and User\\nAccount Administrator. With the Owner role, a secu\", \"rity principal can access all resources and assign\\npermissions to others. A contributor has the same\", \" level of access to all resources but they can\\u2019t assign\\npermissions. A Reader can only view existing\", \" Azure resources and a User Account Administrator can\\nmanage access to Azure resources.\\nMore granula\", \"r built-in roles such as DNS Zone Contributor have rights limited to a single service.\\nSecurity prin\", \"cipals can take on any number of roles.\\n153 CHAPTER 9 | Cloud-native securityScopes\\nRoles can be app\", \"lied to a restricted set of resources within Azure. For instance, applying scope to the\\nprevious exa\", \"mple of reading from a Service Bus queue, you can narrow the permission to a single\\nqueue: \\u201cRead mes\", \"sages from Azure Service Bus endpoint blah.servicebus.windows.net/queue1\\u201d\\nThe scope can be as narrow\", \" as a single resource or it can be applied to an entire resource group,\\nsubscription, or even manage\", \"ment group.\\nWhen testing if a security principal has certain permission, the combination of role and\", \" scope are\\ntaken into account. This combination provides a powerful authorization mechanism.\\nDeny\\nPr\", \"eviously, only \\u201callow\\u201d rules were permitted for RBAC. This behavior made some scopes complicated\\nto \", \"build. For instance, allowing a security principal access to all storage accounts except one require\", \"d\\ngranting explicit permission to a potentially endless list of storage accounts. Every time a new s\", \"torage\\naccount was created, it would have to be added to this list of accounts. This added managemen\", \"t\\noverhead that certainly wasn\\u2019t desirable.\\nDeny rules take precedence over allow rules. Now represe\", \"nting the same \\u201callow all but one\\u201d scope\\ncould be represented as two rules \\u201callow all\\u201d and \\u201cdeny thi\", \"s one specific one\\u201d. Deny rules not only\\nease management but allow for resources that are extra secu\", \"re by denying access to everybody.\\nChecking access\\nAs you can imagine, having a large number of role\", \"s and scopes can make figuring out the effective\\npermission of a service principal quite difficult. \", \"Piling deny rules on top of that, only serves to increase\\nthe complexity. Fortunately, there\\u2019s a per\", \"missions calculator that can show the effective permissions\\nfor any service principal. It\\u2019s typicall\", \"y found under the IAM tab in the portal, as shown in Figure 9-3.\\nFigure 9-4. Permission calculator f\", \"or an app service.\\n154 CHAPTER 9 | Cloud-native securitySecuring secrets\\nPasswords and certificates \", \"are a common attack vector for attackers. Password-cracking hardware can\\ndo a brute-force attack and\", \" try to guess billions of passwords per second. So it\\u2019s important that the\\npasswords that are used t\", \"o access resources are strong, with a large variety of characters. These\\npasswords are exactly the k\", \"ind of passwords that are near impossible to remember. Fortunately, the\\npasswords in Azure don\\u2019t act\", \"ually need to be known by any human.\\nMany security experts suggest that using a password manager to \", \"keep your own passwords is the\\nbest approach. While it centralizes your passwords in one location, i\", \"t also allows using highly complex\\npasswords and ensuring they\\u2019re unique for each account. The same \", \"system exists within Azure: a\\ncentral store for secrets.\\nAzure Key Vault\\nAzure Key Vault provides a \", \"centralized location to store passwords for things such as databases, API\\nkeys, and certificates. On\", \"ce a secret is entered into the Vault, it\\u2019s never shown again and the\\ncommands to extract and view i\", \"t are purposefully complicated. The information in the safe is\\nprotected using either software encry\", \"ption or FIPS 140-2 Level 2 validated Hardware Security\\nModules.\\nAccess to the key vault is provided\", \" through RBACs, meaning that not just any user can access the\\ninformation in the vault. Say a web ap\", \"plication wishes to access the database connection string stored\\nin Azure Key Vault. To gain access,\", \" applications need to run using a service principal. Under this\\nassumed role, they can read the secr\", \"ets from the safe. There are a number of different security\\nsettings that can further limit the acce\", \"ss that an application has to the vault, so that it can\\u2019t update\\nsecrets but only read them.\\nAccess \", \"to the key vault can be monitored to ensure that only the expected applications are accessing\\nthe va\", \"ult. The logs can be integrated back into Azure Monitor, unlocking the ability to set up alerts\\nwhen\", \" unexpected conditions are encountered.\\nKubernetes\\nWithin Kubernetes, there\\u2019s a similar service for \", \"maintaining small pieces of secret information.\\nKubernetes Secrets can be set via the typical kubect\", \"l executable.\\nCreating a secret is as simple as finding the base64 version of the values to be store\", \"d:\\necho -n 'admin' | base64\\nYWRtaW4=\\necho -n '1f2d1e2e67df' | base64\\nMWYyZDFlMmU2N2Rm\\nThen adding it\", \" to a secrets file named secret.yml for example that looks similar to the following\\nexample:\\napiVers\", \"ion: v1\\nkind: Secret\\nmetadata:\\nname: mysecret\\n155 CHAPTER 9 | Cloud-native securitytype: Opaque\\ndata\", \":\\nusername: YWRtaW4=\\npassword: MWYyZDFlMmU2N2Rm\\nFinally, this file can be loaded into Kubernetes by \", \"running the following command:\\nkubectl apply -f ./secret.yaml\\nThese secrets can then be mounted into\", \" volumes or exposed to container processes through\\nenvironment variables. The Twelve-factor app appr\", \"oach to building applications suggests using the\\nlowest common denominator to transmit settings to a\", \"n application. Environment variables are the\\nlowest common denominator, because they\\u2019re supported no\", \" matter the operating system or\\napplication.\\nAn alternative to use the built-in Kubernetes secrets i\", \"s to access the secrets in Azure Key Vault from\\nwithin Kubernetes. The simplest way to do this is to\", \" assign an RBAC role to the container looking to\\nload secrets. The application can then use the Azur\", \"e Key Vault APIs to access the secrets. However,\\nthis approach requires modifications to the code an\", \"d doesn\\u2019t follow the pattern of using environment\\nvariables. Instead, it\\u2019s possible to inject values\", \" into a container. This approach is actually more secure\\nthan using the Kubernetes secrets directly,\", \" as they can be accessed by users on the cluster.\\nEncryption in transit and at rest\\nKeeping data saf\", \"e is important whether it\\u2019s on disk or transiting between various different services.\\nThe most effec\", \"tive way to keep data from leaking is to encrypt it into a format that can\\u2019t be easily read\\nby other\", \"s. Azure supports a wide range of encryption options.\\nIn transit\\nThere are several ways to encrypt t\", \"raffic on the network in Azure. The access to Azure services is\\ntypically done over connections that\", \" use Transport Layer Security (TLS). For instance, all the\\nconnections to the Azure APIs require TLS\", \" connections. Equally, connections to endpoints in Azure\\nstorage can be restricted to work only over\", \" TLS encrypted connections.\\nTLS is a complicated protocol and simply knowing that the connection is \", \"using TLS isn\\u2019t sufficient to\\nensure security. For instance, TLS 1.0 is chronically insecure, and TL\", \"S 1.1 isn\\u2019t much better. Even within\\nthe versions of TLS, there are various settings that can make t\", \"he connections easier to decrypt. The\\nbest course of action is to check and see if the server connec\", \"tion is using up-to-date and well\\nconfigured protocols.\\nThis check can be done by an external servic\", \"e such as SSL labs\\u2019 SSL Server Test. A test run against a\\ntypical Azure endpoint, in this case a ser\", \"vice bus endpoint, yields a near perfect score of A.\\nEven services like Azure SQL databases use TLS \", \"encryption to keep data hidden. The interesting part\\nabout encrypting the data in transit using TLS \", \"is that it isn\\u2019t possible, even for Microsoft, to listen in on\\nthe connection between computers runn\", \"ing TLS. This should provide comfort for companies\\nconcerned that their data may be at risk from Mic\", \"rosoft proper or even a state actor with more\\nresources than the standard attacker.\\n156 CHAPTER 9 | \", \"Cloud-native securityFigure 9-5. SSL labs report showing a score of A for a Service Bus endpoint.\\nWh\", \"ile this level of encryption isn\\u2019t going to be sufficient for all time, it should inspire confidence\", \" that\\nAzure TLS connections are quite secure. Azure will continue to evolve its security standards a\", \"s\\nencryption improves. It\\u2019s nice to know that there\\u2019s somebody watching the security standards and\\nu\", \"pdating Azure as they improve.\\nAt rest\\nIn any application, there are a number of places where data r\", \"ests on the disk. The application code\\nitself is loaded from some storage mechanism. Most applicatio\", \"ns also use some kind of a database\\nsuch as SQL Server, Cosmos DB, or even the amazingly price-effic\", \"ient Table Storage. These databases\\nall use heavily encrypted storage to ensure that nobody other th\", \"an the applications with proper\\npermissions can read your data. Even the system operators can\\u2019t read\", \" data that has been encrypted.\\nSo customers can remain confident their secret information remains se\", \"cret.\\nStorage\\nThe underpinning of much of Azure is the Azure Storage engine. Virtual machine disks a\", \"re mounted\\non top of Azure Storage. Azure Kubernetes Service runs on virtual machines that, themselv\", \"es, are\\nhosted on Azure Storage. Even serverless technologies, such as Azure Functions Apps and Azur\", \"e\\nContainer Instances, run out of disk that is part of Azure Storage.\\nIf Azure Storage is well encry\", \"pted, then it provides for a foundation for most everything else to also\\nbe encrypted. Azure Storage\", \" is encrypted with FIPS 140-2 compliant 256-bit AES. This is a well-\\nregarded encryption technology \", \"having been the subject of extensive academic scrutiny over the last\\n20 or so years. At present, the\", \"re\\u2019s no known practical attack that would allow someone without\\nknowledge of the key to read data en\", \"crypted by AES.\\nBy default, the keys used for encrypting Azure Storage are managed by Microsoft. The\", \"re are extensive\\nprotections in place to ensure to prevent malicious access to these keys. However, \", \"users with\\nparticular encryption requirements can also provide their own storage keys that are manag\", \"ed in Azure\\n157 CHAPTER 9 | Cloud-native securityKey Vault. These keys can be revoked at any time, w\", \"hich would effectively render the contents of the\\nStorage account using them inaccessible.\\nVirtual m\", \"achines use encrypted storage, but it\\u2019s possible to provide another layer of encryption by\\nusing tec\", \"hnologies like BitLocker on Windows or DM-Crypt on Linux. These technologies mean that\\neven if the d\", \"isk image was leaked off of storage, it would remain near impossible to read it.\\nAzure SQL\\nDatabases\", \" hosted on Azure SQL use a technology called Transparent Data Encryption (TDE) to ensure\\ndata remain\", \"s encrypted. It\\u2019s enabled by default on all newly created SQL databases, but must be\\nenabled manuall\", \"y for legacy databases. TDE executes real-time encryption and decryption of not just\\nthe database, b\", \"ut also the backups and transaction logs.\\nThe encryption parameters are stored in the master databas\", \"e and, on startup, are read into memory\\nfor the remaining operations. This means that the master dat\", \"abase must remain unencrypted. The\\nactual key is managed by Microsoft. However, users with exacting \", \"security requirements may provide\\ntheir own key in Key Vault in much the same way as is done for Azu\", \"re Storage. The Key Vault provides\\nfor such services as key rotation and revocation.\\nThe \\u201cTransparen\", \"t\\u201d part of TDS comes from the fact that there aren\\u2019t client changes needed to use an\\nencrypted datab\", \"ase. While this approach provides for good security, leaking the database password is\\nenough for use\", \"rs to be able to decrypt the data. There\\u2019s another approach that encrypts individual\\ncolumns or tabl\", \"es in a database. Always Encrypted ensures that at no point the encrypted data\\nappears in plain text\", \" inside the database.\\nSetting up this tier of encryption requires running through a wizard in SQL Se\", \"rver Management Studio\\nto select the sort of encryption and where in Key Vault to store the associat\", \"ed keys.\\n158 CHAPTER 9 | Cloud-native securityFigure 9-6. Selecting columns in a table to be encrypt\", \"ed using Always Encrypted.\\nClient applications that read information from these encrypted columns ne\", \"ed to make special\\nallowances to read encrypted data. Connection strings need to be updated with Col\", \"umn Encryption\\nSetting=Enabled and client credentials must be retrieved from the Key Vault. The SQL \", \"Server client\\nmust then be primed with the column encryption keys. Once that is done, the remaining \", \"actions use\\nthe standard interfaces to SQL Client. That is, tools like Dapper and Entity Framework, \", \"which are built\\non top of SQL Client, will continue to work without changes. Always Encrypted may no\", \"t yet be\\navailable for every SQL Server driver on every language.\\nThe combination of TDE and Always \", \"Encrypted, both of which can be used with client-specific keys,\\nensures that even the most exacting \", \"encryption requirements are supported.\\nCosmos DB\\nCosmos DB is the newest database provided by Micros\", \"oft in Azure. It has been built from the ground\\nup with security and cryptography in mind. AES-256bi\", \"t encryption is standard for all Cosmos DB\\n159 CHAPTER 9 | Cloud-native securitydatabases and can\\u2019t \", \"be disabled. Coupled with the TLS 1.2 requirement for communication, the entire\\nstorage solution is \", \"encrypted.\\nFigure 9-7. The flow of data encryption within Cosmos DB.\\nWhile Cosmos DB doesn\\u2019t provide\", \" for supplying customer encryption keys, there has been significant\\nwork done by the team to ensure \", \"it remains PCI-DSS compliant without that. Cosmos DB also doesn\\u2019t\\nsupport any sort of single column \", \"encryption similar to Azure SQL\\u2019s Always Encrypted yet.\\nKeeping secure\\nAzure has all the tools neces\", \"sary to release a highly secure product. However, a chain is only as strong\\nas its weakest link. If \", \"the applications deployed on top of Azure aren\\u2019t developed with a proper\\nsecurity mindset and good s\", \"ecurity audits, then they become the weak link in the chain. There are\\nmany great static analysis to\", \"ols, encryption libraries, and security practices that can be used to ensure\\nthat the software insta\", \"lled on Azure is as secure as Azure itself. Examples include static analysis tools,\\nencryption libra\", \"ries, and security practices.\\n160 CHAPTER 9 | Cloud-native security10\\nCHAPTER\\nDevOps\\nThe favorite ma\", \"ntra of software consultants is to answer \\u201cIt depends\\u201d to any question posed. It isn\\u2019t\\nbecause softw\", \"are consultants are fond of not taking a position. It\\u2019s because there\\u2019s no one true\\nanswer to any qu\", \"estions in software. There\\u2019s no absolute right and wrong, but rather a balance\\nbetween opposites.\\nTa\", \"ke, for instance, the two major schools of developing web applications: Single Page Applications\\n(SP\", \"As) versus server-side applications. On the one hand, the user experience tends to be better with\\nSP\", \"As and the amount of traffic to the web server can be minimized making it possible to host them\\non s\", \"omething as simple as static hosting. On the other hand, SPAs tend to be slower to develop and\\nmore \", \"difficult to test. Which one is the right choice? Well, it depends on your situation.\\nCloud-native a\", \"pplications aren\\u2019t immune to that same dichotomy. They have clear advantages in\\nterms of speed of de\", \"velopment, stability, and scalability, but managing them can be quite a bit more\\ndifficult.\\nYears ag\", \"o, it wasn\\u2019t uncommon for the process of moving an application from development to\\nproduction to tak\", \"e a month, or even more. Companies released software on a 6-month or even every\\nyear cadence. One ne\", \"eds to look no further than Microsoft Windows to get an idea for the cadence of\\nreleases that were a\", \"cceptable before the ever-green days of Windows 10. Five years passed between\\nWindows XP and Vista, \", \"a further three between Vista and Windows 7.\\nIt\\u2019s now fairly well established that being able to rel\", \"ease software rapidly gives fast-moving companies\\na huge market advantage over their more sloth-like\", \" competitors. It\\u2019s for that reason that major\\nupdates to Windows 10 are now approximately every six \", \"months.\\nThe patterns and practices that enable faster, more reliable releases to deliver value to th\", \"e business\\nare collectively known as DevOps. They consist of a wide range of ideas spanning the enti\", \"re software\\ndevelopment life cycle from specifying an application all the way up to delivering and o\", \"perating that\\napplication.\\nDevOps emerged before microservices and it\\u2019s likely that the movement tow\", \"ards smaller, more fit to\\npurpose services wouldn\\u2019t have been possible without DevOps to make releas\", \"ing and operating not\\njust one but many applications in production easier.\\n161 CHAPTER 10 | DevOpsFi\", \"gure 10-1 - DevOps and microservices.\\nThrough good DevOps practices, it\\u2019s possible to realize the ad\", \"vantages of cloud-native applications\\nwithout suffocating under a mountain of work actually operatin\", \"g the applications.\\nThere\\u2019s no golden hammer when it comes to DevOps. Nobody can sell a complete and\", \" all-\\nencompassing solution for releasing and operating high-quality applications. This is because e\", \"ach\\napplication is wildly different from all others. However, there are tools that can make DevOps a\", \" far less\\ndaunting proposition. One of these tools is known as Azure DevOps.\\nAzure DevOps\\nAzure DevO\", \"ps has a long pedigree. It can trace its roots back to when Team Foundation Server first\\nmoved onlin\", \"e and through the various name changes: Visual Studio Online and Visual Studio Team\\nServices. Throug\", \"h the years, however, it has become far more than its predecessors.\\nAzure DevOps is divided into fiv\", \"e major components:\\nFigure 10-2 - Azure DevOps.\\nAzure Repos - Source code management that supports t\", \"he venerable Team Foundation Version\\nControl (TFVC) and the industry favorite Git. Pull requests pro\", \"vide a way to enable social coding by\\nfostering discussion of changes as they\\u2019re made.\\n162 CHAPTER 1\", \"0 | DevOpsAzure Boards - Provides an issue and work item tracking tool that strives to allow users t\", \"o pick the\\nworkflows that work best for them. It comes with a number of pre-configured templates inc\", \"luding\\nones to support SCRUM and Kanban styles of development.\\nAzure Pipelines - A build and release\", \" management system that supports tight integration with Azure.\\nBuilds can be run on various platform\", \"s from Windows to Linux to macOS. Build agents may be\\nprovisioned in the cloud or on-premises.\\nAzure\", \" Test Plans - No QA person will be left behind with the test management and exploratory\\ntesting supp\", \"ort offered by the Test Plans feature.\\nAzure Artifacts - An artifact feed that allows companies to c\", \"reate their own, internal, versions of\\nNuGet, npm, and others. It serves a double purpose of acting \", \"as a cache of upstream packages if\\nthere\\u2019s a failure of a centralized repository.\\nThe top-level orga\", \"nizational unit in Azure DevOps is known as a Project. Within each project the\\nvarious components, s\", \"uch as Azure Artifacts, can be turned on and off. Each of these components\\nprovides different advant\", \"ages for cloud-native applications. The three most useful are repositories,\\nboards, and pipelines. I\", \"f users want to manage their source code in another repository stack, such as\\nGitHub, but still take\", \" advantage of Azure Pipelines and other components, that\\u2019s perfectly possible.\\nFortunately, developm\", \"ent teams have many options when selecting a repository. One of them is\\nGitHub.\\nGitHub Actions\\nFound\", \"ed in 2009, GitHub is a widely popular web-based repository for hosting projects,\\ndocumentation, and\", \" code. Many large tech companies, such as Apple, Amazon, Google, and\\nmainstream corporations use Git\", \"Hub. GitHub uses the open-source, distributed version control system\\nnamed Git as its foundation. On\", \" top, it then adds its own set of features, including defect tracking,\\nfeature and pull requests, ta\", \"sks management, and wikis for each code base.\\nAs GitHub evolves, it too is adding DevOps features. F\", \"or example, GitHub has its own continuous\\nintegration/continuous delivery (CI/CD) pipeline, called G\", \"itHub Actions. GitHub Actions is a\\ncommunity-powered workflow automation tool. It lets DevOps teams \", \"integrate with their existing\\ntooling, mix and match new products, and hook into their software life\", \"cycle, including existing CI/CD\\npartners.\\u201d\\nGitHub has over 40 million users, making it the largest h\", \"ost of source code in the world. In October of\\n2018, Microsoft purchased GitHub. Microsoft has pledg\", \"ed that GitHub will remain an open platform\\nthat any developer can plug into and extend. It continue\", \"s to operate as an independent company.\\nGitHub offers plans for enterprise, team, professional, and \", \"free accounts.\\nSource control\\nOrganizing the code for a cloud-native application can be challenging.\", \" Instead of a single giant\\napplication, the cloud-native applications tend to be made up of a web of\", \" smaller applications that\\ntalk with one another. As with all things in computing, the best arrangem\", \"ent of code remains an open\\n163 CHAPTER 10 | DevOpsquestion. There are examples of successful applic\", \"ations using different kinds of layouts, but two\\nvariants seem to have the most popularity.\\nBefore g\", \"etting down into the actual source control itself, it\\u2019s probably worth deciding on how many\\nprojects\", \" are appropriate. Within a single project, there\\u2019s support for multiple repositories, and build\\npipe\", \"lines. Boards are a little more complicated, but there too, the tasks can easily be assigned to\\nmult\", \"iple teams within a single project. It\\u2019s possible to support hundreds, even thousands of\\ndevelopers,\", \" out of a single Azure DevOps project. Doing so is likely the best approach as it provides a\\nsingle \", \"place for all developer to work out of and reduces the confusion of finding that one application\\nwhe\", \"n developers are unsure in which project in which it resides.\\nSplitting up code for microservices wi\", \"thin the Azure DevOps project can be slightly more challenging.\\nFigure 10-3 - One vs. many repositor\", \"ies.\\nRepository per microservice\\nAt first glance, this approach seems like the most logical approach\", \" to splitting up the source code for\\nmicroservices. Each repository can contain the code needed to b\", \"uild the one microservice. The\\nadvantages to this approach are readily visible:\\n1. Instructions for \", \"building and maintaining the application can be added to a README file at\\nthe root of each repositor\", \"y. When flipping through the repositories, it\\u2019s easy to find these\\ninstructions, reducing spin-up ti\", \"me for developers.\\n2. Every service is located in a logical place, easily found by knowing the name \", \"of the service.\\n3. Builds can easily be set up such that they\\u2019re only triggered when a change is mad\", \"e to the\\nowning repository.\\n4. The number of changes coming into a repository is limited to the smal\", \"l number of developers\\nworking on the project.\\n164 CHAPTER 10 | DevOps5. Security is easy to set up \", \"by restricting the repositories to which developers have read and\\nwrite permissions.\\n6. Repository l\", \"evel settings can be changed by the owning team with a minimum of discussion\\nwith others.\\nOne of the\", \" key ideas behind microservices is that services should be siloed and separated from each\\nother. Whe\", \"n using Domain Driven Design to decide on the boundaries for services the services act as\\ntransactio\", \"nal boundaries. Database updates shouldn\\u2019t span multiple services. This collection of related\\ndata i\", \"s referred to as a bounded context. This idea is reflected by the isolation of microservice data to\\n\", \"a database separate and autonomous from the rest of the services. It makes a great deal of sense to\\n\", \"carry this idea all the way through to the source code.\\nHowever, this approach isn\\u2019t without its iss\", \"ues. One of the more gnarly development problems of our\\ntime is managing dependencies. Consider the \", \"number of files that make up the average\\nnode_modules directory. A fresh install of something like c\", \"reate-react-app is likely to bring with it\\nthousands of packages. The question of how to manage thes\", \"e dependencies is a difficult one.\\nIf a dependency is updated, then downstream packages must also up\", \"date this dependency.\\nUnfortunately, that takes development work so, invariably, the node_modules di\", \"rectory ends up with\\nmultiple versions of a single package, each one a dependency of some other pack\", \"age that is\\nversioned at a slightly different cadence. When deploying an application, which version \", \"of a\\ndependency should be used? The version that is currently in production? The version that is cur\", \"rently\\nin Beta but is likely to be in production by the time the consumer makes it to production? Di\", \"fficult\\nproblems that aren\\u2019t resolved by just using microservices.\\nThere are libraries that are depe\", \"nded upon by a wide variety of projects. By dividing the microservices\\nup with one in each repositor\", \"y the internal dependencies can best be resolved by using the internal\\nrepository, Azure Artifacts. \", \"Builds for libraries will push their latest versions into Azure Artifacts for\\ninternal consumption. \", \"The downstream project must still be manually updated to take a dependency\\non the newly updated pack\", \"ages.\\nAnother disadvantage presents itself when moving code between services. Although it would be n\", \"ice\\nto believe that the first division of an application into microservices is 100% correct, the rea\", \"lity is that\\nrarely we\\u2019re so prescient as to make no service division mistakes. Thus, functionality \", \"and the code that\\ndrives it will need to move from service to service: repository to repository. Whe\", \"n leaping from one\\nrepository to another, the code loses its history. There are many cases, especial\", \"ly in the event of an\\naudit, where having full history on a piece of code is invaluable.\\nThe final a\", \"nd most important disadvantage is coordinating changes. In a true microservices\\napplication, there s\", \"hould be no deployment dependencies between services. It should be possible to\\ndeploy services A, B,\", \" and C in any order as they have loose coupling. In reality, however, there are\\ntimes when it\\u2019s desi\", \"rable to make a change that crosses multiple repositories at the same time. Some\\nexamples include up\", \"dating a library to close a security hole or changing a communication protocol\\nused by all services.\", \"\\nTo do a cross-repository change requires a commit to each repository be made in succession. Each\\nch\", \"ange in each repository will need to be pull-requested and reviewed separately. This activity can be\", \"\\ndifficult to coordinate.\\n165 CHAPTER 10 | DevOpsAn alternative to using many repositories is to put\", \" all the source code together in a giant, all knowing,\\nsingle repository.\\nSingle repository\\nIn this \", \"approach, sometimes referred to as a monorepository, all the source code for every service is\\nput in\", \"to the same repository. At first, this approach seems like a terrible idea likely to make dealing\\nwi\", \"th source code unwieldy. There are, however, some marked advantages to working this way.\\nThe first a\", \"dvantage is that it\\u2019s easier to manage dependencies between projects. Instead of relying on\\nsome ext\", \"ernal artifact feed, projects can directly import one another. This means that updates are\\ninstant, \", \"and conflicting versions are likely to be found at compile time on the developer\\u2019s workstation.\\nIn e\", \"ffect, shifting some of the integration testing left.\\nWhen moving code between projects, it\\u2019s now ea\", \"sier to preserve the history as the files will be\\ndetected as having been moved rather than being re\", \"written.\\nAnother advantage is that wide ranging changes that cross service boundaries can be made in\", \" a\\nsingle commit. This activity reduces the overhead of having potentially dozens of changes to revi\", \"ew\\nindividually.\\nThere are many tools that can perform static analysis of code to detect insecure pr\", \"ogramming\\npractices or problematic use of APIs. In a multi-repository world, each repository will ne\", \"ed to be\\niterated over to find the problems in them. The single repository allows running the analys\", \"is all in one\\nplace.\\nThere are also many disadvantages to the single repository approach. One of the\", \" most worrying ones\\nis that having a single repository raises security concerns. If the contents of \", \"a repository are leaked in\\na repository per service model, the amount of code lost is minimal. With \", \"a single repository,\\neverything the company owns could be lost. There have been many examples in the\", \" past of this\\nhappening and derailing entire game development efforts. Having multiple repositories \", \"exposes less\\nsurface area, which is a desirable trait in most security practices.\\nThe size of the si\", \"ngle repository is likely to become unmanageable rapidly. This presents some\\ninteresting performance\", \" implications. It may become necessary to use specialized tools such as Virtual\\nFile System for Git,\", \" which was originally designed to improve the experience for developers on the\\nWindows team.\\nFrequen\", \"tly the argument for using a single repository boils down to an argument that Facebook or\\nGoogle use\", \" this method for source code arrangement. If the approach is good enough for these\\ncompanies, then, \", \"surely, it\\u2019s the correct approach for all companies. The truth of the matter is that few\\ncompanies o\", \"perate on anything like the scale of Facebook or Google. The problems that occur at\\nthose scales are\", \" different from those most developers will face. What is good for the goose may not\\nbe good for the \", \"gander.\\nIn the end, either solution can be used to host the source code for microservices. However, \", \"in most\\ncases, the management, and engineering overhead of operating in a single repository isn\\u2019t wo\", \"rth the\\nmeager advantages. Splitting code up over multiple repositories encourages better separation\", \" of\\nconcerns and encourages autonomy among development teams.\\n166 CHAPTER 10 | DevOpsStandard direct\", \"ory structure\\nRegardless of the single versus multiple repositories debate each service will have it\", \"s own directory.\\nOne of the best optimizations to allow developers to cross between projects quickly\", \" is to maintain a\\nstandard directory structure.\\nFigure 10-4 - Standard directory structure.\\nWhenever\", \" a new project is created, a template that puts in place the correct structure should be used.\\nThis \", \"template can also include such useful items as a skeleton README file and an azure-\\npipelines.yml. I\", \"n any microservice architecture, a high degree of variance between projects makes bulk\\noperations ag\", \"ainst the services more difficult.\\nThere are many tools that can provide templating for an entire di\", \"rectory, containing several source\\ncode directories. Yeoman is popular in the JavaScript world and G\", \"itHub have recently released\\nRepository Templates, which provide much of the same functionality.\\nTas\", \"k management\\nManaging tasks in any project can be difficult. Up front there are countless questions \", \"to be answered\\nabout the sort of workflows to set up to ensure optimal developer productivity.\\nCloud\", \"-native applications tend to be smaller than traditional software products or at least they\\u2019re\\ndivid\", \"ed into smaller services. Tracking of issues or tasks related to these services remains as important\", \"\\nas with any other software project. Nobody wants to lose track of some work item or explain to a\\ncu\", \"stomer that their issue wasn\\u2019t properly logged. Boards are configured at the project level but withi\", \"n\\neach project, areas can be defined. These allow breaking down issues across several components. Th\", \"e\\nadvantage to keeping all the work for the entire application in one place is that it\\u2019s easy to mov\", \"e work\\nitems from one team to another as they\\u2019re understood better.\\n167 CHAPTER 10 | DevOpsAzure Dev\", \"Ops comes with a number of popular templates pre-configured. In the most basic\\nconfiguration, all th\", \"at is needed to know is what\\u2019s in the backlog, what people are working on, and\\nwhat\\u2019s done. It\\u2019s imp\", \"ortant to have this visibility into the process of building software, so that work\\ncan be prioritize\", \"d and completed tasks reported to the customer. Of course, few software projects\\nstick to a process \", \"as simple as to do, doing, and done. It doesn\\u2019t take long for people to start adding\\nsteps like QA o\", \"r Detailed Specification to the process.\\nOne of the more important parts of Agile methodologies is s\", \"elf-introspection at regular intervals.\\nThese reviews are meant to provide insight into what problem\", \"s the team is facing and how they can\\nbe improved. Frequently, this means changing the flow of issue\", \"s and features through the\\ndevelopment process. So, it\\u2019s perfectly healthy to expand the layouts of \", \"the boards with additional\\nstages.\\nThe stages in the boards aren\\u2019t the only organizational tool. Dep\", \"ending on the configuration of the\\nboard, there\\u2019s a hierarchy of work items. The most granular item \", \"that can appear on a board is a task.\\nOut of the box a task contains fields for a title, description\", \", a priority, an estimate of the amount of\\nwork remaining and the ability to link to other work item\", \"s or development items (branches, commits,\\npull requests, builds, and so forth). Work items can be c\", \"lassified into different areas of the application\\nand different iterations (sprints) to make finding\", \" them easier.\\nFigure 10-5 - Task in Azure DevOps.\\nThe description field supports the normal styles y\", \"ou\\u2019d expect (bold, italic underscore and strike\\nthrough) and the ability to insert images. This make\", \"s it a powerful tool for use when specifying work\\nor bugs.\\nTasks can be rolled up into features, whi\", \"ch define a larger unit of work. Features, in turn, can be rolled\\nup into epics. Classifying tasks i\", \"n this hierarchy makes it much easier to understand how close a large\\nfeature is to rolling out.\\n168\", \" CHAPTER 10 | DevOpsFigure 10-6 - Work item in Azure DevOps.\\nThere are different kinds of views into\", \" the issues in Azure Boards. Items that aren\\u2019t yet scheduled\\nappear in the backlog. From there, they\", \" can be assigned to a sprint. A sprint is a time box during\\nwhich it\\u2019s expected some quantity of wor\", \"k will be completed. This work can include tasks but also the\\nresolution of tickets. Once there, the\", \" entire sprint can be managed from the Sprint board section. This\\nview shows how work is progressing\", \" and includes a burn down chart to give an ever-updating\\nestimate of if the sprint will be successfu\", \"l.\\nFigure 10-7 - Board in Azure DevOps.\\nBy now, it should be apparent that there\\u2019s a great deal of p\", \"ower in the Boards in Azure DevOps. For\\ndevelopers, there are easy views of what is being worked on.\", \" For project managers views into\\nupcoming work as well as an overview of existing work. For managers\", \", there are plenty of reports\\nabout resourcing and capacity. Unfortunately, there\\u2019s nothing magical \", \"about cloud-native applications\\nthat eliminate the need to track work. But if you must track work, t\", \"here are a few places where the\\nexperience is better than in Azure DevOps.\\nCI/CD pipelines\\nAlmost no\", \" change in the software development life cycle has been so revolutionary as the advent of\\ncontinuous\", \" integration (CI) and continuous delivery (CD). Building and running automated tests\\nagainst the sou\", \"rce code of a project as soon as a change is checked in catches mistakes early. Prior to\\nthe advent \", \"of continuous integration builds, it wouldn\\u2019t be uncommon to pull code from the\\n169 CHAPTER 10 | Dev\", \"Opsrepository and find that it didn\\u2019t pass tests or couldn\\u2019t even be built. This resulted in trackin\", \"g down\\nthe source of the breakage.\\nTraditionally shipping software to the production environment req\", \"uired extensive documentation and\\na list of steps. Each one of these steps needed to be manually com\", \"pleted in a very error prone\\nprocess.\\nFigure 10-8 - Checklist.\\nThe sister of continuous integration \", \"is continuous delivery in which the freshly built packages are\\ndeployed to an environment. The manua\", \"l process can\\u2019t scale to match the speed of development so\\nautomation becomes more important. Checkl\", \"ists are replaced by scripts that can execute the same\\ntasks faster and more accurately than any hum\", \"an.\\nThe environment to which continuous delivery delivers might be a test environment or, as is bein\", \"g\\ndone by many major technology companies, it could be the production environment. The latter\\nrequir\", \"es an investment in high-quality tests that can give confidence that a change isn\\u2019t going to\\nbreak p\", \"roduction for users. In the same way that continuous integration caught issues in the code\\nearly con\", \"tinuous delivery catches issues in the deployment process early.\\nThe importance of automating the bu\", \"ild and delivery process is accentuated by cloud-native\\napplications. Deployments happen more freque\", \"ntly and to more environments so manually deploying\\nborders on impossible.\\nAzure Builds\\nAzure DevOps\", \" provides a set of tools to make continuous integration and deployment easier than\\never. These tools\", \" are located under Azure Pipelines. The first of them is Azure Builds, which is a tool\\nfor running Y\", \"AML-based build definitions at scale. Users can either bring their own build machines\\n(great for if \", \"the build requires a meticulously set up environment) or use a machine from a constantly\\nrefreshed p\", \"ool of Azure hosted virtual machines. These hosted build agents come pre-installed with a\\n170 CHAPTE\", \"R 10 | DevOpswide range of development tools for not just .NET development but for everything from J\", \"ava to\\nPython to iPhone development.\\nDevOps includes a wide range of out of the box build definition\", \"s that can be customized for any build.\\nThe build definitions are defined in a file called azure-pip\", \"elines.yml and checked into the repository so\\nthey can be versioned along with the source code. This\", \" makes it much easier to make changes to the\\nbuild pipeline in a branch as the changes can be checke\", \"d into just that branch. An example azure-\\npipelines.yml for building an ASP.NET web application on \", \"full framework is show in Figure 10-9.\\nname: $(rev:r)\\nvariables:\\nversion: 9.2.0.$(Build.BuildNumber)\", \"\\nsolution: Portals.sln\\nartifactName: drop\\nbuildPlatform: any cpu\\nbuildConfiguration: release\\npool:\\nn\", \"ame: Hosted VisualStudio\\ndemands:\\n- msbuild\\n- visualstudio\\n- vstest\\nsteps:\\n- task: NuGetToolInstalle\", \"r@0\\ndisplayName: 'Use NuGet 4.4.1'\\ninputs:\\nversionSpec: 4.4.1\\n- task: NuGetCommand@2\\ndisplayName: 'N\", \"uGet restore'\\ninputs:\\nrestoreSolution: '$(solution)'\\n- task: VSBuild@1\\ndisplayName: 'Build solution'\", \"\\ninputs:\\nsolution: '$(solution)'\\nmsbuildArgs: '-p:DeployOnBuild=true -p:WebPublishMethod=Package -\\np\", \":PackageAsSingleFile=true -p:SkipInvalidConfigurations=true -\\np:PackageLocation=\\\"$(build.artifactsta\", \"gingdirectory)\\\\\\\\\\\"'\\nplatform: '$(buildPlatform)'\\nconfiguration: '$(buildConfiguration)'\\n- task: VSTes\", \"t@2\\ndisplayName: 'Test Assemblies'\\ninputs:\\ntestAssemblyVer2: |\\n**\\\\$(buildConfiguration)\\\\**\\\\*test*.dl\", \"l\\n!**\\\\obj\\\\**\\n!**\\\\*testadapter.dll\\nplatform: '$(buildPlatform)'\\nconfiguration: '$(buildConfiguration)\", \"'\\n- task: CopyFiles@2\\ndisplayName: 'Copy UI Test Files to: $(build.artifactstagingdirectory)'\\ninputs\", \":\\n171 CHAPTER 10 | DevOpsSourceFolder: UITests\\nTargetFolder: '$(build.artifactstagingdirectory)/uite\", \"sts'\\n- task: PublishBuildArtifacts@1\\ndisplayName: 'Publish Artifact'\\ninputs:\\nPathtoPublish: '$(build\", \".artifactstagingdirectory)'\\nArtifactName: '$(artifactName)'\\ncondition: succeededOrFailed()\\nFigure 10\", \"-9 - A sample azure-pipelines.yml\\nThis build definition uses a number of built-in tasks that make cr\", \"eating builds as simple as building a\\nLego set (simpler than the giant Millennium Falcon). For insta\", \"nce, the NuGet task restores NuGet\\npackages, while the VSBuild task calls the Visual Studio build to\", \"ols to perform the actual compilation.\\nThere are hundreds of different tasks available in Azure DevO\", \"ps, with thousands more that are\\nmaintained by the community. It\\u2019s likely that no matter what build \", \"tasks you\\u2019re looking to run,\\nsomebody has built one already.\\nBuilds can be triggered manually, by a \", \"check-in, on a schedule, or by the completion of another build.\\nIn most cases, building on every che\", \"ck-in is desirable. Builds can be filtered so that different builds run\\nagainst different parts of t\", \"he repository or against different branches. This allows for scenarios like\\nrunning fast builds with\", \" reduced testing on pull requests and running a full regression suite against\\nthe trunk on a nightly\", \" basis.\\nThe end result of a build is a collection of files known as build artifacts. These artifacts\", \" can be passed\\nalong to the next step in the build process or added to an Azure Artifacts feed, so t\", \"hey can be\\nconsumed by other builds.\\nAzure DevOps releases\\nBuilds take care of compiling the softwar\", \"e into a shippable package, but the artifacts still need to be\\npushed out to a testing environment t\", \"o complete continuous delivery. For this, Azure DevOps uses a\\nseparate tool called Releases. The Rel\", \"eases tool makes use of the same tasks\\u2019 library that were\\navailable to the Build but introduce a con\", \"cept of \\u201cstages\\u201d. A stage is an isolated environment into\\nwhich the package is installed. For instan\", \"ce, a product might make use of a development, a QA, and a\\nproduction environment. Code is continuou\", \"sly delivered into the development environment where\\nautomated tests can be run against it. Once tho\", \"se tests pass the release moves onto the QA\\nenvironment for manual testing. Finally, the code is pus\", \"hed to production where it\\u2019s visible to\\neverybody.\\nFigure 10-10 - Release pipeline\\nEach stage in the\", \" build can be automatically triggered by the completion of the previous phase. In\\nmany cases, howeve\", \"r, this isn\\u2019t desirable. Moving code into production might require approval from\\nsomebody. The Relea\", \"ses tool supports this by allowing approvers at each step of the release pipeline.\\nRules can be set \", \"up such that a specific person or group of people must sign off on a release before it\\n172 CHAPTER 1\", \"0 | DevOpsmakes into production. These gates allow for manual quality checks and also for compliance\", \" with any\\nregulatory requirements related to control what goes into production.\\nEverybody gets a bui\", \"ld pipeline\\nThere\\u2019s no cost to configuring many build pipelines, so it\\u2019s advantageous to have at lea\", \"st one build\\npipeline per microservice. Ideally, microservices are independently deployable to any e\", \"nvironment so\\nhaving each one able to be released via its own pipeline without releasing a mass of u\", \"nrelated code is\\nperfect. Each pipeline can have its own set of approvals allowing for variations in\", \" build process for\\neach service.\\nVersioning releases\\nOne drawback to using the Releases functionalit\", \"y is that it can\\u2019t be defined in a checked-in azure-\\npipelines.yml file. There are many reasons you \", \"might want to do that from having per-branch release\\ndefinitions to including a release skeleton in \", \"your project template. Fortunately, work is ongoing to\\nshift some of the stages support into the Bui\", \"ld component. This will be known as multi-stage build\\nand the first version is available now!\\nFeatur\", \"e flags\\nIn chapter 1, we affirmed that cloud native is much about speed and agility. Users expect ra\", \"pid\\nresponsiveness, innovative features, and zero downtime. Feature flags are a modern deployment\\nte\", \"chnique that helps increase agility for cloud-native applications. They enable you to deploy new\\nfea\", \"tures into a production environment, but restrict their availability. With the flick of a switch, yo\", \"u can\\nactivate a new feature for specific users without restarting the app or deploying new code. Th\", \"ey\\nseparate the release of new features from their code deployment.\\nFeature flags are built upon con\", \"ditional logic that control visibility of functionality for users at run\\ntime. In modern cloud-nativ\", \"e systems, it\\u2019s common to deploy new features into production early, but\\ntest them with a limited au\", \"dience. As confidence increases, the feature can be incrementally rolled out\\nto wider audiences.\\nOth\", \"er use cases for feature flags include:\\n\\u2022 Restrict premium functionality to specific customer groups\", \" willing to pay higher subscription\\nfees.\\n\\u2022 Stabilize a system by quickly deactivating a problem fea\", \"ture, avoiding the risks of a rollback or\\nimmediate hotfix.\\n\\u2022 Disable an optional feature with high \", \"resource consumption during peak usage periods.\\n\\u2022 Conduct experimental feature releases to small use\", \"r segments to validate feasibility and\\npopularity.\\nFeature flags also promote trunk-based developmen\", \"t. It\\u2019s a source-control branching model where\\ndevelopers collaborate on features in a single branch\", \". The approach minimizes the risk and complexity\\nof merging large numbers of long-running feature br\", \"anches. Features are unavailable until activated.\\n173 CHAPTER 10 | DevOpsImplementing feature flags\\n\", \"At its core, a feature flag is a reference to a simple decision object. It returns a Boolean state o\", \"f on or\\noff. The flag typically wraps a block of code that encapsulates a feature capability. The st\", \"ate of the flag\\ndetermines whether that code block executes for a given user. Figure 10-11 shows the\", \"\\nimplementation.\\nif (featureFlag) {\\n// Run this code block if the featureFlag value is true\\n} else {\", \"\\n// Run this code block if the featureFlag value is false\\n}\\nFigure 10-11 - Simple feature flag imple\", \"mentation.\\nNote how this approach separates the decision logic from the feature code.\\nIn chapter 1, \", \"we discussed the Twelve-Factor App. The guidance recommended keeping configuration\\nsettings external\", \" from application executable code. When needed, settings can be read in from the\\nexternal source. Fe\", \"ature flag configuration values should also be independent from their codebase. By\\nexternalizing fla\", \"g configuration in a separate repository, you can change flag state without modifying\\nand redeployin\", \"g the application.\\nAzure App Configuration provides a centralized repository for feature flags. With\", \" it, you define\\ndifferent kinds of feature flags and manipulate their states quickly and confidently\", \". You add the App\\nConfiguration client libraries to your application to enable feature flag function\", \"ality. Various\\nprogramming language frameworks are supported.\\nFeature flags can be easily implemente\", \"d in an ASP.NET Core service. Installing the .NET Feature\\nManagement libraries and App Configuration\", \" provider enable you to declaratively add feature flags to\\nyour code. They enable FeatureGate attrib\", \"utes so that you don\\u2019t have to manually write if statements\\nacross your codebase.\\nOnce configured in\", \" your Startup class, you can add feature flag functionality at the controller, action,\\nor middleware\", \" level. Figure 10-12 presents controller and action implementation:\\n[FeatureGate(MyFeatureFlags.Feat\", \"ureA)]\\npublic class ProductController : Controller\\n{\\n...\\n}\\n[FeatureGate(MyFeatureFlags.FeatureA)]\\npu\", \"blic IActionResult UpdateProductStatus()\\n{\\nreturn ObjectResult(ProductDto);\\n}\\nFigure 10-12 - Feature\", \" flag implementation in a controller and action.\\nIf a feature flag is disabled, the user will receiv\", \"e a 404 (Not Found) status code with no response body.\\nFeature flags can also be injected directly i\", \"nto C# classes. Figure 10-13 shows feature flag injection:\\n174 CHAPTER 10 | DevOpspublic class Produ\", \"ctController : Controller\\n{\\nprivate readonly IFeatureManager _featureManager;\\npublic ProductControll\", \"er(IFeatureManager featureManager)\\n{\\n_featureManager = featureManager;\\n}\\n}\\nFigure 10-13 - Feature fl\", \"ag injection into a class.\\nThe Feature Management libraries manage the feature flag lifecycle behind\", \" the scenes. For example,\\nto minimize high numbers of calls to the configuration store, the librarie\", \"s cache flag states for a\\nspecified duration. They can guarantee the immutability of flag states dur\", \"ing a request call. They also\\noffer a Point-in-time snapshot. You can reconstruct the history of any\", \" key-value and provide its past\\nvalue at any moment within the previous seven days.\\nInfrastructure a\", \"s code\\nCloud-native systems embrace microservices, containers, and modern system design to achieve s\", \"peed\\nand agility. They provide automated build and release stages to ensure consistent and quality c\", \"ode.\\nBut, that\\u2019s only part of the story. How do you provision the cloud environments upon which thes\", \"e\\nsystems run?\\nModern cloud-native applications embrace the widely accepted practice of Infrastructu\", \"re as Code, or\\nIaC. With IaC, you automate platform provisioning. You essentially apply software eng\", \"ineering\\npractices such as testing and versioning to your DevOps practices. Your infrastructure and\\n\", \"deployments are automated, consistent, and repeatable. Just as continuous delivery automated the\\ntra\", \"ditional model of manual deployments, Infrastructure as Code (IaC) is evolving how application\\nenvir\", \"onments are managed.\\nTools like Azure Resource Manager (ARM), Terraform, and the Azure Command Line \", \"Interface (CLI)\\nenable you to declaratively script the cloud infrastructure you require.\\nAzure Resou\", \"rce Manager templates\\nARM stands for Azure Resource Manager. It\\u2019s an API provisioning engine that is\", \" built into Azure and\\nexposed as an API service. ARM enables you to deploy, update, delete, and mana\", \"ge the resources\\ncontained in Azure resource group in a single, coordinated operation. You provide t\", \"he engine with a\\nJSON-based template that specifies the resources you require and their configuratio\", \"n. ARM\\nautomatically orchestrates the deployment in the correct order respecting dependencies. The e\", \"ngine\\nensures idempotency. If a desired resource already exists with the same configuration, provisi\", \"oning\\nwill be ignored.\\nAzure Resource Manager templates are a JSON-based language for defining vario\", \"us resources in\\nAzure. The basic schema looks something like Figure 10-14.\\n{\\n\\\"$schema\\\": \\\"https://sch\", \"ema.management.azure.com/schemas/2015-01-\\n175 CHAPTER 10 | DevOps01/deploymentTemplate.json#\\\",\\n\\\"cont\", \"entVersion\\\": \\\"\\\",\\n\\\"apiProfile\\\": \\\"\\\",\\n\\\"parameters\\\": { },\\n\\\"variables\\\": { },\\n\\\"functions\\\": [ ],\\n\\\"resources\", \"\\\": [ ],\\n\\\"outputs\\\": { }\\n}\\nFigure 10-14 - The schema for a Resource Manager template\\nWithin this templ\", \"ate, one might define a storage container inside the resources section like so:\\n\\\"resources\\\": [\\n{\\n\\\"ty\", \"pe\\\": \\\"Microsoft.Storage/storageAccounts\\\",\\n\\\"name\\\": \\\"[variables('storageAccountName')]\\\",\\n\\\"location\\\": \\\"\", \"[parameters('location')]\\\",\\n\\\"apiVersion\\\": \\\"2018-07-01\\\",\\n\\\"sku\\\": {\\n\\\"name\\\": \\\"[parameters('storageAccount\", \"Type')]\\\"\\n},\\n\\\"kind\\\": \\\"StorageV2\\\",\\n\\\"properties\\\": {}\\n}\\n],\\nFigure 10-15 - An example of a storage accoun\", \"t defined in a Resource Manager template\\nAn ARM template can be parameterized with dynamic environme\", \"nt and configuration information.\\nDoing so enables it to be reused to define different environments,\", \" such as development, QA, or\\nproduction. Normally, the template creates all resources within a singl\", \"e Azure resource group. It\\u2019s\\npossible to define multiple resource groups in a single Resource Manage\", \"r template, if needed. You\\ncan delete all resources in an environment by deleting the resource group\", \" itself. Cost analysis can also\\nbe run at the resource group level, allowing for quick accounting of\", \" how much each environment is\\ncosting.\\nThere are many examples of ARM templates available in the Azu\", \"re Quickstart Templates project on\\nGitHub. They can help accelerate creating a new template or modif\", \"ying an existing one.\\nResource Manager templates can be run in many of ways. Perhaps the simplest wa\", \"y is to simply paste\\nthem into the Azure portal. For experimental deployments, this method can be qu\", \"ick. They can also be\\nrun as part of a build or release process in Azure DevOps. There are tasks tha\", \"t will leverage\\nconnections into Azure to run the templates. Changes to Resource Manager templates a\", \"re applied\\nincrementally, meaning that to add a new resource requires just adding it to the template\", \". The tooling\\nwill reconcile differences between the current resources and those defined in the temp\", \"late. Resources\\nwill then be created or altered so they match what is defined in the template.\\nTerra\", \"form\\nCloud-native applications are often constructed to be cloud agnostic. Being so means the applic\", \"ation\\nisn\\u2019t tightly coupled to a particular cloud vendor and can be deployed to any public cloud.\\n17\", \"6 CHAPTER 10 | DevOpsTerraform is a commercial templating tool that can provision cloud-native appli\", \"cations across all the\\nmajor cloud players: Azure, Google Cloud Platform, AWS, and AliCloud. Instead\", \" of using JSON as the\\ntemplate definition language, it uses the slightly more terse HCL (Hashicorp C\", \"onfiguration Language).\\nAn example Terraform file that does the same as the previous Resource Manage\", \"r template (Figure 10-\\n15) is shown in Figure 10-16:\\nprovider \\\"azurerm\\\" {\\nversion = \\\"=1.28.0\\\"\\n}\\nreso\", \"urce \\\"azurerm_resource_group\\\" \\\"testrg\\\" {\\nname = \\\"production\\\"\\nlocation = \\\"West US\\\"\\n}\\nresource \\\"azurer\", \"m_storage_account\\\" \\\"testsa\\\" {\\nname = \\\"${var.storageAccountName}\\\"\\nresource_group_name = \\\"${azurerm_re\", \"source_group.testrg.name}\\\"\\nlocation = \\\"${var.region}\\\"\\naccount_tier = \\\"${var.tier}\\\"\\naccount_replicati\", \"on_type = \\\"${var.replicationType}\\\"\\n}\\nFigure 10-16 - An example of a Resource Manager template\\nTerraf\", \"orm also provides intuitive error messages for problem templates. There\\u2019s also a handy validate\\ntask\", \" that can be used in the build phase to catch template errors early.\\nAs with Resource Manager templa\", \"tes, command-line tools are available to deploy Terraform\\ntemplates. There are also community-create\", \"d tasks in Azure Pipelines that can validate and apply\\nTerraform templates.\\nSometimes Terraform and \", \"ARM templates output meaningful values, such as a connection string to a\\nnewly created database. Thi\", \"s information can be captured in the build pipeline and used in\\nsubsequent tasks.\\nAzure CLI Scripts \", \"and Tasks\\nFinally, you can leverage Azure CLI to declaratively script your cloud infrastructure. Azu\", \"re CLI scripts\\ncan be created, found, and shared to provision and configure almost any Azure resourc\", \"e. The CLI is\\nsimple to use with a gentle learning curve. Scripts are executed within either PowerSh\", \"ell or Bash.\\nThey\\u2019re also straightforward to debug, especially when compared with ARM templates.\\nAzu\", \"re CLI scripts work well when you need to tear down and redeploy your infrastructure. Updating\\nan ex\", \"isting environment can be tricky. Many CLI commands aren\\u2019t idempotent. That means they\\u2019ll\\nrecreate t\", \"he resource each time they\\u2019re run, even if the resource already exists. It\\u2019s always possible to\\nadd \", \"code that checks for the existence of each resource before creating it. But, doing so, your script\\nc\", \"an become bloated and difficult to manage.\\nThese scripts can also be embedded in Azure DevOps pipeli\", \"nes as Azure CLI tasks. Executing the\\npipeline invokes the script.\\n177 CHAPTER 10 | DevOpsFigure 10-\", \"17 shows a YAML snippet that lists the version of Azure CLI and the details of the\\nsubscription. Not\", \"e how Azure CLI commands are included in an inline script.\\n- task: AzureCLI@2\\ndisplayName: Azure CLI\", \"\\ninputs:\\nazureSubscription: <Name of the Azure Resource Manager service connection>\\nscriptType: ps\\ns\", \"criptLocation: inlineScript\\ninlineScript: |\\naz --version\\naz account show\\nFigure 10-17 - Azure CLI sc\", \"ript\\nIn the article, What is Infrastructure as Code, Author Sam Guckenheimer describes how, \\u201cTeams w\", \"ho\\nimplement IaC can deliver stable environments rapidly and at scale. Teams avoid manual\\nconfigurat\", \"ion of environments and enforce consistency by representing the desired state of their\\nenvironments \", \"via code. Infrastructure deployments with IaC are repeatable and prevent runtime issues\\ncaused by co\", \"nfiguration drift or missing dependencies. DevOps teams can work together with a\\nunified set of prac\", \"tices and tools to deliver applications and their supporting infrastructure rapidly,\\nreliably, and a\", \"t scale.\\u201d\\nCloud Native Application Bundles\\nA key property of cloud-native applications is that they \", \"leverage the capabilities of the cloud to speed\\nup development. This design often means that a full \", \"application uses different kinds of technologies.\\nApplications may be shipped in Docker containers, \", \"some services may use Azure Functions, while\\nother parts may run directly on virtual machines alloca\", \"ted on large metal servers with hardware GPU\\nacceleration. No two cloud-native applications are the \", \"same, so it\\u2019s been difficult to provide a single\\nmechanism for shipping them.\\nThe Docker containers \", \"may run on Kubernetes using a Helm Chart for deployment. The Azure\\nFunctions may be allocated using \", \"Terraform templates. Finally, the virtual machines may be allocated\\nusing Terraform but built out us\", \"ing Ansible. This is a large variety of technologies and there has been\\nno way to package them all t\", \"ogether into a reasonable package. Until now.\\nCloud Native Application Bundles (CNABs) are a joint e\", \"ffort by many community-minded companies\\nsuch as Microsoft, Docker, and HashiCorp to develop a speci\", \"fication to package distributed\\napplications.\\nThe effort was announced in December of 2018, so there\", \"\\u2019s still a fair bit of work to do to expose the\\neffort to the greater community. However, there\\u2019s al\", \"ready an open specification and a reference\\nimplementation known as Duffle. This tool, which was wri\", \"tten in Go, is a joint effort between Docker\\nand Microsoft.\\nThe CNABs can contain different kinds of\", \" installation technologies. This aspect allows things like Helm\\nCharts, Terraform templates, and Ans\", \"ible Playbooks to coexist in the same package. Once built, the\\npackages are self-contained and porta\", \"ble; they can be installed from a USB stick. The packages are\\ncryptographically signed to ensure the\", \"y originate from the party they claim.\\n178 CHAPTER 10 | DevOpsThe core of a CNAB is a file called bu\", \"ndle.json. This file defines the contents of the bundle, be they\\nTerraform or images or anything els\", \"e. Figure 11-9 defines a CNAB that invokes some Terraform.\\nNotice, however, that it actually defines\", \" an invocation image that is used to invoke the Terraform.\\nWhen packaged up, the Docker file that is\", \" located in the cnab directory is built into a Docker image,\\nwhich will be included in the bundle. H\", \"aving Terraform installed inside a Docker container in the\\nbundle means that users don\\u2019t need to hav\", \"e Terraform installed on their machine to run the bundling.\\n{\\n\\\"name\\\": \\\"terraform\\\",\\n\\\"version\\\": \\\"0.1.0\", \"\\\",\\n\\\"schemaVersion\\\": \\\"v1.0.0-WD\\\",\\n\\\"parameters\\\": {\\n\\\"backend\\\": {\\n\\\"type\\\": \\\"boolean\\\",\\n\\\"defaultValue\\\": fal\", \"se,\\n\\\"destination\\\": {\\n\\\"env\\\": \\\"TF_VAR_backend\\\"\\n}\\n}\\n},\\n\\\"invocationImages\\\": [\\n{\\n\\\"imageType\\\": \\\"docker\\\",\\n\\\"\", \"image\\\": \\\"cnab/terraform:latest\\\"\\n}\\n],\\n\\\"credentials\\\": {\\n\\\"tenant_id\\\": {\\n\\\"env\\\": \\\"TF_VAR_tenant_id\\\"\\n},\\n\\\"c\", \"lient_id\\\": {\\n\\\"env\\\": \\\"TF_VAR_client_id\\\"\\n},\\n\\\"client_secret\\\": {\\n\\\"env\\\": \\\"TF_VAR_client_secret\\\"\\n},\\n\\\"subsc\", \"ription_id\\\": {\\n\\\"env\\\": \\\"TF_VAR_subscription_id\\\"\\n},\\n\\\"ssh_authorized_key\\\": {\\n\\\"env\\\": \\\"TF_VAR_ssh_authori\", \"zed_key\\\"\\n}\\n},\\n\\\"actions\\\": {\\n\\\"status\\\": {\\n\\\"modifies\\\": true\\n}\\n}\\n}\\nFigure 10-18 - An example Terraform fi\", \"le\\nThe bundle.json also defines a set of parameters that are passed down into the Terraform.\\nParamet\", \"erization of the bundle allows for installation in various different environments.\\nThe CNAB format i\", \"s also flexible, allowing it to be used against any cloud. It can even be used against\\non-premises s\", \"olutions such as OpenStack.\\n179 CHAPTER 10 | DevOpsDevOps Decisions\\nThere are so many great tools in\", \" the DevOps space these days and even more fantastic books and\\npapers on how to succeed. A favorite \", \"book to get started on the DevOps journey is The Phoenix\\nProject, which follows the transformation o\", \"f a fictional company from NoOps to DevOps. One thing is\\nfor certain: DevOps is no longer a \\u201cnice to\", \" have\\u201d when deploying complex, Cloud Native Applications.\\nIt\\u2019s a requirement and should be planned f\", \"or and resourced at the start of any project.\\nReferences\\n\\u2022 Azure DevOps\\n\\u2022 Azure Resource Manager\\n\\u2022 T\", \"erraform\\n\\u2022 Azure CLI\\n180 CHAPTER 10 | DevOps11\\nCHAPTER\\nSummary: Architecting\\ncloud-native apps\\nIn su\", \"mmary, here are important conclusions from this guide:\\n\\u2022 Cloud-native is about designing modern appl\", \"ications that embrace rapid change, large scale,\\nand resilience, in modern, dynamic environments suc\", \"h as public, private, and hybrid clouds.\\n\\u2022 The Cloud Native Computing Foundation (CNCF) is an influe\", \"ntial open-source consortium\\nof over 300 major corporations. It\\u2019s responsible for driving the adopti\", \"on of cloud-native\\ncomputing across technology and cloud stacks.\\n\\u2022 CNCF guidelines recommend that cl\", \"oud-native applications embrace six important pillars as\\nshown in Figure 11-1:\\nFigure 11-1. Cloud-na\", \"tive foundational pillars\\n\\u2022 These cloud-native pillars include:\\n\\u2013 The cloud and its underlying servi\", \"ce model\\n\\u2013 Modern design principles\\n\\u2013 Microservices\\n\\u2013 Containerization and container orchestration\\n\\u2013\", \" Cloud-based backing services, such as databases and message brokers\\n\\u2013 Automation, including Infrast\", \"ructure as Code and code deployment\\n181 CHAPTER 11 | Summary: Architecting cloud-native apps\\u2022 Kubern\", \"etes is the hosting environment of choice for most cloud-native applications. Smaller,\\nsimple servic\", \"es are sometimes hosted in serverless platforms, such as Azure Functions. Among\\nmany key automation \", \"features, both environments provide automatic scaling to handle\\nfluctuating workload volumes.\\n\\u2022 Serv\", \"ice communication becomes a significant design decision when constructing a cloud-\\nnative applicatio\", \"n. Applications typically expose an API gateway to manage front-end client\\ncommunication. Then backe\", \"nd microservices strive to communicate with each other\\nimplementing asynchronous communication patte\", \"rns, when possible.\\n\\u2022 gRPC is a modern, high-performance framework that evolves the age-old remote p\", \"rocedure\\ncall (RPC) protocol. Cloud-native applications often embrace gRPC to streamline messaging\\nb\", \"etween back-end services. gRPC uses HTTP/2 for its transport protocol. It can be up to 8x\\nfaster tha\", \"n JSON serialization with message sizes 60-80% smaller. gRPC is open source and\\nmanaged by the Cloud\", \" Native Computing Foundation (CNCF).\\n\\u2022 Distributed data is a model often implemented by cloud-native\", \" applications. Applications\\nsegregate business functionality into small, independent microservices. \", \"Each microservice\\nencapsulates its own dependencies, data, and state. The classic shared database mo\", \"del\\nevolves into one of many smaller databases, each aligning with a microservice. When the\\nsmoke cl\", \"ears, we emerge with a design that exposes a database-per-microservice model.\\n\\u2022 No-SQL databases ref\", \"er to high-performance, non-relational data stores. They excel in their\\nease-of-use, scalability, re\", \"silience, and availability characteristics. High volume services that\\nrequire sub second response ti\", \"me favor NoSQL datastores. The proliferation of NoSQL\\ntechnologies for distributed cloud-native syst\", \"ems can\\u2019t be overstated.\\n\\u2022 NewSQL is an emerging database technology that combines the distributed s\", \"calability of\\nNoSQL and the ACID guarantees of a relational database. NewSQL databases target busine\", \"ss\\nsystems that must process high-volumes of data, across distributed environments, with full\\ntransa\", \"ctional/ACID compliance. The Cloud Native Computing Foundation (CNCF) features\\nseveral NewSQL databa\", \"se projects.\\n\\u2022 Resiliency is the ability of your system to react to failure and still remain functio\", \"nal. Cloud-\\nnative systems embrace distributed architecture where failure is inevitable. Application\", \"s must\\nbe constructed to respond elegantly to failure and quickly return to a fully functioning stat\", \"e.\\n\\u2022 Service meshes are a configurable infrastructure layer with built-in capabilities to handle\\nser\", \"vice communication and other cross-cutting challenges. They decouple cross-cutting\\nresponsibilities \", \"from your business code. These responsibilities move into a service proxy.\\nReferred to as the Sideca\", \"r pattern, the proxy is deployed into a separate process to provide\\nisolation from your business cod\", \"e.\\n\\u2022 Observability is a key design consideration for cloud-native applications. As services are\\ndist\", \"ributed across a cluster of nodes, centralized logging, monitoring, and alerts, become\\nmandatory. Az\", \"ure Monitor is a collection of cloud-based tools designed to provide visibility\\ninto the state of yo\", \"ur system.\\n182 CHAPTER 11 | Summary: Architecting cloud-native apps\\u2022 Infrastructure as Code is a wid\", \"ely accepted practice that automates platform provisioning.\\nYour infrastructure and deployments are \", \"automated, consistent, and repeatable. Tools like\\nAzure Resource Manager, Terraform, and the Azure C\", \"LI, enable you to declaratively script the\\ncloud infrastructure you require.\\n\\u2022 Code automation is a \", \"requirement for cloud-native applications. Modern CI/CD systems help\\nfulfill this principle. They pr\", \"ovide separate build and deployment steps that help ensure\\nconsistent and quality code. The build st\", \"age transforms the code into a binary artifact. The\\nrelease stage picks up the binary artifact, appl\", \"ies external environment configuration, and\\ndeploys it to a specified environment. Azure DevOps and \", \"GitHub are full-featured DevOps\\nenvironments.\\n183 CHAPTER 11 | Summary: Architecting cloud-native ap\", \"ps\"]"