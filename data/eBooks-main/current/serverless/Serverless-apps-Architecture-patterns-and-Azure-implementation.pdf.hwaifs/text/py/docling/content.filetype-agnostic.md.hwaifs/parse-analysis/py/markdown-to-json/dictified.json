{"*": {"Azure Logic Apps": "Azure Logic Apps provides a serverless engine to build automated workflows to integrate apps and data between cloud services and on -premises systems. You build workflows using a visual designer. You can trigger workflows based on events or timers and leverage connectors to integration applications and facilitate business-to-business (B2B) communication. Logic Apps integrates seamlessly with Azure Functions.\n\nLogic Apps can do more than just connect your cloud services (like functions) with cloud resources (like queues and databases). You can also orchestrate on-premises workflows with the on-premises gateway. For example, you can use the Logic App to trigger an on-premises SQL stored procedure in response to a cloud-based event or conditional logic in your workflow. Learn more about Connecting to on -premises data sources with Azure On-premises Data Gateway .\n\n08:30\n\n03 PM\n\nAvg\n\n50\u2122H\n\n95\u2122H\n\n99\u2122H\n\nRefresh\n\nStart with a common trigger\n\nPick from one of the most commonly used triggers, then orchestrate any number of actions using the rich collection of connectors\n\nAzure Functions\n\nWhen a message is received in a Service\n\nBus queue\n\nService bus\n\nRecurrence\n\n9S Cognitive services\n\n/ Machine learning\n\n5 &gt; SharePoint\n\n<!-- image -->\n\nLike Azure Functions, you kick off Logic App workflows with a trigger. There are many triggers for you to choose from. The following capture shows just a few of the more popular ones out of hundreds that are available.\n\n<!-- image -->\n\nOnce the app is triggered, you can use the visual designer to build out steps, loops, conditions, and actions. Any data ingested in a previous step is available for you to use in subsequent steps. The following workflow loads URLs from a CosmosDB database. It finds the ones with a host of t.co then searches for them on Twitter. If it finds corresponding tweets, it updates the documents with the related tweets by calling a function.\n\nWhen a HTTP\n\nrequest is received\n\nSQL\n\nWhen a new tweet is posted\n\nWhen a Event Grid event occurs\n\n\u2022 Office 365\n\nIf true\n\nFor each\n\n\"Select an output from previous steps\n\nScope\n\n{x}\n\n{x}\n\nRecurrence\n\nInitialize variable\n\nInitialize variable 2\n\n<!-- image -->\n\nI Add anaction II Add a condition\n\nThe Logic Apps dashboard shows the history of running your workflows and whether each run completed successfully or not. You can navigate into any given run and inspect the data used by each step for troubleshooting. Logic Apps also provides existing templates you can edit and are well suited for complex enterprise workflows.\n\nTo learn more, see Azure Logic Apps .", "Event Grid": "Azure Event Grid provides serverless infrastructure for event-based applications. You can publish to Event Grid from any source and consume messages from any platform. Event Grid also has built-in support for events from Azure resources to streamline integration with your applications. For example, you can subscribe to blob storage events to notify your app when a file is uploaded. Your application can then publish a custom event grid message that is consumed by other cloud or on-premises applications. Event Grid was built to reliably handle massive scale. You get the benefits of publishing and subscribing to messages without the overhead of setting up the necessary infrastructure.\n\nC: \\\n\n<!-- image -->\n\nThe major features of event grid include:\n\n['Fully managed event routing.', 'Near real -time event delivery at scale.', 'Broad coverage both inside and outside of Azure.']", "Scenarios": "Event Grid addresses several different scenarios. This section covers three of the most common ones.", "Ops automation": "<!-- image -->\n\nEvent Grid can help speed automation and simplify policy enforcement by notifying Azure Automation when infrastructure is provisioned.", "Application integration": "<!-- image -->\n\nYou can use Event Grid to connect your app to other services. Using standard HTTP protocols, even legacy apps can be easily modified to publish Event Grid messages. Web hooks are available for other services and platforms to consume Event Grid messages.", "Serverless apps": "<!-- image -->\n\nEvent Grid can trigger Azure Functions, Logic Apps, or your own custom code. A major benefit of using Event Grid is that it uses a push mechanism to send messages when events occur. The push architecture consumes fewer resources and scales better than polling mechanisms. Polling must check for updates on a regular interval.", "Event Grid vs. other Azure messaging services": "Azure provides several messaging services, including Event Hubs and Service Bus. Each is designed to address a specific set of use cases. The following diagram provides a high-level overview of the differences between the services.\n\nEvent Hubs\n\n\u2022 \"Point in time\" data\n\n\u2022 Fast pull\n\n\u2022 Replay / strict ordering\n\n\u2022 Big data streams\n\n<!-- image -->\n\nFor a more in -depth comparison, see Compare messaging services .", "Performance targets": "Using Event Grid you can take advantage of the following performance guarantees:\n\n['Subsecond end -to -end latency in the 99th percentile.', '99.99% availability.', '10 million events per second per region.', '100 million subscriptions per region.', '50 -ms publisher latency.', '24 -hour retry with exponential back-off for guaranteed delivery in the 1-day window.', 'Transparent regional failover.']", "Event Grid schema": "Event Grid uses a standard schema to wrap custom events. The schema is like an envelope that wraps your custom data element. Here is an example Event Grid message:\n\n```\n[{ \"id\": \"03e24f21 -a955 -43cc -8921 -1f61a6081ce0\" , \"eventType\": \"myCustomEvent\" , \"subject\": \"foo/bar/12\" , \"eventTime\": \"2018 -09 -22T10:36:01+00:00\" , \"data\": { \"favoriteColor\": \"blue\" , \"favoriteAnimal\": \"panther\" , \"favoritePlanet\": \"Jupiter\" }, \"dataVersion\": \"1.0\" }]\n```\n\nEverything about the message is standard except the data property. You can inspect the message and use the eventType and dataVersion to de-serialize the custom portion of the payload.", "Azure resources": "A major benefit of using Event Grid is the automatic messages produced by Azure. In Azure, resources automatically publish to a topic that allows you to subscribe for various events. The following table lists the resource types, message types, and events that are available automatically.\n\n| Azure resource     | Event type                                | Description                                                                                                     |\n|--------------------|-------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n| Azure subscription | Microsoft.Resources.ResourceWriteSuccess  | Raised when a resource create or update operation succeeds.                                                     |\n|                    | Microsoft.Resources.ResourceWriteFailure  | Raised when a resource create or update operation fails.                                                        |\n|                    | Microsoft.Resources.ResourceWriteCancel   | Raised when a resource create or update operation is canceled.                                                  |\n|                    | Microsoft.Resources.ResourceDeleteSuccess | Raised when a resource delete operation succeeds.                                                               |\n|                    | Microsoft.Resources.ResourceDeleteFailure | Raised when a resource delete operation fails.                                                                  |\n|                    | Microsoft.Resources.ResourceDeleteCancel  | Raised when a resource delete operation is canceled. This event happens when a template deployment is canceled. |\n| Blob storage       | Microsoft.Storage.BlobCreated             | Raised when a blob is created.                                                                                  |\n|                    | Microsoft.Storage.BlobDeleted             | Raised when a blob is deleted.                                                                                  |\n| Event hubs         | Microsoft.EventHub.CaptureFileCreated     | Raised when a capture file is created.                                                                          |\n| IoT Hub            | Microsoft.Devices.DeviceCreated           | Published when a device is registered to an IoT hub.                                                            |\n|                    | Microsoft.Devices.DeviceDeleted           | Published when a device is deleted from an IoT hub.                                                             |\n| Resource groups    | Microsoft.Resources.ResourceWriteSuccess  | Raised when a resource create or update operation succeeds.                                                     |\n|                    | Microsoft.Resources.ResourceWriteFailure  | Raised when a resource create or update operation fails.                                                        |\n|                    | Microsoft.Resources.ResourceWriteCancel   | Raised when a resource create or update operation is canceled.                                                  |\n|                    | Microsoft.Resources.ResourceDeleteSuccess | Raised when a resource delete operation succeeds.                                                               |\n|                    | Microsoft.Resources.ResourceDeleteFailure | Raised when a resource delete operation fails.                                                                  |\n\n| Azure resource   | Event type                               | Description                                                                                                     |\n|------------------|------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n|                  | Microsoft.Resources.ResourceDeleteCancel | Raised when a resource delete operation is canceled. This event happens when a template deployment is canceled. |\n\nFor more information, see Azure Event Grid event schema .\n\nYou can access Event Grid from any type of application, even one that runs on-premises.", "Conclusion": "The following key takeaways are the most important conclusions from this guide.\n\nBenefits of using serverless. Serverless solutions provide the important benefit of cost savings because serverless is implemented in a pay-per-use model. Serverless makes it possible to independently scale, test, and deploy individual components of your application. Serverless is uniquely suited to implement microservices architectures and integrates fully into a DevOps pipeline.\n\nCode as a unit of deployment. Serverless abstracts the hardware, OS, and runtime away from the application. Serverless enables focusing on business logic in code as the unit of deployment.\n\nTriggers and bindings. Serverless eases integration with storage, APIs, and other cloud resources. Azure Functions provides triggers to execute code and bindings to interact with resources.\n\nMicroservices. The microservices architecture is becoming the preferred approach for distributed and large or complex mission-critical applications that are based on multiple independent subsystems in the form of autonomous services. In a microservice -based architecture, the application is built as a collection of services that can be developed, tested, versioned, deployed, and scaled independently. Serverless is an architecture well -suited for building these services.\n\nServerless platforms. Serverless isn't just about the code. Platforms that support serverless architectures include serverless workflows and orchestration, serverless messaging and event services, and serverless databases.\n\nServerless challenges. Serverless introduces challenges related to distributed application development, such as fragmented and independent data models, resiliency, versioning, and service discovery. Serverless may not be ideally suited to long running processes or components that benefit from tighter coupling.\n\nServerless as a tool, not the toolbox. Serverless is not the exclusive solution to application architecture. It is a tool that can be leveraged as part of a hybrid application that may contain traditional tiers, monolith back ends, and containers. Serverless can be used to enhance existing solutions and is not an all -or-nothing approach to application development.\n\nCHAPTER\n\n6C", "Recommended resources": ["Big Data Processing: Serverless MapReduce on Azure", "Create serverless applications", "Customer Reviews App with Cognitive Services", "File processing and validation using Azure Functions, Logic Apps, and Durable Functions", "Implementing a simple Azure Function with a Xamarin.Forms client", "In -editor game telemetry visualization", "IoT Reliable Edge Relay", "Produce and Consume messages through Service Bus, Event Hubs, and Storage Queues with Azure Functions", "Serverless functions for GraphQL", "Serverless Microservices reference architecture"], "Durable Azure Functions": "When creating serverless applications with Azure Functions, your operations will typically be designed to run in a stateless manner. The reason for this design choice is because as the platform scales, it becomes difficult to know what servers the code is running on. It also becomes difficult to know how many instances are active at any given point. However, there are classes of applications that require the current state of a process to be known. Consider the process of submitting an order to an online store. The checkout operation might be a workflow that is composed of multiple operations that need to know the state of the process. Such information may include the product inventory, if the customer has any credits on their account, and also the results of processing the credit card. These operations could easily be their own internal workflows or even services from third-party systems.\n\nVarious patterns exist today that assist with the coordination of application state between internal and external systems. It's common to come across solutions that rely on centralized queuing systems, distributed key-value stores, or shared databases to manage that state. However, these are all additional resources that now need to be provisioned and managed. In a serverless environment, your code could become cumbersome trying to coordinate with these resources manually. Azure Functions offers an alternative for creating stateful functions called Durable Functions.\n\nDurable Functions is an extension to the Azure Functions runtime that enables the definition of stateful workflows in code. By breaking down workflows into activities, the Durable Functions extension can manage state, create progress checkpoints, and handle the distribution of function calls across servers. In the background, it makes use of an Azure Storage account to persist execution history, schedule activity functions and retrieve responses. Your serverless code should never interact with persisted information in that storage account, and is typically not something with which developers need to interact.", "Triggering a stateful workflow": "Stateful workflows in Durable Functions can be broken down into two intrinsic components; orchestration and activity triggers. Triggers and bindings are core components used by Azure Functions to enable your serverless functions to be notified when to start, receive input, and return results.", "Working with the Orchestration client": "Orchestrations are unique when compared to other styles of triggered operations in Azure Functions. Durable Functions enables the execution of functions that may take hours or even days to complete. That type of behavior comes with the need to able to check the status of a running orchestration, preemptively terminate, or send notifications of external events.\n\nFor such cases, the Durable Functions extension provides the DurableOrchestrationClient class that allows you to interact with orchestrated functions. You get access to the orchestration client by using the OrchestrationClientAttribute binding. Generally, you would include this attribute with another trigger type, such as an HttpTrigger or ServiceBusTrigger. Once the source function has been triggered, the orchestration client can be used to start an orchestrator function.\n\n```\n[FunctionName(\"KickOff\")] public static async Task<HttpResponseMessage> Run( [HttpTrigger(AuthorizationLevel.Function , \"POST\")]HttpRequestMessage req, [OrchestrationClient ] DurableOrchestrationClient<orchestrationClient>) { OrderRequestData data = await req.Content . ReadAsAsync<OrderRequestData>(); string instanceId = await orchestrationClient.StartNewAsync(\"PlaceOrder\", data); return orchestrationClient.CreateCheckStatusResponse(req, instanceId); }\n```", "The orchestrator function": "Annotating a function with the OrchestrationTriggerAttribute in Azure Functions marks that function as an orchestrator function. It's responsible for managing the various activities that make up your stateful workflow.\n\nOrchestrator functions are unable to make use of bindings other than the OrchestrationTriggerAttribute. This attribute can only be used with a parameter type of DurableOrchestrationContext. No other inputs can be used since deserialization of inputs in the function signature isn't supported. To get inputs provided by the orchestration client, the GetInput&lt;T&gt; method must be used.\n\nAlso, the return types of orchestration functions must be either void, Task, or a JSON serializable value.\n\nError handling code has been left out for brevity\n\n```\n[FunctionName(\"PlaceOrder\")] public static async Task<string> PlaceOrder([OrchestrationTrigger] DurableOrchestrationContext context) { OrderRequestData orderData = context.GetInput<OrderRequestData>(); await context.CallActivityAsync<bool>(\"CheckAndReserveInventory\", orderData); await context.CallActivityAsync<string>(\"ProcessPayment\", orderData); string trackingNumber = await context.CallActivityAsync<string>(\"ScheduleShipping\" , orderData); await context.CallActivityAsync<string>(\"EmailCustomer\", trackingNumber); return trackingNumber; }\n```\n\nMultiple instances of an orchestration can be started and running at the same time. Calling the StartNewAsync method on the DurableOrchestrationClient launches a new instance of the orchestration. The method returns a Task&lt;string&gt; that completes when the orchestration has started.\n\nAn exception of type TimeoutException gets thrown if the orchestration hasn't started within 30 seconds.\n\nThe completed Task&lt;string&gt; from StartNewAsync should contain the unique ID of the orchestration instance. This instance ID can be used to invoke operations on that specific orchestration. The orchestration can be queried for the status or sent event notifications.", "The activity functions": "Activity functions are the discrete operations that get composed together within an orchestration function to create the workflow. Here is where most of actual work would take place. They represent the business logic, long running processes, and the puzzle pieces to a larger solution.\n\nThe ActivityTriggerAttribute is used to annotate a function parameter of type DurableActivityContext. Using the annotation informs the runtime that the function is intended to be used as an activity function. Input values to activity functions are retrieved using the GetInput&lt;T&gt; method of the DurableActivityContext parameter.\n\nSimilar to orchestration functions, the return types of activity functions must be either void, Task, or a JSON serializable value.\n\nAny unhandled exceptions that get thrown within activity functions will get sent up to the calling orchestrator function and presented as a TaskFailedException. At this point, the error can be caught and logged in the orchestrator, and the activity can be retried.\n\n```\n[FunctionName(\"CheckAndReserveInventory\")] public static bool CheckAndReserveInventory([ActivityTrigger] DurableActivityContext context) { OrderRequestData orderData = context.GetInput<OrderRequestData>(); // Connect to inventory system and try to reserve items return true; }\n```", "Orchestration patterns": "Durable Functions makes it easier to create stateful workflows that are composed of discrete, long running activities in a serverless environment. Since Durable Functions can track the progress of your workflows and periodically checkpoints the execution history, it lends itself to implementing some interesting patterns.", "Function chaining": "In a typical sequential process, activities need to execute one after the other in a particular order. Optionally, the upcoming activity may require some output from the previous function. This dependency on the ordering of activities creates a function chain of execution.\n\nThe benefit of using Durable Functions to implement this workflow pattern comes from its ability to do checkpointing. If the server crashes, the network times out or some other issue occurs, Durable functions can resume from the last known state and continue running your workflow even if it's on another server.\n\n```\n[FunctionName(\"PlaceOrder\")] public static async Task<string> PlaceOrder([OrchestrationTrigger] DurableOrchestrationContext context) { OrderRequestData orderData = context.GetInput<OrderRequestData>(); await context.CallActivityAsync<bool>(\"CheckAndReserveInventory\", orderData); await context.CallActivityAsync<bool>(\"ProcessPayment\", orderData); string trackingNumber = await context.CallActivityAsync<string>(\"ScheduleShipping\" , orderData); await context.CallActivityAsync<string>(\"EmailCustomer\", trackingNumber); return trackingNumber; }\n```\n\nIn the preceding code sample, the CallActivityAsync function is responsible for running a given activity on a virtual machine in the data center. When the await returns and the underlying Task completes, the execution will be recorded to the history table. The code in the orchestrator function can make use of any of the familiar constructs of the Task Parallel Library and the async/await keywords.\n\nThe following code is a simplified example of what the ProcessPayment method may look like:\n\n```\n[FunctionName(\"ProcessPayment\")] public static bool ProcessPayment([ActivityTrigger] DurableActivityContext context) { OrderRequestData orderData = context.GetInput<OrderRequestData>(); ApplyCoupons(orderData); if(IssuePaymentRequest(orderData)) { return true; } return false; }\n```", "Asynchronous HTTP APIs": "In some cases, workflows may contain activities that take a relatively long period of time to complete. Imagine a process that kicks off the backup of media files into blob storage. Depending on the size and quantity of the media files, this backup process may take hours to complete.\n\nIn this scenario, the DurableOrchestrationClient's ability to check the status of a running workflow becomes useful. When using an HttpTrigger to start a workflow, the CreateCheckStatusResponse method can be used to return an instance of HttpResponseMessage. This response provides the client with a URI in the payload that can be used to check the status of the running process.\n\n```\n[FunctionName(\"OrderWorkflow\")] public static async Task<HttpResponseMessage> Run( [HttpTrigger(AuthorizationLevel.Function , \"POST\")]HttpRequestMessage req, [OrchestrationClient ] DurableOrchestrationClient orchestrationClient) { OrderRequestData data = await req.Content . ReadAsAsync<OrderRequestData>(); string instanceId = await orchestrationClient.StartNewAsync(\"PlaceOrder\", data); return orchestrationClient.CreateCheckStatusResponse(req, instanceId); }\n```\n\nThe sample result below shows the structure of the response payload.\n\n```\n{ \"id\": \"instanceId\" , \"statusQueryGetUri\": \"http://host/statusUri\" , \"sendEventPostUri\": \"http://host/eventUri\" , \"terminatePostUri\": \"http://host/terminateUri\" }\n```\n\nUsing your preferred HTTP client, GET requests can be made to the URI in statusQueryGetUri to inspect the status of the running workflow. The returned status response should resemble the following code.\n\n```\n{ \"runtimeStatus\": \"Running\" , \"input\": { \"$type\": \"DurableFunctionsDemos.OrderRequestData, DurableFunctionsDemos\" }, \"output\": null , \"createdTime\": \"2018 -01 -01T00:22:05Z\" , \"lastUpdatedTime\": \"2018-01-01T00:22:09Z\" }\n```\n\nAs the process continues, the status response will change to either Failed or Completed. On successful completion, the output property in the payload will contain any returned data.", "Monitoring": "For simple recurring tasks, Azure Functions provides the TimerTrigger that can be scheduled based on a CRON expression. The timer works well for simple, short-lived tasks, but there might be scenarios where more flexible scheduling is needed. This scenario is when the monitoring pattern and Durable Functions can help.\n\nDurable Functions allows for flexible scheduling intervals, lifetime management, and the creation of multiple monitor processes from a single orchestration function. One use case for this functionality might be to create watchers for stock price changes that complete once a certain threshold is met.\n\n```\n[FunctionName(\"CheckStockPrice\")] public static async Task CheckStockPrice([OrchestrationTrigger] DurableOrchestrationContext context) { StockWatcherInfo stockInfo = context.GetInput<StockWatcherInfo>(); const int checkIntervalSeconds = 120; StockPrice initialStockPrice = null; DateTime fireAt; DateTime exitTime = context.CurrentUtcDateTime . Add(stockInfo.TimeLimit); while (context.CurrentUtcDateTime < exitTime) { StockPrice currentStockPrice = await context.CallActivityAsync<StockPrice>(\"GetStockPrice\", stockInfo); if (initialStockPrice == null) { initialStockPrice = currentStockPrice; fireAt = context.CurrentUtcDateTime . AddSeconds(checkIntervalSeconds); await context.CreateTimer(fireAt, CancellationToken.None); continue; } decimal percentageChange = (initialStockPrice.Price -currentStockPrice.Price) / ((initialStockPrice.Price + currentStockPrice.Price) / 2); if (Math.Abs(percentageChange) >= stockInfo.PercentageChange) { // Change threshold detected await context.CallActivityAsync(\"NotifyStockPercentageChange\" , currentStockPrice); break; } // Sleep til next polling interval fireAt = context.CurrentUtcDateTime . AddSeconds(checkIntervalSeconds); await context.CreateTimer(fireAt, CancellationToken.None); } }\n```\n\nDurableOrchestrationContext's CreateTimer method sets up the schedule for the next invocation of the loop to check for stock price changes. DurableOrchestrationContext also has a CurrentUtcDateTime property to get the current DateTime value in UTC. It's better to use this property instead of DateTime.UtcNow because it's easily mocked for testing.", "Serverless business scenarios and use cases": "There are many use cases and scenarios for serverless applications. This chapter includes samples that illustrate the different scenarios. The scenarios include links to related documentation and public source code repositories. The samples in this chapter enable you to get started on your own building and implementing serverless solutions.", "Big data processing": "This example uses serverless to do a map/reduce operation on a big data set. It determines the average speed of New York Yellow taxi trips per day in 2017.\n\nBig Data Processing: Serverless MapReduce on Azure", "Create serverless applications: hands -on lab": "Learn how to use functions to execute server -side logic and build serverless architectures.\n\n['Choosing the best Azure service for your business', 'Creating Azure Functions', 'Using triggers', 'Chaining functions', 'Long -running workflows', 'Monitoring', 'Development, testing, and deployment']\n\nCreate serverless applications", "Customer reviews": "This sample showcases the new Azure Functions tooling for C# Class Libraries in Visual Studio. Create a website where customers submit product reviews that are stored in Azure storage blobs and\n\nCosmosDB. Add an Azure Function to perform automated moderation of the customer reviews using Azure Cognitive Services. Use an Azure storage queue to decouple the website from the function.\n\nCustomer Reviews App with Cognitive Services", "File processing and validation": "This example parses a set of CSV files from hypothetical customers. It ensures that all files required for a customer \"batch\" are ready, then validates the structure of each file. Different solutions are presented using Azure Functions, Logic Apps, and Durable Functions.\n\nFile processing and validation using Azure Functions, Logic Apps, and Durable Functions", "Game data visualization": "An example of how a developer could implement an in-editor data visualization solution for their game. In fact, an Unreal Engine 4 Plugin and Unity Plugin were developed using this sample as its backend. The service component is game engine agnostic.\n\nIn -editor game telemetry visualization", "GraphQL": "Create a serverless function that exposes a GraphQL API.\n\nServerless functions for GraphQL", "Internet of Things (IoT) reliable edge relay": "This sample implements a new communication protocol to enable reliable upstream communication from IoT devices. It automates data gap detection and backfill.\n\nIoT Reliable Edge Relay", "Microservices reference architecture": "A reference architecture that walks you through the decision-making process involved in designing, developing, and delivering the Rideshare by Relecloud application (a fictitious company). It includes hands -on instructions for configuring and deploying all of the architecture's components.", "Serverless for mobile": "Azure Functions are easy to implement and maintain, and accessible through HTTP. They are a great way to implement an API for a mobile application. Microsoft offers great cross-platform tools for iOS, Android, and Windows with Xamarin. As such, Xamarin and Azure Functions are working great together. This article shows how to implement an Azure Function in the Azure portal or in Visual Studio at first, and build a cross -platform client with Xamarin.Forms running on Android, iOS, and Windows.\n\nImplementing a simple Azure Function with a Xamarin.Forms client", "Serverless messaging": "This sample shows how to utilize Durable Functions' fan-out pattern to load an arbitrary number of messages across any number of sessions/partitions. It targets Service Bus, Event Hubs, or Storage Queues. The sample also adds the ability to consume those messages with another Azure Function and load the resulting timing data in to another Event Hub. The data is then ingested into analytics services like Azure Data Explorer.\n\nProduce and Consume messages through Service Bus, Event Hubs, and Storage Queues with Azure Functions"}}