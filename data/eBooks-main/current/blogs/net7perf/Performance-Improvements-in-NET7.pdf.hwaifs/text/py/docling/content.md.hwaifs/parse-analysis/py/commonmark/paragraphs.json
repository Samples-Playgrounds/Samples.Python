[
    "Partner Software Engineer, .NET",
    "Partner Software Engineer, .NET",
    "Microsoft",
    "Microsoft",
    "A year ago, I published Performance Improvements in .NET 6, following on the heels of similar posts for .NET 5, .NET Core 3.0, .NET Core 2.1, and .NET Core 2.0. I enjoy writing these posts and love reading developers",
    "A year ago, I published Performance Improvements in .NET 6, following on the heels of similar posts for .NET 5, .NET Core 3.0, .NET Core 2.1, and .NET Core 2.0. I enjoy writing these posts and love reading developers",
    "As with previous versions of .NET, performance is a key focus that pervades the entire stack, whether it be features created explicitly for performance or non-performance-related features that are still designed and implemented with performance keenly in mind. And now that a .NET 7 release candidate is just around the corner, it",
    "As with previous versions of .NET, performance is a key focus that pervades the entire stack, whether it be features created explicitly for performance or non-performance-related features that are still designed and implemented with performance keenly in mind. And now that a .NET 7 release candidate is just around the corner, it",
    "One thought before we dive in. In past years, I",
    "One thought before we dive in. In past years, I",
    "TL;DR: .NET 7 is fast. Really fast. A thousand performance-impacting PRs went into runtime and core libraries this release, never mind all the improvements in ASP.NET Core and Windows Forms and Entity Framework and beyond. It",
    "TL;DR: .NET 7 is fast. Really fast. A thousand performance-impacting PRs went into runtime and core libraries this release, never mind all the improvements in ASP.NET Core and Windows Forms and Entity Framework and beyond. It",
    "Or, if you prefer a slightly longer adventure, one filled with interesting nuggets of performancefocused data, consider skimming through the post, looking for the small code snippets and corresponding tables showing a wealth of measurable performance improvements. At that point, you, too, may walk away with your head held high and my thanks.",
    "Or, if you prefer a slightly longer adventure, one filled with interesting nuggets of performancefocused data, consider skimming through the post, looking for the small code snippets and corresponding tables showing a wealth of measurable performance improvements. At that point, you, too, may walk away with your head held high and my thanks.",
    "Both noted paths achieve one of my primary goals for spending the time to write these posts, to highlight the greatness of the next release and to encourage everyone to give it a try. But, I have other goals for these posts, too. I want everyone interested to walk away from this post with an upleveled understanding of how .NET is implemented, why various decisions were made, tradeoffs that were evaluated, techniques that were employed, algorithms that were considered, and valuable tools and approaches that were utilized to make .NET even faster than it was previously. I want developers to learn from our own learnings and find ways to apply this new-found knowledge to their own codebases, thereby further increasing the overall performance of code in the ecosystem. I want developers to take an extra beat, think about reaching for a profiler the next time they",
    "Both noted paths achieve one of my primary goals for spending the time to write these posts, to highlight the greatness of the next release and to encourage everyone to give it a try. But, I have other goals for these posts, too. I want everyone interested to walk away from this post with an upleveled understanding of how .NET is implemented, why various decisions were made, tradeoffs that were evaluated, techniques that were employed, algorithms that were considered, and valuable tools and approaches that were utilized to make .NET even faster than it was previously. I want developers to learn from our own learnings and find ways to apply this new-found knowledge to their own codebases, thereby further increasing the overall performance of code in the ecosystem. I want developers to take an extra beat, think about reaching for a profiler the next time they",
    "| Setup.........................................................................................................................................                                                | 1                                                                                                                                                                                   |",
    "| Setup.........................................................................................................................................                                                | 1                                                                                                                                                                                   |",
    "File I/O ..................................................................................................................................  159",
    "File I/O ..................................................................................................................................  159",
    "Compression ........................................................................................................................  168",
    "Compression ........................................................................................................................  168",
    "Networking ..........................................................................................................................  173",
    "Networking ..........................................................................................................................  173",
    "JSON .....................................................................................................................................  190",
    "JSON .....................................................................................................................................  190",
    "XML .......................................................................................................................................  193",
    "XML .......................................................................................................................................  193",
    "Cryptography  .......................................................................................................................  198",
    "Cryptography  .......................................................................................................................  198",
    "Diagnostics  ...........................................................................................................................  203",
    "Diagnostics  ...........................................................................................................................  203",
    "Exceptions ............................................................................................................................  208",
    "Exceptions ............................................................................................................................  208",
    "Registry ................................................................................................................................  211",
    "Registry ................................................................................................................................  211",
    "Analyzers ..............................................................................................................................  213",
    "Analyzers ..............................................................................................................................  213",
    "What",
    "What",
    "........................................................................................................................  227",
    "........................................................................................................................  227",
    "The microbenchmarks throughout this post utilize benchmarkdotnet. To make it easy for you to follow along with your own validation, I have a very simple setup for the benchmarks I use. Create a new C# project:",
    "The microbenchmarks throughout this post utilize benchmarkdotnet. To make it easy for you to follow along with your own validation, I have a very simple setup for the benchmarks I use. Create a new C# project:",
    "Your new benchmarks directory will contain a benchmarks.csproj file and a Program.cs file. Replace the contents of benchmarks.csproj with this:",
    "Your new benchmarks directory will contain a benchmarks.csproj file and a Program.cs file. Replace the contents of benchmarks.csproj with this:",
    "and the contents of Program.cs with this:",
    "and the contents of Program.cs with this:",
    "For each benchmark included in this write-up, you can then just copy and paste the code into this test class, and run the benchmarks. For example, to run a benchmark comparing performance on .NET 6 and .NET 7, do:",
    "For each benchmark included in this write-up, you can then just copy and paste the code into this test class, and run the benchmarks. For example, to run a benchmark comparing performance on .NET 6 and .NET 7, do:",
    "This command says ",
    "This command says ",
    "which instead builds targeting the .NET 7 surface area and then only runs once against .NET 7. You can do this on any of Windows, Linux, or macOS. Unless otherwise called out (e.g. where the improvements are specific to Unix and I run the benchmarks on Linux), the results I share were recorded on Windows 11 64bit but aren",
    "which instead builds targeting the .NET 7 surface area and then only runs once against .NET 7. You can do this on any of Windows, Linux, or macOS. Unless otherwise called out (e.g. where the improvements are specific to Unix and I run the benchmarks on Linux), the results I share were recorded on Windows 11 64bit but aren",
    "The release of the first .NET 7 release candidate is right around the corner. All of the measurements in this post were gathered with a recent daily build of .NET 7 RC1.",
    "The release of the first .NET 7 release candidate is right around the corner. All of the measurements in this post were gathered with a recent daily build of .NET 7 RC1.",
    "Also, my standard caveat: These are microbenchmarks. It is expected that different hardware, different versions of operating systems, and the way in which the wind is currently blowing can affect the numbers involved. Your mileage may vary.",
    "Also, my standard caveat: These are microbenchmarks. It is expected that different hardware, different versions of operating systems, and the way in which the wind is currently blowing can affect the numbers involved. Your mileage may vary.",
    "I",
    "I",
    "One common approach is to use the ",
    "One common approach is to use the ",
    "with:",
    "with:",
    "in addition to doing all of its normal test execution and timing, benchmarkdotnet also outputs a Program-asm.md file that contains this:",
    "in addition to doing all of its normal test execution and timing, benchmarkdotnet also outputs a Program-asm.md file that contains this:",
    "Pretty neat. This support was recently improved further in dotnet/benchmarkdotnet#2072, which allows passing a filter list on the commandline to benchmarkdotnet to tell it exactly which methods",
    "Pretty neat. This support was recently improved further in dotnet/benchmarkdotnet#2072, which allows passing a filter list on the commandline to benchmarkdotnet to tell it exactly which methods",
    "If you can get your hands on a ",
    "If you can get your hands on a ",
    "\u2026 until .NET 7, that is. As of dotnet/runtime#73365, this assembly dumping support is now available in release builds as well, which me ans it",
    "\u2026 until .NET 7, that is. As of dotnet/runtime#73365, this assembly dumping support is now available in release builds as well, which me ans it",
    "and building it (e.g. dotnet build -c Release ). Then, set the DOTNET",
    "and building it (e.g. dotnet build -c Release ). Then, set the DOTNET",
    "and then running the app. You should see code like this output to the console:",
    "and then running the app. You should see code like this output to the console:",
    "This is immeasurably helpful for perf ormance analysis and tuning, even for questions as simple as ",
    "This is immeasurably helpful for perf ormance analysis and tuning, even for questions as simple as ",
    "Note that it can sometimes be a little confusing figuring out what name to specify as the value for DOTNET",
    "Note that it can sometimes be a little confusing figuring out what name to specify as the value for DOTNET",
    "We can see for ",
    "We can see for ",
    "[",
    "[",
    "method, which doesn",
    "method, which doesn",
    "With that out of the way, let",
    "With that out of the way, let",
    "On-stack replacement (OSR) is one of the coolest features to hit the JIT in .NET 7. But to really understand OSR, we first need to understand tiered compilation, so a quick recap\u2026",
    "On-stack replacement (OSR) is one of the coolest features to hit the JIT in .NET 7. But to really understand OSR, we first need to understand tiered compilation, so a quick recap\u2026",
    "One of the issues a managed environment with a JIT compiler has to deal with is tradeoffs between startup and throughput. Historically, the job of an optimizing compiler is to, well, optimize, in order to enable the best possible throughput of the application or service once running. But such optimization takes analysis, takes time, and performing all of that work then leads to increased startup time, as all of the code on the startup path (e.g. all of the code that needs to be run before a web server can serve the first request) needs to be compiled. So a JIT compiler needs to make tradeoffs: better throughput at the expense of longer startup time, or better startup time at the expense of decreased throughput. For some kinds of apps and services, the tradeoff is an easy call, e.g. if your service starts up once and then runs for days, several extra seconds of startup time doesn",
    "One of the issues a managed environment with a JIT compiler has to deal with is tradeoffs between startup and throughput. Historically, the job of an optimizing compiler is to, well, optimize, in order to enable the best possible throughput of the application or service once running. But such optimization takes analysis, takes time, and performing all of that work then leads to increased startup time, as all of the code on the startup path (e.g. all of the code that needs to be run before a web server can serve the first request) needs to be compiled. So a JIT compiler needs to make tradeoffs: better throughput at the expense of longer startup time, or better startup time at the expense of decreased throughput. For some kinds of apps and services, the tradeoff is an easy call, e.g. if your service starts up once and then runs for days, several extra seconds of startup time doesn",
    "certain baseline instruction set (e.g. what vectorizing instructions are available) whereas the JIT can see what",
    "certain baseline instruction set (e.g. what vectorizing instructions are available) whereas the JIT can see what",
    "Tiered compilation enables the JIT to have its proverbial cake and eat it, too. The idea is simple: allow the JIT to compile the same code multiple times. The first time, the JIT can use as a few optimizations as make sense (a handful of optimizations can actually make the JIT",
    "Tiered compilation enables the JIT to have its proverbial cake and eat it, too. The idea is simple: allow the JIT to compile the same code multiple times. The first time, the JIT can use as a few optimizations as make sense (a handful of optimizations can actually make the JIT",
    "A problem, however, is methods that don",
    "A problem, however, is methods that don",
    "I get numbers printed out like:",
    "I get numbers printed out like:",
    "Now, try setting DOTNET",
    "Now, try setting DOTNET",
    "In other words, with DOTNET",
    "In other words, with DOTNET",
    "but importantly, this method was still participating in tiering. In fact, we can get confirmation of that by using the aforementioned DOTNET",
    "but importantly, this method was still participating in tiering. In fact, we can get confirmation of that by using the aforementioned DOTNET",
    "highlighting that Main was indeed compiled twice. How is that possible? On-stack replacement.",
    "highlighting that Main was indeed compiled twice. How is that possible? On-stack replacement.",
    "The idea behind on-stack replacement is a method can be replaced not just between invocations but even while it",
    "The idea behind on-stack replacement is a method can be replaced not just between invocations but even while it",
    "A few relevant things to notice here. First, the comments at the top highlight how this code was compiled:",
    "A few relevant things to notice here. First, the comments at the top highlight how this code was compiled:",
    "So, we know this is the initial version (",
    "So, we know this is the initial version (",
    "Our IsAsciiDigit helper method is trivially inlineable, but it",
    "Our IsAsciiDigit helper method is trivially inlineable, but it",
    "C745A8E8030000       mov      dword ptr ",
    "C745A8E8030000       mov      dword ptr ",
    "That 0x3E8 is the hex value for the decimal 1,000, which is the default number of iterations a loop needs to iterate before the JIT will generate the optimized version of the method (this is configurable via the DOTNET",
    "That 0x3E8 is the hex value for the decimal 1,000, which is the default number of iterations a loop needs to iterate before the JIT will generate the optimized version of the method (this is configurable via the DOTNET",
    "The generated code is loading that counter into the ecx register, decrementing it, storing it back, and then seeing whether the counter dropped to 0. If it didn",
    "The generated code is loading that counter into the ecx register, decrementing it, storing it back, and then seeing whether the counter dropped to 0. If it didn",
    "| 48B9F04BF24FFC7F0000 BAE7070000 E82E1FB25F C5FB10442430 C5FB5905E049F6FF C4E1FB2CD0 488BC1 48F7EA 488BCA   | mov rcx, 0x7FFC4FF24BF0 mov edx, 0x7E7 call CORINFO",
    "| 48B9F04BF24FFC7F0000 BAE7070000 E82E1FB25F C5FB10442430 C5FB5905E049F6FF C4E1FB2CD0 488BC1 48F7EA 488BCA   | mov rcx, 0x7FFC4FF24BF0 mov edx, 0x7E7 call CORINFO",
    "Here, again, we notice a few interesting things. First, in the header we see this:",
    "Here, again, we notice a few interesting things. First, in the header we see this:",
    "so we know this is both optimized ",
    "so we know this is both optimized ",
    "| G",
    "| G",
    "This is loading a value into rcx , subtracting 48 from it (48 is the decimal ASCII value of the ",
    "This is loading a value into rcx , subtracting 48 from it (48 is the decimal ASCII value of the ",
    "Great, so now in .NET 7, we can largely avoid the tradeoffs between startup and throughput, as OSR enables tiered compilation to apply to all methods, even those that are long-running. A multitude of PRs went into enabling this, including many over the last few years, but all of the functionality was disabled in the shipping bits. Thanks to improvements like dotnet/runtime#62831 which implemented support for OSR on Arm64 (previously only x64 support was implemented), and dotnet/runtime#63406 and dotnet/runtime#65609 which revised how OSR imports and epilogs are handled, dotnet/runtime#65675 enables OSR (and as a result DOTNET",
    "Great, so now in .NET 7, we can largely avoid the tradeoffs between startup and throughput, as OSR enables tiered compilation to apply to all methods, even those that are long-running. A multitude of PRs went into enabling this, including many over the last few years, but all of the functionality was disabled in the shipping bits. Thanks to improvements like dotnet/runtime#62831 which implemented support for OSR on Arm64 (previously only x64 support was implemented), and dotnet/runtime#63406 and dotnet/runtime#65609 which revised how OSR imports and epilogs are handled, dotnet/runtime#65675 enables OSR (and as a result DOTNET",
    "But, tiered compilation and OSR aren",
    "But, tiered compilation and OSR aren",
    "When I do so, I get this output:",
    "When I do so, I get this output:",
    "Note, again, we see two outputs for Program:Test . First, we see the ",
    "Note, again, we see two outputs for Program:Test . First, we see the ",
    "This is so useful that components are now written with tiering in mind. Consider the new Regex source generator, which is discussed later in this post (Roslyn source generators were introduced a couple of years ago; just as how Roslyn analyzers are able to plug into the compiler and surface additional diagnostics based on all of the data the compiler learns from the source code, Roslyn source generators are able to analyze that same data and then further augment the compilation unit with additional source). The Regex source generator applies a technique based on this in dotnet/runtime#67775. Regex supports setting a process-wide timeout that gets applied to Regex instances that don",
    "This is so useful that components are now written with tiering in mind. Consider the new Regex source generator, which is discussed later in this post (Roslyn source generators were introduced a couple of years ago; just as how Roslyn analyzers are able to plug into the compiler and surface additional diagnostics based on all of the data the compiler learns from the source code, Roslyn source generators are able to analyze that same data and then further augment the compilation unit with additional source). The Regex source generator applies a technique based on this in dotnet/runtime#67775. Regex supports setting a process-wide timeout that gets applied to Regex instances that don",
    "which it then uses at call sites like this:",
    "which it then uses at call sites like this:",
    "In tier-0, these checks will still be emitted in the assembly code, but in tier-1 where throughput matters, if the relevant AppContext switch hasn",
    "In tier-0, these checks will still be emitted in the assembly code, but in tier-1 where throughput matters, if the relevant AppContext switch hasn",
    "Timeout.InfiniteTimeSpan , at which point s",
    "Timeout.InfiniteTimeSpan , at which point s",
    "But, this is somewhat old news. The JIT has been able to do such an optimization since tiered compilation was introduced in .NET Core 3 .0. Now in .NET 7, though, with OSR it",
    "But, this is somewhat old news. The JIT has been able to do such an optimization since tiered compilation was introduced in .NET Core 3 .0. Now in .NET 7, though, with OSR it",
    "I wrote about profile-guided optimization (PGO) in my Performance Improvements in .NET 6 post, but I",
    "I wrote about profile-guided optimization (PGO) in my Performance Improvements in .NET 6 post, but I",
    "PGO has been around for a long time, in any number of languages and compilers. The basic idea is you compile your app, asking the compiler to inject instrumentation into the application to track various pieces of interesting information. You then put your app through its paces, running through various common scenarios, causing that instrumentation to ",
    "PGO has been around for a long time, in any number of languages and compilers. The basic idea is you compile your app, asking the compiler to inject instrumentation into the application to track various pieces of interesting information. You then put your app through its paces, running through various common scenarios, causing that instrumentation to ",
    "Dynamic PGO takes advantage of tiered compilation. I noted that the JIT instruments the tier-0 code to track how many times the method is called, or in the case of loops, how many times the loop executes. It can instrument it for other things as well. For example, it can track exactly which concrete types are used as the target of an interface dispatch, and then in tier-1 specialize the code to expect the most common types (this is referred to as ",
    "Dynamic PGO takes advantage of tiered compilation. I noted that the JIT instruments the tier-0 code to track how many times the method is called, or in the case of loops, how many times the loop executes. It can instrument it for other things as well. For example, it can track exactly which concrete types are used as the target of an interface dispatch, and then in tier-1 specialize the code to expect the most common types (this is referred to as ",
    "The tier-0 code for DoWork ends up looking like this:",
    "The tier-0 code for DoWork ends up looking like this:",
    "and most notably, you can see the call ",
    "and most notably, you can see the call ",
    "That first block is checking the concrete type of the IPrinter (stored in rdi ) and comparing it against the known type for Printer ( 0x7FFC3F1B2D98 ). If the y",
    "That first block is checking the concrete type of the IPrinter (stored in rdi ) and comparing it against the known type for Printer ( 0x7FFC3F1B2D98 ). If the y",
    "That all existed in .NET 6, so why are we talking about it now? Several things have improved. First, PGO now works with OSR, thanks to improvements like dotnet/runtime#61453 . That",
    "That all existed in .NET 6, so why are we talking about it now? Several things have improved. First, PGO now works with OSR, thanks to improvements like dotnet/runtime#61453 . That",
    "PGO already knew how to instrument virtual dispatch. Now in .NET 7, thanks in large part to dotnet/runtime#68703, it can do so for delegates as well (at least for delegates to instance methods). Consider this simple console app:",
    "PGO already knew how to instrument virtual dispatch. Now in .NET 7, thanks in large part to dotnet/runtime#68703, it can do so for delegates as well (at least for delegates to instance methods). Consider this simple console app:",
    "Without PGO enabled, I get generated optimized assembly like this:",
    "Without PGO enabled, I get generated optimized assembly like this:",
    "Note the call ",
    "Note the call ",
    "I chose the 42 constant in i =",
    "I chose the 42 constant in i =",
    "| 751D     | jne SHORT G",
    "| 751D     | jne SHORT G",
    "This is loading the target address from the delegate into r8 and is loading the address of the expected target into rax . If they",
    "This is loading the target address from the delegate into r8 and is loading the address of the expected target into rax . If they",
    "With PGO disabled, we get the same performance throughput for .NET 6 and .NET 7:",
    "With PGO disabled, we get the same performance throughput for .NET 6 and .NET 7:",
    "| Method      | Runtime   | Mean     |   Ratio |",
    "| Method      | Runtime   | Mean     |   Ratio |",
    "But the picture changes when we enable dynamic PGO ( DOTNET",
    "But the picture changes when we enable dynamic PGO ( DOTNET",
    "| Method      | Runtime   | Mean       |   Ratio |",
    "| Method      | Runtime   | Mean       |   Ratio |",
    "dotnet/runtime#70377 is another valuable improvement with dynamic PGO, which enables PGO to play nicely with loop cloning and invariant hoisting. To understand this better, a brief digression into what those are. Loop cloning is a mechanism the JIT employs to avoid various overheads in the fast path of a loop. Consider the Test method in this example:",
    "dotnet/runtime#70377 is another valuable improvement with dynamic PGO, which enables PGO to play nicely with loop cloning and invariant hoisting. To understand this better, a brief digression into what those are. Loop cloning is a mechanism the JIT employs to avoid various overheads in the fast path of a loop. Consider the Test method in this example:",
    "The JIT doesn",
    "The JIT doesn",
    "That way, at the expense of some code duplication, we get our fast loop without bounds checks and only pay for the bounds checks in the slow path. You can see this in the generated assembly (if you can",
    "That way, at the expense of some code duplication, we get our fast loop without bounds checks and only pay for the bounds checks in the slow path. You can see this in the generated assembly (if you can",
    "That G",
    "That G",
    "with the bounds checks only showing up in the slow-path block:",
    "with the bounds checks only showing up in the slow-path block:",
    "That",
    "That",
    "Note that the value of array.Length - 42 doesn",
    "Note that the value of array.Length - 42 doesn",
    "Here again we see the array being tested for null ( test rcx, rcx ) and the array",
    "Here again we see the array being tested for null ( test rcx, rcx ) and the array",
    "Ok, so how does this apply to dynamic PGO? Remember that with the interface/virtual dispatch avoidance PGO is able to do, it does so by doing a type check to see whether the type in use is the most common type; if it is, it uses a fast path that calls directly to that type",
    "Ok, so how does this apply to dynamic PGO? Remember that with the interface/virtual dispatch avoidance PGO is able to do, it does so by doing a type check to see whether the type in use is the most common type; if it is, it uses a fast path that calls directly to that type",
    "When we look at the optimized assembly generated for this with dynamic PGO enabled, we see this:",
    "When we look at the optimized assembly generated for this with dynamic PGO enabled, we see this:",
    "We can see in the G",
    "We can see in the G",
    "jne SHORT G",
    "jne SHORT G",
    "Interestingly, improvements like this can bring with them their own challenges. PGO leads to a significant increase in the number of type checks, since call sites that specialize for a given type need to compare against that type. However, common subexpression elimination (CSE) hasn",
    "Interestingly, improvements like this can bring with them their own challenges. PGO leads to a significant increase in the number of type checks, since call sites that specialize for a given type need to compare against that type. However, common subexpression elimination (CSE) hasn",
    "On .NET 6, the JIT produced this assembly code:",
    "On .NET 6, the JIT produced this assembly code:",
    "Note the C# has four tests for string and the assembly code has four loads with mov rax,offset MT",
    "Note the C# has four tests for string and the assembly code has four loads with mov rax,offset MT",
    "One of the things that makes .NET attractive is its safety. The runtime guards access to arrays, strings, and sp ans such that you can",
    "One of the things that makes .NET attractive is its safety. The runtime guards access to arrays, strings, and sp ans such that you can",
    "results in:",
    "results in:",
    "The array is passed into this method in the rcx register, pointing to the method table pointer in the object, and the length of an array is stored in the object just after that method table pointer (which is 8 bytes in a 64-bit process). Thus the cmp dword ptr ",
    "The array is passed into this method in the rcx register, pointing to the method table pointer in the object, and the length of an array is stored in the object just after that method table pointer (which is 8 bytes in a 64-bit process). Thus the cmp dword ptr ",
    "of the array and comparing the length to 0; that makes sense, since the length can",
    "of the array and comparing the length to 0; that makes sense, since the length can",
    "While these bounds checks in and of themselves aren",
    "While these bounds checks in and of themselves aren",
    "For example, dotnet/runtime#61662 from ",
    "For example, dotnet/runtime#61662 from ",
    "It",
    "It",
    "where that G",
    "where that G",
    "No bounds checks, which is most easily seen by the lack of the telltale call",
    "No bounds checks, which is most easily seen by the lack of the telltale call",
    "CORINFO",
    "CORINFO",
    "dotnet/runtime#61569 and dotnet/runtime#62864 also help to eliminate bounds checks when dealing with constant strings and spans initialized from RVA statics (",
    "dotnet/runtime#61569 and dotnet/runtime#62864 also help to eliminate bounds checks when dealing with constant strings and spans initialized from RVA statics (",
    "On .NET 6, we get this assembly:",
    "On .NET 6, we get this assembly:",
    "The beginning of this makes sense: the JIT was obviously able to see that the length of Text is 5, so it",
    "The beginning of this makes sense: the JIT was obviously able to see that the length of Text is 5, so it",
    "So much nicer.",
    "So much nicer.",
    "dotnet/runtime#67141 is a great example of how evolving ecosystem needs drives specific optimizations into the JIT. The Regex compiler and source generator handle some cases of regular expression character classes by using a bitmap lookup stored in strings. For example, to determine whether a char c is in the character class ",
    "dotnet/runtime#67141 is a great example of how evolving ecosystem needs drives specific optimizations into the JIT. The Regex compiler and source generator handle some cases of regular expression character classes by using a bitmap lookup stored in strings. For example, to determine whether a char c is in the character class ",
    "The implementation is treating an 8-character string as a 128-bit lookup table. If the character is known to be in range (such that it",
    "The implementation is treating an 8-character string as a 128-bit lookup table. If the character is known to be in range (such that it",
    "The previously mentioned PR takes care of the length check. And this PR takes care of the bit shift. So in .NET 7, we get this loveliness:",
    "The previously mentioned PR takes care of the length check. And this PR takes care of the bit shift. So in .NET 7, we get this loveliness:",
    "Note the distinct lack of a call CORINFO",
    "Note the distinct lack of a call CORINFO",
    "Bounds chec ks are an obvious source of overhead when talking about array access, but they",
    "Bounds chec ks are an obvious source of overhead when talking about array access, but they",
    "assembly code like the following would be generated:",
    "assembly code like the following would be generated:",
    "This should look fairly familiar from our previous discussion; the JIT is loading the array",
    "This should look fairly familiar from our previous discussion; the JIT is loading the array",
    null,
    null,
    "That",
    "That",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "This previous example assumes you know the size of each dimension of the multidimensional array (it",
    "This previous example assumes you know the size of each dimension of the multidimensional array (it",
    "multidimensional arrays can have a non-zero lower bound, Array.GetLowerBound . That would lead to code like this:",
    "multidimensional arrays can have a non-zero lower bound, Array.GetLowerBound . That would lead to code like this:",
    "In .NET 7, thanks to dotnet/runtime#60816, those GetLowerBound and GetUpperBound calls become JIT intrinsics. An ",
    "In .NET 7, thanks to dotnet/runtime#60816, those GetLowerBound and GetUpperBound calls become JIT intrinsics. An ",
    "Importantly, note there are no more call s (other than for the bounds check exception at the end). For example, instead of that first GetUpperBound call:",
    "Importantly, note there are no more call s (other than for the bounds check exception at the end). For example, instead of that first GetUpperBound call:",
    "we get:",
    "we get:",
    "and it ends up being much faster:",
    "and it ends up being much faster:",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "We previously saw how PGO interacts with loop hoisting and cloning, and those optimizations have seen other improvements, as well.",
    "We previously saw how PGO interacts with loop hoisting and cloning, and those optimizations have seen other improvements, as well.",
    "Historically, the JIT",
    "Historically, the JIT",
    "At first glance, you might look at this and say ",
    "At first glance, you might look at this and say ",
    "We can see that some hoisting has happened here. After all, the inner most loop (tagged M00",
    "We can see that some hoisting has happened here. After all, the inner most loop (tagged M00",
    "Notice now where those imul instructions live. There are four labels, each one corresponding to one of the loops, and we can see the outermost loop has the imul ebx,esi,3E8 (for the thousands computation) and the next loop has the imul r14d,edi,64 (for the hundreds computation), highlighting that these computations were hoisted out to the appropriate level (the tens and ones computation are still in the right places).",
    "Notice now where those imul instructions live. There are four labels, each one corresponding to one of the loops, and we can see the outermost loop has the imul ebx,esi,3E8 (for the thousands computation) and the next loop has the imul r14d,edi,64 (for the hundreds computation), highlighting that these computations were hoisted out to the appropriate level (the tens and ones computation are still in the right places).",
    "More improvements have gone in on the cloning side. Previously, loop cloning would only apply for loops iterating by 1 from a low to a high value. With dotnet/runtime#60148, the comparison against the upper value can be ",
    "More improvements have gone in on the cloning side. Previously, loop cloning would only apply for loops iterating by 1 from a low to a high value. With dotnet/runtime#60148, the comparison against the upper value can be ",
    "Without loop cloning, the JIT can",
    "Without loop cloning, the JIT can",
    "Notice how in the core loop, a t label M00",
    "Notice how in the core loop, a t label M00",
    "Notice how the code size is larger, and how there are now two variations of the loop: one at M00",
    "Notice how the code size is larger, and how there are now two variations of the loop: one at M00",
    "CORINFO",
    "CORINFO",
    "Other changes also improved loop cloning. dotnet/runtime#59886 enables the JIT to choose different forms for how to emit the the conditions for choosing the fast or slow loop path, e.g. whether to emit",
    "Other changes also improved loop cloning. dotnet/runtime#59886 enables the JIT to choose different forms for how to emit the the conditions for choosing the fast or slow loop path, e.g. whether to emit",
    "all the conditions, ",
    "all the conditions, ",
    "Constant folding is an optimization where a compiler computes the value of an expression involving only constants at compile-time rather than generating the code to compute the value at run-time. There are multiple levels of constant folding in .NET, with some constant folding performed by the C# compiler and some constant folding performed by the JIT compiler. For example, given the C# code:",
    "Constant folding is an optimization where a compiler computes the value of an expression involving only constants at compile-time rather than generating the code to compute the value at run-time. There are multiple levels of constant folding in .NET, with some constant folding performed by the C# compiler and some constant folding performed by the JIT compiler. For example, given the C# code:",
    "the C# compiler will generate IL for these methods like the following:",
    "the C# compiler will generate IL for these methods like the following:",
    "You can see that the C# compiler has computed the value of 3 + (4",
    "You can see that the C# compiler has computed the value of 3 + (4",
    "The assembly for method A isn",
    "The assembly for method A isn",
    "The JIT has long performed constant folding, but it improves further in .NET 7. One of the ways constant folding can improve is by exposing more values to be folded, which often means more inlining. dotnet/runtime#55745 helped the inliner to understand that a method call like M(constant + constant) (noting that those constants might be the result of some other method call) is itself passing a constant to M , and a constant being passed to a method call is a hint to the inliner that it should consider being more aggressive about inlining, since exposing that constant to the body of the callee can potentially significantly reduce the amount of code required to implement the callee. The JIT might have previously inlined such a method anyway, but when it comes to inlining, the JIT is all about heuristics and generating enough evidence that it",
    "The JIT has long performed constant folding, but it improves further in .NET 7. One of the ways constant folding can improve is by exposing more values to be folded, which often means more inlining. dotnet/runtime#55745 helped the inliner to understand that a method call like M(constant + constant) (noting that those constants might be the result of some other method call) is itself passing a constant to M , and a constant being passed to a method call is a hint to the inliner that it should consider being more aggressive about inlining, since exposing that constant to the body of the callee can potentially significantly reduce the amount of code required to implement the callee. The JIT might have previously inlined such a method anyway, but when it comes to inlining, the JIT is all about heuristics and generating enough evidence that it",
    "and, eschewing argument validation for the purposes of this example, Interval is:",
    "and, eschewing argument validation for the purposes of this example, Interval is:",
    "which if everything gets inlined means FromSeconds is essentially:",
    "which if everything gets inlined means FromSeconds is essentially:",
    "and if value is a constant, let",
    "and if value is a constant, let",
    "I",
    "I",
    "we now get the simple and clean:",
    "we now get the simple and clean:",
    "Another change improving constant folding included dotnet/runtime#57726 from ",
    "Another change improving constant folding included dotnet/runtime#57726 from ",
    "In .NET 6, the JIT generated this:",
    "In .NET 6, the JIT generated this:",
    "The interesting thing here is that some constants (39, which is the value of KnownColor.DarkOrange , and 1, which is a private StateKnownColorValid constant) are being loaded into registers ( mov eax, 1 , mov ecx, 39 ) and then later being stored into the relevant location for the Color struct being returned ( mov ",
    "The interesting thing here is that some constants (39, which is the value of KnownColor.DarkOrange , and 1, which is a private StateKnownColorValid constant) are being loaded into registers ( mov eax, 1 , mov ecx, 39 ) and then later being stored into the relevant location for the Color struct being returned ( mov ",
    "with direct assignment of these constant values into their destination locations ( mov word ptr ",
    "with direct assignment of these constant values into their destination locations ( mov word ptr ",
    "However, a large category of improvement came from an optimization related to propagation, that of forward substitution. Consider this silly benchmark:",
    "However, a large category of improvement came from an optimization related to propagation, that of forward substitution. Consider this silly benchmark:",
    "If we look at the assembly code generated for Compute1 on .NET 6, it looks like what we",
    "If we look at the assembly code generated for Compute1 on .NET 6, it looks like what we",
    "But Compute2 is a bit different. The structure of the code is such that the additional call to SomethingElse ends up slightly perturbing something about the JIT",
    "But Compute2 is a bit different. The structure of the code is such that the additional call to SomethingElse ends up slightly perturbing something about the JIT",
    "Rather than a single mov eax, 50 to put the value 0x50 into the return register, we have 5 separate add eax, 10 to build up that same 0x5 0 (80) value. That",
    "Rather than a single mov eax, 50 to put the value 0x50 into the return register, we have 5 separate add eax, 10 to build up that same 0x5 0 (80) value. That",
    "It turns out that many of the JIT",
    "It turns out that many of the JIT",
    "| add                      | eax,50                   |",
    "| add                      | eax,50                   |",
    "SIMD, or Single Instruction Multiple Data, is a kind of processing in which one instruction applies to multiple pieces of data at the same time. You",
    "SIMD, or Single Instruction Multiple Data, is a kind of processing in which one instruction applies to multiple pieces of data at the same time. You",
    ".NET has long had support for vectorization in the form of Vector",
    ".NET has long had support for vectorization in the form of Vector",
    "Starting in .NET Core 3.0, .NET gained literally thousands of new ",
    "Starting in .NET Core 3.0, .NET gained literally thousands of new ",
    ".NET 7 has introduced a middle ground. Previous releases saw the introduction of the Vector128",
    ".NET 7 has introduced a middle ground. Previous releases saw the introduction of the Vector128",
    "dotnet/runtime#53450, dotnet/runtime#63414, dotnet/runtime#60094, and dotnet/runtime#68559, a very large set of cross-platform operations is defined over these types as well, e.g. Vector128",
    "dotnet/runtime#53450, dotnet/runtime#63414, dotnet/runtime#60094, and dotnet/runtime#68559, a very large set of cross-platform operations is defined over these types as well, e.g. Vector128",
    "I have two functions: one that directly uses the Sse2.MoveMask hardware intrinsic and one that uses the new Vector128",
    "I have two functions: one that directly uses the Sse2.MoveMask hardware intrinsic and one that uses the new Vector128",
    "Notice anything? The code for the two methods is identical, both resulting in a vpmovmskb (Move Byte Mask) instruction. Yet the former code will only work on a platform that supports SSE2 whereas the latter code will work on any platform with support for 128-bit vectors, including Arm64 and WASM (and any future platforms on-boarded that also support SIMD ); it",
    "Notice anything? The code for the two methods is identical, both resulting in a vpmovmskb (Move Byte Mask) instruction. Yet the former code will only work on a platform that supports SSE2 whereas the latter code will work on any platform with support for 128-bit vectors, including Arm64 and WASM (and any future platforms on-boarded that also support SIMD ); it",
    "To explore this a bit more, let",
    "To explore this a bit more, let",
    "How would we vectorize this with Vector",
    "How would we vectorize this with Vector",
    "Now that we know we h ave enough data, we can get to coding our vectorized loop. In this loop, we",
    "Now that we know we h ave enough data, we can get to coding our vectorized loop. In this loop, we",
    "And we",
    "And we",
    "th at might or might not overlap with elements we",
    "th at might or might not overlap with elements we",
    "Congratulations, we",
    "Congratulations, we",
    "| Method         | Mean      |   Ratio |",
    "| Method         | Mean      |   Ratio |",
    "A 24x speedup",
    "A 24x speedup",
    "You deploy this in your service, and you see Contains being called on your hot path, but you don",
    "You deploy this in your service, and you see Contains being called on your hot path, but you don",
    "One thing we can now do is switch from using Vector",
    "One thing we can now do is switch from using Vector",
    "With that in hand, we can now try it on our smaller 30 element data set:",
    "With that in hand, we can now try it on our smaller 30 element data set:",
    "| Method         | Mean      |   Ratio |",
    "| Method         | Mean      |   Ratio |",
    "Woo hoo, victory, all your performance are belong to us\u2026 again",
    "Woo hoo, victory, all your performance are belong to us\u2026 again",
    "What about on the larger data set again? Previously with Vector",
    "What about on the larger data set again? Previously with Vector",
    "| Method         | Mean      |   Ratio |",
    "| Method         | Mean      |   Ratio |",
    "\u2026 closer to 15x. Nothing to sneeze at, but it",
    "\u2026 closer to 15x. Nothing to sneeze at, but it",
    "And, boom, we",
    "And, boom, we",
    "| Method         | Mean      |   Ratio |",
    "| Method         | Mean      |   Ratio |",
    "We now have an implementation that is vectorized on any platform with either 128-bit or 256-bit vector instructions (x86, x64, Arm64, WASM, etc.), that can use either based on the input length, and that can be included in an R2R image if that",
    "We now have an implementation that is vectorized on any platform with either 128-bit or 256-bit vector instructions (x86, x64, Arm64, WASM, etc.), that can use either based on the input length, and that can be included in an R2R image if that",
    "There are many factors that impact which path you go down, and I expect we",
    "There are many factors that impact which path you go down, and I expect we",
    "I already mentioned several PRs that exposed the new cross-platform vector support, but that only scratches the surface of the work done to actually enable these operations and to enable them to produce high-quality code. As just one example of a category of such work, a set of changes went in to help ensure that zero vector constants are handled well, such as dotnet/runtime#63821 that ",
    "I already mentioned several PRs that exposed the new cross-platform vector support, but that only scratches the surface of the work done to actually enable these operations and to enable them to produce high-quality code. As just one example of a category of such work, a set of changes went in to help ensure that zero vector constants are handled well, such as dotnet/runtime#63821 that ",
    "Inlining is one of the most important optimizations the JIT can do. The concept is simple: instead of making a call to some method, take the code from that method and bake it into the call site. This has the obvious advantage of avoiding the overhead of a method call, but except for really small methods on really hot paths, that",
    "Inlining is one of the most important optimizations the JIT can do. The concept is simple: instead of making a call to some method, take the code from that method and bake it into the call site. This has the obvious advantage of avoiding the overhead of a method call, but except for really small methods on really hot paths, that",
    "All that is to say, inlining is really important, it",
    "All that is to say, inlining is really important, it",
    "One really interesting improvement around inlining is dotnet/runtime#64521, and it might be surprising. Consider the Boolean.ToString method; here",
    "One really interesting improvement around inlining is dotnet/runtime#64521, and it might be surprising. Consider the Boolean.ToString method; here",
    "public override string ToString()",
    "public override string ToString()",
    "{",
    "{",
    "Pretty simple, right? You",
    "Pretty simple, right? You",
    "produces this assembly code:",
    "produces this assembly code:",
    "Note the call System.Boolean.ToString() . The reason for this is, historically, the JIT has been unable to inline methods across assembly boundaries if those methods contain string literals (like the ",
    "Note the call System.Boolean.ToString() . The reason for this is, historically, the JIT has been unable to inline methods across assembly boundaries if those methods contain string literals (like the ",
    "No more call System.Boolean.ToString() .",
    "No more call System.Boolean.ToString() .",
    "dotnet/runtime#61408 made two changes related to inlining. First, it taught the inliner how to better see the what methods were being called in an inlining candidate, and in particular when tiered compilation is disabled or when a method would bypass tier-0 (such as a method with loops before OSR existed or with OSR disabled); by understanding what methods are being called, it can better understand the cost of the method, e.g. if those method calls are actually hardware intrinsics with a very low cost. Second, it enabled CSE in more cases with SIMD vectors.",
    "dotnet/runtime#61408 made two changes related to inlining. First, it taught the inliner how to better see the what methods were being called in an inlining candidate, and in particular when tiered compilation is disabled or when a method would bypass tier-0 (such as a method with loops before OSR existed or with OSR disabled); by understanding what methods are being called, it can better understand the cost of the method, e.g. if those method calls are actually hardware intrinsics with a very low cost. Second, it enabled CSE in more cases with SIMD vectors.",
    "dotnet/runtime#71778 also impacted inlining, and in particular in situations where a typeof() could be propagated to the callee (e.g. via a method argument). In previous releases of .NET, various",
    "dotnet/runtime#71778 also impacted inlining, and in particular in situations where a typeof() could be propagated to the callee (e.g. via a method argument). In previous releases of .NET, various",
    "members on Type like IsValueType were turned into JIT intrinsics, such that the JIT could substitute a constant value for calls where it could compute the answer at compile time. For example, this:",
    "members on Type like IsValueType were turned into JIT intrinsics, such that the JIT could substitute a constant value for calls where it could compute the answer at compile time. For example, this:",
    "results in this assembly code on .NET 6:",
    "results in this assembly code on .NET 6:",
    "However, change the benchmark slightly:",
    "However, change the benchmark slightly:",
    "and it",
    "and it",
    "Effectively, as part of inlining the JIT loses the notion that the argument is a constant and fails to propagate it. This PR fixes that, such that on .NET 7, we now get what we expect:",
    "Effectively, as part of inlining the JIT loses the notion that the argument is a constant and fails to propagate it. This PR fixes that, such that on .NET 7, we now get what we expect:",
    "A huge amount of effort in .NET 7 went into making code gen for Arm64 as good or better than its x64 counterpart. I",
    "A huge amount of effort in .NET 7 went into making code gen for Arm64 as good or better than its x64 counterpart. I",
    "Addressing modes . ",
    "Addressing modes . ",
    "managed arrays. dotnet/runtime#66902 improves the use of addressing modes when the element type is byte . dotnet/runtime#65468 improves addressing modes used for floating point. And dotnet/runtime#67490 implements addressing modes for SIMD vectors, specifically for loads with unscaled indices.",
    "managed arrays. dotnet/runtime#66902 improves the use of addressing modes when the element type is byte . dotnet/runtime#65468 improves addressing modes used for floating point. And dotnet/runtime#67490 implements addressing modes for SIMD vectors, specifically for loads with unscaled indices.",
    "Better instruction selection . Various techniques go into ensuring that the best instructions are selected to represent input code. dotnet/runtime#61037 teaches the JIT how to recognize the pattern (a ",
    "Better instruction selection . Various techniques go into ensuring that the best instructions are selected to represent input code. dotnet/runtime#61037 teaches the JIT how to recognize the pattern (a ",
    "Vectorization . dotnet/runtime#64864 adds new AdvSimd.LoadPairVector64 / AdvSimd.LoadPairVector128 hardware intrinsics.",
    "Vectorization . dotnet/runtime#64864 adds new AdvSimd.LoadPairVector64 / AdvSimd.LoadPairVector128 hardware intrinsics.",
    "Zeroing . Lots of operations require state to be set to zero, such as initializing all reference locals in a method to zero as part of the method",
    "Zeroing . Lots of operations require state to be set to zero, such as initializing all reference locals in a method to zero as part of the method",
    "Memory Model . dotnet/runtime#62895 enables store barriers to be used wherever possible instead of full barriers, and uses one-way barriers for volatile variables. dotnet/runtime#67384 enables volatile reads/writes to be implemented with the ldapr instruction, while dotnet/runtime#64354 uses a cheaper instruction sequence to handle volatile indirections. There",
    "Memory Model . dotnet/runtime#62895 enables store barriers to be used wherever possible instead of full barriers, and uses one-way barriers for volatile variables. dotnet/runtime#67384 enables volatile reads/writes to be implemented with the ldapr instruction, while dotnet/runtime#64354 uses a cheaper instruction sequence to handle volatile indirections. There",
    "While logically part of the runtime, the JIT is actually isolated from the rest of the runtime, only interacting with it through an interface that enables communication between the JIT and the rest of the VM (Virtual Machine). There",
    "While logically part of the runtime, the JIT is actually isolated from the rest of the runtime, only interacting with it through an interface that enables communication between the JIT and the rest of the VM (Virtual Machine). There",
    "dotnet/runtime#65738 rewrote various ",
    "dotnet/runtime#65738 rewrote various ",
    "kunalspathak commented on Mar 22 \u2022 edited - windows x64 improvements: dotnet/perf-autofiling-issues#4226, dotnet/perf-autofiling-issues#4225",
    "kunalspathak commented on Mar 22 \u2022 edited - windows x64 improvements: dotnet/perf-autofiling-issues#4226, dotnet/perf-autofiling-issues#4225",
    "single one it",
    "single one it",
    "Windows Arm64 Improvements dotnet/perf-autofiling-issues#4251 dotnet/perf-autofiling-issues#4252",
    "Windows Arm64 Improvements dotnet/perf-autofiling-issues#4251 dotnet/perf-autofiling-issues#4252",
    "DrewScoggins commented on Mar 24 \u2022 edited -",
    "DrewScoggins commented on Mar 24 \u2022 edited -",
    "For anyone familiar with generics and interested in performance, you may have heard the refrain that generic virtual methods are relatively expensive. They are, comparatively. For example on .NET 6, this code:",
    "For anyone familiar with generics and interested in performance, you may have heard the refrain that generic virtual methods are relatively expensive. They are, comparatively. For example on .NET 6, this code:",
    "results in:",
    "results in:",
    "Member",
    "Member",
    "| Method            | Mean      |   Ratio |",
    "| Method            | Mean      |   Ratio |",
    "dotnet/runtime#65926 eases the pain a tad. Some of the cost comes from looking up some cached information in a hash table in the runtime, and as is the case with many map implementations, this one involves computing a hash code and using a mod operation to map to the right bucket. Other hash table implementations around dotnet/runtime, including Dictionary",
    "dotnet/runtime#65926 eases the pain a tad. Some of the cost comes from looking up some cached information in a hash table in the runtime, and as is the case with many map implementations, this one involves computing a hash code and using a mod operation to map to the right bucket. Other hash table implementations around dotnet/runtime, including Dictionary",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "Not enough of an improvement for us to start recommending people use them, but a 5% improvement takes a bit of the edge off the sting.",
    "Not enough of an improvement for us to start recommending people use them, but a 5% improvement takes a bit of the edge off the sting.",
    "It",
    "It",
    "dotnet/runtime#58196 from ",
    "dotnet/runtime#58196 from ",
    "dotnet/runtime#67182. On a machine with support for BMI2, 64-bit shifts can be performed with the shlx , sarx , and shrx instructions.",
    "dotnet/runtime#67182. On a machine with support for BMI2, 64-bit shifts can be performed with the shlx , sarx , and shrx instructions.",
    "dotnet/runtime#69003 from ",
    "dotnet/runtime#69003 from ",
    "dotnet/runtime#61412 from ",
    "dotnet/runtime#61412 from ",
    "dotnet/runtime#63545 from ",
    "dotnet/runtime#63545 from ",
    "dotnet/runtime#62394. / and % by a vector",
    "dotnet/runtime#62394. / and % by a vector",
    "dotnet/runtime#60787. Loop alignment in .NET 6 provides a very nice exploration of why and how the JIT handles loop alignment. This PR extends that further by trying to ",
    "dotnet/runtime#60787. Loop alignment in .NET 6 provides a very nice exploration of why and how the JIT handles loop alignment. This PR extends that further by trying to ",
    "'",
    "'",
    "To many people, the word ",
    "To many people, the word ",
    ".NET has long had support for AOT code generation. For example, .NET Framework had it in the form of ngen , and .NET Core has it in the form of crossgen . Both of those solutions involve a standard .NET executable that has some of its IL already compiled to assembly code, but not all methods will have assembly code generated for them, various things can invalidate the assembly code that was generated, external .NET assemblies without any native assembly code can be loaded, and so on, and in all of those cases, the runtime continues to utilize a JIT compiler. Native AOT is different. It",
    ".NET has long had support for AOT code generation. For example, .NET Framework had it in the form of ngen , and .NET Core has it in the form of crossgen . Both of those solutions involve a standard .NET executable that has some of its IL already compiled to assembly code, but not all methods will have assembly code generated for them, various things can invalidate the assembly code that was generated, external .NET assemblies without any native assembly code can be loaded, and so on, and in all of those cases, the runtime continues to utilize a JIT compiler. Native AOT is different. It",
    "Too many PRs to mention have gone into bringing up the Native AOT stack, in part because it",
    "Too many PRs to mention have gone into bringing up the Native AOT stack, in part because it",
    "Today, Native AOT is focused on console applications, so let",
    "Today, Native AOT is focused on console applications, so let",
    "We now have our nativeaotexample directory containing a nativeaotexample.csproj and a ",
    "We now have our nativeaotexample directory containing a nativeaotexample.csproj and a ",
    "A nd then\u2026 actually, that",
    "A nd then\u2026 actually, that",
    "I now have my generated executable in the output publish directory:",
    "I now have my generated executable in the output publish directory:",
    "so 2M instead of 3.5MB. Of course, for that significant reduction I",
    "so 2M instead of 3.5MB. Of course, for that significant reduction I",
    "Setting InvariantGlobalization to true means I",
    "Setting InvariantGlobalization to true means I",
    "Setting UseSystemResourceKeys to true means nice exception messages are stripped away.",
    "Setting UseSystemResourceKeys to true means nice exception messages are stripped away.",
    "Setting IlcGenerateStackTraceData to false means I",
    "Setting IlcGenerateStackTraceData to false means I",
    "Setting DebuggerSupport to false\u2026 good luck debugging things.",
    "Setting DebuggerSupport to false\u2026 good luck debugging things.",
    "\u2026 you get the idea.",
    "\u2026 you get the idea.",
    "One of the potentially mind-boggling aspects of Native AOT for a developer used to .NET is that, as it says on the tin, it really is native. After publishing the app, there is no IL involved, and there",
    "One of the potentially mind-boggling aspects of Native AOT for a developer used to .NET is that, as it says on the tin, it really is native. After publishing the app, there is no IL involved, and there",
    "With the JIT, IsDynamicCodeCompiled is true. But with Native AOT, it",
    "With the JIT, IsDynamicCodeCompiled is true. But with Native AOT, it",
    "SDK, emits C# code into the assembly using it. That C# code takes the place of the reflection emit that would have happened at run-time, and is thus able to work successfully with Native AOT.",
    "SDK, emits C# code into the assembly using it. That C# code takes the place of the reflection emit that would have happened at run-time, and is thus able to work successfully with Native AOT.",
    "| Method          | Mean       |   Ratio |",
    "| Method          | Mean       |   Ratio |",
    "So, yes, there are some constraints associated with Native AOT, but there are also solutions for working with those constraints. And further, those constraints can actually bring further benefits. Consider dotnet/runtime#64497 . Remember how we talked about ",
    "So, yes, there are some constraints associated with Native AOT, but there are also solutions for working with those constraints. And further, those constraints can actually bring further benefits. Consider dotnet/runtime#64497 . Remember how we talked about ",
    "This is a really exciting space, one we expect to see flourish in coming releases.",
    "This is a really exciting space, one we expect to see flourish in coming releases.",
    "Up until now I",
    "Up until now I",
    "Just as with coreclr (which can JIT compile, AOT compile partially with JIT fallback, and fully Native AOT compile), mono has multiple ways of actually executing code. One of those ways is an interpreter, which enables mono to execute .NET code in environments that don",
    "Just as with coreclr (which can JIT compile, AOT compile partially with JIT fallback, and fully Native AOT compile), mono has multiple ways of actually executing code. One of those ways is an interpreter, which enables mono to execute .NET code in environments that don",
    "Time to first Ul (ms)",
    "Time to first Ul (ms)",
    "300",
    "300",
    "280",
    "280",
    "260",
    "260",
    "240",
    "240",
    "The interpreter isn",
    "The interpreter isn",
    "Beyond such backend improvements, another class of improvement came from further unification between coreclr and mono. Years ago, coreclr and mono had their own entire library stack built on top of them. Over time, as .NET was open sourced, portions of mono",
    "Beyond such backend improvements, another class of improvement came from further unification between coreclr and mono. Years ago, coreclr and mono had their own entire library stack built on top of them. Over time, as .NET was open sourced, portions of mono",
    "One of the biggest categories of improvements, however, is in vectorization. This comes in two pieces. First, Vector",
    "One of the biggest categories of improvements, however, is in vectorization. This comes in two pieces. First, Vector",
    "dotnet/runtime#66391, dotnet/runtime#66409, dotnet/runtime#66512, dotnet/runtime#66586, dotnet/runtime#66589, dotnet/runtime#66597, dotnet/runtime#66476, and dotnet/runtime#67125; that significant amount of work means all that code that gets vectorized using these abstractions will light-up on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70086, mono now knows how to translate Vector128",
    "dotnet/runtime#66391, dotnet/runtime#66409, dotnet/runtime#66512, dotnet/runtime#66586, dotnet/runtime#66589, dotnet/runtime#66597, dotnet/runtime#66476, and dotnet/runtime#67125; that significant amount of work means all that code that gets vectorized using these abstractions will light-up on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70086, mono now knows how to translate Vector128",
    "Reflection is one of those areas you either love or hate (I find it a bit humorous to be writing this section immediately after writing the Native AOT section). It",
    "Reflection is one of those areas you either love or hate (I find it a bit humorous to be writing this section immediately after writing the Native AOT section). It",
    "One of the most impacted areas is reflection invoke. Available via MethodBase.Invoke , this functionality let",
    "One of the most impacted areas is reflection invoke. Available via MethodBase.Invoke , this functionality let",
    "| Method           | Runtime   | Mean      |   Ratio |",
    "| Method           | Runtime   | Mean      |   Ratio |",
    "Reflection also involves lots of manipulation of objects that represent types, methods, properties, and so on, and tweaks here and there can add up to a measurable difference when using these APIs. For example, I",
    "Reflection also involves lots of manipulation of objects that represent types, methods, properties, and so on, and tweaks here and there can add up to a measurable difference when using these APIs. For example, I",
    "| Method            | Runtime   | Mean      |   Ratio |",
    "| Method            | Runtime   | Mean      |   Ratio |",
    "Another example of this phenomenon comes in dotnet/runtime#62866, which moved much of the underlying support for AssemblyName out of native runtime code into managed code in CoreLib. That in turn has an impact on anything that uses it, such as when using Activator.CreateInstance overloads that take assembly names that need to be parsed.",
    "Another example of this phenomenon comes in dotnet/runtime#62866, which moved much of the underlying support for AssemblyName out of native runtime code into managed code in CoreLib. That in turn has an impact on anything that uses it, such as when using Activator.CreateInstance overloads that take assembly names that need to be parsed.",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "Other changes contributed to Activator.CreateInstance improvements as well. dotnet/runtime#67148 removed several array and list allocations from inside of the RuntimeType.CreateInstanceImpl me thod that",
    "Other changes contributed to Activator.CreateInstance improvements as well. dotnet/runtime#67148 removed several array and list allocations from inside of the RuntimeType.CreateInstanceImpl me thod that",
    "Type.EmptyTypes",
    "Type.EmptyTypes",
    "| Method         | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method         | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "And since we were talking about AssemblyName , other PRs improved it in other ways as well. dotnet/runtime#66750, for example, updated the computation of AssemblyName.FullName to use stack-allocated memory and ArrayPool",
    "And since we were talking about AssemblyName , other PRs improved it in other ways as well. dotnet/runtime#66750, for example, updated the computation of AssemblyName.FullName to use stack-allocated memory and ArrayPool",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "More reflection-related operations have also been turned into JIT intrinsics, as discussed earlier enabling the JIT to compute answers to various questions at JIT compile time rather than at run-time. This was done, for example, for Type.IsByRefLike in dotnet/runtime#67852.",
    "More reflection-related operations have also been turned into JIT intrinsics, as discussed earlier enabling the JIT to compute answers to various questions at JIT compile time rather than at run-time. This was done, for example, for Type.IsByRefLike in dotnet/runtime#67852.",
    "| Method      | Runtime   | Mean      |   Ratio | Code Size   |",
    "| Method      | Runtime   | Mean      |   Ratio | Code Size   |",
    "That the .NET 7 version is so close to zero is called out in a warning by benchmarkdotnet:",
    "That the .NET 7 version is so close to zero is called out in a warning by benchmarkdotnet:",
    "and it",
    "and it",
    "There are also improvements that are hard to see but that remove overheads as part of populating reflection",
    "There are also improvements that are hard to see but that remove overheads as part of populating reflection",
    ".NET has long had great support for interop, enabling .NET applications to consume huge amounts of functionality written in other languages and/or exposed by the underlying operating system. The bedrock of this support has been ",
    ".NET has long had great support for interop, enabling .NET applications to consume huge amounts of functionality written in other languages and/or exposed by the underlying operating system. The bedrock of this support has been ",
    "If I want to call this function from C#, I can declare a ",
    "If I want to call this function from C#, I can declare a ",
    "There are several interesting things to note here. Several of the arguments are directly blittable with the same representation on the managed and native side of the equation, e.g. lpPipeAttributes is a pointer and nSize is a 32-bit integer. But what about the return value? The bool type in C# ( System.Boolean ) is a one-byte type, but the BOOL type in the native signature is four bytes; thus code calling this managed method can",
    "There are several interesting things to note here. Several of the arguments are directly blittable with the same representation on the managed and native side of the equation, e.g. lpPipeAttributes is a pointer and nSize is a 32-bit integer. But what about the return value? The bool type in C# ( System.Boolean ) is a one-byte type, but the BOOL type in the native signature is four bytes; thus code calling this managed method can",
    "and some code somewhere needs to take any error produced by this method and ensure it",
    "and some code somewhere needs to take any error produced by this method and ensure it",
    "If there",
    "If there",
    "There are a variety of downsides to this. First, it takes time to generate all that marshalling code, time which can then negatively impact user experience for things like startup. Second, the nature of its implementation inhibits various optimizations, such as inlining. Thi rd, there are platforms that don",
    "There are a variety of downsides to this. First, it takes time to generate all that marshalling code, time which can then negatively impact user experience for things like startup. Second, the nature of its implementation inhibits various optimizations, such as inlining. Thi rd, there are platforms that don",
    "But what if that logic could all be generated at build time rather than at run time? The cost of generating the code would be incurred only at build time and not on every execution. The code would effectively just end up being user code that has all of the C# compiler",
    "But what if that logic could all be generated at build time rather than at run time? The cost of generating the code would be incurred only at build time and not on every execution. The code would effectively just end up being user code that has all of the C# compiler",
    ".NET 6 included several source generators in the .NET SDK, and .NET 7 doubles down on this effort including several more. One of these is the brand new LibraryImport generator, which provides exactly the magical, desirable solution we were just discussing.",
    ".NET 6 included several source generators in the .NET SDK, and .NET 7 doubles down on this effort including several more. One of these is the brand new LibraryImport generator, which provides exactly the magical, desirable solution we were just discussing.",
    "Let",
    "Let",
    "Now if you",
    "Now if you",
    "opt-in to having it persisted on disk by adding a ",
    "opt-in to having it persisted on disk by adding a ",
    "With this, you can read exactly the marshalling work that",
    "With this, you can read exactly the marshalling work that",
    "A sheer ton of work went in to enabling this. I touched on some of it last year in Performance Improvements in .NET 6, but a significant amount of additional effort has gone into .NET 7 to polish the design and make the implementation robust, roll it out across all of dotnet/runtime and beyond, and expose the functionality for all C# developers to use:",
    "A sheer ton of work went in to enabling this. I touched on some of it last year in Performance Improvements in .NET 6, but a significant amount of additional effort has gone into .NET 7 to polish the design and make the implementation robust, roll it out across all of dotnet/runtime and beyond, and expose the functionality for all C# developers to use:",
    "The LibraryImport generator started its life as an experiment in dotnet/runtimelab. When it was ready, dotnet/runtime#59579 brought 180 commits spanning years of effort into the dotnet/runtime main branch.",
    "The LibraryImport generator started its life as an experiment in dotnet/runtimelab. When it was ready, dotnet/runtime#59579 brought 180 commits spanning years of effort into the dotnet/runtime main branch.",
    "In .NET 6, there were almost 3000 ",
    "In .NET 6, there were almost 3000 ",
    "Such porting is significantly easier when there",
    "Such porting is significantly easier when there",
    "18g-",
    "18g-",
    "[",
    "[",
    "O references private static unsafe extern bool CreatePipe(",
    "O references private static unsafe extern bool CreatePipe(",
    "19",
    "19",
    "Convert to ",
    "Convert to ",
    "21 Convert to ",
    "21 Convert to ",
    "22 Order modifiers",
    "22 Order modifiers",
    "23",
    "23",
    "24",
    "24",
    "Move static members to another type...",
    "Move static members to another type...",
    "29 Change signature...",
    "29 Change signature...",
    "Wrap every parameter",
    "Wrap every parameter",
    "Unwrap parameter list",
    "Unwrap parameter list",
    "Extract base class...",
    "Extract base class...",
    "Suppress or Configure issues",
    "Suppress or Configure issues",
    ":::",
    ":::",
    "There were plenty of other PRs that went into making the LibraryImport generator a reality for .NET 7. To highlight just a few more, dotnet/runtime#63320 introduces a new ",
    "There were plenty of other PRs that went into making the LibraryImport generator a reality for .NET 7. To highlight just a few more, dotnet/runtime#63320 introduces a new ",
    "One more category of interop-related changes that I think are worth talking about are to do with SafeHandle cleanup. As a reminder, SafeHandle exists to mitigate various issues around managing native handles and file descriptors. A native handle or file descriptor is just a memory address or number that refers to some owned resource and which must be cleaned up / closed when done with it. A SafeHandle at its core is just a managed object that wraps such a value and provides a Dispose method and a finalizer for closing it. That way, if you neglect to Dispose of the SafeHandle in order to close the resource, the resource will still be cleaned up when the SafeHandle is garbage collected and its finalizer eventually run. SafeHandle then also provides some synchronization around that closure, trying to minimize the possibility that the resource is closed while it",
    "One more category of interop-related changes that I think are worth talking about are to do with SafeHandle cleanup. As a reminder, SafeHandle exists to mitigate various issues around managing native handles and file descriptors. A native handle or file descriptor is just a memory address or number that refers to some owned resource and which must be cleaned up / closed when done with it. A SafeHandle at its core is just a managed object that wraps such a value and provides a Dispose method and a finalizer for closing it. That way, if you neglect to Dispose of the SafeHandle in order to close the resource, the resource will still be cleaned up when the SafeHandle is garbage collected and its finalizer eventually run. SafeHandle then also provides some synchronization around that closure, trying to minimize the possibility that the resource is closed while it",
    "\u2022 \u2022 Mark the method ",
    "\u2022 \u2022 Mark the method ",
    "and DangerousRelease (and due to the wonders of LibraryImport I",
    "and DangerousRelease (and due to the wonders of LibraryImport I",
    "dotnet/runtime#71854 added some debug-only tracking code to SafeHandle to make it easier for developers working in dotnet/runtime (or more specifically, developers using a checked build of the runtime) to find such issues. When the SafeHandle is constructed, it captures the current stack trace, and if the SafeHandle is finalized, it dumps that stack trace to the console, making it easy to see where SafeHandles that do end up getting finalized were created, in order to track them down and ensure they",
    "dotnet/runtime#71854 added some debug-only tracking code to SafeHandle to make it easier for developers working in dotnet/runtime (or more specifically, developers using a checked build of the runtime) to find such issues. When the SafeHandle is constructed, it captures the current stack trace, and if the SafeHandle is finalized, it dumps that stack trace to the console, making it easy to see where SafeHandles that do end up getting finalized were created, in order to track them down and ensure they",
    "and code that uses it like:",
    "and code that uses it like:",
    "Seems straightforward enough. Except this code will actually leave a SafeHandle for finalization on the failure path. It doesn",
    "Seems straightforward enough. Except this code will actually leave a SafeHandle for finalization on the failure path. It doesn",
    "That way, this SafeHandle won",
    "That way, this SafeHandle won",
    "dotnet/runtime#71991, dotnet/runtime#71854, dotnet/runtime#72116, dotnet/runtime#72189, dotnet/runtime#72222, dotnet/runtime#72203, and dotnet/runtime#72279 all found and fixed many occurrences of SafeHandle s being left for finalization (many thanks to the diagnostics put in place in the earlier mentioned PR).",
    "dotnet/runtime#71991, dotnet/runtime#71854, dotnet/runtime#72116, dotnet/runtime#72189, dotnet/runtime#72222, dotnet/runtime#72203, and dotnet/runtime#72279 all found and fixed many occurrences of SafeHandle s being left for finalization (many thanks to the diagnostics put in place in the earlier mentioned PR).",
    "Other PRs also accrued to improved interop performance. dotnet/runtime#70000 from ",
    "Other PRs also accrued to improved interop performance. dotnet/runtime#70000 from ",
    "Marshal.GetDelegateForFunctionPointer . dotnet/runtime#68694 also moved some trivial functionality from native to managed, as part of relaxing argument validation on the use of pinning handles. This in turn measurably reduced the overhead involved with using GCHandle.Alloc for such pinning handles:",
    "Marshal.GetDelegateForFunctionPointer . dotnet/runtime#68694 also moved some trivial functionality from native to managed, as part of relaxing argument validation on the use of pinning handles. This in turn measurably reduced the overhead involved with using GCHandle.Alloc for such pinning handles:",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   |",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   |",
    "Threading is one of those cross-cutting concerns that impacts every application, such that changes in the threading space can have a wide-spread impact. This release sees two very substantial changes to the ThreadPool itself; dotnet/runtime#64834 switches the ",
    "Threading is one of those cross-cutting concerns that impacts every application, such that changes in the threading space can have a wide-spread impact. This release sees two very substantial changes to the ThreadPool itself; dotnet/runtime#64834 switches the ",
    "One in particular is dotnet/runtime#69386. The ThreadPool has a ",
    "One in particular is dotnet/runtime#69386. The ThreadPool has a ",
    "Another is dotnet/runtime#57885. In order to coordinate threads, when work items were enqueued and dequeued, the pool was issuing requests to its threads to let them know that there was work available to do. This, however, often resulted in oversubscription, where more threads than necessary would race to try to get work items, especially when the system wasn",
    "Another is dotnet/runtime#57885. In order to coordinate threads, when work items were enqueued and dequeued, the pool was issuing requests to its threads to let them know that there was work available to do. This, however, often resulted in oversubscription, where more threads than necessary would race to try to get work items, especially when the system wasn",
    "| Method         | Runtime   | Mean      |   Ratio |",
    "| Method         | Runtime   | Mean      |   Ratio |",
    "There have been improvements outside of ThreadPool , as well. One notable change is in the handling of AsyncLocal",
    "There have been improvements outside of ThreadPool , as well. One notable change is in the handling of AsyncLocal",
    "So, this PR took the complexity hit to add a dedicated type for four key/value pairs, in order to optimize from one to four of them rather than one to three. While this improves throughput a bit, its main intent was to improve allocation, which is does over .NET 6 by ~20%.",
    "So, this PR took the complexity hit to add a dedicated type for four key/value pairs, in order to optimize from one to four of them rather than one to three. While this improves throughput a bit, its main intent was to improve allocation, which is does over .NET 6 by ~20%.",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   | Allocated   |   Alloc Ratio |",
    "Another valuable fix comes for locking in dotnet/runtime#70165. This particular improvement is a bit harder to demonstrate with benchmarkdotnet, so just try running this program, first on .NET 6 and then on .NET 7:",
    "Another valuable fix comes for locking in dotnet/runtime#70165. This particular improvement is a bit harder to demonstrate with benchmarkdotnet, so just try running this program, first on .NET 6 and then on .NET 7:",
    "This is simply spinning up 100 tasks, each of which enters and exits a read-write lock, waits for them all, and then does the process over again, for 10 seconds. It also times how long it takes to enter and exit the lock, and writes a warning if it had to wait for at least 15ms. When I run this on .NET 6, I get ~100 occurrences of it taking ",
    "This is simply spinning up 100 tasks, each of which enters and exits a read-write lock, waits for them all, and then does the process over again, for 10 seconds. It also times how long it takes to enter and exit the lock, and writes a warning if it had to wait for at least 15ms. When I run this on .NET 6, I get ~100 occurrences of it taking ",
    "One final threading-related change to call out: dotnet/runtime#68639. This one is Windows specific. Windows has the concept of processor groups, each of which can have up to 64 cores in it, and by default when a pro cess runs, it",
    "One final threading-related change to call out: dotnet/runtime#68639. This one is Windows specific. Windows has the concept of processor groups, each of which can have up to 64 cores in it, and by default when a pro cess runs, it",
    "We",
    "We",
    "float and double got a very nice boost in their implementation of parsing (e.g. double.Parse , float.TryParse , etc.). dotnet/runtime#62301 from ",
    "float and double got a very nice boost in their implementation of parsing (e.g. double.Parse , float.TryParse , etc.). dotnet/runtime#62301 from ",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "bool.TryParse and bool.TryFormat were also improved. dotnet/runtime#64782 streamlined these implementations by using BinaryPrimitives to perform fewer writes and reads. For example, instead of TryFormat writing out ",
    "bool.TryParse and bool.TryFormat were also improved. dotnet/runtime#64782 streamlined these implementations by using BinaryPrimitives to perform fewer writes and reads. For example, instead of TryFormat writing out ",
    "which requires four writes, it can instead implement the same operation in a single write by doing:",
    "which requires four writes, it can instead implement the same operation in a single write by doing:",
    "That 0x65007500720054 is the numerical value of the four characters in memory as a single ulong . You can see the impact of these changes with a microbenchmark:",
    "That 0x65007500720054 is the numerical value of the four characters in memory as a single ulong . You can see the impact of these changes with a microbenchmark:",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "Enum gets several performance boosts, as well. For example, when performing an operation like Enum.IsDefined , Enum.GetName , or Enum.ToString , the implementation consults a cache of all of the values defined on the enum. This cache includes the string name and the value for every defined enumeration in the Enum . It",
    "Enum gets several performance boosts, as well. For example, when performing an operation like Enum.IsDefined , Enum.GetName , or Enum.ToString , the implementation consults a cache of all of the values defined on the enum. This cache includes the string name and the value for every defined enumeration in the Enum . It",
    "and arrays), and for enums with more than that, it does a SpanHelpers.BinarySearch (which is the implementation for Array.BinarySearch ).",
    "and arrays), and for enums with more than that, it does a SpanHelpers.BinarySearch (which is the implementation for Array.BinarySearch ).",
    "| Method     | Runtime   | Mean      |   Ratio |",
    "| Method     | Runtime   | Mean      |   Ratio |",
    "Enum s also get a boost in conjunction with Nullable",
    "Enum s also get a boost in conjunction with Nullable",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "Not to be left out, Guid ",
    "Not to be left out, Guid ",
    "| Method     | Runtime   | Mean     |   Ratio | Code Size   |",
    "| Method     | Runtime   | Mean     |   Ratio | Code Size   |",
    "DateTime equality is also improved. dotnet/runtime#59857 shaves some overhead off of DateTime.Equals . DateTime is implemented with a single ulong ",
    "DateTime equality is also improved. dotnet/runtime#59857 shaves some overhead off of DateTime.Equals . DateTime is implemented with a single ulong ",
    "so instead of a mov , and , and , and cmp , we get just an xor and a shl .",
    "so instead of a mov , and , and , and cmp , we get just an xor and a shl .",
    "Other operations on DateTime also become more efficient, thanks to dotnet/runtime#72712 from ",
    "Other operations on DateTime also become more efficient, thanks to dotnet/runtime#72712 from ",
    "| Method    | Runtime   | Mean       |   Ratio |",
    "| Method    | Runtime   | Mean       |   Ratio |",
    "So, we",
    "So, we",
    "There",
    "There",
    "code applied to any types that implement the interfaces\u2026 which all of the numerical types in .NET 7 do (including not just the primitives but also, for example, BigInteger and Complex ). A preview version of this feature, including necessary runtime support, language syntax, C# compiler support, generic interfaces, and interface implementations all shipped in .NET 6 and C# 10, but it wasn",
    "code applied to any types that implement the interfaces\u2026 which all of the numerical types in .NET 7 do (including not just the primitives but also, for example, BigInteger and Complex ). A preview version of this feature, including necessary runtime support, language syntax, C# compiler support, generic interfaces, and interface implementations all shipped in .NET 6 and C# 10, but it wasn",
    "While this support is all primarily intended for external consumers, the core libraries do consume some of it internally. You can see how these APIs clean up consuming code even while maintaining performance in PRs like dotnet/runtime#68226 and dotnet/runtime#68183, which use the interfaces to deduplicate a bunch of LINQ code in Enumerable . Sum / Average / Min / Max . There are multiple overloads of these methods for int , long , float , double , and decimal . The GitHub summary of the diffs tells the story on how much code was able to be deleted:",
    "While this support is all primarily intended for external consumers, the core libraries do consume some of it internally. You can see how these APIs clean up consuming code even while maintaining performance in PRs like dotnet/runtime#68226 and dotnet/runtime#68183, which use the interfaces to deduplicate a bunch of LINQ code in Enumerable . Sum / Average / Min / Max . There are multiple overloads of these methods for int , long , float , double , and decimal . The GitHub summary of the diffs tells the story on how much code was able to be deleted:",
    "Another simple example comes from the new System.Formats.Tar library in .NET 7, which as the name suggests is used for reading and writing archives in any of multiple tar file formats. The tar file formats include integer values in octal representation, so the TarReader class needs to parse octal values. Some of these values are 32-bit integers, and some are 64-bit integers. Rather than have two separate ParseOctalAsUInt32 and ParseOctalAsUInt64 methods, dotnet/runtime#74281",
    "Another simple example comes from the new System.Formats.Tar library in .NET 7, which as the name suggests is used for reading and writing archives in any of multiple tar file formats. The tar file formats include integer values in octal representation, so the TarReader class needs to parse octal values. Some of these values are 32-bit integers, and some are 64-bit integers. Rather than have two separate ParseOctalAsUInt32 and ParseOctalAsUInt64 methods, dotnet/runtime#74281",
    "and the compiler will pick the appropriate one based on the context.",
    "and the compiler will pick the appropriate one based on the context.",
    "In addition to all the existing types that get these interfaces, there are also new types. dotnet/runtime#69204 adds the new Int128 and UInt128 types. As these types implement all of the relevant generic math interfaces, they come complete with a huge number of methods, over 100 each, all of which are implemented efficiently in managed code. In the future, the aim is that some set of these will be optimized further by the JIT and to take advantage of hardware acceleration.",
    "In addition to all the existing types that get these interfaces, there are also new types. dotnet/runtime#69204 adds the new Int128 and UInt128 types. As these types implement all of the relevant generic math interfaces, they come complete with a huge number of methods, over 100 each, all of which are implemented efficiently in managed code. In the future, the aim is that some set of these will be optimized further by the JIT and to take advantage of hardware acceleration.",
    "Several PRs moved native implementations of these kinds of math operations to managed code. dotnet/runtime#63881 from ",
    "Several PRs moved native implementations of these kinds of math operations to managed code. dotnet/runtime#63881 from ",
    null,
    null,
    "public int ILogB(double arg) =",
    "public int ILogB(double arg) =",
    "| Method   | Runtime   |     arg | Mean     |   Ratio |",
    "| Method   | Runtime   |     arg | Mean     |   Ratio |",
    "Other math operations were also improved in various ways. Math{F}.Truncate was improved in dotnet/runtime#65014 from ",
    "Other math operations were also improved in various ways. Math{F}.Truncate was improved in dotnet/runtime#65014 from ",
    "dotnet/runtime#65584 did the same for Max and Min so that the Arm-specific fmax and fmin instructions could be used. And several BitConverter APIs were also turned into intrinsics in dotnet/runtime#71567 in order to enable better code generation in some generic math scenarios.",
    "dotnet/runtime#65584 did the same for Max and Min so that the Arm-specific fmax and fmin instructions could be used. And several BitConverter APIs were also turned into intrinsics in dotnet/runtime#71567 in order to enable better code generation in some generic math scenarios.",
    "dotnet/runtime#55121 from ",
    "dotnet/runtime#55121 from ",
    "| Method   | Runtime   | Mean    |   Ratio |",
    "| Method   | Runtime   | Mean    |   Ratio |",
    "Also related to BigInteger (and not just for really big ones), dotnet/runtime#35565 from ",
    "Also related to BigInteger (and not just for really big ones), dotnet/runtime#35565 from ",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "While there are many forms of computation that can consume resources in applications, some of the most common include processing of data stored in arrays, strings, and now spans. Thus you see a focus in every .NET release on removing as much overhead as possible from such scenarios, while also finding ways to further optimize the concrete operations developers are commonly performing.",
    "While there are many forms of computation that can consume resources in applications, some of the most common include processing of data stored in arrays, strings, and now spans. Thus you see a focus in every .NET release on removing as much overhead as possible from such scenarios, while also finding ways to further optimize the concrete operations developers are commonly performing.",
    "Let",
    "Let",
    "or that are ASCII letters:",
    "or that are ASCII letters:",
    "or other such groups. Interestingly, there",
    "or other such groups. Interestingly, there",
    "which while more ",
    "which while more ",
    "than ",
    "than ",
    "IsAsciiDigit",
    "IsAsciiDigit",
    "IsAsciiHexDigit",
    "IsAsciiHexDigit",
    "IsAsciiHexDigitLower",
    "IsAsciiHexDigitLower",
    "IsAsciiHexDigitUpper",
    "IsAsciiHexDigitUpper",
    "IsAsciiLetter",
    "IsAsciiLetter",
    "IsAsciiLetterLower",
    "IsAsciiLetterLower",
    "IsAsciiLetterUpper",
    "IsAsciiLetterUpper",
    "IsAsciiLetterOrDigit",
    "IsAsciiLetterOrDigit",
    "These methods were added by dotnet/runtime#69318, which also employed them in dozens of locations where such checks were being performed across dotnet/runtime (many of them using lessefficient approaches).",
    "These methods were added by dotnet/runtime#69318, which also employed them in dozens of locations where such checks were being performed across dotnet/runtime (many of them using lessefficient approaches).",
    "Another new API focused on encapsulating a common pattern is the new MemoryExtensions.CommonPrefixLength method, introduced by dotnet/runtime#67929. This accepts either two ReadOnlySpan",
    "Another new API focused on encapsulating a common pattern is the new MemoryExtensions.CommonPrefixLength method, introduced by dotnet/runtime#67929. This accepts either two ReadOnlySpan",
    "Yet another new set of APIs are the IndexOfAnyExcept and LastIndexOfAnyExcept methods, introduced by dotnet/runtime#67941 and used in a variety of additional call sites by dotnet/runtime#71146 and dotnet/runtime#71278. While somewhat of a mouthful, these methods are quite handy. They do what their name suggests: whereas IndexOf(T value) searches for the first",
    "Yet another new set of APIs are the IndexOfAnyExcept and LastIndexOfAnyExcept methods, introduced by dotnet/runtime#67941 and used in a variety of additional call sites by dotnet/runtime#71146 and dotnet/runtime#71278. While somewhat of a mouthful, these methods are quite handy. They do what their name suggests: whereas IndexOf(T value) searches for the first",
    "occurrence of value in the input, and whereas IndexOfAny(T value0, T value1, ...) searches for the first occurrence of any of value0 , value1 , etc. in the input, IndexOfAnyExcept(T value) searches for the first occurrence of something that",
    "occurrence of value in the input, and whereas IndexOfAny(T value0, T value1, ...) searches for the first occurrence of any of value0 , value1 , etc. in the input, IndexOfAnyExcept(T value) searches for the first occurrence of something that",
    "dotnet/runtime#73488 vectorizes this overload, as well.",
    "dotnet/runtime#73488 vectorizes this overload, as well.",
    "| Method           | Mean      |   Ratio |",
    "| Method           | Mean      |   Ratio |",
    "Of course, while new ",
    "Of course, while new ",
    "'",
    "'",
    "This is pulling down the text to ",
    "This is pulling down the text to ",
    "| Method   | Runtime   | needle     | Mean        |   Ratio |",
    "| Method   | Runtime   | needle     | Mean        |   Ratio |",
    "For ",
    "For ",
    "Another example of significantly changing the algorithm employed is dotnet/runtime#67758, which enables some amount of vectorization to be applied to IndexOf(",
    "Another example of significantly changing the algorithm employed is dotnet/runtime#67758, which enables some amount of vectorization to be applied to IndexOf(",
    "StringComparison.OrdinalIgnoreCase) . Previously, this operation was implemented with a fairly typical substring search, walking the input string and at every location doing an inner loop to compare the target string, except performing a ToUpper on every character in order to do it in a caseinsensitive manner. Now with this PR, which is based on approaches previously used by Regex , if the target string begins with an ASCII character, the implementation can use IndexOf (if the character isn",
    "StringComparison.OrdinalIgnoreCase) . Previously, this operation was implemented with a fairly typical substring search, walking the input string and at every location doing an inner loop to compare the target string, except performing a ToUpper on every character in order to do it in a caseinsensitive manner. Now with this PR, which is based on approaches previously used by Regex , if the target string begins with an ASCII character, the implementation can use IndexOf (if the character isn",
    "Here, both words are about 4x faster on .NET 7 than they were on .NET 6:",
    "Here, both words are about 4x faster on .NET 7 than they were on .NET 6:",
    "| Method   | Runtime   | needle     | Mean       |   Ratio |",
    "| Method   | Runtime   | needle     | Mean       |   Ratio |",
    "as we",
    "as we",
    "Another example comes from dotnet/runtime#67492 from ",
    "Another example comes from dotnet/runtime#67492 from ",
    "[",
    "[",
    "public bool Contains() =",
    "public bool Contains() =",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "dotnet/runtime#60974 from ",
    "dotnet/runtime#60974 from ",
    "private int",
    "private int",
    "[",
    "[",
    "public int IndexOf() =",
    "public int IndexOf() =",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "One final interesting IndexOf -related optimization. string has long had IndexOf / IndexOfAny / LastIndexOf / LastIndexOfAny , and obviously for string it",
    "One final interesting IndexOf -related optimization. string has long had IndexOf / IndexOfAny / LastIndexOf / LastIndexOfAny , and obviously for string it",
    "IndexOf / IndexOfAny / LastIndexOf / LastIndexOfAny methods. But for spans, this is about more than just char , and so MemoryExtensions grew its own set of implementations largely separate from string ",
    "IndexOf / IndexOfAny / LastIndexOf / LastIndexOfAny methods. But for spans, this is about more than just char , and so MemoryExtensions grew its own set of implementations largely separate from string ",
    "dotnet/runtime#63817, all of these are now unified, such that both string and MemoryExtensions get the best of what the other had.",
    "dotnet/runtime#63817, all of these are now unified, such that both string and MemoryExtensions get the best of what the other had.",
    "| Method         | Runtime   | Mean        |   Ratio |",
    "| Method         | Runtime   | Mean        |   Ratio |",
    "That same PR also cleans up uses of the IndexOf family, and in particular around uses that are checking for containment rather than the actual index of a result. The IndexOf family of methods return a non-negative value when an element is found, and otherwise return -1. That means when checking whether an element was found, code can use either ",
    "That same PR also cleans up uses of the IndexOf family, and in particular around uses that are checking for containment rather than the actual index of a result. The IndexOf family of methods return a non-negative value when an element is found, and otherwise return -1. That means when checking whether an element was found, code can use either ",
    "Speaking of call sites, one of the great things about having highly optimized IndexOf methods is using them in all the places that can benefit, removing the maintenance impact of open-coded replacements while also reaping the perf wins. dotnet/runtime#63913 used IndexOf inside of StringBuilder.Replace to speed up the search for the next character to be replaced:",
    "Speaking of call sites, one of the great things about having highly optimized IndexOf methods is using them in all the places that can benefit, removing the maintenance impact of open-coded replacements while also reaping the perf wins. dotnet/runtime#63913 used IndexOf inside of StringBuilder.Replace to speed up the search for the next character to be replaced:",
    "| Method   | Runtime   | Mean        |   Ratio |",
    "| Method   | Runtime   | Mean        |   Ratio |",
    "dotnet/runtime#60463 from ",
    "dotnet/runtime#60463 from ",
    "| Method       | Runtime   | Mean     |   Ratio |",
    "| Method       | Runtime   | Mean     |   Ratio |",
    "And dotnet/runtime#70176 cleaned up a plethora of additional uses.",
    "And dotnet/runtime#70176 cleaned up a plethora of additional uses.",
    "Finally on the IndexOf front, as noted, a lot of time and energy over the years has gone into optimizing these methods. In previous releases, some of that energy has been in the form of using hardware intrinsics directly, e.g. having an SSE2 code path and an AVX2 code path and an AdvSimd code path. Now that we have Vector128",
    "Finally on the IndexOf front, as noted, a lot of time and energy over the years has gone into optimizing these methods. In previous releases, some of that energy has been in the form of using hardware intrinsics directly, e.g. having an SSE2 code path and an AVX2 code path and an AdvSimd code path. Now that we have Vector128",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "The IndexOf family is just one of many on string / MemoryExtensions that has seen dramatic improvements. Another are the SequenceEquals family, including Equals , StartsWith , and EndsWith . One of my favorite changes in the whole release is dotnet/runtime#65288 and is squarely in this area. It",
    "The IndexOf family is just one of many on string / MemoryExtensions that has seen dramatic improvements. Another are the SequenceEquals family, including Equals , StartsWith , and EndsWith . One of my favorite changes in the whole release is dotnet/runtime#65288 and is squarely in this area. It",
    "but instead as value.StartsWith(",
    "but instead as value.StartsWith(",
    "StringComparison.OrdinalIgnoreCase) , it will recognize that the whole comparison string is ASCII and will OR in the appropriate mask on both the comparison constant and on the read data from the input in order to perform the comparison in a case-insensitive manner.",
    "StringComparison.OrdinalIgnoreCase) , it will recognize that the whole comparison string is ASCII and will OR in the appropriate mask on both the comparison constant and on the read data from the input in order to perform the comparison in a case-insensitive manner.",
    "| Method                    | Runtime   | Mean      |   Ratio |",
    "| Method                    | Runtime   | Mean      |   Ratio |",
    "Interestingly, since .NET 5 the code generated by RegexOptions.Compiled would perform similar unrolling when comparing sequences of multiple characters, and when the source generator was added in .NET 7, it also learned how to do this. However, the source generator has problems with such an optimization, due to endianness. The constants being compared against are subject to byte ordering issues, such that the source generator would need to emit code that could handle running on either little-endian or bigendian machines. The JIT has no such problem, as it",
    "Interestingly, since .NET 5 the code generated by RegexOptions.Compiled would perform similar unrolling when comparing sequences of multiple characters, and when the source generator was added in .NET 7, it also learned how to do this. However, the source generator has problems with such an optimization, due to endianness. The constants being compared against are subject to byte ordering issues, such that the source generator would need to emit code that could handle running on either little-endian or bigendian machines. The JIT has no such problem, as it",
    "much easier to read code utilizing StartsWith that",
    "much easier to read code utilizing StartsWith that",
    "StartsWith and EndsWith have improved in other ways. dotnet/runtime#63734 (improved further by dotnet/runtime#64530) added another really interesting JIT-based optimization, but to understand it, we need to understand string ",
    "StartsWith and EndsWith have improved in other ways. dotnet/runtime#63734 (improved further by dotnet/runtime#64530) added another really interesting JIT-based optimization, but to understand it, we need to understand string ",
    "which given what I just described makes sense: if the Length is 0, then the string doesn",
    "which given what I just described makes sense: if the Length is 0, then the string doesn",
    "If the value parameter isn",
    "If the value parameter isn",
    "and we",
    "and we",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "(Another example of IsKnownConstant being used comes from dotnet/runtime#64016, which uses it to improve Math.Round when a MidpointRounding mode is specified. Call sites to this almost always explicitly specify the enum value as a constant, which then allows the JIT to specialize the code generation for the method to the specific mode being used; that in turn, for example, enables a Math.Round(..., MidpointRounding.AwayFromZero) call on Arm64 to be lowered to a single frinta instruction.)",
    "(Another example of IsKnownConstant being used comes from dotnet/runtime#64016, which uses it to improve Math.Round when a MidpointRounding mode is specified. Call sites to this almost always explicitly specify the enum value as a constant, which then allows the JIT to specialize the code generation for the method to the specific mode being used; that in turn, for example, enables a Math.Round(..., MidpointRounding.AwayFromZero) call on Arm64 to be lowered to a single frinta instruction.)",
    "EndsWith was also improved in dotnet/runtime#72750, and specifically for when StringComparison.OrdinalIgnoreCase is specified. This simple PR just switched which internal helper method was used to implement this method, taking advantage of one that is sufficient for the needs of this method and that has lower overheads.",
    "EndsWith was also improved in dotnet/runtime#72750, and specifically for when StringComparison.OrdinalIgnoreCase is specified. This simple PR just switched which internal helper method was used to implement this method, taking advantage of one that is sufficient for the needs of this method and that has lower overheads.",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "Finally, dotnet/runtime#67202 and dotnet/runtime#73475 employ Vector128",
    "Finally, dotnet/runtime#67202 and dotnet/runtime#73475 employ Vector128",
    "Another method that",
    "Another method that",
    "private char",
    "private char",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "String.Split also saw vectorization improvements in dotnet/runtime#64899 from ",
    "String.Split also saw vectorization improvements in dotnet/runtime#64899 from ",
    "Converting various formats of strings is something many applications and services do, whether that",
    "Converting various formats of strings is something many applications and services do, whether that",
    "Base64 characters (there",
    "Base64 characters (there",
    "| Method           | Runtime   | Mean      |   Ratio |",
    "| Method           | Runtime   | Mean      |   Ratio |",
    "Just as widening can be used to go from bytes to chars, narrowing can be used to go from chars to bytes, in particular if the chars are actually ASCII and thus have a 0 upper byte. Such narrowing can be vectorized, and the internal NarrowUtf16ToAscii utility helper does exactly that, used as part of methods like Encoding.ASCII.GetBytes . While this method was previously vectorized, its primary fastpath utilized SSE2 and thus didn",
    "Just as widening can be used to go from bytes to chars, narrowing can be used to go from chars to bytes, in particular if the chars are actually ASCII and thus have a 0 upper byte. Such narrowing can be vectorized, and the internal NarrowUtf16ToAscii utility helper does exactly that, used as part of methods like Encoding.ASCII.GetBytes . While this method was previously vectorized, its primary fastpath utilized SSE2 and thus didn",
    null,
    null,
    "Encoding.UTF8.GetByteCount . (And in the same vein, dotnet/runtime#67192 changed the internal HexConverter.EncodeToUtf16 method from using SSSE3 intrinsics to instead use Vector128",
    "Encoding.UTF8.GetByteCount . (And in the same vein, dotnet/runtime#67192 changed the internal HexConverter.EncodeToUtf16 method from using SSSE3 intrinsics to instead use Vector128",
    "Encoding.UTF8 was also improved a bit. In particular, dotnet/runtime#69910 streamlined the implementations of GetMaxByteCount and GetMaxCharCount , making them small enough to be commonly inlined when used directly off of Encoding.UTF8 such that the JIT is able to devirtualize the calls.",
    "Encoding.UTF8 was also improved a bit. In particular, dotnet/runtime#69910 streamlined the implementations of GetMaxByteCount and GetMaxCharCount , making them small enough to be commonly inlined when used directly off of Encoding.UTF8 such that the JIT is able to devirtualize the calls.",
    "| Method          | Runtime   | Mean      |   Ratio |",
    "| Method          | Runtime   | Mean      |   Ratio |",
    "Arguably the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals. Initially implemented in the C# compiler in dotnet/roslyn#58991, with follow-on work in dotnet/roslyn#59390, dotnet/roslyn#61532, and dotnet/roslyn#62044, UTF8 literals enables the compiler to perform the UTF8 encoding into bytes at compile-time. Rather than writing a normal string, e.g. ",
    "Arguably the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals. Initially implemented in the C# compiler in dotnet/roslyn#58991, with follow-on work in dotnet/roslyn#59390, dotnet/roslyn#61532, and dotnet/roslyn#62044, UTF8 literals enables the compiler to perform the UTF8 encoding into bytes at compile-time. Rather than writing a normal string, e.g. ",
    "the C# compiler will compile that equivalent to if you wrote:",
    "the C# compiler will compile that equivalent to if you wrote:",
    "In other words, the compiler is doing the equivalent of Encoding.UTF8.GetBytes at compile-time and hardcoding the resulting bytes, saving the cost of performing that encoding at run-time. Of course, at first glance, that array allocation might look terribly inefficient. However, looks can be deceiving, and are in this case. For several releases now, when the C# compiler sees a byte",
    "In other words, the compiler is doing the equivalent of Encoding.UTF8.GetBytes at compile-time and hardcoding the resulting bytes, saving the cost of performing that encoding at run-time. Of course, at first glance, that array allocation might look terribly inefficient. However, looks can be deceiving, and are in this case. For several releases now, when the C# compiler sees a byte",
    "This means we not only save on the encoding costs at run-time, and we not only avoid whatever managed allocations might be required to store the resulting data, we also benefit from the JIT being able to see information about the encoded data, like it",
    "This means we not only save on the encoding costs at run-time, and we not only avoid whatever managed allocations might be required to store the resulting data, we also benefit from the JIT being able to see information about the encoded data, like it",
    "for which the JIT produces:",
    "for which the JIT produces:",
    "The JIT inlines the property access, sees that the span is being constructed with a length of 5 , and so rather than emitting any array allocations or span constructions or anything even resembling that, it simply outputs mov eax, 5 to return the known length of the span.",
    "The JIT inlines the property access, sees that the span is being constructed with a length of 5 , and so rather than emitting any array allocations or span constructions or anything even resembling that, it simply outputs mov eax, 5 to return the known length of the span.",
    "Thanks primarily to dotnet/runtime#70568, dotnet/runtime#69995, dotnet/runtime#70894, dotnet/runtime#71417 from ",
    "Thanks primarily to dotnet/runtime#70568, dotnet/runtime#69995, dotnet/runtime#70894, dotnet/runtime#71417 from ",
    "| Method       | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method       | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "Like I said, not fair, but it proves the point :)",
    "Like I said, not fair, but it proves the point :)",
    "Encoding is of course just one mechanism for creating string instances. Others have also improved in .NET 7. Take the super common long.ToString , for example. Previous releases improved int.ToString , but there were enough differences between the 32-bit and 64-bit algorithms that long didn",
    "Encoding is of course just one mechanism for creating string instances. Others have also improved in .NET 7. Take the super common long.ToString , for example. Previous releases improved int.ToString , but there were enough differences between the 32-bit and 64-bit algorithms that long didn",
    "You can also see improvements in string.Format and StringBuilder.AppendFormat , as well as other helpers that layer on top of these (like TextWriter.AppendFormat ). dotnet/runtime#69757 overhauls the core routines inside Format to avoid unnecessary bounds checking, favor expected cases, and generally clean up the implementation. It also, however, utilities IndexOfAny to search for the next interpolation hole that needs to be filled in, and if the non-hole-character to hole ratio is high (e.g. long format string with few holes), it can be way faster than before.",
    "You can also see improvements in string.Format and StringBuilder.AppendFormat , as well as other helpers that layer on top of these (like TextWriter.AppendFormat ). dotnet/runtime#69757 overhauls the core routines inside Format to avoid unnecessary bounds checking, favor expected cases, and generally clean up the implementation. It also, however, utilities IndexOfAny to search for the next interpolation hole that needs to be filled in, and if the non-hole-character to hole ratio is high (e.g. long format string with few holes), it can be way faster than before.",
    "| Method       | Runtime   | Mean      |   Ratio |",
    "| Method       | Runtime   | Mean      |   Ratio |",
    "Speaking of StringBuilder , it",
    "Speaking of StringBuilder , it",
    "That fixed statement translates into a ",
    "That fixed statement translates into a ",
    "where that string.GetRawStringData method is just an internal version of the public string.GetPinnableReference method, returning a ref instead of a ref readonly . This means that all of the high-performance code inside of StringBuilder that had been using pointers to avoid bounds checking and the like can continue to do so, but now also does so without pinning all of the inputs.",
    "where that string.GetRawStringData method is just an internal version of the public string.GetPinnableReference method, returning a ref instead of a ref readonly . This means that all of the high-performance code inside of StringBuilder that had been using pointers to avoid bounds checking and the like can continue to do so, but now also does so without pinning all of the inputs.",
    "The second thing this StringBuilder change did was unify an optimization that was present for string inputs to also apply to char",
    "The second thing this StringBuilder change did was unify an optimization that was present for string inputs to also apply to char",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio |",
    "One of the great things about improving things low in the stack is they have a multiplicative effect; they not only help improve the performance of user code that directly relies on the improved functionality, they can also help improve the performance of other code in the core libraries, which then further helps dependent apps and services. You can see this, for example, with DateTimeOffset.ToString , which depends on StringBuilder :",
    "One of the great things about improving things low in the stack is they have a multiplicative effect; they not only help improve the performance of user code that directly relies on the improved functionality, they can also help improve the performance of other code in the core libraries, which then further helps dependent apps and services. You can see this, for example, with DateTimeOffset.ToString , which depends on StringBuilder :",
    "| Method                 | Runtime   | Mean     |   Ratio |",
    "| Method                 | Runtime   | Mean     |   Ratio |",
    "StringBuilder itself was then further updated by dotnet/runtime#64922 from ",
    "StringBuilder itself was then further updated by dotnet/runtime#64922 from ",
    "previously discussed PR to insert the resulting characters at the right location (it also falls back to ToString when there",
    "previously discussed PR to insert the resulting characters at the right location (it also falls back to ToString when there",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Other minor improvements to StringBuilder have also been made, like dotnet/runtime#60406 which removed a small int",
    "Other minor improvements to StringBuilder have also been made, like dotnet/runtime#60406 which removed a small int",
    "We don",
    "We don",
    "Note that I",
    "Note that I",
    "As an aside, the expanded string.Concat version highlights that this method could have been written to result in a bit less IL if it were instead written as:",
    "As an aside, the expanded string.Concat version highlights that this method could have been written to result in a bit less IL if it were instead written as:",
    "but this doesn",
    "but this doesn",
    "| Method            | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method            | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "There are also places where StringBuilder was still applicable, but it was being used on hot-enough paths that previous releases of .NET saw the StringBuilder instance being cached. Several of the core libraries, including System.Private.CoreLib, have an internal StringBuilderCache type which caches a StringBuilder instance in a ",
    "There are also places where StringBuilder was still applicable, but it was being used on hot-enough paths that previous releases of .NET saw the StringBuilder instance being cached. Several of the core libraries, including System.Private.CoreLib, have an internal StringBuilderCache type which caches a StringBuilder instance in a ",
    "remaining uses of StringBuilderCache have been replaced. I",
    "remaining uses of StringBuilderCache have been replaced. I",
    "In the same vein of not doing unnecessary work, there",
    "In the same vein of not doing unnecessary work, there",
    "The relevant thing to recognize here is these methods have overloads that take just the starting offset. Since the length being specified is the remainder after the specified offset, the call could instead be simplified to:",
    "The relevant thing to recognize here is these methods have overloads that take just the starting offset. Since the length being specified is the remainder after the specified offset, the call could instead be simplified to:",
    "which is not only more readable and maintainable, it has some small efficiency benefits, e.g. on 64-bit the Slice(int, int) constructor has an extra addition over Slice(int) , and for 32-bit the Slice(int, int) constructor incurs an additional comparison and branch. It",
    "which is not only more readable and maintainable, it has some small efficiency benefits, e.g. on 64-bit the Slice(int, int) constructor has an extra addition over Slice(int) , and for 32-bit the Slice(int, int) constructor incurs an additional comparison and branch. It",
    "Ok, enough about string . What about spans? One of the coolest features in C# 11 is the new support for ref fields. What is a ref field? You",
    "Ok, enough about string . What about spans? One of the coolest features in C# 11 is the new support for ref fields. What is a ref field? You",
    "Later versions of C# added the ability to have local ref s, e.g.",
    "Later versions of C# added the ability to have local ref s, e.g.",
    "and even to have ref returns, e.g.",
    "and even to have ref returns, e.g.",
    "These facilities are more advanc ed, but they",
    "These facilities are more advanc ed, but they",
    "Span",
    "Span",
    "But not span. Span",
    "But not span. Span",
    "Note there",
    "Note there",
    "but rather than that being equivalent to calling some setter:",
    "but rather than that being equivalent to calling some setter:",
    "it",
    "it",
    "That",
    "That",
    "The rollout of ref fields throughout dotnet/runtime was done in dotnet/runtime#71498, following the C# language gaining this support primarily in dotnet/roslyn#62155, which itself was the culmination of many PRs first into a feature branch. ref fields alone doesn ",
    "The rollout of ref fields throughout dotnet/runtime was done in dotnet/runtime#71498, following the C# language gaining this support primarily in dotnet/roslyn#62155, which itself was the culmination of many PRs first into a feature branch. ref fields alone doesn ",
    "added in dotnet/runtime#67447 (and then made public and used more broadly in dotnet/runtime#71589). This may beg the question, why does ref field support enable two new constructors that take ref s, considering spans already were able to store a ref ? After all, the MemoryMarshal.CreateSpan(ref T reference, int length) and corresponding CreateReadOnlySpan methods have existed for as long as spans have, and these new constructors are equivalent to calling those methods with a length of 1. The answer is: safety.",
    "added in dotnet/runtime#67447 (and then made public and used more broadly in dotnet/runtime#71589). This may beg the question, why does ref field support enable two new constructors that take ref s, considering spans already were able to store a ref ? After all, the MemoryMarshal.CreateSpan(ref T reference, int length) and corresponding CreateReadOnlySpan methods have existed for as long as spans have, and these new constructors are equivalent to calling those methods with a length of 1. The answer is: safety.",
    "Imagine if you could willynilly call this constructor. You",
    "Imagine if you could willynilly call this constructor. You",
    "At this point the caller of this method is handed a span that refers to garbage; that",
    "At this point the caller of this method is handed a span that refers to garbage; that",
    "but at that point you",
    "but at that point you",
    "In other words, the compiler now understands that Span",
    "In other words, the compiler now understands that Span",
    "of the method, which is bad. Hence how this relates to ref fields: because ref fields are now a thing, the compiler",
    "of the method, which is bad. Hence how this relates to ref fields: because ref fields are now a thing, the compiler",
    "As is often the case, addressing one issue kicks the can down the road a bit and exposes another. The compiler now believes that a ref passed to a method on a ref struct could enable that ref struct instance to store the ref (note that this was already the case with ref struct s passed to methods on ref structs ), but what if we don",
    "As is often the case, addressing one issue kicks the can down the road a bit and exposes another. The compiler now believes that a ref passed to a method on a ref struct could enable that ref struct instance to store the ref (note that this was already the case with ref struct s passed to methods on ref structs ), but what if we don",
    "We have a ref struct SpanWriter that takes a Span",
    "We have a ref struct SpanWriter that takes a Span",
    "error CS8350: This combination of arguments to ",
    "error CS8350: This combination of arguments to ",
    "What do we do? The Write method doesn",
    "What do we do? The Write method doesn",
    "If Write were then to try to store value , the compiler would balk:",
    "If Write were then to try to store value , the compiler would balk:",
    "But as it",
    "But as it",
    "There",
    "There",
    "This produces a compiler error:",
    "This produces a compiler error:",
    "Effectively, that",
    "Effectively, that",
    "and now the code will compile successfully. Of course, this also places demands on callers of this method. For a call site, the compiler sees the ",
    "and now the code will compile successfully. Of course, this also places demands on callers of this method. For a call site, the compiler sees the ",
    "Another impactful span-related change comes in dotnet/runtime#70095 from ",
    "Another impactful span-related change comes in dotnet/runtime#70095 from ",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "Another span-related change, dotnet/runtime#72727 refactored a bunch of code paths to eliminate some cached arrays. Why avoid cached arrays? After all, isn",
    "Another span-related change, dotnet/runtime#72727 refactored a bunch of code paths to eliminate some cached arrays. Why avoid cached arrays? After all, isn",
    "and replaced it with code like:",
    "and replaced it with code like:",
    "This h as a variety of benefits. There",
    "This h as a variety of benefits. There",
    "| Method     | Mean     |   Ratio |",
    "| Method     | Mean     |   Ratio |",
    "Another example from that PR took code along the lines of:",
    "Another example from that PR took code along the lines of:",
    "and replaced it with code like:",
    "and replaced it with code like:",
    "In this case, not only have we avoided the char",
    "In this case, not only have we avoided the char",
    "Of course, in some cases the arrays are entirely unnecessary. In that same PR, there were several cases like this:",
    "Of course, in some cases the arrays are entirely unnecessary. In that same PR, there were several cases like this:",
    "By switching to use spans, again, we can instead write it like this:",
    "By switching to use spans, again, we can instead write it like this:",
    "MemoryExtensions.IndexOfAny has a dedicated overload for two and three arguments, at which point we don",
    "MemoryExtensions.IndexOfAny has a dedicated overload for two and three arguments, at which point we don",
    "Finally, dotnet/runtime#59670 from ",
    "Finally, dotnet/runtime#59670 from ",
    "Back in May, I shared a fairly detailed post about the improvements coming to Regular Expressions in .NET 7. As a recap, prior to .NET 5, Regex ",
    "Back in May, I shared a fairly detailed post about the improvements coming to Regular Expressions in .NET 7. As a recap, prior to .NET 5, Regex ",
    "Welcome back. With that context, I",
    "Welcome back. With that context, I",
    "Let",
    "Let",
    "A significant number of years of development went into the NonBacktracking implementation, which was initially added into dotnet/runtime in dotnet/runtime#60607. However, the original research and implementation for it actually came from Microsoft Research (MSR), and was available as an experimental package in the form of the Symbolic Regex Matcher (SRM) library published by MSR. You can still see vestiges of this in the current code now in .NET 7, but it",
    "A significant number of years of development went into the NonBacktracking implementation, which was initially added into dotnet/runtime in dotnet/runtime#60607. However, the original research and implementation for it actually came from Microsoft Research (MSR), and was available as an experimental package in the form of the Symbolic Regex Matcher (SRM) library published by MSR. You can still see vestiges of this in the current code now in .NET 7, but it",
    "This i mplementation is based on the notion of regular expression derivatives, a concept that",
    "This i mplementation is based on the notion of regular expression derivatives, a concept that",
    "11",
    "11",
    "to match three word characters, if you apply this to the next input character ",
    "to match three word characters, if you apply this to the next input character ",
    "e",
    "e",
    "[",
    "[",
    "Looks an awful lot like a DFA, doesn",
    "Looks an awful lot like a DFA, doesn",
    "Of course, the devil is in the details and there",
    "Of course, the devil is in the details and there",
    "As noted, the non-backtracking engine is linear in the length of the input. But that doesn",
    "As noted, the non-backtracking engine is linear in the length of the input. But that doesn",
    "implementation simply doesn",
    "implementation simply doesn",
    "Even after its progress as a standalone library from MSR, more than 100 PRs went into making RegexOptions.NonBacktracking what it is now in .NET 7, including optimizations like dotnet/runtime#70217 from ",
    "Even after its progress as a standalone library from MSR, more than 100 PRs went into making RegexOptions.NonBacktracking what it is now in .NET 7, including optimizations like dotnet/runtime#70217 from ",
    "There",
    "There",
    "RuntimeHelpers.EnsureSufficientExecutionStack and",
    "RuntimeHelpers.EnsureSufficientExecutionStack and",
    "RuntimeHelpers.TryEnsureSufficientExecutionStack for this purpose). If it detects it",
    "RuntimeHelpers.TryEnsureSufficientExecutionStack for this purpose). If it detects it",
    "As was mentioned in my previous blog post about regular expressions, both the backtracking implementations and the non-backtracking implementation have their place. The main benefit of the non-backtracking implementation is predictability: because of the linear processing guarantee, once you",
    "As was mentioned in my previous blog post about regular expressions, both the backtracking implementations and the non-backtracking implementation have their place. The main benefit of the non-backtracking implementation is predictability: because of the linear processing guarantee, once you",
    "Regex gets several new methods in .NET 7, all of which enable improved performance. The simplicity of the new APIs likely also misrepresents how much work was necessary to enable them, in particular because the new APIs all support ReadOnlySpan",
    "Regex gets several new methods in .NET 7, all of which enable improved performance. The simplicity of the new APIs likely also misrepresents how much work was necessary to enable them, in particular because the new APIs all support ReadOnlySpan",
    "dotnet/runtime#65473 brings Regex into the span-based era of .NET, overcoming a significant limitation in Regex since spans were introduced back in .NET Core 2.1. Regex has historically been based on processing System.String inputs, and that fact pervades the Regex design and implementation, including the APIs exposed for the extensibility model Regex.CompileToAssembly relied on in .NET Framework ( CompileToAssembly is now obsoleted and has never been functional in .NET Core). One subtly that relies on the nature of string as the input is how match information is returned to callers. Regex.Match returns a Match object that represents the first match in the input, and that Match object exposes a NextMatch method that enables moving to the next match. That means the Match object needs to store a reference to the input, so that it can be fed back into the matching engine as part of such a NextMatch call. If that input is a string , great, no problem. But if that input is a ReadOnlySpan",
    "dotnet/runtime#65473 brings Regex into the span-based era of .NET, overcoming a significant limitation in Regex since spans were introduced back in .NET Core 2.1. Regex has historically been based on processing System.String inputs, and that fact pervades the Regex design and implementation, including the APIs exposed for the extensibility model Regex.CompileToAssembly relied on in .NET Framework ( CompileToAssembly is now obsoleted and has never been functional in .NET Core). One subtly that relies on the nature of string as the input is how match information is returned to callers. Regex.Match returns a Match object that represents the first match in the input, and that Match object exposes a NextMatch method that enables moving to the next match. That means the Match object needs to store a reference to the input, so that it can be fed back into the matching engine as part of such a NextMatch call. If that input is a string , great, no problem. But if that input is a ReadOnlySpan",
    "First, we made FindFirstChar and Go virtual instead of abstract. The design that splits these methods is largely antiquated, and in particular the forced separation between a stage of processing where you find the next possible location of a match and then a stage where you actually perform the match at that location doesn",
    "First, we made FindFirstChar and Go virtual instead of abstract. The design that splits these methods is largely antiquated, and in particular the forced separation between a stage of processing where you find the next possible location of a match and then a stage where you actually perform the match at that location doesn",
    "span; they no longer need to access the protected RegexRunner.runtext , RegexRunner.runtextbeg , and RegexRunner.runtextend members tha t surface the input; they",
    "span; they no longer need to access the protected RegexRunner.runtext , RegexRunner.runtextbeg , and RegexRunner.runtextend members tha t surface the input; they",
    "That will result in the JIT generating assembly code along the lines of this:",
    "That will result in the JIT generating assembly code along the lines of this:",
    "In contrast, if we",
    "In contrast, if we",
    "And when it comes to compilers, something in a canonical form is really good, because the more common the shape of the code, the more likely it is to be heavily optimized:",
    "And when it comes to compilers, something in a canonical form is really good, because the more common the shape of the code, the more likely it is to be heavily optimized:",
    "So even without all the other benefits that come from operating in terms of span, we immediately get low-level code generation benefits from performing all the logic in terms of spans. While the above example was made up (obviously the matching logic does more than a simple for loop) , here",
    "So even without all the other benefits that come from operating in terms of span, we immediately get low-level code generation benefits from performing all the logic in terms of spans. While the above example was made up (obviously the matching logic does more than a simple for loop) , here",
    "and here",
    "and here",
    "The most interesting thing to notice here is the:",
    "The most interesting thing to notice here is the:",
    "at the end of the first version that doesn",
    "at the end of the first version that doesn",
    "dotnet/runtime#66129, dotnet/runtime#66178, and dotnet/runtime#72728, all of which clean up unnecessary checks against the bounds that are then always 0 and span.Length .",
    "dotnet/runtime#66129, dotnet/runtime#66178, and dotnet/runtime#72728, all of which clean up unnecessary checks against the bounds that are then always 0 and span.Length .",
    "Ok, so the engines are now able to be handed span inputs and process them, great, what can we do with that? Well, Regex.IsMatch is easy: it",
    "Ok, so the engines are now able to be handed span inputs and process them, great, what can we do with that? Well, Regex.IsMatch is easy: it",
    "So, IsMatch and Count can work with spans. But we still don",
    "So, IsMatch and Count can work with spans. But we still don",
    "Being a ref struct , the enumerator is able to store a reference to the input span, and is thus able to iterate through matches, which are represented by the ValueMatch ref struct. Notably, today ValueMatch doesn",
    "Being a ref struct , the enumerator is able to store a reference to the input span, and is thus able to iterate through matches, which are represented by the ValueMatch ref struct. Notably, today ValueMatch doesn",
    "As noted earlier, the core of all of the engines is a Scan(ReadOnlySpan",
    "As noted earlier, the core of all of the engines is a Scan(ReadOnlySpan",
    "when it either finds the location of the next match or exhausts the input without finding another. For the backtracking engines, the implementation of that method is logically as follows:",
    "when it either finds the location of the next match or exhausts the input without finding another. For the backtracking engines, the implementation of that method is logically as follows:",
    "We try to match the input at the current position, and if we",
    "We try to match the input at the current position, and if we",
    "As with FindFirstChar previously, that TryFindNextPossibleStartingPosition has the responsibility of searching as quickly as possible for the next place to match (or determining that nothing else could possibly match, in which case it would return false and the loop would exit). As FindFirstChar , and it was embued with multiple ways of doing its job. In .NET 7,",
    "As with FindFirstChar previously, that TryFindNextPossibleStartingPosition has the responsibility of searching as quickly as possible for the next place to match (or determining that nothing else could possibly match, in which case it would return false and the loop would exit). As FindFirstChar , and it was embued with multiple ways of doing its job. In .NET 7,",
    "TryFindNextPossibleStartingPosition learns many more and improved ways of helping the engine be fast.",
    "TryFindNextPossibleStartingPosition learns many more and improved ways of helping the engine be fast.",
    "In .NET 6, the interpreter engine had effectively two ways of implementing TryFindNextPossibleStartingPosition : a Boyer-Moore substring search if the pattern began with a string (potentially case-insensitive) of at least two characters, and a linear scan for a character class known to be the set of all possible chars that could begin a match. For the latter case, the interpreter had eight different implementations for matching, based on a combination of whether RegexOptions.RightToLeft was set or not, whether the character class required case-insensitive comparison or not, and whether the character class contained only a single character or more than one character. Some of these were more optimized than others, e.g. a left-to-right, case-sensitive, single-char search would use an IndexOf(char) to search for the next location, an optimization added in .NET 5. However, every time this operation was performed, the engine would need to recompute which case it would be. dotnet/runtime#60822 improved this, introducing an internal",
    "In .NET 6, the interpreter engine had effectively two ways of implementing TryFindNextPossibleStartingPosition : a Boyer-Moore substring search if the pattern began with a string (potentially case-insensitive) of at least two characters, and a linear scan for a character class known to be the set of all possible chars that could begin a match. For the latter case, the interpreter had eight different implementations for matching, based on a combination of whether RegexOptions.RightToLeft was set or not, whether the character class required case-insensitive comparison or not, and whether the character class contained only a single character or more than one character. Some of these were more optimized than others, e.g. a left-to-right, case-sensitive, single-char search would use an IndexOf(char) to search for the next location, an optimization added in .NET 5. However, every time this operation was performed, the engine would need to recompute which case it would be. dotnet/runtime#60822 improved this, introducing an internal",
    "enum of the strategies used by TryFindNextPossibleStartingPosition to find the next opportunity, adding a switch to TryFindNextPossibleStartingPosition to quickly jump to the right strategy, and precomputing which strategy to use when the interpreter was constructed. This not only made the interpreter",
    "enum of the strategies used by TryFindNextPossibleStartingPosition to find the next opportunity, adding a switch to TryFindNextPossibleStartingPosition to quickly jump to the right strategy, and precomputing which strategy to use when the interpreter was constructed. This not only made the interpreter",
    "dotnet/runtime#60888 then added the first additional strategy. The implementation was already capable of using IndexOf(char) , but as mentioned previously in this post, the implementation of IndexOf(ReadOnlySpan",
    "dotnet/runtime#60888 then added the first additional strategy. The implementation was already capable of using IndexOf(char) , but as mentioned previously in this post, the implementation of IndexOf(ReadOnlySpan",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio |",
    "dotnet/runtime#61490 then removed BoyerMoore entirely. This wasn",
    "dotnet/runtime#61490 then removed BoyerMoore entirely. This wasn",
    "check akin to c == ",
    "check akin to c == ",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "The previous PR started turning IgnoreCase pattern text into sets, in particular for ASCII, e.g. (?i)a would become ",
    "The previous PR started turning IgnoreCase pattern text into sets, in particular for ASCII, e.g. (?i)a would become ",
    "dotnet/runtime#63477 (and then later improved in dotnet/runtime#66572) proceeded to add another searching strategy, this one inspired by nimregex",
    "dotnet/runtime#63477 (and then later improved in dotnet/runtime#66572) proceeded to add another searching strategy, this one inspired by nimregex",
    "(@",
    "(@",
    "find it, we can match backwards through as many ",
    "find it, we can match backwards through as many ",
    "| Method   | Runtime   | Mean        |   Ratio |",
    "| Method   | Runtime   | Mean        |   Ratio |",
    "Of course, as has been talked about elsewhere, the best optimizations aren",
    "Of course, as has been talked about elsewhere, the best optimizations aren",
    "TryFindNextPossibleStartingPosition won",
    "TryFindNextPossibleStartingPosition won",
    "| Method   | Runtime   | Mean          |   Ratio |",
    "| Method   | Runtime   | Mean          |   Ratio |",
    "dotnet/runtime#67732 is another PR related to improving anchor handling. It",
    "dotnet/runtime#67732 is another PR related to improving anchor handling. It",
    "By this point, the engines are able to use IndexOf(ReadOnlySpan",
    "By this point, the engines are able to use IndexOf(ReadOnlySpan",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "Loop handling in the compiled and source generated engines has been significantly improved, both with respect to processing them faster and with respect to backtracking less.",
    "Loop handling in the compiled and source generated engines has been significantly improved, both with respect to processing them faster and with respect to backtracking less.",
    "With regular greedy loops (e.g. c",
    "With regular greedy loops (e.g. c",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "Sometimes optimizations are well-intended but slightly miss the mark. dotnet/runtime#63398 fixes such an issue with an optimization introduced in .NET 5; the optimization was valuable but only for a subset of the scenarios it was intended to cover. While TryFindNextPossibleStartingPosition ",
    "Sometimes optimizations are well-intended but slightly miss the mark. dotnet/runtime#63398 fixes such an issue with an optimization introduced in .NET 5; the optimization was valuable but only for a subset of the scenarios it was intended to cover. While TryFindNextPossibleStartingPosition ",
    "TryMatchAtCurrentPosition to do so. One of the occasions in which it",
    "TryMatchAtCurrentPosition to do so. One of the occasions in which it",
    "| Method   | Runtime   | Mean         |   Ratio |",
    "| Method   | Runtime   | Mean         |   Ratio |",
    "As mentioned elsewhere, the best optimizations are those that make work entirely vanish rather than just making work faster. dotnet/runtime#68989, dotnet/runtime#63299, and dotnet/runtime#63518 do exactly that by improving the pattern analyzers ability to find and eliminate more unnecessary backtracking, a process the analyzer refers to as ",
    "As mentioned elsewhere, the best optimizations are those that make work entirely vanish rather than just making work faster. dotnet/runtime#68989, dotnet/runtime#63299, and dotnet/runtime#63518 do exactly that by improving the pattern analyzers ability to find and eliminate more unnecessary backtracking, a process the analyzer refers to as ",
    "(Note that those comments aren",
    "(Note that those comments aren",
    "When a regular expression is input, it",
    "When a regular expression is input, it",
    "[",
    "[",
    "as it will produce a Scan method like this (comment and all):",
    "as it will produce a Scan method like this (comment and all):",
    "Another set of transformations was introduced in dotnet/runtime#59903, specifically around alternations (which beyond loops are the other source of backtracking). This introduced two main optimizations. First, it enables rewriting alternations into alternations of alternations, e.g. transforming axy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z) , which is then further reduced into ax",
    "Another set of transformations was introduced in dotnet/runtime#59903, specifically around alternations (which beyond loops are the other source of backtracking). This introduced two main optimizations. First, it enables rewriting alternations into alternations of alternations, e.g. transforming axy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z) , which is then further reduced into ax",
    "The .NET 7 regex implementation has no fewer than four engines: the interpreter (what you get if you don",
    "The .NET 7 regex implementation has no fewer than four engines: the interpreter (what you get if you don",
    "dotnet/runtime#59186 provided the initial implementation of the source generator. This was a direct port of the compiler, effectively a line-by-line translation of IL into C#; the result is C# akin to what you",
    "dotnet/runtime#59186 provided the initial implementation of the source generator. This was a direct port of the compiler, effectively a line-by-line translation of IL into C#; the result is C# akin to what you",
    "series of instructions, would just emit the IL for processing each. It had some opportunity for being more efficient, e.g. loop unrolling, but a lot of value was left on the table. In .NET 5, an alternate path was added in support of patterns without backtracking; this code path was based on being handed the parsed node tree rather than being based on the series of instructions, and that higher-level form enabled the compiler to derive more insights about the pattern that it could then use to generate more efficient code. In .NET 7, support for all regex features were incrementally added in, over the course of multiple PRs, in particular dotnet/runtime#60385 for backtracking single char loops, dotnet/runtime#61698 for backtracking single char lazy loops, dotnet/runtime#61784 for other backtracking lazy loops, and dotnet/runtime#61906 for other backtracking loops as well as back references and conditionals. At that point, the only features missing were support for RegexOptions.RightToLeft and lookbehinds (which are implemented in terms of right-to-left), and we decided based on relatively little use of these features that we needn",
    "series of instructions, would just emit the IL for processing each. It had some opportunity for being more efficient, e.g. loop unrolling, but a lot of value was left on the table. In .NET 5, an alternate path was added in support of patterns without backtracking; this code path was based on being handed the parsed node tree rather than being based on the series of instructions, and that higher-level form enabled the compiler to derive more insights about the pattern that it could then use to generate more efficient code. In .NET 7, support for all regex features were incrementally added in, over the course of multiple PRs, in particular dotnet/runtime#60385 for backtracking single char loops, dotnet/runtime#61698 for backtracking single char lazy loops, dotnet/runtime#61784 for other backtracking lazy loops, and dotnet/runtime#61906 for other backtracking loops as well as back references and conditionals. At that point, the only features missing were support for RegexOptions.RightToLeft and lookbehinds (which are implemented in terms of right-to-left), and we decided based on relatively little use of these features that we needn",
    "One of the great things about the source generator emitting idiomatic C# is it makes it easy to iterate. Every time you put in a pattern and see what the generator emits, it",
    "One of the great things about the source generator emitting idiomatic C# is it makes it easy to iterate. Every time you put in a pattern and see what the generator emits, it",
    "The compiler and source generator were also updated to take advantage of newer features. dotnet/runtime#63277, for example, teaches the source generator how to determine if unsafe code is allowed, and if it is, it emits a ",
    "The compiler and source generator were also updated to take advantage of newer features. dotnet/runtime#63277, for example, teaches the source generator how to determine if unsafe code is allowed, and if it is, it emits a ",
    "One last and interesting code generation aspect is in optimizations around character class matching. Matching character classes, whether ones explicitly written by the developer or ones implicitly created by the engine (e.g. as part of finding the set of all characters that can begin the expression), can be one of the more time-consuming aspects of matching; if you imagine having to evaluate this logic for every character in the input, then how many instructions needs to be executed as part of matching a character class directly correlates to how long it takes to perform the overall match. We thus spend some time trying to ensure we generate optimal matching code for as many categories of character classes as possible. dotnet/runtime#67365, for example, improved a bunch of cases found to be common in real-world use, like specially-recognizing sets like ",
    "One last and interesting code generation aspect is in optimizations around character class matching. Matching character classes, whether ones explicitly written by the developer or ones implicitly created by the engine (e.g. as part of finding the set of all characters that can begin the expression), can be one of the more time-consuming aspects of matching; if you imagine having to evaluate this logic for every character in the input, then how many instructions needs to be executed as part of matching a character class directly correlates to how long it takes to perform the overall match. We thus spend some time trying to ensure we generate optimal matching code for as many categories of character classes as possible. dotnet/runtime#67365, for example, improved a bunch of cases found to be common in real-world use, like specially-recognizing sets like ",
    "| Method   | Runtime   | Mean            |   Ratio |",
    "| Method   | Runtime   | Mean            |   Ratio |",
    "Or dotnet/runtime#68924, which taught the source generator how to use all of the new char ASCII helper methods, like char.IsAsciiLetterOrDigit , as well as some existing helpers it didn",
    "Or dotnet/runtime#68924, which taught the source generator how to use all of the new char ASCII helper methods, like char.IsAsciiLetterOrDigit , as well as some existing helpers it didn",
    "now produces this in the core matching logic emitted by the source generator:",
    "now produces this in the core matching logic emitted by the source generator:",
    "Other changes impacting character class code generation included dotnet/runtime#72328, which improved the handling of character classes that involve character class subtraction; dotnet/runtime#72317 from ",
    "Other changes impacting character class code generation included dotnet/runtime#72328, which improved the handling of character classes that involve character class subtraction; dotnet/runtime#72317 from ",
    "Finally, with all of these improvements to Regex , a multitude of PRs fixed up regexes being used across dotnet/runtime, in various ways. dotnet/runtime#66142, dotnet/runtime#66179 from ",
    "Finally, with all of these improvements to Regex , a multitude of PRs fixed up regexes being used across dotnet/runtime, in various ways. dotnet/runtime#66142, dotnet/runtime#66179 from ",
    "System.Collections hasn",
    "System.Collections hasn",
    "shows a measurable improvement in throughput between .NET 6 and .NET 7:",
    "shows a measurable improvement in throughput between .NET 6 and .NET 7:",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   |",
    "| Method   | Runtime   | Mean     |   Ratio | Code Size   |",
    "Beyond that, there have been explicit improvements elsewhere in collections. ImmutableArray",
    "Beyond that, there have been explicit improvements elsewhere in collections. ImmutableArray",
    "allocation, while also speeding up the sort itself by removing several layers of indirection from every comparison.",
    "allocation, while also speeding up the sort itself by removing several layers of indirection from every comparison.",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio |",
    "dotnet/runtime#61196 from ",
    "dotnet/runtime#61196 from ",
    "SortedSet",
    "SortedSet",
    "| Method        | Runtime   | Mean     |   Ratio |",
    "| Method        | Runtime   | Mean     |   Ratio |",
    "One last PR to look at in collections: dotnet/runtime#67923. ConditionalWeakTable",
    "One last PR to look at in collections: dotnet/runtime#67923. ConditionalWeakTable",
    "Let",
    "Let",
    "dotnet/runtime#64470 is the result of analyzing various real-world code bases for use of Enumerable.Min and Enumerable.Max , a nd seeing that it",
    "dotnet/runtime#64470 is the result of analyzing various real-world code bases for use of Enumerable.Min and Enumerable.Max , a nd seeing that it",
    "| Method   | Runtime   |   Length | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   |   Length | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "One of the more interesting aspects of the PR, however, is one line that",
    "One of the more interesting aspects of the PR, however, is one line that",
    "However, if you look at the PR, you",
    "However, if you look at the PR, you",
    "How come? Well at this point in the code flow, we know that source isn",
    "How come? Well at this point in the code flow, we know that source isn",
    "Console.WriteLine((object)new uint",
    "Console.WriteLine((object)new uint",
    "int",
    "int",
    "This results in:",
    "This results in:",
    "Note the former involves a method call to the JIT",
    "Note the former involves a method call to the JIT",
    "| Method        | Mean      |   Ratio | Code Size   |",
    "| Method        | Mean      |   Ratio | Code Size   |",
    "Of course, these two operations aren",
    "Of course, these two operations aren",
    "of the int",
    "of the int",
    "This improvement was built upon further in dotnet/runtime#64624, which expands the input types supported and the operations that take advantage. First, it introduced a private helper for extracting a ReadOnlySpan",
    "This improvement was built upon further in dotnet/runtime#64624, which expands the input types supported and the operations that take advantage. First, it introduced a private helper for extracting a ReadOnlySpan",
    "Expands the previous Min",
    "Expands the previous Min",
    "Uses direct span access for Average",
    "Uses direct span access for Average",
    "Similarly uses direct span access for Min",
    "Similarly uses direct span access for Min",
    "Vectorizes Average",
    "Vectorizes Average",
    "The effect of that is evident in microbenchmarks, e.g.",
    "The effect of that is evident in microbenchmarks, e.g.",
    "| Method   | Runtime   | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "The previous LINQ PRs were examples from making existing operations faster. But sometimes performance improvements come about from new APIs that can be used in place of previous ones in certain situations to further improve performance. One such example of that comes from new APIs introduced in dotnet/runtime#70525 from ",
    "The previous LINQ PRs were examples from making existing operations faster. But sometimes performance improvements come about from new APIs that can be used in place of previous ones in certain situations to further improve performance. One such example of that comes from new APIs introduced in dotnet/runtime#70525 from ",
    "| Method   |   Length | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   |   Length | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    ".NET 6 saw some huge file I/O improvements, in particular a complete rewrite of FileStream . While .NET 7 doesn",
    ".NET 6 saw some huge file I/O improvements, in particular a complete rewrite of FileStream . While .NET 7 doesn",
    "One form of performance improvement that also masquerades as a reliability improvement is increasing responsiveness to cancellation requests. The faster something can be canceled, the sooner the system is able to give back valuable resources in use, and the sooner things waiting for that operation to complete are able to be unblocked. There have been several improvements of this ilk in .NET 7.",
    "One form of performance improvement that also masquerades as a reliability improvement is increasing responsiveness to cancellation requests. The faster something can be canceled, the sooner the system is able to give back valuable resources in use, and the sooner things waiting for that operation to complete are able to be unblocked. There have been several improvements of this ilk in .NET 7.",
    "In some cases, it comes from adding cancelable overloads where things weren",
    "In some cases, it comes from adding cancelable overloads where things weren",
    "From my perspective, though, a more interesting form of this is when an existing overload is purportedly cancelable but isn",
    "From my perspective, though, a more interesting form of this is when an existing overload is purportedly cancelable but isn",
    "AnonymousPipeClientStream / AnonymousPipeServerStream and",
    "AnonymousPipeClientStream / AnonymousPipeServerStream and",
    "NamedPipeClientStream / NamedPipeServerStream . Also, on Windows, the OS makes a distinction between handles opened for synchronous I/O from handles opened for overlapped I/O (aka asynchronous I/O), and this is reflected in the .NET API: you can open a named pipe for synchronous or overlapped I/O based on the PipeOptions.Asynchronous option specified at construction. And, on",
    "NamedPipeClientStream / NamedPipeServerStream . Also, on Windows, the OS makes a distinction between handles opened for synchronous I/O from handles opened for overlapped I/O (aka asynchronous I/O), and this is reflected in the .NET API: you can open a named pipe for synchronous or overlapped I/O based on the PipeOptions.Asynchronous option specified at construction. And, on",
    "Unix, named pipes, contrary to their naming, are actually implemented on top of Unix domain sockets. Now some history:",
    "Unix, named pipes, contrary to their naming, are actually implemented on top of Unix domain sockets. Now some history:",
    ".NET Framework 4.8: No cancellation support. The pipe Stream -derived types didn",
    ".NET Framework 4.8: No cancellation support. The pipe Stream -derived types didn",
    ".NET Core 1.0: On Windows, with a named pipe opened for asynchronous I/O, cancellation was fully supported. The implementation would register with the CancellationToken , and upon a cancellation request, would use CancelIoEx for the NativeOverlapped",
    ".NET Core 1.0: On Windows, with a named pipe opened for asynchronous I/O, cancellation was fully supported. The implementation would register with the CancellationToken , and upon a cancellation request, would use CancelIoEx for the NativeOverlapped",
    ".NET Core 2.1: On Unix, the implementation was improved to avoid the polling loop, but it still lacked a truly cancelable Socket.ReceiveAsync / Socket.SendAsync . Instead, by this point Socket.ReceiveAsync supported zero-byte reads, where a caller could pass a zero-length buffer to ReceiveAsync and use that as notification for data being available to consume without actually consuming it. The Unix implementation for asynchronous named pipe streams then changed to issue zero-byte reads, and would await a Task.WhenAny of both that operation",
    ".NET Core 2.1: On Unix, the implementation was improved to avoid the polling loop, but it still lacked a truly cancelable Socket.ReceiveAsync / Socket.SendAsync . Instead, by this point Socket.ReceiveAsync supported zero-byte reads, where a caller could pass a zero-length buffer to ReceiveAsync and use that as notification for data being available to consume without actually consuming it. The Unix implementation for asynchronous named pipe streams then changed to issue zero-byte reads, and would await a Task.WhenAny of both that operation",
    ".NET Core 3.0: On Unix, Socket got truly cancelable ReceiveAsync and SendAsync methods, which asynchronous named pipes were updated to utilize. At this point, the Windows and Unix implementations were effectively on par with regards to cancellation; both good for asynchronous named pipes, and just posing for everything else.",
    ".NET Core 3.0: On Unix, Socket got truly cancelable ReceiveAsync and SendAsync methods, which asynchronous named pipes were updated to utilize. At this point, the Windows and Unix implementations were effectively on par with regards to cancellation; both good for asynchronous named pipes, and just posing for everything else.",
    ".NET 5: On Unix, SafeSocketHandle was exposed and it became possible to create a Socket for an arbitrary supplied SafeSocketHandle , which enabled creating a Socket that actually referred to an anonymous pipe. This in tern enabled every PipeStream on Unix to be implemented in terms of Socket , which enabled ReceiveAsync / SendAsync to be fully cancelable for both anonymous and named pipes, regardless of how they were opened.",
    ".NET 5: On Unix, SafeSocketHandle was exposed and it became possible to create a Socket for an arbitrary supplied SafeSocketHandle , which enabled creating a Socket that actually referred to an anonymous pipe. This in tern enabled every PipeStream on Unix to be implemented in terms of Socket , which enabled ReceiveAsync / SendAsync to be fully cancelable for both anonymous and named pipes, regardless of how they were opened.",
    "So by .NET 5, the problem was addressed on Unix, but still an issue on Windows. Until now. In .NET 7, we",
    "So by .NET 5, the problem was addressed on Unix, but still an issue on Windows. Until now. In .NET 7, we",
    "So, there",
    "So, there",
    "| Method         | Runtime   | Cancelable   | Named   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method         | Runtime   | Cancelable   | Named   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "The rest of the performance-focused changes around I/O in .NET 7 were primarily focused on one of two things: reducing syscalls, and reducing allocation.",
    "The rest of the performance-focused changes around I/O in .NET 7 were primarily focused on one of two things: reducing syscalls, and reducing allocation.",
    "Several PRs went into reducing syscalls on Unix as part of copying files, e.g. File.Copy and FileInfo.CopyTo . dotnet/runtime#59695 from ",
    "Several PRs went into reducing syscalls on Unix as part of copying files, e.g. File.Copy and FileInfo.CopyTo . dotnet/runtime#59695 from ",
    "some issues the function had in previous releases). Unlike a typical read/write loop that reads the data from the source and then writes it to the destination, copy",
    "some issues the function had in previous releases). Unlike a typical read/write loop that reads the data from the source and then writes it to the destination, copy",
    "Another example of avoiding syscalls comes for the File.WriteXx and File.AppendXx methods when on Unix. The implementation of these methods opens a FileStream or a SafeFileHandle directly, and it was specifying FileOptions.SequentialScan . SequentialScan is primarily relevant for reading data from a file, and hints to OS caching to expect data to be read from the file sequentially rather than randomly. However, these write/append methods don",
    "Another example of avoiding syscalls comes for the File.WriteXx and File.AppendXx methods when on Unix. The implementation of these methods opens a FileStream or a SafeFileHandle directly, and it was specifying FileOptions.SequentialScan . SequentialScan is primarily relevant for reading data from a file, and hints to OS caching to expect data to be read from the file sequentially rather than randomly. However, these write/append methods don",
    "Directory handling has seen reduced syscalls across the directory lifecycle, especially on Unix. dotnet/runtime#58799 from ",
    "Directory handling has seen reduced syscalls across the directory lifecycle, especially on Unix. dotnet/runtime#58799 from ",
    "dotnet/runtime#63675 then improves the performance of moving directories, on both Unix and Windows, removing several syscalls. The shared code for Directory.Move and DirectorInfo.MoveTo was doing explicit directory existence checks for the source and destination locations, but on Windows the Win32 API called to perform the move d oes such checks itself, so they",
    "dotnet/runtime#63675 then improves the performance of moving directories, on both Unix and Windows, removing several syscalls. The shared code for Directory.Move and DirectorInfo.MoveTo was doing explicit directory existence checks for the source and destination locations, but on Windows the Win32 API called to perform the move d oes such checks itself, so they",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "And then also on Unix, dotnet/runtime#59520 from ",
    "And then also on Unix, dotnet/runtime#59520 from ",
    "Syscalls were also reduced as part of support for memory-mapped files. dotnet/runtime#63754 takes advantage of special-casing to do so while opening a MemoryMappedFile . When MemoryMappedFile.CreateFromFile was called, one of the first things it would do is call File.Exists to determine w hether the specified file already exists; that",
    "Syscalls were also reduced as part of support for memory-mapped files. dotnet/runtime#63754 takes advantage of special-casing to do so while opening a MemoryMappedFile . When MemoryMappedFile.CreateFromFile was called, one of the first things it would do is call File.Exists to determine w hether the specified file already exists; that",
    "Finally, there",
    "Finally, there",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Beyond system calls, there have also been a plethora of improvements around reducing allocation. One such change is dotnet/runtime#58167, which improved the performance of the commonly-used File.WriteAllText{Async} and File.AppendAllText{Async} methods. The PR recognizes two things: one, that these operations are common enough that it",
    "Beyond system calls, there have also been a plethora of improvements around reducing allocation. One such change is dotnet/runtime#58167, which improved the performance of the commonly-used File.WriteAllText{Async} and File.AppendAllText{Async} methods. The PR recognizes two things: one, that these operations are common enough that it",
    "| Method       | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method       | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "dotnet/runtime#61519 similarly updates File.ReadAllBytes{Async} to use SafeFileHandle (and RandomAccess ) directly rather than going through FileStream , shaving off some allocation from each use. It also makes the same SequentialScan change as mentioned earlier. While this case is about reading (whereas the previous change saw SequentialScan being complete overhead with no benefit), ReadAllBytes{Async} is very frequently used to read smaller files where the overhead of the additional syscall can measure up to 10% of the total cost (and for larger files, modern kernels are pretty good about caching even without a sequentiality hint, so there",
    "dotnet/runtime#61519 similarly updates File.ReadAllBytes{Async} to use SafeFileHandle (and RandomAccess ) directly rather than going through FileStream , shaving off some allocation from each use. It also makes the same SequentialScan change as mentioned earlier. While this case is about reading (whereas the previous change saw SequentialScan being complete overhead with no benefit), ReadAllBytes{Async} is very frequently used to read smaller files where the overhead of the additional syscall can measure up to 10% of the total cost (and for larger files, modern kernels are pretty good about caching even without a sequentiality hint, so there",
    "Another such change is dotnet/runtime#68662, which improved Path.Join ",
    "Another such change is dotnet/runtime#68662, which improved Path.Join ",
    "Beyond that, there are a multitude of allocation-focused PRs, such as dotnet/runtime#69335 from ",
    "Beyond that, there are a multitude of allocation-focused PRs, such as dotnet/runtime#69335 from ",
    "But my personal favorite improvement in this area come from dotnet/runtime#69272, which adds a few new helpers to Stream :",
    "But my personal favorite improvement in this area come from dotnet/runtime#69272, which adds a few new helpers to Stream :",
    "In fairness, these are more about usability than they are about performance, but in this case there",
    "In fairness, these are more about usability than they are about performance, but in this case there",
    "that negatively impact performance, such as by using a Stream.ReadAsync overload that needs to allocate a returned Task",
    "that negatively impact performance, such as by using a Stream.ReadAsync overload that needs to allocate a returned Task",
    ".NET Core 2.1 added support for the Brotli compression algorithm, surfacing it in two ways: BrotliStream and the pair of BrotliEncoder / BrotliDecoder structs that BrotliStream is itself built on top of. For the most part, these types just provide wrappers around a native C implementation from google/brotli, and so while the .NET layer has the opportunity to improve how data is moved around, managed allocation, and so on, the speed and quality of the compression itself are largely at the mercy of the C implementation and the intricacies of the Brotli algorithm.",
    ".NET Core 2.1 added support for the Brotli compression algorithm, surfacing it in two ways: BrotliStream and the pair of BrotliEncoder / BrotliDecoder structs that BrotliStream is itself built on top of. For the most part, these types just provide wrappers around a native C implementation from google/brotli, and so while the .NET layer has the opportunity to improve how data is moved around, managed allocation, and so on, the speed and quality of the compression itself are largely at the mercy of the C implementation and the intricacies of the Brotli algorithm.",
    "As with many compression algorithms, Brotli provides a knob that allows for a quintessential tradeoff to be made between compression speed (how fast data can be compressed) and compression quality/ratio (how small can the compressed output be made). The hand-wavy idea is the more time the algorithm spends looking for opportunity, the more space can be saved. Many algorithms expose this as a numerical dial, in Brotli",
    "As with many compression algorithms, Brotli provides a knob that allows for a quintessential tradeoff to be made between compression speed (how fast data can be compressed) and compression quality/ratio (how small can the compressed output be made). The hand-wavy idea is the more time the algorithm spends looking for opportunity, the more space can be saved. Many algorithms expose this as a numerical dial, in Brotli",
    "For better or worse (and I",
    "For better or worse (and I",
    "Is that so bad? Maybe compression quality is the most important thing? For example, reducing the size of data can make it faster to then transmit it over a wire, and with a slow connection, size then meaningfully translates into end-to-end throughput.",
    "Is that so bad? Maybe compression quality is the most important thing? For example, reducing the size of data can make it faster to then transmit it over a wire, and with a slow connection, size then meaningfully translates into end-to-end throughput.",
    "The problem is just how much this extra effort costs. Compression speed and ratio are highly dependent on the data being compressed, so take this example with a small grain of salt as it",
    "The problem is just how much this extra effort costs. Compression speed and ratio are highly dependent on the data being compressed, so take this example with a small grain of salt as it",
    "uses BrotliEncoder to compress the The Complete Works of William Shakespeare from Project Gutenberg at varying levels of compression:",
    "uses BrotliEncoder to compress the The Complete Works of William Shakespeare from Project Gutenberg at varying levels of compression:",
    "3,000,000.00",
    "3,000,000.00",
    "2,000,000.00",
    "2,000,000.00",
    "1,500,000.00",
    "1,500,000.00",
    "1,000,000.00",
    "1,000,000.00",
    "500,000.00",
    "500,000.00",
    "0.00",
    "0.00",
    "}",
    "}",
    "}",
    "}",
    "O..",
    "O..",
    "The code is measuring how long it takes to compress the input data at each of the levels (doing a warmup and then averaging several iterations), timing how long it takes and capturing the resulting compressed data size. For the size, I get values like this:",
    "The code is measuring how long it takes to compress the input data at each of the levels (doing a warmup and then averaging several iterations), timing how long it takes and capturing the resulting compressed data size. For the size, I get values like this:",
    "|   Level | Size (bytes)   |",
    "|   Level | Size (bytes)   |",
    "4",
    "4",
    "6",
    "6",
    "8",
    "8",
    "10",
    "10",
    "12",
    "12",
    "That",
    "That",
    "Size (bytes)",
    "Size (bytes)",
    "000OI",
    "000OI",
    "0008",
    "0008",
    "0009",
    "0009",
    "000 \u2022",
    "000 \u2022",
    "000Z",
    "000Z",
    "|   Level | Time (ms)   |",
    "|   Level | Time (ms)   |",
    "OI",
    "OI",
    "-O......",
    "-O......",
    "8",
    "8",
    "This chart shows an almost exponential increase in processing time as we near the upper end of the dial, with quality level 11 compressing ~33% better than quality level 0 but taking ~440x as long to achieve that. If that",
    "This chart shows an almost exponential increase in processing time as we near the upper end of the dial, with quality level 11 compressing ~33% better than quality level 0 but taking ~440x as long to achieve that. If that",
    "dotnet/runtime#72266 fixes that. A very small change, it simply makes CompressMode.Compress and CompressionLevel.Optimal for Brotli map to quality level 4, which across many kinds of inputs does represent a fairly balanced trade-off between size and speed.",
    "dotnet/runtime#72266 fixes that. A very small change, it simply makes CompressMode.Compress and CompressionLevel.Optimal for Brotli map to quality level 4, which across many kinds of inputs does represent a fairly balanced trade-off between size and speed.",
    ") \u044d\u0448",
    ") \u044d\u0448",
    "........",
    "........",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "| Method   | Runtime   | Mean       |   Ratio |",
    "Other improvements have gone into compression, such as dotnet/runtime#69439 which updates the internal ZipHelper.AdvanceToPosition function used by ZipArchive to reuse a buffer on every iteration of a loop rather than allocating a new buffer for each iteration, dotnet/runtime#66764 which uses spans judiciously to avoid a bunch of superfluous string and string",
    "Other improvements have gone into compression, such as dotnet/runtime#69439 which updates the internal ZipHelper.AdvanceToPosition function used by ZipArchive to reuse a buffer on every iteration of a loop rather than allocating a new buffer for each iteration, dotnet/runtime#66764 which uses spans judiciously to avoid a bunch of superfluous string and string",
    "Networking is the life-blood of almost every service, with performance being critical to success. In previous releases, a lot of effort was focused on the lower layers of the networking stack, e.g. .NET 5 saw a significant investment in improving the performance of sockets on Linux. In .NET 7, much of the effort is above sockets.",
    "Networking is the life-blood of almost every service, with performance being critical to success. In previous releases, a lot of effort was focused on the lower layers of the networking stack, e.g. .NET 5 saw a significant investment in improving the performance of sockets on Linux. In .NET 7, much of the effort is above sockets.",
    "That said, there were some interesting performance improvements in sockets itself for .NET 7. One of the more interesting is dotnet/runtime#64770, which revamped how some synchronization is handled inside of SocketsAsyncEventArgs . As background, in the early days of networking in .NET Framework, asynchrony was enabled via Begin / End methods (the ",
    "That said, there were some interesting performance improvements in sockets itself for .NET 7. One of the more interesting is dotnet/runtime#64770, which revamped how some synchronization is handled inside of SocketsAsyncEventArgs . As background, in the early days of networking in .NET Framework, asynchrony was enabled via Begin / End methods (the ",
    "SocketAsyncEventArgs on Windows is implemented to use winsock and overlapped I/O. When you call an async method like ValueTask",
    "SocketAsyncEventArgs on Windows is implemented to use winsock and overlapped I/O. When you call an async method like ValueTask",
    "FILE",
    "FILE",
    "a potential race condition, where our code that",
    "a potential race condition, where our code that",
    "A more-easily quantifiable change around sockets is dotnet/runtime#71090, which improves the performance of SocketAddress.Equals . A SocketAddress is the serialized form of an EndPoint , with a byte",
    "A more-easily quantifiable change around sockets is dotnet/runtime#71090, which improves the performance of SocketAddress.Equals . A SocketAddress is the serialized form of an EndPoint , with a byte",
    "| Method      | Runtime   | Mean      |   Ratio |",
    "| Method      | Runtime   | Mean      |   Ratio |",
    "Let",
    "Let",
    "One of the more impactful changes to SslStream on .NET 7 is in support for TLS resumption on Linux. When a TLS connection is established, the client and server engage in a handshake protocol where they collaborate to decide on a TLS version and cipher suites to use, authenticate and validate each other",
    "One of the more impactful changes to SslStream on .NET 7 is in support for TLS resumption on Linux. When a TLS connection is established, the client and server engage in a handshake protocol where they collaborate to decide on a TLS version and cipher suites to use, authenticate and validate each other",
    "| Method    | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method    | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Another significant improvement for SslStream in .NET 7 is support for OCSP stapling. When a client handshakes with the server and the server shares its certificate, a client that cares about validating it",
    "Another significant improvement for SslStream in .NET 7 is support for OCSP stapling. When a client handshakes with the server and the server shares its certificate, a client that cares about validating it",
    "the OCSP responder, the server itself contacts the OCSP responder and gets a signed ticket from the OCSP responder stating that the server",
    "the OCSP responder, the server itself contacts the OCSP responder and gets a signed ticket from the OCSP responder stating that the server",
    "The aforementioned changes are primarily about the performance of opening a connection. Additional work has been done to improve that further in other ways. dotnet/runtime#69527 gets rid of allocations associated with several SafeHandle instances that were being created unnecessarily on Linux as part of establishing a TLS connection. This highlights the benefits of doing profiling on multiple platforms, as while these SafeHandle s were necessary in the Windows implementation, they were fairly meaningless in the Linux implementation (due to differences between SChannel and OpenSSL), and were only brought along for the ride because of how the platform-abstraction layer (PAL) was defined to reuse most of the SslStream code across platforms. And dotnet/runtime#68188 avoids several collections allocated as part of the TLS handshake. This one is particularly interesting as it",
    "The aforementioned changes are primarily about the performance of opening a connection. Additional work has been done to improve that further in other ways. dotnet/runtime#69527 gets rid of allocations associated with several SafeHandle instances that were being created unnecessarily on Linux as part of establishing a TLS connection. This highlights the benefits of doing profiling on multiple platforms, as while these SafeHandle s were necessary in the Windows implementation, they were fairly meaningless in the Linux implementation (due to differences between SChannel and OpenSSL), and were only brought along for the ride because of how the platform-abstraction layer (PAL) was defined to reuse most of the SslStream code across platforms. And dotnet/runtime#68188 avoids several collections allocated as part of the TLS handshake. This one is particularly interesting as it",
    "And then some code in the same implementation comes along and wants to read the contents of these items. That code might look like:",
    "And then some code in the same implementation comes along and wants to read the contents of these items. That code might look like:",
    "but the very act of accessing Items just to check its count forces the collection into existence (with a 0 Count ). If the code instead checks:",
    "but the very act of accessing Items just to check its count forces the collection into existence (with a 0 Count ). If the code instead checks:",
    "It can save that unnecessary collection allocation. The approach is made even simpler with C# pattern matching:",
    "It can save that unnecessary collection allocation. The approach is made even simpler with C# pattern matching:",
    "This is one of those things that",
    "This is one of those things that",
    "dotnet/runtime#69098 is another good example of how profiling can lead to insights about allocations that can be removed. Application-Layer Protocol Negotation (ALPN) allows code establishing a TLS connection to piggy-back on the roundtrips that are being used for the TLS handshake anyway to negotiate some higher-level protocol that will end up being used as well. A very common use-case, for example, is for an HTTPS client/server to negotiate which version of HTTP should be used. This information is exposed from SslStream as an SslApplicationProtocol struct returned from its NegotiatedApplicationProtocol property, but as the actual negotiated protocol can be arbitrary data, SslApplicationProtocol just wraps a byte",
    "dotnet/runtime#69098 is another good example of how profiling can lead to insights about allocations that can be removed. Application-Layer Protocol Negotation (ALPN) allows code establishing a TLS connection to piggy-back on the roundtrips that are being used for the TLS handshake anyway to negotiate some higher-level protocol that will end up being used as well. A very common use-case, for example, is for an HTTPS client/server to negotiate which version of HTTP should be used. This information is exposed from SslStream as an SslApplicationProtocol struct returned from its NegotiatedApplicationProtocol property, but as the actual negotiated protocol can be arbitrary data, SslApplicationProtocol just wraps a byte",
    "dutifully allocating a byte",
    "dutifully allocating a byte",
    "MemoryMarshal.TryGetArray method), and once you",
    "MemoryMarshal.TryGetArray method), and once you",
    "Everything discussed thus far was about establishing connections. What about the performance of reading and writing on that connection? Improvements have been made there, too, in particular around memory management and asynchrony. But first we need some context.",
    "Everything discussed thus far was about establishing connections. What about the performance of reading and writing on that connection? Improvements have been made there, too, in particular around memory management and asynchrony. But first we need some context.",
    "When async/await were first introduced, Task and Task",
    "When async/await were first introduced, Task and Task",
    "them. ValueTask",
    "them. ValueTask",
    "IValueTaskSource",
    "IValueTaskSource",
    "PoolingAsyncValueTaskMethodBuilder and PoolingAsyncValueTaskMethodBuilder",
    "PoolingAsyncValueTaskMethodBuilder and PoolingAsyncValueTaskMethodBuilder",
    "can be changed to be:",
    "can be changed to be:",
    "which will cause the C# compiler to emit the implementation of this method using PoolingAsyncValueTaskMethodBuilder",
    "which will cause the C# compiler to emit the implementation of this method using PoolingAsyncValueTaskMethodBuilder",
    "PoolingAsyncValueTaskMethodBuilder",
    "PoolingAsyncValueTaskMethodBuilder",
    "tradeoffs involved in its usage, and while it can make microbenchmarks look really good, it can also negatively impact real-world usage, e.g. by increasing the cost of garbage collections that do occur by increasing the number of Gen2 to Gen0 references that exist. As such, while the functionality is valuable, we",
    "tradeoffs involved in its usage, and while it can make microbenchmarks look really good, it can also negatively impact real-world usage, e.g. by increasing the cost of garbage collections that do occur by increasing the number of Gen2 to Gen0 references that exist. As such, while the functionality is valuable, we",
    "Such is the case with SslStream . With dotnet/runtime#69418, two core and hot async methods on SslStream ",
    "Such is the case with SslStream . With dotnet/runtime#69418, two core and hot async methods on SslStream ",
    "| Method         | Runtime   | Mean     |   Ratio | Code Size   | Allocated   |   Alloc Ratio |",
    "| Method         | Runtime   | Mean     |   Ratio | Code Size   | Allocated   |   Alloc Ratio |",
    "One final change related to reading and writing performance on an SslStream . I find this one particularly interesting, as it highlights a new and powerful C# 11 and .NET 7 feature: static abstract members in interfaces. SslStream , as with every Stream , exposes both synchronous and asynchronous methods for reading and writing. And as you may be aware, the code within SslStream for implementing reads and writes is not particularly small. Thus, we really want to avoid having to duplicate all of the code paths, once for synchronous work and once for asynchronous work, when in reality the only place that bifurcation is needed is at the leaves where calls into the underlying Stream are made to perform the actual I/O. Historically, we",
    "One final change related to reading and writing performance on an SslStream . I find this one particularly interesting, as it highlights a new and powerful C# 11 and .NET 7 feature: static abstract members in interfaces. SslStream , as with every Stream , exposes both synchronous and asynchronous methods for reading and writing. And as you may be aware, the code within SslStream for implementing reads and writes is not particularly small. Thus, we really want to avoid having to duplicate all of the code paths, once for synchronous work and once for asynchronous work, when in reality the only place that bifurcation is needed is at the leaves where calls into the underlying Stream are made to perform the actual I/O. Historically, we",
    "This way most of the logic and code is shared, and when useAsync is false, everything completes synchronously and so we don",
    "This way most of the logic and code is shared, and when useAsync is false, everything completes synchronously and so we don",
    "We can then declare two implementations of this interface:",
    "We can then declare two implementations of this interface:",
    "Then we can redeclare our earlier example as:",
    "Then we can redeclare our earlier example as:",
    "Note that the generic constraint on the TReader parameter here allows the implementation to invoke the interface methods, and passing the structs as a generic avoids boxing. One code path supporting both sync and async implementations.",
    "Note that the generic constraint on the TReader parameter here allows the implementation to invoke the interface methods, and passing the structs as a generic avoids boxing. One code path supporting both sync and async implementations.",
    "This latter generic approach is how SslStream has historically handled the unification of its sync and async implementations. It gets better in .NET 7 with C# 11 now that we have static abstract methods in interfaces. We can instead declare our interface as (note the static abstract addition):",
    "This latter generic approach is how SslStream has historically handled the unification of its sync and async implementations. It gets better in .NET 7 with C# 11 now that we have static abstract methods in interfaces. We can instead declare our interface as (note the static abstract addition):",
    "our types as (note the static addition):",
    "our types as (note the static addition):",
    "and our consuming methods as (note the removal of the parameter and the switch to calling static methods on the type parameter):",
    "and our consuming methods as (note the removal of the parameter and the switch to calling static methods on the type parameter):",
    "Not only is this cleaner, but from a performance perspective we no longer need to pass around the dummy generic parameter, which is general goodness, but for an async method it",
    "Not only is this cleaner, but from a performance perspective we no longer need to pass around the dummy generic parameter, which is general goodness, but for an async method it",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "| Method         | Runtime   | Mean     |   Ratio |",
    "Let",
    "Let",
    "One aspect of HttpClient that cuts across all versions of HTTP is support for handling and representing headers. While significant improvements went into previous releases to trim down the size of the data structures used to store header information, further work on this front was done for .NET 7. dotnet/runtime#62981, for example, improves the data structure used to store headers. One of the things HttpHeaders needs to deal with is that there",
    "One aspect of HttpClient that cuts across all versions of HTTP is support for handling and representing headers. While significant improvements went into previous releases to trim down the size of the data structures used to store header information, further work on this front was done for .NET 7. dotnet/runtime#62981, for example, improves the data structure used to store headers. One of the things HttpHeaders needs to deal with is that there",
    "Another header-related size reduction comes in dotnet/runtime#64105. The internal representation of headers involves a HeaderDescriptor that enables ",
    "Another header-related size reduction comes in dotnet/runtime#64105. The internal representation of headers involves a HeaderDescriptor that enables ",
    "need to look up information from that field, we cut the number of fields in half. And while this HeaderDescriptor is it self a struct, it",
    "need to look up information from that field, we cut the number of fields in half. And while this HeaderDescriptor is it self a struct, it",
    "| Method     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Similarly focused on allocation, dotnet/runtime#63057 removes two fields from the HttpHeaderValueCollection",
    "Similarly focused on allocation, dotnet/runtime#63057 removes two fields from the HttpHeaderValueCollection",
    "HttpRequestHeaders.UserAgent , and HttpResponseHeaders.Server . The initial design and implementation of this type were overly flexible, with a mechanism for custom validation of values, which entailed multiple fields for storing things like an Action",
    "HttpRequestHeaders.UserAgent , and HttpResponseHeaders.Server . The initial design and implementation of this type were overly flexible, with a mechanism for custom validation of values, which entailed multiple fields for storing things like an Action",
    "A more focused allocation reduction comes in dotnet/runtime#63641. The shared internal utility method HttpRuleParser.GetHostLength was using string.Substring in order to hand back the parsed host information, but only some of the callers needed this. Rather than making everyone pay for something that not everyone needed, this logic was moved into only the call sites that needed it.",
    "A more focused allocation reduction comes in dotnet/runtime#63641. The shared internal utility method HttpRuleParser.GetHostLength was using string.Substring in order to hand back the parsed host information, but only some of the callers needed this. Rather than making everyone pay for something that not everyone needed, this logic was moved into only the call sites that needed it.",
    "Other small allocation improvements were also made outside of headers. For example, when new HTTP/1 and HTTP/2 connections are created, the implementation queues a work item to the thread pool to handle the actual creation, primarily to escape locks that might be held higher in the call stack. To do so, it used Task.Run . And while normally Task.Run is a fine thing to use, in this case there were two issues: the resulting Task was being ignored, such that any unexpected exceptions would just be eaten, and the lambda being passed to Task.Run was closing over this and a local, which means the C# compiler will have generated code to allocate both a ",
    "Other small allocation improvements were also made outside of headers. For example, when new HTTP/1 and HTTP/2 connections are created, the implementation queues a work item to the thread pool to handle the actual creation, primarily to escape locks that might be held higher in the call stack. To do so, it used Task.Run . And while normally Task.Run is a fine thing to use, in this case there were two issues: the resulting Task was being ignored, such that any unexpected exceptions would just be eaten, and the lambda being passed to Task.Run was closing over this and a local, which means the C# compiler will have generated code to allocate both a ",
    "Folks using HTTP often need to go through a proxy server, and in .NET the ability to go through an HTTP proxy is represented via the IWebProxy interface; it has three members, GetProxy for getting the Uri of the proxy to use for a given destination Uri , the IsBypassed method which says whether a given Uri should go through a proxy or not, and then a Credentials property to be used when accessing the target proxy. The canonical implementation of IWebProxy provided in the core libraries is the aptly named WebProxy . WebProxy is fairly simple: you give it a proxy Uri , and then calls to GetProxy return that proxy Uri if the destination isn",
    "Folks using HTTP often need to go through a proxy server, and in .NET the ability to go through an HTTP proxy is represented via the IWebProxy interface; it has three members, GetProxy for getting the Uri of the proxy to use for a given destination Uri , the IsBypassed method which says whether a given Uri should go through a proxy or not, and then a Credentials property to be used when accessing the target proxy. The canonical implementation of IWebProxy provided in the core libraries is the aptly named WebProxy . WebProxy is fairly simple: you give it a proxy Uri , and then calls to GetProxy return that proxy Uri if the destination isn",
    null,
    null,
    "| Method     | Runtime   | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method     | Runtime   | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "Also related to HTTP, WebUtility ",
    "Also related to HTTP, WebUtility ",
    "IndexOfAny in HttpListener ",
    "IndexOfAny in HttpListener ",
    "| Method     | Runtime   | Mean      |   Ratio |",
    "| Method     | Runtime   | Mean      |   Ratio |",
    "There have been a myriad of other performance-related improvements in networking as well, such as dotnet/runtime#67881 which removed the use of TcpClient from FtpWebRequest ; dotnet/runtime#68745 in WebSocket which removed a parameter from one of the core async methods (and since parameters end up on the state machine, if the async method yields this results in fewer allocated bytes); and dotnet/runtime#70866 and dotnet/runtime#70900, which replaced all remaining use of Marshal.PtrToStructure in the core networking code with more efficient marshaling (e.g. just performing casts). While Marshal.PtrToStructure is valuable when custom marshaling directives are used and the runtime needs to be involved in the conversion, it",
    "There have been a myriad of other performance-related improvements in networking as well, such as dotnet/runtime#67881 which removed the use of TcpClient from FtpWebRequest ; dotnet/runtime#68745 in WebSocket which removed a parameter from one of the core async methods (and since parameters end up on the state machine, if the async method yields this results in fewer allocated bytes); and dotnet/runtime#70866 and dotnet/runtime#70900, which replaced all remaining use of Marshal.PtrToStructure in the core networking code with more efficient marshaling (e.g. just performing casts). While Marshal.PtrToStructure is valuable when custom marshaling directives are used and the runtime needs to be involved in the conversion, it",
    "| Method         | Mean       |   Ratio |",
    "| Method         | Mean       |   Ratio |",
    "For folks using NegotiateStream , dotnet/runtime#71280 from",
    "For folks using NegotiateStream , dotnet/runtime#71280 from",
    null,
    null,
    "| Method    | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method    | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "System.Text.Json was introduced in .NET Core 3.0, and has seen a significant amount of investment in each release since. .NET 7 is no exception. New features in .NET 7 include support for customizing contracts, polymorphic serialization, support for required members, support for DateOnly / TimeOnly, support for IAsyncEnumerable",
    "System.Text.Json was introduced in .NET Core 3.0, and has seen a significant amount of investment in each release since. .NET 7 is no exception. New features in .NET 7 include support for customizing contracts, polymorphic serialization, support for required members, support for DateOnly / TimeOnly, support for IAsyncEnumerable",
    "One of the biggest performance pitfalls we",
    "One of the biggest performance pitfalls we",
    "| Method          | Runtime   | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method          | Runtime   | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "In .NET 7, this was fixed in dotnet/runtime#64646 (and subsequently tweaked in dotnet/runtime#66248) by adding a global cache of the type information separate from the options instances. A JsonSerializerOptions still has a cache, but when new handlers are generated via reflection emit, those are also cached at the global level (with appropriate removal when no longer used in order to avoid unbounded leaks).",
    "In .NET 7, this was fixed in dotnet/runtime#64646 (and subsequently tweaked in dotnet/runtime#66248) by adding a global cache of the type information separate from the options instances. A JsonSerializerOptions still has a cache, but when new handlers are generated via reflection emit, those are also cached at the global level (with appropriate removal when no longer used in order to avoid unbounded leaks).",
    "| Method          | Runtime   | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method          | Runtime   | Mean         |   Ratio | Allocated   |   Alloc Ratio |",
    "As can be seen here, it",
    "As can be seen here, it",
    "Another change to JsonSerializer came in dotnet/runtime#72510, which slightly improved the performance of serialization when using the source generator. The source generator emits helpers for performing the serialization/deserialization work, and these are then invoked by JsonSerializer via delegates (as part of abstracting away all the different implementation strategies for how to get and set members on the types being serialized and deserialized). Previously, these helpers were being emitted as static methods, which in turn meant that the delegates were being created to static methods. Delegates to instance methods are a bit faster to invoke than delegates to static methods, so this PR made a simple few-line change for the source generator to emit these as instance methods instead.",
    "Another change to JsonSerializer came in dotnet/runtime#72510, which slightly improved the performance of serialization when using the source generator. The source generator emits helpers for performing the serialization/deserialization work, and these are then invoked by JsonSerializer via delegates (as part of abstracting away all the different implementation strategies for how to get and set members on the types being serialized and deserialized). Previously, these helpers were being emitted as static methods, which in turn meant that the delegates were being created to static methods. Delegates to instance methods are a bit faster to invoke than delegates to static methods, so this PR made a simple few-line change for the source generator to emit these as instance methods instead.",
    "Yet another for JsonSerializer comes in dotnet/runtime#73338, which improves allocation with how it utilizes Utf8JsonWriter . Utf8JsonWriter is a class, and every time JsonSerializer would write out JSON, it would allocate a new Utf8JsonWriter instance. In turn, Utf8JsonWriter needs something to write to, and although the serializer was using an IBufferWriter implementation that pooled the underlying byte",
    "Yet another for JsonSerializer comes in dotnet/runtime#73338, which improves allocation with how it utilizes Utf8JsonWriter . Utf8JsonWriter is a class, and every time JsonSerializer would write out JSON, it would allocate a new Utf8JsonWriter instance. In turn, Utf8JsonWriter needs something to write to, and although the serializer was using an IBufferWriter implementation that pooled the underlying byte",
    "Serialize operation, it then ensures the current thread has a Utf8JsonWriter and IBufferWriter instance it can use, and uses them; for the most part this is straightforward, but it needs to ensure that the serialization operation itself doesn",
    "Serialize operation, it then ensures the current thread has a Utf8JsonWriter and IBufferWriter instance it can use, and uses them; for the most part this is straightforward, but it needs to ensure that the serialization operation itself doesn",
    "| Method            | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method            | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Utf8JsonWriter and Utf8JsonReader also saw several improvements directly. dotnet/runtime#69580 adds a few new performance-focused members, the ValueIsEscaped property (which exposes already tracked information and enables consumers to avoid the expense of re-checking) and the CopyString method (which provides a non-allocating mechanism to get access to a string value from the reader). It then also uses the added support internally to speed up certain operations on Utf8JsonReader . And dotnet/runtime#63863, dotnet/runtime#71534, and dotnet/runtime#61746 fix how some exception checks and throws were being handled so as to not slow down the non-exceptional fast paths.",
    "Utf8JsonWriter and Utf8JsonReader also saw several improvements directly. dotnet/runtime#69580 adds a few new performance-focused members, the ValueIsEscaped property (which exposes already tracked information and enables consumers to avoid the expense of re-checking) and the CopyString method (which provides a non-allocating mechanism to get access to a string value from the reader). It then also uses the added support internally to speed up certain operations on Utf8JsonReader . And dotnet/runtime#63863, dotnet/runtime#71534, and dotnet/runtime#61746 fix how some exception checks and throws were being handled so as to not slow down the non-exceptional fast paths.",
    "System.Xml is used by a huge number of applications and services, but ever since JSON hit the scene and has been all the rage, XML has taken a back seat and thus hasn",
    "System.Xml is used by a huge number of applications and services, but ever since JSON hit the scene and has been all the rage, XML has taken a back seat and thus hasn",
    "Sometimes a performance fix is as easy as changing a single number. That",
    "Sometimes a performance fix is as easy as changing a single number. That",
    "| Method              | Runtime   |   ItemCount | Mean           |   Ratio | Allocated    |   Alloc Ratio |",
    "| Method              | Runtime   |   ItemCount | Mean           |   Ratio | Allocated    |   Alloc Ratio |",
    "XmlReader and XmlWriter saw other allocation-related improvements as well. dotnet/runtime#60076 from ",
    "XmlReader and XmlWriter saw other allocation-related improvements as well. dotnet/runtime#60076 from ",
    "where ",
    "where ",
    "which while shorter is also more efficient, avoiding the intermediate string allocations, as the custom interpolated string handler used by string.Create will format those into a pooled buffer rather than allocating intermediate temporaries.",
    "which while shorter is also more efficient, avoiding the intermediate string allocations, as the custom interpolated string handler used by string.Create will format those into a pooled buffer rather than allocating intermediate temporaries.",
    "XmlSerializer is also quite popular and also gets a (small) allocation reduction, in particular for deserialization. XmlSerializer has two modes for generating serialization/deserialization routines: using reflection emit to dynamically generate IL at run-time that are tuned to the specific shape of the types being serialized/deserialized, and the XML Serializer Generator Tool (sgen), which generates a .dll containing the same support, just ahead-of-time (a sort-of precursor to the Roslyn source",
    "XmlSerializer is also quite popular and also gets a (small) allocation reduction, in particular for deserialization. XmlSerializer has two modes for generating serialization/deserialization routines: using reflection emit to dynamically generate IL at run-time that are tuned to the specific shape of the types being serialized/deserialized, and the XML Serializer Generator Tool (sgen), which generates a .dll containing the same support, just ahead-of-time (a sort-of precursor to the Roslyn source",
    "generators we love today). In both cases, when deserializing, the generated code wants to track which properties of the object being deserialized have already been set, and to do that, it uses a bool",
    "generators we love today). In both cases, when deserializing, the generated code wants to track which properties of the object being deserialized have already been set, and to do that, it uses a bool",
    "Here",
    "Here",
    "Allocations Call Tree Functions Collections",
    "Allocations Call Tree Functions Collections",
    "Type",
    "Type",
    "System.Xml. NameTable.Entry",
    "System.Xml. NameTable.Entry",
    "Type",
    "Type",
    "System.String",
    "System.String",
    "Release",
    "Release",
    "System String",
    "System String",
    "Release",
    "Release",
    "Allocations -",
    "Allocations -",
    "33,000",
    "33,000",
    "| System.Boolean",
    "| System.Boolean",
    "We",
    "We",
    "Other allocation reduction went into the creation of the serializer/deserializer itself, such as with dotnet/runtime#68738 dotnet/runtime#66915 using stack allocation for building up small text instead of using a StringBuilder , dotnet/runtime#66797 avoiding delegate and closure allocations in accessing the avoiding allocating strings to escape text that didn",
    "Other allocation reduction went into the creation of the serializer/deserializer itself, such as with dotnet/runtime#68738 dotnet/runtime#66915 using stack allocation for building up small text instead of using a StringBuilder , dotnet/runtime#66797 avoiding delegate and closure allocations in accessing the avoiding allocating strings to escape text that didn",
    null,
    null,
    "For folks using XML schema, dotnet/runtime#66908 replaces some Hashtable s in the implementation where those collections were storing int s as the value. Given that Hashtable is a non-generic collection, every one of those int s was getting boxed, resulting in unnecessary allocation overhead; these were fixed by replacing these Hashtable s with Dictionary",
    "For folks using XML schema, dotnet/runtime#66908 replaces some Hashtable s in the implementation where those collections were storing int s as the value. Given that Hashtable is a non-generic collection, every one of those int s was getting boxed, resulting in unnecessary allocation overhead; these were fixed by replacing these Hashtable s with Dictionary",
    null,
    null,
    "avoid temporary string allocation in the implementation of the internal XsdDateTime and XsdDuration types, which are used by the public XmlConvert .",
    "avoid temporary string allocation in the implementation of the internal XsdDateTime and XsdDuration types, which are used by the public XmlConvert .",
    "| Method             | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method             | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "XML pops up in other areas as well, as in the XmlWriterTraceListener type. While the System.Diagnostics.Trace type isn",
    "XML pops up in other areas as well, as in the XmlWriterTraceListener type. While the System.Diagnostics.Trace type isn",
    "| Method     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "\u2022 System.Security.Cryptography.Algorithms.dIl",
    "\u2022 System.Security.Cryptography.Algorithms.dIl",
    "\u2022 System.Security.Cryptography.Cng.dll",
    "\u2022 System.Security.Cryptography.Cng.dll",
    "System.Security. Cryptography.Csp.dil",
    "System.Security. Cryptography.Csp.dil",
    "System.Security. Cryptography.OpenSsl.dil",
    "System.Security. Cryptography.OpenSsl.dil",
    "787 KB",
    "787 KB",
    "475 KB",
    "475 KB",
    "186 KB",
    "186 KB",
    "92 KB",
    "92 KB",
    "32 KB",
    "32 KB",
    "Some fairly significant new features came to System.Security.Cryptography in .NET 7, including the support necessary to enable the previously discussed OCSP stapling and support for building certificate revocation lists, but there was also a fair amount of effort put into making existing support faster and more lightweight. 476 KB",
    "Some fairly significant new features came to System.Security.Cryptography in .NET 7, including the support necessary to enable the previously discussed OCSP stapling and support for building certificate revocation lists, but there was also a fair amount of effort put into making existing support faster and more lightweight. 476 KB",
    "One fairly substantial change in .NET 7 is split across dotnet/runtime#61025, dotnet/runtime#61137, and dotnet/runtime#64307 . These PRs don",
    "One fairly substantial change in .NET 7 is split across dotnet/runtime#61025, dotnet/runtime#61137, and dotnet/runtime#64307 . These PRs don",
    "System.Security.Cryptography assembly. When .NET Core was first envisioned, a goal was to make it extremely modular, and large swaths of code were teased apart to create many smaller assemblies. For example, cryptographic functionality was split between",
    "System.Security.Cryptography assembly. When .NET Core was first envisioned, a goal was to make it extremely modular, and large swaths of code were teased apart to create many smaller assemblies. For example, cryptographic functionality was split between",
    "System.Security.Cryptography.Algorithms.dll , System.Security.Cryptography.Cng.dll , System.Security.Cryptography.Csp.dll , System.Security.Cryptography.Encoding.dll , System.Security.Cryptography.OpenSsl.dll , System.Security.Cryptography.Primitives.dll , and System.Security.Cryptography.X509Certificates.dll . You can see this if you look in your shared framework folder for a previous release, e.g. here",
    "System.Security.Cryptography.Algorithms.dll , System.Security.Cryptography.Cng.dll , System.Security.Cryptography.Csp.dll , System.Security.Cryptography.Encoding.dll , System.Security.Cryptography.OpenSsl.dll , System.Security.Cryptography.Primitives.dll , and System.Security.Cryptography.X509Certificates.dll . You can see this if you look in your shared framework folder for a previous release, e.g. here",
    "These PRs move all of that code into a single System.Security.Cryptography.dll assembly. This has several benefits. First, crypto is used in a huge number of applications, and most apps would end up",
    "These PRs move all of that code into a single System.Security.Cryptography.dll assembly. This has several benefits. First, crypto is used in a huge number of applications, and most apps would end up",
    "System.Security. Cryptography.Algorithms.dil tal System.Security.Cryptography.Cng.dIl",
    "System.Security. Cryptography.Algorithms.dil tal System.Security.Cryptography.Cng.dIl",
    "7 KB",
    "7 KB",
    "6 KB",
    "6 KB",
    "requiring multiple (or even most) of these assemblies . Every assembly that",
    "requiring multiple (or even most) of these assemblies . Every assembly that",
    "a System.Security.Cryptography.Encoding.dll a System.Security. Cryptography.Primitives.dIl",
    "a System.Security.Cryptography.Encoding.dll a System.Security. Cryptography.Primitives.dIl",
    "| System.Security.Cryptography.OpenSsl.dll             |",
    "| System.Security.Cryptography.OpenSsl.dll             |",
    "Interesting, you still see a bunch of assemblies there, but all except for",
    "Interesting, you still see a bunch of assemblies there, but all except for",
    "System.Security.Cryptography.dll are tiny; that",
    "System.Security.Cryptography.dll are tiny; that",
    "Assemblies :",
    "Assemblies :",
    "4",
    "4",
    "*",
    "*",
    "..: Metadata",
    "..: Metadata",
    "*",
    "*",
    "\u2022\u2022 System.Runtime",
    "\u2022\u2022 System.Runtime",
    "\u2022\u2022\u2022 System.Security. Cryptography",
    "\u2022\u2022\u2022 System.Security. Cryptography",
    "= {} -",
    "= {} -",
    "\u00abModule \u203a",
    "\u00abModule \u203a",
    "\u2022 Derived Types",
    "\u2022 Derived Types",
    "System.Security.Cryptography.Primitives (7.0.0.0, NETCoreApp, v7.0)",
    "System.Security.Cryptography.Primitives (7.0.0.0, NETCoreApp, v7.0)",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "[",
    "In addition to the startup and maintenance wins this provides, this has also enabled further subsequent optimization. For example, there",
    "In addition to the startup and maintenance wins this provides, this has also enabled further subsequent optimization. For example, there",
    "In terms of actual code improvements, there are many. One category of improvements is around ",
    "In terms of actual code improvements, there are many. One category of improvements is around ",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "In addition to making one-shots lighterweight, other PRs have then used these one-shot operations in more places in order to simplify their code and benefit from the increased performance, e.g. dotnet/runtime#70639 from ",
    "In addition to making one-shots lighterweight, other PRs have then used these one-shot operations in more places in order to simplify their code and benefit from the increased performance, e.g. dotnet/runtime#70639 from ",
    "There",
    "There",
    "Stack allocation . As has been seen in many other PRs referenced throughout this post, using stackalloc is a very effective way to get rid o f array allocations in many situations. It",
    "Stack allocation . As has been seen in many other PRs referenced throughout this post, using stackalloc is a very effective way to get rid o f array allocations in many situations. It",
    "Avoiding double copies . Most of the crypto APIs that accept byte",
    "Avoiding double copies . Most of the crypto APIs that accept byte",
    "Rfc2898DeriveBytes to supports spans such that its constructors that accept spans can then do the more efficient thing.",
    "Rfc2898DeriveBytes to supports spans such that its constructors that accept spans can then do the more efficient thing.",
    "Replacing O(1) data structures . O(1) lookup data structures like Dictionary",
    "Replacing O(1) data structures . O(1) lookup data structures like Dictionary",
    "Simply avoiding unnecessary work . The best optimizations are ones where you simply stop doing work you don",
    "Simply avoiding unnecessary work . The best optimizations are ones where you simply stop doing work you don",
    "your dependencies. The implementation of symmetric encryption on macOS uses the CommonCrypto library. One of the functions it exposes is CCCryptorFinal end of the encryption/decryption process. However, there are several cases called out in the even in those situations is wasteful. The fix? Stop doing unnecessary work.",
    "your dependencies. The implementation of symmetric encryption on macOS uses the CommonCrypto library. One of the functions it exposes is CCCryptorFinal end of the encryption/decryption process. However, there are several cases called out in the even in those situations is wasteful. The fix? Stop doing unnecessary work.",
    "New APIs . A bunch of new APIs were introduced for cryptography in .NET 7. Most are focused on easing scenarios that were difficult to do correctly before, like dotnet/runtime#66509 from ",
    "New APIs . A bunch of new APIs were introduced for cryptography in .NET 7. Most are focused on easing scenarios that were difficult to do correctly before, like dotnet/runtime#66509 from ",
    "Let",
    "Let",
    "The Process class is used for a variety of purposes, including querying information about running processes, interacting with other processes (e.g. being notified of their exiting), and launching processes. The performance of querying for information in particular had some notable improvements in .NET 7. Process provides several APIs for querying for process information, one of the most common being Process.GetProcessesByName : apps that know the name of the process they",
    "The Process class is used for a variety of purposes, including querying information about running processes, interacting with other processes (e.g. being notified of their exiting), and launching processes. The performance of querying for information in particular had some notable improvements in .NET 7. Process provides several APIs for querying for process information, one of the most common being Process.GetProcessesByName : apps that know the name of the process they",
    "| Method             | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method             | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Accessing various pieces of information from a Process has also improved. If you load a Process object via the Process.GetProcesses or Process.GetProcessesByName methods, by design they load all information about the Process being retrieved; internally their state will be populated such that subsequent accesses to members of the Process instance will be very fast. But, if you access a Process via Process.GetProcessById or Process.GetCurrentProcess (which is effectively GetProcessById for the current process",
    "Accessing various pieces of information from a Process has also improved. If you load a Process object via the Process.GetProcesses or Process.GetProcessesByName methods, by design they load all information about the Process being retrieved; internally their state will be populated such that subsequent accesses to members of the Process instance will be very fast. But, if you access a Process via Process.GetProcessById or Process.GetCurrentProcess (which is effectively GetProcessById for the current process",
    "process",
    "process",
    "| Method                             | Runtime   | Mean        |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method                             | Runtime   | Mean        |   Ratio | Allocated   |   Alloc Ratio |",
    "Interestingly, this PR had a small deficiency we didn",
    "Interestingly, this PR had a small deficiency we didn",
    "Several additional PRs helped out the Process class. When launching processes with Process.Start on Unix, the implementation was using Encoding.UTF8.GetBytes as part of argument handling, resulting in a temporary array being allocated per argument; dotnet/runtime#71279 removes that per-argument allocation, instead using Encoding.UTF8.GetByteCount to determine how large a space is needed and then using the Encoding.UTF8.GetBytes overload that accepts a span to encode directly into the native memory already being allocated. dotnet/runtime#71136 simplifies and streamlines the code involved in getting the ",
    "Several additional PRs helped out the Process class. When launching processes with Process.Start on Unix, the implementation was using Encoding.UTF8.GetBytes as part of argument handling, resulting in a temporary array being allocated per argument; dotnet/runtime#71279 removes that per-argument allocation, instead using Encoding.UTF8.GetByteCount to determine how large a space is needed and then using the Encoding.UTF8.GetBytes overload that accepts a span to encode directly into the native memory already being allocated. dotnet/runtime#71136 simplifies and streamlines the code involved in getting the ",
    "Another area of performance investment has been in DiagnosticSource , and in particular around enumerating through data from Activity instances. This work translates into faster integration and interoperability via OpenTelemetry, in order to be able to export data from .NET Activity information faster. dotnet/runtime#67012 from ",
    "Another area of performance investment has been in DiagnosticSource , and in particular around enumerating through data from Activity instances. This work translates into faster integration and interoperability via OpenTelemetry, in order to be able to export data from .NET Activity information faster. dotnet/runtime#67012 from ",
    "enumerator returned when enumerating Activity.Links and Activity.Events by avoiding a copy of each T value:",
    "enumerator returned when enumerating Activity.Links and Activity.Events by avoiding a copy of each T value:",
    "| Method                 | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method                 | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "Then dotnet/runtime#67920 from ",
    "Then dotnet/runtime#67920 from ",
    "| Method                     | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method                     | Mean      |   Ratio | Allocated   |   Alloc Ratio |",
    "Of course, when it comes to diagnostics, anyone who",
    "Of course, when it comes to diagnostics, anyone who",
    "is easy, but allocates a new object just to measure. To address this, Stopwatch has for years exposed the static GetTimestamp() method which avoids that allocation, but consuming and translating the resulting long value is complicated, requiring a formula involving using Stopwatch.Frequency and TimeSpan.TicksPerSecond in the right incantation. To make this pattern easy, dotnet/runtime#66372 adds a static GetElapsedTime method that handles that conversion, such that someone who wants that last mile of performance can write:",
    "is easy, but allocates a new object just to measure. To address this, Stopwatch has for years exposed the static GetTimestamp() method which avoids that allocation, but consuming and translating the resulting long value is complicated, requiring a formula involving using Stopwatch.Frequency and TimeSpan.TicksPerSecond in the right incantation. To make this pattern easy, dotnet/runtime#66372 adds a static GetElapsedTime method that handles that conversion, such that someone who wants that last mile of performance can write:",
    "which avoids the allocation and saves a few cycles:",
    "which avoids the allocation and saves a few cycles:",
    "| long timestamp = Stopwatch.GetTimestamp(); return Stopwatch.GetElapsedTime(timestamp);   |",
    "| long timestamp = Stopwatch.GetTimestamp(); return Stopwatch.GetElapsedTime(timestamp);   |",
    "| Method   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "It might be odd to see the subject of ",
    "It might be odd to see the subject of ",
    "Instead, one of the things we do concern ourselves with is how to minimize the impact of checking for exceptional cond itions: the actual exception throwing may be unexpected and slow, but it",
    "Instead, one of the things we do concern ourselves with is how to minimize the impact of checking for exceptional cond itions: the actual exception throwing may be unexpected and slow, but it",
    "Because of all of that, high-performance librari es often come up with custom ",
    "Because of all of that, high-performance librari es often come up with custom ",
    "This keeps the IL associated with the throwing out of the calling function, minimizing the impact of the throw. That",
    "This keeps the IL associated with the throwing out of the calling function, minimizing the impact of the throw. That",
    "Other times, libraries will encapsulate both the checking and throwing. This is exactly what the ArgumentNullException.ThrowIfNull method that was added in .NET 6 does:",
    "Other times, libraries will encapsulate both the checking and throwing. This is exactly what the ArgumentNullException.ThrowIfNull method that was added in .NET 6 does:",
    "With that, callers benefit from the concise call site:",
    "With that, callers benefit from the concise call site:",
    "the IL remains concise, and the assembly generated for the JIT will include the streamlined condition check from the inlined ThrowIfNull but won",
    "the IL remains concise, and the assembly generated for the JIT will include the streamlined condition check from the inlined ThrowIfNull but won",
    "Whenever we introduce new public APIs in .NET, I",
    "Whenever we introduce new public APIs in .NET, I",
    "For those unaware, the ",
    "For those unaware, the ",
    "The C# compiler then compiled that as equivalent to:",
    "The C# compiler then compiled that as equivalent to:",
    "(albeit using its own ThrowIfNull helper injected as internal into the assembly). Armed with the new feature, dotnet/runtime#64720 and dotnet/runtime#65108 rolled out use of ",
    "(albeit using its own ThrowIfNull helper injected as internal into the assembly). Armed with the new feature, dotnet/runtime#64720 and dotnet/runtime#65108 rolled out use of ",
    "APIs internally. Interestingly, while we expected a peanut-buttery effect of slight perf improvements in many places, our performance auto-analysis system flagged several performance improvements (e.g. dotnet/perf-autofiling-issues#3531) as stemming from these changes, in particular because it enabled the JIT",
    "APIs internally. Interestingly, while we expected a peanut-buttery effect of slight perf improvements in many places, our performance auto-analysis system flagged several performance improvements (e.g. dotnet/perf-autofiling-issues#3531) as stemming from these changes, in particular because it enabled the JIT",
    "helper",
    "helper",
    "With the success of ArgumentNullException.ThrowIfNull and along with its significant roll-out in .NET 7, .NET 7 also sees the introduction of several more such throw helpers. dotnet/runtime#61633, for example, adds an overload of ArgumentNullException.ThrowIfNull that works with pointers. dotnet/runtime#64357 adds the new ArgumentException.ThrowIfNullOrEmpty helper as well as using it in several hundred places. And dotnet/runtime#58684 from ",
    "With the success of ArgumentNullException.ThrowIfNull and along with its significant roll-out in .NET 7, .NET 7 also sees the introduction of several more such throw helpers. dotnet/runtime#61633, for example, adds an overload of ArgumentNullException.ThrowIfNull that works with pointers. dotnet/runtime#64357 adds the new ArgumentException.ThrowIfNullOrEmpty helper as well as using it in several hundred places. And dotnet/runtime#58684 from ",
    "On Windows, the Registry is a database provided by the OS for applications and the system itself to load and store configuration settings. Practically every application accesses the registry. I just tried a simple console app:",
    "On Windows, the Registry is a database provided by the OS for applications and the system itself to load and store configuration settings. Practically every application accesses the registry. I just tried a simple console app:",
    "Console.WriteLine(",
    "Console.WriteLine(",
    "built it as release, and then ran the resulting .exe. That execution alone triggered 64 RegQueryValue operations (as visible via SysInternals",
    "built it as release, and then ran the resulting .exe. That execution alone triggered 64 RegQueryValue operations (as visible via SysInternals",
    "It",
    "It",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |",
    "The ability to easily plug custom code, whether for analyzers or source generators, into the Roslyn compiler is one of my favorite features in all of C#. It means the developers working on C# don",
    "The ability to easily plug custom code, whether for analyzers or source generators, into the Roslyn compiler is one of my favorite features in all of C#. It means the developers working on C# don",
    "One of my favorite new analyzers was added in dotnet/roslyn-analyzers#5594 from ",
    "One of my favorite new analyzers was added in dotnet/roslyn-analyzers#5594 from ",
    "Virtual calls are more expensive than regular nonvirtual invocation and generally can",
    "Virtual calls are more expensive than regular nonvirtual invocation and generally can",
    "If a type check (e.g. something is typeof(SomeType) ) is performed where SomeType is sealed, that check can be implemented along the lines of something is not null ",
    "If a type check (e.g. something is typeof(SomeType) ) is performed where SomeType is sealed, that check can be implemented along the lines of something is not null ",
    "Arrays in .NET are covariant, which means if types B and C both derive from type A , you can have a variable typed as A",
    "Arrays in .NET are covariant, which means if types B and C both derive from type A , you can have a variable typed as A",
    "Spans shift this covariance check to their constructor; rather than performing the covariance check on every write into the array, the check is performed when a span is being constructed from an array, such that if you try to create a new Span",
    "Spans shift this covariance check to their constructor; rather than performing the covariance check on every write into the array, the check is performed when a span is being constructed from an array, such that if you try to create a new Span",
    "It effectively would be impossible for an analyzer to be able to safely recommend sealing public types. After all, it has no kno wledge of the type",
    "It effectively would be impossible for an analyzer to be able to safely recommend sealing public types. After all, it has no kno wledge of the type",
    "In .NET 6, we sealed over 2300 types, but even with that, this analyzer ended up finding more to seal. dotnet/runtime#59941 from ",
    "In .NET 6, we sealed over 2300 types, but even with that, this analyzer ended up finding more to seal. dotnet/runtime#59941 from ",
    "Another new analyzer, CA1854, was added in dotnet/roslyn-analyzers#4851 from ",
    "Another new analyzer, CA1854, was added in dotnet/roslyn-analyzers#4851 from ",
    "Dictionary",
    "Dictionary",
    "A benefit of this, in addition to arguably being simpler, is that it",
    "A benefit of this, in addition to arguably being simpler, is that it",
    "| Method   | Mean     |   Ratio |",
    "| Method   | Mean     |   Ratio |",
    "Somewhat ironically, even as I write this example, the analyzer and its auto-fixer are helpfully trying to get me to change my benchmark code:",
    "Somewhat ironically, even as I write this example, the analyzer and its auto-fixer are helpfully trying to get me to change my benchmark code:",
    "L",
    "L",
    "1",
    "1",
    "2",
    "2",
    "3",
    "3",
    "4",
    "4",
    "5",
    "5",
    "6",
    "6",
    "7",
    "7",
    "8",
    "8",
    "if (",
    "if (",
    "Use ",
    "Use ",
    "\u2022 CA1854 Prefer a ",
    "\u2022 CA1854 Prefer a ",
    "Convert to conditional expression",
    "Convert to conditional expression",
    "Introduce parameter for ",
    "Introduce parameter for ",
    "Invert if",
    "Invert if",
    "Suppress or Configure issues",
    "Suppress or Configure issues",
    "O references",
    "O references",
    "{",
    "{",
    "guarded by a ",
    "guarded by a ",
    "Lines 32 to 36",
    "Lines 32 to 36",
    "Similarly, dotnet/roslyn-analyzers#4836 from ",
    "Similarly, dotnet/roslyn-analyzers#4836 from ",
    "which the analyzer flagged and which it",
    "which the analyzer flagged and which it",
    "Nice and simple. And faster, since as with the TryGetValue case, this is now doing a single dictionary lookup rather than two. :::{custom-style=Figure}",
    "Nice and simple. And faster, since as with the TryGetValue case, this is now doing a single dictionary lookup rather than two. :::{custom-style=Figure}",
    "if (",
    "if (",
    "Remove unnecessary call",
    "Remove unnecessary call",
    "\u2022 \u2022 CA1853 Do not guard Dictionary, Remove(key) with",
    "\u2022 \u2022 CA1853 Do not guard Dictionary, Remove(key) with",
    "Invert if",
    "Invert if",
    "Suppress or Configure issues \u2022",
    "Suppress or Configure issues \u2022",
    "'",
    "'",
    "Lines 45 to 50",
    "Lines 45 to 50",
    "Another nice analyzer added in dotnet/roslyn-analyzers#5907 and dotnet/roslyn-analyzers#5910 is CA1851, which looks for code that iterates through some kinds of enumerables multiple times. Enumerating an enumerator, whether directly or via helper methods like those in LINQ, can have nontrivial cost. Calling GetEnumerator typically allocates an enumerator object, and every item yielded typically involves two interface calls, one to MoveNext and one to Current. If something can be done via a single pass over the enumerable rather than multiple passes, that can save such costs. In some cases, seeing places this analyzer fires can also inspire changes that avoid any use of enumerators. For example, dotnet/runtime#67292 enabled CA1851 for dotnet/runtime, and in doing so, it fixed several diagnostics issued by the analyzer (even in a code base that",
    "Another nice analyzer added in dotnet/roslyn-analyzers#5907 and dotnet/roslyn-analyzers#5910 is CA1851, which looks for code that iterates through some kinds of enumerables multiple times. Enumerating an enumerator, whether directly or via helper methods like those in LINQ, can have nontrivial cost. Calling GetEnumerator typically allocates an enumerator object, and every item yielded typically involves two interface calls, one to MoveNext and one to Current. If something can be done via a single pass over the enumerable rather than multiple passes, that can save such costs. In some cases, seeing places this analyzer fires can also inspire changes that avoid any use of enumerators. For example, dotnet/runtime#67292 enabled CA1851 for dotnet/runtime, and in doing so, it fixed several diagnostics issued by the analyzer (even in a code base that",
    "The method",
    "The method",
    "with this. First, it",
    "with this. First, it",
    "With that, we only ever iterate it once (and possibly 0 times if ToArray can special-case it, and bonus, we validate on the copy rather than on the mutable original.",
    "With that, we only ever iterate it once (and possibly 0 times if ToArray can special-case it, and bonus, we validate on the copy rather than on the mutable original.",
    "Yet another helpful analyzer is the new CA1850 introduced in dotnet/roslyn-analyzers#4797 from ",
    "Yet another helpful analyzer is the new CA1850 introduced in dotnet/roslyn-analyzers#4797 from ",
    "However, .NET 5 introduced new ",
    "However, .NET 5 introduced new ",
    "CA1850 finds occurrences of the former pattern and recommends changing them to the latter.",
    "CA1850 finds occurrences of the former pattern and recommends changing them to the latter.",
    "public bytel",
    "public bytel",
    "using (SHA256 h = SHA256.Create())",
    "using (SHA256 h = SHA256.Create())",
    "{",
    "{",
    "The result is not only simpler, it",
    "The result is not only simpler, it",
    "The .NET 7 SDK also includes new analyzers around ",
    "The .NET 7 SDK also includes new analyzers around ",
    "| Method   | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "| Method   | Mean       |   Ratio | Allocated   |   Alloc Ratio |",
    "Convert to ",
    "Convert to ",
    "Use ",
    "Use ",
    "Generate constructor ",
    "Generate constructor ",
    "Generate Equals(object)",
    "Generate Equals(object)",
    "Generate Equals and GetHashCode",
    "Generate Equals and GetHashCode",
    "Encapsulate field: ",
    "Encapsulate field: ",
    "Encapsulate field: ",
    "Encapsulate field: ",
    "Extract base class...",
    "Extract base class...",
    "Suppress or Configure issues",
    "Suppress or Configure issues",
    "\u2022 \u00ae Use ",
    "\u2022 \u00ae Use ",
    "Lines 38 to 40",
    "Lines 38 to 40",
    "private readonly Regex ",
    "private readonly Regex ",
    "private readonly Regex ",
    "private readonly Regex ",
    "This release also saw dotnet/runtime turn on a bunch of additional IDEXXXX code style rules and make a huge number of code changes in response. Most of the resulting changes are purely about simplifying the code, but in almost every case some portion of the changes also have a functional and performance impact.",
    "This release also saw dotnet/runtime turn on a bunch of additional IDEXXXX code style rules and make a huge number of code changes in response. Most of the resulting changes are purely about simplifying the code, but in almost every case some portion of the changes also have a functional and performance impact.",
    "Let",
    "Let",
    "Here we have a method CallSite that",
    "Here we have a method CallSite that",
    "The most important aspect of this is that ",
    "The most important aspect of this is that ",
    "non-null and will just reuse the same delegate. Thus, this lambda only ever results in a single allocation for the whole process (ignoring any race conditions on the initial lazy initialization such that multiple threads all racing to initialize the field might end up producing a few additional unnecessary allocations). It",
    "non-null and will just reuse the same delegate. Thus, this lambda only ever results in a single allocation for the whole process (ignoring any race conditions on the initial lazy initialization such that multiple threads all racing to initialize the field might end up producing a few additional unnecessary allocations). It",
    "| Method         | Mean      |   Ratio |",
    "| Method         | Mean      |   Ratio |",
    "So, the compiler is able to cache references to lambdas, great. What about method groups, i.e. where you just name the method directly? Previously, if changed my code to:",
    "So, the compiler is able to cache references to lambdas, great. What about method groups, i.e. where you just name the method directly? Previously, if changed my code to:",
    "the compiler would generate the equivalent of:",
    "the compiler would generate the equivalent of:",
    "which has the unfortunate effect of allocating a new delegate on every invocation, even though we",
    "which has the unfortunate effect of allocating a new delegate on every invocation, even though we",
    "Note we again have a caching field that",
    "Note we again have a caching field that",
    "And that brings us to IDE0200, which recognizes lambda expressions that can be removed. dotnet/runtime#71011 enabled the analyzer for dotnet/runtime, resulting in more than 100 call sites changing accordingly. However, IDE0200 does more than just this mostly stylistic change. It also recognizes some patterns that can make a more substantial impact. Consider this code that was changed as part of that PR:",
    "And that brings us to IDE0200, which recognizes lambda expressions that can be removed. dotnet/runtime#71011 enabled the analyzer for dotnet/runtime, resulting in more than 100 call sites changing accordingly. However, IDE0200 does more than just this mostly stylistic change. It also recognizes some patterns that can make a more substantial impact. Consider this code that was changed as part of that PR:",
    "That delegate closes over the disposable local, which means this method needs to allocate a display class. But IDE0200 recognizes that instead of closing over disposable , we can create the delegate directly to the Dispose method:",
    "That delegate closes over the disposable local, which means this method needs to allocate a display class. But IDE0200 recognizes that instead of closing over disposable , we can create the delegate directly to the Dispose method:",
    "We still get a delegate allocation, but we avoid the display class allocation, and as a bonus we save on the additional metadata required for the synthesized display class and method generated for the lambda.",
    "We still get a delegate allocation, but we avoid the display class allocation, and as a bonus we save on the additional metadata required for the synthesized display class and method generated for the lambda.",
    "IDE0020 is another good example of an analyzer that is primarily focused on making code cleaner, more maintainable, more modern, but that can also lead to removing overhead from many different places. The analyzer looks for code performing unnecessary duplicative casts and recommends using C# pattern matching syntax instead. For example, dotnet/runtime#70523 enabled the analyzer and switched more than 250 locations from code like:",
    "IDE0020 is another good example of an analyzer that is primarily focused on making code cleaner, more maintainable, more modern, but that can also lead to removing overhead from many different places. The analyzer looks for code performing unnecessary duplicative casts and recommends using C# pattern matching syntax instead. For example, dotnet/runtime#70523 enabled the analyzer and switched more than 250 locations from code like:",
    "to instead be like:",
    "to instead be like:",
    "In addition to being cleaner, this ends up saving a cast operation, which can add measurable overhead if the JIT is unable to remove it:",
    "In addition to being cleaner, this ends up saving a cast operation, which can add measurable overhead if the JIT is unable to remove it:",
    "| Method      | Mean     |   Ratio |",
    "| Method      | Mean     |   Ratio |",
    "Then there",
    "Then there",
    "into code that",
    "into code that",
    "Nice, concise, and primarily about cleaning up the code and making it simpler and more maintainable by utilizing newer C# syntax. However, there is also a small performance advantage in some situations as well. For example, consider this snippet:",
    "Nice, concise, and primarily about cleaning up the code and making it simpler and more maintainable by utilizing newer C# syntax. However, there is also a small performance advantage in some situations as well. For example, consider this snippet:",
    "The C# compiler lowers these expressions to the equivalent of this:",
    "The C# compiler lowers these expressions to the equivalent of this:",
    "for which the JIT then generates:",
    "for which the JIT then generates:",
    "Note how the Get1 variant has an extra cmp instruction ( cmp ",
    "Note how the Get1 variant has an extra cmp instruction ( cmp ",
    "Another interesting example is IDE0060, which finds unused parameters and recommends removing them. This was done for non-public members in System.Private.CoreLib in dotnet/runtime#63015. As with some of the other mentioned rules, it",
    "Another interesting example is IDE0060, which finds unused parameters and recommends removing them. This was done for non-public members in System.Private.CoreLib in dotnet/runtime#63015. As with some of the other mentioned rules, it",
    "One final example of peanut-buttery performance improvements from applying an analyzer comes from dotnet/runtime#70896 and dotnet/runtime#71361, which applied IDE0029 across dotnet/runtime. IDE0029 flags cases where null coalescing can be used, e.g. flagging:",
    "One final example of peanut-buttery performance improvements from applying an analyzer comes from dotnet/runtime#70896 and dotnet/runtime#71361, which applied IDE0029 across dotnet/runtime. IDE0029 flags cases where null coalescing can be used, e.g. flagging:",
    "and recommending it be converted to:",
    "and recommending it be converted to:",
    "As with some of the previous rules discussed, that in and of itself doesn",
    "As with some of the previous rules discussed, that in and of itself doesn",
    "which is rewritten to:",
    "which is rewritten to:",
    "This avoids an unnecessary re-access to an array. Or again from those PRs the expression:",
    "This avoids an unnecessary re-access to an array. Or again from those PRs the expression:",
    "entry.GetKey(",
    "entry.GetKey(",
    "and avoiding an unnecessary table lookup.",
    "and avoiding an unnecessary table lookup.",
    "Whew",
    "Whew",
    "The next step is on you. Download the latest .NET 7 bits and take them for a spin. Upgrade your apps. Write and share your own benchmarks. Provide feedback, positive and critical. Find something you think can be better? Open an issue, or better yet, submit a PR with the fix. We",
    "The next step is on you. Download the latest .NET 7 bits and take them for a spin. Upgrade your apps. Write and share your own benchmarks. Provide feedback, positive and critical. Find something you think can be better? Open an issue, or better yet, submit a PR with the fix. We",
    "Until next time\u2026",
    "Until next time\u2026",
    "Happy coding",
    "Happy coding"
]