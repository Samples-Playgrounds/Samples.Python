"[\"Performance Improvements\\nin .NET 7\\nStephen Toub\\nPartner Software Engineer, .NET\\nMicrosoftIntroductio\", \"n\\nA year ago, I published Performance Improvements in .NET 6, following on the heels of similar post\", \"s\\nfor .NET 5, .NET Core 3.0, .NET Core 2.1, and .NET Core 2.0. I enjoy writing these posts and love\\n\", \"reading developers\\u2019 responses to them. One comment in particular last year resonated with me. The\\nco\", \"mmenter cited the Die Hard movie quote, \\u201c\\u2018When Alexander saw the breadth of his domain, he\\nwept for \", \"there were no more worlds to conquer\\u2019,\\u201d and questioned whether .NET performance\\nimprovements were si\", \"milar. Has the well run dry? Are there no more \\u201c[performance] worlds to\\nconquer\\u201d? I\\u2019m a bit giddy to\", \" say that, even with how fast .NET 6 is, .NET 7 definitively highlights how\\nmuch more can be and has\", \" been done.\\nAs with previous versions of .NET, performance is a key focus that pervades the entire s\", \"tack, whether it\\nbe features created explicitly for performance or non-performance-related features \", \"that are still\\ndesigned and implemented with performance keenly in mind. And now that a .NET 7 relea\", \"se\\ncandidate is just around the corner, it\\u2019s a good time to discuss much of it. Over the course of t\", \"he last\\nyear, every time I\\u2019ve reviewed a PR that might positively impact performance, I\\u2019ve copied th\", \"at link to a\\njournal I maintain for the purposes of writing this post. When I sat down to write this\", \" a few weeks ago,\\nI was faced with a list of almost 1000 performance-impacting PRs (out of more than\", \" 7000 PRs that\\nwent into the release), and I\\u2019m excited to share approximately 500 of them here with \", \"you.\\nOne thought before we dive in. In past years, I\\u2019ve received the odd piece of negative feedback \", \"about\\nthe length of some of my performance-focused write-ups, and while I disagree with the criticis\", \"m, I\\nrespect the opinion. So, this year, consider this a \\u201cchoose your own adventure.\\u201d If you\\u2019re here\", \" just\\nlooking for a super short adventure, one that provides the top-level summary and a core messag\", \"e to\\ntake away from your time here, I\\u2019m happy to oblige:\\nTL;DR: .NET 7 is fast. Really fast. A thous\", \"and performance-impacting PRs went into runtime and core\\nlibraries this release, never mind all the \", \"improvements in ASP.NET Core and Windows Forms and\\nEntity Framework and beyond. It\\u2019s the fastest .NE\", \"T ever. If your manager asks you why your project\\nshould upgrade to .NET 7, you can say \\u201cin addition\", \" to all the new functionality in the release, .NET 7 is\\nsuper fast.\\u201d\\nOr, if you prefer a slightly lo\", \"nger adventure, one filled with interesting nuggets of performance-\\nfocused data, consider skimming \", \"through the post, looking for the small code snippets and\\ncorresponding tables showing a wealth of m\", \"easurable performance improvements. At that point, you,\\ntoo, may walk away with your head held high \", \"and my thanks.\\nBoth noted paths achieve one of my primary goals for spending the time to write these\", \" posts, to\\nhighlight the greatness of the next release and to encourage everyone to give it a try. B\", \"ut, I have other\\ngoals for these posts, too. I want everyone interested to walk away from this post \", \"with an upleveled\\nunderstanding of how .NET is implemented, why various decisions were made, tradeof\", \"fs that were\\nevaluated, techniques that were employed, algorithms that were considered, and valuable\", \" tools and\\napproaches that were utilized to make .NET even faster than it was previously. I want dev\", \"elopers to\\nlearn from our own learnings and find ways to apply this new-found knowledge to their own\", \"\\ncodebases, thereby further increasing the overall performance of code in the ecosystem. I want\\ndeve\", \"lopers to take an extra beat, think about reaching for a profiler the next time they\\u2019re working on a\", \"gnarly problem, think about looking at the source for the component they\\u2019re using in order to better\", \"\\nunderstand how to work with it, and think about revisiting previous assumptions and decisions to\\nde\", \"termine whether they\\u2019re still accurate and appropriate. And I want developers to be excited at the\\np\", \"rospect of submitting PRs to improve .NET not only for themselves but for every developer around\\nthe\", \" globe using .NET. If any of that sounds interesting, then I encourage you to choose the last\\nadvent\", \"ure: prepare a carafe of your favorite hot beverage, get comfortable, and please enjoy.Contents\\nSetu\", \"p ..................................................................................................\", \"....................................... 1\\nJIT ......................................................\", \"........................................................................................ 3\\nOn-Stack \", \"Replacement ........................................................................................\", \".......................................................... 13\\nPGO ..................................\", \"....................................................................................................\", \".................................................. 23\\nBounds Check Elimination .....................\", \"....................................................................................................\", \"................... 35\\nLoop Hoisting and Cloning ...................................................\", \"....................................................................................... 45\\nFolding, \", \"propagation, and substitution ......................................................................\", \"............................................. 50\\nVectorization .....................................\", \"....................................................................................................\", \"............................. 54\\nInlining ..........................................................\", \"....................................................................................................\", \".................... 62\\nArm64 ......................................................................\", \"....................................................................................................\", \"......... 64\\nJIT helpers ...........................................................................\", \"................................................................................................ 65\\n\", \"Grab Bag ...........................................................................................\", \"................................................................................... 67\\nGC ..........\", \"....................................................................................................\", \".............................. 71\\nNative AOT .......................................................\", \"...................................................................... 72\\nMono .....................\", \"....................................................................................................\", \"............. 75\\nReflection ........................................................................\", \"....................................................... 78\\nInterop .................................\", \"................................................................................................... \", \"82\\nThreading .......................................................................................\", \"........................................ 89\\nPrimitive Types and Numerics ...........................\", \".................................................................. 93\\nArrays, Strings, and Spans ...\", \"............................................................................................... 101\\n\", \"Regex ..............................................................................................\", \"...................................... 128\\nRegexOptions.NonBacktracking.............................\", \".................................................................................................. 1\", \"28\\nNew APIs ........................................................................................\", \".................................................................................... 133\\nTryFindNext\", \"PossibleStartingPosition ...........................................................................\", \".......................................... 138\\nLoops and Backtracking ..............................\", \"....................................................................................................\", \"............ 143\\nCode generation ...................................................................\", \".......................................................................................... 146\\nColle\", \"ctions .............................................................................................\", \"............................... 150\\nLINQ ...........................................................\", \"........................................................................... 153\\ni ContentsFile I/O .\", \"....................................................................................................\", \"............................. 159\\nCompression ......................................................\", \".................................................................. 168\\nNetworking ..................\", \"....................................................................................................\", \".... 173\\nJSON ......................................................................................\", \"............................................... 190\\nXML ............................................\", \"........................................................................................... 193\\nCryp\", \"tography ...........................................................................................\", \"............................ 198\\nDiagnostics .......................................................\", \".................................................................... 203\\nExceptions ................\", \"....................................................................................................\", \"........ 208\\nRegistry ..............................................................................\", \".................................................. 211\\nAnalyzers ...................................\", \"........................................................................................... 213\\nWhat\", \"\\u2019s Next? ...........................................................................................\", \"............................. 227\\nii Contents1\\nCHAPTER\\nSetup\\nThe microbenchmarks throughout this pos\", \"t utilize benchmarkdotnet. To make it easy for you to follow\\nalong with your own validation, I have \", \"a very simple setup for the benchmarks I use. Create a new C#\\nproject:\\ndotnet new console -o benchma\", \"rks\\ncd benchmarks\\nYour new benchmarks directory will contain a benchmarks.csproj file and a Program.\", \"cs file. Replace\\nthe contents of benchmarks.csproj with this:\\n<Project Sdk=\\\"Microsoft.NET.Sdk\\\">\\n<Pro\", \"pertyGroup>\\n<OutputType>Exe</OutputType>\\n<TargetFrameworks>net7.0;net6.0</TargetFrameworks>\\n<LangVer\", \"sion>Preview</LangVersion>\\n<AllowUnsafeBlocks>true</AllowUnsafeBlocks>\\n<ServerGarbageCollection>true\", \"</ServerGarbageCollection>\\n</PropertyGroup>\\n<ItemGroup>\\n<PackageReference Include=\\\"benchmarkdotnet\\\" \", \"Version=\\\"0.13.2\\\" />\\n</ItemGroup>\\n</Project>\\nand the contents of Program.cs with this:\\nusing Benchmar\", \"kDotNet.Attributes;\\nusing BenchmarkDotNet.Running;\\nusing Microsoft.Win32;\\nusing System;\\nusing System\", \".Buffers;\\nusing System.Collections.Generic;\\nusing System.Collections.Immutable;\\nusing System.Compone\", \"ntModel;\\nusing System.Diagnostics;\\nusing System.IO;\\nusing System.IO.Compression;\\nusing System.IO.Mem\", \"oryMappedFiles;\\nusing System.IO.Pipes;\\nusing System.Linq;\\nusing System.Net;\\nusing System.Net.Http;\\nu\", \"sing System.Net.Http.Headers;\\nusing System.Net.Security;\\nusing System.Net.Sockets;\\nusing System.Nume\", \"rics;\\n1 CHAPTER 1 | Setupusing System.Reflection;\\nusing System.Runtime.CompilerServices;\\nusing Syste\", \"m.Runtime.InteropServices;\\nusing System.Runtime.Intrinsics;\\nusing System.Security.Authentication;\\nus\", \"ing System.Security.Cryptography;\\nusing System.Security.Cryptography.X509Certificates;\\nusing System.\", \"Text;\\nusing System.Text.Json;\\nusing System.Text.RegularExpressions;\\nusing System.Threading;\\nusing Sy\", \"stem.Threading.Tasks;\\nusing System.Xml;\\n[MemoryDiagnoser(displayGenColumns: false)]\\n[DisassemblyDiag\", \"noser]\\n[HideColumns(\\\"Error\\\", \\\"StdDev\\\", \\\"Median\\\", \\\"RatioSD\\\")]\\npublic partial class Program\\n{\\nstatic v\", \"oid Main(string[] args) =>\\nBenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args);\\n// ..\", \". copy [Benchmark]s here\\n}\\nFor each benchmark included in this write-up, you can then just copy and \", \"paste the code into this test\\nclass, and run the benchmarks. For example, to run a benchmark compari\", \"ng performance on .NET 6\\nand .NET 7, do:\\ndotnet run -c Release -f net6.0 --filter '**' --runtimes ne\", \"t6.0 net7.0\\nThis command says \\u201cbuild the benchmarks in release configuration targeting the .NET 6 su\", \"rface area,\\nand then run all of the benchmarks on both .NET 6 and .NET 7.\\u201d Or to run just on .NET 7:\", \"\\ndotnet run -c Release -f net7.0 --filter '**' --runtimes net7.0\\nwhich instead builds targeting the \", \".NET 7 surface area and then only runs once against .NET 7. You\\ncan do this on any of Windows, Linux\", \", or macOS. Unless otherwise called out (e.g. where the\\nimprovements are specific to Unix and I run \", \"the benchmarks on Linux), the results I share were\\nrecorded on Windows 11 64-bit but aren\\u2019t Windows-\", \"specific and should show similar relative\\ndifferences on the other operating systems as well.\\nThe re\", \"lease of the first .NET 7 release candidate is right around the corner. All of the measurements in\\nt\", \"his post were gathered with a recent daily build of .NET 7 RC1.\\nAlso, my standard caveat: These are \", \"microbenchmarks. It is expected that different hardware, different\\nversions of operating systems, an\", \"d the way in which the wind is currently blowing can affect the\\nnumbers involved. Your mileage may v\", \"ary.\\n2 CHAPTER 1 | Setup2\\nCHAPTER\\nJIT\\nI\\u2019d like to kick off a discussion of performance improvements \", \"in the Just-In-Time (JIT) compiler by\\ntalking about something that itself isn\\u2019t actually a performan\", \"ce improvement. Being able to\\nunderstand exactly what assembly code is generated by the JIT is criti\", \"cal when fine-tuning lower-level,\\nperformance-sensitive code. There are multiple ways to get at that\", \" assembly code. The online tool\\nsharplab.io is incredibly useful for this (thanks to [@ashmind](http\", \"s://github.com/ashmind) for this\\ntool); however it currently only targets a single release, so as I \", \"write this I\\u2019m only able to see the\\noutput for .NET 6, which makes it difficult to use for A/B compa\", \"risons. godbolt.org is also valuable for\\nthis, with C# support added in compiler-explorer/compiler-e\", \"xplorer#3168 from\\n[@hez2010](https://github.com/hez2010), with similar limitations. The most flexibl\", \"e solutions involve\\ngetting at that assembly code locally, as it enables comparing whatever versions\", \" or local builds you\\ndesire with whatever configurations and switches set that you need.\\nOne common \", \"approach is to use the [DisassemblyDiagnoser] in benchmarkdotnet. Simply slap the\\n[DisassemblyDiagno\", \"ser] attribute onto your test class: benchmarkdotnet will find the assembly code\\ngenerated for your \", \"tests and some depth of functions they call, and dump out the found assembly\\ncode in a human-readabl\", \"e form. For example, if I run this test:\\nusing BenchmarkDotNet.Attributes;\\nusing BenchmarkDotNet.Run\", \"ning;\\nusing System;\\n[DisassemblyDiagnoser]\\npublic partial class Program\\n{\\nstatic void Main(string[] \", \"args) =>\\nBenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args);\\nprivate int _a = 42, _b\", \" = 84;\\n[Benchmark]\\npublic int Min() => Math.Min(_a, _b);\\n}\\nwith:\\ndotnet run -c Release -f net7.0 --f\", \"ilter '**'\\nin addition to doing all of its normal test execution and timing, benchmarkdotnet also ou\", \"tputs a\\nProgram-asm.md file that contains this:\\n; Program.Min()\\nmov eax,[rcx+8]\\nmov edx,[rcx+0C]\\ncmp\", \" eax,edx\\n3 CHAPTER 2 | JITjg short M00_L01\\nmov edx,eax\\nM00_L00:\\nmov eax,edx\\nret\\nM00_L01:\\njmp short M\", \"00_L00\\n; Total bytes of code 17\\nPretty neat. This support was recently improved further in dotnet/be\", \"nchmarkdotnet#2072, which\\nallows passing a filter list on the command-line to benchmarkdotnet to tel\", \"l it exactly which methods\\u2019\\nassembly code should be dumped.\\nIf you can get your hands on a \\u201cdebug\\u201d o\", \"r \\u201cchecked\\u201d build of the .NET runtime (\\u201cchecked\\u201d is a build\\nthat has optimizations enabled but also \", \"still includes asserts), and specifically of clrjit.dll, another\\nvaluable approach is to set an envi\", \"ronment variable that causes the JIT itself to spit out a human-\\nreadable description of all of the \", \"assembly code it emits. This can be used with any kind of\\napplication, as it\\u2019s part of the JIT itsel\", \"f rather than part of any specific tool or other environment, it\\nsupports showing the code the JIT g\", \"enerates each time it generates code (e.g. if it first compiles a\\nmethod without optimization and th\", \"en later recompiles it with optimization), and overall it\\u2019s the most\\naccurate picture of the assembl\", \"y code as it comes \\u201cstraight from the horses mouth,\\u201d as it were. The\\n(big) downside of course is tha\", \"t it requires a non-release build of the runtime, which typically means\\nyou need to build it yoursel\", \"f from the sources in the dotnet/runtime repo.\\n\\u2026 until .NET 7, that is. As of dotnet/runtime#73365, \", \"this assembly dumping support is now available in\\nrelease builds as well, which means it\\u2019s simply pa\", \"rt of .NET 7 and you don\\u2019t need anything special to\\nuse it. To see this, try creating a simple \\u201chell\", \"o world\\u201d app like:\\nusing System;\\nclass Program\\n{\\npublic static void Main() => Console.WriteLine(\\\"Hel\", \"lo, world!\\\");\\n}\\nand building it (e.g. dotnet build -c Release). Then, set the DOTNET_JitDisasm envir\", \"onment\\nvariable to the name of the method we care about, in this case \\u201cMain\\u201d (the exact syntax allow\", \"ed is\\nmore permissive and allows for some use of wildcards, optional namespace and class names, etc.\", \"). As\\nI\\u2019m using PowerShell, that means:\\n$env:DOTNET_JitDisasm=\\\"Main\\\"\\nand then running the app. You s\", \"hould see code like this output to the console:\\n; Assembly listing for method Program:Main()\\n; Emitt\", \"ing BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; MinOpts code\\n; rbp based fram\", \"e\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n55 push rbp\\n4883EC20 sub rsp, 32\\n4 CHAPTER \", \"2 | JIT488D6C2420 lea rbp, [rsp+20H]\\nG_M000_IG02: ;; offset=000AH\\n48B9D820400A8E010000 mov rcx, 0x18\", \"E0A4020D8\\n488B09 mov rcx, gword ptr [rcx]\\nFF1583B31000 call [Console:WriteLine(String)]\\n90 nop\\nG_M00\", \"0_IG03: ;; offset=001EH\\n4883C420 add rsp, 32\\n5D pop rbp\\nC3 ret\\n; Total bytes of code 36\\nHello, world\", \"!\\nThis is immeasurably helpful for performance analysis and tuning, even for questions as simple as \", \"\\u201cdid\\nmy function get inlined\\u201d or \\u201cis this code I expected to be optimized away actually getting opti\", \"mized\\naway.\\u201d Throughout the rest of this post, I\\u2019ll include assembly snippets generated by one of th\", \"ese two\\nmechanisms, in order to help exemplify concepts.\\nNote that it can sometimes be a little conf\", \"using figuring out what name to specify as the value for\\nDOTNET_JitDisasm, especially when the metho\", \"d you care about is one that the C# compiler names or\\nname mangles (since the JIT only sees the IL a\", \"nd metadata, not the original C#), e.g. the name of the\\nentry point method for a program with top-le\", \"vel statements, the names of local functions, etc. To\\nboth help with this and to provide a really va\", \"luable top-level view of the work the JIT is doing, .NET 7\\nalso supports the new DOTNET_JitDisasmSum\", \"mary environment variable (introduced in\\ndotnet/runtime#74090). Set that to \\u201c1\\u201d, and it\\u2019ll result in\", \" the JIT emitting a line every time it compiles a\\nmethod, including the name of that method which is\", \" copy/pasteable with DOTNET_JitDisasm. This\\nfeature is useful in-and-of-itself, however, as it can q\", \"uickly highlight for you what\\u2019s being compiled,\\nwhen, and with what settings. For example, if I set \", \"the environment variable and then run a \\u201chello,\\nworld\\u201d console app, I get this output:\\n1: JIT compil\", \"ed CastHelpers:StelemRef(Array,long,Object) [Tier1, IL size=88, code\\nsize=93]\\n2: JIT compiled CastHe\", \"lpers:LdelemaRef(Array,long,long):byref [Tier1, IL size=44, code\\nsize=44]\\n3: JIT compiled SpanHelper\", \"s:IndexOfNullCharacter(byref):int [Tier1, IL size=792, code\\nsize=388]\\n4: JIT compiled Program:Main()\", \" [Tier0, IL size=11, code size=36]\\n5: JIT compiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):l\", \"ong [Tier0, IL\\nsize=490, code size=1187]\\nHello, world!\\nWe can see for \\u201chello, world\\u201d there\\u2019s only 5 \", \"methods that actually get JIT compiled. There are of\\ncourse many more methods that get executed as p\", \"art of a simple \\u201chello, world,\\u201d but almost all of\\nthem have precompiled native code available as par\", \"t of the \\u201cReady To Run\\u201d (R2R) images of the core\\nlibraries. The first three in the above list (Stele\", \"mRef, LdelemaRef, and IndexOfNullCharacter) don\\u2019t\\nbecause they explicitly opted-out of R2R via use o\", \"f the\\n[MethodImpl(MethodImplOptions.AggressiveOptimization)] attribute (despite the name, this\\nattri\", \"bute should almost never be used, and is only used for very specific reasons in a few very specific\\n\", \"places in the core libraries). Then there\\u2019s our Main method. And lastly there\\u2019s the NarrowUtf16ToAsc\", \"ii\\n5 CHAPTER 2 | JITmethod, which doesn\\u2019t have R2R code, either, due to using the variable-width Vec\", \"tor<T> (more on\\nthat later). Every other method that\\u2019s run doesn\\u2019t require JIT\\u2019ing. If we instead fi\", \"rst set the\\nDOTNET_ReadyToRun environment variable to 0, the list is much longer, and gives you a ve\", \"ry good\\nsense of what the JIT needs to do on startup (and why technologies like R2R are important fo\", \"r startup\\ntime). Note how many methods get compiled before \\u201chello, world\\u201d is output:\\n1: JIT compiled\", \" CastHelpers:StelemRef(Array,long,Object) [Tier1, IL size=88, code\\nsize=93]\\n2: JIT compiled CastHelp\", \"ers:LdelemaRef(Array,long,long):byref [Tier1, IL size=44, code\\nsize=44]\\n3: JIT compiled AppContext:S\", \"etup(long,long,int) [Tier0, IL size=68, code size=275]\\n4: JIT compiled Dictionary`2:.ctor(int):this \", \"[Tier0, IL size=9, code size=40]\\n5: JIT compiled Dictionary`2:.ctor(int,IEqualityComparer`1):this [T\", \"ier0, IL size=102,\\ncode size=444]\\n6: JIT compiled Object:.ctor():this [Tier0, IL size=1, code size=1\", \"0]\\n7: JIT compiled Dictionary`2:Initialize(int):int:this [Tier0, IL size=56, code size=231]\\n8: JIT c\", \"ompiled HashHelpers:GetPrime(int):int [Tier0, IL size=83, code size=379]\\n9: JIT compiled HashHelpers\", \":.cctor() [Tier0, IL size=24, code size=102]\\n10: JIT compiled HashHelpers:GetFastModMultiplier(int):\", \"long [Tier0, IL size=9, code\\nsize=37]\\n11: JIT compiled Type:GetTypeFromHandle(RuntimeTypeHandle):Typ\", \"e [Tier0, IL size=8, code\\nsize=14]\\n12: JIT compiled Type:op_Equality(Type,Type):bool [Tier0, IL size\", \"=38, code size=143]\\n13: JIT compiled\\nNonRandomizedStringEqualityComparer:GetStringComparer(Object):I\", \"EqualityComparer`1 [Tier0,\\nIL size=39, code size=170]\\n14: JIT compiled NonRandomizedStringEqualityCo\", \"mparer:.cctor() [Tier0, IL size=46, code\\nsize=232]\\n15: JIT compiled EqualityComparer`1:get_Default()\", \":EqualityComparer`1 [Tier0, IL size=6,\\ncode size=36]\\n16: JIT compiled EqualityComparer`1:.cctor() [T\", \"ier0, IL size=26, code size=125]\\n17: JIT compiled ComparerHelpers:CreateDefaultEqualityComparer(Type\", \"):Object [Tier0, IL\\nsize=235, code size=949]\\n18: JIT compiled CastHelpers:ChkCastClass(long,Object):\", \"Object [Tier0, IL size=22, code\\nsize=72]\\n19: JIT compiled RuntimeHelpers:GetMethodTable(Object):long\", \" [Tier0, IL size=11, code\\nsize=33]\\n20: JIT compiled CastHelpers:IsInstanceOfClass(long,Object):Objec\", \"t [Tier0, IL size=97,\\ncode size=257]\\n21: JIT compiled GenericEqualityComparer`1:.ctor():this [Tier0,\", \" IL size=7, code size=31]\\n22: JIT compiled EqualityComparer`1:.ctor():this [Tier0, IL size=7, code s\", \"ize=31]\\n23: JIT compiled CastHelpers:ChkCastClassSpecial(long,Object):Object [Tier0, IL size=87,\\ncod\", \"e size=246]\\n24: JIT compiled OrdinalComparer:.ctor(IEqualityComparer`1):this [Tier0, IL size=8, code\", \"\\nsize=39]\\n25: JIT compiled NonRandomizedStringEqualityComparer:.ctor(IEqualityComparer`1):this\\n[Tier\", \"0, IL size=14, code size=52]\\n26: JIT compiled StringComparer:get_Ordinal():StringComparer [Tier0, IL\", \" size=6, code\\nsize=49]\\n27: JIT compiled OrdinalCaseSensitiveComparer:.cctor() [Tier0, IL size=11, co\", \"de size=71]\\n28: JIT compiled OrdinalCaseSensitiveComparer:.ctor():this [Tier0, IL size=8, code\\nsize=\", \"33]\\n29: JIT compiled OrdinalComparer:.ctor(bool):this [Tier0, IL size=14, code size=43]\\n30: JIT comp\", \"iled StringComparer:.ctor():this [Tier0, IL size=7, code size=31]\\n31: JIT compiled StringComparer:ge\", \"t_OrdinalIgnoreCase():StringComparer [Tier0, IL size=6,\\ncode size=49]\\n32: JIT compiled OrdinalIgnore\", \"CaseComparer:.cctor() [Tier0, IL size=11, code size=71]\\n33: JIT compiled OrdinalIgnoreCaseComparer:.\", \"ctor():this [Tier0, IL size=8, code size=36]\\n34: JIT compiled OrdinalIgnoreCaseComparer:.ctor(IEqual\", \"ityComparer`1):this [Tier0, IL\\n6 CHAPTER 2 | JITsize=8, code size=39]\\n35: JIT compiled CastHelpers:C\", \"hkCastAny(long,Object):Object [Tier0, IL size=38, code\\nsize=115]\\n36: JIT compiled CastHelpers:TryGet\", \"(long,long):int [Tier0, IL size=129, code size=308]\\n37: JIT compiled CastHelpers:TableData(ref):byre\", \"f [Tier0, IL size=7, code size=31]\\n38: JIT compiled MemoryMarshal:GetArrayDataReference(ref):byref [\", \"Tier0, IL size=7, code\\nsize=24]\\n39: JIT compiled CastHelpers:KeyToBucket(byref,long,long):int [Tier0\", \", IL size=38, code\\nsize=87]\\n40: JIT compiled CastHelpers:HashShift(byref):int [Tier0, IL size=3, cod\", \"e size=16]\\n41: JIT compiled BitOperations:RotateLeft(long,int):long [Tier0, IL size=17, code\\nsize=23\", \"]\\n42: JIT compiled CastHelpers:Element(byref,int):byref [Tier0, IL size=15, code size=33]\\n43: JIT co\", \"mpiled Volatile:Read(byref):int [Tier0, IL size=6, code size=16]\\n44: JIT compiled String:Ctor(long):\", \"String [Tier0, IL size=57, code size=155]\\n45: JIT compiled String:wcslen(long):int [Tier0, IL size=7\", \", code size=31]\\n46: JIT compiled SpanHelpers:IndexOfNullCharacter(byref):int [Tier1, IL size=792, co\", \"de\\nsize=388]\\n47: JIT compiled String:get_Length():int:this [Tier0, IL size=7, code size=17]\\n48: JIT \", \"compiled Buffer:Memmove(byref,byref,long) [Tier0, IL size=59, code size=102]\\n49: JIT compiled Runtim\", \"eHelpers:IsReferenceOrContainsReferences():bool [Tier0, IL size=2,\\ncode size=8]\\n50: JIT compiled Buf\", \"fer:Memmove(byref,byref,long) [Tier0, IL size=480, code size=678]\\n51: JIT compiled Dictionary`2:Add(\", \"__Canon,__Canon):this [Tier0, IL size=11, code size=55]\\n52: JIT compiled Dictionary`2:TryInsert(__Ca\", \"non,__Canon,ubyte):bool:this [Tier0, IL\\nsize=675, code size=2467]\\n53: JIT compiled OrdinalComparer:G\", \"etHashCode(String):int:this [Tier0, IL size=7, code\\nsize=37]\\n54: JIT compiled String:GetNonRandomize\", \"dHashCode():int:this [Tier0, IL size=110, code\\nsize=290]\\n55: JIT compiled BitOperations:RotateLeft(i\", \"nt,int):int [Tier0, IL size=17, code size=20]\\n56: JIT compiled Dictionary`2:GetBucket(int):byref:thi\", \"s [Tier0, IL size=29, code size=90]\\n57: JIT compiled HashHelpers:FastMod(int,int,long):int [Tier0, I\", \"L size=20, code size=70]\\n58: JIT compiled Type:get_IsValueType():bool:this [Tier0, IL size=7, code s\", \"ize=39]\\n59: JIT compiled RuntimeType:IsValueTypeImpl():bool:this [Tier0, IL size=54, code\\nsize=158]\\n\", \"60: JIT compiled RuntimeType:GetNativeTypeHandle():TypeHandle:this [Tier0, IL size=12,\\ncode size=48]\", \"\\n61: JIT compiled TypeHandle:.ctor(long):this [Tier0, IL size=8, code size=25]\\n62: JIT compiled Type\", \"Handle:get_IsTypeDesc():bool:this [Tier0, IL size=14, code size=38]\\n63: JIT compiled TypeHandle:AsMe\", \"thodTable():long:this [Tier0, IL size=7, code size=17]\\n64: JIT compiled MethodTable:get_IsValueType(\", \"):bool:this [Tier0, IL size=20, code\\nsize=32]\\n65: JIT compiled GC:KeepAlive(Object) [Tier0, IL size=\", \"1, code size=10]\\n66: JIT compiled Buffer:_Memmove(byref,byref,long) [Tier0, IL size=25, code size=27\", \"9]\\n67: JIT compiled Environment:InitializeCommandLineArgs(long,int,long):ref [Tier0, IL\\nsize=75, cod\", \"e size=332]\\n68: JIT compiled Environment:.cctor() [Tier0, IL size=11, code size=163]\\n69: JIT compile\", \"d StartupHookProvider:ProcessStartupHooks() [Tier-0 switched to FullOpts,\\nIL size=365, code size=105\", \"3]\\n70: JIT compiled StartupHookProvider:get_IsSupported():bool [Tier0, IL size=18, code\\nsize=60]\\n71:\", \" JIT compiled AppContext:TryGetSwitch(String,byref):bool [Tier0, IL size=97, code\\nsize=322]\\n72: JIT \", \"compiled ArgumentException:ThrowIfNullOrEmpty(String,String) [Tier0, IL size=16,\\ncode size=53]\\n73: J\", \"IT compiled String:IsNullOrEmpty(String):bool [Tier0, IL size=15, code size=58]\\n74: JIT compiled App\", \"Context:GetData(String):Object [Tier0, IL size=64, code size=205]\\n75: JIT compiled ArgumentNullExcep\", \"tion:ThrowIfNull(Object,String) [Tier0, IL size=10,\\ncode size=42]\\n76: JIT compiled Monitor:Enter(Obj\", \"ect,byref) [Tier0, IL size=17, code size=55]\\n7 CHAPTER 2 | JIT77: JIT compiled Dictionary`2:TryGetVa\", \"lue(__Canon,byref):bool:this [Tier0, IL size=39,\\ncode size=97]\\n78: JIT compiled Dictionary`2:FindVal\", \"ue(__Canon):byref:this [Tier0, IL size=391, code\\nsize=1466]\\n79: JIT compiled EventSource:.cctor() [T\", \"ier0, IL size=34, code size=80]\\n80: JIT compiled EventSource:InitializeIsSupported():bool [Tier0, IL\", \" size=18, code\\nsize=60]\\n81: JIT compiled RuntimeEventSource:.ctor():this [Tier0, IL size=55, code si\", \"ze=184]\\n82: JIT compiled\\nGuid:.ctor(int,short,short,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte)\", \":this [Tier0, IL\\nsize=86, code size=132]\\n83: JIT compiled EventSource:.ctor(Guid,String):this [Tier0\", \", IL size=11, code size=90]\\n84: JIT compiled EventSource:.ctor(Guid,String,int,ref):this [Tier0, IL \", \"size=58, code\\nsize=187]\\n85: JIT compiled EventSource:get_IsSupported():bool [Tier0, IL size=6, code \", \"size=11]\\n86: JIT compiled TraceLoggingEventHandleTable:.ctor():this [Tier0, IL size=20, code\\nsize=67\", \"]\\n87: JIT compiled EventSource:ValidateSettings(int):int [Tier0, IL size=37, code size=147]\\n88: JIT \", \"compiled EventSource:Initialize(Guid,String,ref):this [Tier0, IL size=418, code\\nsize=1584]\\n89: JIT c\", \"ompiled Guid:op_Equality(Guid,Guid):bool [Tier0, IL size=10, code size=39]\\n90: JIT compiled Guid:Equ\", \"alsCore(byref,byref):bool [Tier0, IL size=132, code size=171]\\n91: JIT compiled ActivityTracker:get_I\", \"nstance():ActivityTracker [Tier0, IL size=6, code\\nsize=49]\\n92: JIT compiled ActivityTracker:.cctor()\", \" [Tier0, IL size=11, code size=71]\\n93: JIT compiled ActivityTracker:.ctor():this [Tier0, IL size=7, \", \"code size=31]\\n94: JIT compiled RuntimeEventSource:get_ProviderMetadata():ReadOnlySpan`1:this [Tier0,\", \" IL\\nsize=13, code size=91]\\n95: JIT compiled ReadOnlySpan`1:.ctor(long,int):this [Tier0, IL size=51, \", \"code size=115]\\n96: JIT compiled RuntimeHelpers:IsReferenceOrContainsReferences():bool [Tier0, IL siz\", \"e=2,\\ncode size=8]\\n97: JIT compiled ReadOnlySpan`1:get_Length():int:this [Tier0, IL size=7, code size\", \"=17]\\n98: JIT compiled OverrideEventProvider:.ctor(EventSource,int):this [Tier0, IL size=22,\\ncode siz\", \"e=68]\\n99: JIT compiled EventProvider:.ctor(int):this [Tier0, IL size=46, code size=194]\\n100: JIT com\", \"piled EtwEventProvider:.ctor():this [Tier0, IL size=7, code size=31]\\n101: JIT compiled EventProvider\", \":Register(EventSource):this [Tier0, IL size=48, code\\nsize=186]\\n102: JIT compiled MulticastDelegate:C\", \"torClosed(Object,long):this [Tier0, IL size=23, code\\nsize=70]\\n103: JIT compiled EventProvider:EventR\", \"egister(EventSource,EtwEnableCallback):int:this\\n[Tier0, IL size=53, code size=154]\\n104: JIT compiled\", \" EventSource:get_Name():String:this [Tier0, IL size=7, code size=18]\\n105: JIT compiled EventSource:g\", \"et_Guid():Guid:this [Tier0, IL size=7, code size=41]\\n106: JIT compiled\\nEtwEventProvider:System.Diagn\", \"ostics.Tracing.IEventProvider.EventRegister(EventSource,EtwEna\\nbleCallback,long,byref):int:this [Tie\", \"r0, IL size=19, code size=71]\\n107: JIT compiled Advapi32:EventRegister(byref,EtwEnableCallback,long,\", \"byref):int [Tier0,\\nIL size=53, code size=374]\\n108: JIT compiled Marshal:GetFunctionPointerForDelegat\", \"e(__Canon):long [Tier0, IL size=17,\\ncode size=54]\\n109: JIT compiled Marshal:GetFunctionPointerForDel\", \"egate(Delegate):long [Tier0, IL size=18,\\ncode size=53]\\n110: JIT compiled EventPipeEventProvider:.cto\", \"r():this [Tier0, IL size=18, code size=41]\\n111: JIT compiled EventListener:get_EventListenersLock():\", \"Object [Tier0, IL size=41, code\\nsize=157]\\n112: JIT compiled List`1:.ctor(int):this [Tier0, IL size=4\", \"7, code size=275]\\n113: JIT compiled Interlocked:CompareExchange(byref,__Canon,__Canon):__Canon [Tier\", \"0, IL\\nsize=9, code size=50]\\n114: JIT compiled NativeRuntimeEventSource:.cctor() [Tier0, IL size=11, \", \"code size=71]\\n115: JIT compiled NativeRuntimeEventSource:.ctor():this [Tier0, IL size=63, code size=\", \"184]\\n8 CHAPTER 2 | JIT116: JIT compiled\\nGuid:.ctor(int,ushort,ushort,ubyte,ubyte,ubyte,ubyte,ubyte,u\", \"byte,ubyte,ubyte):this [Tier0,\\nIL size=88, code size=132]\\n117: JIT compiled NativeRuntimeEventSource\", \":get_ProviderMetadata():ReadOnlySpan`1:this\\n[Tier0, IL size=13, code size=91]\\n118: JIT compiled\\nEven\", \"tPipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventRegister(EventSource,\\nEtwEnableCal\", \"lback,long,byref):int:this [Tier0, IL size=44, code size=118]\\n119: JIT compiled EventPipeInternal:Cr\", \"eateProvider(String,EtwEnableCallback):long [Tier0,\\nIL size=43, code size=320]\\n120: JIT compiled Utf\", \"16StringMarshaller:GetPinnableReference(String):byref [Tier0, IL\\nsize=13, code size=50]\\n121: JIT com\", \"piled String:GetPinnableReference():byref:this [Tier0, IL size=7, code\\nsize=24]\\n122: JIT compiled Ev\", \"entListener:AddEventSource(EventSource) [Tier0, IL size=175, code\\nsize=560]\\n123: JIT compiled List`1\", \":get_Count():int:this [Tier0, IL size=7, code size=17]\\n124: JIT compiled WeakReference`1:.ctor(__Can\", \"on):this [Tier0, IL size=9, code size=42]\\n125: JIT compiled WeakReference`1:.ctor(__Canon,bool):this\", \" [Tier0, IL size=15, code\\nsize=60]\\n126: JIT compiled List`1:Add(__Canon):this [Tier0, IL size=60, co\", \"de size=124]\\n127: JIT compiled String:op_Inequality(String,String):bool [Tier0, IL size=11, code\\nsiz\", \"e=46]\\n128: JIT compiled String:Equals(String,String):bool [Tier0, IL size=36, code size=114]\\n129: JI\", \"T compiled ReadOnlySpan`1:GetPinnableReference():byref:this [Tier0, IL size=23,\\ncode size=57]\\n130: J\", \"IT compiled EventProvider:SetInformation(int,long,int):int:this [Tier0, IL size=38,\\ncode size=131]\\n1\", \"31: JIT compiled ILStubClass:IL_STUB_PInvoke(long,int,long,int):int [FullOpts, IL\\nsize=62, code size\", \"=170]\\n132: JIT compiled Program:Main() [Tier0, IL size=11, code size=36]\\n133: JIT compiled Console:W\", \"riteLine(String) [Tier0, IL size=12, code size=59]\\n134: JIT compiled Console:get_Out():TextWriter [T\", \"ier0, IL size=20, code size=113]\\n135: JIT compiled Console:.cctor() [Tier0, IL size=11, code size=71\", \"]\\n136: JIT compiled Volatile:Read(byref):__Canon [Tier0, IL size=6, code size=21]\\n137: JIT compiled \", \"Console:<get_Out>g__EnsureInitialized|26_0():TextWriter [Tier0, IL\\nsize=63, code size=209]\\n138: JIT \", \"compiled ConsolePal:OpenStandardOutput():Stream [Tier0, IL size=34, code\\nsize=130]\\n139: JIT compiled\", \" Console:get_OutputEncoding():Encoding [Tier0, IL size=72, code size=237]\\n140: JIT compiled ConsoleP\", \"al:get_OutputEncoding():Encoding [Tier0, IL size=11, code\\nsize=200]\\n141: JIT compiled NativeLibrary:\", \"LoadLibraryCallbackStub(String,Assembly,bool,int):long\\n[Tier0, IL size=63, code size=280]\\n142: JIT c\", \"ompiled EncodingHelper:GetSupportedConsoleEncoding(int):Encoding [Tier0, IL\\nsize=53, code size=186]\\n\", \"143: JIT compiled Encoding:GetEncoding(int):Encoding [Tier0, IL size=340, code size=1025]\\n144: JIT c\", \"ompiled EncodingProvider:GetEncodingFromProvider(int):Encoding [Tier0, IL\\nsize=51, code size=232]\\n14\", \"5: JIT compiled Encoding:FilterDisallowedEncodings(Encoding):Encoding [Tier0, IL\\nsize=29, code size=\", \"84]\\n146: JIT compiled LocalAppContextSwitches:get_EnableUnsafeUTF7Encoding():bool [Tier0, IL\\nsize=16\", \", code size=46]\\n147: JIT compiled LocalAppContextSwitches:GetCachedSwitchValue(String,byref):bool [T\", \"ier0,\\nIL size=22, code size=76]\\n148: JIT compiled LocalAppContextSwitches:GetCachedSwitchValueIntern\", \"al(String,byref):bool\\n[Tier0, IL size=46, code size=168]\\n149: JIT compiled LocalAppContextSwitches:G\", \"etSwitchDefaultValue(String):bool [Tier0, IL\\nsize=32, code size=98]\\n150: JIT compiled String:op_Equa\", \"lity(String,String):bool [Tier0, IL size=8, code size=39]\\n151: JIT compiled Encoding:get_Default():E\", \"ncoding [Tier0, IL size=6, code size=49]\\n9 CHAPTER 2 | JIT152: JIT compiled Encoding:.cctor() [Tier0\", \", IL size=12, code size=73]\\n153: JIT compiled UTF8EncodingSealed:.ctor(bool):this [Tier0, IL size=8,\", \" code size=40]\\n154: JIT compiled UTF8Encoding:.ctor(bool):this [Tier0, IL size=14, code size=43]\\n155\", \": JIT compiled UTF8Encoding:.ctor():this [Tier0, IL size=12, code size=36]\\n156: JIT compiled Encodin\", \"g:.ctor(int):this [Tier0, IL size=42, code size=152]\\n157: JIT compiled UTF8Encoding:SetDefaultFallba\", \"cks():this [Tier0, IL size=64, code\\nsize=212]\\n158: JIT compiled EncoderReplacementFallback:.ctor(Str\", \"ing):this [Tier0, IL size=110, code\\nsize=360]\\n159: JIT compiled EncoderFallback:.ctor():this [Tier0,\", \" IL size=7, code size=31]\\n160: JIT compiled String:get_Chars(int):ushort:this [Tier0, IL size=29, co\", \"de size=61]\\n161: JIT compiled Char:IsSurrogate(ushort):bool [Tier0, IL size=17, code size=43]\\n162: J\", \"IT compiled Char:IsBetween(ushort,ushort,ushort):bool [Tier0, IL size=12, code\\nsize=52]\\n163: JIT com\", \"piled DecoderReplacementFallback:.ctor(String):this [Tier0, IL size=110, code\\nsize=360]\\n164: JIT com\", \"piled DecoderFallback:.ctor():this [Tier0, IL size=7, code size=31]\\n165: JIT compiled Encoding:get_C\", \"odePage():int:this [Tier0, IL size=7, code size=17]\\n166: JIT compiled Encoding:get_UTF8():Encoding [\", \"Tier0, IL size=6, code size=49]\\n167: JIT compiled UTF8Encoding:.cctor() [Tier0, IL size=12, code siz\", \"e=76]\\n168: JIT compiled Volatile:Write(byref,__Canon) [Tier0, IL size=6, code size=32]\\n169: JIT comp\", \"iled ConsolePal:GetStandardFile(int,int,bool):Stream [Tier0, IL size=50, code\\nsize=183]\\n170: JIT com\", \"piled ConsolePal:get_InvalidHandleValue():long [Tier0, IL size=7, code\\nsize=41]\\n171: JIT compiled In\", \"tPtr:.ctor(int):this [Tier0, IL size=9, code size=25]\\n172: JIT compiled ConsolePal:ConsoleHandleIsWr\", \"itable(long):bool [Tier0, IL size=26, code\\nsize=68]\\n173: JIT compiled Kernel32:WriteFile(long,long,i\", \"nt,byref,long):int [Tier0, IL size=46,\\ncode size=294]\\n174: JIT compiled Marshal:SetLastSystemError(i\", \"nt) [Tier0, IL size=7, code size=40]\\n175: JIT compiled Marshal:GetLastSystemError():int [Tier0, IL s\", \"ize=6, code size=34]\\n176: JIT compiled WindowsConsoleStream:.ctor(long,int,bool):this [Tier0, IL siz\", \"e=37, code\\nsize=90]\\n177: JIT compiled ConsoleStream:.ctor(int):this [Tier0, IL size=31, code size=71\", \"]\\n178: JIT compiled Stream:.ctor():this [Tier0, IL size=7, code size=31]\\n179: JIT compiled MarshalBy\", \"RefObject:.ctor():this [Tier0, IL size=7, code size=31]\\n180: JIT compiled Kernel32:GetFileType(long)\", \":int [Tier0, IL size=27, code size=217]\\n181: JIT compiled Console:CreateOutputWriter(Stream):TextWri\", \"ter [Tier0, IL size=50, code\\nsize=230]\\n182: JIT compiled Stream:.cctor() [Tier0, IL size=11, code si\", \"ze=71]\\n183: JIT compiled NullStream:.ctor():this [Tier0, IL size=7, code size=31]\\n184: JIT compiled \", \"EncodingExtensions:RemovePreamble(Encoding):Encoding [Tier0, IL size=25,\\ncode size=118]\\n185: JIT com\", \"piled UTF8EncodingSealed:get_Preamble():ReadOnlySpan`1:this [Tier0, IL\\nsize=24, code size=99]\\n186: J\", \"IT compiled UTF8Encoding:get_PreambleSpan():ReadOnlySpan`1 [Tier0, IL size=12, code\\nsize=87]\\n187: JI\", \"T compiled ConsoleEncoding:.ctor(Encoding):this [Tier0, IL size=14, code size=52]\\n188: JIT compiled \", \"Encoding:.ctor():this [Tier0, IL size=8, code size=33]\\n189: JIT compiled Encoding:SetDefaultFallback\", \"s():this [Tier0, IL size=23, code size=65]\\n190: JIT compiled EncoderFallback:get_ReplacementFallback\", \"():EncoderFallback [Tier0, IL\\nsize=6, code size=49]\\n191: JIT compiled EncoderReplacementFallback:.cc\", \"tor() [Tier0, IL size=11, code size=71]\\n192: JIT compiled EncoderReplacementFallback:.ctor():this [T\", \"ier0, IL size=12, code\\nsize=44]\\n193: JIT compiled DecoderFallback:get_ReplacementFallback():DecoderF\", \"allback [Tier0, IL\\nsize=6, code size=49]\\n194: JIT compiled DecoderReplacementFallback:.cctor() [Tier\", \"0, IL size=11, code size=71]\\n195: JIT compiled DecoderReplacementFallback:.ctor():this [Tier0, IL si\", \"ze=12, code\\nsize=44]\\n10 CHAPTER 2 | JIT196: JIT compiled StreamWriter:.ctor(Stream,Encoding,int,bool\", \"):this [Tier0, IL size=201,\\ncode size=564]\\n197: JIT compiled Task:get_CompletedTask():Task [Tier0, I\", \"L size=6, code size=49]\\n198: JIT compiled Task:.cctor() [Tier0, IL size=76, code size=316]\\n199: JIT \", \"compiled TaskFactory:.ctor():this [Tier0, IL size=7, code size=31]\\n200: JIT compiled Task`1:.ctor(bo\", \"ol,VoidTaskResult,int,CancellationToken):this [Tier0, IL\\nsize=21, code size=75]\\n201: JIT compiled Ta\", \"sk:.ctor(bool,int,CancellationToken):this [Tier0, IL size=70, code\\nsize=181]\\n202: JIT compiled <>c:.\", \"cctor() [Tier0, IL size=11, code size=71]\\n203: JIT compiled <>c:.ctor():this [Tier0, IL size=7, code\", \" size=31]\\n204: JIT compiled TextWriter:.ctor(IFormatProvider):this [Tier0, IL size=36, code\\nsize=124\", \"]\\n205: JIT compiled TextWriter:.cctor() [Tier0, IL size=26, code size=108]\\n206: JIT compiled NullTex\", \"tWriter:.ctor():this [Tier0, IL size=7, code size=31]\\n207: JIT compiled TextWriter:.ctor():this [Tie\", \"r0, IL size=29, code size=103]\\n208: JIT compiled String:ToCharArray():ref:this [Tier0, IL size=52, c\", \"ode size=173]\\n209: JIT compiled MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, co\", \"de\\nsize=24]\\n210: JIT compiled ConsoleStream:get_CanWrite():bool:this [Tier0, IL size=7, code size=18\", \"]\\n211: JIT compiled ConsoleEncoding:GetEncoder():Encoder:this [Tier0, IL size=12, code\\nsize=57]\\n212:\", \" JIT compiled UTF8Encoding:GetEncoder():Encoder:this [Tier0, IL size=7, code size=63]\\n213: JIT compi\", \"led EncoderNLS:.ctor(Encoding):this [Tier0, IL size=37, code size=102]\\n214: JIT compiled Encoder:.ct\", \"or():this [Tier0, IL size=7, code size=31]\\n215: JIT compiled Encoding:get_EncoderFallback():EncoderF\", \"allback:this [Tier0, IL size=7,\\ncode size=18]\\n216: JIT compiled EncoderNLS:Reset():this [Tier0, IL s\", \"ize=24, code size=92]\\n217: JIT compiled ConsoleStream:get_CanSeek():bool:this [Tier0, IL size=2, cod\", \"e size=12]\\n218: JIT compiled StreamWriter:set_AutoFlush(bool):this [Tier0, IL size=25, code size=72]\", \"\\n219: JIT compiled StreamWriter:CheckAsyncTaskInProgress():this [Tier0, IL size=19, code\\nsize=47]\\n22\", \"0: JIT compiled Task:get_IsCompleted():bool:this [Tier0, IL size=16, code size=40]\\n221: JIT compiled\", \" Task:IsCompletedMethod(int):bool [Tier0, IL size=11, code size=25]\\n222: JIT compiled StreamWriter:F\", \"lush(bool,bool):this [Tier0, IL size=272, code size=1127]\\n223: JIT compiled StreamWriter:ThrowIfDisp\", \"osed():this [Tier0, IL size=15, code size=43]\\n224: JIT compiled Encoding:get_Preamble():ReadOnlySpan\", \"`1:this [Tier0, IL size=12, code\\nsize=70]\\n225: JIT compiled ConsoleEncoding:GetPreamble():ref:this [\", \"Tier0, IL size=6, code size=27]\\n226: JIT compiled Array:Empty():ref [Tier0, IL size=6, code size=49]\", \"\\n227: JIT compiled EmptyArray`1:.cctor() [Tier0, IL size=12, code size=52]\\n228: JIT compiled ReadOnl\", \"ySpan`1:op_Implicit(ref):ReadOnlySpan`1 [Tier0, IL size=7, code\\nsize=79]\\n229: JIT compiled ReadOnlyS\", \"pan`1:.ctor(ref):this [Tier0, IL size=33, code size=81]\\n230: JIT compiled MemoryMarshal:GetArrayData\", \"Reference(ref):byref [Tier0, IL size=7, code\\nsize=24]\\n231: JIT compiled ConsoleEncoding:GetMaxByteCo\", \"unt(int):int:this [Tier0, IL size=13, code\\nsize=63]\\n232: JIT compiled UTF8EncodingSealed:GetMaxByteC\", \"ount(int):int:this [Tier0, IL size=20,\\ncode size=50]\\n233: JIT compiled Span`1:.ctor(long,int):this [\", \"Tier0, IL size=51, code size=115]\\n234: JIT compiled ReadOnlySpan`1:.ctor(ref,int,int):this [Tier0, I\", \"L size=65, code\\nsize=147]\\n235: JIT compiled Encoder:GetBytes(ReadOnlySpan`1,Span`1,bool):int:this [T\", \"ier0, IL\\nsize=44, code size=234]\\n236: JIT compiled MemoryMarshal:GetNonNullPinnableReference(ReadOnl\", \"ySpan`1):byref [Tier0,\\nIL size=30, code size=54]\\n237: JIT compiled ReadOnlySpan`1:get_Length():int:t\", \"his [Tier0, IL size=7, code size=17]\\n238: JIT compiled MemoryMarshal:GetNonNullPinnableReference(Spa\", \"n`1):byref [Tier0, IL\\nsize=30, code size=54]\\n239: JIT compiled Span`1:get_Length():int:this [Tier0, \", \"IL size=7, code size=17]\\n11 CHAPTER 2 | JIT240: JIT compiled EncoderNLS:GetBytes(long,int,long,int,b\", \"ool):int:this [Tier0, IL size=92,\\ncode size=279]\\n241: JIT compiled ArgumentNullException:ThrowIfNull\", \"(long,String) [Tier0, IL size=12, code\\nsize=45]\\n242: JIT compiled Encoding:GetBytes(long,int,long,in\", \"t,EncoderNLS):int:this [Tier0, IL\\nsize=57, code size=187]\\n243: JIT compiled EncoderNLS:get_HasLeftov\", \"erData():bool:this [Tier0, IL size=35, code\\nsize=105]\\n244: JIT compiled UTF8Encoding:GetBytesFast(lo\", \"ng,int,long,int,byref):int:this [Tier0, IL\\nsize=33, code size=119]\\n245: JIT compiled Utf8Utility:Tra\", \"nscodeToUtf8(long,int,long,int,byref,byref):int [Tier0,\\nIL size=1446, code size=3208]\\n246: JIT compi\", \"led Math:Min(int,int):int [Tier0, IL size=8, code size=28]\\n247: JIT compiled ASCIIUtility:NarrowUtf1\", \"6ToAscii(long,long,long):long [Tier0, IL\\nsize=490, code size=1187]\\n248: JIT compiled WindowsConsoleS\", \"tream:Flush():this [Tier0, IL size=26, code size=56]\\n249: JIT compiled ConsoleStream:Flush():this [T\", \"ier0, IL size=1, code size=10]\\n250: JIT compiled TextWriter:Synchronized(TextWriter):TextWriter [Tie\", \"r0, IL size=28, code\\nsize=121]\\n251: JIT compiled SyncTextWriter:.ctor(TextWriter):this [Tier0, IL si\", \"ze=14, code size=52]\\n252: JIT compiled SyncTextWriter:WriteLine(String):this [Tier0, IL size=13, cod\", \"e size=140]\\n253: JIT compiled StreamWriter:WriteLine(String):this [Tier0, IL size=20, code size=110]\", \"\\n254: JIT compiled String:op_Implicit(String):ReadOnlySpan`1 [Tier0, IL size=31, code\\nsize=171]\\n255:\", \" JIT compiled String:GetRawStringData():byref:this [Tier0, IL size=7, code size=24]\\n256: JIT compile\", \"d ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, code size=39]\\n257: JIT compiled StreamWri\", \"ter:WriteSpan(ReadOnlySpan`1,bool):this [Tier0, IL size=368,\\ncode size=1036]\\n258: JIT compiled Memor\", \"yMarshal:GetReference(ReadOnlySpan`1):byref [Tier0, IL size=8, code\\nsize=17]\\n259: JIT compiled Buffe\", \"r:MemoryCopy(long,long,long,long) [Tier0, IL size=21, code size=83]\\n260: JIT compiled Unsafe:ReadUna\", \"ligned(long):long [Tier0, IL size=10, code size=17]\\n261: JIT compiled ASCIIUtility:AllCharsInUInt64A\", \"reAscii(long):bool [Tier0, IL size=16,\\ncode size=38]\\n262: JIT compiled ASCIIUtility:NarrowFourUtf16C\", \"harsToAsciiAndWriteToBuffer(byref,long)\\n[Tier0, IL size=107, code size=171]\\n263: JIT compiled Unsafe\", \":WriteUnaligned(byref,int) [Tier0, IL size=11, code size=22]\\n264: JIT compiled Unsafe:ReadUnaligned(\", \"long):int [Tier0, IL size=10, code size=16]\\n265: JIT compiled ASCIIUtility:AllCharsInUInt32AreAscii(\", \"int):bool [Tier0, IL size=11, code\\nsize=25]\\n266: JIT compiled ASCIIUtility:NarrowTwoUtf16CharsToAsci\", \"iAndWriteToBuffer(byref,int)\\n[Tier0, IL size=24, code size=35]\\n267: JIT compiled Span`1:Slice(int,in\", \"t):Span`1:this [Tier0, IL size=39, code size=135]\\n268: JIT compiled Span`1:.ctor(byref,int):this [Ti\", \"er0, IL size=15, code size=39]\\n269: JIT compiled Span`1:op_Implicit(Span`1):ReadOnlySpan`1 [Tier0, I\", \"L size=19, code\\nsize=90]\\n270: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, \", \"code size=39]\\n271: JIT compiled WindowsConsoleStream:Write(ReadOnlySpan`1):this [Tier0, IL size=35, \", \"code\\nsize=149]\\n272: JIT compiled WindowsConsoleStream:WriteFileNative(long,ReadOnlySpan`1,bool):int\\n\", \"[Tier0, IL size=107, code size=272]\\n273: JIT compiled ReadOnlySpan`1:get_IsEmpty():bool:this [Tier0,\", \" IL size=10, code size=24]\\nHello, world!\\n274: JIT compiled AppContext:OnProcessExit() [Tier0, IL siz\", \"e=43, code size=161]\\n275: JIT compiled AssemblyLoadContext:OnProcessExit() [Tier0, IL size=101, code\", \" size=442]\\n276: JIT compiled EventListener:DisposeOnShutdown() [Tier0, IL size=150, code size=618]\\n2\", \"77: JIT compiled List`1:.ctor():this [Tier0, IL size=18, code size=133]\\n278: JIT compiled List`1:.cc\", \"tor() [Tier0, IL size=12, code size=129]\\n279: JIT compiled List`1:GetEnumerator():Enumerator:this [T\", \"ier0, IL size=7, code size=162]\\n280: JIT compiled Enumerator:.ctor(List`1):this [Tier0, IL size=39, \", \"code size=64]\\n281: JIT compiled Enumerator:MoveNext():bool:this [Tier0, IL size=81, code size=159]\\n1\", \"2 CHAPTER 2 | JIT282: JIT compiled Enumerator:get_Current():__Canon:this [Tier0, IL size=7, code siz\", \"e=22]\\n283: JIT compiled WeakReference`1:TryGetTarget(byref):bool:this [Tier0, IL size=24, code\\nsize=\", \"66]\\n284: JIT compiled List`1:AddWithResize(__Canon):this [Tier0, IL size=39, code size=85]\\n285: JIT \", \"compiled List`1:Grow(int):this [Tier0, IL size=53, code size=121]\\n286: JIT compiled List`1:set_Capac\", \"ity(int):this [Tier0, IL size=86, code size=342]\\n287: JIT compiled CastHelpers:StelemRef_Helper(byre\", \"f,long,Object) [Tier0, IL size=34, code\\nsize=104]\\n288: JIT compiled CastHelpers:StelemRef_Helper_NoC\", \"acheLookup(byref,long,Object) [Tier0, IL\\nsize=26, code size=111]\\n289: JIT compiled Enumerator:MoveNe\", \"xtRare():bool:this [Tier0, IL size=57, code size=80]\\n290: JIT compiled Enumerator:Dispose():this [Ti\", \"er0, IL size=1, code size=14]\\n291: JIT compiled EventSource:Dispose():this [Tier0, IL size=14, code \", \"size=54]\\n292: JIT compiled EventSource:Dispose(bool):this [Tier0, IL size=124, code size=236]\\n293: J\", \"IT compiled EventProvider:Dispose():this [Tier0, IL size=14, code size=54]\\n294: JIT compiled EventPr\", \"ovider:Dispose(bool):this [Tier0, IL size=90, code size=230]\\n295: JIT compiled EventProvider:EventUn\", \"register(long):this [Tier0, IL size=14, code\\nsize=50]\\n296: JIT compiled\\nEtwEventProvider:System.Diag\", \"nostics.Tracing.IEventProvider.EventUnregister(long):int:this\\n[Tier0, IL size=7, code size=181]\\n297:\", \" JIT compiled GC:SuppressFinalize(Object) [Tier0, IL size=18, code size=53]\\n298: JIT compiled\\nEventP\", \"ipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventUnregister(long):int:\\nthis [Tier0, I\", \"L size=13, code size=187]\\nWith that out of the way, let\\u2019s move on to actual performance improvements\", \", starting with on-stack\\nreplacement.\\nOn-Stack Replacement\\nOn-stack replacement (OSR) is one of the \", \"coolest features to hit the JIT in .NET 7. But to really\\nunderstand OSR, we first need to understand\", \" tiered compilation, so a quick recap\\u2026\\nOne of the issues a managed environment with a JIT compiler h\", \"as to deal with is tradeoffs between\\nstartup and throughput. Historically, the job of an optimizing \", \"compiler is to, well, optimize, in order to\\nenable the best possible throughput of the application o\", \"r service once running. But such optimization\\ntakes analysis, takes time, and performing all of that\", \" work then leads to increased startup time, as all\\nof the code on the startup path (e.g. all of the \", \"code that needs to be run before a web server can\\nserve the first request) needs to be compiled. So \", \"a JIT compiler needs to make tradeoffs: better\\nthroughput at the expense of longer startup time, or \", \"better startup time at the expense of decreased\\nthroughput. For some kinds of apps and services, the\", \" tradeoff is an easy call, e.g. if your service starts\\nup once and then runs for days, several extra\", \" seconds of startup time doesn\\u2019t matter, or if you\\u2019re a\\nconsole application that\\u2019s going to do a qui\", \"ck computation and exit, startup time is all that matters.\\nBut how can the JIT know which scenario i\", \"t\\u2019s in, and do we really want every developer having to\\nknow about these kinds of settings and trade\", \"offs and configure every one of their applications\\naccordingly? One answer to this has been ahead-of\", \"-time compilation, which has taken various forms\\nin .NET. For example, all of the core libraries are\", \" \\u201ccrossgen\\u201d\\u2019d, meaning they\\u2019ve been run through a\\ntool that produces the previously mentioned R2R fo\", \"rmat, yielding binaries that contain assembly code\\nthat needs only minor tweaks to actually execute;\", \" not every method can have code generated for it,\\nbut enough that it significantly reduces startup t\", \"ime. Of course, such approaches have their own\\ndownsides, e.g. one of the promises of a JIT compiler\", \" is it can take advantage of knowledge of the\\ncurrent machine / process in order to best optimize, s\", \"o for example the R2R images have to assume a\\n13 CHAPTER 2 | JITcertain baseline instruction set (e.\", \"g. what vectorizing instructions are available) whereas the JIT can see\\nwhat\\u2019s actually available an\", \"d use the best. \\u201cTiered compilation\\u201d provides another answer, one that\\u2019s\\nusable with or without thes\", \"e other ahead-of-time (AOT) compilation solutions.\\nTiered compilation enables the JIT to have its pr\", \"overbial cake and eat it, too. The idea is simple: allow\\nthe JIT to compile the same code multiple t\", \"imes. The first time, the JIT can use as a few optimizations\\nas make sense (a handful of optimizatio\", \"ns can actually make the JIT\\u2019s own throughput faster, so those\\nstill make sense to apply), producing\", \" fairly unoptimized assembly code but doing so really quickly.\\nAnd when it does so, it can add some \", \"instrumentation into the assembly to track how often the\\nmethods are called. As it turns out, many f\", \"unctions used on a startup path are invoked once or maybe\\nonly a handful of times, and it would take\", \" more time to optimize them than it does to just execute\\nthem unoptimized. Then, when the method\\u2019s i\", \"nstrumentation triggers some threshold, for example a\\nmethod having been executed 30 times, a work i\", \"tem gets queued to recompile that method, but this\\ntime with all the optimizations the JIT can throw\", \" at it. This is lovingly referred to as \\u201ctiering up.\\u201d Once\\nthat recompilation has completed, call si\", \"tes to the method are patched with the address of the newly\\nhighly optimized assembly code, and futu\", \"re invocations will then take the fast path. So, we get faster\\nstartup and faster sustained throughp\", \"ut. At least, that\\u2019s the hope.\\nA problem, however, is methods that don\\u2019t fit this mold. While it\\u2019s c\", \"ertainly the case that many\\nperformance-sensitive methods are relatively quick and executed many, ma\", \"ny, many times, there\\u2019s\\nalso a large number of performance-sensitive methods that are executed just \", \"a handful of times, or\\nmaybe even only once, but that take a very long time to execute, maybe even t\", \"he duration of the\\nwhole process: methods with loops. As a result, by default tiered compilation has\", \"n\\u2019t applied to loops,\\nthough it can be enabled by setting the DOTNET_TC_QuickJitForLoops environment\", \" variable to 1. We\\ncan see the effect of this by trying this simple console app with .NET 6. With th\", \"e default settings, run\\nthis app:\\nclass Program\\n{\\nstatic void Main()\\n{\\nvar sw = new System.Diagnosti\", \"cs.Stopwatch();\\nwhile (true)\\n{\\nsw.Restart();\\nfor (int trial = 0; trial < 10_000; trial++)\\n{\\nint coun\", \"t = 0;\\nfor (int i = 0; i < char.MaxValue; i++)\\nif (IsAsciiDigit((char)i))\\ncount++;\\n}\\nsw.Stop();\\nCons\", \"ole.WriteLine(sw.Elapsed);\\n}\\nstatic bool IsAsciiDigit(char c) => (uint)(c - '0') <= 9;\\n}\\n}\\nI get num\", \"bers printed out like:\\n14 CHAPTER 2 | JIT00:00:00.5734352\\n00:00:00.5526667\\n00:00:00.5675267\\n00:00:00\", \".5588724\\n00:00:00.5616028\\nNow, try setting DOTNET_TC_QuickJitForLoops to 1. When I then run it again\", \", I get numbers like this:\\n00:00:01.2841397\\n00:00:01.2693485\\n00:00:01.2755646\\n00:00:01.2656678\\n00:00\", \":01.2679925\\nIn other words, with DOTNET_TC_QuickJitForLoops enabled, it\\u2019s taking 2.5x as long as wit\", \"hout (the\\ndefault in .NET 6). That\\u2019s because this main function never gets optimizations applied to \", \"it. By setting\\nDOTNET_TC_QuickJitForLoops to 1, we\\u2019re saying \\u201cJIT, please apply tiering to methods w\", \"ith loops as\\nwell,\\u201d but this method with a loop is only ever invoked once, so for the duration of th\", \"e process it ends\\nup remaining at \\u201ctier-0,\\u201d aka unoptimized. Now, let\\u2019s try the same thing with .NET\", \" 7. Regardless of\\nwhether that environment variable is set, I again get numbers like this:\\n00:00:00.\", \"5528889\\n00:00:00.5562563\\n00:00:00.5622086\\n00:00:00.5668220\\n00:00:00.5589112\\nbut importantly, this me\", \"thod was still participating in tiering. In fact, we can get confirmation of that\\nby using the afore\", \"mentioned DOTNET_JitDisasmSummary=1 environment variable. When I set that and\\nrun again, I see these\", \" lines in the output:\\n4: JIT compiled Program:Main() [Tier0, IL size=83, code size=319]\\n...\\n6: JIT c\", \"ompiled Program:Main() [Tier1-OSR @0x27, IL size=83, code size=380]\\nhighlighting that Main was indee\", \"d compiled twice. How is that possible? On-stack replacement.\\nThe idea behind on-stack replacement i\", \"s a method can be replaced not just between invocations but\\neven while it\\u2019s executing, while it\\u2019s \\u201co\", \"n the stack.\\u201d In addition to the tier-0 code being instrumented\\nfor call counts, loops are also inst\", \"rumented for iteration counts. When the iterations surpass a certain\\nlimit, the JIT compiles a new h\", \"ighly optimized version of that method, transfers all the local/register\\nstate from the current invo\", \"cation to the new invocation, and then jumps to the appropriate location in\\nthe new method. We can s\", \"ee this in action by using the previously discussed DOTNET_JitDisasm\\nenvironment variable. Set that \", \"to Program:* in order to see the assembly code generated for all of the\\nmethods in the Program class\", \", and then run the app again. You should see output like the following:\\n; Assembly listing for metho\", \"d Program:Main()\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; MinOp\", \"ts code\\n; rbp based frame\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n55 push rbp\\n15 CHAP\", \"TER 2 | JIT4881EC80000000 sub rsp, 128\\n488DAC2480000000 lea rbp, [rsp+80H]\\nC5D857E4 vxorps xmm4, xmm\", \"4\\nC5F97F65B0 vmovdqa xmmword ptr [rbp-50H], xmm4\\n33C0 xor eax, eax\\n488945C0 mov qword ptr [rbp-40H],\", \" rax\\nG_M000_IG02: ;; offset=001FH\\n48B9002F0B50FC7F0000 mov rcx, 0x7FFC500B2F00\\nE8721FB25F call CORIN\", \"FO_HELP_NEWSFAST\\n488945B0 mov gword ptr [rbp-50H], rax\\n488B4DB0 mov rcx, gword ptr [rbp-50H]\\nFF1544C\", \"70D00 call [Stopwatch:.ctor():this]\\n488B4DB0 mov rcx, gword ptr [rbp-50H]\\n48894DC0 mov gword ptr [rb\", \"p-40H], rcx\\nC745A8E8030000 mov dword ptr [rbp-58H], 0x3E8\\nG_M000_IG03: ;; offset=004BH\\n8B4DA8 mov ec\", \"x, dword ptr [rbp-58H]\\nFFC9 dec ecx\\n894DA8 mov dword ptr [rbp-58H], ecx\\n837DA800 cmp dword ptr [rbp-\", \"58H], 0\\n7F0E jg SHORT G_M000_IG05\\nG_M000_IG04: ;; offset=0059H\\n488D4DA8 lea rcx, [rbp-58H]\\nBA0600000\", \"0 mov edx, 6\\nE8B985AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG05: ;; offset=0067H\\n488B4DC0 mov rcx, \", \"gword ptr [rbp-40H]\\n3909 cmp dword ptr [rcx], ecx\\nFF1585C70D00 call [Stopwatch:Restart():this]\\n33C9 \", \"xor ecx, ecx\\n894DBC mov dword ptr [rbp-44H], ecx\\n33C9 xor ecx, ecx\\n894DB8 mov dword ptr [rbp-48H], e\", \"cx\\nEB20 jmp SHORT G_M000_IG08\\nG_M000_IG06: ;; offset=007FH\\n8B4DB8 mov ecx, dword ptr [rbp-48H]\\n0FB7C\", \"9 movzx rcx, cx\\nFF152DD40B00 call [Program:<Main>g__IsAsciiDigit|0_0(ushort):bool]\\n85C0 test eax, ea\", \"x\\n7408 je SHORT G_M000_IG07\\n8B4DBC mov ecx, dword ptr [rbp-44H]\\nFFC1 inc ecx\\n894DBC mov dword ptr [r\", \"bp-44H], ecx\\nG_M000_IG07: ;; offset=0097H\\n8B4DB8 mov ecx, dword ptr [rbp-48H]\\nFFC1 inc ecx\\n894DB8 mo\", \"v dword ptr [rbp-48H], ecx\\nG_M000_IG08: ;; offset=009FH\\n8B4DA8 mov ecx, dword ptr [rbp-58H]\\nFFC9 dec\", \" ecx\\n894DA8 mov dword ptr [rbp-58H], ecx\\n837DA800 cmp dword ptr [rbp-58H], 0\\n7F0E jg SHORT G_M000_IG\", \"10\\n16 CHAPTER 2 | JITG_M000_IG09: ;; offset=00ADH\\n488D4DA8 lea rcx, [rbp-58H]\\nBA23000000 mov edx, 35\", \"\\nE86585AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG10: ;; offset=00BBH\\n817DB800CA9A3B cmp dword ptr [\", \"rbp-48H], 0x3B9ACA00\\n7CBB jl SHORT G_M000_IG06\\n488B4DC0 mov rcx, gword ptr [rbp-40H]\\n3909 cmp dword \", \"ptr [rcx], ecx\\nFF1570C70D00 call [Stopwatch:get_ElapsedMilliseconds():long:this]\\n488BC8 mov rcx, rax\", \"\\nFF1507D00D00 call [Console:WriteLine(long)]\\nE96DFFFFFF jmp G_M000_IG03\\n; Total bytes of code 222\\n; \", \"Assembly listing for method Program:<Main>g__IsAsciiDigit|0_0(ushort):bool\\n; Emitting BLENDED_CODE f\", \"or X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; MinOpts code\\n; rbp based frame\\n; partially inte\", \"rruptible\\nG_M000_IG01: ;; offset=0000H\\n55 push rbp\\n488BEC mov rbp, rsp\\n894D10 mov dword ptr [rbp+10H\", \"], ecx\\nG_M000_IG02: ;; offset=0007H\\n8B4510 mov eax, dword ptr [rbp+10H]\\n0FB7C0 movzx rax, ax\\n83C0D0 \", \"add eax, -48\\n83F809 cmp eax, 9\\n0F96C0 setbe al\\n0FB6C0 movzx rax, al\\nG_M000_IG03: ;; offset=0019H\\n5D \", \"pop rbp\\nC3 ret\\nA few relevant things to notice here. First, the comments at the top highlight how th\", \"is code was\\ncompiled:\\n; Tier-0 compilation\\n; MinOpts code\\nSo, we know this is the initial version (\\u201c\", \"Tier-0\\u201d) of the method compiled with minimal optimization\\n(\\u201cMinOpts\\u201d). Second, note this line of the\", \" assembly:\\nFF152DD40B00 call [Program:<Main>g__IsAsciiDigit|0_0(ushort):bool]\\nOur IsAsciiDigit helpe\", \"r method is trivially inlineable, but it\\u2019s not getting inlined; instead, the\\nassembly has a call to \", \"it, and indeed we can see below the generated code (also \\u201cMinOpts\\u201d) for\\nIsAsciiDigit. Why? Because i\", \"nlining is an optimization (a really important one) that\\u2019s disabled as\\npart of tier-0 (because the a\", \"nalysis for doing inlining well is also quite costly). Third, we can see the\\ncode the JIT is outputt\", \"ing to instrument this method. This is a bit more involved, but I\\u2019ll point out the\\nrelevant parts. F\", \"irst, we see:\\n17 CHAPTER 2 | JITC745A8E8030000 mov dword ptr [rbp-58H], 0x3E8\\nThat 0x3E8 is the hex \", \"value for the decimal 1,000, which is the default number of iterations a loop\\nneeds to iterate befor\", \"e the JIT will generate the optimized version of the method (this is configurable\\nvia the DOTNET_TC_\", \"OnStackReplacement_InitialCounter environment variable). So we see 1,000\\nbeing stored into this stac\", \"k location. Then a bit later in the method we see this:\\nG_M000_IG03: ;; offset=004BH\\n8B4DA8 mov ecx,\", \" dword ptr [rbp-58H]\\nFFC9 dec ecx\\n894DA8 mov dword ptr [rbp-58H], ecx\\n837DA800 cmp dword ptr [rbp-58\", \"H], 0\\n7F0E jg SHORT G_M000_IG05\\nG_M000_IG04: ;; offset=0059H\\n488D4DA8 lea rcx, [rbp-58H]\\nBA06000000 \", \"mov edx, 6\\nE8B985AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG05: ;; offset=0067H\\nThe generated code i\", \"s loading that counter into the ecx register, decrementing it, storing it back, and\\nthen seeing whet\", \"her the counter dropped to 0. If it didn\\u2019t, the code skips to G_M000_IG05, which is the\\nlabel for th\", \"e actual code in the rest of the loop. But if the counter did drop to 0, the JIT proceeds to\\nstore r\", \"elevant state into the the rcx and edx registers and then calls the CORINFO_HELP_PATCHPOINT\\nhelper m\", \"ethod. That helper is responsible for triggering the creation of the optimized method if it\\ndoesn\\u2019t \", \"yet exist, fixing up all appropriate tracking state, and jumping to the new method. And indeed,\\nif y\", \"ou look again at your console output from running the program, you\\u2019ll see yet another output for\\nthe\", \" Main method:\\n; Assembly listing for method Program:Main()\\n; Emitting BLENDED_CODE for X64 CPU with \", \"AVX - Windows\\n; Tier-1 compilation\\n; OSR variant for entry point 0x23\\n; optimized code\\n; rsp based f\", \"rame\\n; fully interruptible\\n; No PGO data\\n; 1 inlinees with PGO data; 8 single block inlinees; 0 inli\", \"nees without PGO data\\nG_M000_IG01: ;; offset=0000H\\n4883EC58 sub rsp, 88\\n4889BC24D8000000 mov qword p\", \"tr [rsp+D8H], rdi\\n4889B424D0000000 mov qword ptr [rsp+D0H], rsi\\n48899C24C8000000 mov qword ptr [rsp+\", \"C8H], rbx\\nC5F877 vzeroupper\\n33C0 xor eax, eax\\n4889442428 mov qword ptr [rsp+28H], rax\\n4889442420 mov\", \" qword ptr [rsp+20H], rax\\n488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n8BBC249C000000 mov edi, dwor\", \"d ptr [rsp+9CH]\\n8BB42498000000 mov esi, dword ptr [rsp+98H]\\nG_M000_IG02: ;; offset=0041H\\nEB45 jmp SH\", \"ORT G_M000_IG05\\nalign [0 bytes for IG06]\\n18 CHAPTER 2 | JITG_M000_IG03: ;; offset=0043H\\n33C9 xor ecx\", \", ecx\\n488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n48894B08 mov qword ptr [rbx+08H], rcx\\n488D4C2428\", \" lea rcx, [rsp+28H]\\n48B87066E68AFD7F0000 mov rax, 0x7FFD8AE66670\\nG_M000_IG04: ;; offset=0060H\\nFFD0 c\", \"all rax ; Kernel32:QueryPerformanceCounter(long):int\\n488B442428 mov rax, qword ptr [rsp+28H]\\n488B9C2\", \"4A0000000 mov rbx, gword ptr [rsp+A0H]\\n48894310 mov qword ptr [rbx+10H], rax\\nC6431801 mov byte ptr [\", \"rbx+18H], 1\\n33FF xor edi, edi\\n33F6 xor esi, esi\\n833D92A1E55F00 cmp dword ptr [(reloc 0x7ffcafe1ae34)\", \"], 0\\n0F85CA000000 jne G_M000_IG13\\nG_M000_IG05: ;; offset=0088H\\n81FE00CA9A3B cmp esi, 0x3B9ACA00\\n7D17\", \" jge SHORT G_M000_IG09\\nG_M000_IG06: ;; offset=0090H\\n0FB7CE movzx rcx, si\\n83C1D0 add ecx, -48\\n83F909 \", \"cmp ecx, 9\\n7702 ja SHORT G_M000_IG08\\nG_M000_IG07: ;; offset=009BH\\nFFC7 inc edi\\nG_M000_IG08: ;; offse\", \"t=009DH\\nFFC6 inc esi\\n81FE00CA9A3B cmp esi, 0x3B9ACA00\\n7CE9 jl SHORT G_M000_IG06\\nG_M000_IG09: ;; offs\", \"et=00A7H\\n488B6B08 mov rbp, qword ptr [rbx+08H]\\n48899C24A0000000 mov gword ptr [rsp+A0H], rbx\\n807B180\", \"0 cmp byte ptr [rbx+18H], 0\\n7436 je SHORT G_M000_IG12\\nG_M000_IG10: ;; offset=00B9H\\n488D4C2420 lea rc\", \"x, [rsp+20H]\\n48B87066E68AFD7F0000 mov rax, 0x7FFD8AE66670\\nG_M000_IG11: ;; offset=00C8H\\nFFD0 call rax\", \" ; Kernel32:QueryPerformanceCounter(long):int\\n488B4C2420 mov rcx, qword ptr [rsp+20H]\\n488B9C24A00000\", \"00 mov rbx, gword ptr [rsp+A0H]\\n482B4B10 sub rcx, qword ptr [rbx+10H]\\n4803E9 add rbp, rcx\\n833D2FA1E5\", \"5F00 cmp dword ptr [(reloc 0x7ffcafe1ae34)], 0\\n48899C24A0000000 mov gword ptr [rsp+A0H], rbx\\n756D jn\", \"e SHORT G_M000_IG14\\nG_M000_IG12: ;; offset=00EFH\\nC5F857C0 vxorps xmm0, xmm0\\nC4E1FB2AC5 vcvtsi2sd xmm\", \"0, rbp\\nC5FB11442430 vmovsd qword ptr [rsp+30H], xmm0\\n19 CHAPTER 2 | JIT48B9F04BF24FFC7F0000 mov rcx,\", \" 0x7FFC4FF24BF0\\nBAE7070000 mov edx, 0x7E7\\nE82E1FB25F call CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE\\nC5\", \"FB10442430 vmovsd xmm0, qword ptr [rsp+30H]\\nC5FB5905E049F6FF vmulsd xmm0, xmm0, qword ptr [(reloc 0x\", \"7ffc4ff25720)]\\nC4E1FB2CD0 vcvttsd2si rdx, xmm0\\n48B94B598638D6C56D34 mov rcx, 0x346DC5D63886594B\\n488B\", \"C1 mov rax, rcx\\n48F7EA imul rdx:rax, rdx\\n488BCA mov rcx, rdx\\n48C1E93F shr rcx, 63\\n48C1FA0B sar rdx, \", \"11\\n4803CA add rcx, rdx\\nFF1567CE0D00 call [Console:WriteLine(long)]\\nE9F5FEFFFF jmp G_M000_IG03\\nG_M000\", \"_IG13: ;; offset=014EH\\nE8DDCBAC5F call CORINFO_HELP_POLL_GC\\nE930FFFFFF jmp G_M000_IG05\\nG_M000_IG14: \", \";; offset=0158H\\nE8D3CBAC5F call CORINFO_HELP_POLL_GC\\nEB90 jmp SHORT G_M000_IG12\\n; Total bytes of cod\", \"e 351\\nHere, again, we notice a few interesting things. First, in the header we see this:\\n; Tier-1 co\", \"mpilation\\n; OSR variant for entry point 0x23\\n; optimized code\\nso we know this is both optimized \\u201ctie\", \"r-1\\u201d code and is the \\u201cOSR variant\\u201d for this method. Second,\\nnotice there\\u2019s no longer a call to the I\", \"sAsciiDigit helper. Instead, where that call would have been,\\nwe see this:\\nG_M000_IG06: ;; offset=00\", \"90H\\n0FB7CE movzx rcx, si\\n83C1D0 add ecx, -48\\n83F909 cmp ecx, 9\\n7702 ja SHORT G_M000_IG08\\nThis is loa\", \"ding a value into rcx, subtracting 48 from it (48 is the decimal ASCII value of the '0'\\ncharacter) a\", \"nd comparing the resulting value to 9. Sounds an awful lot like our IsAsciiDigit\\nimplementation ((ui\", \"nt)(c - '0') <= 9), doesn\\u2019t it? That\\u2019s because it is. The helper was successfully\\ninlined in this no\", \"w-optimized code.\\nGreat, so now in .NET 7, we can largely avoid the tradeoffs between startup and th\", \"roughput, as OSR\\nenables tiered compilation to apply to all methods, even those that are long-runnin\", \"g. A multitude of\\nPRs went into enabling this, including many over the last few years, but all of th\", \"e functionality was\\ndisabled in the shipping bits. Thanks to improvements like dotnet/runtime#62831 \", \"which implemented\\nsupport for OSR on Arm64 (previously only x64 support was implemented), and\\ndotnet\", \"/runtime#63406 and dotnet/runtime#65609 which revised how OSR imports and epilogs are\\nhandled, dotne\", \"t/runtime#65675 enables OSR (and as a result DOTNET_TC_QuickJitForLoops) by\\ndefault.\\n20 CHAPTER 2 | \", \"JITBut, tiered compilation and OSR aren\\u2019t just about startup (though they\\u2019re of course very valuable\", \"\\nthere). They\\u2019re also about further improving throughput. Even though tiered compilation was\\norigina\", \"lly envisioned as a way to optimize startup while not hurting throughput, it\\u2019s become much\\nmore than\", \" that. There are various things the JIT can learn about a method during tier-0 that it can\\nthen use \", \"for tier-1. For example, the very fact that the tier-0 code executed means that any statics\\naccessed\", \" by the method will have been initialized, and that means that any readonly statics will not\\nonly ha\", \"ve been initialized by the time the tier-1 code executes but their values won\\u2019t ever change. And\\ntha\", \"t in turn means that any readonly statics of primitive types (e.g. bool, int, etc.) can be treated l\", \"ike\\nconsts instead of static readonly fields, and during tier-1 compilation the JIT can optimize the\", \"m\\njust as it would have optimized a const. For example, try running this simple program after settin\", \"g\\nDOTNET_JitDisasm to Program:Test:\\nusing System.Runtime.CompilerServices;\\nclass Program\\n{\\nstatic re\", \"adonly bool Is64Bit = Environment.Is64BitProcess;\\nstatic int Main()\\n{\\nint count = 0;\\nfor (int i = 0;\", \" i < 1_000_000_000; i++)\\nif (Test())\\ncount++;\\nreturn count;\\n}\\n[MethodImpl(MethodImplOptions.NoInlini\", \"ng)]\\nstatic bool Test() => Is64Bit;\\n}\\nWhen I do so, I get this output:\\n; Assembly listing for method\", \" Program:Test():bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; M\", \"inOpts code\\n; rbp based frame\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n55 push rbp\\n488\", \"3EC20 sub rsp, 32\\n488D6C2420 lea rbp, [rsp+20H]\\nG_M000_IG02: ;; offset=000AH\\n48B9B8639A3FFC7F0000 mo\", \"v rcx, 0x7FFC3F9A63B8\\nBA01000000 mov edx, 1\\nE8C220B25F call CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE\\n\", \"0FB60545580C00 movzx rax, byte ptr [(reloc 0x7ffc3f9a63ea)]\\nG_M000_IG03: ;; offset=0025H\\n4883C420 ad\", \"d rsp, 32\\n5D pop rbp\\nC3 ret\\n; Total bytes of code 43\\n21 CHAPTER 2 | JIT; Assembly listing for method\", \" Program:Test():bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; o\", \"ptimized code\\n; rsp based frame\\n; partially interruptible\\n; No PGO data\\nG_M000_IG01: ;; offset=0000H\", \"\\nG_M000_IG02: ;; offset=0000H\\nB801000000 mov eax, 1\\nG_M000_IG03: ;; offset=0005H\\nC3 ret\\n; Total byte\", \"s of code 6\\nNote, again, we see two outputs for Program:Test. First, we see the \\u201cTier-0\\u201d code, which\", \" is accessing a\\nstatic (note the call CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE instruction). But then\", \" we see\\nthe \\u201cTier-1\\u201d code, where all of that overhead has vanished and is instead replaced simply by\", \" mov eax,\\n1. Since the \\u201cTier-0\\u201d code had to have executed in order for it to tier up, the \\u201cTier-1\\u201d c\", \"ode was\\ngenerated knowing that the value of the static readonly bool Is64Bit field was true (1), and\", \" so\\nthe entirety of this method is storing the value 1 into the eax register used for the return val\", \"ue.\\nThis is so useful that components are now written with tiering in mind. Consider the new Regex s\", \"ource\\ngenerator, which is discussed later in this post (Roslyn source generators were introduced a c\", \"ouple of\\nyears ago; just as how Roslyn analyzers are able to plug into the compiler and surface addi\", \"tional\\ndiagnostics based on all of the data the compiler learns from the source code, Roslyn source\\n\", \"generators are able to analyze that same data and then further augment the compilation unit with\\nadd\", \"itional source). The Regex source generator applies a technique based on this in\\ndotnet/runtime#6777\", \"5. Regex supports setting a process-wide timeout that gets applied to Regex\\ninstances that don\\u2019t exp\", \"licitly set a timeout. That means, even though it\\u2019s super rare for such a\\nprocess-wide timeout to be\", \" set, the Regex source generator still needs to output timeout-related code\\njust in case it\\u2019s needed\", \". It does so by outputting some helpers like this:\\nstatic class Utilities\\n{\\ninternal static readonly\", \" TimeSpan s_defaultTimeout =\\nAppContext.GetData(\\\"REGEX_DEFAULT_MATCH_TIMEOUT\\\") is TimeSpan timeout ?\", \" timeout :\\nTimeout.InfiniteTimeSpan;\\ninternal static readonly bool s_hasTimeout = s_defaultTimeout !\", \"=\\nTimeout.InfiniteTimeSpan;\\n}\\nwhich it then uses at call sites like this:\\nif (Utilities.s_hasTimeout\", \")\\n{\\nbase.CheckTimeout();\\n}\\nIn tier-0, these checks will still be emitted in the assembly code, but i\", \"n tier-1 where throughput\\nmatters, if the relevant AppContext switch hasn\\u2019t been set, then s_default\", \"Timeout will be\\n22 CHAPTER 2 | JITTimeout.InfiniteTimeSpan, at which point s_hasTimeout will be fals\", \"e. And since s_hasTimeout is a\\nstatic readonly bool, the JIT will be able to treat that as a const, \", \"and all conditions like if\\n(Utilities.s_hasTimeout) will be treated equal to if (false) and be elimi\", \"nated from the\\nassembly code entirely as dead code.\\nBut, this is somewhat old news. The JIT has been\", \" able to do such an optimization since tiered\\ncompilation was introduced in .NET Core 3.0. Now in .N\", \"ET 7, though, with OSR it\\u2019s also able to do so\\nby default for methods with loops (and thus enable ca\", \"ses like the regex one). However, the real magic\\nof OSR comes into play when combined with another e\", \"xciting feature: dynamic PGO.\\nPGO\\nI wrote about profile-guided optimization (PGO) in my Performance \", \"Improvements in .NET 6 post, but\\nI\\u2019ll cover it again here as it\\u2019s seen a multitude of improvements f\", \"or .NET 7.\\nPGO has been around for a long time, in any number of languages and compilers. The basic \", \"idea is\\nyou compile your app, asking the compiler to inject instrumentation into the application to \", \"track\\nvarious pieces of interesting information. You then put your app through its paces, running th\", \"rough\\nvarious common scenarios, causing that instrumentation to \\u201cprofile\\u201d what happens when the app \", \"is\\nexecuted, and the results of that are then saved out. The app is then recompiled, feeding those\\ni\", \"nstrumentation results back into the compiler, and allowing it to optimize the app for exactly how i\", \"t\\u2019s\\nexpected to be used. This approach to PGO is referred to as \\u201cstatic PGO,\\u201d as the information is \", \"all\\ngleaned ahead of actual deployment, and it\\u2019s something .NET has been doing in various forms for\\n\", \"years. From my perspective, though, the really interesting development in .NET is \\u201cdynamic PGO,\\u201d\\nwhi\", \"ch was introduced in .NET 6, but off by default.\\nDynamic PGO takes advantage of tiered compilation. \", \"I noted that the JIT instruments the tier-0 code\\nto track how many times the method is called, or in\", \" the case of loops, how many times the loop\\nexecutes. It can instrument it for other things as well.\", \" For example, it can track exactly which concrete\\ntypes are used as the target of an interface dispa\", \"tch, and then in tier-1 specialize the code to expect\\nthe most common types (this is referred to as \", \"\\u201cguarded devirtualization,\\u201d or GDV). You can see this in\\nthis little example. Set the DOTNET_TieredP\", \"GO environment variable to 1, and then run this on .NET 7:\\nclass Program\\n{\\nstatic void Main()\\n{\\nIPri\", \"nter printer = new Printer();\\nfor (int i = 0; ; i++)\\n{\\nDoWork(printer, i);\\n}\\n}\\nstatic void DoWork(IP\", \"rinter printer, int i)\\n{\\nprinter.PrintIfTrue(i == int.MaxValue);\\n}\\ninterface IPrinter\\n{\\nvoid PrintIf\", \"True(bool condition);\\n23 CHAPTER 2 | JIT}\\nclass Printer : IPrinter\\n{\\npublic void PrintIfTrue(bool co\", \"ndition)\\n{\\nif (condition) Console.WriteLine(\\\"Print!\\\");\\n}\\n}\\n}\\nThe tier-0 code for DoWork ends up look\", \"ing like this:\\nG_M000_IG01: ;; offset=0000H\\n55 push rbp\\n4883EC30 sub rsp, 48\\n488D6C2430 lea rbp, [rs\", \"p+30H]\\n33C0 xor eax, eax\\n488945F8 mov qword ptr [rbp-08H], rax\\n488945F0 mov qword ptr [rbp-10H], rax\", \"\\n48894D10 mov gword ptr [rbp+10H], rcx\\n895518 mov dword ptr [rbp+18H], edx\\nG_M000_IG02: ;; offset=00\", \"1BH\\nFF059F220F00 inc dword ptr [(reloc 0x7ffc3f1b2ea0)]\\n488B4D10 mov rcx, gword ptr [rbp+10H]\\n48894D\", \"F8 mov gword ptr [rbp-08H], rcx\\n488B4DF8 mov rcx, gword ptr [rbp-08H]\\n48BAA82E1B3FFC7F0000 mov rdx, \", \"0x7FFC3F1B2EA8\\nE8B47EC55F call CORINFO_HELP_CLASSPROFILE32\\n488B4DF8 mov rcx, gword ptr [rbp-08H]\\n488\", \"94DF0 mov gword ptr [rbp-10H], rcx\\n488B4DF0 mov rcx, gword ptr [rbp-10H]\\n33D2 xor edx, edx\\n817D18FFF\", \"FFF7F cmp dword ptr [rbp+18H], 0x7FFFFFFF\\n0F94C2 sete dl\\n49BB0800F13EFC7F0000 mov r11, 0x7FFC3EF1000\", \"8\\n41FF13 call [r11]IPrinter:PrintIfTrue(bool):this\\n90 nop\\nG_M000_IG03: ;; offset=0062H\\n4883C430 add \", \"rsp, 48\\n5D pop rbp\\nC3 ret\\nand most notably, you can see the call [r11]IPrinter:PrintIfTrue(bool):thi\", \"s doing the\\ninterface dispatch. But, then look at the code generated for tier-1. We still see the ca\", \"ll\\n[r11]IPrinter:PrintIfTrue(bool):this, but we also see this:\\nG_M000_IG02: ;; offset=0020H\\n48B9982D\", \"1B3FFC7F0000 mov rcx, 0x7FFC3F1B2D98\\n48390F cmp qword ptr [rdi], rcx\\n7521 jne SHORT G_M000_IG05\\n81FE\", \"FFFFFF7F cmp esi, 0x7FFFFFFF\\n7404 je SHORT G_M000_IG04\\nG_M000_IG03: ;; offset=0037H\\nFFC6 inc esi\\nEBE\", \"5 jmp SHORT G_M000_IG02\\n24 CHAPTER 2 | JITG_M000_IG04: ;; offset=003BH\\n48B9D820801A24020000 mov rcx,\", \" 0x2241A8020D8\\n488B09 mov rcx, gword ptr [rcx]\\nFF1572CD0D00 call [Console:WriteLine(String)]\\nEBE7 jm\", \"p SHORT G_M000_IG03\\nThat first block is checking the concrete type of the IPrinter (stored in rdi) a\", \"nd comparing it against\\nthe known type for Printer (0x7FFC3F1B2D98). If they\\u2019re different, it just j\", \"umps to the same interface\\ndispatch it was doing in the unoptimized version. But if they\\u2019re the same\", \", it then jumps directly to an\\ninlined version of Printer.PrintIfTrue (you can see the call to Conso\", \"le:WriteLine right there in\\nthis method). Thus, the common case (the only case in this example) is s\", \"uper efficient at the expense\\nof a single comparison and branch.\\nThat all existed in .NET 6, so why \", \"are we talking about it now? Several things have improved. First,\\nPGO now works with OSR, thanks to \", \"improvements like dotnet/runtime#61453. That\\u2019s a big deal, as it\\nmeans hot long-running methods that\", \" do this kind of interface dispatch (which are fairly common)\\ncan get these kinds of devirtualizatio\", \"n/inlining optimizations. Second, while PGO isn\\u2019t currently\\nenabled by default, we\\u2019ve made it much e\", \"asier to turn on. Between dotnet/runtime#71438 and\\ndotnet/sdk#26350, it\\u2019s now possible to simply put\", \" <TieredPGO>true</TieredPGO> into your .csproj,\\nand it\\u2019ll have the same effect as if you set DOTNET_\", \"TieredPGO=1 prior to every invocation of the app,\\nenabling dynamic PGO (note that it doesn\\u2019t disable\", \" use of R2R images, so if you want the entirety of\\nthe core libraries also employing dynamic PGO, yo\", \"u\\u2019ll also need to set DOTNET_ReadyToRun=0). Third,\\nhowever, is dynamic PGO has been taught how to in\", \"strument and optimize additional things.\\nPGO already knew how to instrument virtual dispatch. Now in\", \" .NET 7, thanks in large part to\\ndotnet/runtime#68703, it can do so for delegates as well (at least \", \"for delegates to instance methods).\\nConsider this simple console app:\\nusing System.Runtime.CompilerS\", \"ervices;\\nclass Program\\n{\\nstatic int[] s_values = Enumerable.Range(0, 1_000).ToArray();\\nstatic void M\", \"ain()\\n{\\nfor (int i = 0; i < 1_000_000; i++)\\nSum(s_values, i => i * 42);\\n}\\n[MethodImpl(MethodImplOpti\", \"ons.NoInlining)]\\nstatic int Sum(int[] values, Func<int, int> func)\\n{\\nint sum = 0;\\nforeach (int value\", \" in values)\\nsum += func(value);\\nreturn sum;\\n}\\n}\\nWithout PGO enabled, I get generated optimized assem\", \"bly like this:\\n; Assembly listing for method Program:Sum(ref,Func`2):int\\n; Emitting BLENDED_CODE for\", \" X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n25 CHAPTER 2 | JIT; optimized code\\n; rsp based fram\", \"e\\n; partially interruptible\\n; No PGO data\\nG_M000_IG01: ;; offset=0000H\\n4156 push r14\\n57 push rdi\\n56 \", \"push rsi\\n55 push rbp\\n53 push rbx\\n4883EC20 sub rsp, 32\\n488BF2 mov rsi, rdx\\nG_M000_IG02: ;; offset=000\", \"DH\\n33FF xor edi, edi\\n488BD9 mov rbx, rcx\\n33ED xor ebp, ebp\\n448B7308 mov r14d, dword ptr [rbx+08H]\\n45\", \"85F6 test r14d, r14d\\n7E16 jle SHORT G_M000_IG04\\nG_M000_IG03: ;; offset=001DH\\n8BD5 mov edx, ebp\\n8B549\", \"310 mov edx, dword ptr [rbx+4*rdx+10H]\\n488B4E08 mov rcx, gword ptr [rsi+08H]\\nFF5618 call [rsi+18H]Fu\", \"nc`2:Invoke(int):int:this\\n03F8 add edi, eax\\nFFC5 inc ebp\\n443BF5 cmp r14d, ebp\\n7FEA jg SHORT G_M000_I\", \"G03\\nG_M000_IG04: ;; offset=0033H\\n8BC7 mov eax, edi\\nG_M000_IG05: ;; offset=0035H\\n4883C420 add rsp, 32\", \"\\n5B pop rbx\\n5D pop rbp\\n5E pop rsi\\n5F pop rdi\\n415E pop r14\\nC3 ret\\n; Total bytes of code 64\\nNote the c\", \"all [rsi+18H]Func'2:Invoke(int):int:this in there that\\u2019s invoking the delegate. Now\\nwith PGO enabled\", \":\\n; Assembly listing for method Program:Sum(ref,Func`2):int\\n; Emitting BLENDED_CODE for X64 CPU with\", \" AVX - Windows\\n; Tier-1 compilation\\n; optimized code\\n; optimized using profile data\\n; rsp based fram\", \"e\\n; fully interruptible\\n; with Dynamic PGO: edge weights are valid, and fgCalledCount is 5628\\n; 0 in\", \"linees with PGO data; 1 single block inlinees; 0 inlinees without PGO data\\nG_M000_IG01: ;; offset=00\", \"00H\\n26 CHAPTER 2 | JIT4157 push r15\\n4156 push r14\\n57 push rdi\\n56 push rsi\\n55 push rbp\\n53 push rbx\\n48\", \"83EC28 sub rsp, 40\\n488BF2 mov rsi, rdx\\nG_M000_IG02: ;; offset=000FH\\n33FF xor edi, edi\\n488BD9 mov rbx\", \", rcx\\n33ED xor ebp, ebp\\n448B7308 mov r14d, dword ptr [rbx+08H]\\n4585F6 test r14d, r14d\\n7E27 jle SHORT\", \" G_M000_IG05\\nG_M000_IG03: ;; offset=001FH\\n8BC5 mov eax, ebp\\n8B548310 mov edx, dword ptr [rbx+4*rax+1\", \"0H]\\n4C8B4618 mov r8, qword ptr [rsi+18H]\\n48B8A0C2CF3CFC7F0000 mov rax, 0x7FFC3CCFC2A0\\n4C3BC0 cmp r8,\", \" rax\\n751D jne SHORT G_M000_IG07\\n446BFA2A imul r15d, edx, 42\\nG_M000_IG04: ;; offset=003CH\\n4103FF add \", \"edi, r15d\\nFFC5 inc ebp\\n443BF5 cmp r14d, ebp\\n7FD9 jg SHORT G_M000_IG03\\nG_M000_IG05: ;; offset=0046H\\n8\", \"BC7 mov eax, edi\\nG_M000_IG06: ;; offset=0048H\\n4883C428 add rsp, 40\\n5B pop rbx\\n5D pop rbp\\n5E pop rsi\\n\", \"5F pop rdi\\n415E pop r14\\n415F pop r15\\nC3 ret\\nG_M000_IG07: ;; offset=0055H\\n488B4E08 mov rcx, gword ptr\", \" [rsi+08H]\\n41FFD0 call r8\\n448BF8 mov r15d, eax\\nEBDB jmp SHORT G_M000_IG04\\nI chose the 42 constant in\", \" i => i * 42 to make it easy to see in the assembly, and sure enough, there\\nit is:\\nG_M000_IG03: ;; o\", \"ffset=001FH\\n8BC5 mov eax, ebp\\n8B548310 mov edx, dword ptr [rbx+4*rax+10H]\\n4C8B4618 mov r8, qword ptr\", \" [rsi+18H]\\n48B8A0C2CF3CFC7F0000 mov rax, 0x7FFC3CCFC2A0\\n4C3BC0 cmp r8, rax\\n27 CHAPTER 2 | JIT751D jn\", \"e SHORT G_M000_IG07\\n446BFA2A imul r15d, edx, 42\\nThis is loading the target address from the delegate\", \" into r8 and is loading the address of the\\nexpected target into rax. If they\\u2019re the same, it then si\", \"mply performs the inlined operation (imul\\nr15d, edx, 42), and otherwise it jumps to G_M000_IG07 whic\", \"h calls to the function in r8. The effect\\nof this is obvious if we run this as a benchmark:\\nstatic i\", \"nt[] s_values = Enumerable.Range(0, 1_000).ToArray();\\n[Benchmark]\\npublic int DelegatePGO() => Sum(s_\", \"values, i => i * 42);\\nstatic int Sum(int[] values, Func<int, int>? func)\\n{\\nint sum = 0;\\nforeach (int\", \" value in values)\\n{\\nsum += func(value);\\n}\\nreturn sum;\\n}\\nWith PGO disabled, we get the same performan\", \"ce throughput for .NET 6 and .NET 7:\\nMethod Runtime Mean Ratio\\nDelegatePGO .NET 6.0 1.665 us 1.00\\nDe\", \"legatePGO .NET 7.0 1.659 us 1.00\\nBut the picture changes when we enable dynamic PGO (DOTNET_TieredPG\", \"O=1). .NET 6 gets ~14%\\nfaster, but .NET 7 gets ~3x faster!\\nMethod Runtime Mean Ratio\\nDelegatePGO .NE\", \"T 6.0 1,427.7 ns 1.00\\nDelegatePGO .NET 7.0 539.0 ns 0.38\\ndotnet/runtime#70377 is another valuable im\", \"provement with dynamic PGO, which enables PGO to\\nplay nicely with loop cloning and invariant hoistin\", \"g. To understand this better, a brief digression into\\nwhat those are. Loop cloning is a mechanism th\", \"e JIT employs to avoid various overheads in the fast\\npath of a loop. Consider the Test method in thi\", \"s example:\\nusing System.Runtime.CompilerServices;\\nclass Program\\n{\\nstatic void Main()\\n{\\nint[] array =\", \" new int[10_000_000];\\nfor (int i = 0; i < 1_000_000; i++)\\n{\\nTest(array);\\n}\\n}\\n28 CHAPTER 2 | JIT[Meth\", \"odImpl(MethodImplOptions.NoInlining)]\\nprivate static bool Test(int[] array)\\n{\\nfor (int i = 0; i < 0x\", \"12345; i++)\\n{\\nif (array[i] == 42)\\n{\\nreturn true;\\n}\\n}\\nreturn false;\\n}\\n}\\nThe JIT doesn\\u2019t know whether \", \"the passed in array is of sufficient length that all accesses to array[i]\\ninside the loop will be in\", \" bounds, and thus it would need to inject bounds checks for every access.\\nWhile it\\u2019d be nice to simp\", \"ly do the length check up front and simply throw an exception early if it\\nwasn\\u2019t long enough, doing \", \"so could also change behavior (imagine the method were writing into the\\narray as it went, or otherwi\", \"se mutating some shared state). Instead, the JIT employs \\u201cloop cloning.\\u201d It\\nessentially rewrites thi\", \"s Test method to be more like this:\\nif (array is not null && array.Length >= 0x12345)\\n{\\nfor (int i =\", \" 0; i < 0x12345; i++)\\n{\\nif (array[i] == 42) // no bounds checks emitted for this access :-)\\n{\\nreturn\", \" true;\\n}\\n}\\n}\\nelse\\n{\\nfor (int i = 0; i < 0x12345; i++)\\n{\\nif (array[i] == 42) // bounds checks emitted\", \" for this access :-(\\n{\\nreturn true;\\n}\\n}\\n}\\nreturn false;\\nThat way, at the expense of some code duplic\", \"ation, we get our fast loop without bounds checks and\\nonly pay for the bounds checks in the slow pat\", \"h. You can see this in the generated assembly (if you\\ncan\\u2019t already tell, DOTNET_JitDisasm is one of\", \" my favorite features in .NET 7):\\n; Assembly listing for method Program:Test(ref):bool\\n; Emitting BL\", \"ENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; optimized code\\n; rsp based frame\\n; \", \"fully interruptible\\n; No PGO data\\nG_M000_IG01: ;; offset=0000H\\n4883EC28 sub rsp, 40\\n29 CHAPTER 2 | J\", \"ITG_M000_IG02: ;; offset=0004H\\n33C0 xor eax, eax\\n4885C9 test rcx, rcx\\n7429 je SHORT G_M000_IG05\\n8179\", \"0845230100 cmp dword ptr [rcx+08H], 0x12345\\n7C20 jl SHORT G_M000_IG05\\n0F1F40000F1F840000000000 align\", \" [12 bytes for IG03]\\nG_M000_IG03: ;; offset=0020H\\n8BD0 mov edx, eax\\n837C91102A cmp dword ptr [rcx+4*\", \"rdx+10H], 42\\n7429 je SHORT G_M000_IG08\\nFFC0 inc eax\\n3D45230100 cmp eax, 0x12345\\n7CEE jl SHORT G_M000\", \"_IG03\\nG_M000_IG04: ;; offset=0032H\\nEB17 jmp SHORT G_M000_IG06\\nG_M000_IG05: ;; offset=0034H\\n3B4108 cm\", \"p eax, dword ptr [rcx+08H]\\n7323 jae SHORT G_M000_IG10\\n8BD0 mov edx, eax\\n837C91102A cmp dword ptr [rc\", \"x+4*rdx+10H], 42\\n7410 je SHORT G_M000_IG08\\nFFC0 inc eax\\n3D45230100 cmp eax, 0x12345\\n7CE9 jl SHORT G_\", \"M000_IG05\\nG_M000_IG06: ;; offset=004BH\\n33C0 xor eax, eax\\nG_M000_IG07: ;; offset=004DH\\n4883C428 add r\", \"sp, 40\\nC3 ret\\nG_M000_IG08: ;; offset=0052H\\nB801000000 mov eax, 1\\nG_M000_IG09: ;; offset=0057H\\n4883C4\", \"28 add rsp, 40\\nC3 ret\\nG_M000_IG10: ;; offset=005CH\\nE81FA0C15F call CORINFO_HELP_RNGCHKFAIL\\nCC int3\\n;\", \" Total bytes of code 98\\nThat G_M000_IG02 section is doing the null check and the length check, jumpi\", \"ng to the G_M000_IG05\\nblock if either fails. If both succeed, it\\u2019s then executing the loop (block G_\", \"M000_IG03) without bounds\\nchecks:\\nG_M000_IG03: ;; offset=0020H\\n8BD0 mov edx, eax\\n837C91102A cmp dwor\", \"d ptr [rcx+4*rdx+10H], 42\\n7429 je SHORT G_M000_IG08\\nFFC0 inc eax\\n30 CHAPTER 2 | JIT3D45230100 cmp ea\", \"x, 0x12345\\n7CEE jl SHORT G_M000_IG03\\nwith the bounds checks only showing up in the slow-path block:\\n\", \"G_M000_IG05: ;; offset=0034H\\n3B4108 cmp eax, dword ptr [rcx+08H]\\n7323 jae SHORT G_M000_IG10\\n8BD0 mov\", \" edx, eax\\n837C91102A cmp dword ptr [rcx+4*rdx+10H], 42\\n7410 je SHORT G_M000_IG08\\nFFC0 inc eax\\n3D4523\", \"0100 cmp eax, 0x12345\\n7CE9 jl SHORT G_M000_IG05\\nThat\\u2019s \\u201cloop cloning.\\u201d What about \\u201cinvariant hoistin\", \"g\\u201d? Hoisting means pulling something out of a\\nloop to be before the loop, and invariants are things \", \"that don\\u2019t change. Thus invariant hoisting is\\npulling something out of a loop to before the loop in \", \"order to avoid recomputing every iteration of\\nthe loop an answer that won\\u2019t change. Effectively, the\", \" previous example already showed invariant\\nhoisting, in that the bounds check is moved to be before \", \"the loop rather than in the loop, but a more\\nconcrete example would be something like this:\\n[MethodI\", \"mpl(MethodImplOptions.NoInlining)]\\nprivate static bool Test(int[] array)\\n{\\nfor (int i = 0; i < 0x123\", \"45; i++)\\n{\\nif (array[i] == array.Length - 42)\\n{\\nreturn true;\\n}\\n}\\nreturn false;\\n}\\nNote that the value\", \" of array.Length - 42 doesn\\u2019t change on each iteration of the loop, so it\\u2019s\\n\\u201cinvariant\\u201d to the loop \", \"iteration and can be lifted out, which the generated code does:\\nG_M000_IG02: ;; offset=0004H\\n33D2 xo\", \"r edx, edx\\n4885C9 test rcx, rcx\\n742A je SHORT G_M000_IG05\\n448B4108 mov r8d, dword ptr [rcx+08H]\\n4181\", \"F845230100 cmp r8d, 0x12345\\n7C1D jl SHORT G_M000_IG05\\n4183C0D6 add r8d, -42\\n0F1F4000 align [4 bytes \", \"for IG03]\\nG_M000_IG03: ;; offset=0020H\\n8BC2 mov eax, edx\\n4439448110 cmp dword ptr [rcx+4*rax+10H], r\", \"8d\\n7433 je SHORT G_M000_IG08\\nFFC2 inc edx\\n81FA45230100 cmp edx, 0x12345\\n7CED jl SHORT G_M000_IG03\\n31\", \" CHAPTER 2 | JITHere again we see the array being tested for null (test rcx, rcx) and the array\\u2019s le\", \"ngth being\\nchecked (mov r8d, dword ptr [rcx+08H], cmp r8d, 0x12345), but then with the array\\u2019s lengt\", \"h in\\nr8d, we then see this up-front block subtracting 42 from the length (add r8d, -42), and that\\u2019s \", \"before\\nwe continue into the fast-path loop in the G_M000_IG03 block. This keeps that additional set \", \"of\\noperations out of the loop, thereby avoiding the overhead of recomputing the value per iteration.\", \"\\nOk, so how does this apply to dynamic PGO? Remember that with the interface/virtual dispatch\\navoida\", \"nce PGO is able to do, it does so by doing a type check to see whether the type in use is the\\nmost c\", \"ommon type; if it is, it uses a fast path that calls directly to that type\\u2019s method (and in doing so\", \"\\nthat call is then potentially inlined), and if it isn\\u2019t, it falls back to normal interface/virtual \", \"dispatch. That\\ncheck can be invariant to a loop. So when a method is tiered up and PGO kicks in, the\", \" type check can\\nnow be hoisted out of the loop, making it even cheaper to handle the common case. Co\", \"nsider this\\nvariation of our original example:\\nusing System.Runtime.CompilerServices;\\nclass Program\\n\", \"{\\nstatic void Main()\\n{\\nIPrinter printer = new BlankPrinter();\\nwhile (true)\\n{\\nDoWork(printer);\\n}\\n}\\n[M\", \"ethodImpl(MethodImplOptions.NoInlining)]\\nstatic void DoWork(IPrinter printer)\\n{\\nfor (int j = 0; j < \", \"123; j++)\\n{\\nprinter.Print(j);\\n}\\n}\\ninterface IPrinter\\n{\\nvoid Print(int i);\\n}\\nclass BlankPrinter : IPr\", \"inter\\n{\\npublic void Print(int i)\\n{\\nConsole.Write(\\\"\\\");\\n}\\n}\\n}\\nWhen we look at the optimized assembly g\", \"enerated for this with dynamic PGO enabled, we see this:\\n; Assembly listing for method Program:DoWor\", \"k(IPrinter)\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; optimized \", \"code\\n; optimized using profile data\\n32 CHAPTER 2 | JIT; rsp based frame\\n; partially interruptible\\n; \", \"with Dynamic PGO: edge weights are invalid, and fgCalledCount is 12187\\n; 0 inlinees with PGO data; 1\", \" single block inlinees; 0 inlinees without PGO data\\nG_M000_IG01: ;; offset=0000H\\n57 push rdi\\n56 push\", \" rsi\\n4883EC28 sub rsp, 40\\n488BF1 mov rsi, rcx\\nG_M000_IG02: ;; offset=0009H\\n33FF xor edi, edi\\n4885F6 \", \"test rsi, rsi\\n742B je SHORT G_M000_IG05\\n48B9982DD43CFC7F0000 mov rcx, 0x7FFC3CD42D98\\n48390E cmp qwor\", \"d ptr [rsi], rcx\\n751C jne SHORT G_M000_IG05\\nG_M000_IG03: ;; offset=001FH\\n48B9282040F948020000 mov rc\", \"x, 0x248F9402028\\n488B09 mov rcx, gword ptr [rcx]\\nFF1526A80D00 call [Console:Write(String)]\\nFFC7 inc \", \"edi\\n83FF7B cmp edi, 123\\n7CE6 jl SHORT G_M000_IG03\\nG_M000_IG04: ;; offset=0039H\\nEB29 jmp SHORT G_M000\", \"_IG07\\nG_M000_IG05: ;; offset=003BH\\n48B9982DD43CFC7F0000 mov rcx, 0x7FFC3CD42D98\\n48390E cmp qword ptr\", \" [rsi], rcx\\n7521 jne SHORT G_M000_IG08\\n48B9282040F948020000 mov rcx, 0x248F9402028\\n488B09 mov rcx, g\", \"word ptr [rcx]\\nFF15FBA70D00 call [Console:Write(String)]\\nG_M000_IG06: ;; offset=005DH\\nFFC7 inc edi\\n8\", \"3FF7B cmp edi, 123\\n7CD7 jl SHORT G_M000_IG05\\nG_M000_IG07: ;; offset=0064H\\n4883C428 add rsp, 40\\n5E po\", \"p rsi\\n5F pop rdi\\nC3 ret\\nG_M000_IG08: ;; offset=006BH\\n488BCE mov rcx, rsi\\n8BD7 mov edx, edi\\n49BB1000A\", \"A3CFC7F0000 mov r11, 0x7FFC3CAA0010\\n41FF13 call [r11]IPrinter:Print(int):this\\nEBDE jmp SHORT G_M000_\", \"IG06\\n; Total bytes of code 127\\nWe can see in the G_M000_IG02 block that it\\u2019s doing the type check on\", \" the IPrinter instance and\\njumping to G_M000_IG05 if the check fails (mov rcx, 0x7FFC3CD42D98, cmp q\", \"word ptr [rsi], rcx,\\n33 CHAPTER 2 | JITjne SHORT G_M000_IG05), otherwise falling through to G_M000_I\", \"G03 which is a tight fast-path loop\\nthat\\u2019s inlined BlankPrinter.Print with no type checks in sight!\\n\", \"Interestingly, improvements like this can bring with them their own challenges. PGO leads to a\\nsigni\", \"ficant increase in the number of type checks, since call sites that specialize for a given type need\", \"\\nto compare against that type. However, common subexpression elimination (CSE) hasn\\u2019t historically\\nw\", \"orked for such type handles (CSE is a compiler optimization where duplicate expressions are\\neliminat\", \"ed by computing the result once and then storing it for subsequent use rather than\\nrecomputing it ea\", \"ch time). dotnet/runtime#70580 fixes this by enabling CSE for such constant\\nhandles. For example, co\", \"nsider this method:\\n[Benchmark]\\n[Arguments(\\\"\\\", \\\"\\\", \\\"\\\", \\\"\\\")]\\npublic bool AllAreStrings(object o1, obj\", \"ect o2, object o3, object o4) =>\\no1 is string && o2 is string && o3 is string && o4 is string;\\nOn .N\", \"ET 6, the JIT produced this assembly code:\\n; Program.AllAreStrings(System.Object, System.Object, Sys\", \"tem.Object, System.Object)\\ntest rdx,rdx\\nje short M00_L01\\nmov rax,offset MT_System.String\\ncmp [rdx],r\", \"ax\\njne short M00_L01\\ntest r8,r8\\nje short M00_L01\\nmov rax,offset MT_System.String\\ncmp [r8],rax\\njne sh\", \"ort M00_L01\\ntest r9,r9\\nje short M00_L01\\nmov rax,offset MT_System.String\\ncmp [r9],rax\\njne short M00_L\", \"01\\nmov rax,[rsp+28]\\ntest rax,rax\\nje short M00_L00\\nmov rdx,offset MT_System.String\\ncmp [rax],rdx\\nje s\", \"hort M00_L00\\nxor eax,eax\\nM00_L00:\\ntest rax,rax\\nsetne al\\nmovzx eax,al\\nret\\nM00_L01:\\nxor eax,eax\\nret\\n; \", \"Total bytes of code 100\\nNote the C# has four tests for string and the assembly code has four loads w\", \"ith mov rax,offset\\nMT_System.String. Now on .NET 7, the load is performed just once:\\n; Program.AllAr\", \"eStrings(System.Object, System.Object, System.Object, System.Object)\\ntest rdx,rdx\\nje short M00_L01\\n3\", \"4 CHAPTER 2 | JITmov rax,offset MT_System.String\\ncmp [rdx],rax\\njne short M00_L01\\ntest r8,r8\\nje short\", \" M00_L01\\ncmp [r8],rax\\njne short M00_L01\\ntest r9,r9\\nje short M00_L01\\ncmp [r9],rax\\njne short M00_L01\\nm\", \"ov rdx,[rsp+28]\\ntest rdx,rdx\\nje short M00_L00\\ncmp [rdx],rax\\nje short M00_L00\\nxor edx,edx\\nM00_L00:\\nxo\", \"r eax,eax\\ntest rdx,rdx\\nsetne al\\nret\\nM00_L01:\\nxor eax,eax\\nret\\n; Total bytes of code 69\\nBounds Check E\", \"limination\\nOne of the things that makes .NET attractive is its safety. The runtime guards access to \", \"arrays, strings,\\nand spans such that you can\\u2019t accidentally corrupt memory by walking off either end\", \"; if you do, rather\\nthan reading/writing arbitrary memory, you\\u2019ll get exceptions. Of course, that\\u2019s \", \"not magic; it\\u2019s done by\\nthe JIT inserting bounds checks every time one of these data structures is i\", \"ndexed. For example, this:\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nstatic int Read0thElement(int[\", \"] array) => array[0];\\nresults in:\\nG_M000_IG01: ;; offset=0000H\\n4883EC28 sub rsp, 40\\nG_M000_IG02: ;; \", \"offset=0004H\\n83790800 cmp dword ptr [rcx+08H], 0\\n7608 jbe SHORT G_M000_IG04\\n8B4110 mov eax, dword pt\", \"r [rcx+10H]\\nG_M000_IG03: ;; offset=000DH\\n4883C428 add rsp, 40\\nC3 ret\\nG_M000_IG04: ;; offset=0012H\\nE8\", \"E9A0C25F call CORINFO_HELP_RNGCHKFAIL\\nCC int3\\nThe array is passed into this method in the rcx regist\", \"er, pointing to the method table pointer in the\\nobject, and the length of an array is stored in the \", \"object just after that method table pointer (which is\\n8 bytes in a 64-bit process). Thus the cmp dwo\", \"rd ptr [rcx+08H], 0 instruction is reading the length\\n35 CHAPTER 2 | JITof the array and comparing t\", \"he length to 0; that makes sense, since the length can\\u2019t be negative, and\\nwe\\u2019re trying to access the\", \" 0th element, so as long as the length isn\\u2019t 0, the array has enough elements\\nfor us to access its 0\", \"th element. In the event that the length was 0, the code jumps to the end of the\\nfunction, which con\", \"tains call CORINFO_HELP_RNGCHKFAIL; that\\u2019s a JIT helper function that throws an\\nIndexOutOfRangeExcep\", \"tion. If the length was sufficient, however, it then reads the int stored at the\\nbeginning of the ar\", \"ray\\u2019s data, which on 64-bit is 16 bytes (0x10) past the pointer (mov eax, dword\\nptr [rcx+10H]).\\nWhil\", \"e these bounds checks in and of themselves aren\\u2019t super expensive, do a lot of them and their\\ncosts \", \"add up. So while the JIT needs to ensure that \\u201csafe\\u201d accesses don\\u2019t go out of bounds, it also tries\\n\", \"to prove that certain accesses won\\u2019t, in which case it needn\\u2019t emit the bounds check that it knows w\", \"ill\\nbe superfluous. In every release of .NET, more and more cases have been added to find places the\", \"se\\nbounds checks can be eliminated, and .NET 7 is no exception.\\nFor example, dotnet/runtime#61662 fr\", \"om [@anthonycanino](https://github.com/anthonycanino)\\nenabled the JIT to understand various forms of\", \" binary operations as part of range checks. Consider\\nthis method:\\n[MethodImpl(MethodImplOptions.NoIn\", \"lining)]\\nprivate static ushort[]? Convert(ReadOnlySpan<byte> bytes)\\n{\\nif (bytes.Length != 16)\\n{\\nretu\", \"rn null;\\n}\\nvar result = new ushort[8];\\nfor (int i = 0; i < result.Length; i++)\\n{\\nresult[i] = (ushort\", \")(bytes[i * 2] * 256 + bytes[i * 2 + 1]);\\n}\\nreturn result;\\n}\\nIt\\u2019s validating that the input span is \", \"16 bytes long and then creating a new ushort[8] where each\\nushort in the array combines two of the i\", \"nput bytes. To do that, it\\u2019s looping over the output array,\\nand indexing into the bytes array using \", \"i * 2 and i * 2 + 1 as the indices. On .NET 6, each of those\\nindexing operations would result in a b\", \"ounds check, with assembly like:\\ncmp r8d,10\\njae short G_M000_IG04\\nmovsxd r8,r8d\\nwhere that G_M000_IG\", \"04 is the call CORINFO_HELP_RNGCHKFAIL we\\u2019re now familiar with. But on .NET\\n7, we get this assembly \", \"for the method:\\nG_M000_IG01: ;; offset=0000H\\n56 push rsi\\n4883EC20 sub rsp, 32\\nG_M000_IG02: ;; offset\", \"=0005H\\n488B31 mov rsi, bword ptr [rcx]\\n8B4908 mov ecx, dword ptr [rcx+08H]\\n36 CHAPTER 2 | JIT83F910 \", \"cmp ecx, 16\\n754C jne SHORT G_M000_IG05\\n48B9302F542FFC7F0000 mov rcx, 0x7FFC2F542F30\\nBA08000000 mov e\", \"dx, 8\\nE80C1EB05F call CORINFO_HELP_NEWARR_1_VC\\n33D2 xor edx, edx\\nalign [0 bytes for IG03]\\nG_M000_IG0\", \"3: ;; offset=0026H\\n8D0C12 lea ecx, [rdx+rdx]\\n448BC1 mov r8d, ecx\\nFFC1 inc ecx\\n458BC0 mov r8d, r8d\\n46\", \"0FB60406 movzx r8, byte ptr [rsi+r8]\\n41C1E008 shl r8d, 8\\n8BC9 mov ecx, ecx\\n0FB60C0E movzx rcx, byte \", \"ptr [rsi+rcx]\\n4103C8 add ecx, r8d\\n0FB7C9 movzx rcx, cx\\n448BC2 mov r8d, edx\\n6642894C4010 mov word ptr\", \" [rax+2*r8+10H], cx\\nFFC2 inc edx\\n83FA08 cmp edx, 8\\n7CD0 jl SHORT G_M000_IG03\\nG_M000_IG04: ;; offset=\", \"0056H\\n4883C420 add rsp, 32\\n5E pop rsi\\nC3 ret\\nG_M000_IG05: ;; offset=005CH\\n33C0 xor rax, rax\\nG_M000_I\", \"G06: ;; offset=005EH\\n4883C420 add rsp, 32\\n5E pop rsi\\nC3 ret\\n; Total bytes of code 100\\nNo bounds chec\", \"ks, which is most easily seen by the lack of the telltale call\\nCORINFO_HELP_RNGCHKFAIL at the end of\", \" the method. With this PR, the JIT is able to understand the\\nimpact of certain multiplication and sh\", \"ift operations and their relationships to the bounds of the data\\nstructure. Since it can see that th\", \"e result array\\u2019s length is 8 and the loop is iterating from 0 to that\\nexclusive upper bound, it know\", \"s that i will always be in the range [0, 7], which means that i * 2 will\\nalways be in the range [0, \", \"14] and i * 2 + 1 will always be in the range [0, 15]. As such, it\\u2019s able\\nto prove that the bounds c\", \"hecks aren\\u2019t needed.\\ndotnet/runtime#61569 and dotnet/runtime#62864 also help to eliminate bounds che\", \"cks when dealing\\nwith constant strings and spans initialized from RVA statics (\\u201cRelative Virtual Add\", \"ress\\u201d static fields,\\nbasically a static field that lives in a module\\u2019s data section). For example, c\", \"onsider this benchmark:\\n[Benchmark]\\n[Arguments(1)]\\npublic char GetChar(int i)\\n{\\nconst string Text = \", \"\\\"hello\\\";\\n37 CHAPTER 2 | JITreturn (uint)i < Text.Length ? Text[i] : '\\\\0';\\n}\\nOn .NET 6, we get this a\", \"ssembly:\\n; Program.GetChar(Int32)\\nsub rsp,28\\nmov eax,edx\\ncmp rax,5\\njl short M00_L00\\nxor eax,eax\\nadd \", \"rsp,28\\nret\\nM00_L00:\\ncmp edx,5\\njae short M00_L01\\nmov rax,2278B331450\\nmov rax,[rax]\\nmovsxd rdx,edx\\nmov\", \"zx eax,word ptr [rax+rdx*2+0C]\\nadd rsp,28\\nret\\nM00_L01:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total by\", \"tes of code 56\\nThe beginning of this makes sense: the JIT was obviously able to see that the length \", \"of Text is 5, so\\nit\\u2019s implementing the (uint)i < Text.Length check by doing cmp rax,5, and if i as a\", \"n unsigned\\nvalue is greater than or equal to 5, it\\u2019s then zero\\u2019ing out the return value (to return t\", \"he '\\\\0') and\\nexiting. If the length is less than 5 (in which case it\\u2019s also at least 0 due to the un\", \"signed comparison), it\\nthen jumps to M00_L00 to read the value from the string\\u2026 but we then see anot\", \"her cmp against 5, this\\ntime as part of a range check. So even though the JIT knew the index was in \", \"bounds, it wasn\\u2019t able to\\nremove the bounds check. Now it is; in .NET 7, we get this:\\n; Program.GetC\", \"har(Int32)\\ncmp edx,5\\njb short M00_L00\\nxor eax,eax\\nret\\nM00_L00:\\nmov rax,2B0AF002530\\nmov rax,[rax]\\nmov\", \" edx,edx\\nmovzx eax,word ptr [rax+rdx*2+0C]\\nret\\n; Total bytes of code 29\\nSo much nicer.\\ndotnet/runtim\", \"e#67141 is a great example of how evolving ecosystem needs drives specific\\noptimizations into the JI\", \"T. The Regex compiler and source generator handle some cases of regular\\nexpression character classes\", \" by using a bitmap lookup stored in strings. For example, to determine\\nwhether a char c is in the ch\", \"aracter class \\\"[A-Za-z0-9_]\\\" (which will match an underscore or any\\nASCII letter or digit), the impl\", \"ementation ends up generating an expression like the body of the\\nfollowing method:\\n38 CHAPTER 2 | JI\", \"T[Benchmark]\\n[Arguments('a')]\\npublic bool IsInSet(char c) =>\\nc < 128 && (\\\"\\\\0\\\\0\\\\0\\\\u03FF\\\\uFFFE\\\\u87FF\\\\u\", \"FFFE\\\\u07FF\\\"[c >> 4] & (1 << (c & 0xF))) != 0;\\nThe implementation is treating an 8-character string a\", \"s a 128-bit lookup table. If the character is\\nknown to be in range (such that it\\u2019s effectively a 7-b\", \"it value), it\\u2019s then using the top 3 bits of the value\\nto index into the 8 elements of the string, a\", \"nd the bottom 4 bits to select one of the 16 bits in that\\nelement, giving us an answer as to whether\", \" this input character is in the set or not. In .NET 6, even\\nthough we know the character is in range\", \" of the string, the JIT couldn\\u2019t see through either the length\\ncomparison or the bit shift.\\n; Progra\", \"m.IsInSet(Char)\\nsub rsp,28\\nmovzx eax,dx\\ncmp eax,80\\njge short M00_L00\\nmov edx,eax\\nsar edx,4\\ncmp edx,8\", \"\\njae short M00_L01\\nmov rcx,299835A1518\\nmov rcx,[rcx]\\nmovsxd rdx,edx\\nmovzx edx,word ptr [rcx+rdx*2+0C\", \"]\\nand eax,0F\\nbt edx,eax\\nsetb al\\nmovzx eax,al\\nadd rsp,28\\nret\\nM00_L00:\\nxor eax,eax\\nadd rsp,28\\nret\\nM00_\", \"L01:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total bytes of code 75\\nThe previously mentioned PR takes c\", \"are of the length check. And this PR takes care of the bit shift. So\\nin .NET 7, we get this loveline\", \"ss:\\n; Program.IsInSet(Char)\\nmovzx eax,dx\\ncmp eax,80\\njge short M00_L00\\nmov edx,eax\\nsar edx,4\\nmov rcx,\", \"197D4800608\\nmov rcx,[rcx]\\nmov edx,edx\\nmovzx edx,word ptr [rcx+rdx*2+0C]\\nand eax,0F\\nbt edx,eax\\nsetb a\", \"l\\nmovzx eax,al\\nret\\n39 CHAPTER 2 | JITM00_L00:\\nxor eax,eax\\nret\\n; Total bytes of code 51\\nNote the dist\", \"inct lack of a call CORINFO_HELP_RNGCHKFAIL. And as you might guess, this check can\\nhappen a lot in \", \"a Regex, making this a very useful addition.\\nBounds checks are an obvious source of overhead when ta\", \"lking about array access, but they\\u2019re not the\\nonly ones. There\\u2019s also the need to use the cheapest i\", \"nstructions possible. In .NET 6, with a method\\nlike:\\n[MethodImpl(MethodImplOptions.NoInlining)]\\npriv\", \"ate static int Get(int[] values, int i) => values[i];\\nassembly code like the following would be gene\", \"rated:\\n; Program.Get(Int32[], Int32)\\nsub rsp,28\\ncmp edx,[rcx+8]\\njae short M01_L00\\nmovsxd rax,edx\\nmov\", \" eax,[rcx+rax*4+10]\\nadd rsp,28\\nret\\nM01_L00:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total bytes of code\", \" 27\\nThis should look fairly familiar from our previous discussion; the JIT is loading the array\\u2019s le\", \"ngth\\n([rcx+8]) and comparing that with the value of i (in edx), and then jumping to the end to throw\", \" an\\nexception if i is out of bounds. Immediately after that jump we see a movsxd rax, edx instructio\", \"n,\\nwhich is taking the 32-bit value of i from edx and moving it into the 64-bit register rax. And as\", \" part\\nof moving it, it\\u2019s sign-extending it; that\\u2019s the \\u201csxd\\u201d part of the instruction name (sign-exte\", \"nding means\\nthe upper 32 bits of the new 64-bit value will be set to the value of the upper bit of t\", \"he 32-bit value,\\nso that the number retains its signed value). The interesting thing is, though, we \", \"know that the Length\\nof an array and of a span is non-negative, and since we just bounds checked i a\", \"gainst the Length, we\\nalso know that i is non-negative. That makes such sign-extension useless, sinc\", \"e the upper bit is\\nguaranteed to be 0. Since the mov instruction that zero-extends is a tad cheaper \", \"than movsxd, we can\\nsimply use that instead. And that\\u2019s exactly what dotnet/runtime#57970 from\\n[@pen\", \"tp](https://github.com/pentp) does for both arrays and spans (dotnet/runtime#70884 also\\nsimilarly av\", \"oids some signed casts in other situations). Now on .NET 7, we get this:\\n; Program.Get(Int32[], Int3\", \"2)\\nsub rsp,28\\ncmp edx,[rcx+8]\\njae short M01_L00\\nmov eax,edx\\nmov eax,[rcx+rax*4+10]\\nadd rsp,28\\nret\\nM0\", \"1_L00:\\ncall CORINFO_HELP_RNGCHKFAIL\\n40 CHAPTER 2 | JITint 3\\n; Total bytes of code 26\\nThat\\u2019s not the \", \"only source of overhead with array access, though. In fact, there\\u2019s a very large category\\nof array a\", \"ccess overhead that\\u2019s been there forever, but that\\u2019s so well known there are even old FxCop\\nrules an\", \"d newer Roslyn analyzers that warn against it: multidimensional array accesses. The overhead\\nin the \", \"case of a multidimensional array isn\\u2019t just an extra branch on every indexing operation, or\\naddition\", \"al math required to compute the location of the element, but rather that they currently pass\\nthrough\", \" the JIT\\u2019s optimization phases largely unmodified. dotnet/runtime#70271 improves the state\\nof the wo\", \"rld here by doing an expansion of a multidimensional array access early in the JIT\\u2019s pipeline,\\nsuch \", \"that later optimization phases can improve multidimensional accesses as they would other code,\\ninclu\", \"ding CSE and loop invariant hoisting. The impact of this is visible in a simple benchmark that\\nsums \", \"all the elements of a multidimensional array.\\nprivate int[,] _square;\\n[Params(1000)]\\npublic int Size\", \" { get; set; }\\n[GlobalSetup]\\npublic void Setup()\\n{\\nint count = 0;\\n_square = new int[Size, Size];\\nfor\", \" (int i = 0; i < Size; i++)\\n{\\nfor (int j = 0; j < Size; j++)\\n{\\n_square[i, j] = count++;\\n}\\n}\\n}\\n[Bench\", \"mark]\\npublic int Sum()\\n{\\nint[,] square = _square;\\nint sum = 0;\\nfor (int i = 0; i < Size; i++)\\n{\\nfor \", \"(int j = 0; j < Size; j++)\\n{\\nsum += square[i, j];\\n}\\n}\\nreturn sum;\\n}\\nMethod Runtime Mean Ratio\\nSum .N\", \"ET 6.0 964.1 us 1.00\\nSum .NET 7.0 674.7 us 0.70\\nThis previous example assumes you know the size of e\", \"ach dimension of the multidimensional array\\n(it\\u2019s referring to the Size directly in the loops). That\", \"\\u2019s obviously not always (or maybe even rarely) the\\ncase. In such situations, you\\u2019d be more likely to\", \" use the Array.GetUpperBound method, and because\\n41 CHAPTER 2 | JITmultidimensional arrays can have \", \"a non-zero lower bound, Array.GetLowerBound. That would lead to\\ncode like this:\\nprivate int[,] _squa\", \"re;\\n[Params(1000)]\\npublic int Size { get; set; }\\n[GlobalSetup]\\npublic void Setup()\\n{\\nint count = 0;\\n\", \"_square = new int[Size, Size];\\nfor (int i = 0; i < Size; i++)\\n{\\nfor (int j = 0; j < Size; j++)\\n{\\n_sq\", \"uare[i, j] = count++;\\n}\\n}\\n}\\n[Benchmark]\\npublic int Sum()\\n{\\nint[,] square = _square;\\nint sum = 0;\\nfor\", \" (int i = square.GetLowerBound(0); i < square.GetUpperBound(0); i++)\\n{\\nfor (int j = square.GetLowerB\", \"ound(1); j < square.GetUpperBound(1); j++)\\n{\\nsum += square[i, j];\\n}\\n}\\nreturn sum;\\n}\\nIn .NET 7, thank\", \"s to dotnet/runtime#60816, those GetLowerBound and GetUpperBound calls become\\nJIT intrinsics. An \\u201cin\", \"trinsic\\u201d to a compiler is something the compiler has intrinsic knowledge of, such\\nthat rather than r\", \"elying solely on a method\\u2019s defined implementation (if it even has one), the compiler\\ncan substitute\", \" in something it considers to be better. There are literally thousands of methods in .NET\\nknown in t\", \"his manner to the JIT, with GetLowerBound and GetUpperBound being two of the most\\nrecent. Now as int\", \"rinsics, when they\\u2019re passed a constant value (e.g. 0 for the 0th rank), the JIT can\\nsubstitute the \", \"necessary assembly instructions to read directly from the memory location that houses\\nthe bounds. He\", \"re\\u2019s what the assembly code for this benchmark looked like with .NET 6; the main thing\\nto see here a\", \"re all of the calls out to GetLowerBound and GetUpperBound:\\n; Program.Sum()\\npush rdi\\npush rsi\\npush r\", \"bp\\npush rbx\\nsub rsp,28\\nmov rsi,[rcx+8]\\nxor edi,edi\\nmov rcx,rsi\\nxor edx,edx\\n42 CHAPTER 2 | JITcmp [rc\", \"x],ecx\\ncall System.Array.GetLowerBound(Int32)\\nmov ebx,eax\\nmov rcx,rsi\\nxor edx,edx\\ncall System.Array.\", \"GetUpperBound(Int32)\\ncmp eax,ebx\\njle short M00_L03\\nM00_L00:\\nmov rcx,[rsi]\\nmov ecx,[rcx+4]\\nadd ecx,0F\", \"FFFFFE8\\nshr ecx,3\\ncmp ecx,1\\njbe short M00_L05\\nlea rdx,[rsi+10]\\ninc ecx\\nmovsxd rcx,ecx\\nmov ebp,[rdx+r\", \"cx*4]\\nmov rcx,rsi\\nmov edx,1\\ncall System.Array.GetUpperBound(Int32)\\ncmp eax,ebp\\njle short M00_L02\\nM00\", \"_L01:\\nmov ecx,ebx\\nsub ecx,[rsi+18]\\ncmp ecx,[rsi+10]\\njae short M00_L04\\nmov edx,ebp\\nsub edx,[rsi+1C]\\nc\", \"mp edx,[rsi+14]\\njae short M00_L04\\nmov eax,[rsi+14]\\nimul rax,rcx\\nmov rcx,rdx\\nadd rcx,rax\\nadd edi,[rsi\", \"+rcx*4+20]\\ninc ebp\\nmov rcx,rsi\\nmov edx,1\\ncall System.Array.GetUpperBound(Int32)\\ncmp eax,ebp\\njg short\", \" M00_L01\\nM00_L02:\\ninc ebx\\nmov rcx,rsi\\nxor edx,edx\\ncall System.Array.GetUpperBound(Int32)\\ncmp eax,ebx\", \"\\njg short M00_L00\\nM00_L03:\\nmov eax,edi\\nadd rsp,28\\npop rbx\\npop rbp\\npop rsi\\npop rdi\\nret\\nM00_L04:\\ncall \", \"CORINFO_HELP_RNGCHKFAIL\\n43 CHAPTER 2 | JITM00_L05:\\nmov rcx,offset MT_System.IndexOutOfRangeException\", \"\\ncall CORINFO_HELP_NEWSFAST\\nmov rsi,rax\\ncall System.SR.get_IndexOutOfRange_ArrayRankIndex()\\nmov rdx,\", \"rax\\nmov rcx,rsi\\ncall System.IndexOutOfRangeException..ctor(System.String)\\nmov rcx,rsi\\ncall CORINFO_H\", \"ELP_THROW\\nint 3\\n; Total bytes of code 219\\nNow here\\u2019s what it is for .NET 7:\\n; Program.Sum()\\npush r14\", \"\\npush rdi\\npush rsi\\npush rbp\\npush rbx\\nsub rsp,20\\nmov rdx,[rcx+8]\\nxor eax,eax\\nmov ecx,[rdx+18]\\nmov r8d\", \",ecx\\nmov r9d,[rdx+10]\\nlea ecx,[rcx+r9+0FFFF]\\ncmp ecx,r8d\\njle short M00_L03\\nmov r9d,[rdx+1C]\\nmov r10d\", \",[rdx+14]\\nlea r10d,[r9+r10+0FFFF]\\nM00_L00:\\nmov r11d,r9d\\ncmp r10d,r11d\\njle short M00_L02\\nmov esi,r8d\\n\", \"sub esi,[rdx+18]\\nmov edi,[rdx+10]\\nM00_L01:\\nmov ebx,esi\\ncmp ebx,edi\\njae short M00_L04\\nmov ebp,[rdx+14\", \"]\\nimul ebx,ebp\\nmov r14d,r11d\\nsub r14d,[rdx+1C]\\ncmp r14d,ebp\\njae short M00_L04\\nadd ebx,r14d\\nadd eax,[\", \"rdx+rbx*4+20]\\ninc r11d\\ncmp r10d,r11d\\njg short M00_L01\\nM00_L02:\\ninc r8d\\ncmp ecx,r8d\\njg short M00_L00\\n\", \"M00_L03:\\n44 CHAPTER 2 | JITadd rsp,20\\npop rbx\\npop rbp\\npop rsi\\npop rdi\\npop r14\\nret\\nM00_L04:\\ncall CORI\", \"NFO_HELP_RNGCHKFAIL\\nint 3\\n; Total bytes of code 130\\nImportantly, note there are no more calls (other\", \" than for the bounds check exception at the end). For\\nexample, instead of that first GetUpperBound c\", \"all:\\ncall System.Array.GetUpperBound(Int32)\\nwe get:\\nmov r9d,[rdx+1C]\\nmov r10d,[rdx+14]\\nlea r10d,[r9+\", \"r10+0FFFF]\\nand it ends up being much faster:\\nMethod Runtime Mean Ratio\\nSum .NET 6.0 2,657.5 us 1.00\\n\", \"Sum .NET 7.0 676.3 us 0.25\\nLoop Hoisting and Cloning\\nWe previously saw how PGO interacts with loop h\", \"oisting and cloning, and those optimizations have\\nseen other improvements, as well.\\nHistorically, th\", \"e JIT\\u2019s support for hoisting has been limited to lifting an invariant out one level.\\nConsider this e\", \"xample:\\n[Benchmark]\\npublic void Compute()\\n{\\nfor (int thousands = 0; thousands < 10; thousands++)\\n{\\nf\", \"or (int hundreds = 0; hundreds < 10; hundreds++)\\n{\\nfor (int tens = 0; tens < 10; tens++)\\n{\\nfor (int \", \"ones = 0; ones < 10; ones++)\\n{\\nint n = ComputeNumber(thousands, hundreds, tens, ones);\\nProcess(n);\\n}\", \"\\n}\\n}\\n}\\n}\\n45 CHAPTER 2 | JITstatic int ComputeNumber(int thousands, int hundreds, int tens, int ones)\", \" =>\\n(thousands * 1000) +\\n(hundreds * 100) +\\n(tens * 10) +\\nones;\\n[MethodImpl(MethodImplOptions.NoInli\", \"ning)]\\nstatic void Process(int n) { }\\nAt first glance, you might look at this and say \\u201cwhat could be\", \" hoisted, the computation of n requires\\nall of the loop inputs, and all of that computation is in Co\", \"mputeNumber.\\u201d But from a compiler\\u2019s\\nperspective, the ComputeNumber function is inlineable and thus l\", \"ogically can be part of its caller, the\\ncomputation of n is actually split into multiple pieces, and\", \" each of those pieces can be hoisted to\\ndifferent levels, e.g. the tens computation can be hoisted o\", \"ut one level, the hundreds out two levels,\\nand the thousands out three levels. Here\\u2019s what [Disassem\", \"blyDiagnoser] outputs for .NET 6:\\n; Program.Compute()\\npush r14\\npush rdi\\npush rsi\\npush rbp\\npush rbx\\ns\", \"ub rsp,20\\nxor esi,esi\\nM00_L00:\\nxor edi,edi\\nM00_L01:\\nxor ebx,ebx\\nM00_L02:\\nxor ebp,ebp\\nimul ecx,esi,3E\", \"8\\nimul eax,edi,64\\nadd ecx,eax\\nlea eax,[rbx+rbx*4]\\nlea r14d,[rcx+rax*2]\\nM00_L03:\\nlea ecx,[r14+rbp]\\nca\", \"ll Program.Process(Int32)\\ninc ebp\\ncmp ebp,0A\\njl short M00_L03\\ninc ebx\\ncmp ebx,0A\\njl short M00_L02\\nin\", \"c edi\\ncmp edi,0A\\njl short M00_L01\\ninc esi\\ncmp esi,0A\\njl short M00_L00\\nadd rsp,20\\npop rbx\\npop rbp\\npop\", \" rsi\\npop rdi\\npop r14\\nret\\n; Total bytes of code 84\\n46 CHAPTER 2 | JITWe can see that some hoisting ha\", \"s happened here. After all, the inner most loop (tagged M00_L03) is\\nonly five instructions: incremen\", \"t ebp (which at this point is the ones counter value), and if it\\u2019s still less\\nthan 0xA (10), jump ba\", \"ck to M00_L03 which adds whatever is in r14 to ones. Great, so we\\u2019ve hoisted\\nall of the unnecessary \", \"computation out of the inner loop, being left only with adding the ones\\nposition to the rest of the \", \"number. Let\\u2019s go out a level. M00_L02 is the label for the tens loop. What\\ndo we see there? Trouble.\", \" The two instructions imul ecx,esi,3E8 and imul eax,edi,64 are\\nperforming the thousands * 1000 and h\", \"undreds * 100 operations, highlighting that these\\noperations which could have been hoisted out furth\", \"er were left stuck in the next-to-innermost loop.\\nNow, here\\u2019s what we get for .NET 7, where this was\", \" improved in dotnet/runtime#68061:\\n; Program.Compute()\\npush r15\\npush r14\\npush r12\\npush rdi\\npush rsi\\n\", \"push rbp\\npush rbx\\nsub rsp,20\\nxor esi,esi\\nM00_L00:\\nxor edi,edi\\nimul ebx,esi,3E8\\nM00_L01:\\nxor ebp,ebp\\n\", \"imul r14d,edi,64\\nadd r14d,ebx\\nM00_L02:\\nxor r15d,r15d\\nlea ecx,[rbp+rbp*4]\\nlea r12d,[r14+rcx*2]\\nM00_L0\", \"3:\\nlea ecx,[r12+r15]\\ncall qword ptr [Program.Process(Int32)]\\ninc r15d\\ncmp r15d,0A\\njl short M00_L03\\ni\", \"nc ebp\\ncmp ebp,0A\\njl short M00_L02\\ninc edi\\ncmp edi,0A\\njl short M00_L01\\ninc esi\\ncmp esi,0A\\njl short M\", \"00_L00\\nadd rsp,20\\npop rbx\\npop rbp\\npop rsi\\npop rdi\\npop r12\\npop r14\\npop r15\\nret\\n; Total bytes of code \", \"99\\n47 CHAPTER 2 | JITNotice now where those imul instructions live. There are four labels, each one \", \"corresponding to one\\nof the loops, and we can see the outermost loop has the imul ebx,esi,3E8 (for t\", \"he thousands\\ncomputation) and the next loop has the imul r14d,edi,64 (for the hundreds computation),\", \"\\nhighlighting that these computations were hoisted out to the appropriate level (the tens and ones\\nc\", \"omputation are still in the right places).\\nMore improvements have gone in on the cloning side. Previ\", \"ously, loop cloning would only apply for\\nloops iterating by 1 from a low to a high value. With dotne\", \"t/runtime#60148, the comparison against\\nthe upper value can be <= rather than just <. And with dotne\", \"t/runtime#67930, loops that iterate\\ndownward can also be cloned, as can loops that have increments a\", \"nd decrements larger than 1.\\nConsider this benchmark:\\nprivate int[] _values = Enumerable.Range(0, 10\", \"00).ToArray();\\n[Benchmark]\\n[Arguments(0, 0, 1000)]\\npublic int LastIndexOf(int arg, int offset, int c\", \"ount)\\n{\\nint[] values = _values;\\nfor (int i = offset + count - 1; i >= offset; i--)\\nif (values[i] == \", \"arg)\\nreturn i;\\nreturn 0;\\n}\\nWithout loop cloning, the JIT can\\u2019t assume that offset through offset+cou\", \"nt are in range, and thus\\nevery access to the array needs to be bounds checked. With loop cloning, t\", \"he JIT could generate one\\nversion of the loop without bounds checks and only use that when it knows \", \"all accesses will be valid.\\nThat\\u2019s exactly what happens now in .NET 7. Here\\u2019s what we got with .NET \", \"6:\\n; Program.LastIndexOf(Int32, Int32, Int32)\\nsub rsp,28\\nmov rcx,[rcx+8]\\nlea eax,[r8+r9+0FFFF]\\ncmp e\", \"ax,r8d\\njl short M00_L01\\nmov r9d,[rcx+8]\\nnop word ptr [rax+rax]\\nM00_L00:\\ncmp eax,r9d\\njae short M00_L0\", \"3\\nmovsxd r10,eax\\ncmp [rcx+r10*4+10],edx\\nje short M00_L02\\ndec eax\\ncmp eax,r8d\\njge short M00_L00\\nM00_L\", \"01:\\nxor eax,eax\\nadd rsp,28\\nret\\nM00_L02:\\nadd rsp,28\\nret\\nM00_L03:\\ncall CORINFO_HELP_RNGCHKFAIL\\n48 CHAP\", \"TER 2 | JITint 3\\n; Total bytes of code 72\\nNotice how in the core loop, at label M00_L00, there\\u2019s a b\", \"ounds check (cmp eax,r9d and jae short\\nM00_L03, which jumps to a call CORINFO_HELP_RNGCHKFAIL). And \", \"here\\u2019s what we get with .NET 7:\\n; Program.LastIndexOf(Int32, Int32, Int32)\\nsub rsp,28\\nmov rax,[rcx+8\", \"]\\nlea ecx,[r8+r9+0FFFF]\\ncmp ecx,r8d\\njl short M00_L02\\ntest rax,rax\\nje short M00_L01\\ntest ecx,ecx\\njl s\", \"hort M00_L01\\ntest r8d,r8d\\njl short M00_L01\\ncmp [rax+8],ecx\\njle short M00_L01\\nM00_L00:\\nmov r9d,ecx\\ncm\", \"p [rax+r9*4+10],edx\\nje short M00_L03\\ndec ecx\\ncmp ecx,r8d\\njge short M00_L00\\njmp short M00_L02\\nM00_L01\", \":\\ncmp ecx,[rax+8]\\njae short M00_L04\\nmov r9d,ecx\\ncmp [rax+r9*4+10],edx\\nje short M00_L03\\ndec ecx\\ncmp e\", \"cx,r8d\\njge short M00_L01\\nM00_L02:\\nxor eax,eax\\nadd rsp,28\\nret\\nM00_L03:\\nmov eax,ecx\\nadd rsp,28\\nret\\nM00\", \"_L04:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total bytes of code 98\\nNotice how the code size is larger\", \", and how there are now two variations of the loop: one at M00_L00\\nand one at M00_L01. The second on\", \"e, M00_L01, has a branch to that same call\\nCORINFO_HELP_RNGCHKFAIL, but the first one doesn\\u2019t, becau\", \"se that loop will only end up being used\\nafter proving that the offset, count, and _values.Length ar\", \"e such that the indexing will always be in\\nbounds.\\nOther changes also improved loop cloning. dotnet/\", \"runtime#59886 enables the JIT to choose different\\nforms for how to emit the the conditions for choos\", \"ing the fast or slow loop path, e.g. whether to emit\\n49 CHAPTER 2 | JITall the conditions, & them to\", \"gether, and then branch (if (!(cond1 & cond2)) goto slowPath), or\\nwhether to emit each condition on \", \"its own (if (!cond1) goto slowPath; if (!cond2) goto\\nslowPath). dotnet/runtime#66257 enables loop cl\", \"oning to kick in when the loop variable is initialized\\nto more kinds of expressions (e.g. for (int f\", \"romindex = lastIndex - lengthToClear; ...)). And\\ndotnet/runtime#70232 increases the JIT\\u2019s willingnes\", \"s to clone loops with bodies that do a broader set\\nof operations.\\nFolding, propagation, and substitu\", \"tion\\nConstant folding is an optimization where a compiler computes the value of an expression involv\", \"ing\\nonly constants at compile-time rather than generating the code to compute the value at run-time.\", \"\\nThere are multiple levels of constant folding in .NET, with some constant folding performed by the \", \"C#\\ncompiler and some constant folding performed by the JIT compiler. For example, given the C# code:\", \"\\n[Benchmark]\\npublic int A() => 3 + (4 * 5);\\n[Benchmark]\\npublic int B() => A() * 2;\\nthe C# compiler w\", \"ill generate IL for these methods like the following:\\n.method public hidebysig instance int32 A () c\", \"il managed\\n{\\n.maxstack 8\\nIL_0000: ldc.i4.s 23\\nIL_0002: ret\\n}\\n.method public hidebysig instance int32\", \" B () cil managed\\n{\\n.maxstack 8\\nIL_0000: ldarg.0\\nIL_0001: call instance int32 Program::A()\\nIL_0006: \", \"ldc.i4.2\\nIL_0007: mul\\nIL_0008: ret\\n}\\nYou can see that the C# compiler has computed the value of 3 + \", \"(4*5), as the IL for method A simply\\ncontains the equivalent of return 23;. However, method B contai\", \"ns the equivalent of return A() *\\n2;, highlighting that the constant folding performed by the C# com\", \"piler was intramethod only. Now\\nhere\\u2019s what the JIT generates:\\n; Program.A()\\nmov eax,17\\nret\\n; Total \", \"bytes of code 6\\n; Program.B()\\nmov eax,2E\\nret\\n; Total bytes of code 6\\n50 CHAPTER 2 | JITThe assembly \", \"for method A isn\\u2019t particularly interesting; it\\u2019s just returning that same value 23 (hex\\n0x17). But \", \"method B is more interesting. The JIT has inlined the call from B to A, exposing the contents\\nof A t\", \"o B, such that the JIT effectively sees the body of B as the equivalent of return 23 * 2;. At that\\np\", \"oint, the JIT can do its own constant folding, and it transforms the body of B to simply return 46 (\", \"hex\\n0x2e). Constant propagation is intricately linked to constant folding and is essentially just th\", \"e idea that\\nyou can substitute a constant value (typically one computed via constant folding) into f\", \"urther\\nexpressions, at which point they may also be able to be folded.\\nThe JIT has long performed co\", \"nstant folding, but it improves further in .NET 7. One of the ways\\nconstant folding can improve is b\", \"y exposing more values to be folded, which often means more\\ninlining. dotnet/runtime#55745 helped th\", \"e inliner to understand that a method call like M(constant +\\nconstant) (noting that those constants \", \"might be the result of some other method call) is itself\\npassing a constant to M, and a constant bei\", \"ng passed to a method call is a hint to the inliner that it\\nshould consider being more aggressive ab\", \"out inlining, since exposing that constant to the body of the\\ncallee can potentially significantly r\", \"educe the amount of code required to implement the callee. The\\nJIT might have previously inlined suc\", \"h a method anyway, but when it comes to inlining, the JIT is all\\nabout heuristics and generating eno\", \"ugh evidence that it\\u2019s worthwhile to inline something; this\\ncontributes to that evidence. This patte\", \"rn shows up, for example, in the various FromXx methods on\\nTimeSpan. For example, TimeSpan.FromSecon\", \"ds is implemented as:\\npublic static TimeSpan FromSeconds(double value) => Interval(value, TicksPerSe\", \"cond); //\\nTicksPerSecond is a constant\\nand, eschewing argument validation for the purposes of this e\", \"xample, Interval is:\\nprivate static TimeSpan Interval(double value, double scale) =>\\nIntervalFromDou\", \"bleTicks(value * scale);\\nprivate static TimeSpan IntervalFromDoubleTicks(double ticks) => ticks == l\", \"ong.MaxValue ?\\nTimeSpan.MaxValue : new TimeSpan((long)ticks);\\nwhich if everything gets inlined means\", \" FromSeconds is essentially:\\npublic static TimeSpan FromSeconds(double value)\\n{\\ndouble ticks = value\", \" * 10_000_000;\\nreturn ticks == long.MaxValue ? TimeSpan.MaxValue : new TimeSpan((long)ticks);\\n}\\nand \", \"if value is a constant, let\\u2019s say 5, that whole thing can be constant folded (with dead code\\nelimina\", \"tion on the ticks == long.MaxValue branch) to simply:\\nreturn new TimeSpan(50_000_000);\\nI\\u2019ll spare yo\", \"u the .NET 6 assembly for this, but on .NET 7 with a benchmark like:\\n[Benchmark]\\npublic TimeSpan Fro\", \"mSeconds() => TimeSpan.FromSeconds(5);\\nwe now get the simple and clean:\\n; Program.FromSeconds()\\nmov \", \"eax,2FAF080\\n51 CHAPTER 2 | JITret\\n; Total bytes of code 6\\nAnother change improving constant folding \", \"included dotnet/runtime#57726 from\\n[@SingleAccretion](https://github.com/SingleAccretion), which unb\", \"locked constant folding in a\\nparticular scenario that sometimes manifests when doing field-by-field \", \"assignment of structs being\\nreturned from method calls. As a small example, consider this trivial pr\", \"operty, which access the\\nColor.DarkOrange property, which in turn does new Color(KnownColor.DarkOran\", \"ge):\\n[Benchmark]\\npublic Color DarkOrange() => Color.DarkOrange;\\nIn .NET 6, the JIT generated this:\\n;\", \" Program.DarkOrange()\\nmov eax,1\\nmov ecx,39\\nxor r8d,r8d\\nmov [rdx],r8\\nmov [rdx+8],r8\\nmov [rdx+10],cx\\nm\", \"ov [rdx+12],ax\\nmov rax,rdx\\nret\\n; Total bytes of code 32\\nThe interesting thing here is that some cons\", \"tants (39, which is the value of KnownColor.DarkOrange,\\nand 1, which is a private StateKnownColorVal\", \"id constant) are being loaded into registers (mov eax,\\n1, mov ecx, 39) and then later being stored i\", \"nto the relevant location for the Color struct being\\nreturned (mov [rdx+12],ax and mov [rdx+10],cx).\", \" In .NET 7, it now generates:\\n; Program.DarkOrange()\\nxor eax,eax\\nmov [rdx],rax\\nmov [rdx+8],rax\\nmov w\", \"ord ptr [rdx+10],39\\nmov word ptr [rdx+12],1\\nmov rax,rdx\\nret\\n; Total bytes of code 25\\nwith direct ass\", \"ignment of these constant values into their destination locations (mov word ptr\\n[rdx+12],1 and mov w\", \"ord ptr [rdx+10],39). Other changes contributing to constant folding\\nincluded dotnet/runtime#58171 f\", \"rom [@SingleAccretion](https://github.com/SingleAccretion) and\\ndotnet/runtime#57605 from [@SingleAcc\", \"retion](https://github.com/SingleAccretion).\\nHowever, a large category of improvement came from an o\", \"ptimization related to propagation, that of\\nforward substitution. Consider this silly benchmark:\\n[Be\", \"nchmark]\\npublic int Compute1() => Value + Value + Value + Value + Value;\\n[Benchmark]\\npublic int Comp\", \"ute2() => SomethingElse() + Value + Value + Value + Value + Value;\\nprivate static int Value => 16;\\n5\", \"2 CHAPTER 2 | JIT[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static int SomethingElse() => 42\", \";\\nIf we look at the assembly code generated for Compute1 on .NET 6, it looks like what we\\u2019d hope for\", \".\\nWe\\u2019re adding Value 5 times, Value is trivially inlined and returns a constant value 16, and so we\\u2019\", \"d\\nhope that the assembly code generated for Compute1 would effectively just be returning the value 8\", \"0\\n(hex 0x50), which is exactly what happens:\\n; Program.Compute1()\\nmov eax,50\\nret\\n; Total bytes of co\", \"de 6\\nBut Compute2 is a bit different. The structure of the code is such that the additional call to\\n\", \"SomethingElse ends up slightly perturbing something about the JIT\\u2019s analysis, and .NET 6 ends up\\nwit\", \"h this assembly code:\\n; Program.Compute2()\\nsub rsp,28\\ncall Program.SomethingElse()\\nadd eax,10\\nadd ea\", \"x,10\\nadd eax,10\\nadd eax,10\\nadd eax,10\\nadd rsp,28\\nret\\n; Total bytes of code 29\\nRather than a single m\", \"ov eax, 50 to put the value 0x50 into the return register, we have 5 separate\\nadd eax, 10 to build u\", \"p that same 0x50 (80) value. That\\u2019s\\u2026 not ideal.\\nIt turns out that many of the JIT\\u2019s optimizations op\", \"erate on the tree data structures created as part of\\nparsing the IL. In some cases, optimizations ca\", \"n do better when they\\u2019re exposed to more of the\\nprogram, in other words when the tree they\\u2019re operat\", \"ing on is larger and contains more to be\\nanalyzed. However, various operations can break up these tr\", \"ees into smaller, individual ones, such as\\nwith temporary variables created as part of inlining, and\", \" in doing so can inhibit these operations.\\nSomething is needed in order to effectively stitch these \", \"trees back together, and that\\u2019s forward\\nsubstitution. You can think of forward substitution almost l\", \"ike an inverse of CSE; rather than trying to\\nfind duplicate expressions and eliminate them by comput\", \"ing the value once and storing it into a\\ntemporary, forward substitution eliminates that temporary a\", \"nd effectively moves the expression tree\\ninto its use site. Obviously you don\\u2019t want to do this if i\", \"t would then negate CSE and result in\\nduplicate work, but for expressions that are defined once and \", \"used once, this kind of forward\\npropagation is valuable. dotnet/runtime#61023 added an initial limit\", \"ed version of forward\\nsubstitution, and then dotnet/runtime#63720 added a more robust generalized im\", \"plementation.\\nSubsequently, dotnet/runtime#70587 expanded it to also cover some SIMD vectors, and th\", \"en\\ndotnet/runtime#71161 improved it further to enable substitutions into more places (in this case i\", \"nto\\ncall arguments). And with those, our silly benchmark now produces the following on .NET 7:\\n; Pro\", \"gram.Compute2()\\nsub rsp,28\\ncall qword ptr [7FFCB8DAF9A8]\\n53 CHAPTER 2 | JITadd eax,50\\nadd rsp,28\\nret\", \"\\n; Total bytes of code 18\\nVectorization\\nSIMD, or Single Instruction Multiple Data, is a kind of proc\", \"essing in which one instruction applies to\\nmultiple pieces of data at the same time. You\\u2019ve got a li\", \"st of numbers and you want to find the index\\nof a particular value? You could walk the list comparin\", \"g one element at a time, and that would be fine\\nfunctionally. But what if in the same amount of time\", \" it takes you to read and compare one element,\\nyou could instead read and compare two elements, or f\", \"our elements, or 32 elements? That\\u2019s SIMD,\\nand the art of utilizing SIMD instructions is lovingly re\", \"ferred to as \\u201cvectorization,\\u201d where operations\\nare applied to all of the elements in a \\u201cvector\\u201d at t\", \"he same time.\\n.NET has long had support for vectorization in the form of Vector<T>, which is an easy\", \"-to-use type\\nwith first-class JIT support to enable a developer to write vectorized implementations.\", \" One of\\nVector<T>\\u2019s greatest strengths is also one of its greatest weaknesses. The type is designed \", \"to adapt to\\nwhatever width vector instructions are available in your hardware. If the machine suppor\", \"ts 256-bit\\nwidth vectors, great, that\\u2019s what Vector<T> will target. If not, if the machine supports \", \"128-bit width\\nvectors, great, that\\u2019s what Vector<T> targets. But that flexibility comes with various\", \" downsides, at least\\ntoday; for example, the operations you can perform on a Vector<T> end up needin\", \"g to be agnostic to\\nthe width of the vectors used, since the width is variable based on the hardware\", \" on which the code\\nactually runs. And that means the operations that can be exposed on Vector<T> are\", \" limited, which in\\nturn limits the kinds of operations that can be vectorized with it. Also, because\", \" it\\u2019s only ever a single\\nsize in a given process, some data set sizes that fall in between 128 bits \", \"and 256 bits might not be\\nprocessed as well as you\\u2019d hope. You write your Vector<byte>-based algorit\", \"hm, and you run it on a\\nmachine with support for 256-bit vectors, which means it can process 32 byte\", \"s at a time, but then you\\nfeed it an input with 31 bytes. Had Vector<T> mapped to 128-bit vectors, i\", \"t could have been used to\\nimprove the processing of that input, but as its vector size is larger tha\", \"n the input data size, the\\nimplementation ends up falling back to one that\\u2019s not accelerated. There \", \"are also issues related to\\nR2R and Native AOT, since ahead-of-time compilation needs to know in adva\", \"nce what instructions\\nshould be used for Vector<T> operations. You already saw this earlier when dis\", \"cussing the output of\\nDOTNET_JitDisasmSummary; we saw that the NarrowUtf16ToAscii method was one of \", \"only a few\\nmethods that was JIT compiled in a \\u201chello, world\\u201d console app, and that this was because \", \"it lacked R2R\\ncode due to its use of Vector<T>.\\nStarting in .NET Core 3.0, .NET gained literally tho\", \"usands of new \\u201chardware intrinsics\\u201d methods, most\\nof which are .NET APIs that map down to one of the\", \"se SIMD instructions. These intrinsics enable an\\nexpert to write an implementation tuned to a specif\", \"ic instruction set, and if done well, get the best\\npossible performance, but it also requires the de\", \"veloper to understand each instruction set and to\\nimplement their algorithm for each instruction set\", \" that might be relevant, e.g. an AVX2\\nimplementation if it\\u2019s supported, or an SSE2 implementation if\", \" it\\u2019s supported, or an ArmBase\\nimplementation if it\\u2019s supported, and so on.\\n.NET 7 has introduced a \", \"middle ground. Previous releases saw the introduction of the Vector128<T>\\nand Vector256<T> types, bu\", \"t purely as the vehicle by which data moved in and out of the hardware\\nintrinsics, since they\\u2019re all\", \" tied to specific width vectors. Now in .NET 7, exposed via\\n54 CHAPTER 2 | JITdotnet/runtime#53450, \", \"dotnet/runtime#63414, dotnet/runtime#60094, and dotnet/runtime#68559, a\\nvery large set of cross-plat\", \"form operations is defined over these types as well, e.g.\\nVector128<T>.ExtractMostSignificantBits, V\", \"ector256.ConditionalSelect, and so on. A\\ndeveloper who wants or needs to go beyond what the high-lev\", \"el Vector<T> offers can choose to\\ntarget one or more of these two types. Typically this would amount\", \" to a developer writing one code\\npath based on Vector128<T>, as that has the broadest reach and achi\", \"eves a significant amount of the\\ngains from vectorization, and then if is motivated to do so can add\", \" a second path for Vector256<T> in\\norder to potentially double throughput further on platforms that \", \"have 256-bit width vectors. Think of\\nthese types and methods as a platform-abstraction layer: you co\", \"de to these methods, and then the JIT\\ntranslates them into the most appropriate instructions for the\", \" underlying platform. Consider this\\nsimple code as an example:\\nusing System.Runtime.CompilerServices\", \";\\nusing System.Runtime.Intrinsics;\\nusing System.Runtime.Intrinsics.X86;\\ninternal class Program\\n{\\npri\", \"vate static void Main()\\n{\\nVector128<byte> v = Vector128.Create((byte)123);\\nwhile (true)\\n{\\nWithIntrin\", \"sics(v);\\nWithVector(v);\\n}\\n}\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static int WithIntrin\", \"sics(Vector128<byte> v) => Sse2.MoveMask(v);\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate stat\", \"ic uint WithVector(Vector128<byte> v) => v.ExtractMostSignificantBits();\\n}\\nI have two functions: one\", \" that directly uses the Sse2.MoveMask hardware intrinsic and one that uses\\nthe new Vector128<T>.Extr\", \"actMostSignificantBits method. Using DOTNET_JitDisasm=Program.*,\\nhere\\u2019s what the optimized tier-1 co\", \"de for these looks like on my x64 Windows machine:\\n; Assembly listing for method Program:WithIntrins\", \"ics(Vector128`1):int\\nG_M000_IG01: ;; offset=0000H\\nC5F877 vzeroupper\\nG_M000_IG02: ;; offset=0003H\\nC5F\", \"91001 vmovupd xmm0, xmmword ptr [rcx]\\nC5F9D7C0 vpmovmskb eax, xmm0\\nG_M000_IG03: ;; offset=000BH\\nC3 r\", \"et\\n; Total bytes of code 12\\n; Assembly listing for method Program:WithVector(Vector128`1):int\\nG_M000\", \"_IG01: ;; offset=0000H\\nC5F877 vzeroupper\\n55 CHAPTER 2 | JITG_M000_IG02: ;; offset=0003H\\nC5F91001 vmo\", \"vupd xmm0, xmmword ptr [rcx]\\nC5F9D7C0 vpmovmskb eax, xmm0\\nG_M000_IG03: ;; offset=000BH\\nC3 ret\\n; Tota\", \"l bytes of code 12\\nNotice anything? The code for the two methods is identical, both resulting in a v\", \"pmovmskb (Move Byte\\nMask) instruction. Yet the former code will only work on a platform that support\", \"s SSE2 whereas the\\nlatter code will work on any platform with support for 128-bit vectors, including\", \" Arm64 and WASM\\n(and any future platforms on-boarded that also support SIMD); it\\u2019ll just result in d\", \"ifferent instructions\\nbeing emitted on those platforms.\\nTo explore this a bit more, let\\u2019s take a sim\", \"ple example and vectorize it. We\\u2019ll implement a Contains\\nmethod, where we want to search a span of b\", \"ytes for a specific value and return whether it was found:\\nstatic bool Contains(ReadOnlySpan<byte> h\", \"aystack, byte needle)\\n{\\nfor (int i = 0; i < haystack.Length; i++)\\n{\\nif (haystack[i] == needle)\\n{\\nret\", \"urn true;\\n}\\n}\\nreturn false;\\n}\\nHow would we vectorize this with Vector<T>? First things first, we nee\", \"d to check whether it\\u2019s even\\nsupported, and fall back to our existing implementation if it\\u2019s not (Ve\", \"ctor.IsHardwareAccelerated).\\nWe also need to fall back if the length of the input is less than the s\", \"ize of a vector\\n(Vector<byte>.Count).\\nstatic bool Contains(ReadOnlySpan<byte> haystack, byte needle)\", \"\\n{\\nif (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count)\\n{\\n// ...\\n}\\nelse\\n{\\nfor \", \"(int i = 0; i < haystack.Length; i++)\\n{\\nif (haystack[i] == needle)\\n{\\nreturn true;\\n}\\n}\\n}\\nreturn false\", \";\\n}\\n56 CHAPTER 2 | JITNow that we know we have enough data, we can get to coding our vectorized loop\", \". In this loop, we\\u2019ll\\nbe searching for the needle, which means we need a vector that contains that v\", \"alue for every element;\\nthe Vector<T>\\u2019s constructor provides that (new Vector<byte>(needle)). And we\", \" need to be able to\\nslice off a vector\\u2019s width of data at a time; for a bit more efficiency, I\\u2019ll us\", \"e pointers. We need a current\\niteration pointer, and we need to iterate until the point where we cou\", \"ldn\\u2019t form another vector\\nbecause we\\u2019re too close to the end, and a straightforward way to do that i\", \"s to get a pointer that\\u2019s\\nexactly one vector\\u2019s width from the end; that way, we can just iterate unt\", \"il our current pointer is equal\\nto or greater than that threshold. And finally, in our loop body, we\", \" need to compare our current\\nvector with the target vector to see if any elements are the same (Vect\", \"or.EqualsAny), if any is\\nreturning true, and if not bumping our current pointer to the next location\", \". At this point we have:\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle)\\n{\\nif \", \"(Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count)\\n{\\nfixed (byte* haystackPtr =\", \" &MemoryMarshal.GetReference(haystack))\\n{\\nVector<byte> target = new Vector<byte>(needle);\\nbyte* curr\", \"ent = haystackPtr;\\nbyte* endMinusOneVector = haystackPtr + haystack.Length - Vector<byte>.Count;\\ndo\\n\", \"{\\nif (Vector.EqualsAny(target, *(Vector<byte>*)current))\\n{\\nreturn true;\\n}\\ncurrent += Vector<byte>.Co\", \"unt;\\n}\\nwhile (current < endMinusOneVector);\\n// ...\\n}\\n}\\nelse\\n{\\nfor (int i = 0; i < haystack.Length; i\", \"++)\\n{\\nif (haystack[i] == needle)\\n{\\nreturn true;\\n}\\n}\\n}\\nreturn false;\\n}\\nAnd we\\u2019re almost done. The las\", \"t issue to handle is we may still have a few elements at the end we\\nhaven\\u2019t searched. There are a co\", \"uple of ways we could handle that. One would be to just continue\\nwith our fall back implementation a\", \"nd process each of the remaining elements one at a time. Another\\nwould be to employ a trick that\\u2019s c\", \"ommon when vectorizing idempotent operations. Our operation\\nisn\\u2019t mutating anything, which means it \", \"doesn\\u2019t matter if we compare the same element multiple\\ntimes, which means we can just do one final v\", \"ector compare for the last vector in the search space;\\n57 CHAPTER 2 | JITthat might or might not ove\", \"rlap with elements we\\u2019ve already looked at, but it won\\u2019t hurt anything if it\\ndoes. And with that, ou\", \"r implementation is complete:\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle)\\n\", \"{\\nif (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count)\\n{\\nfixed (byte* haystack\", \"Ptr = &MemoryMarshal.GetReference(haystack))\\n{\\nVector<byte> target = new Vector<byte>(needle);\\nbyte*\", \" current = haystackPtr;\\nbyte* endMinusOneVector = haystackPtr + haystack.Length - Vector<byte>.Count\", \";\\ndo\\n{\\nif (Vector.EqualsAny(target, *(Vector<byte>*)current))\\n{\\nreturn true;\\n}\\ncurrent += Vector<byt\", \"e>.Count;\\n}\\nwhile (current < endMinusOneVector);\\nif (Vector.EqualsAny(target, *(Vector<byte>*)endMin\", \"usOneVector))\\n{\\nreturn true;\\n}\\n}\\n}\\nelse\\n{\\nfor (int i = 0; i < haystack.Length; i++)\\n{\\nif (haystack[i\", \"] == needle)\\n{\\nreturn true;\\n}\\n}\\n}\\nreturn false;\\n}\\nCongratulations, we\\u2019ve vectorized this operation, \", \"and fairly decently at that. We can throw this into\\nbenchmarkdotnet and see really nice speedups:\\npr\", \"ivate byte[] _data = Enumerable.Repeat((byte)123, 999).Append((byte)42).ToArray();\\n[Benchmark(Baseli\", \"ne = true)]\\n[Arguments((byte)42)]\\npublic bool Find(byte value) => Contains(_data, value); // just th\", \"e fallback path in its\\nown method\\n[Benchmark]\\n[Arguments((byte)42)]\\npublic bool FindVectorized(byte \", \"value) => Contains_Vectorized(_data, value); // the\\nimplementation we just wrote\\n58 CHAPTER 2 | JITM\", \"ethod Mean Ratio\\nFind 484.05 ns 1.00\\nFindVectorized 20.21 ns 0.04\\nA 24x speedup! Woo hoo, victory, a\", \"ll your performance are belong to us!\\nYou deploy this in your service, and you see Contains being ca\", \"lled on your hot path, but you don\\u2019t\\nsee the improvements you were expecting. You dig in a little mo\", \"re, and you discover that while you\\ntested this with an input array with 1000 elements, typical inpu\", \"ts had more like 30 elements. What\\nhappens if we change our benchmark to have just 30 elements? That\", \"\\u2019s not long enough to form a\\nvector, so we fall back to the one-at-a-time path, and we don\\u2019t get any\", \" speedups at all.\\nOne thing we can now do is switch from using Vector<T> to Vector128<T>. That will \", \"then lower the\\nthreshold from 32 bytes to 16 bytes, such that inputs in that range will still have s\", \"ome amount of\\nvectorization applied. As these Vector128<T> and Vector256<T> types have been designed\", \" very\\nrecently, they also utilize all the cool new toys, and thus we can use refs instead of pointer\", \"s. Other\\nthan that, we can keep the shape of our implementation almost the same, substituting Vector\", \"128\\nwhere we were using Vector, and using some methods on Unsafe to manipulate our refs instead of\\np\", \"ointer arithmetic on the span we fixed.\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byt\", \"e needle)\\n{\\nif (Vector128.IsHardwareAccelerated && haystack.Length >= Vector128<byte>.Count)\\n{\\nref b\", \"yte current = ref MemoryMarshal.GetReference(haystack);\\nVector128<byte> target = Vector128.Create(ne\", \"edle);\\nref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length -\\nVector128<byte>.Co\", \"unt);\\ndo\\n{\\nif (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref current)))\\n{\\nreturn true;\\n}\\ncurr\", \"ent = ref Unsafe.Add(ref current, Vector128<byte>.Count);\\n}\\nwhile (Unsafe.IsAddressLessThan(ref curr\", \"ent, ref endMinusOneVector));\\nif (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref endMinusOneVe\", \"ctor)))\\n{\\nreturn true;\\n}\\n}\\nelse\\n{\\nfor (int i = 0; i < haystack.Length; i++)\\n{\\nif (haystack[i] == nee\", \"dle)\\n{\\nreturn true;\\n}\\n}\\n}\\n59 CHAPTER 2 | JITreturn false;\\n}\\nWith that in hand, we can now try it on \", \"our smaller 30 element data set:\\nprivate byte[] _data = Enumerable.Repeat((byte)123, 29).Append((byt\", \"e)42).ToArray();\\n[Benchmark(Baseline = true)]\\n[Arguments((byte)42)]\\npublic bool Find(byte value) => \", \"Contains(_data, value);\\n[Benchmark]\\n[Arguments((byte)42)]\\npublic bool FindVectorized(byte value) => \", \"Contains_Vectorized(_data, value);\\nMethod Mean Ratio\\nFind 15.388 ns 1.00\\nFindVectorized 1.747 ns 0.1\", \"1\\nWoo hoo, victory, all your performance are belong to us\\u2026 again!\\nWhat about on the larger data set \", \"again? Previously with Vector<T> we had a 24x speedup, but now:\\nMethod Mean Ratio\\nFind 484.25 ns 1.0\", \"0\\nFindVectorized 32.92 ns 0.07\\n\\u2026 closer to 15x. Nothing to sneeze at, but it\\u2019s not the 24x we previo\", \"usly saw. What if we want to have\\nour cake and eat it, too? Let\\u2019s also add a Vector256<T> path. To d\", \"o that, we literally copy/paste our\\nVector128<T> code, search/replace all references to Vector128 in\", \" the copied code with Vector256,\\nand just put it into an additional condition that uses the Vector25\", \"6<T> path if it\\u2019s supported and there\\nare enough elements to utilize it.\\nstatic unsafe bool Contains\", \"(ReadOnlySpan<byte> haystack, byte needle)\\n{\\nif (Vector128.IsHardwareAccelerated && haystack.Length \", \">= Vector128<byte>.Count)\\n{\\nref byte current = ref MemoryMarshal.GetReference(haystack);\\nif (Vector2\", \"56.IsHardwareAccelerated && haystack.Length >= Vector256<byte>.Count)\\n{\\nVector256<byte> target = Vec\", \"tor256.Create(needle);\\nref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length -\\nVe\", \"ctor256<byte>.Count);\\ndo\\n{\\nif (Vector256.EqualsAny(target, Vector256.LoadUnsafe(ref current)))\\n{\\nret\", \"urn true;\\n}\\ncurrent = ref Unsafe.Add(ref current, Vector256<byte>.Count);\\n}\\nwhile (Unsafe.IsAddressL\", \"essThan(ref current, ref endMinusOneVector));\\n60 CHAPTER 2 | JITif (Vector256.EqualsAny(target, Vect\", \"or256.LoadUnsafe(ref endMinusOneVector)))\\n{\\nreturn true;\\n}\\n}\\nelse\\n{\\nVector128<byte> target = Vector1\", \"28.Create(needle);\\nref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length -\\nVector\", \"128<byte>.Count);\\ndo\\n{\\nif (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref current)))\\n{\\nreturn \", \"true;\\n}\\ncurrent = ref Unsafe.Add(ref current, Vector128<byte>.Count);\\n}\\nwhile (Unsafe.IsAddressLessT\", \"han(ref current, ref endMinusOneVector));\\nif (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref e\", \"ndMinusOneVector)))\\n{\\nreturn true;\\n}\\n}\\n}\\nelse\\n{\\nfor (int i = 0; i < haystack.Length; i++)\\n{\\nif (hays\", \"tack[i] == needle)\\n{\\nreturn true;\\n}\\n}\\n}\\nreturn false;\\n}\\nAnd, boom, we\\u2019re back:\\nMethod Mean Ratio\\nFin\", \"d 484.53 ns 1.00\\nFindVectorized 20.08 ns 0.04\\nWe now have an implementation that is vectorized on an\", \"y platform with either 128-bit or 256-bit\\nvector instructions (x86, x64, Arm64, WASM, etc.), that ca\", \"n use either based on the input length, and\\nthat can be included in an R2R image if that\\u2019s of intere\", \"st.\\nThere are many factors that impact which path you go down, and I expect we\\u2019ll have guidance\\nfort\", \"hcoming to help navigate all the factors and approaches. But the capabilities are all there, and\\nwhe\", \"ther you choose to use Vector<T>, Vector128<T> and/or Vector256<T>, or the hardware\\nintrinsics direc\", \"tly, there are some amazing performance opportunities ready for the taking.\\n61 CHAPTER 2 | JITI alre\", \"ady mentioned several PRs that exposed the new cross-platform vector support, but that only\\nscratche\", \"s the surface of the work done to actually enable these operations and to enable them to\\nproduce hig\", \"h-quality code. As just one example of a category of such work, a set of changes went in\\nto help ens\", \"ure that zero vector constants are handled well, such as dotnet/runtime#63821 that\\n\\u201cmorphed\\u201d (change\", \"d) Vector128/256<T>.Create(default) into Vector128/256<T>.Zero, which then\\nenables subsequent optimi\", \"zations to focus only on Zero; dotnet/runtime#65028 that enabled\\nconstant propagation of Vector128/2\", \"56<T>.Zero; dotnet/runtime#68874 and dotnet/runtime#70171\\nthat add first-class knowledge of vector c\", \"onstants to the JIT\\u2019s intermediate representation; and\\ndotnet/runtime#62933, dotnet/runtime#65632, d\", \"otnet/runtime#55875, dotnet/runtime#67502, and\\ndotnet/runtime#64783 that all improve the code qualit\", \"y of instructions generated for zero vector\\ncomparisons.\\nInlining\\nInlining is one of the most import\", \"ant optimizations the JIT can do. The concept is simple: instead of\\nmaking a call to some method, ta\", \"ke the code from that method and bake it into the call site. This has\\nthe obvious advantage of avoid\", \"ing the overhead of a method call, but except for really small methods\\non really hot paths, that\\u2019s o\", \"ften on the smaller side of the wins inlining brings. The bigger wins are\\ndue to the callee\\u2019s code b\", \"eing exposed to the caller\\u2019s code, and vice versa. So, for example, if the\\ncaller is passing a const\", \"ant as an argument to the callee, if the method isn\\u2019t inlined, the compilation of\\nthe callee has no \", \"knowledge of that constant, but if the callee is inlined, all of the code in the callee is\\nthen awar\", \"e of its argument being a constant value, and can do all of the optimizations possible with\\nsuch a c\", \"onstant, like dead code elimination, branch elimination, constant folding and propagation,\\nand so on\", \". Of course, if it were all rainbows and unicorns, everything possible to be inlined would be\\ninline\", \"d, and that\\u2019s obviously not happening. Inlining brings with it the cost of potentially increased\\nbin\", \"ary size. If the code being inlined would result in the same amount or less assembly code in the\\ncal\", \"ler than it takes to call the callee (and if the JIT can quickly determine that), then inlining is a\", \" no-\\nbrainer. But if the code being inlined would increase the size of the callee non-trivially, now\", \" the JIT\\nneeds to weigh that increase in code size against the throughput benefits that could come f\", \"rom it.\\nThat code size increase can itself result in throughput regressions, due to increasing the n\", \"umber of\\ndistinct instructions to be executed and thereby putting more pressure on the instruction c\", \"ache. As\\nwith any cache, the more times you need to read from memory to populate it, the less effect\", \"ive the\\ncache will be. If you have a function that gets inlined into 100 different call sites, every\", \" one of those\\ncall sites\\u2019 copies of the callee\\u2019s instructions are unique, and calling each of those \", \"100 functions could\\nend up thrashing the instruction cache; in contrast, if all of those 100 functio\", \"ns \\u201cshared\\u201d the same\\ninstructions by simply calling the single instance of the callee, it\\u2019s likely t\", \"he instruction cache would be\\nmuch more effective and lead to fewer trips to memory.\\nAll that is to \", \"say, inlining is really important, it\\u2019s important that the \\u201cright\\u201d things be inlined and that it\\nnot\", \" overinline, and as such every release of .NET in recent memory has seen nice improvements\\naround in\", \"lining. .NET 7 is no exception.\\nOne really interesting improvement around inlining is dotnet/runtime\", \"#64521, and it might be\\nsurprising. Consider the Boolean.ToString method; here\\u2019s its full implementa\", \"tion:\\npublic override string ToString()\\n{\\n62 CHAPTER 2 | JITif (!m_value) return \\\"False\\\";\\nreturn \\\"Tr\", \"ue\\\";\\n}\\nPretty simple, right? You\\u2019d expect something this trivial to be inlined. Alas, on .NET 6, thi\", \"s benchmark:\\nprivate bool _value = true;\\n[Benchmark]\\npublic int BoolStringLength() => _value.ToStrin\", \"g().Length;\\nproduces this assembly code:\\n; Program.BoolStringLength()\\nsub rsp,28\\ncmp [rcx],ecx\\nadd r\", \"cx,8\\ncall System.Boolean.ToString()\\nmov eax,[rax+8]\\nadd rsp,28\\nret\\n; Total bytes of code 23\\nNote the\", \" call System.Boolean.ToString(). The reason for this is, historically, the JIT has been\\nunable to in\", \"line methods across assembly boundaries if those methods contain string literals (like the\\n\\\"False\\\" a\", \"nd \\\"True\\\" in that Boolean.ToString implementation). This restriction had to do with string\\ninterning\", \" and the possibility that such inlining could lead to visible behavioral differences. Those\\nconcerns\", \" are no longer valid, and so this PR removes the restriction. As a result, that same benchmark\\non .N\", \"ET 7 now produces this:\\n; Program.BoolStringLength()\\ncmp byte ptr [rcx+8],0\\nje short M00_L01\\nmov rax\", \",1DB54800D20\\nmov rax,[rax]\\nM00_L00:\\nmov eax,[rax+8]\\nret\\nM00_L01:\\nmov rax,1DB54800D18\\nmov rax,[rax]\\nj\", \"mp short M00_L00\\n; Total bytes of code 38\\nNo more call System.Boolean.ToString().\\ndotnet/runtime#614\", \"08 made two changes related to inlining. First, it taught the inliner how to better\\nsee the what met\", \"hods were being called in an inlining candidate, and in particular when tiered\\ncompilation is disabl\", \"ed or when a method would bypass tier-0 (such as a method with loops before\\nOSR existed or with OSR \", \"disabled); by understanding what methods are being called, it can better\\nunderstand the cost of the \", \"method, e.g. if those method calls are actually hardware intrinsics with a\\nvery low cost. Second, it\", \" enabled CSE in more cases with SIMD vectors.\\ndotnet/runtime#71778 also impacted inlining, and in pa\", \"rticular in situations where a typeof() could\\nbe propagated to the callee (e.g. via a method argumen\", \"t). In previous releases of .NET, various\\n63 CHAPTER 2 | JITmembers on Type like IsValueType were tu\", \"rned into JIT intrinsics, such that the JIT could substitute a\\nconstant value for calls where it cou\", \"ld compute the answer at compile time. For example, this:\\n[Benchmark]\\npublic bool IsValueType() => I\", \"sValueType<int>();\\nprivate static bool IsValueType<T>() => typeof(T).IsValueType;\\nresults in this as\", \"sembly code on .NET 6:\\n; Program.IsValueType()\\nmov eax,1\\nret\\n; Total bytes of code 6\\nHowever, change\", \" the benchmark slightly:\\n[Benchmark]\\npublic bool IsValueType() => IsValueType(typeof(int));\\nprivate \", \"static bool IsValueType(Type t) => t.IsValueType;\\nand it\\u2019s no longer as simple:\\n; Program.IsValueTyp\", \"e()\\nsub rsp,28\\nmov rcx,offset MT_System.Int32\\ncall CORINFO_HELP_TYPEHANDLE_TO_RUNTIMETYPE\\nmov rcx,ra\", \"x\\nmov rax,[7FFCA47C9560]\\ncmp [rcx],ecx\\nadd rsp,28\\njmp rax\\n; Total bytes of code 38\\nEffectively, as p\", \"art of inlining the JIT loses the notion that the argument is a constant and fails to\\npropagate it. \", \"This PR fixes that, such that on .NET 7, we now get what we expect:\\n; Program.IsValueType()\\nmov eax,\", \"1\\nret\\n; Total bytes of code 6\\nArm64\\nA huge amount of effort in .NET 7 went into making code gen for \", \"Arm64 as good or better than its\\nx64 counterpart. I\\u2019ve already discussed a bunch of PRs that are rel\", \"evant regardless of architecture, and\\nothers that are specific to Arm, but there are plenty more. To\", \" rattle off some of them:\\n\\u2022 Addressing modes. \\u201cAddressing mode\\u201d is the term used to refer to how the\", \" operand of\\ninstructions are specified. It could be the actual value, it could be the address from w\", \"here a value\\nshould be loaded, it could be the register containing the value, and so on. Arm support\", \"s a\\n\\u201cscaled\\u201d addressing mode, typically used for indexing into an array, where the size of each\\nelem\", \"ent is supplied and the instruction \\u201cscales\\u201d the provided offset by the specified scale.\\ndotnet/runt\", \"ime#60808 enables the JIT to utilize this addressing mode. More generally,\\ndotnet/runtime#70749 enab\", \"les the JIT to use addressing modes when accessing elements of\\n64 CHAPTER 2 | JITmanaged arrays. dot\", \"net/runtime#66902 improves the use of addressing modes when the\\nelement type is byte. dotnet/runtime\", \"#65468 improves addressing modes used for floating point.\\nAnd dotnet/runtime#67490 implements addres\", \"sing modes for SIMD vectors, specifically for\\nloads with unscaled indices.\\n\\u2022 Better instruction sele\", \"ction. Various techniques go into ensuring that the best instructions are\\nselected to represent inpu\", \"t code. dotnet/runtime#61037 teaches the JIT how to recognize the\\npattern (a * b) + c with integers \", \"and fold that into a single madd or msub instruction, while\\ndotnet/runtime#66621 does the same for a\", \" - (b * c) and msub. dotnet/runtime#61045\\nenables the JIT to recognize certain constant bit shift op\", \"erations (either explicit in the code or\\nimplicit to various forms of managed array access) and emit\", \" sbfiz/ubfiz instructions.\\ndotnet/runtime#70599, dotnet/runtime#66407, and dotnet/runtime#65535 all \", \"handle various\\nforms of optimizing a % b. dotnet/runtime#61847 from\\n[@SeanWoo](https://github.com/Se\", \"anWoo) removes an unnecessary movi emitted as part of\\nsetting a dereferenced pointer to a constant v\", \"alue. dotnet/runtime#57926 from\\n[@SingleAccretion](https://github.com/SingleAccretion) enables compu\", \"ting a 64-bit result as the\\nmultiplication of two 32-bit integers to be done with smull/umull. And d\", \"otnet/runtime#61549\\nfolds adds with sign extension or zero extension into a single add instruction w\", \"ith\\nuxtw/sxtw/lsl, while dotnet/runtime#62630 drops redundant zero extensions after a ldr\\ninstructio\", \"n.\\n\\u2022 Vectorization. dotnet/runtime#64864 adds new\\nAdvSimd.LoadPairVector64/AdvSimd.LoadPairVector128\", \" hardware intrinsics.\\n\\u2022 Zeroing. Lots of operations require state to be set to zero, such as initial\", \"izing all reference locals\\nin a method to zero as part of the method\\u2019s prologue (so that the GC does\", \"n\\u2019t see and try to\\nfollow garbage references). While such functionality was previously vectorized,\\nd\", \"otnet/runtime#63422 enables this to be implemented using 128-bit width vector instructions\\non Arm. A\", \"nd dotnet/runtime#64481 changes the instruction sequences used for zeroing in order\\nto avoid unneces\", \"sary zeroing, free up additional registers, and enable the CPU to recognize\\nvarious instruction sequ\", \"ences and better optimize.\\n\\u2022 Memory Model. dotnet/runtime#62895 enables store barriers to be used wh\", \"erever possible\\ninstead of full barriers, and uses one-way barriers for volatile variables. dotnet/r\", \"untime#67384\\nenables volatile reads/writes to be implemented with the ldapr instruction, while\\ndotne\", \"t/runtime#64354 uses a cheaper instruction sequence to handle volatile indirections.\\nThere\\u2019s dotnet/\", \"runtime#70600, which enables LSE Atomics to be used for Interlocked\\noperations; dotnet/runtime#71512\", \", which enables using the atomics instruction on Unix\\nmachines; and dotnet/runtime#70921, which enab\", \"les the same but on Windows.\\nJIT helpers\\nWhile logically part of the runtime, the JIT is actually is\", \"olated from the rest of the runtime, only\\ninteracting with it through an interface that enables comm\", \"unication between the JIT and the rest of\\nthe VM (Virtual Machine). There\\u2019s a large amount of VM fun\", \"ctionality then that the JIT relies on for\\ngood performance.\\ndotnet/runtime#65738 rewrote various \\u201cs\", \"tubs\\u201d to be more efficient. Stubs are tiny bits of code that\\nserve to perform some check and then re\", \"direct execution somewhere else. For example, when an\\ninterface dispatch call site is expected to on\", \"ly ever be used with a single implementation of that\\ninterface, the JIT might employ a \\u201cdispatch stu\", \"b\\u201d that compares the type of the object against the\\n65 CHAPTER 2 | JITsingle one it\\u2019s cached, and if\", \" they\\u2019re equal simply jumps to the right target. You know you\\u2019re in the\\ncorest of the core areas of \", \"the runtime when a PR contains lots of assembly code for every\\narchitecture the runtime targets. And\", \" it paid off; there\\u2019s a virtual group of folks from around .NET that\\nreview performance improvements\", \" and regressions in our automated performance test suites, and\\nattribute these back to the PRs likel\", \"y to be the cause (this is mostly automated but requires some\\nhuman oversight). It\\u2019s always nice the\", \"n when a few days after a PR is merged and performance\\ninformation has stabilized that you see a ras\", \"h of comments like there were on this PR:\\nFor anyone familiar with generics and interested in perfor\", \"mance, you may have heard the refrain that\\ngeneric virtual methods are relatively expensive. They ar\", \"e, comparatively. For example on .NET 6, this\\ncode:\\nprivate Example _example = new Example();\\n[Bench\", \"mark(Baseline = true)] public void GenericNonVirtual() =>\\n_example.GenericNonVirtual<Example>();\\n[Be\", \"nchmark] public void GenericVirtual() => _example.GenericVirtual<Example>();\\nclass Example\\n{\\n[Method\", \"Impl(MethodImplOptions.NoInlining)]\\npublic void GenericNonVirtual<T>() { }\\n[MethodImpl(MethodImplOpt\", \"ions.NoInlining)]\\npublic virtual void GenericVirtual<T>() { }\\n}\\nresults in:\\n66 CHAPTER 2 | JITMethod\", \" Mean Ratio\\nGenericNonVirtual 0.4866 1.00\\nns\\nGenericVirtual 6.4552 13.28\\nns\\ndotnet/runtime#65926 eas\", \"es the pain a tad. Some of the cost comes from looking up some cached\\ninformation in a hash table in\", \" the runtime, and as is the case with many map implementations, this\\none involves computing a hash c\", \"ode and using a mod operation to map to the right bucket. Other\\nhash table implementations around do\", \"tnet/runtime, including Dictionary<,>, HashSet<,>, and\\nConcurrentDictionary<,> previously switched t\", \"o a \\u201cfastmod\\u201d implementation; this PR does the same\\nfor this EEHashtable, which is used as part of t\", \"he CORINFO_GENERIC_HANDLE JIT helper function\\nemployed:\\nMethod Runtime Mean Ratio\\nGenericVirtual .NE\", \"T 6.0 6.475 ns 1.00\\nGenericVirtual .NET 7.0 6.119 ns 0.95\\nNot enough of an improvement for us to sta\", \"rt recommending people use them, but a 5%\\nimprovement takes a bit of the edge off the sting.\\nGrab Ba\", \"g\\nIt\\u2019s near impossible to cover every performance change that goes into the JIT, and I\\u2019m not going t\", \"o\\ntry. But there were so many more PRs, I couldn\\u2019t just leave them all unsung, so here\\u2019s a few more\\n\", \"quickies:\\n\\u2022 dotnet/runtime#58196 from [@benjamin-hodgson](https://github.com/benjamin-hodgson).\\nGive\", \"n an expression like (byte)x | (byte)y, that can be morphed into (byte)(x | y), which\\ncan optimize a\", \"way some movs.\\nprivate int _x, _y;\\n[Benchmark]\\npublic int Test() => (byte)_x | (byte)_y;\\n; *** .NET \", \"6 ***\\n; Program.Test(Int32, Int32)\\nmovzx eax,dl\\nmovzx edx,r8b\\nor eax,edx\\nret\\n; Total bytes of code 1\", \"0\\n; *** .NET 7 ***\\n; Program.Test(Int32, Int32)\\nor edx,r8d\\nmovzx eax,dl\\nret\\n; Total bytes of code 7\\n\", \"67 CHAPTER 2 | JIT\\u2022 dotnet/runtime#67182. On a machine with support for BMI2, 64-bit shifts can be p\", \"erformed with\\nthe shlx, sarx, and shrx instructions.\\n[Benchmark]\\n[Arguments(123, 1)]\\npublic ulong Sh\", \"ift(ulong x, int y) => x << y;\\n; *** .NET 6 ***\\n; Program.Shift(UInt64, Int32)\\nmov ecx,r8d\\nmov rax,r\", \"dx\\nshl rax,cl\\nret\\n; Total bytes of code 10\\n; *** .NET 7 ***\\n; Program.Shift(UInt64, Int32)\\nshlx rax,\", \"rdx,r8\\nret\\n; Total bytes of code 6\\n\\u2022 dotnet/runtime#69003 from [@SkiFoD](https://github.com/SkiFoD).\", \" The pattern ~x + 1 can be\\nchanged into a two\\u2019s-complement negation.\\n[Benchmark]\\n[Arguments(42)]\\npub\", \"lic int Neg(int i) => ~i + 1;\\n; *** .NET 6 ***\\n; Program.Neg(Int32)\\nmov eax,edx\\nnot eax\\ninc eax\\nret\\n\", \"; Total bytes of code 7\\n; *** .NET 7 ***\\n; Program.Neg(Int32)\\nmov eax,edx\\nneg eax\\nret\\n; Total bytes \", \"of code 5\\n\\u2022 dotnet/runtime#61412 from [@SkiFoD](https://github.com/SkiFoD). An expression X & 1 == 1\", \"\\nto test whether the bottom bit of a number is set can changed to the cheaper X & 1 (which isn\\u2019t\\nact\", \"ually expressible without a following != 0 in C#).\\n[Benchmark]\\n[Arguments(42)]\\npublic bool BitSet(in\", \"t x) => (x & 1) == 1;\\n; *** .NET 6 ***\\n; Program.BitSet(Int32)\\ntest dl,1\\nsetne al\\n68 CHAPTER 2 | JIT\", \"movzx eax,al\\nret\\n; Total bytes of code 10\\n; *** .NET 7 ***\\n; Program.BitSet(Int32)\\nmov eax,edx\\nand e\", \"ax,1\\nret\\n; Total bytes of code 6\\n\\u2022 dotnet/runtime#63545 from [@Wraith2](https://github.com/Wraith2).\", \" The expression x & (x -\\n1) can be lowered to the blsr instruction.\\n[Benchmark]\\n[Arguments(42)]\\npubl\", \"ic int ResetLowestSetBit(int x) => x & (x - 1);\\n; *** .NET 6 ***\\n; Program.ResetLowestSetBit(Int32)\\n\", \"lea eax,[rdx+0FFFF]\\nand eax,edx\\nret\\n; Total bytes of code 6\\n; *** .NET 7 ***\\n; Program.ResetLowestSe\", \"tBit(Int32)\\nblsr eax,edx\\nret\\n; Total bytes of code 6\\n\\u2022 dotnet/runtime#62394. / and % by a vector\\u2019s .\", \"Count wasn\\u2019t recognizing that Count can be\\nunsigned, but doing so leads to better code gen.\\n[Benchma\", \"rk]\\n[Arguments(42u)]\\npublic long DivideByVectorCount(uint i) => i / Vector<byte>.Count;\\n; *** .NET 6\", \" ***\\n; Program.DivideByVectorCount(UInt32)\\nmov eax,edx\\nmov rdx,rax\\nsar rdx,3F\\nand rdx,1F\\nadd rax,rdx\", \"\\nsar rax,5\\nret\\n; Total bytes of code 21\\n; *** .NET 7 ***\\n; Program.DivideByVectorCount(UInt32)\\nmov e\", \"ax,edx\\nshr rax,5\\nret\\n; Total bytes of code 7\\n69 CHAPTER 2 | JIT\\u2022 dotnet/runtime#60787. Loop alignmen\", \"t in .NET 6 provides a very nice exploration of why and\\nhow the JIT handles loop alignment. This PR \", \"extends that further by trying to \\u201chide\\u201d an emitted\\nalign instruction behind an unconditional jmp th\", \"at might already exist, in order to minimize the\\nimpact of the processor having to fetch and decode \", \"nops.\\n70 CHAPTER 2 | JIT3\\nCHAPTER\\nGC\\n\\u201cRegions\\u201d is a feature of the garbage collector (GC) that\\u2019s bee\", \"n in the works for multiple years. It\\u2019s\\nenabled by default in 64-bit processes in .NET 7 as of dotne\", \"t/runtime#64688, but as with other multi-\\nyear features, a multitude of PRs went into making it a re\", \"ality. At a 30,000 foot level, \\u201cregions\\u201d replaces\\nthe current \\u201csegments\\u201d approach to managing memory\", \" on the GC heap; rather than having a few\\ngigantic segments of memory (e.g. each 1GB), often associa\", \"ted 1:1 with a generation, the GC instead\\nmaintains many, many smaller regions (e.g. each 4MB) as th\", \"eir own entity. This enables the GC to be\\nmore agile with regards to operations like repurposing reg\", \"ions of memory from one generation to\\nanother. For more information on regions, the blog post Put a \", \"DPAD on that GC! from the primary\\ndeveloper on the GC is still the best resource.\\n71 CHAPTER 3 | GC4\", \"\\nCHAPTER\\nNative AOT\\nTo many people, the word \\u201cperformance\\u201d in the context of software is about throu\", \"ghput. How fast\\ndoes something execute? How much data per second can it process? How many requests p\", \"er second\\ncan it process? And so on. But there are many other facets to performance. How much memory\", \" does\\nit consume? How fast does it start up and get to the point of doing something useful? How much\", \"\\nspace does it consume on disk? How long would it take to download? And then there are related\\nconce\", \"rns. In order to achieve these goals, what dependencies are required? What kinds of operations\\ndoes \", \"it need to perform to achieve these goals, and are all of those operations permitted in the target\\ne\", \"nvironment? If any of this paragraph resonates with you, you are the target audience for the Native\\n\", \"AOT support now shipping in .NET 7.\\n.NET has long had support for AOT code generation. For example, \", \".NET Framework had it in the form\\nof ngen, and .NET Core has it in the form of crossgen. Both of tho\", \"se solutions involve a standard .NET\\nexecutable that has some of its IL already compiled to assembly\", \" code, but not all methods will have\\nassembly code generated for them, various things can invalidate\", \" the assembly code that was\\ngenerated, external .NET assemblies without any native assembly code can\", \" be loaded, and so on, and\\nin all of those cases, the runtime continues to utilize a JIT compiler. N\", \"ative AOT is different. It\\u2019s an\\nevolution of CoreRT, which itself was an evolution of .NET Native, a\", \"nd it\\u2019s entirely free of a JIT. The\\nbinary that results from publishing a build is a completely stan\", \"dalone executable in the target\\nplatform\\u2019s platform-specific file format (e.g. COFF on Windows, ELF \", \"on Linux, Mach-O on macOS) with\\nno external dependencies other than ones standard to that platform (\", \"e.g. libc). And it\\u2019s entirely native:\\nno IL in sight, no JIT, no nothing. All required code is compi\", \"led and/or linked in to the executable,\\nincluding the same GC that\\u2019s used with standard .NET apps an\", \"d services, and a minimal runtime that\\nprovides services around threading and the like. All of that \", \"brings great benefits: super fast startup\\ntime, small and entirely-self contained deployment, and ab\", \"ility to run in places JIT compilers aren\\u2019t\\nallowed (e.g. because memory pages that were writable ca\", \"n\\u2019t then be executable). It also brings\\nlimitations: no JIT means no dynamic loading of arbitrary as\", \"semblies (e.g. Assembly.LoadFile) and no\\nreflection emit (e.g. DynamicMethod), everything compiled a\", \"nd linked in to the app means the more\\nfunctionality that\\u2019s used (or might be used) the larger is yo\", \"ur deployment, etc. Even with those\\nlimitations, for a certain class of application, Native AOT is a\", \"n incredibly exciting and welcome\\naddition to .NET 7.\\nToo many PRs to mention have gone into bringin\", \"g up the Native AOT stack, in part because it\\u2019s been\\nin the works for years (as part of the archived\", \" dotnet/corert project and then as part of\\ndotnet/runtimelab/feature/NativeAOT) and in part because \", \"there have been over a hundred PRs just\\nin dotnet/runtime that have gone into bringing Native AOT up\", \" to a shippable state since the code was\\noriginally brought over from dotnet/runtimelab in dotnet/ru\", \"ntime#62563 and dotnet/runtime#62563.\\nBetween that and there not being a previous version to compare\", \" its performance to, instead of\\nfocusing PR by PR on improvements, let\\u2019s just look at how to use it \", \"and the benefits it brings.\\n72 CHAPTER 4 | Native AOTToday, Native AOT is focused on console applica\", \"tions, so let\\u2019s create a console app:\\ndotnet new console -o nativeaotexample\\nWe now have our nativea\", \"otexample directory containing a nativeaotexample.csproj and a \\u201chello,\\nworld\\u201d Program.cs. To enable \", \"publishing the application with Native AOT, edit the .csproj to include\\nthis in the existing <Proper\", \"tyGroup>...</PropertyGroup>.\\n<PublishAot>true</PublishAot>\\nAnd then\\u2026 actually, that\\u2019s it. Our app is\", \" now fully configured to be able to target Native AOT. All that\\u2019s\\nleft is to publish. As I\\u2019m current\", \"ly writing this on my Windows x64 machine, I\\u2019ll target that:\\ndotnet publish -r win-x64 -c Release\\nI \", \"now have my generated executable in the output publish directory:\\nDirectory: C:\\\\nativeaotexample\\\\bin\", \"\\\\Release\\\\net7.0\\\\win-x64\\\\publish\\nMode LastWriteTime Length Name\\n-a--- 8/27/2022 6:19 PM 2061824 nativ\", \"eaotexample.exe\\n-a--- 8/27/2022 6:19 PM 14290944 nativeaotexample.pdb\\nso 2M instead of 3.5MB. Of cou\", \"rse, for that significant reduction I\\u2019ve given up some things:\\n\\u2022 Setting InvariantGlobalization to t\", \"rue means I\\u2019m now not respecting culture information and\\nam instead using a set of invariant data fo\", \"r most globalization operations.\\n\\u2022 Setting UseSystemResourceKeys to true means nice exception messag\", \"es are stripped away.\\n\\u2022 Setting IlcGenerateStackTraceData to false means I\\u2019m going to get fairly poo\", \"r stack traces\\nshould I need to debug an exception.\\n\\u2022 Setting DebuggerSupport to false\\u2026 good luck de\", \"bugging things.\\n\\u2022 \\u2026 you get the idea.\\nOne of the potentially mind-boggling aspects of Native AOT for\", \" a developer used to .NET is that, as it\\nsays on the tin, it really is native. After publishing the \", \"app, there is no IL involved, and there\\u2019s no JIT\\nthat could even process it. This makes some of the \", \"other investments in .NET 7 all the more valuable,\\nfor example everywhere investments are happening \", \"in source generators. Code that previously relied\\non reflection emit for good performance will need \", \"another scheme. We can see that, for example, with\\nRegex. Historically for optimal throughput with R\", \"egex, it\\u2019s been recommended to use\\nRegexOptions.Compiled, which uses reflection emit at run-time to \", \"generate an optimized\\nimplementation of the specified pattern. But if you look at the implementation\", \" of the Regex\\nconstructor, you\\u2019ll find this nugget:\\nif (RuntimeFeature.IsDynamicCodeCompiled)\\n{\\nfact\", \"ory = Compile(pattern, tree, options, matchTimeout != InfiniteMatchTimeout);\\n}\\nWith the JIT, IsDynam\", \"icCodeCompiled is true. But with Native AOT, it\\u2019s false. Thus, with Native AOT\\nand Regex, there\\u2019s no\", \" difference between specifying RegexOptions.Compiled and not, and another\\nmechanism is required to g\", \"et the throughput benefits promised by RegexOptions.Compiled. Enter\\n[GeneratedRegex(...)], which, al\", \"ong with the new regex source generator shipping in the .NET 7\\n73 CHAPTER 4 | Native AOTSDK, emits C\", \"# code into the assembly using it. That C# code takes the place of the reflection emit that\\nwould ha\", \"ve happened at run-time, and is thus able to work successfully with Native AOT.\\nprivate static reado\", \"nly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0\", \".txt\\\").Result;\\nprivate Regex _interpreter = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline);\\n\", \"private Regex _compiled = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled |\\nRegexOptions.Multil\", \"ine);\\n[GeneratedRegex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline)]\\nprivate partial Regex SG();\\n[Ben\", \"chmark(Baseline = true)] public int Interpreter() => _interpreter.Count(s_haystack);\\n[Benchmark] pub\", \"lic int Compiled() => _compiled.Count(s_haystack);\\n[Benchmark] public int SourceGenerator() => SG().\", \"Count(s_haystack);\\nMethod Mean Ratio\\nInterpreter 9,036.7 us 1.00\\nCompiled 9,064.8 us 1.00\\nSourceGene\", \"rator 426.1 us 0.05\\nSo, yes, there are some constraints associated with Native AOT, but there are al\", \"so solutions for\\nworking with those constraints. And further, those constraints can actually bring f\", \"urther benefits.\\nConsider dotnet/runtime#64497. Remember how we talked about \\u201cguarded devirtualizati\", \"on\\u201d in\\ndynamic PGO, where via instrumentation the JIT can determine the most likely type to be used \", \"at a\\ngiven call site and special-case it? With Native AOT, the entirety of the program is known at c\", \"ompile\\ntime, with no support for Assembly.LoadFrom or the like. That means at compile time, the comp\", \"iler\\ncan do whole-program analysis to determine what types implement what interfaces. If a given\\nint\", \"erface only has a single type that implements it, then every call site through that interface can be\", \"\\nunconditionally devirtualized, without any type-check guards.\\nThis is a really exciting space, one \", \"we expect to see flourish in coming releases.\\n74 CHAPTER 4 | Native AOT5\\nCHAPTER\\nMono\\nUp until now I\", \"\\u2019ve referred to \\u201cthe JIT,\\u201d \\u201cthe GC,\\u201d and \\u201cthe runtime,\\u201d but in reality there are actually\\nmultiple r\", \"untimes in .NET. I\\u2019ve been talking about \\u201ccoreclr,\\u201d which is the runtime that\\u2019s recommended\\nfor use \", \"on Linux, macOS, and Windows. However, there\\u2019s also \\u201cmono,\\u201d which powers Blazor wasm\\napplications, A\", \"ndroid apps, and iOS apps. It\\u2019s also seen significant improvements in .NET 7.\\nJust as with coreclr (\", \"which can JIT compile, AOT compile partially with JIT fallback, and fully Native\\nAOT compile), mono \", \"has multiple ways of actually executing code. One of those ways is an interpreter,\\nwhich enables mon\", \"o to execute .NET code in environments that don\\u2019t permit JIT\\u2019ing and without\\nrequiring ahead-of-time\", \" compilation or incurring any limitations it may bring. Interestingly, though,\\nthe interpreter is it\", \"self almost a full-fledged compiler, parsing the IL, generating its own intermediate\\nrepresentation \", \"(IR) for it, and doing one or more optimization passes over that IR; it\\u2019s just that at the\\nend of th\", \"e pipeline when a compiler would normally emit code, the interpreter instead saves off that\\ndata for\", \" it to interpret when the time comes to run. As such, the interpreter has a very similar\\nconundrum t\", \"o the one we discussed with coreclr\\u2019s JIT: the time it takes to optimize vs the desire to\\nstart up q\", \"uickly. And in .NET 7, the interpreter employs a similar solution: tiered compilation.\\ndotnet/runtim\", \"e#68823 adds the ability for the interpreter to initially compile with minimal\\noptimization of that \", \"IR, and then once a certain threshold of call counts has been hit, then take the\\ntime to do as much \", \"optimization on the IR as possible for all future invocations of that method. This\\nyields the same b\", \"enefits as it does for coreclr: improved startup time while also having efficient\\nsustained throughp\", \"ut. When this merged, we saw improvements in Blazor wasm app startup time\\nimprove by 10-20%. Here\\u2019s \", \"one example from an app being tracked in our benchmarking system:\\n75 CHAPTER 5 | MonoThe interpreter\", \" isn\\u2019t just used for entire apps, though. Just as how coreclr can use the JIT when an R2R\\nimage does\", \"n\\u2019t contain code for a method, mono can use the interpreter when there\\u2019s no AOT code\\nfor a method. O\", \"nce such case that occurred on mono was with generic delegate invocation, where the\\npresence of a ge\", \"neric delegate being invoked would trigger falling back to the interpreter; for .NET 7,\\nthat gap was\", \" addressed with dotnet/runtime#70653. A more impactful case, however, is\\ndotnet/runtime#64867. Previ\", \"ously, any methods with catch or filter exception handling clauses\\ncouldn\\u2019t be AOT compiled and woul\", \"d fall back to being interpreted. With this PR, the method is now\\nable to be AOT compiled, and it on\", \"ly falls back to using the interpreter when an exception actually\\noccurs, switching over to the inte\", \"rpreter for the remainder of that method call\\u2019s execution. Since many\\nmethods contain such clauses, \", \"this can make a big difference in throughput and CPU consumption. In\\nthe same vein, dotnet/runtime#6\", \"3065 enabled methods with finally exception handling clauses to\\nbe AOT compiled; just the finally bl\", \"ock gets interpreted rather than the entire method being\\ninterpreted.\\nBeyond such backend improvemen\", \"ts, another class of improvement came from further unification\\nbetween coreclr and mono. Years ago, \", \"coreclr and mono had their own entire library stack built on\\ntop of them. Over time, as .NET was ope\", \"n sourced, portions of mono\\u2019s stack got replaced by shared\\ncomponents, bit by bit. Fast forward to t\", \"oday, all of the core .NET libraries above\\nSystem.Private.CoreLib are the same regardless of which r\", \"untime is being employed. In fact, the\\nsource for CoreLib itself is almost entirely shared, with ~95\", \"% of the source files being compiled into\\nthe CoreLib that\\u2019s built for each runtime, and just a few \", \"percent of the source specialized for each\\n(these statements means that the vast majority of the per\", \"formance improvements discussed in the\\nrest of this post apply equally whether running on mono and c\", \"oreclr). Even so, every release now we\\ntry to chip away at that few remaining percent, for reasons o\", \"f maintainability, but also because the\\nsource used for coreclr\\u2019s CoreLib has generally had more att\", \"ention paid to it from a performance\\nperspective. dotnet/runtime#71325, for example, moves mono\\u2019s ar\", \"ray and span sorting generic\\nsorting utility class over to the more efficient implementation used by\", \" coreclr.\\nOne of the biggest categories of improvements, however, is in vectorization. This comes in\", \" two pieces.\\nFirst, Vector<T> and Vector128<T> are now fully accelerated on both x64 and Arm64, than\", \"ks to PRs\\nlike dotnet/runtime#64961, dotnet/runtime#65086, dotnet/runtime#65128, dotnet/runtime#6631\", \"7,\\n76 CHAPTER 5 | Monodotnet/runtime#66391, dotnet/runtime#66409, dotnet/runtime#66512, dotnet/runti\", \"me#66586,\\ndotnet/runtime#66589, dotnet/runtime#66597, dotnet/runtime#66476, and dotnet/runtime#67125\", \";\\nthat significant amount of work means all that code that gets vectorized using these abstractions \", \"will\\nlight-up on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70086, mono now\\n\", \"knows how to translate Vector128<T> operations to WASM\\u2019s SIMD instruction set, such that code\\nvector\", \"ized with Vector128<T> will also be accelerated when running in Blazor wasm applications and\\nanywher\", \"e else WASM might be executed.\\n77 CHAPTER 5 | Mono6\\nCHAPTER\\nReflection\\nReflection is one of those ar\", \"eas you either love or hate (I find it a bit humorous to be writing this\\nsection immediately after w\", \"riting the Native AOT section). It\\u2019s immensely powerful, providing the\\nability to query all of the m\", \"etadata for code in your process and for arbitrary assemblies you might\\nencounter, to invoke arbitra\", \"ry functionality dynamically, and even to emit dynamically-generated IL at\\nrun-time. It\\u2019s also diffi\", \"cult to handle well in the face of tooling like a linker or a solution like Native\\nAOT that needs to\", \" be able to determine at build time exactly what code will be executed, and it\\u2019s\\ngenerally quite exp\", \"ensive at run-time; thus it\\u2019s both something we strive to avoid when possible but\\nalso invest in red\", \"ucing the costs of, as it\\u2019s so popular in so many different kinds of applications\\nbecause it is incr\", \"edibly useful. As with most releases, it\\u2019s seen some nice improvements in .NET 7.\\nOne of the most im\", \"pacted areas is reflection invoke. Available via MethodBase.Invoke, this\\nfunctionality let\\u2019s you tak\", \"e a MethodBase (e.g. MethodInfo) object that represents some method for\\nwhich the caller previously \", \"queried, and call it, with arbitrary arguments that the runtime needs to\\nmarshal through to the call\", \"ee, and with an arbitrary return value that needs to be marshaled back. If\\nyou know the signature of\", \" the method ahead of time, the best way to optimize invocation speed is to\\ncreate a delegate from th\", \"e MethodBase via CreateDelegate<T> and then use that delegate for all\\nfuture invocations. But in som\", \"e circumstances, you don\\u2019t know the signature at compile time, and thus\\ncan\\u2019t easily rely on delegat\", \"es with known matching signatures. To address this, some libraries have\\ntaken to using reflection em\", \"it to generate code at run-time specific to the target method. This is\\nextremely complicated and it\\u2019\", \"s not something we want apps to have to do. Instead, in .NET 7 via\\ndotnet/runtime#66357, dotnet/runt\", \"ime#69575, and dotnet/runtime#74614, Invoke will itself use\\nreflection emit (in the form of DynamicM\", \"ethod) to generate a delegate that is customized for invoking\\nthe target, and then future invocation\", \" via that MethodInfo will utilize that generated method. This\\ngives developers most of the performan\", \"ce benefits of a custom reflection emit-based implementation\\nbut without having the complexity or ch\", \"allenges of such an implementation in their own code base.\\nprivate MethodInfo _method;\\n[GlobalSetup]\", \"\\npublic void Setup() => _method = typeof(Program).GetMethod(\\\"MyMethod\\\",\\nBindingFlags.NonPublic | Bin\", \"dingFlags.Static);\\n[Benchmark]\\npublic void MethodInfoInvoke() => _method.Invoke(null, null);\\nprivate\", \" static void MyMethod() { }\\n78 CHAPTER 6 | ReflectionMethod Runtime Mean Ratio\\nMethodInfoInvoke .NET\", \" 6.0 43.846 ns 1.00\\nMethodInfoInvoke .NET 7.0 8.078 ns 0.18\\nReflection also involves lots of manipul\", \"ation of objects that represent types, methods, properties, and\\nso on, and tweaks here and there can\", \" add up to a measurable difference when using these APIs. For\\nexample, I\\u2019ve talked in past performan\", \"ce posts about how, potentially counterintuitively, one of the\\nways we\\u2019ve achieved performance boost\", \"s is by porting native code from the runtime back into\\nmanaged C#. There are a variety of ways in wh\", \"ich doing so can help performance, but one is that\\nthere is some overhead associated with calling fr\", \"om managed code into the runtime, and eliminating\\nsuch hops avoids that overhead. This can be seen i\", \"n full effect in dotnet/runtime#71873, which moves\\nseveral of these \\u201cFCalls\\u201d related to Type, Runtim\", \"eType (the Type-derived class used by the runtime to\\nrepresent its types), and Enum out of native in\", \"to managed.\\n[Benchmark]\\npublic Type GetUnderlyingType() => Enum.GetUnderlyingType(typeof(DayOfWeek))\", \";\\nMethod Runtime Mean Ratio\\nGetUnderlyingType .NET 6.0 27.413 ns 1.00\\nGetUnderlyingType .NET 7.0 5.1\", \"15 ns 0.19\\nAnother example of this phenomenon comes in dotnet/runtime#62866, which moved much of the\", \"\\nunderlying support for AssemblyName out of native runtime code into managed code in CoreLib. That\\ni\", \"n turn has an impact on anything that uses it, such as when using Activator.CreateInstance\\noverloads\", \" that take assembly names that need to be parsed.\\nprivate readonly string _assemblyName = typeof(MyC\", \"lass).Assembly.FullName;\\nprivate readonly string _typeName = typeof(MyClass).FullName;\\npublic class \", \"MyClass { }\\n[Benchmark]\\npublic object CreateInstance() => Activator.CreateInstance(_assemblyName, _t\", \"ypeName);\\nMethod Runtime Mean Ratio\\nCreateInstance .NET 6.0 3.827 us 1.00\\nCreateInstance .NET 7.0 2.\", \"276 us 0.60\\nOther changes contributed to Activator.CreateInstance improvements as well.\\ndotnet/runti\", \"me#67148 removed several array and list allocations from inside of the\\nRuntimeType.CreateInstanceImp\", \"l method that\\u2019s used by CreateInstance (using Type.EmptyTypes\\ninstead of allocating a new Type[0], a\", \"voiding unnecessarily turning a builder into an array, etc.),\\nresulting in less allocation and faste\", \"r throughput.\\n[Benchmark]\\npublic void CreateInstance() => Activator.CreateInstance(typeof(MyClass),\\n\", \"BindingFlags.NonPublic | BindingFlags.Instance, null, Array.Empty<object>(), null);\\ninternal class M\", \"yClass\\n{\\n79 CHAPTER 6 | Reflectioninternal MyClass() { }\\n}\\nMethod Runtime Mean Ratio Allocated Alloc\", \" Ratio\\nCreateInstance .NET 6.0 167.8 ns 1.00 320 B 1.00\\nCreateInstance .NET 7.0 143.4 ns 0.85 200 B \", \"0.62\\nAnd since we were talking about AssemblyName, other PRs improved it in other ways as well.\\ndotn\", \"et/runtime#66750, for example, updated the computation of AssemblyName.FullName to use\\nstack-allocat\", \"ed memory and ArrayPool<char> instead of using a StringBuilder:\\nprivate AssemblyName[] _names = AppD\", \"omain.CurrentDomain.GetAssemblies().Select(a => new\\nAssemblyName(a.FullName)).ToArray();\\n[Benchmark]\", \"\\npublic int Names()\\n{\\nint sum = 0;\\nforeach (AssemblyName name in _names)\\n{\\nsum += name.FullName.Leng\", \"th;\\n}\\nreturn sum;\\n}\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nNames .NET 6.0 3.423 us 1.00 9.1\", \"4 KB 1.00\\nNames .NET 7.0 2.010 us 0.59 2.43 KB 0.27\\nMore reflection-related operations have also bee\", \"n turned into JIT intrinsics, as discussed earlier\\nenabling the JIT to compute answers to various qu\", \"estions at JIT compile time rather than at run-time.\\nThis was done, for example, for Type.IsByRefLik\", \"e in dotnet/runtime#67852.\\n[Benchmark]\\npublic bool IsByRefLike() => typeof(ReadOnlySpan<char>).IsByR\", \"efLike;\\nMethod Runtime Mean Ratio Code Size\\nIsByRefLike .NET 6.0 2.1322 ns 1.000 31 B\\nIsByRefLike .N\", \"ET 7.0 0.0000 ns 0.000 6 B\\nThat the .NET 7 version is so close to zero is called out in a warning by\", \" benchmarkdotnet:\\n// * Warnings *\\nZeroMeasurement\\nProgram.IsByRefLike: Runtime=.NET 7.0, Toolchain=n\", \"et7.0 -> The method duration is\\nindistinguishable from the empty method duration\\nand it\\u2019s so indisti\", \"nguishable from an empty method because that\\u2019s effectively what it is, as we can see\\nfrom the disass\", \"embly:\\n80 CHAPTER 6 | Reflection; Program.IsByRefLike()\\nmov eax,1\\nret\\n; Total bytes of code 6\\nThere \", \"are also improvements that are hard to see but that remove overheads as part of populating\\nreflectio\", \"n\\u2019s caches, which end up reducing the work done typically on startup paths, helping apps to\\nlaunch f\", \"aster. dotnet/runtime#66825, dotnet/runtime#66912, and dotnet/runtime#67149 all fall into\\nthis categ\", \"ory by removing unnecessary or duplicative array allocations as part of gathering data on\\nparameters\", \", properties, and events.\\n81 CHAPTER 6 | Reflection7\\nCHAPTER\\nInterop\\n.NET has long had great support\", \" for interop, enabling .NET applications to consume huge amounts of\\nfunctionality written in other l\", \"anguages and/or exposed by the underlying operating system. The\\nbedrock of this support has been \\u201cPl\", \"atform Invoke,\\u201d or \\u201cP/Invoke,\\u201d represented in code by\\n[DllImport(...)] applied to methods. The DllIm\", \"portAttribute enables declaring a method that\\ncan be called like any other .NET method but that actu\", \"ally represents some external method that the\\nruntime should call when this managed method is invoke\", \"d. The DllImport specifies details about in\\nwhat library the function lives, what its actual name is\", \" in the exports from that library, high-level\\ndetails about marshalling of input arguments and retur\", \"n values, and so on, and the runtime ensures\\nall the right things happen. This mechanism works on al\", \"l operating systems. For example, Windows\\nhas a method CreatePipe for creating an anonymous pipe:\\nBO\", \"OL CreatePipe(\\n[out] PHANDLE hReadPipe,\\n[out] PHANDLE hWritePipe,\\n[in, optional] LPSECURITY_ATTRIBUT\", \"ES lpPipeAttributes,\\n[in] DWORD nSize\\n);\\nIf I want to call this function from C#, I can declare a [D\", \"llImport(...)] counterpart to it which I can\\nthen invoke as I can any other managed method:\\n[DllImpo\", \"rt(\\\"kernel32\\\", SetLastError = true)]\\n[return: MarshalAs(UnmanagedType.Bool)]\\nprivate static unsafe e\", \"xtern bool CreatePipe(\\nout SafeFileHandle hReadPipe,\\nout SafeFileHandle hWritePipe,\\nvoid* lpPipeAttr\", \"ibutes,\\nuint nSize);\\nThere are several interesting things to note here. Several of the arguments are\", \" directly blittable with\\nthe same representation on the managed and native side of the equation, e.g\", \". lpPipeAttributes is a\\npointer and nSize is a 32-bit integer. But what about the return value? The \", \"bool type in C#\\n(System.Boolean) is a one-byte type, but the BOOL type in the native signature is fo\", \"ur bytes; thus code\\ncalling this managed method can\\u2019t just directly invoke the native function someh\", \"ow, as there needs to\\nbe some \\u201cmarshalling\\u201d logic that converts the four-byte return BOOL into the o\", \"ne-byte return bool.\\nSimiarly, the native function has two out pointers for hReadPipe and hWritePipe\", \", but the managed\\nsignature declares two SafeFileHandles (a SafeHandle is a .NET type that wraps a p\", \"ointer and\\nprovides a finalizer and Dispose method for ensuring that pointer is appropriately cleane\", \"d up when\\nit\\u2019s no longer being used). Some logic needs to take the output handles generated by the n\", \"ative\\nfunction and wrap them into these SafeFileHandles to be output from the managed method. And\\nwh\", \"at about that SetLastError = true? .NET has methods like Marshal.GetLastPInvokeError(),\\n82 CHAPTER 7\", \" | Interopand some code somewhere needs to take any error produced by this method and ensure it\\u2019s av\", \"ailable\\nfor consumption via a subsequent GetLastPInvokeError().\\nIf there\\u2019s no marshalling logic requ\", \"ired, such that the managed signature and native signature are for\\nall intents and purposes the same\", \", all arguments blittable, all return values blittable, no additional\\nlogic required around the invo\", \"cation of the method, etc., then a [DllImport(...)] ends up being a\\nsimple passthrough with the runt\", \"ime needing to do very little work to implement it. If, however, the\\n[DllImport(...)] involves any o\", \"f this marshalling work, the runtime needs to generate a \\u201cstub,\\u201d\\ncreating a dedicated method that\\u2019s \", \"called when the [DllImport(...)] is called, that handles fixing\\nup all inputs, that delegates to the\", \" actual native function, and that fixes up all of the outputs. That\\nstub is generated at execution t\", \"ime, with the runtime effectively doing reflection emit, generating IL\\ndynamically that\\u2019s then JIT\\u2019d\", \".\\nThere are a variety of downsides to this. First, it takes time to generate all that marshalling co\", \"de, time\\nwhich can then negatively impact user experience for things like startup. Second, the natur\", \"e of its\\nimplementation inhibits various optimizations, such as inlining. Third, there are platforms\", \" that don\\u2019t\\nallow for JIT\\u2019ing due to the security exposure of allowing for dynamically generated cod\", \"e to then be\\nexecuted (or in the case of Native AOT, where there isn\\u2019t a JIT at all). And fourth, it\", \"\\u2019s all hidden away\\nmaking it more challenging for a developer to really understand what\\u2019s going on.\\n\", \"But what if that logic could all be generated at build time rather than at run time? The cost of\\ngen\", \"erating the code would be incurred only at build time and not on every execution. The code would\\neff\", \"ectively just end up being user code that has all of the C# compiler\\u2019s and runtime\\u2019s optimizations\\na\", \"vailable to it. The code, which then would just be part of the app, would be able to be ahead-of-tim\", \"e\\ncompiled using whatever AOT system is desirable, whether it be crossgen or Native AOT or some\\nothe\", \"r system. And the code would be inspectable, viewable by users to understand exactly what work\\nis be\", \"ing done on their behalf. Sounds pretty desirable. Sounds magical. Sounds like a job for a Roslyn\\nso\", \"urce generator, mentioned earlier.\\n.NET 6 included several source generators in the .NET SDK, and .N\", \"ET 7 doubles down on this effort\\nincluding several more. One of these is the brand new LibraryImport\", \" generator, which provides exactly\\nthe magical, desirable solution we were just discussing.\\nLet\\u2019s re\", \"turn to our previous CreatePipe example. We\\u2019ll make two small tweaks. We change the\\nattribute from D\", \"llImport to LibraryImport, and we change the extern keyword to be partial:\\n[LibraryImport(\\\"kernel32\\\"\", \", SetLastError = true)]\\n[return: MarshalAs(UnmanagedType.Bool)]\\nprivate static unsafe partial bool C\", \"reatePipe(\\nout SafeFileHandle hReadPipe,\\nout SafeFileHandle hWritePipe,\\nvoid* lpPipeAttributes,\\nuint\", \" nSize);\\nNow if you\\u2019re following along at home in Visual Studio, try right-clicking on CreatePipe an\", \"d selecting\\nGo to Definition. That might seem a little strange. \\u201cGo to Definition? Isn\\u2019t this the de\", \"finition?\\u201d This is a\\npartial method, which is a way of declaring something that another partial defi\", \"nition fills in, and in this\\ncase, a source generator in .NET 7 SDK has noticed this method with the\", \" [LibraryImport] attribute\\nand fully generated the entire marshalling stub code in C# that\\u2019s built d\", \"irectly into the assembly.\\nWhile by default that code isn\\u2019t persisted, Visual Studio still enables y\", \"ou to browse it (and you can\\n83 CHAPTER 7 | Interopopt-in to having it persisted on disk by adding a\", \"\\n<EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles> property into your .csproj).\\nHere\\u2019s w\", \"hat it currently looks like for that method:\\n[System.CodeDom.Compiler.GeneratedCodeAttribute(\\\"Micros\", \"oft.Interop.LibraryImportGenerator\\\",\\n\\\"7.0.6.42316\\\")]\\n[System.Runtime.CompilerServices.SkipLocalsInit\", \"Attribute]\\nprivate static unsafe partial bool CreatePipe(out\\nglobal::Microsoft.Win32.SafeHandles.Saf\", \"eFileHandle hReadPipe, out\\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle hWritePipe, void* lpPi\", \"peAttributes, uint\\nnSize)\\n{\\nint __lastError;\\nbool __invokeSucceeded = default;\\nSystem.Runtime.Compil\", \"erServices.Unsafe.SkipInit(out hReadPipe);\\nSystem.Runtime.CompilerServices.Unsafe.SkipInit(out hWrit\", \"ePipe);\\nSystem.IntPtr __hReadPipe_native = default;\\nSystem.IntPtr __hWritePipe_native = default;\\nboo\", \"l __retVal;\\nint __retVal_native = default;\\n// Setup - Perform required setup.\\nglobal::Microsoft.Win3\", \"2.SafeHandles.SafeFileHandle hReadPipe__newHandle = new\\nglobal::Microsoft.Win32.SafeHandles.SafeFile\", \"Handle();\\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle hWritePipe__newHandle = new\\nglobal::Mic\", \"rosoft.Win32.SafeHandles.SafeFileHandle();\\ntry\\n{\\n{\\nSystem.Runtime.InteropServices.Marshal.SetLastSys\", \"temError(0);\\n__retVal_native = __PInvoke(&__hReadPipe_native, &__hWritePipe_native,\\nlpPipeAttributes\", \", nSize);\\n__lastError = System.Runtime.InteropServices.Marshal.GetLastSystemError();\\n}\\n__invokeSucce\", \"eded = true;\\n// Unmarshal - Convert native data to managed data.\\n__retVal = __retVal_native != 0;\\n}\\n\", \"finally\\n{\\nif (__invokeSucceeded)\\n{\\n// GuaranteedUnmarshal - Convert native data to managed data even\", \" in the case\\nof an exception during the non-cleanup phases.\\nSystem.Runtime.InteropServices.Marshal.I\", \"nitHandle(hWritePipe__newHandle,\\n__hWritePipe_native);\\nhWritePipe = hWritePipe__newHandle;\\nSystem.Ru\", \"ntime.InteropServices.Marshal.InitHandle(hReadPipe__newHandle,\\n__hReadPipe_native);\\nhReadPipe = hRea\", \"dPipe__newHandle;\\n}\\n}\\nSystem.Runtime.InteropServices.Marshal.SetLastPInvokeError(__lastError);\\nretur\", \"n __retVal;\\n// Local P/Invoke\\n[System.Runtime.InteropServices.DllImportAttribute(\\\"kernel32\\\", EntryPo\", \"int =\\n84 CHAPTER 7 | Interop\\\"CreatePipe\\\", ExactSpelling = true)]\\nstatic extern unsafe int __PInvoke(\", \"System.IntPtr* hReadPipe, System.IntPtr* hWritePipe,\\nvoid* lpPipeAttributes, uint nSize);\\n}\\nWith thi\", \"s, you can read exactly the marshalling work that\\u2019s being performed. Two SafeHandle\\ninstances are be\", \"ing allocated and then later after the native function completes, the\\nMarshal.InitHandle method is u\", \"sed to store the resulting handles into these instances (the\\nallocations happen before the native fu\", \"nction call, as performing them after the native handles have\\nalready been produced increases the ch\", \"ances of a leak if the SafeHandle allocation fails due to an\\nout-of-memory situation). The BOOL to b\", \"ool conversion happens via a != 0 comparison. And the error\\ninformation is captured by calling Marsh\", \"al.GetLastSystemError() just after the native function call\\nand then Marshal.SetLastPInvokeError(int\", \") just prior to returning. The actual native function call\\nis still implemented with a [DllImport(..\", \".)], but now that P/Invoke is blittable and doesn\\u2019t require\\nany stub to be generated by the runtime,\", \" as all that work has been handled in this C# code.\\nA sheer ton of work went in to enabling this. I \", \"touched on some of it last year in Performance\\nImprovements in .NET 6, but a significant amount of a\", \"dditional effort has gone into .NET 7 to polish\\nthe design and make the implementation robust, roll \", \"it out across all of dotnet/runtime and beyond,\\nand expose the functionality for all C# developers t\", \"o use:\\n\\u2022 The LibraryImport generator started its life as an experiment in dotnet/runtimelab. When it\", \" was\\nready, dotnet/runtime#59579 brought 180 commits spanning years of effort into the\\ndotnet/runtim\", \"e main branch.\\n\\u2022 In .NET 6, there were almost 3000 [DllImport] uses throughout the core .NET librari\", \"es. As of my\\nwriting this, in .NET 7 there are\\u2026 let me search\\u2026 wait for it\\u2026 7 (I was hoping I could \", \"say 0, but\\nthere are just a few stragglers, mostly related to COM interop, still remaining). That\\u2019s \", \"not a\\ntransformation that happens over night. A multitude of PRs went library by library converting\\n\", \"from the old to the new, such as dotnet/runtime#62295 and dotnet/runtime#61640 for\\nSystem.Private.Co\", \"reLib, dotnet/runtime#61742 and dotnet/runtime#62309 for the cryptography\\nlibraries, dotnet/runtime#\", \"61765 for networking, dotnet/runtime#61996 and\\ndotnet/runtime#61638 for most of the other I/O-relate\", \"d libraries, and a long-tail of additional\\nporting in dotnet/runtime#61975, dotnet/runtime#61389, do\", \"tnet/runtime#62353,\\ndotnet/runtime#61990, dotnet/runtime#61949, dotnet/runtime#61805, dotnet/runtime\", \"#61741,\\ndotnet/runtime#61184, dotnet/runtime#54290, dotnet/runtime#62365, dotnet/runtime#61609,\\ndotn\", \"et/runtime#61532, and dotnet/runtime#54236.\\n\\u2022 Such porting is significantly easier when there\\u2019s a to\", \"ol to help automate it.\\ndotnet/runtime#72819 enables the analyzer and fixer for performing these tra\", \"nsformations.\\n:::{custom-style=Figure}\\n85 CHAPTER 7 | Interop:::\\nThere were plenty of other PRs that\", \" went into making the LibraryImport generator a reality for .NET 7.\\nTo highlight just a few more, do\", \"tnet/runtime#63320 introduces a new\\n[DisabledRuntimeMarshalling] attribute that can be specified at \", \"the assembly level to disable all of\\nthe runtime\\u2019s built-in marshalling; at that point, the only mar\", \"shalling performed as part of interop is\\nthe marshaling done in the user\\u2019s code, e.g. that which is \", \"generated by [LibraryImport]. Other PRs\\nlike dotnet/runtime#67635 and dotnet/runtime#68173 added new\", \" marshaling types that encompass\\ncommon marshaling logic and can be referenced from [LibraryImport(.\", \"..)] use to customize how\\nmarshaling is performed (the generator is pattern-based and allows for cus\", \"tomization of marshalling\\nby providing types that implement the right shape, which these types do in\", \" support of the most\\ncommon marshalling needs). Really usefully, dotnet/runtime#71989 added support \", \"for marshaling\\n{ReadOnly}Span<T>, such that spans can be used directly in [LibraryImport(...)] metho\", \"d\\nsignatures, just as arrays can be (examples in dotnet/runtime are available in dotnet/runtime#7325\", \"6).\\nAnd dotnet/runtime#69043 consolidated logic to be shared between the runtime\\u2019s marshalling\\nsuppo\", \"rt in [DllImport] and the generators support with [LibraryImport].\\nOne more category of interop-rela\", \"ted changes that I think are worth talking about are to do with\\nSafeHandle cleanup. As a reminder, S\", \"afeHandle exists to mitigate various issues around managing\\nnative handles and file descriptors. A n\", \"ative handle or file descriptor is just a memory address or\\nnumber that refers to some owned resourc\", \"e and which must be cleaned up / closed when done with\\nit. A SafeHandle at its core is just a manage\", \"d object that wraps such a value and provides a Dispose\\nmethod and a finalizer for closing it. That \", \"way, if you neglect to Dispose of the SafeHandle in order to\\nclose the resource, the resource will s\", \"till be cleaned up when the SafeHandle is garbage collected and\\nits finalizer eventually run. SafeHa\", \"ndle then also provides some synchronization around that closure,\\ntrying to minimize the possibility\", \" that the resource is closed while it\\u2019s still in use. It provides\\nDangerousAddRef and DangerousRelea\", \"se methods that increment and decrement a ref count,\\nrespectively, and if Dispose is called while th\", \"e ref count is above zero, the actual releasing of the\\nhandle triggered by Dispose is delayed until \", \"the ref count goes back to 0. When you pass a\\nSafeHandle into a P/Invoke, the generated code for tha\", \"t P/Invoke handles calling DangerousAddRef\\n86 CHAPTER 7 | Interopand DangerousRelease (and due to th\", \"e wonders of LibraryImport I\\u2019ve already extolled, you can easily\\nsee that being done, such as in the\", \" previous generated code example). Our code tries hard to clean\\nup after SafeHandles deterministical\", \"ly, but it\\u2019s quite easy to accidentally leave some for finalization.\\ndotnet/runtime#71854 added some\", \" debug-only tracking code to SafeHandle to make it easier for\\ndevelopers working in dotnet/runtime (\", \"or more specifically, developers using a checked build of the\\nruntime) to find such issues. When the\", \" SafeHandle is constructed, it captures the current stack trace,\\nand if the SafeHandle is finalized,\", \" it dumps that stack trace to the console, making it easy to see\\nwhere SafeHandles that do end up ge\", \"tting finalized were created, in order to track them down and\\nensure they\\u2019re being disposed of. As i\", \"s probably evident from that PR touching over 150 files and\\nalmost 1000 lines of code, there were qu\", \"ite a few places that benefited from clean up. Now to be fair,\\nmany of these are on exceptional code\", \" paths. For example, consider a hypothetical P/Invoke like:\\n[LibraryImport(\\\"SomeLibrary\\\", SetLastErr\", \"or = true)]\\ninternal static partial SafeFileHandle CreateFile();\\nand code that uses it like:\\nSafeFil\", \"eHandle handle = Interop.CreateFile();\\nif (handle.IsInvalid)\\n{\\nthrow new UhOhException(Marshal.GetLa\", \"stPInvokeError());\\n}\\nreturn handle;\\nSeems straightforward enough. Except this code will actually lea\", \"ve a SafeHandle for finalization on\\nthe failure path. It doesn\\u2019t matter that SafeHandle has an inval\", \"id handle in it, it\\u2019s still a finalizable\\nobject. To deal with that, this code would have been more \", \"robustly written as:\\nSafeFileHandle handle = Interop.CreateFile();\\nif (handle.IsInvalid)\\n{\\nint lastE\", \"rror = Marshal.GetLastPInvokeError();\\nhandle.Dispose(); // or handle.SetHandleAsInvalid()\\nthrow new \", \"UhOhException(lastError);\\n}\\nreturn handle;\\nThat way, this SafeHandle won\\u2019t create finalization press\", \"ure even in the case of failure. Note, as well,\\nthat as part of adding in the Dispose call, I also m\", \"oved the Marshal.GetLastPInvokeError() up.\\nThat\\u2019s because calling Dispose on a SafeHandle may end up\", \" invoking the SafeHandle\\u2019s\\nReleaseHandle method, which the developer of the SafeHandle-derived type \", \"will have overridden to\\nclose the resource, which typically involves making another P/Invoke. And if\", \" that P/Invoke has\\nSetLastError=true on it, it can overwrite the very error code for which we\\u2019re abo\", \"ut to throw. Hence,\\nwe access and store the last error immediately after the interop call once we kn\", \"ow it failed, then clean\\nup, and only then throw. All that said, there were a myriad of places in th\", \"at PR where SafeHandles\\nwere being left for finalization even on the success path. And that PR wasn\\u2019\", \"t alone.\\ndotnet/runtime#71991, dotnet/runtime#71854, dotnet/runtime#72116, dotnet/runtime#72189,\\ndot\", \"net/runtime#72222, dotnet/runtime#72203, and dotnet/runtime#72279 all found and fixed many\\noccurrenc\", \"es of SafeHandles being left for finalization (many thanks to the diagnostics put in place in\\nthe ea\", \"rlier mentioned PR).\\n87 CHAPTER 7 | InteropOther PRs also accrued to improved interop performance. d\", \"otnet/runtime#70000 from\\n[@huoyaoyuan](https://github.com/huoyaoyuan) rewrote several delegate-relat\", \"ed \\u201cFCalls\\u201d from being\\nimplemented in native code to instead being managed, resulting in less overhe\", \"ad when invoking\\nthese operations that are commonly involved in scenarios involving\\nMarshal.GetDeleg\", \"ateForFunctionPointer. dotnet/runtime#68694 also moved some trivial\\nfunctionality from native to man\", \"aged, as part of relaxing argument validation on the use of pinning\\nhandles. This in turn measurably\", \" reduced the overhead involved with using GCHandle.Alloc for such\\npinning handles:\\nprivate byte[] _b\", \"uffer = new byte[1024];\\n[Benchmark]\\npublic void PinUnpin()\\n{\\nGCHandle.Alloc(_buffer, GCHandleType.Pi\", \"nned).Free();\\n}\\nMethod Runtime Mean Ratio Code Size\\nPinUnpin .NET 6.0 37.11 ns 1.00 353 B\\nPinUnpin .\", \"NET 7.0 32.17 ns 0.87 232 B\\n88 CHAPTER 7 | Interop8\\nCHAPTER\\nThreading\\nThreading is one of those cros\", \"s-cutting concerns that impacts every application, such that changes in\\nthe threading space can have\", \" a wide-spread impact. This release sees two very substantial changes to\\nthe ThreadPool itself; dotn\", \"et/runtime#64834 switches the \\u201cIO pool\\u201d over to using an entirely\\nmanaged implementation (whereas pr\", \"eviously the IO pool was still in native code even though the\\nworker pool had been moved entirely to\", \" managed in previous releases), and dotnet/runtime#71864\\nsimilarly switches the timer implementation\", \" from one based in native to one entirely in managed\\ncode. Those two changes can impact performance,\", \" and the former was demonstrated to on larger\\nhardware, but for the most part that wasn\\u2019t their prim\", \"ary goal. Instead, other PRs have been focused\\non improving throughput.\\nOne in particular is dotnet/\", \"runtime#69386. The ThreadPool has a \\u201cglobal queue\\u201d that any thread can\\nqueue work into, and then eac\", \"h thread in the pool has its own \\u201clocal queue\\u201d (which any thread can\\ndequeue from but only the ownin\", \"g thread can enqueue into). When a worker needs another piece of\\nwork to process, it first checks it\", \"s own local queue, then it checks the global queue, and then only if it\\ncouldn\\u2019t find work in either\", \" of those two places, it goes and checks all of the other threads\\u2019 local\\nqueues to see if it can hel\", \"p lighten their load. As machines scale up to have more and more cores, and\\nmore and more threads, t\", \"here\\u2019s more and more contention on these shared queues, and in particular\\non the global queue. This \", \"PR addresses this for such larger machines by introducing additional global\\nqueues once the machine \", \"reaches a certain threshold (32 processors today). This helps to partition\\naccesses across multiple \", \"queues, thereby decreasing contention.\\nAnother is dotnet/runtime#57885. In order to coordinate threa\", \"ds, when work items were enqueued\\nand dequeued, the pool was issuing requests to its threads to let \", \"them know that there was work\\navailable to do. This, however, often resulted in oversubscription, wh\", \"ere more threads than necessary\\nwould race to try to get work items, especially when the system wasn\", \"\\u2019t at full load. That in turn would\\nmanifest as a throughput regression. This change overhauls how t\", \"hreads are requested, such that only\\none additional thread is requested at a time, and after that th\", \"read has dequeued its first work item, it\\ncan issue a request for an additional thread if there\\u2019s wo\", \"rk remaining, and then that one can issue an\\nadditional request, and so on. Here\\u2019s one of our perfor\", \"mance tests in our performance test suite (I\\u2019ve\\nsimplified it down to remove a bunch of configuratio\", \"n options from the test, but it\\u2019s still accurately\\none of those configurations). At first glance you\", \" might think, \\u201chey, this is a performance test about\\nArrayPool, why is it showing up in a threading \", \"discussion?\\u201d And, you\\u2019d be right, this is a performance\\ntest that was written focused on ArrayPool. \", \"However, as mentioned earlier, threading impacts\\neverything, and in this case, that await Task.Yield\", \"() in the middle there causes the remainder of\\nthis method to be queued to the ThreadPool for execut\", \"ion. And because of how the test is structured,\\ndoing \\u201creal work\\u201d that competes for CPU cycles with \", \"thread pool threads all racing to get their next\\ntask, it shows a measurable improvement when moving\", \" to .NET 7.\\n89 CHAPTER 8 | Threadingprivate readonly byte[][] _nestedArrays = new byte[8][];\\nprivate\", \" const int Iterations = 100_000;\\nprivate static byte IterateAll(byte[] arr)\\n{\\nbyte ret = default;\\nfo\", \"reach (byte item in arr) ret = item;\\nreturn ret;\\n}\\n[Benchmark(OperationsPerInvoke = Iterations)]\\npub\", \"lic async Task MultipleSerial()\\n{\\nfor (int i = 0; i < Iterations; i++)\\n{\\nfor (int j = 0; j < _nested\", \"Arrays.Length; j++)\\n{\\n_nestedArrays[j] = ArrayPool<byte>.Shared.Rent(4096);\\n_nestedArrays[j].AsSpan(\", \").Clear();\\n}\\nawait Task.Yield();\\nfor (int j = _nestedArrays.Length - 1; j >= 0; j--)\\n{\\nIterateAll(_n\", \"estedArrays[j]);\\nArrayPool<byte>.Shared.Return(_nestedArrays[j]);\\n}\\n}\\n}\\nMethod Runtime Mean Ratio\\nMu\", \"ltipleSerial .NET 6.0 14.340 us 1.00\\nMultipleSerial .NET 7.0 9.262 us 0.65\\nThere have been improveme\", \"nts outside of ThreadPool, as well. One notable change is in the handling\\nof AsyncLocal<T>s, in dotn\", \"et/runtime#68790. AsyncLocal<T> is integrated tightly with\\nExecutionContext; in fact, in .NET Core, \", \"ExecutionContext is entirely about flowing AsyncLocal<T>\\ninstances. An ExecutionContext instance mai\", \"ntains a single field, a map data structure, that stores\\nthe data for all AsyncLocal<T> with data pr\", \"esent in that context. Each AsyncLocal<T> has an object it\\nuses as a key, and any gets or sets on th\", \"at AsyncLocal<T> manifest as getting the current\\nExecutionContext, looking up that AsyncLocal<T>\\u2019s k\", \"ey in the context\\u2019s dictionary, and then either\\nreturning whatever data it finds, or in the case of \", \"a setter, creating a new ExecutionContext with an\\nupdated dictionary and publishing that back. This \", \"dictionary thus needs to be very efficient for reads\\nand writes, as developers expect AsyncLocal<T> \", \"access to be as fast as possible, often treating it as if\\nit were any other local. So, to optimize t\", \"hese lookups, the representation of that dictionary changes\\nbased on how many AsyncLocal<T>s are rep\", \"resented in this context. For up to three items, dedicated\\nimplementations with fields for each of t\", \"he three keys and values were used. Above that up to around\\n16 elements, an array of key/value pairs\", \" was used. And above that, a Dictionary<,> was used. For the\\nmost part, this has worked well, with t\", \"he majority of ExecutionContexts being able to represent\\nmany flows with one of the first three type\", \"s. However, it turns out that four active AsyncLocal<T>\\ninstances is really common, especially in AS\", \"P.NET where ASP.NET infrastructure itself uses a couple.\\n90 CHAPTER 8 | ThreadingSo, this PR took th\", \"e complexity hit to add a dedicated type for four key/value pairs, in order to\\noptimize from one to \", \"four of them rather than one to three. While this improves throughput a bit, its\\nmain intent was to \", \"improve allocation, which is does over .NET 6 by ~20%.\\nprivate AsyncLocal<int> asyncLocal1 = new Asy\", \"ncLocal<int>();\\nprivate AsyncLocal<int> asyncLocal2 = new AsyncLocal<int>();\\nprivate AsyncLocal<int>\", \" asyncLocal3 = new AsyncLocal<int>();\\nprivate AsyncLocal<int> asyncLocal4 = new AsyncLocal<int>();\\n[\", \"Benchmark(OperationsPerInvoke = 4000)]\\npublic void Update()\\n{\\nfor (int i = 0; i < 1000; i++)\\n{\\nasync\", \"Local1.Value++;\\nasyncLocal2.Value++;\\nasyncLocal3.Value++;\\nasyncLocal4.Value++;\\n}\\n}\\nMethod Runtime Me\", \"an Ratio Code Size Allocated Alloc Ratio\\nUpdate .NET 6.0 61.96 ns 1.00 1,272 B 176 B 1.00\\nUpdate .NE\", \"T 7.0 61.92 ns 1.00 1,832 B 144 B 0.82\\nAnother valuable fix comes for locking in dotnet/runtime#7016\", \"5. This particular improvement is a bit\\nharder to demonstrate with benchmarkdotnet, so just try runn\", \"ing this program, first on .NET 6 and\\nthen on .NET 7:\\nusing System.Diagnostics;\\nvar rwl = new Reader\", \"WriterLockSlim();\\nvar tasks = new Task[100];\\nint count = 0;\\nDateTime end = DateTime.UtcNow + TimeSpa\", \"n.FromSeconds(10);\\nwhile (DateTime.UtcNow < end)\\n{\\nfor (int i = 0; i < 100; ++i)\\n{\\ntasks[i] = Task.R\", \"un(() =>\\n{\\nvar sw = Stopwatch.StartNew();\\nrwl.EnterReadLock();\\nrwl.ExitReadLock();\\nsw.Stop();\\nif (sw\", \".ElapsedMilliseconds >= 10)\\n{\\nConsole.WriteLine(Interlocked.Increment(ref count));\\n}\\n});\\n}\\nTask.Wait\", \"All(tasks);\\n}\\n91 CHAPTER 8 | ThreadingThis is simply spinning up 100 tasks, each of which enters and\", \" exits a read-write lock, waits for them\\nall, and then does the process over again, for 10 seconds. \", \"It also times how long it takes to enter and\\nexit the lock, and writes a warning if it had to wait f\", \"or at least 15ms. When I run this on .NET 6, I get\\n~100 occurrences of it taking >= 10 ms to enter/e\", \"xit the lock. On .NET 7, I get 0 occurrences. Why the\\ndifference? The implementation of ReaderWriter\", \"LockSlim has its own spin loop implementation, and\\nthat spin loop tries to mix together various thin\", \"gs to do as it spins, ranging from calling\\nThread.SpinWait to Thread.Sleep(0) to Thread.Sleep(1). Th\", \"e issue lies in the Thread.Sleep(1).\\nThat\\u2019s saying \\u201cput this thread to sleep for 1 millisecond\\u201d; how\", \"ever, the operating system has the\\nultimate say on such timings, and on Windows, by default that sle\", \"ep is going to be closer to 15\\nmilliseconds (on Linux it\\u2019s a bit lower but still quite high). Thus, \", \"every time there was enough\\ncontention on the lock to force it to call Thread.Sleep(1), we\\u2019d incur a\", \" delay of at least 15\\nmilliseconds, if not more. The aforementioned PR fixed this by eliminating use\", \" of Thread.Sleep(1).\\nOne final threading-related change to call out: dotnet/runtime#68639. This one \", \"is Windows specific.\\nWindows has the concept of processor groups, each of which can have up to 64 co\", \"res in it, and by\\ndefault when a process runs, it\\u2019s assigned a specific processor group and can only\", \" use the cores in\\nthat group. With .NET 7, the runtime flips its default so that by default it will \", \"try to use all processor\\ngroups if possible.\\n92 CHAPTER 8 | Threading9\\nCHAPTER\\nPrimitive Types and\\nN\", \"umerics\\nWe\\u2019ve looked at code generation and GC, at threading and vectorization, at interop\\u2026 let\\u2019s tu\", \"rn our\\nattention to some of the fundamental types in the system. Primitives like int and bool and do\", \"uble,\\ncore types like Guid and DateTime, they form the backbone on which everything is built, and ev\", \"ery\\nrelease it\\u2019s exciting to see the improvements that find their way into these types.\\nfloat and do\", \"uble got a very nice boost in their implementation of parsing (e.g. double.Parse,\\nfloat.TryParse, et\", \"c.). dotnet/runtime#62301 from [@CarlVerret](https://github.com/CarlVerret)\\nsignificantly improves d\", \"ouble.Parse and float.Parse for parsing UTF16 text into floating-point\\nvalues. This is particularly \", \"neat because it\\u2019s based on some relatively recent research from\\n[@lemire](https://github.com/lemire)\", \" and [@CarlVerret](https://github.com/CarlVerret), who used C#\\nwith .NET 5 to implement a very fast \", \"implementation for parsing floating-point numbers, and that\\nimplementation how now found its way int\", \"o .NET 7!\\nprivate string[] _valuesToParse;\\n[GlobalSetup]\\npublic void Setup()\\n{\\nusing HttpClient hc =\", \" new HttpClient();\\nstring text =\\nhc.GetStringAsync(\\\"https://raw.githubusercontent.com/CarlVerret/csF\", \"astFloat/1d800237275f759\\nb743b86fcce6680d072c1e834/Benchmark/data/canada.txt\\\").Result;\\nvar lines = n\", \"ew List<string>();\\nforeach (ReadOnlySpan<char> line in text.AsSpan().EnumerateLines())\\n{\\nReadOnlySpa\", \"n<char> trimmed = line.Trim();\\nif (!trimmed.IsEmpty)\\n{\\nlines.Add(trimmed.ToString());\\n}\\n}\\n_valuesToP\", \"arse = lines.ToArray();\\n}\\n[Benchmark]\\npublic double ParseAll()\\n{\\ndouble total = 0;\\nforeach (string s\", \" in _valuesToParse)\\n{\\ntotal += double.Parse(s);\\n93 CHAPTER 9 | Primitive Types and Numerics}\\nreturn \", \"total;\\n}\\nMethod Runtime Mean Ratio\\nParseAll .NET 6.0 26.84 ms 1.00\\nParseAll .NET 7.0 12.63 ms 0.47\\nb\", \"ool.TryParse and bool.TryFormat were also improved. dotnet/runtime#64782 streamlined these\\nimplement\", \"ations by using BinaryPrimitives to perform fewer writes and reads. For example, instead\\nof TryForma\", \"t writing out \\u201cTrue\\u201d by doing:\\ndestination[0] = 'T';\\ndestination[1] = 'r';\\ndestination[2] = 'u';\\ndes\", \"tination[3] = 'e';\\nwhich requires four writes, it can instead implement the same operation in a sing\", \"le write by doing:\\nBinaryPrimitives.WriteUInt64LittleEndian(MemoryMarshal.AsBytes(destination),\\n0x65\", \"007500720054); // \\\"True\\\"\\nThat 0x65007500720054 is the numerical value of the four characters in memo\", \"ry as a single ulong. You\\ncan see the impact of these changes with a microbenchmark:\\nprivate bool _v\", \"alue = true;\\nprivate char[] _chars = new char[] { 'T', 'r', 'u', 'e' };\\n[Benchmark] public bool Pars\", \"eTrue() => bool.TryParse(_chars, out _);\\n[Benchmark] public bool FormatTrue() => _value.TryFormat(_c\", \"hars, out _);\\nMethod Runtime Mean Ratio\\nParseTrue .NET 6.0 7.347 ns 1.00\\nParseTrue .NET 7.0 2.327 ns\", \" 0.32\\nFormatTrue .NET 6.0 3.030 ns 1.00\\nFormatTrue .NET 7.0 1.997 ns 0.66\\nEnum gets several performa\", \"nce boosts, as well. For example, when performing an operation like\\nEnum.IsDefined, Enum.GetName, or\", \" Enum.ToString, the implementation consults a cache of all of the\\nvalues defined on the enum. This c\", \"ache includes the string name and the value for every defined\\nenumeration in the Enum. It\\u2019s also sor\", \"ted by value in an array, so when one of these operations is\\nperformed, the code uses Array.BinarySe\", \"arch to find the index of the relevant entry. The issue with\\nthat is one of overheads. When it comes\", \" to algorithmic complexity, a binary search is faster than a\\nlinear search; after all, a binary sear\", \"ch is O(log N) whereas a linear search is O(N). However, there\\u2019s\\nalso less overhead for every step o\", \"f the algorithm in a linear search, and so for smaller values of N, it\\ncan be much faster to simply \", \"do the simple thing. That\\u2019s what dotnet/runtime#57973 does for enums.\\nFor enums with less than or eq\", \"ual to 32 defined values, the implementation now just does a linear\\nsearch via the internal SpanHelp\", \"ers.IndexOf (the worker routine behind IndexOf on spans, strings,\\n94 CHAPTER 9 | Primitive Types and\", \" Numericsand arrays), and for enums with more than that, it does a SpanHelpers.BinarySearch (which i\", \"s the\\nimplementation for Array.BinarySearch).\\nprivate DayOfWeek[] _days = Enum.GetValues<DayOfWeek>(\", \");\\n[Benchmark]\\npublic bool AllDefined()\\n{\\nforeach (DayOfWeek day in _days)\\n{\\nif (!Enum.IsDefined(day\", \"))\\n{\\nreturn false;\\n}\\n}\\nreturn true;\\n}\\nMethod Runtime Mean Ratio\\nAllDefined .NET 6.0 159.28 ns 1.00\\nA\", \"llDefined .NET 7.0 94.86 ns 0.60\\nEnums also get a boost in conjunction with Nullable<T> and Equality\", \"Comparer<T>.Default.\\nEqualityComparer<T>.Default caches a singleton instance of an EqualityComparer<\", \"T> instance\\nreturned from all accesses to Default. That singleton is initialized based on the T in q\", \"uestion, with the\\nimplementation choosing from a multitude of different internal implementations, fo\", \"r example a\\nByteArrayComparer specialized for bytes, a GenericEqualityComparer<T> for Ts that implem\", \"ent\\nIComparable<T>, and so on. The catch-all, for arbitrary types, is an ObjectEqualityComparer<T>. \", \"As it\\nhappens, nullable enums would end up hitting this catch-all path, which means that every Equal\", \"s call\\nwould box the arguments. dotnet/runtime#68077 fixes this by ensuring nullable enums get mappe\", \"d\\nto (an existing) specialized comparer for Nullable<T> and simple tweaks its definition to ensure i\", \"t can\\nplay nicely with enums. The results highlight just how much unnecessary overhead there was\\npre\", \"viously.\\nprivate DayOfWeek?[] _enums = Enum.GetValues<DayOfWeek>().Select(e =>\\n(DayOfWeek?)e).ToArra\", \"y();\\n[Benchmark]\\n[Arguments(DayOfWeek.Saturday)]\\npublic int FindEnum(DayOfWeek value) => IndexOf(_en\", \"ums, value);\\nprivate static int IndexOf<T>(T[] values, T value)\\n{\\nfor (int i = 0; i < values.Length;\", \" i++)\\n{\\nif (EqualityComparer<T>.Default.Equals(values[i], value))\\n{\\nreturn i;\\n}\\n}\\nreturn -1;\\n}\\n95 CH\", \"APTER 9 | Primitive Types and NumericsMethod Runtime Mean Ratio\\nFindEnum .NET 6.0 421.608 ns 1.00\\nFi\", \"ndEnum .NET 7.0 5.466 ns 0.01\\nNot to be left out, Guid\\u2019s equality operations also get faster, thanks\", \" to dotnet/runtime#66889 from\\n[@madelson](https://github.com/madelson). The previous implementation \", \"of Guid split the data into\\nfour 32-bit values and performed 4 int comparisons. With this change, if\", \" the current hardware has\\n128-bit SIMD support, the implementation loads the data from the two guids\", \" as two vectors and\\nsimply does a single comparison.\\nprivate Guid _guid1 = Guid.Parse(\\\"0aa2511d-251a\", \"-4764-b374-4b5e259b6d9a\\\");\\nprivate Guid _guid2 = Guid.Parse(\\\"0aa2511d-251a-4764-b374-4b5e259b6d9a\\\");\", \"\\n[Benchmark]\\npublic bool GuidEquals() => _guid1 == _guid2;\\nMethod Runtime Mean Ratio Code Size\\nGuidE\", \"quals .NET 6.0 2.119 ns 1.00 90 B\\nGuidEquals .NET 7.0 1.354 ns 0.64 78 B\\nDateTime equality is also i\", \"mproved. dotnet/runtime#59857 shaves some overhead off of\\nDateTime.Equals. DateTime is implemented w\", \"ith a single ulong _dateData field, where the majority\\nof the bits store a ticks offset from 1/1/000\", \"1 12:00am and where each tick is 100 nanoseconds, and\\nwhere the top two bits describe the DateTimeKi\", \"nd. Thus the public Ticks property returns the value\\nof _dateData but with the top two bits masked o\", \"ut, e.g. _dateData & 0x3FFFFFFFFFFFFFFF. The\\nequality operators were all then just comparing one Dat\", \"eTime\\u2019s Ticks against the others, such that we\\neffectively get (dt1._dateData & 0x3FFFFFFFFFFFFFFF) \", \"== (dt2._dateData &\\n0x3FFFFFFFFFFFFFFF). However, as a micro-optimization that can instead be expres\", \"sed more\\nefficiently as ((dt1._dateData ^ dt2._dateData) << 2) == 0. It\\u2019s difficult to measure the\\nd\", \"ifference in such tiny operations, but you can see it simply from the number of instructions involve\", \"d,\\nwhere on .NET 6 this produces:\\n; Program.DateTimeEquals()\\nmov rax,[rcx+8]\\nmov rdx,[rcx+10]\\nmov rc\", \"x,0FFFFFFFFFFFF\\nand rax,rcx\\nand rdx,rcx\\ncmp rax,rdx\\nsete al\\nmovzx eax,al\\nret\\n; Total bytes of code 3\", \"4\\nand on .NET 7 this produces:\\n; Program.DateTimeEquals()\\nmov rax,[rcx+8]\\nmov rdx,[rcx+10]\\nxor rax,r\", \"dx\\nshl rax,2\\n96 CHAPTER 9 | Primitive Types and Numericssete al\\nmovzx eax,al\\nret\\n; Total bytes of co\", \"de 22\\nso instead of a mov, and, and, and cmp, we get just an xor and a shl.\\nOther operations on Date\", \"Time also become more efficient, thanks to dotnet/runtime#72712 from\\n[@SergeiPavlov](https://github.\", \"com/SergeiPavlov) and dotnet/runtime#73277 from\\n[@SergeiPavlov](https://github.com/SergeiPavlov). In\", \" another case of .NET benefiting from recent\\nadvancements in research, these PRs implemented the alg\", \"orithm from Neri and Schneider\\u2019s\\n\\u201cEuclidean Affine Functions and Applications to Calendar Algorithms\", \"\\u201d in order to improve\\nDateTime.Day, DateTime.DayOfYear, DateTime.Month, and DateTime.Year, as well a\", \"s the internal\\nhelper DateTime.GetDate() that\\u2019s used by a bunch of other methods like DateTime.AddMo\", \"nths,\\nUtf8Formatter.TryFormat(DateTime, ...), DateTime.TryFormat, and DateTime.ToString.\\nprivate Dat\", \"eTime _dt = DateTime.UtcNow;\\nprivate char[] _dest = new char[100];\\n[Benchmark] public int Day() => _\", \"dt.Day;\\n[Benchmark] public int Month() => _dt.Month;\\n[Benchmark] public int Year() => _dt.Year;\\n[Ben\", \"chmark] public bool TryFormat() => _dt.TryFormat(_dest, out _, \\\"r\\\");\\nMethod Runtime Mean Ratio\\nDay .\", \"NET 6.0 5.2080 ns 1.00\\nDay .NET 7.0 2.0549 ns 0.39\\nMonth .NET 6.0 4.1186 ns 1.00\\nMonth .NET 7.0 2.09\", \"45 ns 0.51\\nYear .NET 6.0 3.1422 ns 1.00\\nYear .NET 7.0 0.8200 ns 0.26\\nTryFormat .NET 6.0 27.6259 ns 1\", \".00\\nTryFormat .NET 7.0 25.9848 ns 0.94\\nSo, we\\u2019ve touched on improvements to a few types, but the pi\\u00e8\", \"ce de r\\u00e9sistance around primitive types\\nin this release is \\u201cgeneric math,\\u201d which impacts almost ever\", \"y primitive type in .NET. There are\\nsignificant improvements here, some which have been in the makin\", \"g for literally over a decade.\\nThere\\u2019s an excellent blog post from June dedicated just to generic ma\", \"th, so I won\\u2019t go into much\\ndepth here. At a high level, however, there are now over 30 new interfac\", \"es that utilize the new C# 11\\nstatic abstract interface methods functionality, exposing wide-ranging\", \" operations from exponentiation\\nfunctions to trigonometric functions to standard numerical operators\", \", all available via generics, such\\nthat you can write one implementation that operates over these in\", \"terfaces generically and have your\\n97 CHAPTER 9 | Primitive Types and Numericscode applied to any ty\", \"pes that implement the interfaces\\u2026 which all of the numerical types in .NET 7\\ndo (including not just\", \" the primitives but also, for example, BigInteger and Complex). A preview\\nversion of this feature, i\", \"ncluding necessary runtime support, language syntax, C# compiler support,\\ngeneric interfaces, and in\", \"terface implementations all shipped in .NET 6 and C# 10, but it wasn\\u2019t\\nsupported for production use,\", \" and you had to download an experimental reference assembly in order\\nto get access. With dotnet/runt\", \"ime#65731, all of this support moved into .NET 7 as supported\\nfunctionality. dotnet/runtime#66748, d\", \"otnet/runtime#67453, dotnet/runtime#69391,\\ndotnet/runtime#69582, dotnet/runtime#69756, and dotnet/ru\", \"ntime#71800 all updated the design\\nand implementation based on feedback from usage in .NET 6 and .NE\", \"T 7 previews as well as a proper\\nAPI review with our API review team (a process every new API in .NE\", \"T goes through before it\\u2019s\\nshipped publicly). dotnet/runtime#67714 added support for user-defined ch\", \"ecked operators, a new\\nC# 11 feature that enables both unchecked and checked variations of operators\", \" to be exposed, with\\nthe compiler picking the right one based on the checked context. dotnet/runtime\", \"#68096 also added\\nsupport for the new C# 11 unsigned right shift operator (>>>). And dotnet/runtime#\", \"69651,\\ndotnet/runtime#67939, dotnet/runtime#73274, dotnet/runtime#71033, dotnet/runtime#71010,\\ndotne\", \"t/runtime#68251, dotnet/runtime#68217, and dotnet/runtime#68094 all added large swaths of\\nnew public\", \" surface area for various operations, all with highly-efficient managed implementations, in\\nmany cas\", \"es based on the open source AMD Math Library.\\nWhile this support is all primarily intended for exter\", \"nal consumers, the core libraries do consume\\nsome of it internally. You can see how these APIs clean\", \" up consuming code even while maintaining\\nperformance in PRs like dotnet/runtime#68226 and dotnet/ru\", \"ntime#68183, which use the interfaces\\nto deduplicate a bunch of LINQ code in Enumerable.Sum/Average/\", \"Min/Max. There are multiple\\noverloads of these methods for int, long, float, double, and decimal. Th\", \"e GitHub summary of the\\ndiffs tells the story on how much code was able to be deleted:\\nAnother simpl\", \"e example comes from the new System.Formats.Tar library in .NET 7, which as the\\nname suggests is use\", \"d for reading and writing archives in any of multiple tar file formats. The tar file\\nformats include\", \" integer values in octal representation, so the TarReader class needs to parse octal\\nvalues. Some of\", \" these values are 32-bit integers, and some are 64-bit integers. Rather than have two\\nseparate Parse\", \"OctalAsUInt32 and ParseOctalAsUInt64 methods, dotnet/runtime#74281]\\nconsolidated the methods into a \", \"single ParseOctal<T> with the constraint where T : struct,\\nINumber<T>. The implementation is then en\", \"tirely in terms of T and can be used for either of these\\ntypes (plus any other types meeting the con\", \"straints, should that ever be needed). What\\u2019s particularly\\ninteresting about this example is the Par\", \"seOctal<T> method includes use of checked, e.g. value =\\nchecked((value * octalFactor) + T.CreateTrun\", \"cating(digit));. This is only possible because\\nC# 11 includes the aforementioned support for user-de\", \"fined checked operators, enabling the generic\\nmath interfaces to support both the normal and checked\", \" varieties, e.g. the IMultiplyOperators<,,>\\ninterface contains these methods:\\n98 CHAPTER 9 | Primiti\", \"ve Types and Numericsstatic abstract TResult operator *(TSelf left, TOther right);\\nstatic virtual TR\", \"esult operator checked *(TSelf left, TOther right) => left * right;\\nand the compiler will pick the a\", \"ppropriate one based on the context.\\nIn addition to all the existing types that get these interfaces\", \", there are also new types.\\ndotnet/runtime#69204 adds the new Int128 and UInt128 types. As these typ\", \"es implement all of the\\nrelevant generic math interfaces, they come complete with a huge number of m\", \"ethods, over 100 each,\\nall of which are implemented efficiently in managed code. In the future, the \", \"aim is that some set of\\nthese will be optimized further by the JIT and to take advantage of hardware\", \" acceleration.\\nSeveral PRs moved native implementations of these kinds of math operations to managed\", \" code.\\ndotnet/runtime#63881 from [@am11](https://github.com/am11) did so for Math.Abs and Math.AbsF\\n\", \"(absolute value), and dotnet/runtime#56236 from\\n[@alexcovington](https://github.com/alexcovington) d\", \"id so for Math.ILogB and MathF.ILogB (base 2\\ninteger logarithm). The latter\\u2019s implementation is base\", \"d on the MUSL libc implementation of the same\\nalgorithm, and in addition to improving performance (i\", \"n part by avoiding the transition between\\nmanaged and native code, in part by the actual algorithm e\", \"mployed), it also enabled deleting two\\ndistinct implementations from native code, one from the corec\", \"lr side and one from the mono side,\\nwhich is always a nice win from a maintainability perspective.\\n[\", \"Benchmark]\\n[Arguments(12345.6789)]\\npublic int ILogB(double arg) => Math.ILogB(arg);\\nMethod Runtime a\", \"rg Mean Ratio\\nILogB .NET 6.0 12345.6789 4.056 ns 1.00\\nILogB .NET 7.0 12345.6789 1.059 ns 0.26\\nOther \", \"math operations were also improved in various ways. Math{F}.Truncate was improved in\\ndotnet/runtime#\", \"65014 from [@MichalPetryka](https://github.com/MichalPetryka) by making it into a\\nJIT intrinsic, suc\", \"h that on Arm64 the JIT could directly emit a frintz instruction.\\ndotnet/runtime#65584 did the same \", \"for Max and Min so that the Arm-specific fmax and fmin\\ninstructions could be used. And several BitCo\", \"nverter APIs were also turned into intrinsics in\\ndotnet/runtime#71567 in order to enable better code\", \" generation in some generic math scenarios.\\ndotnet/runtime#55121 from [@key-moon](https://github.com\", \"/key-moon) also improves parsing, but\\nfor BigInteger, and more specifically for really, really big B\", \"igIntegers. The algorithm previously\\nemployed for parsing a string into a BigInteger was O(N^2) wher\", \"e N is the number of digits, but\\nwhile a larger algorithmic complexity than we\\u2019d normally like, it h\", \"as a low constant overhead and so is\\nstill reasonable for reasonably-sized values. In contrast, an a\", \"lternative algorithm is available that runs\\nin O(N * (log N)^2) time, but with a much higher constan\", \"t factor involved. That makes is so that it\\u2019s\\nreally only worth switching for really big numbers. Wh\", \"ich is what this PR does. It implements the\\nalternative algorithm and switches over to it when the i\", \"nput is at least 20,000 digits (so, yes, big). But\\nfor such large numbers, it makes a significant di\", \"fference.\\n99 CHAPTER 9 | Primitive Types and Numericsprivate string _input = string.Concat(Enumerabl\", \"e.Repeat(\\\"1234567890\\\", 100_000)); // \\\"One\\nmiiilliiiion digits\\\"\\n[Benchmark]\\npublic BigInteger Parse()\", \" => BigInteger.Parse(_input);\\nMethod Runtime Mean Ratio\\nParse .NET 6.0 3.474 s 1.00\\nParse .NET 7.0 1\", \".672 s 0.48\\nAlso related to BigInteger (and not just for really big ones), dotnet/runtime#35565 from\", \"\\n[@sakno](https://github.com/sakno) overhauled much of the internals of BigInteger to be based on\\nsp\", \"ans rather than arrays. That in turn enabled a fair amount of use of stack allocation and slicing to\", \"\\navoid allocation overheads, while also improving reliability and safety by moving some code away\\nfr\", \"om unsafe pointers to safe spans. The primary performance impact is visible in allocation numbers,\\na\", \"nd in particular for operations related to division.\\nprivate BigInteger _bi1 = BigInteger.Parse(stri\", \"ng.Concat(Enumerable.Repeat(\\\"9876543210\\\",\\n100)));\\nprivate BigInteger _bi2 = BigInteger.Parse(string.\", \"Concat(Enumerable.Repeat(\\\"1234567890\\\",\\n100)));\\nprivate BigInteger _bi3 = BigInteger.Parse(string.Con\", \"cat(Enumerable.Repeat(\\\"12345\\\", 10)));\\n[Benchmark]\\npublic BigInteger ModPow() => BigInteger.ModPow(_b\", \"i1, _bi2, _bi3);\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nModPow .NET 6.0 1.527 ms 1.00 706 B\", \" 1.00\\nModPow .NET 7.0 1.589 ms 1.04 50 B 0.07\\n100 CHAPTER 9 | Primitive Types and Numerics10\\nCHAPTER\", \"\\nArrays, Strings, and Spans\\nWhile there are many forms of computation that can consume resources in \", \"applications, some of the\\nmost common include processing of data stored in arrays, strings, and now \", \"spans. Thus you see a\\nfocus in every .NET release on removing as much overhead as possible from such\", \" scenarios, while also\\nfinding ways to further optimize the concrete operations developers are commo\", \"nly performing.\\nLet\\u2019s start with some new APIs that can help make writing more efficient code easier\", \". When examining\\nstring parsing/processing code, it\\u2019s very common to see characters examined for the\", \"ir inclusion in\\nvarious sets. For example, you might see a loop looking for characters that are ASCI\", \"I digits:\\nwhile (i < str.Length)\\n{\\nif (str[i] >= '0' && str[i] <= '9')\\n{\\ni++;\\n}\\n}\\nor that are ASCII \", \"letters:\\nwhile (i < str.Length)\\n{\\nif ((str[i] >= 'a' && str[i] <= 'z') || (str[i] >= 'A' && str[i] <\", \"= 'Z'))\\n{\\ni++;\\n}\\n}\\nor other such groups. Interestingly, there\\u2019s wide-spread variation in how such ch\", \"ecks are coded, often\\ndepending on how much effort a developer put in to optimizing them, or in some\", \" cases likely not\\neven recognizing that some amount of performance was being left on the table. For \", \"example, that\\nsame ASCII letter check could instead be written as:\\nwhile (i < str.Length)\\n{\\nif ((uin\", \"t)((c | 0x20) - 'a') <= 'z' - 'a')\\n{\\ni++;\\n}\\n}\\nwhich while more \\u201cintense\\u201d is also much more concise a\", \"nd more efficient. It\\u2019s taking advantage of a\\nfew tricks. First, rather than having two comparisons \", \"to determine whether the character is greater\\nthan or equal to the lower bound and less than or equa\", \"l to the upper bound, it\\u2019s doing a single\\ncomparison based on the distance between the character and\", \" the lower bound ((uint)(c - 'a')). If\\n'c' is beyond 'z', then 'c' - 'a' will be larger than 25, and\", \" the comparison will fail. If 'c' is earlier\\n101 CHAPTER 10 | Arrays, Strings, and Spansthan 'a', th\", \"en 'c' - 'a' will be negative, and casting it to uint will then cause it to wrap around to a\\nmassive\", \" number, also larger than 25, again causing the comparison to fail. Thus, we\\u2019re able to pay a\\nsingle\", \" additional subtraction to avoid an entire additional comparison and branch, which is almost\\nalways \", \"a good deal. The second trick is that | 0x20. The ASCII table has some well-thought-out\\nrelationship\", \"s, including that upper-case 'A' and lower-case 'a' differ by only a single bit ('A' is\\n0b1000001 an\", \"d 'a' is 0b1100001). To go from any lowercase ASCII letter to its uppercase ASCII\\nequivalent, we thu\", \"s need only to & ~0x20 (to turn off that bit), and to go in the opposite direction\\nfrom any uppercas\", \"e ASCII letter to its lowercase ASCII equivalent, we need only to | 0x20 (to turn on\\nthat bit). We c\", \"an take advantage of this in our range check, then, by normalizing our char c to be\\nlowercase, such \", \"that for the low cost of a bit twiddle, we can achieve both the lowercase and\\nuppercase range checks\", \". Of course, those tricks aren\\u2019t something we want every developer to have to\\nknow and write on each\", \" use. Instead, .NET 7 exposes a bunch of new helpers on System.Char to\\nencapsulate these common chec\", \"ks, done in an efficient manner. char already had methods like\\nIsDigit and IsLetter, which provided \", \"the more comprehensive Unicode meaning of those monikers\\n(e.g. there are ~320 Unicode characters cat\", \"egorized as \\u201cdigits\\u201d). Now in .NET 7, there are also these\\nhelpers:\\n\\u2022 IsAsciiDigit\\n\\u2022 IsAsciiHexDigit\", \"\\n\\u2022 IsAsciiHexDigitLower\\n\\u2022 IsAsciiHexDigitUpper\\n\\u2022 IsAsciiLetter\\n\\u2022 IsAsciiLetterLower\\n\\u2022 IsAsciiLetterU\", \"pper\\n\\u2022 IsAsciiLetterOrDigit\\nThese methods were added by dotnet/runtime#69318, which also employed th\", \"em in dozens of\\nlocations where such checks were being performed across dotnet/runtime (many of them\", \" using less-\\nefficient approaches).\\nAnother new API focused on encapsulating a common pattern is the\", \" new\\nMemoryExtensions.CommonPrefixLength method, introduced by dotnet/runtime#67929. This accepts\\nei\", \"ther two ReadOnlySpan<T> instances or a Span<T> and a ReadOnlySpan<T>, and an optional\\nIEqualityComp\", \"arer<T>, and returns the number of elements that are the same at the beginning of\\neach input span. T\", \"his is useful when you want to know the first place that two inputs differ.\\ndotnet/runtime#68210 fro\", \"m [@gfoidl](https://github.com/gfoidl) then utilized the new Vector128\\nfunctionality to provide a ba\", \"sic vectorization of the implementation. As it\\u2019s comparing two sequences\\nand looking for the first p\", \"lace they differ, this implementation uses a neat trick, which is to have a\\nsingle method implemente\", \"d to compare the sequences as bytes. If the T being compared is bitwise-\\nequatable and no custom equ\", \"ality comparer is supplied, then it reinterpret-casts the refs from the\\nspans as byte refs, and uses\", \" the single shared implementation.\\nYet another new set of APIs are the IndexOfAnyExcept and LastInde\", \"xOfAnyExcept methods,\\nintroduced by dotnet/runtime#67941 and used in a variety of additional call si\", \"tes by\\ndotnet/runtime#71146 and dotnet/runtime#71278. While somewhat of a mouthful, these methods\\nar\", \"e quite handy. They do what their name suggests: whereas IndexOf(T value) searches for the first\\n102\", \" CHAPTER 10 | Arrays, Strings, and Spansoccurrence of value in the input, and whereas IndexOfAny(T v\", \"alue0, T value1, ...) searches for\\nthe first occurrence of any of value0, value1, etc. in the input,\", \" IndexOfAnyExcept(T value) searches\\nfor the first occurrence of something that\\u2019s not equal to value,\", \" and similarly IndexOfAnyExcept(T\\nvalue0, T value1, ...) searches for the first occurrence of someth\", \"ing that\\u2019s not equal to value0,\\nvalue1, etc. For example, let\\u2019s say you wanted to know whether an ar\", \"ray of integers was entirely 0.\\nYou can now write that as:\\nbool allZero = array.AsSpan().IndexOfAnyE\", \"xcept(0) < 0;\\ndotnet/runtime#73488 vectorizes this overload, as well.\\nprivate byte[] _zeros = new by\", \"te[1024];\\n[Benchmark(Baseline = true)]\\npublic bool OpenCoded()\\n{\\nforeach (byte b in _zeros)\\n{\\nif (b \", \"!= 0)\\n{\\nreturn false;\\n}\\n}\\nreturn true;\\n}\\n[Benchmark]\\npublic bool IndexOfAnyExcept() => _zeros.AsSpan\", \"().IndexOfAnyExcept((byte)0) < 0;\\nMethod Mean Ratio\\nOpenCoded 370.47 ns 1.00\\nIndexOfAnyExcept 23.84 \", \"ns 0.06\\nOf course, while new \\u201cindex of\\u201d variations are helpful, we already have a bunch of such meth\", \"ods, and\\nit\\u2019s important that they are as efficient as possible. These core IndexOf{Any} methods are \", \"used in\\nhuge numbers of places, many of which are performance-sensitive, and so every release they g\", \"et\\nadditional tender-loving care. While PRs like dotnet/runtime#67811 got gains by paying very close\", \"\\nattention to the assembly code being generated (in this case, tweaking some of the checks used on\\nA\", \"rm64 in IndexOf and IndexOfAny to achieve better utilization), the biggest improvements here come\\nin\", \" places where either vectorization was added and none was previously employed, or where the\\nvectoriz\", \"ation scheme was overhauled for significant gain. Let\\u2019s start with dotnet/runtime#63285,\\nwhich yield\", \"s huge improvements for many uses of IndexOf and LastIndexOf for \\u201csubstrings\\u201d of bytes\\nand chars. Pr\", \"eviously, given a call like str.IndexOf(\\\"hello\\\"), the implementation would essentially\\ndo the equiva\", \"lent of repeatedly searching for the \\u2018h\\u2019, and when an \\u2018h\\u2019 was found, then performing a\\nSequenceEqual\", \" to match the remainder. As you can imagine, however, it\\u2019s very easy to run into cases\\nwhere the fir\", \"st character being searched for is very common, such that you frequently have to break\\nout of the ve\", \"ctorized loop in order to do the full string comparison. Instead, the PR implements an\\nalgorithm bas\", \"ed on SIMD-friendly algorithms for substring searching. Rather than just searching for\\nthe first cha\", \"racter, it can instead vectorize a search for both the first and last character at appropriate\\ndista\", \"nces from each other. In our \\u201chello\\u201d example, in any given input, it\\u2019s much more likely to find an\\n1\", \"03 CHAPTER 10 | Arrays, Strings, and Spans\\u2018h\\u2019 than it is to find an \\u2018h\\u2019 followed four characters lat\", \"er by an \\u2018o\\u2019, and thus this implementation is able\\nto stay within the vectorized loop a lot longer, \", \"garnering many fewer false positives that force it down\\nthe SequenceEqual route. The implementation \", \"also handles cases where the two characters selected\\nare equal, in which case it\\u2019ll quickly look for\", \" another character that\\u2019s not equal in order to maximize\\nthe efficiency of the search. We can see th\", \"e impact of all of this with a couple of examples:\\nprivate static readonly string s_haystack = new\\nH\", \"ttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\n[A\", \"rguments(\\\"Sherlock\\\")]\\n[Arguments(\\\"elementary\\\")]\\npublic int Count(string needle)\\n{\\nReadOnlySpan<char>\", \" haystack = s_haystack;\\nint count = 0, pos;\\nwhile ((pos = haystack.IndexOf(needle)) >= 0)\\n{\\nhaystack\", \" = haystack.Slice(pos + needle.Length);\\ncount++;\\n}\\nreturn count;\\n}\\nThis is pulling down the text to \", \"\\u201cThe Adventures of Sherlock Holmes\\u201d from Project Gutenberg and\\nthen benchmarking using IndexOf to co\", \"unt the occurrences of \\u201cSherlock\\u201d and \\u201celementary\\u201d in the\\ntext. On my machine, I get results like th\", \"is:\\nMethod Runtime needle Mean Ratio\\nCount .NET 6.0 Sherlock 43.68 us 1.00\\nCount .NET 7.0 Sherlock 4\", \"8.33 us 1.11\\nCount .NET 6.0 elementary 1,063.67 us 1.00\\nCount .NET 7.0 elementary 56.04 us 0.05\\nFor \", \"\\u201cSherlock\\u201d, the performance is actually a bit worse in .NET 7 than in .NET 6; not much, but a\\nmeasur\", \"able 10%. That\\u2019s because there are very few capital 'S' characters in the source text, 841 to be\\nexa\", \"ct, out of 593,836 characters in the document. At only 0.1% density of the starting character, the\\nn\", \"ew algorithm doesn\\u2019t bring much benefit, as the existing algorithm that searched for the first\\nchara\", \"cter alone captures pretty much all of the possible vectorization gains to be had, and we do pay\\na b\", \"it of overhead in doing a search for both the 'S' and the 'k', whereas previously we\\u2019d have only\\nsea\", \"rched for the 'S'. In contrast, though, there are 54,614 'e' characters in the document, so almost\\n1\", \"0% of the source. In that case, .NET 7 is 20x faster than .NET 6, taking 53us on .NET 7 to count all\", \" the\\n'e'\\u2019s vs 1084us on .NET 6. In this case, the new scheme yields immense gains, by vectorizing a \", \"search\\nfor both the 'e' and a 'y' at the specific distance away, a combination that is much, much le\", \"ss\\nfrequent. This is one of those situations where overall there are on average huge observed gains \", \"even\\nthough we can see small regressions for some specific inputs.\\n104 CHAPTER 10 | Arrays, Strings,\", \" and SpansAnother example of significantly changing the algorithm employed is dotnet/runtime#67758, \", \"which\\nenables some amount of vectorization to be applied to IndexOf(\\\"...\\\",\\nStringComparison.OrdinalI\", \"gnoreCase). Previously, this operation was implemented with a fairly\\ntypical substring search, walki\", \"ng the input string and at every location doing an inner loop to\\ncompare the target string, except p\", \"erforming a ToUpper on every character in order to do it in a case-\\ninsensitive manner. Now with thi\", \"s PR, which is based on approaches previously used by Regex, if the\\ntarget string begins with an ASC\", \"II character, the implementation can use IndexOf (if the character isn\\u2019t\\nan ASCII letter) or IndexOf\", \"Any (if the character is an ASCII letter) to quickly jump ahead to the first\\npossible location of a \", \"match. Let\\u2019s take the exact same benchmark as we just looked at, but tweaked\\nto use OrdinalIgnoreCas\", \"e:\\nprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenber\", \"g.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\n[Arguments(\\\"Sherlock\\\")]\\n[Arguments(\\\"elementary\\\")]\\n\", \"public int Count(string needle)\\n{\\nReadOnlySpan<char> haystack = s_haystack;\\nint count = 0, pos;\\nwhil\", \"e ((pos = haystack.IndexOf(needle, StringComparison.OrdinalIgnoreCase)) >= 0)\\n{\\nhaystack = haystack.\", \"Slice(pos + needle.Length);\\ncount++;\\n}\\nreturn count;\\n}\\nHere, both words are about 4x faster on .NET \", \"7 than they were on .NET 6:\\nMethod Runtime needle Mean Ratio\\nCount .NET 6.0 Sherlock 2,113.1 us 1.00\", \"\\nCount .NET 7.0 Sherlock 467.3 us 0.22\\nCount .NET 6.0 elementary 2,325.6 us 1.00\\nCount .NET 7.0 elem\", \"entary 638.8 us 0.27\\nas we\\u2019re now doing a vectorized IndexOfAny('S', 's') or IndexOfAny('E', 'e') ra\", \"ther than\\nmanually walking each character and comparing it. (dotnet/runtime#73533 uses the same appr\", \"oach\\nnow for handling IndexOf(char, StringComparison.OrdinalIgnoreCase).)\\nAnother example comes from\", \" dotnet/runtime#67492 from [@gfoidl](https://github.com/gfoidl). It\\nupdates MemoryExtensions.Contain\", \"s with the approach we discussed earlier for handling the\\nleftover elements at the end of vectorized\", \" operation: process one last vector\\u2019s worth of data, even if it\\nmeans duplicating some work already \", \"done. This particularly helps for smaller inputs where the\\nprocessing time might otherwise be domina\", \"ted by the serial handling of those leftovers.\\nprivate byte[] _data = new byte[95];\\n105 CHAPTER 10 |\", \" Arrays, Strings, and Spans[Benchmark]\\npublic bool Contains() => _data.AsSpan().Contains((byte)1);\\nM\", \"ethod Runtime Mean Ratio\\nContains .NET 6.0 15.115 ns 1.00\\nContains .NET 7.0 2.557 ns 0.17\\ndotnet/run\", \"time#60974 from [@alexcovington](https://github.com/alexcovington) broadens the\\nimpact of IndexOf. P\", \"rior to this PR, IndexOf was vectorized for one and two-byte sized primitive\\ntypes, but this PR exte\", \"nds it as well to four and eight-byte sized primitives. As with most of the other\\nvectorized impleme\", \"ntations, it checks whether the T is bitwise-equatable, which is important for the\\nvectorization as \", \"it\\u2019s only looking at the bits in memory and not paying attention to any Equals\\nimplementation that m\", \"ight be defined on the type. In practice today, that means this is limited to just\\na handful of type\", \"s of which the runtime has intimate knowledge (Boolean, Byte, SByte, UInt16, Int16,\\nChar, UInt32, In\", \"t32, UInt64, Int64, UIntPtr, IntPtr, Rune, and enums), but in theory it could be\\nextended in the fut\", \"ure.\\nprivate int[] _data = new int[1000];\\n[Benchmark]\\npublic int IndexOf() => _data.AsSpan().IndexOf\", \"(42);\\nMethod Runtime Mean Ratio\\nIndexOf .NET 6.0 252.17 ns 1.00\\nIndexOf .NET 7.0 78.82 ns 0.31\\nOne f\", \"inal interesting IndexOf-related optimization. string has long had\\nIndexOf/IndexOfAny/LastIndexOf/La\", \"stIndexOfAny, and obviously for string it\\u2019s all about\\nprocessing chars. When ReadOnlySpan<T> and Spa\", \"n<T> came on the scene, MemoryExtensions was\\nadded to provide extension methods for spans and friend\", \"s, including such\\nIndexOf/IndexOfAny/LastIndexOf/LastIndexOfAny methods. But for spans, this is abou\", \"t more than\\njust char, and so MemoryExtensions grew its own set of implementations largely separate \", \"from\\nstring\\u2019s. Over the years, MemoryExtensions implementations have specialized more and more types\", \",\\nbut in particular byte and char, such that over time string\\u2019s implementations have mostly been\\nrep\", \"laced by delegation into the same implementation as MemoryExtensions uses. However,\\nIndexOfAny and L\", \"astIndexOfAny had been unification holdouts, each in its own direction.\\nstring.IndexOfAny did delega\", \"te to the same implementation as MemoryExtensions.IndexOfAny for\\n1-5 values being searched for, but \", \"for more than 5 values, string.IndexOfAny used a \\u201cprobabilistic\\nmap,\\u201d essentially a Bloom filter. It\", \" creates a 256-bit table, and quickly sets bits in that table based on\\nthe values being searched for\", \" (essentially hashing them, but with a trivial hash function). Then it\\niterates through the input, a\", \"nd rather than checking every input character against every one of the\\ntarget values, it instead fir\", \"st looks up the input character in the table. If the corresponding bit isn\\u2019t set,\\nit knows the input\", \" character doesn\\u2019t match any of the target values. If the corresponding bit is set,\\nthen it proceeds\", \" to compare the input character against each of the target values, with a high\\nprobability of it bei\", \"ng one of them. MemoryExtensions.IndexOfAny lacked such a filter for more than\\n5 values. Conversely,\", \" string.LastIndexOfAny didn\\u2019t provide any vectorization for multiple target\\nvalues, whereas MemoryEx\", \"tensions.LastIndexOfAny vectorized two and three target values. As of\\n106 CHAPTER 10 | Arrays, Strin\", \"gs, and Spansdotnet/runtime#63817, all of these are now unified, such that both string and MemoryExt\", \"ensions\\nget the best of what the other had.\\nprivate readonly char[] s_target = new[] { 'z', 'q' };\\nc\", \"onst string Sonnet = \\\"\\\"\\\"\\nShall I compare thee to a summer's day?\\nThou art more lovely and more tempe\", \"rate:\\nRough winds do shake the darling buds of May,\\nAnd summer's lease hath all too short a date;\\nSo\", \"metime too hot the eye of heaven shines,\\nAnd often is his gold complexion dimm'd;\\nAnd every fair fro\", \"m fair sometime declines,\\nBy chance or nature's changing course untrimm'd;\\nBut thy eternal summer sh\", \"all not fade,\\nNor lose possession of that fair thou ow'st;\\nNor shall death brag thou wander'st in hi\", \"s shade,\\nWhen in eternal lines to time thou grow'st:\\nSo long as men can breathe or eyes can see,\\nSo \", \"long lives this, and this gives life to thee.\\n\\\"\\\"\\\";\\n[Benchmark]\\npublic int LastIndexOfAny() => Sonnet\", \".LastIndexOfAny(s_target);\\n[Benchmark]\\npublic int CountLines()\\n{\\nint count = 0;\\nforeach (ReadOnlySpa\", \"n<char> _ in Sonnet.AsSpan().EnumerateLines())\\n{\\ncount++;\\n}\\nreturn count;\\n}\\nMethod Runtime Mean Rati\", \"o\\nLastIndexOfAny .NET 6.0 443.29 ns 1.00\\nLastIndexOfAny .NET 7.0 31.79 ns 0.07\\nCountLines .NET 6.0 1\", \",689.66 ns 1.00\\nCountLines .NET 7.0 1,461.64 ns 0.86\\nThat same PR also cleans up uses of the IndexOf\", \" family, and in particular around uses that are\\nchecking for containment rather than the actual inde\", \"x of a result. The IndexOf family of methods\\nreturn a non-negative value when an element is found, a\", \"nd otherwise return -1. That means when\\nchecking whether an element was found, code can use either >\", \"= 0 or != -1, and when checking\\nwhether an element wasn\\u2019t found, code can use either < 0 or == -1. I\", \"t turns out that the code\\ngenerated for comparisons against 0 is ever so slightly more efficient tha\", \"n comparisons generated\\nagainst -1, and this isn\\u2019t something the JIT can itself substitute without t\", \"he IndexOf methods being\\nintrinsics such that the JIT can understand the semantics of the return val\", \"ue. Thus, for consistency and\\na small perf gain, all relevant call sites were switched to compare ag\", \"ainst 0 instead of against -1.\\n107 CHAPTER 10 | Arrays, Strings, and SpansSpeaking of call sites, on\", \"e of the great things about having highly optimized IndexOf methods is\\nusing them in all the places \", \"that can benefit, removing the maintenance impact of open-coded\\nreplacements while also reaping the \", \"perf wins. dotnet/runtime#63913 used IndexOf inside of\\nStringBuilder.Replace to speed up the search \", \"for the next character to be replaced:\\nprivate StringBuilder _builder = new StringBuilder(Sonnet);\\n[\", \"Benchmark]\\npublic void Replace()\\n{\\n_builder.Replace('?', '!');\\n_builder.Replace('!', '?');\\n}\\nMethod \", \"Runtime Mean Ratio\\nReplace .NET 6.0 1,563.69 ns 1.00\\nReplace .NET 7.0 70.84 ns 0.04\\ndotnet/runtime#6\", \"0463 from [@nietras](https://github.com/nietras) used IndexOfAny in\\nStringReader.ReadLine to search \", \"for '\\\\r' and '\\\\n' line ending characters, which results in some\\nsubstantial throughput gains even wi\", \"th the allocation and copy that is inherent to the method\\u2019s\\ndesign:\\n[Benchmark]\\npublic void ReadAllL\", \"ines()\\n{\\nvar reader = new StringReader(Sonnet);\\nwhile (reader.ReadLine() != null) ;\\n}\\nMethod Runtime\", \" Mean Ratio\\nReadAllLines .NET 6.0 947.8 ns 1.00\\nReadAllLines .NET 7.0 385.7 ns 0.41\\nAnd dotnet/runti\", \"me#70176 cleaned up a plethora of additional uses.\\nFinally on the IndexOf front, as noted, a lot of \", \"time and energy over the years has gone into\\noptimizing these methods. In previous releases, some of\", \" that energy has been in the form of using\\nhardware intrinsics directly, e.g. having an SSE2 code pa\", \"th and an AVX2 code path and an AdvSimd\\ncode path. Now that we have Vector128<T> and Vector256<T>, m\", \"any such uses can be simplified\\n(e.g. avoiding the duplication between an SSE2 implementation and an\", \" AdvSimd implementation)\\nwhile still maintaining as good or even better performance and while automa\", \"tically supporting\\nvectorization on other platforms with their own intrinsics, like WebAssembly. dot\", \"net/runtime#73481,\\ndotnet/runtime#73556, dotnet/runtime#73368, dotnet/runtime#73364, dotnet/runtime#\", \"73064, and\\ndotnet/runtime#73469 all contributed here, in some cases incurring meaningful throughput \", \"gains:\\n[Benchmark]\\npublic int IndexOfAny() => Sonnet.AsSpan().IndexOfAny(\\\"!.<>\\\");\\n108 CHAPTER 10 | A\", \"rrays, Strings, and SpansMethod Runtime Mean Ratio\\nIndexOfAny .NET 6.0 52.29 ns 1.00\\nIndexOfAny .NET\", \" 7.0 40.17 ns 0.77\\nThe IndexOf family is just one of many on string/MemoryExtensions that has seen d\", \"ramatic\\nimprovements. Another are the SequenceEquals family, including Equals, StartsWith, and EndsW\", \"ith.\\nOne of my favorite changes in the whole release is dotnet/runtime#65288 and is squarely in this\", \" area.\\nIt\\u2019s very common to see calls to methods like StartsWith with a constant string argument, e.g\", \".\\nvalue.StartsWith(\\\"https://\\\"), value.SequenceEquals(\\\"Key\\\"), etc. These methods are now\\nrecognized b\", \"y the JIT, which can now automatically unroll the comparison and compare more than\\none char at a tim\", \"e, e.g. doing a single read of four chars as a long and a single comparison of that\\nlong against the\", \" expected combination of those four chars. The result is beautiful. Making it even\\nbetter is dotnet/\", \"runtime#66095, which adds to this support for OrdinalIgnoreCase. Remember those\\nASCII bit twiddling \", \"tricks discussed a bit earlier with char.IsAsciiLetter and friends? The JIT now\\nemploys the same tri\", \"ck as part of this unrolling, so if you do that same\\nvalue.StartsWith(\\\"https://\\\") but instead as val\", \"ue.StartsWith(\\\"https://\\\",\\nStringComparison.OrdinalIgnoreCase), it will recognize that the whole comp\", \"arison string is ASCII\\nand will OR in the appropriate mask on both the comparison constant and on th\", \"e read data from the\\ninput in order to perform the comparison in a case-insensitive manner.\\nprivate \", \"string _value = \\\"https://dot.net\\\";\\n[Benchmark]\\npublic bool IsHttps_Ordinal() => _value.StartsWith(\\\"h\", \"ttps://\\\", StringComparison.Ordinal);\\n[Benchmark]\\npublic bool IsHttps_OrdinalIgnoreCase() => _value.S\", \"tartsWith(\\\"https://\\\",\\nStringComparison.OrdinalIgnoreCase);\\nMethod Runtime Mean Ratio\\nIsHttps_Ordinal\", \" .NET 6.0 4.5634 ns 1.00\\nIsHttps_Ordinal .NET 7.0 0.4873 ns 0.11\\nIsHttps_OrdinalIgnoreCase .NET 6.0 \", \"6.5654 ns 1.00\\nIsHttps_OrdinalIgnoreCase .NET 7.0 0.5577 ns 0.08\\nInterestingly, since .NET 5 the cod\", \"e generated by RegexOptions.Compiled would perform similar\\nunrolling when comparing sequences of mul\", \"tiple characters, and when the source generator was\\nadded in .NET 7, it also learned how to do this.\", \" However, the source generator has problems with such\\nan optimization, due to endianness. The consta\", \"nts being compared against are subject to byte\\nordering issues, such that the source generator would\", \" need to emit code that could handle running\\non either little-endian or big-endian machines. The JIT\", \" has no such problem, as it\\u2019s generating the\\ncode on the same machine on which the code will execute\", \" (and in scenarios where it\\u2019s being used to\\ngenerate code ahead of time, the entirety of that code i\", \"s already tied to a particular architecture). By\\nmoving this optimization into the JIT, the correspo\", \"nding code could be deleted from\\nRegexOptions.Compiled and the regex source generator, which then al\", \"so benefits from producing\\n109 CHAPTER 10 | Arrays, Strings, and Spansmuch easier to read code utili\", \"zing StartsWith that\\u2019s just as fast (dotnet/runtime#65222 and\\ndotnet/runtime#66339). Wins all around\", \". (This could only be removed from RegexOptions.Compiled\\nafter dotnet/runtime#68055, which fixed the\", \" ability for the JIT to recognize these string literals in\\nDynamicMethods, which RegexOptions.Compil\", \"ed uses with reflection emit to spit out the IL for the\\nregex being compiled.)\\nStartsWith and EndsWi\", \"th have improved in other ways. dotnet/runtime#63734 (improved further by\\ndotnet/runtime#64530) adde\", \"d another really interesting JIT-based optimization, but to understand it,\\nwe need to understand str\", \"ing\\u2019s internal layout. string is essentially represented in memory as an\\nint length followed by that\", \" many chars plus a null terminator char. The actual System.String class\\nrepresents this in C# as an \", \"int _stringLength field followed by a char _firstChar field, such that\\n_firstChar indeed lines up wi\", \"th the first character of the string, or the null terminator if the string is\\nempty. Internally in S\", \"ystem.Private.CoreLib, and in particular in methods on string itself, code will\\noften refer to _firs\", \"tChar directly when the first character needs to be consulted, as it\\u2019s typically faster\\nto do that t\", \"han to use str[0], in particular because there are no bounds checks involved and the\\nstring\\u2019s length\", \" generally needn\\u2019t be consulted. Now, consider a method like public bool\\nStartsWith(char value) on s\", \"tring. In .NET 6, the implementation was:\\nreturn Length != 0 && _firstChar == value;\\nwhich given wha\", \"t I just described makes sense: if the Length is 0, then the string doesn\\u2019t begin with\\nthe specified\", \" character, and if Length is not 0, then we can just compare the value against\\n_firstChar. But, why \", \"is that Length check even needed at all? Couldn\\u2019t we just do return\\n_firstChar == value;? That will \", \"avoid the additional comparison and branch, and it will work just\\nfine\\u2026 unless the target character \", \"is itself '\\\\0', in which case we could get false positives on the result.\\nNow to this PR. The PR int\", \"roduces an internal JIT intrinsinc RuntimeHelpers.IsKnownConstant, which\\nthe JIT will substitute wit\", \"h true if the containing method is inlined and the argument passed to\\nIsKnownConstant is then seen t\", \"o be a constant. In such cases, the implementation can rely on other\\nJIT optimizations kicking in an\", \"d optimizing various code in the method, effectively enabling a\\ndeveloper to write two different imp\", \"lementations, one when the argument is known to be a constant\\nand one when not. With that in hand, t\", \"he PR is able to optimize StartsWith as follows:\\npublic bool StartsWith(char value)\\n{\\nif (RuntimeHel\", \"pers.IsKnownConstant(value) && value != '\\\\0')\\nreturn _firstChar == value;\\nreturn Length != 0 && _fir\", \"stChar == value;\\n}\\nIf the value parameter isn\\u2019t a constant, then IsKnownConstant will be substituted\", \" with false, the\\nentire starting if block will be eliminated, and the method will be left exactly wa\", \"s it was before. But, if\\nthis method gets inlined and the value was actually a constant, then the va\", \"lue != '\\\\0' condition will\\nalso be evaluatable at JIT-compile-time. If the value is in fact '\\\\0', we\", \"ll, again that whole if block will\\nbe eliminated and we\\u2019re no worse off. But in the common case wher\", \"e the value isn\\u2019t null, the entire\\nmethod will end up being compiled as if it were:\\nreturn _firstCha\", \"r == ConstantValue;\\n110 CHAPTER 10 | Arrays, Strings, and Spansand we\\u2019ve saved ourselves a read of t\", \"he string\\u2019s length, a comparison, and a branch.\\ndotnet/runtime#69038 then employs a similar techniqu\", \"e for EndsWith.\\nprivate string _value = \\\"https://dot.net\\\";\\n[Benchmark]\\npublic bool StartsWith() =>\\n_\", \"value.StartsWith('a') ||\\n_value.StartsWith('b') ||\\n_value.StartsWith('c') ||\\n_value.StartsWith('d') \", \"||\\n_value.StartsWith('e') ||\\n_value.StartsWith('f') ||\\n_value.StartsWith('g') ||\\n_value.StartsWith('\", \"i') ||\\n_value.StartsWith('j') ||\\n_value.StartsWith('k') ||\\n_value.StartsWith('l') ||\\n_value.StartsWi\", \"th('m') ||\\n_value.StartsWith('n') ||\\n_value.StartsWith('o') ||\\n_value.StartsWith('p');\\nMethod Runtim\", \"e Mean Ratio\\nStartsWith .NET 6.0 8.130 ns 1.00\\nStartsWith .NET 7.0 1.653 ns 0.20\\n(Another example of\", \" IsKnownConstant being used comes from dotnet/runtime#64016, which uses it\\nto improve Math.Round whe\", \"n a MidpointRounding mode is specified. Call sites to this almost always\\nexplicitly specify the enum\", \" value as a constant, which then allows the JIT to specialize the code\\ngeneration for the method to \", \"the specific mode being used; that in turn, for example, enables a\\nMath.Round(..., MidpointRounding.\", \"AwayFromZero) call on Arm64 to be lowered to a single frinta\\ninstruction.)\\nEndsWith was also improve\", \"d in dotnet/runtime#72750, and specifically for when\\nStringComparison.OrdinalIgnoreCase is specified\", \". This simple PR just switched which internal\\nhelper method was used to implement this method, takin\", \"g advantage of one that is sufficient for the\\nneeds of this method and that has lower overheads.\\n[Be\", \"nchmark]\\n[Arguments(\\\"System.Private.CoreLib.dll\\\", \\\".DLL\\\")]\\npublic bool EndsWith(string haystack, str\", \"ing needle) =>\\nhaystack.EndsWith(needle, StringComparison.OrdinalIgnoreCase);\\nMethod Runtime Mean Ra\", \"tio\\nEndsWith .NET 6.0 10.861 ns 1.00\\nEndsWith .NET 7.0 5.385 ns 0.50\\nFinally, dotnet/runtime#67202 a\", \"nd dotnet/runtime#73475 employ Vector128<T> and Vector256<T>\\nto replace direct hardware intrinsics u\", \"sage, just as was previously shown for various IndexOf methods,\\nbut here for SequenceEqual and Seque\", \"nceCompareTo, respectively.\\n111 CHAPTER 10 | Arrays, Strings, and SpansAnother method that\\u2019s seem so\", \"me attention in .NET 7 is MemoryExtensions.Reverse (and\\nArray.Reverse as it shares the same implemen\", \"tation), which performs an in-place reversal of the\\ntarget span. dotnet/runtime#64412 from [@alexcov\", \"ington](https://github.com/alexcovington)\\nprovides a vectorized implementation via direct use of AVX\", \"2 and SSSE3 hardware intrinsics, with\\ndotnet/runtime#72780 from [@SwapnilGaikwad](https://github.com\", \"/SwapnilGaikwad) following up to\\nadd an AdvSimd intrinsics implementation for Arm64. (There was an u\", \"nintended regression\\nintroduced by the original vectorization change, but that was fixed by dotnet/r\", \"untime#70650.)\\nprivate char[] text = \\\"Free. Cross-platform. Open source.\\\\r\\\\nA developer platform for\", \"\\nbuilding all your apps.\\\".ToCharArray();\\n[Benchmark]\\npublic void Reverse() => Array.Reverse(text);\\nM\", \"ethod Runtime Mean Ratio\\nReverse .NET 6.0 21.352 ns 1.00\\nReverse .NET 7.0 9.536 ns 0.45\\nString.Split\", \" also saw vectorization improvements in dotnet/runtime#64899 from\\n[@yesmey](https://github.com/yesme\", \"y). As with some of the previously discussed PRs, it switched the\\nexisting usage of SSE2 and SSSE3 h\", \"ardware intrinsics over to the new Vector128<T> helpers, which\\nimproved upon the existing implementa\", \"tion while also implicitly adding vectorization support for\\nArm64.\\nConverting various formats of str\", \"ings is something many applications and services do, whether that\\u2019s\\nconverting from UTF8 bytes to an\", \"d from string or formatting and parsing hex values. Such\\noperations have also improved in a variety \", \"of ways in .NET 7. Base64-encoding, for example, is a way\\nof representing arbitrary binary data (thi\", \"nk byte[]) across mediums that only support text, encoding\\nbytes into one of 64 different ASCII char\", \"acters. Multiple APIs in .NET implement this encoding. For\\nconverting between binary data represente\", \"d as ReadOnlySpan<byte> and UTF8 (actually ASCII)\\nencoded data also represented as ReadOnlySpan<byte\", \">, the System.Buffers.Text.Base64 type\\nprovides EncodeToUtf8 and DecodeFromUtf8 methods. These were \", \"vectorized several releases ago,\\nbut they were further improved in .NET 7 via dotnet/runtime#70654 f\", \"rom\\n[@a74nh](https://github.com/a74nh), which converted the SSSE3-based implementation to use\\nVector\", \"128<T> (which in turn implicitly enabled vectorization on Arm64). However, for converting\\nbetween ar\", \"bitrary binary data represented as ReadOnlySpan<byte>/byte[] and\\nReadOnlySpan<char>/char[]/string, t\", \"he System.Convert type exposes multiple methods, e.g.\\nConvert.ToBase64String, and these methods hist\", \"orically were not vectorized. That changes in .NET\\n7, where dotnet/runtime#71795 and dotnet/runtime#\", \"73320 vectorize the ToBase64String,\\nToBase64CharArray, and TryToBase64Chars methods. The way they do\", \" this is interesting. Rather than\\neffectively duplicating the vectorization implementation from Base\", \"64.EncodeToUtf8, they instead\\nlayer on top of EncodeToUtf8, calling it to encode the input byte data\", \" into an output Span<byte>.\\nThen, then they \\u201cwiden\\u201d those bytes into chars (remember, Base64-encoded\", \" data is a set of ASCII\\nchars, so going from these bytes to chars entails adding just a 0 byte onto \", \"each element). That\\nwidening can itself easily be done in a vectorized manner. The other interesting\", \" thing about this\\nlayering is it doesn\\u2019t actually require separate intermediate storage for the enco\", \"ded bytes. The\\nimplementation can perfectly compute the number of resulting characters for encoding \", \"X bytes into Y\\n112 CHAPTER 10 | Arrays, Strings, and SpansBase64 characters (there\\u2019s a formula), and\", \" the implementation can either allocate that final space\\n(e.g. in the case of ToBase64CharArray) or \", \"ensure the provided space is sufficient (e.g. in the case of\\nTryToBase64Chars). And since we know th\", \"e initial encoding will require exactly half as many bytes, we\\ncan encode into that same space (with\", \" the destination span reinterpreted as a byte span rather than\\nchar span), and then widen \\u201cin place\\u201d\", \": walk from the end of the bytes and the end of the char space,\\ncopying the bytes into the destinati\", \"on.\\nprivate byte[] _data = Encoding.UTF8.GetBytes(\\\"\\\"\\\"\\nShall I compare thee to a summer's day?\\nThou a\", \"rt more lovely and more temperate:\\nRough winds do shake the darling buds of May,\\nAnd summer's lease \", \"hath all too short a date;\\nSometime too hot the eye of heaven shines,\\nAnd often is his gold complexi\", \"on dimm'd;\\nAnd every fair from fair sometime declines,\\nBy chance or nature's changing course untrimm\", \"'d;\\nBut thy eternal summer shall not fade,\\nNor lose possession of that fair thou ow'st;\\nNor shall de\", \"ath brag thou wander'st in his shade,\\nWhen in eternal lines to time thou grow'st:\\nSo long as men can\", \" breathe or eyes can see,\\nSo long lives this, and this gives life to thee.\\n\\\"\\\"\\\");\\nprivate char[] _enc\", \"oded = new char[1000];\\n[Benchmark]\\npublic bool TryToBase64Chars() => Convert.TryToBase64Chars(_data,\", \" _encoded, out _);\\nMethod Runtime Mean Ratio\\nTryToBase64Chars .NET 6.0 623.25 ns 1.00\\nTryToBase64Cha\", \"rs .NET 7.0 81.82 ns 0.13\\nJust as widening can be used to go from bytes to chars, narrowing can be u\", \"sed to go from chars to\\nbytes, in particular if the chars are actually ASCII and thus have a 0 upper\", \" byte. Such narrowing can be\\nvectorized, and the internal NarrowUtf16ToAscii utility helper does exa\", \"ctly that, used as part of\\nmethods like Encoding.ASCII.GetBytes. While this method was previously ve\", \"ctorized, its primary\\nfast-path utilized SSE2 and thus didn\\u2019t apply to Arm64; thanks to dotnet/runti\", \"me#70080 from\\n[@SwapnilGaikwad](https://github.com/SwapnilGaikwad), that path was changed over to be\", \" based on\\nthe cross-platform Vector128<T>, enabling the same level of optimization across supported\\n\", \"platforms. Similarly, dotnet/runtime#71637 from\\n[@SwapnilGaikwad](https://github.com/SwapnilGaikwad)\", \" adds Arm64 vectorization to the\\nGetIndexOfFirstNonAsciiChar internal helper that\\u2019s used by methods \", \"like\\nEncoding.UTF8.GetByteCount. (And in the same vein, dotnet/runtime#67192 changed the internal\\nHe\", \"xConverter.EncodeToUtf16 method from using SSSE3 intrinsics to instead use Vector128<T>,\\nautomatical\", \"ly providing an Arm64 implementation.)\\nEncoding.UTF8 was also improved a bit. In particular, dotnet/\", \"runtime#69910 streamlined the\\nimplementations of GetMaxByteCount and GetMaxCharCount, making them sm\", \"all enough to be\\ncommonly inlined when used directly off of Encoding.UTF8 such that the JIT is able \", \"to devirtualize the\\ncalls.\\n113 CHAPTER 10 | Arrays, Strings, and Spans[Benchmark]\\npublic int GetMaxB\", \"yteCount() => Encoding.UTF8.GetMaxByteCount(Sonnet.Length);\\nMethod Runtime Mean Ratio\\nGetMaxByteCoun\", \"t .NET 6.0 1.7442 ns 1.00\\nGetMaxByteCount .NET 7.0 0.4746 ns 0.27\\nArguably the biggest improvement a\", \"round UTF8 in .NET 7 is the new C# 11 support for UTF8 literals.\\nInitially implemented in the C# com\", \"piler in dotnet/roslyn#58991, with follow-on work in\\ndotnet/roslyn#59390, dotnet/roslyn#61532, and d\", \"otnet/roslyn#62044, UTF8 literals enables the\\ncompiler to perform the UTF8 encoding into bytes at co\", \"mpile-time. Rather than writing a normal\\nstring, e.g. \\\"hello\\\", a developer simply appends the new u8\", \" suffix onto the string literal, e.g.\\n\\\"hello\\\"u8. At that point, this is no longer a string. Rather, \", \"the natural type of this expression is a\\nReadOnlySpan<byte>. If you write:\\npublic static ReadOnlySpa\", \"n<byte> Text => \\\"hello\\\"u8;\\nthe C# compiler will compile that equivalent to if you wrote:\\npublic stat\", \"ic ReadOnlySpan<byte> Text =>\\nnew ReadOnlySpan<byte>(new byte[] { (byte)'h', (byte)'e', (byte)'l', (\", \"byte)'l',\\n(byte)'o', (byte)'\\\\0' }, 0, 5);\\nIn other words, the compiler is doing the equivalent of En\", \"coding.UTF8.GetBytes at compile-time and\\nhardcoding the resulting bytes, saving the cost of performi\", \"ng that encoding at run-time. Of course, at\\nfirst glance, that array allocation might look terribly \", \"inefficient. However, looks can be deceiving, and\\nare in this case. For several releases now, when t\", \"he C# compiler sees a byte[] (or sbyte[] or bool[])\\nbeing initialized with a constant length and con\", \"stant values and immediately cast to or used to\\nconstruct a ReadOnlySpan<byte>, it optimizes away th\", \"e byte[] allocation. Instead, it blits the data for\\nthat span into the assembly\\u2019s data section, and \", \"then constructs a span that points directly to that data\\nin the loaded assembly. This is the actual \", \"generated IL for the above property:\\nIL_0000: ldsflda valuetype '<PrivateImplementationDetails>'/'__\", \"StaticArrayInitTypeSize=6'\\n'<PrivateImplementationDetails>'::F3AEFE62965A91903610F0E23CC8A69D5B87CEA\", \"6D28E75489B0D2CA02\\nED7993C\\nIL_0005: ldc.i4.5\\nIL_0006: newobj instance void valuetype\\n[System.Runtime\", \"]System.ReadOnlySpan`1<uint8>::.ctor(void*, int32)\\nIL_000b: ret\\nThis means we not only save on the e\", \"ncoding costs at run-time, and we not only avoid whatever\\nmanaged allocations might be required to s\", \"tore the resulting data, we also benefit from the JIT being\\nable to see information about the encode\", \"d data, like it\\u2019s length, enabling knock-on optimizations. You\\ncan see this clearly by examining the\", \" assembly generated for a method like:\\npublic static int M() => Text.Length;\\nfor which the JIT produ\", \"ces:\\n; Program.M()\\nmov eax,5\\n114 CHAPTER 10 | Arrays, Strings, and Spansret\\n; Total bytes of code 6\\n\", \"The JIT inlines the property access, sees that the span is being constructed with a length of 5, and\", \" so\\nrather than emitting any array allocations or span constructions or anything even resembling tha\", \"t, it\\nsimply outputs mov eax, 5 to return the known length of the span.\\nThanks primarily to dotnet/r\", \"untime#70568, dotnet/runtime#69995, dotnet/runtime#70894,\\ndotnet/runtime#71417 from [@am11](https://\", \"github.com/am11), dotnet/runtime#71292,\\ndotnet/runtime#70513, and dotnet/runtime#71992, u8 is now us\", \"ed more than 2100 times throughout\\ndotnet/runtime. Hardly a fair comparison, but the following bench\", \"mark demonstrates how little work\\nis actually being performed for u8 at execution time:\\n[Benchmark(B\", \"aseline = true)]\\npublic ReadOnlySpan<byte> WithEncoding() => Encoding.UTF8.GetBytes(\\\"test\\\");\\n[Benchm\", \"ark]\\npublic ReadOnlySpan<byte> Withu8() => \\\"test\\\"u8;\\nMethod Mean Ratio Allocated Alloc Ratio\\nWithEnc\", \"oding 17.3347 ns 1.000 32 B 1.00\\nWithu8 0.0060 ns 0.000 - 0.00\\nLike I said, not fair, but it proves \", \"the point :)\\nEncoding is of course just one mechanism for creating string instances. Others have als\", \"o improved in\\n.NET 7. Take the super common long.ToString, for example. Previous releases improved\\ni\", \"nt.ToString, but there were enough differences between the 32-bit and 64-bit algorithms that long\\ndi\", \"dn\\u2019t see all of the same gains. Now thanks to dotnet/runtime#68795, the 64-bit formatting code\\npaths\", \" are made much more similar to the 32-bit, resulting in faster performance.\\nYou can also see improve\", \"ments in string.Format and StringBuilder.AppendFormat, as well as\\nother helpers that layer on top of\", \" these (like TextWriter.AppendFormat). dotnet/runtime#69757\\noverhauls the core routines inside Forma\", \"t to avoid unnecessary bounds checking, favor expected\\ncases, and generally clean up the implementat\", \"ion. It also, however, utilities IndexOfAny to search for\\nthe next interpolation hole that needs to \", \"be filled in, and if the non-hole-character to hole ratio is high\\n(e.g. long format string with few \", \"holes), it can be way faster than before.\\nprivate StringBuilder _sb = new StringBuilder();\\n[Benchmar\", \"k]\\npublic void AppendFormat()\\n{\\n_sb.Clear();\\n_sb.AppendFormat(\\\"There is already one outstanding '{0}\", \"' call for this WebSocket\\ninstance.\\\" +\\n\\\"ReceiveAsync and SendAsync can be called simultaneously, but\", \" at most\\none \\\" +\\n\\\"outstanding operation for each of them is allowed at the same time.\\\",\\n\\\"ReceiveAsyn\", \"c\\\");\\n}\\n115 CHAPTER 10 | Arrays, Strings, and SpansMethod Runtime Mean Ratio\\nAppendFormat .NET 6.0 33\", \"8.23 ns 1.00\\nAppendFormat .NET 7.0 49.15 ns 0.15\\nSpeaking of StringBuilder, it\\u2019s seen additional imp\", \"rovements beyond the aforementioned changes\\nto AppendFormat. One interesting change is dotnet/runtim\", \"e#64405, which achieved two related\\nthings. The first was to remove pinning as part of formatting op\", \"erations. As an example,\\nStringBuilder has an Append(char* value, int valueCount) overload which cop\", \"ies the specified\\nnumber of characters from the specified pointer into the StringBuilder, and other \", \"APIs were\\nimplemented in terms of this method; for example, the Append(string? value, int startIndex\", \",\\nint count) method was essentially implemented as:\\nfixed (char* ptr = value)\\n{\\nAppend(ptr + startIn\", \"dex, count);\\n}\\nThat fixed statement translates into a \\u201cpinning pointer.\\u201d Normally the GC is free to \", \"move managed\\nobjects around on the heap, which it might do in order to compact the heap (to, for exa\", \"mple, avoid\\nsmall, unusuable fragments of memory between objects). But if the GC can move objects ar\", \"ound, a\\nnormal native pointer into that memory would be terribly unsafe and unreliable, as without n\", \"otice the\\ndata being pointed to could move and your pointer could now be pointing to garbage or to s\", \"ome\\nother object that was shifted to this location. There are two ways for dealing with this. The fi\", \"rst is a\\n\\u201cmanaged pointer,\\u201d otherwise known as a \\u201creference\\u201d or \\u201cref,\\u201d as that\\u2019s exactly what you ge\", \"t when you\\nhave the \\u201cref\\u201d keyword in C#; it\\u2019s a pointer that the runtime will update with the correc\", \"t value when it\\nmoves the object being pointed into. The second is to prevent the pointed-to object \", \"from being\\nmoved, \\u201cpinning\\u201d it in place. And that\\u2019s what the \\u201cfixed\\u201d keyword does, pinning the refer\", \"enced object\\nfor the duration of the fixed block, during which time it\\u2019s safe to use the supplied po\", \"inter. Thankfully,\\npinning is cheap when no GC occurs; when a GC does occur, however, pinned objects\", \" aren\\u2019t able to be\\nmoved around, and thus pinning can have a global impact on the performance of the\", \" application (and\\non GCs themselves). There are also various optimizations inhibited by pinning. Wit\", \"h all of the advents\\nin C# around being able to use ref in many more places (e.g. ref locals, ref re\", \"turns, and now in C# 11,\\nref fields), and with all of the new APIs in .NET for manipulating refs (e.\", \"g. Unsafe.Add,\\nUnsafe.AreSame), it\\u2019s now possible to rewrite code that was using pinning pointers to\", \" instead use\\nmanaged pointers, thereby avoiding the problems that come from pinning. Which is what t\", \"his PR did.\\nRather than implementing all of the Append methods in terms of an Append(char*, int) hel\", \"per,\\nthey\\u2019re now all implemented in terms of an Append(ref char, int) helper. So for example instead\", \" of\\nthe previously shown Append(string? value, int startIndex, int count) implementation, it\\u2019s\\nnow a\", \"kin to\\nAppend(ref Unsafe.Add(ref value.GetRawStringData(), startIndex), count);\\nwhere that string.Ge\", \"tRawStringData method is just an internal version of the public\\nstring.GetPinnableReference method, \", \"returning a ref instead of a ref readonly. This means that\\nall of the high-performance code inside o\", \"f StringBuilder that had been using pointers to avoid\\nbounds checking and the like can continue to d\", \"o so, but now also does so without pinning all of the\\ninputs.\\n116 CHAPTER 10 | Arrays, Strings, and \", \"SpansThe second thing this StringBuilder change did was unify an optimization that was present for\\ns\", \"tring inputs to also apply to char[] inputs and ReadOnlySpan<char> inputs. Specifically, because\\nit\\u2019\", \"s so common to append string instances to a StringBuilder, a special code path was long ago\\nput in p\", \"lace to optimize for this input and specifically for the case where there\\u2019s already enough room\\nin t\", \"he StringBuilder to hold the whole input, at which point an efficient copy can be used. With a\\nshare\", \"d Append(ref char, int) helper, though, this optimization can be moved down into that\\nhelper, such t\", \"hat it not only helps out string but any other type that also calls into the same helper.\\nThe effect\", \"s of this are visible in a simple microbenchmark:\\nprivate StringBuilder _sb = new StringBuilder();\\n[\", \"Benchmark]\\npublic void AppendSpan()\\n{\\n_sb.Clear();\\n_sb.Append(\\\"this\\\".AsSpan());\\n_sb.Append(\\\"is\\\".AsSp\", \"an());\\n_sb.Append(\\\"a\\\".AsSpan());\\n_sb.Append(\\\"test\\\".AsSpan());\\n_sb.Append(\\\".\\\".AsSpan());\\n}\\nMethod Run\", \"time Mean Ratio\\nAppendSpan .NET 6.0 35.98 ns 1.00\\nAppendSpan .NET 7.0 17.59 ns 0.49\\nOne of the great\", \" things about improving things low in the stack is they have a multiplicative effect;\\nthey not only \", \"help improve the performance of user code that directly relies on the improved\\nfunctionality, they c\", \"an also help improve the performance of other code in the core libraries, which\\nthen further helps d\", \"ependent apps and services. You can see this, for example, with\\nDateTimeOffset.ToString, which depen\", \"ds on StringBuilder:\\nprivate DateTimeOffset _dto = DateTimeOffset.UtcNow;\\n[Benchmark]\\npublic string \", \"DateTimeOffsetToString() => _dto.ToString();\\nMethod Runtime Mean Ratio\\nDateTimeOffsetToString .NET 6\", \".0 340.4 ns 1.00\\nDateTimeOffsetToString .NET 7.0 289.4 ns 0.85\\nStringBuilder itself was then further\", \" updated by dotnet/runtime#64922 from [@teo-\\ntsirpanis](https://github.com/teo-tsirpanis), which imp\", \"roves the Insert methods. It used to be that\\nthe Append(primitive) methods on StringBuilder (e.g. Ap\", \"pend(int)) would call ToString on the\\nvalue and then append the resulting string. With the advent of\", \" ISpanFormattable, as a fast-path\\nthose methods now try to format the value directly into the String\", \"Builder\\u2019s internal buffer, and only\\nif there\\u2019s not enough room remaining do they then take the old p\", \"ath as a fallback. Insert wasn\\u2019t\\nimproved in this way at the time, because it can\\u2019t just format into\", \" the space at the end of the builder;\\nthe insert location could be anywhere in the builder. This PR \", \"addresses that by formatting into some\\ntemporary stack space, and then delegating to the existing in\", \"ternal ref-based helper from the\\n117 CHAPTER 10 | Arrays, Strings, and Spanspreviously discussed PR \", \"to insert the resulting characters at the right location (it also falls back to\\nToString when there\\u2019\", \"s not enough stack space for the ISpanFormattable.TryFormat, but that only\\nhappens in incredibly cor\", \"ner cases, like a floating-point value that formats to hundreds of digits).\\nprivate StringBuilder _s\", \"b = new StringBuilder();\\n[Benchmark]\\npublic void Insert()\\n{\\n_sb.Clear();\\n_sb.Insert(0, 12345);\\n}\\nMet\", \"hod Runtime Mean Ratio Allocated Alloc Ratio\\nInsert .NET 6.0 30.02 ns 1.00 32 B 1.00\\nInsert .NET 7.0\", \" 25.53 ns 0.85 - 0.00\\nOther minor improvements to StringBuilder have also been made, like dotnet/run\", \"time#60406 which\\nremoved a small int[] allocation from the Replace method. Even with all these impro\", \"vements,\\nthough, the fastest use of StringBuilder is no use; dotnet/runtime#68768 removed a bunch of\", \" uses\\nof StringBuilder that would have been better served with other string-creation mechanisms. For\", \"\\nexample, the legacy DataView type had some code that created a sorting specification as a string:\\np\", \"rivate static string CreateSortString(PropertyDescriptor property, ListSortDirection\\ndirection)\\n{\\nva\", \"r resultString = new StringBuilder();\\nresultString.Append('[');\\nresultString.Append(property.Name);\\n\", \"resultString.Append(']');\\nif (ListSortDirection.Descending == direction)\\n{\\nresultString.Append(\\\" DES\", \"C\\\");\\n}\\nreturn resultString.ToString();\\n}\\nWe don\\u2019t actually need the StringBuilder here, as in the wo\", \"rst-case we\\u2019re just concatenating three\\nstrings, and string.Concat has a dedicated overload for that\", \" exact operation that has the best\\npossible implementation for that operation (and if we ever found \", \"a better way, that method would be\\nimproved according). So we can just use that:\\nprivate static stri\", \"ng CreateSortString(PropertyDescriptor property, ListSortDirection\\ndirection) =>\\ndirection == ListSo\", \"rtDirection.Descending ?\\n$\\\"[{property.Name}] DESC\\\" :\\n$\\\"[{property.Name}]\\\";\\nNote that I\\u2019ve expressed \", \"that concatenation via an interpolated string, but the C# compiler will \\u201clower\\u201d\\nthis interpolated st\", \"ring to a call to string.Concat, so the IL for this is indistinguishable from if I\\u2019d\\ninstead written\", \":\\nprivate static string CreateSortString(PropertyDescriptor property, ListSortDirection\\ndirection) =\", \">\\n118 CHAPTER 10 | Arrays, Strings, and Spansdirection == ListSortDirection.Descending ?\\nstring.Conc\", \"at(\\\"[\\\", property.Name, \\\"] DESC\\\") :\\nstring.Concat(\\\"[\\\", property.Name, \\\"]\\\");\\nAs an aside, the expanded\", \" string.Concat version highlights that this method could have been\\nwritten to result in a bit less I\", \"L if it were instead written as:\\nprivate static string CreateSortString(PropertyDescriptor property,\", \" ListSortDirection\\ndirection) =>\\nstring.Concat(\\\"[\\\", property.Name, direction == ListSortDirection.De\", \"scending ? \\\"] DESC\\\"\\n: \\\"]\\\");\\nbut this doesn\\u2019t meaningfully affect performance and here clarity and ma\", \"intainability was more\\nimportant than shaving off a few bytes.\\n[Benchmark(Baseline = true)]\\n[Argumen\", \"ts(\\\"SomeProperty\\\", ListSortDirection.Descending)]\\npublic string WithStringBuilder(string name, ListS\", \"ortDirection direction)\\n{\\nvar resultString = new StringBuilder();\\nresultString.Append('[');\\nresultSt\", \"ring.Append(name);\\nresultString.Append(']');\\nif (ListSortDirection.Descending == direction)\\n{\\nresult\", \"String.Append(\\\" DESC\\\");\\n}\\nreturn resultString.ToString();\\n}\\n[Benchmark]\\n[Arguments(\\\"SomeProperty\\\", L\", \"istSortDirection.Descending)]\\npublic string WithConcat(string name, ListSortDirection direction) =>\\n\", \"direction == ListSortDirection.Descending?\\n$\\\"[{name}] DESC\\\" :\\n$\\\"[{name}]\\\";\\nMethod Mean Ratio Allocat\", \"ed Alloc Ratio\\nWithStringBuilder 68.34 ns 1.00 272 B 1.00\\nWithConcat 20.78 ns 0.31 64 B 0.24\\nThere a\", \"re also places where StringBuilder was still applicable, but it was being used on hot-enough\\npaths t\", \"hat previous releases of .NET saw the StringBuilder instance being cached. Several of the\\ncore libra\", \"ries, including System.Private.CoreLib, have an internal StringBuilderCache type which\\ncaches a Stri\", \"ngBuilder instance in a [ThreadStatic], meaning every thread could end up having\\nsuch an instance. T\", \"here are several issues with this, including that the buffers employed by\\nStringBuilder aren\\u2019t usabl\", \"e for anything else while the StringBuilder isn\\u2019t in use, and because of\\nthat, StringBuilderCache pl\", \"aces a limit on the capacity of the StringBuilder instances that can be\\ncached; attempts to cache on\", \"es longer than that result in them being thrown away. It\\u2019d be better\\ninstead to use cached arrays th\", \"at aren\\u2019t length-limited and that everyone has access to for sharing.\\nMany of the core .NET librarie\", \"s have an internal ValueStringBuilder type for this purpose, a ref\\nstruct-based type that can use st\", \"ackalloc\\u2019d memory to start and then if necessary grow into\\nArrayPool<char> arrays. And with dotnet/r\", \"untime#64522 and dotnet/runtime#69683, many of the\\n119 CHAPTER 10 | Arrays, Strings, and Spansremain\", \"ing uses of StringBuilderCache have been replaced. I\\u2019m hopeful we can entirely remove\\nStringBuilderC\", \"ache in the future.\\nIn the same vein of not doing unnecessary work, there\\u2019s a fairly common pattern \", \"that shows up with\\nmethods like string.Substring and span.Slice:\\nspan = span.Slice(offset, str.Lengt\", \"h - offset);\\nThe relevant thing to recognize here is these methods have overloads that take just the\", \" starting offset.\\nSince the length being specified is the remainder after the specified offset, the \", \"call could instead be\\nsimplified to:\\nspan = span.Slice(offset);\\nwhich is not only more readable and \", \"maintainable, it has some small efficiency benefits, e.g. on 64-bit\\nthe Slice(int, int) constructor \", \"has an extra addition over Slice(int), and for 32-bit the\\nSlice(int, int) constructor incurs an addi\", \"tional comparison and branch. It\\u2019s thus beneficial for both\\ncode maintenance and for performance to \", \"simplify these calls, which dotnet/runtime#68937 does for\\nall found occurrences of that pattern. Thi\", \"s is then made more impactful by dotnet/runtime#73882,\\nwhich streamlines string.Substring to remove \", \"unnecessary overheads, e.g. it condenses four\\nargument validation checks down to a single fast-path \", \"comparison (in 64-bit processes).\\nOk, enough about string. What about spans? One of the coolest feat\", \"ures in C# 11 is the new support\\nfor ref fields. What is a ref field? You\\u2019re familiar with refs in C\", \"# in general, and we\\u2019ve already\\ndiscussed how they\\u2019re essentially managed pointers, i.e. pointers th\", \"at the runtime can update at any\\ntime due to the object it references getting moved on the heap. The\", \"se references can point to the\\nbeginning of an object, or they can point somewhere inside the object\", \", in which case they\\u2019re referred\\nto as \\u201cinterior pointers.\\u201d ref has existed in C# since 1.0, but at \", \"that time it was primarily about passing\\nby reference to method calls, e.g.\\nclass Data\\n{\\npublic int \", \"Value;\\n}\\n...\\nvoid Add(ref int i)\\n{\\ni++;\\n}\\n...\\nvar d = new Data { Value = 42 };\\nAdd(ref d.Value);\\nDeb\", \"ug.Assert(d.Value == 43);\\nLater versions of C# added the ability to have local refs, e.g.\\nvoid Add(r\", \"ef int i)\\n{\\nref j = ref i;\\nj++;\\n}\\nand even to have ref returns, e.g.\\n120 CHAPTER 10 | Arrays, String\", \"s, and Spansref int Add(ref int i)\\n{\\nref j = ref i;\\nj++;\\nreturn ref j;\\n}\\nThese facilities are more a\", \"dvanced, but they\\u2019re used liberally throughout higher-performance code\\nbases, and many of the optimi\", \"zations in .NET in recent years are possible in large part due to these\\nref-related capabilities.\\nSp\", \"an<T> and ReadOnlySpan<T> themselves are heavily-based on refs. For example, the indexer on\\nmany old\", \"er collection types is implemented as a get/set property, e.g.\\nprivate T[] _items;\\n...\\npublic T this\", \"[int i]\\n{\\nget => _items[i];\\nset => _items[i] = value;\\n}\\nBut not span. Span<T>\\u2019s indexer looks more l\", \"ike this:\\npublic ref T this[int index]\\n{\\nget\\n{\\nif ((uint)index >= (uint)_length)\\nThrowHelper.ThrowIn\", \"dexOutOfRangeException();\\nreturn ref Unsafe.Add(ref _reference, index);\\n}\\n}\\nNote there\\u2019s only a gett\", \"er and no setter; that\\u2019s because it returns a ref T to the actual storage\\nlocation. It\\u2019s a writable \", \"ref, so you can assign to it, e.g. you can write:\\nspan[i] = value;\\nbut rather than that being equiva\", \"lent to calling some setter:\\nspan.set_Item(i, value);\\nit\\u2019s actually equivalent to using the getter t\", \"o retrieve the ref and then writing a value through that\\nref, e.g.\\nref T item = ref span.get_Item(i)\", \";\\nitem = value;\\nThat\\u2019s all well and good, but what\\u2019s that _reference in the getter definition? Well,\", \" Span<T> is really\\njust a tuple of two fields: a reference (to the start of the memory being referre\", \"d to) and a length (how\\nmany elements from that reference are included in the span). In the past, th\", \"e runtime had to hack this\\nwith an internal type (ByReference<T>) specially recognized by the runtim\", \"e to be a reference. But as\\nof C# 11 and .NET 7, ref structs can now contain ref fields, which means\", \" Span<T> today is literally\\ndefined as follows:\\n121 CHAPTER 10 | Arrays, Strings, and Spanspublic re\", \"adonly ref struct Span<T>\\n{\\ninternal readonly ref T _reference;\\nprivate readonly int _length;\\n...\\n}\\n\", \"The rollout of ref fields throughout dotnet/runtime was done in dotnet/runtime#71498, following the\\n\", \"C# language gaining this support primarily in dotnet/roslyn#62155, which itself was the culmination\\n\", \"of many PRs first into a feature branch. ref fields alone doesn\\u2019t itself automatically improve\\nperfo\", \"rmance, but it does simplify code significantly, and it allows for both new custom code that uses\\nre\", \"f fields as well as new APIs that take advantage of them, both of which can help with performance\\n(a\", \"nd specifically performance without sacrificing potential safety). One such example of a new API is\\n\", \"new constructors on ReadOnlySpan<T> and Span<T>:\\npublic Span(ref T reference);\\npublic ReadOnlySpan(i\", \"n T reference);\\nadded in dotnet/runtime#67447 (and then made public and used more broadly in\\ndotnet/\", \"runtime#71589). This may beg the question, why does ref field support enable two new\\nconstructors th\", \"at take refs, considering spans already were able to store a ref? After all, the\\nMemoryMarshal.Creat\", \"eSpan(ref T reference, int length) and corresponding\\nCreateReadOnlySpan methods have existed for as \", \"long as spans have, and these new constructors are\\nequivalent to calling those methods with a length\", \" of 1. The answer is: safety.\\nImagine if you could willy-nilly call this constructor. You\\u2019d be able \", \"to write code like this:\\npublic Span<int> RuhRoh()\\n{\\nint i = 42;\\nreturn new Span<int>(ref i);\\n}\\nAt t\", \"his point the caller of this method is handed a span that refers to garbage; that\\u2019s bad in code\\nthat\", \"\\u2019s intended to be safe. You can already accomplish the same thing by using pointers:\\npublic Span<int\", \"> RuhRoh()\\n{\\nunsafe\\n{\\nint i = 42;\\nreturn new Span<int>(&i, 1);\\n}\\n}\\nbut at that point you\\u2019ve taken on\", \" the risk of using unsafe code and pointers and any resulting\\nproblems are on you. With C# 11, if yo\", \"u now try to write the above code using the ref-based\\nconstructor, you\\u2019ll be greeted with an error l\", \"ike this:\\nerror CS8347: Cannot use a result of 'Span<int>.Span(ref int)' in this context because it\\n\", \"may expose variables referenced by parameter 'reference' outside of their declaration scope\\nIn other\", \" words, the compiler now understands that Span<int> as a ref struct could be storing the\\npassed in r\", \"ef, and if it does store it (which Span<T> does), this is akin to passing a ref to a local out\\n122 C\", \"HAPTER 10 | Arrays, Strings, and Spansof the method, which is bad. Hence how this relates to ref fie\", \"lds: because ref fields are now a thing,\\nthe compiler\\u2019s rules for safe-handling of refs have been up\", \"dated, which in turn enables us to expose\\nthe aforementioned constructors on {ReadOnly}Span<T>.\\nAs i\", \"s often the case, addressing one issue kicks the can down the road a bit and exposes another. The\\nco\", \"mpiler now believes that a ref passed to a method on a ref struct could enable that ref struct\\ninsta\", \"nce to store the ref (note that this was already the case with ref structs passed to methods on\\nref \", \"structs), but what if we don\\u2019t want that? What if we want to be able to say \\u201cthis ref is not\\nstorabl\", \"e and should not escape the calling scope\\u201d? From a caller\\u2019s perspective, we want the compiler\\nto all\", \"ow passing in such refs without it complaining about potential extension of lifetime, and from a\\ncal\", \"lee\\u2019s perspective, we want the compiler to prevent the method from doing what it\\u2019s not supposed\\nto d\", \"o. Enter scoped. The new C# keyword does exactly what we just wished for: put it on a ref or ref\\nstr\", \"uct parameter, and the compiler both will guarantee (short of using unsafe code) that the method\\ncan\", \"\\u2019t stash away the argument and will then enable the caller to write code that relies on that\\nguarant\", \"ee. For example, consider this program:\\nvar writer = new SpanWriter(stackalloc char[128]);\\nAppend(re\", \"f writer, 123);\\nwriter.Write(\\\".\\\");\\nAppend(ref writer, 45);\\nConsole.WriteLine(writer.AsSpan().ToStrin\", \"g());\\nstatic void Append(ref SpanWriter builder, byte value)\\n{\\nSpan<char> tmp = stackalloc char[3];\\n\", \"value.TryFormat(tmp, out int charsWritten);\\nbuilder.Write(tmp.Slice(0, charsWritten));\\n}\\nref struct \", \"SpanWriter\\n{\\nprivate readonly Span<char> _chars;\\nprivate int _length;\\npublic SpanWriter(Span<char> d\", \"estination) => _chars = destination;\\npublic Span<char> AsSpan() => _chars.Slice(0, _length);\\npublic \", \"void Write(ReadOnlySpan<char> value)\\n{\\nif (_length > _chars.Length - value.Length)\\n{\\nthrow new Inval\", \"idOperationException(\\\"Not enough remaining space\\\");\\n}\\nvalue.CopyTo(_chars.Slice(_length));\\n_length +\", \"= value.Length;\\n}\\n}\\nWe have a ref struct SpanWriter that takes a Span<char> to its constructor and a\", \"llows for writing\\nto it by copying in additional content and then updating the stored length. The Wr\", \"ite method accepts\\na ReadOnlySpan<char>. And we then have a helper Append method which is formatting\", \" a byte into\\nsome stackalloc\\u2019d temporary space and passing the resulting formatted chars in to Write\", \".\\nStraightforward. Except, this doesn\\u2019t compile:\\n123 CHAPTER 10 | Arrays, Strings, and Spanserror CS\", \"8350: This combination of arguments to 'SpanWriter.Write(ReadOnlySpan<char>)' is\\ndisallowed because \", \"it may expose variables referenced by parameter 'value' outside of their\\ndeclaration scope\\nWhat do w\", \"e do? The Write method doesn\\u2019t actually store the value parameter and won\\u2019t ever need\\nto, so we can \", \"change the signature of the method to annotate it as scoped:\\npublic void Write(scoped ReadOnlySpan<c\", \"har> value)\\nIf Write were then to try to store value, the compiler would balk:\\nerror CS8352: Cannot \", \"use variable 'ReadOnlySpan<char>' in this context because it may\\nexpose referenced variables outside\", \" of their declaration scope\\nBut as it\\u2019s not trying to do so, everything now compiles successfully. Y\", \"ou can see examples of how this\\nis utilized in the aforementioned dotnet/runtime#71589.\\nThere\\u2019s also\", \" the other direction: there are some things that are implicitly scoped, like the this\\nreference on a\", \" struct. Consider this code:\\npublic struct SingleItemList\\n{\\nprivate int _value;\\npublic ref int this[\", \"int i]\\n{\\nget\\n{\\nif (i != 0) throw new IndexOutOfRangeException();\\nreturn ref _value;\\n}\\n}\\n}\\nThis produ\", \"ces a compiler error:\\nerror CS8170: Struct members cannot return 'this' or other instance members by\", \" reference\\nEffectively, that\\u2019s because this is implicitly scoped (even though that keyword wasn\\u2019t pr\", \"eviously\\navailable). What if we want to enable such an item to be returned? Enter [UnscopedRef]. Thi\", \"s is rare\\nenough in need that it doesn\\u2019t get its own C# language keyword, but the C# compiler does r\", \"ecognize\\nthe new [UnscopedRef] attribute. It can be put onto relevant parameters but also onto metho\", \"ds and\\nproperties, in which case it applies to the this reference for that member. As such, we can m\", \"odify our\\nprevious code example to be:\\n[UnscopedRef]\\npublic ref int this[int i]\\nand now the code wil\", \"l compile successfully. Of course, this also places demands on callers of this\\nmethod. For a call si\", \"te, the compiler sees the [UnscopedRef] on the member being invoked, and then\\nknows that the returne\", \"d ref might reference something from that struct, and thus assigns to the\\nreturned ref the same life\", \"time as that struct. So, if that struct were a local living on the stack, the ref\\nwould also be limi\", \"ted to that same method.\\n124 CHAPTER 10 | Arrays, Strings, and SpansAnother impactful span-related c\", \"hange comes in dotnet/runtime#70095 from [@teo-\\ntsirpanis](https://github.com/teo-tsirpanis). System\", \".HashCode\\u2019s goal is to provide a fast, easy-to-use\\nimplementation for producing high-quality hash co\", \"des. In its current incarnation, it incorporates a\\nrandom process-wide seed and is an implementation\", \" of the xxHash32 non-cryptographic hash\\nalgorithm. In a previous release, HashCode saw the addition \", \"of an AddBytes methods, which accepts a\\nReadOnlySpan<byte> and is useful for incorporating sequences\", \" of data that should be part of a type\\u2019s\\nhash code, e.g. BigInteger.GetHashCode includes all the dat\", \"a that makes up the BigInteger. The\\nxxHash32 algorithm works by accumulating 4 32-bit unsigned integ\", \"ers and then combining them\\ntogether into the hash code; thus if you call HashCode.Add(int), the fir\", \"st three times you call it you\\u2019re\\njust storing the values separately into the instance, and then the\", \" fourth time you call it all of those\\nvalues are combined into the hash code (and there\\u2019s a separate\", \" process that incorporates any\\nremaining values if the number of 32-bit values added wasn\\u2019t an exact\", \" multiple of 4). Thus, previously\\nAddBytes was simply implemented to repeatedly read the next 4 byte\", \"s from the input span and call\\nAdd(int) with those bytes as an integer. But those Add calls have ove\", \"rhead. Instead, this PR skips the\\nAdd calls and directly handles the accumulation and combining of t\", \"he 16 bytes. Interestingly, it still has\\nto deal with the possibility that previous calls to Add may\", \" have left some state queued, which means\\n(with the current implementation at least), if there are m\", \"ultiple pieces of state to include in the hash\\ncode, say a ReadOnlySpan<byte> and an additional int,\", \" it\\u2019s more efficient to add the span first and\\nthen the int rather than the other way around. So for\", \" example when dotnet/runtime#71274 from\\n[@huoyaoyuan](https://github.com/huoyaoyuan) changed BigInte\", \"ger.GetHashCode to use\\nHashCode.AddBytes, it coded the method to first call AddBytes with the BigInt\", \"eger\\u2019s _bits and then\\ncall Add with the _sign.\\nprivate byte[] _data = Enumerable.Range(0, 256).Selec\", \"t(i => (byte)i).ToArray();\\n[Benchmark]\\npublic int AddBytes()\\n{\\nHashCode hc = default;\\nhc.AddBytes(_d\", \"ata);\\nreturn hc.ToHashCode();\\n}\\nMethod Runtime Mean Ratio\\nAddBytes .NET 6.0 159.11 ns 1.00\\nAddBytes \", \".NET 7.0 42.11 ns 0.26\\nAnother span-related change, dotnet/runtime#72727 refactored a bunch of code \", \"paths to eliminate\\nsome cached arrays. Why avoid cached arrays? After all, isn\\u2019t it desirable to cac\", \"he an array once and\\nreuse it over and over again? It is, if that\\u2019s the best option, but sometimes t\", \"here are better options. For\\nexample, one of the changes took code like:\\nprivate static readonly cha\", \"r[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' };\\n...\\nint index = value.IndexOfAny(s_pathDelims);\\nand\", \" replaced it with code like:\\nint index = value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\n125 CHAPTER 10 | Array\", \"s, Strings, and SpansThis has a variety of benefits. There\\u2019s the usability benefit of keeping the to\", \"kens being searched close\\nto the use site, and the usability benefit of the list being immutable suc\", \"h that some code somewhere\\nwon\\u2019t accidentally replace a value in the array. But there are also perfo\", \"rmance benefits. We don\\u2019t need\\nan extra field to store the array. We don\\u2019t need to allocate the arra\", \"y as part of this type\\u2019s static\\nconstructor. And loading/using the string is slightly faster.\\nprivat\", \"e static readonly char[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' };\\nprivate static readonly string\", \" s_value = \\\"abcdefghijklmnopqrstuvwxyz\\\";\\n[Benchmark]\\npublic int WithArray() => s_value.IndexOfAny(s_\", \"pathDelims);\\n[Benchmark]\\npublic int WithString() => s_value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\nMethod Me\", \"an Ratio\\nWithArray 8.601 ns 1.00\\nWithString 6.949 ns 0.81\\nAnother example from that PR took code alo\", \"ng the lines of:\\nprivate static readonly char[] s_whitespaces = new char[] { ' ', '\\\\t', '\\\\n', '\\\\r' }\", \";\\n...\\nswitch (attr.Value.Trim(s_whitespaces))\\n{\\ncase \\\"preserve\\\": return Preserve;\\ncase \\\"default\\\": re\", \"turn Default;\\n}\\nand replaced it with code like:\\nswitch (attr.Value.AsSpan().Trim(\\\" \\\\t\\\\n\\\\r\\\"))\\n{\\ncase \", \"\\\"preserve\\\": return Preserve;\\ncase \\\"default\\\": return Default;\\n}\\nIn this case, not only have we avoide\", \"d the char[], but if the text did require any trimming of\\nwhitespaces, the new version (which trims \", \"a span instead of the original string) will save an allocation\\nfor the trimmed string. This is takin\", \"g advantage of the new C# 11 feature that supports switching on\\nReadOnlySpan<char>s just as you can \", \"switch on strings, added in dotnet/roslyn#44388 from\\n[@YairHalberstadt](https://github.com/YairHalbe\", \"rstadt). dotnet/runtime#68831 also took advantage\\nof this in several additional places.\\nOf course, i\", \"n some cases the arrays are entirely unnecessary. In that same PR, there were several cases\\nlike thi\", \"s:\\nprivate static readonly char[] WhiteSpaceChecks = new char[] { ' ', '\\\\u00A0' };\\n...\\nint wsIndex =\", \" target.IndexOfAny(WhiteSpaceChecks, targetPosition);\\nif (wsIndex < 0)\\n{\\nreturn false;\\n}\\n126 CHAPTER\", \" 10 | Arrays, Strings, and SpansBy switching to use spans, again, we can instead write it like this:\", \"\\nint wsIndex = target.AsSpan(targetPosition).IndexOfAny(' ', '\\\\u00A0');\\nif (wsIndex < 0)\\n{\\nreturn fa\", \"lse;\\n}\\nwsIndex += targetPosition;\\nMemoryExtensions.IndexOfAny has a dedicated overload for two and t\", \"hree arguments, at which\\npoint we don\\u2019t need the array at all (these overloads also happen to be fas\", \"ter; when passing an array\\nof two chars, the implementation would extract the two chars from the arr\", \"ay and pass them off to the\\nsame two-argument implementation). Multiple other PRs similarly removed \", \"array allocations.\\ndotnet/runtime#60409 removed a single-char array that was cached to be able to pa\", \"ss it to\\nstring.Split and replaced it with usage of the Split overload that directly accepts a singl\", \"e char.\\nFinally, dotnet/runtime#59670 from [@NewellClark](https://github.com/NewellClark) got rid of\", \" even\\nmore arrays. We saw earlier how the C# compiler special-cases byte[]s constructed with a const\", \"ant\\nlength and constant elements and that\\u2019s immediately cast to a ReadOnlySpan<byte>. Thus, it can b\", \"e\\nbeneficial any time there\\u2019s such a byte[] being cached to instead expose it as a ReadOnlySpan<byte\", \">.\\nAs I discussed in the .NET 6 post, this avoids even the one-time array allocation you\\u2019d get for a\", \" cached\\narray, results in much more efficient access, and supplies to the JIT compiler more informat\", \"ion that\\nenables it to more heavily optimize\\u2026 goodness all around. This PR removed even more arrays \", \"in this\\nmanner, as did dotnet/runtime#60411, dotnet/runtime#72743, dotnet/runtime#73115 from\\n[@vcsjo\", \"nes](https://github.com/vcsjones), and dotnet/runtime#70665.\\n127 CHAPTER 10 | Arrays, Strings, and S\", \"pans11\\nCHAPTER\\nRegex\\nBack in May, I shared a fairly detailed post about the improvements coming to R\", \"egular Expressions in\\n.NET 7. As a recap, prior to .NET 5, Regex\\u2019s implementation had largely been u\", \"ntouched for quite\\nsome time. In .NET 5, we brought it back up to be on par with or better than mult\", \"iple other industry\\nimplementations from a performance perspective. .NET 7 takes some significant le\", \"aps forward from\\nthat. If you haven\\u2019t read the post yet, please go ahead and do so now; I\\u2019ll wait\\u2026\\nW\", \"elcome back. With that context, I\\u2019ll avoid duplicating content here, and instead focus on how exactl\", \"y\\nthese improvements came about and the PRs that did so.\\nRegexOptions.NonBacktracking\\nLet\\u2019s start wi\", \"th one of the larger new features in Regex, the new RegexOptions.NonBacktracking\\nimplementation. As \", \"discussed in the previous post, RegexOptions.NonBacktracking switches the\\nprocessing of Regex over t\", \"o using a new engine based in finite automata. It has two primary modes of\\nexecution, one that relie\", \"s on DFAs (deterministic finite automata) and one that relies on NFAs (non-\\ndeterministic finite aut\", \"omata). Both implementations provide a very valuable guarantee: processing\\ntime is linear in the len\", \"gth of the input. Whereas a backtracking engine (which is what Regex uses if\\nNonBacktracking isn\\u2019t s\", \"pecified) can hit a situation known as \\u201ccatastrophic backtracking,\\u201d where\\nproblematic expressions co\", \"mbined with problematic input can result in exponential processing in the\\nlength of the input, NonBa\", \"cktracking guarantees it\\u2019ll only ever do an ammortized-constant amount\\nof work per character in the \", \"input. In the case of a DFA, that constant is very small. With an NFA, that\\nconstant can be much lar\", \"ger, based on the complexity of the pattern, but for any given pattern the\\nwork is still linear in t\", \"he length of the input.\\nA significant number of years of development went into the NonBacktracking i\", \"mplementation, which\\nwas initially added into dotnet/runtime in dotnet/runtime#60607. However, the o\", \"riginal research and\\nimplementation for it actually came from Microsoft Research (MSR), and was avai\", \"lable as an\\nexperimental package in the form of the Symbolic Regex Matcher (SRM) library published b\", \"y MSR.\\nYou can still see vestiges of this in the current code now in .NET 7, but it\\u2019s evolved signif\", \"icantly, in\\ntight collaboration between developers on the .NET team and the researchers at MSR (prio\", \"r to being\\nintegrated in dotnet/runtime, it was incubated for over a year in dotnet/runtimelab, wher\", \"e the original\\nSRM code was brought in via dotnet/runtimelab#588 from [@veanes](https://github.com/v\", \"eanes)).\\nThis implementation is based on the notion of regular expression derivatives, a concept tha\", \"t\\u2019s been\\naround for decades (the term was originally coined in a paper by Janusz Brzozowski in the 1\", \"960s) and\\nwhich has been significantly advanced for this implementation. Regex derivatives form the \", \"basis for\\nhow the automata (think \\u201cgraph\\u201d) used to process input are constructed. The idea at its co\", \"re is fairly\\nsimple: take a regex and process a single character\\u2026 what is the new regex you get to d\", \"escribe what\\nremains after processing that one character? That\\u2019s the derivative. For example, given \", \"the regex \\\\w{3}\\n128 CHAPTER 11 | Regexto match three word characters, if you apply this to the next \", \"input character \\u2018a\\u2019, well, that will strip off\\nthe first \\\\w, leaving us with the derivative \\\\w{2}. S\", \"imple, right? How about something more\\ncomplicated, like the expression .*(the|he). What happens if \", \"the next character is a t? Well, it\\u2019s\\npossible that t could be consumed by the .* at the beginning o\", \"f the pattern, in which case the\\nremaining regex would be exactly the same as the starting one (.*(t\", \"he|he)), since after matching t\\nwe could still match exactly the same input as without the t. But, t\", \"he t could have also been part of\\nmatching the, and applied to the, we\\u2019d strip off the t and be left\", \" with he, so now our derivative is\\n.*(the|he)|he. Then what about the he in the original alternation\", \"? t doesn\\u2019t match h, so the\\nderivative would be nothing, which we\\u2019ll express here as an empty charac\", \"ter class, giving us\\n.*(the|he)|he|[]. Of course, as part of an alternation, that \\u201cnothing\\u201d at the e\", \"nd is a nop, and so we\\ncan simplify the whole derivative to just .*(the|he)|he\\u2026 done. That was all w\", \"hen applying the\\noriginal pattern against a next t. What if it was against an h instead? Following t\", \"he same logic as for\\nthe t, this time we end up with .*(the|he)|e. And so on. What if we instead sta\", \"rt with the h\\nderivative and the next character is an e? Then we\\u2019re taking the pattern .*(the|he)|e \", \"and applying it\\nto e. Against the left side of the alternation, it can be consumed by the .* (but do\", \"esn\\u2019t match either t\\nor h), and so we just end up with that same subexpression. But against the righ\", \"t side of the\\nalternation, e matches e, leaving us with the empty string (): .*(the|he)|(). At the p\", \"oint where a\\npattern is \\u201cnullable\\u201d (it can match the empty string), that can be considered a match. \", \"We can visualize\\nthis whole thing as a graph, with transitions for every input character to the deri\", \"vative that comes\\nfrom applying it.\\n129 CHAPTER 11 | Regex130 CHAPTER 11 | RegexLooks an awful lot l\", \"ike a DFA, doesn\\u2019t it? It should. And that\\u2019s exactly how NonBacktracking\\nconstructs the DFAs it uses\", \" to process input. For every regex construct (concatenations, alternations,\\nloops, etc.) the engine \", \"knows how to derive the next regex based on the character being evaluated.\\nThis application is done \", \"lazily, so we have an initial starting state (the original pattern), and then when\\nwe evaluate the n\", \"ext character in the input, it looks to see whether there\\u2019s already a derivative\\navailable for that \", \"transition: if there is, it follows it, and if there isn\\u2019t, it dynamically/lazily derives the\\nnext n\", \"ode in the graph. At its core, that\\u2019s how it works.\\nOf course, the devil is in the details and there\", \"\\u2019s a ton of complication and engineering smarts that go\\ninto making the engine efficient. One such e\", \"xample is a tradeoff between memory consumption and\\nthroughput. Given the ability to have any char a\", \"s input, you could have effectively ~65K transitions\\nout of every node (e.g. every node could need a\", \" ~65K element table); that would significantly increase\\nmemory consumption. However, if you actually\", \" had that many transitions, it\\u2019s very likely a significant\\nmajority of them would point to the same \", \"target node. Thus, NonBacktracking maintains its own\\ngroupings of characters into what it calls \\u201cmin\", \"terms.\\u201d If two characters will have exactly the same\\ntransition, they\\u2019re part of the same minterm. T\", \"he transitions are then constructed in terms of\\nminterms, with at most one transition per minterm ou\", \"t of a given node. When the next input character\\nis read, it maps that to a minterm ID, and then fin\", \"ds the appropriate transition for that ID; one\\nadditional level of indirection in order to save a po\", \"tentially huge amount of memory. That mapping is\\nhandled via an array bitmap for ASCII and an effici\", \"ent data structure known as a Binary Decision\\nDiagram (BDD) for everything above 0x7F.\\nAs noted, the\", \" non-backtracking engine is linear in the length of the input. But that doesn\\u2019t mean it\\nalways looks\", \" at each input character exactly once. If you call Regex.IsMatch, it does; after all, IsMatch\\nonly n\", \"eeds to determine whether there is a match and doesn\\u2019t need to compute any additional\\ninformation, s\", \"uch as where the match actual starts or ends, any information on captures, etc. Thus, the\\nengine can\", \" simply employ its automata to walk along the input, transitioning from node to node in\\nthe graph un\", \"til it comes to a final state or runs out of input. Other operations, however, do require it\\nto gath\", \"er more information. Regex.Match needs to compute everything, and that can actually entail\\nmultiple \", \"walks over the input. In the initial implementation, the equivalent of Match would always take\\nthree\", \" passes: match forwards to find the end of a match, then match a reversed-copy of the pattern in\\nrev\", \"erse from that ending location in order to find where the match actually starts, and then once more\\n\", \"walk forwards from that known starting position to find the actual ending position. However, with\\ndo\", \"tnet/runtime#68199 from [@olsaarik](https://github.com/olsaarik), unless captures are required, it\\nc\", \"an now be done in only two passes: once forward to find the guaranteed ending location of the\\nmatch,\", \" and then once in reverse to find its starting location. And dotnet/runtime#65129 from\\n[@olsaarik](h\", \"ttps://github.com/olsaarik) added captures support, which the original implementation\\nalso didn\\u2019t ha\", \"ve. This captures support adds back a third pass, such that once the bounds of the\\nmatch are known, \", \"the engine runs the forward pass one more time, but this time with an NFA-based\\n\\u201csimulation\\u201d that is\", \" able to record \\u201ccapture effects\\u201d on transitions. All of this enables the non-\\nbacktracking implemen\", \"tation to have the exact same semantics as the backtracking engines, always\\nproducing the same match\", \"es in the same order with the same capture information. The only\\ndifference in this regard is, where\", \"as with the backtracking engines capture groups inside of loops will\\nstore all values captured in ev\", \"ery iteration of the loop, only the last iteration is stored with the non-\\nbacktracking implementati\", \"on. On top of that, there are a few constructs the non-backtracking\\n131 CHAPTER 11 | Regeximplementa\", \"tion simply doesn\\u2019t support, such that attempting to use any of those will fail when trying\\nto const\", \"ruct the Regex, e.g. backreferences and lookarounds.\\nEven after its progress as a standalone library\", \" from MSR, more than 100 PRs went into making\\nRegexOptions.NonBacktracking what it is now in .NET 7,\", \" including optimizations like\\ndotnet/runtime#70217 from [@olsaarik](https://github.com/olsaarik) tha\", \"t tries to streamline the tight\\ninner matching loop at the heart of the DFA (e.g. read the next inpu\", \"t character, find the appropriate\\ntransition to take, move to the next node, and check information a\", \"bout the node like whether it\\u2019s a\\nfinal state) and optimizations like dotnet/runtime#65637 from [@ve\", \"anes](https://github.com/veanes)\\nthat optimized the NFA mode to avoid superfluous allocations, cachi\", \"ng and reusing list and set\\nobjects to make the handling of the lists of states ammortized allocatio\", \"n-free.\\nThere\\u2019s one more set of PRs of performance interest for NonBacktracking. The Regex implement\", \"ation\\nfor taking patterns and turning them into something processable, regardless of which of the mu\", \"ltiple\\nengines is being used, is essentially a compiler, and as with many compilers, it naturally le\", \"nds itself to\\nrecursive algorithms. In the case of Regex, those algorithms involve walking around tr\", \"ees of regular\\nexpression constructs. Recursion ends up being a very handy way of expressing these a\", \"lgorithms, but\\nrecursion also suffers from the possibility of stack overflow; essentially it\\u2019s using\", \" stack space as scratch\\nspace, and if it ends up using too much, things go badly. One common approac\", \"h to dealing with this\\nis turning the recursive algorithm into an iterative one, which typically inv\", \"olves using an explicit stack\\nof state rather than the implicit one. The nice thing about this is th\", \"e amount of state you can store is\\nlimited only by how much memory you have, as opposed to being lim\", \"ited by your thread\\u2019s stack\\nspace. The downsides, however, are that it\\u2019s typically much less natural\", \" to write the algorithms in this\\nmanner, and it typically requires allocating heap space for the sta\", \"ck, which then leads to additional\\ncomplications if you want to avoid that allocation, such as vario\", \"us kinds of pooling.\\ndotnet/runtime#60385 introduces a different approach for Regex, which is then u\", \"sed by\\ndotnet/runtime#60786 from [@olsaarik](https://github.com/olsaarik) specifically in the\\nNonBac\", \"ktracking implementation. It still uses recursion, and thus benefits from the expressiveness of\\nthe \", \"recursive algorithm as well as being able to use stack space and thus avoid additional allocation in\", \"\\nthe most common cases, but then to avoid stack overflows, it issues explicit checks to ensure we\\u2019re\", \"\\nnot too deep on the stack (.NET has long provided the helpers\\nRuntimeHelpers.EnsureSufficientExecut\", \"ionStack and\\nRuntimeHelpers.TryEnsureSufficientExecutionStack for this purpose). If it detects it\\u2019s \", \"too deep\\non the stack, it forks off continued execution into another thread. Hitting this condition \", \"is expensive,\\nbut it\\u2019s very rarely if ever actually hit in practice (e.g. the only time it\\u2019s hit in \", \"our vast functional tests\\nare in the tests explicitly written to stress it), it keeps the code simpl\", \"e, and it keeps the typical cases\\nfast. A similar approach is used in other areas of dotnet/runtime,\", \" such as in System.Linq.Expressions.\\nAs was mentioned in my previous blog post about regular express\", \"ions, both the backtracking\\nimplementations and the non-backtracking implementation have their place\", \". The main benefit of the\\nnon-backtracking implementation is predictability: because of the linear p\", \"rocessing guarantee, once\\nyou\\u2019ve constructed the regex, you don\\u2019t need to worry about malicious inpu\", \"ts causing worst-case\\nbehavior in the processing of your potentially susceptible expressions. This d\", \"oesn\\u2019t mean\\nRegexOptions.NonBacktracking is always the fastest; in fact, it\\u2019s frequently not. In exc\", \"hange for\\nreduced best-case performance, it provides the best worst-case performance, and for some k\", \"inds of\\napplications, that\\u2019s a really worthwhile and valuable tradeoff.\\n132 CHAPTER 11 | RegexNew AP\", \"Is\\nRegex gets several new methods in .NET 7, all of which enable improved performance. The simplicit\", \"y\\nof the new APIs likely also misrepresents how much work was necessary to enable them, in particula\", \"r\\nbecause the new APIs all support ReadOnlySpan<char> inputs into the regex engines.\\ndotnet/runtime#\", \"65473 brings Regex into the span-based era of .NET, overcoming a significant\\nlimitation in Regex sin\", \"ce spans were introduced back in .NET Core 2.1. Regex has historically been\\nbased on processing Syst\", \"em.String inputs, and that fact pervades the Regex design and\\nimplementation, including the APIs exp\", \"osed for the extensibility model Regex.CompileToAssembly\\nrelied on in .NET Framework (CompileToAssem\", \"bly is now obsoleted and has never been functional in\\n.NET Core). One subtly that relies on the natu\", \"re of string as the input is how match information is\\nreturned to callers. Regex.Match returns a Mat\", \"ch object that represents the first match in the input,\\nand that Match object exposes a NextMatch me\", \"thod that enables moving to the next match. That\\nmeans the Match object needs to store a reference t\", \"o the input, so that it can be fed back into the\\nmatching engine as part of such a NextMatch call. I\", \"f that input is a string, great, no problem. But if\\nthat input is a ReadOnlySpan<char>, that span as\", \" a ref struct can\\u2019t be stored on the class Match\\nobject, since ref structs can only live on the stac\", \"k and not the heap. That alone would make it a\\nchallenge to support spans, but the problem is even m\", \"ore deeply rooted. All of the regex engines rely\\non a RegexRunner, a base class that stores on it al\", \"l of the state necessary to feed into the\\nFindFirstChar and Go methods that compose the actual match\", \"ing logic for the regular expressions\\n(these methods contain all of the core code for performing the\", \" match, with FindFirstChar being an\\noptimization to skip past input positions that couldn\\u2019t possibly\", \" start a match and then Go performing\\nthe actual matching logic). If you look at the internal RegexI\", \"nterpreter type, which is the engine you\\nget when you construct a new Regex(...) without the RegexOp\", \"tions.Compiled or\\nRegexOptions.NonBacktracking flags, it derives from RegexRunner. Similarly, when y\", \"ou use\\nRegexOptions.Compiled, it hands off the dynamic methods it reflection emits to a type derived\", \" from\\nRegexRunner, RegexOptions.NonBacktracking has a SymbolicRegexRunnerFactory that produces\\ntypes\", \" derived from RegexRunner, and so on. Most relevant here, RegexRunner is public, because the\\ntypes g\", \"enerated by the Regex.CompileToAssembly type (and now the regex source generator) include\\nones deriv\", \"ed from this RegexRunner. Those FindFirstChar and Go methods are thus abstract and\\nprotected, and pa\", \"rameterless, because they pick up all the state they need from protected members\\non the base class. \", \"That includes the string input to process. So what about spans? We could of\\ncourse have just called \", \"ToString() on an input ReadOnlySpan<char>. That would have been\\nfunctionally correct, but would have\", \" completely defeated the purpose of accepting spans, and worse,\\nwould have been so unexpected as to \", \"likely cause consuming apps to be worse performing than they\\nwould have without the APIs. Instead, w\", \"e needed a new approach and new APIs.\\nFirst, we made FindFirstChar and Go virtual instead of abstrac\", \"t. The design that splits these methods\\nis largely antiquated, and in particular the forced separati\", \"on between a stage of processing where you\\nfind the next possible location of a match and then a sta\", \"ge where you actually perform the match at\\nthat location doesn\\u2019t align well with all engines, like t\", \"he one used by NonBacktracking (which initially\\nimplemented FindFirstChar as a nop and had all its l\", \"ogic in Go). Then we added a new virtual Scan\\nmethod which, importantly, takes a ReadOnlySpan<char> \", \"as a parameter; the span can\\u2019t be exposed\\nfrom the base RegexRunner and must be passed in. We then i\", \"mplemented FindFirstChar and Go in\\nterms of Scan, and made them \\u201cjust work.\\u201d Then, all of the engine\", \"s are implemented in terms of that\\n133 CHAPTER 11 | Regexspan; they no longer need to access the pro\", \"tected RegexRunner.runtext, RegexRunner.runtextbeg,\\nand RegexRunner.runtextend members that surface \", \"the input; they\\u2019re just handed the span, already\\nsliced to the input region, and process that. One o\", \"f the neat things about this from a performance\\nperspective is it enables the JIT to do a better job\", \" at shaving off various overheads, in particular\\naround bounds checking. When the logic is implement\", \"ed in terms of string, in addition to the input\\nstring itself the engine is also handed the beginnin\", \"g and end of the region of the input to process\\n(since the developer could have called a method like\", \" Regex.Match(string input, int beginning,\\nint length) in order to only process a substring). Obvious\", \"ly the engine matching logic is way more\\ncomplicated than this, but simplifying, imagine the entiret\", \"y of the engine was just a loop over the\\ninput. With the input, beginning, and length, that would lo\", \"ok like:\\n[Benchmark]\\n[Arguments(\\\"abc\\\", 0, 3)]\\npublic void Scan(string input, int beginning, int leng\", \"th)\\n{\\nfor (int i = beginning; i < length; i++)\\n{\\nCheck(input[i]);\\n}\\n}\\n[MethodImpl(MethodImplOptions.\", \"AggressiveInlining)]\\nprivate void Check(char c) { }\\nThat will result in the JIT generating assembly \", \"code along the lines of this:\\n; Program.Scan(System.String, Int32, Int32)\\nsub rsp,28\\ncmp r8d,r9d\\njge\", \" short M00_L01\\nmov eax,[rdx+8]\\nM00_L00:\\ncmp r8d,eax\\njae short M00_L02\\ninc r8d\\ncmp r8d,r9d\\njl short M\", \"00_L00\\nM00_L01:\\nadd rsp,28\\nret\\nM00_L02:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total bytes of code 36\\n\", \"In contrast, if we\\u2019re dealing with a span, which already factors in the bounds, then we can write a \", \"more\\ncanonical loop like this:\\n[Benchmark]\\n[Arguments(\\\"abc\\\")]\\npublic void Scan(ReadOnlySpan<char> in\", \"put)\\n{\\nfor (int i = 0; i < input.Length; i++)\\n{\\nCheck(input[i]);\\n}\\n}\\n134 CHAPTER 11 | Regex[MethodIm\", \"pl(MethodImplOptions.AggressiveInlining)]\\nprivate void Check(char c) { }\\nAnd when it comes to compil\", \"ers, something in a canonical form is really good, because the more\\ncommon the shape of the code, th\", \"e more likely it is to be heavily optimized:\\n; Program.Scan(System.ReadOnlySpan`1<Char>)\\nmov rax,[rd\", \"x]\\nmov edx,[rdx+8]\\nxor ecx,ecx\\ntest edx,edx\\njle short M00_L01\\nM00_L00:\\nmov r8d,ecx\\nmovsx r8,word ptr\", \" [rax+r8*2]\\ninc ecx\\ncmp ecx,edx\\njl short M00_L00\\nM00_L01:\\nret\\n; Total bytes of code 27\\nSo even witho\", \"ut all the other benefits that come from operating in terms of span, we immediately get\\nlow-level co\", \"de generation benefits from performing all the logic in terms of spans. While the above\\nexample was \", \"made up (obviously the matching logic does more than a simple for loop), here\\u2019s a real\\nexample. When\", \" a regex contains a \\\\b, as part of evaluating the input against that \\\\b the backtracking\\nengines cal\", \"l a RegexRunner.IsBoundary helper method which checks whether the character at the\\ncurrent position \", \"is a word character and whether the character before it is a word character (factoring\\nin the bounds\", \" of the input as well). Here\\u2019s what the IsBoundary method based on string looked like\\n(the runtext i\", \"t\\u2019s using is the name of the string field on RegexRunner that stores the input):\\n[Benchmark]\\n[Argume\", \"nts(0, 0, 26)]\\npublic bool IsBoundary(int index, int startpos, int endpos)\\n{\\nreturn (index > startpo\", \"s && IsBoundaryWordChar(runtext[index - 1])) !=\\n(index < endpos && IsBoundaryWordChar(runtext[index]\", \"));\\n}\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate bool IsBoundaryWordChar(char c) => false;\\na\", \"nd here\\u2019s what the span version looks like:\\n[Benchmark]\\n[Arguments(\\\"abcdefghijklmnopqrstuvwxyz\\\", 0)]\", \"\\npublic bool IsBoundary(ReadOnlySpan<char> inputSpan, int index)\\n{\\nint indexM1 = index - 1;\\nreturn (\", \"(uint)indexM1 < (uint)inputSpan.Length &&\\nIsBoundaryWordChar(inputSpan[indexM1])) !=\\n((uint)index < \", \"(uint)inputSpan.Length && IsBoundaryWordChar(inputSpan[index]));\\n}\\n[MethodImpl(MethodImplOptions.NoI\", \"nlining)]\\nprivate bool IsBoundaryWordChar(char c) => false;\\n135 CHAPTER 11 | RegexAnd here\\u2019s the res\", \"ulting assembly:\\n; Program.IsBoundary(Int32, Int32, Int32)\\npush rdi\\npush rsi\\npush rbp\\npush rbx\\nsub r\", \"sp,28\\nmov rdi,rcx\\nmov esi,edx\\nmov ebx,r9d\\ncmp esi,r8d\\njle short M00_L00\\nmov rcx,rdi\\nmov rcx,[rcx+8]\\n\", \"lea edx,[rsi-1]\\ncmp edx,[rcx+8]\\njae short M00_L04\\nmov edx,edx\\nmovzx edx,word ptr [rcx+rdx*2+0C]\\nmov \", \"rcx,rdi\\ncall qword ptr [Program.IsBoundaryWordChar(Char)]\\njmp short M00_L01\\nM00_L00:\\nxor eax,eax\\nM00\", \"_L01:\\nmov ebp,eax\\ncmp esi,ebx\\njge short M00_L02\\nmov rcx,rdi\\nmov rcx,[rcx+8]\\ncmp esi,[rcx+8]\\njae shor\", \"t M00_L04\\nmov edx,esi\\nmovzx edx,word ptr [rcx+rdx*2+0C]\\nmov rcx,rdi\\ncall qword ptr [Program.IsBounda\", \"ryWordChar(Char)]\\njmp short M00_L03\\nM00_L02:\\nxor eax,eax\\nM00_L03:\\ncmp ebp,eax\\nsetne al\\nmovzx eax,al\\n\", \"add rsp,28\\npop rbx\\npop rbp\\npop rsi\\npop rdi\\nret\\nM00_L04:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n; Total b\", \"ytes of code 117\\n; Program.IsBoundary(System.ReadOnlySpan`1<Char>, Int32)\\npush r14\\npush rdi\\npush rsi\", \"\\npush rbp\\n136 CHAPTER 11 | Regexpush rbx\\nsub rsp,20\\nmov rdi,rcx\\nmov esi,r8d\\nmov rbx,[rdx]\\nmov ebp,[r\", \"dx+8]\\nlea edx,[rsi-1]\\ncmp edx,ebp\\njae short M00_L00\\nmov edx,edx\\nmovzx edx,word ptr [rbx+rdx*2]\\nmov r\", \"cx,rdi\\ncall qword ptr [Program.IsBoundaryWordChar(Char)]\\njmp short M00_L01\\nM00_L00:\\nxor eax,eax\\nM00_\", \"L01:\\nmov r14d,eax\\ncmp esi,ebp\\njae short M00_L02\\nmov edx,esi\\nmovzx edx,word ptr [rbx+rdx*2]\\nmov rcx,r\", \"di\\ncall qword ptr [Program.IsBoundaryWordChar(Char)]\\njmp short M00_L03\\nM00_L02:\\nxor eax,eax\\nM00_L03:\", \"\\ncmp r14d,eax\\nsetne al\\nmovzx eax,al\\nadd rsp,20\\npop rbx\\npop rbp\\npop rsi\\npop rdi\\npop r14\\nret\\n; Total b\", \"ytes of code 94\\nThe most interesting thing to notice here is the:\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\", \"\\nat the end of the first version that doesn\\u2019t exist at the end of the second. As we saw earlier, thi\", \"s is\\nwhat the generated assembly looks like when the JIT is emitting the code to throw an index out \", \"of\\nrange exception for an array, string, or span. It\\u2019s at the end because it\\u2019s considered to be \\u201ccol\", \"d,\\u201d rarely\\nexecuted. It exists in the first because the JIT can\\u2019t prove based on local analysis of t\", \"hat function that\\nthe runtext[index-1] and runtext[index] accesses will be in range of the string (i\", \"t can\\u2019t know or\\ntrust any implied relationship between startpos, endpos, and the bounds of runtext).\", \" But in the\\nsecond, the JIT can know and trust that the ReadOnlySpan<char>\\u2019s lower bound is 0 and up\", \"per bound\\n(exclusive) is the span\\u2019s Length, and with how the method is constructed, it can then prov\", \"e that the\\nspan accesses are always in bound. As such, it doesn\\u2019t need to emit any bounds checks in \", \"the method,\\nand the method then lacks the tell-tale signature of the index out of range throw. You c\", \"an see more\\nexamples of taking advantage of spans now being at the heart of the all of the engines i\", \"n\\n137 CHAPTER 11 | Regexdotnet/runtime#66129, dotnet/runtime#66178, and dotnet/runtime#72728, all of\", \" which clean up\\nunnecessary checks against the bounds that are then always 0 and span.Length.\\nOk, so\", \" the engines are now able to be handed span inputs and process them, great, what can we do\\nwith that\", \"? Well, Regex.IsMatch is easy: it\\u2019s not encumbered by needing to perform multiple matches,\\nand thus \", \"doesn\\u2019t need to worry about how to store that input ReadOnlySpan<char> for the next\\nmatch. Similarly\", \", the new Regex.Count, which provides an optimized implementation for counting\\nhow many matches ther\", \"e are in the input, can bypass using Match or MatchCollection, and thus can\\neasily operate over span\", \"s as well; dotnet/runtime#64289 added string-based overloads, and\\ndotnet/runtime#66026 added span-ba\", \"sed overloads. We can optimize Count further by passing\\nadditional information into the engines to l\", \"et them know how much information they actually need to\\ncompute. For example, I noted previously tha\", \"t NonBacktracking is fairly pay-for-play in how much\\nwork it needs to do relative to what informatio\", \"n it needs to gather. It\\u2019s cheapest to just determine\\nwhether there is a match, as it can do that in\", \" a single forward pass through the input. If it also needs\\nto compute the actual starting and ending\", \" bounds, that requires another reverse pass through some\\nof the input. And if it then also needs to \", \"compute capture information, that requires yet another\\nforward pass based on an NFA (even if the oth\", \"er two were DFA-based). Count needs the bounds\\ninformation, as it needs to know where to start looki\", \"ng for the next match, but it doesn\\u2019t need the\\ncapture information, since none of that capture infor\", \"mation is handed back to the caller.\\ndotnet/runtime#68242 updates the engines to receive this additi\", \"onal information, such that methods\\nlike Count can be made more efficient.\\nSo, IsMatch and Count can\", \" work with spans. But we still don\\u2019t have a method that lets you actually get\\nback that match inform\", \"ation. Enter the new EnumerateMatches method, added by\\ndotnet/runtime#67794. EnumerateMatches is ver\", \"y similar to Match, except instead of handing back a\\nMatch class instance, it hands back a ref struc\", \"t enumerator:\\npublic ref struct ValueMatchEnumerator\\n{\\nprivate readonly Regex _regex;\\nprivate readon\", \"ly ReadOnlySpan<char> _input;\\nprivate ValueMatch _current;\\nprivate int _startAt;\\nprivate int _prevLe\", \"n;\\n...\\n}\\nBeing a ref struct, the enumerator is able to store a reference to the input span, and is t\", \"hus able to\\niterate through matches, which are represented by the ValueMatch ref struct. Notably, to\", \"day\\nValueMatch doesn\\u2019t provide capture information, which also enables it to partake in the optimiza\", \"tions\\npreviously mentioned for Count. Even if you have an input string, EnumerateMatches is thus a w\", \"ay to\\nhave ammortized allocation-free enumeration of all matches in the input. In .NET 7, though, th\", \"ere isn\\u2019t\\na way to have such allocation-free enumeration if you also need all the capture data. That\", \"\\u2019s something\\nwe\\u2019ll investigate designing in the future if/as needed.\\nTryFindNextPossibleStartingPosi\", \"tion\\nAs noted earlier, the core of all of the engines is a Scan(ReadOnlySpan<char>) method that acce\", \"pts\\nthe input text to match, combines that with positional information from the base instance, and e\", \"xits\\n138 CHAPTER 11 | Regexwhen it either finds the location of the next match or exhausts the input\", \" without finding another. For\\nthe backtracking engines, the implementation of that method is logical\", \"ly as follows:\\nprotected override void Scan(ReadOnlySpan<char> inputSpan)\\n{\\nwhile (!TryMatchAtCurren\", \"tPosition(inputSpan) &&\\nbase.runtextpos != inputSpan.Length)\\n{\\nbase.runtextpos++;\\n}\\n}\\nWe try to matc\", \"h the input at the current position, and if we\\u2019re successful in doing so, that\\u2019s it, we exit.\\nIf the\", \" current position doesn\\u2019t match, however, then if there\\u2019s any input remaining we \\u201cbump\\u201d the\\nposition\", \" and start the process over. In regex engine terminology, this is often referred to as a\\n\\u201cbumpalong \", \"loop.\\u201d However, if we actually ran the full matching process at every input character, that\\ncould be\", \" unnecessarily slow. For many patterns, there\\u2019s something about the pattern that would\\nenable us to \", \"be more thoughtful about where we perform full matches, quickly skipping past locations\\nthat couldn\\u2019\", \"t possibly match, and only spending our time and resources on locations that have a real\\nchance of m\", \"atching. To elevate that concept to a first-class one, the backtracking engines\\u2019\\n\\u201cbumpalong loop\\u201d is\", \" typically more like the following (I say \\u201ctypically\\u201d because in some cases the\\ncompiled and source \", \"generated regexes are able to generate something even better).\\nprotected override void Scan(ReadOnly\", \"Span<char> inputSpan)\\n{\\nwhile (TryFindNextPossibleStartingPosition(inputSpan) &&\\n!TryMatchAtCurrentP\", \"osition(inputSpan) &&\\nbase.runtextpos != inputSpan.Length)\\n{\\nbase.runtextpos++;\\n}\\n}\\nAs with FindFirs\", \"tChar previously, that TryFindNextPossibleStartingPosition has the\\nresponsibility of searching as qu\", \"ickly as possible for the next place to match (or determining that\\nnothing else could possibly match\", \", in which case it would return false and the loop would exit). As\\nFindFirstChar, and it was embued \", \"with multiple ways of doing its job. In .NET 7,\\nTryFindNextPossibleStartingPosition learns many more\", \" and improved ways of helping the engine\\nbe fast.\\nIn .NET 6, the interpreter engine had effectively \", \"two ways of implementing\\nTryFindNextPossibleStartingPosition: a Boyer-Moore substring search if the \", \"pattern began with a\\nstring (potentially case-insensitive) of at least two characters, and a linear \", \"scan for a character class\\nknown to be the set of all possible chars that could begin a match. For t\", \"he latter case, the interpreter\\nhad eight different implementations for matching, based on a combina\", \"tion of whether\\nRegexOptions.RightToLeft was set or not, whether the character class required case-i\", \"nsensitive\\ncomparison or not, and whether the character class contained only a single character or m\", \"ore than\\none character. Some of these were more optimized than others, e.g. a left-to-right, case-se\", \"nsitive,\\nsingle-char search would use an IndexOf(char) to search for the next location, an optimizat\", \"ion\\nadded in .NET 5. However, every time this operation was performed, the engine would need to\\nreco\", \"mpute which case it would be. dotnet/runtime#60822 improved this, introducing an internal\\n139 CHAPTE\", \"R 11 | Regexenum of the strategies used by TryFindNextPossibleStartingPosition to find the next oppo\", \"rtunity,\\nadding a switch to TryFindNextPossibleStartingPosition to quickly jump to the right strateg\", \"y,\\nand precomputing which strategy to use when the interpreter was constructed. This not only made\\nt\", \"he interpreter\\u2019s implementation at match time faster, it made it effectively free (in terms of runti\", \"me\\noverhead at match time) to add additional strategies.\\ndotnet/runtime#60888 then added the first a\", \"dditional strategy. The implementation was already\\ncapable of using IndexOf(char), but as mentioned \", \"previously in this post, the implementation of\\nIndexOf(ReadOnlySpan<char>) got way better in .NET 7 \", \"in many cases, to the point where it ends up\\nbeing significantly better than Boyer-Moore in all but \", \"the most corner of corner cases. So this PR\\nenables a new IndexOf(ReadOnlySpan<char>) strategy to be\", \" used to search for a prefix string in the\\ncase where the string is case-sensitive.\\nprivate static r\", \"eadonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/16\", \"61-0.txt\\\").Result;\\nprivate Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled);\\n[Benc\", \"hmark]\\npublic int Count() => _regex.Matches(s_haystack).Count;\\nMethod Runtime Mean Ratio\\nCount .NET \", \"6.0 377.32 us 1.00\\nCount .NET 7.0 55.44 us 0.15\\ndotnet/runtime#61490 then removed Boyer-Moore entire\", \"ly. This wasn\\u2019t done in the previously\\nmentioned PR because of lack of a good way to handle case-ins\", \"ensitive matches. However, this PR\\nalso special-cased ASCII letters to teach the optimizer how to tu\", \"rn an ASCII case-insensitive match\\ninto a set of both casings of that letter (excluding the few know\", \"n to be a problem, like i and k, which\\ncan both be impacted by the employed culture and which might \", \"map case-insensitively to more than\\ntwo values). With enough of the common cases covered, rather tha\", \"n use Boyer-Moore to perform a\\ncase-insensitive search, the implementation just uses IndexOfAny(char\", \", char, ...) to search for\\nthe starting set, and the vectorization employed by IndexOfAny ends up ou\", \"tpacing the old\\nimplementation handily in real-world cases. This PR goes further than that, such tha\", \"t it doesn\\u2019t just\\ndiscover the \\u201cstarting set,\\u201d but is able to find all of the character classes that\", \" could match a pattern a\\nfixed-offset from the beginning; that then gives the analyzer the ability t\", \"o choose the set that\\u2019s\\nexpected to be least common and issue a search for it instead of whatever ha\", \"ppens to be at the\\nbeginning. The PR goes even further, too, motivated in large part by the non-back\", \"tracking engine. The\\nnon-backtracking engine\\u2019s prototype implementation also used IndexOfAny(char, c\", \"har, ...) when\\nit arrived at a starting state and was thus able to quickly skip through input text t\", \"hat wouldn\\u2019t have a\\nchance of pushing it to the next state. We wanted all of the engines to share as\", \" much logic as\\npossible, in particular around this speed ahead, and so this PR unified the interpret\", \"er with the non-\\nbacktracking engine to have them share the exact same TryFindNextPossibleStartingPo\", \"sition\\nroutine (which the non-backtracking engine just calls at an appropriate place in its graph tr\", \"aversal\\nloop). Since the non-backtracking engine was already using IndexOfAny in this manner, initia\", \"lly not\\ndoing so popped as a significant regression on a variety of patterns we measure, and this ca\", \"used us to\\ninvest in using it everywhere. This PR also introduced the first special-casing for case-\", \"insensitive\\ncomparisons into the compiled engine, e.g. if we found a set that was [Ee], rather than \", \"emitting a\\n140 CHAPTER 11 | Regexcheck akin to c == 'E' || c == 'e', we\\u2019d instead emit a check akin \", \"to (c | 0x20) == 'e' (those\\nfun ASCII tricks discussed earlier coming into play again).\\nprivate stat\", \"ic readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/166\", \"1/1661-0.txt\\\").Result;\\nprivate Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled |\\nR\", \"egexOptions.IgnoreCase);\\n[Benchmark]\\npublic int Count() => _regex.Matches(s_haystack).Count;\\nMethod \", \"Runtime Mean Ratio\\nCount .NET 6.0 499.3 us 1.00\\nCount .NET 7.0 177.7 us 0.35\\nThe previous PR started\", \" turning IgnoreCase pattern text into sets, in particular for ASCII, e.g. (?i)a\\nwould become [Aa]. T\", \"hat PR hacked in the support for ASCII knowing that something more complete\\nwould be coming along, a\", \"s it did in dotnet/runtime#67184. Rather than hardcoding the case-\\ninsensitive sets that just the AS\", \"CII characters map to, this PR essentially hardcodes the sets for every\\npossible char. Once that\\u2019s d\", \"one, we no longer need to know about case-insensitivity at match time\\nand can instead just double-do\", \"wn on efficiently matching sets, which we already need to be able to\\ndo well. Now, I said it encodes\", \" the sets for every possible char; that\\u2019s not entirely true. If it were true,\\nthat would take up a l\", \"arge amount of memory, and in fact, most of that memory would be wasted\\nbecause the vast majority of\", \" characters don\\u2019t participate in case conversion\\u2026 there are only ~2,000\\ncharacters that we need to h\", \"andle. As such, the implementation employs a three-tier table scheme.\\nThe first table has 64 element\", \"s, dividing the full range of chars into 64 groupings; of those 64 groups,\\n54 of them have no charac\", \"ters that participate in case conversion, so if we hit one of those entries, we\\ncan immediately stop\", \" the search. For the remaining 10 that do have at least one character in their\\nrange participating, \", \"the character and the value from the first table are used to compute an index into\\nthe second table;\", \" there, too, the majority of entries say that nothing participates in case conversion.\\nIt\\u2019s only if \", \"we get a legitimate hit in the second table does that give us an index into the third table, at\\nwhic\", \"h location we can find all of the characters considered case-equivalent with the first.\\ndotnet/runti\", \"me#63477 (and then later improved in dotnet/runtime#66572) proceeded to add another\\nsearching strate\", \"gy, this one inspired by nim-regex\\u2019s literal optimizations. There are a multitude of\\nregexes we trac\", \"k from a performance perspective to ensure we\\u2019re not regressing in common cases\\nand to help guide in\", \"vestments. One is the set of patterns in mariomka/regex-benchmark languages\\nregex benchmark. One of \", \"those is for URIs:\\n(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\". This pattern defies the \", \"thus-far\\nenabled strategies for finding a next good location, as it\\u2019s guaranteed to begin with a \\u201cwo\", \"rd\\ncharacter\\u201d (\\\\w), which includes ~50,000 of the ~65,000 possible characters; we don\\u2019t have a good \", \"way\\nof vectorizing a search for such a character class. However, this pattern is interesting in that\", \" it begins\\nwith a loop, and not only that, it\\u2019s an upper-unbounded loop which our analysis will dete\", \"rmine is\\natomic, because the character guaranteed to immediately follow the loop is a ':', which is \", \"itself not a\\nword character, and thus there\\u2019s nothing the loop could match and give up as part of ba\", \"cktracking\\nthat would match ':'. That all lends itself to a different approach to vectorization: rat\", \"her than trying\\nto search for the \\\\w character class, we can instead search for the substring \\\"://\\\",\", \" and then once we\\n141 CHAPTER 11 | Regexfind it, we can match backwards through as many [\\\\w]s as we \", \"can find; in this case, the only\\nconstraint is we need to match at least one. This PR added that str\", \"ategy, for a literal after an atomic\\nloop, to all of the engines.\\nprivate static readonly string s_h\", \"aystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\", \"\\nprivate Regex _regex = new Regex(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\",\\nRegexOptio\", \"ns.Compiled);\\n[Benchmark]\\npublic bool IsMatch() => _regex.IsMatch(s_haystack); // Uri's in Sherlock \", \"Holmes? \\\"Most\\nunlikely.\\\"\\nMethod Runtime Mean Ratio\\nIsMatch .NET 6.0 4,291.77 us 1.000\\nIsMatch .NET 7\", \".0 42.40 us 0.010\\nOf course, as has been talked about elsewhere, the best optimizations aren\\u2019t ones \", \"that make\\nsomething faster but rather ones that make something entirely unnecessary. That\\u2019s what\\ndot\", \"net/runtime#64177 does, in particular in relation to anchors. The .NET regex implementation has\\nlong\", \" had optimizations for patterns with a starting anchor: if the pattern begins with ^, for example\\n(a\", \"nd RegexOptions.Multiline wasn\\u2019t specified), the pattern is rooted to the beginning, meaning it\\ncan\\u2019\", \"t possibly match at any position other than 0; as such, with such an anchor,\\nTryFindNextPossibleStar\", \"tingPosition won\\u2019t do any searching at all. The key here, though, is being\\nable to detect whether th\", \"e pattern begins with such an anchor. In some cases, like ^abc$, that\\u2019s trivial.\\nIn other cases, lik\", \"e ^abc|^def, the existing analysis had trouble seeing through that alternation to find\\nthe guarantee\", \"d starting ^ anchor. This PR fixes that. It also adds a new strategy based on discovering\\nthat a pat\", \"tern has an ending anchor like $. If the analysis engine can determine a maximum number of\\ncharacter\", \"s for any possible match, and it has such an anchor, then it can simply jump to that distance\\nfrom t\", \"he end of the string, and bypass even looking at anything before then.\\nprivate static readonly strin\", \"g s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Re\", \"sult;\\nprivate Regex _regex = new Regex(@\\\"^abc|^def\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic bool\", \" IsMatch() => _regex.IsMatch(s_haystack); // Why search _all_ the text?!\\nMethod Runtime Mean Ratio\\nI\", \"sMatch .NET 6.0 867,890.56 ns 1.000\\nIsMatch .NET 7.0 33.55 ns 0.000\\ndotnet/runtime#67732 is another \", \"PR related to improving anchor handling. It\\u2019s always fun when a bug\\nfix or code simplification refac\", \"toring turns into a performance improvement. The PR\\u2019s primary purpose\\nwas to simplify some complicat\", \"ed code that was computing the set of characters that could possibly\\nstart a match. It turns out tha\", \"t complication was hiding a logic bug which manifested in it missing\\nsome opportunities to report va\", \"lid starting character classes, the impact of which is that some\\nsearches which could have been vect\", \"orized weren\\u2019t. By simplifying the implementation, the bug was\\nfixed, exposing more performance oppo\", \"rtunities.\\n142 CHAPTER 11 | RegexBy this point, the engines are able to use IndexOf(ReadOnlySpan<cha\", \"r>) to find a substring at the\\nbeginning of a pattern. But sometimes the most valuable substring isn\", \"\\u2019t at the beginning, but\\nsomewhere in the middle or even at the end. As long as it\\u2019s at a fixed-offs\", \"et from the beginning of the\\npattern, we can search for it, and then just back-off by the offset to \", \"the position we should actually try\\nrunning the match. dotnet/runtime#67907 does exactly that.\\npriva\", \"te static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/fi\", \"les/1661/1661-0.txt\\\").Result;\\nprivate Regex _regex = new Regex(@\\\"looking|feeling\\\", RegexOptions.Comp\", \"iled);\\n[Benchmark]\\npublic int Count() => _regex.Matches(s_haystack).Count; // will search for \\\"ing\\\"\\n\", \"Method Runtime Mean Ratio\\nCount .NET 6.0 444.2 us 1.00\\nCount .NET 7.0 122.6 us 0.28\\nLoops and Backtr\", \"acking\\nLoop handling in the compiled and source generated engines has been significantly improved, b\", \"oth\\nwith respect to processing them faster and with respect to backtracking less.\\nWith regular greed\", \"y loops (e.g. c*), there are two directions to be concerned about: how quickly can\\nwe consume all th\", \"e elements that match the loop, and how quickly can we give back elements that\\nmight be necessary as\", \" part of backtracking for the remainder of the expression to match. And with\\nlazy loops, we\\u2019re prima\", \"rily concerned with backtracking, which is the forward direction (since lazy\\nloops consume as part o\", \"f backtracking rather than giving back as part of backtracking). With PRs\\ndotnet/runtime#63428, dotn\", \"et/runtime#68400, dotnet/runtime#64254, and dotnet/runtime#73910, in\\nboth the compiler and source ge\", \"nerator we now make full use of effectively all of the variants of\\nIndexOf, IndexOfAny, LastIndexOf,\", \" LastIndexOfAny, IndexOfAnyExcept, and\\nLastIndexOfAnyExcept in order to speed along these searches. \", \"For example, in a pattern like .*abc,\\nthe forward direction of that loop entails consuming every cha\", \"racter until the next newline, which we\\ncan optimize with an IndexOf('\\\\n'). Then as part of backtrac\", \"king, rather than giving up one\\ncharacter at a time, we can LastIndexOf(\\\"abc\\\") in order to find the \", \"next viable location that could\\npossibly match the remainder of the pattern. Or for example, in a pa\", \"ttern like [^a-c]*def, the loop\\nwill initially greedily consume everything other than 'a', 'b', or '\", \"c', so we can use\\nIndexOfAnyExcept('a', 'b', 'c') to find the initial end of the loop. And so on. Th\", \"is can yield huge\\nperformance gains, and with the source generator, also makes the generated code mo\", \"re idiomatic\\nand easier to understand.\\nprivate static readonly string s_haystack = new\\nHttpClient().\", \"GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _regex = new\", \" Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled |\\nRegexOptions.Multiline);\\n[Benchmark]\\npublic int \", \"Count() => _regex.Matches(s_haystack).Count;\\n143 CHAPTER 11 | RegexMethod Runtime Mean Ratio\\nCount .\", \"NET 6.0 3,369.5 us 1.00\\nCount .NET 7.0 430.2 us 0.13\\nSometimes optimizations are well-intended but s\", \"lightly miss the mark. dotnet/runtime#63398 fixes\\nsuch an issue with an optimization introduced in .\", \"NET 5; the optimization was valuable but only for a\\nsubset of the scenarios it was intended to cover\", \". While TryFindNextPossibleStartingPosition\\u2019s\\nprimary raison d\\u2019\\u00eatre is to update the bumpalong posit\", \"ion, it\\u2019s also possible for\\nTryMatchAtCurrentPosition to do so. One of the occasions in which it\\u2019ll \", \"do so is when the pattern\\nbegins with an upper-unbounded single-character greedy loop. Since process\", \"ing starts with the loop\\nhaving fully consumed everything it could possibly match, subsequent trips \", \"through the scan loop\\ndon\\u2019t need to reconsider any starting position within that loop; doing so woul\", \"d just be duplicating\\nwork done in a previous iteration of the scan loop. And as such, TryMatchAtCur\", \"rentPosition can\\nupdate the bumpalong position to the end of the loop. The optimization added in .NE\", \"T 5 was dutifully\\ndoing this, and it did so in a way that fully handled atomic loops. But with greed\", \"y loops, the updated\\nposition was getting updated every time we backtracked, meaning it started goin\", \"g backwards, when it\\nshould have remained at the end of the loop. This PR fixes that, yielding signi\", \"ficant savings in the\\nadditional covered cases.\\nprivate static readonly string s_haystack = new\\nHttp\", \"Client().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _re\", \"gex = new Regex(@\\\".*stephen\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic int Count() => _regex.Match\", \"es(s_haystack).Count;\\nMethod Runtime Mean Ratio\\nCount .NET 6.0 103,962.8 us 1.000\\nCount .NET 7.0 336\", \".9 us 0.003\\nAs mentioned elsewhere, the best optimizations are those that make work entirely vanish \", \"rather than\\njust making work faster. dotnet/runtime#68989, dotnet/runtime#63299, and dotnet/runtime#\", \"63518\\ndo exactly that by improving the pattern analyzers ability to find and eliminate more unnecess\", \"ary\\nbacktracking, a process the analyzer refers to as \\u201cauto-atomicity\\u201d (automatically making loops a\", \"tomic).\\nFor example, in the pattern a*?b, we have a lazy loop of 'a's followed by a b. That loop can\", \" only\\nmatch 'a's, and 'a' doesn\\u2019t overlap with 'b'. So let\\u2019s say the input is \\\"aaaaaaaab\\\". The loop \", \"is lazy,\\nso we\\u2019ll start out by trying to match just 'b'. It won\\u2019t match, so we\\u2019ll backtrack into the\", \" lazy loop and\\ntry to match \\\"ab\\\". It won\\u2019t match so we\\u2019ll backtrack into the lazy loop and try to ma\", \"tch \\\"aab\\\". And so\\non, until we\\u2019ve consumed all the 'a's such that the rest of the pattern has a chan\", \"ce of matching the\\nrest of the input. That\\u2019s exactly what an atomic greedy loop does, so we can tran\", \"sform the pattern\\na*?b into (?>a*)b, which is much more efficiently processed. In fact, we can see e\", \"xactly how it\\u2019s\\nprocessed just by looking at the source-generated implementation of this pattern:\\npr\", \"ivate bool TryMatchAtCurrentPosition(ReadOnlySpan<char> inputSpan)\\n{\\nint pos = base.runtextpos;\\nint \", \"matchStart = pos;\\nReadOnlySpan<char> slice = inputSpan.Slice(pos);\\n144 CHAPTER 11 | Regex// Match 'a\", \"' atomically any number of times.\\n{\\nint iteration = slice.IndexOfAnyExcept('a');\\nif (iteration < 0)\\n\", \"{\\niteration = slice.Length;\\n}\\nslice = slice.Slice(iteration);\\npos += iteration;\\n}\\n// Advance the nex\", \"t matching position.\\nif (base.runtextpos < pos)\\n{\\nbase.runtextpos = pos;\\n}\\n// Match 'b'.\\nif (slice.I\", \"sEmpty || slice[0] != 'b')\\n{\\nreturn false; // The input didn't match.\\n}\\n// The input matched.\\npos++;\", \"\\nbase.runtextpos = pos;\\nbase.Capture(0, matchStart, pos);\\nreturn true;\\n}\\n(Note that those comments a\", \"ren\\u2019t ones I added for this blog post; the source generator itself is\\nemitting commented code.)\\nWhen\", \" a regular expression is input, it\\u2019s parsed into a tree-based form. The \\u201cauto-atomicity\\u201d analysis\\ndi\", \"scussed in the previous PR is one form of analysis that walks around this tree looking for\\nopportuni\", \"ties to transform portions of the tree into a behaviorally equivalent alternative that will be\\nmore \", \"efficient to execute. Several PRs introduced additional such transformations.\\ndotnet/runtime#63695, \", \"for example, looks for \\u201cempty\\u201d and \\u201cnothing\\u201d nodes in the tree that can be\\nremoved. An \\u201cempty\\u201d node \", \"is something that matches the empty string, so for example in the\\nalternation abc|def||ghi, the thir\", \"d branch of that alternation is empty. A \\u201cnothing\\u201d node is\\nsomething that can\\u2019t match anything, so f\", \"or example in the concatenation abc(?!)def, that (?!) in\\nmiddle is a negative lookahead around an em\", \"pty, which can\\u2019t possibly match anything, as it\\u2019s saying\\nthe expression won\\u2019t match if it\\u2019s followed\", \" by an empty string, which everything is. These constructs\\noften arise as a result of other transfor\", \"mations rather than being something a developer typically\\nwrites by hand, just as there are optimiza\", \"tions in the JIT where you might look at them and say \\u201cwhy\\non earth is that something a developer wo\", \"uld write\\u201d but it ends up being a valuable optimization\\nanyways because inlining might transform per\", \"fectly reasonable code into something that matches the\\ntarget pattern. Thus, for example, if you did\", \" have abc(?!)def, since that concatenation requires the\\n(?!) to match in order to be successful, the\", \" concatenation itself can simply be replaced by a\\n\\u201cnothing.\\u201d You can see this easily if you try this\", \" with the source generator:\\n[GeneratedRegex(@\\\"abc(?!)def\\\")]\\n145 CHAPTER 11 | Regexas it will produce\", \" a Scan method like this (comment and all):\\nprotected override void Scan(ReadOnlySpan<char> inputSpa\", \"n)\\n{\\n// The pattern never matches anything.\\n}\\nAnother set of transformations was introduced in dotne\", \"t/runtime#59903, specifically around\\nalternations (which beyond loops are the other source of backtr\", \"acking). This introduced two main\\noptimizations. First, it enables rewriting alternations into alter\", \"nations of alternations, e.g. transforming\\naxy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z), which is then f\", \"urther reduced into ax[yz]|bx[yz]. This\\ncan enable the backtracking engines to more efficiently proc\", \"ess alternations due to fewer branches\\nand thus less potential backtracking. The PR also enabled lim\", \"ited reordering of branches in an\\nalternation. Generally branches can\\u2019t be reordered, as the order c\", \"an impact exactly what\\u2019s matched\\nand what\\u2019s captured, but if the engine can prove there\\u2019s no effect \", \"on ordering, then it\\u2019s free to\\nreorder. One key place that ordering isn\\u2019t a factor is if the alterna\", \"tion is atomic due to it being\\nwrapped in an atomic group (and the auto-atomicity analysis will add \", \"such groups implicitly in some\\nsituations). Reordering the branches then enables other optimizations\", \", like the one previously\\nmentioned from this PR. And then once those optimizations have kicked in, \", \"if we\\u2019re left with an atomic\\nalternation where every branch begins with a different letter, than can\", \" enable further optimizations in\\nterms of how the alternation is lowered; this PR teaches the source\", \" generator how to emit a switch\\nstatement, which leads to both more efficient and more readable code\", \". (The detection of whether\\nnodes in the tree are atomic, and other such properties such as performi\", \"ng captures or introducing\\nbacktracking, turned out to be valuable enough that dotnet/runtime#65734 \", \"added dedicated support\\nfor this.)\\nCode generation\\nThe .NET 7 regex implementation has no fewer than\", \" four engines: the interpreter (what you get if you\\ndon\\u2019t explicitly choose another engine), the com\", \"piler (what you get with RegexOptions.Compiled),\\nthe non-backtracking engine (what you get with Rege\", \"xOptions.NonBacktracking), and the source\\ngenerator (what you get with [GeneratedRegex(...)]). The i\", \"nterpreter and the non-backtracking\\nengine don\\u2019t require any kind of code generation; they\\u2019re both b\", \"ased on creating in-memory data\\nstructures that represent how to match input against the pattern. Th\", \"e other two, though, both\\ngenerate code specific to the pattern; the generated code is code attempti\", \"ng to mimick what you\\nmight write if you weren\\u2019t using Regex at all and were instead writing code to\", \" perform a similar match\\ndirectly. The source generator spits out C# that\\u2019s compiled directly into y\", \"our assembly, and the\\ncompiler spits out IL at run-time via reflection emit. The fact that these are\", \" generating code specific to\\nthe pattern means there\\u2019s a ton of opportunity to optimize.\\ndotnet/runt\", \"ime#59186 provided the initial implementation of the source generator. This was a direct\\nport of the\", \" compiler, effectively a line-by-line translation of IL into C#; the result is C# akin to what\\nyou\\u2019d\", \" get if you were to run the generated IL through a decompiler like ILSpy. A bunch of PRs then\\nprocee\", \"ded to iterate on and tweak the source generator, but the biggest improvements came from\\nchanges tha\", \"t changed the compiler and the source generator together. Prior to .NET 5, the compiler\\nspit out IL \", \"that was very similar to what the interpreter would do. The interpreter is handed a series of\\ninstru\", \"ctions that it walks through one by one and interprets, and the compiler, handed that same\\n146 CHAPT\", \"ER 11 | Regexseries of instructions, would just emit the IL for processing each. It had some opportu\", \"nity for being\\nmore efficient, e.g. loop unrolling, but a lot of value was left on the table. In .NE\", \"T 5, an alternate path\\nwas added in support of patterns without backtracking; this code path was bas\", \"ed on being handed\\nthe parsed node tree rather than being based on the series of instructions, and t\", \"hat higher-level form\\nenabled the compiler to derive more insights about the pattern that it could t\", \"hen use to generate\\nmore efficient code. In .NET 7, support for all regex features were incrementall\", \"y added in, over the\\ncourse of multiple PRs, in particular dotnet/runtime#60385 for backtracking sin\", \"gle char loops,\\ndotnet/runtime#61698 for backtracking single char lazy loops, dotnet/runtime#61784 f\", \"or other\\nbacktracking lazy loops, and dotnet/runtime#61906 for other backtracking loops as well as b\", \"ack\\nreferences and conditionals. At that point, the only features missing were support for\\nRegexOpti\", \"ons.RightToLeft and lookbehinds (which are implemented in terms of right-to-left), and\\nwe decided ba\", \"sed on relatively little use of these features that we needn\\u2019t keep around the old\\ncompiler code jus\", \"t to enable them. So, dotnet/runtime#62318 deleted the old implementation. But,\\neven though these fe\", \"atures are relatively rare, it\\u2019s a lot easier to tell a story that \\u201call patterns are\\nsupported\\u201d than\", \" one that requires special callouts and exceptions, so dotnet/runtime#66127 and\\ndotnet/runtime#66280\", \" added full lookbehind and RightToLeft support such that there were no\\ntakebacks. At this point, bot\", \"h the compiler and source generator now supported everything the\\ncompiler previously did, but now wi\", \"th the more modernized code generation. This code generation is\\nin turn what enables many of the opt\", \"imizations previously discussed, e.g. it provides the opportunity\\nto use APIs like LastIndexOf as pa\", \"rt of backtracking, which would have been near impossible with the\\nprevious approach.\\nOne of the gre\", \"at things about the source generator emitting idiomatic C# is it makes it easy to iterate.\\nEvery tim\", \"e you put in a pattern and see what the generator emits, it\\u2019s like being asked to do a code\\nreview o\", \"f someone else\\u2019s code, and you very frequently see something \\u201cnew\\u201d worthy of comment, or\\nin this cas\", \"e, improving the generator to address the issue. And so a bunch of PRs were originated\\nbased on revi\", \"ewing what the generator emitted and then tweaking the generator to do better (and\\nsince the compile\", \"r was effectively entirely rewritten along with the source generator, they maintain the\\nsame structu\", \"re, and it\\u2019s easy to port improvements from one to the other). For example,\\ndotnet/runtime#68846 and\", \" dotnet/runtime#69198 tweaked how some comparisons were being\\nperformed in order for them to convey \", \"enough information to the JIT that it can eliminate some\\nsubsequent bounds checking, and dotnet/runt\", \"ime#68490 recognized a variety of conditions being\\nemitted that could never happen in some situation\", \"s observable statically and was able to elide all that\\ncode gen. It also became obvious that some pa\", \"tterns didn\\u2019t need the full expressivity of the scan loop,\\nand a more compact and customized Scan im\", \"plementation could be used. dotnet/runtime#68560\\ndoes that, such that, for example, a simple pattern\", \" like hello won\\u2019t emit a loop at all and will instead\\nhave a simpler Scan implementation like:\\nprote\", \"cted override void Scan(ReadOnlySpan<char> inputSpan)\\n{\\nif (TryFindNextPossibleStartingPosition(inpu\", \"tSpan))\\n{\\n// The search in TryFindNextPossibleStartingPosition performed the entire match.\\nint start\", \" = base.runtextpos;\\nint end = base.runtextpos = start + 5;\\nbase.Capture(0, start, end);\\n}\\n}\\n147 CHAP\", \"TER 11 | RegexThe compiler and source generator were also updated to take advantage of newer feature\", \"s.\\ndotnet/runtime#63277, for example, teaches the source generator how to determine if unsafe code i\", \"s\\nallowed, and if it is, it emits a [SkipLocalsInit] for the core logic; the matching routine can re\", \"sult in\\nmany locals being emitted, and SkipLocalsInit can make it cheaper to call the function due t\", \"o less\\nzero\\u2019ing being necessary. Then there\\u2019s the issue of where the code is generated; we want help\", \"er\\nfunctions (like the \\\\w IsWordChar helper introduced in dotnet/runtime#62620) that can be shared\\na\", \"mongst multiple generated regexes, and we want to be able to share the exact same regex\\nimplementati\", \"on if the same pattern/options/timeout combination are used in multiple places in the\\nsame assembly \", \"(dotnet/runtime#66747), but doing so then exposes this implementation detail to user\\ncode in the sam\", \"e assembly. To still be able to get the perf benefits of such code sharing while\\navoiding the result\", \"ing complications, dotnet/runtime#66432 and then dotnet/runtime#71765 teaches\\nthe source generator t\", \"o use the new file-local types features in C# 11 (dotnet/roslyn#62375).\\nOne last and interesting cod\", \"e generation aspect is in optimizations around character class matching.\\nMatching character classes,\", \" whether ones explicitly written by the developer or ones implicitly created\\nby the engine (e.g. as \", \"part of finding the set of all characters that can begin the expression), can be\\none of the more tim\", \"e-consuming aspects of matching; if you imagine having to evaluate this logic for\\nevery character in\", \" the input, then how many instructions needs to be executed as part of matching a\\ncharacter class di\", \"rectly correlates to how long it takes to perform the overall match. We thus spend\\nsome time trying \", \"to ensure we generate optimal matching code for as many categories of character\\nclasses as possible.\", \" dotnet/runtime#67365, for example, improved a bunch of cases found to be\\ncommon in real-world use, \", \"like specially-recognizing sets like [\\\\d\\\\D], [\\\\s\\\\S], and [\\\\w\\\\W] as meaning\\n\\u201cmatch anything\\u201d (just as\", \" is the case for . in RegexOptions.Singleline mode), in which case existing\\noptimizations around the\", \" handling of \\u201cmatch anything\\u201d can kick in.\\nprivate static readonly string s_haystack = new string('a\", \"', 1_000_000);\\nprivate Regex _regex = new Regex(@\\\"([\\\\s\\\\S]*)\\\", RegexOptions.Compiled);\\n[Benchmark]\\npu\", \"blic Match Match() => _regex.Match(s_haystack);\\nMethod Runtime Mean Ratio\\nMatch .NET 6.0 1,934,393.6\", \"9 ns 1.000\\nMatch .NET 7.0 91.80 ns 0.000\\nOr dotnet/runtime#68924, which taught the source generator \", \"how to use all of the new char ASCII\\nhelper methods, like char.IsAsciiLetterOrDigit, as well as some\", \" existing helpers it didn\\u2019t yet know\\nabout, in the generated output; for example this:\\n[GeneratedReg\", \"ex(@\\\"[A-Za-z][A-Z][a-z][0-9][A-Za-z0-9][0-9A-F][0-9a-f][0-9A-Fa-\\nf]\\\\p{Cc}\\\\p{L}[\\\\p{L}\\\\d]\\\\p{Ll}\\\\p{Lu}\\\\\", \"p{N}\\\\p{P}\\\\p{Z}\\\\p{S}\\\")]\\nnow produces this in the core matching logic emitted by the source generator:\", \"\\nif ((uint)slice.Length < 17 ||\\n!char.IsAsciiLetter(slice[0]) || // Match a character in the set [A-\", \"Za-z].\\n!char.IsAsciiLetterUpper(slice[1]) || // Match a character in the set [A-Z].\\n!char.IsAsciiLet\", \"terLower(slice[2]) || // Match a character in the set [a-z].\\n!char.IsAsciiDigit(slice[3]) || // Matc\", \"h '0' through '9'.\\n!char.IsAsciiLetterOrDigit(slice[4]) || // Match a character in the set [0-9A-Za-\", \"z].\\n148 CHAPTER 11 | Regex!char.IsAsciiHexDigitUpper(slice[5]) || // Match a character in the set [0\", \"-9A-F].\\n!char.IsAsciiHexDigitLower(slice[6]) || // Match a character in the set [0-9a-f].\\n!char.IsAs\", \"ciiHexDigit(slice[7]) || // Match a character in the set [0-9A-Fa-f].\\n!char.IsControl(slice[8]) || /\", \"/ Match a character in the set [\\\\p{Cc}].\\n!char.IsLetter(slice[9]) || // Match a character in the set\", \" [\\\\p{L}].\\n!char.IsLetterOrDigit(slice[10]) || // Match a character in the set [\\\\p{L}\\\\d].\\n!char.IsLow\", \"er(slice[11]) || // Match a character in the set [\\\\p{Ll}].\\n!char.IsUpper(slice[12]) || // Match a ch\", \"aracter in the set [\\\\p{Lu}].\\n!char.IsNumber(slice[13]) || // Match a character in the set [\\\\p{N}].\\n!\", \"char.IsPunctuation(slice[14]) || // Match a character in the set [\\\\p{P}].\\n!char.IsSeparator(slice[15\", \"]) || // Match a character in the set [\\\\p{Z}].\\n!char.IsSymbol(slice[16])) // Match a character in th\", \"e set [\\\\p{S}].\\n{\\nreturn false; // The input didn't match.\\n}\\nOther changes impacting character class \", \"code generation included dotnet/runtime#72328, which\\nimproved the handling of character classes that\", \" involve character class subtraction;\\ndotnet/runtime#72317 from [@teo-tsirpanis](https://github.com/\", \"teo-tsirpanis), which enabled\\nadditional cases where the generator could avoid emitting a bitmap loo\", \"kup; dotnet/runtime#67133,\\nwhich added a tighter bounds check when it does emit such a lookup table;\", \" and\\ndotnet/runtime#61562, which enables better normalization of character classes in the engine\\u2019s\\ni\", \"nternal representation, thus leading to downstream optimizations better recognizing more character\\nc\", \"lasses.\\nFinally, with all of these improvements to Regex, a multitude of PRs fixed up regexes being \", \"used\\nacross dotnet/runtime, in various ways. dotnet/runtime#66142, dotnet/runtime#66179 from\\n[@Clock\", \"work-Muse](https://github.com/Clockwork-Muse), and dotnet/runtime#62325 from\\n[@Clockwork-Muse](https\", \"://github.com/Clockwork-Muse) all converted Regex usage over to using\\n[GeneratedRegex(...)]. dotnet/\", \"runtime#68961 optimized other usage in various ways. The PR\\nreplaced several regex.Matches(...).Succ\", \"ess calls with IsMatch(...), as using IsMatch has less\\noverhead due to not needing to construct a Ma\", \"tch instance and due to being able to avoid more\\nexpensive phases in the non-backtracking engine to \", \"compute exact bounds and capture information.\\nThe PR also replaced some Match/Match.MoveNext usage w\", \"ith EnumerateMatches, in order to avoid\\nneeding Match object allocations. The PR also entirely remov\", \"ed at least one regex usage that was just\\nas doable as a cheaper IndexOf. dotnet/runtime#68766 also \", \"removed a use of\\nRegexOptions.CultureInvariant. Specifying CultureInvariant changes the behavior of\\n\", \"IgnoreCase by alternating which casing tables are employed; if IgnoreCase isn\\u2019t specified and there\\u2019\", \"s\\nno inline case-insensitivity options ((?i)), then specifying CultureInvariant is a nop. But a\\npote\", \"ntially expensive one. For any code that\\u2019s size conscious, the Regex implementation is structured\\nin\", \" a way as to try to make it as trimmmer friendly as possible. If you only ever do new\\nRegex(pattern)\", \", we\\u2019d really like to be able to statically determine that the compiler and non-\\nbacktracking implem\", \"entations aren\\u2019t needed such that the trimmer can remove it without having a\\nvisible and meaningful \", \"negative impact. However, the trimmer analysis isn\\u2019t yet sophisticated enough\\nto see exactly which o\", \"ptions are used and only keep the additional engines linked in if\\nRegexOptions.Compiled or RegexOpti\", \"ons.NonBacktracking is used; instead, any use of an overload\\nthat takes a RegexOptions will result i\", \"n that code continuing to be referenced. By getting rid of the\\noptions, we increase the chances that\", \" no code in the app is using this constructor, which would in turn\\nenable this constructor, the comp\", \"iler, and the non-backtracking implementation to be trimmed away.\\n149 CHAPTER 11 | Regex12\\nCHAPTER\\nC\", \"ollections\\nSystem.Collections hasn\\u2019t seen as much investment in .NET 7 as it has in previous release\", \"s, though\\nmany of the lower-level improvements have a trickle-up effect into collections as well. Fo\", \"r example,\\nDictionary<,>\\u2019s code hasn\\u2019t changed between .NET 6 and .NET 7, but even so, this benchmar\", \"k\\nfocused on dictionary lookups:\\nprivate Dictionary<int, int> _dictionary = Enumerable.Range(0, 10_0\", \"00).ToDictionary(i =>\\ni);\\n[Benchmark]\\npublic int Sum()\\n{\\nDictionary<int, int> dictionary = _dictiona\", \"ry;\\nint sum = 0;\\nfor (int i = 0; i < 10_000; i++)\\n{\\nif (dictionary.TryGetValue(i, out int value))\\n{\\n\", \"sum += value;\\n}\\n}\\nreturn sum;\\n}\\nshows a measurable improvement in throughput between .NET 6 and .NET\", \" 7:\\nMethod Runtime Mean Ratio Code Size\\nSum .NET 6.0 51.18 us 1.00 431 B\\nSum .NET 7.0 43.44 us 0.85 \", \"413 B\\nBeyond that, there have been explicit improvements elsewhere in collections. ImmutableArray<T>\", \", for\\nexample. As a reminder, ImmutableArray<T> is a very thin struct-based wrapper around a T[] tha\", \"t\\nhides the mutability of T[]; unless you\\u2019re using unsafe code, neither the length nor the shallow\\nc\", \"ontents of an ImmutableArray<T> will ever change (by shallow, I mean the data stored directly in\\ntha\", \"t array can\\u2019t be mutated, but if there are mutable reference types stored in the array, those\\ninstan\", \"ces themselves may still have their data mutated). As a result, ImmutableArray<T> also has an\\nassoci\", \"ated \\u201cbuilder\\u201d type, which does support mutation: you create the builder, populate it, and then\\ntran\", \"sfer that contents to an ImmutableArray<T> which is frozen forevermore. In\\ndotnet/runtime#70850 from\", \" [@grbell-ms](https://github.com/grbell-ms), the builder\\u2019s Sort method is\\nchanged to use a span, whi\", \"ch in turn avoids an IComparer<T> allocation and a Comparison<T>\\n150 CHAPTER 12 | Collectionsallocat\", \"ion, while also speeding up the sort itself by removing several layers of indirection from every\\ncom\", \"parison.\\nprivate ImmutableArray<int>.Builder _builder = ImmutableArray.CreateBuilder<int>();\\n[Global\", \"Setup]\\npublic void Setup()\\n{\\n_builder.AddRange(Enumerable.Range(0, 1_000));\\n}\\n[Benchmark]\\npublic voi\", \"d Sort()\\n{\\n_builder.Sort((left, right) => right.CompareTo(left));\\n_builder.Sort((left, right) => lef\", \"t.CompareTo(right));\\n}\\nMethod Runtime Mean Ratio\\nSort .NET 6.0 86.28 us 1.00\\nSort .NET 7.0 67.17 us \", \"0.78\\ndotnet/runtime#61196 from [@lateapexearlyspeed](https://github.com/lateapexearlyspeed) brings\\nI\", \"mmutableArray<T> into the span-based era, adding around 10 new methods to ImmutableArray<T>\\nthat int\", \"eroperate with Span<T> and ReadOnlySpan<T>. These are valuable from a performance\\nperspective becaus\", \"e it means if you have your data in a span, you can get it into an\\nImmutableArray<T> without incurri\", \"ng additional allocations beyond the one the ImmutableArray<T>\\nitself will create. dotnet/runtime#66\", \"550 from [@RaymondHuy](https://github.com/RaymondHuy) also\\nadds a bunch of new methods to the immuta\", \"ble collection builders, which provide efficient\\nimplementations for operations like replacing eleme\", \"nts and adding, inserting, and removing ranges.\\nSortedSet<T> also saw some improvements in .NET 7. F\", \"or example, SortedSet<T> internally uses a\\nred/black tree as its internal data structure, and it use\", \"s a Log2 operation to determine the maximum\\ndepth the tree could be for a given node count. Previous\", \"ly, that operation was implemented as a loop.\\nBut thanks to dotnet/runtime#58793 from [@teo-tsirpani\", \"s](https://github.com/teo-tsirpanis) that\\nimplementation is now simply a call to BitOperations.Log2,\", \" which is in turn implemented trivially in\\nterms of one of multiple hardware intrinsics if they\\u2019re s\", \"upported (e.g. Lzcnt.LeadingZeroCount,\\nArmBase.LeadingZeroCount, X86Base.BitScanReverse). And dotnet\", \"/runtime#56561 from\\n[@johnthcall](https://github.com/johnthcall) improves SortedSet<T> copy performa\", \"nce by\\nstreamlining how the iteration through the nodes in the tree is handled.\\n[Params(100)]\\npublic\", \" int Count { get; set; }\\nprivate static SortedSet<string> _set;\\n[GlobalSetup]\\npublic void GlobalSetu\", \"p()\\n{\\n_set = new SortedSet<string>(StringComparer.OrdinalIgnoreCase);\\nfor (int i = 0; i < Count; i++\", \")\\n{\\n_set.Add(Guid.NewGuid().ToString());\\n151 CHAPTER 12 | Collections}\\n}\\n[Benchmark]\\npublic SortedSe\", \"t<string> SortedSetCopy()\\n{\\nreturn new SortedSet<string>(_set, StringComparer.OrdinalIgnoreCase);\\n}\\n\", \"Method Runtime Mean Ratio\\nSortedSetCopy .NET 6.0 2.397 us 1.00\\nSortedSetCopy .NET 7.0 2.090 us 0.87\\n\", \"One last PR to look at in collections: dotnet/runtime#67923. ConditionalWeakTable<TKey, TValue>\\nis a\", \" collection most developers haven\\u2019t used, but when you need it, you need it. It\\u2019s used primarily for\", \"\\ntwo purposes: to associate additional state with some object, and to maintain a weak collection of\\n\", \"objects. Essentially, it\\u2019s a thread-safe dictionary that doesn\\u2019t maintain strong references to anyth\", \"ing it\\nstores but ensures that the value associated with a key will remain rooted as long as the ass\", \"ociated\\nkey is rooted. It exposes many of the same APIs as ConcurrentDictionary<,>, but for adding i\", \"tems\\nto the collection, it\\u2019s historically only had an Add method. That means if the design of the co\", \"nsuming\\ncode entailed trying to use the collection as a set, where duplicates were common, it would \", \"also be\\ncommon to experience exceptions when trying to Add an item that already existed in the colle\", \"ction.\\nNow in .NET 7, it has a TryAdd method, which enables such usage without potentially incurring\", \" the\\ncosts of such exceptions (and without needing to add try/catch blocks to defend against them).\\n\", \"152 CHAPTER 12 | Collections13\\nCHAPTER\\nLINQ\\nLet\\u2019s move on to Language-Integrated Query (LINQ). LINQ \", \"is a productivity feature that practically\\nevery .NET developer uses. It enables otherwise complicat\", \"ed operations to be trivially expressed,\\nwhether via language-integrated query comprehension syntax \", \"or via direct use of methods on\\nSystem.Linq.Enumerable. That productivity and expressivity, however,\", \" comes at a bit of an overhead\\ncost. In the vast majority of situations, those costs (such as delega\", \"te and closure allocations, delegate\\ninvocations, use of interface methods on arbitrary enumerables \", \"vs direct access to indexers and\\nLength/Count properties, etc.) don\\u2019t have a significant impact, but\", \" for really hot paths, they can and\\ndo show up in a meaningful way. This leads some folks to declare\", \" LINQ as being broadly off-limits in\\ntheir codebases. From my perspective, that\\u2019s misguided; LINQ is\", \" extremely useful and has its place. In\\n.NET itself, we use LINQ, we\\u2019re just practical and thoughtfu\", \"l about where, avoiding it in code paths\\nwe\\u2019ve optimized to be lightweight and fast due to expectati\", \"ons that such code paths could matter to\\nconsumers. And as such, while LINQ itself may not perform a\", \"s fast as a hand-rolled solution, we still\\ncare a lot about the performance of LINQ\\u2019s implementation\", \", so that it can be used in more and more\\nplaces, and so that where it\\u2019s used there\\u2019s as little over\", \"head as possible. There are also differences\\nbetween operations in LINQ; with over 200 overloads pro\", \"viding various kinds of functionality, some of\\nthese overloads benefit from more performance tuning \", \"than do others, based on their expected\\nusage.\\ndotnet/runtime#64470 is the result of analyzing vario\", \"us real-world code bases for use of\\nEnumerable.Min and Enumerable.Max, and seeing that it\\u2019s very com\", \"mon to use these with arrays,\\noften ones that are quite large. This PR updates the Min<T>(IEnumerabl\", \"e<T>) and\\nMax<T>(IEnumerable<T>) overloads when the input is an int[] or long[] to vectorize the\\npro\", \"cessing, using Vector<T>. The net effect of this is significantly faster execution time for larger\\na\", \"rrays, but still improved performance even for short arrays (because the implementation is now able\\n\", \"to access the array directly rather than going through the enumerable, leading to less allocation an\", \"d\\ninterface dispatch and more applicable optimizations like inlining).\\n[Params(4, 1024)]\\npublic int \", \"Length { get; set; }\\nprivate IEnumerable<int> _source;\\n[GlobalSetup]\\npublic void Setup() => _source \", \"= Enumerable.Range(1, Length).ToArray();\\n[Benchmark]\\npublic int Min() => _source.Min();\\n[Benchmark]\\n\", \"public int Max() => _source.Max();\\n153 CHAPTER 13 | LINQMethod Runtime Length Mean Ratio Allocated A\", \"lloc Ratio\\nMin .NET 6.0 4 26.167 ns 1.00 32 B 1.00\\nMin .NET 7.0 4 4.788 ns 0.18 - 0.00\\nMax .NET 6.0 \", \"4 25.236 ns 1.00 32 B 1.00\\nMax .NET 7.0 4 4.234 ns 0.17 - 0.00\\nMin .NET 6.0 1024 3,987.102 ns 1.00 3\", \"2 B 1.00\\nMin .NET 7.0 1024 101.830 ns 0.03 - 0.00\\nMax .NET 6.0 1024 3,798.069 ns 1.00 32 B 1.00\\nMax \", \".NET 7.0 1024 100.279 ns 0.03 - 0.00\\nOne of the more interesting aspects of the PR, however, is one \", \"line that\\u2019s meant to help with the non-\\narray cases. In performance optimization, and in particular \", \"when adding \\u201cfast paths\\u201d to better handle\\ncertain cases, there\\u2019s almost always a winner and a loser:\", \" the winner is the case the optimization is\\nintended to help, and the loser is every other case that\", \"\\u2019s penalized by whatever checks are necessary\\nto determine whether to take the improved path. An opt\", \"imization that special-cases arrays might\\nnormally look like:\\nif (source is int[] array)\\n{\\nProcessAr\", \"ray(array);\\n}\\nelse\\n{\\nProcessEnumerable(source);\\n}\\nHowever, if you look at the PR, you\\u2019ll see the if \", \"condition is actually:\\nif (source.GetType() == typeof(int[]))\\nHow come? Well at this point in the co\", \"de flow, we know that source isn\\u2019t null, so we don\\u2019t need the\\nextra null check that is will bring. H\", \"owever, that\\u2019s minor compared to the real impact here, that of\\nsupport for array covariance. It migh\", \"t surprise you to learn that there are types beyond int[] that will\\nsatisfy a source is int check\\u2026 t\", \"ry running Console.WriteLine((object)new uint[42] is\\nint[]);, and you\\u2019ll find it prints out True. (T\", \"his is also a rare case where the .NET runtime and C# the\\nlanguage disagree on aspects of the type s\", \"ystem. If you change that\\nConsole.WriteLine((object)new uint[42] is int[]); to instead be Console.Wr\", \"iteLine(new\\nuint[42] is int[]);, i.e. remove the (object) cast, you\\u2019ll find it starts printing out F\", \"alse instead of\\nTrue. That\\u2019s because the C# compiler believes it\\u2019s impossible for a uint[] to ever b\", \"e an int[], and\\nthus optimizes the check away entirely to be a constant false.) Thus the runtime is \", \"having to do more\\nwork as part of the type check than just a simple comparison against the known typ\", \"e identity of\\n154 CHAPTER 13 | LINQint[]. We can see this by looking at the assembly generated for t\", \"hese two methods (the latter\\nassumes we\\u2019ve already null-checked the input, which is the case in thes\", \"e LINQ methods):\\npublic IEnumerable<object> Inputs { get; } = new[] { new object() };\\n[Benchmark]\\n[A\", \"rgumentsSource(nameof(Inputs))]\\npublic bool M1(object o) => o is int[];\\n[Benchmark]\\n[ArgumentsSource\", \"(nameof(Inputs))]\\npublic bool M2(object o) => o.GetType() == typeof(int[]);\\nThis results in:\\n; Progr\", \"am.M1(System.Object)\\nsub rsp,28\\nmov rcx,offset MT_System.Int32[]\\ncall qword ptr\\n[System.Runtime.Comp\", \"ilerServices.CastHelpers.IsInstanceOfAny(Void*, System.Object)]\\ntest rax,rax\\nsetne al\\nmovzx eax,al\\na\", \"dd rsp,28\\nret\\n; Total bytes of code 34\\n; Program.M2(System.Object)\\nmov rax,offset MT_System.Int32[]\\n\", \"cmp [rdx],rax\\nsete al\\nmovzx eax,al\\nret\\n; Total bytes of code 20\\nNote the former involves a method ca\", \"ll to the JIT\\u2019s CastHelpers.IsInstanceOfAny helper method,\\nand that it\\u2019s not inlined. That in turn i\", \"mpacts performance:\\nprivate IEnumerable<int> _source = (int[])(object)new uint[42];\\n[Benchmark(Basel\", \"ine = true)]\\npublic bool WithIs() => _source is int[];\\n[Benchmark]\\npublic bool WithTypeCheck() => _s\", \"ource.GetType() == typeof(int[]);\\nMethod Mean Ratio Code Size\\nWithIs 1.9246 ns 1.000 215 B\\nWithTypeC\", \"heck 0.0013 ns 0.001 24 B\\nOf course, these two operations aren\\u2019t semantically equivalent, so if this\", \" was for something that\\nrequired the semantics of the former, we couldn\\u2019t use the latter. But in the\", \" case of this LINQ\\nperformance optimization, we can choose to only optimize the int[] case, forego t\", \"he super rare case\\n155 CHAPTER 13 | LINQof the int[] actually being a uint[] (or e.g. DayOfWeek[]), \", \"and minimize the performance penalty of\\nthe optimization for IEnumerable<int> inputs other than int[\", \"] to just a few quick instructions.\\nThis improvement was built upon further in dotnet/runtime#64624,\", \" which expands the input types\\nsupported and the operations that take advantage. First, it introduce\", \"d a private helper for extracting a\\nReadOnlySpan<T> from certain types of IEnumerable<T> inputs, nam\", \"ely today those inputs that are\\nactually either a T[] or a List<T>; as with the previous PR, it uses\", \" the GetType() == typeof(T[])\\nform to avoid significantly penalizing other inputs. Both of these typ\", \"es enable extracting a\\nReadOnlySpan<T> for the actual storage, in the case of T[] via a cast and in \", \"the case of List<T> via\\nthe CollectionsMarshal.AsSpan method that was introduced in .NET 5. Once we \", \"have that span, we\\ncan do a few interesting things. This PR:\\n\\u2022 Expands the previous Min<T>(IEnumerab\", \"le<T>) and Max<T>(IEnumerable<T>) optimizations to\\nnot only apply to int[] and long[] but also to Li\", \"st<int> and List<long>.\\n\\u2022 Uses direct span access for Average<T>(IEnumerable<T>) and Sum<T>(IEnumera\", \"ble<T>) for T\\nbeing int, long, float, double, or decimal, all for arrays and lists.\\n\\u2022 Similarly uses\", \" direct span access for Min<T>(IEnumerable<T>) and Max<T>(IEnumerable<T>) for\\nT being float, double,\", \" and decimal.\\n\\u2022 Vectorizes Average<int>(IEnumerable<int>) for arrays and lists\\nThe effect of that is\", \" evident in microbenchmarks, e.g.\\nprivate static float[] CreateRandom()\\n{\\nvar r = new Random(42);\\nva\", \"r results = new float[10_000];\\nfor (int i = 0; i < results.Length; i++)\\n{\\nresults[i] = (float)r.Next\", \"Double();\\n}\\nreturn results;\\n}\\nprivate IEnumerable<float> _floats = CreateRandom();\\n[Benchmark]\\npubli\", \"c float Sum() => _floats.Sum();\\n[Benchmark]\\npublic float Average() => _floats.Average();\\n[Benchmark]\", \"\\npublic float Min() => _floats.Min();\\n[Benchmark]\\npublic float Max() => _floats.Max();\\nMethod Runtim\", \"e Mean Ratio Allocated Alloc Ratio\\nSum .NET 6.0 39.067 us 1.00 32 B 1.00\\nSum .NET 7.0 14.349 us 0.37\", \" - 0.00\\nAverage .NET 6.0 41.232 us 1.00 32 B 1.00\\n156 CHAPTER 13 | LINQMethod Runtime Mean Ratio All\", \"ocated Alloc Ratio\\nAverage .NET 7.0 14.378 us 0.35 - 0.00\\nMin .NET 6.0 45.522 us 1.00 32 B 1.00\\nMin \", \".NET 7.0 9.668 us 0.21 - 0.00\\nMax .NET 6.0 41.178 us 1.00 32 B 1.00\\nMax .NET 7.0 9.210 us 0.22 - 0.0\", \"0\\nThe previous LINQ PRs were examples from making existing operations faster. But sometimes\\nperforma\", \"nce improvements come about from new APIs that can be used in place of previous ones in\\ncertain situ\", \"ations to further improve performance. One such example of that comes from new APIs\\nintroduced in do\", \"tnet/runtime#70525 from [@deeprobin](https://github.com/deeprobin) which were\\nthen improved in dotne\", \"t/runtime#71564. One of the most popular methods in LINQ is\\nEnumerable.OrderBy (and its inverse Orde\", \"rByDescending), which enables creating a sorted copy of\\nthe input enumerable. To do so, the caller p\", \"asses a Func<TSource,TKey> predicate to OrderBy which\\nOrderBy uses to extract the comparison key for\", \" each item. However, it\\u2019s relatively common to want to\\nsort items with themselves as the keys; this \", \"is, after all, the default for methods like Array.Sort, and in\\nsuch cases callers of OrderBy end up \", \"passing in an identity function, e.g. OrderBy(x => x). To\\neliminate that cruft, .NET 7 introduces th\", \"e new Order and OrderDescending methods, which, in the\\nspirit of pairs like Distinct and DistinctBy,\", \" perform that same sorting operation, just with an implicit\\nx => x done on behalf of the caller. But\", \" beyond performance, a nice benefit of this is the\\nimplementation then knows that the keys will all \", \"be the same as the inputs, and it no longer needs to\\ninvoke the callback for each item to retrieve i\", \"ts key nor allocate a new array to store those keys. Thus\\nif you find yourself using LINQ and reachi\", \"ng for OrderBy(x => x), consider instead using Order()\\nand reaping the (primarily allocation) benefi\", \"ts:\\n[Params(1024)]\\npublic int Length { get; set; }\\nprivate int[] _arr;\\n[GlobalSetup]\\npublic void Set\", \"up() => _arr = Enumerable.Range(1, Length).Reverse().ToArray();\\n[Benchmark(Baseline = true)]\\npublic \", \"void OrderBy()\\n{\\nforeach (int _ in _arr.OrderBy(x => x)) { }\\n}\\n[Benchmark]\\npublic void Order()\\n{\\nfor\", \"each (int _ in _arr.Order()) { }\\n}\\n157 CHAPTER 13 | LINQMethod Length Mean Ratio Allocated Alloc Rat\", \"io\\nOrderBy 1024 68.74 us 1.00 12.3 KB 1.00\\nOrder 1024 66.24 us 0.96 8.28 KB 0.67\\n158 CHAPTER 13 | LI\", \"NQ14\\nCHAPTER\\nFile I/O\\n.NET 6 saw some huge file I/O improvements, in particular a complete rewrite o\", \"f FileStream. While\\n.NET 7 doesn\\u2019t have any single changes on that scale, it does have a significant\", \" number of\\nimprovements that measurably \\u201cmove the needle,\\u201d and in variety of ways.\\nOne form of perfo\", \"rmance improvement that also masquerades as a reliability improvement is\\nincreasing responsiveness t\", \"o cancellation requests. The faster something can be canceled, the sooner\\nthe system is able to give\", \" back valuable resources in use, and the sooner things waiting for that\\noperation to complete are ab\", \"le to be unblocked. There have been several improvements of this ilk in\\n.NET 7.\\nIn some cases, it co\", \"mes from adding cancelable overloads where things weren\\u2019t previously cancelable\\nat all. That\\u2019s the c\", \"ase for dotnet/runtime#61898 from [@bgrainger](https://github.com/bgrainger),\\nwhich added new cancel\", \"able overloads of TextReader.ReadLineAsync and\\nTextReader.ReadToEndAsync, and that includes override\", \"s of these methods on StreamReader and\\nStringReader; dotnet/runtime#64301 from [@bgrainger](https://\", \"github.com/bgrainger) then\\noverrode these methods (and others missing overrides) on the NullStreamRe\", \"ader type returned from\\nTextReader.Null and StreamReader.Null (interestingly, these were defined as \", \"two different types,\\nunnecessarily, and so this PR also unified on just having both use the StreamRe\", \"ader variant, as it\\nsatisfies the required types of both). You can see this put to good use in dotne\", \"t/runtime#66492 from\\n[@lateapexearlyspeed](https://github.com/lateapexearlyspeed), which adds a new\\n\", \"File.ReadLinesAsync method. This produces an IAsyncEnumerable<string> of the lines in the file,\\nis b\", \"ased on a simple loop around the new StreamReader.ReadLineAsync overload, and is thus itself\\nfully c\", \"ancelable.\\nFrom my perspective, though, a more interesting form of this is when an existing overload\", \" is\\npurportedly cancelable but isn\\u2019t actually. For example, the base Stream.ReadAsync method just wr\", \"aps\\nthe Stream.BeginRead/EndRead methods, which aren\\u2019t cancelable, so if a Stream-derived type doesn\", \"\\u2019t\\noverride ReadAsync, attempts to cancel a call to its ReadAsync will be minimally effective. It do\", \"es an\\nup-front check for cancellation, such that if cancellation was requested prior to the call bei\", \"ng made, it\\nwill be immediately canceled, but after that check the supplied CancellationToken is eff\", \"ectively\\nignored. Over time we\\u2019ve tried to stamp out all remaining such cases, but a few stragglers \", \"have\\nremained. One pernicious case has been with pipes. For this discussion, there are two relevant \", \"kinds of\\npipes, anonymous and named, which are represented in .NET as pairs of streams:\\nAnonymousPip\", \"eClientStream/AnonymousPipeServerStream and\\nNamedPipeClientStream/NamedPipeServerStream. Also, on Wi\", \"ndows, the OS makes a distinction\\nbetween handles opened for synchronous I/O from handles opened for\", \" overlapped I/O (aka\\nasynchronous I/O), and this is reflected in the .NET API: you can open a named \", \"pipe for synchronous\\nor overlapped I/O based on the PipeOptions.Asynchronous option specified at con\", \"struction. And, on\\n159 CHAPTER 14 | File I/OUnix, named pipes, contrary to their naming, are actuall\", \"y implemented on top of Unix domain sockets.\\nNow some history:\\n\\u2022 .NET Framework 4.8: No cancellation\", \" support. The pipe Stream-derived types didn\\u2019t even\\noverride ReadAsync or WriteAsync, so all they go\", \"t was the default up-front check for\\ncancellation and then the token was ignored.\\n\\u2022 .NET Core 1.0: O\", \"n Windows, with a named pipe opened for asynchronous I/O, cancellation was\\nfully supported. The impl\", \"ementation would register with the CancellationToken, and upon a\\ncancellation request, would use Can\", \"celIoEx for the NativeOverlapped* associated with the\\nasynchronous operation. On Unix, with named pi\", \"pes implemented in terms of sockets, if the pipe\\nwas opened with PipeOptions.Asynchronous, the imple\", \"mentation would simulate cancellation\\nvia polling: rather than simply issuing the Socket.ReceiveAsyn\", \"c/Socket.SendAsync (which\\nwasn\\u2019t cancelable at the time), it would queue a work item to the ThreadPo\", \"ol, and that work\\nitem would run a polling loop, making Socket.Poll calls with a small timeout, chec\", \"king the\\ntoken, and then looping around to do it again until either the Poll indicated the operation\", \"\\nwould succeed or cancellation was requested. On both Windows and Unix, other than a named\\npipe open\", \"ed with Asynchronous, after the operation was initated, cancellation was a nop.\\n\\u2022 .NET Core 2.1: On \", \"Unix, the implementation was improved to avoid the polling loop, but it still\\nlacked a truly cancela\", \"ble Socket.ReceiveAsync/Socket.SendAsync. Instead, by this point\\nSocket.ReceiveAsync supported zero-\", \"byte reads, where a caller could pass a zero-length buffer\\nto ReceiveAsync and use that as notificat\", \"ion for data being available to consume without\\nactually consuming it. The Unix implementation for a\", \"synchronous named pipe streams then\\nchanged to issue zero-byte reads, and would await a Task.WhenAny\", \" of both that operation\\u2019s\\ntask and a task that would be completed when cancellation was requested. B\", \"etter, but still far\\nfrom ideal.\\n\\u2022 .NET Core 3.0: On Unix, Socket got truly cancelable ReceiveAsync \", \"and SendAsync methods,\\nwhich asynchronous named pipes were updated to utilize. At this point, the Wi\", \"ndows and Unix\\nimplementations were effectively on par with regards to cancellation; both good for\\na\", \"synchronous named pipes, and just posing for everything else.\\n\\u2022 .NET 5: On Unix, SafeSocketHandle wa\", \"s exposed and it became possible to create a Socket for\\nan arbitrary supplied SafeSocketHandle, whic\", \"h enabled creating a Socket that actually referred\\nto an anonymous pipe. This in tern enabled every \", \"PipeStream on Unix to be implemented in\\nterms of Socket, which enabled ReceiveAsync/SendAsync to be \", \"fully cancelable for both\\nanonymous and named pipes, regardless of how they were opened.\\nSo by .NET \", \"5, the problem was addressed on Unix, but still an issue on Windows. Until now. In .NET 7,\\nwe\\u2019ve mad\", \"e the rest of the operations fully cancelable on Windows as well, thanks to\\ndotnet/runtime#72503 (an\", \"d a subsequent tweak in dotnet/runtime#72612). Windows doesn\\u2019t support\\noverlapped I/O for anonymous \", \"pipes today, so for anonymous pipes and for named pipes opened for\\nsynchronous I/O, the Windows impl\", \"ementation would just delegate to the base Stream\\nimplementation, which would queue a work item to t\", \"he ThreadPool to invoke the synchronous\\ncounterpart, just on another thread. Instead, the implementa\", \"tions now queue that work item, but\\ninstead of just calling the synchronous method, it does some pre\", \"- and post- work that registers for\\ncancellation, passing in the thread ID of the thread that\\u2019s abou\", \"t to perform the I/O. If cancellation is\\nrequested, the implementation then uses CancelSynchronousIo\", \" to interrupt it. There\\u2019s a race\\ncondition here, in that the moment the thread registers for cancell\", \"ation, cancellation could be\\nrequested, such that CancelSynchronousIo could be called before the ope\", \"ration is actually initiated.\\n160 CHAPTER 14 | File I/OSo, there\\u2019s a small spin loop employed, where\", \" if cancellation is requested between the time\\nregistration occurs and the time the synchronous I/O \", \"is actually performed, the cancellation thread\\nwill spin until the I/O is initiated, but this condit\", \"ion is expected to be exceedingly rare. There\\u2019s also a\\nrace condition on the other side, that of Can\", \"celSynchronousIo being requested after the I/O has\\nalready completed; to address that race, the impl\", \"ementation relies on the guarantees made by\\nCancellationTokenRegistration.Dispose, which promises th\", \"at the associated callback will either\\nnever be invoked or will already have fully completed executi\", \"ng by the time Dispose returns. Not only\\ndoes this implementation complete the puzzle such that all \", \"asynchronous read/write operations on\\nboth anonymous and named pipes on both Windows and Unix are ca\", \"ncelable, it also actually\\nimproves normal throughput.\\nprivate Stream _server;\\nprivate Stream _clien\", \"t;\\nprivate byte[] _buffer = new byte[1];\\nprivate CancellationTokenSource _cts = new CancellationToke\", \"nSource();\\n[Params(false, true)]\\npublic bool Cancelable { get; set; }\\n[Params(false, true)]\\npublic b\", \"ool Named { get; set; }\\n[GlobalSetup]\\npublic void Setup()\\n{\\nif (Named)\\n{\\nstring name = Guid.NewGuid(\", \").ToString(\\\"N\\\");\\nvar server = new NamedPipeServerStream(name, PipeDirection.Out);\\nvar client = new N\", \"amedPipeClientStream(\\\".\\\", name, PipeDirection.In);\\nTask.WaitAll(server.WaitForConnectionAsync(), cli\", \"ent.ConnectAsync());\\n_server = server;\\n_client = client;\\n}\\nelse\\n{\\nvar server = new AnonymousPipeServ\", \"erStream(PipeDirection.Out);\\nvar client = new AnonymousPipeClientStream(PipeDirection.In,\\nserver.Cli\", \"entSafePipeHandle);\\n_server = server;\\n_client = client;\\n}\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n\", \"_server.Dispose();\\n_client.Dispose();\\n}\\n[Benchmark(OperationsPerInvoke = 1000)]\\npublic async Task Re\", \"adWriteAsync()\\n{\\nCancellationToken ct = Cancelable ? _cts.Token : default;\\nfor (int i = 0; i < 1000;\", \" i++)\\n{\\n161 CHAPTER 14 | File I/OValueTask<int> read = _client.ReadAsync(_buffer, ct);\\nawait _server\", \".WriteAsync(_buffer, ct);\\nawait read;\\n}\\n}\\nMethod Runtime Cancelable Named Mean Ratio Allocated Alloc\", \" Ratio\\nReadWriteAsync .NET 6.0 False False 22.08 us 1.00 400 B 1.00\\nReadWriteAsync .NET 7.0 False Fa\", \"lse 12.61 us 0.76 192 B 0.48\\nReadWriteAsync .NET 6.0 False True 38.45 us 1.00 400 B 1.00\\nReadWriteAs\", \"ync .NET 7.0 False True 32.16 us 0.84 220 B 0.55\\nReadWriteAsync .NET 6.0 True False 27.11 us 1.00 40\", \"0 B 1.00\\nReadWriteAsync .NET 7.0 True False 13.29 us 0.52 193 B 0.48\\nReadWriteAsync .NET 6.0 True Tr\", \"ue 38.57 us 1.00 400 B 1.00\\nReadWriteAsync .NET 7.0 True True 33.07 us 0.86 214 B 0.54\\nThe rest of t\", \"he performance-focused changes around I/O in .NET 7 were primarily focused on one of\\ntwo things: red\", \"ucing syscalls, and reducing allocation.\\nSeveral PRs went into reducing syscalls on Unix as part of \", \"copying files, e.g. File.Copy and\\nFileInfo.CopyTo. dotnet/runtime#59695 from [@tmds](https://github.\", \"com/tmds) reduced overheads\\nin several ways. The code had been performing a stat call in order to de\", \"termine up front whether the\\nsource was actually a directory, in which case the operation would erro\", \"r out. Instead, the PR simply\\ntries to open the source file, which it would need to do anyway for th\", \"e copy operation, and then it\\nonly performs that stat if opening the file fails. If opening the file\", \" succeeds, the code was already\\nperforming an fstat to gather data on the file, such as whether it w\", \"as seekable; with this change, it\\nnow also extracts from the results of that single fstat the source\", \" file size, which it then threads\\nthrough to the core copy routine, which itself is then able to avo\", \"id an fstat syscall it had been\\nperforming in order to get the size. Saving those syscalls is great,\", \" in particular for very small files\\nwhere the overhead of setting up the copy can actually be more e\", \"xpensive than the actual copy of the\\nbytes. But the biggest benefit of this PR is that it takes adva\", \"ntage of IOCTL-FICLONERANGE on Linux.\\nSome Linux file systems, like XFS and Btrfs, support \\u201ccopy-on-\", \"write,\\u201d which means that rather than\\ncopying all of the data to a new file, the file system simply n\", \"otes that there are two different files\\npointing to the same data, sharing the underlying storage. T\", \"his makes the \\u201ccopy\\u201d super fast, since\\nnothing actually needs to be copied and instead the file syst\", \"em just needs to update some\\nbookkeeping; plus, less space is consumed on disk, since there\\u2019s just a\", \" single store of the data. The file\\nsystem then only needs to actually copy data that\\u2019s overwritten \", \"in one of the files. This PR uses ioctl\\nand FICLONE to perform the copy as copy-on-write if the sour\", \"ce and destination file system are the\\nsame and the file system supports the operation. In a similar\", \" vein, dotnet/runtime#64264 from\\n[@tmds](https://github.com/tmds) further improves File.Copy/FileInf\", \"o.CopyTo by utilizing\\ncopy_file_range on Linux if it\\u2019s supported (and only if it\\u2019s a new enough kern\", \"el that it addresses\\n162 CHAPTER 14 | File I/Osome issues the function had in previous releases). Un\", \"like a typical read/write loop that reads the data\\nfrom the source and then writes it to the destina\", \"tion, copy_file_range is implemented to stay\\nentirely in kernel mode, without having to transition t\", \"o user space for each read and write.\\nAnother example of avoiding syscalls comes for the File.WriteX\", \"x and File.AppendXx methods when\\non Unix. The implementation of these methods opens a FileStream or \", \"a SafeFileHandle directly,\\nand it was specifying FileOptions.SequentialScan. SequentialScan is prima\", \"rily relevant for reading\\ndata from a file, and hints to OS caching to expect data to be read from t\", \"he file sequentially rather\\nthan randomly. However, these write/append methods don\\u2019t read, they only\", \" write, and the\\nimplementation of FileOptions.SequentialScan on Unix requires an additional syscall \", \"via\\nposix_fadvise (passing in POSIX_FADV_SEQUENTIAL); thus, we\\u2019re paying for a syscall and not\\nbenef\", \"iting from it. This situation is akin to the famous Henny Youngman joke: \\u201cThe patient says,\\n\\u2018Doctor,\", \" it hurts when I do this\\u2019; the doctor says, \\u2018Then don\\u2019t do that!\\u2019.\\u201d Here, too, the answer is \\u201cdon\\u2019t\\n\", \"do that,\\u201d and so dotnet/runtime#59247 from [@tmds](https://github.com/tmds) simply stops passing\\nSeq\", \"uentialScan in places where it won\\u2019t help but may hurt.\\nDirectory handling has seen reduced syscalls\", \" across the directory lifecycle, especially on Unix.\\ndotnet/runtime#58799 from [@tmds](https://githu\", \"b.com/tmds) speeds up directory creation on Unix.\\nPreviously, the implementation of directory creati\", \"on would first check to see if the directory already\\nexisted, which involves a syscall. In the expec\", \"ted minority case where it already existed the code could\\nearly exit out. But in the expected more c\", \"ommon case where the directory didn\\u2019t exist, it would then\\nparse the file path to find all of the di\", \"rectories in it, walk up the directory list until it found one that\\ndid exist, and then try to creat\", \"e all of the subdirectories back down through the target one. However,\\nthe expected most common case\", \" is the parent directories already exist and the child directory doesn\\u2019t,\\nin which case we\\u2019re still \", \"paying for all that parsing when we could have just created the target\\ndirectory. This PR addresses \", \"that by changing the up-front existence check to instead simply try to\\nmkdir the target directory; i\", \"f it succeeds, great, we\\u2019re done, and if it fails, the error code from the\\nfailure can be used inste\", \"ad of the existence check to know whether mkdir failed because it had no\\nwork to do. dotnet/runtime#\", \"61777 then takes this a step further and avoids string allocations while\\ncreating directories by usi\", \"ng stack memory for the paths temporarily needed to pass to mkdir.\\ndotnet/runtime#63675 then improve\", \"s the performance of moving directories, on both Unix and\\nWindows, removing several syscalls. The sh\", \"ared code for Directory.Move and DirectorInfo.MoveTo\\nwas doing explicit directory existence checks f\", \"or the source and destination locations, but on\\nWindows the Win32 API called to perform the move doe\", \"s such checks itself, so they\\u2019re not needed\\npreemptively. On Unix, we can similarly avoid the existe\", \"nce check for the source directory, as the\\nrename function called will similarly simply fail if the \", \"source doesn\\u2019t exist (with an appropriate error\\nthat let\\u2019s us deduce what went wrong so the right ex\", \"ception can be thrown), and for the destination,\\nthe code had been issuing separate existence checks\", \" for whether the destination existed as a directory\\nor as a file, but a single stat call suffices fo\", \"r both.\\nprivate string _path1;\\nprivate string _path2;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n_path1 = P\", \"ath.GetTempFileName();\\n_path2 = Path.GetTempFileName();\\n163 CHAPTER 14 | File I/OFile.Delete(_path1)\", \";\\nFile.Delete(_path2);\\nDirectory.CreateDirectory(_path1);\\n}\\n[Benchmark]\\npublic void Move()\\n{\\nDirecto\", \"ry.Move(_path1, _path2);\\nDirectory.Move(_path2, _path1);\\n}\\nMethod Runtime Mean Ratio Allocated Alloc\", \" Ratio\\nMove .NET 6.0 31.70 us 1.00 256 B 1.00\\nMove .NET 7.0 26.31 us 0.83 - 0.00\\nAnd then also on Un\", \"ix, dotnet/runtime#59520 from [@tmds](https://github.com/tmds) improves\\ndirectory deletion, and in p\", \"articular recursive deletion (deleting a directory and everything it contains\\nand everything they co\", \"ntain and so on), by utilizing the information already provided by the file\\nsystem enumeration to av\", \"oid a secondary existence check.\\nSyscalls were also reduced as part of support for memory-mapped fil\", \"es. dotnet/runtime#63754 takes\\nadvantage of special-casing to do so while opening a MemoryMappedFile\", \". When\\nMemoryMappedFile.CreateFromFile was called, one of the first things it would do is call File.\", \"Exists\\nto determine whether the specified file already exists; that\\u2019s because later in the method as\", \" part of\\ndealing with errors and exceptions, the implementation needs to know whether to delete the \", \"file that\\nmight then exist; the implementation constructs a FileStream, and doing might will the spe\", \"cified file\\ninto existence. However, that only happens for some FileMode values, which is configurab\", \"le via an\\nargument passed by callers of CreateFromFile. The common and default value of FileMode is\\n\", \"FileMode.Open, which requires that the file exist such that constructing the FileStream will throw i\", \"f it\\ndoesn\\u2019t. That means we only actually need to call File.Exists if the FileMode is something othe\", \"r\\nthan Open or CreateNew, which means we can trivially avoid the extra system call in the majority c\", \"ase.\\ndotnet/runtime#63790 also helps here, in two ways. First, throughout the CreateFromFile operati\", \"on,\\nthe implementation might access the FileStream\\u2019s Length multiple times, but each call results in\", \" a\\nsyscall to read the underlying length of the file. We can instead read it once and use that one v\", \"alue for\\nall of the various checks performed. Second, .NET 6 introduced the File.OpenHandle method w\", \"hich\\nenables opening a file handle / file descriptor directly into a SafeFileHandle, rather than hav\", \"ing to go\\nthrough FileStream to do so. The use of the FileStream in MemoryMappedFile is actually qui\", \"te\\nminimal, and so it makes sense to just use the SafeFileHandle directly rather than also construct\", \"ing\\nthe superfluous FileStream and its supporting state. This helps to reduce allocations.\\nFinally, \", \"there\\u2019s dotnet/runtime#63794, which recognizes that a MemoryMappedViewAccessor or\\nMemoryMappedViewSt\", \"ream opened for read-only access can\\u2019t have been written to. Sounds obvious,\\nbut the practical impli\", \"cation of this is that closing either needn\\u2019t bother flushing, since that view\\ncouldn\\u2019t have changed\", \" any data in the implementation, and flushing a view can be relatively\\nexpensive, especially for lar\", \"ger views. Thus, a simple change to avoid flushing if the view isn\\u2019t writable\\ncan yield a measurable\", \" improvement to MemoryMappedViewAccessor/MemoryMappedviewStream\\u2019s\\nDispose.\\n164 CHAPTER 14 | File I/O\", \"private string _path;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n_path = Path.GetTempFileName();\\nFile.Write\", \"AllBytes(_path, Enumerable.Range(0, 10_000_000).Select(i =>\\n(byte)i).ToArray());\\n}\\n[GlobalCleanup]\\np\", \"ublic void Cleanup()\\n{\\nFile.Delete(_path);\\n}\\n[Benchmark]\\npublic void MMF()\\n{\\nusing var mmf = MemoryM\", \"appedFile.CreateFromFile(_path, FileMode.Open, null);\\nusing var s = mmf.CreateViewStream(0, 10_000_0\", \"00, MemoryMappedFileAccess.Read);\\n}\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nMMF .NET 6.0 315\", \".7 us 1.00 488 B 1.00\\nMMF .NET 7.0 227.1 us 0.68 336 B 0.69\\nBeyond system calls, there have also bee\", \"n a plethora of improvements around reducing allocation.\\nOne such change is dotnet/runtime#58167, wh\", \"ich improved the performance of the commonly-used\\nFile.WriteAllText{Async} and File.AppendAllText{As\", \"ync} methods. The PR recognizes two\\nthings: one, that these operations are common enough that it\\u2019s w\", \"orth avoiding the small-but-\\nmeasurable overhead of going through a FileStream and instead just goin\", \"g directly to the\\nunderlying SafeFileHandle, and, two, that since the methods are passed the entiret\", \"y of the payload\\nto output, the implementation can use that knowledge (in particular for length) to \", \"do better than the\\nStreamWriter that was previously employed. In doing so, the implementation avoids\", \" the overheads\\n(primarily in allocation) of the streams and writers and temporary buffers.\\nprivate s\", \"tring _path;\\n[GlobalSetup]\\npublic void Setup() => _path = Path.GetRandomFileName();\\n[GlobalCleanup]\\n\", \"public void Cleanup() => File.Delete(_path);\\n[Benchmark]\\npublic void WriteAllText() => File.WriteAll\", \"Text(_path, Sonnet);\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nWriteAllText .NET 6.0 488.5 us \", \"1.00 9944 B 1.00\\nWriteAllText .NET 7.0 482.9 us 0.99 392 B 0.04\\n165 CHAPTER 14 | File I/Odotnet/runt\", \"ime#61519 similarly updates File.ReadAllBytes{Async} to use SafeFileHandle (and\\nRandomAccess) direct\", \"ly rather than going through FileStream, shaving off some allocation from each\\nuse. It also makes th\", \"e same SequentialScan change as mentioned earlier. While this case is about\\nreading (whereas the pre\", \"vious change saw SequentialScan being complete overhead with no\\nbenefit), ReadAllBytes{Async} is ver\", \"y frequently used to read smaller files where the overhead of the\\nadditional syscall can measure up \", \"to 10% of the total cost (and for larger files, modern kernels are\\npretty good about caching even wi\", \"thout a sequentiality hint, so there\\u2019s little downside measured\\nthere).\\nAnother such change is dotne\", \"t/runtime#68662, which improved Path.Join\\u2019s handling of null or\\nempty path segments. Path.Join has o\", \"verloads that accept strings and overloads that accept\\nReadOnlySpan<char>s, but all of the overloads\", \" produce strings. The string-based overloads just\\nwrapped each string in a span and delegated to the\", \" span-based overloads. However, in the event that\\nthe join operation is a nop (e.g. there are two pa\", \"th segments and the second is empty so the join\\nshould just return the first), the span-based implem\", \"entation still needs to create a new string (there\\u2019s\\nno way for the ReadOnlySpan<char>-based overloa\", \"ds to extract a string from the span). As such, the\\nstring-based overloads can do a little bit bette\", \"r in the case of one of them being null or empty; they\\ncan do the same thing the Path.Combine overlo\", \"ads do, which is to have the M argument overload\\ndelegate to the M-1 argument overload, filtering ou\", \"t a null or empty, and in the base case of the\\noverload with two arguments, if a segment is null or \", \"empty, the other (or empty) can just be returned\\ndirectly.\\nBeyond that, there are a multitude of all\", \"ocation-focused PRs, such as dotnet/runtime#69335 from\\n[@pedrobsaila](https://github.com/pedrobsaila\", \") which adds a fast-path based on stack allocation to\\nthe internal ReadLink helper that\\u2019s used on Un\", \"ix anywhere we need to follow symlinks, or\\ndotnet/runtime#68752 that updates NamedPipeClientStream.C\", \"onnectAsync to remove a delegate\\nallocation (by passing state into a Task.Factory.StartNew call expl\", \"icitly), or dotnet/runtime#69412\\nwhich adds an optimized Read(Span<byte>) override to the Stream ret\", \"urned from\\nAssembly.GetManifestResourceStream.\\nBut my personal favorite improvement in this area com\", \"e from dotnet/runtime#69272, which adds a\\nfew new helpers to Stream:\\npublic void ReadExactly(byte[] \", \"buffer, int offset, int count);\\npublic void ReadExactly(Span<byte> buffer);\\npublic ValueTask ReadExa\", \"ctlyAsync(byte[] buffer, int offset, int count, CancellationToken\\ncancellationToken = default);\\npubl\", \"ic ValueTask ReadExactlyAsync(Memory<byte> buffer, CancellationToken cancellationToken\\n= default);\\np\", \"ublic int ReadAtLeast(Span<byte> buffer, int minimumBytes, bool throwOnEndOfStream =\\ntrue);\\npublic V\", \"alueTask<int> ReadAtLeastAsync(Memory<byte> buffer, int minimumBytes, bool\\nthrowOnEndOfStream = true\", \", CancellationToken cancellationToken = default);\\nIn fairness, these are more about usability than t\", \"hey are about performance, but in this case there\\u2019s a\\ntight correlation between the two. It\\u2019s very c\", \"ommon to write these helpers one\\u2019s self (the\\naforementioned PR deleted many open-coded loops for thi\", \"s functionality from across the core\\nlibraries) as the functionality is greatly needed, and it\\u2019s unf\", \"ortunately easy to get them wrong in ways\\n166 CHAPTER 14 | File I/Othat negatively impact performanc\", \"e, such as by using a Stream.ReadAsync overload that needs to\\nallocate a returned Task<int> or readi\", \"ng fewer bytes than is allowed as part of a read call. These\\nimplementations are correct and efficie\", \"nt.\\n167 CHAPTER 14 | File I/O15\\nCHAPTER\\nCompression\\n.NET Core 2.1 added support for the Brotli compr\", \"ession algorithm, surfacing it in two ways:\\nBrotliStream and the pair of BrotliEncoder/BrotliDecoder\", \" structs that BrotliStream is itself built\\non top of. For the most part, these types just provide wr\", \"appers around a native C implementation\\nfrom google/brotli, and so while the .NET layer has the oppo\", \"rtunity to improve how data is moved\\naround, managed allocation, and so on, the speed and quality of\", \" the compression itself are largely at\\nthe mercy of the C implementation and the intricacies of the \", \"Brotli algorithm.\\nAs with many compression algorithms, Brotli provides a knob that allows for a quin\", \"tessential tradeoff\\nto be made between compression speed (how fast data can be compressed) and compr\", \"ession\\nquality/ratio (how small can the compressed output be made). The hand-wavy idea is the more t\", \"ime\\nthe algorithm spends looking for opportunity, the more space can be saved. Many algorithms expos\", \"e\\nthis as a numerical dial, in Brotli\\u2019s case going from 0 (fastest speed, least compression) to 11 (\", \"spend as\\nmuch time as is needed to minimize the output size). But while BrotliEncoder surfaces that \", \"same\\nrange, BrotliStream\\u2019s surface area is simpler: most use just specifies that compression should \", \"be\\nperformed (e.g. new BrotliStream(destination, CompressionMode.Compress)) and the only knob\\navaila\", \"ble is via the CompressionLevel enum (e.g. new BrotliStream(destination,\\nCompressionLevel.Fastest)),\", \" which provides just a few options: CompressionLevel.NoCompression,\\nCompressionLevel.Fastest, Compre\", \"ssionLevel.Optimal, and CompressionLevel.SmallestSize.\\nThis means the BrotliStream implementation ne\", \"eds to select a default value when no\\nCompressionLevel is specified and needs to map CompressionLeve\", \"l to an underlying numerical\\nvalue when one is.\\nFor better or worse (and I\\u2019m about to argue \\u201cmuch wo\", \"rse\\u201d), the native C implementation itself defines\\nthe default to be 11 (google/brotli#encode.h), and\", \" so that\\u2019s what BrotliStream has ended up using\\nwhen no CompressionLevel is explicitly specified. Fu\", \"rther, the CompressionLevel.Optimal enum\\nvalue is poorly named. It\\u2019s intended to represent a good de\", \"fault that\\u2019s a balanced tradeoff between\\nspeed and quality; that\\u2019s exactly what it means for Deflate\", \"Stream, GZipStream, and ZLibStream. But\\nfor BrotliStream, as the default it similarly got translated\", \" to mean the underlying native library\\u2019s\\ndefault, which is 11. This means that when constructing a B\", \"rotliStream with either\\nCompressionMode.Compress or CompressionLevel.Optimal, rather than getting a \", \"nice balanced\\ndefault, you\\u2019re getting the dial turned all the way up to 11.\\nIs that so bad? Maybe co\", \"mpression quality is the most important thing? For example, reducing the\\nsize of data can make it fa\", \"ster to then transmit it over a wire, and with a slow connection, size then\\nmeaningfully translates \", \"into end-to-end throughput.\\nThe problem is just how much this extra effort costs. Compression speed \", \"and ratio are highly\\ndependent on the data being compressed, so take this example with a small grain\", \" of salt as it\\u2019s not\\nentirely representative of all use, but it\\u2019s good enough for our purposes. Cons\", \"ider this code, which\\n168 CHAPTER 15 | Compressionuses BrotliEncoder to compress the The Complete Wo\", \"rks of William Shakespeare from Project\\nGutenberg at varying levels of compression:\\nusing System.Buf\", \"fers;\\nusing System.Diagnostics;\\nusing System.IO.Compression;\\nusing System.Text;\\nusing var hc = new H\", \"ttpClient();\\nbyte[] data = await hc.GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-\", \"8\\\");\\nConsole.WriteLine(data.Length);\\nvar compressed = new MemoryStream();\\nvar sw = new Stopwatch();\\n\", \"for (int level = 0; level <= 11; level++)\\n{\\nconst int Trials = 10;\\ncompressed.Position = 0;\\nCompress\", \"(level, data, compressed);\\nsw.Restart();\\nfor (int i = 0; i < Trials; i++)\\n{\\ncompressed.Position = 0;\", \"\\nCompress(level, data, compressed);\\n}\\nsw.Stop();\\nConsole.WriteLine($\\\"{level},{sw.Elapsed.TotalMillis\", \"econds /\\nTrials},{compressed.Position}\\\");\\nstatic void Compress(int level, byte[] data, Stream destin\", \"ation)\\n{\\nvar encoder = new BrotliEncoder(quality: level, window: 22);\\nWrite(ref encoder, data, desti\", \"nation, false);\\nWrite(ref encoder, Array.Empty<byte>(), destination, true);\\nencoder.Dispose();\\nstati\", \"c void Write(ref BrotliEncoder encoder, byte[] data, Stream destination, bool\\nisFinalBlock)\\n{\\nbyte[]\", \" output = ArrayPool<byte>.Shared.Rent(4096);\\nOperationStatus lastResult = OperationStatus.Destinatio\", \"nTooSmall;\\nReadOnlySpan<byte> buffer = data;\\nwhile (lastResult == OperationStatus.DestinationTooSmal\", \"l)\\n{\\nlastResult = encoder.Compress(buffer, output, out int bytesConsumed, out\\nint bytesWritten, isFi\", \"nalBlock);\\nif (lastResult == OperationStatus.InvalidData) throw new\\nInvalidOperationException();\\nif \", \"(bytesWritten > 0) destination.Write(output.AsSpan(0, bytesWritten));\\nif (bytesConsumed > 0) buffer \", \"= buffer.Slice(bytesConsumed);\\n}\\nArrayPool<byte>.Shared.Return(output);\\n}\\n169 CHAPTER 15 | Compressi\", \"on}\\n}\\nThe code is measuring how long it takes to compress the input data at each of the levels (doin\", \"g a\\nwarmup and then averaging several iterations), timing how long it takes and capturing the result\", \"ing\\ncompressed data size. For the size, I get values like this:\\nLevel Size (bytes)\\n0 2,512,855.00\\n1 \", \"2,315,466.00\\n2 2,224,638.00\\n3 2,218,328.00\\n4 2,027,153.00\\n5 1,964,810.00\\n6 1,923,456.00\\n7 1,889,927.\", \"00\\n8 1,863,988.00\\n9 1,846,685.00\\n10 1,741,561.00\\n11 1,702,214.00\\nThat\\u2019s a fairly liner progression f\", \"rom least to most compression. That\\u2019s not the problem. This is the\\nproblem:\\n170 CHAPTER 15 | Compres\", \"sionTime\\nLevel (ms)\\n0 24.11\\n1 36.67\\n2 64.13\\n3 73.72\\n4 146.41\\n5 257.12\\n6 328.54\\n7 492.81\\n8 702.38\\n9 8\", \"92.08\\n10 4,830.32\\n11 10,634.88\\nThis chart shows an almost exponential increase in processing time as\", \" we near the upper end of the\\ndial, with quality level 11 compressing ~33% better than quality level\", \" 0 but taking ~440x as long to\\nachieve that. If that\\u2019s what a developer wants, they can specify Comp\", \"ressionLevel.SmallestSize, but\\nthat cost by default and for the balanced CompressionLevel.Optimal is\", \" far out of whack.\\ndotnet/runtime#72266 fixes that. A very small change, it simply makes CompressMod\", \"e.Compress and\\nCompressionLevel.Optimal for Brotli map to quality level 4, which across many kinds o\", \"f inputs does\\nrepresent a fairly balanced trade-off between size and speed.\\n171 CHAPTER 15 | Compres\", \"sionprivate byte[] _data = new\\nHttpClient().GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.\", \"txt.utf-8\\\").Result;\\nprivate Stream _output = new MemoryStream();\\n[Benchmark]\\npublic void Compress()\\n\", \"{\\n_output.Position = 0;\\nusing var brotli = new BrotliStream(_output, CompressionMode.Compress, leave\", \"Open:\\ntrue);\\nbrotli.Write(_data);\\n}\\nMethod Runtime Mean Ratio\\nCompress .NET 6.0 9,807.0 ms 1.00\\nComp\", \"ress .NET 7.0 133.1 ms 0.01\\nOther improvements have gone into compression, such as dotnet/runtime#69\", \"439 which updates the\\ninternal ZipHelper.AdvanceToPosition function used by ZipArchive to reuse a bu\", \"ffer on every\\niteration of a loop rather than allocating a new buffer for each iteration, dotnet/run\", \"time#66764 which\\nuses spans judiciously to avoid a bunch of superfluous string and string[] allocati\", \"ons from\\nSystem.IO.Packaging, and dotnet/runtime#73082 updating the zlib implementations shipped as \", \"part\\nof .NET from v1.2.11 (which was released in January 2017) to v1.2.12 (which was released in Mar\", \"ch\\n2022).\\n172 CHAPTER 15 | Compression16\\nCHAPTER\\nNetworking\\nNetworking is the life-blood of almost e\", \"very service, with performance being critical to success. In\\nprevious releases, a lot of effort was \", \"focused on the lower layers of the networking stack, e.g. .NET 5\\nsaw a significant investment in imp\", \"roving the performance of sockets on Linux. In .NET 7, much of the\\neffort is above sockets.\\nThat sai\", \"d, there were some interesting performance improvements in sockets itself for .NET 7. One of\\nthe mor\", \"e interesting is dotnet/runtime#64770, which revamped how some synchronization is handled\\ninside of \", \"SocketsAsyncEventArgs. As background, in the early days of networking in .NET Framework,\\nasynchrony \", \"was enabled via Begin/End methods (the \\u201cAPM\\u201d pattern). This pattern is not only\\ncomplicated to use w\", \"ell, it\\u2019s relatively inefficient, resulting in allocation for every single operation\\nperformed (at a\", \" minimum for the IAsyncResult object that\\u2019s returned from the BeginXx method). To\\nhelp make networki\", \"ng operations more efficient, SocketsAsyncEventArgs was introduced.\\nSocketsAsyncEventArgs is a reusa\", \"ble class you allocate to hold all of the state associated with\\nasynchronous operations: allocate on\", \"e, pass it to various async methods (e.g. ReceiveAsync), and\\nthen completion events are raised on th\", \"e SocketAsyncEventArgs instance when the operation\\ncompletes. It can be quite efficient when used co\", \"rrectly, but it\\u2019s also complicated to use correctly. In\\nsubsequent releases, Task-based and ValueTas\", \"k-based APIs were released; these have the efficiency\\nof SocketAsyncEventArgs and the ease-of-use of\", \" async/await, and are the recommended starting\\npoint for all Socket-based asynchronous programming t\", \"oday. They have the efficiency of\\nSocketAsyncEventArgs because they\\u2019re actually implemented as a thi\", \"n veneer on top of it under the\\ncovers, and so while most code these days isn\\u2019t written to use Socke\", \"tAsyncEventArgs directly, it\\u2019s still\\nvery relevant from a performance perspective.\\nSocketAsyncEventA\", \"rgs on Windows is implemented to use winsock and overlapped I/O. When you\\ncall an async method like \", \"ValueTask<Socket> Socket.AcceptAsync(CancellationToken), that grabs\\nan internal SocketAsyncEventArgs\", \" and issues an AcceptAsync on it, which in turn gets a\\nNativeOverlapped* from the ThreadPoolBoundHan\", \"dle associated with the socket, and uses it to issue\\nthe native AcceptEx call. When that handle is i\", \"nitially created, we set the\\nFILE_SKIP_COMPLETION_PORT_ON_SUCCESS completion notification mode on th\", \"e socket; use of this\\nwas introduced in earlier releases of .NET Core, and it enables a significant \", \"number of socket\\noperations, in particular sends and receives, to complete synchronously, which in t\", \"urn saves\\nunnecessary trips through the thread pool, unnecessary unwinding of async state machines, \", \"and so\\non. But it also causes a condundrum. There are some operations we want to perform associated \", \"with\\nasynchronous operation but that have additional overhead, such as registering for the cancellat\", \"ion of\\nthose operations, and we don\\u2019t want to pay the cost of doing them if the operation is going t\", \"o\\ncomplete synchronously. That means we really want to delay performing such registration until afte\", \"r\\nwe\\u2019ve made the native call and discovered the operation didn\\u2019t complete synchronously\\u2026 but at that\", \"\\npoint we\\u2019ve already initiated the operation, so if it doesn\\u2019t complete synchronously, then we\\u2019re no\", \"w in\\n173 CHAPTER 16 | Networkinga potential race condition, where our code that\\u2019s still setting up t\", \"he asynchronous operation is racing\\nwith it potentially completing in a callback on another thread. \", \"Fun. SocketAsyncEventArgs handled\\nthis race condition with a spin lock; the theory was that contenti\", \"on would be incredibly rare, as the\\nvast majority cases would either be the operation completing syn\", \"chronously (in which case there\\u2019s no\\nother thread involved) or asynchronously with enough of a delay\", \" that the small amount of additional\\nwork performed by the initiating thread would have long ago com\", \"pleted by the time the\\nasynchronous operation completed. And for the most part, that was true. Howev\", \"er, it turns out that\\nit\\u2019s actually much more common than expected for certain kinds of operations, \", \"like Accepts. Accepts\\nend up almost always completing asynchronously, but if there\\u2019s already a pendi\", \"ng connection,\\ncompleting asynchronously almost immediately, which then induces this race condition \", \"to happen\\nmore frequently and results in more contention on the spin locks. Contention on a spin loc\", \"k is\\nsomething you really want to avoid. And in fact, for a particular benchmark, this spin lock sho\", \"wed up\\nas the cause for an almost 300% slowdown in requests-per-second (RPS) for a benchmark that us\", \"ed a\\ndedicated connection per request (e.g. with every response setting \\u201cConnection: close\\u201d).\\ndotnet\", \"/runtime#64770 changed the synchronization mechanism to no longer involve a spin lock;\\ninstead, it m\", \"aintains a simple gate implemented as an Interlocked.CompareExchange. If the initiating\\nthread gets \", \"to the gate first, from that point on the operation is considered asynchronous and any\\nadditional wo\", \"rk is handled by the completing callback. Conversely, if the callback gets to the gate first,\\nthe in\", \"itiating thread treats the operation as if it completed synchronously. This not only avoids one of\\nt\", \"he threads spinning while waiting for the other to make forward progress, it also increases the\\nnumb\", \"er of operations that end up being handled as synchronous, which in turn reduces other costs\\n(e.g. t\", \"he code awaiting the task returned from this operation doesn\\u2019t need to hook up a callback and\\nexit, \", \"and can instead itself continue executing synchronously). The impact of this is difficult to come\\nup\", \" with a microbenchmark for, but it can have meaningful impact for loaded Windows servers that\\nend up\", \" accepting significant numbers of connections in steady state.\\nA more-easily quantifiable change aro\", \"und sockets is dotnet/runtime#71090, which improves the\\nperformance of SocketAddress.Equals. A Socke\", \"tAddress is the serialized form of an EndPoint, with\\na byte[] containing the sequence of bytes that \", \"represent the address. Its Equals method, used to\\ndetermine whether to SocketAddress instances are t\", \"he same, looped over that byte[] byte-by-byte.\\nNot only is such code gratuitous when there are now h\", \"elpers available like SequenceEqual for\\ncomparing spans, doing it byte-by-byte is also much less eff\", \"icient than the vectorized implementation\\nin SequenceEqual. Thus, this PR simply replaced the open-c\", \"oded comparison loop with a call to\\nSequenceEqual.\\nprivate SocketAddress _addr = new IPEndPoint(IPAd\", \"dress.Parse(\\\"123.123.123.123\\\"),\\n80).Serialize();\\nprivate SocketAddress _addr_same = new IPEndPoint(I\", \"PAddress.Parse(\\\"123.123.123.123\\\"),\\n80).Serialize();\\n[Benchmark]\\npublic bool Equals_Same() => _addr.E\", \"quals(_addr_same);\\nMethod Runtime Mean Ratio\\nEquals_Same .NET 6.0 57.659 ns 1.00\\nEquals_Same .NET 7.\", \"0 4.435 ns 0.08\\n174 CHAPTER 16 | NetworkingLet\\u2019s move up to some more interesting changes in the lay\", \"ers above Sockets, starting with\\nSslStream.\\nOne of the more impactful changes to SslStream on .NET 7\", \" is in support for TLS resumption on Linux.\\nWhen a TLS connection is established, the client and ser\", \"ver engage in a handshake protocol where\\nthey collaborate to decide on a TLS version and cipher suit\", \"es to use, authenticate and validate each\\nother\\u2019s identity, and create symmetric encryption keys for\", \" use after the handshake. This represents a\\nsignificant portion of the time required to establish a \", \"new connection. For a client that might\\ndisconnect from a server and then reconnect later, as is fai\", \"rly common in distributed applications, TLS\\nresumption allows a client and server to essentially pic\", \"k up where they left off, with the client and/or\\nserver storing some amount of information about rec\", \"ent connections and using that information to\\nresume. Windows SChannel provides default support for \", \"TLS resumption, and thus the Windows\\nimplementation of SslStream (which is built on SChannel) has lo\", \"ng had support for TLS resumption.\\nBut OpenSSL\\u2019s model requires additional code to enable TLS resump\", \"tion, and such code wasn\\u2019t\\npresent in the Linux implementation of SslStream. With dotnet/runtime#570\", \"79 and\\ndotnet/runtime#63030, .NET 7 adds server-side support for TLS resumption (using the variant t\", \"hat\\ndoesn\\u2019t require storing recent connection state on the server), and with dotnet/runtime#64369, .\", \"NET 7\\nadds client-side support (which does require storing additional state). The effect of this is \", \"significant, in\\nparticular for a benchmark that opens and closes lots of connections between clients\", \".\\nprivate NetworkStream _client, _server;\\nprivate readonly byte[] _buffer = new byte[1];\\nprivate rea\", \"donly SslServerAuthenticationOptions _options = new\\nSslServerAuthenticationOptions\\n{\\nServerCertifica\", \"teContext = SslStreamCertificateContext.Create(GetCertificate(), null),\\n};\\n[GlobalSetup]\\npublic void\", \" Setup()\\n{\\nusing var listener = new Socket(AddressFamily.InterNetwork, SocketType.Stream,\\nProtocolTy\", \"pe.Tcp);\\nlistener.Bind(new IPEndPoint(IPAddress.Loopback, 0));\\nlistener.Listen(1);\\nvar client = new \", \"Socket(AddressFamily.InterNetwork, SocketType.Stream,\\nProtocolType.Tcp);\\nclient.Connect(listener.Loc\", \"alEndPoint);\\n_server = new NetworkStream(listener.Accept(), ownsSocket: true);\\n_client = new Network\", \"Stream(client, ownsSocket: true);\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n_client.Dispose();\\n_serv\", \"er.Dispose();\\n}\\n[Benchmark]\\npublic async Task Handshake()\\n{\\nusing var client = new SslStream(_client\", \", leaveInnerStreamOpen: true, delegate { return\\n175 CHAPTER 16 | Networkingtrue; });\\nusing var serve\", \"r = new SslStream(_server, leaveInnerStreamOpen: true, delegate { return\\ntrue; });\\nawait Task.WhenAl\", \"l(\\nclient.AuthenticateAsClientAsync(\\\"localhost\\\", null, SslProtocols.None,\\ncheckCertificateRevocation\", \": false),\\nserver.AuthenticateAsServerAsync(_options));\\nawait client.WriteAsync(_buffer);\\nawait serve\", \"r.ReadAsync(_buffer);\\nawait server.WriteAsync(_buffer);\\nawait client.ReadAsync(_buffer);\\n}\\nprivate s\", \"tatic X509Certificate2 GetCertificate() =>\\nnew X509Certificate2(\\nConvert.FromBase64String(\\\"MIIUmgIBA\", \"zCCFFYGCSqGSIb3DQEHAaCCFEcEghRDMIIUPzCCCiAGCSqGSIb3DQEHA\\naCCChEEggoNMIIKCTCCCgUGCyqGSIb3DQEMCgECoIIJ\", \"fjCCCXowHAYKKoZIhvcNAQwBAzAOBAhCAauyUWggWwICB9AE\\ngglYefzzX/jx0b+BLU/TkAVj1KBpojf0o6qdTXV42drqIGhX/k1\", \"WwF1ypVYdHeeuDfhH2eXHImwPTw+0bACY0dSiIHK\\nptm0sb/MskoGI8nlOtHWLi+QBirJ9LSUZcBNOLwoMeYLSFEWWBT69k/sWrc\", \"6/SpDoVumkfG4pZ02D9bQgs1+k8fpZjZ\\nGoZp1jput8CQXPE3JpCsrkdSdiAbWdbNNnYAy4C9Ej/vdyXJVdBTEsKzPYajAzo6Phj\", \"/oS/J3hMxxbReMtj2Z0QkoBB\\nVMc70d+DpAK5OY3et872D5bZjvxhjAYh5JoVTCLTLjbtPRn1g7qh2dQsIpfQ5KrdgqdImshHvxg\", \"L92ooC1eQVqQffMn\\nZ0/LchWNb2rMDa89K9CtAefEIF4ve2bOUZUNFqQ6dvd90SgKq6jNfwQf/1u70WKE86+vChXMMcHFeKso6hT\", \"E9+/zuUP\\nNVmbRefYAtDd7ng996S15FNVdxqyVLlmfcihX1jGhTLi//WuMEaOfXJ9KiwYUyxdUnMp5QJqO8X/tiwnsuhlFe3NKMX\", \"\\nY77jUe8F7I+dv5cjb9iKXAT+q8oYx1LcWu2mj1ER9/b2omnotp2FIaJDwI40Tts6t4QVH3bUNE9gFIfTMK+WMgKBz/J\\nAGvC1vb\", \"PSdFsWIqwhl7mEYWx83HJp/+Uqp5f+d8m4phSan2rkHEeDjkUaoifLWHWDmL94SZBrgU6yGVK9dU82kr7jCS\\nUTrnga8qDYsHwpQ\", \"22QZtu0aOJGepSwZU7NZNMiyX6QR2hI0CNMjvTK2VusHFB+qnvw+19DzaDT6P0KNPxwBwp07KMQm\\n3HWTRNt9u6gKUmo5FHngoGt\", \"e+TZdY66dAwCl0Pt+p1v18XlOB2KOQZKLXnhgikjOwYQxFr3oTb2MjsP6YqnSF9EpYpm\\niNySXiYmrYxVinHmK+5JBqoQCN2C3N2\", \"4slZkYq+AYUTnNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1av\\nfWI/ieKKxyiYp/ZNXaxc+ycgpsSsAJEuhb83bUk\", \"SBpGg9PvFEF0DXm4ah67Ja1SSTmvrCnrOsWZXIpciexMWRGoKrdv\\nd7Yzj9E8hiu+CGTC4T6+7FxVXJrjCg9zU9G2U6g7uxzoyjG\", \"j1wqkhxgvl9pPbz6/KqDRLOHCEwRF4qlWXhsJy4levxG\\ntifFt6n7DWaNSsOUf8Nwpi+d4fd7LQ7B5tW/y+/vVZziORueruCWO4L\", \"nfPhpJ70g18uyN7KyzrWy29rpE46rfjZGGt0\\nWDZYahObPbw6HjcqSOuzwRoJMxamQb2qsuQnaBS6Bhb5PAnY4SEA045odf/u9uC\", \"7mLom2KGNHHz6HrgEPas2UHoJLux\\nYvY1pza/29akuVQZQUvMA5yMFHHGYZLtTKtCGdVGwX0+QS6ovpV93xux4I/5TrD5U8z9RmT\", \"dAx03R3MUhkHF7Zbv5eg\\nDNsVar+41YWG4VkV1ZXtsZRKJf0hvKNvrpH0e7fVKBdXljm5PXOSg2VdtkhhOpnKKSMcv6MbGWVi/sv\", \"WLnc7Qim4A4M\\nDaz+bFVZmh3oGJ7WHvRQhWIcHUL+YJx+064+4IKXZJ/2a/+b2o7C8mJ3GGSBx831ADogg6MRWZx3UY19OZ8YMvp\", \"zmZE\\nBRZZnm4KgNpj+SQnf6pGzD2cmnRhzG60LSNPb17iKbdoUAEMkgt2tlMKXpnt1r7qwsIoTt407cAdCEsUH7OU/AjfFmS\\nkKJ\", \"Z7vC5HweqZPnhgJgZ6LYHlfiRzUR1xeDg8JG0nb0vb7LUE4nGPy39/TxIGos7WNwGpG1QVL/8pKjFdjwREaR8e5C\\nSTlQ7gxHV+G\", \"3FFvFGpA1p8cRFzlgE6khDLrSJIUkhkHMA3oFwwAzBNIKVXjToyxCogDqxWya0E1Hw5rVCS/zOCS1De2\\nXQbXs//g46TW0wTJwvg\", \"Nbs0xLShf3XB+23meeEsMTCR0+igtMMMsh5K/vBUGcJA27ru/KM9qEBcseb/tqCkhhsdj1dn\\nH0HDmpgFf5DfVrjm+P6ickcF2b+\", \"Ojr9t7XHgFszap3COpEPGmeJqNOUTuU53tu/O774IBgqINMWvvG65yQwsEO06jRr\\nFPRUGb0eH6UM4vC7wbKajnfDuI/EXSgvuOS\", \"Z9wE8DeoeK/5We4pN7MSWoDl39gI/LBoNDKFYEYuAw/bhGp8nOwDKki4\\na16aYcBGRClpN3ymrdurWsi7TjyFHXfgW8fZe4jXLuK\", \"RIk19lmL1gWyD+3bT3mkI2cU2OaY2C0fVHhtiBVaYbxBV8+k\\njK8q0Q70zf0r+xMHnewk9APFqUjguPguTdpCoH0VAQST9Mmriv/\", \"J12+Y+fL6H+jrtDY2zHPxTF85pA4bBBnLA7Qt9TK\\nCe6uuWu5yBqxOV3w2Oa4Pockv1gJzFbVnwlEUWnIjbWVIyo9vo4LBd03uJH\", \"PPIQbUp9kCP/Zw+Zblo42/ifyY+a+scw\\nl1q1dZ7Y0L92yJCKm9Qf6Q+1PBK+uU9pcuVTg/Imqcg5T7jFO5QCi88uwcorgQp+qoe\", \"Fi0F9tnUecfDl6d0PSgAPnX9\\nXA0ny3bPwSiWOA8+uW73gesxnGTsNrtc1j85tail8N6m6S2tHXwOmM65J4XRZlzzeM4D/Rzzh13\", \"xpRA9kzm9T2cSHsX\\nEYmSW1X7WovrmYhdOh9K3DPwSyG4tD58cvC7X79UbOB+d17ieo7ZCj+NSLVQO1BqTK0QfErdoVHGKfQG8Lc\", \"/ERQRqj1\\n32Mhi2/r5Ca7AWdqD7/3wgRdQTJSFXt/akpM44xu5DMTCISEFOLWiseSOBtzT6ssaq2Q35dCkXp5wVbWxkXAD7Gm34F\", \"\\nFXXyZrJWAx45Y40wj/0KDJoEzXCuS4Cyiskx1EtYNNOtfDC5wngywmINFUnnW0NkdKSxmDJvrT6HkRKN8ftik7tP4Zv\\nTaTS28Z\", \"0fDmWJ+RjvZW+vtF6mrIzYgGOgdpZwG0ZOSKrXKrY3xpMO16fXyawFfBosLzCty7uA57niPS76UXdbplgPan\\nIGFyceTg1MsNDsd\", \"8vszXd4KezN2VMaxvw+93s0Uk/3Mc+5MAj+UhXPi5UguXMhNo/CU7erzyxYreOlAI7ZzGhPk+oT9\\ng/MqWa5RpA2IBUaK/wgaNaH\", \"ChfCcDj/J1qEl6YQQboixxp1IjQxiV9bRQzgwf31Cu2m/FuHTTkPCdxDK156pyFdhcgT\\npTNy7RPLDF0MBMGCSqGSIb3DQEJFTEG\", \"BAQBAAAAMF0GCSsGAQQBgjcRATFQHk4ATQBpAGMAcgBvAHMAbwBmAHQAIABT\\nAHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgB\", \"hAHAAaABpAGMAIABQAHIAbwB2AGkAZABlAHIwggoXBgkqhkiG9w0\\nBBwagggoIMIIKBAIBADCCCf0GCSqGSIb3DQEHATAcBgoqhk\", \"iG9w0BDAEGMA4ECH63Q8xWHKhqAgIH0ICCCdDAo9x82r\\nwRM6s16wMo01glVedahn1COCP1FKmP6lQ3kjcHruIWlcKW+eCUpt41q\", \"s0LM3iFcPQj5x7675DeLL0AC2Ebu7Jhg0FGM\\nJZwHLbmJLyG0VSb1WhX2UfxNSdLrdZv8pmejB7DYdV3xAj8DBCRGfwwnbTQjFH9\", \"wUPga5U79Dvpqq+YVvUEEci1N6tT\\nPu32LOOEvjoEtpskrHoKyqLGV7sSgM6xMIDcfVWbLb8fDcVS1JQRHbeOdGClFMDjwzr+eGW\", \"d+OyOZ6BydUGjIKAZpRp\\n176 CHAPTER 16 | Networking0YTk5jjYUMNRbvBP1VPq9ASIh8pJnt/Kq1nqfj7EPatXJJUZAH35\", \"E6bSbLBnP0+5+xim1l4HsB8066c4B3aTUXnLepP\\nRyMIn6Xh5ev0pF3aUc4ZlWgar57TzKUFBTkcH5OCbqZloQ7ZCDNc4C3WKVLS\", \"UOKLj3QOxJPrb6/nyXZHjki1tGKisb9\\nRLv4dkeMdRjsSwNRn6Cfdlk2qHWUCiWLlsLXFyMSM12qrSSfIIBRo0wbn1SEJagHqUml\", \"F9UR5A6b5OODIbDq3cXH/q6\\nU09zVX/BxqxyZqEfeSAcvXjqImLWnZzbIgm0QH7jOtti/vEfvdzypdWH9V64PzQj/5B8P4ZpbQyW\", \"UgzKEIdx24WhTOc\\ndwNivkaEkGFTra3qw2dKO0RTVtx3bSgesHCumQDuDf8yafLfchWuqihYV7zvqW9BWrsa0W7yKNXLNqdlSz8K\", \"vuTnFff\\nOOHrJQwBs+JKdMcKX5IR222RH3fp8Dp17y8hFEaPp4AqpuhHGALXOCwmuPtlUjuHRCUluh3BjaPPLNwLmSGfe0piOVh\\n\", \"4rTyJCfN4rlz0lWBAAfIHi47J9sTnSgEJgkTuemPJXssQ3Z/trcYdfhlYjelOBtS/5DW3wFmjNDilwVBQT66li5xUvc\\nWvZPx/sc\", \"XgbgpsMThqguJWtiPLR1SzusKCN4q7bVQ8D8ErHh5uMb5NmNRIZ/xNeqslqTU9A4bi0TE0FjEu28F0Wg4Cx\\niwqNM58xik9eni85\", \"t+S0Uo9wPV1V2Vdhe9LkO3PeoSTCau4D189DoViL44WPDQ+TCSvlPP7SFEwaBvUlGBWjxJWVb81\\nlkgRsol1bllUvIzN13V0LSiA\", \"0Nks9w9H8cQ17ZRe2r7SpDDR6Rn5oLb9G98AyvlcgJfyUe1iZCUAUZGEU247KwePtXY\\nAlO47HbAJe0bOtM9zp7KyWxbImKCfxsP\", \"Wv6CR6PH+ooHDBO9kXVpKaJCYWeYybSMuPufy/u/rMcIVO4oXVsdnjh4jAx\\npQOXowCAcN2+Q+XnqtiCr9Mzd0q5ee7jsYuJF6LQ\", \"RdNP04wIpwjpdggKyB7zURPeTXlV8vIjUs25+CoCxp+fCXfXKqe\\n2xxdbQ2zFbpKSbJdpbWad3F6MsFBGOKTdyK8EZODGApBtlo7\", \"1kY6uOxKiBwJKd76zTMsPEQWOZphi2khpTxIVYONrmP\\nKjSO8zc4dTC8SW+d1kmCt4UYblwoeDCAYp2RiDHpgC+5yuBDCooT/6fG\", \"6GQpa1X0PiH2oUCpltZz2M4+1bH2HdTeBfc\\n1Mtj/hniLL8VdH0qcpS0KYPUxJFEg6IxxrWw1OBreY//6pJLm76nKiflzhz+Mt0R\", \"bQZqkPP/K9BxzQw//bW9Kh4iRQ3\\n7D9HNQG/GtrCEcbH4V4uUjbj34sEo0FC7gVvDob0Bik8l/c901zQZEydqe0DgHtGbY2xIZ2q\", \"qsQy4LDVfHNHqSLiNss\\nL8BJtxUyvnhiwHD7jmyCB6cWyFGtibRBehQzleioS16xvLph88CMGV3IH9By5QtXpDIB4vjhibE6coPk\", \"TmpDCB9xlTE\\n3TV4GBt5JLttkjfOkXAAx0xD523Adcy6FVe5QYuY1O8170O6l88YptozyWi5jVfDh+aDg9pjsw/aZ1hCURe9KDaB\", \"4gI\\nlW4ZEGKsf5e/xU+vuVxw374te/Y2aCChSj93XyC+Fjxe06s4yifVAYA0+HtLMGNHe/X0kPXvRnoa5kIu0yHrzViQrBb\\n/4Sb\", \"ms617Gg1BFONks1JO2G0zIt8CouTqVmdtuH7tV0JZV/Nmg7NQ1X59XDC/JH2i4jOu8OhnmIZFlTysS6e1qnqsGt\\n/0XcUyzPia8+\", \"UIAynXmyi8sWlUjy37w6YqapAfcs7B3TezqIwn7RgRasJpNBi7eQQqg5YLe6EYTxctKNkGpzeTBUiXN\\nXM4Gv3tIaMbzwlhUNbYW\", \"uNBsi/7XJPM5jMycINRbdPwYy19gRBs3pm0FoP2Lhl5mVAJ2R8a40Lo5g73wvt9Th+uB9/y\\nc196RryQe280yfgKiwUoFFcDnL6S\", \"oQTRCTl95mF8zw1f3Hc7QImhubgcLntXEndzSNN7ZIDSAB8HiDSR6CGYPNiCNAC\\n4hj+jUswoWIE257h+deWFTUvjTZmXH+XMoN6\", \"trqjdeCH0hePdmrIWVdr1uTIoO16TR6mFNm6Utzc0t5vVrcpnEh3w6a\\nmVHw5xmweW4S75ncN6vSPxGjtfuQ6c2RTG5NXZuWpnhX\", \"wOxgoBN4q/h99zVRvwwsF32Eyzx6GOYLmORgCkzke9eXjjX\\nWY83oysXx/aE9WCqt3en8zzRzzA1aO9Yi88uv1OOqTvWEoGrf4e7\", \"SgjXO6hNjYE6EEvK+mMz6a9F3xSWsUlMsZPIIBe\\n8CEgNEhXKsa6xw7ljSx8Nz7zYG+u5rgXKFmSNvWvwasZyIfRXkccqODl17Ba\", \"evbWp/ir3rJ/b9mOiV0UW8qIJ3zC6b1\\nlXU5pNuOODjqhKkjIHPGXiql+uBPVlfUy8Zbi4AntZAeNIB7HtUavVKX6CF7k9AFtRHI\", \"WK70+cFEw4yMZiQjaWeB3dt\\n16Fz6LZ8+c17kuB2wFuZQqYQkf3quWQVPwKj41gFYoFSwFfJ8L6TBcNHI2u3avtVp9ZbP9zArT8A\", \"n9Ryri/PwTSbPLT\\ncaz549b60/0k4c/qV4XRMuFsi29CXcMnLSCPpPKs71LTvsRXK6QUJd4fX/KnTiWargbS6tT6lR/bBqY/gFU1\", \"xWyKQ8x\\nij97vlQjffSKdcbj5JsnjSr8xAh9idfJ2FWZZUJReR9EU1twK7slyUivNLVY7bqroE6CzYaEDecRqfwIrFrzmH+gJoM\\n\", \"88waGRC0JTvm8GpBX0eTb5bnMxJKPtH1GIffgyQLERO1jwjApr6SJEB4yV7x48CZPod9wE51OxUY2hEdAA5l7DBTJys\\ng5gn/nhY\", \"6ZzL0llb39yVyDEcZdmrji0ncEMdBDioGBV3mNz1DL398ZLdjG+xkneI3sgyzgm3cZZ1+/A2kloIEmOKJSe\\n0k/B1cyMB5QRnXpO\", \"bF1vWXjauMVIKm0wlLY3YQ9I1vfr6y1o2DN+Vy0sumbIQrjDKqMDswHzAHBgUrDgMCGgQUHEWyD\\n7i5PbatVl3k0+S9WV3ZJRAEF\", \"Fd7xcvfj1HpkOawyGnJdtcQ0KWPAgIH0A==\\\"),\\n\\\"testcertificate\\\",\\nX509KeyStorageFlags.DefaultKeySet);\\nMethod\", \" Runtime Mean Ratio Allocated Alloc Ratio\\nHandshake .NET 6.0 4.647 ms 1.00 19.27 KB 1.00\\nHandshake .\", \"NET 7.0 2.314 ms 0.50 9.56 KB 0.50\\nAnother significant improvement for SslStream in .NET 7 is suppor\", \"t for OCSP stapling. When a client\\nhandshakes with the server and the server shares its certificate,\", \" a client that cares about validating it\\u2019s\\ntalking to exactly who it intended to talk to needs to va\", \"lidate that certificate. In the days of yore, such\\nvalidation was done with certificate revocation l\", \"ists (CRL), where periodically the client would\\ndownload a giant list of certificates known to be re\", \"voked. Online Certificate Status Protocol (OCSP) is\\na newer protocol and mechanism that enables a cl\", \"ient to get real-time information about a certificate;\\nwhile the client handshakes with the server a\", \"nd the server sends the client its certificate, the client\\nthen connects to an \\u201cOCSP responder\\u201d and \", \"sends it a request to determine whether the certificate is\\nconsidered good. OCSP has multiple issues\", \" of its own, however. In particular, it places a significant\\nload on these OCSP responder servers, w\", \"ith every client making a real-time request to it about every\\ncertificate encountered, and also pote\", \"ntially significantly increasing the time it takes the client to\\nestablish a connection. OCSP stapli\", \"ng offers a solution to this. Rather than a client issuing a request to\\n177 CHAPTER 16 | Networkingt\", \"he OCSP responder, the server itself contacts the OCSP responder and gets a signed ticket from the\\nO\", \"CSP responder stating that the server\\u2019s certificate is good and will be for some period of time. Whe\", \"n\\na client handshakes with the server, the server can then \\u201cstaple\\u201d (include) this signed ticket as \", \"part of\\nits response to the client, giving the validation to the client directly rather than the cli\", \"ent needing to\\nmake a separate roundtrip to the OCSP responder. This reduces overheads for everyone \", \"involved.\\ndotnet/runtime#67011 adds support for OCSP stapling to SslStream client usage on Linux, wi\", \"th\\ndotnet/runtime#69833 adding the Linux server-side counterpart, and dotnet/runtime#71570 adds\\nclie\", \"nt-side support for Windows.\\nThe aforementioned changes are primarily about the performance of openi\", \"ng a connection.\\nAdditional work has been done to improve that further in other ways. dotnet/runtime\", \"#69527 gets rid\\nof allocations associated with several SafeHandle instances that were being created \", \"unnecessarily on\\nLinux as part of establishing a TLS connection. This highlights the benefits of doi\", \"ng profiling on\\nmultiple platforms, as while these SafeHandles were necessary in the Windows impleme\", \"ntation, they\\nwere fairly meaningless in the Linux implementation (due to differences between SChann\", \"el and\\nOpenSSL), and were only brought along for the ride because of how the platform-abstraction la\", \"yer\\n(PAL) was defined to reuse most of the SslStream code across platforms. And dotnet/runtime#68188\", \"\\navoids several collections allocated as part of the TLS handshake. This one is particularly interes\", \"ting as\\nit\\u2019s come up multiple times in the past in various libraries. Imagine you have a lazily init\", \"ialized\\nproperty like this:\\nprivate List<T>? _items;\\npublic List<T> Items => _items ??= new List<T>(\", \");\\nAnd then some code in the same implementation comes along and wants to read the contents of\\nthese\", \" items. That code might look like:\\nif (Items.Count > 0) { ... }\\nbut the very act of accessing Items \", \"just to check its count forces the collection into existence (with a 0\\nCount). If the code instead c\", \"hecks:\\nif (_items is List<T> items && items.Count > 0) { ... }\\nIt can save that unnecessary collecti\", \"on allocation. The approach is made even simpler with C# pattern\\nmatching:\\nif (_items is { Count: > \", \"0 }) items) { ... }\\nThis is one of those things that\\u2019s incredibly obvious once you \\u201csee\\u201d it and real\", \"ize what\\u2019s happening,\\nbut you often miss until it jumps out at you in a profiler.\\ndotnet/runtime#690\", \"98 is another good example of how profiling can lead to insights about\\nallocations that can be remov\", \"ed. Application-Layer Protocol Negotation (ALPN) allows code\\nestablishing a TLS connection to piggy-\", \"back on the roundtrips that are being used for the TLS\\nhandshake anyway to negotiate some higher-lev\", \"el protocol that will end up being used as well. A very\\ncommon use-case, for example, is for an HTTP\", \"S client/server to negotiate which version of HTTP\\nshould be used. This information is exposed from \", \"SslStream as an SslApplicationProtocol struct\\nreturned from its NegotiatedApplicationProtocol proper\", \"ty, but as the actual negotiated protocol\\ncan be arbitrary data, SslApplicationProtocol just wraps a\", \" byte[]. The implementation had been\\n178 CHAPTER 16 | Networkingdutifully allocating a byte[] to hol\", \"d the bytes passed around as part of ALPN, since we need such a\\nbyte[] to store in the SslApplicatio\", \"nProtocol. But while the byte data can be arbitrary, in practice\\nby far the most common byte sequenc\", \"es are equivalent to \\u201chttp/1.1\\u201d for HTTP/1.1, \\u201ch2\\u201d for HTTP/2,\\nand \\u201ch3\\u201d for HTTP/3. Thus, it makes s\", \"ense to special-case those values and use a reusable cached\\nbyte[] singleton when one of those value\", \"s is needed. If SslApplicationProtocol exposed the\\nunderlying byte[] directly to consumers, we\\u2019d be \", \"hesitant to use such singletons, as doing so would\\nmean that if code wrote into the byte[] it would \", \"potentially be changing the value for other\\nconsumers in the same process. However, SslApplicationPr\", \"otocol exposes it as a\\nReadOnlyMemory<byte>, which is only mutable via unsafe code (using the\\nMemory\", \"Marshal.TryGetArray method), and once you\\u2019re employing unsafe code to do \\u201cbad\\u201d things,\\\"\\nall bets are\", \" off anyway. dotnet/runtime#63674 also removes allocations related to ALPN, in this case\\navoiding th\", \"e need for a byte[] allocation on Linux when setting the negotiated protocol on a client\\nSslStream. \", \"It uses stack memory instead of an array allocation for protocols up to 256 bytes in length,\\nwhich i\", \"s way larger than any in known use, and thus doesn\\u2019t bother to do anything fancy for the\\nfallback pa\", \"th, which will never be used in practice. And dotnet/runtime#69103 further avoids ALPN-\\nrelated allo\", \"cations and work on Windows by entirely skipping some unnecessary code paths: various\\nmethods can be\", \" invoked multiple times during a TLS handshake, but even though the ALPN-related\\nwork only needed to\", \" happen once the first time, the code wasn\\u2019t special-casing it and was instead\\nrepeating the work ov\", \"er and over.\\nEverything discussed thus far was about establishing connections. What about the perfor\", \"mance of\\nreading and writing on that connection? Improvements have been made there, too, in particul\", \"ar\\naround memory management and asynchrony. But first we need some context.\\nWhen async/await were fi\", \"rst introduced, Task and Task<TResult> were the only game in town; while\\nthe pattern-based mechanism\", \" the compiler supports for arbitrary \\u201ctask-like\\u201d types enabled async\\nmethods to return other types, \", \"in practice it was only tasks (which also followed our guidance). We\\nsoon realized, however, that a \", \"significant number of calls to a significant number of commonly-used\\nasync APIs would actually compl\", \"ete synchronously. Consider, for example, a method like\\nMemoryStream.ReadAsync: MemoryStream is back\", \"ed entirely by an in-memory buffer, so even though\\nthe operation is \\u201casync,\\u201d every call to it comple\", \"tes synchronously, as the operation can be performed\\nwithout doing any potentially long-running I/O.\", \" Or consider FileStream.ReadAsync. By default\\nFileStream employs its own internal buffer. If you iss\", \"ue a call to FileStream.ReadAsync with your\\nown buffer and ask for only, say, 16 bytes, under the co\", \"vers FileStream.ReadAsync will issue the\\nactual native call with its own much larger buffer, which b\", \"y default is 4K. The first time you issue your\\n16-byte read, actual I/O will be required and the ope\", \"ration is likely to complete asynchronously. But\\nthe next 255 calls you make could simply end up dra\", \"ining the remainder of the data read into that 4K\\nbuffer, in which case 255 of the 256 \\u201casync\\u201d opera\", \"tions actually complete synchronously. If the\\nmethod returns a Task<int>, every one of those 255 syn\", \"chronously-completing calls could still end\\nup allocating a Task<int>, just to hand back the int tha\", \"t\\u2019s already known. Various techniques were\\ndevised to minimize this, e.g. if the int is one of a few\", \" well-known values (e.g. -1 through 8), then the\\nasync method infrastructure will hand back a pre-al\", \"located and cached Task<int> instance for that\\nvalue, and various stream implementations (including \", \"FileStream) would cache the previously-\\nreturned Task<int> and hand it back for the next call as wel\", \"l if the next call yielded exactly the same\\nnumber of bytes. But those optimizations don\\u2019t fully mit\", \"igate the issue. Instead, we introduced the\\nValueTask<TResult> struct and provided the necessary \\u201cbu\", \"ilder\\u201d to allow async methods to return\\n179 CHAPTER 16 | Networkingthem. ValueTask<TResult> was simp\", \"ly a discrimated union between a TResult and Task<TResult>. If\\nan async method completed asynchronou\", \"sly (or if it failed synchronously), well, it would simply\\nallocate the Task<TResult> as it otherwis\", \"e would have and return that task wrapped in a\\nValueTask<TResult>. But if the method actually comple\", \"ted synchronously and successfully, it would\\ncreate a ValueTask<TResult> that just wrapped the resul\", \"ting TResult, which then eliminates all\\nallocation overhead for the synchronously-completing case. Y\", \"ay, everyone\\u2019s happy. Well, almost\\neveryone. For really hot paths, especially those lower down in th\", \"e stack that many other code paths\\nbuild on top of, it can also be beneficial to avoid the allocatio\", \"ns even for the asynchronously\\ncompleting case. To address that, .NET Core 2.1 saw the introduction \", \"of the\\nIValueTaskSource<TResult> interface along with enabling ValueTask<TResult> to wrap an instanc\", \"e\\nof that interface in addition to a TResult or a Task<TResult> (at which point it also became\\nmeani\", \"ngful to introduce a non-generic ValueTask and the associated IValueTaskSource). Someone\\ncan impleme\", \"nt this interface with whatever behaviors they want, although we codified the typical\\nimplementation\", \" of the core async logic into the ManualResetValueTaskSourceCore helper struct,\\nwhich is typically e\", \"mbedded into some object, with the interface methods delegating to\\ncorresponding helpers on the stru\", \"ct. Why would someone want to do this? Most commonly, it\\u2019s to be\\nable to reuse the same instance imp\", \"lementing this interface over and over and over. So, for example,\\nSocket exposes a ValueTask<int> Re\", \"ceiveAsync method, and it caches a single instance of an\\nIValueTaskSource<int> implementation for us\", \"e with such receives. As long as you only ever have\\none receive pending on a given socket at a time \", \"(which is the 99.999% case), every ReceiveAsync call\\nwill either return a ValueTask<int> wrapped aro\", \"und an int value or a ValueTask<int> wrapped\\naround that reusable IValueTaskSource<int>, making all \", \"use of ReceiveAsync ammortized\\nallocation-free (there is another instance used for SendAsync, such t\", \"hat you can have a concurrent\\nread and write on the socket and still avoid allocations). However, im\", \"plementing this support is still\\nnon-trivial, and can be super hard when dealing with an operation t\", \"hat\\u2019s composed of multiple\\nsuboperations, which is exactly where async/await shine. Thus, C# 10 adde\", \"d support for overriding\\nthe default builder that\\u2019s used on an individual async method (e.g. such th\", \"at someone could provide\\ntheir own builder for a ValueTask<int>-returning method instead of the one \", \"that allocates Task<int>\\ninstances for asynchronous completion) and .NET 6 included the new\\nPoolingA\", \"syncValueTaskMethodBuilder and PoolingAsyncValueTaskMethodBuilder<> types. With\\nthose, an async meth\", \"od like:\\npublic async ValueTask<int> ReadAsync(Memory<byte> buffer) { ... }\\ncan be changed to be:\\n[A\", \"syncMethodBuilder(typeof(PoolingAsyncValueTaskMethodBuilder<>))]\\npublic async ValueTask<int> ReadAsy\", \"nc(Memory<byte> buffer) { ... }\\nwhich will cause the C# compiler to emit the implementation of this \", \"method using\\nPoolingAsyncValueTaskMethodBuilder<int> instead of the default\\nAsyncValueTaskMethodBuil\", \"der<int>. The implementation of\\nPoolingAsyncValueTaskMethodBuilder<TResult> is true to its name; it \", \"employs pooling to avoid\\nmost of the allocation asynchronous completion would otherwise experience (\", \"I say \\u201cmost\\u201d because\\nthe pooling by design tries to balance all the various costs involved and may s\", \"till sometimes allocate),\\nand makes it easy for methods implemented with async/await to reap those b\", \"enefits. So, if this was\\nall introduced in the last release, why am I talking about it now? Pooling \", \"isn\\u2019t free. There are various\\n180 CHAPTER 16 | Networkingtradeoffs involved in its usage, and while \", \"it can make microbenchmarks look really good, it can also\\nnegatively impact real-world usage, e.g. b\", \"y increasing the cost of garbage collections that do occur by\\nincreasing the number of Gen2 to Gen0 \", \"references that exist. As such, while the functionality is\\nvaluable, we\\u2019ve been methodical in where \", \"and how we use it, choosing to do so more slowly and only\\nemploying it after sufficient analysis dee\", \"ms it\\u2019s worthwhile.\\nSuch is the case with SslStream. With dotnet/runtime#69418, two core and hot asy\", \"nc methods on\\nSslStream\\u2019s read path were annotated to use pooling. A microbenchmark shows what I mea\", \"n when I\\nwrote this can make microbenchmarks look really good (focus on the allocation columns). Thi\", \"s\\nbenchmark is repeatedly issuing a read (that will be forced to complete asynchronously because\\nthe\", \"re\\u2019s no available data to satisfy it), then issuing a write to enable that read to complete, and the\", \"n\\nawaiting the read\\u2019s completion; every read thus completes asynchronously.\\nprivate SslStream _sslCl\", \"ient, _sslServer;\\nprivate readonly byte[] _buffer = new byte[1];\\nprivate readonly SslServerAuthentic\", \"ationOptions _options = new\\nSslServerAuthenticationOptions\\n{\\nServerCertificateContext = SslStreamCer\", \"tificateContext.Create(GetCertificate(), null),\\n};\\n[GlobalSetup]\\npublic void Setup()\\n{\\nusing var lis\", \"tener = new Socket(AddressFamily.InterNetwork, SocketType.Stream,\\nProtocolType.Tcp);\\nlistener.Bind(n\", \"ew IPEndPoint(IPAddress.Loopback, 0));\\nlistener.Listen(1);\\nvar client = new Socket(AddressFamily.Int\", \"erNetwork, SocketType.Stream,\\nProtocolType.Tcp);\\nclient.Connect(listener.LocalEndPoint);\\n_sslClient \", \"= new SslStream(new NetworkStream(client, ownsSocket: true),\\nleaveInnerStreamOpen: true, delegate { \", \"return true; });\\n_sslServer = new SslStream(new NetworkStream(listener.Accept(), ownsSocket: true),\\n\", \"leaveInnerStreamOpen: true, delegate { return true; });\\nTask.WaitAll(\\n_sslClient.AuthenticateAsClien\", \"tAsync(\\\"localhost\\\", null, SslProtocols.None,\\ncheckCertificateRevocation: false),\\n_sslServer.Authenti\", \"cateAsServerAsync(_options));\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n_sslClient.Dispose();\\n_sslSe\", \"rver.Dispose();\\n}\\n[Benchmark]\\npublic async Task ReadWriteAsync()\\n{\\nfor (int i = 0; i < 1000; i++)\\n{\\n\", \"ValueTask<int> read = _sslClient.ReadAsync(_buffer);\\n181 CHAPTER 16 | Networkingawait _sslServer.Wri\", \"teAsync(_buffer);\\nawait read;\\n}\\n}\\nMethod Runtime Mean Ratio Code Size Allocated Alloc Ratio\\nReadWrit\", \"eAsync .NET 6.0 68.34 ms 1.00 510 B 336404 B 1.000\\nReadWriteAsync .NET 7.0 69.60 ms 1.02 514 B 995 B\", \" 0.003\\nOne final change related to reading and writing performance on an SslStream. I find this one\\n\", \"particularly interesting, as it highlights a new and powerful C# 11 and .NET 7 feature: static abstr\", \"act\\nmembers in interfaces. SslStream, as with every Stream, exposes both synchronous and asynchronou\", \"s\\nmethods for reading and writing. And as you may be aware, the code within SslStream for\\nimplementi\", \"ng reads and writes is not particularly small. Thus, we really want to avoid having to\\nduplicate all\", \" of the code paths, once for synchronous work and once for asynchronous work, when in\\nreality the on\", \"ly place that bifurcation is needed is at the leaves where calls into the underlying Stream\\nare made\", \" to perform the actual I/O. Historically, we\\u2019ve had two different mechanisms we\\u2019ve employed\\nin dotne\", \"t/runtime for handling such unification. One is to make all methods async, but with an\\nadditional bo\", \"ol useAsync parameter that gets fed through the call chain, then branching based on it\\nat the leaves\", \", e.g.\\npublic static void Work(Stream s) =>\\nA(s, useAsyunc: false).GetAwaiter().GetResult(); // GetR\", \"esult() to propagate any\\nexceptions\\npublic static Task WorkAsync(Stream S) =>\\nA(s, useAsync: true);\\n\", \"internal static async Task A(Stream s, bool useAsync)\\n{\\n...\\nawait B(s, useAsync);\\n...\\n}\\nprivate stat\", \"ic async Task B(Stream s, bool useAsync)\\n{\\n...\\nint bytesRead = useAsync ?\\nawait s.ReadAsync(buffer) \", \":\\ns.Read(buffer.Span);\\n...\\n}\\nThis way most of the logic and code is shared, and when useAsync is fal\", \"se, everything completes\\nsynchronously and so we don\\u2019t pay for allocation that might otherwise be as\", \"sociated with the async-\\nness. The other approach is similar in spirit, but instead of a bool parame\", \"ter, taking advantage of\\ngeneric specialization and interface-implementing structs. Consider an inte\", \"rface like:\\ninterface IReader\\n{\\nValueTask<int> ReadAsync(Stream s, Memory<byte> buffer);\\n}\\n182 CHAPT\", \"ER 16 | NetworkingWe can then declare two implementations of this interface:\\nstruct SyncReader : IRe\", \"ader\\n{\\npublic ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) =>\\nnew ValueTask<int>(s.Read(b\", \"uffer.Span));\\n}\\nstruct AsyncReader : IReader\\n{\\npublic ValueTask<int> ReadAsync(Stream s, Memory<byte\", \"> buffer) =>\\ns.ReadAsync(buffer);\\n}\\nThen we can redeclare our earlier example as:\\npublic static void\", \" Work(Stream s) =>\\nA(stream, default(SyncReader)).GetAwaiter().GetResult(); // to propagate any exce\", \"ptions\\npublic static Task WorkAsync(Stream S) =>\\nA(s, default(AsyncReader));\\ninternal static async T\", \"ask A<TReader>(Stream s, TReader reader) where TReader : IReader\\n{\\n...\\nawait B(s, reader);\\n...\\n}\\npri\", \"vate static async Task B<TReader>(Stream s, TReader reader) where TReader : IReader\\n{\\n...\\nint bytesR\", \"ead = await reader.ReadAsync(s, buffer);\\n...\\n}\\nNote that the generic constraint on the TReader param\", \"eter here allows the implementation to invoke\\nthe interface methods, and passing the structs as a ge\", \"neric avoids boxing. One code path supporting\\nboth sync and async implementations.\\nThis latter gener\", \"ic approach is how SslStream has historically handled the unification of its sync and\\nasync implemen\", \"tations. It gets better in .NET 7 with C# 11 now that we have static abstract methods\\nin interfaces.\", \" We can instead declare our interface as (note the static abstract addition):\\ninterface IReader\\n{\\nst\", \"atic abstract ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer);\\n}\\nour types as (note the stat\", \"ic addition):\\nstruct SyncReader : IReader\\n{\\npublic static ValueTask<int> ReadAsync(Stream s, Memory<\", \"byte> buffer) =>\\nnew ValueTask<int>(s.Read(buffer.Span));\\n}\\nstruct AsyncReader : IReader\\n183 CHAPTER\", \" 16 | Networking{\\npublic static ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) =>\\ns.ReadAsy\", \"nc(buffer);\\n}\\nand our consuming methods as (note the removal of the parameter and the switch to call\", \"ing static\\nmethods on the type parameter):\\npublic static void Work(Stream s) =>\\nA<SyncReader>(stream\", \").GetAwaiter().GetResult(); // to propagate any exceptions\\npublic static Task WorkAsync(Stream S) =>\", \"\\nA<AsyncReader>(s);\\ninternal static async Task A<TReader>(Stream s) where TReader : IReader\\n{\\n...\\naw\", \"ait B<TReader>(s);\\n...\\n}\\nprivate static async Task B<TReader>(Stream s) where TReader : IReader\\n{\\n..\", \".\\nint bytesRead = await TReader.ReadAsync(s, buffer);\\n...\\n}\\nNot only is this cleaner, but from a per\", \"formance perspective we no longer need to pass around the\\ndummy generic parameter, which is general \", \"goodness, but for an async method it\\u2019s particularly\\nbeneficial because the state machine type ends u\", \"p storing all parameters as fields, which means every\\nparameter can increase the amount of allocatio\", \"n incurred by an async method if the method ends up\\ncompleting asynchronously. dotnet/runtime#65239 \", \"flipped SslStream (and NegotiateStream) to\\nfollow this approach. It\\u2019s also used in multiple other pl\", \"aces now throughout dotnet/runtime.\\ndotnet/runtime#69278 from [@teo-tsirpanis](https://github.com/te\", \"o-tsirpanis) changed the\\nRandomAccess class\\u2019 implementation for Windows and the ThreadPool\\u2019s mechani\", \"sm for invoking work\\nitems to use the same approach. Further, dotnet/runtime#63546 did the same in t\", \"he Regex\\nimplementation, and in particular in the new RegexOptions.NonBacktracking implementation, a\", \"s a\\nway to abstract over DFA and NFA-based operations using the same code (this technique was since\\n\", \"further utilized in NonBacktracking, such as by dotnet/runtime#71234 from\\n[@olsaarik](https://github\", \".com/olsaarik)). And potentially most impactfully, dotnet/runtime#73768 did\\nso with IndexOfAny to ab\", \"stract away the differences between IndexOfAny and IndexOfAnyExcept\\n(also for the Last variants). Wi\", \"th the introduction of the {Last}IndexOfAnyExcept variations\\npreviously mentioned, we now have four \", \"different variants of IndexOfAny with essentially the same\\nfunctionality: searching forward or backw\", \"ards, and with equality or inequality. While more challenging\\nto try to unify the directional aspect\", \", this PR utilized this same kind of generic specialization to hide\\nbehind an interface the ability \", \"to negate the comparison; the core implementations of these methods\\ncan then be implemented once and\", \" passed either a Negate or DontNegate implementation of the\\ninterface. The net result is not only th\", \"at the new Except varieties immediately gained all of the\\noptimizations of the non-Except varieties,\", \" but also the goal of trying to make everything consistent\\nresulted in finding places where we were \", \"missing optimization opportunities in existing methods\\n(gaps that the PR also rectified).\\n184 CHAPTE\", \"R 16 | Networkingprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https:\", \"//www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\npublic int LastIndexOfAny() => s_hay\", \"stack.AsSpan().LastIndexOfAny(';', '_');\\nMethod Runtime Mean Ratio\\nLastIndexOfAny .NET 6.0 9.977 us \", \"1.00\\nLastIndexOfAny .NET 7.0 1.172 us 0.12\\nLet\\u2019s move up the stack to HTTP. Most of the folks focusi\", \"ng on networking in .NET 7 were focused on\\ntaking the preview support for HTTP/3 that shipped in .NE\", \"T 6 and making it a first-class supported\\nfeature in .NET 7. That included functional improvements, \", \"reliability and correctness fixes, and\\nperformance improvements, such that HTTP/3 can now be used vi\", \"a HttpClient on both Windows\\nand Linux (it depends on an underlying QUIC implementation in the msqui\", \"c component, which isn\\u2019t\\ncurrently available for macOS). However, there were significant improvement\", \"s throughout the HTTP\\nstack, beyond HTTP/3.\\nOne aspect of HttpClient that cuts across all versions o\", \"f HTTP is support for handling and\\nrepresenting headers. While significant improvements went into pr\", \"evious releases to trim down the\\nsize of the data structures used to store header information, furth\", \"er work on this front was done for\\n.NET 7. dotnet/runtime#62981, for example, improves the data stru\", \"cture used to store headers. One of\\nthe things HttpHeaders needs to deal with is that there\\u2019s no def\", \"ined limit to the number of headers\\nthat can be sent with an HTTP request or response (though in ord\", \"er to mitigate possible denial of\\nservice attacks, the implementation has a configurable limit for h\", \"ow many bytes of headers are\\naccepted from the server), and thus it needs to be able to handle an ar\", \"bitrary number of them and to\\ndo so with efficient access. As such, for the longest time HttpHeaders\", \" has used a Dictionary<,> to\\nprovide O(1) lookup into these headers. However, while it\\u2019s valid to ha\", \"ve large numbers of headers,\\nit\\u2019s most common to only have a handful, and for only a few items, the \", \"overheads involved in a hash\\ntable like Dictionary<> can be more than just storing the elements in a\", \"n array and doing an O(N)\\nlookup by doing a linear search through all the elements (algorithmic comp\", \"lexity ignores the\\n\\u201cconstants\\u201d involved, so for a small N, an O(N) algorithm might be much faster an\", \"d lighterweight than\\nan O(1)). This PR takes advantage of that and teaches HttpHeaders how to use ei\", \"ther an array or a\\ndictionary; for common numbers of headers (the current threshold is 64), it just \", \"uses an array, and in\\nthe rare case where that threshold is exceeded, it graduates into a dictionary\", \". This reduces the\\nallocation in HttpHeader in all but the most niche cases while also making it fas\", \"ter for lookups.\\nAnother header-related size reduction comes in dotnet/runtime#64105. The internal r\", \"epresentation of\\nheaders involves a HeaderDescriptor that enables \\u201cknown headers\\u201d (headers defined i\", \"n the HTTP\\nspecifications or that we\\u2019re otherwise aware of and want to optimize) to share common dat\", \"a, e.g. if a\\nresponse header matches one of these known headers, we can just use the header name str\", \"ing\\nsingleton rather than allocating a new string for that header each time we receive it. This\\nHead\", \"erDescriptor accomodated both known headers and custom headers by having two fields, one\\nfor known h\", \"eader data (which would be null for custom headers) and one for the header name.\\nInstead, this PR em\", \"ploys a relatively-common technique of having a single object field that then\\nstores either the know\", \"n header information or the name, since the known header information itself\\nincludes the name, and t\", \"hus we don\\u2019t need the duplication. At the expense of a type check when we\\n185 CHAPTER 16 | Networkin\", \"gneed to look up information from that field, we cut the number of fields in half. And while this\\nHe\", \"aderDescriptor is itself a struct, it\\u2019s stored in header collections, and thus by cutting the size o\", \"f the\\nHeaderDescriptor in half, we can significantly reduce the size of those collections, especiall\", \"y when\\nmany custom headers are involved.\\nprivate readonly string[] _strings = new[] { \\\"Access-Contro\", \"l-Allow-Credentials\\\", \\\"Access-\\nControl-Allow-Origin\\\", \\\"Cache-Control\\\", \\\"Connection\\\", \\\"Date\\\", \\\"Server\", \"\\\" };\\n[Benchmark]\\npublic HttpResponseHeaders GetHeaders()\\n{\\nvar headers = new HttpResponseMessage().H\", \"eaders;\\nforeach (string s in _strings)\\n{\\nheaders.TryAddWithoutValidation(s, s);\\n}\\nreturn headers;\\n}\\n\", \"Method Runtime Mean Ratio Allocated Alloc Ratio\\nGetHeaders .NET 6.0 334.4 ns 1.00 664 B 1.00\\nGetHead\", \"ers .NET 7.0 213.9 ns 0.64 360 B 0.54\\nSimilarly focused on allocation, dotnet/runtime#63057 removes \", \"two fields from the\\nHttpHeaderValueCollection<T> collection type, which provides the concrete implem\", \"entation for\\nICollection<T> properties like HttpContentHeaders.ContentEncoding,\\nHttpRequestHeaders.U\", \"serAgent, and HttpResponseHeaders.Server. The initial design and\\nimplementation of this type were ov\", \"erly flexible, with a mechanism for custom validation of values,\\nwhich entailed multiple fields for \", \"storing things like an Action<> callback to use for validation. But as\\nit turns out in practice, tha\", \"t validation was only used for one specific consumer, and so rather than\\nmaking everyone pay for the\", \" extra space that wasn\\u2019t typically used, the validation was instead\\nextracted out to just the call s\", \"ites it was required.\\nA more focused allocation reduction comes in dotnet/runtime#63641. The shared \", \"internal utility\\nmethod HttpRuleParser.GetHostLength was using string.Substring in order to hand bac\", \"k the\\nparsed host information, but only some of the callers needed this. Rather than making everyone\", \" pay\\nfor something that not everyone needed, this logic was moved into only the call sites that need\", \"ed it.\\nOther small allocation improvements were also made outside of headers. For example, when new\\n\", \"HTTP/1 and HTTP/2 connections are created, the implementation queues a work item to the thread\\npool \", \"to handle the actual creation, primarily to escape locks that might be held higher in the call\\nstack\", \". To do so, it used Task.Run. And while normally Task.Run is a fine thing to use, in this case there\", \"\\nwere two issues: the resulting Task was being ignored, such that any unexpected exceptions would\\nju\", \"st be eaten, and the lambda being passed to Task.Run was closing over this and a local, which\\nmeans \", \"the C# compiler will have generated code to allocate both a \\u201cdisplay class\\u201d (an object to store\\nthe \", \"state being passed in) for the closure and then also a delegate to a method on that display class.\\nI\", \"nstead, dotnet/runtime#68750 switches it to use ThreadPool.QueueUserWorkItem, using the\\noverload tha\", \"t takes a generic TState, and passing in a tuple of all required state in order to avoid\\nboth superf\", \"luous allocations.\\n186 CHAPTER 16 | NetworkingFolks using HTTP often need to go through a proxy serv\", \"er, and in .NET the ability to go through an\\nHTTP proxy is represented via the IWebProxy interface; \", \"it has three members, GetProxy for getting the\\nUri of the proxy to use for a given destination Uri, \", \"the IsBypassed method which says whether a\\ngiven Uri should go through a proxy or not, and then a Cr\", \"edentials property to be used when\\naccessing the target proxy. The canonical implementation of IWebP\", \"roxy provided in the core libraries\\nis the aptly named WebProxy. WebProxy is fairly simple: you give\", \" it a proxy Uri, and then calls to\\nGetProxy return that proxy Uri if the destination isn\\u2019t to be byp\", \"assed. Whether a Uri should be\\nbypassed is determined by two things (assuming a non-null proxy Uri w\", \"as provided): did the\\nconstructor of the WebProxy specify that \\u201clocal\\u201d destinations should be bypass\", \"ed (and if so, is this\\ndestination local), or does this destination address match any of any number \", \"of regular expressions\\nprovided. As it turns out, this latter aspect has been relatively slow and al\", \"location-heavy in all previous\\nreleases of .NET, for two reasons: every call to check whether an add\", \"ress was bypassed was recreating\\na Regex instance for every supplied regular expression, and every c\", \"all to check whether an address\\nwas bypassed was deriving a new string from the Uri to use to match \", \"against the Regex. In .NET 7,\\nboth of those issues have been fixed, yielding significant improvement\", \"s if you rely on this regular\\nexpression functionality. dotnet/runtime#73803 from\\n[@onehourlate](htt\", \"ps://github.com/onehourlate) changed the handling of the collection of these\\nRegex instances. The pr\", \"oblem was that WebProxy exposes an ArrayList (this type goes back to the\\nbeginning of .NET and was c\", \"reated pre-generics), which the consumer could modify, and so WebProxy\\nhad to assume the collection \", \"was modified between uses and addressed that by simply creating new\\nRegex instances on every use; no\", \"t good. Instead, this PR creates a custom ArrayList-derived type\\nthat can track all relevant mutatio\", \"ns, and then only if the collection is changed (which is incredibly\\nrare, bordering on never) do the\", \" Regex instances need to be recreated. And dotnet/runtime#73807\\ntakes advantage of stack allocation \", \"and the MemoryExtensions.TryWrite method with string\\ninterpolation to format the text into stack mem\", \"ory, avoiding the string allocation. This, combined with\\nthe new Regex.IsMatch(ReadOnlySpan<char>) o\", \"verload that enables us to match against that\\nstackalloc\\u2019d span, makes that aspect of the operation \", \"allocation-free as well. Altogether, drastic\\nimprovements:\\nprivate WebProxy _proxy = new WebProxy(\\\"h\", \"ttp://doesntexist\\\", BypassOnLocal: false, new[] {\\n@\\\"\\\\.microsoft.com\\\", @\\\"\\\\.dot.net\\\", @\\\"\\\\.bing.com\\\" })\", \";\\nprivate Uri _destination = new\\nUri(\\\"https://docs.microsoft.com/dotnet/api/system.net.webproxy\\\");\\n[\", \"Benchmark]\\npublic bool IsBypassed() => _proxy.IsBypassed(_destination);\\nMethod Runtime Mean Ratio Al\", \"located Alloc Ratio\\nIsBypassed .NET 6.0 5,343.2 ns 1.00 7528 B 1.00\\nIsBypassed .NET 7.0 205.5 ns 0.0\", \"4 - 0.00\\nAlso related to HTTP, WebUtility\\u2019s HtmlDecode method has improved for .NET 7. The implement\", \"ation\\nhad been manually iterating through each character in the input looking for a '&' to be unesca\", \"ped.\\nAny time you see such an open-coded loop looking for one or more specific characters, it\\u2019s a re\", \"d flag\\nthat IndexOf should be strongly considered. dotnet/runtime#70700 deletes the entire searching\", \"\\nfunction and replaces it with IndexOf, yielding simpler and much faster code (you can see other\\nimp\", \"rovements to use IndexOf variants in networking, such as dotnet/runtime#71137, which used\\n187 CHAPTE\", \"R 16 | NetworkingIndexOfAny in HttpListener\\u2019s HandleAuthentication to search a header for certain ki\", \"nds of\\nwhitespace):\\nprivate string _encoded = WebUtility.HtmlEncode(\\\"\\\"\\\"\\nLorem ipsum dolor sit amet, \", \"consectetur adipiscing elit, sed do eiusmod tempor\\nincididunt ut labore et dolore magna aliqua.\\nCond\", \"imentum vitae sapien pellentesque habitant. Vitae auctor eu augue ut lectus. Augue\\nlacus viverra vit\", \"ae congue eu.\\nTempus quam pellentesque nec nam aliquam sem. Urna nec tincidunt praesent semper\\nfeugi\", \"at nibh sed. Amet tellus cras adipiscing\\nenim eu. Duis ultricies lacus sed turpis tincidunt. Et soll\", \"icitudin ac orci phasellus\\negestas tellus rutrum tellus pellentesque.\\n\\\"\\\"\\\");\\n[Benchmark]\\npublic strin\", \"g HtmlDecode() => WebUtility.HtmlDecode(_encoded);\\nMethod Runtime Mean Ratio\\nHtmlDecode .NET 6.0 245\", \".54 ns 1.00\\nHtmlDecode .NET 7.0 19.66 ns 0.08\\nThere have been a myriad of other performance-related \", \"improvements in networking as well, such as\\ndotnet/runtime#67881 which removed the use of TcpClient \", \"from FtpWebRequest;\\ndotnet/runtime#68745 in WebSocket which removed a parameter from one of the core\", \" async methods\\n(and since parameters end up on the state machine, if the async method yields this re\", \"sults in fewer\\nallocated bytes); and dotnet/runtime#70866 and dotnet/runtime#70900, which replaced a\", \"ll remaining\\nuse of Marshal.PtrToStructure in the core networking code with more efficient marshalin\", \"g (e.g. just\\nperforming casts). While Marshal.PtrToStructure is valuable when custom marshaling dire\", \"ctives are\\nused and the runtime needs to be involved in the conversion, it\\u2019s also much more heavywei\", \"ght than\\njust casting, which can be done when the native and managed layouts are bit-for-bit compati\", \"ble. As\\nwith the u8 example earlier, this comparison is hardly fair, but that\\u2019s exactly the point:\\np\", \"rivate IntPtr _mem;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n_mem = Marshal.AllocHGlobal(8);\\nMarshal.Stru\", \"ctureToPtr(new SimpleType { Value1 = 42, Value2 = 84 }, _mem, false);\\n}\\n[GlobalCleanup]\\npublic void \", \"Cleanup() => Marshal.FreeHGlobal(_mem);\\npublic struct SimpleType\\n{\\npublic int Value1;\\npublic int Val\", \"ue2;\\n}\\n[Benchmark(Baseline = true)]\\npublic SimpleType PtrToStructure() => Marshal.PtrToStructure<Sim\", \"pleType>(_mem);\\n[Benchmark]\\npublic unsafe SimpleType Cast() => *(SimpleType*)_mem;\\n188 CHAPTER 16 | \", \"NetworkingMethod Mean Ratio\\nPtrToStructure 26.6593 ns 1.000\\nCast 0.0736 ns 0.003\\nFor folks using Neg\", \"otiateStream, dotnet/runtime#71280 from\\n[@filipnavara](https://github.com/filipnavara) will also be \", \"very welcome (this comes as part of a larger\\neffort, primarily in dotnet/runtime#71777 from [@filipn\", \"avara](https://github.com/filipnavara) and\\ndotnet/runtime#70720 from [@filipnavara](https://github.c\", \"om/filipnavara), to expose the new\\nNegotiateAuthentication class). It removes a significant amount o\", \"f allocation from a typical NTLM\\nhandshake by reusing a buffer rather than reallocating a new buffer\", \" for each of multiple phases of the\\nhandshake:\\nprivate NetworkStream _client, _server;\\n[GlobalSetup]\", \"\\npublic void Setup()\\n{\\nusing var listener = new Socket(AddressFamily.InterNetwork, SocketType.Stream\", \",\\nProtocolType.Tcp);\\nlistener.Bind(new IPEndPoint(IPAddress.Loopback, 0));\\nlistener.Listen(1);\\nvar c\", \"lient = new Socket(AddressFamily.InterNetwork, SocketType.Stream,\\nProtocolType.Tcp);\\nclient.Connect(\", \"listener.LocalEndPoint);\\nSocket server = listener.Accept();\\n_client = new NetworkStream(client, owns\", \"Socket: true);\\n_server = new NetworkStream(server, ownsSocket: true);\\n}\\n[Benchmark]\\npublic async Tas\", \"k Handshake()\\n{\\nusing NegotiateStream client = new NegotiateStream(_client, leaveInnerStreamOpen:\\ntr\", \"ue);\\nusing NegotiateStream server = new NegotiateStream(_server, leaveInnerStreamOpen:\\ntrue);\\nawait \", \"Task.WhenAll(client.AuthenticateAsClientAsync(),\\nserver.AuthenticateAsServerAsync());\\n}\\nMethod Runti\", \"me Mean Ratio Allocated Alloc Ratio\\nHandshake .NET 6.0 1.905 ms 1.00 240.5 KB 1.00\\nHandshake .NET 7.\", \"0 1.913 ms 1.00 99.28 KB 0.41\\n189 CHAPTER 16 | Networking17\\nCHAPTER\\nJSON\\nSystem.Text.Json was introd\", \"uced in .NET Core 3.0, and has seen a significant amount of investment\\nin each release since. .NET 7\", \" is no exception. New features in .NET 7 include support for customizing\\ncontracts, polymorphic seri\", \"alization, support for required members, support for DateOnly / TimeOnly,\\nsupport for IAsyncEnumerab\", \"le<T> and JsonDocument in source generation, and support for\\nconfiguring MaxDepth in JsonWriterOptio\", \"ns. However, there have also been new features specifically\\nfocused on performance, and other change\", \"s about improving performance of JSON handling in a\\nvariety of scenarios.\\nOne of the biggest perform\", \"ance pitfalls we\\u2019ve seen developers face with System.Text.Json has to do\\nwith how the library caches\", \" data. In order to achieve good serialization and deserialization\\nperformance when the source genera\", \"tor isn\\u2019t used, System.Text.Json uses reflection emit to\\ngenerate custom code for reading/writing me\", \"mbers of the types being processed. Instead of then\\nhaving to pay reflection invoke costs on every a\", \"ccess, the library incurs a much larger one-time cost\\nper type to perform this code generation, but \", \"then all subsequent handling of these types is very\\nfast\\u2026 assuming the generated code is available f\", \"or use. These generated handlers need to be stored\\nsomewhere, and the location that\\u2019s used for stori\", \"ng them is them is JsonSerializerOptions. The\\nidea was intended to be that developers would instanti\", \"ate an options instance once and pass it\\naround to all of their serialization/deserialization calls;\", \" thus, state like these generated handlers could\\nbe cached on them. And that works well when develop\", \"ers follow the recommended model. But when\\nthey don\\u2019t, performance falls off a cliff, and hard. Inst\", \"ead of \\u201cjust\\u201d paying for the reflection invoke\\ncosts, each use of a new JsonSerializerOptions ends u\", \"p re-generating via reflection emit those\\nhandlers, skyrocketing the cost of serialization and deser\", \"ialization. A super simple benchmark makes\\nthis obvious:\\nprivate JsonSerializerOptions _options = ne\", \"w JsonSerializerOptions();\\nprivate MyAmazingClass _instance = new MyAmazingClass();\\n[Benchmark(Basel\", \"ine = true)]\\npublic string ImplicitOptions() => JsonSerializer.Serialize(_instance);\\n[Benchmark]\\npub\", \"lic string WithCached() => JsonSerializer.Serialize(_instance, _options);\\n[Benchmark]\\npublic string \", \"WithoutCached() => JsonSerializer.Serialize(_instance, new\\nJsonSerializerOptions());\\npublic class My\", \"AmazingClass\\n{\\npublic int Value { get; set; }\\n}\\n190 CHAPTER 17 | JSONMethod Runtime Mean Ratio Alloc\", \"ated Alloc Ratio\\nImplicitOptions .NET 6.0 170.3 ns 1.00 200 B 1.00\\nWithCached .NET 6.0 163.8 ns 0.96\", \" 200 B 1.00\\nWithoutCached .NET 6.0 100,440.6 ns 592.48 7393 B 36.97\\nIn .NET 7, this was fixed in dot\", \"net/runtime#64646 (and subsequently tweaked in\\ndotnet/runtime#66248) by adding a global cache of the\", \" type information separate from the options\\ninstances. A JsonSerializerOptions still has a cache, bu\", \"t when new handlers are generated via\\nreflection emit, those are also cached at the global level (wi\", \"th appropriate removal when no longer\\nused in order to avoid unbounded leaks).\\nMethod Runtime Mean R\", \"atio Allocated Alloc Ratio\\nImplicitOptions .NET 6.0 170.3 ns 1.00 200 B 1.00\\nImplicitOptions .NET 7.\", \"0 166.8 ns 0.98 48 B 0.24\\nWithCached .NET 6.0 163.8 ns 0.96 200 B 1.00\\nWithCached .NET 7.0 168.3 ns \", \"0.99 48 B 0.24\\nWithoutCached .NET 6.0 100,440.6 ns 592.48 7393 B 36.97\\nWithoutCached .NET 7.0 590.1 \", \"ns 3.47 337 B 1.69\\nAs can be seen here, it\\u2019s still more expensive to create a new JsonSerializerOpti\", \"ons instance on\\neach call, and the recommended approach is \\u201cdon\\u2019t do that.\\u201d But if someone does do i\", \"t, in this\\nexample they\\u2019re only paying 3.6x the cost rather than 621x the cost, a huge improvement.\\n\", \"dotnet/runtime#61434 also now exposes the JsonSerializerOptions.Default instance that\\u2019s used\\nby defa\", \"ult if no options are explicitly provided.\\nAnother change to JsonSerializer came in dotnet/runtime#7\", \"2510, which slightly improved the\\nperformance of serialization when using the source generator. The \", \"source generator emits helpers for\\nperforming the serialization/deserialization work, and these are \", \"then invoked by JsonSerializer via\\ndelegates (as part of abstracting away all the different implemen\", \"tation strategies for how to get and\\nset members on the types being serialized and deserialized). Pr\", \"eviously, these helpers were being\\nemitted as static methods, which in turn meant that the delegates\", \" were being created to static\\nmethods. Delegates to instance methods are a bit faster to invoke than\", \" delegates to static methods,\\nso this PR made a simple few-line change for the source generator to e\", \"mit these as instance methods\\ninstead.\\nYet another for JsonSerializer comes in dotnet/runtime#73338,\", \" which improves allocation with how\\nit utilizes Utf8JsonWriter. Utf8JsonWriter is a class, and every\", \" time JsonSerializer would write\\nout JSON, it would allocate a new Utf8JsonWriter instance. In turn,\", \" Utf8JsonWriter needs\\nsomething to write to, and although the serializer was using an IBufferWriter \", \"implementation that\\npooled the underlying byte[] instances employed, the implementation of IBufferWr\", \"iter itself is a\\nclass that JsonSerializer would allocate. A typical Serialize call would then end u\", \"p allocating a\\nfew extra objects and an extra couple of hundred bytes just for these helper data str\", \"uctures. To\\naddress that, this PR takes advantage of [ThreadStatic], which can be put onto static fi\", \"elds to make\\nthem per-thread rather than per-process. From whatever thread is performing the (synchr\", \"onous)\\n191 CHAPTER 17 | JSONSerialize operation, it then ensures the current thread has a Utf8JsonWr\", \"iter and IBufferWriter\\ninstance it can use, and uses them; for the most part this is straightforward\", \", but it needs to ensure that\\nthe serialization operation itself doesn\\u2019t try to recursively serializ\", \"e, in which case these objects could\\nend up being used erroneously while already in use. It also nee\", \"ds to make sure that the pooled\\nIBufferWriter doesn\\u2019t hold on to any of its byte[]s while it\\u2019s not b\", \"eing used. That instance gets its\\narrays from ArrayPool<T>, and we want those arrays to be usable in\", \" the meantime by anyone else\\nmaking use of the pool, not sequestered off in this cached IBufferWrite\", \"r implementation. This\\noptimization is also only really meaningful for small object graphs being ser\", \"ialized, and only applies to\\nthe synchronous operations (asynchronous operations would require a mor\", \"e complicated pooling\\nmechanism, since the operation isn\\u2019t tied to a specific thread, and the overhe\", \"ad of such complication\\nwould likely outweigh the modest gain this optimization provides).\\nprivate b\", \"yte[] _data = new byte[] { 1, 2, 3, 4, 5 };\\n[Benchmark]\\npublic string SerializeToString() => JsonSer\", \"ializer.Serialize(_data);\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nSerializeToString .NET 6.0\", \" 146.4 ns 1.00 200 B 1.00\\nSerializeToString .NET 7.0 137.5 ns 0.94 48 B 0.24\\nUtf8JsonWriter and Utf8\", \"JsonReader also saw several improvements directly. dotnet/runtime#69580\\nadds a few new performance-f\", \"ocused members, the ValueIsEscaped property (which exposes already\\ntracked information and enables c\", \"onsumers to avoid the expense of re-checking) and the CopyString\\nmethod (which provides a non-alloca\", \"ting mechanism to get access to a string value from the reader).\\nIt then also uses the added support\", \" internally to speed up certain operations on Utf8JsonReader. And\\ndotnet/runtime#63863, dotnet/runti\", \"me#71534, and dotnet/runtime#61746 fix how some exception\\nchecks and throws were being handled so as\", \" to not slow down the non-exceptional fast paths.\\n192 CHAPTER 17 | JSON18\\nCHAPTER\\nXML\\nSystem.Xml is \", \"used by a huge number of applications and services, but ever since JSON hit the scene\\nand has been a\", \"ll the rage, XML has taken a back seat and thus hasn\\u2019t seen a lot of investment from\\neither a functi\", \"onality or performance perspective. Thankfully, System.Xml gets a bit of performance\\nlove in .NET 7,\", \" in particular around reducing allocation on some commonly used code paths.\\nSometimes a performance \", \"fix is as easy as changing a single number. That\\u2019s the case with\\ndotnet/runtime#63459 from [@chrisdc\", \"moore](https://github.com/chrisdcmoore), which addresses a\\nlong-standing issue with the asynchronous\", \" methods on the popular XmlReader. When XmlReader was\\noriginally written, whoever developed it chose\", \" a fairly common buffer size to be used for read\\noperations, namely 4K or 8K chars depending on vari\", \"ous conditions. When XmlReader later gained\\nasynchronous reading functionality, for whatever reason \", \"a much, much larger buffer size of 64K chars\\nwas selected (presumably in hopes of minimizing the num\", \"ber of asynchronous operations that would\\nneed to be employed, but the actual rationale is lost to h\", \"istory). A key problem with such a buffer size,\\nbeyond it leading to a lot of allocation, is the all\", \"ocation it produces typically ends up on the Large\\nObject Heap (LOH). By default, under the expectat\", \"ion that really large objects are long-lived, objects\\ngreater than 85K bytes are allocated into the \", \"LOH, which is treated as part of Gen 2, and that makes\\nsuch allocation if not long-lived even more e\", \"xpensive in terms of overall impact on the system. Well,\\n64K chars is 128K bytes, which puts it squa\", \"rely above that threshold. This PR lowers the size from 64K\\nchars to 32K chars, putting it below the\", \" threshold (and generally reducing allocation pressure, how\\nmuch memory needs to be zero\\u2019d, etc). Wh\", \"ile it\\u2019s still a very large allocation, and in the future we\\ncould look at pooling the buffer or emp\", \"loying a smaller one (e.g. no different from what\\u2019s done for\\nthe synchronous APIs), this simple one-\", \"number change alone makes a substantial difference for\\nshorter input documents (while not perceivabl\", \"y negatively impacting larger ones).\\nprivate readonly XmlReaderSettings _settings = new XmlReaderSet\", \"tings { Async = true };\\nprivate MemoryStream _stream;\\n[Params(10, 1_000_000)]\\npublic int ItemCount;\\n\", \"[GlobalSetup]\\npublic void Setup()\\n{\\n_stream = new MemoryStream();\\nusing XmlWriter writer = XmlWriter\", \".Create(_stream);\\nwriter.WriteStartElement(\\\"Items\\\");\\nfor (var i = 0; i < ItemCount; i++)\\n{\\nwriter.Wr\", \"iteStartElement($\\\"Item{i}\\\");\\nwriter.WriteEndElement();\\n}\\nwriter.WriteEndElement();\\n193 CHAPTER 18 | \", \"XML}\\n[Benchmark]\\npublic async Task XmlReader_ReadAsync()\\n{\\n_stream.Position = 0;\\nusing XmlReader rea\", \"der = XmlReader.Create(_stream, _settings);\\nwhile (await reader.ReadAsync());\\n}\\nAlloc\\nMethod Runtime\", \" ItemCount Mean Ratio Allocated Ratio\\nXmlReader_ReadAsync .NET 6.0 10 42.344 us 1.00 195.94 KB 1.00\\n\", \"XmlReader_ReadAsync .NET 7.0 10 9.992 us 0.23 99.94 KB 0.51\\nXmlReader_ReadAsync .NET 6.0 1000000 340\", \",382.953 1.00 101790.34 1.00\\nus KB\\nXmlReader_ReadAsync .NET 7.0 1000000 333,417.347 0.98 101804.45 1\", \".00\\nus KB\\nXmlReader and XmlWriter saw other allocation-related improvements as well. dotnet/runtime#\", \"60076\\nfrom [@kronic](https://github.com/kronic) improved the ReadOnlyTernaryTree internal type that\\u2019\", \"s\\nused when XmlOutputMethod.Html is specified in the XmlWriterSettings. This included using a\\nReadOn\", \"lySpan<byte> initialized from an RVA static instead of a large byte[] array that would need to\\nbe al\", \"located. And dotnet/runtime#60057 from [@kronic](https://github.com/kronic), which converted\\n~400 st\", \"ring creations in the System.Private.Xml assembly to use interpolated strings. Many of\\nthese cases w\", \"ere stylistic, converting something like string1 + \\\":\\\" + string2 into\\n$\\\"{string1}:{string2}\\\"; I say \", \"stylistic here because the C# compiler will generate the exact same\\ncode for both of those, a call t\", \"o string.Concat(string1, \\\":\\\", string2), given that there\\u2019s a\\nConcat overload that accepts three stri\", \"ngs. However, some of the changes do impact allocation. For\\nexample, the private XmlTextWriter.Gener\", \"atePrefix method had the code:\\nreturn \\\"d\\\" + _top.ToString(\\\"d\\\", CultureInfo.InvariantCulture)\\n+ \\\"p\\\" +\", \" temp.ToString(\\\"d\\\", CultureInfo.InvariantCulture);\\nwhere _top and temp are both ints. This will resu\", \"lt in allocating two temporary strings and then\\nconcatenating those with the two constant strings. I\", \"nstead, the PR changed it to:\\nreturn string.Create(CultureInfo.InvariantCulture, $\\\"d{_top:d}p{temp:d\", \"}\\\");\\nwhich while shorter is also more efficient, avoiding the intermediate string allocations, as th\", \"e custom\\ninterpolated string handler used by string.Create will format those into a pooled buffer ra\", \"ther than\\nallocating intermediate temporaries.\\nXmlSerializer is also quite popular and also gets a (\", \"small) allocation reduction, in particular for\\ndeserialization. XmlSerializer has two modes for gene\", \"rating serialization/deserialization routines:\\nusing reflection emit to dynamically generate IL at r\", \"un-time that are tuned to the specific shape of the\\ntypes being serialized/deserialized, and the XML\", \" Serializer Generator Tool (sgen), which generates a\\n.dll containing the same support, just ahead-of\", \"-time (a sort-of precursor to the Roslyn source\\n194 CHAPTER 18 | XMLgenerators we love today). In bo\", \"th cases, when deserializing, the generated code wants to track which\\nproperties of the object being\", \" deserialized have already been set, and to do that, it uses a bool[] as a\\nbit array. Every time an \", \"object is deserialized, it allocates a bool[] with enough elements to track\\nevery member of the type\", \". But in common usage, the vast majority of types being deserialized only\\nhave a relatively small nu\", \"mber of properties, which means we can easily use stack memory to track\\nthis information rather than\", \" heap memory. That\\u2019s what dotnet/runtime#66914 does. It updates both\\nof the code generators to stack\", \"alloc into a Span<bool> for less than or equal to 32 values, and\\notherwise fall back to the old appr\", \"oach of heap-allocating the bool[] (which can also then be stored\\ninto a Span<bool> so that the subs\", \"equent code paths simply use a span instead of an array). You can\\nsee this quite easily in the .NET \", \"Object Allocation Tracking tool in Visual Studio. For this console app\\n(which, as an aside, shows ho\", \"w lovely the new raw string literals feature in C# is for working with\\nXML):\\nusing System.Text;\\nusin\", \"g System.Xml.Serialization;\\nvar serializer = new XmlSerializer(typeof(Release[]));\\nvar stream = new \", \"MemoryStream(Encoding.UTF8.GetBytes(\\n\\\"\\\"\\\"\\n<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n<ArrayOfRelease xmln\", \"s:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\nxmlns:xsd=\\\"http://www.w3.org/2001/XMLSchema\\\">\\n<Rel\", \"ease><Major>1</Major><Minor>0</Minor></Release>\\n<Release><Major>1</Major><Minor>1</Minor></Release>\\n\", \"<Release><Major>2</Major><Minor>0</Minor></Release>\\n<Release><Major>2</Major><Minor>1</Minor></Relea\", \"se>\\n<Release><Major>2</Major><Minor>2</Minor></Release>\\n<Release><Major>3</Major><Minor>0</Minor></R\", \"elease>\\n<Release><Major>3</Major><Minor>1</Minor></Release>\\n<Release><Major>5</Major><Minor>0</Minor\", \"></Release>\\n<Release><Major>6</Major><Minor>0</Minor></Release>\\n<Release><Major>7</Major><Minor>0</M\", \"inor></Release>\\n</ArrayOfRelease>\\n\\\"\\\"\\\"));\\nfor (int i = 0; i < 1000; i++)\\n{\\nstream.Position = 0;\\nseria\", \"lizer.Deserialize(stream);\\n}\\npublic class Release\\n{\\npublic int Major;\\npublic int Minor;\\npublic int B\", \"uild;\\npublic int Revision;\\n}\\nHere\\u2019s what I see when I run this under .NET 6:\\n195 CHAPTER 18 | XMLWe\\u2019\", \"re running a thousand deserializations, each of which will deserialize 10 Release instances, and so\\n\", \"we expect to see 10,000 Release objects being allocated, which we do\\u2026 but we also see 10,000\\nbool[] \", \"being allocated. Now with .NET 7 (note the distinct lack of the per-object bool[]):\\nOther allocation\", \" reduction went into the creation of the serializer/deserializer itself, such as with\\ndotnet/runtime\", \"#68738 avoiding allocating strings to escape text that didn\\u2019t actually need escaping,\\ndotnet/runtime\", \"#66915 using stack allocation for building up small text instead of using a\\nStringBuilder, dotnet/ru\", \"ntime#66797 avoiding delegate and closure allocations in accessing the\\ncache of serializers previous\", \"ly created, dotnet/runtime#67001 from\\n[@TrayanZapryanov](https://github.com/TrayanZapryanov) caching\", \" an array used with string.Split,\\nand dotnet/runtime#67002 from [@TrayanZapryanov](https://github.co\", \"m/TrayanZapryanov) that\\nchanged some parsing code to avoid a string.ToCharArray invocation.\\nFor folk\", \"s using XML schema, dotnet/runtime#66908 replaces some Hashtables in the implementation\\nwhere those \", \"collections were storing ints as the value. Given that Hashtable is a non-generic\\ncollection, every \", \"one of those ints was getting boxed, resulting in unnecessary allocation overhead;\\nthese were fixed \", \"by replacing these Hashtables with Dictionary<..., int> instances. (As an aside,\\nthis is a fairly co\", \"mmon performance-focused replacement to do, but you need to be careful as\\nHashtable has a few behavi\", \"oral differences from Dictionary<,>; beyond the obvious difference of\\nHashtable returning null from \", \"its indexer when a key isn\\u2019t found and Dictionary<,> throwing in\\nthat same condition, Hashtable is t\", \"hread-safe for use with not only multiple readers but multiple\\nreaders concurrent with a single writ\", \"er, and Dictionary<,> is not.) dotnet/runtime#67045 reduces\\nallocation of XmlQualifiedName instances\", \" in the implementation of XsdBuilder.ProcessElement and\\nXsdBuilder.ProcessAttribute. And dotnet/runt\", \"ime#64868 from\\n[@TrayanZapryanov](https://github.com/TrayanZapryanov) uses stack-based memory and po\", \"oling to\\n196 CHAPTER 18 | XMLavoid temporary string allocation in the implementation of the internal\", \" XsdDateTime and\\nXsdDuration types, which are used by the public XmlConvert.\\nprivate TimeSpan _ts = \", \"TimeSpan.FromMilliseconds(12345);\\n[Benchmark]\\npublic string XmlConvertToString() => XmlConvert.ToStr\", \"ing(_ts);\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nXmlConvertToString .NET 6.0 90.70 ns 1.00 \", \"184 B 1.00\\nXmlConvertToString .NET 7.0 59.21 ns 0.65 40 B 0.22\\nXML pops up in other areas as well, a\", \"s in the XmlWriterTraceListener type. While the\\nSystem.Diagnostics.Trace type isn\\u2019t the recommended \", \"tracing mechanism for new code, it\\u2019s widely\\nused in existing applications, and XmlWriterTraceListene\", \"r let\\u2019s you plug in to that mechanism to\\nwrite out XML logs for traced information. dotnet/runtime#6\", \"6762 avoids a bunch of string allocation\\noccurring as part of this tracing, by formatting much of th\", \"e header information into a span and then\\nwriting that out rather than ToString()\\u2019ing each individua\", \"l piece of data.\\n[GlobalSetup]\\npublic void Setup()\\n{\\nTrace.Listeners.Clear();\\nTrace.Listeners.Add(ne\", \"w XmlWriterTraceListener(Stream.Null));\\n}\\n[Benchmark]\\npublic void TraceWrite()\\n{\\nTrace.WriteLine(\\\"So\", \"mething important\\\");\\n}\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nTraceWrite .NET 6.0 961.9 ns \", \"1.00 288 B 1.00\\nTraceWrite .NET 7.0 772.2 ns 0.80 64 B 0.22\\n197 CHAPTER 18 | XML19\\nCHAPTER\\nCryptogra\", \"phy\\nSome fairly significant new features came to System.Security.Cryptography in .NET 7, including t\", \"he\\nsupport necessary to enable the previously discussed OCSP stapling and support for building\\ncerti\", \"ficate revocation lists, but there was also a fair amount of effort put into making existing support\", \"\\nfaster and more lightweight.\\nOne fairly substantial change in .NET 7 is split across dotnet/runtime\", \"#61025, dotnet/runtime#61137,\\nand dotnet/runtime#64307. These PRs don\\u2019t change any code materially, \", \"but instead consolidate all of\\nthe various cryptography-related assemblies in the core libraries int\", \"o a single\\nSystem.Security.Cryptography assembly. When .NET Core was first envisioned, a goal was to\", \" make\\nit extremely modular, and large swaths of code were teased apart to create many smaller assemb\", \"lies.\\nFor example, cryptographic functionality was split between\\nSystem.Security.Cryptography.Algori\", \"thms.dll, System.Security.Cryptography.Cng.dll,\\nSystem.Security.Cryptography.Csp.dll, System.Securit\", \"y.Cryptography.Encoding.dll,\\nSystem.Security.Cryptography.OpenSsl.dll, System.Security.Cryptography.\", \"Primitives.dll,\\nand System.Security.Cryptography.X509Certificates.dll. You can see this if you look \", \"in your\\nshared framework folder for a previous release, e.g. here\\u2019s mine for .NET 6:\\nThese PRs move \", \"all of that code into a single System.Security.Cryptography.dll assembly. This has\\nseveral benefits.\", \" First, crypto is used in a huge number of applications, and most apps would end up\\n198 CHAPTER 19 |\", \" Cryptographyrequiring multiple (or even most) of these assemblies. Every assembly that\\u2019s loaded add\", \"s overhead.\\nSecond, a variety of helper files had to be compiled into each assembly, leading to over\", \"all larger\\namount of compiled code to be distributed. And third, we weren\\u2019t able to implement everyt\", \"hing as\\noptimal as we\\u2019d have otherwise liked due to functionality in one assembly not exposed to ano\", \"ther\\n(and we avoid using InternalsVisibleTo as it hampers maintainability and impedes other analysis\", \"\\nand optimizations). Now in .NET 7, the shared framework looks more like this:\\nInteresting, you stil\", \"l see a bunch of assemblies there, but all except for\\nSystem.Security.Cryptography.dll are tiny; tha\", \"t\\u2019s because these are simple facades. Because we\\nneed to support binaries built for .NET 6 and earli\", \"er running on .NET 7, we need to be able to handle\\nbinaries that refer to types in these assemblies,\", \" but in .NET 7, those types actually live in\\nSystem.Security.Cryptography.dll. .NET provides a solut\", \"ion for this in the form of the\\n[TypeForwardedTo(...)] attribute, which enables one assembly to say \", \"\\u201chey, if you\\u2019re looking for type\\nX, it now lives over there.\\u201d And if you crack open one of these ass\", \"emblies in a tool like ILSpy, you can\\nsee they\\u2019re essentially empty except for a bunch of these attr\", \"ibutes:\\n199 CHAPTER 19 | CryptographyIn addition to the startup and maintenance wins this provides, \", \"this has also enabled further\\nsubsequent optimization. For example, there\\u2019s a lot of object cloning \", \"that goes on in the innards of\\nthis library. Various objects are used to wrap native handles to OS c\", \"ryptographic resources, and to\\nhandle lifetime semantics and ownership appropriately, there are many\", \" cases where a native handle is\\nduplicated and then wrapped in one or more new managed objects. In s\", \"ome cases, however, the\\noriginal resource is then destroyed because it\\u2019s no longer needed, and the w\", \"hole operation could\\nhave been made more efficient if the original resource just had its ownership t\", \"ransferred to the new\\nobjects rather than being duplicated and destroyed. This kind of ownership tra\", \"nsfer typically is hard to\\ndo between assemblies as it generally requires public API that\\u2019s not focu\", \"sed on such usage patterns,\\nbut with internals access, this can be overcome. dotnet/runtime#72120 do\", \"es this, for example, to\\nreduce allocation of various resources inside the RSACng, DSACng, ECDsaCng,\", \" and ECDiffieHellmanCng\\npublic types.\\nIn terms of actual code improvements, there are many. One cate\", \"gory of improvements is around\\n\\u201cone-shot\\u201d operations. With many forms of data processing, all of the\", \" data needn\\u2019t be processed in\\none operation. A block of data can be processed, then another, then an\", \"other, until finally there\\u2019s no\\nmore data to be processed. In such usage, there\\u2019s often some kind of\", \" state carried over from the\\nprocessing of one block to the processing of the next, and then the pro\", \"cessing of the last block is\\nspecial as it needn\\u2019t carry over anything and instead needs to perform \", \"whatever work is required to\\nend the whole operation, e.g. outputting any final footer or checksum t\", \"hat might be required as part\\nof the format. Thus, APIs that are able to handle arbitrary number of \", \"blocks of data are often a bit\\nmore expensive in one way, shape, or form than APIs that only support\", \" a single input; this latter\\ncategory is known as \\u201cone shot\\u201d operations, because they do everything \", \"in \\u201cone shot.\\u201d In some cases,\\none-shot operations can be significantly cheaper, and in other cases t\", \"hey merely avoid some\\nallocations that would have been necessary to transfer state from the processi\", \"ng of one block of data\\nto the next. dotnet/runtime#58270 from [@vcsjones](https://github.com/vcsjon\", \"es) and\\ndotnet/runtime#65725 from [@vcsjones](https://github.com/vcsjones) both improved the\\nperform\", \"ance of various one-shot operations on \\u201csymmetric\\u201d cryptograhic algorithms (algorithms that\\nuse the \", \"same key information to both encrypt and decrypt), like AES. The former does so by\\nrefactoring the i\", \"mplementations to avoid some reset work that\\u2019s not necessary in the case of one-\\nshots because the r\", \"elevant state is about to go away, anyway, and that in turns also allows the\\nimplementation to store\", \" less of certain kinds of state. The latter does so for decryption one-shots by\\ndecrypting directly \", \"into the destination buffer whenever possible, using stack space if possible when\\ngoing directly int\", \"o the user\\u2019s buffer isn\\u2019t feasible, etc.\\n200 CHAPTER 19 | Cryptographyprivate byte[] _plaintext = En\", \"coding.UTF8.GetBytes(\\\"This is a test. This is only a test.\\nNothing to see here.\\\");\\nprivate byte[] _i\", \"v = Enumerable.Range(0, 16).Select(i => (byte)i).ToArray();\\nprivate Aes _aes = Aes.Create();\\nprivate\", \" byte[] _output = new byte[1000];\\n[Benchmark]\\npublic bool OneShot() => _aes.TryEncryptCfb(_plaintext\", \", _iv, _output, out _);\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nOneShot .NET 6.0 1.828 us 1.\", \"00 336 B 1.00\\nOneShot .NET 7.0 1.770 us 0.97 184 B 0.55\\nIn addition to making one-shots lighterweigh\", \"t, other PRs have then used these one-shot operations in\\nmore places in order to simplify their code\", \" and benefit from the increased performance, e.g.\\ndotnet/runtime#70639 from [@vcsjones](https://gith\", \"ub.com/vcsjones), dotnet/runtime#70857 from\\n[@vcsjones](https://github.com/vcsjones), dotnet/runtime\", \"#64005 from\\n[@vcsjones](https://github.com/vcsjones), and dotnet/runtime#64174 from\\n[@vcsjones](http\", \"s://github.com/vcsjones).\\nThere\\u2019s also a large number of PRs that have focused on removing allocatio\", \"ns from around the crypto\\nstack:\\n\\u2022 Stack allocation. As has been seen in many other PRs referenced t\", \"hroughout this post, using\\nstackalloc is a very effective way to get rid of array allocations in man\", \"y situations. It\\u2019s used\\neffectively in multiple crypto PRs to avoid either temporary or pooled array\", \" allocations, such as\\nin dotnet/runtime#64584 from [@vcsjones](https://github.com/vcsjones), dotnet/\", \"runtime#69831\\nfrom [@vcsjones](https://github.com/vcsjones), dotnet/runtime#70173 from\\n[@vcsjones](h\", \"ttps://github.com/vcsjones), dotnet/runtime#69812 from\\n[@vcsjones](https://github.com/vcsjones), and\", \" dotnet/runtime#69448 from\\n[@vcsjones](https://github.com/vcsjones). Sometimes this is used when cal\", \"ling an API that has\\nmultiple overloads, including one taking an array and one taking a span. Othert\", \"imes it\\u2019s used\\nwith P/Invokes that often just pass out a small amount of data. Sometimes it\\u2019s used t\", \"o avoid\\ntemporary array allocations, and sometimes it\\u2019s used in places where pooling was used\\nprevio\", \"usly, but the data is often small enough to avoid even the overheads of pooling.\\n\\u2022 Avoiding double c\", \"opies. Most of the crypto APIs that accept byte[]s and store them end up\\nmaking defensive copies of \", \"those arrays rather than storing the original. This is fairly common\\nthroughout .NET, but it\\u2019s espec\", \"ially common in the crypto stack, where the ability to trust the\\ndata is as you expect it (and valid\", \"ate it) is paramount. In some cases, though, code ends up\\nallocating a temporary byte[] just to pass\", \" data into one of these APIs that copies and re-\\nallocates, anyway. dotnet/runtime#71102 from [@vcsj\", \"ones](https://github.com/vcsjones),\\ndotnet/runtime#69024 from [@vcsjones](https://github.com/vcsjone\", \"s), dotnet/runtime#71015\\nfrom [@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69534 fro\", \"m\\n[@vcsjones](https://github.com/vcsjones) deal with that duplication in some cases by extracting\\na \", \"span to the original data instead of creating a temporary byte[]; when that span is passed into\\nthe \", \"target API, the target API still makes a copy, but we\\u2019ve avoided the first one and thus cut the\\narra\", \"y allocation for these operations effectively in half. dotnet/runtime#71888 from\\n[@vcsjones](https:/\", \"/github.com/vcsjones) is a variation on this theme, improving the internals of\\n201 CHAPTER 19 | Cryp\", \"tographyRfc2898DeriveBytes to supports spans such that its constructors that accept spans can then d\", \"o\\nthe more efficient thing.\\n\\u2022 Replacing O(1) data structures. O(1) lookup data structures like Dicti\", \"onary<,> and\\nHashSet<> are the lifeblood of most applications and services, but sometimes algorithmi\", \"c\\ncomplexity is misleading. Yes, these provide very efficient searching, but there\\u2019s still overhead\\n\", \"associated with computing a hash code, mapping that hash code to a location in the data\\nstructure, a\", \"nd so on. If there\\u2019s only ever a handful of items (i.e. the N in the complexity is really,\\nreally sm\", \"all), it can be much faster to just do a linear search, and if N is sufficiently small, a data\\nstruc\", \"ture may not even be needed at all: the search can just be open-coded as a waterfall of\\nif/elseif/el\", \"se constructs. That\\u2019s the case in a PR like dotnet/runtime#71341 from\\n[@vcsjones](https://github.com\", \"/vcsjones), where the 99.999% case involves just five strings\\n(names of hash algorithms); it\\u2019s cheap\", \"er to just compare against each than it is do a\\nHashSet<>.Contains, especially since the JIT now unr\", \"olls and vectorizes the comparison against\\nthe constant string names.\\n\\u2022 Simply avoiding unnecessary \", \"work. The best optimizations are ones where you simply stop\\ndoing work you don\\u2019t have to do. dotnet/\", \"runtime#68553 from\\n[@vcsjones](https://github.com/vcsjones) is a good example of this. This code was\", \" performing a\\nhash of some data in order to determine the length of resulting hashes for that partic\", \"ular\\nconfiguration, but we actually know ahead of time exactly how long a hash for a given algorithm\", \"\\nis going to be, and we already have in this code a cascading if/elseif/else that\\u2019s checking for eac\", \"h\\nknown algorithm, so we can instead just hardcode the length for each. dotnet/runtime#70589\\nfrom [@\", \"vcsjones](https://github.com/vcsjones) is another good example, in the same spirit of\\nthe ownership \", \"transfer example mentioned earlier (but this one didn\\u2019t previously span assembly\\nboundaries). Rather\", \" than in several places taking an X509Extension, serializing it to a byte[],\\nand passing that tempor\", \"ary byte[] to something else that in turn makes a defensive copy, we\\ncan instead provide an internal\", \" pathway for ownership transfer, bypassing all of the middle\\nstages. Another good one is dotnet/runt\", \"ime#70618 from\\n[@vcsjones](https://github.com/vcsjones), as it\\u2019s an example of how it pays to really\", \" understand\\nyour dependencies. The implementation of symmetric encryption on macOS uses the\\nCommonCr\", \"ypto library. One of the functions it exposes is CCCryptorFinal, which is used at the\\nend of the enc\", \"ryption/decryption process. However, there are several cases called out in the\\ndocs where it\\u2019s unnec\", \"essary (\\u201csuperfluous,\\u201d according to the docs), and so our dutifully calling it\\neven in those situati\", \"ons is wasteful. The fix? Stop doing unnecessary work.\\n\\u2022 New APIs. A bunch of new APIs were introduc\", \"ed for cryptography in .NET 7. Most are focused\\non easing scenarios that were difficult to do correc\", \"tly before, like dotnet/runtime#66509 from\\n[@vcsjones](https://github.com/vcsjones) that provides an\", \" X500DistinguishedNameBuilder. But\\nsome are focused squarely on performance. dotnet/runtime#57835 fr\", \"om\\n[@vcsjones](https://github.com/vcsjones), for example, exposes a new RawDataMemory property\\non X5\", \"09Certificate2. Whereas the existing RawData property returns a new byte[] on every\\ncall (again a de\", \"fensive copy to avoid having to deal with the possiblity that the consumer\\nmucked with the raw data)\", \", this new RawDataMemory returns a ReadOnlyMemory<byte> around\\nthe internal byte[]. Since the only w\", \"ay to access and mutate that underlying byte[] via a\\nReadOnlyMemory<byte> is via unsafe interop code\", \" (namely via the\\nSystem.Runtime.InteropServices.MemoryMarshal type), it doesn\\u2019t create a defensive c\", \"opy and\\nenables accessing this data freely without additional allocation.\\n202 CHAPTER 19 | Cryptogra\", \"phy20\\nCHAPTER\\nDiagnostics\\nLet\\u2019s turn our attention to System.Diagnostics, which encompasses types ra\", \"nging from process\\nmanagement to tracing.\\nThe Process class is used for a variety of purposes, inclu\", \"ding querying information about running\\nprocesses, interacting with other processes (e.g. being noti\", \"fied of their exiting), and launching\\nprocesses. The performance of querying for information in part\", \"icular had some notable improvements\\nin .NET 7. Process provides several APIs for querying for proce\", \"ss information, one of the most\\ncommon being Process.GetProcessesByName: apps that know the name of \", \"the process they\\u2019re\\ninterested in can pass that to GetProcessesByName and get back a Process[] conta\", \"ining a Process\\nfor each. It turns out that previous releases of .NET were loading the full informat\", \"ion (e.g. all of its\\nthreads) about every Process on the machine in order to filter down to just tho\", \"se with the target\\nname. dotnet/runtime#68705 fixes that by only loading the name for a process rath\", \"er than all of the\\ninformation for it. While this helps a bit with throughput, it helps a ton with a\", \"llocation:\\n[Benchmark]\\npublic void GetProcessesByName()\\n{\\nforeach (Process p in Process.GetProcesses\", \"ByName(\\\"dotnet.exe\\\"))\\np.Dispose();\\n}\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nGetProcessesByN\", \"ame .NET 6.0 2.287 ms 1.00 447.86 KB 1.000\\nGetProcessesByName .NET 7.0 2.086 ms 0.90 2.14 KB 0.005\\nA\", \"ccessing various pieces of information from a Process has also improved. If you load a Process\\nobjec\", \"t via the Process.GetProcesses or Process.GetProcessesByName methods, by design they load\\nall inform\", \"ation about the Process being retrieved; internally their state will be populated such that\\nsubseque\", \"nt accesses to members of the Process instance will be very fast. But, if you access a\\nProcess via P\", \"rocess.GetProcessById or Process.GetCurrentProcess (which is effectively\\nGetProcessById for the curr\", \"ent process\\u2019 id), no information other than the process\\u2019 ID is\\nprepopulated, and the state for the P\", \"rocess instance is queried on-demand. In most cases, accessing\\na single member of one of those lazy-\", \"loaded Process instances triggers loading all of the data for it,\\nas the information is all availabl\", \"e as part of the same native operation, e.g. on Windows using\\nNtQuerySystemInformation and on Linux \", \"reading from /proc/pid/stat and /proc/pid/status. But\\nin some cases we can be more fine-grained abou\", \"t it, using APIs that serve up a subset of the data\\nmuch more quickly. dotnet/runtime#59672 from [@S\", \"teveDunn](https://github.com/SteveDunn)\\nprovides one such optimization, using the QueryFullProcessIm\", \"ageName on Windows to read the\\nprocess name in response to Process.ProcessName being used. If all yo\", \"u care about reading is the\\n203 CHAPTER 20 | Diagnosticsprocess\\u2019 name, it\\u2019s a huge boost in throughp\", \"ut, and even if you subsequently go on to read additional\\nstate from the Process and force it to loa\", \"d everything else, accessing the process name is so fast that\\nit doesn\\u2019t add meaningful overhead to \", \"the all-up operation. This is visible in this benchmark:\\n[Benchmark]\\npublic string GetCurrentProcess\", \"Name()\\n{\\nusing Process current = Process.GetCurrentProcess();\\nreturn current.ProcessName;\\n}\\n[Benchma\", \"rk]\\npublic string GetCurrentProcessNameAndWorkingSet()\\n{\\nusing Process current = Process.GetCurrentP\", \"rocess();\\nreturn $\\\"{current.ProcessName} {current.WorkingSet64}\\\";\\n}\\nMethod Runtime Mean Ratio Alloca\", \"ted Alloc Ratio\\nGetCurrentProcessName .NET 6.0 3,070.54 us 1.00 3954 B 1.00\\nGetCurrentProcessName .N\", \"ET 7.0 32.30 us 0.01 456 B 0.12\\nGetCurrentProcessNameAndWorkingSet .NET 6.0 3,055.70 us 1.00 4010 B \", \"1.00\\nGetCurrentProcessNameAndWorkingSet .NET 7.0 3,149.92 us 1.03 4186 B 1.04\\nInterestingly, this PR\", \" had a small deficiency we didn\\u2019t initially catch, which is that the\\nQueryFullProcessImageName API w\", \"e switched to didn\\u2019t work in the case of elevated/privileged\\nprocesses. To accomodate those, dotnet/\", \"runtime#70073 from\\n[@schuettecarsten](https://github.com/schuettecarsten) updated the code to keep b\", \"oth the new and\\nold implementations, starting with the new one and then only falling back to the old\", \" if operating on\\nan incompatible process.\\nSeveral additional PRs helped out the Process class. When \", \"launching processes with Process.Start\\non Unix, the implementation was using Encoding.UTF8.GetBytes \", \"as part of argument handling,\\nresulting in a temporary array being allocated per argument; dotnet/ru\", \"ntime#71279 removes that\\nper-argument allocation, instead using Encoding.UTF8.GetByteCount to determ\", \"ine how large a\\nspace is needed and then using the Encoding.UTF8.GetBytes overload that accepts a sp\", \"an to encode\\ndirectly into the native memory already being allocated. dotnet/runtime#71136 simplifie\", \"s and\\nstreamlines the code involved in getting the \\u201cshort name\\u201d of a process on Windows for use in\\nc\", \"omparing process names. And dotnet/runtime#45690 replaces a custom cache with use of\\nArrayPool in th\", \"e Windows implementation of getting all process information, enabling effective reuse\\nof the array t\", \"hat ends up being used rather than having it sequestered off in the Process\\nimplementation forever.\\n\", \"Another area of performance investment has been in DiagnosticSource, and in particular around\\nenumer\", \"ating through data from Activity instances. This work translates into faster integration and\\ninterop\", \"erability via OpenTelemetry, in order to be able to export data from .NET Activity information\\nfaste\", \"r. dotnet/runtime#67012 from [@CodeBlanch](https://github.com/CodeBlanch), for example,\\nimproved the\", \" performance of the internal DiagLinkedList<T>.DiagEnumerator type that\\u2019s the\\n204 CHAPTER 20 | Diagn\", \"osticsenumerator returned when enumerating Activity.Links and Activity.Events by avoiding a copy\\nof \", \"each T value:\\nprivate readonly Activity _activity;\\npublic Program()\\n{\\nusing ActivitySource activityS\", \"ource = new ActivitySource(\\\"Perf7Source\\\");\\nActivitySource.AddActivityListener(new ActivityListener\\n{\", \"\\nShouldListenTo = s => s == activitySource,\\nSample = (ref ActivityCreationOptions<ActivityContext> o\", \") =>\\nActivitySamplingResult.AllDataAndRecorded\\n});\\n_activity = activitySource.StartActivity(\\n\\\"TestAc\", \"tivity\\\",\\nActivityKind.Internal,\\nparentContext: default,\\nlinks: Enumerable.Range(0, 1024).Select(_ =>\", \" new ActivityLink(default)).ToArray());\\n_activity.Stop();\\n}\\n[Benchmark(Baseline = true)]\\npublic Acti\", \"vityLink EnumerateActivityLinks()\\n{\\nActivityLink last = default;\\nforeach (ActivityLink link in _acti\", \"vity.Links) last = link;\\nreturn last;\\n}\\nMethod Runtime Mean Ratio Allocated Alloc Ratio\\nEnumerateAct\", \"ivityLinks .NET 6.0 19.62 us 1.00 64 B 1.00\\nEnumerateActivityLinks .NET 7.0 13.72 us 0.70 32 B 0.50\\n\", \"Then dotnet/runtime#67920 from [@CodeBlanch](https://github.com/CodeBlanch) and\\ndotnet/runtime#68933\", \" from [@CodeBlanch](https://github.com/CodeBlanch) added new\\nEnumerateTagObjects, EnumerateEvents, a\", \"nd EnumerateLinks enumeration methods that return a\\nstruct-based enumerator that has a ref T-returni\", \"ng Current to avoid yet another layer of copy.\\nprivate readonly Activity _activity;\\npublic Program()\", \"\\n{\\nusing ActivitySource activitySource = new ActivitySource(\\\"Perf7Source\\\");\\nActivitySource.AddActivi\", \"tyListener(new ActivityListener\\n{\\nShouldListenTo = s => s == activitySource,\\nSample = (ref ActivityC\", \"reationOptions<ActivityContext> o) =>\\nActivitySamplingResult.AllDataAndRecorded\\n});\\n_activity = acti\", \"vitySource.StartActivity(\\n\\\"TestActivity\\\",\\nActivityKind.Internal,\\nparentContext: default,\\nlinks: Enum\", \"erable.Range(0, 1024).Select(_ => new ActivityLink(default)).ToArray());\\n205 CHAPTER 20 | Diagnostic\", \"s_activity.Stop();\\n}\\n[Benchmark(Baseline = true)]\\npublic ActivityLink EnumerateActivityLinks_Old()\\n{\", \"\\nActivityLink last = default;\\nforeach (ActivityLink link in _activity.Links) last = link;\\nreturn las\", \"t;\\n}\\n[Benchmark]\\npublic ActivityLink EnumerateActivityLinks_New()\\n{\\nActivityLink last = default;\\nfor\", \"each (ActivityLink link in _activity.EnumerateLinks()) last = link;\\nreturn last;\\n}\\nMethod Mean Ratio\", \" Allocated Alloc Ratio\\nEnumerateActivityLinks_Old 13.655 us 1.00 32 B 1.00\\nEnumerateActivityLinks_Ne\", \"w 2.380 us 0.17 - 0.00\\nOf course, when it comes to diagnostics, anyone who\\u2019s ever done anything with\", \" regards to timing and\\nmeasurements is likely familiar with good ol\\u2019 Stopwatch. Stopwatch is a simpl\", \"e type that\\u2019s very handy\\nfor getting precise measurements and is thus used all over the place. But f\", \"or folks that are really cost-\\nsensitive, the fact that Stopwatch is a class can be prohibitive, e.g\", \". writing:\\nStopwatch sw = Stopwatch.StartNew();\\n...;\\nTimeSpan elapsed = sw.Elapsed;\\nis easy, but all\", \"ocates a new object just to measure. To address this, Stopwatch has for years exposed\\nthe static Get\", \"Timestamp() method which avoids that allocation, but consuming and translating the\\nresulting long va\", \"lue is complicated, requiring a formula involving using Stopwatch.Frequency and\\nTimeSpan.TicksPerSec\", \"ond in the right incantation. To make this pattern easy, dotnet/runtime#66372\\nadds a static GetElaps\", \"edTime method that handles that conversion, such that someone who wants\\nthat last mile of performanc\", \"e can write:\\nlong timestamp = Stopwatch.GetTimestamp();\\n...\\nTimeSpan elapsed = Stopwatch.GetElapsedT\", \"ime(timestamp);\\nwhich avoids the allocation and saves a few cycles:\\n[Benchmark(Baseline = true)]\\npub\", \"lic TimeSpan Old()\\n{\\nStopwatch sw = Stopwatch.StartNew();\\nreturn sw.Elapsed;\\n}\\n[Benchmark]\\npublic Ti\", \"meSpan New()\\n{\\n206 CHAPTER 20 | Diagnosticslong timestamp = Stopwatch.GetTimestamp();\\nreturn Stopwat\", \"ch.GetElapsedTime(timestamp);\\n}\\nMethod Mean Ratio Allocated Alloc Ratio\\nOld 32.90 ns 1.00 40 B 1.00\\n\", \"New 26.30 ns 0.80 - 0.00\\n207 CHAPTER 20 | Diagnostics21\\nCHAPTER\\nExceptions\\nIt might be odd to see th\", \"e subject of \\u201cexceptions\\u201d in a post on performance improvements. After all,\\nexceptions are by their \", \"very nature meant to be \\u201cexceptional\\u201d (in the \\u201crare\\u201d sense), and thus wouldn\\u2019t\\ntypically contribute \", \"to fast-path performance. Which is a good thing, because fast-paths that throw\\nexceptions in the com\", \"mon case are no longer fast: throwing exceptions is quite expensive.\\nInstead, one of the things we d\", \"o concern ourselves with is how to minimize the impact of checking for\\nexceptional conditions: the a\", \"ctual exception throwing may be unexpected and slow, but it\\u2019s super\\ncommon to need to check for thos\", \"e unexpected conditions, and that checking should be very fast. We\\nalso want such checking to minima\", \"lly impact binary size, especially if we\\u2019re going to have many such\\nchecks all over the place, in ge\", \"neric code for which we end up with many copies due to generic\\nspecialization, in functions that mig\", \"ht be inlined, and so on. Further, we don\\u2019t want such checks to\\nimpede other optimizations; for exam\", \"ple, if I have a small function that wants to do some argument\\nvalidation and would otherwise be inl\", \"ineable, I likely don\\u2019t want the presence of exception throwing to\\ninvalidate the possibility of inl\", \"ining.\\nBecause of all of that, high-performance libraries often come up with custom \\u201cthrow helpers\\u201d \", \"they use\\nto achieve their goals. There are a variety of patterns for this. Sometimes a library will \", \"just define its\\nown static method that handles constructing and throwing an exception, and then call\", \" sites do the\\ncondition check and delegate to the method if throwing is needed:\\nif (arg is null)\\nThr\", \"owArgumentNullException(nameof(arg));\\n...\\n[DoesNotReturn]\\nprivate static void ThrowArgumentNullExcep\", \"tion(string arg) =>\\nthrow new ArgumentNullException(arg);\\nThis keeps the IL associated with the thro\", \"wing out of the calling function, minimizing the impact of\\nthe throw. That\\u2019s particularly valuable w\", \"hen additional work is needed to construct the exception, e.g.\\nprivate static void ThrowArgumentNull\", \"Exception(string arg) =>\\nthrow new ArgumentNullException(arg, SR.SomeResourceMessage);\\nOther times, \", \"libraries will encapsulate both the checking and throwing. This is exactly what the\\nArgumentNullExce\", \"ption.ThrowIfNull method that was added in .NET 6 does:\\npublic static void ThrowIfNull([NotNull] obj\", \"ect? argument,\\n[CallerArgumentExpression(\\\"argument\\\")] string? paramName = null)\\n{\\nif (argument is nu\", \"ll)\\nThrow(paramName);\\n}\\n208 CHAPTER 21 | Exceptions[DoesNotReturn]\\ninternal static void Throw(string\", \"? paramName) => throw new\\nArgumentNullException(paramName);\\nWith that, callers benefit from the conc\", \"ise call site:\\npublic void M(string arg)\\n{\\nArgumentNullException.ThrowIfNull(arg);\\n...\\n}\\nthe IL rema\", \"ins concise, and the assembly generated for the JIT will include the streamlined condition\\ncheck fro\", \"m the inlined ThrowIfNull but won\\u2019t inline the Throw helper, resulting in effectively the same\\ncode \", \"as if you\\u2019d written the previously shown manual version with ThrowArgumentNullException\\nyourself. Ni\", \"ce.\\nWhenever we introduce new public APIs in .NET, I\\u2019m particularly keen on seeing them used as wide\", \"ly\\nas possible. Doing so serves multiple purposes, including helping to validate that the new API is\", \"\\nusable and fully addresses the intended scenarios, and including the rest of the codebase benefitin\", \"g\\nfrom whatever that API is meant to provide, whether it be a performance improvement or just a\\nredu\", \"ction in routinely written code. In the case of ArgumentNullException.ThrowIfNull, however, I\\npurpos\", \"efully put on the brakes. We used it in .NET 6 in several dozen call sites, but primarily just in\\npl\", \"ace of custom ThrowIfNull-like helpers that had sprung up in various libraries around the runtime,\\ne\", \"ffectively deduplicating them. What we didn\\u2019t do, however, was replace the literally thousands of nu\", \"ll\\nchecks we have with calls to ArgumentNullException.ThrowIfNull. Why? Because the new !! C#\\nfeatur\", \"e was right around the corner, destined for C# 11.\\nFor those unaware, the !! feature enabled putting\", \" !! onto parameter names in member signatures,\\ne.g.\\npublic void Process(string name!!)\\n{\\n...\\n}\\nThe C\", \"# compiler then compiled that as equivalent to:\\npublic void Process(string name)\\n{\\nArgumentNullExcep\", \"tion.ThrowIfNull(name);\\n}\\n(albeit using its own ThrowIfNull helper injected as internal into the ass\", \"embly). Armed with the new\\nfeature, dotnet/runtime#64720 and dotnet/runtime#65108 rolled out use of \", \"!! across\\ndotnet/runtime, replacing ~25,000 lines of code with ~5000 lines that used !!. But, what\\u2019s\", \" the line\\nfrom Kung Fu Panda, \\u201cOne often meets his destiny on the road he takes to avoid it\\u201d? The pr\", \"esence of\\nthat initial PR kicked off an unprecedented debate about the !! feature, with many folks l\", \"iking the\\nconcept but a myriad of different opinions about exactly how it should be exposed, and in \", \"the end,\\nthe only common ground was to cut the feature. In response, dotnet/runtime#68178 undid all \", \"usage\\nof !!, replacing most of it with ArgumentNullException.ThrowIfNull. There are now ~5000 uses o\", \"f\\nArgumentNullException.ThrowIfNull across dotnet/runtime, making it one of our most popular\\n209 CHA\", \"PTER 21 | ExceptionsAPIs internally. Interestingly, while we expected a peanut-buttery effect of sli\", \"ght perf improvements in\\nmany places, our performance auto-analysis system flagged several performan\", \"ce improvements (e.g.\\ndotnet/perf-autofiling-issues#3531) as stemming from these changes, in particu\", \"lar because it enabled\\nthe JIT\\u2019s inlining heuristics to flag more methods for inlining.\\nWith the suc\", \"cess of ArgumentNullException.ThrowIfNull and along with its significant roll-out in\\n.NET 7, .NET 7 \", \"also sees the introduction of several more such throw helpers. dotnet/runtime#61633,\\nfor example, ad\", \"ds an overload of ArgumentNullException.ThrowIfNull that works with pointers.\\ndotnet/runtime#64357 a\", \"dds the new ArgumentException.ThrowIfNullOrEmpty helper as well as\\nusing it in several hundred place\", \"s. And dotnet/runtime#58684 from\\n[@Bibletoon](https://github.com/Bibletoon) adds the new ObjectDispo\", \"sedException.ThrowIf helper\\n(tweaked by dotnet/runtime#71544 to help ensure it\\u2019s inlineable), which \", \"is then used at over a\\nhundred additional call sites by dotnet/runtime#71546.\\n210 CHAPTER 21 | Excep\", \"tions22\\nCHAPTER\\nRegistry\\nOn Windows, the Registry is a database provided by the OS for applications \", \"and the system itself to\\nload and store configuration settings. Practically every application access\", \"es the registry. I just tried a\\nsimple console app:\\nConsole.WriteLine(\\\"Hello, world\\\");\\nbuilt it as r\", \"elease, and then ran the resulting .exe. That execution alone triggered 64 RegQueryValue\\noperations \", \"(as visible via SysInternals\\u2019 Process Monitor tool). The core .NET libraries even access the\\nregistr\", \"y for a variety of purposes, such as for gathering data for TimeZoneInfo, gathering data for\\nvarious\", \" calendars like HijriCalendar and JapaneseCalendar, or for serving up environment variables\\nas part \", \"of Environment.GetEnvironmentVariable(EnvironmentVariableTarget) with\\nEnvironmentVariableTarget.User\", \" or EnvironmentVariableTarget.Machine.\\nIt\\u2019s thus beneficial to streamline access to registry data on\", \" Windows, in particular for reducing\\noverheads in startup paths where the registry is frequently acc\", \"essed. dotnet/runtime#66918 does just\\nthat. Previously, calling RegistryKey.GetValue would make a ca\", \"ll to RegQueryValueEx with a null\\nbuffer; this tells the RegQueryValueEx method that the caller want\", \"s to know how big a buffer is\\nrequired in order to store the value for the key. The implementation w\", \"ould then allocate a buffer of\\nthe appropriate size and call RegQueryValueEx again, and for values t\", \"hat are to be returned as strings,\\nwould then allocate a string based on the data in that buffer. Th\", \"is PR instead recognizes that the vast\\nmajority of data returned from calls to the registry is relat\", \"ively small. It starts with a stackalloc\\u2019d\\nbuffer of 512 bytes, and uses that buffer as part of the \", \"initial call to RegQueryValueEx. If the buffer\\nwas sufficiently large, we no longer have to make a s\", \"econd system call to retrieve the actual data: we\\nalready got it. If the buffer was too small, we re\", \"nt an ArrayPool buffer of sufficient size and use that\\npooled buffer for the subsequent RegQueryValu\", \"eEx call. Except in situations where we actually need\\nto return a byte[] array to the caller (e.g. t\", \"he type of the key is REG_BINARY), this avoids the need for\\nthe allocated byte[]. And for keys that \", \"return strings (e.g. the type of the key is REG_SZ), previously\\nthe old implementation would have al\", \"located a temporary char[] to use as the buffer passed to\\nRegQueryValueEx, but we can instead just r\", \"einterpret cast (e.g. MemoryMarshal.Cast) the original\\nbuffer (whether a stackalloc\\u2019d span or the re\", \"nted buffer as a Span<char>), and use that to construct\\nthe resulting string.\\nprivate static readonl\", \"y RegistryKey s_netFramework =\\nRegistry.LocalMachine.OpenSubKey(@\\\"SOFTWARE\\\\Microsoft\\\\.NETFramework\\\")\", \";\\n[Benchmark] public string RegSz() => (string)s_netFramework.GetValue(\\\"InstallRoot\\\");\\n211 CHAPTER 2\", \"2 | RegistryMethod Runtime Mean Ratio Allocated Alloc Ratio\\nRegSz .NET 6.0 6.266 us 1.00 200 B 1.00\\n\", \"RegSz .NET 7.0 3.182 us 0.51 96 B 0.48\\n212 CHAPTER 22 | Registry23\\nCHAPTER\\nAnalyzers\\nThe ability to \", \"easily plug custom code, whether for analyzers or source generators, into the Roslyn\\ncompiler is one\", \" of my favorite features in all of C#. It means the developers working on C# don\\u2019t need\\nto be solely\", \" responsible for highlighting every possible thing you might want to diagnose in your\\ncode. Instead,\", \" library authors can write their own analyzers, ship them either in dedicated nuget\\npackages or as s\", \"ide-by-side in nuget packages with APIs, and those analyzers augment the compiler\\u2019s\\nown analysis to \", \"help developers write better code. We ship a large number of analyzer rules in the\\n.NET SDK, many of\", \" which are focused on performance, and we augment that set with more and more\\nanalyzers every releas\", \"e. We also work to apply more and more of those rules against our own\\ncodebases in every release. .N\", \"ET 7 is no exception.\\nOne of my favorite new analyzers was added in dotnet/roslyn-analyzers#5594 fro\", \"m\\n[@NewellClark](https://github.com/NewellClark) (and tweaked in dotnet/roslyn-analyzers#5972). In\\nm\", \"y .NET 6 performance post, I talked about some of the overheads possible when types aren\\u2019t sealed:\\n\\u2022\", \" Virtual calls are more expensive than regular non-virtual invocation and generally can\\u2019t be\\ninlined\", \", since the JIT doesn\\u2019t know what is the actual type of the instance and thus the actual\\ntarget of t\", \"he invocation (at least not without assistance from PGO). But if the JIT can see that a\\nvirtual meth\", \"od is being invoked on a sealed type, it can devirtualize the call and potentially even\\ninline it.\\n\\u2022\", \" If a type check (e.g. something is typeof(SomeType)) is performed where SomeType is sealed,\\nthat ch\", \"eck can be implemented along the lines of something is not null &&\\nsomething.GetType() == typeof(Som\", \"eType). In contrast, if SomeType is not sealed, the check is\\ngoing to be more along the lines of Cas\", \"tHelpers.IsInstanceOfClass(typeof(SomeType),\\nsomething), where IsInstanceOfClass is a non-trivial (a\", \"nd today non-inlined) call into a JIT\\nhelper method in Corelib that not only checks for null and for\", \" direct equality with the specified\\ntype, but also linearly walks the parent hierarchy of the type o\", \"f the object being tested to see if it\\nmight derive from the specified type.\\n\\u2022 Arrays in .NET are co\", \"variant, which means if types B and C both derive from type A, you can have\\na variable typed as A[] \", \"that\\u2019s storing a B[]. Since C derives from A, it\\u2019s valid to treat a C as an A,\\nbut if the A[] is act\", \"ually a B[], storing a C into that array would mean storing a C into a B[],\\nwhich is invalid. Thus, \", \"every time you store an object reference into an array of reference types,\\nadditional validation may\", \" need to be performed to ensure the reference being written is\\ncompatible with the concrete type of \", \"the array in question. But, if A in this example were sealed,\\nnothing could derive from it, so stori\", \"ng objects into it doesn\\u2019t require such covariance checks.\\n\\u2022 Spans shift this covariance check to th\", \"eir constructor; rather than performing the covariance\\ncheck on every write into the array, the chec\", \"k is performed when a span is being constructed\\nfrom an array, such that if you try to create a new \", \"Span<A>(bArray), the ctor will throw an\\nexception. If A is sealed, the JIT is able to elide such a c\", \"heck as well.\\n213 CHAPTER 23 | AnalyzersIt effectively would be impossible for an analyzer to be abl\", \"e to safely recommend sealing public types.\\nAfter all, it has no knowledge of the type\\u2019s purpose, ho\", \"w it\\u2019s intended to be used, and whether anyone\\noutside of the assembly containing the type actually \", \"derives from it. But internal and private types are\\nanother story. An analyzer can actually see ever\", \"y possible type that could be deriving from a private\\ntype, since the analyzer has access to the who\", \"le compilation unit containing that type, and it needn\\u2019t\\nworry about compatibility because anything \", \"that could derive from such a type necessarily must also\\nbe non-public and would be recompiled right\", \" along with the base type. Further, with the exception of\\nassemblies annotated as InternalsVisibleTo\", \", an analyzer can have the same insight into internal types.\\nThus, this PR adds CA1852, an analyzer \", \"that flags in non-InternalsVisibleTo assemblies all private and\\ninternal types that aren\\u2019t sealed an\", \"d that have no types deriving from them and recommends they be\\nsealed. (Due to some current limitati\", \"ons in the infrastructure around fixers and how this analyzer had\\nto be written in order to be able \", \"to see all of the types in the assembly, the analyzer for CA1852\\ndoesn\\u2019t show up in Visual Studio. I\", \"t can, however, be applied using the dotnet format tool. And if\\nyou bump up the level of the rule fr\", \"om info to warning or error, it\\u2019ll show up as part of builds as well.)\\nIn .NET 6, we sealed over 230\", \"0 types, but even with that, this analyzer ended up finding more to seal.\\ndotnet/runtime#59941 from \", \"[@NewellClark](https://github.com/NewellClark) sealed another ~70\\ntypes, and dotnet/runtime#68268 wh\", \"ich enabled the rule as an warning in dotnet/runtime (which\\nbuilds with warnings-as-errors) sealed a\", \"nother ~100 types. As a larger example of the rule in use,\\nASP.NET hadn\\u2019t done much in the way of se\", \"aling types in previous releases, but with CA1852 now in\\nthe .NET SDK, dotnet/aspnetcore#41457 enabl\", \"ed the analyzer and sealed more than ~1100 types.\\nAnother new analyzer, CA1854, was added in dotnet/\", \"roslyn-analyzers#4851 from\\n[@CollinAlpert](https://github.com/CollinAlpert) and then enabled in dotn\", \"et/runtime#70157. This\\nanalyzer looks for the surprisingly common pattern where a Dictionary<TKey, T\", \"Value>\\u2019s\\nContainsKey is used to determine whether a dictionary contains a particular entry, and then\", \" if it does,\\nthe dictionary\\u2019s indexer is used to retrieve the value associated with the key, e.g.\\nif\", \" (_dictionary.ContainsKey(key))\\n{\\nvar value = _dictionary[key];\\nUse(value);\\n}\\nDictionary\\u2019s TryGetVal\", \"ue method already combines both of these operations, both looking up the\\nkey and retrieving its valu\", \"e if it exists, doing so as a single operation:\\nif (_dictionary.TryGetValue(key, out var value))\\n{\\nU\", \"se(value);\\n}\\nA benefit of this, in addition to arguably being simpler, is that it\\u2019s also faster. Whi\", \"le Dictionary<TKey,\\nTValue> provides very fast lookups, and while the performance of those lookups h\", \"as gotten faster\\nover time, doing fast work is still more expensive than doing no work, and if we ca\", \"n do one lookup\\ninstead of two, that can result in a meaningful performance boost, in particular if \", \"it\\u2019s being performed\\non a fast path. And we can see from this simple benchmark that looks up a word \", \"in a dictionary that,\\nfor this operation, making distinct calls to ContainsKey and the indexer does \", \"indeed double the cost\\nof using the dictionary, almost exactly:\\n214 CHAPTER 23 | Analyzersprivate re\", \"adonly Dictionary<string, int> _counts = Regex.Matches(\\nnew\\nHttpClient().GetStringAsync(\\\"https://www\", \".gutenberg.org/cache/epub/100/pg100.txt\\\").Result,\\n@\\\"\\\\b\\\\w+\\\\b\\\")\\n.Cast<Match>()\\n.GroupBy(word => word.V\", \"alue, StringComparer.OrdinalIgnoreCase)\\n.ToDictionary(word => word.Key, word => word.Count(),\\nString\", \"Comparer.OrdinalIgnoreCase);\\nprivate string _word = \\\"the\\\";\\n[Benchmark(Baseline = true)]\\npublic int L\", \"ookup1()\\n{\\nif (_counts.ContainsKey(_word))\\n{\\nreturn _counts[_word];\\n}\\nreturn -1;\\n}\\n[Benchmark]\\npubli\", \"c int Lookup2()\\n{\\nif (_counts.TryGetValue(_word, out int count))\\n{\\nreturn count;\\n}\\nreturn -1;\\n}\\nMeth\", \"od Mean Ratio\\nLookup1 28.20 ns 1.00\\nLookup2 14.12 ns 0.50\\nSomewhat ironically, even as I write this \", \"example, the analyzer and its auto-fixer are helpfully trying to\\nget me to change my benchmark code:\", \"\\n215 CHAPTER 23 | AnalyzersSimilarly, dotnet/roslyn-analyzers#4836 from [@chucker](https://github.co\", \"m/chucker) added CA1853,\\nwhich looks for cases where a Remove call on a dictionary is guarded by a C\", \"ontainsKey call. It seems\\nit\\u2019s fairly natural for developers to only call Remove on a dictionary onc\", \"e they\\u2019re sure the dictionary\\ncontains the thing being removed; maybe they think Remove will throw a\", \"n exception if the specified\\nkey doesn\\u2019t exist. However, Remove actually allows this as a first-clas\", \"s scenario, with its return Boolean\\nvalue indicating whether the key was in the dictionary (and thus\", \" successfully removed) or not. An\\nexample of this comes from dotnet/runtime#68724, where CA1853 was \", \"enabled for dotnet/runtime.\\nThe EventPipeEventDispatcher type\\u2019s RemoveEventListener method had code \", \"like this:\\nif (m_subscriptions.ContainsKey(listener))\\n{\\nm_subscriptions.Remove(listener);\\n}\\nwhich th\", \"e analyzer flagged and which it\\u2019s auto-fixer replaced with just:\\nm_subscriptions.Remove(listener);\\nN\", \"ice and simple. And faster, since as with the TryGetValue case, this is now doing a single dictionar\", \"y\\nlookup rather than two. :::{custom-style=Figure}\\n216 CHAPTER 23 | Analyzers:::\\nAnother nice analyz\", \"er added in dotnet/roslyn-analyzers#5907 and dotnet/roslyn-analyzers#5910 is\\nCA1851, which looks for\", \" code that iterates through some kinds of enumerables multiple times.\\nEnumerating an enumerator, whe\", \"ther directly or via helper methods like those in LINQ, can have non-\\ntrivial cost. Calling GetEnume\", \"rator typically allocates an enumerator object, and every item yielded\\ntypically involves two interf\", \"ace calls, one to MoveNext and one to Current. If something can be done\\nvia a single pass over the e\", \"numerable rather than multiple passes, that can save such costs. In some\\ncases, seeing places this a\", \"nalyzer fires can also inspire changes that avoid any use of enumerators. For\\nexample, dotnet/runtim\", \"e#67292 enabled CA1851 for dotnet/runtime, and in doing so, it fixed several\\ndiagnostics issued by t\", \"he analyzer (even in a code base that\\u2019s already fairly stringent about\\nenumerator and LINQ usage). A\", \"s an example, this is a function in\\nSystem.ComponentModel.Composition that was flagged by the analyz\", \"er:\\nprivate void InitializeTypeCatalog(IEnumerable<Type> types)\\n{\\nforeach (Type type in types)\\n{\\nif \", \"(type == null)\\n{\\nthrow ExceptionBuilder.CreateContainsNullElement(nameof(types));\\n}\\nelse if (type.As\", \"sembly.ReflectionOnly)\\n{\\nthrow new ArgumentException(SR.Format(SR.Argument_ElementReflectionOnlyType\", \",\\nnameof(types)), nameof(types));\\n}\\n}\\n_types = types.ToArray();\\n}\\nThe method\\u2019s purpose is to convert\", \" the enumerable into an array to be stored, but also to validate\\nthat the contents are all non-null \", \"and non-\\u201cReflectionOnly.\\u201d To achieve that, the method is first using\\na foreach to iterate through th\", \"e enumerable, validating each element along the way, and then once\\nit\\u2019s done so, it calls ToArray() \", \"to convert the enumerable into an array. There are multiple problems\\n217 CHAPTER 23 | Analyzerswith \", \"this. First, it\\u2019s incurring the expense of interating through the enumerable twice, once for the\\nfor\", \"each and once for the ToArray(), which internally needs to enumerate it if it can\\u2019t do something\\nspe\", \"cial like cast to ICollection<Type> and CopyTo the data out of it. Second, it\\u2019s possible the caller\\u2019\", \"s\\nIEnumerable<Type> changes on each iteration, so any validation done in the first iteration isn\\u2019t\\na\", \"ctually ensuring there aren\\u2019t nulls in the resulting array, for example. Since the expectation of th\", \"e\\nmethod is that all inputs are valid and we don\\u2019t need to optimize for the failure cases, the bette\", \"r\\napproach is to first call ToArray() and then validate the contents of that array, which is exactly\", \" what\\nthat PR fixes it to do:\\nprivate void InitializeTypeCatalog(IEnumerable<Type> types)\\n{\\nType[] a\", \"rr = types.ToArray();\\nforeach (Type type in arr)\\n{\\nif (type == null)\\n{\\nthrow ExceptionBuilder.Create\", \"ContainsNullElement(nameof(types));\\n}\\nif (type.Assembly.ReflectionOnly)\\n{\\nthrow new ArgumentExceptio\", \"n(SR.Format(SR.Argument_ElementReflectionOnlyType,\\nnameof(types)), nameof(types));\\n}\\n}\\n_types = arr;\", \"\\n}\\nWith that, we only ever iterate it once (and possibly 0 times if ToArray can special-case it, and\", \" bonus,\\nwe validate on the copy rather than on the mutable original.\\nYet another helpful analyzer is\", \" the new CA1850 introduced in dotnet/roslyn-analyzers#4797 from\\n[@wzchua](https://github.com/wzchua)\", \". It used to be that if you wanted to cryptographically hash\\nsome data in .NET, you would create an \", \"instance of a hash algorithm and call its ComputeHash\\nmethod, e.g.\\npublic byte[] Hash(byte[] data)\\n{\", \"\\nusing (SHA256 h = SHA256.Create())\\n{\\nreturn h.ComputeHash(data);\\n}\\n}\\nHowever, .NET 5 introduced new\", \" \\u201cone-shot\\u201d hashing methods, which obviates the need to create a\\nnew HashAlgorithm instance, providi\", \"ng a static method that performs the whole operation.\\npublic byte[] Hash(byte[] data)\\n{\\nreturn SHA25\", \"6.HashData(data);\\n}\\nCA1850 finds occurrences of the former pattern and recommends changing them to t\", \"he latter.\\n218 CHAPTER 23 | AnalyzersThe result is not only simpler, it\\u2019s also faster:\\nprivate reado\", \"nly byte[] _data = RandomNumberGenerator.GetBytes(128);\\n[Benchmark(Baseline = true)]\\npublic byte[] H\", \"ash1()\\n{\\nusing (SHA256 h = SHA256.Create())\\n{\\nreturn h.ComputeHash(_data);\\n}\\n}\\n[Benchmark]\\npublic by\", \"te[] Hash2()\\n{\\nreturn SHA256.HashData(_data);\\n}\\nMethod Mean Ratio Allocated Alloc Ratio\\nHash1 1,212.\", \"9 ns 1.00 240 B 1.00\\nHash2 950.8 ns 0.78 56 B 0.23\\nThe .NET 7 SDK also includes new analyzers around\", \" [GeneratedRegex(...)] (dotnet/runtime#68976)\\nand the already mentioned ones for LibraryImport, all \", \"of which help to move your code forwards to\\nmore modern patterns that have better performance charac\", \"teristics.\\n219 CHAPTER 23 | AnalyzersThis release also saw dotnet/runtime turn on a bunch of additio\", \"nal IDEXXXX code style rules and\\nmake a huge number of code changes in response. Most of the resulti\", \"ng changes are purely about\\nsimplifying the code, but in almost every case some portion of the chang\", \"es also have a functional and\\nperformance impact.\\nLet\\u2019s start with IDE0200, which is about removing \", \"unnecessary lambdas. Consider a setup like this:\\npublic class C\\n{\\npublic void CallSite() => M(i => W\", \"ork(i));\\npublic void M(Action<int> action) { }\\nprivate static void Work(int value) { }\\n}\\nHere we hav\", \"e a method CallSite that\\u2019s invoking a method M and passing a lambda to it. Method M\\naccepts an Actio\", \"n<int>, and the call site is passing a lambda that takes the supplied Int32 and\\npasses it off to som\", \"e static functionality. For this code, the C# compiler is going to generate\\nsomething along the line\", \"s of this:\\npublic class C\\n{\\n[CompilerGenerated]\\nprivate sealed class <>c\\n{\\npublic static readonly <>\", \"c <>9 = new <>c();\\npublic static Action<int> <>9__0_0;\\ninternal void <CallSite>b__0_0(int i) => Work\", \"(i);\\n}\\npublic void CallSite() => M(<>c.<>9__0_0 ??= new\\nAction<int>(<>c.<>9.<CallSite>b__0_0));\\npubl\", \"ic void M(Action<int> action) { }\\nprivate static void Work(int value) { }\\n}\\nThe most important aspec\", \"t of this is that <>9__0_0 field the compiler emitted. That field is a cache for\\nthe delegate create\", \"d in CallSite. The first time CallSite is invoked, it\\u2019ll allocate a new delegate for\\nthe lambda and \", \"store it into that field. For all subsequent invocations, however, it\\u2019ll find the field is\\n220 CHAPT\", \"ER 23 | Analyzersnon-null and will just reuse the same delegate. Thus, this lambda only ever results\", \" in a single\\nallocation for the whole process (ignoring any race conditions on the initial lazy init\", \"ialization such that\\nmultiple threads all racing to initialize the field might end up producing a fe\", \"w additional unnecessary\\nallocations). It\\u2019s important to recognize this caching only happens because\", \" the lambda doesn\\u2019t access\\nany instance state and doesn\\u2019t close over any locals; if it did either of\", \" those things, such caching\\nwouldn\\u2019t happen. Secondarily, it\\u2019s interesting to note the pattern the c\", \"ompiler uses for the lambda\\nitself. Note that generated <CallSite>b__0_0 method is generated as an i\", \"nstance method, and the\\ncall site refers to that method of a singleton instance that\\u2019s used to initi\", \"alize a <>9 field. That\\u2019s done\\nbecause delegates to static methods use something called a \\u201cshuffle t\", \"hunk\\u201d to move arguments into\\nthe right place for the target method invocation, making delegates to s\", \"tatics ever so slightly more\\nexpensive to invoke than delegates to instance methods.\\nprivate Action \", \"_instance = new C().InstanceMethod;\\nprivate Action _static = C.StaticMethod;\\n[Benchmark(Baseline = t\", \"rue)]\\npublic void InvokeInstance() => _instance();\\n[Benchmark]\\npublic void InvokeStatic() => _static\", \"();\\nprivate sealed class C\\n{\\npublic static void StaticMethod() { }\\npublic void InstanceMethod() { }\\n\", \"}\\nMethod Mean Ratio\\nInvokeInstance 0.8858 ns 1.00\\nInvokeStatic 1.3979 ns 1.58\\nSo, the compiler is ab\", \"le to cache references to lambdas, great. What about method groups, i.e. where\\nyou just name the met\", \"hod directly? Previously, if changed my code to:\\npublic class C\\n{\\npublic void CallSite() => M(Work);\", \"\\npublic void M(Action<int> action) { }\\nprivate static void Work(int value) { }\\n}\\nthe compiler would \", \"generate the equivalent of:\\npublic class C\\n{\\npublic void CallSite() => M(new Action<int>(Work));\\npub\", \"lic void M(Action<int> action) { }\\nprivate static void Work(int value) { }\\n}\\n221 CHAPTER 23 | Analyz\", \"erswhich has the unfortunate effect of allocating a new delegate on every invocation, even though we\", \"\\u2019re\\nstill dealing with the exact same static method. Thanks to dotnet/roslyn#58288 from\\n[@pawchen](h\", \"ttps://github.com/pawchen), the compiler will now generate the equivalent of:\\npublic class C\\n{\\n[Comp\", \"ilerGenerated]\\nprivate static class <>O\\n{\\npublic static Action<int> <0>__Work;\\n}\\npublic void CallSit\", \"e() => M(<>O.<0>__Work ??= new Action<int>(Work));\\npublic void M(Action<int> action) { }\\nprivate sta\", \"tic void Work(int value) { }\\n}\\nNote we again have a caching field that\\u2019s used to enable allocating t\", \"he delegate once and caching it.\\nThat means that places where code was using a lambda to enable this\", \" caching can now switch back to\\nthe cleaner and simpler method group way of expressing the desired f\", \"unctionality. There is the\\ninteresting difference to be cognizant of that since we don\\u2019t have a lamb\", \"da which required the\\ncompiler emitting a new method for, we\\u2019re still creating a delegate directly t\", \"o the static method.\\nHowever, the minor difference in thunk overhead is typically made up for by the\", \" fact that we don\\u2019t\\nhave a second method to invoke; in the common case where the static helper being\", \" invoked isn\\u2019t\\ninlinable (because it\\u2019s not super tiny, because it has exception handling, etc.), we \", \"previously would\\nhave incurred the cost of the delegate invocation plus the non-inlinable method cal\", \"l, and now we just\\nhave the cost of an ever-so-slightly more expensive delegate invocation; on the w\", \"hole, it\\u2019s typically a\\nwash.\\nAnd that brings us to IDE0200, which recognizes lambda expressions that\", \" can be removed.\\ndotnet/runtime#71011 enabled the analyzer for dotnet/runtime, resulting in more tha\", \"n 100 call sites\\nchanging accordingly. However, IDE0200 does more than just this mostly stylistic ch\", \"ange. It also\\nrecognizes some patterns that can make a more substantial impact. Consider this code t\", \"hat was\\nchanged as part of that PR:\\nAction disposeAction;\\nIDisposable? disposable = null;\\n...\\nif (di\", \"sposable != null)\\n{\\ndisposeAction = () => disposable.Dispose();\\n}\\nThat delegate closes over the disp\", \"osable local, which means this method needs to allocate a display\\nclass. But IDE0200 recognizes that\", \" instead of closing over disposable, we can create the delegate\\ndirectly to the Dispose method:\\nActi\", \"on disposeAction;\\nIDisposable? disposable = null;\\n...\\nif (disposable != null)\\n{\\n222 CHAPTER 23 | Ana\", \"lyzersdisposeAction = disposable.Dispose;\\n}\\nWe still get a delegate allocation, but we avoid the dis\", \"play class allocation, and as a bonus we save on\\nthe additional metadata required for the synthesize\", \"d display class and method generated for the\\nlambda.\\nIDE0020 is another good example of an analyzer \", \"that is primarily focused on making code cleaner,\\nmore maintainable, more modern, but that can also \", \"lead to removing overhead from many different\\nplaces. The analyzer looks for code performing unneces\", \"sary duplicative casts and recommends using\\nC# pattern matching syntax instead. For example, dotnet/\", \"runtime#70523 enabled the analyzer and\\nswitched more than 250 locations from code like:\\nif (value is\", \" SqlDouble)\\n{\\nSqlDouble i = (SqlDouble)value;\\nreturn CompareTo(i);\\n}\\nto instead be like:\\nif (value i\", \"s SqlDouble i)\\n{\\nreturn CompareTo(i);\\n}\\nIn addition to being cleaner, this ends up saving a cast ope\", \"ration, which can add measurable\\noverhead if the JIT is unable to remove it:\\nprivate object _value =\", \" new List<string>();\\n[Benchmark(Baseline = true)]\\npublic List<string> WithCast()\\n{\\nobject value = _v\", \"alue;\\nreturn value is List<string> ? (List<string>)value : null;\\n}\\n[Benchmark]\\npublic List<string> W\", \"ithPattern()\\n{\\nobject value = _value;\\nreturn value is List<string> list ? list : null;\\n}\\nMethod Mean\", \" Ratio\\nWithCast 2.602 ns 1.00\\nWithPattern 1.886 ns 0.73\\nThen there\\u2019s IDE0031, which promotes using n\", \"ull propagation features of C#. This analyzer typically\\nmanifests as recommending changing snippets \", \"like:\\nreturn _value != null ? _value.Property : null;\\ninto code that\\u2019s instead like:\\n223 CHAPTER 23 \", \"| Analyzersreturn _value?.Property;\\nNice, concise, and primarily about cleaning up the code and maki\", \"ng it simpler and more maintainable\\nby utilizing newer C# syntax. However, there is also a small per\", \"formance advantage in some situations\\nas well. For example, consider this snippet:\\npublic class C\\n{\\n\", \"private C _value;\\npublic int? Get1() => _value != null ? _value.Prop : null;\\npublic int? Get2() => _\", \"value?.Prop;\\npublic int Prop => 42;\\n}\\nThe C# compiler lowers these expressions to the equivalent of \", \"this:\\npublic Nullable<int> Get1()\\n{\\nif (_value == null) return null;\\nreturn _value.Prop;\\n}\\npublic Nu\", \"llable<int> Get2()\\n{\\nC value = _value;\\nif (value == null) return null;\\nreturn value.Prop;\\n}\\nfor whic\", \"h the JIT then generates:\\n; Program.Get1()\\npush rax\\nmov rdx,[rcx+8]\\ntest rdx,rdx\\njne short M00_L00\\nx\", \"or eax,eax\\nadd rsp,8\\nret\\nM00_L00:\\ncmp [rdx],dl\\nmov dword ptr [rsp+4],2A\\nmov byte ptr [rsp],1\\nmov rax\", \",[rsp]\\nadd rsp,8\\nret\\n; Total bytes of code 40\\n; Program.Get2()\\npush rax\\nmov rax,[rcx+8]\\ntest rax,rax\", \"\\njne short M00_L00\\nxor eax,eax\\nadd rsp,8\\nret\\nM00_L00:\\n224 CHAPTER 23 | Analyzersmov dword ptr [rsp+4\", \"],2A\\nmov byte ptr [rsp],1\\nmov rax,[rsp]\\nadd rsp,8\\nret\\n; Total bytes of code 38\\nNote how the Get1 var\", \"iant has an extra cmp instruction (cmp [rdx],dl) in the otherwise identical\\nassembly to Get2 (other \", \"than register selection). That cmp instruction in Get1 is the JIT forcing a null\\ncheck on the second\", \" read of _value prior to accessing its Prop, whereas in Get2 the null check against\\nthe local means \", \"the JIT doesn\\u2019t need to add an additional null check on the second use of the local,\\nsince nothing c\", \"ould have changed it. dotnet/runtime#70965 rolled out additional use of the null\\npropagation operato\", \"r via auto-fixing IDE0031, resulting in ~120 uses being improved.\\nAnother interesting example is IDE\", \"0060, which finds unused parameters and recommends removing\\nthem. This was done for non-public membe\", \"rs in System.Private.CoreLib in dotnet/runtime#63015. As\\nwith some of the other mentioned rules, it\\u2019\", \"s primarily about good hygiene. There can be some small\\nadditional cost associated with passing addi\", \"tional parameters (the overhead of reading the values at\\nthe call site, putting them into the right \", \"register or stack location, etc., and also the metadata size\\nassociated with the additional paramete\", \"r information), but the larger benefit comes from auditing all\\nof the cited violations and finding p\", \"laces where work is simply being performed unnecessarily. For\\nexample, that PR made some updates to \", \"the TimeZoneInfo type\\u2019s implementation for Unix. In that\\nimplementation is a TZif_ParseRaw method, w\", \"hich is used to extract some information from a time\\nzone data file. Amongst many input and output p\", \"arameters, it had out bool[] StandardTime, out\\nbool[] GmtTime, which the implementation was dutifull\", \"y filling in by allocating and populating new\\narrays for each. The call site for TZif_ParseRaw was t\", \"hen taking those arrays and feeding them into\\nanother method TZif_GenerateAdjustmentRules, which ign\", \"ored them! Thus, not only was this PR\\nable to remove those parameters from TZif_GenerateAdjustmentRu\", \"les, it was able to update\\nTZif_ParseRaw to no longer need to allocate and populate those arrays at \", \"all, which obviously yields\\na much larger gain.\\nOne final example of peanut-buttery performance impr\", \"ovements from applying an analyzer comes\\nfrom dotnet/runtime#70896 and dotnet/runtime#71361, which a\", \"pplied IDE0029 across\\ndotnet/runtime. IDE0029 flags cases where null coalescing can be used, e.g. fl\", \"agging:\\nreturn message != null ? message : string.Empty;\\nand recommending it be converted to:\\nreturn\", \" message ?? string.Empty;\\nAs with some of the previous rules discussed, that in and of itself doesn\\u2019\", \"t make a meaningful\\nperformance improvement, and rather is about clarity and simplicity. However, in\", \" various cases it can.\\nFor example, the aforementioned PRs contained an example like:\\nnull != foundC\", \"olumns[i] ? foundColumns[i] : DBNull.Value;\\nwhich is rewritten to:\\nfoundColumns[i] ?? DBNull.Value\\nT\", \"his avoids an unnecessary re-access to an array. Or again from those PRs the expression:\\n225 CHAPTER\", \" 23 | Analyzersentry.GetKey(_thisCollection) != null ? entry.GetKey(_thisCollection) : \\\"key\\\"\\nbeing c\", \"hanged to:\\nentry.GetKey(_thisCollection) ?? \\\"key\\\"\\nand avoiding an unnecessary table lookup.\\n226 CHAP\", \"TER 23 | Analyzers24\\nCHAPTER\\nWhat\\u2019s Next?\\nWhew! That was a lot. Congrats on getting through it all.\\n\", \"The next step is on you. Download the latest .NET 7 bits and take them for a spin. Upgrade your apps\", \".\\nWrite and share your own benchmarks. Provide feedback, positive and critical. Find something you\\nt\", \"hink can be better? Open an issue, or better yet, submit a PR with the fix. We\\u2019re excited to work wi\", \"th\\nyou to polish .NET 7 to be the best .NET release yet; meanwhile, we\\u2019re getting going on .NET 8 :)\", \"\\nUntil next time\\u2026\\nHappy coding!\\n227 CHAPTER 24 | What\\u2019s Next?\"]"