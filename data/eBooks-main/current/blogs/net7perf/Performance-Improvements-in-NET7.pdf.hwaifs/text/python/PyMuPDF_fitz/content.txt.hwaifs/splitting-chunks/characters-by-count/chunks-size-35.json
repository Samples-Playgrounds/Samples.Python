"[\" \\n \\n \\n \\n \\n \\n \\n \\nPerformance Improvements \\n in .NET 7 \\n \\n \\nStephen Toub \\nPartner Software Engineer, .\", \"NET \\nMicrosoft \\n \\n \\n \\nIntroduction \\nA year ago, I published Performance Improvements in .NET 6, foll\", \"owing on the heels of similar posts \\nfor .NET 5, .NET Core 3.0, .NET Core 2.1, and .NET Core 2.0. I \", \"enjoy writing these posts and love \\nreading developers\\u2019 responses to them. One comment in particular\", \" last year resonated with me. The \\ncommenter cited the Die Hard movie quote, \\u201c\\u2018When Alexander saw th\", \"e breadth of his domain, he \\nwept for there were no more worlds to conquer\\u2019,\\u201d and questioned whether\", \" .NET performance \\nimprovements were similar. Has the well run dry? Are there no more \\u201c[performance]\", \" worlds to \\nconquer\\u201d? I\\u2019m a bit giddy to say that, even with how fast .NET 6 is, .NET 7 definitively\", \" highlights how \\nmuch more can be and has been done. \\nAs with previous versions of .NET, performance\", \" is a key focus that pervades the entire stack, whether it \\nbe features created explicitly for perfo\", \"rmance or non-performance-related features that are still \\ndesigned and implemented with performance\", \" keenly in mind. And now that a .NET 7 release \\ncandidate is just around the corner, it\\u2019s a good tim\", \"e to discuss much of it. Over the course of the last \\nyear, every time I\\u2019ve reviewed a PR that might\", \" positively impact performance, I\\u2019ve copied that link to a \\njournal I maintain for the purposes of w\", \"riting this post. When I sat down to write this a few weeks ago, \\nI was faced with a list of almost \", \"1000 performance-impacting PRs (out of more than 7000 PRs that \\nwent into the release), and I\\u2019m exci\", \"ted to share approximately 500 of them here with you. \\nOne thought before we dive in. In past years,\", \" I\\u2019ve received the odd piece of negative feedback about \\nthe length of some of my performance-focuse\", \"d write-ups, and while I disagree with the criticism, I \\nrespect the opinion. So, this year, conside\", \"r this a \\u201cchoose your own adventure.\\u201d If you\\u2019re here just \\nlooking for a super short adventure, one \", \"that provides the top-level summary and a core message to \\ntake away from your time here, I\\u2019m happy \", \"to oblige: \\nTL;DR: .NET 7 is fast. Really fast. A thousand performance-impacting PRs went into runti\", \"me and core \\nlibraries this release, never mind all the improvements in ASP.NET Core and Windows For\", \"ms and \\nEntity Framework and beyond. It\\u2019s the fastest .NET ever. If your manager asks you why your p\", \"roject \\nshould upgrade to .NET 7, you can say \\u201cin addition to all the new functionality in the relea\", \"se, .NET 7 is \\nsuper fast.\\u201d \\nOr, if you prefer a slightly longer adventure, one filled with interest\", \"ing nuggets of performance-\\nfocused data, consider skimming through the post, looking for the small \", \"code snippets and \\ncorresponding tables showing a wealth of measurable performance improvements. At \", \"that point, you, \\ntoo, may walk away with your head held high and my thanks. \\nBoth noted paths achie\", \"ve one of my primary goals for spending the time to write these posts, to \\nhighlight the greatness o\", \"f the next release and to encourage everyone to give it a try. But, I have other \\ngoals for these po\", \"sts, too. I want everyone interested to walk away from this post with an upleveled \\nunderstanding of\", \" how .NET is implemented, why various decisions were made, tradeoffs that were \\nevaluated, technique\", \"s that were employed, algorithms that were considered, and valuable tools and \\napproaches that were \", \"utilized to make .NET even faster than it was previously. I want developers to \\nlearn from our own l\", \"earnings and find ways to apply this new-found knowledge to their own \\ncodebases, thereby further in\", \"creasing the overall performance of code in the ecosystem. I want \\ndevelopers to take an extra beat,\", \" think about reaching for a profiler the next time they\\u2019re working on a \\ngnarly problem, think about\", \" looking at the source for the component they\\u2019re using in order to better \\nunderstand how to work wi\", \"th it, and think about revisiting previous assumptions and decisions to \\ndetermine whether they\\u2019re s\", \"till accurate and appropriate. And I want developers to be excited at the \\nprospect of submitting PR\", \"s to improve .NET not only for themselves but for every developer around \\nthe globe using .NET. If a\", \"ny of that sounds interesting, then I encourage you to choose the last \\nadventure: prepare a carafe \", \"of your favorite hot beverage, get comfortable, and please enjoy. \\n \\ni \\nContents \\n \\nContents \\nSetup \", \"....................................................................................................\", \"..................................... 1 \\nJIT .......................................................\", \"....................................................................................... 3 \\nOn-Stack \", \"Replacement ........................................................................................\", \".......................................................... 13 \\nPGO .................................\", \"....................................................................................................\", \"................................................... 23 \\nBounds Check Elimination ...................\", \"....................................................................................................\", \"..................... 35 \\nLoop Hoisting and Cloning ................................................\", \".......................................................................................... 45 \\nFoldi\", \"ng, propagation, and substitution ..................................................................\", \"................................................. 50 \\nVectorization ................................\", \"....................................................................................................\", \".................................. 54 \\nInlining ....................................................\", \"....................................................................................................\", \".......................... 62 \\nArm64 ...............................................................\", \"....................................................................................................\", \"................ 64 \\nJIT helpers ...................................................................\", \"....................................................................................................\", \".... 65 \\nGrab Bag ..................................................................................\", \"............................................................................................ 67 \\nGC \", \"....................................................................................................\", \"........................................ 71 \\nNative AOT ............................................\", \"................................................................................. 72 \\nMono .........\", \"....................................................................................................\", \"......................... 75 \\nReflection ...........................................................\", \".................................................................... 78 \\nInterop ...................\", \"....................................................................................................\", \"............. 82 \\nThreading ........................................................................\", \"....................................................... 89 \\nPrimitive Types and Numerics ...........\", \".................................................................................. 93 \\nArrays, Strin\", \"gs, and Spans ......................................................................................\", \"............ 101 \\nRegex ............................................................................\", \"........................................................ 128 \\nRegexOptions.NonBacktracking..........\", \"....................................................................................................\", \"................. 128 \\nNew APIs ....................................................................\", \"....................................................................................................\", \".... 133 \\nTryFindNextPossibleStartingPosition ......................................................\", \"............................................................... 138 \\nLoops and Backtracking ........\", \"....................................................................................................\", \".................................. 143 \\nCode generation ............................................\", \"....................................................................................................\", \"............. 146 \\nCollections .....................................................................\", \"....................................................... 150 \\nLINQ ..................................\", \"....................................................................................................\", \" 153 \\n \\nii \\nContents \\nFile I/O .....................................................................\", \"............................................................. 159 \\nCompression .....................\", \"................................................................................................... \", \"168 \\nNetworking ....................................................................................\", \"...................................... 173 \\nJSON ...................................................\", \".................................................................................. 190 \\nXML ........\", \"....................................................................................................\", \"........................... 193 \\nCryptography ......................................................\", \"................................................................. 198 \\nDiagnostics .................\", \"....................................................................................................\", \"...... 203 \\nExceptions .............................................................................\", \"............................................... 208 \\nRegistry ......................................\", \".......................................................................................... 211 \\nAnal\", \"yzers ..............................................................................................\", \"................................ 213 \\nWhat\\u2019s Next? .................................................\", \"....................................................................... 227 \\n \\n1 \\nCHAPTER 1 | Setup \", \"\\n \\nCHAPTER 1 \\nSetup \\nThe microbenchmarks throughout this post utilize benchmarkdotnet. To make it ea\", \"sy for you to follow \\nalong with your own validation, I have a very simple setup for the benchmarks \", \"I use. Create a new C# \\nproject: \\ndotnet new console -o benchmarks \\ncd benchmarks \\nYour new benchmar\", \"ks directory will contain a benchmarks.csproj file and a Program.cs file. Replace \\nthe contents of b\", \"enchmarks.csproj with this: \\n<Project Sdk=\\\"Microsoft.NET.Sdk\\\"> \\n \\n  <PropertyGroup> \\n    <OutputType\", \">Exe</OutputType> \\n    <TargetFrameworks>net7.0;net6.0</TargetFrameworks> \\n    <LangVersion>Preview<\", \"/LangVersion> \\n    <AllowUnsafeBlocks>true</AllowUnsafeBlocks> \\n    <ServerGarbageCollection>true</S\", \"erverGarbageCollection> \\n  </PropertyGroup> \\n \\n  <ItemGroup> \\n    <PackageReference Include=\\\"benchma\", \"rkdotnet\\\" Version=\\\"0.13.2\\\" /> \\n  </ItemGroup> \\n \\n</Project> \\nand the contents of Program.cs with thi\", \"s: \\nusing BenchmarkDotNet.Attributes; \\nusing BenchmarkDotNet.Running; \\nusing Microsoft.Win32; \\nusing\", \" System; \\nusing System.Buffers; \\nusing System.Collections.Generic; \\nusing System.Collections.Immutab\", \"le; \\nusing System.ComponentModel; \\nusing System.Diagnostics; \\nusing System.IO; \\nusing System.IO.Comp\", \"ression; \\nusing System.IO.MemoryMappedFiles; \\nusing System.IO.Pipes; \\nusing System.Linq; \\nusing Syst\", \"em.Net; \\nusing System.Net.Http; \\nusing System.Net.Http.Headers; \\nusing System.Net.Security; \\nusing S\", \"ystem.Net.Sockets; \\nusing System.Numerics; \\n \\n2 \\nCHAPTER 1 | Setup \\n \\nusing System.Reflection; \\nusin\", \"g System.Runtime.CompilerServices; \\nusing System.Runtime.InteropServices; \\nusing System.Runtime.Intr\", \"insics; \\nusing System.Security.Authentication; \\nusing System.Security.Cryptography; \\nusing System.Se\", \"curity.Cryptography.X509Certificates; \\nusing System.Text; \\nusing System.Text.Json; \\nusing System.Tex\", \"t.RegularExpressions; \\nusing System.Threading; \\nusing System.Threading.Tasks; \\nusing System.Xml; \\n \\n\", \"[MemoryDiagnoser(displayGenColumns: false)] \\n[DisassemblyDiagnoser] \\n[HideColumns(\\\"Error\\\", \\\"StdDev\\\",\", \" \\\"Median\\\", \\\"RatioSD\\\")] \\npublic partial class Program \\n{ \\n    static void Main(string[] args) => \\nBen\", \"chmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args); \\n \\n    // ... copy [Benchmark]s her\", \"e \\n} \\nFor each benchmark included in this write-up, you can then just copy and paste the code into t\", \"his test \\nclass, and run the benchmarks. For example, to run a benchmark comparing performance on .N\", \"ET 6 \\nand .NET 7, do: \\ndotnet run -c Release -f net6.0 --filter '**' --runtimes net6.0 net7.0 \\nThis \", \"command says \\u201cbuild the benchmarks in release configuration targeting the .NET 6 surface area, \\nand \", \"then run all of the benchmarks on both .NET 6 and .NET 7.\\u201d Or to run just on .NET 7: \\ndotnet run -c \", \"Release -f net7.0 --filter '**' --runtimes net7.0 \\nwhich instead builds targeting the .NET 7 surface\", \" area and then only runs once against .NET 7. You \\ncan do this on any of Windows, Linux, or macOS. U\", \"nless otherwise called out (e.g. where the \\nimprovements are specific to Unix and I run the benchmar\", \"ks on Linux), the results I share were \\nrecorded on Windows 11 64-bit but aren\\u2019t Windows-specific an\", \"d should show similar relative \\ndifferences on the other operating systems as well. \\nThe release of \", \"the first .NET 7 release candidate is right around the corner. All of the measurements in \\nthis post\", \" were gathered with a recent daily build of .NET 7 RC1. \\nAlso, my standard caveat: These are microbe\", \"nchmarks. It is expected that different hardware, different \\nversions of operating systems, and the \", \"way in which the wind is currently blowing can affect the \\nnumbers involved. Your mileage may vary. \", \"\\n \\n3 \\nCHAPTER 2 | JIT \\n \\nCHAPTER 2 \\nJIT \\nI\\u2019d like to kick off a discussion of performance improvemen\", \"ts in the Just-In-Time (JIT) compiler by \\ntalking about something that itself isn\\u2019t actually a perfo\", \"rmance improvement. Being able to \\nunderstand exactly what assembly code is generated by the JIT is \", \"critical when fine-tuning lower-level, \\nperformance-sensitive code. There are multiple ways to get a\", \"t that assembly code. The online tool \\nsharplab.io is incredibly useful for this (thanks to [@ashmin\", \"d](https://github.com/ashmind) for this \\ntool); however it currently only targets a single release, \", \"so as I write this I\\u2019m only able to see the \\noutput for .NET 6, which makes it difficult to use for \", \"A/B comparisons. godbolt.org is also valuable for \\nthis, with C# support added in compiler-explorer/\", \"compiler-explorer#3168 from \\n[@hez2010](https://github.com/hez2010), with similar limitations. The m\", \"ost flexible solutions involve \\ngetting at that assembly code locally, as it enables comparing whate\", \"ver versions or local builds you \\ndesire with whatever configurations and switches set that you need\", \". \\nOne common approach is to use the [DisassemblyDiagnoser] in benchmarkdotnet. Simply slap the \\n[Di\", \"sassemblyDiagnoser] attribute onto your test class: benchmarkdotnet will find the assembly code \\ngen\", \"erated for your tests and some depth of functions they call, and dump out the found assembly \\ncode i\", \"n a human-readable form. For example, if I run this test: \\nusing BenchmarkDotNet.Attributes; \\nusing \", \"BenchmarkDotNet.Running; \\nusing System; \\n \\n[DisassemblyDiagnoser] \\npublic partial class Program \\n{ \\n\", \"    static void Main(string[] args) => \\nBenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run\", \"(args); \\n \\n    private int _a = 42, _b = 84; \\n \\n    [Benchmark] \\n    public int Min() => Math.Min(_a\", \", _b); \\n} \\nwith: \\ndotnet run -c Release -f net7.0 --filter '**' \\nin addition to doing all of its nor\", \"mal test execution and timing, benchmarkdotnet also outputs a \\nProgram-asm.md file that contains thi\", \"s: \\n; Program.Min() \\n       mov       eax,[rcx+8] \\n       mov       edx,[rcx+0C] \\n       cmp       e\", \"ax,edx \\n \\n4 \\nCHAPTER 2 | JIT \\n \\n       jg        short M00_L01 \\n       mov       edx,eax \\nM00_L00: \\n\", \"       mov       eax,edx \\n       ret \\nM00_L01: \\n       jmp       short M00_L00 \\n; Total bytes of cod\", \"e 17 \\nPretty neat. This support was recently improved further in dotnet/benchmarkdotnet#2072, which \", \"\\nallows passing a filter list on the command-line to benchmarkdotnet to tell it exactly which method\", \"s\\u2019 \\nassembly code should be dumped. \\nIf you can get your hands on a \\u201cdebug\\u201d or \\u201cchecked\\u201d build of th\", \"e .NET runtime (\\u201cchecked\\u201d is a build \\nthat has optimizations enabled but also still includes asserts\", \"), and specifically of clrjit.dll, another \\nvaluable approach is to set an environment variable that\", \" causes the JIT itself to spit out a human-\\nreadable description of all of the assembly code it emit\", \"s. This can be used with any kind of \\napplication, as it\\u2019s part of the JIT itself rather than part o\", \"f any specific tool or other environment, it \\nsupports showing the code the JIT generates each time \", \"it generates code (e.g. if it first compiles a \\nmethod without optimization and then later recompile\", \"s it with optimization), and overall it\\u2019s the most \\naccurate picture of the assembly code as it come\", \"s \\u201cstraight from the horses mouth,\\u201d as it were. The \\n(big) downside of course is that it requires a \", \"non-release build of the runtime, which typically means \\nyou need to build it yourself from the sour\", \"ces in the dotnet/runtime repo. \\n\\u2026 until .NET 7, that is. As of dotnet/runtime#73365, this assembly \", \"dumping support is now available in \\nrelease builds as well, which means it\\u2019s simply part of .NET 7 \", \"and you don\\u2019t need anything special to \\nuse it. To see this, try creating a simple \\u201chello world\\u201d app\", \" like: \\nusing System; \\n \\nclass Program \\n{ \\n    public static void Main() => Console.WriteLine(\\\"Hello\", \", world!\\\"); \\n} \\nand building it (e.g. dotnet build -c Release). Then, set the DOTNET_JitDisasm envir\", \"onment \\nvariable to the name of the method we care about, in this case \\u201cMain\\u201d (the exact syntax allo\", \"wed is \\nmore permissive and allows for some use of wildcards, optional namespace and class names, et\", \"c.). As \\nI\\u2019m using PowerShell, that means: \\n$env:DOTNET_JitDisasm=\\\"Main\\\" \\nand then running the app. \", \"You should see code like this output to the console: \\n; Assembly listing for method Program:Main() \\n\", \"; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compilation \\n; MinOpts code \\n; rbp \", \"based frame \\n; partially interruptible \\n \\nG_M000_IG01:                ;; offset=0000H \\n       55    \", \"               push     rbp \\n       4883EC20             sub      rsp, 32 \\n \\n5 \\nCHAPTER 2 | JIT \\n \\n \", \"      488D6C2420           lea      rbp, [rsp+20H] \\n \\nG_M000_IG02:                ;; offset=000AH \\n \", \"      48B9D820400A8E010000 mov      rcx, 0x18E0A4020D8 \\n       488B09               mov      rcx, gw\", \"ord ptr [rcx] \\n       FF1583B31000         call     [Console:WriteLine(String)] \\n       90          \", \"         nop \\n \\nG_M000_IG03:                ;; offset=001EH \\n       4883C420             add      rs\", \"p, 32 \\n       5D                   pop      rbp \\n       C3                   ret \\n \\n; Total bytes of\", \" code 36 \\n \\nHello, world! \\nThis is immeasurably helpful for performance analysis and tuning, even fo\", \"r questions as simple as \\u201cdid \\nmy function get inlined\\u201d or \\u201cis this code I expected to be optimized \", \"away actually getting optimized \\naway.\\u201d Throughout the rest of this post, I\\u2019ll include assembly snip\", \"pets generated by one of these two \\nmechanisms, in order to help exemplify concepts. \\nNote that it c\", \"an sometimes be a little confusing figuring out what name to specify as the value for \\nDOTNET_JitDis\", \"asm, especially when the method you care about is one that the C# compiler names or \\nname mangles (s\", \"ince the JIT only sees the IL and metadata, not the original C#), e.g. the name of the \\nentry point \", \"method for a program with top-level statements, the names of local functions, etc. To \\nboth help wit\", \"h this and to provide a really valuable top-level view of the work the JIT is doing, .NET 7 \\nalso su\", \"pports the new DOTNET_JitDisasmSummary environment variable (introduced in \\ndotnet/runtime#74090). S\", \"et that to \\u201c1\\u201d, and it\\u2019ll result in the JIT emitting a line every time it compiles a \\nmethod, includ\", \"ing the name of that method which is copy/pasteable with DOTNET_JitDisasm. This \\nfeature is useful i\", \"n-and-of-itself, however, as it can quickly highlight for you what\\u2019s being compiled, \\nwhen, and with\", \" what settings. For example, if I set the environment variable and then run a \\u201chello, \\nworld\\u201d consol\", \"e app, I get this output: \\n   1: JIT compiled CastHelpers:StelemRef(Array,long,Object) [Tier1, IL si\", \"ze=88, code \\nsize=93] \\n   2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):byref [Tier1, IL s\", \"ize=44, code \\nsize=44] \\n   3: JIT compiled SpanHelpers:IndexOfNullCharacter(byref):int [Tier1, IL si\", \"ze=792, code \\nsize=388] \\n   4: JIT compiled Program:Main() [Tier0, IL size=11, code size=36] \\n   5: \", \"JIT compiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL \\nsize=490, code size=11\", \"87] \\nHello, world! \\nWe can see for \\u201chello, world\\u201d there\\u2019s only 5 methods that actually get JIT compi\", \"led. There are of \\ncourse many more methods that get executed as part of a simple \\u201chello, world,\\u201d bu\", \"t almost all of \\nthem have precompiled native code available as part of the \\u201cReady To Run\\u201d (R2R) ima\", \"ges of the core \\nlibraries. The first three in the above list (StelemRef, LdelemaRef, and IndexOfNul\", \"lCharacter) don\\u2019t \\nbecause they explicitly opted-out of R2R via use of the \\n[MethodImpl(MethodImplOp\", \"tions.AggressiveOptimization)] attribute (despite the name, this \\nattribute should almost never be u\", \"sed, and is only used for very specific reasons in a few very specific \\nplaces in the core libraries\", \"). Then there\\u2019s our Main method. And lastly there\\u2019s the NarrowUtf16ToAscii \\n \\n6 \\nCHAPTER 2 | JIT \\n \\n\", \"method, which doesn\\u2019t have R2R code, either, due to using the variable-width Vector<T> (more on \\ntha\", \"t later). Every other method that\\u2019s run doesn\\u2019t require JIT\\u2019ing. If we instead first set the \\nDOTNET\", \"_ReadyToRun environment variable to 0, the list is much longer, and gives you a very good \\nsense of \", \"what the JIT needs to do on startup (and why technologies like R2R are important for startup \\ntime).\", \" Note how many methods get compiled before \\u201chello, world\\u201d is output: \\n   1: JIT compiled CastHelpers\", \":StelemRef(Array,long,Object) [Tier1, IL size=88, code \\nsize=93] \\n   2: JIT compiled CastHelpers:Lde\", \"lemaRef(Array,long,long):byref [Tier1, IL size=44, code \\nsize=44] \\n   3: JIT compiled AppContext:Set\", \"up(long,long,int) [Tier0, IL size=68, code size=275] \\n   4: JIT compiled Dictionary`2:.ctor(int):thi\", \"s [Tier0, IL size=9, code size=40] \\n   5: JIT compiled Dictionary`2:.ctor(int,IEqualityComparer`1):t\", \"his [Tier0, IL size=102, \\ncode size=444] \\n   6: JIT compiled Object:.ctor():this [Tier0, IL size=1, \", \"code size=10] \\n   7: JIT compiled Dictionary`2:Initialize(int):int:this [Tier0, IL size=56, code siz\", \"e=231] \\n   8: JIT compiled HashHelpers:GetPrime(int):int [Tier0, IL size=83, code size=379] \\n   9: J\", \"IT compiled HashHelpers:.cctor() [Tier0, IL size=24, code size=102] \\n  10: JIT compiled HashHelpers:\", \"GetFastModMultiplier(int):long [Tier0, IL size=9, code \\nsize=37] \\n  11: JIT compiled Type:GetTypeFro\", \"mHandle(RuntimeTypeHandle):Type [Tier0, IL size=8, code \\nsize=14] \\n  12: JIT compiled Type:op_Equali\", \"ty(Type,Type):bool [Tier0, IL size=38, code size=143] \\n  13: JIT compiled \\nNonRandomizedStringEquali\", \"tyComparer:GetStringComparer(Object):IEqualityComparer`1 [Tier0, \\nIL size=39, code size=170] \\n  14: \", \"JIT compiled NonRandomizedStringEqualityComparer:.cctor() [Tier0, IL size=46, code \\nsize=232] \\n  15:\", \" JIT compiled EqualityComparer`1:get_Default():EqualityComparer`1 [Tier0, IL size=6, \\ncode size=36] \", \"\\n  16: JIT compiled EqualityComparer`1:.cctor() [Tier0, IL size=26, code size=125] \\n  17: JIT compil\", \"ed ComparerHelpers:CreateDefaultEqualityComparer(Type):Object [Tier0, IL \\nsize=235, code size=949] \\n\", \"  18: JIT compiled CastHelpers:ChkCastClass(long,Object):Object [Tier0, IL size=22, code \\nsize=72] \\n\", \"  19: JIT compiled RuntimeHelpers:GetMethodTable(Object):long [Tier0, IL size=11, code \\nsize=33] \\n  \", \"20: JIT compiled CastHelpers:IsInstanceOfClass(long,Object):Object [Tier0, IL size=97, \\ncode size=25\", \"7] \\n  21: JIT compiled GenericEqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31] \\n  22\", \": JIT compiled EqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31] \\n  23: JIT compiled \", \"CastHelpers:ChkCastClassSpecial(long,Object):Object [Tier0, IL size=87, \\ncode size=246] \\n  24: JIT c\", \"ompiled OrdinalComparer:.ctor(IEqualityComparer`1):this [Tier0, IL size=8, code \\nsize=39] \\n  25: JIT\", \" compiled NonRandomizedStringEqualityComparer:.ctor(IEqualityComparer`1):this \\n[Tier0, IL size=14, c\", \"ode size=52] \\n  26: JIT compiled StringComparer:get_Ordinal():StringComparer [Tier0, IL size=6, code\", \" \\nsize=49] \\n  27: JIT compiled OrdinalCaseSensitiveComparer:.cctor() [Tier0, IL size=11, code size=7\", \"1] \\n  28: JIT compiled OrdinalCaseSensitiveComparer:.ctor():this [Tier0, IL size=8, code \\nsize=33] \\n\", \"  29: JIT compiled OrdinalComparer:.ctor(bool):this [Tier0, IL size=14, code size=43] \\n  30: JIT com\", \"piled StringComparer:.ctor():this [Tier0, IL size=7, code size=31] \\n  31: JIT compiled StringCompare\", \"r:get_OrdinalIgnoreCase():StringComparer [Tier0, IL size=6, \\ncode size=49] \\n  32: JIT compiled Ordin\", \"alIgnoreCaseComparer:.cctor() [Tier0, IL size=11, code size=71] \\n  33: JIT compiled OrdinalIgnoreCas\", \"eComparer:.ctor():this [Tier0, IL size=8, code size=36] \\n  34: JIT compiled OrdinalIgnoreCaseCompare\", \"r:.ctor(IEqualityComparer`1):this [Tier0, IL \\n \\n7 \\nCHAPTER 2 | JIT \\n \\nsize=8, code size=39] \\n  35: J\", \"IT compiled CastHelpers:ChkCastAny(long,Object):Object [Tier0, IL size=38, code \\nsize=115] \\n  36: JI\", \"T compiled CastHelpers:TryGet(long,long):int [Tier0, IL size=129, code size=308] \\n  37: JIT compiled\", \" CastHelpers:TableData(ref):byref [Tier0, IL size=7, code size=31] \\n  38: JIT compiled MemoryMarshal\", \":GetArrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24] \\n  39: JIT compiled CastHelpers:\", \"KeyToBucket(byref,long,long):int [Tier0, IL size=38, code \\nsize=87] \\n  40: JIT compiled CastHelpers:\", \"HashShift(byref):int [Tier0, IL size=3, code size=16] \\n  41: JIT compiled BitOperations:RotateLeft(l\", \"ong,int):long [Tier0, IL size=17, code \\nsize=23] \\n  42: JIT compiled CastHelpers:Element(byref,int):\", \"byref [Tier0, IL size=15, code size=33] \\n  43: JIT compiled Volatile:Read(byref):int [Tier0, IL size\", \"=6, code size=16] \\n  44: JIT compiled String:Ctor(long):String [Tier0, IL size=57, code size=155] \\n \", \" 45: JIT compiled String:wcslen(long):int [Tier0, IL size=7, code size=31] \\n  46: JIT compiled SpanH\", \"elpers:IndexOfNullCharacter(byref):int [Tier1, IL size=792, code \\nsize=388] \\n  47: JIT compiled Stri\", \"ng:get_Length():int:this [Tier0, IL size=7, code size=17] \\n  48: JIT compiled Buffer:Memmove(byref,b\", \"yref,long) [Tier0, IL size=59, code size=102] \\n  49: JIT compiled RuntimeHelpers:IsReferenceOrContai\", \"nsReferences():bool [Tier0, IL size=2, \\ncode size=8] \\n  50: JIT compiled Buffer:Memmove(byref,byref,\", \"long) [Tier0, IL size=480, code size=678] \\n  51: JIT compiled Dictionary`2:Add(__Canon,__Canon):this\", \" [Tier0, IL size=11, code size=55] \\n  52: JIT compiled Dictionary`2:TryInsert(__Canon,__Canon,ubyte)\", \":bool:this [Tier0, IL \\nsize=675, code size=2467] \\n  53: JIT compiled OrdinalComparer:GetHashCode(Str\", \"ing):int:this [Tier0, IL size=7, code \\nsize=37] \\n  54: JIT compiled String:GetNonRandomizedHashCode(\", \"):int:this [Tier0, IL size=110, code \\nsize=290] \\n  55: JIT compiled BitOperations:RotateLeft(int,int\", \"):int [Tier0, IL size=17, code size=20] \\n  56: JIT compiled Dictionary`2:GetBucket(int):byref:this [\", \"Tier0, IL size=29, code size=90] \\n  57: JIT compiled HashHelpers:FastMod(int,int,long):int [Tier0, I\", \"L size=20, code size=70] \\n  58: JIT compiled Type:get_IsValueType():bool:this [Tier0, IL size=7, cod\", \"e size=39] \\n  59: JIT compiled RuntimeType:IsValueTypeImpl():bool:this [Tier0, IL size=54, code \\nsiz\", \"e=158] \\n  60: JIT compiled RuntimeType:GetNativeTypeHandle():TypeHandle:this [Tier0, IL size=12, \\nco\", \"de size=48] \\n  61: JIT compiled TypeHandle:.ctor(long):this [Tier0, IL size=8, code size=25] \\n  62: \", \"JIT compiled TypeHandle:get_IsTypeDesc():bool:this [Tier0, IL size=14, code size=38] \\n  63: JIT comp\", \"iled TypeHandle:AsMethodTable():long:this [Tier0, IL size=7, code size=17] \\n  64: JIT compiled Metho\", \"dTable:get_IsValueType():bool:this [Tier0, IL size=20, code \\nsize=32] \\n  65: JIT compiled GC:KeepAli\", \"ve(Object) [Tier0, IL size=1, code size=10] \\n  66: JIT compiled Buffer:_Memmove(byref,byref,long) [T\", \"ier0, IL size=25, code size=279] \\n  67: JIT compiled Environment:InitializeCommandLineArgs(long,int,\", \"long):ref [Tier0, IL \\nsize=75, code size=332] \\n  68: JIT compiled Environment:.cctor() [Tier0, IL si\", \"ze=11, code size=163] \\n  69: JIT compiled StartupHookProvider:ProcessStartupHooks() [Tier-0 switched\", \" to FullOpts, \\nIL size=365, code size=1053] \\n  70: JIT compiled StartupHookProvider:get_IsSupported(\", \"):bool [Tier0, IL size=18, code \\nsize=60] \\n  71: JIT compiled AppContext:TryGetSwitch(String,byref):\", \"bool [Tier0, IL size=97, code \\nsize=322] \\n  72: JIT compiled ArgumentException:ThrowIfNullOrEmpty(St\", \"ring,String) [Tier0, IL size=16, \\ncode size=53] \\n  73: JIT compiled String:IsNullOrEmpty(String):boo\", \"l [Tier0, IL size=15, code size=58] \\n  74: JIT compiled AppContext:GetData(String):Object [Tier0, IL\", \" size=64, code size=205] \\n  75: JIT compiled ArgumentNullException:ThrowIfNull(Object,String) [Tier0\", \", IL size=10, \\ncode size=42] \\n  76: JIT compiled Monitor:Enter(Object,byref) [Tier0, IL size=17, cod\", \"e size=55] \\n \\n8 \\nCHAPTER 2 | JIT \\n \\n  77: JIT compiled Dictionary`2:TryGetValue(__Canon,byref):bool:\", \"this [Tier0, IL size=39, \\ncode size=97] \\n  78: JIT compiled Dictionary`2:FindValue(__Canon):byref:th\", \"is [Tier0, IL size=391, code \\nsize=1466] \\n  79: JIT compiled EventSource:.cctor() [Tier0, IL size=34\", \", code size=80] \\n  80: JIT compiled EventSource:InitializeIsSupported():bool [Tier0, IL size=18, cod\", \"e \\nsize=60] \\n  81: JIT compiled RuntimeEventSource:.ctor():this [Tier0, IL size=55, code size=184] \\n\", \"  82: JIT compiled \\nGuid:.ctor(int,short,short,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte):this\", \" [Tier0, IL \\nsize=86, code size=132] \\n  83: JIT compiled EventSource:.ctor(Guid,String):this [Tier0,\", \" IL size=11, code size=90] \\n  84: JIT compiled EventSource:.ctor(Guid,String,int,ref):this [Tier0, I\", \"L size=58, code \\nsize=187] \\n  85: JIT compiled EventSource:get_IsSupported():bool [Tier0, IL size=6,\", \" code size=11] \\n  86: JIT compiled TraceLoggingEventHandleTable:.ctor():this [Tier0, IL size=20, cod\", \"e \\nsize=67] \\n  87: JIT compiled EventSource:ValidateSettings(int):int [Tier0, IL size=37, code size=\", \"147] \\n  88: JIT compiled EventSource:Initialize(Guid,String,ref):this [Tier0, IL size=418, code \\nsiz\", \"e=1584] \\n  89: JIT compiled Guid:op_Equality(Guid,Guid):bool [Tier0, IL size=10, code size=39] \\n  90\", \": JIT compiled Guid:EqualsCore(byref,byref):bool [Tier0, IL size=132, code size=171] \\n  91: JIT comp\", \"iled ActivityTracker:get_Instance():ActivityTracker [Tier0, IL size=6, code \\nsize=49] \\n  92: JIT com\", \"piled ActivityTracker:.cctor() [Tier0, IL size=11, code size=71] \\n  93: JIT compiled ActivityTracker\", \":.ctor():this [Tier0, IL size=7, code size=31] \\n  94: JIT compiled RuntimeEventSource:get_ProviderMe\", \"tadata():ReadOnlySpan`1:this [Tier0, IL \\nsize=13, code size=91] \\n  95: JIT compiled ReadOnlySpan`1:.\", \"ctor(long,int):this [Tier0, IL size=51, code size=115] \\n  96: JIT compiled RuntimeHelpers:IsReferenc\", \"eOrContainsReferences():bool [Tier0, IL size=2, \\ncode size=8] \\n  97: JIT compiled ReadOnlySpan`1:get\", \"_Length():int:this [Tier0, IL size=7, code size=17] \\n  98: JIT compiled OverrideEventProvider:.ctor(\", \"EventSource,int):this [Tier0, IL size=22, \\ncode size=68] \\n  99: JIT compiled EventProvider:.ctor(int\", \"):this [Tier0, IL size=46, code size=194] \\n 100: JIT compiled EtwEventProvider:.ctor():this [Tier0, \", \"IL size=7, code size=31] \\n 101: JIT compiled EventProvider:Register(EventSource):this [Tier0, IL siz\", \"e=48, code \\nsize=186] \\n 102: JIT compiled MulticastDelegate:CtorClosed(Object,long):this [Tier0, IL \", \"size=23, code \\nsize=70] \\n 103: JIT compiled EventProvider:EventRegister(EventSource,EtwEnableCallbac\", \"k):int:this \\n[Tier0, IL size=53, code size=154] \\n 104: JIT compiled EventSource:get_Name():String:th\", \"is [Tier0, IL size=7, code size=18] \\n 105: JIT compiled EventSource:get_Guid():Guid:this [Tier0, IL \", \"size=7, code size=41] \\n 106: JIT compiled \\nEtwEventProvider:System.Diagnostics.Tracing.IEventProvide\", \"r.EventRegister(EventSource,EtwEna\\nbleCallback,long,byref):int:this [Tier0, IL size=19, code size=71\", \"] \\n 107: JIT compiled Advapi32:EventRegister(byref,EtwEnableCallback,long,byref):int [Tier0, \\nIL siz\", \"e=53, code size=374] \\n 108: JIT compiled Marshal:GetFunctionPointerForDelegate(__Canon):long [Tier0,\", \" IL size=17, \\ncode size=54] \\n 109: JIT compiled Marshal:GetFunctionPointerForDelegate(Delegate):long\", \" [Tier0, IL size=18, \\ncode size=53] \\n 110: JIT compiled EventPipeEventProvider:.ctor():this [Tier0, \", \"IL size=18, code size=41] \\n 111: JIT compiled EventListener:get_EventListenersLock():Object [Tier0, \", \"IL size=41, code \\nsize=157] \\n 112: JIT compiled List`1:.ctor(int):this [Tier0, IL size=47, code size\", \"=275] \\n 113: JIT compiled Interlocked:CompareExchange(byref,__Canon,__Canon):__Canon [Tier0, IL \\nsiz\", \"e=9, code size=50] \\n 114: JIT compiled NativeRuntimeEventSource:.cctor() [Tier0, IL size=11, code si\", \"ze=71] \\n 115: JIT compiled NativeRuntimeEventSource:.ctor():this [Tier0, IL size=63, code size=184] \", \"\\n \\n9 \\nCHAPTER 2 | JIT \\n \\n 116: JIT compiled \\nGuid:.ctor(int,ushort,ushort,ubyte,ubyte,ubyte,ubyte,ub\", \"yte,ubyte,ubyte,ubyte):this [Tier0, \\nIL size=88, code size=132] \\n 117: JIT compiled NativeRuntimeEve\", \"ntSource:get_ProviderMetadata():ReadOnlySpan`1:this \\n[Tier0, IL size=13, code size=91] \\n 118: JIT co\", \"mpiled \\nEventPipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventRegister(EventSource,\\n\", \"EtwEnableCallback,long,byref):int:this [Tier0, IL size=44, code size=118] \\n 119: JIT compiled EventP\", \"ipeInternal:CreateProvider(String,EtwEnableCallback):long [Tier0, \\nIL size=43, code size=320] \\n 120:\", \" JIT compiled Utf16StringMarshaller:GetPinnableReference(String):byref [Tier0, IL \\nsize=13, code siz\", \"e=50] \\n 121: JIT compiled String:GetPinnableReference():byref:this [Tier0, IL size=7, code \\nsize=24]\", \" \\n 122: JIT compiled EventListener:AddEventSource(EventSource) [Tier0, IL size=175, code \\nsize=560] \", \"\\n 123: JIT compiled List`1:get_Count():int:this [Tier0, IL size=7, code size=17] \\n 124: JIT compiled\", \" WeakReference`1:.ctor(__Canon):this [Tier0, IL size=9, code size=42] \\n 125: JIT compiled WeakRefere\", \"nce`1:.ctor(__Canon,bool):this [Tier0, IL size=15, code \\nsize=60] \\n 126: JIT compiled List`1:Add(__C\", \"anon):this [Tier0, IL size=60, code size=124] \\n 127: JIT compiled String:op_Inequality(String,String\", \"):bool [Tier0, IL size=11, code \\nsize=46] \\n 128: JIT compiled String:Equals(String,String):bool [Tie\", \"r0, IL size=36, code size=114] \\n 129: JIT compiled ReadOnlySpan`1:GetPinnableReference():byref:this \", \"[Tier0, IL size=23, \\ncode size=57] \\n 130: JIT compiled EventProvider:SetInformation(int,long,int):in\", \"t:this [Tier0, IL size=38, \\ncode size=131] \\n 131: JIT compiled ILStubClass:IL_STUB_PInvoke(long,int,\", \"long,int):int [FullOpts, IL \\nsize=62, code size=170] \\n 132: JIT compiled Program:Main() [Tier0, IL s\", \"ize=11, code size=36] \\n 133: JIT compiled Console:WriteLine(String) [Tier0, IL size=12, code size=59\", \"] \\n 134: JIT compiled Console:get_Out():TextWriter [Tier0, IL size=20, code size=113] \\n 135: JIT com\", \"piled Console:.cctor() [Tier0, IL size=11, code size=71] \\n 136: JIT compiled Volatile:Read(byref):__\", \"Canon [Tier0, IL size=6, code size=21] \\n 137: JIT compiled Console:<get_Out>g__EnsureInitialized|26_\", \"0():TextWriter [Tier0, IL \\nsize=63, code size=209] \\n 138: JIT compiled ConsolePal:OpenStandardOutput\", \"():Stream [Tier0, IL size=34, code \\nsize=130] \\n 139: JIT compiled Console:get_OutputEncoding():Encod\", \"ing [Tier0, IL size=72, code size=237] \\n 140: JIT compiled ConsolePal:get_OutputEncoding():Encoding \", \"[Tier0, IL size=11, code \\nsize=200] \\n 141: JIT compiled NativeLibrary:LoadLibraryCallbackStub(String\", \",Assembly,bool,int):long \\n[Tier0, IL size=63, code size=280] \\n 142: JIT compiled EncodingHelper:GetS\", \"upportedConsoleEncoding(int):Encoding [Tier0, IL \\nsize=53, code size=186] \\n 143: JIT compiled Encodi\", \"ng:GetEncoding(int):Encoding [Tier0, IL size=340, code size=1025] \\n 144: JIT compiled EncodingProvid\", \"er:GetEncodingFromProvider(int):Encoding [Tier0, IL \\nsize=51, code size=232] \\n 145: JIT compiled Enc\", \"oding:FilterDisallowedEncodings(Encoding):Encoding [Tier0, IL \\nsize=29, code size=84] \\n 146: JIT com\", \"piled LocalAppContextSwitches:get_EnableUnsafeUTF7Encoding():bool [Tier0, IL \\nsize=16, code size=46]\", \" \\n 147: JIT compiled LocalAppContextSwitches:GetCachedSwitchValue(String,byref):bool [Tier0, \\nIL siz\", \"e=22, code size=76] \\n 148: JIT compiled LocalAppContextSwitches:GetCachedSwitchValueInternal(String,\", \"byref):bool \\n[Tier0, IL size=46, code size=168] \\n 149: JIT compiled LocalAppContextSwitches:GetSwitc\", \"hDefaultValue(String):bool [Tier0, IL \\nsize=32, code size=98] \\n 150: JIT compiled String:op_Equality\", \"(String,String):bool [Tier0, IL size=8, code size=39] \\n 151: JIT compiled Encoding:get_Default():Enc\", \"oding [Tier0, IL size=6, code size=49] \\n \\n10 \\nCHAPTER 2 | JIT \\n \\n 152: JIT compiled Encoding:.cctor(\", \") [Tier0, IL size=12, code size=73] \\n 153: JIT compiled UTF8EncodingSealed:.ctor(bool):this [Tier0, \", \"IL size=8, code size=40] \\n 154: JIT compiled UTF8Encoding:.ctor(bool):this [Tier0, IL size=14, code \", \"size=43] \\n 155: JIT compiled UTF8Encoding:.ctor():this [Tier0, IL size=12, code size=36] \\n 156: JIT \", \"compiled Encoding:.ctor(int):this [Tier0, IL size=42, code size=152] \\n 157: JIT compiled UTF8Encodin\", \"g:SetDefaultFallbacks():this [Tier0, IL size=64, code \\nsize=212] \\n 158: JIT compiled EncoderReplacem\", \"entFallback:.ctor(String):this [Tier0, IL size=110, code \\nsize=360] \\n 159: JIT compiled EncoderFallb\", \"ack:.ctor():this [Tier0, IL size=7, code size=31] \\n 160: JIT compiled String:get_Chars(int):ushort:t\", \"his [Tier0, IL size=29, code size=61] \\n 161: JIT compiled Char:IsSurrogate(ushort):bool [Tier0, IL s\", \"ize=17, code size=43] \\n 162: JIT compiled Char:IsBetween(ushort,ushort,ushort):bool [Tier0, IL size=\", \"12, code \\nsize=52] \\n 163: JIT compiled DecoderReplacementFallback:.ctor(String):this [Tier0, IL size\", \"=110, code \\nsize=360] \\n 164: JIT compiled DecoderFallback:.ctor():this [Tier0, IL size=7, code size=\", \"31] \\n 165: JIT compiled Encoding:get_CodePage():int:this [Tier0, IL size=7, code size=17] \\n 166: JIT\", \" compiled Encoding:get_UTF8():Encoding [Tier0, IL size=6, code size=49] \\n 167: JIT compiled UTF8Enco\", \"ding:.cctor() [Tier0, IL size=12, code size=76] \\n 168: JIT compiled Volatile:Write(byref,__Canon) [T\", \"ier0, IL size=6, code size=32] \\n 169: JIT compiled ConsolePal:GetStandardFile(int,int,bool):Stream [\", \"Tier0, IL size=50, code \\nsize=183] \\n 170: JIT compiled ConsolePal:get_InvalidHandleValue():long [Tie\", \"r0, IL size=7, code \\nsize=41] \\n 171: JIT compiled IntPtr:.ctor(int):this [Tier0, IL size=9, code siz\", \"e=25] \\n 172: JIT compiled ConsolePal:ConsoleHandleIsWritable(long):bool [Tier0, IL size=26, code \\nsi\", \"ze=68] \\n 173: JIT compiled Kernel32:WriteFile(long,long,int,byref,long):int [Tier0, IL size=46, \\ncod\", \"e size=294] \\n 174: JIT compiled Marshal:SetLastSystemError(int) [Tier0, IL size=7, code size=40] \\n 1\", \"75: JIT compiled Marshal:GetLastSystemError():int [Tier0, IL size=6, code size=34] \\n 176: JIT compil\", \"ed WindowsConsoleStream:.ctor(long,int,bool):this [Tier0, IL size=37, code \\nsize=90] \\n 177: JIT comp\", \"iled ConsoleStream:.ctor(int):this [Tier0, IL size=31, code size=71] \\n 178: JIT compiled Stream:.cto\", \"r():this [Tier0, IL size=7, code size=31] \\n 179: JIT compiled MarshalByRefObject:.ctor():this [Tier0\", \", IL size=7, code size=31] \\n 180: JIT compiled Kernel32:GetFileType(long):int [Tier0, IL size=27, co\", \"de size=217] \\n 181: JIT compiled Console:CreateOutputWriter(Stream):TextWriter [Tier0, IL size=50, c\", \"ode \\nsize=230] \\n 182: JIT compiled Stream:.cctor() [Tier0, IL size=11, code size=71] \\n 183: JIT comp\", \"iled NullStream:.ctor():this [Tier0, IL size=7, code size=31] \\n 184: JIT compiled EncodingExtensions\", \":RemovePreamble(Encoding):Encoding [Tier0, IL size=25, \\ncode size=118] \\n 185: JIT compiled UTF8Encod\", \"ingSealed:get_Preamble():ReadOnlySpan`1:this [Tier0, IL \\nsize=24, code size=99] \\n 186: JIT compiled \", \"UTF8Encoding:get_PreambleSpan():ReadOnlySpan`1 [Tier0, IL size=12, code \\nsize=87] \\n 187: JIT compile\", \"d ConsoleEncoding:.ctor(Encoding):this [Tier0, IL size=14, code size=52] \\n 188: JIT compiled Encodin\", \"g:.ctor():this [Tier0, IL size=8, code size=33] \\n 189: JIT compiled Encoding:SetDefaultFallbacks():t\", \"his [Tier0, IL size=23, code size=65] \\n 190: JIT compiled EncoderFallback:get_ReplacementFallback():\", \"EncoderFallback [Tier0, IL \\nsize=6, code size=49] \\n 191: JIT compiled EncoderReplacementFallback:.cc\", \"tor() [Tier0, IL size=11, code size=71] \\n 192: JIT compiled EncoderReplacementFallback:.ctor():this \", \"[Tier0, IL size=12, code \\nsize=44] \\n 193: JIT compiled DecoderFallback:get_ReplacementFallback():Dec\", \"oderFallback [Tier0, IL \\nsize=6, code size=49] \\n 194: JIT compiled DecoderReplacementFallback:.cctor\", \"() [Tier0, IL size=11, code size=71] \\n 195: JIT compiled DecoderReplacementFallback:.ctor():this [Ti\", \"er0, IL size=12, code \\nsize=44] \\n \\n11 \\nCHAPTER 2 | JIT \\n \\n 196: JIT compiled StreamWriter:.ctor(Stre\", \"am,Encoding,int,bool):this [Tier0, IL size=201, \\ncode size=564] \\n 197: JIT compiled Task:get_Complet\", \"edTask():Task [Tier0, IL size=6, code size=49] \\n 198: JIT compiled Task:.cctor() [Tier0, IL size=76,\", \" code size=316] \\n 199: JIT compiled TaskFactory:.ctor():this [Tier0, IL size=7, code size=31] \\n 200:\", \" JIT compiled Task`1:.ctor(bool,VoidTaskResult,int,CancellationToken):this [Tier0, IL \\nsize=21, code\", \" size=75] \\n 201: JIT compiled Task:.ctor(bool,int,CancellationToken):this [Tier0, IL size=70, code \\n\", \"size=181] \\n 202: JIT compiled <>c:.cctor() [Tier0, IL size=11, code size=71] \\n 203: JIT compiled <>c\", \":.ctor():this [Tier0, IL size=7, code size=31] \\n 204: JIT compiled TextWriter:.ctor(IFormatProvider)\", \":this [Tier0, IL size=36, code \\nsize=124] \\n 205: JIT compiled TextWriter:.cctor() [Tier0, IL size=26\", \", code size=108] \\n 206: JIT compiled NullTextWriter:.ctor():this [Tier0, IL size=7, code size=31] \\n \", \"207: JIT compiled TextWriter:.ctor():this [Tier0, IL size=29, code size=103] \\n 208: JIT compiled Str\", \"ing:ToCharArray():ref:this [Tier0, IL size=52, code size=173] \\n 209: JIT compiled MemoryMarshal:GetA\", \"rrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24] \\n 210: JIT compiled ConsoleStream:get\", \"_CanWrite():bool:this [Tier0, IL size=7, code size=18] \\n 211: JIT compiled ConsoleEncoding:GetEncode\", \"r():Encoder:this [Tier0, IL size=12, code \\nsize=57] \\n 212: JIT compiled UTF8Encoding:GetEncoder():En\", \"coder:this [Tier0, IL size=7, code size=63] \\n 213: JIT compiled EncoderNLS:.ctor(Encoding):this [Tie\", \"r0, IL size=37, code size=102] \\n 214: JIT compiled Encoder:.ctor():this [Tier0, IL size=7, code size\", \"=31] \\n 215: JIT compiled Encoding:get_EncoderFallback():EncoderFallback:this [Tier0, IL size=7, \\ncod\", \"e size=18] \\n 216: JIT compiled EncoderNLS:Reset():this [Tier0, IL size=24, code size=92] \\n 217: JIT \", \"compiled ConsoleStream:get_CanSeek():bool:this [Tier0, IL size=2, code size=12] \\n 218: JIT compiled \", \"StreamWriter:set_AutoFlush(bool):this [Tier0, IL size=25, code size=72] \\n 219: JIT compiled StreamWr\", \"iter:CheckAsyncTaskInProgress():this [Tier0, IL size=19, code \\nsize=47] \\n 220: JIT compiled Task:get\", \"_IsCompleted():bool:this [Tier0, IL size=16, code size=40] \\n 221: JIT compiled Task:IsCompletedMetho\", \"d(int):bool [Tier0, IL size=11, code size=25] \\n 222: JIT compiled StreamWriter:Flush(bool,bool):this\", \" [Tier0, IL size=272, code size=1127] \\n 223: JIT compiled StreamWriter:ThrowIfDisposed():this [Tier0\", \", IL size=15, code size=43] \\n 224: JIT compiled Encoding:get_Preamble():ReadOnlySpan`1:this [Tier0, \", \"IL size=12, code \\nsize=70] \\n 225: JIT compiled ConsoleEncoding:GetPreamble():ref:this [Tier0, IL siz\", \"e=6, code size=27] \\n 226: JIT compiled Array:Empty():ref [Tier0, IL size=6, code size=49] \\n 227: JIT\", \" compiled EmptyArray`1:.cctor() [Tier0, IL size=12, code size=52] \\n 228: JIT compiled ReadOnlySpan`1\", \":op_Implicit(ref):ReadOnlySpan`1 [Tier0, IL size=7, code \\nsize=79] \\n 229: JIT compiled ReadOnlySpan`\", \"1:.ctor(ref):this [Tier0, IL size=33, code size=81] \\n 230: JIT compiled MemoryMarshal:GetArrayDataRe\", \"ference(ref):byref [Tier0, IL size=7, code \\nsize=24] \\n 231: JIT compiled ConsoleEncoding:GetMaxByteC\", \"ount(int):int:this [Tier0, IL size=13, code \\nsize=63] \\n 232: JIT compiled UTF8EncodingSealed:GetMaxB\", \"yteCount(int):int:this [Tier0, IL size=20, \\ncode size=50] \\n 233: JIT compiled Span`1:.ctor(long,int)\", \":this [Tier0, IL size=51, code size=115] \\n 234: JIT compiled ReadOnlySpan`1:.ctor(ref,int,int):this \", \"[Tier0, IL size=65, code \\nsize=147] \\n 235: JIT compiled Encoder:GetBytes(ReadOnlySpan`1,Span`1,bool)\", \":int:this [Tier0, IL \\nsize=44, code size=234] \\n 236: JIT compiled MemoryMarshal:GetNonNullPinnableRe\", \"ference(ReadOnlySpan`1):byref [Tier0, \\nIL size=30, code size=54] \\n 237: JIT compiled ReadOnlySpan`1:\", \"get_Length():int:this [Tier0, IL size=7, code size=17] \\n 238: JIT compiled MemoryMarshal:GetNonNullP\", \"innableReference(Span`1):byref [Tier0, IL \\nsize=30, code size=54] \\n 239: JIT compiled Span`1:get_Len\", \"gth():int:this [Tier0, IL size=7, code size=17] \\n \\n12 \\nCHAPTER 2 | JIT \\n \\n 240: JIT compiled Encoder\", \"NLS:GetBytes(long,int,long,int,bool):int:this [Tier0, IL size=92, \\ncode size=279] \\n 241: JIT compile\", \"d ArgumentNullException:ThrowIfNull(long,String) [Tier0, IL size=12, code \\nsize=45] \\n 242: JIT compi\", \"led Encoding:GetBytes(long,int,long,int,EncoderNLS):int:this [Tier0, IL \\nsize=57, code size=187] \\n 2\", \"43: JIT compiled EncoderNLS:get_HasLeftoverData():bool:this [Tier0, IL size=35, code \\nsize=105] \\n 24\", \"4: JIT compiled UTF8Encoding:GetBytesFast(long,int,long,int,byref):int:this [Tier0, IL \\nsize=33, cod\", \"e size=119] \\n 245: JIT compiled Utf8Utility:TranscodeToUtf8(long,int,long,int,byref,byref):int [Tier\", \"0, \\nIL size=1446, code size=3208] \\n 246: JIT compiled Math:Min(int,int):int [Tier0, IL size=8, code \", \"size=28] \\n 247: JIT compiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL \\nsize=4\", \"90, code size=1187] \\n 248: JIT compiled WindowsConsoleStream:Flush():this [Tier0, IL size=26, code s\", \"ize=56] \\n 249: JIT compiled ConsoleStream:Flush():this [Tier0, IL size=1, code size=10] \\n 250: JIT c\", \"ompiled TextWriter:Synchronized(TextWriter):TextWriter [Tier0, IL size=28, code \\nsize=121] \\n 251: JI\", \"T compiled SyncTextWriter:.ctor(TextWriter):this [Tier0, IL size=14, code size=52] \\n 252: JIT compil\", \"ed SyncTextWriter:WriteLine(String):this [Tier0, IL size=13, code size=140] \\n 253: JIT compiled Stre\", \"amWriter:WriteLine(String):this [Tier0, IL size=20, code size=110] \\n 254: JIT compiled String:op_Imp\", \"licit(String):ReadOnlySpan`1 [Tier0, IL size=31, code \\nsize=171] \\n 255: JIT compiled String:GetRawSt\", \"ringData():byref:this [Tier0, IL size=7, code size=24] \\n 256: JIT compiled ReadOnlySpan`1:.ctor(byre\", \"f,int):this [Tier0, IL size=15, code size=39] \\n 257: JIT compiled StreamWriter:WriteSpan(ReadOnlySpa\", \"n`1,bool):this [Tier0, IL size=368, \\ncode size=1036] \\n 258: JIT compiled MemoryMarshal:GetReference(\", \"ReadOnlySpan`1):byref [Tier0, IL size=8, code \\nsize=17] \\n 259: JIT compiled Buffer:MemoryCopy(long,l\", \"ong,long,long) [Tier0, IL size=21, code size=83] \\n 260: JIT compiled Unsafe:ReadUnaligned(long):long\", \" [Tier0, IL size=10, code size=17] \\n 261: JIT compiled ASCIIUtility:AllCharsInUInt64AreAscii(long):b\", \"ool [Tier0, IL size=16, \\ncode size=38] \\n 262: JIT compiled ASCIIUtility:NarrowFourUtf16CharsToAsciiA\", \"ndWriteToBuffer(byref,long) \\n[Tier0, IL size=107, code size=171] \\n 263: JIT compiled Unsafe:WriteUna\", \"ligned(byref,int) [Tier0, IL size=11, code size=22] \\n 264: JIT compiled Unsafe:ReadUnaligned(long):i\", \"nt [Tier0, IL size=10, code size=16] \\n 265: JIT compiled ASCIIUtility:AllCharsInUInt32AreAscii(int):\", \"bool [Tier0, IL size=11, code \\nsize=25] \\n 266: JIT compiled ASCIIUtility:NarrowTwoUtf16CharsToAsciiA\", \"ndWriteToBuffer(byref,int) \\n[Tier0, IL size=24, code size=35] \\n 267: JIT compiled Span`1:Slice(int,i\", \"nt):Span`1:this [Tier0, IL size=39, code size=135] \\n 268: JIT compiled Span`1:.ctor(byref,int):this \", \"[Tier0, IL size=15, code size=39] \\n 269: JIT compiled Span`1:op_Implicit(Span`1):ReadOnlySpan`1 [Tie\", \"r0, IL size=19, code \\nsize=90] \\n 270: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL s\", \"ize=15, code size=39] \\n 271: JIT compiled WindowsConsoleStream:Write(ReadOnlySpan`1):this [Tier0, IL\", \" size=35, code \\nsize=149] \\n 272: JIT compiled WindowsConsoleStream:WriteFileNative(long,ReadOnlySpan\", \"`1,bool):int \\n[Tier0, IL size=107, code size=272] \\n 273: JIT compiled ReadOnlySpan`1:get_IsEmpty():b\", \"ool:this [Tier0, IL size=10, code size=24] \\nHello, world! \\n 274: JIT compiled AppContext:OnProcessEx\", \"it() [Tier0, IL size=43, code size=161] \\n 275: JIT compiled AssemblyLoadContext:OnProcessExit() [Tie\", \"r0, IL size=101, code size=442] \\n 276: JIT compiled EventListener:DisposeOnShutdown() [Tier0, IL siz\", \"e=150, code size=618] \\n 277: JIT compiled List`1:.ctor():this [Tier0, IL size=18, code size=133] \\n 2\", \"78: JIT compiled List`1:.cctor() [Tier0, IL size=12, code size=129] \\n 279: JIT compiled List`1:GetEn\", \"umerator():Enumerator:this [Tier0, IL size=7, code size=162] \\n 280: JIT compiled Enumerator:.ctor(Li\", \"st`1):this [Tier0, IL size=39, code size=64] \\n 281: JIT compiled Enumerator:MoveNext():bool:this [Ti\", \"er0, IL size=81, code size=159] \\n \\n13 \\nCHAPTER 2 | JIT \\n \\n 282: JIT compiled Enumerator:get_Current(\", \"):__Canon:this [Tier0, IL size=7, code size=22] \\n 283: JIT compiled WeakReference`1:TryGetTarget(byr\", \"ef):bool:this [Tier0, IL size=24, code \\nsize=66] \\n 284: JIT compiled List`1:AddWithResize(__Canon):t\", \"his [Tier0, IL size=39, code size=85] \\n 285: JIT compiled List`1:Grow(int):this [Tier0, IL size=53, \", \"code size=121] \\n 286: JIT compiled List`1:set_Capacity(int):this [Tier0, IL size=86, code size=342] \", \"\\n 287: JIT compiled CastHelpers:StelemRef_Helper(byref,long,Object) [Tier0, IL size=34, code \\nsize=1\", \"04] \\n 288: JIT compiled CastHelpers:StelemRef_Helper_NoCacheLookup(byref,long,Object) [Tier0, IL \\nsi\", \"ze=26, code size=111] \\n 289: JIT compiled Enumerator:MoveNextRare():bool:this [Tier0, IL size=57, co\", \"de size=80] \\n 290: JIT compiled Enumerator:Dispose():this [Tier0, IL size=1, code size=14] \\n 291: JI\", \"T compiled EventSource:Dispose():this [Tier0, IL size=14, code size=54] \\n 292: JIT compiled EventSou\", \"rce:Dispose(bool):this [Tier0, IL size=124, code size=236] \\n 293: JIT compiled EventProvider:Dispose\", \"():this [Tier0, IL size=14, code size=54] \\n 294: JIT compiled EventProvider:Dispose(bool):this [Tier\", \"0, IL size=90, code size=230] \\n 295: JIT compiled EventProvider:EventUnregister(long):this [Tier0, I\", \"L size=14, code \\nsize=50] \\n 296: JIT compiled \\nEtwEventProvider:System.Diagnostics.Tracing.IEventPro\", \"vider.EventUnregister(long):int:this \\n[Tier0, IL size=7, code size=181] \\n 297: JIT compiled GC:Suppr\", \"essFinalize(Object) [Tier0, IL size=18, code size=53] \\n 298: JIT compiled \\nEventPipeEventProvider:Sy\", \"stem.Diagnostics.Tracing.IEventProvider.EventUnregister(long):int:\\nthis [Tier0, IL size=13, code siz\", \"e=187] \\nWith that out of the way, let\\u2019s move on to actual performance improvements, starting with on\", \"-stack \\nreplacement. \\nOn-Stack Replacement \\nOn-stack replacement (OSR) is one of the coolest feature\", \"s to hit the JIT in .NET 7. But to really \\nunderstand OSR, we first need to understand tiered compil\", \"ation, so a quick recap\\u2026 \\nOne of the issues a managed environment with a JIT compiler has to deal wi\", \"th is tradeoffs between \\nstartup and throughput. Historically, the job of an optimizing compiler is \", \"to, well, optimize, in order to \\nenable the best possible throughput of the application or service o\", \"nce running. But such optimization \\ntakes analysis, takes time, and performing all of that work then\", \" leads to increased startup time, as all \\nof the code on the startup path (e.g. all of the code that\", \" needs to be run before a web server can \\nserve the first request) needs to be compiled. So a JIT co\", \"mpiler needs to make tradeoffs: better \\nthroughput at the expense of longer startup time, or better \", \"startup time at the expense of decreased \\nthroughput. For some kinds of apps and services, the trade\", \"off is an easy call, e.g. if your service starts \\nup once and then runs for days, several extra seco\", \"nds of startup time doesn\\u2019t matter, or if you\\u2019re a \\nconsole application that\\u2019s going to do a quick c\", \"omputation and exit, startup time is all that matters. \\nBut how can the JIT know which scenario it\\u2019s\", \" in, and do we really want every developer having to \\nknow about these kinds of settings and tradeof\", \"fs and configure every one of their applications \\naccordingly? One answer to this has been ahead-of-\", \"time compilation, which has taken various forms \\nin .NET. For example, all of the core libraries are\", \" \\u201ccrossgen\\u201d\\u2019d, meaning they\\u2019ve been run through a \\ntool that produces the previously mentioned R2R f\", \"ormat, yielding binaries that contain assembly code \\nthat needs only minor tweaks to actually execut\", \"e; not every method can have code generated for it, \\nbut enough that it significantly reduces startu\", \"p time. Of course, such approaches have their own \\ndownsides, e.g. one of the promises of a JIT comp\", \"iler is it can take advantage of knowledge of the \\ncurrent machine / process in order to best optimi\", \"ze, so for example the R2R images have to assume a \\n \\n14 \\nCHAPTER 2 | JIT \\n \\ncertain baseline instru\", \"ction set (e.g. what vectorizing instructions are available) whereas the JIT can see \\nwhat\\u2019s actuall\", \"y available and use the best. \\u201cTiered compilation\\u201d provides another answer, one that\\u2019s \\nusable with \", \"or without these other ahead-of-time (AOT) compilation solutions. \\nTiered compilation enables the JI\", \"T to have its proverbial cake and eat it, too. The idea is simple: allow \\nthe JIT to compile the sam\", \"e code multiple times. The first time, the JIT can use as a few optimizations \\nas make sense (a hand\", \"ful of optimizations can actually make the JIT\\u2019s own throughput faster, so those \\nstill make sense t\", \"o apply), producing fairly unoptimized assembly code but doing so really quickly. \\nAnd when it does \", \"so, it can add some instrumentation into the assembly to track how often the \\nmethods are called. As\", \" it turns out, many functions used on a startup path are invoked once or maybe \\nonly a handful of ti\", \"mes, and it would take more time to optimize them than it does to just execute \\nthem unoptimized. Th\", \"en, when the method\\u2019s instrumentation triggers some threshold, for example a \\nmethod having been exe\", \"cuted 30 times, a work item gets queued to recompile that method, but this \\ntime with all the optimi\", \"zations the JIT can throw at it. This is lovingly referred to as \\u201ctiering up.\\u201d Once \\nthat recompilat\", \"ion has completed, call sites to the method are patched with the address of the newly \\nhighly optimi\", \"zed assembly code, and future invocations will then take the fast path. So, we get faster \\nstartup a\", \"nd faster sustained throughput. At least, that\\u2019s the hope. \\nA problem, however, is methods that don\\u2019\", \"t fit this mold. While it\\u2019s certainly the case that many \\nperformance-sensitive methods are relative\", \"ly quick and executed many, many, many times, there\\u2019s \\nalso a large number of performance-sensitive \", \"methods that are executed just a handful of times, or \\nmaybe even only once, but that take a very lo\", \"ng time to execute, maybe even the duration of the \\nwhole process: methods with loops. As a result, \", \"by default tiered compilation hasn\\u2019t applied to loops, \\nthough it can be enabled by setting the DOTN\", \"ET_TC_QuickJitForLoops environment variable to 1. We \\ncan see the effect of this by trying this simp\", \"le console app with .NET 6. With the default settings, run \\nthis app: \\nclass Program \\n{ \\n    static \", \"void Main() \\n    { \\n        var sw = new System.Diagnostics.Stopwatch(); \\n        while (true) \\n    \", \"    { \\n            sw.Restart(); \\n            for (int trial = 0; trial < 10_000; trial++) \\n        \", \"    { \\n                int count = 0; \\n                for (int i = 0; i < char.MaxValue; i++) \\n    \", \"                if (IsAsciiDigit((char)i)) \\n                        count++; \\n            } \\n       \", \"     sw.Stop(); \\n            Console.WriteLine(sw.Elapsed); \\n        } \\n \\n        static bool IsAsci\", \"iDigit(char c) => (uint)(c - '0') <= 9; \\n    } \\n} \\nI get numbers printed out like: \\n \\n15 \\nCHAPTER 2 \", \"| JIT \\n \\n00:00:00.5734352 \\n00:00:00.5526667 \\n00:00:00.5675267 \\n00:00:00.5588724 \\n00:00:00.5616028 \\nN\", \"ow, try setting DOTNET_TC_QuickJitForLoops to 1. When I then run it again, I get numbers like this: \", \"\\n00:00:01.2841397 \\n00:00:01.2693485 \\n00:00:01.2755646 \\n00:00:01.2656678 \\n00:00:01.2679925 \\nIn other \", \"words, with DOTNET_TC_QuickJitForLoops enabled, it\\u2019s taking 2.5x as long as without (the \\ndefault in\", \" .NET 6). That\\u2019s because this main function never gets optimizations applied to it. By setting \\nDOTN\", \"ET_TC_QuickJitForLoops to 1, we\\u2019re saying \\u201cJIT, please apply tiering to methods with loops as \\nwell,\", \"\\u201d but this method with a loop is only ever invoked once, so for the duration of the process it ends \", \"\\nup remaining at \\u201ctier-0,\\u201d aka unoptimized. Now, let\\u2019s try the same thing with .NET 7. Regardless of\", \" \\nwhether that environment variable is set, I again get numbers like this: \\n00:00:00.5528889 \\n00:00:\", \"00.5562563 \\n00:00:00.5622086 \\n00:00:00.5668220 \\n00:00:00.5589112 \\nbut importantly, this method was s\", \"till participating in tiering. In fact, we can get confirmation of that \\nby using the aforementioned\", \" DOTNET_JitDisasmSummary=1 environment variable. When I set that and \\nrun again, I see these lines i\", \"n the output: \\n   4: JIT compiled Program:Main() [Tier0, IL size=83, code size=319] \\n... \\n   6: JIT \", \"compiled Program:Main() [Tier1-OSR @0x27, IL size=83, code size=380] \\nhighlighting that Main was ind\", \"eed compiled twice. How is that possible? On-stack replacement. \\nThe idea behind on-stack replacemen\", \"t is a method can be replaced not just between invocations but \\neven while it\\u2019s executing, while it\\u2019\", \"s \\u201con the stack.\\u201d In addition to the tier-0 code being instrumented \\nfor call counts, loops are also\", \" instrumented for iteration counts. When the iterations surpass a certain \\nlimit, the JIT compiles a\", \" new highly optimized version of that method, transfers all the local/register \\nstate from the curre\", \"nt invocation to the new invocation, and then jumps to the appropriate location in \\nthe new method. \", \"We can see this in action by using the previously discussed DOTNET_JitDisasm \\nenvironment variable. \", \"Set that to Program:* in order to see the assembly code generated for all of the \\nmethods in the Pro\", \"gram class, and then run the app again. You should see output like the following: \\n; Assembly listin\", \"g for method Program:Main() \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compil\", \"ation \\n; MinOpts code \\n; rbp based frame \\n; partially interruptible \\n \\nG_M000_IG01:                ;\", \"; offset=0000H \\n       55                   push     rbp \\n \\n16 \\nCHAPTER 2 | JIT \\n \\n       4881EC8000\", \"0000       sub      rsp, 128 \\n       488DAC2480000000     lea      rbp, [rsp+80H] \\n       C5D857E4  \", \"           vxorps   xmm4, xmm4 \\n       C5F97F65B0           vmovdqa  xmmword ptr [rbp-50H], xmm4 \\n  \", \"     33C0                 xor      eax, eax \\n       488945C0             mov      qword ptr [rbp-40H\", \"], rax \\n \\nG_M000_IG02:                ;; offset=001FH \\n       48B9002F0B50FC7F0000 mov      rcx, 0x7\", \"FFC500B2F00 \\n       E8721FB25F           call     CORINFO_HELP_NEWSFAST \\n       488945B0            \", \" mov      gword ptr [rbp-50H], rax \\n       488B4DB0             mov      rcx, gword ptr [rbp-50H] \\n \", \"      FF1544C70D00         call     [Stopwatch:.ctor():this] \\n       488B4DB0             mov      r\", \"cx, gword ptr [rbp-50H] \\n       48894DC0             mov      gword ptr [rbp-40H], rcx \\n       C745A\", \"8E8030000       mov      dword ptr [rbp-58H], 0x3E8 \\n \\nG_M000_IG03:                ;; offset=004BH \\n\", \"       8B4DA8               mov      ecx, dword ptr [rbp-58H] \\n       FFC9                 dec      \", \"ecx \\n       894DA8               mov      dword ptr [rbp-58H], ecx \\n       837DA800             cmp \", \"     dword ptr [rbp-58H], 0 \\n       7F0E                 jg       SHORT G_M000_IG05 \\n \\nG_M000_IG04: \", \"               ;; offset=0059H \\n       488D4DA8             lea      rcx, [rbp-58H] \\n       BA060000\", \"00           mov      edx, 6 \\n       E8B985AB5F           call     CORINFO_HELP_PATCHPOINT \\n \\nG_M000\", \"_IG05:                ;; offset=0067H \\n       488B4DC0             mov      rcx, gword ptr [rbp-40H]\", \" \\n       3909                 cmp      dword ptr [rcx], ecx \\n       FF1585C70D00         call     [S\", \"topwatch:Restart():this] \\n       33C9                 xor      ecx, ecx \\n       894DBC              \", \" mov      dword ptr [rbp-44H], ecx \\n       33C9                 xor      ecx, ecx \\n       894DB8    \", \"           mov      dword ptr [rbp-48H], ecx \\n       EB20                 jmp      SHORT G_M000_IG08\", \" \\n \\nG_M000_IG06:                ;; offset=007FH \\n       8B4DB8               mov      ecx, dword ptr\", \" [rbp-48H] \\n       0FB7C9               movzx    rcx, cx \\n       FF152DD40B00         call     [Prog\", \"ram:<Main>g__IsAsciiDigit|0_0(ushort):bool] \\n       85C0                 test     eax, eax \\n       7\", \"408                 je       SHORT G_M000_IG07 \\n       8B4DBC               mov      ecx, dword ptr \", \"[rbp-44H] \\n       FFC1                 inc      ecx \\n       894DBC               mov      dword ptr \", \"[rbp-44H], ecx \\n \\nG_M000_IG07:                ;; offset=0097H \\n       8B4DB8               mov      \", \"ecx, dword ptr [rbp-48H] \\n       FFC1                 inc      ecx \\n       894DB8               mov \", \"     dword ptr [rbp-48H], ecx \\n \\nG_M000_IG08:                ;; offset=009FH \\n       8B4DA8         \", \"      mov      ecx, dword ptr [rbp-58H] \\n       FFC9                 dec      ecx \\n       894DA8    \", \"           mov      dword ptr [rbp-58H], ecx \\n       837DA800             cmp      dword ptr [rbp-58\", \"H], 0 \\n       7F0E                 jg       SHORT G_M000_IG10 \\n \\n \\n17 \\nCHAPTER 2 | JIT \\n \\nG_M000_IG0\", \"9:                ;; offset=00ADH \\n       488D4DA8             lea      rcx, [rbp-58H] \\n       BA230\", \"00000           mov      edx, 35 \\n       E86585AB5F           call     CORINFO_HELP_PATCHPOINT \\n \\nG_\", \"M000_IG10:                ;; offset=00BBH \\n       817DB800CA9A3B       cmp      dword ptr [rbp-48H],\", \" 0x3B9ACA00 \\n       7CBB                 jl       SHORT G_M000_IG06 \\n       488B4DC0             mov\", \"      rcx, gword ptr [rbp-40H] \\n       3909                 cmp      dword ptr [rcx], ecx \\n       FF\", \"1570C70D00         call     [Stopwatch:get_ElapsedMilliseconds():long:this] \\n       488BC8          \", \"     mov      rcx, rax \\n       FF1507D00D00         call     [Console:WriteLine(long)] \\n       E96DF\", \"FFFFF           jmp      G_M000_IG03 \\n \\n; Total bytes of code 222 \\n \\n; Assembly listing for method P\", \"rogram:<Main>g__IsAsciiDigit|0_0(ushort):bool \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Window\", \"s \\n; Tier-0 compilation \\n; MinOpts code \\n; rbp based frame \\n; partially interruptible \\n \\nG_M000_IG01\", \":                ;; offset=0000H \\n       55                   push     rbp \\n       488BEC           \", \"    mov      rbp, rsp \\n       894D10               mov      dword ptr [rbp+10H], ecx \\n \\nG_M000_IG02:\", \"                ;; offset=0007H \\n       8B4510               mov      eax, dword ptr [rbp+10H] \\n    \", \"   0FB7C0               movzx    rax, ax \\n       83C0D0               add      eax, -48 \\n       83F8\", \"09               cmp      eax, 9 \\n       0F96C0               setbe    al \\n       0FB6C0            \", \"   movzx    rax, al \\n \\nG_M000_IG03:                ;; offset=0019H \\n       5D                   pop \", \"     rbp \\n       C3                   ret \\nA few relevant things to notice here. First, the comments\", \" at the top highlight how this code was \\ncompiled: \\n; Tier-0 compilation \\n; MinOpts code \\nSo, we kno\", \"w this is the initial version (\\u201cTier-0\\u201d) of the method compiled with minimal optimization \\n(\\u201cMinOpts\", \"\\u201d). Second, note this line of the assembly: \\nFF152DD40B00         call     [Program:<Main>g__IsAscii\", \"Digit|0_0(ushort):bool] \\nOur IsAsciiDigit helper method is trivially inlineable, but it\\u2019s not gettin\", \"g inlined; instead, the \\nassembly has a call to it, and indeed we can see below the generated code (\", \"also \\u201cMinOpts\\u201d) for \\nIsAsciiDigit. Why? Because inlining is an optimization (a really important one)\", \" that\\u2019s disabled as \\npart of tier-0 (because the analysis for doing inlining well is also quite cost\", \"ly). Third, we can see the \\ncode the JIT is outputting to instrument this method. This is a bit more\", \" involved, but I\\u2019ll point out the \\nrelevant parts. First, we see: \\n \\n18 \\nCHAPTER 2 | JIT \\n \\nC745A8E8\", \"030000       mov      dword ptr [rbp-58H], 0x3E8 \\nThat 0x3E8 is the hex value for the decimal 1,000,\", \" which is the default number of iterations a loop \\nneeds to iterate before the JIT will generate the\", \" optimized version of the method (this is configurable \\nvia the DOTNET_TC_OnStackReplacement_Initial\", \"Counter environment variable). So we see 1,000 \\nbeing stored into this stack location. Then a bit la\", \"ter in the method we see this: \\nG_M000_IG03:                ;; offset=004BH \\n       8B4DA8          \", \"     mov      ecx, dword ptr [rbp-58H] \\n       FFC9                 dec      ecx \\n       894DA8     \", \"          mov      dword ptr [rbp-58H], ecx \\n       837DA800             cmp      dword ptr [rbp-58H\", \"], 0 \\n       7F0E                 jg       SHORT G_M000_IG05 \\n        \\nG_M000_IG04:                ;\", \"; offset=0059H \\n       488D4DA8             lea      rcx, [rbp-58H] \\n       BA06000000           mov\", \"      edx, 6 \\n       E8B985AB5F           call     CORINFO_HELP_PATCHPOINT \\n \\nG_M000_IG05:          \", \"      ;; offset=0067H \\nThe generated code is loading that counter into the ecx register, decrementin\", \"g it, storing it back, and \\nthen seeing whether the counter dropped to 0. If it didn\\u2019t, the code ski\", \"ps to G_M000_IG05, which is the \\nlabel for the actual code in the rest of the loop. But if the count\", \"er did drop to 0, the JIT proceeds to \\nstore relevant state into the the rcx and edx registers and t\", \"hen calls the CORINFO_HELP_PATCHPOINT \\nhelper method. That helper is responsible for triggering the \", \"creation of the optimized method if it \\ndoesn\\u2019t yet exist, fixing up all appropriate tracking state,\", \" and jumping to the new method. And indeed, \\nif you look again at your console output from running t\", \"he program, you\\u2019ll see yet another output for \\nthe Main method: \\n; Assembly listing for method Progr\", \"am:Main() \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation \\n; OSR varia\", \"nt for entry point 0x23 \\n; optimized code \\n; rsp based frame \\n; fully interruptible \\n; No PGO data \\n\", \"; 1 inlinees with PGO data; 8 single block inlinees; 0 inlinees without PGO data \\n \\nG_M000_IG01:    \", \"            ;; offset=0000H \\n       4883EC58             sub      rsp, 88 \\n       4889BC24D8000000  \", \"   mov      qword ptr [rsp+D8H], rdi \\n       4889B424D0000000     mov      qword ptr [rsp+D0H], rsi \", \"\\n       48899C24C8000000     mov      qword ptr [rsp+C8H], rbx \\n       C5F877               vzeroupp\", \"er \\n       33C0                 xor      eax, eax \\n       4889442428           mov      qword ptr [r\", \"sp+28H], rax \\n       4889442420           mov      qword ptr [rsp+20H], rax \\n       488B9C24A0000000\", \"     mov      rbx, gword ptr [rsp+A0H] \\n       8BBC249C000000       mov      edi, dword ptr [rsp+9CH\", \"] \\n       8BB42498000000       mov      esi, dword ptr [rsp+98H] \\n \\nG_M000_IG02:                ;; o\", \"ffset=0041H \\n       EB45                 jmp      SHORT G_M000_IG05 \\n                            ali\", \"gn    [0 bytes for IG06] \\n \\n19 \\nCHAPTER 2 | JIT \\n \\n \\nG_M000_IG03:                ;; offset=0043H \\n  \", \"     33C9                 xor      ecx, ecx \\n       488B9C24A0000000     mov      rbx, gword ptr [rs\", \"p+A0H] \\n       48894B08             mov      qword ptr [rbx+08H], rcx \\n       488D4C2428           l\", \"ea      rcx, [rsp+28H] \\n       48B87066E68AFD7F0000 mov      rax, 0x7FFD8AE66670 \\n \\nG_M000_IG04:    \", \"            ;; offset=0060H \\n       FFD0                 call     rax ; Kernel32:QueryPerformanceCou\", \"nter(long):int \\n       488B442428           mov      rax, qword ptr [rsp+28H] \\n       488B9C24A00000\", \"00     mov      rbx, gword ptr [rsp+A0H] \\n       48894310             mov      qword ptr [rbx+10H], \", \"rax \\n       C6431801             mov      byte  ptr [rbx+18H], 1 \\n       33FF                 xor   \", \"   edi, edi \\n       33F6                 xor      esi, esi \\n       833D92A1E55F00       cmp      dwo\", \"rd ptr [(reloc 0x7ffcafe1ae34)], 0 \\n       0F85CA000000         jne      G_M000_IG13 \\n \\nG_M000_IG05:\", \"                ;; offset=0088H \\n       81FE00CA9A3B         cmp      esi, 0x3B9ACA00 \\n       7D17  \", \"               jge      SHORT G_M000_IG09 \\n \\nG_M000_IG06:                ;; offset=0090H \\n       0FB\", \"7CE               movzx    rcx, si \\n       83C1D0               add      ecx, -48 \\n       83F909    \", \"           cmp      ecx, 9 \\n       7702                 ja       SHORT G_M000_IG08 \\n \\nG_M000_IG07:  \", \"              ;; offset=009BH \\n       FFC7                 inc      edi \\n \\nG_M000_IG08:             \", \"   ;; offset=009DH \\n       FFC6                 inc      esi \\n       81FE00CA9A3B         cmp      e\", \"si, 0x3B9ACA00 \\n       7CE9                 jl       SHORT G_M000_IG06 \\n \\nG_M000_IG09:              \", \"  ;; offset=00A7H \\n       488B6B08             mov      rbp, qword ptr [rbx+08H] \\n       48899C24A00\", \"00000     mov      gword ptr [rsp+A0H], rbx \\n       807B1800             cmp      byte  ptr [rbx+18H\", \"], 0 \\n       7436                 je       SHORT G_M000_IG12 \\n \\nG_M000_IG10:                ;; offse\", \"t=00B9H \\n       488D4C2420           lea      rcx, [rsp+20H] \\n       48B87066E68AFD7F0000 mov      r\", \"ax, 0x7FFD8AE66670 \\n \\nG_M000_IG11:                ;; offset=00C8H \\n       FFD0                 call \", \"    rax ; Kernel32:QueryPerformanceCounter(long):int \\n       488B4C2420           mov      rcx, qwor\", \"d ptr [rsp+20H] \\n       488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H] \\n       482B4B10     \", \"        sub      rcx, qword ptr [rbx+10H] \\n       4803E9               add      rbp, rcx \\n       833\", \"D2FA1E55F00       cmp      dword ptr [(reloc 0x7ffcafe1ae34)], 0 \\n       48899C24A0000000     mov   \", \"   gword ptr [rsp+A0H], rbx \\n       756D                 jne      SHORT G_M000_IG14 \\n \\nG_M000_IG12: \", \"               ;; offset=00EFH \\n       C5F857C0             vxorps   xmm0, xmm0 \\n       C4E1FB2AC5  \", \"         vcvtsi2sd  xmm0, rbp \\n       C5FB11442430         vmovsd   qword ptr [rsp+30H], xmm0 \\n \\n20 \", \"\\nCHAPTER 2 | JIT \\n \\n       48B9F04BF24FFC7F0000 mov      rcx, 0x7FFC4FF24BF0 \\n       BAE7070000     \", \"      mov      edx, 0x7E7 \\n       E82E1FB25F           call     CORINFO_HELP_GETSHARED_NONGCSTATIC_B\", \"ASE \\n       C5FB10442430         vmovsd   xmm0, qword ptr [rsp+30H] \\n       C5FB5905E049F6FF     vmu\", \"lsd   xmm0, xmm0, qword ptr [(reloc 0x7ffc4ff25720)] \\n       C4E1FB2CD0           vcvttsd2si  rdx, x\", \"mm0 \\n       48B94B598638D6C56D34 mov      rcx, 0x346DC5D63886594B \\n       488BC1               mov  \", \"    rax, rcx \\n       48F7EA               imul     rdx:rax, rdx \\n       488BCA               mov    \", \"  rcx, rdx \\n       48C1E93F             shr      rcx, 63 \\n       48C1FA0B             sar      rdx, \", \"11 \\n       4803CA               add      rcx, rdx \\n       FF1567CE0D00         call     [Console:Wri\", \"teLine(long)] \\n       E9F5FEFFFF           jmp      G_M000_IG03 \\n \\nG_M000_IG13:                ;; of\", \"fset=014EH \\n       E8DDCBAC5F           call     CORINFO_HELP_POLL_GC \\n       E930FFFFFF           j\", \"mp      G_M000_IG05 \\n \\nG_M000_IG14:                ;; offset=0158H \\n       E8D3CBAC5F           call\", \"     CORINFO_HELP_POLL_GC \\n       EB90                 jmp      SHORT G_M000_IG12 \\n \\n; Total bytes o\", \"f code 351 \\nHere, again, we notice a few interesting things. First, in the header we see this: \\n; Ti\", \"er-1 compilation \\n; OSR variant for entry point 0x23 \\n; optimized code \\nso we know this is both opti\", \"mized \\u201ctier-1\\u201d code and is the \\u201cOSR variant\\u201d for this method. Second, \\nnotice there\\u2019s no longer a ca\", \"ll to the IsAsciiDigit helper. Instead, where that call would have been, \\nwe see this: \\nG_M000_IG06:\", \"                ;; offset=0090H \\n       0FB7CE               movzx    rcx, si \\n       83C1D0        \", \"       add      ecx, -48 \\n       83F909               cmp      ecx, 9 \\n       7702                 j\", \"a       SHORT G_M000_IG08 \\nThis is loading a value into rcx, subtracting 48 from it (48 is the decim\", \"al ASCII value of the '0' \\ncharacter) and comparing the resulting value to 9. Sounds an awful lot li\", \"ke our IsAsciiDigit \\nimplementation ((uint)(c - '0') <= 9), doesn\\u2019t it? That\\u2019s because it is. The he\", \"lper was successfully \\ninlined in this now-optimized code. \\nGreat, so now in .NET 7, we can largely \", \"avoid the tradeoffs between startup and throughput, as OSR \\nenables tiered compilation to apply to a\", \"ll methods, even those that are long-running. A multitude of \\nPRs went into enabling this, including\", \" many over the last few years, but all of the functionality was \\ndisabled in the shipping bits. Than\", \"ks to improvements like dotnet/runtime#62831 which implemented \\nsupport for OSR on Arm64 (previously\", \" only x64 support was implemented), and \\ndotnet/runtime#63406 and dotnet/runtime#65609 which revised\", \" how OSR imports and epilogs are \\nhandled, dotnet/runtime#65675 enables OSR (and as a result DOTNET_\", \"TC_QuickJitForLoops) by \\ndefault. \\n \\n21 \\nCHAPTER 2 | JIT \\n \\nBut, tiered compilation and OSR aren\\u2019t j\", \"ust about startup (though they\\u2019re of course very valuable \\nthere). They\\u2019re also about further improv\", \"ing throughput. Even though tiered compilation was \\noriginally envisioned as a way to optimize start\", \"up while not hurting throughput, it\\u2019s become much \\nmore than that. There are various things the JIT \", \"can learn about a method during tier-0 that it can \\nthen use for tier-1. For example, the very fact \", \"that the tier-0 code executed means that any statics \\naccessed by the method will have been initiali\", \"zed, and that means that any readonly statics will not \\nonly have been initialized by the time the t\", \"ier-1 code executes but their values won\\u2019t ever change. And \\nthat in turn means that any readonly st\", \"atics of primitive types (e.g. bool, int, etc.) can be treated like \\nconsts instead of static readon\", \"ly fields, and during tier-1 compilation the JIT can optimize them \\njust as it would have optimized \", \"a const. For example, try running this simple program after setting \\nDOTNET_JitDisasm to Program:Tes\", \"t: \\nusing System.Runtime.CompilerServices; \\n \\nclass Program \\n{ \\n    static readonly bool Is64Bit = E\", \"nvironment.Is64BitProcess; \\n \\n    static int Main() \\n    { \\n        int count = 0; \\n        for (int\", \" i = 0; i < 1_000_000_000; i++) \\n            if (Test()) \\n                count++; \\n        return c\", \"ount; \\n    } \\n \\n    [MethodImpl(MethodImplOptions.NoInlining)] \\n    static bool Test() => Is64Bit; \\n\", \"} \\nWhen I do so, I get this output: \\n; Assembly listing for method Program:Test():bool \\n; Emitting B\", \"LENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compilation \\n; MinOpts code \\n; rbp based frame \", \"\\n; partially interruptible \\n \\nG_M000_IG01:                ;; offset=0000H \\n       55                \", \"   push     rbp \\n       4883EC20             sub      rsp, 32 \\n       488D6C2420           lea      \", \"rbp, [rsp+20H] \\n \\nG_M000_IG02:                ;; offset=000AH \\n       48B9B8639A3FFC7F0000 mov      \", \"rcx, 0x7FFC3F9A63B8 \\n       BA01000000           mov      edx, 1 \\n       E8C220B25F           call  \", \"   CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE \\n       0FB60545580C00       movzx    rax, byte  ptr [(re\", \"loc 0x7ffc3f9a63ea)] \\n \\nG_M000_IG03:                ;; offset=0025H \\n       4883C420             add\", \"      rsp, 32 \\n       5D                   pop      rbp \\n       C3                   ret \\n \\n; Total \", \"bytes of code 43 \\n \\n22 \\nCHAPTER 2 | JIT \\n \\n \\n; Assembly listing for method Program:Test():bool \\n; Em\", \"itting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation \\n; optimized code \\n; rsp ba\", \"sed frame \\n; partially interruptible \\n; No PGO data \\n \\nG_M000_IG01:                ;; offset=0000H \\n\", \" \\nG_M000_IG02:                ;; offset=0000H \\n       B801000000           mov      eax, 1 \\n \\nG_M000\", \"_IG03:                ;; offset=0005H \\n       C3                   ret \\n \\n; Total bytes of code 6 \\nN\", \"ote, again, we see two outputs for Program:Test. First, we see the \\u201cTier-0\\u201d code, which is accessing\", \" a \\nstatic (note the call     CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE instruction). But then we see \", \"\\nthe \\u201cTier-1\\u201d code, where all of that overhead has vanished and is instead replaced simply by mov ea\", \"x, \\n1. Since the \\u201cTier-0\\u201d code had to have executed in order for it to tier up, the \\u201cTier-1\\u201d code wa\", \"s \\ngenerated knowing that the value of the static readonly bool Is64Bit field was true (1), and so \\n\", \"the entirety of this method is storing the value 1 into the eax register used for the return value. \", \"\\nThis is so useful that components are now written with tiering in mind. Consider the new Regex sour\", \"ce \\ngenerator, which is discussed later in this post (Roslyn source generators were introduced a cou\", \"ple of \\nyears ago; just as how Roslyn analyzers are able to plug into the compiler and surface addit\", \"ional \\ndiagnostics based on all of the data the compiler learns from the source code, Roslyn source \", \"\\ngenerators are able to analyze that same data and then further augment the compilation unit with \\na\", \"dditional source). The Regex source generator applies a technique based on this in \\ndotnet/runtime#6\", \"7775. Regex supports setting a process-wide timeout that gets applied to Regex \\ninstances that don\\u2019t\", \" explicitly set a timeout. That means, even though it\\u2019s super rare for such a \\nprocess-wide timeout \", \"to be set, the Regex source generator still needs to output timeout-related code \\njust in case it\\u2019s \", \"needed. It does so by outputting some helpers like this: \\nstatic class Utilities \\n{ \\n    internal st\", \"atic readonly TimeSpan s_defaultTimeout = \\nAppContext.GetData(\\\"REGEX_DEFAULT_MATCH_TIMEOUT\\\") is Time\", \"Span timeout ? timeout : \\nTimeout.InfiniteTimeSpan; \\n    internal static readonly bool s_hasTimeout \", \"= s_defaultTimeout != \\nTimeout.InfiniteTimeSpan; \\n} \\nwhich it then uses at call sites like this: \\nif\", \" (Utilities.s_hasTimeout) \\n{ \\n    base.CheckTimeout(); \\n} \\nIn tier-0, these checks will still be emi\", \"tted in the assembly code, but in tier-1 where throughput \\nmatters, if the relevant AppContext switc\", \"h hasn\\u2019t been set, then s_defaultTimeout will be \\n \\n23 \\nCHAPTER 2 | JIT \\n \\nTimeout.InfiniteTimeSpan,\", \" at which point s_hasTimeout will be false. And since s_hasTimeout is a \\nstatic readonly bool, the J\", \"IT will be able to treat that as a const, and all conditions like if \\n(Utilities.s_hasTimeout) will \", \"be treated equal to if (false) and be eliminated from the \\nassembly code entirely as dead code. \\nBut\", \", this is somewhat old news. The JIT has been able to do such an optimization since tiered \\ncompilat\", \"ion was introduced in .NET Core 3.0. Now in .NET 7, though, with OSR it\\u2019s also able to do so \\nby def\", \"ault for methods with loops (and thus enable cases like the regex one). However, the real magic \\nof \", \"OSR comes into play when combined with another exciting feature: dynamic PGO. \\nPGO \\nI wrote about pr\", \"ofile-guided optimization (PGO) in my Performance Improvements in .NET 6 post, but \\nI\\u2019ll cover it ag\", \"ain here as it\\u2019s seen a multitude of improvements for .NET 7. \\nPGO has been around for a long time, \", \"in any number of languages and compilers. The basic idea is \\nyou compile your app, asking the compil\", \"er to inject instrumentation into the application to track \\nvarious pieces of interesting informatio\", \"n. You then put your app through its paces, running through \\nvarious common scenarios, causing that \", \"instrumentation to \\u201cprofile\\u201d what happens when the app is \\nexecuted, and the results of that are the\", \"n saved out. The app is then recompiled, feeding those \\ninstrumentation results back into the compil\", \"er, and allowing it to optimize the app for exactly how it\\u2019s \\nexpected to be used. This approach to \", \"PGO is referred to as \\u201cstatic PGO,\\u201d as the information is all \\ngleaned ahead of actual deployment, a\", \"nd it\\u2019s something .NET has been doing in various forms for \\nyears. From my perspective, though, the \", \"really interesting development in .NET is \\u201cdynamic PGO,\\u201d \\nwhich was introduced in .NET 6, but off by\", \" default. \\nDynamic PGO takes advantage of tiered compilation. I noted that the JIT instruments the t\", \"ier-0 code \\nto track how many times the method is called, or in the case of loops, how many times th\", \"e loop \\nexecutes. It can instrument it for other things as well. For example, it can track exactly w\", \"hich concrete \\ntypes are used as the target of an interface dispatch, and then in tier-1 specialize \", \"the code to expect \\nthe most common types (this is referred to as \\u201cguarded devirtualization,\\u201d or GDV\", \"). You can see this in \\nthis little example. Set the DOTNET_TieredPGO environment variable to 1, and\", \" then run this on .NET 7: \\nclass Program \\n{ \\n    static void Main() \\n    { \\n        IPrinter printer\", \" = new Printer(); \\n        for (int i = 0; ; i++) \\n        { \\n            DoWork(printer, i); \\n     \", \"   } \\n    } \\n \\n    static void DoWork(IPrinter printer, int i) \\n    { \\n        printer.PrintIfTrue(i\", \" == int.MaxValue); \\n    } \\n \\n    interface IPrinter \\n    { \\n        void PrintIfTrue(bool condition)\", \"; \\n \\n24 \\nCHAPTER 2 | JIT \\n \\n    } \\n \\n    class Printer : IPrinter \\n    { \\n        public void PrintI\", \"fTrue(bool condition) \\n        { \\n            if (condition) Console.WriteLine(\\\"Print!\\\"); \\n        }\", \" \\n    } \\n} \\nThe tier-0 code for DoWork ends up looking like this: \\nG_M000_IG01:                ;; of\", \"fset=0000H \\n       55                   push     rbp \\n       4883EC30             sub      rsp, 48 \\n\", \"       488D6C2430           lea      rbp, [rsp+30H] \\n       33C0                 xor      eax, eax \\n\", \"       488945F8             mov      qword ptr [rbp-08H], rax \\n       488945F0             mov      \", \"qword ptr [rbp-10H], rax \\n       48894D10             mov      gword ptr [rbp+10H], rcx \\n       8955\", \"18               mov      dword ptr [rbp+18H], edx \\n \\nG_M000_IG02:                ;; offset=001BH \\n \", \"      FF059F220F00         inc      dword ptr [(reloc 0x7ffc3f1b2ea0)] \\n       488B4D10             \", \"mov      rcx, gword ptr [rbp+10H] \\n       48894DF8             mov      gword ptr [rbp-08H], rcx \\n  \", \"     488B4DF8             mov      rcx, gword ptr [rbp-08H] \\n       48BAA82E1B3FFC7F0000 mov      rd\", \"x, 0x7FFC3F1B2EA8 \\n       E8B47EC55F           call     CORINFO_HELP_CLASSPROFILE32 \\n       488B4DF8\", \"             mov      rcx, gword ptr [rbp-08H] \\n       48894DF0             mov      gword ptr [rbp-\", \"10H], rcx \\n       488B4DF0             mov      rcx, gword ptr [rbp-10H] \\n       33D2               \", \"  xor      edx, edx \\n       817D18FFFFFF7F       cmp      dword ptr [rbp+18H], 0x7FFFFFFF \\n       0F\", \"94C2               sete     dl \\n       49BB0800F13EFC7F0000 mov      r11, 0x7FFC3EF10008 \\n       41F\", \"F13               call     [r11]IPrinter:PrintIfTrue(bool):this \\n       90                   nop \\n \\n\", \"G_M000_IG03:                ;; offset=0062H \\n       4883C430             add      rsp, 48 \\n       5D\", \"                   pop      rbp \\n       C3                   ret \\nand most notably, you can see the \", \"call [r11]IPrinter:PrintIfTrue(bool):this doing the \\ninterface dispatch. But, then look at the code \", \"generated for tier-1. We still see the call \\n[r11]IPrinter:PrintIfTrue(bool):this, but we also see t\", \"his: \\nG_M000_IG02:                ;; offset=0020H \\n       48B9982D1B3FFC7F0000 mov      rcx, 0x7FFC3\", \"F1B2D98 \\n       48390F               cmp      qword ptr [rdi], rcx \\n       7521                 jne \", \"     SHORT G_M000_IG05 \\n       81FEFFFFFF7F         cmp      esi, 0x7FFFFFFF \\n       7404           \", \"      je       SHORT G_M000_IG04 \\n \\nG_M000_IG03:                ;; offset=0037H \\n       FFC6        \", \"         inc      esi \\n       EBE5                 jmp      SHORT G_M000_IG02 \\n \\n \\n25 \\nCHAPTER 2 | J\", \"IT \\n \\nG_M000_IG04:                ;; offset=003BH \\n       48B9D820801A24020000 mov      rcx, 0x2241A\", \"8020D8 \\n       488B09               mov      rcx, gword ptr [rcx] \\n       FF1572CD0D00         call \", \"    [Console:WriteLine(String)] \\n       EBE7                 jmp      SHORT G_M000_IG03 \\nThat first \", \"block is checking the concrete type of the IPrinter (stored in rdi) and comparing it against \\nthe kn\", \"own type for Printer (0x7FFC3F1B2D98). If they\\u2019re different, it just jumps to the same interface \\ndi\", \"spatch it was doing in the unoptimized version. But if they\\u2019re the same, it then jumps directly to a\", \"n \\ninlined version of Printer.PrintIfTrue (you can see the call to Console:WriteLine right there in \", \"\\nthis method). Thus, the common case (the only case in this example) is super efficient at the expen\", \"se \\nof a single comparison and branch. \\nThat all existed in .NET 6, so why are we talking about it n\", \"ow? Several things have improved. First, \\nPGO now works with OSR, thanks to improvements like dotnet\", \"/runtime#61453. That\\u2019s a big deal, as it \\nmeans hot long-running methods that do this kind of interf\", \"ace dispatch (which are fairly common) \\ncan get these kinds of devirtualization/inlining optimizatio\", \"ns. Second, while PGO isn\\u2019t currently \\nenabled by default, we\\u2019ve made it much easier to turn on. Bet\", \"ween dotnet/runtime#71438 and \\ndotnet/sdk#26350, it\\u2019s now possible to simply put <TieredPGO>true</Ti\", \"eredPGO> into your .csproj, \\nand it\\u2019ll have the same effect as if you set DOTNET_TieredPGO=1 prior t\", \"o every invocation of the app, \\nenabling dynamic PGO (note that it doesn\\u2019t disable use of R2R images\", \", so if you want the entirety of \\nthe core libraries also employing dynamic PGO, you\\u2019ll also need to\", \" set DOTNET_ReadyToRun=0). Third, \\nhowever, is dynamic PGO has been taught how to instrument and opt\", \"imize additional things. \\nPGO already knew how to instrument virtual dispatch. Now in .NET 7, thanks\", \" in large part to \\ndotnet/runtime#68703, it can do so for delegates as well (at least for delegates \", \"to instance methods). \\nConsider this simple console app: \\nusing System.Runtime.CompilerServices; \\n \\n\", \"class Program \\n{ \\n    static int[] s_values = Enumerable.Range(0, 1_000).ToArray(); \\n \\n    static vo\", \"id Main() \\n    { \\n        for (int i = 0; i < 1_000_000; i++) \\n            Sum(s_values, i => i * 42\", \"); \\n    } \\n \\n    [MethodImpl(MethodImplOptions.NoInlining)] \\n    static int Sum(int[] values, Func<i\", \"nt, int> func) \\n    { \\n        int sum = 0; \\n        foreach (int value in values) \\n            sum \", \"+= func(value); \\n        return sum; \\n    } \\n} \\nWithout PGO enabled, I get generated optimized assem\", \"bly like this: \\n; Assembly listing for method Program:Sum(ref,Func`2):int \\n; Emitting BLENDED_CODE f\", \"or X64 CPU with AVX - Windows \\n; Tier-1 compilation \\n \\n26 \\nCHAPTER 2 | JIT \\n \\n; optimized code \\n; rs\", \"p based frame \\n; partially interruptible \\n; No PGO data \\n \\nG_M000_IG01:                ;; offset=000\", \"0H \\n       4156                 push     r14 \\n       57                   push     rdi \\n       56   \", \"                push     rsi \\n       55                   push     rbp \\n       53                   \", \"push     rbx \\n       4883EC20             sub      rsp, 32 \\n       488BF2               mov      rsi\", \", rdx \\n \\nG_M000_IG02:                ;; offset=000DH \\n       33FF                 xor      edi, edi \", \"\\n       488BD9               mov      rbx, rcx \\n       33ED                 xor      ebp, ebp \\n     \", \"  448B7308             mov      r14d, dword ptr [rbx+08H] \\n       4585F6               test     r14d\", \", r14d \\n       7E16                 jle      SHORT G_M000_IG04 \\n \\nG_M000_IG03:                ;; off\", \"set=001DH \\n       8BD5                 mov      edx, ebp \\n       8B549310             mov      edx, \", \"dword ptr [rbx+4*rdx+10H] \\n       488B4E08             mov      rcx, gword ptr [rsi+08H] \\n       FF5\", \"618               call     [rsi+18H]Func`2:Invoke(int):int:this \\n       03F8                 add    \", \"  edi, eax \\n       FFC5                 inc      ebp \\n       443BF5               cmp      r14d, ebp\", \" \\n       7FEA                 jg       SHORT G_M000_IG03 \\n \\nG_M000_IG04:                ;; offset=00\", \"33H \\n       8BC7                 mov      eax, edi \\n \\nG_M000_IG05:                ;; offset=0035H \\n \", \"      4883C420             add      rsp, 32 \\n       5B                   pop      rbx \\n       5D    \", \"               pop      rbp \\n       5E                   pop      rsi \\n       5F                   p\", \"op      rdi \\n       415E                 pop      r14 \\n       C3                   ret \\n \\n; Total by\", \"tes of code 64 \\nNote the call [rsi+18H]Func'2:Invoke(int):int:this in there that\\u2019s invoking the dele\", \"gate. Now \\nwith PGO enabled: \\n; Assembly listing for method Program:Sum(ref,Func`2):int \\n; Emitting \", \"BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation \\n; optimized code \\n; optimized usi\", \"ng profile data \\n; rsp based frame \\n; fully interruptible \\n; with Dynamic PGO: edge weights are vali\", \"d, and fgCalledCount is 5628 \\n; 0 inlinees with PGO data; 1 single block inlinees; 0 inlinees withou\", \"t PGO data \\n \\nG_M000_IG01:                ;; offset=0000H \\n \\n27 \\nCHAPTER 2 | JIT \\n \\n       4157     \", \"            push     r15 \\n       4156                 push     r14 \\n       57                   push\", \"     rdi \\n       56                   push     rsi \\n       55                   push     rbp \\n      \", \" 53                   push     rbx \\n       4883EC28             sub      rsp, 40 \\n       488BF2     \", \"          mov      rsi, rdx \\n \\nG_M000_IG02:                ;; offset=000FH \\n       33FF             \", \"    xor      edi, edi \\n       488BD9               mov      rbx, rcx \\n       33ED                 xo\", \"r      ebp, ebp \\n       448B7308             mov      r14d, dword ptr [rbx+08H] \\n       4585F6      \", \"         test     r14d, r14d \\n       7E27                 jle      SHORT G_M000_IG05 \\n \\nG_M000_IG03:\", \"                ;; offset=001FH \\n       8BC5                 mov      eax, ebp \\n       8B548310     \", \"        mov      edx, dword ptr [rbx+4*rax+10H] \\n       4C8B4618             mov      r8, qword ptr \", \"[rsi+18H] \\n       48B8A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A0 \\n       4C3BC0               cmp\", \"      r8, rax \\n       751D                 jne      SHORT G_M000_IG07 \\n       446BFA2A             i\", \"mul     r15d, edx, 42 \\n \\nG_M000_IG04:                ;; offset=003CH \\n       4103FF               ad\", \"d      edi, r15d \\n       FFC5                 inc      ebp \\n       443BF5               cmp      r14\", \"d, ebp \\n       7FD9                 jg       SHORT G_M000_IG03 \\n \\nG_M000_IG05:                ;; off\", \"set=0046H \\n       8BC7                 mov      eax, edi \\n \\nG_M000_IG06:                ;; offset=00\", \"48H \\n       4883C428             add      rsp, 40 \\n       5B                   pop      rbx \\n       \", \"5D                   pop      rbp \\n       5E                   pop      rsi \\n       5F              \", \"     pop      rdi \\n       415E                 pop      r14 \\n       415F                 pop      r1\", \"5 \\n       C3                   ret \\n \\nG_M000_IG07:                ;; offset=0055H \\n       488B4E08  \", \"           mov      rcx, gword ptr [rsi+08H] \\n       41FFD0               call     r8 \\n       448BF8\", \"               mov      r15d, eax \\n       EBDB                 jmp      SHORT G_M000_IG04 \\nI chose t\", \"he 42 constant in i => i * 42 to make it easy to see in the assembly, and sure enough, there \\nit is:\", \" \\nG_M000_IG03:                ;; offset=001FH \\n       8BC5                 mov      eax, ebp \\n      \", \" 8B548310             mov      edx, dword ptr [rbx+4*rax+10H] \\n       4C8B4618             mov      \", \"r8, qword ptr [rsi+18H] \\n       48B8A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A0 \\n       4C3BC0    \", \"           cmp      r8, rax \\n \\n28 \\nCHAPTER 2 | JIT \\n \\n       751D                 jne      SHORT G_M\", \"000_IG07 \\n       446BFA2A             imul     r15d, edx, 42 \\nThis is loading the target address fro\", \"m the delegate into r8 and is loading the address of the \\nexpected target into rax. If they\\u2019re the s\", \"ame, it then simply performs the inlined operation (imul \\nr15d, edx, 42), and otherwise it jumps to \", \"G_M000_IG07 which calls to the function in r8. The effect \\nof this is obvious if we run this as a be\", \"nchmark: \\nstatic int[] s_values = Enumerable.Range(0, 1_000).ToArray(); \\n \\n[Benchmark] \\npublic int D\", \"elegatePGO() => Sum(s_values, i => i * 42); \\n \\nstatic int Sum(int[] values, Func<int, int>? func) \\n{\", \" \\n    int sum = 0; \\n    foreach (int value in values) \\n    { \\n        sum += func(value); \\n    } \\n  \", \"  return sum; \\n} \\nWith PGO disabled, we get the same performance throughput for .NET 6 and .NET 7: \\n\", \"Method \\nRuntime \\nMean \\nRatio \\nDelegatePGO \\n.NET 6.0 \\n1.665 us \\n1.00 \\nDelegatePGO \\n.NET 7.0 \\n1.659 us\", \" \\n1.00 \\nBut the picture changes when we enable dynamic PGO (DOTNET_TieredPGO=1). .NET 6 gets ~14% \\nf\", \"aster, but .NET 7 gets ~3x faster! \\nMethod \\nRuntime \\nMean \\nRatio \\nDelegatePGO \\n.NET 6.0 \\n1,427.7 ns \", \"\\n1.00 \\nDelegatePGO \\n.NET 7.0 \\n539.0 ns \\n0.38 \\ndotnet/runtime#70377 is another valuable improvement w\", \"ith dynamic PGO, which enables PGO to \\nplay nicely with loop cloning and invariant hoisting. To unde\", \"rstand this better, a brief digression into \\nwhat those are. Loop cloning is a mechanism the JIT emp\", \"loys to avoid various overheads in the fast \\npath of a loop. Consider the Test method in this exampl\", \"e: \\nusing System.Runtime.CompilerServices; \\n \\nclass Program \\n{ \\n    static void Main() \\n    { \\n     \", \"   int[] array = new int[10_000_000]; \\n        for (int i = 0; i < 1_000_000; i++) \\n        { \\n     \", \"       Test(array); \\n        } \\n    } \\n \\n \\n29 \\nCHAPTER 2 | JIT \\n \\n    [MethodImpl(MethodImplOptions.\", \"NoInlining)] \\n    private static bool Test(int[] array) \\n    { \\n        for (int i = 0; i < 0x12345;\", \" i++) \\n        { \\n            if (array[i] == 42) \\n            { \\n                return true; \\n    \", \"        } \\n        } \\n \\n        return false; \\n    } \\n} \\nThe JIT doesn\\u2019t know whether the passed in \", \"array is of sufficient length that all accesses to array[i] \\ninside the loop will be in bounds, and \", \"thus it would need to inject bounds checks for every access. \\nWhile it\\u2019d be nice to simply do the le\", \"ngth check up front and simply throw an exception early if it \\nwasn\\u2019t long enough, doing so could al\", \"so change behavior (imagine the method were writing into the \\narray as it went, or otherwise mutatin\", \"g some shared state). Instead, the JIT employs \\u201cloop cloning.\\u201d It \\nessentially rewrites this Test me\", \"thod to be more like this: \\nif (array is not null && array.Length >= 0x12345) \\n{ \\n    for (int i = 0\", \"; i < 0x12345; i++) \\n    { \\n        if (array[i] == 42) // no bounds checks emitted for this access \", \":-) \\n        { \\n            return true; \\n        } \\n    } \\n} \\nelse \\n{ \\n    for (int i = 0; i < 0x12\", \"345; i++) \\n    { \\n        if (array[i] == 42) // bounds checks emitted for this access :-( \\n        \", \"{ \\n            return true; \\n        } \\n    } \\n} \\nreturn false; \\nThat way, at the expense of some co\", \"de duplication, we get our fast loop without bounds checks and \\nonly pay for the bounds checks in th\", \"e slow path. You can see this in the generated assembly (if you \\ncan\\u2019t already tell, DOTNET_JitDisas\", \"m is one of my favorite features in .NET 7): \\n; Assembly listing for method Program:Test(ref):bool \\n\", \"; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation \\n; optimized code \\n; rs\", \"p based frame \\n; fully interruptible \\n; No PGO data \\n \\nG_M000_IG01:                ;; offset=0000H \\n\", \"       4883EC28             sub      rsp, 40 \\n \\n30 \\nCHAPTER 2 | JIT \\n \\n \\nG_M000_IG02:               \", \" ;; offset=0004H \\n       33C0                 xor      eax, eax \\n       4885C9               test   \", \"  rcx, rcx \\n       7429                 je       SHORT G_M000_IG05 \\n       81790845230100       cmp \", \"     dword ptr [rcx+08H], 0x12345 \\n       7C20                 jl       SHORT G_M000_IG05 \\n       0F\", \"1F40000F1F840000000000 align    [12 bytes for IG03] \\n \\nG_M000_IG03:                ;; offset=0020H \\n\", \"       8BD0                 mov      edx, eax \\n       837C91102A           cmp      dword ptr [rcx+4\", \"*rdx+10H], 42 \\n       7429                 je       SHORT G_M000_IG08 \\n       FFC0                 i\", \"nc      eax \\n       3D45230100           cmp      eax, 0x12345 \\n       7CEE                 jl      \", \" SHORT G_M000_IG03 \\n \\nG_M000_IG04:                ;; offset=0032H \\n       EB17                 jmp  \", \"    SHORT G_M000_IG06 \\n \\nG_M000_IG05:                ;; offset=0034H \\n       3B4108               cm\", \"p      eax, dword ptr [rcx+08H] \\n       7323                 jae      SHORT G_M000_IG10 \\n       8BD0\", \"                 mov      edx, eax \\n       837C91102A           cmp      dword ptr [rcx+4*rdx+10H], \", \"42 \\n       7410                 je       SHORT G_M000_IG08 \\n       FFC0                 inc      eax\", \" \\n       3D45230100           cmp      eax, 0x12345 \\n       7CE9                 jl       SHORT G_M0\", \"00_IG05 \\n \\nG_M000_IG06:                ;; offset=004BH \\n       33C0                 xor      eax, ea\", \"x \\n \\nG_M000_IG07:                ;; offset=004DH \\n       4883C428             add      rsp, 40 \\n    \", \"   C3                   ret \\n \\nG_M000_IG08:                ;; offset=0052H \\n       B801000000       \", \"    mov      eax, 1 \\n \\nG_M000_IG09:                ;; offset=0057H \\n       4883C428             add \", \"     rsp, 40 \\n       C3                   ret \\n \\nG_M000_IG10:                ;; offset=005CH \\n      \", \" E81FA0C15F           call     CORINFO_HELP_RNGCHKFAIL \\n       CC                   int3 \\n \\n; Total \", \"bytes of code 98 \\nThat G_M000_IG02 section is doing the null check and the length check, jumping to \", \"the G_M000_IG05 \\nblock if either fails. If both succeed, it\\u2019s then executing the loop (block G_M000_\", \"IG03) without bounds \\nchecks: \\nG_M000_IG03:                ;; offset=0020H \\n       8BD0             \", \"    mov      edx, eax \\n       837C91102A           cmp      dword ptr [rcx+4*rdx+10H], 42 \\n       74\", \"29                 je       SHORT G_M000_IG08 \\n       FFC0                 inc      eax \\n \\n31 \\nCHAPT\", \"ER 2 | JIT \\n \\n       3D45230100           cmp      eax, 0x12345 \\n       7CEE                 jl     \", \"  SHORT G_M000_IG03 \\nwith the bounds checks only showing up in the slow-path block: \\nG_M000_IG05:   \", \"             ;; offset=0034H \\n       3B4108               cmp      eax, dword ptr [rcx+08H] \\n       \", \"7323                 jae      SHORT G_M000_IG10 \\n       8BD0                 mov      edx, eax \\n    \", \"   837C91102A           cmp      dword ptr [rcx+4*rdx+10H], 42 \\n       7410                 je      \", \" SHORT G_M000_IG08 \\n       FFC0                 inc      eax \\n       3D45230100           cmp      e\", \"ax, 0x12345 \\n       7CE9                 jl       SHORT G_M000_IG05 \\nThat\\u2019s \\u201cloop cloning.\\u201d What abo\", \"ut \\u201cinvariant hoisting\\u201d? Hoisting means pulling something out of a \\nloop to be before the loop, and \", \"invariants are things that don\\u2019t change. Thus invariant hoisting is \\npulling something out of a loop\", \" to before the loop in order to avoid recomputing every iteration of \\nthe loop an answer that won\\u2019t \", \"change. Effectively, the previous example already showed invariant \\nhoisting, in that the bounds che\", \"ck is moved to be before the loop rather than in the loop, but a more \\nconcrete example would be som\", \"ething like this: \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate static bool Test(int[] array)\", \" \\n{ \\n    for (int i = 0; i < 0x12345; i++) \\n    { \\n        if (array[i] == array.Length - 42) \\n     \", \"   { \\n            return true; \\n        } \\n    } \\n \\n    return false; \\n} \\nNote that the value of arr\", \"ay.Length - 42 doesn\\u2019t change on each iteration of the loop, so it\\u2019s \\n\\u201cinvariant\\u201d to the loop iterat\", \"ion and can be lifted out, which the generated code does: \\nG_M000_IG02:                ;; offset=000\", \"4H \\n       33D2                 xor      edx, edx \\n       4885C9               test     rcx, rcx \\n  \", \"     742A                 je       SHORT G_M000_IG05 \\n       448B4108             mov      r8d, dwor\", \"d ptr [rcx+08H] \\n       4181F845230100       cmp      r8d, 0x12345 \\n       7C1D                 jl  \", \"     SHORT G_M000_IG05 \\n       4183C0D6             add      r8d, -42 \\n       0F1F4000             a\", \"lign    [4 bytes for IG03] \\n \\nG_M000_IG03:                ;; offset=0020H \\n       8BC2              \", \"   mov      eax, edx \\n       4439448110           cmp      dword ptr [rcx+4*rax+10H], r8d \\n       74\", \"33                 je       SHORT G_M000_IG08 \\n       FFC2                 inc      edx \\n       81FA\", \"45230100         cmp      edx, 0x12345 \\n       7CED                 jl       SHORT G_M000_IG03 \\n \\n32\", \" \\nCHAPTER 2 | JIT \\n \\nHere again we see the array being tested for null (test rcx, rcx) and the array\", \"\\u2019s length being \\nchecked (mov r8d, dword ptr [rcx+08H], cmp r8d, 0x12345), but then with the array\\u2019s\", \" length in \\nr8d, we then see this up-front block subtracting 42 from the length (add r8d, -42), and \", \"that\\u2019s before \\nwe continue into the fast-path loop in the G_M000_IG03 block. This keeps that additio\", \"nal set of \\noperations out of the loop, thereby avoiding the overhead of recomputing the value per i\", \"teration. \\nOk, so how does this apply to dynamic PGO? Remember that with the interface/virtual dispa\", \"tch \\navoidance PGO is able to do, it does so by doing a type check to see whether the type in use is\", \" the \\nmost common type; if it is, it uses a fast path that calls directly to that type\\u2019s method (and\", \" in doing so \\nthat call is then potentially inlined), and if it isn\\u2019t, it falls back to normal inter\", \"face/virtual dispatch. That \\ncheck can be invariant to a loop. So when a method is tiered up and PGO\", \" kicks in, the type check can \\nnow be hoisted out of the loop, making it even cheaper to handle the \", \"common case. Consider this \\nvariation of our original example: \\nusing System.Runtime.CompilerService\", \"s; \\n \\nclass Program \\n{ \\n    static void Main() \\n    { \\n        IPrinter printer = new BlankPrinter()\", \"; \\n        while (true) \\n        { \\n            DoWork(printer); \\n        } \\n    } \\n \\n    [MethodImp\", \"l(MethodImplOptions.NoInlining)] \\n    static void DoWork(IPrinter printer) \\n    { \\n        for (int \", \"j = 0; j < 123; j++) \\n        { \\n            printer.Print(j); \\n        } \\n    } \\n \\n    interface IP\", \"rinter \\n    { \\n        void Print(int i); \\n    } \\n \\n    class BlankPrinter : IPrinter \\n    { \\n      \", \"  public void Print(int i) \\n        { \\n            Console.Write(\\\"\\\"); \\n        } \\n    } \\n} \\nWhen we \", \"look at the optimized assembly generated for this with dynamic PGO enabled, we see this: \\n; Assembly\", \" listing for method Program:DoWork(IPrinter) \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\", \" \\n; Tier-1 compilation \\n; optimized code \\n; optimized using profile data \\n \\n33 \\nCHAPTER 2 | JIT \\n \\n;\", \" rsp based frame \\n; partially interruptible \\n; with Dynamic PGO: edge weights are invalid, and fgCal\", \"ledCount is 12187 \\n; 0 inlinees with PGO data; 1 single block inlinees; 0 inlinees without PGO data \", \"\\n \\nG_M000_IG01:                ;; offset=0000H \\n       57                   push     rdi \\n       56 \", \"                  push     rsi \\n       4883EC28             sub      rsp, 40 \\n       488BF1         \", \"      mov      rsi, rcx \\n \\nG_M000_IG02:                ;; offset=0009H \\n       33FF                 \", \"xor      edi, edi \\n       4885F6               test     rsi, rsi \\n       742B                 je    \", \"   SHORT G_M000_IG05 \\n       48B9982DD43CFC7F0000 mov      rcx, 0x7FFC3CD42D98 \\n       48390E       \", \"        cmp      qword ptr [rsi], rcx \\n       751C                 jne      SHORT G_M000_IG05 \\n \\nG_M\", \"000_IG03:                ;; offset=001FH \\n       48B9282040F948020000 mov      rcx, 0x248F9402028 \\n \", \"      488B09               mov      rcx, gword ptr [rcx] \\n       FF1526A80D00         call     [Cons\", \"ole:Write(String)] \\n       FFC7                 inc      edi \\n       83FF7B               cmp      e\", \"di, 123 \\n       7CE6                 jl       SHORT G_M000_IG03 \\n \\nG_M000_IG04:                ;; of\", \"fset=0039H \\n       EB29                 jmp      SHORT G_M000_IG07 \\n \\nG_M000_IG05:                ;;\", \" offset=003BH \\n       48B9982DD43CFC7F0000 mov      rcx, 0x7FFC3CD42D98 \\n       48390E              \", \" cmp      qword ptr [rsi], rcx \\n       7521                 jne      SHORT G_M000_IG08 \\n       48B92\", \"82040F948020000 mov      rcx, 0x248F9402028 \\n       488B09               mov      rcx, gword ptr [rc\", \"x] \\n       FF15FBA70D00         call     [Console:Write(String)] \\n \\nG_M000_IG06:                ;; o\", \"ffset=005DH \\n       FFC7                 inc      edi \\n       83FF7B               cmp      edi, 123\", \" \\n       7CD7                 jl       SHORT G_M000_IG05 \\n \\nG_M000_IG07:                ;; offset=00\", \"64H \\n       4883C428             add      rsp, 40 \\n       5E                   pop      rsi \\n       \", \"5F                   pop      rdi \\n       C3                   ret \\n \\nG_M000_IG08:                ;;\", \" offset=006BH \\n       488BCE               mov      rcx, rsi \\n       8BD7                 mov      e\", \"dx, edi \\n       49BB1000AA3CFC7F0000 mov      r11, 0x7FFC3CAA0010 \\n       41FF13               call \", \"    [r11]IPrinter:Print(int):this \\n       EBDE                 jmp      SHORT G_M000_IG06 \\n \\n; Total\", \" bytes of code 127 \\nWe can see in the G_M000_IG02 block that it\\u2019s doing the type check on the IPrint\", \"er instance and \\njumping to G_M000_IG05 if the check fails (mov rcx, 0x7FFC3CD42D98, cmp qword ptr [\", \"rsi], rcx, \\n \\n34 \\nCHAPTER 2 | JIT \\n \\njne SHORT G_M000_IG05), otherwise falling through to G_M000_IG0\", \"3 which is a tight fast-path loop \\nthat\\u2019s inlined BlankPrinter.Print with no type checks in sight! \\n\", \"Interestingly, improvements like this can bring with them their own challenges. PGO leads to a \\nsign\", \"ificant increase in the number of type checks, since call sites that specialize for a given type nee\", \"d \\nto compare against that type. However, common subexpression elimination (CSE) hasn\\u2019t historically\", \" \\nworked for such type handles (CSE is a compiler optimization where duplicate expressions are \\nelim\", \"inated by computing the result once and then storing it for subsequent use rather than \\nrecomputing \", \"it each time). dotnet/runtime#70580 fixes this by enabling CSE for such constant \\nhandles. For examp\", \"le, consider this method: \\n[Benchmark] \\n[Arguments(\\\"\\\", \\\"\\\", \\\"\\\", \\\"\\\")] \\npublic bool AllAreStrings(objec\", \"t o1, object o2, object o3, object o4) => \\n    o1 is string && o2 is string && o3 is string && o4 is\", \" string; \\nOn .NET 6, the JIT produced this assembly code: \\n; Program.AllAreStrings(System.Object, Sy\", \"stem.Object, System.Object, System.Object) \\n       test      rdx,rdx \\n       je        short M00_L01\", \" \\n       mov       rax,offset MT_System.String \\n       cmp       [rdx],rax \\n       jne       short M\", \"00_L01 \\n       test      r8,r8 \\n       je        short M00_L01 \\n       mov       rax,offset MT_Syste\", \"m.String \\n       cmp       [r8],rax \\n       jne       short M00_L01 \\n       test      r9,r9 \\n       \", \"je        short M00_L01 \\n       mov       rax,offset MT_System.String \\n       cmp       [r9],rax \\n  \", \"     jne       short M00_L01 \\n       mov       rax,[rsp+28] \\n       test      rax,rax \\n       je    \", \"    short M00_L00 \\n       mov       rdx,offset MT_System.String \\n       cmp       [rax],rdx \\n       \", \"je        short M00_L00 \\n       xor       eax,eax \\nM00_L00: \\n       test      rax,rax \\n       setne \", \"    al \\n       movzx     eax,al \\n       ret \\nM00_L01: \\n       xor       eax,eax \\n       ret \\n; Total\", \" bytes of code 100 \\nNote the C# has four tests for string and the assembly code has four loads with \", \"mov rax,offset \\nMT_System.String. Now on .NET 7, the load is performed just once: \\n; Program.AllAreS\", \"trings(System.Object, System.Object, System.Object, System.Object) \\n       test      rdx,rdx \\n      \", \" je        short M00_L01 \\n \\n35 \\nCHAPTER 2 | JIT \\n \\n       mov       rax,offset MT_System.String \\n   \", \"    cmp       [rdx],rax \\n       jne       short M00_L01 \\n       test      r8,r8 \\n       je        sh\", \"ort M00_L01 \\n       cmp       [r8],rax \\n       jne       short M00_L01 \\n       test      r9,r9 \\n    \", \"   je        short M00_L01 \\n       cmp       [r9],rax \\n       jne       short M00_L01 \\n       mov   \", \"    rdx,[rsp+28] \\n       test      rdx,rdx \\n       je        short M00_L00 \\n       cmp       [rdx],r\", \"ax \\n       je        short M00_L00 \\n       xor       edx,edx \\nM00_L00: \\n       xor       eax,eax \\n  \", \"     test      rdx,rdx \\n       setne     al \\n       ret \\nM00_L01: \\n       xor       eax,eax \\n       \", \"ret \\n; Total bytes of code 69 \\nBounds Check Elimination \\nOne of the things that makes .NET attractiv\", \"e is its safety. The runtime guards access to arrays, strings, \\nand spans such that you can\\u2019t accide\", \"ntally corrupt memory by walking off either end; if you do, rather \\nthan reading/writing arbitrary m\", \"emory, you\\u2019ll get exceptions. Of course, that\\u2019s not magic; it\\u2019s done by \\nthe JIT inserting bounds ch\", \"ecks every time one of these data structures is indexed. For example, this: \\n[MethodImpl(MethodImplO\", \"ptions.NoInlining)] \\nstatic int Read0thElement(int[] array) => array[0]; \\nresults in: \\nG_M000_IG01: \", \"               ;; offset=0000H \\n       4883EC28             sub      rsp, 40 \\n \\nG_M000_IG02:        \", \"        ;; offset=0004H \\n       83790800             cmp      dword ptr [rcx+08H], 0 \\n       7608   \", \"              jbe      SHORT G_M000_IG04 \\n       8B4110               mov      eax, dword ptr [rcx+1\", \"0H] \\n \\nG_M000_IG03:                ;; offset=000DH \\n       4883C428             add      rsp, 40 \\n  \", \"     C3                   ret \\n \\nG_M000_IG04:                ;; offset=0012H \\n       E8E9A0C25F     \", \"      call     CORINFO_HELP_RNGCHKFAIL \\n       CC                   int3 \\nThe array is passed into t\", \"his method in the rcx register, pointing to the method table pointer in the \\nobject, and the length \", \"of an array is stored in the object just after that method table pointer (which is \\n8 bytes in a 64-\", \"bit process). Thus the cmp dword ptr [rcx+08H], 0 instruction is reading the length \\n \\n36 \\nCHAPTER 2\", \" | JIT \\n \\nof the array and comparing the length to 0; that makes sense, since the length can\\u2019t be ne\", \"gative, and \\nwe\\u2019re trying to access the 0th element, so as long as the length isn\\u2019t 0, the array has\", \" enough elements \\nfor us to access its 0th element. In the event that the length was 0, the code jum\", \"ps to the end of the \\nfunction, which contains call CORINFO_HELP_RNGCHKFAIL; that\\u2019s a JIT helper fun\", \"ction that throws an \\nIndexOutOfRangeException. If the length was sufficient, however, it then reads\", \" the int stored at the \\nbeginning of the array\\u2019s data, which on 64-bit is 16 bytes (0x10) past the p\", \"ointer (mov eax, dword \\nptr [rcx+10H]). \\nWhile these bounds checks in and of themselves aren\\u2019t super\", \" expensive, do a lot of them and their \\ncosts add up. So while the JIT needs to ensure that \\u201csafe\\u201d a\", \"ccesses don\\u2019t go out of bounds, it also tries \\nto prove that certain accesses won\\u2019t, in which case i\", \"t needn\\u2019t emit the bounds check that it knows will \\nbe superfluous. In every release of .NET, more a\", \"nd more cases have been added to find places these \\nbounds checks can be eliminated, and .NET 7 is n\", \"o exception. \\nFor example, dotnet/runtime#61662 from [@anthonycanino](https://github.com/anthonycani\", \"no) \\nenabled the JIT to understand various forms of binary operations as part of range checks. Consi\", \"der \\nthis method: \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate static ushort[]? Convert(Read\", \"OnlySpan<byte> bytes) \\n{ \\n    if (bytes.Length != 16) \\n    { \\n        return null; \\n    } \\n \\n    var\", \" result = new ushort[8]; \\n    for (int i = 0; i < result.Length; i++) \\n    { \\n        result[i] = (u\", \"short)(bytes[i * 2] * 256 + bytes[i * 2 + 1]); \\n    } \\n \\n    return result; \\n} \\nIt\\u2019s validating that\", \" the input span is 16 bytes long and then creating a new ushort[8] where each \\nushort in the array c\", \"ombines two of the input bytes. To do that, it\\u2019s looping over the output array, \\nand indexing into t\", \"he bytes array using i * 2 and i * 2 + 1 as the indices. On .NET 6, each of those \\nindexing operatio\", \"ns would result in a bounds check, with assembly like: \\ncmp       r8d,10     \\njae       short G_M000\", \"_IG04  \\nmovsxd    r8,r8d \\nwhere that G_M000_IG04 is the call CORINFO_HELP_RNGCHKFAIL we\\u2019re now famil\", \"iar with. But on .NET \\n7, we get this assembly for the method: \\nG_M000_IG01:                ;; offse\", \"t=0000H \\n       56                   push     rsi \\n       4883EC20             sub      rsp, 32 \\n \\nG\", \"_M000_IG02:                ;; offset=0005H \\n       488B31               mov      rsi, bword ptr [rcx\", \"] \\n       8B4908               mov      ecx, dword ptr [rcx+08H] \\n \\n37 \\nCHAPTER 2 | JIT \\n \\n       83\", \"F910               cmp      ecx, 16 \\n       754C                 jne      SHORT G_M000_IG05 \\n       \", \"48B9302F542FFC7F0000 mov      rcx, 0x7FFC2F542F30 \\n       BA08000000           mov      edx, 8 \\n    \", \"   E80C1EB05F           call     CORINFO_HELP_NEWARR_1_VC \\n       33D2                 xor      edx,\", \" edx \\n                            align    [0 bytes for IG03] \\n \\nG_M000_IG03:                ;; offs\", \"et=0026H \\n       8D0C12               lea      ecx, [rdx+rdx] \\n       448BC1               mov      \", \"r8d, ecx \\n       FFC1                 inc      ecx \\n       458BC0               mov      r8d, r8d \\n \", \"      460FB60406           movzx    r8, byte  ptr [rsi+r8] \\n       41C1E008             shl      r8d\", \", 8 \\n       8BC9                 mov      ecx, ecx \\n       0FB60C0E             movzx    rcx, byte  \", \"ptr [rsi+rcx] \\n       4103C8               add      ecx, r8d \\n       0FB7C9               movzx    r\", \"cx, cx \\n       448BC2               mov      r8d, edx \\n       6642894C4010         mov      word  pt\", \"r [rax+2*r8+10H], cx \\n       FFC2                 inc      edx \\n       83FA08               cmp     \", \" edx, 8 \\n       7CD0                 jl       SHORT G_M000_IG03 \\n \\nG_M000_IG04:                ;; of\", \"fset=0056H \\n       4883C420             add      rsp, 32 \\n       5E                   pop      rsi \\n\", \"       C3                   ret \\n \\nG_M000_IG05:                ;; offset=005CH \\n       33C0         \", \"        xor      rax, rax \\n \\nG_M000_IG06:                ;; offset=005EH \\n       4883C420           \", \"  add      rsp, 32 \\n       5E                   pop      rsi \\n       C3                   ret \\n \\n; T\", \"otal bytes of code 100 \\nNo bounds checks, which is most easily seen by the lack of the telltale call\", \" \\nCORINFO_HELP_RNGCHKFAIL at the end of the method. With this PR, the JIT is able to understand the \", \"\\nimpact of certain multiplication and shift operations and their relationships to the bounds of the \", \"data \\nstructure. Since it can see that the result array\\u2019s length is 8 and the loop is iterating from\", \" 0 to that \\nexclusive upper bound, it knows that i will always be in the range [0, 7], which means t\", \"hat i * 2 will \\nalways be in the range [0, 14] and i * 2 + 1 will always be in the range [0, 15]. As\", \" such, it\\u2019s able \\nto prove that the bounds checks aren\\u2019t needed. \\ndotnet/runtime#61569 and dotnet/ru\", \"ntime#62864 also help to eliminate bounds checks when dealing \\nwith constant strings and spans initi\", \"alized from RVA statics (\\u201cRelative Virtual Address\\u201d static fields, \\nbasically a static field that li\", \"ves in a module\\u2019s data section). For example, consider this benchmark: \\n[Benchmark] \\n[Arguments(1)] \", \"\\npublic char GetChar(int i) \\n{ \\n    const string Text = \\\"hello\\\"; \\n \\n38 \\nCHAPTER 2 | JIT \\n \\n    retur\", \"n (uint)i < Text.Length ? Text[i] : '\\\\0'; \\n} \\nOn .NET 6, we get this assembly: \\n; Program.GetChar(In\", \"t32) \\n       sub       rsp,28 \\n       mov       eax,edx \\n       cmp       rax,5 \\n       jl        sh\", \"ort M00_L00 \\n       xor       eax,eax \\n       add       rsp,28 \\n       ret \\nM00_L00: \\n       cmp    \", \"   edx,5 \\n       jae       short M00_L01 \\n       mov       rax,2278B331450 \\n       mov       rax,[ra\", \"x] \\n       movsxd    rdx,edx \\n       movzx     eax,word ptr [rax+rdx*2+0C] \\n       add       rsp,28 \", \"\\n       ret \\nM00_L01: \\n       call      CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes o\", \"f code 56 \\nThe beginning of this makes sense: the JIT was obviously able to see that the length of T\", \"ext is 5, so \\nit\\u2019s implementing the (uint)i < Text.Length check by doing cmp rax,5, and if i as an u\", \"nsigned \\nvalue is greater than or equal to 5, it\\u2019s then zero\\u2019ing out the return value (to return the\", \" '\\\\0') and \\nexiting. If the length is less than 5 (in which case it\\u2019s also at least 0 due to the uns\", \"igned comparison), it \\nthen jumps to M00_L00 to read the value from the string\\u2026 but we then see anot\", \"her cmp against 5, this \\ntime as part of a range check. So even though the JIT knew the index was in\", \" bounds, it wasn\\u2019t able to \\nremove the bounds check. Now it is; in .NET 7, we get this: \\n; Program.G\", \"etChar(Int32) \\n       cmp       edx,5 \\n       jb        short M00_L00 \\n       xor       eax,eax \\n   \", \"    ret \\nM00_L00: \\n       mov       rax,2B0AF002530 \\n       mov       rax,[rax] \\n       mov       ed\", \"x,edx \\n       movzx     eax,word ptr [rax+rdx*2+0C] \\n       ret \\n; Total bytes of code 29 \\nSo much n\", \"icer. \\ndotnet/runtime#67141 is a great example of how evolving ecosystem needs drives specific \\nopti\", \"mizations into the JIT. The Regex compiler and source generator handle some cases of regular \\nexpres\", \"sion character classes by using a bitmap lookup stored in strings. For example, to determine \\nwhethe\", \"r a char c is in the character class \\\"[A-Za-z0-9_]\\\" (which will match an underscore or any \\nASCII le\", \"tter or digit), the implementation ends up generating an expression like the body of the \\nfollowing \", \"method: \\n \\n39 \\nCHAPTER 2 | JIT \\n \\n[Benchmark] \\n[Arguments('a')] \\npublic bool IsInSet(char c) => \\n   \", \" c < 128 && (\\\"\\\\0\\\\0\\\\0\\\\u03FF\\\\uFFFE\\\\u87FF\\\\uFFFE\\\\u07FF\\\"[c >> 4] & (1 << (c & 0xF))) != 0; \\nThe implement\", \"ation is treating an 8-character string as a 128-bit lookup table. If the character is \\nknown to be \", \"in range (such that it\\u2019s effectively a 7-bit value), it\\u2019s then using the top 3 bits of the value \\nto\", \" index into the 8 elements of the string, and the bottom 4 bits to select one of the 16 bits in that\", \" \\nelement, giving us an answer as to whether this input character is in the set or not. In .NET 6, e\", \"ven \\nthough we know the character is in range of the string, the JIT couldn\\u2019t see through either the\", \" length \\ncomparison or the bit shift. \\n; Program.IsInSet(Char) \\n       sub       rsp,28 \\n       movz\", \"x     eax,dx \\n       cmp       eax,80 \\n       jge       short M00_L00 \\n       mov       edx,eax \\n   \", \"    sar       edx,4 \\n       cmp       edx,8 \\n       jae       short M00_L01 \\n       mov       rcx,29\", \"9835A1518 \\n       mov       rcx,[rcx] \\n       movsxd    rdx,edx \\n       movzx     edx,word ptr [rcx+\", \"rdx*2+0C] \\n       and       eax,0F \\n       bt        edx,eax \\n       setb      al \\n       movzx     \", \"eax,al \\n       add       rsp,28 \\n       ret \\nM00_L00: \\n       xor       eax,eax \\n       add       rs\", \"p,28 \\n       ret \\nM00_L01: \\n       call      CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total by\", \"tes of code 75 \\nThe previously mentioned PR takes care of the length check. And this PR takes care o\", \"f the bit shift. So \\nin .NET 7, we get this loveliness: \\n; Program.IsInSet(Char) \\n       movzx     e\", \"ax,dx \\n       cmp       eax,80 \\n       jge       short M00_L00 \\n       mov       edx,eax \\n       sar\", \"       edx,4 \\n       mov       rcx,197D4800608 \\n       mov       rcx,[rcx] \\n       mov       edx,edx\", \" \\n       movzx     edx,word ptr [rcx+rdx*2+0C] \\n       and       eax,0F \\n       bt        edx,eax \\n \", \"      setb      al \\n       movzx     eax,al \\n       ret \\n \\n40 \\nCHAPTER 2 | JIT \\n \\nM00_L00: \\n       x\", \"or       eax,eax \\n       ret \\n; Total bytes of code 51 \\nNote the distinct lack of a call CORINFO_HEL\", \"P_RNGCHKFAIL. And as you might guess, this check can \\nhappen a lot in a Regex, making this a very us\", \"eful addition. \\nBounds checks are an obvious source of overhead when talking about array access, but\", \" they\\u2019re not the \\nonly ones. There\\u2019s also the need to use the cheapest instructions possible. In .NE\", \"T 6, with a method \\nlike: \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate static int Get(int[] \", \"values, int i) => values[i]; \\nassembly code like the following would be generated: \\n; Program.Get(In\", \"t32[], Int32) \\n       sub       rsp,28 \\n       cmp       edx,[rcx+8] \\n       jae       short M01_L00\", \" \\n       movsxd    rax,edx \\n       mov       eax,[rcx+rax*4+10] \\n       add       rsp,28 \\n       ret\", \" \\nM01_L00: \\n       call      CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes of code 27 \\n\", \"This should look fairly familiar from our previous discussion; the JIT is loading the array\\u2019s length\", \" \\n([rcx+8]) and comparing that with the value of i (in edx), and then jumping to the end to throw an\", \" \\nexception if i is out of bounds. Immediately after that jump we see a movsxd rax, edx instruction,\", \" \\nwhich is taking the 32-bit value of i from edx and moving it into the 64-bit register rax. And as \", \"part \\nof moving it, it\\u2019s sign-extending it; that\\u2019s the \\u201csxd\\u201d part of the instruction name (sign-exte\", \"nding means \\nthe upper 32 bits of the new 64-bit value will be set to the value of the upper bit of \", \"the 32-bit value, \\nso that the number retains its signed value). The interesting thing is, though, w\", \"e know that the Length \\nof an array and of a span is non-negative, and since we just bounds checked \", \"i against the Length, we \\nalso know that i is non-negative. That makes such sign-extension useless, \", \"since the upper bit is \\nguaranteed to be 0. Since the mov instruction that zero-extends is a tad che\", \"aper than movsxd, we can \\nsimply use that instead. And that\\u2019s exactly what dotnet/runtime#57970 from\", \" \\n[@pentp](https://github.com/pentp) does for both arrays and spans (dotnet/runtime#70884 also \\nsimi\", \"larly avoids some signed casts in other situations). Now on .NET 7, we get this: \\n; Program.Get(Int3\", \"2[], Int32) \\n       sub       rsp,28 \\n       cmp       edx,[rcx+8] \\n       jae       short M01_L00 \\n\", \"       mov       eax,edx \\n       mov       eax,[rcx+rax*4+10] \\n       add       rsp,28 \\n       ret \\n\", \"M01_L00: \\n       call      CORINFO_HELP_RNGCHKFAIL \\n \\n41 \\nCHAPTER 2 | JIT \\n \\n       int       3 \\n; T\", \"otal bytes of code 26 \\nThat\\u2019s not the only source of overhead with array access, though. In fact, th\", \"ere\\u2019s a very large category \\nof array access overhead that\\u2019s been there forever, but that\\u2019s so well \", \"known there are even old FxCop \\nrules and newer Roslyn analyzers that warn against it: multidimensio\", \"nal array accesses. The overhead \\nin the case of a multidimensional array isn\\u2019t just an extra branch\", \" on every indexing operation, or \\nadditional math required to compute the location of the element, b\", \"ut rather that they currently pass \\nthrough the JIT\\u2019s optimization phases largely unmodified. dotnet\", \"/runtime#70271 improves the state \\nof the world here by doing an expansion of a multidimensional arr\", \"ay access early in the JIT\\u2019s pipeline, \\nsuch that later optimization phases can improve multidimensi\", \"onal accesses as they would other code, \\nincluding CSE and loop invariant hoisting. The impact of th\", \"is is visible in a simple benchmark that \\nsums all the elements of a multidimensional array. \\nprivat\", \"e int[,] _square; \\n \\n[Params(1000)] \\npublic int Size { get; set; } \\n \\n[GlobalSetup] \\npublic void Set\", \"up() \\n{ \\n    int count = 0; \\n    _square = new int[Size, Size]; \\n    for (int i = 0; i < Size; i++) \", \"\\n    { \\n        for (int j = 0; j < Size; j++) \\n        { \\n            _square[i, j] = count++; \\n   \", \"     } \\n    } \\n} \\n \\n[Benchmark] \\npublic int Sum() \\n{ \\n    int[,] square = _square; \\n    int sum = 0;\", \" \\n    for (int i = 0; i < Size; i++) \\n    { \\n        for (int j = 0; j < Size; j++) \\n        { \\n    \", \"        sum += square[i, j]; \\n        } \\n    } \\n    return sum; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nSu\", \"m \\n.NET 6.0 \\n964.1 us \\n1.00 \\nSum \\n.NET 7.0 \\n674.7 us \\n0.70 \\nThis previous example assumes you know t\", \"he size of each dimension of the multidimensional array \\n(it\\u2019s referring to the Size directly in the\", \" loops). That\\u2019s obviously not always (or maybe even rarely) the \\ncase. In such situations, you\\u2019d be \", \"more likely to use the Array.GetUpperBound method, and because \\n \\n42 \\nCHAPTER 2 | JIT \\n \\nmultidimens\", \"ional arrays can have a non-zero lower bound, Array.GetLowerBound. That would lead to \\ncode like thi\", \"s: \\nprivate int[,] _square; \\n \\n[Params(1000)] \\npublic int Size { get; set; } \\n \\n[GlobalSetup] \\npubli\", \"c void Setup() \\n{ \\n    int count = 0; \\n    _square = new int[Size, Size]; \\n    for (int i = 0; i < S\", \"ize; i++) \\n    { \\n        for (int j = 0; j < Size; j++) \\n        { \\n            _square[i, j] = cou\", \"nt++; \\n        } \\n    } \\n} \\n \\n[Benchmark] \\npublic int Sum() \\n{ \\n    int[,] square = _square; \\n    in\", \"t sum = 0; \\n    for (int i = square.GetLowerBound(0); i < square.GetUpperBound(0); i++) \\n    { \\n    \", \"    for (int j = square.GetLowerBound(1); j < square.GetUpperBound(1); j++) \\n        { \\n            \", \"sum += square[i, j]; \\n        } \\n    } \\n    return sum; \\n} \\nIn .NET 7, thanks to dotnet/runtime#6081\", \"6, those GetLowerBound and GetUpperBound calls become \\nJIT intrinsics. An \\u201cintrinsic\\u201d to a compiler \", \"is something the compiler has intrinsic knowledge of, such \\nthat rather than relying solely on a met\", \"hod\\u2019s defined implementation (if it even has one), the compiler \\ncan substitute in something it cons\", \"iders to be better. There are literally thousands of methods in .NET \\nknown in this manner to the JI\", \"T, with GetLowerBound and GetUpperBound being two of the most \\nrecent. Now as intrinsics, when they\\u2019\", \"re passed a constant value (e.g. 0 for the 0th rank), the JIT can \\nsubstitute the necessary assembly\", \" instructions to read directly from the memory location that houses \\nthe bounds. Here\\u2019s what the ass\", \"embly code for this benchmark looked like with .NET 6; the main thing \\nto see here are all of the ca\", \"lls out to GetLowerBound and GetUpperBound: \\n; Program.Sum() \\n       push      rdi \\n       push     \", \" rsi \\n       push      rbp \\n       push      rbx \\n       sub       rsp,28 \\n       mov       rsi,[rcx\", \"+8] \\n       xor       edi,edi \\n       mov       rcx,rsi \\n       xor       edx,edx \\n \\n43 \\nCHAPTER 2 |\", \" JIT \\n \\n       cmp       [rcx],ecx \\n       call      System.Array.GetLowerBound(Int32) \\n       mov  \", \"     ebx,eax \\n       mov       rcx,rsi \\n       xor       edx,edx \\n       call      System.Array.GetU\", \"pperBound(Int32) \\n       cmp       eax,ebx \\n       jle       short M00_L03 \\nM00_L00: \\n       mov    \", \"   rcx,[rsi] \\n       mov       ecx,[rcx+4] \\n       add       ecx,0FFFFFFE8 \\n       shr       ecx,3 \\n\", \"       cmp       ecx,1 \\n       jbe       short M00_L05 \\n       lea       rdx,[rsi+10] \\n       inc   \", \"    ecx \\n       movsxd    rcx,ecx \\n       mov       ebp,[rdx+rcx*4] \\n       mov       rcx,rsi \\n     \", \"  mov       edx,1 \\n       call      System.Array.GetUpperBound(Int32) \\n       cmp       eax,ebp \\n   \", \"    jle       short M00_L02 \\nM00_L01: \\n       mov       ecx,ebx \\n       sub       ecx,[rsi+18] \\n    \", \"   cmp       ecx,[rsi+10] \\n       jae       short M00_L04 \\n       mov       edx,ebp \\n       sub     \", \"  edx,[rsi+1C] \\n       cmp       edx,[rsi+14] \\n       jae       short M00_L04 \\n       mov       eax,\", \"[rsi+14] \\n       imul      rax,rcx \\n       mov       rcx,rdx \\n       add       rcx,rax \\n       add  \", \"     edi,[rsi+rcx*4+20] \\n       inc       ebp \\n       mov       rcx,rsi \\n       mov       edx,1 \\n   \", \"    call      System.Array.GetUpperBound(Int32) \\n       cmp       eax,ebp \\n       jg        short M0\", \"0_L01 \\nM00_L02: \\n       inc       ebx \\n       mov       rcx,rsi \\n       xor       edx,edx \\n       ca\", \"ll      System.Array.GetUpperBound(Int32) \\n       cmp       eax,ebx \\n       jg        short M00_L00 \", \"\\nM00_L03: \\n       mov       eax,edi \\n       add       rsp,28 \\n       pop       rbx \\n       pop      \", \" rbp \\n       pop       rsi \\n       pop       rdi \\n       ret \\nM00_L04: \\n       call      CORINFO_HEL\", \"P_RNGCHKFAIL \\n \\n44 \\nCHAPTER 2 | JIT \\n \\nM00_L05: \\n       mov       rcx,offset MT_System.IndexOutOfRan\", \"geException \\n       call      CORINFO_HELP_NEWSFAST \\n       mov       rsi,rax \\n       call      Syst\", \"em.SR.get_IndexOutOfRange_ArrayRankIndex() \\n       mov       rdx,rax \\n       mov       rcx,rsi \\n    \", \"   call      System.IndexOutOfRangeException..ctor(System.String) \\n       mov       rcx,rsi \\n       \", \"call      CORINFO_HELP_THROW \\n       int       3 \\n; Total bytes of code 219 \\nNow here\\u2019s what it is f\", \"or .NET 7: \\n; Program.Sum() \\n       push      r14 \\n       push      rdi \\n       push      rsi \\n     \", \"  push      rbp \\n       push      rbx \\n       sub       rsp,20 \\n       mov       rdx,[rcx+8] \\n      \", \" xor       eax,eax \\n       mov       ecx,[rdx+18] \\n       mov       r8d,ecx \\n       mov       r9d,[r\", \"dx+10] \\n       lea       ecx,[rcx+r9+0FFFF] \\n       cmp       ecx,r8d \\n       jle       short M00_L0\", \"3 \\n       mov       r9d,[rdx+1C] \\n       mov       r10d,[rdx+14] \\n       lea       r10d,[r9+r10+0FFF\", \"F] \\nM00_L00: \\n       mov       r11d,r9d \\n       cmp       r10d,r11d \\n       jle       short M00_L02 \", \"\\n       mov       esi,r8d \\n       sub       esi,[rdx+18] \\n       mov       edi,[rdx+10] \\nM00_L01: \\n \", \"      mov       ebx,esi \\n       cmp       ebx,edi \\n       jae       short M00_L04 \\n       mov       \", \"ebp,[rdx+14] \\n       imul      ebx,ebp \\n       mov       r14d,r11d \\n       sub       r14d,[rdx+1C] \\n\", \"       cmp       r14d,ebp \\n       jae       short M00_L04 \\n       add       ebx,r14d \\n       add    \", \"   eax,[rdx+rbx*4+20] \\n       inc       r11d \\n       cmp       r10d,r11d \\n       jg        short M00\", \"_L01 \\nM00_L02: \\n       inc       r8d \\n       cmp       ecx,r8d \\n       jg        short M00_L00 \\nM00_\", \"L03: \\n \\n45 \\nCHAPTER 2 | JIT \\n \\n       add       rsp,20 \\n       pop       rbx \\n       pop       rbp \\n\", \"       pop       rsi \\n       pop       rdi \\n       pop       r14 \\n       ret \\nM00_L04: \\n       call \", \"     CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes of code 130 \\nImportantly, note there\", \" are no more calls (other than for the bounds check exception at the end). For \\nexample, instead of \", \"that first GetUpperBound call: \\ncall      System.Array.GetUpperBound(Int32) \\nwe get: \\nmov       r9d,\", \"[rdx+1C] \\nmov       r10d,[rdx+14] \\nlea       r10d,[r9+r10+0FFFF] \\nand it ends up being much faster: \", \"\\nMethod \\nRuntime \\nMean \\nRatio \\nSum \\n.NET 6.0 \\n2,657.5 us \\n1.00 \\nSum \\n.NET 7.0 \\n676.3 us \\n0.25 \\nLoop \", \"Hoisting and Cloning \\nWe previously saw how PGO interacts with loop hoisting and cloning, and those \", \"optimizations have \\nseen other improvements, as well. \\nHistorically, the JIT\\u2019s support for hoisting \", \"has been limited to lifting an invariant out one level. \\nConsider this example: \\n[Benchmark] \\npublic\", \" void Compute() \\n{ \\n    for (int thousands = 0; thousands < 10; thousands++) \\n    { \\n        for (in\", \"t hundreds = 0; hundreds < 10; hundreds++) \\n        { \\n            for (int tens = 0; tens < 10; ten\", \"s++) \\n            { \\n                for (int ones = 0; ones < 10; ones++) \\n                { \\n     \", \"               int n = ComputeNumber(thousands, hundreds, tens, ones); \\n                    Process(\", \"n); \\n                } \\n            } \\n        } \\n    } \\n} \\n \\n \\n46 \\nCHAPTER 2 | JIT \\n \\nstatic int Co\", \"mputeNumber(int thousands, int hundreds, int tens, int ones) => \\n    (thousands * 1000) + \\n    (hund\", \"reds * 100) + \\n    (tens * 10) + \\n    ones; \\n \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nstatic vo\", \"id Process(int n) { } \\nAt first glance, you might look at this and say \\u201cwhat could be hoisted, the c\", \"omputation of n requires \\nall of the loop inputs, and all of that computation is in ComputeNumber.\\u201d \", \"But from a compiler\\u2019s \\nperspective, the ComputeNumber function is inlineable and thus logically can \", \"be part of its caller, the \\ncomputation of n is actually split into multiple pieces, and each of tho\", \"se pieces can be hoisted to \\ndifferent levels, e.g. the tens computation can be hoisted out one leve\", \"l, the hundreds out two levels, \\nand the thousands out three levels. Here\\u2019s what [DisassemblyDiagnos\", \"er] outputs for .NET 6: \\n; Program.Compute() \\n       push      r14 \\n       push      rdi \\n       pus\", \"h      rsi \\n       push      rbp \\n       push      rbx \\n       sub       rsp,20 \\n       xor       es\", \"i,esi \\nM00_L00: \\n       xor       edi,edi \\nM00_L01: \\n       xor       ebx,ebx \\nM00_L02: \\n       xor \", \"      ebp,ebp \\n       imul      ecx,esi,3E8 \\n       imul      eax,edi,64 \\n       add       ecx,eax \\n\", \"       lea       eax,[rbx+rbx*4] \\n       lea       r14d,[rcx+rax*2] \\nM00_L03: \\n       lea       ecx,\", \"[r14+rbp] \\n       call      Program.Process(Int32) \\n       inc       ebp \\n       cmp       ebp,0A \\n \", \"      jl        short M00_L03 \\n       inc       ebx \\n       cmp       ebx,0A \\n       jl        short\", \" M00_L02 \\n       inc       edi \\n       cmp       edi,0A \\n       jl        short M00_L01 \\n       inc \", \"      esi \\n       cmp       esi,0A \\n       jl        short M00_L00 \\n       add       rsp,20 \\n       \", \"pop       rbx \\n       pop       rbp \\n       pop       rsi \\n       pop       rdi \\n       pop       r1\", \"4 \\n       ret \\n; Total bytes of code 84 \\n \\n47 \\nCHAPTER 2 | JIT \\n \\nWe can see that some hoisting has \", \"happened here. After all, the inner most loop (tagged M00_L03) is \\nonly five instructions: increment\", \" ebp (which at this point is the ones counter value), and if it\\u2019s still less \\nthan 0xA (10), jump ba\", \"ck to M00_L03 which adds whatever is in r14 to ones. Great, so we\\u2019ve hoisted \\nall of the unnecessary\", \" computation out of the inner loop, being left only with adding the ones \\nposition to the rest of th\", \"e number. Let\\u2019s go out a level. M00_L02 is the label for the tens loop. What \\ndo we see there? Troub\", \"le. The two instructions imul ecx,esi,3E8 and imul eax,edi,64 are \\nperforming the thousands * 1000 a\", \"nd hundreds * 100 operations, highlighting that these \\noperations which could have been hoisted out \", \"further were left stuck in the next-to-innermost loop. \\nNow, here\\u2019s what we get for .NET 7, where th\", \"is was improved in dotnet/runtime#68061: \\n; Program.Compute() \\n       push      r15 \\n       push    \", \"  r14 \\n       push      r12 \\n       push      rdi \\n       push      rsi \\n       push      rbp \\n     \", \"  push      rbx \\n       sub       rsp,20 \\n       xor       esi,esi \\nM00_L00: \\n       xor       edi,e\", \"di \\n       imul      ebx,esi,3E8 \\nM00_L01: \\n       xor       ebp,ebp \\n       imul      r14d,edi,64 \\n\", \"       add       r14d,ebx \\nM00_L02: \\n       xor       r15d,r15d \\n       lea       ecx,[rbp+rbp*4] \\n \", \"      lea       r12d,[r14+rcx*2] \\nM00_L03: \\n       lea       ecx,[r12+r15] \\n       call      qword p\", \"tr [Program.Process(Int32)] \\n       inc       r15d \\n       cmp       r15d,0A \\n       jl        short\", \" M00_L03 \\n       inc       ebp \\n       cmp       ebp,0A \\n       jl        short M00_L02 \\n       inc \", \"      edi \\n       cmp       edi,0A \\n       jl        short M00_L01 \\n       inc       esi \\n       cmp\", \"       esi,0A \\n       jl        short M00_L00 \\n       add       rsp,20 \\n       pop       rbx \\n      \", \" pop       rbp \\n       pop       rsi \\n       pop       rdi \\n       pop       r12 \\n       pop       r\", \"14 \\n       pop       r15 \\n       ret \\n; Total bytes of code 99 \\n \\n48 \\nCHAPTER 2 | JIT \\n \\nNotice now \", \"where those imul instructions live. There are four labels, each one corresponding to one \\nof the loo\", \"ps, and we can see the outermost loop has the imul ebx,esi,3E8 (for the thousands \\ncomputation) and \", \"the next loop has the imul r14d,edi,64 (for the hundreds computation), \\nhighlighting that these comp\", \"utations were hoisted out to the appropriate level (the tens and ones \\ncomputation are still in the \", \"right places). \\nMore improvements have gone in on the cloning side. Previously, loop cloning would o\", \"nly apply for \\nloops iterating by 1 from a low to a high value. With dotnet/runtime#60148, the compa\", \"rison against \\nthe upper value can be <= rather than just <. And with dotnet/runtime#67930, loops th\", \"at iterate \\ndownward can also be cloned, as can loops that have increments and decrements larger tha\", \"n 1. \\nConsider this benchmark: \\nprivate int[] _values = Enumerable.Range(0, 1000).ToArray(); \\n \\n[Ben\", \"chmark] \\n[Arguments(0, 0, 1000)] \\npublic int LastIndexOf(int arg, int offset, int count) \\n{ \\n    int\", \"[] values = _values; \\n    for (int i = offset + count - 1; i >= offset; i--) \\n        if (values[i] \", \"== arg) \\n            return i; \\n    return 0; \\n} \\nWithout loop cloning, the JIT can\\u2019t assume that of\", \"fset through offset+count are in range, and thus \\nevery access to the array needs to be bounds check\", \"ed. With loop cloning, the JIT could generate one \\nversion of the loop without bounds checks and onl\", \"y use that when it knows all accesses will be valid. \\nThat\\u2019s exactly what happens now in .NET 7. Her\", \"e\\u2019s what we got with .NET 6: \\n; Program.LastIndexOf(Int32, Int32, Int32) \\n       sub       rsp,28 \\n \", \"      mov       rcx,[rcx+8] \\n       lea       eax,[r8+r9+0FFFF] \\n       cmp       eax,r8d \\n       jl\", \"        short M00_L01 \\n       mov       r9d,[rcx+8] \\n       nop       word ptr [rax+rax] \\nM00_L00: \\n\", \"       cmp       eax,r9d \\n       jae       short M00_L03 \\n       movsxd    r10,eax \\n       cmp      \", \" [rcx+r10*4+10],edx \\n       je        short M00_L02 \\n       dec       eax \\n       cmp       eax,r8d \", \"\\n       jge       short M00_L00 \\nM00_L01: \\n       xor       eax,eax \\n       add       rsp,28 \\n      \", \" ret \\nM00_L02: \\n       add       rsp,28 \\n       ret \\nM00_L03: \\n       call      CORINFO_HELP_RNGCHKF\", \"AIL \\n \\n49 \\nCHAPTER 2 | JIT \\n \\n       int       3 \\n; Total bytes of code 72 \\nNotice how in the core l\", \"oop, at label M00_L00, there\\u2019s a bounds check (cmp eax,r9d and jae short \\nM00_L03, which jumps to a \", \"call CORINFO_HELP_RNGCHKFAIL). And here\\u2019s what we get with .NET 7: \\n; Program.LastIndexOf(Int32, Int\", \"32, Int32) \\n       sub       rsp,28 \\n       mov       rax,[rcx+8] \\n       lea       ecx,[r8+r9+0FFFF\", \"] \\n       cmp       ecx,r8d \\n       jl        short M00_L02 \\n       test      rax,rax \\n       je    \", \"    short M00_L01 \\n       test      ecx,ecx \\n       jl        short M00_L01 \\n       test      r8d,r8\", \"d \\n       jl        short M00_L01 \\n       cmp       [rax+8],ecx \\n       jle       short M00_L01 \\nM00\", \"_L00: \\n       mov       r9d,ecx \\n       cmp       [rax+r9*4+10],edx \\n       je        short M00_L03 \", \"\\n       dec       ecx \\n       cmp       ecx,r8d \\n       jge       short M00_L00 \\n       jmp       sh\", \"ort M00_L02 \\nM00_L01: \\n       cmp       ecx,[rax+8] \\n       jae       short M00_L04 \\n       mov     \", \"  r9d,ecx \\n       cmp       [rax+r9*4+10],edx \\n       je        short M00_L03 \\n       dec       ecx \", \"\\n       cmp       ecx,r8d \\n       jge       short M00_L01 \\nM00_L02: \\n       xor       eax,eax \\n     \", \"  add       rsp,28 \\n       ret \\nM00_L03: \\n       mov       eax,ecx \\n       add       rsp,28 \\n       \", \"ret \\nM00_L04: \\n       call      CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes of code 9\", \"8 \\nNotice how the code size is larger, and how there are now two variations of the loop: one at M00_\", \"L00 \\nand one at M00_L01. The second one, M00_L01, has a branch to that same call \\nCORINFO_HELP_RNGCH\", \"KFAIL, but the first one doesn\\u2019t, because that loop will only end up being used \\nafter proving that \", \"the offset, count, and _values.Length are such that the indexing will always be in \\nbounds. \\nOther c\", \"hanges also improved loop cloning. dotnet/runtime#59886 enables the JIT to choose different \\nforms f\", \"or how to emit the the conditions for choosing the fast or slow loop path, e.g. whether to emit \\n \\n5\", \"0 \\nCHAPTER 2 | JIT \\n \\nall the conditions, & them together, and then branch (if (!(cond1 & cond2)) go\", \"to slowPath), or \\nwhether to emit each condition on its own (if (!cond1) goto slowPath; if (!cond2) \", \"goto \\nslowPath). dotnet/runtime#66257 enables loop cloning to kick in when the loop variable is init\", \"ialized \\nto more kinds of expressions (e.g. for (int fromindex = lastIndex - lengthToClear; ...)). A\", \"nd \\ndotnet/runtime#70232 increases the JIT\\u2019s willingness to clone loops with bodies that do a broade\", \"r set \\nof operations. \\nFolding, propagation, and substitution \\nConstant folding is an optimization w\", \"here a compiler computes the value of an expression involving \\nonly constants at compile-time rather\", \" than generating the code to compute the value at run-time. \\nThere are multiple levels of constant f\", \"olding in .NET, with some constant folding performed by the C# \\ncompiler and some constant folding p\", \"erformed by the JIT compiler. For example, given the C# code: \\n[Benchmark] \\npublic int A() => 3 + (4\", \" * 5); \\n \\n[Benchmark] \\npublic int B() => A() * 2; \\nthe C# compiler will generate IL for these method\", \"s like the following: \\n.method public hidebysig instance int32 A () cil managed  \\n{ \\n    .maxstack 8\", \" \\n    IL_0000: ldc.i4.s 23 \\n    IL_0002: ret \\n} \\n \\n.method public hidebysig instance int32 B () cil \", \"managed  \\n{ \\n    .maxstack 8 \\n    IL_0000: ldarg.0 \\n    IL_0001: call instance int32 Program::A() \\n \", \"   IL_0006: ldc.i4.2 \\n    IL_0007: mul \\n    IL_0008: ret \\n} \\nYou can see that the C# compiler has co\", \"mputed the value of 3 + (4*5), as the IL for method A simply \\ncontains the equivalent of return 23;.\", \" However, method B contains the equivalent of return A() * \\n2;, highlighting that the constant foldi\", \"ng performed by the C# compiler was intramethod only. Now \\nhere\\u2019s what the JIT generates: \\n; Program\", \".A() \\n       mov       eax,17 \\n       ret \\n; Total bytes of code 6 \\n \\n; Program.B() \\n       mov     \", \"  eax,2E \\n       ret \\n; Total bytes of code 6 \\n \\n51 \\nCHAPTER 2 | JIT \\n \\nThe assembly for method A is\", \"n\\u2019t particularly interesting; it\\u2019s just returning that same value 23 (hex \\n0x17). But method B is mo\", \"re interesting. The JIT has inlined the call from B to A, exposing the contents \\nof A to B, such tha\", \"t the JIT effectively sees the body of B as the equivalent of return 23 * 2;. At that \\npoint, the JI\", \"T can do its own constant folding, and it transforms the body of B to simply return 46 (hex \\n0x2e). \", \"Constant propagation is intricately linked to constant folding and is essentially just the idea that\", \" \\nyou can substitute a constant value (typically one computed via constant folding) into further \\nex\", \"pressions, at which point they may also be able to be folded. \\nThe JIT has long performed constant f\", \"olding, but it improves further in .NET 7. One of the ways \\nconstant folding can improve is by expos\", \"ing more values to be folded, which often means more \\ninlining. dotnet/runtime#55745 helped the inli\", \"ner to understand that a method call like M(constant + \\nconstant) (noting that those constants might\", \" be the result of some other method call) is itself \\npassing a constant to M, and a constant being p\", \"assed to a method call is a hint to the inliner that it \\nshould consider being more aggressive about\", \" inlining, since exposing that constant to the body of the \\ncallee can potentially significantly red\", \"uce the amount of code required to implement the callee. The \\nJIT might have previously inlined such\", \" a method anyway, but when it comes to inlining, the JIT is all \\nabout heuristics and generating eno\", \"ugh evidence that it\\u2019s worthwhile to inline something; this \\ncontributes to that evidence. This patt\", \"ern shows up, for example, in the various FromXx methods on \\nTimeSpan. For example, TimeSpan.FromSec\", \"onds is implemented as: \\npublic static TimeSpan FromSeconds(double value) => Interval(value, TicksPe\", \"rSecond); // \\nTicksPerSecond is a constant \\nand, eschewing argument validation for the purposes of t\", \"his example, Interval is: \\nprivate static TimeSpan Interval(double value, double scale) => \\nInterval\", \"FromDoubleTicks(value * scale); \\nprivate static TimeSpan IntervalFromDoubleTicks(double ticks) => ti\", \"cks == long.MaxValue ? \\nTimeSpan.MaxValue : new TimeSpan((long)ticks); \\nwhich if everything gets inl\", \"ined means FromSeconds is essentially: \\npublic static TimeSpan FromSeconds(double value) \\n{ \\n    dou\", \"ble ticks = value * 10_000_000; \\n    return ticks == long.MaxValue ? TimeSpan.MaxValue : new TimeSpa\", \"n((long)ticks); \\n} \\nand if value is a constant, let\\u2019s say 5, that whole thing can be constant folded\", \" (with dead code \\nelimination on the ticks == long.MaxValue branch) to simply: \\nreturn new TimeSpan(\", \"50_000_000); \\nI\\u2019ll spare you the .NET 6 assembly for this, but on .NET 7 with a benchmark like: \\n[Be\", \"nchmark] \\npublic TimeSpan FromSeconds() => TimeSpan.FromSeconds(5); \\nwe now get the simple and clean\", \": \\n; Program.FromSeconds() \\n       mov       eax,2FAF080 \\n \\n52 \\nCHAPTER 2 | JIT \\n \\n       ret \\n; Tot\", \"al bytes of code 6 \\nAnother change improving constant folding included dotnet/runtime#57726 from \\n[@\", \"SingleAccretion](https://github.com/SingleAccretion), which unblocked constant folding in a \\nparticu\", \"lar scenario that sometimes manifests when doing field-by-field assignment of structs being \\nreturne\", \"d from method calls. As a small example, consider this trivial property, which access the \\nColor.Dar\", \"kOrange property, which in turn does new Color(KnownColor.DarkOrange): \\n[Benchmark] \\npublic Color Da\", \"rkOrange() => Color.DarkOrange; \\nIn .NET 6, the JIT generated this: \\n; Program.DarkOrange() \\n       \", \"mov       eax,1 \\n       mov       ecx,39 \\n       xor       r8d,r8d \\n       mov       [rdx],r8 \\n     \", \"  mov       [rdx+8],r8 \\n       mov       [rdx+10],cx \\n       mov       [rdx+12],ax \\n       mov      \", \" rax,rdx \\n       ret \\n; Total bytes of code 32 \\nThe interesting thing here is that some constants (3\", \"9, which is the value of KnownColor.DarkOrange, \\nand 1, which is a private StateKnownColorValid cons\", \"tant) are being loaded into registers (mov eax, \\n1, mov ecx, 39) and then later being stored into th\", \"e relevant location for the Color struct being \\nreturned (mov [rdx+12],ax and mov [rdx+10],cx). In .\", \"NET 7, it now generates: \\n; Program.DarkOrange() \\n       xor       eax,eax \\n       mov       [rdx],r\", \"ax \\n       mov       [rdx+8],rax \\n       mov       word ptr [rdx+10],39 \\n       mov       word ptr [\", \"rdx+12],1 \\n       mov       rax,rdx \\n       ret \\n; Total bytes of code 25 \\nwith direct assignment of\", \" these constant values into their destination locations (mov word ptr \\n[rdx+12],1 and mov word ptr [\", \"rdx+10],39). Other changes contributing to constant folding \\nincluded dotnet/runtime#58171 from [@Si\", \"ngleAccretion](https://github.com/SingleAccretion) and \\ndotnet/runtime#57605 from [@SingleAccretion]\", \"(https://github.com/SingleAccretion). \\nHowever, a large category of improvement came from an optimiz\", \"ation related to propagation, that of \\nforward substitution. Consider this silly benchmark: \\n[Benchm\", \"ark] \\npublic int Compute1() => Value + Value + Value + Value + Value; \\n \\n[Benchmark] \\npublic int Com\", \"pute2() => SomethingElse() + Value + Value + Value + Value + Value; \\n \\nprivate static int Value => 1\", \"6; \\n \\n53 \\nCHAPTER 2 | JIT \\n \\n \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate static int Someth\", \"ingElse() => 42; \\nIf we look at the assembly code generated for Compute1 on .NET 6, it looks like wh\", \"at we\\u2019d hope for. \\nWe\\u2019re adding Value 5 times, Value is trivially inlined and returns a constant val\", \"ue 16, and so we\\u2019d \\nhope that the assembly code generated for Compute1 would effectively just be ret\", \"urning the value 80 \\n(hex 0x50), which is exactly what happens: \\n; Program.Compute1() \\n       mov   \", \"    eax,50 \\n       ret \\n; Total bytes of code 6 \\nBut Compute2 is a bit different. The structure of t\", \"he code is such that the additional call to \\nSomethingElse ends up slightly perturbing something abo\", \"ut the JIT\\u2019s analysis, and .NET 6 ends up \\nwith this assembly code: \\n; Program.Compute2() \\n       su\", \"b       rsp,28 \\n       call      Program.SomethingElse() \\n       add       eax,10 \\n       add       \", \"eax,10 \\n       add       eax,10 \\n       add       eax,10 \\n       add       eax,10 \\n       add       \", \"rsp,28 \\n       ret \\n; Total bytes of code 29 \\nRather than a single mov eax, 50 to put the value 0x50\", \" into the return register, we have 5 separate \\nadd eax, 10 to build up that same 0x50 (80) value. Th\", \"at\\u2019s\\u2026 not ideal. \\nIt turns out that many of the JIT\\u2019s optimizations operate on the tree data structu\", \"res created as part of \\nparsing the IL. In some cases, optimizations can do better when they\\u2019re expo\", \"sed to more of the \\nprogram, in other words when the tree they\\u2019re operating on is larger and contain\", \"s more to be \\nanalyzed. However, various operations can break up these trees into smaller, individua\", \"l ones, such as \\nwith temporary variables created as part of inlining, and in doing so can inhibit t\", \"hese operations. \\nSomething is needed in order to effectively stitch these trees back together, and \", \"that\\u2019s forward \\nsubstitution. You can think of forward substitution almost like an inverse of CSE; r\", \"ather than trying to \\nfind duplicate expressions and eliminate them by computing the value once and \", \"storing it into a \\ntemporary, forward substitution eliminates that temporary and effectively moves t\", \"he expression tree \\ninto its use site. Obviously you don\\u2019t want to do this if it would then negate C\", \"SE and result in \\nduplicate work, but for expressions that are defined once and used once, this kind\", \" of forward \\npropagation is valuable. dotnet/runtime#61023 added an initial limited version of forwa\", \"rd \\nsubstitution, and then dotnet/runtime#63720 added a more robust generalized implementation. \\nSub\", \"sequently, dotnet/runtime#70587 expanded it to also cover some SIMD vectors, and then \\ndotnet/runtim\", \"e#71161 improved it further to enable substitutions into more places (in this case into \\ncall argume\", \"nts). And with those, our silly benchmark now produces the following on .NET 7: \\n; Program.Compute2(\", \") \\n       sub       rsp,28 \\n       call      qword ptr [7FFCB8DAF9A8] \\n \\n54 \\nCHAPTER 2 | JIT \\n \\n    \", \"   add       eax,50 \\n       add       rsp,28 \\n       ret \\n; Total bytes of code 18 \\nVectorization \\nS\", \"IMD, or Single Instruction Multiple Data, is a kind of processing in which one instruction applies t\", \"o \\nmultiple pieces of data at the same time. You\\u2019ve got a list of numbers and you want to find the i\", \"ndex \\nof a particular value? You could walk the list comparing one element at a time, and that would\", \" be fine \\nfunctionally. But what if in the same amount of time it takes you to read and compare one \", \"element, \\nyou could instead read and compare two elements, or four elements, or 32 elements? That\\u2019s \", \"SIMD, \\nand the art of utilizing SIMD instructions is lovingly referred to as \\u201cvectorization,\\u201d where \", \"operations \\nare applied to all of the elements in a \\u201cvector\\u201d at the same time. \\n.NET has long had su\", \"pport for vectorization in the form of Vector<T>, which is an easy-to-use type \\nwith first-class JIT\", \" support to enable a developer to write vectorized implementations. One of \\nVector<T>\\u2019s greatest str\", \"engths is also one of its greatest weaknesses. The type is designed to adapt to \\nwhatever width vect\", \"or instructions are available in your hardware. If the machine supports 256-bit \\nwidth vectors, grea\", \"t, that\\u2019s what Vector<T> will target. If not, if the machine supports 128-bit width \\nvectors, great,\", \" that\\u2019s what Vector<T> targets. But that flexibility comes with various downsides, at least \\ntoday; \", \"for example, the operations you can perform on a Vector<T> end up needing to be agnostic to \\nthe wid\", \"th of the vectors used, since the width is variable based on the hardware on which the code \\nactuall\", \"y runs. And that means the operations that can be exposed on Vector<T> are limited, which in \\nturn l\", \"imits the kinds of operations that can be vectorized with it. Also, because it\\u2019s only ever a single \", \"\\nsize in a given process, some data set sizes that fall in between 128 bits and 256 bits might not b\", \"e \\nprocessed as well as you\\u2019d hope. You write your Vector<byte>-based algorithm, and you run it on a\", \" \\nmachine with support for 256-bit vectors, which means it can process 32 bytes at a time, but then \", \"you \\nfeed it an input with 31 bytes. Had Vector<T> mapped to 128-bit vectors, it could have been use\", \"d to \\nimprove the processing of that input, but as its vector size is larger than the input data siz\", \"e, the \\nimplementation ends up falling back to one that\\u2019s not accelerated. There are also issues rel\", \"ated to \\nR2R and Native AOT, since ahead-of-time compilation needs to know in advance what instructi\", \"ons \\nshould be used for Vector<T> operations. You already saw this earlier when discussing the outpu\", \"t of \\nDOTNET_JitDisasmSummary; we saw that the NarrowUtf16ToAscii method was one of only a few \\nmeth\", \"ods that was JIT compiled in a \\u201chello, world\\u201d console app, and that this was because it lacked R2R \\n\", \"code due to its use of Vector<T>. \\nStarting in .NET Core 3.0, .NET gained literally thousands of new\", \" \\u201chardware intrinsics\\u201d methods, most \\nof which are .NET APIs that map down to one of these SIMD inst\", \"ructions. These intrinsics enable an \\nexpert to write an implementation tuned to a specific instruct\", \"ion set, and if done well, get the best \\npossible performance, but it also requires the developer to\", \" understand each instruction set and to \\nimplement their algorithm for each instruction set that mig\", \"ht be relevant, e.g. an AVX2 \\nimplementation if it\\u2019s supported, or an SSE2 implementation if it\\u2019s su\", \"pported, or an ArmBase \\nimplementation if it\\u2019s supported, and so on. \\n.NET 7 has introduced a middle\", \" ground. Previous releases saw the introduction of the Vector128<T> \\nand Vector256<T> types, but pur\", \"ely as the vehicle by which data moved in and out of the hardware \\nintrinsics, since they\\u2019re all tie\", \"d to specific width vectors. Now in .NET 7, exposed via \\n \\n55 \\nCHAPTER 2 | JIT \\n \\ndotnet/runtime#534\", \"50, dotnet/runtime#63414, dotnet/runtime#60094, and dotnet/runtime#68559, a \\nvery large set of cross\", \"-platform operations is defined over these types as well, e.g. \\nVector128<T>.ExtractMostSignificantB\", \"its, Vector256.ConditionalSelect, and so on. A \\ndeveloper who wants or needs to go beyond what the h\", \"igh-level Vector<T> offers can choose to \\ntarget one or more of these two types. Typically this woul\", \"d amount to a developer writing one code \\npath based on Vector128<T>, as that has the broadest reach\", \" and achieves a significant amount of the \\ngains from vectorization, and then if is motivated to do \", \"so can add a second path for Vector256<T> in \\norder to potentially double throughput further on plat\", \"forms that have 256-bit width vectors. Think of \\nthese types and methods as a platform-abstraction l\", \"ayer: you code to these methods, and then the JIT \\ntranslates them into the most appropriate instruc\", \"tions for the underlying platform. Consider this \\nsimple code as an example: \\nusing System.Runtime.C\", \"ompilerServices; \\nusing System.Runtime.Intrinsics; \\nusing System.Runtime.Intrinsics.X86; \\n \\ninternal\", \" class Program \\n{ \\n    private static void Main() \\n    { \\n        Vector128<byte> v = Vector128.Crea\", \"te((byte)123); \\n        while (true) \\n        { \\n            WithIntrinsics(v); \\n            WithVec\", \"tor(v); \\n        } \\n    } \\n \\n    [MethodImpl(MethodImplOptions.NoInlining)] \\n    private static int \", \"WithIntrinsics(Vector128<byte> v) => Sse2.MoveMask(v); \\n \\n    [MethodImpl(MethodImplOptions.NoInlini\", \"ng)] \\n    private static uint WithVector(Vector128<byte> v) => v.ExtractMostSignificantBits(); \\n} \\nI\", \" have two functions: one that directly uses the Sse2.MoveMask hardware intrinsic and one that uses \\n\", \"the new Vector128<T>.ExtractMostSignificantBits method. Using DOTNET_JitDisasm=Program.*, \\nhere\\u2019s wh\", \"at the optimized tier-1 code for these looks like on my x64 Windows machine: \\n; Assembly listing for\", \" method Program:WithIntrinsics(Vector128`1):int \\nG_M000_IG01:                ;; offset=0000H \\n      \", \" C5F877               vzeroupper \\n \\nG_M000_IG02:                ;; offset=0003H \\n       C5F91001    \", \"         vmovupd  xmm0, xmmword ptr [rcx] \\n       C5F9D7C0             vpmovmskb eax, xmm0 \\n \\nG_M000\", \"_IG03:                ;; offset=000BH \\n       C3                   ret \\n \\n; Total bytes of code 12 \\n\", \" \\n; Assembly listing for method Program:WithVector(Vector128`1):int \\nG_M000_IG01:                ;; \", \"offset=0000H \\n       C5F877               vzeroupper \\n \\n \\n56 \\nCHAPTER 2 | JIT \\n \\nG_M000_IG02:       \", \"         ;; offset=0003H \\n       C5F91001             vmovupd  xmm0, xmmword ptr [rcx] \\n       C5F9D\", \"7C0             vpmovmskb eax, xmm0 \\n \\nG_M000_IG03:                ;; offset=000BH \\n       C3       \", \"            ret \\n \\n; Total bytes of code 12 \\nNotice anything? The code for the two methods is identi\", \"cal, both resulting in a vpmovmskb (Move Byte \\nMask) instruction. Yet the former code will only work\", \" on a platform that supports SSE2 whereas the \\nlatter code will work on any platform with support fo\", \"r 128-bit vectors, including Arm64 and WASM \\n(and any future platforms on-boarded that also support \", \"SIMD); it\\u2019ll just result in different instructions \\nbeing emitted on those platforms. \\nTo explore th\", \"is a bit more, let\\u2019s take a simple example and vectorize it. We\\u2019ll implement a Contains \\nmethod, whe\", \"re we want to search a span of bytes for a specific value and return whether it was found: \\nstatic b\", \"ool Contains(ReadOnlySpan<byte> haystack, byte needle) \\n{ \\n    for (int i = 0; i < haystack.Length; \", \"i++) \\n    { \\n        if (haystack[i] == needle) \\n        { \\n            return true; \\n        } \\n   \", \" } \\n \\n    return false; \\n} \\nHow would we vectorize this with Vector<T>? First things first, we need \", \"to check whether it\\u2019s even \\nsupported, and fall back to our existing implementation if it\\u2019s not (Vec\", \"tor.IsHardwareAccelerated). \\nWe also need to fall back if the length of the input is less than the s\", \"ize of a vector \\n(Vector<byte>.Count). \\nstatic bool Contains(ReadOnlySpan<byte> haystack, byte needl\", \"e) \\n{ \\n    if (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count) \\n    { \\n      \", \"  // ... \\n    } \\n    else \\n    { \\n        for (int i = 0; i < haystack.Length; i++) \\n        { \\n    \", \"        if (haystack[i] == needle) \\n            { \\n                return true; \\n            } \\n    \", \"    } \\n    } \\n \\n    return false; \\n} \\n \\n57 \\nCHAPTER 2 | JIT \\n \\nNow that we know we have enough data,\", \" we can get to coding our vectorized loop. In this loop, we\\u2019ll \\nbe searching for the needle, which m\", \"eans we need a vector that contains that value for every element; \\nthe Vector<T>\\u2019s constructor provi\", \"des that (new Vector<byte>(needle)). And we need to be able to \\nslice off a vector\\u2019s width of data a\", \"t a time; for a bit more efficiency, I\\u2019ll use pointers. We need a current \\niteration pointer, and we\", \" need to iterate until the point where we couldn\\u2019t form another vector \\nbecause we\\u2019re too close to t\", \"he end, and a straightforward way to do that is to get a pointer that\\u2019s \\nexactly one vector\\u2019s width \", \"from the end; that way, we can just iterate until our current pointer is equal \\nto or greater than t\", \"hat threshold. And finally, in our loop body, we need to compare our current \\nvector with the target\", \" vector to see if any elements are the same (Vector.EqualsAny), if any is \\nreturning true, and if no\", \"t bumping our current pointer to the next location. At this point we have: \\nstatic unsafe bool Conta\", \"ins(ReadOnlySpan<byte> haystack, byte needle) \\n{ \\n    if (Vector.IsHardwareAccelerated && haystack.L\", \"ength >= Vector<byte>.Count) \\n    { \\n        fixed (byte* haystackPtr = &MemoryMarshal.GetReference(\", \"haystack)) \\n        { \\n            Vector<byte> target = new Vector<byte>(needle); \\n            byte\", \"* current = haystackPtr; \\n            byte* endMinusOneVector = haystackPtr + haystack.Length - Vect\", \"or<byte>.Count; \\n            do \\n            { \\n                if (Vector.EqualsAny(target, *(Vecto\", \"r<byte>*)current)) \\n                { \\n                    return true; \\n                } \\n \\n      \", \"          current += Vector<byte>.Count; \\n            } \\n            while (current < endMinusOneVec\", \"tor); \\n \\n            // ... \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i < haystack\", \".Length; i++) \\n        { \\n            if (haystack[i] == needle) \\n            { \\n                ret\", \"urn true; \\n            } \\n        } \\n    } \\n \\n    return false; \\n} \\nAnd we\\u2019re almost done. The last \", \"issue to handle is we may still have a few elements at the end we \\nhaven\\u2019t searched. There are a cou\", \"ple of ways we could handle that. One would be to just continue \\nwith our fall back implementation a\", \"nd process each of the remaining elements one at a time. Another \\nwould be to employ a trick that\\u2019s \", \"common when vectorizing idempotent operations. Our operation \\nisn\\u2019t mutating anything, which means i\", \"t doesn\\u2019t matter if we compare the same element multiple \\ntimes, which means we can just do one fina\", \"l vector compare for the last vector in the search space; \\n \\n58 \\nCHAPTER 2 | JIT \\n \\nthat might or mi\", \"ght not overlap with elements we\\u2019ve already looked at, but it won\\u2019t hurt anything if it \\ndoes. And w\", \"ith that, our implementation is complete: \\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, \", \"byte needle) \\n{ \\n    if (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count) \\n   \", \" { \\n        fixed (byte* haystackPtr = &MemoryMarshal.GetReference(haystack)) \\n        { \\n          \", \"  Vector<byte> target = new Vector<byte>(needle); \\n            byte* current = haystackPtr; \\n       \", \"     byte* endMinusOneVector = haystackPtr + haystack.Length - Vector<byte>.Count; \\n            do \\n\", \"            { \\n                if (Vector.EqualsAny(target, *(Vector<byte>*)current)) \\n             \", \"   { \\n                    return true; \\n                } \\n \\n                current += Vector<byte>\", \".Count; \\n            } \\n            while (current < endMinusOneVector); \\n \\n            if (Vector.E\", \"qualsAny(target, *(Vector<byte>*)endMinusOneVector)) \\n            { \\n                return true; \\n \", \"           } \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i < haystack.Length; i++) \\n\", \"        { \\n            if (haystack[i] == needle) \\n            { \\n                return true; \\n    \", \"        } \\n        } \\n    } \\n \\n    return false; \\n} \\nCongratulations, we\\u2019ve vectorized this operatio\", \"n, and fairly decently at that. We can throw this into \\nbenchmarkdotnet and see really nice speedups\", \": \\nprivate byte[] _data = Enumerable.Repeat((byte)123, 999).Append((byte)42).ToArray(); \\n \\n[Benchmar\", \"k(Baseline = true)] \\n[Arguments((byte)42)] \\npublic bool Find(byte value) => Contains(_data, value); \", \"// just the fallback path in its \\nown method \\n \\n[Benchmark] \\n[Arguments((byte)42)] \\npublic bool Find\", \"Vectorized(byte value) => Contains_Vectorized(_data, value); // the \\nimplementation we just wrote \\n \", \"\\n \\n \\n59 \\nCHAPTER 2 | JIT \\n \\nMethod \\nMean \\nRatio \\nFind \\n484.05 ns \\n1.00 \\nFindVectorized \\n20.21 ns \\n0.\", \"04 \\nA 24x speedup! Woo hoo, victory, all your performance are belong to us! \\nYou deploy this in your\", \" service, and you see Contains being called on your hot path, but you don\\u2019t \\nsee the improvements yo\", \"u were expecting. You dig in a little more, and you discover that while you \\ntested this with an inp\", \"ut array with 1000 elements, typical inputs had more like 30 elements. What \\nhappens if we change ou\", \"r benchmark to have just 30 elements? That\\u2019s not long enough to form a \\nvector, so we fall back to t\", \"he one-at-a-time path, and we don\\u2019t get any speedups at all. \\nOne thing we can now do is switch from\", \" using Vector<T> to Vector128<T>. That will then lower the \\nthreshold from 32 bytes to 16 bytes, suc\", \"h that inputs in that range will still have some amount of \\nvectorization applied. As these Vector12\", \"8<T> and Vector256<T> types have been designed very \\nrecently, they also utilize all the cool new to\", \"ys, and thus we can use refs instead of pointers. Other \\nthan that, we can keep the shape of our imp\", \"lementation almost the same, substituting Vector128 \\nwhere we were using Vector, and using some meth\", \"ods on Unsafe to manipulate our refs instead of \\npointer arithmetic on the span we fixed. \\nstatic un\", \"safe bool Contains(ReadOnlySpan<byte> haystack, byte needle) \\n{ \\n    if (Vector128.IsHardwareAcceler\", \"ated && haystack.Length >= Vector128<byte>.Count) \\n    { \\n        ref byte current = ref MemoryMarsh\", \"al.GetReference(haystack); \\n \\n        Vector128<byte> target = Vector128.Create(needle); \\n        re\", \"f byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length - \\nVector128<byte>.Count); \\n \", \"       do \\n        { \\n            if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref current))\", \") \\n            { \\n                return true; \\n            } \\n \\n            current = ref Unsafe.Ad\", \"d(ref current, Vector128<byte>.Count); \\n        } \\n        while (Unsafe.IsAddressLessThan(ref curre\", \"nt, ref endMinusOneVector)); \\n \\n        if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref end\", \"MinusOneVector))) \\n        { \\n            return true; \\n        } \\n    } \\n    else \\n    { \\n        f\", \"or (int i = 0; i < haystack.Length; i++) \\n        { \\n            if (haystack[i] == needle) \\n       \", \"     { \\n                return true; \\n            } \\n        } \\n    } \\n \\n60 \\nCHAPTER 2 | JIT \\n \\n \\n  \", \"  return false; \\n} \\nWith that in hand, we can now try it on our smaller 30 element data set: \\nprivat\", \"e byte[] _data = Enumerable.Repeat((byte)123, 29).Append((byte)42).ToArray(); \\n \\n[Benchmark(Baseline\", \" = true)] \\n[Arguments((byte)42)] \\npublic bool Find(byte value) => Contains(_data, value); \\n \\n[Benchm\", \"ark] \\n[Arguments((byte)42)] \\npublic bool FindVectorized(byte value) => Contains_Vectorized(_data, va\", \"lue); \\nMethod \\nMean \\nRatio \\nFind \\n15.388 ns \\n1.00 \\nFindVectorized \\n1.747 ns \\n0.11 \\nWoo hoo, victory,\", \" all your performance are belong to us\\u2026 again! \\nWhat about on the larger data set again? Previously \", \"with Vector<T> we had a 24x speedup, but now: \\nMethod \\nMean \\nRatio \\nFind \\n484.25 ns \\n1.00 \\nFindVecto\", \"rized \\n32.92 ns \\n0.07 \\n\\u2026 closer to 15x. Nothing to sneeze at, but it\\u2019s not the 24x we previously saw\", \". What if we want to have \\nour cake and eat it, too? Let\\u2019s also add a Vector256<T> path. To do that,\", \" we literally copy/paste our \\nVector128<T> code, search/replace all references to Vector128 in the c\", \"opied code with Vector256, \\nand just put it into an additional condition that uses the Vector256<T> \", \"path if it\\u2019s supported and there \\nare enough elements to utilize it. \\nstatic unsafe bool Contains(Re\", \"adOnlySpan<byte> haystack, byte needle) \\n{ \\n    if (Vector128.IsHardwareAccelerated && haystack.Leng\", \"th >= Vector128<byte>.Count) \\n    { \\n        ref byte current = ref MemoryMarshal.GetReference(hayst\", \"ack); \\n             \\n        if (Vector256.IsHardwareAccelerated && haystack.Length >= Vector256<byt\", \"e>.Count) \\n        { \\n            Vector256<byte> target = Vector256.Create(needle); \\n            re\", \"f byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length - \\nVector256<byte>.Count); \\n \", \"           do \\n            { \\n                if (Vector256.EqualsAny(target, Vector256.LoadUnsafe(r\", \"ef current))) \\n                { \\n                    return true; \\n                } \\n \\n           \", \"     current = ref Unsafe.Add(ref current, Vector256<byte>.Count); \\n            } \\n            while\", \" (Unsafe.IsAddressLessThan(ref current, ref endMinusOneVector)); \\n \\n61 \\nCHAPTER 2 | JIT \\n \\n \\n       \", \"     if (Vector256.EqualsAny(target, Vector256.LoadUnsafe(ref endMinusOneVector))) \\n            { \\n \", \"               return true; \\n            } \\n        } \\n        else \\n        { \\n            Vector12\", \"8<byte> target = Vector128.Create(needle); \\n            ref byte endMinusOneVector = ref Unsafe.Add(\", \"ref current, haystack.Length - \\nVector128<byte>.Count); \\n            do \\n            { \\n            \", \"    if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref current))) \\n                { \\n        \", \"            return true; \\n                } \\n \\n                current = ref Unsafe.Add(ref current,\", \" Vector128<byte>.Count); \\n            } \\n            while (Unsafe.IsAddressLessThan(ref current, re\", \"f endMinusOneVector)); \\n \\n            if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref endMi\", \"nusOneVector))) \\n            { \\n                return true; \\n            } \\n        } \\n    } \\n    e\", \"lse \\n    { \\n        for (int i = 0; i < haystack.Length; i++) \\n        { \\n            if (haystack[i\", \"] == needle) \\n            { \\n                return true; \\n            } \\n        } \\n    } \\n \\n    re\", \"turn false; \\n} \\nAnd, boom, we\\u2019re back: \\nMethod \\nMean \\nRatio \\nFind \\n484.53 ns \\n1.00 \\nFindVectorized \\n\", \"20.08 ns \\n0.04 \\nWe now have an implementation that is vectorized on any platform with either 128-bit\", \" or 256-bit \\nvector instructions (x86, x64, Arm64, WASM, etc.), that can use either based on the inp\", \"ut length, and \\nthat can be included in an R2R image if that\\u2019s of interest. \\nThere are many factors \", \"that impact which path you go down, and I expect we\\u2019ll have guidance \\nforthcoming to help navigate a\", \"ll the factors and approaches. But the capabilities are all there, and \\nwhether you choose to use Ve\", \"ctor<T>, Vector128<T> and/or Vector256<T>, or the hardware \\nintrinsics directly, there are some amaz\", \"ing performance opportunities ready for the taking. \\n \\n62 \\nCHAPTER 2 | JIT \\n \\nI already mentioned se\", \"veral PRs that exposed the new cross-platform vector support, but that only \\nscratches the surface o\", \"f the work done to actually enable these operations and to enable them to \\nproduce high-quality code\", \". As just one example of a category of such work, a set of changes went in \\nto help ensure that zero\", \" vector constants are handled well, such as dotnet/runtime#63821 that \\n\\u201cmorphed\\u201d (changed) Vector128\", \"/256<T>.Create(default) into Vector128/256<T>.Zero, which then \\nenables subsequent optimizations to \", \"focus only on Zero; dotnet/runtime#65028 that enabled \\nconstant propagation of Vector128/256<T>.Zero\", \"; dotnet/runtime#68874 and dotnet/runtime#70171 \\nthat add first-class knowledge of vector constants \", \"to the JIT\\u2019s intermediate representation; and \\ndotnet/runtime#62933, dotnet/runtime#65632, dotnet/ru\", \"ntime#55875, dotnet/runtime#67502, and \\ndotnet/runtime#64783 that all improve the code quality of in\", \"structions generated for zero vector \\ncomparisons. \\nInlining \\nInlining is one of the most important \", \"optimizations the JIT can do. The concept is simple: instead of \\nmaking a call to some method, take \", \"the code from that method and bake it into the call site. This has \\nthe obvious advantage of avoidin\", \"g the overhead of a method call, but except for really small methods \\non really hot paths, that\\u2019s of\", \"ten on the smaller side of the wins inlining brings. The bigger wins are \\ndue to the callee\\u2019s code b\", \"eing exposed to the caller\\u2019s code, and vice versa. So, for example, if the \\ncaller is passing a cons\", \"tant as an argument to the callee, if the method isn\\u2019t inlined, the compilation of \\nthe callee has n\", \"o knowledge of that constant, but if the callee is inlined, all of the code in the callee is \\nthen a\", \"ware of its argument being a constant value, and can do all of the optimizations possible with \\nsuch\", \" a constant, like dead code elimination, branch elimination, constant folding and propagation, \\nand \", \"so on. Of course, if it were all rainbows and unicorns, everything possible to be inlined would be \\n\", \"inlined, and that\\u2019s obviously not happening. Inlining brings with it the cost of potentially increas\", \"ed \\nbinary size. If the code being inlined would result in the same amount or less assembly code in \", \"the \\ncaller than it takes to call the callee (and if the JIT can quickly determine that), then inlin\", \"ing is a no-\\nbrainer. But if the code being inlined would increase the size of the callee non-trivia\", \"lly, now the JIT \\nneeds to weigh that increase in code size against the throughput benefits that cou\", \"ld come from it. \\nThat code size increase can itself result in throughput regressions, due to increa\", \"sing the number of \\ndistinct instructions to be executed and thereby putting more pressure on the in\", \"struction cache. As \\nwith any cache, the more times you need to read from memory to populate it, the\", \" less effective the \\ncache will be. If you have a function that gets inlined into 100 different call\", \" sites, every one of those \\ncall sites\\u2019 copies of the callee\\u2019s instructions are unique, and calling \", \"each of those 100 functions could \\nend up thrashing the instruction cache; in contrast, if all of th\", \"ose 100 functions \\u201cshared\\u201d the same \\ninstructions by simply calling the single instance of the calle\", \"e, it\\u2019s likely the instruction cache would be \\nmuch more effective and lead to fewer trips to memory\", \". \\nAll that is to say, inlining is really important, it\\u2019s important that the \\u201cright\\u201d things be inlin\", \"ed and that it \\nnot overinline, and as such every release of .NET in recent memory has seen nice imp\", \"rovements \\naround inlining. .NET 7 is no exception. \\nOne really interesting improvement around inlin\", \"ing is dotnet/runtime#64521, and it might be \\nsurprising. Consider the Boolean.ToString method; here\", \"\\u2019s its full implementation: \\npublic override string ToString() \\n{ \\n \\n63 \\nCHAPTER 2 | JIT \\n \\n    if (\", \"!m_value) return \\\"False\\\"; \\n    return \\\"True\\\"; \\n} \\nPretty simple, right? You\\u2019d expect something this \", \"trivial to be inlined. Alas, on .NET 6, this benchmark: \\nprivate bool _value = true; \\n \\n[Benchmark] \", \"\\npublic int BoolStringLength() => _value.ToString().Length; \\nproduces this assembly code: \\n; Program\", \".BoolStringLength() \\n       sub       rsp,28 \\n       cmp       [rcx],ecx \\n       add       rcx,8 \\n  \", \"     call      System.Boolean.ToString() \\n       mov       eax,[rax+8] \\n       add       rsp,28 \\n   \", \"    ret \\n; Total bytes of code 23 \\nNote the call System.Boolean.ToString(). The reason for this is, \", \"historically, the JIT has been \\nunable to inline methods across assembly boundaries if those methods\", \" contain string literals (like the \\n\\\"False\\\" and \\\"True\\\" in that Boolean.ToString implementation). Thi\", \"s restriction had to do with string \\ninterning and the possibility that such inlining could lead to \", \"visible behavioral differences. Those \\nconcerns are no longer valid, and so this PR removes the rest\", \"riction. As a result, that same benchmark \\non .NET 7 now produces this: \\n; Program.BoolStringLength(\", \") \\n       cmp       byte ptr [rcx+8],0 \\n       je        short M00_L01 \\n       mov       rax,1DB5480\", \"0D20 \\n       mov       rax,[rax] \\nM00_L00: \\n       mov       eax,[rax+8] \\n       ret \\nM00_L01: \\n    \", \"   mov       rax,1DB54800D18 \\n       mov       rax,[rax] \\n       jmp       short M00_L00 \\n; Total by\", \"tes of code 38 \\nNo more call System.Boolean.ToString(). \\ndotnet/runtime#61408 made two changes relat\", \"ed to inlining. First, it taught the inliner how to better \\nsee the what methods were being called i\", \"n an inlining candidate, and in particular when tiered \\ncompilation is disabled or when a method wou\", \"ld bypass tier-0 (such as a method with loops before \\nOSR existed or with OSR disabled); by understa\", \"nding what methods are being called, it can better \\nunderstand the cost of the method, e.g. if those\", \" method calls are actually hardware intrinsics with a \\nvery low cost. Second, it enabled CSE in more\", \" cases with SIMD vectors. \\ndotnet/runtime#71778 also impacted inlining, and in particular in situati\", \"ons where a typeof() could \\nbe propagated to the callee (e.g. via a method argument). In previous re\", \"leases of .NET, various \\n \\n64 \\nCHAPTER 2 | JIT \\n \\nmembers on Type like IsValueType were turned into \", \"JIT intrinsics, such that the JIT could substitute a \\nconstant value for calls where it could comput\", \"e the answer at compile time. For example, this: \\n[Benchmark] \\npublic bool IsValueType() => IsValueT\", \"ype<int>(); \\n \\nprivate static bool IsValueType<T>() => typeof(T).IsValueType; \\nresults in this assem\", \"bly code on .NET 6: \\n; Program.IsValueType() \\n       mov       eax,1 \\n       ret \\n; Total bytes of c\", \"ode 6 \\nHowever, change the benchmark slightly: \\n[Benchmark] \\npublic bool IsValueType() => IsValueTyp\", \"e(typeof(int)); \\n \\nprivate static bool IsValueType(Type t) => t.IsValueType; \\nand it\\u2019s no longer as \", \"simple: \\n; Program.IsValueType() \\n       sub       rsp,28 \\n       mov       rcx,offset MT_System.Int\", \"32 \\n       call      CORINFO_HELP_TYPEHANDLE_TO_RUNTIMETYPE \\n       mov       rcx,rax \\n       mov   \", \"    rax,[7FFCA47C9560] \\n       cmp       [rcx],ecx \\n       add       rsp,28 \\n       jmp       rax \\n;\", \" Total bytes of code 38 \\nEffectively, as part of inlining the JIT loses the notion that the argument\", \" is a constant and fails to \\npropagate it. This PR fixes that, such that on .NET 7, we now get what \", \"we expect: \\n; Program.IsValueType() \\n       mov       eax,1 \\n       ret \\n; Total bytes of code 6 \\nAr\", \"m64 \\nA huge amount of effort in .NET 7 went into making code gen for Arm64 as good or better than it\", \"s \\nx64 counterpart. I\\u2019ve already discussed a bunch of PRs that are relevant regardless of architectu\", \"re, and \\nothers that are specific to Arm, but there are plenty more. To rattle off some of them: \\n\\u2022 \", \"\\nAddressing modes. \\u201cAddressing mode\\u201d is the term used to refer to how the operand of \\ninstructions a\", \"re specified. It could be the actual value, it could be the address from where a value \\nshould be lo\", \"aded, it could be the register containing the value, and so on. Arm supports a \\n\\u201cscaled\\u201d addressing \", \"mode, typically used for indexing into an array, where the size of each \\nelement is supplied and the\", \" instruction \\u201cscales\\u201d the provided offset by the specified scale. \\ndotnet/runtime#60808 enables the \", \"JIT to utilize this addressing mode. More generally, \\ndotnet/runtime#70749 enables the JIT to use ad\", \"dressing modes when accessing elements of \\n \\n65 \\nCHAPTER 2 | JIT \\n \\nmanaged arrays. dotnet/runtime#6\", \"6902 improves the use of addressing modes when the \\nelement type is byte. dotnet/runtime#65468 impro\", \"ves addressing modes used for floating point. \\nAnd dotnet/runtime#67490 implements addressing modes \", \"for SIMD vectors, specifically for \\nloads with unscaled indices. \\n\\u2022 \\nBetter instruction selection. V\", \"arious techniques go into ensuring that the best instructions are \\nselected to represent input code.\", \" dotnet/runtime#61037 teaches the JIT how to recognize the \\npattern (a * b) + c with integers and fo\", \"ld that into a single madd or msub instruction, while \\ndotnet/runtime#66621 does the same for a - (b\", \" * c) and msub. dotnet/runtime#61045 \\nenables the JIT to recognize certain constant bit shift operat\", \"ions (either explicit in the code or \\nimplicit to various forms of managed array access) and emit sb\", \"fiz/ubfiz instructions. \\ndotnet/runtime#70599, dotnet/runtime#66407, and dotnet/runtime#65535 all ha\", \"ndle various \\nforms of optimizing a % b. dotnet/runtime#61847 from \\n[@SeanWoo](https://github.com/Se\", \"anWoo) removes an unnecessary movi emitted as part of \\nsetting a dereferenced pointer to a constant \", \"value. dotnet/runtime#57926 from \\n[@SingleAccretion](https://github.com/SingleAccretion) enables com\", \"puting a 64-bit result as the \\nmultiplication of two 32-bit integers to be done with smull/umull. An\", \"d dotnet/runtime#61549 \\nfolds adds with sign extension or zero extension into a single add instructi\", \"on with \\nuxtw/sxtw/lsl, while dotnet/runtime#62630 drops redundant zero extensions after a ldr \\ninst\", \"ruction. \\n\\u2022 \\nVectorization. dotnet/runtime#64864 adds new \\nAdvSimd.LoadPairVector64/AdvSimd.LoadPair\", \"Vector128 hardware intrinsics. \\n\\u2022 \\nZeroing. Lots of operations require state to be set to zero, such\", \" as initializing all reference locals \\nin a method to zero as part of the method\\u2019s prologue (so that\", \" the GC doesn\\u2019t see and try to \\nfollow garbage references). While such functionality was previously \", \"vectorized, \\ndotnet/runtime#63422 enables this to be implemented using 128-bit width vector instruct\", \"ions \\non Arm. And dotnet/runtime#64481 changes the instruction sequences used for zeroing in order \\n\", \"to avoid unnecessary zeroing, free up additional registers, and enable the CPU to recognize \\nvarious\", \" instruction sequences and better optimize. \\n\\u2022 \\nMemory Model. dotnet/runtime#62895 enables store bar\", \"riers to be used wherever possible \\ninstead of full barriers, and uses one-way barriers for volatile\", \" variables. dotnet/runtime#67384 \\nenables volatile reads/writes to be implemented with the ldapr ins\", \"truction, while \\ndotnet/runtime#64354 uses a cheaper instruction sequence to handle volatile indirec\", \"tions. \\nThere\\u2019s dotnet/runtime#70600, which enables LSE Atomics to be used for Interlocked \\noperatio\", \"ns; dotnet/runtime#71512, which enables using the atomics instruction on Unix \\nmachines; and dotnet/\", \"runtime#70921, which enables the same but on Windows. \\nJIT helpers \\nWhile logically part of the runt\", \"ime, the JIT is actually isolated from the rest of the runtime, only \\ninteracting with it through an\", \" interface that enables communication between the JIT and the rest of \\nthe VM (Virtual Machine). The\", \"re\\u2019s a large amount of VM functionality then that the JIT relies on for \\ngood performance. \\ndotnet/r\", \"untime#65738 rewrote various \\u201cstubs\\u201d to be more efficient. Stubs are tiny bits of code that \\nserve t\", \"o perform some check and then redirect execution somewhere else. For example, when an \\ninterface dis\", \"patch call site is expected to only ever be used with a single implementation of that \\ninterface, th\", \"e JIT might employ a \\u201cdispatch stub\\u201d that compares the type of the object against the \\n \\n66 \\nCHAPTER\", \" 2 | JIT \\n \\nsingle one it\\u2019s cached, and if they\\u2019re equal simply jumps to the right target. You know \", \"you\\u2019re in the \\ncorest of the core areas of the runtime when a PR contains lots of assembly code for \", \"every \\narchitecture the runtime targets. And it paid off; there\\u2019s a virtual group of folks from arou\", \"nd .NET that \\nreview performance improvements and regressions in our automated performance test suit\", \"es, and \\nattribute these back to the PRs likely to be the cause (this is mostly automated but requir\", \"es some \\nhuman oversight). It\\u2019s always nice then when a few days after a PR is merged and performanc\", \"e \\ninformation has stabilized that you see a rash of comments like there were on this PR: \\n \\nFor any\", \"one familiar with generics and interested in performance, you may have heard the refrain that \\ngener\", \"ic virtual methods are relatively expensive. They are, comparatively. For example on .NET 6, this \\nc\", \"ode: \\nprivate Example _example = new Example(); \\n \\n[Benchmark(Baseline = true)] public void GenericN\", \"onVirtual() => \\n_example.GenericNonVirtual<Example>(); \\n[Benchmark] public void GenericVirtual() => \", \"_example.GenericVirtual<Example>(); \\n \\nclass Example \\n{ \\n    [MethodImpl(MethodImplOptions.NoInlinin\", \"g)] \\n    public void GenericNonVirtual<T>() { } \\n \\n    [MethodImpl(MethodImplOptions.NoInlining)] \\n \", \"   public virtual void GenericVirtual<T>() { } \\n} \\nresults in: \\n \\n \\n \\n67 \\nCHAPTER 2 | JIT \\n \\nMethod \", \"\\nMean \\nRatio \\nGenericNonVirtual \\n0.4866 \\nns \\n1.00 \\nGenericVirtual \\n6.4552 \\nns \\n13.28 \\ndotnet/runtime\", \"#65926 eases the pain a tad. Some of the cost comes from looking up some cached \\ninformation in a ha\", \"sh table in the runtime, and as is the case with many map implementations, this \\none involves comput\", \"ing a hash code and using a mod operation to map to the right bucket. Other \\nhash table implementati\", \"ons around dotnet/runtime, including Dictionary<,>, HashSet<,>, and \\nConcurrentDictionary<,> previou\", \"sly switched to a \\u201cfastmod\\u201d implementation; this PR does the same \\nfor this EEHashtable, which is us\", \"ed as part of the CORINFO_GENERIC_HANDLE JIT helper function \\nemployed: \\nMethod \\nRuntime \\nMean \\nRati\", \"o \\nGenericVirtual \\n.NET 6.0 \\n6.475 ns \\n1.00 \\nGenericVirtual \\n.NET 7.0 \\n6.119 ns \\n0.95 \\nNot enough of\", \" an improvement for us to start recommending people use them, but a 5% \\nimprovement takes a bit of t\", \"he edge off the sting. \\nGrab Bag \\nIt\\u2019s near impossible to cover every performance change that goes i\", \"nto the JIT, and I\\u2019m not going to \\ntry. But there were so many more PRs, I couldn\\u2019t just leave them \", \"all unsung, so here\\u2019s a few more \\nquickies: \\n\\u2022 \\ndotnet/runtime#58196 from [@benjamin-hodgson](https:\", \"//github.com/benjamin-hodgson). \\nGiven an expression like (byte)x | (byte)y, that can be morphed int\", \"o (byte)(x | y), which \\ncan optimize away some movs. \\nprivate int _x, _y; \\n \\n[Benchmark] \\npublic int\", \" Test() => (byte)_x | (byte)_y; \\n \\n \\n; *** .NET 6 *** \\n; Program.Test(Int32, Int32) \\n       movzx   \", \"  eax,dl \\n       movzx     edx,r8b \\n       or        eax,edx \\n       ret \\n; Total bytes of code 10 \\n\", \" \\n; *** .NET 7 *** \\n; Program.Test(Int32, Int32) \\n       or        edx,r8d \\n       movzx     eax,dl \", \"\\n       ret \\n; Total bytes of code 7 \\n \\n68 \\nCHAPTER 2 | JIT \\n \\n\\u2022 \\ndotnet/runtime#67182. On a machine\", \" with support for BMI2, 64-bit shifts can be performed with \\nthe shlx, sarx, and shrx instructions. \", \"\\n[Benchmark] \\n[Arguments(123, 1)] \\npublic ulong Shift(ulong x, int y) => x << y; \\n \\n \\n; *** .NET 6 *\", \"** \\n; Program.Shift(UInt64, Int32) \\n       mov       ecx,r8d \\n       mov       rax,rdx \\n       shl  \", \"     rax,cl \\n       ret \\n; Total bytes of code 10 \\n \\n; *** .NET 7 *** \\n; Program.Shift(UInt64, Int32\", \") \\n       shlx      rax,rdx,r8 \\n       ret \\n; Total bytes of code 6 \\n\\u2022 \\ndotnet/runtime#69003 from [@\", \"SkiFoD](https://github.com/SkiFoD). The pattern ~x + 1 can be \\nchanged into a two\\u2019s-complement negat\", \"ion. \\n[Benchmark] \\n[Arguments(42)] \\npublic int Neg(int i) => ~i + 1; \\n \\n \\n; *** .NET 6 *** \\n; Progra\", \"m.Neg(Int32) \\n       mov       eax,edx \\n       not       eax \\n       inc       eax \\n       ret \\n; To\", \"tal bytes of code 7 \\n \\n; *** .NET 7 *** \\n; Program.Neg(Int32) \\n       mov       eax,edx \\n       neg \", \"      eax \\n       ret \\n; Total bytes of code 5 \\n\\u2022 \\ndotnet/runtime#61412 from [@SkiFoD](https://githu\", \"b.com/SkiFoD). An expression X & 1 == 1 \\nto test whether the bottom bit of a number is set can chang\", \"ed to the cheaper X & 1 (which isn\\u2019t \\nactually expressible without a following != 0 in C#). \\n[Benchm\", \"ark] \\n[Arguments(42)] \\npublic bool BitSet(int x) => (x & 1) == 1; \\n \\n \\n; *** .NET 6 *** \\n; Program.B\", \"itSet(Int32) \\n       test      dl,1 \\n       setne     al \\n \\n69 \\nCHAPTER 2 | JIT \\n \\n       movzx     \", \"eax,al \\n       ret \\n; Total bytes of code 10 \\n \\n; *** .NET 7 *** \\n; Program.BitSet(Int32) \\n       mo\", \"v       eax,edx \\n       and       eax,1 \\n       ret \\n; Total bytes of code 6 \\n\\u2022 \\ndotnet/runtime#6354\", \"5 from [@Wraith2](https://github.com/Wraith2). The expression x & (x - \\n1) can be lowered to the bls\", \"r instruction. \\n[Benchmark] \\n[Arguments(42)] \\npublic int ResetLowestSetBit(int x) => x & (x - 1); \\n \", \"\\n \\n; *** .NET 6 *** \\n; Program.ResetLowestSetBit(Int32) \\n       lea       eax,[rdx+0FFFF] \\n       an\", \"d       eax,edx \\n       ret \\n; Total bytes of code 6 \\n \\n; *** .NET 7 *** \\n; Program.ResetLowestSetBi\", \"t(Int32) \\n       blsr      eax,edx \\n       ret \\n; Total bytes of code 6 \\n\\u2022 \\ndotnet/runtime#62394. / \", \"and % by a vector\\u2019s .Count wasn\\u2019t recognizing that Count can be \\nunsigned, but doing so leads to bet\", \"ter code gen. \\n[Benchmark] \\n[Arguments(42u)] \\npublic long DivideByVectorCount(uint i) => i / Vector<\", \"byte>.Count; \\n \\n \\n; *** .NET 6 *** \\n; Program.DivideByVectorCount(UInt32) \\n       mov       eax,edx \", \"\\n       mov       rdx,rax \\n       sar       rdx,3F \\n       and       rdx,1F \\n       add       rax,rd\", \"x \\n       sar       rax,5 \\n       ret \\n; Total bytes of code 21 \\n \\n; *** .NET 7 *** \\n; Program.Divid\", \"eByVectorCount(UInt32) \\n       mov       eax,edx \\n       shr       rax,5 \\n       ret \\n; Total bytes \", \"of code 7 \\n \\n70 \\nCHAPTER 2 | JIT \\n \\n\\u2022 \\ndotnet/runtime#60787. Loop alignment in .NET 6 provides a ver\", \"y nice exploration of why and \\nhow the JIT handles loop alignment. This PR extends that further by t\", \"rying to \\u201chide\\u201d an emitted \\nalign instruction behind an unconditional jmp that might already exist, \", \"in order to minimize the \\nimpact of the processor having to fetch and decode nops. \\n \\n71 \\nCHAPTER 3 \", \"| GC \\n \\nCHAPTER 3 \\nGC \\n\\u201cRegions\\u201d is a feature of the garbage collector (GC) that\\u2019s been in the works\", \" for multiple years. It\\u2019s \\nenabled by default in 64-bit processes in .NET 7 as of dotnet/runtime#646\", \"88, but as with other multi-\\nyear features, a multitude of PRs went into making it a reality. At a 3\", \"0,000 foot level, \\u201cregions\\u201d replaces \\nthe current \\u201csegments\\u201d approach to managing memory on the GC h\", \"eap; rather than having a few \\ngigantic segments of memory (e.g. each 1GB), often associated 1:1 wit\", \"h a generation, the GC instead \\nmaintains many, many smaller regions (e.g. each 4MB) as their own en\", \"tity. This enables the GC to be \\nmore agile with regards to operations like repurposing regions of m\", \"emory from one generation to \\nanother. For more information on regions, the blog post Put a DPAD on \", \"that GC! from the primary \\ndeveloper on the GC is still the best resource. \\n \\n72 \\nCHAPTER 4 | Native\", \" AOT \\n \\nCHAPTER 4 \\nNative AOT \\nTo many people, the word \\u201cperformance\\u201d in the context of software is \", \"about throughput. How fast \\ndoes something execute? How much data per second can it process? How man\", \"y requests per second \\ncan it process? And so on. But there are many other facets to performance. Ho\", \"w much memory does \\nit consume? How fast does it start up and get to the point of doing something us\", \"eful? How much \\nspace does it consume on disk? How long would it take to download? And then there ar\", \"e related \\nconcerns. In order to achieve these goals, what dependencies are required? What kinds of \", \"operations \\ndoes it need to perform to achieve these goals, and are all of those operations permitte\", \"d in the target \\nenvironment? If any of this paragraph resonates with you, you are the target audien\", \"ce for the Native \\nAOT support now shipping in .NET 7. \\n.NET has long had support for AOT code gener\", \"ation. For example, .NET Framework had it in the form \\nof ngen, and .NET Core has it in the form of \", \"crossgen. Both of those solutions involve a standard .NET \\nexecutable that has some of its IL alread\", \"y compiled to assembly code, but not all methods will have \\nassembly code generated for them, variou\", \"s things can invalidate the assembly code that was \\ngenerated, external .NET assemblies without any \", \"native assembly code can be loaded, and so on, and \\nin all of those cases, the runtime continues to \", \"utilize a JIT compiler. Native AOT is different. It\\u2019s an \\nevolution of CoreRT, which itself was an e\", \"volution of .NET Native, and it\\u2019s entirely free of a JIT. The \\nbinary that results from publishing a\", \" build is a completely standalone executable in the target \\nplatform\\u2019s platform-specific file format\", \" (e.g. COFF on Windows, ELF on Linux, Mach-O on macOS) with \\nno external dependencies other than one\", \"s standard to that platform (e.g. libc). And it\\u2019s entirely native: \\nno IL in sight, no JIT, no nothi\", \"ng. All required code is compiled and/or linked in to the executable, \\nincluding the same GC that\\u2019s \", \"used with standard .NET apps and services, and a minimal runtime that \\nprovides services around thre\", \"ading and the like. All of that brings great benefits: super fast startup \\ntime, small and entirely-\", \"self contained deployment, and ability to run in places JIT compilers aren\\u2019t \\nallowed (e.g. because \", \"memory pages that were writable can\\u2019t then be executable). It also brings \\nlimitations: no JIT means\", \" no dynamic loading of arbitrary assemblies (e.g. Assembly.LoadFile) and no \\nreflection emit (e.g. D\", \"ynamicMethod), everything compiled and linked in to the app means the more \\nfunctionality that\\u2019s use\", \"d (or might be used) the larger is your deployment, etc. Even with those \\nlimitations, for a certain\", \" class of application, Native AOT is an incredibly exciting and welcome \\naddition to .NET 7. \\nToo ma\", \"ny PRs to mention have gone into bringing up the Native AOT stack, in part because it\\u2019s been \\nin the\", \" works for years (as part of the archived dotnet/corert project and then as part of \\ndotnet/runtimel\", \"ab/feature/NativeAOT) and in part because there have been over a hundred PRs just \\nin dotnet/runtime\", \" that have gone into bringing Native AOT up to a shippable state since the code was \\noriginally brou\", \"ght over from dotnet/runtimelab in dotnet/runtime#62563 and dotnet/runtime#62563. \\nBetween that and \", \"there not being a previous version to compare its performance to, instead of \\nfocusing PR by PR on i\", \"mprovements, let\\u2019s just look at how to use it and the benefits it brings. \\n \\n73 \\nCHAPTER 4 | Native \", \"AOT \\n \\nToday, Native AOT is focused on console applications, so let\\u2019s create a console app: \\ndotnet \", \"new console -o nativeaotexample \\nWe now have our nativeaotexample directory containing a nativeaotex\", \"ample.csproj and a \\u201chello, \\nworld\\u201d Program.cs. To enable publishing the application with Native AOT,\", \" edit the .csproj to include \\nthis in the existing <PropertyGroup>...</PropertyGroup>.  \\n<PublishAot\", \">true</PublishAot> \\nAnd then\\u2026 actually, that\\u2019s it. Our app is now fully configured to be able to tar\", \"get Native AOT. All that\\u2019s \\nleft is to publish. As I\\u2019m currently writing this on my Windows x64 mach\", \"ine, I\\u2019ll target that: \\ndotnet publish -r win-x64 -c Release \\nI now have my generated executable in \", \"the output publish directory: \\n    Directory: C:\\\\nativeaotexample\\\\bin\\\\Release\\\\net7.0\\\\win-x64\\\\publish\", \" \\n \\nMode                 LastWriteTime         Length Name \\n-a---           8/27/2022  6:19 PM      \", \"  2061824 nativeaotexample.exe \\n-a---           8/27/2022  6:19 PM       14290944 nativeaotexample.p\", \"db \\nso 2M instead of 3.5MB. Of course, for that significant reduction I\\u2019ve given up some things: \\n\\u2022 \", \"\\nSetting InvariantGlobalization to true means I\\u2019m now not respecting culture information and \\nam ins\", \"tead using a set of invariant data for most globalization operations. \\n\\u2022 \\nSetting UseSystemResourceK\", \"eys to true means nice exception messages are stripped away. \\n\\u2022 \\nSetting IlcGenerateStackTraceData t\", \"o false means I\\u2019m going to get fairly poor stack traces \\nshould I need to debug an exception. \\n\\u2022 \\nSe\", \"tting DebuggerSupport to false\\u2026 good luck debugging things. \\n\\u2022 \\n\\u2026 you get the idea. \\nOne of the pote\", \"ntially mind-boggling aspects of Native AOT for a developer used to .NET is that, as it \\nsays on the\", \" tin, it really is native. After publishing the app, there is no IL involved, and there\\u2019s no JIT \\nth\", \"at could even process it. This makes some of the other investments in .NET 7 all the more valuable, \", \"\\nfor example everywhere investments are happening in source generators. Code that previously relied \", \"\\non reflection emit for good performance will need another scheme. We can see that, for example, wit\", \"h \\nRegex. Historically for optimal throughput with Regex, it\\u2019s been recommended to use \\nRegexOptions\", \".Compiled, which uses reflection emit at run-time to generate an optimized \\nimplementation of the sp\", \"ecified pattern. But if you look at the implementation of the Regex \\nconstructor, you\\u2019ll find this n\", \"ugget: \\nif (RuntimeFeature.IsDynamicCodeCompiled) \\n{ \\n    factory = Compile(pattern, tree, options, \", \"matchTimeout != InfiniteMatchTimeout); \\n} \\nWith the JIT, IsDynamicCodeCompiled is true. But with Nat\", \"ive AOT, it\\u2019s false. Thus, with Native AOT \\nand Regex, there\\u2019s no difference between specifying Rege\", \"xOptions.Compiled and not, and another \\nmechanism is required to get the throughput benefits promise\", \"d by RegexOptions.Compiled. Enter \\n[GeneratedRegex(...)], which, along with the new regex source gen\", \"erator shipping in the .NET 7 \\n \\n74 \\nCHAPTER 4 | Native AOT \\n \\nSDK, emits C# code into the assembly \", \"using it. That C# code takes the place of the reflection emit that \\nwould have happened at run-time,\", \" and is thus able to work successfully with Native AOT. \\nprivate static readonly string s_haystack =\", \" new \\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\n     \\n\", \"private Regex _interpreter = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline); \\n \\nprivate Rege\", \"x _compiled = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled | \\nRegexOptions.Multiline); \\n \\n[G\", \"eneratedRegex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline)] \\nprivate partial Regex SG(); \\n \\n[Benchma\", \"rk(Baseline = true)] public int Interpreter() => _interpreter.Count(s_haystack); \\n \\n[Benchmark] publ\", \"ic int Compiled() => _compiled.Count(s_haystack); \\n \\n[Benchmark] public int SourceGenerator() => SG(\", \").Count(s_haystack); \\nMethod \\nMean \\nRatio \\nInterpreter \\n9,036.7 us \\n1.00 \\nCompiled \\n9,064.8 us \\n1.00\", \" \\nSourceGenerator \\n426.1 us \\n0.05 \\nSo, yes, there are some constraints associated with Native AOT, b\", \"ut there are also solutions for \\nworking with those constraints. And further, those constraints can \", \"actually bring further benefits. \\nConsider dotnet/runtime#64497. Remember how we talked about \\u201cguard\", \"ed devirtualization\\u201d in \\ndynamic PGO, where via instrumentation the JIT can determine the most likel\", \"y type to be used at a \\ngiven call site and special-case it? With Native AOT, the entirety of the pr\", \"ogram is known at compile \\ntime, with no support for Assembly.LoadFrom or the like. That means at co\", \"mpile time, the compiler \\ncan do whole-program analysis to determine what types implement what inter\", \"faces. If a given \\ninterface only has a single type that implements it, then every call site through\", \" that interface can be \\nunconditionally devirtualized, without any type-check guards. \\nThis is a rea\", \"lly exciting space, one we expect to see flourish in coming releases. \\n \\n75 \\nCHAPTER 5 | Mono \\n \\nCHA\", \"PTER 5 \\nMono \\nUp until now I\\u2019ve referred to \\u201cthe JIT,\\u201d \\u201cthe GC,\\u201d and \\u201cthe runtime,\\u201d but in reality t\", \"here are actually \\nmultiple runtimes in .NET. I\\u2019ve been talking about \\u201ccoreclr,\\u201d which is the runtim\", \"e that\\u2019s recommended \\nfor use on Linux, macOS, and Windows. However, there\\u2019s also \\u201cmono,\\u201d which powe\", \"rs Blazor wasm \\napplications, Android apps, and iOS apps. It\\u2019s also seen significant improvements in\", \" .NET 7. \\nJust as with coreclr (which can JIT compile, AOT compile partially with JIT fallback, and \", \"fully Native \\nAOT compile), mono has multiple ways of actually executing code. One of those ways is \", \"an interpreter, \\nwhich enables mono to execute .NET code in environments that don\\u2019t permit JIT\\u2019ing a\", \"nd without \\nrequiring ahead-of-time compilation or incurring any limitations it may bring. Interesti\", \"ngly, though, \\nthe interpreter is itself almost a full-fledged compiler, parsing the IL, generating \", \"its own intermediate \\nrepresentation (IR) for it, and doing one or more optimization passes over tha\", \"t IR; it\\u2019s just that at the \\nend of the pipeline when a compiler would normally emit code, the inter\", \"preter instead saves off that \\ndata for it to interpret when the time comes to run. As such, the int\", \"erpreter has a very similar \\nconundrum to the one we discussed with coreclr\\u2019s JIT: the time it takes\", \" to optimize vs the desire to \\nstart up quickly. And in .NET 7, the interpreter employs a similar so\", \"lution: tiered compilation. \\ndotnet/runtime#68823 adds the ability for the interpreter to initially \", \"compile with minimal \\noptimization of that IR, and then once a certain threshold of call counts has \", \"been hit, then take the \\ntime to do as much optimization on the IR as possible for all future invoca\", \"tions of that method. This \\nyields the same benefits as it does for coreclr: improved startup time w\", \"hile also having efficient \\nsustained throughput. When this merged, we saw improvements in Blazor wa\", \"sm app startup time \\nimprove by 10-20%. Here\\u2019s one example from an app being tracked in our benchmar\", \"king system: \\n \\n76 \\nCHAPTER 5 | Mono \\n \\n \\nThe interpreter isn\\u2019t just used for entire apps, though. J\", \"ust as how coreclr can use the JIT when an R2R \\nimage doesn\\u2019t contain code for a method, mono can us\", \"e the interpreter when there\\u2019s no AOT code \\nfor a method. Once such case that occurred on mono was w\", \"ith generic delegate invocation, where the \\npresence of a generic delegate being invoked would trigg\", \"er falling back to the interpreter; for .NET 7, \\nthat gap was addressed with dotnet/runtime#70653. A\", \" more impactful case, however, is \\ndotnet/runtime#64867. Previously, any methods with catch or filte\", \"r exception handling clauses \\ncouldn\\u2019t be AOT compiled and would fall back to being interpreted. Wit\", \"h this PR, the method is now \\nable to be AOT compiled, and it only falls back to using the interpret\", \"er when an exception actually \\noccurs, switching over to the interpreter for the remainder of that m\", \"ethod call\\u2019s execution. Since many \\nmethods contain such clauses, this can make a big difference in \", \"throughput and CPU consumption. In \\nthe same vein, dotnet/runtime#63065 enabled methods with finally\", \" exception handling clauses to \\nbe AOT compiled; just the finally block gets interpreted rather than\", \" the entire method being \\ninterpreted. \\nBeyond such backend improvements, another class of improveme\", \"nt came from further unification \\nbetween coreclr and mono. Years ago, coreclr and mono had their ow\", \"n entire library stack built on \\ntop of them. Over time, as .NET was open sourced, portions of mono\\u2019\", \"s stack got replaced by shared \\ncomponents, bit by bit. Fast forward to today, all of the core .NET \", \"libraries above \\nSystem.Private.CoreLib are the same regardless of which runtime is being employed. \", \"In fact, the \\nsource for CoreLib itself is almost entirely shared, with ~95% of the source files bei\", \"ng compiled into \\nthe CoreLib that\\u2019s built for each runtime, and just a few percent of the source sp\", \"ecialized for each \\n(these statements means that the vast majority of the performance improvements d\", \"iscussed in the \\nrest of this post apply equally whether running on mono and coreclr). Even so, ever\", \"y release now we \\ntry to chip away at that few remaining percent, for reasons of maintainability, bu\", \"t also because the \\nsource used for coreclr\\u2019s CoreLib has generally had more attention paid to it fr\", \"om a performance \\nperspective. dotnet/runtime#71325, for example, moves mono\\u2019s array and span sortin\", \"g generic \\nsorting utility class over to the more efficient implementation used by coreclr. \\nOne of \", \"the biggest categories of improvements, however, is in vectorization. This comes in two pieces. \\nFir\", \"st, Vector<T> and Vector128<T> are now fully accelerated on both x64 and Arm64, thanks to PRs \\nlike \", \"dotnet/runtime#64961, dotnet/runtime#65086, dotnet/runtime#65128, dotnet/runtime#66317, \\n \\n77 \\nCHAPT\", \"ER 5 | Mono \\n \\ndotnet/runtime#66391, dotnet/runtime#66409, dotnet/runtime#66512, dotnet/runtime#6658\", \"6, \\ndotnet/runtime#66589, dotnet/runtime#66597, dotnet/runtime#66476, and dotnet/runtime#67125; \\ntha\", \"t significant amount of work means all that code that gets vectorized using these abstractions will \", \"\\nlight-up on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70086, mono now \\nkno\", \"ws how to translate Vector128<T> operations to WASM\\u2019s SIMD instruction set, such that code \\nvectoriz\", \"ed with Vector128<T> will also be accelerated when running in Blazor wasm applications and \\nanywhere\", \" else WASM might be executed. \\n \\n78 \\nCHAPTER 6 | Reflection \\n \\nCHAPTER 6 \\nReflection \\nReflection is \", \"one of those areas you either love or hate (I find it a bit humorous to be writing this \\nsection imm\", \"ediately after writing the Native AOT section). It\\u2019s immensely powerful, providing the \\nability to q\", \"uery all of the metadata for code in your process and for arbitrary assemblies you might \\nencounter,\", \" to invoke arbitrary functionality dynamically, and even to emit dynamically-generated IL at \\nrun-ti\", \"me. It\\u2019s also difficult to handle well in the face of tooling like a linker or a solution like Nativ\", \"e \\nAOT that needs to be able to determine at build time exactly what code will be executed, and it\\u2019s\", \" \\ngenerally quite expensive at run-time; thus it\\u2019s both something we strive to avoid when possible b\", \"ut \\nalso invest in reducing the costs of, as it\\u2019s so popular in so many different kinds of applicati\", \"ons \\nbecause it is incredibly useful. As with most releases, it\\u2019s seen some nice improvements in .NE\", \"T 7. \\nOne of the most impacted areas is reflection invoke. Available via MethodBase.Invoke, this \\nfu\", \"nctionality let\\u2019s you take a MethodBase (e.g. MethodInfo) object that represents some method for \\nwh\", \"ich the caller previously queried, and call it, with arbitrary arguments that the runtime needs to \\n\", \"marshal through to the callee, and with an arbitrary return value that needs to be marshaled back. I\", \"f \\nyou know the signature of the method ahead of time, the best way to optimize invocation speed is \", \"to \\ncreate a delegate from the MethodBase via CreateDelegate<T> and then use that delegate for all \\n\", \"future invocations. But in some circumstances, you don\\u2019t know the signature at compile time, and thu\", \"s \\ncan\\u2019t easily rely on delegates with known matching signatures. To address this, some libraries ha\", \"ve \\ntaken to using reflection emit to generate code at run-time specific to the target method. This \", \"is \\nextremely complicated and it\\u2019s not something we want apps to have to do. Instead, in .NET 7 via \", \"\\ndotnet/runtime#66357, dotnet/runtime#69575, and dotnet/runtime#74614, Invoke will itself use \\nrefle\", \"ction emit (in the form of DynamicMethod) to generate a delegate that is customized for invoking \\nth\", \"e target, and then future invocation via that MethodInfo will utilize that generated method. This \\ng\", \"ives developers most of the performance benefits of a custom reflection emit-based implementation \\nb\", \"ut without having the complexity or challenges of such an implementation in their own code base. \\npr\", \"ivate MethodInfo _method; \\n \\n[GlobalSetup] \\npublic void Setup() => _method = typeof(Program).GetMeth\", \"od(\\\"MyMethod\\\", \\nBindingFlags.NonPublic | BindingFlags.Static); \\n \\n[Benchmark] \\npublic void MethodInf\", \"oInvoke() => _method.Invoke(null, null); \\n \\nprivate static void MyMethod() { } \\n \\n \\n \\n79 \\nCHAPTER 6 \", \"| Reflection \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nMethodInfoInvoke \\n.NET 6.0 \\n43.846 ns \\n1.00 \\nMethodInf\", \"oInvoke \\n.NET 7.0 \\n8.078 ns \\n0.18 \\nReflection also involves lots of manipulation of objects that rep\", \"resent types, methods, properties, and \\nso on, and tweaks here and there can add up to a measurable \", \"difference when using these APIs. For \\nexample, I\\u2019ve talked in past performance posts about how, pot\", \"entially counterintuitively, one of the \\nways we\\u2019ve achieved performance boosts is by porting native\", \" code from the runtime back into \\nmanaged C#. There are a variety of ways in which doing so can help\", \" performance, but one is that \\nthere is some overhead associated with calling from managed code into\", \" the runtime, and eliminating \\nsuch hops avoids that overhead. This can be seen in full effect in do\", \"tnet/runtime#71873, which moves \\nseveral of these \\u201cFCalls\\u201d related to Type, RuntimeType (the Type-de\", \"rived class used by the runtime to \\nrepresent its types), and Enum out of native into managed. \\n[Ben\", \"chmark] \\npublic Type GetUnderlyingType() => Enum.GetUnderlyingType(typeof(DayOfWeek)); \\nMethod \\nRunt\", \"ime \\nMean \\nRatio \\nGetUnderlyingType \\n.NET 6.0 \\n27.413 ns \\n1.00 \\nGetUnderlyingType \\n.NET 7.0 \\n5.115 n\", \"s \\n0.19 \\nAnother example of this phenomenon comes in dotnet/runtime#62866, which moved much of the \\n\", \"underlying support for AssemblyName out of native runtime code into managed code in CoreLib. That \\ni\", \"n turn has an impact on anything that uses it, such as when using Activator.CreateInstance \\noverload\", \"s that take assembly names that need to be parsed. \\nprivate readonly string _assemblyName = typeof(M\", \"yClass).Assembly.FullName; \\nprivate readonly string _typeName = typeof(MyClass).FullName; \\npublic cl\", \"ass MyClass { } \\n \\n[Benchmark] \\npublic object CreateInstance() => Activator.CreateInstance(_assembly\", \"Name, _typeName); \\nMethod \\nRuntime \\nMean \\nRatio \\nCreateInstance \\n.NET 6.0 \\n3.827 us \\n1.00 \\nCreateIns\", \"tance \\n.NET 7.0 \\n2.276 us \\n0.60 \\nOther changes contributed to Activator.CreateInstance improvements \", \"as well. \\ndotnet/runtime#67148 removed several array and list allocations from inside of the \\nRuntim\", \"eType.CreateInstanceImpl method that\\u2019s used by CreateInstance (using Type.EmptyTypes \\ninstead of all\", \"ocating a new Type[0], avoiding unnecessarily turning a builder into an array, etc.), \\nresulting in \", \"less allocation and faster throughput. \\n[Benchmark] \\npublic void CreateInstance() => Activator.Creat\", \"eInstance(typeof(MyClass), \\nBindingFlags.NonPublic | BindingFlags.Instance, null, Array.Empty<object\", \">(), null); \\n \\ninternal class MyClass \\n{ \\n \\n80 \\nCHAPTER 6 | Reflection \\n \\n    internal MyClass() { }\", \" \\n} \\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAlloc Ratio \\nCreateInstance \\n.NET 6.0 \\n167.8 ns \\n1.00 \\n\", \"320 B \\n1.00 \\nCreateInstance \\n.NET 7.0 \\n143.4 ns \\n0.85 \\n200 B \\n0.62 \\nAnd since we were talking about \", \"AssemblyName, other PRs improved it in other ways as well. \\ndotnet/runtime#66750, for example, updat\", \"ed the computation of AssemblyName.FullName to use \\nstack-allocated memory and ArrayPool<char> inste\", \"ad of using a StringBuilder: \\nprivate AssemblyName[] _names = AppDomain.CurrentDomain.GetAssemblies(\", \").Select(a => new \\nAssemblyName(a.FullName)).ToArray(); \\n \\n[Benchmark] \\npublic int Names() \\n{ \\n    i\", \"nt sum = 0; \\n    foreach (AssemblyName name in _names) \\n    { \\n        sum += name.FullName.Length; \", \"\\n    } \\n    return sum; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nNames \\n.NET 6.0 \\n3\", \".423 us \\n1.00 \\n9.14 KB \\n1.00 \\nNames \\n.NET 7.0 \\n2.010 us \\n0.59 \\n2.43 KB \\n0.27 \\nMore reflection-relate\", \"d operations have also been turned into JIT intrinsics, as discussed earlier \\nenabling the JIT to co\", \"mpute answers to various questions at JIT compile time rather than at run-time. \\nThis was done, for \", \"example, for Type.IsByRefLike in dotnet/runtime#67852. \\n[Benchmark] \\npublic bool IsByRefLike() => ty\", \"peof(ReadOnlySpan<char>).IsByRefLike; \\nMethod \\nRuntime \\nMean \\nRatio \\nCode Size \\nIsByRefLike \\n.NET 6.\", \"0 \\n2.1322 ns \\n1.000 \\n31 B \\nIsByRefLike \\n.NET 7.0 \\n0.0000 ns \\n0.000 \\n6 B \\nThat the .NET 7 version is \", \"so close to zero is called out in a warning by benchmarkdotnet: \\n// * Warnings * \\nZeroMeasurement \\n \", \" Program.IsByRefLike: Runtime=.NET 7.0, Toolchain=net7.0 -> The method duration is \\nindistinguishabl\", \"e from the empty method duration \\nand it\\u2019s so indistinguishable from an empty method because that\\u2019s \", \"effectively what it is, as we can see \\nfrom the disassembly: \\n \\n \\n \\n81 \\nCHAPTER 6 | Reflection \\n \\n \\n\", \"; Program.IsByRefLike() \\n       mov       eax,1 \\n       ret \\n; Total bytes of code 6 \\nThere are also\", \" improvements that are hard to see but that remove overheads as part of populating \\nreflection\\u2019s cac\", \"hes, which end up reducing the work done typically on startup paths, helping apps to \\nlaunch faster.\", \" dotnet/runtime#66825, dotnet/runtime#66912, and dotnet/runtime#67149 all fall into \\nthis category b\", \"y removing unnecessary or duplicative array allocations as part of gathering data on \\nparameters, pr\", \"operties, and events. \\n \\n82 \\nCHAPTER 7 | Interop \\n \\nCHAPTER 7 \\nInterop \\n.NET has long had great supp\", \"ort for interop, enabling .NET applications to consume huge amounts of \\nfunctionality written in oth\", \"er languages and/or exposed by the underlying operating system. The \\nbedrock of this support has bee\", \"n \\u201cPlatform Invoke,\\u201d or \\u201cP/Invoke,\\u201d represented in code by \\n[DllImport(...)] applied to methods. The\", \" DllImportAttribute enables declaring a method that \\ncan be called like any other .NET method but th\", \"at actually represents some external method that the \\nruntime should call when this managed method i\", \"s invoked. The DllImport specifies details about in \\nwhat library the function lives, what its actua\", \"l name is in the exports from that library, high-level \\ndetails about marshalling of input arguments\", \" and return values, and so on, and the runtime ensures \\nall the right things happen. This mechanism \", \"works on all operating systems. For example, Windows \\nhas a method CreatePipe for creating an anonym\", \"ous pipe: \\nBOOL CreatePipe( \\n  [out]          PHANDLE               hReadPipe, \\n  [out]          PHA\", \"NDLE               hWritePipe, \\n  [in, optional] LPSECURITY_ATTRIBUTES lpPipeAttributes, \\n  [in]    \", \"       DWORD                 nSize \\n); \\nIf I want to call this function from C#, I can declare a [Dl\", \"lImport(...)] counterpart to it which I can \\nthen invoke as I can any other managed method: \\n[DllImp\", \"ort(\\\"kernel32\\\", SetLastError = true)] \\n[return: MarshalAs(UnmanagedType.Bool)] \\nprivate static unsaf\", \"e extern bool CreatePipe( \\n    out SafeFileHandle hReadPipe, \\n    out SafeFileHandle hWritePipe, \\n  \", \"  void* lpPipeAttributes, \\n    uint nSize); \\nThere are several interesting things to note here. Seve\", \"ral of the arguments are directly blittable with \\nthe same representation on the managed and native \", \"side of the equation, e.g. lpPipeAttributes is a \\npointer and nSize is a 32-bit integer. But what ab\", \"out the return value? The bool type in C# \\n(System.Boolean) is a one-byte type, but the BOOL type in\", \" the native signature is four bytes; thus code \\ncalling this managed method can\\u2019t just directly invo\", \"ke the native function somehow, as there needs to \\nbe some \\u201cmarshalling\\u201d logic that converts the fou\", \"r-byte return BOOL into the one-byte return bool. \\nSimiarly, the native function has two out pointer\", \"s for hReadPipe and hWritePipe, but the managed \\nsignature declares two SafeFileHandles (a SafeHandl\", \"e is a .NET type that wraps a pointer and \\nprovides a finalizer and Dispose method for ensuring that\", \" pointer is appropriately cleaned up when \\nit\\u2019s no longer being used). Some logic needs to take the \", \"output handles generated by the native \\nfunction and wrap them into these SafeFileHandles to be outp\", \"ut from the managed method. And \\nwhat about that SetLastError = true? .NET has methods like Marshal.\", \"GetLastPInvokeError(), \\n \\n83 \\nCHAPTER 7 | Interop \\n \\nand some code somewhere needs to take any error\", \" produced by this method and ensure it\\u2019s available \\nfor consumption via a subsequent GetLastPInvokeE\", \"rror(). \\nIf there\\u2019s no marshalling logic required, such that the managed signature and native signat\", \"ure are for \\nall intents and purposes the same, all arguments blittable, all return values blittable\", \", no additional \\nlogic required around the invocation of the method, etc., then a [DllImport(...)] e\", \"nds up being a \\nsimple passthrough with the runtime needing to do very little work to implement it. \", \"If, however, the \\n[DllImport(...)] involves any of this marshalling work, the runtime needs to gener\", \"ate a \\u201cstub,\\u201d \\ncreating a dedicated method that\\u2019s called when the [DllImport(...)] is called, that h\", \"andles fixing \\nup all inputs, that delegates to the actual native function, and that fixes up all of\", \" the outputs. That \\nstub is generated at execution time, with the runtime effectively doing reflecti\", \"on emit, generating IL \\ndynamically that\\u2019s then JIT\\u2019d. \\nThere are a variety of downsides to this. Fi\", \"rst, it takes time to generate all that marshalling code, time \\nwhich can then negatively impact use\", \"r experience for things like startup. Second, the nature of its \\nimplementation inhibits various opt\", \"imizations, such as inlining. Third, there are platforms that don\\u2019t \\nallow for JIT\\u2019ing due to the se\", \"curity exposure of allowing for dynamically generated code to then be \\nexecuted (or in the case of N\", \"ative AOT, where there isn\\u2019t a JIT at all). And fourth, it\\u2019s all hidden away \\nmaking it more challen\", \"ging for a developer to really understand what\\u2019s going on. \\nBut what if that logic could all be gene\", \"rated at build time rather than at run time? The cost of \\ngenerating the code would be incurred only\", \" at build time and not on every execution. The code would \\neffectively just end up being user code t\", \"hat has all of the C# compiler\\u2019s and runtime\\u2019s optimizations \\navailable to it. The code, which then \", \"would just be part of the app, would be able to be ahead-of-time \\ncompiled using whatever AOT system\", \" is desirable, whether it be crossgen or Native AOT or some \\nother system. And the code would be ins\", \"pectable, viewable by users to understand exactly what work \\nis being done on their behalf. Sounds p\", \"retty desirable. Sounds magical. Sounds like a job for a Roslyn \\nsource generator, mentioned earlier\", \". \\n.NET 6 included several source generators in the .NET SDK, and .NET 7 doubles down on this effort\", \" \\nincluding several more. One of these is the brand new LibraryImport generator, which provides exac\", \"tly \\nthe magical, desirable solution we were just discussing. \\nLet\\u2019s return to our previous CreatePi\", \"pe example. We\\u2019ll make two small tweaks. We change the \\nattribute from DllImport to LibraryImport, a\", \"nd we change the extern keyword to be partial: \\n[LibraryImport(\\\"kernel32\\\", SetLastError = true)] \\n[r\", \"eturn: MarshalAs(UnmanagedType.Bool)] \\nprivate static unsafe partial bool CreatePipe( \\n    out SafeF\", \"ileHandle hReadPipe, \\n    out SafeFileHandle hWritePipe, \\n    void* lpPipeAttributes, \\n    uint nSiz\", \"e); \\nNow if you\\u2019re following along at home in Visual Studio, try right-clicking on CreatePipe and se\", \"lecting \\nGo to Definition. That might seem a little strange. \\u201cGo to Definition? Isn\\u2019t this the defin\", \"ition?\\u201d This is a \\npartial method, which is a way of declaring something that another partial defini\", \"tion fills in, and in this \\ncase, a source generator in .NET 7 SDK has noticed this method with the \", \"[LibraryImport] attribute \\nand fully generated the entire marshalling stub code in C# that\\u2019s built d\", \"irectly into the assembly. \\nWhile by default that code isn\\u2019t persisted, Visual Studio still enables \", \"you to browse it (and you can \\n \\n84 \\nCHAPTER 7 | Interop \\n \\nopt-in to having it persisted on disk by\", \" adding a \\n<EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles> property into your .csproj)\", \". \\nHere\\u2019s what it currently looks like for that method: \\n[System.CodeDom.Compiler.GeneratedCodeAttri\", \"bute(\\\"Microsoft.Interop.LibraryImportGenerator\\\", \\n\\\"7.0.6.42316\\\")] \\n[System.Runtime.CompilerServices.\", \"SkipLocalsInitAttribute] \\nprivate static unsafe partial bool CreatePipe(out \\nglobal::Microsoft.Win32\", \".SafeHandles.SafeFileHandle hReadPipe, out \\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle hWrit\", \"ePipe, void* lpPipeAttributes, uint \\nnSize) \\n{ \\n    int __lastError; \\n    bool __invokeSucceeded = d\", \"efault; \\n    System.Runtime.CompilerServices.Unsafe.SkipInit(out hReadPipe); \\n    System.Runtime.Com\", \"pilerServices.Unsafe.SkipInit(out hWritePipe); \\n    System.IntPtr __hReadPipe_native = default; \\n   \", \" System.IntPtr __hWritePipe_native = default; \\n    bool __retVal; \\n    int __retVal_native = default\", \"; \\n     \\n    // Setup - Perform required setup. \\n    global::Microsoft.Win32.SafeHandles.SafeFileHan\", \"dle hReadPipe__newHandle = new \\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle(); \\n    global::M\", \"icrosoft.Win32.SafeHandles.SafeFileHandle hWritePipe__newHandle = new \\nglobal::Microsoft.Win32.SafeH\", \"andles.SafeFileHandle(); \\n    try \\n    { \\n        { \\n            System.Runtime.InteropServices.Mars\", \"hal.SetLastSystemError(0); \\n            __retVal_native = __PInvoke(&__hReadPipe_native, &__hWritePi\", \"pe_native, \\nlpPipeAttributes, nSize); \\n            __lastError = System.Runtime.InteropServices.Mars\", \"hal.GetLastSystemError(); \\n        } \\n \\n        __invokeSucceeded = true; \\n     \\n        // Unmarsha\", \"l - Convert native data to managed data. \\n        __retVal = __retVal_native != 0; \\n    } \\n    final\", \"ly \\n    { \\n        if (__invokeSucceeded) \\n        { \\n            // GuaranteedUnmarshal - Convert n\", \"ative data to managed data even in the case \\nof an exception during the non-cleanup phases. \\n       \", \"     System.Runtime.InteropServices.Marshal.InitHandle(hWritePipe__newHandle, \\n__hWritePipe_native);\", \" \\n            hWritePipe = hWritePipe__newHandle; \\n            System.Runtime.InteropServices.Marsha\", \"l.InitHandle(hReadPipe__newHandle, \\n__hReadPipe_native); \\n            hReadPipe = hReadPipe__newHand\", \"le; \\n        } \\n    } \\n \\n    System.Runtime.InteropServices.Marshal.SetLastPInvokeError(__lastError)\", \"; \\n    return __retVal; \\n     \\n    // Local P/Invoke \\n    [System.Runtime.InteropServices.DllImportA\", \"ttribute(\\\"kernel32\\\", EntryPoint = \\n \\n85 \\nCHAPTER 7 | Interop \\n \\n\\\"CreatePipe\\\", ExactSpelling = true)]\", \" \\n    static extern unsafe int __PInvoke(System.IntPtr* hReadPipe, System.IntPtr* hWritePipe, \\nvoid*\", \" lpPipeAttributes, uint nSize); \\n} \\nWith this, you can read exactly the marshalling work that\\u2019s bein\", \"g performed. Two SafeHandle \\ninstances are being allocated and then later after the native function \", \"completes, the \\nMarshal.InitHandle method is used to store the resulting handles into these instance\", \"s (the \\nallocations happen before the native function call, as performing them after the native hand\", \"les have \\nalready been produced increases the chances of a leak if the SafeHandle allocation fails d\", \"ue to an \\nout-of-memory situation). The BOOL to bool conversion happens via a != 0 comparison. And t\", \"he error \\ninformation is captured by calling Marshal.GetLastSystemError() just after the native func\", \"tion call \\nand then Marshal.SetLastPInvokeError(int) just prior to returning. The actual native func\", \"tion call \\nis still implemented with a [DllImport(...)], but now that P/Invoke is blittable and does\", \"n\\u2019t require \\nany stub to be generated by the runtime, as all that work has been handled in this C# c\", \"ode. \\nA sheer ton of work went in to enabling this. I touched on some of it last year in Performance\", \" \\nImprovements in .NET 6, but a significant amount of additional effort has gone into .NET 7 to poli\", \"sh \\nthe design and make the implementation robust, roll it out across all of dotnet/runtime and beyo\", \"nd, \\nand expose the functionality for all C# developers to use: \\n\\u2022 \\nThe LibraryImport generator star\", \"ted its life as an experiment in dotnet/runtimelab. When it was \\nready, dotnet/runtime#59579 brought\", \" 180 commits spanning years of effort into the \\ndotnet/runtime main branch. \\n\\u2022 \\nIn .NET 6, there wer\", \"e almost 3000 [DllImport] uses throughout the core .NET libraries. As of my \\nwriting this, in .NET 7\", \" there are\\u2026 let me search\\u2026 wait for it\\u2026 7 (I was hoping I could say 0, but \\nthere are just a few str\", \"agglers, mostly related to COM interop, still remaining). That\\u2019s not a \\ntransformation that happens \", \"over night. A multitude of PRs went library by library converting \\nfrom the old to the new, such as \", \"dotnet/runtime#62295 and dotnet/runtime#61640 for \\nSystem.Private.CoreLib, dotnet/runtime#61742 and \", \"dotnet/runtime#62309 for the cryptography \\nlibraries, dotnet/runtime#61765 for networking, dotnet/ru\", \"ntime#61996 and \\ndotnet/runtime#61638 for most of the other I/O-related libraries, and a long-tail o\", \"f additional \\nporting in dotnet/runtime#61975, dotnet/runtime#61389, dotnet/runtime#62353, \\ndotnet/r\", \"untime#61990, dotnet/runtime#61949, dotnet/runtime#61805, dotnet/runtime#61741, \\ndotnet/runtime#6118\", \"4, dotnet/runtime#54290, dotnet/runtime#62365, dotnet/runtime#61609, \\ndotnet/runtime#61532, and dotn\", \"et/runtime#54236. \\n\\u2022 \\nSuch porting is significantly easier when there\\u2019s a tool to help automate it. \", \"\\ndotnet/runtime#72819 enables the analyzer and fixer for performing these transformations. \\n:::{cust\", \"om-style=Figure} \\n \\n86 \\nCHAPTER 7 | Interop \\n \\n ::: \\nThere were plenty of other PRs that went into m\", \"aking the LibraryImport generator a reality for .NET 7. \\nTo highlight just a few more, dotnet/runtim\", \"e#63320 introduces a new \\n[DisabledRuntimeMarshalling] attribute that can be specified at the assemb\", \"ly level to disable all of \\nthe runtime\\u2019s built-in marshalling; at that point, the only marshalling \", \"performed as part of interop is \\nthe marshaling done in the user\\u2019s code, e.g. that which is generate\", \"d by [LibraryImport]. Other PRs \\nlike dotnet/runtime#67635 and dotnet/runtime#68173 added new marsha\", \"ling types that encompass \\ncommon marshaling logic and can be referenced from [LibraryImport(...)] u\", \"se to customize how \\nmarshaling is performed (the generator is pattern-based and allows for customiz\", \"ation of marshalling \\nby providing types that implement the right shape, which these types do in sup\", \"port of the most \\ncommon marshalling needs). Really usefully, dotnet/runtime#71989 added support for\", \" marshaling \\n{ReadOnly}Span<T>, such that spans can be used directly in [LibraryImport(...)] method \", \"\\nsignatures, just as arrays can be (examples in dotnet/runtime are available in dotnet/runtime#73256\", \"). \\nAnd dotnet/runtime#69043 consolidated logic to be shared between the runtime\\u2019s marshalling \\nsupp\", \"ort in [DllImport] and the generators support with [LibraryImport]. \\nOne more category of interop-re\", \"lated changes that I think are worth talking about are to do with \\nSafeHandle cleanup. As a reminder\", \", SafeHandle exists to mitigate various issues around managing \\nnative handles and file descriptors.\", \" A native handle or file descriptor is just a memory address or \\nnumber that refers to some owned re\", \"source and which must be cleaned up / closed when done with \\nit. A SafeHandle at its core is just a \", \"managed object that wraps such a value and provides a Dispose \\nmethod and a finalizer for closing it\", \". That way, if you neglect to Dispose of the SafeHandle in order to \\nclose the resource, the resourc\", \"e will still be cleaned up when the SafeHandle is garbage collected and \\nits finalizer eventually ru\", \"n. SafeHandle then also provides some synchronization around that closure, \\ntrying to minimize the p\", \"ossibility that the resource is closed while it\\u2019s still in use. It provides \\nDangerousAddRef and Dan\", \"gerousRelease methods that increment and decrement a ref count, \\nrespectively, and if Dispose is cal\", \"led while the ref count is above zero, the actual releasing of the \\nhandle triggered by Dispose is d\", \"elayed until the ref count goes back to 0. When you pass a \\nSafeHandle into a P/Invoke, the generate\", \"d code for that P/Invoke handles calling DangerousAddRef \\n \\n87 \\nCHAPTER 7 | Interop \\n \\nand Dangerous\", \"Release (and due to the wonders of LibraryImport I\\u2019ve already extolled, you can easily \\nsee that bei\", \"ng done, such as in the previous generated code example). Our code tries hard to clean \\nup after Saf\", \"eHandles deterministically, but it\\u2019s quite easy to accidentally leave some for finalization. \\ndotnet\", \"/runtime#71854 added some debug-only tracking code to SafeHandle to make it easier for \\ndevelopers w\", \"orking in dotnet/runtime (or more specifically, developers using a checked build of the \\nruntime) to\", \" find such issues. When the SafeHandle is constructed, it captures the current stack trace, \\nand if \", \"the SafeHandle is finalized, it dumps that stack trace to the console, making it easy to see \\nwhere \", \"SafeHandles that do end up getting finalized were created, in order to track them down and \\nensure t\", \"hey\\u2019re being disposed of. As is probably evident from that PR touching over 150 files and \\nalmost 10\", \"00 lines of code, there were quite a few places that benefited from clean up. Now to be fair, \\nmany \", \"of these are on exceptional code paths. For example, consider a hypothetical P/Invoke like: \\n[Librar\", \"yImport(\\\"SomeLibrary\\\", SetLastError = true)] \\ninternal static partial SafeFileHandle CreateFile(); \\n\", \"and code that uses it like: \\nSafeFileHandle handle = Interop.CreateFile(); \\nif (handle.IsInvalid) \\n{\", \" \\n    throw new UhOhException(Marshal.GetLastPInvokeError()); \\n} \\nreturn handle; \\nSeems straightforw\", \"ard enough. Except this code will actually leave a SafeHandle for finalization on \\nthe failure path.\", \" It doesn\\u2019t matter that SafeHandle has an invalid handle in it, it\\u2019s still a finalizable \\nobject. To\", \" deal with that, this code would have been more robustly written as: \\nSafeFileHandle handle = Intero\", \"p.CreateFile(); \\nif (handle.IsInvalid) \\n{ \\n    int lastError = Marshal.GetLastPInvokeError(); \\n    h\", \"andle.Dispose(); // or handle.SetHandleAsInvalid() \\n    throw new UhOhException(lastError); \\n} \\nretu\", \"rn handle; \\nThat way, this SafeHandle won\\u2019t create finalization pressure even in the case of failure\", \". Note, as well, \\nthat as part of adding in the Dispose call, I also moved the Marshal.GetLastPInvok\", \"eError() up. \\nThat\\u2019s because calling Dispose on a SafeHandle may end up invoking the SafeHandle\\u2019s \\nR\", \"eleaseHandle method, which the developer of the SafeHandle-derived type will have overridden to \\nclo\", \"se the resource, which typically involves making another P/Invoke. And if that P/Invoke has \\nSetLast\", \"Error=true on it, it can overwrite the very error code for which we\\u2019re about to throw. Hence, \\nwe ac\", \"cess and store the last error immediately after the interop call once we know it failed, then clean \", \"\\nup, and only then throw. All that said, there were a myriad of places in that PR where SafeHandles \", \"\\nwere being left for finalization even on the success path. And that PR wasn\\u2019t alone. \\ndotnet/runtim\", \"e#71991, dotnet/runtime#71854, dotnet/runtime#72116, dotnet/runtime#72189, \\ndotnet/runtime#72222, do\", \"tnet/runtime#72203, and dotnet/runtime#72279 all found and fixed many \\noccurrences of SafeHandles be\", \"ing left for finalization (many thanks to the diagnostics put in place in \\nthe earlier mentioned PR)\", \". \\n \\n88 \\nCHAPTER 7 | Interop \\n \\nOther PRs also accrued to improved interop performance. dotnet/runti\", \"me#70000 from \\n[@huoyaoyuan](https://github.com/huoyaoyuan) rewrote several delegate-related \\u201cFCalls\", \"\\u201d from being \\nimplemented in native code to instead being managed, resulting in less overhead when i\", \"nvoking \\nthese operations that are commonly involved in scenarios involving \\nMarshal.GetDelegateForF\", \"unctionPointer. dotnet/runtime#68694 also moved some trivial \\nfunctionality from native to managed, \", \"as part of relaxing argument validation on the use of pinning \\nhandles. This in turn measurably redu\", \"ced the overhead involved with using GCHandle.Alloc for such \\npinning handles: \\nprivate byte[] _buff\", \"er = new byte[1024]; \\n \\n[Benchmark] \\npublic void PinUnpin() \\n{ \\n    GCHandle.Alloc(_buffer, GCHandle\", \"Type.Pinned).Free(); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nCode Size \\nPinUnpin \\n.NET 6.0 \\n37.11 ns \\n1.00\", \" \\n353 B \\nPinUnpin \\n.NET 7.0 \\n32.17 ns \\n0.87 \\n232 B \\n \\n89 \\nCHAPTER 8 | Threading \\n \\nCHAPTER 8 \\nThread\", \"ing \\nThreading is one of those cross-cutting concerns that impacts every application, such that chan\", \"ges in \\nthe threading space can have a wide-spread impact. This release sees two very substantial ch\", \"anges to \\nthe ThreadPool itself; dotnet/runtime#64834 switches the \\u201cIO pool\\u201d over to using an entire\", \"ly \\nmanaged implementation (whereas previously the IO pool was still in native code even though the \", \"\\nworker pool had been moved entirely to managed in previous releases), and dotnet/runtime#71864 \\nsim\", \"ilarly switches the timer implementation from one based in native to one entirely in managed \\ncode. \", \"Those two changes can impact performance, and the former was demonstrated to on larger \\nhardware, bu\", \"t for the most part that wasn\\u2019t their primary goal. Instead, other PRs have been focused \\non improvi\", \"ng throughput. \\nOne in particular is dotnet/runtime#69386. The ThreadPool has a \\u201cglobal queue\\u201d that \", \"any thread can \\nqueue work into, and then each thread in the pool has its own \\u201clocal queue\\u201d (which a\", \"ny thread can \\ndequeue from but only the owning thread can enqueue into). When a worker needs anothe\", \"r piece of \\nwork to process, it first checks its own local queue, then it checks the global queue, a\", \"nd then only if it \\ncouldn\\u2019t find work in either of those two places, it goes and checks all of the \", \"other threads\\u2019 local \\nqueues to see if it can help lighten their load. As machines scale up to have \", \"more and more cores, and \\nmore and more threads, there\\u2019s more and more contention on these shared qu\", \"eues, and in particular \\non the global queue. This PR addresses this for such larger machines by int\", \"roducing additional global \\nqueues once the machine reaches a certain threshold (32 processors today\", \"). This helps to partition \\naccesses across multiple queues, thereby decreasing contention. \\nAnother\", \" is dotnet/runtime#57885. In order to coordinate threads, when work items were enqueued \\nand dequeue\", \"d, the pool was issuing requests to its threads to let them know that there was work \\navailable to d\", \"o. This, however, often resulted in oversubscription, where more threads than necessary \\nwould race \", \"to try to get work items, especially when the system wasn\\u2019t at full load. That in turn would \\nmanife\", \"st as a throughput regression. This change overhauls how threads are requested, such that only \\none \", \"additional thread is requested at a time, and after that thread has dequeued its first work item, it\", \" \\ncan issue a request for an additional thread if there\\u2019s work remaining, and then that one can issu\", \"e an \\nadditional request, and so on. Here\\u2019s one of our performance tests in our performance test sui\", \"te (I\\u2019ve \\nsimplified it down to remove a bunch of configuration options from the test, but it\\u2019s stil\", \"l accurately \\none of those configurations). At first glance you might think, \\u201chey, this is a perform\", \"ance test about \\nArrayPool, why is it showing up in a threading discussion?\\u201d And, you\\u2019d be right, th\", \"is is a performance \\ntest that was written focused on ArrayPool. However, as mentioned earlier, thre\", \"ading impacts \\neverything, and in this case, that await Task.Yield() in the middle there causes the \", \"remainder of \\nthis method to be queued to the ThreadPool for execution. And because of how the test \", \"is structured, \\ndoing \\u201creal work\\u201d that competes for CPU cycles with thread pool threads all racing t\", \"o get their next \\ntask, it shows a measurable improvement when moving to .NET 7. \\n \\n90 \\nCHAPTER 8 | \", \"Threading \\n \\nprivate readonly byte[][] _nestedArrays = new byte[8][]; \\nprivate const int Iterations \", \"= 100_000; \\n \\nprivate static byte IterateAll(byte[] arr) \\n{ \\n    byte ret = default; \\n    foreach (b\", \"yte item in arr) ret = item; \\n    return ret; \\n} \\n \\n[Benchmark(OperationsPerInvoke = Iterations)] \\np\", \"ublic async Task MultipleSerial() \\n{ \\n    for (int i = 0; i < Iterations; i++) \\n    { \\n        for (\", \"int j = 0; j < _nestedArrays.Length; j++) \\n        { \\n            _nestedArrays[j] = ArrayPool<byte>\", \".Shared.Rent(4096); \\n            _nestedArrays[j].AsSpan().Clear(); \\n        } \\n \\n        await Task\", \".Yield(); \\n \\n        for (int j = _nestedArrays.Length - 1; j >= 0; j--) \\n        { \\n            Ite\", \"rateAll(_nestedArrays[j]); \\n            ArrayPool<byte>.Shared.Return(_nestedArrays[j]); \\n        } \", \"\\n    } \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nMultipleSerial \\n.NET 6.0 \\n14.340 us \\n1.00 \\nMultipleSerial \\n\", \".NET 7.0 \\n9.262 us \\n0.65 \\nThere have been improvements outside of ThreadPool, as well. One notable c\", \"hange is in the handling \\nof AsyncLocal<T>s, in dotnet/runtime#68790. AsyncLocal<T> is integrated ti\", \"ghtly with \\nExecutionContext; in fact, in .NET Core, ExecutionContext is entirely about flowing Asyn\", \"cLocal<T> \\ninstances. An ExecutionContext instance maintains a single field, a map data structure, t\", \"hat stores \\nthe data for all AsyncLocal<T> with data present in that context. Each AsyncLocal<T> has\", \" an object it \\nuses as a key, and any gets or sets on that AsyncLocal<T> manifest as getting the cur\", \"rent \\nExecutionContext, looking up that AsyncLocal<T>\\u2019s key in the context\\u2019s dictionary, and then ei\", \"ther \\nreturning whatever data it finds, or in the case of a setter, creating a new ExecutionContext \", \"with an \\nupdated dictionary and publishing that back. This dictionary thus needs to be very efficien\", \"t for reads \\nand writes, as developers expect AsyncLocal<T> access to be as fast as possible, often \", \"treating it as if \\nit were any other local. So, to optimize these lookups, the representation of tha\", \"t dictionary changes \\nbased on how many AsyncLocal<T>s are represented in this context. For up to th\", \"ree items, dedicated \\nimplementations with fields for each of the three keys and values were used. A\", \"bove that up to around \\n16 elements, an array of key/value pairs was used. And above that, a Diction\", \"ary<,> was used. For the \\nmost part, this has worked well, with the majority of ExecutionContexts be\", \"ing able to represent \\nmany flows with one of the first three types. However, it turns out that four\", \" active AsyncLocal<T> \\ninstances is really common, especially in ASP.NET where ASP.NET infrastructur\", \"e itself uses a couple. \\n \\n91 \\nCHAPTER 8 | Threading \\n \\nSo, this PR took the complexity hit to add a\", \" dedicated type for four key/value pairs, in order to \\noptimize from one to four of them rather than\", \" one to three. While this improves throughput a bit, its \\nmain intent was to improve allocation, whi\", \"ch is does over .NET 6 by ~20%. \\nprivate AsyncLocal<int> asyncLocal1 = new AsyncLocal<int>(); \\npriva\", \"te AsyncLocal<int> asyncLocal2 = new AsyncLocal<int>(); \\nprivate AsyncLocal<int> asyncLocal3 = new A\", \"syncLocal<int>(); \\nprivate AsyncLocal<int> asyncLocal4 = new AsyncLocal<int>(); \\n \\n[Benchmark(Operat\", \"ionsPerInvoke = 4000)] \\npublic void Update() \\n{ \\n    for (int i = 0; i < 1000; i++) \\n    { \\n        \", \"asyncLocal1.Value++; \\n        asyncLocal2.Value++; \\n        asyncLocal3.Value++; \\n        asyncLocal\", \"4.Value++; \\n    } \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nCode Size \\nAllocated \\nAlloc Ratio \\nUpdate \\n.NET \", \"6.0 \\n61.96 ns \\n1.00 \\n1,272 B \\n176 B \\n1.00 \\nUpdate \\n.NET 7.0 \\n61.92 ns \\n1.00 \\n1,832 B \\n144 B \\n0.82 \\nA\", \"nother valuable fix comes for locking in dotnet/runtime#70165. This particular improvement is a bit \", \"\\nharder to demonstrate with benchmarkdotnet, so just try running this program, first on .NET 6 and \\n\", \"then on .NET 7: \\nusing System.Diagnostics; \\n \\nvar rwl = new ReaderWriterLockSlim(); \\nvar tasks = new\", \" Task[100]; \\nint count = 0; \\n \\nDateTime end = DateTime.UtcNow + TimeSpan.FromSeconds(10); \\nwhile (Da\", \"teTime.UtcNow < end) \\n{ \\n    for (int i = 0; i < 100; ++i) \\n    { \\n        tasks[i] = Task.Run(() =>\", \" \\n        { \\n            var sw = Stopwatch.StartNew(); \\n            rwl.EnterReadLock(); \\n         \", \"   rwl.ExitReadLock(); \\n            sw.Stop(); \\n            if (sw.ElapsedMilliseconds >= 10) \\n     \", \"       { \\n                Console.WriteLine(Interlocked.Increment(ref count)); \\n            } \\n     \", \"   }); \\n    } \\n \\n    Task.WaitAll(tasks); \\n} \\n \\n92 \\nCHAPTER 8 | Threading \\n \\nThis is simply spinning\", \" up 100 tasks, each of which enters and exits a read-write lock, waits for them \\nall, and then does \", \"the process over again, for 10 seconds. It also times how long it takes to enter and \\nexit the lock,\", \" and writes a warning if it had to wait for at least 15ms. When I run this on .NET 6, I get \\n~100 oc\", \"currences of it taking >= 10 ms to enter/exit the lock. On .NET 7, I get 0 occurrences. Why the \\ndif\", \"ference? The implementation of ReaderWriterLockSlim has its own spin loop implementation, and \\nthat \", \"spin loop tries to mix together various things to do as it spins, ranging from calling \\nThread.SpinW\", \"ait to Thread.Sleep(0) to Thread.Sleep(1). The issue lies in the Thread.Sleep(1). \\nThat\\u2019s saying \\u201cpu\", \"t this thread to sleep for 1 millisecond\\u201d; however, the operating system has the \\nultimate say on su\", \"ch timings, and on Windows, by default that sleep is going to be closer to 15 \\nmilliseconds (on Linu\", \"x it\\u2019s a bit lower but still quite high). Thus, every time there was enough \\ncontention on the lock \", \"to force it to call Thread.Sleep(1), we\\u2019d incur a delay of at least 15 \\nmilliseconds, if not more. T\", \"he aforementioned PR fixed this by eliminating use of Thread.Sleep(1). \\nOne final threading-related \", \"change to call out: dotnet/runtime#68639. This one is Windows specific. \\nWindows has the concept of \", \"processor groups, each of which can have up to 64 cores in it, and by \\ndefault when a process runs, \", \"it\\u2019s assigned a specific processor group and can only use the cores in \\nthat group. With .NET 7, the\", \" runtime flips its default so that by default it will try to use all processor \\ngroups if possible. \", \"\\n \\n93 \\nCHAPTER 9 | Primitive Types and Numerics \\n \\nCHAPTER 9 \\nPrimitive Types and \\nNumerics \\nWe\\u2019ve l\", \"ooked at code generation and GC, at threading and vectorization, at interop\\u2026 let\\u2019s turn our \\nattenti\", \"on to some of the fundamental types in the system. Primitives like int and bool and double, \\ncore ty\", \"pes like Guid and DateTime, they form the backbone on which everything is built, and every \\nrelease \", \"it\\u2019s exciting to see the improvements that find their way into these types. \\nfloat and double got a \", \"very nice boost in their implementation of parsing (e.g. double.Parse, \\nfloat.TryParse, etc.). dotne\", \"t/runtime#62301 from [@CarlVerret](https://github.com/CarlVerret) \\nsignificantly improves double.Par\", \"se and float.Parse for parsing UTF16 text into floating-point \\nvalues. This is particularly neat bec\", \"ause it\\u2019s based on some relatively recent research from \\n[@lemire](https://github.com/lemire) and [@\", \"CarlVerret](https://github.com/CarlVerret), who used C# \\nwith .NET 5 to implement a very fast implem\", \"entation for parsing floating-point numbers, and that \\nimplementation how now found its way into .NE\", \"T 7! \\nprivate string[] _valuesToParse; \\n \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    using HttpClien\", \"t hc = new HttpClient(); \\n    string text = \\nhc.GetStringAsync(\\\"https://raw.githubusercontent.com/Ca\", \"rlVerret/csFastFloat/1d800237275f759\\nb743b86fcce6680d072c1e834/Benchmark/data/canada.txt\\\").Result; \\n\", \"    var lines = new List<string>(); \\n    foreach (ReadOnlySpan<char> line in text.AsSpan().Enumerate\", \"Lines()) \\n    { \\n        ReadOnlySpan<char> trimmed = line.Trim(); \\n        if (!trimmed.IsEmpty) \\n \", \"       { \\n            lines.Add(trimmed.ToString()); \\n        } \\n    } \\n    _valuesToParse = lines.T\", \"oArray(); \\n} \\n \\n[Benchmark] \\npublic double ParseAll() \\n{ \\n    double total = 0; \\n    foreach (string\", \" s in _valuesToParse) \\n    { \\n        total += double.Parse(s); \\n \\n94 \\nCHAPTER 9 | Primitive Types a\", \"nd Numerics \\n \\n    } \\n    return total; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nParseAll \\n.NET 6.0 \\n26.84 \", \"ms \\n1.00 \\nParseAll \\n.NET 7.0 \\n12.63 ms \\n0.47 \\nbool.TryParse and bool.TryFormat were also improved. d\", \"otnet/runtime#64782 streamlined these \\nimplementations by using BinaryPrimitives to perform fewer wr\", \"ites and reads. For example, instead \\nof TryFormat writing out \\u201cTrue\\u201d by doing: \\ndestination[0] = 'T\", \"'; \\ndestination[1] = 'r'; \\ndestination[2] = 'u'; \\ndestination[3] = 'e'; \\nwhich requires four writes,\", \" it can instead implement the same operation in a single write by doing: \\nBinaryPrimitives.WriteUInt\", \"64LittleEndian(MemoryMarshal.AsBytes(destination), \\n0x65007500720054); // \\\"True\\\" \\nThat 0x65007500720\", \"054 is the numerical value of the four characters in memory as a single ulong. You \\ncan see the impa\", \"ct of these changes with a microbenchmark: \\nprivate bool _value = true; \\nprivate char[] _chars = new\", \" char[] { 'T', 'r', 'u', 'e' }; \\n \\n[Benchmark] public bool ParseTrue() => bool.TryParse(_chars, out \", \"_); \\n[Benchmark] public bool FormatTrue() => _value.TryFormat(_chars, out _); \\nMethod \\nRuntime \\nMean\", \" \\nRatio \\nParseTrue \\n.NET 6.0 \\n7.347 ns \\n1.00 \\nParseTrue \\n.NET 7.0 \\n2.327 ns \\n0.32 \\n \\n \\n \\n \\nFormatTru\", \"e \\n.NET 6.0 \\n3.030 ns \\n1.00 \\nFormatTrue \\n.NET 7.0 \\n1.997 ns \\n0.66 \\nEnum gets several performance boo\", \"sts, as well. For example, when performing an operation like \\nEnum.IsDefined, Enum.GetName, or Enum.\", \"ToString, the implementation consults a cache of all of the \\nvalues defined on the enum. This cache \", \"includes the string name and the value for every defined \\nenumeration in the Enum. It\\u2019s also sorted \", \"by value in an array, so when one of these operations is \\nperformed, the code uses Array.BinarySearc\", \"h to find the index of the relevant entry. The issue with \\nthat is one of overheads. When it comes t\", \"o algorithmic complexity, a binary search is faster than a \\nlinear search; after all, a binary searc\", \"h is O(log N) whereas a linear search is O(N). However, there\\u2019s \\nalso less overhead for every step o\", \"f the algorithm in a linear search, and so for smaller values of N, it \\ncan be much faster to simply\", \" do the simple thing. That\\u2019s what dotnet/runtime#57973 does for enums. \\nFor enums with less than or \", \"equal to 32 defined values, the implementation now just does a linear \\nsearch via the internal SpanH\", \"elpers.IndexOf (the worker routine behind IndexOf on spans, strings, \\n \\n95 \\nCHAPTER 9 | Primitive Ty\", \"pes and Numerics \\n \\nand arrays), and for enums with more than that, it does a SpanHelpers.BinarySear\", \"ch (which is the \\nimplementation for Array.BinarySearch). \\nprivate DayOfWeek[] _days = Enum.GetValue\", \"s<DayOfWeek>(); \\n \\n[Benchmark] \\npublic bool AllDefined() \\n{ \\n    foreach (DayOfWeek day in _days) \\n \", \"   { \\n        if (!Enum.IsDefined(day)) \\n        { \\n            return false; \\n        } \\n    } \\n \\n \", \"   return true; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllDefined \\n.NET 6.0 \\n159.28 ns \\n1.00 \\nAllDefined \", \"\\n.NET 7.0 \\n94.86 ns \\n0.60 \\nEnums also get a boost in conjunction with Nullable<T> and EqualityCompar\", \"er<T>.Default. \\nEqualityComparer<T>.Default caches a singleton instance of an EqualityComparer<T> in\", \"stance \\nreturned from all accesses to Default. That singleton is initialized based on the T in quest\", \"ion, with the \\nimplementation choosing from a multitude of different internal implementations, for e\", \"xample a \\nByteArrayComparer specialized for bytes, a GenericEqualityComparer<T> for Ts that implemen\", \"t \\nIComparable<T>, and so on. The catch-all, for arbitrary types, is an ObjectEqualityComparer<T>. A\", \"s it \\nhappens, nullable enums would end up hitting this catch-all path, which means that every Equal\", \"s call \\nwould box the arguments. dotnet/runtime#68077 fixes this by ensuring nullable enums get mapp\", \"ed \\nto (an existing) specialized comparer for Nullable<T> and simple tweaks its definition to ensure\", \" it can \\nplay nicely with enums. The results highlight just how much unnecessary overhead there was \", \"\\npreviously. \\nprivate DayOfWeek?[] _enums = Enum.GetValues<DayOfWeek>().Select(e => \\n(DayOfWeek?)e).\", \"ToArray(); \\n \\n[Benchmark] \\n[Arguments(DayOfWeek.Saturday)] \\npublic int FindEnum(DayOfWeek value) => \", \"IndexOf(_enums, value); \\n \\nprivate static int IndexOf<T>(T[] values, T value) \\n{ \\n    for (int i = 0\", \"; i < values.Length; i++) \\n    { \\n        if (EqualityComparer<T>.Default.Equals(values[i], value)) \", \"\\n        { \\n            return i; \\n        } \\n    } \\n \\n    return -1; \\n} \\n \\n96 \\nCHAPTER 9 | Primitiv\", \"e Types and Numerics \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nFindEnum \\n.NET 6.0 \\n421.608 ns \\n1.00 \\nFindEnum\", \" \\n.NET 7.0 \\n5.466 ns \\n0.01 \\nNot to be left out, Guid\\u2019s equality operations also get faster, thanks t\", \"o dotnet/runtime#66889 from \\n[@madelson](https://github.com/madelson). The previous implementation o\", \"f Guid split the data into \\nfour 32-bit values and performed 4 int comparisons. With this change, if\", \" the current hardware has \\n128-bit SIMD support, the implementation loads the data from the two guid\", \"s as two vectors and \\nsimply does a single comparison. \\nprivate Guid _guid1 = Guid.Parse(\\\"0aa2511d-2\", \"51a-4764-b374-4b5e259b6d9a\\\"); \\nprivate Guid _guid2 = Guid.Parse(\\\"0aa2511d-251a-4764-b374-4b5e259b6d9\", \"a\\\"); \\n \\n[Benchmark] \\npublic bool GuidEquals() => _guid1 == _guid2; \\nMethod \\nRuntime \\nMean \\nRatio \\nCo\", \"de Size \\nGuidEquals \\n.NET 6.0 \\n2.119 ns \\n1.00 \\n90 B \\nGuidEquals \\n.NET 7.0 \\n1.354 ns \\n0.64 \\n78 B \\nDat\", \"eTime equality is also improved. dotnet/runtime#59857 shaves some overhead off of \\nDateTime.Equals. \", \"DateTime is implemented with a single ulong _dateData field, where the majority \\nof the bits store a\", \" ticks offset from 1/1/0001 12:00am and where each tick is 100 nanoseconds, and \\nwhere the top two b\", \"its describe the DateTimeKind. Thus the public Ticks property returns the value \\nof _dateData but wi\", \"th the top two bits masked out, e.g. _dateData & 0x3FFFFFFFFFFFFFFF. The \\nequality operators were al\", \"l then just comparing one DateTime\\u2019s Ticks against the others, such that we \\neffectively get (dt1._d\", \"ateData & 0x3FFFFFFFFFFFFFFF) == (dt2._dateData & \\n0x3FFFFFFFFFFFFFFF). However, as a micro-optimiza\", \"tion that can instead be expressed more \\nefficiently as ((dt1._dateData ^ dt2._dateData) << 2) == 0.\", \" It\\u2019s difficult to measure the \\ndifference in such tiny operations, but you can see it simply from t\", \"he number of instructions involved, \\nwhere on .NET 6 this produces: \\n; Program.DateTimeEquals() \\n   \", \"    mov       rax,[rcx+8] \\n       mov       rdx,[rcx+10] \\n       mov       rcx,0FFFFFFFFFFFF \\n      \", \" and       rax,rcx \\n       and       rdx,rcx \\n       cmp       rax,rdx \\n       sete      al \\n       \", \"movzx     eax,al \\n       ret \\n; Total bytes of code 34 \\nand on .NET 7 this produces: \\n; Program.Date\", \"TimeEquals() \\n       mov       rax,[rcx+8] \\n       mov       rdx,[rcx+10] \\n       xor       rax,rdx \", \"\\n       shl       rax,2 \\n \\n97 \\nCHAPTER 9 | Primitive Types and Numerics \\n \\n       sete      al \\n    \", \"   movzx     eax,al \\n       ret \\n; Total bytes of code 22 \\nso instead of a mov, and, and, and cmp, w\", \"e get just an xor and a shl. \\nOther operations on DateTime also become more efficient, thanks to dot\", \"net/runtime#72712 from \\n[@SergeiPavlov](https://github.com/SergeiPavlov) and dotnet/runtime#73277 fr\", \"om \\n[@SergeiPavlov](https://github.com/SergeiPavlov). In another case of .NET benefiting from recent\", \" \\nadvancements in research, these PRs implemented the algorithm from Neri and Schneider\\u2019s \\n\\u201cEuclidea\", \"n Affine Functions and Applications to Calendar Algorithms\\u201d in order to improve \\nDateTime.Day, DateT\", \"ime.DayOfYear, DateTime.Month, and DateTime.Year, as well as the internal \\nhelper DateTime.GetDate()\", \" that\\u2019s used by a bunch of other methods like DateTime.AddMonths, \\nUtf8Formatter.TryFormat(DateTime,\", \" ...), DateTime.TryFormat, and DateTime.ToString. \\nprivate DateTime _dt = DateTime.UtcNow; \\nprivate \", \"char[] _dest = new char[100]; \\n \\n[Benchmark] public int Day() => _dt.Day; \\n[Benchmark] public int Mo\", \"nth() => _dt.Month; \\n[Benchmark] public int Year() => _dt.Year; \\n[Benchmark] public bool TryFormat()\", \" => _dt.TryFormat(_dest, out _, \\\"r\\\"); \\nMethod \\nRuntime \\nMean \\nRatio \\nDay \\n.NET 6.0 \\n5.2080 ns \\n1.00 \", \"\\nDay \\n.NET 7.0 \\n2.0549 ns \\n0.39 \\n \\n \\n \\n \\nMonth \\n.NET 6.0 \\n4.1186 ns \\n1.00 \\nMonth \\n.NET 7.0 \\n2.0945 n\", \"s \\n0.51 \\n \\n \\n \\n \\nYear \\n.NET 6.0 \\n3.1422 ns \\n1.00 \\nYear \\n.NET 7.0 \\n0.8200 ns \\n0.26 \\n \\n \\n \\n \\nTryFormat\", \" \\n.NET 6.0 \\n27.6259 ns \\n1.00 \\nTryFormat \\n.NET 7.0 \\n25.9848 ns \\n0.94 \\nSo, we\\u2019ve touched on improvemen\", \"ts to a few types, but the pi\\u00e8ce de r\\u00e9sistance around primitive types \\nin this release is \\u201cgeneric m\", \"ath,\\u201d which impacts almost every primitive type in .NET. There are \\nsignificant improvements here, s\", \"ome which have been in the making for literally over a decade. \\nThere\\u2019s an excellent blog post from \", \"June dedicated just to generic math, so I won\\u2019t go into much \\ndepth here. At a high level, however, \", \"there are now over 30 new interfaces that utilize the new C# 11 \\nstatic abstract interface methods f\", \"unctionality, exposing wide-ranging operations from exponentiation \\nfunctions to trigonometric funct\", \"ions to standard numerical operators, all available via generics, such \\nthat you can write one imple\", \"mentation that operates over these interfaces generically and have your \\n \\n98 \\nCHAPTER 9 | Primitive\", \" Types and Numerics \\n \\ncode applied to any types that implement the interfaces\\u2026 which all of the num\", \"erical types in .NET 7 \\ndo (including not just the primitives but also, for example, BigInteger and \", \"Complex). A preview \\nversion of this feature, including necessary runtime support, language syntax, \", \"C# compiler support, \\ngeneric interfaces, and interface implementations all shipped in .NET 6 and C#\", \" 10, but it wasn\\u2019t \\nsupported for production use, and you had to download an experimental reference \", \"assembly in order \\nto get access. With dotnet/runtime#65731, all of this support moved into .NET 7 a\", \"s supported \\nfunctionality. dotnet/runtime#66748, dotnet/runtime#67453, dotnet/runtime#69391, \\ndotne\", \"t/runtime#69582, dotnet/runtime#69756, and dotnet/runtime#71800 all updated the design \\nand implemen\", \"tation based on feedback from usage in .NET 6 and .NET 7 previews as well as a proper \\nAPI review wi\", \"th our API review team (a process every new API in .NET goes through before it\\u2019s \\nshipped publicly).\", \" dotnet/runtime#67714 added support for user-defined checked operators, a new \\nC# 11 feature that en\", \"ables both unchecked and checked variations of operators to be exposed, with \\nthe compiler picking t\", \"he right one based on the checked context. dotnet/runtime#68096 also added \\nsupport for the new C# 1\", \"1 unsigned right shift operator (>>>). And dotnet/runtime#69651, \\ndotnet/runtime#67939, dotnet/runti\", \"me#73274, dotnet/runtime#71033, dotnet/runtime#71010, \\ndotnet/runtime#68251, dotnet/runtime#68217, a\", \"nd dotnet/runtime#68094 all added large swaths of \\nnew public surface area for various operations, a\", \"ll with highly-efficient managed implementations, in \\nmany cases based on the open source AMD Math L\", \"ibrary. \\nWhile this support is all primarily intended for external consumers, the core libraries do \", \"consume \\nsome of it internally. You can see how these APIs clean up consuming code even while mainta\", \"ining \\nperformance in PRs like dotnet/runtime#68226 and dotnet/runtime#68183, which use the interfac\", \"es \\nto deduplicate a bunch of LINQ code in Enumerable.Sum/Average/Min/Max. There are multiple \\noverl\", \"oads of these methods for int, long, float, double, and decimal. The GitHub summary of the \\ndiffs te\", \"lls the story on how much code was able to be deleted: \\n \\n \\nAnother simple example comes from the ne\", \"w System.Formats.Tar library in .NET 7, which as the \\nname suggests is used for reading and writing \", \"archives in any of multiple tar file formats. The tar file \\nformats include integer values in octal \", \"representation, so the TarReader class needs to parse octal \\nvalues. Some of these values are 32-bit\", \" integers, and some are 64-bit integers. Rather than have two \\nseparate ParseOctalAsUInt32 and Parse\", \"OctalAsUInt64 methods, dotnet/runtime#74281] \\nconsolidated the methods into a single ParseOctal<T> w\", \"ith the constraint where T : struct, \\nINumber<T>. The implementation is then entirely in terms of T \", \"and can be used for either of these \\ntypes (plus any other types meeting the constraints, should tha\", \"t ever be needed). What\\u2019s particularly \\ninteresting about this example is the ParseOctal<T> method i\", \"ncludes use of checked, e.g. value = \\nchecked((value * octalFactor) + T.CreateTruncating(digit));. T\", \"his is only possible because \\nC# 11 includes the aforementioned support for user-defined checked ope\", \"rators, enabling the generic \\nmath interfaces to support both the normal and checked varieties, e.g.\", \" the IMultiplyOperators<,,> \\ninterface contains these methods: \\n \\n99 \\nCHAPTER 9 | Primitive Types an\", \"d Numerics \\n \\nstatic abstract TResult operator *(TSelf left, TOther right); \\nstatic virtual TResult \", \"operator checked *(TSelf left, TOther right) => left * right; \\nand the compiler will pick the approp\", \"riate one based on the context. \\nIn addition to all the existing types that get these interfaces, th\", \"ere are also new types. \\ndotnet/runtime#69204 adds the new Int128 and UInt128 types. As these types \", \"implement all of the \\nrelevant generic math interfaces, they come complete with a huge number of met\", \"hods, over 100 each, \\nall of which are implemented efficiently in managed code. In the future, the a\", \"im is that some set of \\nthese will be optimized further by the JIT and to take advantage of hardware\", \" acceleration. \\nSeveral PRs moved native implementations of these kinds of math operations to manage\", \"d code. \\ndotnet/runtime#63881 from [@am11](https://github.com/am11) did so for Math.Abs and Math.Abs\", \"F \\n(absolute value), and dotnet/runtime#56236 from \\n[@alexcovington](https://github.com/alexcovingto\", \"n) did so for Math.ILogB and MathF.ILogB (base 2 \\ninteger logarithm). The latter\\u2019s implementation is\", \" based on the MUSL libc implementation of the same \\nalgorithm, and in addition to improving performa\", \"nce (in part by avoiding the transition between \\nmanaged and native code, in part by the actual algo\", \"rithm employed), it also enabled deleting two \\ndistinct implementations from native code, one from t\", \"he coreclr side and one from the mono side, \\nwhich is always a nice win from a maintainability persp\", \"ective. \\n[Benchmark] \\n[Arguments(12345.6789)] \\npublic int ILogB(double arg) => Math.ILogB(arg); \\nMet\", \"hod \\nRuntime \\narg \\nMean \\nRatio \\nILogB \\n.NET 6.0 \\n12345.6789 \\n4.056 ns \\n1.00 \\nILogB \\n.NET 7.0 \\n12345.\", \"6789 \\n1.059 ns \\n0.26 \\nOther math operations were also improved in various ways. Math{F}.Truncate was\", \" improved in \\ndotnet/runtime#65014 from [@MichalPetryka](https://github.com/MichalPetryka) by making\", \" it into a \\nJIT intrinsic, such that on Arm64 the JIT could directly emit a frintz instruction. \\ndot\", \"net/runtime#65584 did the same for Max and Min so that the Arm-specific fmax and fmin \\ninstructions \", \"could be used. And several BitConverter APIs were also turned into intrinsics in \\ndotnet/runtime#715\", \"67 in order to enable better code generation in some generic math scenarios. \\ndotnet/runtime#55121 f\", \"rom [@key-moon](https://github.com/key-moon) also improves parsing, but \\nfor BigInteger, and more sp\", \"ecifically for really, really big BigIntegers. The algorithm previously \\nemployed for parsing a stri\", \"ng into a BigInteger was O(N^2) where N is the number of digits, but \\nwhile a larger algorithmic com\", \"plexity than we\\u2019d normally like, it has a low constant overhead and so is \\nstill reasonable for reas\", \"onably-sized values. In contrast, an alternative algorithm is available that runs \\nin O(N * (log N)^\", \"2) time, but with a much higher constant factor involved. That makes is so that it\\u2019s \\nreally only wo\", \"rth switching for really big numbers. Which is what this PR does. It implements the \\nalternative alg\", \"orithm and switches over to it when the input is at least 20,000 digits (so, yes, big). But \\nfor suc\", \"h large numbers, it makes a significant difference. \\n \\n \\n \\n100 \\nCHAPTER 9 | Primitive Types and Nume\", \"rics \\n \\n \\nprivate string _input = string.Concat(Enumerable.Repeat(\\\"1234567890\\\", 100_000)); // \\\"One \\n\", \"miiilliiiion digits\\\" \\n \\n[Benchmark] \\npublic BigInteger Parse() => BigInteger.Parse(_input); \\nMethod \", \"\\nRuntime \\nMean \\nRatio \\nParse \\n.NET 6.0 \\n3.474 s \\n1.00 \\nParse \\n.NET 7.0 \\n1.672 s \\n0.48 \\nAlso related \", \"to BigInteger (and not just for really big ones), dotnet/runtime#35565 from \\n[@sakno](https://github\", \".com/sakno) overhauled much of the internals of BigInteger to be based on \\nspans rather than arrays.\", \" That in turn enabled a fair amount of use of stack allocation and slicing to \\navoid allocation over\", \"heads, while also improving reliability and safety by moving some code away \\nfrom unsafe pointers to\", \" safe spans. The primary performance impact is visible in allocation numbers, \\nand in particular for\", \" operations related to division. \\nprivate BigInteger _bi1 = BigInteger.Parse(string.Concat(Enumerabl\", \"e.Repeat(\\\"9876543210\\\", \\n100))); \\nprivate BigInteger _bi2 = BigInteger.Parse(string.Concat(Enumerable\", \".Repeat(\\\"1234567890\\\", \\n100))); \\nprivate BigInteger _bi3 = BigInteger.Parse(string.Concat(Enumerable.\", \"Repeat(\\\"12345\\\", 10))); \\n \\n[Benchmark] \\npublic BigInteger ModPow() => BigInteger.ModPow(_bi1, _bi2, _\", \"bi3); \\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAlloc Ratio \\nModPow \\n.NET 6.0 \\n1.527 ms \\n1.00 \\n706 B \", \"\\n1.00 \\nModPow \\n.NET 7.0 \\n1.589 ms \\n1.04 \\n50 B \\n0.07 \\n \\n101 \\nCHAPTER 10 | Arrays, Strings, and Spans \", \"\\n \\nCHAPTER 10 \\nArrays, Strings, and Spans \\nWhile there are many forms of computation that can consum\", \"e resources in applications, some of the \\nmost common include processing of data stored in arrays, s\", \"trings, and now spans. Thus you see a \\nfocus in every .NET release on removing as much overhead as p\", \"ossible from such scenarios, while also \\nfinding ways to further optimize the concrete operations de\", \"velopers are commonly performing. \\nLet\\u2019s start with some new APIs that can help make writing more ef\", \"ficient code easier. When examining \\nstring parsing/processing code, it\\u2019s very common to see charact\", \"ers examined for their inclusion in \\nvarious sets. For example, you might see a loop looking for cha\", \"racters that are ASCII digits: \\nwhile (i < str.Length) \\n{ \\n    if (str[i] >= '0' && str[i] <= '9') \\n\", \"    { \\n        i++; \\n    } \\n} \\nor that are ASCII letters: \\nwhile (i < str.Length) \\n{ \\n    if ((str[i\", \"] >= 'a' && str[i] <= 'z') || (str[i] >= 'A' && str[i] <= 'Z')) \\n    { \\n        i++; \\n    } \\n} \\nor o\", \"ther such groups. Interestingly, there\\u2019s wide-spread variation in how such checks are coded, often \\n\", \"depending on how much effort a developer put in to optimizing them, or in some cases likely not \\neve\", \"n recognizing that some amount of performance was being left on the table. For example, that \\nsame A\", \"SCII letter check could instead be written as: \\nwhile (i < str.Length) \\n{ \\n    if ((uint)((c | 0x20)\", \" - 'a') <= 'z' - 'a') \\n    { \\n        i++; \\n    } \\n} \\nwhich while more \\u201cintense\\u201d is also much more c\", \"oncise and more efficient. It\\u2019s taking advantage of a \\nfew tricks. First, rather than having two com\", \"parisons to determine whether the character is greater \\nthan or equal to the lower bound and less th\", \"an or equal to the upper bound, it\\u2019s doing a single \\ncomparison based on the distance between the ch\", \"aracter and the lower bound ((uint)(c - 'a')). If \\n'c' is beyond 'z', then 'c' - 'a' will be larger \", \"than 25, and the comparison will fail. If 'c' is earlier \\n \\n102 \\nCHAPTER 10 | Arrays, Strings, and S\", \"pans \\n \\nthan 'a', then 'c' - 'a' will be negative, and casting it to uint will then cause it to wrap\", \" around to a \\nmassive number, also larger than 25, again causing the comparison to fail. Thus, we\\u2019re\", \" able to pay a \\nsingle additional subtraction to avoid an entire additional comparison and branch, w\", \"hich is almost \\nalways a good deal. The second trick is that | 0x20. The ASCII table has some well-t\", \"hought-out \\nrelationships, including that upper-case 'A' and lower-case 'a' differ by only a single \", \"bit ('A' is \\n0b1000001 and 'a' is 0b1100001). To go from any lowercase ASCII letter to its uppercase\", \" ASCII \\nequivalent, we thus need only to & ~0x20 (to turn off that bit), and to go in the opposite d\", \"irection \\nfrom any uppercase ASCII letter to its lowercase ASCII equivalent, we need only to | 0x20 \", \"(to turn on \\nthat bit). We can take advantage of this in our range check, then, by normalizing our c\", \"har c to be \\nlowercase, such that for the low cost of a bit twiddle, we can achieve both the lowerca\", \"se and \\nuppercase range checks. Of course, those tricks aren\\u2019t something we want every developer to \", \"have to \\nknow and write on each use. Instead, .NET 7 exposes a bunch of new helpers on System.Char t\", \"o \\nencapsulate these common checks, done in an efficient manner. char already had methods like \\nIsDi\", \"git and IsLetter, which provided the more comprehensive Unicode meaning of those monikers \\n(e.g. the\", \"re are ~320 Unicode characters categorized as \\u201cdigits\\u201d). Now in .NET 7, there are also these \\nhelper\", \"s: \\n\\u2022 \\nIsAsciiDigit \\n\\u2022 \\nIsAsciiHexDigit \\n\\u2022 \\nIsAsciiHexDigitLower \\n\\u2022 \\nIsAsciiHexDigitUpper \\n\\u2022 \\nIsAsci\", \"iLetter \\n\\u2022 \\nIsAsciiLetterLower \\n\\u2022 \\nIsAsciiLetterUpper \\n\\u2022 \\nIsAsciiLetterOrDigit \\nThese methods were a\", \"dded by dotnet/runtime#69318, which also employed them in dozens of \\nlocations where such checks wer\", \"e being performed across dotnet/runtime (many of them using less-\\nefficient approaches). \\nAnother ne\", \"w API focused on encapsulating a common pattern is the new \\nMemoryExtensions.CommonPrefixLength meth\", \"od, introduced by dotnet/runtime#67929. This accepts \\neither two ReadOnlySpan<T> instances or a Span\", \"<T> and a ReadOnlySpan<T>, and an optional \\nIEqualityComparer<T>, and returns the number of elements\", \" that are the same at the beginning of \\neach input span. This is useful when you want to know the fi\", \"rst place that two inputs differ. \\ndotnet/runtime#68210 from [@gfoidl](https://github.com/gfoidl) th\", \"en utilized the new Vector128 \\nfunctionality to provide a basic vectorization of the implementation.\", \" As it\\u2019s comparing two sequences \\nand looking for the first place they differ, this implementation u\", \"ses a neat trick, which is to have a \\nsingle method implemented to compare the sequences as bytes. I\", \"f the T being compared is bitwise-\\nequatable and no custom equality comparer is supplied, then it re\", \"interpret-casts the refs from the \\nspans as byte refs, and uses the single shared implementation. \\nY\", \"et another new set of APIs are the IndexOfAnyExcept and LastIndexOfAnyExcept methods, \\nintroduced by\", \" dotnet/runtime#67941 and used in a variety of additional call sites by \\ndotnet/runtime#71146 and do\", \"tnet/runtime#71278. While somewhat of a mouthful, these methods \\nare quite handy. They do what their\", \" name suggests: whereas IndexOf(T value) searches for the first \\n \\n103 \\nCHAPTER 10 | Arrays, Strings\", \", and Spans \\n \\noccurrence of value in the input, and whereas IndexOfAny(T value0, T value1, ...) sea\", \"rches for \\nthe first occurrence of any of value0, value1, etc. in the input, IndexOfAnyExcept(T valu\", \"e) searches \\nfor the first occurrence of something that\\u2019s not equal to value, and similarly IndexOfA\", \"nyExcept(T \\nvalue0, T value1, ...) searches for the first occurrence of something that\\u2019s not equal t\", \"o value0, \\nvalue1, etc. For example, let\\u2019s say you wanted to know whether an array of integers was e\", \"ntirely 0. \\nYou can now write that as: \\nbool allZero = array.AsSpan().IndexOfAnyExcept(0) < 0; \\ndotn\", \"et/runtime#73488 vectorizes this overload, as well. \\nprivate byte[] _zeros = new byte[1024]; \\n \\n[Ben\", \"chmark(Baseline = true)] \\npublic bool OpenCoded() \\n{ \\n    foreach (byte b in _zeros) \\n    { \\n       \", \" if (b != 0) \\n        { \\n            return false; \\n        } \\n    } \\n \\n    return true; \\n} \\n \\n[Benc\", \"hmark] \\npublic bool IndexOfAnyExcept() => _zeros.AsSpan().IndexOfAnyExcept((byte)0) < 0; \\nMethod \\nMe\", \"an \\nRatio \\nOpenCoded \\n370.47 ns \\n1.00 \\nIndexOfAnyExcept \\n23.84 ns \\n0.06 \\nOf course, while new \\u201cindex\", \" of\\u201d variations are helpful, we already have a bunch of such methods, and \\nit\\u2019s important that they \", \"are as efficient as possible. These core IndexOf{Any} methods are used in \\nhuge numbers of places, m\", \"any of which are performance-sensitive, and so every release they get \\nadditional tender-loving care\", \". While PRs like dotnet/runtime#67811 got gains by paying very close \\nattention to the assembly code\", \" being generated (in this case, tweaking some of the checks used on \\nArm64 in IndexOf and IndexOfAny\", \" to achieve better utilization), the biggest improvements here come \\nin places where either vectoriz\", \"ation was added and none was previously employed, or where the \\nvectorization scheme was overhauled \", \"for significant gain. Let\\u2019s start with dotnet/runtime#63285, \\nwhich yields huge improvements for man\", \"y uses of IndexOf and LastIndexOf for \\u201csubstrings\\u201d of bytes \\nand chars. Previously, given a call lik\", \"e str.IndexOf(\\\"hello\\\"), the implementation would essentially \\ndo the equivalent of repeatedly search\", \"ing for the \\u2018h\\u2019, and when an \\u2018h\\u2019 was found, then performing a \\nSequenceEqual to match the remainder.\", \" As you can imagine, however, it\\u2019s very easy to run into cases \\nwhere the first character being sear\", \"ched for is very common, such that you frequently have to break \\nout of the vectorized loop in order\", \" to do the full string comparison. Instead, the PR implements an \\nalgorithm based on SIMD-friendly a\", \"lgorithms for substring searching. Rather than just searching for \\nthe first character, it can inste\", \"ad vectorize a search for both the first and last character at appropriate \\ndistances from each othe\", \"r. In our \\u201chello\\u201d example, in any given input, it\\u2019s much more likely to find an \\n \\n104 \\nCHAPTER 10 |\", \" Arrays, Strings, and Spans \\n \\n\\u2018h\\u2019 than it is to find an \\u2018h\\u2019 followed four characters later by an \\u2018o\", \"\\u2019, and thus this implementation is able \\nto stay within the vectorized loop a lot longer, garnering \", \"many fewer false positives that force it down \\nthe SequenceEqual route. The implementation also hand\", \"les cases where the two characters selected \\nare equal, in which case it\\u2019ll quickly look for another\", \" character that\\u2019s not equal in order to maximize \\nthe efficiency of the search. We can see the impac\", \"t of all of this with a couple of examples: \\nprivate static readonly string s_haystack = new \\nHttpCl\", \"ient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\n \\n[Benchmark] \\n[Ar\", \"guments(\\\"Sherlock\\\")] \\n[Arguments(\\\"elementary\\\")] \\npublic int Count(string needle) \\n{ \\n    ReadOnlySpa\", \"n<char> haystack = s_haystack; \\n    int count = 0, pos; \\n    while ((pos = haystack.IndexOf(needle))\", \" >= 0) \\n    { \\n        haystack = haystack.Slice(pos + needle.Length); \\n        count++; \\n    } \\n \\n \", \"   return count; \\n} \\nThis is pulling down the text to \\u201cThe Adventures of Sherlock Holmes\\u201d from Proje\", \"ct Gutenberg and \\nthen benchmarking using IndexOf to count the occurrences of \\u201cSherlock\\u201d and \\u201celemen\", \"tary\\u201d in the \\ntext. On my machine, I get results like this: \\nMethod \\nRuntime \\nneedle \\nMean \\nRatio \\nC\", \"ount \\n.NET 6.0 \\nSherlock \\n43.68 us \\n1.00 \\nCount \\n.NET 7.0 \\nSherlock \\n48.33 us \\n1.11 \\n \\n \\n \\n \\n \\nCount\", \" \\n.NET 6.0 \\nelementary \\n1,063.67 us \\n1.00 \\nCount \\n.NET 7.0 \\nelementary \\n56.04 us \\n0.05 \\nFor \\u201cSherloc\", \"k\\u201d, the performance is actually a bit worse in .NET 7 than in .NET 6; not much, but a \\nmeasurable 10\", \"%. That\\u2019s because there are very few capital 'S' characters in the source text, 841 to be \\nexact, ou\", \"t of 593,836 characters in the document. At only 0.1% density of the starting character, the \\nnew al\", \"gorithm doesn\\u2019t bring much benefit, as the existing algorithm that searched for the first \\ncharacter\", \" alone captures pretty much all of the possible vectorization gains to be had, and we do pay \\na bit \", \"of overhead in doing a search for both the 'S' and the 'k', whereas previously we\\u2019d have only \\nsearc\", \"hed for the 'S'. In contrast, though, there are 54,614 'e' characters in the document, so almost \\n10\", \"% of the source. In that case, .NET 7 is 20x faster than .NET 6, taking 53us on .NET 7 to count all \", \"the \\n'e'\\u2019s vs 1084us on .NET 6. In this case, the new scheme yields immense gains, by vectorizing a \", \"search \\nfor both the 'e' and a 'y' at the specific distance away, a combination that is much, much l\", \"ess \\nfrequent. This is one of those situations where overall there are on average huge observed gain\", \"s even \\nthough we can see small regressions for some specific inputs. \\n \\n105 \\nCHAPTER 10 | Arrays, S\", \"trings, and Spans \\n \\nAnother example of significantly changing the algorithm employed is dotnet/runt\", \"ime#67758, which \\nenables some amount of vectorization to be applied to IndexOf(\\\"...\\\", \\nStringCompar\", \"ison.OrdinalIgnoreCase). Previously, this operation was implemented with a fairly \\ntypical substring\", \" search, walking the input string and at every location doing an inner loop to \\ncompare the target s\", \"tring, except performing a ToUpper on every character in order to do it in a case-\\ninsensitive manne\", \"r. Now with this PR, which is based on approaches previously used by Regex, if the \\ntarget string be\", \"gins with an ASCII character, the implementation can use IndexOf (if the character isn\\u2019t \\nan ASCII l\", \"etter) or IndexOfAny (if the character is an ASCII letter) to quickly jump ahead to the first \\npossi\", \"ble location of a match. Let\\u2019s take the exact same benchmark as we just looked at, but tweaked \\nto u\", \"se OrdinalIgnoreCase: \\nprivate static readonly string s_haystack = new \\nHttpClient().GetStringAsync(\", \"\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\n \\n[Benchmark] \\n[Arguments(\\\"Sherlock\\\")] \\n\", \"[Arguments(\\\"elementary\\\")] \\npublic int Count(string needle) \\n{ \\n    ReadOnlySpan<char> haystack = s_h\", \"aystack; \\n    int count = 0, pos; \\n    while ((pos = haystack.IndexOf(needle, StringComparison.Ordin\", \"alIgnoreCase)) >= 0) \\n    { \\n        haystack = haystack.Slice(pos + needle.Length); \\n        count+\", \"+; \\n    } \\n \\n    return count; \\n} \\nHere, both words are about 4x faster on .NET 7 than they were on \", \".NET 6: \\nMethod \\nRuntime \\nneedle \\nMean \\nRatio \\nCount \\n.NET 6.0 \\nSherlock \\n2,113.1 us \\n1.00 \\nCount \\n.\", \"NET 7.0 \\nSherlock \\n467.3 us \\n0.22 \\n \\n \\n \\n \\n \\nCount \\n.NET 6.0 \\nelementary \\n2,325.6 us \\n1.00 \\nCount \\n.\", \"NET 7.0 \\nelementary \\n638.8 us \\n0.27 \\nas we\\u2019re now doing a vectorized IndexOfAny('S', 's') or IndexOf\", \"Any('E', 'e') rather than \\nmanually walking each character and comparing it. (dotnet/runtime#73533 u\", \"ses the same approach \\nnow for handling IndexOf(char, StringComparison.OrdinalIgnoreCase).) \\nAnother\", \" example comes from dotnet/runtime#67492 from [@gfoidl](https://github.com/gfoidl). It \\nupdates Memo\", \"ryExtensions.Contains with the approach we discussed earlier for handling the \\nleftover elements at \", \"the end of vectorized operation: process one last vector\\u2019s worth of data, even if it \\nmeans duplicat\", \"ing some work already done. This particularly helps for smaller inputs where the \\nprocessing time mi\", \"ght otherwise be dominated by the serial handling of those leftovers. \\nprivate byte[] _data = new by\", \"te[95]; \\n \\n \\n106 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\n[Benchmark] \\npublic bool Contains() => \", \"_data.AsSpan().Contains((byte)1); \\nMethod \\nRuntime \\nMean \\nRatio \\nContains \\n.NET 6.0 \\n15.115 ns \\n1.00\", \" \\nContains \\n.NET 7.0 \\n2.557 ns \\n0.17 \\ndotnet/runtime#60974 from [@alexcovington](https://github.com/\", \"alexcovington) broadens the \\nimpact of IndexOf. Prior to this PR, IndexOf was vectorized for one and\", \" two-byte sized primitive \\ntypes, but this PR extends it as well to four and eight-byte sized primit\", \"ives. As with most of the other \\nvectorized implementations, it checks whether the T is bitwise-equa\", \"table, which is important for the \\nvectorization as it\\u2019s only looking at the bits in memory and not \", \"paying attention to any Equals \\nimplementation that might be defined on the type. In practice today,\", \" that means this is limited to just \\na handful of types of which the runtime has intimate knowledge \", \"(Boolean, Byte, SByte, UInt16, Int16, \\nChar, UInt32, Int32, UInt64, Int64, UIntPtr, IntPtr, Rune, an\", \"d enums), but in theory it could be \\nextended in the future. \\nprivate int[] _data = new int[1000]; \\n\", \" \\n[Benchmark] \\npublic int IndexOf() => _data.AsSpan().IndexOf(42); \\nMethod \\nRuntime \\nMean \\nRatio \\nIn\", \"dexOf \\n.NET 6.0 \\n252.17 ns \\n1.00 \\nIndexOf \\n.NET 7.0 \\n78.82 ns \\n0.31 \\nOne final interesting IndexOf-r\", \"elated optimization. string has long had \\nIndexOf/IndexOfAny/LastIndexOf/LastIndexOfAny, and obvious\", \"ly for string it\\u2019s all about \\nprocessing chars. When ReadOnlySpan<T> and Span<T> came on the scene, \", \"MemoryExtensions was \\nadded to provide extension methods for spans and friends, including such \\nInde\", \"xOf/IndexOfAny/LastIndexOf/LastIndexOfAny methods. But for spans, this is about more than \\njust char\", \", and so MemoryExtensions grew its own set of implementations largely separate from \\nstring\\u2019s. Over \", \"the years, MemoryExtensions implementations have specialized more and more types, \\nbut in particular\", \" byte and char, such that over time string\\u2019s implementations have mostly been \\nreplaced by delegatio\", \"n into the same implementation as MemoryExtensions uses. However, \\nIndexOfAny and LastIndexOfAny had\", \" been unification holdouts, each in its own direction. \\nstring.IndexOfAny did delegate to the same i\", \"mplementation as MemoryExtensions.IndexOfAny for \\n1-5 values being searched for, but for more than 5\", \" values, string.IndexOfAny used a \\u201cprobabilistic \\nmap,\\u201d essentially a Bloom filter. It creates a 256\", \"-bit table, and quickly sets bits in that table based on \\nthe values being searched for (essentially\", \" hashing them, but with a trivial hash function). Then it \\niterates through the input, and rather th\", \"an checking every input character against every one of the \\ntarget values, it instead first looks up\", \" the input character in the table. If the corresponding bit isn\\u2019t set, \\nit knows the input character\", \" doesn\\u2019t match any of the target values. If the corresponding bit is set, \\nthen it proceeds to compa\", \"re the input character against each of the target values, with a high \\nprobability of it being one o\", \"f them. MemoryExtensions.IndexOfAny lacked such a filter for more than \\n5 values. Conversely, string\", \".LastIndexOfAny didn\\u2019t provide any vectorization for multiple target \\nvalues, whereas MemoryExtensio\", \"ns.LastIndexOfAny vectorized two and three target values. As of \\n \\n107 \\nCHAPTER 10 | Arrays, Strings\", \", and Spans \\n \\ndotnet/runtime#63817, all of these are now unified, such that both string and MemoryE\", \"xtensions \\nget the best of what the other had. \\nprivate readonly char[] s_target = new[] { 'z', 'q' \", \"}; \\nconst string Sonnet = \\\"\\\"\\\" \\n    Shall I compare thee to a summer's day? \\n    Thou art more lovely\", \" and more temperate: \\n    Rough winds do shake the darling buds of May, \\n    And summer's lease hath\", \" all too short a date; \\n    Sometime too hot the eye of heaven shines, \\n    And often is his gold co\", \"mplexion dimm'd; \\n    And every fair from fair sometime declines, \\n    By chance or nature's changin\", \"g course untrimm'd; \\n    But thy eternal summer shall not fade, \\n    Nor lose possession of that fai\", \"r thou ow'st; \\n    Nor shall death brag thou wander'st in his shade, \\n    When in eternal lines to t\", \"ime thou grow'st: \\n    So long as men can breathe or eyes can see, \\n    So long lives this, and this\", \" gives life to thee. \\n    \\\"\\\"\\\"; \\n \\n[Benchmark] \\npublic int LastIndexOfAny() => Sonnet.LastIndexOfAny(\", \"s_target); \\n \\n[Benchmark] \\npublic int CountLines() \\n{ \\n    int count = 0; \\n    foreach (ReadOnlySpan\", \"<char> _ in Sonnet.AsSpan().EnumerateLines()) \\n    { \\n        count++; \\n    } \\n \\n    return count; \\n\", \"} \\nMethod \\nRuntime \\nMean \\nRatio \\nLastIndexOfAny \\n.NET 6.0 \\n443.29 ns \\n1.00 \\nLastIndexOfAny \\n.NET 7.0\", \" \\n31.79 ns \\n0.07 \\n \\n \\n \\n \\nCountLines \\n.NET 6.0 \\n1,689.66 ns \\n1.00 \\nCountLines \\n.NET 7.0 \\n1,461.64 ns\", \" \\n0.86 \\nThat same PR also cleans up uses of the IndexOf family, and in particular around uses that a\", \"re \\nchecking for containment rather than the actual index of a result. The IndexOf family of methods\", \" \\nreturn a non-negative value when an element is found, and otherwise return -1. That means when \\nch\", \"ecking whether an element was found, code can use either >= 0 or != -1, and when checking \\nwhether a\", \"n element wasn\\u2019t found, code can use either < 0 or == -1. It turns out that the code \\ngenerated for \", \"comparisons against 0 is ever so slightly more efficient than comparisons generated \\nagainst -1, and\", \" this isn\\u2019t something the JIT can itself substitute without the IndexOf methods being \\nintrinsics su\", \"ch that the JIT can understand the semantics of the return value. Thus, for consistency and \\na small\", \" perf gain, all relevant call sites were switched to compare against 0 instead of against -1. \\n \\n108\", \" \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nSpeaking of call sites, one of the great things about h\", \"aving highly optimized IndexOf methods is \\nusing them in all the places that can benefit, removing t\", \"he maintenance impact of open-coded \\nreplacements while also reaping the perf wins. dotnet/runtime#6\", \"3913 used IndexOf inside of \\nStringBuilder.Replace to speed up the search for the next character to \", \"be replaced: \\nprivate StringBuilder _builder = new StringBuilder(Sonnet); \\n \\n[Benchmark] \\npublic voi\", \"d Replace() \\n{ \\n    _builder.Replace('?', '!'); \\n    _builder.Replace('!', '?'); \\n} \\nMethod \\nRuntime\", \" \\nMean \\nRatio \\nReplace \\n.NET 6.0 \\n1,563.69 ns \\n1.00 \\nReplace \\n.NET 7.0 \\n70.84 ns \\n0.04 \\ndotnet/runti\", \"me#60463 from [@nietras](https://github.com/nietras) used IndexOfAny in \\nStringReader.ReadLine to se\", \"arch for '\\\\r' and '\\\\n' line ending characters, which results in some \\nsubstantial throughput gains e\", \"ven with the allocation and copy that is inherent to the method\\u2019s \\ndesign: \\n[Benchmark] \\npublic void\", \" ReadAllLines() \\n{ \\n    var reader = new StringReader(Sonnet); \\n    while (reader.ReadLine() != null\", \") ; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nReadAllLines \\n.NET 6.0 \\n947.8 ns \\n1.00 \\nReadAllLines \\n.NET 7.0\", \" \\n385.7 ns \\n0.41 \\nAnd dotnet/runtime#70176 cleaned up a plethora of additional uses. \\nFinally on the\", \" IndexOf front, as noted, a lot of time and energy over the years has gone into \\noptimizing these me\", \"thods. In previous releases, some of that energy has been in the form of using \\nhardware intrinsics \", \"directly, e.g. having an SSE2 code path and an AVX2 code path and an AdvSimd \\ncode path. Now that we\", \" have Vector128<T> and Vector256<T>, many such uses can be simplified \\n(e.g. avoiding the duplicatio\", \"n between an SSE2 implementation and an AdvSimd implementation) \\nwhile still maintaining as good or \", \"even better performance and while automatically supporting \\nvectorization on other platforms with th\", \"eir own intrinsics, like WebAssembly. dotnet/runtime#73481, \\ndotnet/runtime#73556, dotnet/runtime#73\", \"368, dotnet/runtime#73364, dotnet/runtime#73064, and \\ndotnet/runtime#73469 all contributed here, in \", \"some cases incurring meaningful throughput gains: \\n[Benchmark] \\npublic int IndexOfAny() => Sonnet.As\", \"Span().IndexOfAny(\\\"!.<>\\\"); \\n \\n \\n \\n109 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nMethod \\nRuntime \\nM\", \"ean \\nRatio \\nIndexOfAny \\n.NET 6.0 \\n52.29 ns \\n1.00 \\nIndexOfAny \\n.NET 7.0 \\n40.17 ns \\n0.77 \\nThe IndexOf \", \"family is just one of many on string/MemoryExtensions that has seen dramatic \\nimprovements. Another \", \"are the SequenceEquals family, including Equals, StartsWith, and EndsWith. \\nOne of my favorite chang\", \"es in the whole release is dotnet/runtime#65288 and is squarely in this area. \\nIt\\u2019s very common to s\", \"ee calls to methods like StartsWith with a constant string argument, e.g. \\nvalue.StartsWith(\\\"https:/\", \"/\\\"), value.SequenceEquals(\\\"Key\\\"), etc. These methods are now \\nrecognized by the JIT, which can now a\", \"utomatically unroll the comparison and compare more than \\none char at a time, e.g. doing a single re\", \"ad of four chars as a long and a single comparison of that \\nlong against the expected combination of\", \" those four chars. The result is beautiful. Making it even \\nbetter is dotnet/runtime#66095, which ad\", \"ds to this support for OrdinalIgnoreCase. Remember those \\nASCII bit twiddling tricks discussed a bit\", \" earlier with char.IsAsciiLetter and friends? The JIT now \\nemploys the same trick as part of this un\", \"rolling, so if you do that same \\nvalue.StartsWith(\\\"https://\\\") but instead as value.StartsWith(\\\"https\", \"://\\\", \\nStringComparison.OrdinalIgnoreCase), it will recognize that the whole comparison string is AS\", \"CII \\nand will OR in the appropriate mask on both the comparison constant and on the read data from t\", \"he \\ninput in order to perform the comparison in a case-insensitive manner. \\nprivate string _value = \", \"\\\"https://dot.net\\\"; \\n \\n[Benchmark] \\npublic bool IsHttps_Ordinal() => _value.StartsWith(\\\"https://\\\", St\", \"ringComparison.Ordinal); \\n \\n[Benchmark] \\npublic bool IsHttps_OrdinalIgnoreCase() => _value.StartsWit\", \"h(\\\"https://\\\", \\nStringComparison.OrdinalIgnoreCase); \\nMethod \\nRuntime \\nMean \\nRatio \\nIsHttps_Ordinal \\n\", \".NET 6.0 \\n4.5634 ns \\n1.00 \\nIsHttps_Ordinal \\n.NET 7.0 \\n0.4873 ns \\n0.11 \\n \\n \\n \\n \\nIsHttps_OrdinalIgnore\", \"Case \\n.NET 6.0 \\n6.5654 ns \\n1.00 \\nIsHttps_OrdinalIgnoreCase \\n.NET 7.0 \\n0.5577 ns \\n0.08 \\nInterestingly\", \", since .NET 5 the code generated by RegexOptions.Compiled would perform similar \\nunrolling when com\", \"paring sequences of multiple characters, and when the source generator was \\nadded in .NET 7, it also\", \" learned how to do this. However, the source generator has problems with such \\nan optimization, due \", \"to endianness. The constants being compared against are subject to byte \\nordering issues, such that \", \"the source generator would need to emit code that could handle running \\non either little-endian or b\", \"ig-endian machines. The JIT has no such problem, as it\\u2019s generating the \\ncode on the same machine on\", \" which the code will execute (and in scenarios where it\\u2019s being used to \\ngenerate code ahead of time\", \", the entirety of that code is already tied to a particular architecture). By \\nmoving this optimizat\", \"ion into the JIT, the corresponding code could be deleted from \\nRegexOptions.Compiled and the regex \", \"source generator, which then also benefits from producing \\n \\n110 \\nCHAPTER 10 | Arrays, Strings, and \", \"Spans \\n \\nmuch easier to read code utilizing StartsWith that\\u2019s just as fast (dotnet/runtime#65222 and\", \" \\ndotnet/runtime#66339). Wins all around. (This could only be removed from RegexOptions.Compiled \\naf\", \"ter dotnet/runtime#68055, which fixed the ability for the JIT to recognize these string literals in \", \"\\nDynamicMethods, which RegexOptions.Compiled uses with reflection emit to spit out the IL for the \\nr\", \"egex being compiled.) \\nStartsWith and EndsWith have improved in other ways. dotnet/runtime#63734 (im\", \"proved further by \\ndotnet/runtime#64530) added another really interesting JIT-based optimization, bu\", \"t to understand it, \\nwe need to understand string\\u2019s internal layout. string is essentially represent\", \"ed in memory as an \\nint length followed by that many chars plus a null terminator char. The actual S\", \"ystem.String class \\nrepresents this in C# as an int _stringLength field followed by a char _firstCha\", \"r field, such that \\n_firstChar indeed lines up with the first character of the string, or the null t\", \"erminator if the string is \\nempty. Internally in System.Private.CoreLib, and in particular in method\", \"s on string itself, code will \\noften refer to _firstChar directly when the first character needs to \", \"be consulted, as it\\u2019s typically faster \\nto do that than to use str[0], in particular because there a\", \"re no bounds checks involved and the \\nstring\\u2019s length generally needn\\u2019t be consulted. Now, consider \", \"a method like public bool \\nStartsWith(char value) on string. In .NET 6, the implementation was: \\nret\", \"urn Length != 0 && _firstChar == value; \\nwhich given what I just described makes sense: if the Lengt\", \"h is 0, then the string doesn\\u2019t begin with \\nthe specified character, and if Length is not 0, then we\", \" can just compare the value against \\n_firstChar. But, why is that Length check even needed at all? C\", \"ouldn\\u2019t we just do return \\n_firstChar == value;? That will avoid the additional comparison and branc\", \"h, and it will work just \\nfine\\u2026 unless the target character is itself '\\\\0', in which case we could g\", \"et false positives on the result. \\nNow to this PR. The PR introduces an internal JIT intrinsinc Runt\", \"imeHelpers.IsKnownConstant, which \\nthe JIT will substitute with true if the containing method is inl\", \"ined and the argument passed to \\nIsKnownConstant is then seen to be a constant. In such cases, the i\", \"mplementation can rely on other \\nJIT optimizations kicking in and optimizing various code in the met\", \"hod, effectively enabling a \\ndeveloper to write two different implementations, one when the argument\", \" is known to be a constant \\nand one when not. With that in hand, the PR is able to optimize StartsWi\", \"th as follows: \\npublic bool StartsWith(char value) \\n{ \\n    if (RuntimeHelpers.IsKnownConstant(value)\", \" && value != '\\\\0') \\n        return _firstChar == value; \\n \\n    return Length != 0 && _firstChar == v\", \"alue; \\n} \\nIf the value parameter isn\\u2019t a constant, then IsKnownConstant will be substituted with fal\", \"se, the \\nentire starting if block will be eliminated, and the method will be left exactly was it was\", \" before. But, if \\nthis method gets inlined and the value was actually a constant, then the value != \", \"'\\\\0' condition will \\nalso be evaluatable at JIT-compile-time. If the value is in fact '\\\\0', well, ag\", \"ain that whole if block will \\nbe eliminated and we\\u2019re no worse off. But in the common case where the\", \" value isn\\u2019t null, the entire \\nmethod will end up being compiled as if it were: \\nreturn _firstChar =\", \"= ConstantValue; \\n \\n111 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nand we\\u2019ve saved ourselves a read\", \" of the string\\u2019s length, a comparison, and a branch. \\ndotnet/runtime#69038 then employs a similar te\", \"chnique for EndsWith. \\nprivate string _value = \\\"https://dot.net\\\"; \\n \\n[Benchmark] \\npublic bool Starts\", \"With() => \\n    _value.StartsWith('a') || \\n    _value.StartsWith('b') || \\n    _value.StartsWith('c') \", \"|| \\n    _value.StartsWith('d') || \\n    _value.StartsWith('e') || \\n    _value.StartsWith('f') || \\n   \", \" _value.StartsWith('g') || \\n    _value.StartsWith('i') || \\n    _value.StartsWith('j') || \\n    _value\", \".StartsWith('k') || \\n    _value.StartsWith('l') || \\n    _value.StartsWith('m') || \\n    _value.Starts\", \"With('n') || \\n    _value.StartsWith('o') || \\n    _value.StartsWith('p'); \\nMethod \\nRuntime \\nMean \\nRat\", \"io \\nStartsWith \\n.NET 6.0 \\n8.130 ns \\n1.00 \\nStartsWith \\n.NET 7.0 \\n1.653 ns \\n0.20 \\n(Another example of \", \"IsKnownConstant being used comes from dotnet/runtime#64016, which uses it \\nto improve Math.Round whe\", \"n a MidpointRounding mode is specified. Call sites to this almost always \\nexplicitly specify the enu\", \"m value as a constant, which then allows the JIT to specialize the code \\ngeneration for the method t\", \"o the specific mode being used; that in turn, for example, enables a \\nMath.Round(..., MidpointRoundi\", \"ng.AwayFromZero) call on Arm64 to be lowered to a single frinta \\ninstruction.) \\nEndsWith was also im\", \"proved in dotnet/runtime#72750, and specifically for when \\nStringComparison.OrdinalIgnoreCase is spe\", \"cified. This simple PR just switched which internal \\nhelper method was used to implement this method\", \", taking advantage of one that is sufficient for the \\nneeds of this method and that has lower overhe\", \"ads. \\n[Benchmark] \\n[Arguments(\\\"System.Private.CoreLib.dll\\\", \\\".DLL\\\")] \\npublic bool EndsWith(string ha\", \"ystack, string needle) => \\n    haystack.EndsWith(needle, StringComparison.OrdinalIgnoreCase); \\nMetho\", \"d \\nRuntime \\nMean \\nRatio \\nEndsWith \\n.NET 6.0 \\n10.861 ns \\n1.00 \\nEndsWith \\n.NET 7.0 \\n5.385 ns \\n0.50 \\nFi\", \"nally, dotnet/runtime#67202 and dotnet/runtime#73475 employ Vector128<T> and Vector256<T> \\nto replac\", \"e direct hardware intrinsics usage, just as was previously shown for various IndexOf methods, \\nbut h\", \"ere for SequenceEqual and SequenceCompareTo, respectively. \\n \\n112 \\nCHAPTER 10 | Arrays, Strings, and\", \" Spans \\n \\nAnother method that\\u2019s seem some attention in .NET 7 is MemoryExtensions.Reverse (and \\nArra\", \"y.Reverse as it shares the same implementation), which performs an in-place reversal of the \\ntarget \", \"span. dotnet/runtime#64412 from [@alexcovington](https://github.com/alexcovington) \\nprovides a vecto\", \"rized implementation via direct use of AVX2 and SSSE3 hardware intrinsics, with \\ndotnet/runtime#7278\", \"0 from [@SwapnilGaikwad](https://github.com/SwapnilGaikwad) following up to \\nadd an AdvSimd intrinsi\", \"cs implementation for Arm64. (There was an unintended regression \\nintroduced by the original vectori\", \"zation change, but that was fixed by dotnet/runtime#70650.) \\nprivate char[] text = \\\"Free. Cross-plat\", \"form. Open source.\\\\r\\\\nA developer platform for \\nbuilding all your apps.\\\".ToCharArray(); \\n \\n[Benchmar\", \"k] \\npublic void Reverse() => Array.Reverse(text); \\nMethod \\nRuntime \\nMean \\nRatio \\nReverse \\n.NET 6.0 \\n\", \"21.352 ns \\n1.00 \\nReverse \\n.NET 7.0 \\n9.536 ns \\n0.45 \\nString.Split also saw vectorization improvements\", \" in dotnet/runtime#64899 from \\n[@yesmey](https://github.com/yesmey). As with some of the previously \", \"discussed PRs, it switched the \\nexisting usage of SSE2 and SSSE3 hardware intrinsics over to the new\", \" Vector128<T> helpers, which \\nimproved upon the existing implementation while also implicitly adding\", \" vectorization support for \\nArm64. \\nConverting various formats of strings is something many applicat\", \"ions and services do, whether that\\u2019s \\nconverting from UTF8 bytes to and from string or formatting an\", \"d parsing hex values. Such \\noperations have also improved in a variety of ways in .NET 7. Base64-enc\", \"oding, for example, is a way \\nof representing arbitrary binary data (think byte[]) across mediums th\", \"at only support text, encoding \\nbytes into one of 64 different ASCII characters. Multiple APIs in .N\", \"ET implement this encoding. For \\nconverting between binary data represented as ReadOnlySpan<byte> an\", \"d UTF8 (actually ASCII) \\nencoded data also represented as ReadOnlySpan<byte>, the System.Buffers.Tex\", \"t.Base64 type \\nprovides EncodeToUtf8 and DecodeFromUtf8 methods. These were vectorized several relea\", \"ses ago, \\nbut they were further improved in .NET 7 via dotnet/runtime#70654 from \\n[@a74nh](https://g\", \"ithub.com/a74nh), which converted the SSSE3-based implementation to use \\nVector128<T> (which in turn\", \" implicitly enabled vectorization on Arm64). However, for converting \\nbetween arbitrary binary data \", \"represented as ReadOnlySpan<byte>/byte[] and \\nReadOnlySpan<char>/char[]/string, the System.Convert t\", \"ype exposes multiple methods, e.g. \\nConvert.ToBase64String, and these methods historically were not \", \"vectorized. That changes in .NET \\n7, where dotnet/runtime#71795 and dotnet/runtime#73320 vectorize t\", \"he ToBase64String, \\nToBase64CharArray, and TryToBase64Chars methods. The way they do this is interes\", \"ting. Rather than \\neffectively duplicating the vectorization implementation from Base64.EncodeToUtf8\", \", they instead \\nlayer on top of EncodeToUtf8, calling it to encode the input byte data into an outpu\", \"t Span<byte>. \\nThen, then they \\u201cwiden\\u201d those bytes into chars (remember, Base64-encoded data is a se\", \"t of ASCII \\nchars, so going from these bytes to chars entails adding just a 0 byte onto each element\", \"). That \\nwidening can itself easily be done in a vectorized manner. The other interesting thing abou\", \"t this \\nlayering is it doesn\\u2019t actually require separate intermediate storage for the encoded bytes.\", \" The \\nimplementation can perfectly compute the number of resulting characters for encoding X bytes i\", \"nto Y \\n \\n113 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nBase64 characters (there\\u2019s a formula), and \", \"the implementation can either allocate that final space \\n(e.g. in the case of ToBase64CharArray) or \", \"ensure the provided space is sufficient (e.g. in the case of \\nTryToBase64Chars). And since we know t\", \"he initial encoding will require exactly half as many bytes, we \\ncan encode into that same space (wi\", \"th the destination span reinterpreted as a byte span rather than \\nchar span), and then widen \\u201cin pla\", \"ce\\u201d: walk from the end of the bytes and the end of the char space, \\ncopying the bytes into the desti\", \"nation. \\nprivate byte[] _data = Encoding.UTF8.GetBytes(\\\"\\\"\\\" \\n    Shall I compare thee to a summer's d\", \"ay? \\n    Thou art more lovely and more temperate: \\n    Rough winds do shake the darling buds of May,\", \" \\n    And summer's lease hath all too short a date; \\n    Sometime too hot the eye of heaven shines, \", \"\\n    And often is his gold complexion dimm'd; \\n    And every fair from fair sometime declines, \\n    \", \"By chance or nature's changing course untrimm'd; \\n    But thy eternal summer shall not fade, \\n    No\", \"r lose possession of that fair thou ow'st; \\n    Nor shall death brag thou wander'st in his shade, \\n \", \"   When in eternal lines to time thou grow'st: \\n    So long as men can breathe or eyes can see, \\n   \", \" So long lives this, and this gives life to thee. \\n    \\\"\\\"\\\"); \\nprivate char[] _encoded = new char[100\", \"0]; \\n \\n[Benchmark] \\npublic bool TryToBase64Chars() => Convert.TryToBase64Chars(_data, _encoded, out \", \"_); \\nMethod \\nRuntime \\nMean \\nRatio \\nTryToBase64Chars \\n.NET 6.0 \\n623.25 ns \\n1.00 \\nTryToBase64Chars \\n.N\", \"ET 7.0 \\n81.82 ns \\n0.13 \\nJust as widening can be used to go from bytes to chars, narrowing can be use\", \"d to go from chars to \\nbytes, in particular if the chars are actually ASCII and thus have a 0 upper \", \"byte. Such narrowing can be \\nvectorized, and the internal NarrowUtf16ToAscii utility helper does exa\", \"ctly that, used as part of \\nmethods like Encoding.ASCII.GetBytes. While this method was previously v\", \"ectorized, its primary \\nfast-path utilized SSE2 and thus didn\\u2019t apply to Arm64; thanks to dotnet/run\", \"time#70080 from \\n[@SwapnilGaikwad](https://github.com/SwapnilGaikwad), that path was changed over to\", \" be based on \\nthe cross-platform Vector128<T>, enabling the same level of optimization across suppor\", \"ted \\nplatforms. Similarly, dotnet/runtime#71637 from \\n[@SwapnilGaikwad](https://github.com/SwapnilGa\", \"ikwad) adds Arm64 vectorization to the \\nGetIndexOfFirstNonAsciiChar internal helper that\\u2019s used by m\", \"ethods like \\nEncoding.UTF8.GetByteCount. (And in the same vein, dotnet/runtime#67192 changed the int\", \"ernal \\nHexConverter.EncodeToUtf16 method from using SSSE3 intrinsics to instead use Vector128<T>, \\na\", \"utomatically providing an Arm64 implementation.) \\nEncoding.UTF8 was also improved a bit. In particul\", \"ar, dotnet/runtime#69910 streamlined the \\nimplementations of GetMaxByteCount and GetMaxCharCount, ma\", \"king them small enough to be \\ncommonly inlined when used directly off of Encoding.UTF8 such that the\", \" JIT is able to devirtualize the \\ncalls. \\n \\n114 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\n[Benchma\", \"rk] \\npublic int GetMaxByteCount() => Encoding.UTF8.GetMaxByteCount(Sonnet.Length); \\nMethod \\nRuntime \", \"\\nMean \\nRatio \\nGetMaxByteCount \\n.NET 6.0 \\n1.7442 ns \\n1.00 \\nGetMaxByteCount \\n.NET 7.0 \\n0.4746 ns \\n0.27\", \" \\nArguably the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals.\", \" \\nInitially implemented in the C# compiler in dotnet/roslyn#58991, with follow-on work in \\ndotnet/ro\", \"slyn#59390, dotnet/roslyn#61532, and dotnet/roslyn#62044, UTF8 literals enables the \\ncompiler to per\", \"form the UTF8 encoding into bytes at compile-time. Rather than writing a normal \\nstring, e.g. \\\"hello\", \"\\\", a developer simply appends the new u8 suffix onto the string literal, e.g. \\n\\\"hello\\\"u8. At that po\", \"int, this is no longer a string. Rather, the natural type of this expression is a \\nReadOnlySpan<byte\", \">. If you write: \\npublic static ReadOnlySpan<byte> Text => \\\"hello\\\"u8; \\nthe C# compiler will compile \", \"that equivalent to if you wrote: \\npublic static ReadOnlySpan<byte> Text => \\n    new ReadOnlySpan<byt\", \"e>(new byte[] { (byte)'h', (byte)'e', (byte)'l', (byte)'l', \\n(byte)'o', (byte)'\\\\0' }, 0, 5);     \\nIn\", \" other words, the compiler is doing the equivalent of Encoding.UTF8.GetBytes at compile-time and \\nha\", \"rdcoding the resulting bytes, saving the cost of performing that encoding at run-time. Of course, at\", \" \\nfirst glance, that array allocation might look terribly inefficient. However, looks can be deceivi\", \"ng, and \\nare in this case. For several releases now, when the C# compiler sees a byte[] (or sbyte[] \", \"or bool[]) \\nbeing initialized with a constant length and constant values and immediately cast to or \", \"used to \\nconstruct a ReadOnlySpan<byte>, it optimizes away the byte[] allocation. Instead, it blits \", \"the data for \\nthat span into the assembly\\u2019s data section, and then constructs a span that points dir\", \"ectly to that data \\nin the loaded assembly. This is the actual generated IL for the above property: \", \"\\nIL_0000: ldsflda valuetype '<PrivateImplementationDetails>'/'__StaticArrayInitTypeSize=6' \\n'<Privat\", \"eImplementationDetails>'::F3AEFE62965A91903610F0E23CC8A69D5B87CEA6D28E75489B0D2CA02\\nED7993C \\nIL_0005\", \": ldc.i4.5 \\nIL_0006: newobj instance void valuetype \\n[System.Runtime]System.ReadOnlySpan`1<uint8>::.\", \"ctor(void*, int32) \\nIL_000b: ret \\nThis means we not only save on the encoding costs at run-time, and\", \" we not only avoid whatever \\nmanaged allocations might be required to store the resulting data, we a\", \"lso benefit from the JIT being \\nable to see information about the encoded data, like it\\u2019s length, en\", \"abling knock-on optimizations. You \\ncan see this clearly by examining the assembly generated for a m\", \"ethod like: \\npublic static int M() => Text.Length; \\nfor which the JIT produces: \\n; Program.M() \\n    \", \"   mov       eax,5 \\n \\n115 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\n       ret \\n; Total bytes of c\", \"ode 6 \\nThe JIT inlines the property access, sees that the span is being constructed with a length of\", \" 5, and so \\nrather than emitting any array allocations or span constructions or anything even resemb\", \"ling that, it \\nsimply outputs mov eax, 5 to return the known length of the span. \\nThanks primarily t\", \"o dotnet/runtime#70568, dotnet/runtime#69995, dotnet/runtime#70894, \\ndotnet/runtime#71417 from [@am1\", \"1](https://github.com/am11), dotnet/runtime#71292, \\ndotnet/runtime#70513, and dotnet/runtime#71992, \", \"u8 is now used more than 2100 times throughout \\ndotnet/runtime. Hardly a fair comparison, but the fo\", \"llowing benchmark demonstrates how little work \\nis actually being performed for u8 at execution time\", \": \\n[Benchmark(Baseline = true)] \\npublic ReadOnlySpan<byte> WithEncoding() => Encoding.UTF8.GetBytes(\", \"\\\"test\\\"); \\n     \\n[Benchmark]  \\npublic ReadOnlySpan<byte> Withu8() => \\\"test\\\"u8; \\nMethod \\nMean \\nRatio \\n\", \"Allocated \\nAlloc Ratio \\nWithEncoding \\n17.3347 ns \\n1.000 \\n32 B \\n1.00 \\nWithu8 \\n0.0060 ns \\n0.000 \\n- \\n0.\", \"00 \\nLike I said, not fair, but it proves the point :) \\nEncoding is of course just one mechanism for \", \"creating string instances. Others have also improved in \\n.NET 7. Take the super common long.ToString\", \", for example. Previous releases improved \\nint.ToString, but there were enough differences between t\", \"he 32-bit and 64-bit algorithms that long \\ndidn\\u2019t see all of the same gains. Now thanks to dotnet/ru\", \"ntime#68795, the 64-bit formatting code \\npaths are made much more similar to the 32-bit, resulting i\", \"n faster performance. \\nYou can also see improvements in string.Format and StringBuilder.AppendFormat\", \", as well as \\nother helpers that layer on top of these (like TextWriter.AppendFormat). dotnet/runtim\", \"e#69757 \\noverhauls the core routines inside Format to avoid unnecessary bounds checking, favor expec\", \"ted \\ncases, and generally clean up the implementation. It also, however, utilities IndexOfAny to sea\", \"rch for \\nthe next interpolation hole that needs to be filled in, and if the non-hole-character to ho\", \"le ratio is high \\n(e.g. long format string with few holes), it can be way faster than before. \\npriva\", \"te StringBuilder _sb = new StringBuilder(); \\n \\n[Benchmark] \\npublic void AppendFormat() \\n{ \\n    _sb.C\", \"lear(); \\n    _sb.AppendFormat(\\\"There is already one outstanding '{0}' call for this WebSocket \\ninsta\", \"nce.\\\" + \\n                     \\\"ReceiveAsync and SendAsync can be called simultaneously, but at most \", \"\\none \\\" + \\n                     \\\"outstanding operation for each of them is allowed at the same time.\\\"\", \", \\n                     \\\"ReceiveAsync\\\"); \\n} \\n \\n \\n \\n116 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nM\", \"ethod \\nRuntime \\nMean \\nRatio \\nAppendFormat \\n.NET 6.0 \\n338.23 ns \\n1.00 \\nAppendFormat \\n.NET 7.0 \\n49.15 \", \"ns \\n0.15 \\nSpeaking of StringBuilder, it\\u2019s seen additional improvements beyond the aforementioned cha\", \"nges \\nto AppendFormat. One interesting change is dotnet/runtime#64405, which achieved two related \\nt\", \"hings. The first was to remove pinning as part of formatting operations. As an example, \\nStringBuild\", \"er has an Append(char* value, int valueCount) overload which copies the specified \\nnumber of charact\", \"ers from the specified pointer into the StringBuilder, and other APIs were \\nimplemented in terms of \", \"this method; for example, the Append(string? value, int startIndex, \\nint count) method was essential\", \"ly implemented as: \\nfixed (char* ptr = value) \\n{ \\n    Append(ptr + startIndex, count); \\n} \\nThat fixe\", \"d statement translates into a \\u201cpinning pointer.\\u201d Normally the GC is free to move managed \\nobjects ar\", \"ound on the heap, which it might do in order to compact the heap (to, for example, avoid \\nsmall, unu\", \"suable fragments of memory between objects). But if the GC can move objects around, a \\nnormal native\", \" pointer into that memory would be terribly unsafe and unreliable, as without notice the \\ndata being\", \" pointed to could move and your pointer could now be pointing to garbage or to some \\nother object th\", \"at was shifted to this location. There are two ways for dealing with this. The first is a \\n\\u201cmanaged \", \"pointer,\\u201d otherwise known as a \\u201creference\\u201d or \\u201cref,\\u201d as that\\u2019s exactly what you get when you \\nhave t\", \"he \\u201cref\\u201d keyword in C#; it\\u2019s a pointer that the runtime will update with the correct value when it \\n\", \"moves the object being pointed into. The second is to prevent the pointed-to object from being \\nmove\", \"d, \\u201cpinning\\u201d it in place. And that\\u2019s what the \\u201cfixed\\u201d keyword does, pinning the referenced object \\nf\", \"or the duration of the fixed block, during which time it\\u2019s safe to use the supplied pointer. Thankfu\", \"lly, \\npinning is cheap when no GC occurs; when a GC does occur, however, pinned objects aren\\u2019t able \", \"to be \\nmoved around, and thus pinning can have a global impact on the performance of the application\", \" (and \\non GCs themselves). There are also various optimizations inhibited by pinning. With all of th\", \"e advents \\nin C# around being able to use ref in many more places (e.g. ref locals, ref returns, and\", \" now in C# 11, \\nref fields), and with all of the new APIs in .NET for manipulating refs (e.g. Unsafe\", \".Add, \\nUnsafe.AreSame), it\\u2019s now possible to rewrite code that was using pinning pointers to instead\", \" use \\nmanaged pointers, thereby avoiding the problems that come from pinning. Which is what this PR \", \"did. \\nRather than implementing all of the Append methods in terms of an Append(char*, int) helper, \\n\", \"they\\u2019re now all implemented in terms of an Append(ref char, int) helper. So for example instead of \\n\", \"the previously shown Append(string? value, int startIndex, int count) implementation, it\\u2019s \\nnow akin\", \" to \\nAppend(ref Unsafe.Add(ref value.GetRawStringData(), startIndex), count); \\nwhere that string.Get\", \"RawStringData method is just an internal version of the public \\nstring.GetPinnableReference method, \", \"returning a ref instead of a ref readonly. This means that \\nall of the high-performance code inside \", \"of StringBuilder that had been using pointers to avoid \\nbounds checking and the like can continue to\", \" do so, but now also does so without pinning all of the \\ninputs. \\n \\n117 \\nCHAPTER 10 | Arrays, String\", \"s, and Spans \\n \\nThe second thing this StringBuilder change did was unify an optimization that was pr\", \"esent for \\nstring inputs to also apply to char[] inputs and ReadOnlySpan<char> inputs. Specifically,\", \" because \\nit\\u2019s so common to append string instances to a StringBuilder, a special code path was long\", \" ago \\nput in place to optimize for this input and specifically for the case where there\\u2019s already en\", \"ough room \\nin the StringBuilder to hold the whole input, at which point an efficient copy can be use\", \"d. With a \\nshared Append(ref char, int) helper, though, this optimization can be moved down into tha\", \"t \\nhelper, such that it not only helps out string but any other type that also calls into the same h\", \"elper. \\nThe effects of this are visible in a simple microbenchmark: \\nprivate StringBuilder _sb = new\", \" StringBuilder(); \\n \\n[Benchmark] \\npublic void AppendSpan() \\n{ \\n    _sb.Clear(); \\n    _sb.Append(\\\"thi\", \"s\\\".AsSpan()); \\n    _sb.Append(\\\"is\\\".AsSpan()); \\n    _sb.Append(\\\"a\\\".AsSpan()); \\n    _sb.Append(\\\"test\\\".\", \"AsSpan()); \\n    _sb.Append(\\\".\\\".AsSpan()); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAppendSpan \\n.NET 6.0 \\n35\", \".98 ns \\n1.00 \\nAppendSpan \\n.NET 7.0 \\n17.59 ns \\n0.49 \\nOne of the great things about improving things l\", \"ow in the stack is they have a multiplicative effect; \\nthey not only help improve the performance of\", \" user code that directly relies on the improved \\nfunctionality, they can also help improve the perfo\", \"rmance of other code in the core libraries, which \\nthen further helps dependent apps and services. Y\", \"ou can see this, for example, with \\nDateTimeOffset.ToString, which depends on StringBuilder: \\nprivat\", \"e DateTimeOffset _dto = DateTimeOffset.UtcNow; \\n \\n[Benchmark] \\npublic string DateTimeOffsetToString(\", \") => _dto.ToString(); \\nMethod \\nRuntime \\nMean \\nRatio \\nDateTimeOffsetToString \\n.NET 6.0 \\n340.4 ns \\n1.0\", \"0 \\nDateTimeOffsetToString \\n.NET 7.0 \\n289.4 ns \\n0.85 \\nStringBuilder itself was then further updated b\", \"y dotnet/runtime#64922 from [@teo-\\ntsirpanis](https://github.com/teo-tsirpanis), which improves the \", \"Insert methods. It used to be that \\nthe Append(primitive) methods on StringBuilder (e.g. Append(int)\", \") would call ToString on the \\nvalue and then append the resulting string. With the advent of ISpanFo\", \"rmattable, as a fast-path \\nthose methods now try to format the value directly into the StringBuilder\", \"\\u2019s internal buffer, and only \\nif there\\u2019s not enough room remaining do they then take the old path as\", \" a fallback. Insert wasn\\u2019t \\nimproved in this way at the time, because it can\\u2019t just format into the \", \"space at the end of the builder; \\nthe insert location could be anywhere in the builder. This PR addr\", \"esses that by formatting into some \\ntemporary stack space, and then delegating to the existing inter\", \"nal ref-based helper from the \\n \\n118 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\npreviously discusse\", \"d PR to insert the resulting characters at the right location (it also falls back to \\nToString when \", \"there\\u2019s not enough stack space for the ISpanFormattable.TryFormat, but that only \\nhappens in incredi\", \"bly corner cases, like a floating-point value that formats to hundreds of digits). \\nprivate StringBu\", \"ilder _sb = new StringBuilder(); \\n \\n[Benchmark] \\npublic void Insert() \\n{ \\n    _sb.Clear(); \\n    _sb.\", \"Insert(0, 12345); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nInsert \\n.NET 6.0 \\n30.02 \", \"ns \\n1.00 \\n32 B \\n1.00 \\nInsert \\n.NET 7.0 \\n25.53 ns \\n0.85 \\n- \\n0.00 \\nOther minor improvements to StringB\", \"uilder have also been made, like dotnet/runtime#60406 which \\nremoved a small int[] allocation from t\", \"he Replace method. Even with all these improvements, \\nthough, the fastest use of StringBuilder is no\", \" use; dotnet/runtime#68768 removed a bunch of uses \\nof StringBuilder that would have been better ser\", \"ved with other string-creation mechanisms. For \\nexample, the legacy DataView type had some code that\", \" created a sorting specification as a string: \\nprivate static string CreateSortString(PropertyDescri\", \"ptor property, ListSortDirection \\ndirection) \\n{ \\n    var resultString = new StringBuilder(); \\n    re\", \"sultString.Append('['); \\n    resultString.Append(property.Name); \\n    resultString.Append(']'); \\n   \", \" if (ListSortDirection.Descending == direction) \\n    { \\n        resultString.Append(\\\" DESC\\\"); \\n    }\", \" \\n    return resultString.ToString(); \\n} \\nWe don\\u2019t actually need the StringBuilder here, as in the w\", \"orst-case we\\u2019re just concatenating three \\nstrings, and string.Concat has a dedicated overload for th\", \"at exact operation that has the best \\npossible implementation for that operation (and if we ever fou\", \"nd a better way, that method would be \\nimproved according). So we can just use that: \\nprivate static\", \" string CreateSortString(PropertyDescriptor property, ListSortDirection \\ndirection) => \\n    directio\", \"n == ListSortDirection.Descending ? \\n        $\\\"[{property.Name}] DESC\\\" : \\n        $\\\"[{property.Name}\", \"]\\\"; \\nNote that I\\u2019ve expressed that concatenation via an interpolated string, but the C# compiler wil\", \"l \\u201clower\\u201d \\nthis interpolated string to a call to string.Concat, so the IL for this is indistinguisha\", \"ble from if I\\u2019d \\ninstead written: \\nprivate static string CreateSortString(PropertyDescriptor propert\", \"y, ListSortDirection \\ndirection) => \\n \\n119 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\n    direction\", \" == ListSortDirection.Descending ? \\n        string.Concat(\\\"[\\\", property.Name, \\\"] DESC\\\") : \\n        s\", \"tring.Concat(\\\"[\\\", property.Name, \\\"]\\\"); \\nAs an aside, the expanded string.Concat version highlights t\", \"hat this method could have been \\nwritten to result in a bit less IL if it were instead written as: \\n\", \"private static string CreateSortString(PropertyDescriptor property, ListSortDirection \\ndirection) =>\", \" \\n    string.Concat(\\\"[\\\", property.Name, direction == ListSortDirection.Descending ? \\\"] DESC\\\" \\n: \\\"]\\\")\", \";  \\nbut this doesn\\u2019t meaningfully affect performance and here clarity and maintainability was more \\n\", \"important than shaving off a few bytes. \\n[Benchmark(Baseline = true)] \\n[Arguments(\\\"SomeProperty\\\", Li\", \"stSortDirection.Descending)] \\npublic string WithStringBuilder(string name, ListSortDirection directi\", \"on) \\n{ \\n    var resultString = new StringBuilder(); \\n    resultString.Append('['); \\n    resultString\", \".Append(name); \\n    resultString.Append(']'); \\n    if (ListSortDirection.Descending == direction) \\n \", \"   { \\n        resultString.Append(\\\" DESC\\\"); \\n    } \\n    return resultString.ToString(); \\n} \\n \\n[Bench\", \"mark] \\n[Arguments(\\\"SomeProperty\\\", ListSortDirection.Descending)] \\npublic string WithConcat(string na\", \"me, ListSortDirection direction) => \\n    direction == ListSortDirection.Descending? \\n        $\\\"[{nam\", \"e}] DESC\\\" : \\n        $\\\"[{name}]\\\"; \\nMethod \\nMean \\nRatio Allocated \\nAlloc Ratio \\nWithStringBuilder \\n68\", \".34 ns \\n1.00 \\n272 B \\n1.00 \\nWithConcat \\n20.78 ns \\n0.31 \\n64 B \\n0.24 \\nThere are also places where Strin\", \"gBuilder was still applicable, but it was being used on hot-enough \\npaths that previous releases of \", \".NET saw the StringBuilder instance being cached. Several of the \\ncore libraries, including System.P\", \"rivate.CoreLib, have an internal StringBuilderCache type which \\ncaches a StringBuilder instance in a\", \" [ThreadStatic], meaning every thread could end up having \\nsuch an instance. There are several issue\", \"s with this, including that the buffers employed by \\nStringBuilder aren\\u2019t usable for anything else w\", \"hile the StringBuilder isn\\u2019t in use, and because of \\nthat, StringBuilderCache places a limit on the \", \"capacity of the StringBuilder instances that can be \\ncached; attempts to cache ones longer than that\", \" result in them being thrown away. It\\u2019d be better \\ninstead to use cached arrays that aren\\u2019t length-l\", \"imited and that everyone has access to for sharing. \\nMany of the core .NET libraries have an interna\", \"l ValueStringBuilder type for this purpose, a ref \\nstruct-based type that can use stackalloc\\u2019d memor\", \"y to start and then if necessary grow into \\nArrayPool<char> arrays. And with dotnet/runtime#64522 an\", \"d dotnet/runtime#69683, many of the \\n \\n120 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nremaining use\", \"s of StringBuilderCache have been replaced. I\\u2019m hopeful we can entirely remove \\nStringBuilderCache i\", \"n the future. \\nIn the same vein of not doing unnecessary work, there\\u2019s a fairly common pattern that \", \"shows up with \\nmethods like string.Substring and span.Slice: \\nspan = span.Slice(offset, str.Length -\", \" offset); \\nThe relevant thing to recognize here is these methods have overloads that take just the s\", \"tarting offset. \\nSince the length being specified is the remainder after the specified offset, the c\", \"all could instead be \\nsimplified to: \\nspan = span.Slice(offset); \\nwhich is not only more readable an\", \"d maintainable, it has some small efficiency benefits, e.g. on 64-bit \\nthe Slice(int, int) construct\", \"or has an extra addition over Slice(int), and for 32-bit the \\nSlice(int, int) constructor incurs an \", \"additional comparison and branch. It\\u2019s thus beneficial for both \\ncode maintenance and for performanc\", \"e to simplify these calls, which dotnet/runtime#68937 does for \\nall found occurrences of that patter\", \"n. This is then made more impactful by dotnet/runtime#73882, \\nwhich streamlines string.Substring to \", \"remove unnecessary overheads, e.g. it condenses four \\nargument validation checks down to a single fa\", \"st-path comparison (in 64-bit processes). \\nOk, enough about string. What about spans? One of the coo\", \"lest features in C# 11 is the new support \\nfor ref fields. What is a ref field? You\\u2019re familiar with\", \" refs in C# in general, and we\\u2019ve already \\ndiscussed how they\\u2019re essentially managed pointers, i.e. \", \"pointers that the runtime can update at any \\ntime due to the object it references getting moved on t\", \"he heap. These references can point to the \\nbeginning of an object, or they can point somewhere insi\", \"de the object, in which case they\\u2019re referred \\nto as \\u201cinterior pointers.\\u201d ref has existed in C# sinc\", \"e 1.0, but at that time it was primarily about passing \\nby reference to method calls, e.g. \\nclass Da\", \"ta \\n{ \\n    public int Value; \\n} \\n... \\nvoid Add(ref int i) \\n{ \\n    i++; \\n} \\n... \\nvar d = new Data { V\", \"alue = 42 }; \\nAdd(ref d.Value); \\nDebug.Assert(d.Value == 43); \\nLater versions of C# added the abilit\", \"y to have local refs, e.g. \\nvoid Add(ref int i) \\n{ \\n    ref j = ref i; \\n    j++; \\n} \\nand even to hav\", \"e ref returns, e.g. \\n \\n121 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nref int Add(ref int i) \\n{ \\n  \", \"  ref j = ref i; \\n    j++; \\n    return ref j; \\n} \\nThese facilities are more advanced, but they\\u2019re us\", \"ed liberally throughout higher-performance code \\nbases, and many of the optimizations in .NET in rec\", \"ent years are possible in large part due to these \\nref-related capabilities. \\nSpan<T> and ReadOnlySp\", \"an<T> themselves are heavily-based on refs. For example, the indexer on \\nmany older collection types\", \" is implemented as a get/set property, e.g. \\nprivate T[] _items; \\n... \\npublic T this[int i] \\n{ \\n    \", \"get => _items[i]; \\n    set => _items[i] = value; \\n} \\nBut not span. Span<T>\\u2019s indexer looks more like\", \" this: \\npublic ref T this[int index] \\n{ \\n    get \\n    { \\n        if ((uint)index >= (uint)_length) \\n\", \"            ThrowHelper.ThrowIndexOutOfRangeException(); \\n \\n        return ref Unsafe.Add(ref _refer\", \"ence, index); \\n    } \\n} \\nNote there\\u2019s only a getter and no setter; that\\u2019s because it returns a ref T\", \" to the actual storage \\nlocation. It\\u2019s a writable ref, so you can assign to it, e.g. you can write: \", \"\\nspan[i] = value; \\nbut rather than that being equivalent to calling some setter: \\nspan.set_Item(i, v\", \"alue); \\nit\\u2019s actually equivalent to using the getter to retrieve the ref and then writing a value th\", \"rough that \\nref, e.g. \\nref T item = ref span.get_Item(i); \\nitem = value; \\nThat\\u2019s all well and good, \", \"but what\\u2019s that _reference in the getter definition? Well, Span<T> is really \\njust a tuple of two fi\", \"elds: a reference (to the start of the memory being referred to) and a length (how \\nmany elements fr\", \"om that reference are included in the span). In the past, the runtime had to hack this \\nwith an inte\", \"rnal type (ByReference<T>) specially recognized by the runtime to be a reference. But as \\nof C# 11 a\", \"nd .NET 7, ref structs can now contain ref fields, which means Span<T> today is literally \\ndefined a\", \"s follows: \\n \\n122 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\npublic readonly ref struct Span<T> \\n{ \", \"\\n    internal readonly ref T _reference; \\n    private readonly int _length; \\n    ... \\n} \\nThe rollout\", \" of ref fields throughout dotnet/runtime was done in dotnet/runtime#71498, following the \\nC# languag\", \"e gaining this support primarily in dotnet/roslyn#62155, which itself was the culmination \\nof many P\", \"Rs first into a feature branch. ref fields alone doesn\\u2019t itself automatically improve \\nperformance, \", \"but it does simplify code significantly, and it allows for both new custom code that uses \\nref field\", \"s as well as new APIs that take advantage of them, both of which can help with performance \\n(and spe\", \"cifically performance without sacrificing potential safety). One such example of a new API is \\nnew c\", \"onstructors on ReadOnlySpan<T> and Span<T>: \\npublic Span(ref T reference); \\npublic ReadOnlySpan(in T\", \" reference); \\nadded in dotnet/runtime#67447 (and then made public and used more broadly in \\ndotnet/r\", \"untime#71589). This may beg the question, why does ref field support enable two new \\nconstructors th\", \"at take refs, considering spans already were able to store a ref? After all, the \\nMemoryMarshal.Crea\", \"teSpan(ref T reference, int length) and corresponding \\nCreateReadOnlySpan methods have existed for a\", \"s long as spans have, and these new constructors are \\nequivalent to calling those methods with a len\", \"gth of 1. The answer is: safety. \\nImagine if you could willy-nilly call this constructor. You\\u2019d be a\", \"ble to write code like this: \\npublic Span<int> RuhRoh() \\n{ \\n    int i = 42; \\n    return new Span<int\", \">(ref i); \\n} \\nAt this point the caller of this method is handed a span that refers to garbage; that\\u2019\", \"s bad in code \\nthat\\u2019s intended to be safe. You can already accomplish the same thing by using pointe\", \"rs: \\npublic Span<int> RuhRoh() \\n{ \\n    unsafe \\n    { \\n        int i = 42; \\n        return new Span<i\", \"nt>(&i, 1); \\n    } \\n} \\nbut at that point you\\u2019ve taken on the risk of using unsafe code and pointers \", \"and any resulting \\nproblems are on you. With C# 11, if you now try to write the above code using the\", \" ref-based \\nconstructor, you\\u2019ll be greeted with an error like this: \\nerror CS8347: Cannot use a resu\", \"lt of 'Span<int>.Span(ref int)' in this context because it \\nmay expose variables referenced by param\", \"eter 'reference' outside of their declaration scope \\nIn other words, the compiler now understands th\", \"at Span<int> as a ref struct could be storing the \\npassed in ref, and if it does store it (which Spa\", \"n<T> does), this is akin to passing a ref to a local out \\n \\n123 \\nCHAPTER 10 | Arrays, Strings, and S\", \"pans \\n \\nof the method, which is bad. Hence how this relates to ref fields: because ref fields are no\", \"w a thing, \\nthe compiler\\u2019s rules for safe-handling of refs have been updated, which in turn enables \", \"us to expose \\nthe aforementioned constructors on {ReadOnly}Span<T>. \\nAs is often the case, addressin\", \"g one issue kicks the can down the road a bit and exposes another. The \\ncompiler now believes that a\", \" ref passed to a method on a ref struct could enable that ref struct \\ninstance to store the ref (not\", \"e that this was already the case with ref structs passed to methods on \\nref structs), but what if we\", \" don\\u2019t want that? What if we want to be able to say \\u201cthis ref is not \\nstorable and should not escape\", \" the calling scope\\u201d? From a caller\\u2019s perspective, we want the compiler \\nto allow passing in such ref\", \"s without it complaining about potential extension of lifetime, and from a \\ncallee\\u2019s perspective, we\", \" want the compiler to prevent the method from doing what it\\u2019s not supposed \\nto do. Enter scoped. The\", \" new C# keyword does exactly what we just wished for: put it on a ref or ref \\nstruct parameter, and \", \"the compiler both will guarantee (short of using unsafe code) that the method \\ncan\\u2019t stash away the \", \"argument and will then enable the caller to write code that relies on that \\nguarantee. For example, \", \"consider this program: \\nvar writer = new SpanWriter(stackalloc char[128]); \\nAppend(ref writer, 123);\", \" \\nwriter.Write(\\\".\\\"); \\nAppend(ref writer, 45); \\nConsole.WriteLine(writer.AsSpan().ToString()); \\n \\nsta\", \"tic void Append(ref SpanWriter builder, byte value) \\n{ \\n    Span<char> tmp = stackalloc char[3]; \\n  \", \"  value.TryFormat(tmp, out int charsWritten); \\n    builder.Write(tmp.Slice(0, charsWritten)); \\n} \\n \\n\", \"ref struct SpanWriter \\n{ \\n    private readonly Span<char> _chars; \\n    private int _length; \\n \\n    p\", \"ublic SpanWriter(Span<char> destination) => _chars = destination; \\n \\n    public Span<char> AsSpan() \", \"=> _chars.Slice(0, _length); \\n \\n    public void Write(ReadOnlySpan<char> value) \\n    { \\n        if (\", \"_length > _chars.Length - value.Length) \\n        { \\n            throw new InvalidOperationException(\", \"\\\"Not enough remaining space\\\"); \\n        } \\n \\n        value.CopyTo(_chars.Slice(_length)); \\n        _\", \"length += value.Length; \\n    } \\n} \\nWe have a ref struct SpanWriter that takes a Span<char> to its co\", \"nstructor and allows for writing \\nto it by copying in additional content and then updating the store\", \"d length. The Write method accepts \\na ReadOnlySpan<char>. And we then have a helper Append method wh\", \"ich is formatting a byte into \\nsome stackalloc\\u2019d temporary space and passing the resulting formatted\", \" chars in to Write. \\nStraightforward. Except, this doesn\\u2019t compile: \\n \\n124 \\nCHAPTER 10 | Arrays, Str\", \"ings, and Spans \\n \\nerror CS8350: This combination of arguments to 'SpanWriter.Write(ReadOnlySpan<cha\", \"r>)' is \\ndisallowed because it may expose variables referenced by parameter 'value' outside of their\", \" \\ndeclaration scope \\nWhat do we do? The Write method doesn\\u2019t actually store the value parameter and \", \"won\\u2019t ever need \\nto, so we can change the signature of the method to annotate it as scoped: \\npublic \", \"void Write(scoped ReadOnlySpan<char> value) \\nIf Write were then to try to store value, the compiler \", \"would balk: \\nerror CS8352: Cannot use variable 'ReadOnlySpan<char>' in this context because it may \\n\", \"expose referenced variables outside of their declaration scope \\nBut as it\\u2019s not trying to do so, eve\", \"rything now compiles successfully. You can see examples of how this \\nis utilized in the aforemention\", \"ed dotnet/runtime#71589. \\nThere\\u2019s also the other direction: there are some things that are implicitl\", \"y scoped, like the this \\nreference on a struct. Consider this code: \\npublic struct SingleItemList \\n{\", \" \\n    private int _value; \\n     \\n    public ref int this[int i] \\n    { \\n        get \\n        { \\n    \", \"        if (i != 0) throw new IndexOutOfRangeException(); \\n             \\n            return ref _val\", \"ue; \\n        } \\n    } \\n} \\nThis produces a compiler error: \\nerror CS8170: Struct members cannot retur\", \"n 'this' or other instance members by reference \\nEffectively, that\\u2019s because this is implicitly scop\", \"ed (even though that keyword wasn\\u2019t previously \\navailable). What if we want to enable such an item t\", \"o be returned? Enter [UnscopedRef]. This is rare \\nenough in need that it doesn\\u2019t get its own C# lang\", \"uage keyword, but the C# compiler does recognize \\nthe new [UnscopedRef] attribute. It can be put ont\", \"o relevant parameters but also onto methods and \\nproperties, in which case it applies to the this re\", \"ference for that member. As such, we can modify our \\nprevious code example to be: \\n[UnscopedRef] \\npu\", \"blic ref int this[int i] \\nand now the code will compile successfully. Of course, this also places de\", \"mands on callers of this \\nmethod. For a call site, the compiler sees the [UnscopedRef] on the member\", \" being invoked, and then \\nknows that the returned ref might reference something from that struct, an\", \"d thus assigns to the \\nreturned ref the same lifetime as that struct. So, if that struct were a loca\", \"l living on the stack, the ref \\nwould also be limited to that same method. \\n \\n125 \\nCHAPTER 10 | Arra\", \"ys, Strings, and Spans \\n \\nAnother impactful span-related change comes in dotnet/runtime#70095 from [\", \"@teo-\\ntsirpanis](https://github.com/teo-tsirpanis). System.HashCode\\u2019s goal is to provide a fast, eas\", \"y-to-use \\nimplementation for producing high-quality hash codes. In its current incarnation, it incor\", \"porates a \\nrandom process-wide seed and is an implementation of the xxHash32 non-cryptographic hash \", \"\\nalgorithm. In a previous release, HashCode saw the addition of an AddBytes methods, which accepts a\", \" \\nReadOnlySpan<byte> and is useful for incorporating sequences of data that should be part of a type\", \"\\u2019s \\nhash code, e.g. BigInteger.GetHashCode includes all the data that makes up the BigInteger. The \\n\", \"xxHash32 algorithm works by accumulating 4 32-bit unsigned integers and then combining them \\ntogethe\", \"r into the hash code; thus if you call HashCode.Add(int), the first three times you call it you\\u2019re \\n\", \"just storing the values separately into the instance, and then the fourth time you call it all of th\", \"ose \\nvalues are combined into the hash code (and there\\u2019s a separate process that incorporates any \\nr\", \"emaining values if the number of 32-bit values added wasn\\u2019t an exact multiple of 4). Thus, previousl\", \"y \\nAddBytes was simply implemented to repeatedly read the next 4 bytes from the input span and call \", \"\\nAdd(int) with those bytes as an integer. But those Add calls have overhead. Instead, this PR skips \", \"the \\nAdd calls and directly handles the accumulation and combining of the 16 bytes. Interestingly, i\", \"t still has \\nto deal with the possibility that previous calls to Add may have left some state queued\", \", which means \\n(with the current implementation at least), if there are multiple pieces of state to \", \"include in the hash \\ncode, say a ReadOnlySpan<byte> and an additional int, it\\u2019s more efficient to ad\", \"d the span first and \\nthen the int rather than the other way around. So for example when dotnet/runt\", \"ime#71274 from \\n[@huoyaoyuan](https://github.com/huoyaoyuan) changed BigInteger.GetHashCode to use \\n\", \"HashCode.AddBytes, it coded the method to first call AddBytes with the BigInteger\\u2019s _bits and then \\n\", \"call Add with the _sign. \\nprivate byte[] _data = Enumerable.Range(0, 256).Select(i => (byte)i).ToArr\", \"ay(); \\n \\n[Benchmark] \\npublic int AddBytes() \\n{ \\n    HashCode hc = default; \\n    hc.AddBytes(_data); \", \"\\n    return hc.ToHashCode(); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAddBytes \\n.NET 6.0 \\n159.11 ns \\n1.00 \\n\", \"AddBytes \\n.NET 7.0 \\n42.11 ns \\n0.26 \\nAnother span-related change, dotnet/runtime#72727 refactored a b\", \"unch of code paths to eliminate \\nsome cached arrays. Why avoid cached arrays? After all, isn\\u2019t it de\", \"sirable to cache an array once and \\nreuse it over and over again? It is, if that\\u2019s the best option, \", \"but sometimes there are better options. For \\nexample, one of the changes took code like: \\nprivate st\", \"atic readonly char[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' }; \\n... \\nint index = value.IndexOfAny\", \"(s_pathDelims); \\nand replaced it with code like: \\nint index = value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\"); \\n\", \" \\n126 \\nCHAPTER 10 | Arrays, Strings, and Spans \\n \\nThis has a variety of benefits. There\\u2019s the usabil\", \"ity benefit of keeping the tokens being searched close \\nto the use site, and the usability benefit o\", \"f the list being immutable such that some code somewhere \\nwon\\u2019t accidentally replace a value in the \", \"array. But there are also performance benefits. We don\\u2019t need \\nan extra field to store the array. We\", \" don\\u2019t need to allocate the array as part of this type\\u2019s static \\nconstructor. And loading/using the \", \"string is slightly faster. \\nprivate static readonly char[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#'\", \" }; \\nprivate static readonly string s_value = \\\"abcdefghijklmnopqrstuvwxyz\\\"; \\n \\n[Benchmark] \\npublic i\", \"nt WithArray() => s_value.IndexOfAny(s_pathDelims); \\n \\n[Benchmark] \\npublic int WithString() => s_val\", \"ue.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\"); \\nMethod \\nMean \\nRatio \\nWithArray \\n8.601 ns \\n1.00 \\nWithString \\n6.949\", \" ns \\n0.81 \\nAnother example from that PR took code along the lines of: \\nprivate static readonly char[\", \"] s_whitespaces = new char[] { ' ', '\\\\t', '\\\\n', '\\\\r' }; \\n... \\nswitch (attr.Value.Trim(s_whitespaces)\", \") \\n{ \\n    case \\\"preserve\\\": return Preserve; \\n    case \\\"default\\\": return Default; \\n} \\nand replaced it\", \" with code like: \\nswitch (attr.Value.AsSpan().Trim(\\\" \\\\t\\\\n\\\\r\\\")) \\n{ \\n    case \\\"preserve\\\": return Prese\", \"rve; \\n    case \\\"default\\\": return Default; \\n} \\nIn this case, not only have we avoided the char[], but\", \" if the text did require any trimming of \\nwhitespaces, the new version (which trims a span instead o\", \"f the original string) will save an allocation \\nfor the trimmed string. This is taking advantage of \", \"the new C# 11 feature that supports switching on \\nReadOnlySpan<char>s just as you can switch on stri\", \"ngs, added in dotnet/roslyn#44388 from \\n[@YairHalberstadt](https://github.com/YairHalberstadt). dotn\", \"et/runtime#68831 also took advantage \\nof this in several additional places. \\nOf course, in some case\", \"s the arrays are entirely unnecessary. In that same PR, there were several cases \\nlike this: \\nprivat\", \"e static readonly char[] WhiteSpaceChecks = new char[] { ' ', '\\\\u00A0' }; \\n... \\nint wsIndex = target\", \".IndexOfAny(WhiteSpaceChecks, targetPosition); \\nif (wsIndex < 0) \\n{ \\n    return false; \\n} \\n \\n127 \\nCH\", \"APTER 10 | Arrays, Strings, and Spans \\n \\nBy switching to use spans, again, we can instead write it l\", \"ike this: \\nint wsIndex = target.AsSpan(targetPosition).IndexOfAny(' ', '\\\\u00A0'); \\nif (wsIndex < 0) \", \"\\n{ \\n    return false; \\n} \\nwsIndex += targetPosition; \\nMemoryExtensions.IndexOfAny has a dedicated ov\", \"erload for two and three arguments, at which \\npoint we don\\u2019t need the array at all (these overloads \", \"also happen to be faster; when passing an array \\nof two chars, the implementation would extract the \", \"two chars from the array and pass them off to the \\nsame two-argument implementation). Multiple other\", \" PRs similarly removed array allocations. \\ndotnet/runtime#60409 removed a single-char array that was\", \" cached to be able to pass it to \\nstring.Split and replaced it with usage of the Split overload that\", \" directly accepts a single char. \\nFinally, dotnet/runtime#59670 from [@NewellClark](https://github.c\", \"om/NewellClark) got rid of even \\nmore arrays. We saw earlier how the C# compiler special-cases byte[\", \"]s constructed with a constant \\nlength and constant elements and that\\u2019s immediately cast to a ReadOn\", \"lySpan<byte>. Thus, it can be \\nbeneficial any time there\\u2019s such a byte[] being cached to instead exp\", \"ose it as a ReadOnlySpan<byte>. \\nAs I discussed in the .NET 6 post, this avoids even the one-time ar\", \"ray allocation you\\u2019d get for a cached \\narray, results in much more efficient access, and supplies to\", \" the JIT compiler more information that \\nenables it to more heavily optimize\\u2026 goodness all around. T\", \"his PR removed even more arrays in this \\nmanner, as did dotnet/runtime#60411, dotnet/runtime#72743, \", \"dotnet/runtime#73115 from \\n[@vcsjones](https://github.com/vcsjones), and dotnet/runtime#70665. \\n \\n12\", \"8 \\nCHAPTER 11 | Regex \\n \\nCHAPTER 11 \\nRegex \\nBack in May, I shared a fairly detailed post about the i\", \"mprovements coming to Regular Expressions in \\n.NET 7. As a recap, prior to .NET 5, Regex\\u2019s implement\", \"ation had largely been untouched for quite \\nsome time. In .NET 5, we brought it back up to be on par\", \" with or better than multiple other industry \\nimplementations from a performance perspective. .NET 7\", \" takes some significant leaps forward from \\nthat. If you haven\\u2019t read the post yet, please go ahead \", \"and do so now; I\\u2019ll wait\\u2026 \\nWelcome back. With that context, I\\u2019ll avoid duplicating content here, and\", \" instead focus on how exactly \\nthese improvements came about and the PRs that did so. \\nRegexOptions.\", \"NonBacktracking \\nLet\\u2019s start with one of the larger new features in Regex, the new RegexOptions.NonB\", \"acktracking \\nimplementation. As discussed in the previous post, RegexOptions.NonBacktracking switche\", \"s the \\nprocessing of Regex over to using a new engine based in finite automata. It has two primary m\", \"odes of \\nexecution, one that relies on DFAs (deterministic finite automata) and one that relies on N\", \"FAs (non-\\ndeterministic finite automata). Both implementations provide a very valuable guarantee: pr\", \"ocessing \\ntime is linear in the length of the input. Whereas a backtracking engine (which is what Re\", \"gex uses if \\nNonBacktracking isn\\u2019t specified) can hit a situation known as \\u201ccatastrophic backtrackin\", \"g,\\u201d where \\nproblematic expressions combined with problematic input can result in exponential process\", \"ing in the \\nlength of the input, NonBacktracking guarantees it\\u2019ll only ever do an ammortized-constan\", \"t amount \\nof work per character in the input. In the case of a DFA, that constant is very small. Wit\", \"h an NFA, that \\nconstant can be much larger, based on the complexity of the pattern, but for any giv\", \"en pattern the \\nwork is still linear in the length of the input. \\nA significant number of years of d\", \"evelopment went into the NonBacktracking implementation, which \\nwas initially added into dotnet/runt\", \"ime in dotnet/runtime#60607. However, the original research and \\nimplementation for it actually came\", \" from Microsoft Research (MSR), and was available as an \\nexperimental package in the form of the Sym\", \"bolic Regex Matcher (SRM) library published by MSR. \\nYou can still see vestiges of this in the curre\", \"nt code now in .NET 7, but it\\u2019s evolved significantly, in \\ntight collaboration between developers on\", \" the .NET team and the researchers at MSR (prior to being \\nintegrated in dotnet/runtime, it was incu\", \"bated for over a year in dotnet/runtimelab, where the original \\nSRM code was brought in via dotnet/r\", \"untimelab#588 from [@veanes](https://github.com/veanes)). \\nThis implementation is based on the notio\", \"n of regular expression derivatives, a concept that\\u2019s been \\naround for decades (the term was origina\", \"lly coined in a paper by Janusz Brzozowski in the 1960s) and \\nwhich has been significantly advanced \", \"for this implementation. Regex derivatives form the basis for \\nhow the automata (think \\u201cgraph\\u201d) used\", \" to process input are constructed. The idea at its core is fairly \\nsimple: take a regex and process \", \"a single character\\u2026 what is the new regex you get to describe what \\nremains after processing that on\", \"e character? That\\u2019s the derivative. For example, given the regex \\\\w{3} \\n \\n129 \\nCHAPTER 11 | Regex \\n \", \"\\nto match three word characters, if you apply this to the next input character \\u2018a\\u2019, well, that will \", \"strip off \\nthe first \\\\w, leaving us with the derivative \\\\w{2}. Simple, right? How about something mo\", \"re \\ncomplicated, like the expression .*(the|he). What happens if the next character is a t? Well, it\", \"\\u2019s \\npossible that t could be consumed by the .* at the beginning of the pattern, in which case the \\n\", \"remaining regex would be exactly the same as the starting one (.*(the|he)), since after matching t \\n\", \"we could still match exactly the same input as without the t. But, the t could have also been part o\", \"f \\nmatching the, and applied to the, we\\u2019d strip off the t and be left with he, so now our derivative\", \" is \\n.*(the|he)|he. Then what about the he in the original alternation? t doesn\\u2019t match h, so the \\nd\", \"erivative would be nothing, which we\\u2019ll express here as an empty character class, giving us \\n.*(the|\", \"he)|he|[]. Of course, as part of an alternation, that \\u201cnothing\\u201d at the end is a nop, and so we \\ncan \", \"simplify the whole derivative to just .*(the|he)|he\\u2026 done. That was all when applying the \\noriginal \", \"pattern against a next t. What if it was against an h instead? Following the same logic as for \\nthe \", \"t, this time we end up with .*(the|he)|e. And so on. What if we instead start with the h \\nderivative\", \" and the next character is an e? Then we\\u2019re taking the pattern .*(the|he)|e and applying it \\nto e. A\", \"gainst the left side of the alternation, it can be consumed by the .* (but doesn\\u2019t match either t \\no\", \"r h), and so we just end up with that same subexpression. But against the right side of the \\nalterna\", \"tion, e matches e, leaving us with the empty string (): .*(the|he)|(). At the point where a \\npattern\", \" is \\u201cnullable\\u201d (it can match the empty string), that can be considered a match. We can visualize \\nth\", \"is whole thing as a graph, with transitions for every input character to the derivative that comes \\n\", \"from applying it. \\n \\n130 \\nCHAPTER 11 | Regex \\n \\n \\n \\n131 \\nCHAPTER 11 | Regex \\n \\nLooks an awful lot li\", \"ke a DFA, doesn\\u2019t it? It should. And that\\u2019s exactly how NonBacktracking \\nconstructs the DFAs it uses\", \" to process input. For every regex construct (concatenations, alternations, \\nloops, etc.) the engine\", \" knows how to derive the next regex based on the character being evaluated. \\nThis application is don\", \"e lazily, so we have an initial starting state (the original pattern), and then when \\nwe evaluate th\", \"e next character in the input, it looks to see whether there\\u2019s already a derivative \\navailable for t\", \"hat transition: if there is, it follows it, and if there isn\\u2019t, it dynamically/lazily derives the \\nn\", \"ext node in the graph. At its core, that\\u2019s how it works. \\nOf course, the devil is in the details and\", \" there\\u2019s a ton of complication and engineering smarts that go \\ninto making the engine efficient. One\", \" such example is a tradeoff between memory consumption and \\nthroughput. Given the ability to have an\", \"y char as input, you could have effectively ~65K transitions \\nout of every node (e.g. every node cou\", \"ld need a ~65K element table); that would significantly increase \\nmemory consumption. However, if yo\", \"u actually had that many transitions, it\\u2019s very likely a significant \\nmajority of them would point t\", \"o the same target node. Thus, NonBacktracking maintains its own \\ngroupings of characters into what i\", \"t calls \\u201cminterms.\\u201d If two characters will have exactly the same \\ntransition, they\\u2019re part of the sa\", \"me minterm. The transitions are then constructed in terms of \\nminterms, with at most one transition \", \"per minterm out of a given node. When the next input character \\nis read, it maps that to a minterm I\", \"D, and then finds the appropriate transition for that ID; one \\nadditional level of indirection in or\", \"der to save a potentially huge amount of memory. That mapping is \\nhandled via an array bitmap for AS\", \"CII and an efficient data structure known as a Binary Decision \\nDiagram (BDD) for everything above 0\", \"x7F. \\nAs noted, the non-backtracking engine is linear in the length of the input. But that doesn\\u2019t m\", \"ean it \\nalways looks at each input character exactly once. If you call Regex.IsMatch, it does; after\", \" all, IsMatch \\nonly needs to determine whether there is a match and doesn\\u2019t need to compute any addi\", \"tional \\ninformation, such as where the match actual starts or ends, any information on captures, etc\", \". Thus, the \\nengine can simply employ its automata to walk along the input, transitioning from node \", \"to node in \\nthe graph until it comes to a final state or runs out of input. Other operations, howeve\", \"r, do require it \\nto gather more information. Regex.Match needs to compute everything, and that can \", \"actually entail \\nmultiple walks over the input. In the initial implementation, the equivalent of Mat\", \"ch would always take \\nthree passes: match forwards to find the end of a match, then match a reversed\", \"-copy of the pattern in \\nreverse from that ending location in order to find where the match actually\", \" starts, and then once more \\nwalk forwards from that known starting position to find the actual endi\", \"ng position. However, with \\ndotnet/runtime#68199 from [@olsaarik](https://github.com/olsaarik), unle\", \"ss captures are required, it \\ncan now be done in only two passes: once forward to find the guarantee\", \"d ending location of the \\nmatch, and then once in reverse to find its starting location. And dotnet/\", \"runtime#65129 from \\n[@olsaarik](https://github.com/olsaarik) added captures support, which the origi\", \"nal implementation \\nalso didn\\u2019t have. This captures support adds back a third pass, such that once t\", \"he bounds of the \\nmatch are known, the engine runs the forward pass one more time, but this time wit\", \"h an NFA-based \\n\\u201csimulation\\u201d that is able to record \\u201ccapture effects\\u201d on transitions. All of this en\", \"ables the non-\\nbacktracking implementation to have the exact same semantics as the backtracking engi\", \"nes, always \\nproducing the same matches in the same order with the same capture information. The onl\", \"y \\ndifference in this regard is, whereas with the backtracking engines capture groups inside of loop\", \"s will \\nstore all values captured in every iteration of the loop, only the last iteration is stored \", \"with the non-\\nbacktracking implementation. On top of that, there are a few constructs the non-backtr\", \"acking \\n \\n132 \\nCHAPTER 11 | Regex \\n \\nimplementation simply doesn\\u2019t support, such that attempting to \", \"use any of those will fail when trying \\nto construct the Regex, e.g. backreferences and lookarounds.\", \" \\nEven after its progress as a standalone library from MSR, more than 100 PRs went into making \\nRege\", \"xOptions.NonBacktracking what it is now in .NET 7, including optimizations like \\ndotnet/runtime#7021\", \"7 from [@olsaarik](https://github.com/olsaarik) that tries to streamline the tight \\ninner matching l\", \"oop at the heart of the DFA (e.g. read the next input character, find the appropriate \\ntransition to\", \" take, move to the next node, and check information about the node like whether it\\u2019s a \\nfinal state)\", \" and optimizations like dotnet/runtime#65637 from [@veanes](https://github.com/veanes) \\nthat optimiz\", \"ed the NFA mode to avoid superfluous allocations, caching and reusing list and set \\nobjects to make \", \"the handling of the lists of states ammortized allocation-free. \\nThere\\u2019s one more set of PRs of perf\", \"ormance interest for NonBacktracking. The Regex implementation \\nfor taking patterns and turning them\", \" into something processable, regardless of which of the multiple \\nengines is being used, is essentia\", \"lly a compiler, and as with many compilers, it naturally lends itself to \\nrecursive algorithms. In t\", \"he case of Regex, those algorithms involve walking around trees of regular \\nexpression constructs. R\", \"ecursion ends up being a very handy way of expressing these algorithms, but \\nrecursion also suffers \", \"from the possibility of stack overflow; essentially it\\u2019s using stack space as scratch \\nspace, and if\", \" it ends up using too much, things go badly. One common approach to dealing with this \\nis turning th\", \"e recursive algorithm into an iterative one, which typically involves using an explicit stack \\nof st\", \"ate rather than the implicit one. The nice thing about this is the amount of state you can store is \", \"\\nlimited only by how much memory you have, as opposed to being limited by your thread\\u2019s stack \\nspace\", \". The downsides, however, are that it\\u2019s typically much less natural to write the algorithms in this \", \"\\nmanner, and it typically requires allocating heap space for the stack, which then leads to addition\", \"al \\ncomplications if you want to avoid that allocation, such as various kinds of pooling. \\ndotnet/ru\", \"ntime#60385 introduces a different approach for Regex, which is then used by \\ndotnet/runtime#60786 f\", \"rom [@olsaarik](https://github.com/olsaarik) specifically in the \\nNonBacktracking implementation. It\", \" still uses recursion, and thus benefits from the expressiveness of \\nthe recursive algorithm as well\", \" as being able to use stack space and thus avoid additional allocation in \\nthe most common cases, bu\", \"t then to avoid stack overflows, it issues explicit checks to ensure we\\u2019re \\nnot too deep on the stac\", \"k (.NET has long provided the helpers \\nRuntimeHelpers.EnsureSufficientExecutionStack and \\nRuntimeHel\", \"pers.TryEnsureSufficientExecutionStack for this purpose). If it detects it\\u2019s too deep \\non the stack,\", \" it forks off continued execution into another thread. Hitting this condition is expensive, \\nbut it\\u2019\", \"s very rarely if ever actually hit in practice (e.g. the only time it\\u2019s hit in our vast functional t\", \"ests \\nare in the tests explicitly written to stress it), it keeps the code simple, and it keeps the \", \"typical cases \\nfast. A similar approach is used in other areas of dotnet/runtime, such as in System.\", \"Linq.Expressions. \\nAs was mentioned in my previous blog post about regular expressions, both the bac\", \"ktracking \\nimplementations and the non-backtracking implementation have their place. The main benefi\", \"t of the \\nnon-backtracking implementation is predictability: because of the linear processing guaran\", \"tee, once \\nyou\\u2019ve constructed the regex, you don\\u2019t need to worry about malicious inputs causing wors\", \"t-case \\nbehavior in the processing of your potentially susceptible expressions. This doesn\\u2019t mean \\nR\", \"egexOptions.NonBacktracking is always the fastest; in fact, it\\u2019s frequently not. In exchange for \\nre\", \"duced best-case performance, it provides the best worst-case performance, and for some kinds of \\napp\", \"lications, that\\u2019s a really worthwhile and valuable tradeoff. \\n \\n133 \\nCHAPTER 11 | Regex \\n \\nNew APIs \", \"\\nRegex gets several new methods in .NET 7, all of which enable improved performance. The simplicity \", \"\\nof the new APIs likely also misrepresents how much work was necessary to enable them, in particular\", \" \\nbecause the new APIs all support ReadOnlySpan<char> inputs into the regex engines. \\ndotnet/runtime\", \"#65473 brings Regex into the span-based era of .NET, overcoming a significant \\nlimitation in Regex s\", \"ince spans were introduced back in .NET Core 2.1. Regex has historically been \\nbased on processing S\", \"ystem.String inputs, and that fact pervades the Regex design and \\nimplementation, including the APIs\", \" exposed for the extensibility model Regex.CompileToAssembly \\nrelied on in .NET Framework (CompileTo\", \"Assembly is now obsoleted and has never been functional in \\n.NET Core). One subtly that relies on th\", \"e nature of string as the input is how match information is \\nreturned to callers. Regex.Match return\", \"s a Match object that represents the first match in the input, \\nand that Match object exposes a Next\", \"Match method that enables moving to the next match. That \\nmeans the Match object needs to store a re\", \"ference to the input, so that it can be fed back into the \\nmatching engine as part of such a NextMat\", \"ch call. If that input is a string, great, no problem. But if \\nthat input is a ReadOnlySpan<char>, t\", \"hat span as a ref struct can\\u2019t be stored on the class Match \\nobject, since ref structs can only live\", \" on the stack and not the heap. That alone would make it a \\nchallenge to support spans, but the prob\", \"lem is even more deeply rooted. All of the regex engines rely \\non a RegexRunner, a base class that s\", \"tores on it all of the state necessary to feed into the \\nFindFirstChar and Go methods that compose t\", \"he actual matching logic for the regular expressions \\n(these methods contain all of the core code fo\", \"r performing the match, with FindFirstChar being an \\noptimization to skip past input positions that \", \"couldn\\u2019t possibly start a match and then Go performing \\nthe actual matching logic). If you look at t\", \"he internal RegexInterpreter type, which is the engine you \\nget when you construct a new Regex(...) \", \"without the RegexOptions.Compiled or \\nRegexOptions.NonBacktracking flags, it derives from RegexRunne\", \"r. Similarly, when you use \\nRegexOptions.Compiled, it hands off the dynamic methods it reflection em\", \"its to a type derived from \\nRegexRunner, RegexOptions.NonBacktracking has a SymbolicRegexRunnerFacto\", \"ry that produces \\ntypes derived from RegexRunner, and so on. Most relevant here, RegexRunner is publ\", \"ic, because the \\ntypes generated by the Regex.CompileToAssembly type (and now the regex source gener\", \"ator) include \\nones derived from this RegexRunner. Those FindFirstChar and Go methods are thus abstr\", \"act and \\nprotected, and parameterless, because they pick up all the state they need from protected m\", \"embers \\non the base class. That includes the string input to process. So what about spans? We could \", \"of \\ncourse have just called ToString() on an input ReadOnlySpan<char>. That would have been \\nfunctio\", \"nally correct, but would have completely defeated the purpose of accepting spans, and worse, \\nwould \", \"have been so unexpected as to likely cause consuming apps to be worse performing than they \\nwould ha\", \"ve without the APIs. Instead, we needed a new approach and new APIs. \\nFirst, we made FindFirstChar a\", \"nd Go virtual instead of abstract. The design that splits these methods \\nis largely antiquated, and \", \"in particular the forced separation between a stage of processing where you \\nfind the next possible \", \"location of a match and then a stage where you actually perform the match at \\nthat location doesn\\u2019t \", \"align well with all engines, like the one used by NonBacktracking (which initially \\nimplemented Find\", \"FirstChar as a nop and had all its logic in Go). Then we added a new virtual Scan \\nmethod which, imp\", \"ortantly, takes a ReadOnlySpan<char> as a parameter; the span can\\u2019t be exposed \\nfrom the base RegexR\", \"unner and must be passed in. We then implemented FindFirstChar and Go in \\nterms of Scan, and made th\", \"em \\u201cjust work.\\u201d Then, all of the engines are implemented in terms of that \\n \\n134 \\nCHAPTER 11 | Regex\", \" \\n \\nspan; they no longer need to access the protected RegexRunner.runtext, RegexRunner.runtextbeg, \\n\", \"and RegexRunner.runtextend members that surface the input; they\\u2019re just handed the span, already \\nsl\", \"iced to the input region, and process that. One of the neat things about this from a performance \\npe\", \"rspective is it enables the JIT to do a better job at shaving off various overheads, in particular \\n\", \"around bounds checking. When the logic is implemented in terms of string, in addition to the input \\n\", \"string itself the engine is also handed the beginning and end of the region of the input to process \", \"\\n(since the developer could have called a method like Regex.Match(string input, int beginning, \\nint \", \"length) in order to only process a substring). Obviously the engine matching logic is way more \\ncomp\", \"licated than this, but simplifying, imagine the entirety of the engine was just a loop over the \\ninp\", \"ut. With the input, beginning, and length, that would look like: \\n[Benchmark] \\n[Arguments(\\\"abc\\\", 0, \", \"3)] \\npublic void Scan(string input, int beginning, int length) \\n{ \\n    for (int i = beginning; i < l\", \"ength; i++) \\n    { \\n        Check(input[i]); \\n    } \\n} \\n \\n[MethodImpl(MethodImplOptions.AggressiveIn\", \"lining)] \\nprivate void Check(char c) { } \\nThat will result in the JIT generating assembly code along\", \" the lines of this: \\n; Program.Scan(System.String, Int32, Int32) \\n       sub       rsp,28 \\n       cm\", \"p       r8d,r9d \\n       jge       short M00_L01 \\n       mov       eax,[rdx+8] \\nM00_L00: \\n       cmp \", \"      r8d,eax \\n       jae       short M00_L02 \\n       inc       r8d \\n       cmp       r8d,r9d \\n     \", \"  jl        short M00_L00 \\nM00_L01: \\n       add       rsp,28 \\n       ret \\nM00_L02: \\n       call     \", \" CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes of code 36 \\nIn contrast, if we\\u2019re dealin\", \"g with a span, which already factors in the bounds, then we can write a more \\ncanonical loop like th\", \"is: \\n[Benchmark] \\n[Arguments(\\\"abc\\\")] \\npublic void Scan(ReadOnlySpan<char> input) \\n{ \\n    for (int i \", \"= 0; i < input.Length; i++) \\n    { \\n        Check(input[i]); \\n    } \\n} \\n \\n135 \\nCHAPTER 11 | Regex \\n \", \"\\n \\n[MethodImpl(MethodImplOptions.AggressiveInlining)] \\nprivate void Check(char c) { } \\nAnd when it c\", \"omes to compilers, something in a canonical form is really good, because the more \\ncommon the shape \", \"of the code, the more likely it is to be heavily optimized: \\n; Program.Scan(System.ReadOnlySpan`1<Ch\", \"ar>) \\n       mov       rax,[rdx] \\n       mov       edx,[rdx+8] \\n       xor       ecx,ecx \\n       tes\", \"t      edx,edx \\n       jle       short M00_L01 \\nM00_L00: \\n       mov       r8d,ecx \\n       movsx    \", \" r8,word ptr [rax+r8*2] \\n       inc       ecx \\n       cmp       ecx,edx \\n       jl        short M00_\", \"L00 \\nM00_L01: \\n       ret \\n; Total bytes of code 27 \\nSo even without all the other benefits that com\", \"e from operating in terms of span, we immediately get \\nlow-level code generation benefits from perfo\", \"rming all the logic in terms of spans. While the above \\nexample was made up (obviously the matching \", \"logic does more than a simple for loop), here\\u2019s a real \\nexample. When a regex contains a \\\\b, as part\", \" of evaluating the input against that \\\\b the backtracking \\nengines call a RegexRunner.IsBoundary hel\", \"per method which checks whether the character at the \\ncurrent position is a word character and wheth\", \"er the character before it is a word character (factoring \\nin the bounds of the input as well). Here\", \"\\u2019s what the IsBoundary method based on string looked like \\n(the runtext it\\u2019s using is the name of th\", \"e string field on RegexRunner that stores the input): \\n[Benchmark] \\n[Arguments(0, 0, 26)] \\npublic bo\", \"ol IsBoundary(int index, int startpos, int endpos) \\n{ \\n    return (index > startpos && IsBoundaryWor\", \"dChar(runtext[index - 1])) != \\n           (index < endpos   && IsBoundaryWordChar(runtext[index])); \", \"\\n} \\n \\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate bool IsBoundaryWordChar(char c) => false; \", \"\\nand here\\u2019s what the span version looks like: \\n[Benchmark] \\n[Arguments(\\\"abcdefghijklmnopqrstuvwxyz\\\",\", \" 0)] \\npublic bool IsBoundary(ReadOnlySpan<char> inputSpan, int index) \\n{ \\n    int indexM1 = index - \", \"1; \\n    return ((uint)indexM1 < (uint)inputSpan.Length && \\nIsBoundaryWordChar(inputSpan[indexM1])) !\", \"= \\n            ((uint)index < (uint)inputSpan.Length && IsBoundaryWordChar(inputSpan[index])); \\n} \\n \", \"\\n[MethodImpl(MethodImplOptions.NoInlining)] \\nprivate bool IsBoundaryWordChar(char c) => false; \\n \\n13\", \"6 \\nCHAPTER 11 | Regex \\n \\nAnd here\\u2019s the resulting assembly: \\n; Program.IsBoundary(Int32, Int32, Int3\", \"2) \\n       push      rdi \\n       push      rsi \\n       push      rbp \\n       push      rbx \\n       s\", \"ub       rsp,28 \\n       mov       rdi,rcx \\n       mov       esi,edx \\n       mov       ebx,r9d \\n     \", \"  cmp       esi,r8d \\n       jle       short M00_L00 \\n       mov       rcx,rdi \\n       mov       rcx,\", \"[rcx+8] \\n       lea       edx,[rsi-1] \\n       cmp       edx,[rcx+8] \\n       jae       short M00_L04 \", \"\\n       mov       edx,edx \\n       movzx     edx,word ptr [rcx+rdx*2+0C] \\n       mov       rcx,rdi \\n \", \"      call      qword ptr [Program.IsBoundaryWordChar(Char)] \\n       jmp       short M00_L01 \\nM00_L0\", \"0: \\n       xor       eax,eax \\nM00_L01: \\n       mov       ebp,eax \\n       cmp       esi,ebx \\n       j\", \"ge       short M00_L02 \\n       mov       rcx,rdi \\n       mov       rcx,[rcx+8] \\n       cmp       esi\", \",[rcx+8] \\n       jae       short M00_L04 \\n       mov       edx,esi \\n       movzx     edx,word ptr [r\", \"cx+rdx*2+0C] \\n       mov       rcx,rdi \\n       call      qword ptr [Program.IsBoundaryWordChar(Char)\", \"] \\n       jmp       short M00_L03 \\nM00_L02: \\n       xor       eax,eax \\nM00_L03: \\n       cmp       eb\", \"p,eax \\n       setne     al \\n       movzx     eax,al \\n       add       rsp,28 \\n       pop       rbx \\n\", \"       pop       rbp \\n       pop       rsi \\n       pop       rdi \\n       ret \\nM00_L04: \\n       call \", \"     CORINFO_HELP_RNGCHKFAIL \\n       int       3 \\n; Total bytes of code 117 \\n \\n; Program.IsBoundary(\", \"System.ReadOnlySpan`1<Char>, Int32) \\n       push      r14 \\n       push      rdi \\n       push      rs\", \"i \\n       push      rbp \\n \\n137 \\nCHAPTER 11 | Regex \\n \\n       push      rbx \\n       sub       rsp,20 \", \"\\n       mov       rdi,rcx \\n       mov       esi,r8d \\n       mov       rbx,[rdx] \\n       mov       eb\", \"p,[rdx+8] \\n       lea       edx,[rsi-1] \\n       cmp       edx,ebp \\n       jae       short M00_L00 \\n \", \"      mov       edx,edx \\n       movzx     edx,word ptr [rbx+rdx*2] \\n       mov       rcx,rdi \\n      \", \" call      qword ptr [Program.IsBoundaryWordChar(Char)] \\n       jmp       short M00_L01 \\nM00_L00: \\n \", \"      xor       eax,eax \\nM00_L01: \\n       mov       r14d,eax \\n       cmp       esi,ebp \\n       jae  \", \"     short M00_L02 \\n       mov       edx,esi \\n       movzx     edx,word ptr [rbx+rdx*2] \\n       mov \", \"      rcx,rdi \\n       call      qword ptr [Program.IsBoundaryWordChar(Char)] \\n       jmp       short\", \" M00_L03 \\nM00_L02: \\n       xor       eax,eax \\nM00_L03: \\n       cmp       r14d,eax \\n       setne     \", \"al \\n       movzx     eax,al \\n       add       rsp,20 \\n       pop       rbx \\n       pop       rbp \\n  \", \"     pop       rsi \\n       pop       rdi \\n       pop       r14 \\n       ret \\n; Total bytes of code 94\", \" \\nThe most interesting thing to notice here is the: \\ncall      CORINFO_HELP_RNGCHKFAIL \\nint       3 \", \"\\nat the end of the first version that doesn\\u2019t exist at the end of the second. As we saw earlier, thi\", \"s is \\nwhat the generated assembly looks like when the JIT is emitting the code to throw an index out\", \" of \\nrange exception for an array, string, or span. It\\u2019s at the end because it\\u2019s considered to be \\u201cc\", \"old,\\u201d rarely \\nexecuted. It exists in the first because the JIT can\\u2019t prove based on local analysis o\", \"f that function that \\nthe runtext[index-1] and runtext[index] accesses will be in range of the strin\", \"g (it can\\u2019t know or \\ntrust any implied relationship between startpos, endpos, and the bounds of runt\", \"ext). But in the \\nsecond, the JIT can know and trust that the ReadOnlySpan<char>\\u2019s lower bound is 0 \", \"and upper bound \\n(exclusive) is the span\\u2019s Length, and with how the method is constructed, it can th\", \"en prove that the \\nspan accesses are always in bound. As such, it doesn\\u2019t need to emit any bounds ch\", \"ecks in the method, \\nand the method then lacks the tell-tale signature of the index out of range thr\", \"ow. You can see more \\nexamples of taking advantage of spans now being at the heart of the all of the\", \" engines in \\n \\n138 \\nCHAPTER 11 | Regex \\n \\ndotnet/runtime#66129, dotnet/runtime#66178, and dotnet/run\", \"time#72728, all of which clean up \\nunnecessary checks against the bounds that are then always 0 and \", \"span.Length. \\nOk, so the engines are now able to be handed span inputs and process them, great, what\", \" can we do \\nwith that? Well, Regex.IsMatch is easy: it\\u2019s not encumbered by needing to perform multip\", \"le matches, \\nand thus doesn\\u2019t need to worry about how to store that input ReadOnlySpan<char> for the\", \" next \\nmatch. Similarly, the new Regex.Count, which provides an optimized implementation for countin\", \"g \\nhow many matches there are in the input, can bypass using Match or MatchCollection, and thus can \", \"\\neasily operate over spans as well; dotnet/runtime#64289 added string-based overloads, and \\ndotnet/r\", \"untime#66026 added span-based overloads. We can optimize Count further by passing \\nadditional inform\", \"ation into the engines to let them know how much information they actually need to \\ncompute. For exa\", \"mple, I noted previously that NonBacktracking is fairly pay-for-play in how much \\nwork it needs to d\", \"o relative to what information it needs to gather. It\\u2019s cheapest to just determine \\nwhether there is\", \" a match, as it can do that in a single forward pass through the input. If it also needs \\nto compute\", \" the actual starting and ending bounds, that requires another reverse pass through some \\nof the inpu\", \"t. And if it then also needs to compute capture information, that requires yet another \\nforward pass\", \" based on an NFA (even if the other two were DFA-based). Count needs the bounds \\ninformation, as it \", \"needs to know where to start looking for the next match, but it doesn\\u2019t need the \\ncapture informatio\", \"n, since none of that capture information is handed back to the caller. \\ndotnet/runtime#68242 update\", \"s the engines to receive this additional information, such that methods \\nlike Count can be made more\", \" efficient. \\nSo, IsMatch and Count can work with spans. But we still don\\u2019t have a method that lets y\", \"ou actually get \\nback that match information. Enter the new EnumerateMatches method, added by \\ndotne\", \"t/runtime#67794. EnumerateMatches is very similar to Match, except instead of handing back a \\nMatch \", \"class instance, it hands back a ref struct enumerator: \\npublic ref struct ValueMatchEnumerator \\n{ \\n \", \"   private readonly Regex _regex; \\n    private readonly ReadOnlySpan<char> _input; \\n    private Valu\", \"eMatch _current; \\n    private int _startAt; \\n    private int _prevLen; \\n    ... \\n} \\nBeing a ref stru\", \"ct, the enumerator is able to store a reference to the input span, and is thus able to \\niterate thro\", \"ugh matches, which are represented by the ValueMatch ref struct. Notably, today \\nValueMatch doesn\\u2019t \", \"provide capture information, which also enables it to partake in the optimizations \\npreviously menti\", \"oned for Count. Even if you have an input string, EnumerateMatches is thus a way to \\nhave ammortized\", \" allocation-free enumeration of all matches in the input. In .NET 7, though, there isn\\u2019t \\na way to h\", \"ave such allocation-free enumeration if you also need all the capture data. That\\u2019s something \\nwe\\u2019ll \", \"investigate designing in the future if/as needed. \\nTryFindNextPossibleStartingPosition \\nAs noted ear\", \"lier, the core of all of the engines is a Scan(ReadOnlySpan<char>) method that accepts \\nthe input te\", \"xt to match, combines that with positional information from the base instance, and exits \\n \\n139 \\nCHA\", \"PTER 11 | Regex \\n \\nwhen it either finds the location of the next match or exhausts the input without\", \" finding another. For \\nthe backtracking engines, the implementation of that method is logically as f\", \"ollows: \\nprotected override void Scan(ReadOnlySpan<char> inputSpan) \\n{ \\n    while (!TryMatchAtCurren\", \"tPosition(inputSpan) && \\n           base.runtextpos != inputSpan.Length) \\n    { \\n        base.runtex\", \"tpos++; \\n    } \\n} \\nWe try to match the input at the current position, and if we\\u2019re successful in doi\", \"ng so, that\\u2019s it, we exit. \\nIf the current position doesn\\u2019t match, however, then if there\\u2019s any inpu\", \"t remaining we \\u201cbump\\u201d the \\nposition and start the process over. In regex engine terminology, this is\", \" often referred to as a \\n\\u201cbumpalong loop.\\u201d However, if we actually ran the full matching process at \", \"every input character, that \\ncould be unnecessarily slow. For many patterns, there\\u2019s something about\", \" the pattern that would \\nenable us to be more thoughtful about where we perform full matches, quickl\", \"y skipping past locations \\nthat couldn\\u2019t possibly match, and only spending our time and resources on\", \" locations that have a real \\nchance of matching. To elevate that concept to a first-class one, the b\", \"acktracking engines\\u2019 \\n\\u201cbumpalong loop\\u201d is typically more like the following (I say \\u201ctypically\\u201d becau\", \"se in some cases the \\ncompiled and source generated regexes are able to generate something even bett\", \"er). \\nprotected override void Scan(ReadOnlySpan<char> inputSpan) \\n{ \\n    while (TryFindNextPossibleS\", \"tartingPosition(inputSpan) && \\n           !TryMatchAtCurrentPosition(inputSpan) && \\n           base.\", \"runtextpos != inputSpan.Length) \\n    { \\n        base.runtextpos++; \\n    } \\n} \\nAs with FindFirstChar \", \"previously, that TryFindNextPossibleStartingPosition has the \\nresponsibility of searching as quickly\", \" as possible for the next place to match (or determining that \\nnothing else could possibly match, in\", \" which case it would return false and the loop would exit). As \\nFindFirstChar, and it was embued wit\", \"h multiple ways of doing its job. In .NET 7, \\nTryFindNextPossibleStartingPosition learns many more a\", \"nd improved ways of helping the engine \\nbe fast. \\nIn .NET 6, the interpreter engine had effectively \", \"two ways of implementing \\nTryFindNextPossibleStartingPosition: a Boyer-Moore substring search if the\", \" pattern began with a \\nstring (potentially case-insensitive) of at least two characters, and a linea\", \"r scan for a character class \\nknown to be the set of all possible chars that could begin a match. Fo\", \"r the latter case, the interpreter \\nhad eight different implementations for matching, based on a com\", \"bination of whether \\nRegexOptions.RightToLeft was set or not, whether the character class required c\", \"ase-insensitive \\ncomparison or not, and whether the character class contained only a single characte\", \"r or more than \\none character. Some of these were more optimized than others, e.g. a left-to-right, \", \"case-sensitive, \\nsingle-char search would use an IndexOf(char) to search for the next location, an o\", \"ptimization \\nadded in .NET 5. However, every time this operation was performed, the engine would nee\", \"d to \\nrecompute which case it would be. dotnet/runtime#60822 improved this, introducing an internal \", \"\\n \\n140 \\nCHAPTER 11 | Regex \\n \\nenum of the strategies used by TryFindNextPossibleStartingPosition to \", \"find the next opportunity, \\nadding a switch to TryFindNextPossibleStartingPosition to quickly jump t\", \"o the right strategy, \\nand precomputing which strategy to use when the interpreter was constructed. \", \"This not only made \\nthe interpreter\\u2019s implementation at match time faster, it made it effectively fr\", \"ee (in terms of runtime \\noverhead at match time) to add additional strategies. \\ndotnet/runtime#60888\", \" then added the first additional strategy. The implementation was already \\ncapable of using IndexOf(\", \"char), but as mentioned previously in this post, the implementation of \\nIndexOf(ReadOnlySpan<char>) \", \"got way better in .NET 7 in many cases, to the point where it ends up \\nbeing significantly better th\", \"an Boyer-Moore in all but the most corner of corner cases. So this PR \\nenables a new IndexOf(ReadOnl\", \"ySpan<char>) strategy to be used to search for a prefix string in the \\ncase where the string is case\", \"-sensitive. \\nprivate static readonly string s_haystack = new \\nHttpClient().GetStringAsync(\\\"https://w\", \"ww.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\"\", \", RegexOptions.Compiled); \\n \\n[Benchmark] \\npublic int Count() => _regex.Matches(s_haystack).Count; \\nM\", \"ethod \\nRuntime \\nMean \\nRatio \\nCount \\n.NET 6.0 \\n377.32 us \\n1.00 \\nCount \\n.NET 7.0 \\n55.44 us \\n0.15 \\ndotn\", \"et/runtime#61490 then removed Boyer-Moore entirely. This wasn\\u2019t done in the previously \\nmentioned PR\", \" because of lack of a good way to handle case-insensitive matches. However, this PR \\nalso special-ca\", \"sed ASCII letters to teach the optimizer how to turn an ASCII case-insensitive match \\ninto a set of \", \"both casings of that letter (excluding the few known to be a problem, like i and k, which \\ncan both \", \"be impacted by the employed culture and which might map case-insensitively to more than \\ntwo values)\", \". With enough of the common cases covered, rather than use Boyer-Moore to perform a \\ncase-insensitiv\", \"e search, the implementation just uses IndexOfAny(char, char, ...) to search for \\nthe starting set, \", \"and the vectorization employed by IndexOfAny ends up outpacing the old \\nimplementation handily in re\", \"al-world cases. This PR goes further than that, such that it doesn\\u2019t just \\ndiscover the \\u201cstarting se\", \"t,\\u201d but is able to find all of the character classes that could match a pattern a \\nfixed-offset from\", \" the beginning; that then gives the analyzer the ability to choose the set that\\u2019s \\nexpected to be le\", \"ast common and issue a search for it instead of whatever happens to be at the \\nbeginning. The PR goe\", \"s even further, too, motivated in large part by the non-backtracking engine. The \\nnon-backtracking e\", \"ngine\\u2019s prototype implementation also used IndexOfAny(char, char, ...) when \\nit arrived at a startin\", \"g state and was thus able to quickly skip through input text that wouldn\\u2019t have a \\nchance of pushing\", \" it to the next state. We wanted all of the engines to share as much logic as \\npossible, in particul\", \"ar around this speed ahead, and so this PR unified the interpreter with the non-\\nbacktracking engine\", \" to have them share the exact same TryFindNextPossibleStartingPosition \\nroutine (which the non-backt\", \"racking engine just calls at an appropriate place in its graph traversal \\nloop). Since the non-backt\", \"racking engine was already using IndexOfAny in this manner, initially not \\ndoing so popped as a sign\", \"ificant regression on a variety of patterns we measure, and this caused us to \\ninvest in using it ev\", \"erywhere. This PR also introduced the first special-casing for case-insensitive \\ncomparisons into th\", \"e compiled engine, e.g. if we found a set that was [Ee], rather than emitting a \\n \\n141 \\nCHAPTER 11 |\", \" Regex \\n \\ncheck akin to c == 'E' || c == 'e', we\\u2019d instead emit a check akin to (c | 0x20) == 'e' (t\", \"hose \\nfun ASCII tricks discussed earlier coming into play again). \\nprivate static readonly string s_\", \"haystack = new \\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Resul\", \"t; \\nprivate Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled | \\nRegexOptions.Ignore\", \"Case); \\n \\n[Benchmark] \\npublic int Count() => _regex.Matches(s_haystack).Count; \\nMethod \\nRuntime \\nMea\", \"n \\nRatio \\nCount \\n.NET 6.0 \\n499.3 us \\n1.00 \\nCount \\n.NET 7.0 \\n177.7 us \\n0.35 \\nThe previous PR started \", \"turning IgnoreCase pattern text into sets, in particular for ASCII, e.g. (?i)a \\nwould become [Aa]. T\", \"hat PR hacked in the support for ASCII knowing that something more complete \\nwould be coming along, \", \"as it did in dotnet/runtime#67184. Rather than hardcoding the case-\\ninsensitive sets that just the A\", \"SCII characters map to, this PR essentially hardcodes the sets for every \\npossible char. Once that\\u2019s\", \" done, we no longer need to know about case-insensitivity at match time \\nand can instead just double\", \"-down on efficiently matching sets, which we already need to be able to \\ndo well. Now, I said it enc\", \"odes the sets for every possible char; that\\u2019s not entirely true. If it were true, \\nthat would take u\", \"p a large amount of memory, and in fact, most of that memory would be wasted \\nbecause the vast major\", \"ity of characters don\\u2019t participate in case conversion\\u2026 there are only ~2,000 \\ncharacters that we ne\", \"ed to handle. As such, the implementation employs a three-tier table scheme. \\nThe first table has 64\", \" elements, dividing the full range of chars into 64 groupings; of those 64 groups, \\n54 of them have \", \"no characters that participate in case conversion, so if we hit one of those entries, we \\ncan immedi\", \"ately stop the search. For the remaining 10 that do have at least one character in their \\nrange part\", \"icipating, the character and the value from the first table are used to compute an index into \\nthe s\", \"econd table; there, too, the majority of entries say that nothing participates in case conversion. \\n\", \"It\\u2019s only if we get a legitimate hit in the second table does that give us an index into the third t\", \"able, at \\nwhich location we can find all of the characters considered case-equivalent with the first\", \". \\ndotnet/runtime#63477 (and then later improved in dotnet/runtime#66572) proceeded to add another \\n\", \"searching strategy, this one inspired by nim-regex\\u2019s literal optimizations. There are a multitude of\", \" \\nregexes we track from a performance perspective to ensure we\\u2019re not regressing in common cases \\nan\", \"d to help guide investments. One is the set of patterns in mariomka/regex-benchmark languages \\nregex\", \" benchmark. One of those is for URIs: \\n(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\". This\", \" pattern defies the thus-far \\nenabled strategies for finding a next good location, as it\\u2019s guarantee\", \"d to begin with a \\u201cword \\ncharacter\\u201d (\\\\w), which includes ~50,000 of the ~65,000 possible characters;\", \" we don\\u2019t have a good way \\nof vectorizing a search for such a character class. However, this pattern\", \" is interesting in that it begins \\nwith a loop, and not only that, it\\u2019s an upper-unbounded loop whic\", \"h our analysis will determine is \\natomic, because the character guaranteed to immediately follow the\", \" loop is a ':', which is itself not a \\nword character, and thus there\\u2019s nothing the loop could match\", \" and give up as part of backtracking \\nthat would match ':'. That all lends itself to a different app\", \"roach to vectorization: rather than trying \\nto search for the \\\\w character class, we can instead sea\", \"rch for the substring \\\"://\\\", and then once we \\n \\n142 \\nCHAPTER 11 | Regex \\n \\nfind it, we can match ba\", \"ckwards through as many [\\\\w]s as we can find; in this case, the only \\nconstraint is we need to match\", \" at least one. This PR added that strategy, for a literal after an atomic \\nloop, to all of the engin\", \"es. \\nprivate static readonly string s_haystack = new \\nHttpClient().GetStringAsync(\\\"https://www.guten\", \"berg.org/files/1661/1661-0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#\", \"]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\", \\nRegexOptions.Compiled); \\n \\n[Benchmark] \\npublic bool IsMatch() => _re\", \"gex.IsMatch(s_haystack); // Uri's in Sherlock Holmes? \\\"Most \\nunlikely.\\\" \\nMethod \\nRuntime \\nMean \\nRati\", \"o \\nIsMatch \\n.NET 6.0 \\n4,291.77 us \\n1.000 \\nIsMatch \\n.NET 7.0 \\n42.40 us \\n0.010 \\nOf course, as has been\", \" talked about elsewhere, the best optimizations aren\\u2019t ones that make \\nsomething faster but rather o\", \"nes that make something entirely unnecessary. That\\u2019s what \\ndotnet/runtime#64177 does, in particular \", \"in relation to anchors. The .NET regex implementation has \\nlong had optimizations for patterns with \", \"a starting anchor: if the pattern begins with ^, for example \\n(and RegexOptions.Multiline wasn\\u2019t spe\", \"cified), the pattern is rooted to the beginning, meaning it \\ncan\\u2019t possibly match at any position ot\", \"her than 0; as such, with such an anchor, \\nTryFindNextPossibleStartingPosition won\\u2019t do any searchin\", \"g at all. The key here, though, is being \\nable to detect whether the pattern begins with such an anc\", \"hor. In some cases, like ^abc$, that\\u2019s trivial. \\nIn other cases, like ^abc|^def, the existing analys\", \"is had trouble seeing through that alternation to find \\nthe guaranteed starting ^ anchor. This PR fi\", \"xes that. It also adds a new strategy based on discovering \\nthat a pattern has an ending anchor like\", \" $. If the analysis engine can determine a maximum number of \\ncharacters for any possible match, and\", \" it has such an anchor, then it can simply jump to that distance \\nfrom the end of the string, and by\", \"pass even looking at anything before then. \\nprivate static readonly string s_haystack = new \\nHttpCli\", \"ent().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\nprivate Regex _rege\", \"x = new Regex(@\\\"^abc|^def\\\", RegexOptions.Compiled); \\n \\n[Benchmark] \\npublic bool IsMatch() => _regex.\", \"IsMatch(s_haystack); // Why search _all_ the text?! \\nMethod \\nRuntime \\nMean \\nRatio \\nIsMatch \\n.NET 6.0\", \" \\n867,890.56 ns \\n1.000 \\nIsMatch \\n.NET 7.0 \\n33.55 ns \\n0.000 \\ndotnet/runtime#67732 is another PR relat\", \"ed to improving anchor handling. It\\u2019s always fun when a bug \\nfix or code simplification refactoring \", \"turns into a performance improvement. The PR\\u2019s primary purpose \\nwas to simplify some complicated cod\", \"e that was computing the set of characters that could possibly \\nstart a match. It turns out that com\", \"plication was hiding a logic bug which manifested in it missing \\nsome opportunities to report valid \", \"starting character classes, the impact of which is that some \\nsearches which could have been vectori\", \"zed weren\\u2019t. By simplifying the implementation, the bug was \\nfixed, exposing more performance opport\", \"unities. \\n \\n143 \\nCHAPTER 11 | Regex \\n \\nBy this point, the engines are able to use IndexOf(ReadOnlySp\", \"an<char>) to find a substring at the \\nbeginning of a pattern. But sometimes the most valuable substr\", \"ing isn\\u2019t at the beginning, but \\nsomewhere in the middle or even at the end. As long as it\\u2019s at a fi\", \"xed-offset from the beginning of the \\npattern, we can search for it, and then just back-off by the o\", \"ffset to the position we should actually try \\nrunning the match. dotnet/runtime#67907 does exactly t\", \"hat. \\nprivate static readonly string s_haystack = new \\nHttpClient().GetStringAsync(\\\"https://www.gute\", \"nberg.org/files/1661/1661-0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"looking|feeling\\\", Rege\", \"xOptions.Compiled); \\n \\n[Benchmark] \\npublic int Count() => _regex.Matches(s_haystack).Count; // will \", \"search for \\\"ing\\\" \\nMethod \\nRuntime \\nMean \\nRatio \\nCount \\n.NET 6.0 \\n444.2 us \\n1.00 \\nCount \\n.NET 7.0 \\n12\", \"2.6 us \\n0.28 \\nLoops and Backtracking \\nLoop handling in the compiled and source generated engines has\", \" been significantly improved, both \\nwith respect to processing them faster and with respect to backt\", \"racking less. \\nWith regular greedy loops (e.g. c*), there are two directions to be concerned about: \", \"how quickly can \\nwe consume all the elements that match the loop, and how quickly can we give back e\", \"lements that \\nmight be necessary as part of backtracking for the remainder of the expression to matc\", \"h. And with \\nlazy loops, we\\u2019re primarily concerned with backtracking, which is the forward direction\", \" (since lazy \\nloops consume as part of backtracking rather than giving back as part of backtracking)\", \". With PRs \\ndotnet/runtime#63428, dotnet/runtime#68400, dotnet/runtime#64254, and dotnet/runtime#739\", \"10, in \\nboth the compiler and source generator we now make full use of effectively all of the varian\", \"ts of \\nIndexOf, IndexOfAny, LastIndexOf, LastIndexOfAny, IndexOfAnyExcept, and \\nLastIndexOfAnyExcept\", \" in order to speed along these searches. For example, in a pattern like .*abc, \\nthe forward directio\", \"n of that loop entails consuming every character until the next newline, which we \\ncan optimize with\", \" an IndexOf('\\\\n'). Then as part of backtracking, rather than giving up one \\ncharacter at a time, we \", \"can LastIndexOf(\\\"abc\\\") in order to find the next viable location that could \\npossibly match the rema\", \"inder of the pattern. Or for example, in a pattern like [^a-c]*def, the loop \\nwill initially greedil\", \"y consume everything other than 'a', 'b', or 'c', so we can use \\nIndexOfAnyExcept('a', 'b', 'c') to \", \"find the initial end of the loop. And so on. This can yield huge \\nperformance gains, and with the so\", \"urce generator, also makes the generated code more idiomatic \\nand easier to understand. \\nprivate sta\", \"tic readonly string s_haystack = new \\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1\", \"661/1661-0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Compile\", \"d | \\nRegexOptions.Multiline); \\n \\n[Benchmark] \\npublic int Count() => _regex.Matches(s_haystack).Count\", \"; \\n \\n \\n \\n144 \\nCHAPTER 11 | Regex \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nCount \\n.NET 6.0 \\n3,369.5 us \\n1.00 \", \"\\nCount \\n.NET 7.0 \\n430.2 us \\n0.13 \\nSometimes optimizations are well-intended but slightly miss the ma\", \"rk. dotnet/runtime#63398 fixes \\nsuch an issue with an optimization introduced in .NET 5; the optimiz\", \"ation was valuable but only for a \\nsubset of the scenarios it was intended to cover. While TryFindNe\", \"xtPossibleStartingPosition\\u2019s \\nprimary raison d\\u2019\\u00eatre is to update the bumpalong position, it\\u2019s also p\", \"ossible for \\nTryMatchAtCurrentPosition to do so. One of the occasions in which it\\u2019ll do so is when t\", \"he pattern \\nbegins with an upper-unbounded single-character greedy loop. Since processing starts wit\", \"h the loop \\nhaving fully consumed everything it could possibly match, subsequent trips through the s\", \"can loop \\ndon\\u2019t need to reconsider any starting position within that loop; doing so would just be du\", \"plicating \\nwork done in a previous iteration of the scan loop. And as such, TryMatchAtCurrentPositio\", \"n can \\nupdate the bumpalong position to the end of the loop. The optimization added in .NET 5 was du\", \"tifully \\ndoing this, and it did so in a way that fully handled atomic loops. But with greedy loops, \", \"the updated \\nposition was getting updated every time we backtracked, meaning it started going backwa\", \"rds, when it \\nshould have remained at the end of the loop. This PR fixes that, yielding significant \", \"savings in the \\nadditional covered cases. \\nprivate static readonly string s_haystack = new \\nHttpClie\", \"nt().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\nprivate Regex _regex\", \" = new Regex(@\\\".*stephen\\\", RegexOptions.Compiled); \\n \\n[Benchmark] \\npublic int Count() => _regex.Matc\", \"hes(s_haystack).Count; \\nMethod \\nRuntime \\nMean \\nRatio \\nCount \\n.NET 6.0 \\n103,962.8 us \\n1.000 \\nCount \\n.\", \"NET 7.0 \\n336.9 us \\n0.003 \\nAs mentioned elsewhere, the best optimizations are those that make work en\", \"tirely vanish rather than \\njust making work faster. dotnet/runtime#68989, dotnet/runtime#63299, and \", \"dotnet/runtime#63518 \\ndo exactly that by improving the pattern analyzers ability to find and elimina\", \"te more unnecessary \\nbacktracking, a process the analyzer refers to as \\u201cauto-atomicity\\u201d (automatical\", \"ly making loops atomic). \\nFor example, in the pattern a*?b, we have a lazy loop of 'a's followed by \", \"a b. That loop can only \\nmatch 'a's, and 'a' doesn\\u2019t overlap with 'b'. So let\\u2019s say the input is \\\"aa\", \"aaaaaab\\\". The loop is lazy, \\nso we\\u2019ll start out by trying to match just 'b'. It won\\u2019t match, so we\\u2019l\", \"l backtrack into the lazy loop and \\ntry to match \\\"ab\\\". It won\\u2019t match so we\\u2019ll backtrack into the la\", \"zy loop and try to match \\\"aab\\\". And so \\non, until we\\u2019ve consumed all the 'a's such that the rest of \", \"the pattern has a chance of matching the \\nrest of the input. That\\u2019s exactly what an atomic greedy lo\", \"op does, so we can transform the pattern \\na*?b into (?>a*)b, which is much more efficiently processe\", \"d. In fact, we can see exactly how it\\u2019s \\nprocessed just by looking at the source-generated implement\", \"ation of this pattern: \\nprivate bool TryMatchAtCurrentPosition(ReadOnlySpan<char> inputSpan) \\n{ \\n   \", \" int pos = base.runtextpos; \\n    int matchStart = pos; \\n    ReadOnlySpan<char> slice = inputSpan.Sli\", \"ce(pos); \\n \\n145 \\nCHAPTER 11 | Regex \\n \\n \\n    // Match 'a' atomically any number of times. \\n    { \\n  \", \"      int iteration = slice.IndexOfAnyExcept('a'); \\n        if (iteration < 0) \\n        { \\n         \", \"   iteration = slice.Length; \\n        } \\n \\n        slice = slice.Slice(iteration); \\n        pos += i\", \"teration; \\n    } \\n \\n    // Advance the next matching position. \\n    if (base.runtextpos < pos) \\n    \", \"{ \\n        base.runtextpos = pos; \\n    } \\n \\n    // Match 'b'. \\n    if (slice.IsEmpty || slice[0] != \", \"'b') \\n    { \\n        return false; // The input didn't match. \\n    } \\n \\n    // The input matched. \\n \", \"   pos++; \\n    base.runtextpos = pos; \\n    base.Capture(0, matchStart, pos); \\n    return true; \\n} \\n(\", \"Note that those comments aren\\u2019t ones I added for this blog post; the source generator itself is \\nemi\", \"tting commented code.) \\nWhen a regular expression is input, it\\u2019s parsed into a tree-based form. The \", \"\\u201cauto-atomicity\\u201d analysis \\ndiscussed in the previous PR is one form of analysis that walks around th\", \"is tree looking for \\nopportunities to transform portions of the tree into a behaviorally equivalent \", \"alternative that will be \\nmore efficient to execute. Several PRs introduced additional such transfor\", \"mations. \\ndotnet/runtime#63695, for example, looks for \\u201cempty\\u201d and \\u201cnothing\\u201d nodes in the tree that \", \"can be \\nremoved. An \\u201cempty\\u201d node is something that matches the empty string, so for example in the \\n\", \"alternation abc|def||ghi, the third branch of that alternation is empty. A \\u201cnothing\\u201d node is \\nsometh\", \"ing that can\\u2019t match anything, so for example in the concatenation abc(?!)def, that (?!) in \\nmiddle \", \"is a negative lookahead around an empty, which can\\u2019t possibly match anything, as it\\u2019s saying \\nthe ex\", \"pression won\\u2019t match if it\\u2019s followed by an empty string, which everything is. These constructs \\noft\", \"en arise as a result of other transformations rather than being something a developer typically \\nwri\", \"tes by hand, just as there are optimizations in the JIT where you might look at them and say \\u201cwhy \\no\", \"n earth is that something a developer would write\\u201d but it ends up being a valuable optimization \\nany\", \"ways because inlining might transform perfectly reasonable code into something that matches the \\ntar\", \"get pattern. Thus, for example, if you did have abc(?!)def, since that concatenation requires the \\n(\", \"?!) to match in order to be successful, the concatenation itself can simply be replaced by a \\n\\u201cnothi\", \"ng.\\u201d You can see this easily if you try this with the source generator: \\n[GeneratedRegex(@\\\"abc(?!)de\", \"f\\\")] \\n \\n146 \\nCHAPTER 11 | Regex \\n \\nas it will produce a Scan method like this (comment and all): \\npr\", \"otected override void Scan(ReadOnlySpan<char> inputSpan) \\n{ \\n    // The pattern never matches anythi\", \"ng. \\n} \\nAnother set of transformations was introduced in dotnet/runtime#59903, specifically around \\n\", \"alternations (which beyond loops are the other source of backtracking). This introduced two main \\nop\", \"timizations. First, it enables rewriting alternations into alternations of alternations, e.g. transf\", \"orming \\naxy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z), which is then further reduced into ax[yz]|bx[yz]. \", \"This \\ncan enable the backtracking engines to more efficiently process alternations due to fewer bran\", \"ches \\nand thus less potential backtracking. The PR also enabled limited reordering of branches in an\", \" \\nalternation. Generally branches can\\u2019t be reordered, as the order can impact exactly what\\u2019s matched\", \" \\nand what\\u2019s captured, but if the engine can prove there\\u2019s no effect on ordering, then it\\u2019s free to \", \"\\nreorder. One key place that ordering isn\\u2019t a factor is if the alternation is atomic due to it being\", \" \\nwrapped in an atomic group (and the auto-atomicity analysis will add such groups implicitly in som\", \"e \\nsituations). Reordering the branches then enables other optimizations, like the one previously \\nm\", \"entioned from this PR. And then once those optimizations have kicked in, if we\\u2019re left with an atomi\", \"c \\nalternation where every branch begins with a different letter, than can enable further optimizati\", \"ons in \\nterms of how the alternation is lowered; this PR teaches the source generator how to emit a \", \"switch \\nstatement, which leads to both more efficient and more readable code. (The detection of whet\", \"her \\nnodes in the tree are atomic, and other such properties such as performing captures or introduc\", \"ing \\nbacktracking, turned out to be valuable enough that dotnet/runtime#65734 added dedicated suppor\", \"t \\nfor this.) \\nCode generation \\nThe .NET 7 regex implementation has no fewer than four engines: the \", \"interpreter (what you get if you \\ndon\\u2019t explicitly choose another engine), the compiler (what you ge\", \"t with RegexOptions.Compiled), \\nthe non-backtracking engine (what you get with RegexOptions.NonBackt\", \"racking), and the source \\ngenerator (what you get with [GeneratedRegex(...)]). The interpreter and t\", \"he non-backtracking \\nengine don\\u2019t require any kind of code generation; they\\u2019re both based on creatin\", \"g in-memory data \\nstructures that represent how to match input against the pattern. The other two, t\", \"hough, both \\ngenerate code specific to the pattern; the generated code is code attempting to mimick \", \"what you \\nmight write if you weren\\u2019t using Regex at all and were instead writing code to perform a s\", \"imilar match \\ndirectly. The source generator spits out C# that\\u2019s compiled directly into your assembl\", \"y, and the \\ncompiler spits out IL at run-time via reflection emit. The fact that these are generatin\", \"g code specific to \\nthe pattern means there\\u2019s a ton of opportunity to optimize. \\ndotnet/runtime#5918\", \"6 provided the initial implementation of the source generator. This was a direct \\nport of the compil\", \"er, effectively a line-by-line translation of IL into C#; the result is C# akin to what \\nyou\\u2019d get i\", \"f you were to run the generated IL through a decompiler like ILSpy. A bunch of PRs then \\nproceeded t\", \"o iterate on and tweak the source generator, but the biggest improvements came from \\nchanges that ch\", \"anged the compiler and the source generator together. Prior to .NET 5, the compiler \\nspit out IL tha\", \"t was very similar to what the interpreter would do. The interpreter is handed a series of \\ninstruct\", \"ions that it walks through one by one and interprets, and the compiler, handed that same \\n \\n147 \\nCHA\", \"PTER 11 | Regex \\n \\nseries of instructions, would just emit the IL for processing each. It had some o\", \"pportunity for being \\nmore efficient, e.g. loop unrolling, but a lot of value was left on the table.\", \" In .NET 5, an alternate path \\nwas added in support of patterns without backtracking; this code path\", \" was based on being handed \\nthe parsed node tree rather than being based on the series of instructio\", \"ns, and that higher-level form \\nenabled the compiler to derive more insights about the pattern that \", \"it could then use to generate \\nmore efficient code. In .NET 7, support for all regex features were i\", \"ncrementally added in, over the \\ncourse of multiple PRs, in particular dotnet/runtime#60385 for back\", \"tracking single char loops, \\ndotnet/runtime#61698 for backtracking single char lazy loops, dotnet/ru\", \"ntime#61784 for other \\nbacktracking lazy loops, and dotnet/runtime#61906 for other backtracking loop\", \"s as well as back \\nreferences and conditionals. At that point, the only features missing were suppor\", \"t for \\nRegexOptions.RightToLeft and lookbehinds (which are implemented in terms of right-to-left), a\", \"nd \\nwe decided based on relatively little use of these features that we needn\\u2019t keep around the old \", \"\\ncompiler code just to enable them. So, dotnet/runtime#62318 deleted the old implementation. But, \\ne\", \"ven though these features are relatively rare, it\\u2019s a lot easier to tell a story that \\u201call patterns \", \"are \\nsupported\\u201d than one that requires special callouts and exceptions, so dotnet/runtime#66127 and \", \"\\ndotnet/runtime#66280 added full lookbehind and RightToLeft support such that there were no \\ntakebac\", \"ks. At this point, both the compiler and source generator now supported everything the \\ncompiler pre\", \"viously did, but now with the more modernized code generation. This code generation is \\nin turn what\", \" enables many of the optimizations previously discussed, e.g. it provides the opportunity \\nto use AP\", \"Is like LastIndexOf as part of backtracking, which would have been near impossible with the \\npreviou\", \"s approach. \\nOne of the great things about the source generator emitting idiomatic C# is it makes it\", \" easy to iterate. \\nEvery time you put in a pattern and see what the generator emits, it\\u2019s like being\", \" asked to do a code \\nreview of someone else\\u2019s code, and you very frequently see something \\u201cnew\\u201d wort\", \"hy of comment, or \\nin this case, improving the generator to address the issue. And so a bunch of PRs\", \" were originated \\nbased on reviewing what the generator emitted and then tweaking the generator to d\", \"o better (and \\nsince the compiler was effectively entirely rewritten along with the source generator\", \", they maintain the \\nsame structure, and it\\u2019s easy to port improvements from one to the other). For \", \"example, \\ndotnet/runtime#68846 and dotnet/runtime#69198 tweaked how some comparisons were being \\nper\", \"formed in order for them to convey enough information to the JIT that it can eliminate some \\nsubsequ\", \"ent bounds checking, and dotnet/runtime#68490 recognized a variety of conditions being \\nemitted that\", \" could never happen in some situations observable statically and was able to elide all that \\ncode ge\", \"n. It also became obvious that some patterns didn\\u2019t need the full expressivity of the scan loop, \\nan\", \"d a more compact and customized Scan implementation could be used. dotnet/runtime#68560 \\ndoes that, \", \"such that, for example, a simple pattern like hello won\\u2019t emit a loop at all and will instead \\nhave \", \"a simpler Scan implementation like: \\nprotected override void Scan(ReadOnlySpan<char> inputSpan) \\n{ \\n\", \"    if (TryFindNextPossibleStartingPosition(inputSpan)) \\n    { \\n        // The search in TryFindNext\", \"PossibleStartingPosition performed the entire match. \\n        int start = base.runtextpos; \\n        \", \"int end = base.runtextpos = start + 5; \\n        base.Capture(0, start, end); \\n    } \\n} \\n \\n148 \\nCHAPT\", \"ER 11 | Regex \\n \\nThe compiler and source generator were also updated to take advantage of newer feat\", \"ures. \\ndotnet/runtime#63277, for example, teaches the source generator how to determine if unsafe co\", \"de is \\nallowed, and if it is, it emits a [SkipLocalsInit] for the core logic; the matching routine c\", \"an result in \\nmany locals being emitted, and SkipLocalsInit can make it cheaper to call the function\", \" due to less \\nzero\\u2019ing being necessary. Then there\\u2019s the issue of where the code is generated; we wa\", \"nt helper \\nfunctions (like the \\\\w IsWordChar helper introduced in dotnet/runtime#62620) that can be \", \"shared \\namongst multiple generated regexes, and we want to be able to share the exact same regex \\nim\", \"plementation if the same pattern/options/timeout combination are used in multiple places in the \\nsam\", \"e assembly (dotnet/runtime#66747), but doing so then exposes this implementation detail to user \\ncod\", \"e in the same assembly. To still be able to get the perf benefits of such code sharing while \\navoidi\", \"ng the resulting complications, dotnet/runtime#66432 and then dotnet/runtime#71765 teaches \\nthe sour\", \"ce generator to use the new file-local types features in C# 11 (dotnet/roslyn#62375). \\nOne last and \", \"interesting code generation aspect is in optimizations around character class matching. \\nMatching ch\", \"aracter classes, whether ones explicitly written by the developer or ones implicitly created \\nby the\", \" engine (e.g. as part of finding the set of all characters that can begin the expression), can be \\no\", \"ne of the more time-consuming aspects of matching; if you imagine having to evaluate this logic for \", \"\\nevery character in the input, then how many instructions needs to be executed as part of matching a\", \" \\ncharacter class directly correlates to how long it takes to perform the overall match. We thus spe\", \"nd \\nsome time trying to ensure we generate optimal matching code for as many categories of character\", \" \\nclasses as possible. dotnet/runtime#67365, for example, improved a bunch of cases found to be \\ncom\", \"mon in real-world use, like specially-recognizing sets like [\\\\d\\\\D], [\\\\s\\\\S], and [\\\\w\\\\W] as meaning \\n\\u201c\", \"match anything\\u201d (just as is the case for . in RegexOptions.Singleline mode), in which case existing \", \"\\noptimizations around the handling of \\u201cmatch anything\\u201d can kick in. \\nprivate static readonly string \", \"s_haystack = new string('a', 1_000_000); \\nprivate Regex _regex = new Regex(@\\\"([\\\\s\\\\S]*)\\\", RegexOption\", \"s.Compiled); \\n \\n[Benchmark] \\npublic Match Match() => _regex.Match(s_haystack); \\nMethod \\nRuntime \\nMea\", \"n \\nRatio \\nMatch \\n.NET 6.0 \\n1,934,393.69 ns \\n1.000 \\nMatch \\n.NET 7.0 \\n91.80 ns \\n0.000 \\nOr dotnet/runti\", \"me#68924, which taught the source generator how to use all of the new char ASCII \\nhelper methods, li\", \"ke char.IsAsciiLetterOrDigit, as well as some existing helpers it didn\\u2019t yet know \\nabout, in the gen\", \"erated output; for example this: \\n[GeneratedRegex(@\\\"[A-Za-z][A-Z][a-z][0-9][A-Za-z0-9][0-9A-F][0-9a-\", \"f][0-9A-Fa-\\nf]\\\\p{Cc}\\\\p{L}[\\\\p{L}\\\\d]\\\\p{Ll}\\\\p{Lu}\\\\p{N}\\\\p{P}\\\\p{Z}\\\\p{S}\\\")] \\nnow produces this in the core\", \" matching logic emitted by the source generator: \\nif ((uint)slice.Length < 17 || \\n    !char.IsAsciiL\", \"etter(slice[0]) || // Match a character in the set [A-Za-z]. \\n    !char.IsAsciiLetterUpper(slice[1])\", \" || // Match a character in the set [A-Z]. \\n    !char.IsAsciiLetterLower(slice[2]) || // Match a cha\", \"racter in the set [a-z]. \\n    !char.IsAsciiDigit(slice[3]) || // Match '0' through '9'. \\n    !char.I\", \"sAsciiLetterOrDigit(slice[4]) || // Match a character in the set [0-9A-Za-z]. \\n \\n149 \\nCHAPTER 11 | R\", \"egex \\n \\n    !char.IsAsciiHexDigitUpper(slice[5]) || // Match a character in the set [0-9A-F]. \\n    !\", \"char.IsAsciiHexDigitLower(slice[6]) || // Match a character in the set [0-9a-f]. \\n    !char.IsAsciiH\", \"exDigit(slice[7]) || // Match a character in the set [0-9A-Fa-f]. \\n    !char.IsControl(slice[8]) || \", \"// Match a character in the set [\\\\p{Cc}]. \\n    !char.IsLetter(slice[9]) || // Match a character in t\", \"he set [\\\\p{L}]. \\n    !char.IsLetterOrDigit(slice[10]) || // Match a character in the set [\\\\p{L}\\\\d]. \", \"\\n    !char.IsLower(slice[11]) || // Match a character in the set [\\\\p{Ll}]. \\n    !char.IsUpper(slice[\", \"12]) || // Match a character in the set [\\\\p{Lu}]. \\n    !char.IsNumber(slice[13]) || // Match a chara\", \"cter in the set [\\\\p{N}]. \\n    !char.IsPunctuation(slice[14]) || // Match a character in the set [\\\\p{\", \"P}]. \\n    !char.IsSeparator(slice[15]) || // Match a character in the set [\\\\p{Z}]. \\n    !char.IsSymb\", \"ol(slice[16])) // Match a character in the set [\\\\p{S}]. \\n{ \\n    return false; // The input didn't ma\", \"tch. \\n} \\nOther changes impacting character class code generation included dotnet/runtime#72328, whic\", \"h \\nimproved the handling of character classes that involve character class subtraction; \\ndotnet/runt\", \"ime#72317 from [@teo-tsirpanis](https://github.com/teo-tsirpanis), which enabled \\nadditional cases w\", \"here the generator could avoid emitting a bitmap lookup; dotnet/runtime#67133, \\nwhich added a tighte\", \"r bounds check when it does emit such a lookup table; and \\ndotnet/runtime#61562, which enables bette\", \"r normalization of character classes in the engine\\u2019s \\ninternal representation, thus leading to downs\", \"tream optimizations better recognizing more character \\nclasses. \\nFinally, with all of these improvem\", \"ents to Regex, a multitude of PRs fixed up regexes being used \\nacross dotnet/runtime, in various way\", \"s. dotnet/runtime#66142, dotnet/runtime#66179 from \\n[@Clockwork-Muse](https://github.com/Clockwork-M\", \"use), and dotnet/runtime#62325 from \\n[@Clockwork-Muse](https://github.com/Clockwork-Muse) all conver\", \"ted Regex usage over to using \\n[GeneratedRegex(...)]. dotnet/runtime#68961 optimized other usage in \", \"various ways. The PR \\nreplaced several regex.Matches(...).Success calls with IsMatch(...), as using \", \"IsMatch has less \\noverhead due to not needing to construct a Match instance and due to being able to\", \" avoid more \\nexpensive phases in the non-backtracking engine to compute exact bounds and capture inf\", \"ormation. \\nThe PR also replaced some Match/Match.MoveNext usage with EnumerateMatches, in order to a\", \"void \\nneeding Match object allocations. The PR also entirely removed at least one regex usage that w\", \"as just \\nas doable as a cheaper IndexOf. dotnet/runtime#68766 also removed a use of \\nRegexOptions.Cu\", \"ltureInvariant. Specifying CultureInvariant changes the behavior of \\nIgnoreCase by alternating which\", \" casing tables are employed; if IgnoreCase isn\\u2019t specified and there\\u2019s \\nno inline case-insensitivity\", \" options ((?i)), then specifying CultureInvariant is a nop. But a \\npotentially expensive one. For an\", \"y code that\\u2019s size conscious, the Regex implementation is structured \\nin a way as to try to make it \", \"as trimmmer friendly as possible. If you only ever do new \\nRegex(pattern), we\\u2019d really like to be ab\", \"le to statically determine that the compiler and non-\\nbacktracking implementations aren\\u2019t needed suc\", \"h that the trimmer can remove it without having a \\nvisible and meaningful negative impact. However, \", \"the trimmer analysis isn\\u2019t yet sophisticated enough \\nto see exactly which options are used and only \", \"keep the additional engines linked in if \\nRegexOptions.Compiled or RegexOptions.NonBacktracking is u\", \"sed; instead, any use of an overload \\nthat takes a RegexOptions will result in that code continuing \", \"to be referenced. By getting rid of the \\noptions, we increase the chances that no code in the app is\", \" using this constructor, which would in turn \\nenable this constructor, the compiler, and the non-bac\", \"ktracking implementation to be trimmed away. \\n \\n150 \\nCHAPTER 12 | Collections \\n \\nCHAPTER 12 \\nCollect\", \"ions \\nSystem.Collections hasn\\u2019t seen as much investment in .NET 7 as it has in previous releases, th\", \"ough \\nmany of the lower-level improvements have a trickle-up effect into collections as well. For ex\", \"ample, \\nDictionary<,>\\u2019s code hasn\\u2019t changed between .NET 6 and .NET 7, but even so, this benchmark \\n\", \"focused on dictionary lookups: \\nprivate Dictionary<int, int> _dictionary = Enumerable.Range(0, 10_00\", \"0).ToDictionary(i => \\ni); \\n \\n[Benchmark] \\npublic int Sum() \\n{ \\n    Dictionary<int, int> dictionary =\", \" _dictionary; \\n    int sum = 0; \\n \\n    for (int i = 0; i < 10_000; i++) \\n    { \\n        if (dictiona\", \"ry.TryGetValue(i, out int value)) \\n        { \\n            sum += value; \\n        } \\n    } \\n \\n    ret\", \"urn sum; \\n} \\nshows a measurable improvement in throughput between .NET 6 and .NET 7: \\nMethod \\nRuntim\", \"e \\nMean \\nRatio \\nCode Size \\nSum \\n.NET 6.0 \\n51.18 us \\n1.00 \\n431 B \\nSum \\n.NET 7.0 \\n43.44 us \\n0.85 \\n413 \", \"B \\nBeyond that, there have been explicit improvements elsewhere in collections. ImmutableArray<T>, f\", \"or \\nexample. As a reminder, ImmutableArray<T> is a very thin struct-based wrapper around a T[] that \", \"\\nhides the mutability of T[]; unless you\\u2019re using unsafe code, neither the length nor the shallow \\nc\", \"ontents of an ImmutableArray<T> will ever change (by shallow, I mean the data stored directly in \\nth\", \"at array can\\u2019t be mutated, but if there are mutable reference types stored in the array, those \\ninst\", \"ances themselves may still have their data mutated). As a result, ImmutableArray<T> also has an \\nass\", \"ociated \\u201cbuilder\\u201d type, which does support mutation: you create the builder, populate it, and then \\n\", \"transfer that contents to an ImmutableArray<T> which is frozen forevermore. In \\ndotnet/runtime#70850\", \" from [@grbell-ms](https://github.com/grbell-ms), the builder\\u2019s Sort method is \\nchanged to use a spa\", \"n, which in turn avoids an IComparer<T> allocation and a Comparison<T> \\n \\n151 \\nCHAPTER 12 | Collecti\", \"ons \\n \\nallocation, while also speeding up the sort itself by removing several layers of indirection \", \"from every \\ncomparison. \\nprivate ImmutableArray<int>.Builder _builder = ImmutableArray.CreateBuilder\", \"<int>(); \\n \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    _builder.AddRange(Enumerable.Range(0, 1_000))\", \"; \\n} \\n \\n[Benchmark] \\npublic void Sort() \\n{ \\n    _builder.Sort((left, right) => right.CompareTo(left)\", \"); \\n    _builder.Sort((left, right) => left.CompareTo(right)); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nSor\", \"t \\n.NET 6.0 \\n86.28 us \\n1.00 \\nSort \\n.NET 7.0 \\n67.17 us \\n0.78 \\ndotnet/runtime#61196 from [@lateapexear\", \"lyspeed](https://github.com/lateapexearlyspeed) brings \\nImmutableArray<T> into the span-based era, a\", \"dding around 10 new methods to ImmutableArray<T> \\nthat interoperate with Span<T> and ReadOnlySpan<T>\", \". These are valuable from a performance \\nperspective because it means if you have your data in a spa\", \"n, you can get it into an \\nImmutableArray<T> without incurring additional allocations beyond the one\", \" the ImmutableArray<T> \\nitself will create. dotnet/runtime#66550 from [@RaymondHuy](https://github.c\", \"om/RaymondHuy) also \\nadds a bunch of new methods to the immutable collection builders, which provide\", \" efficient \\nimplementations for operations like replacing elements and adding, inserting, and removi\", \"ng ranges. \\nSortedSet<T> also saw some improvements in .NET 7. For example, SortedSet<T> internally \", \"uses a \\nred/black tree as its internal data structure, and it uses a Log2 operation to determine the\", \" maximum \\ndepth the tree could be for a given node count. Previously, that operation was implemented\", \" as a loop. \\nBut thanks to dotnet/runtime#58793 from [@teo-tsirpanis](https://github.com/teo-tsirpan\", \"is) that \\nimplementation is now simply a call to BitOperations.Log2, which is in turn implemented tr\", \"ivially in \\nterms of one of multiple hardware intrinsics if they\\u2019re supported (e.g. Lzcnt.LeadingZer\", \"oCount, \\nArmBase.LeadingZeroCount, X86Base.BitScanReverse). And dotnet/runtime#56561 from \\n[@johnthc\", \"all](https://github.com/johnthcall) improves SortedSet<T> copy performance by \\nstreamlining how the \", \"iteration through the nodes in the tree is handled. \\n[Params(100)] \\npublic int Count { get; set; } \\n\", \" \\nprivate static SortedSet<string> _set; \\n \\n[GlobalSetup] \\npublic void GlobalSetup() \\n{ \\n    _set = \", \"new SortedSet<string>(StringComparer.OrdinalIgnoreCase); \\n    for (int i = 0; i < Count; i++) \\n    {\", \" \\n        _set.Add(Guid.NewGuid().ToString()); \\n \\n152 \\nCHAPTER 12 | Collections \\n \\n    } \\n} \\n \\n[Benc\", \"hmark] \\npublic SortedSet<string> SortedSetCopy() \\n{ \\n    return new SortedSet<string>(_set, StringCo\", \"mparer.OrdinalIgnoreCase); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nSortedSetCopy \\n.NET 6.0 \\n2.397 us \\n1.00\", \" \\nSortedSetCopy \\n.NET 7.0 \\n2.090 us \\n0.87 \\nOne last PR to look at in collections: dotnet/runtime#679\", \"23. ConditionalWeakTable<TKey, TValue> \\nis a collection most developers haven\\u2019t used, but when you n\", \"eed it, you need it. It\\u2019s used primarily for \\ntwo purposes: to associate additional state with some \", \"object, and to maintain a weak collection of \\nobjects. Essentially, it\\u2019s a thread-safe dictionary th\", \"at doesn\\u2019t maintain strong references to anything it \\nstores but ensures that the value associated w\", \"ith a key will remain rooted as long as the associated \\nkey is rooted. It exposes many of the same A\", \"PIs as ConcurrentDictionary<,>, but for adding items \\nto the collection, it\\u2019s historically only had \", \"an Add method. That means if the design of the consuming \\ncode entailed trying to use the collection\", \" as a set, where duplicates were common, it would also be \\ncommon to experience exceptions when tryi\", \"ng to Add an item that already existed in the collection. \\nNow in .NET 7, it has a TryAdd method, wh\", \"ich enables such usage without potentially incurring the \\ncosts of such exceptions (and without need\", \"ing to add try/catch blocks to defend against them). \\n \\n153 \\nCHAPTER 13 | LINQ \\n \\nCHAPTER 13 \\nLINQ \\n\", \"Let\\u2019s move on to Language-Integrated Query (LINQ). LINQ is a productivity feature that practically \\n\", \"every .NET developer uses. It enables otherwise complicated operations to be trivially expressed, \\nw\", \"hether via language-integrated query comprehension syntax or via direct use of methods on \\nSystem.Li\", \"nq.Enumerable. That productivity and expressivity, however, comes at a bit of an overhead \\ncost. In \", \"the vast majority of situations, those costs (such as delegate and closure allocations, delegate \\nin\", \"vocations, use of interface methods on arbitrary enumerables vs direct access to indexers and \\nLengt\", \"h/Count properties, etc.) don\\u2019t have a significant impact, but for really hot paths, they can and \\nd\", \"o show up in a meaningful way. This leads some folks to declare LINQ as being broadly off-limits in \", \"\\ntheir codebases. From my perspective, that\\u2019s misguided; LINQ is extremely useful and has its place.\", \" In \\n.NET itself, we use LINQ, we\\u2019re just practical and thoughtful about where, avoiding it in code \", \"paths \\nwe\\u2019ve optimized to be lightweight and fast due to expectations that such code paths could mat\", \"ter to \\nconsumers. And as such, while LINQ itself may not perform as fast as a hand-rolled solution,\", \" we still \\ncare a lot about the performance of LINQ\\u2019s implementation, so that it can be used in more\", \" and more \\nplaces, and so that where it\\u2019s used there\\u2019s as little overhead as possible. There are als\", \"o differences \\nbetween operations in LINQ; with over 200 overloads providing various kinds of functi\", \"onality, some of \\nthese overloads benefit from more performance tuning than do others, based on thei\", \"r expected \\nusage. \\ndotnet/runtime#64470 is the result of analyzing various real-world code bases fo\", \"r use of \\nEnumerable.Min and Enumerable.Max, and seeing that it\\u2019s very common to use these with arra\", \"ys, \\noften ones that are quite large. This PR updates the Min<T>(IEnumerable<T>) and \\nMax<T>(IEnumer\", \"able<T>) overloads when the input is an int[] or long[] to vectorize the \\nprocessing, using Vector<T\", \">. The net effect of this is significantly faster execution time for larger \\narrays, but still impro\", \"ved performance even for short arrays (because the implementation is now able \\nto access the array d\", \"irectly rather than going through the enumerable, leading to less allocation and \\ninterface dispatch\", \" and more applicable optimizations like inlining). \\n[Params(4, 1024)] \\npublic int Length { get; set;\", \" } \\n \\nprivate IEnumerable<int> _source; \\n \\n[GlobalSetup] \\npublic void Setup() => _source = Enumerabl\", \"e.Range(1, Length).ToArray(); \\n \\n[Benchmark] \\npublic int Min() => _source.Min(); \\n \\n[Benchmark] \\npub\", \"lic int Max() => _source.Max(); \\n \\n154 \\nCHAPTER 13 | LINQ \\n \\nMethod \\nRuntime \\nLength \\nMean \\nRatio Al\", \"located \\nAlloc Ratio \\nMin \\n.NET 6.0 \\n4 \\n26.167 ns \\n1.00 \\n32 B \\n1.00 \\nMin \\n.NET 7.0 \\n4 \\n4.788 ns \\n0.1\", \"8 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\n \\nMax \\n.NET 6.0 \\n4 \\n25.236 ns \\n1.00 \\n32 B \\n1.00 \\nMax \\n.NET 7.0 \\n4 \\n4.234 ns \", \"\\n0.17 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\n \\nMin \\n.NET 6.0 \\n1024 \\n3,987.102 ns \\n1.00 \\n32 B \\n1.00 \\nMin \\n.NET 7.0 \\n10\", \"24 \\n101.830 ns \\n0.03 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\n \\nMax \\n.NET 6.0 \\n1024 \\n3,798.069 ns \\n1.00 \\n32 B \\n1.00 \\nMa\", \"x \\n.NET 7.0 \\n1024 \\n100.279 ns \\n0.03 \\n- \\n0.00 \\nOne of the more interesting aspects of the PR, however\", \", is one line that\\u2019s meant to help with the non-\\narray cases. In performance optimization, and in pa\", \"rticular when adding \\u201cfast paths\\u201d to better handle \\ncertain cases, there\\u2019s almost always a winner an\", \"d a loser: the winner is the case the optimization is \\nintended to help, and the loser is every othe\", \"r case that\\u2019s penalized by whatever checks are necessary \\nto determine whether to take the improved \", \"path. An optimization that special-cases arrays might \\nnormally look like: \\nif (source is int[] arra\", \"y) \\n{ \\n    ProcessArray(array); \\n} \\nelse \\n{ \\n    ProcessEnumerable(source); \\n} \\nHowever, if you look\", \" at the PR, you\\u2019ll see the if condition is actually: \\nif (source.GetType() == typeof(int[])) \\nHow co\", \"me? Well at this point in the code flow, we know that source isn\\u2019t null, so we don\\u2019t need the \\nextra\", \" null check that is will bring. However, that\\u2019s minor compared to the real impact here, that of \\nsup\", \"port for array covariance. It might surprise you to learn that there are types beyond int[] that wil\", \"l \\nsatisfy a source is int check\\u2026 try running Console.WriteLine((object)new uint[42] is \\nint[]);, an\", \"d you\\u2019ll find it prints out True. (This is also a rare case where the .NET runtime and C# the \\nlangu\", \"age disagree on aspects of the type system. If you change that \\nConsole.WriteLine((object)new uint[4\", \"2] is int[]); to instead be Console.WriteLine(new \\nuint[42] is int[]);, i.e. remove the (object) cas\", \"t, you\\u2019ll find it starts printing out False instead of \\nTrue. That\\u2019s because the C# compiler believe\", \"s it\\u2019s impossible for a uint[] to ever be an int[], and \\nthus optimizes the check away entirely to b\", \"e a constant false.) Thus the runtime is having to do more \\nwork as part of the type check than just\", \" a simple comparison against the known type identity of \\n \\n155 \\nCHAPTER 13 | LINQ \\n \\nint[]. We can s\", \"ee this by looking at the assembly generated for these two methods (the latter \\nassumes we\\u2019ve alread\", \"y null-checked the input, which is the case in these LINQ methods): \\npublic IEnumerable<object> Inpu\", \"ts { get; } = new[] { new object() }; \\n \\n[Benchmark] \\n[ArgumentsSource(nameof(Inputs))] \\npublic bool\", \" M1(object o) => o is int[]; \\n \\n[Benchmark] \\n[ArgumentsSource(nameof(Inputs))] \\npublic bool M2(objec\", \"t o) => o.GetType() == typeof(int[]); \\nThis results in: \\n; Program.M1(System.Object) \\n       sub    \", \"   rsp,28 \\n       mov       rcx,offset MT_System.Int32[] \\n       call      qword ptr \\n[System.Runtim\", \"e.CompilerServices.CastHelpers.IsInstanceOfAny(Void*, System.Object)] \\n       test      rax,rax \\n   \", \"    setne     al \\n       movzx     eax,al \\n       add       rsp,28 \\n       ret \\n; Total bytes of cod\", \"e 34 \\n \\n \\n; Program.M2(System.Object) \\n       mov       rax,offset MT_System.Int32[] \\n       cmp    \", \"   [rdx],rax \\n       sete      al \\n       movzx     eax,al \\n       ret \\n; Total bytes of code 20 \\nNo\", \"te the former involves a method call to the JIT\\u2019s CastHelpers.IsInstanceOfAny helper method, \\nand th\", \"at it\\u2019s not inlined. That in turn impacts performance: \\nprivate IEnumerable<int> _source = (int[])(o\", \"bject)new uint[42]; \\n \\n[Benchmark(Baseline = true)] \\npublic bool WithIs() => _source is int[]; \\n \\n[B\", \"enchmark] \\npublic bool WithTypeCheck() => _source.GetType() == typeof(int[]); \\nMethod \\nMean \\nRatio \\n\", \"Code Size \\nWithIs \\n1.9246 ns \\n1.000 \\n215 B \\nWithTypeCheck \\n0.0013 ns \\n0.001 \\n24 B \\nOf course, these \", \"two operations aren\\u2019t semantically equivalent, so if this was for something that \\nrequired the seman\", \"tics of the former, we couldn\\u2019t use the latter. But in the case of this LINQ \\nperformance optimizati\", \"on, we can choose to only optimize the int[] case, forego the super rare case \\n \\n156 \\nCHAPTER 13 | L\", \"INQ \\n \\nof the int[] actually being a uint[] (or e.g. DayOfWeek[]), and minimize the performance pena\", \"lty of \\nthe optimization for IEnumerable<int> inputs other than int[] to just a few quick instructio\", \"ns. \\nThis improvement was built upon further in dotnet/runtime#64624, which expands the input types \", \"\\nsupported and the operations that take advantage. First, it introduced a private helper for extract\", \"ing a \\nReadOnlySpan<T> from certain types of IEnumerable<T> inputs, namely today those inputs that a\", \"re \\nactually either a T[] or a List<T>; as with the previous PR, it uses the GetType() == typeof(T[]\", \") \\nform to avoid significantly penalizing other inputs. Both of these types enable extracting a \\nRea\", \"dOnlySpan<T> for the actual storage, in the case of T[] via a cast and in the case of List<T> via \\nt\", \"he CollectionsMarshal.AsSpan method that was introduced in .NET 5. Once we have that span, we \\ncan d\", \"o a few interesting things. This PR: \\n\\u2022 \\nExpands the previous Min<T>(IEnumerable<T>) and Max<T>(IEnu\", \"merable<T>) optimizations to \\nnot only apply to int[] and long[] but also to List<int> and List<long\", \">. \\n\\u2022 \\nUses direct span access for Average<T>(IEnumerable<T>) and Sum<T>(IEnumerable<T>) for T \\nbein\", \"g int, long, float, double, or decimal, all for arrays and lists. \\n\\u2022 \\nSimilarly uses direct span acc\", \"ess for Min<T>(IEnumerable<T>) and Max<T>(IEnumerable<T>) for \\nT being float, double, and decimal. \\n\", \"\\u2022 \\nVectorizes Average<int>(IEnumerable<int>) for arrays and lists \\nThe effect of that is evident in \", \"microbenchmarks, e.g. \\nprivate static float[] CreateRandom() \\n{ \\n    var r = new Random(42); \\n    va\", \"r results = new float[10_000]; \\n    for (int i = 0; i < results.Length; i++) \\n    { \\n        results\", \"[i] = (float)r.NextDouble(); \\n    } \\n    return results; \\n} \\n \\nprivate IEnumerable<float> _floats = \", \"CreateRandom(); \\n \\n[Benchmark] \\npublic float Sum() => _floats.Sum(); \\n \\n[Benchmark] \\npublic float Av\", \"erage() => _floats.Average(); \\n \\n[Benchmark] \\npublic float Min() => _floats.Min(); \\n \\n[Benchmark] \\np\", \"ublic float Max() => _floats.Max(); \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nSum \\n.NET\", \" 6.0 \\n39.067 us \\n1.00 \\n32 B \\n1.00 \\nSum \\n.NET 7.0 \\n14.349 us \\n0.37 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\nAverage \\n.NE\", \"T 6.0 \\n41.232 us \\n1.00 \\n32 B \\n1.00 \\n \\n157 \\nCHAPTER 13 | LINQ \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nAlloca\", \"ted \\nAlloc Ratio \\nAverage \\n.NET 7.0 \\n14.378 us \\n0.35 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\nMin \\n.NET 6.0 \\n45.522 us \", \"\\n1.00 \\n32 B \\n1.00 \\nMin \\n.NET 7.0 \\n9.668 us \\n0.21 \\n- \\n0.00 \\n \\n \\n \\n \\n \\n \\nMax \\n.NET 6.0 \\n41.178 us \\n1.0\", \"0 \\n32 B \\n1.00 \\nMax \\n.NET 7.0 \\n9.210 us \\n0.22 \\n- \\n0.00 \\nThe previous LINQ PRs were examples from maki\", \"ng existing operations faster. But sometimes \\nperformance improvements come about from new APIs that\", \" can be used in place of previous ones in \\ncertain situations to further improve performance. One su\", \"ch example of that comes from new APIs \\nintroduced in dotnet/runtime#70525 from [@deeprobin](https:/\", \"/github.com/deeprobin) which were \\nthen improved in dotnet/runtime#71564. One of the most popular me\", \"thods in LINQ is \\nEnumerable.OrderBy (and its inverse OrderByDescending), which enables creating a s\", \"orted copy of \\nthe input enumerable. To do so, the caller passes a Func<TSource,TKey> predicate to O\", \"rderBy which \\nOrderBy uses to extract the comparison key for each item. However, it\\u2019s relatively com\", \"mon to want to \\nsort items with themselves as the keys; this is, after all, the default for methods \", \"like Array.Sort, and in \\nsuch cases callers of OrderBy end up passing in an identity function, e.g. \", \"OrderBy(x => x). To \\neliminate that cruft, .NET 7 introduces the new Order and OrderDescending metho\", \"ds, which, in the \\nspirit of pairs like Distinct and DistinctBy, perform that same sorting operation\", \", just with an implicit \\nx => x done on behalf of the caller. But beyond performance, a nice benefit\", \" of this is the \\nimplementation then knows that the keys will all be the same as the inputs, and it \", \"no longer needs to \\ninvoke the callback for each item to retrieve its key nor allocate a new array t\", \"o store those keys. Thus \\nif you find yourself using LINQ and reaching for OrderBy(x => x), consider\", \" instead using Order() \\nand reaping the (primarily allocation) benefits: \\n[Params(1024)] \\npublic int\", \" Length { get; set; } \\n \\nprivate int[] _arr; \\n \\n[GlobalSetup] \\npublic void Setup() => _arr = Enumera\", \"ble.Range(1, Length).Reverse().ToArray(); \\n \\n[Benchmark(Baseline = true)] \\npublic void OrderBy() \\n{ \", \"\\n    foreach (int _ in _arr.OrderBy(x => x)) { } \\n} \\n \\n[Benchmark] \\npublic void Order() \\n{ \\n    fore\", \"ach (int _ in _arr.Order()) { } \\n} \\n \\n \\n \\n158 \\nCHAPTER 13 | LINQ \\n \\nMethod \\nLength \\nMean \\nRatio \\nAll\", \"ocated \\nAlloc Ratio \\nOrderBy \\n1024 \\n68.74 us \\n1.00 \\n12.3 KB \\n1.00 \\nOrder \\n1024 \\n66.24 us \\n0.96 \\n8.28\", \" KB \\n0.67 \\n \\n159 \\nCHAPTER 14 | File I/O \\n \\nCHAPTER 14 \\nFile I/O \\n.NET 6 saw some huge file I/O impro\", \"vements, in particular a complete rewrite of FileStream. While \\n.NET 7 doesn\\u2019t have any single chang\", \"es on that scale, it does have a significant number of \\nimprovements that measurably \\u201cmove the needl\", \"e,\\u201d and in variety of ways. \\nOne form of performance improvement that also masquerades as a reliabil\", \"ity improvement is \\nincreasing responsiveness to cancellation requests. The faster something can be \", \"canceled, the sooner \\nthe system is able to give back valuable resources in use, and the sooner thin\", \"gs waiting for that \\noperation to complete are able to be unblocked. There have been several improve\", \"ments of this ilk in \\n.NET 7. \\nIn some cases, it comes from adding cancelable overloads where things\", \" weren\\u2019t previously cancelable \\nat all. That\\u2019s the case for dotnet/runtime#61898 from [@bgrainger](h\", \"ttps://github.com/bgrainger), \\nwhich added new cancelable overloads of TextReader.ReadLineAsync and \", \"\\nTextReader.ReadToEndAsync, and that includes overrides of these methods on StreamReader and \\nString\", \"Reader; dotnet/runtime#64301 from [@bgrainger](https://github.com/bgrainger) then \\noverrode these me\", \"thods (and others missing overrides) on the NullStreamReader type returned from \\nTextReader.Null and\", \" StreamReader.Null (interestingly, these were defined as two different types, \\nunnecessarily, and so\", \" this PR also unified on just having both use the StreamReader variant, as it \\nsatisfies the require\", \"d types of both). You can see this put to good use in dotnet/runtime#66492 from \\n[@lateapexearlyspee\", \"d](https://github.com/lateapexearlyspeed), which adds a new \\nFile.ReadLinesAsync method. This produc\", \"es an IAsyncEnumerable<string> of the lines in the file, \\nis based on a simple loop around the new S\", \"treamReader.ReadLineAsync overload, and is thus itself \\nfully cancelable. \\nFrom my perspective, thou\", \"gh, a more interesting form of this is when an existing overload is \\npurportedly cancelable but isn\\u2019\", \"t actually. For example, the base Stream.ReadAsync method just wraps \\nthe Stream.BeginRead/EndRead m\", \"ethods, which aren\\u2019t cancelable, so if a Stream-derived type doesn\\u2019t \\noverride ReadAsync, attempts t\", \"o cancel a call to its ReadAsync will be minimally effective. It does an \\nup-front check for cancell\", \"ation, such that if cancellation was requested prior to the call being made, it \\nwill be immediately\", \" canceled, but after that check the supplied CancellationToken is effectively \\nignored. Over time we\", \"\\u2019ve tried to stamp out all remaining such cases, but a few stragglers have \\nremained. One pernicious\", \" case has been with pipes. For this discussion, there are two relevant kinds of \\npipes, anonymous an\", \"d named, which are represented in .NET as pairs of streams: \\nAnonymousPipeClientStream/AnonymousPipe\", \"ServerStream and \\nNamedPipeClientStream/NamedPipeServerStream. Also, on Windows, the OS makes a dist\", \"inction \\nbetween handles opened for synchronous I/O from handles opened for overlapped I/O (aka \\nasy\", \"nchronous I/O), and this is reflected in the .NET API: you can open a named pipe for synchronous \\nor\", \" overlapped I/O based on the PipeOptions.Asynchronous option specified at construction. And, on \\n \\n1\", \"60 \\nCHAPTER 14 | File I/O \\n \\nUnix, named pipes, contrary to their naming, are actually implemented o\", \"n top of Unix domain sockets. \\nNow some history: \\n\\u2022 \\n.NET Framework 4.8: No cancellation support. Th\", \"e pipe Stream-derived types didn\\u2019t even \\noverride ReadAsync or WriteAsync, so all they got was the d\", \"efault up-front check for \\ncancellation and then the token was ignored. \\n\\u2022 \\n.NET Core 1.0: On Window\", \"s, with a named pipe opened for asynchronous I/O, cancellation was \\nfully supported. The implementat\", \"ion would register with the CancellationToken, and upon a \\ncancellation request, would use CancelIoE\", \"x for the NativeOverlapped* associated with the \\nasynchronous operation. On Unix, with named pipes i\", \"mplemented in terms of sockets, if the pipe \\nwas opened with PipeOptions.Asynchronous, the implement\", \"ation would simulate cancellation \\nvia polling: rather than simply issuing the Socket.ReceiveAsync/S\", \"ocket.SendAsync (which \\nwasn\\u2019t cancelable at the time), it would queue a work item to the ThreadPool\", \", and that work \\nitem would run a polling loop, making Socket.Poll calls with a small timeout, check\", \"ing the \\ntoken, and then looping around to do it again until either the Poll indicated the operation\", \" \\nwould succeed or cancellation was requested. On both Windows and Unix, other than a named \\npipe op\", \"ened with Asynchronous, after the operation was initated, cancellation was a nop. \\n\\u2022 \\n.NET Core 2.1:\", \" On Unix, the implementation was improved to avoid the polling loop, but it still \\nlacked a truly ca\", \"ncelable Socket.ReceiveAsync/Socket.SendAsync. Instead, by this point \\nSocket.ReceiveAsync supported\", \" zero-byte reads, where a caller could pass a zero-length buffer \\nto ReceiveAsync and use that as no\", \"tification for data being available to consume without \\nactually consuming it. The Unix implementati\", \"on for asynchronous named pipe streams then \\nchanged to issue zero-byte reads, and would await a Tas\", \"k.WhenAny of both that operation\\u2019s \\ntask and a task that would be completed when cancellation was re\", \"quested. Better, but still far \\nfrom ideal. \\n\\u2022 \\n.NET Core 3.0: On Unix, Socket got truly cancelable \", \"ReceiveAsync and SendAsync methods, \\nwhich asynchronous named pipes were updated to utilize. At this\", \" point, the Windows and Unix \\nimplementations were effectively on par with regards to cancellation; \", \"both good for \\nasynchronous named pipes, and just posing for everything else. \\n\\u2022 \\n.NET 5: On Unix, S\", \"afeSocketHandle was exposed and it became possible to create a Socket for \\nan arbitrary supplied Saf\", \"eSocketHandle, which enabled creating a Socket that actually referred \\nto an anonymous pipe. This in\", \" tern enabled every PipeStream on Unix to be implemented in \\nterms of Socket, which enabled ReceiveA\", \"sync/SendAsync to be fully cancelable for both \\nanonymous and named pipes, regardless of how they we\", \"re opened. \\nSo by .NET 5, the problem was addressed on Unix, but still an issue on Windows. Until no\", \"w. In .NET 7, \\nwe\\u2019ve made the rest of the operations fully cancelable on Windows as well, thanks to \", \"\\ndotnet/runtime#72503 (and a subsequent tweak in dotnet/runtime#72612). Windows doesn\\u2019t support \\nove\", \"rlapped I/O for anonymous pipes today, so for anonymous pipes and for named pipes opened for \\nsynchr\", \"onous I/O, the Windows implementation would just delegate to the base Stream \\nimplementation, which \", \"would queue a work item to the ThreadPool to invoke the synchronous \\ncounterpart, just on another th\", \"read. Instead, the implementations now queue that work item, but \\ninstead of just calling the synchr\", \"onous method, it does some pre- and post- work that registers for \\ncancellation, passing in the thre\", \"ad ID of the thread that\\u2019s about to perform the I/O. If cancellation is \\nrequested, the implementati\", \"on then uses CancelSynchronousIo to interrupt it. There\\u2019s a race \\ncondition here, in that the moment\", \" the thread registers for cancellation, cancellation could be \\nrequested, such that CancelSynchronou\", \"sIo could be called before the operation is actually initiated. \\n \\n161 \\nCHAPTER 14 | File I/O \\n \\nSo,\", \" there\\u2019s a small spin loop employed, where if cancellation is requested between the time \\nregistrati\", \"on occurs and the time the synchronous I/O is actually performed, the cancellation thread \\nwill spin\", \" until the I/O is initiated, but this condition is expected to be exceedingly rare. There\\u2019s also a \\n\", \"race condition on the other side, that of CancelSynchronousIo being requested after the I/O has \\nalr\", \"eady completed; to address that race, the implementation relies on the guarantees made by \\nCancellat\", \"ionTokenRegistration.Dispose, which promises that the associated callback will either \\nnever be invo\", \"ked or will already have fully completed executing by the time Dispose returns. Not only \\ndoes this \", \"implementation complete the puzzle such that all asynchronous read/write operations on \\nboth anonymo\", \"us and named pipes on both Windows and Unix are cancelable, it also actually \\nimproves normal throug\", \"hput. \\nprivate Stream _server; \\nprivate Stream _client; \\nprivate byte[] _buffer = new byte[1]; \\npriv\", \"ate CancellationTokenSource _cts = new CancellationTokenSource(); \\n \\n[Params(false, true)] \\npublic b\", \"ool Cancelable { get; set; } \\n \\n[Params(false, true)] \\npublic bool Named { get; set; } \\n \\n[GlobalSet\", \"up] \\npublic void Setup() \\n{ \\n    if (Named) \\n    { \\n        string name = Guid.NewGuid().ToString(\\\"N\", \"\\\"); \\n        var server = new NamedPipeServerStream(name, PipeDirection.Out); \\n        var client = \", \"new NamedPipeClientStream(\\\".\\\", name, PipeDirection.In); \\n        Task.WaitAll(server.WaitForConnecti\", \"onAsync(), client.ConnectAsync()); \\n        _server = server; \\n        _client = client; \\n    } \\n   \", \" else \\n    { \\n        var server = new AnonymousPipeServerStream(PipeDirection.Out); \\n        var cl\", \"ient = new AnonymousPipeClientStream(PipeDirection.In, \\nserver.ClientSafePipeHandle); \\n        _serv\", \"er = server; \\n        _client = client; \\n    } \\n} \\n \\n[GlobalCleanup] \\npublic void Cleanup() \\n{ \\n    \", \"_server.Dispose(); \\n    _client.Dispose(); \\n} \\n \\n[Benchmark(OperationsPerInvoke = 1000)] \\npublic asy\", \"nc Task ReadWriteAsync() \\n{ \\n    CancellationToken ct = Cancelable ? _cts.Token : default; \\n    for \", \"(int i = 0; i < 1000; i++) \\n    { \\n \\n162 \\nCHAPTER 14 | File I/O \\n \\n        ValueTask<int> read = _cl\", \"ient.ReadAsync(_buffer, ct); \\n        await _server.WriteAsync(_buffer, ct); \\n        await read; \\n \", \"   } \\n} \\nMethod \\nRuntime \\nCancelable \\nNamed \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nReadWriteAsync \\n.N\", \"ET 6.0 \\nFalse \\nFalse \\n22.08 us \\n1.00 \\n400 B \\n1.00 \\nReadWriteAsync \\n.NET 7.0 \\nFalse \\nFalse \\n12.61 us \", \"\\n0.76 \\n192 B \\n0.48 \\n \\n \\n \\n \\n \\n \\n \\n \\nReadWriteAsync \\n.NET 6.0 \\nFalse \\nTrue \\n38.45 us \\n1.00 \\n400 B \\n1.\", \"00 \\nReadWriteAsync \\n.NET 7.0 \\nFalse \\nTrue \\n32.16 us \\n0.84 \\n220 B \\n0.55 \\n \\n \\n \\n \\n \\n \\n \\n \\nReadWriteAsy\", \"nc \\n.NET 6.0 \\nTrue \\nFalse \\n27.11 us \\n1.00 \\n400 B \\n1.00 \\nReadWriteAsync \\n.NET 7.0 \\nTrue \\nFalse \\n13.29\", \" us \\n0.52 \\n193 B \\n0.48 \\n \\n \\n \\n \\n \\n \\n \\n \\nReadWriteAsync \\n.NET 6.0 \\nTrue \\nTrue \\n38.57 us \\n1.00 \\n400 B \", \"\\n1.00 \\nReadWriteAsync \\n.NET 7.0 \\nTrue \\nTrue \\n33.07 us \\n0.86 \\n214 B \\n0.54 \\nThe rest of the performanc\", \"e-focused changes around I/O in .NET 7 were primarily focused on one of \\ntwo things: reducing syscal\", \"ls, and reducing allocation. \\nSeveral PRs went into reducing syscalls on Unix as part of copying fil\", \"es, e.g. File.Copy and \\nFileInfo.CopyTo. dotnet/runtime#59695 from [@tmds](https://github.com/tmds) \", \"reduced overheads \\nin several ways. The code had been performing a stat call in order to determine u\", \"p front whether the \\nsource was actually a directory, in which case the operation would error out. I\", \"nstead, the PR simply \\ntries to open the source file, which it would need to do anyway for the copy \", \"operation, and then it \\nonly performs that stat if opening the file fails. If opening the file succe\", \"eds, the code was already \\nperforming an fstat to gather data on the file, such as whether it was se\", \"ekable; with this change, it \\nnow also extracts from the results of that single fstat the source fil\", \"e size, which it then threads \\nthrough to the core copy routine, which itself is then able to avoid \", \"an fstat syscall it had been \\nperforming in order to get the size. Saving those syscalls is great, i\", \"n particular for very small files \\nwhere the overhead of setting up the copy can actually be more ex\", \"pensive than the actual copy of the \\nbytes. But the biggest benefit of this PR is that it takes adva\", \"ntage of IOCTL-FICLONERANGE on Linux. \\nSome Linux file systems, like XFS and Btrfs, support \\u201ccopy-on\", \"-write,\\u201d which means that rather than \\ncopying all of the data to a new file, the file system simply\", \" notes that there are two different files \\npointing to the same data, sharing the underlying storage\", \". This makes the \\u201ccopy\\u201d super fast, since \\nnothing actually needs to be copied and instead the file \", \"system just needs to update some \\nbookkeeping; plus, less space is consumed on disk, since there\\u2019s j\", \"ust a single store of the data. The file \\nsystem then only needs to actually copy data that\\u2019s overwr\", \"itten in one of the files. This PR uses ioctl \\nand FICLONE to perform the copy as copy-on-write if t\", \"he source and destination file system are the \\nsame and the file system supports the operation. In a\", \" similar vein, dotnet/runtime#64264 from \\n[@tmds](https://github.com/tmds) further improves File.Cop\", \"y/FileInfo.CopyTo by utilizing \\ncopy_file_range on Linux if it\\u2019s supported (and only if it\\u2019s a new e\", \"nough kernel that it addresses \\n \\n163 \\nCHAPTER 14 | File I/O \\n \\nsome issues the function had in prev\", \"ious releases). Unlike a typical read/write loop that reads the data \\nfrom the source and then write\", \"s it to the destination, copy_file_range is implemented to stay \\nentirely in kernel mode, without ha\", \"ving to transition to user space for each read and write. \\nAnother example of avoiding syscalls come\", \"s for the File.WriteXx and File.AppendXx methods when \\non Unix. The implementation of these methods \", \"opens a FileStream or a SafeFileHandle directly, \\nand it was specifying FileOptions.SequentialScan. \", \"SequentialScan is primarily relevant for reading \\ndata from a file, and hints to OS caching to expec\", \"t data to be read from the file sequentially rather \\nthan randomly. However, these write/append meth\", \"ods don\\u2019t read, they only write, and the \\nimplementation of FileOptions.SequentialScan on Unix requi\", \"res an additional syscall via \\nposix_fadvise (passing in POSIX_FADV_SEQUENTIAL); thus, we\\u2019re paying \", \"for a syscall and not \\nbenefiting from it. This situation is akin to the famous Henny Youngman joke:\", \" \\u201cThe patient says, \\n\\u2018Doctor, it hurts when I do this\\u2019; the doctor says, \\u2018Then don\\u2019t do that!\\u2019.\\u201d Her\", \"e, too, the answer is \\u201cdon\\u2019t \\ndo that,\\u201d and so dotnet/runtime#59247 from [@tmds](https://github.com/\", \"tmds) simply stops passing \\nSequentialScan in places where it won\\u2019t help but may hurt. \\nDirectory ha\", \"ndling has seen reduced syscalls across the directory lifecycle, especially on Unix. \\ndotnet/runtime\", \"#58799 from [@tmds](https://github.com/tmds) speeds up directory creation on Unix. \\nPreviously, the \", \"implementation of directory creation would first check to see if the directory already \\nexisted, whi\", \"ch involves a syscall. In the expected minority case where it already existed the code could \\nearly \", \"exit out. But in the expected more common case where the directory didn\\u2019t exist, it would then \\npars\", \"e the file path to find all of the directories in it, walk up the directory list until it found one \", \"that \\ndid exist, and then try to create all of the subdirectories back down through the target one. \", \"However, \\nthe expected most common case is the parent directories already exist and the child direct\", \"ory doesn\\u2019t, \\nin which case we\\u2019re still paying for all that parsing when we could have just created \", \"the target \\ndirectory. This PR addresses that by changing the up-front existence check to instead si\", \"mply try to \\nmkdir the target directory; if it succeeds, great, we\\u2019re done, and if it fails, the err\", \"or code from the \\nfailure can be used instead of the existence check to know whether mkdir failed be\", \"cause it had no \\nwork to do. dotnet/runtime#61777 then takes this a step further and avoids string a\", \"llocations while \\ncreating directories by using stack memory for the paths temporarily needed to pas\", \"s to mkdir. \\ndotnet/runtime#63675 then improves the performance of moving directories, on both Unix \", \"and \\nWindows, removing several syscalls. The shared code for Directory.Move and DirectorInfo.MoveTo \", \"\\nwas doing explicit directory existence checks for the source and destination locations, but on \\nWin\", \"dows the Win32 API called to perform the move does such checks itself, so they\\u2019re not needed \\npreemp\", \"tively. On Unix, we can similarly avoid the existence check for the source directory, as the \\nrename\", \" function called will similarly simply fail if the source doesn\\u2019t exist (with an appropriate error \\n\", \"that let\\u2019s us deduce what went wrong so the right exception can be thrown), and for the destination,\", \" \\nthe code had been issuing separate existence checks for whether the destination existed as a direc\", \"tory \\nor as a file, but a single stat call suffices for both. \\nprivate string _path1; \\nprivate strin\", \"g _path2; \\n \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    _path1 = Path.GetTempFileName(); \\n    _path2\", \" = Path.GetTempFileName(); \\n \\n164 \\nCHAPTER 14 | File I/O \\n \\n    File.Delete(_path1); \\n    File.Delet\", \"e(_path2); \\n    Directory.CreateDirectory(_path1); \\n} \\n \\n[Benchmark] \\npublic void Move() \\n{ \\n    Dir\", \"ectory.Move(_path1, _path2); \\n    Directory.Move(_path2, _path1); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\n\", \"Allocated \\nAlloc Ratio \\nMove \\n.NET 6.0 \\n31.70 us \\n1.00 \\n256 B \\n1.00 \\nMove \\n.NET 7.0 \\n26.31 us \\n0.83 \", \"\\n- \\n0.00 \\nAnd then also on Unix, dotnet/runtime#59520 from [@tmds](https://github.com/tmds) improves\", \" \\ndirectory deletion, and in particular recursive deletion (deleting a directory and everything it c\", \"ontains \\nand everything they contain and so on), by utilizing the information already provided by th\", \"e file \\nsystem enumeration to avoid a secondary existence check. \\nSyscalls were also reduced as part\", \" of support for memory-mapped files. dotnet/runtime#63754 takes \\nadvantage of special-casing to do s\", \"o while opening a MemoryMappedFile. When \\nMemoryMappedFile.CreateFromFile was called, one of the fir\", \"st things it would do is call File.Exists \\nto determine whether the specified file already exists; t\", \"hat\\u2019s because later in the method as part of \\ndealing with errors and exceptions, the implementation\", \" needs to know whether to delete the file that \\nmight then exist; the implementation constructs a Fi\", \"leStream, and doing might will the specified file \\ninto existence. However, that only happens for so\", \"me FileMode values, which is configurable via an \\nargument passed by callers of CreateFromFile. The \", \"common and default value of FileMode is \\nFileMode.Open, which requires that the file exist such that\", \" constructing the FileStream will throw if it \\ndoesn\\u2019t. That means we only actually need to call Fil\", \"e.Exists if the FileMode is something other \\nthan Open or CreateNew, which means we can trivially av\", \"oid the extra system call in the majority case. \\ndotnet/runtime#63790 also helps here, in two ways. \", \"First, throughout the CreateFromFile operation, \\nthe implementation might access the FileStream\\u2019s Le\", \"ngth multiple times, but each call results in a \\nsyscall to read the underlying length of the file. \", \"We can instead read it once and use that one value for \\nall of the various checks performed. Second,\", \" .NET 6 introduced the File.OpenHandle method which \\nenables opening a file handle / file descriptor\", \" directly into a SafeFileHandle, rather than having to go \\nthrough FileStream to do so. The use of t\", \"he FileStream in MemoryMappedFile is actually quite \\nminimal, and so it makes sense to just use the \", \"SafeFileHandle directly rather than also constructing \\nthe superfluous FileStream and its supporting\", \" state. This helps to reduce allocations. \\nFinally, there\\u2019s dotnet/runtime#63794, which recognizes t\", \"hat a MemoryMappedViewAccessor or \\nMemoryMappedViewStream opened for read-only access can\\u2019t have bee\", \"n written to. Sounds obvious, \\nbut the practical implication of this is that closing either needn\\u2019t \", \"bother flushing, since that view \\ncouldn\\u2019t have changed any data in the implementation, and flushing\", \" a view can be relatively \\nexpensive, especially for larger views. Thus, a simple change to avoid fl\", \"ushing if the view isn\\u2019t writable \\ncan yield a measurable improvement to MemoryMappedViewAccessor/Me\", \"moryMappedviewStream\\u2019s \\nDispose. \\n \\n165 \\nCHAPTER 14 | File I/O \\n \\nprivate string _path; \\n \\n[GlobalSe\", \"tup] \\npublic void Setup() \\n{ \\n    _path = Path.GetTempFileName(); \\n    File.WriteAllBytes(_path, Enu\", \"merable.Range(0, 10_000_000).Select(i => \\n(byte)i).ToArray()); \\n} \\n \\n[GlobalCleanup] \\npublic void Cl\", \"eanup() \\n{ \\n    File.Delete(_path); \\n} \\n \\n[Benchmark] \\npublic void MMF() \\n{ \\n    using var mmf = Mem\", \"oryMappedFile.CreateFromFile(_path, FileMode.Open, null); \\n    using var s = mmf.CreateViewStream(0,\", \" 10_000_000, MemoryMappedFileAccess.Read); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \", \"\\nMMF \\n.NET 6.0 \\n315.7 us \\n1.00 \\n488 B \\n1.00 \\nMMF \\n.NET 7.0 \\n227.1 us \\n0.68 \\n336 B \\n0.69 \\nBeyond syst\", \"em calls, there have also been a plethora of improvements around reducing allocation. \\nOne such chan\", \"ge is dotnet/runtime#58167, which improved the performance of the commonly-used \\nFile.WriteAllText{A\", \"sync} and File.AppendAllText{Async} methods. The PR recognizes two \\nthings: one, that these operatio\", \"ns are common enough that it\\u2019s worth avoiding the small-but-\\nmeasurable overhead of going through a \", \"FileStream and instead just going directly to the \\nunderlying SafeFileHandle, and, two, that since t\", \"he methods are passed the entirety of the payload \\nto output, the implementation can use that knowle\", \"dge (in particular for length) to do better than the \\nStreamWriter that was previously employed. In \", \"doing so, the implementation avoids the overheads \\n(primarily in allocation) of the streams and writ\", \"ers and temporary buffers. \\nprivate string _path; \\n \\n[GlobalSetup] \\npublic void Setup() => _path = P\", \"ath.GetRandomFileName(); \\n \\n[GlobalCleanup] \\npublic void Cleanup() => File.Delete(_path); \\n \\n[Benchm\", \"ark] \\npublic void WriteAllText() => File.WriteAllText(_path, Sonnet); \\nMethod \\nRuntime \\nMean \\nRatio \", \"\\nAllocated \\nAlloc Ratio \\nWriteAllText \\n.NET 6.0 \\n488.5 us \\n1.00 \\n9944 B \\n1.00 \\nWriteAllText \\n.NET 7.\", \"0 \\n482.9 us \\n0.99 \\n392 B \\n0.04 \\n \\n166 \\nCHAPTER 14 | File I/O \\n \\ndotnet/runtime#61519 similarly updat\", \"es File.ReadAllBytes{Async} to use SafeFileHandle (and \\nRandomAccess) directly rather than going thr\", \"ough FileStream, shaving off some allocation from each \\nuse. It also makes the same SequentialScan c\", \"hange as mentioned earlier. While this case is about \\nreading (whereas the previous change saw Seque\", \"ntialScan being complete overhead with no \\nbenefit), ReadAllBytes{Async} is very frequently used to \", \"read smaller files where the overhead of the \\nadditional syscall can measure up to 10% of the total \", \"cost (and for larger files, modern kernels are \\npretty good about caching even without a sequentiali\", \"ty hint, so there\\u2019s little downside measured \\nthere). \\nAnother such change is dotnet/runtime#68662, \", \"which improved Path.Join\\u2019s handling of null or \\nempty path segments. Path.Join has overloads that ac\", \"cept strings and overloads that accept \\nReadOnlySpan<char>s, but all of the overloads produce string\", \"s. The string-based overloads just \\nwrapped each string in a span and delegated to the span-based ov\", \"erloads. However, in the event that \\nthe join operation is a nop (e.g. there are two path segments a\", \"nd the second is empty so the join \\nshould just return the first), the span-based implementation sti\", \"ll needs to create a new string (there\\u2019s \\nno way for the ReadOnlySpan<char>-based overloads to extra\", \"ct a string from the span). As such, the \\nstring-based overloads can do a little bit better in the c\", \"ase of one of them being null or empty; they \\ncan do the same thing the Path.Combine overloads do, w\", \"hich is to have the M argument overload \\ndelegate to the M-1 argument overload, filtering out a null\", \" or empty, and in the base case of the \\noverload with two arguments, if a segment is null or empty, \", \"the other (or empty) can just be returned \\ndirectly. \\nBeyond that, there are a multitude of allocati\", \"on-focused PRs, such as dotnet/runtime#69335 from \\n[@pedrobsaila](https://github.com/pedrobsaila) wh\", \"ich adds a fast-path based on stack allocation to \\nthe internal ReadLink helper that\\u2019s used on Unix \", \"anywhere we need to follow symlinks, or \\ndotnet/runtime#68752 that updates NamedPipeClientStream.Con\", \"nectAsync to remove a delegate \\nallocation (by passing state into a Task.Factory.StartNew call expli\", \"citly), or dotnet/runtime#69412 \\nwhich adds an optimized Read(Span<byte>) override to the Stream ret\", \"urned from \\nAssembly.GetManifestResourceStream. \\nBut my personal favorite improvement in this area c\", \"ome from dotnet/runtime#69272, which adds a \\nfew new helpers to Stream: \\npublic void ReadExactly(byt\", \"e[] buffer, int offset, int count); \\npublic void ReadExactly(Span<byte> buffer); \\n \\npublic ValueTask\", \" ReadExactlyAsync(byte[] buffer, int offset, int count, CancellationToken \\ncancellationToken = defau\", \"lt); \\npublic ValueTask ReadExactlyAsync(Memory<byte> buffer, CancellationToken cancellationToken \\n= \", \"default); \\n \\npublic int ReadAtLeast(Span<byte> buffer, int minimumBytes, bool throwOnEndOfStream = \\n\", \"true); \\npublic ValueTask<int> ReadAtLeastAsync(Memory<byte> buffer, int minimumBytes, bool \\nthrowOnE\", \"ndOfStream = true, CancellationToken cancellationToken = default); \\nIn fairness, these are more abou\", \"t usability than they are about performance, but in this case there\\u2019s a \\ntight correlation between t\", \"he two. It\\u2019s very common to write these helpers one\\u2019s self (the \\naforementioned PR deleted many open\", \"-coded loops for this functionality from across the core \\nlibraries) as the functionality is greatly\", \" needed, and it\\u2019s unfortunately easy to get them wrong in ways \\n \\n167 \\nCHAPTER 14 | File I/O \\n \\nthat\", \" negatively impact performance, such as by using a Stream.ReadAsync overload that needs to \\nallocate\", \" a returned Task<int> or reading fewer bytes than is allowed as part of a read call. These \\nimplemen\", \"tations are correct and efficient. \\n \\n168 \\nCHAPTER 15 | Compression \\n \\nCHAPTER 15 \\nCompression \\n.NET\", \" Core 2.1 added support for the Brotli compression algorithm, surfacing it in two ways: \\nBrotliStrea\", \"m and the pair of BrotliEncoder/BrotliDecoder structs that BrotliStream is itself built \\non top of. \", \"For the most part, these types just provide wrappers around a native C implementation \\nfrom google/b\", \"rotli, and so while the .NET layer has the opportunity to improve how data is moved \\naround, managed\", \" allocation, and so on, the speed and quality of the compression itself are largely at \\nthe mercy of\", \" the C implementation and the intricacies of the Brotli algorithm. \\nAs with many compression algorit\", \"hms, Brotli provides a knob that allows for a quintessential tradeoff \\nto be made between compressio\", \"n speed (how fast data can be compressed) and compression \\nquality/ratio (how small can the compress\", \"ed output be made). The hand-wavy idea is the more time \\nthe algorithm spends looking for opportunit\", \"y, the more space can be saved. Many algorithms expose \\nthis as a numerical dial, in Brotli\\u2019s case g\", \"oing from 0 (fastest speed, least compression) to 11 (spend as \\nmuch time as is needed to minimize t\", \"he output size). But while BrotliEncoder surfaces that same \\nrange, BrotliStream\\u2019s surface area is s\", \"impler: most use just specifies that compression should be \\nperformed (e.g. new BrotliStream(destina\", \"tion, CompressionMode.Compress)) and the only knob \\navailable is via the CompressionLevel enum (e.g.\", \" new BrotliStream(destination, \\nCompressionLevel.Fastest)), which provides just a few options: Compr\", \"essionLevel.NoCompression, \\nCompressionLevel.Fastest, CompressionLevel.Optimal, and CompressionLevel\", \".SmallestSize. \\nThis means the BrotliStream implementation needs to select a default value when no \\n\", \"CompressionLevel is specified and needs to map CompressionLevel to an underlying numerical \\nvalue wh\", \"en one is. \\nFor better or worse (and I\\u2019m about to argue \\u201cmuch worse\\u201d), the native C implementation i\", \"tself defines \\nthe default to be 11 (google/brotli#encode.h), and so that\\u2019s what BrotliStream has en\", \"ded up using \\nwhen no CompressionLevel is explicitly specified. Further, the CompressionLevel.Optima\", \"l enum \\nvalue is poorly named. It\\u2019s intended to represent a good default that\\u2019s a balanced tradeoff \", \"between \\nspeed and quality; that\\u2019s exactly what it means for DeflateStream, GZipStream, and ZLibStre\", \"am. But \\nfor BrotliStream, as the default it similarly got translated to mean the underlying native \", \"library\\u2019s \\ndefault, which is 11. This means that when constructing a BrotliStream with either \\nCompr\", \"essionMode.Compress or CompressionLevel.Optimal, rather than getting a nice balanced \\ndefault, you\\u2019r\", \"e getting the dial turned all the way up to 11. \\nIs that so bad? Maybe compression quality is the mo\", \"st important thing? For example, reducing the \\nsize of data can make it faster to then transmit it o\", \"ver a wire, and with a slow connection, size then \\nmeaningfully translates into end-to-end throughpu\", \"t. \\nThe problem is just how much this extra effort costs. Compression speed and ratio are highly \\nde\", \"pendent on the data being compressed, so take this example with a small grain of salt as it\\u2019s not \\ne\", \"ntirely representative of all use, but it\\u2019s good enough for our purposes. Consider this code, which \", \"\\n \\n169 \\nCHAPTER 15 | Compression \\n \\nuses BrotliEncoder to compress the The Complete Works of William\", \" Shakespeare from Project \\nGutenberg at varying levels of compression: \\nusing System.Buffers; \\nusing\", \" System.Diagnostics; \\nusing System.IO.Compression; \\nusing System.Text; \\n \\nusing var hc = new HttpCli\", \"ent(); \\nbyte[] data = await hc.GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-8\\\"); \", \"\\nConsole.WriteLine(data.Length); \\n \\nvar compressed = new MemoryStream(); \\nvar sw = new Stopwatch(); \", \"\\n \\nfor (int level = 0; level <= 11; level++) \\n{ \\n    const int Trials = 10; \\n \\n    compressed.Positi\", \"on = 0; \\n    Compress(level, data, compressed); \\n \\n    sw.Restart(); \\n    for (int i = 0; i < Trials\", \"; i++) \\n    { \\n        compressed.Position = 0; \\n        Compress(level, data, compressed); \\n    } \\n\", \"    sw.Stop(); \\n \\n    Console.WriteLine($\\\"{level},{sw.Elapsed.TotalMilliseconds / \\nTrials},{compress\", \"ed.Position}\\\"); \\n \\n    static void Compress(int level, byte[] data, Stream destination) \\n    { \\n    \", \"    var encoder = new BrotliEncoder(quality: level, window: 22); \\n        Write(ref encoder, data, d\", \"estination, false); \\n        Write(ref encoder, Array.Empty<byte>(), destination, true); \\n        en\", \"coder.Dispose(); \\n \\n        static void Write(ref BrotliEncoder encoder, byte[] data, Stream destina\", \"tion, bool \\nisFinalBlock) \\n        { \\n            byte[] output = ArrayPool<byte>.Shared.Rent(4096);\", \" \\n \\n            OperationStatus lastResult = OperationStatus.DestinationTooSmall; \\n            ReadO\", \"nlySpan<byte> buffer = data; \\n            while (lastResult == OperationStatus.DestinationTooSmall) \", \"\\n            { \\n                lastResult = encoder.Compress(buffer, output, out int bytesConsumed,\", \" out \\nint bytesWritten, isFinalBlock); \\n                if (lastResult == OperationStatus.InvalidDat\", \"a) throw new \\nInvalidOperationException(); \\n                if (bytesWritten > 0) destination.Write(\", \"output.AsSpan(0, bytesWritten)); \\n                if (bytesConsumed > 0) buffer = buffer.Slice(bytes\", \"Consumed); \\n            } \\n \\n            ArrayPool<byte>.Shared.Return(output); \\n        } \\n \\n170 \\nC\", \"HAPTER 15 | Compression \\n \\n    } \\n} \\nThe code is measuring how long it takes to compress the input d\", \"ata at each of the levels (doing a \\nwarmup and then averaging several iterations), timing how long i\", \"t takes and capturing the resulting \\ncompressed data size. For the size, I get values like this: \\nLe\", \"vel \\nSize (bytes) \\n0 \\n2,512,855.00 \\n1 \\n2,315,466.00 \\n2 \\n2,224,638.00 \\n3 \\n2,218,328.00 \\n4 \\n2,027,153.\", \"00 \\n5 \\n1,964,810.00 \\n6 \\n1,923,456.00 \\n7 \\n1,889,927.00 \\n8 \\n1,863,988.00 \\n9 \\n1,846,685.00 \\n10 \\n1,741,5\", \"61.00 \\n11 \\n1,702,214.00 \\n \\nThat\\u2019s a fairly liner progression from least to most compression. That\\u2019s \", \"not the problem. This is the \\nproblem: \\n \\n \\n \\n171 \\nCHAPTER 15 | Compression \\n \\nLevel \\nTime \\n(ms) \\n0 \", \"\\n24.11 \\n1 \\n36.67 \\n2 \\n64.13 \\n3 \\n73.72 \\n4 \\n146.41 \\n5 \\n257.12 \\n6 \\n328.54 \\n7 \\n492.81 \\n8 \\n702.38 \\n9 \\n892.\", \"08 \\n10 \\n4,830.32 \\n11 \\n10,634.88 \\n \\nThis chart shows an almost exponential increase in processing tim\", \"e as we near the upper end of the \\ndial, with quality level 11 compressing ~33% better than quality \", \"level 0 but taking ~440x as long to \\nachieve that. If that\\u2019s what a developer wants, they can specif\", \"y CompressionLevel.SmallestSize, but \\nthat cost by default and for the balanced CompressionLevel.Opt\", \"imal is far out of whack. \\ndotnet/runtime#72266 fixes that. A very small change, it simply makes Com\", \"pressMode.Compress and \\nCompressionLevel.Optimal for Brotli map to quality level 4, which across man\", \"y kinds of inputs does \\nrepresent a fairly balanced trade-off between size and speed. \\n \\n172 \\nCHAPTE\", \"R 15 | Compression \\n \\nprivate byte[] _data = new \\nHttpClient().GetByteArrayAsync(\\\"https://www.gutenb\", \"erg.org/ebooks/100.txt.utf-8\\\").Result; \\nprivate Stream _output = new MemoryStream(); \\n \\n[Benchmark] \", \"\\npublic void Compress() \\n{ \\n    _output.Position = 0; \\n    using var brotli = new BrotliStream(_outp\", \"ut, CompressionMode.Compress, leaveOpen: \\ntrue); \\n    brotli.Write(_data); \\n} \\nMethod \\nRuntime \\nMean\", \" \\nRatio \\nCompress \\n.NET 6.0 \\n9,807.0 ms \\n1.00 \\nCompress \\n.NET 7.0 \\n133.1 ms \\n0.01 \\nOther improvement\", \"s have gone into compression, such as dotnet/runtime#69439 which updates the \\ninternal ZipHelper.Adv\", \"anceToPosition function used by ZipArchive to reuse a buffer on every \\niteration of a loop rather th\", \"an allocating a new buffer for each iteration, dotnet/runtime#66764 which \\nuses spans judiciously to\", \" avoid a bunch of superfluous string and string[] allocations from \\nSystem.IO.Packaging, and dotnet/\", \"runtime#73082 updating the zlib implementations shipped as part \\nof .NET from v1.2.11 (which was rel\", \"eased in January 2017) to v1.2.12 (which was released in March \\n2022). \\n \\n173 \\nCHAPTER 16 | Networki\", \"ng \\n \\nCHAPTER 16 \\nNetworking \\nNetworking is the life-blood of almost every service, with performance\", \" being critical to success. In \\nprevious releases, a lot of effort was focused on the lower layers o\", \"f the networking stack, e.g. .NET 5 \\nsaw a significant investment in improving the performance of so\", \"ckets on Linux. In .NET 7, much of the \\neffort is above sockets. \\nThat said, there were some interes\", \"ting performance improvements in sockets itself for .NET 7. One of \\nthe more interesting is dotnet/r\", \"untime#64770, which revamped how some synchronization is handled \\ninside of SocketsAsyncEventArgs. A\", \"s background, in the early days of networking in .NET Framework, \\nasynchrony was enabled via Begin/E\", \"nd methods (the \\u201cAPM\\u201d pattern). This pattern is not only \\ncomplicated to use well, it\\u2019s relatively i\", \"nefficient, resulting in allocation for every single operation \\nperformed (at a minimum for the IAsy\", \"ncResult object that\\u2019s returned from the BeginXx method). To \\nhelp make networking operations more e\", \"fficient, SocketsAsyncEventArgs was introduced. \\nSocketsAsyncEventArgs is a reusable class you alloc\", \"ate to hold all of the state associated with \\nasynchronous operations: allocate one, pass it to vari\", \"ous async methods (e.g. ReceiveAsync), and \\nthen completion events are raised on the SocketAsyncEven\", \"tArgs instance when the operation \\ncompletes. It can be quite efficient when used correctly, but it\\u2019\", \"s also complicated to use correctly. In \\nsubsequent releases, Task-based and ValueTask-based APIs we\", \"re released; these have the efficiency \\nof SocketAsyncEventArgs and the ease-of-use of async/await, \", \"and are the recommended starting \\npoint for all Socket-based asynchronous programming today. They ha\", \"ve the efficiency of \\nSocketAsyncEventArgs because they\\u2019re actually implemented as a thin veneer on \", \"top of it under the \\ncovers, and so while most code these days isn\\u2019t written to use SocketAsyncEvent\", \"Args directly, it\\u2019s still \\nvery relevant from a performance perspective. \\nSocketAsyncEventArgs on Wi\", \"ndows is implemented to use winsock and overlapped I/O. When you \\ncall an async method like ValueTas\", \"k<Socket> Socket.AcceptAsync(CancellationToken), that grabs \\nan internal SocketAsyncEventArgs and is\", \"sues an AcceptAsync on it, which in turn gets a \\nNativeOverlapped* from the ThreadPoolBoundHandle as\", \"sociated with the socket, and uses it to issue \\nthe native AcceptEx call. When that handle is initia\", \"lly created, we set the \\nFILE_SKIP_COMPLETION_PORT_ON_SUCCESS completion notification mode on the so\", \"cket; use of this \\nwas introduced in earlier releases of .NET Core, and it enables a significant num\", \"ber of socket \\noperations, in particular sends and receives, to complete synchronously, which in tur\", \"n saves \\nunnecessary trips through the thread pool, unnecessary unwinding of async state machines, a\", \"nd so \\non. But it also causes a condundrum. There are some operations we want to perform associated \", \"with \\nasynchronous operation but that have additional overhead, such as registering for the cancella\", \"tion of \\nthose operations, and we don\\u2019t want to pay the cost of doing them if the operation is going\", \" to \\ncomplete synchronously. That means we really want to delay performing such registration until a\", \"fter \\nwe\\u2019ve made the native call and discovered the operation didn\\u2019t complete synchronously\\u2026 but at \", \"that \\npoint we\\u2019ve already initiated the operation, so if it doesn\\u2019t complete synchronously, then we\\u2019\", \"re now in \\n \\n174 \\nCHAPTER 16 | Networking \\n \\na potential race condition, where our code that\\u2019s still\", \" setting up the asynchronous operation is racing \\nwith it potentially completing in a callback on an\", \"other thread. Fun. SocketAsyncEventArgs handled \\nthis race condition with a spin lock; the theory wa\", \"s that contention would be incredibly rare, as the \\nvast majority cases would either be the operatio\", \"n completing synchronously (in which case there\\u2019s no \\nother thread involved) or asynchronously with \", \"enough of a delay that the small amount of additional \\nwork performed by the initiating thread would\", \" have long ago completed by the time the \\nasynchronous operation completed. And for the most part, t\", \"hat was true. However, it turns out that \\nit\\u2019s actually much more common than expected for certain k\", \"inds of operations, like Accepts. Accepts \\nend up almost always completing asynchronously, but if th\", \"ere\\u2019s already a pending connection, \\ncompleting asynchronously almost immediately, which then induce\", \"s this race condition to happen \\nmore frequently and results in more contention on the spin locks. C\", \"ontention on a spin lock is \\nsomething you really want to avoid. And in fact, for a particular bench\", \"mark, this spin lock showed up \\nas the cause for an almost 300% slowdown in requests-per-second (RPS\", \") for a benchmark that used a \\ndedicated connection per request (e.g. with every response setting \\u201cC\", \"onnection: close\\u201d). \\ndotnet/runtime#64770 changed the synchronization mechanism to no longer involve\", \" a spin lock; \\ninstead, it maintains a simple gate implemented as an Interlocked.CompareExchange. If\", \" the initiating \\nthread gets to the gate first, from that point on the operation is considered async\", \"hronous and any \\nadditional work is handled by the completing callback. Conversely, if the callback \", \"gets to the gate first, \\nthe initiating thread treats the operation as if it completed synchronously\", \". This not only avoids one of \\nthe threads spinning while waiting for the other to make forward prog\", \"ress, it also increases the \\nnumber of operations that end up being handled as synchronous, which in\", \" turn reduces other costs \\n(e.g. the code awaiting the task returned from this operation doesn\\u2019t nee\", \"d to hook up a callback and \\nexit, and can instead itself continue executing synchronously). The imp\", \"act of this is difficult to come \\nup with a microbenchmark for, but it can have meaningful impact fo\", \"r loaded Windows servers that \\nend up accepting significant numbers of connections in steady state. \", \"\\nA more-easily quantifiable change around sockets is dotnet/runtime#71090, which improves the \\nperfo\", \"rmance of SocketAddress.Equals. A SocketAddress is the serialized form of an EndPoint, with \\na byte[\", \"] containing the sequence of bytes that represent the address. Its Equals method, used to \\ndetermine\", \" whether to SocketAddress instances are the same, looped over that byte[] byte-by-byte. \\nNot only is\", \" such code gratuitous when there are now helpers available like SequenceEqual for \\ncomparing spans, \", \"doing it byte-by-byte is also much less efficient than the vectorized implementation \\nin SequenceEqu\", \"al. Thus, this PR simply replaced the open-coded comparison loop with a call to \\nSequenceEqual. \\npri\", \"vate SocketAddress _addr = new IPEndPoint(IPAddress.Parse(\\\"123.123.123.123\\\"), \\n80).Serialize(); \\npri\", \"vate SocketAddress _addr_same = new IPEndPoint(IPAddress.Parse(\\\"123.123.123.123\\\"), \\n80).Serialize();\", \" \\n \\n[Benchmark] \\npublic bool Equals_Same() => _addr.Equals(_addr_same); \\nMethod \\nRuntime \\nMean \\nRati\", \"o \\nEquals_Same \\n.NET 6.0 \\n57.659 ns \\n1.00 \\nEquals_Same \\n.NET 7.0 \\n4.435 ns \\n0.08 \\n \\n175 \\nCHAPTER 16 \", \"| Networking \\n \\nLet\\u2019s move up to some more interesting changes in the layers above Sockets, starting\", \" with \\nSslStream. \\nOne of the more impactful changes to SslStream on .NET 7 is in support for TLS re\", \"sumption on Linux. \\nWhen a TLS connection is established, the client and server engage in a handshak\", \"e protocol where \\nthey collaborate to decide on a TLS version and cipher suites to use, authenticate\", \" and validate each \\nother\\u2019s identity, and create symmetric encryption keys for use after the handsha\", \"ke. This represents a \\nsignificant portion of the time required to establish a new connection. For a\", \" client that might \\ndisconnect from a server and then reconnect later, as is fairly common in distri\", \"buted applications, TLS \\nresumption allows a client and server to essentially pick up where they lef\", \"t off, with the client and/or \\nserver storing some amount of information about recent connections an\", \"d using that information to \\nresume. Windows SChannel provides default support for TLS resumption, a\", \"nd thus the Windows \\nimplementation of SslStream (which is built on SChannel) has long had support f\", \"or TLS resumption. \\nBut OpenSSL\\u2019s model requires additional code to enable TLS resumption, and such \", \"code wasn\\u2019t \\npresent in the Linux implementation of SslStream. With dotnet/runtime#57079 and \\ndotnet\", \"/runtime#63030, .NET 7 adds server-side support for TLS resumption (using the variant that \\ndoesn\\u2019t \", \"require storing recent connection state on the server), and with dotnet/runtime#64369, .NET 7 \\nadds \", \"client-side support (which does require storing additional state). The effect of this is significant\", \", in \\nparticular for a benchmark that opens and closes lots of connections between clients. \\nprivate\", \" NetworkStream _client, _server; \\nprivate readonly byte[] _buffer = new byte[1]; \\nprivate readonly S\", \"slServerAuthenticationOptions _options = new \\nSslServerAuthenticationOptions \\n{ \\n    ServerCertifica\", \"teContext = SslStreamCertificateContext.Create(GetCertificate(), null), \\n}; \\n \\n[GlobalSetup] \\npublic\", \" void Setup() \\n{ \\n    using var listener = new Socket(AddressFamily.InterNetwork, SocketType.Stream,\", \" \\nProtocolType.Tcp); \\n    listener.Bind(new IPEndPoint(IPAddress.Loopback, 0)); \\n    listener.Listen\", \"(1); \\n \\n    var client = new Socket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp\", \"); \\n    client.Connect(listener.LocalEndPoint); \\n \\n    _server = new NetworkStream(listener.Accept()\", \", ownsSocket: true); \\n    _client = new NetworkStream(client, ownsSocket: true); \\n} \\n \\n[GlobalCleanu\", \"p] \\npublic void Cleanup() \\n{ \\n    _client.Dispose(); \\n    _server.Dispose(); \\n} \\n \\n[Benchmark] \\npubl\", \"ic async Task Handshake() \\n{ \\n    using var client = new SslStream(_client, leaveInnerStreamOpen: tr\", \"ue, delegate { return \\n \\n176 \\nCHAPTER 16 | Networking \\n \\ntrue; }); \\n    using var server = new SslSt\", \"ream(_server, leaveInnerStreamOpen: true, delegate { return \\ntrue; }); \\n \\n    await Task.WhenAll( \\n \", \"       client.AuthenticateAsClientAsync(\\\"localhost\\\", null, SslProtocols.None, \\ncheckCertificateRevoc\", \"ation: false), \\n        server.AuthenticateAsServerAsync(_options)); \\n \\n    await client.WriteAsync(\", \"_buffer); \\n    await server.ReadAsync(_buffer); \\n    await server.WriteAsync(_buffer); \\n    await cl\", \"ient.ReadAsync(_buffer); \\n} \\n \\nprivate static X509Certificate2 GetCertificate() => \\n    new X509Cert\", \"ificate2( \\n        \\nConvert.FromBase64String(\\\"MIIUmgIBAzCCFFYGCSqGSIb3DQEHAaCCFEcEghRDMIIUPzCCCiAGCS\", \"qGSIb3DQEHA\\naCCChEEggoNMIIKCTCCCgUGCyqGSIb3DQEMCgECoIIJfjCCCXowHAYKKoZIhvcNAQwBAzAOBAhCAauyUWggWwICB\", \"9AE\\ngglYefzzX/jx0b+BLU/TkAVj1KBpojf0o6qdTXV42drqIGhX/k1WwF1ypVYdHeeuDfhH2eXHImwPTw+0bACY0dSiIHK\\nptm0\", \"sb/MskoGI8nlOtHWLi+QBirJ9LSUZcBNOLwoMeYLSFEWWBT69k/sWrc6/SpDoVumkfG4pZ02D9bQgs1+k8fpZjZ\\nGoZp1jput8CQ\", \"XPE3JpCsrkdSdiAbWdbNNnYAy4C9Ej/vdyXJVdBTEsKzPYajAzo6Phj/oS/J3hMxxbReMtj2Z0QkoBB\\nVMc70d+DpAK5OY3et872\", \"D5bZjvxhjAYh5JoVTCLTLjbtPRn1g7qh2dQsIpfQ5KrdgqdImshHvxgL92ooC1eQVqQffMn\\nZ0/LchWNb2rMDa89K9CtAefEIF4v\", \"e2bOUZUNFqQ6dvd90SgKq6jNfwQf/1u70WKE86+vChXMMcHFeKso6hTE9+/zuUP\\nNVmbRefYAtDd7ng996S15FNVdxqyVLlmfcih\", \"X1jGhTLi//WuMEaOfXJ9KiwYUyxdUnMp5QJqO8X/tiwnsuhlFe3NKMX\\nY77jUe8F7I+dv5cjb9iKXAT+q8oYx1LcWu2mj1ER9/b2\", \"omnotp2FIaJDwI40Tts6t4QVH3bUNE9gFIfTMK+WMgKBz/J\\nAGvC1vbPSdFsWIqwhl7mEYWx83HJp/+Uqp5f+d8m4phSan2rkHEe\", \"DjkUaoifLWHWDmL94SZBrgU6yGVK9dU82kr7jCS\\nUTrnga8qDYsHwpQ22QZtu0aOJGepSwZU7NZNMiyX6QR2hI0CNMjvTK2VusHF\", \"B+qnvw+19DzaDT6P0KNPxwBwp07KMQm\\n3HWTRNt9u6gKUmo5FHngoGte+TZdY66dAwCl0Pt+p1v18XlOB2KOQZKLXnhgikjOwYQx\", \"Fr3oTb2MjsP6YqnSF9EpYpm\\niNySXiYmrYxVinHmK+5JBqoQCN2C3N24slZkYq+AYUTnNST7Ib2We3bBICOFdVUgtFITRW40T+0X\", \"ZnIv8G1Kbaq/1av\\nfWI/ieKKxyiYp/ZNXaxc+ycgpsSsAJEuhb83bUkSBpGg9PvFEF0DXm4ah67Ja1SSTmvrCnrOsWZXIpciexMW\", \"RGoKrdv\\nd7Yzj9E8hiu+CGTC4T6+7FxVXJrjCg9zU9G2U6g7uxzoyjGj1wqkhxgvl9pPbz6/KqDRLOHCEwRF4qlWXhsJy4levxG\\n\", \"tifFt6n7DWaNSsOUf8Nwpi+d4fd7LQ7B5tW/y+/vVZziORueruCWO4LnfPhpJ70g18uyN7KyzrWy29rpE46rfjZGGt0\\nWDZYahOb\", \"Pbw6HjcqSOuzwRoJMxamQb2qsuQnaBS6Bhb5PAnY4SEA045odf/u9uC7mLom2KGNHHz6HrgEPas2UHoJLux\\nYvY1pza/29akuVQZ\", \"QUvMA5yMFHHGYZLtTKtCGdVGwX0+QS6ovpV93xux4I/5TrD5U8z9RmTdAx03R3MUhkHF7Zbv5eg\\nDNsVar+41YWG4VkV1ZXtsZRK\", \"Jf0hvKNvrpH0e7fVKBdXljm5PXOSg2VdtkhhOpnKKSMcv6MbGWVi/svWLnc7Qim4A4M\\nDaz+bFVZmh3oGJ7WHvRQhWIcHUL+YJx+\", \"064+4IKXZJ/2a/+b2o7C8mJ3GGSBx831ADogg6MRWZx3UY19OZ8YMvpzmZE\\nBRZZnm4KgNpj+SQnf6pGzD2cmnRhzG60LSNPb17i\", \"KbdoUAEMkgt2tlMKXpnt1r7qwsIoTt407cAdCEsUH7OU/AjfFmS\\nkKJZ7vC5HweqZPnhgJgZ6LYHlfiRzUR1xeDg8JG0nb0vb7LU\", \"E4nGPy39/TxIGos7WNwGpG1QVL/8pKjFdjwREaR8e5C\\nSTlQ7gxHV+G3FFvFGpA1p8cRFzlgE6khDLrSJIUkhkHMA3oFwwAzBNIK\", \"VXjToyxCogDqxWya0E1Hw5rVCS/zOCS1De2\\nXQbXs//g46TW0wTJwvgNbs0xLShf3XB+23meeEsMTCR0+igtMMMsh5K/vBUGcJA2\", \"7ru/KM9qEBcseb/tqCkhhsdj1dn\\nH0HDmpgFf5DfVrjm+P6ickcF2b+Ojr9t7XHgFszap3COpEPGmeJqNOUTuU53tu/O774IBgqI\", \"NMWvvG65yQwsEO06jRr\\nFPRUGb0eH6UM4vC7wbKajnfDuI/EXSgvuOSZ9wE8DeoeK/5We4pN7MSWoDl39gI/LBoNDKFYEYuAw/bh\", \"Gp8nOwDKki4\\na16aYcBGRClpN3ymrdurWsi7TjyFHXfgW8fZe4jXLuKRIk19lmL1gWyD+3bT3mkI2cU2OaY2C0fVHhtiBVaYbxBV\", \"8+k\\njK8q0Q70zf0r+xMHnewk9APFqUjguPguTdpCoH0VAQST9Mmriv/J12+Y+fL6H+jrtDY2zHPxTF85pA4bBBnLA7Qt9TK\\nCe6u\", \"uWu5yBqxOV3w2Oa4Pockv1gJzFbVnwlEUWnIjbWVIyo9vo4LBd03uJHPPIQbUp9kCP/Zw+Zblo42/ifyY+a+scw\\nl1q1dZ7Y0L92\", \"yJCKm9Qf6Q+1PBK+uU9pcuVTg/Imqcg5T7jFO5QCi88uwcorgQp+qoeFi0F9tnUecfDl6d0PSgAPnX9\\nXA0ny3bPwSiWOA8+uW73\", \"gesxnGTsNrtc1j85tail8N6m6S2tHXwOmM65J4XRZlzzeM4D/Rzzh13xpRA9kzm9T2cSHsX\\nEYmSW1X7WovrmYhdOh9K3DPwSyG4\", \"tD58cvC7X79UbOB+d17ieo7ZCj+NSLVQO1BqTK0QfErdoVHGKfQG8Lc/ERQRqj1\\n32Mhi2/r5Ca7AWdqD7/3wgRdQTJSFXt/akpM\", \"44xu5DMTCISEFOLWiseSOBtzT6ssaq2Q35dCkXp5wVbWxkXAD7Gm34F\\nFXXyZrJWAx45Y40wj/0KDJoEzXCuS4Cyiskx1EtYNNOt\", \"fDC5wngywmINFUnnW0NkdKSxmDJvrT6HkRKN8ftik7tP4Zv\\nTaTS28Z0fDmWJ+RjvZW+vtF6mrIzYgGOgdpZwG0ZOSKrXKrY3xpM\", \"O16fXyawFfBosLzCty7uA57niPS76UXdbplgPan\\nIGFyceTg1MsNDsd8vszXd4KezN2VMaxvw+93s0Uk/3Mc+5MAj+UhXPi5UguX\", \"MhNo/CU7erzyxYreOlAI7ZzGhPk+oT9\\ng/MqWa5RpA2IBUaK/wgaNaHChfCcDj/J1qEl6YQQboixxp1IjQxiV9bRQzgwf31Cu2m/\", \"FuHTTkPCdxDK156pyFdhcgT\\npTNy7RPLDF0MBMGCSqGSIb3DQEJFTEGBAQBAAAAMF0GCSsGAQQBgjcRATFQHk4ATQBpAGMAcgBvA\", \"HMAbwBmAHQAIABT\\nAHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgBhAHAAaABpAGMAIABQAHIAbwB2AGkAZABlAHIwggoXBgkq\", \"hkiG9w0\\nBBwagggoIMIIKBAIBADCCCf0GCSqGSIb3DQEHATAcBgoqhkiG9w0BDAEGMA4ECH63Q8xWHKhqAgIH0ICCCdDAo9x82r\\n\", \"wRM6s16wMo01glVedahn1COCP1FKmP6lQ3kjcHruIWlcKW+eCUpt41qs0LM3iFcPQj5x7675DeLL0AC2Ebu7Jhg0FGM\\nJZwHLbmJ\", \"LyG0VSb1WhX2UfxNSdLrdZv8pmejB7DYdV3xAj8DBCRGfwwnbTQjFH9wUPga5U79Dvpqq+YVvUEEci1N6tT\\nPu32LOOEvjoEtpsk\", \"rHoKyqLGV7sSgM6xMIDcfVWbLb8fDcVS1JQRHbeOdGClFMDjwzr+eGWd+OyOZ6BydUGjIKAZpRp\\n \\n177 \\nCHAPTER 16 | Netw\", \"orking \\n \\n0YTk5jjYUMNRbvBP1VPq9ASIh8pJnt/Kq1nqfj7EPatXJJUZAH35E6bSbLBnP0+5+xim1l4HsB8066c4B3aTUXnLep\", \"P\\nRyMIn6Xh5ev0pF3aUc4ZlWgar57TzKUFBTkcH5OCbqZloQ7ZCDNc4C3WKVLSUOKLj3QOxJPrb6/nyXZHjki1tGKisb9\\nRLv4dk\", \"eMdRjsSwNRn6Cfdlk2qHWUCiWLlsLXFyMSM12qrSSfIIBRo0wbn1SEJagHqUmlF9UR5A6b5OODIbDq3cXH/q6\\nU09zVX/BxqxyZq\", \"EfeSAcvXjqImLWnZzbIgm0QH7jOtti/vEfvdzypdWH9V64PzQj/5B8P4ZpbQyWUgzKEIdx24WhTOc\\ndwNivkaEkGFTra3qw2dKO0\", \"RTVtx3bSgesHCumQDuDf8yafLfchWuqihYV7zvqW9BWrsa0W7yKNXLNqdlSz8KvuTnFff\\nOOHrJQwBs+JKdMcKX5IR222RH3fp8D\", \"p17y8hFEaPp4AqpuhHGALXOCwmuPtlUjuHRCUluh3BjaPPLNwLmSGfe0piOVh\\n4rTyJCfN4rlz0lWBAAfIHi47J9sTnSgEJgkTue\", \"mPJXssQ3Z/trcYdfhlYjelOBtS/5DW3wFmjNDilwVBQT66li5xUvc\\nWvZPx/scXgbgpsMThqguJWtiPLR1SzusKCN4q7bVQ8D8Er\", \"Hh5uMb5NmNRIZ/xNeqslqTU9A4bi0TE0FjEu28F0Wg4Cx\\niwqNM58xik9eni85t+S0Uo9wPV1V2Vdhe9LkO3PeoSTCau4D189DoV\", \"iL44WPDQ+TCSvlPP7SFEwaBvUlGBWjxJWVb81\\nlkgRsol1bllUvIzN13V0LSiA0Nks9w9H8cQ17ZRe2r7SpDDR6Rn5oLb9G98Ayv\", \"lcgJfyUe1iZCUAUZGEU247KwePtXY\\nAlO47HbAJe0bOtM9zp7KyWxbImKCfxsPWv6CR6PH+ooHDBO9kXVpKaJCYWeYybSMuPufy/\", \"u/rMcIVO4oXVsdnjh4jAx\\npQOXowCAcN2+Q+XnqtiCr9Mzd0q5ee7jsYuJF6LQRdNP04wIpwjpdggKyB7zURPeTXlV8vIjUs25+C\", \"oCxp+fCXfXKqe\\n2xxdbQ2zFbpKSbJdpbWad3F6MsFBGOKTdyK8EZODGApBtlo71kY6uOxKiBwJKd76zTMsPEQWOZphi2khpTxIVY\", \"ONrmP\\nKjSO8zc4dTC8SW+d1kmCt4UYblwoeDCAYp2RiDHpgC+5yuBDCooT/6fG6GQpa1X0PiH2oUCpltZz2M4+1bH2HdTeBfc\\n1M\", \"tj/hniLL8VdH0qcpS0KYPUxJFEg6IxxrWw1OBreY//6pJLm76nKiflzhz+Mt0RbQZqkPP/K9BxzQw//bW9Kh4iRQ3\\n7D9HNQG/Gt\", \"rCEcbH4V4uUjbj34sEo0FC7gVvDob0Bik8l/c901zQZEydqe0DgHtGbY2xIZ2qqsQy4LDVfHNHqSLiNss\\nL8BJtxUyvnhiwHD7jm\", \"yCB6cWyFGtibRBehQzleioS16xvLph88CMGV3IH9By5QtXpDIB4vjhibE6coPkTmpDCB9xlTE\\n3TV4GBt5JLttkjfOkXAAx0xD52\", \"3Adcy6FVe5QYuY1O8170O6l88YptozyWi5jVfDh+aDg9pjsw/aZ1hCURe9KDaB4gI\\nlW4ZEGKsf5e/xU+vuVxw374te/Y2aCChSj\", \"93XyC+Fjxe06s4yifVAYA0+HtLMGNHe/X0kPXvRnoa5kIu0yHrzViQrBb\\n/4Sbms617Gg1BFONks1JO2G0zIt8CouTqVmdtuH7tV\", \"0JZV/Nmg7NQ1X59XDC/JH2i4jOu8OhnmIZFlTysS6e1qnqsGt\\n/0XcUyzPia8+UIAynXmyi8sWlUjy37w6YqapAfcs7B3TezqIwn\", \"7RgRasJpNBi7eQQqg5YLe6EYTxctKNkGpzeTBUiXN\\nXM4Gv3tIaMbzwlhUNbYWuNBsi/7XJPM5jMycINRbdPwYy19gRBs3pm0FoP\", \"2Lhl5mVAJ2R8a40Lo5g73wvt9Th+uB9/y\\nc196RryQe280yfgKiwUoFFcDnL6SoQTRCTl95mF8zw1f3Hc7QImhubgcLntXEndzSN\", \"N7ZIDSAB8HiDSR6CGYPNiCNAC\\n4hj+jUswoWIE257h+deWFTUvjTZmXH+XMoN6trqjdeCH0hePdmrIWVdr1uTIoO16TR6mFNm6Ut\", \"zc0t5vVrcpnEh3w6a\\nmVHw5xmweW4S75ncN6vSPxGjtfuQ6c2RTG5NXZuWpnhXwOxgoBN4q/h99zVRvwwsF32Eyzx6GOYLmORgCk\", \"zke9eXjjX\\nWY83oysXx/aE9WCqt3en8zzRzzA1aO9Yi88uv1OOqTvWEoGrf4e7SgjXO6hNjYE6EEvK+mMz6a9F3xSWsUlMsZPIIB\", \"e\\n8CEgNEhXKsa6xw7ljSx8Nz7zYG+u5rgXKFmSNvWvwasZyIfRXkccqODl17BaevbWp/ir3rJ/b9mOiV0UW8qIJ3zC6b1\\nlXU5pN\", \"uOODjqhKkjIHPGXiql+uBPVlfUy8Zbi4AntZAeNIB7HtUavVKX6CF7k9AFtRHIWK70+cFEw4yMZiQjaWeB3dt\\n16Fz6LZ8+c17ku\", \"B2wFuZQqYQkf3quWQVPwKj41gFYoFSwFfJ8L6TBcNHI2u3avtVp9ZbP9zArT8An9Ryri/PwTSbPLT\\ncaz549b60/0k4c/qV4XRMu\", \"Fsi29CXcMnLSCPpPKs71LTvsRXK6QUJd4fX/KnTiWargbS6tT6lR/bBqY/gFU1xWyKQ8x\\nij97vlQjffSKdcbj5JsnjSr8xAh9id\", \"fJ2FWZZUJReR9EU1twK7slyUivNLVY7bqroE6CzYaEDecRqfwIrFrzmH+gJoM\\n88waGRC0JTvm8GpBX0eTb5bnMxJKPtH1GIffgy\", \"QLERO1jwjApr6SJEB4yV7x48CZPod9wE51OxUY2hEdAA5l7DBTJys\\ng5gn/nhY6ZzL0llb39yVyDEcZdmrji0ncEMdBDioGBV3mN\", \"z1DL398ZLdjG+xkneI3sgyzgm3cZZ1+/A2kloIEmOKJSe\\n0k/B1cyMB5QRnXpObF1vWXjauMVIKm0wlLY3YQ9I1vfr6y1o2DN+Vy\", \"0sumbIQrjDKqMDswHzAHBgUrDgMCGgQUHEWyD\\n7i5PbatVl3k0+S9WV3ZJRAEFFd7xcvfj1HpkOawyGnJdtcQ0KWPAgIH0A==\\\"),\", \" \\n        \\\"testcertificate\\\", \\n        X509KeyStorageFlags.DefaultKeySet); \\nMethod \\nRuntime \\nMean \\nRa\", \"tio \\nAllocated \\nAlloc Ratio \\nHandshake \\n.NET 6.0 \\n4.647 ms \\n1.00 \\n19.27 KB \\n1.00 \\nHandshake \\n.NET 7.\", \"0 \\n2.314 ms \\n0.50 \\n9.56 KB \\n0.50 \\nAnother significant improvement for SslStream in .NET 7 is support\", \" for OCSP stapling. When a client \\nhandshakes with the server and the server shares its certificate,\", \" a client that cares about validating it\\u2019s \\ntalking to exactly who it intended to talk to needs to v\", \"alidate that certificate. In the days of yore, such \\nvalidation was done with certificate revocation\", \" lists (CRL), where periodically the client would \\ndownload a giant list of certificates known to be\", \" revoked. Online Certificate Status Protocol (OCSP) is \\na newer protocol and mechanism that enables \", \"a client to get real-time information about a certificate; \\nwhile the client handshakes with the ser\", \"ver and the server sends the client its certificate, the client \\nthen connects to an \\u201cOCSP responder\", \"\\u201d and sends it a request to determine whether the certificate is \\nconsidered good. OCSP has multiple\", \" issues of its own, however. In particular, it places a significant \\nload on these OCSP responder se\", \"rvers, with every client making a real-time request to it about every \\ncertificate encountered, and \", \"also potentially significantly increasing the time it takes the client to \\nestablish a connection. O\", \"CSP stapling offers a solution to this. Rather than a client issuing a request to \\n \\n178 \\nCHAPTER 16\", \" | Networking \\n \\nthe OCSP responder, the server itself contacts the OCSP responder and gets a signed\", \" ticket from the \\nOCSP responder stating that the server\\u2019s certificate is good and will be for some \", \"period of time. When \\na client handshakes with the server, the server can then \\u201cstaple\\u201d (include) th\", \"is signed ticket as part of \\nits response to the client, giving the validation to the client directl\", \"y rather than the client needing to \\nmake a separate roundtrip to the OCSP responder. This reduces o\", \"verheads for everyone involved. \\ndotnet/runtime#67011 adds support for OCSP stapling to SslStream cl\", \"ient usage on Linux, with \\ndotnet/runtime#69833 adding the Linux server-side counterpart, and dotnet\", \"/runtime#71570 adds \\nclient-side support for Windows. \\nThe aforementioned changes are primarily abou\", \"t the performance of opening a connection. \\nAdditional work has been done to improve that further in\", \" other ways. dotnet/runtime#69527 gets rid \\nof allocations associated with several SafeHandle instan\", \"ces that were being created unnecessarily on \\nLinux as part of establishing a TLS connection. This h\", \"ighlights the benefits of doing profiling on \\nmultiple platforms, as while these SafeHandles were ne\", \"cessary in the Windows implementation, they \\nwere fairly meaningless in the Linux implementation (du\", \"e to differences between SChannel and \\nOpenSSL), and were only brought along for the ride because of\", \" how the platform-abstraction layer \\n(PAL) was defined to reuse most of the SslStream code across pl\", \"atforms. And dotnet/runtime#68188 \\navoids several collections allocated as part of the TLS handshake\", \". This one is particularly interesting as \\nit\\u2019s come up multiple times in the past in various librar\", \"ies. Imagine you have a lazily initialized \\nproperty like this: \\nprivate List<T>? _items; \\npublic Li\", \"st<T> Items => _items ??= new List<T>(); \\nAnd then some code in the same implementation comes along \", \"and wants to read the contents of \\nthese items. That code might look like: \\nif (Items.Count > 0) { .\", \".. } \\nbut the very act of accessing Items just to check its count forces the collection into existen\", \"ce (with a 0 \\nCount). If the code instead checks: \\nif (_items is List<T> items && items.Count > 0) {\", \" ... } \\nIt can save that unnecessary collection allocation. The approach is made even simpler with C\", \"# pattern \\nmatching: \\nif (_items is { Count: > 0 }) items) { ... } \\nThis is one of those things that\", \"\\u2019s incredibly obvious once you \\u201csee\\u201d it and realize what\\u2019s happening, \\nbut you often miss until it j\", \"umps out at you in a profiler. \\ndotnet/runtime#69098 is another good example of how profiling can le\", \"ad to insights about \\nallocations that can be removed. Application-Layer Protocol Negotation (ALPN) \", \"allows code \\nestablishing a TLS connection to piggy-back on the roundtrips that are being used for t\", \"he TLS \\nhandshake anyway to negotiate some higher-level protocol that will end up being used as well\", \". A very \\ncommon use-case, for example, is for an HTTPS client/server to negotiate which version of \", \"HTTP \\nshould be used. This information is exposed from SslStream as an SslApplicationProtocol struct\", \" \\nreturned from its NegotiatedApplicationProtocol property, but as the actual negotiated protocol \\nc\", \"an be arbitrary data, SslApplicationProtocol just wraps a byte[]. The implementation had been \\n \\n179\", \" \\nCHAPTER 16 | Networking \\n \\ndutifully allocating a byte[] to hold the bytes passed around as part o\", \"f ALPN, since we need such a \\nbyte[] to store in the SslApplicationProtocol. But while the byte data\", \" can be arbitrary, in practice \\nby far the most common byte sequences are equivalent to \\u201chttp/1.1\\u201d f\", \"or HTTP/1.1, \\u201ch2\\u201d for HTTP/2, \\nand \\u201ch3\\u201d for HTTP/3. Thus, it makes sense to special-case those value\", \"s and use a reusable cached \\nbyte[] singleton when one of those values is needed. If SslApplicationP\", \"rotocol exposed the \\nunderlying byte[] directly to consumers, we\\u2019d be hesitant to use such singleton\", \"s, as doing so would \\nmean that if code wrote into the byte[] it would potentially be changing the v\", \"alue for other \\nconsumers in the same process. However, SslApplicationProtocol exposes it as a \\nRead\", \"OnlyMemory<byte>, which is only mutable via unsafe code (using the \\nMemoryMarshal.TryGetArray method\", \"), and once you\\u2019re employing unsafe code to do \\u201cbad\\u201d things,\\\" \\nall bets are off anyway. dotnet/runti\", \"me#63674 also removes allocations related to ALPN, in this case \\navoiding the need for a byte[] allo\", \"cation on Linux when setting the negotiated protocol on a client \\nSslStream. It uses stack memory in\", \"stead of an array allocation for protocols up to 256 bytes in length, \\nwhich is way larger than any \", \"in known use, and thus doesn\\u2019t bother to do anything fancy for the \\nfallback path, which will never \", \"be used in practice. And dotnet/runtime#69103 further avoids ALPN-\\nrelated allocations and work on W\", \"indows by entirely skipping some unnecessary code paths: various \\nmethods can be invoked multiple ti\", \"mes during a TLS handshake, but even though the ALPN-related \\nwork only needed to happen once the fi\", \"rst time, the code wasn\\u2019t special-casing it and was instead \\nrepeating the work over and over. \\nEver\", \"ything discussed thus far was about establishing connections. What about the performance of \\nreading\", \" and writing on that connection? Improvements have been made there, too, in particular \\naround memor\", \"y management and asynchrony. But first we need some context. \\nWhen async/await were first introduced\", \", Task and Task<TResult> were the only game in town; while \\nthe pattern-based mechanism the compiler\", \" supports for arbitrary \\u201ctask-like\\u201d types enabled async \\nmethods to return other types, in practice \", \"it was only tasks (which also followed our guidance). We \\nsoon realized, however, that a significant\", \" number of calls to a significant number of commonly-used \\nasync APIs would actually complete synchr\", \"onously. Consider, for example, a method like \\nMemoryStream.ReadAsync: MemoryStream is backed entire\", \"ly by an in-memory buffer, so even though \\nthe operation is \\u201casync,\\u201d every call to it completes sync\", \"hronously, as the operation can be performed \\nwithout doing any potentially long-running I/O. Or con\", \"sider FileStream.ReadAsync. By default \\nFileStream employs its own internal buffer. If you issue a c\", \"all to FileStream.ReadAsync with your \\nown buffer and ask for only, say, 16 bytes, under the covers \", \"FileStream.ReadAsync will issue the \\nactual native call with its own much larger buffer, which by de\", \"fault is 4K. The first time you issue your \\n16-byte read, actual I/O will be required and the operat\", \"ion is likely to complete asynchronously. But \\nthe next 255 calls you make could simply end up drain\", \"ing the remainder of the data read into that 4K \\nbuffer, in which case 255 of the 256 \\u201casync\\u201d operat\", \"ions actually complete synchronously. If the \\nmethod returns a Task<int>, every one of those 255 syn\", \"chronously-completing calls could still end \\nup allocating a Task<int>, just to hand back the int th\", \"at\\u2019s already known. Various techniques were \\ndevised to minimize this, e.g. if the int is one of a f\", \"ew well-known values (e.g. -1 through 8), then the \\nasync method infrastructure will hand back a pre\", \"-allocated and cached Task<int> instance for that \\nvalue, and various stream implementations (includ\", \"ing FileStream) would cache the previously-\\nreturned Task<int> and hand it back for the next call as\", \" well if the next call yielded exactly the same \\nnumber of bytes. But those optimizations don\\u2019t full\", \"y mitigate the issue. Instead, we introduced the \\nValueTask<TResult> struct and provided the necessa\", \"ry \\u201cbuilder\\u201d to allow async methods to return \\n \\n180 \\nCHAPTER 16 | Networking \\n \\nthem. ValueTask<TRe\", \"sult> was simply a discrimated union between a TResult and Task<TResult>. If \\nan async method comple\", \"ted asynchronously (or if it failed synchronously), well, it would simply \\nallocate the Task<TResult\", \"> as it otherwise would have and return that task wrapped in a \\nValueTask<TResult>. But if the metho\", \"d actually completed synchronously and successfully, it would \\ncreate a ValueTask<TResult> that just\", \" wrapped the resulting TResult, which then eliminates all \\nallocation overhead for the synchronously\", \"-completing case. Yay, everyone\\u2019s happy. Well, almost \\neveryone. For really hot paths, especially th\", \"ose lower down in the stack that many other code paths \\nbuild on top of, it can also be beneficial t\", \"o avoid the allocations even for the asynchronously \\ncompleting case. To address that, .NET Core 2.1\", \" saw the introduction of the \\nIValueTaskSource<TResult> interface along with enabling ValueTask<TRes\", \"ult> to wrap an instance \\nof that interface in addition to a TResult or a Task<TResult> (at which po\", \"int it also became \\nmeaningful to introduce a non-generic ValueTask and the associated IValueTaskSou\", \"rce). Someone \\ncan implement this interface with whatever behaviors they want, although we codified \", \"the typical \\nimplementation of the core async logic into the ManualResetValueTaskSourceCore helper s\", \"truct, \\nwhich is typically embedded into some object, with the interface methods delegating to \\ncorr\", \"esponding helpers on the struct. Why would someone want to do this? Most commonly, it\\u2019s to be \\nable \", \"to reuse the same instance implementing this interface over and over and over. So, for example, \\nSoc\", \"ket exposes a ValueTask<int> ReceiveAsync method, and it caches a single instance of an \\nIValueTaskS\", \"ource<int> implementation for use with such receives. As long as you only ever have \\none receive pen\", \"ding on a given socket at a time (which is the 99.999% case), every ReceiveAsync call \\nwill either r\", \"eturn a ValueTask<int> wrapped around an int value or a ValueTask<int> wrapped \\naround that reusable\", \" IValueTaskSource<int>, making all use of ReceiveAsync ammortized \\nallocation-free (there is another\", \" instance used for SendAsync, such that you can have a concurrent \\nread and write on the socket and \", \"still avoid allocations). However, implementing this support is still \\nnon-trivial, and can be super\", \" hard when dealing with an operation that\\u2019s composed of multiple \\nsuboperations, which is exactly wh\", \"ere async/await shine. Thus, C# 10 added support for overriding \\nthe default builder that\\u2019s used on \", \"an individual async method (e.g. such that someone could provide \\ntheir own builder for a ValueTask<\", \"int>-returning method instead of the one that allocates Task<int> \\ninstances for asynchronous comple\", \"tion) and .NET 6 included the new \\nPoolingAsyncValueTaskMethodBuilder and PoolingAsyncValueTaskMetho\", \"dBuilder<> types. With \\nthose, an async method like: \\npublic async ValueTask<int> ReadAsync(Memory<b\", \"yte> buffer) { ... } \\ncan be changed to be: \\n[AsyncMethodBuilder(typeof(PoolingAsyncValueTaskMethodB\", \"uilder<>))] \\npublic async ValueTask<int> ReadAsync(Memory<byte> buffer) { ... } \\nwhich will cause th\", \"e C# compiler to emit the implementation of this method using \\nPoolingAsyncValueTaskMethodBuilder<in\", \"t> instead of the default \\nAsyncValueTaskMethodBuilder<int>. The implementation of \\nPoolingAsyncValu\", \"eTaskMethodBuilder<TResult> is true to its name; it employs pooling to avoid \\nmost of the allocation\", \" asynchronous completion would otherwise experience (I say \\u201cmost\\u201d because \\nthe pooling by design tri\", \"es to balance all the various costs involved and may still sometimes allocate), \\nand makes it easy f\", \"or methods implemented with async/await to reap those benefits. So, if this was \\nall introduced in t\", \"he last release, why am I talking about it now? Pooling isn\\u2019t free. There are various \\n \\n181 \\nCHAPTE\", \"R 16 | Networking \\n \\ntradeoffs involved in its usage, and while it can make microbenchmarks look rea\", \"lly good, it can also \\nnegatively impact real-world usage, e.g. by increasing the cost of garbage co\", \"llections that do occur by \\nincreasing the number of Gen2 to Gen0 references that exist. As such, wh\", \"ile the functionality is \\nvaluable, we\\u2019ve been methodical in where and how we use it, choosing to do\", \" so more slowly and only \\nemploying it after sufficient analysis deems it\\u2019s worthwhile. \\nSuch is the\", \" case with SslStream. With dotnet/runtime#69418, two core and hot async methods on \\nSslStream\\u2019s read\", \" path were annotated to use pooling. A microbenchmark shows what I mean when I \\nwrote this can make \", \"microbenchmarks look really good (focus on the allocation columns). This \\nbenchmark is repeatedly is\", \"suing a read (that will be forced to complete asynchronously because \\nthere\\u2019s no available data to s\", \"atisfy it), then issuing a write to enable that read to complete, and then \\nawaiting the read\\u2019s comp\", \"letion; every read thus completes asynchronously. \\nprivate SslStream _sslClient, _sslServer; \\nprivat\", \"e readonly byte[] _buffer = new byte[1]; \\nprivate readonly SslServerAuthenticationOptions _options =\", \" new \\nSslServerAuthenticationOptions \\n{ \\n    ServerCertificateContext = SslStreamCertificateContext.\", \"Create(GetCertificate(), null), \\n}; \\n     \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    using var list\", \"ener = new Socket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp); \\n    listener.B\", \"ind(new IPEndPoint(IPAddress.Loopback, 0)); \\n    listener.Listen(1); \\n \\n    var client = new Socket(\", \"AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp); \\n    client.Connect(listener.Loca\", \"lEndPoint); \\n \\n    _sslClient = new SslStream(new NetworkStream(client, ownsSocket: true), \\nleaveInn\", \"erStreamOpen: true, delegate { return true; }); \\n    _sslServer = new SslStream(new NetworkStream(li\", \"stener.Accept(), ownsSocket: true), \\nleaveInnerStreamOpen: true, delegate { return true; }); \\n \\n    \", \"Task.WaitAll( \\n        _sslClient.AuthenticateAsClientAsync(\\\"localhost\\\", null, SslProtocols.None, \\nc\", \"heckCertificateRevocation: false), \\n        _sslServer.AuthenticateAsServerAsync(_options)); \\n} \\n \\n[\", \"GlobalCleanup] \\npublic void Cleanup() \\n{ \\n    _sslClient.Dispose(); \\n    _sslServer.Dispose(); \\n} \\n \", \"\\n[Benchmark] \\npublic async Task ReadWriteAsync() \\n{ \\n    for (int i = 0; i < 1000; i++) \\n    { \\n    \", \"    ValueTask<int> read = _sslClient.ReadAsync(_buffer); \\n \\n182 \\nCHAPTER 16 | Networking \\n \\n        \", \"await _sslServer.WriteAsync(_buffer); \\n        await read; \\n    } \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\n\", \"Code Size \\nAllocated \\nAlloc Ratio \\nReadWriteAsync \\n.NET 6.0 \\n68.34 ms \\n1.00 \\n510 B \\n336404 B \\n1.000 \", \"\\nReadWriteAsync \\n.NET 7.0 \\n69.60 ms \\n1.02 \\n514 B \\n995 B \\n0.003 \\nOne final change related to reading \", \"and writing performance on an SslStream. I find this one \\nparticularly interesting, as it highlights\", \" a new and powerful C# 11 and .NET 7 feature: static abstract \\nmembers in interfaces. SslStream, as \", \"with every Stream, exposes both synchronous and asynchronous \\nmethods for reading and writing. And a\", \"s you may be aware, the code within SslStream for \\nimplementing reads and writes is not particularly\", \" small. Thus, we really want to avoid having to \\nduplicate all of the code paths, once for synchrono\", \"us work and once for asynchronous work, when in \\nreality the only place that bifurcation is needed i\", \"s at the leaves where calls into the underlying Stream \\nare made to perform the actual I/O. Historic\", \"ally, we\\u2019ve had two different mechanisms we\\u2019ve employed \\nin dotnet/runtime for handling such unifica\", \"tion. One is to make all methods async, but with an \\nadditional bool useAsync parameter that gets fe\", \"d through the call chain, then branching based on it \\nat the leaves, e.g. \\npublic static void Work(S\", \"tream s) => \\n    A(s, useAsyunc: false).GetAwaiter().GetResult(); // GetResult() to propagate any \\ne\", \"xceptions \\n \\npublic static Task WorkAsync(Stream S) => \\n    A(s, useAsync: true); \\n \\ninternal static\", \" async Task A(Stream s, bool useAsync) \\n{ \\n    ... \\n    await B(s, useAsync); \\n    ... \\n} \\n \\nprivate\", \" static async Task B(Stream s, bool useAsync) \\n{ \\n    ... \\n    int bytesRead = useAsync ? \\n        a\", \"wait s.ReadAsync(buffer) : \\n        s.Read(buffer.Span); \\n    ... \\n} \\nThis way most of the logic and\", \" code is shared, and when useAsync is false, everything completes \\nsynchronously and so we don\\u2019t pay\", \" for allocation that might otherwise be associated with the async-\\nness. The other approach is simil\", \"ar in spirit, but instead of a bool parameter, taking advantage of \\ngeneric specialization and inter\", \"face-implementing structs. Consider an interface like: \\ninterface IReader \\n{ \\n    ValueTask<int> Rea\", \"dAsync(Stream s, Memory<byte> buffer); \\n} \\n \\n183 \\nCHAPTER 16 | Networking \\n \\nWe can then declare two\", \" implementations of this interface: \\nstruct SyncReader : IReader \\n{ \\n    public ValueTask<int> ReadA\", \"sync(Stream s, Memory<byte> buffer) => \\n        new ValueTask<int>(s.Read(buffer.Span)); \\n} \\n \\nstruc\", \"t AsyncReader : IReader \\n{ \\n    public ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) => \\n \", \"       s.ReadAsync(buffer); \\n} \\nThen we can redeclare our earlier example as: \\npublic static void Wo\", \"rk(Stream s) => \\n    A(stream, default(SyncReader)).GetAwaiter().GetResult(); // to propagate any ex\", \"ceptions \\n \\npublic static Task WorkAsync(Stream S) => \\n    A(s, default(AsyncReader)); \\n \\ninternal s\", \"tatic async Task A<TReader>(Stream s, TReader reader) where TReader : IReader \\n{ \\n    ... \\n    await\", \" B(s, reader); \\n    ... \\n} \\n \\nprivate static async Task B<TReader>(Stream s, TReader reader) where T\", \"Reader : IReader \\n{ \\n    ... \\n    int bytesRead = await reader.ReadAsync(s, buffer); \\n    ... \\n} \\nNo\", \"te that the generic constraint on the TReader parameter here allows the implementation to invoke \\nth\", \"e interface methods, and passing the structs as a generic avoids boxing. One code path supporting \\nb\", \"oth sync and async implementations. \\nThis latter generic approach is how SslStream has historically \", \"handled the unification of its sync and \\nasync implementations. It gets better in .NET 7 with C# 11 \", \"now that we have static abstract methods \\nin interfaces. We can instead declare our interface as (no\", \"te the static abstract addition): \\ninterface IReader \\n{ \\n    static abstract ValueTask<int> ReadAsyn\", \"c(Stream s, Memory<byte> buffer); \\n} \\nour types as (note the static addition): \\nstruct SyncReader : \", \"IReader \\n{ \\n    public static ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) => \\n        ne\", \"w ValueTask<int>(s.Read(buffer.Span)); \\n} \\n \\nstruct AsyncReader : IReader \\n \\n184 \\nCHAPTER 16 | Netwo\", \"rking \\n \\n{ \\n    public static ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) => \\n        s.\", \"ReadAsync(buffer); \\n} \\nand our consuming methods as (note the removal of the parameter and the switc\", \"h to calling static \\nmethods on the type parameter): \\npublic static void Work(Stream s) => \\n    A<Sy\", \"ncReader>(stream).GetAwaiter().GetResult(); // to propagate any exceptions \\n \\npublic static Task Wor\", \"kAsync(Stream S) => \\n    A<AsyncReader>(s); \\n \\ninternal static async Task A<TReader>(Stream s) where\", \" TReader : IReader \\n{ \\n    ... \\n    await B<TReader>(s); \\n    ... \\n} \\n \\nprivate static async Task B<\", \"TReader>(Stream s) where TReader : IReader \\n{ \\n    ... \\n    int bytesRead = await TReader.ReadAsync(\", \"s, buffer); \\n    ... \\n} \\nNot only is this cleaner, but from a performance perspective we no longer n\", \"eed to pass around the \\ndummy generic parameter, which is general goodness, but for an async method \", \"it\\u2019s particularly \\nbeneficial because the state machine type ends up storing all parameters as field\", \"s, which means every \\nparameter can increase the amount of allocation incurred by an async method if\", \" the method ends up \\ncompleting asynchronously. dotnet/runtime#65239 flipped SslStream (and Negotiat\", \"eStream) to \\nfollow this approach. It\\u2019s also used in multiple other places now throughout dotnet/run\", \"time. \\ndotnet/runtime#69278 from [@teo-tsirpanis](https://github.com/teo-tsirpanis) changed the \\nRan\", \"domAccess class\\u2019 implementation for Windows and the ThreadPool\\u2019s mechanism for invoking work \\nitems \", \"to use the same approach. Further, dotnet/runtime#63546 did the same in the Regex \\nimplementation, a\", \"nd in particular in the new RegexOptions.NonBacktracking implementation, as a \\nway to abstract over \", \"DFA and NFA-based operations using the same code (this technique was since \\nfurther utilized in NonB\", \"acktracking, such as by dotnet/runtime#71234 from \\n[@olsaarik](https://github.com/olsaarik)). And po\", \"tentially most impactfully, dotnet/runtime#73768 did \\nso with IndexOfAny to abstract away the differ\", \"ences between IndexOfAny and IndexOfAnyExcept \\n(also for the Last variants). With the introduction o\", \"f the {Last}IndexOfAnyExcept variations \\npreviously mentioned, we now have four different variants o\", \"f IndexOfAny with essentially the same \\nfunctionality: searching forward or backwards, and with equa\", \"lity or inequality. While more challenging \\nto try to unify the directional aspect, this PR utilized\", \" this same kind of generic specialization to hide \\nbehind an interface the ability to negate the com\", \"parison; the core implementations of these methods \\ncan then be implemented once and passed either a\", \" Negate or DontNegate implementation of the \\ninterface. The net result is not only that the new Exce\", \"pt varieties immediately gained all of the \\noptimizations of the non-Except varieties, but also the \", \"goal of trying to make everything consistent \\nresulted in finding places where we were missing optim\", \"ization opportunities in existing methods \\n(gaps that the PR also rectified). \\n \\n185 \\nCHAPTER 16 | N\", \"etworking \\n \\nprivate static readonly string s_haystack = new \\nHttpClient().GetStringAsync(\\\"https://w\", \"ww.gutenberg.org/files/1661/1661-0.txt\\\").Result; \\n \\n[Benchmark] \\npublic int LastIndexOfAny() => s_ha\", \"ystack.AsSpan().LastIndexOfAny(';', '_'); \\nMethod \\nRuntime \\nMean \\nRatio \\nLastIndexOfAny \\n.NET 6.0 \\n9\", \".977 us \\n1.00 \\nLastIndexOfAny \\n.NET 7.0 \\n1.172 us \\n0.12 \\nLet\\u2019s move up the stack to HTTP. Most of th\", \"e folks focusing on networking in .NET 7 were focused on \\ntaking the preview support for HTTP/3 that\", \" shipped in .NET 6 and making it a first-class supported \\nfeature in .NET 7. That included functiona\", \"l improvements, reliability and correctness fixes, and \\nperformance improvements, such that HTTP/3 c\", \"an now be used via HttpClient on both Windows \\nand Linux (it depends on an underlying QUIC implement\", \"ation in the msquic component, which isn\\u2019t \\ncurrently available for macOS). However, there were sign\", \"ificant improvements throughout the HTTP \\nstack, beyond HTTP/3. \\nOne aspect of HttpClient that cuts \", \"across all versions of HTTP is support for handling and \\nrepresenting headers. While significant imp\", \"rovements went into previous releases to trim down the \\nsize of the data structures used to store he\", \"ader information, further work on this front was done for \\n.NET 7. dotnet/runtime#62981, for example\", \", improves the data structure used to store headers. One of \\nthe things HttpHeaders needs to deal wi\", \"th is that there\\u2019s no defined limit to the number of headers \\nthat can be sent with an HTTP request \", \"or response (though in order to mitigate possible denial of \\nservice attacks, the implementation has\", \" a configurable limit for how many bytes of headers are \\naccepted from the server), and thus it need\", \"s to be able to handle an arbitrary number of them and to \\ndo so with efficient access. As such, for\", \" the longest time HttpHeaders has used a Dictionary<,> to \\nprovide O(1) lookup into these headers. H\", \"owever, while it\\u2019s valid to have large numbers of headers, \\nit\\u2019s most common to only have a handful,\", \" and for only a few items, the overheads involved in a hash \\ntable like Dictionary<> can be more tha\", \"n just storing the elements in an array and doing an O(N) \\nlookup by doing a linear search through a\", \"ll the elements (algorithmic complexity ignores the \\n\\u201cconstants\\u201d involved, so for a small N, an O(N)\", \" algorithm might be much faster and lighterweight than \\nan O(1)). This PR takes advantage of that an\", \"d teaches HttpHeaders how to use either an array or a \\ndictionary; for common numbers of headers (th\", \"e current threshold is 64), it just uses an array, and in \\nthe rare case where that threshold is exc\", \"eeded, it graduates into a dictionary. This reduces the \\nallocation in HttpHeader in all but the mos\", \"t niche cases while also making it faster for lookups. \\nAnother header-related size reduction comes \", \"in dotnet/runtime#64105. The internal representation of \\nheaders involves a HeaderDescriptor that en\", \"ables \\u201cknown headers\\u201d (headers defined in the HTTP \\nspecifications or that we\\u2019re otherwise aware of \", \"and want to optimize) to share common data, e.g. if a \\nresponse header matches one of these known he\", \"aders, we can just use the header name string \\nsingleton rather than allocating a new string for tha\", \"t header each time we receive it. This \\nHeaderDescriptor accomodated both known headers and custom h\", \"eaders by having two fields, one \\nfor known header data (which would be null for custom headers) and\", \" one for the header name. \\nInstead, this PR employs a relatively-common technique of having a single\", \" object field that then \\nstores either the known header information or the name, since the known hea\", \"der information itself \\nincludes the name, and thus we don\\u2019t need the duplication. At the expense of\", \" a type check when we \\n \\n186 \\nCHAPTER 16 | Networking \\n \\nneed to look up information from that field\", \", we cut the number of fields in half. And while this \\nHeaderDescriptor is itself a struct, it\\u2019s sto\", \"red in header collections, and thus by cutting the size of the \\nHeaderDescriptor in half, we can sig\", \"nificantly reduce the size of those collections, especially when \\nmany custom headers are involved. \", \"\\nprivate readonly string[] _strings = new[] { \\\"Access-Control-Allow-Credentials\\\", \\\"Access-\\nControl-A\", \"llow-Origin\\\", \\\"Cache-Control\\\", \\\"Connection\\\", \\\"Date\\\", \\\"Server\\\" }; \\n \\n[Benchmark] \\npublic HttpResponse\", \"Headers GetHeaders() \\n{ \\n    var headers = new HttpResponseMessage().Headers; \\n    foreach (string s\", \" in _strings) \\n    { \\n        headers.TryAddWithoutValidation(s, s); \\n    } \\n    return headers; \\n} \", \"\\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAlloc Ratio \\nGetHeaders \\n.NET 6.0 \\n334.4 ns \\n1.00 \\n664 B \\n1\", \".00 \\nGetHeaders \\n.NET 7.0 \\n213.9 ns \\n0.64 \\n360 B \\n0.54 \\nSimilarly focused on allocation, dotnet/runt\", \"ime#63057 removes two fields from the \\nHttpHeaderValueCollection<T> collection type, which provides \", \"the concrete implementation for \\nICollection<T> properties like HttpContentHeaders.ContentEncoding, \", \"\\nHttpRequestHeaders.UserAgent, and HttpResponseHeaders.Server. The initial design and \\nimplementatio\", \"n of this type were overly flexible, with a mechanism for custom validation of values, \\nwhich entail\", \"ed multiple fields for storing things like an Action<> callback to use for validation. But as \\nit tu\", \"rns out in practice, that validation was only used for one specific consumer, and so rather than \\nma\", \"king everyone pay for the extra space that wasn\\u2019t typically used, the validation was instead \\nextrac\", \"ted out to just the call sites it was required. \\nA more focused allocation reduction comes in dotnet\", \"/runtime#63641. The shared internal utility \\nmethod HttpRuleParser.GetHostLength was using string.Su\", \"bstring in order to hand back the \\nparsed host information, but only some of the callers needed this\", \". Rather than making everyone pay \\nfor something that not everyone needed, this logic was moved into\", \" only the call sites that needed it. \\nOther small allocation improvements were also made outside of \", \"headers. For example, when new \\nHTTP/1 and HTTP/2 connections are created, the implementation queues\", \" a work item to the thread \\npool to handle the actual creation, primarily to escape locks that might\", \" be held higher in the call \\nstack. To do so, it used Task.Run. And while normally Task.Run is a fin\", \"e thing to use, in this case there \\nwere two issues: the resulting Task was being ignored, such that\", \" any unexpected exceptions would \\njust be eaten, and the lambda being passed to Task.Run was closing\", \" over this and a local, which \\nmeans the C# compiler will have generated code to allocate both a \\u201cdi\", \"splay class\\u201d (an object to store \\nthe state being passed in) for the closure and then also a delegat\", \"e to a method on that display class. \\nInstead, dotnet/runtime#68750 switches it to use ThreadPool.Qu\", \"eueUserWorkItem, using the \\noverload that takes a generic TState, and passing in a tuple of all requ\", \"ired state in order to avoid \\nboth superfluous allocations. \\n \\n187 \\nCHAPTER 16 | Networking \\n \\nFolks\", \" using HTTP often need to go through a proxy server, and in .NET the ability to go through an \\nHTTP \", \"proxy is represented via the IWebProxy interface; it has three members, GetProxy for getting the \\nUr\", \"i of the proxy to use for a given destination Uri, the IsBypassed method which says whether a \\ngiven\", \" Uri should go through a proxy or not, and then a Credentials property to be used when \\naccessing th\", \"e target proxy. The canonical implementation of IWebProxy provided in the core libraries \\nis the apt\", \"ly named WebProxy. WebProxy is fairly simple: you give it a proxy Uri, and then calls to \\nGetProxy r\", \"eturn that proxy Uri if the destination isn\\u2019t to be bypassed. Whether a Uri should be \\nbypassed is d\", \"etermined by two things (assuming a non-null proxy Uri was provided): did the \\nconstructor of the We\", \"bProxy specify that \\u201clocal\\u201d destinations should be bypassed (and if so, is this \\ndestination local),\", \" or does this destination address match any of any number of regular expressions \\nprovided. As it tu\", \"rns out, this latter aspect has been relatively slow and allocation-heavy in all previous \\nreleases \", \"of .NET, for two reasons: every call to check whether an address was bypassed was recreating \\na Rege\", \"x instance for every supplied regular expression, and every call to check whether an address \\nwas by\", \"passed was deriving a new string from the Uri to use to match against the Regex. In .NET 7, \\nboth of\", \" those issues have been fixed, yielding significant improvements if you rely on this regular \\nexpres\", \"sion functionality. dotnet/runtime#73803 from \\n[@onehourlate](https://github.com/onehourlate) change\", \"d the handling of the collection of these \\nRegex instances. The problem was that WebProxy exposes an\", \" ArrayList (this type goes back to the \\nbeginning of .NET and was created pre-generics), which the c\", \"onsumer could modify, and so WebProxy \\nhad to assume the collection was modified between uses and ad\", \"dressed that by simply creating new \\nRegex instances on every use; not good. Instead, this PR create\", \"s a custom ArrayList-derived type \\nthat can track all relevant mutations, and then only if the colle\", \"ction is changed (which is incredibly \\nrare, bordering on never) do the Regex instances need to be r\", \"ecreated. And dotnet/runtime#73807 \\ntakes advantage of stack allocation and the MemoryExtensions.Try\", \"Write method with string \\ninterpolation to format the text into stack memory, avoiding the string al\", \"location. This, combined with \\nthe new Regex.IsMatch(ReadOnlySpan<char>) overload that enables us to\", \" match against that \\nstackalloc\\u2019d span, makes that aspect of the operation allocation-free as well. \", \"Altogether, drastic \\nimprovements: \\nprivate WebProxy _proxy = new WebProxy(\\\"http://doesntexist\\\", Byp\", \"assOnLocal: false, new[] { \\n@\\\"\\\\.microsoft.com\\\", @\\\"\\\\.dot.net\\\", @\\\"\\\\.bing.com\\\" }); \\nprivate Uri _destin\", \"ation = new \\nUri(\\\"https://docs.microsoft.com/dotnet/api/system.net.webproxy\\\"); \\n \\n[Benchmark] \\npubli\", \"c bool IsBypassed() => _proxy.IsBypassed(_destination); \\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAll\", \"oc Ratio \\nIsBypassed \\n.NET 6.0 \\n5,343.2 ns \\n1.00 \\n7528 B \\n1.00 \\nIsBypassed \\n.NET 7.0 \\n205.5 ns \\n0.04\", \" \\n- \\n0.00 \\nAlso related to HTTP, WebUtility\\u2019s HtmlDecode method has improved for .NET 7. The impleme\", \"ntation \\nhad been manually iterating through each character in the input looking for a '&' to be une\", \"scaped. \\nAny time you see such an open-coded loop looking for one or more specific characters, it\\u2019s \", \"a red flag \\nthat IndexOf should be strongly considered. dotnet/runtime#70700 deletes the entire sear\", \"ching \\nfunction and replaces it with IndexOf, yielding simpler and much faster code (you can see oth\", \"er \\nimprovements to use IndexOf variants in networking, such as dotnet/runtime#71137, which used \\n \\n\", \"188 \\nCHAPTER 16 | Networking \\n \\nIndexOfAny in HttpListener\\u2019s HandleAuthentication to search a header\", \" for certain kinds of \\nwhitespace): \\nprivate string _encoded = WebUtility.HtmlEncode(\\\"\\\"\\\" \\n    Lorem \", \"ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor \\nincididunt ut labore et do\", \"lore magna aliqua. \\n    Condimentum vitae sapien pellentesque habitant. Vitae auctor eu augue ut lec\", \"tus. Augue \\nlacus viverra vitae congue eu. \\n    Tempus quam pellentesque nec nam aliquam sem. Urna n\", \"ec tincidunt praesent semper \\nfeugiat nibh sed. Amet tellus cras adipiscing \\n    enim eu. Duis ultri\", \"cies lacus sed turpis tincidunt. Et sollicitudin ac orci phasellus \\negestas tellus rutrum tellus pel\", \"lentesque. \\n    \\\"\\\"\\\"); \\n \\n[Benchmark] \\npublic string HtmlDecode() => WebUtility.HtmlDecode(_encoded);\", \" \\nMethod \\nRuntime \\nMean \\nRatio \\nHtmlDecode \\n.NET 6.0 \\n245.54 ns \\n1.00 \\nHtmlDecode \\n.NET 7.0 \\n19.66 n\", \"s \\n0.08 \\nThere have been a myriad of other performance-related improvements in networking as well, s\", \"uch as \\ndotnet/runtime#67881 which removed the use of TcpClient from FtpWebRequest; \\ndotnet/runtime#\", \"68745 in WebSocket which removed a parameter from one of the core async methods \\n(and since paramete\", \"rs end up on the state machine, if the async method yields this results in fewer \\nallocated bytes); \", \"and dotnet/runtime#70866 and dotnet/runtime#70900, which replaced all remaining \\nuse of Marshal.PtrT\", \"oStructure in the core networking code with more efficient marshaling (e.g. just \\nperforming casts).\", \" While Marshal.PtrToStructure is valuable when custom marshaling directives are \\nused and the runtim\", \"e needs to be involved in the conversion, it\\u2019s also much more heavyweight than \\njust casting, which \", \"can be done when the native and managed layouts are bit-for-bit compatible. As \\nwith the u8 example \", \"earlier, this comparison is hardly fair, but that\\u2019s exactly the point: \\nprivate IntPtr _mem; \\n \\n[Glo\", \"balSetup] \\npublic void Setup() \\n{ \\n    _mem = Marshal.AllocHGlobal(8); \\n    Marshal.StructureToPtr(n\", \"ew SimpleType { Value1 = 42, Value2 = 84 }, _mem, false); \\n} \\n \\n[GlobalCleanup] \\npublic void Cleanup\", \"() => Marshal.FreeHGlobal(_mem); \\n \\npublic struct SimpleType \\n{ \\n    public int Value1; \\n    public \", \"int Value2; \\n} \\n \\n[Benchmark(Baseline = true)] \\npublic SimpleType PtrToStructure() => Marshal.PtrToS\", \"tructure<SimpleType>(_mem); \\n \\n[Benchmark] \\npublic unsafe SimpleType Cast() => *(SimpleType*)_mem; \\n\", \" \\n189 \\nCHAPTER 16 | Networking \\n \\nMethod \\nMean \\nRatio \\nPtrToStructure \\n26.6593 ns \\n1.000 \\nCast \\n0.07\", \"36 ns \\n0.003 \\nFor folks using NegotiateStream, dotnet/runtime#71280 from \\n[@filipnavara](https://git\", \"hub.com/filipnavara) will also be very welcome (this comes as part of a larger \\neffort, primarily in\", \" dotnet/runtime#71777 from [@filipnavara](https://github.com/filipnavara) and \\ndotnet/runtime#70720 \", \"from [@filipnavara](https://github.com/filipnavara), to expose the new \\nNegotiateAuthentication clas\", \"s). It removes a significant amount of allocation from a typical NTLM \\nhandshake by reusing a buffer\", \" rather than reallocating a new buffer for each of multiple phases of the \\nhandshake: \\nprivate Netwo\", \"rkStream _client, _server; \\n \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    using var listener = new So\", \"cket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp); \\n    listener.Bind(new IPEnd\", \"Point(IPAddress.Loopback, 0)); \\n    listener.Listen(1); \\n \\n    var client = new Socket(AddressFamily\", \".InterNetwork, SocketType.Stream, \\nProtocolType.Tcp); \\n    client.Connect(listener.LocalEndPoint); \\n\", \" \\n    Socket server = listener.Accept(); \\n \\n    _client = new NetworkStream(client, ownsSocket: true\", \"); \\n    _server = new NetworkStream(server, ownsSocket: true); \\n} \\n \\n[Benchmark] \\npublic async Task \", \"Handshake() \\n{ \\n    using NegotiateStream client = new NegotiateStream(_client, leaveInnerStreamOpen\", \": \\ntrue); \\n    using NegotiateStream server = new NegotiateStream(_server, leaveInnerStreamOpen: \\ntr\", \"ue); \\n    await Task.WhenAll(client.AuthenticateAsClientAsync(), \\nserver.AuthenticateAsServerAsync()\", \"); \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nHandshake \\n.NET 6.0 \\n1.905 ms \\n1.00 \\n24\", \"0.5 KB \\n1.00 \\nHandshake \\n.NET 7.0 \\n1.913 ms \\n1.00 \\n99.28 KB \\n0.41 \\n \\n190 \\nCHAPTER 17 | JSON \\n \\nCHAPT\", \"ER 17 \\nJSON \\nSystem.Text.Json was introduced in .NET Core 3.0, and has seen a significant amount of \", \"investment \\nin each release since. .NET 7 is no exception. New features in .NET 7 include support fo\", \"r customizing \\ncontracts, polymorphic serialization, support for required members, support for DateO\", \"nly / TimeOnly, \\nsupport for IAsyncEnumerable<T> and JsonDocument in source generation, and support \", \"for \\nconfiguring MaxDepth in JsonWriterOptions. However, there have also been new features specifica\", \"lly \\nfocused on performance, and other changes about improving performance of JSON handling in a \\nva\", \"riety of scenarios. \\nOne of the biggest performance pitfalls we\\u2019ve seen developers face with System.\", \"Text.Json has to do \\nwith how the library caches data. In order to achieve good serialization and de\", \"serialization \\nperformance when the source generator isn\\u2019t used, System.Text.Json uses reflection em\", \"it to \\ngenerate custom code for reading/writing members of the types being processed. Instead of the\", \"n \\nhaving to pay reflection invoke costs on every access, the library incurs a much larger one-time \", \"cost \\nper type to perform this code generation, but then all subsequent handling of these types is v\", \"ery \\nfast\\u2026 assuming the generated code is available for use. These generated handlers need to be sto\", \"red \\nsomewhere, and the location that\\u2019s used for storing them is them is JsonSerializerOptions. The \", \"\\nidea was intended to be that developers would instantiate an options instance once and pass it \\naro\", \"und to all of their serialization/deserialization calls; thus, state like these generated handlers c\", \"ould \\nbe cached on them. And that works well when developers follow the recommended model. But when \", \"\\nthey don\\u2019t, performance falls off a cliff, and hard. Instead of \\u201cjust\\u201d paying for the reflection in\", \"voke \\ncosts, each use of a new JsonSerializerOptions ends up re-generating via reflection emit those\", \" \\nhandlers, skyrocketing the cost of serialization and deserialization. A super simple benchmark mak\", \"es \\nthis obvious: \\nprivate JsonSerializerOptions _options = new JsonSerializerOptions(); \\nprivate My\", \"AmazingClass _instance = new MyAmazingClass(); \\n \\n[Benchmark(Baseline = true)] \\npublic string Implic\", \"itOptions() => JsonSerializer.Serialize(_instance); \\n \\n[Benchmark] \\npublic string WithCached() => Js\", \"onSerializer.Serialize(_instance, _options); \\n \\n[Benchmark] \\npublic string WithoutCached() => JsonSe\", \"rializer.Serialize(_instance, new \\nJsonSerializerOptions()); \\n \\npublic class MyAmazingClass \\n{ \\n    \", \"public int Value { get; set; } \\n} \\n \\n191 \\nCHAPTER 17 | JSON \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocat\", \"ed \\nAlloc Ratio \\nImplicitOptions \\n.NET 6.0 \\n170.3 ns \\n1.00 \\n200 B \\n1.00 \\nWithCached \\n.NET 6.0 \\n163.8\", \" ns \\n0.96 \\n200 B \\n1.00 \\nWithoutCached \\n.NET 6.0 \\n100,440.6 ns \\n592.48 \\n7393 B \\n36.97 \\nIn .NET 7, thi\", \"s was fixed in dotnet/runtime#64646 (and subsequently tweaked in \\ndotnet/runtime#66248) by adding a \", \"global cache of the type information separate from the options \\ninstances. A JsonSerializerOptions s\", \"till has a cache, but when new handlers are generated via \\nreflection emit, those are also cached at\", \" the global level (with appropriate removal when no longer \\nused in order to avoid unbounded leaks).\", \" \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nImplicitOptions \\n.NET 6.0 \\n170.3 ns \\n1.00 \\n2\", \"00 B \\n1.00 \\nImplicitOptions \\n.NET 7.0 \\n166.8 ns \\n0.98 \\n48 B \\n0.24 \\nWithCached \\n.NET 6.0 \\n163.8 ns \\n0\", \".96 \\n200 B \\n1.00 \\nWithCached \\n.NET 7.0 \\n168.3 ns \\n0.99 \\n48 B \\n0.24 \\nWithoutCached \\n.NET 6.0 \\n100,440\", \".6 ns \\n592.48 \\n7393 B \\n36.97 \\nWithoutCached \\n.NET 7.0 \\n590.1 ns \\n3.47 \\n337 B \\n1.69 \\nAs can be seen h\", \"ere, it\\u2019s still more expensive to create a new JsonSerializerOptions instance on \\neach call, and the\", \" recommended approach is \\u201cdon\\u2019t do that.\\u201d But if someone does do it, in this \\nexample they\\u2019re only p\", \"aying 3.6x the cost rather than 621x the cost, a huge improvement. \\ndotnet/runtime#61434 also now ex\", \"poses the JsonSerializerOptions.Default instance that\\u2019s used \\nby default if no options are explicitl\", \"y provided. \\nAnother change to JsonSerializer came in dotnet/runtime#72510, which slightly improved \", \"the \\nperformance of serialization when using the source generator. The source generator emits helper\", \"s for \\nperforming the serialization/deserialization work, and these are then invoked by JsonSerializ\", \"er via \\ndelegates (as part of abstracting away all the different implementation strategies for how t\", \"o get and \\nset members on the types being serialized and deserialized). Previously, these helpers we\", \"re being \\nemitted as static methods, which in turn meant that the delegates were being created to st\", \"atic \\nmethods. Delegates to instance methods are a bit faster to invoke than delegates to static met\", \"hods, \\nso this PR made a simple few-line change for the source generator to emit these as instance m\", \"ethods \\ninstead. \\nYet another for JsonSerializer comes in dotnet/runtime#73338, which improves alloc\", \"ation with how \\nit utilizes Utf8JsonWriter. Utf8JsonWriter is a class, and every time JsonSerializer\", \" would write \\nout JSON, it would allocate a new Utf8JsonWriter instance. In turn, Utf8JsonWriter nee\", \"ds \\nsomething to write to, and although the serializer was using an IBufferWriter implementation tha\", \"t \\npooled the underlying byte[] instances employed, the implementation of IBufferWriter itself is a \", \"\\nclass that JsonSerializer would allocate. A typical Serialize call would then end up allocating a \\n\", \"few extra objects and an extra couple of hundred bytes just for these helper data structures. To \\nad\", \"dress that, this PR takes advantage of [ThreadStatic], which can be put onto static fields to make \\n\", \"them per-thread rather than per-process. From whatever thread is performing the (synchronous) \\n \\n192\", \" \\nCHAPTER 17 | JSON \\n \\nSerialize operation, it then ensures the current thread has a Utf8JsonWriter \", \"and IBufferWriter \\ninstance it can use, and uses them; for the most part this is straightforward, bu\", \"t it needs to ensure that \\nthe serialization operation itself doesn\\u2019t try to recursively serialize, \", \"in which case these objects could \\nend up being used erroneously while already in use. It also needs\", \" to make sure that the pooled \\nIBufferWriter doesn\\u2019t hold on to any of its byte[]s while it\\u2019s not be\", \"ing used. That instance gets its \\narrays from ArrayPool<T>, and we want those arrays to be usable in\", \" the meantime by anyone else \\nmaking use of the pool, not sequestered off in this cached IBufferWrit\", \"er implementation. This \\noptimization is also only really meaningful for small object graphs being s\", \"erialized, and only applies to \\nthe synchronous operations (asynchronous operations would require a \", \"more complicated pooling \\nmechanism, since the operation isn\\u2019t tied to a specific thread, and the ov\", \"erhead of such complication \\nwould likely outweigh the modest gain this optimization provides). \\npri\", \"vate byte[] _data = new byte[] { 1, 2, 3, 4, 5 }; \\n \\n[Benchmark] \\npublic string SerializeToString() \", \"=> JsonSerializer.Serialize(_data); \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nSerialize\", \"ToString \\n.NET 6.0 \\n146.4 ns \\n1.00 \\n200 B \\n1.00 \\nSerializeToString \\n.NET 7.0 \\n137.5 ns \\n0.94 \\n48 B \\n\", \"0.24 \\nUtf8JsonWriter and Utf8JsonReader also saw several improvements directly. dotnet/runtime#69580\", \" \\nadds a few new performance-focused members, the ValueIsEscaped property (which exposes already \\ntr\", \"acked information and enables consumers to avoid the expense of re-checking) and the CopyString \\nmet\", \"hod (which provides a non-allocating mechanism to get access to a string value from the reader). \\nIt\", \" then also uses the added support internally to speed up certain operations on Utf8JsonReader. And \\n\", \"dotnet/runtime#63863, dotnet/runtime#71534, and dotnet/runtime#61746 fix how some exception \\nchecks \", \"and throws were being handled so as to not slow down the non-exceptional fast paths. \\n \\n193 \\nCHAPTER\", \" 18 | XML \\n \\nCHAPTER 18 \\nXML \\nSystem.Xml is used by a huge number of applications and services, but \", \"ever since JSON hit the scene \\nand has been all the rage, XML has taken a back seat and thus hasn\\u2019t \", \"seen a lot of investment from \\neither a functionality or performance perspective. Thankfully, System\", \".Xml gets a bit of performance \\nlove in .NET 7, in particular around reducing allocation on some com\", \"monly used code paths. \\nSometimes a performance fix is as easy as changing a single number. That\\u2019s t\", \"he case with \\ndotnet/runtime#63459 from [@chrisdcmoore](https://github.com/chrisdcmoore), which addr\", \"esses a \\nlong-standing issue with the asynchronous methods on the popular XmlReader. When XmlReader \", \"was \\noriginally written, whoever developed it chose a fairly common buffer size to be used for read \", \"\\noperations, namely 4K or 8K chars depending on various conditions. When XmlReader later gained \\nasy\", \"nchronous reading functionality, for whatever reason a much, much larger buffer size of 64K chars \\nw\", \"as selected (presumably in hopes of minimizing the number of asynchronous operations that would \\nnee\", \"d to be employed, but the actual rationale is lost to history). A key problem with such a buffer siz\", \"e, \\nbeyond it leading to a lot of allocation, is the allocation it produces typically ends up on the\", \" Large \\nObject Heap (LOH). By default, under the expectation that really large objects are long-live\", \"d, objects \\ngreater than 85K bytes are allocated into the LOH, which is treated as part of Gen 2, an\", \"d that makes \\nsuch allocation if not long-lived even more expensive in terms of overall impact on th\", \"e system. Well, \\n64K chars is 128K bytes, which puts it squarely above that threshold. This PR lower\", \"s the size from 64K \\nchars to 32K chars, putting it below the threshold (and generally reducing allo\", \"cation pressure, how \\nmuch memory needs to be zero\\u2019d, etc). While it\\u2019s still a very large allocation\", \", and in the future we \\ncould look at pooling the buffer or employing a smaller one (e.g. no differe\", \"nt from what\\u2019s done for \\nthe synchronous APIs), this simple one-number change alone makes a substant\", \"ial difference for \\nshorter input documents (while not perceivably negatively impacting larger ones)\", \". \\nprivate readonly XmlReaderSettings _settings = new XmlReaderSettings { Async = true }; \\nprivate M\", \"emoryStream _stream; \\n \\n[Params(10, 1_000_000)] \\npublic int ItemCount; \\n \\n[GlobalSetup] \\npublic void\", \" Setup() \\n{ \\n    _stream = new MemoryStream(); \\n    using XmlWriter writer = XmlWriter.Create(_strea\", \"m); \\n    writer.WriteStartElement(\\\"Items\\\"); \\n    for (var i = 0; i < ItemCount; i++) \\n    { \\n       \", \" writer.WriteStartElement($\\\"Item{i}\\\"); \\n        writer.WriteEndElement(); \\n    } \\n    writer.WriteEn\", \"dElement(); \\n \\n194 \\nCHAPTER 18 | XML \\n \\n} \\n \\n[Benchmark] \\npublic async Task XmlReader_ReadAsync() \\n{\", \" \\n    _stream.Position = 0; \\n    using XmlReader reader = XmlReader.Create(_stream, _settings); \\n   \", \" while (await reader.ReadAsync()); \\n} \\nMethod \\nRuntime \\nItemCount \\nMean \\nRatio \\nAllocated \\nAlloc \\nRa\", \"tio \\nXmlReader_ReadAsync \\n.NET 6.0 \\n10 \\n42.344 us \\n1.00 \\n195.94 KB \\n1.00 \\nXmlReader_ReadAsync \\n.NET \", \"7.0 \\n10 \\n9.992 us \\n0.23 \\n99.94 KB \\n0.51 \\n \\n \\n \\n \\n \\n \\n \\nXmlReader_ReadAsync \\n.NET 6.0 \\n1000000 \\n340,3\", \"82.953 \\nus \\n1.00 \\n101790.34 \\nKB \\n1.00 \\nXmlReader_ReadAsync \\n.NET 7.0 \\n1000000 \\n333,417.347 \\nus \\n0.98\", \" \\n101804.45 \\nKB \\n1.00 \\nXmlReader and XmlWriter saw other allocation-related improvements as well. do\", \"tnet/runtime#60076 \\nfrom [@kronic](https://github.com/kronic) improved the ReadOnlyTernaryTree inter\", \"nal type that\\u2019s \\nused when XmlOutputMethod.Html is specified in the XmlWriterSettings. This included\", \" using a \\nReadOnlySpan<byte> initialized from an RVA static instead of a large byte[] array that wou\", \"ld need to \\nbe allocated. And dotnet/runtime#60057 from [@kronic](https://github.com/kronic), which \", \"converted \\n~400 string creations in the System.Private.Xml assembly to use interpolated strings. Man\", \"y of \\nthese cases were stylistic, converting something like string1 + \\\":\\\" + string2 into \\n$\\\"{string1\", \"}:{string2}\\\"; I say stylistic here because the C# compiler will generate the exact same \\ncode for bo\", \"th of those, a call to string.Concat(string1, \\\":\\\", string2), given that there\\u2019s a \\nConcat overload t\", \"hat accepts three strings. However, some of the changes do impact allocation. For \\nexample, the priv\", \"ate XmlTextWriter.GeneratePrefix method had the code: \\nreturn \\\"d\\\" + _top.ToString(\\\"d\\\", CultureInfo.I\", \"nvariantCulture) \\n     + \\\"p\\\" + temp.ToString(\\\"d\\\", CultureInfo.InvariantCulture); \\nwhere _top and tem\", \"p are both ints. This will result in allocating two temporary strings and then \\nconcatenating those \", \"with the two constant strings. Instead, the PR changed it to: \\nreturn string.Create(CultureInfo.Inva\", \"riantCulture, $\\\"d{_top:d}p{temp:d}\\\"); \\nwhich while shorter is also more efficient, avoiding the inte\", \"rmediate string allocations, as the custom \\ninterpolated string handler used by string.Create will f\", \"ormat those into a pooled buffer rather than \\nallocating intermediate temporaries. \\nXmlSerializer is\", \" also quite popular and also gets a (small) allocation reduction, in particular for \\ndeserialization\", \". XmlSerializer has two modes for generating serialization/deserialization routines: \\nusing reflecti\", \"on emit to dynamically generate IL at run-time that are tuned to the specific shape of the \\ntypes be\", \"ing serialized/deserialized, and the XML Serializer Generator Tool (sgen), which generates a \\n.dll c\", \"ontaining the same support, just ahead-of-time (a sort-of precursor to the Roslyn source \\n \\n195 \\nCHA\", \"PTER 18 | XML \\n \\ngenerators we love today). In both cases, when deserializing, the generated code wa\", \"nts to track which \\nproperties of the object being deserialized have already been set, and to do tha\", \"t, it uses a bool[] as a \\nbit array. Every time an object is deserialized, it allocates a bool[] wit\", \"h enough elements to track \\nevery member of the type. But in common usage, the vast majority of type\", \"s being deserialized only \\nhave a relatively small number of properties, which means we can easily u\", \"se stack memory to track \\nthis information rather than heap memory. That\\u2019s what dotnet/runtime#66914\", \" does. It updates both \\nof the code generators to stackalloc into a Span<bool> for less than or equa\", \"l to 32 values, and \\notherwise fall back to the old approach of heap-allocating the bool[] (which ca\", \"n also then be stored \\ninto a Span<bool> so that the subsequent code paths simply use a span instead\", \" of an array). You can \\nsee this quite easily in the .NET Object Allocation Tracking tool in Visual \", \"Studio. For this console app \\n(which, as an aside, shows how lovely the new raw string literals feat\", \"ure in C# is for working with \\nXML): \\nusing System.Text; \\nusing System.Xml.Serialization; \\n \\nvar ser\", \"ializer = new XmlSerializer(typeof(Release[])); \\nvar stream = new MemoryStream(Encoding.UTF8.GetByte\", \"s( \\n    \\\"\\\"\\\" \\n    <?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?> \\n    <ArrayOfRelease xmlns:xsi=\\\"http://www.w\", \"3.org/2001/XMLSchema-instance\\\" \\nxmlns:xsd=\\\"http://www.w3.org/2001/XMLSchema\\\"> \\n        <Release><Maj\", \"or>1</Major><Minor>0</Minor></Release> \\n        <Release><Major>1</Major><Minor>1</Minor></Release> \", \"\\n        <Release><Major>2</Major><Minor>0</Minor></Release> \\n        <Release><Major>2</Major><Mino\", \"r>1</Minor></Release> \\n        <Release><Major>2</Major><Minor>2</Minor></Release> \\n        <Release\", \"><Major>3</Major><Minor>0</Minor></Release> \\n        <Release><Major>3</Major><Minor>1</Minor></Rele\", \"ase> \\n        <Release><Major>5</Major><Minor>0</Minor></Release> \\n        <Release><Major>6</Major>\", \"<Minor>0</Minor></Release> \\n        <Release><Major>7</Major><Minor>0</Minor></Release> \\n    </Array\", \"OfRelease> \\n    \\\"\\\"\\\")); \\n \\nfor (int i = 0; i < 1000; i++) \\n{ \\n    stream.Position = 0; \\n    serialize\", \"r.Deserialize(stream); \\n} \\n \\npublic class Release \\n{ \\n    public int Major; \\n    public int Minor; \\n\", \"    public int Build; \\n    public int Revision; \\n} \\nHere\\u2019s what I see when I run this under .NET 6: \", \"\\n \\n196 \\nCHAPTER 18 | XML \\n \\n \\nWe\\u2019re running a thousand deserializations, each of which will deserial\", \"ize 10 Release instances, and so \\nwe expect to see 10,000 Release objects being allocated, which we \", \"do\\u2026 but we also see 10,000 \\nbool[] being allocated. Now with .NET 7 (note the distinct lack of the p\", \"er-object bool[]): \\n \\nOther allocation reduction went into the creation of the serializer/deserializ\", \"er itself, such as with \\ndotnet/runtime#68738 avoiding allocating strings to escape text that didn\\u2019t\", \" actually need escaping, \\ndotnet/runtime#66915 using stack allocation for building up small text ins\", \"tead of using a \\nStringBuilder, dotnet/runtime#66797 avoiding delegate and closure allocations in ac\", \"cessing the \\ncache of serializers previously created, dotnet/runtime#67001 from \\n[@TrayanZapryanov](\", \"https://github.com/TrayanZapryanov) caching an array used with string.Split, \\nand dotnet/runtime#670\", \"02 from [@TrayanZapryanov](https://github.com/TrayanZapryanov) that \\nchanged some parsing code to av\", \"oid a string.ToCharArray invocation. \\nFor folks using XML schema, dotnet/runtime#66908 replaces some\", \" Hashtables in the implementation \\nwhere those collections were storing ints as the value. Given tha\", \"t Hashtable is a non-generic \\ncollection, every one of those ints was getting boxed, resulting in un\", \"necessary allocation overhead; \\nthese were fixed by replacing these Hashtables with Dictionary<..., \", \"int> instances. (As an aside, \\nthis is a fairly common performance-focused replacement to do, but yo\", \"u need to be careful as \\nHashtable has a few behavioral differences from Dictionary<,>; beyond the o\", \"bvious difference of \\nHashtable returning null from its indexer when a key isn\\u2019t found and Dictionar\", \"y<,> throwing in \\nthat same condition, Hashtable is thread-safe for use with not only multiple reade\", \"rs but multiple \\nreaders concurrent with a single writer, and Dictionary<,> is not.) dotnet/runtime#\", \"67045 reduces \\nallocation of XmlQualifiedName instances in the implementation of XsdBuilder.ProcessE\", \"lement and \\nXsdBuilder.ProcessAttribute. And dotnet/runtime#64868 from \\n[@TrayanZapryanov](https://g\", \"ithub.com/TrayanZapryanov) uses stack-based memory and pooling to \\n \\n197 \\nCHAPTER 18 | XML \\n \\navoid \", \"temporary string allocation in the implementation of the internal XsdDateTime and \\nXsdDuration types\", \", which are used by the public XmlConvert. \\nprivate TimeSpan _ts = TimeSpan.FromMilliseconds(12345);\", \" \\n \\n[Benchmark] \\npublic string XmlConvertToString() => XmlConvert.ToString(_ts); \\nMethod \\nRuntime \\nM\", \"ean \\nRatio \\nAllocated \\nAlloc Ratio \\nXmlConvertToString \\n.NET 6.0 \\n90.70 ns \\n1.00 \\n184 B \\n1.00 \\nXmlCo\", \"nvertToString \\n.NET 7.0 \\n59.21 ns \\n0.65 \\n40 B \\n0.22 \\nXML pops up in other areas as well, as in the X\", \"mlWriterTraceListener type. While the \\nSystem.Diagnostics.Trace type isn\\u2019t the recommended tracing m\", \"echanism for new code, it\\u2019s widely \\nused in existing applications, and XmlWriterTraceListener let\\u2019s \", \"you plug in to that mechanism to \\nwrite out XML logs for traced information. dotnet/runtime#66762 av\", \"oids a bunch of string allocation \\noccurring as part of this tracing, by formatting much of the head\", \"er information into a span and then \\nwriting that out rather than ToString()\\u2019ing each individual pie\", \"ce of data. \\n[GlobalSetup] \\npublic void Setup() \\n{ \\n    Trace.Listeners.Clear(); \\n    Trace.Listener\", \"s.Add(new XmlWriterTraceListener(Stream.Null)); \\n} \\n \\n[Benchmark] \\npublic void TraceWrite() \\n{ \\n    \", \"Trace.WriteLine(\\\"Something important\\\"); \\n} \\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAlloc Ratio \\nTra\", \"ceWrite \\n.NET 6.0 \\n961.9 ns \\n1.00 \\n288 B \\n1.00 \\nTraceWrite \\n.NET 7.0 \\n772.2 ns \\n0.80 \\n64 B \\n0.22 \\n \\n\", \"198 \\nCHAPTER 19 | Cryptography \\n \\nCHAPTER 19 \\nCryptography \\nSome fairly significant new features cam\", \"e to System.Security.Cryptography in .NET 7, including the \\nsupport necessary to enable the previous\", \"ly discussed OCSP stapling and support for building \\ncertificate revocation lists, but there was als\", \"o a fair amount of effort put into making existing support \\nfaster and more lightweight. \\nOne fairly\", \" substantial change in .NET 7 is split across dotnet/runtime#61025, dotnet/runtime#61137, \\nand dotne\", \"t/runtime#64307. These PRs don\\u2019t change any code materially, but instead consolidate all of \\nthe var\", \"ious cryptography-related assemblies in the core libraries into a single \\nSystem.Security.Cryptograp\", \"hy assembly. When .NET Core was first envisioned, a goal was to make \\nit extremely modular, and larg\", \"e swaths of code were teased apart to create many smaller assemblies. \\nFor example, cryptographic fu\", \"nctionality was split between \\nSystem.Security.Cryptography.Algorithms.dll, System.Security.Cryptogr\", \"aphy.Cng.dll, \\nSystem.Security.Cryptography.Csp.dll, System.Security.Cryptography.Encoding.dll, \\nSys\", \"tem.Security.Cryptography.OpenSsl.dll, System.Security.Cryptography.Primitives.dll, \\nand System.Secu\", \"rity.Cryptography.X509Certificates.dll. You can see this if you look in your \\nshared framework folde\", \"r for a previous release, e.g. here\\u2019s mine for .NET 6: \\n \\nThese PRs move all of that code into a sin\", \"gle System.Security.Cryptography.dll assembly. This has \\nseveral benefits. First, crypto is used in \", \"a huge number of applications, and most apps would end up \\n \\n199 \\nCHAPTER 19 | Cryptography \\n \\nrequi\", \"ring multiple (or even most) of these assemblies. Every assembly that\\u2019s loaded adds overhead. \\nSecon\", \"d, a variety of helper files had to be compiled into each assembly, leading to overall larger \\namoun\", \"t of compiled code to be distributed. And third, we weren\\u2019t able to implement everything as \\noptimal\", \" as we\\u2019d have otherwise liked due to functionality in one assembly not exposed to another \\n(and we a\", \"void using InternalsVisibleTo as it hampers maintainability and impedes other analysis \\nand optimiza\", \"tions). Now in .NET 7, the shared framework looks more like this: \\n \\nInteresting, you still see a bu\", \"nch of assemblies there, but all except for \\nSystem.Security.Cryptography.dll are tiny; that\\u2019s becau\", \"se these are simple facades. Because we \\nneed to support binaries built for .NET 6 and earlier runni\", \"ng on .NET 7, we need to be able to handle \\nbinaries that refer to types in these assemblies, but in\", \" .NET 7, those types actually live in \\nSystem.Security.Cryptography.dll. .NET provides a solution fo\", \"r this in the form of the \\n[TypeForwardedTo(...)] attribute, which enables one assembly to say \\u201chey,\", \" if you\\u2019re looking for type \\nX, it now lives over there.\\u201d And if you crack open one of these assembl\", \"ies in a tool like ILSpy, you can \\nsee they\\u2019re essentially empty except for a bunch of these attribu\", \"tes: \\n \\n200 \\nCHAPTER 19 | Cryptography \\n \\n \\nIn addition to the startup and maintenance wins this pro\", \"vides, this has also enabled further \\nsubsequent optimization. For example, there\\u2019s a lot of object \", \"cloning that goes on in the innards of \\nthis library. Various objects are used to wrap native handle\", \"s to OS cryptographic resources, and to \\nhandle lifetime semantics and ownership appropriately, ther\", \"e are many cases where a native handle is \\nduplicated and then wrapped in one or more new managed ob\", \"jects. In some cases, however, the \\noriginal resource is then destroyed because it\\u2019s no longer neede\", \"d, and the whole operation could \\nhave been made more efficient if the original resource just had it\", \"s ownership transferred to the new \\nobjects rather than being duplicated and destroyed. This kind of\", \" ownership transfer typically is hard to \\ndo between assemblies as it generally requires public API \", \"that\\u2019s not focused on such usage patterns, \\nbut with internals access, this can be overcome. dotnet/\", \"runtime#72120 does this, for example, to \\nreduce allocation of various resources inside the RSACng, \", \"DSACng, ECDsaCng, and ECDiffieHellmanCng \\npublic types. \\nIn terms of actual code improvements, there\", \" are many. One category of improvements is around \\n\\u201cone-shot\\u201d operations. With many forms of data pr\", \"ocessing, all of the data needn\\u2019t be processed in \\none operation. A block of data can be processed, \", \"then another, then another, until finally there\\u2019s no \\nmore data to be processed. In such usage, ther\", \"e\\u2019s often some kind of state carried over from the \\nprocessing of one block to the processing of the\", \" next, and then the processing of the last block is \\nspecial as it needn\\u2019t carry over anything and i\", \"nstead needs to perform whatever work is required to \\nend the whole operation, e.g. outputting any f\", \"inal footer or checksum that might be required as part \\nof the format. Thus, APIs that are able to h\", \"andle arbitrary number of blocks of data are often a bit \\nmore expensive in one way, shape, or form \", \"than APIs that only support a single input; this latter \\ncategory is known as \\u201cone shot\\u201d operations,\", \" because they do everything in \\u201cone shot.\\u201d In some cases, \\none-shot operations can be significantly \", \"cheaper, and in other cases they merely avoid some \\nallocations that would have been necessary to tr\", \"ansfer state from the processing of one block of data \\nto the next. dotnet/runtime#58270 from [@vcsj\", \"ones](https://github.com/vcsjones) and \\ndotnet/runtime#65725 from [@vcsjones](https://github.com/vcs\", \"jones) both improved the \\nperformance of various one-shot operations on \\u201csymmetric\\u201d cryptograhic alg\", \"orithms (algorithms that \\nuse the same key information to both encrypt and decrypt), like AES. The f\", \"ormer does so by \\nrefactoring the implementations to avoid some reset work that\\u2019s not necessary in t\", \"he case of one-\\nshots because the relevant state is about to go away, anyway, and that in turns also\", \" allows the \\nimplementation to store less of certain kinds of state. The latter does so for decrypti\", \"on one-shots by \\ndecrypting directly into the destination buffer whenever possible, using stack spac\", \"e if possible when \\ngoing directly into the user\\u2019s buffer isn\\u2019t feasible, etc. \\n \\n201 \\nCHAPTER 19 | \", \"Cryptography \\n \\nprivate byte[] _plaintext = Encoding.UTF8.GetBytes(\\\"This is a test. This is only a t\", \"est. \\nNothing to see here.\\\"); \\nprivate byte[] _iv = Enumerable.Range(0, 16).Select(i => (byte)i).ToA\", \"rray(); \\nprivate Aes _aes = Aes.Create(); \\nprivate byte[] _output = new byte[1000]; \\n \\n[Benchmark] \\n\", \"public bool OneShot() => _aes.TryEncryptCfb(_plaintext, _iv, _output, out _); \\nMethod \\nRuntime \\nMean\", \" \\nRatio \\nAllocated \\nAlloc Ratio \\nOneShot \\n.NET 6.0 \\n1.828 us \\n1.00 \\n336 B \\n1.00 \\nOneShot \\n.NET 7.0 \\n\", \"1.770 us \\n0.97 \\n184 B \\n0.55 \\nIn addition to making one-shots lighterweight, other PRs have then used\", \" these one-shot operations in \\nmore places in order to simplify their code and benefit from the incr\", \"eased performance, e.g. \\ndotnet/runtime#70639 from [@vcsjones](https://github.com/vcsjones), dotnet/\", \"runtime#70857 from \\n[@vcsjones](https://github.com/vcsjones), dotnet/runtime#64005 from \\n[@vcsjones]\", \"(https://github.com/vcsjones), and dotnet/runtime#64174 from \\n[@vcsjones](https://github.com/vcsjone\", \"s). \\nThere\\u2019s also a large number of PRs that have focused on removing allocations from around the cr\", \"ypto \\nstack: \\n\\u2022 \\nStack allocation. As has been seen in many other PRs referenced throughout this pos\", \"t, using \\nstackalloc is a very effective way to get rid of array allocations in many situations. It\\u2019\", \"s used \\neffectively in multiple crypto PRs to avoid either temporary or pooled array allocations, su\", \"ch as \\nin dotnet/runtime#64584 from [@vcsjones](https://github.com/vcsjones), dotnet/runtime#69831 \\n\", \"from [@vcsjones](https://github.com/vcsjones), dotnet/runtime#70173 from \\n[@vcsjones](https://github\", \".com/vcsjones), dotnet/runtime#69812 from \\n[@vcsjones](https://github.com/vcsjones), and dotnet/runt\", \"ime#69448 from \\n[@vcsjones](https://github.com/vcsjones). Sometimes this is used when calling an API\", \" that has \\nmultiple overloads, including one taking an array and one taking a span. Othertimes it\\u2019s \", \"used \\nwith P/Invokes that often just pass out a small amount of data. Sometimes it\\u2019s used to avoid \\n\", \"temporary array allocations, and sometimes it\\u2019s used in places where pooling was used \\npreviously, b\", \"ut the data is often small enough to avoid even the overheads of pooling. \\n\\u2022 \\nAvoiding double copies\", \". Most of the crypto APIs that accept byte[]s and store them end up \\nmaking defensive copies of thos\", \"e arrays rather than storing the original. This is fairly common \\nthroughout .NET, but it\\u2019s especial\", \"ly common in the crypto stack, where the ability to trust the \\ndata is as you expect it (and validat\", \"e it) is paramount. In some cases, though, code ends up \\nallocating a temporary byte[] just to pass \", \"data into one of these APIs that copies and re-\\nallocates, anyway. dotnet/runtime#71102 from [@vcsjo\", \"nes](https://github.com/vcsjones), \\ndotnet/runtime#69024 from [@vcsjones](https://github.com/vcsjone\", \"s), dotnet/runtime#71015 \\nfrom [@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69534 fr\", \"om \\n[@vcsjones](https://github.com/vcsjones) deal with that duplication in some cases by extracting \", \"\\na span to the original data instead of creating a temporary byte[]; when that span is passed into \\n\", \"the target API, the target API still makes a copy, but we\\u2019ve avoided the first one and thus cut the \", \"\\narray allocation for these operations effectively in half. dotnet/runtime#71888 from \\n[@vcsjones](h\", \"ttps://github.com/vcsjones) is a variation on this theme, improving the internals of \\n \\n202 \\nCHAPTER\", \" 19 | Cryptography \\n \\nRfc2898DeriveBytes to supports spans such that its constructors that accept sp\", \"ans can then do \\nthe more efficient thing. \\n\\u2022 \\nReplacing O(1) data structures. O(1) lookup data stru\", \"ctures like Dictionary<,> and \\nHashSet<> are the lifeblood of most applications and services, but so\", \"metimes algorithmic \\ncomplexity is misleading. Yes, these provide very efficient searching, but ther\", \"e\\u2019s still overhead \\nassociated with computing a hash code, mapping that hash code to a location in t\", \"he data \\nstructure, and so on. If there\\u2019s only ever a handful of items (i.e. the N in the complexity\", \" is really, \\nreally small), it can be much faster to just do a linear search, and if N is sufficient\", \"ly small, a data \\nstructure may not even be needed at all: the search can just be open-coded as a wa\", \"terfall of \\nif/elseif/else constructs. That\\u2019s the case in a PR like dotnet/runtime#71341 from \\n[@vcs\", \"jones](https://github.com/vcsjones), where the 99.999% case involves just five strings \\n(names of ha\", \"sh algorithms); it\\u2019s cheaper to just compare against each than it is do a \\nHashSet<>.Contains, espec\", \"ially since the JIT now unrolls and vectorizes the comparison against \\nthe constant string names. \\n\\u2022\", \" \\nSimply avoiding unnecessary work. The best optimizations are ones where you simply stop \\ndoing wor\", \"k you don\\u2019t have to do. dotnet/runtime#68553 from \\n[@vcsjones](https://github.com/vcsjones) is a goo\", \"d example of this. This code was performing a \\nhash of some data in order to determine the length of\", \" resulting hashes for that particular \\nconfiguration, but we actually know ahead of time exactly how\", \" long a hash for a given algorithm \\nis going to be, and we already have in this code a cascading if/\", \"elseif/else that\\u2019s checking for each \\nknown algorithm, so we can instead just hardcode the length fo\", \"r each. dotnet/runtime#70589 \\nfrom [@vcsjones](https://github.com/vcsjones) is another good example,\", \" in the same spirit of \\nthe ownership transfer example mentioned earlier (but this one didn\\u2019t previo\", \"usly span assembly \\nboundaries). Rather than in several places taking an X509Extension, serializing \", \"it to a byte[], \\nand passing that temporary byte[] to something else that in turn makes a defensive \", \"copy, we \\ncan instead provide an internal pathway for ownership transfer, bypassing all of the middl\", \"e \\nstages. Another good one is dotnet/runtime#70618 from \\n[@vcsjones](https://github.com/vcsjones), \", \"as it\\u2019s an example of how it pays to really understand \\nyour dependencies. The implementation of sym\", \"metric encryption on macOS uses the \\nCommonCrypto library. One of the functions it exposes is CCCryp\", \"torFinal, which is used at the \\nend of the encryption/decryption process. However, there are several\", \" cases called out in the \\ndocs where it\\u2019s unnecessary (\\u201csuperfluous,\\u201d according to the docs), and so\", \" our dutifully calling it \\neven in those situations is wasteful. The fix? Stop doing unnecessary wor\", \"k. \\n\\u2022 \\nNew APIs. A bunch of new APIs were introduced for cryptography in .NET 7. Most are focused \\no\", \"n easing scenarios that were difficult to do correctly before, like dotnet/runtime#66509 from \\n[@vcs\", \"jones](https://github.com/vcsjones) that provides an X500DistinguishedNameBuilder. But \\nsome are foc\", \"used squarely on performance. dotnet/runtime#57835 from \\n[@vcsjones](https://github.com/vcsjones), f\", \"or example, exposes a new RawDataMemory property \\non X509Certificate2. Whereas the existing RawData \", \"property returns a new byte[] on every \\ncall (again a defensive copy to avoid having to deal with th\", \"e possiblity that the consumer \\nmucked with the raw data), this new RawDataMemory returns a ReadOnly\", \"Memory<byte> around \\nthe internal byte[]. Since the only way to access and mutate that underlying by\", \"te[] via a \\nReadOnlyMemory<byte> is via unsafe interop code (namely via the \\nSystem.Runtime.InteropS\", \"ervices.MemoryMarshal type), it doesn\\u2019t create a defensive copy and \\nenables accessing this data fre\", \"ely without additional allocation. \\n \\n203 \\nCHAPTER 20 | Diagnostics \\n \\nCHAPTER 20 \\nDiagnostics \\nLet\\u2019\", \"s turn our attention to System.Diagnostics, which encompasses types ranging from process \\nmanagement\", \" to tracing. \\nThe Process class is used for a variety of purposes, including querying information ab\", \"out running \\nprocesses, interacting with other processes (e.g. being notified of their exiting), and\", \" launching \\nprocesses. The performance of querying for information in particular had some notable im\", \"provements \\nin .NET 7. Process provides several APIs for querying for process information, one of th\", \"e most \\ncommon being Process.GetProcessesByName: apps that know the name of the process they\\u2019re \\nint\", \"erested in can pass that to GetProcessesByName and get back a Process[] containing a Process \\nfor ea\", \"ch. It turns out that previous releases of .NET were loading the full information (e.g. all of its \\n\", \"threads) about every Process on the machine in order to filter down to just those with the target \\nn\", \"ame. dotnet/runtime#68705 fixes that by only loading the name for a process rather than all of the \\n\", \"information for it. While this helps a bit with throughput, it helps a ton with allocation: \\n[Benchm\", \"ark] \\npublic void GetProcessesByName() \\n{ \\n    foreach (Process p in Process.GetProcessesByName(\\\"dot\", \"net.exe\\\")) \\n        p.Dispose(); \\n} \\nMethod \\nRuntime \\nMean \\nRatio Allocated \\nAlloc Ratio \\nGetProcess\", \"esByName \\n.NET 6.0 \\n2.287 ms \\n1.00 \\n447.86 KB \\n1.000 \\nGetProcessesByName \\n.NET 7.0 \\n2.086 ms \\n0.90 \\n\", \"2.14 KB \\n0.005 \\nAccessing various pieces of information from a Process has also improved. If you loa\", \"d a Process \\nobject via the Process.GetProcesses or Process.GetProcessesByName methods, by design th\", \"ey load \\nall information about the Process being retrieved; internally their state will be populated\", \" such that \\nsubsequent accesses to members of the Process instance will be very fast. But, if you ac\", \"cess a \\nProcess via Process.GetProcessById or Process.GetCurrentProcess (which is effectively \\nGetPr\", \"ocessById for the current process\\u2019 id), no information other than the process\\u2019 ID is \\nprepopulated, \", \"and the state for the Process instance is queried on-demand. In most cases, accessing \\na single memb\", \"er of one of those lazy-loaded Process instances triggers loading all of the data for it, \\nas the in\", \"formation is all available as part of the same native operation, e.g. on Windows using \\nNtQuerySyste\", \"mInformation and on Linux reading from /proc/pid/stat and /proc/pid/status. But \\nin some cases we ca\", \"n be more fine-grained about it, using APIs that serve up a subset of the data \\nmuch more quickly. d\", \"otnet/runtime#59672 from [@SteveDunn](https://github.com/SteveDunn) \\nprovides one such optimization,\", \" using the QueryFullProcessImageName on Windows to read the \\nprocess name in response to Process.Pro\", \"cessName being used. If all you care about reading is the \\n \\n204 \\nCHAPTER 20 | Diagnostics \\n \\nproces\", \"s\\u2019 name, it\\u2019s a huge boost in throughput, and even if you subsequently go on to read additional \\nsta\", \"te from the Process and force it to load everything else, accessing the process name is so fast that\", \" \\nit doesn\\u2019t add meaningful overhead to the all-up operation. This is visible in this benchmark: \\n[B\", \"enchmark] \\npublic string GetCurrentProcessName() \\n{ \\n    using Process current = Process.GetCurrentP\", \"rocess(); \\n    return current.ProcessName; \\n} \\n \\n[Benchmark] \\npublic string GetCurrentProcessNameAnd\", \"WorkingSet() \\n{ \\n    using Process current = Process.GetCurrentProcess(); \\n    return $\\\"{current.Pro\", \"cessName} {current.WorkingSet64}\\\"; \\n} \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nGetCurr\", \"entProcessName \\n.NET 6.0 \\n3,070.54 us \\n1.00 \\n3954 B \\n1.00 \\nGetCurrentProcessName \\n.NET 7.0 \\n32.30 us\", \" \\n0.01 \\n456 B \\n0.12 \\n \\n \\n \\n \\n \\n \\nGetCurrentProcessNameAndWorkingSet \\n.NET 6.0 \\n3,055.70 us \\n1.00 \\n40\", \"10 B \\n1.00 \\nGetCurrentProcessNameAndWorkingSet \\n.NET 7.0 \\n3,149.92 us \\n1.03 \\n4186 B \\n1.04 \\nInteresti\", \"ngly, this PR had a small deficiency we didn\\u2019t initially catch, which is that the \\nQueryFullProcessI\", \"mageName API we switched to didn\\u2019t work in the case of elevated/privileged \\nprocesses. To accomodate\", \" those, dotnet/runtime#70073 from \\n[@schuettecarsten](https://github.com/schuettecarsten) updated th\", \"e code to keep both the new and \\nold implementations, starting with the new one and then only fallin\", \"g back to the old if operating on \\nan incompatible process. \\nSeveral additional PRs helped out the P\", \"rocess class. When launching processes with Process.Start \\non Unix, the implementation was using Enc\", \"oding.UTF8.GetBytes as part of argument handling, \\nresulting in a temporary array being allocated pe\", \"r argument; dotnet/runtime#71279 removes that \\nper-argument allocation, instead using Encoding.UTF8.\", \"GetByteCount to determine how large a \\nspace is needed and then using the Encoding.UTF8.GetBytes ove\", \"rload that accepts a span to encode \\ndirectly into the native memory already being allocated. dotnet\", \"/runtime#71136 simplifies and \\nstreamlines the code involved in getting the \\u201cshort name\\u201d of a proces\", \"s on Windows for use in \\ncomparing process names. And dotnet/runtime#45690 replaces a custom cache w\", \"ith use of \\nArrayPool in the Windows implementation of getting all process information, enabling eff\", \"ective reuse \\nof the array that ends up being used rather than having it sequestered off in the Proc\", \"ess \\nimplementation forever. \\nAnother area of performance investment has been in DiagnosticSource, a\", \"nd in particular around \\nenumerating through data from Activity instances. This work translates into\", \" faster integration and \\ninteroperability via OpenTelemetry, in order to be able to export data from\", \" .NET Activity information \\nfaster. dotnet/runtime#67012 from [@CodeBlanch](https://github.com/CodeB\", \"lanch), for example, \\nimproved the performance of the internal DiagLinkedList<T>.DiagEnumerator type\", \" that\\u2019s the \\n \\n205 \\nCHAPTER 20 | Diagnostics \\n \\nenumerator returned when enumerating Activity.Links \", \"and Activity.Events by avoiding a copy \\nof each T value: \\nprivate readonly Activity _activity; \\n \\npu\", \"blic Program() \\n{ \\n    using ActivitySource activitySource = new ActivitySource(\\\"Perf7Source\\\"); \\n   \", \" ActivitySource.AddActivityListener(new ActivityListener \\n    { \\n        ShouldListenTo = s => s == \", \"activitySource, \\n        Sample = (ref ActivityCreationOptions<ActivityContext> o) => \\nActivitySampl\", \"ingResult.AllDataAndRecorded \\n    }); \\n \\n    _activity = activitySource.StartActivity( \\n        \\\"Tes\", \"tActivity\\\", \\n        ActivityKind.Internal, \\n        parentContext: default, \\n        links: Enumera\", \"ble.Range(0, 1024).Select(_ => new ActivityLink(default)).ToArray()); \\n    _activity.Stop(); \\n} \\n \\n[\", \"Benchmark(Baseline = true)] \\npublic ActivityLink EnumerateActivityLinks() \\n{ \\n    ActivityLink last \", \"= default; \\n    foreach (ActivityLink link in _activity.Links) last = link; \\n    return last; \\n} \\nMe\", \"thod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nEnumerateActivityLinks \\n.NET 6.0 \\n19.62 us \\n1.00\", \" \\n64 B \\n1.00 \\nEnumerateActivityLinks \\n.NET 7.0 \\n13.72 us \\n0.70 \\n32 B \\n0.50 \\nThen dotnet/runtime#6792\", \"0 from [@CodeBlanch](https://github.com/CodeBlanch) and \\ndotnet/runtime#68933 from [@CodeBlanch](htt\", \"ps://github.com/CodeBlanch) added new \\nEnumerateTagObjects, EnumerateEvents, and EnumerateLinks enum\", \"eration methods that return a \\nstruct-based enumerator that has a ref T-returning Current to avoid y\", \"et another layer of copy. \\nprivate readonly Activity _activity; \\n \\npublic Program() \\n{ \\n    using Ac\", \"tivitySource activitySource = new ActivitySource(\\\"Perf7Source\\\"); \\n    ActivitySource.AddActivityList\", \"ener(new ActivityListener \\n    { \\n        ShouldListenTo = s => s == activitySource, \\n        Sample\", \" = (ref ActivityCreationOptions<ActivityContext> o) => \\nActivitySamplingResult.AllDataAndRecorded \\n \", \"   }); \\n \\n    _activity = activitySource.StartActivity( \\n        \\\"TestActivity\\\", \\n        ActivityKi\", \"nd.Internal, \\n        parentContext: default, \\n        links: Enumerable.Range(0, 1024).Select(_ => \", \"new ActivityLink(default)).ToArray()); \\n \\n206 \\nCHAPTER 20 | Diagnostics \\n \\n    _activity.Stop(); \\n} \", \"\\n \\n[Benchmark(Baseline = true)] \\npublic ActivityLink EnumerateActivityLinks_Old() \\n{ \\n    ActivityLi\", \"nk last = default; \\n    foreach (ActivityLink link in _activity.Links) last = link; \\n    return last\", \"; \\n} \\n \\n[Benchmark] \\npublic ActivityLink EnumerateActivityLinks_New() \\n{ \\n    ActivityLink last = de\", \"fault; \\n    foreach (ActivityLink link in _activity.EnumerateLinks()) last = link; \\n    return last;\", \" \\n} \\nMethod \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nEnumerateActivityLinks_Old \\n13.655 us \\n1.00 \\n32 B \", \"\\n1.00 \\nEnumerateActivityLinks_New \\n2.380 us \\n0.17 \\n- \\n0.00 \\nOf course, when it comes to diagnostics,\", \" anyone who\\u2019s ever done anything with regards to timing and \\nmeasurements is likely familiar with go\", \"od ol\\u2019 Stopwatch. Stopwatch is a simple type that\\u2019s very handy \\nfor getting precise measurements and\", \" is thus used all over the place. But for folks that are really cost-\\nsensitive, the fact that Stopw\", \"atch is a class can be prohibitive, e.g. writing: \\nStopwatch sw = Stopwatch.StartNew(); \\n...; \\nTimeS\", \"pan elapsed = sw.Elapsed; \\nis easy, but allocates a new object just to measure. To address this, Sto\", \"pwatch has for years exposed \\nthe static GetTimestamp() method which avoids that allocation, but con\", \"suming and translating the \\nresulting long value is complicated, requiring a formula involving using\", \" Stopwatch.Frequency and \\nTimeSpan.TicksPerSecond in the right incantation. To make this pattern eas\", \"y, dotnet/runtime#66372 \\nadds a static GetElapsedTime method that handles that conversion, such that\", \" someone who wants \\nthat last mile of performance can write: \\nlong timestamp = Stopwatch.GetTimestam\", \"p(); \\n... \\nTimeSpan elapsed = Stopwatch.GetElapsedTime(timestamp); \\nwhich avoids the allocation and \", \"saves a few cycles: \\n[Benchmark(Baseline = true)] \\npublic TimeSpan Old() \\n{ \\n    Stopwatch sw = Stop\", \"watch.StartNew(); \\n    return sw.Elapsed; \\n} \\n \\n[Benchmark] \\npublic TimeSpan New() \\n{ \\n \\n207 \\nCHAPTE\", \"R 20 | Diagnostics \\n \\n    long timestamp = Stopwatch.GetTimestamp(); \\n    return Stopwatch.GetElapse\", \"dTime(timestamp); \\n} \\nMethod \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nOld \\n32.90 ns \\n1.00 \\n40 B \\n1.00 \\n\", \"New \\n26.30 ns \\n0.80 \\n- \\n0.00 \\n \\n208 \\nCHAPTER 21 | Exceptions \\n \\nCHAPTER 21 \\nExceptions \\nIt might be \", \"odd to see the subject of \\u201cexceptions\\u201d in a post on performance improvements. After all, \\nexceptions\", \" are by their very nature meant to be \\u201cexceptional\\u201d (in the \\u201crare\\u201d sense), and thus wouldn\\u2019t \\ntypica\", \"lly contribute to fast-path performance. Which is a good thing, because fast-paths that throw \\nexcep\", \"tions in the common case are no longer fast: throwing exceptions is quite expensive. \\nInstead, one o\", \"f the things we do concern ourselves with is how to minimize the impact of checking for \\nexceptional\", \" conditions: the actual exception throwing may be unexpected and slow, but it\\u2019s super \\ncommon to nee\", \"d to check for those unexpected conditions, and that checking should be very fast. We \\nalso want suc\", \"h checking to minimally impact binary size, especially if we\\u2019re going to have many such \\nchecks all \", \"over the place, in generic code for which we end up with many copies due to generic \\nspecialization,\", \" in functions that might be inlined, and so on. Further, we don\\u2019t want such checks to \\nimpede other \", \"optimizations; for example, if I have a small function that wants to do some argument \\nvalidation an\", \"d would otherwise be inlineable, I likely don\\u2019t want the presence of exception throwing to \\ninvalida\", \"te the possibility of inlining. \\nBecause of all of that, high-performance libraries often come up wi\", \"th custom \\u201cthrow helpers\\u201d they use \\nto achieve their goals. There are a variety of patterns for this\", \". Sometimes a library will just define its \\nown static method that handles constructing and throwing\", \" an exception, and then call sites do the \\ncondition check and delegate to the method if throwing is\", \" needed: \\nif (arg is null) \\n    ThrowArgumentNullException(nameof(arg)); \\n... \\n[DoesNotReturn] \\npriv\", \"ate static void ThrowArgumentNullException(string arg) => \\n    throw new ArgumentNullException(arg);\", \" \\nThis keeps the IL associated with the throwing out of the calling function, minimizing the impact \", \"of \\nthe throw. That\\u2019s particularly valuable when additional work is needed to construct the exceptio\", \"n, e.g. \\nprivate static void ThrowArgumentNullException(string arg) => \\n    throw new ArgumentNullEx\", \"ception(arg, SR.SomeResourceMessage); \\nOther times, libraries will encapsulate both the checking and\", \" throwing. This is exactly what the \\nArgumentNullException.ThrowIfNull method that was added in .NET\", \" 6 does: \\npublic static void ThrowIfNull([NotNull] object? argument, \\n[CallerArgumentExpression(\\\"arg\", \"ument\\\")] string? paramName = null) \\n{ \\n    if (argument is null) \\n        Throw(paramName); \\n} \\n \\n \\n\", \"209 \\nCHAPTER 21 | Exceptions \\n \\n[DoesNotReturn] \\ninternal static void Throw(string? paramName) => th\", \"row new \\nArgumentNullException(paramName); \\nWith that, callers benefit from the concise call site: \\n\", \"public void M(string arg) \\n{ \\n    ArgumentNullException.ThrowIfNull(arg); \\n    ... \\n} \\nthe IL remain\", \"s concise, and the assembly generated for the JIT will include the streamlined condition \\ncheck from\", \" the inlined ThrowIfNull but won\\u2019t inline the Throw helper, resulting in effectively the same \\ncode \", \"as if you\\u2019d written the previously shown manual version with ThrowArgumentNullException \\nyourself. N\", \"ice. \\nWhenever we introduce new public APIs in .NET, I\\u2019m particularly keen on seeing them used as wi\", \"dely \\nas possible. Doing so serves multiple purposes, including helping to validate that the new API\", \" is \\nusable and fully addresses the intended scenarios, and including the rest of the codebase benef\", \"iting \\nfrom whatever that API is meant to provide, whether it be a performance improvement or just a\", \" \\nreduction in routinely written code. In the case of ArgumentNullException.ThrowIfNull, however, I \", \"\\npurposefully put on the brakes. We used it in .NET 6 in several dozen call sites, but primarily jus\", \"t in \\nplace of custom ThrowIfNull-like helpers that had sprung up in various libraries around the ru\", \"ntime, \\neffectively deduplicating them. What we didn\\u2019t do, however, was replace the literally thousa\", \"nds of null \\nchecks we have with calls to ArgumentNullException.ThrowIfNull. Why? Because the new !!\", \" C# \\nfeature was right around the corner, destined for C# 11. \\nFor those unaware, the !! feature ena\", \"bled putting !! onto parameter names in member signatures, \\ne.g. \\npublic void Process(string name!!)\", \" \\n{ \\n    ... \\n} \\nThe C# compiler then compiled that as equivalent to: \\npublic void Process(string na\", \"me) \\n{ \\n    ArgumentNullException.ThrowIfNull(name); \\n} \\n(albeit using its own ThrowIfNull helper in\", \"jected as internal into the assembly). Armed with the new \\nfeature, dotnet/runtime#64720 and dotnet/\", \"runtime#65108 rolled out use of !! across \\ndotnet/runtime, replacing ~25,000 lines of code with ~500\", \"0 lines that used !!. But, what\\u2019s the line \\nfrom Kung Fu Panda, \\u201cOne often meets his destiny on the \", \"road he takes to avoid it\\u201d? The presence of \\nthat initial PR kicked off an unprecedented debate abou\", \"t the !! feature, with many folks liking the \\nconcept but a myriad of different opinions about exact\", \"ly how it should be exposed, and in the end, \\nthe only common ground was to cut the feature. In resp\", \"onse, dotnet/runtime#68178 undid all usage \\nof !!, replacing most of it with ArgumentNullException.T\", \"hrowIfNull. There are now ~5000 uses of \\nArgumentNullException.ThrowIfNull across dotnet/runtime, ma\", \"king it one of our most popular \\n \\n210 \\nCHAPTER 21 | Exceptions \\n \\nAPIs internally. Interestingly, w\", \"hile we expected a peanut-buttery effect of slight perf improvements in \\nmany places, our performanc\", \"e auto-analysis system flagged several performance improvements (e.g. \\ndotnet/perf-autofiling-issues\", \"#3531) as stemming from these changes, in particular because it enabled \\nthe JIT\\u2019s inlining heuristi\", \"cs to flag more methods for inlining. \\nWith the success of ArgumentNullException.ThrowIfNull and alo\", \"ng with its significant roll-out in \\n.NET 7, .NET 7 also sees the introduction of several more such \", \"throw helpers. dotnet/runtime#61633, \\nfor example, adds an overload of ArgumentNullException.ThrowIf\", \"Null that works with pointers. \\ndotnet/runtime#64357 adds the new ArgumentException.ThrowIfNullOrEmp\", \"ty helper as well as \\nusing it in several hundred places. And dotnet/runtime#58684 from \\n[@Bibletoon\", \"](https://github.com/Bibletoon) adds the new ObjectDisposedException.ThrowIf helper \\n(tweaked by dot\", \"net/runtime#71544 to help ensure it\\u2019s inlineable), which is then used at over a \\nhundred additional \", \"call sites by dotnet/runtime#71546. \\n \\n211 \\nCHAPTER 22 | Registry \\n \\nCHAPTER 22 \\nRegistry \\nOn Window\", \"s, the Registry is a database provided by the OS for applications and the system itself to \\nload and\", \" store configuration settings. Practically every application accesses the registry. I just tried a \\n\", \"simple console app: \\nConsole.WriteLine(\\\"Hello, world\\\"); \\nbuilt it as release, and then ran the resul\", \"ting .exe. That execution alone triggered 64 RegQueryValue \\noperations (as visible via SysInternals\\u2019\", \" Process Monitor tool). The core .NET libraries even access the \\nregistry for a variety of purposes,\", \" such as for gathering data for TimeZoneInfo, gathering data for \\nvarious calendars like HijriCalend\", \"ar and JapaneseCalendar, or for serving up environment variables \\nas part of Environment.GetEnvironm\", \"entVariable(EnvironmentVariableTarget) with \\nEnvironmentVariableTarget.User or EnvironmentVariableTa\", \"rget.Machine. \\nIt\\u2019s thus beneficial to streamline access to registry data on Windows, in particular \", \"for reducing \\noverheads in startup paths where the registry is frequently accessed. dotnet/runtime#6\", \"6918 does just \\nthat. Previously, calling RegistryKey.GetValue would make a call to RegQueryValueEx \", \"with a null \\nbuffer; this tells the RegQueryValueEx method that the caller wants to know how big a b\", \"uffer is \\nrequired in order to store the value for the key. The implementation would then allocate a\", \" buffer of \\nthe appropriate size and call RegQueryValueEx again, and for values that are to be retur\", \"ned as strings, \\nwould then allocate a string based on the data in that buffer. This PR instead reco\", \"gnizes that the vast \\nmajority of data returned from calls to the registry is relatively small. It s\", \"tarts with a stackalloc\\u2019d \\nbuffer of 512 bytes, and uses that buffer as part of the initial call to \", \"RegQueryValueEx. If the buffer \\nwas sufficiently large, we no longer have to make a second system ca\", \"ll to retrieve the actual data: we \\nalready got it. If the buffer was too small, we rent an ArrayPoo\", \"l buffer of sufficient size and use that \\npooled buffer for the subsequent RegQueryValueEx call. Exc\", \"ept in situations where we actually need \\nto return a byte[] array to the caller (e.g. the type of t\", \"he key is REG_BINARY), this avoids the need for \\nthe allocated byte[]. And for keys that return stri\", \"ngs (e.g. the type of the key is REG_SZ), previously \\nthe old implementation would have allocated a \", \"temporary char[] to use as the buffer passed to \\nRegQueryValueEx, but we can instead just reinterpre\", \"t cast (e.g. MemoryMarshal.Cast) the original \\nbuffer (whether a stackalloc\\u2019d span or the rented buf\", \"fer as a Span<char>), and use that to construct \\nthe resulting string. \\nprivate static readonly Regi\", \"stryKey s_netFramework = \\nRegistry.LocalMachine.OpenSubKey(@\\\"SOFTWARE\\\\Microsoft\\\\.NETFramework\\\"); \\n \\n\", \"[Benchmark] public string RegSz() => (string)s_netFramework.GetValue(\\\"InstallRoot\\\"); \\n \\n \\n \\n212 \\nCHA\", \"PTER 22 | Registry \\n \\nMethod \\nRuntime \\nMean \\nRatio \\nAllocated \\nAlloc Ratio \\nRegSz \\n.NET 6.0 \\n6.266 u\", \"s \\n1.00 \\n200 B \\n1.00 \\nRegSz \\n.NET 7.0 \\n3.182 us \\n0.51 \\n96 B \\n0.48 \\n \\n213 \\nCHAPTER 23 | Analyzers \\n \\n\", \"CHAPTER 23 \\nAnalyzers \\nThe ability to easily plug custom code, whether for analyzers or source gener\", \"ators, into the Roslyn \\ncompiler is one of my favorite features in all of C#. It means the developer\", \"s working on C# don\\u2019t need \\nto be solely responsible for highlighting every possible thing you might\", \" want to diagnose in your \\ncode. Instead, library authors can write their own analyzers, ship them e\", \"ither in dedicated nuget \\npackages or as side-by-side in nuget packages with APIs, and those analyze\", \"rs augment the compiler\\u2019s \\nown analysis to help developers write better code. We ship a large number\", \" of analyzer rules in the \\n.NET SDK, many of which are focused on performance, and we augment that s\", \"et with more and more \\nanalyzers every release. We also work to apply more and more of those rules a\", \"gainst our own \\ncodebases in every release. .NET 7 is no exception. \\nOne of my favorite new analyzer\", \"s was added in dotnet/roslyn-analyzers#5594 from \\n[@NewellClark](https://github.com/NewellClark) (an\", \"d tweaked in dotnet/roslyn-analyzers#5972). In \\nmy .NET 6 performance post, I talked about some of t\", \"he overheads possible when types aren\\u2019t sealed: \\n\\u2022 \\nVirtual calls are more expensive than regular no\", \"n-virtual invocation and generally can\\u2019t be \\ninlined, since the JIT doesn\\u2019t know what is the actual \", \"type of the instance and thus the actual \\ntarget of the invocation (at least not without assistance \", \"from PGO). But if the JIT can see that a \\nvirtual method is being invoked on a sealed type, it can d\", \"evirtualize the call and potentially even \\ninline it. \\n\\u2022 \\nIf a type check (e.g. something is typeof(\", \"SomeType)) is performed where SomeType is sealed, \\nthat check can be implemented along the lines of \", \"something is not null && \\nsomething.GetType() == typeof(SomeType). In contrast, if SomeType is not s\", \"ealed, the check is \\ngoing to be more along the lines of CastHelpers.IsInstanceOfClass(typeof(SomeTy\", \"pe), \\nsomething), where IsInstanceOfClass is a non-trivial (and today non-inlined) call into a JIT \\n\", \"helper method in Corelib that not only checks for null and for direct equality with the specified \\nt\", \"ype, but also linearly walks the parent hierarchy of the type of the object being tested to see if i\", \"t \\nmight derive from the specified type. \\n\\u2022 \\nArrays in .NET are covariant, which means if types B an\", \"d C both derive from type A, you can have \\na variable typed as A[] that\\u2019s storing a B[]. Since C der\", \"ives from A, it\\u2019s valid to treat a C as an A, \\nbut if the A[] is actually a B[], storing a C into th\", \"at array would mean storing a C into a B[], \\nwhich is invalid. Thus, every time you store an object \", \"reference into an array of reference types, \\nadditional validation may need to be performed to ensur\", \"e the reference being written is \\ncompatible with the concrete type of the array in question. But, i\", \"f A in this example were sealed, \\nnothing could derive from it, so storing objects into it doesn\\u2019t r\", \"equire such covariance checks. \\n\\u2022 \\nSpans shift this covariance check to their constructor; rather th\", \"an performing the covariance \\ncheck on every write into the array, the check is performed when a spa\", \"n is being constructed \\nfrom an array, such that if you try to create a new Span<A>(bArray), the cto\", \"r will throw an \\nexception. If A is sealed, the JIT is able to elide such a check as well. \\n \\n214 \\nC\", \"HAPTER 23 | Analyzers \\n \\nIt effectively would be impossible for an analyzer to be able to safely rec\", \"ommend sealing public types. \\nAfter all, it has no knowledge of the type\\u2019s purpose, how it\\u2019s intende\", \"d to be used, and whether anyone \\noutside of the assembly containing the type actually derives from \", \"it. But internal and private types are \\nanother story. An analyzer can actually see every possible t\", \"ype that could be deriving from a private \\ntype, since the analyzer has access to the whole compilat\", \"ion unit containing that type, and it needn\\u2019t \\nworry about compatibility because anything that could\", \" derive from such a type necessarily must also \\nbe non-public and would be recompiled right along wi\", \"th the base type. Further, with the exception of \\nassemblies annotated as InternalsVisibleTo, an ana\", \"lyzer can have the same insight into internal types. \\nThus, this PR adds CA1852, an analyzer that fl\", \"ags in non-InternalsVisibleTo assemblies all private and \\ninternal types that aren\\u2019t sealed and that\", \" have no types deriving from them and recommends they be \\nsealed. (Due to some current limitations i\", \"n the infrastructure around fixers and how this analyzer had \\nto be written in order to be able to s\", \"ee all of the types in the assembly, the analyzer for CA1852 \\ndoesn\\u2019t show up in Visual Studio. It c\", \"an, however, be applied using the dotnet format tool. And if \\nyou bump up the level of the rule from\", \" info to warning or error, it\\u2019ll show up as part of builds as well.) \\nIn .NET 6, we sealed over 2300\", \" types, but even with that, this analyzer ended up finding more to seal. \\ndotnet/runtime#59941 from \", \"[@NewellClark](https://github.com/NewellClark) sealed another ~70 \\ntypes, and dotnet/runtime#68268 w\", \"hich enabled the rule as an warning in dotnet/runtime (which \\nbuilds with warnings-as-errors) sealed\", \" another ~100 types. As a larger example of the rule in use, \\nASP.NET hadn\\u2019t done much in the way of\", \" sealing types in previous releases, but with CA1852 now in \\nthe .NET SDK, dotnet/aspnetcore#41457 e\", \"nabled the analyzer and sealed more than ~1100 types. \\nAnother new analyzer, CA1854, was added in do\", \"tnet/roslyn-analyzers#4851 from \\n[@CollinAlpert](https://github.com/CollinAlpert) and then enabled i\", \"n dotnet/runtime#70157. This \\nanalyzer looks for the surprisingly common pattern where a Dictionary<\", \"TKey, TValue>\\u2019s \\nContainsKey is used to determine whether a dictionary contains a particular entry, \", \"and then if it does, \\nthe dictionary\\u2019s indexer is used to retrieve the value associated with the key\", \", e.g. \\nif (_dictionary.ContainsKey(key)) \\n{ \\n    var value = _dictionary[key]; \\n    Use(value); \\n} \", \"\\nDictionary\\u2019s TryGetValue method already combines both of these operations, both looking up the \\nkey\", \" and retrieving its value if it exists, doing so as a single operation: \\nif (_dictionary.TryGetValue\", \"(key, out var value)) \\n{ \\n     Use(value); \\n} \\nA benefit of this, in addition to arguably being simp\", \"ler, is that it\\u2019s also faster. While Dictionary<TKey, \\nTValue> provides very fast lookups, and while\", \" the performance of those lookups has gotten faster \\nover time, doing fast work is still more expens\", \"ive than doing no work, and if we can do one lookup \\ninstead of two, that can result in a meaningful\", \" performance boost, in particular if it\\u2019s being performed \\non a fast path. And we can see from this \", \"simple benchmark that looks up a word in a dictionary that, \\nfor this operation, making distinct cal\", \"ls to ContainsKey and the indexer does indeed double the cost \\nof using the dictionary, almost exact\", \"ly: \\n \\n215 \\nCHAPTER 23 | Analyzers \\n \\nprivate readonly Dictionary<string, int> _counts = Regex.Match\", \"es( \\n    new \\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/cache/epub/100/pg100.txt\\\").Resu\", \"lt, \\n@\\\"\\\\b\\\\w+\\\\b\\\") \\n    .Cast<Match>() \\n    .GroupBy(word => word.Value, StringComparer.OrdinalIgnoreC\", \"ase) \\n    .ToDictionary(word => word.Key, word => word.Count(), \\nStringComparer.OrdinalIgnoreCase); \", \"\\n \\nprivate string _word = \\\"the\\\"; \\n \\n[Benchmark(Baseline = true)] \\npublic int Lookup1() \\n{ \\n    if (_\", \"counts.ContainsKey(_word)) \\n    { \\n        return _counts[_word]; \\n    } \\n \\n    return -1; \\n} \\n \\n[Be\", \"nchmark] \\npublic int Lookup2() \\n{ \\n    if (_counts.TryGetValue(_word, out int count)) \\n    { \\n      \", \"  return count; \\n    } \\n \\n    return -1; \\n} \\nMethod \\nMean \\nRatio \\nLookup1 \\n28.20 ns \\n1.00 \\nLookup2 \\n\", \"14.12 ns \\n0.50 \\nSomewhat ironically, even as I write this example, the analyzer and its auto-fixer a\", \"re helpfully trying to \\nget me to change my benchmark code: \\n \\n216 \\nCHAPTER 23 | Analyzers \\n \\n \\nSimi\", \"larly, dotnet/roslyn-analyzers#4836 from [@chucker](https://github.com/chucker) added CA1853, \\nwhich\", \" looks for cases where a Remove call on a dictionary is guarded by a ContainsKey call. It seems \\nit\\u2019\", \"s fairly natural for developers to only call Remove on a dictionary once they\\u2019re sure the dictionary\", \" \\ncontains the thing being removed; maybe they think Remove will throw an exception if the specified\", \" \\nkey doesn\\u2019t exist. However, Remove actually allows this as a first-class scenario, with its return\", \" Boolean \\nvalue indicating whether the key was in the dictionary (and thus successfully removed) or \", \"not. An \\nexample of this comes from dotnet/runtime#68724, where CA1853 was enabled for dotnet/runtim\", \"e. \\nThe EventPipeEventDispatcher type\\u2019s RemoveEventListener method had code like this: \\nif (m_subscr\", \"iptions.ContainsKey(listener)) \\n{ \\n    m_subscriptions.Remove(listener); \\n} \\nwhich the analyzer flag\", \"ged and which it\\u2019s auto-fixer replaced with just: \\nm_subscriptions.Remove(listener); \\nNice and simpl\", \"e. And faster, since as with the TryGetValue case, this is now doing a single dictionary \\nlookup rat\", \"her than two. :::{custom-style=Figure} \\n \\n217 \\nCHAPTER 23 | Analyzers \\n \\n ::: \\nAnother nice analyzer\", \" added in dotnet/roslyn-analyzers#5907 and dotnet/roslyn-analyzers#5910 is \\nCA1851, which looks for \", \"code that iterates through some kinds of enumerables multiple times. \\nEnumerating an enumerator, whe\", \"ther directly or via helper methods like those in LINQ, can have non-\\ntrivial cost. Calling GetEnume\", \"rator typically allocates an enumerator object, and every item yielded \\ntypically involves two inter\", \"face calls, one to MoveNext and one to Current. If something can be done \\nvia a single pass over the\", \" enumerable rather than multiple passes, that can save such costs. In some \\ncases, seeing places thi\", \"s analyzer fires can also inspire changes that avoid any use of enumerators. For \\nexample, dotnet/ru\", \"ntime#67292 enabled CA1851 for dotnet/runtime, and in doing so, it fixed several \\ndiagnostics issued\", \" by the analyzer (even in a code base that\\u2019s already fairly stringent about \\nenumerator and LINQ usa\", \"ge). As an example, this is a function in \\nSystem.ComponentModel.Composition that was flagged by the\", \" analyzer: \\nprivate void InitializeTypeCatalog(IEnumerable<Type> types) \\n{ \\n    foreach (Type type i\", \"n types) \\n    { \\n        if (type == null) \\n        { \\n            throw ExceptionBuilder.CreateCont\", \"ainsNullElement(nameof(types)); \\n        } \\n        else if (type.Assembly.ReflectionOnly) \\n        \", \"{ \\n            throw new ArgumentException(SR.Format(SR.Argument_ElementReflectionOnlyType, \\nnameof(\", \"types)), nameof(types)); \\n        } \\n    } \\n \\n    _types = types.ToArray(); \\n} \\nThe method\\u2019s purpose\", \" is to convert the enumerable into an array to be stored, but also to validate \\nthat the contents ar\", \"e all non-null and non-\\u201cReflectionOnly.\\u201d To achieve that, the method is first using \\na foreach to it\", \"erate through the enumerable, validating each element along the way, and then once \\nit\\u2019s done so, it\", \" calls ToArray() to convert the enumerable into an array. There are multiple problems \\n \\n218 \\nCHAPTE\", \"R 23 | Analyzers \\n \\nwith this. First, it\\u2019s incurring the expense of interating through the enumerabl\", \"e twice, once for the \\nforeach and once for the ToArray(), which internally needs to enumerate it if\", \" it can\\u2019t do something \\nspecial like cast to ICollection<Type> and CopyTo the data out of it. Second\", \", it\\u2019s possible the caller\\u2019s \\nIEnumerable<Type> changes on each iteration, so any validation done in\", \" the first iteration isn\\u2019t \\nactually ensuring there aren\\u2019t nulls in the resulting array, for example\", \". Since the expectation of the \\nmethod is that all inputs are valid and we don\\u2019t need to optimize fo\", \"r the failure cases, the better \\napproach is to first call ToArray() and then validate the contents \", \"of that array, which is exactly what \\nthat PR fixes it to do: \\nprivate void InitializeTypeCatalog(IE\", \"numerable<Type> types) \\n{ \\n    Type[] arr = types.ToArray(); \\n    foreach (Type type in arr) \\n    { \", \"\\n        if (type == null) \\n        { \\n            throw ExceptionBuilder.CreateContainsNullElement(\", \"nameof(types)); \\n        } \\n \\n        if (type.Assembly.ReflectionOnly) \\n        { \\n            thro\", \"w new ArgumentException(SR.Format(SR.Argument_ElementReflectionOnlyType, \\nnameof(types)), nameof(typ\", \"es)); \\n        } \\n    } \\n \\n \\n    _types = arr; \\n} \\nWith that, we only ever iterate it once (and poss\", \"ibly 0 times if ToArray can special-case it, and bonus, \\nwe validate on the copy rather than on the \", \"mutable original. \\nYet another helpful analyzer is the new CA1850 introduced in dotnet/roslyn-analyz\", \"ers#4797 from \\n[@wzchua](https://github.com/wzchua). It used to be that if you wanted to cryptograph\", \"ically hash \\nsome data in .NET, you would create an instance of a hash algorithm and call its Comput\", \"eHash \\nmethod, e.g. \\npublic byte[] Hash(byte[] data) \\n{ \\n    using (SHA256 h = SHA256.Create()) \\n   \", \" { \\n        return h.ComputeHash(data); \\n    } \\n} \\nHowever, .NET 5 introduced new \\u201cone-shot\\u201d hashing\", \" methods, which obviates the need to create a \\nnew HashAlgorithm instance, providing a static method\", \" that performs the whole operation. \\npublic byte[] Hash(byte[] data) \\n{ \\n    return SHA256.HashData(\", \"data); \\n} \\nCA1850 finds occurrences of the former pattern and recommends changing them to the latter\", \". \\n \\n219 \\nCHAPTER 23 | Analyzers \\n \\nThe result is not only simpler, it\\u2019s also faster: \\nprivate reado\", \"nly byte[] _data = RandomNumberGenerator.GetBytes(128); \\n \\n[Benchmark(Baseline = true)] \\npublic byte\", \"[] Hash1() \\n{ \\n    using (SHA256 h = SHA256.Create()) \\n    { \\n        return h.ComputeHash(_data); \\n\", \"    } \\n} \\n \\n[Benchmark] \\npublic byte[] Hash2() \\n{ \\n    return SHA256.HashData(_data); \\n} \\nMethod \\nMe\", \"an \\nRatio \\nAllocated \\nAlloc Ratio \\nHash1 \\n1,212.9 ns \\n1.00 \\n240 B \\n1.00 \\nHash2 \\n950.8 ns \\n0.78 \\n56 B\", \" \\n0.23 \\n \\nThe .NET 7 SDK also includes new analyzers around [GeneratedRegex(...)] (dotnet/runtime#68\", \"976) \\nand the already mentioned ones for LibraryImport, all of which help to move your code forwards\", \" to \\nmore modern patterns that have better performance characteristics. \\n \\n220 \\nCHAPTER 23 | Analyze\", \"rs \\n \\n \\nThis release also saw dotnet/runtime turn on a bunch of additional IDEXXXX code style rules \", \"and \\nmake a huge number of code changes in response. Most of the resulting changes are purely about \", \"\\nsimplifying the code, but in almost every case some portion of the changes also have a functional a\", \"nd \\nperformance impact. \\nLet\\u2019s start with IDE0200, which is about removing unnecessary lambdas. Cons\", \"ider a setup like this: \\npublic class C \\n{ \\n    public void CallSite() => M(i => Work(i)); \\n \\n    pu\", \"blic void M(Action<int> action) { } \\n    private static void Work(int value) { } \\n} \\nHere we have a \", \"method CallSite that\\u2019s invoking a method M and passing a lambda to it. Method M \\naccepts an Action<i\", \"nt>, and the call site is passing a lambda that takes the supplied Int32 and \\npasses it off to some \", \"static functionality. For this code, the C# compiler is going to generate \\nsomething along the lines\", \" of this: \\npublic class C \\n{ \\n    [CompilerGenerated] \\n    private sealed class <>c \\n    { \\n        \", \"public static readonly <>c <>9 = new <>c(); \\n \\n        public static Action<int> <>9__0_0; \\n \\n      \", \"  internal void <CallSite>b__0_0(int i) => Work(i); \\n    } \\n \\n    public void CallSite() => M(<>c.<>\", \"9__0_0 ??= new \\nAction<int>(<>c.<>9.<CallSite>b__0_0)); \\n \\n    public void M(Action<int> action) { }\", \" \\n    private static void Work(int value) { } \\n} \\nThe most important aspect of this is that <>9__0_0\", \" field the compiler emitted. That field is a cache for \\nthe delegate created in CallSite. The first \", \"time CallSite is invoked, it\\u2019ll allocate a new delegate for \\nthe lambda and store it into that field\", \". For all subsequent invocations, however, it\\u2019ll find the field is \\n \\n221 \\nCHAPTER 23 | Analyzers \\n \", \"\\nnon-null and will just reuse the same delegate. Thus, this lambda only ever results in a single \\nal\", \"location for the whole process (ignoring any race conditions on the initial lazy initialization such\", \" that \\nmultiple threads all racing to initialize the field might end up producing a few additional u\", \"nnecessary \\nallocations). It\\u2019s important to recognize this caching only happens because the lambda d\", \"oesn\\u2019t access \\nany instance state and doesn\\u2019t close over any locals; if it did either of those thing\", \"s, such caching \\nwouldn\\u2019t happen. Secondarily, it\\u2019s interesting to note the pattern the compiler use\", \"s for the lambda \\nitself. Note that generated <CallSite>b__0_0 method is generated as an instance me\", \"thod, and the \\ncall site refers to that method of a singleton instance that\\u2019s used to initialize a <\", \">9 field. That\\u2019s done \\nbecause delegates to static methods use something called a \\u201cshuffle thunk\\u201d to\", \" move arguments into \\nthe right place for the target method invocation, making delegates to statics \", \"ever so slightly more \\nexpensive to invoke than delegates to instance methods. \\nprivate Action _inst\", \"ance = new C().InstanceMethod; \\nprivate Action _static = C.StaticMethod; \\n \\n[Benchmark(Baseline = tr\", \"ue)] \\npublic void InvokeInstance() => _instance(); \\n \\n[Benchmark] \\npublic void InvokeStatic() => _st\", \"atic();     \\n \\nprivate sealed class C \\n{ \\n    public static void StaticMethod() { } \\n    public void\", \" InstanceMethod() { } \\n} \\nMethod \\nMean \\nRatio \\nInvokeInstance \\n0.8858 ns \\n1.00 \\nInvokeStatic \\n1.3979\", \" ns \\n1.58 \\nSo, the compiler is able to cache references to lambdas, great. What about method groups,\", \" i.e. where \\nyou just name the method directly? Previously, if changed my code to: \\npublic class C \\n\", \"{ \\n    public void CallSite() => M(Work); \\n \\n    public void M(Action<int> action) { } \\n    private \", \"static void Work(int value) { } \\n} \\nthe compiler would generate the equivalent of: \\npublic class C \\n\", \"{ \\n    public void CallSite() => M(new Action<int>(Work)); \\n \\n    public void M(Action<int> action) \", \"{ } \\n    private static void Work(int value) { } \\n} \\n \\n222 \\nCHAPTER 23 | Analyzers \\n \\nwhich has the \", \"unfortunate effect of allocating a new delegate on every invocation, even though we\\u2019re \\nstill dealin\", \"g with the exact same static method. Thanks to dotnet/roslyn#58288 from \\n[@pawchen](https://github.c\", \"om/pawchen), the compiler will now generate the equivalent of: \\npublic class C \\n{ \\n    [CompilerGene\", \"rated] \\n    private static class <>O \\n    { \\n        public static Action<int> <0>__Work; \\n    } \\n \\n\", \"    public void CallSite() => M(<>O.<0>__Work ??= new Action<int>(Work)); \\n \\n    public void M(Actio\", \"n<int> action) { } \\n    private static void Work(int value) { } \\n} \\nNote we again have a caching fie\", \"ld that\\u2019s used to enable allocating the delegate once and caching it. \\nThat means that places where \", \"code was using a lambda to enable this caching can now switch back to \\nthe cleaner and simpler metho\", \"d group way of expressing the desired functionality. There is the \\ninteresting difference to be cogn\", \"izant of that since we don\\u2019t have a lambda which required the \\ncompiler emitting a new method for, w\", \"e\\u2019re still creating a delegate directly to the static method. \\nHowever, the minor difference in thun\", \"k overhead is typically made up for by the fact that we don\\u2019t \\nhave a second method to invoke; in th\", \"e common case where the static helper being invoked isn\\u2019t \\ninlinable (because it\\u2019s not super tiny, b\", \"ecause it has exception handling, etc.), we previously would \\nhave incurred the cost of the delegate\", \" invocation plus the non-inlinable method call, and now we just \\nhave the cost of an ever-so-slightl\", \"y more expensive delegate invocation; on the whole, it\\u2019s typically a \\nwash. \\nAnd that brings us to I\", \"DE0200, which recognizes lambda expressions that can be removed. \\ndotnet/runtime#71011 enabled the a\", \"nalyzer for dotnet/runtime, resulting in more than 100 call sites \\nchanging accordingly. However, ID\", \"E0200 does more than just this mostly stylistic change. It also \\nrecognizes some patterns that can m\", \"ake a more substantial impact. Consider this code that was \\nchanged as part of that PR: \\nAction disp\", \"oseAction; \\nIDisposable? disposable = null; \\n... \\nif (disposable != null) \\n{ \\n    disposeAction = ()\", \" => disposable.Dispose(); \\n} \\nThat delegate closes over the disposable local, which means this metho\", \"d needs to allocate a display \\nclass. But IDE0200 recognizes that instead of closing over disposable\", \", we can create the delegate \\ndirectly to the Dispose method: \\nAction disposeAction; \\nIDisposable? d\", \"isposable = null; \\n... \\nif (disposable != null) \\n{ \\n \\n223 \\nCHAPTER 23 | Analyzers \\n \\n    disposeActi\", \"on = disposable.Dispose; \\n} \\nWe still get a delegate allocation, but we avoid the display class allo\", \"cation, and as a bonus we save on \\nthe additional metadata required for the synthesized display clas\", \"s and method generated for the \\nlambda. \\nIDE0020 is another good example of an analyzer that is prim\", \"arily focused on making code cleaner, \\nmore maintainable, more modern, but that can also lead to rem\", \"oving overhead from many different \\nplaces. The analyzer looks for code performing unnecessary dupli\", \"cative casts and recommends using \\nC# pattern matching syntax instead. For example, dotnet/runtime#7\", \"0523 enabled the analyzer and \\nswitched more than 250 locations from code like: \\nif (value is SqlDou\", \"ble) \\n{ \\n    SqlDouble i = (SqlDouble)value; \\n    return CompareTo(i); \\n} \\nto instead be like: \\nif (\", \"value is SqlDouble i) \\n{ \\n    return CompareTo(i); \\n} \\nIn addition to being cleaner, this ends up sa\", \"ving a cast operation, which can add measurable \\noverhead if the JIT is unable to remove it: \\nprivat\", \"e object _value = new List<string>(); \\n \\n[Benchmark(Baseline = true)] \\npublic List<string> WithCast(\", \") \\n{ \\n    object value = _value; \\n    return value is List<string> ? (List<string>)value : null; \\n} \", \"\\n \\n[Benchmark] \\npublic List<string> WithPattern() \\n{ \\n    object value = _value; \\n    return value i\", \"s List<string> list ? list : null; \\n} \\nMethod \\nMean \\nRatio \\nWithCast \\n2.602 ns \\n1.00 \\nWithPattern \\n1\", \".886 ns \\n0.73 \\nThen there\\u2019s IDE0031, which promotes using null propagation features of C#. This anal\", \"yzer typically \\nmanifests as recommending changing snippets like: \\nreturn _value != null ? _value.Pr\", \"operty : null; \\ninto code that\\u2019s instead like: \\n \\n224 \\nCHAPTER 23 | Analyzers \\n \\nreturn _value?.Prop\", \"erty; \\nNice, concise, and primarily about cleaning up the code and making it simpler and more mainta\", \"inable \\nby utilizing newer C# syntax. However, there is also a small performance advantage in some s\", \"ituations \\nas well. For example, consider this snippet: \\npublic class C \\n{ \\n    private C _value; \\n \", \"    \\n    public int? Get1() => _value != null ? _value.Prop : null; \\n    public int? Get2() => _valu\", \"e?.Prop; \\n     \\n    public int Prop => 42; \\n} \\nThe C# compiler lowers these expressions to the equiv\", \"alent of this: \\npublic Nullable<int> Get1() \\n{ \\n    if (_value == null) return null; \\n    return _va\", \"lue.Prop; \\n} \\n \\npublic Nullable<int> Get2() \\n{ \\n    C value = _value; \\n    if (value == null) return\", \" null; \\n    return value.Prop; \\n} \\nfor which the JIT then generates: \\n; Program.Get1() \\n       push \", \"     rax \\n       mov       rdx,[rcx+8] \\n       test      rdx,rdx \\n       jne       short M00_L00 \\n  \", \"     xor       eax,eax \\n       add       rsp,8 \\n       ret \\nM00_L00: \\n       cmp       [rdx],dl \\n   \", \"    mov       dword ptr [rsp+4],2A \\n       mov       byte ptr [rsp],1 \\n       mov       rax,[rsp] \\n \", \"      add       rsp,8 \\n       ret \\n; Total bytes of code 40 \\n \\n; Program.Get2() \\n       push      ra\", \"x \\n       mov       rax,[rcx+8] \\n       test      rax,rax \\n       jne       short M00_L00 \\n       xo\", \"r       eax,eax \\n       add       rsp,8 \\n       ret \\nM00_L00: \\n \\n225 \\nCHAPTER 23 | Analyzers \\n \\n    \", \"   mov       dword ptr [rsp+4],2A \\n       mov       byte ptr [rsp],1 \\n       mov       rax,[rsp] \\n  \", \"     add       rsp,8 \\n       ret \\n; Total bytes of code 38 \\nNote how the Get1 variant has an extra c\", \"mp instruction (cmp [rdx],dl) in the otherwise identical \\nassembly to Get2 (other than register sele\", \"ction). That cmp instruction in Get1 is the JIT forcing a null \\ncheck on the second read of _value p\", \"rior to accessing its Prop, whereas in Get2 the null check against \\nthe local means the JIT doesn\\u2019t \", \"need to add an additional null check on the second use of the local, \\nsince nothing could have chang\", \"ed it. dotnet/runtime#70965 rolled out additional use of the null \\npropagation operator via auto-fix\", \"ing IDE0031, resulting in ~120 uses being improved. \\nAnother interesting example is IDE0060, which f\", \"inds unused parameters and recommends removing \\nthem. This was done for non-public members in System\", \".Private.CoreLib in dotnet/runtime#63015. As \\nwith some of the other mentioned rules, it\\u2019s primarily\", \" about good hygiene. There can be some small \\nadditional cost associated with passing additional par\", \"ameters (the overhead of reading the values at \\nthe call site, putting them into the right register \", \"or stack location, etc., and also the metadata size \\nassociated with the additional parameter inform\", \"ation), but the larger benefit comes from auditing all \\nof the cited violations and finding places w\", \"here work is simply being performed unnecessarily. For \\nexample, that PR made some updates to the Ti\", \"meZoneInfo type\\u2019s implementation for Unix. In that \\nimplementation is a TZif_ParseRaw method, which \", \"is used to extract some information from a time \\nzone data file. Amongst many input and output param\", \"eters, it had out bool[] StandardTime, out \\nbool[] GmtTime, which the implementation was dutifully f\", \"illing in by allocating and populating new \\narrays for each. The call site for TZif_ParseRaw was the\", \"n taking those arrays and feeding them into \\nanother method TZif_GenerateAdjustmentRules, which igno\", \"red them! Thus, not only was this PR \\nable to remove those parameters from TZif_GenerateAdjustmentRu\", \"les, it was able to update \\nTZif_ParseRaw to no longer need to allocate and populate those arrays at\", \" all, which obviously yields \\na much larger gain. \\nOne final example of peanut-buttery performance i\", \"mprovements from applying an analyzer comes \\nfrom dotnet/runtime#70896 and dotnet/runtime#71361, whi\", \"ch applied IDE0029 across \\ndotnet/runtime. IDE0029 flags cases where null coalescing can be used, e.\", \"g. flagging: \\nreturn message != null ? message : string.Empty; \\nand recommending it be converted to:\", \" \\nreturn message ?? string.Empty; \\nAs with some of the previous rules discussed, that in and of itse\", \"lf doesn\\u2019t make a meaningful \\nperformance improvement, and rather is about clarity and simplicity. H\", \"owever, in various cases it can. \\nFor example, the aforementioned PRs contained an example like: \\nnu\", \"ll != foundColumns[i] ? foundColumns[i] : DBNull.Value; \\nwhich is rewritten to: \\nfoundColumns[i] ?? \", \"DBNull.Value \\nThis avoids an unnecessary re-access to an array. Or again from those PRs the expressi\", \"on: \\n \\n226 \\nCHAPTER 23 | Analyzers \\n \\nentry.GetKey(_thisCollection) != null ? entry.GetKey(_thisColl\", \"ection) : \\\"key\\\" \\nbeing changed to: \\nentry.GetKey(_thisCollection) ?? \\\"key\\\" \\nand avoiding an unnecess\", \"ary table lookup. \\n \\n227 \\nCHAPTER 24 | What\\u2019s Next? \\n \\nCHAPTER 24 \\nWhat\\u2019s Next? \\nWhew! That was a lo\", \"t. Congrats on getting through it all. \\nThe next step is on you. Download the latest .NET 7 bits and\", \" take them for a spin. Upgrade your apps. \\nWrite and share your own benchmarks. Provide feedback, po\", \"sitive and critical. Find something you \\nthink can be better? Open an issue, or better yet, submit a\", \" PR with the fix. We\\u2019re excited to work with \\nyou to polish .NET 7 to be the best .NET release yet; \", \"meanwhile, we\\u2019re getting going on .NET 8 :) \\nUntil next time\\u2026 \\nHappy coding! \\n\"]"