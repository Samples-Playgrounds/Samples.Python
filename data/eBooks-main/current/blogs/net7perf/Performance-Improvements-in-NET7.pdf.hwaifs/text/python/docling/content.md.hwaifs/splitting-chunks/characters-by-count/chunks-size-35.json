"[\"<!-- image -->\\n\\n## Performance Improvements in .NET 7\\n\\n## Stephen Toub\\n\\nPartner Software Engineer, .\", \"NET\\n\\nMicrosoft\\n\\n## Introduction\\n\\nA year ago, I published Performance Improvements in .NET 6, followi\", \"ng on the heels of similar posts for .NET 5, .NET Core 3.0, .NET Core 2.1, and .NET Core 2.0. I enjo\", \"y writing these posts and love reading developers' responses to them. One comment in particular last\", \" year resonated with me. The commenter cited the Die Ha rd movie quote, ''When Alexander saw the bre\", \"adth of his domain, he wept for there were no more worlds to conquer',' and questioned whether .NET \", \"performance improvements were similar. Has the well run dry? Are there no more '[performance] worlds\", \" to conquer'? I'm a bit giddy to say that, even with how fast .NET 6 is, .NET 7 definitively highlig\", \"hts how much more can be and has been done.\\n\\nAs with previous versions of .NET, performance is a key\", \" focus that pervades the entire stack, whether it be features created explicitly for performance or \", \"non-performance-related features that are still designed and implemented with performance keenly in \", \"mind. And now that a .NET 7 release candidate is just around the corner, it's a good time to discuss\", \" much of it. Over the cou rse of the last year, every time I've reviewed a PR that might positively \", \"impact performance, I've copied that link to a journal I maintain for the purposes of writing this p\", \"ost. When I sat down to write this a few weeks ago, I was faced with a list of almost 1000 performan\", \"ce-impacting PRs (out of more than 7000 PRs that went into the release), and I'm excited to share ap\", \"proximately 500 of them here with you.\\n\\nOne thought before we dive in. In past years, I've received \", \"the odd piece of negative feedback abou t the length of some of my performance-focused write-ups, an\", \"d while I disagree with the criticism, I respect the opinion. So, this year, consider this a 'choose\", \" your own adventure.' If you're here just looking for a super short adventure, one that provides the\", \" top-level summary and a core message to take away from your time here, I'm happy to oblige:\\n\\nTL;DR:\", \" .NET 7 is fast. Really fast. A thousand performance-impacting PRs went into runtime and core librar\", \"ies this release, never mind all the improvements in ASP.NET Core and Windows Forms and Entity Frame\", \"work and beyond. It's the fastest .NET ever. If your manager asks you why your project should upgrad\", \"e to .NET 7, you can say 'in addition to all the new functionality in the release, .NET 7 is super f\", \"ast.'\\n\\nOr, if you prefer a slightly longer adventure, one filled with interesting nuggets of perform\", \"ancefocused data, consider skimming through the post, looking for the small code snippets and corres\", \"ponding tables showing a wealth of measurable performance improvements. At that point, you, too, may\", \" walk away with your head held high and my thanks.\\n\\nBoth noted paths achieve one of my primary goals\", \" for spending the time to write these posts, to highlight the greatness of the next release and to e\", \"ncourage everyone to give it a try. But, I have other goals for these posts, too. I want everyone in\", \"terested to walk away from this post with an upleveled understanding of how .NET is implemented, why\", \" various decisions were made, tradeoffs that were evaluated, techniques that were employed, algorith\", \"ms that were considered, and valuable tools and approaches that were utilized to make .NET even fast\", \"er than it was previously. I want developers to learn from our own learnings and find ways to apply \", \"this new-found knowledge to their own codebases, thereby further increasing the overall performance \", \"of code in the ecosystem. I want developers to take an extra beat, think about reaching for a profil\", \"er the next time they're working on a gnarly problem, think about looking at the source fo r the com\", \"ponent they're using in order to better understand how to work with it, and think about revisiting p\", \"revious assumptions and decisions to determine whether they're still accurate and appropriate. And I\", \" want developers to be excited at the prospect of submitting PRs to improve .NET not only for themse\", \"lves but for every developer around the globe using .NET. If any of that sounds interesting, then I \", \"encourage you to choose the last adventure: prepare a carafe of your favorite hot beverage, get comf\", \"ortable, and please enjoy.\\n\\n## Contents\\n\\n| Setup....................................................\", \".....................................................................................               \", \"                                 | 1                                                                \", \"                                                                                                    \", \"               |\\n|----------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"---------|------------------------------------------------------------------------------------------\", \"-------------------------------------------------------------------------------------------|\\n| JIT..\", \"....................................................................................................\", \"........................................                                             | 3            \", \"                                                                                                    \", \"                                                                   |\\n| On-Stack Replacement ........\", \"....................................................................................................\", \"......................................13                     |                                      \", \"                                                                                                    \", \"                                           |\\n| PGO..................................................\", \"....................................................................................................\", \"..................................23 |                                                              \", \"                                                                                                    \", \"                   |\\n| Bounds Check Elimination.....................................................\", \".......................................................................................35           \", \"             |                                                                                      \", \"                                                                                               |\\n| L\", \"oop Hoisting and Cloning ...........................................................................\", \"...............................................................45                        |          \", \"                                                                                                    \", \"                                                                       |\\n| Folding, propagation, and\", \" substitution.......................................................................................\", \"............................50                                   |                                  \", \"                                                                                                    \", \"                                               |\\n| Vectorization....................................\", \"....................................................................................................\", \"..............................54         |                                                          \", \"                                                                                                    \", \"                       |\\n| Inlining.................................................................\", \"....................................................................................................\", \".............62  |                                                                                  \", \"                                                                                                   |\", \"\\n| Arm64............................................................................................\", \".......................................................................................64    |      \", \"                                                                                                    \", \"                                                                           |\\n| JIT helpers .........\", \"....................................................................................................\", \"..............................................................65     |                              \", \"                                                                                                    \", \"                                                   |\\n| Grab Bag.....................................\", \"....................................................................................................\", \".....................................67      |                                                      \", \"                                                                                                    \", \"                           |\\n| GC...................................................................\", \".........................................................................                           \", \"                     | 71                                                                           \", \"                                                                                                    \", \"   |\\n| Native AOT...................................................................................\", \"..........................................                                                       | 7\", \"2                                                                                                   \", \"                                                                               |\\n| Mono             \", \"                                                                                                    \", \"                                                                         | .........................\", \"....................................................................................................\", \"......... 75                                           |\\n| Reflection ..............................\", \".................................................................................................   \", \"                                                 | 78                                               \", \"                                                                                                    \", \"                               |\\n| Interop..........................................................\", \"..........................................................................                          \", \"                         | 82                                                                       \", \"                                                                                                    \", \"       |\\n| Threading................................................................................\", \"...............................................                                                     \", \" | 89                                                                                               \", \"                                                                                   |\\n| Primitive Typ\", \"es and Numerics ....................................................................................\", \".........                                                                    | 93                   \", \"                                                                                                    \", \"                                                           |\\n| Arrays, Strings, and Spans...........\", \".......................................................................................101          \", \"                                                     |                                              \", \"                                                                                                    \", \"                                   |\\n| Regex........................................................\", \"............................................................................128                     \", \"                             |                                                                      \", \"                                                                                                    \", \"           |\\n| RegexOptions.NonBacktracking.........................................................\", \"......................................................................128                           \", \"     |                                                                                              \", \"                                                                                       |\\n| New      \", \"                                                                                                    \", \"                                                                                 | APIs.............\", \"....................................................................................................\", \"...........................................................133 |\\n| TryFindNextPossibleStartingPositi\", \"on .................................................................................................\", \"....................138                                  |                                          \", \"                                                                                                    \", \"                                       |\\n| Loops and Backtracking ..................................\", \"....................................................................................................\", \"........143                      |                                                                  \", \"                                                                                                    \", \"               |\\n| Code generation..................................................................\", \"...........................................................................................146      \", \"         |                                                                                          \", \"                                                                                           |\\n| Colle\", \"ctions..............................................................................................\", \"..............................150                                                    |              \", \"                                                                                                    \", \"                                                                   |\\n\\nFile I/O .....................\", \"....................................................................................................\", \".........  159\\n\\nCompression ........................................................................\", \"................................................  168\\n\\nNetworking ..................................\", \"........................................................................................  173\\n\\nJSON \", \"....................................................................................................\", \".................................  190\\n\\nXML ........................................................\", \"...............................................................................  193\\n\\nCryptography  \", \"....................................................................................................\", \"...................  198\\n\\nDiagnostics  .............................................................\", \"..............................................................  203\\n\\nExceptions ....................\", \"....................................................................................................\", \"....  208\\n\\nRegistry ................................................................................\", \"................................................  211\\n\\nAnalyzers ...................................\", \"...........................................................................................  213\\n\\nWh\", \"at's Next?\\n\\n........................................................................................\", \"................................  227\\n\\n## Setup\\n\\nThe microbenchmarks throughout this post utilize be\", \"nchmarkdotnet. To make it easy for you to follow along with your own validation, I have a very simpl\", \"e setup for the benchmarks I use. Create a new C# project:\\n\\n```\\ndotnet new console -o benchmarks cd \", \"benchmarks\\n```\\n\\nYour new benchmarks directory will contain a benchmarks.csproj file and a Program.cs\", \" file. Replace the contents of benchmarks.csproj with this:\\n\\n```\\n<Project Sdk=\\\"Microsoft.NET.Sdk\\\" > \", \"<PropertyGroup> <OutputType> Exe </OutputType> <TargetFrameworks> net7.0;net6.0 </TargetFrameworks> \", \"<LangVersion> Preview </LangVersion> <AllowUnsafeBlocks> true </AllowUnsafeBlocks> <ServerGarbageCol\", \"lection> true </ServerGarbageCollection> </PropertyGroup> <ItemGroup> <PackageReference Include=\\\"ben\", \"chmarkdotnet\\\" Version=\\\"0.13.2\\\" /> </ItemGroup> </Project>\\n```\\n\\nand the contents of Program.cs with t\", \"his:\\n\\n```\\nusing BenchmarkDotNet.Attributes; using BenchmarkDotNet.Running; using Microsoft.Win32; us\", \"ing System; using System.Buffers; using System.Collections.Generic; using System.Collections.Immutab\", \"le; using System.ComponentModel; using System.Diagnostics; using System.IO; using System.IO.Compress\", \"ion; using System.IO.MemoryMappedFiles; using System.IO.Pipes; using System.Linq; using System.Net; \", \"using System.Net.Http; using System.Net.Http.Headers; using System.Net.Security; using System.Net.So\", \"ckets; using System.Numerics;\\n```\\n\\n```\\nusing System.Reflection; using System.Runtime.CompilerService\", \"s; using System.Runtime.InteropServices; using System.Runtime.Intrinsics; using System.Security.Auth\", \"entication; using System.Security.Cryptography; using System.Security.Cryptography.X509Certificates;\", \" using System.Text; using System.Text.Json; using System.Text.RegularExpressions; using System.Threa\", \"ding; using System.Threading.Tasks; using System.Xml; [MemoryDiagnoser(displayGenColumns: false )] [\", \"DisassemblyDiagnoser] [HideColumns(\\\"Error\\\", \\\"StdDev\\\", \\\"Median\\\", \\\"RatioSD\\\")] public partial class Pro\", \"gram { static void Main(string[] args) => BenchmarkSwitcher.FromAssembly( typeof (Program).Assembly)\", \".Run(args); // ... copy [Benchmark]s here }\\n```\\n\\nFor each benchmark included in this write-up, you c\", \"an then just copy and paste the code into this test class, and run the benchmarks. For example, to r\", \"un a benchmark comparing performance on .NET 6 and .NET 7, do:\\n\\n```\\ndotnet run -c Release -f net6.0 \", \"--filter '**' --runtimes net6.0 net7.0\\n```\\n\\nThis command says 'build the benchmarks in release confi\", \"guration ta rgeting the .NET 6 surface area, and then run all of the benchmarks on both .NET 6 and .\", \"NET 7.' Or to run just on .NET 7:\\n\\n```\\ndotnet run -c Release -f net7.0 --filter '**' --runtimes net7\", \".0\\n```\\n\\nwhich instead builds targeting the .NET 7 surface area and then only runs once against .NET \", \"7. You can do this on any of Windows, Linux, or macOS. Unless otherwise called out (e.g. where the i\", \"mprovements are specific to Unix and I run the benchmarks on Linux), the results I share were record\", \"ed on Windows 11 64bit but aren't Windows-specific and should show similar relative differences on t\", \"he other operating systems as well.\\n\\nThe release of the first .NET 7 release candidate is right arou\", \"nd the corner. All of the measurements in this post were gathered with a recent daily build of .NET \", \"7 RC1.\\n\\nAlso, my standard caveat: These are microbenchmarks. It is expected that different hardware,\", \" different versions of operating systems, and the way in which the wind is currently blowing can aff\", \"ect the numbers involved. Your mileage may vary.\\n\\n<!-- image -->\\n\\n## JIT\\n\\nI'd like to kick off a dis\", \"cussion of performance improvements in the Just-In-Time (JIT) compiler by talking about something th\", \"at itself isn't actually a performance improvement. Being able to understand exactly what assembly c\", \"ode is generated by the JIT is critical when fine-tuning lower-level, performance-sensitive code. Th\", \"ere are multiple ways to get at that assembly code. The online tool sharplab.io is incredibly useful\", \" for this (thanks to [@ashmind](https://github.com/ashmind) for this tool); however it currently onl\", \"y targets a single release, so as I write this I'm onl y able to see the output for .NET 6, which ma\", \"kes it difficult to use for A/B comparisons. godbolt.org is also valuable for this, with C# support \", \"added in compiler-explorer/compiler-explorer#3168 from [@hez2010](https://github.com/hez2010), with \", \"similar limitations. The most flexible solutions involve getting at that assembly code locally, as i\", \"t enables comparing whatever versions or local builds you desire with whatever configurations and sw\", \"itches set that you need.\\n\\nOne common approach is to use the [DisassemblyDiagnoser] in benchmarkdotn\", \"et. Simply slap the [DisassemblyDiagnoser] attribute onto your test class: benchmarkdotnet will find\", \" the assembly code generated for your tests and some depth of functions they call, and dump out the \", \"found assembly code in a human-readable form. For example, if I run this test:\\n\\n```\\nusing BenchmarkD\", \"otNet.Attributes; using BenchmarkDotNet.Running; using System; [DisassemblyDiagnoser] public partial\", \" class Program { static void Main(string[] args) => BenchmarkSwitcher.FromAssembly( typeof (Program)\", \".Assembly).Run(args); private int _a = 42, _b = 84; [Benchmark] public int Min() => Math.Min(_a, _b)\", \"; }\\n```\\n\\nwith:\\n\\n```\\ndotnet run -c Release -f net7.0 --filter '**'\\n```\\n\\nin addition to doing all of i\", \"ts normal test execution and timing, benchmarkdotnet also outputs a Program-asm.md file that contain\", \"s this:\\n\\n```\\n; Program.Min() mov       eax,[rcx+8] mov       edx,[rcx+0C] cmp       eax,edx\\n```\\n\\n```\", \"\\njg        short M00_L01 mov       edx,eax M00_L00: mov       eax,edx ret M00_L01: jmp       short M\", \"00_L00 ; Total bytes of code 17\\n```\\n\\nPretty neat. This support was recently improved further in dotn\", \"et/benchmarkdotnet#2072, which allows passing a filter list on the commandline to benchmarkdotnet to\", \" tell it exactly which methods' assembly code should be dumped.\\n\\nIf you can get your hands on a 'deb\", \"ug' or 'checked' build of the .NET runtime ('checked' is a build that has optimizations enabled but \", \"also still includes asserts), and specifically of clrjit.dll, another valuable approach is to set an\", \" environment variable that causes the JIT itself to spit out a humanreadable description of all of t\", \"he assembly code it emits. This can be used with any kind of application, as it's part of the JIT it\", \"self rather than part of any speci fic tool or other environment, it supports showing the code the J\", \"IT generates each time it generates code (e.g. if it first compiles a method without optimization an\", \"d then later recompiles it with optimization), and overall it's the most accurate picture o f the as\", \"sembly code as it comes 'straight from the horses mouth,' as it were. The (big) downside of course i\", \"s that it requires a non-release build of the runtime, which typically means you need to build it yo\", \"urself from the sources in the dotnet/runtime repo.\\n\\n\\u2026 until .NET 7, that is. As of dotnet/runtime#7\", \"3365, this assembly dumping support is now available in release builds as well, which me ans it's si\", \"mply part of .NET 7 and you don't need anything special to use it. To see this, try creating a simpl\", \"e 'hello world' app like:\\n\\n```\\nusing System; class Program { public static void Main() => Console.Wr\", \"iteLine(\\\"Hello, world!\\\"); }\\n```\\n\\nand building it (e.g. dotnet build -c Release ). Then, set the DOTN\", \"ET\\\\_JitDisasm environment variable to the name of the method we care about, in this case 'Main' (the\", \" exact syntax allowed is more permissive and allows for some use of wildcards, optional namespace an\", \"d class names, etc.). As I'm using PowerShell, that means:\\n\\n```\\n$env:DOTNET_JitDisasm=\\\"Main\\\"\\n```\\n\\nan\", \"d then running the app. You should see code like this output to the console:\\n\\n```\\n; Assembly listing\", \" for method Program:Main() ; Emitting BLENDED_CODE for X64 CPU with AVX - Windows ; Tier-0 compilati\", \"on ; MinOpts code ; rbp based frame ; partially interruptible G_M000_IG01:                ;; offset=\", \"0000H 55                   push     rbp 4883EC20             sub      rsp, 32\\n```\\n\\n```\\n488D6C2420   \", \"        lea      rbp, [rsp+20H] G_M000_IG02:                ;; offset=000AH 48B9D820400A8E010000 mov\", \"      rcx, 0x18E0A4020D8 488B09               mov      rcx, gword ptr [rcx] FF1583B31000         cal\", \"l     [Console:WriteLine(String)] 90                   nop G_M000_IG03:                ;; offset=001\", \"EH 4883C420             add      rsp, 32 5D                   pop      rbp C3                   ret \", \"; Total bytes of code 36 Hello, world!\\n```\\n\\nThis is immeasurably helpful for perf ormance analysis a\", \"nd tuning, even for questions as simple as 'did my function get inlined' or 'is this code I expected\", \" to be optimized away actually getting optimized away.' Throughout the rest of this post, I'll inclu\", \"de assembly snippets generated by one of these two mechanisms, in order to help exemplify concepts.\\n\", \"\\nNote that it can sometimes be a little confusing figuring out what name to specify as the value for\", \" DOTNET\\\\_JitDisasm , especially when the method you care about is one that the C# compiler names or \", \"name mangles (since the JIT only sees the IL and metadata, not the original C#), e.g. the name of th\", \"e entry point method for a program with top-level statements, the names of local functions, etc. To \", \"both help with this and to provide a really valuable top-level view of the work the JIT is doing, .N\", \"ET 7 also supports the new DOTNET\\\\_JitDisasmSummary environment variable (introduced in dotnet/runti\", \"me#74090 ). Set that to '1', and it'll result i n the JIT emitting a line every time it compiles a m\", \"ethod, including the name of that method which is copy/pasteable with DOTNET\\\\_JitDisasm . This featu\", \"re is useful in-and-ofitself, however, as it can quickly highlight for you what's being compiled, wh\", \"en, a nd with what settings. For example, if I set the environment variable and then run a 'hello, w\", \"orld' console app, I get this output:\\n\\n```\\n1: JIT compiled CastHelpers:StelemRef(Array,long,Object) \", \"[Tier1, IL size=88, code size=93] 2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):byref [Tie\", \"r1, IL size=44, code size=44] 3: JIT compiled SpanHelpers:IndexOfNullCharacter(byref):int [Tier1, IL\", \" size=792, code size=388] 4: JIT compiled Program:Main() [Tier0, IL size=11, code size=36] 5: JIT co\", \"mpiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL size=490, code size=1187] Hel\", \"lo, world!\\n```\\n\\nWe can see for 'hello, world' there's only 5 methods that actually get JIT compiled.\", \" There are of course many more methods that get executed as part of a simple 'hello, world,' but alm\", \"ost all of them have precompiled native code available as part of the 'Ready To Run' (R2R) images of\", \" the core libraries. The first three in the above list ( StelemRef , LdelemaRef , and IndexOfNullCha\", \"racter ) don't because they explicitly opted-out of R2R via use of the\\n\\n[MethodImpl(MethodImplOption\", \"s.AggressiveOptimization)] attribute (despite the name, this attribute should almost never be used, \", \"and is only used for very specific reasons in a few very specific places in the core libraries). The\", \"n there's our Main method. And lastly there's the NarrowUtf16ToAscii\\n\\nmethod, which doesn't have R2R\", \" code, either, due to using the variable -width Vector&lt;T&gt; (more on that later). Every other me\", \"thod that's run doesn't require JIT'ing. If we instead first set the DOTNET\\\\_ReadyToRun environment \", \"variable to 0 , the list is much longer, and gives you a very good sense of what the JIT needs to do\", \" on startup (and why technologies like R2R are important for startup time). Note how many methods ge\", \"t compiled before 'hello, world' is output:\\n\\n```\\n1: JIT compiled CastHelpers:StelemRef(Array,long,Ob\", \"ject) [Tier1, IL size=88, code size=93] 2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):byre\", \"f [Tier1, IL size=44, code size=44] 3: JIT compiled AppContext:Setup(long,long,int) [Tier0, IL size=\", \"68, code size=275] 4: JIT compiled Dictionary`2:.ctor(int):this [Tier0, IL size=9, code size=40] 5: \", \"JIT compiled Dictionary`2:.ctor(int,IEqualityComparer`1):this [Tier0, IL size=102, code size=444] 6:\", \" JIT compiled Object:.ctor():this [Tier0, IL size=1, code size=10] 7: JIT compiled Dictionary`2:Init\", \"ialize(int):int:this [Tier0, IL size=56, code size=231] 8: JIT compiled HashHelpers:GetPrime(int):in\", \"t [Tier0, IL size=83, code size=379] 9: JIT compiled HashHelpers:.cctor() [Tier0, IL size=24, code s\", \"ize=102] 10: JIT compiled HashHelpers:GetFastModMultiplier(int):long [Tier0, IL size=9, code size=37\", \"] 11: JIT compiled Type:GetTypeFromHandle(RuntimeTypeHandle):Type [Tier0, IL size=8, code size=14] 1\", \"2: JIT compiled Type:op_Equality(Type,Type):bool [Tier0, IL size=38, code size=143] 13: JIT compiled\", \" NonRandomizedStringEqualityComparer:GetStringComparer(Object):IEqualityComparer`1 [Tier0, IL size=3\", \"9, code size=170] 14: JIT compiled NonRandomizedStringEqualityComparer:.cctor() [Tier0, IL size=46, \", \"code size=232] 15: JIT compiled EqualityComparer`1:get_Default():EqualityComparer`1 [Tier0, IL size=\", \"6, code size=36] 16: JIT compiled EqualityComparer`1:.cctor() [Tier0, IL size=26, code size=125] 17:\", \" JIT compiled ComparerHelpers:CreateDefaultEqualityComparer(Type):Object [Tier0, IL size=235, code s\", \"ize=949] 18: JIT compiled CastHelpers:ChkCastClass(long,Object):Object [Tier0, IL size=22, code size\", \"=72] 19: JIT compiled RuntimeHelpers:GetMethodTable(Object):long [Tier0, IL size=11, code size=33] 2\", \"0: JIT compiled CastHelpers:IsInstanceOfClass(long,Object):Object [Tier0, IL size=97, code size=257]\", \" 21: JIT compiled GenericEqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31] 22: JIT co\", \"mpiled EqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31] 23: JIT compiled CastHelpers\", \":ChkCastClassSpecial(long,Object):Object [Tier0, IL size=87, code size=246] 24: JIT compiled Ordinal\", \"Comparer:.ctor(IEqualityComparer`1):this [Tier0, IL size=8, code size=39] 25: JIT compiled NonRandom\", \"izedStringEqualityComparer:.ctor(IEqualityComparer`1):this [Tier0, IL size=14, code size=52] 26: JIT\", \" compiled StringComparer:get_Ordinal():StringComparer [Tier0, IL size=6, code size=49] 27: JIT compi\", \"led OrdinalCaseSensitiveComparer:.cctor() [Tier0, IL size=11, code size=71] 28: JIT compiled Ordinal\", \"CaseSensitiveComparer:.ctor():this [Tier0, IL size=8, code size=33] 29: JIT compiled OrdinalComparer\", \":.ctor(bool):this [Tier0, IL size=14, code size=43] 30: JIT compiled StringComparer:.ctor():this [Ti\", \"er0, IL size=7, code size=31] 31: JIT compiled StringComparer:get_OrdinalIgnoreCase():StringComparer\", \" [Tier0, IL size=6, code size=49] 32: JIT compiled OrdinalIgnoreCaseComparer:.cctor() [Tier0, IL siz\", \"e=11, code size=71] 33: JIT compiled OrdinalIgnoreCaseComparer:.ctor():this [Tier0, IL size=8, code \", \"size=36] 34: JIT compiled OrdinalIgnoreCaseComparer:.ctor(IEqualityComparer`1):this [Tier0, IL\\n```\\n\\n\", \"```\\nsize=8, code size=39] 35: JIT compiled CastHelpers:ChkCastAny(long,Object):Object [Tier0, IL siz\", \"e=38, code size=115] 36: JIT compiled CastHelpers:TryGet(long,long):int [Tier0, IL size=129, code si\", \"ze=308] 37: JIT compiled CastHelpers:TableData(ref):byref [Tier0, IL size=7, code size=31] 38: JIT c\", \"ompiled MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, code size=24] 39: JIT comp\", \"iled CastHelpers:KeyToBucket(byref,long,long):int [Tier0, IL size=38, code size=87] 40: JIT compiled\", \" CastHelpers:HashShift(byref):int [Tier0, IL size=3, code size=16] 41: JIT compiled BitOperations:Ro\", \"tateLeft(long,int):long [Tier0, IL size=17, code size=23] 42: JIT compiled CastHelpers:Element(byref\", \",int):byref [Tier0, IL size=15, code size=33] 43: JIT compiled Volatile:Read(byref):int [Tier0, IL s\", \"ize=6, code size=16] 44: JIT compiled String:Ctor(long):String [Tier0, IL size=57, code size=155] 45\", \": JIT compiled String:wcslen(long):int [Tier0, IL size=7, code size=31] 46: JIT compiled SpanHelpers\", \":IndexOfNullCharacter(byref):int [Tier1, IL size=792, code size=388] 47: JIT compiled String:get_Len\", \"gth():int:this [Tier0, IL size=7, code size=17] 48: JIT compiled Buffer:Memmove(byref,byref,long) [T\", \"ier0, IL size=59, code size=102] 49: JIT compiled RuntimeHelpers:IsReferenceOrContainsReferences():b\", \"ool [Tier0, IL size=2, code size=8] 50: JIT compiled Buffer:Memmove(byref,byref,long) [Tier0, IL siz\", \"e=480, code size=678] 51: JIT compiled Dictionary`2:Add(__Canon,__Canon):this [Tier0, IL size=11, co\", \"de size=55] 52: JIT compiled Dictionary`2:TryInsert(__Canon,__Canon,ubyte):bool:this [Tier0, IL size\", \"=675, code size=2467] 53: JIT compiled OrdinalComparer:GetHashCode(String):int:this [Tier0, IL size=\", \"7, code size=37] 54: JIT compiled String:GetNonRandomizedHashCode():int:this [Tier0, IL size=110, co\", \"de size=290] 55: JIT compiled BitOperations:RotateLeft(int,int):int [Tier0, IL size=17, code size=20\", \"] 56: JIT compiled Dictionary`2:GetBucket(int):byref:this [Tier0, IL size=29, code size=90] 57: JIT \", \"compiled HashHelpers:FastMod(int,int,long):int [Tier0, IL size=20, code size=70] 58: JIT compiled Ty\", \"pe:get_IsValueType():bool:this [Tier0, IL size=7, code size=39] 59: JIT compiled RuntimeType:IsValue\", \"TypeImpl():bool:this [Tier0, IL size=54, code size=158] 60: JIT compiled RuntimeType:GetNativeTypeHa\", \"ndle():TypeHandle:this [Tier0, IL size=12, code size=48] 61: JIT compiled TypeHandle:.ctor(long):thi\", \"s [Tier0, IL size=8, code size=25] 62: JIT compiled TypeHandle:get_IsTypeDesc():bool:this [Tier0, IL\", \" size=14, code size=38] 63: JIT compiled TypeHandle:AsMethodTable():long:this [Tier0, IL size=7, cod\", \"e size=17] 64: JIT compiled MethodTable:get_IsValueType():bool:this [Tier0, IL size=20, code size=32\", \"] 65: JIT compiled GC:KeepAlive(Object) [Tier0, IL size=1, code size=10] 66: JIT compiled Buffer:_Me\", \"mmove(byref,byref,long) [Tier0, IL size=25, code size=279] 67: JIT compiled Environment:InitializeCo\", \"mmandLineArgs(long,int,long):ref [Tier0, IL size=75, code size=332] 68: JIT compiled Environment:.cc\", \"tor() [Tier0, IL size=11, code size=163] 69: JIT compiled StartupHookProvider:ProcessStartupHooks() \", \"[Tier-0 switched to FullOpts, IL size=365, code size=1053] 70: JIT compiled StartupHookProvider:get_\", \"IsSupported():bool [Tier0, IL size=18, code size=60] 71: JIT compiled AppContext:TryGetSwitch(String\", \",byref):bool [Tier0, IL size=97, code size=322] 72: JIT compiled ArgumentException:ThrowIfNullOrEmpt\", \"y(String,String) [Tier0, IL size=16, code size=53] 73: JIT compiled String:IsNullOrEmpty(String):boo\", \"l [Tier0, IL size=15, code size=58] 74: JIT compiled AppContext:GetData(String):Object [Tier0, IL si\", \"ze=64, code size=205] 75: JIT compiled ArgumentNullException:ThrowIfNull(Object,String) [Tier0, IL s\", \"ize=10, code size=42] 76: JIT compiled Monitor:Enter(Object,byref) [Tier0, IL size=17, code size=55]\", \"\\n```\\n\\n```\\n77: JIT compiled Dictionary`2:TryGetValue(__Canon,byref):bool:this [Tier0, IL size=39, cod\", \"e size=97] 78: JIT compiled Dictionary`2:FindValue(__Canon):byref:this [Tier0, IL size=391, code siz\", \"e=1466] 79: JIT compiled EventSource:.cctor() [Tier0, IL size=34, code size=80] 80: JIT compiled Eve\", \"ntSource:InitializeIsSupported():bool [Tier0, IL size=18, code size=60] 81: JIT compiled RuntimeEven\", \"tSource:.ctor():this [Tier0, IL size=55, code size=184] 82: JIT compiled Guid:.ctor(int,short,short,\", \"ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte):this [Tier0, IL size=86, code size=132] 83: JIT com\", \"piled EventSource:.ctor(Guid,String):this [Tier0, IL size=11, code size=90] 84: JIT compiled EventSo\", \"urce:.ctor(Guid,String,int,ref):this [Tier0, IL size=58, code size=187] 85: JIT compiled EventSource\", \":get_IsSupported():bool [Tier0, IL size=6, code size=11] 86: JIT compiled TraceLoggingEventHandleTab\", \"le:.ctor():this [Tier0, IL size=20, code size=67] 87: JIT compiled EventSource:ValidateSettings(int)\", \":int [Tier0, IL size=37, code size=147] 88: JIT compiled EventSource:Initialize(Guid,String,ref):thi\", \"s [Tier0, IL size=418, code size=1584] 89: JIT compiled Guid:op_Equality(Guid,Guid):bool [Tier0, IL \", \"size=10, code size=39] 90: JIT compiled Guid:EqualsCore(byref,byref):bool [Tier0, IL size=132, code \", \"size=171] 91: JIT compiled ActivityTracker:get_Instance():ActivityTracker [Tier0, IL size=6, code si\", \"ze=49] 92: JIT compiled ActivityTracker:.cctor() [Tier0, IL size=11, code size=71] 93: JIT compiled \", \"ActivityTracker:.ctor():this [Tier0, IL size=7, code size=31] 94: JIT compiled RuntimeEventSource:ge\", \"t_ProviderMetadata():ReadOnlySpan`1:this [Tier0, IL size=13, code size=91] 95: JIT compiled ReadOnly\", \"Span`1:.ctor(long,int):this [Tier0, IL size=51, code size=115] 96: JIT compiled RuntimeHelpers:IsRef\", \"erenceOrContainsReferences():bool [Tier0, IL size=2, code size=8] 97: JIT compiled ReadOnlySpan`1:ge\", \"t_Length():int:this [Tier0, IL size=7, code size=17] 98: JIT compiled OverrideEventProvider:.ctor(Ev\", \"entSource,int):this [Tier0, IL size=22, code size=68] 99: JIT compiled EventProvider:.ctor(int):this\", \" [Tier0, IL size=46, code size=194] 100: JIT compiled EtwEventProvider:.ctor():this [Tier0, IL size=\", \"7, code size=31] 101: JIT compiled EventProvider:Register(EventSource):this [Tier0, IL size=48, code\", \" size=186] 102: JIT compiled MulticastDelegate:CtorClosed(Object,long):this [Tier0, IL size=23, code\", \" size=70] 103: JIT compiled EventProvider:EventRegister(EventSource,EtwEnableCallback):int:this [Tie\", \"r0, IL size=53, code size=154] 104: JIT compiled EventSource:get_Name():String:this [Tier0, IL size=\", \"7, code size=18] 105: JIT compiled EventSource:get_Guid():Guid:this [Tier0, IL size=7, code size=41]\", \" 106: JIT compiled EtwEventProvider:System.Diagnostics.Tracing.IEventProvider.EventRegister(EventSou\", \"rce,EtwEna bleCallback,long,byref):int:this [Tier0, IL size=19, code size=71] 107: JIT compiled Adva\", \"pi32:EventRegister(byref,EtwEnableCallback,long,byref):int [Tier0, IL size=53, code size=374] 108: J\", \"IT compiled Marshal:GetFunctionPointerForDelegate(__Canon):long [Tier0, IL size=17, code size=54] 10\", \"9: JIT compiled Marshal:GetFunctionPointerForDelegate(Delegate):long [Tier0, IL size=18, code size=5\", \"3] 110: JIT compiled EventPipeEventProvider:.ctor():this [Tier0, IL size=18, code size=41] 111: JIT \", \"compiled EventListener:get_EventListenersLock():Object [Tier0, IL size=41, code size=157] 112: JIT c\", \"ompiled List`1:.ctor(int):this [Tier0, IL size=47, code size=275] 113: JIT compiled Interlocked:Comp\", \"areExchange(byref,__Canon,__Canon):__Canon [Tier0, IL size=9, code size=50] 114: JIT compiled Native\", \"RuntimeEventSource:.cctor() [Tier0, IL size=11, code size=71] 115: JIT compiled NativeRuntimeEventSo\", \"urce:.ctor():this [Tier0, IL size=63, code size=184]\\n```\\n\\n```\\n116: JIT compiled Guid:.ctor(int,ushor\", \"t,ushort,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte):this [Tier0, IL size=88, code size=132] 11\", \"7: JIT compiled NativeRuntimeEventSource:get_ProviderMetadata():ReadOnlySpan`1:this [Tier0, IL size=\", \"13, code size=91] 118: JIT compiled EventPipeEventProvider:System.Diagnostics.Tracing.IEventProvider\", \".EventRegister(EventSource, EtwEnableCallback,long,byref):int:this [Tier0, IL size=44, code size=118\", \"] 119: JIT compiled EventPipeInternal:CreateProvider(String,EtwEnableCallback):long [Tier0, IL size=\", \"43, code size=320] 120: JIT compiled Utf16StringMarshaller:GetPinnableReference(String):byref [Tier0\", \", IL size=13, code size=50] 121: JIT compiled String:GetPinnableReference():byref:this [Tier0, IL si\", \"ze=7, code size=24] 122: JIT compiled EventListener:AddEventSource(EventSource) [Tier0, IL size=175,\", \" code size=560] 123: JIT compiled List`1:get_Count():int:this [Tier0, IL size=7, code size=17] 124: \", \"JIT compiled WeakReference`1:.ctor(__Canon):this [Tier0, IL size=9, code size=42] 125: JIT compiled \", \"WeakReference`1:.ctor(__Canon,bool):this [Tier0, IL size=15, code size=60] 126: JIT compiled List`1:\", \"Add(__Canon):this [Tier0, IL size=60, code size=124] 127: JIT compiled String:op_Inequality(String,S\", \"tring):bool [Tier0, IL size=11, code size=46] 128: JIT compiled String:Equals(String,String):bool [T\", \"ier0, IL size=36, code size=114] 129: JIT compiled ReadOnlySpan`1:GetPinnableReference():byref:this \", \"[Tier0, IL size=23, code size=57] 130: JIT compiled EventProvider:SetInformation(int,long,int):int:t\", \"his [Tier0, IL size=38, code size=131] 131: JIT compiled ILStubClass:IL_STUB_PInvoke(long,int,long,i\", \"nt):int [FullOpts, IL size=62, code size=170] 132: JIT compiled Program:Main() [Tier0, IL size=11, c\", \"ode size=36] 133: JIT compiled Console:WriteLine(String) [Tier0, IL size=12, code size=59] 134: JIT \", \"compiled Console:get_Out():TextWriter [Tier0, IL size=20, code size=113] 135: JIT compiled Console:.\", \"cctor() [Tier0, IL size=11, code size=71] 136: JIT compiled Volatile:Read(byref):__Canon [Tier0, IL \", \"size=6, code size=21] 137: JIT compiled Console:<get_Out>g__EnsureInitialized|26_0():TextWriter [Tie\", \"r0, IL size=63, code size=209] 138: JIT compiled ConsolePal:OpenStandardOutput():Stream [Tier0, IL s\", \"ize=34, code size=130] 139: JIT compiled Console:get_OutputEncoding():Encoding [Tier0, IL size=72, c\", \"ode size=237] 140: JIT compiled ConsolePal:get_OutputEncoding():Encoding [Tier0, IL size=11, code si\", \"ze=200] 141: JIT compiled NativeLibrary:LoadLibraryCallbackStub(String,Assembly,bool,int):long [Tier\", \"0, IL size=63, code size=280] 142: JIT compiled EncodingHelper:GetSupportedConsoleEncoding(int):Enco\", \"ding [Tier0, IL size=53, code size=186] 143: JIT compiled Encoding:GetEncoding(int):Encoding [Tier0,\", \" IL size=340, code size=1025] 144: JIT compiled EncodingProvider:GetEncodingFromProvider(int):Encodi\", \"ng [Tier0, IL size=51, code size=232] 145: JIT compiled Encoding:FilterDisallowedEncodings(Encoding)\", \":Encoding [Tier0, IL size=29, code size=84] 146: JIT compiled LocalAppContextSwitches:get_EnableUnsa\", \"feUTF7Encoding():bool [Tier0, IL size=16, code size=46] 147: JIT compiled LocalAppContextSwitches:Ge\", \"tCachedSwitchValue(String,byref):bool [Tier0, IL size=22, code size=76] 148: JIT compiled LocalAppCo\", \"ntextSwitches:GetCachedSwitchValueInternal(String,byref):bool [Tier0, IL size=46, code size=168] 149\", \": JIT compiled LocalAppContextSwitches:GetSwitchDefaultValue(String):bool [Tier0, IL size=32, code s\", \"ize=98] 150: JIT compiled String:op_Equality(String,String):bool [Tier0, IL size=8, code size=39] 15\", \"1: JIT compiled Encoding:get_Default():Encoding [Tier0, IL size=6, code size=49]\\n```\\n\\n```\\n152: JIT c\", \"ompiled Encoding:.cctor() [Tier0, IL size=12, code size=73] 153: JIT compiled UTF8EncodingSealed:.ct\", \"or(bool):this [Tier0, IL size=8, code size=40] 154: JIT compiled UTF8Encoding:.ctor(bool):this [Tier\", \"0, IL size=14, code size=43] 155: JIT compiled UTF8Encoding:.ctor():this [Tier0, IL size=12, code si\", \"ze=36] 156: JIT compiled Encoding:.ctor(int):this [Tier0, IL size=42, code size=152] 157: JIT compil\", \"ed UTF8Encoding:SetDefaultFallbacks():this [Tier0, IL size=64, code size=212] 158: JIT compiled Enco\", \"derReplacementFallback:.ctor(String):this [Tier0, IL size=110, code size=360] 159: JIT compiled Enco\", \"derFallback:.ctor():this [Tier0, IL size=7, code size=31] 160: JIT compiled String:get_Chars(int):us\", \"hort:this [Tier0, IL size=29, code size=61] 161: JIT compiled Char:IsSurrogate(ushort):bool [Tier0, \", \"IL size=17, code size=43] 162: JIT compiled Char:IsBetween(ushort,ushort,ushort):bool [Tier0, IL siz\", \"e=12, code size=52] 163: JIT compiled DecoderReplacementFallback:.ctor(String):this [Tier0, IL size=\", \"110, code size=360] 164: JIT compiled DecoderFallback:.ctor():this [Tier0, IL size=7, code size=31] \", \"165: JIT compiled Encoding:get_CodePage():int:this [Tier0, IL size=7, code size=17] 166: JIT compile\", \"d Encoding:get_UTF8():Encoding [Tier0, IL size=6, code size=49] 167: JIT compiled UTF8Encoding:.ccto\", \"r() [Tier0, IL size=12, code size=76] 168: JIT compiled Volatile:Write(byref,__Canon) [Tier0, IL siz\", \"e=6, code size=32] 169: JIT compiled ConsolePal:GetStandardFile(int,int,bool):Stream [Tier0, IL size\", \"=50, code size=183] 170: JIT compiled ConsolePal:get_InvalidHandleValue():long [Tier0, IL size=7, co\", \"de size=41] 171: JIT compiled IntPtr:.ctor(int):this [Tier0, IL size=9, code size=25] 172: JIT compi\", \"led ConsolePal:ConsoleHandleIsWritable(long):bool [Tier0, IL size=26, code size=68] 173: JIT compile\", \"d Kernel32:WriteFile(long,long,int,byref,long):int [Tier0, IL size=46, code size=294] 174: JIT compi\", \"led Marshal:SetLastSystemError(int) [Tier0, IL size=7, code size=40] 175: JIT compiled Marshal:GetLa\", \"stSystemError():int [Tier0, IL size=6, code size=34] 176: JIT compiled WindowsConsoleStream:.ctor(lo\", \"ng,int,bool):this [Tier0, IL size=37, code size=90] 177: JIT compiled ConsoleStream:.ctor(int):this \", \"[Tier0, IL size=31, code size=71] 178: JIT compiled Stream:.ctor():this [Tier0, IL size=7, code size\", \"=31] 179: JIT compiled MarshalByRefObject:.ctor():this [Tier0, IL size=7, code size=31] 180: JIT com\", \"piled Kernel32:GetFileType(long):int [Tier0, IL size=27, code size=217] 181: JIT compiled Console:Cr\", \"eateOutputWriter(Stream):TextWriter [Tier0, IL size=50, code size=230] 182: JIT compiled Stream:.cct\", \"or() [Tier0, IL size=11, code size=71] 183: JIT compiled NullStream:.ctor():this [Tier0, IL size=7, \", \"code size=31] 184: JIT compiled EncodingExtensions:RemovePreamble(Encoding):Encoding [Tier0, IL size\", \"=25, code size=118] 185: JIT compiled UTF8EncodingSealed:get_Preamble():ReadOnlySpan`1:this [Tier0, \", \"IL size=24, code size=99] 186: JIT compiled UTF8Encoding:get_PreambleSpan():ReadOnlySpan`1 [Tier0, I\", \"L size=12, code size=87] 187: JIT compiled ConsoleEncoding:.ctor(Encoding):this [Tier0, IL size=14, \", \"code size=52] 188: JIT compiled Encoding:.ctor():this [Tier0, IL size=8, code size=33] 189: JIT comp\", \"iled Encoding:SetDefaultFallbacks():this [Tier0, IL size=23, code size=65] 190: JIT compiled Encoder\", \"Fallback:get_ReplacementFallback():EncoderFallback [Tier0, IL size=6, code size=49] 191: JIT compile\", \"d EncoderReplacementFallback:.cctor() [Tier0, IL size=11, code size=71] 192: JIT compiled EncoderRep\", \"lacementFallback:.ctor():this [Tier0, IL size=12, code size=44] 193: JIT compiled DecoderFallback:ge\", \"t_ReplacementFallback():DecoderFallback [Tier0, IL size=6, code size=49] 194: JIT compiled DecoderRe\", \"placementFallback:.cctor() [Tier0, IL size=11, code size=71] 195: JIT compiled DecoderReplacementFal\", \"lback:.ctor():this [Tier0, IL size=12, code size=44]\\n```\\n\\n```\\n196: JIT compiled StreamWriter:.ctor(S\", \"tream,Encoding,int,bool):this [Tier0, IL size=201, code size=564] 197: JIT compiled Task:get_Complet\", \"edTask():Task [Tier0, IL size=6, code size=49] 198: JIT compiled Task:.cctor() [Tier0, IL size=76, c\", \"ode size=316] 199: JIT compiled TaskFactory:.ctor():this [Tier0, IL size=7, code size=31] 200: JIT c\", \"ompiled Task`1:.ctor(bool,VoidTaskResult,int,CancellationToken):this [Tier0, IL size=21, code size=7\", \"5] 201: JIT compiled Task:.ctor(bool,int,CancellationToken):this [Tier0, IL size=70, code size=181] \", \"202: JIT compiled <>c:.cctor() [Tier0, IL size=11, code size=71] 203: JIT compiled <>c:.ctor():this \", \"[Tier0, IL size=7, code size=31] 204: JIT compiled TextWriter:.ctor(IFormatProvider):this [Tier0, IL\", \" size=36, code size=124] 205: JIT compiled TextWriter:.cctor() [Tier0, IL size=26, code size=108] 20\", \"6: JIT compiled NullTextWriter:.ctor():this [Tier0, IL size=7, code size=31] 207: JIT compiled TextW\", \"riter:.ctor():this [Tier0, IL size=29, code size=103] 208: JIT compiled String:ToCharArray():ref:thi\", \"s [Tier0, IL size=52, code size=173] 209: JIT compiled MemoryMarshal:GetArrayDataReference(ref):byre\", \"f [Tier0, IL size=7, code size=24] 210: JIT compiled ConsoleStream:get_CanWrite():bool:this [Tier0, \", \"IL size=7, code size=18] 211: JIT compiled ConsoleEncoding:GetEncoder():Encoder:this [Tier0, IL size\", \"=12, code size=57] 212: JIT compiled UTF8Encoding:GetEncoder():Encoder:this [Tier0, IL size=7, code \", \"size=63] 213: JIT compiled EncoderNLS:.ctor(Encoding):this [Tier0, IL size=37, code size=102] 214: J\", \"IT compiled Encoder:.ctor():this [Tier0, IL size=7, code size=31] 215: JIT compiled Encoding:get_Enc\", \"oderFallback():EncoderFallback:this [Tier0, IL size=7, code size=18] 216: JIT compiled EncoderNLS:Re\", \"set():this [Tier0, IL size=24, code size=92] 217: JIT compiled ConsoleStream:get_CanSeek():bool:this\", \" [Tier0, IL size=2, code size=12] 218: JIT compiled StreamWriter:set_AutoFlush(bool):this [Tier0, IL\", \" size=25, code size=72] 219: JIT compiled StreamWriter:CheckAsyncTaskInProgress():this [Tier0, IL si\", \"ze=19, code size=47] 220: JIT compiled Task:get_IsCompleted():bool:this [Tier0, IL size=16, code siz\", \"e=40] 221: JIT compiled Task:IsCompletedMethod(int):bool [Tier0, IL size=11, code size=25] 222: JIT \", \"compiled StreamWriter:Flush(bool,bool):this [Tier0, IL size=272, code size=1127] 223: JIT compiled S\", \"treamWriter:ThrowIfDisposed():this [Tier0, IL size=15, code size=43] 224: JIT compiled Encoding:get_\", \"Preamble():ReadOnlySpan`1:this [Tier0, IL size=12, code size=70] 225: JIT compiled ConsoleEncoding:G\", \"etPreamble():ref:this [Tier0, IL size=6, code size=27] 226: JIT compiled Array:Empty():ref [Tier0, I\", \"L size=6, code size=49] 227: JIT compiled EmptyArray`1:.cctor() [Tier0, IL size=12, code size=52] 22\", \"8: JIT compiled ReadOnlySpan`1:op_Implicit(ref):ReadOnlySpan`1 [Tier0, IL size=7, code size=79] 229:\", \" JIT compiled ReadOnlySpan`1:.ctor(ref):this [Tier0, IL size=33, code size=81] 230: JIT compiled Mem\", \"oryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, code size=24] 231: JIT compiled Conso\", \"leEncoding:GetMaxByteCount(int):int:this [Tier0, IL size=13, code size=63] 232: JIT compiled UTF8Enc\", \"odingSealed:GetMaxByteCount(int):int:this [Tier0, IL size=20, code size=50] 233: JIT compiled Span`1\", \":.ctor(long,int):this [Tier0, IL size=51, code size=115] 234: JIT compiled ReadOnlySpan`1:.ctor(ref,\", \"int,int):this [Tier0, IL size=65, code size=147] 235: JIT compiled Encoder:GetBytes(ReadOnlySpan`1,S\", \"pan`1,bool):int:this [Tier0, IL size=44, code size=234] 236: JIT compiled MemoryMarshal:GetNonNullPi\", \"nnableReference(ReadOnlySpan`1):byref [Tier0, IL size=30, code size=54] 237: JIT compiled ReadOnlySp\", \"an`1:get_Length():int:this [Tier0, IL size=7, code size=17] 238: JIT compiled MemoryMarshal:GetNonNu\", \"llPinnableReference(Span`1):byref [Tier0, IL size=30, code size=54] 239: JIT compiled Span`1:get_Len\", \"gth():int:this [Tier0, IL size=7, code size=17]\\n```\\n\\n```\\n240: JIT compiled EncoderNLS:GetBytes(long,\", \"int,long,int,bool):int:this [Tier0, IL size=92, code size=279] 241: JIT compiled ArgumentNullExcepti\", \"on:ThrowIfNull(long,String) [Tier0, IL size=12, code size=45] 242: JIT compiled Encoding:GetBytes(lo\", \"ng,int,long,int,EncoderNLS):int:this [Tier0, IL size=57, code size=187] 243: JIT compiled EncoderNLS\", \":get_HasLeftoverData():bool:this [Tier0, IL size=35, code size=105] 244: JIT compiled UTF8Encoding:G\", \"etBytesFast(long,int,long,int,byref):int:this [Tier0, IL size=33, code size=119] 245: JIT compiled U\", \"tf8Utility:TranscodeToUtf8(long,int,long,int,byref,byref):int [Tier0, IL size=1446, code size=3208] \", \"246: JIT compiled Math:Min(int,int):int [Tier0, IL size=8, code size=28] 247: JIT compiled ASCIIUtil\", \"ity:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL size=490, code size=1187] 248: JIT compiled W\", \"indowsConsoleStream:Flush():this [Tier0, IL size=26, code size=56] 249: JIT compiled ConsoleStream:F\", \"lush():this [Tier0, IL size=1, code size=10] 250: JIT compiled TextWriter:Synchronized(TextWriter):T\", \"extWriter [Tier0, IL size=28, code size=121] 251: JIT compiled SyncTextWriter:.ctor(TextWriter):this\", \" [Tier0, IL size=14, code size=52] 252: JIT compiled SyncTextWriter:WriteLine(String):this [Tier0, I\", \"L size=13, code size=140] 253: JIT compiled StreamWriter:WriteLine(String):this [Tier0, IL size=20, \", \"code size=110] 254: JIT compiled String:op_Implicit(String):ReadOnlySpan`1 [Tier0, IL size=31, code \", \"size=171] 255: JIT compiled String:GetRawStringData():byref:this [Tier0, IL size=7, code size=24] 25\", \"6: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, code size=39] 257: JIT comp\", \"iled StreamWriter:WriteSpan(ReadOnlySpan`1,bool):this [Tier0, IL size=368, code size=1036] 258: JIT \", \"compiled MemoryMarshal:GetReference(ReadOnlySpan`1):byref [Tier0, IL size=8, code size=17] 259: JIT \", \"compiled Buffer:MemoryCopy(long,long,long,long) [Tier0, IL size=21, code size=83] 260: JIT compiled \", \"Unsafe:ReadUnaligned(long):long [Tier0, IL size=10, code size=17] 261: JIT compiled ASCIIUtility:All\", \"CharsInUInt64AreAscii(long):bool [Tier0, IL size=16, code size=38] 262: JIT compiled ASCIIUtility:Na\", \"rrowFourUtf16CharsToAsciiAndWriteToBuffer(byref,long) [Tier0, IL size=107, code size=171] 263: JIT c\", \"ompiled Unsafe:WriteUnaligned(byref,int) [Tier0, IL size=11, code size=22] 264: JIT compiled Unsafe:\", \"ReadUnaligned(long):int [Tier0, IL size=10, code size=16] 265: JIT compiled ASCIIUtility:AllCharsInU\", \"Int32AreAscii(int):bool [Tier0, IL size=11, code size=25] 266: JIT compiled ASCIIUtility:NarrowTwoUt\", \"f16CharsToAsciiAndWriteToBuffer(byref,int) [Tier0, IL size=24, code size=35] 267: JIT compiled Span`\", \"1:Slice(int,int):Span`1:this [Tier0, IL size=39, code size=135] 268: JIT compiled Span`1:.ctor(byref\", \",int):this [Tier0, IL size=15, code size=39] 269: JIT compiled Span`1:op_Implicit(Span`1):ReadOnlySp\", \"an`1 [Tier0, IL size=19, code size=90] 270: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0\", \", IL size=15, code size=39] 271: JIT compiled WindowsConsoleStream:Write(ReadOnlySpan`1):this [Tier0\", \", IL size=35, code size=149] 272: JIT compiled WindowsConsoleStream:WriteFileNative(long,ReadOnlySpa\", \"n`1,bool):int [Tier0, IL size=107, code size=272] 273: JIT compiled ReadOnlySpan`1:get_IsEmpty():boo\", \"l:this [Tier0, IL size=10, code size=24] Hello, world! 274: JIT compiled AppContext:OnProcessExit() \", \"[Tier0, IL size=43, code size=161] 275: JIT compiled AssemblyLoadContext:OnProcessExit() [Tier0, IL \", \"size=101, code size=442] 276: JIT compiled EventListener:DisposeOnShutdown() [Tier0, IL size=150, co\", \"de size=618] 277: JIT compiled List`1:.ctor():this [Tier0, IL size=18, code size=133] 278: JIT compi\", \"led List`1:.cctor() [Tier0, IL size=12, code size=129] 279: JIT compiled List`1:GetEnumerator():Enum\", \"erator:this [Tier0, IL size=7, code size=162] 280: JIT compiled Enumerator:.ctor(List`1):this [Tier0\", \", IL size=39, code size=64] 281: JIT compiled Enumerator:MoveNext():bool:this [Tier0, IL size=81, co\", \"de size=159]\\n```\\n\\n```\\n282: JIT compiled Enumerator:get_Current():__Canon:this [Tier0, IL size=7, cod\", \"e size=22] 283: JIT compiled WeakReference`1:TryGetTarget(byref):bool:this [Tier0, IL size=24, code \", \"size=66] 284: JIT compiled List`1:AddWithResize(__Canon):this [Tier0, IL size=39, code size=85] 285:\", \" JIT compiled List`1:Grow(int):this [Tier0, IL size=53, code size=121] 286: JIT compiled List`1:set_\", \"Capacity(int):this [Tier0, IL size=86, code size=342] 287: JIT compiled CastHelpers:StelemRef_Helper\", \"(byref,long,Object) [Tier0, IL size=34, code size=104] 288: JIT compiled CastHelpers:StelemRef_Helpe\", \"r_NoCacheLookup(byref,long,Object) [Tier0, IL size=26, code size=111] 289: JIT compiled Enumerator:M\", \"oveNextRare():bool:this [Tier0, IL size=57, code size=80] 290: JIT compiled Enumerator:Dispose():thi\", \"s [Tier0, IL size=1, code size=14] 291: JIT compiled EventSource:Dispose():this [Tier0, IL size=14, \", \"code size=54] 292: JIT compiled EventSource:Dispose(bool):this [Tier0, IL size=124, code size=236] 2\", \"93: JIT compiled EventProvider:Dispose():this [Tier0, IL size=14, code size=54] 294: JIT compiled Ev\", \"entProvider:Dispose(bool):this [Tier0, IL size=90, code size=230] 295: JIT compiled EventProvider:Ev\", \"entUnregister(long):this [Tier0, IL size=14, code size=50] 296: JIT compiled EtwEventProvider:System\", \".Diagnostics.Tracing.IEventProvider.EventUnregister(long):int:this [Tier0, IL size=7, code size=181]\", \" 297: JIT compiled GC:SuppressFinalize(Object) [Tier0, IL size=18, code size=53] 298: JIT compiled E\", \"ventPipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventUnregister(long):int: this [Tie\", \"r0, IL size=13, code size=187]\\n```\\n\\nWith that out of the way, let's move on to actual performance im\", \"provements, starting with on -stack replacement.\\n\\n## On-Stack Replacement\\n\\nOn-stack replacement (OSR\", \") is one of the coolest features to hit the JIT in .NET 7. But to really understand OSR, we first ne\", \"ed to understand tiered compilation, so a quick recap\\u2026\\n\\nOne of the issues a managed environment with\", \" a JIT compiler has to deal with is tradeoffs between startup and throughput. Historically, the job \", \"of an optimizing compiler is to, well, optimize, in order to enable the best possible throughput of \", \"the application or service once running. But such optimization takes analysis, takes time, and perfo\", \"rming all of that work then leads to increased startup time, as all of the code on the startup path \", \"(e.g. all of the code that needs to be run before a web server can serve the first request) needs to\", \" be compiled. So a JIT compiler needs to make tradeoffs: better throughput at the expense of longer \", \"startup time, or better startup time at the expense of decreased throughput. For some kinds of apps \", \"and services, the tradeoff is an easy call, e.g. if your service starts up once and then runs for da\", \"ys, several extra seconds of startup time doesn't matter, or if you're a console application that's \", \"going to do a quick computation and exit, startup time is all that matters. But how can the JIT know\", \" which scenario it's in, and do we really want every developer having to know about these kinds of s\", \"ettings and tradeoffs and configure every one of their applications accordingly? One answer to this \", \"has been ahead-of-time compilation, which has taken various forms in .NET. For example, all of the c\", \"ore libraries are 'crossgen''d, meaning they've been run through a tool that produces the previously\", \" mentioned R2R format, yielding binaries that contain assembly code that needs only minor tweaks to \", \"actually execute; not every method can have code generated for it, but enough that it significantly \", \"reduces startup time. Of course, such approaches have their own downsides, e.g. one of the promises \", \"of a JIT compiler is it can take advantage of knowledge of the current machine / process in order to\", \" best optimize, so for example the R2R images have to assume a\\n\\ncertain baseline instruction set (e.\", \"g. what vectorizing instructions are available) whereas the JIT can see what's actually available an\", \"d use the best. 'Tiered compilation' provides another answer, one that's usable with or without thes\", \"e other ahead-of-time (AOT) compilation solutions.\\n\\nTiered compilation enables the JIT to have its p\", \"roverbial cake and eat it, too. The idea is simple: allow the JIT to compile the same code multiple \", \"times. The first time, the JIT can use as a few optimizations as make sense (a handful of optimizati\", \"ons can actually make the JIT's own throughput faster, so those still make sense to apply), producin\", \"g fairly unoptimized assembly code but doing so really quickly. And when it does so, it can add some\", \" instrumentation into the assembly to track how often the methods are called. As it turns out, many \", \"functions used on a startup path are invoked once or maybe only a handful of times, and it would tak\", \"e more time to optimize them than it does to just execute them unoptimized. Then, when the method's \", \"instrumentation triggers some threshold, for example a method having been executed 30 times, a work \", \"item gets queued to recompile that method, but this time with all the optimizations the JIT can thro\", \"w at it. This is lovingly referred to as 'tiering up.' Once that recompilation has completed, call s\", \"ites to the method are patched with the address of the newly highly optimized assembly code, and fut\", \"ure invocations will then take the fast path. So, we get faster startup and faster sustained through\", \"put. At least, that's the h ope.\\n\\nA problem, however, is methods that don't fit this mold. While it'\", \"s certainly the case that many performancesensitive methods are relatively quick and executed many, \", \"many, many times, there's also a large number of performance-sensitive methods that are executed jus\", \"t a handful of times, or maybe even only once, but that take a very long time to execute, maybe even\", \" the duration of the whole process: methods with loops. As a result, by default tiered compilation h\", \"asn't applied to loops, though it can be enabled by setting the DOTNET\\\\_TC\\\\_QuickJitForLoops environ\", \"ment variable to 1 . We can see the effect of this by trying this simple console app with .NET 6. Wi\", \"th the default settings, run this app:\\n\\n```\\nclass Program { static void Main() { var sw = new System\", \".Diagnostics.Stopwatch(); while ( true ) { sw.Restart(); for (int trial = 0; trial < 10_000; trial++\", \") { int count = 0; for (int i = 0; i < char.MaxValue; i++) if (IsAsciiDigit((char)i)) count++; } sw.\", \"Stop(); Console.WriteLine(sw.Elapsed); } static bool IsAsciiDigit(char c) => (uint)(c - '0') <= 9; }\", \" }\\n```\\n\\nI get numbers printed out like:\\n\\n```\\n00:00:00.5734352 00:00:00.5526667 00:00:00.5675267 00:0\", \"0:00.5588724 00:00:00.5616028\\n```\\n\\nNow, try setting DOTNET\\\\_TC\\\\_QuickJitForLoops to 1 . When I then \", \"run it again, I get numbers like this:\\n\\n```\\n00:00:01.2841397 00:00:01.2693485 00:00:01.2755646 00:00\", \":01.2656678 00:00:01.2679925\\n```\\n\\nIn other words, with DOTNET\\\\_TC\\\\_QuickJitForLoops enabled, it's ta\", \"king 2.5x as long as without (the default in .NET 6). That's because this main function never gets o\", \"ptimizations applied to it. By setting DOTNET\\\\_TC\\\\_QuickJitForLoops to 1 , we're saying 'JIT, please\", \" apply tiering to methods with loops as well,' but this method with a loop is only ever invoked once\", \", so for the duration of the process it ends up remaining at 'tier -0,' aka unoptimized. Now, let's \", \"try the same thing with .NET 7 . Regardless of whether that environment variable is set, I again get\", \" numbers like this:\\n\\n```\\n00:00:00.5528889 00:00:00.5562563 00:00:00.5622086 00:00:00.5668220 00:00:0\", \"0.5589112\\n```\\n\\nbut importantly, this method was still participating in tiering. In fact, we can get \", \"confirmation of that by using the aforementioned DOTNET\\\\_JitDisasmSummary=1 environment variable. Wh\", \"en I set that and run again, I see these lines in the output:\\n\\n```\\n4: JIT compiled Program:Main() [T\", \"ier0, IL size=83, code size=319] ... 6: JIT compiled Program:Main() [Tier1-OSR @0x27, IL size=83, co\", \"de size=380]\\n```\\n\\nhighlighting that Main was indeed compiled twice. How is that possible? On-stack r\", \"eplacement.\\n\\nThe idea behind on-stack replacement is a method can be replaced not just between invoc\", \"ations but even while it's executing, while it's 'on the stack.' In addition to the tier -0 code bei\", \"ng instrumented for call counts, loops are also instrumented for iteration counts. When the iteratio\", \"ns surpass a certain limit, the JIT compiles a new highly optimized version of that method, transfer\", \"s all the local/register state from the current invocation to the new invocation, and then jumps to \", \"the appropriate location in the new method. We can see this in action by using the previously discus\", \"sed DOTNET\\\\_JitDisasm environment variable. Set that to Program:* in order to see the assembly code \", \"generated for all of the methods in the Program class, and then run the app again. You should see ou\", \"tput like the following:\\n\\n```\\n; Assembly listing for method Program:Main() ; Emitting BLENDED_CODE f\", \"or X64 CPU with AVX - Windows ; Tier-0 compilation ; MinOpts code ; rbp based frame ; partially inte\", \"rruptible G_M000_IG01:                ;; offset=0000H 55                   push     rbp\\n```\\n\\n```\\n488\", \"1EC80000000       sub      rsp, 128 488DAC2480000000     lea      rbp, [rsp+80H] C5D857E4           \", \"  vxorps   xmm4, xmm4 C5F97F65B0           vmovdqa  xmmword ptr [rbp-50H], xmm4 33C0                \", \" xor      eax, eax 488945C0             mov      qword ptr [rbp-40H], rax G_M000_IG02:              \", \"  ;; offset=001FH 48B9002F0B50FC7F0000 mov      rcx, 0x7FFC500B2F00 E8721FB25F           call     CO\", \"RINFO_HELP_NEWSFAST 488945B0             mov      gword ptr [rbp-50H], rax 488B4DB0             mov \", \"     rcx, gword ptr [rbp-50H] FF1544C70D00         call     [Stopwatch:.ctor():this] 488B4DB0       \", \"      mov      rcx, gword ptr [rbp-50H] 48894DC0             mov      gword ptr [rbp-40H], rcx C745A\", \"8E8030000       mov      dword ptr [rbp-58H], 0x3E8 G_M000_IG03:                ;; offset=004BH 8B4D\", \"A8               mov      ecx, dword ptr [rbp-58H] FFC9                 dec      ecx 894DA8         \", \"      mov      dword ptr [rbp-58H], ecx 837DA800             cmp      dword ptr [rbp-58H], 0 7F0E   \", \"              jg       SHORT G_M000_IG05 G_M000_IG04:                ;; offset=0059H 488D4DA8       \", \"      lea      rcx, [rbp-58H] BA06000000           mov      edx, 6 E8B985AB5F           call     COR\", \"INFO_HELP_PATCHPOINT G_M000_IG05:                ;; offset=0067H 488B4DC0             mov      rcx, \", \"gword ptr [rbp-40H] 3909                 cmp      dword ptr [rcx], ecx FF1585C70D00         call    \", \" [Stopwatch:Restart():this] 33C9                 xor      ecx, ecx 894DBC               mov      dwo\", \"rd ptr [rbp-44H], ecx 33C9                 xor      ecx, ecx 894DB8               mov      dword ptr\", \" [rbp-48H], ecx EB20                 jmp      SHORT G_M000_IG08 G_M000_IG06:                ;; offse\", \"t=007FH 8B4DB8               mov      ecx, dword ptr [rbp-48H] 0FB7C9               movzx    rcx, cx\", \" FF152DD40B00         call     [Program:<Main>g__IsAsciiDigit|0_0(ushort):bool] 85C0                \", \" test     eax, eax 7408                 je       SHORT G_M000_IG07 8B4DBC               mov      ecx\", \", dword ptr [rbp-44H] FFC1                 inc      ecx 894DBC               mov      dword ptr [rbp\", \"-44H], ecx G_M000_IG07:                ;; offset=0097H 8B4DB8               mov      ecx, dword ptr \", \"[rbp-48H] FFC1                 inc      ecx 894DB8               mov      dword ptr [rbp-48H], ecx G\", \"_M000_IG08:                ;; offset=009FH 8B4DA8               mov      ecx, dword ptr [rbp-58H] FF\", \"C9                 dec      ecx 894DA8               mov      dword ptr [rbp-58H], ecx 837DA800     \", \"        cmp      dword ptr [rbp-58H], 0 7F0E                 jg       SHORT G_M000_IG10\\n```\\n\\n```\\nG_M\", \"000_IG09:                ;; offset=00ADH 488D4DA8             lea      rcx, [rbp-58H] BA23000000    \", \"       mov      edx, 35 E86585AB5F           call     CORINFO_HELP_PATCHPOINT G_M000_IG10:          \", \"      ;; offset=00BBH 817DB800CA9A3B       cmp      dword ptr [rbp-48H], 0x3B9ACA00 7CBB            \", \"     jl       SHORT G_M000_IG06 488B4DC0             mov      rcx, gword ptr [rbp-40H] 3909         \", \"        cmp      dword ptr [rcx], ecx FF1570C70D00         call     [Stopwatch:get_ElapsedMillisecon\", \"ds():long:this] 488BC8               mov      rcx, rax FF1507D00D00         call     [Console:WriteL\", \"ine(long)] E96DFFFFFF           jmp      G_M000_IG03 ; Total bytes of code 222 ; Assembly listing fo\", \"r method Program:<Main>g__IsAsciiDigit|0_0(ushort):bool ; Emitting BLENDED_CODE for X64 CPU with AVX\", \" - Windows ; Tier-0 compilation ; MinOpts code ; rbp based frame ; partially interruptible G_M000_IG\", \"01:                ;; offset=0000H 55                   push     rbp 488BEC               mov      r\", \"bp, rsp 894D10               mov      dword ptr [rbp+10H], ecx G_M000_IG02:                ;; offset\", \"=0007H 8B4510               mov      eax, dword ptr [rbp+10H] 0FB7C0               movzx    rax, ax \", \"83C0D0               add      eax, -48 83F809               cmp      eax, 9 0F96C0               set\", \"be    al 0FB6C0               movzx    rax, al G_M000_IG03:                ;; offset=0019H 5D       \", \"            pop      rbp C3                   ret\\n```\\n\\nA few relevant things to notice here. First, \", \"the comments at the top highlight how this code was compiled:\\n\\n```\\n; Tier-0 compilation ; MinOpts co\", \"de\\n```\\n\\nSo, we know this is the initial version ('Tier -0') of the method compiled with minimal opti\", \"mization ('MinOpts'). Second, note this line of the assembly:\\n\\n```\\nFF152DD40B00         call     [Pr\", \"ogram:<Main>g__IsAsciiDigit|0_0(ushort):bool]\\n```\\n\\nOur IsAsciiDigit helper method is trivially inlin\", \"eable, but it's not getting inlined; instead, the assembly has a call to it, and indeed we can see b\", \"elow the generated code (also 'MinOpts') for IsAsciiDigit . Why? Because inlining is an optimization\", \" (a really important one) that's disabled as part of tier-0 (because the analysis for doing inlining\", \" well is also quite costly). Third, we can see the code the JIT is outputting to instrument this met\", \"hod. This is a bit more involved, but I'll point out the relevant parts. First, we see:\\n\\nC745A8E8030\", \"000       mov      dword ptr [rbp-58H], 0x3E8\\n\\nThat 0x3E8 is the hex value for the decimal 1,000, wh\", \"ich is the default number of iterations a loop needs to iterate before the JIT will generate the opt\", \"imized version of the method (this is configurable via the DOTNET\\\\_TC\\\\_OnStackReplacement\\\\_InitialCo\", \"unter environment variable). So we see 1,000 being stored into this stack location. Then a bit later\", \" in the method we see this:\\n\\n```\\nG_M000_IG03:                ;; offset=004BH 8B4DA8               mo\", \"v      ecx, dword ptr [rbp-58H] FFC9                 dec      ecx 894DA8               mov      dwor\", \"d ptr [rbp-58H], ecx 837DA800             cmp      dword ptr [rbp-58H], 0 7F0E                 jg   \", \"    SHORT G_M000_IG05 G_M000_IG04:                ;; offset=0059H 488D4DA8             lea      rcx,\", \" [rbp-58H] BA06000000           mov      edx, 6 E8B985AB5F           call     CORINFO_HELP_PATCHPOIN\", \"T G_M000_IG05:                ;; offset=0067H\\n```\\n\\nThe generated code is loading that counter into t\", \"he ecx register, decrementing it, storing it back, and then seeing whether the counter dropped to 0.\", \" If it didn't, the code skips to G\\\\_M000\\\\_IG05 , which is the label for the actual code in the rest \", \"of the loop. But if the counter did drop to 0, the JIT proceeds to store relevant state into the the\", \" rcx and edx registers and then calls the CORINFO\\\\_HELP\\\\_PATCHPOINT helper method. That helper is re\", \"sponsible for triggering the creation of the optimized method if it doesn't yet exist, fixing up all\", \" appropriate tracking state, and jumping to the new method. And indeed, if you look again at your co\", \"nsole output from running the program, you'll see yet another output for the Main method:\\n\\n```\\n; Ass\", \"embly listing for method Program:Main() ; Emitting BLENDED_CODE for X64 CPU with AVX - Windows ; Tie\", \"r-1 compilation ; OSR variant for entry point 0x23 ; optimized code ; rsp based frame ; fully interr\", \"uptible ; No PGO data ; 1 inlinees with PGO data; 8 single block inlinees; 0 inlinees without PGO da\", \"ta G_M000_IG01:                ;; offset=0000H 4883EC58             sub      rsp, 88 4889BC24D800000\", \"0     mov      qword ptr [rsp+D8H], rdi 4889B424D0000000     mov      qword ptr [rsp+D0H], rsi 48899\", \"C24C8000000     mov      qword ptr [rsp+C8H], rbx C5F877               vzeroupper 33C0              \", \"   xor      eax, eax 4889442428           mov      qword ptr [rsp+28H], rax 4889442420           mov\", \"      qword ptr [rsp+20H], rax 488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H] 8BBC249C000000\", \"       mov      edi, dword ptr [rsp+9CH] 8BB42498000000       mov      esi, dword ptr [rsp+98H] G_M0\", \"00_IG02:                ;; offset=0041H EB45                 jmp      SHORT G_M000_IG05 align    [0 \", \"bytes for IG06]\\n```\\n\\n```\\nG_M000_IG03:                ;; offset=0043H 33C9                 xor      e\", \"cx, ecx 488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H] 48894B08             mov      qword p\", \"tr [rbx+08H], rcx 488D4C2428           lea      rcx, [rsp+28H] 48B87066E68AFD7F0000 mov      rax, 0x\", \"7FFD8AE66670 G_M000_IG04:                ;; offset=0060H FFD0                 call     rax ; Kernel3\", \"2:QueryPerformanceCounter(long):int 488B442428           mov      rax, qword ptr [rsp+28H] 488B9C24A\", \"0000000     mov      rbx, gword ptr [rsp+A0H] 48894310             mov      qword ptr [rbx+10H], rax\", \" C6431801             mov      byte  ptr [rbx+18H], 1 33FF                 xor      edi, edi 33F6   \", \"              xor      esi, esi 833D92A1E55F00       cmp      dword ptr [(reloc 0x7ffcafe1ae34)], 0 \", \"0F85CA000000         jne      G_M000_IG13 G_M000_IG05:                ;; offset=0088H 81FE00CA9A3B  \", \"       cmp      esi, 0x3B9ACA00 7D17                 jge      SHORT G_M000_IG09 G_M000_IG06:        \", \"        ;; offset=0090H 0FB7CE               movzx    rcx, si 83C1D0               add      ecx, -48\", \" 83F909               cmp      ecx, 9 7702                 ja       SHORT G_M000_IG08 G_M000_IG07:  \", \"              ;; offset=009BH FFC7                 inc      edi G_M000_IG08:                ;; offse\", \"t=009DH FFC6                 inc      esi 81FE00CA9A3B         cmp      esi, 0x3B9ACA00 7CE9        \", \"         jl       SHORT G_M000_IG06 G_M000_IG09:                ;; offset=00A7H 488B6B08            \", \" mov      rbp, qword ptr [rbx+08H] 48899C24A0000000     mov      gword ptr [rsp+A0H], rbx 807B1800  \", \"           cmp      byte  ptr [rbx+18H], 0 7436                 je       SHORT G_M000_IG12 G_M000_IG\", \"10:                ;; offset=00B9H 488D4C2420           lea      rcx, [rsp+20H] 48B87066E68AFD7F0000\", \" mov      rax, 0x7FFD8AE66670 G_M000_IG11:                ;; offset=00C8H FFD0                 call \", \"    rax ; Kernel32:QueryPerformanceCounter(long):int 488B4C2420           mov      rcx, qword ptr [r\", \"sp+20H] 488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H] 482B4B10             sub      rcx, qw\", \"ord ptr [rbx+10H] 4803E9               add      rbp, rcx 833D2FA1E55F00       cmp      dword ptr [(r\", \"eloc 0x7ffcafe1ae34)], 0 48899C24A0000000     mov      gword ptr [rsp+A0H], rbx 756D                \", \" jne      SHORT G_M000_IG14 G_M000_IG12:                ;; offset=00EFH C5F857C0             vxorps \", \"  xmm0, xmm0 C4E1FB2AC5           vcvtsi2sd  xmm0, rbp C5FB11442430         vmovsd   qword ptr [rsp+\", \"30H], xmm0\\n```\\n\\n| 48B9F04BF24FFC7F0000 BAE7070000 E82E1FB25F C5FB10442430 C5FB5905E049F6FF C4E1FB2CD\", \"0 488BC1 48F7EA 488BCA   | mov rcx, 0x7FFC4FF24BF0 mov edx, 0x7E7 call CORINFO_HELP_GETSHARED_NONGCS\", \"TATIC_BASE vmovsd xmm0, qword ptr [rsp+30H] vmulsd xmm0, xmm0, qword ptr [(reloc 0x7ffc4ff25720)] vc\", \"vttsd2si rdx, xmm0 48B94B598638D6C56D34 mov rcx, 0x346DC5D63886594B mov rax, rcx imul rdx:rax, rdx m\", \"ov rcx, rdx   |\\n|-----------------------------------------------------------------------------------\", \"-------------------------|--------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"----------------------------------------------------------------------------------------------------\", \"--------------|\\n\\nHere, again, we notice a few interesting things. First, in the header we see this:\\n\", \"\\n```\\n; Tier-1 compilation ; OSR variant for entry point 0x23 ; optimized code\\n```\\n\\nso we know this i\", \"s both optimized 'tier -1' code and is the 'OSR variant' for this method. Second, notice there's no \", \"longer a call to the IsAsciiDigit helper. Instead, where that call would have been, we see this:\\n\\n| \", \"G_M000_IG06:   | ;; offset=0090H      |\\n|----------------|----------------------|\\n| 0FB7CE         |\", \" movzx rcx, si        |\\n| 83C1D0         | add ecx, -48         |\\n| 83F909         | cmp ecx, 9     \", \"      |\\n| 7702           | ja SHORT G_M000_IG08 |\\n\\nThis is loading a value into rcx , subtracting 48\", \" from it (48 is the decimal ASCII value of the '0' character) and comparing the resulting value to 9\", \". Sounds an awful lot like our IsAsciiDigit implementation ( (uint)(c - '0') &lt;= 9 ), doesn't it? \", \"That's because it is. The helper was successfully inlined in this now-optimized code.\\n\\nGreat, so now\", \" in .NET 7, we can largely avoid the tradeoffs between startup and throughput, as OSR enables tiered\", \" compilation to apply to all methods, even those that are long-running. A multitude of PRs went into\", \" enabling this, including many over the last few years, but all of the functionality was disabled in\", \" the shipping bits. Thanks to improvements like dotnet/runtime#62831 which implemented support for O\", \"SR on Arm64 (previously only x64 support was implemented), and dotnet/runtime#63406 and dotnet/runti\", \"me#65609 which revised how OSR imports and epilogs are handled, dotnet/runtime#65675 enables OSR (an\", \"d as a result DOTNET\\\\_TC\\\\_QuickJitForLoops ) by default.\\n\\nBut, tiered compilation and OSR aren't jus\", \"t about startup (though they're of course very valuable there). They're also about further improving\", \" throughput. Even though tiered compilation was originally envisioned as a way to optimize startup w\", \"hile not hurting throughput, it's become much more than that. There are various things the JIT can l\", \"earn about a method during tier-0 that it can then use for tier-1. For example, the very fact that t\", \"he tier-0 code executed means that any static s accessed by the method will have been initialized, a\", \"nd that means that any readonly static s will not only have been initialized by the time the tier1 c\", \"ode executes but their values won't ever change. And that in turn means that any readonly statics of\", \" primitive types (e.g. bool , int , etc.) can be treated like const s instead of static readonly fie\", \"lds, and during tier-1 compilation the JIT can optimize them just as it would have optimized a const\", \" . For example, try running this simple program after setting DOTNET\\\\_JitDisasm to Program:Test :\\n\\n`\", \"``\\nusing System.Runtime.CompilerServices; class Program { static readonly bool Is64Bit = Environment\", \".Is64BitProcess; static int Main() { int count = 0; for (int i = 0; i < 1_000_000_000; i++) if (Test\", \"()) count++; return count; } [MethodImpl(MethodImplOptions.NoInlining)] static bool Test() => Is64Bi\", \"t; }\\n```\\n\\nWhen I do so, I get this output:\\n\\n```\\n; Assembly listing for method Program:Test():bool ; \", \"Emitting BLENDED_CODE for X64 CPU with AVX - Windows ; Tier-0 compilation ; MinOpts code ; rbp based\", \" frame ; partially interruptible G_M000_IG01:                ;; offset=0000H 55                   pu\", \"sh     rbp 4883EC20             sub      rsp, 32 488D6C2420           lea      rbp, [rsp+20H] G_M000\", \"_IG02:                ;; offset=000AH 48B9B8639A3FFC7F0000 mov      rcx, 0x7FFC3F9A63B8 BA01000000  \", \"         mov      edx, 1 E8C220B25F           call     CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE 0FB60\", \"545580C00       movzx    rax, byte  ptr [(reloc 0x7ffc3f9a63ea)] G_M000_IG03:                ;; offs\", \"et=0025H 4883C420             add      rsp, 32 5D                   pop      rbp C3                 \", \"  ret ; Total bytes of code 43\\n```\\n\\n```\\n; Assembly listing for method Program:Test():bool ; Emitting\", \" BLENDED_CODE for X64 CPU with AVX - Windows ; Tier-1 compilation ; optimized code ; rsp based frame\", \" ; partially interruptible ; No PGO data G_M000_IG01:                ;; offset=0000H G_M000_IG02:   \", \"             ;; offset=0000H B801000000           mov      eax, 1 G_M000_IG03:                ;; off\", \"set=0005H C3                   ret ; Total bytes of code 6\\n```\\n\\nNote, again, we see two outputs for \", \"Program:Test . First, we see the 'Tier -0' code, which is accessing a static (note the call     CORI\", \"NFO\\\\_HELP\\\\_GETSHARED\\\\_NONGCSTATIC\\\\_BASE instruction). But then we see the 'Tier -1' code, where all \", \"of that overhead has vanished and is instead replaced simply by mov eax, 1 . Since the 'Tier -0' cod\", \"e had to have executed in order for it to tier up, the 'Tier -1' code was generated knowing that the\", \" value of the static readonly bool Is64Bit field was true ( 1 ), and so the entirety of this method \", \"is storing the value 1 into the eax register used for the return value.\\n\\nThis is so useful that comp\", \"onents are now written with tiering in mind. Consider the new Regex source generator, which is discu\", \"ssed later in this post (Roslyn source generators were introduced a couple of years ago; just as how\", \" Roslyn analyzers are able to plug into the compiler and surface additional diagnostics based on all\", \" of the data the compiler learns from the source code, Roslyn source generators are able to analyze \", \"that same data and then further augment the compilation unit with additional source). The Regex sour\", \"ce generator applies a technique based on this in dotnet/runtime#67775. Regex supports setting a pro\", \"cess-wide timeout that gets applied to Regex instances that don't explicitly set a timeout. That mea\", \"ns, even though it's super rare for such a process-wide timeout to be set, the Regex source generato\", \"r still needs to output timeout-related code just in case it's needed. It does so by outputting some\", \" helpers like this:\\n\\n```\\nstatic class Utilities { internal static readonly TimeSpan s_defaultTimeout\", \" = AppContext.GetData(\\\"REGEX_DEFAULT_MATCH_TIMEOUT\\\") is TimeSpan timeout ? timeout : Timeout.Infinit\", \"eTimeSpan; internal static readonly bool s_hasTimeout = s_defaultTimeout != Timeout.InfiniteTimeSpan\", \"; }\\n```\\n\\nwhich it then uses at call sites like this:\\n\\n```\\nif (Utilities.s_hasTimeout) { base .CheckT\", \"imeout(); }\\n```\\n\\nIn tier-0, these checks will still be emitted in the assembly code, but in tier-1 w\", \"here throughput matters, if the relevant AppContext switch hasn't been set, then s\\\\_defaultTimeout w\", \"ill be\\n\\nTimeout.InfiniteTimeSpan , at which point s\\\\_hasTimeout will be false . And since s\\\\_hasTime\", \"out is a static readonly bool , the JIT will be able to treat that as a const , and all conditions l\", \"ike if (Utilities.s\\\\_hasTimeout) will be treated equal to if (false) and be eliminated from the asse\", \"mbly code entirely as dead code.\\n\\nBut, this is somewhat old news. The JIT has been able to do such a\", \"n optimization since tiered compilation was introduced in .NET Core 3 .0. Now in .NET 7, though, wit\", \"h OSR it's also able to do so by default for methods with loops (and thus enable cases like the rege\", \"x one). However, the real magic of OSR comes into play when combined with another exciting feature: \", \"dynamic PGO.\\n\\n## PGO\\n\\nI wrote about profile-guided optimization (PGO) in my Performance Improvements\", \" in .NET 6 post, but I'll cover it again here as it's seen a multitude of improvements for .NET 7.\\n\\n\", \"PGO has been around for a long time, in any number of languages and compilers. The basic idea is you\", \" compile your app, asking the compiler to inject instrumentation into the application to track vario\", \"us pieces of interesting information. You then put your app through its paces, running through vario\", \"us common scenarios, causing that instrumentation to 'profile' what happens when the app is executed\", \", and the results of that are then saved out. The app is then recompiled, feeding those instrumentat\", \" ion results back into the compiler, and allowing it to optimize the app for exactly how it's expect\", \"ed to be used. This approach to PGO is referred to as 'static PGO,' as the information is all gleane\", \"d ahead of actual deployment, and it's something .NET has been doing in various forms for years. Fro\", \"m my perspective, though, the really interesting development in .NET is 'dynamic PGO,' which was int\", \"roduced in .NET 6, but off by default.\\n\\nDynamic PGO takes advantage of tiered compilation. I noted t\", \"hat the JIT instruments the tier-0 code to track how many times the method is called, or in the case\", \" of loops, how many times the loop executes. It can instrument it for other things as well. For exam\", \"ple, it can track exactly which concrete types are used as the target of an interface dispatch, and \", \"then in tier-1 specialize the code to expect the most common types (this is referred to as 'guarded \", \"devirtualization,' or GDV). You can see this in this little example. Set the DOTNET\\\\_TieredPGO envir\", \"onment variable to 1 , and then run this on .NET 7:\\n\\n```\\nclass Program { static void Main() { IPrint\", \"er printer = new Printer(); for (int i = 0; ; i++) { DoWork(printer, i); } } static void DoWork(IPri\", \"nter printer, int i) { printer.PrintIfTrue(i == int.MaxValue); } interface IPrinter { void PrintIfTr\", \"ue(bool condition);\\n```\\n\\n```\\n} class Printer : IPrinter { public void PrintIfTrue(bool condition) { \", \"if (condition) Console.WriteLine(\\\"Print!\\\"); } } }\\n```\\n\\nThe tier-0 code for DoWork ends up looking li\", \"ke this:\\n\\n```\\nG_M000_IG01:                ;; offset=0000H 55                   push     rbp 4883EC30\", \"             sub      rsp, 48 488D6C2430           lea      rbp, [rsp+30H] 33C0                 xor \", \"     eax, eax 488945F8             mov      qword ptr [rbp-08H], rax 488945F0             mov      q\", \"word ptr [rbp-10H], rax 48894D10             mov      gword ptr [rbp+10H], rcx 895518               \", \"mov      dword ptr [rbp+18H], edx G_M000_IG02:                ;; offset=001BH FF059F220F00         i\", \"nc      dword ptr [(reloc 0x7ffc3f1b2ea0)] 488B4D10             mov      rcx, gword ptr [rbp+10H] 48\", \"894DF8             mov      gword ptr [rbp-08H], rcx 488B4DF8             mov      rcx, gword ptr [r\", \"bp-08H] 48BAA82E1B3FFC7F0000 mov      rdx, 0x7FFC3F1B2EA8 E8B47EC55F           call     CORINFO_HELP\", \"_CLASSPROFILE32 488B4DF8             mov      rcx, gword ptr [rbp-08H] 48894DF0             mov     \", \" gword ptr [rbp-10H], rcx 488B4DF0             mov      rcx, gword ptr [rbp-10H] 33D2               \", \"  xor      edx, edx 817D18FFFFFF7F       cmp      dword ptr [rbp+18H], 0x7FFFFFFF 0F94C2            \", \"   sete     dl 49BB0800F13EFC7F0000 mov      r11, 0x7FFC3EF10008 41FF13               call     [r11]\", \"IPrinter:PrintIfTrue(bool):this 90                   nop G_M000_IG03:                ;; offset=0062H\", \" 4883C430             add      rsp, 48 5D                   pop      rbp C3                   ret\\n``\", \"`\\n\\nand most notably, you can see the call [r11]IPrinter:PrintIfTrue(bool):this doing the interface d\", \"ispatch. But, then look at the code generated for tier-1. We still see the call [r11]IPrinter:PrintI\", \"fTrue(bool):this , but we also see this:\\n\\n```\\nG_M000_IG02:                ;; offset=0020H 48B9982D1B\", \"3FFC7F0000 mov      rcx, 0x7FFC3F1B2D98 48390F               cmp      qword ptr [rdi], rcx 7521     \", \"            jne      SHORT G_M000_IG05 81FEFFFFFF7F         cmp      esi, 0x7FFFFFFF 7404           \", \"      je       SHORT G_M000_IG04 G_M000_IG03:                ;; offset=0037H FFC6                 in\", \"c      esi EBE5                 jmp      SHORT G_M000_IG02\\n```\\n\\n```\\nG_M000_IG04:                ;; o\", \"ffset=003BH 48B9D820801A24020000 mov      rcx, 0x2241A8020D8 488B09               mov      rcx, gwor\", \"d ptr [rcx] FF1572CD0D00         call     [Console:WriteLine(String)] EBE7                 jmp      \", \"SHORT G_M000_IG03\\n```\\n\\nThat first block is checking the concrete type of the IPrinter (stored in rdi\", \" ) and comparing it against the known type for Printer ( 0x7FFC3F1B2D98 ). If the y're different, it\", \" just jumps to the same interface dispatch it was doing in the unoptimized version. But if they're t\", \"he same, it then jumps directly to an inlined version of Printer.PrintIfTrue (you can see the call t\", \"o Console:WriteLine right there in this method). Thus, the common case (the only case in this exampl\", \"e) is super efficient at the expense of a single comparison and branch.\\n\\nThat all existed in .NET 6,\", \" so why are we talking about it now? Several things have improved. First, PGO now works with OSR, th\", \"anks to improvements like dotnet/runtime#61453 . That's a big deal, as it means hot long-running met\", \"hods that do this kind of interface dispatch (which are fairly common) can get these kinds of devirt\", \"ualization/inlining optimizations. Second, while PGO isn't currently enabled by default, we've made \", \"it much easier to turn on. Between dotnet/runtime#71438 and dotnet/sdk#26350 , it's now possible to \", \"simply put &lt;TieredPGO&gt;true&lt;/TieredPGO&gt; into your .csproj, and it'll have the sa me effec\", \"t as if you set DOTNET\\\\_TieredPGO=1 prior to every invocation of the app, enabling dynamic PGO (note\", \" that it doesn't disable use of R2R images, so if you want the entirety of the core libraries also e\", \"mploying dynamic PGO, you'll also need to set DOTNET\\\\_ReadyToRun=0 ). Third, however, is dynamic PGO\", \" has been taught how to instrument and optimize additional things.\\n\\nPGO already knew how to instrume\", \"nt virtual dispatch. Now in .NET 7, thanks in large part to dotnet/runtime#68703, it can do so for d\", \"elegates as well (at least for delegates to instance methods). Consider this simple console app:\\n\\n``\", \"`\\nusing System.Runtime.CompilerServices; class Program { static int[] s_values = Enumerable.Range(0,\", \" 1_000).ToArray(); static void Main() { for (int i = 0; i < 1_000_000; i++) Sum(s_values, i => i * 4\", \"2); } [MethodImpl(MethodImplOptions.NoInlining)] static int Sum(int[] values, Func<int, int> func) {\", \" int sum = 0; foreach (int value in values) sum += func(value); return sum; } }\\n```\\n\\nWithout PGO ena\", \"bled, I get generated optimized assembly like this:\\n\\n```\\n; Assembly listing for method Program:Sum(r\", \"ef,Func`2):int ; Emitting BLENDED_CODE for X64 CPU with AVX - Windows ; Tier-1 compilation\\n```\\n\\n```\\n\", \"; optimized code ; rsp based frame ; partially interruptible ; No PGO data G_M000_IG01:             \", \"   ;; offset=0000H 4156                 push     r14 57                   push     rdi 56           \", \"        push     rsi 55                   push     rbp 53                   push     rbx 4883EC20   \", \"          sub      rsp, 32 488BF2               mov      rsi, rdx G_M000_IG02:                ;; off\", \"set=000DH 33FF                 xor      edi, edi 488BD9               mov      rbx, rcx 33ED        \", \"         xor      ebp, ebp 448B7308             mov      r14d, dword ptr [rbx+08H] 4585F6           \", \"    test     r14d, r14d 7E16                 jle      SHORT G_M000_IG04 G_M000_IG03:                \", \";; offset=001DH 8BD5                 mov      edx, ebp 8B549310             mov      edx, dword ptr \", \"[rbx+4*rdx+10H] 488B4E08             mov      rcx, gword ptr [rsi+08H] FF5618               call    \", \" [rsi+18H]Func`2:Invoke(int):int:this 03F8                 add      edi, eax FFC5                 in\", \"c      ebp 443BF5               cmp      r14d, ebp 7FEA                 jg       SHORT G_M000_IG03 G\", \"_M000_IG04:                ;; offset=0033H 8BC7                 mov      eax, edi G_M000_IG05:      \", \"          ;; offset=0035H 4883C420             add      rsp, 32 5B                   pop      rbx 5D\", \"                   pop      rbp 5E                   pop      rsi 5F                   pop      rdi \", \"415E                 pop      r14 C3                   ret ; Total bytes of code 64\\n```\\n\\nNote the ca\", \"ll [rsi+18H]Func'2:Invoke(int):int:this in there that's invoking the delegate. Now with PGO enabled:\", \"\\n\\n```\\n; Assembly listing for method Program:Sum(ref,Func`2):int ; Emitting BLENDED_CODE for X64 CPU \", \"with AVX - Windows ; Tier-1 compilation ; optimized code ; optimized using profile data ; rsp based \", \"frame ; fully interruptible ; with Dynamic PGO: edge weights are valid, and fgCalledCount is 5628 ; \", \"0 inlinees with PGO data; 1 single block inlinees; 0 inlinees without PGO data G_M000_IG01:         \", \"       ;; offset=0000H\\n```\\n\\n```\\n4157                 push     r15 4156                 push     r14 \", \"57                   push     rdi 56                   push     rsi 55                   push     rb\", \"p 53                   push     rbx 4883EC28             sub      rsp, 40 488BF2               mov  \", \"    rsi, rdx G_M000_IG02:                ;; offset=000FH 33FF                 xor      edi, edi 488B\", \"D9               mov      rbx, rcx 33ED                 xor      ebp, ebp 448B7308             mov  \", \"    r14d, dword ptr [rbx+08H] 4585F6               test     r14d, r14d 7E27                 jle     \", \" SHORT G_M000_IG05 G_M000_IG03:                ;; offset=001FH 8BC5                 mov      eax, eb\", \"p 8B548310             mov      edx, dword ptr [rbx+4*rax+10H] 4C8B4618             mov      r8, qwo\", \"rd ptr [rsi+18H] 48B8A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A0 4C3BC0               cmp      r8,\", \" rax 751D                 jne      SHORT G_M000_IG07 446BFA2A             imul     r15d, edx, 42 G_M\", \"000_IG04:                ;; offset=003CH 4103FF               add      edi, r15d FFC5               \", \"  inc      ebp 443BF5               cmp      r14d, ebp 7FD9                 jg       SHORT G_M000_IG\", \"03 G_M000_IG05:                ;; offset=0046H 8BC7                 mov      eax, edi G_M000_IG06:  \", \"              ;; offset=0048H 4883C428             add      rsp, 40 5B                   pop      rb\", \"x 5D                   pop      rbp 5E                   pop      rsi 5F                   pop      \", \"rdi 415E                 pop      r14 415F                 pop      r15 C3                   ret G_M\", \"000_IG07:                ;; offset=0055H 488B4E08             mov      rcx, gword ptr [rsi+08H] 41FF\", \"D0               call     r8 448BF8               mov      r15d, eax EBDB                 jmp      S\", \"HORT G_M000_IG04\\n```\\n\\nI chose the 42 constant in i =&gt; i * 42 to make it easy to see in the assemb\", \"ly, and sure enough, there it is:\\n\\n```\\nG_M000_IG03:                ;; offset=001FH 8BC5             \", \"    mov      eax, ebp 8B548310             mov      edx, dword ptr [rbx+4*rax+10H] 4C8B4618         \", \"    mov      r8, qword ptr [rsi+18H] 48B8A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A0 4C3BC0       \", \"        cmp      r8, rax\\n```\\n\\n| 751D     | jne SHORT G_M000_IG07   |\\n|----------|-------------------\", \"------|\\n| 446BFA2A | imul r15d, edx, 42      |\\n\\nThis is loading the target address from the delegate\", \" into r8 and is loading the address of the expected target into rax . If they're the same, it then s\", \"imply performs the inlined operation ( imul r15d, edx, 42 ), and otherwise it jumps to G\\\\_M000\\\\_IG07\", \" which calls to the function in r8 . The effect of this is obvious if we run this as a benchmark:\\n\\n`\", \"``\\nstatic int[] s_values = Enumerable.Range(0, 1_000).ToArray(); [Benchmark] public int DelegatePGO(\", \") => Sum(s_values, i => i * 42); static int Sum(int[] values, Func<int, int>? func) { int sum = 0; f\", \"oreach (int value in values) { sum += func(value); } return sum; }\\n```\\n\\nWith PGO disabled, we get th\", \"e same performance throughput for .NET 6 and .NET 7:\\n\\n| Method      | Runtime   | Mean     |   Ratio\", \" |\\n|-------------|-----------|----------|---------|\\n| DelegatePGO | .NET 6.0  | 1.665 us |       1 |\", \"\\n| DelegatePGO | .NET 7.0  | 1.659 us |       1 |\\n\\nBut the picture changes when we enable dynamic PG\", \"O ( DOTNET\\\\_TieredPGO=1 ). .NET 6 gets ~14% faster, but .NET 7 gets ~3x faster!\\n\\n| Method      | Run\", \"time   | Mean       |   Ratio |\\n|-------------|-----------|------------|---------|\\n| DelegatePGO | .\", \"NET 6.0  | 1,427.7 ns |    1    |\\n| DelegatePGO | .NET 7.0  | 539.0 ns   |    0.38 |\\n\\ndotnet/runtime\", \"#70377 is another valuable improvement with dynamic PGO, which enables PGO to play nicely with loop \", \"cloning and invariant hoisting. To understand this better, a brief digression into what those are. L\", \"oop cloning is a mechanism the JIT employs to avoid various overheads in the fast path of a loop. Co\", \"nsider the Test method in this example:\\n\\n```\\nusing System.Runtime.CompilerServices; class Program { \", \"static void Main() { int[] array = new int[10_000_000]; for (int i = 0; i < 1_000_000; i++) { Test(a\", \"rray); } }\\n```\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)] private static bool Test(int[] array)\", \" { for (int i = 0; i < 0x12345; i++) { if (array[i] == 42) { return true ; } } return false ; } }\\n``\", \"`\\n\\nThe JIT doesn't know whether the passed in array is of sufficient length that all accesses to arr\", \"ay[i] inside the loop will be in bounds, and thus it would need to inject bounds checks for every ac\", \"cess. While it'd be nice to simply do the length check up f ront and simply throw an exception early\", \" if it wasn't long enough, doing so could also change behavior (imagine the method were writing into\", \" the array as it went, or otherwise mutating some shared state). Instead, the JIT employs 'loop clon\", \"ing.' It essentially rewrites this Test method to be more like this:\\n\\n```\\nif (array is not null && a\", \"rray.Length >= 0x12345) { for (int i = 0; i < 0x12345; i++) { if (array[i] == 42) // no bounds check\", \"s emitted for this access :-) { return true ; } } } else { for (int i = 0; i < 0x12345; i++) { if (a\", \"rray[i] == 42) // bounds checks emitted for this access :-( { return true ; } } } return false ;\\n```\", \"\\n\\nThat way, at the expense of some code duplication, we get our fast loop without bounds checks and \", \"only pay for the bounds checks in the slow path. You can see this in the generated assembly (if you \", \"can't already tell, DOTNET\\\\_JitDisasm is one of my favorite features in .NET 7):\\n\\n```\\n; Assembly lis\", \"ting for method Program:Test(ref):bool ; Emitting BLENDED_CODE for X64 CPU with AVX - Windows ; Tier\", \"-1 compilation ; optimized code ; rsp based frame ; fully interruptible ; No PGO data G_M000_IG01:  \", \"              ;; offset=0000H 4883EC28             sub      rsp, 40\\n```\\n\\n```\\nG_M000_IG02:           \", \"     ;; offset=0004H 33C0                 xor      eax, eax 4885C9               test     rcx, rcx 7\", \"429                 je       SHORT G_M000_IG05 81790845230100       cmp      dword ptr [rcx+08H], 0x\", \"12345 7C20                 jl       SHORT G_M000_IG05 0F1F40000F1F840000000000 align    [12 bytes fo\", \"r IG03] G_M000_IG03:                ;; offset=0020H 8BD0                 mov      edx, eax 837C91102\", \"A           cmp      dword ptr [rcx+4*rdx+10H], 42 7429                 je       SHORT G_M000_IG08 F\", \"FC0                 inc      eax 3D45230100           cmp      eax, 0x12345 7CEE                 jl \", \"      SHORT G_M000_IG03 G_M000_IG04:                ;; offset=0032H EB17                 jmp      SH\", \"ORT G_M000_IG06 G_M000_IG05:                ;; offset=0034H 3B4108               cmp      eax, dword\", \" ptr [rcx+08H] 7323                 jae      SHORT G_M000_IG10 8BD0                 mov      edx, ea\", \"x 837C91102A           cmp      dword ptr [rcx+4*rdx+10H], 42 7410                 je       SHORT G_\", \"M000_IG08 FFC0                 inc      eax 3D45230100           cmp      eax, 0x12345 7CE9         \", \"        jl       SHORT G_M000_IG05 G_M000_IG06:                ;; offset=004BH 33C0                 \", \"xor      eax, eax G_M000_IG07:                ;; offset=004DH 4883C428             add      rsp, 40 \", \"C3                   ret G_M000_IG08:                ;; offset=0052H B801000000           mov      e\", \"ax, 1 G_M000_IG09:                ;; offset=0057H 4883C428             add      rsp, 40 C3          \", \"         ret G_M000_IG10:                ;; offset=005CH E81FA0C15F           call     CORINFO_HELP_\", \"RNGCHKFAIL CC                   int3 ; Total bytes of code 98\\n```\\n\\nThat G\\\\_M000\\\\_IG02 section is doi\", \"ng the null check and the length check, jumping to the G\\\\_M000\\\\_IG05 block if either fails. If both \", \"succeed, it's then executing the loop (block G\\\\_M000\\\\_IG03) without bounds checks:\\n\\n```\\nG_M000_IG03:\", \"                ;; offset=0020H 8BD0                 mov      edx, eax 837C91102A           cmp     \", \" dword ptr [rcx+4*rdx+10H], 42 7429                 je       SHORT G_M000_IG08 FFC0                 \", \"inc      eax\\n```\\n\\n```\\n3D45230100           cmp      eax, 0x12345 7CEE                 jl       SHORT\", \" G_M000_IG03\\n```\\n\\nwith the bounds checks only showing up in the slow-path block:\\n\\n```\\nG_M000_IG05:  \", \"              ;; offset=0034H 3B4108               cmp      eax, dword ptr [rcx+08H] 7323           \", \"      jae      SHORT G_M000_IG10 8BD0                 mov      edx, eax 837C91102A           cmp    \", \"  dword ptr [rcx+4*rdx+10H], 42 7410                 je       SHORT G_M000_IG08 FFC0                \", \" inc      eax 3D45230100           cmp      eax, 0x12345 7CE9                 jl       SHORT G_M000_\", \"IG05\\n```\\n\\nThat's 'loop cloning.' What about 'invariant hoisting'? Hoisting means pulling something o\", \"ut of a loop to be before the loop, and invariants are things that don't change. Thus invariant hois\", \"ting is pulling something out of a loop to before the loop in order to avoid recomputing every itera\", \"tion of the loop an answer that won't change. Effectively, the previous example already showed invar\", \"iant hoisting, in that the bounds check is moved to be before the loop rather than in the loop, but \", \"a more concrete example would be something like this:\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)\", \"] private static bool Test(int[] array) { for (int i = 0; i < 0x12345; i++) { if (array[i] == array.\", \"Length - 42) { return true ; } } return false ; }\\n```\\n\\nNote that the value of array.Length - 42 does\", \"n't change on each iteration of the loop, so it's 'invariant' to the loop iteration and can be lifte\", \"d out, which the generated code does:\\n\\n```\\nG_M000_IG02:                ;; offset=0004H 33D2         \", \"        xor      edx, edx 4885C9               test     rcx, rcx 742A                 je       SHORT\", \" G_M000_IG05 448B4108             mov      r8d, dword ptr [rcx+08H] 4181F845230100       cmp      r8\", \"d, 0x12345 7C1D                 jl       SHORT G_M000_IG05 4183C0D6             add      r8d, -42 0F\", \"1F4000             align    [4 bytes for IG03] G_M000_IG03:                ;; offset=0020H 8BC2     \", \"            mov      eax, edx 4439448110           cmp      dword ptr [rcx+4*rax+10H], r8d 7433     \", \"            je       SHORT G_M000_IG08 FFC2                 inc      edx 81FA45230100         cmp   \", \"   edx, 0x12345 7CED                 jl       SHORT G_M000_IG03\\n```\\n\\nHere again we see the array bei\", \"ng tested for null ( test rcx, rcx ) and the array's length being checked ( mov r8d, dword ptr [rcx+\", \"08H] , cmp r8d, 0x12345 ), but then with the array's length in r8d , we then see this up-front block\", \" subtracting 42 from the length ( add r8d, -42 ), and that's before we continue into the fast-path l\", \"oop in the G\\\\_M000\\\\_IG03 block. This keeps that additional set of operations out of the loop, thereb\", \"y avoiding the overhead of recomputing the value per iteration.\\n\\nOk, so how does this apply to dynam\", \"ic PGO? Remember that with the interface/virtual dispatch avoidance PGO is able to do, it does so by\", \" doing a type check to see whether the type in use is the most common type; if it is, it uses a fast\", \" path that calls directly to that type's method (and in doing so that call is then potentially inlin\", \"ed), and if it isn't, it falls back to normal interface/virtual dispatch. That check can be invarian\", \"t to a loop. So when a method is tiered up and PGO kicks in, the type check can now be hoisted out o\", \"f the loop, making it even cheaper to handle the common case. Consider this variation of our origina\", \"l example:\\n\\n```\\nusing System.Runtime.CompilerServices; class Program { static void Main() { IPrinter\", \" printer = new BlankPrinter(); while ( true ) { DoWork(printer); } } [MethodImpl(MethodImplOptions.N\", \"oInlining)] static void DoWork(IPrinter printer) { for (int j = 0; j < 123; j++) { printer.Print(j);\", \" } } interface IPrinter { void Print(int i); } class BlankPrinter : IPrinter { public void Print(int\", \" i) { Console.Write(\\\"\\\"); } } }\\n```\\n\\nWhen we look at the optimized assembly generated for this with d\", \"ynamic PGO enabled, we see this:\\n\\n```\\n; Assembly listing for method Program:DoWork(IPrinter) ; Emitt\", \"ing BLENDED_CODE for X64 CPU with AVX - Windows ; Tier-1 compilation ; optimized code ; optimized us\", \"ing profile data\\n```\\n\\n```\\n; rsp based frame ; partially interruptible ; with Dynamic PGO: edge weigh\", \"ts are invalid, and fgCalledCount is 12187 ; 0 inlinees with PGO data; 1 single block inlinees; 0 in\", \"linees without PGO data G_M000_IG01:                ;; offset=0000H 57                   push     rd\", \"i 56                   push     rsi 4883EC28             sub      rsp, 40 488BF1               mov  \", \"    rsi, rcx G_M000_IG02:                ;; offset=0009H 33FF                 xor      edi, edi 4885\", \"F6               test     rsi, rsi 742B                 je       SHORT G_M000_IG05 48B9982DD43CFC7F0\", \"000 mov      rcx, 0x7FFC3CD42D98 48390E               cmp      qword ptr [rsi], rcx 751C            \", \"     jne      SHORT G_M000_IG05 G_M000_IG03:                ;; offset=001FH 48B9282040F948020000 mov\", \"      rcx, 0x248F9402028 488B09               mov      rcx, gword ptr [rcx] FF1526A80D00         cal\", \"l     [Console:Write(String)] FFC7                 inc      edi 83FF7B               cmp      edi, 1\", \"23 7CE6                 jl       SHORT G_M000_IG03 G_M000_IG04:                ;; offset=0039H EB29 \", \"                jmp      SHORT G_M000_IG07 G_M000_IG05:                ;; offset=003BH 48B9982DD43CF\", \"C7F0000 mov      rcx, 0x7FFC3CD42D98 48390E               cmp      qword ptr [rsi], rcx 7521        \", \"         jne      SHORT G_M000_IG08 48B9282040F948020000 mov      rcx, 0x248F9402028 488B09         \", \"      mov      rcx, gword ptr [rcx] FF15FBA70D00         call     [Console:Write(String)] G_M000_IG0\", \"6:                ;; offset=005DH FFC7                 inc      edi 83FF7B               cmp      ed\", \"i, 123 7CD7                 jl       SHORT G_M000_IG05 G_M000_IG07:                ;; offset=0064H 4\", \"883C428             add      rsp, 40 5E                   pop      rsi 5F                   pop     \", \" rdi C3                   ret G_M000_IG08:                ;; offset=006BH 488BCE               mov  \", \"    rcx, rsi 8BD7                 mov      edx, edi 49BB1000AA3CFC7F0000 mov      r11, 0x7FFC3CAA001\", \"0 41FF13               call     [r11]IPrinter:Print(int):this EBDE                 jmp      SHORT G_\", \"M000_IG06 ; Total bytes of code 127\\n```\\n\\nWe can see in the G\\\\_M000\\\\_IG02 block that it's doing the t\", \"ype check on the IPrinter instance and jumping to G\\\\_M000\\\\_IG05 if the check fails ( mov rcx, 0x7FFC\", \"3CD42D98 , cmp qword ptr [rsi], rcx ,\\n\\njne SHORT G\\\\_M000\\\\_IG05 ), otherwise falling through to G\\\\_M0\", \"00\\\\_IG03 which is a tight fast-path loop that's inlined BlankPrinter.Print with no type checks in si\", \"ght!\\n\\nInterestingly, improvements like this can bring with them their own challenges. PGO leads to a\", \" significant increase in the number of type checks, since call sites that specialize for a given typ\", \"e need to compare against that type. However, common subexpression elimination (CSE) hasn't historic\", \"ally worked for such type handles (CSE is a compiler optimization where duplicate expressions are el\", \"iminated by computing the result once and then storing it for subsequent use rather than recomputing\", \" it each time). dotnet/runtime#70580 fixes this by enabling CSE for such constant handles. For examp\", \"le, consider this method:\\n\\n```\\n[Benchmark] [Arguments(\\\"\\\", \\\"\\\", \\\"\\\", \\\"\\\")] public bool AllAreStrings(obj\", \"ect o1, object o2, object o3, object o4) => o1 is string && o2 is string && o3 is string && o4 is st\", \"ring;\\n```\\n\\nOn .NET 6, the JIT produced this assembly code:\\n\\n```\\n; Program.AllAreStrings(System.Objec\", \"t, System.Object, System.Object, System.Object) test      rdx,rdx je        short M00_L01 mov       \", \"rax,offset MT_System.String cmp       [rdx],rax jne       short M00_L01 test      r8,r8 je        sh\", \"ort M00_L01 mov       rax,offset MT_System.String cmp       [r8],rax jne       short M00_L01 test   \", \"   r9,r9 je        short M00_L01 mov       rax,offset MT_System.String cmp       [r9],rax jne       \", \"short M00_L01 mov       rax,[rsp+28] test      rax,rax je        short M00_L00 mov       rdx,offset \", \"MT_System.String cmp       [rax],rdx je        short M00_L00 xor       eax,eax M00_L00: test      ra\", \"x,rax setne     al movzx     eax,al ret M00_L01: xor       eax,eax ret ; Total bytes of code 100\\n```\", \"\\n\\nNote the C# has four tests for string and the assembly code has four loads with mov rax,offset MT\\\\\", \"_System.String . Now on .NET 7, the load is performed just once:\\n\\n```\\n; Program.AllAreStrings(System\", \".Object, System.Object, System.Object, System.Object) test      rdx,rdx je        short M00_L01\\n```\\n\", \"\\n```\\nmov       rax,offset MT_System.String cmp       [rdx],rax jne       short M00_L01 test      r8,\", \"r8 je        short M00_L01 cmp       [r8],rax jne       short M00_L01 test      r9,r9 je        shor\", \"t M00_L01 cmp       [r9],rax jne       short M00_L01 mov       rdx,[rsp+28] test      rdx,rdx je    \", \"    short M00_L00 cmp       [rdx],rax je        short M00_L00 xor       edx,edx M00_L00: xor       e\", \"ax,eax test      rdx,rdx setne     al ret M00_L01: xor       eax,eax ret ; Total bytes of code 69\\n``\", \"`\\n\\n## Bounds Check Elimination\\n\\nOne of the things that makes .NET attractive is its safety. The runt\", \"ime guards access to arrays, strings, and sp ans such that you can't accidentally corrupt memory by \", \"walking off either end; if you do, rather than reading/writing arbitrary memory, you'll get exceptio\", \"ns. Of course, that's not magic; it's done by the JIT inserting bounds checks every time one of thes\", \"e data structures is indexed. For example, this:\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)] sta\", \"tic int Read0thElement(int[] array) => array[0];\\n```\\n\\nresults in:\\n\\n```\\nG_M000_IG01:                ;\", \"; offset=0000H 4883EC28             sub      rsp, 40 G_M000_IG02:                ;; offset=0004H 837\", \"90800             cmp      dword ptr [rcx+08H], 0 7608                 jbe      SHORT G_M000_IG04 8B\", \"4110               mov      eax, dword ptr [rcx+10H] G_M000_IG03:                ;; offset=000DH 488\", \"3C428             add      rsp, 40 C3                   ret G_M000_IG04:                ;; offset=00\", \"12H E8E9A0C25F           call     CORINFO_HELP_RNGCHKFAIL CC                   int3\\n```\\n\\nThe array i\", \"s passed into this method in the rcx register, pointing to the method table pointer in the object, a\", \"nd the length of an array is stored in the object just after that method table pointer (which is 8 b\", \"ytes in a 64-bit process). Thus the cmp dword ptr [rcx+08H], 0 instruction is reading the length\\n\\nof\", \" the array and comparing the length to 0; that makes sense, since the length can't be negative, and \", \"we're trying to access the 0th element, so as long as the length isn't 0, the array has enough eleme\", \"nts for us to access its 0th element. In the event that the length was 0, the code jumps to the end \", \"of the function, which contains call CORINFO\\\\_HELP\\\\_RNGCHKFAIL ; that's a JIT helper function that t\", \"hrows an IndexOutOfRangeException . If the length was sufficient, however, it then reads the int sto\", \"red at the beginning of the array's data, which on 64 -bit is 16 bytes (0x10) past the pointer ( mov\", \" eax, dword ptr [rcx+10H] ).\\n\\nWhile these bounds checks in and of themselves aren't super expensive,\", \" do a lot of them and their costs add up. So while t he JIT needs to ensure that 'safe' accesses don\", \"'t go out of bounds, it also tries to prove that certain accesses won't, in which case it needn't em\", \"it the bounds check that it knows will be superfluous. In every release of .NET, more and more cases\", \" have been added to find places these bounds checks can be eliminated, and .NET 7 is no exception.\\n\\n\", \"For example, dotnet/runtime#61662 from [@anthonycanino](https://github.com/anthonycanino) enabled th\", \"e JIT to understand various forms of binary operations as part of range checks. Consider this method\", \":\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)] private static ushort[]? Convert(ReadOnlySpan<byte\", \"> bytes) { if (bytes.Length != 16) { return null ; } var result = new ushort[8]; for (int i = 0; i <\", \" result.Length; i++) { result[i] = (ushort)(bytes[i * 2] * 256 + bytes[i * 2 + 1]); } return result;\", \" }\\n```\\n\\nIt's validating that the input span is 16 bytes long and then creating a new ushort[8] where\", \" each ushort in the array combines two of the input bytes. To do that, it's looping over the output \", \"array, and indexing into the bytes array using i * 2 and i * 2 + 1 as the indices. On .NET 6, each o\", \"f those indexing operations would result in a bounds check, with assembly like:\\n\\n```\\ncmp       r8d,1\", \"0 jae       short G_M000_IG04 movsxd    r8,r8d\\n```\\n\\nwhere that G\\\\_M000\\\\_IG04 is the call CORINFO\\\\_HE\", \"LP\\\\_RNGCHKFAIL we're now familiar with. But on .NE T 7, we get this assembly for the method:\\n\\n```\\nG_\", \"M000_IG01:                ;; offset=0000H 56                   push     rsi 4883EC20             sub\", \"      rsp, 32 G_M000_IG02:                ;; offset=0005H 488B31               mov      rsi, bword p\", \"tr [rcx] 8B4908               mov      ecx, dword ptr [rcx+08H]\\n```\\n\\n```\\n83F910               cmp   \", \"   ecx, 16 754C                 jne      SHORT G_M000_IG05 48B9302F542FFC7F0000 mov      rcx, 0x7FFC\", \"2F542F30 BA08000000           mov      edx, 8 E80C1EB05F           call     CORINFO_HELP_NEWARR_1_VC\", \" 33D2                 xor      edx, edx align    [0 bytes for IG03] G_M000_IG03:                ;; o\", \"ffset=0026H 8D0C12               lea      ecx, [rdx+rdx] 448BC1               mov      r8d, ecx FFC1\", \"                 inc      ecx 458BC0               mov      r8d, r8d 460FB60406           movzx    r\", \"8, byte  ptr [rsi+r8] 41C1E008             shl      r8d, 8 8BC9                 mov      ecx, ecx 0F\", \"B60C0E             movzx    rcx, byte  ptr [rsi+rcx] 4103C8               add      ecx, r8d 0FB7C9  \", \"             movzx    rcx, cx 448BC2               mov      r8d, edx 6642894C4010         mov      w\", \"ord  ptr [rax+2*r8+10H], cx FFC2                 inc      edx 83FA08               cmp      edx, 8 7\", \"CD0                 jl       SHORT G_M000_IG03 G_M000_IG04:                ;; offset=0056H 4883C420 \", \"            add      rsp, 32 5E                   pop      rsi C3                   ret G_M000_IG05:\", \"                ;; offset=005CH 33C0                 xor      rax, rax G_M000_IG06:                ;\", \"; offset=005EH 4883C420             add      rsp, 32 5E                   pop      rsi C3           \", \"        ret ; Total bytes of code 100\\n```\\n\\nNo bounds checks, which is most easily seen by the lack o\", \"f the telltale call\\n\\nCORINFO\\\\_HELP\\\\_RNGCHKFAIL at the end of the method. With this PR, the JIT is ab\", \"le to understand the impact of certain multiplication and shift operations and their relationships t\", \"o the bounds of the data structure. Since it can see that the result array's length is 8 and the loo\", \"p is iterating from 0 to that exclusive upper bound, it knows that i will always be in the range [0,\", \" 7] , which means that i * 2 will always be in the range [0, 14] and i * 2 + 1 will always be in the\", \" range [0, 15] . As such, it's able to prove that the bounds checks aren't ne eded.\\n\\ndotnet/runtime#\", \"61569 and dotnet/runtime#62864 also help to eliminate bounds checks when dealing with constant strin\", \"gs and spans initialized from RVA statics ('Relative Virtual Address' static fields, basically a sta\", \"tic field that lives in a module's data section). For example, consider this benchmark :\\n\\n```\\n[Bench\", \"mark] [Arguments(1)] public char GetChar(int i) { const string Text = \\\"hello\\\";\\n```\\n\\n```\\nreturn (uint\", \")i < Text.Length ? Text[i] : '\\\\0'; }\\n```\\n\\nOn .NET 6, we get this assembly:\\n\\n```\\n; Program.GetChar(In\", \"t32) sub       rsp,28 mov       eax,edx cmp       rax,5 jl        short M00_L00 xor       eax,eax ad\", \"d       rsp,28 ret M00_L00: cmp       edx,5 jae       short M00_L01 mov       rax,2278B331450 mov   \", \"    rax,[rax] movsxd    rdx,edx movzx     eax,word ptr [rax+rdx*2+0C] add       rsp,28 ret M00_L01: \", \"call      CORINFO_HELP_RNGCHKFAIL int       3 ; Total bytes of code 56\\n```\\n\\nThe beginning of this ma\", \"kes sense: the JIT was obviously able to see that the length of Text is 5, so it's implementing the \", \"(uint)i &lt; Text.Length check by doing cmp rax,5 , and if i as an unsigned value is greater than or\", \" equal to 5, it's then zero'ing out the return value (to return the '\\\\0' ) and exiting. If the lengt\", \"h is less than 5 ( in which case it's also at least 0 due to the unsigned comparison), it then jumps\", \" to M00\\\\_L00 to read the value from the string\\u2026 but we then see another cmp against 5, this time as \", \"part of a range check. So even though the JIT knew the index was in bounds, it wasn't able to remove\", \" the bounds check. Now it is; in .NET 7, we get this:\\n\\n```\\n; Program.GetChar(Int32) cmp       edx,5 \", \"jb        short M00_L00 xor       eax,eax ret M00_L00: mov       rax,2B0AF002530 mov       rax,[rax]\", \" mov       edx,edx movzx     eax,word ptr [rax+rdx*2+0C] ret ; Total bytes of code 29\\n```\\n\\nSo much n\", \"icer.\\n\\ndotnet/runtime#67141 is a great example of how evolving ecosystem needs drives specific optim\", \"izations into the JIT. The Regex compiler and source generator handle some cases of regular expressi\", \"on character classes by using a bitmap lookup stored in strings. For example, to determine whether a\", \" char c is in the character class \\\"[A-Za-z0-9\\\\_]\\\" (which will match an underscore or any ASCII lette\", \"r or digit), the implementation ends up generating an expression like the body of the following meth\", \"od:\\n\\n```\\n[Benchmark] [Arguments('a')] public bool IsInSet(char c) => c < 128 && (\\\"\\\\0\\\\0\\\\0\\\\u03FF\\\\uFFFE\", \"\\\\u87FF\\\\uFFFE\\\\u07FF\\\"[c >> 4] & (1 << (c & 0xF))) != 0;\\n```\\n\\nThe implementation is treating an 8-chara\", \"cter string as a 128-bit lookup table. If the character is known to be in range (such that it's effe\", \"ctively a 7 -bit value), it 's then using the top 3 bits of the value to index into the 8 elements o\", \"f the string, and the bottom 4 bits to select one of the 16 bits in that element, giving us an answe\", \"r as to whether this input character is in the set or not. In .NET 6, even though we know the charac\", \"ter is in range of the string, the JIT couldn't see through either the length comparison or the bit \", \"shift.\\n\\n```\\n; Program.IsInSet(Char) sub       rsp,28 movzx     eax,dx cmp       eax,80 jge       sho\", \"rt M00_L00 mov       edx,eax sar       edx,4 cmp       edx,8 jae       short M00_L01 mov       rcx,2\", \"99835A1518 mov       rcx,[rcx] movsxd    rdx,edx movzx     edx,word ptr [rcx+rdx*2+0C] and       eax\", \",0F bt        edx,eax setb      al movzx     eax,al add       rsp,28 ret M00_L00: xor       eax,eax \", \"add       rsp,28 ret M00_L01: call      CORINFO_HELP_RNGCHKFAIL int       3 ; Total bytes of code 75\", \"\\n```\\n\\nThe previously mentioned PR takes care of the length check. And this PR takes care of the bit \", \"shift. So in .NET 7, we get this loveliness:\\n\\n```\\n; Program.IsInSet(Char) movzx     eax,dx cmp      \", \" eax,80 jge       short M00_L00 mov       edx,eax sar       edx,4 mov       rcx,197D4800608 mov     \", \"  rcx,[rcx] mov       edx,edx movzx     edx,word ptr [rcx+rdx*2+0C] and       eax,0F bt        edx,e\", \"ax setb      al movzx     eax,al ret\\n```\\n\\n```\\nM00_L00: xor       eax,eax ret ; Total bytes of code 5\", \"1\\n```\\n\\nNote the distinct lack of a call CORINFO\\\\_HELP\\\\_RNGCHKFAIL . And as you might guess, this che\", \"ck can happen a lot in a Regex , making this a very useful addition.\\n\\nBounds chec ks are an obvious \", \"source of overhead when talking about array access, but they're not the only ones. There's also the \", \"need to use the cheapest instructions possible. In .NET 6, with a method like:\\n\\n```\\n[MethodImpl(Meth\", \"odImplOptions.NoInlining)] private static int Get(int[] values, int i) => values[i];\\n```\\n\\nassembly c\", \"ode like the following would be generated:\\n\\n```\\n; Program.Get(Int32[], Int32) sub       rsp,28 cmp  \", \"     edx,[rcx+8] jae       short M01_L00 movsxd    rax,edx mov       eax,[rcx+rax*4+10] add       rs\", \"p,28 ret M01_L00: call      CORINFO_HELP_RNGCHKFAIL int       3 ; Total bytes of code 27\\n```\\n\\nThis s\", \"hould look fairly familiar from our previous discussion; the JIT is loading the array's length ( [rc\", \"x+8] ) and comparing that with the value of i (in edx ), and then jumping to the end to throw an exc\", \"eption if i is out of bounds. Immediately after that jump we see a movsxd rax, edx instruction, whic\", \"h is taking the 32-bit value of i from edx and moving it into the 64-bit register rax . And as part \", \"of moving it, it's sign -extending it; that's the 'sxd' part of the instruction name (sign -extendin\", \"g means the upper 32 bits of the new 64-bit value will be set to the value of the upper bit of the 3\", \"2-bit value, so that the number retains its signed value). The interesting thing is, though, we know\", \" that the Length of an array and of a span is non-negative, and since we just bounds checked i again\", \"st the Length , we also know that i is non-negative. That makes such sign-extension useless, since t\", \"he upper bit is guaranteed to be 0. Since the mov instruction that zero-extends is a tad cheaper tha\", \"n movsxd , we can simply use that instead. And that's exactly what dotnet/runtime#57970 from\\n\\n[@pent\", \"p](https://github.com/pentp) does for both arrays and spans (dotnet/runtime#70884 also similarly avo\", \"ids some signed casts in other situations). Now on .NET 7, we get this:\\n\\n```\\n; Program.Get(Int32[], \", \"Int32) sub       rsp,28 cmp       edx,[rcx+8] jae       short M01_L00 mov       eax,edx mov       ea\", \"x,[rcx+rax*4+10] add       rsp,28 ret M01_L00: call      CORINFO_HELP_RNGCHKFAIL\\n```\\n\\n```\\nint       \", \"3\\n```\\n\\n```\\n; Total bytes of code 26\\n```\\n\\nThat's not the only source of overhead with array access, t\", \"hough. In fact, there's a very large category of array access overhead that's been there forever, bu\", \"t that's so well known there are even old FxCop rules and newer Roslyn analyzers that warn against i\", \"t: multidimensional array accesses. The overhead in the case of a multidimensional array isn't just \", \"an extra branch on every indexing opera tion, or additional math required to compute the location of\", \" the element, but rather that they currently pass through the JIT's optimization phases largely unmo\", \"dified. dotnet/runtime#70271 improves the state of the world here by doing an expansion of a multidi\", \"mensional array access early in the JIT's pipeline, such that later optimization phases can improve \", \"multidimensional accesses as they would other code, including CSE and loop invariant hoisting. The i\", \"mpact of this is visible in a simple benchmark that sums all the elements of a multidimensional arra\", \"y.\\n\\n```\\nprivate int[,] _square; [Params(1000)] public int Size { get ; set ; } [GlobalSetup] public \", \"void Setup() { int count = 0; _square = new int[Size, Size]; for (int i = 0; i < Size; i++) { for (i\", \"nt j = 0; j < Size; j++) { _square[i, j] = count++; } } } [Benchmark] public int Sum() { int[,] squa\", \"re = _square; int sum = 0; for (int i = 0; i < Size; i++) { for (int j = 0; j < Size; j++) { sum += \", \"square[i, j]; } } return sum; }\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio |\\n|----------|-----\", \"------|----------|---------|\\n| Sum      | .NET 6.0  | 964.1 us |     1   |\\n| Sum      | .NET 7.0  | \", \"674.7 us |     0.7 |\\n\\nThis previous example assumes you know the size of each dimension of the multi\", \"dimensional array (it's referring to the Size directly in the loops). That's obviously not always (o\", \"r maybe even rarely) the case. In such situations, you'd be more likely to use the Array.GetUpperBou\", \"nd method, and because\\n\\nmultidimensional arrays can have a non-zero lower bound, Array.GetLowerBound\", \" . That would lead to code like this:\\n\\n```\\nprivate int[,] _square; [Params(1000)] public int Size { \", \"get ; set ; } [GlobalSetup] public void Setup() { int count = 0; _square = new int[Size, Size]; for \", \"(int i = 0; i < Size; i++) { for (int j = 0; j < Size; j++) { _square[i, j] = count++; } } } [Benchm\", \"ark] public int Sum() { int[,] square = _square; int sum = 0; for (int i = square.GetLowerBound(0); \", \"i < square.GetUpperBound(0); i++) { for (int j = square.GetLowerBound(1); j < square.GetUpperBound(1\", \"); j++) { sum += square[i, j]; } } return sum; }\\n```\\n\\nIn .NET 7, thanks to dotnet/runtime#60816, tho\", \"se GetLowerBound and GetUpperBound calls become JIT intrinsics. An 'intrinsic' to a compiler is some\", \"thing the compiler has intrinsic knowledge of, such that rather than relying solely on a method's de\", \"fined implementation (if it even has one), the compiler can substitute in something it considers to \", \"be better. There are literally thousands of methods in .NET known in this manner to the JIT, with Ge\", \"tLowerBound and GetUpperBound being two of the most recent. Now as intrinsics, when they're passed a\", \" constant value (e.g. 0 for the 0th rank), the JIT can substitute the necessary assembly instruction\", \"s to read directly from the memory location that houses the bounds. Here's what the assembly code fo\", \"r this benchmark looked like with .NET 6; the main thing to see here are all of the call s out to Ge\", \"tLowerBound and GetUpperBound :\\n\\n```\\n; Program.Sum() push      rdi push      rsi push      rbp push \", \"     rbx sub       rsp,28 mov       rsi,[rcx+8] xor       edi,edi mov       rcx,rsi xor       edx,ed\", \"x\\n```\\n\\n```\\ncmp       [rcx],ecx call      System.Array.GetLowerBound(Int32) mov       ebx,eax mov    \", \"   rcx,rsi xor       edx,edx call      System.Array.GetUpperBound(Int32) cmp       eax,ebx jle      \", \" short M00_L03 M00_L00: mov       rcx,[rsi] mov       ecx,[rcx+4] add       ecx,0FFFFFFE8 shr       \", \"ecx,3 cmp       ecx,1 jbe       short M00_L05 lea       rdx,[rsi+10] inc       ecx movsxd    rcx,ecx\", \" mov       ebp,[rdx+rcx*4] mov       rcx,rsi mov       edx,1 call      System.Array.GetUpperBound(In\", \"t32) cmp       eax,ebp jle       short M00_L02 M00_L01: mov       ecx,ebx sub       ecx,[rsi+18] cmp\", \"       ecx,[rsi+10] jae       short M00_L04 mov       edx,ebp sub       edx,[rsi+1C] cmp       edx,[\", \"rsi+14] jae       short M00_L04 mov       eax,[rsi+14] imul      rax,rcx mov       rcx,rdx add      \", \" rcx,rax add       edi,[rsi+rcx*4+20] inc       ebp mov       rcx,rsi mov       edx,1 call      Syst\", \"em.Array.GetUpperBound(Int32) cmp       eax,ebp jg        short M00_L01 M00_L02: inc       ebx mov  \", \"     rcx,rsi xor       edx,edx call      System.Array.GetUpperBound(Int32) cmp       eax,ebx jg     \", \"   short M00_L00 M00_L03: mov       eax,edi add       rsp,28 pop       rbx pop       rbp pop       r\", \"si pop       rdi ret M00_L04: call      CORINFO_HELP_RNGCHKFAIL\\n```\\n\\n```\\nM00_L05: mov       rcx,offs\", \"et MT_System.IndexOutOfRangeException call      CORINFO_HELP_NEWSFAST mov       rsi,rax call      Sy\", \"stem.SR.get_IndexOutOfRange_ArrayRankIndex() mov       rdx,rax mov       rcx,rsi call      System.In\", \"dexOutOfRangeException..ctor(System.String) mov       rcx,rsi call      CORINFO_HELP_THROW int      \", \" 3 ; Total bytes of code 219\\n```\\n\\n## Now here's what it is for .NET 7:\\n\\n```\\n; Program.Sum() push    \", \"  r14 push      rdi push      rsi push      rbp push      rbx sub       rsp,20 mov       rdx,[rcx+8]\", \" xor       eax,eax mov       ecx,[rdx+18] mov       r8d,ecx mov       r9d,[rdx+10] lea       ecx,[rc\", \"x+r9+0FFFF] cmp       ecx,r8d jle       short M00_L03 mov       r9d,[rdx+1C] mov       r10d,[rdx+14]\", \" lea       r10d,[r9+r10+0FFFF] M00_L00: mov       r11d,r9d cmp       r10d,r11d jle       short M00_L\", \"02 mov       esi,r8d sub       esi,[rdx+18] mov       edi,[rdx+10] M00_L01: mov       ebx,esi cmp   \", \"    ebx,edi jae       short M00_L04 mov       ebp,[rdx+14] imul      ebx,ebp mov       r14d,r11d sub\", \"       r14d,[rdx+1C] cmp       r14d,ebp jae       short M00_L04 add       ebx,r14d add       eax,[rd\", \"x+rbx*4+20] inc       r11d cmp       r10d,r11d jg        short M00_L01 M00_L02: inc       r8d cmp   \", \"    ecx,r8d jg        short M00_L00 M00_L03:\\n```\\n\\n```\\nadd       rsp,20 pop       rbx pop       rbp p\", \"op       rsi pop       rdi pop       r14 ret M00_L04: call      CORINFO_HELP_RNGCHKFAIL int       3 \", \"; Total bytes of code 130\\n```\\n\\nImportantly, note there are no more call s (other than for the bounds\", \" check exception at the end). For example, instead of that first GetUpperBound call:\\n\\n```\\ncall      \", \"System.Array.GetUpperBound(Int32)\\n```\\n\\nwe get:\\n\\n```\\nmov       r9d,[rdx+1C] mov       r10d,[rdx+14] l\", \"ea       r10d,[r9+r10+0FFFF]\\n```\\n\\nand it ends up being much faster:\\n\\n| Method   | Runtime   | Mean  \", \"     |   Ratio |\\n|----------|-----------|------------|---------|\\n| Sum      | .NET 6.0  | 2,657.5 us\", \" |    1    |\\n| Sum      | .NET 7.0  | 676.3 us   |    0.25 |\\n\\n## Loop Hoisting and Cloning\\n\\nWe previ\", \"ously saw how PGO interacts with loop hoisting and cloning, and those optimizations have seen other \", \"improvements, as well.\\n\\nHistorically, the JIT's support for hoisting has been limited to lifting an \", \"invariant out one level. Consider this example:\\n\\n```\\n[Benchmark] public void Compute() { for (int th\", \"ousands = 0; thousands < 10; thousands++) { for (int hundreds = 0; hundreds < 10; hundreds++) { for \", \"(int tens = 0; tens < 10; tens++) { for (int ones = 0; ones < 10; ones++) { int n = ComputeNumber(th\", \"ousands, hundreds, tens, ones); Process(n); } } } } }\\n```\\n\\n```\\nstatic int ComputeNumber(int thousand\", \"s, int hundreds, int tens, int ones) => (thousands * 1000) + (hundreds * 100) + (tens * 10) + ones; \", \"[MethodImpl(MethodImplOptions.NoInlining)] static void Process(int n) { }\\n```\\n\\nAt first glance, you \", \"might look at this and say 'what could be hoisted, the computation of n requires all of the loop inp\", \"uts, and all of that computation is in ComputeNumber .' But from a compiler's perspective, the Compu\", \"teNumber function is inlineable and thus logically can be part of its caller, the computation of n i\", \"s actually split into multiple pieces, and each of those pieces can be hoisted to different levels, \", \"e.g. the tens computation can be hoisted out one level, the hundreds out two levels, and the thousan\", \"ds out three levels. Here's what [DisassemblyDiagnoser] outputs for .NET 6:\\n\\n```\\n; Program.Compute()\", \" push      r14 push      rdi push      rsi push      rbp push      rbx sub       rsp,20 xor       es\", \"i,esi M00_L00: xor       edi,edi M00_L01: xor       ebx,ebx M00_L02: xor       ebp,ebp imul      ecx\", \",esi,3E8 imul      eax,edi,64 add       ecx,eax lea       eax,[rbx+rbx*4] lea       r14d,[rcx+rax*2]\", \" M00_L03: lea       ecx,[r14+rbp] call      Program.Process(Int32) inc       ebp cmp       ebp,0A jl\", \"        short M00_L03 inc       ebx cmp       ebx,0A jl        short M00_L02 inc       edi cmp      \", \" edi,0A jl        short M00_L01 inc       esi cmp       esi,0A jl        short M00_L00 add       rsp\", \",20 pop       rbx pop       rbp pop       rsi pop       rdi pop       r14 ret ; Total bytes of code \", \"84\\n```\\n\\nWe can see that some hoisting has happened here. After all, the inner most loop (tagged M00\\\\\", \"_L03) is only five instructions: increment ebp (which at this point is the ones counter value), and \", \"if it's still less than 0xA (10), jump back to M00\\\\_L03 which adds whatever is in r14 to ones . Grea\", \"t, so we've hoisted all of the unnecessary computation out of the inner loop, being left only with a\", \"dding the ones position to the rest of the number. Let's g o out a level. M00\\\\_L02 is the label for \", \"the tens loop. What do we see there? Trouble. The two instructions imul ecx,esi,3E8 and imul eax,edi\", \",64 are performing the thousands * 1000 and hundreds * 100 operations, highlighting that these opera\", \"tions which could have been hoisted out further were left stuck in the next-to-innermost loop. Now, \", \"here's what we get for .NET 7, where this was improved in dotnet/runtime#68061:\\n\\n```\\n; Program.Compu\", \"te() push      r15 push      r14 push      r12 push      rdi push      rsi push      rbp push      r\", \"bx sub       rsp,20 xor       esi,esi M00_L00: xor       edi,edi imul      ebx,esi,3E8 M00_L01: xor \", \"      ebp,ebp imul      r14d,edi,64 add       r14d,ebx M00_L02: xor       r15d,r15d lea       ecx,[r\", \"bp+rbp*4] lea       r12d,[r14+rcx*2] M00_L03: lea       ecx,[r12+r15] call      qword ptr [Program.P\", \"rocess(Int32)] inc       r15d cmp       r15d,0A jl        short M00_L03 inc       ebp cmp       ebp,\", \"0A jl        short M00_L02 inc       edi cmp       edi,0A jl        short M00_L01 inc       esi cmp \", \"      esi,0A jl        short M00_L00 add       rsp,20 pop       rbx pop       rbp pop       rsi pop \", \"      rdi pop       r12 pop       r14 pop       r15 ret ; Total bytes of code 99\\n```\\n\\nNotice now whe\", \"re those imul instructions live. There are four labels, each one corresponding to one of the loops, \", \"and we can see the outermost loop has the imul ebx,esi,3E8 (for the thousands computation) and the n\", \"ext loop has the imul r14d,edi,64 (for the hundreds computation), highlighting that these computatio\", \"ns were hoisted out to the appropriate level (the tens and ones computation are still in the right p\", \"laces).\\n\\nMore improvements have gone in on the cloning side. Previously, loop cloning would only app\", \"ly for loops iterating by 1 from a low to a high value. With dotnet/runtime#60148, the comparison ag\", \"ainst the upper value can be &lt;= rather than just &lt; . And with dotnet/runtime#67930, loops that\", \" iterate downward can also be cloned, as can loops that have increments and decrements larger than 1\", \". Consider this benchmark:\\n\\n```\\nprivate int[] _values = Enumerable.Range(0, 1000).ToArray(); [Benchm\", \"ark] [Arguments(0, 0, 1000)] public int LastIndexOf(int arg, int offset, int count) { int[] values =\", \" _values; for (int i = offset + count - 1; i >= offset; i--) if (values[i] == arg) return i; return \", \"0; }\\n```\\n\\nWithout loop cloning, the JIT can't assume that offset through offset+count are in range, \", \"and thus every access to the array needs to be bounds checked. With loop cloning, the JIT could gene\", \"rate one version of the loop without bounds checks and only use that when it knows all accesses will\", \" be valid. That's exactly what happens now in .NET 7. Here's what we got with .NET 6:\\n\\n```\\n; Program\", \".LastIndexOf(Int32, Int32, Int32) sub       rsp,28 mov       rcx,[rcx+8] lea       eax,[r8+r9+0FFFF]\", \" cmp       eax,r8d jl        short M00_L01 mov       r9d,[rcx+8] nop       word ptr [rax+rax] M00_L0\", \"0: cmp       eax,r9d jae       short M00_L03 movsxd    r10,eax cmp       [rcx+r10*4+10],edx je      \", \"  short M00_L02 dec       eax cmp       eax,r8d jge       short M00_L00 M00_L01: xor       eax,eax a\", \"dd       rsp,28 ret M00_L02: add       rsp,28 ret M00_L03: call      CORINFO_HELP_RNGCHKFAIL\\n```\\n\\n``\", \"`\\nint       3 ; Total bytes of code 72\\n```\\n\\nNotice how in the core loop, a t label M00\\\\_L00, there's\", \" a bounds check ( cmp eax,r9d and jae short M00\\\\_L03 , which jumps to a call CORINFO\\\\_HELP\\\\_RNGCHKFA\", \"IL ). And here's what we get with .NET 7:\\n\\n```\\n; Program.LastIndexOf(Int32, Int32, Int32) sub       \", \"rsp,28 mov       rax,[rcx+8] lea       ecx,[r8+r9+0FFFF] cmp       ecx,r8d jl        short M00_L02 t\", \"est      rax,rax je        short M00_L01 test      ecx,ecx jl        short M00_L01 test      r8d,r8d\", \" jl        short M00_L01 cmp       [rax+8],ecx jle       short M00_L01 M00_L00: mov       r9d,ecx cm\", \"p       [rax+r9*4+10],edx je        short M00_L03 dec       ecx cmp       ecx,r8d jge       short M0\", \"0_L00 jmp       short M00_L02 M00_L01: cmp       ecx,[rax+8] jae       short M00_L04 mov       r9d,e\", \"cx cmp       [rax+r9*4+10],edx je        short M00_L03 dec       ecx cmp       ecx,r8d jge       sho\", \"rt M00_L01 M00_L02: xor       eax,eax add       rsp,28 ret M00_L03: mov       eax,ecx add       rsp,\", \"28 ret M00_L04: call      CORINFO_HELP_RNGCHKFAIL int       3 ; Total bytes of code 98\\n```\\n\\nNotice h\", \"ow the code size is larger, and how there are now two variations of the loop: one at M00\\\\_L00 and on\", \"e at M00\\\\_L01. The second one, M00\\\\_L01, has a branch to that same call\\n\\nCORINFO\\\\_HELP\\\\_RNGCHKFAIL ,\", \" but the first one doesn't, because that loop will only end up being used after proving that the off\", \"set , count , and \\\\_values.Length are such that the indexing will always be in bounds.\\n\\nOther change\", \"s also improved loop cloning. dotnet/runtime#59886 enables the JIT to choose different forms for how\", \" to emit the the conditions for choosing the fast or slow loop path, e.g. whether to emit\\n\\nall the c\", \"onditions, &amp; them together, and then branch ( if (!(cond1 &amp; cond2)) goto slowPath ), or whet\", \"her to emit each condition on its own ( if (!cond1) goto slowPath; if (!cond2) goto slowPath ). dotn\", \"et/runtime#66257 enables loop cloning to kick in when the loop variable is initialized to more kinds\", \" of expressions (e.g. for (int fromindex = lastIndex - lengthToClear; ...) ). And dotnet/runtime#702\", \"32 increases the JIT's willingness to clone loops with bodies that do a broader set of operations.\\n\\n\", \"## Folding, propagation, and substitution\\n\\nConstant folding is an optimization where a compiler comp\", \"utes the value of an expression involving only constants at compile-time rather than generating the \", \"code to compute the value at run-time. There are multiple levels of constant folding in .NET, with s\", \"ome constant folding performed by the C# compiler and some constant folding performed by the JIT com\", \"piler. For example, given the C# code:\\n\\n```\\n[Benchmark] public int A() => 3 + (4 * 5); [Benchmark] p\", \"ublic int B() => A() * 2;\\n```\\n\\nthe C# compiler will generate IL for these methods like the following\", \":\\n\\n```\\n.method public hidebysig instance int32 A () cil managed { .maxstack 8 IL_0000: ldc.i4.s 23 I\", \"L_0002: ret } .method public hidebysig instance int32 B () cil managed { .maxstack 8 IL_0000: ldarg.\", \"0 IL_0001: call instance int32 Program::A() IL_0006: ldc.i4.2 IL_0007: mul IL_0008: ret }\\n```\\n\\nYou c\", \"an see that the C# compiler has computed the value of 3 + (4*5) , as the IL for method A simply cont\", \"ains the equivalent of return 23; . However, method B contains the equivalent of return A() * 2; , h\", \"ighlighting that the constant folding performed by the C# compiler was intramethod only. Now here's \", \"what the JIT generates:\\n\\n```\\n; Program.A() mov       eax,17 ret ; Total bytes of code 6 ; Program.B(\", \") mov       eax,2E ret ; Total bytes of code 6\\n```\\n\\nThe assembly for method A isn't particularly int\", \"eresting; it's just returning that same value 23 (hex 0x17). But method B is more interesting. The J\", \"IT has inlined the call from B to A , exposing the contents of A to B , such that the JIT effectivel\", \"y sees the body of B as the equivalent of return 23 * 2; . At that point, the JIT can do its own con\", \"stant folding, and it transforms the body of B to simply return 46 (hex 0x2e). Constant propagation \", \"is intricately linked to constant folding and is essentially just the idea that you can substitute a\", \" constant value (typically one computed via constant folding) into further expressions, at which poi\", \"nt they may also be able to be folded.\\n\\nThe JIT has long performed constant folding, but it improves\", \" further in .NET 7. One of the ways constant folding can improve is by exposing more values to be fo\", \"lded, which often means more inlining. dotnet/runtime#55745 helped the inliner to understand that a \", \"method call like M(constant + constant) (noting that those constants might be the result of some oth\", \"er method call) is itself passing a constant to M , and a constant being passed to a method call is \", \"a hint to the inliner that it should consider being more aggressive about inlining, since exposing t\", \"hat constant to the body of the callee can potentially significantly reduce the amount of code requi\", \"red to implement the callee. The JIT might have previously inlined such a method anyway, but when it\", \" comes to inlining, the JIT is all about heuristics and generating enough evidence that it's worthwh\", \"ile to inline something; this contributes to that evidence. This pattern shows up, for example, in t\", \"he various FromXx methods on TimeSpan . For example, TimeSpan.FromSeconds is implemented as:\\n\\n```\\npu\", \"blic static TimeSpan FromSeconds(double value) => Interval(value, TicksPerSecond); // TicksPerSecond\", \" is a constant\\n```\\n\\nand, eschewing argument validation for the purposes of this example, Interval is\", \":\\n\\n```\\nprivate static TimeSpan Interval(double value, double scale) => IntervalFromDoubleTicks(value\", \" * scale); private static TimeSpan IntervalFromDoubleTicks(double ticks) => ticks == long.MaxValue ?\", \" TimeSpan.MaxValue : new TimeSpan((long)ticks);\\n```\\n\\nwhich if everything gets inlined means FromSeco\", \"nds is essentially:\\n\\n```\\npublic static TimeSpan FromSeconds(double value) { double ticks = value * 1\", \"0_000_000; return ticks == long.MaxValue ? TimeSpan.MaxValue : new TimeSpan((long)ticks); }\\n```\\n\\nand\", \" if value is a constant, let's say 5 , that whole thing can be constant folded (with dead code elimi\", \"nation on the ticks == long.MaxValue branch) to simply:\\n\\n```\\nreturn new TimeSpan(50_000_000);\\n```\\n\\nI\", \"'ll spare you the .NET 6 assembly for this, but on .NET 7 with a benchmark like:\\n\\n```\\n[Benchmark] pu\", \"blic TimeSpan FromSeconds() => TimeSpan.FromSeconds(5);\\n```\\n\\nwe now get the simple and clean:\\n\\n```\\n;\", \" Program.FromSeconds() mov       eax,2FAF080\\n```\\n\\n```\\nret ; Total bytes of code 6\\n```\\n\\nAnother chang\", \"e improving constant folding included dotnet/runtime#57726 from [@SingleAccretion](https://github.co\", \"m/SingleAccretion), which unblocked constant folding in a particular scenario that sometimes manifes\", \"ts when doing field-by-field assignment of structs being returned from method calls. As a small exam\", \"ple, consider this trivial property, which access the Color.DarkOrange property, which in turn does \", \"new Color(KnownColor.DarkOrange) :\\n\\n```\\n[Benchmark] public Color DarkOrange() => Color.DarkOrange;\\n`\", \"``\\n\\nIn .NET 6, the JIT generated this:\\n\\n```\\n; Program.DarkOrange() mov       eax,1 mov       ecx,39 \", \"xor       r8d,r8d mov       [rdx],r8 mov       [rdx+8],r8 mov       [rdx+10],cx mov       [rdx+12],a\", \"x mov       rax,rdx ret ; Total bytes of code 32\\n```\\n\\nThe interesting thing here is that some consta\", \"nts (39, which is the value of KnownColor.DarkOrange , and 1, which is a private StateKnownColorVali\", \"d constant) are being loaded into registers ( mov eax, 1 , mov ecx, 39 ) and then later being stored\", \" into the relevant location for the Color struct being returned ( mov [rdx+12],ax and mov [rdx+10],c\", \"x ). In .NET 7, it now generates:\\n\\n```\\n; Program.DarkOrange() xor       eax,eax mov       [rdx],rax \", \"mov       [rdx+8],rax mov       word ptr [rdx+10],39 mov       word ptr [rdx+12],1 mov       rax,rdx\", \" ret ; Total bytes of code 25\\n```\\n\\nwith direct assignment of these constant values into their destin\", \"ation locations ( mov word ptr [rdx+12],1 and mov word ptr [rdx+10],39 ). Other changes contributing\", \" to constant folding included dotnet/runtime#58171 from [@SingleAccretion](https://github.com/Single\", \"Accretion) and dotnet/runtime#57605 from [@SingleAccretion](https://github.com/SingleAccretion).\\n\\nHo\", \"wever, a large category of improvement came from an optimization related to propagation, that of for\", \"ward substitution. Consider this silly benchmark:\\n\\n```\\n[Benchmark] public int Compute1() => Value + \", \"Value + Value + Value + Value; [Benchmark] public int Compute2() => SomethingElse() + Value + Value \", \"+ Value + Value + Value; private static int Value => 16;\\n```\\n\\n```\\n[MethodImpl(MethodImplOptions.NoIn\", \"lining)] private static int SomethingElse() => 42;\\n```\\n\\nIf we look at the assembly code generated fo\", \"r Compute1 on .NET 6, it looks like what we'd hope for. We're adding Value 5 times, Value is trivial\", \"ly inlined and returns a constant value 16, and so we'd hope that the assembly code generated for Co\", \"mpute1 would effectively just be returning the value 80 (hex 0x50), which is exactly what happens:\\n\\n\", \"```\\n; Program.Compute1() mov       eax,50 ret ; Total bytes of code 6\\n```\\n\\nBut Compute2 is a bit dif\", \"ferent. The structure of the code is such that the additional call to SomethingElse ends up slightly\", \" perturbing something about the JIT's analysis, and .NET 6 ends up with this assembly code:\\n\\n```\\n; P\", \"rogram.Compute2() sub       rsp,28 call      Program.SomethingElse() add       eax,10 add       eax,\", \"10 add       eax,10 add       eax,10 add       eax,10 add       rsp,28 ret ; Total bytes of code 29\\n\", \"```\\n\\nRather than a single mov eax, 50 to put the value 0x50 into the return register, we have 5 sepa\", \"rate add eax, 10 to build up that same 0x5 0 (80) value. That's\\u2026 not ideal.\\n\\nIt turns out that many \", \"of the JIT's optimizations operate on the tree data structures created as part of parsing the IL. In\", \" some cases, optimizations can do better when they're exposed to more of the program, in other words\", \" when the tree they're operating on is larger and contains more to be analyzed. However, various ope\", \"rations can break up these trees into smaller, individual ones, such as with temporary variables cre\", \"ated as part of inlining, and in doing so can inhibit these operations. Something is needed in order\", \" to effectively stitch these trees back together, and that's forward substitution. You can think of \", \"forward substitution almost like an inverse of CSE; rather than trying to find duplicate expressions\", \" and eliminate them by computing the value once and storing it into a temporary, forward substitutio\", \"n eliminates that temporary and effectively moves the expression tree into its use site. Obviously y\", \"ou don't want to do this if it would then negate CSE and result in duplicate work, but for expressio\", \"ns that are defined once and used once, this kind of forward propagation is valuable. dotnet/runtime\", \"#61023 added an initial limited version of forward substitution, and then dotnet/runtime#63720 added\", \" a more robust generalized implementation. Subsequently, dotnet/runtime#70587 expanded it to also co\", \"ver some SIMD vectors, and then dotnet/runtime#71161 improved it further to enable substitutions int\", \"o more places (in this case into call arguments). And with those, our silly benchmark now produces t\", \"he following on .NET 7:\\n\\n```\\n; Program.Compute2() sub       rsp,28 call      qword ptr [7FFCB8DAF9A8\", \"]\\n```\\n\\n| add                      | eax,50                   |\\n|--------------------------|---------\", \"-----------------|\\n| add                      | rsp,28                   |\\n| ; Total bytes of code 1\", \"8 | ; Total bytes of code 18 |\\n\\n## Vectorization\\n\\nSIMD, or Single Instruction Multiple Data, is a ki\", \"nd of processing in which one instruction applies to multiple pieces of data at the same time. You'v\", \"e got a list of numbers and you want to find the index of a particular value? You could walk the lis\", \"t comparing one element at a time, and that would be fine functionally. But what if in the same amou\", \"nt of time it takes you to read and compare one element, you could instead read and compare two elem\", \"ents, or four elements, or 32 elements? That's SIMD, and the art of utilizing SIMD instru ctions is \", \"lovingly referred to as 'vectorization,' where operations are applied to all of the elements in a 'v\", \"ector' at the same time.\\n\\n.NET has long had support for vectorization in the form of Vector&lt;T&gt;\", \" , which is an easy-to-use type with first-class JIT support to enable a developer to write vectoriz\", \"ed implementations. One of Vector&lt;T&gt; 's greatest strengths is also one of its greatest weaknes\", \"ses. The type is designed to adapt to whatever width vector instructions are available in your hardw\", \"are. If the machine supports 256-bit width vectors, great, that's what Vector&lt;T&gt; will target. \", \"If not, if the machine supports 128-bit width vectors, great, that's what Vector&lt;T&gt; targets. B\", \"ut that flexibility comes with various downsides, at least today; for example, the operations you ca\", \"n perform on a Vector&lt;T&gt; end up needing to be agnostic to the width of the vectors used, since\", \" the width is variable based on the hardware on which the code actually runs. And that means the ope\", \"rations that can be exposed on Vector&lt;T&gt; are limited, which in turn limits the kinds of operat\", \"ions that can be vectorized with it. Also, because it's only ever a single size in a given process, \", \"some data set sizes that fall in between 128 bits and 256 bits might not be processed as well as you\", \"'d hope. You write your Vector&lt;byte&gt; -based algorithm, and you run it on a machine with suppor\", \"t for 256-bit vectors, which means it can process 32 bytes at a time, but then you feed it an input \", \"with 31 bytes. Had Vector&lt;T&gt; mapped to 128-bit vectors, it could have been used to improve the\", \" processing of that input, but as its vector size is larger than the input data size, the implementa\", \"tion ends up falling back to one that's not accelerated. There are also issues related to R2R and Na\", \"tive AOT, since ahead-of-time compilation needs to know in advance what instructions should be used \", \"for Vector&lt;T&gt; operations. You already saw this earlier when discussing the output of DOTNET\\\\_J\", \"itDisasmSummary ; we saw that the NarrowUtf16ToAscii method was one of only a few methods that was J\", \"IT compiled in a 'hello, world' console app, and that this was because it lacked R2R code due to its\", \" use of Vector&lt;T&gt; .\\n\\nStarting in .NET Core 3.0, .NET gained literally thousands of new 'hardwa\", \"re intrinsics' methods, most of which are .NET APIs that map down to one of these SIMD instructions.\", \" These intrinsics enable an expert to write an implementation tuned to a specific instruction set, a\", \"nd if done well, get the best possible performance, but it also requires the developer to understand\", \" each instruction set and to implement their algorithm for each instruction set that might be releva\", \"nt, e.g. an AVX2 implementation if it's supported, or an SSE2 implementation if it's supported, or a\", \"n ArmBase implementation if it's supported, and so on.\\n\\n.NET 7 has introduced a middle ground. Previ\", \"ous releases saw the introduction of the Vector128&lt;T&gt; and Vector256&lt;T&gt; types, but purely\", \" as the vehicle by which data moved in and out of the hardware intrinsics, since they're all tied to\", \" specific width vectors. Now in . NET 7, exposed via\\n\\ndotnet/runtime#53450, dotnet/runtime#63414, do\", \"tnet/runtime#60094, and dotnet/runtime#68559, a very large set of cross-platform operations is defin\", \"ed over these types as well, e.g. Vector128&lt;T&gt;.ExtractMostSignificantBits , Vector256.Conditio\", \"nalSelect , and so on. A developer who wants or needs to go beyond what the high-level Vector&lt;T&g\", \"t; offers can choose to target one or more of these two types. Typically this would amount to a deve\", \"loper writing one code path based on Vector128&lt;T&gt; , as that has the broadest reach and achieve\", \"s a significant amount of the gains from vectorization, and then if is motivated to do so can add a \", \"second path for Vector256&lt;T&gt; in order to potentially double throughput further on platforms th\", \"at have 256-bit width vectors. Think of these types and methods as a platform-abstraction layer: you\", \" code to these methods, and then the JIT translates them into the most appropriate instructions for \", \"the underlying platform. Consider this simple code as an example:\\n\\n```\\nusing System.Runtime.Compiler\", \"Services; using System.Runtime.Intrinsics; using System.Runtime.Intrinsics.X86; internal class Progr\", \"am { private static void Main() { Vector128<byte> v = Vector128.Create((byte)123); while ( true ) { \", \"WithIntrinsics(v); WithVector(v); } } [MethodImpl(MethodImplOptions.NoInlining)] private static int \", \"WithIntrinsics(Vector128<byte> v) => Sse2.MoveMask(v); [MethodImpl(MethodImplOptions.NoInlining)] pr\", \"ivate static uint WithVector(Vector128<byte> v) => v.ExtractMostSignificantBits(); }\\n```\\n\\nI have two\", \" functions: one that directly uses the Sse2.MoveMask hardware intrinsic and one that uses the new Ve\", \"ctor128&lt;T&gt;.ExtractMostSignificantBits method. Using DOTNET\\\\_JitDisasm=Program.* , here's what \", \"the optimized tier -1 code for these looks like on my x64 Windows machine:\\n\\n```\\n; Assembly listing f\", \"or method Program:WithIntrinsics(Vector128`1):int G_M000_IG01:                ;; offset=0000H C5F877\", \"               vzeroupper G_M000_IG02:                ;; offset=0003H C5F91001             vmovupd  \", \"xmm0, xmmword ptr [rcx] C5F9D7C0             vpmovmskb eax, xmm0 G_M000_IG03:                ;; offs\", \"et=000BH C3                   ret ; Total bytes of code 12 ; Assembly listing for method Program:Wit\", \"hVector(Vector128`1):int G_M000_IG01:                ;; offset=0000H C5F877               vzeroupper\", \"\\n```\\n\\n```\\nG_M000_IG02:                ;; offset=0003H C5F91001             vmovupd  xmm0, xmmword pt\", \"r [rcx] C5F9D7C0             vpmovmskb eax, xmm0 G_M000_IG03:                ;; offset=000BH C3     \", \"              ret ; Total bytes of code 12\\n```\\n\\nNotice anything? The code for the two methods is ide\", \"ntical, both resulting in a vpmovmskb (Move Byte Mask) instruction. Yet the former code will only wo\", \"rk on a platform that supports SSE2 whereas the latter code will work on any platform with support f\", \"or 128-bit vectors, including Arm64 and WASM (and any future platforms on-boarded that also support \", \"SIMD ); it'll just result in different instructions being emitted on those platforms.\\n\\nTo explore th\", \"is a bit more, let's take a simple example and vectorize it. We'll implement a Contains method, wher\", \"e we want to search a span of bytes for a specific value and return whether it was found:\\n\\n```\\nstati\", \"c bool Contains(ReadOnlySpan<byte> haystack, byte needle) { for (int i = 0; i < haystack.Length; i++\", \") { if (haystack[i] == needle) { return true ; } } return false ; }\\n```\\n\\nHow would we vectorize this\", \" with Vector&lt;T&gt; ? First things first, we need to check whether it's even supported, and fall b\", \"ack to our existing implementation if it's not ( Vector.IsHardwareAccelerated ). We also need to fal\", \"l back if the length of the input is less than the size of a vector ( Vector&lt;byte&gt;.Count ).\\n\\n`\", \"``\\nstatic bool Contains(ReadOnlySpan<byte> haystack, byte needle) { if (Vector.IsHardwareAccelerated\", \" && haystack.Length >= Vector<byte>.Count) { // ... } else { for (int i = 0; i < haystack.Length; i+\", \"+) { if (haystack[i] == needle) { return true ; } } } return false ; }\\n```\\n\\nNow that we know we h av\", \"e enough data, we can get to coding our vectorized loop. In this loop, we'll be searching for the ne\", \"edle , which means we need a vector that contains that value for every element; the Vector&lt;T&gt; \", \"'s constructor provides that ( new Vector&lt;byte&gt;(needle) ). And we need to be able to slice off\", \" a vector's width of data at a time; for a bit more efficiency, I'll use pointers. We need a current\", \" iteration pointer, and we need to iterate until the point where we couldn't form another vector bec\", \"ause we're too close to the end, and a straightforward way to do that is to get a pointer that's exa\", \"ctly one vector's width from the end; that way, we can just iterate until our current pointer is equ\", \"al to or greater than that threshold. And finally, in our loop body, we need to compare our current \", \"vector with the target vector to see if any elements are the same ( Vector.EqualsAny ), if any is re\", \"turning true, and if not bumping our current pointer to the next location. At this point we have:\\n\\n`\", \"``\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle) { if (Vector.IsHardwareAcce\", \"lerated && haystack.Length >= Vector<byte>.Count) { fixed (byte* haystackPtr = &MemoryMarshal.GetRef\", \"erence(haystack)) { Vector<byte> target = new Vector<byte>(needle); byte* current = haystackPtr; byt\", \"e* endMinusOneVector = haystackPtr + haystack.Length - Vector<byte>.Count; do { if (Vector.EqualsAny\", \"(target, *(Vector<byte>*)current)) { return true ; } current += Vector<byte>.Count; } while (current\", \" < endMinusOneVector); // ... } } else { for (int i = 0; i < haystack.Length; i++) { if (haystack[i]\", \" == needle) { return true ; } } } return false ; }\\n```\\n\\nAnd we're almost done. The last issue to han\", \"dle is we may still have a few elements at the end we haven't searched. There are a couple of ways w\", \"e could handle that. One would be to just continue with our fall back implementation and process eac\", \"h of the remaining elements one at a time. Another would be to employ a trick that's co mmon when ve\", \"ctorizing idempotent operations. Our operation isn't mutating anything, which means it doesn't matte\", \"r if we compare the same element multiple times, which means we can just do one final vector compare\", \" for the last vector in the search space;\\n\\nth at might or might not overlap with elements we've alre\", \"ady looked at, but it won't hurt anything if it does. And with that, our implementation is complete:\", \"\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle) { if (Vector.IsHardwareA\", \"ccelerated && haystack.Length >= Vector<byte>.Count) { fixed (byte* haystackPtr = &MemoryMarshal.Get\", \"Reference(haystack)) { Vector<byte> target = new Vector<byte>(needle); byte* current = haystackPtr; \", \"byte* endMinusOneVector = haystackPtr + haystack.Length - Vector<byte>.Count; do { if (Vector.Equals\", \"Any(target, *(Vector<byte>*)current)) { return true ; } current += Vector<byte>.Count; } while (curr\", \"ent < endMinusOneVector); if (Vector.EqualsAny(target, *(Vector<byte>*)endMinusOneVector)) { return \", \"true ; } } } else { for (int i = 0; i < haystack.Length; i++) { if (haystack[i] == needle) { return \", \"true ; } } } return false ; }\\n```\\n\\nCongratulations, we've vectorized this operation, and fairly dece\", \"ntly at that. We can throw this into benchmarkdotnet and see really nice speedups:\\n\\n```\\nprivate byte\", \"[] _data = Enumerable.Repeat((byte)123, 999).Append((byte)42).ToArray(); [Benchmark(Baseline = true \", \")] [Arguments((byte)42)] public bool Find(byte value) => Contains(_data, value); // just the fallbac\", \"k path in its own method [Benchmark] [Arguments((byte)42)] public bool FindVectorized(byte value) =>\", \" Contains_Vectorized(_data, value); // the implementation we just wrote\\n```\\n\\n| Method         | Mean\", \"      |   Ratio |\\n|----------------|-----------|---------|\\n| Find           | 484.05 ns |    1    |\\n\", \"| FindVectorized | 20.21 ns  |    0.04 |\\n\\nA 24x speedup! Woo hoo, victory, all your performance are \", \"belong to us!\\n\\nYou deploy this in your service, and you see Contains being called on your hot path, \", \"but you don't see the improvements you were expecting. You dig in a little more, and you discover th\", \"at while you tested this with an input array with 1000 elements, typical inputs had more like 30 ele\", \"ments. What happens if we change our benchmark to have just 30 elements? That' s not long enough to \", \"form a vector, so we fall back to the one-at-atime path, and we don't get any speedups at all.\\n\\nOne \", \"thing we can now do is switch from using Vector&lt;T&gt; to Vector128&lt;T&gt; . That will then lowe\", \"r the threshold from 32 bytes to 16 bytes, such that inputs in that range will still have some amoun\", \"t of vectorization applied. As these Vector128&lt;T&gt; and Vector256&lt;T&gt; types have been desig\", \"ned very recently, they also utilize all the cool new toys, and thus we can use ref s instead of poi\", \"nters. Other than that, we can keep the shape of our implementation almost the same, substituting Ve\", \"ctor128 where we were using Vector , and using some methods on Unsafe to manipulate our ref s instea\", \"d of pointer arithmetic on the span we fixed.\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<byte> ha\", \"ystack, byte needle) { if (Vector128.IsHardwareAccelerated && haystack.Length >= Vector128<byte>.Cou\", \"nt) { ref byte current = ref MemoryMarshal.GetReference(haystack); Vector128<byte> target = Vector12\", \"8.Create(needle); ref byte endMinusOneVector = ref Unsafe.Add( ref current, haystack.Length Vector12\", \"8<byte>.Count); do { if (Vector128.EqualsAny(target, Vector128.LoadUnsafe( ref current))) { return t\", \"rue ; } current = ref Unsafe.Add( ref current, Vector128<byte>.Count); } while (Unsafe.IsAddressLess\", \"Than( ref current, ref endMinusOneVector)); if (Vector128.EqualsAny(target, Vector128.LoadUnsafe( re\", \"f endMinusOneVector))) { return true ; } } else { for (int i = 0; i < haystack.Length; i++) { if (ha\", \"ystack[i] == needle) { return true ; } } }\\n```\\n\\n```\\nreturn false ; }\\n```\\n\\nWith that in hand, we can \", \"now try it on our smaller 30 element data set:\\n\\n```\\nprivate byte[] _data = Enumerable.Repeat((byte)1\", \"23, 29).Append((byte)42).ToArray(); [Benchmark(Baseline = true )] [Arguments((byte)42)] public bool \", \"Find(byte value) => Contains(_data, value); [Benchmark] [Arguments((byte)42)] public bool FindVector\", \"ized(byte value) => Contains_Vectorized(_data, value);\\n```\\n\\n| Method         | Mean      |   Ratio |\", \"\\n|----------------|-----------|---------|\\n| Find           | 15.388 ns |    1    |\\n| FindVectorized \", \"| 1.747 ns  |    0.11 |\\n\\nWoo hoo, victory, all your performance are belong to us\\u2026 again!\\n\\nWhat about\", \" on the larger data set again? Previously with Vector&lt;T&gt; we had a 24x speedup, but now:\\n\\n| Met\", \"hod         | Mean      |   Ratio |\\n|----------------|-----------|---------|\\n| Find           | 484.\", \"25 ns |    1    |\\n| FindVectorized | 32.92 ns  |    0.07 |\\n\\n\\u2026 closer to 15x. Nothing to sneeze at, b\", \"ut it's not the 24x we previously saw. What if we want to have our cake and eat it, too? Let's also \", \"add a Vector256&lt;T&gt; path. To do that, we literally copy/paste our Vector128&lt;T&gt; code, sear\", \"ch/replace all references to Vector128 in the copied code with Vector256 , and just put it into an a\", \"dditional condition that uses the Vector256&lt;T&gt; path if it's supported and there are enough ele\", \"ments to utilize it.\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle) { if\", \" (Vector128.IsHardwareAccelerated && haystack.Length >= Vector128<byte>.Count) { ref byte current = \", \"ref MemoryMarshal.GetReference(haystack); if (Vector256.IsHardwareAccelerated && haystack.Length >= \", \"Vector256<byte>.Count) { Vector256<byte> target = Vector256.Create(needle); ref byte endMinusOneVect\", \"or = ref Unsafe.Add( ref current, haystack.Length Vector256<byte>.Count); do { if (Vector256.EqualsA\", \"ny(target, Vector256.LoadUnsafe( ref current))) { return true ; } current = ref Unsafe.Add( ref curr\", \"ent, Vector256<byte>.Count); } while (Unsafe.IsAddressLessThan( ref current, ref endMinusOneVector))\", \";\\n```\\n\\n```\\nif (Vector256.EqualsAny(target, Vector256.LoadUnsafe( ref endMinusOneVector))) { return t\", \"rue ; } } else { Vector128<byte> target = Vector128.Create(needle); ref byte endMinusOneVector = ref\", \" Unsafe.Add( ref current, haystack.Length Vector128<byte>.Count); do { if (Vector128.EqualsAny(targe\", \"t, Vector128.LoadUnsafe( ref current))) { return true ; } current = ref Unsafe.Add( ref current, Vec\", \"tor128<byte>.Count); } while (Unsafe.IsAddressLessThan( ref current, ref endMinusOneVector)); if (Ve\", \"ctor128.EqualsAny(target, Vector128.LoadUnsafe( ref endMinusOneVector))) { return true ; } } } else \", \"{ for (int i = 0; i < haystack.Length; i++) { if (haystack[i] == needle) { return true ; } } } retur\", \"n false ; }\\n```\\n\\nAnd, boom, we're back:\\n\\n| Method         | Mean      |   Ratio |\\n|----------------|\", \"-----------|---------|\\n| Find           | 484.53 ns |    1    |\\n| FindVectorized | 20.08 ns  |    0.\", \"04 |\\n\\nWe now have an implementation that is vectorized on any platform with either 128-bit or 256-bi\", \"t vector instructions (x86, x64, Arm64, WASM, etc.), that can use either based on the input length, \", \"and that can be included in an R2R image if that's of interest.\\n\\nThere are many factors that impact \", \"which path you go down, and I expect we'll have guidance forthcoming to help navigate all the factor\", \"s and approaches. But the capabilities are all there, and whether you choose to use Vector&lt;T&gt; \", \", Vector128&lt;T&gt; and/or Vector256&lt;T&gt; , or the hardware intrinsics directly, there are some\", \" amazing performance opportunities ready for the taking.\\n\\nI already mentioned several PRs that expos\", \"ed the new cross-platform vector support, but that only scratches the surface of the work done to ac\", \"tually enable these operations and to enable them to produce high-quality code. As just one example \", \"of a category of such work, a set of changes went in to help ensure that zero vector constants are h\", \"andled well, such as dotnet/runtime#63821 that 'morphed' (changed) Vector128/256&lt;T&gt;.Create(def\", \"ault) into Vector128/256&lt;T&gt;.Zero , which then enables subsequent optimizations to focus only o\", \"n Zero ; dotnet/runtime#65028 that enabled constant propagation of Vector128/256&lt;T&gt;.Zero ; dot\", \"net/runtime#68874 and dotnet/runtime#70171 that add firstclass knowledge of vector constants to the \", \"JIT's intermediate representation; and dotnet/runtime#62933, dotnet/runtime#65632, dotnet/runtime#55\", \"875, dotnet/runtime#67502, and dotnet/runtime#64783 that all improve the code quality of instruction\", \"s generated for zero vector comparisons.\\n\\n## Inlining\\n\\nInlining is one of the most important optimiz\", \"ations the JIT can do. The concept is simple: instead of making a call to some method, take the code\", \" from that method and bake it into the call site. This has the obvious advantage of avoiding the ove\", \"rhead of a method call, but except for really small methods on really hot paths, that' s often on th\", \"e smaller side of the wins inlining brings. The bigger wins are due to the callee's code being expos\", \"ed to the caller's code, and vice versa. So, for example, if the caller is passing a constant as an \", \"argument to the callee, if the method isn't inlined, the compilation of the callee has no knowledge \", \"of that constant, but if the callee is inlined, all of the code in the callee is then aware of its a\", \"rgument being a constant value, and can do all of the optimizations possible with such a constant, l\", \"ike dead code elimination, branch elimination, constant folding and propagation, and so on. Of cours\", \"e, if it were all rainbows and unicorns, everything possible to be inlined would be inlined, and tha\", \"t's obviously not happening. Inlining brings with it th e cost of potentially increased binary size.\", \" If the code being inlined would result in the same amount or less assembly code in the caller than \", \"it takes to call the callee (and if the JIT can quickly determine that), then inlining is a nobraine\", \"r. But if the code being inlined would increase the size of the callee non-trivially, now the JIT ne\", \"eds to weigh that increase in code size against the throughput benefits that could come from it. Tha\", \"t code size increase can itself result in throughput regressions, due to increasing the number of di\", \"stinct instructions to be executed and thereby putting more pressure on the instruction cache. As wi\", \"th any cache, the more times you need to read from memory to populate it, the less effective the cac\", \"he will be. If you have a function that gets inlined into 100 different call sites, every one of tho\", \"se call sites' copies of the callee's instructions are unique, and calling each of those 100 functio\", \"ns could end up thrashing the instruction cache; in contrast, if all of those 1 00 functions 'shared\", \"' the same instructions by simply calling the single instance of the callee, it's likely the instruc\", \"tion cache would be much more effective and lead to fewer trips to memory.\\n\\nAll that is to say, inli\", \"ning is really important, it's important that the 'right' things be inlined and that it not overinli\", \"ne, and as such every release of .NET in recent memory has seen nice improvements around inlining. .\", \"NET 7 is no exception.\\n\\nOne really interesting improvement around inlining is dotnet/runtime#64521, \", \"and it might be surprising. Consider the Boolean.ToString method; here's its full implementation:\\n\\np\", \"ublic override string ToString()\\n\\n{\\n\\n```\\nif (!m_value) return \\\"False\\\"; return \\\"True\\\"; }\\n```\\n\\nPretty \", \"simple, right? You'd expect something this trivial to be inlined. Alas, on .NET 6, this benchmark:\\n\\n\", \"```\\nprivate bool _value = true ; [Benchmark] public int BoolStringLength() => _value.ToString().Leng\", \"th;\\n```\\n\\nproduces this assembly code:\\n\\n```\\n; Program.BoolStringLength() sub       rsp,28 cmp       [\", \"rcx],ecx add       rcx,8 call      System.Boolean.ToString() mov       eax,[rax+8] add       rsp,28 \", \"ret ; Total bytes of code 23\\n```\\n\\nNote the call System.Boolean.ToString() . The reason for this is, \", \"historically, the JIT has been unable to inline methods across assembly boundaries if those methods \", \"contain string literals (like the \\\"False\\\" and \\\"True\\\" in that Boolean.ToString implementation). This \", \"restriction had to do with string interning and the possibility that such inlining could lead to vis\", \"ible behavioral differences. Those concerns are no longer valid, and so this PR removes the restrict\", \"ion. As a result, that same benchmark on .NET 7 now produces this:\\n\\n```\\n; Program.BoolStringLength()\", \" cmp       byte ptr [rcx+8],0 je        short M00_L01 mov       rax,1DB54800D20 mov       rax,[rax] \", \"M00_L00: mov       eax,[rax+8] ret M00_L01: mov       rax,1DB54800D18 mov       rax,[rax] jmp       \", \"short M00_L00 ; Total bytes of code 38\\n```\\n\\nNo more call System.Boolean.ToString() .\\n\\ndotnet/runtime\", \"#61408 made two changes related to inlining. First, it taught the inliner how to better see the what\", \" methods were being called in an inlining candidate, and in particular when tiered compilation is di\", \"sabled or when a method would bypass tier-0 (such as a method with loops before OSR existed or with \", \"OSR disabled); by understanding what methods are being called, it can better understand the cost of \", \"the method, e.g. if those method calls are actually hardware intrinsics with a very low cost. Second\", \", it enabled CSE in more cases with SIMD vectors.\\n\\ndotnet/runtime#71778 also impacted inlining, and \", \"in particular in situations where a typeof() could be propagated to the callee (e.g. via a method ar\", \"gument). In previous releases of .NET, various\\n\\nmembers on Type like IsValueType were turned into JI\", \"T intrinsics, such that the JIT could substitute a constant value for calls where it could compute t\", \"he answer at compile time. For example, this:\\n\\n```\\n[Benchmark] public bool IsValueType() => IsValueT\", \"ype<int>(); private static bool IsValueType<T>() => typeof (T).IsValueType;\\n```\\n\\nresults in this ass\", \"embly code on .NET 6:\\n\\n```\\n; Program.IsValueType() mov       eax,1 ret ; Total bytes of code 6\\n```\\n\\n\", \"However, change the benchmark slightly:\\n\\n```\\n[Benchmark] public bool IsValueType() => IsValueType( t\", \"ypeof (int)); private static bool IsValueType(Type t) => t.IsValueType;\\n```\\n\\nand it's no longer as s\", \"imple:\\n\\n```\\n; Program.IsValueType() sub       rsp,28 mov       rcx,offset MT_System.Int32 call      \", \"CORINFO_HELP_TYPEHANDLE_TO_RUNTIMETYPE mov       rcx,rax mov       rax,[7FFCA47C9560] cmp       [rcx\", \"],ecx add       rsp,28 jmp       rax ; Total bytes of code 38\\n```\\n\\nEffectively, as part of inlining \", \"the JIT loses the notion that the argument is a constant and fails to propagate it. This PR fixes th\", \"at, such that on .NET 7, we now get what we expect:\\n\\n```\\n; Program.IsValueType() mov       eax,1 ret\", \" ; Total bytes of code 6\\n```\\n\\n## Arm64\\n\\nA huge amount of effort in .NET 7 went into making code gen \", \"for Arm64 as good or better than its x64 counterpart. I've already discussed a bunch of PRs that are\", \" relevant regardless of architecture, and others that are specific to Arm, but there are plenty more\", \". To rattle off some of them:\\n\\n- Addressing modes . 'Addressing mode' is the term used to refer to h\", \"ow the operand of instructions are specified. It could be the actual value, it could be the address \", \"from where a value should be loaded, it could be the register containing the value, and so on. Arm s\", \"upports a 'scaled' addressing mode, typically used for indexing into an array, where the size of eac\", \"h element is supplied and the instruction 'scales' the provided offset by the specified scale. dotne\", \"t/runtime#60808 enables the JIT to utilize this addressing mode. More generally, dotnet/runtime#7074\", \"9 enables the JIT to use addressing modes when accessing elements of\\n\\nmanaged arrays. dotnet/runtime\", \"#66902 improves the use of addressing modes when the element type is byte . dotnet/runtime#65468 imp\", \"roves addressing modes used for floating point. And dotnet/runtime#67490 implements addressing modes\", \" for SIMD vectors, specifically for loads with unscaled indices.\\n\\n- Better instruction selection . V\", \"arious techniques go into ensuring that the best instructions are selected to represent input code. \", \"dotnet/runtime#61037 teaches the JIT how to recognize the pattern (a * b) + c with integers and fold\", \" that into a single madd or msub instruction, while dotnet/runtime#66621 does the same for a - (b * \", \"c) and msub . dotnet/runtime#61045 enables the JIT to recognize certain constant bit shift operation\", \"s (either explicit in the code or implicit to various forms of managed array access) and emit sbfiz \", \"/ ubfiz instructions. dotnet/runtime#70599, dotnet/runtime#66407, and dotnet/runtime#65535 all handl\", \"e various forms of optimizing a % b . dotnet/runtime#61847 from [@SeanWoo](https://github.com/SeanWo\", \"o) removes an unnecessary movi emitted as part of setting a dereferenced pointer to a constant value\", \". dotnet/runtime#57926 from [@SingleAccretion](https://github.com/SingleAccretion) enables computing\", \" a 64-bit result as the multiplication of two 32-bit integers to be done with smull / umull . And do\", \"tnet/runtime#61549 folds adds with sign extension or zero extension into a single add instruction wi\", \"th uxtw / sxtw / lsl , while dotnet/runtime#62630 drops redundant zero extensions after a ldr instru\", \"ction.\\n- Vectorization . dotnet/runtime#64864 adds new AdvSimd.LoadPairVector64 / AdvSimd.LoadPairVe\", \"ctor128 hardware intrinsics.\\n- Zeroing . Lots of operations require state to be set to zero, such as\", \" initializing all reference locals in a method to zero as part of the method's prologue (so that the\", \" GC doesn't see and try to follow garbage references). While such functionality was previously vecto\", \"rized, dotnet/runtime#63422 enables this to be implemented using 128-bit width vector instructions o\", \"n Arm. And dotnet/runtime#64481 changes the instruction sequences used for zeroing in order to avoid\", \" unnecessary zeroing, free up additional registers, and enable the CPU to recognize various instruct\", \"ion sequences and better optimize.\\n- Memory Model . dotnet/runtime#62895 enables store barriers to b\", \"e used wherever possible instead of full barriers, and uses one-way barriers for volatile variables.\", \" dotnet/runtime#67384 enables volatile reads/writes to be implemented with the ldapr instruction, wh\", \"ile dotnet/runtime#64354 uses a cheaper instruction sequence to handle volatile indirections. There'\", \"s dotnet/runtime#70600, which enables LSE Atomics to be used for Interlocked operations; dotnet/runt\", \"ime#71512, which enables using the atomics instruction on Unix machines; and dotnet/runtime#70921, w\", \"hich enables the same but on Windows.\\n\\n## JIT helpers\\n\\nWhile logically part of the runtime, the JIT \", \"is actually isolated from the rest of the runtime, only interacting with it through an interface tha\", \"t enables communication between the JIT and the rest of the VM (Virtual Machine). There's a large am\", \"ount of VM f unctionality then that the JIT relies on for good performance.\\n\\ndotnet/runtime#65738 re\", \"wrote various 'stubs' to be more efficient. Stubs are tiny bits of code that serve to perform some c\", \"heck and then redirect execution somewhere else. For example, when an interface dispatch call site i\", \"s expected to only ever be used with a single implementation of that interface, the JIT might employ\", \" a 'dispatch stub' that compares the type of the object agains t the\\n\\nkunalspathak commented on Mar \", \"22 \\u2022 edited - windows x64 improvements: dotnet/perf-autofiling-issues#4226, dotnet/perf-autofiling-i\", \"ssues#4225\\n\\nsingle one it's cached, and if they're equal simply jumps to the right target. You know \", \"you're in the corest of the core areas of the runtime when a PR contains lots of assembly code for e\", \"very architecture the runtime targets. And it paid off; there' s a virtual group of folks from aroun\", \"d .NET that review performance improvements and regressions in our automated performance test suites\", \", and attribute these back to the PRs likely to be the cause (this is mostly automated but requires \", \"some human oversigh t). It's always nice then when a few days after a PR is merged and performance i\", \"nformation has stabilized that you see a rash of comments like there were on this PR:\\n\\nWindows Arm64\", \" Improvements dotnet/perf-autofiling-issues#4251 dotnet/perf-autofiling-issues#4252\\n\\nDrewScoggins co\", \"mmented on Mar 24 \\u2022 edited -\\n\\n<!-- image -->\\n\\nFor anyone familiar with generics and interested in pe\", \"rformance, you may have heard the refrain that generic virtual methods are relatively expensive. The\", \"y are, comparatively. For example on .NET 6, this code:\\n\\n```\\nprivate Example _example = new Example(\", \"); [Benchmark(Baseline = true )] public void GenericNonVirtual() => _example.GenericNonVirtual<Examp\", \"le>(); [Benchmark] public void GenericVirtual() => _example.GenericVirtual<Example>(); class Example\", \" { [MethodImpl(MethodImplOptions.NoInlining)] public void GenericNonVirtual<T>() { } [MethodImpl(Met\", \"hodImplOptions.NoInlining)] public virtual void GenericVirtual<T>() { } }\\n```\\n\\nresults in:\\n\\nMember\\n\\n\", \"| Method            | Mean      |   Ratio |\\n|-------------------|-----------|---------|\\n| GenericNon\", \"Virtual | 0.4866 ns |    1    |\\n| GenericVirtual    | 6.4552 ns |   13.28 |\\n\\ndotnet/runtime#65926 ea\", \"ses the pain a tad. Some of the cost comes from looking up some cached information in a hash table i\", \"n the runtime, and as is the case with many map implementations, this one involves computing a hash \", \"code and using a mod operation to map to the right bucket. Other hash table implementations around d\", \"otnet/runtime, including Dictionary&lt;,&gt; , HashSet&lt;,&gt; , and ConcurrentDictionary&lt;,&gt; \", \"previously switched to a 'fastmod' implementation; this PR does the same for this EEHashtable , whic\", \"h is used as part of the CORINFO\\\\_GENERIC\\\\_HANDLE JIT helper function employed:\\n\\n| Method         | \", \"Runtime   | Mean     |   Ratio |\\n|----------------|-----------|----------|---------|\\n| GenericVirtua\", \"l | .NET 6.0  | 6.475 ns |    1    |\\n| GenericVirtual | .NET 7.0  | 6.119 ns |    0.95 |\\n\\nNot enough\", \" of an improvement for us to start recommending people use them, but a 5% improvement takes a bit of\", \" the edge off the sting.\\n\\n## Grab Bag\\n\\nIt's near impossible to cover every performance change that g\", \"oes into the JIT, and I'm not going to try. But there were so many more PRs, I couldn't just leave t\", \"hem all unsung, so here's a few mor e quickies:\\n\\n- dotnet/runtime#58196 from [@benjamin-hodgson](htt\", \"ps://github.com/benjamin-hodgson). Given an expression like (byte)x | (byte)y , that can be morphed \", \"into (byte)(x | y) , which can optimize away some mov s.\\n\\n```\\nprivate int _x, _y; [Benchmark] public\", \" int Test() => (byte)_x | (byte)_y;\\n```\\n\\n```\\n; *** .NET 6 *** ; Program.Test(Int32, Int32) movzx    \", \" eax,dl movzx     edx,r8b or        eax,edx ret ; Total bytes of code 10 ; *** .NET 7 *** ; Program.\", \"Test(Int32, Int32) or        edx,r8d movzx     eax,dl ret ; Total bytes of code 7\\n```\\n\\n- dotnet/runt\", \"ime#67182. On a machine with support for BMI2, 64-bit shifts can be performed with the shlx , sarx ,\", \" and shrx instructions.\\n- dotnet/runtime#69003 from [@SkiFoD](https://github.com/SkiFoD). The patter\", \"n ~x + 1 can be changed into a two's -complement negation.\\n- dotnet/runtime#61412 from [@SkiFoD](htt\", \"ps://github.com/SkiFoD). An expression X &amp; 1 == 1 to test whether the bottom bit of a number is \", \"set can changed to the cheaper X &amp; 1 (which isn't actually expressible without a following != 0 \", \"in C#).\\n\\n```\\n[Benchmark] [Arguments(123, 1)] public ulong Shift(ulong x, int y) => x << y;\\n```\\n\\n```\\n\", \"; *** .NET 6 *** ; Program.Shift(UInt64, Int32) mov       ecx,r8d mov       rax,rdx shl       rax,cl\", \" ret ; Total bytes of code 10 ; *** .NET 7 *** ; Program.Shift(UInt64, Int32) shlx      rax,rdx,r8 r\", \"et ; Total bytes of code 6\\n```\\n\\n```\\n[Benchmark] [Arguments(42)] public int Neg(int i) => ~i + 1;\\n```\", \"\\n\\n```\\n; *** .NET 6 *** ; Program.Neg(Int32) mov       eax,edx not       eax inc       eax ret ; Tota\", \"l bytes of code 7 ; *** .NET 7 *** ; Program.Neg(Int32) mov       eax,edx neg       eax ret ; Total \", \"bytes of code 5\\n```\\n\\n```\\n[Benchmark] [Arguments(42)] public bool BitSet(int x) => (x & 1) == 1;\\n```\\n\", \"\\n```\\n; *** .NET 6 *** ; Program.BitSet(Int32) test      dl,1 setne     al\\n```\\n\\n```\\nmovzx     eax,al \", \"ret ; Total bytes of code 10 ; *** .NET 7 *** ; Program.BitSet(Int32) mov       eax,edx and       ea\", \"x,1 ret ; Total bytes of code 6\\n```\\n\\n- dotnet/runtime#63545 from [@Wraith2](https://github.com/Wrait\", \"h2). The expression x &amp; (x 1) can be lowered to the blsr instruction.\\n- dotnet/runtime#62394. / \", \"and % by a vector's .Count wasn't reco gnizing that Count can be unsigned, but doing so leads to bet\", \"ter code gen.\\n\\n```\\n[Benchmark] [Arguments(42)] public int ResetLowestSetBit(int x) => x & (x - 1);\\n`\", \"``\\n\\n```\\n; *** .NET 6 *** ; Program.ResetLowestSetBit(Int32) lea       eax,[rdx+0FFFF] and       eax,\", \"edx ret ; Total bytes of code 6 ; *** .NET 7 *** ; Program.ResetLowestSetBit(Int32) blsr      eax,ed\", \"x ret ; Total bytes of code 6\\n```\\n\\n```\\n[Benchmark] [Arguments(42u)] public long DivideByVectorCount(\", \"uint i) => i / Vector<byte>.Count;\\n```\\n\\n```\\n; *** .NET 6 *** ; Program.DivideByVectorCount(UInt32) m\", \"ov       eax,edx mov       rdx,rax sar       rdx,3F and       rdx,1F add       rax,rdx sar       rax\", \",5 ret ; Total bytes of code 21 ; *** .NET 7 *** ; Program.DivideByVectorCount(UInt32) mov       eax\", \",edx shr       rax,5 ret ; Total bytes of code 7\\n```\\n\\n- dotnet/runtime#60787. Loop alignment in .NET\", \" 6 provides a very nice exploration of why and how the JIT handles loop alignment. This PR extends t\", \"hat further by trying to 'hide' an emitted align instruction behind an unconditional jmp that might \", \"already exist, in order to minimize the impact of the processor having to fetch and decode nop s.\\n\\n<\", \"!-- image -->\\n\\n'Regions' is a feature of the garbage collector (GC) that's been in the works for mul\", \"tiple years. It's enabled by default in 64-bit processes in .NET 7 as of dotnet/runtime#64688, but a\", \"s with other multiyear features, a multitude of PRs went into making it a reality. At a 30,000 foot \", \"level, 'regions' replaces the current 'segments' approach to managing memory on the GC heap; rather \", \"than having a few gigantic segments of memory (e.g. each 1GB), often associated 1:1 with a generatio\", \"n, the GC instead maintains many, many smaller regions (e.g. each 4MB) as their own entity. This ena\", \"bles the GC to be more agile with regards to operations like repurposing regions of memory from one \", \"generation to another. For more information on regions, the blog post Put a DPAD on that GC! from th\", \"e primary developer on the GC is still the best resource.\\n\\n## Native AOT\\n\\nTo many people, the word '\", \"performance' in the context of software is about throughput. How fast does something execute? How mu\", \"ch data per second can it process? How many requests per second can it process? And so on. But there\", \" are many other facets to performance. How much memory does it consume? How fast does it start up an\", \"d get to the point of doing something useful? How much space does it consume on disk? How long would\", \" it take to download? And then there are related concerns. In order to achieve these goals, what dep\", \"endencies are required? What kinds of operations does it need to perform to achieve these goals, and\", \" are all of those operations permitted in the target environment? If any of this paragraph resonates\", \" with you, you are the target audience for the Native AOT support now shipping in .NET 7.\\n\\n.NET has \", \"long had support for AOT code generation. For example, .NET Framework had it in the form of ngen , a\", \"nd .NET Core has it in the form of crossgen . Both of those solutions involve a standard .NET execut\", \"able that has some of its IL already compiled to assembly code, but not all methods will have assemb\", \"ly code generated for them, various things can invalidate the assembly code that was generated, exte\", \"rnal .NET assemblies without any native assembly code can be loaded, and so on, and in all of those \", \"cases, the runtime continues to utilize a JIT compiler. Native AOT is different. It's an evolution o\", \"f CoreRT, which itself was an evolution of .NET Native, and it's entirely free of a JIT. The binary \", \"that results from publishing a build is a completely standalone executable in the target platform's \", \"platform -specific file format (e.g. COFF on Windows, ELF on Linux, Mach-O on macOS) with no externa\", \"l dependencies other than ones standard to that platform (e.g. libc). And it's entirely native: no I\", \"L in sight, no JIT, no nothing. All required code is compiled and/or linked in to the executable, in\", \"cluding the same GC that's used with standard .NET apps and services, and a minimal runtime that pro\", \"vides services around threading and the like. All of that brings great benefits: super fast startup \", \"time, small and entirely-self contained deployment , and ability to run in places JIT compilers aren\", \"'t allowed (e.g. because memory pages that were writable can't then be executable). It also brings l\", \"imitations: no JIT means no dynamic loading of arbitrary assemblies (e.g. Assembly.LoadFile ) and no\", \" reflection emit (e.g. DynamicMethod ), everything compiled and linked in to the app means the more \", \"functionality that's used (or might be used) the larger is your deployment, etc. Even with those lim\", \"itations, for a certain class of application, Native AOT is an incredibly exciting and welcome addit\", \"ion to .NET 7.\\n\\nToo many PRs to mention have gone into bringing up the Native AOT stack, in part bec\", \"ause it's been in the works for years (as part of the archived dotnet/corert project and then as par\", \"t of dotnet/runtimelab/feature/NativeAOT) and in part because there have been over a hundred PRs jus\", \"t in dotnet/runtime that have gone into bringing Native AOT up to a shippable state since the code w\", \"as originally brought over from dotnet/runtimelab in dotnet/runtime#62563 and dotnet/runtime#62563. \", \"Between that and there not being a previous version to compare its performance to, instead of focusi\", \"ng PR by PR on improvements, let's just look at how to use it and the benefits it brings.\\n\\nToday, Na\", \"tive AOT is focused on console applications, so let's create a console app:\\n\\n```\\ndotnet new console \", \"-o nativeaotexample\\n```\\n\\nWe now have our nativeaotexample directory containing a nativeaotexample.cs\", \"proj and a 'hello, world' Program.cs . To enable publishing the application with Native AOT, edit th\", \"e .csproj to include this in the existing &lt;PropertyGroup&gt;...&lt;/PropertyGroup&gt; .\\n\\n```\\n<Pub\", \"lishAot>true</PublishAot>\\n```\\n\\nA nd then\\u2026 actually, that's it. Our app is now fully configured to be\", \" able to target Native AOT. All that's left is to publish. As I'm currently writing this on my Windo\", \"ws x64 machine, I'll target that:\\n\\n```\\ndotnet publish -r win-x64 -c Release\\n```\\n\\nI now have my gener\", \"ated executable in the output publish directory:\\n\\n```\\nDirectory: C:\\\\nativeaotexample\\\\bin\\\\Release\\\\net\", \"7.0\\\\win-x64\\\\publish Mode                 LastWriteTime         Length Name -a---           8/27/2022\", \"  6:19 PM        2061824 nativeaotexample.exe -a---           8/27/2022  6:19 PM       14290944 nati\", \"veaotexample.pdb\\n```\\n\\nso 2M instead of 3.5MB. Of course, for that significant reduction I've given u\", \"p some things:\\n\\n- Setting InvariantGlobalization to true means I'm now not respecting c ulture infor\", \"mation and am instead using a set of invariant data for most globalization operations.\\n- Setting Use\", \"SystemResourceKeys to true means nice exception messages are stripped away.\\n- Setting IlcGenerateSta\", \"ckTraceData to false means I'm going to get fair ly poor stack traces should I need to debug an exce\", \"ption.\\n- Setting DebuggerSupport to false\\u2026 good luck debugging things.\\n- \\u2026 you get the idea.\\n\\nOne of\", \" the potentially mind-boggling aspects of Native AOT for a developer used to .NET is that, as it say\", \"s on the tin, it really is native. After publishing the app, there is no IL involved, and there's no\", \" JIT that could even process it. This makes some of the other investments in .NET 7 all the more val\", \"uable, for example everywhere investments are happening in source generators. Code that previously r\", \"elied on reflection emit for good performance will need another scheme. We can see that, for example\", \", with Regex . Historically for optimal throughput with Regex , it's been recommended to use RegexOp\", \"tions.Compiled , which uses reflection emit at run-time to generate an optimized implementation of t\", \"he specified pattern. But if you look at the implementation of the Regex constructor, you'll find th\", \"is nugget:\\n\\n```\\nif (RuntimeFeature.IsDynamicCodeCompiled) { factory = Compile(pattern, tree, options\", \", matchTimeout != InfiniteMatchTimeout); }\\n```\\n\\nWith the JIT, IsDynamicCodeCompiled is true. But wit\", \"h Native AOT, it's false. Thus, with Native AOT and Regex , there's no difference between specifying\", \" RegexOptions.Compiled and not, and another mechanism is required to get the throughput benefits pro\", \"mised by RegexOptions.Compiled . Enter [GeneratedRegex(...)] , which, along with the new regex sourc\", \"e generator shipping in the .NET 7\\n\\nSDK, emits C# code into the assembly using it. That C# code take\", \"s the place of the reflection emit that would have happened at run-time, and is thus able to work su\", \"ccessfully with Native AOT.\\n\\n```\\nprivate static readonly string s_haystack = new HttpClient().GetStr\", \"ingAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; private Regex _interpreter = new\", \" Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline); private Regex _compiled = new Regex(@\\\"^.*elemen\", \"tary.*$\\\", RegexOptions.Compiled | RegexOptions.Multiline); [GeneratedRegex(@\\\"^.*elementary.*$\\\", Rege\", \"xOptions.Multiline)] private partial Regex SG(); [Benchmark(Baseline = true )] public int Interprete\", \"r() => _interpreter.Count(s_haystack); [Benchmark] public int Compiled() => _compiled.Count(s_haysta\", \"ck); [Benchmark] public int SourceGenerator() => SG().Count(s_haystack);\\n```\\n\\n| Method          | Me\", \"an       |   Ratio |\\n|-----------------|------------|---------|\\n| Interpreter     | 9,036.7 us |    \", \"1    |\\n| Compiled        | 9,064.8 us |    1    |\\n| SourceGenerator | 426.1 us   |    0.05 |\\n\\nSo, ye\", \"s, there are some constraints associated with Native AOT, but there are also solutions for working w\", \"ith those constraints. And further, those constraints can actually bring further benefits. Consider \", \"dotnet/runtime#64497 . Remember how we talked about 'guarded devirtualization' in dynamic PGO, where\", \" via instrumentation the JIT can determine the most likely type to be used at a given call site and \", \"special-case it? With Native AOT, the entirety of the program is known at compile time, with no supp\", \"ort for Assembly.LoadFrom or the like. That means at compile time, the compiler can do whole-program\", \" analysis to determine what types implement what interfaces. If a given interface only has a single \", \"type that implements it, then every call site through that interface can be unconditionally devirtua\", \"lized, without any type-check guards.\\n\\nThis is a really exciting space, one we expect to see flouris\", \"h in coming releases.\\n\\n## Mono\\n\\nUp until now I've referred to 'the JIT,' 'the GC,' and 'the runtime,\", \"' but in reality there are actually multiple runtimes in .NET. I've been talking about 'coreclr,' wh\", \"ich is the runtime that's recommended for use on Linux, macOS, and Windows. However, there's also 'm\", \"ono,' which powers Blazor wasm applications, Android apps, and iOS apps. It's also seen sign ificant\", \" improvements in .NET 7.\\n\\nJust as with coreclr (which can JIT compile, AOT compile partially with JI\", \"T fallback, and fully Native AOT compile), mono has multiple ways of actually executing code. One of\", \" those ways is an interpreter, which enables mono to execute .NET code in environments that don't pe\", \"rmit JIT'ing and without requiring ahead-of-time compilation or incurring any limitations it may bri\", \"ng. Interestingly, though, the interpreter is itself almost a full-fledged compiler, parsing the IL,\", \" generating its own intermediate representation (IR) for it, and doing one or more optimization pass\", \"es over that IR; it's just that at the end of the pipeline when a compiler would normally emit code,\", \" the interpreter instead saves off that data for it to interpret when the time comes to run. As such\", \", the interpreter has a very similar conundrum to the one we discussed with coreclr's JIT: the time \", \"it takes to optimize vs the desire to start up quickly. And in .NET 7, the interpreter employs a sim\", \"ilar solution: tiered compilation. dotnet/runtime#68823 adds the ability for the interpreter to init\", \"ially compile with minimal optimization of that IR, and then once a certain threshold of call counts\", \" has been hit, then take the time to do as much optimization on the IR as possible for all future in\", \"vocations of that method. This yields the same benefits as it does for coreclr: improved startup tim\", \"e while also having efficient sustained throughput. When this merged, we saw improvements in Blazor \", \"wasm app startup time improve by 1020%. Here's one example from an app being tracked in our benchmar\", \"king system:\\n\\nTime to first Ul (ms)\\n\\n300\\n\\n280\\n\\n260\\n\\n240\\n\\n<!-- image -->\\n\\nThe interpreter isn't just \", \"used for entire apps, though. Just as how coreclr can use the JIT when an R2R i mage doesn't contain\", \" code for a method, mono can use the interpreter when there's no AOT code for a method. Once such ca\", \"se that occurred on mono was with generic delegate invocation, where the presence of a generic deleg\", \"ate being invoked would trigger falling back to the interpreter; for .NET 7, that gap was addressed \", \"with dotnet/runtime#70653. A more impactful case, however, is dotnet/runtime#64867. Previously, any \", \"methods with catch or filter exception handling clauses couldn't be AOT compiled and would fall back\", \" to being interpreted. With this PR, the method is now able to be AOT compiled, and it only falls ba\", \"ck to using the interpreter when an exception actually occurs, switching over to the interpreter for\", \" the remainder of that method call's execution. Since many methods contain such clauses, this can ma\", \"ke a big difference in throughput and CPU consumption. In the same vein, dotnet/runtime#63065 enable\", \"d methods with finally exception handling clauses to be AOT compiled; just the finally block gets in\", \"terpreted rather than the entire method being interpreted.\\n\\nBeyond such backend improvements, anothe\", \"r class of improvement came from further unification between coreclr and mono. Years ago, coreclr an\", \"d mono had their own entire library stack built on top of them. Over time, as .NET was open sourced,\", \" portions of mono's stack got replaced by shared components, bit by bit. Fast forward to today, all \", \"of the core .NET libraries above System.Private.CoreLib are the same regardless of which runtime is \", \"being employed. In fact, the source for CoreLib itself is almost entirely shared, with ~95% of the s\", \"ource files being compiled into the CoreLib that's built for each runtime, and just a few percent of\", \" the source specialized for each (these statements means that the vast majority of the performance i\", \"mprovements discussed in the rest of this post apply equally whether running on mono and coreclr). E\", \"ven so, every release now we try to chip away at that few remaining percent, for reasons of maintain\", \"ability, but also because the source used for coreclr's CoreLib has generally had more attention pai\", \"d to it from a performance perspective. dotnet/runtime#71325 , for example, moves mono's array and s\", \"pan sorting generic sorting utility class over to the more efficient implementation used by coreclr.\", \"\\n\\nOne of the biggest categories of improvements, however, is in vectorization. This comes in two pie\", \"ces. First, Vector&lt;T&gt; and Vector128&lt;T&gt; are now fully accelerated on both x64 and Arm64, \", \"thanks to PRs like dotnet/runtime#64961, dotnet/runtime#65086, dotnet/runtime#65128, dotnet/runtime#\", \"66317,\\n\\ndotnet/runtime#66391, dotnet/runtime#66409, dotnet/runtime#66512, dotnet/runtime#66586, dotn\", \"et/runtime#66589, dotnet/runtime#66597, dotnet/runtime#66476, and dotnet/runtime#67125; that signifi\", \"cant amount of work means all that code that gets vectorized using these abstractions will light-up \", \"on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70086, mono now knows how to t\", \"ranslate Vector128&lt;T&gt; operations to WASM's SIMD instruction set, such that code vectorized wit\", \"h Vector128&lt;T&gt; will also be accelerated when running in Blazor wasm applications and anywhere \", \"else WASM might be executed.\\n\\n## Reflection\\n\\nReflection is one of those areas you either love or hat\", \"e (I find it a bit humorous to be writing this section immediately after writing the Native AOT sect\", \"ion). It's immensely powerful, providing the ability to query all of the metadata for code in your p\", \"rocess and for arbitrary assemblies you might encounter, to invoke arbitrary functionality dynamical\", \"ly, and even to emit dynamically-generated IL at runtime. It's also difficult to handle well in the \", \"face of tooling like a linker or a solution like Native AOT that needs to be able to determine at bu\", \"ild time exactly what code will be executed, and it's generally quite expensive at runtime; thus it'\", \"s both something we strive to avoid when possible but also invest in reducing the costs of, as it's \", \"so popular in so many different kinds of applications because it is incredibly useful. As with most \", \"releases, it's seen some nice improvements in .NET 7.\\n\\nOne of the most impacted areas is reflection \", \"invoke. Available via MethodBase.Invoke , this functionality let's yo u take a MethodBase (e.g. Meth\", \"odInfo ) object that represents some method for which the caller previously queried, and call it, wi\", \"th arbitrary arguments that the runtime needs to marshal through to the callee, and with an arbitrar\", \"y return value that needs to be marshaled back. If you know the signature of the method ahead of tim\", \"e, the best way to optimize invocation speed is to create a delegate from the MethodBase via CreateD\", \"elegate&lt;T&gt; and then use that delegate for all future invocations. But in some circu mstances, \", \"you don't know the signature at compile time, and thus can't easily rely on delegates with known mat\", \"ching signatures. To address this, some libraries have taken to using reflection emit to generate co\", \"de at run-time specific to the target method. This is extremely complicated and it's not something w\", \"e want apps to have to do. Instead, in .NET 7 via dotnet/runtime#66357, dotnet/runtime#69575, and do\", \"tnet/runtime#74614, Invoke will itself use reflection emit (in the form of DynamicMethod ) to genera\", \"te a delegate that is customized for invoking the target, and then future invocation via that Method\", \"Info will utilize that generated method. This gives developers most of the performance benefits of a\", \" custom reflection emit-based implementation but without having the complexity or challenges of such\", \" an implementation in their own code base.\\n\\n```\\nprivate MethodInfo _method; [GlobalSetup] public voi\", \"d Setup() => _method = typeof (Program).GetMethod(\\\"MyMethod\\\", BindingFlags.NonPublic | BindingFlags.\", \"Static); [Benchmark] public void MethodInfoInvoke() => _method.Invoke( null , null ); private static\", \" void MyMethod() { }\\n```\\n\\n<!-- image -->\\n\\n| Method           | Runtime   | Mean      |   Ratio |\\n|--\", \"----------------|-----------|-----------|---------|\\n| MethodInfoInvoke | .NET 6.0  | 43.846 ns |    \", \"1    |\\n| MethodInfoInvoke | .NET 7.0  | 8.078 ns  |    0.18 |\\n\\nReflection also involves lots of mani\", \"pulation of objects that represent types, methods, properties, and so on, and tweaks here and there \", \"can add up to a measurable difference when using these APIs. For example, I've talked in past perfor\", \"mance posts about how, potentially counterin tuitively, one of the ways we've achieved performance b\", \"oosts is by porting native code from the runtime back into managed C#. There are a variety of ways i\", \"n which doing so can help performance, but one is that there is some overhead associated with callin\", \"g from managed code into the runtime, and eliminating such hops avoids that overhead. This can be se\", \"en in full effect in dotnet/runtime#71873, which moves several of th ese 'FCalls' related to Type , \", \"RuntimeType (the Type -derived class used by the runtime to represent its types), and Enum out of na\", \"tive into managed.\\n\\n```\\n[Benchmark] public Type GetUnderlyingType() => Enum.GetUnderlyingType( typeo\", \"f (DayOfWeek));\\n```\\n\\n| Method            | Runtime   | Mean      |   Ratio |\\n|-------------------|--\", \"---------|-----------|---------|\\n| GetUnderlyingType | .NET 6.0  | 27.413 ns |    1    |\\n| GetUnderl\", \"yingType | .NET 7.0  | 5.115 ns  |    0.19 |\\n\\nAnother example of this phenomenon comes in dotnet/run\", \"time#62866, which moved much of the underlying support for AssemblyName out of native runtime code i\", \"nto managed code in CoreLib. That in turn has an impact on anything that uses it, such as when using\", \" Activator.CreateInstance overloads that take assembly names that need to be parsed.\\n\\n```\\nprivate re\", \"adonly string _assemblyName = typeof (MyClass).Assembly.FullName; private readonly string _typeName \", \"= typeof (MyClass).FullName; public class MyClass { } [Benchmark] public object CreateInstance() => \", \"Activator.CreateInstance(_assemblyName, _typeName);\\n```\\n\\n| Method         | Runtime   | Mean     |  \", \" Ratio |\\n|----------------|-----------|----------|---------|\\n| CreateInstance | .NET 6.0  | 3.827 us\", \" |     1   |\\n| CreateInstance | .NET 7.0  | 2.276 us |     0.6 |\\n\\nOther changes contributed to Activ\", \"ator.CreateInstance improvements as well. dotnet/runtime#67148 removed several array and list alloca\", \"tions from inside of the RuntimeType.CreateInstanceImpl me thod that's used by CreateInstance (using\", \" instead of allocating a new Type[0] , avoiding unnecessarily turning a builder into an array, etc.)\", \", resulting in less allocation and faster throughput.\\n\\nType.EmptyTypes\\n\\n```\\n[Benchmark] public void \", \"CreateInstance() => Activator.CreateInstance( typeof (MyClass), BindingFlags.NonPublic | BindingFlag\", \"s.Instance, null , Array.Empty<object>(), null ); internal class MyClass {\\n```\\n\\n```\\ninternal MyClass\", \"() { } }\\n```\\n\\n| Method         | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|---\", \"-------------|-----------|----------|---------|-------------|---------------|\\n| CreateInstance | .NE\", \"T 6.0  | 167.8 ns |    1    | 320 B       |          1    |\\n| CreateInstance | .NET 7.0  | 143.4 ns \", \"|    0.85 | 200 B       |          0.62 |\\n\\nAnd since we were talking about AssemblyName , other PRs \", \"improved it in other ways as well. dotnet/runtime#66750, for example, updated the computation of Ass\", \"emblyName.FullName to use stack-allocated memory and ArrayPool&lt;char&gt; instead of using a String\", \"Builder :\\n\\n```\\nprivate AssemblyName[] _names = AppDomain.CurrentDomain.GetAssemblies().Select(a => n\", \"ew AssemblyName(a.FullName)).ToArray(); [Benchmark] public int Names() { int sum = 0; foreach (Assem\", \"blyName name in _names) { sum += name.FullName.Length; } return sum; }\\n```\\n\\n| Method   | Runtime   |\", \" Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|----------|-----------|----------|---------|---\", \"----------|---------------|\\n| Names    | .NET 6.0  | 3.423 us |    1    | 9.14 KB     |          1  \", \"  |\\n| Names    | .NET 7.0  | 2.010 us |    0.59 | 2.43 KB     |          0.27 |\\n\\nMore reflection-rel\", \"ated operations have also been turned into JIT intrinsics, as discussed earlier enabling the JIT to \", \"compute answers to various questions at JIT compile time rather than at run-time. This was done, for\", \" example, for Type.IsByRefLike in dotnet/runtime#67852.\\n\\n```\\n[Benchmark] public bool IsByRefLike() =\", \"> typeof (ReadOnlySpan<char>).IsByRefLike;\\n```\\n\\n| Method      | Runtime   | Mean      |   Ratio | Co\", \"de Size   |\\n|-------------|-----------|-----------|---------|-------------|\\n| IsByRefLike | .NET 6.0\", \"  | 2.1322 ns |       1 | 31 B        |\\n| IsByRefLike | .NET 7.0  | 0.0000 ns |       0 | 6 B       \", \"  |\\n\\nThat the .NET 7 version is so close to zero is called out in a warning by benchmarkdotnet:\\n\\n```\", \"\\n// * Warnings * ZeroMeasurement Program.IsByRefLike: Runtime=.NET 7.0, Toolchain=net7.0 -> The meth\", \"od duration is indistinguishable from the empty method duration\\n```\\n\\nand it's so indistinguishable f\", \"rom an empty method because that's effectively what it is, as we can see from the disassembly:\\n\\n```\\n\", \"; Program.IsByRefLike() mov       eax,1 ret ; Total bytes of code 6\\n```\\n\\nThere are also improvements\", \" that are hard to see but that remove overheads as part of populating reflection's caches, which end\", \" up reducing the work done typically on star tup paths, helping apps to launch faster. dotnet/runtim\", \"e#66825, dotnet/runtime#66912, and dotnet/runtime#67149 all fall into this category by removing unne\", \"cessary or duplicative array allocations as part of gathering data on parameters, properties, and ev\", \"ents.\\n\\n## Interop\\n\\n.NET has long had great support for interop, enabling .NET applications to consum\", \"e huge amounts of functionality written in other languages and/or exposed by the underlying operatin\", \"g system. The bedrock of this support has been 'Platform Invoke,' or 'P/Invoke,' represented in code\", \" by [DllImport(...)] applied to methods. The DllImportAttribute enables declaring a method that can \", \"be called like any other .NET method but that actually represents some external method that the runt\", \"ime should call when this managed method is invoked. The DllImport specifies details about in what l\", \"ibrary the function lives, what its actual name is in the exports from that library, high-level deta\", \"ils about marshalling of input arguments and return values, and so on, and the runtime ensures all t\", \"he right things happen. This mechanism works on all operating systems. For example, Windows has a me\", \"thod CreatePipe for creating an anonymous pipe:\\n\\n```\\nBOOL CreatePipe( [out]          PHANDLE        \", \"       hReadPipe, [out]          PHANDLE               hWritePipe, [in, optional] LPSECURITY_ATTRIBU\", \"TES lpPipeAttributes, [in]           DWORD                 nSize );\\n```\\n\\nIf I want to call this func\", \"tion from C#, I can declare a [DllImport(...)] counterpart to it which I can then invoke as I can an\", \"y other managed method:\\n\\n```\\n[DllImport(\\\"kernel32\\\", SetLastError = true )] [ return : MarshalAs(Unma\", \"nagedType.Bool)] private static unsafe extern bool CreatePipe( out SafeFileHandle hReadPipe, out Saf\", \"eFileHandle hWritePipe, void* lpPipeAttributes, uint nSize);\\n```\\n\\nThere are several interesting thin\", \"gs to note here. Several of the arguments are directly blittable with the same representation on the\", \" managed and native side of the equation, e.g. lpPipeAttributes is a pointer and nSize is a 32-bit i\", \"nteger. But what about the return value? The bool type in C# ( System.Boolean ) is a one-byte type, \", \"but the BOOL type in the native signature is four bytes; thus code calling this managed method can't\", \" just directly invoke the native function somehow, as there needs to be some 'marshalling' logic tha\", \"t converts the four -byte return BOOL into the one-byte return bool . Simiarly, the native function \", \"has two out pointers for hReadPipe and hWritePipe , but the managed signature declares two SafeFileH\", \"andle s (a SafeHandle is a .NET type that wraps a pointer and provides a finalizer and Dispose metho\", \"d for ensuring that pointer is appropriately cleaned up when it's no l onger being used). Some logic\", \" needs to take the output handles generated by the native function and wrap them into these SafeFile\", \"Handles to be output from the managed method. And what about that SetLastError = true ? .NET has met\", \"hods like Marshal.GetLastPInvokeError() ,\\n\\nand some code somewhere needs to take any error produced \", \"by this method and ensure it's available for consumption via a subsequent GetLastPInvokeError() .\\n\\nI\", \"f there's no marshalling logic required, such that the managed signature and native sign ature are f\", \"or all intents and purposes the same, all arguments blittable, all return values blittable, no addit\", \"ional logic required around the invocation of the method, etc., then a [DllImport(...)] ends up bein\", \"g a simple passthrough with the runtime needing to do very little work to implement it. If, however,\", \" the [DllImport(...)] involves any of this marshalling work, the runtime needs to generate a 'stub,'\", \" creating a dedicated method that's called when the [DllImport(...)] is called, that handles fixing \", \"up all inputs, that delegates to the actual native function, and that fixes up all of the outputs. T\", \"hat stub is generated at execution time, with the runtime effectively doing reflection emit, generat\", \"ing IL dynamically that's then JIT'd.\\n\\nThere are a variety of downsides to this. First, it takes tim\", \"e to generate all that marshalling code, time which can then negatively impact user experience for t\", \"hings like startup. Second, the nature of its implementation inhibits various optimizations, such as\", \" inlining. Thi rd, there are platforms that don't allow for JIT'ing due to the security exposure of \", \"allowing for dynamically generated code to then be executed (or in the case of Native AOT, where the\", \"re isn't a JIT at all). And fourth, it's all hidden away making it more challenging for a developer \", \"to really understand what's going on.\\n\\nBut what if that logic could all be generated at build time r\", \"ather than at run time? The cost of generating the code would be incurred only at build time and not\", \" on every execution. The code would effectively just end up being user code that has all of the C# c\", \"ompiler's and runtime's optimizations available to it. The code, which then would just be part of th\", \"e app, would be able to be ahead-of-time compiled using whatever AOT system is desirable, whether it\", \" be crossgen or Native AOT or some other system. And the code would be inspectable, viewable by user\", \"s to understand exactly what work is being done on their behalf. Sounds pretty desirable. Sounds mag\", \"ical. Sounds like a job for a Roslyn source generator, mentioned earlier.\\n\\n.NET 6 included several s\", \"ource generators in the .NET SDK, and .NET 7 doubles down on this effort including several more. One\", \" of these is the brand new LibraryImport generator, which provides exactly the magical, desirable so\", \"lution we were just discussing.\\n\\nLet's return to our previous CreatePipe example. We'll make two sma\", \"ll tweaks. We change the attribute from DllImport to LibraryImport , and we change the extern keywor\", \"d to be partial :\\n\\n```\\n[LibraryImport(\\\"kernel32\\\", SetLastError = true )] [ return : MarshalAs(Unmana\", \"gedType.Bool)] private static unsafe partial bool CreatePipe( out SafeFileHandle hReadPipe, out Safe\", \"FileHandle hWritePipe, void* lpPipeAttributes, uint nSize);\\n```\\n\\nNow if you're following along a t h\", \"ome in Visual Studio, try right-clicking on CreatePipe and selecting Go to Definition. That might se\", \"em a little strange. 'Go to Definition? Isn't this the definition?' This is a partial method, which \", \"is a way of declaring something that another partial definition fills in, and in this case, a source\", \" generator in .NET 7 SDK has noticed this method with the [LibraryImport] attribute and fully genera\", \"ted the entire marshalling stub code in C# that's built directly into the assembly. While by default\", \" that cod e isn't persisted, Visual Studio still enables you to browse it (and you can\\n\\nopt-in to ha\", \"ving it persisted on disk by adding a &lt;EmitCompilerGeneratedFiles&gt;true&lt;/EmitCompilerGenerat\", \"edFiles&gt; property into your .csproj). Here's what it currently looks like fo r that method:\\n\\n```\\n\", \"[System.CodeDom.Compiler.GeneratedCodeAttribute(\\\"Microsoft.Interop.LibraryImportGenerator\\\", \\\"7.0.6.4\", \"2316\\\")] [System.Runtime.CompilerServices.SkipLocalsInitAttribute] private static unsafe partial bool\", \" CreatePipe( out global ::Microsoft.Win32.SafeHandles.SafeFileHandle hReadPipe, out global ::Microso\", \"ft.Win32.SafeHandles.SafeFileHandle hWritePipe, void* lpPipeAttributes, uint nSize) { int __lastErro\", \"r; bool __invokeSucceeded = default ; System.Runtime.CompilerServices.Unsafe.SkipInit( out hReadPipe\", \"); System.Runtime.CompilerServices.Unsafe.SkipInit( out hWritePipe); System.IntPtr __hReadPipe_nativ\", \"e = default ; System.IntPtr __hWritePipe_native = default ; bool __retVal; int __retVal_native = def\", \"ault ; // Setup - Perform required setup. global ::Microsoft.Win32.SafeHandles.SafeFileHandle hReadP\", \"ipe__newHandle = new global ::Microsoft.Win32.SafeHandles.SafeFileHandle(); global ::Microsoft.Win32\", \".SafeHandles.SafeFileHandle hWritePipe__newHandle = new global ::Microsoft.Win32.SafeHandles.SafeFil\", \"eHandle(); try { { System.Runtime.InteropServices.Marshal.SetLastSystemError(0); __retVal_native = _\", \"_PInvoke(&__hReadPipe_native, &__hWritePipe_native, lpPipeAttributes, nSize); __lastError = System.R\", \"untime.InteropServices.Marshal.GetLastSystemError(); } __invokeSucceeded = true ; // Unmarshal - Con\", \"vert native data to managed data. __retVal = __retVal_native != 0; } finally { if (__invokeSucceeded\", \") { // GuaranteedUnmarshal - Convert native data to managed data even in the case of an exception du\", \"ring the non-cleanup phases. System.Runtime.InteropServices.Marshal.InitHandle(hWritePipe__newHandle\", \", __hWritePipe_native); hWritePipe = hWritePipe__newHandle; System.Runtime.InteropServices.Marshal.I\", \"nitHandle(hReadPipe__newHandle, __hReadPipe_native); hReadPipe = hReadPipe__newHandle; } } System.Ru\", \"ntime.InteropServices.Marshal.SetLastPInvokeError(__lastError); return __retVal; // Local P/Invoke [\", \"System.Runtime.InteropServices.DllImportAttribute(\\\"kernel32\\\", EntryPoint =\\n```\\n\\n```\\n\\\"CreatePipe\\\", Ex\", \"actSpelling = true )] static extern unsafe int __PInvoke(System.IntPtr* hReadPipe, System.IntPtr* hW\", \"ritePipe, void* lpPipeAttributes, uint nSize); }\\n```\\n\\nWith this, you can read exactly the marshallin\", \"g work that's being performed. Two SafeHandle instances are being allocated and then later after the\", \" native function completes, the Marshal.InitHandle method is used to store the resulting handles int\", \"o these instances (the allocations happen before the native function call, as performing them after \", \"the native handles have already been produced increases the chances of a leak if the SafeHandle allo\", \"cation fails due to an out-of-memory situation). The BOOL to bool conversion happens via a != 0 comp\", \"arison. And the error information is captured by calling Marshal.GetLastSystemError() just after the\", \" native function call and then Marshal.SetLastPInvokeError(int) just prior to returning. The actual \", \"native function call is still implemented with a [DllImport(...)] , but now that P/Invoke is blittab\", \"le and doesn't require any stub to be generated by the runtime, as all that work has been handled in\", \" this C# code.\\n\\nA sheer ton of work went in to enabling this. I touched on some of it last year in P\", \"erformance Improvements in .NET 6, but a significant amount of additional effort has gone into .NET \", \"7 to polish the design and make the implementation robust, roll it out across all of dotnet/runtime \", \"and beyond, and expose the functionality for all C# developers to use:\\n\\n- The LibraryImport generato\", \"r started its life as an experiment in dotnet/runtimelab. When it was ready, dotnet/runtime#59579 br\", \"ought 180 commits spanning years of effort into the dotnet/runtime main branch.\\n- In .NET 6, there w\", \"ere almost 3000 [DllImport] uses throughout the core .NET libraries. As of my writing this, in .NET \", \"7 there are\\u2026 let me search\\u2026 wait for it\\u2026 7 (I was hoping I could say 0, but there are just a few str\", \"agglers, mostly related to COM interop, still remaining). That's not a transformation that happens o\", \"ver night. A multitude of PRs went library by library converting from the old to the new, such as do\", \"tnet/runtime#62295 and dotnet/runtime#61640 for System.Private.CoreLib, dotnet/runtime#61742 and dot\", \"net/runtime#62309 for the cryptography libraries, dotnet/runtime#61765 for networking, dotnet/runtim\", \"e#61996 and dotnet/runtime#61638 for most of the other I/O-related libraries, and a long-tail of add\", \"itional porting in dotnet/runtime#61975, dotnet/runtime#61389, dotnet/runtime#62353, dotnet/runtime#\", \"61990, dotnet/runtime#61949, dotnet/runtime#61805, dotnet/runtime#61741, dotnet/runtime#61184, dotne\", \"t/runtime#54290, dotnet/runtime#62365, dotnet/runtime#61609, dotnet/runtime#61532, and dotnet/runtim\", \"e#54236.\\n- Such porting is significantly easier when there's a tool to help automate it. dotnet/runt\", \"ime#72819 enables the analyzer and fixer for performing these transformations. :::{custom-style=Figu\", \"re}\\n\\n18g-\\n\\n[return: MarshalAs(UnmanagedType.Bool)]\\n\\nO references private static unsafe extern bool C\", \"reatePipe(\\n\\n19\\n\\nConvert to 'Librarylmport'\\n\\n21 Convert to 'LibraryImport with 'A' suffix\\n\\n22 Order m\", \"odifiers\\n\\n23\\n\\n24\\n\\nMove static members to another type...\\n\\n29 Change signature...\\n\\nWrap every paramet\", \"er\\n\\nUnwrap parameter list\\n\\nExtract base class...\\n\\nSuppress or Configure issues\\n\\n<!-- image -->\\n\\n:::\\n\", \"\\nThere were plenty of other PRs that went into making the LibraryImport generator a reality for .NET\", \" 7. To highlight just a few more, dotnet/runtime#63320 introduces a new [DisabledRuntimeMarshalling]\", \" attribute that can be specified at the assembly level to disable all of the runtime's built -in mar\", \"shalling; at that point, the only marshalling performed as part of interop is the marshaling done in\", \" the user's code, e.g. that which is generated by [LibraryImport] . Other PRs like dotnet/runtime#67\", \"635 and dotnet/runtime#68173 added new marshaling types that encompass common marshaling logic and c\", \"an be referenced from [LibraryImport(...)] use to customize how marshaling is performed (the generat\", \"or is pattern-based and allows for customization of marshalling by providing types that implement th\", \"e right shape, which these types do in support of the most common marshalling needs). Really usefull\", \"y, dotnet/runtime#71989 added support for marshaling {ReadOnly}Span&lt;T&gt; , such that spans can b\", \"e used directly in [LibraryImport(...)] method signatures, just as arrays can be (examples in dotnet\", \"/runtime are available in dotnet/runtime#73256). And dotnet/runtime#69043 consolidated logic to be s\", \"hared between the runtime's marshalling support in [DllImport] and the generators support with [Libr\", \"aryImport] .\\n\\nOne more category of interop-related changes that I think are worth talking about are \", \"to do with SafeHandle cleanup. As a reminder, SafeHandle exists to mitigate various issues around ma\", \"naging native handles and file descriptors. A native handle or file descriptor is just a memory addr\", \"ess or number that refers to some owned resource and which must be cleaned up / closed when done wit\", \"h it. A SafeHandle at its core is just a managed object that wraps such a value and provides a Dispo\", \"se method and a finalizer for closing it. That way, if you neglect to Dispose of the SafeHandle in o\", \"rder to close the resource, the resource will still be cleaned up when the SafeHandle is garbage col\", \"lected and its finalizer eventually run. SafeHandle then also provides some synchronization around t\", \"hat closure, trying to minimize the possibility that the resource is closed while it's still in use.\", \" It provides DangerousAddRef and DangerousRelease methods that increment and decrement a ref count, \", \"respectively, and if Dispose is called while the ref count is above zero, the actual releasing of th\", \"e handle triggered by Dispose is delayed until the ref count goes back to 0. When you pass a SafeHan\", \"dle into a P/Invoke, the generated code for that P/Invoke handles calling DangerousAddRef\\n\\n\\u2022 \\u2022 Mark \", \"the method \\\"CreatePipe' with \\\"Library/mportAtribute' instead\\n\\nand DangerousRelease (and due to the w\", \"onders of LibraryImport I've already extolled, you can easily see that being done, such as in the pr\", \"evious generated code example). Our code tries hard to clean up after SafeHandle s deterministically\", \", but it's quite easy to accidentally l eave some for finalization.\\n\\ndotnet/runtime#71854 added some\", \" debug-only tracking code to SafeHandle to make it easier for developers working in dotnet/runtime (\", \"or more specifically, developers using a checked build of the runtime) to find such issues. When the\", \" SafeHandle is constructed, it captures the current stack trace, and if the SafeHandle is finalized,\", \" it dumps that stack trace to the console, making it easy to see where SafeHandles that do end up ge\", \"tting finalized were created, in order to track them down and ensure they're being disposed of. As i\", \"s probably evident from that PR touching over 150 files and almost 1000 lines of code, there were qu\", \"ite a few places that benefited from clean up. Now to be fair, many of these are on exceptional code\", \" paths. For example, consider a hypothetical P/Invoke like:\\n\\n```\\n[LibraryImport(\\\"SomeLibrary\\\", SetLa\", \"stError = true )] internal static partial SafeFileHandle CreateFile();\\n```\\n\\nand code that uses it li\", \"ke:\\n\\n```\\nSafeFileHandle handle = Interop.CreateFile(); if (handle.IsInvalid) { throw new UhOhExcepti\", \"on(Marshal.GetLastPInvokeError()); } return handle;\\n```\\n\\nSeems straightforward enough. Except this c\", \"ode will actually leave a SafeHandle for finalization on the failure path. It doesn't matter that Sa\", \"feHandle has an invalid handle in it, it's still a finalizable object. To deal with that, this code \", \"would have been more robustly written as:\\n\\n```\\nSafeFileHandle handle = Interop.CreateFile(); if (han\", \"dle.IsInvalid) { int lastError = Marshal.GetLastPInvokeError(); handle.Dispose(); // or handle.SetHa\", \"ndleAsInvalid() throw new UhOhException(lastError); } return handle;\\n```\\n\\nThat way, this SafeHandle \", \"won't create finalization pressure even in the case of failure. Note, as well, that as part of addin\", \"g in the Dispose call, I also moved the Marshal.GetLastPInvokeError() up. That's because calling Dis\", \"pose on a SafeHandle may end up invoking the SafeHandle 's ReleaseHandle method, which the developer\", \" of the SafeHandle -derived type will have overridden to close the resource, which typically involve\", \"s making another P/Invoke. And if that P/Invoke has SetLastError=true on it, it can overwrite the ve\", \"ry error code for which we're about to throw. Hence, we access and store the last error immediately \", \"after the interop call once we know it failed, then clean up, and only then throw. All that said, th\", \"ere were a myriad of places in that PR where SafeHandle s were being l eft for finalization even on \", \"the success path. And that PR wasn't alone.\\n\\ndotnet/runtime#71991, dotnet/runtime#71854, dotnet/runt\", \"ime#72116, dotnet/runtime#72189, dotnet/runtime#72222, dotnet/runtime#72203, and dotnet/runtime#7227\", \"9 all found and fixed many occurrences of SafeHandle s being left for finalization (many thanks to t\", \"he diagnostics put in place in the earlier mentioned PR).\\n\\nOther PRs also accrued to improved intero\", \"p performance. dotnet/runtime#70000 from [@huoyaoyuan](https://github.com/huoyaoyuan) rewrote severa\", \"l delegaterelated 'FCalls' from being implemented in native code to instead being managed, resulting\", \" in less overhead when invoking these operations that are commonly involved in scenarios involving\\n\\n\", \"Marshal.GetDelegateForFunctionPointer . dotnet/runtime#68694 also moved some trivial functionality f\", \"rom native to managed, as part of relaxing argument validation on the use of pinning handles. This i\", \"n turn measurably reduced the overhead involved with using GCHandle.Alloc for such pinning handles:\\n\", \"\\n```\\nprivate byte[] _buffer = new byte[1024]; [Benchmark] public void PinUnpin() { GCHandle.Alloc(_b\", \"uffer, GCHandleType.Pinned).Free(); }\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Code Size  \", \" |\\n|----------|-----------|----------|---------|-------------|\\n| PinUnpin | .NET 6.0  | 37.11 ns |  \", \"  1    | 353 B       |\\n| PinUnpin | .NET 7.0  | 32.17 ns |    0.87 | 232 B       |\\n\\n## Threading\\n\\nTh\", \"reading is one of those cross-cutting concerns that impacts every application, such that changes in \", \"the threading space can have a wide-spread impact. This release sees two very substantial changes to\", \" the ThreadPool itself; dotnet/runtime#64834 switches the 'IO pool' over to using an entirely manage\", \"d implementation (whereas previously the IO pool was still in native code even though the worker poo\", \"l had been moved entirely to managed in previous releases), and dotnet/runtime#71864 similarly switc\", \"hes the timer implementation from one based in native to one entirely in managed code. Those two cha\", \"nges can impact performance, and the former was demonstrated to on larger hardware, but for the most\", \" part that wasn't their primary goal. Instead, other PRs have been focused on improving throughput.\\n\", \"\\nOne in particular is dotnet/runtime#69386. The ThreadPool has a 'global queue' that any thread can \", \"queue work into, and then each thread in the pool has its own 'local queue' (which any thread can de\", \"queue from but only the owning thread can enqueue into). When a worker needs another piece of work t\", \"o process, it first checks its own local queue, then it checks the global queue, and then only if it\", \" couldn't find work in either of those two places, it goes and checks all of the other threads' loca\", \"l queues to see if it can help lighten their load. As machines scale up to have more and more cores,\", \" and more and more threads, there's more and more contention on these shared queues, and in particul\", \"ar on the global queue. This PR addresses this for such larger machines by introducing additional gl\", \"obal queues once the machine reaches a certain threshold (32 processors today). This helps to partit\", \"ion accesses across multiple queues, thereby decreasing contention.\\n\\nAnother is dotnet/runtime#57885\", \". In order to coordinate threads, when work items were enqueued and dequeued, the pool was issuing r\", \"equests to its threads to let them know that there was work available to do. This, however, often re\", \"sulted in oversubscription, where more threads than necessary would race to try to get work items, e\", \"specially when the system wasn't at full load. That in turn would manifest as a throughput regressio\", \"n. This change overhauls how threads are requested, such that only one additional thread is requeste\", \"d at a time, and after that thread has dequeued its first work item, it can issue a request for an a\", \"dditional thread if there's work remaining, and then that one can issue an additional request, and s\", \"o on. Here's one of our performance tests in our performance test suite (I've simplified it down to \", \"remove a bunch of configuration options from the test, but it's still accurately one of those config\", \"urations). At first glance you might think , 'hey, this is a performance test about ArrayPool , why \", \"is it showing up in a threading discussion?' And, you'd be right, this is a performance test that wa\", \"s written focused on ArrayPool . However, as mentioned earlier, threading impacts everything, and in\", \" this case, that await Task.Yield() in the middle there causes the remainder of this method to be qu\", \"eued to the ThreadPool for execution. And because of how the test is structured, doing 'real work' t\", \"hat competes for CPU cycles with thread pool threads all racing to get their next task, it shows a m\", \"easurable improvement when moving to .NET 7.\\n\\n```\\nprivate readonly byte[][] _nestedArrays = new byte\", \"[8][]; private const int Iterations = 100_000; private static byte IterateAll(byte[] arr) { byte ret\", \" = default ; foreach (byte item in arr) ret = item; return ret; } [Benchmark(OperationsPerInvoke = I\", \"terations)] public async Task MultipleSerial() { for (int i = 0; i < Iterations; i++) { for (int j =\", \" 0; j < _nestedArrays.Length; j++) { _nestedArrays[j] = ArrayPool<byte>.Shared.Rent(4096); _nestedAr\", \"rays[j].AsSpan().Clear(); } await Task.Yield(); for (int j = _nestedArrays.Length - 1; j >= 0; j--) \", \"{ IterateAll(_nestedArrays[j]); ArrayPool<byte>.Shared.Return(_nestedArrays[j]); } } }\\n```\\n\\n| Method\", \"         | Runtime   | Mean      |   Ratio |\\n|----------------|-----------|-----------|---------|\\n| \", \"MultipleSerial | .NET 6.0  | 14.340 us |    1    |\\n| MultipleSerial | .NET 7.0  | 9.262 us  |    0.6\", \"5 |\\n\\nThere have been improvements outside of ThreadPool , as well. One notable change is in the hand\", \"ling of AsyncLocal&lt;T&gt; s, in dotnet/runtime#68790. AsyncLocal&lt;T&gt; is integrated tightly wi\", \"th ExecutionContext ; in fact, in .NET Core, ExecutionContext is entirely about flowing AsyncLocal&l\", \"t;T&gt; instances. An ExecutionContext instance maintains a single field, a map data structure, that\", \" stores the data for all AsyncLocal&lt;T&gt; with data present in that context. Each AsyncLocal&lt;T\", \"&gt; has an object it uses as a key, and any gets or sets on that AsyncLocal&lt;T&gt; manifest as ge\", \"tting the current ExecutionContext , looking up that AsyncLocal&lt;T&gt; 's key in the context's dic\", \"tionary, and then either returning whatever data it finds, or in the case of a setter, creating a ne\", \"w ExecutionContext with an updated dictionary and publishing that back. This dictionary thus needs t\", \"o be very efficient for reads and writes, as developers expect AsyncLocal&lt;T&gt; access to be as f\", \"ast as possible, often treating it as if it were any other local. So, to optimize these lookups, the\", \" representation of that dictionary changes based on how many AsyncLocal&lt;T&gt; s are represented i\", \"n this context. For up to three items, dedicated implementations with fields for each of the three k\", \"eys and values were used. Above that up to around 16 elements, an array of key/value pairs was used.\", \" And above that, a Dictionary&lt;,&gt; was used. For the most part, this has worked well, with the m\", \"ajority of ExecutionContext s being able to represent many flows with one of the first three types. \", \"However, it turns out that four active AsyncLocal&lt;T&gt; instances is really common, especially in\", \" ASP.NET where ASP.NET infrastructure itself uses a couple.\\n\\nSo, this PR took the complexity hit to \", \"add a dedicated type for four key/value pairs, in order to optimize from one to four of them rather \", \"than one to three. While this improves throughput a bit, its main intent was to improve allocation, \", \"which is does over .NET 6 by ~20%.\\n\\n```\\nprivate AsyncLocal<int> asyncLocal1 = new AsyncLocal<int>();\", \" private AsyncLocal<int> asyncLocal2 = new AsyncLocal<int>(); private AsyncLocal<int> asyncLocal3 = \", \"new AsyncLocal<int>(); private AsyncLocal<int> asyncLocal4 = new AsyncLocal<int>(); [Benchmark(Opera\", \"tionsPerInvoke = 4000)] public void Update() { for (int i = 0; i < 1000; i++) { asyncLocal1.Value++;\", \" asyncLocal2.Value++; asyncLocal3.Value++; asyncLocal4.Value++; } }\\n```\\n\\n| Method   | Runtime   | Me\", \"an     |   Ratio | Code Size   | Allocated   |   Alloc Ratio |\\n|----------|-----------|----------|--\", \"-------|-------------|-------------|---------------|\\n| Update   | .NET 6.0  | 61.96 ns |       1 | 1\", \",272 B     | 176 B       |          1    |\\n| Update   | .NET 7.0  | 61.92 ns |       1 | 1,832 B    \", \" | 144 B       |          0.82 |\\n\\nAnother valuable fix comes for locking in dotnet/runtime#70165. Th\", \"is particular improvement is a bit harder to demonstrate with benchmarkdotnet, so just try running t\", \"his program, first on .NET 6 and then on .NET 7:\\n\\n```\\nusing System.Diagnostics; var rwl = new Reader\", \"WriterLockSlim(); var tasks = new Task[100]; int count = 0; DateTime end = DateTime.UtcNow + TimeSpa\", \"n.FromSeconds(10); while (DateTime.UtcNow < end) { for (int i = 0; i < 100; ++i) { tasks[i] = Task.R\", \"un(() => { var sw = Stopwatch.StartNew(); rwl.EnterReadLock(); rwl.ExitReadLock(); sw.Stop(); if (sw\", \".ElapsedMilliseconds >= 10) { Console.WriteLine(Interlocked.Increment( ref count)); } }); } Task.Wai\", \"tAll(tasks); }\\n```\\n\\nThis is simply spinning up 100 tasks, each of which enters and exits a read-writ\", \"e lock, waits for them all, and then does the process over again, for 10 seconds. It also times how \", \"long it takes to enter and exit the lock, and writes a warning if it had to wait for at least 15ms. \", \"When I run this on .NET 6, I get ~100 occurrences of it taking &gt;= 10 ms to enter/exit the lock. O\", \"n .NET 7, I get 0 occurrences. Why the difference? The implementation of ReaderWriterLockSlim has it\", \"s own spin loop implementation, and that spin loop tries to mix together various things to do as it \", \"spins, ranging from calling Thread.SpinWait to Thread.Sleep(0) to Thread.Sleep(1) . The issue lies i\", \"n the Thread.Sleep(1) . That's saying 'put this thread to sleep for 1 millisecond'; however, the ope\", \"rating system has the ultimate say on such timings, and on Windows, by default that sleep is going t\", \"o be closer to 15 milliseconds (on Linux it's a bit lower but still quite h igh). Thus, every time t\", \"here was enough contention on the lock to force it to call Thread.Sleep(1) , we'd incur a delay of a\", \"t least 15 milliseconds, if not more. The aforementioned PR fixed this by eliminating use of Thread.\", \"Sleep(1) .\\n\\nOne final threading-related change to call out: dotnet/runtime#68639. This one is Window\", \"s specific. Windows has the concept of processor groups, each of which can have up to 64 cores in it\", \", and by default when a pro cess runs, it's assigned a specific processor group and can only use the\", \" cores in that group. With .NET 7, the runtime flips its default so that by default it will try to u\", \"se all processor groups if possible.\\n\\n## Primitive Types and Numerics\\n\\nWe've looked at code generati\", \"on and GC, at threading and vectorization, at interop\\u2026 let's turn our attention to some of the funda\", \"mental types in the system. Primitives like int and bool and double , core types like Guid and DateT\", \"ime , they form the backbone on which everything is built, and every release it's exciting to see th\", \"e improvements that find their way into these types.\\n\\nfloat and double got a very nice boost in thei\", \"r implementation of parsing (e.g. double.Parse , float.TryParse , etc.). dotnet/runtime#62301 from [\", \"@CarlVerret](https://github.com/CarlVerret) significantly improves double.Parse and float.Parse for \", \"parsing UTF16 text into floating-point values. This is particularly neat because it's based on some \", \"relatively recent research from [@lemire](https://github.com/lemire) and [@CarlVerret](https://githu\", \"b.com/CarlVerret), who used C# with .NET 5 to implement a very fast implementation for parsing float\", \"ing-point numbers, and that implementation how now found its way into .NET 7!\\n\\n```\\nprivate string[] \", \"_valuesToParse; [GlobalSetup] public void Setup() { using HttpClient hc = new HttpClient(); string t\", \"ext = hc.GetStringAsync(\\\"https://raw.githubusercontent.com/CarlVerret/csFastFloat/1d800237275f759 b7\", \"43b86fcce6680d072c1e834/Benchmark/data/canada.txt\\\").Result; var lines = new List<string>(); foreach \", \"(ReadOnlySpan<char> line in text.AsSpan().EnumerateLines()) { ReadOnlySpan<char> trimmed = line.Trim\", \"(); if (!trimmed.IsEmpty) { lines.Add(trimmed.ToString()); } } _valuesToParse = lines.ToArray(); } [\", \"Benchmark] public double ParseAll() { double total = 0; foreach (string s in _valuesToParse) { total\", \" += double.Parse(s);\\n```\\n\\n<!-- image -->\\n\\n```\\n} return total; }\\n```\\n\\n| Method   | Runtime   | Mean  \", \"   |   Ratio |\\n|----------|-----------|----------|---------|\\n| ParseAll | .NET 6.0  | 26.84 ms |    \", \"1    |\\n| ParseAll | .NET 7.0  | 12.63 ms |    0.47 |\\n\\nbool.TryParse and bool.TryFormat were also imp\", \"roved. dotnet/runtime#64782 streamlined these implementations by using BinaryPrimitives to perform f\", \"ewer writes and reads. For example, instead of TryFormat writing out 'True' by doing:\\n\\n```\\ndestinati\", \"on[0] = 'T'; destination[1] = 'r'; destination[2] = 'u'; destination[3] = 'e';\\n```\\n\\nwhich requires f\", \"our writes, it can instead implement the same operation in a single write by doing:\\n\\n```\\nBinaryPrimi\", \"tives.WriteUInt64LittleEndian(MemoryMarshal.AsBytes(destination), 0x65007500720054); // \\\"True\\\"\\n```\\n\\n\", \"That 0x65007500720054 is the numerical value of the four characters in memory as a single ulong . Yo\", \"u can see the impact of these changes with a microbenchmark:\\n\\n```\\nprivate bool _value = true ; priva\", \"te char[] _chars = new char[] { 'T', 'r', 'u', 'e' }; [Benchmark] public bool ParseTrue() => bool.Tr\", \"yParse(_chars, out _); [Benchmark] public bool FormatTrue() => _value.TryFormat(_chars, out _);\\n```\\n\", \"\\n| Method     | Runtime   | Mean     |   Ratio |\\n|------------|-----------|----------|---------|\\n| P\", \"arseTrue  | .NET 6.0  | 7.347 ns |    1    |\\n| ParseTrue  | .NET 7.0  | 2.327 ns |    0.32 |\\n| Forma\", \"tTrue | .NET 6.0  | 3.030 ns |    1    |\\n| FormatTrue | .NET 7.0  | 1.997 ns |    0.66 |\\n\\nEnum gets \", \"several performance boosts, as well. For example, when performing an operation like Enum.IsDefined ,\", \" Enum.GetName , or Enum.ToString , the implementation consults a cache of all of the values defined \", \"on the enum. This cache includes the string name and the value for every defined enumeration in the \", \"Enum . It's also sorted by value in an array, so when one of these operations is performed, the code\", \" uses Array.BinarySearch to find the index of the relevant entry. The issue with that is one of over\", \"heads. When it comes to algorithmic complexity, a binary search is faster than a linear search; afte\", \"r all, a binary search is O(log N) whereas a linear search is O(N) . However, there's also less over\", \"head for every step of the algorithm in a linear search, and so for smaller values of N , it can be \", \"much faster to simply do the simple thing. That's what dotnet/runtime#57973 does for enums. For enum\", \"s with less than or equal to 32 defined values, the implementation now just does a linear search via\", \" the internal SpanHelpers.IndexOf (the worker routine behind IndexOf on spans, strings,\\n\\nand arrays)\", \", and for enums with more than that, it does a SpanHelpers.BinarySearch (which is the implementation\", \" for Array.BinarySearch ).\\n\\n```\\nprivate DayOfWeek[] _days = Enum.GetValues<DayOfWeek>(); [Benchmark]\", \" public bool AllDefined() { foreach (DayOfWeek day in _days) { if (!Enum.IsDefined(day)) { return fa\", \"lse ; } } return true ; }\\n```\\n\\n| Method     | Runtime   | Mean      |   Ratio |\\n|------------|------\", \"-----|-----------|---------|\\n| AllDefined | .NET 6.0  | 159.28 ns |     1   |\\n| AllDefined | .NET 7.\", \"0  | 94.86 ns  |     0.6 |\\n\\nEnum s also get a boost in conjunction with Nullable&lt;T&gt; and Equali\", \"tyComparer&lt;T&gt;.Default . EqualityComparer&lt;T&gt;.Default caches a singleton instance of an Eq\", \"ualityComparer&lt;T&gt; instance returned from all accesses to Default . That singleton is initializ\", \"ed based on the T in question, with the implementation choosing from a multitude of different intern\", \"al implementations, for example a ByteArrayComparer specialized for bytes, a GenericEqualityComparer\", \"&lt;T&gt; for T s that implement IComparable&lt;T&gt; , and so on. The catch-all, for arbitrary type\", \"s, is an ObjectEqualityComparer&lt;T&gt; . As it happens, nullable enums would end up hitting this c\", \"atch-all path, which means that every Equals call would box the arguments. dotnet/runtime#68077 fixe\", \"s this by ensuring nullable enums get mapped to (an existing) specialized comparer for Nullable&lt;T\", \"&gt; and simple tweaks its definition to ensure it can play nicely with enums. The results highlight\", \" just how much unnecessary overhead there was previously.\\n\\n```\\nprivate DayOfWeek?[] _enums = Enum.Ge\", \"tValues<DayOfWeek>().Select(e => (DayOfWeek?)e).ToArray(); [Benchmark] [Arguments(DayOfWeek.Saturday\", \")] public int FindEnum(DayOfWeek value) => IndexOf(_enums, value); private static int IndexOf<T>(T[]\", \" values, T value) { for (int i = 0; i < values.Length; i++) { if (EqualityComparer<T>.Default.Equals\", \"(values[i], value)) { return i; } } return -1; }\\n```\\n\\n| Method   | Runtime   | Mean       |   Ratio \", \"|\\n|----------|-----------|------------|---------|\\n| FindEnum | .NET 6.0  | 421.608 ns |    1    |\\n| \", \"FindEnum | .NET 7.0  | 5.466 ns   |    0.01 |\\n\\nNot to be left out, Guid 's equality operations also \", \"get faster, thanks to dotnet/runtime#66889 from [@madelson](https://github.com/madelson). The previo\", \"us implementation of Guid split the data into four 32-bit values and performed 4 int comparisons. Wi\", \"th this change, if the current hardware has 128-bit SIMD support, the implementation loads the data \", \"from the two guids as two vectors and simply does a single comparison.\\n\\n```\\nprivate Guid _guid1 = Gu\", \"id.Parse(\\\"0aa2511d-251a-4764-b374-4b5e259b6d9a\\\"); private Guid _guid2 = Guid.Parse(\\\"0aa2511d-251a-47\", \"64-b374-4b5e259b6d9a\\\"); [Benchmark] public bool GuidEquals() => _guid1 == _guid2;\\n```\\n\\n| Method     \", \"| Runtime   | Mean     |   Ratio | Code Size   |\\n|------------|-----------|----------|---------|----\", \"---------|\\n| GuidEquals | .NET 6.0  | 2.119 ns |    1    | 90 B        |\\n| GuidEquals | .NET 7.0  | \", \"1.354 ns |    0.64 | 78 B        |\\n\\nDateTime equality is also improved. dotnet/runtime#59857 shaves \", \"some overhead off of DateTime.Equals . DateTime is implemented with a single ulong \\\\_dateData field,\", \" where the majority of the bits store a ticks offset from 1/1/0001 12:00am and where each tick is 10\", \"0 nanoseconds, and where the top two bits describe the DateTimeKind . Thus the public Ticks property\", \" returns the value of \\\\_dateData but with the top two bits masked out, e.g. \\\\_dateData &amp; 0x3FFFF\", \"FFFFFFFFFFF . The equality operators were all then just comparing one DateTime 's Ticks against the \", \"others, such that we effectively get (dt1.\\\\_dateData &amp; 0x3FFFFFFFFFFFFFFF) == (dt2.\\\\_dateData &a\", \"mp; 0x3FFFFFFFFFFFFFFF) . However, as a micro-optimization that can instead be expressed more effici\", \"ently as ((dt1.\\\\_dateData ^ dt2.\\\\_dateData) &lt;&lt; 2) == 0 . It's difficult to measure the differe\", \"nce in such tiny operations, but you can see it simply from the number of instructions involved, whe\", \"re on .NET 6 this produces:\\n\\n```\\n; Program.DateTimeEquals() mov       rax,[rcx+8] mov       rdx,[rcx\", \"+10] mov       rcx,0FFFFFFFFFFFF and       rax,rcx and       rdx,rcx cmp       rax,rdx sete      al \", \"movzx     eax,al ret ; Total bytes of code 34\\n```\\n\\n## and on .NET 7 this produces:\\n\\n```\\n; Program.Da\", \"teTimeEquals() mov       rax,[rcx+8] mov       rdx,[rcx+10] xor       rax,rdx shl       rax,2\\n```\\n\\n`\", \"``\\nsete      al movzx     eax,al ret ; Total bytes of code 22\\n```\\n\\nso instead of a mov , and , and ,\", \" and cmp , we get just an xor and a shl .\\n\\nOther operations on DateTime also become more efficient, \", \"thanks to dotnet/runtime#72712 from [@SergeiPavlov](https://github.com/SergeiPavlov) and dotnet/runt\", \"ime#73277 from [@SergeiPavlov](https://github.com/SergeiPavlov). In another case of .NET benefiting \", \"from recent advancements in research, these PRs implemented the algorithm from Neri and Schneider's \", \"'Euclidean Affine Functions and Applications to Calendar Algorithms' in order to improve DateTime.Da\", \"y , DateTime.DayOfYear , DateTime.Month , and DateTime.Year , as well as the internal helper DateTim\", \"e.GetDate() that's used by a bunch of other methods like DateTime.AddMonths , Utf8Formatter.TryForma\", \"t(DateTime, ...) , DateTime.TryFormat , and DateTime.ToString .\\n\\n```\\nprivate DateTime _dt = DateTime\", \".UtcNow; private char[] _dest = new char[100]; [Benchmark] public int Day() => _dt.Day; [Benchmark] \", \"public int Month() => _dt.Month; [Benchmark] public int Year() => _dt.Year; [Benchmark] public bool \", \"TryFormat() => _dt.TryFormat(_dest, out _, \\\"r\\\");\\n```\\n\\n| Method    | Runtime   | Mean       |   Ratio\", \" |\\n|-----------|-----------|------------|---------|\\n| Day       | .NET 6.0  | 5.2080 ns  |    1    |\", \"\\n| Day       | .NET 7.0  | 2.0549 ns  |    0.39 |\\n| Month     | .NET 6.0  | 4.1186 ns  |    1    |\\n|\", \" Month     | .NET 7.0  | 2.0945 ns  |    0.51 |\\n| Year      | .NET 6.0  | 3.1422 ns  |    1    |\\n| Y\", \"ear      | .NET 7.0  | 0.8200 ns  |    0.26 |\\n| TryFormat | .NET 6.0  | 27.6259 ns |    1    |\\n| Try\", \"Format | .NET 7.0  | 25.9848 ns |    0.94 |\\n\\nSo, we've touched on improvements to a few types, but t\", \"he pi\\u00e8ce de r\\u00e9sistance around primitive types in this release is 'generic math,' which impacts almos\", \"t every primitive type in .NET. There are significant improvements here, some which have been in the\", \" making for literally over a decade.\\n\\nThere's an excellent blog post from June dedicated just to gen\", \"eric math , so I won't go into much depth here. At a high level, however, there are now over 30 new \", \"interfaces that utilize the new C# 11 static abstract interface methods functionality, exposing wide\", \"-ranging operations from exponentiation functions to trigonometric functions to standard numerical o\", \"perators, all available via generics, such that you can write one implementation that operates over \", \"these interfaces generically and have your\\n\\ncode applied to any types that implement the interfaces\\u2026\", \" which all of the numerical types in .NET 7 do (including not just the primitives but also, for exam\", \"ple, BigInteger and Complex ). A preview version of this feature, including necessary runtime suppor\", \"t, language syntax, C# compiler support, generic interfaces, and interface implementations all shipp\", \"ed in .NET 6 and C# 10, but it wasn't supported for production use, and you had to download an exper\", \"imental reference assembly in order to get access. With dotnet/runtime#65731, all of this support mo\", \"ved into .NET 7 as supported functionality. dotnet/runtime#66748, dotnet/runtime#67453, dotnet/runti\", \"me#69391, dotnet/runtime#69582, dotnet/runtime#69756, and dotnet/runtime#71800 all updated the desig\", \"n and implementation based on feedback from usage in .NET 6 and .NET 7 previews as well as a proper \", \"API review with our API review team (a process every new API in .NET goes through before it's shippe\", \"d publicly). dotnet/runtime#67714 added support for user-defined checked operators, a new C# 11 feat\", \"ure that enables both unchecked and checked variations of operators to be exposed, with the compiler\", \" picking the right one based on the checked context. dotnet/runtime#68096 also added support for the\", \" new C# 11 unsigned right shift operator ( &gt;&gt;&gt; ). And dotnet/runtime#69651, dotnet/runtime#\", \"67939, dotnet/runtime#73274, dotnet/runtime#71033, dotnet/runtime#71010, dotnet/runtime#68251, dotne\", \"t/runtime#68217, and dotnet/runtime#68094 all added large swaths of new public surface area for vari\", \"ous operations, all with highly-efficient managed implementations, in many cases based on the open s\", \"ource AMD Math Library.\\n\\nWhile this support is all primarily intended for external consumers, the co\", \"re libraries do consume some of it internally. You can see how these APIs clean up consuming code ev\", \"en while maintaining performance in PRs like dotnet/runtime#68226 and dotnet/runtime#68183, which us\", \"e the interfaces to deduplicate a bunch of LINQ code in Enumerable . Sum / Average / Min / Max . The\", \"re are multiple overloads of these methods for int , long , float , double , and decimal . The GitHu\", \"b summary of the diffs tells the story on how much code was able to be deleted:\\n\\n<!-- image -->\\n\\nAno\", \"ther simple example comes from the new System.Formats.Tar library in .NET 7, which as the name sugge\", \"sts is used for reading and writing archives in any of multiple tar file formats. The tar file forma\", \"ts include integer values in octal representation, so the TarReader class needs to parse octal value\", \"s. Some of these values are 32-bit integers, and some are 64-bit integers. Rather than have two sepa\", \"rate ParseOctalAsUInt32 and ParseOctalAsUInt64 methods, dotnet/runtime#74281] consolidated the metho\", \"ds into a single ParseOctal&lt;T&gt; with the constraint where T : struct, INumber&lt;T&gt; . The im\", \"plementation is then entirely in terms of T and can be used for either of these types (plus any othe\", \"r types meeting the constraints, should that ever be needed). What's particularly interesting about \", \"this example is the ParseOctal&lt;T&gt; method includes use of checked , e.g. value = checked((value\", \" * octalFactor) + T.CreateTruncating(digit)); . This is only possible because C# 11 includes the afo\", \"rementioned support for user-defined checked operators, enabling the generic math interfaces to supp\", \"ort both the normal and checked varieties, e.g. the IMultiplyOperators&lt;,,&gt; interface contains \", \"these methods:\\n\\n```\\nstatic abstract TResult operator *(TSelf left, TOther right); static virtual TRe\", \"sult operator checked\\n```\\n\\n```\\n*(TSelf left, TOther right) => left * right;\\n```\\n\\nand the compiler wi\", \"ll pick the appropriate one based on the context.\\n\\nIn addition to all the existing types that get th\", \"ese interfaces, there are also new types. dotnet/runtime#69204 adds the new Int128 and UInt128 types\", \". As these types implement all of the relevant generic math interfaces, they come complete with a hu\", \"ge number of methods, over 100 each, all of which are implemented efficiently in managed code. In th\", \"e future, the aim is that some set of these will be optimized further by the JIT and to take advanta\", \"ge of hardware acceleration.\\n\\nSeveral PRs moved native implementations of these kinds of math operat\", \"ions to managed code. dotnet/runtime#63881 from [@am11](https://github.com/am11) did so for Math.Abs\", \" and Math.AbsF (absolute value), and dotnet/runtime#56236 from\\n\\n[@alexcovington](https://github.com/\", \"alexcovington) did so for Math.ILogB and MathF.ILogB (base 2 integer logarithm). The latter's implem\", \"entation is based on the MUSL libc implementation of the same algorithm, and in addition to improvin\", \"g performance (in part by avoiding the transition between managed and native code, in part by the ac\", \"tual algorithm employed), it also enabled deleting two distinct implementations from native code, on\", \"e from the coreclr side and one from the mono side, which is always a nice win from a maintainabilit\", \"y perspective.\\n\\n```\\n[Benchmark] [Arguments(12345.6789)]\\n```\\n\\npublic int ILogB(double arg) =&gt; Math\", \".ILogB(arg);\\n\\n| Method   | Runtime   |     arg | Mean     |   Ratio |\\n|----------|-----------|------\", \"---|----------|---------|\\n| ILogB    | .NET 6.0  | 12345.7 | 4.056 ns |    1    |\\n| ILogB    | .NET \", \"7.0  | 12345.7 | 1.059 ns |    0.26 |\\n\\nOther math operations were also improved in various ways. Mat\", \"h{F}.Truncate was improved in dotnet/runtime#65014 from [@MichalPetryka](https://github.com/MichalPe\", \"tryka) by making it into a JIT intrinsic, such that on Arm64 the JIT could directly emit a frintz in\", \"struction.\\n\\ndotnet/runtime#65584 did the same for Max and Min so that the Arm-specific fmax and fmin\", \" instructions could be used. And several BitConverter APIs were also turned into intrinsics in dotne\", \"t/runtime#71567 in order to enable better code generation in some generic math scenarios.\\n\\ndotnet/ru\", \"ntime#55121 from [@key-moon](https://github.com/key-moon) also improves parsing, but for BigInteger \", \", and more specifically for really, really big BigIntegers . The algorithm previously employed for p\", \"arsing a string into a BigInteger was O(N^2) where N is the number of digits, but while a larger alg\", \"orithmic complexity than we'd normally like, it has a low constant overhead and so is still reasonab\", \"le for reasonably-sized values. In contrast, an alternative algorithm is available that runs in O(N \", \"* (log N)^2) time, but with a much higher constant factor involved. That makes is so that it's reall\", \"y only worth switching for really big numbers. Which is what this PR does. It implements the alterna\", \"tive algorithm and switches over to it when the input is at least 20,000 digits (so, yes, big). But \", \"for such large numbers, it makes a significant difference.\\n\\n```\\nprivate string _input = string.Conca\", \"t(Enumerable.Repeat(\\\"1234567890\\\", 100_000)); // \\\"One miiilliiiion digits\\\" [Benchmark] public BigInte\", \"ger Parse() => BigInteger.Parse(_input);\\n```\\n\\n| Method   | Runtime   | Mean    |   Ratio |\\n|--------\", \"--|-----------|---------|---------|\\n| Parse    | .NET 6.0  | 3.474 s |    1    |\\n| Parse    | .NET 7\", \".0  | 1.672 s |    0.48 |\\n\\nAlso related to BigInteger (and not just for really big ones), dotnet/run\", \"time#35565 from [@sakno](https://github.com/sakno) overhauled much of the internals of BigInteger to\", \" be based on spans rather than arrays. That in turn enabled a fair amount of use of stack allocation\", \" and slicing to avoid allocation overheads, while also improving reliability and safety by moving so\", \"me code away from unsafe pointers to safe spans. The primary performance impact is visible in alloca\", \"tion numbers, and in particular for operations related to division.\\n\\n```\\nprivate BigInteger _bi1 = B\", \"igInteger.Parse(string.Concat(Enumerable.Repeat(\\\"9876543210\\\", 100))); private BigInteger _bi2 = BigI\", \"nteger.Parse(string.Concat(Enumerable.Repeat(\\\"1234567890\\\", 100))); private BigInteger _bi3 = BigInte\", \"ger.Parse(string.Concat(Enumerable.Repeat(\\\"12345\\\", 10))); [Benchmark] public BigInteger ModPow() => \", \"BigInteger.ModPow(_bi1, _bi2, _bi3);\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Allocated   \", \"|   Alloc Ratio |\\n|----------|-----------|----------|---------|-------------|---------------|\\n| ModP\", \"ow   | .NET 6.0  | 1.527 ms |    1    | 706 B       |          1    |\\n| ModPow   | .NET 7.0  | 1.589\", \" ms |    1.04 | 50 B        |          0.07 |\\n\\n## Arrays, Strings, and Spans\\n\\nWhile there are many f\", \"orms of computation that can consume resources in applications, some of the most common include proc\", \"essing of data stored in arrays, strings, and now spans. Thus you see a focus in every .NET release \", \"on removing as much overhead as possible from such scenarios, while also finding ways to further opt\", \"imize the concrete operations developers are commonly performing.\\n\\nLet's start with some new APIs th\", \"at can help make writing more efficient code easier. When examining string parsing/processi ng code,\", \" it's very common to see characters examined for their inclusion in various sets. For example, you m\", \"ight see a loop looking for characters that are ASCII digits:\\n\\n```\\nwhile (i < str.Length) { if (str[\", \"i] >= '0' && str[i] <= '9') { i++; } }\\n```\\n\\nor that are ASCII letters:\\n\\n```\\nwhile (i < str.Length) {\", \" if ((str[i] >= 'a' && str[i] <= 'z') || (str[i] >= 'A' && str[i] <= 'Z')) { i++; } }\\n```\\n\\nor other \", \"such groups. Interestingly, there's wide -spread variation in how such checks are coded, often depen\", \"ding on how much effort a developer put in to optimizing them, or in some cases likely not even reco\", \"gnizing that some amount of performance was being left on the table. For example, that same ASCII le\", \"tter check could instead be written as:\\n\\n```\\nwhile (i < str.Length) { if ((uint)((c | 0x20) - 'a') <\", \"= 'z' - 'a') { i++; } }\\n```\\n\\nwhich while more 'intense' is also much more concise and more efficient\", \". It's taking advantage of a few tricks. First, rather than having two comparisons to determine whet\", \"her the character is greater than or equal to the lower bound and less than or equal to the upper bo\", \"und, it's doing a single comparison based on the distance between the character and the lower bound \", \"( (uint)(c - 'a') ). If 'c' is beyond 'z' , then 'c' - 'a' will be larger than 25, and the compariso\", \"n will fail. If 'c' is earlier\\n\\n<!-- image -->\\n\\nthan 'a' , then 'c' - 'a' will be negative, and cast\", \"ing it to uint will then cause it to wrap around to a massive number, also larger than 25, again cau\", \"sing the comparison to fail. Thus, we're able to pay a single additional subtraction to avoid an ent\", \"ire additional comparison and branch, which is almost always a good deal. The second trick is that |\", \" 0x20 . The ASCII table has some well-thought-out relationships, including that upper-case 'A' and l\", \"ower-case 'a' differ by only a single bit ( 'A' is 0b1000001 and 'a' is 0b1100001 ). To go from any \", \"lowercase ASCII letter to its uppercase ASCII equivalent, we thus need only to &amp; ~0x20 (to turn \", \"off that bit), and to go in the opposite direction from any uppercase ASCII letter to its lowercase \", \"ASCII equivalent, we need only to | 0x20 (to turn on that bit). We can take advantage of this in our\", \" range check, then, by normalizing our char c to be lowercase, such that for the low cost of a bit t\", \"widdle, we can achieve both the lowercase and uppercase range checks. Of course, those tricks aren't\", \" something we want every developer to have to know and write on each use. Instead, .NET 7 exposes a \", \"bunch of new helpers on System.Char to encapsulate these common checks, done in an efficient manner.\", \" char already had methods like IsDigit and IsLetter , which provided the more comprehensive Unicode \", \"meaning of those monikers (e.g. there are ~320 Unicode characters categorized as 'digits'). Now in .\", \"NET 7, there are also these helpers:\\n\\n- IsAsciiDigit\\n- IsAsciiHexDigit\\n- IsAsciiHexDigitLower\\n- IsAs\", \"ciiHexDigitUpper\\n- IsAsciiLetter\\n- IsAsciiLetterLower\\n- IsAsciiLetterUpper\\n- IsAsciiLetterOrDigit\\n\\nT\", \"hese methods were added by dotnet/runtime#69318, which also employed them in dozens of locations whe\", \"re such checks were being performed across dotnet/runtime (many of them using lessefficient approach\", \"es).\\n\\nAnother new API focused on encapsulating a common pattern is the new MemoryExtensions.CommonPr\", \"efixLength method, introduced by dotnet/runtime#67929. This accepts either two ReadOnlySpan&lt;T&gt;\", \" instances or a Span&lt;T&gt; and a ReadOnlySpan&lt;T&gt; , and an optional IEqualityComparer&lt;T&g\", \"t; , and returns the number of elements that are the same at the beginning of each input span. This \", \"is useful when you want to know the first place that two inputs differ. dotnet/runtime#68210 from [@\", \"gfoidl](https://github.com/gfoidl) then utilized the new Vector128 functionality to provide a basic \", \"vectorization of the implementation. As it's comparing two sequences and looking for the first place\", \" they differ, this implementation uses a neat trick, which is to have a single method implemented to\", \" compare the sequences as bytes. If the T being compared is bitwiseequatable and no custom equality \", \"comparer is supplied, then it reinterpret-casts the refs from the spans as byte refs, and uses the s\", \"ingle shared implementation.\\n\\nYet another new set of APIs are the IndexOfAnyExcept and LastIndexOfAn\", \"yExcept methods, introduced by dotnet/runtime#67941 and used in a variety of additional call sites b\", \"y dotnet/runtime#71146 and dotnet/runtime#71278. While somewhat of a mouthful, these methods are qui\", \"te handy. They do what their name suggests: whereas IndexOf(T value) searches for the first\\n\\noccurre\", \"nce of value in the input, and whereas IndexOfAny(T value0, T value1, ...) searches for the first oc\", \"currence of any of value0 , value1 , etc. in the input, IndexOfAnyExcept(T value) searches for the f\", \"irst occurrence of something that's not equal to value , and similarly IndexOfAnyExcept(T value0, T \", \"value1, ...) searches for the first occurrence of something that's not equal to value0 , value1 , et\", \"c. For example, let's say you wanted to know whether an array of integers was entirely 0. You can no\", \"w write that as:\\n\\n```\\nbool allZero = array.AsSpan().IndexOfAnyExcept(0) < 0;\\n```\\n\\ndotnet/runtime#734\", \"88 vectorizes this overload, as well.\\n\\n```\\nprivate byte[] _zeros = new byte[1024]; [Benchmark(Baseli\", \"ne = true )] public bool OpenCoded() { foreach (byte b in _zeros) { if (b != 0) { return false ; } }\", \" return true ; } [Benchmark] public bool IndexOfAnyExcept() => _zeros.AsSpan().IndexOfAnyExcept((byt\", \"e)0) < 0;\\n```\\n\\n| Method           | Mean      |   Ratio |\\n|------------------|-----------|---------|\", \"\\n| OpenCoded        | 370.47 ns |    1    |\\n| IndexOfAnyExcept | 23.84 ns  |    0.06 |\\n\\nOf course, w\", \"hile new 'index of' variations are helpful, we already have a bunch of such methods, and it's import\", \"ant that they are as efficient as possible. These core IndexOf{Any} methods are used in huge numbers\", \" of places, many of which are performance-sensitive, and so every release they get additional tender\", \"-loving care. While PRs like dotnet/runtime#67811 got gains by paying very close attention to the as\", \"sembly code being generated (in this case, tweaking some of the checks used on Arm64 in IndexOf and \", \"IndexOfAny to achieve better utilization), the biggest improvements here come in places where either\", \" vectorization was added and none was previously employed, or where the vectorization scheme was ove\", \"rhauled for significant gain. Let's start with dotnet/runtime#63285, which yields huge improvements \", \"for many uses of IndexOf and LastIndexOf for 'substrings' of byte s and char s. Previously, given a \", \"call like str.IndexOf(\\\"hello\\\") , the implementation would essentially do the equivalent of repeatedl\", \"y searching for the 'h', and when an 'h' was found, then performing a SequenceEqual to match the rem\", \"ainder. As you can imagine, however, it's very easy to run into cases where the first character bein\", \"g searched for is very common, such that you frequently have to break out of the vectorized loop in \", \"order to do the full string comparison. Instead, the PR implements an algorithm based on SIMD-friend\", \"ly algorithms for substring searching. Rather than just searching for the first character, it can in\", \"stead vectorize a search for both the first and last character at appropriate distances from each ot\", \"her. In our 'hello' example, in any given input, it's much more likely to find an\\n\\n'h' than it is to\", \" find an 'h' followed four characters later by an 'o', and thus this implementation is able to stay \", \"within the vectorized loop a lot longer, garnering many fewer false positives that force it down the\", \" SequenceEqual route. The implementation also handles cases where the two characters selected are eq\", \"ual, in which case it'll quickly look for another character that's not equal in order to maximize th\", \"e efficiency of the search. We can see the impact of all of this with a couple of examples:\\n\\n```\\npri\", \"vate static readonly string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/\", \"files/1661/1661-0.txt\\\").Result; [Benchmark] [Arguments(\\\"Sherlock\\\")] [Arguments(\\\"elementary\\\")] public\", \" int Count(string needle) { ReadOnlySpan<char> haystack = s_haystack; int count = 0, pos; while ((po\", \"s = haystack.IndexOf(needle)) >= 0) { haystack = haystack.Slice(pos + needle.Length); count++; } ret\", \"urn count; }\\n```\\n\\nThis is pulling down the text to 'The Adventures of Sherlock Holmes' from Project \", \"Gutenberg and then benchmarking using IndexOf to count the occurrences of 'Sherlock' and 'elementary\", \"' in the text. On my machine, I get results like this:\\n\\n| Method   | Runtime   | needle     | Mean  \", \"      |   Ratio |\\n|----------|-----------|------------|-------------|---------|\\n| Count    | .NET 6.\", \"0  | Sherlock   | 43.68 us    |    1    |\\n| Count    | .NET 7.0  | Sherlock   | 48.33 us    |    1.1\", \"1 |\\n| Count    | .NET 6.0  | elementary | 1,063.67 us |    1    |\\n| Count    | .NET 7.0  | elementar\", \"y | 56.04 us    |    0.05 |\\n\\nFor 'Sherlock', the performance is actually a bit worse in .NET 7 than \", \"in .NET 6; not much, but a measurable 10%. That's because there are very few capital 'S' characters \", \"in the source text, 841 to be exact, out of 593,836 characters in the document. At only 0.1% density\", \" of the starting character, the new algorithm doesn't bring much benefit, as the existing algorithm \", \"that searched for the first character alone captures pretty much all of the possible vectorization g\", \"ains to be had, and we do pay a bit of overhead in doing a search for both the 'S' and the 'k' , whe\", \"reas previously we'd have only searched for the 'S' . In contrast, though, there are 54,614 'e' char\", \"acters in the document, so almost 10% of the source. In that case, .NET 7 is 20x faster than .NET 6,\", \" taking 53us on .NET 7 to count all the 'e' 's vs 1084us on .NET 6. In this case, the new scheme yie\", \"lds immense gains, by vectorizing a search for both the 'e' and a 'y' at the specific distance away,\", \" a combination that is much, much less frequent. This is one of those situations where overall there\", \" are on average huge observed gains even though we can see small regressions for some specific input\", \"s.\\n\\nAnother example of significantly changing the algorithm employed is dotnet/runtime#67758, which \", \"enables some amount of vectorization to be applied to IndexOf(\\\"...\\\",\\n\\nStringComparison.OrdinalIgnore\", \"Case) . Previously, this operation was implemented with a fairly typical substring search, walking t\", \"he input string and at every location doing an inner loop to compare the target string, except perfo\", \"rming a ToUpper on every character in order to do it in a caseinsensitive manner. Now with this PR, \", \"which is based on approaches previously used by Regex , if the target string begins with an ASCII ch\", \"aracter, the implementation can use IndexOf (if the character isn't an ASCII letter) or IndexOfAny (\", \"if the character is an ASCII letter) to quickly jump ahead to the first possible location of a match\", \". Let's take the exact same benchmark as we just looked at, but tweaked to use OrdinalIgnoreCase :\\n\\n\", \"```\\nprivate static readonly string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenbe\", \"rg.org/files/1661/1661-0.txt\\\").Result; [Benchmark] [Arguments(\\\"Sherlock\\\")] [Arguments(\\\"elementary\\\")]\", \" public int Count(string needle) { ReadOnlySpan<char> haystack = s_haystack; int count = 0, pos; whi\", \"le ((pos = haystack.IndexOf(needle, StringComparison.OrdinalIgnoreCase)) >= 0) { haystack = haystack\", \".Slice(pos + needle.Length); count++; } return count; }\\n```\\n\\nHere, both words are about 4x faster on\", \" .NET 7 than they were on .NET 6:\\n\\n| Method   | Runtime   | needle     | Mean       |   Ratio |\\n|---\", \"-------|-----------|------------|------------|---------|\\n| Count    | .NET 6.0  | Sherlock   | 2,113\", \".1 us |    1    |\\n| Count    | .NET 7.0  | Sherlock   | 467.3 us   |    0.22 |\\n| Count    | .NET 6.0\", \"  | elementary | 2,325.6 us |    1    |\\n| Count    | .NET 7.0  | elementary | 638.8 us   |    0.27 |\", \"\\n\\nas we're now doing a vectorized IndexOfAny('S', 's') or IndexOfAny('E', 'e') rather than manually \", \"walking each character and comparing it. (dotnet/runtime#73533 uses the same approach now for handli\", \"ng IndexOf(char, StringComparison.OrdinalIgnoreCase). )\\n\\nAnother example comes from dotnet/runtime#6\", \"7492 from [@gfoidl](https://github.com/gfoidl). It updates MemoryExtensions.Contains with the approa\", \"ch we discussed earlier for handling the leftover elements at th e end of vectorized operation: proc\", \"ess one last vector's worth of data, even if it means duplicating some work already done. This parti\", \"cularly helps for smaller inputs where the processing time might otherwise be dominated by the seria\", \"l handling of those leftovers.\\n\\n```\\nprivate byte[] _data = new\\n```\\n\\n```\\nbyte[95];\\n```\\n\\n[Benchmark]\\n\\n\", \"public bool Contains() =&gt; \\\\_data.AsSpan().Contains((byte)1);\\n\\n| Method   | Runtime   | Mean      \", \"|   Ratio |\\n|----------|-----------|-----------|---------|\\n| Contains | .NET 6.0  | 15.115 ns |    1\", \"    |\\n| Contains | .NET 7.0  | 2.557 ns  |    0.17 |\\n\\ndotnet/runtime#60974 from [@alexcovington](htt\", \"ps://github.com/alexcovington) broadens the impact of IndexOf . Prior to this PR, IndexOf was vector\", \"ized for one and two-byte sized primitive types, but this PR extends it as well to four and eight-by\", \"te sized primitives. As with most of the other vectorized implementations, it checks whether the T i\", \"s bitwise-equatable, which is important for the vectorization as it's only looking at the bits in me\", \"mory and not paying attention to any Equals implementation that might be defined on the type. In pra\", \"ctice today, that means this is limited to just a handful of types of which the runtime has intimate\", \" knowledge ( Boolean , Byte , SByte , UInt16 , Int16 , Char , UInt32 , Int32 , UInt64 , Int64 , UInt\", \"Ptr , IntPtr , Rune , and enums), but in theory it could be extended in the future.\\n\\nprivate int[] \\\\\", \"_data = new int[1000];\\n\\n[Benchmark]\\n\\npublic int IndexOf() =&gt; \\\\_data.AsSpan().IndexOf(42);\\n\\n| Meth\", \"od   | Runtime   | Mean      |   Ratio |\\n|----------|-----------|-----------|---------|\\n| IndexOf  |\", \" .NET 6.0  | 252.17 ns |    1    |\\n| IndexOf  | .NET 7.0  | 78.82 ns  |    0.31 |\\n\\nOne final interes\", \"ting IndexOf -related optimization. string has long had IndexOf / IndexOfAny / LastIndexOf / LastInd\", \"exOfAny , and obviously for string it's all about processing char s. When ReadOnlySpan&lt;T&gt; and \", \"Span&lt;T&gt; came on the scene, MemoryExtensions was added to provide extension methods for spans a\", \"nd friends, including such\\n\\nIndexOf / IndexOfAny / LastIndexOf / LastIndexOfAny methods. But for spa\", \"ns, this is about more than just char , and so MemoryExtensions grew its own set of implementations \", \"largely separate from string 's. Over the years, MemoryExtensions implementations have specialized m\", \"ore and more types, but in particular byte and char , such that over time string 's implementations \", \"have mostly been replaced by delegation into the same implementation as MemoryExtensions uses. Howev\", \"er, IndexOfAny and LastIndexOfAny had been unification holdouts, each in its own direction. string.I\", \"ndexOfAny did delegate to the same implementation as MemoryExtensions.IndexOfAny for 1-5 values bein\", \"g searched for, but for more than 5 values, string.IndexOfAny used a 'probabilistic map,' essentiall\", \"y a Bloom filter. It creates a 256-bit table, and quickly sets bits in that table based on the value\", \"s being searched for (essentially hashing them, but with a trivial hash function). Then it iterates \", \"through the input, and rather than checking every input character against every one of the target va\", \"lues, it instead first looks up the i nput character in the table. If the corresponding bit isn't se\", \"t, it knows the input character doesn't match any of the target values. If the corresponding bit is \", \"set, then it proceeds to compare the input character against each of the target values, with a high \", \"probability of it being one of them. MemoryExtensions.IndexOfAny lacked such a filter for more than \", \"5 values. Conversely, string.LastIndexOfAny didn't provide any vectorization for multiple target val\", \"ues, whereas MemoryExtensions.LastIndexOfAny vectorized two and three target values. As of\\n\\ndotnet/r\", \"untime#63817, all of these are now unified, such that both string and MemoryExtensions get the best \", \"of what the other had.\\n\\n```\\nprivate readonly char[] s_target = new [] { 'z', 'q' }; const string Son\", \"net = \\\"\\\"\\\" Shall I compare thee to a summer's day? Thou art more lovely and more temperate: Rough win\", \"ds do shake the darling buds of May, And summer's lease hath all too short a date; Sometime too hot \", \"the eye of heaven shines, And often is his gold complexion dimm'd; And every fair from fair sometime\", \" declines, By chance or nature's changing course untrimm'd; But thy eternal summer shall not fade, N\", \"or lose possession of that fair thou ow'st; Nor shall death brag thou wander'st in his shade, When i\", \"n eternal lines to time thou grow'st: So long as men can breathe or eyes can see, So long lives this\", \" , and this gives life to thee. \\\"\\\"\\\"; [Benchmark] public int LastIndexOfAny() => Sonnet.LastIndexOfAn\", \"y(s_target); [Benchmark] public int CountLines() { int count = 0; foreach (ReadOnlySpan<char> _ in S\", \"onnet.AsSpan().EnumerateLines()) { count++; } return count; }\\n```\\n\\n| Method         | Runtime   | Me\", \"an        |   Ratio |\\n|----------------|-----------|-------------|---------|\\n| LastIndexOfAny | .NET\", \" 6.0  | 443.29 ns   |    1    |\\n| LastIndexOfAny | .NET 7.0  | 31.79 ns    |    0.07 |\\n| CountLines \", \"    | .NET 6.0  | 1,689.66 ns |    1    |\\n| CountLines     | .NET 7.0  | 1,461.64 ns |    0.86 |\\n\\nTh\", \"at same PR also cleans up uses of the IndexOf family, and in particular around uses that are checkin\", \"g for containment rather than the actual index of a result. The IndexOf family of methods return a n\", \"on-negative value when an element is found, and otherwise return -1. That means when checking whethe\", \"r an element was found, code can use either &gt;= 0 or != -1 , and when checking whether an element \", \"wasn't found, code can use either &lt; 0 or == -1 . It turns out that the code generated for compari\", \"sons against 0 is ever so slightly more efficient than comparisons generated against 1, and this isn\", \"'t something the JIT can itself substitute without the IndexOf methods being intrinsics such that th\", \"e JIT can understand the semantics of the return value. Thus, for consistency and a small perf gain,\", \" all relevant call sites were switched to compare against 0 instead of against -1.\\n\\nSpeaking of call\", \" sites, one of the great things about having highly optimized IndexOf methods is using them in all t\", \"he places that can benefit, removing the maintenance impact of open-coded replacements while also re\", \"aping the perf wins. dotnet/runtime#63913 used IndexOf inside of StringBuilder.Replace to speed up t\", \"he search for the next character to be replaced:\\n\\n```\\nprivate StringBuilder _builder = new StringBui\", \"lder(Sonnet); [Benchmark] public void Replace() { _builder.Replace('?', '!'); _builder.Replace('!', \", \"'?'); }\\n```\\n\\n| Method   | Runtime   | Mean        |   Ratio |\\n|----------|-----------|-------------|\", \"---------|\\n| Replace  | .NET 6.0  | 1,563.69 ns |    1    |\\n| Replace  | .NET 7.0  | 70.84 ns    |  \", \"  0.04 |\\n\\ndotnet/runtime#60463 from [@nietras](https://github.com/nietras) used IndexOfAny in String\", \"Reader.ReadLine to search for '\\\\r' and '\\\\n' line ending characters, which results in some substantia\", \"l throughput gains even with the allocation and copy that is inherent to the method's design:\\n\\n```\\n[\", \"Benchmark] public void ReadAllLines() { var reader = new StringReader(Sonnet); while (reader.ReadLin\", \"e() != null ) ; }\\n```\\n\\n| Method       | Runtime   | Mean     |   Ratio |\\n|--------------|-----------\", \"|----------|---------|\\n| ReadAllLines | .NET 6.0  | 947.8 ns |    1    |\\n| ReadAllLines | .NET 7.0  \", \"| 385.7 ns |    0.41 |\\n\\nAnd dotnet/runtime#70176 cleaned up a plethora of additional uses.\\n\\nFinally \", \"on the IndexOf front, as noted, a lot of time and energy over the years has gone into optimizing the\", \"se methods. In previous releases, some of that energy has been in the form of using hardware intrins\", \"ics directly, e.g. having an SSE2 code path and an AVX2 code path and an AdvSimd code path. Now that\", \" we have Vector128&lt;T&gt; and Vector256&lt;T&gt; , many such uses can be simplified (e.g. avoiding\", \" the duplication between an SSE2 implementation and an AdvSimd implementation) while still maintaini\", \"ng as good or even better performance and while automatically supporting vectorization on other plat\", \"forms with their own intrinsics, like WebAssembly. dotnet/runtime#73481, dotnet/runtime#73556, dotne\", \"t/runtime#73368, dotnet/runtime#73364, dotnet/runtime#73064, and dotnet/runtime#73469 all contribute\", \"d here, in some cases incurring meaningful throughput gains:\\n\\n```\\n[Benchmark] public int IndexOfAny(\", \") => Sonnet.AsSpan().IndexOfAny(\\\"!.<>\\\");\\n```\\n\\n| Method     | Runtime   | Mean     |   Ratio |\\n|-----\", \"-------|-----------|----------|---------|\\n| IndexOfAny | .NET 6.0  | 52.29 ns |    1    |\\n| IndexOfA\", \"ny | .NET 7.0  | 40.17 ns |    0.77 |\\n\\nThe IndexOf family is just one of many on string / MemoryExte\", \"nsions that has seen dramatic improvements. Another are the SequenceEquals family, including Equals \", \", StartsWith , and EndsWith . One of my favorite changes in the whole release is dotnet/runtime#6528\", \"8 and is squarely in this area. It's very common to see calls to methods like StartsWith with a cons\", \"tant string argument, e.g. value.StartsWith(\\\"https://\\\") , value.SequenceEquals(\\\"Key\\\") , etc. These m\", \"ethods are now recognized by the JIT, which can now automatically unroll the comparison and compare \", \"more than one char at a time, e.g. doing a single read of four chars as a long and a single comparis\", \"on of that long against the expected combination of those four chars. The result is beautiful. Makin\", \"g it even better is dotnet/runtime#66095, which adds to this support for OrdinalIgnoreCase . Remembe\", \"r those ASCII bit twiddling tricks discussed a bit earlier with char.IsAsciiLetter and friends? The \", \"JIT now employs the same trick as part of this unrolling, so if you do that same value.StartsWith(\\\"h\", \"ttps://\\\")\\n\\nbut instead as value.StartsWith(\\\"https://\\\",\\n\\nStringComparison.OrdinalIgnoreCase) , it wil\", \"l recognize that the whole comparison string is ASCII and will OR in the appropriate mask on both th\", \"e comparison constant and on the read data from the input in order to perform the comparison in a ca\", \"se-insensitive manner.\\n\\n```\\nprivate string _value = \\\"https://dot.net\\\"; [Benchmark] public bool IsHtt\", \"ps_Ordinal() => _value.StartsWith(\\\"https://\\\", StringComparison.Ordinal); [Benchmark] public bool IsH\", \"ttps_OrdinalIgnoreCase() => _value.StartsWith(\\\"https://\\\", StringComparison.OrdinalIgnoreCase);\\n```\\n\\n\", \"| Method                    | Runtime   | Mean      |   Ratio |\\n|---------------------------|-------\", \"----|-----------|---------|\\n| IsHttps_Ordinal           | .NET 6.0  | 4.5634 ns |    1    |\\n| IsHttp\", \"s_Ordinal           | .NET 7.0  | 0.4873 ns |    0.11 |\\n| IsHttps_OrdinalIgnoreCase | .NET 6.0  | 6.\", \"5654 ns |    1    |\\n| IsHttps_OrdinalIgnoreCase | .NET 7.0  | 0.5577 ns |    0.08 |\\n\\nInterestingly, \", \"since .NET 5 the code generated by RegexOptions.Compiled would perform similar unrolling when compar\", \"ing sequences of multiple characters, and when the source generator was added in .NET 7, it also lea\", \"rned how to do this. However, the source generator has problems with such an optimization, due to en\", \"dianness. The constants being compared against are subject to byte ordering issues, such that the so\", \"urce generator would need to emit code that could handle running on either little-endian or bigendia\", \"n machines. The JIT has no such problem, as it's generating the code on the same machine on which th\", \"e code will execute (and in scenarios where it's being used to generate code ahead of time, the enti\", \"rety of that code is already tied to a particular architecture). By moving this optimization into th\", \"e JIT, the corresponding code could be deleted from RegexOptions.Compiled and the regex source gener\", \"ator, which then also benefits from producing\\n\\nmuch easier to read code utilizing StartsWith that's \", \"just as fast ( dotnet/runtime#65222 and dotnet/runtime#66339). Wins all around. (This could only be \", \"removed from RegexOptions.Compiled after dotnet/runtime#68055, which fixed the ability for the JIT t\", \"o recognize these string literals in DynamicMethod s, which RegexOptions.Compiled uses with reflecti\", \"on emit to spit out the IL for the regex being compiled.)\\n\\nStartsWith and EndsWith have improved in \", \"other ways. dotnet/runtime#63734 (improved further by dotnet/runtime#64530) added another really int\", \"eresting JIT-based optimization, but to understand it, we need to understand string 's internal layo\", \"ut. string is essentially represented in memory as an int length followed by that many char s plus a\", \" null terminator char . The actual System.String class represents this in C# as an int \\\\_stringLengt\", \"h field followed by a char \\\\_firstChar field, such that \\\\_firstChar indeed lines up with the first c\", \"haracter of the string, or the null terminator if the string is empty. Internally in System.Private.\", \"CoreLib, and in particular in methods on string itself, code will often refer to \\\\_firstChar directl\", \"y when the first charact er needs to be consulted, as it's typically faster to do that than to use s\", \"tr[0] , in particular because there are no bounds checks involved and the string's length generally \", \"needn't be consulted. Now, consider a method like public bool StartsWith(char value) on string . In \", \".NET 6, the implementation was:\\n\\n```\\nreturn\\n```\\n\\n```\\nLength != 0 && _firstChar == value;\\n```\\n\\nwhich \", \"given what I just described makes sense: if the Length is 0, then the string doesn't begin with the \", \"specified character, and if Length is not 0, then we can just compare the value against \\\\_firstChar \", \". But, why is that Length check even needed at all? Couldn't we just do return \\\\_firstChar == value;\", \" ? That will avoid the additional comparison and branch, and it will work just fine\\u2026 unless the targ\", \"et character is it self '\\\\0' , in which case we could get false positives on the result. Now to this\", \" PR. The PR introduces an internal JIT intrinsinc RuntimeHelpers.IsKnownConstant , which the JIT wil\", \"l substitute with true if the containing method is inlined and the argument passed to IsKnownConstan\", \"t is then seen to be a constant. In such cases, the implementation can rely on other JIT optimizatio\", \"ns kicking in and optimizing various code in the method, effectively enabling a developer to write t\", \"wo different implementations, one when the argument is known to be a constant and one when not. With\", \" that in hand, the PR is able to optimize StartsWith as follows:\\n\\n```\\npublic bool StartsWith(char va\", \"lue) { if (RuntimeHelpers.IsKnownConstant(value) && value != '\\\\0') return _firstChar == value; retur\", \"n Length != 0 && _firstChar == value; }\\n```\\n\\nIf the value parameter isn't a constant, then IsKnownCo\", \"nstant will be substituted with false , the entire starting if block will be eliminated, and the met\", \"hod will be left exactly was it was before. But, if this method gets inlined and the value was actua\", \"lly a constant, then the value != '\\\\0' condition will also be evaluatable at JIT-compile-time. If th\", \"e value is in fact '\\\\0' , well, again that whole if block will be eliminated and we're no worse off.\", \" But in the common case where the value isn't null, the entire method will end up being compiled as \", \"if it were:\\n\\n```\\nreturn _firstChar == ConstantValue;\\n```\\n\\nand we've saved ourselves a read of the st\", \"ring's length, a comparison, and a branch. dotnet/runtime#69038 then employs a similar technique for\", \" EndsWith .\\n\\n```\\nprivate string _value = \\\"https://dot.net\\\"; [Benchmark] public bool StartsWith() => \", \"_value.StartsWith('a') || _value.StartsWith('b') || _value.StartsWith('c') || _value.StartsWith('d')\", \" || _value.StartsWith('e') || _value.StartsWith('f') || _value.StartsWith('g') || _value.StartsWith(\", \"'i') || _value.StartsWith('j') || _value.StartsWith('k') || _value.StartsWith('l') || _value.StartsW\", \"ith('m') || _value.StartsWith('n') || _value.StartsWith('o') || _value.StartsWith('p');\\n```\\n\\n| Metho\", \"d     | Runtime   | Mean     |   Ratio |\\n|------------|-----------|----------|---------|\\n| StartsWit\", \"h | .NET 6.0  | 8.130 ns |     1   |\\n| StartsWith | .NET 7.0  | 1.653 ns |     0.2 |\\n\\n(Another examp\", \"le of IsKnownConstant being used comes from dotnet/runtime#64016, which uses it to improve Math.Roun\", \"d when a MidpointRounding mode is specified. Call sites to this almost always explicitly specify the\", \" enum value as a constant, which then allows the JIT to specialize the code generation for the metho\", \"d to the specific mode being used; that in turn, for example, enables a Math.Round(..., MidpointRoun\", \"ding.AwayFromZero) call on Arm64 to be lowered to a single frinta instruction.)\\n\\nEndsWith was also i\", \"mproved in dotnet/runtime#72750, and specifically for when StringComparison.OrdinalIgnoreCase is spe\", \"cified. This simple PR just switched which internal helper method was used to implement this method,\", \" taking advantage of one that is sufficient for the needs of this method and that has lower overhead\", \"s.\\n\\n```\\n[Benchmark] [Arguments(\\\"System.Private.CoreLib.dll\\\", \\\".DLL\\\")] public bool EndsWith(string ha\", \"ystack, string needle) => haystack.EndsWith(needle, StringComparison.OrdinalIgnoreCase);\\n```\\n\\n| Meth\", \"od   | Runtime   | Mean      |   Ratio |\\n|----------|-----------|-----------|---------|\\n| EndsWith |\", \" .NET 6.0  | 10.861 ns |     1   |\\n| EndsWith | .NET 7.0  | 5.385 ns  |     0.5 |\\n\\nFinally, dotnet/r\", \"untime#67202 and dotnet/runtime#73475 employ Vector128&lt;T&gt; and Vector256&lt;T&gt; to replace di\", \"rect hardware intrinsics usage, just as was previously shown for various IndexOf methods, but here f\", \"or SequenceEqual and SequenceCompareTo , respectively.\\n\\nAnother method that's seem some attention in\", \" .NET 7 is MemoryExtensions.Reverse (and Array.Reverse as it shares the same implementation), which \", \"performs an in-place reversal of the target span. dotnet/runtime#64412 from [@alexcovington](https:/\", \"/github.com/alexcovington) provides a vectorized implementation via direct use of AVX2 and SSSE3 har\", \"dware intrinsics, with dotnet/runtime#72780 from [@SwapnilGaikwad](https://github.com/SwapnilGaikwad\", \") following up to add an AdvSimd intrinsics implementation for Arm64. (There was an unintended regre\", \"ssion introduced by the original vectorization change, but that was fixed by dotnet/runtime#70650.)\\n\", \"\\nprivate char[] text = \\\"Free. Cross-platform. Open source.\\\\r\\\\nA developer platform for building all \", \"your apps.\\\".ToCharArray(); [Benchmark] public void Reverse() =&gt; Array.Reverse(text);\\n\\n| Method   \", \"| Runtime   | Mean      |   Ratio |\\n|----------|-----------|-----------|---------|\\n| Reverse  | .NET\", \" 6.0  | 21.352 ns |    1    |\\n| Reverse  | .NET 7.0  | 9.536 ns  |    0.45 |\\n\\nString.Split also saw \", \"vectorization improvements in dotnet/runtime#64899 from [@yesmey](https://github.com/yesmey). As wit\", \"h some of the previously discussed PRs, it switched the existing usage of SSE2 and SSSE3 hardware in\", \"trinsics over to the new Vector128&lt;T&gt; helpers, which improved upon the existing implementation\", \" while also implicitly adding vectorization support for Arm64.\\n\\nConverting various formats of string\", \"s is something many applications and services do, whether that's converting from UTF8 bytes to and f\", \"rom string or formatting and parsing hex values. Such operations have also improved in a variety of \", \"ways in .NET 7. Base64-encoding, for example, is a way of representing arbitrary binary data (think \", \"byte[] ) across mediums that only support text, encoding bytes into one of 64 different ASCII charac\", \"ters. Multiple APIs in .NET implement this encoding. For converting between binary data represented \", \"as ReadOnlySpan&lt;byte&gt; and UTF8 (actually ASCII) encoded data also represented as ReadOnlySpan&\", \"lt;byte&gt; , the System.Buffers.Text.Base64 type provides EncodeToUtf8 and DecodeFromUtf8 methods. \", \"These were vectorized several releases ago, but they were further improved in .NET 7 via dotnet/runt\", \"ime#70654 from [@a74nh](https://github.com/a74nh), which converted the SSSE3-based implementation to\", \" use Vector128&lt;T&gt; (which in turn implicitly enabled vectorization on Arm64). However, for conv\", \"erting between arbitrary binary data represented as ReadOnlySpan&lt;byte&gt; / byte[] and ReadOnlySp\", \"an&lt;char&gt; / char[] / string , the System.Convert type exposes multiple methods, e.g. Convert.To\", \"Base64String , and these methods historically were not vectorized. That changes in .NET 7, where dot\", \"net/runtime#71795 and dotnet/runtime#73320 vectorize the ToBase64String , ToBase64CharArray , and Tr\", \"yToBase64Chars methods. The way they do this is interesting. Rather than effectively duplicating the\", \" vectorization implementation from Base64.EncodeToUtf8 , they instead layer on top of EncodeToUtf8 ,\", \" calling it to encode the input byte data into an output Span&lt;byte&gt; . Then, then they 'widen' \", \"those bytes into chars (remember, Base64 -encoded data is a set of ASCII chars, so going from these \", \"bytes to chars entails adding just a 0 byte onto each element). That widening can itself easily be d\", \"one in a vectorized manner. The other interesting thing about this layering is it doesn't actually r\", \"equire separate inter mediate storage for the encoded bytes. The implementation can perfectly comput\", \"e the number of resulting characters for encoding X bytes into Y\\n\\nBase64 characters (there's a formu\", \"la), and the implementation can either allocate that final space (e.g. in the case of ToBase64CharAr\", \"ray) or ensure the provided space is sufficient (e.g. in the case of TryToBase64Chars). And since we\", \" know the initial encoding will require exactly half as many bytes, we can encode into that same spa\", \"ce (with the destination span reinterpreted as a byte span rather than char span), and then widen 'i\", \"n place': walk from the end of the bytes and the end of the char space, copying the bytes into the d\", \"estination.\\n\\n```\\nprivate byte[] _data = Encoding.UTF8.GetBytes(\\\"\\\"\\\" Shall I compare thee to a summer'\", \"s day? Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And su\", \"mmer's lease hath all too short a date; Sometime too hot the eye of heaven shines, And often is his \", \"gold complexion dimm'd; And every fair from fair sometime declines, By chance or nature's changing c\", \"ourse untrimm'd; But thy eternal summer shall not fade, Nor lose possession of that fair thou ow'st;\", \" Nor shall death brag thou wander'st in his shade, When in eternal lines to time thou grow'st: So lo\", \"ng as men can breathe or eyes can see, So long lives this , and this gives life to thee. \\\"\\\"\\\"); priva\", \"te char[] _encoded = new char[1000]; [Benchmark] public bool TryToBase64Chars() => Convert.TryToBase\", \"64Chars(_data, _encoded, out _);\\n```\\n\\n| Method           | Runtime   | Mean      |   Ratio |\\n|------\", \"------------|-----------|-----------|---------|\\n| TryToBase64Chars | .NET 6.0  | 623.25 ns |    1   \", \" |\\n| TryToBase64Chars | .NET 7.0  | 81.82 ns  |    0.13 |\\n\\nJust as widening can be used to go from b\", \"ytes to chars, narrowing can be used to go from chars to bytes, in particular if the chars are actua\", \"lly ASCII and thus have a 0 upper byte. Such narrowing can be vectorized, and the internal NarrowUtf\", \"16ToAscii utility helper does exactly that, used as part of methods like Encoding.ASCII.GetBytes . W\", \"hile this method was previously vectorized, its primary fastpath utilized SSE2 and thus didn't apply\", \" to Arm64; thanks to dotnet/runtime#70080 from [@SwapnilGaikwad](https://github.com/SwapnilGaikwad),\", \" that path was changed over to be based on the cross-platform Vector128&lt;T&gt; , enabling the same\", \" level of optimization across supported platforms. Similarly, dotnet/runtime#71637 from\\n\\n[@SwapnilGa\", \"ikwad](https://github.com/SwapnilGaikwad) adds Arm64 vectorization to the GetIndexOfFirstNonAsciiCha\", \"r internal helper that's used by methods like\\n\\nEncoding.UTF8.GetByteCount . (And in the same vein, d\", \"otnet/runtime#67192 changed the internal HexConverter.EncodeToUtf16 method from using SSSE3 intrinsi\", \"cs to instead use Vector128&lt;T&gt; , automatically providing an Arm64 implementation.)\\n\\nEncoding.U\", \"TF8 was also improved a bit. In particular, dotnet/runtime#69910 streamlined the implementations of \", \"GetMaxByteCount and GetMaxCharCount , making them small enough to be commonly inlined when used dire\", \"ctly off of Encoding.UTF8 such that the JIT is able to devirtualize the calls.\\n\\n```\\n[Benchmark] publ\", \"ic int GetMaxByteCount() => Encoding.UTF8.GetMaxByteCount(Sonnet.Length);\\n```\\n\\n| Method          | R\", \"untime   | Mean      |   Ratio |\\n|-----------------|-----------|-----------|---------|\\n| GetMaxByteC\", \"ount | .NET 6.0  | 1.7442 ns |    1    |\\n| GetMaxByteCount | .NET 7.0  | 0.4746 ns |    0.27 |\\n\\nArgu\", \"ably the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals. Initi\", \"ally implemented in the C# compiler in dotnet/roslyn#58991, with follow-on work in dotnet/roslyn#593\", \"90, dotnet/roslyn#61532, and dotnet/roslyn#62044, UTF8 literals enables the compiler to perform the \", \"UTF8 encoding into bytes at compile-time. Rather than writing a normal string, e.g. \\\"hello\\\" , a deve\", \"loper simply appends the new u8 suffix onto the string literal, e.g. \\\"hello\\\"u8 . At that point, this\", \" is no longer a string. Rather, the natural type of this expression is a ReadOnlySpan&lt;byte&gt; . \", \"If you write:\\n\\n```\\npublic static ReadOnlySpan<byte> Text => \\\"hello\\\"u8;\\n```\\n\\nthe C# compiler will com\", \"pile that equivalent to if you wrote:\\n\\n```\\npublic static ReadOnlySpan<byte> Text => new ReadOnlySpan\", \"<byte>( new byte[] { (byte)'h', (byte)'e', (byte)'l', (byte)'l', (byte)'o', (byte)'\\\\0' }, 0, 5);\\n```\", \"\\n\\nIn other words, the compiler is doing the equivalent of Encoding.UTF8.GetBytes at compile-time and\", \" hardcoding the resulting bytes, saving the cost of performing that encoding at run-time. Of course,\", \" at first glance, that array allocation might look terribly inefficient. However, looks can be decei\", \"ving, and are in this case. For several releases now, when the C# compiler sees a byte[] (or sbyte[]\", \" or bool[] ) being initialized with a constant length and constant values and immediately cast to or\", \" used to construct a ReadOnlySpan&lt;byte&gt; , it optimizes away the byte[] allocation. Instead, it\", \" blits the data for that span into the assembly's data section, and then constructs a span that poin\", \"ts directly to that data in the loaded assembly. This is the actual generated IL for the above prope\", \"rty:\\n\\n```\\nIL_0000: ldsflda valuetype '<PrivateImplementationDetails>'/'__StaticArrayInitTypeSize=6' \", \"'<PrivateImplementationDetails>'::F3AEFE62965A91903610F0E23CC8A69D5B87CEA6D28E75489B0D2CA02 ED7993C \", \"IL_0005: ldc.i4.5 IL_0006: newobj instance void valuetype [System.Runtime]System.ReadOnlySpan`1<uint\", \"8>::.ctor(void*, int32) IL_000b: ret\\n```\\n\\nThis means we not only save on the encoding costs at run-t\", \"ime, and we not only avoid whatever managed allocations might be required to store the resulting dat\", \"a, we also benefit from the JIT being able to see information about the encoded data, like it's leng\", \"th, enabling knock -on optimizations. You can see this clearly by examining the assembly generated f\", \"or a method like:\\n\\n```\\npublic static\\n```\\n\\n```\\nint M() => Text.Length;\\n```\\n\\nfor which the JIT produce\", \"s:\\n\\n```\\n; Program.M() mov       eax,5\\n```\\n\\n```\\nret ; Total bytes of code 6\\n```\\n\\nThe JIT inlines the \", \"property access, sees that the span is being constructed with a length of 5 , and so rather than emi\", \"tting any array allocations or span constructions or anything even resembling that, it simply output\", \"s mov eax, 5 to return the known length of the span.\\n\\nThanks primarily to dotnet/runtime#70568, dotn\", \"et/runtime#69995, dotnet/runtime#70894, dotnet/runtime#71417 from [@am11](https://github.com/am11), \", \"dotnet/runtime#71292, dotnet/runtime#70513, and dotnet/runtime#71992, u8 is now used more than 2100 \", \"times throughout dotnet/runtime. Hardly a fair comparison, but the following benchmark demonstrates \", \"how little work is actually being performed for u8 at execution time:\\n\\n```\\n[Benchmark(Baseline = tru\", \"e )] public ReadOnlySpan<byte> WithEncoding() => Encoding.UTF8.GetBytes(\\\"test\\\"); [Benchmark] public \", \"ReadOnlySpan<byte> Withu8() => \\\"test\\\"u8;\\n```\\n\\n| Method       | Mean       |   Ratio | Allocated   | \", \"  Alloc Ratio |\\n|--------------|------------|---------|-------------|---------------|\\n| WithEncoding\", \" | 17.3347 ns |       1 | 32 B        |             1 |\\n| Withu8       | 0.0060 ns  |       0 | -   \", \"        |             0 |\\n\\nLike I said, not fair, but it proves the point :)\\n\\nEncoding is of course \", \"just one mechanism for creating string instances. Others have also improved in .NET 7. Take the supe\", \"r common long.ToString , for example. Previous releases improved int.ToString , but there were enoug\", \"h differences between the 32-bit and 64-bit algorithms that long didn't see all of the same gains. N\", \"ow thanks to dotnet/runtime#68795, the 64-bit formatting code paths are made much more similar to th\", \"e 32-bit, resulting in faster performance.\\n\\nYou can also see improvements in string.Format and Strin\", \"gBuilder.AppendFormat , as well as other helpers that layer on top of these (like TextWriter.AppendF\", \"ormat ). dotnet/runtime#69757 overhauls the core routines inside Format to avoid unnecessary bounds \", \"checking, favor expected cases, and generally clean up the implementation. It also, however, utiliti\", \"es IndexOfAny to search for the next interpolation hole that needs to be filled in, and if the non-h\", \"ole-character to hole ratio is high (e.g. long format string with few holes), it can be way faster t\", \"han before.\\n\\n```\\nprivate StringBuilder _sb = new StringBuilder(); [Benchmark] public void AppendForm\", \"at() { _sb.Clear(); _sb.AppendFormat(\\\"There is already one outstanding '{0}' call for this WebSocket\", \" instance.\\\" + \\\"ReceiveAsync and SendAsync can be called simultaneously, but at most one \\\" + \\\"outstan\", \"ding operation for each of them is allowed at the same time.\\\", \\\"ReceiveAsync\\\"); }\\n```\\n\\n| Method     \", \"  | Runtime   | Mean      |   Ratio |\\n|--------------|-----------|-----------|---------|\\n| AppendFor\", \"mat | .NET 6.0  | 338.23 ns |    1    |\\n| AppendFormat | .NET 7.0  | 49.15 ns  |    0.15 |\\n\\nSpeaking\", \" of StringBuilder , it's seen additional improvements beyond the aforementioned changes to AppendFor\", \"mat . One interesting change is dotnet/runtime#64405, which achieved two related things. The first w\", \"as to remove pinning as part of formatting operations. As an example, StringBuilder has an Append(ch\", \"ar* value, int valueCount) overload which copies the specified number of characters from the specifi\", \"ed pointer into the StringBuilder , and other APIs were implemented in terms of this method; for exa\", \"mple, the Append(string? value, int startIndex, int count) method was essentially implemented as:\\n\\n`\", \"``\\nfixed (char* ptr = value) { Append(ptr + startIndex, count); }\\n```\\n\\nThat fixed statement translat\", \"es into a 'pinning pointer.' Normally the GC is free to move managed objects around on the heap, whi\", \"ch it might do in order to compact the heap (to, for example, avoid small, unusuable fragments of me\", \"mory between objects). But if the GC can move objects around, a normal native pointer into that memo\", \"ry would be terribly unsafe and unreliable, as without notice the data being pointed to could move a\", \"nd your pointer could now be pointing to garbage or to some other object that was shifted to this lo\", \"cation. There are two ways for dealing with this. The first is a 'managed pointer,' otherwise known \", \"as a 'reference' or 'ref,' as that's exactly what you get when you have the 'ref' keyword in C#; it'\", \"s a pointer that the runtime will update with the correct value when it moves the object being point\", \"ed into. The second is to prevent the pointed-to object from being moved, 'pinning' it in place. And\", \" that's what the 'fixed' keyword does, pinning the referenced object for the duration of the fixed b\", \"lock, during which time it's safe to use the supplied pointer. Thankfully, pinning is cheap when no \", \"GC occurs; when a GC does occur, however, pinned objects aren't able to be moved around, and thus pi\", \"nning can have a global impact on the performance of the application (and on GCs themselves). There \", \"are also various optimizations inhibited by pinning. With all of the advents in C# around being able\", \" to use ref in many more places (e.g. ref locals, ref returns, and now in C# 11, ref fields), and wi\", \"th all of the new APIs in .NET for manipulating refs (e.g. Unsafe.Add , Unsafe.AreSame ), it's now p\", \"ossible to rewrite code that was using pinning pointers to instead use managed pointers, thereby avo\", \"iding the problems that come from pinning. Which is what this PR did. Rather than implementing all o\", \"f the Append methods in terms of an Append(char*, int) helper, they're now all implemented in terms \", \"of an Append(ref char, int) helper. So for example instead of the previously shown Append(string? va\", \"lue, int startIndex, int count) implementation, it's now akin to\\n\\n```\\nAppend( ref Unsafe.Add( ref va\", \"lue.GetRawStringData(), startIndex), count);\\n```\\n\\nwhere that string.GetRawStringData method is just \", \"an internal version of the public string.GetPinnableReference method, returning a ref instead of a r\", \"ef readonly . This means that all of the high-performance code inside of StringBuilder that had been\", \" using pointers to avoid bounds checking and the like can continue to do so, but now also does so wi\", \"thout pinning all of the inputs.\\n\\nThe second thing this StringBuilder change did was unify an optimi\", \"zation that was present for string inputs to also apply to char[] inputs and ReadOnlySpan&lt;char&gt\", \"; inputs. Specifically, because it's so common to append string instances to a StringBuilder , a spe\", \"cial code path was long ago put in place to optimize for this input and specifically for the case wh\", \"ere there's already enough room in the StringBuilder to hold the whole input, at which point an effi\", \"cient copy can be used. With a shared Append(ref char, int) helper, though, this optimization can be\", \" moved down into that helper, such that it not only helps out string but any other type that also ca\", \"lls into the same helper. The effects of this are visible in a simple microbenchmark:\\n\\n```\\nprivate S\", \"tringBuilder _sb = new StringBuilder(); [Benchmark] public void AppendSpan() { _sb.Clear(); _sb.Appe\", \"nd(\\\"this\\\".AsSpan()); _sb.Append(\\\"is\\\".AsSpan()); _sb.Append(\\\"a\\\".AsSpan()); _sb.Append(\\\"test\\\".AsSpan()\", \"); _sb.Append(\\\".\\\".AsSpan()); }\\n```\\n\\n| Method     | Runtime   | Mean     |   Ratio |\\n|------------|--\", \"---------|----------|---------|\\n| AppendSpan | .NET 6.0  | 35.98 ns |    1    |\\n| AppendSpan | .NET \", \"7.0  | 17.59 ns |    0.49 |\\n\\nOne of the great things about improving things low in the stack is they\", \" have a multiplicative effect; they not only help improve the performance of user code that directly\", \" relies on the improved functionality, they can also help improve the performance of other code in t\", \"he core libraries, which then further helps dependent apps and services. You can see this, for examp\", \"le, with DateTimeOffset.ToString , which depends on StringBuilder :\\n\\n```\\nprivate DateTimeOffset _dto\", \" = DateTimeOffset.UtcNow; [Benchmark] public string DateTimeOffsetToString() => _dto.ToString();\\n```\", \"\\n\\n| Method                 | Runtime   | Mean     |   Ratio |\\n|------------------------|-----------|\", \"----------|---------|\\n| DateTimeOffsetToString | .NET 6.0  | 340.4 ns |    1    |\\n| DateTimeOffsetTo\", \"String | .NET 7.0  | 289.4 ns |    0.85 |\\n\\nStringBuilder itself was then further updated by dotnet/r\", \"untime#64922 from [@teotsirpanis](https://github.com/teo-tsirpanis), which improves the Insert metho\", \"ds. It used to be that the Append(primitive) methods on StringBuilder (e.g. Append(int) ) would call\", \" ToString on the value and then append the resulting string. With the advent of ISpanFormattable , a\", \"s a fast-path those methods now try to format the value directly into the StringBuilder 's internal \", \"buffer, and only if there's not enough room remaining do they then take the old path as a fallback. \", \"Insert wasn't improved in this way at the time, because it can't just format into the space at the e\", \"nd of the builder; the insert location could be anywhere in the builder. This PR addresses that by f\", \"ormatting into some temporary stack space, and then delegating to the existing internal ref-based he\", \"lper from the\\n\\npreviously discussed PR to insert the resulting characters at the right location (it \", \"also falls back to ToString when there's not enough stack space for the ISpanFormattable.TryFormat ,\", \" but that only happens in incredibly corner cases, like a floating-point value that formats to hundr\", \"eds of digits).\\n\\n```\\nprivate StringBuilder _sb = new StringBuilder(); [Benchmark] public void Insert\", \"() { _sb.Clear(); _sb.Insert(0, 12345); }\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Allocat\", \"ed   |   Alloc Ratio |\\n|----------|-----------|----------|---------|-------------|---------------|\\n|\", \" Insert   | .NET 6.0  | 30.02 ns |    1    | 32 B        |             1 |\\n| Insert   | .NET 7.0  | \", \"25.53 ns |    0.85 | -           |             0 |\\n\\nOther minor improvements to StringBuilder have a\", \"lso been made, like dotnet/runtime#60406 which removed a small int[] allocation from the Replace met\", \"hod. Even with all these improvements, though, the fastest use of StringBuilder is no use; dotnet/ru\", \"ntime#68768 removed a bunch of uses of StringBuilder that would have been better served with other s\", \"tring -creation mechanisms. For example, the legacy DataView type had some code that created a sorti\", \"ng specification as a string:\\n\\n```\\nprivate static string CreateSortString(PropertyDescriptor propert\", \"y, ListSortDirection direction) { var resultString = new StringBuilder(); resultString.Append('['); \", \"resultString.Append(property.Name); resultString.Append(']'); if (ListSortDirection.Descending == di\", \"rection) { resultString.Append(\\\" DESC\\\"); } return resultString.ToString(); }\\n```\\n\\nWe don't actually \", \"need the StringBuilder here, as in the worstcase we're just concaten ating three strings, and string\", \".Concat has a dedicated overload for that exact operation that has the best possible implementation \", \"for that operation (and if we ever found a better way, that method would be improved according). So \", \"we can just use that:\\n\\n```\\nprivate static string CreateSortString(PropertyDescriptor property, ListS\", \"ortDirection direction) => direction == ListSortDirection.Descending ? $\\\"[{property.Name}] DESC\\\" : $\", \"\\\"[{property.Name}]\\\";\\n```\\n\\nNote that I've expressed that concatenation via an interpolated string, bu\", \"t the C# compiler will 'lower' this interpolated string to a call to string.Concat , so the IL for t\", \"his is indistinguishable from if I'd instead written:\\n\\n```\\nprivate static string CreateSortString(Pr\", \"opertyDescriptor property, ListSortDirection direction) =>\\n```\\n\\n```\\ndirection == ListSortDirection.D\", \"escending ? string.Concat(\\\"[\\\", property.Name, \\\"] DESC\\\") : string.Concat(\\\"[\\\", property.Name, \\\"]\\\");\\n``\", \"`\\n\\nAs an aside, the expanded string.Concat version highlights that this method could have been writt\", \"en to result in a bit less IL if it were instead written as:\\n\\n```\\nprivate static string CreateSortSt\", \"ring(PropertyDescriptor property, ListSortDirection direction) => string.Concat(\\\"[\\\", property.Name, \", \"direction == ListSortDirection.Descending ? \\\"] DESC\\\" : \\\"]\\\");\\n```\\n\\nbut this doesn't meaningfully affe\", \"ct performance and here clarity and maintainability was more important than shaving off a few bytes.\", \"\\n\\n```\\n[Benchmark(Baseline = true )] [Arguments(\\\"SomeProperty\\\", ListSortDirection.Descending)] public\", \" string WithStringBuilder(string name, ListSortDirection direction) { var resultString = new StringB\", \"uilder(); resultString.Append('['); resultString.Append(name); resultString.Append(']'); if (ListSor\", \"tDirection.Descending == direction) { resultString.Append(\\\" DESC\\\"); } return resultString.ToString()\", \"; } [Benchmark] [Arguments(\\\"SomeProperty\\\", ListSortDirection.Descending)] public string WithConcat(s\", \"tring name, ListSortDirection direction) => direction == ListSortDirection.Descending? $\\\"[{name}] DE\", \"SC\\\" : $\\\"[{name}]\\\";\\n```\\n\\n| Method            | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|--\", \"-----------------|----------|---------|-------------|---------------|\\n| WithStringBuilder | 68.34 ns\", \" |    1    | 272 B       |          1    |\\n| WithConcat        | 20.78 ns |    0.31 | 64 B        | \", \"         0.24 |\\n\\nThere are also places where StringBuilder was still applicable, but it was being us\", \"ed on hot-enough paths that previous releases of .NET saw the StringBuilder instance being cached. S\", \"everal of the core libraries, including System.Private.CoreLib, have an internal StringBuilderCache \", \"type which caches a StringBuilder instance in a [ThreadStatic] , meaning every thread could end up h\", \"aving such an instance. There are several issues with this, including that the buffers employed by S\", \"tringBuilder aren't usable for anything else while the StringBuilder isn't in use, and because of th\", \"at, StringBuilderCache places a limit on the capacity of the StringBuilder instances that can be cac\", \"hed; attempts to cache ones longer than that result in them being thrown away. It'd be better instea\", \"d to use cached arrays that aren't length -limited and that everyone has access to for sharing. Many\", \" of the core .NET libraries have an internal ValueStringBuilder type for this purpose, a ref struct \", \"-based type that can use stackalloc 'd memory to start and then if necessary grow into ArrayPool&lt;\", \"char&gt; arrays. And with dotnet/runtime#64522 and dotnet/runtime#69683, many of the\\n\\nremaining uses\", \" of StringBuilderCache have been replaced. I'm hopeful we can entirely remove StringBuilderCache in \", \"the future.\\n\\nIn the same vein of not doing unnecessary work, there's a fairly common pattern that sh\", \"ows up with methods like string.Substring and span.Slice :\\n\\n```\\nspan = span.Slice(offset, str.Length\", \" - offset);\\n```\\n\\nThe relevant thing to recognize here is these methods have overloads that take just\", \" the starting offset. Since the length being specified is the remainder after the specified offset, \", \"the call could instead be simplified to:\\n\\n```\\nspan = span.Slice(offset);\\n```\\n\\nwhich is not only more\", \" readable and maintainable, it has some small efficiency benefits, e.g. on 64-bit the Slice(int, int\", \") constructor has an extra addition over Slice(int) , and for 32-bit the Slice(int, int) constructor\", \" incurs an additional comparison and branch. It's thus beneficial for both code maintenance and for \", \"performance to simplify these calls, which dotnet/runtime#68937 does for all found occurrences of th\", \"at pattern. This is then made more impactful by dotnet/runtime#73882, which streamlines string.Subst\", \"ring to remove unnecessary overheads, e.g. it condenses four argument validation checks down to a si\", \"ngle fast-path comparison (in 64-bit processes).\\n\\nOk, enough about string . What about spans? One of\", \" the coolest features in C# 11 is the new support for ref fields. What is a ref field? You're famili\", \"ar with ref s in C# in general, and we've already discussed how they're essentially managed pointers\", \", i.e. pointers that the runtime can update at any time due to the object it references getting move\", \"d on the heap. These references can point to the beginning of an object, or they can point somewhere\", \" inside the object, in which case they're referred to as 'interior pointers.' ref has existed in C# \", \"since 1.0, but at that time it was primarily about passing by reference to method calls, e.g.\\n\\n```\\nc\", \"lass Data { public int Value; } ... void Add( ref int i) { i++; } ... var d = new Data { Value = 42 \", \"}; Add( ref d.Value); Debug.Assert(d.Value == 43);\\n```\\n\\nLater versions of C# added the ability to ha\", \"ve local ref s, e.g.\\n\\n```\\nvoid Add( ref int i) { ref j = ref i; j++; }\\n```\\n\\nand even to have ref ret\", \"urns, e.g.\\n\\n```\\nref int Add( ref int i) { ref j = ref i; j++; return ref j; }\\n```\\n\\nThese facilities \", \"are more advanc ed, but they're used liberally throughout higher -performance code bases, and many o\", \"f the optimizations in .NET in recent years are possible in large part due to these ref -related cap\", \"abilities.\\n\\nSpan&lt;T&gt; and ReadOnlySpan&lt;T&gt; themselves are heavily-based on ref s. For examp\", \"le, the indexer on many older collection types is implemented as a get/set property, e.g.\\n\\n```\\npriva\", \"te T[] _items; ... public T this [int i] { get => _items[i]; set => _items[i] = value; }\\n```\\n\\nBut no\", \"t span. Span&lt;T&gt; 's indexer looks more like this:\\n\\n```\\npublic ref T this [int index] { get { if\", \" ((uint)index >= (uint)_length) ThrowHelper.ThrowIndexOutOfRangeException(); return ref Unsafe.Add( \", \"ref _reference, index); } }\\n```\\n\\nNote there's only a getter and no setter; that's because it returns\", \" a ref T to the actual storage location. It's a writable ref, so you can assign to it, e.g. you can \", \"write:\\n\\n```\\nspan[i] = value;\\n```\\n\\nbut rather than that being equivalent to calling some setter:\\n\\n```\", \"\\nspan.set_Item(i, value);\\n```\\n\\nit's actually equivalent to using the getter to retrieve the ref and \", \"then writing a value through that ref , e.g.\\n\\n```\\nref T item = ref span.get_Item(i); item = value;\\n`\", \"``\\n\\nThat's all well and good, but what's that \\\\_reference in the getter definition? Well, Span&lt;T&\", \"gt; is really just a tuple of two fields: a reference (to the start of the memory being referred to)\", \" and a length (how many elements from that reference are included in the span). In the past, the run\", \"time had to hack this with an internal type ( ByReference&lt;T&gt; ) specially recognized by the run\", \"time to be a reference. But as of C# 11 and .NET 7, ref structs can now contain ref fields, which me\", \"ans Span&lt;T&gt; today is literally defined as follows:\\n\\n```\\npublic readonly ref struct Span<T> { i\", \"nternal readonly ref T _reference; private readonly int _length; ... }\\n```\\n\\nThe rollout of ref field\", \"s throughout dotnet/runtime was done in dotnet/runtime#71498, following the C# language gaining this\", \" support primarily in dotnet/roslyn#62155, which itself was the culmination of many PRs first into a\", \" feature branch. ref fields alone doesn 't itself automatically improve performance, but it does sim\", \"plify code significantly, and it allows for both new custom code that uses ref fields as well as new\", \" APIs that take advantage of them, both of which can help with performance (and specifically perform\", \"ance without sacrificing potential safety). One such example of a new API is new constructors on Rea\", \"dOnlySpan&lt;T&gt; and Span&lt;T&gt; :\\n\\n```\\npublic Span( ref T reference); public ReadOnlySpan( in T\", \" reference);\\n```\\n\\nadded in dotnet/runtime#67447 (and then made public and used more broadly in dotne\", \"t/runtime#71589). This may beg the question, why does ref field support enable two new constructors \", \"that take ref s, considering spans already were able to store a ref ? After all, the MemoryMarshal.C\", \"reateSpan(ref T reference, int length) and corresponding CreateReadOnlySpan methods have existed for\", \" as long as spans have, and these new constructors are equivalent to calling those methods with a le\", \"ngth of 1. The answer is: safety.\\n\\nImagine if you could willynilly call this constructor. You'd be a\", \"ble to write code like this:\\n\\n```\\npublic Span<int> RuhRoh() { int i = 42; return new Span<int>( ref \", \"i); }\\n```\\n\\nAt this point the caller of this method is handed a span that refers to garbage; that's b\", \"ad in code that's intended to be safe. You can already accomplish the same thing by using pointers:\\n\", \"\\n```\\npublic Span<int> RuhRoh() { unsafe { int i = 42; return new Span<int>(&i, 1); } }\\n```\\n\\nbut at t\", \"hat point you've taken on the risk of using unsafe code and pointers and any resulting problems are \", \"on you. With C# 11, if you now try to write the above code using the ref -based constructor, you'll \", \"be greeted with an error like this:\\n\\n```\\nerror CS8347: Cannot use a result of 'Span<int>.Span(ref in\", \"t)' in this context because it may expose variables referenced by parameter 'reference' outside of t\", \"heir declaration scope\\n```\\n\\nIn other words, the compiler now understands that Span&lt;int&gt; as a r\", \"ef struct could be storing the passed in ref , and if it does store it (which Span&lt;T&gt; does), t\", \"his is akin to passing a ref to a local out\\n\\nof the method, which is bad. Hence how this relates to \", \"ref fields: because ref fields are now a thing, the compiler's rules for safe -handling of ref s hav\", \"e been updated, which in turn enables us to expose the aforementioned constructors on {ReadOnly}Span\", \"&lt;T&gt; .\\n\\nAs is often the case, addressing one issue kicks the can down the road a bit and expose\", \"s another. The compiler now believes that a ref passed to a method on a ref struct could enable that\", \" ref struct instance to store the ref (note that this was already the case with ref struct s passed \", \"to methods on ref structs ), but what if we don't want that? What if we want to be able to say 'this\", \" ref is not storable and should not escape the calling scope'? From a caller's perspective, we want \", \"the compiler to allow passing in such ref s without it complaining about potential extension of life\", \"time, and from a callee's perspective, we want the compiler to prevent the method from doing what it\", \"'s not supposed to do. Enter scoped . The new C# keyword does exactly what we just wished for: put i\", \"t on a ref or ref struct parameter, and the compiler both will guarantee (short of using unsafe code\", \") that the method can't stash away the argument and will then enable the caller to write code that r\", \"elies on that guarantee. For example, consider this program:\\n\\n```\\nvar writer = new SpanWriter( stack\", \"alloc char[128]); Append( ref writer, 123); writer.Write(\\\".\\\"); Append( ref writer, 45); Console.Writ\", \"eLine(writer.AsSpan().ToString()); static void Append( ref SpanWriter builder, byte value) { Span<ch\", \"ar> tmp = stackalloc char[3]; value.TryFormat(tmp, out int charsWritten); builder.Write(tmp.Slice(0,\", \" charsWritten)); } ref struct SpanWriter { private readonly Span<char> _chars; private int _length; \", \"public SpanWriter(Span<char> destination) => _chars = destination; public Span<char> AsSpan() => _ch\", \"ars.Slice(0, _length); public void Write(ReadOnlySpan<char> value) { if (_length > _chars.Length - v\", \"alue.Length) { throw new InvalidOperationException(\\\"Not enough remaining space\\\"); } value.CopyTo(_ch\", \"ars.Slice(_length)); _length += value.Length; } }\\n```\\n\\nWe have a ref struct SpanWriter that takes a \", \"Span&lt;char&gt; to its constructor and allows for writing to it by copying in additional content an\", \"d then updating the stored length. The Write method accepts a ReadOnlySpan&lt;char&gt; . And we then\", \" have a helper Append method which is formatting a byte into some stackalloc 'd temporary space and \", \"passing the resulting formatted char s in to Write . Straightforward. Except, this doesn't compile:\\n\", \"\\nerror CS8350: This combination of arguments to 'SpanWriter.Write(ReadOnlySpan&lt;char&gt;)' is\\n\\n```\", \"\\ndisallowed because it may expose variables referenced by parameter 'value' outside of their declara\", \"tion scope\\n```\\n\\nWhat do we do? The Write method doesn't actually store the value parameter and won't\", \" ever need to, so we can change the signature of the method to annotate it as scoped :\\n\\n```\\npublic v\", \"oid Write(scoped ReadOnlySpan<char> value)\\n```\\n\\nIf Write were then to try to store value , the compi\", \"ler would balk:\\n\\n```\\nerror CS8352: Cannot use variable 'ReadOnlySpan<char>' in this context because \", \"it may expose referenced variables outside of their declaration scope\\n```\\n\\nBut as it's not trying to\", \" do so, everything now compiles successfully. You can see examples of how this is utilized in the af\", \"orementioned dotnet/runtime#71589.\\n\\nThere's also the other direction: there are some things that are\", \" implicitly scoped , like the this reference on a struct. Consider this code:\\n\\n```\\npublic struct Sin\", \"gleItemList { private int _value; public ref int this [int i] { get { if (i != 0) throw new IndexOut\", \"OfRangeException(); return ref _value; } } }\\n```\\n\\nThis produces a compiler error:\\n\\n```\\nerror CS8170:\", \" Struct members cannot return 'this' or other instance members by reference\\n```\\n\\nEffectively, that's\", \" because this is implicitly scoped (even though that keyword wasn't previously available). What if w\", \"e want to enable such an item to be returned? Enter [UnscopedRef] . This is rare enough in n eed tha\", \"t it doesn't get its own C# language keyword, but the C# compiler does recognize the new [UnscopedRe\", \"f] attribute. It can be put onto relevant parameters but also onto methods and properties, in which \", \"case it applies to the this reference for that member. As such, we can modify our previous code exam\", \"ple to be:\\n\\n```\\n[UnscopedRef] public ref int this [int i]\\n```\\n\\nand now the code will compile success\", \"fully. Of course, this also places demands on callers of this method. For a call site, the compiler \", \"sees the [UnscopedRef] on the member being invoked, and then knows that the returned ref might refer\", \"ence something from that struct, and thus assigns to the returned ref the same lifetime as that stru\", \"ct. So, if that struct were a local living on the stack, the ref would also be limited to that same \", \"method.\\n\\nAnother impactful span-related change comes in dotnet/runtime#70095 from [@teotsirpanis](ht\", \"tps://github.com/teo-tsirpanis). System.HashCode 's goal is to pr ovide a fast, easy-to-use implemen\", \"tation for producing high-quality hash codes. In its current incarnation, it incorporates a random p\", \"rocess-wide seed and is an implementation of the xxHash32 non-cryptographic hash algorithm. In a pre\", \"vious release, HashCode saw the addition of an AddBytes methods, which accepts a ReadOnlySpan&lt;byt\", \"e&gt; and is useful for incorporating sequences of data that should be part of a type's hash code, e\", \".g. BigInteger.GetHashCode includes all the data that makes up the BigInteger . The xxHash32 algorit\", \"hm works by accumulating 4 32-bit unsigned integers and then combining them together into the hash c\", \"ode; thus if you call HashCode.Add(int) , the first three times you call it you're just storing the \", \"values separately into the instance, and then the fourth time you call it all of those values are co\", \"mbined into the hash code (and there's a separate process that incorporates any remaining values if \", \"the number of 32-bit va lues added wasn't an exact multiple of 4). Thus, previously AddBytes was sim\", \"ply implemented to repeatedly read the next 4 bytes from the input span and call Add(int) with those\", \" bytes as an integer. But those Add calls have overhead. Instead, this PR skips the Add calls and di\", \"rectly handles the accumulation and combining of the 16 bytes. Interestingly, it still has to deal w\", \"ith the possibility that previous calls to Add may have left some state queued, which means (with th\", \"e current implementation at least), if there are multiple pieces of state to include in the hash cod\", \"e, say a ReadOnlySpan&lt;byte&gt; and an additional int , it's more efficient to add the span first \", \"and then the int rather than the other way around. So for example when dotnet/runtime#71274 from [@h\", \"uoyaoyuan](https://github.com/huoyaoyuan) changed BigInteger.GetHashCode to use HashCode.AddBytes , \", \"it coded the method to first call AddBytes with the BigInteger 's \\\\_bits and then call Add with the \", \"\\\\_sign .\\n\\n```\\nprivate byte[] _data = Enumerable.Range(0, 256).Select(i => (byte)i).ToArray(); [Bench\", \"mark] public int AddBytes() { HashCode hc = default ; hc.AddBytes(_data); return hc.ToHashCode(); }\\n\", \"```\\n\\n| Method   | Runtime   | Mean      |   Ratio |\\n|----------|-----------|-----------|---------|\\n|\", \" AddBytes | .NET 6.0  | 159.11 ns |    1    |\\n| AddBytes | .NET 7.0  | 42.11 ns  |    0.26 |\\n\\nAnothe\", \"r span-related change, dotnet/runtime#72727 refactored a bunch of code paths to eliminate some cache\", \"d arrays. Why avoid cached arrays? After all, isn't it desirable to cache an array once and reuse it\", \" over and over again? It is, if that's the best option, but sometimes there are better options. For \", \"example, one of the changes took code like:\\n\\n```\\nprivate static readonly char[] s_pathDelims = { ':'\", \", '\\\\\\\\', '/', '?', '#' }; ... int index = value.IndexOfAny(s_pathDelims);\\n```\\n\\nand replaced it with c\", \"ode like:\\n\\n```\\nint index = value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\n```\\n\\nThis h as a variety of benefits\", \". There's the usability benefit of keeping the tokens being searched close to the use site, and the \", \"usability benefit of the list being immutable such that some code somewhere won't accidentally repla\", \"ce a value in the array. But there are also performance benefits. We don't need an extra field to st\", \"ore the array. We don't need to allocate the array as part of this type's static constructor. And lo\", \"ading/using the string is slightly faster.\\n\\n```\\nprivate static readonly char[] s_pathDelims = { ':',\", \" '\\\\\\\\', '/', '?', '#' }; private static readonly string s_value = \\\"abcdefghijklmnopqrstuvwxyz\\\"; [Benc\", \"hmark] public int WithArray() => s_value.IndexOfAny(s_pathDelims); [Benchmark] public int WithString\", \"() => s_value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\n```\\n\\n| Method     | Mean     |   Ratio |\\n|------------|\", \"----------|---------|\\n| WithArray  | 8.601 ns |    1    |\\n| WithString | 6.949 ns |    0.81 |\\n\\nAnoth\", \"er example from that PR took code along the lines of:\\n\\n```\\nprivate static readonly char[] s_whitespa\", \"ces = new char[] { ' ', '\\\\t', '\\\\n', '\\\\r' }; ... switch (attr.Value.Trim(s_whitespaces)) { case \\\"pres\", \"erve\\\": return Preserve; case \\\"default\\\": return Default; }\\n```\\n\\nand replaced it with code like:\\n\\n```\\n\", \"switch (attr.Value.AsSpan().Trim(\\\" \\\\t\\\\n\\\\r\\\")) { case \\\"preserve\\\": return Preserve; case \\\"default\\\": ret\", \"urn Default; }\\n```\\n\\nIn this case, not only have we avoided the char[] , but if the text did require \", \"any trimming of whitespaces, the new version (which trims a span instead of the original string) wil\", \"l save an allocation for the trimmed string. This is taking advantage of the new C# 11 feature that \", \"supports switching on ReadOnlySpan&lt;char&gt; s just as you can switch on string s, added in dotnet\", \"/roslyn#44388 from [@YairHalberstadt](https://github.com/YairHalberstadt). dotnet/runtime#68831 also\", \" took advantage of this in several additional places.\\n\\nOf course, in some cases the arrays are entir\", \"ely unnecessary. In that same PR, there were several cases like this:\\n\\n```\\nprivate static readonly c\", \"har[] WhiteSpaceChecks = new char[] { ' ', '\\\\u00A0' }; ... int wsIndex = target.IndexOfAny(WhiteSpac\", \"eChecks, targetPosition); if (wsIndex < 0) { return false ; }\\n```\\n\\nBy switching to use spans, again,\", \" we can instead write it like this:\\n\\n```\\nint wsIndex = target.AsSpan(targetPosition).IndexOfAny(' ',\", \" '\\\\u00A0'); if (wsIndex < 0) { return false ; } wsIndex += targetPosition;\\n```\\n\\nMemoryExtensions.Ind\", \"exOfAny has a dedicated overload for two and three arguments, at which point we don't need the array\", \" at all (these overloads also happen to be faster; when passing an array of two chars, the implement\", \"ation would extract the two chars from the array and pass them off to the same two-argument implemen\", \"tation). Multiple other PRs similarly removed array allocations. dotnet/runtime#60409 removed a sing\", \"le-char array that was cached to be able to pass it to string.Split and replaced it with usage of th\", \"e Split overload that directly accepts a single char .\\n\\nFinally, dotnet/runtime#59670 from [@NewellC\", \"lark](https://github.com/NewellClark) got rid of even more arrays. We saw earlier how the C# compile\", \"r special-cases byte[] s constructed with a constant length and constant elements and that's immedia\", \"tely cast to a ReadOnlySpan&lt;byte&gt; . Thus, it can be beneficial any time there's such a byte[] \", \"being cached to instead expose it as a ReadOnlySpan&lt;byte&gt; . As I discussed in the .NET 6 post,\", \" this avoids even the onetime array allocation you'd get for a cached array, results in much more ef\", \"ficient access, and supplies to the JIT compiler more information that enables it to more heavily op\", \"timize\\u2026 goodness all around. This PR removed even more arrays in this manner, as did dotnet/runtime#\", \"60411, dotnet/runtime#72743, dotnet/runtime#73115 from [@vcsjones](https://github.com/vcsjones), and\", \" dotnet/runtime#70665.\\n\\n<!-- image -->\\n\\nBack in May, I shared a fairly detailed post about the impro\", \"vements coming to Regular Expressions in .NET 7. As a recap, prior to .NET 5, Regex 's implementatio\", \"n had largely been untouched for quite some time. In .NET 5, we brought it back up to be on par with\", \" or better than multiple other industry implementations from a performance perspective. .NET 7 takes\", \" some significant leaps forward from that. If you haven't read the post yet, please go ahead and do \", \"so now; I'll wait\\u2026\\n\\nWelcome back. With that context, I'll avoid duplicating content here, and instea\", \"d focus on how exactly these improvements came about and the PRs that did so.\\n\\n## RegexOptions.NonBa\", \"cktracking\\n\\nLet's start with one of the larger new features in Regex , the new RegexOptions.NonBackt\", \"racking implementation. As discussed in the previous post, RegexOptions.NonBacktracking switches the\", \" processing of Regex over to using a new engine based in finite automata. It has two primary modes o\", \"f execution, one that relies on DFAs (deterministic finite automata) and one that relies on NFAs (no\", \"ndeterministic finite automata). Both implementations provide a very valuable guarantee: processing \", \"time is linear in the length of the input. Whereas a backtracking engine (which is what Regex uses i\", \"f NonBacktracking isn't specified) can hit a situation known as 'catastrophic backtracking,' where p\", \"roblematic expressions combined with problematic input can result in exponential processing in the l\", \"ength of the input, NonBacktracking guarantees it'll only ever do an ammortized -constant amount of \", \"work per character in the input. In the case of a DFA, that constant is very small. With an NFA, tha\", \"t constant can be much larger, based on the complexity of the pattern, but for any given pattern the\", \" work is still linear in the length of the input.\\n\\nA significant number of years of development went\", \" into the NonBacktracking implementation, which was initially added into dotnet/runtime in dotnet/ru\", \"ntime#60607. However, the original research and implementation for it actually came from Microsoft R\", \"esearch (MSR), and was available as an experimental package in the form of the Symbolic Regex Matche\", \"r (SRM) library published by MSR. You can still see vestiges of this in the current code now in .NET\", \" 7, but it's evolved significantly, in tight collaboration between developers on the .NET team and t\", \"he researchers at MSR (prior to being integrated in dotnet/runtime, it was incubated for over a year\", \" in dotnet/runtimelab, where the original SRM code was brought in via dotnet/runtimelab#588 from [@v\", \"eanes](https://github.com/veanes)).\\n\\nThis i mplementation is based on the notion of regular expressi\", \"on derivatives, a concept that's been around for decades (the term was originally coined in a paper \", \"by Janusz Brzozowski in the 1960s) and which has been significantly advanced for this implementation\", \". Regex derivatives form the basis for how the automata (think 'graph') used to process input are co\", \"nstructed. The idea at its core is fairly simple: take a regex and process a single character\\u2026 what \", \"is the new regex you get to describe what remains after processing that one character? That's the de\", \"rivative. For example, given the regex \\\\w{3}\\n\\n11\\n\\nto match three word characters, if you apply this \", \"to the next input character 'a', well, that will strip off the first \\\\w , leaving us with the deriva\", \"tive \\\\w{2} . Simple, right? How about something more complicated, like the expression .*(the|he) . W\", \"hat happens if the next character is a t ? Well, it's possible that t could be consumed by the .* at\", \" the beginning of the pattern, in which case the remaining regex would be exactly the same as the st\", \"arting one ( .*(the|he) ), since after matching t we could still match exactly the same input as wit\", \"hout the t . But, the t could have also been part of matching the , and applied to the , we'd strip \", \"off the t and be left with he , so now our derivative is .*(the|he)|he . Then what about the he in t\", \"he original alternation? t doesn't match h , so the derivative would be nothing, which we'll express\", \" here as an empty character class, giving us .*(the|he)|he|[] . Of course, as part of an alternati o\", \"n, that 'nothing' at the end is a nop, and so we can simplify the whole derivative to just .*(the|he\", \")|he \\u2026 done. That was all when applying the original pattern against a next t . What if it was again\", \"st an h instead? Following the same logic as for the t , this time we end up with .*(the|he)|e . And\", \" so on. What if we instead start with the h derivative and the next character is an e ? Then we're t\", \"aking the pattern .*(the|he)|e and applying it to e . Against the left side of the alternation, it c\", \"an be consumed by the .* (but doesn't match either t or h ), and so we just end up with that same su\", \"bexpression. But against the right side of the alternation, e matches e , leaving us with the empty \", \"string () : .*(the|he)|() . At the point where a pattern is 'nullable' (it ca n match the empty stri\", \"ng), that can be considered a match. We can visualize this whole thing as a graph, with transitions \", \"for every input character to the derivative that comes from applying it.\\n\\ne\\n\\n[^eht]\\n\\n<!-- image -->\\n\", \"\\nLooks an awful lot like a DFA, doesn't it? It should. And that's exactly how NonBacktracking constr\", \"ucts the DFAs it uses to process input. For every regex construct (concatenations, alternations, loo\", \"ps, etc.) the engine knows how to derive the next regex based on the character being evaluated. This\", \" application is done lazily, so we have an initial starting state (the original pattern), and then w\", \"hen we evaluate the next character in the input, it looks to see whether there's already a derivativ\", \"e available f or that transition: if there is, it follows it, and if there isn't, it dynamically/laz\", \"ily derives the next node in the graph. At its core, that's how it works.\\n\\nOf course, the devil is i\", \"n the details and there's a ton of complication and engineering smarts that go into making the engin\", \"e efficient. One such example is a tradeoff between memory consumption and throughput. Given the abi\", \"lity to have any char as input, you could have effectively ~65K transitions out of every node (e.g. \", \"every node could need a ~65K element table); that would significantly increase memory consumption. H\", \"owever, if you actually had that many transitions, it's very likely a significant majority of them w\", \"ould point to the same target node. Thus, NonBacktracking maintains its own groupin gs of characters\", \" into what it calls 'minterms.' If two characters will have exactly the same transition, they're par\", \"t of the same minterm. The transitions are then constructed in terms of minterms, with at most one t\", \"ransition per minterm out of a given node. When the next input character is read, it maps that to a \", \"minterm ID, and then finds the appropriate transition for that ID; one additional level of indirecti\", \"on in order to save a potentially huge amount of memory. That mapping is handled via an array bitmap\", \" for ASCII and an efficient data structure known as a Binary Decision Diagram (BDD) for everything a\", \"bove 0x7F.\\n\\nAs noted, the non-backtracking engine is linear in the length of the input. But that doe\", \"sn't mean it always looks at each input character exactly once. If you call Regex.IsMatch , it does;\", \" after all, IsMatch only needs to determine whether there is a match and doesn't need to compute any\", \" additional information, such as where the match actual starts or ends, any information on captures,\", \" etc. Thus, the engine can simply employ its automata to walk along the input, transitioning from no\", \"de to node in the graph until it comes to a final state or runs out of input. Other operations, howe\", \"ver, do require it to gather more information. Regex.Match needs to compute everything, and that can\", \" actually entail multiple walks over the input. In the initial implementation, the equivalent of Mat\", \"ch would always take three passes: match forwards to find the end of a match, then match a reversed-\", \"copy of the pattern in reverse from that ending location in order to find where the match actually s\", \"tarts, and then once more walk forwards from that known starting position to find the actual ending \", \"position. However, with dotnet/runtime#68199 from [@olsaarik](https://github.com/olsaarik), unless c\", \"aptures are required, it can now be done in only two passes: once forward to find the guaranteed end\", \"ing location of the match, and then once in reverse to find its starting location. And dotnet/runtim\", \"e#65129 from [@olsaarik](https://github.com/olsaarik) added captures support, which the original imp\", \"lementation also didn't have. This captures support adds back a third pass, such that once the bound\", \"s of the match are known, the engine runs the forward pass one more time, but this time with an NFA-\", \"based 'simulation' that is able to record 'capture effects' on transitions. All of this enables the \", \"non -backtracking implementation to have the exact same semantics as the backtracking engines, alway\", \"s producing the same matches in the same order with the same capture information. The only differenc\", \"e in this regard is, whereas with the backtracking engines capture groups inside of loops will store\", \" all values captured in every iteration of the loop, only the last iteration is stored with the nonb\", \"acktracking implementation. On top of that, there are a few constructs the non-backtracking\\n\\nimpleme\", \"ntation simply doesn't support, such that attempting to use any of those will fail when trying to co\", \"nstruct the Regex , e.g. backreferences and lookarounds.\\n\\nEven after its progress as a standalone li\", \"brary from MSR, more than 100 PRs went into making RegexOptions.NonBacktracking what it is now in .N\", \"ET 7, including optimizations like dotnet/runtime#70217 from [@olsaarik](https://github.com/olsaarik\", \") that tries to streamline the tight inner matching loop at the heart of the DFA (e.g. read the next\", \" input character, find the appropriate transition to take, move to the next node, and check informat\", \"ion about the node like whether it's a final state) and optimizations like dotnet/runtime#65637 from\", \" [@veanes](https://github.com/veanes) that optimized the NFA mode to avoid superfluous allocations, \", \"caching and reusing list and set objects to make the handling of the lists of states ammortized allo\", \"cation-free.\\n\\nThere's one more set of PRs of performance interest for NonBacktracking . The Regex im\", \"plementation for taking patterns and turning them into something processable, regardless of which of\", \" the multiple engines is being used, is essentially a compiler, and as with many compilers, it natur\", \"ally lends itself to recursive algorithms. In the case of Regex , those algorithms involve walking a\", \"round trees of regular expression constructs. Recursion ends up being a very handy way of expressing\", \" these algorithms, but recursion also suffers from the possibility of stack overflow; essentially it\", \"'s using stack space as scratch space, and if it ends up using too much, things go badly. One common\", \" approach to dealing with this is turning the recursive algorithm into an iterative one, which typic\", \"ally involves using an explicit stack of state rather than the implicit one. The nice thing about th\", \"is is the amount of state you can store is limited only by how much memory you have , as opposed to \", \"being limited by your thread's stack space. The downsides, however, are that it's typically much les\", \"s natural to write the algorithms in this manner, and it typically requires allocating heap space fo\", \"r the stack, which then leads to additional complications if you want to avoid that allocation, such\", \" as various kinds of pooling. dotnet/runtime#60385 introduces a different approach for Regex , which\", \" is then used by dotnet/runtime#60786 from [@olsaarik](https://github.com/olsaarik) specifically in \", \"the NonBacktracking implementation. It still uses recursion, and thus benefits from the expressivene\", \"ss of the recursive algorithm as well as being able to use stack space and thus avoid additional all\", \"ocation in the most common cases, but then to avoid stack overflows, it issues explicit checks to en\", \"sure we're not too deep on the stack (.NET has long provided the helpers\\n\\nRuntimeHelpers.EnsureSuffi\", \"cientExecutionStack and\\n\\nRuntimeHelpers.TryEnsureSufficientExecutionStack for this purpose). If it d\", \"etects it's too deep on the stack, it forks off continued execution into another thread. Hitting thi\", \"s condition is expensive, but it's very rarely if ever actually hit in practice (e.g. the only time \", \"it's hit in our vast functional tests are in the tests explicitly written to stress it), it keeps th\", \"e code simple, and it keeps the typical cases fast. A similar approach is used in other areas of dot\", \"net/runtime, such as in System.Linq.Expressions.\\n\\nAs was mentioned in my previous blog post about re\", \"gular expressions, both the backtracking implementations and the non-backtracking implementation hav\", \"e their place. The main benefit of the non-backtracking implementation is predictability: because of\", \" the linear processing guarantee, once you've constructed the regex, you don't need to worry about m\", \"alicious inputs causing worst -case beh avior in the processing of your potentially susceptible expr\", \"essions. This doesn't mean RegexOptions.NonBacktracking is always the fastest; in fact, it's frequen\", \"tly not. In exchange for reduced best-case performance, it provides the best worst-case performance,\", \" and for some kinds of applications, that's a really worthwhile and valuable tradeoff.\\n\\n## New APIs\\n\", \"\\nRegex gets several new methods in .NET 7, all of which enable improved performance. The simplicity \", \"of the new APIs likely also misrepresents how much work was necessary to enable them, in particular \", \"because the new APIs all support ReadOnlySpan&lt;char&gt; inputs into the regex engines.\\n\\ndotnet/run\", \"time#65473 brings Regex into the span-based era of .NET, overcoming a significant limitation in Rege\", \"x since spans were introduced back in .NET Core 2.1. Regex has historically been based on processing\", \" System.String inputs, and that fact pervades the Regex design and implementation, including the API\", \"s exposed for the extensibility model Regex.CompileToAssembly relied on in .NET Framework ( CompileT\", \"oAssembly is now obsoleted and has never been functional in .NET Core). One subtly that relies on th\", \"e nature of string as the input is how match information is returned to callers. Regex.Match returns\", \" a Match object that represents the first match in the input, and that Match object exposes a NextMa\", \"tch method that enables moving to the next match. That means the Match object needs to store a refer\", \"ence to the input, so that it can be fed back into the matching engine as part of such a NextMatch c\", \"all. If that input is a string , great, no problem. But if that input is a ReadOnlySpan&lt;char&gt; \", \", that span as a ref struct can't be stored on the class Match object, since ref structs can only li\", \"ve on the stack and not the heap. That alone would make it a challenge to support spans, but the pro\", \"blem is even more deeply rooted. All of the regex engines rely on a RegexRunner , a base class that \", \"stores on it all of the state necessary to feed into the FindFirstChar and Go methods that compose t\", \"he actual matching logic for the regular expressions (these methods contain all of the core code for\", \" performing the match, with FindFirstChar being an optimization to skip past input positions that co\", \"ul dn't possibly start a match and then Go performing the actual matching logic). If you look at the\", \" internal RegexInterpreter type, which is the engine you get when you construct a new Regex(...) wit\", \"hout the RegexOptions.Compiled or RegexOptions.NonBacktracking flags, it derives from RegexRunner . \", \"Similarly, when you use RegexOptions.Compiled , it hands off the dynamic methods it reflection emits\", \" to a type derived from RegexRunner , RegexOptions.NonBacktracking has a SymbolicRegexRunnerFactory \", \"that produces types derived from RegexRunner , and so on. Most relevant here, RegexRunner is public,\", \" because the types generated by the Regex.CompileToAssembly type (and now the regex source generator\", \") include ones derived from this RegexRunner . Those FindFirstChar and Go methods are thus abstract \", \"and protected , and parameterless, because they pick up all the state they need from protected membe\", \"rs on the base class. That includes the string input to process. So what about spans? We could of co\", \"urse have just called ToString() on an input ReadOnlySpan&lt;char&gt; . That would have been functio\", \"nally correct, but would have completely defeated the purpose of accepting spans, and worse, would h\", \"ave been so unexpected as to likely cause consuming apps to be worse performing than they would have\", \" without the APIs. Instead, we needed a new approach and new APIs.\\n\\nFirst, we made FindFirstChar and\", \" Go virtual instead of abstract. The design that splits these methods is largely antiquated, and in \", \"particular the forced separation between a stage of processing where you find the next possible loca\", \"tion of a match and then a stage where you actually perform the match at that location doesn't align\", \" well with all engines, like the one used by NonBacktracking (which initially implemented FindFirstC\", \"har as a nop and had all its logic in Go ). Then we added a new virtual Scan method which, important\", \"ly, takes a ReadOnlySpan&lt;char&gt; as a parameter; the span can't be exposed from the base RegexRu\", \"nner and must be passed in. We then implemented FindFirstChar and Go in terms of Scan , and made the\", \"m 'just work.' Then, all of the engines are implemented in terms of that\\n\\nspan; they no longer need \", \"to access the protected RegexRunner.runtext , RegexRunner.runtextbeg , and RegexRunner.runtextend me\", \"mbers tha t surface the input; they're just handed the span, already sliced to the input region, and\", \" process that. One of the neat things about this from a performance perspective is it enables the JI\", \"T to do a better job at shaving off various overheads, in particular around bounds checking. When th\", \"e logic is implemented in terms of string , in addition to the input string itself the engine is als\", \"o handed the beginning and end of the region of the input to process (since the developer could have\", \" called a method like Regex.Match(string input, int beginning, int length) in order to only process \", \"a substring). Obviously the engine matching logic is way more complicated than this, but simplifying\", \", imagine the entirety of the engine was just a loop over the input. With the input, beginning, and \", \"length, that would look like:\\n\\n```\\n[Benchmark] [Arguments(\\\"abc\\\", 0, 3)] public void Scan(string inpu\", \"t, int beginning, int length) { for (int i = beginning; i < length; i++) { Check(input[i]); } } [Met\", \"hodImpl(MethodImplOptions.AggressiveInlining)] private void Check(char c) { }\\n```\\n\\nThat will result \", \"in the JIT generating assembly code along the lines of this:\\n\\n```\\n; Program.Scan(System.String, Int3\", \"2, Int32) sub       rsp,28 cmp       r8d,r9d jge       short M00_L01 mov       eax,[rdx+8] M00_L00: \", \"cmp       r8d,eax jae       short M00_L02 inc       r8d cmp       r8d,r9d jl        short M00_L00 M0\", \"0_L01: add       rsp,28 ret M00_L02: call      CORINFO_HELP_RNGCHKFAIL int       3 ; Total bytes of \", \"code 36\\n```\\n\\nIn contrast, if we're dealing with a span, which already factors in the bounds, then we\", \" can write a more canonical loop like this:\\n\\n```\\n[Benchmark] [Arguments(\\\"abc\\\")] public void Scan(Rea\", \"dOnlySpan<char> input) { for (int i = 0; i < input.Length; i++) { Check(input[i]); } }\\n```\\n\\n```\\n[Met\", \"hodImpl(MethodImplOptions.AggressiveInlining)] private void Check(char c) { }\\n```\\n\\nAnd when it comes\", \" to compilers, something in a canonical form is really good, because the more common the shape of th\", \"e code, the more likely it is to be heavily optimized:\\n\\n```\\n; Program.Scan(System.ReadOnlySpan`1<Cha\", \"r>) mov       rax,[rdx] mov       edx,[rdx+8] xor       ecx,ecx test      edx,edx jle       short M0\", \"0_L01 M00_L00: mov       r8d,ecx movsx     r8,word ptr [rax+r8*2] inc       ecx cmp       ecx,edx jl\", \"        short M00_L00 M00_L01: ret ; Total bytes of code 27\\n```\\n\\nSo even without all the other benef\", \"its that come from operating in terms of span, we immediately get low-level code generation benefits\", \" from performing all the logic in terms of spans. While the above example was made up (obviously the\", \" matching logic does more than a simple for loop) , here's a real example. When a regex contains a \\\\\", \"b , as part of evaluating the input against that \\\\b the backtracking engines call a RegexRunner.IsBo\", \"undary helper method which checks whether the character at the current position is a word character \", \"and whether the character before it is a word character (factoring in the bounds of the input as wel\", \"l). Here's what the IsBoundary method based on string looked like (the runtext it's using is the nam\", \"e of the string field on RegexRunner that stores the input):\\n\\n```\\n[Benchmark] [Arguments(0, 0, 26)] \", \"public bool IsBoundary(int index, int startpos, int endpos) { return (index > startpos && IsBoundary\", \"WordChar(runtext[index - 1])) != (index < endpos   && IsBoundaryWordChar(runtext[index])); } [Method\", \"Impl(MethodImplOptions.NoInlining)] private bool IsBoundaryWordChar(char c) => false ;\\n```\\n\\nand here\", \"'s what the span version looks like:\\n\\n```\\n[Benchmark] [Arguments(\\\"abcdefghijklmnopqrstuvwxyz\\\", 0)] p\", \"ublic bool IsBoundary(ReadOnlySpan<char> inputSpan, int index) { int indexM1 = index - 1; return ((u\", \"int)indexM1 < (uint)inputSpan.Length && IsBoundaryWordChar(inputSpan[indexM1])) != ((uint)index < (u\", \"int)inputSpan.Length && IsBoundaryWordChar(inputSpan[index])); } [MethodImpl(MethodImplOptions.NoInl\", \"ining)] private bool IsBoundaryWordChar(char c) => false ;\\n```\\n\\n## And here's the resulting assembly\", \":\\n\\n```\\n; Program.IsBoundary(Int32, Int32, Int32) push      rdi push      rsi push      rbp push     \", \" rbx sub       rsp,28 mov       rdi,rcx mov       esi,edx mov       ebx,r9d cmp       esi,r8d jle   \", \"    short M00_L00 mov       rcx,rdi mov       rcx,[rcx+8] lea       edx,[rsi-1] cmp       edx,[rcx+8\", \"] jae       short M00_L04 mov       edx,edx movzx     edx,word ptr [rcx+rdx*2+0C] mov       rcx,rdi \", \"call      qword ptr [Program.IsBoundaryWordChar(Char)] jmp       short M00_L01 M00_L00: xor       ea\", \"x,eax M00_L01: mov       ebp,eax cmp       esi,ebx jge       short M00_L02 mov       rcx,rdi mov    \", \"   rcx,[rcx+8] cmp       esi,[rcx+8] jae       short M00_L04 mov       edx,esi movzx     edx,word pt\", \"r [rcx+rdx*2+0C] mov       rcx,rdi call      qword ptr [Program.IsBoundaryWordChar(Char)] jmp       \", \"short M00_L03 M00_L02: xor       eax,eax M00_L03: cmp       ebp,eax setne     al movzx     eax,al ad\", \"d       rsp,28 pop       rbx pop       rbp pop       rsi pop       rdi ret M00_L04: call      CORINF\", \"O_HELP_RNGCHKFAIL int       3 ; Total bytes of code 117 ; Program.IsBoundary(System.ReadOnlySpan`1<C\", \"har>, Int32) push      r14 push      rdi push      rsi push      rbp\\n```\\n\\n```\\npush      rbx sub     \", \"  rsp,20 mov       rdi,rcx mov       esi,r8d mov       rbx,[rdx] mov       ebp,[rdx+8] lea       edx\", \",[rsi-1] cmp       edx,ebp jae       short M00_L00 mov       edx,edx movzx     edx,word ptr [rbx+rdx\", \"*2] mov       rcx,rdi call      qword ptr [Program.IsBoundaryWordChar(Char)] jmp       short M00_L01\", \" M00_L00: xor       eax,eax M00_L01: mov       r14d,eax cmp       esi,ebp jae       short M00_L02 mo\", \"v       edx,esi movzx     edx,word ptr [rbx+rdx*2] mov       rcx,rdi call      qword ptr [Program.Is\", \"BoundaryWordChar(Char)] jmp       short M00_L03 M00_L02: xor       eax,eax M00_L03: cmp       r14d,e\", \"ax setne     al movzx     eax,al add       rsp,20 pop       rbx pop       rbp pop       rsi pop     \", \"  rdi pop       r14 ret ; Total bytes of code 94\\n```\\n\\nThe most interesting thing to notice here is t\", \"he:\\n\\n```\\ncall      CORINFO_HELP_RNGCHKFAIL int       3\\n```\\n\\nat the end of the first version that doe\", \"sn't exist at the end of the second. As we saw earlier, this is what the generated assembly looks li\", \"ke when the JIT is emitting the code to throw an index out of range exception for an array, string, \", \"or span. It's at the end because it's considered to be 'cold,' rarely executed. It exists in the fir\", \"st because the JIT can't prov e based on local analysis of that function that the runtext[index-1] a\", \"nd runtext[index] accesses will be in range of the string (it can't know or trust any implied relati\", \"onship between startpos , endpos , and the bounds of runtext ). But in the second, the JIT can know \", \"and trust that the ReadOnlySpan&lt;char&gt; 's lower bound is 0 and upper bound (ex clusive) is the \", \"span's Length , and with how the method is constructed, it can then prove that the span accesses are\", \" always in bound. As such, it doesn't need to emit any bounds checks in the method, and the method t\", \"hen lacks the tell-tale signature of the index out of range throw. You can see more examples of taki\", \"ng advantage of spans now being at the heart of the all of the engines in\\n\\ndotnet/runtime#66129, dot\", \"net/runtime#66178, and dotnet/runtime#72728, all of which clean up unnecessary checks against the bo\", \"unds that are then always 0 and span.Length .\\n\\nOk, so the engines are now able to be handed span inp\", \"uts and process them, great, what can we do with that? Well, Regex.IsMatch is easy: it's not encumbe\", \"red by needing to perform multiple matches, and thus doesn't need to worry about how to store that i\", \"nput ReadOnlySpan&lt;char&gt; for the next match. Similarly, the new Regex.Count , which provides an\", \" optimized implementation for counting how many matches there are in the input, can bypass using Mat\", \"ch or MatchCollection , and thus can easily operate over spans as well; dotnet/runtime#64289 added s\", \"tring -based overloads, and dotnet/runtime#66026 added span-based overloads. We can optimize Count f\", \"urther by passing additional information into the engines to let them know how much information they\", \" actually need to compute. For example, I noted previously that NonBacktracking is fairly pay-for-pl\", \"ay in how much work it needs to do relative to what information it ne eds to gather. It's cheapest t\", \"o just determine whether there is a match, as it can do that in a single forward pass through the in\", \"put. If it also needs to compute the actual starting and ending bounds, that requires another revers\", \"e pass through some of the input. And if it then also needs to compute capture information, that req\", \"uires yet another forward pass based on an NFA (even if the other two were DFA-based). Count needs t\", \"he bounds information, as it needs to know where to start looking for the next mat ch, but it doesn'\", \"t need the capture information, since none of that capture information is handed back to the caller.\", \" dotnet/runtime#68242 updates the engines to receive this additional information, such that methods \", \"like Count can be made more efficient.\\n\\nSo, IsMatch and Count can work with spans. But we still don'\", \"t have a method that lets you actually get back that match information. Enter the new EnumerateMatch\", \"es method, added by dotnet/runtime#67794. EnumerateMatches is very similar to Match , except instead\", \" of handing back a Match class instance, it hands back a ref struct enumerator:\\n\\n```\\npublic ref stru\", \"ct ValueMatchEnumerator { private readonly Regex _regex; private readonly ReadOnlySpan<char> _input;\", \" private ValueMatch _current; private int _startAt; private int _prevLen; ... }\\n```\\n\\nBeing a ref str\", \"uct , the enumerator is able to store a reference to the input span, and is thus able to iterate thr\", \"ough matches, which are represented by the ValueMatch ref struct. Notably, today ValueMatch doesn't \", \"provide capture information, which also enables it to partake in the optimizations previously mentio\", \"ned for Count . Even if you have an input string , EnumerateMatches is thus a way to have ammortized\", \" allocationfree enumeration of all matches in the input. In .NET 7, though, there isn't a way to hav\", \"e such allocation-free enumeration if you also need a ll the capture data. That's something we'll in\", \"vestigate designing in the future if/as needed.\\n\\n## TryFindNextPossibleStartingPosition\\n\\nAs noted ea\", \"rlier, the core of all of the engines is a Scan(ReadOnlySpan&lt;char&gt;) method that accepts the in\", \"put text to match, combines that with positional information from the base instance, and exits\\n\\nwhen\", \" it either finds the location of the next match or exhausts the input without finding another. For t\", \"he backtracking engines, the implementation of that method is logically as follows:\\n\\n```\\nprotected o\", \"verride void Scan(ReadOnlySpan<char> inputSpan) { while (!TryMatchAtCurrentPosition(inputSpan) && ba\", \"se .runtextpos != inputSpan.Length) { base .runtextpos++; } }\\n```\\n\\nWe try to match the input at the \", \"current position, and if we're successful in doing so, that's it, we exit. If the current position d\", \"oesn't match, however, then if there's any input remaining we 'bump' the position and start the proc\", \"ess over. In regex engine terminology, this is often referred to as a 'bumpalong loop.' However, if \", \"we actually ran the full matching process at every input character, that could be unnecessarily slow\", \". For many patterns, there's something about the pattern that would enable us to be more thoughtful \", \"about where we perform full matches, quickly skipping past locations that couldn't possibly match, a\", \"nd only spending our time and resources on locations that have a real chance of matching. To elevate\", \" that concept to a firstclass one, the backtracking engines' 'bumpalong loop' is typically more like\", \" the following (I say 'typically' because in some cases the compiled and source generated regexes ar\", \"e able to generate something even better).\\n\\n```\\nprotected override void Scan(ReadOnlySpan<char> inpu\", \"tSpan) { while (TryFindNextPossibleStartingPosition(inputSpan) && !TryMatchAtCurrentPosition(inputSp\", \"an) && base .runtextpos != inputSpan.Length) { base .runtextpos++; } }\\n```\\n\\nAs with FindFirstChar pr\", \"eviously, that TryFindNextPossibleStartingPosition has the responsibility of searching as quickly as\", \" possible for the next place to match (or determining that nothing else could possibly match, in whi\", \"ch case it would return false and the loop would exit). As FindFirstChar , and it was embued with mu\", \"ltiple ways of doing its job. In .NET 7,\\n\\nTryFindNextPossibleStartingPosition learns many more and i\", \"mproved ways of helping the engine be fast.\\n\\nIn .NET 6, the interpreter engine had effectively two w\", \"ays of implementing TryFindNextPossibleStartingPosition : a Boyer-Moore substring search if the patt\", \"ern began with a string (potentially case-insensitive) of at least two characters, and a linear scan\", \" for a character class known to be the set of all possible chars that could begin a match. For the l\", \"atter case, the interpreter had eight different implementations for matching, based on a combination\", \" of whether RegexOptions.RightToLeft was set or not, whether the character class required case-insen\", \"sitive comparison or not, and whether the character class contained only a single character or more \", \"than one character. Some of these were more optimized than others, e.g. a left-to-right, case-sensit\", \"ive, single-char search would use an IndexOf(char) to search for the next location, an optimization \", \"added in .NET 5. However, every time this operation was performed, the engine would need to recomput\", \"e which case it would be. dotnet/runtime#60822 improved this, introducing an internal\\n\\nenum of the s\", \"trategies used by TryFindNextPossibleStartingPosition to find the next opportunity, adding a switch \", \"to TryFindNextPossibleStartingPosition to quickly jump to the right strategy, and precomputing which\", \" strategy to use when the interpreter was constructed. This not only made the interpreter's implemen\", \"tation at match time faster, it made it effectively free (in terms of runtime overhead at match time\", \") to add additional strategies.\\n\\ndotnet/runtime#60888 then added the first additional strategy. The \", \"implementation was already capable of using IndexOf(char) , but as mentioned previously in this post\", \", the implementation of IndexOf(ReadOnlySpan&lt;char&gt;) got way better in .NET 7 in many cases, to\", \" the point where it ends up being significantly better than Boyer-Moore in all but the most corner o\", \"f corner cases. So this PR enables a new IndexOf(ReadOnlySpan&lt;char&gt;) strategy to be used to se\", \"arch for a prefix string in the case where the string is case-sensitive.\\n\\n```\\nprivate static readonl\", \"y string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.t\", \"xt\\\").Result; private Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled); [Benchmark]\", \" public int Count() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method   | Runtime   | Mean      |  \", \" Ratio |\\n|----------|-----------|-----------|---------|\\n| Count    | .NET 6.0  | 377.32 us |    1   \", \" |\\n| Count    | .NET 7.0  | 55.44 us  |    0.15 |\\n\\ndotnet/runtime#61490 then removed BoyerMoore enti\", \"rely. This wasn't done in the previously mentioned PR because of lack of a good way to handle case-i\", \"nsensitive matches. However, this PR also special-cased ASCII letters to teach the optimizer how to \", \"turn an ASCII case-insensitive match into a set of both casings of that letter (excluding the few kn\", \"own to be a problem, like i and k , which can both be impacted by the employed culture and which mig\", \"ht map case-insensitively to more than two values). With enough of the common cases covered, rather \", \"than use Boyer-Moore to perform a case-insensitive search, the implementation just uses IndexOfAny(c\", \"har, char, ...) to search for the starting set, and the vectorization employed by IndexOfAny ends up\", \" outpacing the old implementation handily in realworld cases. This PR goes further than that, such t\", \"hat it doesn't just discover the 'starting set,' but is able to find all of the character classes th\", \"at could match a pattern a fixed-offset from the beginning; that then gives the analyzer the a bilit\", \"y to choose the set that's expected to be least common and issue a search for it instead of whatever\", \" happens to be at the beginning. The PR goes even further, too, motivated in large part by the non-b\", \"acktracking engine. The nonbacktracking engine's p rototype implementation also used IndexOfAny(char\", \", char, ...) when it arrived at a starting state and was thus able to quickly skip through input tex\", \"t that wouldn't have a chance of pushing it to the next state. We wanted all of the engines to share\", \" as much logic as possible, in particular around this speed ahead, and so this PR unified the interp\", \"reter with the nonbacktracking engine to have them share the exact same TryFindNextPossibleStartingP\", \"osition routine (which the non-backtracking engine just calls at an appropriate place in its graph t\", \"raversal loop). Since the non-backtracking engine was already using IndexOfAny in this manner, initi\", \"ally not doing so popped as a significant regression on a variety of patterns we measure, and this c\", \"aused us to invest in using it everywhere. This PR also introduced the first special-casing for case\", \"-insensitive comparisons into the compiled engine, e.g. if we found a set that was [Ee] , rather tha\", \"n emitting a\\n\\ncheck akin to c == 'E' || c == 'e' , we'd instead emit a check akin to (c | 0x20) == '\", \"e' (those fun ASCII tricks discussed earlier coming into play again).\\n\\n```\\nprivate static readonly s\", \"tring s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\"\", \").Result; private Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled | RegexOptions.I\", \"gnoreCase); [Benchmark] public int Count() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method   | Ru\", \"ntime   | Mean     |   Ratio |\\n|----------|-----------|----------|---------|\\n| Count    | .NET 6.0  \", \"| 499.3 us |    1    |\\n| Count    | .NET 7.0  | 177.7 us |    0.35 |\\n\\nThe previous PR started turnin\", \"g IgnoreCase pattern text into sets, in particular for ASCII, e.g. (?i)a would become [Aa] . That PR\", \" hacked in the support for ASCII knowing that something more complete would be coming along, as it d\", \"id in dotnet/runtime#67184. Rather than hardcoding the caseinsensitive sets that just the ASCII char\", \"acters map to, this PR essentially hardcodes the sets for every possible char. Once that's done, we \", \"no longer need to know about case-insensitivity at match time and can instead just double-down on ef\", \"ficiently matching sets, which we already need to be able to do well. Now, I said it encodes the set\", \"s for every possible char; that's not entirely true. If it were true, that would take up a large amo\", \"unt of memory, and in fact, most of that memory would be wasted because the vast majority of charact\", \"ers don't participate in case conversion\\u2026 there are only ~2,000 characters that we need to handle. A\", \"s such, the implementation employs a three-tier table scheme. The first table has 64 elements, divid\", \"ing the full range of chars into 64 groupings; of those 64 groups, 54 of them have no characters tha\", \"t participate in case conversion, so if we hit one of those entries, we can immediately stop the sea\", \"rch. For the remaining 10 that do have at least one character in their range participating, the char\", \"acter and the value from the first table are used to compute an index into the second table; there, \", \"too, the majority of entries say that nothing participates in case conversion. It's only if we get a\", \" legitimate hit in the second table does that give us an index into the third table, at which locati\", \"on we can find all of the characters considered case-equivalent with the first.\\n\\ndotnet/runtime#6347\", \"7 (and then later improved in dotnet/runtime#66572) proceeded to add another searching strategy, thi\", \"s one inspired by nimregex's literal optimizations . There are a multitude of regexes we track from \", \"a performance perspective to ensure we're not regressing in common cases and to help guide investmen\", \"ts. One is the set of patterns in mariomka/regex-benchmark languages regex benchmark. One of those i\", \"s for URIs:\\n\\n(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\" . This pattern defies the thus-\", \"far enabled strategies for finding a next good location, as it's guaranteed to begin with a 'word ch\", \"aracter' ( \\\\w ), which includes ~50,000 of the ~65,000 possible characters; we don't have a good way\", \" of vectorizing a search for such a character class. However, this pattern is interesting in that it\", \" begins with a loop, and not only that, it's an upper -unbounded loop which our analysis will determ\", \"ine is atomic, because the character guaranteed to immediately follow the loop is a ':' , which is i\", \"tself not a word character, and thus there's nothing the loop could match and give up as part of bac\", \"ktracking that would match ':' . That all lends itself to a different approach to vectorization: rat\", \"her than trying to search for the \\\\w character class, we can instead search for the substring \\\"://\\\" \", \", and then once we\\n\\nfind it, we can match backwards through as many [\\\\w] s as we can find; in this c\", \"ase, the only constraint is we need to match at least one. This PR added that strategy, for a litera\", \"l after an atomic loop, to all of the engines.\\n\\n```\\nprivate static readonly string s_haystack = new \", \"HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; private Regex\", \" _regex = new Regex(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\", RegexOptions.Compiled); \", \"[Benchmark] public bool IsMatch() => _regex.IsMatch(s_haystack); // Uri's in Sherlock Holmes? \\\"Most \", \"unlikely.\\\"\\n```\\n\\n| Method   | Runtime   | Mean        |   Ratio |\\n|----------|-----------|-----------\", \"--|---------|\\n| IsMatch  | .NET 6.0  | 4,291.77 us |    1    |\\n| IsMatch  | .NET 7.0  | 42.40 us    \", \"|    0.01 |\\n\\nOf course, as has been talked about elsewhere, the best optimizations aren't ones that \", \"make something faster but rather ones that make something entirely unnecessary. That's what dotnet/r\", \"untime#64177 does, in particular in relation to anchors. The .NET regex implementation has long had \", \"optimizations for patterns with a starting anchor: if the pattern begins with ^ , for example (and R\", \"egexOptions.Multiline wasn't specified), the patt ern is rooted to the beginning, meaning it can't p\", \"ossibly match at any position other than 0 ; as such, with such an anchor,\\n\\nTryFindNextPossibleStart\", \"ingPosition won't do any searching at all. The key here, though, is being able to detect whether the\", \" pattern begins with such an anchor. In some cases, like ^abc$ , that's trivial. In other cases, lik\", \"e ^abc|^def , the existing analysis had trouble seeing through that alternation to find the guarante\", \"ed starting ^ anchor. This PR fixes that. It also adds a new strategy based on discovering that a pa\", \"ttern has an ending anchor like $ . If the analysis engine can determine a maximum number of charact\", \"ers for any possible match, and it has such an anchor, then it can simply jump to that distance from\", \" the end of the string, and bypass even looking at anything before then.\\n\\n```\\nprivate static readonl\", \"y string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.t\", \"xt\\\").Result; private Regex _regex = new Regex(@\\\"^abc|^def\\\", RegexOptions.Compiled); [Benchmark] publ\", \"ic bool IsMatch() => _regex.IsMatch(s_haystack); // Why search _all_ the text?!\\n```\\n\\n| Method   | Ru\", \"ntime   | Mean          |   Ratio |\\n|----------|-----------|---------------|---------|\\n| IsMatch  | \", \".NET 6.0  | 867,890.56 ns |       1 |\\n| IsMatch  | .NET 7.0  | 33.55 ns      |       0 |\\n\\ndotnet/run\", \"time#67732 is another PR related to improving anchor handling. It's always fun when a bug fix or cod\", \"e simplification refactoring turns into a performance improvement. The PR's primary purpose was to s\", \"implify some complicated code that was computing the set of characters that could possibly start a m\", \"atch. It turns out that complication was hiding a logic bug which manifested in it missing some oppo\", \"rtunities to report valid starting character classes, the impact of which is that some searches whic\", \"h could have been vectorized weren't. By simplifying the implementation, the bug was fixed, exposing\", \" more performance opportunities.\\n\\nBy this point, the engines are able to use IndexOf(ReadOnlySpan&lt\", \";char&gt;) to find a substring at the beginning of a pattern. But sometimes the most valuable substr\", \"ing isn't at the beginning, but somewhere in the middle or even at the end. As long as it's at a fix\", \"ed -offset from the beginning of the pattern, we can search for it, and then just back-off by the of\", \"fset to the position we should actually try running the match. dotnet/runtime#67907 does exactly tha\", \"t.\\n\\n```\\nprivate static readonly string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gut\", \"enberg.org/files/1661/1661-0.txt\\\").Result; private Regex _regex = new Regex(@\\\"looking|feeling\\\", Rege\", \"xOptions.Compiled); [Benchmark] public int Count() => _regex.Matches(s_haystack).Count; // will sear\", \"ch for \\\"ing\\\"\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio |\\n|----------|-----------|----------|-\", \"--------|\\n| Count    | .NET 6.0  | 444.2 us |    1    |\\n| Count    | .NET 7.0  | 122.6 us |    0.28 \", \"|\\n\\n## Loops and Backtracking\\n\\nLoop handling in the compiled and source generated engines has been si\", \"gnificantly improved, both with respect to processing them faster and with respect to backtracking l\", \"ess.\\n\\nWith regular greedy loops (e.g. c* ), there are two directions to be concerned about: how quic\", \"kly can we consume all the elements that match the loop, and how quickly can we give back elements t\", \"hat might be necessary as part of backtracking for the remainder of the expression to match. And wit\", \"h lazy loops, we're primarily concerned with backtracking, which is the forward direction (since laz\", \"y loops consume as part of backtracking rather than giving back as part of backtracking). With PRs d\", \"otnet/runtime#63428, dotnet/runtime#68400, dotnet/runtime#64254, and dotnet/runtime#73910, in both t\", \"he compiler and source generator we now make full use of effectively all of the variants of IndexOf \", \", IndexOfAny , LastIndexOf , LastIndexOfAny , IndexOfAnyExcept , and LastIndexOfAnyExcept in order t\", \"o speed along these searches. For example, in a pattern like .*abc , the forward direction of that l\", \"oop entails consuming every character until the next newline, which we can optimize with an IndexOf(\", \"'\\\\n') . Then as part of backtracking, rather than giving up one character at a time, we can LastInde\", \"xOf(\\\"abc\\\") in order to find the next viable location that could possibly match the remainder of the \", \"pattern. Or for example, in a pattern like [^a-c]*def , the loop will initially greedily consume eve\", \"rything other than 'a' , 'b' , or 'c' , so we can use IndexOfAnyExcept('a', 'b', 'c') to find the in\", \"itial end of the loop. And so on. This can yield huge performance gains, and with the source generat\", \"or, also makes the generated code more idiomatic and easier to understand.\\n\\n```\\nprivate static reado\", \"nly string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0\", \".txt\\\").Result; private Regex _regex = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled | RegexOp\", \"tions.Multiline); [Benchmark] public int Count() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method \", \"  | Runtime   | Mean       |   Ratio |\\n|----------|-----------|------------|---------|\\n| Count    | \", \".NET 6.0  | 3,369.5 us |    1    |\\n| Count    | .NET 7.0  | 430.2 us   |    0.13 |\\n\\nSometimes optimi\", \"zations are well-intended but slightly miss the mark. dotnet/runtime#63398 fixes such an issue with \", \"an optimization introduced in .NET 5; the optimization was valuable but only for a subset of the sce\", \"narios it was intended to cover. While TryFindNextPossibleStartingPosition 's primary raison d'\\u00eatre \", \"is to update the bumpalong position, it's also possible for update the bumpalong position to the end\", \" of the loop. The optimization added in .NET 5 was dutifully position was getting updated every time\", \" we backtracked, meaning it started going backwards, when it\\n\\nTryMatchAtCurrentPosition to do so. On\", \"e of the occasions in which it'll d o so is when the pattern begins with an upper-unbounded single-c\", \"haracter greedy loop. Since processing starts with the loop having fully consumed everything it coul\", \"d possibly match, subsequent trips through the scan loop don't need to reconsider any starti ng posi\", \"tion within that loop; doing so would just be duplicating work done in a previous iteration of the s\", \"can loop. And as such, TryMatchAtCurrentPosition can doing this, and it did so in a way that fully h\", \"andled atomic loops. But with greedy loops, the updated should have remained at the end of the loop.\", \" This PR fixes that, yielding significant savings in the additional covered cases.\\n\\n```\\nprivate stat\", \"ic readonly string s_haystack = new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/166\", \"1/1661-0.txt\\\").Result; private Regex _regex = new Regex(@\\\".*stephen\\\", RegexOptions.Compiled); [Bench\", \"mark] public int Count() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method   | Runtime   | Mean    \", \"     |   Ratio |\\n|----------|-----------|--------------|---------|\\n| Count    | .NET 6.0  | 103,962.\", \"8 us |   1     |\\n| Count    | .NET 7.0  | 336.9 us     |   0.003 |\\n\\nAs mentioned elsewhere, the best\", \" optimizations are those that make work entirely vanish rather than just making work faster. dotnet/\", \"runtime#68989, dotnet/runtime#63299, and dotnet/runtime#63518 do exactly that by improving the patte\", \"rn analyzers ability to find and eliminate more unnecessary backtracking, a process the analyzer ref\", \"ers to as 'auto -atomicity' (automatically making loops atomic). For example, in the pattern a*?b , \", \"we have a lazy loop of 'a' s followed by a b . That loop can only match 'a' s, and 'a' doesn't overl\", \"ap with 'b' . So let's say the input is \\\"aaaaaaaab\\\" . The loop is lazy, so we'll start out by trying\", \" to match just 'b' . It won't match, so we'll backtrack into the lazy loop and try to match \\\"ab\\\" . I\", \"t won't match so we'll backtrack into the lazy loop and try to match \\\"aab\\\" . And so on, until we've \", \"consumed all the 'a' s such that the rest of the pattern has a chance of matching the rest of the in\", \"put. That's exactly what an atomic greedy loop does, so we can transform the pattern a*?b into (?&gt\", \";a*)b , which is much more effici ently processed. In fact, we can see exactly how it's processed ju\", \"st by looking at the source-generated implementation of this pattern:\\n\\n```\\nprivate bool TryMatchAtCu\", \"rrentPosition(ReadOnlySpan<char> inputSpan) { int pos = base .runtextpos; int matchStart = pos; Read\", \"OnlySpan<char> slice = inputSpan.Slice(pos);\\n```\\n\\n```\\n// Match 'a' atomically any number of times. {\", \" int iteration = slice.IndexOfAnyExcept('a'); if (iteration < 0) { iteration = slice.Length; } slice\", \" = slice.Slice(iteration); pos += iteration; } // Advance the next matching position. if ( base .run\", \"textpos < pos) { base .runtextpos = pos; } // Match 'b'. if (slice.IsEmpty || slice[0] != 'b') { ret\", \"urn false ; // The input didn't match. } // The input matched. pos++; base .runtextpos = pos; base .\", \"Capture(0, matchStart, pos); return true ; }\\n```\\n\\n(Note that those comments aren't ones I added for \", \"this blog post; the source g enerator itself is emitting commented code.)\\n\\nWhen a regular expression\", \" is input, it's parsed into a tree -based form. The 'auto -atomicity' analysis discussed in the prev\", \"ious PR is one form of analysis that walks around this tree looking for opportunities to transform p\", \"ortions of the tree into a behaviorally equivalent alternative that will be more efficient to execut\", \"e. Several PRs introduced additional such transformations. dotnet/runtime#63695 , for example, looks\", \" for 'empty' and 'nothing' nodes in the tree that can be removed. An 'empty' node is something that \", \"matches the empty string, so for example in the alternation abc|def||ghi , the third branch of that \", \"alternation is em pty. A 'nothing' node is something that can't match anything, so for example in th\", \"e concatenation abc(?!)def , that (?!) in middle is a negative lookahead around an empty, which can'\", \"t possibly match anything, as it's saying the expression won't match if it' s followed by an empty s\", \"tring, which everything is. These constructs often arise as a result of other transformations rather\", \" than being something a developer typically writes by hand, just as there are optimizations in the J\", \"IT where you might look at them and say 'why on earth is that something a developer would write' but\", \" it ends up being a valuable optimization anyways because inlining might transform perfectly reasona\", \"ble code into something that matches the target pattern. Thus, for example, if you did have abc(?!)d\", \"ef , since that concatenation requires the (?!) to match in order to be successful, the concatenatio\", \"n itself can simply be replaced by a 'nothing.' You can see this easily if you try this with the sou\", \"rce generator:\\n\\n[GeneratedRegex(@\\\"abc(?!)def\\\")]\\n\\nas it will produce a Scan method like this (comment\", \" and all):\\n\\n```\\nprotected override void Scan(ReadOnlySpan<char> inputSpan) { // The pattern never ma\", \"tches anything. }\\n```\\n\\nAnother set of transformations was introduced in dotnet/runtime#59903, specif\", \"ically around alternations (which beyond loops are the other source of backtracking). This introduce\", \"d two main optimizations. First, it enables rewriting alternations into alternations of alternations\", \", e.g. transforming axy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z) , which is then further reduced into ax\", \"[yz]|bx[yz] . This can enable the backtracking engines to more efficiently process alternations due \", \"to fewer branches and thus less potential backtracking. The PR also enabled limited reordering of br\", \"anches in an alternation. Generally branches can't be reordered, as the order can impact exactly wha\", \"t's matched and what's captured, but if the engine can prove there's no effect on ordering, then it'\", \"s free to reorder. One key place that ordering isn't a factor is if the alternation is atomic due to\", \" it being wrapped in an atomic group (and the auto-atomicity analysis will add such groups implicitl\", \"y in some situations). Reordering the branches then enables other optimizations, like the one previo\", \"usly mentioned from this PR. And then once those optimizations have kicked in, if we're left with an\", \" atomic alternation where every branch begins with a different letter, than can enable further optim\", \"izations in terms of how the alternation is lowered; this PR teaches the source generator how to emi\", \"t a switch statement, which leads to both more efficient and more readable code. (The detection of w\", \"hether nodes in the tree are atomic, and other such properties such as performing captures or introd\", \"ucing backtracking, turned out to be valuable enough that dotnet/runtime#65734 added dedicated suppo\", \"rt for this.)\\n\\n## Code generation\\n\\nThe .NET 7 regex implementation has no fewer than four engines: t\", \"he interpreter (what you get if you don't explicitly choose another engine), the compiler (what you \", \"get with RegexOptions.Compiled ), the non-backtracking engine (what you get with RegexOptions.NonBac\", \"ktracking ), and the source generator (what you get with [GeneratedRegex(...)] ). The interpreter an\", \"d the non-backtracking engine don't require any kind of code generation; they're both based on creat\", \"ing in -memory data structures that represent how to match input against the pattern. The other two,\", \" though, both generate code specific to the pattern; the generated code is code attempting to mimick\", \" what you might write if you weren't using Regex at all and were instead writing code to perform a s\", \"imilar match directly. The source gener ator spits out C# that's compiled directly into your assembl\", \"y, and the compiler spits out IL at run-time via reflection emit. The fact that these are generating\", \" code specific to the pattern means there's a ton of opportunity to optimize.\\n\\ndotnet/runtime#59186 \", \"provided the initial implementation of the source generator. This was a direct port of the compiler,\", \" effectively a line-by-line translation of IL into C#; the result is C# akin to what you'd get if yo\", \"u were to run the generated IL through a decompiler like ILSpy. A bunch of PRs then proceeded to ite\", \"rate on and tweak the source generator, but the biggest improvements came from changes that changed \", \"the compiler and the source generator together. Prior to .NET 5, the compiler spit out IL that was v\", \"ery similar to what the interpreter would do. The interpreter is handed a series of instructions tha\", \"t it walks through one by one and interprets, and the compiler, handed that same\\n\\nseries of instruct\", \"ions, would just emit the IL for processing each. It had some opportunity for being more efficient, \", \"e.g. loop unrolling, but a lot of value was left on the table. In .NET 5, an alternate path was adde\", \"d in support of patterns without backtracking; this code path was based on being handed the parsed n\", \"ode tree rather than being based on the series of instructions, and that higher-level form enabled t\", \"he compiler to derive more insights about the pattern that it could then use to generate more effici\", \"ent code. In .NET 7, support for all regex features were incrementally added in, over the course of \", \"multiple PRs, in particular dotnet/runtime#60385 for backtracking single char loops, dotnet/runtime#\", \"61698 for backtracking single char lazy loops, dotnet/runtime#61784 for other backtracking lazy loop\", \"s, and dotnet/runtime#61906 for other backtracking loops as well as back references and conditionals\", \". At that point, the only features missing were support for RegexOptions.RightToLeft and lookbehinds\", \" (which are implemented in terms of right-to-left), and we decided based on relatively little use of\", \" these features that we needn't keep around the old compiler code just to enable them. So, dotnet/ru\", \"ntime#62318 deleted the old implementation. But, even though these features are relatively rare, it'\", \"s a lot easier to tell a story that 'all patterns are supported' than one that requires special call\", \"ou ts and exceptions, so dotnet/runtime#66127 and dotnet/runtime#66280 added full lookbehind and Rig\", \"htToLeft support such that there were no takebacks. At this point, both the compiler and source gene\", \"rator now supported everything the compiler previously did, but now with the more modernized code ge\", \"neration. This code generation is in turn what enables many of the optimizations previously discusse\", \"d, e.g. it provides the opportunity to use APIs like LastIndexOf as part of backtracking, which woul\", \"d have been near impossible with the previous approach.\\n\\nOne of the great things about the source ge\", \"nerator emitting idiomatic C# is it makes it easy to iterate. Every time you put in a pattern and se\", \"e what the generator emits, it's like being asked to do a code review of someone else's code, and yo\", \"u very frequently see something 'new' worthy of comment, or in this case, improving the generator to\", \" address the issue. And so a bunch of PRs were originated based on reviewing what the generator emit\", \"ted and then tweaking the generator to do better (and since the compiler was effectively entirely re\", \"written along with the source generator, they maintain the same structure, and it's easy to port imp\", \"rovements from one to the other). For example, dotnet/runtime#68846 and dotnet/runtime#69198 tweaked\", \" how some comparisons were being performed in order for them to convey enough information to the JIT\", \" that it can eliminate some subsequent bounds checking, and dotnet/runtime#68490 recognized a variet\", \"y of conditions being emitted that could never happen in some situations observable statically and w\", \"as able to elide all that code gen. It also became obvious that some patterns didn't need the full e\", \"xpressivity of the scan loop, and a more compact and customized Scan implementation could be used. d\", \"otnet/runtime#68560 does that, such that, for example, a simple pattern like hello won't emit a loop\", \" at all and will instead have a simpler Scan implementation like:\\n\\n```\\nprotected override void Scan(\", \"ReadOnlySpan<char> inputSpan) { if (TryFindNextPossibleStartingPosition(inputSpan)) { // The search \", \"in TryFindNextPossibleStartingPosition performed the entire match. int start = base .runtextpos; int\", \" end = base .runtextpos = start + 5; base .Capture(0, start, end); } }\\n```\\n\\nThe compiler and source \", \"generator were also updated to take advantage of newer features. dotnet/runtime#63277, for example, \", \"teaches the source generator how to determine if unsafe code is allowed, and if it is, it emits a [S\", \"kipLocalsInit] for the core logic; the matching routine can result in many locals being emitted, and\", \" SkipLocalsInit can make it cheaper to call the function due to less zero'ing being necessary. Then \", \"there's the issue of where the code is generated; we want helper functions (like the \\\\w IsWordChar h\", \"elper introduced in dotnet/runtime#62620) that can be shared amongst multiple generated regexes, and\", \" we want to be able to share the exact same regex implementation if the same pattern/options/timeout\", \" combination are used in multiple places in the same assembly (dotnet/runtime#66747), but doing so t\", \"hen exposes this implementation detail to user code in the same assembly. To still be able to get th\", \"e perf benefits of such code sharing while avoiding the resulting complications, dotnet/runtime#6643\", \"2 and then dotnet/runtime#71765 teaches the source generator to use the new file-local types feature\", \"s in C# 11 (dotnet/roslyn#62375).\\n\\nOne last and interesting code generation aspect is in optimizatio\", \"ns around character class matching. Matching character classes, whether ones explicitly written by t\", \"he developer or ones implicitly created by the engine (e.g. as part of finding the set of all charac\", \"ters that can begin the expression), can be one of the more time-consuming aspects of matching; if y\", \"ou imagine having to evaluate this logic for every character in the input, then how many instruction\", \"s needs to be executed as part of matching a character class directly correlates to how long it take\", \"s to perform the overall match. We thus spend some time trying to ensure we generate optimal matchin\", \"g code for as many categories of character classes as possible. dotnet/runtime#67365, for example, i\", \"mproved a bunch of cases found to be common in real-world use, like specially-recognizing sets like \", \"[\\\\d\\\\D] , [\\\\s\\\\S] , and [\\\\w\\\\W] as meaning 'match anything' (just as is the case for . in RegexOptions.\", \"Singleline mode), in which case existing optimizations around the handling of 'match anything' can k\", \"ick in.\\n\\n```\\nprivate static readonly string s_haystack = new string('a', 1_000_000); private Regex _\", \"regex = new Regex(@\\\"([\\\\s\\\\S]*)\\\", RegexOptions.Compiled); [Benchmark] public Match Match() => _regex.M\", \"atch(s_haystack);\\n```\\n\\n| Method   | Runtime   | Mean            |   Ratio |\\n|----------|-----------|\", \"-----------------|---------|\\n| Match    | .NET 6.0  | 1,934,393.69 ns |       1 |\\n| Match    | .NET \", \"7.0  | 91.80 ns        |       0 |\\n\\nOr dotnet/runtime#68924, which taught the source generator how t\", \"o use all of the new char ASCII helper methods, like char.IsAsciiLetterOrDigit , as well as some exi\", \"sting helpers it didn't yet know about, in the generated output; for example this:\\n\\n```\\n[GeneratedRe\", \"gex(@\\\"[A-Za-z][A-Z][a-z][0-9][A-Za-z0-9][0-9A-F][0-9a-f][0-9A-Faf]\\\\p{Cc}\\\\p{L}[\\\\p{L}\\\\d]\\\\p{Ll}\\\\p{Lu}\\\\p\", \"{N}\\\\p{P}\\\\p{Z}\\\\p{S}\\\")]\\n```\\n\\nnow produces this in the core matching logic emitted by the source genera\", \"tor:\\n\\n```\\nif ((uint)slice.Length < 17 || !char.IsAsciiLetter(slice[0]) || // Match a character in th\", \"e set [A-Za-z]. !char.IsAsciiLetterUpper(slice[1]) || // Match a character in the set [A-Z]. !char.I\", \"sAsciiLetterLower(slice[2]) || // Match a character in the set [a-z]. !char.IsAsciiDigit(slice[3]) |\", \"| // Match '0' through '9'. !char.IsAsciiLetterOrDigit(slice[4]) || // Match a character in the set \", \"[0-9A-Za-z].\\n```\\n\\n```\\n!char.IsAsciiHexDigitUpper(slice[5]) || // Match a character in the set [0-9A-\", \"F]. !char.IsAsciiHexDigitLower(slice[6]) || // Match a character in the set [0-9a-f]. !char.IsAsciiH\", \"exDigit(slice[7]) || // Match a character in the set [0-9A-Fa-f]. !char.IsControl(slice[8]) || // Ma\", \"tch a character in the set [\\\\p{Cc}]. !char.IsLetter(slice[9]) || // Match a character in the set [\\\\p\", \"{L}]. !char.IsLetterOrDigit(slice[10]) || // Match a character in the set [\\\\p{L}\\\\d]. !char.IsLower(s\", \"lice[11]) || // Match a character in the set [\\\\p{Ll}]. !char.IsUpper(slice[12]) || // Match a charac\", \"ter in the set [\\\\p{Lu}]. !char.IsNumber(slice[13]) || // Match a character in the set [\\\\p{N}]. !char\", \".IsPunctuation(slice[14]) || // Match a character in the set [\\\\p{P}]. !char.IsSeparator(slice[15]) |\", \"| // Match a character in the set [\\\\p{Z}]. !char.IsSymbol(slice[16])) // Match a character in the se\", \"t [\\\\p{S}]. { return false ; // The input didn't match. }\\n```\\n\\nOther changes impacting character clas\", \"s code generation included dotnet/runtime#72328, which improved the handling of character classes th\", \"at involve character class subtraction; dotnet/runtime#72317 from [@teo-tsirpanis](https://github.co\", \"m/teo-tsirpanis), which enabled additional cases where the generator could avoid emitting a bitmap l\", \"ookup; dotnet/runtime#67133, which added a tighter bounds check when it does emit such a lookup tabl\", \"e; and dotnet/runtime#61562 , which enables better normalization of character classes in the engine'\", \"s internal representation, thus leading to downstream optimizations better recognizing more characte\", \"r classes.\\n\\nFinally, with all of these improvements to Regex , a multitude of PRs fixed up regexes b\", \"eing used across dotnet/runtime, in various ways. dotnet/runtime#66142, dotnet/runtime#66179 from [@\", \"Clockwork-Muse](https://github.com/Clockwork-Muse), and dotnet/runtime#62325 from [@Clockwork-Muse](\", \"https://github.com/Clockwork-Muse) all converted Regex usage over to using [GeneratedRegex(...)] . d\", \"otnet/runtime#68961 optimized other usage in various ways. The PR replaced several regex.Matches(...\", \").Success calls with IsMatch(...) , as using IsMatch has less overhead due to not needing to constru\", \"ct a Match instance and due to being able to avoid more expensive phases in the non-backtracking eng\", \"ine to compute exact bounds and capture information. The PR also replaced some Match / Match.MoveNex\", \"t usage with EnumerateMatches , in order to avoid needing Match object allocations. The PR also enti\", \"rely removed at least one regex usage that was just as doable as a cheaper IndexOf . dotnet/runtime#\", \"68766 also removed a use of RegexOptions.CultureInvariant . Specifying CultureInvariant changes the \", \"behavior of IgnoreCase by alternating which casing tables are employed; if IgnoreCase isn't specifie\", \"d and there's no inline case-insensitivity options ( (?i) ), then specifying CultureInvariant is a n\", \"op. But a potentially expensive one. For any code that's size conscious, the Regex implementation is\", \" structured in a way as to try to make it as trimmmer friendly as possible. If you only ever do new \", \"Regex(pattern) , we'd really like to be able to statically determine that the compiler and non -back\", \"tracking implementations aren't nee ded such that the trimmer can remove it without having a visible\", \" and meaningful negative impact. However, the trimmer analysis isn't yet sophisticated enough to see\", \" exactly which options are used and only keep the additional engines linked in if RegexOptions.Compi\", \"led or RegexOptions.NonBacktracking is used; instead, any use of an overload that takes a RegexOptio\", \"ns will result in that code continuing to be referenced. By getting rid of the options, we increase \", \"the chances that no code in the app is using this constructor, which would in turn enable this const\", \"ructor, the compiler, and the non-backtracking implementation to be trimmed away.\\n\\n## Collections\\n\\nS\", \"ystem.Collections hasn't seen as much investment in .NET 7 as it has in previous releases, though ma\", \"ny of the lower-level improvements have a trickle-up effect into collections as well. For example, D\", \"ictionary&lt;,&gt; 's code hasn't changed between .NET 6 and .NET 7, but even so, this benchmark foc\", \"used on dictionary lookups:\\n\\n```\\nprivate Dictionary<int, int> _dictionary = Enumerable.Range(0, 10_0\", \"00).ToDictionary(i => i); [Benchmark] public int Sum() { Dictionary<int, int> dictionary = _dictiona\", \"ry; int sum = 0; for (int i = 0; i < 10_000; i++) { if (dictionary.TryGetValue(i, out int value)) { \", \"sum += value; } } return sum; }\\n```\\n\\nshows a measurable improvement in throughput between .NET 6 and\", \" .NET 7:\\n\\n| Method   | Runtime   | Mean     |   Ratio | Code Size   |\\n|----------|-----------|------\", \"----|---------|-------------|\\n| Sum      | .NET 6.0  | 51.18 us |    1    | 431 B       |\\n| Sum     \", \" | .NET 7.0  | 43.44 us |    0.85 | 413 B       |\\n\\nBeyond that, there have been explicit improvement\", \"s elsewhere in collections. ImmutableArray&lt;T&gt; , for example. As a reminder, ImmutableArray&lt;\", \"T&gt; is a very thin struct-based wrapper around a T[] that hides the mutability of T[] ; unless you\", \"'re using unsafe code , neither the length nor the shallow contents of an ImmutableArray&lt;T&gt; wi\", \"ll ever change (by shallow, I mean the data stored directly in that array can't be mutated, but if t\", \"here are mutable reference types stored in the array, those instances themselves may still have thei\", \"r data mutated). As a result, ImmutableArray&lt;T&gt; also has an associated 'builder' type, which d\", \"oes support mutation: you create the builder, populate it, and then transfer that contents to an Imm\", \"utableArray&lt;T&gt; which is frozen forevermore. In dotnet/runtime#70850 from [@grbell-ms](https://\", \"github.com/grbellms), the builder's Sort method is changed to use a span, which in turn avoids an IC\", \"omparer&lt;T&gt; allocation and a Comparison&lt;T&gt;\\n\\nallocation, while also speeding up the sort i\", \"tself by removing several layers of indirection from every comparison.\\n\\n```\\nprivate ImmutableArray<i\", \"nt>.Builder _builder = ImmutableArray.CreateBuilder<int>(); [GlobalSetup] public void Setup() { _bui\", \"lder.AddRange(Enumerable.Range(0, 1_000)); } [Benchmark] public void Sort() { _builder.Sort((left, r\", \"ight) => right.CompareTo(left)); _builder.Sort((left, right) => left.CompareTo(right)); }\\n```\\n\\n| Met\", \"hod   | Runtime   | Mean     |   Ratio |\\n|----------|-----------|----------|---------|\\n| Sort     | \", \".NET 6.0  | 86.28 us |    1    |\\n| Sort     | .NET 7.0  | 67.17 us |    0.78 |\\n\\ndotnet/runtime#61196\", \" from [@lateapexearlyspeed](https://github.com/lateapexearlyspeed) brings ImmutableArray&lt;T&gt; in\", \"to the span-based era, adding around 10 new methods to ImmutableArray&lt;T&gt; that interoperate wit\", \"h Span&lt;T&gt; and ReadOnlySpan&lt;T&gt; . These are valuable from a performance perspective becaus\", \"e it means if you have your data in a span, you can get it into an ImmutableArray&lt;T&gt; without i\", \"ncurring additional allocations beyond the one the ImmutableArray&lt;T&gt; itself will create. dotne\", \"t/runtime#66550 from [@RaymondHuy](https://github.com/RaymondHuy) also adds a bunch of new methods t\", \"o the immutable collection builders, which provide efficient implementations for operations like rep\", \"lacing elements and adding, inserting, and removing ranges.\\n\\nSortedSet&lt;T&gt; also saw some improv\", \"ements in .NET 7. For example, SortedSet&lt;T&gt; internally uses a red/black tree as its internal d\", \"ata structure, and it uses a Log2 operation to determine the maximum depth the tree could be for a g\", \"iven node count. Previously, that operation was implemented as a loop. But thanks to dotnet/runtime#\", \"58793 from [@teo-tsirpanis](https://github.com/teo-tsirpanis) that implementation is now simply a ca\", \"ll to BitOperations.Log2 , which is in turn implemented trivially in terms of one of multiple hardwa\", \"re intrinsics if they're supported (e.g. Lzcnt.LeadingZeroCount , ArmBase.LeadingZeroCount , X86Base\", \".BitScanReverse ). And dotnet/runtime#56561 from [@johnthcall](https://github.com/johnthcall) improv\", \"es SortedSet&lt;T&gt; copy performance by streamlining how the iteration through the nodes in the tr\", \"ee is handled.\\n\\n```\\n[Params(100)] public int Count { get ; set ; } private static SortedSet<string> \", \"_ set ; [GlobalSetup] public void GlobalSetup() { _set = new SortedSet<string>(StringComparer.Ordina\", \"lIgnoreCase); for (int i = 0; i < Count; i++) { _set.Add(Guid.NewGuid().ToString());\\n```\\n\\n```\\n} } [B\", \"enchmark] public SortedSet<string> SortedSetCopy() { return new SortedSet<string>(_set, StringCompar\", \"er.OrdinalIgnoreCase); }\\n```\\n\\n| Method        | Runtime   | Mean     |   Ratio |\\n|---------------|--\", \"---------|----------|---------|\\n| SortedSetCopy | .NET 6.0  | 2.397 us |    1    |\\n| SortedSetCopy |\", \" .NET 7.0  | 2.090 us |    0.87 |\\n\\nOne last PR to look at in collections: dotnet/runtime#67923. Cond\", \"itionalWeakTable&lt;TKey, TValue&gt; is a collection most developers haven't used, but when you need\", \" it, you need it. It's used primarily for two purposes: to associate additional state with some obje\", \"ct, and to maintain a weak collection of objects. Essentially, it's a thread -safe dictionary that d\", \"oesn't maintain strong references to anything it stores but ensures that the value associated with a\", \" key will remain rooted as long as the associated key is rooted. It exposes many of the same APIs as\", \" ConcurrentDictionary&lt;,&gt; , but for adding items to the collection, it's historically only had \", \"an Add method. That means if the design of the consuming code entailed trying to use the collection \", \"as a set, where duplicates were common, it would also be common to experience exceptions when trying\", \" to Add an item that already existed in the collection. Now in .NET 7, it has a TryAdd method, which\", \" enables such usage without potentially incurring the costs of such exceptions (and without needing \", \"to add try/catch blocks to defend against them).\\n\\n## LINQ\\n\\nLet's move on to Language -Integrated Que\", \"ry (LINQ). LINQ is a productivity feature that practically every .NET developer uses. It enables oth\", \"erwise complicated operations to be trivially expressed, whether via language-integrated query compr\", \"ehension syntax or via direct use of methods on System.Linq.Enumerable . That productivity and expre\", \"ssivity, however, comes at a bit of an overhead cost. In the vast majority of situations, those cost\", \"s (such as delegate and closure allocations, delegate invocations, use of interface methods on arbit\", \"rary enumerables vs direct access to indexers and Length / Count properties, etc.) don't have a sign\", \"ificant impact, but for really hot paths, they can and do show up in a meaningful way. This leads so\", \"me folks to declare LINQ as being broadly off-limits in their codebases. From my perspective, that's\", \" misguided; LINQ is extremely useful and has its place. In .NET itself, we use LINQ, we're just prac\", \"tical and thoughtful about where, avoiding it in code paths we've optimized to be light weight and f\", \"ast due to expectations that such code paths could matter to consumers. And as such, while LINQ itse\", \"lf may not perform as fast as a hand-rolled solution, we still care a lot about the performance of L\", \"INQ's implementation, so that it can be used in more and more places, and so that where it's used th\", \"ere's as little overhead as possible. There are also differences between operations in LINQ; with ov\", \"er 200 overloads providing various kinds of functionality, some of these overloads benefit from more\", \" performance tuning than do others, based on their expected usage.\\n\\ndotnet/runtime#64470 is the resu\", \"lt of analyzing various real-world code bases for use of Enumerable.Min and Enumerable.Max , a nd se\", \"eing that it's very common to use these with arrays, often ones that are quite large. This PR update\", \"s the Min&lt;T&gt;(IEnumerable&lt;T&gt;) and Max&lt;T&gt;(IEnumerable&lt;T&gt;) overloads when the i\", \"nput is an int[] or long[] to vectorize the processing, using Vector&lt;T&gt; . The net effect of th\", \"is is significantly faster execution time for larger arrays, but still improved performance even for\", \" short arrays (because the implementation is now able to access the array directly rather than going\", \" through the enumerable, leading to less allocation and interface dispatch and more applicable optim\", \"izations like inlining).\\n\\n```\\n[Params(4, 1024)] public int Length { get ; set ; } private IEnumerabl\", \"e<int> _source; [GlobalSetup] public void Setup() => _source = Enumerable.Range(1, Length).ToArray()\", \"; [Benchmark] public int Min() => _source.Min(); [Benchmark] public int Max() => _source.Max();\\n```\\n\", \"\\n| Method   | Runtime   |   Length | Mean         |   Ratio | Allocated   |   Alloc Ratio |\\n|-------\", \"---|-----------|----------|--------------|---------|-------------|---------------|\\n| Min      | .NET\", \" 6.0  |        4 | 26.167 ns    |    1    | 32 B        |             1 |\\n| Min      | .NET 7.0  |  \", \"      4 | 4.788 ns     |    0.18 | -           |             0 |\\n| Max      | .NET 6.0  |        4 |\", \" 25.236 ns    |    1    | 32 B        |             1 |\\n| Max      | .NET 7.0  |        4 | 4.234 ns\", \"     |    0.17 | -           |             0 |\\n| Min      | .NET 6.0  |     1024 | 3,987.102 ns |   \", \" 1    | 32 B        |             1 |\\n| Min      | .NET 7.0  |     1024 | 101.830 ns   |    0.03 | -\", \"           |             0 |\\n| Max      | .NET 6.0  |     1024 | 3,798.069 ns |    1    | 32 B      \", \"  |             1 |\\n| Max      | .NET 7.0  |     1024 | 100.279 ns   |    0.03 | -           |      \", \"       0 |\\n\\nOne of the more interesting aspects of the PR, however, is one line that's meant to help\", \" with the non -array cases. In performance optimization, and in particular when adding 'fast paths' \", \"to better handle certain cases, there's almos t always a winner and a loser: the winner is the case \", \"the optimization is intended to help, and the loser is every other case that's penalized by whatever\", \" checks are necessary to determine whether to take the improved path. An optimization that special-c\", \"ases arrays might normally look like:\\n\\n```\\nif (source is int[] array) { ProcessArray(array); } else \", \"{ ProcessEnumerable(source); }\\n```\\n\\nHowever, if you look at the PR, you'll see the if condition is a\", \"ctually:\\n\\n```\\nif (source.GetType() == typeof\\n```\\n\\n```\\n(int[]))\\n```\\n\\nHow come? Well at this point in \", \"the code flow, we know that source isn't null, so we don't need the extra null check that is will br\", \"ing. However, that's minor compared to the real impact here, that of support for array covariance. I\", \"t might surprise you to learn that there are types beyond int[] that will satisfy a source is int ch\", \"eck\\u2026 try running Console.WriteLine((object)new uint[42] is int[]); , and you'll find it prints out T\", \"rue . (This is also a rare case where the .NET runtime and C# the language disagree on aspects of th\", \"e type system. If you change that\\n\\nConsole.WriteLine((object)new uint[42] is int[]); to instead be C\", \"onsole.WriteLine(new uint[42] is int[]); , i.e. remove the (object) cast, you'll find it starts prin\", \"ting out False instead of True . That's because the C# compiler believes it's impossible for a uint[\", \"] to ever be an int[] , and thus optimizes the check away entirely to be a constant false .) Thus th\", \"e runtime is having to do more work as part of the type check than just a simple comparison against \", \"the known type identity of\\n\\nint[] . We can see this by looking at the assembly generated for these t\", \"wo methods (the latter assumes we've already null -checked the input, which is the case in these LIN\", \"Q methods):\\n\\n```\\npublic IEnumerable<object> Inputs { get ; } = new [] { new object() }; [Benchmark] \", \"[ArgumentsSource(nameof(Inputs))] public bool M1(object o) => o is int[]; [Benchmark] [ArgumentsSour\", \"ce(nameof(Inputs))] public bool M2(object o) => o.GetType() == typeof (int[]);\\n```\\n\\nThis results in:\", \"\\n\\n```\\n; Program.M1(System.Object) sub       rsp,28 mov       rcx,offset MT_System.Int32[] call      \", \"qword ptr [System.Runtime.CompilerServices.CastHelpers.IsInstanceOfAny(Void*, System.Object)] test  \", \"    rax,rax setne     al movzx     eax,al add       rsp,28 ret ; Total bytes of code 34\\n```\\n\\n```\\n; P\", \"rogram.M2(System.Object) mov       rax,offset MT_System.Int32[] cmp       [rdx],rax sete      al mov\", \"zx     eax,al ret ; Total bytes of code 20\\n```\\n\\nNote the former involves a method call to the JIT's \", \"CastHelpers.IsInstanceOfAny helper method, and that it's not inlined. That in turn impacts performan\", \"ce:\\n\\n```\\nprivate IEnumerable<int> _source = (int[])(object) new uint[42]; [Benchmark(Baseline = true\", \" )] public bool WithIs() => _source is int[]; [Benchmark] public bool WithTypeCheck() => _source.Get\", \"Type() == typeof (int[]);\\n```\\n\\n| Method        | Mean      |   Ratio | Code Size   |\\n|--------------\", \"-|-----------|---------|-------------|\\n| WithIs        | 1.9246 ns |   1     | 215 B       |\\n| WithT\", \"ypeCheck | 0.0013 ns |   0.001 | 24 B        |\\n\\nOf course, these two operations aren't semantically \", \"equivalent, so if this was for something that required the semantics of the former, we couldn't use \", \"the latter. But in the case of this LINQ performance optimization, we can choose to only optimize th\", \"e int[] case, forego the super rare case\\n\\nof the int[] actually being a uint[] (or e.g. DayOfWeek[] \", \"), and minimize the performance penalty of the optimization for IEnumerable&lt;int&gt; inputs other \", \"than int[] to just a few quick instructions.\\n\\nThis improvement was built upon further in dotnet/runt\", \"ime#64624, which expands the input types supported and the operations that take advantage. First, it\", \" introduced a private helper for extracting a ReadOnlySpan&lt;T&gt; from certain types of IEnumerabl\", \"e&lt;T&gt; inputs, namely today those inputs that are actually either a T[] or a List&lt;T&gt; ; as \", \"with the previous PR, it uses the GetType() == typeof(T[]) form to avoid significantly penalizing ot\", \"her inputs. Both of these types enable extracting a ReadOnlySpan&lt;T&gt; for the actual storage, in\", \" the case of T[] via a cast and in the case of List&lt;T&gt; via the CollectionsMarshal.AsSpan metho\", \"d that was introduced in .NET 5. Once we have that span, we can do a few interesting things. This PR\", \":\\n\\n- Expands the previous Min&lt;T&gt;(IEnumerable&lt;T&gt;) and Max&lt;T&gt;(IEnumerable&lt;T&gt;) \", \"optimizations to not only apply to int[] and long[] but also to List&lt;int&gt; and List&lt;long&gt;\", \" .\\n- Uses direct span access for Average&lt;T&gt;(IEnumerable&lt;T&gt;) and Sum&lt;T&gt;(IEnumerable\", \"&lt;T&gt;) for T being int , long , float , double , or decimal , all for arrays and lists.\\n- Simila\", \"rly uses direct span access for Min&lt;T&gt;(IEnumerable&lt;T&gt;) and Max&lt;T&gt;(IEnumerable&lt;T\", \"&gt;) for T being float , double , and decimal .\\n- Vectorizes Average&lt;int&gt;(IEnumerable&lt;int&\", \"gt;) for arrays and lists\\n\\nThe effect of that is evident in microbenchmarks, e.g.\\n\\n```\\nprivate stati\", \"c float[] CreateRandom() { var r = new Random(42); var results = new float[10_000]; for (int i = 0; \", \"i < results.Length; i++) { results[i] = (float)r.NextDouble(); } return results; } private IEnumerab\", \"le<float> _floats = CreateRandom(); [Benchmark] public float Sum() => _floats.Sum(); [Benchmark] pub\", \"lic float Average() => _floats.Average(); [Benchmark] public float Min() => _floats.Min(); [Benchmar\", \"k] public float Max() => _floats.Max();\\n```\\n\\n| Method   | Runtime   | Mean      |   Ratio | Allocate\", \"d   |   Alloc Ratio |\\n|----------|-----------|-----------|---------|-------------|---------------|\\n|\", \" Sum      | .NET 6.0  | 39.067 us |    1    | 32 B        |             1 |\\n| Sum      | .NET 7.0  |\", \" 14.349 us |    0.37 | -           |             0 |\\n| Average  | .NET 6.0  | 41.232 us |    1    | \", \"32 B        |             1 |\\n\\n| Method   | Runtime   | Mean      |   Ratio | Allocated   |   Alloc \", \"Ratio |\\n|----------|-----------|-----------|---------|-------------|---------------|\\n| Average  | .N\", \"ET 7.0  | 14.378 us |    0.35 | -           |             0 |\\n| Min      | .NET 6.0  | 45.522 us |  \", \"  1    | 32 B        |             1 |\\n| Min      | .NET 7.0  | 9.668 us  |    0.21 | -           | \", \"            0 |\\n| Max      | .NET 6.0  | 41.178 us |    1    | 32 B        |             1 |\\n| Max  \", \"    | .NET 7.0  | 9.210 us  |    0.22 | -           |             0 |\\n\\nThe previous LINQ PRs were ex\", \"amples from making existing operations faster. But sometimes performance improvements come about fro\", \"m new APIs that can be used in place of previous ones in certain situations to further improve perfo\", \"rmance. One such example of that comes from new APIs introduced in dotnet/runtime#70525 from [@deepr\", \"obin](https://github.com/deeprobin) which were then improved in dotnet/runtime#71564. One of the mos\", \"t popular methods in LINQ is Enumerable.OrderBy (and its inverse OrderByDescending ), which enables \", \"creating a sorted copy of the input enumerable. To do so, the caller passes a Func&lt;TSource,TKey&g\", \"t; predicate to OrderBy which OrderBy uses to extract the co mparison key for each item. However, it\", \"'s relatively common to want to sort items with themselves as the keys; this is, after all, the defa\", \"ult for methods like Array.Sort , and in such cases callers of OrderBy end up passing in an identity\", \" function, e.g. OrderBy(x =&gt; x) . To eliminate that cruft, .NET 7 introduces the new Order and Or\", \"derDescending methods, which, in the spirit of pairs like Distinct and DistinctBy , perform that sam\", \"e sorting operation, just with an implicit x =&gt; x done on behalf of the caller. But beyond perfor\", \"mance, a nice benefit of this is the implementation then knows that the keys will all be the same as\", \" the inputs, and it no longer needs to invoke the callback for each item to retrieve its key nor all\", \"ocate a new array to store those keys. Thus if you find yourself using LINQ and reaching for OrderBy\", \"(x =&gt; x) , consider instead using Order() and reaping the (primarily allocation) benefits:\\n\\n```\\n[\", \"Params(1024)] public int Length { get ; set ; } private int[] _arr; [GlobalSetup] public void Setup(\", \") => _arr = Enumerable.Range(1, Length).Reverse().ToArray(); [Benchmark(Baseline = true )] public vo\", \"id OrderBy() { foreach (int _ in _arr.OrderBy(x => x)) { } } [Benchmark] public void Order() { forea\", \"ch (int _ in _arr.Order()) { } }\\n```\\n\\n| Method   |   Length | Mean     |   Ratio | Allocated   |   A\", \"lloc Ratio |\\n|----------|----------|----------|---------|-------------|---------------|\\n| OrderBy  |\", \"     1024 | 68.74 us |    1    | 12.3 KB     |          1    |\\n| Order    |     1024 | 66.24 us |   \", \" 0.96 | 8.28 KB     |          0.67 |\\n\\n## File I/O\\n\\n.NET 6 saw some huge file I/O improvements, in p\", \"articular a complete rewrite of FileStream . While .NET 7 doesn't have any single changes on that sc\", \"ale, it does have a significant number of improvements that measurably 'move the needle,' and in var\", \"iety of ways.\\n\\nOne form of performance improvement that also masquerades as a reliability improvemen\", \"t is increasing responsiveness to cancellation requests. The faster something can be canceled, the s\", \"ooner the system is able to give back valuable resources in use, and the sooner things waiting for t\", \"hat operation to complete are able to be unblocked. There have been several improvements of this ilk\", \" in .NET 7.\\n\\nIn some cases, it comes from adding cancelable overloads where things weren't previousl\", \"y cancelabl e at all. That's the case for dotnet/runtime#61898 from [@bgrainger](https://github.com/\", \"bgrainger), which added new cancelable overloads of TextReader.ReadLineAsync and TextReader.ReadToEn\", \"dAsync , and that includes overrides of these methods on StreamReader and StringReader ; dotnet/runt\", \"ime#64301 from [@bgrainger](https://github.com/bgrainger) then overrode these methods (and others mi\", \"ssing overrides) on the NullStreamReader type returned from TextReader.Null and StreamReader.Null (i\", \"nterestingly, these were defined as two different types, unnecessarily, and so this PR also unified \", \"on just having both use the StreamReader variant, as it satisfies the required types of both). You c\", \"an see this put to good use in dotnet/runtime#66492 from [@lateapexearlyspeed](https://github.com/la\", \"teapexearlyspeed), which adds a new File.ReadLinesAsync method. This produces an IAsyncEnumerable&lt\", \";string&gt; of the lines in the file, is based on a simple loop around the new StreamReader.ReadLine\", \"Async overload, and is thus itself fully cancelable.\\n\\nFrom my perspective, though, a more interestin\", \"g form of this is when an existing overload is purportedly cancelable but isn't actually. For exampl\", \"e, the base Stream.ReadAsync method just wraps the Stream.BeginRead / EndRead methods, which aren't \", \"cancelable, so if a Stream -derived type doesn't override ReadAsync , attempts to cancel a call to i\", \"ts ReadAsync will be minimally effective. It does an up-front check for cancellation, such that if c\", \"ancellation was requested prior to the call being made, it will be immediately canceled, but after t\", \"hat check the supplied CancellationToken is effectively ignored. Over time we've tried to stamp out \", \"all remaining such cases, but a few stragglers have remained. One pernicious case has been with pipe\", \"s. For this discussion, there are two relevant kinds of pipes, anonymous and named, which are repres\", \"ented in .NET as pairs of streams:\\n\\nAnonymousPipeClientStream / AnonymousPipeServerStream and\\n\\nNamed\", \"PipeClientStream / NamedPipeServerStream . Also, on Windows, the OS makes a distinction between hand\", \"les opened for synchronous I/O from handles opened for overlapped I/O (aka asynchronous I/O), and th\", \"is is reflected in the .NET API: you can open a named pipe for synchronous or overlapped I/O based o\", \"n the PipeOptions.Asynchronous option specified at construction. And, on\\n\\n<!-- image -->\\n\\nUnix, name\", \"d pipes, contrary to their naming, are actually implemented on top of Unix domain sockets. Now some \", \"history:\\n\\n- .NET Framework 4.8: No cancellation support. The pipe Stream -derived types didn't even \", \"override ReadAsync or WriteAsync , so all they got was the default up-front check for cancellation a\", \"nd then the token was ignored.\\n- .NET Core 1.0: On Windows, with a named pipe opened for asynchronou\", \"s I/O, cancellation was fully supported. The implementation would register with the CancellationToke\", \"n , and upon a cancellation request, would use CancelIoEx for the NativeOverlapped* associated with \", \"the asynchronous operation. On Unix, with named pipes implemented in terms of sockets, if the pipe w\", \"as opened with PipeOptions.Asynchronous , the implementation would simulate cancellation via polling\", \": rather than simply issuing the Socket.ReceiveAsync / Socket.SendAsync (which wasn't cancelable at \", \"the time), it would queue a work item to the ThreadPool , and that work item would run a polling loo\", \"p, making Socket.Poll calls with a small timeout, checking the token, and then looping around to do \", \"it again until either the Poll indicated the operation would succeed or cancellation was requested. \", \"On both Windows and Unix, other than a named pipe opened with Asynchronous , after the operation was\", \" initated, cancellation was a nop.\\n- .NET Core 2.1: On Unix, the implementation was improved to avoi\", \"d the polling loop, but it still lacked a truly cancelable Socket.ReceiveAsync / Socket.SendAsync . \", \"Instead, by this point Socket.ReceiveAsync supported zero-byte reads, where a caller could pass a ze\", \"ro-length buffer to ReceiveAsync and use that as notification for data being available to consume wi\", \"thout actually consuming it. The Unix implementation for asynchronous named pipe streams then change\", \"d to issue zero-byte reads, and would await a Task.WhenAny of both that operation's task and a task \", \"that would be completed when cancellation was requested. Better, but still far from ideal.\\n- .NET Co\", \"re 3.0: On Unix, Socket got truly cancelable ReceiveAsync and SendAsync methods, which asynchronous \", \"named pipes were updated to utilize. At this point, the Windows and Unix implementations were effect\", \"ively on par with regards to cancellation; both good for asynchronous named pipes, and just posing f\", \"or everything else.\\n- .NET 5: On Unix, SafeSocketHandle was exposed and it became possible to create\", \" a Socket for an arbitrary supplied SafeSocketHandle , which enabled creating a Socket that actually\", \" referred to an anonymous pipe. This in tern enabled every PipeStream on Unix to be implemented in t\", \"erms of Socket , which enabled ReceiveAsync / SendAsync to be fully cancelable for both anonymous an\", \"d named pipes, regardless of how they were opened.\\n\\nSo by .NET 5, the problem was addressed on Unix,\", \" but still an issue on Windows. Until now. In .NET 7, we've made the rest of the operations fully ca\", \"ncelable on Windows as well, thanks to dotnet/runtime#72503 (and a subsequent tweak in dotnet/runtim\", \"e#72612 ). Windows doesn't support overlapped I/O for anonymous pipes today, so for anonymous pipes \", \"and for named pipes opened for synchronous I/O, the Windows implementation would just delegate to th\", \"e base Stream implementation, which would queue a work item to the ThreadPool to invoke the synchron\", \"ous counterpart, just on another thread. Instead, the implementations now queue that work item, but \", \"instead of just calling the synchronous method, it does some pre- and post- work that registers for \", \"cancellation, passing in the thread ID of the thread that's about to perform the I/O. If cancellatio\", \"n is requested, the implementation then uses CancelSynchronousIo to interrupt it. There's a race con\", \"dition here, in that the moment the thread registers for cancellation, cancellation could be request\", \"ed, such that CancelSynchronousIo could be called before the operation is actually initiated.\\n\\nSo, t\", \"here's a small spin loop employed, where if cancellation is requested between the time registration \", \"occurs and the time the synchronous I/O is actually performed, the cancellation thread will spin unt\", \"il the I/O is initiated , but this condition is expected to be exceedingly rare. There's also a race\", \" condition on the other side, that of CancelSynchronousIo being requested after the I/O has already \", \"completed; to address that race, the implementation relies on the guarantees made by CancellationTok\", \"enRegistration.Dispose , which promises that the associated callback will either never be invoked or\", \" will already have fully completed executing by the time Dispose returns. Not only does this impleme\", \"ntation complete the puzzle such that all asynchronous read/write operations on both anonymous and n\", \"amed pipes on both Windows and Unix are cancelable, it also actually improves normal throughput.\\n\\n``\", \"`\\nprivate Stream _server; private Stream _client; private byte[] _buffer = new byte[1]; private Canc\", \"ellationTokenSource _cts = new CancellationTokenSource(); [Params( false , true )] public bool Cance\", \"lable { get ; set ; } [Params( false , true )] public bool Named { get ; set ; } [GlobalSetup] publi\", \"c void Setup() { if (Named) { string name = Guid.NewGuid().ToString(\\\"N\\\"); var server = new NamedPipe\", \"ServerStream(name, PipeDirection.Out); var client = new NamedPipeClientStream(\\\".\\\", name, PipeDirecti\", \"on.In); Task.WaitAll(server.WaitForConnectionAsync(), client.ConnectAsync()); _server = server; _cli\", \"ent = client; } else { var server = new AnonymousPipeServerStream(PipeDirection.Out); var client = n\", \"ew AnonymousPipeClientStream(PipeDirection.In, server.ClientSafePipeHandle); _server = server; _clie\", \"nt = client; } } [GlobalCleanup] public void Cleanup() { _server.Dispose(); _client.Dispose(); } [Be\", \"nchmark(OperationsPerInvoke = 1000)] public async Task ReadWriteAsync() { CancellationToken ct = Can\", \"celable ? _cts.Token : default ; for (int i = 0; i < 1000; i++) {\\n```\\n\\n```\\nValueTask<int> read = _cl\", \"ient.ReadAsync(_buffer, ct); await _server.WriteAsync(_buffer, ct); await read; } }\\n```\\n\\n| Method   \", \"      | Runtime   | Cancelable   | Named   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|---\", \"-------------|-----------|--------------|---------|----------|---------|-------------|--------------\", \"-|\\n| ReadWriteAsync | .NET 6.0  | False        | False   | 22.08 us |    1    | 400 B       |       \", \"   1    |\\n| ReadWriteAsync | .NET 7.0  | False        | False   | 12.61 us |    0.76 | 192 B       |\", \"          0.48 |\\n| ReadWriteAsync | .NET 6.0  | False        | True    | 38.45 us |    1    | 400 B \", \"      |          1    |\\n| ReadWriteAsync | .NET 7.0  | False        | True    | 32.16 us |    0.84 |\", \" 220 B       |          0.55 |\\n| ReadWriteAsync | .NET 6.0  | True         | False   | 27.11 us |   \", \" 1    | 400 B       |          1    |\\n| ReadWriteAsync | .NET 7.0  | True         | False   | 13.29 \", \"us |    0.52 | 193 B       |          0.48 |\\n| ReadWriteAsync | .NET 6.0  | True         | True    |\", \" 38.57 us |    1    | 400 B       |          1    |\\n| ReadWriteAsync | .NET 7.0  | True         | Tr\", \"ue    | 33.07 us |    0.86 | 214 B       |          0.54 |\\n\\nThe rest of the performance-focused chan\", \"ges around I/O in .NET 7 were primarily focused on one of two things: reducing syscalls, and reducin\", \"g allocation.\\n\\nSeveral PRs went into reducing syscalls on Unix as part of copying files, e.g. File.C\", \"opy and FileInfo.CopyTo . dotnet/runtime#59695 from [@tmds](https://github.com/tmds) reduced overhea\", \"ds in several ways. The code had been performing a stat call in order to determine up front whether \", \"the source was actually a directory, in which case the operation would error out. Instead, the PR si\", \"mply tries to open the source file, which it would need to do anyway for the copy operation, and the\", \"n it only performs that stat if opening the file fails. If opening the file succeeds, the code was a\", \"lready performing an fstat to gather data on the file, such as whether it was seekable; with this ch\", \"ange, it now also extracts from the results of that single fstat the source file size, which it then\", \" threads through to the core copy routine, which itself is then able to avoid an fstat syscall it ha\", \"d been performing in order to get the size. Saving those syscalls is great, in particular for very s\", \"mall files where the overhead of setting up the copy can actually be more expensive than the actual \", \"copy of the bytes. But the biggest benefit of this PR is that it takes advantage of IOCTL-FICLONERAN\", \"GE on Linux. Some Linux file sys tems, like XFS and Btrfs, support 'copy -onwrite,' which means that\", \" rather than copying all of the data to a new file, the file system simply notes that there are two \", \"different files pointing to the same data, sharing the underlying storage. This makes the 'copy' sup\", \"er fast, since nothing actually needs to be copied and instead the file system just needs to update \", \"some bookkeeping; plus, less space is consumed on disk, since there's just a single store of the dat\", \"a. The file system then only needs to actuall y copy data that's overwritten in one of the files. Th\", \"is PR uses ioctl and FICLONE to perform the copy as copy-on-write if the source and destination file\", \" system are the same and the file system supports the operation. In a similar vein, dotnet/runtime#6\", \"4264 from [@tmds](https://github.com/tmds) further improves File.Copy / FileInfo.CopyTo by utilizing\", \" copy\\\\_file\\\\_range on Linux if it's supported (and only if it's a new enough kerne l that it address\", \"es\\n\\nsome issues the function had in previous releases). Unlike a typical read/write loop that reads \", \"the data from the source and then writes it to the destination, copy\\\\_file\\\\_range is implemented to \", \"stay entirely in kernel mode, without having to transition to user space for each read and write.\\n\\nA\", \"nother example of avoiding syscalls comes for the File.WriteXx and File.AppendXx methods when on Uni\", \"x. The implementation of these methods opens a FileStream or a SafeFileHandle directly, and it was s\", \"pecifying FileOptions.SequentialScan . SequentialScan is primarily relevant for reading data from a \", \"file, and hints to OS caching to expect data to be read from the file sequentially rather than rando\", \"mly. However, these write/append methods don't read, the y only write, and the implementation of Fil\", \"eOptions.SequentialScan on Unix requires an additional syscall via posix\\\\_fadvise (passing in POSIX\\\\\", \"_FADV\\\\_SEQUENTIAL ); thus, we're paying for a syscall and not benefiting from it. This situation is \", \"akin to the famou s Henny Youngman joke: 'The patient says, 'Doctor, it hurts when I do this'; the d\", \"octor says, 'Then don't do that!'.' Here, too, the answer is 'don't do that,' and so dotnet/runtime#\", \"59247 from [@tmds](https://github.com/tmds) simply stops passing SequentialScan in places where it w\", \"on't help but may hurt.\\n\\nDirectory handling has seen reduced syscalls across the directory lifecycle\", \", especially on Unix. dotnet/runtime#58799 from [@tmds](https://github.com/tmds) speeds up directory\", \" creation on Unix. Previously, the implementation of directory creation would first check to see if \", \"the directory already existed, which involves a syscall. In the expected minority case where it alre\", \"ady existed the code could early exit out. But in the expected more common case where the directory \", \"didn't exist, it would then parse the file path to find all of the directories in it, walk up the di\", \"rectory list until it found one that did exist, and then try to create all of the subdirectories bac\", \"k down through the target one. However, the expected most common case is the parent directories alre\", \"ady exist and the child directory doesn't, in which case we're still pa ying for all that parsing wh\", \"en we could have just created the target directory. This PR addresses that by changing the up-front \", \"existence check to instead simply try to mkdir the target directory; if it succeeds, great, we're do\", \"ne, and if it fails, the err or code from the failure can be used instead of the existence check to \", \"know whether mkdir failed because it had no work to do. dotnet/runtime#61777 then takes this a step \", \"further and avoids string allocations while creating directories by using stack memory for the paths\", \" temporarily needed to pass to mkdir .\\n\\ndotnet/runtime#63675 then improves the performance of moving\", \" directories, on both Unix and Windows, removing several syscalls. The shared code for Directory.Mov\", \"e and DirectorInfo.MoveTo was doing explicit directory existence checks for the source and destinati\", \"on locations, but on Windows the Win32 API called to perform the move d oes such checks itself, so t\", \"hey're not needed preemptively. On Unix, we can similarly avoid the existence check for the source d\", \"irectory, as the rename function called will similarly simply fail if the source doesn't exist (with\", \" an appropriate error that l et's us deduce what went wrong so the right exception can be thrown), a\", \"nd for the destination, the code had been issuing separate existence checks for whether the destinat\", \"ion existed as a directory or as a file, but a single stat call suffices for both.\\n\\n```\\nprivate stri\", \"ng _path1; private string _path2; [GlobalSetup] public void Setup() { _path1 = Path.GetTempFileName(\", \"); _path2 = Path.GetTempFileName();\\n```\\n\\n```\\nFile.Delete(_path1); File.Delete(_path2); Directory.Cre\", \"ateDirectory(_path1); } [Benchmark] public void Move() { Directory.Move(_path1, _path2); Directory.M\", \"ove(_path2, _path1); }\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Rati\", \"o |\\n|----------|-----------|----------|---------|-------------|---------------|\\n| Move     | .NET 6.\", \"0  | 31.70 us |    1    | 256 B       |             1 |\\n| Move     | .NET 7.0  | 26.31 us |    0.83 \", \"| -           |             0 |\\n\\nAnd then also on Unix, dotnet/runtime#59520 from [@tmds](https://gi\", \"thub.com/tmds) improves directory deletion, and in particular recursive deletion (deleting a directo\", \"ry and everything it contains and everything they contain and so on), by utilizing the information a\", \"lready provided by the file system enumeration to avoid a secondary existence check.\\n\\nSyscalls were \", \"also reduced as part of support for memory-mapped files. dotnet/runtime#63754 takes advantage of spe\", \"cial-casing to do so while opening a MemoryMappedFile . When MemoryMappedFile.CreateFromFile was cal\", \"led, one of the first things it would do is call File.Exists to determine w hether the specified fil\", \"e already exists; that's because later in the method as part of dealing with errors and exceptions, \", \"the implementation needs to know whether to delete the file that might then exist; the implementatio\", \"n constructs a FileStream , and doing might will the specified file into existence. However, that on\", \"ly happens for some FileMode values, which is configurable via an argument passed by callers of Crea\", \"teFromFile . The common and default value of FileMode is FileMode.Open , which requires that the fil\", \"e exist such that constructing the FileStream will throw if it doesn't. That means we only actually \", \"need to call File.Exists if the FileMode is something other than Open or CreateNew , which means we \", \"can trivially avoid the extra system call in the majority case. dotnet/runtime#63790 also helps here\", \", in two ways. First, throughout the CreateFromFile operation, the implementation might access the F\", \"ileStream 's Length multiple times, but each call results in a syscall to read the underlying length\", \" of the file. We can instead read it once and use that one value for all of the various checks perfo\", \"rmed. Second, .NET 6 introduced the File.OpenHandle method which enables opening a file handle / fil\", \"e descriptor directly into a SafeFileHandle , rather than having to go through FileStream to do so. \", \"The use of the FileStream in MemoryMappedFile is actually quite minimal, and so it makes sense to ju\", \"st use the SafeFileHandle directly rather than also constructing the superfluous FileStream and its \", \"supporting state. This helps to reduce allocations.\\n\\nFinally, there's dotnet/runtime#63794, which re\", \"cognizes that a MemoryMappedViewAccessor or MemoryMappedViewStream opened for readonly access can't \", \"have been written to. Sounds obvious, but the practical implication of this is that closing either n\", \"eedn't bother flushing, since that view couldn't have changed any data in the implementation, and fl\", \"us hing a view can be relatively expensive, especially for larger views. Thus, a simple change to av\", \"oid flushing if the view isn't writable can yield a measurable improvement to MemoryMappedViewAccess\", \"or / MemoryMappedviewStream 's Dispose .\\n\\n```\\nprivate string _path; [GlobalSetup] public void Setup(\", \") { _path = Path.GetTempFileName(); File.WriteAllBytes(_path, Enumerable.Range(0, 10_000_000).Select\", \"(i => (byte)i).ToArray()); } [GlobalCleanup] public void Cleanup() { File.Delete(_path); } [Benchmar\", \"k] public void MMF() { using var mmf = MemoryMappedFile.CreateFromFile(_path, FileMode.Open, null );\", \" using var s = mmf.CreateViewStream(0, 10_000_000, MemoryMappedFileAccess.Read); }\\n```\\n\\n| Method   |\", \" Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|----------|-----------|----------|-\", \"--------|-------------|---------------|\\n| MMF      | .NET 6.0  | 315.7 us |    1    | 488 B       | \", \"         1    |\\n| MMF      | .NET 7.0  | 227.1 us |    0.68 | 336 B       |          0.69 |\\n\\nBeyond \", \"system calls, there have also been a plethora of improvements around reducing allocation. One such c\", \"hange is dotnet/runtime#58167, which improved the performance of the commonly-used File.WriteAllText\", \"{Async} and File.AppendAllText{Async} methods. The PR recognizes two things: one, that these operati\", \"ons are common enough that it's worth avoiding the small -butmeasurable overhead of going through a \", \"FileStream and instead just going directly to the underlying SafeFileHandle , and, two, that since t\", \"he methods are passed the entirety of the payload to output, the implementation can use that knowled\", \"ge (in particular for length) to do better than the StreamWriter that was previously employed. In do\", \"ing so, the implementation avoids the overheads (primarily in allocation) of the streams and writers\", \" and temporary buffers.\\n\\n```\\nprivate string _path; [GlobalSetup] public void Setup() => _path = Path\", \".GetRandomFileName(); [GlobalCleanup] public void Cleanup() => File.Delete(_path); [Benchmark] publi\", \"c void WriteAllText() => File.WriteAllText(_path, Sonnet);\\n```\\n\\n| Method       | Runtime   | Mean   \", \"  |   Ratio | Allocated   |   Alloc Ratio |\\n|--------------|-----------|----------|---------|-------\", \"------|---------------|\\n| WriteAllText | .NET 6.0  | 488.5 us |    1    | 9944 B      |          1  \", \"  |\\n| WriteAllText | .NET 7.0  | 482.9 us |    0.99 | 392 B       |          0.04 |\\n\\ndotnet/runtime#\", \"61519 similarly updates File.ReadAllBytes{Async} to use SafeFileHandle (and RandomAccess ) directly \", \"rather than going through FileStream , shaving off some allocation from each use. It also makes the \", \"same SequentialScan change as mentioned earlier. While this case is about reading (whereas the previ\", \"ous change saw SequentialScan being complete overhead with no benefit), ReadAllBytes{Async} is very \", \"frequently used to read smaller files where the overhead of the additional syscall can measure up to\", \" 10% of the total cost (and for larger files, modern kernels are pretty good about caching even with\", \"out a sequentiality hint, so there's little downside measured there).\\n\\nAnother such change is dotnet\", \"/runtime#68662, which improved Path.Join 's handling of null or empty path segments. Path.Join has o\", \"verloads that accept string s and overloads that accept ReadOnlySpan&lt;char&gt; s, but all of the o\", \"verloads produce string s. The string -based overloads just wrapped each string in a span and delega\", \"ted to the span-based overloads. However, in the event that the join operation is a nop (e.g. there \", \"are two path segments and the second is empty so the join should just return the first), the spanbas\", \"ed implementation still needs to create a new string (there's no way for the ReadOnlySpan&lt;char&gt\", \"; -based overloads to extract a string from the span). As such, the string -based overloads can do a\", \" little bit better in the case of one of them being null or empty; they can do the same thing the Pa\", \"th.Combine overloads do, which is to have the M argument overload delegate to the M-1 argument overl\", \"oad, filtering out a null or empty, and in the base case of the overload with two arguments, if a se\", \"gment is null or empty, the other (or empty) can just be returned directly.\\n\\nBeyond that, there are \", \"a multitude of allocation-focused PRs, such as dotnet/runtime#69335 from [@pedrobsaila](https://gith\", \"ub.com/pedrobsaila) which adds a fast-path based on stack allocation to the internal ReadLink helper\", \" that's used on Unix anywhere we need to follow symlinks, or dotnet/runtime#68752 that updates Named\", \"PipeClientStream.ConnectAsync to remove a delegate allocation (by passing state into a Task.Factory.\", \"StartNew call explicitly), or dotnet/runtime#69412 which adds an optimized Read(Span&lt;byte&gt;) ov\", \"erride to the Stream returned from Assembly.GetManifestResourceStream .\\n\\nBut my personal favorite im\", \"provement in this area come from dotnet/runtime#69272, which adds a few new helpers to Stream :\\n\\n```\", \"\\npublic void ReadExactly(byte[] buffer, int offset, int count); public void ReadExactly(Span<byte> b\", \"uffer); public ValueTask ReadExactlyAsync(byte[] buffer, int offset, int count, CancellationToken ca\", \"ncellationToken = default ); public ValueTask ReadExactlyAsync(Memory<byte> buffer, CancellationToke\", \"n cancellationToken = default ); public int ReadAtLeast(Span<byte> buffer, int minimumBytes, bool th\", \"rowOnEndOfStream = true ); public ValueTask<int> ReadAtLeastAsync(Memory<byte> buffer, int minimumBy\", \"tes, bool throwOnEndOfStream = true , CancellationToken cancellationToken = default );\\n```\\n\\nIn fairn\", \"ess, these are more about usability than they are about performance, but in this case there's a tigh\", \"t correlation between the two. It's very common to write these helpers one's self (the aforementione\", \"d PR deleted many open-coded loops for this functionality from across the core libraries) as the fun\", \"ctionality is greatly needed, and it's unfortunat ely easy to get them wrong in ways\\n\\nthat negativel\", \"y impact performance, such as by using a Stream.ReadAsync overload that needs to allocate a returned\", \" Task&lt;int&gt; or reading fewer bytes than is allowed as part of a read call. These implementation\", \"s are correct and efficient.\\n\\n## Compression\\n\\n.NET Core 2.1 added support for the Brotli compression\", \" algorithm, surfacing it in two ways: BrotliStream and the pair of BrotliEncoder / BrotliDecoder str\", \"ucts that BrotliStream is itself built on top of. For the most part, these types just provide wrappe\", \"rs around a native C implementation from google/brotli, and so while the .NET layer has the opportun\", \"ity to improve how data is moved around, managed allocation, and so on, the speed and quality of the\", \" compression itself are largely at the mercy of the C implementation and the intricacies of the Brot\", \"li algorithm.\\n\\nAs with many compression algorithms, Brotli provides a knob that allows for a quintes\", \"sential tradeoff to be made between compression speed (how fast data can be compressed) and compress\", \"ion quality/ratio (how small can the compressed output be made). The hand-wavy idea is the more time\", \" the algorithm spends looking for opportunity, the more space can be saved. Many algorithms expose t\", \"his as a numerical dial, in Brotli's case going from 0 (fastest speed, least compression) to 11 (spe\", \"nd as much time as is needed to minimize the output size). But while BrotliEncoder surfaces that sam\", \"e range, BrotliStream 's surface area is simpler: most use j ust specifies that compression should b\", \"e performed (e.g. new BrotliStream(destination, CompressionMode.Compress) ) and the only knob availa\", \"ble is via the CompressionLevel enum (e.g. new BrotliStream(destination, CompressionLevel.Fastest) )\", \", which provides just a few options: CompressionLevel.NoCompression , CompressionLevel.Fastest , Com\", \"pressionLevel.Optimal , and CompressionLevel.SmallestSize . This means the BrotliStream implementati\", \"on needs to select a default value when no CompressionLevel is specified and needs to map Compressio\", \"nLevel to an underlying numerical value when one is.\\n\\nFor better or worse (and I'm about to argue 'm\", \"uch worse'), the native C implementation its elf defines the default to be 11 (google/brotli#encode.\", \"h ), and so that's what BrotliStream has ended up using when no CompressionLevel is explicitly speci\", \"fied. Further, the CompressionLevel.Optimal enum value is poorly named. It's intended to represent a\", \" good default that's a balanced tradeoff between speed and quality; that's exactly what it means for\", \" DeflateStream , GZipStream , and ZLibStream . But for BrotliStream , as the default it similarly go\", \"t translated to mean the underlying native library's default, which is 11. This means that when cons\", \"tructing a BrotliStream with either CompressionMode.Compress or CompressionLevel.Optimal , rather th\", \"an getting a nice balanced default, you're getting the dial turned all the way up to 11.\\n\\nIs that so\", \" bad? Maybe compression quality is the most important thing? For example, reducing the size of data \", \"can make it faster to then transmit it over a wire, and with a slow connection, size then meaningful\", \"ly translates into end-to-end throughput.\\n\\nThe problem is just how much this extra effort costs. Com\", \"pression speed and ratio are highly dependent on the data being compressed, so take this example wit\", \"h a small grain of salt as it's not entirely representative of all use, but it's good enough for our\", \" purposes. Consider this code, which\\n\\nuses BrotliEncoder to compress the The Complete Works of Willi\", \"am Shakespeare from Project Gutenberg at varying levels of compression:\\n\\n```\\nusing System.Buffers; u\", \"sing System.Diagnostics; using System.IO.Compression; using System.Text; using var hc = new HttpClie\", \"nt(); byte[] data = await hc.GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-8\\\"); Co\", \"nsole.WriteLine(data.Length); var compressed = new MemoryStream(); var sw = new Stopwatch(); for (in\", \"t level = 0; level <= 11; level++) { const int Trials = 10; compressed.Position = 0; Compress(level,\", \" data, compressed); sw.Restart(); for (int i = 0; i < Trials; i++) { compressed.Position = 0; Compre\", \"ss(level, data, compressed); } sw.Stop(); Console.WriteLine($\\\"{level},{sw.Elapsed.TotalMilliseconds \", \"/ Trials},{compressed.Position}\\\"); static void Compress(int level, byte[] data, Stream destination) \", \"{ var encoder = new BrotliEncoder(quality: level, window: 22); Write( ref encoder, data, destination\", \", false ); Write( ref encoder, Array.Empty<byte>(), destination, true ); encoder.Dispose(); static v\", \"oid Write( ref BrotliEncoder encoder, byte[] data, Stream destination, bool isFinalBlock) { byte[] o\", \"utput = ArrayPool<byte>.Shared.Rent(4096); OperationStatus lastResult = OperationStatus.DestinationT\", \"ooSmall; ReadOnlySpan<byte> buffer = data; while (lastResult == OperationStatus.DestinationTooSmall)\", \" { lastResult = encoder.Compress(buffer, output, out int bytesConsumed, out int bytesWritten, isFina\", \"lBlock); if (lastResult == OperationStatus.InvalidData) throw new InvalidOperationException(); if (b\", \"ytesWritten > 0) destination.Write(output.AsSpan(0, bytesWritten)); if (bytesConsumed > 0) buffer = \", \"buffer.Slice(bytesConsumed); } ArrayPool<byte>.Shared.Return(output); }\\n```\\n\\n3,000,000.00\\n\\n2,000,000\", \".00\\n\\n1,500,000.00\\n\\n1,000,000.00\\n\\n500,000.00\\n\\n0.00\\n\\n}\\n\\n}\\n\\nO..\\n\\nThe code is measuring how long it take\", \"s to compress the input data at each of the levels (doing a warmup and then averaging several iterat\", \"ions), timing how long it takes and capturing the resulting compressed data size. For the size, I ge\", \"t values like this:\\n\\n|   Level | Size (bytes)   |\\n|---------|----------------|\\n|       0 | 2,512,855\", \".00   |\\n|       1 | 2,315,466.00   |\\n|       2 | 2,224,638.00   |\\n|       3 | 2,218,328.00   |\\n|    \", \"   4 | 2,027,153.00   |\\n|       5 | 1,964,810.00   |\\n|       6 | 1,923,456.00   |\\n|       7 | 1,889,\", \"927.00   |\\n|       8 | 1,863,988.00   |\\n|       9 | 1,846,685.00   |\\n|      10 | 1,741,561.00   |\\n| \", \"     11 | 1,702,214.00   |\\n\\n4\\n\\n6\\n\\n8\\n\\n10\\n\\n12\\n\\n<!-- image -->\\n\\nThat's a fairly liner progression from \", \"least to most compression. That's not the problem. This is the problem:\\n\\nSize (bytes)\\n\\n000OI\\n\\n0008\\n\\n\", \"0009\\n\\n000 \\u2022\\n\\n000Z\\n\\n|   Level | Time (ms)   |\\n|---------|-------------|\\n|       0 | 24.11       |\\n|  \", \"     1 | 36.67       |\\n|       2 | 64.13       |\\n|       3 | 73.72       |\\n|       4 | 146.41      |\", \"\\n|       5 | 257.12      |\\n|       6 | 328.54      |\\n|       7 | 492.81      |\\n|       8 | 702.38   \", \"   |\\n|       9 | 892.08      |\\n|      10 | 4,830.32    |\\n|      11 | 10,634.88   |\\n\\nOI\\n\\n-O......\\n\\n8\\n\", \"\\n<!-- image -->\\n\\nThis chart shows an almost exponential increase in processing time as we near the u\", \"pper end of the dial, with quality level 11 compressing ~33% better than quality level 0 but taking \", \"~440x as long to achieve that. If that's what a developer wants, they can specify CompressionLevel.S\", \"mallestSize , but that cost by default and for the balanced CompressionLevel.Optimal is far out of w\", \"hack.\\n\\ndotnet/runtime#72266 fixes that. A very small change, it simply makes CompressMode.Compress a\", \"nd CompressionLevel.Optimal for Brotli map to quality level 4, which across many kinds of inputs doe\", \"s represent a fairly balanced trade-off between size and speed.\\n\\n) \\u044d\\u0448!|\\n\\n........\\n\\n```\\nprivate byte[\", \"] _data = new HttpClient().GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-8\\\").Resul\", \"t; private Stream _output = new MemoryStream(); [Benchmark] public void Compress() { _output.Positio\", \"n = 0; using var brotli = new BrotliStream(_output, CompressionMode.Compress, leaveOpen: true ); bro\", \"tli.Write(_data); }\\n```\\n\\n| Method   | Runtime   | Mean       |   Ratio |\\n|----------|-----------|---\", \"---------|---------|\\n| Compress | .NET 6.0  | 9,807.0 ms |    1    |\\n| Compress | .NET 7.0  | 133.1 \", \"ms   |    0.01 |\\n\\nOther improvements have gone into compression, such as dotnet/runtime#69439 which \", \"updates the internal ZipHelper.AdvanceToPosition function used by ZipArchive to reuse a buffer on ev\", \"ery iteration of a loop rather than allocating a new buffer for each iteration, dotnet/runtime#66764\", \" which uses spans judiciously to avoid a bunch of superfluous string and string[] allocations from S\", \"ystem.IO.Packaging , and dotnet/runtime#73082 updating the zlib implementations shipped as part of .\", \"NET from v1.2.11 (which was released in January 2017) to v1.2.12 (which was released in March 2022).\", \"\\n\\n## Networking\\n\\nNetworking is the life-blood of almost every service, with performance being critic\", \"al to success. In previous releases, a lot of effort was focused on the lower layers of the networki\", \"ng stack, e.g. .NET 5 saw a significant investment in improving the performance of sockets on Linux.\", \" In .NET 7, much of the effort is above sockets.\\n\\nThat said, there were some interesting performance\", \" improvements in sockets itself for .NET 7. One of the more interesting is dotnet/runtime#64770, whi\", \"ch revamped how some synchronization is handled inside of SocketsAsyncEventArgs . As background, in \", \"the early days of networking in .NET Framework, asynchrony was enabled via Begin / End methods (the \", \"'APM' pattern). This pattern is not only complicated to use well, it's relatively inefficient, resul\", \"ting in allocation for every single operation performed (at a minimum for the IAsyncResult object th\", \"at's returned from the BeginXx method). To help make networking operations more efficient, SocketsAs\", \"yncEventArgs was introduced. SocketsAsyncEventArgs is a reusable class you allocate to hold all of t\", \"he state associated with asynchronous operations: allocate one, pass it to various async methods (e.\", \"g. ReceiveAsync ), and then completion events are raised on the SocketAsyncEventArgs instance when t\", \"he operation completes. It can be quite efficient when used correctly, but it' s also complicated to\", \" use correctly. In subsequent releases, Task -based and ValueTask -based APIs were released; these h\", \"ave the efficiency of SocketAsyncEventArgs and the ease-of-use of async/await , and are the recommen\", \"ded starting point for all Socket -based asynchronous programming today. They have the efficiency of\", \" SocketAsyncEventArgs becaus e they're actually implemented as a thin veneer on top of it under the \", \"covers, and so while most code these days isn't written to use SocketAsyncEventArgs directly, it's s\", \"till very relevant from a performance perspective.\\n\\nSocketAsyncEventArgs on Windows is implemented t\", \"o use winsock and overlapped I/O. When you call an async method like ValueTask&lt;Socket&gt; Socket.\", \"AcceptAsync(CancellationToken) , that grabs an internal SocketAsyncEventArgs and issues an AcceptAsy\", \"nc on it, which in turn gets a NativeOverlapped* from the ThreadPoolBoundHandle associated with the \", \"socket, and uses it to issue the native AcceptEx call. When that handle is initially created, we set\", \" the\\n\\nFILE\\\\_SKIP\\\\_COMPLETION\\\\_PORT\\\\_ON\\\\_SUCCESS completion notification mode on the socket; use of t\", \"his was introduced in earlier releases of .NET Core, and it enables a significant number of socket o\", \"perations, in particular sends and receives, to complete synchronously, which in turn saves unnecess\", \"ary trips through the thread pool, unnecessary unwinding of async state machines, and so on. But it \", \"also causes a condundrum. There are some operations we want to perform associated with asynchronous \", \"operation but that have additional overhead, such as registering for the cancellation of those opera\", \"tions, and we don't wan t to pay the cost of doing them if the operation is going to complete synchr\", \"onously. That means we really want to delay performing such registration until after we've made the \", \"native call and discovered the operation didn't complete synchronously\\u2026 but at t hat point we've alr\", \"eady initiated the operation, so if it doesn't complete synchronously, then we're now in\\n\\n<!-- image\", \" -->\\n\\na potential race condition, where our code that's still setting up the asynchronous operation \", \"is racing with it potentially completing in a callback on another thread. Fun. SocketAsyncEventArgs \", \"handled this race condition with a spin lock; the theory was that contention would be incredibly rar\", \"e, as the vast majority cases would either be the operation completing synchronously (in which case \", \"there's no other thread involved) or asynchronously with enough of a delay that the small amount of \", \"additional work performed by the initiating thread would have long ago completed by the time the asy\", \"nchronous operation completed. And for the most part, that was true. However, it turns out that it's\", \" actually much more common than expected for certain kinds of operations, like Accepts. Accepts end \", \"up almost always completing asynchronously, but if there's already a pending connection, completing \", \"asynchronously almost immediately, which then induces this race condition to happen more frequently \", \"and results in more contention on the spin locks. Contention on a spin lock is something you really \", \"want to avoid. And in fact, for a particular benchmark, this spin lock showed up as the cause for an\", \" almost 300% slowdown in requests-per-second (RPS) for a benchmark that used a dedicated connection \", \"per request (e.g. with every response setting 'Connection: close'). dotnet/runtime#64770 changed the\", \" synchronization mechanism to no longer involve a spin lock; instead, it maintains a simple gate imp\", \"lemented as an Interlocked.CompareExchange . If the initiating thread gets to the gate first, from t\", \"hat point on the operation is considered asynchronous and any additional work is handled by the comp\", \"leting callback. Conversely, if the callback gets to the gate first, the initiating thread treats th\", \"e operation as if it completed synchronously. This not only avoids one of the threads spinning while\", \" waiting for the other to make forward progress, it also increases the number of operations that end\", \" up being handled as synchronous, which in turn reduces other costs (e.g. the code await ing the tas\", \"k returned from this operation doesn't n eed to hook up a callback and exit, and can instead itself \", \"continue executing synchronously). The impact of this is difficult to come up with a microbenchmark \", \"for, but it can have meaningful impact for loaded Windows servers that end up accepting significant \", \"numbers of connections in steady state.\\n\\nA more-easily quantifiable change around sockets is dotnet/\", \"runtime#71090, which improves the performance of SocketAddress.Equals . A SocketAddress is the seria\", \"lized form of an EndPoint , with a byte[] containing the sequence of bytes that represent the addres\", \"s. Its Equals method, used to determine whether to SocketAddress instances are the same, looped over\", \" that byte[] byte-by-byte. Not only is such code gratuitous when there are now helpers available lik\", \"e SequenceEqual for comparing spans, doing it byte-by-byte is also much less efficient than the vect\", \"orized implementation in SequenceEqual . Thus, this PR simply replaced the open-coded comparison loo\", \"p with a call to SequenceEqual .\\n\\n```\\nprivate SocketAddress _addr = new IPEndPoint(IPAddress.Parse(\\\"\", \"123.123.123.123\\\"), 80).Serialize(); private SocketAddress _addr_same = new IPEndPoint(IPAddress.Pars\", \"e(\\\"123.123.123.123\\\"), 80).Serialize(); [Benchmark] public bool Equals_Same() => _addr.Equals(_addr_s\", \"ame);\\n```\\n\\n| Method      | Runtime   | Mean      |   Ratio |\\n|-------------|-----------|-----------|\", \"---------|\\n| Equals_Same | .NET 6.0  | 57.659 ns |    1    |\\n| Equals_Same | .NET 7.0  | 4.435 ns  |\", \"    0.08 |\\n\\nLet's move up to some more interesting changes in the layers above Sockets , starting wi\", \"th SslStream .\\n\\nOne of the more impactful changes to SslStream on .NET 7 is in support for TLS resum\", \"ption on Linux. When a TLS connection is established, the client and server engage in a handshake pr\", \"otocol where they collaborate to decide on a TLS version and cipher suites to use, authenticate and \", \"validate each other's identity, and create symmetric encryption keys for use after the handshake. Th\", \"is represents a significant portion of the time required to establish a new connection. For a client\", \" that might disconnect from a server and then reconnect later, as is fairly common in distributed ap\", \"plications, TLS resumption allows a client and server to essentially pick up where they left off, wi\", \"th the client and/or server storing some amount of information about recent connections and using th\", \"at information to resume. Windows SChannel provides default support for TLS resumption, and thus the\", \" Windows implementation of SslStream (which is built on SChannel) has long had support for TLS resum\", \"ption. But OpenSSL's model requires additional code to enable TLS resumption, and such code wasn't p\", \"resent in the Linux implementation of SslStream . With dotnet/runtime#57079 and dotnet/runtime#63030\", \", .NET 7 adds server-side support for TLS resumption (using the variant that doesn't require storing\", \" recent connection state on the server), and with dotnet/runtime#64369, .NET 7 adds client-side supp\", \"ort (which does require storing additional state). The effect of this is significant, in particular \", \"for a benchmark that opens and closes lots of connections between clients.\\n\\n```\\nprivate NetworkStrea\", \"m _client, _server; private readonly byte[] _buffer = new byte[1]; private readonly SslServerAuthent\", \"icationOptions _options = new SslServerAuthenticationOptions { ServerCertificateContext = SslStreamC\", \"ertificateContext.Create(GetCertificate(), null ), }; [GlobalSetup] public void Setup() { using var \", \"listener = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); listener.Bin\", \"d( new IPEndPoint(IPAddress.Loopback, 0)); listener.Listen(1); var client = new Socket(AddressFamily\", \".InterNetwork, SocketType.Stream, ProtocolType.Tcp); client.Connect(listener.LocalEndPoint); _server\", \" = new NetworkStream(listener.Accept(), ownsSocket: true ); _client = new NetworkStream(client, owns\", \"Socket: true ); } [GlobalCleanup] public void Cleanup() { _client.Dispose(); _server.Dispose(); } [B\", \"enchmark] public async Task Handshake() { using var client = new SslStream(_client, leaveInnerStream\", \"Open: true , delegate { return\\n```\\n\\n```\\ntrue ; }); using var server = new SslStream(_server, leaveIn\", \"nerStreamOpen: true , delegate { return true ; }); await Task.WhenAll( client.AuthenticateAsClientAs\", \"ync(\\\"localhost\\\", null , SslProtocols.None, checkCertificateRevocation: false ), server.AuthenticateA\", \"sServerAsync(_options)); await client.WriteAsync(_buffer); await server.ReadAsync(_buffer); await se\", \"rver.WriteAsync(_buffer); await client.ReadAsync(_buffer); } private static X509Certificate2 GetCert\", \"ificate() => new X509Certificate2( Convert.FromBase64String(\\\"MIIUmgIBAzCCFFYGCSqGSIb3DQEHAaCCFEcEghR\", \"DMIIUPzCCCiAGCSqGSIb3DQEHA aCCChEEggoNMIIKCTCCCgUGCyqGSIb3DQEMCgECoIIJfjCCCXowHAYKKoZIhvcNAQwBAzAOBA\", \"hCAauyUWggWwICB9AE gglYefzzX/jx0b+BLU/TkAVj1KBpojf0o6qdTXV42drqIGhX/k1WwF1ypVYdHeeuDfhH2eXHImwPTw+0b\", \"ACY0dSiIHK ptm0sb/MskoGI8nlOtHWLi+QBirJ9LSUZcBNOLwoMeYLSFEWWBT69k/sWrc6/SpDoVumkfG4pZ02D9bQgs1+k8fpZ\", \"jZ GoZp1jput8CQXPE3JpCsrkdSdiAbWdbNNnYAy4C9Ej/vdyXJVdBTEsKzPYajAzo6Phj/oS/J3hMxxbReMtj2Z0QkoBB VMc70\", \"d+DpAK5OY3et872D5bZjvxhjAYh5JoVTCLTLjbtPRn1g7qh2dQsIpfQ5KrdgqdImshHvxgL92ooC1eQVqQffMn Z0/LchWNb2rMD\", \"a89K9CtAefEIF4ve2bOUZUNFqQ6dvd90SgKq6jNfwQf/1u70WKE86+vChXMMcHFeKso6hTE9+/zuUP NVmbRefYAtDd7ng996S15\", \"FNVdxqyVLlmfcihX1jGhTLi//WuMEaOfXJ9KiwYUyxdUnMp5QJqO8X/tiwnsuhlFe3NKMX Y77jUe8F7I+dv5cjb9iKXAT+q8oYx\", \"1LcWu2mj1ER9/b2omnotp2FIaJDwI40Tts6t4QVH3bUNE9gFIfTMK+WMgKBz/J AGvC1vbPSdFsWIqwhl7mEYWx83HJp/+Uqp5f+\", \"d8m4phSan2rkHEeDjkUaoifLWHWDmL94SZBrgU6yGVK9dU82kr7jCS UTrnga8qDYsHwpQ22QZtu0aOJGepSwZU7NZNMiyX6QR2h\", \"I0CNMjvTK2VusHFB+qnvw+19DzaDT6P0KNPxwBwp07KMQm 3HWTRNt9u6gKUmo5FHngoGte+TZdY66dAwCl0Pt+p1v18XlOB2KOQ\", \"ZKLXnhgikjOwYQxFr3oTb2MjsP6YqnSF9EpYpm iNySXiYmrYxVinHmK+5JBqoQCN2C3N24slZkYq+AYUTnNST7Ib2We3bBICOFd\", \"VUgtFITRW40T+0XZnIv8G1Kbaq/1av fWI/ieKKxyiYp/ZNXaxc+ycgpsSsAJEuhb83bUkSBpGg9PvFEF0DXm4ah67Ja1SSTmvrC\", \"nrOsWZXIpciexMWRGoKrdv d7Yzj9E8hiu+CGTC4T6+7FxVXJrjCg9zU9G2U6g7uxzoyjGj1wqkhxgvl9pPbz6/KqDRLOHCEwRF4\", \"qlWXhsJy4levxG tifFt6n7DWaNSsOUf8Nwpi+d4fd7LQ7B5tW/y+/vVZziORueruCWO4LnfPhpJ70g18uyN7KyzrWy29rpE46rf\", \"jZGGt0 WDZYahObPbw6HjcqSOuzwRoJMxamQb2qsuQnaBS6Bhb5PAnY4SEA045odf/u9uC7mLom2KGNHHz6HrgEPas2UHoJLux Y\", \"vY1pza/29akuVQZQUvMA5yMFHHGYZLtTKtCGdVGwX0+QS6ovpV93xux4I/5TrD5U8z9RmTdAx03R3MUhkHF7Zbv5eg DNsVar+41\", \"YWG4VkV1ZXtsZRKJf0hvKNvrpH0e7fVKBdXljm5PXOSg2VdtkhhOpnKKSMcv6MbGWVi/svWLnc7Qim4A4M Daz+bFVZmh3oGJ7WH\", \"vRQhWIcHUL+YJx+064+4IKXZJ/2a/+b2o7C8mJ3GGSBx831ADogg6MRWZx3UY19OZ8YMvpzmZE BRZZnm4KgNpj+SQnf6pGzD2cm\", \"nRhzG60LSNPb17iKbdoUAEMkgt2tlMKXpnt1r7qwsIoTt407cAdCEsUH7OU/AjfFmS kKJZ7vC5HweqZPnhgJgZ6LYHlfiRzUR1x\", \"eDg8JG0nb0vb7LUE4nGPy39/TxIGos7WNwGpG1QVL/8pKjFdjwREaR8e5C STlQ7gxHV+G3FFvFGpA1p8cRFzlgE6khDLrSJIUkh\", \"kHMA3oFwwAzBNIKVXjToyxCogDqxWya0E1Hw5rVCS/zOCS1De2 XQbXs//g46TW0wTJwvgNbs0xLShf3XB+23meeEsMTCR0+igtM\", \"MMsh5K/vBUGcJA27ru/KM9qEBcseb/tqCkhhsdj1dn H0HDmpgFf5DfVrjm+P6ickcF2b+Ojr9t7XHgFszap3COpEPGmeJqNOUTu\", \"U53tu/O774IBgqINMWvvG65yQwsEO06jRr FPRUGb0eH6UM4vC7wbKajnfDuI/EXSgvuOSZ9wE8DeoeK/5We4pN7MSWoDl39gI/L\", \"BoNDKFYEYuAw/bhGp8nOwDKki4 a16aYcBGRClpN3ymrdurWsi7TjyFHXfgW8fZe4jXLuKRIk19lmL1gWyD+3bT3mkI2cU2OaY2C\", \"0fVHhtiBVaYbxBV8+k jK8q0Q70zf0r+xMHnewk9APFqUjguPguTdpCoH0VAQST9Mmriv/J12+Y+fL6H+jrtDY2zHPxTF85pA4bB\", \"BnLA7Qt9TK Ce6uuWu5yBqxOV3w2Oa4Pockv1gJzFbVnwlEUWnIjbWVIyo9vo4LBd03uJHPPIQbUp9kCP/Zw+Zblo42/ifyY+a+s\", \"cw l1q1dZ7Y0L92yJCKm9Qf6Q+1PBK+uU9pcuVTg/Imqcg5T7jFO5QCi88uwcorgQp+qoeFi0F9tnUecfDl6d0PSgAPnX9 XA0ny\", \"3bPwSiWOA8+uW73gesxnGTsNrtc1j85tail8N6m6S2tHXwOmM65J4XRZlzzeM4D/Rzzh13xpRA9kzm9T2cSHsX EYmSW1X7Wovrm\", \"YhdOh9K3DPwSyG4tD58cvC7X79UbOB+d17ieo7ZCj+NSLVQO1BqTK0QfErdoVHGKfQG8Lc/ERQRqj1 32Mhi2/r5Ca7AWdqD7/3w\", \"gRdQTJSFXt/akpM44xu5DMTCISEFOLWiseSOBtzT6ssaq2Q35dCkXp5wVbWxkXAD7Gm34F FXXyZrJWAx45Y40wj/0KDJoEzXCuS\", \"4Cyiskx1EtYNNOtfDC5wngywmINFUnnW0NkdKSxmDJvrT6HkRKN8ftik7tP4Zv TaTS28Z0fDmWJ+RjvZW+vtF6mrIzYgGOgdpZw\", \"G0ZOSKrXKrY3xpMO16fXyawFfBosLzCty7uA57niPS76UXdbplgPan IGFyceTg1MsNDsd8vszXd4KezN2VMaxvw+93s0Uk/3Mc+\", \"5MAj+UhXPi5UguXMhNo/CU7erzyxYreOlAI7ZzGhPk+oT9 g/MqWa5RpA2IBUaK/wgaNaHChfCcDj/J1qEl6YQQboixxp1IjQxiV\", \"9bRQzgwf31Cu2m/FuHTTkPCdxDK156pyFdhcgT pTNy7RPLDF0MBMGCSqGSIb3DQEJFTEGBAQBAAAAMF0GCSsGAQQBgjcRATFQHk\", \"4ATQBpAGMAcgBvAHMAbwBmAHQAIABT AHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgBhAHAAaABpAGMAIABQAHIAbwB2AGkAZ\", \"ABlAHIwggoXBgkqhkiG9w0 BBwagggoIMIIKBAIBADCCCf0GCSqGSIb3DQEHATAcBgoqhkiG9w0BDAEGMA4ECH63Q8xWHKhqAgIH\", \"0ICCCdDAo9x82r wRM6s16wMo01glVedahn1COCP1FKmP6lQ3kjcHruIWlcKW+eCUpt41qs0LM3iFcPQj5x7675DeLL0AC2Ebu7J\", \"hg0FGM JZwHLbmJLyG0VSb1WhX2UfxNSdLrdZv8pmejB7DYdV3xAj8DBCRGfwwnbTQjFH9wUPga5U79Dvpqq+YVvUEEci1N6tT P\", \"u32LOOEvjoEtpskrHoKyqLGV7sSgM6xMIDcfVWbLb8fDcVS1JQRHbeOdGClFMDjwzr+eGWd+OyOZ6BydUGjIKAZpRp\\n```\\n\\n<!--\", \" image -->\\n\\n| Method    | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|----------\", \"-|-----------|----------|---------|-------------|---------------|\\n| Handshake | .NET 6.0  | 4.647 ms\", \" |     1   | 19.27 KB    |           1   |\\n| Handshake | .NET 7.0  | 2.314 ms |     0.5 | 9.56 KB   \", \"  |           0.5 |\\n\\nAnother significant improvement for SslStream in .NET 7 is support for OCSP sta\", \"pling. When a client handshakes with the server and the server shares its certificate, a client that\", \" cares about validating it's talking to exactly who it intended to talk to needs to validate that ce\", \"rtificate. In the days of yore, such validation was done with certificate revocation lists (CRL), wh\", \"ere periodically the client would download a giant list of certificates known to be revoked. Online \", \"Certificate Status Protocol (OCSP) is a newer protocol and mechanism that enables a client to get re\", \"al-time information about a certificate; while the client handshakes with the server and the server \", \"sends the client its certificate, the client then connects to an 'OCSP responder' and sends it a req\", \"uest to determine whether the certi ficate is considered good. OCSP has multiple issues of its own, \", \"however. In particular, it places a significant load on these OCSP responder servers, with every cli\", \"ent making a real-time request to it about every certificate encountered, and also potentially signi\", \"ficantly increasing the time it takes the client to establish a connection. OCSP stapling offers a s\", \"olution to this. Rather than a client issuing a request to\\n\\nthe OCSP responder, the server itself co\", \"ntacts the OCSP responder and gets a signed ticket from the OCSP responder stating that the server's\", \" certificate is good and will be for some period of time. When a client handshakes with the server, \", \"the server can then 'staple' (include) this signed ticket as part of its response to the client, giv\", \"ing the validation to the client directly rather than the client needing to make a separate roundtri\", \"p to the OCSP responder. This reduces overheads for everyone involved. dotnet/runtime#67011 adds sup\", \"port for OCSP stapling to SslStream client usage on Linux, with dotnet/runtime#69833 adding the Linu\", \"x server-side counterpart, and dotnet/runtime#71570 adds client-side support for Windows.\\n\\nThe afore\", \"mentioned changes are primarily about the performance of opening a connection. Additional work has b\", \"een done to improve that further in other ways. dotnet/runtime#69527 gets rid of allocations associa\", \"ted with several SafeHandle instances that were being created unnecessarily on Linux as part of esta\", \"blishing a TLS connection. This highlights the benefits of doing profiling on multiple platforms, as\", \" while these SafeHandle s were necessary in the Windows implementation, they were fairly meaningless\", \" in the Linux implementation (due to differences between SChannel and OpenSSL), and were only brough\", \"t along for the ride because of how the platform-abstraction layer (PAL) was defined to reuse most o\", \"f the SslStream code across platforms. And dotnet/runtime#68188 avoids several collections allocated\", \" as part of the TLS handshake. This one is particularly interesting as it's come up multiple times i\", \"n the past in various libraries. Imagine you have a lazily initialized property like this:\\n\\n```\\npriv\", \"ate List<T>? _items;\\n```\\n\\n```\\npublic List<T> Items => _items ??= new List<T>();\\n```\\n\\nAnd then some c\", \"ode in the same implementation comes along and wants to read the contents of these items. That code \", \"might look like:\\n\\n```\\nif\\n```\\n\\n```\\n(Items.Count > 0) { ... }\\n```\\n\\nbut the very act of accessing Items\", \" just to check its count forces the collection into existence (with a 0 Count ). If the code instead\", \" checks:\\n\\n```\\nif (_items is\\n```\\n\\n```\\nList<T> items && items.Count > 0) { ... }\\n```\\n\\nIt can save that\", \" unnecessary collection allocation. The approach is made even simpler with C# pattern matching:\\n\\n```\", \"\\nif (_items is\\n```\\n\\n```\\n{ Count: > 0 }) items) { ... }\\n```\\n\\nThis is one of those things that's incre\", \"dibly obvious once you 'see' it and realize what's happening, but you often miss until it jumps out \", \"at you in a profiler.\\n\\ndotnet/runtime#69098 is another good example of how profiling can lead to ins\", \"ights about allocations that can be removed. Application-Layer Protocol Negotation (ALPN) allows cod\", \"e establishing a TLS connection to piggy-back on the roundtrips that are being used for the TLS hand\", \"shake anyway to negotiate some higher-level protocol that will end up being used as well. A very com\", \"mon use-case, for example, is for an HTTPS client/server to negotiate which version of HTTP should b\", \"e used. This information is exposed from SslStream as an SslApplicationProtocol struct returned from\", \" its NegotiatedApplicationProtocol property, but as the actual negotiated protocol can be arbitrary \", \"data, SslApplicationProtocol just wraps a byte[] . The implementation had been\\n\\ndutifully allocating\", \" a byte[] to hold the bytes passed around as part of ALPN, since we need such a byte[] to store in t\", \"he SslApplicationProtocol . But while the byte data can be arbitrary, in practice by far the most co\", \"mmon byte sequences are equivalent to 'http/1.1' for HTTP/1.1, 'h2' for HTTP/2, and 'h3' for HTTP/3.\", \" Thus, it makes sense to special -case those values and use a reusable cached byte[] singleton when \", \"one of those values is needed. If SslApplicationProtocol exposed the underlying byte[] directly to c\", \"onsumers, we'd be hesitant to use such si ngletons, as doing so would mean that if code wrote into t\", \"he byte[] it would potentially be changing the value for other consumers in the same process. Howeve\", \"r, SslApplicationProtocol exposes it as a ReadOnlyMemory&lt;byte&gt; , which is only mutable via uns\", \"afe code (using the\\n\\nMemoryMarshal.TryGetArray method), and once you're employing unsafe code to do \", \"'bad' things,\\\" all bets are off anyway. dotnet/runtime#63674 also removes allocations related to ALP\", \"N, in this case avoiding the need for a byte[] allocation on Linux when setting the negotiated proto\", \"col on a client SslStream . It uses stack memory instead of an array allocation for protocols up to \", \"256 bytes in length, which is way larger than any in known use, and thus doesn't bother to do anythi\", \"ng fancy for the fallback path, which will never be used in practice. And dotnet/runtime#69103 furth\", \"er avoids ALPNrelated allocations and work on Windows by entirely skipping some unnecessary code pat\", \"hs: various methods can be invoked multiple times during a TLS handshake, but even though the ALPN-r\", \"elated work only needed to happen once the first time, the code wasn't special -casing it and was in\", \"stead repeating the work over and over.\\n\\nEverything discussed thus far was about establishing connec\", \"tions. What about the performance of reading and writing on that connection? Improvements have been \", \"made there, too, in particular around memory management and asynchrony. But first we need some conte\", \"xt.\\n\\nWhen async/await were first introduced, Task and Task&lt;TResult&gt; were the only game in town\", \"; while the patternbased mechanism the compiler supports for arbitrary 'task -like' types enabled as\", \"ync methods to return other types, in practice it was only tasks (which also followed our guidance).\", \" We soon realized, however, that a significant number of calls to a significant number of commonly-u\", \"sed async APIs would actually complete synchronously. Consider, for example, a method like MemoryStr\", \"eam.ReadAsync : MemoryStream is backed entirely by an in-memory buffer, so even though the operation\", \" is 'async,' every call to it completes synchronously, as the operation can be performed without doi\", \"ng any potentially long-running I/O. Or consider FileStream.ReadAsync . By default FileStream employ\", \"s its own internal buffer. If you issue a call to FileStream.ReadAsync with your own buffer and ask \", \"for only, say, 16 bytes, under the covers FileStream.ReadAsync will issue the actual native call wit\", \"h its own much larger buffer, which by default is 4K. The first time you issue your 16-byte read, ac\", \"tual I/O will be required and the operation is likely to complete asynchronously. But the next 255 c\", \"alls you make could simply end up draining the remainder of the data read into that 4K buffer, in wh\", \"ich case 255 of the 256 'async' operations actually complete synchronously. If the method returns a \", \"Task&lt;int&gt; , every one of those 255 synchronously-completing calls could still end up allocatin\", \"g a Task&lt;int&gt; , just to hand back the int that's already known. Various techniques were devise\", \"d to minimize this, e.g. if the int is one of a few well-known values (e.g. -1 through 8), then the \", \"async method infrastructure will hand back a pre-allocated and cached Task&lt;int&gt; instance for t\", \"hat value, and various stream implementations (including FileStream ) would cache the previouslyretu\", \"rned Task&lt;int&gt; and hand it back for the next call as well if the next call yielded exactly the\", \" same number of bytes. But those optimizations don't fully mitigate the issue. Instead, we introduce\", \"d the ValueTask&lt;TResult&gt; struct and provided the necessary 'builder' t o allow async methods t\", \"o return\\n\\nthem. ValueTask&lt;TResult&gt; was simply a discrimated union between a TResult and Task&l\", \"t;TResult&gt; . If an async method completed asynchronously (or if it failed synchronously), well, i\", \"t would simply allocate the Task&lt;TResult&gt; as it otherwise would have and return that task wrap\", \"ped in a ValueTask&lt;TResult&gt; . But if the method actually completed synchronously and successfu\", \"lly, it would create a ValueTask&lt;TResult&gt; that just wrapped the resulting TResult , which then\", \" eliminates all allocation overhead for the synchronouslycompleting case. Yay, everyone's happy. Wel\", \"l, almost everyone. For really hot paths, especially those lower down in the stack that many other c\", \"ode paths build on top of, it can also be beneficial to avoid the allocations even for the asynchron\", \"ously completing case. To address that, .NET Core 2.1 saw the introduction of the\\n\\nIValueTaskSource&\", \"lt;TResult&gt; interface along with enabling ValueTask&lt;TResult&gt; to wrap an instance of that in\", \"terface in addition to a TResult or a Task&lt;TResult&gt; (at which point it also became meaningful \", \"to introduce a non-generic ValueTask and the associated IValueTaskSource ). Someone can implement th\", \"is interface with whatever behaviors they want, although we codified the typical implementation of t\", \"he core async logic into the ManualResetValueTaskSourceCore helper struct, which is typically embedd\", \"ed into some object, with the interface methods delegating to corresponding helpers on the struct. W\", \"hy would someone want to do this? Most commonly, it's to be able to reuse the same instance implemen\", \"ting this interface over and over and over. So, for example, Socket exposes a ValueTask&lt;int&gt; R\", \"eceiveAsync method, and it caches a single instance of an IValueTaskSource&lt;int&gt; implementation\", \" for use with such receives. As long as you only ever have one receive pending on a given socket at \", \"a time (which is the 99.999% case), every ReceiveAsync call will either return a ValueTask&lt;int&gt\", \"; wrapped around an int value or a ValueTask&lt;int&gt; wrapped around that reusable IValueTaskSourc\", \"e&lt;int&gt; , making all use of ReceiveAsync ammortized allocation-free (there is another instance \", \"used for SendAsync , such that you can have a concurrent read and write on the socket and still avoi\", \"d allocations). However, implementing this support is still nontrivial, and can be super hard when d\", \"ealing with an operation that's composed of multiple suboperations, which is exactly where async/awa\", \"it shine. Thus, C# 10 added support for overriding the default builder that's used on an individual \", \"asyn c method (e.g. such that someone could provide their own builder for a ValueTask&lt;int&gt; -re\", \"turning method instead of the one that allocates Task&lt;int&gt; instances for asynchronous completi\", \"on) and .NET 6 included the new\\n\\nPoolingAsyncValueTaskMethodBuilder and PoolingAsyncValueTaskMethodB\", \"uilder&lt;&gt; types. With those, an async method like:\\n\\n```\\npublic\\n```\\n\\n```\\nasync ValueTask<int> Re\", \"adAsync(Memory<byte> buffer) { ... }\\n```\\n\\ncan be changed to be:\\n\\n```\\n[AsyncMethodBuilder( typeof (Po\", \"olingAsyncValueTaskMethodBuilder<>))] public async ValueTask<int> ReadAsync(Memory<byte> buffer) { .\", \".. }\\n```\\n\\nwhich will cause the C# compiler to emit the implementation of this method using PoolingAs\", \"yncValueTaskMethodBuilder&lt;int&gt; instead of the default AsyncValueTaskMethodBuilder&lt;int&gt; .\", \" The implementation of\\n\\nPoolingAsyncValueTaskMethodBuilder&lt;TResult&gt; is true to its name; it em\", \"ploys pooling to avoid most of the allocation asynchronous completion would otherwise experience (I \", \"say 'most' because the pooling by design tries to balance all the various costs involved and may sti\", \"ll sometimes allocate), and makes it easy for methods implemented with async / await to reap those b\", \"enefits. So, if this was all introduced in the last release, why am I talking about it now? Pooling \", \"isn't free. There are various\\n\\ntradeoffs involved in its usage, and while it can make microbenchmark\", \"s look really good, it can also negatively impact real-world usage, e.g. by increasing the cost of g\", \"arbage collections that do occur by increasing the number of Gen2 to Gen0 references that exist. As \", \"such, while the functionality is valuable, we've been methodical in where and how we use it, choosin\", \"g to do so more slowly and only employing it after sufficient analysis deems it's worthwhile.\\n\\nSuch \", \"is the case with SslStream . With dotnet/runtime#69418, two core and hot async methods on SslStream \", \"'s read path were annotated to use pooling. A microbenchmark shows what I mean when I wrote this can\", \" make microbenchmarks look really good (focus on the allocation columns). This benchmark is repeated\", \"ly issuing a read (that will be forced to complete asynchronously because there's no available data \", \"to satisfy it), then issuing a write to enable that read to complete, and then await i ng the read's\", \" completion; every read thus completes asynchronously.\\n\\n```\\nprivate SslStream _sslClient, _sslServer\", \"; private readonly byte[] _buffer = new byte[1]; private readonly SslServerAuthenticationOptions _op\", \"tions = new SslServerAuthenticationOptions { ServerCertificateContext = SslStreamCertificateContext.\", \"Create(GetCertificate(), null ), }; [GlobalSetup] public void Setup() { using var listener = new Soc\", \"ket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); listener.Bind( new IPEndPoint(\", \"IPAddress.Loopback, 0)); listener.Listen(1); var client = new Socket(AddressFamily.InterNetwork, Soc\", \"ketType.Stream, ProtocolType.Tcp); client.Connect(listener.LocalEndPoint); _sslClient = new SslStrea\", \"m( new NetworkStream(client, ownsSocket: true ), leaveInnerStreamOpen: true , delegate { return true\", \" ; }); _sslServer = new SslStream( new NetworkStream(listener.Accept(), ownsSocket: true ), leaveInn\", \"erStreamOpen: true , delegate { return true ; }); Task.WaitAll( _sslClient.AuthenticateAsClientAsync\", \"(\\\"localhost\\\", null , SslProtocols.None, checkCertificateRevocation: false ), _sslServer.Authenticate\", \"AsServerAsync(_options)); } [GlobalCleanup] public void Cleanup() { _sslClient.Dispose(); _sslServer\", \".Dispose(); } [Benchmark] public async Task ReadWriteAsync() { for (int i = 0; i < 1000; i++) { Valu\", \"eTask<int> read = _sslClient.ReadAsync(_buffer);\\n```\\n\\n```\\nawait _sslServer.WriteAsync(_buffer); awai\", \"t read; } }\\n```\\n\\n| Method         | Runtime   | Mean     |   Ratio | Code Size   | Allocated   |   A\", \"lloc Ratio |\\n|----------------|-----------|----------|---------|-------------|-------------|--------\", \"-------|\\n| ReadWriteAsync | .NET 6.0  | 68.34 ms |    1    | 510 B       | 336404 B    |         1  \", \"   |\\n| ReadWriteAsync | .NET 7.0  | 69.60 ms |    1.02 | 514 B       | 995 B       |         0.003 |\", \"\\n\\nOne final change related to reading and writing performance on an SslStream . I find this one part\", \"icularly interesting, as it highlights a new and powerful C# 11 and .NET 7 feature: static abstract \", \"members in interfaces. SslStream , as with every Stream , exposes both synchronous and asynchronous \", \"methods for reading and writing. And as you may be aware, the code within SslStream for implementing\", \" reads and writes is not particularly small. Thus, we really want to avoid having to duplicate all o\", \"f the code paths, once for synchronous work and once for asynchronous work, when in reality the only\", \" place that bifurcation is needed is at the leaves where calls into the underlying Stream are made t\", \"o perform the actual I/O. Historically, we've had two different mechanisms we've employed in dotnet/\", \"runtime for handling such unification. One is to make all methods async , but with an additional boo\", \"l useAsync parameter that gets fed through the call chain, then branching based on it at the leaves,\", \" e.g.\\n\\n```\\npublic static void Work(Stream s) => A(s, useAsyunc: false ).GetAwaiter().GetResult(); //\", \" GetResult() to propagate any exceptions public static Task WorkAsync(Stream S) => A(s, useAsync: tr\", \"ue ); internal static async Task A(Stream s, bool useAsync) { ... await B(s, useAsync); ... } privat\", \"e static async Task B(Stream s, bool useAsync) { ... int bytesRead = useAsync ? await s.ReadAsync(bu\", \"ffer) : s.Read(buffer.Span); ... }\\n```\\n\\nThis way most of the logic and code is shared, and when useA\", \"sync is false, everything completes synchronously and so we don't pay for allocation that might othe\", \"rwise be associated with the async -ness. The other approach is similar in spirit, but instead of a \", \"bool parameter, taking advantage of generic specialization and interface-implementing structs. Consi\", \"der an interface like:\\n\\n```\\ninterface IReader { ValueTask<int> ReadAsync(Stream s, Memory<byte> buff\", \"er); }\\n```\\n\\nWe can then declare two implementations of this interface:\\n\\n```\\nstruct SyncReader : IRea\", \"der { public ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) => new ValueTask<int>(s.Read(bu\", \"ffer.Span)); } struct AsyncReader : IReader { public ValueTask<int> ReadAsync(Stream s, Memory<byte>\", \" buffer) => s.ReadAsync(buffer); }\\n```\\n\\nThen we can redeclare our earlier example as:\\n\\n```\\npublic st\", \"atic void Work(Stream s) => A(stream, default (SyncReader)).GetAwaiter().GetResult(); // to propagat\", \"e any exceptions public static Task WorkAsync(Stream S) => A(s, default (AsyncReader)); internal sta\", \"tic async Task A<TReader>(Stream s, TReader reader) where TReader : IReader { ... await B(s, reader)\", \"; ... } private static async Task B<TReader>(Stream s, TReader reader) where TReader : IReader { ...\", \" int bytesRead = await reader.ReadAsync(s, buffer); ... }\\n```\\n\\nNote that the generic constraint on t\", \"he TReader parameter here allows the implementation to invoke the interface methods, and passing the\", \" structs as a generic avoids boxing. One code path supporting both sync and async implementations.\\n\\n\", \"This latter generic approach is how SslStream has historically handled the unification of its sync a\", \"nd async implementations. It gets better in .NET 7 with C# 11 now that we have static abstract metho\", \"ds in interfaces. We can instead declare our interface as (note the static abstract addition):\\n\\n```\\n\", \"interface IReader { static abstract ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer); }\\n```\\n\\n\", \"our types as (note the static addition):\\n\\n```\\nstruct SyncReader : IReader { public static ValueTask<\", \"int> ReadAsync(Stream s, Memory<byte> buffer) => new ValueTask<int>(s.Read(buffer.Span)); } struct A\", \"syncReader : IReader\\n```\\n\\n```\\n{ public static ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer\", \") => s.ReadAsync(buffer); }\\n```\\n\\nand our consuming methods as (note the removal of the parameter and\", \" the switch to calling static methods on the type parameter):\\n\\n```\\npublic static void Work(Stream s)\", \" => A<SyncReader>(stream).GetAwaiter().GetResult(); // to propagate any exceptions public static Tas\", \"k WorkAsync(Stream S) => A<AsyncReader>(s); internal static async Task A<TReader>(Stream s) where TR\", \"eader : IReader { ... await B<TReader>(s); ... } private static async Task B<TReader>(Stream s) wher\", \"e TReader : IReader { ... int bytesRead = await TReader.ReadAsync(s, buffer); ... }\\n```\\n\\nNot only is\", \" this cleaner, but from a performance perspective we no longer need to pass around the dummy generic\", \" parameter, which is general goodness, but for an async method it's particularly beneficial because \", \"the state machine type ends up storing all parameters as fields, which means every parameter can inc\", \"rease the amount of allocation incurred by an async method if the method ends up completing asynchro\", \"nously. dotnet/runtime#65239 flipped SslStream (and NegotiateStream ) to follow this approach. It's \", \"also used in multiple other places now throughout dotnet/runtime. dotnet/runtime#69278 from [@teo-ts\", \"irpanis](https://github.com/teo-tsirpanis) changed the RandomAccess class' implementation for Window\", \"s and the ThreadPool 's mech anism for invoking work items to use the same approach. Further, dotnet\", \"/runtime#63546 did the same in the Regex implementation, and in particular in the new RegexOptions.N\", \"onBacktracking implementation, as a way to abstract over DFA and NFA-based operations using the same\", \" code (this technique was since further utilized in NonBacktracking , such as by dotnet/runtime#7123\", \"4 from [@olsaarik](https://github.com/olsaarik)). And potentially most impactfully, dotnet/runtime#7\", \"3768 did so with IndexOfAny to abstract away the differences between IndexOfAny and IndexOfAnyExcept\", \" (also for the Last variants). With the introduction of the {Last}IndexOfAnyExcept variations previo\", \"usly mentioned, we now have four different variants of IndexOfAny with essentially the same function\", \"ality: searching forward or backwards, and with equality or inequality. While more challenging to tr\", \"y to unify the directional aspect, this PR utilized this same kind of generic specialization to hide\", \" behind an interface the ability to negate the comparison; the core implementations of these methods\", \" can then be implemented once and passed either a Negate or DontNegate implementation of the interfa\", \"ce. The net result is not only that the new Except varieties immediately gained all of the optimizat\", \"ions of the nonExcept varieties, but also the goal of trying to make everything consistent resulted \", \"in finding places where we were missing optimization opportunities in existing methods (gaps that th\", \"e PR also rectified).\\n\\n```\\nprivate static readonly string s_haystack = new HttpClient().GetStringAsy\", \"nc(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result; [Benchmark] public int LastIndexOfAny(\", \") => s_haystack.AsSpan().LastIndexOfAny(';', '_');\\n```\\n\\n| Method         | Runtime   | Mean     |   \", \"Ratio |\\n|----------------|-----------|----------|---------|\\n| LastIndexOfAny | .NET 6.0  | 9.977 us \", \"|    1    |\\n| LastIndexOfAny | .NET 7.0  | 1.172 us |    0.12 |\\n\\nLet's move up the stack to HTTP. Mo\", \"st of the folks focusing on networking in .NET 7 were focused on taking the preview support for HTTP\", \"/3 that shipped in .NET 6 and making it a first-class supported feature in .NET 7. That included fun\", \"ctional improvements, reliability and correctness fixes, and performance improvements, such that HTT\", \"P/3 can now be used via HttpClient on both Windows and Linux (it depends on an underlying QUIC imple\", \"mentation in the msquic component, which isn't currently available for macOS). However, there were s\", \"ignificant improvements throughout the HTTP stack, beyond HTTP/3.\\n\\nOne aspect of HttpClient that cut\", \"s across all versions of HTTP is support for handling and representing headers. While significant im\", \"provements went into previous releases to trim down the size of the data structures used to store he\", \"ader information, further work on this front was done for .NET 7. dotnet/runtime#62981, for example,\", \" improves the data structure used to store headers. One of the things HttpHeaders needs to deal with\", \" is that there's no defined limit to the number of headers that can be sent with an HTTP request or \", \"response (though in order to mitigate possible denial of service attacks, the implementation has a c\", \"onfigurable limit for how many bytes of headers are accepted from the server), and thus it needs to \", \"be able to handle an arbitrary number of them and to do so with efficient access. As such, for the l\", \"ongest time HttpHeaders has used a Dictionary&lt;,&gt; to provide O(1) lookup into these headers. Ho\", \"wever, while it's valid to have large numbers of headers, it's most common to only have a handful, a\", \"nd for only a few items, the overheads involved in a hash table like Dictionary&lt;&gt; can be more \", \"than just storing the elements in an array and doing an O(N) lookup by doing a linear search through\", \" all the elements (algorithmic complexity ignores the 'constants' involved, so for a small N , an O(\", \"N) algorithm might be much faster and lighterweight than an O(1) ). This PR takes advantage of that \", \"and teaches HttpHeaders how to use either an array or a dictionary; for common numbers of headers (t\", \"he current threshold is 64), it just uses an array, and in the rare case where that threshold is exc\", \"eeded, it graduates into a dictionary. This reduces the allocation in HttpHeader in all but the most\", \" niche cases while also making it faster for lookups.\\n\\nAnother header-related size reduction comes i\", \"n dotnet/runtime#64105. The internal representation of headers involves a HeaderDescriptor that enab\", \"les 'known headers' (headers defined in the HTTP specifications or that we're otherwise aware of and\", \" want to optimize) to share common data, e.g. if a response header matches one of these known header\", \"s, we can just use the header name string singleton rather than allocating a new string for that hea\", \"der each time we receive it. This HeaderDescriptor accomodated both known headers and custom headers\", \" by having two fields, one for known header data (which would be null for custom headers) and one fo\", \"r the header name. Instead, this PR employs a relatively-common technique of having a single object \", \"field that then stores either the known header information or the name, since the known header infor\", \"mation itself includes the name, and thus we don't need the duplication. At the expense of a type ch\", \"eck when we\\n\\nneed to look up information from that field, we cut the number of fields in half. And w\", \"hile this HeaderDescriptor is it self a struct, it's stored in header collections, and thus by cutti\", \"ng the size of the HeaderDescriptor in half, we can significantly reduce the size of those collectio\", \"ns, especially when many custom headers are involved.\\n\\n```\\nprivate readonly string[] _strings = new \", \"[] { \\\"Access-Control-Allow-Credentials\\\", \\\"AccessControl-Allow-Origin\\\", \\\"Cache-Control\\\", \\\"Connection\\\"\", \", \\\"Date\\\", \\\"Server\\\" }; [Benchmark] public HttpResponseHeaders GetHeaders() { var headers = new HttpRe\", \"sponseMessage().Headers; foreach (string s in _strings) { headers.TryAddWithoutValidation(s, s); } r\", \"eturn headers; }\\n```\\n\\n| Method     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n\", \"|------------|-----------|----------|---------|-------------|---------------|\\n| GetHeaders | .NET 6.\", \"0  | 334.4 ns |    1    | 664 B       |          1    |\\n| GetHeaders | .NET 7.0  | 213.9 ns |    0.6\", \"4 | 360 B       |          0.54 |\\n\\nSimilarly focused on allocation, dotnet/runtime#63057 removes two\", \" fields from the HttpHeaderValueCollection&lt;T&gt; collection type, which provides the concrete imp\", \"lementation for ICollection&lt;T&gt; properties like HttpContentHeaders.ContentEncoding ,\\n\\nHttpReque\", \"stHeaders.UserAgent , and HttpResponseHeaders.Server . The initial design and implementation of this\", \" type were overly flexible, with a mechanism for custom validation of values, which entailed multipl\", \"e fields for storing things like an Action&lt;&gt; callback to use for validation. But as it turns o\", \"ut in practice, that validation was only used for one specific consumer, and so rather than making e\", \"veryone pay for the extra space that wasn't typically used, t he validation was instead extracted ou\", \"t to just the call sites it was required.\\n\\nA more focused allocation reduction comes in dotnet/runti\", \"me#63641. The shared internal utility method HttpRuleParser.GetHostLength was using string.Substring\", \" in order to hand back the parsed host information, but only some of the callers needed this. Rather\", \" than making everyone pay for something that not everyone needed, this logic was moved into only the\", \" call sites that needed it.\\n\\nOther small allocation improvements were also made outside of headers. \", \"For example, when new HTTP/1 and HTTP/2 connections are created, the implementation queues a work it\", \"em to the thread pool to handle the actual creation, primarily to escape locks that might be held hi\", \"gher in the call stack. To do so, it used Task.Run . And while normally Task.Run is a fine thing to \", \"use, in this case there were two issues: the resulting Task was being ignored, such that any unexpec\", \"ted exceptions would just be eaten, and the lambda being passed to Task.Run was closing over this an\", \"d a local, which means the C# compiler will have generated code to allocate both a 'display class' (\", \"an object to store the state being passed in) for the closure and then also a delegate to a method o\", \"n that display class. Instead, dotnet/runtime#68750 switches it to use ThreadPool.QueueUserWorkItem \", \", using the overload that takes a generic TState , and passing in a tuple of all required state in o\", \"rder to avoid both superfluous allocations.\\n\\nFolks using HTTP often need to go through a proxy serve\", \"r, and in .NET the ability to go through an HTTP proxy is represented via the IWebProxy interface; i\", \"t has three members, GetProxy for getting the Uri of the proxy to use for a given destination Uri , \", \"the IsBypassed method which says whether a given Uri should go through a proxy or not, and then a Cr\", \"edentials property to be used when accessing the target proxy. The canonical implementation of IWebP\", \"roxy provided in the core libraries is the aptly named WebProxy . WebProxy is fairly simple: you giv\", \"e it a proxy Uri , and then calls to GetProxy return that proxy Uri if the destination isn't to be b\", \"ypassed. Whether a Uri should be bypassed is determined by two things (assuming a non-null proxy Uri\", \" was provided): did the constructor of the WebProxy specify that 'local' destinations should be bypa\", \"ssed (and if so, is this destination local), or does this destination address match any of any numbe\", \"r of regular expressions provided. As it turns out, this latter aspect has been relatively slow and \", \"allocation-heavy in all previous releases of .NET, for two reasons: every call to check whether an a\", \"ddress was bypassed was recreating a Regex instance for every supplied regular expression, and every\", \" call to check whether an address was bypassed was deriving a new string from the Uri to use to matc\", \"h against the Regex . In .NET 7, both of those issues have been fixed, yielding significant improvem\", \"ents if you rely on this regular expression functionality. dotnet/runtime#73803 from\\n\\n[@onehourlate]\", \"(https://github.com/onehourlate) changed the handling of the collection of these Regex instances. Th\", \"e problem was that WebProxy exposes an ArrayList (this type goes back to the beginning of .NET and w\", \"as created pre-generics), which the consumer could modify, and so WebProxy had to assume the collect\", \"ion was modified between uses and addressed that by simply creating new Regex instances on every use\", \"; not good. Instead, this PR creates a custom ArrayList -derived type that can track all relevant mu\", \"tations, and then only if the collection is changed (which is incredibly rare, bordering on never) d\", \"o the Regex instances need to be recreated. And dotnet/runtime#73807 takes advantage of stack alloca\", \"tion and the MemoryExtensions.TryWrite method with string interpolation to format the text into stac\", \"k memory, avoiding the string allocation. This, combined with the new Regex.IsMatch(ReadOnlySpan&lt;\", \"char&gt;) overload that enables us to match against that stackalloc 'd span, make s that aspect of t\", \"he operation allocation-free as well. Altogether, drastic improvements:\\n\\n```\\nprivate WebProxy _proxy\", \" = new WebProxy(\\\"http://doesntexist\\\", BypassOnLocal: false , new [] { @\\\"\\\\.microsoft.com\\\", @\\\"\\\\.dot.ne\", \"t\\\", @\\\"\\\\.bing.com\\\" }); private Uri _destination = new Uri(\\\"https://docs.microsoft.com/dotnet/api/syst\", \"em.net.webproxy\\\"); [Benchmark] public bool IsBypassed() => _proxy.IsBypassed(_destination);\\n```\\n\\n| M\", \"ethod     | Runtime   | Mean       |   Ratio | Allocated   |   Alloc Ratio |\\n|------------|---------\", \"--|------------|---------|-------------|---------------|\\n| IsBypassed | .NET 6.0  | 5,343.2 ns |    \", \"1    | 7528 B      |             1 |\\n| IsBypassed | .NET 7.0  | 205.5 ns   |    0.04 | -           |\", \"             0 |\\n\\nAlso related to HTTP, WebUtility 's HtmlDecode method has improved for .NET 7. The\", \" implementation had been manually iterating through each character in the input looking for a '&amp;\", \"' to be unescaped. Any time you see such an opencoded loop looking for one or more specific characte\", \"rs, it's a red flag that IndexOf should be strongly considered. dotnet/runtime#70700 deletes the ent\", \"ire searching function and replaces it with IndexOf , yielding simpler and much faster code (you can\", \" see other improvements to use IndexOf variants in networking, such as dotnet/runtime#71137, which u\", \"sed\\n\\nIndexOfAny in HttpListener 's HandleAuthentication to search a header for certain kinds of whit\", \"espace):\\n\\n```\\nprivate string _encoded = WebUtility.HtmlEncode(\\\"\\\"\\\" Lorem ipsum dolor sit amet, consec\", \"tetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Condimentu\", \"m vitae sapien pellentesque habitant. Vitae auctor eu augue ut lectus. Augue lacus viverra vitae con\", \"gue eu. Tempus quam pellentesque nec nam aliquam sem. Urna nec tincidunt praesent semper feugiat nib\", \"h sed. Amet tellus cras adipiscing enim eu. Duis ultricies lacus sed turpis tincidunt. Et sollicitud\", \"in ac orci phasellus egestas tellus rutrum tellus pellentesque. \\\"\\\"\\\"); [Benchmark] public string Html\", \"Decode() => WebUtility.HtmlDecode(_encoded);\\n```\\n\\n| Method     | Runtime   | Mean      |   Ratio |\\n|\", \"------------|-----------|-----------|---------|\\n| HtmlDecode | .NET 6.0  | 245.54 ns |    1    |\\n| H\", \"tmlDecode | .NET 7.0  | 19.66 ns  |    0.08 |\\n\\nThere have been a myriad of other performance-related\", \" improvements in networking as well, such as dotnet/runtime#67881 which removed the use of TcpClient\", \" from FtpWebRequest ; dotnet/runtime#68745 in WebSocket which removed a parameter from one of the co\", \"re async methods (and since parameters end up on the state machine, if the async method yields this \", \"results in fewer allocated bytes); and dotnet/runtime#70866 and dotnet/runtime#70900, which replaced\", \" all remaining use of Marshal.PtrToStructure in the core networking code with more efficient marshal\", \"ing (e.g. just performing casts). While Marshal.PtrToStructure is valuable when custom marshaling di\", \"rectives are used and the runtime needs to be involved in the conversion, it's also much more heavyw\", \"eight than just casting, which can be done when the native and managed layouts are bit-for-bit compa\", \"tible. As with the u8 example earlier, this comparison is hardly fair, but that's exactly the point:\", \"\\n\\n```\\nprivate IntPtr _mem; [GlobalSetup] public void Setup() { _mem = Marshal.AllocHGlobal(8); Marsh\", \"al.StructureToPtr( new SimpleType { Value1 = 42, Value2 = 84 }, _mem, false ); } [GlobalCleanup] pub\", \"lic void Cleanup() => Marshal.FreeHGlobal(_mem); public struct SimpleType { public int Value1; publi\", \"c int Value2; } [Benchmark(Baseline = true )] public SimpleType PtrToStructure() => Marshal.PtrToStr\", \"ucture<SimpleType>(_mem); [Benchmark] public unsafe SimpleType Cast() => *(SimpleType*)_mem;\\n```\\n\\n| \", \"Method         | Mean       |   Ratio |\\n|----------------|------------|---------|\\n| PtrToStructure |\", \" 26.6593 ns |   1     |\\n| Cast           | 0.0736 ns  |   0.003 |\\n\\nFor folks using NegotiateStream ,\", \" dotnet/runtime#71280 from\\n\\n[@filipnavara](https://github.com/filipnavara) will also be very welcome\", \" (this comes as part of a larger effort, primarily in dotnet/runtime#71777 from [@filipnavara](https\", \"://github.com/filipnavara) and dotnet/runtime#70720 from [@filipnavara](https://github.com/filipnava\", \"ra), to expose the new NegotiateAuthentication class). It removes a significant amount of allocation\", \" from a typical NTLM handshake by reusing a buffer rather than reallocating a new buffer for each of\", \" multiple phases of the handshake:\\n\\n```\\nprivate NetworkStream _client, _server; [GlobalSetup] public\", \" void Setup() { using var listener = new Socket(AddressFamily.InterNetwork, SocketType.Stream, Proto\", \"colType.Tcp); listener.Bind( new IPEndPoint(IPAddress.Loopback, 0)); listener.Listen(1); var client \", \"= new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); client.Connect(listen\", \"er.LocalEndPoint); Socket server = listener.Accept(); _client = new NetworkStream(client, ownsSocket\", \": true ); _server = new NetworkStream(server, ownsSocket: true ); } [Benchmark] public async Task Ha\", \"ndshake() { using NegotiateStream client = new NegotiateStream(_client, leaveInnerStreamOpen: true )\", \"; using NegotiateStream server = new NegotiateStream(_server, leaveInnerStreamOpen: true ); await Ta\", \"sk.WhenAll(client.AuthenticateAsClientAsync(), server.AuthenticateAsServerAsync()); }\\n```\\n\\n| Method \", \"   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|-----------|-----------|-------\", \"---|---------|-------------|---------------|\\n| Handshake | .NET 6.0  | 1.905 ms |       1 | 240.5 KB\", \"    |          1    |\\n| Handshake | .NET 7.0  | 1.913 ms |       1 | 99.28 KB    |          0.41 |\\n\\n\", \"## JSON\\n\\nSystem.Text.Json was introduced in .NET Core 3.0, and has seen a significant amount of inve\", \"stment in each release since. .NET 7 is no exception. New features in .NET 7 include support for cus\", \"tomizing contracts, polymorphic serialization, support for required members, support for DateOnly / \", \"TimeOnly, support for IAsyncEnumerable&lt;T&gt; and JsonDocument in source generation, and support f\", \"or configuring MaxDepth in JsonWriterOptions. However, there have also been new features specificall\", \"y focused on performance, and other changes about improving performance of JSON handling in a variet\", \"y of scenarios.\\n\\nOne of the biggest performance pitfalls we've seen developers face with System.Text\", \".Json has to do with how the library caches data. In order to achieve good serialization and deseria\", \"lization performance when the source generator isn't used, System.Text.Json uses reflection emit to \", \"generate custom code for reading/writing members of the types being processed. Instead of then havin\", \"g to pay reflection invoke costs on every access, the library incurs a much larger one-time cost per\", \" type to perform this code generation, but then all subsequent handling of these types is very fast\\u2026\", \" assuming the generated code is available for use. These generated handlers need to be stored somewh\", \"ere, and the location that's used for storing them is them is JsonSerializerOptions . The idea was i\", \"ntended to be that developers would instantiate an options instance once and pass it around to all o\", \"f their serialization/deserialization calls; thus, state like these generated handlers could be cach\", \"ed on them. And that works well when developers follow the recommended model. But when they don't, p\", \"erformance falls off a cliff, and hard. Instead of 'just' paying for the reflection invoke costs, ea\", \"ch use of a new JsonSerializerOptions ends up re-generating via reflection emit those handlers, skyr\", \"ocketing the cost of serialization and deserialization. A super simple benchmark makes this obvious:\", \"\\n\\n```\\nprivate JsonSerializerOptions _options = new JsonSerializerOptions(); private MyAmazingClass _\", \"instance = new MyAmazingClass(); [Benchmark(Baseline = true )] public string ImplicitOptions() => Js\", \"onSerializer.Serialize(_instance); [Benchmark] public string WithCached() => JsonSerializer.Serializ\", \"e(_instance, _options); [Benchmark] public string WithoutCached() => JsonSerializer.Serialize(_insta\", \"nce, new JsonSerializerOptions()); public class MyAmazingClass { public int Value { get ; set ; } }\\n\", \"```\\n\\n<!-- image -->\\n\\n| Method          | Runtime   | Mean         |   Ratio | Allocated   |   Alloc \", \"Ratio |\\n|-----------------|-----------|--------------|---------|-------------|---------------|\\n| Imp\", \"licitOptions | .NET 6.0  | 170.3 ns     |    1    | 200 B       |          1    |\\n| WithCached      \", \"| .NET 6.0  | 163.8 ns     |    0.96 | 200 B       |          1    |\\n| WithoutCached   | .NET 6.0  |\", \" 100,440.6 ns |  592.48 | 7393 B      |         36.97 |\\n\\nIn .NET 7, this was fixed in dotnet/runtime\", \"#64646 (and subsequently tweaked in dotnet/runtime#66248) by adding a global cache of the type infor\", \"mation separate from the options instances. A JsonSerializerOptions still has a cache, but when new \", \"handlers are generated via reflection emit, those are also cached at the global level (with appropri\", \"ate removal when no longer used in order to avoid unbounded leaks).\\n\\n| Method          | Runtime   |\", \" Mean         |   Ratio | Allocated   |   Alloc Ratio |\\n|-----------------|-----------|-------------\", \"-|---------|-------------|---------------|\\n| ImplicitOptions | .NET 6.0  | 170.3 ns     |    1    | \", \"200 B       |          1    |\\n| ImplicitOptions | .NET 7.0  | 166.8 ns     |    0.98 | 48 B        |\", \"          0.24 |\\n| WithCached      | .NET 6.0  | 163.8 ns     |    0.96 | 200 B       |          1  \", \"  |\\n| WithCached      | .NET 7.0  | 168.3 ns     |    0.99 | 48 B        |          0.24 |\\n| Without\", \"Cached   | .NET 6.0  | 100,440.6 ns |  592.48 | 7393 B      |         36.97 |\\n| WithoutCached   | .N\", \"ET 7.0  | 590.1 ns     |    3.47 | 337 B       |          1.69 |\\n\\nAs can be seen here, it's still mo\", \"re expensive to create a new JsonSerializerOptions instance on each call, and the recommended approa\", \"ch is 'don't do that.' But if someone does do it, in this example they're only paying 3.6x the cost \", \"rather than 621x the c ost, a huge improvement. dotnet/runtime#61434 also now exposes the JsonSerial\", \"izerOptions.Default instance that's used by default if no options are explicitly provided.\\n\\nAnother \", \"change to JsonSerializer came in dotnet/runtime#72510, which slightly improved the performance of se\", \"rialization when using the source generator. The source generator emits helpers for performing the s\", \"erialization/deserialization work, and these are then invoked by JsonSerializer via delegates (as pa\", \"rt of abstracting away all the different implementation strategies for how to get and set members on\", \" the types being serialized and deserialized). Previously, these helpers were being emitted as stati\", \"c methods, which in turn meant that the delegates were being created to static methods. Delegates to\", \" instance methods are a bit faster to invoke than delegates to static methods, so this PR made a sim\", \"ple few-line change for the source generator to emit these as instance methods instead.\\n\\nYet another\", \" for JsonSerializer comes in dotnet/runtime#73338, which improves allocation with how it utilizes Ut\", \"f8JsonWriter . Utf8JsonWriter is a class, and every time JsonSerializer would write out JSON, it wou\", \"ld allocate a new Utf8JsonWriter instance. In turn, Utf8JsonWriter needs something to write to, and \", \"although the serializer was using an IBufferWriter implementation that pooled the underlying byte[] \", \"instances employed, the implementation of IBufferWriter itself is a class that JsonSerializer would \", \"allocate. A typical Serialize call would then end up allocating a few extra objects and an extra cou\", \"ple of hundred bytes just for these helper data structures. To address that, this PR takes advantage\", \" of [ThreadStatic] , which can be put onto static fields to make them per-thread rather than per-pro\", \"cess. From whatever thread is performing the (synchronous)\\n\\nSerialize operation, it then ensures the\", \" current thread has a Utf8JsonWriter and IBufferWriter instance it can use, and uses them; for the m\", \"ost part this is straightforward, but it needs to ensure that the serialization operation itself doe\", \"sn't try to recursively serialize, in which case these objects could end up being used erroneously w\", \"hile already in use. It also needs to make sure that the pooled IBufferWriter doesn't hold on to any\", \" of its byte[] s while it's not being used. That instance gets its arrays from ArrayPool&lt;T&gt; , \", \"and we want those arrays to be usable in the meantime by anyone else making use of the pool, not seq\", \"uestered off in this cached IBufferWriter implementation. This optimization is also only really mean\", \"ingful for small object graphs being serialized, and only applies to the synchronous operations (asy\", \"nchronous operations would require a more complicated pooling mechanism, since the operation isn't t\", \"ied to a specific thread, and the overhead of such complication would likely outweigh the modest gai\", \"n this optimization provides).\\n\\n```\\nprivate byte[] _data = new byte[] { 1, 2, 3, 4, 5 }; [Benchmark]\", \" public string SerializeToString() => JsonSerializer.Serialize(_data);\\n```\\n\\n| Method            | Ru\", \"ntime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|-------------------|-----------|------\", \"----|---------|-------------|---------------|\\n| SerializeToString | .NET 6.0  | 146.4 ns |    1    |\", \" 200 B       |          1    |\\n| SerializeToString | .NET 7.0  | 137.5 ns |    0.94 | 48 B        | \", \"         0.24 |\\n\\nUtf8JsonWriter and Utf8JsonReader also saw several improvements directly. dotnet/ru\", \"ntime#69580 adds a few new performance-focused members, the ValueIsEscaped property (which exposes a\", \"lready tracked information and enables consumers to avoid the expense of re-checking) and the CopySt\", \"ring method (which provides a non-allocating mechanism to get access to a string value from the read\", \"er). It then also uses the added support internally to speed up certain operations on Utf8JsonReader\", \" . And dotnet/runtime#63863, dotnet/runtime#71534, and dotnet/runtime#61746 fix how some exception c\", \"hecks and throws were being handled so as to not slow down the non-exceptional fast paths.\\n\\n<!-- ima\", \"ge -->\\n\\n## XML\\n\\nSystem.Xml is used by a huge number of applications and services, but ever since JSO\", \"N hit the scene and has been all the rage, XML has taken a back seat and thus hasn't seen a lot of i\", \"nvestment from either a functionality or performance perspective. Thankfully, System.Xml gets a bit \", \"of performance love in .NET 7, in particular around reducing allocation on some commonly used code p\", \"aths.\\n\\nSometimes a performance fix is as easy as changing a single number. That's the case with dotn\", \"et/runtime#63459 from [@chrisdcmoore](https://github.com/chrisdcmoore), which addresses a long-stand\", \"ing issue with the asynchronous methods on the popular XmlReader . When XmlReader was originally wri\", \"tten, whoever developed it chose a fairly common buffer size to be used for read operations, namely \", \"4K or 8K char s depending on various conditions. When XmlReader later gained asynchronous reading fu\", \"nctionality, for whatever reason a much, much larger buffer size of 64K char s was selected (presuma\", \"bly in hopes of minimizing the number of asynchronous operations that would need to be employed, but\", \" the actual rationale is lost to history). A key problem with such a buffer size, beyond it leading \", \"to a lot of allocation, is the allocation it produces typically ends up on the Large Object Heap (LO\", \"H). By default, under the expectation that really large objects are long-lived, objects greater than\", \" 85K bytes are allocated into the LOH, which is treated as part of Gen 2, and that makes such alloca\", \"tion if not long-lived even more expensive in terms of overall impact on the system. Well, 64K char \", \"s is 128K bytes, which puts it squarely above that threshold. This PR lowers the size from 64K char \", \"s to 32K char s, putting it below the threshold (and generally reducing allocation pressure, how muc\", \"h memory needs to be zero'd, etc). While it's still a very large allocation, and in the future we co\", \"uld look at pooling the buffer or employing a smaller one (e.g. no different from what's done for th\", \"e synchronous APIs), this simple one-number change alone makes a substantial difference for shorter \", \"input documents (while not perceivably negatively impacting larger ones).\\n\\n```\\nprivate readonly XmlR\", \"eaderSettings _settings = new XmlReaderSettings { Async = true }; private MemoryStream _stream; [Par\", \"ams(10, 1_000_000)] public int ItemCount; [GlobalSetup] public void Setup() { _stream = new MemorySt\", \"ream(); using XmlWriter writer = XmlWriter.Create(_stream); writer.WriteStartElement(\\\"Items\\\"); for (\", \"var i = 0; i < ItemCount; i++) { writer.WriteStartElement($\\\"Item{i}\\\"); writer.WriteEndElement(); } w\", \"riter.WriteEndElement();\\n```\\n\\n```\\n} [Benchmark] public async Task XmlReader_ReadAsync() { _stream.Po\", \"sition = 0; using XmlReader reader = XmlReader.Create(_stream, _settings); while (await reader.ReadA\", \"sync()); }\\n```\\n\\n| Method              | Runtime   |   ItemCount | Mean           |   Ratio | Allocat\", \"ed    |   Alloc Ratio |\\n|---------------------|-----------|-------------|----------------|---------|\", \"--------------|---------------|\\n| XmlReader_ReadAsync | .NET 6.0  |          10 | 42.344 us      |  \", \"  1    | 195.94 KB    |          1    |\\n| XmlReader_ReadAsync | .NET 7.0  |          10 | 9.992 us  \", \"     |    0.23 | 99.94 KB     |          0.51 |\\n| XmlReader_ReadAsync | .NET 6.0  |     1000000 | 34\", \"0,382.953 us |    1    | 101790.34 KB |          1    |\\n| XmlReader_ReadAsync | .NET 7.0  |     1000\", \"000 | 333,417.347 us |    0.98 | 101804.45 KB |          1    |\\n\\nXmlReader and XmlWriter saw other a\", \"llocation-related improvements as well. dotnet/runtime#60076 from [@kronic](https://github.com/kroni\", \"c) improved the ReadOnlyTernaryTree internal type that's used when XmlOutputMethod.Html is specified\", \" in the XmlWriterSettings . This included using a ReadOnlySpan&lt;byte&gt; initialized from an RVA s\", \"tatic instead of a large byte[] array that would need to be allocated. And dotnet/runtime#60057 from\", \" [@kronic](https://github.com/kronic), which converted ~400 string creations in the System.Private.X\", \"ml assembly to use interpolated strings. Many of these cases were stylistic, converting something li\", \"ke string1 + \\\":\\\" + string2 into $\\\"{string1}:{string2}\\\" ; I say stylistic here because the C# compile\", \"r will generate the exact same code for both of those, a call to string.Concat(string1, \\\":\\\", string2\", \") , given that there's a Concat overload that accepts three strings. However, some of the changes do\", \" impact allocation. For example, the private XmlTextWriter.GeneratePrefix method had the code:\\n\\n```\\n\", \"return \\\"d\\\" + _top.ToString(\\\"d\\\", CultureInfo.InvariantCulture) + \\\"p\\\" + temp.ToString(\\\"d\\\", CultureInfo\", \".InvariantCulture);\\n```\\n\\nwhere \\\\_top and temp are both int s. This will result in allocating two tem\", \"porary strings and then concatenating those with the two constant strings. Instead, the PR changed i\", \"t to:\\n\\n```\\nreturn\\n```\\n\\n```\\nstring.Create(CultureInfo.InvariantCulture, $\\\"d{_top:d}p{temp:d}\\\");\\n```\\n\\n\", \"which while shorter is also more efficient, avoiding the intermediate string allocations, as the cus\", \"tom interpolated string handler used by string.Create will format those into a pooled buffer rather \", \"than allocating intermediate temporaries.\\n\\nXmlSerializer is also quite popular and also gets a (smal\", \"l) allocation reduction, in particular for deserialization. XmlSerializer has two modes for generati\", \"ng serialization/deserialization routines: using reflection emit to dynamically generate IL at run-t\", \"ime that are tuned to the specific shape of the types being serialized/deserialized, and the XML Ser\", \"ializer Generator Tool (sgen), which generates a .dll containing the same support, just ahead-of-tim\", \"e (a sort-of precursor to the Roslyn source\\n\\ngenerators we love today). In both cases, when deserial\", \"izing, the generated code wants to track which properties of the object being deserialized have alre\", \"ady been set, and to do that, it uses a bool[] as a bit array. Every time an object is deserialized,\", \" it allocates a bool[] with enough elements to track every member of the type. But in common usage, \", \"the vast majority of types being deserialized only have a relatively small number of properties, whi\", \"ch means we can easily use stack memory to track this information rather than heap memory. That's wh\", \"at dotnet/runtime#66914 does. It updates both of the code generators to stackalloc into a Span&lt;bo\", \"ol&gt; for less than or equal to 32 values, and otherwise fall back to the old approach of heap-allo\", \"cating the bool[] (which can also then be stored into a Span&lt;bool&gt; so that the subsequent code\", \" paths simply use a span instead of an array). You can see this quite easily in the .NET Object Allo\", \"cation Tracking tool in Visual Studio. For this console app (which, as an aside, shows how lovely th\", \"e new raw string literals feature in C# is for working with XML):\\n\\n```\\nusing System.Text; using Syst\", \"em.Xml.Serialization; var serializer = new XmlSerializer( typeof (Release[])); var stream = new Memo\", \"ryStream(Encoding.UTF8.GetBytes( \\\"\\\"\\\" <?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?> <ArrayOfRelease xmlns:xs\", \"i=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" xmlns:xsd=\\\"http://www.w3.org/2001/XMLSchema\\\"> <Release\", \"><Major>1</Major><Minor>0</Minor></Release> <Release><Major>1</Major><Minor>1</Minor></Release> <Rel\", \"ease><Major>2</Major><Minor>0</Minor></Release> <Release><Major>2</Major><Minor>1</Minor></Release> \", \"<Release><Major>2</Major><Minor>2</Minor></Release> <Release><Major>3</Major><Minor>0</Minor></Relea\", \"se> <Release><Major>3</Major><Minor>1</Minor></Release> <Release><Major>5</Major><Minor>0</Minor></R\", \"elease> <Release><Major>6</Major><Minor>0</Minor></Release> <Release><Major>7</Major><Minor>0</Minor\", \"></Release> </ArrayOfRelease> \\\"\\\"\\\")); for (int i = 0; i < 1000; i++) { stream.Position = 0; serialize\", \"r.Deserialize(stream); } public class Release { public int Major; public int Minor; public int Build\", \"; public int Revision; }\\n```\\n\\nHere's what I see when I run this under .NET 6:\\n\\nAllocations Call Tree\", \" Functions Collections\\n\\nType\\n\\nSystem.Xml. NameTable.Entry\\n\\nType\\n\\nSystem.String\\n\\nRelease\\n\\n<!-- image \", \"-->\\n\\nSystem String\\n\\nRelease\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\nAllocations -\\n\\n33,000\\n\\n\", \"| System.Boolean[]           | 29,123 10,013 Allocations -   |\\n|----------------------------|-------\", \"------------------------|\\n| System.Xml.NameTable.Entry | 10,000 33,000                 |\\n|          \", \"                  | 28,964                        |\\n|                            | 10,000           \", \"             |\\n\\nWe're running a thousand d eserializations, each of which will deserialize 10 Releas\", \"e instances, and so we expect to see 10,000 Release objects being allocated, which we do\\u2026 but we als\", \"o see 10,000 bool[] being allocated. Now with .NET 7 (note the distinct lack of the per-object bool[\", \"] ):\\n\\n<!-- image -->\\n\\nOther allocation reduction went into the creation of the serializer/deserializ\", \"er itself, such as with dotnet/runtime#68738 dotnet/runtime#66915 using stack allocation for buildin\", \"g up small text instead of using a StringBuilder , dotnet/runtime#66797 avoiding delegate and closur\", \"e allocations in accessing the avoiding allocating strings to escape text that didn't actually need \", \"escaping, cache of serializers previously created, dotnet/runtime#67001 from\\n\\n[@TrayanZapryanov](htt\", \"ps://github.com/TrayanZapryanov) caching an array used with string.Split , and dotnet/runtime#67002 \", \"from [@TrayanZapryanov](https://github.com/TrayanZapryanov) that changed some parsing code to avoid \", \"a string.ToCharArray invocation.\\n\\nFor folks using XML schema, dotnet/runtime#66908 replaces some Has\", \"htable s in the implementation where those collections were storing int s as the value. Given that H\", \"ashtable is a non-generic collection, every one of those int s was getting boxed, resulting in unnec\", \"essary allocation overhead; these were fixed by replacing these Hashtable s with Dictionary&lt;..., \", \"int&gt; instances. (As an aside, this is a fairly common performance-focused replacement to do, but \", \"you need to be careful as Hashtable has a few behavioral differences from Dictionary&lt;,&gt; ; beyo\", \"nd the obvious difference of Hashtable returning null from its indexer when a key isn't found and Di\", \"ctionary&lt;,&gt; throwing in that same condition, Hashtable is thread-safe for use with not only mu\", \"ltiple readers but multiple readers concurrent with a single writer, and Dictionary&lt;,&gt; is not.\", \") dotnet/runtime#67045 reduces allocation of XmlQualifiedName instances in the implementation of Xsd\", \"Builder.ProcessElement and XsdBuilder.ProcessAttribute . And dotnet/runtime#64868 from\\n\\n[@TrayanZapr\", \"yanov](https://github.com/TrayanZapryanov) uses stack-based memory and pooling to\\n\\navoid temporary s\", \"tring allocation in the implementation of the internal XsdDateTime and XsdDuration types, which are \", \"used by the public XmlConvert .\\n\\n```\\nprivate TimeSpan _ts = TimeSpan.FromMilliseconds(12345); [Bench\", \"mark] public string XmlConvertToString() => XmlConvert.ToString(_ts);\\n```\\n\\n| Method             | Ru\", \"ntime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|--------------------|-----------|-----\", \"-----|---------|-------------|---------------|\\n| XmlConvertToString | .NET 6.0  | 90.70 ns |    1   \", \" | 184 B       |          1    |\\n| XmlConvertToString | .NET 7.0  | 59.21 ns |    0.65 | 40 B       \", \" |          0.22 |\\n\\nXML pops up in other areas as well, as in the XmlWriterTraceListener type. While\", \" the System.Diagnostics.Trace type isn't the recommended tracing mechanism for new code, it's widely\", \" used in existing applications, and XmlWriterTraceListener let's you plug in to that mechanism to wr\", \"ite out XML logs for traced information. dotnet/runtime#66762 avoids a bunch of string allocation oc\", \"curring as part of this tracing, by formatting much of the header information into a span and then w\", \"riting that out rather than ToString() 'ing each individual piece of data.\\n\\n```\\n[GlobalSetup] public\", \" void Setup() { Trace.Listeners.Clear(); Trace.Listeners.Add( new XmlWriterTraceListener(Stream.Null\", \")); } [Benchmark] public void TraceWrite() { Trace.WriteLine(\\\"Something important\\\"); }\\n```\\n\\n| Method\", \"     | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|------------|-----------|----\", \"------|---------|-------------|---------------|\\n| TraceWrite | .NET 6.0  | 961.9 ns |     1   | 288 \", \"B       |          1    |\\n| TraceWrite | .NET 7.0  | 772.2 ns |     0.8 | 64 B        |          0.2\", \"2 |\\n\\n\\u2022 System.Security.Cryptography.Algorithms.dIl\\n\\n\\u2022 System.Security.Cryptography.Cng.dll\\n\\nSystem.S\", \"ecurity. Cryptography.Csp.dil\\n\\n## Cryptography\\n\\nSystem.Security. Cryptography.OpenSsl.dil\\n\\n787 KB\\n\\n4\", \"75 KB\\n\\n186 KB\\n\\n92 KB\\n\\n32 KB\\n\\nSome fairly significant new features came to System.Security.Cryptograp\", \"hy in .NET 7, including the support necessary to enable the previously discussed OCSP stapling and s\", \"upport for building certificate revocation lists, but there was also a fair amount of effort put int\", \"o making existing support faster and more lightweight. 476 KB\\n\\nOne fairly substantial change in .NET\", \" 7 is split across dotnet/runtime#61025, dotnet/runtime#61137, and dotnet/runtime#64307 . These PRs \", \"don't change any code materially, but instead cons olidate all of the various cryptography-related a\", \"ssemblies in the core libraries into a single\\n\\nSystem.Security.Cryptography assembly. When .NET Core\", \" was first envisioned, a goal was to make it extremely modular, and large swaths of code were teased\", \" apart to create many smaller assemblies. For example, cryptographic functionality was split between\", \"\\n\\nSystem.Security.Cryptography.Algorithms.dll , System.Security.Cryptography.Cng.dll , System.Securi\", \"ty.Cryptography.Csp.dll , System.Security.Cryptography.Encoding.dll , System.Security.Cryptography.O\", \"penSsl.dll , System.Security.Cryptography.Primitives.dll , and System.Security.Cryptography.X509Cert\", \"ificates.dll . You can see this if you look in your shared framework folder for a previous release, \", \"e.g. here's mine for .NET 6 :\\n\\n<!-- image -->\\n\\nThese PRs move all of that code into a single System.\", \"Security.Cryptography.dll assembly. This has several benefits. First, crypto is used in a huge numbe\", \"r of applications, and most apps would end up\\n\\nSystem.Security. Cryptography.Algorithms.dil tal Syst\", \"em.Security.Cryptography.Cng.dIl\\n\\n7 KB\\n\\n6 KB\\n\\nrequiring multiple (or even most) of these assemblies \", \". Every assembly that's loaded adds overhead. Second, a variety of helper files had to be compiled i\", \"nto each assembly, leading to overall larger amount of compiled code to be distributed. And third, w\", \"e weren't able to implement everything as optimal as we' d have otherwise liked due to functionality\", \" in one assembly not exposed to another (and we avoid using InternalsVisibleTo as it hampers maintai\", \"nability and impedes other analysis and optimizations). Now in .NET 7, the shared framework looks mo\", \"re like this:\\n\\na System.Security.Cryptography.Encoding.dll a System.Security. Cryptography.Primitive\", \"s.dIl\\n\\n<!-- image -->\\n\\n| System.Security.Cryptography.OpenSsl.dll             |\\n|-------------------\", \"-----------------------------------|\\n| a System.Security. Cryptography.X509Certificates.dIl |\\n\\nInter\", \"esting, you still see a bunch of assemblies there, but all except for\\n\\nSystem.Security.Cryptography.\", \"dll are tiny; that's because these are simple facades. Because we need to support binaries built for\", \" .NET 6 and earlier running on .NET 7, we need to be able to handle binaries that refer to types in \", \"these assemblies, but in .NET 7, those types actually live in System.Security.Cryptography.dll . .NE\", \"T provides a solution for this in the form of the [TypeForwardedTo(...)] attribute, which enables on\", \"e asse mbly to say 'hey, if you're looking for type X, it now lives over there.' And if you crack op\", \"en one of these assemblies in a tool like ILSpy, you can see they're essentially empty except for a \", \"bunch o f these attributes:\\n\\nAssemblies :\\n\\n- 4\\n\\n- *\\u2022 System.Security.Cryptography.Primitives (7.0.0.\", \"0, NETCoreApp, v7.0)\\n\\n+ ..: Metadata\\n\\n- *\\u00b0 References\\n\\n+ \\u2022\\u2022 System.Runtime\\n\\n+ \\u2022\\u2022\\u2022 System.Security. C\", \"ryptography\\n\\n= {} -\\n\\n\\u00abModule \\u203a\\n\\n\\u2022 Derived Types\\n\\nSystem.Security.Cryptography.Primitives (7.0.0.0, N\", \"ETCoreApp, v7.0)\\n\\n[assembly: TypeForwardedTo(typeof(AsymmetricAlgorithm))]\\n\\n[assembly: TypeForwarded\", \"To(typeof(CipherMode))]\\n\\n[assembly: TypeForwardedTo(typeof(CryptographicOperations))]\\n\\n[assembly: Ty\", \"peForwardedTo(typeof(CryptographicException))]\\n\\n[assembly: TypeForwardedTo(typeof(CryptographicUnexp\", \"ectedOperationException))]\\n\\n[assembly: TypeForwardedTo(typeof(CryptoStreamMode))]\\n\\n[assembly: TypeFo\", \"rwardedTo(typeof(CryptoStream))]\\n\\n<!-- image -->\\n\\nIn addition to the startup and maintenance wins th\", \"is provides, this has also enabled further subsequent optimization. For example, there's a lot of ob\", \"ject cloning that goes on in the innards of this library. Various objects are used to wrap native ha\", \"ndles to OS cryptographic resources, and to handle lifetime semantics and ownership appropriately, t\", \"here are many cases where a native handle is duplicated and then wrapped in one or more new managed \", \"objects. In some cases, however, the ori ginal resource is then destroyed because it's no longer nee\", \"ded, and the whole operation could have been made more efficient if the original resource just had i\", \"ts ownership transferred to the new objects rather than being duplicated and destroyed. This kind of\", \" ownership transfer typically is hard to do between assemblies as it generally requires public API t\", \"hat's not focused on such usage patterns, but with internals access, this can be overcome. dotnet/ru\", \"ntime#72120 does this, for example, to reduce allocation of various resources inside the RSACng , DS\", \"ACng , ECDsaCng , and ECDiffieHellmanCng public types.\\n\\nIn terms of actual code improvements, there \", \"are many. One category of improvements is around 'one -shot' operations. With many forms of data pro\", \"cessing, all of the data needn't be processed in one operation. A block of data can be processed, th\", \"en another, then another, until finally there's no more data to be processed. In such usage, there's\", \" often some kind of state carried over from the processing of one block to the processing of the nex\", \"t, and then the processing of the last block is special as it needn't carry over anything and instea\", \"d needs to perform whatever work is required to end the whole operation, e.g. outputting any final f\", \"ooter or checksum that might be required as part of the format. Thus, APIs that are able to handle a\", \"rbitrary number of blocks of data are often a bit more expensive in one way, shape, or form than API\", \"s that only support a single input; this latter category is known as 'one shot' operations, because \", \"they do everything in 'one shot.' In some cases, one-shot operations can be significantly cheaper, a\", \"nd in other cases they merely avoid some allocations that would have been necessary to transfer stat\", \"e from the processing of one block of data to the next. dotnet/runtime#58270 from [@vcsjones](https:\", \"//github.com/vcsjones) and dotnet/runtime#65725 from [@vcsjones](https://github.com/vcsjones) both i\", \"mproved the performance of various oneshot operations on 'symmetric' cryptograhic algorithms (algori\", \"thms that use the same key information to both encrypt and decrypt), like AES. The former does so by\", \" refactoring the implementations to avoid some reset work that's not necessary in the case of one -s\", \"hots because the relevant state is about to go away, anyway, and that in turns also allows the imple\", \"mentation to store less of certain kinds of state. The latter does so for decryption one-shots by de\", \"crypting directly into the destination buffer whenever possible, using stack space if possible when \", \"going directly into the user's buffer isn't feasible, etc.\\n\\n```\\nprivate byte[] _plaintext = Encoding\", \".UTF8.GetBytes(\\\"This is a test. This is only a test. Nothing to see here.\\\"); private byte[] _iv = En\", \"umerable.Range(0, 16).Select(i => (byte)i).ToArray(); private Aes _aes = Aes.Create(); private byte[\", \"] _output = new byte[1000]; [Benchmark] public bool OneShot() => _aes.TryEncryptCfb(_plaintext, _iv,\", \" _output, out _);\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|\", \"----------|-----------|----------|---------|-------------|---------------|\\n| OneShot  | .NET 6.0  | \", \"1.828 us |    1    | 336 B       |          1    |\\n| OneShot  | .NET 7.0  | 1.770 us |    0.97 | 184\", \" B       |          0.55 |\\n\\nIn addition to making one-shots lighterweight, other PRs have then used \", \"these one-shot operations in more places in order to simplify their code and benefit from the increa\", \"sed performance, e.g. dotnet/runtime#70639 from [@vcsjones](https://github.com/vcsjones), dotnet/run\", \"time#70857 from [@vcsjones](https://github.com/vcsjones), dotnet/runtime#64005 from [@vcsjones](http\", \"s://github.com/vcsjones), and dotnet/runtime#64174 from [@vcsjones](https://github.com/vcsjones).\\n\\nT\", \"here's also a large number of PRs that have focused on removing allocations from around the crypto s\", \"tack:\\n\\n- Stack allocation . As has been seen in many other PRs referenced throughout this post, usin\", \"g stackalloc is a very effective way to get rid o f array allocations in many situations. It's used \", \"effectively in multiple crypto PRs to avoid either temporary or pooled array allocations, such as in\", \" dotnet/runtime#64584 from [@vcsjones](https://github.com/vcsjones), dotnet/runtime#69831 from [@vcs\", \"jones](https://github.com/vcsjones), dotnet/runtime#70173 from [@vcsjones](https://github.com/vcsjon\", \"es), dotnet/runtime#69812 from [@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69448 fr\", \"om [@vcsjones](https://github.com/vcsjones). Sometimes this is used when calling an API that has mul\", \"tiple overloads, including one taking an array and one taking a span. Othertimes it's used with P/In\", \"vokes that often just pass out a small amount of data. Sometimes it's used to avoid temporary array \", \"allocations, and sometimes it's used in places where pooling was used previously, but the data is of\", \"ten small enough to avoid even the overheads of pooling.\\n- Avoiding double copies . Most of the cryp\", \"to APIs that accept byte[] s and store them end up making defensive copies of those arrays rather th\", \"an storing the original. This is fairly common throughout .NET, but it's especially common in the cr\", \"ypto stack, where the ability to trust the data is as you expect it (and validate it) is paramount. \", \"In some cases, though, code ends up allocating a temporary byte[] just to pass data into one of thes\", \"e APIs that copies and reallocates, anyway. dotnet/runtime#71102 from [@vcsjones](https://github.com\", \"/vcsjones), dotnet/runtime#69024 from [@vcsjones](https://github.com/vcsjones), dotnet/runtime#71015\", \" from [@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69534 from [@vcsjones](https://gi\", \"thub.com/vcsjones) deal with that duplication in some cases by extracting a span to the original dat\", \"a instead of creating a temporary byte[] ; when that span is passed into the target API, the target \", \"API still makes a copy, but we've avoided the first one and thus cut the array allocation for these \", \"operations effectively in half. dotnet/runtime#71888 from [@vcsjones](https://github.com/vcsjones) i\", \"s a variation on this theme, improving the internals of\\n\\nRfc2898DeriveBytes to supports spans such t\", \"hat its constructors that accept spans can then do the more efficient thing.\\n\\n- Replacing O(1) data \", \"structures . O(1) lookup data structures like Dictionary&lt;,&gt; and HashSet&lt;&gt; are the lifebl\", \"ood of most applications and services, but sometimes algorithmic complexity is misleading. Yes, thes\", \"e provide very efficient searching, but there's still overhead associated with computing a hash code\", \", mapping that hash code to a location in the data structure, and so on. If there's only ever a hand\", \"ful of items (i.e. the N in the complexity is really, really small), it can be much faster to just d\", \"o a linear search, and if N is sufficiently small, a data structure may not even be needed at all: t\", \"he search can just be open-coded as a waterfall of if/elseif/else constructs. That's the case in a P\", \"R like dotnet/runtime#71341 from [@vcsjones](https://github.com/vcsjones), where the 99.999% case in\", \"volves just five strings (names of hash algorithms); it's cheaper to just compare against each than \", \"it is do a HashSet&lt;&gt;.Contains , especially since the JIT now unrolls and vectorizes the compar\", \"ison against the constant string names.\\n- Simply avoiding unnecessary work . The best optimizations \", \"are ones where you simply stop doing work you don't have to do. dotnet/runtime#68553 from [@vcsjones\", \"](https://github.com/vcsjones) is a good example of this. This code was performing a hash of some da\", \"ta in order to determine the length of resulting hashes for that particular configuration, but we ac\", \"tually know ahead of time exactly how long a hash for a given algorithm is going to be, and we alrea\", \"dy have in this code a cascading if/elseif/else that's checking for each known algorithm, so we can \", \"instead just hardcode the length for each. dotnet/runtime#70589 from [@vcsjones](https://github.com/\", \"vcsjones) is another good example, in the same spirit of the ownership transfer example mentioned ea\", \"rlier (but this one didn't previously span assembly boundaries). Rather than in several places takin\", \"g an X509Extension , serializing it to a byte[] , and passing that temporary byte[] to something els\", \"e that in turn makes a defensive copy, we can instead provide an internal pathway for ownership tran\", \"sfer, bypassing all of the middle stages. Another good one is dotnet/runtime#70618 from [@vcsjones](\", \"https://github.com/vcsjones), as it's an example of how it pays to really understand , which is used\", \" at the docs where it's unnecessary ('superfluous,' according to the docs), and so our dutifully cal\", \"ling it\\n\\nyour dependencies. The implementation of symmetric encryption on macOS uses the CommonCrypt\", \"o library. One of the functions it exposes is CCCryptorFinal end of the encryption/decryption proces\", \"s. However, there are several cases called out in the even in those situations is wasteful. The fix?\", \" Stop doing unnecessary work.\\n\\n- New APIs . A bunch of new APIs were introduced for cryptography in \", \".NET 7. Most are focused on easing scenarios that were difficult to do correctly before, like dotnet\", \"/runtime#66509 from [@vcsjones](https://github.com/vcsjones) that provides an X500DistinguishedNameB\", \"uilder . But some are focused squarely on performance. dotnet/runtime#57835 from [@vcsjones](https:/\", \"/github.com/vcsjones), for example, exposes a new RawDataMemory property on X509Certificate2 . Where\", \"as the existing RawData property returns a new byte[] on every call (again a defensive copy to avoid\", \" having to deal with the possiblity that the consumer mucked with the raw data), this new RawDataMem\", \"ory returns a ReadOnlyMemory&lt;byte&gt; around the internal byte[] . Since the only way to access a\", \"nd mutate that underlying byte[] via a ReadOnlyMemory&lt;byte&gt; is via unsafe interop code (namely\", \" via the System.Runtime.InteropServices.MemoryMarshal type), it doesn't create a defensive copy and \", \"enables accessing this data freely without additional allocation.\\n\\n## Diagnostics\\n\\nLet's turn our at\", \"tention to System.Diagnostics, which encompasses types ranging from process management to tracing.\\n\\n\", \"The Process class is used for a variety of purposes, including querying information about running pr\", \"ocesses, interacting with other processes (e.g. being notified of their exiting), and launching proc\", \"esses. The performance of querying for information in particular had some notable improvements in .N\", \"ET 7. Process provides several APIs for querying for process information, one of the most common bei\", \"ng Process.GetProcessesByName : apps that know the name of the process they're interested in can pas\", \"s that to GetProcessesByName and get back a Process[] containing a Process for each. It turns out th\", \"at previous releases of .NET were loading the full information (e.g. all of its threads) about every\", \" Process on the machine in order to filter down to just those with the target name. dotnet/runtime#6\", \"8705 fixes that by only loading the name for a process rather than all of the information for it. Wh\", \"ile this helps a bit with throughput, it helps a ton with allocation:\\n\\n```\\n[Benchmark] public void G\", \"etProcessesByName() { foreach (Process p in Process.GetProcessesByName(\\\"dotnet.exe\\\")) p.Dispose(); }\", \"\\n```\\n\\n| Method             | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|-------\", \"-------------|-----------|----------|---------|-------------|---------------|\\n| GetProcessesByName |\", \" .NET 6.0  | 2.287 ms |     1   | 447.86 KB   |         1     |\\n| GetProcessesByName | .NET 7.0  | 2\", \".086 ms |     0.9 | 2.14 KB     |         0.005 |\\n\\nAccessing various pieces of information from a Pr\", \"ocess has also improved. If you load a Process object via the Process.GetProcesses or Process.GetPro\", \"cessesByName methods, by design they load all information about the Process being retrieved; interna\", \"lly their state will be populated such that subsequent accesses to members of the Process instance w\", \"ill be very fast. But, if you access a Process via Process.GetProcessById or Process.GetCurrentProce\", \"ss (which is effectively GetProcessById for the current process' id), no information other than the \", \"process' ID is prepopulated, and the state for the Process instance is queried on-demand. In most ca\", \"ses, accessing a single member of one of those lazy-loaded Process instances triggers loading all of\", \" the data for it, as the information is all available as part of the same native operation, e.g. on \", \"Windows using NtQuerySystemInformation and on Linux reading from /proc/pid/stat and /proc/pid/status\", \" . But in some cases we can be more fine-grained about it, using APIs that serve up a subset of the \", \"data much more quickly. dotnet/runtime#59672 from [@SteveDunn](https://github.com/SteveDunn) provide\", \"s one such optimization, using the QueryFullProcessImageName on Windows to read the process name in \", \"response to Process.ProcessName being used. If all you care about reading is the\\n\\n<!-- image -->\\n\\npr\", \"ocess' name, it's a huge boost in throughput, and even if you subsequently go on to read additional \", \"state from the Process and force it to load everything else, accessing the process name is so fast t\", \"hat it doesn't add meaningful overhead to the all -up operation. This is visible in this benchmark:\\n\", \"\\n```\\n[Benchmark] public string GetCurrentProcessName() { using Process current = Process.GetCurrentP\", \"rocess(); return current.ProcessName; } [Benchmark] public string GetCurrentProcessNameAndWorkingSet\", \"() { using Process current = Process.GetCurrentProcess(); return $\\\"{current.ProcessName} {current.Wo\", \"rkingSet64}\\\"; }\\n```\\n\\n| Method                             | Runtime   | Mean        |   Ratio | Allo\", \"cated   |   Alloc Ratio |\\n|------------------------------------|-----------|-------------|---------|\", \"-------------|---------------|\\n| GetCurrentProcessName              | .NET 6.0  | 3,070.54 us |    1\", \"    | 3954 B      |          1    |\\n| GetCurrentProcessName              | .NET 7.0  | 32.30 us    |\", \"    0.01 | 456 B       |          0.12 |\\n| GetCurrentProcessNameAndWorkingSet | .NET 6.0  | 3,055.70\", \" us |    1    | 4010 B      |          1    |\\n| GetCurrentProcessNameAndWorkingSet | .NET 7.0  | 3,1\", \"49.92 us |    1.03 | 4186 B      |          1.04 |\\n\\nInterestingly, this PR had a small deficiency we\", \" didn't initially catch, which is that the QueryFullProcessImageName API we switched to didn't work \", \"in the case of elevated/privileged processes. To accomodate those, dotnet/runtime#70073 from [@schue\", \"ttecarsten](https://github.com/schuettecarsten) updated the code to keep both the new and old implem\", \"entations, starting with the new one and then only falling back to the old if operating on an incomp\", \"atible process.\\n\\nSeveral additional PRs helped out the Process class. When launching processes with \", \"Process.Start on Unix, the implementation was using Encoding.UTF8.GetBytes as part of argument handl\", \"ing, resulting in a temporary array being allocated per argument; dotnet/runtime#71279 removes that \", \"per-argument allocation, instead using Encoding.UTF8.GetByteCount to determine how large a space is \", \"needed and then using the Encoding.UTF8.GetBytes overload that accepts a span to encode directly int\", \"o the native memory already being allocated. dotnet/runtime#71136 simplifies and streamlines the cod\", \"e involved in getting the 'short name' of a process on Windows for use in comparing process names. A\", \"nd dotnet/runtime#45690 replaces a custom cache with use of ArrayPool in the Windows implementation \", \"of getting all process information, enabling effective reuse of the array that ends up being used ra\", \"ther than having it sequestered off in the Process implementation forever.\\n\\nAnother area of performa\", \"nce investment has been in DiagnosticSource , and in particular around enumerating through data from\", \" Activity instances. This work translates into faster integration and interoperability via OpenTelem\", \"etry, in order to be able to export data from .NET Activity information faster. dotnet/runtime#67012\", \" from [@CodeBlanch](https://github.com/CodeBlanch), for example, improved the performance of the int\", \"ernal DiagLinkedList&lt;T&gt;.DiagEnumerator type that's the\\n\\nenumerator returned when enumerating A\", \"ctivity.Links and Activity.Events by avoiding a copy of each T value:\\n\\n```\\nprivate readonly Activity\", \" _activity; public Program() { using ActivitySource activitySource = new ActivitySource(\\\"Perf7Source\", \"\\\"); ActivitySource.AddActivityListener( new ActivityListener { ShouldListenTo = s => s == activitySo\", \"urce, Sample = ( ref ActivityCreationOptions<ActivityContext> o) => ActivitySamplingResult.AllDataAn\", \"dRecorded }); _activity = activitySource.StartActivity( \\\"TestActivity\\\", ActivityKind.Internal, paren\", \"tContext: default , links: Enumerable.Range(0, 1024).Select(_ => new ActivityLink( default )).ToArra\", \"y()); _activity.Stop(); } [Benchmark(Baseline = true )] public ActivityLink EnumerateActivityLinks()\", \" { ActivityLink last = default ; foreach (ActivityLink link in _activity.Links) last = link; return \", \"last; }\\n```\\n\\n| Method                 | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ratio\", \" |\\n|------------------------|-----------|----------|---------|-------------|---------------|\\n| Enume\", \"rateActivityLinks | .NET 6.0  | 19.62 us |     1   | 64 B        |           1   |\\n| EnumerateActivi\", \"tyLinks | .NET 7.0  | 13.72 us |     0.7 | 32 B        |           0.5 |\\n\\nThen dotnet/runtime#67920 \", \"from [@CodeBlanch](https://github.com/CodeBlanch) and dotnet/runtime#68933 from [@CodeBlanch](https:\", \"//github.com/CodeBlanch) added new EnumerateTagObjects , EnumerateEvents , and EnumerateLinks enumer\", \"ation methods that return a struct-based enumerator that has a ref T -returning Current to avoid yet\", \" another layer of copy.\\n\\n```\\nprivate readonly Activity _activity; public Program() { using ActivityS\", \"ource activitySource = new ActivitySource(\\\"Perf7Source\\\"); ActivitySource.AddActivityListener( new Ac\", \"tivityListener { ShouldListenTo = s => s == activitySource, Sample = ( ref ActivityCreationOptions<A\", \"ctivityContext> o) => ActivitySamplingResult.AllDataAndRecorded }); _activity = activitySource.Start\", \"Activity( \\\"TestActivity\\\", ActivityKind.Internal, parentContext: default , links: Enumerable.Range(0,\", \" 1024).Select(_ => new ActivityLink( default )).ToArray());\\n```\\n\\n```\\n_activity.Stop(); } [Benchmark(\", \"Baseline = true )] public ActivityLink EnumerateActivityLinks_Old() { ActivityLink last = default ; \", \"foreach (ActivityLink link in _activity.Links) last = link; return last; } [Benchmark] public Activi\", \"tyLink EnumerateActivityLinks_New() { ActivityLink last = default ; foreach (ActivityLink link in _a\", \"ctivity.EnumerateLinks()) last = link; return last; }\\n```\\n\\n| Method                     | Mean      \", \"|   Ratio | Allocated   |   Alloc Ratio |\\n|----------------------------|-----------|---------|------\", \"-------|---------------|\\n| EnumerateActivityLinks_Old | 13.655 us |    1    | 32 B        |         \", \"    1 |\\n| EnumerateActivityLinks_New | 2.380 us  |    0.17 | -           |             0 |\\n\\nOf cours\", \"e, when it comes to diagnostics, anyone who's ever done anything with regards to timing and measurem\", \"ents is likely familiar with good ol' Stopwatch . Stopwatch is a simple type that's very handy for g\", \"etting precise measurements and is thus used all over the place. But for folks that are really costs\", \"ensitive, the fact that Stopwatch is a class can be prohibitive, e.g. writing:\\n\\n```\\nStopwatch sw = S\", \"topwatch.StartNew(); ...; TimeSpan elapsed = sw.Elapsed;\\n```\\n\\nis easy, but allocates a new object ju\", \"st to measure. To address this, Stopwatch has for years exposed the static GetTimestamp() method whi\", \"ch avoids that allocation, but consuming and translating the resulting long value is complicated, re\", \"quiring a formula involving using Stopwatch.Frequency and TimeSpan.TicksPerSecond in the right incan\", \"tation. To make this pattern easy, dotnet/runtime#66372 adds a static GetElapsedTime method that han\", \"dles that conversion, such that someone who wants that last mile of performance can write:\\n\\n```\\nlong\", \" timestamp = Stopwatch.GetTimestamp(); ... TimeSpan elapsed = Stopwatch.GetElapsedTime(timestamp);\\n`\", \"``\\n\\nwhich avoids the allocation and saves a few cycles:\\n\\n```\\n[Benchmark(Baseline = true )] public Ti\", \"meSpan Old() { Stopwatch sw = Stopwatch.StartNew(); return sw.Elapsed; } [Benchmark] public TimeSpan\", \" New() {\\n```\\n\\n| long timestamp = Stopwatch.GetTimestamp(); return Stopwatch.GetElapsedTime(timestamp\", \");   |\\n|------------------------------------------------------------------------------------------|\\n\", \"\\n| Method   | Mean     |   Ratio | Allocated   |   Alloc Ratio |\\n|----------|----------|---------|--\", \"-----------|---------------|\\n| Old      | 32.90 ns |     1   | 40 B        |             1 |\\n| New  \", \"    | 26.30 ns |     0.8 | -           |             0 |\\n\\n## Exceptions\\n\\nIt might be odd to see the \", \"subject of 'exceptions' in a post on performance improvements. After all, exceptions are by their ve\", \"ry nature meant to be 'exceptional' (in the 'rare' sense), and thus wouldn't typically contribute to\", \" fast-path performance. Which is a good thing, because fast-paths that throw exceptions in the commo\", \"n case are no longer fast: throwing exceptions is quite expensive.\\n\\nInstead, one of the things we do\", \" concern ourselves with is how to minimize the impact of checking for exceptional cond itions: the a\", \"ctual exception throwing may be unexpected and slow, but it's super common to need to check for thos\", \"e unexpected conditions, and that checking should be very fast. We also want such checking to minima\", \"lly impact binary size, especially if we're going to have many such checks all over the place, in ge\", \"neric code for which we end up with many copies due to generic specialization, in functions that mig\", \"ht be inlined, and so on. Further, we don't want such checks to impede other optimizations; for exam\", \"ple, if I have a small function that wants to do some argument validation and would otherwise be inl\", \"ineable, I likely don't want the presence of exception throwing to invalidate the possibility of inl\", \"ining.\\n\\nBecause of all of that, high-performance librari es often come up with custom 'throw helpers\", \"' they use to achieve their goals. There are a variety of patterns for this. Sometimes a library wil\", \"l just define its own static method that handles constructing and throwing an exception, and then ca\", \"ll sites do the condition check and delegate to the method if throwing is needed:\\n\\n```\\nif (arg is nu\", \"ll ) ThrowArgumentNullException(nameof(arg)); ... [DoesNotReturn] private static void ThrowArgumentN\", \"ullException(string arg) => throw new ArgumentNullException(arg);\\n```\\n\\nThis keeps the IL associated \", \"with the throwing out of the calling function, minimizing the impact of the throw. That's particular\", \"ly valuable when additional work is needed to construct the exception, e.g.\\n\\n```\\nprivate static void\", \" ThrowArgumentNullException(string arg) => throw new ArgumentNullException(arg, SR.SomeResourceMessa\", \"ge);\\n```\\n\\nOther times, libraries will encapsulate both the checking and throwing. This is exactly wh\", \"at the ArgumentNullException.ThrowIfNull method that was added in .NET 6 does:\\n\\n```\\npublic static vo\", \"id ThrowIfNull([NotNull] object? argument, [CallerArgumentExpression(\\\"argument\\\")] string? paramName \", \"= null ) { if (argument is null ) Throw(paramName); }\\n```\\n\\n```\\n[DoesNotReturn] internal static void \", \"Throw(string? paramName) => throw new ArgumentNullException(paramName);\\n```\\n\\nWith that, callers bene\", \"fit from the concise call site:\\n\\n```\\npublic void M(string arg) { ArgumentNullException.ThrowIfNull(a\", \"rg); ... }\\n```\\n\\nthe IL remains concise, and the assembly generated for the JIT will include the stre\", \"amlined condition check from the inlined ThrowIfNull but won't inline the Throw helper, resulting in\", \" effectively the same code as if you'd written the previously shown manu al version with ThrowArgume\", \"ntNullException yourself. Nice.\\n\\nWhenever we introduce new public APIs in .NET, I'm particularly kee\", \"n on seeing them used as widely as possible. Doing so serves multiple purposes, including helping to\", \" validate that the new API is usable and fully addresses the intended scenarios, and including the r\", \"est of the codebase benefiting from whatever that API is meant to provide, whether it be a performan\", \"ce improvement or just a reduction in routinely written code. In the case of ArgumentNullException.T\", \"hrowIfNull , however, I purposefully put on the brakes. We used it in .NET 6 in several dozen call s\", \"ites, but primarily just in place of custom ThrowIfNull -like helpers that had sprung up in various \", \"libraries around the runtime, effectively de duplicating them. What we didn't do, however, was repla\", \"ce the literally thousands of null checks we have with calls to ArgumentNullException.ThrowIfNull . \", \"Why? Because the new !! C# feature was right around the corner, destined for C# 11.\\n\\nFor those unawa\", \"re, the !! feature enabled putting !! onto parameter names in member signatures, e.g.\\n\\n```\\npublic vo\", \"id Process(string name!!) { ... }\\n```\\n\\nThe C# compiler then compiled that as equivalent to:\\n\\n```\\npub\", \"lic void Process(string name) { ArgumentNullException.ThrowIfNull(name); }\\n```\\n\\n(albeit using its ow\", \"n ThrowIfNull helper injected as internal into the assembly). Armed with the new feature, dotnet/run\", \"time#64720 and dotnet/runtime#65108 rolled out use of !! across dotnet/runtime, replacing ~25,000 li\", \"nes of code with ~5000 lines that used !! . But, what's t he line from Kung Fu Panda, 'One often mee\", \"ts his destiny on the road he takes to avoid it'? The presence of that initial PR kicked off an unpr\", \"ecedented debate about the !! feature, with many folks liking the concept but a myriad of different \", \"opinions about exactly how it should be exposed, and in the end, the only common ground was to cut t\", \"he feature. In response, dotnet/runtime#68178 undid all usage of !! , replacing most of it with Argu\", \"mentNullException.ThrowIfNull . There are now ~5000 uses of ArgumentNullException.ThrowIfNull across\", \" dotnet/runtime, making it one of our most popular\\n\\nAPIs internally. Interestingly, while we expecte\", \"d a peanut-buttery effect of slight perf improvements in many places, our performance auto-analysis \", \"system flagged several performance improvements (e.g. dotnet/perf-autofiling-issues#3531) as stemmin\", \"g from these changes, in particular because it enabled the JIT's inlining heuristics to flag more me\", \"thods for inlining.\\n\\nhelper\\n\\nWith the success of ArgumentNullException.ThrowIfNull and along with it\", \"s significant roll-out in .NET 7, .NET 7 also sees the introduction of several more such throw helpe\", \"rs. dotnet/runtime#61633, for example, adds an overload of ArgumentNullException.ThrowIfNull that wo\", \"rks with pointers. dotnet/runtime#64357 adds the new ArgumentException.ThrowIfNullOrEmpty helper as \", \"well as using it in several hundred places. And dotnet/runtime#58684 from [@Bibletoon](https://githu\", \"b.com/Bibletoon) adds the new ObjectDisposedException.ThrowIf (tweaked by dotnet/runtime#71544 to he\", \"lp ensure it's inlineable), which is then used at over a hundred additional call sites by dotnet/run\", \"time#71546.\\n\\n## Registry\\n\\nOn Windows, the Registry is a database provided by the OS for applications\", \" and the system itself to load and store configuration settings. Practically every application acces\", \"ses the registry. I just tried a simple console app:\\n\\nConsole.WriteLine(\\\"Hello, world\\\");\\n\\nbuilt it a\", \"s release, and then ran the resulting .exe. That execution alone triggered 64 RegQueryValue operatio\", \"ns (as visible via SysInternals' Process Monitor tool). The core .NET libraries even access the regi\", \"stry for a variety of purposes, such as for gathering data for TimeZoneInfo , gathering data for var\", \"ious calendars like HijriCalendar and JapaneseCalendar , or for serving up environment variables as \", \"part of Environment.GetEnvironmentVariable(EnvironmentVariableTarget) with EnvironmentVariableTarget\", \".User or EnvironmentVariableTarget.Machine .\\n\\nIt's thus beneficial to streamline access to registry \", \"data on Windows, in particular for reducing overheads in startup paths where the registry is frequen\", \"tly accessed. dotnet/runtime#66918 does just that. Previously, calling RegistryKey.GetValue would ma\", \"ke a call to RegQueryValueEx with a null buffer; this tells the RegQueryValueEx method that the call\", \"er wants to know how big a buffer is required in order to store the value for the key. The implement\", \"ation would then allocate a buffer of the appropriate size and call RegQueryValueEx again, and for v\", \"alues that are to be returned as strings, would then allocate a string based on the data in that buf\", \"fer. This PR instead recognizes that the vast majority of data returned from calls to the registry i\", \"s relatively small. It starts with a stackalloc 'd buffer of 512 bytes, and uses that buffer as part\", \" of the initial call to RegQueryValueEx . If the buffer was sufficiently large, we no longer have to\", \" make a second system call to retrieve the actual data: we already got it. If the buffer was too sma\", \"ll, we rent an ArrayPool buffer of sufficient size and use that pooled buffer for the subsequent Reg\", \"QueryValueEx call. Except in situations where we actually need to return a byte[] array to the calle\", \"r (e.g. the type of the key is REG\\\\_BINARY ), this avoids the need for the allocated byte[] . And fo\", \"r keys that return strings (e.g. the type of the key is REG\\\\_SZ ), previously the old implementation\", \" would have allocated a temporary char[] to use as the buffer passed to RegQueryValueEx , but we can\", \" instead just reinterpret cast (e.g. MemoryMarshal.Cast ) the original buffer (whether a stackalloc \", \"'d span or the rented buffer as a Span&lt;char&gt; ), and use that to construct the resulting string\", \".\\n\\n```\\nprivate static readonly RegistryKey s_netFramework = Registry.LocalMachine.OpenSubKey(@\\\"SOFTW\", \"ARE\\\\Microsoft\\\\.NETFramework\\\"); [Benchmark] public\\n```\\n\\n```\\nstring RegSz() => (string)s_netFramework.\", \"GetValue(\\\"InstallRoot\\\");\\n```\\n\\n| Method   | Runtime   | Mean     |   Ratio | Allocated   |   Alloc Ra\", \"tio |\\n|----------|-----------|----------|---------|-------------|---------------|\\n| RegSz    | .NET \", \"6.0  | 6.266 us |    1    | 200 B       |          1    |\\n| RegSz    | .NET 7.0  | 3.182 us |    0.5\", \"1 | 96 B        |          0.48 |\\n\\n## Analyzers\\n\\nThe ability to easily plug custom code, whether for\", \" analyzers or source generators, into the Roslyn compiler is one of my favorite features in all of C\", \"#. It means the developers working on C# don't need to be solely responsible for highlighting every \", \"possible thing you might want to diagnose in your code. Instead, library authors can write their own\", \" analyzers, ship them either in dedicated nuget packages or as side-byside in nuget packages with AP\", \"Is, and those analyzers augment the compiler's own analysis to help developers write better code. We\", \" ship a large number of analyzer rules in the .NET SDK, many of which are focused on performance, an\", \"d we augment that set with more and more analyzers every release. We also work to apply more and mor\", \"e of those rules against our own codebases in every release. .NET 7 is no exception.\\n\\nOne of my favo\", \"rite new analyzers was added in dotnet/roslyn-analyzers#5594 from [@NewellClark](https://github.com/\", \"NewellClark) (and tweaked in dotnet/roslyn-analyzers#5972). In my .NET 6 performance post, I t alked\", \" about some of the overheads possible when types aren't sealed:\\n\\n- Virtual calls are more expensive \", \"than regular nonvirtual invocation and generally can't be inlined, since the JIT doesn't know what i\", \"s the actual type of the instance and thus the actual target of the invocation (at least not without\", \" assistance from PGO). But if the JIT can see that a virtual method is being invoked on a sealed typ\", \"e, it can devirtualize the call and potentially even inline it.\\n- If a type check (e.g. something is\", \" typeof(SomeType) ) is performed where SomeType is sealed, that check can be implemented along the l\", \"ines of something is not null &amp;&amp; something.GetType() == typeof(SomeType) . In contrast, if S\", \"omeType is not sealed, the check is going to be more along the lines of CastHelpers.IsInstanceOfClas\", \"s(typeof(SomeType), something) , where IsInstanceOfClass is a non-trivial (and today non-inlined) ca\", \"ll into a JIT helper method in Corelib that not only checks for null and for direct equality with th\", \"e specified type, but also linearly walks the parent hierarchy of the type of the object being teste\", \"d to see if it might derive from the specified type.\\n- Arrays in .NET are covariant, which means if \", \"types B and C both derive from type A , you can have a variable typed as A[] that's storing a B[] . \", \"Since C derives from A , it's valid to treat a C as an A , but if the A[] is actually a B[] , storin\", \"g a C into that array would mean storing a C into a B[] , which is invalid. Thus, every time you sto\", \"re an object reference into an array of reference types, additional validation may need to be perfor\", \"med to ensure the reference being written is compatible with the concrete type of the array in quest\", \"ion. But, if A in this example were sealed, nothing could derive from it, so storing objects into it\", \" doesn't r equire such covariance checks.\\n- Spans shift this covariance check to their constructor; \", \"rather than performing the covariance check on every write into the array, the check is performed wh\", \"en a span is being constructed from an array, such that if you try to create a new Span&lt;A&gt;(bAr\", \"ray) , the ctor will throw an exception. If A is sealed, the JIT is able to elide such a check as we\", \"ll.\\n\\nIt effectively would be impossible for an analyzer to be able to safely recommend sealing publi\", \"c types. After all, it has no kno wledge of the type's purpose, how it's intended to be used, and wh\", \"ether anyone outside of the assembly containing the type actually derives from it. But internal and \", \"private types are another story. An analyzer can actually see every possible type that could be deri\", \"ving from a private type, since the analyzer has access to the whole compilation unit containing tha\", \"t type, and it needn't worry about compatibility because anything that could derive from such a type\", \" necessarily must also be non-public and would be recompiled right along with the base type. Further\", \", with the exception of assemblies annotated as InternalsVisibleTo, an analyzer can have the same in\", \"sight into internal types. Thus, this PR adds CA1852, an analyzer that flags in non-InternalsVisible\", \"To assemblies all private and internal types that aren't sealed and that have no types deriving from\", \" them and recommends they be sealed. (Due to some current limitations in the infrastructure around f\", \"ixers and how this analyzer had to be written in order to be able to see all of the types in the ass\", \"embly, the analyzer for CA1852 doesn't show up in Visual Studio. It can, however, be applied using t\", \"he dotnet format tool. And if you bump up the level of the rule from info to warning or error, it'll\", \" show up as pa rt of builds as well.)\\n\\nIn .NET 6, we sealed over 2300 types, but even with that, thi\", \"s analyzer ended up finding more to seal. dotnet/runtime#59941 from [@NewellClark](https://github.co\", \"m/NewellClark) sealed another ~70 types, and dotnet/runtime#68268 which enabled the rule as an warni\", \"ng in dotnet/runtime (which builds with warnings-as-errors) sealed another ~100 types. As a larger e\", \"xample of the rule in use, ASP.NET hadn't done much in the way of sealing types in previous releases\", \", but with CA1852 now in the .NET SDK, dotnet/aspnetcore#41457 enabled the analyzer and sealed more \", \"than ~1100 types.\\n\\nAnother new analyzer, CA1854, was added in dotnet/roslyn-analyzers#4851 from [@Co\", \"llinAlpert](https://github.com/CollinAlpert) and then enabled in dotnet/runtime#70157. This analyzer\", \" looks for the surprisingly common pattern where a Dictionary&lt;TKey, TValue&gt; 's ContainsKey is \", \"used to determine whether a dictionary contains a particular entry, and then if it does, the diction\", \"ary's indexer is used to retrieve the value associated with the key, e.g.\\n\\n```\\nif (_dictionary.Conta\", \"insKey(key)) { var value = _dictionary[key]; Use(value); }\\n```\\n\\nDictionary's TryGetValue method alre\", \"ady combines both of these operations, both looking up the key and retrieving its value if it exists\", \", doing so as a single operation:\\n\\n```\\nif (_dictionary.TryGetValue(key, out var value)) { Use(value)\", \"; }\\n```\\n\\nA benefit of this, in addition to arguably being simpler, is that it's also faster. While D\", \"ictionary&lt;TKey, TValue&gt; provides very fast lookups, and while the performance of those lookups\", \" has gotten faster over time, doing fast work is still more expensive than doing no work, and if we \", \"can do one lookup instead of two, that can result in a meaningful performance boost, in particular i\", \"f it's being performed on a fast path. And we can see from this simple benchmark that looks up a wor\", \"d in a dictionary that, for this operation, making distinct calls to ContainsKey and the indexer doe\", \"s indeed double the cost of using the dictionary, almost exactly:\\n\\n```\\nprivate readonly Dictionary<s\", \"tring, int> _counts = Regex.Matches( new HttpClient().GetStringAsync(\\\"https://www.gutenberg.org/cach\", \"e/epub/100/pg100.txt\\\").Result, @\\\"\\\\b\\\\w+\\\\b\\\") .Cast<Match>() .GroupBy(word => word.Value, StringCompare\", \"r.OrdinalIgnoreCase) .ToDictionary(word => word.Key, word => word.Count(), StringComparer.OrdinalIgn\", \"oreCase); private string _word = \\\"the\\\"; [Benchmark(Baseline = true )] public int Lookup1() { if (_co\", \"unts.ContainsKey(_word)) { return _counts[_word]; } return -1; } [Benchmark] public int Lookup2() { \", \"if (_counts.TryGetValue(_word, out int count)) { return count; } return -1; }\\n```\\n\\n| Method   | Mean\", \"     |   Ratio |\\n|----------|----------|---------|\\n| Lookup1  | 28.20 ns |     1   |\\n| Lookup2  | 14\", \".12 ns |     0.5 |\\n\\nSomewhat ironically, even as I write this example, the analyzer and its auto-fix\", \"er are helpfully trying to get me to change my benchmark code:\\n\\nL\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\nif (\\\\_cou\", \"nts. ContainsKey(\\\\_word))\\n\\nUse 'TryGetValue(TKey, out TValue)'\\n\\n\\u2022 CA1854 Prefer a 'TryGetValue' call\", \" over a Dictionary indexer access\\n\\nConvert to conditional expression\\n\\nIntroduce parameter for '\\n\\nInv\", \"ert if\\n\\nSuppress or Configure issues\\n\\nO references\\n\\n{\\n\\nguarded by a 'ContainsKey' check to avoid dou\", \"ble lookup\\n\\nLines 32 to 36\\n\\n<!-- image -->\\n\\nSimilarly, dotnet/roslyn-analyzers#4836 from [@chucker](\", \"https://github.com/chucker) added CA1853, which looks for cases where a Remove call on a dictionary \", \"is guarded by a ContainsKey call. It seems it's fairly natural for developers to only call Remove on\", \" a dictionary once they're sure the dictionary contains the thing being removed; maybe they think Re\", \"move will throw an exception if the specified key doesn't exist. However, Remove actually allows thi\", \"s as a first-class scenario, with its return Boolean value indicating whether the key was in the dic\", \"tionary (and thus successfully removed) or not. An example of this comes from dotnet/runtime#68724, \", \"where CA1853 was enabled for dotnet/runtime. The EventPipeEventDispatcher type's RemoveEventListener\", \" method had code like this:\\n\\n```\\nif (m_subscriptions.ContainsKey(listener)) { m_subscriptions.Remove\", \"(listener); }\\n```\\n\\nwhich the analyzer flagged and which it's auto -fixer replaced with just:\\n\\n```\\nm_\", \"subscriptions.Remove(listener);\\n```\\n\\nNice and simple. And faster, since as with the TryGetValue case\", \", this is now doing a single dictionary lookup rather than two. :::{custom-style=Figure}\\n\\nif (\\\\_subs\", \"criptions. ContainsKey(listener))\\n\\nRemove unnecessary call\\n\\n\\u2022 \\u2022 CA1853 Do not guard Dictionary, Remo\", \"ve(key) with\\n\\nInvert if\\n\\nSuppress or Configure issues \\u2022\\n\\n'Dictionary. ContainsKey(key)\\\"\\n\\nLines 45 to\", \" 50\\n\\n<!-- image -->\\n\\nAnother nice analyzer added in dotnet/roslyn-analyzers#5907 and dotnet/roslyn-a\", \"nalyzers#5910 is CA1851, which looks for code that iterates through some kinds of enumerables multip\", \"le times. Enumerating an enumerator, whether directly or via helper methods like those in LINQ, can \", \"have nontrivial cost. Calling GetEnumerator typically allocates an enumerator object, and every item\", \" yielded typically involves two interface calls, one to MoveNext and one to Current. If something ca\", \"n be done via a single pass over the enumerable rather than multiple passes, that can save such cost\", \"s. In some cases, seeing places this analyzer fires can also inspire changes that avoid any use of e\", \"numerators. For example, dotnet/runtime#67292 enabled CA1851 for dotnet/runtime, and in doing so, it\", \" fixed several diagnostics issued by the analyzer (even in a code base that's already fairly stringe\", \"nt about enumerator and LINQ usage). As an example, this is a function in System.ComponentModel.Comp\", \"osition that was flagged by the analyzer:\\n\\n```\\nprivate void InitializeTypeCatalog(IEnumerable<Type> \", \"types) { foreach (Type type in types) { if (type == null ) { throw ExceptionBuilder.CreateContainsNu\", \"llElement(nameof(types)); } else if (type.Assembly.ReflectionOnly) { throw new ArgumentException(SR.\", \"Format(SR.Argument_ElementReflectionOnlyType, nameof(types)), nameof(types)); } } _types = types.ToA\", \"rray(); }\\n```\\n\\nThe method's purpose is to convert the enumerable into an array to be stored, but als\", \"o to validate that the contents are all non-null and non'ReflectionOnly.' To achieve that, the metho\", \"d is first using a foreach to iterate through the enumerable, validating each element along the way,\", \" and then once it's done so, it calls ToArray() to convert the enumerable into an array. There are m\", \"ultiple problems\\n\\nwith this. First, it's incurring the expense of interating through t he enumerable\", \" twice, once for the foreach and once for the ToArray() , which internally needs to enumerate it if \", \"it can't do something special like cast to ICollection&lt;Type&gt; and CopyTo the data out of it. Se\", \"cond, it's possible the caller's IEnumerable&lt;Type&gt; changes on each iteration, so any validatio\", \"n done in the first iteration isn't actually ensuring there aren't nulls in the resulting array, for\", \" example. Since the expectation of the method is that all inputs are valid and we don't need to opti\", \"mize for the failure cases, the better approach is to first call ToArray() and then validate the con\", \"tents of that array, which is exactly what that PR fixes it to do:\\n\\n```\\nprivate void InitializeTypeC\", \"atalog(IEnumerable<Type> types) { Type[] arr = types.ToArray(); foreach (Type type in arr) { if (typ\", \"e == null ) { throw ExceptionBuilder.CreateContainsNullElement(nameof(types)); } if (type.Assembly.R\", \"eflectionOnly) { throw new ArgumentException(SR.Format(SR.Argument_ElementReflectionOnlyType, nameof\", \"(types)), nameof(types)); } } _types = arr; }\\n```\\n\\nWith that, we only ever iterate it once (and poss\", \"ibly 0 times if ToArray can special-case it, and bonus, we validate on the copy rather than on the m\", \"utable original.\\n\\nYet another helpful analyzer is the new CA1850 introduced in dotnet/roslyn-analyze\", \"rs#4797 from [@wzchua](https://github.com/wzchua). It used to be that if you wanted to cryptographic\", \"ally hash some data in .NET, you would create an instance of a hash algorithm and call its ComputeHa\", \"sh method, e.g.\\n\\n```\\npublic byte[] Hash(byte[] data) { using (SHA256 h = SHA256.Create()) { return h\", \".ComputeHash(data); } }\\n```\\n\\nHowever, .NET 5 introduced new 'one -shot' hashing methods, which obvia\", \"tes the need to create a new HashAlgorithm instance, providing a static method that performs the who\", \"le operation.\\n\\n```\\npublic byte[] Hash(byte[] data) { return SHA256.HashData(data); }\\n```\\n\\nCA1850 fin\", \"ds occurrences of the former pattern and recommends changing them to the latter.\\n\\npublic bytel] Hash\", \"(byte[] data)\\n\\nusing (SHA256 h = SHA256.Create())\\n\\n{\\n\\nThe result is not only simpler, it's also fast\", \"er:\\n\\n```\\nprivate readonly byte[] _data = RandomNumberGenerator.GetBytes(128); [Benchmark(Baseline = \", \"true )] public byte[] Hash1() { using (SHA256 h = SHA256.Create()) { return h.ComputeHash(_data); } \", \"} [Benchmark] public byte[] Hash2() { return SHA256.HashData(_data); } } return SHA256. HashData(dat\", \"a);\\n```\\n\\nThe .NET 7 SDK also includes new analyzers around [GeneratedRegex(...)] (dotnet/runtime#689\", \"76) and the already mentioned ones for LibraryImport, all of which help to move your code forwards t\", \"o more modern patterns that have better performance characteristics.\\n\\n| Method   | Mean       |   Ra\", \"tio | Allocated   |   Alloc Ratio |\\n|----------|------------|---------|-------------|---------------\", \"|\\n| Hash1    | 1,212.9 ns |    1    | 240 B       |          1    |\\n| Hash2    | 950.8 ns   |    0.7\", \"8 | 56 B        |          0.23 |\\n\\n<!-- image -->\\n\\nConvert to 'GeneratedRegexAttribute'.\\n\\nUse 'new(.\", \"..)\\\"\\n\\nGenerate constructor 'Program(Regex)\\\"\\n\\nGenerate Equals(object)\\n\\nGenerate Equals and GetHashCod\", \"e\\n\\nEncapsulate field: '\\\\_parseSocial\\\" (and use property)\\n\\nEncapsulate field: '\\\\_parseSocial' (but st\", \"ill use field)\\n\\nExtract base class...\\n\\nSuppress or Configure issues\\n\\n\\u2022 \\u00ae Use 'GeneratedRegexAttribut\", \"e' to generate the regular expression implementation at compile-time\\n\\nLines 38 to 40\\n\\nprivate readon\", \"ly Regex \\\\_parseSocial = new RegexC@\\\"[0-9]{3}-[0-9]{2}-[0-9]{4}\\\");\\n\\nprivate readonly Regex \\\\_parseSo\", \"cial = MyRegexO;\\n\\n<!-- image -->\\n\\nThis release also saw dotnet/runtime turn on a bunch of additional\", \" IDEXXXX code style rules and make a huge number of code changes in response. Most of the resulting \", \"changes are purely about simplifying the code, but in almost every case some portion of the changes \", \"also have a functional and performance impact.\\n\\nLet's start with IDE0200, which is about removing un\", \"necessary lambdas. Consider a setup like this:\\n\\n```\\npublic class C { public void CallSite() => M(i =\", \"> Work(i)); public void M(Action<int> action) { } private static void Work(int value) { } }\\n```\\n\\nHer\", \"e we have a method CallSite that's invoking a method M and passing a lambda to it. Method M accepts \", \"an Action&lt;int&gt; , and the call site is passing a lambda that takes the supplied Int32 and passe\", \"s it off to some static functionality. For this code, the C# compiler is going to generate something\", \" along the lines of this:\\n\\n```\\npublic class C { [CompilerGenerated] private sealed class <>c { publi\", \"c static readonly <>c <>9 = new <>c(); public static Action<int> <>9__0_0; internal void <CallSite>b\", \"__0_0(int i) => Work(i); } public void CallSite() => M(<>c.<>9__0_0 ??= new Action<int>(<>c.<>9.<Cal\", \"lSite>b__0_0)); public void M(Action<int> action) { } private static void Work(int value) { } }\\n```\\n\", \"\\nThe most important aspect of this is that &lt;&gt;9\\\\_\\\\_0\\\\_0 field the compiler emitted. That field \", \"is a cache for the delegate created in CallSite . The first time CallSite is invoked, it'll allocate\", \" a new delegate for the lambda and store it into that field. For all subsequent invocations, however\", \", it'll find the field is\\n\\nnon-null and will just reuse the same delegate. Thus, this lambda only ev\", \"er results in a single allocation for the whole process (ignoring any race conditions on the initial\", \" lazy initialization such that multiple threads all racing to initialize the field might end up prod\", \"ucing a few additional unnecessary allocations). It's important to recognize this caching only happe\", \"ns because the lambda doesn't access any instance state and doesn't close over any locals; if it did\", \" either of those things, such caching wouldn't happen. Secondarily, it's interesting to note the pat\", \"tern the compiler uses for the lambda itself. Note that generated &lt;CallSite&gt;b\\\\_\\\\_0\\\\_0 method i\", \"s generated as an instance method, and the call site refers to that method of a singleton instance t\", \"hat's used to initialize a &lt;&gt;9 field. That's done because delegates to static methods use some\", \"thing called a 'shuffle thunk' to move arguments into the right place for the target method invocati\", \"on, making delegates to statics ever so slightly more expensive to invoke than delegates to instance\", \" methods.\\n\\n```\\nprivate Action _instance = new C().InstanceMethod; private Action _static = C.StaticM\", \"ethod; [Benchmark(Baseline = true )] public void InvokeInstance() => _instance(); [Benchmark] public\", \" void InvokeStatic() => _static(); private sealed class C { public static void StaticMethod() { } pu\", \"blic void InstanceMethod() { } }\\n```\\n\\n| Method         | Mean      |   Ratio |\\n|----------------|---\", \"--------|---------|\\n| InvokeInstance | 0.8858 ns |    1    |\\n| InvokeStatic   | 1.3979 ns |    1.58 \", \"|\\n\\nSo, the compiler is able to cache references to lambdas, great. What about method groups, i.e. wh\", \"ere you just name the method directly? Previously, if changed my code to:\\n\\n```\\npublic class C { publ\", \"ic void CallSite() => M(Work); public void M(Action<int> action) { } private static void Work(int va\", \"lue) { } }\\n```\\n\\nthe compiler would generate the equivalent of:\\n\\n```\\npublic class C { public void Cal\", \"lSite() => M( new Action<int>(Work)); public void M(Action<int> action) { } private static void Work\", \"(int value) { } }\\n```\\n\\nwhich has the unfortunate effect of allocating a new delegate on every invoca\", \"tion, even though we're still dealing with the exact same static method. Thanks to dotnet/roslyn#582\", \"88 from [@pawchen](https://github.com/pawchen), the compiler will now generate the equivalent of:\\n\\n`\", \"``\\npublic class C { [CompilerGenerated] private static class <>O { public static Action<int> <0>__Wo\", \"rk; } public void CallSite() => M(<>O.<0>__Work ??= new Action<int>(Work)); public void M(Action<int\", \"> action) { } private static void Work(int value) { } }\\n```\\n\\nNote we again have a caching field that\", \"'s used to enable allocating the delegate once and caching it. That means that places where code was\", \" using a lambda to enable this caching can now switch back to the cleaner and simpler method group w\", \"ay of expressing the desired functionality. There is the interesting difference to be cognizant of t\", \"hat since we don't have a lambda which required the compiler emitting a new method for, we're still \", \"creating a delegate directly to the static method. However, the minor difference in thunk overhead i\", \"s typically made up for by the fact that we don't have a second method to invoke; in the common case\", \" where the static helper being invoked isn't inlinable (because it's not super tiny, because it has \", \"exception handling, etc.), we previously would have incurred the cost of the delegate invocation plu\", \"s the non-inlinable method call, and now we just have the cost of an ever-soslightly more expensive \", \"delegate invocation; on the whole, it's typically a wash.\\n\\nAnd that brings us to IDE0200, which reco\", \"gnizes lambda expressions that can be removed. dotnet/runtime#71011 enabled the analyzer for dotnet/\", \"runtime, resulting in more than 100 call sites changing accordingly. However, IDE0200 does more than\", \" just this mostly stylistic change. It also recognizes some patterns that can make a more substantia\", \"l impact. Consider this code that was changed as part of that PR:\\n\\n```\\nAction disposeAction; IDispos\", \"able? disposable = null ; ... if (disposable != null ) { disposeAction = () => disposable.Dispose();\", \" }\\n```\\n\\nThat delegate closes over the disposable local, which means this method needs to allocate a \", \"display class. But IDE0200 recognizes that instead of closing over disposable , we can create the de\", \"legate directly to the Dispose method:\\n\\n```\\nAction disposeAction; IDisposable? disposable = null ; .\", \".. if (disposable != null ) {\\n```\\n\\n```\\ndisposeAction = disposable.Dispose; }\\n```\\n\\nWe still get a del\", \"egate allocation, but we avoid the display class allocation, and as a bonus we save on the additiona\", \"l metadata required for the synthesized display class and method generated for the lambda.\\n\\nIDE0020 \", \"is another good example of an analyzer that is primarily focused on making code cleaner, more mainta\", \"inable, more modern, but that can also lead to removing overhead from many different places. The ana\", \"lyzer looks for code performing unnecessary duplicative casts and recommends using C# pattern matchi\", \"ng syntax instead. For example, dotnet/runtime#70523 enabled the analyzer and switched more than 250\", \" locations from code like:\\n\\n```\\nif (value is SqlDouble) { SqlDouble i = (SqlDouble)value; return Com\", \"pareTo(i); }\\n```\\n\\nto instead be like:\\n\\n```\\nif (value is SqlDouble i) { return CompareTo(i); }\\n```\\n\\nI\", \"n addition to being cleaner, this ends up saving a cast operation, which can add measurable overhead\", \" if the JIT is unable to remove it:\\n\\n```\\nprivate object _value = new List<string>(); [Benchmark(Base\", \"line = true )] public List<string> WithCast() { object value = _value; return value is List<string> \", \"? (List<string>)value : null ; } [Benchmark] public List<string> WithPattern() { object value = _val\", \"ue; return value is List<string> list ? list : null ; }\\n```\\n\\n| Method      | Mean     |   Ratio |\\n|-\", \"------------|----------|---------|\\n| WithCast    | 2.602 ns |    1    |\\n| WithPattern | 1.886 ns |  \", \"  0.73 |\\n\\nThen there's IDE0031, which promotes using null propagation features of C#. This analyzer \", \"typically manifests as recommending changing snippets like:\\n\\n```\\nreturn _value != null ? _value.Prop\", \"erty : null ;\\n```\\n\\ninto code that's instead like:\\n\\n```\\nreturn\\n```\\n\\n```\\n_value?.Property;\\n```\\n\\nNice, \", \"concise, and primarily about cleaning up the code and making it simpler and more maintainable by uti\", \"lizing newer C# syntax. However, there is also a small performance advantage in some situations as w\", \"ell. For example, consider this snippet:\\n\\n```\\npublic class C { private C _value; public int? Get1() \", \"=> _value != null ? _value.Prop : null ; public int? Get2() => _value?.Prop; public int Prop => 42; \", \"}\\n```\\n\\nThe C# compiler lowers these expressions to the equivalent of this:\\n\\n```\\npublic Nullable<int>\", \" Get1() { if (_value == null ) return null ; return _value.Prop; } public Nullable<int> Get2() { C v\", \"alue = _value; if (value == null ) return null ; return value.Prop; }\\n```\\n\\nfor which the JIT then ge\", \"nerates:\\n\\n```\\n; Program.Get1() push      rax mov       rdx,[rcx+8] test      rdx,rdx jne       short\", \" M00_L00 xor       eax,eax add       rsp,8 ret M00_L00: cmp       [rdx],dl mov       dword ptr [rsp+\", \"4],2A mov       byte ptr [rsp],1 mov       rax,[rsp] add       rsp,8 ret ; Total bytes of code 40 ; \", \"Program.Get2() push      rax mov       rax,[rcx+8] test      rax,rax jne       short M00_L00 xor    \", \"   eax,eax add       rsp,8 ret M00_L00:\\n```\\n\\n```\\nmov       dword ptr [rsp+4],2A mov       byte ptr [\", \"rsp],1 mov       rax,[rsp] add       rsp,8 ret ; Total bytes of code 38\\n```\\n\\nNote how the Get1 varia\", \"nt has an extra cmp instruction ( cmp [rdx],dl ) in the otherwise identical assembly to Get2 (other \", \"than register selection). That cmp instruction in Get1 is the JIT forcing a null check on the second\", \" read of \\\\_value prior to accessing its Prop , whereas in Get2 the null check against the local mean\", \"s the JIT doesn't need to add an additional null check on the second use of the local, since nothing\", \" could have changed it. dotnet/runtime#70965 rolled out additional use of the null propagation opera\", \"tor via auto-fixing IDE0031, resulting in ~120 uses being improved.\\n\\nAnother interesting example is \", \"IDE0060, which finds unused parameters and recommends removing them. This was done for non-public me\", \"mbers in System.Private.CoreLib in dotnet/runtime#63015. As with some of the other mentioned rules, \", \"it's primarily about good hygiene. There can be some small additional cost associated with passing a\", \"dditional parameters (the overhead of reading the values at the call site, putting them into the rig\", \"ht register or stack location, etc., and also the metadata size associated with the additional param\", \"eter information), but the larger benefit comes from auditing all of the cited violations and findin\", \"g places where work is simply being performed unnecessarily. For example, that PR made some updates \", \"to the TimeZoneInfo type's implementation for Unix. In that implementation is a TZif\\\\_ParseRaw metho\", \"d, which is used to extract some information from a time zone data file. Amongst many input and outp\", \"ut parameters, it had out bool[] StandardTime, out bool[] GmtTime , which the implementation was dut\", \"ifully filling in by allocating and populating new arrays for each. The call site for TZif\\\\_ParseRaw\", \" was then taking those arrays and feeding them into another method TZif\\\\_GenerateAdjustmentRules , w\", \"hich ignored them! Thus, not only was this PR able to remove those parameters from TZif\\\\_GenerateAdj\", \"ustmentRules , it was able to update TZif\\\\_ParseRaw to no longer need to allocate and populate those\", \" arrays at all, which obviously yields a much larger gain.\\n\\nOne final example of peanut-buttery perf\", \"ormance improvements from applying an analyzer comes from dotnet/runtime#70896 and dotnet/runtime#71\", \"361, which applied IDE0029 across dotnet/runtime. IDE0029 flags cases where null coalescing can be u\", \"sed, e.g. flagging:\\n\\n```\\nreturn message != null\\n```\\n\\n```\\n? message : string.Empty;\\n```\\n\\nand recommen\", \"ding it be converted to:\\n\\n```\\nreturn\\n```\\n\\n```\\nmessage ?? string.Empty;\\n```\\n\\nAs with some of the prev\", \"ious rules discussed, that in and of itself doesn't make a meaningful performance improvement, and r\", \"ather is about clarity and simplicity. However, in various cases it can. For example, the aforementi\", \"oned PRs contained an example like:\\n\\n```\\nnull\\n```\\n\\n```\\n!= foundColumns[i] ? foundColumns[i] : DBNull\", \".Value;\\n```\\n\\nwhich is rewritten to:\\n\\n```\\nfoundColumns[i] ?? DBNull.Value\\n```\\n\\nThis avoids an unneces\", \"sary re-access to an array. Or again from those PRs the expression:\\n\\nentry.GetKey(\\\\_thisCollection) \", \"!= null being changed to:\\n\\n```\\nentry.GetKey(_thisCollection) ?? \\\"key\\\"\\n```\\n\\nand avoiding an unnecessa\", \"ry table lookup.\\n\\n```\\n? entry.GetKey(_thisCollection) : \\\"key\\\"\\n```\\n\\n## What's Next?\\n\\nWhew! That was a\", \" lot. Congrats on getting through it all.\\n\\nThe next step is on you. Download the latest .NET 7 bits \", \"and take them for a spin. Upgrade your apps. Write and share your own benchmarks. Provide feedback, \", \"positive and critical. Find something you think can be better? Open an issue, or better yet, submit \", \"a PR with the fix. We're excited to w ork with you to polish .NET 7 to be the best .NET release yet;\", \" meanwhile, we're getting going on .NET 8 :)\\n\\nUntil next time\\u2026\\n\\nHappy coding!\\n\\n<!-- image -->\"]"