"[\"![](_page_0_Picture_0.jpeg)\\n\\n### Performance Improvements in .NET 7\\n\\nStephen Toub\\n\\nPartner Software \", \"Engineer, .NET\\n\\nMicrosoft\\n\\n#### Introduction\\n\\nA year ago, I published [Performance Improvements in .\", \"NET 6,](https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-6) following on the he\", \"els of similar posts for [.NET 5,](https://devblogs.microsoft.com/dotnet/performance-improvements-in\", \"-net-5) [.NET Core 3.0,](https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-core-\", \"3-0) [.NET Core 2.1,](https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-core-2-1\", \") and [.NET Core 2.0.](https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-core) I\", \" enjoy writing these posts and love reading developers' responses to them. One comment in particular\", \" last year resonated with me. The commenter cited the Die Hard movie quote, \\\"'When Alexander saw the\", \" breadth of his domain, he wept for there were no more worlds to conquer',\\\" and questioned whether .\", \"NET performance improvements were similar. Has the well run dry? Are there no more \\\"[performance] wo\", \"rlds to conquer\\\"? I'm a bit giddy to say that, even with how fast .NET 6 is, .NET 7 definitively hig\", \"hlights how much more can be and has been done.\\n\\nAs with previous versions of .NET, performance is a\", \" key focus that pervades the entire stack, whether it be features created explicitly for performance\", \" or non-performance-related features that are still designed and implemented with performance keenly\", \" in mind. And now that a .NET 7 release candidate is just around the corner, it's a good time to dis\", \"cuss much of it. Over the course of the last year, every time I've reviewed a PR that might positive\", \"ly impact performance, I've copied that link to a journal I maintain for the purposes of writing thi\", \"s post. When I sat down to write this a few weeks ago, I was faced with a list of almost 1000 perfor\", \"mance-impacting PRs (out of more than 7000 PRs that went into the release), and I'm excited to share\", \" approximately 500 of them here with you.\\n\\nOne thought before we dive in. In past years, I've receiv\", \"ed the odd piece of negative feedback about the length of some of my performance-focused write-ups, \", \"and while I disagree with the criticism, I respect the opinion. So, this year, consider this a \\\"choo\", \"se your own adventure.\\\" If you're here just looking for a super short adventure, one that provides t\", \"he top-level summary and a core message to take away from your time here, I'm happy to oblige:\\n\\nTL;D\", \"R: .NET 7 is fast. Really fast. A thousand performance-impacting PRs went into runtime and core libr\", \"aries this release, never mind all the improvements in ASP.NET Core and Windows Forms and Entity Fra\", \"mework and beyond. It's the fastest .NET ever. If your manager asks you why your project should upgr\", \"ade to .NET 7, you can say \\\"in addition to all the new functionality in the release, .NET 7 is super\", \" fast.\\\"\\n\\nOr, if you prefer a slightly longer adventure, one filled with interesting nuggets of perfo\", \"rmancefocused data, consider skimming through the post, looking for the small code snippets and corr\", \"esponding tables showing a wealth of measurable performance improvements. At that point, you, too, m\", \"ay walk away with your head held high and my thanks.\\n\\nBoth noted paths achieve one of my primary goa\", \"ls for spending the time to write these posts, to highlight the greatness of the next release and to\", \" encourage everyone to give it a try. But, I have other goals for these posts, too. I want everyone \", \"interested to walk away from this post with an upleveled understanding of how .NET is implemented, w\", \"hy various decisions were made, tradeoffs that were evaluated, techniques that were employed, algori\", \"thms that were considered, and valuable tools and approaches that were utilized to make .NET even fa\", \"ster than it was previously. I want developers to learn from our own learnings and find ways to appl\", \"y this new-found knowledge to their own codebases, thereby further increasing the overall performanc\", \"e of code in the ecosystem. I want developers to take an extra beat, think about reaching for a prof\", \"iler the next time they're working on a gnarly problem, think about looking at the source for the co\", \"mponent they're using in order to better understand how to work with it, and think about revisiting \", \"previous assumptions and decisions to determine whether they're still accurate and appropriate. And \", \"I want developers to be excited at the prospect of submitting PRs to improve .NET not only for thems\", \"elves but for every developer around the globe using .NET. If any of that sounds interesting, then I\", \" encourage you to choose the last adventure: prepare a carafe of your favorite hot beverage, get com\", \"fortable, and please enjoy.\\n\\n#### Contents\\n\\n| Setup                                  |     |\\n|------\", \"----------------------------------|-----|\\n| JIT                                    | 3   |\\n| On-Stac\", \"k Replacement                   | 13  |\\n| PGO                                    | 23  |\\n| Bounds Ch\", \"eck Elimination               | 35  |\\n| Loop Hoisting and Cloning              | 45  |\\n| Folding, pr\", \"opagation, and substitution | 50  |\\n| Vectorization                          | 54  |\\n| Inlining     \", \"                          | 62  |\\n| Arm64                                  | 64  |\\n| JIT helpers    \", \"                        | 65  |\\n| Grab Bag                               | 67  |\\n| GC               \", \"                      | 71  |\\n| Native AOT                             | 72  |\\n| Mono               \", \"                    | 75  |\\n| Reflection                             | 78  |\\n| Interop              \", \"                  | 82  |\\n| Threading                              |     |\\n| Primitive Types and Num\", \"erics           |     |\\n| Arrays, Strings, and Spans             | 101 |\\n| Regex                    \", \"              | 128 |\\n| RegexOptions.NonBacktracking           | 128 |\\n| New APIs                   \", \"            | 133 |\\n| TryFindNextPossibleStartingPosition    | 138 |\\n| Loops and Backtracking       \", \"          | 143 |\\n| Code generation                        | 146 |\\n| Collections                    \", \"        | 150 |\\n| LINQ                                   | 153 |\\n|                                  \", \"      |     |\\n\\n| File I/O     | 159 |\\n|--------------|-----|\\n| Compression  | 168 |\\n| Networking   |\", \" 173 |\\n| JSON         | 190 |\\n| XML          | 193 |\\n| Cryptography | 198 |\\n| Diagnostics  | 203 |\\n|\", \" Exceptions   | 208 |\\n| Registry     | 211 |\\n| Analyzers    | 213 |\\n| What's Next? | 227 |\\n\\n**CHAPTE\", \"R** 1\\n\\n### <span id=\\\"page-5-0\\\"></span>Setup\\n\\nThe microbenchmarks throughout this post utilize [bench\", \"markdotnet.](https://github.com/dotnet/benchmarkdotnet) To make it easy for you to follow along with\", \" your own validation, I have a very simple setup for the benchmarks I use. Create a new C# project:\\n\", \"\\n```\\ndotnet new console -o benchmarks\\ncd benchmarks\\n```\\n\\nYour new benchmarks directory will contain \", \"a benchmarks.csproj file and a Program.cs file. Replace the contents of benchmarks.csproj with this:\", \"\\n\\n```\\n<Project Sdk=\\\"Microsoft.NET.Sdk\\\">\\n <PropertyGroup>\\n <OutputType>Exe</OutputType>\\n <TargetFrame\", \"works>net7.0;net6.0</TargetFrameworks>\\n <LangVersion>Preview</LangVersion>\\n <AllowUnsafeBlocks>true<\", \"/AllowUnsafeBlocks>\\n <ServerGarbageCollection>true</ServerGarbageCollection>\\n </PropertyGroup>\\n <Ite\", \"mGroup>\\n <PackageReference Include=\\\"benchmarkdotnet\\\" Version=\\\"0.13.2\\\" />\\n </ItemGroup>\\n</Project>\\n``\", \"`\\n\\nand the contents of Program.cs with this:\\n\\n```\\nusing BenchmarkDotNet.Attributes;\\nusing BenchmarkD\", \"otNet.Running;\\nusing Microsoft.Win32;\\nusing System;\\nusing System.Buffers;\\nusing System.Collections.G\", \"eneric;\\nusing System.Collections.Immutable;\\nusing System.ComponentModel;\\nusing System.Diagnostics;\\nu\", \"sing System.IO;\\nusing System.IO.Compression;\\nusing System.IO.MemoryMappedFiles;\\nusing System.IO.Pipe\", \"s;\\nusing System.Linq;\\nusing System.Net;\\nusing System.Net.Http;\\nusing System.Net.Http.Headers;\\nusing \", \"System.Net.Security;\\nusing System.Net.Sockets;\\nusing System.Numerics;\\n```\\n\\n1 CHAPTER 1 | Setup\\n\\n```\\n\", \"using System.Reflection;\\nusing System.Runtime.CompilerServices;\\nusing System.Runtime.InteropServices\", \";\\nusing System.Runtime.Intrinsics;\\nusing System.Security.Authentication;\\nusing System.Security.Crypt\", \"ography;\\nusing System.Security.Cryptography.X509Certificates;\\nusing System.Text;\\nusing System.Text.J\", \"son;\\nusing System.Text.RegularExpressions;\\nusing System.Threading;\\nusing System.Threading.Tasks;\\nusi\", \"ng System.Xml;\\n[MemoryDiagnoser(displayGenColumns: false)]\\n[DisassemblyDiagnoser]\\n[HideColumns(\\\"Erro\", \"r\\\", \\\"StdDev\\\", \\\"Median\\\", \\\"RatioSD\\\")]\\npublic partial class Program\\n{\\n static void Main(string[] args) \", \"=> \\nBenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args);\\n // ... copy [Benchmark]s he\", \"re\\n}\\n```\\n\\nFor each benchmark included in this write-up, you can then just copy and paste the code in\", \"to this test class, and run the benchmarks. For example, to run a benchmark comparing performance on\", \" .NET 6 and .NET 7, do:\\n\\n```\\ndotnet run -c Release -f net6.0 --filter '**' --runtimes net6.0 net7.0\\n\", \"```\\n\\nThis command says \\\"build the benchmarks in release configuration targeting the .NET 6 surface a\", \"rea, and then run all of the benchmarks on both .NET 6 and .NET 7.\\\" Or to run just on .NET 7:\\n\\n```\\nd\", \"otnet run -c Release -f net7.0 --filter '**' --runtimes net7.0\\n```\\n\\nwhich instead builds targeting t\", \"he .NET 7 surface area and then only runs once against .NET 7. You can do this on any of Windows, Li\", \"nux, or macOS. Unless otherwise called out (e.g. where the improvements are specific to Unix and I r\", \"un the benchmarks on Linux), the results I share were recorded on Windows 11 64-bit but aren't Windo\", \"ws-specific and should show similar relative differences on the other operating systems as well.\\n\\nTh\", \"e release of the first .NET 7 release candidate is right around the corner. All of the measurements \", \"in this post were gathered with a recent [daily build](https://github.com/dotnet/installer/blob/main\", \"/README.md#installers-and-binaries) of .NET 7 RC1.\\n\\nAlso, my standard caveat: These are microbenchma\", \"rks. It is expected that different hardware, different versions of operating systems, and the way in\", \" which the wind is currently blowing can affect the numbers involved. Your mileage may vary.\\n\\n2 CHAP\", \"TER 1 | Setup\\n\\n### <span id=\\\"page-7-0\\\"></span>JIT\\n\\nI'd like to kick off a discussion of performance \", \"improvements in the Just-In-Time (JIT) compiler by talking about something that itself isn't actuall\", \"y a performance improvement. Being able to understand exactly what assembly code is generated by the\", \" JIT is critical when fine-tuning lower-level, performance-sensitive code. There are multiple ways t\", \"o get at that assembly code. The online tool [sharplab.io](https://sharplab.io/#v2:EYLgxg9gTgpgtADwG\", \"wBYA0AXEBDAzgWwB8ABAJgEYBYAKGIGYACMhgYRoG8aHuGAHKAJYA3bBhgMBAOwwMA+tgYBeBilJo5wJQwAcKANxce9CdIYBZKQA\", \"oAlEoB850QAsAdBcmX562cGsHqAL5AA) is *incredibly useful* for this (thanks to [@ashmind](https://githu\", \"b.com/ashmind) for this tool); however it currently only targets a single release, so as I write thi\", \"s I'm only able to see the output for .NET 6, which makes it difficult to use for A/B comparisons. [\", \"godbolt.org](https://godbolt.org/z/4v33asW6z) is also valuable for this, with C# support added in [c\", \"ompiler-explorer/compiler-explorer#3168](https://github.com/compiler-explorer/compiler-explorer/pull\", \"/3168) from [@hez2010](https://github.com/hez2010), with similar limitations. The most flexible solu\", \"tions involve getting at that assembly code locally, as it enables comparing whatever versions or lo\", \"cal builds you desire with whatever configurations and switches set that you need.\\n\\nOne common appro\", \"ach is to use the [DisassemblyDiagnoser] in benchmarkdotnet. Simply slap the [DisassemblyDiagnoser] \", \"attribute onto your test class: benchmarkdotnet will find the assembly code generated for your tests\", \" and some depth of functions they call, and dump out the found assembly code in a human-readable for\", \"m. For example, if I run this test:\\n\\n```\\nusing BenchmarkDotNet.Attributes;\\nusing BenchmarkDotNet.Run\", \"ning;\\nusing System;\\n[DisassemblyDiagnoser]\\npublic partial class Program\\n{\\n static void Main(string[]\", \" args) => \\nBenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args);\\n private int _a = 42,\", \" _b = 84;\\n [Benchmark]\\n public int Min() => Math.Min(_a, _b);\\n}\\n```\\n\\nwith:\\n\\n```\\ndotnet run -c Releas\", \"e -f net7.0 --filter '**'\\n```\\n\\nin addition to doing all of its normal test execution and timing, ben\", \"chmarkdotnet also outputs a Program-asm.md file that contains this:\\n\\n```\\n; Program.Min()\\n mov eax,[r\", \"cx+8]\\n mov edx,[rcx+0C]\\n cmp eax,edx\\n```\\n\\n```\\n jg short M00_L01\\n mov edx,eax\\nM00_L00:\\n mov eax,edx\\n \", \"ret\\nM00_L01:\\n jmp short M00_L00\\n; Total bytes of code 17\\n```\\n\\nPretty neat. This support was recently\", \" improved further in [dotnet/benchmarkdotnet#2072,](https://github.com/dotnet/BenchmarkDotNet/pull/2\", \"072) which allows passing a filter list on the command-line to benchmarkdotnet to tell it exactly wh\", \"ich methods' assembly code should be dumped.\\n\\nIf you can get your hands on a \\\"debug\\\" or \\\"checked\\\" bu\", \"ild of the .NET runtime (\\\"checked\\\" is a build that has optimizations enabled but also still includes\", \" asserts), and specifically of clrjit.dll, another valuable approach is to set an environment variab\", \"le that causes the JIT itself to spit out a humanreadable description of all of the assembly code it\", \" emits. This can be used with any kind of application, as it's part of the JIT itself rather than pa\", \"rt of any specific tool or other environment, it supports showing the code the JIT generates each ti\", \"me it generates code (e.g. if it first compiles a method without optimization and then later recompi\", \"les it with optimization), and overall it's the most accurate picture of the assembly code as it com\", \"es \\\"straight from the horses mouth,\\\" as it were. The (big) downside of course is that it requires a \", \"non-release build of the runtime, which typically means you need to build it yourself from the sourc\", \"es in the [dotnet/runtime](https://github.com/dotnet/runtime) repo.\\n\\n\\u2026 until .NET 7, that is. As of \", \"[dotnet/runtime#73365,](https://github.com/dotnet/runtime/pull/73365) this assembly dumping support \", \"is now available in release builds as well, which means it's simply part of .NET 7 and you don't nee\", \"d anything special to use it. To see this, try creating a simple \\\"hello world\\\" app like:\\n\\n```\\nusing \", \"System;\\nclass Program\\n{\\n public static void Main() => Console.WriteLine(\\\"Hello, world!\\\");\\n}\\n```\\n\\nand\", \" building it (e.g. dotnet build -c Release). Then, set the DOTNET\\\\_JitDisasm environment variable to\", \" the name of the method we care about, in this case \\\"Main\\\" (the exact syntax allowed is more permiss\", \"ive and allows for some use of wildcards, optional namespace and class names, etc.). As I'm using Po\", \"werShell, that means:\\n\\n```\\n$env:DOTNET_JitDisasm=\\\"Main\\\"\\n```\\n\\nand then running the app. You should se\", \"e code like this output to the console:\\n\\n```\\n; Assembly listing for method Program:Main()\\n; Emitting\", \" BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; MinOpts code\\n; rbp based frame\\n;\", \" partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n 55 push rbp\\n 4883EC20 sub rsp, 32\\n```\\n\\n```\\n 4\", \"88D6C2420 lea rbp, [rsp+20H]\\nG_M000_IG02: ;; offset=000AH\\n 48B9D820400A8E010000 mov rcx, 0x18E0A4020\", \"D8\\n 488B09 mov rcx, gword ptr [rcx]\\n FF1583B31000 call [Console:WriteLine(String)]\\n 90 nop\\nG_M000_IG\", \"03: ;; offset=001EH\\n 4883C420 add rsp, 32\\n 5D pop rbp\\n C3 ret\\n; Total bytes of code 36\\nHello, world!\", \"\\n```\\n\\nThis is immeasurably helpful for performance analysis and tuning, even for questions as simple\", \" as \\\"did my function get inlined\\\" or \\\"is this code I expected to be optimized away actually getting \", \"optimized away.\\\" Throughout the rest of this post, I'll include assembly snippets generated by one o\", \"f these two mechanisms, in order to help exemplify concepts.\\n\\nNote that it can sometimes be a little\", \" confusing figuring out what name to specify as the value for DOTNET\\\\_JitDisasm, especially when the\", \" method you care about is one that the C# compiler names or name mangles (since the JIT only sees th\", \"e IL and metadata, not the original C#), e.g. the name of the entry point method for a program with \", \"top-level statements, the names of local functions, etc. To both help with this and to provide a rea\", \"lly valuable top-level view of the work the JIT is doing, .NET 7 also supports the new DOTNET\\\\_JitDi\", \"sasmSummary environment variable (introduced in [dotnet/runtime#74090](https://github.com/dotnet/run\", \"time/pull/74090)). Set that to \\\"1\\\", and it'll result in the JIT emitting a line every time it compil\", \"es a method, including the name of that method which is copy/pasteable with DOTNET\\\\_JitDisasm. This \", \"feature is useful in-and-of-itself, however, as it can quickly highlight for you what's being compil\", \"ed, when, and with what settings. For example, if I set the environment variable and then run a \\\"hel\", \"lo, world\\\" console app, I get this output:\\n\\n```\\n 1: JIT compiled CastHelpers:StelemRef(Array,long,Ob\", \"ject) [Tier1, IL size=88, code \\nsize=93]\\n 2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):by\", \"ref [Tier1, IL size=44, code \\nsize=44]\\n 3: JIT compiled SpanHelpers:IndexOfNullCharacter(byref):int \", \"[Tier1, IL size=792, code \\nsize=388]\\n 4: JIT compiled Program:Main() [Tier0, IL size=11, code size=3\", \"6]\\n 5: JIT compiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL \\nsize=490, code \", \"size=1187]\\nHello, world!\\n```\\n\\nWe can see for \\\"hello, world\\\" there's only 5 methods that actually get\", \" JIT compiled. There are of course many more methods that get executed as part of a simple \\\"hello, w\", \"orld,\\\" but almost all of them have precompiled native code available as part of the [\\\"Ready To Run\\\" \", \"\\\\(R2R\\\\)](https://docs.microsoft.com/dotnet/core/deploying/ready-to-run) images of the core libraries\", \". The first three in the above list (StelemRef, LdelemaRef, and IndexOfNullCharacter) don't because \", \"they explicitly opted-out of R2R via use of the\\n\\n[MethodImpl(MethodImplOptions.AggressiveOptimizatio\", \"n)] attribute (despite the name, this attribute should almost never be used, and is only used for ve\", \"ry specific reasons in a few very specific places in the core libraries). Then there's our Main meth\", \"od. And lastly there's the NarrowUtf16ToAscii\\n\\nmethod, which doesn't have R2R code, either, due to u\", \"sing the variable-width Vector<T> (more on that later). Every other method that's run doesn't requir\", \"e JIT'ing. If we instead first set the DOTNET\\\\_ReadyToRun environment variable to 0, the list is muc\", \"h longer, and gives you a very good sense of what the JIT needs to do on startup (and why technologi\", \"es like R2R are important for startup time). Note how many methods get compiled before \\\"hello, world\", \"\\\" is output:\\n\\n```\\n 1: JIT compiled CastHelpers:StelemRef(Array,long,Object) [Tier1, IL size=88, code\", \" \\nsize=93]\\n 2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):byref [Tier1, IL size=44, code \\n\", \"size=44]\\n 3: JIT compiled AppContext:Setup(long,long,int) [Tier0, IL size=68, code size=275]\\n 4: JIT\", \" compiled Dictionary`2:.ctor(int):this [Tier0, IL size=9, code size=40]\\n 5: JIT compiled Dictionary`\", \"2:.ctor(int,IEqualityComparer`1):this [Tier0, IL size=102, \\ncode size=444]\\n 6: JIT compiled Object:.\", \"ctor():this [Tier0, IL size=1, code size=10]\\n 7: JIT compiled Dictionary`2:Initialize(int):int:this \", \"[Tier0, IL size=56, code size=231]\\n 8: JIT compiled HashHelpers:GetPrime(int):int [Tier0, IL size=83\", \", code size=379]\\n 9: JIT compiled HashHelpers:.cctor() [Tier0, IL size=24, code size=102]\\n 10: JIT c\", \"ompiled HashHelpers:GetFastModMultiplier(int):long [Tier0, IL size=9, code \\nsize=37]\\n 11: JIT compil\", \"ed Type:GetTypeFromHandle(RuntimeTypeHandle):Type [Tier0, IL size=8, code \\nsize=14]\\n 12: JIT compile\", \"d Type:op_Equality(Type,Type):bool [Tier0, IL size=38, code size=143]\\n 13: JIT compiled \\nNonRandomiz\", \"edStringEqualityComparer:GetStringComparer(Object):IEqualityComparer`1 [Tier0, \\nIL size=39, code siz\", \"e=170]\\n 14: JIT compiled NonRandomizedStringEqualityComparer:.cctor() [Tier0, IL size=46, code \\nsize\", \"=232]\\n 15: JIT compiled EqualityComparer`1:get_Default():EqualityComparer`1 [Tier0, IL size=6, \\ncode\", \" size=36]\\n 16: JIT compiled EqualityComparer`1:.cctor() [Tier0, IL size=26, code size=125]\\n 17: JIT \", \"compiled ComparerHelpers:CreateDefaultEqualityComparer(Type):Object [Tier0, IL \\nsize=235, code size=\", \"949]\\n 18: JIT compiled CastHelpers:ChkCastClass(long,Object):Object [Tier0, IL size=22, code \\nsize=7\", \"2]\\n 19: JIT compiled RuntimeHelpers:GetMethodTable(Object):long [Tier0, IL size=11, code \\nsize=33]\\n \", \"20: JIT compiled CastHelpers:IsInstanceOfClass(long,Object):Object [Tier0, IL size=97, \\ncode size=25\", \"7]\\n 21: JIT compiled GenericEqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31]\\n 22: JI\", \"T compiled EqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31]\\n 23: JIT compiled CastHe\", \"lpers:ChkCastClassSpecial(long,Object):Object [Tier0, IL size=87, \\ncode size=246]\\n 24: JIT compiled \", \"OrdinalComparer:.ctor(IEqualityComparer`1):this [Tier0, IL size=8, code \\nsize=39]\\n 25: JIT compiled \", \"NonRandomizedStringEqualityComparer:.ctor(IEqualityComparer`1):this \\n[Tier0, IL size=14, code size=5\", \"2]\\n 26: JIT compiled StringComparer:get_Ordinal():StringComparer [Tier0, IL size=6, code \\nsize=49]\\n \", \"27: JIT compiled OrdinalCaseSensitiveComparer:.cctor() [Tier0, IL size=11, code size=71]\\n 28: JIT co\", \"mpiled OrdinalCaseSensitiveComparer:.ctor():this [Tier0, IL size=8, code \\nsize=33]\\n 29: JIT compiled\", \" OrdinalComparer:.ctor(bool):this [Tier0, IL size=14, code size=43]\\n 30: JIT compiled StringComparer\", \":.ctor():this [Tier0, IL size=7, code size=31]\\n 31: JIT compiled StringComparer:get_OrdinalIgnoreCas\", \"e():StringComparer [Tier0, IL size=6, \\ncode size=49]\\n 32: JIT compiled OrdinalIgnoreCaseComparer:.cc\", \"tor() [Tier0, IL size=11, code size=71]\\n 33: JIT compiled OrdinalIgnoreCaseComparer:.ctor():this [Ti\", \"er0, IL size=8, code size=36]\\n 34: JIT compiled OrdinalIgnoreCaseComparer:.ctor(IEqualityComparer`1)\", \":this [Tier0, IL\\n```\\n\\n```\\nsize=8, code size=39]\\n 35: JIT compiled CastHelpers:ChkCastAny(long,Object\", \"):Object [Tier0, IL size=38, code \\nsize=115]\\n 36: JIT compiled CastHelpers:TryGet(long,long):int [Ti\", \"er0, IL size=129, code size=308]\\n 37: JIT compiled CastHelpers:TableData(ref):byref [Tier0, IL size=\", \"7, code size=31]\\n 38: JIT compiled MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7,\", \" code \\nsize=24]\\n 39: JIT compiled CastHelpers:KeyToBucket(byref,long,long):int [Tier0, IL size=38, c\", \"ode \\nsize=87]\\n 40: JIT compiled CastHelpers:HashShift(byref):int [Tier0, IL size=3, code size=16]\\n 4\", \"1: JIT compiled BitOperations:RotateLeft(long,int):long [Tier0, IL size=17, code \\nsize=23]\\n 42: JIT \", \"compiled CastHelpers:Element(byref,int):byref [Tier0, IL size=15, code size=33]\\n 43: JIT compiled Vo\", \"latile:Read(byref):int [Tier0, IL size=6, code size=16]\\n 44: JIT compiled String:Ctor(long):String [\", \"Tier0, IL size=57, code size=155]\\n 45: JIT compiled String:wcslen(long):int [Tier0, IL size=7, code \", \"size=31]\\n 46: JIT compiled SpanHelpers:IndexOfNullCharacter(byref):int [Tier1, IL size=792, code \\nsi\", \"ze=388]\\n 47: JIT compiled String:get_Length():int:this [Tier0, IL size=7, code size=17]\\n 48: JIT com\", \"piled Buffer:Memmove(byref,byref,long) [Tier0, IL size=59, code size=102]\\n 49: JIT compiled RuntimeH\", \"elpers:IsReferenceOrContainsReferences():bool [Tier0, IL size=2, \\ncode size=8]\\n 50: JIT compiled Buf\", \"fer:Memmove(byref,byref,long) [Tier0, IL size=480, code size=678]\\n 51: JIT compiled Dictionary`2:Add\", \"(__Canon,__Canon):this [Tier0, IL size=11, code size=55]\\n 52: JIT compiled Dictionary`2:TryInsert(__\", \"Canon,__Canon,ubyte):bool:this [Tier0, IL \\nsize=675, code size=2467]\\n 53: JIT compiled OrdinalCompar\", \"er:GetHashCode(String):int:this [Tier0, IL size=7, code \\nsize=37]\\n 54: JIT compiled String:GetNonRan\", \"domizedHashCode():int:this [Tier0, IL size=110, code \\nsize=290]\\n 55: JIT compiled BitOperations:Rota\", \"teLeft(int,int):int [Tier0, IL size=17, code size=20]\\n 56: JIT compiled Dictionary`2:GetBucket(int):\", \"byref:this [Tier0, IL size=29, code size=90]\\n 57: JIT compiled HashHelpers:FastMod(int,int,long):int\", \" [Tier0, IL size=20, code size=70]\\n 58: JIT compiled Type:get_IsValueType():bool:this [Tier0, IL siz\", \"e=7, code size=39]\\n 59: JIT compiled RuntimeType:IsValueTypeImpl():bool:this [Tier0, IL size=54, cod\", \"e \\nsize=158]\\n 60: JIT compiled RuntimeType:GetNativeTypeHandle():TypeHandle:this [Tier0, IL size=12,\", \" \\ncode size=48]\\n 61: JIT compiled TypeHandle:.ctor(long):this [Tier0, IL size=8, code size=25]\\n 62: \", \"JIT compiled TypeHandle:get_IsTypeDesc():bool:this [Tier0, IL size=14, code size=38]\\n 63: JIT compil\", \"ed TypeHandle:AsMethodTable():long:this [Tier0, IL size=7, code size=17]\\n 64: JIT compiled MethodTab\", \"le:get_IsValueType():bool:this [Tier0, IL size=20, code \\nsize=32]\\n 65: JIT compiled GC:KeepAlive(Obj\", \"ect) [Tier0, IL size=1, code size=10]\\n 66: JIT compiled Buffer:_Memmove(byref,byref,long) [Tier0, IL\", \" size=25, code size=279]\\n 67: JIT compiled Environment:InitializeCommandLineArgs(long,int,long):ref \", \"[Tier0, IL \\nsize=75, code size=332]\\n 68: JIT compiled Environment:.cctor() [Tier0, IL size=11, code \", \"size=163]\\n 69: JIT compiled StartupHookProvider:ProcessStartupHooks() [Tier-0 switched to FullOpts, \", \"\\nIL size=365, code size=1053]\\n 70: JIT compiled StartupHookProvider:get_IsSupported():bool [Tier0, I\", \"L size=18, code \\nsize=60]\\n 71: JIT compiled AppContext:TryGetSwitch(String,byref):bool [Tier0, IL si\", \"ze=97, code \\nsize=322]\\n 72: JIT compiled ArgumentException:ThrowIfNullOrEmpty(String,String) [Tier0,\", \" IL size=16, \\ncode size=53]\\n 73: JIT compiled String:IsNullOrEmpty(String):bool [Tier0, IL size=15, \", \"code size=58]\\n 74: JIT compiled AppContext:GetData(String):Object [Tier0, IL size=64, code size=205]\", \"\\n 75: JIT compiled ArgumentNullException:ThrowIfNull(Object,String) [Tier0, IL size=10, \\ncode size=4\", \"2]\\n 76: JIT compiled Monitor:Enter(Object,byref) [Tier0, IL size=17, code size=55]\\n```\\n\\n```\\n 77: JIT\", \" compiled Dictionary`2:TryGetValue(__Canon,byref):bool:this [Tier0, IL size=39, \\ncode size=97]\\n 78: \", \"JIT compiled Dictionary`2:FindValue(__Canon):byref:this [Tier0, IL size=391, code \\nsize=1466]\\n 79: J\", \"IT compiled EventSource:.cctor() [Tier0, IL size=34, code size=80]\\n 80: JIT compiled EventSource:Ini\", \"tializeIsSupported():bool [Tier0, IL size=18, code \\nsize=60]\\n 81: JIT compiled RuntimeEventSource:.c\", \"tor():this [Tier0, IL size=55, code size=184]\\n 82: JIT compiled \\nGuid:.ctor(int,short,short,ubyte,ub\", \"yte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte):this [Tier0, IL \\nsize=86, code size=132]\\n 83: JIT compiled \", \"EventSource:.ctor(Guid,String):this [Tier0, IL size=11, code size=90]\\n 84: JIT compiled EventSource:\", \".ctor(Guid,String,int,ref):this [Tier0, IL size=58, code \\nsize=187]\\n 85: JIT compiled EventSource:ge\", \"t_IsSupported():bool [Tier0, IL size=6, code size=11]\\n 86: JIT compiled TraceLoggingEventHandleTable\", \":.ctor():this [Tier0, IL size=20, code \\nsize=67]\\n 87: JIT compiled EventSource:ValidateSettings(int)\", \":int [Tier0, IL size=37, code size=147]\\n 88: JIT compiled EventSource:Initialize(Guid,String,ref):th\", \"is [Tier0, IL size=418, code \\nsize=1584]\\n 89: JIT compiled Guid:op_Equality(Guid,Guid):bool [Tier0, \", \"IL size=10, code size=39]\\n 90: JIT compiled Guid:EqualsCore(byref,byref):bool [Tier0, IL size=132, c\", \"ode size=171]\\n 91: JIT compiled ActivityTracker:get_Instance():ActivityTracker [Tier0, IL size=6, co\", \"de \\nsize=49]\\n 92: JIT compiled ActivityTracker:.cctor() [Tier0, IL size=11, code size=71]\\n 93: JIT c\", \"ompiled ActivityTracker:.ctor():this [Tier0, IL size=7, code size=31]\\n 94: JIT compiled RuntimeEvent\", \"Source:get_ProviderMetadata():ReadOnlySpan`1:this [Tier0, IL \\nsize=13, code size=91]\\n 95: JIT compil\", \"ed ReadOnlySpan`1:.ctor(long,int):this [Tier0, IL size=51, code size=115]\\n 96: JIT compiled RuntimeH\", \"elpers:IsReferenceOrContainsReferences():bool [Tier0, IL size=2, \\ncode size=8]\\n 97: JIT compiled Rea\", \"dOnlySpan`1:get_Length():int:this [Tier0, IL size=7, code size=17]\\n 98: JIT compiled OverrideEventPr\", \"ovider:.ctor(EventSource,int):this [Tier0, IL size=22, \\ncode size=68]\\n 99: JIT compiled EventProvide\", \"r:.ctor(int):this [Tier0, IL size=46, code size=194]\\n 100: JIT compiled EtwEventProvider:.ctor():thi\", \"s [Tier0, IL size=7, code size=31]\\n 101: JIT compiled EventProvider:Register(EventSource):this [Tier\", \"0, IL size=48, code \\nsize=186]\\n 102: JIT compiled MulticastDelegate:CtorClosed(Object,long):this [Ti\", \"er0, IL size=23, code \\nsize=70]\\n 103: JIT compiled EventProvider:EventRegister(EventSource,EtwEnable\", \"Callback):int:this \\n[Tier0, IL size=53, code size=154]\\n 104: JIT compiled EventSource:get_Name():Str\", \"ing:this [Tier0, IL size=7, code size=18]\\n 105: JIT compiled EventSource:get_Guid():Guid:this [Tier0\", \", IL size=7, code size=41]\\n 106: JIT compiled \\nEtwEventProvider:System.Diagnostics.Tracing.IEventPro\", \"vider.EventRegister(EventSource,EtwEna\\nbleCallback,long,byref):int:this [Tier0, IL size=19, code siz\", \"e=71]\\n 107: JIT compiled Advapi32:EventRegister(byref,EtwEnableCallback,long,byref):int [Tier0, \\nIL \", \"size=53, code size=374]\\n 108: JIT compiled Marshal:GetFunctionPointerForDelegate(__Canon):long [Tier\", \"0, IL size=17, \\ncode size=54]\\n 109: JIT compiled Marshal:GetFunctionPointerForDelegate(Delegate):lon\", \"g [Tier0, IL size=18, \\ncode size=53]\\n 110: JIT compiled EventPipeEventProvider:.ctor():this [Tier0, \", \"IL size=18, code size=41]\\n 111: JIT compiled EventListener:get_EventListenersLock():Object [Tier0, I\", \"L size=41, code \\nsize=157]\\n 112: JIT compiled List`1:.ctor(int):this [Tier0, IL size=47, code size=2\", \"75]\\n 113: JIT compiled Interlocked:CompareExchange(byref,__Canon,__Canon):__Canon [Tier0, IL \\nsize=9\", \", code size=50]\\n 114: JIT compiled NativeRuntimeEventSource:.cctor() [Tier0, IL size=11, code size=7\", \"1]\\n 115: JIT compiled NativeRuntimeEventSource:.ctor():this [Tier0, IL size=63, code size=184]\\n```\\n\\n\", \"```\\n116: JIT compiled \\nGuid:.ctor(int,ushort,ushort,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte)\", \":this [Tier0, \\nIL size=88, code size=132]\\n 117: JIT compiled NativeRuntimeEventSource:get_ProviderMe\", \"tadata():ReadOnlySpan`1:this \\n[Tier0, IL size=13, code size=91]\\n 118: JIT compiled \\nEventPipeEventPr\", \"ovider:System.Diagnostics.Tracing.IEventProvider.EventRegister(EventSource,\\nEtwEnableCallback,long,b\", \"yref):int:this [Tier0, IL size=44, code size=118]\\n 119: JIT compiled EventPipeInternal:CreateProvide\", \"r(String,EtwEnableCallback):long [Tier0, \\nIL size=43, code size=320]\\n 120: JIT compiled Utf16StringM\", \"arshaller:GetPinnableReference(String):byref [Tier0, IL \\nsize=13, code size=50]\\n 121: JIT compiled S\", \"tring:GetPinnableReference():byref:this [Tier0, IL size=7, code \\nsize=24]\\n 122: JIT compiled EventLi\", \"stener:AddEventSource(EventSource) [Tier0, IL size=175, code \\nsize=560]\\n 123: JIT compiled List`1:ge\", \"t_Count():int:this [Tier0, IL size=7, code size=17]\\n 124: JIT compiled WeakReference`1:.ctor(__Canon\", \"):this [Tier0, IL size=9, code size=42]\\n 125: JIT compiled WeakReference`1:.ctor(__Canon,bool):this \", \"[Tier0, IL size=15, code \\nsize=60]\\n 126: JIT compiled List`1:Add(__Canon):this [Tier0, IL size=60, c\", \"ode size=124]\\n 127: JIT compiled String:op_Inequality(String,String):bool [Tier0, IL size=11, code \\n\", \"size=46]\\n 128: JIT compiled String:Equals(String,String):bool [Tier0, IL size=36, code size=114]\\n 12\", \"9: JIT compiled ReadOnlySpan`1:GetPinnableReference():byref:this [Tier0, IL size=23, \\ncode size=57]\\n\", \" 130: JIT compiled EventProvider:SetInformation(int,long,int):int:this [Tier0, IL size=38, \\ncode siz\", \"e=131]\\n 131: JIT compiled ILStubClass:IL_STUB_PInvoke(long,int,long,int):int [FullOpts, IL \\nsize=62,\", \" code size=170]\\n 132: JIT compiled Program:Main() [Tier0, IL size=11, code size=36]\\n 133: JIT compil\", \"ed Console:WriteLine(String) [Tier0, IL size=12, code size=59]\\n 134: JIT compiled Console:get_Out():\", \"TextWriter [Tier0, IL size=20, code size=113]\\n 135: JIT compiled Console:.cctor() [Tier0, IL size=11\", \", code size=71]\\n 136: JIT compiled Volatile:Read(byref):__Canon [Tier0, IL size=6, code size=21]\\n 13\", \"7: JIT compiled Console:<get_Out>g__EnsureInitialized|26_0():TextWriter [Tier0, IL \\nsize=63, code si\", \"ze=209]\\n 138: JIT compiled ConsolePal:OpenStandardOutput():Stream [Tier0, IL size=34, code \\nsize=130\", \"]\\n 139: JIT compiled Console:get_OutputEncoding():Encoding [Tier0, IL size=72, code size=237]\\n 140: \", \"JIT compiled ConsolePal:get_OutputEncoding():Encoding [Tier0, IL size=11, code \\nsize=200]\\n 141: JIT \", \"compiled NativeLibrary:LoadLibraryCallbackStub(String,Assembly,bool,int):long \\n[Tier0, IL size=63, c\", \"ode size=280]\\n 142: JIT compiled EncodingHelper:GetSupportedConsoleEncoding(int):Encoding [Tier0, IL\", \" \\nsize=53, code size=186]\\n 143: JIT compiled Encoding:GetEncoding(int):Encoding [Tier0, IL size=340,\", \" code size=1025]\\n 144: JIT compiled EncodingProvider:GetEncodingFromProvider(int):Encoding [Tier0, I\", \"L \\nsize=51, code size=232]\\n 145: JIT compiled Encoding:FilterDisallowedEncodings(Encoding):Encoding \", \"[Tier0, IL \\nsize=29, code size=84]\\n 146: JIT compiled LocalAppContextSwitches:get_EnableUnsafeUTF7En\", \"coding():bool [Tier0, IL \\nsize=16, code size=46]\\n 147: JIT compiled LocalAppContextSwitches:GetCache\", \"dSwitchValue(String,byref):bool [Tier0, \\nIL size=22, code size=76]\\n 148: JIT compiled LocalAppContex\", \"tSwitches:GetCachedSwitchValueInternal(String,byref):bool \\n[Tier0, IL size=46, code size=168]\\n 149: \", \"JIT compiled LocalAppContextSwitches:GetSwitchDefaultValue(String):bool [Tier0, IL \\nsize=32, code si\", \"ze=98]\\n 150: JIT compiled String:op_Equality(String,String):bool [Tier0, IL size=8, code size=39]\\n 1\", \"51: JIT compiled Encoding:get_Default():Encoding [Tier0, IL size=6, code size=49]\\n```\\n\\n```\\n152: JIT \", \"compiled Encoding:.cctor() [Tier0, IL size=12, code size=73]\\n 153: JIT compiled UTF8EncodingSealed:.\", \"ctor(bool):this [Tier0, IL size=8, code size=40]\\n 154: JIT compiled UTF8Encoding:.ctor(bool):this [T\", \"ier0, IL size=14, code size=43]\\n 155: JIT compiled UTF8Encoding:.ctor():this [Tier0, IL size=12, cod\", \"e size=36]\\n 156: JIT compiled Encoding:.ctor(int):this [Tier0, IL size=42, code size=152]\\n 157: JIT \", \"compiled UTF8Encoding:SetDefaultFallbacks():this [Tier0, IL size=64, code \\nsize=212]\\n 158: JIT compi\", \"led EncoderReplacementFallback:.ctor(String):this [Tier0, IL size=110, code \\nsize=360]\\n 159: JIT com\", \"piled EncoderFallback:.ctor():this [Tier0, IL size=7, code size=31]\\n 160: JIT compiled String:get_Ch\", \"ars(int):ushort:this [Tier0, IL size=29, code size=61]\\n 161: JIT compiled Char:IsSurrogate(ushort):b\", \"ool [Tier0, IL size=17, code size=43]\\n 162: JIT compiled Char:IsBetween(ushort,ushort,ushort):bool [\", \"Tier0, IL size=12, code \\nsize=52]\\n 163: JIT compiled DecoderReplacementFallback:.ctor(String):this [\", \"Tier0, IL size=110, code \\nsize=360]\\n 164: JIT compiled DecoderFallback:.ctor():this [Tier0, IL size=\", \"7, code size=31]\\n 165: JIT compiled Encoding:get_CodePage():int:this [Tier0, IL size=7, code size=17\", \"]\\n 166: JIT compiled Encoding:get_UTF8():Encoding [Tier0, IL size=6, code size=49]\\n 167: JIT compile\", \"d UTF8Encoding:.cctor() [Tier0, IL size=12, code size=76]\\n 168: JIT compiled Volatile:Write(byref,__\", \"Canon) [Tier0, IL size=6, code size=32]\\n 169: JIT compiled ConsolePal:GetStandardFile(int,int,bool):\", \"Stream [Tier0, IL size=50, code \\nsize=183]\\n 170: JIT compiled ConsolePal:get_InvalidHandleValue():lo\", \"ng [Tier0, IL size=7, code \\nsize=41]\\n 171: JIT compiled IntPtr:.ctor(int):this [Tier0, IL size=9, co\", \"de size=25]\\n 172: JIT compiled ConsolePal:ConsoleHandleIsWritable(long):bool [Tier0, IL size=26, cod\", \"e \\nsize=68]\\n 173: JIT compiled Kernel32:WriteFile(long,long,int,byref,long):int [Tier0, IL size=46, \", \"\\ncode size=294]\\n 174: JIT compiled Marshal:SetLastSystemError(int) [Tier0, IL size=7, code size=40]\\n\", \" 175: JIT compiled Marshal:GetLastSystemError():int [Tier0, IL size=6, code size=34]\\n 176: JIT compi\", \"led WindowsConsoleStream:.ctor(long,int,bool):this [Tier0, IL size=37, code \\nsize=90]\\n 177: JIT comp\", \"iled ConsoleStream:.ctor(int):this [Tier0, IL size=31, code size=71]\\n 178: JIT compiled Stream:.ctor\", \"():this [Tier0, IL size=7, code size=31]\\n 179: JIT compiled MarshalByRefObject:.ctor():this [Tier0, \", \"IL size=7, code size=31]\\n 180: JIT compiled Kernel32:GetFileType(long):int [Tier0, IL size=27, code \", \"size=217]\\n 181: JIT compiled Console:CreateOutputWriter(Stream):TextWriter [Tier0, IL size=50, code \", \"\\nsize=230]\\n 182: JIT compiled Stream:.cctor() [Tier0, IL size=11, code size=71]\\n 183: JIT compiled N\", \"ullStream:.ctor():this [Tier0, IL size=7, code size=31]\\n 184: JIT compiled EncodingExtensions:Remove\", \"Preamble(Encoding):Encoding [Tier0, IL size=25, \\ncode size=118]\\n 185: JIT compiled UTF8EncodingSeale\", \"d:get_Preamble():ReadOnlySpan`1:this [Tier0, IL \\nsize=24, code size=99]\\n 186: JIT compiled UTF8Encod\", \"ing:get_PreambleSpan():ReadOnlySpan`1 [Tier0, IL size=12, code \\nsize=87]\\n 187: JIT compiled ConsoleE\", \"ncoding:.ctor(Encoding):this [Tier0, IL size=14, code size=52]\\n 188: JIT compiled Encoding:.ctor():t\", \"his [Tier0, IL size=8, code size=33]\\n 189: JIT compiled Encoding:SetDefaultFallbacks():this [Tier0, \", \"IL size=23, code size=65]\\n 190: JIT compiled EncoderFallback:get_ReplacementFallback():EncoderFallba\", \"ck [Tier0, IL \\nsize=6, code size=49]\\n 191: JIT compiled EncoderReplacementFallback:.cctor() [Tier0, \", \"IL size=11, code size=71]\\n 192: JIT compiled EncoderReplacementFallback:.ctor():this [Tier0, IL size\", \"=12, code \\nsize=44]\\n 193: JIT compiled DecoderFallback:get_ReplacementFallback():DecoderFallback [Ti\", \"er0, IL \\nsize=6, code size=49]\\n 194: JIT compiled DecoderReplacementFallback:.cctor() [Tier0, IL siz\", \"e=11, code size=71]\\n 195: JIT compiled DecoderReplacementFallback:.ctor():this [Tier0, IL size=12, c\", \"ode \\nsize=44]\\n```\\n\\n```\\n196: JIT compiled StreamWriter:.ctor(Stream,Encoding,int,bool):this [Tier0, I\", \"L size=201, \\ncode size=564]\\n 197: JIT compiled Task:get_CompletedTask():Task [Tier0, IL size=6, code\", \" size=49]\\n 198: JIT compiled Task:.cctor() [Tier0, IL size=76, code size=316]\\n 199: JIT compiled Tas\", \"kFactory:.ctor():this [Tier0, IL size=7, code size=31]\\n 200: JIT compiled Task`1:.ctor(bool,VoidTask\", \"Result,int,CancellationToken):this [Tier0, IL \\nsize=21, code size=75]\\n 201: JIT compiled Task:.ctor(\", \"bool,int,CancellationToken):this [Tier0, IL size=70, code \\nsize=181]\\n 202: JIT compiled <>c:.cctor()\", \" [Tier0, IL size=11, code size=71]\\n 203: JIT compiled <>c:.ctor():this [Tier0, IL size=7, code size=\", \"31]\\n 204: JIT compiled TextWriter:.ctor(IFormatProvider):this [Tier0, IL size=36, code \\nsize=124]\\n 2\", \"05: JIT compiled TextWriter:.cctor() [Tier0, IL size=26, code size=108]\\n 206: JIT compiled NullTextW\", \"riter:.ctor():this [Tier0, IL size=7, code size=31]\\n 207: JIT compiled TextWriter:.ctor():this [Tier\", \"0, IL size=29, code size=103]\\n 208: JIT compiled String:ToCharArray():ref:this [Tier0, IL size=52, c\", \"ode size=173]\\n 209: JIT compiled MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, c\", \"ode \\nsize=24]\\n 210: JIT compiled ConsoleStream:get_CanWrite():bool:this [Tier0, IL size=7, code size\", \"=18]\\n 211: JIT compiled ConsoleEncoding:GetEncoder():Encoder:this [Tier0, IL size=12, code \\nsize=57]\", \"\\n 212: JIT compiled UTF8Encoding:GetEncoder():Encoder:this [Tier0, IL size=7, code size=63]\\n 213: JI\", \"T compiled EncoderNLS:.ctor(Encoding):this [Tier0, IL size=37, code size=102]\\n 214: JIT compiled Enc\", \"oder:.ctor():this [Tier0, IL size=7, code size=31]\\n 215: JIT compiled Encoding:get_EncoderFallback()\", \":EncoderFallback:this [Tier0, IL size=7, \\ncode size=18]\\n 216: JIT compiled EncoderNLS:Reset():this [\", \"Tier0, IL size=24, code size=92]\\n 217: JIT compiled ConsoleStream:get_CanSeek():bool:this [Tier0, IL\", \" size=2, code size=12]\\n 218: JIT compiled StreamWriter:set_AutoFlush(bool):this [Tier0, IL size=25, \", \"code size=72]\\n 219: JIT compiled StreamWriter:CheckAsyncTaskInProgress():this [Tier0, IL size=19, co\", \"de \\nsize=47]\\n 220: JIT compiled Task:get_IsCompleted():bool:this [Tier0, IL size=16, code size=40]\\n \", \"221: JIT compiled Task:IsCompletedMethod(int):bool [Tier0, IL size=11, code size=25]\\n 222: JIT compi\", \"led StreamWriter:Flush(bool,bool):this [Tier0, IL size=272, code size=1127]\\n 223: JIT compiled Strea\", \"mWriter:ThrowIfDisposed():this [Tier0, IL size=15, code size=43]\\n 224: JIT compiled Encoding:get_Pre\", \"amble():ReadOnlySpan`1:this [Tier0, IL size=12, code \\nsize=70]\\n 225: JIT compiled ConsoleEncoding:Ge\", \"tPreamble():ref:this [Tier0, IL size=6, code size=27]\\n 226: JIT compiled Array:Empty():ref [Tier0, I\", \"L size=6, code size=49]\\n 227: JIT compiled EmptyArray`1:.cctor() [Tier0, IL size=12, code size=52]\\n \", \"228: JIT compiled ReadOnlySpan`1:op_Implicit(ref):ReadOnlySpan`1 [Tier0, IL size=7, code \\nsize=79]\\n \", \"229: JIT compiled ReadOnlySpan`1:.ctor(ref):this [Tier0, IL size=33, code size=81]\\n 230: JIT compile\", \"d MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24]\\n 231: JIT compile\", \"d ConsoleEncoding:GetMaxByteCount(int):int:this [Tier0, IL size=13, code \\nsize=63]\\n 232: JIT compile\", \"d UTF8EncodingSealed:GetMaxByteCount(int):int:this [Tier0, IL size=20, \\ncode size=50]\\n 233: JIT comp\", \"iled Span`1:.ctor(long,int):this [Tier0, IL size=51, code size=115]\\n 234: JIT compiled ReadOnlySpan`\", \"1:.ctor(ref,int,int):this [Tier0, IL size=65, code \\nsize=147]\\n 235: JIT compiled Encoder:GetBytes(Re\", \"adOnlySpan`1,Span`1,bool):int:this [Tier0, IL \\nsize=44, code size=234]\\n 236: JIT compiled MemoryMars\", \"hal:GetNonNullPinnableReference(ReadOnlySpan`1):byref [Tier0, \\nIL size=30, code size=54]\\n 237: JIT c\", \"ompiled ReadOnlySpan`1:get_Length():int:this [Tier0, IL size=7, code size=17]\\n 238: JIT compiled Mem\", \"oryMarshal:GetNonNullPinnableReference(Span`1):byref [Tier0, IL \\nsize=30, code size=54]\\n 239: JIT co\", \"mpiled Span`1:get_Length():int:this [Tier0, IL size=7, code size=17]\\n```\\n\\n```\\n240: JIT compiled Enco\", \"derNLS:GetBytes(long,int,long,int,bool):int:this [Tier0, IL size=92, \\ncode size=279]\\n 241: JIT compi\", \"led ArgumentNullException:ThrowIfNull(long,String) [Tier0, IL size=12, code \\nsize=45]\\n 242: JIT comp\", \"iled Encoding:GetBytes(long,int,long,int,EncoderNLS):int:this [Tier0, IL \\nsize=57, code size=187]\\n 2\", \"43: JIT compiled EncoderNLS:get_HasLeftoverData():bool:this [Tier0, IL size=35, code \\nsize=105]\\n 244\", \": JIT compiled UTF8Encoding:GetBytesFast(long,int,long,int,byref):int:this [Tier0, IL \\nsize=33, code\", \" size=119]\\n 245: JIT compiled Utf8Utility:TranscodeToUtf8(long,int,long,int,byref,byref):int [Tier0,\", \" \\nIL size=1446, code size=3208]\\n 246: JIT compiled Math:Min(int,int):int [Tier0, IL size=8, code siz\", \"e=28]\\n 247: JIT compiled ASCIIUtility:NarrowUtf16ToAscii(long,long,long):long [Tier0, IL \\nsize=490, \", \"code size=1187]\\n 248: JIT compiled WindowsConsoleStream:Flush():this [Tier0, IL size=26, code size=5\", \"6]\\n 249: JIT compiled ConsoleStream:Flush():this [Tier0, IL size=1, code size=10]\\n 250: JIT compiled\", \" TextWriter:Synchronized(TextWriter):TextWriter [Tier0, IL size=28, code \\nsize=121]\\n 251: JIT compil\", \"ed SyncTextWriter:.ctor(TextWriter):this [Tier0, IL size=14, code size=52]\\n 252: JIT compiled SyncTe\", \"xtWriter:WriteLine(String):this [Tier0, IL size=13, code size=140]\\n 253: JIT compiled StreamWriter:W\", \"riteLine(String):this [Tier0, IL size=20, code size=110]\\n 254: JIT compiled String:op_Implicit(Strin\", \"g):ReadOnlySpan`1 [Tier0, IL size=31, code \\nsize=171]\\n 255: JIT compiled String:GetRawStringData():b\", \"yref:this [Tier0, IL size=7, code size=24]\\n 256: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [\", \"Tier0, IL size=15, code size=39]\\n 257: JIT compiled StreamWriter:WriteSpan(ReadOnlySpan`1,bool):this\", \" [Tier0, IL size=368, \\ncode size=1036]\\n 258: JIT compiled MemoryMarshal:GetReference(ReadOnlySpan`1)\", \":byref [Tier0, IL size=8, code \\nsize=17]\\n 259: JIT compiled Buffer:MemoryCopy(long,long,long,long) [\", \"Tier0, IL size=21, code size=83]\\n 260: JIT compiled Unsafe:ReadUnaligned(long):long [Tier0, IL size=\", \"10, code size=17]\\n 261: JIT compiled ASCIIUtility:AllCharsInUInt64AreAscii(long):bool [Tier0, IL siz\", \"e=16, \\ncode size=38]\\n 262: JIT compiled ASCIIUtility:NarrowFourUtf16CharsToAsciiAndWriteToBuffer(byr\", \"ef,long) \\n[Tier0, IL size=107, code size=171]\\n 263: JIT compiled Unsafe:WriteUnaligned(byref,int) [T\", \"ier0, IL size=11, code size=22]\\n 264: JIT compiled Unsafe:ReadUnaligned(long):int [Tier0, IL size=10\", \", code size=16]\\n 265: JIT compiled ASCIIUtility:AllCharsInUInt32AreAscii(int):bool [Tier0, IL size=1\", \"1, code \\nsize=25]\\n 266: JIT compiled ASCIIUtility:NarrowTwoUtf16CharsToAsciiAndWriteToBuffer(byref,i\", \"nt) \\n[Tier0, IL size=24, code size=35]\\n 267: JIT compiled Span`1:Slice(int,int):Span`1:this [Tier0, \", \"IL size=39, code size=135]\\n 268: JIT compiled Span`1:.ctor(byref,int):this [Tier0, IL size=15, code \", \"size=39]\\n 269: JIT compiled Span`1:op_Implicit(Span`1):ReadOnlySpan`1 [Tier0, IL size=19, code \\nsize\", \"=90]\\n 270: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, code size=39]\\n 271:\", \" JIT compiled WindowsConsoleStream:Write(ReadOnlySpan`1):this [Tier0, IL size=35, code \\nsize=149]\\n 2\", \"72: JIT compiled WindowsConsoleStream:WriteFileNative(long,ReadOnlySpan`1,bool):int \\n[Tier0, IL size\", \"=107, code size=272]\\n 273: JIT compiled ReadOnlySpan`1:get_IsEmpty():bool:this [Tier0, IL size=10, c\", \"ode size=24]\\nHello, world!\\n 274: JIT compiled AppContext:OnProcessExit() [Tier0, IL size=43, code si\", \"ze=161]\\n 275: JIT compiled AssemblyLoadContext:OnProcessExit() [Tier0, IL size=101, code size=442]\\n \", \"276: JIT compiled EventListener:DisposeOnShutdown() [Tier0, IL size=150, code size=618]\\n 277: JIT co\", \"mpiled List`1:.ctor():this [Tier0, IL size=18, code size=133]\\n 278: JIT compiled List`1:.cctor() [Ti\", \"er0, IL size=12, code size=129]\\n 279: JIT compiled List`1:GetEnumerator():Enumerator:this [Tier0, IL\", \" size=7, code size=162]\\n 280: JIT compiled Enumerator:.ctor(List`1):this [Tier0, IL size=39, code si\", \"ze=64]\\n 281: JIT compiled Enumerator:MoveNext():bool:this [Tier0, IL size=81, code size=159]\\n```\\n\\n``\", \"`\\n282: JIT compiled Enumerator:get_Current():__Canon:this [Tier0, IL size=7, code size=22]\\n 283: JIT\", \" compiled WeakReference`1:TryGetTarget(byref):bool:this [Tier0, IL size=24, code \\nsize=66]\\n 284: JIT\", \" compiled List`1:AddWithResize(__Canon):this [Tier0, IL size=39, code size=85]\\n 285: JIT compiled Li\", \"st`1:Grow(int):this [Tier0, IL size=53, code size=121]\\n 286: JIT compiled List`1:set_Capacity(int):t\", \"his [Tier0, IL size=86, code size=342]\\n 287: JIT compiled CastHelpers:StelemRef_Helper(byref,long,Ob\", \"ject) [Tier0, IL size=34, code \\nsize=104]\\n 288: JIT compiled CastHelpers:StelemRef_Helper_NoCacheLoo\", \"kup(byref,long,Object) [Tier0, IL \\nsize=26, code size=111]\\n 289: JIT compiled Enumerator:MoveNextRar\", \"e():bool:this [Tier0, IL size=57, code size=80]\\n 290: JIT compiled Enumerator:Dispose():this [Tier0,\", \" IL size=1, code size=14]\\n 291: JIT compiled EventSource:Dispose():this [Tier0, IL size=14, code siz\", \"e=54]\\n 292: JIT compiled EventSource:Dispose(bool):this [Tier0, IL size=124, code size=236]\\n 293: JI\", \"T compiled EventProvider:Dispose():this [Tier0, IL size=14, code size=54]\\n 294: JIT compiled EventPr\", \"ovider:Dispose(bool):this [Tier0, IL size=90, code size=230]\\n 295: JIT compiled EventProvider:EventU\", \"nregister(long):this [Tier0, IL size=14, code \\nsize=50]\\n 296: JIT compiled \\nEtwEventProvider:System.\", \"Diagnostics.Tracing.IEventProvider.EventUnregister(long):int:this \\n[Tier0, IL size=7, code size=181]\", \"\\n 297: JIT compiled GC:SuppressFinalize(Object) [Tier0, IL size=18, code size=53]\\n 298: JIT compiled\", \" \\nEventPipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventUnregister(long):int:\\nthis [\", \"Tier0, IL size=13, code size=187]\\n```\\n\\nWith that out of the way, let's move on to actual performance\", \" improvements, starting with on-stack replacement.\\n\\n#### <span id=\\\"page-17-0\\\"></span>**On-Stack Repl\", \"acement**\\n\\nOn-stack replacement (OSR) is one of the coolest features to hit the JIT in .NET 7. But t\", \"o really understand OSR, we first need to understand tiered compilation, so a quick recap\\u2026\\n\\nOne of t\", \"he issues a managed environment with a JIT compiler has to deal with is tradeoffs between startup an\", \"d throughput. Historically, the job of an optimizing compiler is to, well, optimize, in order to ena\", \"ble the best possible throughput of the application or service once running. But such optimization t\", \"akes analysis, takes time, and performing all of that work then leads to increased startup time, as \", \"all of the code on the startup path (e.g. all of the code that needs to be run before a web server c\", \"an serve the first request) needs to be compiled. So a JIT compiler needs to make tradeoffs: better \", \"throughput at the expense of longer startup time, or better startup time at the expense of decreased\", \" throughput. For some kinds of apps and services, the tradeoff is an easy call, e.g. if your service\", \" starts up once and then runs for days, several extra seconds of startup time doesn't matter, or if \", \"you're a console application that's going to do a quick computation and exit, startup time is all th\", \"at matters. But how can the JIT know which scenario it's in, and do we really want every developer h\", \"aving to know about these kinds of settings and tradeoffs and configure every one of their applicati\", \"ons accordingly? One answer to this has been ahead-of-time compilation, which has taken various form\", \"s in .NET. For example, all of the core libraries are \\\"crossgen\\\"'d, meaning they've been run through\", \" a tool that produces the previously mentioned R2R format, yielding binaries that contain assembly c\", \"ode that needs only minor tweaks to actually execute; not every method can have code generated for i\", \"t, but enough that it significantly reduces startup time. Of course, such approaches have their own \", \"downsides, e.g. one of the promises of a JIT compiler is it can take advantage of knowledge of the c\", \"urrent machine / process in order to best optimize, so for example the R2R images have to assume a\\n\\n\", \"certain baseline instruction set (e.g. what vectorizing instructions are available) whereas the JIT \", \"can see what's actually available and use the best. \\\"Tiered compilation\\\" provides another answer, on\", \"e that's usable with or without these other ahead-of-time (AOT) compilation solutions.\\n\\nTiered compi\", \"lation enables the JIT to have its proverbial cake and eat it, too. The idea is simple: allow the JI\", \"T to compile the same code multiple times. The first time, the JIT can use as a few optimizations as\", \" make sense (a handful of optimizations can actually make the JIT's own throughput faster, so those \", \"still make sense to apply), producing fairly unoptimized assembly code but doing so really quickly. \", \"And when it does so, it can add some instrumentation into the assembly to track how often the method\", \"s are called. As it turns out, many functions used on a startup path are invoked once or maybe only \", \"a handful of times, and it would take more time to optimize them than it does to just execute them u\", \"noptimized. Then, when the method's instrumentation triggers some threshold, for example a method ha\", \"ving been executed 30 times, a work item gets queued to recompile that method, but this time with al\", \"l the optimizations the JIT can throw at it. This is lovingly referred to as \\\"tiering up.\\\" Once that\", \" recompilation has completed, call sites to the method are patched with the address of the newly hig\", \"hly optimized assembly code, and future invocations will then take the fast path. So, we get faster \", \"startup *and* faster sustained throughput. At least, that's the hope.\\n\\nA problem, however, is method\", \"s that don't fit this mold. While it's certainly the case that many performance-sensitive methods ar\", \"e relatively quick and executed many, many, many times, there's also a large number of performance-s\", \"ensitive methods that are executed just a handful of times, or maybe even only once, but that take a\", \" very long time to execute, maybe even the duration of the whole process: methods with loops. As a r\", \"esult, by default tiered compilation hasn't applied to loops, though it can be enabled by setting th\", \"e DOTNET\\\\_TC\\\\_QuickJitForLoops environment variable to 1. We can see the effect of this by trying th\", \"is simple console app with .NET 6. With the default settings, run this app:\\n\\n```\\nclass Program\\n{\\n st\", \"atic void Main()\\n {\\n var sw = new System.Diagnostics.Stopwatch();\\n while (true)\\n {\\n sw.Restart();\\n f\", \"or (int trial = 0; trial < 10_000; trial++)\\n {\\n int count = 0;\\n for (int i = 0; i < char.MaxValue; i\", \"++)\\n if (IsAsciiDigit((char)i))\\n count++;\\n }\\n sw.Stop();\\n Console.WriteLine(sw.Elapsed);\\n }\\n static \", \"bool IsAsciiDigit(char c) => (uint)(c - '0') <= 9;\\n }\\n}\\n```\\n\\nI get numbers printed out like:\\n\\n```\\n00\", \":00:00.5734352\\n00:00:00.5526667\\n00:00:00.5675267\\n00:00:00.5588724\\n00:00:00.5616028\\n```\\n\\nNow, try set\", \"ting DOTNET\\\\_TC\\\\_QuickJitForLoops to 1. When I then run it again, I get numbers like this:\\n\\n```\\n00:0\", \"0:01.2841397\\n00:00:01.2693485\\n00:00:01.2755646\\n00:00:01.2656678\\n00:00:01.2679925\\n```\\n\\nIn other words\", \", with DOTNET\\\\_TC\\\\_QuickJitForLoops enabled, it's taking 2.5x as long as without (the default in .NE\", \"T 6). That's because this main function never gets optimizations applied to it. By setting DOTNET\\\\_T\", \"C\\\\_QuickJitForLoops to 1, we're saying \\\"JIT, please apply tiering to methods with loops as well,\\\" bu\", \"t this method with a loop is only ever invoked once, so for the duration of the process it ends up r\", \"emaining at \\\"tier-0,\\\" aka unoptimized. Now, let's try the same thing with .NET 7. Regardless of whet\", \"her that environment variable is set, I again get numbers like this:\\n\\n```\\n00:00:00.5528889\\n00:00:00.\", \"5562563\\n00:00:00.5622086\\n00:00:00.5668220\\n00:00:00.5589112\\n```\\n\\nbut importantly, this method was sti\", \"ll participating in tiering. In fact, we can get confirmation of that by using the aforementioned DO\", \"TNET\\\\_JitDisasmSummary=1 environment variable. When I set that and run again, I see these lines in t\", \"he output:\\n\\n```\\n 4: JIT compiled Program:Main() [Tier0, IL size=83, code size=319]\\n...\\n 6: JIT compi\", \"led Program:Main() [Tier1-OSR @0x27, IL size=83, code size=380]\\n```\\n\\nhighlighting that Main was inde\", \"ed compiled twice. How is that possible? On-stack replacement.\\n\\nThe idea behind on-stack replacement\", \" is a method can be replaced not just between invocations but even while it's executing, while it's \", \"\\\"on the stack.\\\" In addition to the tier-0 code being instrumented for call counts, loops are also in\", \"strumented for iteration counts. When the iterations surpass a certain limit, the JIT compiles a new\", \" highly optimized version of that method, transfers all the local/register state from the current in\", \"vocation to the new invocation, and then jumps to the appropriate location in the new method. We can\", \" see this in action by using the previously discussed DOTNET\\\\_JitDisasm environment variable. Set th\", \"at to Program:\\\\* in order to see the assembly code generated for all of the methods in the Program c\", \"lass, and then run the app again. You should see output like the following:\\n\\n```\\n; Assembly listing \", \"for method Program:Main()\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilatio\", \"n\\n; MinOpts code\\n; rbp based frame\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n 55 push r\", \"bp\\n```\\n\\n```\\n 4881EC80000000 sub rsp, 128\\n 488DAC2480000000 lea rbp, [rsp+80H]\\n C5D857E4 vxorps xmm4,\", \" xmm4\\n C5F97F65B0 vmovdqa xmmword ptr [rbp-50H], xmm4\\n 33C0 xor eax, eax\\n 488945C0 mov qword ptr [rb\", \"p-40H], rax\\nG_M000_IG02: ;; offset=001FH\\n 48B9002F0B50FC7F0000 mov rcx, 0x7FFC500B2F00\\n E8721FB25F c\", \"all CORINFO_HELP_NEWSFAST\\n 488945B0 mov gword ptr [rbp-50H], rax\\n 488B4DB0 mov rcx, gword ptr [rbp-5\", \"0H]\\n FF1544C70D00 call [Stopwatch:.ctor():this]\\n 488B4DB0 mov rcx, gword ptr [rbp-50H]\\n 48894DC0 mov\", \" gword ptr [rbp-40H], rcx\\n C745A8E8030000 mov dword ptr [rbp-58H], 0x3E8\\nG_M000_IG03: ;; offset=004B\", \"H\\n 8B4DA8 mov ecx, dword ptr [rbp-58H]\\n FFC9 dec ecx\\n 894DA8 mov dword ptr [rbp-58H], ecx\\n 837DA800 \", \"cmp dword ptr [rbp-58H], 0\\n 7F0E jg SHORT G_M000_IG05\\nG_M000_IG04: ;; offset=0059H\\n 488D4DA8 lea rcx\", \", [rbp-58H]\\n BA06000000 mov edx, 6\\n E8B985AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG05: ;; offset=0\", \"067H\\n 488B4DC0 mov rcx, gword ptr [rbp-40H]\\n 3909 cmp dword ptr [rcx], ecx\\n FF1585C70D00 call [Stopw\", \"atch:Restart():this]\\n 33C9 xor ecx, ecx\\n 894DBC mov dword ptr [rbp-44H], ecx\\n 33C9 xor ecx, ecx\\n 894\", \"DB8 mov dword ptr [rbp-48H], ecx\\n EB20 jmp SHORT G_M000_IG08\\nG_M000_IG06: ;; offset=007FH\\n 8B4DB8 mo\", \"v ecx, dword ptr [rbp-48H]\\n 0FB7C9 movzx rcx, cx\\n FF152DD40B00 call [Program:<Main>g__IsAsciiDigit|0\", \"_0(ushort):bool]\\n 85C0 test eax, eax\\n 7408 je SHORT G_M000_IG07\\n 8B4DBC mov ecx, dword ptr [rbp-44H]\", \"\\n FFC1 inc ecx\\n 894DBC mov dword ptr [rbp-44H], ecx\\nG_M000_IG07: ;; offset=0097H\\n 8B4DB8 mov ecx, dw\", \"ord ptr [rbp-48H]\\n FFC1 inc ecx\\n 894DB8 mov dword ptr [rbp-48H], ecx\\nG_M000_IG08: ;; offset=009FH\\n 8\", \"B4DA8 mov ecx, dword ptr [rbp-58H]\\n FFC9 dec ecx\\n 894DA8 mov dword ptr [rbp-58H], ecx\\n 837DA800 cmp \", \"dword ptr [rbp-58H], 0\\n 7F0E jg SHORT G_M000_IG10\\n```\\n\\n```\\nG_M000_IG09: ;; offset=00ADH\\n 488D4DA8 le\", \"a rcx, [rbp-58H]\\n BA23000000 mov edx, 35\\n E86585AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG10: ;; of\", \"fset=00BBH\\n 817DB800CA9A3B cmp dword ptr [rbp-48H], 0x3B9ACA00\\n 7CBB jl SHORT G_M000_IG06\\n 488B4DC0 \", \"mov rcx, gword ptr [rbp-40H]\\n 3909 cmp dword ptr [rcx], ecx\\n FF1570C70D00 call [Stopwatch:get_Elapse\", \"dMilliseconds():long:this]\\n 488BC8 mov rcx, rax\\n FF1507D00D00 call [Console:WriteLine(long)]\\n E96DFF\", \"FFFF jmp G_M000_IG03\\n; Total bytes of code 222\\n; Assembly listing for method Program:<Main>g__IsAsci\", \"iDigit|0_0(ushort):bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n\", \"; MinOpts code\\n; rbp based frame\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n 55 push rbp\", \"\\n 488BEC mov rbp, rsp\\n 894D10 mov dword ptr [rbp+10H], ecx\\nG_M000_IG02: ;; offset=0007H\\n 8B4510 mov \", \"eax, dword ptr [rbp+10H]\\n 0FB7C0 movzx rax, ax\\n 83C0D0 add eax, -48\\n 83F809 cmp eax, 9\\n 0F96C0 setbe\", \" al\\n 0FB6C0 movzx rax, al\\nG_M000_IG03: ;; offset=0019H\\n 5D pop rbp\\n C3 ret\\n```\\n\\nA few relevant thing\", \"s to notice here. First, the comments at the top highlight how this code was compiled:\\n\\n```\\n; Tier-0\", \" compilation\\n; MinOpts code\\n```\\n\\nSo, we know this is the initial version (\\\"Tier-0\\\") of the method co\", \"mpiled with minimal optimization (\\\"MinOpts\\\"). Second, note this line of the assembly:\\n\\n```\\nFF152DD40\", \"B00 call [Program:<Main>g__IsAsciiDigit|0_0(ushort):bool]\\n```\\n\\nOur IsAsciiDigit helper method is tri\", \"vially inlineable, but it's not getting inlined; instead, the assembly has a call to it, and indeed \", \"we can see below the generated code (also \\\"MinOpts\\\") for IsAsciiDigit. Why? Because inlining is an o\", \"ptimization (a really important one) that's disabled as part of tier-0 (because the analysis for doi\", \"ng inlining well is also quite costly). Third, we can see the code the JIT is outputting to instrume\", \"nt this method. This is a bit more involved, but I'll point out the relevant parts. First, we see:\\n\\n\", \"```\\nC745A8E8030000 mov dword ptr [rbp-58H], 0x3E8\\n```\\n\\nThat 0x3E8 is the hex value for the decimal 1\", \",000, which is the default number of iterations a loop needs to iterate before the JIT will generate\", \" the optimized version of the method (this is configurable via the DOTNET\\\\_TC\\\\_OnStackReplacement\\\\_I\", \"nitialCounter environment variable). So we see 1,000 being stored into this stack location. Then a b\", \"it later in the method we see this:\\n\\n```\\nG_M000_IG03: ;; offset=004BH\\n 8B4DA8 mov ecx, dword ptr [rb\", \"p-58H]\\n FFC9 dec ecx\\n 894DA8 mov dword ptr [rbp-58H], ecx\\n 837DA800 cmp dword ptr [rbp-58H], 0\\n 7F0E\", \" jg SHORT G_M000_IG05\\nG_M000_IG04: ;; offset=0059H\\n 488D4DA8 lea rcx, [rbp-58H]\\n BA06000000 mov edx,\", \" 6\\n E8B985AB5F call CORINFO_HELP_PATCHPOINT\\nG_M000_IG05: ;; offset=0067H\\n```\\n\\nThe generated code is \", \"loading that counter into the ecx register, decrementing it, storing it back, and then seeing whethe\", \"r the counter dropped to 0. If it didn't, the code skips to G\\\\_M000\\\\_IG05, which is the label for th\", \"e actual code in the rest of the loop. But if the counter did drop to 0, the JIT proceeds to store r\", \"elevant state into the the rcx and edx registers and then calls the CORINFO\\\\_HELP\\\\_PATCHPOINT helper\", \" method. That helper is responsible for triggering the creation of the optimized method if it doesn'\", \"t yet exist, fixing up all appropriate tracking state, and jumping to the new method. And indeed, if\", \" you look again at your console output from running the program, you'll see yet another output for t\", \"he Main method:\\n\\n```\\n; Assembly listing for method Program:Main()\\n; Emitting BLENDED_CODE for X64 CP\", \"U with AVX - Windows\\n; Tier-1 compilation\\n; OSR variant for entry point 0x23\\n; optimized code\\n; rsp \", \"based frame\\n; fully interruptible\\n; No PGO data\\n; 1 inlinees with PGO data; 8 single block inlinees;\", \" 0 inlinees without PGO data\\nG_M000_IG01: ;; offset=0000H\\n 4883EC58 sub rsp, 88\\n 4889BC24D8000000 mo\", \"v qword ptr [rsp+D8H], rdi\\n 4889B424D0000000 mov qword ptr [rsp+D0H], rsi\\n 48899C24C8000000 mov qwor\", \"d ptr [rsp+C8H], rbx\\n C5F877 vzeroupper\\n 33C0 xor eax, eax\\n 4889442428 mov qword ptr [rsp+28H], rax\\n\", \" 4889442420 mov qword ptr [rsp+20H], rax\\n 488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n 8BBC249C000\", \"000 mov edi, dword ptr [rsp+9CH]\\n 8BB42498000000 mov esi, dword ptr [rsp+98H]\\nG_M000_IG02: ;; offset\", \"=0041H\\n EB45 jmp SHORT G_M000_IG05\\n align [0 bytes for IG06]\\n```\\n\\n```\\nG_M000_IG03: ;; offset=0043H\\n \", \"33C9 xor ecx, ecx\\n 488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n 48894B08 mov qword ptr [rbx+08H], \", \"rcx\\n 488D4C2428 lea rcx, [rsp+28H]\\n 48B87066E68AFD7F0000 mov rax, 0x7FFD8AE66670\\nG_M000_IG04: ;; off\", \"set=0060H\\n FFD0 call rax ; Kernel32:QueryPerformanceCounter(long):int\\n 488B442428 mov rax, qword ptr\", \" [rsp+28H]\\n 488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n 48894310 mov qword ptr [rbx+10H], rax\\n C6\", \"431801 mov byte ptr [rbx+18H], 1\\n 33FF xor edi, edi\\n 33F6 xor esi, esi\\n 833D92A1E55F00 cmp dword ptr\", \" [(reloc 0x7ffcafe1ae34)], 0\\n 0F85CA000000 jne G_M000_IG13\\nG_M000_IG05: ;; offset=0088H\\n 81FE00CA9A3\", \"B cmp esi, 0x3B9ACA00\\n 7D17 jge SHORT G_M000_IG09\\nG_M000_IG06: ;; offset=0090H\\n 0FB7CE movzx rcx, si\", \"\\n 83C1D0 add ecx, -48\\n 83F909 cmp ecx, 9\\n 7702 ja SHORT G_M000_IG08\\nG_M000_IG07: ;; offset=009BH\\n FF\", \"C7 inc edi\\nG_M000_IG08: ;; offset=009DH\\n FFC6 inc esi\\n 81FE00CA9A3B cmp esi, 0x3B9ACA00\\n 7CE9 jl SHO\", \"RT G_M000_IG06\\nG_M000_IG09: ;; offset=00A7H\\n 488B6B08 mov rbp, qword ptr [rbx+08H]\\n 48899C24A0000000\", \" mov gword ptr [rsp+A0H], rbx\\n 807B1800 cmp byte ptr [rbx+18H], 0\\n 7436 je SHORT G_M000_IG12\\nG_M000_\", \"IG10: ;; offset=00B9H\\n 488D4C2420 lea rcx, [rsp+20H]\\n 48B87066E68AFD7F0000 mov rax, 0x7FFD8AE66670\\nG\", \"_M000_IG11: ;; offset=00C8H\\n FFD0 call rax ; Kernel32:QueryPerformanceCounter(long):int\\n 488B4C2420 \", \"mov rcx, qword ptr [rsp+20H]\\n 488B9C24A0000000 mov rbx, gword ptr [rsp+A0H]\\n 482B4B10 sub rcx, qword\", \" ptr [rbx+10H]\\n 4803E9 add rbp, rcx\\n 833D2FA1E55F00 cmp dword ptr [(reloc 0x7ffcafe1ae34)], 0\\n 48899\", \"C24A0000000 mov gword ptr [rsp+A0H], rbx\\n 756D jne SHORT G_M000_IG14\\nG_M000_IG12: ;; offset=00EFH\\n C\", \"5F857C0 vxorps xmm0, xmm0\\n C4E1FB2AC5 vcvtsi2sd xmm0, rbp\\n C5FB11442430 vmovsd qword ptr [rsp+30H], \", \"xmm0\\n```\\n\\n```\\n 48B9F04BF24FFC7F0000 mov rcx, 0x7FFC4FF24BF0\\n BAE7070000 mov edx, 0x7E7\\n E82E1FB25F c\", \"all CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE\\n C5FB10442430 vmovsd xmm0, qword ptr [rsp+30H]\\n C5FB5905\", \"E049F6FF vmulsd xmm0, xmm0, qword ptr [(reloc 0x7ffc4ff25720)]\\n C4E1FB2CD0 vcvttsd2si rdx, xmm0\\n 48B\", \"94B598638D6C56D34 mov rcx, 0x346DC5D63886594B\\n 488BC1 mov rax, rcx\\n 48F7EA imul rdx:rax, rdx\\n 488BCA\", \" mov rcx, rdx\\n 48C1E93F shr rcx, 63\\n 48C1FA0B sar rdx, 11\\n 4803CA add rcx, rdx\\n FF1567CE0D00 call [C\", \"onsole:WriteLine(long)]\\n E9F5FEFFFF jmp G_M000_IG03\\nG_M000_IG13: ;; offset=014EH\\n E8DDCBAC5F call CO\", \"RINFO_HELP_POLL_GC\\n E930FFFFFF jmp G_M000_IG05\\nG_M000_IG14: ;; offset=0158H\\n E8D3CBAC5F call CORINFO\", \"_HELP_POLL_GC\\n EB90 jmp SHORT G_M000_IG12\\n; Total bytes of code 351\\n```\\n\\nHere, again, we notice a fe\", \"w interesting things. First, in the header we see this:\\n\\n```\\n; Tier-1 compilation\\n; OSR variant for \", \"entry point 0x23\\n; optimized code\\n```\\n\\nso we know this is both optimized \\\"tier-1\\\" code and is the \\\"O\", \"SR variant\\\" for this method. Second, notice there's no longer a call to the IsAsciiDigit helper. Ins\", \"tead, where that call would have been, we see this:\\n\\n```\\nG_M000_IG06: ;; offset=0090H\\n 0FB7CE movzx \", \"rcx, si\\n 83C1D0 add ecx, -48\\n 83F909 cmp ecx, 9\\n 7702 ja SHORT G_M000_IG08\\n```\\n\\nThis is loading a va\", \"lue into rcx, subtracting 48 from it (48 is the decimal ASCII value of the '0' character) and compar\", \"ing the resulting value to 9. Sounds an awful lot like our IsAsciiDigit implementation ((uint)(c - '\", \"0') <= 9), doesn't it? That's because it is. The helper was successfully inlined in this now-optimiz\", \"ed code.\\n\\nGreat, so now in .NET 7, we can largely avoid the tradeoffs between startup and throughput\", \", as OSR enables tiered compilation to apply to all methods, even those that are long-running. A mul\", \"titude of PRs went into enabling this, including many over the last few years, but all of the functi\", \"onality was disabled in the shipping bits. Thanks to improvements like [dotnet/runtime#62831](https:\", \"//github.com/dotnet/runtime/pull/62831) which implemented support for OSR on Arm64 (previously only \", \"x64 support was implemented), and [dotnet/runtime#63406](https://github.com/dotnet/runtime/pull/6340\", \"6) and [dotnet/runtime#65609](https://github.com/dotnet/runtime/pull/65609) which revised how OSR im\", \"ports and epilogs are handled, [dotnet/runtime#65675](https://github.com/dotnet/runtime/pull/65675) \", \"enables OSR (and as a result DOTNET\\\\_TC\\\\_QuickJitForLoops) by default.\\n\\nBut, tiered compilation and \", \"OSR aren't just about startup (though they're of course very valuable there). They're also about fur\", \"ther improving throughput. Even though tiered compilation was originally envisioned as a way to opti\", \"mize startup while not hurting throughput, it's become much more than that. There are various things\", \" the JIT can learn about a method during tier-0 that it can then use for tier-1. For example, the ve\", \"ry fact that the tier-0 code executed means that any statics accessed by the method will have been i\", \"nitialized, and that means that any readonly statics will not only have been initialized by the time\", \" the tier-1 code executes but their values won't ever change. And that in turn means that any readon\", \"ly statics of primitive types (e.g. bool, int, etc.) can be treated like consts instead of static re\", \"adonly fields, and during tier-1 compilation the JIT can optimize them just as it would have optimiz\", \"ed a const. For example, try running this simple program after setting DOTNET\\\\_JitDisasm to Program:\", \"Test:\\n\\n```\\nusing System.Runtime.CompilerServices;\\nclass Program\\n{\\n static readonly bool Is64Bit = En\", \"vironment.Is64BitProcess;\\n static int Main()\\n {\\n int count = 0;\\n for (int i = 0; i < 1_000_000_000; \", \"i++)\\n if (Test())\\n count++;\\n return count;\\n }\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n static bo\", \"ol Test() => Is64Bit;\\n}\\n```\\n\\nWhen I do so, I get this output:\\n\\n```\\n; Assembly listing for method Pro\", \"gram:Test():bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-0 compilation\\n; MinOp\", \"ts code\\n; rbp based frame\\n; partially interruptible\\nG_M000_IG01: ;; offset=0000H\\n 55 push rbp\\n 4883E\", \"C20 sub rsp, 32\\n 488D6C2420 lea rbp, [rsp+20H]\\nG_M000_IG02: ;; offset=000AH\\n 48B9B8639A3FFC7F0000 mo\", \"v rcx, 0x7FFC3F9A63B8\\n BA01000000 mov edx, 1\\n E8C220B25F call CORINFO_HELP_GETSHARED_NONGCSTATIC_BAS\", \"E\\n 0FB60545580C00 movzx rax, byte ptr [(reloc 0x7ffc3f9a63ea)]\\nG_M000_IG03: ;; offset=0025H\\n 4883C42\", \"0 add rsp, 32\\n 5D pop rbp\\n C3 ret\\n; Total bytes of code 43\\n```\\n\\n```\\n; Assembly listing for method Pr\", \"ogram:Test():bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; opti\", \"mized code\\n; rsp based frame\\n; partially interruptible\\n; No PGO data\\nG_M000_IG01: ;; offset=0000H\\nG_\", \"M000_IG02: ;; offset=0000H\\n B801000000 mov eax, 1\\nG_M000_IG03: ;; offset=0005H\\n C3 ret\\n; Total bytes\", \" of code 6\\n```\\n\\nNote, again, we see two outputs for Program:Test. First, we see the \\\"Tier-0\\\" code, w\", \"hich is accessing a static (note the call CORINFO\\\\_HELP\\\\_GETSHARED\\\\_NONGCSTATIC\\\\_BASE instruction). \", \"But then we see the \\\"Tier-1\\\" code, where all of that overhead has vanished and is instead replaced s\", \"imply by mov eax, 1. Since the \\\"Tier-0\\\" code had to have executed in order for it to tier up, the \\\"T\", \"ier-1\\\" code was generated knowing that the value of the static readonly bool Is64Bit field was true \", \"(1), and so the entirety of this method is storing the value 1 into the eax register used for the re\", \"turn value.\\n\\nThis is so useful that components are now written with tiering in mind. Consider the ne\", \"w Regex source generator, which is discussed later in this post (Roslyn source generators were intro\", \"duced a couple of years ago; just as how Roslyn analyzers are able to plug into the compiler and sur\", \"face additional diagnostics based on all of the data the compiler learns from the source code, Rosly\", \"n source generators are able to analyze that same data and then further augment the compilation unit\", \" with additional source). The Regex source generator applies a technique based on this in [dotnet/ru\", \"ntime#67775.](https://github.com/dotnet/runtime/pull/67775) Regex supports setting a process-wide ti\", \"meout that gets applied to Regex instances that don't explicitly set a timeout. That means, even tho\", \"ugh it's super rare for such a process-wide timeout to be set, the Regex source generator still need\", \"s to output timeout-related code just in case it's needed. It does so by outputting some helpers lik\", \"e this:\\n\\n```\\nstatic class Utilities\\n{\\n internal static readonly TimeSpan s_defaultTimeout = \\nAppCont\", \"ext.GetData(\\\"REGEX_DEFAULT_MATCH_TIMEOUT\\\") is TimeSpan timeout ? timeout : \\nTimeout.InfiniteTimeSpan\", \";\\n internal static readonly bool s_hasTimeout = s_defaultTimeout != \\nTimeout.InfiniteTimeSpan;\\n}\\n```\", \"\\n\\nwhich it then uses at call sites like this:\\n\\n```\\nif (Utilities.s_hasTimeout)\\n{\\n base.CheckTimeout(\", \");\\n}\\n```\\n\\nIn tier-0, these checks will still be emitted in the assembly code, but in tier-1 where th\", \"roughput matters, if the relevant AppContext switch hasn't been set, then s\\\\_defaultTimeout will be\\n\", \"\\nTimeout.InfiniteTimeSpan, at which point s\\\\_hasTimeout will be false. And since s\\\\_hasTimeout is a \", \"static readonly bool, the JIT will be able to treat that as a const, and all conditions like if (Uti\", \"lities.s\\\\_hasTimeout) will be treated equal to if (false) and be eliminated from the assembly code e\", \"ntirely as dead code.\\n\\nBut, this is somewhat old news. The JIT has been able to do such an optimizat\", \"ion since tiered compilation was introduced in .NET Core 3.0. Now in .NET 7, though, with OSR it's a\", \"lso able to do so by default for methods with loops (and thus enable cases like the regex one). Howe\", \"ver, the real magic of OSR comes into play when combined with another exciting feature: dynamic PGO.\", \"\\n\\n#### <span id=\\\"page-27-0\\\"></span>**PGO**\\n\\nI wrote about profile-guided optimization (PGO) in my [P\", \"erformance Improvements in .NET 6](https://devblogs.microsoft.com/dotnet/performance-improvements-in\", \"-net-6) post, but I'll cover it again here as it's seen a multitude of improvements for .NET 7.\\n\\nPGO\", \" has been around for a long time, in any number of languages and compilers. The basic idea is you co\", \"mpile your app, asking the compiler to inject instrumentation into the application to track various \", \"pieces of interesting information. You then put your app through its paces, running through various \", \"common scenarios, causing that instrumentation to \\\"profile\\\" what happens when the app is executed, a\", \"nd the results of that are then saved out. The app is then recompiled, feeding those instrumentation\", \" results back into the compiler, and allowing it to optimize the app for exactly how it's expected t\", \"o be used. This approach to PGO is referred to as \\\"static PGO,\\\" as the information is all gleaned ah\", \"ead of actual deployment, and it's something .NET has been doing in various forms for years. From my\", \" perspective, though, the really interesting development in .NET is \\\"dynamic PGO,\\\" which was introdu\", \"ced in .NET 6, but off by default.\\n\\nDynamic PGO takes advantage of tiered compilation. I noted that \", \"the JIT instruments the tier-0 code to track how many times the method is called, or in the case of \", \"loops, how many times the loop executes. It can instrument it for other things as well. For example,\", \" it can track exactly which concrete types are used as the target of an interface dispatch, and then\", \" in tier-1 specialize the code to expect the most common types (this is referred to as \\\"guarded devi\", \"rtualization,\\\" or GDV). You can see this in this little example. Set the DOTNET\\\\_TieredPGO environme\", \"nt variable to 1, and then run this on .NET 7:\\n\\n```\\nclass Program\\n{\\n static void Main()\\n {\\n IPrinter\", \" printer = new Printer();\\n for (int i = 0; ; i++)\\n {\\n DoWork(printer, i);\\n }\\n }\\n static void DoWork(\", \"IPrinter printer, int i)\\n {\\n printer.PrintIfTrue(i == int.MaxValue);\\n }\\n interface IPrinter\\n {\\n void\", \" PrintIfTrue(bool condition);\\n```\\n\\n```\\n }\\n class Printer : IPrinter\\n {\\n public void PrintIfTrue(bool\", \" condition)\\n {\\n if (condition) Console.WriteLine(\\\"Print!\\\");\\n }\\n }\\n}\\n```\\n\\nThe tier-0 code for DoWork \", \"ends up looking like this:\\n\\n```\\nG_M000_IG01: ;; offset=0000H\\n 55 push rbp\\n 4883EC30 sub rsp, 48\\n 488\", \"D6C2430 lea rbp, [rsp+30H]\\n 33C0 xor eax, eax\\n 488945F8 mov qword ptr [rbp-08H], rax\\n 488945F0 mov q\", \"word ptr [rbp-10H], rax\\n 48894D10 mov gword ptr [rbp+10H], rcx\\n 895518 mov dword ptr [rbp+18H], edx\\n\", \"G_M000_IG02: ;; offset=001BH\\n FF059F220F00 inc dword ptr [(reloc 0x7ffc3f1b2ea0)]\\n 488B4D10 mov rcx,\", \" gword ptr [rbp+10H]\\n 48894DF8 mov gword ptr [rbp-08H], rcx\\n 488B4DF8 mov rcx, gword ptr [rbp-08H]\\n \", \"48BAA82E1B3FFC7F0000 mov rdx, 0x7FFC3F1B2EA8\\n E8B47EC55F call CORINFO_HELP_CLASSPROFILE32\\n 488B4DF8 \", \"mov rcx, gword ptr [rbp-08H]\\n 48894DF0 mov gword ptr [rbp-10H], rcx\\n 488B4DF0 mov rcx, gword ptr [rb\", \"p-10H]\\n 33D2 xor edx, edx\\n 817D18FFFFFF7F cmp dword ptr [rbp+18H], 0x7FFFFFFF\\n 0F94C2 sete dl\\n 49BB0\", \"800F13EFC7F0000 mov r11, 0x7FFC3EF10008\\n 41FF13 call [r11]IPrinter:PrintIfTrue(bool):this\\n 90 nop\\nG_\", \"M000_IG03: ;; offset=0062H\\n 4883C430 add rsp, 48\\n 5D pop rbp\\n C3 ret\\n```\\n\\nand most notably, you can \", \"see the call [r11]IPrinter:PrintIfTrue(bool):this doing the interface dispatch. But, then look at th\", \"e code generated for tier-1. We still see the call [r11]IPrinter:PrintIfTrue(bool):this, *but* we al\", \"so see this:\\n\\n```\\nG_M000_IG02: ;; offset=0020H\\n 48B9982D1B3FFC7F0000 mov rcx, 0x7FFC3F1B2D98\\n 48390F\", \" cmp qword ptr [rdi], rcx\\n 7521 jne SHORT G_M000_IG05\\n 81FEFFFFFF7F cmp esi, 0x7FFFFFFF\\n 7404 je SHO\", \"RT G_M000_IG04\\nG_M000_IG03: ;; offset=0037H\\n FFC6 inc esi\\n EBE5 jmp SHORT G_M000_IG02\\n```\\n\\n```\\nG_M00\", \"0_IG04: ;; offset=003BH\\n 48B9D820801A24020000 mov rcx, 0x2241A8020D8\\n 488B09 mov rcx, gword ptr [rcx\", \"]\\n FF1572CD0D00 call [Console:WriteLine(String)]\\n EBE7 jmp SHORT G_M000_IG03\\n```\\n\\nThat first block i\", \"s checking the concrete type of the IPrinter (stored in rdi) and comparing it against the known type\", \" for Printer (0x7FFC3F1B2D98). If they're different, it just jumps to the same interface dispatch it\", \" was doing in the unoptimized version. But if they're the same, it then jumps directly to an inlined\", \" version of Printer.PrintIfTrue (you can see the call to Console:WriteLine right there in this metho\", \"d). Thus, the common case (the only case in this example) is super efficient at the expense of a sin\", \"gle comparison and branch.\\n\\nThat all existed in .NET 6, so why are we talking about it now? Several \", \"things have improved. First, PGO now works with OSR, thanks to improvements like [dotnet/runtime#614\", \"53](https://github.com/dotnet/runtime/pull/61453). That's a big deal, as it means hot long-running m\", \"ethods that do this kind of interface dispatch (which are fairly common) can get these kinds of devi\", \"rtualization/inlining optimizations. Second, while PGO isn't currently enabled by default, we've mad\", \"e it much easier to turn on. Between [dotnet/runtime#71438](https://github.com/dotnet/runtime/pull/7\", \"1438) and [dotnet/sdk#26350](https://github.com/dotnet/sdk/pull/26350), it's now possible to simply \", \"put <TieredPGO>true</TieredPGO> into your .csproj, and it'll have the same effect as if you set DOTN\", \"ET\\\\_TieredPGO=1 prior to every invocation of the app, enabling dynamic PGO (note that it *doesn't* d\", \"isable use of R2R images, so if you want the entirety of the core libraries also employing dynamic P\", \"GO, you'll also need to set DOTNET\\\\_ReadyToRun=0). Third, however, is dynamic PGO has been taught ho\", \"w to instrument and optimize additional things.\\n\\nPGO already knew how to instrument virtual dispatch\", \". Now in .NET 7, thanks in large part to [dotnet/runtime#68703,](https://github.com/dotnet/runtime/p\", \"ull/68703) it can do so for delegates as well (at least for delegates to instance methods). Consider\", \" this simple console app:\\n\\n```\\nusing System.Runtime.CompilerServices;\\nclass Program\\n{\\n static int[] \", \"s_values = Enumerable.Range(0, 1_000).ToArray();\\n static void Main()\\n {\\n for (int i = 0; i < 1_000_0\", \"00; i++)\\n Sum(s_values, i => i * 42);\\n }\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n static int Sum\", \"(int[] values, Func<int, int> func)\\n {\\n int sum = 0;\\n foreach (int value in values)\\n sum += func(val\", \"ue);\\n return sum;\\n }\\n}\\n```\\n\\nWithout PGO enabled, I get generated optimized assembly like this:\\n\\n```\\n\", \"; Assembly listing for method Program:Sum(ref,Func`2):int\\n; Emitting BLENDED_CODE for X64 CPU with A\", \"VX - Windows\\n; Tier-1 compilation\\n```\\n\\n```\\n; optimized code\\n; rsp based frame\\n; partially interrupti\", \"ble\\n; No PGO data\\nG_M000_IG01: ;; offset=0000H\\n 4156 push r14\\n 57 push rdi\\n 56 push rsi\\n 55 push rbp\", \"\\n 53 push rbx\\n 4883EC20 sub rsp, 32\\n 488BF2 mov rsi, rdx\\nG_M000_IG02: ;; offset=000DH\\n 33FF xor edi,\", \" edi\\n 488BD9 mov rbx, rcx\\n 33ED xor ebp, ebp\\n 448B7308 mov r14d, dword ptr [rbx+08H]\\n 4585F6 test r1\", \"4d, r14d\\n 7E16 jle SHORT G_M000_IG04\\nG_M000_IG03: ;; offset=001DH\\n 8BD5 mov edx, ebp\\n 8B549310 mov e\", \"dx, dword ptr [rbx+4*rdx+10H]\\n 488B4E08 mov rcx, gword ptr [rsi+08H]\\n FF5618 call [rsi+18H]Func`2:In\", \"voke(int):int:this\\n 03F8 add edi, eax\\n FFC5 inc ebp\\n 443BF5 cmp r14d, ebp\\n 7FEA jg SHORT G_M000_IG03\", \"\\nG_M000_IG04: ;; offset=0033H\\n 8BC7 mov eax, edi\\nG_M000_IG05: ;; offset=0035H\\n 4883C420 add rsp, 32\\n\", \" 5B pop rbx\\n 5D pop rbp\\n 5E pop rsi\\n 5F pop rdi\\n 415E pop r14\\n C3 ret\\n; Total bytes of code 64\\n```\\n\\n\", \"Note the call [rsi+18H]Func'2:Invoke(int):int:this in there that's invoking the delegate. Now with P\", \"GO enabled:\\n\\n```\\n; Assembly listing for method Program:Sum(ref,Func`2):int\\n; Emitting BLENDED_CODE f\", \"or X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; optimized code\\n; optimized using profile data\\n;\", \" rsp based frame\\n; fully interruptible\\n; with Dynamic PGO: edge weights are valid, and fgCalledCount\", \" is 5628\\n; 0 inlinees with PGO data; 1 single block inlinees; 0 inlinees without PGO data\\nG_M000_IG0\", \"1: ;; offset=0000H\\n```\\n\\n```\\n 4157 push r15\\n 4156 push r14\\n 57 push rdi\\n 56 push rsi\\n 55 push rbp\\n 53\", \" push rbx\\n 4883EC28 sub rsp, 40\\n 488BF2 mov rsi, rdx\\nG_M000_IG02: ;; offset=000FH\\n 33FF xor edi, edi\", \"\\n 488BD9 mov rbx, rcx\\n 33ED xor ebp, ebp\\n 448B7308 mov r14d, dword ptr [rbx+08H]\\n 4585F6 test r14d, \", \"r14d\\n 7E27 jle SHORT G_M000_IG05\\nG_M000_IG03: ;; offset=001FH\\n 8BC5 mov eax, ebp\\n 8B548310 mov edx, \", \"dword ptr [rbx+4*rax+10H]\\n 4C8B4618 mov r8, qword ptr [rsi+18H]\\n 48B8A0C2CF3CFC7F0000 mov rax, 0x7FF\", \"C3CCFC2A0\\n 4C3BC0 cmp r8, rax\\n 751D jne SHORT G_M000_IG07\\n 446BFA2A imul r15d, edx, 42\\nG_M000_IG04: \", \";; offset=003CH\\n 4103FF add edi, r15d\\n FFC5 inc ebp\\n 443BF5 cmp r14d, ebp\\n 7FD9 jg SHORT G_M000_IG03\", \"\\nG_M000_IG05: ;; offset=0046H\\n 8BC7 mov eax, edi\\nG_M000_IG06: ;; offset=0048H\\n 4883C428 add rsp, 40\\n\", \" 5B pop rbx\\n 5D pop rbp\\n 5E pop rsi\\n 5F pop rdi\\n 415E pop r14\\n 415F pop r15\\n C3 ret\\nG_M000_IG07: ;; \", \"offset=0055H\\n 488B4E08 mov rcx, gword ptr [rsi+08H]\\n 41FFD0 call r8\\n 448BF8 mov r15d, eax\\n EBDB jmp \", \"SHORT G_M000_IG04\\n```\\n\\nI chose the 42 constant in i => i \\\\* 42 to make it easy to see in the assembl\", \"y, and sure enough, there it is:\\n\\n```\\nG_M000_IG03: ;; offset=001FH\\n 8BC5 mov eax, ebp\\n 8B548310 mov \", \"edx, dword ptr [rbx+4*rax+10H]\\n 4C8B4618 mov r8, qword ptr [rsi+18H]\\n 48B8A0C2CF3CFC7F0000 mov rax, \", \"0x7FFC3CCFC2A0\\n 4C3BC0 cmp r8, rax\\n```\\n\\n```\\n 751D jne SHORT G_M000_IG07\\n 446BFA2A imul r15d, edx, 42\", \"\\n```\\n\\nThis is loading the target address from the delegate into r8 and is loading the address of the\", \" expected target into rax. If they're the same, it then simply performs the inlined operation (imul \", \"r15d, edx, 42), and otherwise it jumps to G\\\\_M000\\\\_IG07 which calls to the function in r8. The effec\", \"t of this is obvious if we run this as a benchmark:\\n\\n```\\nstatic int[] s_values = Enumerable.Range(0,\", \" 1_000).ToArray();\\n[Benchmark]\\npublic int DelegatePGO() => Sum(s_values, i => i * 42);\\nstatic int Su\", \"m(int[] values, Func<int, int>? func)\\n{\\n int sum = 0;\\n foreach (int value in values)\\n {\\n sum += func\", \"(value);\\n }\\n return sum;\\n}\\n```\\n\\nWith PGO disabled, we get the same performance throughput for .NET 6\", \" and .NET 7:\\n\\n| Method      | Runtime  | Mean     | Ratio |\\n|-------------|----------|----------|---\", \"----|\\n| DelegatePGO | .NET 6.0 | 1.665 us | 1.00  |\\n| DelegatePGO | .NET 7.0 | 1.659 us | 1.00  |\\n\\nB\", \"ut the picture changes when we enable dynamic PGO (DOTNET\\\\_TieredPGO=1). .NET 6 gets ~14% faster, bu\", \"t .NET 7 gets ~3x faster!\\n\\n| Method      | Runtime  | Mean       | Ratio |\\n|-------------|----------\", \"|------------|-------|\\n| DelegatePGO | .NET 6.0 | 1,427.7 ns | 1.00  |\\n| DelegatePGO | .NET 7.0 | 53\", \"9.0 ns   | 0.38  |\\n\\n[dotnet/runtime#70377](https://github.com/dotnet/runtime/pull/70377) is another \", \"valuable improvement with dynamic PGO, which enables PGO to play nicely with loop cloning and invari\", \"ant hoisting. To understand this better, a brief digression into what those are. Loop cloning is a m\", \"echanism the JIT employs to avoid various overheads in the fast path of a loop. Consider the Test me\", \"thod in this example:\\n\\n```\\nusing System.Runtime.CompilerServices;\\nclass Program\\n{\\n static void Main(\", \")\\n {\\n int[] array = new int[10_000_000];\\n for (int i = 0; i < 1_000_000; i++)\\n {\\n Test(array);\\n }\\n }\", \"\\n```\\n\\n```\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n private static bool Test(int[] array)\\n {\\n for\", \" (int i = 0; i < 0x12345; i++)\\n {\\n if (array[i] == 42)\\n {\\n return true;\\n }\\n }\\n return false;\\n }\\n}\\n``\", \"`\\n\\nThe JIT doesn't know whether the passed in array is of sufficient length that all accesses to arr\", \"ay[i] inside the loop will be in bounds, and thus it would need to inject bounds checks for every ac\", \"cess. While it'd be nice to simply do the length check up front and simply throw an exception early \", \"if it wasn't long enough, doing so could also change behavior (imagine the method were writing into \", \"the array as it went, or otherwise mutating some shared state). Instead, the JIT employs \\\"loop cloni\", \"ng.\\\" It essentially rewrites this Test method to be more like this:\\n\\n```\\nif (array is not null && ar\", \"ray.Length >= 0x12345)\\n{\\n for (int i = 0; i < 0x12345; i++)\\n {\\n if (array[i] == 42) // no bounds che\", \"cks emitted for this access :-)\\n {\\n return true;\\n }\\n }\\n}\\nelse\\n{\\n for (int i = 0; i < 0x12345; i++)\\n \", \"{\\n if (array[i] == 42) // bounds checks emitted for this access :-(\\n {\\n return true;\\n }\\n }\\n}\\nreturn \", \"false;\\n```\\n\\nThat way, at the expense of some code duplication, we get our fast loop without bounds c\", \"hecks and only pay for the bounds checks in the slow path. You can see this in the generated assembl\", \"y (if you can't already tell, DOTNET\\\\_JitDisasm is one of my favorite features in .NET 7):\\n\\n```\\n; As\", \"sembly listing for method Program:Test(ref):bool\\n; Emitting BLENDED_CODE for X64 CPU with AVX - Wind\", \"ows\\n; Tier-1 compilation\\n; optimized code\\n; rsp based frame\\n; fully interruptible\\n; No PGO data\\nG_M0\", \"00_IG01: ;; offset=0000H\\n 4883EC28 sub rsp, 40\\n```\\n\\n```\\nG_M000_IG02: ;; offset=0004H\\n 33C0 xor eax, \", \"eax\\n 4885C9 test rcx, rcx\\n 7429 je SHORT G_M000_IG05\\n 81790845230100 cmp dword ptr [rcx+08H], 0x1234\", \"5\\n 7C20 jl SHORT G_M000_IG05\\n 0F1F40000F1F840000000000 align [12 bytes for IG03]\\nG_M000_IG03: ;; off\", \"set=0020H\\n 8BD0 mov edx, eax\\n 837C91102A cmp dword ptr [rcx+4*rdx+10H], 42\\n 7429 je SHORT G_M000_IG0\", \"8\\n FFC0 inc eax\\n 3D45230100 cmp eax, 0x12345\\n 7CEE jl SHORT G_M000_IG03\\nG_M000_IG04: ;; offset=0032H\", \"\\n EB17 jmp SHORT G_M000_IG06\\nG_M000_IG05: ;; offset=0034H\\n 3B4108 cmp eax, dword ptr [rcx+08H]\\n 7323\", \" jae SHORT G_M000_IG10\\n 8BD0 mov edx, eax\\n 837C91102A cmp dword ptr [rcx+4*rdx+10H], 42\\n 7410 je SHO\", \"RT G_M000_IG08\\n FFC0 inc eax\\n 3D45230100 cmp eax, 0x12345\\n 7CE9 jl SHORT G_M000_IG05\\nG_M000_IG06: ;;\", \" offset=004BH\\n 33C0 xor eax, eax\\nG_M000_IG07: ;; offset=004DH\\n 4883C428 add rsp, 40\\n C3 ret\\nG_M000_I\", \"G08: ;; offset=0052H\\n B801000000 mov eax, 1\\nG_M000_IG09: ;; offset=0057H\\n 4883C428 add rsp, 40\\n C3 r\", \"et\\nG_M000_IG10: ;; offset=005CH\\n E81FA0C15F call CORINFO_HELP_RNGCHKFAIL\\n CC int3\\n; Total bytes of c\", \"ode 98\\n```\\n\\nThat G\\\\_M000\\\\_IG02 section is doing the null check and the length check, jumping to the \", \"G\\\\_M000\\\\_IG05 block if either fails. If both succeed, it's then executing the loop (block G\\\\_M000\\\\_I\", \"G03) without bounds checks:\\n\\n```\\nG_M000_IG03: ;; offset=0020H\\n 8BD0 mov edx, eax\\n 837C91102A cmp dwo\", \"rd ptr [rcx+4*rdx+10H], 42\\n 7429 je SHORT G_M000_IG08\\n FFC0 inc eax\\n```\\n\\n```\\n 3D45230100 cmp eax, 0x\", \"12345\\n 7CEE jl SHORT G_M000_IG03\\n```\\n\\nwith the bounds checks only showing up in the slow-path block:\", \"\\n\\n```\\nG_M000_IG05: ;; offset=0034H\\n 3B4108 cmp eax, dword ptr [rcx+08H]\\n 7323 jae SHORT G_M000_IG10\\n\", \" 8BD0 mov edx, eax\\n 837C91102A cmp dword ptr [rcx+4*rdx+10H], 42\\n 7410 je SHORT G_M000_IG08\\n FFC0 in\", \"c eax\\n 3D45230100 cmp eax, 0x12345\\n 7CE9 jl SHORT G_M000_IG05\\n```\\n\\nThat's \\\"loop cloning.\\\" What about\", \" \\\"invariant hoisting\\\"? Hoisting means pulling something out of a loop to be before the loop, and inv\", \"ariants are things that don't change. Thus invariant hoisting is pulling something out of a loop to \", \"before the loop in order to avoid recomputing every iteration of the loop an answer that won't chang\", \"e. Effectively, the previous example already showed invariant hoisting, in that the bounds check is \", \"moved to be before the loop rather than in the loop, but a more concrete example would be something \", \"like this:\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static bool Test(int[] array)\\n{\\n \", \"for (int i = 0; i < 0x12345; i++)\\n {\\n if (array[i] == array.Length - 42)\\n {\\n return true;\\n }\\n }\\n ret\", \"urn false;\\n}\\n```\\n\\nNote that the value of array.Length - 42 doesn't change on each iteration of the l\", \"oop, so it's \\\"invariant\\\" to the loop iteration and can be lifted out, which the generated code does:\", \"\\n\\n```\\nG_M000_IG02: ;; offset=0004H\\n 33D2 xor edx, edx\\n 4885C9 test rcx, rcx\\n 742A je SHORT G_M000_IG\", \"05\\n 448B4108 mov r8d, dword ptr [rcx+08H]\\n 4181F845230100 cmp r8d, 0x12345\\n 7C1D jl SHORT G_M000_IG0\", \"5\\n 4183C0D6 add r8d, -42\\n 0F1F4000 align [4 bytes for IG03]\\nG_M000_IG03: ;; offset=0020H\\n 8BC2 mov e\", \"ax, edx\\n 4439448110 cmp dword ptr [rcx+4*rax+10H], r8d\\n 7433 je SHORT G_M000_IG08\\n FFC2 inc edx\\n 81F\", \"A45230100 cmp edx, 0x12345\\n 7CED jl SHORT G_M000_IG03\\n```\\n\\nHere again we see the array being tested \", \"for null (test rcx, rcx) and the array's length being checked (mov r8d, dword ptr [rcx+08H], cmp r8d\", \", 0x12345), but then with the array's length in r8d, we then see this up-front block subtracting 42 \", \"from the length (add r8d, -42), and that's before we continue into the fast-path loop in the G\\\\_M000\", \"\\\\_IG03 block. This keeps that additional set of operations out of the loop, thereby avoiding the ove\", \"rhead of recomputing the value per iteration.\\n\\nOk, so how does this apply to dynamic PGO? Remember t\", \"hat with the interface/virtual dispatch avoidance PGO is able to do, it does so by doing a type chec\", \"k to see whether the type in use is the most common type; if it is, it uses a fast path that calls d\", \"irectly to that type's method (and in doing so that call is then potentially inlined), and if it isn\", \"'t, it falls back to normal interface/virtual dispatch. That check can be invariant to a loop. So wh\", \"en a method is tiered up and PGO kicks in, the type check can now be hoisted out of the loop, making\", \" it even cheaper to handle the common case. Consider this variation of our original example:\\n\\n```\\nus\", \"ing System.Runtime.CompilerServices;\\nclass Program\\n{\\n static void Main()\\n {\\n IPrinter printer = new \", \"BlankPrinter();\\n while (true)\\n {\\n DoWork(printer);\\n }\\n }\\n [MethodImpl(MethodImplOptions.NoInlining)]\", \"\\n static void DoWork(IPrinter printer)\\n {\\n for (int j = 0; j < 123; j++)\\n {\\n printer.Print(j);\\n }\\n }\", \"\\n interface IPrinter\\n {\\n void Print(int i);\\n }\\n class BlankPrinter : IPrinter\\n {\\n public void Print(\", \"int i)\\n {\\n Console.Write(\\\"\\\");\\n }\\n }\\n}\\n```\\n\\nWhen we look at the optimized assembly generated for this\", \" with dynamic PGO enabled, we see this:\\n\\n```\\n; Assembly listing for method Program:DoWork(IPrinter)\\n\", \"; Emitting BLENDED_CODE for X64 CPU with AVX - Windows\\n; Tier-1 compilation\\n; optimized code\\n; optim\", \"ized using profile data\\n```\\n\\n```\\n; rsp based frame\\n; partially interruptible\\n; with Dynamic PGO: edg\", \"e weights are invalid, and fgCalledCount is 12187\\n; 0 inlinees with PGO data; 1 single block inlinee\", \"s; 0 inlinees without PGO data\\nG_M000_IG01: ;; offset=0000H\\n 57 push rdi\\n 56 push rsi\\n 4883EC28 sub \", \"rsp, 40\\n 488BF1 mov rsi, rcx\\nG_M000_IG02: ;; offset=0009H\\n 33FF xor edi, edi\\n 4885F6 test rsi, rsi\\n \", \"742B je SHORT G_M000_IG05\\n 48B9982DD43CFC7F0000 mov rcx, 0x7FFC3CD42D98\\n 48390E cmp qword ptr [rsi],\", \" rcx\\n 751C jne SHORT G_M000_IG05\\nG_M000_IG03: ;; offset=001FH\\n 48B9282040F948020000 mov rcx, 0x248F9\", \"402028\\n 488B09 mov rcx, gword ptr [rcx]\\n FF1526A80D00 call [Console:Write(String)]\\n FFC7 inc edi\\n 83\", \"FF7B cmp edi, 123\\n 7CE6 jl SHORT G_M000_IG03\\nG_M000_IG04: ;; offset=0039H\\n EB29 jmp SHORT G_M000_IG0\", \"7\\nG_M000_IG05: ;; offset=003BH\\n 48B9982DD43CFC7F0000 mov rcx, 0x7FFC3CD42D98\\n 48390E cmp qword ptr [\", \"rsi], rcx\\n 7521 jne SHORT G_M000_IG08\\n 48B9282040F948020000 mov rcx, 0x248F9402028\\n 488B09 mov rcx, \", \"gword ptr [rcx]\\n FF15FBA70D00 call [Console:Write(String)]\\nG_M000_IG06: ;; offset=005DH\\n FFC7 inc ed\", \"i\\n 83FF7B cmp edi, 123\\n 7CD7 jl SHORT G_M000_IG05\\nG_M000_IG07: ;; offset=0064H\\n 4883C428 add rsp, 40\", \"\\n 5E pop rsi\\n 5F pop rdi\\n C3 ret\\nG_M000_IG08: ;; offset=006BH\\n 488BCE mov rcx, rsi\\n 8BD7 mov edx, ed\", \"i\\n 49BB1000AA3CFC7F0000 mov r11, 0x7FFC3CAA0010\\n 41FF13 call [r11]IPrinter:Print(int):this\\n EBDE jmp\", \" SHORT G_M000_IG06\\n; Total bytes of code 127\\n```\\n\\nWe can see in the G\\\\_M000\\\\_IG02 block that it's do\", \"ing the type check on the IPrinter instance and jumping to G\\\\_M000\\\\_IG05 if the check fails (mov rcx\", \", 0x7FFC3CD42D98, cmp qword ptr [rsi], rcx,\\n\\njne SHORT G\\\\_M000\\\\_IG05), otherwise falling through to \", \"G\\\\_M000\\\\_IG03 which is a tight fast-path loop that's inlined BlankPrinter.Print with no type checks \", \"in sight!\\n\\nInterestingly, improvements like this can bring with them their own challenges. PGO leads\", \" to a significant increase in the number of type checks, since call sites that specialize for a give\", \"n type need to compare against that type. However, common subexpression elimination (CSE) hasn't his\", \"torically worked for such type handles (CSE is a compiler optimization where duplicate expressions a\", \"re eliminated by computing the result once and then storing it for subsequent use rather than recomp\", \"uting it each time). [dotnet/runtime#70580](https://github.com/dotnet/runtime/pull/70580) fixes this\", \" by enabling CSE for such constant handles. For example, consider this method:\\n\\n```\\n[Benchmark]\\n[Arg\", \"uments(\\\"\\\", \\\"\\\", \\\"\\\", \\\"\\\")]\\npublic bool AllAreStrings(object o1, object o2, object o3, object o4) =>\\n o1\", \" is string && o2 is string && o3 is string && o4 is string;\\n```\\n\\nOn .NET 6, the JIT produced this as\", \"sembly code:\\n\\n```\\n; Program.AllAreStrings(System.Object, System.Object, System.Object, System.Object\", \")\\n test rdx,rdx\\n je short M00_L01\\n mov rax,offset MT_System.String\\n cmp [rdx],rax\\n jne short M00_L01\", \"\\n test r8,r8\\n je short M00_L01\\n mov rax,offset MT_System.String\\n cmp [r8],rax\\n jne short M00_L01\\n te\", \"st r9,r9\\n je short M00_L01\\n mov rax,offset MT_System.String\\n cmp [r9],rax\\n jne short M00_L01\\n mov ra\", \"x,[rsp+28]\\n test rax,rax\\n je short M00_L00\\n mov rdx,offset MT_System.String\\n cmp [rax],rdx\\n je short\", \" M00_L00\\n xor eax,eax\\nM00_L00:\\n test rax,rax\\n setne al\\n movzx eax,al\\n ret\\nM00_L01:\\n xor eax,eax\\n ret\", \"\\n; Total bytes of code 100\\n```\\n\\nNote the C# has four tests for string and the assembly code has four\", \" loads with mov rax,offset MT\\\\_System.String. Now on .NET 7, the load is performed just once:\\n\\n```\\n;\", \" Program.AllAreStrings(System.Object, System.Object, System.Object, System.Object)\\n test rdx,rdx\\n je\", \" short M00_L01\\n```\\n\\n```\\n mov rax,offset MT_System.String\\n cmp [rdx],rax\\n jne short M00_L01\\n test r8,\", \"r8\\n je short M00_L01\\n cmp [r8],rax\\n jne short M00_L01\\n test r9,r9\\n je short M00_L01\\n cmp [r9],rax\\n j\", \"ne short M00_L01\\n mov rdx,[rsp+28]\\n test rdx,rdx\\n je short M00_L00\\n cmp [rdx],rax\\n je short M00_L00\\n\", \" xor edx,edx\\nM00_L00:\\n xor eax,eax\\n test rdx,rdx\\n setne al\\n ret\\nM00_L01:\\n xor eax,eax\\n ret\\n; Total b\", \"ytes of code 69\\n```\\n\\n#### <span id=\\\"page-39-0\\\"></span>**Bounds Check Elimination**\\n\\nOne of the thing\", \"s that makes .NET attractive is its safety. The runtime guards access to arrays, strings, and spans \", \"such that you can't accidentally corrupt memory by walking off either end; if you do, rather than re\", \"ading/writing arbitrary memory, you'll get exceptions. Of course, that's not magic; it's done by the\", \" JIT inserting bounds checks every time one of these data structures is indexed. For example, this:\\n\", \"\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nstatic int Read0thElement(int[] array) => array[0];\\n\", \"```\\n\\nresults in:\\n\\n```\\nG_M000_IG01: ;; offset=0000H\\n 4883EC28 sub rsp, 40\\nG_M000_IG02: ;; offset=0004\", \"H\\n 83790800 cmp dword ptr [rcx+08H], 0\\n 7608 jbe SHORT G_M000_IG04\\n 8B4110 mov eax, dword ptr [rcx+1\", \"0H]\\nG_M000_IG03: ;; offset=000DH\\n 4883C428 add rsp, 40\\n C3 ret\\nG_M000_IG04: ;; offset=0012H\\n E8E9A0C\", \"25F call CORINFO_HELP_RNGCHKFAIL\\n CC int3\\n```\\n\\nThe array is passed into this method in the rcx regis\", \"ter, pointing to the method table pointer in the object, and the length of an array is stored in the\", \" object just after that method table pointer (which is 8 bytes in a 64-bit process). Thus the cmp dw\", \"ord ptr [rcx+08H], 0 instruction is reading the length\\n\\nof the array and comparing the length to 0; \", \"that makes sense, since the length can't be negative, and we're trying to access the 0th element, so\", \" as long as the length isn't 0, the array has enough elements for us to access its 0th element. In t\", \"he event that the length was 0, the code jumps to the end of the function, which contains call CORIN\", \"FO\\\\_HELP\\\\_RNGCHKFAIL; that's a JIT helper function that throws an IndexOutOfRangeException. If the l\", \"ength was sufficient, however, it then reads the int stored at the beginning of the array's data, wh\", \"ich on 64-bit is 16 bytes (0x10) past the pointer (mov eax, dword ptr [rcx+10H]).\\n\\nWhile these bound\", \"s checks in and of themselves aren't super expensive, do a lot of them and their costs add up. So wh\", \"ile the JIT needs to ensure that \\\"safe\\\" accesses don't go out of bounds, it also tries to prove that\", \" certain accesses won't, in which case it needn't emit the bounds check that it knows will be superf\", \"luous. In every release of .NET, more and more cases have been added to find places these bounds che\", \"cks can be eliminated, and .NET 7 is no exception.\\n\\nFor example, [dotnet/runtime#61662](https://gith\", \"ub.com/dotnet/runtime/pull/61662) from [@anthonycanino](https://github.com/anthonycanino) enabled th\", \"e JIT to understand various forms of binary operations as part of range checks. Consider this method\", \":\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static ushort[]? Convert(ReadOnlySpan<byte\", \"> bytes)\\n{\\n if (bytes.Length != 16)\\n {\\n return null;\\n }\\n var result = new ushort[8];\\n for (int i = 0\", \"; i < result.Length; i++)\\n {\\n result[i] = (ushort)(bytes[i * 2] * 256 + bytes[i * 2 + 1]);\\n }\\n retur\", \"n result;\\n}\\n```\\n\\nIt's validating that the input span is 16 bytes long and then creating a new ushort\", \"[8] where each ushort in the array combines two of the input bytes. To do that, it's looping over th\", \"e output array, and indexing into the bytes array using i \\\\* 2 and i \\\\* 2 + 1 as the indices. On .NE\", \"T 6, each of those indexing operations would result in a bounds check, with assembly like:\\n\\n```\\ncmp \", \"r8d,10 \\njae short G_M000_IG04 \\nmovsxd r8,r8d\\n```\\n\\nwhere that G\\\\_M000\\\\_IG04 is the call CORINFO\\\\_HELP\", \"\\\\_RNGCHKFAIL we're now familiar with. But on .NET 7, we get this assembly for the method:\\n\\n```\\nG_M00\", \"0_IG01: ;; offset=0000H\\n 56 push rsi\\n 4883EC20 sub rsp, 32\\nG_M000_IG02: ;; offset=0005H\\n 488B31 mov \", \"rsi, bword ptr [rcx]\\n 8B4908 mov ecx, dword ptr [rcx+08H]\\n```\\n\\n```\\n 83F910 cmp ecx, 16\\n 754C jne SHO\", \"RT G_M000_IG05\\n 48B9302F542FFC7F0000 mov rcx, 0x7FFC2F542F30\\n BA08000000 mov edx, 8\\n E80C1EB05F call\", \" CORINFO_HELP_NEWARR_1_VC\\n 33D2 xor edx, edx\\n align [0 bytes for IG03]\\nG_M000_IG03: ;; offset=0026H\\n\", \" 8D0C12 lea ecx, [rdx+rdx]\\n 448BC1 mov r8d, ecx\\n FFC1 inc ecx\\n 458BC0 mov r8d, r8d\\n 460FB60406 movzx\", \" r8, byte ptr [rsi+r8]\\n 41C1E008 shl r8d, 8\\n 8BC9 mov ecx, ecx\\n 0FB60C0E movzx rcx, byte ptr [rsi+rc\", \"x]\\n 4103C8 add ecx, r8d\\n 0FB7C9 movzx rcx, cx\\n 448BC2 mov r8d, edx\\n 6642894C4010 mov word ptr [rax+2\", \"*r8+10H], cx\\n FFC2 inc edx\\n 83FA08 cmp edx, 8\\n 7CD0 jl SHORT G_M000_IG03\\nG_M000_IG04: ;; offset=0056\", \"H\\n 4883C420 add rsp, 32\\n 5E pop rsi\\n C3 ret\\nG_M000_IG05: ;; offset=005CH\\n 33C0 xor rax, rax\\nG_M000_I\", \"G06: ;; offset=005EH\\n 4883C420 add rsp, 32\\n 5E pop rsi\\n C3 ret\\n; Total bytes of code 100\\n```\\n\\nNo bou\", \"nds checks, which is most easily seen by the lack of the telltale call CORINFO\\\\_HELP\\\\_RNGCHKFAIL at \", \"the end of the method. With this PR, the JIT is able to understand the impact of certain multiplicat\", \"ion and shift operations and their relationships to the bounds of the data structure. Since it can s\", \"ee that the result array's length is 8 and the loop is iterating from 0 to that exclusive upper boun\", \"d, it knows that i will always be in the range [0, 7], which means that i \\\\* 2 will always be in the\", \" range [0, 14] and i \\\\* 2 + 1 will always be in the range [0, 15]. As such, it's able to prove that \", \"the bounds checks aren't needed.\\n\\n[dotnet/runtime#61569](https://github.com/dotnet/runtime/pull/6156\", \"9) and [dotnet/runtime#62864](https://github.com/dotnet/runtime/pull/62864) also help to eliminate b\", \"ounds checks when dealing with constant strings and spans initialized from RVA statics (\\\"Relative Vi\", \"rtual Address\\\" static fields, basically a static field that lives in a module's data section). For e\", \"xample, consider this benchmark:\\n\\n```\\n[Benchmark]\\n[Arguments(1)]\\npublic char GetChar(int i)\\n{\\n const\", \" string Text = \\\"hello\\\";\\n```\\n\\n```\\n return (uint)i < Text.Length ? Text[i] : '\\\\0';\\n}\\n```\\n\\nOn .NET 6, w\", \"e get this assembly:\\n\\n```\\n; Program.GetChar(Int32)\\n sub rsp,28\\n mov eax,edx\\n cmp rax,5\\n jl short M00\", \"_L00\\n xor eax,eax\\n add rsp,28\\n ret\\nM00_L00:\\n cmp edx,5\\n jae short M00_L01\\n mov rax,2278B331450\\n mov \", \"rax,[rax]\\n movsxd rdx,edx\\n movzx eax,word ptr [rax+rdx*2+0C]\\n add rsp,28\\n ret\\nM00_L01:\\n call CORINFO\", \"_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 56\\n```\\n\\nThe beginning of this makes sense: the JIT was\", \" obviously able to see that the length of Text is 5, so it's implementing the (uint)i < Text.Length \", \"check by doing cmp rax,5, and if i as an unsigned value is greater than or equal to 5, it's then zer\", \"o'ing out the return value (to return the '\\\\0') and exiting. If the length is less than 5 (in which \", \"case it's also at least 0 due to the unsigned comparison), it then jumps to M00\\\\_L00 to read the val\", \"ue from the string\\u2026 but we then see another cmp against 5, this time as part of a range check. So ev\", \"en though the JIT knew the index was in bounds, it wasn't able to remove the bounds check. Now it is\", \"; in .NET 7, we get this:\\n\\n```\\n; Program.GetChar(Int32)\\n cmp edx,5\\n jb short M00_L00\\n xor eax,eax\\n r\", \"et\\nM00_L00:\\n mov rax,2B0AF002530\\n mov rax,[rax]\\n mov edx,edx\\n movzx eax,word ptr [rax+rdx*2+0C]\\n ret\", \"\\n; Total bytes of code 29\\n```\\n\\nSo much nicer.\\n\\n[dotnet/runtime#67141](https://github.com/dotnet/runt\", \"ime/pull/67141) is a great example of how evolving ecosystem needs drives specific optimizations int\", \"o the JIT. The Regex compiler and source generator handle some cases of regular expression character\", \" classes by using a bitmap lookup stored in strings. For example, to determine whether a char c is i\", \"n the character class \\\"[A-Za-z0-9\\\\_]\\\" (which will match an underscore or any ASCII letter or digit),\", \" the implementation ends up generating an expression like the body of the following method:\\n\\n```\\n[Be\", \"nchmark]\\n[Arguments('a')]\\npublic bool IsInSet(char c) =>\\n c < 128 && (\\\"\\\\0\\\\0\\\\0\\\\u03FF\\\\uFFFE\\\\u87FF\\\\uFFF\", \"E\\\\u07FF\\\"[c >> 4] & (1 << (c & 0xF))) != 0;\\n```\\n\\nThe implementation is treating an 8-character string\", \" as a 128-bit lookup table. If the character is known to be in range (such that it's effectively a 7\", \"-bit value), it's then using the top 3 bits of the value to index into the 8 elements of the string,\", \" and the bottom 4 bits to select one of the 16 bits in that element, giving us an answer as to wheth\", \"er this input character is in the set or not. In .NET 6, even though we know the character is in ran\", \"ge of the string, the JIT couldn't see through either the length comparison or the bit shift.\\n\\n```\\n;\", \" Program.IsInSet(Char)\\n sub rsp,28\\n movzx eax,dx\\n cmp eax,80\\n jge short M00_L00\\n mov edx,eax\\n sar ed\", \"x,4\\n cmp edx,8\\n jae short M00_L01\\n mov rcx,299835A1518\\n mov rcx,[rcx]\\n movsxd rdx,edx\\n movzx edx,wor\", \"d ptr [rcx+rdx*2+0C]\\n and eax,0F\\n bt edx,eax\\n setb al\\n movzx eax,al\\n add rsp,28\\n ret\\nM00_L00:\\n xor e\", \"ax,eax\\n add rsp,28\\n ret\\nM00_L01:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 75\\n```\\n\\n\", \"The previously mentioned PR takes care of the length check. And this PR takes care of the bit shift.\", \" So in .NET 7, we get this loveliness:\\n\\n```\\n; Program.IsInSet(Char)\\n movzx eax,dx\\n cmp eax,80\\n jge s\", \"hort M00_L00\\n mov edx,eax\\n sar edx,4\\n mov rcx,197D4800608\\n mov rcx,[rcx]\\n mov edx,edx\\n movzx edx,wor\", \"d ptr [rcx+rdx*2+0C]\\n and eax,0F\\n bt edx,eax\\n setb al\\n movzx eax,al\\n ret\\n```\\n\\n```\\nM00_L00:\\n xor eax,\", \"eax\\n ret\\n; Total bytes of code 51\\n```\\n\\nNote the distinct lack of a call CORINFO\\\\_HELP\\\\_RNGCHKFAIL. A\", \"nd as you might guess, this check can happen *a lot* in a Regex, making this a very useful addition.\", \"\\n\\nBounds checks are an obvious source of overhead when talking about array access, but they're not t\", \"he only ones. There's also the need to use the cheapest instructions possible. In .NET 6, with a met\", \"hod like:\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static int Get(int[] values, int i\", \") => values[i];\\n```\\n\\nassembly code like the following would be generated:\\n\\n```\\n; Program.Get(Int32[]\", \", Int32)\\n sub rsp,28\\n cmp edx,[rcx+8]\\n jae short M01_L00\\n movsxd rax,edx\\n mov eax,[rcx+rax*4+10]\\n ad\", \"d rsp,28\\n ret\\nM01_L00:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 27\\n```\\n\\nThis shoul\", \"d look fairly familiar from our previous discussion; the JIT is loading the array's length ([rcx+8])\", \" and comparing that with the value of i (in edx), and then jumping to the end to throw an exception \", \"if i is out of bounds. Immediately after that jump we see a movsxd rax, edx instruction, which is ta\", \"king the 32-bit value of i from edx and moving it into the 64-bit register rax. And as part of movin\", \"g it, it's sign-extending it; that's the \\\"sxd\\\" part of the instruction name (sign-extending means th\", \"e upper 32 bits of the new 64-bit value will be set to the value of the upper bit of the 32-bit valu\", \"e, so that the number retains its signed value). The interesting thing is, though, we know that the \", \"Length of an array and of a span is non-negative, and since we just bounds checked i against the Len\", \"gth, we also know that i is non-negative. That makes such sign-extension useless, since the upper bi\", \"t is guaranteed to be 0. Since the mov instruction that zero-extends is a tad cheaper than movsxd, w\", \"e can simply use that instead. And that's exactly what [dotnet/runtime#57970](https://github.com/dot\", \"net/runtime/pull/57970) from [@pentp](https://github.com/pentp) does for both arrays and spans [\\\\(do\", \"tnet/runtime#70884](https://github.com/dotnet/runtime/pull/70884) also similarly avoids some signed \", \"casts in other situations). Now on .NET 7, we get this:\\n\\n```\\n; Program.Get(Int32[], Int32)\\n sub rsp,\", \"28\\n cmp edx,[rcx+8]\\n jae short M01_L00\\n mov eax,edx\\n mov eax,[rcx+rax*4+10]\\n add rsp,28\\n ret\\nM01_L00\", \":\\n call CORINFO_HELP_RNGCHKFAIL\\n```\\n\\n```\\n int 3\\n; Total bytes of code 26\\n```\\n\\nThat's not the only so\", \"urce of overhead with array access, though. In fact, there's a very large category of array access o\", \"verhead that's been there forever, but that's so well known there are even old FxCop rules and newer\", \" Roslyn analyzers that warn against it: multidimensional array accesses. The overhead in the case of\", \" a multidimensional array isn't just an extra branch on every indexing operation, or additional math\", \" required to compute the location of the element, but rather that they currently pass through the JI\", \"T's optimization phases largely unmodified. [dotnet/runtime#70271](https://github.com/dotnet/runtime\", \"/pull/70271) improves the state of the world here by doing an expansion of a multidimensional array \", \"access early in the JIT's pipeline, such that later optimization phases can improve multidimensional\", \" accesses as they would other code, including CSE and loop invariant hoisting. The impact of this is\", \" visible in a simple benchmark that sums all the elements of a multidimensional array.\\n\\n```\\nprivate \", \"int[,] _square;\\n[Params(1000)]\\npublic int Size { get; set; }\\n[GlobalSetup]\\npublic void Setup()\\n{\\n in\", \"t count = 0;\\n _square = new int[Size, Size];\\n for (int i = 0; i < Size; i++)\\n {\\n for (int j = 0; j <\", \" Size; j++)\\n {\\n _square[i, j] = count++;\\n }\\n }\\n}\\n[Benchmark]\\npublic int Sum()\\n{\\n int[,] square = _sq\", \"uare;\\n int sum = 0;\\n for (int i = 0; i < Size; i++)\\n {\\n for (int j = 0; j < Size; j++)\\n {\\n sum += sq\", \"uare[i, j];\\n }\\n }\\n return sum;\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio |\\n|--------|----------|\", \"----------|-------|\\n| Sum    | .NET 6.0 | 964.1 us | 1.00  |\\n| Sum    | .NET 7.0 | 674.7 us | 0.70  \", \"|\\n\\nThis previous example assumes you know the size of each dimension of the multidimensional array (\", \"it's referring to the Size directly in the loops). That's obviously not always (or maybe even rarely\", \") the case. In such situations, you'd be more likely to use the Array.GetUpperBound method, and beca\", \"use\\n\\nmultidimensional arrays can have a non-zero lower bound, Array.GetLowerBound. That would lead t\", \"o code like this:\\n\\n```\\nprivate int[,] _square;\\n[Params(1000)]\\npublic int Size { get; set; }\\n[GlobalS\", \"etup]\\npublic void Setup()\\n{\\n int count = 0;\\n _square = new int[Size, Size];\\n for (int i = 0; i < Siz\", \"e; i++)\\n {\\n for (int j = 0; j < Size; j++)\\n {\\n _square[i, j] = count++;\\n }\\n }\\n}\\n[Benchmark]\\npublic i\", \"nt Sum()\\n{\\n int[,] square = _square;\\n int sum = 0;\\n for (int i = square.GetLowerBound(0); i < square\", \".GetUpperBound(0); i++)\\n {\\n for (int j = square.GetLowerBound(1); j < square.GetUpperBound(1); j++)\\n\", \" {\\n sum += square[i, j];\\n }\\n }\\n return sum;\\n}\\n```\\n\\nIn .NET 7, thanks to [dotnet/runtime#60816,](http\", \"s://github.com/dotnet/runtime/pull/60816) those GetLowerBound and GetUpperBound calls become JIT int\", \"rinsics. An \\\"intrinsic\\\" to a compiler is something the compiler has intrinsic knowledge of, such tha\", \"t rather than relying solely on a method's defined implementation (if it even has one), the compiler\", \" can substitute in something it considers to be better. There are literally thousands of methods in \", \".NET known in this manner to the JIT, with GetLowerBound and GetUpperBound being two of the most rec\", \"ent. Now as intrinsics, when they're passed a constant value (e.g. 0 for the 0th rank), the JIT can \", \"substitute the necessary assembly instructions to read directly from the memory location that houses\", \" the bounds. Here's what the assembly code for this benchmark looked like with .NET 6; the main thin\", \"g to see here are all of the calls out to GetLowerBound and GetUpperBound:\\n\\n```\\n; Program.Sum()\\n pus\", \"h rdi\\n push rsi\\n push rbp\\n push rbx\\n sub rsp,28\\n mov rsi,[rcx+8]\\n xor edi,edi\\n mov rcx,rsi\\n xor edx,\", \"edx\\n```\\n\\n```\\n cmp [rcx],ecx\\n call System.Array.GetLowerBound(Int32)\\n mov ebx,eax\\n mov rcx,rsi\\n xor e\", \"dx,edx\\n call System.Array.GetUpperBound(Int32)\\n cmp eax,ebx\\n jle short M00_L03\\nM00_L00:\\n mov rcx,[rs\", \"i]\\n mov ecx,[rcx+4]\\n add ecx,0FFFFFFE8\\n shr ecx,3\\n cmp ecx,1\\n jbe short M00_L05\\n lea rdx,[rsi+10]\\n i\", \"nc ecx\\n movsxd rcx,ecx\\n mov ebp,[rdx+rcx*4]\\n mov rcx,rsi\\n mov edx,1\\n call System.Array.GetUpperBound\", \"(Int32)\\n cmp eax,ebp\\n jle short M00_L02\\nM00_L01:\\n mov ecx,ebx\\n sub ecx,[rsi+18]\\n cmp ecx,[rsi+10]\\n j\", \"ae short M00_L04\\n mov edx,ebp\\n sub edx,[rsi+1C]\\n cmp edx,[rsi+14]\\n jae short M00_L04\\n mov eax,[rsi+1\", \"4]\\n imul rax,rcx\\n mov rcx,rdx\\n add rcx,rax\\n add edi,[rsi+rcx*4+20]\\n inc ebp\\n mov rcx,rsi\\n mov edx,1\\n\", \" call System.Array.GetUpperBound(Int32)\\n cmp eax,ebp\\n jg short M00_L01\\nM00_L02:\\n inc ebx\\n mov rcx,rs\", \"i\\n xor edx,edx\\n call System.Array.GetUpperBound(Int32)\\n cmp eax,ebx\\n jg short M00_L00\\nM00_L03:\\n mov \", \"eax,edi\\n add rsp,28\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n ret\\nM00_L04:\\n call CORINFO_HELP_RNGCHKFAIL\\n\", \"```\\n\\n```\\nM00_L05:\\n mov rcx,offset MT_System.IndexOutOfRangeException\\n call CORINFO_HELP_NEWSFAST\\n mo\", \"v rsi,rax\\n call System.SR.get_IndexOutOfRange_ArrayRankIndex()\\n mov rdx,rax\\n mov rcx,rsi\\n call Syste\", \"m.IndexOutOfRangeException..ctor(System.String)\\n mov rcx,rsi\\n call CORINFO_HELP_THROW\\n int 3\\n; Total\", \" bytes of code 219\\n```\\n\\nNow here's what it is for .NET 7:\\n\\n```\\n; Program.Sum()\\n push r14\\n push rdi\\n \", \"push rsi\\n push rbp\\n push rbx\\n sub rsp,20\\n mov rdx,[rcx+8]\\n xor eax,eax\\n mov ecx,[rdx+18]\\n mov r8d,ec\", \"x\\n mov r9d,[rdx+10]\\n lea ecx,[rcx+r9+0FFFF]\\n cmp ecx,r8d\\n jle short M00_L03\\n mov r9d,[rdx+1C]\\n mov r\", \"10d,[rdx+14]\\n lea r10d,[r9+r10+0FFFF]\\nM00_L00:\\n mov r11d,r9d\\n cmp r10d,r11d\\n jle short M00_L02\\n mov \", \"esi,r8d\\n sub esi,[rdx+18]\\n mov edi,[rdx+10]\\nM00_L01:\\n mov ebx,esi\\n cmp ebx,edi\\n jae short M00_L04\\n m\", \"ov ebp,[rdx+14]\\n imul ebx,ebp\\n mov r14d,r11d\\n sub r14d,[rdx+1C]\\n cmp r14d,ebp\\n jae short M00_L04\\n ad\", \"d ebx,r14d\\n add eax,[rdx+rbx*4+20]\\n inc r11d\\n cmp r10d,r11d\\n jg short M00_L01\\nM00_L02:\\n inc r8d\\n cmp\", \" ecx,r8d\\n jg short M00_L00\\nM00_L03:\\n```\\n\\n```\\n add rsp,20\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n pop r1\", \"4\\n ret\\nM00_L04:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 130\\n```\\n\\nImportantly, not\", \"e there are no more calls (other than for the bounds check exception at the end). For example, inste\", \"ad of that first GetUpperBound call:\\n\\n```\\ncall System.Array.GetUpperBound(Int32)\\n```\\n\\nwe get:\\n\\n```\\nm\", \"ov r9d,[rdx+1C]\\nmov r10d,[rdx+14]\\nlea r10d,[r9+r10+0FFFF]\\n```\\n\\nand it ends up being much faster:\\n\\n| \", \"Method | Runtime  | Mean       | Ratio |\\n|--------|----------|------------|-------|\\n| Sum    | .NET \", \"6.0 | 2,657.5 us | 1.00  |\\n| Sum    | .NET 7.0 | 676.3 us   | 0.25  |\\n\\n#### <span id=\\\"page-49-0\\\"></s\", \"pan>**Loop Hoisting and Cloning**\\n\\nWe previously saw how PGO interacts with loop hoisting and clonin\", \"g, and those optimizations have seen other improvements, as well.\\n\\nHistorically, the JIT's support f\", \"or hoisting has been limited to lifting an invariant out one level. Consider this example:\\n\\n```\\n[Ben\", \"chmark]\\npublic void Compute()\\n{\\n for (int thousands = 0; thousands < 10; thousands++)\\n {\\n for (int h\", \"undreds = 0; hundreds < 10; hundreds++)\\n {\\n for (int tens = 0; tens < 10; tens++)\\n {\\n for (int ones \", \"= 0; ones < 10; ones++)\\n {\\n int n = ComputeNumber(thousands, hundreds, tens, ones);\\n Process(n);\\n }\\n\", \" }\\n }\\n }\\n}\\n```\\n\\n```\\nstatic int ComputeNumber(int thousands, int hundreds, int tens, int ones) =>\\n (t\", \"housands * 1000) +\\n (hundreds * 100) +\\n (tens * 10) +\\n ones;\\n[MethodImpl(MethodImplOptions.NoInlinin\", \"g)]\\nstatic void Process(int n) { }\\n```\\n\\nAt first glance, you might look at this and say \\\"what could \", \"be hoisted, the computation of n requires all of the loop inputs, and all of that computation is in \", \"ComputeNumber.\\\" But from a compiler's perspective, the ComputeNumber function is inlineable and thus\", \" logically can be part of its caller, the computation of n is actually split into multiple pieces, a\", \"nd each of those pieces can be hoisted to different levels, e.g. the tens computation can be hoisted\", \" out one level, the hundreds out two levels, and the thousands out three levels. Here's what [Disass\", \"emblyDiagnoser] outputs for .NET 6:\\n\\n```\\n; Program.Compute()\\n push r14\\n push rdi\\n push rsi\\n push rbp\", \"\\n push rbx\\n sub rsp,20\\n xor esi,esi\\nM00_L00:\\n xor edi,edi\\nM00_L01:\\n xor ebx,ebx\\nM00_L02:\\n xor ebp,eb\", \"p\\n imul ecx,esi,3E8\\n imul eax,edi,64\\n add ecx,eax\\n lea eax,[rbx+rbx*4]\\n lea r14d,[rcx+rax*2]\\nM00_L03\", \":\\n lea ecx,[r14+rbp]\\n call Program.Process(Int32)\\n inc ebp\\n cmp ebp,0A\\n jl short M00_L03\\n inc ebx\\n c\", \"mp ebx,0A\\n jl short M00_L02\\n inc edi\\n cmp edi,0A\\n jl short M00_L01\\n inc esi\\n cmp esi,0A\\n jl short M0\", \"0_L00\\n add rsp,20\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n pop r14\\n ret\\n; Total bytes of code 84\\n```\\n\\nWe\", \" can see that *some* hoisting has happened here. After all, the inner most loop (tagged M00\\\\_L03) is\", \" only five instructions: increment ebp (which at this point is the ones counter value), and if it's \", \"still less than 0xA (10), jump back to M00\\\\_L03 which adds whatever is in r14 to ones. Great, so we'\", \"ve hoisted all of the unnecessary computation out of the inner loop, being left only with adding the\", \" ones position to the rest of the number. Let's go out a level. M00\\\\_L02 is the label for the tens l\", \"oop. What do we see there? Trouble. The two instructions imul ecx,esi,3E8 and imul eax,edi,64 are pe\", \"rforming the thousands \\\\* 1000 and hundreds \\\\* 100 operations, highlighting that these operations wh\", \"ich could have been hoisted out further were left stuck in the next-to-innermost loop. Now, here's w\", \"hat we get for .NET 7, where this was improved in [dotnet/runtime#68061:](https://github.com/dotnet/\", \"runtime/issues/68061)\\n\\n```\\n; Program.Compute()\\n push r15\\n push r14\\n push r12\\n push rdi\\n push rsi\\n pu\", \"sh rbp\\n push rbx\\n sub rsp,20\\n xor esi,esi\\nM00_L00:\\n xor edi,edi\\n imul ebx,esi,3E8\\nM00_L01:\\n xor ebp,\", \"ebp\\n imul r14d,edi,64\\n add r14d,ebx\\nM00_L02:\\n xor r15d,r15d\\n lea ecx,[rbp+rbp*4]\\n lea r12d,[r14+rcx*\", \"2]\\nM00_L03:\\n lea ecx,[r12+r15]\\n call qword ptr [Program.Process(Int32)]\\n inc r15d\\n cmp r15d,0A\\n jl s\", \"hort M00_L03\\n inc ebp\\n cmp ebp,0A\\n jl short M00_L02\\n inc edi\\n cmp edi,0A\\n jl short M00_L01\\n inc esi\\n\", \" cmp esi,0A\\n jl short M00_L00\\n add rsp,20\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n pop r12\\n pop r14\\n pop\", \" r15\\n ret\\n; Total bytes of code 99\\n```\\n\\nNotice now where those imul instructions live. There are fou\", \"r labels, each one corresponding to one of the loops, and we can see the outermost loop has the imul\", \" ebx,esi,3E8 (for the thousands computation) and the next loop has the imul r14d,edi,64 (for the hun\", \"dreds computation), highlighting that these computations were hoisted out to the appropriate level (\", \"the tens and ones computation are still in the right places).\\n\\nMore improvements have gone in on the\", \" cloning side. Previously, loop cloning would only apply for loops iterating by 1 from a low to a hi\", \"gh value. With [dotnet/runtime#60148,](https://github.com/dotnet/runtime/pull/60148) the comparison \", \"against the upper value can be <= rather than just <. And with [dotnet/runtime#67930,](https://githu\", \"b.com/dotnet/runtime/pull/67930) loops that iterate downward can also be cloned, as can loops that h\", \"ave increments and decrements larger than 1. Consider this benchmark:\\n\\n```\\nprivate int[] _values = E\", \"numerable.Range(0, 1000).ToArray();\\n[Benchmark]\\n[Arguments(0, 0, 1000)]\\npublic int LastIndexOf(int a\", \"rg, int offset, int count)\\n{\\n int[] values = _values;\\n for (int i = offset + count - 1; i >= offset;\", \" i--)\\n if (values[i] == arg)\\n return i;\\n return 0;\\n}\\n```\\n\\nWithout loop cloning, the JIT can't assume\", \" that offset through offset+count are in range, and thus every access to the array needs to be bound\", \"s checked. With loop cloning, the JIT could generate one version of the loop without bounds checks a\", \"nd only use that when it knows all accesses will be valid. That's exactly what happens now in .NET 7\", \". Here's what we got with .NET 6:\\n\\n```\\n; Program.LastIndexOf(Int32, Int32, Int32)\\n sub rsp,28\\n mov r\", \"cx,[rcx+8]\\n lea eax,[r8+r9+0FFFF]\\n cmp eax,r8d\\n jl short M00_L01\\n mov r9d,[rcx+8]\\n nop word ptr [rax\", \"+rax]\\nM00_L00:\\n cmp eax,r9d\\n jae short M00_L03\\n movsxd r10,eax\\n cmp [rcx+r10*4+10],edx\\n je short M00\", \"_L02\\n dec eax\\n cmp eax,r8d\\n jge short M00_L00\\nM00_L01:\\n xor eax,eax\\n add rsp,28\\n ret\\nM00_L02:\\n add r\", \"sp,28\\n ret\\nM00_L03:\\n call CORINFO_HELP_RNGCHKFAIL\\n```\\n\\n```\\n int 3\\n; Total bytes of code 72\\n```\\n\\nNoti\", \"ce how in the core loop, at label M00\\\\_L00, there's a bounds check (cmp eax,r9d and jae short M00\\\\_L\", \"03, which jumps to a call CORINFO\\\\_HELP\\\\_RNGCHKFAIL). And here's what we get with .NET 7:\\n\\n```\\n; Pro\", \"gram.LastIndexOf(Int32, Int32, Int32)\\n sub rsp,28\\n mov rax,[rcx+8]\\n lea ecx,[r8+r9+0FFFF]\\n cmp ecx,r\", \"8d\\n jl short M00_L02\\n test rax,rax\\n je short M00_L01\\n test ecx,ecx\\n jl short M00_L01\\n test r8d,r8d\\n \", \"jl short M00_L01\\n cmp [rax+8],ecx\\n jle short M00_L01\\nM00_L00:\\n mov r9d,ecx\\n cmp [rax+r9*4+10],edx\\n j\", \"e short M00_L03\\n dec ecx\\n cmp ecx,r8d\\n jge short M00_L00\\n jmp short M00_L02\\nM00_L01:\\n cmp ecx,[rax+8\", \"]\\n jae short M00_L04\\n mov r9d,ecx\\n cmp [rax+r9*4+10],edx\\n je short M00_L03\\n dec ecx\\n cmp ecx,r8d\\n jg\", \"e short M00_L01\\nM00_L02:\\n xor eax,eax\\n add rsp,28\\n ret\\nM00_L03:\\n mov eax,ecx\\n add rsp,28\\n ret\\nM00_L0\", \"4:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 98\\n```\\n\\nNotice how the code size is la\", \"rger, and how there are now two variations of the loop: one at M00\\\\_L00 and one at M00\\\\_L01. The sec\", \"ond one, M00\\\\_L01, has a branch to that same call CORINFO\\\\_HELP\\\\_RNGCHKFAIL, but the first one doesn\", \"'t, because that loop will only end up being used after proving that the offset, count, and \\\\_values\", \".Length are such that the indexing will always be in bounds.\\n\\nOther changes also improved loop cloni\", \"ng. [dotnet/runtime#59886](https://github.com/dotnet/runtime/pull/59886) enables the JIT to choose d\", \"ifferent forms for how to emit the the conditions for choosing the fast or slow loop path, e.g. whet\", \"her to emit\\n\\nall the conditions, & them together, and then branch (if (!(cond1 & cond2)) goto slowPa\", \"th), or whether to emit each condition on its own (if (!cond1) goto slowPath; if (!cond2) goto slowP\", \"ath). [dotnet/runtime#66257](https://github.com/dotnet/runtime/pull/66257) enables loop cloning to k\", \"ick in when the loop variable is initialized to more kinds of expressions (e.g. for (int fromindex =\", \" lastIndex - lengthToClear; ...)). And [dotnet/runtime#70232](https://github.com/dotnet/runtime/pull\", \"/70232) increases the JIT's willingness to clone loops with bodies that do a broader set of operatio\", \"ns.\\n\\n#### <span id=\\\"page-54-0\\\"></span>**Folding, propagation, and substitution**\\n\\nConstant folding i\", \"s an optimization where a compiler computes the value of an expression involving only constants at c\", \"ompile-time rather than generating the code to compute the value at run-time. There are multiple lev\", \"els of constant folding in .NET, with some constant folding performed by the C# compiler and some co\", \"nstant folding performed by the JIT compiler. For example, given the C# code:\\n\\n```\\n[Benchmark]\\npubli\", \"c int A() => 3 + (4 * 5);\\n[Benchmark]\\npublic int B() => A() * 2;\\n```\\n\\nthe C# compiler will generate \", \"IL for these methods like the following:\\n\\n```\\n.method public hidebysig instance int32 A () cil manag\", \"ed \\n{\\n .maxstack 8\\n IL_0000: ldc.i4.s 23\\n IL_0002: ret\\n}\\n.method public hidebysig instance int32 B (\", \") cil managed \\n{\\n .maxstack 8\\n IL_0000: ldarg.0\\n IL_0001: call instance int32 Program::A()\\n IL_0006:\", \" ldc.i4.2\\n IL_0007: mul\\n IL_0008: ret\\n}\\n```\\n\\nYou can see that the C# compiler has computed the value\", \" of 3 + (4\\\\*5), as the IL for method A simply contains the equivalent of return 23;. However, method\", \" B contains the equivalent of return A() \\\\* 2;, highlighting that the constant folding performed by \", \"the C# compiler was intramethod only. Now here's what the JIT generates:\\n\\n```\\n; Program.A()\\n mov eax\", \",17\\n ret\\n; Total bytes of code 6\\n; Program.B()\\n mov eax,2E\\n ret\\n; Total bytes of code 6\\n```\\n\\nThe ass\", \"embly for method A isn't particularly interesting; it's just returning that same value 23 (hex 0x17)\", \". But method B is more interesting. The JIT has inlined the call from B to A, exposing the contents \", \"of A to B, such that the JIT effectively sees the body of B as the equivalent of return 23 \\\\* 2;. At\", \" that point, the JIT can do its own constant folding, and it transforms the body of B to simply retu\", \"rn 46 (hex 0x2e). Constant propagation is intricately linked to constant folding and is essentially \", \"just the idea that you can substitute a constant value (typically one computed via constant folding)\", \" into further expressions, at which point they may also be able to be folded.\\n\\nThe JIT has long perf\", \"ormed constant folding, but it improves further in .NET 7. One of the ways constant folding can impr\", \"ove is by exposing more values to be folded, which often means more inlining. [dotnet/runtime#55745]\", \"(https://github.com/dotnet/runtime/pull/55745) helped the inliner to understand that a method call l\", \"ike M(constant + constant) (noting that those constants might be the result of some other method cal\", \"l) is itself passing a constant to M, and a constant being passed to a method call is a hint to the \", \"inliner that it should consider being more aggressive about inlining, since exposing that constant t\", \"o the body of the callee can potentially significantly reduce the amount of code required to impleme\", \"nt the callee. The JIT might have previously inlined such a method anyway, but when it comes to inli\", \"ning, the JIT is all about heuristics and generating enough evidence that it's worthwhile to inline \", \"something; this contributes to that evidence. This pattern shows up, for example, in the various Fro\", \"mXx methods on TimeSpan. For example, TimeSpan.FromSeconds is implemented as:\\n\\n```\\npublic static Tim\", \"eSpan FromSeconds(double value) => Interval(value, TicksPerSecond); // \\nTicksPerSecond is a constant\", \"\\n```\\n\\nand, eschewing argument validation for the purposes of this example, Interval is:\\n\\n```\\nprivate\", \" static TimeSpan Interval(double value, double scale) => \\nIntervalFromDoubleTicks(value * scale);\\npr\", \"ivate static TimeSpan IntervalFromDoubleTicks(double ticks) => ticks == long.MaxValue ? \\nTimeSpan.Ma\", \"xValue : new TimeSpan((long)ticks);\\n```\\n\\nwhich if everything gets inlined means FromSeconds is essen\", \"tially:\\n\\n```\\npublic static TimeSpan FromSeconds(double value)\\n{\\n double ticks = value * 10_000_000;\\n\", \" return ticks == long.MaxValue ? TimeSpan.MaxValue : new TimeSpan((long)ticks);\\n}\\n```\\n\\nand if value \", \"is a constant, let's say 5, that whole thing can be constant folded (with dead code elimination on t\", \"he ticks == long.MaxValue branch) to simply:\\n\\n```\\nreturn new TimeSpan(50_000_000);\\n```\\n\\nI'll spare y\", \"ou the .NET 6 assembly for this, but on .NET 7 with a benchmark like:\\n\\n```\\n[Benchmark]\\npublic TimeSp\", \"an FromSeconds() => TimeSpan.FromSeconds(5);\\n```\\n\\nwe now get the simple and clean:\\n\\n```\\n; Program.Fr\", \"omSeconds()\\n mov eax,2FAF080\\n```\\n\\n```\\n ret\\n; Total bytes of code 6\\n```\\n\\nAnother change improving con\", \"stant folding included [dotnet/runtime#57726](https://github.com/dotnet/runtime/pull/57726) from [@S\", \"ingleAccretion](https://github.com/SingleAccretion), which unblocked constant folding in a particula\", \"r scenario that sometimes manifests when doing field-by-field assignment of structs being returned f\", \"rom method calls. As a small example, consider this trivial property, which access the Color.DarkOra\", \"nge property, which in turn does new Color(KnownColor.DarkOrange):\\n\\n```\\n[Benchmark]\\npublic Color Dar\", \"kOrange() => Color.DarkOrange;\\n```\\n\\nIn .NET 6, the JIT generated this:\\n\\n```\\n; Program.DarkOrange()\\n \", \"mov eax,1\\n mov ecx,39\\n xor r8d,r8d\\n mov [rdx],r8\\n mov [rdx+8],r8\\n mov [rdx+10],cx\\n mov [rdx+12],ax\\n \", \"mov rax,rdx\\n ret\\n; Total bytes of code 32\\n```\\n\\nThe interesting thing here is that some constants (39\", \", which is the value of KnownColor.DarkOrange, and 1, which is a private StateKnownColorValid consta\", \"nt) are being loaded into registers (mov eax, 1, mov ecx, 39) and then later being stored into the r\", \"elevant location for the Color struct being returned (mov [rdx+12],ax and mov [rdx+10],cx). In .NET \", \"7, it now generates:\\n\\n```\\n; Program.DarkOrange()\\n xor eax,eax\\n mov [rdx],rax\\n mov [rdx+8],rax\\n mov w\", \"ord ptr [rdx+10],39\\n mov word ptr [rdx+12],1\\n mov rax,rdx\\n ret\\n; Total bytes of code 25\\n```\\n\\nwith di\", \"rect assignment of these constant values into their destination locations (mov word ptr [rdx+12],1 a\", \"nd mov word ptr [rdx+10],39). Other changes contributing to constant folding included [dotnet/runtim\", \"e#58171](https://github.com/dotnet/runtime/pull/58171) from [@SingleAccretion](https://github.com/Si\", \"ngleAccretion) and [dotnet/runtime#57605](https://github.com/dotnet/runtime/pull/57605) from [@Singl\", \"eAccretion](https://github.com/SingleAccretion).\\n\\nHowever, a large category of improvement came from\", \" an optimization related to propagation, that of forward substitution. Consider this silly benchmark\", \":\\n\\n```\\n[Benchmark]\\npublic int Compute1() => Value + Value + Value + Value + Value;\\n[Benchmark]\\npubli\", \"c int Compute2() => SomethingElse() + Value + Value + Value + Value + Value;\\nprivate static int Valu\", \"e => 16;\\n```\\n\\n```\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate static int SomethingElse() => 4\", \"2;\\n```\\n\\nIf we look at the assembly code generated for Compute1 on .NET 6, it looks like what we'd ho\", \"pe for. We're adding Value 5 times, Value is trivially inlined and returns a constant value 16, and \", \"so we'd hope that the assembly code generated for Compute1 would effectively just be returning the v\", \"alue 80 (hex 0x50), which is exactly what happens:\\n\\n```\\n; Program.Compute1()\\n mov eax,50\\n ret\\n; Tota\", \"l bytes of code 6\\n```\\n\\nBut Compute2 is a bit different. The structure of the code is such that the a\", \"dditional call to SomethingElse ends up slightly perturbing something about the JIT's analysis, and \", \".NET 6 ends up with this assembly code:\\n\\n```\\n; Program.Compute2()\\n sub rsp,28\\n call Program.Somethin\", \"gElse()\\n add eax,10\\n add eax,10\\n add eax,10\\n add eax,10\\n add eax,10\\n add rsp,28\\n ret\\n; Total bytes o\", \"f code 29\\n```\\n\\nRather than a single mov eax, 50 to put the value 0x50 into the return register, we h\", \"ave 5 separate add eax, 10 to build up that same 0x50 (80) value. That's\\u2026 not ideal.\\n\\nIt turns out t\", \"hat many of the JIT's optimizations operate on the tree data structures created as part of parsing t\", \"he IL. In some cases, optimizations can do better when they're exposed to more of the program, in ot\", \"her words when the tree they're operating on is larger and contains more to be analyzed. However, va\", \"rious operations can break up these trees into smaller, individual ones, such as with temporary vari\", \"ables created as part of inlining, and in doing so can inhibit these operations. Something is needed\", \" in order to effectively stitch these trees back together, and that's forward substitution. You can \", \"think of forward substitution almost like an inverse of CSE; rather than trying to find duplicate ex\", \"pressions and eliminate them by computing the value once and storing it into a temporary, forward su\", \"bstitution eliminates that temporary and effectively moves the expression tree into its use site. Ob\", \"viously you don't want to do this if it would then negate CSE and result in duplicate work, but for \", \"expressions that are defined once and used once, this kind of forward propagation is valuable. [dotn\", \"et/runtime#61023](https://github.com/dotnet/runtime/pull/61023) added an initial limited version of \", \"forward substitution, and then [dotnet/runtime#63720](https://github.com/dotnet/runtime/pull/63720) \", \"added a more robust generalized implementation. Subsequently, [dotnet/runtime#70587](https://github.\", \"com/dotnet/runtime/pull/70587) expanded it to also cover some SIMD vectors, and then [dotnet/runtime\", \"#71161](https://github.com/dotnet/runtime/pull/71161) improved it further to enable substitutions in\", \"to more places (in this case into call arguments). And with those, our silly benchmark now produces \", \"the following on .NET 7:\\n\\n```\\n; Program.Compute2()\\n sub rsp,28\\n call qword ptr [7FFCB8DAF9A8]\\n```\\n\\n`\", \"``\\n add eax,50\\n add rsp,28\\n ret\\n; Total bytes of code 18\\n```\\n\\n#### <span id=\\\"page-58-0\\\"></span>**Vec\", \"torization**\\n\\nSIMD, or Single Instruction Multiple Data, is a kind of processing in which one instru\", \"ction applies to multiple pieces of data at the same time. You've got a list of numbers and you want\", \" to find the index of a particular value? You could walk the list comparing one element at a time, a\", \"nd that would be fine functionally. But what if in the same amount of time it takes you to read and \", \"compare one element, you could instead read and compare two elements, or four elements, or 32 elemen\", \"ts? That's SIMD, and the art of utilizing SIMD instructions is lovingly referred to as \\\"vectorizatio\", \"n,\\\" where operations are applied to all of the elements in a \\\"vector\\\" at the same time.\\n\\n.NET has lo\", \"ng had support for vectorization in the form of Vector<T>, which is an easy-to-use type with first-c\", \"lass JIT support to enable a developer to write vectorized implementations. One of Vector<T>'s great\", \"est strengths is also one of its greatest weaknesses. The type is designed to adapt to whatever widt\", \"h vector instructions are available in your hardware. If the machine supports 256-bit width vectors,\", \" great, that's what Vector<T> will target. If not, if the machine supports 128-bit width vectors, gr\", \"eat, that's what Vector<T> targets. But that flexibility comes with various downsides, at least toda\", \"y; for example, the operations you can perform on a Vector<T> end up needing to be agnostic to the w\", \"idth of the vectors used, since the width is variable based on the hardware on which the code actual\", \"ly runs. And that means the operations that can be exposed on Vector<T> are limited, which in turn l\", \"imits the kinds of operations that can be vectorized with it. Also, because it's only ever a single \", \"size in a given process, some data set sizes that fall in between 128 bits and 256 bits might not be\", \" processed as well as you'd hope. You write your Vector<byte>-based algorithm, and you run it on a m\", \"achine with support for 256-bit vectors, which means it can process 32 bytes at a time, but then you\", \" feed it an input with 31 bytes. Had Vector<T> mapped to 128-bit vectors, it could have been used to\", \" improve the processing of that input, but as its vector size is larger than the input data size, th\", \"e implementation ends up falling back to one that's not accelerated. There are also issues related t\", \"o R2R and Native AOT, since ahead-of-time compilation needs to know in advance what instructions sho\", \"uld be used for Vector<T> operations. You already saw this earlier when discussing the output of DOT\", \"NET\\\\_JitDisasmSummary; we saw that the NarrowUtf16ToAscii method was one of only a few methods that \", \"was JIT compiled in a \\\"hello, world\\\" console app, and that this was because it lacked R2R code due t\", \"o its use of Vector<T>.\\n\\nStarting in .NET Core 3.0, .NET gained literally thousands of new \\\"hardware\", \" intrinsics\\\" methods, most of which are .NET APIs that map down to one of these SIMD instructions. T\", \"hese intrinsics enable an expert to write an implementation tuned to a specific instruction set, and\", \" if done well, get the best possible performance, but it also requires the developer to understand e\", \"ach instruction set and to implement their algorithm for each instruction set that might be relevant\", \", e.g. an AVX2 implementation if it's supported, or an SSE2 implementation if it's supported, or an \", \"ArmBase implementation if it's supported, and so on.\\n\\n.NET 7 has introduced a middle ground. Previou\", \"s releases saw the introduction of the Vector128<T> and Vector256<T> types, but purely as the vehicl\", \"e by which data moved in and out of the hardware intrinsics, since they're all tied to specific widt\", \"h vectors. Now in .NET 7, exposed via\\n\\n[dotnet/runtime#53450,](https://github.com/dotnet/runtime/pul\", \"l/53450) [dotnet/runtime#63414,](https://github.com/dotnet/runtime/pull/63414) [dotnet/runtime#60094\", \",](https://github.com/dotnet/runtime/pull/60094) and [dotnet/runtime#68559,](https://github.com/dotn\", \"et/runtime/pull/68559) a very large set of cross-platform operations is defined over these types as \", \"well, e.g. Vector128<T>.ExtractMostSignificantBits, Vector256.ConditionalSelect, and so on. A develo\", \"per who wants or needs to go beyond what the high-level Vector<T> offers can choose to target one or\", \" more of these two types. Typically this would amount to a developer writing one code path based on \", \"Vector128<T>, as that has the broadest reach and achieves a significant amount of the gains from vec\", \"torization, and then if is motivated to do so can add a second path for Vector256<T> in order to pot\", \"entially double throughput further on platforms that have 256-bit width vectors. Think of these type\", \"s and methods as a platform-abstraction layer: you code to these methods, and then the JIT translate\", \"s them into the most appropriate instructions for the underlying platform. Consider this simple code\", \" as an example:\\n\\n```\\nusing System.Runtime.CompilerServices;\\nusing System.Runtime.Intrinsics;\\nusing S\", \"ystem.Runtime.Intrinsics.X86;\\ninternal class Program\\n{\\n private static void Main()\\n {\\n Vector128<byt\", \"e> v = Vector128.Create((byte)123);\\n while (true)\\n {\\n WithIntrinsics(v);\\n WithVector(v);\\n }\\n }\\n [Met\", \"hodImpl(MethodImplOptions.NoInlining)]\\n private static int WithIntrinsics(Vector128<byte> v) => Sse2\", \".MoveMask(v);\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n private static uint WithVector(Vector128<\", \"byte> v) => v.ExtractMostSignificantBits();\\n}\\n```\\n\\nI have two functions: one that directly uses the \", \"Sse2.MoveMask hardware intrinsic and one that uses the new Vector128<T>.ExtractMostSignificantBits m\", \"ethod. Using DOTNET\\\\_JitDisasm=Program.\\\\*, here's what the optimized tier-1 code for these looks lik\", \"e on my x64 Windows machine:\\n\\n```\\n; Assembly listing for method Program:WithIntrinsics(Vector128`1):\", \"int\\nG_M000_IG01: ;; offset=0000H\\n C5F877 vzeroupper\\nG_M000_IG02: ;; offset=0003H\\n C5F91001 vmovupd x\", \"mm0, xmmword ptr [rcx]\\n C5F9D7C0 vpmovmskb eax, xmm0\\nG_M000_IG03: ;; offset=000BH\\n C3 ret\\n; Total by\", \"tes of code 12\\n; Assembly listing for method Program:WithVector(Vector128`1):int\\nG_M000_IG01: ;; off\", \"set=0000H\\n C5F877 vzeroupper\\n```\\n\\n```\\nG_M000_IG02: ;; offset=0003H\\n C5F91001 vmovupd xmm0, xmmword p\", \"tr [rcx]\\n C5F9D7C0 vpmovmskb eax, xmm0\\nG_M000_IG03: ;; offset=000BH\\n C3 ret\\n; Total bytes of code 12\", \"\\n```\\n\\nNotice anything? The code for the two methods is identical, both resulting in a vpmovmskb (Mov\", \"e Byte Mask) instruction. Yet the former code will only work on a platform that supports SSE2 wherea\", \"s the latter code will work on any platform with support for 128-bit vectors, including Arm64 and WA\", \"SM (and any future platforms on-boarded that also support SIMD); it'll just result in different inst\", \"ructions being emitted on those platforms.\\n\\nTo explore this a bit more, let's take a simple example \", \"and vectorize it. We'll implement a Contains method, where we want to search a span of bytes for a s\", \"pecific value and return whether it was found:\\n\\n```\\nstatic bool Contains(ReadOnlySpan<byte> haystack\", \", byte needle)\\n{\\n for (int i = 0; i < haystack.Length; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n retur\", \"n true;\\n }\\n }\\n return false;\\n}\\n```\\n\\nHow would we vectorize this with Vector<T>? First things first, \", \"we need to check whether it's even supported, and fall back to our existing implementation if it's n\", \"ot (Vector.IsHardwareAccelerated). We also need to fall back if the length of the input is less than\", \" the size of a vector (Vector<byte>.Count).\\n\\n```\\nstatic bool Contains(ReadOnlySpan<byte> haystack, b\", \"yte needle)\\n{\\n if (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count)\\n {\\n // ...\", \"\\n }\\n else\\n {\\n for (int i = 0; i < haystack.Length; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n return tr\", \"ue;\\n }\\n }\\n }\\n return false;\\n}\\n```\\n\\nNow that we know we have enough data, we can get to coding our ve\", \"ctorized loop. In this loop, we'll be searching for the needle, which means we need a vector that co\", \"ntains that value for every element; the Vector<T>'s constructor provides that (new Vector<byte>(nee\", \"dle)). And we need to be able to slice off a vector's width of data at a time; for a bit more effici\", \"ency, I'll use pointers. We need a current iteration pointer, and we need to iterate until the point\", \" where we couldn't form another vector because we're too close to the end, and a straightforward way\", \" to do that is to get a pointer that's exactly one vector's width from the end; that way, we can jus\", \"t iterate until our current pointer is equal to or greater than that threshold. And finally, in our \", \"loop body, we need to compare our current vector with the target vector to see if any elements are t\", \"he same (Vector.EqualsAny), if any is returning true, and if not bumping our current pointer to the \", \"next location. At this point we have:\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, \", \"byte needle)\\n{\\n if (Vector.IsHardwareAccelerated && haystack.Length >= Vector<byte>.Count)\\n {\\n fixed\", \" (byte* haystackPtr = &MemoryMarshal.GetReference(haystack))\\n {\\n Vector<byte> target = new Vector<by\", \"te>(needle);\\n byte* current = haystackPtr;\\n byte* endMinusOneVector = haystackPtr + haystack.Length \", \"- Vector<byte>.Count;\\n do\\n {\\n if (Vector.EqualsAny(target, *(Vector<byte>*)current))\\n {\\n return true\", \";\\n }\\n current += Vector<byte>.Count;\\n }\\n while (current < endMinusOneVector);\\n // ...\\n }\\n }\\n else\\n {\", \"\\n for (int i = 0; i < haystack.Length; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n return true;\\n }\\n }\\n }\", \"\\n return false;\\n}\\n```\\n\\nAnd we're almost done. The last issue to handle is we may still have a few el\", \"ements at the end we haven't searched. There are a couple of ways we could handle that. One would be\", \" to just continue with our fall back implementation and process each of the remaining elements one a\", \"t a time. Another would be to employ a trick that's common when vectorizing idempotent operations. O\", \"ur operation isn't mutating anything, which means it doesn't matter if we compare the same element m\", \"ultiple times, which means we can just do one final vector compare for the last vector in the search\", \" space;\\n\\nthat might or might not overlap with elements we've already looked at, but it won't hurt an\", \"ything if it does. And with that, our implementation is complete:\\n\\n```\\nstatic unsafe bool Contains(R\", \"eadOnlySpan<byte> haystack, byte needle)\\n{\\n if (Vector.IsHardwareAccelerated && haystack.Length >= V\", \"ector<byte>.Count)\\n {\\n fixed (byte* haystackPtr = &MemoryMarshal.GetReference(haystack))\\n {\\n Vector<\", \"byte> target = new Vector<byte>(needle);\\n byte* current = haystackPtr;\\n byte* endMinusOneVector = ha\", \"ystackPtr + haystack.Length - Vector<byte>.Count;\\n do\\n {\\n if (Vector.EqualsAny(target, *(Vector<byte\", \">*)current))\\n {\\n return true;\\n }\\n current += Vector<byte>.Count;\\n }\\n while (current < endMinusOneVec\", \"tor);\\n if (Vector.EqualsAny(target, *(Vector<byte>*)endMinusOneVector))\\n {\\n return true;\\n }\\n }\\n }\\n e\", \"lse\\n {\\n for (int i = 0; i < haystack.Length; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n return true;\\n }\", \"\\n }\\n }\\n return false;\\n}\\n```\\n\\nCongratulations, we've vectorized this operation, and fairly decently a\", \"t that. We can throw this into benchmarkdotnet and see really nice speedups:\\n\\n```\\nprivate byte[] _da\", \"ta = Enumerable.Repeat((byte)123, 999).Append((byte)42).ToArray();\\n[Benchmark(Baseline = true)]\\n[Arg\", \"uments((byte)42)]\\npublic bool Find(byte value) => Contains(_data, value); // just the fallback path \", \"in its \\nown method\\n[Benchmark]\\n[Arguments((byte)42)]\\npublic bool FindVectorized(byte value) => Conta\", \"ins_Vectorized(_data, value); // the \\nimplementation we just wrote\\n```\\n\\n| Method         | Mean     \", \" |      |\\n|----------------|-----------|------|\\n| Find           | 484.05 ns | 1.00 |\\n| FindVectoriz\", \"ed | 20.21 ns  | 0.04 |\\n\\nA 24x speedup! Woo hoo, victory, all your performance are belong to us!\\n\\nYo\", \"u deploy this in your service, and you see Contains being called on your hot path, but you don't see\", \" the improvements you were expecting. You dig in a little more, and you discover that while you test\", \"ed this with an input array with 1000 elements, typical inputs had more like 30 elements. What happe\", \"ns if we change our benchmark to have just 30 elements? That's not long enough to form a vector, so \", \"we fall back to the one-at-a-time path, and we don't get any speedups at all.\\n\\nOne thing we can now \", \"do is switch from using Vector<T> to Vector128<T>. That will then lower the threshold from 32 bytes \", \"to 16 bytes, such that inputs in that range will still have some amount of vectorization applied. As\", \" these Vector128<T> and Vector256<T> types have been designed very recently, they also utilize all t\", \"he cool new toys, and thus we can use refs instead of pointers. Other than that, we can keep the sha\", \"pe of our implementation almost the same, substituting Vector128 where we were using Vector, and usi\", \"ng some methods on Unsafe to manipulate our refs instead of pointer arithmetic on the span we fixed.\", \"\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<byte> haystack, byte needle)\\n{\\n if (Vector128.IsHardw\", \"areAccelerated && haystack.Length >= Vector128<byte>.Count)\\n {\\n ref byte current = ref MemoryMarshal\", \".GetReference(haystack);\\n Vector128<byte> target = Vector128.Create(needle);\\n ref byte endMinusOneVe\", \"ctor = ref Unsafe.Add(ref current, haystack.Length -\\nVector128<byte>.Count);\\n do\\n {\\n if (Vector128.E\", \"qualsAny(target, Vector128.LoadUnsafe(ref current)))\\n {\\n return true;\\n }\\n current = ref Unsafe.Add(r\", \"ef current, Vector128<byte>.Count);\\n }\\n while (Unsafe.IsAddressLessThan(ref current, ref endMinusOne\", \"Vector));\\n if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref endMinusOneVector)))\\n {\\n return \", \"true;\\n }\\n }\\n else\\n {\\n for (int i = 0; i < haystack.Length; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n r\", \"eturn true;\\n }\\n }\\n }\\n```\\n\\n```\\n return false;\\n}\\n```\\n\\nWith that in hand, we can now try it on our smal\", \"ler 30 element data set:\\n\\n```\\nprivate byte[] _data = Enumerable.Repeat((byte)123, 29).Append((byte)4\", \"2).ToArray();\\n[Benchmark(Baseline = true)]\\n[Arguments((byte)42)]\\npublic bool Find(byte value) => Con\", \"tains(_data, value);\\n[Benchmark]\\n[Arguments((byte)42)]\\npublic bool FindVectorized(byte value) => Con\", \"tains_Vectorized(_data, value);\\n```\\n\\n| Method         | Mean      | Ratio |\\n|----------------|------\", \"-----|-------|\\n| Find           | 15.388 ns | 1.00  |\\n| FindVectorized | 1.747 ns  | 0.11  |\\n\\nWoo ho\", \"o, victory, all your performance are belong to us\\u2026 again!\\n\\nWhat about on the larger data set again? \", \"Previously with Vector<T> we had a 24x speedup, but now:\\n\\n| Method         | Mean      |      |\\n|---\", \"-------------|-----------|------|\\n| Find           | 484.25 ns | 1.00 |\\n| FindVectorized | 32.92 ns \", \" | 0.07 |\\n\\n\\u2026 closer to 15x. Nothing to sneeze at, but it's not the 24x we previously saw. What if we\", \" want to have our cake and eat it, too? Let's also add a Vector256<T> path. To do that, we literally\", \" copy/paste our Vector128<T> code, search/replace all references to Vector128 in the copied code wit\", \"h Vector256, and just put it into an additional condition that uses the Vector256<T> path if it's su\", \"pported and there are enough elements to utilize it.\\n\\n```\\nstatic unsafe bool Contains(ReadOnlySpan<b\", \"yte> haystack, byte needle)\\n{\\n if (Vector128.IsHardwareAccelerated && haystack.Length >= Vector128<b\", \"yte>.Count)\\n {\\n ref byte current = ref MemoryMarshal.GetReference(haystack);\\n if (Vector256.IsHardwa\", \"reAccelerated && haystack.Length >= Vector256<byte>.Count)\\n {\\n Vector256<byte> target = Vector256.Cr\", \"eate(needle);\\n ref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length -\\nVector256<\", \"byte>.Count);\\n do\\n {\\n if (Vector256.EqualsAny(target, Vector256.LoadUnsafe(ref current)))\\n {\\n return\", \" true;\\n }\\n current = ref Unsafe.Add(ref current, Vector256<byte>.Count);\\n }\\n while (Unsafe.IsAddress\", \"LessThan(ref current, ref endMinusOneVector));\\n```\\n\\n```\\n if (Vector256.EqualsAny(target, Vector256.L\", \"oadUnsafe(ref endMinusOneVector)))\\n {\\n return true;\\n }\\n }\\n else\\n {\\n Vector128<byte> target = Vector1\", \"28.Create(needle);\\n ref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack.Length -\\nVecto\", \"r128<byte>.Count);\\n do\\n {\\n if (Vector128.EqualsAny(target, Vector128.LoadUnsafe(ref current)))\\n {\\n r\", \"eturn true;\\n }\\n current = ref Unsafe.Add(ref current, Vector128<byte>.Count);\\n }\\n while (Unsafe.IsAd\", \"dressLessThan(ref current, ref endMinusOneVector));\\n if (Vector128.EqualsAny(target, Vector128.LoadU\", \"nsafe(ref endMinusOneVector)))\\n {\\n return true;\\n }\\n }\\n }\\n else\\n {\\n for (int i = 0; i < haystack.Leng\", \"th; i++)\\n {\\n if (haystack[i] == needle)\\n {\\n return true;\\n }\\n }\\n }\\n return false;\\n}\\n```\\n\\nAnd, boom, w\", \"e're back:\\n\\n| Method         | Mean      | Ratio |\\n|----------------|-----------|-------|\\n| Find    \", \"       | 484.53 ns | 1.00  |\\n| FindVectorized | 20.08 ns  | 0.04  |\\n\\nWe now have an implementation t\", \"hat is vectorized on any platform with either 128-bit or 256-bit vector instructions (x86, x64, Arm6\", \"4, WASM, etc.), that can use either based on the input length, and that can be included in an R2R im\", \"age if that's of interest.\\n\\nThere are many factors that impact which path you go down, and I expect \", \"we'll have guidance forthcoming to help navigate all the factors and approaches. But the capabilitie\", \"s are all there, and whether you choose to use Vector<T>, Vector128<T> and/or Vector256<T>, or the h\", \"ardware intrinsics directly, there are some amazing performance opportunities ready for the taking.\\n\", \"\\nI already mentioned several PRs that exposed the new cross-platform vector support, but that only s\", \"cratches the surface of the work done to actually enable these operations and to enable them to prod\", \"uce high-quality code. As just one example of a category of such work, a set of changes went in to h\", \"elp ensure that zero vector constants are handled well, such as [dotnet/runtime#63821](https://githu\", \"b.com/dotnet/runtime/pull/63821) that \\\"morphed\\\" (changed) Vector128/256<T>.Create(default) into Vect\", \"or128/256<T>.Zero, which then enables subsequent optimizations to focus only on Zero; [dotnet/runtim\", \"e#65028](https://github.com/dotnet/runtime/pull/65028) that enabled constant propagation of Vector12\", \"8/256<T>.Zero; [dotnet/runtime#68874](https://github.com/dotnet/runtime/pull/68874) and [dotnet/runt\", \"ime#70171](https://github.com/dotnet/runtime/pull/70171) that add first-class knowledge of vector co\", \"nstants to the JIT's intermediate representation; and [dotnet/runtime#62933,](https://github.com/dot\", \"net/runtime/pull/62933) [dotnet/runtime#65632,](https://github.com/dotnet/runtime/pull/65632) [dotne\", \"t/runtime#55875,](https://github.com/dotnet/runtime/pull/55875) [dotnet/runtime#67502,](https://gith\", \"ub.com/dotnet/runtime/pull/67502) and [dotnet/runtime#64783](https://github.com/dotnet/runtime/pull/\", \"64783) that all improve the code quality of instructions generated for zero vector comparisons.\\n\\n###\", \"# <span id=\\\"page-66-0\\\"></span>**Inlining**\\n\\nInlining is one of the most important optimizations the \", \"JIT can do. The concept is simple: instead of making a call to some method, take the code from that \", \"method and bake it into the call site. This has the obvious advantage of avoiding the overhead of a \", \"method call, but except for really small methods on really hot paths, that's often on the smaller si\", \"de of the wins inlining brings. The bigger wins are due to the callee's code being exposed to the ca\", \"ller's code, and vice versa. So, for example, if the caller is passing a constant as an argument to \", \"the callee, if the method isn't inlined, the compilation of the callee has no knowledge of that cons\", \"tant, but if the callee is inlined, all of the code in the callee is then aware of its argument bein\", \"g a constant value, and can do all of the optimizations possible with such a constant, like dead cod\", \"e elimination, branch elimination, constant folding and propagation, and so on. Of course, if it wer\", \"e all rainbows and unicorns, everything possible to be inlined would be inlined, and that's obviousl\", \"y not happening. Inlining brings with it the cost of potentially increased binary size. If the code \", \"being inlined would result in the same amount or less assembly code in the caller than it takes to c\", \"all the callee (and if the JIT can quickly determine that), then inlining is a nobrainer. But if the\", \" code being inlined would increase the size of the callee non-trivially, now the JIT needs to weigh \", \"that increase in code size against the throughput benefits that could come from it. That code size i\", \"ncrease can itself result in throughput regressions, due to increasing the number of distinct instru\", \"ctions to be executed and thereby putting more pressure on the instruction cache. As with any cache,\", \" the more times you need to read from memory to populate it, the less effective the cache will be. I\", \"f you have a function that gets inlined into 100 different call sites, every one of those call sites\", \"' copies of the callee's instructions are unique, and calling each of those 100 functions could end \", \"up thrashing the instruction cache; in contrast, if all of those 100 functions \\\"shared\\\" the same ins\", \"tructions by simply calling the single instance of the callee, it's likely the instruction cache wou\", \"ld be much more effective and lead to fewer trips to memory.\\n\\nAll that is to say, inlining is *reall\", \"y* important, it's important that the \\\"right\\\" things be inlined and that it not overinline, and as s\", \"uch every release of .NET in recent memory has seen nice improvements around inlining. .NET 7 is no \", \"exception.\\n\\nOne really interesting improvement around inlining is [dotnet/runtime#64521,](https://gi\", \"thub.com/dotnet/runtime/pull/64521) and it might be surprising. Consider the Boolean.ToString method\", \"; here's its full implementation:\\n\\n```\\npublic override string ToString()\\n{\\n```\\n\\n```\\n if (!m_value) r\", \"eturn \\\"False\\\";\\n return \\\"True\\\";\\n}\\n```\\n\\nPretty simple, right? You'd expect something this trivial to b\", \"e inlined. Alas, on .NET 6, this benchmark:\\n\\n```\\nprivate bool _value = true;\\n[Benchmark]\\npublic int \", \"BoolStringLength() => _value.ToString().Length;\\n```\\n\\nproduces this assembly code:\\n\\n```\\n; Program.Boo\", \"lStringLength()\\n sub rsp,28\\n cmp [rcx],ecx\\n add rcx,8\\n call System.Boolean.ToString()\\n mov eax,[rax+\", \"8]\\n add rsp,28\\n ret\\n; Total bytes of code 23\\n```\\n\\nNote the call System.Boolean.ToString(). The reaso\", \"n for this is, historically, the JIT has been unable to inline methods across assembly boundaries if\", \" those methods contain string literals (like the \\\"False\\\" and \\\"True\\\" in that Boolean.ToString impleme\", \"ntation). This restriction had to do with string interning and the possibility that such inlining co\", \"uld lead to visible behavioral differences. Those concerns are no longer valid, and so this PR remov\", \"es the restriction. As a result, that same benchmark on .NET 7 now produces this:\\n\\n```\\n; Program.Boo\", \"lStringLength()\\n cmp byte ptr [rcx+8],0\\n je short M00_L01\\n mov rax,1DB54800D20\\n mov rax,[rax]\\nM00_L0\", \"0:\\n mov eax,[rax+8]\\n ret\\nM00_L01:\\n mov rax,1DB54800D18\\n mov rax,[rax]\\n jmp short M00_L00\\n; Total byt\", \"es of code 38\\n```\\n\\nNo more call System.Boolean.ToString().\\n\\n[dotnet/runtime#61408](https://github.co\", \"m/dotnet/runtime/pull/61408) made two changes related to inlining. First, it taught the inliner how \", \"to better see the what methods were being called in an inlining candidate, and in particular when ti\", \"ered compilation is disabled or when a method would bypass tier-0 (such as a method with loops befor\", \"e OSR existed or with OSR disabled); by understanding what methods are being called, it can better u\", \"nderstand the cost of the method, e.g. if those method calls are actually hardware intrinsics with a\", \" very low cost. Second, it enabled CSE in more cases with SIMD vectors.\\n\\n[dotnet/runtime#71778](http\", \"s://github.com/dotnet/runtime/pull/71778) also impacted inlining, and in particular in situations wh\", \"ere a typeof() could be propagated to the callee (e.g. via a method argument). In previous releases \", \"of .NET, various\\n\\nmembers on Type like IsValueType were turned into JIT intrinsics, such that the JI\", \"T could substitute a constant value for calls where it could compute the answer at compile time. For\", \" example, this:\\n\\n```\\n[Benchmark]\\npublic bool IsValueType() => IsValueType<int>();\\nprivate static boo\", \"l IsValueType<T>() => typeof(T).IsValueType;\\n```\\n\\nresults in this assembly code on .NET 6:\\n\\n```\\n; Pr\", \"ogram.IsValueType()\\n mov eax,1\\n ret\\n; Total bytes of code 6\\n```\\n\\nHowever, change the benchmark sligh\", \"tly:\\n\\n```\\n[Benchmark]\\npublic bool IsValueType() => IsValueType(typeof(int));\\nprivate static bool IsV\", \"alueType(Type t) => t.IsValueType;\\n```\\n\\nand it's no longer as simple:\\n\\n```\\n; Program.IsValueType()\\n \", \"sub rsp,28\\n mov rcx,offset MT_System.Int32\\n call CORINFO_HELP_TYPEHANDLE_TO_RUNTIMETYPE\\n mov rcx,rax\", \"\\n mov rax,[7FFCA47C9560]\\n cmp [rcx],ecx\\n add rsp,28\\n jmp rax\\n; Total bytes of code 38\\n```\\n\\nEffective\", \"ly, as part of inlining the JIT loses the notion that the argument is a constant and fails to propag\", \"ate it. This PR fixes that, such that on .NET 7, we now get what we expect:\\n\\n```\\n; Program.IsValueTy\", \"pe()\\n mov eax,1\\n ret\\n; Total bytes of code 6\\n```\\n\\n#### <span id=\\\"page-68-0\\\"></span>**Arm64**\\n\\nA huge\", \" amount of effort in .NET 7 went into making code gen for Arm64 as good or better than its x64 count\", \"erpart. I've already discussed a bunch of PRs that are relevant regardless of architecture, and othe\", \"rs that are specific to Arm, but there are plenty more. To rattle off some of them:\\n\\n\\u2022 **Addressing \", \"modes**. \\\"Addressing mode\\\" is the term used to refer to how the operand of instructions are specifie\", \"d. It could be the actual value, it could be the address from where a value should be loaded, it cou\", \"ld be the register containing the value, and so on. Arm supports a \\\"scaled\\\" addressing mode, typical\", \"ly used for indexing into an array, where the size of each element is supplied and the instruction \\\"\", \"scales\\\" the provided offset by the specified scale. [dotnet/runtime#60808](https://github.com/dotnet\", \"/runtime/pull/60808) enables the JIT to utilize this addressing mode. More generally, [dotnet/runtim\", \"e#70749](https://github.com/dotnet/runtime/pull/70749) enables the JIT to use addressing modes when \", \"accessing elements of\\n\\n- managed arrays. [dotnet/runtime#66902](https://github.com/dotnet/runtime/pu\", \"ll/66902) improves the use of addressing modes when the element type is byte. [dotnet/runtime#65468]\", \"(https://github.com/dotnet/runtime/pull/65468) improves addressing modes used for floating point. An\", \"d [dotnet/runtime#67490](https://github.com/dotnet/runtime/pull/67490) implements addressing modes f\", \"or SIMD vectors, specifically for loads with unscaled indices.\\n- **Better instruction selection**. V\", \"arious techniques go into ensuring that the best instructions are selected to represent input code. \", \"[dotnet/runtime#61037](https://github.com/dotnet/runtime/pull/61037) teaches the JIT how to recogniz\", \"e the pattern (a \\\\* b) + c with integers and fold that into a single madd or msub instruction, while\", \" [dotnet/runtime#66621](https://github.com/dotnet/runtime/pull/66621) does the same for a - (b \\\\* c)\", \" and msub. [dotnet/runtime#61045](https://github.com/dotnet/runtime/pull/61045) enables the JIT to r\", \"ecognize certain constant bit shift operations (either explicit in the code or implicit to various f\", \"orms of managed array access) and emit sbfiz/ubfiz instructions. [dotnet/runtime#70599,](https://git\", \"hub.com/dotnet/runtime/pull/70599) [dotnet/runtime#66407,](https://github.com/dotnet/runtime/pull/66\", \"407) and [dotnet/runtime#65535](https://github.com/dotnet/runtime/pull/65535) all handle various for\", \"ms of optimizing a % b. [dotnet/runtime#61847](https://github.com/dotnet/runtime/pull/61847) from [@\", \"SeanWoo](https://github.com/SeanWoo) removes an unnecessary movi emitted as part of setting a derefe\", \"renced pointer to a constant value. [dotnet/runtime#57926](https://github.com/dotnet/runtime/pull/57\", \"926) from [@SingleAccretion](https://github.com/SingleAccretion) enables computing a 64-bit result a\", \"s the multiplication of two 32-bit integers to be done with smull/umull. And [dotnet/runtime#61549](\", \"https://github.com/dotnet/runtime/pull/61549) folds adds with sign extension or zero extension into \", \"a single add instruction with uxtw/sxtw/lsl, while [dotnet/runtime#62630](https://github.com/dotnet/\", \"runtime/pull/62630) drops redundant zero extensions after a ldr instruction.\\n- **Vectorization**. [d\", \"otnet/runtime#64864](https://github.com/dotnet/runtime/pull/64864) adds new AdvSimd.LoadPairVector64\", \"/AdvSimd.LoadPairVector128 hardware intrinsics.\\n- **Zeroing**. Lots of operations require state to b\", \"e set to zero, such as initializing all reference locals in a method to zero as part of the method's\", \" prologue (so that the GC doesn't see and try to follow garbage references). While such functionalit\", \"y was previously vectorized, [dotnet/runtime#63422](https://github.com/dotnet/runtime/pull/63422) en\", \"ables this to be implemented using 128-bit width vector instructions on Arm. And [dotnet/runtime#644\", \"81](https://github.com/dotnet/runtime/pull/64481) changes the instruction sequences used for zeroing\", \" in order to avoid unnecessary zeroing, free up additional registers, and enable the CPU to recogniz\", \"e various instruction sequences and better optimize.\\n- **Memory Model**. [dotnet/runtime#62895](http\", \"s://github.com/dotnet/runtime/pull/62895) enables store barriers to be used wherever possible instea\", \"d of full barriers, and uses one-way barriers for volatile variables. [dotnet/runtime#67384](https:/\", \"/github.com/dotnet/runtime/pull/67384) enables volatile reads/writes to be implemented with the ldap\", \"r instruction, while [dotnet/runtime#64354](https://github.com/dotnet/runtime/pull/64354) uses a che\", \"aper instruction sequence to handle volatile indirections. There's [dotnet/runtime#70600,](https://g\", \"ithub.com/dotnet/runtime/pull/70600) which enables LSE Atomics to be used for Interlocked operations\", \"; [dotnet/runtime#71512,](https://github.com/dotnet/runtime/pull/71512) which enables using the atom\", \"ics instruction on Unix machines; and [dotnet/runtime#70921,](https://github.com/dotnet/runtime/pull\", \"/70921) which enables the same but on Windows.\\n\\n#### <span id=\\\"page-69-0\\\"></span>**JIT helpers**\\n\\nWh\", \"ile logically part of the runtime, the JIT is actually isolated from the rest of the runtime, only i\", \"nteracting with it through an interface that enables communication between the JIT and the rest of t\", \"he VM (Virtual Machine). There's a large amount of VM functionality then that the JIT relies on for \", \"good performance.\\n\\n[dotnet/runtime#65738](https://github.com/dotnet/runtime/pull/65738) rewrote vari\", \"ous \\\"stubs\\\" to be more efficient. Stubs are tiny bits of code that serve to perform some check and t\", \"hen redirect execution somewhere else. For example, when an interface dispatch call site is expected\", \" to only ever be used with a single implementation of that interface, the JIT might employ a \\\"dispat\", \"ch stub\\\" that compares the type of the object against the\\n\\nsingle one it's cached, and if they're eq\", \"ual simply jumps to the right target. You know you're in the corest of the core areas of the runtime\", \" when a PR contains lots of assembly code for every architecture the runtime targets. And it paid of\", \"f; there's a virtual group of folks from around .NET that review performance improvements and regres\", \"sions in our automated performance test suites, and attribute these back to the PRs likely to be the\", \" cause (this is mostly automated but requires some human oversight). It's always nice then when a fe\", \"w days after a PR is merged and performance information has stabilized that you see a rash of commen\", \"ts like there were on this PR:\\n\\n![](_page_70_Figure_1.jpeg)\\n\\nFor anyone familiar with generics and i\", \"nterested in performance, you may have heard the refrain that generic virtual methods are relatively\", \" expensive. They are, comparatively. For example on .NET 6, this code:\\n\\n```\\nprivate Example _example\", \" = new Example();\\n[Benchmark(Baseline = true)] public void GenericNonVirtual() => \\n_example.GenericN\", \"onVirtual<Example>();\\n[Benchmark] public void GenericVirtual() => _example.GenericVirtual<Example>()\", \";\\nclass Example\\n{\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n public void GenericNonVirtual<T>() { \", \"}\\n [MethodImpl(MethodImplOptions.NoInlining)]\\n public virtual void GenericVirtual<T>() { }\\n}\\n```\\n\\nre\", \"sults in:\\n\\n| Method            | Mean   | Ratio |\\n|-------------------|--------|-------|\\n| GenericNo\", \"nVirtual | 0.4866 | 1.00  |\\n|                   | ns     |       |\\n| GenericVirtual    | 6.4552 | 13\", \".28 |\\n|                   | ns     |       |\\n\\n[dotnet/runtime#65926](https://github.com/dotnet/runti\", \"me/pull/65926) eases the pain a tad. Some of the cost comes from looking up some cached information \", \"in a hash table in the runtime, and as is the case with many map implementations, this one involves \", \"computing a hash code and using a mod operation to map to the right bucket. Other hash table impleme\", \"ntations around [dotnet/runtime,](https://github.com/dotnet/runtime) including Dictionary<,>, HashSe\", \"t<,>, and ConcurrentDictionary<,> previously switched to a [\\\"fastmod\\\"](https://lemire.me/blog/2019/0\", \"2/08/faster-remainders-when-the-divisor-is-a-constant-beating-compilers-and-libdivide) implementatio\", \"n; this PR does the same for this EEHashtable, which is used as part of the CORINFO\\\\_GENERIC\\\\_HANDLE\", \" JIT helper function employed:\\n\\n| Method         | Runtime  | Mean     | Ratio |\\n|----------------|-\", \"---------|----------|-------|\\n| GenericVirtual | .NET 6.0 | 6.475 ns | 1.00  |\\n| GenericVirtual | .N\", \"ET 7.0 | 6.119 ns | 0.95  |\\n\\nNot enough of an improvement for us to start recommending people use th\", \"em, but a 5% improvement takes a bit of the edge off the sting.\\n\\n#### <span id=\\\"page-71-0\\\"></span>**\", \"Grab Bag**\\n\\nIt's near impossible to cover every performance change that goes into the JIT, and I'm n\", \"ot going to try. But there were so many more PRs, I couldn't just leave them all unsung, so here's a\", \" few more quickies:\\n\\n\\u2022 [dotnet/runtime#58196](https://github.com/dotnet/runtime/pull/58196) from [@b\", \"enjamin-hodgson](https://github.com/benjamin-hodgson). Given an expression like (byte)x | (byte)y, t\", \"hat can be morphed into (byte)(x | y), which can optimize away some movs.\\n\\n```\\nprivate int _x, _y;\\n[\", \"Benchmark]\\npublic int Test() => (byte)_x | (byte)_y;\\n```\\n\\n```\\n; *** .NET 6 ***\\n; Program.Test(Int32,\", \" Int32)\\n movzx eax,dl\\n movzx edx,r8b\\n or eax,edx\\n ret\\n; Total bytes of code 10\\n; *** .NET 7 ***\\n; Pr\", \"ogram.Test(Int32, Int32)\\n or edx,r8d\\n movzx eax,dl\\n ret\\n; Total bytes of code 7\\n```\\n\\n\\u2022 [dotnet/runti\", \"me#67182.](https://github.com/dotnet/runtime/pull/67182) On a machine with support for BMI2, 64-bit \", \"shifts can be performed with the shlx, sarx, and shrx instructions.\\n\\n```\\n[Benchmark]\\n[Arguments(123,\", \" 1)]\\npublic ulong Shift(ulong x, int y) => x << y;\\n```\\n\\n```\\n; *** .NET 6 ***\\n; Program.Shift(UInt64,\", \" Int32)\\n mov ecx,r8d\\n mov rax,rdx\\n shl rax,cl\\n ret\\n; Total bytes of code 10\\n; *** .NET 7 ***\\n; Progr\", \"am.Shift(UInt64, Int32)\\n shlx rax,rdx,r8\\n ret\\n; Total bytes of code 6\\n```\\n\\n\\u2022 [dotnet/runtime#69003](\", \"https://github.com/dotnet/runtime/pull/69003) from [@SkiFoD](https://github.com/SkiFoD). The pattern\", \" ~x + 1 can be changed into a two's-complement negation.\\n\\n```\\n[Benchmark]\\n[Arguments(42)]\\npublic int\", \" Neg(int i) => ~i + 1;\\n```\\n\\n```\\n; *** .NET 6 ***\\n; Program.Neg(Int32)\\n mov eax,edx\\n not eax\\n inc eax\", \"\\n ret\\n; Total bytes of code 7\\n; *** .NET 7 ***\\n; Program.Neg(Int32)\\n mov eax,edx\\n neg eax\\n ret\\n; Tot\", \"al bytes of code 5\\n```\\n\\n\\u2022 [dotnet/runtime#61412](https://github.com/dotnet/runtime/pull/61412) from \", \"[@SkiFoD](https://github.com/SkiFoD). An expression X & 1 == 1 to test whether the bottom bit of a n\", \"umber is set can changed to the cheaper X & 1 (which isn't actually expressible without a following \", \"!= 0 in C#).\\n\\n```\\n[Benchmark]\\n[Arguments(42)]\\npublic bool BitSet(int x) => (x & 1) == 1;\\n```\\n\\n```\\n; \", \"*** .NET 6 ***\\n; Program.BitSet(Int32)\\n test dl,1\\n setne al\\n```\\n\\n```\\n movzx eax,al\\n ret\\n; Total byte\", \"s of code 10\\n; *** .NET 7 ***\\n; Program.BitSet(Int32)\\n mov eax,edx\\n and eax,1\\n ret\\n; Total bytes of \", \"code 6\\n```\\n\\n\\u2022 [dotnet/runtime#63545](https://github.com/dotnet/runtime/pull/63545) from [@Wraith2](h\", \"ttps://github.com/Wraith2). The expression x & (x - 1) can be lowered to the blsr instruction.\\n\\n```\\n\", \"[Benchmark]\\n[Arguments(42)]\\npublic int ResetLowestSetBit(int x) => x & (x - 1);\\n```\\n\\n```\\n; *** .NET \", \"6 ***\\n; Program.ResetLowestSetBit(Int32)\\n lea eax,[rdx+0FFFF]\\n and eax,edx\\n ret\\n; Total bytes of cod\", \"e 6\\n; *** .NET 7 ***\\n; Program.ResetLowestSetBit(Int32)\\n blsr eax,edx\\n ret\\n; Total bytes of code 6\\n`\", \"``\\n\\n\\u2022 [dotnet/runtime#62394.](https://github.com/dotnet/runtime/pull/62394) / and % by a vector's .C\", \"ount wasn't recognizing that Count can be unsigned, but doing so leads to better code gen.\\n\\n```\\n[Ben\", \"chmark]\\n[Arguments(42u)]\\npublic long DivideByVectorCount(uint i) => i / Vector<byte>.Count;\\n```\\n\\n```\", \"\\n; *** .NET 6 ***\\n; Program.DivideByVectorCount(UInt32)\\n mov eax,edx\\n mov rdx,rax\\n sar rdx,3F\\n and r\", \"dx,1F\\n add rax,rdx\\n sar rax,5\\n ret\\n; Total bytes of code 21\\n; *** .NET 7 ***\\n; Program.DivideByVecto\", \"rCount(UInt32)\\n mov eax,edx\\n shr rax,5\\n ret\\n; Total bytes of code 7\\n```\\n\\n\\u2022 [dotnet/runtime#60787.](h\", \"ttps://github.com/dotnet/runtime/pull/60787) [Loop alignment in .NET 6](https://devblogs.microsoft.c\", \"om/dotnet/loop-alignment-in-net-6) provides a very nice exploration of why and how the JIT handles l\", \"oop alignment. This PR extends that further by trying to \\\"hide\\\" an emitted align instruction behind \", \"an unconditional jmp that might already exist, in order to minimize the impact of the processor havi\", \"ng to fetch and decode nops.\\n\\n### <span id=\\\"page-75-0\\\"></span>GC\\n\\n\\\"Regions\\\" is a feature of the garb\", \"age collector (GC) that's been in the works for multiple years. It's enabled by default in 64-bit pr\", \"ocesses in .NET 7 as of [dotnet/runtime#64688,](https://github.com/dotnet/runtime/pull/64688) but as\", \" with other multiyear features, a multitude of PRs went into making it a reality. At a 30,000 foot l\", \"evel, \\\"regions\\\" replaces the current \\\"segments\\\" approach to managing memory on the GC heap; rather t\", \"han having a few gigantic segments of memory (e.g. each 1GB), often associated 1:1 with a generation\", \", the GC instead maintains many, many smaller regions (e.g. each 4MB) as their own entity. This enab\", \"les the GC to be more agile with regards to operations like repurposing regions of memory from one g\", \"eneration to another. For more information on regions, the blog post [Put a DPAD on that GC!](https:\", \"//devblogs.microsoft.com/dotnet/put-a-dpad-on-that-gc) from the primary developer on the GC is still\", \" the best resource.\\n\\n71 CHAPTER 3 | GC\\n\\n**CHAPTER** 4\\n\\n### <span id=\\\"page-76-0\\\"></span>Native AOT\\n\\nT\", \"o many people, the word \\\"performance\\\" in the context of software is about throughput. How fast does \", \"something execute? How much data per second can it process? How many requests per second can it proc\", \"ess? And so on. But there are many other facets to performance. How much memory does it consume? How\", \" fast does it start up and get to the point of doing something useful? How much space does it consum\", \"e on disk? How long would it take to download? And then there are related concerns. In order to achi\", \"eve these goals, what dependencies are required? What kinds of operations does it need to perform to\", \" achieve these goals, and are all of those operations permitted in the target environment? If any of\", \" this paragraph resonates with you, you are the target audience for the Native AOT support now shipp\", \"ing in .NET 7.\\n\\n.NET has long had support for AOT code generation. For example, .NET Framework had i\", \"t in the form of ngen, and .NET Core has it in the form of crossgen. Both of those solutions involve\", \" a standard .NET executable that has some of its IL already compiled to assembly code, but not all m\", \"ethods will have assembly code generated for them, various things can invalidate the assembly code t\", \"hat was generated, external .NET assemblies without any native assembly code can be loaded, and so o\", \"n, and in all of those cases, the runtime continues to utilize a JIT compiler. Native AOT is differe\", \"nt. It's an evolution of CoreRT, which itself was an evolution of .NET Native, and it's entirely fre\", \"e of a JIT. The binary that results from publishing a build is a completely standalone executable in\", \" the target platform's platform-specific file format (e.g. COFF on Windows, ELF on Linux, Mach-O on \", \"macOS) with no external dependencies other than ones standard to that platform (e.g. libc). And it's\", \" entirely native: no IL in sight, no JIT, no nothing. All required code is compiled and/or linked in\", \" to the executable, including the same GC that's used with standard .NET apps and services, and a mi\", \"nimal runtime that provides services around threading and the like. All of that brings great benefit\", \"s: super fast startup time, small and entirely-self contained deployment, and ability to run in plac\", \"es JIT compilers aren't allowed (e.g. because memory pages that were writable can't then be executab\", \"le). It also brings limitations: no JIT means no dynamic loading of arbitrary assemblies (e.g. Assem\", \"bly.LoadFile) and no reflection emit (e.g. DynamicMethod), everything compiled and linked in to the \", \"app means the more functionality that's used (or might be used) the larger is your deployment, etc. \", \"Even with those limitations, for a certain class of application, Native AOT is an incredibly excitin\", \"g and welcome addition to .NET 7.\\n\\nToo many PRs to mention have gone into bringing up the Native AOT\", \" stack, in part because it's been in the works for years (as part of the archived [dotnet/corert](ht\", \"tps://github.com/dotnet/corert) project and then as part of [dotnet/runtimelab/feature/NativeAOT\\\\)](\", \"https://github.com/dotnet/runtimelab/tree/feature/NativeAOT) and in part because there have been ove\", \"r a hundred PRs just in [dotnet/runtime](https://github.com/dotnet/runtime) that have gone into brin\", \"ging Native AOT up to a shippable state since the code was originally brought over from [dotnet/runt\", \"imelab](https://github.com/dotnet/runtimelab) in [dotnet/runtime#62563](https://github.com/dotnet/ru\", \"ntime/pull/62563) and [dotnet/runtime#62563.](https://github.com/dotnet/runtime/pull/62611)  Between\", \" that and there not being a previous version to compare its performance to, instead of focusing PR b\", \"y PR on improvements, let's just look at how to use it and the benefits it brings.\\n\\nToday, Native AO\", \"T is focused on console applications, so let's create a console app:\\n\\n```\\ndotnet new console -o nati\", \"veaotexample\\n```\\n\\nWe now have our nativeaotexample directory containing a nativeaotexample.csproj an\", \"d a \\\"hello, world\\\" Program.cs. To enable publishing the application with Native AOT, edit the .cspro\", \"j to include this in the existing <PropertyGroup>...</PropertyGroup>.\\n\\n```\\n<PublishAot>true</Publish\", \"Aot>\\n```\\n\\nAnd then\\u2026 actually, that's it. Our app is now fully configured to be able to target Native\", \" AOT. All that's left is to publish. As I'm currently writing this on my Windows x64 machine, I'll t\", \"arget that:\\n\\n```\\ndotnet publish -r win-x64 -c Release\\n```\\n\\nI now have my generated executable in the\", \" output publish directory:\\n\\n```\\n Directory: C:\\\\nativeaotexample\\\\bin\\\\Release\\\\net7.0\\\\win-x64\\\\publish\\nM\", \"ode LastWriteTime Length Name\\n-a--- 8/27/2022 6:19 PM 2061824 nativeaotexample.exe\\n-a--- 8/27/2022 6\", \":19 PM 14290944 nativeaotexample.pdb\\n```\\n\\nso 2M instead of 3.5MB. Of course, for that significant re\", \"duction I've given up some things:\\n\\n- Setting InvariantGlobalization to true means I'm now not respe\", \"cting culture information and am instead using a set of invariant data for most globalization operat\", \"ions.\\n- Setting UseSystemResourceKeys to true means nice exception messages are stripped away.\\n- Set\", \"ting IlcGenerateStackTraceData to false means I'm going to get fairly poor stack traces should I nee\", \"d to debug an exception.\\n- Setting DebuggerSupport to false\\u2026 good luck debugging things.\\n- \\u2026 you get\", \" the idea.\\n\\nOne of the potentially mind-boggling aspects of Native AOT for a developer used to .NET \", \"is that, as it says on the tin, it really is native. After publishing the app, there is no IL involv\", \"ed, and there's no JIT that could even process it. This makes some of the other investments in .NET \", \"7 all the more valuable, for example everywhere investments are happening in source generators. Code\", \" that previously relied on reflection emit for good performance will need another scheme. We can see\", \" that, for example, with Regex. Historically for optimal throughput with Regex, it's been recommende\", \"d to use RegexOptions.Compiled, which uses reflection emit at run-time to generate an optimized impl\", \"ementation of the specified pattern. But if you look at the implementation of the Regex constructor,\", \" you'll find this nugget:\\n\\n```\\nif (RuntimeFeature.IsDynamicCodeCompiled)\\n{\\n factory = Compile(patter\", \"n, tree, options, matchTimeout != InfiniteMatchTimeout);\\n}\\n```\\n\\nWith the JIT, IsDynamicCodeCompiled \", \"is true. But with Native AOT, it's false. Thus, with Native AOT and Regex, there's no difference bet\", \"ween specifying RegexOptions.Compiled and not, and another mechanism is required to get the throughp\", \"ut benefits promised by RegexOptions.Compiled. Enter [GeneratedRegex(...)], which, along with the ne\", \"w regex source generator shipping in the .NET 7\\n\\nSDK, emits C# code into the assembly using it. That\", \" C# code takes the place of the reflection emit that would have happened at run-time, and is thus ab\", \"le to work successfully with Native AOT.\\n\\n```\\nprivate static readonly string s_haystack = new\\nHttpCl\", \"ient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _inte\", \"rpreter = new Regex(@\\\"^.*elementary.*$\\\", RegexOptions.Multiline);\\nprivate Regex _compiled = new Rege\", \"x(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled | \\nRegexOptions.Multiline);\\n[GeneratedRegex(@\\\"^.*elemen\", \"tary.*$\\\", RegexOptions.Multiline)]\\nprivate partial Regex SG();\\n[Benchmark(Baseline = true)] public i\", \"nt Interpreter() => _interpreter.Count(s_haystack);\\n[Benchmark] public int Compiled() => _compiled.C\", \"ount(s_haystack);\\n[Benchmark] public int SourceGenerator() => SG().Count(s_haystack);\\n```\\n\\n| Method \", \"         | Mean       | Ratio |\\n|-----------------|------------|-------|\\n| Interpreter     | 9,036.7\", \" us | 1.00  |\\n| Compiled        | 9,064.8 us | 1.00  |\\n| SourceGenerator | 426.1 us   | 0.05  |\\n\\nSo,\", \" yes, there are some constraints associated with Native AOT, but there are also solutions for workin\", \"g with those constraints. And further, those constraints can actually bring further benefits. Consid\", \"er [dotnet/runtime#64497](https://github.com/dotnet/runtime/pull/64497). Remember how we talked abou\", \"t \\\"guarded devirtualization\\\" in dynamic PGO, where via instrumentation the JIT can determine the mos\", \"t likely type to be used at a given call site and special-case it? With Native AOT, the entirety of \", \"the program is known at compile time, with no support for Assembly.LoadFrom or the like. That means \", \"at compile time, the compiler can do whole-program analysis to determine what types implement what i\", \"nterfaces. If a given interface only has a single type that implements it, then every call site thro\", \"ugh that interface can be unconditionally devirtualized, without any type-check guards.\\n\\nThis is a r\", \"eally exciting space, one we expect to see flourish in coming releases.\\n\\n### <span id=\\\"page-79-0\\\"></\", \"span>Mono\\n\\nUp until now I've referred to \\\"the JIT,\\\" \\\"the GC,\\\" and \\\"the runtime,\\\" but in reality ther\", \"e are actually multiple runtimes in .NET. I've been talking about \\\"coreclr,\\\" which is the runtime th\", \"at's recommended for use on Linux, macOS, and Windows. However, there's also \\\"mono,\\\" which powers Bl\", \"azor wasm applications, Android apps, and iOS apps. It's also seen significant improvements in .NET \", \"7.\\n\\nJust as with coreclr (which can JIT compile, AOT compile partially with JIT fallback, and fully \", \"Native AOT compile), mono has multiple ways of actually executing code. One of those ways is an inte\", \"rpreter, which enables mono to execute .NET code in environments that don't permit JIT'ing and witho\", \"ut requiring ahead-of-time compilation or incurring any limitations it may bring. Interestingly, tho\", \"ugh, the interpreter is itself almost a full-fledged compiler, parsing the IL, generating its own in\", \"termediate representation (IR) for it, and doing one or more optimization passes over that IR; it's \", \"just that at the end of the pipeline when a compiler would normally emit code, the interpreter inste\", \"ad saves off that data for it to interpret when the time comes to run. As such, the interpreter has \", \"a very similar conundrum to the one we discussed with coreclr's JIT: the time it takes to optimize v\", \"s the desire to start up quickly. And in .NET 7, the interpreter employs a similar solution: tiered \", \"compilation. [dotnet/runtime#68823](https://github.com/dotnet/runtime/pull/68823) adds the ability f\", \"or the interpreter to initially compile with minimal optimization of that IR, and then once a certai\", \"n threshold of call counts has been hit, then take the time to do as much optimization on the IR as \", \"possible for all future invocations of that method. This yields the same benefits as it does for cor\", \"eclr: improved startup time while also having efficient sustained throughput. When this merged, we s\", \"aw improvements in Blazor wasm app startup time improve by 10-20%. Here's one example from an app be\", \"ing tracked in our benchmarking system:\\n\\n75 CHAPTER 5 | Mono\\n\\n![](_page_80_Figure_1.jpeg)\\n\\nThe inter\", \"preter isn't just used for entire apps, though. Just as how coreclr can use the JIT when an R2R imag\", \"e doesn't contain code for a method, mono can use the interpreter when there's no AOT code for a met\", \"hod. Once such case that occurred on mono was with generic delegate invocation, where the presence o\", \"f a generic delegate being invoked would trigger falling back to the interpreter; for .NET 7, that g\", \"ap was addressed with [dotnet/runtime#70653.](https://github.com/dotnet/runtime/pull/70653) A more i\", \"mpactful case, however, is [dotnet/runtime#64867.](https://github.com/dotnet/runtime/pull/64867) Pre\", \"viously, any methods with catch or filter exception handling clauses couldn't be AOT compiled and wo\", \"uld fall back to being interpreted. With this PR, the method is now able to be AOT compiled, and it \", \"only falls back to using the interpreter when an exception actually occurs, switching over to the in\", \"terpreter for the remainder of that method call's execution. Since many methods contain such clauses\", \", this can make a big difference in throughput and CPU consumption. In the same vein, [dotnet/runtim\", \"e#63065](https://github.com/dotnet/runtime/pull/63065) enabled methods with finally exception handli\", \"ng clauses to be AOT compiled; just the finally block gets interpreted rather than the entire method\", \" being interpreted.\\n\\nBeyond such backend improvements, another class of improvement came from furthe\", \"r unification between coreclr and mono. Years ago, coreclr and mono had their own entire library sta\", \"ck built on top of them. Over time, as .NET was open sourced, portions of mono's stack got replaced \", \"by shared components, bit by bit. Fast forward to today, all of the core .NET libraries above System\", \".Private.CoreLib are the same regardless of which runtime is being employed. In fact, the source for\", \" CoreLib itself is almost entirely shared, with ~95% of the source files being compiled into the Cor\", \"eLib that's built for each runtime, and just a few percent of the source specialized for each (these\", \" statements means that the vast majority of the performance improvements discussed in the rest of th\", \"is post apply equally whether running on mono and coreclr). Even so, every release now we try to chi\", \"p away at that few remaining percent, for reasons of maintainability, but also because the source us\", \"ed for coreclr's CoreLib has generally had more attention paid to it from a performance perspective.\", \" [dotnet/runtime#71325](https://github.com/dotnet/runtime/pull/71325), for example, moves mono's arr\", \"ay and span sorting generic sorting utility class over to the more efficient implementation used by \", \"coreclr.\\n\\nOne of the biggest categories of improvements, however, is in vectorization. This comes in\", \" two pieces. First, Vector<T> and Vector128<T> are now fully accelerated on both x64 and Arm64, than\", \"ks to PRs like [dotnet/runtime#64961,](https://github.com/dotnet/runtime/pull/64961) [dotnet/runtime\", \"#65086,](https://github.com/dotnet/runtime/pull/65086) [dotnet/runtime#65128,](https://github.com/do\", \"tnet/runtime/pull/65128) [dotnet/runtime#66317,](https://github.com/dotnet/runtime/pull/66317) \\n\\n76 \", \"CHAPTER 5 | Mono\\n\\n[dotnet/runtime#66391,](https://github.com/dotnet/runtime/pull/66391) [dotnet/runt\", \"ime#66409,](https://github.com/dotnet/runtime/pull/66409) [dotnet/runtime#66512,](https://github.com\", \"/dotnet/runtime/pull/66512) [dotnet/runtime#66586,](https://github.com/dotnet/runtime/pull/66586) [d\", \"otnet/runtime#66589,](https://github.com/dotnet/runtime/pull/66589) [dotnet/runtime#66597,](https://\", \"github.com/dotnet/runtime/pull/66597) [dotnet/runtime#66476,](https://github.com/dotnet/runtime/pull\", \"/66476) and [dotnet/runtime#67125;](https://github.com/dotnet/runtime/pull/67125) that significant a\", \"mount of work means all that code that gets vectorized using these abstractions will light-up on mon\", \"o and coreclr alike. Second, thanks primarily to [dotnet/runtime#70086,](https://github.com/dotnet/r\", \"untime/pull/70086) mono now knows how to translate Vector128<T> operations to WASM's SIMD instructio\", \"n set, such that code vectorized with Vector128<T> will also be accelerated when running in Blazor w\", \"asm applications and anywhere else WASM might be executed.\\n\\n77 CHAPTER 5 | Mono\\n\\n### <span id=\\\"page-\", \"82-0\\\"></span>Reflection\\n\\nReflection is one of those areas you either love or hate (I find it a bit h\", \"umorous to be writing this section immediately after writing the Native AOT section). It's immensely\", \" powerful, providing the ability to query all of the metadata for code in your process and for arbit\", \"rary assemblies you might encounter, to invoke arbitrary functionality dynamically, and even to emit\", \" dynamically-generated IL at run-time. It's also difficult to handle well in the face of tooling lik\", \"e a linker or a solution like Native AOT that needs to be able to determine at build time exactly wh\", \"at code will be executed, and it's generally quite expensive at run-time; thus it's both something w\", \"e strive to avoid when possible but also invest in reducing the costs of, as it's so popular in so m\", \"any different kinds of applications because it is incredibly useful. As with most releases, it's see\", \"n some nice improvements in .NET 7.\\n\\nOne of the most impacted areas is reflection invoke. Available \", \"via MethodBase.Invoke, this functionality let's you take a MethodBase (e.g. MethodInfo) object that \", \"represents some method for which the caller previously queried, and call it, with arbitrary argument\", \"s that the runtime needs to marshal through to the callee, and with an arbitrary return value that n\", \"eeds to be marshaled back. If you know the signature of the method ahead of time, the best way to op\", \"timize invocation speed is to create a delegate from the MethodBase via CreateDelegate<T> and then u\", \"se that delegate for all future invocations. But in some circumstances, you don't know the signature\", \" at compile time, and thus can't easily rely on delegates with known matching signatures. To address\", \" this, some libraries have taken to using reflection emit to generate code at run-time specific to t\", \"he target method. This is extremely complicated and it's not something we want apps to have to do. I\", \"nstead, in .NET 7 via [dotnet/runtime#66357,](https://github.com/dotnet/runtime/pull/66357) [dotnet/\", \"runtime#69575,](https://github.com/dotnet/runtime/pull/69575) and [dotnet/runtime#74614,](https://gi\", \"thub.com/dotnet/runtime/pull/74614) Invoke will itself use reflection emit (in the form of DynamicMe\", \"thod) to generate a delegate that is customized for invoking the target, and then future invocation \", \"via that MethodInfo will utilize that generated method. This gives developers most of the performanc\", \"e benefits of a custom reflection emit-based implementation but without having the complexity or cha\", \"llenges of such an implementation in their own code base.\\n\\n```\\nprivate MethodInfo _method;\\n[GlobalSe\", \"tup]\\npublic void Setup() => _method = typeof(Program).GetMethod(\\\"MyMethod\\\", \\nBindingFlags.NonPublic \", \"| BindingFlags.Static);\\n[Benchmark]\\npublic void MethodInfoInvoke() => _method.Invoke(null, null);\\npr\", \"ivate static void MyMethod() { }\\n```\\n\\n| Method           | Runtime  | Mean      | Ratio |\\n|---------\", \"---------|----------|-----------|-------|\\n| MethodInfoInvoke | .NET 6.0 | 43.846 ns | 1.00  |\\n| Meth\", \"odInfoInvoke | .NET 7.0 | 8.078 ns  | 0.18  |\\n\\nReflection also involves lots of manipulation of obje\", \"cts that represent types, methods, properties, and so on, and tweaks here and there can add up to a \", \"measurable difference when using these APIs. For example, I've talked in past performance posts abou\", \"t how, potentially counterintuitively, one of the ways we've achieved performance boosts is by porti\", \"ng native code from the runtime back into managed C#. There are a variety of ways in which doing so \", \"can help performance, but one is that there is some overhead associated with calling from managed co\", \"de into the runtime, and eliminating such hops avoids that overhead. This can be seen in full effect\", \" in [dotnet/runtime#71873,](https://github.com/dotnet/runtime/pull/71873) which moves several of the\", \"se \\\"FCalls\\\" related to Type, RuntimeType (the Type-derived class used by the runtime to represent it\", \"s types), and Enum out of native into managed.\\n\\n```\\n[Benchmark]\\npublic Type GetUnderlyingType() => E\", \"num.GetUnderlyingType(typeof(DayOfWeek));\\n```\\n\\n| Method            | Runtime  | Mean      | Ratio |\\n\", \"|-------------------|----------|-----------|-------|\\n| GetUnderlyingType | .NET 6.0 | 27.413 ns | 1.\", \"00  |\\n| GetUnderlyingType | .NET 7.0 | 5.115 ns  | 0.19  |\\n\\nAnother example of this phenomenon comes\", \" in [dotnet/runtime#62866,](https://github.com/dotnet/runtime/pull/62866) which moved much of the un\", \"derlying support for AssemblyName out of native runtime code into managed code in CoreLib. That in t\", \"urn has an impact on anything that uses it, such as when using Activator.CreateInstance overloads th\", \"at take assembly names that need to be parsed.\\n\\n```\\nprivate readonly string _assemblyName = typeof(M\", \"yClass).Assembly.FullName;\\nprivate readonly string _typeName = typeof(MyClass).FullName;\\npublic clas\", \"s MyClass { }\\n[Benchmark]\\npublic object CreateInstance() => Activator.CreateInstance(_assemblyName, \", \"_typeName);\\n```\\n\\n| Method         | Runtime  | Mean     | Ratio |\\n|----------------|----------|-----\", \"-----|-------|\\n| CreateInstance | .NET 6.0 | 3.827 us | 1.00  |\\n| CreateInstance | .NET 7.0 | 2.276 \", \"us | 0.60  |\\n\\nOther changes contributed to Activator.CreateInstance improvements as well. [dotnet/ru\", \"ntime#67148](https://github.com/dotnet/runtime/pull/67148) removed several array and list allocation\", \"s from inside of the RuntimeType.CreateInstanceImpl method that's used by CreateInstance (using Type\", \".EmptyTypes instead of allocating a new Type[0], avoiding unnecessarily turning a builder into an ar\", \"ray, etc.), resulting in less allocation and faster throughput.\\n\\n```\\n[Benchmark]\\npublic void CreateI\", \"nstance() => Activator.CreateInstance(typeof(MyClass), \\nBindingFlags.NonPublic | BindingFlags.Instan\", \"ce, null, Array.Empty<object>(), null);\\ninternal class MyClass\\n{\\n```\\n\\n```\\n internal MyClass() { }\\n}\\n\", \"```\\n\\n| Method         | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|----------------|--\", \"--------|----------|-------|-----------|-------------|\\n| CreateInstance | .NET 6.0 | 167.8 ns | 1.00\", \"  | 320 B     | 1.00        |\\n| CreateInstance | .NET 7.0 | 143.4 ns | 0.85  | 200 B     | 0.62     \", \"   |\\n\\nAnd since we were talking about AssemblyName, other PRs improved it in other ways as well. [do\", \"tnet/runtime#66750,](https://github.com/dotnet/runtime/pull/66750) for example, updated the computat\", \"ion of AssemblyName.FullName to use stack-allocated memory and ArrayPool<char> instead of using a St\", \"ringBuilder:\\n\\n```\\nprivate AssemblyName[] _names = AppDomain.CurrentDomain.GetAssemblies().Select(a =\", \"> new\\nAssemblyName(a.FullName)).ToArray();\\n[Benchmark]\\npublic int Names()\\n{\\n int sum = 0;\\n foreach (\", \"AssemblyName name in _names)\\n {\\n sum += name.FullName.Length;\\n }\\n return sum;\\n}\\n```\\n\\n| Method | Runt\", \"ime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------|----------|----------|-------|--------\", \"---|-------------|\\n| Names  | .NET 6.0 | 3.423 us | 1.00  | 9.14 KB   | 1.00        |\\n| Names  | .NE\", \"T 7.0 | 2.010 us | 0.59  | 2.43 KB   | 0.27        |\\n\\nMore reflection-related operations have also b\", \"een turned into JIT intrinsics, as discussed earlier enabling the JIT to compute answers to various \", \"questions at JIT compile time rather than at run-time. This was done, for example, for Type.IsByRefL\", \"ike in [dotnet/runtime#67852.](https://github.com/dotnet/runtime/pull/67852)\\n\\n```\\n[Benchmark]\\npublic\", \" bool IsByRefLike() => typeof(ReadOnlySpan<char>).IsByRefLike;\\n```\\n\\n| Method      | Runtime  | Mean \", \"     | Ratio | Code Size |\\n|-------------|----------|-----------|-------|-----------|\\n| IsByRefLike \", \"| .NET 6.0 | 2.1322 ns | 1.000 | 31 B      |\\n| IsByRefLike | .NET 7.0 | 0.0000 ns | 0.000 | 6 B     \", \"  |\\n\\nThat the .NET 7 version is so close to zero is called out in a warning by benchmarkdotnet:\\n\\n```\", \"\\n// * Warnings *\\nZeroMeasurement\\n Program.IsByRefLike: Runtime=.NET 7.0, Toolchain=net7.0 -> The met\", \"hod duration is \\nindistinguishable from the empty method duration\\n```\\n\\nand it's so indistinguishable\", \" from an empty method because that's effectively what it is, as we can see from the disassembly:\\n\\n``\", \"`\\n; Program.IsByRefLike()\\n mov eax,1\\n ret\\n; Total bytes of code 6\\n```\\n\\nThere are also improvements t\", \"hat are hard to see but that remove overheads as part of populating reflection's caches, which end u\", \"p reducing the work done typically on startup paths, helping apps to launch faster. [dotnet/runtime#\", \"66825,](https://github.com/dotnet/runtime/pull/66825) [dotnet/runtime#66912,](https://github.com/dot\", \"net/runtime/pull/66912) and [dotnet/runtime#67149](https://github.com/dotnet/runtime/pull/67149) all\", \" fall into this category by removing unnecessary or duplicative array allocations as part of gatheri\", \"ng data on parameters, properties, and events.\\n\\n**CHAPTER** 7\\n\\n### <span id=\\\"page-86-0\\\"></span>Inter\", \"op\\n\\n.NET has long had great support for interop, enabling .NET applications to consume huge amounts \", \"of functionality written in other languages and/or exposed by the underlying operating system. The b\", \"edrock of this support has been \\\"Platform Invoke,\\\" or \\\"P/Invoke,\\\" represented in code by [DllImport(\", \"...)] applied to methods. The DllImportAttribute enables declaring a method that can be called like \", \"any other .NET method but that actually represents some external method that the runtime should call\", \" when this managed method is invoked. The DllImport specifies details about in what library the func\", \"tion lives, what its actual name is in the exports from that library, high-level details about marsh\", \"alling of input arguments and return values, and so on, and the runtime ensures all the right things\", \" happen. This mechanism works on all operating systems. For example, Windows has a method CreatePipe\", \" for creating an anonymous pipe:\\n\\n```\\nBOOL CreatePipe(\\n [out] PHANDLE hReadPipe,\\n [out] PHANDLE hWri\", \"tePipe,\\n [in, optional] LPSECURITY_ATTRIBUTES lpPipeAttributes,\\n [in] DWORD nSize\\n);\\n```\\n\\nIf I want \", \"to call this function from C#, I can declare a [DllImport(...)] counterpart to it which I can then i\", \"nvoke as I can any other managed method:\\n\\n```\\n[DllImport(\\\"kernel32\\\", SetLastError = true)]\\n[return: \", \"MarshalAs(UnmanagedType.Bool)]\\nprivate static unsafe extern bool CreatePipe(\\n out SafeFileHandle hRe\", \"adPipe,\\n out SafeFileHandle hWritePipe,\\n void* lpPipeAttributes,\\n uint nSize);\\n```\\n\\nThere are severa\", \"l interesting things to note here. Several of the arguments are directly blittable with the same rep\", \"resentation on the managed and native side of the equation, e.g. lpPipeAttributes is a pointer and n\", \"Size is a 32-bit integer. But what about the return value? The bool type in C# (System.Boolean) is a\", \" one-byte type, but the BOOL type in the native signature is four bytes; thus code calling this mana\", \"ged method can't just directly invoke the native function somehow, as there needs to be some \\\"marsha\", \"lling\\\" logic that converts the four-byte return BOOL into the one-byte return bool. Simiarly, the na\", \"tive function has two out pointers for hReadPipe and hWritePipe, but the managed signature declares \", \"two SafeFileHandles (a SafeHandle is a .NET type that wraps a pointer and provides a finalizer and D\", \"ispose method for ensuring that pointer is appropriately cleaned up when it's no longer being used).\", \" Some logic needs to take the output handles generated by the native function and wrap them into the\", \"se SafeFileHandles to be output from the managed method. And what about that SetLastError = true? .N\", \"ET has methods like Marshal.GetLastPInvokeError(),\\n\\nand some code somewhere needs to take any error \", \"produced by this method and ensure it's available for consumption via a subsequent GetLastPInvokeErr\", \"or().\\n\\nIf there's no marshalling logic required, such that the managed signature and native signatur\", \"e are for all intents and purposes the same, all arguments blittable, all return values blittable, n\", \"o additional logic required around the invocation of the method, etc., then a [DllImport(...)] ends \", \"up being a simple passthrough with the runtime needing to do very little work to implement it. If, h\", \"owever, the [DllImport(...)] involves any of this marshalling work, the runtime needs to generate a \", \"\\\"stub,\\\" creating a dedicated method that's called when the [DllImport(...)] is called, that handles \", \"fixing up all inputs, that delegates to the actual native function, and that fixes up all of the out\", \"puts. That stub is generated at execution time, with the runtime effectively doing reflection emit, \", \"generating IL dynamically that's then JIT'd.\\n\\nThere are a variety of downsides to this. First, it ta\", \"kes time to generate all that marshalling code, time which can then negatively impact user experienc\", \"e for things like startup. Second, the nature of its implementation inhibits various optimizations, \", \"such as inlining. Third, there are platforms that don't allow for JIT'ing due to the security exposu\", \"re of allowing for dynamically generated code to then be executed (or in the case of Native AOT, whe\", \"re there isn't a JIT at all). And fourth, it's all hidden away making it more challenging for a deve\", \"loper to really understand what's going on.\\n\\nBut what if that logic could all be generated at build \", \"time rather than at run time? The cost of generating the code would be incurred only at build time a\", \"nd not on every execution. The code would effectively just end up being user code that has all of th\", \"e C# compiler's and runtime's optimizations available to it. The code, which then would just be part\", \" of the app, would be able to be ahead-of-time compiled using whatever AOT system is desirable, whet\", \"her it be crossgen or Native AOT or some other system. And the code would be inspectable, viewable b\", \"y users to understand exactly what work is being done on their behalf. Sounds pretty desirable. Soun\", \"ds magical. Sounds like a job for a Roslyn source generator, mentioned earlier.\\n\\n.NET 6 included sev\", \"eral source generators in the .NET SDK, and .NET 7 doubles down on this effort including several mor\", \"e. One of these is the brand new LibraryImport generator, which provides exactly the magical, desira\", \"ble solution we were just discussing.\\n\\nLet's return to our previous CreatePipe example. We'll make t\", \"wo small tweaks. We change the attribute from DllImport to LibraryImport, and we change the extern k\", \"eyword to be partial:\\n\\n```\\n[LibraryImport(\\\"kernel32\\\", SetLastError = true)]\\n[return: MarshalAs(Unman\", \"agedType.Bool)]\\nprivate static unsafe partial bool CreatePipe(\\n out SafeFileHandle hReadPipe,\\n out S\", \"afeFileHandle hWritePipe,\\n void* lpPipeAttributes,\\n uint nSize);\\n```\\n\\nNow if you're following along \", \"at home in Visual Studio, try right-clicking on CreatePipe and selecting Go to Definition. That migh\", \"t seem a little strange. \\\"Go to Definition? Isn't this the definition?\\\" This is a partial method, wh\", \"ich is a way of declaring something that another partial definition fills in, and in this case, a so\", \"urce generator in .NET 7 SDK has noticed this method with the [LibraryImport] attribute and fully ge\", \"nerated the entire marshalling stub code in C# that's built directly into the assembly. While by def\", \"ault that code isn't persisted, Visual Studio still enables you to browse it (and you can\\n\\nopt-in to\", \" having it persisted on disk by adding a\\n\\n<EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFil\", \"es> property into your .csproj). Here's what it currently looks like for that method:\\n\\n```\\n[System.C\", \"odeDom.Compiler.GeneratedCodeAttribute(\\\"Microsoft.Interop.LibraryImportGenerator\\\", \\n\\\"7.0.6.42316\\\")]\\n\", \"[System.Runtime.CompilerServices.SkipLocalsInitAttribute]\\nprivate static unsafe partial bool CreateP\", \"ipe(out\\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle hReadPipe, out\\nglobal::Microsoft.Win32.Sa\", \"feHandles.SafeFileHandle hWritePipe, void* lpPipeAttributes, uint\\nnSize)\\n{\\n int __lastError;\\n bool _\", \"_invokeSucceeded = default;\\n System.Runtime.CompilerServices.Unsafe.SkipInit(out hReadPipe);\\n System\", \".Runtime.CompilerServices.Unsafe.SkipInit(out hWritePipe);\\n System.IntPtr __hReadPipe_native = defau\", \"lt;\\n System.IntPtr __hWritePipe_native = default;\\n bool __retVal;\\n int __retVal_native = default;\\n /\", \"/ Setup - Perform required setup.\\n global::Microsoft.Win32.SafeHandles.SafeFileHandle hReadPipe__new\", \"Handle = new\\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle();\\n global::Microsoft.Win32.SafeHand\", \"les.SafeFileHandle hWritePipe__newHandle = new\\nglobal::Microsoft.Win32.SafeHandles.SafeFileHandle();\", \"\\n try\\n {\\n {\\n System.Runtime.InteropServices.Marshal.SetLastSystemError(0);\\n __retVal_native = __PInv\", \"oke(&__hReadPipe_native, &__hWritePipe_native, \\nlpPipeAttributes, nSize);\\n __lastError = System.Runt\", \"ime.InteropServices.Marshal.GetLastSystemError();\\n }\\n __invokeSucceeded = true;\\n // Unmarshal - Conv\", \"ert native data to managed data.\\n __retVal = __retVal_native != 0;\\n }\\n finally\\n {\\n if (__invokeSucce\", \"eded)\\n {\\n // GuaranteedUnmarshal - Convert native data to managed data even in the case \\nof an excep\", \"tion during the non-cleanup phases.\\n System.Runtime.InteropServices.Marshal.InitHandle(hWritePipe__n\", \"ewHandle, \\n__hWritePipe_native);\\n hWritePipe = hWritePipe__newHandle;\\n System.Runtime.InteropService\", \"s.Marshal.InitHandle(hReadPipe__newHandle, \\n__hReadPipe_native);\\n hReadPipe = hReadPipe__newHandle;\\n\", \" }\\n }\\n System.Runtime.InteropServices.Marshal.SetLastPInvokeError(__lastError);\\n return __retVal;\\n /\", \"/ Local P/Invoke\\n [System.Runtime.InteropServices.DllImportAttribute(\\\"kernel32\\\", EntryPoint =\\n```\\n\\n`\", \"``\\n\\\"CreatePipe\\\", ExactSpelling = true)]\\n static extern unsafe int __PInvoke(System.IntPtr* hReadPipe\", \", System.IntPtr* hWritePipe, \\nvoid* lpPipeAttributes, uint nSize);\\n}\\n```\\n\\nWith this, you can read ex\", \"actly the marshalling work that's being performed. Two SafeHandle instances are being allocated and \", \"then later after the native function completes, the Marshal.InitHandle method is used to store the r\", \"esulting handles into these instances (the allocations happen before the native function call, as pe\", \"rforming them after the native handles have already been produced increases the chances of a leak if\", \" the SafeHandle allocation fails due to an out-of-memory situation). The BOOL to bool conversion hap\", \"pens via a != 0 comparison. And the error information is captured by calling Marshal.GetLastSystemEr\", \"ror() just after the native function call and then Marshal.SetLastPInvokeError(int) just prior to re\", \"turning. The actual native function call is still implemented with a [DllImport(...)], but now that \", \"P/Invoke is blittable and doesn't require any stub to be generated by the runtime, as all that work \", \"has been handled in this C# code.\\n\\nA sheer ton of work went in to enabling this. I touched on some o\", \"f it last year in [Performance](https://devblogs.microsoft.com/dotnet/performance-improvements-in-ne\", \"t-6/)  [Improvements in .NET 6,](https://devblogs.microsoft.com/dotnet/performance-improvements-in-n\", \"et-6/) but a significant amount of additional effort has gone into .NET 7 to polish the design and m\", \"ake the implementation robust, roll it out across all of [dotnet/runtime](https://github.com/dotnet/\", \"runtime) and beyond, and expose the functionality for all C# developers to use:\\n\\n- The LibraryImport\", \" generator started its life as an experiment in [dotnet/runtimelab.](https://github.com/dotnet/runti\", \"melab) When it was ready, [dotnet/runtime#59579](https://github.com/dotnet/runtime/pull/59579) broug\", \"ht 180 commits spanning years of effort into the [dotnet/runtime](https://github.com/dotnet/runtime)\", \" main branch.\\n- In .NET 6, there were almost 3000 [DllImport] uses throughout the core .NET librarie\", \"s. As of my writing this, in .NET 7 there are\\u2026 let me search\\u2026 wait for it\\u2026 7 (I was hoping I could s\", \"ay 0, but there are just a few stragglers, mostly related to COM interop, still remaining). That's n\", \"ot a transformation that happens over night. A multitude of PRs went library by library converting f\", \"rom the old to the new, such as [dotnet/runtime#62295](https://github.com/dotnet/runtime/pull/62295)\", \" and [dotnet/runtime#61640](https://github.com/dotnet/runtime/pull/61640) for System.Private.CoreLib\", \", [dotnet/runtime#61742](https://github.com/dotnet/runtime/pull/61742) and [dotnet/runtime#62309](ht\", \"tps://github.com/dotnet/runtime/pull/62309) for the cryptography libraries, [dotnet/runtime#61765](h\", \"ttps://github.com/dotnet/runtime/pull/61765) for networking, [dotnet/runtime#61996](https://github.c\", \"om/dotnet/runtime/pull/61996) and [dotnet/runtime#61638](https://github.com/dotnet/runtime/pull/6163\", \"8) for most of the other I/O-related libraries, and a long-tail of additional porting in [dotnet/run\", \"time#61975,](https://github.com/dotnet/runtime/pull/61975) [dotnet/runtime#61389,](https://github.co\", \"m/dotnet/runtime/pull/61389) [dotnet/runtime#62353,](https://github.com/dotnet/runtime/pull/62353)  \", \"[dotnet/runtime#61990,](https://github.com/dotnet/runtime/pull/61990) [dotnet/runtime#61949,](https:\", \"//github.com/dotnet/runtime/pull/61949) [dotnet/runtime#61805,](https://github.com/dotnet/runtime/pu\", \"ll/61805) [dotnet/runtime#61741,](https://github.com/dotnet/runtime/pull/61741) [dotnet/runtime#6118\", \"4,](https://github.com/dotnet/runtime/pull/61184) [dotnet/runtime#54290,](https://github.com/dotnet/\", \"runtime/pull/54290) [dotnet/runtime#62365,](https://github.com/dotnet/runtime/pull/62365) [dotnet/ru\", \"ntime#61609,](https://github.com/dotnet/runtime/pull/61609) [dotnet/runtime#61532,](https://github.c\", \"om/dotnet/runtime/pull/61532) and [dotnet/runtime#54236.](https://github.com/dotnet/runtime/pull/542\", \"36)\\n- Such porting is significantly easier when there's a tool to help automate it. [dotnet/runtime#\", \"72819](https://github.com/dotnet/runtime/pull/72819) enables the analyzer and fixer for performing t\", \"hese transformations. :::{custom-style=Figure}\\n\\n![](_page_90_Figure_0.jpeg)\\n\\nThere were plenty of ot\", \"her PRs that went into making the LibraryImport generator a reality for .NET 7. To highlight just a \", \"few more, [dotnet/runtime#63320](https://github.com/dotnet/runtime/pull/63320) introduces a new\\n\\n[Di\", \"sabledRuntimeMarshalling] attribute that can be specified at the assembly level to disable all of th\", \"e runtime's built-in marshalling; at that point, the only marshalling performed as part of interop i\", \"s the marshaling done in the user's code, e.g. that which is generated by [LibraryImport]. Other PRs\", \" like [dotnet/runtime#67635](https://github.com/dotnet/runtime/pull/67635) and [dotnet/runtime#68173\", \"](https://github.com/dotnet/runtime/pull/68173) added new marshaling types that encompass common mar\", \"shaling logic and can be referenced from [LibraryImport(...)] use to customize how marshaling is per\", \"formed (the generator is pattern-based and allows for customization of marshalling by providing type\", \"s that implement the right shape, which these types do in support of the most common marshalling nee\", \"ds). Really usefully, [dotnet/runtime#71989](https://github.com/dotnet/runtime/pull/71989) added sup\", \"port for marshaling {ReadOnly}Span<T>, such that spans can be used directly in [LibraryImport(...)] \", \"method signatures, just as arrays can be (examples in [dotnet/runtime](https://github.com/dotnet/run\", \"time) are available in [dotnet/runtime#73256\\\\)](https://github.com/dotnet/runtime/pull/73256). And [\", \"dotnet/runtime#69043](https://github.com/dotnet/runtime/pull/69043) consolidated logic to be shared \", \"between the runtime's marshalling support in [DllImport] and the generators support with [LibraryImp\", \"ort].\\n\\nOne more category of interop-related changes that I think are worth talking about are to do w\", \"ith SafeHandle cleanup. As a reminder, SafeHandle exists to mitigate various issues around managing \", \"native handles and file descriptors. A native handle or file descriptor is just a memory address or \", \"number that refers to some owned resource and which must be cleaned up / closed when done with it. A\", \" SafeHandle at its core is just a managed object that wraps such a value and provides a Dispose meth\", \"od and a finalizer for closing it. That way, if you neglect to Dispose of the SafeHandle in order to\", \" close the resource, the resource will still be cleaned up when the SafeHandle is garbage collected \", \"and its finalizer eventually run. SafeHandle then also provides some synchronization around that clo\", \"sure, trying to minimize the possibility that the resource is closed while it's still in use. It pro\", \"vides DangerousAddRef and DangerousRelease methods that increment and decrement a ref count, respect\", \"ively, and if Dispose is called while the ref count is above zero, the actual releasing of the handl\", \"e triggered by Dispose is delayed until the ref count goes back to 0. When you pass a SafeHandle int\", \"o a P/Invoke, the generated code for that P/Invoke handles calling DangerousAddRef\\n\\nand DangerousRel\", \"ease (and due to the wonders of LibraryImport I've already extolled, you can easily see that being d\", \"one, such as in the previous generated code example). Our code tries hard to clean up after SafeHand\", \"les deterministically, but it's quite easy to accidentally leave some for finalization.\\n\\n[dotnet/run\", \"time#71854](https://github.com/dotnet/runtime/pull/71991) added some debug-only tracking code to Saf\", \"eHandle to make it easier for developers working in [dotnet/runtime](https://github.com/dotnet/runti\", \"me) (or more specifically, developers using a checked build of the runtime) to find such issues. Whe\", \"n the SafeHandle is constructed, it captures the current stack trace, and if the SafeHandle is final\", \"ized, it dumps that stack trace to the console, making it easy to see where SafeHandles that do end \", \"up getting finalized were created, in order to track them down and ensure they're being disposed of.\", \" As is probably evident from that PR touching over 150 files and almost 1000 lines of code, there we\", \"re quite a few places that benefited from clean up. Now to be fair, many of these are on exceptional\", \" code paths. For example, consider a hypothetical P/Invoke like:\\n\\n```\\n[LibraryImport(\\\"SomeLibrary\\\", \", \"SetLastError = true)]\\ninternal static partial SafeFileHandle CreateFile();\\n```\\n\\nand code that uses i\", \"t like:\\n\\n```\\nSafeFileHandle handle = Interop.CreateFile();\\nif (handle.IsInvalid)\\n{\\n throw new UhOhEx\", \"ception(Marshal.GetLastPInvokeError());\\n}\\nreturn handle;\\n```\\n\\nSeems straightforward enough. Except t\", \"his code will actually leave a SafeHandle for finalization on the failure path. It doesn't matter th\", \"at SafeHandle has an invalid handle in it, it's still a finalizable object. To deal with that, this \", \"code would have been more robustly written as:\\n\\n```\\nSafeFileHandle handle = Interop.CreateFile();\\nif\", \" (handle.IsInvalid)\\n{\\n int lastError = Marshal.GetLastPInvokeError();\\n handle.Dispose(); // or handl\", \"e.SetHandleAsInvalid()\\n throw new UhOhException(lastError);\\n}\\nreturn handle;\\n```\\n\\nThat way, this Saf\", \"eHandle won't create finalization pressure even in the case of failure. Note, as well, that as part \", \"of adding in the Dispose call, I also moved the Marshal.GetLastPInvokeError() up. That's because cal\", \"ling Dispose on a SafeHandle may end up invoking the SafeHandle's ReleaseHandle method, which the de\", \"veloper of the SafeHandle-derived type will have overridden to close the resource, which typically i\", \"nvolves making another P/Invoke. And if that P/Invoke has SetLastError=true on it, it can overwrite \", \"the very error code for which we're about to throw. Hence, we access and store the last error immedi\", \"ately after the interop call once we know it failed, then clean up, and only then throw. All that sa\", \"id, there were a myriad of places in that PR where SafeHandles were being left for finalization even\", \" on the success path. And that PR wasn't alone. [dotnet/runtime#71991,](https://github.com/dotnet/ru\", \"ntime/pull/71991) [dotnet/runtime#71854,](https://github.com/dotnet/runtime/pull/71854) [dotnet/runt\", \"ime#72116,](https://github.com/dotnet/runtime/pull/72116) [dotnet/runtime#72189,](https://github.com\", \"/dotnet/runtime/pull/72189) [dotnet/runtime#72222,](https://github.com/dotnet/runtime/pull/72222) [d\", \"otnet/runtime#72203,](https://github.com/dotnet/runtime/pull/72203) and [dotnet/runtime#72279](https\", \"://github.com/dotnet/runtime/pull/72279) all found and fixed many occurrences of SafeHandles being l\", \"eft for finalization (many thanks to the diagnostics put in place in the earlier mentioned PR).\\n\\nOth\", \"er PRs also accrued to improved interop performance. [dotnet/runtime#70000](https://github.com/dotne\", \"t/runtime/pull/70000) from [@huoyaoyuan](https://github.com/huoyaoyuan) rewrote several delegate-rel\", \"ated \\\"FCalls\\\" from being implemented in native code to instead being managed, resulting in less over\", \"head when invoking these operations that are commonly involved in scenarios involving Marshal.GetDel\", \"egateForFunctionPointer. [dotnet/runtime#68694](https://github.com/dotnet/runtime/pull/68694) also m\", \"oved some trivial functionality from native to managed, as part of relaxing argument validation on t\", \"he use of pinning handles. This in turn measurably reduced the overhead involved with using GCHandle\", \".Alloc for such pinning handles:\\n\\n```\\nprivate byte[] _buffer = new byte[1024];\\n[Benchmark]\\npublic vo\", \"id PinUnpin()\\n{\\n GCHandle.Alloc(_buffer, GCHandleType.Pinned).Free();\\n}\\n```\\n\\n| Method   | Runtime  |\", \" Mean     | Ratio | Code Size |\\n|----------|----------|----------|-------|-----------|\\n| PinUnpin | \", \".NET 6.0 | 37.11 ns | 1.00  | 353 B     |\\n| PinUnpin | .NET 7.0 | 32.17 ns | 0.87  | 232 B     |\\n\\n**\", \"CHAPTER** 8\\n\\n### <span id=\\\"page-93-0\\\"></span>Threading\\n\\nThreading is one of those cross-cutting conc\", \"erns that impacts every application, such that changes in the threading space can have a wide-spread\", \" impact. This release sees two very substantial changes to the ThreadPool itself; [dotnet/runtime#64\", \"834](https://github.com/dotnet/runtime/pull/64834) switches the \\\"IO pool\\\" over to using an entirely \", \"managed implementation (whereas previously the IO pool was still in native code even though the work\", \"er pool had been moved entirely to managed in previous releases), and [dotnet/runtime#71864](https:/\", \"/github.com/dotnet/runtime/pull/71864) similarly switches the timer implementation from one based in\", \" native to one entirely in managed code. Those two changes can impact performance, and the former wa\", \"s demonstrated to on larger hardware, but for the most part that wasn't their primary goal. Instead,\", \" other PRs have been focused on improving throughput.\\n\\nOne in particular is [dotnet/runtime#69386.](\", \"https://github.com/dotnet/runtime/pull/69386) The ThreadPool has a \\\"global queue\\\" that any thread ca\", \"n queue work into, and then each thread in the pool has its own \\\"local queue\\\" (which any thread can \", \"dequeue from but only the owning thread can enqueue into). When a worker needs another piece of work\", \" to process, it first checks its own local queue, then it checks the global queue, and then only if \", \"it couldn't find work in either of those two places, it goes and checks all of the other threads' lo\", \"cal queues to see if it can help lighten their load. As machines scale up to have more and more core\", \"s, and more and more threads, there's more and more contention on these shared queues, and in partic\", \"ular on the global queue. This PR addresses this for such larger machines by introducing additional \", \"global queues once the machine reaches a certain threshold (32 processors today). This helps to part\", \"ition accesses across multiple queues, thereby decreasing contention.\\n\\nAnother is [dotnet/runtime#57\", \"885.](https://github.com/dotnet/runtime/pull/57885) In order to coordinate threads, when work items \", \"were enqueued and dequeued, the pool was issuing requests to its threads to let them know that there\", \" was work available to do. This, however, often resulted in oversubscription, where more threads tha\", \"n necessary would race to try to get work items, especially when the system wasn't at full load. Tha\", \"t in turn would manifest as a throughput regression. This change overhauls how threads are requested\", \", such that only one additional thread is requested at a time, and after that thread has dequeued it\", \"s first work item, it can issue a request for an additional thread if there's work remaining, and th\", \"en that one can issue an additional request, and so on. Here's one of our performance tests in our p\", \"erformance test suite (I've simplified it down to remove a bunch of configuration options from the t\", \"est, but it's still accurately one of those configurations). At first glance you might think, \\\"hey, \", \"this is a performance test about ArrayPool, why is it showing up in a threading discussion?\\\" And, yo\", \"u'd be right, this is a performance test that was written focused on ArrayPool. However, as mentione\", \"d earlier, threading impacts everything, and in this case, that await Task.Yield() in the middle the\", \"re causes the remainder of this method to be queued to the ThreadPool for execution. And because of \", \"how the test is structured, doing \\\"real work\\\" that competes for CPU cycles with thread pool threads \", \"all racing to get their next task, it shows a measurable improvement when moving to .NET 7.\\n\\n```\\npri\", \"vate readonly byte[][] _nestedArrays = new byte[8][];\\nprivate const int Iterations = 100_000;\\nprivat\", \"e static byte IterateAll(byte[] arr)\\n{\\n byte ret = default;\\n foreach (byte item in arr) ret = item;\\n\", \" return ret;\\n}\\n[Benchmark(OperationsPerInvoke = Iterations)]\\npublic async Task MultipleSerial()\\n{\\n f\", \"or (int i = 0; i < Iterations; i++)\\n {\\n for (int j = 0; j < _nestedArrays.Length; j++)\\n {\\n _nestedAr\", \"rays[j] = ArrayPool<byte>.Shared.Rent(4096);\\n _nestedArrays[j].AsSpan().Clear();\\n }\\n await Task.Yiel\", \"d();\\n for (int j = _nestedArrays.Length - 1; j >= 0; j--)\\n {\\n IterateAll(_nestedArrays[j]);\\n ArrayPo\", \"ol<byte>.Shared.Return(_nestedArrays[j]);\\n }\\n }\\n}\\n```\\n\\n| Method         | Runtime  | Mean      | Rat\", \"io |\\n|----------------|----------|-----------|-------|\\n| MultipleSerial | .NET 6.0 | 14.340 us | 1.0\", \"0  |\\n| MultipleSerial | .NET 7.0 | 9.262 us  | 0.65  |\\n\\nThere have been improvements outside of Thre\", \"adPool, as well. One notable change is in the handling of AsyncLocal<T>s, in [dotnet/runtime#68790.]\", \"(https://github.com/dotnet/runtime/pull/68790) AsyncLocal<T> is integrated tightly with ExecutionCon\", \"text; in fact, in .NET Core, ExecutionContext is *entirely* about flowing AsyncLocal<T> instances. A\", \"n ExecutionContext instance maintains a single field, a map data structure, that stores the data for\", \" all AsyncLocal<T> with data present in that context. Each AsyncLocal<T> has an object it uses as a \", \"key, and any gets or sets on that AsyncLocal<T> manifest as getting the current ExecutionContext, lo\", \"oking up that AsyncLocal<T>'s key in the context's dictionary, and then either returning whatever da\", \"ta it finds, or in the case of a setter, creating a new ExecutionContext with an updated dictionary \", \"and publishing that back. This dictionary thus needs to be very efficient for reads and writes, as d\", \"evelopers expect AsyncLocal<T> access to be as fast as possible, often treating it as if it were any\", \" other local. So, to optimize these lookups, the representation of that dictionary changes based on \", \"how many AsyncLocal<T>s are represented in this context. For up to three items, dedicated implementa\", \"tions with fields for each of the three keys and values were used. Above that up to around 16 elemen\", \"ts, an array of key/value pairs was used. And above that, a Dictionary<,> was used. For the most par\", \"t, this has worked well, with the majority of ExecutionContexts being able to represent many flows w\", \"ith one of the first three types. However, it turns out that four active AsyncLocal<T> instances is \", \"really common, especially in ASP.NET where ASP.NET infrastructure itself uses a couple.\\n\\nSo, this PR\", \" took the complexity hit to add a dedicated type for four key/value pairs, in order to optimize from\", \" one to four of them rather than one to three. While this improves throughput a bit, its main intent\", \" was to improve allocation, which is does over .NET 6 by ~20%.\\n\\n```\\nprivate AsyncLocal<int> asyncLoc\", \"al1 = new AsyncLocal<int>();\\nprivate AsyncLocal<int> asyncLocal2 = new AsyncLocal<int>();\\nprivate As\", \"yncLocal<int> asyncLocal3 = new AsyncLocal<int>();\\nprivate AsyncLocal<int> asyncLocal4 = new AsyncLo\", \"cal<int>();\\n[Benchmark(OperationsPerInvoke = 4000)]\\npublic void Update()\\n{\\n for (int i = 0; i < 1000\", \"; i++)\\n {\\n asyncLocal1.Value++;\\n asyncLocal2.Value++;\\n asyncLocal3.Value++;\\n asyncLocal4.Value++;\\n }\", \"\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio | Code Size | Allocated | Alloc Ratio |\\n|--------|---\", \"-------|----------|-------|-----------|-----------|-------------|\\n| Update | .NET 6.0 | 61.96 ns | 1\", \".00  | 1,272 B   | 176 B     | 1.00        |\\n| Update | .NET 7.0 | 61.92 ns | 1.00  | 1,832 B   | 14\", \"4 B     | 0.82        |\\n\\nAnother valuable fix comes for locking in [dotnet/runtime#70165.](https://g\", \"ithub.com/dotnet/runtime/pull/70165) This particular improvement is a bit harder to demonstrate with\", \" benchmarkdotnet, so just try running this program, first on .NET 6 and then on .NET 7:\\n\\n```\\nusing S\", \"ystem.Diagnostics;\\nvar rwl = new ReaderWriterLockSlim();\\nvar tasks = new Task[100];\\nint count = 0;\\nD\", \"ateTime end = DateTime.UtcNow + TimeSpan.FromSeconds(10);\\nwhile (DateTime.UtcNow < end)\\n{\\n for (int \", \"i = 0; i < 100; ++i)\\n {\\n tasks[i] = Task.Run(() =>\\n {\\n var sw = Stopwatch.StartNew();\\n rwl.EnterRead\", \"Lock();\\n rwl.ExitReadLock();\\n sw.Stop();\\n if (sw.ElapsedMilliseconds >= 10)\\n {\\n Console.WriteLine(In\", \"terlocked.Increment(ref count));\\n }\\n });\\n }\\n Task.WaitAll(tasks);\\n}\\n```\\n\\nThis is simply spinning up \", \"100 tasks, each of which enters and exits a read-write lock, waits for them all, and then does the p\", \"rocess over again, for 10 seconds. It also times how long it takes to enter and exit the lock, and w\", \"rites a warning if it had to wait for at least 15ms. When I run this on .NET 6, I get ~100 occurrenc\", \"es of it taking >= 10 ms to enter/exit the lock. On .NET 7, I get 0 occurrences. Why the difference?\", \" The implementation of ReaderWriterLockSlim has its own spin loop implementation, and that spin loop\", \" tries to mix together various things to do as it spins, ranging from calling Thread.SpinWait to Thr\", \"ead.Sleep(0) to Thread.Sleep(1). The issue lies in the Thread.Sleep(1). That's saying \\\"put this thre\", \"ad to sleep for 1 millisecond\\\"; however, the operating system has the ultimate say on such timings, \", \"and on Windows, by default that sleep is going to be closer to 15 milliseconds (on Linux it's a bit \", \"lower but still quite high). Thus, every time there was enough contention on the lock to force it to\", \" call Thread.Sleep(1), we'd incur a delay of at least 15 milliseconds, if not more. The aforemention\", \"ed PR fixed this by eliminating use of Thread.Sleep(1).\\n\\nOne final threading-related change to call \", \"out: [dotnet/runtime#68639.](https://github.com/dotnet/runtime/pull/68639) This one is Windows speci\", \"fic. Windows has the concept of processor groups, each of which can have up to 64 cores in it, and b\", \"y default when a process runs, it's assigned a specific processor group and can only use the cores i\", \"n that group. With .NET 7, the runtime flips its default so that by default it will try to use all p\", \"rocessor groups if possible.\\n\\n# <span id=\\\"page-97-0\\\"></span>Primitive Types and Numerics\\n\\nWe've look\", \"ed at code generation and GC, at threading and vectorization, at interop\\u2026 let's turn our attention t\", \"o some of the fundamental types in the system. Primitives like int and bool and double, core types l\", \"ike Guid and DateTime, they form the backbone on which everything is built, and every release it's e\", \"xciting to see the improvements that find their way into these types.\\n\\nfloat and double got a very n\", \"ice boost in their implementation of parsing (e.g. double.Parse, float.TryParse, etc.). [dotnet/runt\", \"ime#62301](https://github.com/dotnet/runtime/pull/62301) from [@CarlVerret](https://github.com/CarlV\", \"erret) significantly improves double.Parse and float.Parse for parsing UTF16 text into floating-poin\", \"t values. This is particularly neat because it's based on some [relatively recent research](https://\", \"lemire.me/blog/2021/02/22/parsing-floating-point-numbers-really-fast-in-c) from [@lemire](https://gi\", \"thub.com/lemire) and [@CarlVerret](https://github.com/CarlVerret), who used C# with .NET 5 to implem\", \"ent a very fast implementation for parsing floating-point numbers, and that implementation how now f\", \"ound its way into .NET 7!\\n\\n```\\nprivate string[] _valuesToParse;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n\", \" using HttpClient hc = new HttpClient();\\n string text = \\nhc.GetStringAsync(\\\"https://raw.githubuserco\", \"ntent.com/CarlVerret/csFastFloat/1d800237275f759\\nb743b86fcce6680d072c1e834/Benchmark/data/canada.txt\", \"\\\").Result;\\n var lines = new List<string>();\\n foreach (ReadOnlySpan<char> line in text.AsSpan().Enume\", \"rateLines())\\n {\\n ReadOnlySpan<char> trimmed = line.Trim();\\n if (!trimmed.IsEmpty)\\n {\\n lines.Add(trim\", \"med.ToString());\\n }\\n }\\n _valuesToParse = lines.ToArray();\\n}\\n[Benchmark]\\npublic double ParseAll()\\n{\\n \", \"double total = 0;\\n foreach (string s in _valuesToParse)\\n {\\n total += double.Parse(s);\\n```\\n\\n| }<br>re\", \"turn total; |  |\\n|--------------------|--|\\n| }                  |  |\\n\\n| Method   | Runtime  | Mean  \", \"   | Ratio |\\n|----------|----------|----------|-------|\\n| ParseAll | .NET 6.0 | 26.84 ms | 1.00  |\\n|\", \" ParseAll | .NET 7.0 | 12.63 ms | 0.47  |\\n\\nbool.TryParse and bool.TryFormat were also improved. [dot\", \"net/runtime#64782](https://github.com/dotnet/runtime/pull/64782) streamlined these implementations b\", \"y using BinaryPrimitives to perform fewer writes and reads. For example, instead of TryFormat writin\", \"g out \\\"True\\\" by doing:\\n\\n```\\ndestination[0] = 'T';\\ndestination[1] = 'r';\\ndestination[2] = 'u';\\ndestin\", \"ation[3] = 'e';\\n```\\n\\nwhich requires four writes, it can instead implement the same operation in a si\", \"ngle write by doing:\\n\\n```\\nBinaryPrimitives.WriteUInt64LittleEndian(MemoryMarshal.AsBytes(destination\", \"), \\n0x65007500720054); // \\\"True\\\"\\n```\\n\\nThat 0x65007500720054 is the numerical value of the four chara\", \"cters in memory as a single ulong. You can see the impact of these changes with a microbenchmark:\\n\\n`\", \"``\\nprivate bool _value = true;\\nprivate char[] _chars = new char[] { 'T', 'r', 'u', 'e' };\\n[Benchmark\", \"] public bool ParseTrue() => bool.TryParse(_chars, out _);\\n[Benchmark] public bool FormatTrue() => _\", \"value.TryFormat(_chars, out _);\\n```\\n\\n| Method                 | Runtime              | Mean     | Ra\", \"tio |\\n|------------------------|----------------------|----------|-------|\\n| ParseTrue              \", \"| .NET 6.0             | 7.347 ns | 1.00  |\\n| ParseTrue              | .NET 7.0<br>2.327 ns |       \", \"   | 0.32  |\\n|                        |                      |          |       |\\n| FormatTrue      \", \"       | .NET 6.0             | 3.030 ns | 1.00  |\\n| FormatTrue<br>.NET 7.0 |                      |\", \" 1.997 ns | 0.66  |\\n\\nEnum gets several performance boosts, as well. For example, when performing an \", \"operation like Enum.IsDefined, Enum.GetName, or Enum.ToString, the implementation consults a cache o\", \"f all of the values defined on the enum. This cache includes the string name and the value for every\", \" defined enumeration in the Enum. It's also sorted by value in an array, so when one of these operat\", \"ions is performed, the code uses Array.BinarySearch to find the index of the relevant entry. The iss\", \"ue with that is one of overheads. When it comes to algorithmic complexity, a binary search is faster\", \" than a linear search; after all, a binary search is O(log N) whereas a linear search is O(N). Howev\", \"er, there's also less overhead for every step of the algorithm in a linear search, and so for smalle\", \"r values of N, it can be much faster to simply do the simple thing. That's what [dotnet/runtime#5797\", \"3](https://github.com/dotnet/runtime/pull/57973) does for enums. For enums with less than or equal t\", \"o 32 defined values, the implementation now just does a linear search via the internal SpanHelpers.I\", \"ndexOf (the worker routine behind IndexOf on spans, strings,\\n\\nand arrays), and for enums with more t\", \"han that, it does a SpanHelpers.BinarySearch (which is the implementation for Array.BinarySearch).\\n\\n\", \"```\\nprivate DayOfWeek[] _days = Enum.GetValues<DayOfWeek>();\\n[Benchmark]\\npublic bool AllDefined()\\n{\\n\", \" foreach (DayOfWeek day in _days)\\n {\\n if (!Enum.IsDefined(day))\\n {\\n return false;\\n }\\n }\\n return true\", \";\\n}\\n```\\n\\n| Method     | Runtime  |           | Ratio |\\n|------------|----------|-----------|-------|\", \"\\n| AllDefined | .NET 6.0 | 159.28 ns | 1.00  |\\n| AllDefined | .NET 7.0 | 94.86 ns  | 0.60  |\\n\\nEnums \", \"also get a boost in conjunction with Nullable<T> and EqualityComparer<T>.Default. EqualityComparer<T\", \">.Default caches a singleton instance of an EqualityComparer<T> instance returned from all accesses \", \"to Default. That singleton is initialized based on the T in question, with the implementation choosi\", \"ng from a multitude of different internal implementations, for example a ByteArrayComparer specializ\", \"ed for bytes, a GenericEqualityComparer<T> for Ts that implement IComparable<T>, and so on. The catc\", \"h-all, for arbitrary types, is an ObjectEqualityComparer<T>. As it happens, nullable enums would end\", \" up hitting this catch-all path, which means that every Equals call would box the arguments. [dotnet\", \"/runtime#68077](https://github.com/dotnet/runtime/pull/68077) fixes this by ensuring nullable enums \", \"get mapped to (an existing) specialized comparer for Nullable<T> and simple tweaks its definition to\", \" ensure it can play nicely with enums. The results highlight just how much unnecessary overhead ther\", \"e was previously.\\n\\n```\\nprivate DayOfWeek?[] _enums = Enum.GetValues<DayOfWeek>().Select(e => \\n(DayOf\", \"Week?)e).ToArray();\\n[Benchmark]\\n[Arguments(DayOfWeek.Saturday)]\\npublic int FindEnum(DayOfWeek value)\", \" => IndexOf(_enums, value);\\nprivate static int IndexOf<T>(T[] values, T value)\\n{\\n for (int i = 0; i \", \"< values.Length; i++)\\n {\\n if (EqualityComparer<T>.Default.Equals(values[i], value))\\n {\\n return i;\\n }\", \"\\n }\\n return -1;\\n}\\n```\\n\\n| Method   | Runtime  | Mean       | Ratio |\\n|----------|----------|---------\", \"---|-------|\\n| FindEnum | .NET 6.0 | 421.608 ns | 1.00  |\\n| FindEnum | .NET 7.0 | 5.466 ns   | 0.01 \", \" |\\n\\nNot to be left out, Guid's equality operations also get faster, thanks to [dotnet/runtime#66889]\", \"(https://github.com/dotnet/runtime/pull/66889) from [@madelson](https://github.com/madelson). The pr\", \"evious implementation of Guid split the data into four 32-bit values and performed 4 int comparisons\", \". With this change, if the current hardware has 128-bit SIMD support, the implementation loads the d\", \"ata from the two guids as two vectors and simply does a single comparison.\\n\\n```\\nprivate Guid _guid1 \", \"= Guid.Parse(\\\"0aa2511d-251a-4764-b374-4b5e259b6d9a\\\");\\nprivate Guid _guid2 = Guid.Parse(\\\"0aa2511d-251\", \"a-4764-b374-4b5e259b6d9a\\\");\\n[Benchmark]\\npublic bool GuidEquals() => _guid1 == _guid2;\\n```\\n\\n| Method \", \"    | Runtime  | Mean     | Ratio | Code Size |\\n|------------|----------|----------|-------|--------\", \"---|\\n| GuidEquals | .NET 6.0 | 2.119 ns | 1.00  | 90 B      |\\n| GuidEquals | .NET 7.0 | 1.354 ns | 0\", \".64  | 78 B      |\\n\\nDateTime equality is also improved. [dotnet/runtime#59857](https://github.com/do\", \"tnet/runtime/pull/59857) shaves some overhead off of DateTime.Equals. DateTime is implemented with a\", \" single ulong \\\\_dateData field, where the majority of the bits store a ticks offset from 1/1/0001 12\", \":00am and where each tick is 100 nanoseconds, and where the top two bits describe the DateTimeKind. \", \"Thus the public Ticks property returns the value of \\\\_dateData but with the top two bits masked out,\", \" e.g. \\\\_dateData & 0x3FFFFFFFFFFFFFFF. The equality operators were all then just comparing one DateT\", \"ime's Ticks against the others, such that we effectively get (dt1.\\\\_dateData & 0x3FFFFFFFFFFFFFFF) =\", \"= (dt2.\\\\_dateData & 0x3FFFFFFFFFFFFFFF). However, as a micro-optimization that can instead be expres\", \"sed more efficiently as ((dt1.\\\\_dateData ^ dt2.\\\\_dateData) << 2) == 0. It's difficult to measure the\", \" difference in such tiny operations, but you can see it simply from the number of instructions invol\", \"ved, where on .NET 6 this produces:\\n\\n```\\n; Program.DateTimeEquals()\\n mov rax,[rcx+8]\\n mov rdx,[rcx+1\", \"0]\\n mov rcx,0FFFFFFFFFFFF\\n and rax,rcx\\n and rdx,rcx\\n cmp rax,rdx\\n sete al\\n movzx eax,al\\n ret\\n; Total\", \" bytes of code 34\\n```\\n\\nand on .NET 7 this produces:\\n\\n```\\n; Program.DateTimeEquals()\\n mov rax,[rcx+8]\", \"\\n mov rdx,[rcx+10]\\n xor rax,rdx\\n shl rax,2\\n```\\n\\n```\\n sete al\\n movzx eax,al\\n ret\\n; Total bytes of cod\", \"e 22\\n```\\n\\nso instead of a mov, and, and, and cmp, we get just an xor and a shl.\\n\\nOther operations on\", \" DateTime also become more efficient, thanks to [dotnet/runtime#72712](https://github.com/dotnet/run\", \"time/pull/72712) from [@SergeiPavlov](https://github.com/SergeiPavlov) and [dotnet/runtime#73277](ht\", \"tps://github.com/dotnet/runtime/pull/73277) from [@SergeiPavlov](https://github.com/SergeiPavlov). I\", \"n another case of .NET benefiting from recent advancements in research, these PRs implemented the al\", \"gorithm from Neri and Schneider's [\\\"Euclidean Affine Functions and Applications to Calendar Algorith\", \"ms\\\"](https://arxiv.org/pdf/2102.06959.pdf) in order to improve DateTime.Day, DateTime.DayOfYear, Dat\", \"eTime.Month, and DateTime.Year, as well as the internal helper DateTime.GetDate() that's used by a b\", \"unch of other methods like DateTime.AddMonths, Utf8Formatter.TryFormat(DateTime, ...), DateTime.TryF\", \"ormat, and DateTime.ToString.\\n\\n```\\nprivate DateTime _dt = DateTime.UtcNow;\\nprivate char[] _dest = ne\", \"w char[100];\\n[Benchmark] public int Day() => _dt.Day;\\n[Benchmark] public int Month() => _dt.Month;\\n[\", \"Benchmark] public int Year() => _dt.Year;\\n[Benchmark] public bool TryFormat() => _dt.TryFormat(_dest\", \", out _, \\\"r\\\");\\n```\\n\\n| Method    | Runtime<br>Mean       |            | Ratio |\\n|-----------|--------\", \"---------------|------------|-------|\\n| Day       | .NET 6.0<br>5.2080 ns |            | 1.00  |\\n| D\", \"ay       | .NET 7.0              | 2.0549 ns  | 0.39  |\\n|           |                       |       \", \"     |       |\\n| Month     | .NET 6.0<br>4.1186 ns |            | 1.00  |\\n| Month     | .NET 7.0<br>\", \"2.0945 ns |            | 0.51  |\\n|           |                       |            |       |\\n| Year  \", \"    | .NET 6.0              | 3.1422 ns  | 1.00  |\\n| Year      | .NET 7.0              | 0.8200 ns  \", \"| 0.26  |\\n|           |                       |            |       |\\n| TryFormat | .NET 6.0         \", \"     |            | 1.00  |\\n| TryFormat | .NET 7.0              | 25.9848 ns | 0.94  |\\n\\nSo, we've to\", \"uched on improvements to a few types, but the pi\\u00e8ce de r\\u00e9sistance around primitive types in this rel\", \"ease is \\\"generic math,\\\" which impacts almost every primitive type in .NET. There are significant imp\", \"rovements here, some which have been in the making for literally over a decade.\\n\\nThere's an excellen\", \"t blog post from June dedicated just to [generic math](https://devblogs.microsoft.com/dotnet/dotnet-\", \"7-generic-math), so I won't go into much depth here. At a high level, however, there are now over 30\", \" new interfaces that utilize the new C# 11 static abstract interface methods functionality, exposing\", \" wide-ranging operations from exponentiation functions to trigonometric functions to standard numeri\", \"cal operators, all available via generics, such that you can write one implementation that operates \", \"over these interfaces generically and have your\\n\\ncode applied to any types that implement the interf\", \"aces\\u2026 which all of the numerical types in .NET 7 do (including not just the primitives but also, for\", \" example, BigInteger and Complex). A preview version of this feature, including necessary runtime su\", \"pport, language syntax, C# compiler support, generic interfaces, and interface implementations all s\", \"hipped in .NET 6 and C# 10, but it wasn't supported for production use, and you had to download an e\", \"xperimental reference assembly in order to get access. With [dotnet/runtime#65731,](https://github.c\", \"om/dotnet/runtime/pull/65731) all of this support moved into .NET 7 as supported functionality. [dot\", \"net/runtime#66748,](https://github.com/dotnet/runtime/pull/66748) [dotnet/runtime#67453,](https://gi\", \"thub.com/dotnet/runtime/pull/67453) [dotnet/runtime#69391,](https://github.com/dotnet/runtime/pull/6\", \"9391) [dotnet/runtime#69582,](https://github.com/dotnet/runtime/pull/69582) [dotnet/runtime#69756,](\", \"https://github.com/dotnet/runtime/pull/69756) and [dotnet/runtime#71800](https://github.com/dotnet/r\", \"untime/pull/71800) all updated the design and implementation based on feedback from usage in .NET 6 \", \"and .NET 7 previews as well as a proper API review with our API review team (a process every new API\", \" in .NET goes through before it's shipped publicly). [dotnet/runtime#67714](https://github.com/dotne\", \"t/runtime/pull/67714) added support for user-defined checked operators, a new C# 11 feature that ena\", \"bles both unchecked and checked variations of operators to be exposed, with the compiler picking the\", \" right one based on the checked context. [dotnet/runtime#68096](https://github.com/dotnet/runtime/pu\", \"ll/68096) also added support for the new C# 11 unsigned right shift operator (>>>). And [dotnet/runt\", \"ime#69651,](https://github.com/dotnet/runtime/pull/69651)  [dotnet/runtime#67939,](https://github.co\", \"m/dotnet/runtime/pull/67939) [dotnet/runtime#73274,](https://github.com/dotnet/runtime/pull/73274) [\", \"dotnet/runtime#71033,](https://github.com/dotnet/runtime/pull/71033) [dotnet/runtime#71010,](https:/\", \"/github.com/dotnet/runtime/pull/71010) [dotnet/runtime#68251,](https://github.com/dotnet/runtime/pul\", \"l/68251) [dotnet/runtime#68217,](https://github.com/dotnet/runtime/pull/68217) and [dotnet/runtime#6\", \"8094](https://github.com/dotnet/runtime/pull/68094) all added large swaths of new public surface are\", \"a for various operations, all with highly-efficient managed implementations, in many cases based on \", \"the open source [AMD Math Library.](https://github.com/amd/aocl-libm-ose)\\n\\nWhile this support is all\", \" primarily intended for external consumers, the core libraries do consume some of it internally. You\", \" can see how these APIs clean up consuming code even while maintaining performance in PRs like [dotn\", \"et/runtime#68226](https://github.com/dotnet/runtime/pull/68226) and [dotnet/runtime#68183,](https://\", \"github.com/dotnet/runtime/pull/68183) which use the interfaces to deduplicate a bunch of LINQ code i\", \"n Enumerable.Sum/Average/Min/Max. There are multiple overloads of these methods for int, long, float\", \", double, and decimal. The GitHub summary of the diffs tells the story on how much code was able to \", \"be deleted:\\n\\ninterface contains these methods:\\n\\nAnother simple example comes from the new System.For\", \"mats.Tar library in .NET 7, which as the name suggests is used for reading and writing archives in a\", \"ny of multiple [tar file formats.](https://en.wikipedia.org/wiki/Tar_(computing)#File_format) The ta\", \"r file formats include integer values in octal representation, so the TarReader class needs to parse\", \" octal values. Some of these values are 32-bit integers, and some are 64-bit integers. Rather than h\", \"ave two separate ParseOctalAsUInt32 and ParseOctalAsUInt64 methods, [dotnet/runtime#74281\\\\]](https:/\", \"/github.com/dotnet/runtime/pull/74281) consolidated the methods into a single ParseOctal<T> with the\", \" constraint where T : struct, INumber<T>. The implementation is then entirely in terms of T and can \", \"be used for either of these types (plus any other types meeting the constraints, should that ever be\", \" needed). What's particularly interesting about this example is the ParseOctal<T> method includes us\", \"e of checked, e.g. value = checked((value \\\\* octalFactor) + T.CreateTruncating(digit));. This is onl\", \"y possible because C# 11 includes the aforementioned support for [user-defined checked operators,](h\", \"ttps://github.com/dotnet/csharplang/blob/main/proposals/checked-user-defined-operators.md) enabling \", \"the generic\\n\\nmath interfaces to support both the normal and checked varieties, e.g. the IMultiplyOpe\", \"rators<,,>\\n\\n```\\nstatic abstract TResult operator *(TSelf left, TOther right);\\nstatic virtual TResult\", \" operator checked *(TSelf left, TOther right) => left * right;\\n```\\n\\nand the compiler will pick the a\", \"ppropriate one based on the context.\\n\\nIn addition to all the existing types that get these interface\", \"s, there are also new types. [dotnet/runtime#69204](https://github.com/dotnet/runtime/pull/69204) ad\", \"ds the new Int128 and UInt128 types. As these types implement all of the relevant generic math inter\", \"faces, they come complete with a huge number of methods, over 100 each, all of which are implemented\", \" efficiently in managed code. In the future, the aim is that some set of these will be optimized fur\", \"ther by the JIT and to take advantage of hardware acceleration.\\n\\nSeveral PRs moved native implementa\", \"tions of these kinds of math operations to managed code. [dotnet/runtime#63881](https://github.com/d\", \"otnet/runtime/pull/63881) from [@am11](https://github.com/am11) did so for Math.Abs and Math.AbsF (a\", \"bsolute value), and [dotnet/runtime#56236](https://github.com/dotnet/runtime/pull/56236) from\\n\\n[@ale\", \"xcovington](https://github.com/alexcovington) did so for Math.ILogB and MathF.ILogB (base 2 integer \", \"logarithm). The latter's implementation is based on the MUSL libc implementation of the same algorit\", \"hm, and in addition to improving performance (in part by avoiding the transition between managed and\", \" native code, in part by the actual algorithm employed), it also enabled deleting two distinct imple\", \"mentations from native code, one from the coreclr side and one from the mono side, which is always a\", \" nice win from a maintainability perspective.\\n\\n```\\n[Benchmark]\\n[Arguments(12345.6789)]\\npublic int IL\", \"ogB(double arg) => Math.ILogB(arg);\\n```\\n\\n| Method | Runtime  | arg        | Mean     | Ratio |\\n|----\", \"----|----------|------------|----------|-------|\\n| ILogB  | .NET 6.0 | 12345.6789 | 4.056 ns | 1.00 \", \" |\\n| ILogB  | .NET 7.0 | 12345.6789 | 1.059 ns | 0.26  |\\n\\nOther math operations were also improved i\", \"n various ways. Math{F}.Truncate was improved in [dotnet/runtime#65014](https://github.com/dotnet/ru\", \"ntime/pull/65014) from [@MichalPetryka](https://github.com/MichalPetryka) by making it into a JIT in\", \"trinsic, such that on Arm64 the JIT could directly emit a frintz instruction. [dotnet/runtime#65584]\", \"(https://github.com/dotnet/runtime/pull/65584) did the same for Max and Min so that the Arm-specific\", \" fmax and fmin instructions could be used. And several BitConverter APIs were also turned into intri\", \"nsics in [dotnet/runtime#71567](https://github.com/dotnet/runtime/pull/71567) in order to enable bet\", \"ter code generation in some generic math scenarios.\\n\\n[dotnet/runtime#55121](https://github.com/dotne\", \"t/runtime/pull/55121) from [@key-moon](https://github.com/key-moon) also improves parsing, but for B\", \"igInteger, and more specifically for really, really big BigIntegers. The algorithm previously employ\", \"ed for parsing a string into a BigInteger was O(N^2) where N is the number of digits, but while a la\", \"rger algorithmic complexity than we'd normally like, it has a low constant overhead and so is still \", \"reasonable for reasonably-sized values. In contrast, an alternative algorithm is available that runs\", \" in O(N \\\\* (log N)^2) time, but with a much higher constant factor involved. That makes is so that i\", \"t's really only worth switching for really big numbers. Which is what this PR does. It implements th\", \"e alternative algorithm and switches over to it when the input is at least 20,000 digits (so, yes, b\", \"ig). But for such large numbers, it makes a significant difference.\\n\\n```\\nprivate string _input = str\", \"ing.Concat(Enumerable.Repeat(\\\"1234567890\\\", 100_000)); // \\\"One \\nmiiilliiiion digits\\\"\\n[Benchmark]\\npubl\", \"ic BigInteger Parse() => BigInteger.Parse(_input);\\n```\\n\\n| Method | Runtime  | Mean    | Ratio |\\n|---\", \"-----|----------|---------|-------|\\n| Parse  | .NET 6.0 | 3.474 s | 1.00  |\\n| Parse  | .NET 7.0 | 1.\", \"672 s | 0.48  |\\n\\nAlso related to BigInteger (and not just for really big ones), [dotnet/runtime#3556\", \"5](https://github.com/dotnet/runtime/pull/35565) from [@sakno](https://github.com/sakno) overhauled \", \"much of the internals of BigInteger to be based on spans rather than arrays. That in turn enabled a \", \"fair amount of use of stack allocation and slicing to avoid allocation overheads, while also improvi\", \"ng reliability and safety by moving some code away from unsafe pointers to safe spans. The primary p\", \"erformance impact is visible in allocation numbers, and in particular for operations related to divi\", \"sion.\\n\\n```\\nprivate BigInteger _bi1 = BigInteger.Parse(string.Concat(Enumerable.Repeat(\\\"9876543210\\\", \", \"\\n100)));\\nprivate BigInteger _bi2 = BigInteger.Parse(string.Concat(Enumerable.Repeat(\\\"1234567890\\\", \\n1\", \"00)));\\nprivate BigInteger _bi3 = BigInteger.Parse(string.Concat(Enumerable.Repeat(\\\"12345\\\", 10)));\\n[B\", \"enchmark]\\npublic BigInteger ModPow() => BigInteger.ModPow(_bi1, _bi2, _bi3);\\n```\\n\\n| Method | Runtime\", \"  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------|----------|----------|-------|-----------\", \"|-------------|\\n| ModPow | .NET 6.0 | 1.527 ms | 1.00  | 706 B     | 1.00        |\\n| ModPow | .NET 7\", \".0 | 1.589 ms | 1.04  | 50 B      | 0.07        |\\n\\n### <span id=\\\"page-105-0\\\"></span>Arrays, Strings,\", \" and Spans\\n\\nWhile there are many forms of computation that can consume resources in applications, so\", \"me of the most common include processing of data stored in arrays, strings, and now spans. Thus you \", \"see a focus in every .NET release on removing as much overhead as possible from such scenarios, whil\", \"e also finding ways to further optimize the concrete operations developers are commonly performing.\\n\", \"\\nLet's start with some new APIs that can help make writing more efficient code easier. When examinin\", \"g string parsing/processing code, it's very common to see characters examined for their inclusion in\", \" various sets. For example, you might see a loop looking for characters that are ASCII digits:\\n\\n```\\n\", \"while (i < str.Length)\\n{\\n if (str[i] >= '0' && str[i] <= '9')\\n {\\n i++;\\n }\\n}\\n```\\n\\nor that are ASCII l\", \"etters:\\n\\n```\\nwhile (i < str.Length)\\n{\\n if ((str[i] >= 'a' && str[i] <= 'z') || (str[i] >= 'A' && str\", \"[i] <= 'Z'))\\n {\\n i++;\\n }\\n}\\n```\\n\\nor other such groups. Interestingly, there's wide-spread variation i\", \"n how such checks are coded, often depending on how much effort a developer put in to optimizing the\", \"m, or in some cases likely not even recognizing that some amount of performance was being left on th\", \"e table. For example, that same ASCII letter check could instead be written as:\\n\\n```\\nwhile (i < str.\", \"Length)\\n{\\n if ((uint)((c | 0x20) - 'a') <= 'z' - 'a')\\n {\\n i++;\\n }\\n}\\n```\\n\\nwhich while more \\\"intense\\\" \", \"is also much more concise and more efficient. It's taking advantage of a few tricks. First, rather t\", \"han having two comparisons to determine whether the character is greater than or equal to the lower \", \"bound and less than or equal to the upper bound, it's doing a single comparison based on the distanc\", \"e between the character and the lower bound ((uint)(c - 'a')). If 'c' is beyond 'z', then 'c' - 'a' \", \"will be larger than 25, and the comparison will fail. If 'c' is earlier\\n\\nthan 'a', then 'c' - 'a' wi\", \"ll be negative, and casting it to uint will then cause it to wrap around to a massive number, also l\", \"arger than 25, again causing the comparison to fail. Thus, we're able to pay a single additional sub\", \"traction to avoid an entire additional comparison and branch, which is *almost* always a good deal. \", \"The second trick is that | 0x20. The ASCII table has some well-thought-out relationships, including \", \"that upper-case 'A' and lower-case 'a' differ by only a single bit ('A' is 0b1000001 and 'a' is 0b11\", \"00001). To go from any lowercase ASCII letter to its uppercase ASCII equivalent, we thus need only t\", \"o & ~0x20 (to turn off that bit), and to go in the opposite direction from any uppercase ASCII lette\", \"r to its lowercase ASCII equivalent, we need only to | 0x20 (to turn on that bit). We can take advan\", \"tage of this in our range check, then, by normalizing our char c to be lowercase, such that for the \", \"low cost of a bit twiddle, we can achieve both the lowercase and uppercase range checks. Of course, \", \"those tricks aren't something we want every developer to have to know and write on each use. Instead\", \", .NET 7 exposes a bunch of new helpers on System.Char to encapsulate these common checks, done in a\", \"n efficient manner. char already had methods like IsDigit and IsLetter, which provided the more comp\", \"rehensive Unicode meaning of those monikers (e.g. there are ~320 Unicode characters categorized as \\\"\", \"digits\\\"). Now in .NET 7, there are also these helpers:\\n\\n- IsAsciiDigit\\n- IsAsciiHexDigit\\n- IsAsciiHe\", \"xDigitLower\\n- IsAsciiHexDigitUpper\\n- IsAsciiLetter\\n- IsAsciiLetterLower\\n- IsAsciiLetterUpper\\n- IsAsc\", \"iiLetterOrDigit\\n\\nThese methods were added by [dotnet/runtime#69318,](https://github.com/dotnet/runti\", \"me/pull/69318) which also employed them in dozens of locations where such checks were being performe\", \"d across [dotnet/runtime](https://github.com/dotnet/runtime) (many of them using lessefficient appro\", \"aches).\\n\\nAnother new API focused on encapsulating a common pattern is the new MemoryExtensions.Commo\", \"nPrefixLength method, introduced by [dotnet/runtime#67929.](https://github.com/dotnet/runtime/pull/6\", \"7929) This accepts either two ReadOnlySpan<T> instances or a Span<T> and a ReadOnlySpan<T>, and an o\", \"ptional IEqualityComparer<T>, and returns the number of elements that are the same at the beginning \", \"of each input span. This is useful when you want to know the first place that two inputs differ. [do\", \"tnet/runtime#68210](https://github.com/dotnet/runtime/pull/68210) from [@gfoidl](https://github.com/\", \"gfoidl) then utilized the new Vector128 functionality to provide a basic vectorization of the implem\", \"entation. As it's comparing two sequences and looking for the first place they differ, this implemen\", \"tation uses a neat trick, which is to have a single method implemented to compare the sequences as b\", \"ytes. If the T being compared is bitwiseequatable and no custom equality comparer is supplied, then \", \"it reinterpret-casts the refs from the spans as byte refs, and uses the single shared implementation\", \".\\n\\nYet another new set of APIs are the IndexOfAnyExcept and LastIndexOfAnyExcept methods, introduced\", \" by [dotnet/runtime#67941](https://github.com/dotnet/runtime/pull/67941) and used in a variety of ad\", \"ditional call sites by [dotnet/runtime#71146](https://github.com/dotnet/runtime/pull/71146) and [dot\", \"net/runtime#71278.](https://github.com/dotnet/runtime/pull/71278) While somewhat of a mouthful, thes\", \"e methods are quite handy. They do what their name suggests: whereas IndexOf(T value) searches for t\", \"he first occurrence of value in the input, and whereas IndexOfAny(T value0, T value1, ...) searches \", \"for the first occurrence of any of value0, value1, etc. in the input, IndexOfAnyExcept(T value) sear\", \"ches for the first occurrence of something that's *not* equal to value, and similarly IndexOfAnyExce\", \"pt(T value0, T value1, ...) searches for the first occurrence of something that's *not* equal to val\", \"ue0, value1, etc. For example, let's say you wanted to know whether an array of integers was entirel\", \"y 0. You can now write that as:\\n\\n```\\nbool allZero = array.AsSpan().IndexOfAnyExcept(0) < 0;\\n```\\n\\n[do\", \"tnet/runtime#73488](https://github.com/dotnet/runtime/pull/73488) vectorizes this overload, as well.\", \"\\n\\n```\\nprivate byte[] _zeros = new byte[1024];\\n[Benchmark(Baseline = true)]\\npublic bool OpenCoded()\\n{\", \"\\n foreach (byte b in _zeros)\\n {\\n if (b != 0)\\n {\\n return false;\\n }\\n }\\n return true;\\n}\\n[Benchmark]\\npub\", \"lic bool IndexOfAnyExcept() => _zeros.AsSpan().IndexOfAnyExcept((byte)0) < 0;\\n```\\n\\n| Method         \", \"  | Mean      | Ratio |\\n|------------------|-----------|-------|\\n| OpenCoded        | 370.47 ns | 1.\", \"00  |\\n| IndexOfAnyExcept | 23.84 ns  | 0.06  |\\n\\nOf course, while new \\\"index of\\\" variations are helpf\", \"ul, we already have a bunch of such methods, and it's important that they are as efficient as possib\", \"le. These core IndexOf{Any} methods are used in huge numbers of places, many of which are performanc\", \"e-sensitive, and so every release they get additional tender-loving care. While PRs like [dotnet/run\", \"time#67811](https://github.com/dotnet/runtime/pull/67811) got gains by paying very close attention t\", \"o the assembly code being generated (in this case, tweaking some of the checks used on Arm64 in Inde\", \"xOf and IndexOfAny to achieve better utilization), the biggest improvements here come in places wher\", \"e either vectorization was added and none was previously employed, or where the vectorization scheme\", \" was overhauled for significant gain. Let's start with [dotnet/runtime#63285,](https://github.com/do\", \"tnet/runtime/pull/63285)  which yields huge improvements for many uses of IndexOf and LastIndexOf fo\", \"r \\\"substrings\\\" of bytes and chars. Previously, given a call like str.IndexOf(\\\"hello\\\"), the implement\", \"ation would essentially do the equivalent of repeatedly searching for the 'h', and when an 'h' was f\", \"ound, then performing a SequenceEqual to match the remainder. As you can imagine, however, it's very\", \" easy to run into cases where the first character being searched for is very common, such that you f\", \"requently have to break out of the vectorized loop in order to do the full string comparison. Instea\", \"d, the PR implements an algorithm based on [SIMD-friendly algorithms for substring searching.](http:\", \"//0x80.pl/articles/simd-strfind.html#algorithm-1-generic-simd) Rather than just searching for the fi\", \"rst character, it can instead vectorize a search for both the first and last character at appropriat\", \"e distances from each other. In our \\\"hello\\\" example, in any given input, it's much more likely to fi\", \"nd an\\n\\n'h' than it is to find an 'h' followed four characters later by an 'o', and thus this impleme\", \"ntation is able to stay within the vectorized loop a lot longer, garnering many fewer false positive\", \"s that force it down the SequenceEqual route. The implementation also handles cases where the two ch\", \"aracters selected are equal, in which case it'll quickly look for another character that's not equal\", \" in order to maximize the efficiency of the search. We can see the impact of all of this with a coup\", \"le of examples:\\n\\n```\\nprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"ht\", \"tps://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\n[Arguments(\\\"Sherlock\\\")]\\n[Argumen\", \"ts(\\\"elementary\\\")]\\npublic int Count(string needle)\\n{\\n ReadOnlySpan<char> haystack = s_haystack;\\n int \", \"count = 0, pos;\\n while ((pos = haystack.IndexOf(needle)) >= 0)\\n {\\n haystack = haystack.Slice(pos + n\", \"eedle.Length);\\n count++;\\n }\\n return count;\\n}\\n```\\n\\nThis is pulling down the text to \\\"The Adventures o\", \"f Sherlock Holmes\\\" from Project Gutenberg and then benchmarking using IndexOf to count the occurrenc\", \"es of \\\"Sherlock\\\" and \\\"elementary\\\" in the text. On my machine, I get results like this:\\n\\n| Method | R\", \"untime  | needle     | Mean        | Ratio |\\n|--------|----------|------------|-------------|-------\", \"|\\n| Count  | .NET 6.0 | Sherlock   | 43.68 us    | 1.00  |\\n| Count  | .NET 7.0 | Sherlock   | 48.33 \", \"us    | 1.11  |\\n|        |          |            |             |       |\\n| Count  | .NET 6.0 | eleme\", \"ntary | 1,063.67 us | 1.00  |\\n| Count  | .NET 7.0 | elementary | 56.04 us    | 0.05  |\\n\\nFor \\\"Sherloc\", \"k\\\", the performance is actually a bit worse in .NET 7 than in .NET 6; not much, but a measurable 10%\", \". That's because there are very few capital 'S' characters in the source text, 841 to be exact, out \", \"of 593,836 characters in the document. At only 0.1% density of the starting character, the new algor\", \"ithm doesn't bring much benefit, as the existing algorithm that searched for the first character alo\", \"ne captures pretty much all of the possible vectorization gains to be had, and we do pay a bit of ov\", \"erhead in doing a search for both the 'S' and the 'k', whereas previously we'd have only searched fo\", \"r the 'S'. In contrast, though, there are 54,614 'e' characters in the document, so almost 10% of th\", \"e source. In that case, .NET 7 is 20x faster than .NET 6, taking 53us on .NET 7 to count all the 'e'\", \"'s vs 1084us on .NET 6. In this case, the new scheme yields immense gains, by vectorizing a search f\", \"or both the 'e' and a 'y' at the specific distance away, a combination that is much, much less frequ\", \"ent. This is one of those situations where overall there are on average huge observed gains even tho\", \"ugh we can see small regressions for some specific inputs.\\n\\nAnother example of significantly changin\", \"g the algorithm employed is [dotnet/runtime#67758,](https://github.com/dotnet/runtime/issues/67758) \", \"which enables some amount of vectorization to be applied to IndexOf(\\\"...\\\",\\n\\nStringComparison.Ordinal\", \"IgnoreCase). Previously, this operation was implemented with a fairly typical substring search, walk\", \"ing the input string and at every location doing an inner loop to compare the target string, except \", \"performing a ToUpper on every character in order to do it in a caseinsensitive manner. Now with this\", \" PR, which is based on approaches previously used by Regex, if the target string begins with an ASCI\", \"I character, the implementation can use IndexOf (if the character isn't an ASCII letter) or IndexOfA\", \"ny (if the character is an ASCII letter) to quickly jump ahead to the first possible location of a m\", \"atch. Let's take the exact same benchmark as we just looked at, but tweaked to use OrdinalIgnoreCase\", \":\\n\\n```\\nprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gute\", \"nberg.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\n[Arguments(\\\"Sherlock\\\")]\\n[Arguments(\\\"elementary\", \"\\\")]\\npublic int Count(string needle)\\n{\\n ReadOnlySpan<char> haystack = s_haystack;\\n int count = 0, pos\", \";\\n while ((pos = haystack.IndexOf(needle, StringComparison.OrdinalIgnoreCase)) >= 0)\\n {\\n haystack = \", \"haystack.Slice(pos + needle.Length);\\n count++;\\n }\\n return count;\\n}\\n```\\n\\nHere, both words are about 4\", \"x faster on .NET 7 than they were on .NET 6:\\n\\n| Method | Runtime  | needle     | Mean       | Ratio \", \"|\\n|--------|----------|------------|------------|-------|\\n| Count  | .NET 6.0 | Sherlock   | 2,113.1\", \" us | 1.00  |\\n| Count  | .NET 7.0 | Sherlock   | 467.3 us   | 0.22  |\\n|        |          |         \", \"   |            |       |\\n| Count  | .NET 6.0 | elementary | 2,325.6 us | 1.00  |\\n| Count  | .NET 7.\", \"0 | elementary | 638.8 us   | 0.27  |\\n\\nas we're now doing a vectorized IndexOfAny('S', 's') or Index\", \"OfAny('E', 'e') rather than manually walking each character and comparing it. [\\\\(dotnet/runtime#7353\", \"3](https://github.com/dotnet/runtime/pull/73533) uses the same approach now for handling IndexOf(cha\", \"r, StringComparison.OrdinalIgnoreCase).)\\n\\nAnother example comes from [dotnet/runtime#67492](https://\", \"github.com/dotnet/runtime/pull/67492) from [@gfoidl](https://github.com/gfoidl). It updates MemoryEx\", \"tensions.Contains with the approach we discussed earlier for handling the leftover elements at the e\", \"nd of vectorized operation: process one last vector's worth of data, even if it means duplicating so\", \"me work already done. This particularly helps for smaller inputs where the processing time might oth\", \"erwise be dominated by the serial handling of those leftovers.\\n\\n```\\nprivate byte[] _data = new byte[\", \"95];\\n```\\n\\n```\\n[Benchmark]\\npublic bool Contains() => _data.AsSpan().Contains((byte)1);\\n```\\n\\n| Method \", \"  | Runtime  | Mean      | Ratio |\\n|----------|----------|-----------|-------|\\n| Contains | .NET 6.0\", \" | 15.115 ns | 1.00  |\\n| Contains | .NET 7.0 | 2.557 ns  | 0.17  |\\n\\n[dotnet/runtime#60974](https://g\", \"ithub.com/dotnet/runtime/pull/60974) from [@alexcovington](https://github.com/alexcovington) broaden\", \"s the impact of IndexOf. Prior to this PR, IndexOf was vectorized for one and two-byte sized primiti\", \"ve types, but this PR extends it as well to four and eight-byte sized primitives. As with most of th\", \"e other vectorized implementations, it checks whether the T is bitwise-equatable, which is important\", \" for the vectorization as it's only looking at the bits in memory and not paying attention to any Eq\", \"uals implementation that might be defined on the type. In practice today, that means this is limited\", \" to just a handful of types of which the runtime has intimate knowledge (Boolean, Byte, SByte, UInt1\", \"6, Int16, Char, UInt32, Int32, UInt64, Int64, UIntPtr, IntPtr, Rune, and enums), but in theory it co\", \"uld be extended in the future.\\n\\n```\\nprivate int[] _data = new int[1000];\\n[Benchmark]\\npublic int Inde\", \"xOf() => _data.AsSpan().IndexOf(42);\\n```\\n\\n| Method  | Runtime  | Mean      | Ratio |\\n|---------|----\", \"------|-----------|-------|\\n| IndexOf | .NET 6.0 | 252.17 ns | 1.00  |\\n| IndexOf | .NET 7.0 | 78.82 \", \"ns  | 0.31  |\\n\\nOne final interesting IndexOf-related optimization. string has long had IndexOf/Index\", \"OfAny/LastIndexOf/LastIndexOfAny, and obviously for string it's all about processing chars. When Rea\", \"dOnlySpan<T> and Span<T> came on the scene, MemoryExtensions was added to provide extension methods \", \"for spans and friends, including such IndexOf/IndexOfAny/LastIndexOf/LastIndexOfAny methods. But for\", \" spans, this is about more than just char, and so MemoryExtensions grew its own set of implementatio\", \"ns largely separate from string's. Over the years, MemoryExtensions implementations have specialized\", \" more and more types, but in particular byte and char, such that over time string's implementations \", \"have mostly been replaced by delegation into the same implementation as MemoryExtensions uses. Howev\", \"er, IndexOfAny and LastIndexOfAny had been unification holdouts, each in its own direction. string.I\", \"ndexOfAny did delegate to the same implementation as MemoryExtensions.IndexOfAny for 1-5 values bein\", \"g searched for, but for more than 5 values, string.IndexOfAny used a \\\"probabilistic map,\\\" essentiall\", \"y a [Bloom filter.](https://en.wikipedia.org/wiki/Bloom_filter) It creates a 256-bit table, and quic\", \"kly sets bits in that table based on the values being searched for (essentially hashing them, but wi\", \"th a trivial hash function). Then it iterates through the input, and rather than checking every inpu\", \"t character against every one of the target values, it instead first looks up the input character in\", \" the table. If the corresponding bit isn't set, it knows the input character doesn't match any of th\", \"e target values. If the corresponding bit is set, then it proceeds to compare the input character ag\", \"ainst each of the target values, with a high probability of it being one of them. MemoryExtensions.I\", \"ndexOfAny lacked such a filter for more than 5 values. Conversely, string.LastIndexOfAny didn't prov\", \"ide any vectorization for multiple target values, whereas MemoryExtensions.LastIndexOfAny vectorized\", \" two and three target values. As of\\n\\n[dotnet/runtime#63817,](https://github.com/dotnet/runtime/pull/\", \"63817) all of these are now unified, such that both string and MemoryExtensions get the best of what\", \" the other had.\\n\\n```\\nprivate readonly char[] s_target = new[] { 'z', 'q' };\\nconst string Sonnet = \\\"\\\"\", \"\\\"\\n Shall I compare thee to a summer's day?\\n Thou art more lovely and more temperate:\\n Rough winds do\", \" shake the darling buds of May,\\n And summer's lease hath all too short a date;\\n Sometime too hot the\", \" eye of heaven shines,\\n And often is his gold complexion dimm'd;\\n And every fair from fair sometime \", \"declines,\\n By chance or nature's changing course untrimm'd;\\n But thy eternal summer shall not fade,\\n\", \" Nor lose possession of that fair thou ow'st;\\n Nor shall death brag thou wander'st in his shade,\\n Wh\", \"en in eternal lines to time thou grow'st:\\n So long as men can breathe or eyes can see,\\n So long live\", \"s this, and this gives life to thee.\\n \\\"\\\"\\\";\\n[Benchmark]\\npublic int LastIndexOfAny() => Sonnet.LastInd\", \"exOfAny(s_target);\\n[Benchmark]\\npublic int CountLines()\\n{\\n int count = 0;\\n foreach (ReadOnlySpan<char\", \"> _ in Sonnet.AsSpan().EnumerateLines())\\n {\\n count++;\\n }\\n return count;\\n}\\n```\\n\\n| Method         | Ru\", \"ntime  | Mean        | Ratio |\\n|----------------|----------|-------------|-------|\\n| LastIndexOfAny \", \"| .NET 6.0 | 443.29 ns   | 1.00  |\\n| LastIndexOfAny | .NET 7.0 | 31.79 ns    | 0.07  |\\n|            \", \"    |          |             |       |\\n| CountLines     | .NET 6.0 | 1,689.66 ns | 1.00  |\\n| CountLi\", \"nes     | .NET 7.0 | 1,461.64 ns | 0.86  |\\n\\nThat same PR also cleans up uses of the IndexOf family, \", \"and in particular around uses that are checking for containment rather than the actual index of a re\", \"sult. The IndexOf family of methods return a non-negative value when an element is found, and otherw\", \"ise return -1. That means when checking whether an element was found, code can use either >= 0 or !=\", \" -1, and when checking whether an element wasn't found, code can use either < 0 or == -1. It turns o\", \"ut that the code generated for comparisons against 0 is ever so slightly more efficient than compari\", \"sons generated against -1, and this isn't something the JIT can itself substitute without the IndexO\", \"f methods being intrinsics such that the JIT can understand the semantics of the return value. Thus,\", \" for consistency and a small perf gain, all relevant call sites were switched to compare against 0 i\", \"nstead of against -1.\\n\\nSpeaking of call sites, one of the great things about having highly optimized\", \" IndexOf methods is using them in all the places that can benefit, removing the maintenance impact o\", \"f open-coded replacements while also reaping the perf wins. [dotnet/runtime#63913](https://github.co\", \"m/dotnet/runtime/pull/63913) used IndexOf inside of StringBuilder.Replace to speed up the search for\", \" the next character to be replaced:\\n\\n```\\nprivate StringBuilder _builder = new StringBuilder(Sonnet);\", \"\\n[Benchmark]\\npublic void Replace()\\n{\\n _builder.Replace('?', '!');\\n _builder.Replace('!', '?');\\n}\\n```\", \"\\n\\n| Method  | Runtime  | Mean        | Ratio |\\n|---------|----------|-------------|-------|\\n| Replac\", \"e | .NET 6.0 | 1,563.69 ns | 1.00  |\\n| Replace | .NET 7.0 | 70.84 ns    | 0.04  |\\n\\n[dotnet/runtime#6\", \"0463](https://github.com/dotnet/runtime/pull/60463) from [@nietras](https://github.com/nietras) used\", \" IndexOfAny in StringReader.ReadLine to search for '\\\\r' and '\\\\n' line ending characters, which resul\", \"ts in some substantial throughput gains even with the allocation and copy that is inherent to the me\", \"thod's design:\\n\\n```\\n[Benchmark]\\npublic void ReadAllLines()\\n{\\n var reader = new StringReader(Sonnet);\", \"\\n while (reader.ReadLine() != null) ;\\n}\\n```\\n\\n| Method<br>Runtime |          | Mean     | Ratio |  |\\n\", \"|-------------------|----------|----------|-------|--|\\n| ReadAllLines      | .NET 6.0 | 947.8 ns | 1\", \".00  |  |\\n| ReadAllLines      | .NET 7.0 | 385.7 ns | 0.41  |  |\\n\\nAnd [dotnet/runtime#70176](https:/\", \"/github.com/dotnet/runtime/pull/70176) cleaned up a plethora of additional uses.\\n\\nFinally on the Ind\", \"exOf front, as noted, a lot of time and energy over the years has gone into optimizing these methods\", \". In previous releases, some of that energy has been in the form of using hardware intrinsics direct\", \"ly, e.g. having an SSE2 code path and an AVX2 code path and an AdvSimd code path. Now that we have V\", \"ector128<T> and Vector256<T>, many such uses can be simplified (e.g. avoiding the duplication betwee\", \"n an SSE2 implementation and an AdvSimd implementation) while still maintaining as good or even bett\", \"er performance and while automatically supporting vectorization on other platforms with their own in\", \"trinsics, like WebAssembly. [dotnet/runtime#73481,](https://github.com/dotnet/runtime/pull/73481)  [\", \"dotnet/runtime#73556,](https://github.com/dotnet/runtime/pull/73556) [dotnet/runtime#73368,](https:/\", \"/github.com/dotnet/runtime/pull/73368) [dotnet/runtime#73364,](https://github.com/dotnet/runtime/pul\", \"l/73364) [dotnet/runtime#73064,](https://github.com/dotnet/runtime/pull/73064) and [dotnet/runtime#7\", \"3469](https://github.com/dotnet/runtime/pull/73469) all contributed here, in some cases incurring me\", \"aningful throughput gains:\\n\\n```\\n[Benchmark]\\npublic int IndexOfAny() => Sonnet.AsSpan().IndexOfAny(\\\"!\", \".<>\\\");\\n```\\n\\n| Method     | Runtime  | Mean     | Ratio |\\n|------------|----------|----------|-------\", \"|\\n| IndexOfAny | .NET 6.0 | 52.29 ns | 1.00  |\\n| IndexOfAny | .NET 7.0 | 40.17 ns | 0.77  |\\n\\nThe Ind\", \"exOf family is just one of many on string/MemoryExtensions that has seen dramatic improvements. Anot\", \"her are the SequenceEquals family, including Equals, StartsWith, and EndsWith. One of my favorite ch\", \"anges in the whole release is [dotnet/runtime#65288](https://github.com/dotnet/runtime/pull/65288) a\", \"nd is squarely in this area. It's very common to see calls to methods like StartsWith with a constan\", \"t string argument, e.g. value.StartsWith(\\\"https://\\\"), value.SequenceEquals(\\\"Key\\\"), etc. These method\", \"s are now recognized by the JIT, which can now automatically unroll the comparison and compare more \", \"than one char at a time, e.g. doing a single read of four chars as a long and a single comparison of\", \" that long against the expected combination of those four chars. The result is beautiful. Making it \", \"even better is [dotnet/runtime#66095,](https://github.com/dotnet/runtime/pull/66095) which adds to t\", \"his support for OrdinalIgnoreCase. Remember those ASCII bit twiddling tricks discussed a bit earlier\", \" with char.IsAsciiLetter and friends? The JIT now employs the same trick as part of this unrolling, \", \"so if you do that same value.StartsWith(\\\"https://\\\") but instead as value.StartsWith(\\\"https://\\\", Stri\", \"ngComparison.OrdinalIgnoreCase), it will recognize that the whole comparison string is ASCII and wil\", \"l OR in the appropriate mask on both the comparison constant and on the read data from the input in \", \"order to perform the comparison in a case-insensitive manner.\\n\\n```\\nprivate string _value = \\\"https://\", \"dot.net\\\";\\n[Benchmark]\\npublic bool IsHttps_Ordinal() => _value.StartsWith(\\\"https://\\\", StringCompariso\", \"n.Ordinal);\\n[Benchmark]\\npublic bool IsHttps_OrdinalIgnoreCase() => _value.StartsWith(\\\"https://\\\", \\nSt\", \"ringComparison.OrdinalIgnoreCase);\\n```\\n\\n| Method                    | Runtime  | Mean      | Ratio |\", \"\\n|---------------------------|----------|-----------|-------|\\n| IsHttps_Ordinal           | .NET 6.0\", \" | 4.5634 ns | 1.00  |\\n| IsHttps_Ordinal           | .NET 7.0 | 0.4873 ns | 0.11  |\\n|               \", \"            |          |           |       |\\n| IsHttps_OrdinalIgnoreCase | .NET 6.0 | 6.5654 ns | 1.\", \"00  |\\n| IsHttps_OrdinalIgnoreCase | .NET 7.0 | 0.5577 ns | 0.08  |\\n\\nInterestingly, since .NET 5 the \", \"code generated by RegexOptions.Compiled would perform similar unrolling when comparing sequences of \", \"multiple characters, and when the source generator was added in .NET 7, it also learned how to do th\", \"is. However, the source generator has problems with such an optimization, due to endianness. The con\", \"stants being compared against are subject to byte ordering issues, such that the source generator wo\", \"uld need to emit code that could handle running on either little-endian or big-endian machines. The \", \"JIT has no such problem, as it's generating the code on the same machine on which the code will exec\", \"ute (and in scenarios where it's being used to generate code ahead of time, the entirety of that cod\", \"e is already tied to a particular architecture). By moving this optimization into the JIT, the corre\", \"sponding code could be deleted from RegexOptions.Compiled and the regex source generator, which then\", \" also benefits from producing\\n\\nmuch easier to read code utilizing StartsWith that's just as fast ([d\", \"otnet/runtime#65222](https://github.com/dotnet/runtime/pull/65222) and [dotnet/runtime#66339\\\\)](http\", \"s://github.com/dotnet/runtime/issues/66339). Wins all around. (This could only be removed from Regex\", \"Options.Compiled after [dotnet/runtime#68055,](https://github.com/dotnet/runtime/pull/68055) which f\", \"ixed the ability for the JIT to recognize these string literals in DynamicMethods, which RegexOption\", \"s.Compiled uses with reflection emit to spit out the IL for the regex being compiled.)\\n\\nStartsWith a\", \"nd EndsWith have improved in other ways. [dotnet/runtime#63734](https://github.com/dotnet/runtime/pu\", \"ll/63734) (improved further by [dotnet/runtime#64530\\\\)](https://github.com/dotnet/runtime/pull/64530\", \") added another really interesting JIT-based optimization, but to understand it, we need to understa\", \"nd string's internal layout. string is essentially represented in memory as an int length followed b\", \"y that many chars plus a null terminator char. The actual System.String class represents this in C# \", \"as an int \\\\_stringLength field followed by a char \\\\_firstChar field, such that \\\\_firstChar indeed li\", \"nes up with the first character of the string, or the null terminator if the string is empty. Intern\", \"ally in System.Private.CoreLib, and in particular in methods on string itself, code will often refer\", \" to \\\\_firstChar directly when the first character needs to be consulted, as it's typically faster to\", \" do that than to use str[0], in particular because there are no bounds checks involved and the strin\", \"g's length generally needn't be consulted. Now, consider a method like public bool StartsWith(char v\", \"alue) on string. In .NET 6, the implementation was:\\n\\n```\\nreturn Length != 0 && _firstChar == value;\\n\", \"```\\n\\nwhich given what I just described makes sense: if the Length is 0, then the string doesn't begi\", \"n with the specified character, and if Length is not 0, then we can just compare the value against \\\\\", \"_firstChar. But, why is that Length check even needed at all? Couldn't we just do return \\\\_firstChar\", \" == value;? That will avoid the additional comparison and branch, and it will work just fine\\u2026 unless\", \" the target character is itself '\\\\0', in which case we could get false positives on the result. Now \", \"to this PR. The PR introduces an internal JIT intrinsinc RuntimeHelpers.IsKnownConstant, which the J\", \"IT will substitute with true if the containing method is inlined and the argument passed to IsKnownC\", \"onstant is then seen to be a constant. In such cases, the implementation can rely on other JIT optim\", \"izations kicking in and optimizing various code in the method, effectively enabling a developer to w\", \"rite two different implementations, one when the argument is known to be a constant and one when not\", \". With that in hand, the PR is able to optimize StartsWith as follows:\\n\\n```\\npublic bool StartsWith(c\", \"har value)\\n{\\n if (RuntimeHelpers.IsKnownConstant(value) && value != '\\\\0')\\n return _firstChar == valu\", \"e;\\n return Length != 0 && _firstChar == value;\\n}\\n```\\n\\nIf the value parameter isn't a constant, then \", \"IsKnownConstant will be substituted with false, the entire starting if block will be eliminated, and\", \" the method will be left exactly was it was before. But, if this method gets inlined and the value w\", \"as actually a constant, then the value != '\\\\0' condition will also be evaluatable at JIT-compile-tim\", \"e. If the value is in fact '\\\\0', well, again that whole if block will be eliminated and we're no wor\", \"se off. But in the common case where the value isn't null, the entire method will end up being compi\", \"led as if it were:\\n\\n```\\nreturn _firstChar == ConstantValue;\\n```\\n\\nand we've saved ourselves a read of\", \" the string's length, a comparison, and a branch. [dotnet/runtime#69038](https://github.com/dotnet/r\", \"untime/pull/69038) then employs a similar technique for EndsWith.\\n\\n```\\nprivate string _value = \\\"http\", \"s://dot.net\\\";\\n[Benchmark]\\npublic bool StartsWith() =>\\n _value.StartsWith('a') ||\\n _value.StartsWith(\", \"'b') ||\\n _value.StartsWith('c') ||\\n _value.StartsWith('d') ||\\n _value.StartsWith('e') ||\\n _value.Sta\", \"rtsWith('f') ||\\n _value.StartsWith('g') ||\\n _value.StartsWith('i') ||\\n _value.StartsWith('j') ||\\n _v\", \"alue.StartsWith('k') ||\\n _value.StartsWith('l') ||\\n _value.StartsWith('m') ||\\n _value.StartsWith('n'\", \") ||\\n _value.StartsWith('o') ||\\n _value.StartsWith('p');\\n```\\n\\n| Method     | Runtime  | Mean     | R\", \"atio |\\n|------------|----------|----------|-------|\\n| StartsWith | .NET 6.0 | 8.130 ns | 1.00  |\\n| S\", \"tartsWith | .NET 7.0 | 1.653 ns | 0.20  |\\n\\n(Another example of IsKnownConstant being used comes from\", \" [dotnet/runtime#64016,](https://github.com/dotnet/runtime/pull/64016) which uses it to improve Math\", \".Round when a MidpointRounding mode is specified. Call sites to this almost always explicitly specif\", \"y the enum value as a constant, which then allows the JIT to specialize the code generation for the \", \"method to the specific mode being used; that in turn, for example, enables a Math.Round(..., Midpoin\", \"tRounding.AwayFromZero) call on Arm64 to be lowered to a single frinta instruction.)\\n\\nEndsWith was a\", \"lso improved in [dotnet/runtime#72750,](https://github.com/dotnet/runtime/pull/72750) and specifical\", \"ly for when StringComparison.OrdinalIgnoreCase is specified. This simple PR just switched which inte\", \"rnal helper method was used to implement this method, taking advantage of one that is sufficient for\", \" the needs of this method and that has lower overheads.\\n\\n```\\n[Benchmark]\\n[Arguments(\\\"System.Private.\", \"CoreLib.dll\\\", \\\".DLL\\\")]\\npublic bool EndsWith(string haystack, string needle) =>\\n haystack.EndsWith(ne\", \"edle, StringComparison.OrdinalIgnoreCase);\\n```\\n\\n| Method   | Runtime  | Mean      | Ratio |\\n|-------\", \"---|----------|-----------|-------|\\n| EndsWith | .NET 6.0 | 10.861 ns | 1.00  |\\n| EndsWith | .NET 7.\", \"0 | 5.385 ns  | 0.50  |\\n\\nFinally, [dotnet/runtime#67202](https://github.com/dotnet/runtime/pull/6720\", \"2) and [dotnet/runtime#73475](https://github.com/dotnet/runtime/pull/73475) employ Vector128<T> and \", \"Vector256<T> to replace direct hardware intrinsics usage, just as was previously shown for various I\", \"ndexOf methods, but here for SequenceEqual and SequenceCompareTo, respectively.\\n\\nAnother method that\", \"'s seem some attention in .NET 7 is MemoryExtensions.Reverse (and Array.Reverse as it shares the sam\", \"e implementation), which performs an in-place reversal of the target span. [dotnet/runtime#64412](ht\", \"tps://github.com/dotnet/runtime/pull/64412) from [@alexcovington](https://github.com/alexcovington) \", \"provides a vectorized implementation via direct use of AVX2 and SSSE3 hardware intrinsics, with [dot\", \"net/runtime#72780](https://github.com/dotnet/runtime/pull/72780) from [@SwapnilGaikwad](https://gith\", \"ub.com/SwapnilGaikwad) following up to add an AdvSimd intrinsics implementation for Arm64. (There wa\", \"s an unintended regression introduced by the original vectorization change, but that was fixed by [d\", \"otnet/runtime#70650.\\\\)](https://github.com/dotnet/runtime/pull/70650)\\n\\n```\\nprivate char[] text = \\\"Fr\", \"ee. Cross-platform. Open source.\\\\r\\\\nA developer platform for \\nbuilding all your apps.\\\".ToCharArray()\", \";\\n[Benchmark]\\npublic void Reverse() => Array.Reverse(text);\\n```\\n\\n| Method  | Runtime  | Mean      | \", \"Ratio |\\n|---------|----------|-----------|-------|\\n| Reverse | .NET 6.0 | 21.352 ns | 1.00  |\\n| Reve\", \"rse | .NET 7.0 | 9.536 ns  | 0.45  |\\n\\nString.Split also saw vectorization improvements in [dotnet/ru\", \"ntime#64899](https://github.com/dotnet/runtime/pull/64899) from [@yesmey](https://github.com/yesmey)\", \". As with some of the previously discussed PRs, it switched the existing usage of SSE2 and SSSE3 har\", \"dware intrinsics over to the new Vector128<T> helpers, which improved upon the existing implementati\", \"on while also implicitly adding vectorization support for Arm64.\\n\\nConverting various formats of stri\", \"ngs is something many applications and services do, whether that's converting from UTF8 bytes to and\", \" from string or formatting and parsing hex values. Such operations have also improved in a variety o\", \"f ways in .NET 7. [Base64-encoding,](https://en.wikipedia.org/wiki/Base64) for example, is a way of \", \"representing arbitrary binary data (think byte[]) across mediums that only support text, encoding by\", \"tes into one of 64 different ASCII characters. Multiple APIs in .NET implement this encoding. For co\", \"nverting between binary data represented as ReadOnlySpan<byte> and UTF8 (actually ASCII) encoded dat\", \"a also represented as ReadOnlySpan<byte>, the System.Buffers.Text.Base64 type provides EncodeToUtf8 \", \"and DecodeFromUtf8 methods. These were vectorized several releases ago, but they were further improv\", \"ed in .NET 7 via [dotnet/runtime#70654](https://github.com/dotnet/runtime/pull/70654) from [@a74nh](\", \"https://github.com/a74nh), which converted the SSSE3-based implementation to use Vector128<T> (which\", \" in turn implicitly enabled vectorization on Arm64). However, for converting between arbitrary binar\", \"y data represented as ReadOnlySpan<byte>/byte[] and ReadOnlySpan<char>/char[]/string, the System.Con\", \"vert type exposes multiple methods, e.g. Convert.ToBase64String, and these methods historically were\", \" not vectorized. That changes in .NET 7, where [dotnet/runtime#71795](https://github.com/dotnet/runt\", \"ime/pull/71795) and [dotnet/runtime#73320](https://github.com/dotnet/runtime/pull/73320) vectorize t\", \"he ToBase64String, ToBase64CharArray, and TryToBase64Chars methods. The way they do this is interest\", \"ing. Rather than effectively duplicating the vectorization implementation from Base64.EncodeToUtf8, \", \"they instead layer on top of EncodeToUtf8, calling it to encode the input byte data into an output S\", \"pan<byte>. Then, then they \\\"widen\\\" those bytes into chars (remember, Base64-encoded data is a set of\", \" ASCII chars, so going from these bytes to chars entails adding just a 0 byte onto each element). Th\", \"at widening can itself easily be done in a vectorized manner. The other interesting thing about this\", \" layering is it doesn't actually require separate intermediate storage for the encoded bytes. The im\", \"plementation can perfectly compute the number of resulting characters for encoding X bytes into Y\\n\\nB\", \"ase64 characters (there's a formula), and the implementation can either allocate that final space (e\", \".g. in the case of ToBase64CharArray) or ensure the provided space is sufficient (e.g. in the case o\", \"f TryToBase64Chars). And since we know the initial encoding will require exactly half as many bytes,\", \" we can encode into that same space (with the destination span reinterpreted as a byte span rather t\", \"han char span), and then widen \\\"in place\\\": walk from the end of the bytes and the end of the char sp\", \"ace, copying the bytes into the destination.\\n\\n```\\nprivate byte[] _data = Encoding.UTF8.GetBytes(\\\"\\\"\\\"\\n\", \" Shall I compare thee to a summer's day?\\n Thou art more lovely and more temperate:\\n Rough winds do s\", \"hake the darling buds of May,\\n And summer's lease hath all too short a date;\\n Sometime too hot the e\", \"ye of heaven shines,\\n And often is his gold complexion dimm'd;\\n And every fair from fair sometime de\", \"clines,\\n By chance or nature's changing course untrimm'd;\\n But thy eternal summer shall not fade,\\n N\", \"or lose possession of that fair thou ow'st;\\n Nor shall death brag thou wander'st in his shade,\\n When\", \" in eternal lines to time thou grow'st:\\n So long as men can breathe or eyes can see,\\n So long lives \", \"this, and this gives life to thee.\\n \\\"\\\"\\\");\\nprivate char[] _encoded = new char[1000];\\n[Benchmark]\\npubl\", \"ic bool TryToBase64Chars() => Convert.TryToBase64Chars(_data, _encoded, out _);\\n```\\n\\n| Method       \", \"    | Runtime  | Mean      | Ratio |\\n|------------------|----------|-----------|-------|\\n| TryToBase\", \"64Chars | .NET 6.0 | 623.25 ns | 1.00  |\\n| TryToBase64Chars | .NET 7.0 | 81.82 ns  | 0.13  |\\n\\nJust a\", \"s widening can be used to go from bytes to chars, narrowing can be used to go from chars to bytes, i\", \"n particular if the chars are actually ASCII and thus have a 0 upper byte. Such narrowing can be vec\", \"torized, and the internal NarrowUtf16ToAscii utility helper does exactly that, used as part of metho\", \"ds like Encoding.ASCII.GetBytes. While this method was previously vectorized, its primary fast-path \", \"utilized SSE2 and thus didn't apply to Arm64; thanks to [dotnet/runtime#70080](https://github.com/do\", \"tnet/runtime/pull/70080) from [@SwapnilGaikwad](https://github.com/SwapnilGaikwad), that path was ch\", \"anged over to be based on the cross-platform Vector128<T>, enabling the same level of optimization a\", \"cross supported platforms. Similarly, [dotnet/runtime#71637](https://github.com/dotnet/runtime/pull/\", \"71637) from\\n\\n[@SwapnilGaikwad](https://github.com/SwapnilGaikwad) adds Arm64 vectorization to the Ge\", \"tIndexOfFirstNonAsciiChar internal helper that's used by methods like Encoding.UTF8.GetByteCount. (A\", \"nd in the same vein, [dotnet/runtime#67192](https://github.com/dotnet/runtime/pull/67192) changed th\", \"e internal HexConverter.EncodeToUtf16 method from using SSSE3 intrinsics to instead use Vector128<T>\", \", automatically providing an Arm64 implementation.)\\n\\nEncoding.UTF8 was also improved a bit. In parti\", \"cular, [dotnet/runtime#69910](https://github.com/dotnet/runtime/pull/69910) streamlined the implemen\", \"tations of GetMaxByteCount and GetMaxCharCount, making them small enough to be commonly inlined when\", \" used directly off of Encoding.UTF8 such that the JIT is able to devirtualize the calls.\\n\\n```\\n[Bench\", \"mark]\\npublic int GetMaxByteCount() => Encoding.UTF8.GetMaxByteCount(Sonnet.Length);\\n```\\n\\n| Method   \", \"       | Runtime  | Mean      | Ratio |\\n|-----------------|----------|-----------|-------|\\n| GetMaxB\", \"yteCount | .NET 6.0 | 1.7442 ns | 1.00  |\\n| GetMaxByteCount | .NET 7.0 | 0.4746 ns | 0.27  |\\n\\nArguab\", \"ly the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals. Initial\", \"ly implemented in the C# compiler in [dotnet/roslyn#58991,](https://github.com/dotnet/roslyn/pull/58\", \"991) with follow-on work in [dotnet/roslyn#59390,](https://github.com/dotnet/roslyn/pull/59390) [dot\", \"net/roslyn#61532,](https://github.com/dotnet/roslyn/pull/61532) and [dotnet/roslyn#62044,](https://g\", \"ithub.com/dotnet/roslyn/pull/62044) UTF8 literals enables the compiler to perform the UTF8 encoding \", \"into bytes at compile-time. Rather than writing a normal string, e.g. \\\"hello\\\", a developer simply ap\", \"pends the new u8 suffix onto the string literal, e.g. \\\"hello\\\"u8. At that point, this is no longer a \", \"string. Rather, the natural type of this expression is a ReadOnlySpan<byte>. If you write:\\n\\n```\\npubl\", \"ic static ReadOnlySpan<byte> Text => \\\"hello\\\"u8;\\n```\\n\\nthe C# compiler will compile that equivalent to\", \" if you wrote:\\n\\n```\\npublic static ReadOnlySpan<byte> Text =>\\n new ReadOnlySpan<byte>(new byte[] { (b\", \"yte)'h', (byte)'e', (byte)'l', (byte)'l', \\n(byte)'o', (byte)'\\\\0' }, 0, 5);\\n```\\n\\nIn other words, the \", \"compiler is doing the equivalent of Encoding.UTF8.GetBytes at compile-time and hardcoding the result\", \"ing bytes, saving the cost of performing that encoding at run-time. Of course, at first glance, that\", \" array allocation might look terribly inefficient. However, looks can be deceiving, and are in this \", \"case. For several releases now, when the C# compiler sees a byte[] (or sbyte[] or bool[]) being init\", \"ialized with a constant length and constant values and immediately cast to or used to construct a Re\", \"adOnlySpan<byte>, it optimizes away the byte[] allocation. Instead, it blits the data for that span \", \"into the assembly's data section, and then constructs a span that points directly to that data in th\", \"e loaded assembly. This is the actual generated IL for the above property:\\n\\n```\\nIL_0000: ldsflda val\", \"uetype '<PrivateImplementationDetails>'/'__StaticArrayInitTypeSize=6' \\n'<PrivateImplementationDetail\", \"s>'::F3AEFE62965A91903610F0E23CC8A69D5B87CEA6D28E75489B0D2CA02\\nED7993C\\nIL_0005: ldc.i4.5\\nIL_0006: ne\", \"wobj instance void valuetype \\n[System.Runtime]System.ReadOnlySpan`1<uint8>::.ctor(void*, int32)\\nIL_0\", \"00b: ret\\n```\\n\\nThis means we not only save on the encoding costs at run-time, and we not only avoid w\", \"hatever managed allocations might be required to store the resulting data, we also benefit from the \", \"JIT being able to see information about the encoded data, like it's length, enabling knock-on optimi\", \"zations. You can see this clearly by examining the assembly generated for a method like:\\n\\n```\\npublic\", \" static int M() => Text.Length;\\n```\\n\\nfor which the JIT produces:\\n\\n```\\n; Program.M()\\n mov eax,5\\n```\\n\\n\", \"```\\n ret\\n; Total bytes of code 6\\n```\\n\\nThe JIT inlines the property access, sees that the span is bei\", \"ng constructed with a length of 5, and so rather than emitting any array allocations or span constru\", \"ctions or anything even resembling that, it simply outputs mov eax, 5 to return the known length of \", \"the span.\\n\\nThanks primarily to [dotnet/runtime#70568,](https://github.com/dotnet/runtime/pull/70568)\", \" [dotnet/runtime#69995,](https://github.com/dotnet/runtime/pull/69995) [dotnet/runtime#70894,](https\", \"://github.com/dotnet/runtime/pull/70894)  [dotnet/runtime#71417](https://github.com/dotnet/runtime/p\", \"ull/71417) from [@am11](https://github.com/am11), [dotnet/runtime#71292,](https://github.com/dotnet/\", \"runtime/pull/71292)  [dotnet/runtime#70513,](https://github.com/dotnet/runtime/pull/70513) and [dotn\", \"et/runtime#71992,](https://github.com/dotnet/runtime/pull/71992) u8 is now used more than 2100 times\", \" throughout [dotnet/runtime.](https://github.com/dotnet/runtime) Hardly a fair comparison, but the f\", \"ollowing benchmark demonstrates how little work is actually being performed for u8 at execution time\", \":\\n\\n```\\n[Benchmark(Baseline = true)]\\npublic ReadOnlySpan<byte> WithEncoding() => Encoding.UTF8.GetByt\", \"es(\\\"test\\\");\\n[Benchmark] \\npublic ReadOnlySpan<byte> Withu8() => \\\"test\\\"u8;\\n```\\n\\n| Method       | Mean \", \"      | Ratio | Allocated | Alloc Ratio |\\n|--------------|------------|-------|-----------|---------\", \"----|\\n| WithEncoding | 17.3347 ns | 1.000 | 32 B      | 1.00        |\\n| Withu8       | 0.0060 ns  | \", \"0.000 | -         | 0.00        |\\n\\nLike I said, not fair, but it proves the point :)\\n\\nEncoding is of\", \" course just one mechanism for creating string instances. Others have also improved in .NET 7. Take \", \"the super common long.ToString, for example. Previous releases improved int.ToString, but there were\", \" enough differences between the 32-bit and 64-bit algorithms that long didn't see all of the same ga\", \"ins. Now thanks to [dotnet/runtime#68795,](https://github.com/dotnet/runtime/pull/68795) the 64-bit \", \"formatting code paths are made much more similar to the 32-bit, resulting in faster performance.\\n\\nYo\", \"u can also see improvements in string.Format and StringBuilder.AppendFormat, as well as other helper\", \"s that layer on top of these (like TextWriter.AppendFormat). [dotnet/runtime#69757](https://github.c\", \"om/dotnet/runtime/pull/69757) overhauls the core routines inside Format to avoid unnecessary bounds \", \"checking, favor expected cases, and generally clean up the implementation. It also, however, utiliti\", \"es IndexOfAny to search for the next interpolation hole that needs to be filled in, and if the non-h\", \"ole-character to hole ratio is high (e.g. long format string with few holes), it can be way faster t\", \"han before.\\n\\n```\\nprivate StringBuilder _sb = new StringBuilder();\\n[Benchmark]\\npublic void AppendForm\", \"at()\\n{\\n _sb.Clear();\\n _sb.AppendFormat(\\\"There is already one outstanding '{0}' call for this WebSock\", \"et \\ninstance.\\\" +\\n \\\"ReceiveAsync and SendAsync can be called simultaneously, but at most \\none \\\" +\\n \\\"o\", \"utstanding operation for each of them is allowed at the same time.\\\",\\n                   \\\"ReceiveAsyn\", \"c\\\");\\n}\\n```\\n\\n| Method       | Runtime  | Mean      | Ratio |\\n|--------------|----------|-----------|-\", \"------|\\n| AppendFormat | .NET 6.0 | 338.23 ns | 1.00  |\\n| AppendFormat | .NET 7.0 | 49.15 ns  | 0.15\", \"  |\\n\\nSpeaking of StringBuilder, it's seen additional improvements beyond the aforementioned changes \", \"to AppendFormat. One interesting change is [dotnet/runtime#64405,](https://github.com/dotnet/runtime\", \"/pull/64405) which achieved two related things. The first was to remove pinning as part of formattin\", \"g operations. As an example, StringBuilder has an Append(char\\\\* value, int valueCount) overload whic\", \"h copies the specified number of characters from the specified pointer into the StringBuilder, and o\", \"ther APIs were implemented in terms of this method; for example, the Append(string? value, int start\", \"Index, int count) method was essentially implemented as:\\n\\n```\\nfixed (char* ptr = value)\\n{\\n Append(pt\", \"r + startIndex, count);\\n}\\n```\\n\\nThat fixed statement translates into a \\\"pinning pointer.\\\" Normally th\", \"e GC is free to move managed objects around on the heap, which it might do in order to compact the h\", \"eap (to, for example, avoid small, unusuable fragments of memory between objects). But if the GC can\", \" move objects around, a normal native pointer into that memory would be terribly unsafe and unreliab\", \"le, as without notice the data being pointed to could move and your pointer could now be pointing to\", \" garbage or to some other object that was shifted to this location. There are two ways for dealing w\", \"ith this. The first is a \\\"managed pointer,\\\" otherwise known as a \\\"reference\\\" or \\\"ref,\\\" as that's exa\", \"ctly what you get when you have the \\\"ref\\\" keyword in C#; it's a pointer that the runtime will update\", \" with the correct value when it moves the object being pointed into. The second is to prevent the po\", \"inted-to object from being moved, \\\"pinning\\\" it in place. And that's what the \\\"fixed\\\" keyword does, p\", \"inning the referenced object for the duration of the fixed block, during which time it's safe to use\", \" the supplied pointer. Thankfully, pinning is cheap when no GC occurs; when a GC does occur, however\", \", pinned objects aren't able to be moved around, and thus pinning can have a global impact on the pe\", \"rformance of the application (and on GCs themselves). There are also various optimizations inhibited\", \" by pinning. With all of the advents in C# around being able to use ref in many more places (e.g. re\", \"f locals, ref returns, and now in C# 11, ref fields), and with all of the new APIs in .NET for manip\", \"ulating refs (e.g. Unsafe.Add, Unsafe.AreSame), it's now possible to rewrite code that was using pin\", \"ning pointers to instead use managed pointers, thereby avoiding the problems that come from pinning.\", \" Which is what this PR did. Rather than implementing all of the Append methods in terms of an Append\", \"(char\\\\*, int) helper, they're now all implemented in terms of an Append(ref char, int) helper. So fo\", \"r example instead of the previously shown Append(string? value, int startIndex, int count) implement\", \"ation, it's now akin to\\n\\n```\\nAppend(ref Unsafe.Add(ref value.GetRawStringData(), startIndex), count)\", \";\\n```\\n\\nwhere that string.GetRawStringData method is just an internal version of the public string.Ge\", \"tPinnableReference method, returning a ref instead of a ref readonly. This means that all of the hig\", \"h-performance code inside of StringBuilder that had been using pointers to avoid bounds checking and\", \" the like can continue to do so, but now also does so without pinning all of the inputs.\\n\\nThe second\", \" thing this StringBuilder change did was unify an optimization that was present for string inputs to\", \" also apply to char[] inputs and ReadOnlySpan<char> inputs. Specifically, because it's so common to \", \"append string instances to a StringBuilder, a special code path was long ago put in place to optimiz\", \"e for this input and specifically for the case where there's already enough room in the StringBuilde\", \"r to hold the whole input, at which point an efficient copy can be used. With a shared Append(ref ch\", \"ar, int) helper, though, this optimization can be moved down into that helper, such that it not only\", \" helps out string but any other type that also calls into the same helper. The effects of this are v\", \"isible in a simple microbenchmark:\\n\\n```\\nprivate StringBuilder _sb = new StringBuilder();\\n[Benchmark]\", \"\\npublic void AppendSpan()\\n{\\n _sb.Clear();\\n _sb.Append(\\\"this\\\".AsSpan());\\n _sb.Append(\\\"is\\\".AsSpan());\\n\", \" _sb.Append(\\\"a\\\".AsSpan());\\n _sb.Append(\\\"test\\\".AsSpan());\\n _sb.Append(\\\".\\\".AsSpan());\\n}\\n```\\n\\n| Method \", \"    | Runtime  | Mean     | Ratio |\\n|------------|----------|----------|-------|\\n| AppendSpan | .NET\", \" 6.0 | 35.98 ns | 1.00  |\\n| AppendSpan | .NET 7.0 | 17.59 ns | 0.49  |\\n\\nOne of the great things abou\", \"t improving things low in the stack is they have a multiplicative effect; they not only help improve\", \" the performance of user code that directly relies on the improved functionality, they can also help\", \" improve the performance of other code in the core libraries, which then further helps dependent app\", \"s and services. You can see this, for example, with DateTimeOffset.ToString, which depends on String\", \"Builder:\\n\\n```\\nprivate DateTimeOffset _dto = DateTimeOffset.UtcNow;\\n[Benchmark]\\npublic string DateTim\", \"eOffsetToString() => _dto.ToString();\\n```\\n\\n| Method                 | Runtime  | Mean     | Ratio |\\n\", \"|------------------------|----------|----------|-------|\\n| DateTimeOffsetToString | .NET 6.0 | 340.4\", \" ns | 1.00  |\\n| DateTimeOffsetToString | .NET 7.0 | 289.4 ns | 0.85  |\\n\\nStringBuilder itself was the\", \"n further updated by [dotnet/runtime#64922](https://github.com/dotnet/runtime/pull/64922) from [@teo\", \"tsirpanis](https://github.com/teo-tsirpanis), which improves the Insert methods. It used to be that \", \"the Append(primitive) methods on StringBuilder (e.g. Append(int)) would call ToString on the value a\", \"nd then append the resulting string. With the advent of ISpanFormattable, as a fast-path those metho\", \"ds now try to format the value directly into the StringBuilder's internal buffer, and only if there'\", \"s not enough room remaining do they then take the old path as a fallback. Insert wasn't improved in \", \"this way at the time, because it can't just format into the space at the end of the builder; the ins\", \"ert location could be anywhere in the builder. This PR addresses that by formatting into some tempor\", \"ary stack space, and then delegating to the existing internal ref-based helper from the\\n\\npreviously \", \"discussed PR to insert the resulting characters at the right location (it also falls back to ToStrin\", \"g when there's not enough stack space for the ISpanFormattable.TryFormat, but that only happens in i\", \"ncredibly corner cases, like a floating-point value that formats to hundreds of digits).\\n\\n```\\nprivat\", \"e StringBuilder _sb = new StringBuilder();\\n[Benchmark]\\npublic void Insert()\\n{\\n _sb.Clear();\\n _sb.Ins\", \"ert(0, 12345);\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------|-\", \"---------|----------|-------|-----------|-------------|\\n| Insert | .NET 6.0 | 30.02 ns | 1.00  | 32 \", \"B      | 1.00        |\\n| Insert | .NET 7.0 | 25.53 ns | 0.85  | -         | 0.00        |\\n\\nOther min\", \"or improvements to StringBuilder have also been made, like [dotnet/runtime#60406](https://github.com\", \"/dotnet/runtime/pull/60406) which removed a small int[] allocation from the Replace method. Even wit\", \"h all these improvements, though, the fastest use of StringBuilder is no use; [dotnet/runtime#68768]\", \"(https://github.com/dotnet/runtime/pull/68768) removed a bunch of uses of StringBuilder that would h\", \"ave been better served with other string-creation mechanisms. For example, the legacy DataView type \", \"had some code that created a sorting specification as a string:\\n\\n```\\nprivate static string CreateSor\", \"tString(PropertyDescriptor property, ListSortDirection \\ndirection)\\n{\\n var resultString = new StringB\", \"uilder();\\n resultString.Append('[');\\n resultString.Append(property.Name);\\n resultString.Append(']');\", \"\\n if (ListSortDirection.Descending == direction)\\n {\\n resultString.Append(\\\" DESC\\\");\\n }\\n return result\", \"String.ToString();\\n}\\n```\\n\\nWe don't actually need the StringBuilder here, as in the worst-case we're \", \"just concatenating three strings, and string.Concat has a dedicated overload for that exact operatio\", \"n that has the best possible implementation for that operation (and if we ever found a better way, t\", \"hat method would be improved according). So we can just use that:\\n\\n```\\nprivate static string CreateS\", \"ortString(PropertyDescriptor property, ListSortDirection \\ndirection) =>\\n direction == ListSortDirect\", \"ion.Descending ?\\n $\\\"[{property.Name}] DESC\\\" :\\n $\\\"[{property.Name}]\\\";\\n```\\n\\nNote that I've expressed t\", \"hat concatenation via an interpolated string, but the C# compiler will \\\"lower\\\" this interpolated str\", \"ing to a call to string.Concat, so the IL for this is indistinguishable from if I'd instead written:\", \"\\n\\n```\\nprivate static string CreateSortString(PropertyDescriptor property, ListSortDirection \\ndirecti\", \"on) =>\\n```\\n\\n```\\n direction == ListSortDirection.Descending ?\\n string.Concat(\\\"[\\\", property.Name, \\\"] D\", \"ESC\\\") :\\n string.Concat(\\\"[\\\", property.Name, \\\"]\\\");\\n```\\n\\nAs an aside, the expanded string.Concat versio\", \"n highlights that this method could have been written to result in a bit less IL if it were instead \", \"written as:\\n\\n```\\nprivate static string CreateSortString(PropertyDescriptor property, ListSortDirecti\", \"on \\ndirection) =>\\n string.Concat(\\\"[\\\", property.Name, direction == ListSortDirection.Descending ? \\\"] \", \"DESC\\\"\\n: \\\"]\\\");\\n```\\n\\nbut this doesn't meaningfully affect performance and here clarity and maintainabi\", \"lity was more important than shaving off a few bytes.\\n\\n```\\n[Benchmark(Baseline = true)]\\n[Arguments(\\\"\", \"SomeProperty\\\", ListSortDirection.Descending)]\\npublic string WithStringBuilder(string name, ListSortD\", \"irection direction)\\n{\\n var resultString = new StringBuilder();\\n resultString.Append('[');\\n resultStr\", \"ing.Append(name);\\n resultString.Append(']');\\n if (ListSortDirection.Descending == direction)\\n {\\n res\", \"ultString.Append(\\\" DESC\\\");\\n }\\n return resultString.ToString();\\n}\\n[Benchmark]\\n[Arguments(\\\"SomePropert\", \"y\\\", ListSortDirection.Descending)]\\npublic string WithConcat(string name, ListSortDirection direction\", \") =>\\n direction == ListSortDirection.Descending?\\n $\\\"[{name}] DESC\\\" :\\n $\\\"[{name}]\\\";\\n```\\n\\n| Method    \", \"        | Mean     | Ratio | Allocated | Alloc Ratio |\\n|-------------------|----------|-------|-----\", \"------|-------------|\\n| WithStringBuilder | 68.34 ns | 1.00  | 272 B     | 1.00        |\\n| WithConca\", \"t        | 20.78 ns | 0.31  | 64 B      | 0.24        |\\n\\nThere are also places where StringBuilder w\", \"as still applicable, but it was being used on hot-enough paths that previous releases of .NET saw th\", \"e StringBuilder instance being cached. Several of the core libraries, including System.Private.CoreL\", \"ib, have an internal StringBuilderCache type which caches a StringBuilder instance in a [ThreadStati\", \"c], meaning every thread could end up having such an instance. There are several issues with this, i\", \"ncluding that the buffers employed by StringBuilder aren't usable for anything else while the String\", \"Builder isn't in use, and because of that, StringBuilderCache places a limit on the capacity of the \", \"StringBuilder instances that can be cached; attempts to cache ones longer than that result in them b\", \"eing thrown away. It'd be better instead to use cached arrays that aren't length-limited and that ev\", \"eryone has access to for sharing. Many of the core .NET libraries have an internal ValueStringBuilde\", \"r type for this purpose, a ref struct-based type that can use stackalloc'd memory to start and then \", \"if necessary grow into ArrayPool<char> arrays. And with [dotnet/runtime#64522](https://github.com/do\", \"tnet/runtime/pull/64522) and [dotnet/runtime#69683,](https://github.com/dotnet/runtime/pull/69683) m\", \"any of the\\n\\nremaining uses of StringBuilderCache have been replaced. I'm hopeful we can entirely rem\", \"ove StringBuilderCache in the future.\\n\\nIn the same vein of not doing unnecessary work, there's a fai\", \"rly common pattern that shows up with methods like string.Substring and span.Slice:\\n\\n```\\nspan = span\", \".Slice(offset, str.Length - offset);\\n```\\n\\nThe relevant thing to recognize here is these methods have\", \" overloads that take just the starting offset. Since the length being specified is the remainder aft\", \"er the specified offset, the call could instead be simplified to:\\n\\n```\\nspan = span.Slice(offset);\\n``\", \"`\\n\\nwhich is not only more readable and maintainable, it has some small efficiency benefits, e.g. on \", \"64-bit the Slice(int, int) constructor has an extra addition over Slice(int), and for 32-bit the Sli\", \"ce(int, int) constructor incurs an additional comparison and branch. It's thus beneficial for both c\", \"ode maintenance and for performance to simplify these calls, which [dotnet/runtime#68937](https://gi\", \"thub.com/dotnet/runtime/pull/68937) does for all found occurrences of that pattern. This is then mad\", \"e more impactful by [dotnet/runtime#73882,](https://github.com/dotnet/runtime/pull/73882)  which str\", \"eamlines string.Substring to remove unnecessary overheads, e.g. it condenses four argument validatio\", \"n checks down to a single fast-path comparison (in 64-bit processes).\\n\\nOk, enough about string. What\", \" about spans? One of the coolest features in C# 11 is the new support for ref fields. What is a ref \", \"field? You're familiar with refs in C# in general, and we've already discussed how they're essential\", \"ly managed pointers, i.e. pointers that the runtime can update at any time due to the object it refe\", \"rences getting moved on the heap. These references can point to the beginning of an object, or they \", \"can point somewhere inside the object, in which case they're referred to as \\\"interior pointers.\\\" ref\", \" has existed in C# since 1.0, but at that time it was primarily about passing by reference to method\", \" calls, e.g.\\n\\n```\\nclass Data\\n{\\n public int Value;\\n}\\n...\\nvoid Add(ref int i)\\n{\\n i++;\\n}\\n...\\nvar d = ne\", \"w Data { Value = 42 };\\nAdd(ref d.Value);\\nDebug.Assert(d.Value == 43);\\n```\\n\\nLater versions of C# adde\", \"d the ability to have local refs, e.g.\\n\\n```\\nvoid Add(ref int i)\\n{\\n ref j = ref i;\\n j++;\\n}\\n```\\n\\nand e\", \"ven to have ref returns, e.g.\\n\\n```\\nref int Add(ref int i)\\n{\\n ref j = ref i;\\n j++;\\n return ref j;\\n}\\n`\", \"``\\n\\nThese facilities are more advanced, but they're used liberally throughout higher-performance cod\", \"e bases, and many of the optimizations in .NET in recent years are possible in large part due to the\", \"se ref-related capabilities.\\n\\nSpan<T> and ReadOnlySpan<T> themselves are heavily-based on refs. For \", \"example, the indexer on many older collection types is implemented as a get/set property, e.g.\\n\\n```\\n\", \"private T[] _items;\\n...\\npublic T this[int i]\\n{\\n get => _items[i];\\n set => _items[i] = value;\\n}\\n```\\n\\n\", \"But not span. Span<T>'s indexer looks more like this:\\n\\n```\\npublic ref T this[int index]\\n{\\n get\\n {\\n i\", \"f ((uint)index >= (uint)_length)\\n ThrowHelper.ThrowIndexOutOfRangeException();\\n return ref Unsafe.Ad\", \"d(ref _reference, index);\\n }\\n}\\n```\\n\\nNote there's only a getter and no setter; that's because it retu\", \"rns a ref T to the actual storage location. It's a writable ref, so you can assign to it, e.g. you c\", \"an write:\\n\\n```\\nspan[i] = value;\\n```\\n\\nbut rather than that being equivalent to calling some setter:\\n\\n\", \"```\\nspan.set_Item(i, value);\\n```\\n\\nit's actually equivalent to using the getter to retrieve the ref a\", \"nd then writing a value through that ref, e.g.\\n\\n```\\nref T item = ref span.get_Item(i);\\nitem = value;\", \"\\n```\\n\\nThat's all well and good, but what's that \\\\_reference in the getter definition? Well, Span<T> \", \"is really just a tuple of two fields: a reference (to the start of the memory being referred to) and\", \" a length (how many elements from that reference are included in the span). In the past, the runtime\", \" had to hack this with an internal type (ByReference<T>) specially recognized by the runtime to be a\", \" reference. But as of C# 11 and .NET 7, ref structs can now contain ref fields, which means Span<T> \", \"today is literally defined as follows:\\n\\n```\\npublic readonly ref struct Span<T>\\n{\\n internal readonly \", \"ref T _reference;\\n private readonly int _length;\\n ...\\n}\\n```\\n\\nThe rollout of ref fields throughout [d\", \"otnet/runtime](https://github.com/dotnet/runtime) was done in [dotnet/runtime#71498,](https://github\", \".com/dotnet/runtime/pull/71498) following the C# language gaining this support primarily in [dotnet/\", \"roslyn#62155,](https://github.com/dotnet/roslyn/pull/62155) which itself was the culmination of many\", \" PRs first into a feature branch. ref fields alone doesn't itself automatically improve performance,\", \" but it does simplify code significantly, and it allows for both new custom code that uses ref field\", \"s as well as new APIs that take advantage of them, both of which can help with performance (and spec\", \"ifically performance without sacrificing potential safety). One such example of a new API is new con\", \"structors on ReadOnlySpan<T> and Span<T>:\\n\\n```\\npublic Span(ref T reference);\\npublic ReadOnlySpan(in \", \"T reference);\\n```\\n\\nadded in [dotnet/runtime#67447](https://github.com/dotnet/runtime/pull/67447) (an\", \"d then made public and used more broadly in [dotnet/runtime#71589\\\\)](https://github.com/dotnet/runti\", \"me/pull/71589). This may beg the question, why does ref field support enable two new constructors th\", \"at take refs, considering spans already were able to store a ref? After all, the MemoryMarshal.Creat\", \"eSpan(ref T reference, int length) and corresponding CreateReadOnlySpan methods have existed for as \", \"long as spans have, and these new constructors are equivalent to calling those methods with a length\", \" of 1. The answer is: safety.\\n\\nImagine if you could willy-nilly call this constructor. You'd be able\", \" to write code like this:\\n\\n```\\npublic Span<int> RuhRoh()\\n{\\n int i = 42;\\n return new Span<int>(ref i)\", \";\\n}\\n```\\n\\nAt this point the caller of this method is handed a span that refers to garbage; that's bad\", \" in code that's intended to be safe. You can already accomplish the same thing by using pointers:\\n\\n`\", \"``\\npublic Span<int> RuhRoh()\\n{\\n unsafe\\n {\\n int i = 42;\\n return new Span<int>(&i, 1);\\n }\\n}\\n```\\n\\nbut a\", \"t that point you've taken on the risk of using unsafe code and pointers and any resulting problems a\", \"re on you. With C# 11, if you now try to write the above code using the ref-based constructor, you'l\", \"l be greeted with an error like this:\\n\\n```\\nerror CS8347: Cannot use a result of 'Span<int>.Span(ref \", \"int)' in this context because it \\nmay expose variables referenced by parameter 'reference' outside o\", \"f their declaration scope\\n```\\n\\nIn other words, the compiler now understands that Span<int> as a ref \", \"struct could be storing the passed in ref, and if it does store it (which Span<T> does), this is aki\", \"n to passing a ref to a local out\\n\\nof the method, which is bad. Hence how this relates to ref fields\", \": because ref fields are now a thing, the compiler's rules for safe-handling of refs have been updat\", \"ed, which in turn enables us to expose the aforementioned constructors on {ReadOnly}Span<T>.\\n\\nAs is \", \"often the case, addressing one issue kicks the can down the road a bit and exposes another. The comp\", \"iler now believes that a ref passed to a method on a ref struct could enable that ref struct instanc\", \"e to store the ref (note that this was already the case with ref structs passed to methods on ref st\", \"ructs), but what if we don't want that? What if we want to be able to say \\\"this ref is not storable \", \"and should not escape the calling scope\\\"? From a caller's perspective, we want the compiler to allow\", \" passing in such refs without it complaining about potential extension of lifetime, and from a calle\", \"e's perspective, we want the compiler to prevent the method from doing what it's not supposed to do.\", \" Enter scoped. The new C# keyword does exactly what we just wished for: put it on a ref or ref struc\", \"t parameter, and the compiler both will guarantee (short of using unsafe code) that the method can't\", \" stash away the argument and will then enable the caller to write code that relies on that guarantee\", \". For example, consider this program:\\n\\n```\\nvar writer = new SpanWriter(stackalloc char[128]);\\nAppend\", \"(ref writer, 123);\\nwriter.Write(\\\".\\\");\\nAppend(ref writer, 45);\\nConsole.WriteLine(writer.AsSpan().ToSt\", \"ring());\\nstatic void Append(ref SpanWriter builder, byte value)\\n{\\n Span<char> tmp = stackalloc char[\", \"3];\\n value.TryFormat(tmp, out int charsWritten);\\n builder.Write(tmp.Slice(0, charsWritten));\\n}\\nref s\", \"truct SpanWriter\\n{\\n private readonly Span<char> _chars;\\n private int _length;\\n public SpanWriter(Spa\", \"n<char> destination) => _chars = destination;\\n public Span<char> AsSpan() => _chars.Slice(0, _length\", \");\\n public void Write(ReadOnlySpan<char> value)\\n {\\n if (_length > _chars.Length - value.Length)\\n {\\n \", \"throw new InvalidOperationException(\\\"Not enough remaining space\\\");\\n }\\n value.CopyTo(_chars.Slice(_le\", \"ngth));\\n _length += value.Length;\\n }\\n}\\n```\\n\\nWe have a ref struct SpanWriter that takes a Span<char> \", \"to its constructor and allows for writing to it by copying in additional content and then updating t\", \"he stored length. The Write method accepts a ReadOnlySpan<char>. And we then have a helper Append me\", \"thod which is formatting a byte into some stackalloc'd temporary space and passing the resulting for\", \"matted chars in to Write. Straightforward. Except, this doesn't compile:\\n\\nerror CS8350: This combina\", \"tion of arguments to 'SpanWriter.Write(ReadOnlySpan<char>)' is disallowed because it may expose vari\", \"ables referenced by parameter 'value' outside of their declaration scope\\n\\nWhat do we do? The Write m\", \"ethod doesn't actually store the value parameter and won't ever need to, so we can change the signat\", \"ure of the method to annotate it as scoped:\\n\\n```\\npublic void Write(scoped ReadOnlySpan<char> value)\\n\", \"```\\n\\nIf Write were then to try to store value, the compiler would balk:\\n\\n```\\nerror CS8352: Cannot us\", \"e variable 'ReadOnlySpan<char>' in this context because it may \\nexpose referenced variables outside \", \"of their declaration scope\\n```\\n\\nBut as it's not trying to do so, everything now compiles successfull\", \"y. You can see examples of how this is utilized in the aforementioned [dotnet/runtime#71589.](https:\", \"//github.com/dotnet/runtime/pull/71589)\\n\\nThere's also the other direction: there are some things tha\", \"t are implicitly scoped, like the this reference on a struct. Consider this code:\\n\\n```\\npublic struct\", \" SingleItemList\\n{\\n private int _value;\\n public ref int this[int i]\\n {\\n get\\n {\\n if (i != 0) throw new\", \" IndexOutOfRangeException();\\n return ref _value;\\n }\\n }\\n}\\n```\\n\\nThis produces a compiler error:\\n\\n```\\ne\", \"rror CS8170: Struct members cannot return 'this' or other instance members by reference\\n```\\n\\nEffecti\", \"vely, that's because this is implicitly scoped (even though that keyword wasn't previously available\", \"). What if we want to enable such an item to be returned? Enter [UnscopedRef]. This is rare enough i\", \"n need that it doesn't get its own C# language keyword, but the C# compiler does recognize the new [\", \"UnscopedRef] attribute. It can be put onto relevant parameters but also onto methods and properties,\", \" in which case it applies to the this reference for that member. As such, we can modify our previous\", \" code example to be:\\n\\n```\\n[UnscopedRef]\\npublic ref int this[int i]\\n```\\n\\nand now the code will compil\", \"e successfully. Of course, this also places demands on callers of this method. For a call site, the \", \"compiler sees the [UnscopedRef] on the member being invoked, and then knows that the returned ref mi\", \"ght reference something from that struct, and thus assigns to the returned ref the same lifetime as \", \"that struct. So, if that struct were a local living on the stack, the ref would also be limited to t\", \"hat same method.\\n\\nAnother impactful span-related change comes in [dotnet/runtime#70095](https://gith\", \"ub.com/dotnet/runtime/pull/70095) from [@teotsirpanis](https://github.com/teo-tsirpanis). System.Has\", \"hCode's goal is to provide a fast, easy-to-use implementation for producing high-quality hash codes.\", \" In its current incarnation, it incorporates a random process-wide seed and is an implementation of \", \"the xxHash32 non-cryptographic hash algorithm. In a previous release, HashCode saw the addition of a\", \"n AddBytes methods, which accepts a ReadOnlySpan<byte> and is useful for incorporating sequences of \", \"data that should be part of a type's hash code, e.g. BigInteger.GetHashCode includes all the data th\", \"at makes up the BigInteger. The xxHash32 algorithm works by accumulating 4 32-bit unsigned integers \", \"and then combining them together into the hash code; thus if you call HashCode.Add(int), the first t\", \"hree times you call it you're just storing the values separately into the instance, and then the fou\", \"rth time you call it all of those values are combined into the hash code (and there's a separate pro\", \"cess that incorporates any remaining values if the number of 32-bit values added wasn't an exact mul\", \"tiple of 4). Thus, previously AddBytes was simply implemented to repeatedly read the next 4 bytes fr\", \"om the input span and call Add(int) with those bytes as an integer. But those Add calls have overhea\", \"d. Instead, this PR skips the Add calls and directly handles the accumulation and combining of the 1\", \"6 bytes. Interestingly, it still has to deal with the possibility that previous calls to Add may hav\", \"e left some state queued, which means (with the current implementation at least), if there are multi\", \"ple pieces of state to include in the hash code, say a ReadOnlySpan<byte> and an additional int, it'\", \"s more efficient to add the span first and then the int rather than the other way around. So for exa\", \"mple when [dotnet/runtime#71274](https://github.com/dotnet/runtime/pull/71274) from [@huoyaoyuan](ht\", \"tps://github.com/huoyaoyuan) changed BigInteger.GetHashCode to use HashCode.AddBytes, it coded the m\", \"ethod to first call AddBytes with the BigInteger's \\\\_bits and *then* call Add with the \\\\_sign.\\n\\n```\\n\", \"private byte[] _data = Enumerable.Range(0, 256).Select(i => (byte)i).ToArray();\\n[Benchmark]\\npublic i\", \"nt AddBytes()\\n{\\n HashCode hc = default;\\n hc.AddBytes(_data);\\n return hc.ToHashCode();\\n}\\n```\\n\\n| Metho\", \"d   | Runtime  | Mean      | Ratio |\\n|----------|----------|-----------|-------|\\n| AddBytes | .NET 6\", \".0 | 159.11 ns | 1.00  |\\n| AddBytes | .NET 7.0 | 42.11 ns  | 0.26  |\\n\\nAnother span-related change, [\", \"dotnet/runtime#72727](https://github.com/dotnet/runtime/pull/72727) refactored a bunch of code paths\", \" to eliminate some cached arrays. Why avoid cached arrays? After all, isn't it desirable to cache an\", \" array once and reuse it over and over again? It is, if that's the best option, but sometimes there \", \"are better options. For example, one of the changes took code like:\\n\\n```\\nprivate static readonly cha\", \"r[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' };\\n...\\nint index = value.IndexOfAny(s_pathDelims);\\n```\", \"\\n\\nand replaced it with code like:\\n\\n```\\nint index = value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\n```\\n\\nThis ha\", \"s a variety of benefits. There's the usability benefit of keeping the tokens being searched close to\", \" the use site, and the usability benefit of the list being immutable such that some code somewhere w\", \"on't accidentally replace a value in the array. But there are also performance benefits. We don't ne\", \"ed an extra field to store the array. We don't need to allocate the array as part of this type's sta\", \"tic constructor. And loading/using the string is slightly faster.\\n\\n```\\nprivate static readonly char[\", \"] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' };\\nprivate static readonly string s_value = \\\"abcdefghijk\", \"lmnopqrstuvwxyz\\\";\\n[Benchmark]\\npublic int WithArray() => s_value.IndexOfAny(s_pathDelims);\\n[Benchmark\", \"]\\npublic int WithString() => s_value.AsSpan().IndexOfAny(@\\\":\\\\/?#\\\");\\n```\\n\\n| Method     | Mean     | R\", \"atio |\\n|------------|----------|-------|\\n| WithArray  | 8.601 ns | 1.00  |\\n| WithString | 6.949 ns |\", \" 0.81  |\\n\\nAnother example from that PR took code along the lines of:\\n\\n```\\nprivate static readonly ch\", \"ar[] s_whitespaces = new char[] { ' ', '\\\\t', '\\\\n', '\\\\r' };\\n...\\nswitch (attr.Value.Trim(s_whitespaces\", \"))\\n{\\n case \\\"preserve\\\": return Preserve;\\n case \\\"default\\\": return Default;\\n}\\n```\\n\\nand replaced it with\", \" code like:\\n\\n```\\nswitch (attr.Value.AsSpan().Trim(\\\" \\\\t\\\\n\\\\r\\\"))\\n{\\n case \\\"preserve\\\": return Preserve;\\n \", \"case \\\"default\\\": return Default;\\n}\\n```\\n\\nIn this case, not only have we avoided the char[], but if the\", \" text did require any trimming of whitespaces, the new version (which trims a span instead of the or\", \"iginal string) will save an allocation for the trimmed string. This is taking advantage of the new C\", \"# 11 feature that supports switching on ReadOnlySpan<char>s just as you can switch on strings, added\", \" in [dotnet/roslyn#44388](https://github.com/dotnet/roslyn/pull/44388) from [@YairHalberstadt](https\", \"://github.com/YairHalberstadt). [dotnet/runtime#68831](https://github.com/dotnet/runtime/pull/68831)\", \" also took advantage of this in several additional places.\\n\\nOf course, in some cases the arrays are \", \"entirely unnecessary. In that same PR, there were several cases like this:\\n\\n```\\nprivate static reado\", \"nly char[] WhiteSpaceChecks = new char[] { ' ', '\\\\u00A0' };\\n...\\nint wsIndex = target.IndexOfAny(Whit\", \"eSpaceChecks, targetPosition);\\nif (wsIndex < 0)\\n{\\n return false;\\n}\\n```\\n\\nBy switching to use spans, a\", \"gain, we can instead write it like this:\\n\\n```\\nint wsIndex = target.AsSpan(targetPosition).IndexOfAny\", \"(' ', '\\\\u00A0');\\nif (wsIndex < 0)\\n{\\n return false;\\n}\\nwsIndex += targetPosition;\\n```\\n\\nMemoryExtension\", \"s.IndexOfAny has a dedicated overload for two and three arguments, at which point we don't need the \", \"array at all (these overloads also happen to be faster; when passing an array of two chars, the impl\", \"ementation would extract the two chars from the array and pass them off to the same two-argument imp\", \"lementation). Multiple other PRs similarly removed array allocations. [dotnet/runtime#60409](https:/\", \"/github.com/dotnet/runtime/pull/60409) removed a single-char array that was cached to be able to pas\", \"s it to string.Split and replaced it with usage of the Split overload that directly accepts a single\", \" char.\\n\\nFinally, [dotnet/runtime#59670](https://github.com/dotnet/runtime/pull/59670) from [@NewellC\", \"lark](https://github.com/NewellClark) got rid of even more arrays. We saw earlier how the C# compile\", \"r special-cases byte[]s constructed with a constant length and constant elements and that's immediat\", \"ely cast to a ReadOnlySpan<byte>. Thus, it can be beneficial any time there's such a byte[] being ca\", \"ched to instead expose it as a ReadOnlySpan<byte>. As I discussed in the [.NET 6](https://devblogs.m\", \"icrosoft.com/dotnet/performance-improvements-in-net-6) post, this avoids even the one-time array all\", \"ocation you'd get for a cached array, results in much more efficient access, and supplies to the JIT\", \" compiler more information that enables it to more heavily optimize\\u2026 goodness all around. This PR re\", \"moved even more arrays in this manner, as did [dotnet/runtime#60411,](https://github.com/dotnet/runt\", \"ime/pull/60411) [dotnet/runtime#72743,](https://github.com/dotnet/runtime/pull/72743) [dotnet/runtim\", \"e#73115](https://github.com/dotnet/runtime/pull/73115) from [@vcsjones](https://github.com/vcsjones)\", \", and [dotnet/runtime#70665.](https://github.com/dotnet/runtime/pull/70665)\\n\\n**CHAPTER** 11\\n\\n## <spa\", \"n id=\\\"page-132-0\\\"></span>Regex\\n\\nBack in May, I shared a fairly detailed post about the improvements \", \"coming to [Regular Expressions in](https://devblogs.microsoft.com/dotnet/regular-expression-improvem\", \"ents-in-dotnet-7)  [.NET 7.](https://devblogs.microsoft.com/dotnet/regular-expression-improvements-i\", \"n-dotnet-7) As a recap, prior to .NET 5, Regex's implementation had largely been untouched for quite\", \" some time. In .NET 5, we brought it back up to be on par with or better than multiple other industr\", \"y implementations from a performance perspective. .NET 7 takes some significant leaps forward from t\", \"hat. If you haven't read the post yet, please go ahead and do so now; I'll wait\\u2026\\n\\nWelcome back. With\", \" that context, I'll avoid duplicating content here, and instead focus on how exactly these improveme\", \"nts came about and the PRs that did so.\\n\\n#### <span id=\\\"page-132-1\\\"></span>**RegexOptions.NonBacktra\", \"cking**\\n\\nLet's start with one of the larger new features in Regex, the new RegexOptions.NonBacktrack\", \"ing implementation. As discussed in the previous post, RegexOptions.NonBacktracking switches the pro\", \"cessing of Regex over to using a new engine based in finite automata. It has two primary modes of ex\", \"ecution, one that relies on DFAs (deterministic finite automata) and one that relies on NFAs (nondet\", \"erministic finite automata). Both implementations provide a very valuable guarantee: processing time\", \" is linear in the length of the input. Whereas a backtracking engine (which is what Regex uses if No\", \"nBacktracking isn't specified) can hit a situation known as \\\"catastrophic backtracking,\\\" where probl\", \"ematic expressions combined with problematic input can result in exponential processing in the lengt\", \"h of the input, NonBacktracking guarantees it'll only ever do an ammortized-constant amount of work \", \"per character in the input. In the case of a DFA, that constant is very small. With an NFA, that con\", \"stant can be much larger, based on the complexity of the pattern, but for any given pattern the work\", \" is still linear in the length of the input.\\n\\nA significant number of years of development went into\", \" the NonBacktracking implementation, which was initially added into [dotnet/runtime](https://github.\", \"com/dotnet/runtime) in [dotnet/runtime#60607.](https://github.com/dotnet/runtime/pull/60607) However\", \", the original research and implementation for it actually came from Microsoft Research (MSR), and w\", \"as available as an experimental package in the form of the Symbolic Regex Matcher (SRM) library publ\", \"ished by MSR. You can still see vestiges of this in the current code now in .NET 7, but it's evolved\", \" significantly, in tight collaboration between developers on the .NET team and the researchers at MS\", \"R (prior to being integrated in [dotnet/runtime,](https://github.com/dotnet/runtime) it was incubate\", \"d for over a year in [dotnet/runtimelab,](https://github.com/dotnet/runtimelab) where the original S\", \"RM code was brought in via [dotnet/runtimelab#588](https://github.com/dotnet/runtimelab/pull/588) fr\", \"om [@veanes](https://github.com/veanes)).\\n\\nThis implementation is based on the notion of regular exp\", \"ression derivatives, a concept that's been around for decades (the term was originally coined in a p\", \"aper by Janusz Brzozowski in the 1960s) and which has been significantly advanced for this implement\", \"ation. Regex derivatives form the basis for how the automata (think \\\"graph\\\") used to process input a\", \"re constructed. The idea at its core is fairly simple: take a regex and process a single character\\u2026 \", \"what is the new regex you get to describe what remains after processing that one character? That's t\", \"he derivative. For example, given the regex \\\\w{3}\\n\\nto match three word characters, if you apply this\", \" to the next input character 'a', well, that will strip off the first \\\\w, leaving us with the deriva\", \"tive \\\\w{2}. Simple, right? How about something more complicated, like the expression .\\\\*(the|he). Wh\", \"at happens if the next character is a t? Well, it's possible that t could be consumed by the .\\\\* at \", \"the beginning of the pattern, in which case the remaining regex would be exactly the same as the sta\", \"rting one (.\\\\*(the|he)), since after matching t we could still match exactly the same input as witho\", \"ut the t. But, the t could have also been part of matching the, and applied to the, we'd strip off t\", \"he t and be left with he, so now our derivative is .\\\\*(the|he)|he. Then what about the he in the ori\", \"ginal alternation? t doesn't match h, so the derivative would be nothing, which we'll express here a\", \"s an empty character class, giving us .\\\\*(the|he)|he|[]. Of course, as part of an alternation, that \", \"\\\"nothing\\\" at the end is a nop, and so we can simplify the whole derivative to just .\\\\*(the|he)|he\\u2026 d\", \"one. That was all when applying the original pattern against a next t. What if it was against an h i\", \"nstead? Following the same logic as for the t, this time we end up with .\\\\*(the|he)|e. And so on. Wh\", \"at if we instead start with the h derivative and the next character is an e? Then we're taking the p\", \"attern .\\\\*(the|he)|e and applying it to e. Against the left side of the alternation, it can be consu\", \"med by the .\\\\* (but doesn't match either t or h), and so we just end up with that same subexpression\", \". But against the right side of the alternation, e matches e, leaving us with the empty string (): .\", \"\\\\*(the|he)|(). At the point where a pattern is \\\"nullable\\\" (it can match the empty string), that can \", \"be considered a match. We can visualize this whole thing as a graph, with transitions for every inpu\", \"t character to the derivative that comes from applying it.\\n\\n![](_page_134_Figure_0.jpeg)\\n\\nLooks an a\", \"wful lot like a DFA, doesn't it? It should. And that's exactly how NonBacktracking constructs the DF\", \"As it uses to process input. For every regex construct (concatenations, alternations, loops, etc.) t\", \"he engine knows how to derive the next regex based on the character being evaluated. This applicatio\", \"n is done lazily, so we have an initial starting state (the original pattern), and then when we eval\", \"uate the next character in the input, it looks to see whether there's already a derivative available\", \" for that transition: if there is, it follows it, and if there isn't, it dynamically/lazily derives \", \"the next node in the graph. At its core, that's how it works.\\n\\nOf course, the devil is in the detail\", \"s and there's a ton of complication and engineering smarts that go into making the engine efficient.\", \" One such example is a tradeoff between memory consumption and throughput. Given the ability to have\", \" any char as input, you could have effectively ~65K transitions out of every node (e.g. every node c\", \"ould need a ~65K element table); that would significantly increase memory consumption. However, if y\", \"ou actually had that many transitions, it's very likely a significant majority of them would point t\", \"o the same target node. Thus, NonBacktracking maintains its own groupings of characters into what it\", \" calls \\\"minterms.\\\" If two characters will have exactly the same transition, they're part of the same\", \" minterm. The transitions are then constructed in terms of minterms, with at most one transition per\", \" minterm out of a given node. When the next input character is read, it maps that to a minterm ID, a\", \"nd then finds the appropriate transition for that ID; one additional level of indirection in order t\", \"o save a potentially huge amount of memory. That mapping is handled via an array bitmap for ASCII an\", \"d an efficient data structure known as a [Binary Decision](https://en.wikipedia.org/wiki/Binary_deci\", \"sion_diagram)  [Diagram \\\\(BDD\\\\)](https://en.wikipedia.org/wiki/Binary_decision_diagram) for everythi\", \"ng above 0x7F.\\n\\nAs noted, the non-backtracking engine is linear in the length of the input. But that\", \" doesn't mean it always looks at each input character exactly once. If you call Regex.IsMatch, it do\", \"es; after all, IsMatch only needs to determine whether there is a match and doesn't need to compute \", \"any additional information, such as where the match actual starts or ends, any information on captur\", \"es, etc. Thus, the engine can simply employ its automata to walk along the input, transitioning from\", \" node to node in the graph until it comes to a final state or runs out of input. Other operations, h\", \"owever, do require it to gather more information. Regex.Match needs to compute everything, and that \", \"can actually entail multiple walks over the input. In the initial implementation, the equivalent of \", \"Match would always take three passes: match forwards to find the end of *a* match, then match a reve\", \"rsed-copy of the pattern in reverse from that ending location in order to find where the match actua\", \"lly starts, and then once more walk forwards from that known starting position to find the actual en\", \"ding position. However, with [dotnet/runtime#68199](https://github.com/dotnet/runtime/pull/68199) fr\", \"om [@olsaarik](https://github.com/olsaarik), unless captures are required, it can now be done in onl\", \"y two passes: once forward to find the guaranteed ending location of the match, and then once in rev\", \"erse to find its starting location. And [dotnet/runtime#65129](https://github.com/dotnet/runtime/pul\", \"l/65129) from [@olsaarik](https://github.com/olsaarik) added captures support, which the original im\", \"plementation also didn't have. This captures support adds back a third pass, such that once the boun\", \"ds of the match are known, the engine runs the forward pass one more time, but this time with an NFA\", \"-based \\\"simulation\\\" that is able to record \\\"capture effects\\\" on transitions. All of this enables the\", \" nonbacktracking implementation to have the exact same semantics as the backtracking engines, always\", \" producing the same matches in the same order with the same capture information. The only difference\", \" in this regard is, whereas with the backtracking engines capture groups inside of loops will store \", \"all values captured in every iteration of the loop, only the last iteration is stored with the nonba\", \"cktracking implementation. On top of that, there are a few constructs the non-backtracking\\n\\nimplemen\", \"tation simply doesn't support, such that attempting to use any of those will fail when trying to con\", \"struct the Regex, e.g. backreferences and lookarounds.\\n\\nEven after its progress as a standalone libr\", \"ary from MSR, more than 100 PRs went into making RegexOptions.NonBacktracking what it is now in .NET\", \" 7, including optimizations like [dotnet/runtime#70217](https://github.com/dotnet/runtime/pull/70217\", \") from [@olsaarik](https://github.com/olsaarik) that tries to streamline the tight inner matching lo\", \"op at the heart of the DFA (e.g. read the next input character, find the appropriate transition to t\", \"ake, move to the next node, and check information about the node like whether it's a final state) an\", \"d optimizations like [dotnet/runtime#65637](https://github.com/dotnet/runtime/pull/65637) from [@vea\", \"nes](https://github.com/veanes) that optimized the NFA mode to avoid superfluous allocations, cachin\", \"g and reusing list and set objects to make the handling of the lists of states ammortized allocation\", \"-free.\\n\\nThere's one more set of PRs of performance interest for NonBacktracking. The Regex implement\", \"ation for taking patterns and turning them into something processable, regardless of which of the mu\", \"ltiple engines is being used, is essentially a compiler, and as with many compilers, it naturally le\", \"nds itself to recursive algorithms. In the case of Regex, those algorithms involve walking around tr\", \"ees of regular expression constructs. Recursion ends up being a very handy way of expressing these a\", \"lgorithms, but recursion also suffers from the possibility of stack overflow; essentially it's using\", \" stack space as scratch space, and if it ends up using too much, things go badly. One common approac\", \"h to dealing with this is turning the recursive algorithm into an iterative one, which typically inv\", \"olves using an explicit stack of state rather than the implicit one. The nice thing about this is th\", \"e amount of state you can store is limited only by how much memory you have, as opposed to being lim\", \"ited by your thread's stack space. The downsides, however, are that it's typically much less natural\", \" to write the algorithms in this manner, and it typically requires allocating heap space for the sta\", \"ck, which then leads to additional complications if you want to avoid that allocation, such as vario\", \"us kinds of pooling. [dotnet/runtime#60385](https://github.com/dotnet/runtime/pull/60385) introduces\", \" a different approach for Regex, which is then used by [dotnet/runtime#60786](https://github.com/dot\", \"net/runtime/pull/60786) from [@olsaarik](https://github.com/olsaarik) specifically in the NonBacktra\", \"cking implementation. It still uses recursion, and thus benefits from the expressiveness of the recu\", \"rsive algorithm as well as being able to use stack space and thus avoid additional allocation in the\", \" most common cases, but then to avoid stack overflows, it issues explicit checks to ensure we're not\", \" too deep on the stack (.NET has long provided the helpers\\n\\nRuntimeHelpers.EnsureSufficientExecution\", \"Stack and\\n\\nRuntimeHelpers.TryEnsureSufficientExecutionStack for this purpose). If it detects it's to\", \"o deep on the stack, it forks off continued execution into another thread. Hitting this condition is\", \" expensive, but it's very rarely if ever actually hit in practice (e.g. the only time it's hit in ou\", \"r vast functional tests are in the tests explicitly written to stress it), it keeps the code simple,\", \" and it keeps the typical cases fast. A similar approach is used in other areas of [dotnet/runtime,]\", \"(https://github.com/dotnet/runtime) such as in System.Linq.Expressions.\\n\\nAs was mentioned in my prev\", \"ious blog post about regular expressions, both the backtracking implementations and the non-backtrac\", \"king implementation have their place. The main benefit of the non-backtracking implementation is pre\", \"dictability: because of the linear processing guarantee, once you've constructed the regex, you don'\", \"t need to worry about malicious inputs causing worst-case behavior in the processing of your potenti\", \"ally susceptible expressions. This doesn't mean RegexOptions.NonBacktracking is always the fastest; \", \"in fact, it's frequently not. In exchange for reduced best-case performance, it provides the best wo\", \"rst-case performance, and for some kinds of applications, that's a really worthwhile and valuable tr\", \"adeoff.\\n\\n#### <span id=\\\"page-137-0\\\"></span>**New APIs**\\n\\nRegex gets several new methods in .NET 7, a\", \"ll of which enable improved performance. The simplicity of the new APIs likely also misrepresents ho\", \"w much work was necessary to enable them, in particular because the new APIs all support ReadOnlySpa\", \"n<char> inputs into the regex engines.\\n\\n[dotnet/runtime#65473](https://github.com/dotnet/runtime/pul\", \"l/65473) brings Regex into the span-based era of .NET, overcoming a significant limitation in Regex \", \"since spans were introduced back in .NET Core 2.1. Regex has historically been based on processing S\", \"ystem.String inputs, and that fact pervades the Regex design and implementation, including the APIs \", \"exposed for the extensibility model Regex.CompileToAssembly relied on in .NET Framework (CompileToAs\", \"sembly is now obsoleted and has never been functional in .NET Core). One subtly that relies on the n\", \"ature of string as the input is how match information is returned to callers. Regex.Match returns a \", \"Match object that represents the first match in the input, and that Match object exposes a NextMatch\", \" method that enables moving to the next match. That means the Match object needs to store a referenc\", \"e to the input, so that it can be fed back into the matching engine as part of such a NextMatch call\", \". If that input is a string, great, no problem. But if that input is a ReadOnlySpan<char>, that span\", \" as a ref struct can't be stored on the class Match object, since ref structs can only live on the s\", \"tack and not the heap. That alone would make it a challenge to support spans, but the problem is eve\", \"n more deeply rooted. All of the regex engines rely on a RegexRunner, a base class that stores on it\", \" all of the state necessary to feed into the FindFirstChar and Go methods that compose the actual ma\", \"tching logic for the regular expressions (these methods contain all of the core code for performing \", \"the match, with FindFirstChar being an optimization to skip past input positions that couldn't possi\", \"bly start a match and then Go performing the actual matching logic). If you look at the internal Reg\", \"exInterpreter type, which is the engine you get when you construct a new Regex(...) without the Rege\", \"xOptions.Compiled or RegexOptions.NonBacktracking flags, it derives from RegexRunner. Similarly, whe\", \"n you use RegexOptions.Compiled, it hands off the dynamic methods it reflection emits to a type deri\", \"ved from RegexRunner, RegexOptions.NonBacktracking has a SymbolicRegexRunnerFactory that produces ty\", \"pes derived from RegexRunner, and so on. Most relevant here, RegexRunner is public, because the type\", \"s generated by the Regex.CompileToAssembly type (and now the regex source generator) include ones de\", \"rived from this RegexRunner. Those FindFirstChar and Go methods are thus abstract and protected, and\", \" parameterless, because they pick up all the state they need from protected members on the base clas\", \"s. That includes the string input to process. So what about spans? We could of course have just call\", \"ed ToString() on an input ReadOnlySpan<char>. That would have been functionally correct, but would h\", \"ave completely defeated the purpose of accepting spans, and worse, would have been so unexpected as \", \"to likely cause consuming apps to be worse performing than they would have without the APIs. Instead\", \", we needed a new approach and new APIs.\\n\\nFirst, we made FindFirstChar and Go virtual instead of abs\", \"tract. The design that splits these methods is largely antiquated, and in particular the forced sepa\", \"ration between a stage of processing where you find the next possible location of a match and then a\", \" stage where you actually perform the match at that location doesn't align well with all engines, li\", \"ke the one used by NonBacktracking (which initially implemented FindFirstChar as a nop and had all i\", \"ts logic in Go). Then we added a new virtual Scan method which, importantly, takes a ReadOnlySpan<ch\", \"ar> as a parameter; the span can't be exposed from the base RegexRunner and must be passed in. We th\", \"en implemented FindFirstChar and Go in terms of Scan, and made them \\\"just work.\\\" Then, all of the en\", \"gines are implemented in terms of that\\n\\nspan; they no longer need to access the protected RegexRunne\", \"r.runtext, RegexRunner.runtextbeg, and RegexRunner.runtextend members that surface the input; they'r\", \"e just handed the span, already sliced to the input region, and process that. One of the neat things\", \" about this from a performance perspective is it enables the JIT to do a better job at shaving off v\", \"arious overheads, in particular around bounds checking. When the logic is implemented in terms of st\", \"ring, in addition to the input string itself the engine is also handed the beginning and end of the \", \"region of the input to process (since the developer could have called a method like Regex.Match(stri\", \"ng input, int beginning, int length) in order to only process a substring). Obviously the engine mat\", \"ching logic is way more complicated than this, but simplifying, imagine the entirety of the engine w\", \"as just a loop over the input. With the input, beginning, and length, that would look like:\\n\\n```\\n[Be\", \"nchmark]\\n[Arguments(\\\"abc\\\", 0, 3)]\\npublic void Scan(string input, int beginning, int length)\\n{\\n for (\", \"int i = beginning; i < length; i++)\\n {\\n Check(input[i]);\\n }\\n}\\n[MethodImpl(MethodImplOptions.Aggressi\", \"veInlining)]\\nprivate void Check(char c) { }\\n```\\n\\nThat will result in the JIT generating assembly cod\", \"e along the lines of this:\\n\\n```\\n; Program.Scan(System.String, Int32, Int32)\\n sub rsp,28\\n cmp r8d,r9d\", \"\\n jge short M00_L01\\n mov eax,[rdx+8]\\nM00_L00:\\n cmp r8d,eax\\n jae short M00_L02\\n inc r8d\\n cmp r8d,r9d\\n\", \" jl short M00_L00\\nM00_L01:\\n add rsp,28\\n ret\\nM00_L02:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total by\", \"tes of code 36\\n```\\n\\nIn contrast, if we're dealing with a span, which already factors in the bounds, \", \"then we can write a more canonical loop like this:\\n\\n```\\n[Benchmark]\\n[Arguments(\\\"abc\\\")]\\npublic void S\", \"can(ReadOnlySpan<char> input)\\n{\\n for (int i = 0; i < input.Length; i++)\\n {\\n Check(input[i]);\\n }\\n}\\n``\", \"`\\n\\n```\\n[MethodImpl(MethodImplOptions.AggressiveInlining)]\\nprivate void Check(char c) { }\\n```\\n\\nAnd wh\", \"en it comes to compilers, something in a canonical form is really good, because the more common the \", \"shape of the code, the more likely it is to be heavily optimized:\\n\\n```\\n; Program.Scan(System.ReadOnl\", \"ySpan`1<Char>)\\n mov rax,[rdx]\\n mov edx,[rdx+8]\\n xor ecx,ecx\\n test edx,edx\\n jle short M00_L01\\nM00_L00\", \":\\n mov r8d,ecx\\n movsx r8,word ptr [rax+r8*2]\\n inc ecx\\n cmp ecx,edx\\n jl short M00_L00\\nM00_L01:\\n ret\\n;\", \" Total bytes of code 27\\n```\\n\\nSo even without all the other benefits that come from operating in term\", \"s of span, we immediately get low-level code generation benefits from performing all the logic in te\", \"rms of spans. While the above example was made up (obviously the matching logic does more than a sim\", \"ple for loop), here's a real example. When a regex contains a \\\\b, as part of evaluating the input ag\", \"ainst that \\\\b the backtracking engines call a RegexRunner.IsBoundary helper method which checks whet\", \"her the character at the current position is a word character and whether the character before it is\", \" a word character (factoring in the bounds of the input as well). Here's what the IsBoundary method \", \"based on string looked like (the runtext it's using is the name of the string field on RegexRunner t\", \"hat stores the input):\\n\\n```\\n[Benchmark]\\n[Arguments(0, 0, 26)]\\npublic bool IsBoundary(int index, int \", \"startpos, int endpos)\\n{\\n return (index > startpos && IsBoundaryWordChar(runtext[index - 1])) !=\\n (in\", \"dex < endpos && IsBoundaryWordChar(runtext[index]));\\n}\\n[MethodImpl(MethodImplOptions.NoInlining)]\\npr\", \"ivate bool IsBoundaryWordChar(char c) => false;\\n```\\n\\nand here's what the span version looks like:\\n\\n`\", \"``\\n[Benchmark]\\n[Arguments(\\\"abcdefghijklmnopqrstuvwxyz\\\", 0)]\\npublic bool IsBoundary(ReadOnlySpan<char\", \"> inputSpan, int index)\\n{\\n int indexM1 = index - 1;\\n return ((uint)indexM1 < (uint)inputSpan.Length \", \"&& \\nIsBoundaryWordChar(inputSpan[indexM1])) !=\\n ((uint)index < (uint)inputSpan.Length && IsBoundaryW\", \"ordChar(inputSpan[index]));\\n}\\n[MethodImpl(MethodImplOptions.NoInlining)]\\nprivate bool IsBoundaryWord\", \"Char(char c) => false;\\n```\\n\\n```\\n; Program.IsBoundary(Int32, Int32, Int32)\\n push rdi\\n push rsi\\n push \", \"rbp\\n push rbx\\n sub rsp,28\\n mov rdi,rcx\\n mov esi,edx\\n mov ebx,r9d\\n cmp esi,r8d\\n jle short M00_L00\\n mo\", \"v rcx,rdi\\n mov rcx,[rcx+8]\\n lea edx,[rsi-1]\\n cmp edx,[rcx+8]\\n jae short M00_L04\\n mov edx,edx\\n movzx \", \"edx,word ptr [rcx+rdx*2+0C]\\n mov rcx,rdi\\n call qword ptr [Program.IsBoundaryWordChar(Char)]\\n jmp sho\", \"rt M00_L01\\nM00_L00:\\n xor eax,eax\\nM00_L01:\\n mov ebp,eax\\n cmp esi,ebx\\n jge short M00_L02\\n mov rcx,rdi\\n\", \" mov rcx,[rcx+8]\\n cmp esi,[rcx+8]\\n jae short M00_L04\\n mov edx,esi\\n movzx edx,word ptr [rcx+rdx*2+0C]\", \"\\n mov rcx,rdi\\n call qword ptr [Program.IsBoundaryWordChar(Char)]\\n jmp short M00_L03\\nM00_L02:\\n xor ea\", \"x,eax\\nM00_L03:\\n cmp ebp,eax\\n setne al\\n movzx eax,al\\n add rsp,28\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n\", \" ret\\nM00_L04:\\n call CORINFO_HELP_RNGCHKFAIL\\n int 3\\n; Total bytes of code 117\\n; Program.IsBoundary(Sy\", \"stem.ReadOnlySpan`1<Char>, Int32)\\n push r14\\n push rdi\\n push rsi\\n push rbp\\n```\\n\\n```\\n push rbx\\n sub rs\", \"p,20\\n mov rdi,rcx\\n mov esi,r8d\\n mov rbx,[rdx]\\n mov ebp,[rdx+8]\\n lea edx,[rsi-1]\\n cmp edx,ebp\\n jae sh\", \"ort M00_L00\\n mov edx,edx\\n movzx edx,word ptr [rbx+rdx*2]\\n mov rcx,rdi\\n call qword ptr [Program.IsBou\", \"ndaryWordChar(Char)]\\n jmp short M00_L01\\nM00_L00:\\n xor eax,eax\\nM00_L01:\\n mov r14d,eax\\n cmp esi,ebp\\n j\", \"ae short M00_L02\\n mov edx,esi\\n movzx edx,word ptr [rbx+rdx*2]\\n mov rcx,rdi\\n call qword ptr [Program.\", \"IsBoundaryWordChar(Char)]\\n jmp short M00_L03\\nM00_L02:\\n xor eax,eax\\nM00_L03:\\n cmp r14d,eax\\n setne al\\n\", \" movzx eax,al\\n add rsp,20\\n pop rbx\\n pop rbp\\n pop rsi\\n pop rdi\\n pop r14\\n ret\\n; Total bytes of code 94\", \"\\n```\\n\\nThe most interesting thing to notice here is the:\\n\\n```\\ncall CORINFO_HELP_RNGCHKFAIL\\nint 3\\n```\\n\", \"\\nat the end of the first version that doesn't exist at the end of the second. As we saw earlier, thi\", \"s is what the generated assembly looks like when the JIT is emitting the code to throw an index out \", \"of range exception for an array, string, or span. It's at the end because it's considered to be \\\"col\", \"d,\\\" rarely executed. It exists in the first because the JIT can't prove based on local analysis of t\", \"hat function that the runtext[index-1] and runtext[index] accesses will be in range of the string (i\", \"t can't know or trust any implied relationship between startpos, endpos, and the bounds of runtext).\", \" But in the second, the JIT can know and trust that the ReadOnlySpan<char>'s lower bound is 0 and up\", \"per bound (exclusive) is the span's Length, and with how the method is constructed, it can then prov\", \"e that the span accesses are always in bound. As such, it doesn't need to emit any bounds checks in \", \"the method, and the method then lacks the tell-tale signature of the index out of range throw. You c\", \"an see more examples of taking advantage of spans now being at the heart of the all of the engines i\", \"n\\n\\n[dotnet/runtime#66129,](https://github.com/dotnet/runtime/pull/66129) [dotnet/runtime#66178,](htt\", \"ps://github.com/dotnet/runtime/pull/66178) and [dotnet/runtime#72728,](https://github.com/dotnet/run\", \"time/pull/72728) all of which clean up unnecessary checks against the bounds that are then always 0 \", \"and span.Length.\\n\\nOk, so the engines are now able to be handed span inputs and process them, great, \", \"what can we do with that? Well, Regex.IsMatch is easy: it's not encumbered by needing to perform mul\", \"tiple matches, and thus doesn't need to worry about how to store that input ReadOnlySpan<char> for t\", \"he next match. Similarly, the new Regex.Count, which provides an optimized implementation for counti\", \"ng how many matches there are in the input, can bypass using Match or MatchCollection, and thus can \", \"easily operate over spans as well; [dotnet/runtime#64289](https://github.com/dotnet/runtime/pull/642\", \"89) added string-based overloads, and [dotnet/runtime#66026](https://github.com/dotnet/runtime/pull/\", \"66026) added span-based overloads. We can optimize Count further by passing additional information i\", \"nto the engines to let them know how much information they actually need to compute. For example, I \", \"noted previously that NonBacktracking is fairly pay-for-play in how much work it needs to do relativ\", \"e to what information it needs to gather. It's cheapest to just determine whether there is a match, \", \"as it can do that in a single forward pass through the input. If it also needs to compute the actual\", \" starting and ending bounds, that requires another reverse pass through some of the input. And if it\", \" then also needs to compute capture information, that requires yet another forward pass based on an \", \"NFA (even if the other two were DFA-based). Count needs the bounds information, as it needs to know \", \"where to start looking for the next match, but it doesn't need the capture information, since none o\", \"f that capture information is handed back to the caller. [dotnet/runtime#68242](https://github.com/d\", \"otnet/runtime/pull/68242) updates the engines to receive this additional information, such that meth\", \"ods like Count can be made more efficient.\\n\\nSo, IsMatch and Count can work with spans. But we still \", \"don't have a method that lets you actually get back that match information. Enter the new EnumerateM\", \"atches method, added by [dotnet/runtime#67794.](https://github.com/dotnet/runtime/pull/67794) Enumer\", \"ateMatches is very similar to Match, except instead of handing back a Match class instance, it hands\", \" back a ref struct enumerator:\\n\\n```\\npublic ref struct ValueMatchEnumerator\\n{\\n private readonly Regex\", \" _regex;\\n private readonly ReadOnlySpan<char> _input;\\n private ValueMatch _current;\\n private int _st\", \"artAt;\\n private int _prevLen;\\n ...\\n}\\n```\\n\\nBeing a ref struct, the enumerator is able to store a refe\", \"rence to the input span, and is thus able to iterate through matches, which are represented by the V\", \"alueMatch ref struct. Notably, today ValueMatch doesn't provide capture information, which also enab\", \"les it to partake in the optimizations previously mentioned for Count. Even if you have an input str\", \"ing, EnumerateMatches is thus a way to have ammortized allocation-free enumeration of all matches in\", \" the input. In .NET 7, though, there isn't a way to have such allocation-free enumeration if you als\", \"o need all the capture data. That's something we'll investigate designing in the future if/as needed\", \".\\n\\n#### <span id=\\\"page-142-0\\\"></span>**TryFindNextPossibleStartingPosition**\\n\\nAs noted earlier, the \", \"core of all of the engines is a Scan(ReadOnlySpan<char>) method that accepts the input text to match\", \", combines that with positional information from the base instance, and exits\\n\\nwhen it either finds \", \"the location of the next match or exhausts the input without finding another. For the backtracking e\", \"ngines, the implementation of that method is logically as follows:\\n\\n```\\nprotected override void Scan\", \"(ReadOnlySpan<char> inputSpan)\\n{\\n while (!TryMatchAtCurrentPosition(inputSpan) &&\\n base.runtextpos !\", \"= inputSpan.Length)\\n {\\n base.runtextpos++;\\n }\\n}\\n```\\n\\nWe try to match the input at the current positi\", \"on, and if we're successful in doing so, that's it, we exit. If the current position doesn't match, \", \"however, then if there's any input remaining we \\\"bump\\\" the position and start the process over. In r\", \"egex engine terminology, this is often referred to as a \\\"bumpalong loop.\\\" However, if we actually ra\", \"n the full matching process at every input character, that could be unnecessarily slow. For many pat\", \"terns, there's something about the pattern that would enable us to be more thoughtful about where we\", \" perform full matches, quickly skipping past locations that couldn't possibly match, and only spendi\", \"ng our time and resources on locations that have a real chance of matching. To elevate that concept \", \"to a first-class one, the backtracking engines' \\\"bumpalong loop\\\" is typically more like the followin\", \"g (I say \\\"typically\\\" because in some cases the compiled and source generated regexes are able to gen\", \"erate something even better).\\n\\n```\\nprotected override void Scan(ReadOnlySpan<char> inputSpan)\\n{\\n whi\", \"le (TryFindNextPossibleStartingPosition(inputSpan) &&\\n !TryMatchAtCurrentPosition(inputSpan) &&\\n bas\", \"e.runtextpos != inputSpan.Length)\\n {\\n base.runtextpos++;\\n }\\n}\\n```\\n\\nAs with FindFirstChar previously,\", \" that TryFindNextPossibleStartingPosition has the responsibility of searching as quickly as possible\", \" for the next place to match (or determining that nothing else could possibly match, in which case i\", \"t would return false and the loop would exit). As FindFirstChar, and it was embued with multiple way\", \"s of doing its job. In .NET 7, TryFindNextPossibleStartingPosition learns many more and improved way\", \"s of helping the engine be fast.\\n\\nIn .NET 6, the interpreter engine had effectively two ways of impl\", \"ementing TryFindNextPossibleStartingPosition: a Boyer-Moore substring search if the pattern began wi\", \"th a string (potentially case-insensitive) of at least two characters, and a linear scan for a chara\", \"cter class known to be the set of all possible chars that could begin a match. For the latter case, \", \"the interpreter had eight different implementations for matching, based on a combination of whether \", \"RegexOptions.RightToLeft was set or not, whether the character class required case-insensitive compa\", \"rison or not, and whether the character class contained only a single character or more than one cha\", \"racter. Some of these were more optimized than others, e.g. a left-to-right, case-sensitive, single-\", \"char search would use an IndexOf(char) to search for the next location, an optimization added in .NE\", \"T 5. However, every time this operation was performed, the engine would need to recompute which case\", \" it would be. [dotnet/runtime#60822](https://github.com/dotnet/runtime/pull/60822) improved this, in\", \"troducing an internal\\n\\nenum of the strategies used by TryFindNextPossibleStartingPosition to find th\", \"e next opportunity, adding a switch to TryFindNextPossibleStartingPosition to quickly jump to the ri\", \"ght strategy, and precomputing which strategy to use when the interpreter was constructed. This not \", \"only made the interpreter's implementation at match time faster, it made it effectively free (in ter\", \"ms of runtime overhead at match time) to add additional strategies.\\n\\n[dotnet/runtime#60888](https://\", \"github.com/dotnet/runtime/pull/60888) then added the first additional strategy. The implementation w\", \"as already capable of using IndexOf(char), but as mentioned previously in this post, the implementat\", \"ion of IndexOf(ReadOnlySpan<char>) got way better in .NET 7 in many cases, to the point where it end\", \"s up being significantly better than Boyer-Moore in all but the most corner of corner cases. So this\", \" PR enables a new IndexOf(ReadOnlySpan<char>) strategy to be used to search for a prefix string in t\", \"he case where the string is case-sensitive.\\n\\n```\\nprivate static readonly string s_haystack = new\\nHtt\", \"pClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _r\", \"egex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic int Count() => _regex\", \".Matches(s_haystack).Count;\\n```\\n\\n| Method | Runtime  | Mean      | Ratio |\\n|--------|----------|----\", \"-------|-------|\\n| Count  | .NET 6.0 | 377.32 us | 1.00  |\\n| Count  | .NET 7.0 | 55.44 us  | 0.15  |\", \"\\n\\n[dotnet/runtime#61490](https://github.com/dotnet/runtime/pull/61490) then removed Boyer-Moore enti\", \"rely. This wasn't done in the previously mentioned PR because of lack of a good way to handle case-i\", \"nsensitive matches. However, this PR also special-cased ASCII letters to teach the optimizer how to \", \"turn an ASCII case-insensitive match into a set of both casings of that letter (excluding the few kn\", \"own to be a problem, like i and k, which can both be impacted by the employed culture and which migh\", \"t map case-insensitively to more than two values). With enough of the common cases covered, rather t\", \"han use Boyer-Moore to perform a case-insensitive search, the implementation just uses IndexOfAny(ch\", \"ar, char, ...) to search for the starting set, and the vectorization employed by IndexOfAny ends up \", \"outpacing the old implementation handily in real-world cases. This PR goes further than that, such t\", \"hat it doesn't just discover the \\\"starting set,\\\" but is able to find all of the character classes th\", \"at could match a pattern a fixed-offset from the beginning; that then gives the analyzer the ability\", \" to choose the set that's expected to be least common and issue a search for it instead of whatever \", \"happens to be at the beginning. The PR goes even further, too, motivated in large part by the non-ba\", \"cktracking engine. The non-backtracking engine's prototype implementation also used IndexOfAny(char,\", \" char, ...) when it arrived at a starting state and was thus able to quickly skip through input text\", \" that wouldn't have a chance of pushing it to the next state. We wanted all of the engines to share \", \"as much logic as possible, in particular around this speed ahead, and so this PR unified the interpr\", \"eter with the nonbacktracking engine to have them share the exact same TryFindNextPossibleStartingPo\", \"sition routine (which the non-backtracking engine just calls at an appropriate place in its graph tr\", \"aversal loop). Since the non-backtracking engine was already using IndexOfAny in this manner, initia\", \"lly not doing so popped as a significant regression on a variety of patterns we measure, and this ca\", \"used us to invest in using it everywhere. This PR also introduced the first special-casing for case-\", \"insensitive comparisons into the compiled engine, e.g. if we found a set that was [Ee], rather than \", \"emitting a\\n\\ncheck akin to c == 'E' || c == 'e', we'd instead emit a check akin to (c | 0x20) == 'e' \", \"(those fun ASCII tricks discussed earlier coming into play again).\\n\\n```\\nprivate static readonly stri\", \"ng s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").R\", \"esult;\\nprivate Regex _regex = new Regex(@\\\"\\\\belementary\\\\b\\\", RegexOptions.Compiled | \\nRegexOptions.Ign\", \"oreCase);\\n[Benchmark]\\npublic int Count() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method | Runtim\", \"e  | Mean     | Ratio |\\n|--------|----------|----------|-------|\\n| Count  | .NET 6.0 | 499.3 us | 1.\", \"00  |\\n| Count  | .NET 7.0 | 177.7 us | 0.35  |\\n\\nThe previous PR started turning IgnoreCase pattern t\", \"ext into sets, in particular for ASCII, e.g. (?i)a would become [Aa]. That PR hacked in the support \", \"for ASCII knowing that something more complete would be coming along, as it did in [dotnet/runtime#6\", \"7184.](https://github.com/dotnet/runtime/pull/67184) Rather than hardcoding the caseinsensitive sets\", \" that just the ASCII characters map to, this PR essentially hardcodes the sets for every possible ch\", \"ar. Once that's done, we no longer need to know about case-insensitivity at match time and can inste\", \"ad just double-down on efficiently matching sets, which we already need to be able to do well. Now, \", \"I said it encodes the sets for every possible char; that's not entirely true. If it were true, that \", \"would take up a large amount of memory, and in fact, most of that memory would be wasted because the\", \" vast majority of characters don't participate in case conversion\\u2026 there are only ~2,000 characters \", \"that we need to handle. As such, the implementation employs a three-tier table scheme. The first tab\", \"le has 64 elements, dividing the full range of chars into 64 groupings; of those 64 groups, 54 of th\", \"em have no characters that participate in case conversion, so if we hit one of those entries, we can\", \" immediately stop the search. For the remaining 10 that do have at least one character in their rang\", \"e participating, the character and the value from the first table are used to compute an index into \", \"the second table; there, too, the majority of entries say that nothing participates in case conversi\", \"on. It's only if we get a legitimate hit in the second table does that give us an index into the thi\", \"rd table, at which location we can find all of the characters considered case-equivalent with the fi\", \"rst.\\n\\n[dotnet/runtime#63477](https://github.com/dotnet/runtime/pull/63477) (and then later improved \", \"in [dotnet/runtime#66572\\\\)](https://github.com/dotnet/runtime/pull/66572) proceeded to add another s\", \"earching strategy, this one inspired by nim-[regex's literal optimizations](https://nitely.github.io\", \"/2020/11/30/regex-literals-optimization.html). There are a multitude of regexes we track from a perf\", \"ormance perspective to ensure we're not regressing in common cases and to help guide investments. On\", \"e is the set of patterns in [mariomka/regex-benchmark](https://github.com/mariomka/regex-benchmark) \", \"languages regex benchmark. One of those is for [URIs:](https://github.com/mariomka/regex-benchmark/b\", \"lob/17d073ec864931546e2694783f6231e4696a9ed4/csharp/Benchmark.cs#L23) \\n\\n(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+\", \"(?:\\\\?[^\\\\s#]\\\\*)?(?:#[^\\\\s]\\\\*)?\\\". This pattern defies the thus-far enabled strategies for finding a nex\", \"t good location, as it's guaranteed to begin with a \\\"word character\\\" (\\\\w), which includes ~50,000 of\", \" the ~65,000 possible characters; we don't have a good way of vectorizing a search for such a charac\", \"ter class. However, this pattern is interesting in that it begins with a loop, and not only that, it\", \"'s an upper-unbounded loop which our analysis will determine is atomic, because the character guaran\", \"teed to immediately follow the loop is a ':', which is itself not a word character, and thus there's\", \" nothing the loop could match and give up as part of backtracking that would match ':'. That all len\", \"ds itself to a different approach to vectorization: rather than trying to search for the \\\\w characte\", \"r class, we can instead search for the substring \\\"://\\\", and then once we\\n\\nfind it, we can match back\", \"wards through as many [\\\\w]s as we can find; in this case, the only constraint is we need to match at\", \" least one. This PR added that strategy, for a literal after an atomic loop, to all of the engines.\\n\", \"\\n```\\nprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenb\", \"erg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _regex = new Regex(@\\\"[\\\\w]+://[^/\\\\s?#]+[^\\\\s?#]+\", \"(?:\\\\?[^\\\\s#]*)?(?:#[^\\\\s]*)?\\\", \\nRegexOptions.Compiled);\\n[Benchmark]\\npublic bool IsMatch() => _regex.Is\", \"Match(s_haystack); // Uri's in Sherlock Holmes? \\\"Most \\nunlikely.\\\"\\n```\\n\\n| Method  | Runtime  | Mean  \", \"      | Ratio |\\n|---------|----------|-------------|-------|\\n| IsMatch | .NET 6.0 | 4,291.77 us | 1.\", \"000 |\\n| IsMatch | .NET 7.0 | 42.40 us    | 0.010 |\\n\\nOf course, as has been talked about elsewhere, t\", \"he best optimizations aren't ones that make something faster but rather ones that make something ent\", \"irely unnecessary. That's what [dotnet/runtime#64177](https://github.com/dotnet/runtime/pull/64177) \", \"does, in particular in relation to anchors. The .NET regex implementation has long had optimizations\", \" for patterns with a starting anchor: if the pattern begins with ^, for example (and RegexOptions.Mu\", \"ltiline wasn't specified), the pattern is rooted to the beginning, meaning it can't possibly match a\", \"t any position other than 0; as such, with such an anchor, TryFindNextPossibleStartingPosition won't\", \" do any searching at all. The key here, though, is being able to detect whether the pattern begins w\", \"ith such an anchor. In some cases, like ^abc\\\\$, that's trivial.\\n\\nIn other cases, like ^abc|^def, the\", \" existing analysis had trouble seeing through that alternation to find the guaranteed starting ^ anc\", \"hor. This PR fixes that. It also adds a new strategy based on discovering that a pattern has an endi\", \"ng anchor like \\\\$. If the analysis engine can determine a maximum number of characters for any possi\", \"ble match, and it has such an anchor, then it can simply jump to that distance from the end of the s\", \"tring, and bypass even looking at anything before then.\\n\\n```\\nprivate static readonly string s_haysta\", \"ck = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\npriv\", \"ate Regex _regex = new Regex(@\\\"^abc|^def\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic bool IsMatch()\", \" => _regex.IsMatch(s_haystack); // Why search _all_ the text?!\\n```\\n\\n| Method  | Runtime  | Mean     \", \"     | Ratio |\\n|---------|----------|---------------|-------|\\n| IsMatch | .NET 6.0 | 867,890.56 ns |\", \" 1.000 |\\n| IsMatch | .NET 7.0 | 33.55 ns      | 0.000 |\\n\\n[dotnet/runtime#67732](https://github.com/d\", \"otnet/runtime/pull/67732) is another PR related to improving anchor handling. It's always fun when a\", \" bug fix or code simplification refactoring turns into a performance improvement. The PR's primary p\", \"urpose was to simplify some complicated code that was computing the set of characters that could pos\", \"sibly start a match. It turns out that complication was hiding a logic bug which manifested in it mi\", \"ssing some opportunities to report valid starting character classes, the impact of which is that som\", \"e searches which could have been vectorized weren't. By simplifying the implementation, the bug was \", \"fixed, exposing more performance opportunities.\\n\\nBy this point, the engines are able to use IndexOf(\", \"ReadOnlySpan<char>) to find a substring at the beginning of a pattern. But sometimes the most valuab\", \"le substring isn't at the beginning, but somewhere in the middle or even at the end. As long as it's\", \" at a fixed-offset from the beginning of the pattern, we can search for it, and then just back-off b\", \"y the offset to the position we should actually try running the match. [dotnet/runtime#67907](https:\", \"//github.com/dotnet/runtime/pull/67907) does exactly that.\\n\\n```\\nprivate static readonly string s_hay\", \"stack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\np\", \"rivate Regex _regex = new Regex(@\\\"looking|feeling\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic int C\", \"ount() => _regex.Matches(s_haystack).Count; // will search for \\\"ing\\\"\\n```\\n\\n| Method | Runtime  | Mean\", \"     | Ratio |\\n|--------|----------|----------|-------|\\n| Count  | .NET 6.0 | 444.2 us | 1.00  |\\n| C\", \"ount  | .NET 7.0 | 122.6 us | 0.28  |\\n\\n#### <span id=\\\"page-147-0\\\"></span>**Loops and Backtracking**\\n\", \"\\nLoop handling in the compiled and source generated engines has been significantly improved, both wi\", \"th respect to processing them faster and with respect to backtracking less.\\n\\nWith regular greedy loo\", \"ps (e.g. c\\\\*), there are two directions to be concerned about: how quickly can we consume all the el\", \"ements that match the loop, and how quickly can we give back elements that might be necessary as par\", \"t of backtracking for the remainder of the expression to match. And with lazy loops, we're primarily\", \" concerned with backtracking, which is the forward direction (since lazy loops consume as part of ba\", \"cktracking rather than giving back as part of backtracking). With PRs [dotnet/runtime#63428,](https:\", \"//github.com/dotnet/runtime/pull/63428) [dotnet/runtime#68400,](https://github.com/dotnet/runtime/pu\", \"ll/68400) [dotnet/runtime#64254,](https://github.com/dotnet/runtime/pull/64254) and [dotnet/runtime#\", \"73910,](https://github.com/dotnet/runtime/pull/73910) in both the compiler and source generator we n\", \"ow make full use of effectively all of the variants of IndexOf, IndexOfAny, LastIndexOf, LastIndexOf\", \"Any, IndexOfAnyExcept, and LastIndexOfAnyExcept in order to speed along these searches. For example,\", \" in a pattern like .\\\\*abc, the forward direction of that loop entails consuming every character unti\", \"l the next newline, which we can optimize with an IndexOf('\\\\n'). Then as part of backtracking, rathe\", \"r than giving up one character at a time, we can LastIndexOf(\\\"abc\\\") in order to find the next viable\", \" location that could possibly match the remainder of the pattern. Or for example, in a pattern like \", \"[^a-c]\\\\*def, the loop will initially greedily consume everything other than 'a', 'b', or 'c', so we \", \"can use IndexOfAnyExcept('a', 'b', 'c') to find the initial end of the loop. And so on. This can yie\", \"ld huge performance gains, and with the source generator, also makes the generated code more idiomat\", \"ic and easier to understand.\\n\\n```\\nprivate static readonly string s_haystack = new\\nHttpClient().GetSt\", \"ringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result;\\nprivate Regex _regex = new Rege\", \"x(@\\\"^.*elementary.*$\\\", RegexOptions.Compiled | \\nRegexOptions.Multiline);\\n[Benchmark]\\npublic int Coun\", \"t() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method | Runtime  | Mean       | Ratio |\\n|--------|-\", \"---------|------------|-------|\\n| Count  | .NET 6.0 | 3,369.5 us | 1.00  |\\n| Count  | .NET 7.0 | 430\", \".2 us   | 0.13  |\\n\\nSometimes optimizations are well-intended but slightly miss the mark. [dotnet/run\", \"time#63398](https://github.com/dotnet/runtime/pull/63398) fixes such an issue with an optimization i\", \"ntroduced in .NET 5; the optimization was valuable but only for a subset of the scenarios it was int\", \"ended to cover. While TryFindNextPossibleStartingPosition's primary raison d'\\u00eatre is to update the b\", \"umpalong position, it's also possible for TryMatchAtCurrentPosition to do so. One of the occasions i\", \"n which it'll do so is when the pattern begins with an upper-unbounded single-character greedy loop.\", \" Since processing starts with the loop having fully consumed everything it could possibly match, sub\", \"sequent trips through the scan loop don't need to reconsider any starting position within that loop;\", \" doing so would just be duplicating work done in a previous iteration of the scan loop. And as such,\", \" TryMatchAtCurrentPosition can update the bumpalong position to the end of the loop. The optimizatio\", \"n added in .NET 5 was dutifully doing this, and it did so in a way that fully handled atomic loops. \", \"But with greedy loops, the updated position was getting updated every time we backtracked, meaning i\", \"t started going backwards, when it should have remained at the end of the loop. This PR fixes that, \", \"yielding significant savings in the additional covered cases.\\n\\n```\\nprivate static readonly string s_\", \"haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/files/1661/1661-0.txt\\\").Result\", \";\\nprivate Regex _regex = new Regex(@\\\".*stephen\\\", RegexOptions.Compiled);\\n[Benchmark]\\npublic int Coun\", \"t() => _regex.Matches(s_haystack).Count;\\n```\\n\\n| Method | Runtime  | Mean         | Ratio |\\n|--------\", \"|----------|--------------|-------|\\n| Count  | .NET 6.0 | 103,962.8 us | 1.000 |\\n| Count  | .NET 7.0\", \" | 336.9 us     | 0.003 |\\n\\nAs mentioned elsewhere, the best optimizations are those that make work e\", \"ntirely vanish rather than just making work faster. [dotnet/runtime#68989,](https://github.com/dotne\", \"t/runtime/pull/68989) [dotnet/runtime#63299,](https://github.com/dotnet/runtime/pull/63299) and [dot\", \"net/runtime#63518](https://github.com/dotnet/runtime/pull/63518) do exactly that by improving the pa\", \"ttern analyzers ability to find and eliminate more unnecessary backtracking, a process the analyzer \", \"refers to as \\\"auto-atomicity\\\" (automatically making loops atomic). For example, in the pattern a\\\\*?b\", \", we have a lazy loop of 'a's followed by a b. That loop can only match 'a's, and 'a' doesn't overla\", \"p with 'b'. So let's say the input is \\\"aaaaaaaab\\\". The loop is lazy, so we'll start out by trying to\", \" match just 'b'. It won't match, so we'll backtrack into the lazy loop and try to match \\\"ab\\\". It won\", \"'t match so we'll backtrack into the lazy loop and try to match \\\"aab\\\". And so on, until we've consum\", \"ed all the 'a's such that the rest of the pattern has a chance of matching the rest of the input. Th\", \"at's exactly what an atomic greedy loop does, so we can transform the pattern a\\\\*?b into (?>a\\\\*)b, w\", \"hich is much more efficiently processed. In fact, we can see exactly how it's processed just by look\", \"ing at the source-generated implementation of this pattern:\\n\\n```\\nprivate bool TryMatchAtCurrentPosit\", \"ion(ReadOnlySpan<char> inputSpan)\\n{\\n int pos = base.runtextpos;\\n int matchStart = pos;\\n ReadOnlySpan\", \"<char> slice = inputSpan.Slice(pos);\\n```\\n\\n```\\n // Match 'a' atomically any number of times.\\n {\\n int \", \"iteration = slice.IndexOfAnyExcept('a');\\n if (iteration < 0)\\n {\\n iteration = slice.Length;\\n }\\n slice\", \" = slice.Slice(iteration);\\n pos += iteration;\\n }\\n // Advance the next matching position.\\n if (base.r\", \"untextpos < pos)\\n {\\n base.runtextpos = pos;\\n }\\n // Match 'b'.\\n if (slice.IsEmpty || slice[0] != 'b')\", \"\\n {\\n return false; // The input didn't match.\\n }\\n // The input matched.\\n pos++;\\n base.runtextpos = p\", \"os;\\n base.Capture(0, matchStart, pos);\\n return true;\\n}\\n```\\n\\n(Note that those comments aren't ones I \", \"added for this blog post; the source generator itself is emitting commented code.)\\n\\nWhen a regular e\", \"xpression is input, it's parsed into a tree-based form. The \\\"auto-atomicity\\\" analysis discussed in t\", \"he previous PR is one form of analysis that walks around this tree looking for opportunities to tran\", \"sform portions of the tree into a behaviorally equivalent alternative that will be more efficient to\", \" execute. Several PRs introduced additional such transformations. [dotnet/runtime#63695](https://git\", \"hub.com/dotnet/runtime/pull/63695), for example, looks for \\\"empty\\\" and \\\"nothing\\\" nodes in the tree t\", \"hat can be removed. An \\\"empty\\\" node is something that matches the empty string, so for example in th\", \"e alternation abc|def||ghi, the third branch of that alternation is empty. A \\\"nothing\\\" node is somet\", \"hing that can't match anything, so for example in the concatenation abc(?!)def, that (?!) in middle \", \"is a negative lookahead around an empty, which can't possibly match anything, as it's saying the exp\", \"ression won't match if it's followed by an empty string, which everything is. These constructs often\", \" arise as a result of other transformations rather than being something a developer typically writes\", \" by hand, just as there are optimizations in the JIT where you might look at them and say \\\"why on ea\", \"rth is that something a developer would write\\\" but it ends up being a valuable optimization anyways \", \"because inlining might transform perfectly reasonable code into something that matches the target pa\", \"ttern. Thus, for example, if you did have abc(?!)def, since that concatenation requires the (?!) to \", \"match in order to be successful, the concatenation itself can simply be replaced by a \\\"nothing.\\\" You\", \" can see this easily if you try this with the source generator:\\n\\n[GeneratedRegex(@\\\"abc(?!)def\\\")]\\n\\nas\", \" it will produce a Scan method like this (comment and all):\\n\\n```\\nprotected override void Scan(ReadOn\", \"lySpan<char> inputSpan)\\n{\\n // The pattern never matches anything.\\n}\\n```\\n\\nAnother set of transformati\", \"ons was introduced in [dotnet/runtime#59903,](https://github.com/dotnet/runtime/pull/59903) specific\", \"ally around alternations (which beyond loops are the other source of backtracking). This introduced \", \"two main optimizations. First, it enables rewriting alternations into alternations of alternations, \", \"e.g. transforming axy|axz|bxy|bxz into ax(?:y|z)|bx(?:y|z), which is then further reduced into ax[yz\", \"]|bx[yz]. This can enable the backtracking engines to more efficiently process alternations due to f\", \"ewer branches and thus less potential backtracking. The PR also enabled limited reordering of branch\", \"es in an alternation. Generally branches can't be reordered, as the order can impact exactly what's \", \"matched and what's captured, but if the engine can prove there's no effect on ordering, then it's fr\", \"ee to reorder. One key place that ordering isn't a factor is if the alternation is atomic due to it \", \"being wrapped in an atomic group (and the auto-atomicity analysis will add such groups implicitly in\", \" some situations). Reordering the branches then enables other optimizations, like the one previously\", \" mentioned from this PR. And then once those optimizations have kicked in, if we're left with an ato\", \"mic alternation where every branch begins with a different letter, than can enable further optimizat\", \"ions in terms of how the alternation is lowered; this PR teaches the source generator how to emit a \", \"switch statement, which leads to both more efficient and more readable code. (The detection of wheth\", \"er nodes in the tree are atomic, and other such properties such as performing captures or introducin\", \"g backtracking, turned out to be valuable enough that [dotnet/runtime#65734](https://github.com/dotn\", \"et/runtime/pull/65734) added dedicated support for this.)\\n\\n#### <span id=\\\"page-150-0\\\"></span>**Code \", \"generation**\\n\\nThe .NET 7 regex implementation has no fewer than four engines: the interpreter (what \", \"you get if you don't explicitly choose another engine), the compiler (what you get with RegexOptions\", \".Compiled), the non-backtracking engine (what you get with RegexOptions.NonBacktracking), and the so\", \"urce generator (what you get with [GeneratedRegex(...)]). The interpreter and the non-backtracking e\", \"ngine don't require any kind of code generation; they're both based on creating in-memory data struc\", \"tures that represent how to match input against the pattern. The other two, though, both generate co\", \"de specific to the pattern; the generated code is code attempting to mimick what you might write if \", \"you weren't using Regex at all and were instead writing code to perform a similar match directly. Th\", \"e source generator spits out C# that's compiled directly into your assembly, and the compiler spits \", \"out IL at run-time via reflection emit. The fact that these are generating code specific to the patt\", \"ern means there's a ton of opportunity to optimize.\\n\\n[dotnet/runtime#59186](https://github.com/dotne\", \"t/runtime/pull/59186) provided the initial implementation of the source generator. This was a direct\", \" port of the compiler, effectively a line-by-line translation of IL into C#; the result is C# akin t\", \"o what you'd get if you were to run the generated IL through a decompiler like [ILSpy.](https://gith\", \"ub.com/icsharpcode/ILSpy) A bunch of PRs then proceeded to iterate on and tweak the source generator\", \", but the biggest improvements came from changes that changed the compiler and the source generator \", \"together. Prior to .NET 5, the compiler spit out IL that was very similar to what the interpreter wo\", \"uld do. The interpreter is handed a series of instructions that it walks through one by one and inte\", \"rprets, and the compiler, handed that same\\n\\nseries of instructions, would just emit the IL for proce\", \"ssing each. It had some opportunity for being more efficient, e.g. loop unrolling, but a lot of valu\", \"e was left on the table. In .NET 5, an alternate path was added in support of patterns without backt\", \"racking; this code path was based on being handed the parsed node tree rather than being based on th\", \"e series of instructions, and that higher-level form enabled the compiler to derive more insights ab\", \"out the pattern that it could then use to generate more efficient code. In .NET 7, support for all r\", \"egex features were incrementally added in, over the course of multiple PRs, in particular [dotnet/ru\", \"ntime#60385](https://github.com/dotnet/runtime/pull/60385) for backtracking single char loops, [dotn\", \"et/runtime#61698](https://github.com/dotnet/runtime/pull/61698) for backtracking single char lazy lo\", \"ops, [dotnet/runtime#61784](https://github.com/dotnet/runtime/pull/61784) for other backtracking laz\", \"y loops, and [dotnet/runtime#61906](https://github.com/dotnet/runtime/pull/61906) for other backtrac\", \"king loops as well as back references and conditionals. At that point, the only features missing wer\", \"e support for RegexOptions.RightToLeft and lookbehinds (which are implemented in terms of right-to-l\", \"eft), and we decided based on relatively little use of these features that we needn't keep around th\", \"e old compiler code just to enable them. So, [dotnet/runtime#62318](https://github.com/dotnet/runtim\", \"e/pull/62318) deleted the old implementation. But, even though these features are relatively rare, i\", \"t's a lot easier to tell a story that \\\"all patterns are supported\\\" than one that requires special ca\", \"llouts and exceptions, so [dotnet/runtime#66127](https://github.com/dotnet/runtime/pull/66127) and [\", \"dotnet/runtime#66280](https://github.com/dotnet/runtime/pull/66280) added full lookbehind and RightT\", \"oLeft support such that there were no takebacks. At this point, both the compiler and source generat\", \"or now supported everything the compiler previously did, but now with the more modernized code gener\", \"ation. This code generation is in turn what enables many of the optimizations previously discussed, \", \"e.g. it provides the opportunity to use APIs like LastIndexOf as part of backtracking, which would h\", \"ave been near impossible with the previous approach.\\n\\nOne of the great things about the source gener\", \"ator emitting idiomatic C# is it makes it easy to iterate. Every time you put in a pattern and see w\", \"hat the generator emits, it's like being asked to do a code review of someone else's code, and you v\", \"ery frequently see something \\\"new\\\" worthy of comment, or in this case, improving the generator to ad\", \"dress the issue. And so a bunch of PRs were originated based on reviewing what the generator emitted\", \" and then tweaking the generator to do better (and since the compiler was effectively entirely rewri\", \"tten along with the source generator, they maintain the same structure, and it's easy to port improv\", \"ements from one to the other). For example, [dotnet/runtime#68846](https://github.com/dotnet/runtime\", \"/pull/68846) and [dotnet/runtime#69198](https://github.com/dotnet/runtime/pull/69198) tweaked how so\", \"me comparisons were being performed in order for them to convey enough information to the JIT that i\", \"t can eliminate some subsequent bounds checking, and [dotnet/runtime#68490](https://github.com/dotne\", \"t/runtime/pull/68490) recognized a variety of conditions being emitted that could never happen in so\", \"me situations observable statically and was able to elide all that code gen. It also became obvious \", \"that some patterns didn't need the full expressivity of the scan loop, and a more compact and custom\", \"ized Scan implementation could be used. [dotnet/runtime#68560](https://github.com/dotnet/runtime/pul\", \"l/68560) does that, such that, for example, a simple pattern like hello won't emit a loop at all and\", \" will instead have a simpler Scan implementation like:\\n\\n```\\nprotected override void Scan(ReadOnlySpa\", \"n<char> inputSpan)\\n{\\n if (TryFindNextPossibleStartingPosition(inputSpan))\\n {\\n // The search in TryFi\", \"ndNextPossibleStartingPosition performed the entire match.\\n int start = base.runtextpos;\\n int end = \", \"base.runtextpos = start + 5;\\n base.Capture(0, start, end);\\n }\\n}\\n```\\n\\nThe compiler and source generat\", \"or were also updated to take advantage of newer features. [dotnet/runtime#63277,](https://github.com\", \"/dotnet/runtime/pull/63277) for example, teaches the source generator how to determine if unsafe cod\", \"e is allowed, and if it is, it emits a [SkipLocalsInit] for the core logic; the matching routine can\", \" result in many locals being emitted, and SkipLocalsInit can make it cheaper to call the function du\", \"e to less zero'ing being necessary. Then there's the issue of where the code is generated; we want h\", \"elper functions (like the \\\\w IsWordChar helper introduced in [dotnet/runtime#62620\\\\)](https://github\", \".com/dotnet/runtime/pull/62620) that can be shared amongst multiple generated regexes, and we want t\", \"o be able to share the exact same regex implementation if the same pattern/options/timeout combinati\", \"on are used in multiple places in the same assembly [\\\\(dotnet/runtime#66747\\\\)](https://github.com/do\", \"tnet/runtime/pull/66747), but doing so then exposes this implementation detail to user code in the s\", \"ame assembly. To still be able to get the perf benefits of such code sharing while avoiding the resu\", \"lting complications, [dotnet/runtime#66432](https://github.com/dotnet/runtime/pull/66432) and then [\", \"dotnet/runtime#71765](https://github.com/dotnet/runtime/pull/71765) teaches the source generator to \", \"use the new file-local types features in C# 11 [\\\\(dotnet/roslyn#62375\\\\)](https://github.com/dotnet/r\", \"oslyn/pull/62375).\\n\\nOne last and interesting code generation aspect is in optimizations around chara\", \"cter class matching. Matching character classes, whether ones explicitly written by the developer or\", \" ones implicitly created by the engine (e.g. as part of finding the set of all characters that can b\", \"egin the expression), can be one of the more time-consuming aspects of matching; if you imagine havi\", \"ng to evaluate this logic for every character in the input, then how many instructions needs to be e\", \"xecuted as part of matching a character class directly correlates to how long it takes to perform th\", \"e overall match. We thus spend some time trying to ensure we generate optimal matching code for as m\", \"any categories of character classes as possible. [dotnet/runtime#67365,](https://github.com/dotnet/r\", \"untime/pull/67365) for example, improved a bunch of cases found to be common in real-world use, like\", \" specially-recognizing sets like [\\\\d\\\\D], [\\\\s\\\\S], and [\\\\w\\\\W] as meaning \\\"match anything\\\" (just as is \", \"the case for . in RegexOptions.Singleline mode), in which case existing optimizations around the han\", \"dling of \\\"match anything\\\" can kick in.\\n\\n```\\nprivate static readonly string s_haystack = new string('\", \"a', 1_000_000);\\nprivate Regex _regex = new Regex(@\\\"([\\\\s\\\\S]*)\\\", RegexOptions.Compiled);\\n[Benchmark]\\np\", \"ublic Match Match() => _regex.Match(s_haystack);\\n```\\n\\n| Method | Runtime  | Mean            | Ratio \", \"|\\n|--------|----------|-----------------|-------|\\n| Match  | .NET 6.0 | 1,934,393.69 ns | 1.000 |\\n| \", \"Match  | .NET 7.0 | 91.80 ns        | 0.000 |\\n\\nOr [dotnet/runtime#68924,](https://github.com/dotnet/\", \"runtime/pull/68924) which taught the source generator how to use all of the new char ASCII helper me\", \"thods, like char.IsAsciiLetterOrDigit, as well as some existing helpers it didn't yet know about, in\", \" the generated output; for example this:\\n\\n```\\n[GeneratedRegex(@\\\"[A-Za-z][A-Z][a-z][0-9][A-Za-z0-9][0\", \"-9A-F][0-9a-f][0-9A-Fa-\\nf]\\\\p{Cc}\\\\p{L}[\\\\p{L}\\\\d]\\\\p{Ll}\\\\p{Lu}\\\\p{N}\\\\p{P}\\\\p{Z}\\\\p{S}\\\")]\\n```\\n\\nnow produces \", \"this in the core matching logic emitted by the source generator:\\n\\n```\\nif ((uint)slice.Length < 17 ||\", \"\\n !char.IsAsciiLetter(slice[0]) || // Match a character in the set [A-Za-z].\\n !char.IsAsciiLetterUpp\", \"er(slice[1]) || // Match a character in the set [A-Z].\\n !char.IsAsciiLetterLower(slice[2]) || // Mat\", \"ch a character in the set [a-z].\\n !char.IsAsciiDigit(slice[3]) || // Match '0' through '9'.\\n !char.I\", \"sAsciiLetterOrDigit(slice[4]) || // Match a character in the set [0-9A-Za-z].\\n```\\n\\n```\\n !char.IsAsci\", \"iHexDigitUpper(slice[5]) || // Match a character in the set [0-9A-F].\\n !char.IsAsciiHexDigitLower(sl\", \"ice[6]) || // Match a character in the set [0-9a-f].\\n !char.IsAsciiHexDigit(slice[7]) || // Match a \", \"character in the set [0-9A-Fa-f].\\n !char.IsControl(slice[8]) || // Match a character in the set [\\\\p{\", \"Cc}].\\n !char.IsLetter(slice[9]) || // Match a character in the set [\\\\p{L}].\\n !char.IsLetterOrDigit(s\", \"lice[10]) || // Match a character in the set [\\\\p{L}\\\\d].\\n !char.IsLower(slice[11]) || // Match a char\", \"acter in the set [\\\\p{Ll}].\\n !char.IsUpper(slice[12]) || // Match a character in the set [\\\\p{Lu}].\\n !\", \"char.IsNumber(slice[13]) || // Match a character in the set [\\\\p{N}].\\n !char.IsPunctuation(slice[14])\", \" || // Match a character in the set [\\\\p{P}].\\n !char.IsSeparator(slice[15]) || // Match a character i\", \"n the set [\\\\p{Z}].\\n !char.IsSymbol(slice[16])) // Match a character in the set [\\\\p{S}].\\n{\\n return fa\", \"lse; // The input didn't match.\\n}\\n```\\n\\nOther changes impacting character class code generation inclu\", \"ded [dotnet/runtime#72328,](https://github.com/dotnet/runtime/pull/72328) which improved the handlin\", \"g of character classes that involve character class subtraction; [dotnet/runtime#72317](https://gith\", \"ub.com/dotnet/runtime/pull/72317) from [@teo-tsirpanis](https://github.com/teo-tsirpanis), which ena\", \"bled additional cases where the generator could avoid emitting a bitmap lookup; [dotnet/runtime#6713\", \"3,](https://github.com/dotnet/runtime/pull/67133) which added a tighter bounds check when it does em\", \"it such a lookup table; and [dotnet/runtime#61562](https://github.com/dotnet/runtime/pull/61562), wh\", \"ich enables better normalization of character classes in the engine's internal representation, thus \", \"leading to downstream optimizations better recognizing more character classes.\\n\\nFinally, with all of\", \" these improvements to Regex, a multitude of PRs fixed up regexes being used across [dotnet/runtime,\", \"](https://github.com/dotnet/runtime) in various ways. [dotnet/runtime#66142,](https://github.com/dot\", \"net/runtime/pull/66142) [dotnet/runtime#66179](https://github.com/dotnet/runtime/pull/66179) from [@\", \"Clockwork-Muse](https://github.com/Clockwork-Muse), and [dotnet/runtime#62325](https://github.com/do\", \"tnet/runtime/pull/62325) from [@Clockwork-Muse](https://github.com/Clockwork-Muse) all converted Reg\", \"ex usage over to using [GeneratedRegex(...)]. [dotnet/runtime#68961](https://github.com/dotnet/runti\", \"me/pull/68961) optimized other usage in various ways. The PR replaced several regex.Matches(...).Suc\", \"cess calls with IsMatch(...), as using IsMatch has less overhead due to not needing to construct a M\", \"atch instance and due to being able to avoid more expensive phases in the non-backtracking engine to\", \" compute exact bounds and capture information. The PR also replaced some Match/Match.MoveNext usage \", \"with EnumerateMatches, in order to avoid needing Match object allocations. The PR also entirely remo\", \"ved at least one regex usage that was just as doable as a cheaper IndexOf. [dotnet/runtime#68766](ht\", \"tps://github.com/dotnet/runtime/pull/68766) also removed a use of RegexOptions.CultureInvariant. Spe\", \"cifying CultureInvariant changes the behavior of IgnoreCase by alternating which casing tables are e\", \"mployed; if IgnoreCase isn't specified and there's no inline case-insensitivity options ((?i)), then\", \" specifying CultureInvariant is a nop. But a potentially expensive one. For any code that's size con\", \"scious, the Regex implementation is structured in a way as to try to make it as trimmmer friendly as\", \" possible. If you only ever do new Regex(pattern), we'd really like to be able to statically determi\", \"ne that the compiler and nonbacktracking implementations aren't needed such that the trimmer can rem\", \"ove it without having a visible and meaningful negative impact. However, the trimmer analysis isn't \", \"yet sophisticated enough to see exactly which options are used and only keep the additional engines \", \"linked in if RegexOptions.Compiled or RegexOptions.NonBacktracking is used; instead, *any* use of an\", \" overload that takes a RegexOptions will result in that code continuing to be referenced. By getting\", \" rid of the options, we increase the chances that no code in the app is using this constructor, whic\", \"h would in turn enable this constructor, the compiler, and the non-backtracking implementation to be\", \" trimmed away.\\n\\n### <span id=\\\"page-154-0\\\"></span>Collections\\n\\nSystem.Collections hasn't seen as much\", \" investment in .NET 7 as it has in previous releases, though many of the lower-level improvements ha\", \"ve a trickle-up effect into collections as well. For example, Dictionary<,>'s code hasn't changed be\", \"tween .NET 6 and .NET 7, but even so, this benchmark focused on dictionary lookups:\\n\\n```\\nprivate Dic\", \"tionary<int, int> _dictionary = Enumerable.Range(0, 10_000).ToDictionary(i => \\ni);\\n[Benchmark]\\npubli\", \"c int Sum()\\n{\\n Dictionary<int, int> dictionary = _dictionary;\\n int sum = 0;\\n for (int i = 0; i < 10_\", \"000; i++)\\n {\\n if (dictionary.TryGetValue(i, out int value))\\n {\\n sum += value;\\n }\\n }\\n return sum;\\n}\\n`\", \"``\\n\\nshows a measurable improvement in throughput between .NET 6 and .NET 7:\\n\\n| Method | Runtime  | M\", \"ean     | Ratio | Code Size |\\n|--------|----------|----------|-------|-----------|\\n| Sum    | .NET 6\", \".0 | 51.18 us | 1.00  | 431 B     |\\n| Sum    | .NET 7.0 | 43.44 us | 0.85  | 413 B     |\\n\\nBeyond tha\", \"t, there have been explicit improvements elsewhere in collections. ImmutableArray<T>, for example. A\", \"s a reminder, ImmutableArray<T> is a very thin struct-based wrapper around a T[] that hides the muta\", \"bility of T[]; unless you're using unsafe code, neither the length nor the shallow contents of an Im\", \"mutableArray<T> will ever change (by shallow, I mean the data stored directly in that array can't be\", \" mutated, but if there are mutable reference types stored in the array, those instances themselves m\", \"ay still have their data mutated). As a result, ImmutableArray<T> also has an associated \\\"builder\\\" t\", \"ype, which does support mutation: you create the builder, populate it, and then transfer that conten\", \"ts to an ImmutableArray<T> which is frozen forevermore. In [dotnet/runtime#70850](https://github.com\", \"/dotnet/runtime/pull/70850) from [@grbell-ms](https://github.com/grbell-ms), the builder's Sort meth\", \"od is changed to use a span, which in turn avoids an IComparer<T> allocation and a Comparison<T>\\n\\nal\", \"location, while also speeding up the sort itself by removing several layers of indirection from ever\", \"y comparison.\\n\\n```\\nprivate ImmutableArray<int>.Builder _builder = ImmutableArray.CreateBuilder<int>(\", \");\\n[GlobalSetup]\\npublic void Setup()\\n{\\n _builder.AddRange(Enumerable.Range(0, 1_000));\\n}\\n[Benchmark]\", \"\\npublic void Sort()\\n{\\n _builder.Sort((left, right) => right.CompareTo(left));\\n _builder.Sort((left, \", \"right) => left.CompareTo(right));\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio |\\n|--------|--------\", \"--|----------|-------|\\n| Sort   | .NET 6.0 | 86.28 us | 1.00  |\\n| Sort   | .NET 7.0 | 67.17 us | 0.7\", \"8  |\\n\\n[dotnet/runtime#61196](https://github.com/dotnet/runtime/pull/61196) from [@lateapexearlyspeed\", \"](https://github.com/lateapexearlyspeed) brings ImmutableArray<T> into the span-based era, adding ar\", \"ound 10 new methods to ImmutableArray<T> that interoperate with Span<T> and ReadOnlySpan<T>. These a\", \"re valuable from a performance perspective because it means if you have your data in a span, you can\", \" get it into an ImmutableArray<T> without incurring additional allocations beyond the one the Immuta\", \"bleArray<T> itself will create. [dotnet/runtime#66550](https://github.com/dotnet/runtime/pull/66550)\", \" from [@RaymondHuy](https://github.com/RaymondHuy) also adds a bunch of new methods to the immutable\", \" collection builders, which provide efficient implementations for operations like replacing elements\", \" and adding, inserting, and removing ranges.\\n\\nSortedSet<T> also saw some improvements in .NET 7. For\", \" example, SortedSet<T> internally uses a [red/black tree](https://en.wikipedia.org/wiki/Red%E2%80%93\", \"black_tree) as its internal data structure, and it uses a Log2 operation to determine the maximum de\", \"pth the tree could be for a given node count. Previously, that operation was implemented as a loop. \", \"But thanks to [dotnet/runtime#58793](https://github.com/dotnet/runtime/pull/58793) from [@teo-tsirpa\", \"nis](https://github.com/teo-tsirpanis) that implementation is now simply a call to BitOperations.Log\", \"2, which is in turn implemented trivially in terms of one of multiple hardware intrinsics if they're\", \" supported (e.g. Lzcnt.LeadingZeroCount, ArmBase.LeadingZeroCount, X86Base.BitScanReverse). And [dot\", \"net/runtime#56561](https://github.com/dotnet/runtime/pull/56561) from [@johnthcall](https://github.c\", \"om/johnthcall) improves SortedSet<T> copy performance by streamlining how the iteration through the \", \"nodes in the tree is handled.\\n\\n```\\n[Params(100)]\\npublic int Count { get; set; }\\nprivate static Sorte\", \"dSet<string> _set;\\n[GlobalSetup]\\npublic void GlobalSetup()\\n{\\n _set = new SortedSet<string>(StringCom\", \"parer.OrdinalIgnoreCase);\\n for (int i = 0; i < Count; i++)\\n {\\n _set.Add(Guid.NewGuid().ToString());\\n\", \"```\\n\\n```\\n }\\n}\\n[Benchmark]\\npublic SortedSet<string> SortedSetCopy()\\n{\\n return new SortedSet<string>(_\", \"set, StringComparer.OrdinalIgnoreCase);\\n}\\n```\\n\\n| Method        | Runtime  | Mean     | Ratio |\\n|----\", \"-----------|----------|----------|-------|\\n| SortedSetCopy | .NET 6.0 | 2.397 us | 1.00  |\\n| SortedS\", \"etCopy | .NET 7.0 | 2.090 us | 0.87  |\\n\\nOne last PR to look at in collections: [dotnet/runtime#67923\", \".](https://github.com/dotnet/runtime/pull/67923) ConditionalWeakTable<TKey, TValue> is a collection \", \"most developers haven't used, but when you need it, you need it. It's used primarily for two purpose\", \"s: to associate additional state with some object, and to maintain a weak collection of objects. Ess\", \"entially, it's a thread-safe dictionary that doesn't maintain strong references to anything it store\", \"s but ensures that the value associated with a key will remain rooted as long as the associated key \", \"is rooted. It exposes many of the same APIs as ConcurrentDictionary<,>, but for adding items to the \", \"collection, it's historically only had an Add method. That means if the design of the consuming code\", \" entailed trying to use the collection as a set, where duplicates were common, it would also be comm\", \"on to experience exceptions when trying to Add an item that already existed in the collection. Now i\", \"n .NET 7, it has a TryAdd method, which enables such usage without potentially incurring the costs o\", \"f such exceptions (and without needing to add try/catch blocks to defend against them).\\n\\n### <span i\", \"d=\\\"page-157-0\\\"></span>LINQ\\n\\nLet's move on to Language-Integrated Query (LINQ). LINQ is a productivit\", \"y feature that practically every .NET developer uses. It enables otherwise complicated operations to\", \" be trivially expressed, whether via language-integrated query comprehension syntax or via direct us\", \"e of methods on System.Linq.Enumerable. That productivity and expressivity, however, comes at a bit \", \"of an overhead cost. In the vast majority of situations, those costs (such as delegate and closure a\", \"llocations, delegate invocations, use of interface methods on arbitrary enumerables vs direct access\", \" to indexers and Length/Count properties, etc.) don't have a significant impact, but for really hot \", \"paths, they can and do show up in a meaningful way. This leads some folks to declare LINQ as being b\", \"roadly off-limits in their codebases. From my perspective, that's misguided; LINQ is extremely usefu\", \"l and has its place. In .NET itself, we use LINQ, we're just practical and thoughtful about where, a\", \"voiding it in code paths we've optimized to be lightweight and fast due to expectations that such co\", \"de paths could matter to consumers. And as such, while LINQ itself may not perform as fast as a hand\", \"-rolled solution, we still care a lot about the performance of LINQ's implementation, so that it can\", \" be used in more and more places, and so that where it's used there's as little overhead as possible\", \". There are also differences between operations in LINQ; with over 200 overloads providing various k\", \"inds of functionality, some of these overloads benefit from more performance tuning than do others, \", \"based on their expected usage.\\n\\n[dotnet/runtime#64470](https://github.com/dotnet/runtime/pull/64470)\", \" is the result of analyzing various real-world code bases for use of Enumerable.Min and Enumerable.M\", \"ax, and seeing that it's very common to use these with arrays, often ones that are quite large. This\", \" PR updates the Min<T>(IEnumerable<T>) and Max<T>(IEnumerable<T>) overloads when the input is an int\", \"[] or long[] to vectorize the processing, using Vector<T>. The net effect of this is significantly f\", \"aster execution time for larger arrays, but still improved performance even for short arrays (becaus\", \"e the implementation is now able to access the array directly rather than going through the enumerab\", \"le, leading to less allocation and interface dispatch and more applicable optimizations like inlinin\", \"g).\\n\\n```\\n[Params(4, 1024)]\\npublic int Length { get; set; }\\nprivate IEnumerable<int> _source;\\n[Global\", \"Setup]\\npublic void Setup() => _source = Enumerable.Range(1, Length).ToArray();\\n[Benchmark]\\npublic in\", \"t Min() => _source.Min();\\n[Benchmark]\\npublic int Max() => _source.Max();\\n```\\n\\n| Method | Runtime  | \", \"Length | Mean         | Ratio | Allocated | Alloc Ratio |\\n|--------|----------|--------|------------\", \"--|-------|-----------|-------------|\\n| Min    | .NET 6.0 | 4      | 26.167 ns    | 1.00  | 32 B    \", \"  | 1.00        |\\n| Min    | .NET 7.0 | 4      | 4.788 ns     | 0.18  | -         | 0.00        |\\n| \", \"       |          |        |              |       |           |             |\\n| Max    | .NET 6.0 | \", \"4      | 25.236 ns    | 1.00  | 32 B      | 1.00        |\\n| Max    | .NET 7.0 | 4      | 4.234 ns   \", \"  | 0.17  | -         | 0.00        |\\n|        |          |        |              |       |         \", \"  |             |\\n| Min    | .NET 6.0 | 1024   | 3,987.102 ns | 1.00  | 32 B      | 1.00        |\\n| \", \"Min    | .NET 7.0 | 1024   | 101.830 ns   | 0.03  | -         | 0.00        |\\n|        |          | \", \"       |              |       |           |             |\\n| Max    | .NET 6.0 | 1024   | 3,798.069 n\", \"s | 1.00  | 32 B      | 1.00        |\\n| Max    | .NET 7.0 | 1024   | 100.279 ns   | 0.03  | -       \", \"  | 0.00        |\\n\\nOne of the more interesting aspects of the PR, however, is one line that's meant \", \"to help with the nonarray cases. In performance optimization, and in particular when adding \\\"fast pa\", \"ths\\\" to better handle certain cases, there's almost always a winner and a loser: the winner is the c\", \"ase the optimization is intended to help, and the loser is every other case that's penalized by what\", \"ever checks are necessary to determine whether to take the improved path. An optimization that speci\", \"al-cases arrays might normally look like:\\n\\n```\\nif (source is int[] array)\\n{\\n ProcessArray(array);\\n}\\n\", \"else\\n{\\n ProcessEnumerable(source);\\n}\\n```\\n\\nHowever, if you look at the PR, you'll see the if conditio\", \"n is actually:\\n\\n```\\nif (source.GetType() == typeof(int[]))\\n```\\n\\nHow come? Well at this point in the \", \"code flow, we know that source isn't null, so we don't need the extra null check that is will bring.\", \" However, that's minor compared to the real impact here, that of support for array covariance. It mi\", \"ght surprise you to learn that there are types beyond int[] that will satisfy a source is int check\\u2026\", \" try running Console.WriteLine((object)new uint[42] is int[]);, and you'll find it prints out True. \", \"(This is also a rare case where the .NET runtime and C# the language disagree on aspects of the type\", \" system. If you change that\\n\\nConsole.WriteLine((object)new uint[42] is int[]); to instead be Console\", \".WriteLine(new uint[42] is int[]);, i.e. remove the (object) cast, you'll find it starts printing ou\", \"t False instead of True. That's because the C# compiler believes it's impossible for a uint[] to eve\", \"r be an int[], and thus optimizes the check away entirely to be a constant false.) Thus the runtime \", \"is having to do more work as part of the type check than just a simple comparison against the known \", \"type identity of\\n\\nint[]. We can see this by looking at the assembly generated for these two methods \", \"(the latter assumes we've already null-checked the input, which is the case in these LINQ methods):\\n\", \"\\n```\\npublic IEnumerable<object> Inputs { get; } = new[] { new object() };\\n[Benchmark]\\n[ArgumentsSour\", \"ce(nameof(Inputs))]\\npublic bool M1(object o) => o is int[];\\n[Benchmark]\\n[ArgumentsSource(nameof(Inpu\", \"ts))]\\npublic bool M2(object o) => o.GetType() == typeof(int[]);\\n```\\n\\nThis results in:\\n\\n```\\n; Program\", \".M1(System.Object)\\n sub rsp,28\\n mov rcx,offset MT_System.Int32[]\\n call qword ptr \\n[System.Runtime.Co\", \"mpilerServices.CastHelpers.IsInstanceOfAny(Void*, System.Object)]\\n test rax,rax\\n setne al\\n movzx eax\", \",al\\n add rsp,28\\n ret\\n; Total bytes of code 34\\n```\\n\\n```\\n; Program.M2(System.Object)\\n mov rax,offset M\", \"T_System.Int32[]\\n cmp [rdx],rax\\n sete al\\n movzx eax,al\\n ret\\n; Total bytes of code 20\\n```\\n\\nNote the f\", \"ormer involves a method call to the JIT's CastHelpers.IsInstanceOfAny helper method, and that it's n\", \"ot inlined. That in turn impacts performance:\\n\\n```\\nprivate IEnumerable<int> _source = (int[])(object\", \")new uint[42];\\n[Benchmark(Baseline = true)]\\npublic bool WithIs() => _source is int[];\\n[Benchmark]\\npu\", \"blic bool WithTypeCheck() => _source.GetType() == typeof(int[]);\\n```\\n\\n| Method        | Mean      | \", \"Ratio | Code Size |  |\\n|---------------|-----------|-------|-----------|--|\\n| WithIs        | 1.9246\", \" ns | 1.000 | 215 B     |  |\\n| WithTypeCheck | 0.0013 ns | 0.001 | 24 B      |  |\\n\\nOf course, these \", \"two operations aren't semantically equivalent, so if this was for something that required the semant\", \"ics of the former, we couldn't use the latter. But in the case of this LINQ performance optimization\", \", we can choose to only optimize the int[] case, forego the super rare case\\n\\nof the int[] actually b\", \"eing a uint[] (or e.g. DayOfWeek[]), and minimize the performance penalty of the optimization for IE\", \"numerable<int> inputs other than int[] to just a few quick instructions.\\n\\nThis improvement was built\", \" upon further in [dotnet/runtime#64624,](https://github.com/dotnet/runtime/pull/64624) which expands\", \" the input types supported and the operations that take advantage. First, it introduced a private he\", \"lper for extracting a ReadOnlySpan<T> from certain types of IEnumerable<T> inputs, namely today thos\", \"e inputs that are actually either a T[] or a List<T>; as with the previous PR, it uses the GetType()\", \" == typeof(T[]) form to avoid significantly penalizing other inputs. Both of these types enable extr\", \"acting a ReadOnlySpan<T> for the actual storage, in the case of T[] via a cast and in the case of Li\", \"st<T> via the CollectionsMarshal.AsSpan method that was introduced in .NET 5. Once we have that span\", \", we can do a few interesting things. This PR:\\n\\n- Expands the previous Min<T>(IEnumerable<T>) and Ma\", \"x<T>(IEnumerable<T>) optimizations to not only apply to int[] and long[] but also to List<int> and L\", \"ist<long>.\\n- Uses direct span access for Average<T>(IEnumerable<T>) and Sum<T>(IEnumerable<T>) for T\", \" being int, long, float, double, or decimal, all for arrays and lists.\\n- Similarly uses direct span \", \"access for Min<T>(IEnumerable<T>) and Max<T>(IEnumerable<T>) for T being float, double, and decimal.\", \"\\n- Vectorizes Average<int>(IEnumerable<int>) for arrays and lists\\n\\nThe effect of that is evident in \", \"microbenchmarks, e.g.\\n\\n```\\nprivate static float[] CreateRandom()\\n{\\n var r = new Random(42);\\n var res\", \"ults = new float[10_000];\\n for (int i = 0; i < results.Length; i++)\\n {\\n results[i] = (float)r.NextDo\", \"uble();\\n }\\n return results;\\n}\\nprivate IEnumerable<float> _floats = CreateRandom();\\n[Benchmark]\\npubli\", \"c float Sum() => _floats.Sum();\\n[Benchmark]\\npublic float Average() => _floats.Average();\\n[Benchmark]\", \"\\npublic float Min() => _floats.Min();\\n[Benchmark]\\npublic float Max() => _floats.Max();\\n```\\n\\n| Method\", \"  | Runtime  | Mean      | Ratio | Allocated | Alloc Ratio |\\n|---------|----------|-----------|-----\", \"--|-----------|-------------|\\n| Sum     | .NET 6.0 | 39.067 us | 1.00  | 32 B      | 1.00        |\\n|\", \" Sum     | .NET 7.0 | 14.349 us | 0.37  | -         | 0.00        |\\n|         |          |          \", \" |       |           |             |\\n| Average | .NET 6.0 | 41.232 us | 1.00  | 32 B      | 1.00    \", \"    |\\n\\n| Method  | Runtime  | Mean      | Ratio | Allocated | Alloc Ratio |\\n|---------|----------|--\", \"---------|-------|-----------|-------------|\\n| Average | .NET 7.0 | 14.378 us | 0.35  | -         | \", \"0.00        |\\n|         |          |           |       |           |             |\\n| Min     | .NET \", \"6.0 | 45.522 us | 1.00  | 32 B      | 1.00        |\\n| Min     | .NET 7.0 | 9.668 us  | 0.21  | -    \", \"     | 0.00        |\\n|         |          |           |       |           |             |\\n| Max     \", \"| .NET 6.0 | 41.178 us | 1.00  | 32 B      | 1.00        |\\n| Max     | .NET 7.0 | 9.210 us  | 0.22  \", \"| -         | 0.00        |\\n\\nThe previous LINQ PRs were examples from making existing operations fas\", \"ter. But sometimes performance improvements come about from new APIs that can be used in place of pr\", \"evious ones in certain situations to further improve performance. One such example of that comes fro\", \"m new APIs introduced in [dotnet/runtime#70525](https://github.com/dotnet/runtime/pull/70525) from [\", \"@deeprobin](https://github.com/deeprobin) which were then improved in [dotnet/runtime#71564.](https:\", \"//github.com/dotnet/runtime/pull/71564) One of the most popular methods in LINQ is Enumerable.OrderB\", \"y (and its inverse OrderByDescending), which enables creating a sorted copy of the input enumerable.\", \" To do so, the caller passes a Func<TSource,TKey> predicate to OrderBy which OrderBy uses to extract\", \" the comparison key for each item. However, it's relatively common to want to sort items with themse\", \"lves as the keys; this is, after all, the default for methods like Array.Sort, and in such cases cal\", \"lers of OrderBy end up passing in an identity function, e.g. OrderBy(x => x). To eliminate that cruf\", \"t, .NET 7 introduces the new Order and OrderDescending methods, which, in the spirit of pairs like D\", \"istinct and DistinctBy, perform that same sorting operation, just with an implicit x => x done on be\", \"half of the caller. But beyond performance, a nice benefit of this is the implementation then knows \", \"that the keys will all be the same as the inputs, and it no longer needs to invoke the callback for \", \"each item to retrieve its key nor allocate a new array to store those keys. Thus if you find yoursel\", \"f using LINQ and reaching for OrderBy(x => x), consider instead using Order() and reaping the (prima\", \"rily allocation) benefits:\\n\\n```\\n[Params(1024)]\\npublic int Length { get; set; }\\nprivate int[] _arr;\\n[\", \"GlobalSetup]\\npublic void Setup() => _arr = Enumerable.Range(1, Length).Reverse().ToArray();\\n[Benchma\", \"rk(Baseline = true)]\\npublic void OrderBy()\\n{\\n foreach (int _ in _arr.OrderBy(x => x)) { }\\n}\\n[Benchma\", \"rk]\\npublic void Order()\\n{\\n foreach (int _ in _arr.Order()) { }\\n}\\n```\\n\\n| Method  | Length | Mean     \", \"| Ratio | Allocated | Alloc Ratio |\\n|---------|--------|----------|-------|-----------|-------------\", \"|\\n| OrderBy | 1024   | 68.74 us | 1.00  | 12.3 KB   | 1.00        |\\n| Order   | 1024   | 66.24 us | \", \"0.96  | 8.28 KB   | 0.67        |\\n\\n### <span id=\\\"page-163-0\\\"></span>File I/O\\n\\n.NET 6 saw some huge f\", \"ile I/O improvements, in particular a complete rewrite of FileStream. While .NET 7 doesn't have any \", \"single changes on that scale, it does have a significant number of improvements that measurably \\\"mov\", \"e the needle,\\\" and in variety of ways.\\n\\nOne form of performance improvement that also masquerades as\", \" a reliability improvement is increasing responsiveness to cancellation requests. The faster somethi\", \"ng can be canceled, the sooner the system is able to give back valuable resources in use, and the so\", \"oner things waiting for that operation to complete are able to be unblocked. There have been several\", \" improvements of this ilk in .NET 7.\\n\\nIn some cases, it comes from adding cancelable overloads where\", \" things weren't previously cancelable at all. That's the case for [dotnet/runtime#61898](https://git\", \"hub.com/dotnet/runtime/pull/61898) from [@bgrainger](https://github.com/bgrainger), which added new \", \"cancelable overloads of TextReader.ReadLineAsync and TextReader.ReadToEndAsync, and that includes ov\", \"errides of these methods on StreamReader and StringReader; [dotnet/runtime#64301](https://github.com\", \"/dotnet/runtime/pull/64301) from [@bgrainger](https://github.com/bgrainger) then overrode these meth\", \"ods (and others missing overrides) on the NullStreamReader type returned from TextReader.Null and St\", \"reamReader.Null (interestingly, these were defined as two different types, unnecessarily, and so thi\", \"s PR also unified on just having both use the StreamReader variant, as it satisfies the required typ\", \"es of both). You can see this put to good use in [dotnet/runtime#66492](https://github.com/dotnet/ru\", \"ntime/pull/66492) from [@lateapexearlyspeed](https://github.com/lateapexearlyspeed), which adds a ne\", \"w File.ReadLinesAsync method. This produces an IAsyncEnumerable<string> of the lines in the file, is\", \" based on a simple loop around the new StreamReader.ReadLineAsync overload, and is thus itself fully\", \" cancelable.\\n\\nFrom my perspective, though, a more interesting form of this is when an existing overl\", \"oad is purportedly cancelable but isn't actually. For example, the base Stream.ReadAsync method just\", \" wraps the Stream.BeginRead/EndRead methods, which aren't cancelable, so if a Stream-derived type do\", \"esn't override ReadAsync, attempts to cancel a call to its ReadAsync will be minimally effective. It\", \" does an up-front check for cancellation, such that if cancellation was requested prior to the call \", \"being made, it will be immediately canceled, but after that check the supplied CancellationToken is \", \"effectively ignored. Over time we've tried to stamp out all remaining such cases, but a few straggle\", \"rs have remained. One pernicious case has been with pipes. For this discussion, there are two releva\", \"nt kinds of pipes, anonymous and named, which are represented in .NET as pairs of streams:\\n\\nAnonymou\", \"sPipeClientStream/AnonymousPipeServerStream and\\n\\nNamedPipeClientStream/NamedPipeServerStream. Also, \", \"on Windows, the OS makes a distinction between handles opened for synchronous I/O from handles opene\", \"d for overlapped I/O (aka asynchronous I/O), and this is reflected in the .NET API: you can open a n\", \"amed pipe for synchronous or overlapped I/O based on the PipeOptions.Asynchronous option specified a\", \"t construction. And, on\\n\\nUnix, named pipes, contrary to their naming, are actually implemented on to\", \"p of Unix domain sockets. Now some history:\\n\\n- .NET Framework 4.8: No cancellation support. The pipe\", \" Stream-derived types didn't even override ReadAsync or WriteAsync, so all they got was the default \", \"up-front check for cancellation and then the token was ignored.\\n- .NET Core 1.0: On Windows, with a \", \"named pipe opened for asynchronous I/O, cancellation was fully supported. The implementation would r\", \"egister with the CancellationToken, and upon a cancellation request, would use CancelIoEx for the Na\", \"tiveOverlapped\\\\* associated with the asynchronous operation. On Unix, with named pipes implemented i\", \"n terms of sockets, if the pipe was opened with PipeOptions.Asynchronous, the implementation would s\", \"imulate cancellation via polling: rather than simply issuing the Socket.ReceiveAsync/Socket.SendAsyn\", \"c (which wasn't cancelable at the time), it would queue a work item to the ThreadPool, and that work\", \" item would run a polling loop, making Socket.Poll calls with a small timeout, checking the token, a\", \"nd then looping around to do it again until either the Poll indicated the operation would succeed or\", \" cancellation was requested. On both Windows and Unix, other than a named pipe opened with Asynchron\", \"ous, after the operation was initated, cancellation was a nop.\\n- .NET Core 2.1: On Unix, the impleme\", \"ntation was improved to avoid the polling loop, but it still lacked a truly cancelable Socket.Receiv\", \"eAsync/Socket.SendAsync. Instead, by this point Socket.ReceiveAsync supported zero-byte reads, where\", \" a caller could pass a zero-length buffer to ReceiveAsync and use that as notification for data bein\", \"g available to consume without actually consuming it. The Unix implementation for asynchronous named\", \" pipe streams then changed to issue zero-byte reads, and would await a Task.WhenAny of both that ope\", \"ration's task and a task that would be completed when cancellation was requested. Better, but still \", \"far from ideal.\\n- .NET Core 3.0: On Unix, Socket got truly cancelable ReceiveAsync and SendAsync met\", \"hods, which asynchronous named pipes were updated to utilize. At this point, the Windows and Unix im\", \"plementations were effectively on par with regards to cancellation; both good for asynchronous named\", \" pipes, and just posing for everything else.\\n- .NET 5: On Unix, SafeSocketHandle was exposed and it \", \"became possible to create a Socket for an arbitrary supplied SafeSocketHandle, which enabled creatin\", \"g a Socket that actually referred to an anonymous pipe. This in tern enabled every PipeStream on Uni\", \"x to be implemented in terms of Socket, which enabled ReceiveAsync/SendAsync to be fully cancelable \", \"for both anonymous and named pipes, regardless of how they were opened.\\n\\nSo by .NET 5, the problem w\", \"as addressed on Unix, but still an issue on Windows. Until now. In .NET 7, we've made the rest of th\", \"e operations fully cancelable on Windows as well, thanks to [dotnet/runtime#72503](https://github.co\", \"m/dotnet/runtime/pull/72503) (and a subsequent tweak in [dotnet/runtime#72612](https://github.com/do\", \"tnet/runtime/pull/72612)). Windows doesn't support overlapped I/O for anonymous pipes today, so for \", \"anonymous pipes and for named pipes opened for synchronous I/O, the Windows implementation would jus\", \"t delegate to the base Stream implementation, which would queue a work item to the ThreadPool to inv\", \"oke the synchronous counterpart, just on another thread. Instead, the implementations now queue that\", \" work item, but instead of just calling the synchronous method, it does some pre- and post- work tha\", \"t registers for cancellation, passing in the thread ID of the thread that's about to perform the I/O\", \". If cancellation is requested, the implementation then uses CancelSynchronousIo to interrupt it. Th\", \"ere's a race condition here, in that the moment the thread registers for cancellation, cancellation \", \"could be requested, such that CancelSynchronousIo could be called before the operation is actually i\", \"nitiated.\\n\\nSo, there's a small spin loop employed, where if cancellation is requested between the ti\", \"me registration occurs and the time the synchronous I/O is actually performed, the cancellation thre\", \"ad will spin until the I/O is initiated, but this condition is expected to be exceedingly rare. Ther\", \"e's also a race condition on the other side, that of CancelSynchronousIo being requested after the I\", \"/O has already completed; to address that race, the implementation relies on the guarantees made by \", \"CancellationTokenRegistration.Dispose, which promises that the associated callback will either never\", \" be invoked or will already have fully completed executing by the time Dispose returns. Not only doe\", \"s this implementation complete the puzzle such that all asynchronous read/write operations on both a\", \"nonymous and named pipes on both Windows and Unix are cancelable, it also actually improves normal t\", \"hroughput.\\n\\n```\\nprivate Stream _server;\\nprivate Stream _client;\\nprivate byte[] _buffer = new byte[1]\", \";\\nprivate CancellationTokenSource _cts = new CancellationTokenSource();\\n[Params(false, true)]\\npublic\", \" bool Cancelable { get; set; }\\n[Params(false, true)]\\npublic bool Named { get; set; }\\n[GlobalSetup]\\np\", \"ublic void Setup()\\n{\\n if (Named)\\n {\\n string name = Guid.NewGuid().ToString(\\\"N\\\");\\n var server = new N\", \"amedPipeServerStream(name, PipeDirection.Out);\\n var client = new NamedPipeClientStream(\\\".\\\", name, Pi\", \"peDirection.In);\\n Task.WaitAll(server.WaitForConnectionAsync(), client.ConnectAsync());\\n _server = s\", \"erver;\\n _client = client;\\n }\\n else\\n {\\n var server = new AnonymousPipeServerStream(PipeDirection.Out)\", \";\\n var client = new AnonymousPipeClientStream(PipeDirection.In, \\nserver.ClientSafePipeHandle);\\n _ser\", \"ver = server;\\n _client = client;\\n }\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n _server.Dispose();\\n _\", \"client.Dispose();\\n}\\n[Benchmark(OperationsPerInvoke = 1000)]\\npublic async Task ReadWriteAsync()\\n{\\n Ca\", \"ncellationToken ct = Cancelable ? _cts.Token : default;\\n for (int i = 0; i < 1000; i++)\\n {\\n```\\n\\n```\\n\", \" ValueTask<int> read = _client.ReadAsync(_buffer, ct);\\n await _server.WriteAsync(_buffer, ct);\\n awai\", \"t read;\\n }\\n}\\n```\\n\\n| Method         | Runtime  | Cancelable | Named | Mean     | Ratio | Allocated | \", \"Alloc Ratio |\\n|----------------|----------|------------|-------|----------|-------|-----------|-----\", \"--------|\\n| ReadWriteAsync | .NET 6.0 | False      | False | 22.08 us | 1.00  | 400 B     | 1.00    \", \"    |\\n| ReadWriteAsync | .NET 7.0 | False      | False | 12.61 us | 0.76  | 192 B     | 0.48        \", \"|\\n|                |          |            |       |          |       |           |             |\\n| \", \"ReadWriteAsync | .NET 6.0 | False      | True  | 38.45 us | 1.00  | 400 B     | 1.00        |\\n| Read\", \"WriteAsync | .NET 7.0 | False      | True  | 32.16 us | 0.84  | 220 B     | 0.55        |\\n|         \", \"       |          |            |       |          |       |           |             |\\n| ReadWriteAsy\", \"nc | .NET 6.0 | True       | False | 27.11 us | 1.00  | 400 B     | 1.00        |\\n| ReadWriteAsync |\", \" .NET 7.0 | True       | False | 13.29 us | 0.52  | 193 B     | 0.48        |\\n|                |    \", \"      |            |       |          |       |           |             |\\n| ReadWriteAsync | .NET 6.\", \"0 | True       | True  | 38.57 us | 1.00  | 400 B     | 1.00        |\\n| ReadWriteAsync | .NET 7.0 | \", \"True       | True  | 33.07 us | 0.86  | 214 B     | 0.54        |\\n\\nThe rest of the performance-focus\", \"ed changes around I/O in .NET 7 were primarily focused on one of two things: reducing syscalls, and \", \"reducing allocation.\\n\\nSeveral PRs went into reducing syscalls on Unix as part of copying files, e.g.\", \" File.Copy and FileInfo.CopyTo. [dotnet/runtime#59695](https://github.com/dotnet/runtime/pull/59695)\", \" from [@tmds](https://github.com/tmds) reduced overheads in several ways. The code had been performi\", \"ng a stat call in order to determine up front whether the source was actually a directory, in which \", \"case the operation would error out. Instead, the PR simply tries to open the source file, which it w\", \"ould need to do anyway for the copy operation, and then it only performs that stat if opening the fi\", \"le fails. If opening the file succeeds, the code was already performing an fstat to gather data on t\", \"he file, such as whether it was seekable; with this change, it now also extracts from the results of\", \" that single fstat the source file size, which it then threads through to the core copy routine, whi\", \"ch itself is then able to avoid an fstat syscall it had been performing in order to get the size. Sa\", \"ving those syscalls is great, in particular for very small files where the overhead of setting up th\", \"e copy can actually be more expensive than the actual copy of the bytes. But the biggest benefit of \", \"this PR is that it takes advantage of IOCTL-FICLONERANGE on Linux. Some Linux file systems, like XFS\", \" and Btrfs, support \\\"copy-on-write,\\\" which means that rather than copying all of the data to a new f\", \"ile, the file system simply notes that there are two different files pointing to the same data, shar\", \"ing the underlying storage. This makes the \\\"copy\\\" super fast, since nothing actually needs to be cop\", \"ied and instead the file system just needs to update some bookkeeping; plus, less space is consumed \", \"on disk, since there's just a single store of the data. The file system then only needs to actually \", \"copy data that's overwritten in one of the files. This PR uses ioctl and FICLONE to perform the copy\", \" as copy-on-write if the source and destination file system are the same and the file system support\", \"s the operation. In a similar vein, [dotnet/runtime#64264](https://github.com/dotnet/runtime/pull/64\", \"264) from [@tmds](https://github.com/tmds) further improves File.Copy/FileInfo.CopyTo by utilizing c\", \"opy\\\\_file\\\\_range on Linux if it's supported (and only if it's a new enough kernel that it addresses\\n\", \"\\nsome issues the function had in previous releases). Unlike a typical read/write loop that reads the\", \" data from the source and then writes it to the destination, copy\\\\_file\\\\_range is implemented to sta\", \"y entirely in kernel mode, without having to transition to user space for each read and write.\\n\\nAnot\", \"her example of avoiding syscalls comes for the File.WriteXx and File.AppendXx methods when on Unix. \", \"The implementation of these methods opens a FileStream or a SafeFileHandle directly, and it was spec\", \"ifying FileOptions.SequentialScan. SequentialScan is primarily relevant for reading data from a file\", \", and hints to OS caching to expect data to be read from the file sequentially rather than randomly.\", \" However, these write/append methods don't read, they only write, and the implementation of FileOpti\", \"ons.SequentialScan on Unix requires an additional syscall via posix\\\\_fadvise (passing in POSIX\\\\_FADV\", \"\\\\_SEQUENTIAL); thus, we're paying for a syscall and not benefiting from it. This situation is akin t\", \"o the famous Henny Youngman joke: \\\"The patient says, 'Doctor, it hurts when I do this'; the doctor s\", \"ays, 'Then don't do that!'.\\\" Here, too, the answer is \\\"don't do that,\\\" and so [dotnet/runtime#59247]\", \"(https://github.com/dotnet/runtime/pull/59247) from [@tmds](https://github.com/tmds) simply stops pa\", \"ssing SequentialScan in places where it won't help but may hurt.\\n\\nDirectory handling has seen reduce\", \"d syscalls across the directory lifecycle, especially on Unix. [dotnet/runtime#58799](https://github\", \".com/dotnet/runtime/pull/58799) from [@tmds](https://github.com/tmds) speeds up directory creation o\", \"n Unix. Previously, the implementation of directory creation would first check to see if the directo\", \"ry already existed, which involves a syscall. In the expected minority case where it already existed\", \" the code could early exit out. But in the expected more common case where the directory didn't exis\", \"t, it would then parse the file path to find all of the directories in it, walk up the directory lis\", \"t until it found one that did exist, and then try to create all of the subdirectories back down thro\", \"ugh the target one. However, the expected most common case is the parent directories already exist a\", \"nd the child directory doesn't, in which case we're still paying for all that parsing when we could \", \"have just created the target directory. This PR addresses that by changing the up-front existence ch\", \"eck to instead simply try to mkdir the target directory; if it succeeds, great, we're done, and if i\", \"t fails, the error code from the failure can be used instead of the existence check to know whether \", \"mkdir failed because it had no work to do. [dotnet/runtime#61777](https://github.com/dotnet/runtime/\", \"pull/61777) then takes this a step further and avoids string allocations while creating directories \", \"by using stack memory for the paths temporarily needed to pass to mkdir.\\n\\n[dotnet/runtime#63675](htt\", \"ps://github.com/dotnet/runtime/pull/63675) then improves the performance of moving directories, on b\", \"oth Unix and Windows, removing several syscalls. The shared code for Directory.Move and DirectorInfo\", \".MoveTo was doing explicit directory existence checks for the source and destination locations, but \", \"on Windows the Win32 API called to perform the move does such checks itself, so they're not needed p\", \"reemptively. On Unix, we can similarly avoid the existence check for the source directory, as the re\", \"name function called will similarly simply fail if the source doesn't exist (with an appropriate err\", \"or that let's us deduce what went wrong so the right exception can be thrown), and for the destinati\", \"on, the code had been issuing separate existence checks for whether the destination existed as a dir\", \"ectory or as a file, but a single stat call suffices for both.\\n\\n```\\nprivate string _path1;\\nprivate s\", \"tring _path2;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n _path1 = Path.GetTempFileName();\\n _path2 = Path.G\", \"etTempFileName();\\n```\\n\\n```\\n File.Delete(_path1);\\n File.Delete(_path2);\\n Directory.CreateDirectory(_p\", \"ath1);\\n}\\n[Benchmark]\\npublic void Move()\\n{\\n Directory.Move(_path1, _path2);\\n Directory.Move(_path2, _\", \"path1);\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------|--------\", \"--|----------|-------|-----------|-------------|\\n| Move   | .NET 6.0 | 31.70 us | 1.00  | 256 B     \", \"| 1.00        |\\n| Move   | .NET 7.0 | 26.31 us | 0.83  | -         | 0.00        |\\n\\nAnd then also on\", \" Unix, [dotnet/runtime#59520](https://github.com/dotnet/runtime/pull/59520) from [@tmds](https://git\", \"hub.com/tmds) improves directory deletion, and in particular recursive deletion (deleting a director\", \"y and everything it contains and everything they contain and so on), by utilizing the information al\", \"ready provided by the file system enumeration to avoid a secondary existence check.\\n\\nSyscalls were a\", \"lso reduced as part of support for memory-mapped files. [dotnet/runtime#63754](https://github.com/do\", \"tnet/runtime/pull/63754) takes advantage of special-casing to do so while opening a MemoryMappedFile\", \". When MemoryMappedFile.CreateFromFile was called, one of the first things it would do is call File.\", \"Exists to determine whether the specified file already exists; that's because later in the method as\", \" part of dealing with errors and exceptions, the implementation needs to know whether to delete the \", \"file that might then exist; the implementation constructs a FileStream, and doing might will the spe\", \"cified file into existence. However, that only happens for some FileMode values, which is configurab\", \"le via an argument passed by callers of CreateFromFile. The common and default value of FileMode is \", \"FileMode.Open, which requires that the file exist such that constructing the FileStream will throw i\", \"f it doesn't. That means we only actually need to call File.Exists if the FileMode is something othe\", \"r than Open or CreateNew, which means we can trivially avoid the extra system call in the majority c\", \"ase. [dotnet/runtime#63790](https://github.com/dotnet/runtime/pull/63790) also helps here, in two wa\", \"ys. First, throughout the CreateFromFile operation, the implementation might access the FileStream's\", \" Length multiple times, but each call results in a syscall to read the underlying length of the file\", \". We can instead read it once and use that one value for all of the various checks performed. Second\", \", .NET 6 introduced the File.OpenHandle method which enables opening a file handle / file descriptor\", \" directly into a SafeFileHandle, rather than having to go through FileStream to do so. The use of th\", \"e FileStream in MemoryMappedFile is actually quite minimal, and so it makes sense to just use the Sa\", \"feFileHandle directly rather than also constructing the superfluous FileStream and its supporting st\", \"ate. This helps to reduce allocations.\\n\\nFinally, there's [dotnet/runtime#63794,](https://github.com/\", \"dotnet/runtime/pull/63794) which recognizes that a MemoryMappedViewAccessor or MemoryMappedViewStrea\", \"m opened for read-only access can't have been written to. Sounds obvious, but the practical implicat\", \"ion of this is that closing either needn't bother flushing, since that view couldn't have changed an\", \"y data in the implementation, and flushing a view can be relatively expensive, especially for larger\", \" views. Thus, a simple change to avoid flushing if the view isn't writable can yield a measurable im\", \"provement to MemoryMappedViewAccessor/MemoryMappedviewStream's Dispose.\\n\\n```\\nprivate string _path;\\n[\", \"GlobalSetup]\\npublic void Setup()\\n{\\n _path = Path.GetTempFileName();\\n File.WriteAllBytes(_path, Enume\", \"rable.Range(0, 10_000_000).Select(i => \\n(byte)i).ToArray());\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\", \"\\n{\\n File.Delete(_path);\\n}\\n[Benchmark]\\npublic void MMF()\\n{\\n using var mmf = MemoryMappedFile.CreateFr\", \"omFile(_path, FileMode.Open, null);\\n using var s = mmf.CreateViewStream(0, 10_000_000, MemoryMappedF\", \"ileAccess.Read);\\n}\\n```\\n\\n| Method | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------\", \"|----------|----------|-------|-----------|-------------|\\n| MMF    | .NET 6.0 | 315.7 us | 1.00  | 4\", \"88 B     | 1.00        |\\n| MMF    | .NET 7.0 | 227.1 us | 0.68  | 336 B     | 0.69        |\\n\\nBeyond \", \"system calls, there have also been a plethora of improvements around reducing allocation. One such c\", \"hange is [dotnet/runtime#58167,](https://github.com/dotnet/runtime/pull/58167) which improved the pe\", \"rformance of the commonly-used File.WriteAllText{Async} and File.AppendAllText{Async} methods. The P\", \"R recognizes two things: one, that these operations are common enough that it's worth avoiding the s\", \"mall-butmeasurable overhead of going through a FileStream and instead just going directly to the und\", \"erlying SafeFileHandle, and, two, that since the methods are passed the entirety of the payload to o\", \"utput, the implementation can use that knowledge (in particular for length) to do better than the St\", \"reamWriter that was previously employed. In doing so, the implementation avoids the overheads (prima\", \"rily in allocation) of the streams and writers and temporary buffers.\\n\\n```\\nprivate string _path;\\n[Gl\", \"obalSetup]\\npublic void Setup() => _path = Path.GetRandomFileName();\\n[GlobalCleanup]\\npublic void Clea\", \"nup() => File.Delete(_path);\\n[Benchmark]\\npublic void WriteAllText() => File.WriteAllText(_path, Sonn\", \"et);\\n```\\n\\n| Method       | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------------|-\", \"---------|----------|-------|-----------|-------------|\\n| WriteAllText | .NET 6.0 | 488.5 us | 1.00 \", \" | 9944 B    | 1.00        |\\n| WriteAllText | .NET 7.0 | 482.9 us | 0.99  | 392 B     | 0.04        \", \"|\\n\\n[dotnet/runtime#61519](https://github.com/dotnet/runtime/pull/61519) similarly updates File.ReadA\", \"llBytes{Async} to use SafeFileHandle (and RandomAccess) directly rather than going through FileStrea\", \"m, shaving off some allocation from each use. It also makes the same SequentialScan change as mentio\", \"ned earlier. While this case *is* about reading (whereas the previous change saw SequentialScan bein\", \"g complete overhead with no benefit), ReadAllBytes{Async} is very frequently used to read smaller fi\", \"les where the overhead of the additional syscall can measure up to 10% of the total cost (and for la\", \"rger files, modern kernels are pretty good about caching even without a sequentiality hint, so there\", \"'s little downside measured there).\\n\\nAnother such change is [dotnet/runtime#68662,](https://github.c\", \"om/dotnet/runtime/pull/68662) which improved Path.Join's handling of null or empty path segments. Pa\", \"th.Join has overloads that accept strings and overloads that accept ReadOnlySpan<char>s, but all of \", \"the overloads produce strings. The string-based overloads just wrapped each string in a span and del\", \"egated to the span-based overloads. However, in the event that the join operation is a nop (e.g. the\", \"re are two path segments and the second is empty so the join should just return the first), the span\", \"-based implementation still needs to create a new string (there's no way for the ReadOnlySpan<char>-\", \"based overloads to extract a string from the span). As such, the string-based overloads can do a lit\", \"tle bit better in the case of one of them being null or empty; they can do the same thing the Path.C\", \"ombine overloads do, which is to have the M argument overload delegate to the M-1 argument overload,\", \" filtering out a null or empty, and in the base case of the overload with two arguments, if a segmen\", \"t is null or empty, the other (or empty) can just be returned directly.\\n\\nBeyond that, there are a mu\", \"ltitude of allocation-focused PRs, such as [dotnet/runtime#69335](https://github.com/dotnet/runtime/\", \"pull/69335) from [@pedrobsaila](https://github.com/pedrobsaila) which adds a fast-path based on stac\", \"k allocation to the internal ReadLink helper that's used on Unix anywhere we need to follow symlinks\", \", or [dotnet/runtime#68752](https://github.com/dotnet/runtime/pull/68752) that updates NamedPipeClie\", \"ntStream.ConnectAsync to remove a delegate allocation (by passing state into a Task.Factory.StartNew\", \" call explicitly), or [dotnet/runtime#69412](https://github.com/dotnet/runtime/pull/69412) which add\", \"s an optimized Read(Span<byte>) override to the Stream returned from Assembly.GetManifestResourceStr\", \"eam.\\n\\nBut my personal favorite improvement in this area come from [dotnet/runtime#69272,](https://gi\", \"thub.com/dotnet/runtime/pull/69272) which adds a few new helpers to Stream:\\n\\n```\\npublic void ReadExa\", \"ctly(byte[] buffer, int offset, int count);\\npublic void ReadExactly(Span<byte> buffer);\\npublic Value\", \"Task ReadExactlyAsync(byte[] buffer, int offset, int count, CancellationToken \\ncancellationToken = d\", \"efault);\\npublic ValueTask ReadExactlyAsync(Memory<byte> buffer, CancellationToken cancellationToken \", \"\\n= default);\\npublic int ReadAtLeast(Span<byte> buffer, int minimumBytes, bool throwOnEndOfStream = \\n\", \"true);\\npublic ValueTask<int> ReadAtLeastAsync(Memory<byte> buffer, int minimumBytes, bool\\nthrowOnEnd\", \"OfStream = true, CancellationToken cancellationToken = default);\\n```\\n\\nIn fairness, these are more ab\", \"out usability than they are about performance, but in this case there's a tight correlation between \", \"the two. It's very common to write these helpers one's self (the aforementioned PR deleted many open\", \"-coded loops for this functionality from across the core libraries) as the functionality is greatly \", \"needed, and it's unfortunately easy to get them wrong in ways\\n\\nthat negatively impact performance, s\", \"uch as by using a Stream.ReadAsync overload that needs to allocate a returned Task<int> or reading f\", \"ewer bytes than is allowed as part of a read call. These implementations are correct and efficient.\\n\", \"\\n### <span id=\\\"page-172-0\\\"></span>Compression\\n\\n.NET Core 2.1 added support for the [Brotli](https://\", \"en.wikipedia.org/wiki/Brotli) compression algorithm, surfacing it in two ways: BrotliStream and the \", \"pair of BrotliEncoder/BrotliDecoder structs that BrotliStream is itself built on top of. For the mos\", \"t part, these types just provide wrappers around a native C implementation from [google/brotli,](htt\", \"ps://github.com/google/brotli) and so while the .NET layer has the opportunity to improve how data i\", \"s moved around, managed allocation, and so on, the speed and quality of the compression itself are l\", \"argely at the mercy of the C implementation and the intricacies of the Brotli algorithm.\\n\\nAs with ma\", \"ny compression algorithms, Brotli provides a knob that allows for a quintessential tradeoff to be ma\", \"de between compression speed (how fast data can be compressed) and compression quality/ratio (how sm\", \"all can the compressed output be made). The hand-wavy idea is the more time the algorithm spends loo\", \"king for opportunity, the more space can be saved. Many algorithms expose this as a numerical dial, \", \"in Brotli's case going from 0 (fastest speed, least compression) to 11 (spend as much time as is nee\", \"ded to minimize the output size). But while BrotliEncoder surfaces that same range, BrotliStream's s\", \"urface area is simpler: most use just specifies that compression should be performed (e.g. new Brotl\", \"iStream(destination, CompressionMode.Compress)) and the only knob available is via the CompressionLe\", \"vel enum (e.g. new BrotliStream(destination, CompressionLevel.Fastest)), which provides just a few o\", \"ptions: CompressionLevel.NoCompression, CompressionLevel.Fastest, CompressionLevel.Optimal, and Comp\", \"ressionLevel.SmallestSize. This means the BrotliStream implementation needs to select a default valu\", \"e when no CompressionLevel is specified and needs to map CompressionLevel to an underlying numerical\", \" value when one is.\\n\\nFor better or worse (and I'm about to argue \\\"much worse\\\"), the native C impleme\", \"ntation itself defines the default to be 11 [\\\\(google/brotli#encode.h](https://github.com/google/bro\", \"tli/blob/9801a2c5d6c67c467ffad676ac301379bb877fc3/c/include/brotli/encode.h#L60-L61)), and so that's\", \" what BrotliStream has ended up using when no CompressionLevel is explicitly specified. Further, the\", \" CompressionLevel.Optimal enum value is poorly named. It's intended to represent a good default that\", \"'s a balanced tradeoff between speed and quality; that's exactly what it means for DeflateStream, GZ\", \"ipStream, and ZLibStream. But for BrotliStream, as the default it similarly got translated to mean t\", \"he underlying native library's default, which is 11. This means that when constructing a BrotliStrea\", \"m with either CompressionMode.Compress or CompressionLevel.Optimal, rather than getting a nice balan\", \"ced default, you're getting the dial turned all the way up to 11.\\n\\nIs that so bad? Maybe compression\", \" quality is the most important thing? For example, reducing the size of data can make it faster to t\", \"hen transmit it over a wire, and with a slow connection, size then meaningfully translates into end-\", \"to-end throughput.\\n\\nThe problem is just how much this extra effort costs. Compression speed and rati\", \"o are highly dependent on the data being compressed, so take this example with a small grain of salt\", \" as it's not entirely representative of all use, but it's good enough for our purposes. Consider thi\", \"s code, which\\n\\nuses BrotliEncoder to compress the [The Complete Works of William Shakespeare from Pr\", \"oject](https://www.gutenberg.org/cache/epub/100/pg100.txt)  [Gutenberg](https://www.gutenberg.org/ca\", \"che/epub/100/pg100.txt) at varying levels of compression:\\n\\n```\\nusing System.Buffers;\\nusing System.Di\", \"agnostics;\\nusing System.IO.Compression;\\nusing System.Text;\\nusing var hc = new HttpClient();\\nbyte[] d\", \"ata = await hc.GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-8\\\");\\nConsole.WriteLin\", \"e(data.Length);\\nvar compressed = new MemoryStream();\\nvar sw = new Stopwatch();\\nfor (int level = 0; l\", \"evel <= 11; level++)\\n{\\n const int Trials = 10;\\n compressed.Position = 0;\\n Compress(level, data, comp\", \"ressed);\\n sw.Restart();\\n for (int i = 0; i < Trials; i++)\\n {\\n compressed.Position = 0;\\n Compress(lev\", \"el, data, compressed);\\n }\\n sw.Stop();\\n Console.WriteLine($\\\"{level},{sw.Elapsed.TotalMilliseconds / \\n\", \"Trials},{compressed.Position}\\\");\\n static void Compress(int level, byte[] data, Stream destination)\\n \", \"{\\n var encoder = new BrotliEncoder(quality: level, window: 22);\\n Write(ref encoder, data, destinatio\", \"n, false);\\n Write(ref encoder, Array.Empty<byte>(), destination, true);\\n encoder.Dispose();\\n static \", \"void Write(ref BrotliEncoder encoder, byte[] data, Stream destination, bool\\nisFinalBlock)\\n {\\n byte[]\", \" output = ArrayPool<byte>.Shared.Rent(4096);\\n OperationStatus lastResult = OperationStatus.Destinati\", \"onTooSmall;\\n ReadOnlySpan<byte> buffer = data;\\n while (lastResult == OperationStatus.DestinationTooS\", \"mall)\\n {\\n lastResult = encoder.Compress(buffer, output, out int bytesConsumed, out\\nint bytesWritten,\", \" isFinalBlock);\\n if (lastResult == OperationStatus.InvalidData) throw new\\nInvalidOperationException(\", \");\\n if (bytesWritten > 0) destination.Write(output.AsSpan(0, bytesWritten));\\n if (bytesConsumed > 0)\", \" buffer = buffer.Slice(bytesConsumed);\\n }\\n ArrayPool<byte>.Shared.Return(output);\\n }\\n```\\n\\n } }\\n\\nThe \", \"code is measuring how long it takes to compress the input data at each of the levels (doing a warmup\", \" and then averaging several iterations), timing how long it takes and capturing the resulting compre\", \"ssed data size. For the size, I get values like this:\\n\\n| Level | Size (bytes) |\\n|-------|-----------\", \"---|\\n| 0     | 2,512,855.00 |\\n| 1     | 2,315,466.00 |\\n| 2     | 2,224,638.00 |\\n| 3     | 2,218,328.\", \"00 |\\n| 4     | 2,027,153.00 |\\n| 5     | 1,964,810.00 |\\n| 6     | 1,923,456.00 |\\n| 7     | 1,889,927.\", \"00 |\\n| 8     | 1,863,988.00 |\\n| 9     | 1,846,685.00 |\\n| 10    | 1,741,561.00 |\\n| 11    | 1,702,214.\", \"00 |\\n\\n![](_page_174_Figure_3.jpeg)\\n\\nThat's a fairly liner progression from least to most compression\", \". That's not the problem. This is the problem:\\n\\n| Level | Time<br>(ms) |  |\\n|-------|--------------|\", \"--|\\n| 0     | 24.11        |  |\\n| 1     | 36.67        |  |\\n| 2     | 64.13        |  |\\n| 3     | 73\", \".72        |  |\\n| 4     | 146.41       |  |\\n| 5     | 257.12       |  |\\n| 6     | 328.54       |  |\\n\", \"| 7     | 492.81       |  |\\n| 8     | 702.38       |  |\\n| 9     | 892.08       |  |\\n| 10    | 4,830.\", \"32     |  |\\n| 11    | 10,634.88    |  |\\n\\n![](_page_175_Figure_1.jpeg)\\n\\nThis chart shows an almost ex\", \"ponential increase in processing time as we near the upper end of the dial, with quality level 11 co\", \"mpressing ~33% better than quality level 0 but taking ~440x as long to achieve that. If that's what \", \"a developer wants, they can specify CompressionLevel.SmallestSize, but that cost by default and for \", \"the balanced CompressionLevel.Optimal is far out of whack.\\n\\n[dotnet/runtime#72266](https://github.co\", \"m/dotnet/runtime/pull/72266) fixes that. A very small change, it simply makes CompressMode.Compress \", \"and CompressionLevel.Optimal for Brotli map to quality level 4, which across many kinds of inputs do\", \"es represent a fairly balanced trade-off between size and speed.\\n\\n```\\nprivate byte[] _data = new\\nHtt\", \"pClient().GetByteArrayAsync(\\\"https://www.gutenberg.org/ebooks/100.txt.utf-8\\\").Result;\\nprivate Stream\", \" _output = new MemoryStream();\\n[Benchmark]\\npublic void Compress()\\n{\\n _output.Position = 0;\\n using va\", \"r brotli = new BrotliStream(_output, CompressionMode.Compress, leaveOpen: \\ntrue);\\n brotli.Write(_dat\", \"a);\\n}\\n```\\n\\n| Method   | Runtime  | Mean       | Ratio |\\n|----------|----------|------------|-------|\", \"\\n| Compress | .NET 6.0 | 9,807.0 ms | 1.00  |\\n| Compress | .NET 7.0 | 133.1 ms   | 0.01  |\\n\\nOther im\", \"provements have gone into compression, such as [dotnet/runtime#69439](https://github.com/dotnet/runt\", \"ime/pull/69439) which updates the internal ZipHelper.AdvanceToPosition function used by ZipArchive t\", \"o reuse a buffer on every iteration of a loop rather than allocating a new buffer for each iteration\", \", [dotnet/runtime#66764](https://github.com/dotnet/runtime/pull/66764) which uses spans judiciously \", \"to avoid a bunch of superfluous string and string[] allocations from System.IO.Packaging, and [dotne\", \"t/runtime#73082](https://github.com/dotnet/runtime/pull/73082) updating the zlib implementations shi\", \"pped as part of .NET from v1.2.11 (which was released in January 2017) to v1.2.12 (which was release\", \"d in March 2022).\\n\\n### <span id=\\\"page-177-0\\\"></span>Networking\\n\\nNetworking is the life-blood of almo\", \"st every service, with performance being critical to success. In previous releases, a lot of effort \", \"was focused on the lower layers of the networking stack, e.g. .NET 5 saw a significant investment in\", \" improving the performance of sockets on Linux. In .NET 7, much of the effort is above sockets.\\n\\nTha\", \"t said, there were some interesting performance improvements in sockets itself for .NET 7. One of th\", \"e more interesting is [dotnet/runtime#64770,](https://github.com/dotnet/runtime/pull/64770) which re\", \"vamped how some synchronization is handled inside of SocketsAsyncEventArgs. As background, in the ea\", \"rly days of networking in .NET Framework, asynchrony was enabled via Begin/End methods (the \\\"APM\\\" pa\", \"ttern). This pattern is not only complicated to use well, it's relatively inefficient, resulting in \", \"allocation for every single operation performed (at a minimum for the IAsyncResult object that's ret\", \"urned from the BeginXx method). To help make networking operations more efficient, SocketsAsyncEvent\", \"Args was introduced. SocketsAsyncEventArgs is a reusable class you allocate to hold all of the state\", \" associated with asynchronous operations: allocate one, pass it to various async methods (e.g. Recei\", \"veAsync), and then completion events are raised on the SocketAsyncEventArgs instance when the operat\", \"ion completes. It can be quite efficient when used correctly, but it's also complicated to use corre\", \"ctly. In subsequent releases, Task-based and ValueTask-based APIs were released; these have the effi\", \"ciency of SocketAsyncEventArgs and the ease-of-use of async/await, and are the recommended starting \", \"point for all Socket-based asynchronous programming today. They have the efficiency of SocketAsyncEv\", \"entArgs because they're actually implemented as a thin veneer on top of it under the covers, and so \", \"while most code these days isn't written to use SocketAsyncEventArgs directly, it's still very relev\", \"ant from a performance perspective.\\n\\nSocketAsyncEventArgs on Windows is implemented to use winsock a\", \"nd overlapped I/O. When you call an async method like ValueTask<Socket> Socket.AcceptAsync(Cancellat\", \"ionToken), that grabs an internal SocketAsyncEventArgs and issues an AcceptAsync on it, which in tur\", \"n gets a NativeOverlapped\\\\* from the ThreadPoolBoundHandle associated with the socket, and uses it t\", \"o issue the native AcceptEx call. When that handle is initially created, we set the FILE\\\\_SKIP\\\\_COMP\", \"LETION\\\\_PORT\\\\_ON\\\\_SUCCESS completion notification mode on the socket; use of this was introduced in \", \"earlier releases of .NET Core, and it enables a significant number of socket operations, in particul\", \"ar sends and receives, to complete synchronously, which in turn saves unnecessary trips through the \", \"thread pool, unnecessary unwinding of async state machines, and so on. But it also causes a condundr\", \"um. There are some operations we want to perform associated with asynchronous operation but that hav\", \"e additional overhead, such as registering for the cancellation of those operations, and we don't wa\", \"nt to pay the cost of doing them if the operation is going to complete synchronously. That means we \", \"really want to delay performing such registration until after we've made the native call and discove\", \"red the operation didn't complete synchronously\\u2026 but at that point we've already initiated the opera\", \"tion, so if it *doesn't* complete synchronously, then we're now in\\n\\na potential race condition, wher\", \"e our code that's still setting up the asynchronous operation is racing with it potentially completi\", \"ng in a callback on another thread. Fun. SocketAsyncEventArgs handled this race condition with a spi\", \"n lock; the theory was that contention would be incredibly rare, as the vast majority cases would ei\", \"ther be the operation completing synchronously (in which case there's no other thread involved) or a\", \"synchronously with enough of a delay that the small amount of additional work performed by the initi\", \"ating thread would have long ago completed by the time the asynchronous operation completed. And for\", \" the most part, that was true. However, it turns out that it's actually much more common than expect\", \"ed for certain kinds of operations, like Accepts. Accepts end up almost always completing asynchrono\", \"usly, but if there's already a pending connection, completing asynchronously almost immediately, whi\", \"ch then induces this race condition to happen more frequently and results in more contention on the \", \"spin locks. Contention on a spin lock is something you really want to avoid. And in fact, for a part\", \"icular benchmark, this spin lock showed up as the cause for an almost 300% slowdown in requests-per-\", \"second (RPS) for a benchmark that used a dedicated connection per request (e.g. with every response \", \"setting \\\"Connection: close\\\"). [dotnet/runtime#64770](https://github.com/dotnet/runtime/pull/64770) c\", \"hanged the synchronization mechanism to no longer involve a spin lock; instead, it maintains a simpl\", \"e gate implemented as an Interlocked.CompareExchange. If the initiating thread gets to the gate firs\", \"t, from that point on the operation is considered asynchronous and any additional work is handled by\", \" the completing callback. Conversely, if the callback gets to the gate first, the initiating thread \", \"treats the operation as if it completed synchronously. This not only avoids one of the threads spinn\", \"ing while waiting for the other to make forward progress, it also increases the number of operations\", \" that end up being handled as synchronous, which in turn reduces other costs (e.g. the code awaiting\", \" the task returned from this operation doesn't need to hook up a callback and exit, and can instead \", \"itself continue executing synchronously). The impact of this is difficult to come up with a microben\", \"chmark for, but it can have meaningful impact for loaded Windows servers that end up accepting signi\", \"ficant numbers of connections in steady state.\\n\\nA more-easily quantifiable change around sockets is \", \"[dotnet/runtime#71090,](https://github.com/dotnet/runtime/pull/71090) which improves the performance\", \" of SocketAddress.Equals. A SocketAddress is the serialized form of an EndPoint, with a byte[] conta\", \"ining the sequence of bytes that represent the address. Its Equals method, used to determine whether\", \" to SocketAddress instances are the same, looped over that byte[] byte-by-byte. Not only is such cod\", \"e gratuitous when there are now helpers available like SequenceEqual for comparing spans, doing it b\", \"yte-by-byte is also much less efficient than the vectorized implementation in SequenceEqual. Thus, t\", \"his PR simply replaced the open-coded comparison loop with a call to SequenceEqual.\\n\\n```\\nprivate Soc\", \"ketAddress _addr = new IPEndPoint(IPAddress.Parse(\\\"123.123.123.123\\\"), \\n80).Serialize();\\nprivate Sock\", \"etAddress _addr_same = new IPEndPoint(IPAddress.Parse(\\\"123.123.123.123\\\"), \\n80).Serialize();\\n[Benchma\", \"rk]\\npublic bool Equals_Same() => _addr.Equals(_addr_same);\\n```\\n\\n| Method      | Runtime  | Mean     \", \" | Ratio |\\n|-------------|----------|-----------|-------|\\n| Equals_Same | .NET 6.0 | 57.659 ns | 1.0\", \"0  |\\n| Equals_Same | .NET 7.0 | 4.435 ns  | 0.08  |\\n\\nLet's move up to some more interesting changes \", \"in the layers above Sockets, starting with SslStream.\\n\\nOne of the more impactful changes to SslStrea\", \"m on .NET 7 is in support for TLS resumption on Linux. When a TLS connection is established, the cli\", \"ent and server engage in a handshake protocol where they collaborate to decide on a TLS version and \", \"cipher suites to use, authenticate and validate each other's identity, and create symmetric encrypti\", \"on keys for use after the handshake. This represents a significant portion of the time required to e\", \"stablish a new connection. For a client that might disconnect from a server and then reconnect later\", \", as is fairly common in distributed applications, TLS resumption allows a client and server to esse\", \"ntially pick up where they left off, with the client and/or server storing some amount of informatio\", \"n about recent connections and using that information to resume. Windows SChannel provides default s\", \"upport for TLS resumption, and thus the Windows implementation of SslStream (which is built on SChan\", \"nel) has long had support for TLS resumption. But OpenSSL's model requires additional code to enable\", \" TLS resumption, and such code wasn't present in the Linux implementation of SslStream. With [dotnet\", \"/runtime#57079](https://github.com/dotnet/runtime/pull/57079) and [dotnet/runtime#63030,](https://gi\", \"thub.com/dotnet/runtime/pull/63030) .NET 7 adds server-side support for TLS resumption (using the va\", \"riant that *doesn't* require storing recent connection state on the server), and with [dotnet/runtim\", \"e#64369,](https://github.com/dotnet/runtime/pull/64369) .NET 7 adds client-side support (which *does\", \"* require storing additional state). The effect of this is significant, in particular for a benchmar\", \"k that opens and closes lots of connections between clients.\\n\\n```\\nprivate NetworkStream _client, _se\", \"rver;\\nprivate readonly byte[] _buffer = new byte[1];\\nprivate readonly SslServerAuthenticationOptions\", \" _options = new\\nSslServerAuthenticationOptions\\n{\\n ServerCertificateContext = SslStreamCertificateCon\", \"text.Create(GetCertificate(), null),\\n};\\n[GlobalSetup]\\npublic void Setup()\\n{\\n using var listener = ne\", \"w Socket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp);\\n listener.Bind(new IPEnd\", \"Point(IPAddress.Loopback, 0));\\n listener.Listen(1);\\n var client = new Socket(AddressFamily.InterNetw\", \"ork, SocketType.Stream, \\nProtocolType.Tcp);\\n client.Connect(listener.LocalEndPoint);\\n _server = new \", \"NetworkStream(listener.Accept(), ownsSocket: true);\\n _client = new NetworkStream(client, ownsSocket:\", \" true);\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n _client.Dispose();\\n _server.Dispose();\\n}\\n[Benchma\", \"rk]\\npublic async Task Handshake()\\n{\\n using var client = new SslStream(_client, leaveInnerStreamOpen:\", \" true, delegate { return\\n```\\n\\n```\\ntrue; });\\n    using var server = new SslStream(_server, leaveInner\", \"StreamOpen: true, delegate { return\\ntrue; });\\n\\n    await Task.WhenAll(\\n        client.AuthenticateAs\", \"ClientAsync(\\\"localhost\\\", null, SslProtocols.None,\\ncheckCertificateRevocation: false),\\n        server\", \".AuthenticateAsServerAsync(_options));\\n\\n    await client.WriteAsync(_buffer);\\n    await server.ReadA\", \"sync(_buffer);\\n    await server.WriteAsync(_buffer);\\n    await client.ReadAsync(_buffer);\\n}\\n\\nprivate\", \" static X509Certificate2 GetCertificate() =>\\n    new X509Certificate2(\\n```\\n\\nConvert.FromBase64String\", \"(\\\"MIIUmgIBAzCCFFYGCSqGSIb3DQEHAaCCFEcEghRDMIIUPzCCCiAGCSqGSIb3DQEHA aCCChEEggoNMIIKCTCCCgUGCyqGSIb3D\", \"QEMCgECoIIJfjCCCXowHAYKKoZIhvcNAQwBAzAOBAhCAauvUWggWwICB9AE gglYefzzX/jx0b+BLU/TkAVj1KBpojf0o6qdTXV4\", \"2drqIGhX/k1WwF1ypVYdHeeuDfhH2eXHImwPTw+0bACY0dSiIHK ptm0sb/MskoGI8nl0tHWLi+QBirJ9LSUZcBNOLwoMeYLSFEW\", \"WBT69k/sWrc6/SpDoVumkfG4pZ02D9bQgs1+k8fpZjZ GoZp1jput8CQXPE3JpCsrkdSdiAbWdbNNnYAy4C9Ej/vdyXJVdBTEsKz\", \"PYajAzo6Phj/oS/J3hMxxbReMtj2Z0QkoBB VMc70d+DpAK50Y3et872D5bZivxhjAYh5JoVTCLTLjbtPRn1g7qh2dOsIpf05Krd\", \"gqdImshHvxgL92ooC1e0VqOffMn Z0/LchWNb2rMDa89K9CtAefEIF4ve2b0UZUNFqQ6dvd90SgKq6jNfwQf/1u70WKE86+vChXM\", \"McHFeKso6hTE9+/zuUP NVmbRefYAtDd7ng996S15FNVdxqyVLlmfcihX1jGhTLi//WuMEaOfXJ9KiwYUyxdUnMp50Jq08X/tiwn\", \"suhlFe3NKMX Y77jUe8F7I+dv5cjb9iKXAT+q8oYx1LcWu2mj1ER9/b2omnotp2FIaJDwI40Tts6t40VH3bUNE9gFIfTMK+WMgKB\", \"z/J AGvC1vbPSdFsWIqwh17mEYWx83HJp/+Uqp5f+d8m4phSan2rkHEeDjkUaoifLWHWDmL94SZBrgU6yGVK9dU82kr7jCS UTrn\", \"ga8qDYsHwpQ22QZtu0aOJGepSwZU7NZNMiyX6QR2hI0CNMjvTK2VusHFB+qnvw+19DzaDT6P0KNPxwBwp07KMQm 3HWTRNt9u6gK\", \"Umo5FHngoGte+TZdY66dAwCl0Pt+p1v18Xl0B2KOQZKLXnhgikjOwYQxFr3oTb2MjsP6YqnSF9EpYpm iny SXiYmrYxVinHmK+5\", \"JBqoQCN2C3N24s1ZkYq+AYUTnNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITRW40T+0XZnIv8G1Kbaq/1avAVLNST7Ib2We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnI\", \"v8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICO\", \"FdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnI\", \"v8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICO\", \"FdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITR\", \"W40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZnIv8We3bBICOFdVUgtFITRW40T+0XZNIv8We3bBICOFdVUgtFITRW40T+0XZNI\", \"v8We3bBICOFdVUgtFITRW40T+0XZNIv8We3bBICOFdVUgtFITRW40T+0XZNIv8We3bBICOFdVUgtFITRW40T+0XZNIv8We3bBICO\", \"FdVUgtFITRW40T+0XZNIv8We3bBICOFGVUgtFITRW40T+0XZNIv8We3bBICOFGVUgtFITRW40T+0XZNIVAFFITRW40T+0XZNIVAF\", \"FITRW40T+0XZNIVAFFITRW40T+0XZNIVAFFITRW40T+0XZNIVAFFITRW40T+0XZNIVAFFITRW40T+0XZNIVAFFITRW40T+0XZNIV\", \"AFFITRW40T+0XZNIVAFFITRWfWI/ieKKxyiYp/ZNXaxc+ycgpsSsAJEuhb83bUkSBpGg9PvFEF0DXm4ah67Ja1SSTmvrCnr0sWZX\", \"IpciexMWRGoKrdv d7Yzj9E8hiu+CGTC4T6+7FxVXJrjCg9zU9G2U6g7uxzoyjGj1wqkhxgvl9pPbz6/KqDRLOHCEwRF4qlWXhsJ\", \"y4levxG tifFt6n7DWaNSsOUf8Nwpi+d4fd7LQ7B5tW/y+/vVZziORueruCWO4LnfPhpJ70g18uyN7KyzrWy29rpE46rfjZGGt0 \", \"WDZYahObPbw6HjcqSOuzwRoJMxamQb2qsuQnaBS6Bhb5PAnY4SEA045odf/u9uC7mLom2KGNHHz6HrgEPas2UHoJLux YvY1pza/\", \"29akuVQZQUvMA5yMFHHGYZLtTKtCGdVGwX0+QS6ovpV93xux4I/5TrD5U8z9RmTdAx03R3MUhkHF7Zbv5eg DNsVar+41YWG4VkV\", \"1ZXtsZRKJf0hvKNvrpH0e7fVKBdXljm5PXOSg2Vdtkhh0pnKKSMcv6MbGWVi/svWLnc7Qim4A4M Daz+bFVZmh3oGJ7WHvRQhWIc\", \"HUL+YJx+064+4IKXZJ/2a/+b2o7C8mJ3GGSBx831ADogg6MRWZx3UY190Z8YMvpzmZE BRZZnm4KgNpj+SQnf6pGzD2cmnRhzG60\", \"LSNPb17iKbdoUAEMkgt2tlMKXpnt1r7qwsIoTt407cAdCEsUH70U/AjfFmS kKJZ7vC5HweqZPnhgJgZ6LYHlfiRzUR1xeDg8JG0\", \"nb0vb7LUE4nGPy39/TxIGos7WNwGpG1QVL/8pKjFdjwREaR8e5C STlQ7gxHV+G3FFvFGpA1p8cRFzlgE6khDLrSJIUkhkHMA3oF\", \"wwAzBNIKVXjToyxCogDqxWya0E1Hw5rVCS/z0CS1De2 XQbXs//g46TW0wTJwvgNbs0xLShf3XB+23meeEsMTCR0+igtMMMsh5K/\", \"vBUGcJA27ru/KM9qEBcseb/tqCkhhsdj1dn H0HDmpgFf5DfVrjm+P6ickcF2b+Ojr9t7XHgFszap3C0pEPGmeJqNOUTuU53tu/O\", \"774IBgqINMWvvG65yQwsE006jRr FPRUGb0eH6UM4vC7wbKajnfDuI/EXSgvuOSZ9wE8DeoeK/5We4pN7MSWoDl39gI/LBoNDKFY\", \"EYuAw/bhGp8nOwDKki4 a16aYcBGRClpN3ymrdurWsi7TjyFHXfgW8fZe4jXLuKRIk19lmL1gWyD+3bT3mkI2cU2OaY2C0fVHhti\", \"BVaYbxBV8+k iK8q0070zf0r+xMHnewk9APFqUjguPguTdpCoH0VAOST9Mmriv/J12+Y+fL6H+jrtDY2zHPxTF85pA4bBBnLA70t\", \"9TK Ce6uuWu5yBqx0V3w2Oa4Pockv1gJzFbVnwlEUWnIjbWVIyo9vo4LBd03uJHPPIQbUp9kCP/Zw+Zblo42/ifyY+a+scw l1q1\", \"dZ7Y0L92yJCKm9Qf6Q+1PBK+uU9pcuVTg/Imqcg5T7jF05QCi88uwcorgQp+qoeFi0F9tnUecfD16d0PSgAPnX9 XAOny3bPwSiW\", \"OA8+uW73gesxnGTsNrtc1j85tai18N6m6S2tHXwOmM65J4XRZ1zzeM4D/Rzzh13xpRA9kzm9T2cSHsX EYmSW1X7WovrmYhdOh9K\", \"3DPwSyG4tD58cvC7X79UbOB+d17ieo7ZCj+NSLVQO1BqTK0QfErdoVHGKfQG8Lc/ERQRqj1 32Mhi2/r5Ca7AWdqD7/3wgRdQTJS\", \"FXt/akpM44xu5DMTCISEFOLWiseSOBtzT6ssaq2Q35dCkXp5wVbWxkXAD7Gm34F FXXyZrJWAx45Y40wj/0KDJoEzXCuS4Cyiskx\", \"1EtYNNOtfDC5wngywmINFUnnW0NkdKSxmDJvrT6HkRKN8ftik7tP4Zv TaTS28Z0fDmWJ+RjvZW+vtF6mrIzYgG0gdpZwG0Z0SKr\", \"XKrY3xpM016fXyawFfBosLzCty7uA57niPS76UXdbplgPan IGFyceTg1MsNDsd8vszXd4KezN2VMaxvw+93s0Uk/3Mc+5MAj+Uh\", \"XPi5UguXMhNo/CU7erzyxYre01AI7ZzGhPk+oT9 g/MqWa5RpA2IBUaK/wgaNaHChfCcDj/J1qEl6YQQboixxp1IjQxiV9bRQzgw\", \"f31Cu2m/FuHTTkPCdxDK156pyFdhcgT pTNy7RPLDF0MBMGCSqGSIb3DQEJFTEGBAQBAAAAMF0GCSsGAQQBgjcRATFQHk4ATQBpA\", \"GMAcgBvAHMAbwBmAHQAIABT AHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgBhAHAAaABpAGMAIABQAHIAbwB2AGkAZABlAHIw\", \"ggoXBgkqhkiG9w0 BBwagggoIMIIKBAIBADCCCf0GCSqGSIb3DQEHATAcBgoqhkiG9w0BDAEGMA4ECH63Q8xWHKhqAgIH0ICCCdD\", \"Ao9x82r wRM6s16wMo01glVedahn1COCP1FKmP6lQ3kjcHruIWlcKW+eCUpt41qs0LM3iFcPQj5x7675DeLL0AC2Ebu7Jhg0FGM \", \"JZwHLbmJLyG0VSb1WhX2UfxNSdLrdZv8pmejB7DYdV3xAj8DBCRGfwwnbTQjFH9wUPga5U79Dvpqq+YVvUEEci1N6tT Pu32LOOE\", \"vjoEtpskrHoKyqLGV7sSgM6xMIDcfVWbLb8fDcVS1JQRHbeOdGC1FMDjwzr+eGWd+OyOZ6BydUGjIKAZpRp\\n\\n0YTk5jjYUMNRbvB\", \"P1VPq9ASIh8pJnt/Kq1nqfj7EPatXJJUZAH35E6bSbLBnP0+5+xim114HsB8066c4B3aTUXnLepP RyMIn6Xh5ev0pF3aUc4ZlWg\", \"ar57TzKUFBTkcH5OCbqZloQ7ZCDNc4C3WKVLSUOKLj3Q0xJPrb6/nyXZHjki1tGKisb9 RLv4dkeMdRjsSwNRn6Cfdlk2qHWUCiW\", \"LlsLXFyMSM12qrSSfIIBRo0wbn1SEJagHqUmlF9UR5A6b5OODIbDq3cXH/q6 U09zVX/BxqxyZqEfeSAcvXjqImLWnZzbIgm0QH7\", \"jOtti/vEfvdzypdWH9V64PzQj/5B8P4ZpbQyWUgzKEIdx24WhTOc dwNivkaEkGFTra3qw2dKO0RTVtx3bSgesHCumQDuDf8yafL\", \"fchWuqihYV7zvqW9BWrsa0W7yKNXLNqdlSz8KvuTnFff OOHrJQwBs+JKdMcKX5IR222RH3fp8Dp17y8hFEaPp4AqpuhHGALXOCw\", \"muPt1UjuHRCUluh3BjaPPLNwLmSGfe0piOVh 4rTyJCfN4rlz0lWBAAfIHi47J9sTnSgEJgkTuemPJXssQ3Z/trcYdfhlYjel0Bt\", \"S/5DW3wFmjNDilwVBQT66li5xUvc WvZPx/scXgbgpsMThqguJWtiPLR1SzusKCN4q7bV08D8ErHh5uMb5NmNRIZ/xNeqs1qTU9A\", \"4bi0TE0FjEu28F0Wg4Cx iwqNM58xik9eni85t+S0Uo9wPV1V2Vdhe9LkO3PeoSTCau4D189DoViL44WPDO+TCSv1PP7SFEwaBvU\", \"lGBWjxJWVb81 lkgRsol1bllUvIzN13V0LSiA0Nks9w9H8cQ17ZRe2r7SpDDR6Rn5oLb9G98AyvlcgJfyUe1iZCUAUZGEU247Kwe\", \"PtXY AlO47HbAJe0bOtM9zp7KyWxbImKCfxsPWv6CR6PH+ooHDBO9kXVpKaJCYWeYybSMuPufy/u/rMcIVO4oXVsdnjh4jAx pQO\", \"XowCAcN2+Q+XnqtiCr9Mzd0q5ee7jsYuJF6LQRdNP04wIpwjpdggKyB7zURPeTX1V8vIjUs25+CoCxp+fCXfXKqe 2xxdbQ2zFbp\", \"KSbJdpbWad3F6MsFBGOKTdyK8EZODGApBtlo71kY6uOxKiBwJKd76zTMsPEQWOZphi2khpTxIVYONrmP  ${\\\\tt KjS08zc4dTC8\", \"SW+d1kmCt4UYb1woeDCAYp2RiDHpgC+5yuBDCooT/6fG6GQpa1X0PiH2oUCpltZz2M4+1bH2HdTeBfc}$ 1Mtj/hniLL8VdH0qcp\", \"S0KYPUxJFEg6IxxrWw10BreY//6pJLm76nKiflzhz+Mt0RbQZqkPP/K9BxzQw//bW9Kh4iRQ3 7D9HNQG/GtrCEcbH4V4uUjbj34\", \"sEo0FC7gVvDob0Bik81/c901zQZEydqe0DgHtGbY2xIZ2qqsQy4LDVfHNHqSLiNss L8BJtxUyvnhiwHD7jmyCB6cWyFGtibRBeh\", \"QzleioS16xvLph88CMGV3IH9By5QtXpDIB4vjhibE6coPkTmpDCB9xlTE 3TV4GBt5JLttkjf0kXAAx0xD523Adcy6FVe5QYuY10\", \"817006188YptozyWi5jVfDh+aDg9pjsw/aZ1hCURe9KDaB4gI lW4ZEGKsf5e/xU+vuVxw374te/Y2aCChSj93XyC+Fjxe06s4yi\", \"fVAYA0+HtLMGNHe/X0kPXvRnoa5kIu0yHrzViQrBb /4Sbms617Gg1BFONks1J02G0zIt8CouTqVmdtuH7tV0JZV/Nmg7NQ1X59X\", \"DC/JH2i4jOu8OhnmIZFlTysS6e1qnqsGt /0XcUyzPia8+UIAynXmyi8sWlUjy37w6YqapAfcs7B3TezqIwn7RgRasJpNBi7eQQq\", \"g5YLe6EYTxctKNkGpzeTBUiXN XM4Gv3tIaMbzwlhUNbYWuNBsi/7XJPM5jMycINRbdPwYy19gRBs3pm0FoP2Lhl5mVAJ2R8a40L\", \"o5g73wvt9Th+uB9/y c196RryQe280yfgKiwUoFFcDnL6SoQTRCT195mF8zw1f3Hc7QImhubgcLntXEndzSNN7ZIDSAB8HiDSR6C\", \"GYPNiCNAC 4hj+jUswoWIE257h+deWFTUvjTZmXH+XMoN6trqjdeCH0hePdmrIWVdr1uTIo016TR6mFNm6Utzc0t5vVrcpnEh3w6\", \"a mVHw5xmweW4S75ncN6vSPxGjtfuQ6c2RTG5NXZuWpnhXwOxgoBN4q/h99zVRvwwsF32Eyzx6GOYLmORgCkzke9eXjjX WY83oy\", \"sXx/aE9WCqt3en8zzRzzA1aO9Yi88uv1O0qTvWEoGrf4e7SgjXO6hNjYE6EEvK+mMz6a9F3xSWsUlMsZPIIBe 8CEgNEhXKsa6xw\", \"7ljSx8Nz7zYG+u5rgXKFmSNvWvwasZyIfRXkccqODl17BaevbWp/ir3rJ/b9m0iV0UW8qIJ3zC6b1 1XU5pNuOODjqhKkjIHPGXi\", \"q1+uBPVlfUy8Zbi4AntZAeNIB7HtUavVKX6CF7k9AFtRHIWK70+cFEw4yMZiQjaWeB3dt 16Fz6LZ8+c17kuB2wFuZQqYQkf3quW\", \"QVPwKj41gFYoFSwFfJ8L6TBcNHI2u3avtVp9ZbP9zArT8An9Ryri/PwTSbPLT caz549b60/0k4c/qV4XRMuFsi29CXcMnLSCPpP\", \"Ks71LTvsRXK6QUJd4fX/KnTiWargbS6tT61R/bBqY/gFU1xWyKQ8x ij97v1Qjff5Kdcbj5JsnjSr8xAh9idfJ2FWZZUJReR9EU1\", \"twK7slyUivNLVY7bqroE6CzYaEDecRqfwIrFrzmH+gJoM 88waGRC0JTvm8GpBX0eTb5bnMxJKPtH1GIffgyQLER01jwjApr6SJE\", \"B4yV7x48CZPod9wE510xUY2hEdAA517DBTJys g5gn/nhY6ZzL01lb39yVyDEcZdmrji0ncEMdBDioGBV3mNz1DL398ZLdjG+xkn\", \"eI3sgyzgm3cZZ1+/A2kloIEmOKJSe 0k/B1cyMB5QRnXp0bF1vWXjauMVIKm0w1LY3YQ9I1vfr6y1o2DN+Vy0sumbIQrjDKqMDsw\", \"HzAHBgUrDgMCGgQUHEWyD 7i5PbatVl3k0+S9WV3ZJRAEFFd7xcvfj1HpkOawyGnJdtcQ0KWPAgIH0A==\\\"),\\n\\n\\\"testcertifica\", \"te\\\",\\n\\nX509KeyStorageFlags.DefaultKeySet);\\n\\n| Method    | Runtime  | Mean     | Ratio | Allocated | A\", \"lloc Ratio |\\n|-----------|----------|----------|-------|-----------|-------------|\\n| Handshake | .NE\", \"T 6.0 | 4.647 ms | 1.00  | 19.27 KB  | 1.00        |\\n| Handshake | .NET 7.0 | 2.314 ms | 0.50  | 9.5\", \"6 KB   | 0.50        |\\n\\nAnother significant improvement for Ss1Stream in .NET 7 is support for OCSP \", \"stapling. When a client handshakes with the server and the server shares its certificate, a client t\", \"hat cares about validating it's talking to exactly who it intended to talk to needs to validate that\", \" certificate. In the days of yore, such validation was done with certificate revocation lists (CRL),\", \" where periodically the client would download a giant list of certificates known to be revoked. Onli\", \"ne Certificate Status Protocol (OCSP) is a newer protocol and mechanism that enables a client to get\", \" real-time information about a certificate; while the client handshakes with the server and the serv\", \"er sends the client its certificate, the client then connects to an \\\"OCSP responder\\\" and sends it a \", \"request to determine whether the certificate is considered good. OCSP has multiple issues of its own\", \", however. In particular, it places a significant load on these OCSP responder servers, with every c\", \"lient making a real-time request to it about every certificate encountered, and also potentially sig\", \"nificantly increasing the time it takes the client to establish a connection. OCSP stapling offers a\", \" solution to this. Rather than a client issuing a request to\\n\\nthe OCSP responder, the server itself \", \"contacts the OCSP responder and gets a signed ticket from the OCSP responder stating that the server\", \"'s certificate is good and will be for some period of time. When a client handshakes with the server\", \", the server can then \\\"staple\\\" (include) this signed ticket as part of its response to the client, g\", \"iving the validation to the client directly rather than the client needing to make a separate roundt\", \"rip to the OCSP responder. This reduces overheads for everyone involved. [dotnet/runtime#67011](http\", \"s://github.com/dotnet/runtime/pull/67011) adds support for OCSP stapling to SslStream client usage o\", \"n Linux, with [dotnet/runtime#69833](https://github.com/dotnet/runtime/pull/69833) adding the Linux \", \"server-side counterpart, and [dotnet/runtime#71570](https://github.com/dotnet/runtime/pull/71570) ad\", \"ds client-side support for Windows.\\n\\nThe aforementioned changes are primarily about the performance \", \"of opening a connection. Additional work has been done to improve that further in other ways. [dotne\", \"t/runtime#69527](https://github.com/dotnet/runtime/pull/69527) gets rid of allocations associated wi\", \"th several SafeHandle instances that were being created unnecessarily on Linux as part of establishi\", \"ng a TLS connection. This highlights the benefits of doing profiling on multiple platforms, as while\", \" these SafeHandles were necessary in the Windows implementation, they were fairly meaningless in the\", \" Linux implementation (due to differences between SChannel and OpenSSL), and were only brought along\", \" for the ride because of how the platform-abstraction layer (PAL) was defined to reuse most of the S\", \"slStream code across platforms. And [dotnet/runtime#68188](https://github.com/dotnet/runtime/pull/68\", \"188) avoids several collections allocated as part of the TLS handshake. This one is particularly int\", \"eresting as it's come up multiple times in the past in various libraries. Imagine you have a lazily \", \"initialized property like this:\\n\\n```\\nprivate List<T>? _items;\\npublic List<T> Items => _items ??= new\", \" List<T>();\\n```\\n\\nAnd then some code in the same implementation comes along and wants to read the con\", \"tents of these items. That code might look like:\\n\\n```\\nif (Items.Count > 0) { ... }\\n```\\n\\nbut the very\", \" act of accessing Items just to check its count forces the collection into existence (with a 0 Count\", \"). If the code instead checks:\\n\\n```\\nif (_items is List<T> items && items.Count > 0) { ... }\\n```\\n\\nIt \", \"can save that unnecessary collection allocation. The approach is made even simpler with C# pattern m\", \"atching:\\n\\n```\\nif (_items is { Count: > 0 }) items) { ... }\\n```\\n\\nThis is one of those things that's i\", \"ncredibly obvious once you \\\"see\\\" it and realize what's happening, but you often miss until it jumps \", \"out at you in a profiler.\\n\\n[dotnet/runtime#69098](https://github.com/dotnet/runtime/pull/69098) is a\", \"nother good example of how profiling can lead to insights about allocations that can be removed. App\", \"lication-Layer Protocol Negotation (ALPN) allows code establishing a TLS connection to piggy-back on\", \" the roundtrips that are being used for the TLS handshake anyway to negotiate some higher-level prot\", \"ocol that will end up being used as well. A very common use-case, for example, is for an HTTPS clien\", \"t/server to negotiate which version of HTTP should be used. This information is exposed from SslStre\", \"am as an SslApplicationProtocol struct returned from its NegotiatedApplicationProtocol property, but\", \" as the actual negotiated protocol can be arbitrary data, SslApplicationProtocol just wraps a byte[]\", \". The implementation had been\\n\\ndutifully allocating a byte[] to hold the bytes passed around as part\", \" of ALPN, since we need such a byte[] to store in the SslApplicationProtocol. But while the byte dat\", \"a *can* be arbitrary, in practice by far the most common byte sequences are equivalent to \\\"http/1.1\\\"\", \" for HTTP/1.1, \\\"h2\\\" for HTTP/2, and \\\"h3\\\" for HTTP/3. Thus, it makes sense to special-case those valu\", \"es and use a reusable cached byte[] singleton when one of those values is needed. If SslApplicationP\", \"rotocol exposed the underlying byte[] directly to consumers, we'd be hesitant to use such singletons\", \", as doing so would mean that if code wrote into the byte[] it would potentially be changing the val\", \"ue for other consumers in the same process. However, SslApplicationProtocol exposes it as a ReadOnly\", \"Memory<byte>, which is only mutable via unsafe code (using the MemoryMarshal.TryGetArray method), an\", \"d once you're employing unsafe code to do \\\"bad\\\" things,\\\" all bets are off anyway. [dotnet/runtime#63\", \"674](https://github.com/dotnet/runtime/pull/63674) also removes allocations related to ALPN, in this\", \" case avoiding the need for a byte[] allocation on Linux when setting the negotiated protocol on a c\", \"lient SslStream. It uses stack memory instead of an array allocation for protocols up to 256 bytes i\", \"n length, which is way larger than any in known use, and thus doesn't bother to do anything fancy fo\", \"r the fallback path, which will never be used in practice. And [dotnet/runtime#69103](https://github\", \".com/dotnet/runtime/pull/69103) further avoids ALPNrelated allocations and work on Windows by entire\", \"ly skipping some unnecessary code paths: various methods can be invoked multiple times during a TLS \", \"handshake, but even though the ALPN-related work only needed to happen once the first time, the code\", \" wasn't special-casing it and was instead repeating the work over and over.\\n\\nEverything discussed th\", \"us far was about establishing connections. What about the performance of reading and writing on that\", \" connection? Improvements have been made there, too, in particular around memory management and asyn\", \"chrony. But first we need some context.\\n\\nWhen async/await were first introduced, Task and Task<TResu\", \"lt> were the only game in town; while the pattern-based mechanism the compiler supports for arbitrar\", \"y \\\"task-like\\\" types enabled async methods to return other types, in practice it was only tasks (whic\", \"h also followed our guidance). We soon realized, however, that a significant number of calls to a si\", \"gnificant number of commonly-used async APIs would actually complete synchronously. Consider, for ex\", \"ample, a method like MemoryStream.ReadAsync: MemoryStream is backed entirely by an in-memory buffer,\", \" so even though the operation is \\\"async,\\\" every call to it completes synchronously, as the operation\", \" can be performed without doing any potentially long-running I/O. Or consider FileStream.ReadAsync. \", \"By default FileStream employs its own internal buffer. If you issue a call to FileStream.ReadAsync w\", \"ith your own buffer and ask for only, say, 16 bytes, under the covers FileStream.ReadAsync will issu\", \"e the actual native call with its own much larger buffer, which by default is 4K. The first time you\", \" issue your 16-byte read, actual I/O will be required and the operation is likely to complete asynch\", \"ronously. But the next 255 calls you make could simply end up draining the remainder of the data rea\", \"d into that 4K buffer, in which case 255 of the 256 \\\"async\\\" operations actually complete synchronous\", \"ly. If the method returns a Task<int>, every one of those 255 synchronously-completing calls could s\", \"till end up allocating a Task<int>, just to hand back the int that's already known. Various techniqu\", \"es were devised to minimize this, e.g. if the int is one of a few well-known values (e.g. -1 through\", \" 8), then the async method infrastructure will hand back a pre-allocated and cached Task<int> instan\", \"ce for that value, and various stream implementations (including FileStream) would cache the previou\", \"slyreturned Task<int> and hand it back for the next call as well if the next call yielded exactly th\", \"e same number of bytes. But those optimizations don't fully mitigate the issue. Instead, we introduc\", \"ed the ValueTask<TResult> struct and provided the necessary \\\"builder\\\" to allow async methods to retu\", \"rn\\n\\nthem. ValueTask<TResult> was simply a discrimated union between a TResult and Task<TResult>. If \", \"an async method completed asynchronously (or if it failed synchronously), well, it would simply allo\", \"cate the Task<TResult> as it otherwise would have and return that task wrapped in a ValueTask<TResul\", \"t>. But if the method actually completed synchronously and successfully, it would create a ValueTask\", \"<TResult> that just wrapped the resulting TResult, which then eliminates all allocation overhead for\", \" the synchronously-completing case. Yay, everyone's happy. Well, almost everyone. For really hot pat\", \"hs, especially those lower down in the stack that many other code paths build on top of, it can also\", \" be beneficial to avoid the allocations even for the asynchronously completing case. To address that\", \", .NET Core 2.1 saw the introduction of the IValueTaskSource<TResult> interface along with enabling \", \"ValueTask<TResult> to wrap an instance of that interface in addition to a TResult or a Task<TResult>\", \" (at which point it also became meaningful to introduce a non-generic ValueTask and the associated I\", \"ValueTaskSource). Someone can implement this interface with whatever behaviors they want, although w\", \"e codified the typical implementation of the core async logic into the ManualResetValueTaskSourceCor\", \"e helper struct, which is typically embedded into some object, with the interface methods delegating\", \" to corresponding helpers on the struct. Why would someone want to do this? Most commonly, it's to b\", \"e able to reuse the same instance implementing this interface over and over and over. So, for exampl\", \"e, Socket exposes a ValueTask<int> ReceiveAsync method, and it caches a single instance of an IValue\", \"TaskSource<int> implementation for use with such receives. As long as you only ever have one receive\", \" pending on a given socket at a time (which is the 99.999% case), every ReceiveAsync call will eithe\", \"r return a ValueTask<int> wrapped around an int value or a ValueTask<int> wrapped around that reusab\", \"le IValueTaskSource<int>, making all use of ReceiveAsync ammortized allocation-free (there is anothe\", \"r instance used for SendAsync, such that you can have a concurrent read and write on the socket and \", \"still avoid allocations). However, implementing this support is still non-trivial, and can be super \", \"hard when dealing with an operation that's composed of multiple suboperations, which is exactly wher\", \"e async/await shine. Thus, C# 10 added support for overriding the default builder that's used on an \", \"individual async method (e.g. such that someone could provide their own builder for a ValueTask<int>\", \"-returning method instead of the one that allocates Task<int> instances for asynchronous completion)\", \" and .NET 6 included the new\\n\\nPoolingAsyncValueTaskMethodBuilder and PoolingAsyncValueTaskMethodBuil\", \"der<> types. With those, an async method like:\\n\\n```\\npublic async ValueTask<int> ReadAsync(Memory<byt\", \"e> buffer) { ... }\\n```\\n\\ncan be changed to be:\\n\\n```\\n[AsyncMethodBuilder(typeof(PoolingAsyncValueTaskM\", \"ethodBuilder<>))]\\npublic async ValueTask<int> ReadAsync(Memory<byte> buffer) { ... }\\n```\\n\\nwhich will\", \" cause the C# compiler to emit the implementation of this method using PoolingAsyncValueTaskMethodBu\", \"ilder<int> instead of the default AsyncValueTaskMethodBuilder<int>. The implementation of\\n\\nPoolingAs\", \"yncValueTaskMethodBuilder<TResult> is true to its name; it employs pooling to avoid *most* of the al\", \"location asynchronous completion would otherwise experience (I say \\\"most\\\" because the pooling by des\", \"ign tries to balance all the various costs involved and may still sometimes allocate), and makes it \", \"easy for methods implemented with async/await to reap those benefits. So, if this was all introduced\", \" in the last release, why am I talking about it now? Pooling isn't free. There are various\\n\\ntradeoff\", \"s involved in its usage, and while it can make microbenchmarks look really good, it can also negativ\", \"ely impact real-world usage, e.g. by increasing the cost of garbage collections that do occur by inc\", \"reasing the number of Gen2 to Gen0 references that exist. As such, while the functionality is valuab\", \"le, we've been methodical in where and how we use it, choosing to do so more slowly and only employi\", \"ng it after sufficient analysis deems it's worthwhile.\\n\\nSuch is the case with SslStream. With [dotne\", \"t/runtime#69418,](https://github.com/dotnet/runtime/pull/69418) two core and hot async methods on Ss\", \"lStream's read path were annotated to use pooling. A microbenchmark shows what I mean when I wrote t\", \"his can make microbenchmarks look really good (focus on the allocation columns). This benchmark is r\", \"epeatedly issuing a read (that will be forced to complete asynchronously because there's no availabl\", \"e data to satisfy it), then issuing a write to enable that read to complete, and then awaiting the r\", \"ead's completion; every read thus completes asynchronously.\\n\\n```\\nprivate SslStream _sslClient, _sslS\", \"erver;\\nprivate readonly byte[] _buffer = new byte[1];\\nprivate readonly SslServerAuthenticationOption\", \"s _options = new\\nSslServerAuthenticationOptions\\n{\\n ServerCertificateContext = SslStreamCertificateCo\", \"ntext.Create(GetCertificate(), null),\\n};\\n[GlobalSetup]\\npublic void Setup()\\n{\\n using var listener = n\", \"ew Socket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp);\\n listener.Bind(new IPEn\", \"dPoint(IPAddress.Loopback, 0));\\n listener.Listen(1);\\n var client = new Socket(AddressFamily.InterNet\", \"work, SocketType.Stream, \\nProtocolType.Tcp);\\n client.Connect(listener.LocalEndPoint);\\n _sslClient = \", \"new SslStream(new NetworkStream(client, ownsSocket: true), \\nleaveInnerStreamOpen: true, delegate { r\", \"eturn true; });\\n _sslServer = new SslStream(new NetworkStream(listener.Accept(), ownsSocket: true), \", \"\\nleaveInnerStreamOpen: true, delegate { return true; });\\n Task.WaitAll(\\n _sslClient.AuthenticateAsCl\", \"ientAsync(\\\"localhost\\\", null, SslProtocols.None, \\ncheckCertificateRevocation: false),\\n _sslServer.Aut\", \"henticateAsServerAsync(_options));\\n}\\n[GlobalCleanup]\\npublic void Cleanup()\\n{\\n _sslClient.Dispose();\\n\", \" _sslServer.Dispose();\\n}\\n[Benchmark]\\npublic async Task ReadWriteAsync()\\n{\\n for (int i = 0; i < 1000;\", \" i++)\\n {\\n ValueTask<int> read = _sslClient.ReadAsync(_buffer);\\n```\\n\\n```\\n await _sslServer.WriteAsync\", \"(_buffer);\\n await read;\\n }\\n}\\n```\\n\\n| Method         | Runtime  | Mean     | Ratio | Code Size | Alloc\", \"ated | Alloc Ratio |\\n|----------------|----------|----------|-------|-----------|-----------|-------\", \"------|\\n| ReadWriteAsync | .NET 6.0 | 68.34 ms | 1.00  | 510 B     | 336404 B  | 1.000       |\\n| Rea\", \"dWriteAsync | .NET 7.0 | 69.60 ms | 1.02  | 514 B     | 995 B     | 0.003       |\\n\\nOne final change \", \"related to reading and writing performance on an SslStream. I find this one particularly interesting\", \", as it highlights a new and powerful C# 11 and .NET 7 feature: static abstract members in interface\", \"s. SslStream, as with every Stream, exposes both synchronous and asynchronous methods for reading an\", \"d writing. And as you may be aware, the code within SslStream for implementing reads and writes is n\", \"ot particularly small. Thus, we really want to avoid having to duplicate all of the code paths, once\", \" for synchronous work and once for asynchronous work, when in reality the only place that bifurcatio\", \"n is needed is at the leaves where calls into the underlying Stream are made to perform the actual I\", \"/O. Historically, we've had two different mechanisms we've employed in [dotnet/runtime](https://gith\", \"ub.com/dotnet/runtime) for handling such unification. One is to make all methods async, but with an \", \"additional bool useAsync parameter that gets fed through the call chain, then branching based on it \", \"at the leaves, e.g.\\n\\n```\\npublic static void Work(Stream s) =>\\n A(s, useAsyunc: false).GetAwaiter().G\", \"etResult(); // GetResult() to propagate any \\nexceptions\\npublic static Task WorkAsync(Stream S) =>\\n A\", \"(s, useAsync: true);\\ninternal static async Task A(Stream s, bool useAsync)\\n{\\n ...\\n await B(s, useAsy\", \"nc);\\n ...\\n}\\nprivate static async Task B(Stream s, bool useAsync)\\n{\\n ...\\n int bytesRead = useAsync ?\\n\", \" await s.ReadAsync(buffer) :\\n s.Read(buffer.Span);\\n ...\\n}\\n```\\n\\nThis way most of the logic and code i\", \"s shared, and when useAsync is false, everything completes synchronously and so we don't pay for all\", \"ocation that might otherwise be associated with the asyncness. The other approach is similar in spir\", \"it, but instead of a bool parameter, taking advantage of generic specialization and interface-implem\", \"enting structs. Consider an interface like:\\n\\n```\\ninterface IReader\\n{\\n ValueTask<int> ReadAsync(Strea\", \"m s, Memory<byte> buffer);\\n}\\n```\\n\\nWe can then declare two implementations of this interface:\\n\\n```\\nst\", \"ruct SyncReader : IReader\\n{\\n public ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) =>\\n new \", \"ValueTask<int>(s.Read(buffer.Span));\\n}\\nstruct AsyncReader : IReader\\n{\\n public ValueTask<int> ReadAsy\", \"nc(Stream s, Memory<byte> buffer) =>\\n s.ReadAsync(buffer);\\n}\\n```\\n\\nThen we can redeclare our earlier \", \"example as:\\n\\n```\\npublic static void Work(Stream s) =>\\n A(stream, default(SyncReader)).GetAwaiter().G\", \"etResult(); // to propagate any exceptions\\npublic static Task WorkAsync(Stream S) =>\\n A(s, default(A\", \"syncReader));\\ninternal static async Task A<TReader>(Stream s, TReader reader) where TReader : IReade\", \"r\\n{\\n ...\\n await B(s, reader);\\n ...\\n}\\nprivate static async Task B<TReader>(Stream s, TReader reader) \", \"where TReader : IReader\\n{\\n ...\\n int bytesRead = await reader.ReadAsync(s, buffer);\\n ...\\n}\\n```\\n\\nNote \", \"that the generic constraint on the TReader parameter here allows the implementation to invoke the in\", \"terface methods, and passing the structs as a generic avoids boxing. One code path supporting both s\", \"ync and async implementations.\\n\\nThis latter generic approach is how SslStream has historically handl\", \"ed the unification of its sync and async implementations. It gets better in .NET 7 with C# 11 now th\", \"at we have static abstract methods in interfaces. We can instead declare our interface as (note the \", \"static abstract addition):\\n\\n```\\ninterface IReader\\n{\\n static abstract ValueTask<int> ReadAsync(Stream\", \" s, Memory<byte> buffer);\\n}\\n```\\n\\nour types as (note the static addition):\\n\\n```\\nstruct SyncReader : I\", \"Reader\\n{\\n public static ValueTask<int> ReadAsync(Stream s, Memory<byte> buffer) =>\\n new ValueTask<in\", \"t>(s.Read(buffer.Span));\\n}\\nstruct AsyncReader : IReader\\n```\\n\\n```\\n{\\n public static ValueTask<int> Rea\", \"dAsync(Stream s, Memory<byte> buffer) =>\\n s.ReadAsync(buffer);\\n}\\n```\\n\\nand our consuming methods as (\", \"note the removal of the parameter and the switch to calling static methods on the type parameter):\\n\\n\", \"```\\npublic static void Work(Stream s) =>\\n A<SyncReader>(stream).GetAwaiter().GetResult(); // to prop\", \"agate any exceptions\\npublic static Task WorkAsync(Stream S) =>\\n A<AsyncReader>(s);\\ninternal static a\", \"sync Task A<TReader>(Stream s) where TReader : IReader\\n{\\n ...\\n await B<TReader>(s);\\n ...\\n}\\nprivate s\", \"tatic async Task B<TReader>(Stream s) where TReader : IReader\\n{\\n ...\\n int bytesRead = await TReader.\", \"ReadAsync(s, buffer);\\n ...\\n}\\n```\\n\\nNot only is this cleaner, but from a performance perspective we no\", \" longer need to pass around the dummy generic parameter, which is general goodness, but for an async\", \" method it's particularly beneficial because the state machine type ends up storing all parameters a\", \"s fields, which means every parameter can increase the amount of allocation incurred by an async met\", \"hod if the method ends up completing asynchronously. [dotnet/runtime#65239](https://github.com/dotne\", \"t/runtime/pull/65239) flipped SslStream (and NegotiateStream) to follow this approach. It's also use\", \"d in multiple other places now throughout dotnet/runtime. [dotnet/runtime#69278](https://github.com/\", \"dotnet/runtime/pull/69278) from [@teo-tsirpanis](https://github.com/teo-tsirpanis) changed the Rando\", \"mAccess class' implementation for Windows and the ThreadPool's mechanism for invoking work items to \", \"use the same approach. Further, [dotnet/runtime#63546](https://github.com/dotnet/runtime/pull/63546)\", \" did the same in the Regex implementation, and in particular in the new RegexOptions.NonBacktracking\", \" implementation, as a way to abstract over DFA and NFA-based operations using the same code (this te\", \"chnique was since further utilized in NonBacktracking, such as by [dotnet/runtime#71234](https://git\", \"hub.com/dotnet/runtime/pull/71234) from [@olsaarik](https://github.com/olsaarik)). And potentially m\", \"ost impactfully, [dotnet/runtime#73768](https://github.com/dotnet/runtime/pull/73768) did so with In\", \"dexOfAny to abstract away the differences between IndexOfAny and IndexOfAnyExcept (also for the Last\", \" variants). With the introduction of the {Last}IndexOfAnyExcept variations previously mentioned, we \", \"now have four different variants of IndexOfAny with essentially the same functionality: searching fo\", \"rward or backwards, and with equality or inequality. While more challenging to try to unify the dire\", \"ctional aspect, this PR utilized this same kind of generic specialization to hide behind an interfac\", \"e the ability to negate the comparison; the core implementations of these methods can then be implem\", \"ented once and passed either a Negate or DontNegate implementation of the interface. The net result \", \"is not only that the new Except varieties immediately gained all of the optimizations of the non-Exc\", \"ept varieties, but also the goal of trying to make everything consistent resulted in finding places \", \"where we were missing optimization opportunities in existing methods (gaps that the PR also rectifie\", \"d).\\n\\n```\\nprivate static readonly string s_haystack = new\\nHttpClient().GetStringAsync(\\\"https://www.gu\", \"tenberg.org/files/1661/1661-0.txt\\\").Result;\\n[Benchmark]\\npublic int LastIndexOfAny() => s_haystack.As\", \"Span().LastIndexOfAny(';', '_');\\n```\\n\\n| Method         | Runtime  | Mean     | Ratio |\\n|------------\", \"----|----------|----------|-------|\\n| LastIndexOfAny | .NET 6.0 | 9.977 us | 1.00  |\\n| LastIndexOfAn\", \"y | .NET 7.0 | 1.172 us | 0.12  |\\n\\nLet's move up the stack to HTTP. Most of the folks focusing on ne\", \"tworking in .NET 7 were focused on taking the preview support for HTTP/3 that shipped in .NET 6 and \", \"making it a first-class supported feature in .NET 7. That included functional improvements, reliabil\", \"ity and correctness fixes, and performance improvements, such that HTTP/3 can now be used via HttpCl\", \"ient on both Windows and Linux (it depends on an underlying QUIC implementation in the msquic compon\", \"ent, which isn't currently available for macOS). However, there were significant improvements throug\", \"hout the HTTP stack, beyond HTTP/3.\\n\\nOne aspect of HttpClient that cuts across all versions of HTTP \", \"is support for handling and representing headers. While significant improvements went into previous \", \"releases to trim down the size of the data structures used to store header information, further work\", \" on this front was done for .NET 7. [dotnet/runtime#62981,](https://github.com/dotnet/runtime/pull/6\", \"2981) for example, improves the data structure used to store headers. One of the things HttpHeaders \", \"needs to deal with is that there's no defined limit to the number of headers that can be sent with a\", \"n HTTP request or response (though in order to mitigate possible denial of service attacks, the impl\", \"ementation has a configurable limit for how many bytes of headers are accepted from the server), and\", \" thus it needs to be able to handle an arbitrary number of them and to do so with efficient access. \", \"As such, for the longest time HttpHeaders has used a Dictionary<,> to provide O(1) lookup into these\", \" headers. However, while it's valid to have large numbers of headers, it's most common to only have \", \"a handful, and for only a few items, the overheads involved in a hash table like Dictionary<> can be\", \" more than just storing the elements in an array and doing an O(N) lookup by doing a linear search t\", \"hrough all the elements (algorithmic complexity ignores the \\\"constants\\\" involved, so for a small N, \", \"an O(N) algorithm might be much faster and lighterweight than an O(1)). This PR takes advantage of t\", \"hat and teaches HttpHeaders how to use either an array or a dictionary; for common numbers of header\", \"s (the current threshold is 64), it just uses an array, and in the rare case where that threshold is\", \" exceeded, it graduates into a dictionary. This reduces the allocation in HttpHeader in all but the \", \"most niche cases while also making it faster for lookups.\\n\\nAnother header-related size reduction com\", \"es in [dotnet/runtime#64105.](https://github.com/dotnet/runtime/pull/64105) The internal representat\", \"ion of headers involves a HeaderDescriptor that enables \\\"known headers\\\" (headers defined in the HTTP\", \" specifications or that we're otherwise aware of and want to optimize) to share common data, e.g. if\", \" a response header matches one of these known headers, we can just use the header name string single\", \"ton rather than allocating a new string for that header each time we receive it. This HeaderDescript\", \"or accomodated both known headers and custom headers by having two fields, one for known header data\", \" (which would be null for custom headers) and one for the header name. Instead, this PR employs a re\", \"latively-common technique of having a single object field that then stores either the known header i\", \"nformation or the name, since the known header information itself includes the name, and thus we don\", \"'t need the duplication. At the expense of a type check when we\\n\\nneed to look up information from th\", \"at field, we cut the number of fields in half. And while this HeaderDescriptor is itself a struct, i\", \"t's stored in header collections, and thus by cutting the size of the HeaderDescriptor in half, we c\", \"an significantly reduce the size of those collections, especially when many custom headers are invol\", \"ved.\\n\\n```\\nprivate readonly string[] _strings = new[] { \\\"Access-Control-Allow-Credentials\\\", \\\"Access-\\n\", \"Control-Allow-Origin\\\", \\\"Cache-Control\\\", \\\"Connection\\\", \\\"Date\\\", \\\"Server\\\" };\\n[Benchmark]\\npublic HttpRes\", \"ponseHeaders GetHeaders()\\n{\\n var headers = new HttpResponseMessage().Headers;\\n foreach (string s in \", \"_strings)\\n {\\n headers.TryAddWithoutValidation(s, s);\\n }\\n return headers;\\n}\\n```\\n\\n| Method     | Runti\", \"me  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|------------|----------|----------|-------|-----\", \"------|-------------|\\n| GetHeaders | .NET 6.0 | 334.4 ns | 1.00  | 664 B     | 1.00        |\\n| GetHe\", \"aders | .NET 7.0 | 213.9 ns | 0.64  | 360 B     | 0.54        |\\n\\nSimilarly focused on allocation, [d\", \"otnet/runtime#63057](https://github.com/dotnet/runtime/pull/63057) removes two fields from the HttpH\", \"eaderValueCollection<T> collection type, which provides the concrete implementation for ICollection<\", \"T> properties like HttpContentHeaders.ContentEncoding, HttpRequestHeaders.UserAgent, and HttpRespons\", \"eHeaders.Server. The initial design and implementation of this type were overly flexible, with a mec\", \"hanism for custom validation of values, which entailed multiple fields for storing things like an Ac\", \"tion<> callback to use for validation. But as it turns out in practice, that validation was only use\", \"d for one specific consumer, and so rather than making everyone pay for the extra space that wasn't \", \"typically used, the validation was instead extracted out to just the call sites it was required.\\n\\nA \", \"more focused allocation reduction comes in [dotnet/runtime#63641.](https://github.com/dotnet/runtime\", \"/pull/63641) The shared internal utility method HttpRuleParser.GetHostLength was using string.Substr\", \"ing in order to hand back the parsed host information, but only some of the callers needed this. Rat\", \"her than making everyone pay for something that not everyone needed, this logic was moved into only \", \"the call sites that needed it.\\n\\nOther small allocation improvements were also made outside of header\", \"s. For example, when new HTTP/1 and HTTP/2 connections are created, the implementation queues a work\", \" item to the thread pool to handle the actual creation, primarily to escape locks that might be held\", \" higher in the call stack. To do so, it used Task.Run. And while normally Task.Run is a fine thing t\", \"o use, in this case there were two issues: the resulting Task was being ignored, such that any unexp\", \"ected exceptions would just be eaten, and the lambda being passed to Task.Run was closing over this \", \"and a local, which means the C# compiler will have generated code to allocate both a \\\"display class\\\"\", \" (an object to store the state being passed in) for the closure and then also a delegate to a method\", \" on that display class. Instead, [dotnet/runtime#68750](https://github.com/dotnet/runtime/pull/68750\", \") switches it to use ThreadPool.QueueUserWorkItem, using the overload that takes a generic TState, a\", \"nd passing in a tuple of all required state in order to avoid both superfluous allocations.\\n\\nFolks u\", \"sing HTTP often need to go through a proxy server, and in .NET the ability to go through an HTTP pro\", \"xy is represented via the IWebProxy interface; it has three members, GetProxy for getting the Uri of\", \" the proxy to use for a given destination Uri, the IsBypassed method which says whether a given Uri \", \"should go through a proxy or not, and then a Credentials property to be used when accessing the targ\", \"et proxy. The canonical implementation of IWebProxy provided in the core libraries is the aptly name\", \"d WebProxy. WebProxy is fairly simple: you give it a proxy Uri, and then calls to GetProxy return th\", \"at proxy Uri if the destination isn't to be bypassed. Whether a Uri should be bypassed is determined\", \" by two things (assuming a non-null proxy Uri was provided): did the constructor of the WebProxy spe\", \"cify that \\\"local\\\" destinations should be bypassed (and if so, is this destination local), or does th\", \"is destination address match any of any number of regular expressions provided. As it turns out, thi\", \"s latter aspect has been relatively slow and allocation-heavy in all previous releases of .NET, for \", \"two reasons: every call to check whether an address was bypassed was recreating a Regex instance for\", \" every supplied regular expression, and every call to check whether an address was bypassed was deri\", \"ving a new string from the Uri to use to match against the Regex. In .NET 7, both of those issues ha\", \"ve been fixed, yielding significant improvements if you rely on this regular expression functionalit\", \"y. [dotnet/runtime#73803](https://github.com/dotnet/runtime/pull/73803) from\\n\\n[@onehourlate](https:/\", \"/github.com/onehourlate) changed the handling of the collection of these Regex instances. The proble\", \"m was that WebProxy exposes an ArrayList (this type goes back to the beginning of .NET and was creat\", \"ed pre-generics), which the consumer could modify, and so WebProxy had to assume the collection was \", \"modified between uses and addressed that by simply creating new Regex instances on every use; not go\", \"od. Instead, this PR creates a custom ArrayList-derived type that can track all relevant mutations, \", \"and then only if the collection is changed (which is incredibly rare, bordering on never) do the Reg\", \"ex instances need to be recreated. And [dotnet/runtime#73807](https://github.com/dotnet/runtime/pull\", \"/73807) takes advantage of stack allocation and the MemoryExtensions.TryWrite method with string int\", \"erpolation to format the text into stack memory, avoiding the string allocation. This, combined with\", \" the new Regex.IsMatch(ReadOnlySpan<char>) overload that enables us to match against that stackalloc\", \"'d span, makes that aspect of the operation allocation-free as well. Altogether, drastic improvement\", \"s:\\n\\n```\\nprivate WebProxy _proxy = new WebProxy(\\\"http://doesntexist\\\", BypassOnLocal: false, new[] { \\n\", \"@\\\"\\\\.microsoft.com\\\", @\\\"\\\\.dot.net\\\", @\\\"\\\\.bing.com\\\" });\\nprivate Uri _destination = new\\nUri(\\\"https://docs\", \".microsoft.com/dotnet/api/system.net.webproxy\\\");\\n[Benchmark]\\npublic bool IsBypassed() => _proxy.IsBy\", \"passed(_destination);\\n```\\n\\n| Method     | Runtime  | Mean       | Ratio | Allocated | Alloc Ratio |\\n\", \"|------------|----------|------------|-------|-----------|-------------|\\n| IsBypassed | .NET 6.0 | 5\", \",343.2 ns | 1.00  | 7528 B    | 1.00        |\\n| IsBypassed | .NET 7.0 | 205.5 ns   | 0.04  | -      \", \"   | 0.00        |\\n\\nAlso related to HTTP, WebUtility's HtmlDecode method has improved for .NET 7. Th\", \"e implementation had been manually iterating through each character in the input looking for a '&' t\", \"o be unescaped. Any time you see such an open-coded loop looking for one or more specific characters\", \", it's a red flag that IndexOf should be strongly considered. [dotnet/runtime#70700](https://github.\", \"com/dotnet/runtime/pull/70700) deletes the entire searching function and replaces it with IndexOf, y\", \"ielding simpler and much faster code (you can see other improvements to use IndexOf variants in netw\", \"orking, such as [dotnet/runtime#71137,](https://github.com/dotnet/runtime/pull/71137) which used\\n\\nIn\", \"dexOfAny in HttpListener's HandleAuthentication to search a header for certain kinds of whitespace):\", \"\\n\\n```\\nprivate string _encoded = WebUtility.HtmlEncode(\\\"\\\"\\\"\\n Lorem ipsum dolor sit amet, consectetur a\", \"dipiscing elit, sed do eiusmod tempor \\nincididunt ut labore et dolore magna aliqua.\\n Condimentum vit\", \"ae sapien pellentesque habitant. Vitae auctor eu augue ut lectus. Augue \\nlacus viverra vitae congue \", \"eu.\\n Tempus quam pellentesque nec nam aliquam sem. Urna nec tincidunt praesent semper \\nfeugiat nibh \", \"sed. Amet tellus cras adipiscing\\n enim eu. Duis ultricies lacus sed turpis tincidunt. Et sollicitudi\", \"n ac orci phasellus \\negestas tellus rutrum tellus pellentesque.\\n \\\"\\\"\\\");\\n[Benchmark]\\npublic string Htm\", \"lDecode() => WebUtility.HtmlDecode(_encoded);\\n```\\n\\n| Method     | Runtime  | Mean      | Ratio |\\n|--\", \"----------|----------|-----------|-------|\\n| HtmlDecode | .NET 6.0 | 245.54 ns | 1.00  |\\n| HtmlDecod\", \"e | .NET 7.0 | 19.66 ns  | 0.08  |\\n\\nThere have been a myriad of other performance-related improvemen\", \"ts in networking as well, such as [dotnet/runtime#67881](https://github.com/dotnet/runtime/pull/6788\", \"1) which removed the use of TcpClient from FtpWebRequest; [dotnet/runtime#68745](https://github.com/\", \"dotnet/runtime/pull/68745) in WebSocket which removed a parameter from one of the core async methods\", \" (and since parameters end up on the state machine, if the async method yields this results in fewer\", \" allocated bytes); and [dotnet/runtime#70866](https://github.com/dotnet/runtime/pull/70866) and [dot\", \"net/runtime#70900,](https://github.com/dotnet/runtime/pull/70900) which replaced all remaining use o\", \"f Marshal.PtrToStructure in the core networking code with more efficient marshaling (e.g. just perfo\", \"rming casts). While Marshal.PtrToStructure is valuable when custom marshaling directives are used an\", \"d the runtime needs to be involved in the conversion, it's also much more heavyweight than just cast\", \"ing, which can be done when the native and managed layouts are bit-for-bit compatible. As with the u\", \"8 example earlier, this comparison is hardly fair, but that's exactly the point:\\n\\n```\\nprivate IntPtr\", \" _mem;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n _mem = Marshal.AllocHGlobal(8);\\n Marshal.StructureToPtr(\", \"new SimpleType { Value1 = 42, Value2 = 84 }, _mem, false);\\n}\\n[GlobalCleanup]\\npublic void Cleanup() =\", \"> Marshal.FreeHGlobal(_mem);\\npublic struct SimpleType\\n{\\n public int Value1;\\n public int Value2;\\n}\\n[B\", \"enchmark(Baseline = true)]\\npublic SimpleType PtrToStructure() => Marshal.PtrToStructure<SimpleType>(\", \"_mem);\\n[Benchmark]\\npublic unsafe SimpleType Cast() => *(SimpleType*)_mem;\\n```\\n\\n| Method         | Me\", \"an       | Ratio |\\n|----------------|------------|-------|\\n| PtrToStructure | 26.6593 ns | 1.000 |\\n|\", \" Cast           | 0.0736 ns  | 0.003 |\\n\\nFor folks using NegotiateStream, [dotnet/runtime#71280](http\", \"s://github.com/dotnet/runtime/pull/71280) from\\n\\n[@filipnavara](https://github.com/filipnavara) will \", \"also be very welcome (this comes as part of a larger effort, primarily in [dotnet/runtime#71777](htt\", \"ps://github.com/dotnet/runtime/pull/71777) from [@filipnavara](https://github.com/filipnavara) and [\", \"dotnet/runtime#70720](https://github.com/dotnet/runtime/pull/70720) from [@filipnavara](https://gith\", \"ub.com/filipnavara), to expose the new NegotiateAuthentication class). It removes a significant amou\", \"nt of allocation from a typical NTLM handshake by reusing a buffer rather than reallocating a new bu\", \"ffer for each of multiple phases of the handshake:\\n\\n```\\nprivate NetworkStream _client, _server;\\n[Glo\", \"balSetup]\\npublic void Setup()\\n{\\n using var listener = new Socket(AddressFamily.InterNetwork, SocketT\", \"ype.Stream, \\nProtocolType.Tcp);\\n listener.Bind(new IPEndPoint(IPAddress.Loopback, 0));\\n listener.Lis\", \"ten(1);\\n var client = new Socket(AddressFamily.InterNetwork, SocketType.Stream, \\nProtocolType.Tcp);\\n\", \" client.Connect(listener.LocalEndPoint);\\n Socket server = listener.Accept();\\n _client = new NetworkS\", \"tream(client, ownsSocket: true);\\n _server = new NetworkStream(server, ownsSocket: true);\\n}\\n[Benchmar\", \"k]\\npublic async Task Handshake()\\n{\\n using NegotiateStream client = new NegotiateStream(_client, leav\", \"eInnerStreamOpen: \\ntrue);\\n using NegotiateStream server = new NegotiateStream(_server, leaveInnerStr\", \"eamOpen: \\ntrue);\\n await Task.WhenAll(client.AuthenticateAsClientAsync(), \\nserver.AuthenticateAsServe\", \"rAsync());\\n}\\n```\\n\\n| Method    | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|-----------\", \"|----------|----------|-------|-----------|-------------|\\n| Handshake | .NET 6.0 | 1.905 ms | 1.00  \", \"| 240.5 KB  | 1.00        |\\n| Handshake | .NET 7.0 | 1.913 ms | 1.00  | 99.28 KB  | 0.41        |\\n\\n#\", \"## <span id=\\\"page-194-0\\\"></span>JSON\\n\\nSystem.Text.Json was introduced in .NET Core 3.0, and has seen\", \" a significant amount of investment in each release since. .NET 7 is no exception. New features in .\", \"NET 7 include support for [customizing](https://github.com/dotnet/runtime/issues/63686)  [contracts,\", \"](https://github.com/dotnet/runtime/issues/63686) [polymorphic serialization,](https://github.com/do\", \"tnet/runtime/pull/67961) [support for required members,](https://github.com/dotnet/runtime/pull/7293\", \"7) [support for DateOnly / TimeOnly,](https://github.com/dotnet/runtime/pull/69160)  [support for IA\", \"syncEnumerable<T>](https://github.com/dotnet/runtime/pull/68985) and [JsonDocument](https://github.c\", \"om/dotnet/runtime/pull/60236) in source generation, and [support for](https://github.com/dotnet/runt\", \"ime/issues/44947)  [configuring MaxDepth in JsonWriterOptions.](https://github.com/dotnet/runtime/is\", \"sues/44947) However, there have also been new features specifically focused on performance, and othe\", \"r changes about improving performance of JSON handling in a variety of scenarios.\\n\\nOne of the bigges\", \"t performance pitfalls we've seen developers face with System.Text.Json has to do with how the libra\", \"ry caches data. In order to achieve good serialization and deserialization performance when the sour\", \"ce generator isn't used, System.Text.Json uses reflection emit to generate custom code for reading/w\", \"riting members of the types being processed. Instead of then having to pay reflection invoke costs o\", \"n every access, the library incurs a much larger one-time cost per type to perform this code generat\", \"ion, but then all subsequent handling of these types is very fast\\u2026 assuming the generated code is av\", \"ailable for use. These generated handlers need to be stored somewhere, and the location that's used \", \"for storing them is them is JsonSerializerOptions. The idea was intended to be that developers would\", \" instantiate an options instance once and pass it around to all of their serialization/deserializati\", \"on calls; thus, state like these generated handlers could be cached on them. And that works well whe\", \"n developers follow the recommended model. But when they don't, performance falls off a cliff, and h\", \"ard. Instead of \\\"just\\\" paying for the reflection invoke costs, each use of a new JsonSerializerOptio\", \"ns ends up re-generating via reflection emit those handlers, skyrocketing the cost of serialization \", \"and deserialization. A super simple benchmark makes this obvious:\\n\\n```\\nprivate JsonSerializerOptions\", \" _options = new JsonSerializerOptions();\\nprivate MyAmazingClass _instance = new MyAmazingClass();\\n[B\", \"enchmark(Baseline = true)]\\npublic string ImplicitOptions() => JsonSerializer.Serialize(_instance);\\n[\", \"Benchmark]\\npublic string WithCached() => JsonSerializer.Serialize(_instance, _options);\\n[Benchmark]\\n\", \"public string WithoutCached() => JsonSerializer.Serialize(_instance, new\\nJsonSerializerOptions());\\np\", \"ublic class MyAmazingClass\\n{\\n public int Value { get; set; }\\n}\\n```\\n\\n190 CHAPTER 17 | JSON\\n\\n| Method \", \"         | Runtime  | Mean         | Ratio  | Allocated | Alloc Ratio |\\n|-----------------|---------\", \"-|--------------|--------|-----------|-------------|\\n| ImplicitOptions | .NET 6.0 | 170.3 ns     | 1\", \".00   | 200 B     | 1.00        |\\n| WithCached      | .NET 6.0 | 163.8 ns     | 0.96   | 200 B     |\", \" 1.00        |\\n| WithoutCached   | .NET 6.0 | 100,440.6 ns | 592.48 | 7393 B    | 36.97       |\\n\\nIn \", \".NET 7, this was fixed in [dotnet/runtime#64646](https://github.com/dotnet/runtime/pull/64646) (and \", \"subsequently tweaked in [dotnet/runtime#66248\\\\)](https://github.com/dotnet/runtime/pull/66248) by ad\", \"ding a global cache of the type information separate from the options instances. A JsonSerializerOpt\", \"ions still has a cache, but when new handlers are generated via reflection emit, those are also cach\", \"ed at the global level (with appropriate removal when no longer used in order to avoid unbounded lea\", \"ks).\\n\\n| Method          | Runtime  | Mean         | Ratio  | Allocated | Alloc Ratio |\\n|------------\", \"-----|----------|--------------|--------|-----------|-------------|\\n| ImplicitOptions | .NET 6.0 | 1\", \"70.3 ns     | 1.00   | 200 B     | 1.00        |\\n| ImplicitOptions | .NET 7.0 | 166.8 ns     | 0.98 \", \"  | 48 B      | 0.24        |\\n| WithCached      | .NET 6.0 | 163.8 ns     | 0.96   | 200 B     | 1.0\", \"0        |\\n| WithCached      | .NET 7.0 | 168.3 ns     | 0.99   | 48 B      | 0.24        |\\n| Withou\", \"tCached   | .NET 6.0 | 100,440.6 ns | 592.48 | 7393 B    | 36.97       |\\n| WithoutCached   | .NET 7.\", \"0 | 590.1 ns     | 3.47   | 337 B     | 1.69        |\\n\\nAs can be seen here, it's still more expensiv\", \"e to create a new JsonSerializerOptions instance on each call, and the recommended approach is \\\"don'\", \"t do that.\\\" But if someone does do it, in this example they're only paying 3.6x the cost rather than\", \" 621x the cost, a huge improvement. [dotnet/runtime#61434](https://github.com/dotnet/runtime/pull/61\", \"434) also now exposes the JsonSerializerOptions.Default instance that's used by default if no option\", \"s are explicitly provided.\\n\\nAnother change to JsonSerializer came in [dotnet/runtime#72510,](https:/\", \"/github.com/dotnet/runtime/issues/72510) which slightly improved the performance of serialization wh\", \"en using the source generator. The source generator emits helpers for performing the serialization/d\", \"eserialization work, and these are then invoked by JsonSerializer via delegates (as part of abstract\", \"ing away all the different implementation strategies for how to get and set members on the types bei\", \"ng serialized and deserialized). Previously, these helpers were being emitted as static methods, whi\", \"ch in turn meant that the delegates were being created to static methods. Delegates to instance meth\", \"ods are a bit faster to invoke than delegates to static methods, so this PR made a simple few-line c\", \"hange for the source generator to emit these as instance methods instead.\\n\\nYet another for JsonSeria\", \"lizer comes in [dotnet/runtime#73338,](https://github.com/dotnet/runtime/pull/73338) which improves \", \"allocation with how it utilizes Utf8JsonWriter. Utf8JsonWriter is a class, and every time JsonSerial\", \"izer would write out JSON, it would allocate a new Utf8JsonWriter instance. In turn, Utf8JsonWriter \", \"needs something to write to, and although the serializer was using an IBufferWriter implementation t\", \"hat pooled the underlying byte[] instances employed, the implementation of IBufferWriter itself is a\", \" class that JsonSerializer would allocate. A typical Serialize call would then end up allocating a f\", \"ew extra objects and an extra couple of hundred bytes just for these helper data structures. To addr\", \"ess that, this PR takes advantage of [ThreadStatic], which can be put onto static fields to make the\", \"m per-thread rather than per-process. From whatever thread is performing the (synchronous)\\n\\n191 CHAP\", \"TER 17 | JSON\\n\\nSerialize operation, it then ensures the current thread has a Utf8JsonWriter and IBuf\", \"ferWriter instance it can use, and uses them; for the most part this is straightforward, but it need\", \"s to ensure that the serialization operation itself doesn't try to recursively serialize, in which c\", \"ase these objects could end up being used erroneously while already in use. It also needs to make su\", \"re that the pooled IBufferWriter doesn't hold on to any of its byte[]s while it's not being used. Th\", \"at instance gets its arrays from ArrayPool<T>, and we want those arrays to be usable in the meantime\", \" by anyone else making use of the pool, not sequestered off in this cached IBufferWriter implementat\", \"ion. This optimization is also only really meaningful for small object graphs being serialized, and \", \"only applies to the synchronous operations (asynchronous operations would require a more complicated\", \" pooling mechanism, since the operation isn't tied to a specific thread, and the overhead of such co\", \"mplication would likely outweigh the modest gain this optimization provides).\\n\\n```\\nprivate byte[] _d\", \"ata = new byte[] { 1, 2, 3, 4, 5 };\\n[Benchmark]\\npublic string SerializeToString() => JsonSerializer.\", \"Serialize(_data);\\n```\\n\\n| Method            | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\", \"\\n|-------------------|----------|----------|-------|-----------|-------------|\\n| SerializeToString |\", \" .NET 6.0 | 146.4 ns | 1.00  | 200 B     | 1.00        |\\n| SerializeToString | .NET 7.0 | 137.5 ns |\", \" 0.94  | 48 B      | 0.24        |\\n\\nUtf8JsonWriter and Utf8JsonReader also saw several improvements \", \"directly. [dotnet/runtime#69580](https://github.com/dotnet/runtime/pull/69580) adds a few new perfor\", \"mance-focused members, the ValueIsEscaped property (which exposes already tracked information and en\", \"ables consumers to avoid the expense of re-checking) and the CopyString method (which provides a non\", \"-allocating mechanism to get access to a string value from the reader). It then also uses the added \", \"support internally to speed up certain operations on Utf8JsonReader. And [dotnet/runtime#63863,](htt\", \"ps://github.com/dotnet/runtime/pull/63863) [dotnet/runtime#71534,](https://github.com/dotnet/runtime\", \"/pull/71534) and [dotnet/runtime#61746](https://github.com/dotnet/runtime/pull/61746) fix how some e\", \"xception checks and throws were being handled so as to not slow down the non-exceptional fast paths.\", \"\\n\\n192 CHAPTER 17 | JSON\\n\\n### <span id=\\\"page-197-0\\\"></span>XML\\n\\nSystem.Xml is used by a huge number o\", \"f applications and services, but ever since JSON hit the scene and has been all the rage, XML has ta\", \"ken a back seat and thus hasn't seen a lot of investment from either a functionality or performance \", \"perspective. Thankfully, System.Xml gets a bit of performance love in .NET 7, in particular around r\", \"educing allocation on some commonly used code paths.\\n\\nSometimes a performance fix is as easy as chan\", \"ging a single number. That's the case with [dotnet/runtime#63459](https://github.com/dotnet/runtime/\", \"pull/63459) from [@chrisdcmoore](https://github.com/chrisdcmoore), which addresses a long-standing i\", \"ssue with the asynchronous methods on the popular XmlReader. When XmlReader was originally written, \", \"whoever developed it chose a fairly common buffer size to be used for read operations, namely 4K or \", \"8K chars depending on various conditions. When XmlReader later gained asynchronous reading functiona\", \"lity, for whatever reason a much, much larger buffer size of 64K chars was selected (presumably in h\", \"opes of minimizing the number of asynchronous operations that would need to be employed, but the act\", \"ual rationale is lost to history). A key problem with such a buffer size, beyond it leading to a lot\", \" of allocation, is the allocation it produces typically ends up on the Large Object Heap (LOH). By d\", \"efault, under the expectation that really large objects are long-lived, objects greater than 85K byt\", \"es are allocated into the LOH, which is treated as part of Gen 2, and that makes such allocation if \", \"*not* long-lived even more expensive in terms of overall impact on the system. Well, 64K chars is 12\", \"8K bytes, which puts it squarely above that threshold. This PR lowers the size from 64K chars to 32K\", \" chars, putting it below the threshold (and generally reducing allocation pressure, how much memory \", \"needs to be zero'd, etc). While it's still a very large allocation, and in the future we could look \", \"at pooling the buffer or employing a smaller one (e.g. no different from what's done for the synchro\", \"nous APIs), this simple one-number change alone makes a substantial difference for shorter input doc\", \"uments (while not perceivably negatively impacting larger ones).\\n\\n```\\nprivate readonly XmlReaderSett\", \"ings _settings = new XmlReaderSettings { Async = true };\\nprivate MemoryStream _stream;\\n[Params(10, 1\", \"_000_000)]\\npublic int ItemCount;\\n[GlobalSetup]\\npublic void Setup()\\n{\\n _stream = new MemoryStream();\\n\", \" using XmlWriter writer = XmlWriter.Create(_stream);\\n writer.WriteStartElement(\\\"Items\\\");\\n for (var i\", \" = 0; i < ItemCount; i++)\\n {\\n writer.WriteStartElement($\\\"Item{i}\\\");\\n writer.WriteEndElement();\\n }\\n w\", \"riter.WriteEndElement();\\n```\\n\\n```\\n}\\n[Benchmark]\\npublic async Task XmlReader_ReadAsync()\\n{\\n _stream.P\", \"osition = 0;\\n using XmlReader reader = XmlReader.Create(_stream, _settings);\\n while (await reader.Re\", \"adAsync());\\n}\\n```\\n\\n| Method              | Runtime  | ItemCount | Mean              | Ratio | Alloca\", \"ted       | Alloc<br>Ratio |\\n|---------------------|----------|-----------|-------------------|-----\", \"--|-----------------|----------------|\\n| XmlReader_ReadAsync | .NET 6.0 | 10        | 42.344 us     \", \"    | 1.00  | 195.94 KB       | 1.00           |\\n| XmlReader_ReadAsync | .NET 7.0 | 10        | 9.99\", \"2 us          | 0.23  | 99.94 KB        | 0.51           |\\n|                     |          |       \", \"    |                   |       |                 |                |\\n| XmlReader_ReadAsync | .NET 6.\", \"0 | 1000000   | 340,382.953<br>us | 1.00  | 101790.34<br>KB | 1.00           |\\n| XmlReader_ReadAsync\", \" | .NET 7.0 | 1000000   | 333,417.347<br>us | 0.98  | 101804.45<br>KB | 1.00           |\\n\\nXmlReader \", \"and XmlWriter saw other allocation-related improvements as well. [dotnet/runtime#60076](https://gith\", \"ub.com/dotnet/runtime/pull/60076) from [@kronic](https://github.com/kronic) improved the ReadOnlyTer\", \"naryTree internal type that's used when XmlOutputMethod.Html is specified in the XmlWriterSettings. \", \"This included using a ReadOnlySpan<byte> initialized from an RVA static instead of a large byte[] ar\", \"ray that would need to be allocated. And [dotnet/runtime#60057](https://github.com/dotnet/runtime/pu\", \"ll/60057) from [@kronic](https://github.com/kronic), which converted ~400 string creations in the Sy\", \"stem.Private.Xml assembly to use interpolated strings. Many of these cases were stylistic, convertin\", \"g something like string1 + \\\":\\\" + string2 into \\\\$\\\"{string1}:{string2}\\\"; I say stylistic here because \", \"the C# compiler will generate the exact same code for both of those, a call to string.Concat(string1\", \", \\\":\\\", string2), given that there's a Concat overload that accepts three strings. However, some of t\", \"he changes do impact allocation. For example, the private XmlTextWriter.GeneratePrefix method had th\", \"e code:\\n\\n```\\nreturn \\\"d\\\" + _top.ToString(\\\"d\\\", CultureInfo.InvariantCulture)\\n + \\\"p\\\" + temp.ToString(\\\"d\", \"\\\", CultureInfo.InvariantCulture);\\n```\\n\\nwhere \\\\_top and temp are both ints. This will result in alloc\", \"ating two temporary strings and then concatenating those with the two constant strings. Instead, the\", \" PR changed it to:\\n\\n```\\nreturn string.Create(CultureInfo.InvariantCulture, $\\\"d{_top:d}p{temp:d}\\\");\\n`\", \"``\\n\\nwhich while shorter is also more efficient, avoiding the intermediate string allocations, as the\", \" custom interpolated string handler used by string.Create will format those into a pooled buffer rat\", \"her than allocating intermediate temporaries.\\n\\nXmlSerializer is also quite popular and also gets a (\", \"small) allocation reduction, in particular for deserialization. XmlSerializer has two modes for gene\", \"rating serialization/deserialization routines: using reflection emit to dynamically generate IL at r\", \"un-time that are tuned to the specific shape of the types being serialized/deserialized, and the [XM\", \"L Serializer Generator Tool](https://docs.microsoft.com/dotnet/standard/serialization/xml-serializer\", \"-generator-tool-sgen-exe) (sgen), which generates a .dll containing the same support, just ahead-of-\", \"time (a sort-of precursor to the Roslyn source\\n\\ngenerators we love today). In both cases, when deser\", \"ializing, the generated code wants to track which properties of the object being deserialized have a\", \"lready been set, and to do that, it uses a bool[] as a bit array. Every time an object is deserializ\", \"ed, it allocates a bool[] with enough elements to track every member of the type. But in common usag\", \"e, the vast majority of types being deserialized only have a relatively small number of properties, \", \"which means we can easily use stack memory to track this information rather than heap memory. That's\", \" what [dotnet/runtime#66914](https://github.com/dotnet/runtime/pull/66914) does. It updates both of \", \"the code generators to stackalloc into a Span<bool> for less than or equal to 32 values, and otherwi\", \"se fall back to the old approach of heap-allocating the bool[] (which can also then be stored into a\", \" Span<bool> so that the subsequent code paths simply use a span instead of an array). You can see th\", \"is quite easily in the .NET Object Allocation Tracking tool in Visual Studio. For this console app (\", \"which, as an aside, shows how lovely the new raw string literals feature in C# is for working with X\", \"ML):\\n\\n```\\nusing System.Text;\\nusing System.Xml.Serialization;\\nvar serializer = new XmlSerializer(type\", \"of(Release[]));\\nvar stream = new MemoryStream(Encoding.UTF8.GetBytes(\\n \\\"\\\"\\\"\\n <?xml version=\\\"1.0\\\" enco\", \"ding=\\\"utf-8\\\"?>\\n <ArrayOfRelease xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\nxmlns:xsd=\\\"htt\", \"p://www.w3.org/2001/XMLSchema\\\">\\n <Release><Major>1</Major><Minor>0</Minor></Release>\\n <Release><Majo\", \"r>1</Major><Minor>1</Minor></Release>\\n <Release><Major>2</Major><Minor>0</Minor></Release>\\n <Release\", \"><Major>2</Major><Minor>1</Minor></Release>\\n <Release><Major>2</Major><Minor>2</Minor></Release>\\n <R\", \"elease><Major>3</Major><Minor>0</Minor></Release>\\n <Release><Major>3</Major><Minor>1</Minor></Releas\", \"e>\\n <Release><Major>5</Major><Minor>0</Minor></Release>\\n <Release><Major>6</Major><Minor>0</Minor></\", \"Release>\\n <Release><Major>7</Major><Minor>0</Minor></Release>\\n </ArrayOfRelease>\\n \\\"\\\"\\\"));\\nfor (int i \", \"= 0; i < 1000; i++)\\n{\\n stream.Position = 0;\\n serializer.Deserialize(stream);\\n}\\npublic class Release\\n\", \"{\\n public int Major;\\n public int Minor;\\n public int Build;\\n public int Revision;\\n}\\n```\\n\\nHere's what \", \"I see when I run this under .NET 6:\\n\\n| \\u0422\\u0443\\u0440\\u0435                         | Allocations \\u25bc |\\n|-------------\", \"-----------------|---------------|\\n| \\u2663 System.Xml.NameTable.Entry | 33,000        |\\n| \\u2663\\u0163 System.Stri\", \"ng             | 29,123        |\\n| \\u25b6 \\ud83d\\udec5 System.Boolean[]         | 10,013        |\\n| \\u2663 Release       \", \"             | 10,000        |\\n\\nWe're running a thousand deserializations, each of which will deseri\", \"alize 10 Release instances, and so we expect to see 10,000 Release objects being allocated, which we\", \" do\\u2026 but we also see 10,000 bool[] being allocated. Now with .NET 7 (note the distinct lack of the p\", \"er-object bool[]):\\n\\n| Allocations | Call Tree | Functions      | Collections |               |\\n|----\", \"---------|-----------|----------------|-------------|---------------|\\n|             |           |   \", \"             |             |               |\\n| _           |           |                |           \", \"  |               |\\n| \\u0422\\u0443\\u0440\\u0435        |           |                |             | Allocations \\u25bc |\\n| \\ud83d\\udd29 S\", \"yste     | m.Xml.Nan | ne Table. Entr | \\u0443           | 33,000        |\\n| \\ud83d\\udd29 Syste     | m.String  |   \", \"             |             | 28,964        |\\n| \\ud83d\\udd29 Relea     | ise       |                |           \", \"  | 10,000        |\\n\\nOther allocation reduction went into the creation of the serializer/deserialize\", \"r itself, such as with [dotnet/runtime#68738](https://github.com/dotnet/runtime/pull/68738) avoiding\", \" allocating strings to escape text that didn't actually need escaping, [dotnet/runtime#66915](https:\", \"//github.com/dotnet/runtime/pull/66915) using stack allocation for building up small text instead of\", \" using a StringBuilder, [dotnet/runtime#66797](https://github.com/dotnet/runtime/pull/66797) avoidin\", \"g delegate and closure allocations in accessing the cache of serializers previously created, [dotnet\", \"/runtime#67001](https://github.com/dotnet/runtime/pull/67001) from [@TrayanZapryanov](https://github\", \".com/TrayanZapryanov) caching an array used with string.Split, and [dotnet/runtime#67002](https://gi\", \"thub.com/dotnet/runtime/pull/67002) from [@TrayanZapryanov](https://github.com/TrayanZapryanov) that\", \" changed some parsing code to avoid a string.ToCharArray invocation.\\n\\nFor folks using XML schema, [d\", \"otnet/runtime#66908](https://github.com/dotnet/runtime/pull/66908) replaces some Hashtables in the i\", \"mplementation where those collections were storing ints as the value. Given that Hashtable is a non-\", \"generic collection, every one of those ints was getting boxed, resulting in unnecessary allocation o\", \"verhead; these were fixed by replacing these Hashtables with Dictionary<..., int> instances. (As an \", \"aside, this is a fairly common performance-focused replacement to do, but you need to be careful as \", \"Hashtable has a few behavioral differences from Dictionary<,>; beyond the obvious difference of Hash\", \"table returning null from its indexer when a key isn't found and Dictionary<,> throwing in that same\", \" condition, Hashtable is thread-safe for use with not only multiple readers but multiple readers con\", \"current with a single writer, and Dictionary<,> is not.) [dotnet/runtime#67045](https://github.com/d\", \"otnet/runtime/pull/67045) reduces allocation of XmlQualifiedName instances in the implementation of \", \"XsdBuilder.ProcessElement and XsdBuilder.ProcessAttribute. And [dotnet/runtime#64868](https://github\", \".com/dotnet/runtime/pull/64868) from [@TrayanZapryanov](https://github.com/TrayanZapryanov) uses sta\", \"ck-based memory and pooling to\\n\\navoid temporary string allocation in the implementation of the inter\", \"nal XsdDateTime and XsdDuration types, which are used by the public XmlConvert.\\n\\n```\\nprivate TimeSpa\", \"n _ts = TimeSpan.FromMilliseconds(12345);\\n[Benchmark]\\npublic string XmlConvertToString() => XmlConve\", \"rt.ToString(_ts);\\n```\\n\\n| Method             | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio \", \"|\\n|--------------------|----------|----------|-------|-----------|-------------|\\n| XmlConvertToStrin\", \"g | .NET 6.0 | 90.70 ns | 1.00  | 184 B     | 1.00        |\\n| XmlConvertToString | .NET 7.0 | 59.21 \", \"ns | 0.65  | 40 B      | 0.22        |\\n\\nXML pops up in other areas as well, as in the XmlWriterTrace\", \"Listener type. While the System.Diagnostics.Trace type isn't the recommended tracing mechanism for n\", \"ew code, it's widely used in existing applications, and XmlWriterTraceListener let's you plug in to \", \"that mechanism to write out XML logs for traced information. [dotnet/runtime#66762](https://github.c\", \"om/dotnet/runtime/pull/66762) avoids a bunch of string allocation occurring as part of this tracing,\", \" by formatting much of the header information into a span and then writing that out rather than ToSt\", \"ring()'ing each individual piece of data.\\n\\n```\\n[GlobalSetup]\\npublic void Setup()\\n{\\n Trace.Listeners.\", \"Clear();\\n Trace.Listeners.Add(new XmlWriterTraceListener(Stream.Null));\\n}\\n[Benchmark]\\npublic void Tr\", \"aceWrite()\\n{\\n Trace.WriteLine(\\\"Something important\\\");\\n}\\n```\\n\\n| Method     | Runtime  | Mean     | Ra\", \"tio | Allocated | Alloc Ratio |\\n|------------|----------|----------|-------|-----------|------------\", \"-|\\n| TraceWrite | .NET 6.0 | 961.9 ns | 1.00  | 288 B     | 1.00        |\\n| TraceWrite | .NET 7.0 | \", \"772.2 ns | 0.80  | 64 B      | 0.22        |\\n\\n### <span id=\\\"page-202-0\\\"></span>Cryptography\\n\\nSome fa\", \"irly significant new features came to System.Security.Cryptography in .NET 7, including the support \", \"necessary to enable the previously discussed OCSP stapling and support for [building](https://github\", \".com/dotnet/runtime/pull/72708)  [certificate revocation lists,](https://github.com/dotnet/runtime/p\", \"ull/72708) but there was also a fair amount of effort put into making existing support faster and mo\", \"re lightweight.\\n\\nOne fairly substantial change in .NET 7 is split across [dotnet/runtime#61025,](htt\", \"ps://github.com/dotnet/runtime/pull/61025) [dotnet/runtime#61137,](https://github.com/dotnet/runtime\", \"/pull/61137)  and [dotnet/runtime#64307](https://github.com/dotnet/runtime/pull/64307). These PRs do\", \"n't change any code materially, but instead consolidate all of the various cryptography-related asse\", \"mblies in the core libraries into a single\\n\\nSystem.Security.Cryptography assembly. When .NET Core wa\", \"s first envisioned, a goal was to make it extremely modular, and large swaths of code were teased ap\", \"art to create many smaller assemblies. For example, cryptographic functionality was split between\\n\\nS\", \"ystem.Security.Cryptography.Algorithms.dll, System.Security.Cryptography.Cng.dll, System.Security.Cr\", \"yptography.Csp.dll, System.Security.Cryptography.Encoding.dll, System.Security.Cryptography.OpenSsl.\", \"dll, System.Security.Cryptography.Primitives.dll, and System.Security.Cryptography.X509Certificates.\", \"dll. You can see this if you look in your shared framework folder for a previous release, e.g. here'\", \"s mine for .NET 6:\\n\\n| System.Security.Cryptography.Algorithms.dll       | 787 KB |\\n|----------------\", \"-----------------------------------|--------|\\n| System.Security.Cryptography.Cng.dll              | \", \"475 KB |\\n| System.Security.Cryptography.Csp.dll              | 186 KB |\\n| System.Security.Cryptograp\", \"hy.Encoding.dll         | 92 KB  |\\n| System.Security.Cryptography.OpenSsl.dll          | 32 KB  |\\n| \", \"System.Security.Cryptography.Primitives.dll       | 132 KB |\\n| System.Security.Cryptography.X509Cert\", \"ificates.dll | 476 KB |\\n\\nThese PRs move all of that code into a single System.Security.Cryptography.\", \"dll assembly. This has several benefits. First, crypto is used in a huge number of applications, and\", \" most apps would end up\\n\\nrequiring multiple (or even most) of these assemblies. Every assembly that'\", \"s loaded adds overhead. Second, a variety of helper files had to be compiled into each assembly, lea\", \"ding to overall larger amount of compiled code to be distributed. And third, we weren't able to impl\", \"ement everything as optimal as we'd have otherwise liked due to functionality in one assembly not ex\", \"posed to another (and we avoid using InternalsVisibleTo as it hampers maintainability and impedes ot\", \"her analysis and optimizations). Now in .NET 7, the shared framework looks more like this:\\n\\n| System\", \".Security.Cryptography.Algorithms.dll       | 7 KB     |\\n|------------------------------------------\", \"---------|----------|\\n| System.Security.Cryptography.Cng.dll              | 6 KB     |\\n| System.Secu\", \"rity.Cryptography.Csp.dll              | 6 KB     |\\n| System.Security.Cryptography.dll              \", \"    | 1,912 KB |\\n| System.Security.Cryptography.Encoding.dll         | 6 KB     |\\n| System.Security.\", \"Cryptography.OpenSsl.dll          | 6 KB     |\\n| System.Security.Cryptography.Primitives.dll       |\", \" 6 KB     |\\n| System.Security.Cryptography.X509Certificates.dll | 7 KB     |\\n\\nInteresting, you still\", \" see a bunch of assemblies there, but all except for System.Security.Cryptography.dll are tiny; that\", \"'s because these are simple facades. Because we need to support binaries built for .NET 6 and earlie\", \"r running on .NET 7, we need to be able to handle binaries that refer to types in these assemblies, \", \"but in .NET 7, those types actually live in System.Security.Cryptography.dll. .NET provides a soluti\", \"on for this in the form of the [TypeForwardedTo(...)] attribute, which enables one assembly to say \\\"\", \"hey, if you're looking for type X, it now lives over there.\\\" And if you crack open one of these asse\", \"mblies in a tool like [ILSpy,](https://github.com/icsharpcode/ILSpy) you can see they're essentially\", \" empty except for a bunch of these attributes:\\n\\nIn addition to the startup and maintenance wins this\", \" provides, this has also enabled further subsequent optimization. For example, there's a lot of obje\", \"ct cloning that goes on in the innards of this library. Various objects are used to wrap native hand\", \"les to OS cryptographic resources, and to handle lifetime semantics and ownership appropriately, the\", \"re are many cases where a native handle is duplicated and then wrapped in one or more new managed ob\", \"jects. In some cases, however, the original resource is then destroyed because it's no longer needed\", \", and the whole operation could have been made more efficient if the original resource just had its \", \"ownership transferred to the new objects rather than being duplicated and destroyed. This kind of ow\", \"nership transfer typically is hard to do between assemblies as it generally requires public API that\", \"'s not focused on such usage patterns, but with internals access, this can be overcome. [dotnet/runt\", \"ime#72120](https://github.com/dotnet/runtime/pull/72120) does this, for example, to reduce allocatio\", \"n of various resources inside the RSACng, DSACng, ECDsaCng, and ECDiffieHellmanCng public types.\\n\\nIn\", \" terms of actual code improvements, there are many. One category of improvements is around \\\"one-shot\", \"\\\" operations. With many forms of data processing, all of the data needn't be processed in one operat\", \"ion. A block of data can be processed, then another, then another, until finally there's no more dat\", \"a to be processed. In such usage, there's often some kind of state carried over from the processing \", \"of one block to the processing of the next, and then the processing of the last block is special as \", \"it needn't carry over anything and instead needs to perform whatever work is required to end the who\", \"le operation, e.g. outputting any final footer or checksum that might be required as part of the for\", \"mat. Thus, APIs that are able to handle arbitrary number of blocks of data are often a bit more expe\", \"nsive in one way, shape, or form than APIs that only support a single input; this latter category is\", \" known as \\\"one shot\\\" operations, because they do everything in \\\"one shot.\\\" In some cases, one-shot o\", \"perations can be significantly cheaper, and in other cases they merely avoid some allocations that w\", \"ould have been necessary to transfer state from the processing of one block of data to the next. [do\", \"tnet/runtime#58270](https://github.com/dotnet/runtime/pull/58270) from [@vcsjones](https://github.co\", \"m/vcsjones) and [dotnet/runtime#65725](https://github.com/dotnet/runtime/pull/65725) from [@vcsjones\", \"](https://github.com/vcsjones) both improved the performance of various one-shot operations on \\\"symm\", \"etric\\\" cryptograhic algorithms (algorithms that use the same key information to both encrypt and dec\", \"rypt), like AES. The former does so by refactoring the implementations to avoid some reset work that\", \"'s not necessary in the case of oneshots because the relevant state is about to go away, anyway, and\", \" that in turns also allows the implementation to store less of certain kinds of state. The latter do\", \"es so for decryption one-shots by decrypting directly into the destination buffer whenever possible,\", \" using stack space if possible when going directly into the user's buffer isn't feasible, etc.\\n\\n```\\n\", \"private byte[] _plaintext = Encoding.UTF8.GetBytes(\\\"This is a test. This is only a test. \\nNothing to\", \" see here.\\\");\\nprivate byte[] _iv = Enumerable.Range(0, 16).Select(i => (byte)i).ToArray();\\nprivate A\", \"es _aes = Aes.Create();\\nprivate byte[] _output = new byte[1000];\\n[Benchmark]\\npublic bool OneShot() =\", \"> _aes.TryEncryptCfb(_plaintext, _iv, _output, out _);\\n```\\n\\n| Method  | Runtime  | Mean     | Ratio \", \"| Allocated | Alloc Ratio |\\n|---------|----------|----------|-------|-----------|-------------|\\n| On\", \"eShot | .NET 6.0 | 1.828 us | 1.00  | 336 B     | 1.00        |\\n| OneShot | .NET 7.0 | 1.770 us | 0.\", \"97  | 184 B     | 0.55        |\\n\\nIn addition to making one-shots lighterweight, other PRs have then \", \"used these one-shot operations in more places in order to simplify their code and benefit from the i\", \"ncreased performance, e.g. [dotnet/runtime#70639](https://github.com/dotnet/runtime/pull/70639) from\", \" [@vcsjones](https://github.com/vcsjones), [dotnet/runtime#70857](https://github.com/dotnet/runtime/\", \"pull/70857) from [@vcsjones](https://github.com/vcsjones), [dotnet/runtime#64005](https://github.com\", \"/dotnet/runtime/pull/64005) from [@vcsjones](https://github.com/vcsjones), and [dotnet/runtime#64174\", \"](https://github.com/dotnet/runtime/pull/64174) from [@vcsjones](https://github.com/vcsjones).\\n\\nTher\", \"e's also a large number of PRs that have focused on removing allocations from around the crypto stac\", \"k:\\n\\n- **Stack allocation**. As has been seen in many other PRs referenced throughout this post, usin\", \"g stackalloc is a very effective way to get rid of array allocations in many situations. It's used e\", \"ffectively in multiple crypto PRs to avoid either temporary or pooled array allocations, such as in \", \"[dotnet/runtime#64584](https://github.com/dotnet/runtime/pull/64584) from [@vcsjones](https://github\", \".com/vcsjones), [dotnet/runtime#69831](https://github.com/dotnet/runtime/pull/69831) from [@vcsjones\", \"](https://github.com/vcsjones), [dotnet/runtime#70173](https://github.com/dotnet/runtime/pull/70173)\", \" from [@vcsjones](https://github.com/vcsjones), [dotnet/runtime#69812](https://github.com/dotnet/run\", \"time/pull/69812) from [@vcsjones](https://github.com/vcsjones), and [dotnet/runtime#69448](https://g\", \"ithub.com/dotnet/runtime/pull/69448) from [@vcsjones](https://github.com/vcsjones). Sometimes this i\", \"s used when calling an API that has multiple overloads, including one taking an array and one taking\", \" a span. Othertimes it's used with P/Invokes that often just pass out a small amount of data. Someti\", \"mes it's used to avoid temporary array allocations, and sometimes it's used in places where pooling \", \"was used previously, but the data is often small enough to avoid even the overheads of pooling.\\n- **\", \"Avoiding double copies**. Most of the crypto APIs that accept byte[]s and store them end up making d\", \"efensive copies of those arrays rather than storing the original. This is fairly common throughout .\", \"NET, but it's especially common in the crypto stack, where the ability to trust the data is as you e\", \"xpect it (and validate it) is paramount. In some cases, though, code ends up allocating a temporary \", \"byte[] just to pass data into one of these APIs that copies and reallocates, anyway. [dotnet/runtime\", \"#71102](https://github.com/dotnet/runtime/pull/71102) from [@vcsjones](https://github.com/vcsjones),\", \" [dotnet/runtime#69024](https://github.com/dotnet/runtime/pull/69024) from [@vcsjones](https://githu\", \"b.com/vcsjones), [dotnet/runtime#71015](https://github.com/dotnet/runtime/pull/71015) from [@vcsjone\", \"s](https://github.com/vcsjones), and [dotnet/runtime#69534](https://github.com/dotnet/runtime/pull/6\", \"9534) from [@vcsjones](https://github.com/vcsjones) deal with that duplication in some cases by extr\", \"acting a span to the original data instead of creating a temporary byte[]; when that span is passed \", \"into the target API, the target API still makes a copy, but we've avoided the first one and thus cut\", \" the array allocation for these operations effectively in half. [dotnet/runtime#71888](https://githu\", \"b.com/dotnet/runtime/pull/71888) from [@vcsjones](https://github.com/vcsjones) is a variation on thi\", \"s theme, improving the internals of\\n\\nRfc2898DeriveBytes to supports spans such that its constructors\", \" that accept spans can then do the more efficient thing.\\n\\n- **Replacing O(1) data structures**. O(1)\", \" lookup data structures like Dictionary<,> and HashSet<> are the lifeblood of most applications and \", \"services, but sometimes algorithmic complexity is misleading. Yes, these provide very efficient sear\", \"ching, but there's still overhead associated with computing a hash code, mapping that hash code to a\", \" location in the data structure, and so on. If there's only ever a handful of items (i.e. the N in t\", \"he complexity is really, really small), it can be much faster to just do a linear search, and if N i\", \"s sufficiently small, a data structure may not even be needed at all: the search can just be open-co\", \"ded as a waterfall of if/elseif/else constructs. That's the case in a PR like [dotnet/runtime#71341]\", \"(https://github.com/dotnet/runtime/pull/71341) from [@vcsjones](https://github.com/vcsjones), where \", \"the 99.999% case involves just five strings (names of hash algorithms); it's cheaper to just compare\", \" against each than it is do a HashSet<>.Contains, especially since the JIT now unrolls and vectorize\", \"s the comparison against the constant string names.\\n- **Simply avoiding unnecessary work**. The best\", \" optimizations are ones where you simply stop doing work you don't have to do. [dotnet/runtime#68553\", \"](https://github.com/dotnet/runtime/pull/68553) from [@vcsjones](https://github.com/vcsjones) is a g\", \"ood example of this. This code was performing a hash of some data in order to determine the length o\", \"f resulting hashes for that particular configuration, but we actually know ahead of time exactly how\", \" long a hash for a given algorithm is going to be, and we already have in this code a cascading if/e\", \"lseif/else that's checking for each known algorithm, so we can instead just hardcode the length for \", \"each. [dotnet/runtime#70589](https://github.com/dotnet/runtime/pull/70589) from [@vcsjones](https://\", \"github.com/vcsjones) is another good example, in the same spirit of the ownership transfer example m\", \"entioned earlier (but this one didn't previously span assembly boundaries). Rather than in several p\", \"laces taking an X509Extension, serializing it to a byte[], and passing that temporary byte[] to some\", \"thing else that in turn makes a defensive copy, we can instead provide an internal pathway for owner\", \"ship transfer, bypassing all of the middle stages. Another good one is [dotnet/runtime#70618](https:\", \"//github.com/dotnet/runtime/pull/70618) from [@vcsjones](https://github.com/vcsjones), as it's an ex\", \"ample of how it pays to really understand your dependencies. The implementation of symmetric encrypt\", \"ion on macOS uses the CommonCrypto library. One of the functions it exposes is CCCryptorFinal, which\", \" is used at the end of the encryption/decryption process. However, there are several cases called ou\", \"t in the docs where it's unnecessary (\\\"superfluous,\\\" according to the docs), and so our dutifully ca\", \"lling it even in those situations is wasteful. The fix? Stop doing unnecessary work.\\n- **New APIs**.\", \" A bunch of new APIs were introduced for cryptography in .NET 7. Most are focused on easing scenario\", \"s that were difficult to do correctly before, like [dotnet/runtime#66509](https://github.com/dotnet/\", \"runtime/pull/66509) from [@vcsjones](https://github.com/vcsjones) that provides an X500Distinguished\", \"NameBuilder. But some are focused squarely on performance. [dotnet/runtime#57835](https://github.com\", \"/dotnet/runtime/pull/57835) from [@vcsjones](https://github.com/vcsjones), for example, exposes a ne\", \"w RawDataMemory property on X509Certificate2. Whereas the existing RawData property returns a new by\", \"te[] on every call (again a defensive copy to avoid having to deal with the possiblity that the cons\", \"umer mucked with the raw data), this new RawDataMemory returns a ReadOnlyMemory<byte> around the int\", \"ernal byte[]. Since the only way to access and mutate that underlying byte[] via a ReadOnlyMemory<by\", \"te> is via unsafe interop code (namely via the System.Runtime.InteropServices.MemoryMarshal type), i\", \"t doesn't create a defensive copy and enables accessing this data freely without additional allocati\", \"on.\\n\\n### <span id=\\\"page-207-0\\\"></span>Diagnostics\\n\\nLet's turn our attention to System.Diagnostics, w\", \"hich encompasses types ranging from process management to tracing.\\n\\nThe Process class is used for a \", \"variety of purposes, including querying information about running processes, interacting with other \", \"processes (e.g. being notified of their exiting), and launching processes. The performance of queryi\", \"ng for information in particular had some notable improvements in .NET 7. Process provides several A\", \"PIs for querying for process information, one of the most common being Process.GetProcessesByName: a\", \"pps that know the name of the process they're interested in can pass that to GetProcessesByName and \", \"get back a Process[] containing a Process for each. It turns out that previous releases of .NET were\", \" loading the full information (e.g. all of its threads) about every Process on the machine in order \", \"to filter down to just those with the target name. [dotnet/runtime#68705](https://github.com/dotnet/\", \"runtime/pull/68705) fixes that by only loading the name for a process rather than all of the informa\", \"tion for it. While this helps a bit with throughput, it helps a ton with allocation:\\n\\n```\\n[Benchmark\", \"]\\npublic void GetProcessesByName()\\n{\\n foreach (Process p in Process.GetProcessesByName(\\\"dotnet.exe\\\")\", \")\\n p.Dispose();\\n}\\n```\\n\\n| Method             | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio \", \"|\\n|--------------------|----------|----------|-------|-----------|-------------|\\n| GetProcessesByNam\", \"e | .NET 6.0 | 2.287 ms | 1.00  | 447.86 KB | 1.000       |\\n| GetProcessesByName | .NET 7.0 | 2.086 \", \"ms | 0.90  | 2.14 KB   | 0.005       |\\n\\nAccessing various pieces of information from a Process has a\", \"lso improved. If you load a Process object via the Process.GetProcesses or Process.GetProcessesByNam\", \"e methods, by design they load all information about the Process being retrieved; internally their s\", \"tate will be populated such that subsequent accesses to members of the Process instance will be very\", \" fast. But, if you access a Process via Process.GetProcessById or Process.GetCurrentProcess (which i\", \"s effectively GetProcessById for the current process' id), no information other than the process' ID\", \" is prepopulated, and the state for the Process instance is queried on-demand. In most cases, access\", \"ing a single member of one of those lazy-loaded Process instances triggers loading all of the data f\", \"or it, as the information is all available as part of the same native operation, e.g. on Windows usi\", \"ng NtQuerySystemInformation and on Linux reading from /proc/pid/stat and /proc/pid/status. But in so\", \"me cases we can be more fine-grained about it, using APIs that serve up a subset of the data much mo\", \"re quickly. [dotnet/runtime#59672](https://github.com/dotnet/runtime/pull/59672) from [@SteveDunn](h\", \"ttps://github.com/SteveDunn) provides one such optimization, using the QueryFullProcessImageName on \", \"Windows to read the process name in response to Process.ProcessName being used. If all you care abou\", \"t reading is the\\n\\nprocess' name, it's a huge boost in throughput, and even if you subsequently go on\", \" to read additional state from the Process and force it to load everything else, accessing the proce\", \"ss name is so fast that it doesn't add meaningful overhead to the all-up operation. This is visible \", \"in this benchmark:\\n\\n```\\n[Benchmark]\\npublic string GetCurrentProcessName()\\n{\\n using Process current =\", \" Process.GetCurrentProcess();\\n return current.ProcessName;\\n}\\n[Benchmark]\\npublic string GetCurrentPro\", \"cessNameAndWorkingSet()\\n{\\n using Process current = Process.GetCurrentProcess();\\n return $\\\"{current.P\", \"rocessName} {current.WorkingSet64}\\\";\\n}\\n```\\n\\n| Method                             | Runtime  | Mean  \", \"      | Ratio | Allocated | Alloc Ratio |\\n|------------------------------------|----------|---------\", \"----|-------|-----------|-------------|\\n| GetCurrentProcessName              | .NET 6.0 | 3,070.54 u\", \"s | 1.00  | 3954 B    | 1.00        |\\n| GetCurrentProcessName              | .NET 7.0 | 32.30 us    \", \"| 0.01  | 456 B     | 0.12        |\\n|                                    |          |             | \", \"      |           |             |\\n| GetCurrentProcessNameAndWorkingSet | .NET 6.0 | 3,055.70 us | 1.\", \"00  | 4010 B    | 1.00        |\\n| GetCurrentProcessNameAndWorkingSet | .NET 7.0 | 3,149.92 us | 1.03\", \"  | 4186 B    | 1.04        |\\n\\nInterestingly, this PR had a small deficiency we didn't initially cat\", \"ch, which is that the QueryFullProcessImageName API we switched to didn't work in the case of elevat\", \"ed/privileged processes. To accomodate those, [dotnet/runtime#70073](https://github.com/dotnet/runti\", \"me/pull/70073) from [@schuettecarsten](https://github.com/schuettecarsten) updated the code to keep \", \"both the new and old implementations, starting with the new one and then only falling back to the ol\", \"d if operating on\\n\\nSeveral additional PRs helped out the Process class. When launching processes wit\", \"h Process.Start on Unix, the implementation was using Encoding.UTF8.GetBytes as part of argument han\", \"dling, resulting in a temporary array being allocated per argument; [dotnet/runtime#71279](https://g\", \"ithub.com/dotnet/runtime/pull/71279) removes that per-argument allocation, instead using Encoding.UT\", \"F8.GetByteCount to determine how large a space is needed and then using the Encoding.UTF8.GetBytes o\", \"verload that accepts a span to encode directly into the native memory already being allocated. [dotn\", \"et/runtime#71136](https://github.com/dotnet/runtime/pull/71136) simplifies and streamlines the code \", \"involved in getting the \\\"short name\\\" of a process on Windows for use in comparing process names. And\", \" [dotnet/runtime#45690](https://github.com/dotnet/runtime/pull/45690) replaces a custom cache with u\", \"se of ArrayPool in the Windows implementation of getting all process information, enabling effective\", \" reuse of the array that ends up being used rather than having it sequestered off in the Process imp\", \"lementation forever.\\n\\nAnother area of performance investment has been in DiagnosticSource, and in pa\", \"rticular around enumerating through data from Activity instances. This work translates into faster i\", \"ntegration and interoperability via [OpenTelemetry,](https://devblogs.microsoft.com/dotnet/opentelem\", \"etry-net-reaches-v1-0) in order to be able to export data from .NET Activity information faster. [do\", \"tnet/runtime#67012](https://github.com/dotnet/runtime/pull/67012) from [@CodeBlanch](https://github.\", \"com/CodeBlanch), for example, improved the performance of the internal DiagLinkedList<T>.DiagEnumera\", \"tor type that's the\\n\\nan incompatible process.\\n\\nenumerator returned when enumerating Activity.Links a\", \"nd Activity.Events by avoiding a copy of each T value:\\n\\n```\\nprivate readonly Activity _activity;\\npub\", \"lic Program()\\n{\\n using ActivitySource activitySource = new ActivitySource(\\\"Perf7Source\\\");\\n ActivityS\", \"ource.AddActivityListener(new ActivityListener\\n {\\n ShouldListenTo = s => s == activitySource,\\n Sampl\", \"e = (ref ActivityCreationOptions<ActivityContext> o) => \\nActivitySamplingResult.AllDataAndRecorded\\n \", \"});\\n _activity = activitySource.StartActivity(\\n \\\"TestActivity\\\",\\n ActivityKind.Internal,\\n parentConte\", \"xt: default,\\n links: Enumerable.Range(0, 1024).Select(_ => new ActivityLink(default)).ToArray());\\n _\", \"activity.Stop();\\n}\\n[Benchmark(Baseline = true)]\\npublic ActivityLink EnumerateActivityLinks()\\n{\\n Acti\", \"vityLink last = default;\\n foreach (ActivityLink link in _activity.Links) last = link;\\n return last;\\n\", \"}\\n```\\n\\n| Method                 | Runtime  | Mean     | Ratio | Allocated | Alloc Ratio |\\n|---------\", \"---------------|----------|----------|-------|-----------|-------------|\\n| EnumerateActivityLinks | \", \".NET 6.0 | 19.62 us | 1.00  | 64 B      | 1.00        |\\n| EnumerateActivityLinks | .NET 7.0 | 13.72 \", \"us | 0.70  | 32 B      | 0.50        |\\n\\nThen [dotnet/runtime#67920](https://github.com/dotnet/runtim\", \"e/pull/67920) from [@CodeBlanch](https://github.com/CodeBlanch) and [dotnet/runtime#68933](https://g\", \"ithub.com/dotnet/runtime/pull/68933) from [@CodeBlanch](https://github.com/CodeBlanch) added new Enu\", \"merateTagObjects, EnumerateEvents, and EnumerateLinks enumeration methods that return a struct-based\", \" enumerator that has a ref T-returning Current to avoid yet another layer of copy.\\n\\n```\\nprivate read\", \"only Activity _activity;\\npublic Program()\\n{\\n using ActivitySource activitySource = new ActivitySourc\", \"e(\\\"Perf7Source\\\");\\n ActivitySource.AddActivityListener(new ActivityListener\\n {\\n ShouldListenTo = s =>\", \" s == activitySource,\\n Sample = (ref ActivityCreationOptions<ActivityContext> o) => \\nActivitySamplin\", \"gResult.AllDataAndRecorded\\n });\\n _activity = activitySource.StartActivity(\\n \\\"TestActivity\\\",\\n Activit\", \"yKind.Internal,\\n parentContext: default,\\n links: Enumerable.Range(0, 1024).Select(_ => new ActivityL\", \"ink(default)).ToArray());\\n```\\n\\n```\\n _activity.Stop();\\n}\\n[Benchmark(Baseline = true)]\\npublic Activity\", \"Link EnumerateActivityLinks_Old()\\n{\\n ActivityLink last = default;\\n foreach (ActivityLink link in _ac\", \"tivity.Links) last = link;\\n return last;\\n}\\n[Benchmark]\\npublic ActivityLink EnumerateActivityLinks_Ne\", \"w()\\n{\\n ActivityLink last = default;\\n foreach (ActivityLink link in _activity.EnumerateLinks()) last \", \"= link;\\n return last;\\n}\\n```\\n\\n| Method                     | Mean      | Ratio | Allocated | Alloc Ra\", \"tio |\\n|----------------------------|-----------|-------|-----------|-------------|\\n| EnumerateActivi\", \"tyLinks_Old | 13.655 us | 1.00  | 32 B      | 1.00        |\\n| EnumerateActivityLinks_New | 2.380 us \", \" | 0.17  | -         | 0.00        |\\n\\nOf course, when it comes to diagnostics, anyone who's ever don\", \"e anything with regards to timing and measurements is likely familiar with good ol' Stopwatch. Stopw\", \"atch is a simple type that's very handy for getting precise measurements and is thus used all over t\", \"he place. But for folks that are really costsensitive, the fact that Stopwatch is a class can be pro\", \"hibitive, e.g. writing:\\n\\n```\\nStopwatch sw = Stopwatch.StartNew();\\n...;\\nTimeSpan elapsed = sw.Elapsed\", \";\\n```\\n\\nis easy, but allocates a new object just to measure. To address this, Stopwatch has for years\", \" exposed the static GetTimestamp() method which avoids that allocation, but consuming and translatin\", \"g the resulting long value is complicated, requiring a formula involving using Stopwatch.Frequency a\", \"nd TimeSpan.TicksPerSecond in the right incantation. To make this pattern easy, [dotnet/runtime#6637\", \"2](https://github.com/dotnet/runtime/pull/66372) adds a static GetElapsedTime method that handles th\", \"at conversion, such that someone who wants that last mile of performance can write:\\n\\n```\\nlong timest\", \"amp = Stopwatch.GetTimestamp();\\n...\\nTimeSpan elapsed = Stopwatch.GetElapsedTime(timestamp);\\n```\\n\\nwhi\", \"ch avoids the allocation and saves a few cycles:\\n\\n```\\n[Benchmark(Baseline = true)]\\npublic TimeSpan O\", \"ld()\\n{\\n Stopwatch sw = Stopwatch.StartNew();\\n return sw.Elapsed;\\n}\\n[Benchmark]\\npublic TimeSpan New()\", \"\\n{\\n```\\n\\n```\\n long timestamp = Stopwatch.GetTimestamp();\\n return Stopwatch.GetElapsedTime(timestamp);\", \"\\n}\\n```\\n\\n| Method | Mean     | Ratio | Allocated | Alloc Ratio |\\n|--------|----------|-------|-------\", \"----|-------------|\\n| Old    | 32.90 ns | 1.00  | 40 B      | 1.00        |\\n| New    | 26.30 ns | 0.\", \"80  | -         | 0.00        |\\n\\n### <span id=\\\"page-212-0\\\"></span>Exceptions\\n\\nIt might be odd to see\", \" the subject of \\\"exceptions\\\" in a post on performance improvements. After all, exceptions are by the\", \"ir very nature meant to be \\\"exceptional\\\" (in the \\\"rare\\\" sense), and thus wouldn't typically contribu\", \"te to fast-path performance. Which is a good thing, because fast-paths that throw exceptions in the \", \"common case are no longer fast: throwing exceptions is quite expensive.\\n\\nInstead, one of the things \", \"we *do* concern ourselves with is how to minimize the impact of checking for exceptional conditions:\", \" the actual exception throwing may be unexpected and slow, but it's super common to need to check fo\", \"r those unexpected conditions, and that checking should be very fast. We also want such checking to \", \"minimally impact binary size, especially if we're going to have many such checks all over the place,\", \" in generic code for which we end up with many copies due to generic specialization, in functions th\", \"at might be inlined, and so on. Further, we don't want such checks to impede other optimizations; fo\", \"r example, if I have a small function that wants to do some argument validation and would otherwise \", \"be inlineable, I likely don't want the presence of exception throwing to invalidate the possibility \", \"of inlining.\\n\\nBecause of all of that, high-performance libraries often come up with custom \\\"throw he\", \"lpers\\\" they use to achieve their goals. There are a variety of patterns for this. Sometimes a librar\", \"y will just define its own static method that handles constructing and throwing an exception, and th\", \"en call sites do the condition check and delegate to the method if throwing is needed:\\n\\n```\\nif (arg \", \"is null)\\n ThrowArgumentNullException(nameof(arg));\\n...\\n[DoesNotReturn]\\nprivate static void ThrowArgu\", \"mentNullException(string arg) =>\\n throw new ArgumentNullException(arg);\\n```\\n\\nThis keeps the IL assoc\", \"iated with the throwing out of the calling function, minimizing the impact of the throw. That's part\", \"icularly valuable when additional work is needed to construct the exception, e.g.\\n\\n```\\nprivate stati\", \"c void ThrowArgumentNullException(string arg) =>\\n throw new ArgumentNullException(arg, SR.SomeResour\", \"ceMessage);\\n```\\n\\nOther times, libraries will encapsulate both the checking and throwing. This is exa\", \"ctly what the ArgumentNullException.ThrowIfNull method that was added in .NET 6 does:\\n\\n```\\npublic st\", \"atic void ThrowIfNull([NotNull] object? argument, \\n[CallerArgumentExpression(\\\"argument\\\")] string? pa\", \"ramName = null)\\n{\\n if (argument is null)\\n Throw(paramName);\\n}\\n```\\n\\n```\\n[DoesNotReturn]\\ninternal stat\", \"ic void Throw(string? paramName) => throw new\\nArgumentNullException(paramName);\\n```\\n\\nWith that, call\", \"ers benefit from the concise call site:\\n\\n```\\npublic void M(string arg)\\n{\\n ArgumentNullException.Thro\", \"wIfNull(arg);\\n ...\\n}\\n```\\n\\nthe IL remains concise, and the assembly generated for the JIT will includ\", \"e the streamlined condition check from the inlined ThrowIfNull but won't inline the Throw helper, re\", \"sulting in effectively the same code as if you'd written the previously shown manual version with Th\", \"rowArgumentNullException yourself. Nice.\\n\\nWhenever we introduce new public APIs in .NET, I'm particu\", \"larly keen on seeing them used as widely as possible. Doing so serves multiple purposes, including h\", \"elping to validate that the new API is usable and fully addresses the intended scenarios, and includ\", \"ing the rest of the codebase benefiting from whatever that API is meant to provide, whether it be a \", \"performance improvement or just a reduction in routinely written code. In the case of ArgumentNullEx\", \"ception.ThrowIfNull, however, I purposefully put on the brakes. We used it in .NET 6 in several doze\", \"n call sites, but primarily just in place of custom ThrowIfNull-like helpers that had sprung up in v\", \"arious libraries around the runtime, effectively deduplicating them. What we didn't do, however, was\", \" replace the literally thousands of null checks we have with calls to ArgumentNullException.ThrowIfN\", \"ull. Why? Because the new !! C# feature was right around the corner, destined for C# 11.\\n\\nFor those \", \"unaware, the !! feature enabled putting !! onto parameter names in member signatures, e.g.\\n\\n```\\npubl\", \"ic void Process(string name!!)\\n{\\n ...\\n}\\n```\\n\\nThe C# compiler then compiled that as equivalent to:\\n\\n`\", \"``\\npublic void Process(string name)\\n{\\n ArgumentNullException.ThrowIfNull(name);\\n}\\n```\\n\\n(albeit using\", \" its own ThrowIfNull helper injected as internal into the assembly). Armed with the new feature, [do\", \"tnet/runtime#64720](https://github.com/dotnet/runtime/pull/64720) and [dotnet/runtime#65108](https:/\", \"/github.com/dotnet/runtime/pull/65108) rolled out use of !! across [dotnet/runtime,](https://github.\", \"com/dotnet/runtime) replacing ~25,000 lines of code with ~5000 lines that used !!. But, what's the l\", \"ine from Kung Fu Panda, \\\"One often meets his destiny on the road he takes to avoid it\\\"? The presence\", \" of that initial PR kicked off an unprecedented debate about the !! feature, with many folks liking \", \"the concept but a myriad of different opinions about exactly how it should be exposed, and in the en\", \"d, the only common ground was to cut the feature. In response, [dotnet/runtime#68178](https://github\", \".com/dotnet/runtime/pull/68178) undid all usage of !!, replacing most of it with ArgumentNullExcepti\", \"on.ThrowIfNull. There are now ~5000 uses of ArgumentNullException.ThrowIfNull across [dotnet/runtime\", \",](https://github.com/dotnet/runtime) making it one of our most popular\\n\\nAPIs internally. Interestin\", \"gly, while we expected a peanut-buttery effect of slight perf improvements in many places, our perfo\", \"rmance auto-analysis system flagged several performance improvements (e.g. [dotnet/perf-autofiling-i\", \"ssues#3531\\\\)](https://github.com/dotnet/perf-autofiling-issues/issues/3531) as stemming from these c\", \"hanges, in particular because it enabled the JIT's inlining heuristics to flag more methods for inli\", \"ning.\\n\\nWith the success of ArgumentNullException.ThrowIfNull and along with its significant roll-out\", \" in .NET 7, .NET 7 also sees the introduction of several more such throw helpers. [dotnet/runtime#61\", \"633,](https://github.com/dotnet/runtime/pull/61633)  for example, adds an overload of ArgumentNullEx\", \"ception.ThrowIfNull that works with pointers. [dotnet/runtime#64357](https://github.com/dotnet/runti\", \"me/pull/64357) adds the new ArgumentException.ThrowIfNullOrEmpty helper as well as using it in sever\", \"al hundred places. And [dotnet/runtime#58684](https://github.com/dotnet/runtime/pull/58684) from [@B\", \"ibletoon](https://github.com/Bibletoon) adds the new ObjectDisposedException.ThrowIf helper (tweaked\", \" by [dotnet/runtime#71544](https://github.com/dotnet/runtime/pull/71544) to help ensure it's inlinea\", \"ble), which is then used at over a hundred additional call sites by [dotnet/runtime#71546.](https://\", \"github.com/dotnet/runtime/pull/71546)\\n\\n### <span id=\\\"page-215-0\\\"></span>Registry\\n\\nOn Windows, the Re\", \"gistry is a database provided by the OS for applications and the system itself to load and store con\", \"figuration settings. Practically every application accesses the registry. I just tried a simple cons\", \"ole app:\\n\\n```\\nConsole.WriteLine(\\\"Hello, world\\\");\\n```\\n\\nbuilt it as release, and then ran the resultin\", \"g .exe. That execution alone triggered 64 RegQueryValue operations (as visible via SysInternals' [Pr\", \"ocess Monitor](https://docs.microsoft.com/sysinternals/downloads/procmon) tool). The core .NET libra\", \"ries even access the registry for a variety of purposes, such as for gathering data for TimeZoneInfo\", \", gathering data for various calendars like HijriCalendar and JapaneseCalendar, or for serving up en\", \"vironment variables as part of Environment.GetEnvironmentVariable(EnvironmentVariableTarget) with En\", \"vironmentVariableTarget.User or EnvironmentVariableTarget.Machine.\\n\\nIt's thus beneficial to streamli\", \"ne access to registry data on Windows, in particular for reducing overheads in startup paths where t\", \"he registry is frequently accessed. [dotnet/runtime#66918](https://github.com/dotnet/runtime/pull/66\", \"918) does just that. Previously, calling RegistryKey.GetValue would make a call to RegQueryValueEx w\", \"ith a null buffer; this tells the RegQueryValueEx method that the caller wants to know how big a buf\", \"fer is required in order to store the value for the key. The implementation would then allocate a bu\", \"ffer of the appropriate size and call RegQueryValueEx again, and for values that are to be returned \", \"as strings, would then allocate a string based on the data in that buffer. This PR instead recognize\", \"s that the vast majority of data returned from calls to the registry is relatively small. It starts \", \"with a stackalloc'd buffer of 512 bytes, and uses that buffer as part of the initial call to RegQuer\", \"yValueEx. If the buffer was sufficiently large, we no longer have to make a second system call to re\", \"trieve the actual data: we already got it. If the buffer was too small, we rent an ArrayPool buffer \", \"of sufficient size and use that pooled buffer for the subsequent RegQueryValueEx call. Except in sit\", \"uations where we actually need to return a byte[] array to the caller (e.g. the type of the key is R\", \"EG\\\\_BINARY), this avoids the need for the allocated byte[]. And for keys that return strings (e.g. t\", \"he type of the key is REG\\\\_SZ), previously the old implementation would have allocated a temporary c\", \"har[] to use as the buffer passed to RegQueryValueEx, but we can instead just reinterpret cast (e.g.\", \" MemoryMarshal.Cast) the original buffer (whether a stackalloc'd span or the rented buffer as a Span\", \"<char>), and use that to construct the resulting string.\\n\\n```\\nprivate static readonly RegistryKey s_\", \"netFramework = \\nRegistry.LocalMachine.OpenSubKey(@\\\"SOFTWARE\\\\Microsoft\\\\.NETFramework\\\");\\n[Benchmark] p\", \"ublic string RegSz() => (string)s_netFramework.GetValue(\\\"InstallRoot\\\");\\n```\\n\\n| Method | Runtime  | M\", \"ean     | Ratio | Allocated | Alloc Ratio |\\n|--------|----------|----------|-------|-----------|----\", \"---------|\\n| RegSz  | .NET 6.0 | 6.266 us | 1.00  | 200 B     | 1.00        |\\n| RegSz  | .NET 7.0 | \", \"3.182 us | 0.51  | 96 B      | 0.48        |\\n\\n### <span id=\\\"page-217-0\\\"></span>Analyzers\\n\\nThe abilit\", \"y to easily plug custom code, whether for analyzers or source generators, into the Roslyn compiler i\", \"s one of my favorite features in all of C#. It means the developers working on C# don't need to be s\", \"olely responsible for highlighting every possible thing you might want to diagnose in your code. Ins\", \"tead, library authors can write their own analyzers, ship them either in dedicated nuget packages or\", \" as side-by-side in nuget packages with APIs, and those analyzers augment the compiler's own analysi\", \"s to help developers write better code. We ship a large number of analyzer rules in the .NET SDK, ma\", \"ny of which are focused on performance, and we augment that set with more and more analyzers every r\", \"elease. We also work to apply more and more of those rules against our own codebases in every releas\", \"e. .NET 7 is no exception.\\n\\nOne of my favorite new analyzers was added in [dotnet/roslyn-analyzers#5\", \"594](https://github.com/dotnet/roslyn-analyzers/pull/5594) from [@NewellClark](https://github.com/Ne\", \"wellClark) (and tweaked in [dotnet/roslyn-analyzers#5972\\\\)](https://github.com/dotnet/roslyn-analyze\", \"rs/pull/5972). In my [.NET 6 performance](https://devblogs.microsoft.com/dotnet/performance-improvem\", \"ents-in-net-6) post, I talked about some of the overheads possible when types aren't sealed:\\n\\n- Virt\", \"ual calls are more expensive than regular non-virtual invocation and generally can't be inlined, sin\", \"ce the JIT doesn't know what is the actual type of the instance and thus the actual target of the in\", \"vocation (at least not without assistance from PGO). But if the JIT can see that a virtual method is\", \" being invoked on a sealed type, it can devirtualize the call and potentially even inline it.\\n- If a\", \" type check (e.g. something is typeof(SomeType)) is performed where SomeType is sealed, that check c\", \"an be implemented along the lines of something is not null && something.GetType() == typeof(SomeType\", \"). In contrast, if SomeType is not sealed, the check is going to be more along the lines of CastHelp\", \"ers.IsInstanceOfClass(typeof(SomeType), something), where IsInstanceOfClass is a non-trivial (and to\", \"day non-inlined) call into a JIT helper method in Corelib that not only checks for null and for dire\", \"ct equality with the specified type, but also linearly walks the parent hierarchy of the type of the\", \" object being tested to see if it might derive from the specified type.\\n- Arrays in .NET are covaria\", \"nt, which means if types B and C both derive from type A, you can have a variable typed as A[] that'\", \"s storing a B[]. Since C derives from A, it's valid to treat a C as an A, but if the A[] is actually\", \" a B[], storing a C into that array would mean storing a C into a B[], which is invalid. Thus, every\", \" time you store an object reference into an array of reference types, additional validation may need\", \" to be performed to ensure the reference being written is compatible with the concrete type of the a\", \"rray in question. But, if A in this example were sealed, nothing could derive from it, so storing ob\", \"jects into it doesn't require such covariance checks.\\n- Spans shift this covariance check to their c\", \"onstructor; rather than performing the covariance check on every write into the array, the check is \", \"performed when a span is being constructed from an array, such that if you try to create a new Span<\", \"A>(bArray), the ctor will throw an exception. If A is sealed, the JIT is able to elide such a check \", \"as well.\\n\\nIt effectively would be impossible for an analyzer to be able to safely recommend sealing \", \"public types. After all, it has no knowledge of the type's purpose, how it's intended to be used, an\", \"d whether anyone outside of the assembly containing the type actually derives from it. But internal \", \"and private types are another story. An analyzer *can* actually see every possible type that could b\", \"e deriving from a private type, since the analyzer has access to the whole compilation unit containi\", \"ng that type, and it needn't worry about compatibility because anything that could derive from such \", \"a type necessarily must also be non-public and would be recompiled right along with the base type. F\", \"urther, with the exception of assemblies annotated as InternalsVisibleTo, an analyzer can have the s\", \"ame insight into internal types. Thus, this PR adds CA1852, an analyzer that flags in non-InternalsV\", \"isibleTo assemblies all private and internal types that aren't sealed and that have no types derivin\", \"g from them and recommends they be sealed. (Due to some current limitations in the infrastructure ar\", \"ound fixers and how this analyzer had to be written in order to be able to see all of the types in t\", \"he assembly, the analyzer for CA1852 doesn't show up in Visual Studio. It can, however, be applied u\", \"sing the dotnet format tool. And if you bump up the level of the rule from info to warning or error,\", \" it'll show up as part of builds as well.)\\n\\nIn .NET 6, we sealed over 2300 types, but even with that\", \", this analyzer ended up finding more to seal. [dotnet/runtime#59941](https://github.com/dotnet/runt\", \"ime/pull/59941) from [@NewellClark](https://github.com/NewellClark) sealed another ~70 types, and [d\", \"otnet/runtime#68268](https://github.com/dotnet/runtime/pull/68268) which enabled the rule as an warn\", \"ing in [dotnet/runtime](https://github.com/dotnet/runtime) (which builds with warnings-as-errors) se\", \"aled another ~100 types. As a larger example of the rule in use, ASP.NET hadn't done much in the way\", \" of sealing types in previous releases, but with CA1852 now in the .NET SDK, [dotnet/aspnetcore#4145\", \"7](https://github.com/dotnet/aspnetcore/pull/41457) enabled the analyzer and sealed more than ~1100 \", \"types.\\n\\nAnother new analyzer, CA1854, was added in [dotnet/roslyn-analyzers#4851](https://github.com\", \"/dotnet/roslyn-analyzers/pull/4851) from [@CollinAlpert](https://github.com/CollinAlpert) and then e\", \"nabled in [dotnet/runtime#70157.](https://github.com/dotnet/runtime/pull/70157) This analyzer looks \", \"for the surprisingly common pattern where a Dictionary<TKey, TValue>'s ContainsKey is used to determ\", \"ine whether a dictionary contains a particular entry, and then if it does, the dictionary's indexer \", \"is used to retrieve the value associated with the key, e.g.\\n\\n```\\nif (_dictionary.ContainsKey(key))\\n{\", \"\\n var value = _dictionary[key];\\n Use(value);\\n}\\n```\\n\\nDictionary's TryGetValue method already combines\", \" both of these operations, both looking up the key and retrieving its value if it exists, doing so a\", \"s a single operation:\\n\\n```\\nif (_dictionary.TryGetValue(key, out var value))\\n{\\n Use(value);\\n}\\n```\\n\\nA \", \"benefit of this, in addition to arguably being simpler, is that it's also faster. While Dictionary<T\", \"Key, TValue> provides very fast lookups, and while the performance of those lookups has gotten faste\", \"r over time, doing fast work is still more expensive than doing no work, and if we can do one lookup\", \" instead of two, that can result in a meaningful performance boost, in particular if it's being perf\", \"ormed on a fast path. And we can see from this simple benchmark that looks up a word in a dictionary\", \" that, for this operation, making distinct calls to ContainsKey and the indexer does indeed double t\", \"he cost of using the dictionary, almost exactly:\\n\\n```\\nprivate readonly Dictionary<string, int> _coun\", \"ts = Regex.Matches(\\n new\\nHttpClient().GetStringAsync(\\\"https://www.gutenberg.org/cache/epub/100/pg100\", \".txt\\\").Result, \\n@\\\"\\\\b\\\\w+\\\\b\\\")\\n .Cast<Match>()\\n .GroupBy(word => word.Value, StringComparer.OrdinalIgno\", \"reCase)\\n .ToDictionary(word => word.Key, word => word.Count(), \\nStringComparer.OrdinalIgnoreCase);\\np\", \"rivate string _word = \\\"the\\\";\\n[Benchmark(Baseline = true)]\\npublic int Lookup1()\\n{\\n if (_counts.Contai\", \"nsKey(_word))\\n {\\n return _counts[_word];\\n }\\n return -1;\\n}\\n[Benchmark]\\npublic int Lookup2()\\n{\\n if (_c\", \"ounts.TryGetValue(_word, out int count))\\n {\\n return count;\\n }\\n return -1;\\n}\\n```\\n\\n| Method  | Mean   \", \"  | Ratio |\\n|---------|----------|-------|\\n| Lookup1 | 28.20 ns | 1.00  |\\n| Lookup2 | 14.12 ns | 0.5\", \"0  |\\n\\nSomewhat ironically, even as I write this example, the analyzer and its auto-fixer are helpful\", \"ly trying to get me to change my benchmark code:\\n\\n![](_page_220_Figure_0.jpeg)\\n\\nSimilarly, [dotnet/r\", \"oslyn-analyzers#4836](https://github.com/dotnet/roslyn-analyzers/pull/4836) from [@chucker](https://\", \"github.com/chucker) added CA1853, which looks for cases where a Remove call on a dictionary is guard\", \"ed by a ContainsKey call. It seems it's fairly natural for developers to only call Remove on a dicti\", \"onary once they're sure the dictionary contains the thing being removed; maybe they think Remove wil\", \"l throw an exception if the specified key doesn't exist. However, Remove actually allows this as a f\", \"irst-class scenario, with its return Boolean value indicating whether the key was in the dictionary \", \"(and thus successfully removed) or not. An example of this comes from [dotnet/runtime#68724,](https:\", \"//github.com/dotnet/runtime/pull/68724) where CA1853 was enabled for dotnet/runtime. The EventPipeEv\", \"entDispatcher type's RemoveEventListener method had code like this:\\n\\n```\\nif (m_subscriptions.Contain\", \"sKey(listener))\\n{\\n m_subscriptions.Remove(listener);\\n}\\n```\\n\\nwhich the analyzer flagged and which it'\", \"s auto-fixer replaced with just:\\n\\n```\\nm_subscriptions.Remove(listener);\\n```\\n\\nNice and simple. And fa\", \"ster, since as with the TryGetValue case, this is now doing a single dictionary lookup rather than t\", \"wo. :::{custom-style=Figure}\\n\\n![](_page_221_Figure_0.jpeg)\\n\\nAnother nice analyzer added in [dotnet/r\", \"oslyn-analyzers#5907](https://github.com/dotnet/roslyn-analyzers/pull/5907) and [dotnet/roslyn-analy\", \"zers#5910](https://github.com/dotnet/roslyn-analyzers/pull/5910) is CA1851, which looks for code tha\", \"t iterates through some kinds of enumerables multiple times. Enumerating an enumerator, whether dire\", \"ctly or via helper methods like those in LINQ, can have nontrivial cost. Calling GetEnumerator typic\", \"ally allocates an enumerator object, and every item yielded typically involves two interface calls, \", \"one to MoveNext and one to Current. If something can be done via a single pass over the enumerable r\", \"ather than multiple passes, that can save such costs. In some cases, seeing places this analyzer fir\", \"es can also inspire changes that avoid any use of enumerators. For example, [dotnet/runtime#67292](h\", \"ttps://github.com/dotnet/runtime/pull/67292) enabled CA1851 for [dotnet/runtime,](https://github.com\", \"/dotnet/runtime) and in doing so, it fixed several diagnostics issued by the analyzer (even in a cod\", \"e base that's already fairly stringent about enumerator and LINQ usage). As an example, this is a fu\", \"nction in System.ComponentModel.Composition that was flagged by the analyzer:\\n\\n```\\nprivate void Init\", \"ializeTypeCatalog(IEnumerable<Type> types)\\n{\\n foreach (Type type in types)\\n {\\n if (type == null)\\n {\\n\", \" throw ExceptionBuilder.CreateContainsNullElement(nameof(types));\\n }\\n else if (type.Assembly.Reflect\", \"ionOnly)\\n {\\n throw new ArgumentException(SR.Format(SR.Argument_ElementReflectionOnlyType, \\nnameof(ty\", \"pes)), nameof(types));\\n }\\n }\\n _types = types.ToArray();\\n}\\n```\\n\\nThe method's purpose is to convert th\", \"e enumerable into an array to be stored, but also to validate that the contents are all non-null and\", \" non-\\\"ReflectionOnly.\\\" To achieve that, the method is first using a foreach to iterate through the e\", \"numerable, validating each element along the way, and then once it's done so, it calls ToArray() to \", \"convert the enumerable into an array. There are multiple problems\\n\\nwith this. First, it's incurring \", \"the expense of interating through the enumerable twice, once for the foreach and once for the ToArra\", \"y(), which internally needs to enumerate it if it can't do something special like cast to ICollectio\", \"n<Type> and CopyTo the data out of it. Second, it's possible the caller's IEnumerable<Type> changes \", \"on each iteration, so any validation done in the first iteration isn't actually ensuring there aren'\", \"t nulls in the resulting array, for example. Since the expectation of the method is that all inputs \", \"are valid and we don't need to optimize for the failure cases, the better approach is to *first* cal\", \"l ToArray() and then validate the contents of that array, which is exactly what that PR fixes it to \", \"do:\\n\\n```\\nprivate void InitializeTypeCatalog(IEnumerable<Type> types)\\n{\\n Type[] arr = types.ToArray()\", \";\\n foreach (Type type in arr)\\n {\\n if (type == null)\\n {\\n throw ExceptionBuilder.CreateContainsNullEle\", \"ment(nameof(types));\\n }\\n if (type.Assembly.ReflectionOnly)\\n {\\n throw new ArgumentException(SR.Format\", \"(SR.Argument_ElementReflectionOnlyType, \\nnameof(types)), nameof(types));\\n }\\n }\\n _types = arr;\\n}\\n```\\n\", \"\\nWith that, we only ever iterate it once (and possibly 0 times if ToArray can special-case it, and b\", \"onus, we validate on the copy rather than on the mutable original.\\n\\nYet another helpful analyzer is \", \"the new CA1850 introduced in [dotnet/roslyn-analyzers#4797](https://github.com/dotnet/roslyn-analyze\", \"rs/pull/4797) from [@wzchua](https://github.com/wzchua). It used to be that if you wanted to cryptog\", \"raphically hash some data in .NET, you would create an instance of a hash algorithm and call its Com\", \"puteHash method, e.g.\\n\\n```\\npublic byte[] Hash(byte[] data)\\n{\\n using (SHA256 h = SHA256.Create())\\n {\\n\", \" return h.ComputeHash(data);\\n }\\n}\\n```\\n\\nHowever, .NET 5 introduced new \\\"one-shot\\\" hashing methods, wh\", \"ich obviates the need to create a new HashAlgorithm instance, providing a static method that perform\", \"s the whole operation.\\n\\n```\\npublic byte[] Hash(byte[] data)\\n{\\n return SHA256.HashData(data);\\n}\\n```\\n\\n\", \"CA1850 finds occurrences of the former pattern and recommends changing them to the latter.\\n\\nThe resu\", \"lt is not only simpler, it's also faster:\\n\\n```\\nprivate readonly byte[] _data = RandomNumberGenerator\", \".GetBytes(128);\\n[Benchmark(Baseline = true)]\\npublic byte[] Hash1()\\n{\\n using (SHA256 h = SHA256.Creat\", \"e())\\n {\\n return h.ComputeHash(_data);\\n }\\n}\\n[Benchmark]\\npublic byte[] Hash2()\\n{\\n return SHA256.HashDa\", \"ta(_data);\\n}\\n```\\n\\n| Method | Mean       | Ratio | Allocated | Alloc Ratio |\\n|--------|------------|-\", \"------|-----------|-------------|\\n| Hash1  | 1,212.9 ns | 1.00  | 240 B     | 1.00        |\\n| Hash2 \", \" | 950.8 ns   | 0.78  | 56 B      | 0.23        |\\n\\n![](_page_223_Figure_3.jpeg)\\n\\nThe .NET 7 SDK also\", \" includes new analyzers around [GeneratedRegex(...)] [\\\\(dotnet/runtime#68976\\\\)](https://github.com/d\", \"otnet/runtime/pull/68976) and the already mentioned ones for LibraryImport, all of which help to mov\", \"e your code forwards to more modern patterns that have better performance characteristics.\\n\\n![](_pag\", \"e_224_Figure_0.jpeg)\\n\\nThis release also saw [dotnet/runtime](https://github.com/dotnet/runtime) turn\", \" on a bunch of additional IDEXXXX code style rules and make a huge number of code changes in respons\", \"e. Most of the resulting changes are purely about simplifying the code, but in almost every case som\", \"e portion of the changes also have a functional and performance impact.\\n\\nLet's start with IDE0200, w\", \"hich is about removing unnecessary lambdas. Consider a setup like this:\\n\\n```\\npublic class C\\n{\\n publi\", \"c void CallSite() => M(i => Work(i));\\n public void M(Action<int> action) { }\\n private static void Wo\", \"rk(int value) { }\\n}\\n```\\n\\nHere we have a method CallSite that's invoking a method M and passing a lam\", \"bda to it. Method M accepts an Action<int>, and the call site is passing a lambda that takes the sup\", \"plied Int32 and passes it off to some static functionality. For this code, the C# compiler is going \", \"to generate something along the lines of this:\\n\\n```\\npublic class C\\n{\\n [CompilerGenerated]\\n private s\", \"ealed class <>c\\n {\\n public static readonly <>c <>9 = new <>c();\\n public static Action<int> <>9__0_0;\", \"\\n internal void <CallSite>b__0_0(int i) => Work(i);\\n }\\n public void CallSite() => M(<>c.<>9__0_0 ??=\", \" new\\nAction<int>(<>c.<>9.<CallSite>b__0_0));\\n public void M(Action<int> action) { }\\n private static \", \"void Work(int value) { }\\n}\\n```\\n\\nThe most important aspect of this is that <>9\\\\_\\\\_0\\\\_0 field the comp\", \"iler emitted. That field is a cache for the delegate created in CallSite. The first time CallSite is\", \" invoked, it'll allocate a new delegate for the lambda and store it into that field. For all subsequ\", \"ent invocations, however, it'll find the field is\\n\\nnon-null and will just reuse the same delegate. T\", \"hus, this lambda only ever results in a single allocation for the whole process (ignoring any race c\", \"onditions on the initial lazy initialization such that multiple threads all racing to initialize the\", \" field might end up producing a few additional unnecessary allocations). It's important to recognize\", \" this caching only happens because the lambda doesn't access any instance state and doesn't close ov\", \"er any locals; if it did either of those things, such caching wouldn't happen. Secondarily, it's int\", \"eresting to note the pattern the compiler uses for the lambda itself. Note that generated <CallSite>\", \"b\\\\_\\\\_0\\\\_0 method is generated as an instance method, and the call site refers to that method of a si\", \"ngleton instance that's used to initialize a <>9 field. That's done because delegates to static meth\", \"ods use something called a \\\"shuffle thunk\\\" to move arguments into the right place for the target met\", \"hod invocation, making delegates to statics ever so slightly more expensive to invoke than delegates\", \" to instance methods.\\n\\n```\\nprivate Action _instance = new C().InstanceMethod;\\nprivate Action _static\", \" = C.StaticMethod;\\n[Benchmark(Baseline = true)]\\npublic void InvokeInstance() => _instance();\\n[Benchm\", \"ark]\\npublic void InvokeStatic() => _static(); \\nprivate sealed class C\\n{\\n public static void StaticMe\", \"thod() { }\\n public void InstanceMethod() { }\\n}\\n```\\n\\n| Method         | Mean      | Ratio |\\n|--------\", \"--------|-----------|-------|\\n| InvokeInstance | 0.8858 ns | 1.00  |\\n| InvokeStatic   | 1.3979 ns | \", \"1.58  |\\n\\nSo, the compiler is able to cache references to lambdas, great. What about method groups, i\", \".e. where you just name the method directly? Previously, if changed my code to:\\n\\n```\\npublic class C\\n\", \"{\\n public void CallSite() => M(Work);\\n public void M(Action<int> action) { }\\n private static void Wo\", \"rk(int value) { }\\n}\\n```\\n\\nthe compiler would generate the equivalent of:\\n\\n```\\npublic class C\\n{\\n publi\", \"c void CallSite() => M(new Action<int>(Work));\\n public void M(Action<int> action) { }\\n private stati\", \"c void Work(int value) { }\\n}\\n```\\n\\nwhich has the unfortunate effect of allocating a new delegate on e\", \"very invocation, even though we're still dealing with the exact same static method. Thanks to [dotne\", \"t/roslyn#58288](https://github.com/dotnet/roslyn/pull/58288) from [@pawchen](https://github.com/pawc\", \"hen), the compiler will now generate the equivalent of:\\n\\n```\\npublic class C\\n{\\n [CompilerGenerated]\\n \", \"private static class <>O\\n {\\n public static Action<int> <0>__Work;\\n }\\n public void CallSite() => M(<>\", \"O.<0>__Work ??= new Action<int>(Work));\\n public void M(Action<int> action) { }\\n private static void \", \"Work(int value) { }\\n}\\n```\\n\\nNote we again have a caching field that's used to enable allocating the d\", \"elegate once and caching it. That means that places where code was using a lambda to enable this cac\", \"hing can now switch back to the cleaner and simpler method group way of expressing the desired funct\", \"ionality. There is the interesting difference to be cognizant of that since we don't have a lambda w\", \"hich required the compiler emitting a new method for, we're still creating a delegate directly to th\", \"e static method. However, the minor difference in thunk overhead is typically made up for by the fac\", \"t that we don't have a second method to invoke; in the common case where the static helper being inv\", \"oked isn't inlinable (because it's not super tiny, because it has exception handling, etc.), we prev\", \"iously would have incurred the cost of the delegate invocation plus the non-inlinable method call, a\", \"nd now we just have the cost of an ever-so-slightly more expensive delegate invocation; on the whole\", \", it's typically a wash.\\n\\nAnd that brings us to IDE0200, which recognizes lambda expressions that ca\", \"n be removed. [dotnet/runtime#71011](https://github.com/dotnet/runtime/pull/71011) enabled the analy\", \"zer for [dotnet/runtime,](https://github.com/dotnet/runtime) resulting in more than 100 call sites c\", \"hanging accordingly. However, IDE0200 does more than just this mostly stylistic change. It also reco\", \"gnizes some patterns that can make a more substantial impact. Consider this code that was changed as\", \" part of that PR:\\n\\n```\\nAction disposeAction;\\nIDisposable? disposable = null;\\n...\\nif (disposable != n\", \"ull)\\n{\\n disposeAction = () => disposable.Dispose();\\n}\\n```\\n\\nThat delegate closes over the disposable \", \"local, which means this method needs to allocate a display class. But IDE0200 recognizes that instea\", \"d of closing over disposable, we can create the delegate directly to the Dispose method:\\n\\n```\\nAction\", \" disposeAction;\\nIDisposable? disposable = null;\\n...\\nif (disposable != null)\\n{\\n```\\n\\n```\\n disposeActio\", \"n = disposable.Dispose;\\n}\\n```\\n\\nWe still get a delegate allocation, but we avoid the display class al\", \"location, and as a bonus we save on the additional metadata required for the synthesized display cla\", \"ss and method generated for the lambda.\\n\\nIDE0020 is another good example of an analyzer that is prim\", \"arily focused on making code cleaner, more maintainable, more modern, but that can also lead to remo\", \"ving overhead from many different places. The analyzer looks for code performing unnecessary duplica\", \"tive casts and recommends using C# pattern matching syntax instead. For example, [dotnet/runtime#705\", \"23](https://github.com/dotnet/runtime/pull/70523) enabled the analyzer and switched more than 250 lo\", \"cations from code like:\\n\\n```\\nif (value is SqlDouble)\\n{\\n SqlDouble i = (SqlDouble)value;\\n return Comp\", \"areTo(i);\\n}\\n```\\n\\nto instead be like:\\n\\n```\\nif (value is SqlDouble i)\\n{\\n return CompareTo(i);\\n}\\n```\\n\\nI\", \"n addition to being cleaner, this ends up saving a cast operation, which can add measurable overhead\", \" if the JIT is unable to remove it:\\n\\n```\\nprivate object _value = new List<string>();\\n[Benchmark(Base\", \"line = true)]\\npublic List<string> WithCast()\\n{\\n object value = _value;\\n return value is List<string>\", \" ? (List<string>)value : null;\\n}\\n[Benchmark]\\npublic List<string> WithPattern()\\n{\\n object value = _va\", \"lue;\\n return value is List<string> list ? list : null;\\n}\\n```\\n\\n| Method      | Mean     | Ratio |\\n|--\", \"-----------|----------|-------|\\n| WithCast    | 2.602 ns | 1.00  |\\n| WithPattern | 1.886 ns | 0.73  \", \"|\\n\\nThen there's IDE0031, which promotes using null propagation features of C#. This analyzer typical\", \"ly manifests as recommending changing snippets like:\\n\\n```\\nreturn _value != null ? _value.Property : \", \"null;\\n```\\n\\ninto code that's instead like:\\n\\n```\\nreturn _value?.Property;\\n```\\n\\nNice, concise, and prim\", \"arily about cleaning up the code and making it simpler and more maintainable by utilizing newer C# s\", \"yntax. However, there is also a small performance advantage in some situations as well. For example,\", \" consider this snippet:\\n\\n```\\npublic class C\\n{\\n private C _value;\\n public int? Get1() => _value != nu\", \"ll ? _value.Prop : null;\\n public int? Get2() => _value?.Prop;\\n public int Prop => 42;\\n}\\n```\\n\\nThe C# \", \"compiler lowers these expressions to the equivalent of this:\\n\\n```\\npublic Nullable<int> Get1()\\n{\\n if \", \"(_value == null) return null;\\n return _value.Prop;\\n}\\npublic Nullable<int> Get2()\\n{\\n C value = _value\", \";\\n if (value == null) return null;\\n return value.Prop;\\n}\\n```\\n\\nfor which the JIT then generates:\\n\\n```\", \"\\n; Program.Get1()\\n push rax\\n mov rdx,[rcx+8]\\n test rdx,rdx\\n jne short M00_L00\\n xor eax,eax\\n add rsp,\", \"8\\n ret\\nM00_L00:\\n cmp [rdx],dl\\n mov dword ptr [rsp+4],2A\\n mov byte ptr [rsp],1\\n mov rax,[rsp]\\n add rs\", \"p,8\\n ret\\n; Total bytes of code 40\\n; Program.Get2()\\n push rax\\n mov rax,[rcx+8]\\n test rax,rax\\n jne sho\", \"rt M00_L00\\n xor eax,eax\\n add rsp,8\\n ret\\nM00_L00:\\n```\\n\\n```\\n mov dword ptr [rsp+4],2A\\n mov byte ptr [r\", \"sp],1\\n mov rax,[rsp]\\n add rsp,8\\n ret\\n; Total bytes of code 38\\n```\\n\\nNote how the Get1 variant has an \", \"extra cmp instruction (cmp [rdx],dl) in the otherwise identical assembly to Get2 (other than registe\", \"r selection). That cmp instruction in Get1 is the JIT forcing a null check on the second read of \\\\_v\", \"alue prior to accessing its Prop, whereas in Get2 the null check against the local means the JIT doe\", \"sn't need to add an additional null check on the second use of the local, since nothing could have c\", \"hanged it. [dotnet/runtime#70965](https://github.com/dotnet/runtime/pull/70965) rolled out additiona\", \"l use of the null propagation operator via auto-fixing IDE0031, resulting in ~120 uses being improve\", \"d.\\n\\nAnother interesting example is IDE0060, which finds unused parameters and recommends removing th\", \"em. This was done for non-public members in System.Private.CoreLib in [dotnet/runtime#63015.](https:\", \"//github.com/dotnet/runtime/pull/63015) As with some of the other mentioned rules, it's primarily ab\", \"out good hygiene. There can be some small additional cost associated with passing additional paramet\", \"ers (the overhead of reading the values at the call site, putting them into the right register or st\", \"ack location, etc., and also the metadata size associated with the additional parameter information)\", \", but the larger benefit comes from auditing all of the cited violations and finding places where wo\", \"rk is simply being performed unnecessarily. For example, that PR made some updates to the TimeZoneIn\", \"fo type's implementation for Unix. In that implementation is a TZif\\\\_ParseRaw method, which is used \", \"to extract some information from a time zone data file. Amongst many input and output parameters, it\", \" had out bool[] StandardTime, out bool[] GmtTime, which the implementation was dutifully filling in \", \"by allocating and populating new arrays for each. The call site for TZif\\\\_ParseRaw was then taking t\", \"hose arrays and feeding them into another method TZif\\\\_GenerateAdjustmentRules, which ignored them! \", \"Thus, not only was this PR able to remove those parameters from TZif\\\\_GenerateAdjustmentRules, it wa\", \"s able to update TZif\\\\_ParseRaw to no longer need to allocate and populate those arrays at all, whic\", \"h obviously yields a much larger gain.\\n\\nOne final example of peanut-buttery performance improvements\", \" from applying an analyzer comes from [dotnet/runtime#70896](https://github.com/dotnet/runtime/pull/\", \"70896) and [dotnet/runtime#71361,](https://github.com/dotnet/runtime/pull/71361) which applied IDE00\", \"29 across dotnet/runtime. IDE0029 flags cases where null coalescing can be used, e.g. flagging:\\n\\n```\", \"\\nreturn message != null ? message : string.Empty;\\n```\\n\\nand recommending it be converted to:\\n\\n```\\nret\", \"urn message ?? string.Empty;\\n```\\n\\nAs with some of the previous rules discussed, that in and of itsel\", \"f doesn't make a meaningful performance improvement, and rather is about clarity and simplicity. How\", \"ever, in various cases it can. For example, the aforementioned PRs contained an example like:\\n\\n```\\nn\", \"ull != foundColumns[i] ? foundColumns[i] : DBNull.Value;\\n```\\n\\nwhich is rewritten to:\\n\\n```\\nfoundColum\", \"ns[i] ?? DBNull.Value\\n```\\n\\nThis avoids an unnecessary re-access to an array. Or again from those PRs\", \" the expression:\\n\\nentry.GetKey(\\\\_thisCollection) != **null** ? entry.GetKey(\\\\_thisCollection) : \\\"key\", \"\\\"\\n\\nbeing changed to:\\n\\nentry.GetKey(\\\\_thisCollection) ?? \\\"key\\\"\\n\\nand avoiding an unnecessary table loo\", \"kup.\\n\\n### <span id=\\\"page-231-0\\\"></span>What's Next?\\n\\nWhew! That was a lot. Congrats on getting throu\", \"gh it all.\\n\\nThe next step is on you. Download the latest .NET 7 bits and take them for a spin. Upgra\", \"de your apps. Write and share your own benchmarks. Provide feedback, positive and critical. Find som\", \"ething you think can be better? Open an issue, or better yet, submit a PR with the fix. We're excite\", \"d to work with you to polish .NET 7 to be the best .NET release yet; meanwhile, we're getting going \", \"on .NET 8 :)\\n\\nUntil next time\\u2026\\n\\nHappy coding!\"]"