"[\" \\n \\n \\n \\n \\n \\n \\n \\nPerformance Improvements  \\n in .NET 7  \\n \\n \\nStephen Toub  \\nPartner Software Engineer\", \", .NET  \\nMicrosoft  \\n \\n  Introduction  \\nA year ago, I published Performance Improvements in .NET 6 ,\", \" following on the heels of similar posts \\nfor .NET 5 , .NET Core 3.0 , .NET Core 2.1 , and .NET Core\", \" 2.0 . I enjoy writing these posts and love \\nreading developers\\u2019 responses to them. One comment in p\", \"articular last year resonated with me. The \\ncommenter cited the Die Ha rd movie quote, \\u201c\\u2018When Alexan\", \"der saw the breadth of his domain, he \\nwept for there were no more worlds to conquer\\u2019,\\u201d and question\", \"ed whether .NET performance \\nimprovements were similar. Has the well run dry? Are there no more \\u201c[pe\", \"rformance] worlds to \\nconquer\\u201d ? I\\u2019m a bit giddy to say that, even with how fast .NET 6 is, .NET 7 d\", \"efinitively highlights how \\nmuch more can be and has been done.  \\nAs with previous versions of .NET,\", \" performance is a key focus that pervades the entire stack, whether it \\nbe features created  explici\", \"tly for performance or non -performance -related features that are still \\ndesigned and implemented w\", \"ith performance keenly in mind. And now that a .NET 7 release \\ncandidate is just around the corner, \", \"it\\u2019s a good time to discuss much of it. Over the cou rse of the last \\nyear, every time I\\u2019ve reviewed\", \" a PR that might positively impact performance, I\\u2019ve copied that link to a \\njournal I maintain for t\", \"he purposes of writing this post. When I sat down to write this a few weeks ago, \\nI was faced with a\", \" list of alm ost 1000 performance -impacting PRs (out of more than 7000 PRs that \\nwent into the rele\", \"ase), and I\\u2019m excited to share approximately 500 of them here with you.  \\nOne thought before we dive\", \" in. In past years, I\\u2019ve received the odd piece of negative feedback abou t \\nthe length of some of m\", \"y performance -focused write -ups, and while I disagree with the criticism, I \\nrespect the opinion. \", \"So, this year, consider this a \\u201cchoose your own adventure.\\u201d If you\\u2019re here just \\nlooking for a super\", \" short adventure, one that provides  the top -level summary and a core message to \\ntake away from yo\", \"ur time here, I\\u2019m happy to oblige:  \\nTL;DR: .NET 7 is fast. Really fast. A thousand performance -imp\", \"acting PRs went into runtime and core \\nlibraries this release, never mind all the improvements in AS\", \"P.NET Core and Windows Forms and \\nEntity Framework and beyond. It\\u2019s the fastest .NET ever. If your m\", \"anager asks you why your project \\nshould upgrade to .NET 7, you can say \\u201cin addition to all the new \", \"functionality in the release, .NET 7 is \\nsuper fast.\\u201d  \\nOr, if you prefer a slightly longer adventur\", \"e, one filled with interesting nuggets of performance -\\nfocused data, consider skimming through the \", \"post, looking for the small code snippets and \\ncorresponding tables showing a wealth of measurable p\", \"erformance improve ments. At that point, you, \\ntoo, may walk away with your head held high and my th\", \"anks.  \\nBoth noted paths achieve one of my primary goals for spending the time to write these posts,\", \" to \\nhighlight the greatness of the next release and to encourage everyone to g ive it a try. But, I\", \" have other \\ngoals for these posts, too. I want everyone interested to walk away from this post with\", \" an upleveled \\nunderstanding of how .NET is implemented, why various decisions were made, tradeoffs \", \"that were \\nevaluated, techniques that w ere employed, algorithms that were considered, and valuable \", \"tools and \\napproaches that were utilized to make .NET even faster than it was previously. I want dev\", \"elopers to \\nlearn from our own learnings and find ways to apply this new -found knowledge to their o\", \"wn \\ncodebases, thereby further increasing the overall performance of code in the ecosystem. I want \\n\", \"developers to take an extra beat, think about reaching for a profiler the next time they\\u2019re working \", \"on a gnarly problem, think about looking at the source fo r the component they\\u2019re using in order to \", \"better \\nunderstand how to work with it, and think about revisiting previous assumptions and decision\", \"s to \\ndetermine whether they\\u2019re still accurate and appropriate. And I want developers to be excited \", \"at the \\nprospect of submitting PRs to improve .NET not only for themselves but for every developer a\", \"round \\nthe globe using .NET. If any of that sounds interesting, then I encourage you to choose the l\", \"ast \\nadventure: prepare a carafe of your favorite hot beverage, get comfort able, and please enjoy. \", \"  \\ni Contents   \\nContents  \\nSetup  ................................ ................................\", \" ................................ ................................ .........  1 \\nJIT ...............\", \"................. ................................ ................................ ................\", \"................ ..............  3 \\nOn-Stack Replacement  ................................ .........\", \"....................... ................................ ................................ ..........\", \"........  13 \\nPGO ................................ ................................ ................\", \"................ ................................ ................................ .................\", \".......  23 \\nBounds Check Elimination  ................................ ............................\", \".... ................................ ................................ ............  35 \\nLoop Hoisti\", \"ng and Cloning  ................................ ................................ ..................\", \".............. ................................ ..........  45 \\nFolding, propagation, and substituti\", \"on  ................................ ................................ ..............................\", \".. ...................  50 \\nVectorization  ................................ ........................\", \"........ ................................ ................................ .........................\", \"....... ...... 54 \\nInlining  ................................ ................................ .....\", \"........................... ................................ ................................ ......\", \"............  62 \\nArm64  ................................ ................................ .........\", \"....................... ................................ ................................ ..........\", \".........  64 \\nJIT helpers  ................................ ................................ ......\", \".......................... ................................ ................................ .......\", \"....  65 \\nGrab Bag  ................................ ................................ ..............\", \".................. ................................ ................................ .............. \", \" 67 \\nGC ................................ ................................ ..........................\", \"...... ................................ ............  71 \\nNative AOT  ..............................\", \".. ................................ ................................ .............................  \", \"72 \\nMono  ................................ ................................ ........................\", \"........ ................................ ...... 75 \\nReflection  ................................ ..\", \".............................. ................................ ...............................  78 \", \"\\nInterop  ................................ ................................ ........................\", \"........ ................................ .... 82 \\nThreading  ................................ .....\", \"........................... ................................ ...............................  89 \\nPr\", \"imitive Types and Numerics  ................................ ................................ ......\", \".......................  93 \\nArrays, Strings, and Spans  ................................ ..........\", \"...................... ................................ .. 101 \\nRegex  .............................\", \"... ................................ ................................ ..............................\", \".. .... 128 \\nRegexOptions.NonBacktracking ................................ .........................\", \"....... ................................ ...............................  128 \\nNew APIs  ...........\", \"..................... ................................ ................................ ............\", \".................... ................................ ............  133 \\nTryFindNextPossibleStarting\", \"Position  ................................ ................................ ........................\", \"........ .....................  138 \\nLoops and Backtracking  ................................ ......\", \".......................... ................................ ................................ .......\", \".......  143 \\nCode generation  ................................ ................................ ...\", \"............................. ................................ .............................  146 \\nC\", \"ollections  ................................ ................................ ......................\", \".......... ............................  150 \\nLINQ  ................................ ...............\", \"................. ................................ ................................ ...... 153  \\nii \", \"Contents  File I/O  ................................ ................................ ..............\", \".................. ................................ .. 159 \\nCompression  ...........................\", \"..... ................................ ................................ ........................  16\", \"8 \\nNetworking  ................................ ................................ ...................\", \"............. ..........................  173 \\nJSON  ................................ ..............\", \".................. ................................ ................................ ..... 190 \\nXML \", \" ................................ ................................ ................................ \", \"................................ ....... 193 \\nCryptography  ................................ .......\", \"......................... ................................ .......................  198 \\nDiagnostics\", \"  ................................ ................................ ................................\", \" ...........................  203 \\nExceptions  ................................ ....................\", \"............ ................................ ............................  208 \\nRegistry  .........\", \"....................... ................................ ................................ ..........\", \"......................  211 \\nAnalyzers  ................................ ...........................\", \"..... ................................ ..............................  213 \\nWhat\\u2019s Next?  ..........\", \"...................... ................................ ................................ ...........\", \".............  227  \\n1 CHAPTER 1 | Setup  \\n CHAPTER  1 \\nSetup  \\nThe microbenchmarks throughout this \", \"post utilize benchmarkdotnet . To make it easy for you to follow \\nalong with your own validation, I \", \"have a very simple setup for the benchmarks I use. Create a n ew C# \\nproject:  \\ndotnet new console -\", \"o benchmarks  \\ncd benchmarks  \\nYour new benchmarks  directory will contain a benchmarks.csproj  file\", \" and a Program.cs  file. Replace \\nthe contents of benchmarks.csproj  with this:  \\n<Project  Sdk=\\\"Mic\", \"rosoft.NET.Sdk\\\" > \\n \\n  <PropertyGroup>  \\n    <OutputType> Exe</OutputType>  \\n    <TargetFrameworks> \", \"net7.0;net6.0 </TargetFrameworks>  \\n    <LangVersion> Preview </LangVersion>  \\n    <AllowUnsafeBlock\", \"s> true </AllowUnsafeBlocks>  \\n    <ServerGarbageCollection> true </ServerGarbageCollection>  \\n  </P\", \"ropertyGroup>  \\n \\n  <ItemGroup>  \\n    <PackageReference  Include= \\\"benchmarkdotnet\\\"  Version= \\\"0.13.\", \"2\\\"  /> \\n  </ItemGroup>  \\n \\n</Project>  \\nand the contents of Program.cs  with this:  \\nusing Benchmark\", \"DotNet. Attributes ; \\nusing BenchmarkDotNet. Running; \\nusing Microsoft. Win32; \\nusing System; \\nusing\", \" System.Buffers; \\nusing System.Collections .Generic; \\nusing System.Collections .Immutable ; \\nusing S\", \"ystem.ComponentModel ; \\nusing System.Diagnostics ; \\nusing System.IO; \\nusing System.IO.Compression ; \", \"\\nusing System.IO.MemoryMappedFiles ; \\nusing System.IO.Pipes; \\nusing System.Linq; \\nusing System.Net; \", \"\\nusing System.Net.Http; \\nusing System.Net.Http.Headers; \\nusing System.Net.Security ; \\nusing System.N\", \"et.Sockets; \\nusing System.Numerics ;  \\n2 CHAPTER 1 | Setup  \\n using System.Reflection ; \\nusing Syste\", \"m.Runtime.CompilerServices ; \\nusing System.Runtime.InteropServices ; \\nusing System.Runtime.Intrinsic\", \"s ; \\nusing System.Security .Authentication ; \\nusing System.Security .Cryptography ; \\nusing System.Se\", \"curity .Cryptography .X509Certificates ; \\nusing System.Text; \\nusing System.Text.Json; \\nusing System.\", \"Text.RegularExpressions ; \\nusing System.Threading ; \\nusing System.Threading .Tasks; \\nusing System.Xm\", \"l; \\n \\n[MemoryDiagnoser (displayGenColumns: false)] \\n[DisassemblyDiagnoser]  \\n[HideColumns (\\\"Error\\\", \", \"\\\"StdDev\\\" , \\\"Median\\\" , \\\"RatioSD\\\" )] \\npublic partial class Program \\n{ \\n    static void Main(string[] a\", \"rgs) => \\nBenchmarkSwitcher. FromAssembly (typeof(Program). Assembly ).Run(args); \\n \\n    // ... copy \", \"[Benchmark]s here  \\n} \\nFor each benchmark included in this write -up, you can then just copy and pas\", \"te the code into thi s test \\nclass, and run the benchmarks. For example, to run a benchmark comparin\", \"g performance on .NET 6 \\nand .NET 7, do:  \\ndotnet run -c Release -f net6.0 --filter '**' --runtimes \", \"net6.0 net7.0  \\nThis command says \\u201cbuild the benchmarks in release configuration ta rgeting the .NET\", \" 6 surface area, \\nand then run all of the benchmarks on both .NET 6 and .NET 7.\\u201d Or to run just on .\", \"NET 7:  \\ndotnet run -c Release -f net7.0 --filter '**' --runtimes net7.0  \\nwhich instead builds targ\", \"eting the .NET 7 surface area and then only r uns once against .NET 7. You \\ncan do this on any of Wi\", \"ndows, Linux, or macOS. Unless otherwise called out (e.g.  where the \\nimprovements are specific to U\", \"nix and I run the benchmarks on Linux), the results I share were \\nrecorded on Windows 11 64 -bit but\", \" aren\\u2019t  Windows -specific and should show similar relative \\ndifferences on the other operating syst\", \"ems as well.  \\nThe release of the first .NET 7 release candidate is right around the corner. All of \", \"the measurements in \\nthis post were gathered with a recent daily build  of .NET 7 RC1.  \\nAlso, my st\", \"andard caveat: These are microbenchmarks. It is expected that different hardware, different \\nversion\", \"s of operating systems, a nd the way in which the wind is currently blowing can affect the \\nnumbers \", \"involved. Your mileage may vary.   \\n3 CHAPTER 2 | JIT  \\n CHAPTER  2 \\nJIT \\nI\\u2019d like to kick off a dis\", \"cussion of performance improvements in the Just -In-Time (JIT) compiler by \\ntalking about something \", \"that itself isn\\u2019t actually a performance improvement. Being able to \\nunderstand exactly what assembl\", \"y code is generated by the JIT is critical  when fine -tuning lower -level, \\nperformance -sensitive \", \"code. There are multiple ways to get at that assembly code. The online tool \\nsharplab.io  is incredi\", \"bly useful  for this (thanks to [@ashmind](https://github.com/ashmind) for this \\ntool); however it c\", \"urrently only targets a single release, so as I write this I\\u2019m onl y able to see the \\noutput for .NE\", \"T 6, which makes it difficult to use for A/B comparisons. godbolt.org  is also valuable for \\nthis, w\", \"ith C# support added in compiler -explorer/compiler -explorer#3168  from \\n[@hez2010](https://github.\", \"com/hez2010), with similar limitations. The most flexible solutions involve \\ngetting at that assembl\", \"y code locally, as it enables comparing whatever ver sions or local builds you \\ndesire with whatever\", \" configurations and switches set that you need.  \\nOne common approach is to use the [DisassemblyDiag\", \"noser]  in benchmarkdotnet. Simply slap the \\n[DisassemblyDiagnoser]  attribute onto your test class:\", \" benchmarkdotne t will find the assembly code \\ngenerated for your tests and some depth of functions \", \"they call, and dump out the found assembly \\ncode in a human -readable form. For example, if I run th\", \"is test:  \\nusing BenchmarkDotNet. Attributes ; \\nusing BenchmarkDotNet. Running; \\nusing System; \\n \\n[D\", \"isassemblyDiagnoser]  \\npublic partial class Program \\n{ \\n    static void Main(string[] args) => \\nBenc\", \"hmarkSwitcher. FromAssembly (typeof(Program). Assembly ).Run(args); \\n \\n    private int _a = 42, _b =\", \" 84; \\n \\n    [Benchmark]  \\n    public int Min() => Math. Min(_a, _b);  \\n} \\nwith:  \\ndotnet run -c Rele\", \"ase -f net7.0 --filter '**'  \\nin addition to doing all of its normal test execution and timing, benc\", \"hmarkdotnet also outputs a \\nProgram-asm.md  file that contains this:  \\n; Program.Min()  \\n       mov \", \"      eax,[rcx+8]  \\n       mov       edx,[rcx+0C]  \\n       cmp       eax,edx   \\n4 CHAPTER 2 | JIT  \\n\", \"        jg        short M00_L01  \\n       mov       edx,eax  \\nM00_L00:  \\n       mov       eax,edx  \\n \", \"      ret \\nM00_L01:  \\n       jmp       short M00_L00  \\n; Total bytes of code 17  \\nPretty neat. Th is\", \" support was recently improved further in dotnet/benchmarkdotnet#2072 , which \\nallows passing a filt\", \"er list on the command -line to benchmarkdotnet to tell it exactly which methods\\u2019 \\nassembly code sho\", \"uld be dumped.  \\nIf you can get your hands on a \\u201cdebug\\u201d or \\u201cchecked\\u201d build of the .NET runtime (\\u201cche\", \"cked\\u201d is a build \\nthat has optimizations enabled but also still includes asserts), and specifically \", \"of clrjit.dll, another \\nvaluable approach is to set an environment variable that causes the JIT itse\", \"lf to spit out a human -\\nreadable description of all of the assembly code it emits. This can be used\", \" with any kind of \\napplication, as it\\u2019s part of the JIT itself rather than part of any speci fic too\", \"l or other environment, it \\nsupports showing the code the JIT generates each time it generates code \", \"(e.g.  if it first compiles a \\nmethod without optimization and then later recompiles it with optimiz\", \"ation), and overall it\\u2019s the most \\naccurate picture o f the assembly code as it comes \\u201cstraight from\", \" the horses mouth,\\u201d as it were. The \\n(big) downside of course is that it requires a non -release bui\", \"ld of the runtime, which typically means \\nyou need to build it yourself from the sources in the dotn\", \"et/runtime  repo.  \\n\\u2026 until .NET 7, that is. As of dotnet/runtime#73365 , this assembly dumping supp\", \"ort is now available in \\nrelease builds as well, which me ans it\\u2019s simply part of .NET 7 and you don\", \"\\u2019t need anything special to \\nuse it. To see this, try creating a simple \\u201chello world\\u201d app like:  \\nus\", \"ing System; \\n \\nclass Program \\n{ \\n    public static void Main() => Console. WriteLine (\\\"Hello, world!\", \"\\\" ); \\n} \\nand building it ( e.g. dotnet build -c Release ). Then, set the DOTNET_JitDisasm  environme\", \"nt \\nvariable to the name of the method we care about, in this case \\u201cMain\\u201d (the exact syntax allowed \", \"is \\nmore permissive and allows for some use of wildcards, optional namespace and class names, etc.).\", \" As \\nI\\u2019m using PowerShell, that means:  \\n$env:DOTNET_JitDisasm=\\\"Main\\\"  \\nand then running the app. Yo\", \"u should see code like this output to the console:  \\n; Assembly listing for method Program:Main()  \\n\", \"; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compilation  \\n; MinOpts code  \\n; rb\", \"p based frame  \\n; partially interruptible  \\n \\nG_M000_IG01:                ;; offset=0000H  \\n       5\", \"5                   push     rbp  \\n       4883EC20             sub      rsp, 32   \\n5 CHAPTER 2 | JIT\", \"  \\n        488D6C2420           lea      rbp, [rsp+20H]  \\n \\nG_M000_IG02:                ;; offset=00\", \"0AH  \\n       48B9D820400A8E010000 mov      rcx, 0x18E0A4020D8  \\n       488B09               mov     \", \" rcx, gword ptr [rcx]  \\n       FF1583B31000         call     [Console:WriteLine(String)]  \\n       90\", \"                   nop \\n \\nG_M000_IG03:                ;; offset=001EH  \\n       4883C420             \", \"add      rsp, 32  \\n       5D                   pop      rbp  \\n       C3                   ret  \\n \\n; \", \"Total bytes of code 36  \\n \\nHello, world!  \\nThis is immeasurably helpful for perf ormance analysis an\", \"d tuning, even for questions as simple as \\u201cdid \\nmy function get inlined\\u201d or \\u201cis this code I expected\", \" to be optimized away actually getting optimized \\naway.\\u201d Throughout the rest of this post, I\\u2019ll incl\", \"ude assembly snippets generated by one of these two \\nmechanisms, in order to help exemplify concepts\", \".  \\nNote that it can sometimes be a little confusing figuring out what name to specify as the value \", \"for \\nDOTNET_JitDisasm , especially when the method you care about is one that the C# compiler names \", \"or \\nname mangles (since the JIT only sees the IL and metadata, not the original C#), e.g.  the name \", \"of the \\nentry point method for a program with top -level statements, the names of local functions, e\", \"tc. To \\nboth help with this and to provide a really valuable top-level view of the work the JIT is d\", \"oing, .NET 7 \\nalso supports the new DOTNET_JitDisasmSummary  environment variable (introduced in \\ndo\", \"tnet/runtime#74090 ). Set that to \\u201c1\\u201d, and it\\u2019ll result i n the JIT emitting a line every time it co\", \"mpiles a \\nmethod, including the name of that method which is copy/pasteable with DOTNET_JitDisasm . \", \"This \\nfeature is useful in -and-of-itself, however, as it can quickly highlight for you what\\u2019s being\", \" compiled, \\nwhen, a nd with what settings. For example, if I set the environment variable and then r\", \"un a \\u201chello, \\nworld\\u201d console app, I get this output:  \\n   1: JIT compiled CastHelpers:StelemRef(Arra\", \"y,long,Object) [Tier1, IL size=88, code \\nsize=93]  \\n   2: JIT compiled CastHelpers :LdelemaRef(Array\", \",long,long):byref [Tier1, IL size=44, code \\nsize=44]  \\n   3: JIT compiled SpanHelpers:IndexOfNullCha\", \"racter(byref):int [Tier1, IL size=792, code \\nsize=388]  \\n   4: JIT compiled Program:Main() [Tier0, I\", \"L size=11, code size=36]  \\n   5: JIT compiled A SCIIUtility:NarrowUtf16ToAscii(long,long,long):long \", \"[Tier0, IL \\nsize=490, code size=1187]  \\nHello, world!  \\nWe can see for \\u201chello, world\\u201d there\\u2019s only 5\", \" methods that actually get JIT compiled. There are of \\ncourse many more methods that get executed as\", \" part of a  simple \\u201chello, world,\\u201d but almost all of \\nthem have precompiled native code available as\", \" part of the \\u201cReady To Run\\u201d (R2R)  images of the core \\nlibraries. The first three in the above list \", \"( StelemRef , LdelemaRef , and IndexOfNullCharacter ) don\\u2019t \\nbecause they explicitly opted -out of R\", \"2R via use of the \\n[MethodImpl(MethodImplOptions.AggressiveOptimization)]  attribute (despite the na\", \"me, this \\nattribute should almost never be used, and is only used for very specific reasons in a few\", \" very specific \\nplaces in the core libraries). Then there\\u2019s our Main  method. And lastly there\\u2019s the\", \" NarrowUtf16ToAscii   \\n6 CHAPTER 2 | JIT  \\n method, which  doesn\\u2019t have R2R code, either, due to usi\", \"ng the variable -width Vector<T>  (more on \\nthat later). Every other method that\\u2019s run doesn\\u2019t requi\", \"re JIT\\u2019ing. If we instead first set the \\nDOTNET_ReadyToRun  environment variable to 0, the list is m\", \"uch longer, and giv es you a very good \\nsense of what the JIT needs to do on startup (and why techno\", \"logies like R2R are important for startup \\ntime). Note how many methods get compiled before \\u201chello, \", \"world\\u201d is output:  \\n   1: JIT compiled CastHelpers:StelemRef(Array,long,Object) [Tier1, IL size=88, \", \"code \\nsize=93]  \\n   2: JIT compiled CastHelpers:LdelemaRef(Array,long,long):byref [Tier1, IL size=44\", \", code \\nsize=44]  \\n   3: JIT compiled AppContext:Setup(long,long,int) [Tier0, IL size=68, code size=\", \"275]  \\n   4: JIT compiled Dictionary`2:.ctor (int):this [Tier0, IL size=9, code size=40]  \\n   5: JIT\", \" compiled Dictionary`2:.ctor(int,IEqualityComparer`1):this [Tier0, IL size=102, \\ncode size=444]  \\n  \", \" 6: JIT compiled Object:.ctor():this [Tier0, IL size=1, code size=10]  \\n   7: JIT compiled Dictionar\", \"y`2:Init ialize(int):int:this [Tier0, IL size=56, code size=231]  \\n   8: JIT compiled HashHelpers:Ge\", \"tPrime(int):int [Tier0, IL size=83, code size=379]  \\n   9: JIT compiled HashHelpers:.cctor() [Tier0,\", \" IL size=24, code size=102]  \\n  10: JIT compiled HashHelpers:GetFastMod Multiplier(int):long [Tier0,\", \" IL size=9, code \\nsize=37]  \\n  11: JIT compiled Type:GetTypeFromHandle(RuntimeTypeHandle):Type [Tier\", \"0, IL size=8, code \\nsize=14]  \\n  12: JIT compiled Type:op_Equality(Type,Type):bool [Tier0, IL size=3\", \"8, code size=143]  \\n  13: JIT compil ed \\nNonRandomizedStringEqualityComparer:GetStringComparer(Objec\", \"t):IEqualityComparer`1 [Tier0, \\nIL size=39, code size=170]  \\n  14: JIT compiled NonRandomizedStringE\", \"qualityComparer:.cctor() [Tier0, IL size=46, code \\nsize=232]  \\n  15: JIT compiled EqualityComparer`1\", \" :get_Default():EqualityComparer`1 [Tier0, IL size=6, \\ncode size=36]  \\n  16: JIT compiled EqualityCo\", \"mparer`1:.cctor() [Tier0, IL size=26, code size=125]  \\n  17: JIT compiled ComparerHelpers:CreateDefa\", \"ultEqualityComparer(Type):Object [Tier0, IL \\nsize=235, code siz e=949] \\n  18: JIT compiled CastHelpe\", \"rs:ChkCastClass(long,Object):Object [Tier0, IL size=22, code \\nsize=72]  \\n  19: JIT compiled RuntimeH\", \"elpers:GetMethodTable(Object):long [Tier0, IL size=11, code \\nsize=33]  \\n  20: JIT compiled CastHelpe\", \"rs:IsInstanceOfClass(long,O bject):Object [Tier0, IL size=97, \\ncode size=257]  \\n  21: JIT compiled G\", \"enericEqualityComparer`1:.ctor():this [Tier0, IL size=7, code size=31]  \\n  22: JIT compiled Equality\", \"Comparer`1:.ctor():this [Tier0, IL size=7, code size=31]  \\n  23: JIT compiled CastHelpers:C hkCastCl\", \"assSpecial(long,Object):Object [Tier0, IL size=87, \\ncode size=246]  \\n  24: JIT compiled OrdinalCompa\", \"rer:.ctor(IEqualityComparer`1):this [Tier0, IL size=8, code \\nsize=39]  \\n  25: JIT compiled NonRandom\", \"izedStringEqualityComparer:.ctor(IEqualityComparer`1): this \\n[Tier0, IL size=14, code size=52]  \\n  2\", \"6: JIT compiled StringComparer:get_Ordinal():StringComparer [Tier0, IL size=6, code \\nsize=49]  \\n  27\", \": JIT compiled OrdinalCaseSensitiveComparer:.cctor() [Tier0, IL size=11, code size=71]  \\n  28: JIT c\", \"ompiled OrdinalCase SensitiveComparer:.ctor():this [Tier0, IL size=8, code \\nsize=33]  \\n  29: JIT com\", \"piled OrdinalComparer:.ctor(bool):this [Tier0, IL size=14, code size=43]  \\n  30: JIT compiled String\", \"Comparer:.ctor():this [Tier0, IL size=7, code size=31]  \\n  31: JIT compiled StringC omparer:get_Ordi\", \"nalIgnoreCase():StringComparer [Tier0, IL size=6, \\ncode size=49]  \\n  32: JIT compiled OrdinalIgnoreC\", \"aseComparer:.cctor() [Tier0, IL size=11, code size=71]  \\n  33: JIT compiled OrdinalIgnoreCaseCompare\", \"r:.ctor():this [Tier0, IL size=8, code size=3 6] \\n  34: JIT compiled OrdinalIgnoreCaseComparer:.ctor\", \"(IEqualityComparer`1):this [Tier0, IL  \\n7 CHAPTER 2 | JIT  \\n size=8, code size=39]  \\n  35: JIT compi\", \"led CastHelpers:ChkCastAny(long,Object):Object [Tier0, IL size=38, code \\nsize=115]  \\n  36: JIT compi\", \"led CastHelpers:TryGet(long,lon g):int [Tier0, IL size=129, code size=308]  \\n  37: JIT compiled Cast\", \"Helpers:TableData(ref):byref [Tier0, IL size=7, code size=31]  \\n  38: JIT compiled MemoryMarshal:Get\", \"ArrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24]  \\n  39: JIT compiled CastHelper s:Ke\", \"yToBucket(byref,long,long):int [Tier0, IL size=38, code \\nsize=87]  \\n  40: JIT compiled CastHelpers:H\", \"ashShift(byref):int [Tier0, IL size=3, code size=16]  \\n  41: JIT compiled BitOperations:RotateLeft(l\", \"ong,int):long [Tier0, IL size=17, code \\nsize=23]  \\n  42: JIT compiled CastHelpers:Element(byref,int)\", \":byref [Tier0, IL size=15, code size=33]  \\n  43: JIT compiled Volatile:Read(byref):int [Tier0, IL si\", \"ze=6, code size=16]  \\n  44: JIT compiled String:Ctor(long):String [Tier0, IL size=57, code size=155]\", \"  \\n  45: JIT compiled String:wcslen(long):int [Tier0, IL size=7, code size=31]  \\n  46: JIT compiled \", \"SpanHelpers:IndexOfNullCharacter(byref):int [Tier1, IL size=792, code \\nsize=388]  \\n  47: JIT compile\", \"d String:get_Length():int:this [Tier0, IL size=7, code size=17]  \\n  48: JIT compiled Buffer:Memmove(\", \"byref,byref,long) [Tier0, IL size=59, code size=102]  \\n  49: JIT compiled RuntimeHelpers:IsReference\", \"OrContainsReferences():bool [Tier0, IL size=2, \\ncode size=8]  \\n  50: JIT compiled Buffer:Memmove(byr\", \"ef,byref,long) [Tier0, IL size=480, code size= 678] \\n  51: JIT compiled Dictionary`2:Add(__Canon,__C\", \"anon):this [Tier0, IL size=11, code size=55]  \\n  52: JIT compiled Dictionary`2:TryInsert(__Canon,__C\", \"anon,ubyte):bool:this [Tier0, IL \\nsize=675, code size=2467]  \\n  53: JIT compiled OrdinalComparer:Get\", \"HashCode( String):int:this [Tier0, IL size=7, code \\nsize=37]  \\n  54: JIT compiled String:GetNonRando\", \"mizedHashCode():int:this [Tier0, IL size=110, code \\nsize=290]  \\n  55: JIT compiled BitOperations:Rot\", \"ateLeft(int,int):int [Tier0, IL size=17, code size=20]  \\n  56: JIT compile d Dictionary`2:GetBucket(\", \"int):byref:this [Tier0, IL size=29, code size=90]  \\n  57: JIT compiled HashHelpers:FastMod(int,int,l\", \"ong):int [Tier0, IL size=20, code size=70]  \\n  58: JIT compiled Type:get_IsValueType():bool:this [Ti\", \"er0, IL size=7, code size=39]  \\n  59: JIT compiled RuntimeType:IsValueTypeImpl():bool:this [Tier0, I\", \"L size=54, code \\nsize=158]  \\n  60: JIT compiled RuntimeType:GetNativeTypeHandle():TypeHandle:this [T\", \"ier0, IL size=12, \\ncode size=48]  \\n  61: JIT compiled TypeHandle:.ctor(long):this [Tier0, IL size=8 \", \", code size=25]  \\n  62: JIT compiled TypeHandle:get_IsTypeDesc():bool:this [Tier0, IL size=14, code \", \"size=38]  \\n  63: JIT compiled TypeHandle:AsMethodTable():long:this [Tier0, IL size=7, code size=17] \", \" \\n  64: JIT compiled MethodTable:get_IsValueType():bool:this [ Tier0, IL size=20, code \\nsize=32]  \\n \", \" 65: JIT compiled GC:KeepAlive(Object) [Tier0, IL size=1, code size=10]  \\n  66: JIT compiled Buffer:\", \"_Memmove(byref,byref,long) [Tier0, IL size=25, code size=279]  \\n  67: JIT compiled Environment:Initi\", \"alizeCommandLineArgs(long, int,long):ref [Tier0, IL \\nsize=75, code size=332]  \\n  68: JIT compiled En\", \"vironment:.cctor() [Tier0, IL size=11, code size=163]  \\n  69: JIT compiled StartupHookProvider:Proce\", \"ssStartupHooks() [Tier -0 switched to FullOpts, \\nIL size=365, code size=1053]  \\n  70: JIT co mpiled \", \"StartupHookProvider:get_IsSupported():bool [Tier0, IL size=18, code \\nsize=60]  \\n  71: JIT compiled A\", \"ppContext:TryGetSwitch(String,byref):bool [Tier0, IL size=97, code \\nsize=322]  \\n  72: JIT compiled A\", \"rgumentException:ThrowIfNullOrEmpty(String,String) [Tie r0, IL size=16, \\ncode size=53]  \\n  73: JIT c\", \"ompiled String:IsNullOrEmpty(String):bool [Tier0, IL size=15, code size=58]  \\n  74: JIT compiled App\", \"Context:GetData(String):Object [Tier0, IL size=64, code size=205]  \\n  75: JIT compiled ArgumentNullE\", \"xception:ThrowIfNul l(Object,String) [Tier0, IL size=10, \\ncode size=42]  \\n  76: JIT compiled Monitor\", \":Enter(Object,byref) [Tier0, IL size=17, code size=55]   \\n8 CHAPTER 2 | JIT  \\n   77: JIT compiled Di\", \"ctionary`2:TryGetValue(__Canon,byref):bool:this [Tier0, IL size=39, \\ncode size=97]  \\n  78: JIT compi\", \"led Di ctionary`2:FindValue(__Canon):byref:this [Tier0, IL size=391, code \\nsize=1466]  \\n  79: JIT co\", \"mpiled EventSource:.cctor() [Tier0, IL size=34, code size=80]  \\n  80: JIT compiled EventSource:Initi\", \"alizeIsSupported():bool [Tier0, IL size=18, code \\nsize=60]  \\n  81: JIT compiled RuntimeEventSource:.\", \"ctor():this [Tier0, IL size=55, code size=184]  \\n  82: JIT compiled \\nGuid:.ctor(int,short,short,ubyt\", \"e,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte):this [Tier0, IL \\nsize=86, code size=132]  \\n  83: JIT co\", \"mpiled EventSource:.ctor(Guid,Str ing):this [Tier0, IL size=11, code size=90]  \\n  84: JIT compiled E\", \"ventSource:.ctor(Guid,String,int,ref):this [Tier0, IL size=58, code \\nsize=187]  \\n  85: JIT compiled \", \"EventSource:get_IsSupported():bool [Tier0, IL size=6, code size=11]  \\n  86: JIT compiled TraceLog gi\", \"ngEventHandleTable:.ctor():this [Tier0, IL size=20, code \\nsize=67]  \\n  87: JIT compiled EventSource:\", \"ValidateSettings(int):int [Tier0, IL size=37, code size=147]  \\n  88: JIT compiled EventSource:Initia\", \"lize(Guid,String,ref):this [Tier0, IL size=418, code \\nsize=1584] \\n  89: JIT compiled Guid:op_Equalit\", \"y(Guid,Guid):bool [Tier0, IL size=10, code size=39]  \\n  90: JIT compiled Guid:EqualsCore(byref,byref\", \"):bool [Tier0, IL size=132, code size=171]  \\n  91: JIT compiled ActivityTracker:get_Instance():Activ\", \"ityTracker [Tier0, IL  size=6, code \\nsize=49]  \\n  92: JIT compiled ActivityTracker:.cctor() [Tier0, \", \"IL size=11, code size=71]  \\n  93: JIT compiled ActivityTracker:.ctor():this [Tier0, IL size=7, code \", \"size=31]  \\n  94: JIT compiled RuntimeEventSource:get_ProviderMetadata():ReadOnlySpan` 1:this [Tier0,\", \" IL \\nsize=13, code size=91]  \\n  95: JIT compiled ReadOnlySpan`1:.ctor(long,int):this [Tier0, IL size\", \"=51, code size=115]  \\n  96: JIT compiled RuntimeHelpers:IsReferenceOrContainsReferences():bool [Tier\", \"0, IL size=2, \\ncode size=8]  \\n  97: JIT compiled R eadOnlySpan`1:get_Length():int:this [Tier0, IL si\", \"ze=7, code size=17]  \\n  98: JIT compiled OverrideEventProvider:.ctor(EventSource,int):this [Tier0, I\", \"L size=22, \\ncode size=68]  \\n  99: JIT compiled EventProvider:.ctor(int):this [Tier0, IL size=46, cod\", \"e size=194]  \\n 100: JIT compiled EtwEventProvider:.ctor():this [Tier0, IL size=7, code size=31]  \\n 1\", \"01: JIT compiled EventProvider:Register(EventSource):this [Tier0, IL size=48, code \\nsize=186]  \\n 102\", \": JIT compiled MulticastDelegate:CtorClosed(Object,long):this [Tier0, IL si ze=23, code \\nsize=70]  \\n\", \" 103: JIT compiled EventProvider:EventRegister(EventSource,EtwEnableCallback):int:this \\n[Tier0, IL s\", \"ize=53, code size=154]  \\n 104: JIT compiled EventSource:get_Name():String:this [Tier0, IL size=7, co\", \"de size=18]  \\n 105: JIT compiled EventSo urce:get_Guid():Guid:this [Tier0, IL size=7, code size=41] \", \" \\n 106: JIT compiled \\nEtwEventProvider:System.Diagnostics.Tracing.IEventProvider.EventRegister(Event\", \"Source,EtwEna\\nbleCallback,long,byref):int:this [Tier0, IL size=19, code size=71]  \\n 107: JIT compile\", \"d A dvapi32:EventRegister(byref,EtwEnableCallback,long,byref):int [Tier0, \\nIL size=53, code size=374\", \"]  \\n 108: JIT compiled Marshal:GetFunctionPointerForDelegate(__Canon):long [Tier0, IL size=17, \\ncode\", \" size=54]  \\n 109: JIT compiled Marshal:GetFunctionPointerForDelega te(Delegate):long [Tier0, IL size\", \"=18, \\ncode size=53]  \\n 110: JIT compiled EventPipeEventProvider:.ctor():this [Tier0, IL size=18, cod\", \"e size=41]  \\n 111: JIT compiled EventListener:get_EventListenersLock():Object [Tier0, IL size=41, co\", \"de \\nsize=157]  \\n 112: JIT compi led List`1:.ctor(int):this [Tier0, IL size=47, code size=275]  \\n 113\", \": JIT compiled Interlocked:CompareExchange(byref,__Canon,__Canon):__Canon [Tier0, IL \\nsize=9, code s\", \"ize=50]  \\n 114: JIT compiled NativeRuntimeEventSource:.cctor() [Tier0, IL size=11, code size= 71] \\n \", \"115: JIT compiled NativeRuntimeEventSource:.ctor():this [Tier0, IL size=63, code size=184]   \\n9 CHAP\", \"TER 2 | JIT  \\n  116: JIT compiled \\nGuid:.ctor(int,ushort,ushort,ubyte,ubyte,ubyte,ubyte,ubyte,ubyte,\", \"ubyte,ubyte):this [Tier0, \\nIL size=88, code size=132]  \\n 117: JIT compiled Nati veRuntimeEventSource\", \":get_ProviderMetadata():ReadOnlySpan`1:this \\n[Tier0, IL size=13, code size=91]  \\n 118: JIT compiled \", \"\\nEventPipeEventProvider:System.Diagnostics.Tracing.IEventProvider.EventRegister(EventSource,\\nEtwEnab\", \"leCallback,long,byref):int:this [Tier0, I L size=44, code size=118]  \\n 119: JIT compiled EventPipeIn\", \"ternal:CreateProvider(String,EtwEnableCallback):long [Tier0, \\nIL size=43, code size=320]  \\n 120: JIT\", \" compiled Utf16StringMarshaller:GetPinnableReference(String):byref [Tier0, IL \\nsize=13, code size=50\", \"]  \\n 121: JIT compiled String:GetPinnableReference():byref:this [Tier0, IL size=7, code \\nsize=24]  \\n\", \" 122: JIT compiled EventListener:AddEventSource(EventSource) [Tier0, IL size=175, code \\nsize=560]  \\n\", \" 123: JIT compiled List`1:get_Count():int:this [Tier0, IL size=7, co de size=17]  \\n 124: JIT compile\", \"d WeakReference`1:.ctor(__Canon):this [Tier0, IL size=9, code size=42]  \\n 125: JIT compiled WeakRefe\", \"rence`1:.ctor(__Canon,bool):this [Tier0, IL size=15, code \\nsize=60]  \\n 126: JIT compiled List`1:Add(\", \"__Canon):this [Tier0, IL size=60 , code size=124]  \\n 127: JIT compiled String:op_Inequality(String,S\", \"tring):bool [Tier0, IL size=11, code \\nsize=46]  \\n 128: JIT compiled String:Equals(String,String):boo\", \"l [Tier0, IL size=36, code size=114]  \\n 129: JIT compiled ReadOnlySpan`1:GetPinnableReference(): byr\", \"ef:this [Tier0, IL size=23, \\ncode size=57]  \\n 130: JIT compiled EventProvider:SetInformation(int,lon\", \"g,int):int:this [Tier0, IL size=38, \\ncode size=131]  \\n 131: JIT compiled ILStubClass:IL_STUB_PInvoke\", \"(long,int,long,int):int [FullOpts, IL \\nsize=62, code size=17 0] \\n 132: JIT compiled Program:Main() [\", \"Tier0, IL size=11, code size=36]  \\n 133: JIT compiled Console:WriteLine(String) [Tier0, IL size=12, \", \"code size=59]  \\n 134: JIT compiled Console:get_Out():TextWriter [Tier0, IL size=20, code size=113]  \", \"\\n 135: JIT compiled Cons ole:.cctor() [Tier0, IL size=11, code size=71]  \\n 136: JIT compiled Volatil\", \"e:Read(byref):__Canon [Tier0, IL size=6, code size=21]  \\n 137: JIT compiled Console:<get_Out>g__Ensu\", \"reInitialized|26_0():TextWriter [Tier0, IL \\nsize=63, code size=209]  \\n 138: JIT compiled  ConsolePal\", \":OpenStandardOutput():Stream [Tier0, IL size=34, code \\nsize=130]  \\n 139: JIT compiled Console:get_Ou\", \"tputEncoding():Encoding [Tier0, IL size=72, code size=237]  \\n 140: JIT compiled ConsolePal:get_Outpu\", \"tEncoding():Encoding [Tier0, IL size=11, code \\nsize=200] \\n 141: JIT compiled NativeLibrary:LoadLibra\", \"ryCallbackStub(String,Assembly,bool,int):long \\n[Tier0, IL size=63, code size=280]  \\n 142: JIT compil\", \"ed EncodingHelper:GetSupportedConsoleEncoding(int):Encoding [Tier0, IL \\nsize=53, code size=186]  \\n 1\", \"43: JIT compil ed Encoding:GetEncoding(int):Encoding [Tier0, IL size=340, code size=1025]  \\n 144: JI\", \"T compiled EncodingProvider:GetEncodingFromProvider(int):Encoding [Tier0, IL \\nsize=51, code size=232\", \"]  \\n 145: JIT compiled Encoding:FilterDisallowedEncodings(Encoding):Encoding  [Tier0, IL \\nsize=29, c\", \"ode size=84]  \\n 146: JIT compiled LocalAppContextSwitches:get_EnableUnsafeUTF7Encoding():bool [Tier0\", \", IL \\nsize=16, code size=46]  \\n 147: JIT compiled LocalAppContextSwitches:GetCachedSwitchValue(Strin\", \"g,byref):bool [Tier0, \\nIL size=22, code size=76]  \\n 148: JIT compiled LocalAppContextSwitches:GetCac\", \"hedSwitchValueInternal(String,byref):bool \\n[Tier0, IL size=46, code size=168]  \\n 149: JIT compiled L\", \"ocalAppContextSwitches:GetSwitchDefaultValue(String):bool [Tier0, IL \\nsize=32, code size=98]  \\n 150:\", \" JIT  compiled String:op_Equality(String,String):bool [Tier0, IL size=8, code size=39]  \\n 151: JIT c\", \"ompiled Encoding:get_Default():Encoding [Tier0, IL size=6, code size=49]   \\n10 CHAPTER 2 | JIT  \\n  1\", \"52: JIT compiled Encoding:.cctor() [Tier0, IL size=12, code size=73]  \\n 153: JIT compiled UTF8Encodi\", \"ngSealed:.ctor(bool):this [Tier0, IL size=8, code size=40]  \\n 154: JIT compiled UTF8Encoding:.ctor(b\", \"ool):this [Tier0, IL size=14, code size=43]  \\n 155: JIT compiled UTF8Encoding:.ctor():this [Tier0, I\", \"L size=12, code size=36]  \\n 156: JIT compiled Encodi ng:.ctor(int):this [Tier0, IL size=42, code siz\", \"e=152]  \\n 157: JIT compiled UTF8Encoding:SetDefaultFallbacks():this [Tier0, IL size=64, code \\nsize=2\", \"12]  \\n 158: JIT compiled EncoderReplacementFallback:.ctor(String):this [Tier0, IL size=110, code \\nsi\", \"ze=360]  \\n 159: JIT compiled EncoderFallback:.ctor():this [Tier0, IL size=7, code size=31]  \\n 160: J\", \"IT compiled String:get_Chars(int):ushort:this [Tier0, IL size=29, code size=61]  \\n 161: JIT compiled\", \" Char:IsSurrogate(ushort):bool [Tier0, IL size=17, code size=43]  \\n 162: JIT co mpiled Char:IsBetwee\", \"n(ushort,ushort,ushort):bool [Tier0, IL size=12, code \\nsize=52]  \\n 163: JIT compiled DecoderReplacem\", \"entFallback:.ctor(String):this [Tier0, IL size=110, code \\nsize=360]  \\n 164: JIT compiled DecoderFall\", \"back:.ctor():this [Tier0, IL size=7, code size=31]  \\n 165: JIT compiled Encoding:get_CodePage():int:\", \"this [Tier0, IL size=7, code size=17]  \\n 166: JIT compiled Encoding:get_UTF8():Encoding [Tier0, IL s\", \"ize=6, code size=49]  \\n 167: JIT compiled UTF8Encoding:.cctor() [Tier0, IL size=12, code size=76]  \\n\", \" 168: JIT compiled Volatile:Write(byref,__Canon) [Tier0, IL size=6, code size=32]  \\n 169: JIT compil\", \"ed ConsolePal:GetStandardFile(int,int,bool):Stream [Tier0, IL size=50, code \\nsize=183]  \\n 170: JIT c\", \"ompiled ConsolePal:get_InvalidHandleValue():long [Tier0, IL size=7,  code \\nsize=41]  \\n 171: JIT comp\", \"iled IntPtr:.ctor(int):this [Tier0, IL size=9, code size=25]  \\n 172: JIT compiled ConsolePal:Console\", \"HandleIsWritable(long):bool [Tier0, IL size=26, code \\nsize=68]  \\n 173: JIT compiled Kernel32:WriteFi\", \"le(long,long,int,byref,long):int  [Tier0, IL size=46, \\ncode size=294]  \\n 174: JIT compiled Marshal:S\", \"etLastSystemError(int) [Tier0, IL size=7, code size=40]  \\n 175: JIT compiled Marshal:GetLastSystemEr\", \"ror():int [Tier0, IL size=6, code size=34]  \\n 176: JIT compiled WindowsConsoleStream:.ctor(long, int\", \",bool):this [Tier0, IL size=37, code \\nsize=90]  \\n 177: JIT compiled ConsoleStream:.ctor(int):this [T\", \"ier0, IL size=31, code size=71]  \\n 178: JIT compiled Stream:.ctor():this [Tier0, IL size=7, code siz\", \"e=31]  \\n 179: JIT compiled MarshalByRefObject:.ctor():this [ Tier0, IL size=7, code size=31]  \\n 180:\", \" JIT compiled Kernel32:GetFileType(long):int [Tier0, IL size=27, code size=217]  \\n 181: JIT compiled\", \" Console:CreateOutputWriter(Stream):TextWriter [Tier0, IL size=50, code \\nsize=230]  \\n 182: JIT compi\", \"led Stream:.cctor() [Tie r0, IL size=11, code size=71]  \\n 183: JIT compiled NullStream:.ctor():this \", \"[Tier0, IL size=7, code size=31]  \\n 184: JIT compiled EncodingExtensions:RemovePreamble(Encoding):En\", \"coding [Tier0, IL size=25, \\ncode size=118]  \\n 185: JIT compiled UTF8EncodingSealed:get_P reamble():R\", \"eadOnlySpan`1:this [Tier0, IL \\nsize=24, code size=99]  \\n 186: JIT compiled UTF8Encoding:get_Preamble\", \"Span():ReadOnlySpan`1 [Tier0, IL size=12, code \\nsize=87]  \\n 187: JIT compiled ConsoleEncoding:.ctor(\", \"Encoding):this [Tier0, IL size=14, code size=52]  \\n 188: JIT compiled Encoding:.ctor():this [Tier0, \", \"IL size=8, code size=33]  \\n 189: JIT compiled Encoding:SetDefaultFallbacks():this [Tier0, IL size=23\", \", code size=65]  \\n 190: JIT compiled EncoderFallback:get_ReplacementFallback():EncoderFallback [Tier\", \"0, IL \\nsize=6, code size=49]  \\n 191: JIT compiled EncoderReplacementFallback:.cctor() [Tier0, IL siz\", \"e=11, code size=71]  \\n 192: JIT compiled EncoderReplacementFallback:.ctor():this [Tier0, IL size=12,\", \" code \\nsize=44]  \\n 193: JIT compiled DecoderFallback:get_ReplacementFallback( ):DecoderFallback [Tie\", \"r0, IL \\nsize=6, code size=49]  \\n 194: JIT compiled DecoderReplacementFallback:.cctor() [Tier0, IL si\", \"ze=11, code size=71]  \\n 195: JIT compiled DecoderReplacementFallback:.ctor():this [Tier0, IL size=12\", \", code \\nsize=44]   \\n11 CHAPTER 2 | JIT  \\n  196: JIT compiled Stre amWriter:.ctor(Stream,Encoding,int\", \",bool):this [Tier0, IL size=201, \\ncode size=564]  \\n 197: JIT compiled Task:get_CompletedTask():Task \", \"[Tier0, IL size=6, code size=49]  \\n 198: JIT compiled Task:.cctor() [Tier0, IL size=76, code size=31\", \"6]  \\n 199: JIT compiled TaskF actory:.ctor():this [Tier0, IL size=7, code size=31]  \\n 200: JIT compi\", \"led Task`1:.ctor(bool,VoidTaskResult,int,CancellationToken):this [Tier0, IL \\nsize=21, code size=75] \", \" \\n 201: JIT compiled Task:.ctor(bool,int,CancellationToken):this [Tier0, IL size=70, code \\nsize=181]\", \"  \\n 202: JIT compiled <>c:.cctor() [Tier0, IL size=11, code size=71]  \\n 203: JIT compiled <>c:.ctor(\", \"):this [Tier0, IL size=7, code size=31]  \\n 204: JIT compiled TextWriter:.ctor(IFormatProvider):this \", \"[Tier0, IL size=36, code \\nsize=124]  \\n 205: JIT compiled TextWriter:.cctor() [Tier0, IL size=26, cod\", \"e size=108]  \\n 206: JIT compiled NullTextWriter:.ctor():this [Tier0, IL size=7, code size=31]  \\n 207\", \": JIT compiled TextWriter:.ctor():this [Tier0, IL size=29, code size=103]  \\n 208: JIT compiled Strin\", \"g:ToCharArray():ref :this [Tier0, IL size=52, code size=173]  \\n 209: JIT compiled MemoryMarshal:GetA\", \"rrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24]  \\n 210: JIT compiled ConsoleStream:ge\", \"t_CanWrite():bool:this [Tier0, IL size=7, code size=18]  \\n 211: JIT compiled Consol eEncoding:GetEnc\", \"oder():Encoder:this [Tier0, IL size=12, code \\nsize=57]  \\n 212: JIT compiled UTF8Encoding:GetEncoder(\", \"):Encoder:this [Tier0, IL size=7, code size=63]  \\n 213: JIT compiled EncoderNLS:.ctor(Encoding):this\", \" [Tier0, IL size=37, code size=102]  \\n 214: JIT  compiled Encoder:.ctor():this [Tier0, IL size=7, co\", \"de size=31]  \\n 215: JIT compiled Encoding:get_EncoderFallback():EncoderFallback:this [Tier0, IL size\", \"=7, \\ncode size=18]  \\n 216: JIT compiled EncoderNLS:Reset():this [Tier0, IL size=24, code size=92]  \\n\", \" 217: JIT c ompiled ConsoleStream:get_CanSeek():bool:this [Tier0, IL size=2, code size=12]  \\n 218: J\", \"IT compiled StreamWriter:set_AutoFlush(bool):this [Tier0, IL size=25, code size=72]  \\n 219: JIT comp\", \"iled StreamWriter:CheckAsyncTaskInProgress():this [Tier0, IL size=19, co de \\nsize=47]  \\n 220: JIT co\", \"mpiled Task:get_IsCompleted():bool:this [Tier0, IL size=16, code size=40]  \\n 221: JIT compiled Task:\", \"IsCompletedMethod(int):bool [Tier0, IL size=11, code size=25]  \\n 222: JIT compiled StreamWriter:Flus\", \"h(bool,bool):this [Tier0, IL size=27 2, code size=1127]  \\n 223: JIT compiled StreamWriter:ThrowIfDis\", \"posed():this [Tier0, IL size=15, code size=43]  \\n 224: JIT compiled Encoding:get_Preamble():ReadOnly\", \"Span`1:this [Tier0, IL size=12, code \\nsize=70]  \\n 225: JIT compiled ConsoleEncoding:GetPreamble():re\", \" f:this [Tier0, IL size=6, code size=27]  \\n 226: JIT compiled Array:Empty():ref [Tier0, IL size=6, c\", \"ode size=49]  \\n 227: JIT compiled EmptyArray`1:.cctor() [Tier0, IL size=12, code size=52]  \\n 228: JI\", \"T compiled ReadOnlySpan`1:op_Implicit(ref):ReadOnlySpan`1 [Tier 0, IL size=7, code \\nsize=79]  \\n 229:\", \" JIT compiled ReadOnlySpan`1:.ctor(ref):this [Tier0, IL size=33, code size=81]  \\n 230: JIT compiled \", \"MemoryMarshal:GetArrayDataReference(ref):byref [Tier0, IL size=7, code \\nsize=24]  \\n 231: JIT compile\", \"d ConsoleEncoding:GetMaxByte Count(int):int:this [Tier0, IL size=13, code \\nsize=63]  \\n 232: JIT comp\", \"iled UTF8EncodingSealed:GetMaxByteCount(int):int:this [Tier0, IL size=20, \\ncode size=50]  \\n 233: JIT\", \" compiled Span`1:.ctor(long,int):this [Tier0, IL size=51, code size=115]  \\n 234: JIT compiled  ReadO\", \"nlySpan`1:.ctor(ref,int,int):this [Tier0, IL size=65, code \\nsize=147]  \\n 235: JIT compiled Encoder:G\", \"etBytes(ReadOnlySpan`1,Span`1,bool):int:this [Tier0, IL \\nsize=44, code size=234]  \\n 236: JIT compile\", \"d MemoryMarshal:GetNonNullPinnableReference(ReadOnlySpan `1):byref [Tier0, \\nIL size=30, code size=54\", \"]  \\n 237: JIT compiled ReadOnlySpan`1:get_Length():int:this [Tier0, IL size=7, code size=17]  \\n 238:\", \" JIT compiled MemoryMarshal:GetNonNullPinnableReference(Span`1):byref [Tier0, IL \\nsize=30, code size\", \"=54]  \\n 239: JIT comp iled Span`1:get_Length():int:this [Tier0, IL size=7, code size=17]   \\n12 CHAPT\", \"ER 2 | JIT  \\n  240: JIT compiled EncoderNLS:GetBytes(long,int,long,int,bool):int:this [Tier0, IL siz\", \"e=92, \\ncode size=279]  \\n 241: JIT compiled ArgumentNullException:ThrowIfNull(long,String) [Tier0, IL\", \" size= 12, code \\nsize=45]  \\n 242: JIT compiled Encoding:GetBytes(long,int,long,int,EncoderNLS):int:t\", \"his [Tier0, IL \\nsize=57, code size=187]  \\n 243: JIT compiled EncoderNLS:get_HasLeftoverData():bool:t\", \"his [Tier0, IL size=35, code \\nsize=105]  \\n 244: JIT compiled UTF8Encodin g:GetBytesFast(long,int,lon\", \"g,int,byref):int:this [Tier0, IL \\nsize=33, code size=119]  \\n 245: JIT compiled Utf8Utility:Transcode\", \"ToUtf8(long,int,long,int,byref,byref):int [Tier0, \\nIL size=1446, code size=3208]  \\n 246: JIT compile\", \"d Math:Min(int,int):int [Tier0, IL size=8, code size=28]  \\n 247: JIT compiled ASCIIUtility:NarrowUtf\", \"16ToAscii(long,long,long):long [Tier0, IL \\nsize=490, code size=1187]  \\n 248: JIT compiled WindowsCon\", \"soleStream:Flush():this [Tier0, IL size=26, code size=56]  \\n 249: JIT compiled ConsoleStream:Flush (\", \"):this [Tier0, IL size=1, code size=10]  \\n 250: JIT compiled TextWriter:Synchronized(TextWriter):Tex\", \"tWriter [Tier0, IL size=28, code \\nsize=121]  \\n 251: JIT compiled SyncTextWriter:.ctor(TextWriter):th\", \"is [Tier0, IL size=14, code size=52]  \\n 252: JIT compiled Sync TextWriter:WriteLine(String):this [Ti\", \"er0, IL size=13, code size=140]  \\n 253: JIT compiled StreamWriter:WriteLine(String):this [Tier0, IL \", \"size=20, code size=110]  \\n 254: JIT compiled String:op_Implicit(String):ReadOnlySpan`1 [Tier0, IL si\", \"ze=31, code \\nsize=171]  \\n 255: JIT compiled String:GetRawStringData():byref:this [Tier0, IL size=7, \", \"code size=24]  \\n 256: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, code siz\", \"e=39]  \\n 257: JIT compiled StreamWriter:WriteSpan(ReadOnlySpan`1,bool):this [Tier0, IL  size=368, \\nc\", \"ode size=1036]  \\n 258: JIT compiled MemoryMarshal:GetReference(ReadOnlySpan`1):byref [Tier0, IL size\", \"=8, code \\nsize=17]  \\n 259: JIT compiled Buffer:MemoryCopy(long,long,long,long) [Tier0, IL size=21, c\", \"ode size=83]  \\n 260: JIT compiled Unsafe:ReadUnalig ned(long):long [Tier0, IL size=10, code size=17]\", \"  \\n 261: JIT compiled ASCIIUtility:AllCharsInUInt64AreAscii(long):bool [Tier0, IL size=16, \\ncode siz\", \"e=38]  \\n 262: JIT compiled ASCIIUtility:NarrowFourUtf16CharsToAsciiAndWriteToBuffer(byref,long) \\n[Ti\", \"er0, IL size=1 07, code size=171]  \\n 263: JIT compiled Unsafe:WriteUnaligned(byref,int) [Tier0, IL s\", \"ize=11, code size=22]  \\n 264: JIT compiled Unsafe:ReadUnaligned(long):int [Tier0, IL size=10, code s\", \"ize=16]  \\n 265: JIT compiled ASCIIUtility:AllCharsInUInt32AreAscii(int):bool [Tier0, IL size=11, cod\", \"e \\nsize=25]  \\n 266: JIT compiled ASCIIUtility:NarrowTwoUtf16CharsToAsciiAndWriteToBuffer(byref,int) \", \"\\n[Tier0, IL size=24, code size=35]  \\n 267: JIT compiled Span`1:Slice(int,int):Span`1:this [Tier0, IL\", \" size=39, code size=135]  \\n 268: JIT comp iled Span`1:.ctor(byref,int):this [Tier0, IL size=15, code\", \" size=39]  \\n 269: JIT compiled Span`1:op_Implicit(Span`1):ReadOnlySpan`1 [Tier0, IL size=19, code \\ns\", \"ize=90]  \\n 270: JIT compiled ReadOnlySpan`1:.ctor(byref,int):this [Tier0, IL size=15, code size=39] \", \" \\n 271: JIT compiled WindowsConsoleStream:Write(ReadOnlySpan`1):this [Tier0, IL size=35, code \\nsize=\", \"149]  \\n 272: JIT compiled WindowsConsoleStream:WriteFileNative(long,ReadOnlySpan`1,bool):int \\n[Tier0\", \", IL size=107, code size=272]  \\n 273: JIT compiled ReadOnlySpan`1:g et_IsEmpty():bool:this [Tier0, I\", \"L size=10, code size=24]  \\nHello, world!  \\n 274: JIT compiled AppContext:OnProcessExit() [Tier0, IL \", \"size=43, code size=161]  \\n 275: JIT compiled AssemblyLoadContext:OnProcessExit() [Tier0, IL size=101\", \", code size=442]  \\n 276: JIT com piled EventListener:DisposeOnShutdown() [Tier0, IL size=150, code s\", \"ize=618]  \\n 277: JIT compiled List`1:.ctor():this [Tier0, IL size=18, code size=133]  \\n 278: JIT com\", \"piled List`1:.cctor() [Tier0, IL size=12, code size=129]  \\n 279: JIT compiled List`1:GetEnumera tor(\", \"):Enumerator:this [Tier0, IL size=7, code size=162]  \\n 280: JIT compiled Enumerator:.ctor(List`1):th\", \"is [Tier0, IL size=39, code size=64]  \\n 281: JIT compiled Enumerator:MoveNext():bool:this [Tier0, IL\", \" size=81, code size=159]   \\n13 CHAPTER 2 | JIT  \\n  282: JIT compiled Enumerator:g et_Current():__Can\", \"on:this [Tier0, IL size=7, code size=22]  \\n 283: JIT compiled WeakReference`1:TryGetTarget(byref):bo\", \"ol:this [Tier0, IL size=24, code \\nsize=66]  \\n 284: JIT compiled List`1:AddWithResize(__Canon):this [\", \"Tier0, IL size=39, code size=85]  \\n 285: JIT compiled List`1:Grow(int):this [Tier0, IL size=53, code\", \" size=121]  \\n 286: JIT compiled List`1:set_Capacity(int):this [Tier0, IL size=86, code size=342]  \\n \", \"287: JIT compiled CastHelpers:StelemRef_Helper(byref,long,Object) [Tier0, IL size=34, code \\nsize=104\", \"]  \\n 288: JIT compiled CastHelpers:StelemRef_Helper_NoCacheLookup(byref,long,Object) [Tier0, IL \\nsiz\", \"e=26, code size=111]  \\n 289: JIT compiled Enumerator:MoveNextRare():bool:this [Tier0, IL size=57, co\", \"de size=80]  \\n 290: JIT compiled Enumerator:Dispose():this [Tier0, IL  size=1, code size=14]  \\n 291:\", \" JIT compiled EventSource:Dispose():this [Tier0, IL size=14, code size=54]  \\n 292: JIT compiled Even\", \"tSource:Dispose(bool):this [Tier0, IL size=124, code size=236]  \\n 293: JIT compiled EventProvider:Di\", \"spose():this [Tier0, IL size=14,  code size=54]  \\n 294: JIT compiled EventProvider:Dispose(bool):thi\", \"s [Tier0, IL size=90, code size=230]  \\n 295: JIT compiled EventProvider:EventUnregister(long):this [\", \"Tier0, IL size=14, code \\nsize=50]  \\n 296: JIT compiled \\nEtwEventProvider:System.Diagnostics.Traci ng\", \".IEventProvider.EventUnregister(long):int:this \\n[Tier0, IL size=7, code size=181]  \\n 297: JIT compil\", \"ed GC:SuppressFinalize(Object) [Tier0, IL size=18, code size=53]  \\n 298: JIT compiled \\nEventPipeEven\", \"tProvider:System.Diagnostics.Tracing.IEventProvider.EventUnr egister(long):int:\\nthis [Tier0, IL size\", \"=13, code size=187]  \\nWith that out of the way, let\\u2019s move on to actual performance improvements, st\", \"arting with on -stack \\nreplacement.  \\nOn-Stack Replacement  \\nOn-stack replacement (OSR) is one of th\", \"e coolest features to hit the JIT in .NET 7. But to really \\nunderstand OSR, we first need to underst\", \"and tiered compilation, so a quick recap\\u2026  \\nOne of the issues a managed environment with a JIT compi\", \"ler has to deal with is tradeoffs between \\nstartup and throughput. Historically, the j ob of an opti\", \"mizing compiler is to, well, optimize, in order to \\nenable the best possible throughput of the appli\", \"cation or service once running. But such optimization \\ntakes analysis, takes time, and performing al\", \"l of that work then leads to increased startu p time, as all \\nof the code on the startup path (e.g. \", \" all of the code that needs to be run before a web server can \\nserve the first request) needs to be \", \"compiled. So a JIT compiler needs to make tradeoffs: better \\nthroughput at the expense of longer sta\", \"rtup t ime, or better startup time at the expense of decreased \\nthroughput. For some kinds of apps a\", \"nd services, the tradeoff is an easy call, e.g.  if your service starts \\nup once and then runs for d\", \"ays, several extra seconds of startup time doesn\\u2019t matter, or if y ou\\u2019re a \\nconsole application that\", \"\\u2019s going to do a quick computation and exit, startup time is all that matters. \\nBut how can the JIT \", \"know which scenario it\\u2019s in, and do we really want every developer having to \\nknow about these kinds\", \" of settings and tradeoffs  and configure every one of their applications \\naccordingly? One answer t\", \"o this has been ahead -of-time compilation, which has taken various forms \\nin .NET. For example, all\", \" of the core libraries are \\u201ccrossgen\\u201d\\u2019d, meaning they\\u2019ve been run through a \\ntool that produces the \", \"previously mentioned R2R format, yielding binaries that contain assembly code \\nthat needs only minor\", \" tweaks to actually execute; not every method can have code generated for it, \\nbut enough that it si\", \"gnificantly reduces startup time. Of course, such approaches have their own \\ndownsides, e.g.  one of\", \" the promises of a JIT compiler is it can take advantage of knowledge of the \\ncurrent machine / proc\", \"ess in order to best optimize, so for example the R2R images have to assume a  \\n14 CHAPTER 2 | JIT  \", \"\\n certain baseline instructi on set (e.g.  what vectorizing instructions are available) whereas the \", \"JIT can see \\nwhat\\u2019s actually available and use the best. \\u201cTiered compilation\\u201d provides another answe\", \"r, one that\\u2019s \\nusable with or without these other ahead -of-time (AOT) compilation soluti ons. \\nTier\", \"ed compilation enables the JIT to have its proverbial cake and eat it, too. The idea is simple: allo\", \"w \\nthe JIT to compile the same code multiple times. The first time, the JIT can use as a few optimiz\", \"ations \\nas make sense (a handful of optimizations  can actually make the JIT\\u2019s own throughput faster\", \", so those \\nstill make sense to apply), producing fairly unoptimized assembly code but doing so real\", \"ly quickly. \\nAnd when it does so, it can add some instrumentation into the assembly to track how oft\", \"en the \\nmethods are called. As it turns out, many functions used on a startup path are invoked once \", \"or maybe \\nonly a handful of times, and it would take more time to optimize them than it does to just\", \" execute \\nthem unoptimized. Then, when the method\\u2019s instrumentation  triggers some threshold, for ex\", \"ample a \\nmethod having been executed 30 times, a work item gets queued to recompile that method, but\", \" this \\ntime with all the optimizations the JIT can throw at it. This is lovingly referred to as \\u201ctie\", \"ring up.\\u201d Once \\nthat recomp ilation has completed, call sites to the method are patched with the add\", \"ress of the newly \\nhighly optimized assembly code, and future invocations will then take the fast pa\", \"th. So, we get faster \\nstartup and faster sustained throughput. At least, that\\u2019s the h ope. \\nA probl\", \"em, however, is methods that don\\u2019t fit this mold. While it\\u2019s certainly the case that many \\nperforman\", \"ce -sensitive methods are relatively quick and executed many, many, many times, there\\u2019s \\nalso a larg\", \"e number of performance -sensitive methods that are executed just a handful of times, or \\nmaybe even\", \" only once, but that take a very long time to execute, maybe even the duration of the \\nwhole process\", \": methods with loops. As a result, by default tiered compilation hasn\\u2019t applied to loops, \\nthough it\", \" can be  enabled by setting the DOTNET_TC_QuickJitForLoops  environment variable to 1. We \\ncan see t\", \"he effect of this by trying this simple console app with .NET 6. With the default settings, run \\nthi\", \"s app:  \\nclass Program \\n{ \\n    static void Main() \\n    { \\n        var sw = new System.Diagnostics .S\", \"topwatch (); \\n        while (true) \\n        { \\n            sw.Restart(); \\n            for (int trial\", \" = 0; trial < 10_000; trial++)  \\n            { \\n                int count = 0; \\n                for \", \"(int i = 0; i < char.MaxValue ; i++) \\n                    if (IsAsciiDigit ((char)i)) \\n             \", \"           count++;  \\n            } \\n            sw.Stop(); \\n            Console. WriteLine (sw.Elap\", \"sed); \\n        } \\n \\n        static bool IsAsciiDigit (char c) => (uint)(c - '0') <= 9; \\n    } \\n} \\nI \", \"get numbe rs printed out like:   \\n15 CHAPTER 2 | JIT  \\n 00:00:00.5734352  \\n00:00:00.5526667  \\n00:00:\", \"00.5675267  \\n00:00:00.5588724  \\n00:00:00.5616028  \\nNow, try setting DOTNET_TC_QuickJitForLoops  to 1\", \". When I then run it again, I get numbers like this:  \\n00:00:01.2841397  \\n00:00:01.2693485  \\n00:00:0\", \"1.275564 6 \\n00:00:01.2656678  \\n00:00:01.2679925  \\nIn other words, with DOTNET_TC_QuickJitForLoops  e\", \"nabled, it\\u2019s taking 2.5x as long as without (the \\ndefault in .NET 6). That\\u2019s because this main funct\", \"ion never gets optimizations applied to it. By setting \\nDOTNET_TC_QuickJi tForLoops  to 1, we\\u2019re say\", \"ing \\u201cJIT, please apply tiering to methods with loops as \\nwell,\\u201d but this method with a loop is only \", \"ever invoked once, so for the duration of the process it ends \\nup remaining at \\u201ctier -0,\\u201d aka unopti\", \"mized. Now, let\\u2019s try the same thing with .NET 7 . Regardless of \\nwhether that environment variable \", \"is set, I again get numbers like this:  \\n00:00:00.5528889  \\n00:00:00.5562563  \\n00:00:00.5622086  \\n00\", \":00:00.5668220  \\n00:00:00.5589112  \\nbut importantly, this method was still participating in tiering.\", \" In fact, we can g et confirmation of that \\nby using the aforementioned DOTNET_JitDisasmSummary=1  e\", \"nvironment variable. When I set that and \\nrun again, I see these lines in the output:  \\n   4: JIT co\", \"mpiled Program:Main() [Tier0, IL size=83, code size=319]  \\n... \\n   6: JIT compiled Program:Main() [T\", \"ier1 -OSR @0x27, IL size=83, code size=380]  \\nhighlighting that Main  was indeed compiled twice. How\", \" is that possible? On -stack replacement.  \\nThe idea behind on -stack replacement is a method can be\", \" replaced not just between invocations but \\neven  while it\\u2019s executing, while it\\u2019s \\u201con the stack.\\u201d I\", \"n addition to the tier -0 code being instrumented \\nfor call counts, loops are also instrumented for \", \"iteration counts. When the iterations surpass a certain \\nlimit, the JIT compiles a new highly optimi\", \"zed vers ion of that method, transfers all the local/register \\nstate from the current invocation to \", \"the new invocation, and then jumps to the appropriate location in \\nthe new method. We can see this i\", \"n action by using the previously discussed DOTNET_JitDisasm  \\nenviron ment variable. Set that to Pro\", \"gram:*  in order to see the assembly code generated for all of the \\nmethods in the Program  class, a\", \"nd then run the app again. You should see output like the following:  \\n; Assembly listing for method\", \" Program:Main()  \\n; Emitting BLEN DED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compilation  \\n; \", \"MinOpts code  \\n; rbp based frame  \\n; partially interruptible  \\n \\nG_M000_IG01:                ;; offs\", \"et=0000H  \\n       55                   push     rbp   \\n16 CHAPTER 2 | JIT  \\n        4881EC80000000  \", \"     sub      rsp, 128  \\n       488DAC2480000000     lea      rbp, [rsp+80H]  \\n       C5D857E4      \", \"       vxorps   xmm4, xmm4  \\n       C5F97F65B0           vmovdqa  xmmword ptr [rbp -50H], xmm4  \\n   \", \"    33C0                 xor      eax, eax  \\n       488945C0             mov      qword ptr [r bp-40\", \"H], rax  \\n \\nG_M000_IG02:                ;; offset=001FH  \\n       48B9002F0B50FC7F0000 mov      rcx, \", \"0x7FFC500B2F00  \\n       E8721FB25F           call     CORINFO_HELP_NEWSFAST  \\n       488945B0       \", \"      mov      gword ptr [rbp -50H], rax  \\n       488B4DB0             mov      rcx, gword ptr [rbp \", \"-50H] \\n       FF1544C70D00         call     [Stopwatch:.ctor():this]  \\n       488B4DB0             m\", \"ov      rcx, gword ptr [rbp -50H] \\n       48894DC0             mov      gword ptr [rbp -40H], rcx  \\n\", \"       C745A8E8030000       mov      dword ptr [rbp -58H], 0x3E8  \\n \\nG_M000_IG03:                ;; \", \"offset=004BH  \\n       8B4DA8               mov      ecx, dword ptr [rbp -58H] \\n       FFC9          \", \"       dec      ecx  \\n       894DA8               mov      dword ptr [rbp -58H], ecx  \\n       837DA8\", \"00             cmp      dword ptr [rbp -58H], 0 \\n       7F0E                 jg       SHORT G_M000_I\", \"G05  \\n \\nG_M000_IG04:                ;; offset=0059H  \\n       488D4DA8             lea      rcx, [rbp\", \" -58H] \\n       BA06000000           mov      edx, 6  \\n       E8B985AB5F           call     CORINFO_H\", \"ELP_PATCHPOINT  \\n \\nG_M000_IG05:                ;; offset=0067H  \\n       488B4DC0             mov    \", \"  rcx, gword ptr [rbp -40H] \\n       3909                 cmp      dword ptr [rcx], ecx  \\n       FF15\", \"85C70D00         call     [St opwatch:Restart():this]  \\n       33C9                 xor      ecx, ec\", \"x  \\n       894DBC               mov      dword ptr [rbp -44H], ecx  \\n       33C9                 xor\", \"      ecx, ecx  \\n       894DB8               mov      dword ptr [rbp -48H], ecx  \\n       EB20       \", \"          jmp      SHORT G_M000_IG08  \\n \\nG_M000_IG06:                ;; offset=007FH  \\n       8B4DB8\", \"               mov      ecx, dword ptr [rbp -48H] \\n       0FB7C9               movzx    rcx, cx  \\n  \", \"     FF152DD40B00         call     [Program:<Main>g__IsAsciiDig it|0_0(ushort):bool]  \\n       85C0  \", \"               test     eax, eax  \\n       7408                 je       SHORT G_M000_IG07  \\n       8\", \"B4DBC               mov      ecx, dword ptr [rbp -44H] \\n       FFC1                 inc      ecx  \\n \", \"      894DBC               mov       dword ptr [rbp -44H], ecx  \\n \\nG_M000_IG07:                ;; of\", \"fset=0097H  \\n       8B4DB8               mov      ecx, dword ptr [rbp -48H] \\n       FFC1            \", \"     inc      ecx  \\n       894DB8               mov      dword ptr [rbp -48H], ecx  \\n \\nG_M000_IG08: \", \"               ;; offset=009FH  \\n       8B4DA8               mov      ecx, dword ptr [rbp -58H] \\n   \", \"    FFC9                 dec      ecx  \\n       894DA8               mov      dword ptr [rbp -58H], e\", \"cx  \\n       837DA800             cmp      dword ptr [rbp -58H], 0 \\n       7F0E                 jg   \", \"    SHORT G_M000_IG10  \\n  \\n17 CHAPTER 2 | JIT  \\n G_M000_IG09:                ;; offset=00ADH  \\n     \", \"  488D4DA8             lea      rcx, [rbp -58H] \\n       BA23000000           mov      edx, 35  \\n    \", \"   E86585AB5F           call     CORINFO_HELP_PATCHPOINT  \\n \\nG_M000_IG10:                ;; offset=0\", \"0BBH  \\n       817DB800CA9A3B       cmp      dword ptr [rbp -48H], 0x3B9ACA00  \\n       7CBB          \", \"       jl       SHORT G_M000_IG06  \\n       488B4DC0             mov      rcx, gword ptr [rbp -40H] \\n\", \"       3909                 cmp      dword ptr [rcx], ecx  \\n       FF1570C70D00         call     [St\", \"opwatch:get_ElapsedMilliseconds():long:this]  \\n       488BC8               mov      rcx, rax  \\n     \", \"  FF1507D00D00         call     [Console:WriteLine(long)]  \\n       E96DFFFFFF           jmp      G_M\", \"000_IG03  \\n \\n; Total bytes of code 222  \\n \\n; Assembly listing for method Program:<Main>g__IsAsciiDig\", \"it|0_0(ushort):bool  \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-0 compilation  \", \"\\n; MinOpts code  \\n; rbp based frame  \\n; partially interrupt ible \\n \\nG_M000_IG01:                ;; o\", \"ffset=0000H  \\n       55                   push     rbp  \\n       488BEC               mov      rbp, r\", \"sp  \\n       894D10               mov      dword ptr [rbp+10H], ecx  \\n \\nG_M000_IG02:                ;\", \"; offset=0007H  \\n       8B4510               mov      eax, dword ptr [rbp+10H]  \\n       0FB7C0      \", \"         movzx    rax, ax  \\n       83C0D0               add      eax, -48 \\n       83F809            \", \"   cmp      eax, 9  \\n       0F96C0               setbe    al  \\n       0FB6C0               mov zx   \", \" rax, al  \\n \\nG_M000_IG03:                ;; offset=0019H  \\n       5D                   pop      rbp \", \" \\n       C3                   ret  \\nA few relevant things to notice here. First, the comments at the\", \" top highlight how this code was \\ncompiled:  \\n; Tier-0 compilat ion \\n; MinOpts code  \\nSo, we know th\", \"is is the initial version (\\u201cTier -0\\u201d) of the method compiled with minimal optimization \\n(\\u201cMinOpts\\u201d).\", \" Second, note this line of the assembly:  \\nFF152DD40B00         call     [Program:<Main>g__IsAsciiDi\", \"git|0_0(ushort):bool]  \\nOur IsAsciiDigit  helper method is trivially inlineable, but it\\u2019s not gettin\", \"g inlined; instead, the \\nassembly has a call to it, and indeed we can see below the generated code (\", \"also \\u201cMinOpts\\u201d) for \\nIsAsciiDigit . Why? Because inlining is an optimization (a really important one\", \") that\\u2019s  disabled as \\npart of tier -0 (because the analysis for doing inlining well is also quite c\", \"ostly). Third, we can see the \\ncode the JIT is outputting to instrument this method. This is a bit m\", \"ore involved, but I\\u2019ll point out the \\nrelevant parts. First, we see:   \\n18 CHAPTER 2 | JIT  \\n C745A8\", \"E8030000       mov      dword ptr [rbp -58H], 0x3E8  \\nThat 0x3E8  is the hex value for the decimal 1\", \",000, which is the default number of iterations a loop \\nneeds to iterate before the JIT will generat\", \"e the optimized version of the method (this is configur able \\nvia the DOTNET_TC_OnStackReplacement_I\", \"nitialCounter  environment variable). So we see 1,000 \\nbeing stored into this stack location. Then a\", \" bit later in the method we see this:  \\nG_M000_IG03:                ;; offset=004BH  \\n       8B4DA8 \", \"              mov      ecx, dword ptr [rbp -58H] \\n       FFC9                 dec      ecx  \\n       \", \"894DA8               mov      dword ptr [rbp -58H], ecx  \\n       837DA800             cmp      dword\", \" ptr [rbp -58H], 0 \\n       7F0E                 jg       SHORT G_M000_IG05  \\n        \\nG_M000_IG04:  \", \"              ;; offset=0059H  \\n       488D4DA8             lea      rcx, [rbp -58H] \\n       BA06000\", \"000           mov      edx, 6  \\n       E8B985AB5F           call     CORINFO_HELP_PATCHPOINT  \\n \\nG_M\", \"000_IG05:                ;; offset=0067H  \\nThe generat ed code is loading that counter into the ecx \", \"register, decrementing it, storing it back, and \\nthen seeing whether the counter dropped to 0. If it\", \" didn\\u2019t, the code skips to G_M000_IG05 , which is the \\nlabel for the actual code in the rest of the \", \"loop. But if t he counter did drop to 0, the JIT proceeds to \\nstore relevant state into the the rcx \", \"and edx registers and then calls the CORINFO_HELP_PATCHPOINT  \\nhelper method. That helper is respons\", \"ible for triggering the creation of the optimized method if it \\ndoesn\\u2019t yet  exist, fixing up all ap\", \"propriate tracking state, and jumping to the new method. And indeed, \\nif you look again at your cons\", \"ole output from running the program, you\\u2019ll see yet another output for \\nthe Main  method:  \\n; Assemb\", \"ly listing for method Program:Main()  \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tie\", \"r-1 compilation  \\n; OSR variant for entry point 0x23  \\n; optimized code  \\n; rsp based frame  \\n; full\", \"y interruptible  \\n; No PGO data  \\n; 1 inlinees with PGO data; 8 single block inlinees; 0 inlinees wi\", \"thout PG O data \\n \\nG_M000_IG01:                ;; offset=0000H  \\n       4883EC58             sub    \", \"  rsp, 88  \\n       4889BC24D8000000     mov      qword ptr [rsp+D8H], rdi  \\n       4889B424D0000000 \", \"    mov      qword ptr [rsp+D0H], rsi  \\n       48899C24C8000000     mov      qword ptr [rsp+C8H], rb\", \"x  \\n       C5F877               vzeroupper  \\n       33C0                 xor      eax, eax  \\n       \", \"4889442428           mov      qword ptr [rsp+28H], rax  \\n       4889442420           mov      qword \", \"ptr [rsp+20H], rax  \\n       488B9C24A0000 000     mov      rbx, gword ptr [rsp+A0H]  \\n       8BBC249\", \"C000000       mov      edi, dword ptr [rsp+9CH]  \\n       8BB42498000000       mov      esi, dword pt\", \"r [rsp+98H]  \\n \\nG_M000_IG02:                ;; offset=0041H  \\n       EB45                 jmp      S\", \"HORT G_ M000_IG05  \\n                            align    [0 bytes for IG06]   \\n19 CHAPTER 2 | JIT  \\n\", \"  \\nG_M000_IG03:                ;; offset=0043H  \\n       33C9                 xor      ecx, ecx  \\n   \", \"    488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H]  \\n       48894B08             mov      qw\", \"ord ptr [rbx+08H], rcx  \\n       488D4C2428           lea      rcx, [rsp+28H]  \\n       48B87066E68AFD\", \"7F0000 mov      rax, 0x7FFD8AE66670  \\n \\nG_M000_IG04:                ;; offset=0060H  \\n       FFD0   \", \"              call     rax ; Kernel32:QueryPerformanceCounter(l ong):int  \\n       488B442428        \", \"   mov      rax, qword ptr [rsp+28H]  \\n       488B9C24A0000000     mov      rbx, gword ptr [rsp+A0H]\", \"  \\n       48894310             mov      qword ptr [rbx+10H], rax  \\n       C6431801             mov  \", \"    byte  ptr [rbx+18H], 1  \\n       33FF                 xor      edi, edi  \\n       33F6            \", \"     xor      esi, esi  \\n       833D92A1E55F00       cmp      dword ptr [(reloc 0x7ffcafe1ae34)], 0 \", \" \\n       0F85CA000000         jne      G_M000_IG13  \\n \\nG_M000_IG05:                ;; offset=00 88H \", \"\\n       81FE00CA9A3B         cmp      esi, 0x3B9ACA00  \\n       7D17                 jge      SHORT G\", \"_M000_IG09  \\n \\nG_M000_IG06:                ;; offset=0090H  \\n       0FB7CE               movzx    rc\", \"x, si  \\n       83C1D0               add      ecx, -48 \\n       83F909               cmp      ecx, 9  \", \"\\n       7702                 ja       SHORT G_M000_IG08  \\n \\nG_M000_IG07:                ;; offset=00\", \"9BH  \\n       FFC7                 inc      edi  \\n \\nG_M000_IG08:                ;; offset=009DH  \\n   \", \"    FFC6                 inc      esi \\n       81FE00CA9A3B         cmp      esi, 0x3B9ACA00  \\n      \", \" 7CE9                 jl       SHORT G_M000_IG06  \\n \\nG_M000_IG09:                ;; offset=00A7H  \\n \", \"      488B6B08             mov      rbp, qword ptr [rbx+08H]  \\n       48899C24A0000000     mov      \", \"gword ptr [rsp+A0H], rbx  \\n       807B1800             cmp      byte  ptr [rbx+18H], 0  \\n       7436\", \"                 je       SHORT G_M000_IG12  \\n \\nG_M000_IG10:                ;; offset=00B9H  \\n      \", \" 488D4C2420           lea      rcx, [rsp+20H]  \\n       48B87066E 68AFD7F0000 mov      rax, 0x7FFD8AE\", \"66670  \\n \\nG_M000_IG11:                ;; offset=00C8H  \\n       FFD0                 call     rax ; K\", \"ernel32:QueryPerformanceCounter(long):int  \\n       488B4C2420           mov      rcx, qword ptr [rsp\", \"+20H]  \\n       488B9C24A000000 0     mov      rbx, gword ptr [rsp+A0H]  \\n       482B4B10            \", \" sub      rcx, qword ptr [rbx+10H]  \\n       4803E9               add      rbp, rcx  \\n       833D2FA1\", \"E55F00       cmp      dword ptr [(reloc 0x7ffcafe1ae34)], 0  \\n       48899C24A0000000     mov      g\", \"word ptr [rsp+A0H], rbx  \\n       756D                 jne      SHORT G_M000_IG14  \\n \\nG_M000_IG12:   \", \"             ;; offset=00EFH  \\n       C5F857C0             vxorps   xmm0, xmm0  \\n       C4E1FB2AC5  \", \"         vcvtsi2sd  xmm0, rbp  \\n       C5FB11442430         vm ovsd   qword ptr [rsp+30H], xmm0   \\n2\", \"0 CHAPTER 2 | JIT  \\n        48B9F04BF24FFC7F0000 mov      rcx, 0x7FFC4FF24BF0  \\n       BAE7070000   \", \"        mov      edx, 0x7E7  \\n       E82E1FB25F           call     CORINFO_HELP_GETSHARED_NONGCSTATI\", \"C_BASE  \\n       C5FB10442430         vmovsd   xmm0 , qword ptr [rsp+30H]  \\n       C5FB5905E049F6FF  \", \"   vmulsd   xmm0, xmm0, qword ptr [(reloc 0x7ffc4ff25720)]  \\n       C4E1FB2CD0           vcvttsd2si \", \" rdx, xmm0  \\n       48B94B598638D6C56D34 mov      rcx, 0x346DC5D63886594B  \\n       488BC1           \", \"    mov      ra x, rcx \\n       48F7EA               imul     rdx:rax, rdx  \\n       488BCA           \", \"    mov      rcx, rdx  \\n       48C1E93F             shr      rcx, 63  \\n       48C1FA0B             s\", \"ar      rdx, 11  \\n       4803CA               add      rcx, rdx  \\n       FF1567CE0D 00         call \", \"    [Console:WriteLine(long)]  \\n       E9F5FEFFFF           jmp      G_M000_IG03  \\n \\nG_M000_IG13:   \", \"             ;; offset=014EH  \\n       E8DDCBAC5F           call     CORINFO_HELP_POLL_GC  \\n       E9\", \"30FFFFFF           jmp      G_M000_IG05  \\n \\nG_M000_I G14:                ;; offset=0158H  \\n       E8\", \"D3CBAC5F           call     CORINFO_HELP_POLL_GC  \\n       EB90                 jmp      SHORT G_M000\", \"_IG12  \\n \\n; Total bytes of code 351  \\nHere, again, we notice a few interesting things. First, in the\", \" header we see thi s: \\n; Tier-1 compilation  \\n; OSR variant for entry point 0x23  \\n; optimized code \", \" \\nso we know this is both optimized \\u201ctier -1\\u201d code and is the \\u201cOSR variant\\u201d for this method. Second,\", \" \\nnotice there\\u2019s no longer a call to the IsAsciiDigit  helper. Instead, where that ca ll would have \", \"been, \\nwe see this:  \\nG_M000_IG06:                ;; offset=0090H  \\n       0FB7CE               movz\", \"x    rcx, si  \\n       83C1D0               add      ecx, -48 \\n       83F909               cmp      e\", \"cx, 9  \\n       7702                 ja       SHORT G _M000_IG08  \\nThis is loading a value into rcx, \", \"subtracting 48 from it (48 is the decimal ASCII value of the '0' \\ncharacter) and comparing the resul\", \"ting value to 9. Sounds an awful lot like our IsAsciiDigit  \\nimplementation ( (uint)(c - '0') <= 9 )\", \", doesn\\u2019t it? Th at\\u2019s because it is. The helper was successfully \\ninlined in this now -optimized cod\", \"e.  \\nGreat, so now in .NET 7, we can largely avoid the tradeoffs between startup and throughput, as \", \"OSR \\nenables tiered compilation to apply to all methods, even those that are l ong-running. A multit\", \"ude of \\nPRs went into enabling this, including many over the last few years, but all of the function\", \"ality was \\ndisabled in the shipping bits. Thanks to improvements like dotnet/runtime#62831  which im\", \"plemented \\nsupport for OSR on Arm64 (previously only x64 support was implemented), and \\ndotnet/runti\", \"me#63406  and dotnet/runtime#65609  which revised how OSR imports and epilogs are \\nhandled, dotnet/r\", \"untime#65675  enables OSR (and as a result DOTNET_TC_QuickJitForLoops ) by \\ndefault.   \\n21 CHAPTER 2\", \" | JIT  \\n But, tiered compilation and OSR aren\\u2019t just about startup (though they\\u2019re of course very v\", \"aluable \\nthere). They\\u2019re also about further improving throughput. Even though tiered compilation was\", \" \\noriginally envisioned as a way  to optimize startup while not hurting throughput, it\\u2019s become much\", \" \\nmore than that. There are various things the JIT can learn about a method during tier -0 that it c\", \"an \\nthen use for tier -1. For example, the very fact that the tier -0 code executed means that  any \", \"static s \\naccessed by the method will have been initialized, and that means that any readonly static\", \" s will not \\nonly have been initialized by the time the tier -1 code executes but their values won\\u2019t\", \" ever change. And \\nthat in turn means that any readonly s tatics of primitive types (e.g. bool , int\", \", etc.) can be treated like \\nconst s instead of static readonly  fields, and during tier -1 compilat\", \"ion the JIT can optimize them \\njust as it would have optimized a const . For example, try running th\", \"is simple program aft er setting \\nDOTNET_JitDisasm  to Program:Test : \\nusing System.Runtime.Compiler\", \"Services ; \\n \\nclass Program \\n{ \\n    static readonly  bool Is64Bit = Environment. Is64BitProcess ; \\n \", \"\\n    static int Main() \\n    { \\n        int count = 0; \\n        for (int i = 0; i < 1_000_000_000; i+\", \"+) \\n            if (Test()) \\n                count++;  \\n        return count; \\n    } \\n \\n    [MethodI\", \"mpl (MethodImplOptions. NoInlining )] \\n    static bool Test() => Is64Bit;  \\n} \\nWhen I do so, I get t\", \"his output:  \\n; Assembly listing for method Program:Test():bool  \\n; Emitting BLENDED_CODE for X64 CP\", \"U with AVX - Windows \\n; Tier-0 compilation  \\n; MinOpts code  \\n; rbp based frame  \\n; partially interr\", \"uptible  \\n \\nG_M000_IG01:                ;; offset=0000H  \\n       55                   push     rbp  \", \"\\n       4883EC20             sub      rsp, 32 \\n       488D6C2420           lea      rbp, [rsp+20H]  \", \"\\n \\nG_M000_IG02:                ;; offset=000AH  \\n       48B9B8639A3FFC7F0000 mov      rcx, 0x7FFC3F9\", \"A63B8  \\n       BA01000000           mov      edx, 1  \\n       E8C220B25F           call     CORINFO_H\", \"ELP _GETSHARED_NONGCSTATIC_BASE  \\n       0FB60545580C00       movzx    rax, byte  ptr [(reloc 0x7ffc\", \"3f9a63ea)]  \\n \\nG_M000_IG03:                ;; offset=0025H  \\n       4883C420             add      rs\", \"p, 32  \\n       5D                   pop      rbp  \\n       C3                   ret \\n \\n; Total bytes \", \"of code 43   \\n22 CHAPTER 2 | JIT  \\n  \\n; Assembly listing for method Program:Test():bool  \\n; Emitting\", \" BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation  \\n; optimized code  \\n; rsp based \", \"frame  \\n; partially interruptible  \\n; No PGO data  \\n \\nG_M000_IG01:                ;; offset=0000H  \\n\", \" \\nG_M000_IG02:                ;; offset=0000H  \\n       B801000000           mov      eax, 1  \\n \\nG_M0\", \"00_IG03:                ;; offset=0005H  \\n       C3                   ret  \\n \\n; Total bytes of code \", \"6  \\nNote, again, we see two outputs for Program:Test . First, we see the \\u201cTier -0\\u201d code, which is ac\", \"cessing a \\nstatic (note the call     CORINFO_HELP_GETSHARED_NONGCSTATIC_BASE  instruction). But then\", \" we see \\nthe \\u201cTier -1\\u201d code, where all of that overhead has vanished and is instead replaced simply \", \"by  mov eax, \\n1. Since the \\u201cTier -0\\u201d code had to have executed in order for it to tier up, the \\u201cTier\", \" -1\\u201d code was \\ngenerated knowing that the value of the static readonly bool Is64Bit  field was true \", \" (1), and so \\nthe entirety of this method is storing the value 1 into the eax register used for the \", \"return value.  \\nThis is so useful that components are now written with tiering in mind. Consider the\", \" new Regex  source \\ngenerator, which is discussed later in this post (Roslyn source generators were \", \"introduced a couple of \\nyears ago; just as how Roslyn analyzers are able to plug into the compiler a\", \"nd surface additional \\ndiagnostics based on all of the data the compiler learns from the source code\", \", Roslyn source \\ngenerators are able to analyze that same data and then further augme nt the compila\", \"tion unit with \\nadditional source). The Regex  source generator applies a technique based on this in\", \" \\ndotnet/runtime#67775 . Regex  supports setting a process -wide timeout that gets a pplied to Regex\", \"  \\ninstances that don\\u2019t expl icitly set a timeout. That means, even though it\\u2019s super rare for such \", \"a \\nprocess -wide timeout to be set, the Regex  source generator still needs to output timeout -relat\", \"ed code \\njust in case it\\u2019s needed. It does so by outputting some helpers like this:  \\nstatic class U\", \"tilities  \\n{ \\n    internal  static readonly  TimeSpan s_defaultTimeout = \\nAppContext. GetData(\\\"REGEX\", \"_DEFAULT_MATCH_TIMEOUT\\\" ) is TimeSpan timeout ? timeout : \\nTimeout. InfiniteTimeSpan ; \\n    internal\", \"  static readonly  bool s_hasTimeout = s_defaultTimeout != \\nTimeout.InfiniteTimeSpan ; \\n} \\nwhich it \", \"then uses at call sites like this:  \\nif (Utilities. s_hasTimeout ) \\n{ \\n    base.CheckTimeout (); \\n} \", \"\\nIn tier -0, these checks will still be emitted in the assembly code, but in tier -1 where throughpu\", \"t \\nmatters, if the relevant AppContext  switch hasn\\u2019t been set, then s_defaultTimeout  will be  \\n23 \", \"CHAPTER 2 | JIT  \\n Timeout.InfiniteTimeSpan , at which point s_hasTimeout  will be false . And since\", \" s_hasTimeout  is a \\nstatic readonly bool , the JIT will be able to treat that as a const , and all \", \"conditions like if \\n(Utilities.s_hasTimeout)  will be treated equal to if (false)  and be eliminated\", \" from the \\nassembly code entirely as dead code.  \\nBut, this is somewhat old news. The JIT has been a\", \"ble to do such an optimization since tiered \\ncompilation was introduced in .NET Core 3 .0. Now in .N\", \"ET 7, though, with OSR it\\u2019s also able to do so \\nby default for methods with loops (and thus enable c\", \"ases like the regex one). However, the real magic \\nof OSR comes into play when combined with another\", \" exciting feature: dynamic PGO.  \\nPGO \\nI wrote about profile -guided optimization (PGO) in my Perfor\", \"mance Improvements in .NET 6  post, but \\nI\\u2019ll cover it again here as it\\u2019s seen a multitude of improv\", \"ements for .NET 7.  \\nPGO has been around for a long time, in any number of languages and compilers. \", \"The basic idea is \\nyou compile your app, asking the compiler to inject instrumentation into the appl\", \"ication to track \\nvarious pieces of interesting information. You th en put your app through its pace\", \"s, running through \\nvarious common scenarios, causing that instrumentation to \\u201cprofile\\u201d what happens\", \" when the app is \\nexecuted, and the results of that are then saved out. The app is then recompiled, \", \"feeding those \\ninstrumentat ion results back into the compiler, and allowing it to optimize the app \", \"for exactly how it\\u2019s \\nexpected to be used. This approach to PGO is referred to as \\u201cstatic PGO,\\u201d as t\", \"he information is all \\ngleaned ahead of actual deployment, and it\\u2019s something .NET has  been doing i\", \"n various forms for \\nyears. From my perspective, though, the really interesting development in .NET \", \"is \\u201cdynamic PGO,\\u201d \\nwhich was introduced in .NET 6, but off by default.  \\nDynamic PGO takes advantage\", \" of tiered compilation. I noted that the JIT instruments the tier -0 code \\nto track how many times t\", \"he method is called, or in the case of loops, how many times the loop \\nexecutes. It can instrument i\", \"t for other things as well. For example, it can track exactly which concrete \\ntypes are used as the \", \"targe t of an interface dispatch, and then in tier -1 specialize the code to expect \\nthe most common\", \" types (this is referred to as \\u201cguarded devirtualization,\\u201d or GDV). You can see this in \\nthis little\", \" example. Set the DOTNET_TieredPGO  environment variable to 1, and  then run this on .NET 7:  \\nclass\", \" Program \\n{ \\n    static void Main() \\n    { \\n        IPrinter printer = new Printer(); \\n        for (\", \"int i = 0; ; i++)  \\n        { \\n            DoWork(printer, i);  \\n        } \\n    } \\n \\n    static void\", \" DoWork(IPrinter printer, int i) \\n    { \\n        printer. PrintIfTrue (i == int.MaxValue ); \\n    } \\n\", \" \\n    interface  IPrinter  \\n    { \\n        void PrintIfTrue (bool condition);   \\n24 CHAPTER 2 | JIT \", \" \\n     } \\n \\n    class Printer : IPrinter  \\n    { \\n        public void PrintIfTrue (bool condition)  \", \"\\n        { \\n            if (condition) Console. WriteLine (\\\"Print!\\\" ); \\n        } \\n    } \\n} \\nThe tie\", \"r -0 code for DoWork  ends up looking like this:  \\nG_M000_IG01:                ;; offset=0000H  \\n   \", \"    55                   push     rbp  \\n       4883EC30             sub      rsp, 48  \\n       488D6C\", \"2430           lea      rbp, [rsp+30H]  \\n       33C0                 xor      eax, eax  \\n       4889\", \"45F8             mov      qword ptr [rbp -08H], rax  \\n       488945F0             mov      qword ptr\", \" [rbp -10H], rax  \\n       48894D10             mov      gword ptr  [rbp+10H], rcx  \\n       895518   \", \"            mov      dword ptr [rbp+18H], edx  \\n \\nG_M000_IG02:                ;; offset=001BH  \\n    \", \"   FF059F220F00         inc      dword ptr [(reloc 0x7ffc3f1b2ea0)]  \\n       488B4D10             mo\", \"v      rcx, gword ptr [rbp+10H]  \\n       48894DF8             mov      gword ptr [rbp -08H], rcx  \\n \", \"      488B4DF8             mov      rcx, gword ptr [rbp -08H] \\n       48BAA82E1B3FFC7F0000 mov      \", \"rdx, 0x7FFC3F1B2EA8  \\n       E8B47EC55F           call     CORINFO_HELP_CLASSPROFILE32  \\n       488B\", \"4DF8             mov      rcx, gword ptr [rbp -08H] \\n       48894DF0             mov      gword ptr \", \"[rbp -10H], rcx  \\n       488B4DF0             mov      rcx, gword ptr [rbp -10H] \\n       33D2       \", \"          xor      edx, edx  \\n       817D18FFFFFF7F       cmp      dword ptr [rbp+18H], 0x7FFFFFFF  \", \"\\n       0F94C2               sete     dl  \\n       49BB0800F13EFC7F0000 mov      r11, 0x7FFC3EF10008 \", \" \\n       41FF13               call     [r11]IPrinter:PrintIfTrue(bool):this  \\n       90             \", \"      nop  \\n \\nG_M000_IG03:                ;; offset=0062H  \\n       4883C430             add      rsp\", \", 48  \\n       5D                   pop      rbp  \\n       C3                   ret  \\nand most notably\", \", you can see the call [r11]IPrinter:PrintIfTrue(bool):this  doing the \\ninterface dispatch. But,  th\", \"en look at the code generated for tier -1. We still see the call \\n[r11]IPrinter:PrintIfTrue(bool):th\", \"is , but we also see this:  \\nG_M000_IG02:                ;; offset=0020H  \\n       48B9982D1B3FFC7F00\", \"00 mov      rcx, 0x7FFC3F1B2D98  \\n       48390F               cmp      qword ptr [rdi], rcx  \\n      \", \" 7521                 jne      SHORT G_M000_IG05  \\n       81FEFFFFFF7F         cmp      esi, 0x7FFFF\", \"FFF  \\n       7404                 je       SHORT G_M000_IG04  \\n \\nG_M000_IG03:                ;; offs\", \"et=0037H  \\n       FFC6                 inc      esi  \\n       EBE5                 jmp      SHORT G_M\", \"000_IG02  \\n  \\n25 CHAPTER 2 | JIT  \\n G_M000_IG04:                ;; offset=003BH  \\n       48B9D820801\", \"A24020000 mov      rcx, 0x2241A8020D8  \\n       488B09               mov      rcx, gword ptr [rcx]  \\n\", \"       FF1572CD0D00          call     [Console:WriteLine(String)]  \\n       EBE7                 jmp \", \"     SHORT G_M000_IG03  \\nThat first block is checking the concrete type of the IPrinter  (stored in \", \"rdi) and comparing it against \\nthe known type for Printer  (0x7FFC3F1B2D98 ). If the y\\u2019re different,\", \" it just jumps to the same interface \\ndispatch it was doing in the unoptimized version. But if they\\u2019\", \"re the same, it then jumps directly to an \\ninlined version of Printer.PrintIfTrue  (you can see the \", \"call to Console:WriteLine  right there in \\nthis method). Thus, the common case (the only case in thi\", \"s example) is super efficient at the expense \\nof a single comparison and branch.  \\nThat all existed \", \"in .NET 6, so why are we talking about it now? Several things have improved. First, \\nPGO now works w\", \"ith OS R, thanks to improvements like dotnet/runtime#61453 . That\\u2019s a big deal, as it \\nmeans hot lon\", \"g -running methods that do this kind of interface dispatch (which are fairly common) \\ncan get these \", \"kinds of devirtualization/inlining optimizations. Second, while PGO isn\\u2019t currently \\nenabled by defa\", \"ult, we\\u2019ve made it much easier to turn on. Between dotnet/runtime#71438  and \\ndotnet/sdk#26350 , it\\u2019\", \"s now possible to simply put <TieredPGO>true</TieredPGO>  into your .csproj, \\nand it\\u2019ll have the sa \", \"me effect as if you set DOTNET_TieredPGO=1  prior to every invocation of the app, \\nenabling dynamic \", \"PGO (note that it doesn\\u2019t  disable use of R2R images, so if you want the entirety of \\nthe core libra\", \"ries also employing dynamic PGO, you\\u2019ll also need to set DOTNET_ReadyToRun=0 ). Third, \\nhowever, is \", \"dynamic PGO has been taught how to instrument and optimize additional things.  \\nPGO already knew how\", \" to instrument virtual dispatch. Now in .NET 7, thanks in large part to \\ndotnet/runtime#68703 , it c\", \"an do so for delegates as well (at least for delegates to instance methods). \\nConsider this simple c\", \"onsole app:  \\nusing System.Runtime.CompilerServices ; \\n \\nclass Program \\n{ \\n    static int[] s_values\", \" = Enumerable. Range(0, 1_000).ToArray(); \\n \\n    static void Main() \\n    { \\n        for (int i = 0; \", \"i < 1_000_000; i++) \\n            Sum(s_values, i => i * 42); \\n    } \\n \\n    [MethodImpl (MethodImplOp\", \"tions. NoInlining )] \\n    static int Sum(int[] values, Func< int, int> func) \\n    { \\n        int sum\", \" = 0; \\n        foreach (int value in values) \\n            sum += func(value);  \\n        return sum; \", \"\\n    } \\n} \\nWithout PGO enabled, I get generated optimized assembly like this:  \\n; Assembly listing f\", \"or method Program:Sum(ref,Func`2):int  \\n; Emitting B LENDED_CODE for X64 CPU with AVX - Windows \\n; T\", \"ier-1 compilation   \\n26 CHAPTER 2 | JIT  \\n ; optimized code  \\n; rsp based frame  \\n; partially interr\", \"uptible  \\n; No PGO data  \\n \\nG_M000_IG01:                ;; offset=0000H  \\n       4156               \", \"  push     r14  \\n       57                   pus h     rdi  \\n       56                   push     rs\", \"i  \\n       55                   push     rbp  \\n       53                   push     rbx  \\n       488\", \"3EC20             sub      rsp, 32  \\n       488BF2               mov      rsi, rdx  \\n \\nG_M000_IG02: \", \"               ;; offset=000DH  \\n       33FF                 xor      edi, edi  \\n       488BD9      \", \"         mov      rbx, rcx  \\n       33ED                 xor      ebp, ebp  \\n       448B7308        \", \"     mov      r14d, dword ptr [rbx+08H]  \\n       4585F6               test     r14d,  r14d \\n       7\", \"E16                 jle      SHORT G_M000_IG04  \\n \\nG_M000_IG03:                ;; offset=001DH  \\n   \", \"    8BD5                 mov      edx, ebp  \\n       8B549310             mov      edx, dword ptr [rb\", \"x+4*rdx+10H]  \\n       488B4E08             mov      rcx, gword ptr [rsi+08H]  \\n       FF5618        \", \"       call     [rsi+18H]Func`2:Invoke(int):int:this  \\n       03F8                 add      edi, eax\", \"  \\n       FFC5                 inc      ebp  \\n       443BF5               cmp      r14d, ebp  \\n     \", \"  7FEA                 jg       SHORT G_M000_IG03  \\n \\nG_M000_IG04:                ;; offset=0033H  \\n\", \"       8BC7                 mov      eax, edi  \\n \\nG_M000_IG05:                ;; offset=0035H  \\n    \", \"   4883C420             add      rsp, 32  \\n       5B                   pop      rbx  \\n       5D     \", \"              pop      rbp  \\n       5E                   pop      rsi  \\n       5F                   \", \"pop      rdi  \\n       415E                 pop      r14  \\n       C3                   ret  \\n \\n; Tota\", \"l bytes of code 64  \\nNote the call [rsi+18H]Func'2:Invok e(int):int:this  in there that\\u2019s invoking t\", \"he delegate. Now \\nwith PGO enabled:  \\n; Assembly listing for method Program:Sum(ref,Func`2):int  \\n; \", \"Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation  \\n; optimized code  \\n; op\", \"timized using profile da ta \\n; rsp based frame  \\n; fully interruptible  \\n; with Dynamic PGO: edge we\", \"ights are valid, and fgCalledCount is 5628  \\n; 0 inlinees with PGO data; 1 single block inlinees; 0 \", \"inlinees without PGO data  \\n \\nG_M000_IG01:                ;; offset=0000H   \\n27 CHAPTER 2 | JIT  \\n  \", \"      4157                 push     r15  \\n       4156                 push     r14  \\n       57      \", \"             push     rdi  \\n       56                   push     rsi  \\n       55                   p\", \"ush     rbp  \\n       53                   push     rbx  \\n       4883EC28             sub      rsp, 4\", \"0  \\n       488BF2               mov      rsi, rdx  \\n \\nG_M000_IG02:                ;; offset=000FH  \\n\", \"       33FF                 xor      edi, edi  \\n       488BD9               mov      rbx, rcx  \\n    \", \"   33ED                 xor      ebp, ebp  \\n       448B7308             mov      r14d, dword ptr [rb\", \"x+08H]  \\n       4585F6               test     r14d, r14d  \\n       7E27                 jle      SHOR\", \"T G_M000_IG05  \\n \\nG_M000_IG03:                ;; offset=001FH  \\n       8BC5                 mov     \", \" eax, ebp  \\n       8B548310             mov      edx, dword ptr [rbx+4*rax+10H]  \\n       4C8B4618   \", \"          mov      r8, qword ptr [rsi+18H]  \\n       48B8A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A\", \"0  \\n       4C3BC0               cmp      r8, rax  \\n       751D                 jne      SHORT G_M000\", \"_IG07  \\n       446BFA2A             imul     r15d, edx, 42  \\n \\nG_M000_IG04:                ;; offset\", \"=003CH  \\n       4103FF               add      edi, r15d  \\n       FFC5                 inc      ebp  \", \"\\n       443BF5               cmp      r14d, ebp  \\n       7FD9                 jg       SHORT G_M000_\", \"IG03  \\n \\nG_M000_IG05:                ;; offset=0046H  \\n       8BC7                 mov      eax, edi\", \"  \\n \\nG_M000_IG06:                ;; offset=0048H  \\n       4883C428             add      rsp, 40  \\n  \", \"     5B                   pop      rbx  \\n       5D                   pop      rbp  \\n       5E       \", \"            pop      rsi  \\n       5F                   pop      rdi  \\n       415E                 po\", \"p      r14  \\n       415F                 pop      r15  \\n       C3                   ret  \\n \\nG_M000_I\", \"G07:                ;; offset=0055H  \\n       488B4E08             mov      rcx, gword ptr [rsi+08H] \", \" \\n       41FFD0               call     r8  \\n       448BF8               mov      r15d, eax  \\n       \", \"EBDB                 jmp      SHORT G_M000_IG04  \\nI chose the 42 constant in i => i * 42  to make it\", \" easy to see in the assembly, and sure enough, there \\nit is: \\nG_M000_IG03:                ;; offset=\", \"001FH  \\n       8BC5                 mov      eax, ebp  \\n       8B548310             mov      edx, dw\", \"ord ptr [rbx+4*rax+10 H] \\n       4C8B4618             mov      r8, qword ptr [rsi+18H]  \\n       48B8\", \"A0C2CF3CFC7F0000 mov      rax, 0x7FFC3CCFC2A0  \\n       4C3BC0               cmp      r8, rax   \\n28 C\", \"HAPTER 2 | JIT  \\n        751D                 jne      SHORT G_M000_IG07  \\n       446BFA2A          \", \"   imul     r15d, edx, 42  \\nThis is loading the target address from the delegate into r8 and is load\", \"ing the address of the \\nexpected target into rax. If they\\u2019re the same, it then simply performs the i\", \"nlined operation ( imul \\nr15d, edx, 42 ), and otherwise it jumps to G_M0 00_IG07 which calls to the \", \"function in r8. The effect \\nof this is obvious if we run this as a benchmark:  \\nstatic int[] s_value\", \"s = Enumerable. Range(0, 1_000).ToArray(); \\n \\n[Benchmark]  \\npublic int DelegatePGO () => Sum(s_value\", \"s, i => i * 42); \\n \\nstatic int Sum(int[] values, Func< int, int>? func)  \\n{ \\n    int sum = 0; \\n    f\", \"oreach (int value in values) \\n    { \\n        sum += func(value);  \\n    } \\n    return sum; \\n} \\nWith P\", \"GO disabled, we get the same performance throughput for .NET 6 and .NET 7:  \\nMethod  Runtime  Mean  \", \"Ratio  \\nDelegatePGO  .NET 6.0  1.665 us  1.00 \\nDelegatePGO  .NET 7.0  1.659 us  1.00 \\nBut the pictur\", \"e changes when we enable dynamic PGO ( DOTNET_TieredPGO=1 ). .NET 6 gets ~14% \\nfaster, but .NET 7 ge\", \"ts ~3x faster!  \\nMethod  Runtime  Mean  Ratio  \\nDelegatePGO  .NET 6.0  1,427.7 ns  1.00 \\nDelegatePGO\", \"  .NET 7.0  539.0 ns  0.38 \\ndotnet/runtime#70377  is another valuable improvement with dynamic PGO, \", \"which enables PGO to \\nplay nicely with loop cloning and invariant hoi sting. To understand this bett\", \"er, a brief digression into \\nwhat those are. Loop cloning is a mechanism the JIT employs to avoid va\", \"rious overheads in the fast \\npath of a loop. Consider the Test  method in this example:  \\nusing Syst\", \"em.Runtime.CompilerServices ; \\n \\nclass Program \\n{ \\n    static void Main() \\n    { \\n        int[] arra\", \"y = new int[10_000_000]; \\n        for (int i = 0; i < 1_000_000; i++) \\n        { \\n            Test(a\", \"rray);  \\n        } \\n    } \\n  \\n29 CHAPTER 2 | JIT  \\n     [MethodImpl (MethodImplOptions. NoInlining )\", \"] \\n    private static bool Test(int[] array)  \\n    { \\n        for (int i = 0; i < 0x12345; i++) \\n   \", \"     { \\n            if (array[i] == 42) \\n            { \\n                return true; \\n            } \", \"\\n        } \\n \\n        return false; \\n    } \\n} \\nThe JIT doesn\\u2019t know whether the passed in array is o\", \"f sufficient length that all accesses to array[i]  \\ninside the loop will be in bounds, and thus it w\", \"ould need to inject bounds checks for every access. \\nWhile it\\u2019d be nice to simply do the length chec\", \"k up f ront and simply throw an exception early if it \\nwasn\\u2019t long enough, doing so could also chang\", \"e behavior (imagine the method were writing into the \\narray as it went, or otherwise mutating some s\", \"hared state). Instead, the JIT employs \\u201cloop cloning.\\u201d It \\nessenti ally rewrites this Test  method t\", \"o be more like this:  \\nif (array is not null && array. Length >= 0x12345) \\n{ \\n    for (int i = 0; i \", \"< 0x12345; i++) \\n    { \\n        if (array[i] == 42) // no bounds checks emitted for this access : -)\", \" \\n        { \\n            return true; \\n        } \\n    } \\n} \\nelse \\n{ \\n    for (int i = 0; i < 0x12345\", \"; i++) \\n    { \\n        if (array[i] == 42) // bounds checks emitted for this access : -( \\n        { \", \"\\n            return true; \\n        } \\n    } \\n} \\nreturn false; \\nThat way, at the expense of some code\", \" duplication, we get our fast loop without bounds checks and \\nonly pay for the bounds checks in the \", \"slow path. You can see this in the generated assembly (if you \\ncan\\u2019t already tell, DOTNET_JitDisasm \", \" is one of my favorite  features in .NET 7):  \\n; Assembly listing for method Program:Test(ref):bool \", \" \\n; Emitting BLENDED_CODE for X64 CPU with AVX - Windows \\n; Tier-1 compilation  \\n; optimized code  \\n\", \"; rsp based frame  \\n; fully interruptible  \\n; No PGO data  \\n \\nG_M000_IG01:                ;; of fset\", \"=0000H  \\n       4883EC28             sub      rsp, 40   \\n30 CHAPTER 2 | JIT  \\n  \\nG_M000_IG02:       \", \"         ;; offset=0004H  \\n       33C0                 xor      eax, eax  \\n       4885C9            \", \"   test     rcx, rcx  \\n       7429                 je       SHORT G_M000_IG05  \\n       8179084523010\", \"0       cmp      dword ptr [rcx+08H], 0x12345  \\n       7C20                 jl       SHORT G_M000_IG\", \"05  \\n       0F1F40000F1F840000000000 align    [12 bytes for IG03]  \\n \\nG_M000_IG03:                ;;\", \" offset=0020H  \\n       8BD0                 mov      edx, eax  \\n       837C91102A           cmp     \", \" dword ptr [rcx+4*rdx+10H], 42  \\n       7429                 je       SHORT G_M000_IG08  \\n       FFC\", \"0                 inc      eax  \\n       3D45230100           cmp      eax, 0x12345  \\n       7CEE    \", \"             jl       SHORT G_M000_IG03  \\n \\nG_M000_IG04:                ;; offset=0032H  \\n       EB1\", \"7                 jmp      SHORT G_M000_IG06  \\n \\nG_M000_IG05:                ;; offset=0034H  \\n     \", \"  3B4108               cmp      eax, dword ptr [rcx+08H]  \\n       7323                 jae      SHOR\", \"T G_M000_IG10  \\n       8BD0                 mov      edx, eax  \\n       837C91102A           cmp     \", \" dword ptr [rcx+4*rdx+10H], 42  \\n       7410                 je       SHORT G_M000_IG08  \\n       FFC\", \"0                 inc      eax  \\n       3D45230100           cmp      eax, 0x12345  \\n       7CE9    \", \"             jl       SHORT G_M000_IG05  \\n \\nG_M000_IG06:                ;; offset=004BH  \\n       33C\", \"0                 xor      eax, eax  \\n \\nG_M000_IG07:                ;; offset=004DH  \\n       4883C42\", \"8             add      rsp, 40 \\n       C3                   ret  \\n \\nG_M000_IG08:                ;; o\", \"ffset=0052H  \\n       B801000000           mov      eax, 1  \\n \\nG_M000_IG09:                ;; offset=\", \"0057H  \\n       4883C428             add      rsp, 40  \\n       C3                   ret  \\n \\nG_M000_IG\", \"10:                ;; offset=005CH  \\n       E81FA0C15F           call     CORINFO_HELP_RNGCHKFAIL  \\n\", \"       CC                   int3  \\n \\n; Total bytes of code 98  \\nThat G_M000_IG02 section is doing th\", \"e null check and the length check, jumping to the G_M000_I G05 \\nblock if either fails. If both succe\", \"ed, it\\u2019s then executing the loop (block G_M000_IG03) without bounds \\nchecks:  \\nG_M000_IG03:         \", \"       ;; offset=0020H  \\n       8BD0                 mov      edx, eax  \\n       837C91102A          \", \" cmp      dword ptr [rc x+4*rdx+10H], 42  \\n       7429                 je       SHORT G_M000_IG08  \\n\", \"       FFC0                 inc      eax   \\n31 CHAPTER 2 | JIT  \\n        3D45230100           cmp   \", \"   eax, 0x12345  \\n       7CEE                 jl       SHORT G_M000_IG03  \\nwith the bounds checks on\", \"ly showing up  in the slow -path block:  \\nG_M000_IG05:                ;; offset=0034H  \\n       3B410\", \"8               cmp      eax, dword ptr [rcx+08H]  \\n       7323                 jae      SHORT G_M00\", \"0_IG10  \\n       8BD0                 mov      edx, eax  \\n       837C91102A           cmp      dword \", \"ptr [rcx+4*rdx+10H], 42  \\n       7410                 je       SHORT G_M000_IG08  \\n       FFC0      \", \"           inc      eax  \\n       3D45230100           cmp      eax, 0x12345  \\n       7CE9           \", \"      jl       SHORT G_M000_IG05  \\nThat\\u2019s \\u201cloop  cloning.\\u201d What about \\u201cinvariant hoisting\\u201d? Hoisting\", \" means pulling something out of a \\nloop to be before the loop, and invariants are things that don\\u2019t \", \"change. Thus invariant hoisting is \\npulling something out of a loop to before the loop in order to a\", \"void r ecomputing every iteration of \\nthe loop an answer that won\\u2019t change. Effectively, the previou\", \"s example already showed invariant \\nhoisting, in that the bounds check is moved to be before the loo\", \"p rather than in the loop, but a more \\nconcrete example would be s omething like this:  \\n[MethodImpl\", \" (MethodImplOptions. NoInlining )] \\nprivate static bool Test(int[] array)  \\n{ \\n    for (int i = 0; i\", \" < 0x12345; i++) \\n    { \\n        if (array[i] == array. Length - 42) \\n        { \\n            return \", \"true; \\n        } \\n    } \\n \\n    return false; \\n} \\nNote that the value of array.Length - 42 doesn\\u2019t ch\", \"ange on each iteration of the loop, so it\\u2019s \\n\\u201cinvariant\\u201d to the loop iteration and can be lifted out\", \", which the generated code does:  \\nG_M000_IG02:                ;; offset=0004H  \\n       33D2        \", \"         xor      edx, edx  \\n       4885C9               test     rcx, rcx  \\n       742A            \", \"     je       SHORT G_M000_IG05  \\n       448B4108             mov      r8d, dword ptr [rcx+08H]  \\n  \", \"     4181F845230100       cmp      r8d, 0x12345  \\n       7C1D                 jl       SHORT G_M000_\", \"IG05  \\n       4183C0D6             add      r8d, -42 \\n       0F1F4000             align    [4 bytes \", \"for IG03]  \\n \\nG_M000_IG03:                ;; offset=0020H  \\n       8BC2                 mov      eax\", \", edx  \\n       4439448110           cmp      dword ptr [rcx+4*rax+10H], r8d  \\n       7433           \", \"      je       SHORT G_M000_IG08  \\n       FFC2                 inc      edx  \\n       81FA45230100   \", \"      cmp      edx, 0x12345  \\n       7CED                 jl       SHORT G_M000_IG03   \\n32 CHAPTER 2\", \" | JIT  \\n Here again we see the array being tested for null ( test rcx, rcx ) and the array\\u2019s length\", \" being \\nchecked ( mov r8d, dword ptr [rcx+08H] , cmp r8d, 0x12345 ), but then with the array\\u2019s lengt\", \"h in \\nr8d, we then see this up -front block subtracting 42 from the length ( add r8d, -42), and that\", \"\\u2019s before \\nwe continue into the fast -path loop in the G_M000_IG03 block. This keeps that additional\", \" set of \\noperations out of the loop, thereby avoiding the overhead of recomputing the value per iter\", \"ation.  \\nOk, so how does this apply to dy namic PGO? Remember that with the interface/virtual dispat\", \"ch \\navoidance PGO is able to do, it does so by doing a type check to see whether the type in use is \", \"the \\nmost common type; if it is, it uses a fast path that calls directly to that type\\u2019s method (and \", \"in doing so \\nthat call is then potentially inlined), and if it isn\\u2019t, it falls back to normal interf\", \"ace/virtual dispatch. That \\ncheck can be invariant to a loop. So when a method is tiered up and PGO \", \"kicks in, the type check can \\nnow be hoisted out of the loo p, making it even cheaper to handle the \", \"common case. Consider this \\nvariation of our original example:  \\nusing System.Runtime.CompilerServic\", \"es ; \\n \\nclass Program \\n{ \\n    static void Main() \\n    { \\n        IPrinter printer = new BlankPrinter\", \" (); \\n        while (true) \\n        { \\n            DoWork(printer);  \\n        } \\n    } \\n \\n    [Metho\", \"dImpl (MethodImplOptions. NoInlining )] \\n    static void DoWork(IPrinter printer)  \\n    { \\n        f\", \"or (int j = 0; j < 123; j++) \\n        { \\n            printer. Print(j); \\n        } \\n    } \\n \\n    int\", \"erface  IPrinter  \\n    { \\n        void Print(int i); \\n    } \\n \\n    class BlankPrinter : IPrinter  \\n \", \"   { \\n        public void Print(int i) \\n        { \\n            Console. Write(\\\"\\\"); \\n        } \\n    }\", \" \\n} \\nWhen we look at the optimized assembly generated for this with dy namic PGO enabled, we see thi\", \"s:  \\n; Assembly listing for method Program:DoWork(IPrinter)  \\n; Emitting BLENDED_CODE for X64 CPU wi\", \"th AVX - Windows \\n; Tier-1 compilation  \\n; optimized code  \\n; optimized using profile data   \\n33 CHA\", \"PTER 2 | JIT  \\n ; rsp based frame  \\n; partially interruptible  \\n; with Dynamic PGO: edge weights are\", \" invalid, and fgCalledCount is 12187  \\n; 0 inlinees with PGO data; 1 single block inlinees; 0 inline\", \"es without PGO data  \\n \\nG_M000_IG01:                ;; offset=0000H  \\n       57                   pu\", \"sh     rdi  \\n       56                   push     rsi  \\n       4883EC28             sub      rsp, 40\", \"  \\n       488BF1               mov      rsi, rcx  \\n \\nG_M000_IG02:                ;; offset=0009H  \\n \", \"      33FF                 xor      edi, edi  \\n       4885F6               test     rsi, rsi  \\n     \", \"  742B                 je       SHORT G_M000_IG05  \\n       48B9982DD43CFC7F0000 mov      rcx, 0x7FFC\", \"3CD42D98  \\n       48390E               cmp      qword ptr [rsi], rcx  \\n       751C                 j\", \"ne      SHORT G_M000_IG05  \\n \\nG_M000_IG03:                ;; off set=001FH  \\n       48B9282040F94802\", \"0000 mov      rcx, 0x248F9402028  \\n       488B09               mov      rcx, gword ptr [rcx]  \\n     \", \"  FF1526A80D00         call     [Console:Write(String)]  \\n       FFC7                 inc      edi  \", \"\\n       83FF7B               cm p      edi, 123  \\n       7CE6                 jl       SHORT G_M000_\", \"IG03  \\n \\nG_M000_IG04:                ;; offset=0039H  \\n       EB29                 jmp      SHORT G_\", \"M000_IG07  \\n \\nG_M000_IG05:                ;; offset=003BH  \\n       48B9982DD43CFC7F0000 mov      rcx\", \" , 0x7FFC3CD42D98  \\n       48390E               cmp      qword ptr [rsi], rcx  \\n       7521         \", \"        jne      SHORT G_M000_IG08  \\n       48B9282040F948020000 mov      rcx, 0x248F9402028  \\n     \", \"  488B09               mov      rcx, gword ptr [rcx]  \\n       FF15FBA70D00         call     [Console\", \":Write(String)]  \\n \\nG_M000_IG06:                ;; offset=005DH  \\n       FFC7                 inc   \", \"   edi  \\n       83FF7B               cmp      edi, 123  \\n       7CD7                 jl       SHORT \", \"G_M000_IG05  \\n \\nG_M000_IG07:                ;; offset=0064H  \\n       4883C428             add      r\", \"sp, 40  \\n       5E                   pop      rsi  \\n       5F                   pop      rdi  \\n     \", \"  C3                   ret  \\n \\nG_M000_IG08:                ;; offset=006BH  \\n       488BCE          \", \"     mov      rcx, rsi  \\n       8BD7                 mov      edx, edi  \\n       49BB1000AA3CFC7F0000\", \" mov      r11, 0x7FFC3CAA0010  \\n       41FF13               call     [r11]IPrinter:Print(int):this  \", \"\\n       EBDE                 jmp      SHORT G_M000_IG06  \\n \\n; Total byt es of code 127  \\nWe can see \", \"in the G_M000_IG02 block that it\\u2019s doing the type check on the IPrinter  instance and \\njumping to G_\", \"M000_IG05 if the check fails ( mov rcx, 0x7FFC3CD42D98 , cmp qword ptr [rsi], rcx ,  \\n34 CHAPTER 2 |\", \" JIT  \\n jne SHORT G_M000_IG05 ), otherwise falling through to G_M000_IG03 which is a tight fast -pat\", \"h loop \\nthat\\u2019s inlined BlankPrinter.Print  with no type checks in sight!  \\nInterestingly, improvemen\", \"ts like this can bring with them their own challenges. PGO leads to a \\nsignificant increase in the n\", \"umber of type checks, since call sites that specialize for a given type need \\nto compare against tha\", \"t type. However, common subexpression elimination (CSE) hasn\\u2019t historically \\nworked for such type ha\", \"ndles (CSE is a compiler optimization where duplic ate expressions are \\neliminated by computing the \", \"result once and then storing it for subsequent use rather than \\nrecomputing it each time). dotnet/ru\", \"ntime#70580  fixes this by enabling CSE for su ch constant \\nhandles. For example, consider this meth\", \"od:  \\n[Benchmark]  \\n[Arguments (\\\"\\\", \\\"\\\", \\\"\\\", \\\"\\\")] \\npublic bool AllAreStrings (object o1, object o2, o\", \"bject o3, object o4) => \\n    o1 is string && o2 is string && o3 is string && o4 is string; \\nOn .NET \", \"6, the JIT pr oduced this assembly code:  \\n; Program.AllAreStrings(System.Object, System.Object, Sys\", \"tem.Object, System.Object)  \\n       test      rdx,rdx  \\n       je        short M00_L01  \\n       mov \", \"      rax,offset MT_System.String  \\n       cmp       [rdx],rax  \\n       jne       short M00_L01  \\n  \", \"     test      r8,r8  \\n       je        short M00_L01  \\n       mov       rax,offset MT_System.String\", \"  \\n       cmp       [r8],rax  \\n       jne       short M00_L01  \\n       test      r9,r9  \\n       je  \", \"      short M00_L01  \\n       mov       rax,offset MT_S ystem.String  \\n       cmp       [r9],rax  \\n  \", \"     jne       short M00_L01  \\n       mov       rax,[rsp+28]  \\n       test      rax,rax  \\n       je \", \"       short M00_L00  \\n       mov       rdx,offset MT_System.String  \\n       cmp       [rax],rdx  \\n \", \"      je        short M00_L 00 \\n       xor       eax,eax  \\nM00_L00:  \\n       test      rax,rax  \\n   \", \"    setne     al  \\n       movzx     eax,al  \\n       ret \\nM00_L01:  \\n       xor       eax,eax  \\n     \", \"  ret \\n; Total bytes of code 100  \\nNote the C# has four tests for string  and the assembly code has \", \"four  loads with mov rax,offset \\nMT_System.String . Now on .NET 7, the load is performed just once: \", \" \\n; Program.AllAreStrings(System.Object, System.Object, System.Object, System.Object)  \\n       test \", \"     rdx,rdx  \\n       je        short M00_L01   \\n35 CHAPTER 2 | JIT  \\n        mov       rax,of fset \", \"MT_System.String  \\n       cmp       [rdx],rax  \\n       jne       short M00_L01  \\n       test      r8\", \",r8  \\n       je        short M00_L01  \\n       cmp       [r8],rax  \\n       jne       short M00_L01  \\n\", \"       test      r9,r9  \\n       je        short M00_L01  \\n       cmp       [r9],rax  \\n       jne    \", \"   short M00_L01  \\n       mov       rdx,[rsp+28]  \\n       test      rdx,rdx  \\n       je        short\", \" M00_L00  \\n       cmp       [rdx],rax  \\n       je        short M00_L00  \\n       xor       edx,edx  \\n\", \"M00_L00:  \\n       xor       eax,eax  \\n       test      rdx,rdx  \\n       setne     al  \\n       ret \\nM\", \"00_L01:  \\n       xor       eax,eax  \\n       ret \\n; Total bytes of code 69  \\nBounds Check Elimination\", \"  \\nOne of the things that makes .NET attractive is its safety. The runtime guards access to arrays, \", \"strings, \\nand sp ans such that you can\\u2019t accidentally corrupt memory by walking off either end; if y\", \"ou do, rather \\nthan reading/writing arbitrary memory, you\\u2019ll get exceptions. Of course, that\\u2019s not m\", \"agic; it\\u2019s done by \\nthe JIT inserting bounds checks every time one of these  data structures is inde\", \"xed. For example, this:  \\n[MethodImpl (MethodImplOptions. NoInlining )] \\nstatic int Read0thElement (\", \"int[] array) => array[ 0]; \\nresults in:  \\nG_M000_IG01:                ;; offset=0000H  \\n       4883E\", \"C28             sub      rsp, 40  \\n \\nG_M000_IG02:                ;; offset=0004H  \\n       83790800  \", \"           cmp      dword ptr [rcx+08H], 0  \\n       7608                 jbe      SHORT G_M000_IG04 \", \" \\n       8B4110               mov      eax, dword ptr [rcx+10H]  \\n \\nG_M000_IG03:                ;; o\", \"ff set=000DH  \\n       4883C428             add      rsp, 40  \\n       C3                   ret  \\n \\nG_\", \"M000_IG04:                ;; offset=0012H  \\n       E8E9A0C25F           call     CORINFO_HELP_RNGCHK\", \"FAIL  \\n       CC                   int3  \\nThe array is passed into this method in the rcx register, \", \"pointing to the method table pointer in the \\nobject, and the length of an array is stored in the obj\", \"ect just after that method table pointer (which is \\n8 bytes in a 64 -bit process). Thus the cmp dwor\", \"d ptr [rcx+08H], 0  instruction is reading the length  \\n36 CHAPTER 2 | JIT  \\n of the array and compa\", \"ring the length to 0; that makes sense, since the length can\\u2019t be negative, and \\nwe\\u2019re trying to acc\", \"ess the 0th element, so as long as the length isn\\u2019t 0, the array has enough elements \\nfor us to acce\", \"ss its 0th ele ment. In the event that the length was 0, the code jumps to the end of the \\nfunction,\", \" which contains call CORINFO_HELP_RNGCHKFAIL ; that\\u2019s a JIT helper function that throws an \\nIndexOut\", \"OfRangeException . If the length was sufficient, however, it then reads the  int stored at the \\nbegi\", \"nning of the array\\u2019s data, which on 64 -bit is 16 bytes (0x10) past the pointer ( mov eax, dword \\npt\", \"r [rcx+10H] ). \\nWhile these bounds checks in and of themselves aren\\u2019t super expensive, do a lot of t\", \"hem and their \\ncosts add up. So while t he JIT needs to ensure that \\u201csafe\\u201d accesses don\\u2019t go out of \", \"bounds, it also tries \\nto prove that certain accesses won\\u2019t, in which case it needn\\u2019t emit the bound\", \"s check that it knows will \\nbe superfluous. In every release of .NET, more and more cases have bee n\", \" added to find places these \\nbounds checks can be eliminated, and .NET 7 is no exception.  \\nFor exam\", \"ple, dotnet/runtime#61662  from [@anthonycanino](https://github.com/anthonycanino) \\nenabled the JIT \", \"to understand various forms of binary operations as part of range checks. Consider \\nthis method:  \\n[\", \"MethodImpl (MethodImplOptions. NoInlining )] \\nprivate static ushort[]? Convert(ReadOnlySpan< byte> b\", \"ytes)  \\n{ \\n    if (bytes.Length != 16) \\n    { \\n        return null; \\n    } \\n \\n    var result = new u\", \"short[8]; \\n    for (int i = 0; i < result. Length; i++) \\n    { \\n        result[i] = ( ushort)(bytes[\", \"i * 2] * 256 + bytes[i * 2 + 1]); \\n    } \\n \\n    return result; \\n} \\nIt\\u2019s validating that the input sp\", \"an is 16 bytes long and then creating a new ushort[8]  where each \\nushort  in the array combines two\", \" of the input bytes. To do that, it\\u2019s looping over the output array, \\nand indexing into the bytes ar\", \"ray using i * 2  and i * 2 + 1  as the indices. On  .NET 6, each of those \\nindexing operations would\", \" result in a bounds check, with assembly like:  \\ncmp       r8d,10     \\njae       short G_M000_IG04  \", \"\\nmovsxd    r8,r8d  \\nwhere that G_M000_IG04 is the call CORINFO_HELP_RNGCHKFAIL  we\\u2019re now familiar w\", \"ith. But on .NE T \\n7, we get this assembly for the method:  \\nG_M000_IG01:                ;; offset=0\", \"000H  \\n       56                   push     rsi  \\n       4883EC20             sub      rsp, 32  \\n \\nG\", \"_M000_IG02:                ;; offset=0005H  \\n       488B31               mov      rs i, bword ptr [r\", \"cx]  \\n       8B4908               mov      ecx, dword ptr [rcx+08H]   \\n37 CHAPTER 2 | JIT  \\n        \", \"83F910               cmp      ecx, 16  \\n       754C                 jne      SHORT G_M000_IG05  \\n   \", \"    48B9302F542FFC7F0000 mov      rcx, 0x7FFC2F542F30  \\n       BA08000000           mov      edx, 8 \", \" \\n       E80C1EB05F           call     CORINFO_HELP_NEWARR_1_VC  \\n       33D2                 xor   \", \"   edx, edx  \\n                            align    [0 bytes for IG03]  \\n \\nG_M000_IG03:              \", \"  ;; offset=0026H  \\n       8D0C12               lea      ecx, [rdx+rdx]  \\n       448BC1             \", \"  mov      r8d, ecx  \\n       FFC1                 inc      ecx  \\n       458BC0               mov    \", \"  r8d, r8d  \\n       460FB60406           movzx    r8, byte  ptr [rsi+r8]  \\n       41C1E008          \", \"   shl      r8d, 8 \\n       8BC9                 mov      ecx, ecx  \\n       0FB60C0E             movz\", \"x    rcx, byte  ptr [rsi+rcx]  \\n       4103C8               add      ecx, r8d  \\n       0FB7C9       \", \"        movzx    rcx, cx  \\n       448BC2               mov      r8d, edx  \\n       6642894C4010      \", \"   mov      word  ptr [rax+2*r8+10H], cx  \\n       FFC2                 inc      edx  \\n       83FA08 \", \"              cmp      edx, 8  \\n       7CD0                 jl       SHORT G_M000_IG03  \\n \\nG_M000_IG\", \"04:                ;; offset=0056H  \\n       4883C420             add      rsp, 32  \\n       5E       \", \"            pop      rsi  \\n       C3                   ret  \\n \\nG_M000_IG05:                ;; offset\", \"=005CH  \\n       33C0                 xor      rax, rax  \\n \\nG_M000_IG06:                ;; offset=005\", \"EH  \\n       4883C420             add      rsp, 32  \\n       5E                   pop      rsi  \\n     \", \"  C3                   ret  \\n \\n; Total bytes of code 100  \\nNo bounds checks, which is most easily se\", \"en by the lack of the telltale call \\nCORINFO_HELP_RNGCHKFAIL  at the end of th e method. With this P\", \"R, the JIT is able to understand the \\nimpact of certain multiplication and shift operations and thei\", \"r relationships to the bounds of the data \\nstructure. Since it can see that the result array\\u2019s lengt\", \"h is 8 and the loop is iterating from  0 to that \\nexclusive upper bound, it knows that i will always\", \" be in the range [0, 7] , which means that i * 2  will \\nalways be in the range [0, 14]  and i * 2 + \", \"1  will always be in the range [0, 15] . As such, it\\u2019s able \\nto prove that the bounds checks aren\\u2019t \", \"ne eded.  \\ndotnet/runtime#61569  and dotnet/runtime#62864  also help to eliminate bounds checks when\", \" dealing \\nwith constant strings and spans initialized from RVA statics (\\u201cRelative Virtual Address\\u201d s\", \"tatic fields, \\nbasically a static field that lives in a module\\u2019s data section). For example, conside\", \"r this benchmark : \\n[Benchmark]  \\n[Arguments (1)] \\npublic char GetChar(int i) \\n{ \\n    const string T\", \"ext = \\\"hello\\\";  \\n38 CHAPTER 2 | JIT  \\n     return (uint)i < Text. Length ? Text[i] : ' \\\\0'; \\n} \\nOn .\", \"NET 6, we get this assembly:  \\n; Program.GetChar(Int32)  \\n       sub       rsp,28  \\n       mov      \", \" eax,edx  \\n       cmp       rax,5  \\n       jl        short M00_L00  \\n       xor       eax,eax  \\n    \", \"   add       rsp,28  \\n       ret \\nM00_L00:  \\n       cmp       edx,5  \\n       jae       short M00_L01\", \"  \\n       mov       rax,2278B331450  \\n       mov       rax,[rax]  \\n       movsxd    rdx,edx  \\n      \", \" movzx     eax,word ptr [rax+rdx*2+0C]  \\n       add       rsp,28  \\n       ret \\nM00_L01:  \\n       cal\", \"l      CORINFO_HELP_RNGCHKFAIL  \\n       int       3  \\n; Total bytes of code 56  \\nThe beginning of th\", \"is makes sense: the JIT was obviously able to see that the len gth of Text  is 5, so \\nit\\u2019s implement\", \"ing the (uint)i < Text.Length  check by doing cmp rax,5 , and if i as an unsigned \\nvalue is greater \", \"than or equal to 5, it\\u2019s then zero\\u2019ing out the return value (to return the '\\\\0') and \\nexiting. If th\", \"e length is less than 5 ( in which case it\\u2019s also at least 0 due to the unsigned comparison), it \\nth\", \"en jumps to M00_L00 to read the value from the string\\u2026 but we then see another cmp against 5, this \\n\", \"time as part of a range check. So even though the JIT knew the index was in bounds, it wasn\\u2019t able t\", \"o \\nremove the bounds check. Now it is; in .NET 7, we get this:  \\n; Program.GetChar(Int32)  \\n       c\", \"mp       edx,5  \\n       jb        short M00_L00  \\n       xor       eax,eax  \\n       ret \\nM00_L00:  \\n\", \"       mov       rax,2B0AF002530  \\n       mov       rax, [rax] \\n       mov       edx,edx  \\n       mo\", \"vzx     eax,word ptr [rax+rdx*2+0C]  \\n       ret \\n; Total bytes of code 29  \\nSo much nicer.  \\ndotnet\", \"/runtime#67141  is a great example of how evolving ecosystem  needs drives specific \\noptimizations i\", \"nto the JIT. The Regex  compiler and source generator handle some cases of regular \\nexpression chara\", \"cter classes by using a bitmap lookup stored in strings. For example, to determine \\nwhether a char c\", \"  is in the character class \\\"[A-Za-z0-9_]\\\"  (which will match an underscore or any \\nASCII letter or \", \"digit), the implementation ends up generating an expression like the body of the \\nfollowing method: \", \"  \\n39 CHAPTER 2 | JIT  \\n [Benchmark]  \\n[Arguments ('a')] \\npublic bool IsInSet(char c) => \\n    c < 12\", \"8 && (\\\"\\\\0\\\\0\\\\0\\\\u03FF\\\\uFFFE\\\\u87FF\\\\uFFFE\\\\u07FF\\\"[c >> 4] & (1 << (c & 0xF))) != 0; \\nThe implementation i\", \"s treating an 8 -character string as a 128 -bit lookup table. If the character is \\nknown to be in ra\", \"nge (such that it\\u2019s effectively a 7 -bit value), it \\u2019s then using the top 3 bits of the value \\nto in\", \"dex into the 8 elements of the string, and the bottom 4 bits to select one of the 16 bits in that \\ne\", \"lement, giving us an answer as to whether this input character is in the set or not. In .NET 6, even\", \" \\nthough we  know the character is in range of the string, the JIT couldn\\u2019t see through either the l\", \"ength \\ncomparison or the bit shift.  \\n; Program.IsInSet(Char)  \\n       sub       rsp,28  \\n       mov\", \"zx     eax,dx  \\n       cmp       eax,80  \\n       jge       short M00_L00  \\n       mov       edx,eax \", \" \\n       sar       edx,4  \\n       cmp       edx,8  \\n       jae       short M00_L01  \\n       mov     \", \"  rcx,299835A1518  \\n       mov       rcx,[rcx]  \\n       movsxd    rdx,edx  \\n       movzx     edx,wor\", \"d ptr [rcx+rdx*2+0C]  \\n       and       eax,0F  \\n       bt        edx,eax  \\n       setb      al  \\n  \", \"     movzx     eax,al  \\n       add       rsp,28  \\n       ret \\nM00_L00:  \\n       xor       eax,eax  \\n\", \"       add       rsp,28  \\n       ret \\nM00_L01:  \\n       call      CORINFO_HELP_RNGCHKFAIL  \\n       i\", \"nt       3  \\n; Total bytes of cod e 75 \\nThe previously mentioned PR takes care of the length check. \", \"And this PR takes care of the bit shift. So \\nin .NET 7, we get this loveliness:  \\n; Program.IsInSet(\", \"Char)  \\n       movzx     eax,dx  \\n       cmp       eax,80  \\n       jge       short M00_L00  \\n       \", \"mov       edx,eax  \\n       sar       edx,4  \\n       mov       rcx,197D4800608  \\n       mov       rcx\", \",[rcx]  \\n       mov       edx,edx  \\n       movzx     edx,word ptr [rcx+rdx*2+0C]  \\n       and       \", \"eax,0F  \\n       bt        edx,eax  \\n       setb      al  \\n       movzx     e ax,al \\n       ret  \\n40 \", \"CHAPTER 2 | JIT  \\n M00_L00:  \\n       xor       eax,eax  \\n       ret \\n; Total bytes of code 51  \\nNote\", \" the distinct lack of a call CORINFO_HELP_RNGCHKFAIL . And as you might guess, this check can \\nhappe\", \"n a lot in a Regex , making this a very useful addition.  \\nBounds chec ks are an obvious source of o\", \"verhead when talking about array access, but they\\u2019re not the \\nonly ones. There\\u2019s also the need to us\", \"e the cheapest instructions possible. In .NET 6, with a method \\nlike: \\n[MethodImpl (MethodImplOption\", \"s. NoInlining )] \\nprivate static int Get(int[] values, int i) => values[i];  \\nassembly code like the\", \" following would be generated:  \\n; Program.Get(Int32[], Int32)  \\n       sub       rsp,28  \\n       cm\", \"p       edx,[rcx+8]  \\n       jae       short M01_L00  \\n       movsxd    rax,edx  \\n       mov       e\", \"ax,[rcx+rax*4+10]  \\n       add       rsp,28  \\n       ret \\nM01_L00:  \\n       call      CORINFO_HELP_R\", \"NGCHKFAIL  \\n       int       3  \\n; Total bytes of code 27  \\nThis should look fairly familiar from ou\", \"r previous discussion; the JIT is loading the array\\u2019s length \\n([rcx+8] ) and comparing that with the\", \" value of i (in edx), and then jumping to the end to throw an \\nexception if i is out of bounds. Imme\", \"diately after that jump we see a movsxd rax, edx  instruction, \\nwhich is  taking the 32 -bit value o\", \"f i from edx and moving it into the 64 -bit register rax. And as part \\nof moving it, it\\u2019s sign -exte\", \"nding it; that\\u2019s the \\u201csxd\\u201d part of the instruction name (sign -extending means \\nthe upper 32 bits of\", \" the new 64 -bit value will be set t o the value of the upper bit of the 32 -bit value, \\nso that the\", \" number retains its signed value). The interesting thing is, though, we know that the Length  \\nof an\", \" array and of a span is non -negative, and since we just bounds checked i against the Length , we \\na\", \"lso know that i is non -negative. That makes such sign -extension useless, since the upper bit is \\ng\", \"uaranteed to be 0. Since the mov instruction that zero -extends is a tad cheaper than movsxd , we ca\", \"n \\nsimply use that instead. And that\\u2019s exactly what dotnet/runtime#57970  from \\n[@pentp](https://git\", \"hub.com/pentp) does for both arrays and spans ( dotnet/runtime#70884  also \\nsimilarly avoids so me s\", \"igned casts in other situations). Now on .NET 7, we get this:  \\n; Program.Get(Int32[], Int32)  \\n    \", \"   sub       rsp,28  \\n       cmp       edx,[rcx+8]  \\n       jae       short M01_L00  \\n       mov    \", \"   eax,edx  \\n       mov       eax,[rcx+rax*4+10]  \\n       add       rsp,28 \\n       ret \\nM01_L00:  \\n \", \"      call      CORINFO_HELP_RNGCHKFAIL   \\n41 CHAPTER 2 | JIT  \\n        int       3  \\n; Total bytes \", \"of code 26  \\nThat\\u2019s not the only source of overhead with array access, though. In fact, there\\u2019s a ve\", \"ry large category \\nof array access overhead that\\u2019s been there forever, but that\\u2019s so well known ther\", \"e are even old FxCop \\nrules and newer Roslyn analyzers that warn against it: multidimensional array \", \"accesses. The overhead \\nin the case of a multidimensional array isn\\u2019t just an extra branch on every \", \"indexing opera tion, or \\nadditional math required to compute the location of the element, but rather\", \" that they currently pass \\nthrough the JIT\\u2019s optimization phases largely unmodified. dotnet/runtime#\", \"70271  improves the state \\nof the world here by doing an expansion of a multidimensional array acces\", \"s early in the JIT\\u2019s pipeline, \\nsuch that later optimization phases can improve multidimensional acc\", \"esses as they would other code, \\nincluding CSE and loop invariant hoi sting. The impact of this is v\", \"isible in a simple benchmark that \\nsums all the elements of a multidimensional array.  \\nprivate int[\", \",] _square;  \\n \\n[Params(1000)] \\npublic int Size { get; set; } \\n \\n[GlobalSetup]  \\npublic void Setup()\", \" \\n{ \\n    int count = 0; \\n    _square = new int[Size, Size];  \\n    for (int i = 0; i < Size; i++)  \\n \", \"   { \\n        for (int j = 0; j < Size; j++)  \\n        { \\n            _square[i, j] = count++;  \\n   \", \"     } \\n    } \\n} \\n \\n[Benchmark]  \\npublic int Sum() \\n{ \\n    int[,] square = _square;  \\n    int sum = \", \"0; \\n    for (int i = 0; i < Size; i++)  \\n    { \\n        for (int j = 0; j < Size; j++)  \\n        { \\n\", \"            sum += square[i, j];  \\n        } \\n    } \\n    return sum; \\n} \\nMethod  Runtime  Mean  Rati\", \"o  \\nSum .NET 6.0  964.1 us  1.00 \\nSum .NET 7.0  674.7 us  0.70 \\nThis previous example assumes you kn\", \"ow the size of each dimension of the multidimensional array \\n(it\\u2019s referring to the Size  directly i\", \"n the loops). That\\u2019s obviously not always (or maybe even rarely) the \\ncase. In such situations, you\\u2019\", \"d be more likely to use  the Array.GetUpperBound  method, and because  \\n42 CHAPTER 2 | JIT  \\n multid\", \"imensional arrays can have a non -zero lower bound, Array.GetLowerBound . That would lead to \\ncode l\", \"ike this:  \\nprivate int[,] _square;  \\n \\n[Params(1000)] \\npublic int Size { get; set; } \\n \\n[GlobalSetu\", \"p]  \\npublic void Setup() \\n{ \\n    int count = 0; \\n    _square = new int[Size, Size];  \\n    for (int i\", \" = 0; i < Size; i++)  \\n    { \\n        for (int j = 0; j < Size; j++)  \\n        { \\n            _squar\", \"e[i, j] = count++;  \\n        } \\n    } \\n} \\n \\n[Benchmark]  \\npublic int Sum() \\n{ \\n    int[,] square = _\", \"square;  \\n    int sum = 0; \\n    for (int i = square. GetLowerBound (0); i < square. GetUpperBound (0\", \"); i++) \\n    { \\n        for (int j = square. GetLowerBound (1); j < square. GetUpperBound (1); j++) \", \"\\n        { \\n            sum += square[i, j];  \\n        } \\n    } \\n    return sum; \\n} \\nIn .NET 7, than\", \"ks to dotnet/runtime#60816 , those GetLowerBound  and GetUpperBound  calls become \\nJIT intrinsics. A\", \"n \\u201cintrinsic\\u201d to a compiler is something the compiler has intrinsic knowledge of, such \\nthat rather \", \"than relying solely on a method\\u2019s defined implementation (if it even has one), the compiler \\ncan sub\", \"stitute in something it con siders to be better. There are literally thousands of methods in .NET \\nk\", \"nown in this manner to the JIT, with GetLowerBound  and GetUpperBound  being two of the most \\nrecent\", \". Now as intrinsics, when they\\u2019re passed a constant value (e.g. 0 for the 0th rank), the  JIT can \\ns\", \"ubstitute the necessary assembly instructions to read directly from the memory location that houses \", \"\\nthe bounds. Here\\u2019s what the assembly code for this benchmark looked like with .NET 6; the main thin\", \"g \\nto see here are all of the call s out to GetLowerBound  and GetUpperBound : \\n; Program.Sum()  \\n  \", \"     push      rdi  \\n       push      rsi  \\n       push      rbp  \\n       push      rbx  \\n       sub\", \"       rsp,28  \\n       mov       rsi,[rcx+8]  \\n       xor       edi,edi  \\n       mov       rcx,rsi  \", \"\\n       xor       edx,edx   \\n43 CHAPTER 2 | JIT  \\n        cmp       [rcx],ecx  \\n       call      Sys\", \"tem.Array.GetLowerBound(Int32)  \\n       mov       ebx,eax  \\n       mov       rcx,rsi  \\n       xor   \", \"    edx,edx  \\n       call      System.Array.GetUpperBound(Int32)  \\n       cmp       eax,ebx  \\n      \", \" jle       short M00_ L03 \\nM00_L00:  \\n       mov       rcx,[rsi]  \\n       mov       ecx,[rcx+4]  \\n  \", \"     add       ecx,0FFFFFFE8  \\n       shr       ecx,3  \\n       cmp       ecx,1  \\n       jbe       sh\", \"ort M00_L05  \\n       lea       rdx,[rsi+10]  \\n       inc       ecx  \\n       movsxd    rcx,ecx  \\n    \", \"   mov       ebp,[rdx+rcx*4]  \\n       mov       rcx,rsi  \\n       mov       edx,1  \\n       call      \", \"System.Array.GetUpperBound(Int32)  \\n       cmp       eax,ebp  \\n       jle       short M00_L02  \\nM00_\", \"L01:  \\n       mov       ecx,ebx  \\n       sub       ecx,[rsi+18]  \\n       cmp       ecx,[rsi+10]  \\n  \", \"     jae       short M00_L04  \\n       mov       edx,ebp  \\n       sub       edx,[rsi+1C]  \\n       cmp\", \"       edx,[rsi+14]  \\n       jae       short M00_L04  \\n       mov       eax,[rsi+14]  \\n       imul  \", \"    rax,rcx  \\n       mov       rcx,rdx  \\n       add       rcx,rax  \\n       add       edi,[rsi+rcx*4+\", \"20]  \\n       inc       ebp  \\n       mov       rcx,rsi  \\n       mov       edx,1  \\n       call      Sy\", \"stem.Array.GetUpperBound(Int32)  \\n       cmp       eax,ebp  \\n       jg        short M00_L01  \\nM00_L0\", \"2:  \\n       inc       ebx \\n       mov       rcx,rsi  \\n       xor       edx,edx  \\n       call      Sy\", \"stem.Array.GetUpperBound(Int32)  \\n       cmp       eax,ebx  \\n       jg        short M00_L00  \\nM00_L0\", \"3:  \\n       mov       eax,edi  \\n       add       rsp,28  \\n       pop       rbx  \\n       pop       rb\", \"p \\n       pop       rsi  \\n       pop       rdi  \\n       ret \\nM00_L04:  \\n       call      CORINFO_HEL\", \"P_RNGCHKFAIL   \\n44 CHAPTER 2 | JIT  \\n M00_L05:  \\n       mov       rcx,offset MT_System.IndexOutOfRan\", \"geException  \\n       call      CORINFO_HELP_NEWSFAST  \\n       mov       rsi,rax  \\n       call      S\", \"ystem.SR.get_IndexOutOfRange_ArrayRankIndex()  \\n       mov       rdx,rax  \\n       mov       rcx,rsi \", \" \\n       call      System.IndexOutOfRangeException..ctor(System.String)  \\n       mov       rcx,rsi  \", \"\\n       call      CORINFO_HELP_THROW  \\n       int       3  \\n; Total bytes of code 219  \\nNow here\\u2019s w\", \"hat it is for .NET 7:  \\n; Program.Sum()  \\n       push      r14  \\n       push      rdi  \\n       push \", \"     rsi  \\n       push      rbp  \\n       push      rbx  \\n       sub       rsp,20  \\n       mov       \", \"rdx,[rcx+8]  \\n       xor       eax,eax  \\n       mov       ecx,[rdx+18]  \\n       mov       r8d,ecx  \\n\", \"       mov       r9d,[rdx+10]  \\n       lea       ecx,[rcx+r9+0FFFF]  \\n       cmp       ecx,r8d  \\n   \", \"    jle       short M00_L03  \\n       mov       r9d,[rdx+1C]  \\n       mov       r10d,[rdx+14]  \\n     \", \"  lea       r 10d,[r9+r10+0FFFF]  \\nM00_L00:  \\n       mov       r11d,r9d  \\n       cmp       r10d,r11d\", \"  \\n       jle       short M00_L02  \\n       mov       esi,r8d  \\n       sub       esi,[rdx+18]  \\n     \", \"  mov       edi,[rdx+10]  \\nM00_L01:  \\n       mov       ebx,esi  \\n       cmp       ebx,edi  \\n       j\", \"ae       short M00_L04  \\n       mov       ebp,[rdx+14]  \\n       imul      ebx,ebp  \\n       mov      \", \" r14d,r11d  \\n       sub       r14d,[rdx+1C]  \\n       cmp       r14d,ebp  \\n       jae       short M00\", \"_L04  \\n       add       ebx,r14d  \\n       add       eax,[rdx+rbx *4+20] \\n       inc       r11d  \\n   \", \"    cmp       r10d,r11d  \\n       jg        short M00_L01  \\nM00_L02:  \\n       inc       r8d  \\n       \", \"cmp       ecx,r8d  \\n       jg        short M00_L00  \\nM00_L03:   \\n45 CHAPTER 2 | JIT  \\n        add   \", \"    rsp,20  \\n       pop       rbx  \\n       pop       rbp  \\n       pop       rsi  \\n       pop       r\", \"di  \\n       pop       r14  \\n       ret \\nM00_L04:  \\n       call      CORINFO_HELP_RNGCHKFAIL  \\n      \", \" int       3  \\n; Total bytes of code 130  \\nImportantly, note there are no more call s (other than fo\", \"r the bounds check exception at the end ). For \\nexample, instead of that first GetUpperBound  call: \", \"\\ncall      System.Array.GetUpperBound(Int32)  \\nwe get:  \\nmov       r9d,[rdx+1C]  \\nmov       r10d,[rd\", \"x+14]  \\nlea       r10d,[r9+r10+0FFFF]  \\nand it ends up being much faster:  \\nMethod  Runtime  Mean  R\", \"atio  \\nSum .NET 6.0  2,657.5 us  1.00 \\nSum .NET 7.0  676.3 us  0.25 \\nLoop Hoisting and Cloning  \\nWe \", \"previously saw how PGO interacts with loop hoisting and cloning, and those optimizations have \\nseen \", \"other improvements, as well.  \\nHistorically, the JIT\\u2019s support for hoisting has been limited to lift\", \"ing an invariant out one level. \\nConsider this example:  \\n[Benchmark]  \\npublic void Compute() \\n{ \\n  \", \"  for (int thousands = 0; thousands < 10; thousands++)  \\n    { \\n        for (int hundreds = 0; hundr\", \"eds < 10; hundreds++)  \\n        { \\n            for (int tens = 0; tens < 10; tens++)  \\n            {\", \" \\n                for (int ones = 0; ones < 10; ones++)  \\n                { \\n                    int\", \" n = ComputeNumber (thousands, hundreds, tens, ones);  \\n                    Process(n); \\n           \", \"     } \\n            } \\n        } \\n    } \\n} \\n  \\n46 CHAPTER 2 | JIT  \\n static int ComputeNumber (int t\", \"housands, int hundreds, int tens, int ones) =>  \\n    (thousands * 1000) + \\n    (hundreds * 100) + \\n \", \"   (tens * 10) + \\n    ones; \\n \\n[MethodImpl (MethodImplOptions. NoInlining )] \\nstatic void Process(in\", \"t n) { } \\nAt first glance, you might look at this and say \\u201cwhat could be hoisted, the computation of\", \" n requires \\nall of the loop inputs, and all of that computation is in ComputeNumber .\\u201d But from a c\", \"ompiler\\u2019s \\nperspective, the ComputeNum ber function is inlineable and thus logically can be part of \", \"its caller, the \\ncomputation of n is actually split into multiple pieces, and each of those pieces c\", \"an be hoisted to \\ndifferent levels, e.g.  the tens computation can be hoisted out one level, the h u\", \"ndreds out two levels, \\nand the thousands out three levels. Here\\u2019s what [DisassemblyDiagnoser]  outp\", \"uts for .NET 6:  \\n; Program.Compute()  \\n       push      r14  \\n       push      rdi  \\n       push   \", \"   rsi  \\n       push      rbp  \\n       push      rbx  \\n       sub       rsp,20 \\n       xor       esi\", \",esi  \\nM00_L00:  \\n       xor       edi,edi  \\nM00_L01:  \\n       xor       ebx,ebx  \\nM00_L02:  \\n      \", \" xor       ebp,ebp  \\n       imul      ecx,esi,3E8  \\n       imul      eax,edi,64  \\n       add       e\", \"cx,eax  \\n       lea       eax,[rbx+rbx*4]  \\n       lea       r14d,[rcx+rax*2]  \\nM00_L03:  \\n       le\", \"a       ecx,[r14+rbp]  \\n       call      Program.Process(Int32)  \\n       inc       ebp  \\n       cmp \", \"      ebp,0A  \\n       jl        short M00_L03  \\n       inc       ebx  \\n       cmp       ebx,0A  \\n   \", \"    jl        short M00_ L02 \\n       inc       edi  \\n       cmp       edi,0A  \\n       jl        shor\", \"t M00_L01  \\n       inc       esi  \\n       cmp       esi,0A  \\n       jl        short M00_L00  \\n      \", \" add       rsp,20  \\n       pop       rbx  \\n       pop       rbp  \\n       pop       rsi  \\n       pop \", \"      rdi \\n       pop       r14  \\n       ret \\n; Total bytes of code 84   \\n47 CHAPTER 2 | JIT  \\n We c\", \"an see that some  hoisting has happened here. After all, the inner most loop (tagged M00_L03) is \\non\", \"ly five instructions: increment ebp (which at this point is the ones  counter value), and if it\\u2019s st\", \"ill less \\nthan 0xA (10), jump back to M00_L03 which adds whatever is in r14 to ones . Great, so we\\u2019v\", \"e hoisted \\nall of the unnecessary computation out of the inner loop, being left only with adding the\", \" ones \\nposition to the rest of the number. Let\\u2019s g o out a level. M00_L02 is the label for the tens \", \"loop. What \\ndo we see there? Trouble. The two instructions imul ecx,esi,3E8  and imul eax,edi,64  ar\", \"e \\nperforming the thousands * 1000  and hundreds * 100  operations, highlighting that these \\noperati\", \"ons which coul d have been hoisted out further were left stuck in the next -to-innermost loop. \\nNow,\", \" here\\u2019s what we get for .NET 7, where this was improved in dotnet/runtime#68061 : \\n; Program.Compute\", \"()  \\n       push      r15  \\n       push      r14  \\n       push      r12  \\n       push      rdi  \\n   \", \"    push      rsi  \\n       push      rbp  \\n       push      rbx  \\n       sub       rsp,20  \\n       x\", \"or       esi,esi  \\nM00_L00:  \\n       xor       edi,edi  \\n       imul      ebx,esi,3E8  \\nM00_L01: \\n  \", \"     xor       ebp,ebp  \\n       imul      r14d,edi,64  \\n       add       r14d,ebx  \\nM00_L02:  \\n     \", \"  xor       r15d,r15d  \\n       lea       ecx,[rbp+rbp*4]  \\n       lea       r12d,[r14+rcx*2]  \\nM00_L\", \"03:  \\n       lea       ecx,[r12+r15]  \\n       call      qword ptr [Program.Process(Int32)]  \\n       \", \"inc       r15d  \\n       cmp       r15d,0A  \\n       jl        short M00_L03  \\n       inc       ebp  \\n\", \"       cmp       ebp,0A  \\n       jl        short M00_L02  \\n       inc       edi  \\n       cmp       e\", \"di,0A  \\n       jl        short M00_L01  \\n       inc       esi  \\n       cmp       esi,0A  \\n       jl \", \"       short M00_L00  \\n       add       rsp,20  \\n       pop       rbx  \\n       pop       rbp  \\n     \", \"  pop       rsi  \\n       pop       rdi  \\n       pop       r12  \\n       pop       r14  \\n       pop   \", \"    r15  \\n       ret \\n; Total bytes of code 99   \\n48 CHAPTER 2 | JIT  \\n Notice now where those imul \", \" instructions live. There are four labels, each one corresponding to one \\nof the loops, and we can s\", \"ee the outermost loop has the imul ebx,esi,3E8  (for the thousands \\ncomputation) and the next loop h\", \"as the  imul r14d,edi,64  (for the hundreds computation), \\nhighlighting that these computations were\", \" hoisted out to the appropriate level (the tens and ones \\ncomputation are still in the right places)\", \".  \\nMore improvements have gone in on the cloning side. Previously, loop cloning would only apply fo\", \"r \\nloops iterating by 1 from a low to a high value. With dotnet/runtime#60148 , the comparison again\", \"st \\nthe upper value can be <= rather than just <. And with dotnet/runtime#67930 , loops that iterate\", \" \\ndownward can also be cloned, as can loops that have increments and decrements larger than 1. \\nCons\", \"ider this benchmark:  \\nprivate int[] _values = E numerable. Range(0, 1000).ToArray(); \\n \\n[Benchmark]\", \"  \\n[Arguments (0, 0, 1000)] \\npublic int LastIndexOf (int arg, int offset, int count) \\n{ \\n    int[] v\", \"alues = _values;  \\n    for (int i = offset + count - 1; i >= offset; i --) \\n        if (values[i] ==\", \" arg)  \\n            return i; \\n    return 0; \\n} \\nWithout loop cloning, the JIT can\\u2019t assume that off\", \"set  through offset+count  are in range, and thus \\nevery access to the array needs to be bounds chec\", \"ked. With loop cloning, the JIT could generate one \\nversion of the loop without bounds checks and on\", \"ly use that when it knows all accesses will be valid. \\nThat\\u2019s exactly what happens no w in .NET 7. H\", \"ere\\u2019s what we got with .NET 6:  \\n; Program.LastIndexOf(Int32, Int32, Int32)  \\n       sub       rsp,2\", \"8  \\n       mov       rcx,[rcx+8]  \\n       lea       eax,[r8+r9+0FFFF]  \\n       cmp       eax,r8d  \\n \", \"      jl        short M00_L01  \\n       mov       r9d,[rc x+8] \\n       nop       word ptr [rax+rax]  \", \"\\nM00_L00:  \\n       cmp       eax,r9d  \\n       jae       short M00_L03  \\n       movsxd    r10,eax  \\n \", \"      cmp       [rcx+r10*4+10],edx  \\n       je        short M00_L02  \\n       dec       eax  \\n       \", \"cmp       eax,r8d  \\n       jge       short M00_L00  \\nM00_L01:  \\n       xor       eax,eax  \\n       ad\", \"d       rsp,28  \\n       ret \\nM00_L02:  \\n       add       rsp,28  \\n       ret \\nM00_L03:  \\n       call\", \"      CORINFO_HELP_RNGCHKFAIL   \\n49 CHAPTER 2 | JIT  \\n        int       3  \\n; Total bytes of code 72\", \"  \\nNotice how in the core loop, a t label M00_L00, there\\u2019s a bounds check ( cmp eax,r9d  and jae sho\", \"rt \\nM00_L03 , which jumps to a call CORINFO_HELP_RNGCHKFAIL ). And here\\u2019s what we get with .NET 7:  \", \"\\n; Program.LastIndexOf(Int32, Int32, Int32)  \\n       sub       rsp,28  \\n       mov       rax,[rcx+8]\", \"  \\n       lea       ecx,[r8+r9+0FFFF]  \\n       cmp       ecx,r8d  \\n       jl        short M00_L02  \\n\", \"       test      rax,rax  \\n       je        short M00_L01  \\n       test      ecx,ecx  \\n       jl    \", \"    short M00_L01  \\n       test      r8d,r8d  \\n       jl        short M00_L 01 \\n       cmp       [ra\", \"x+8],ecx  \\n       jle       short M00_L01  \\nM00_L00:  \\n       mov       r9d,ecx  \\n       cmp       [\", \"rax+r9*4+10],edx  \\n       je        short M00_L03  \\n       dec       ecx  \\n       cmp       ecx,r8d \", \" \\n       jge       short M00_L00  \\n       jmp       short M00_L02  \\nM00_L01:  \\n       cmp       ecx,\", \"[rax+8]  \\n       jae       short M00_L04  \\n       mov       r9d,ecx  \\n       cmp       [rax+r9*4+10]\", \",edx  \\n       je        short M00_L03  \\n       dec       ecx  \\n       cmp       ecx,r8d  \\n       jge\", \"       short M00_L01  \\nM00_L02: \\n       xor       eax,eax  \\n       add       rsp,28  \\n       ret \\nM0\", \"0_L03:  \\n       mov       eax,ecx  \\n       add       rsp,28  \\n       ret \\nM00_L04:  \\n       call    \", \"  CORINFO_HELP_RNGCHKFAIL  \\n       int       3  \\n; Total bytes of code 98  \\nNotice how the code size\", \" is larger, and how there are now two variations of the loop: one at M00_L00 \\nand one at M00_L01. Th\", \"e second one, M00_L01, has a branch to that same call \\nCORINFO_HELP_RNGCHKFAIL , but the first one d\", \"oesn\\u2019t, because that loop will only end up being used \\nafter pro ving that the offset , count , and \", \"_values.Length  are such that the indexing will always be in \\nbounds.  \\nOther changes also improved \", \"loop cloning. dotnet/runtime#59886  enables the JIT to choose di fferent \\nforms for how to emit the \", \"the conditions for choosing the fast or slow loop path, e.g.  whether to emit  \\n50 CHAPTER 2 | JIT  \", \"\\n all the conditions, & them together, and then branch ( if (!(cond1 & cond2)) goto slowPath ), or \\n\", \"whether to emit each condition on its own ( if (!cond1) goto slowPath; if (!cond2) goto \\nslowPath ).\", \" dotnet/runtime#66257  enables loop cloning to kick in when the loop variable is initialized \\nto mor\", \"e kinds of expressions (e.g. for (int fromindex  = lastIndex - lengthToClear; ...) ). And \\ndotnet/ru\", \"ntime#70232  increases the JIT\\u2019s willingness to clone loops with bodies that do a broader set \\nof op\", \"erations.  \\nFolding, propagation, and substitu tion \\nConstant folding is an optimization where a com\", \"piler computes the value of an expression involving \\nonly constants at compile -time rather than gen\", \"erating the code to compute the value at run -time. \\nThere are multiple levels of constant folding i\", \"n .NET, with some constant folding performed by the C# \\ncompiler and some constant folding performed\", \" by the JIT compiler. For example, given the C# code:  \\n[Benchmark]  \\npublic int A() => 3 + (4 * 5);\", \" \\n \\n[Benchmark]  \\npublic int B() => A() * 2; \\nthe C# compiler will generate IL for these methods lik\", \"e the following:  \\n.method public hidebysig instance int32 A () cil managed  \\n{ \\n    .maxstack 8  \\n \", \"   IL_0000: ldc.i4.s 23  \\n    IL_0002: ret  \\n} \\n \\n.method public hidebysig instance int32 B () cil m\", \"anaged  \\n{ \\n    .maxstack 8  \\n    IL_0000: ldarg.0  \\n    IL_0001: call instance int32 Program::A()  \", \"\\n    IL_0006: ldc.i4.2  \\n    IL_0007: mul  \\n    IL_0008: ret  \\n} \\nYou can see that the C# compiler h\", \"as computed the value of 3 + (4*5) , as the IL for method A simply \\ncontains the equivalent of retur\", \"n 23; . However, method B contains the equivalent of return A() * \\n2;, highlighting that the constan\", \"t folding performed by the C# compiler was intramethod only. Now \\nhere\\u2019s what the JIT generates:  \\n;\", \" Program.A()  \\n       mov       eax,17  \\n       ret \\n; Total bytes of code  6 \\n \\n; Program.B()  \\n   \", \"    mov       eax,2E  \\n       ret \\n; Total bytes of code 6   \\n51 CHAPTER 2 | JIT  \\n The assembly for\", \" method A isn\\u2019t particularly interesting; it\\u2019s just returning that same value 23 (hex \\n0x17). But me\", \"thod B is more interesting. The JIT has inlined the call from B to A, exposing the contents \\nof A to\", \" B, such that the JIT effectively sees the body of B as the equivalent of return 23 * 2; . At that \\n\", \"point, the JIT can do its own constant folding, and it transforms the body of B to simply return 46 \", \"(hex \\n0x2e). Constant pr opagation is intricately linked to constant folding and is essentially just\", \" the idea that \\nyou can substitute a constant value (typically one computed via constant folding) in\", \"to further \\nexpressions, at which point they may also be able to be folded.  \\nThe JIT  has long perf\", \"ormed constant folding, but it improves further in .NET 7. One of the ways \\nconstant folding can imp\", \"rove is by exposing more values to be folded, which often means more \\ninlining. dotnet/runtime#55745\", \"  helped the inliner to understand that a method call like M(constant + \\nconstant)  (noting that tho\", \"se constants might be the result of some other method call) is itself \\npassing a constant to M, and \", \"a constant being passed to a method call  is a hint to the inliner that it \\nshould consider being mo\", \"re aggressive about inlining, since exposing that constant to the body of the \\ncallee can potentiall\", \"y significantly reduce the amount of code required to implement the callee. The \\nJIT might have prev\", \" iously inlined such a method anyway, but when it comes to inlining, the JIT is all \\nabout heuristic\", \"s and generating enough evidence that it\\u2019s worthwhile to inline something; this \\ncontributes to that\", \" evidence. This pattern shows up, for example, in the vario us FromXx  methods on \\nTimeSpan . For ex\", \"ample, TimeSpan.FromSeconds  is implemented as:  \\npublic static TimeSpan FromSeconds (double value) \", \"=> Interval (value, TicksPerSecond); // \\nTicksPerSecond is a constant  \\nand, eschewing argument vali\", \"dation for the purposes of this example, Interval  is: \\nprivate static TimeSpan Interval (double val\", \"ue, double scale) => \\nIntervalFromDoubleTicks (value * scale);  \\nprivate static TimeSpan IntervalFro\", \"mDoubleTicks (double ticks) => ticks  == long.MaxValue  ? \\nTimeSpan. MaxValue  : new TimeSpan ((long\", \")ticks);  \\nwhich if everything gets inlined means FromSeconds  is essentially:  \\npublic static TimeS\", \"pan FromSeconds (double value) \\n{ \\n    double ticks = value * 10_000_000; \\n    return ticks == long.\", \"MaxValue  ? TimeSpan. MaxValue  : new TimeSpan ((long)ticks);  \\n} \\nand if value  is a constant, let\\u2019\", \"s say 5, that whole thing can be constant folded (with dead code \\nelimination on the ticks == long.M\", \"axValue  branch) to simply:  \\nreturn new TimeSpan (50_000_000); \\nI\\u2019ll spare you the .NET 6 assembly \", \"for this, but on .NET 7 with a benchmark like:  \\n[Benchmark]  \\npublic TimeSpan FromSeconds () => Tim\", \"eSpan. FromSeconds (5); \\nwe now get the simple and clean:  \\n; Program.FromSeconds()  \\n       mov    \", \"   eax,2FAF080   \\n52 CHAPTER 2 | JIT  \\n        ret \\n; Total bytes of code 6  \\nAnother change improvi\", \"ng constant folding included dotnet/runtime#57726  from \\n[@SingleAccretion](https://github.com/Singl\", \"eAccretion), which unblocked constant folding in a \\nparticular scenario that sometimes manifests whe\", \"n doing field -by-field assignment of structs being \\nreturned from method calls. As a small example,\", \" consider this trivial property, which access the \\nColor.DarkOrange  property, which in turn does ne\", \"w Color(KnownCol or.DarkOrange) : \\n[Benchmark]  \\npublic Color DarkOrange () => Color. DarkOrange ; \\n\", \"In .NET 6, the JIT generated this:  \\n; Program.DarkOrange()  \\n       mov       eax,1  \\n       mov   \", \"    ecx,39  \\n       xor       r8d,r8d  \\n       mov       [rdx],r8  \\n       mov       [rdx+8], r8 \\n  \", \"     mov       [rdx+10],cx  \\n       mov       [rdx+12],ax  \\n       mov       rax,rdx  \\n       ret \\n;\", \" Total bytes of code 32  \\nThe interesting thing here is that some constants (39, which is the value \", \"of KnownColor.DarkOrange , \\nand 1, which is a private StateKno wnColorValid  constant) are being loa\", \"ded into registers ( mov eax, \\n1, mov ecx, 39 ) and then later being stored into the relevant locati\", \"on for the Color  struct being \\nreturned ( mov [rdx+12],ax  and mov [rdx+10],cx ). In .NET 7, it now\", \" generates:  \\n; Program.DarkOr ange() \\n       xor       eax,eax  \\n       mov       [rdx],rax  \\n     \", \"  mov       [rdx+8],rax  \\n       mov       word ptr [rdx+10],39  \\n       mov       word ptr [rdx+12]\", \",1  \\n       mov       rax,rdx  \\n       ret \\n; Total bytes of code 25  \\nwith direct assignment of the\", \"se constant values into their destination locations ( mov word ptr \\n[rdx+12],1  and mov word ptr [rd\", \"x+10],39 ). Other changes contributing to constant folding \\nincluded dotnet/runtime#58171  from [@Si\", \"ngleAccretion](https://github.com/SingleAccretion) and \\ndotnet/runtime#57605  from [@SingleAccretion\", \"]( https://github.com/SingleAccretion).  \\nHowever, a large category of improvement came from an opti\", \"mization related to propagation, that of \\nforward substitution. Consider this silly benchmark:  \\n[Be\", \"nchmark]  \\npublic int Compute1 () => Value + Value + Value + Value + Value;  \\n \\n[Benchmark]  \\npublic\", \" int Compute2 () => SomethingElse () + Value + Value + Value + Value + Value;  \\n \\nprivate static int\", \" Value => 16;  \\n53 CHAPTER 2 | JIT  \\n  \\n[MethodImpl (MethodImplOptions. NoInlining )] \\nprivate stati\", \"c int SomethingElse () => 42; \\nIf we look at the assembly code g enerated for Compute1  on .NET 6, i\", \"t looks like what we\\u2019d hope for. \\nWe\\u2019re adding Value  5 times, Value  is trivially inlined and retur\", \"ns a constant value 16, and so we\\u2019d \\nhope that the assembly code generated for Compute1  would effec\", \"tively just be returning th e value 80 \\n(hex 0x50), which is exactly what happens:  \\n; Program.Compu\", \"te1()  \\n       mov       eax,50  \\n       ret \\n; Total bytes of code 6  \\nBut Compute2  is a bit diffe\", \"rent. The structure of the code is such that the additional call to \\nSomethingElse  ends up slightly\", \" perturbing something about the JIT\\u2019s analysis, and .NET 6 ends up \\nwith this assembly code:  \\n; Pro\", \"gram.Compute2()  \\n       sub       rsp,28  \\n       call      Program.SomethingElse()  \\n       add   \", \"    eax,10  \\n       add       eax,10  \\n       add       eax,10 \\n       add       eax,10  \\n       add\", \"       eax,10  \\n       add       rsp,28  \\n       ret \\n; Total bytes of code 29  \\nRather than a singl\", \"e mov eax, 50  to put the value 0x50 into the return register, we have 5 separate \\nadd eax, 10  to b\", \"uild up that same 0x5 0 (80) value. That\\u2019s\\u2026 not ideal.  \\nIt turns out that many of the JIT\\u2019s optimiz\", \"ations operate on the tree data structures created as part of \\nparsing the IL. In some cases, optimi\", \"zations can do better when they\\u2019re exposed to more of the \\nprogram, in other words  when the tree th\", \"ey\\u2019re operating on is larger and contains more to be \\nanalyzed. However, various operations can brea\", \"k up these trees into smaller, individual ones, such as \\nwith temporary variables created as part of\", \" inlining, and in doing so can inhibit th ese operations. \\nSomething is needed in order to effective\", \"ly stitch these trees back together, and that\\u2019s forward \\nsubstitution. You can think of forward subs\", \"titution almost like an inverse of CSE; rather than trying to \\nfind duplicate expressions and elimin\", \"a te them by computing the value once and storing it into a \\ntemporary, forward substitution elimina\", \"tes that temporary and effectively moves the expression tree \\ninto its use site. Obviously you don\\u2019t\", \" want to do this if it would then negate CSE and result in \\nduplicate work, but for expressions that\", \" are defined once and used once, this kind of forward \\npropagation is valuable. dotnet/runtime#61023\", \"  added an initial limited version of forward \\nsubstitut ion, and then dotnet/runtime#63720  added a\", \" more robust generalized implementation. \\nSubsequently, dotnet/runtime#70587  expanded i t to also c\", \"over some SIMD vectors, and then \\ndotnet/runtime#71161  improved it further to enable substitutions \", \"into more places (in this case into \\ncall arguments). And with those, our silly benc hmark now produ\", \"ces the following on .NET 7:  \\n; Program.Compute2()  \\n       sub       rsp,28  \\n       call      qwo\", \"rd ptr [7FFCB8DAF9A8]   \\n54 CHAPTER 2 | JIT  \\n        add       eax,50  \\n       add       rsp,28  \\n \", \"      ret \\n; Total bytes of code 18  \\nVectorization  \\nSIMD, or Single Instruction  Multiple Data, is\", \" a kind of processing in which one instruction applies to \\nmultiple pieces of data at the same time.\", \" You\\u2019ve got a list of numbers and you want to find the index \\nof a particular value? You could walk \", \"the list comparing one element at a time , and that would be fine \\nfunctionally. But what if in the \", \"same amount of time it takes you to read and compare one element, \\nyou could instead read and compar\", \"e two elements, or four elements, or 32 elements? That\\u2019s SIMD, \\nand the art of utilizing SIMD instru\", \" ctions is lovingly referred to as \\u201cvectorization,\\u201d where operations \\nare applied to all of the elem\", \"ents in a \\u201cvector\\u201d at the same time.  \\n.NET has long had support for vectorization in the form of Ve\", \"ctor<T> , which is an easy -to-use type \\nwith first -class JIT s upport to enable a developer to wri\", \"te vectorized implementations. One of \\nVector<T> \\u2019s greatest strengths is also one of its greatest w\", \"eaknesses. The type is designed to adapt to \\nwhatever width vector instructions are available in you\", \"r hardware. If the machi ne supports 256 -bit \\nwidth vectors, great, that\\u2019s what Vector<T>  will tar\", \"get. If not, if the machine supports 128 -bit width \\nvectors, great, that\\u2019s what Vector<T>  targets.\", \" But that flexibility comes with various downsides, at least \\ntoday; for example, the op erations yo\", \"u can perform on a Vector<T>  end up needing to be agnostic to \\nthe width of the vectors used, since\", \" the width is variable based on the hardware on which the code \\nactually runs. And that means the op\", \"erations that can be exposed on Vector<T>  are li mited, which in \\nturn limits the kinds of operatio\", \"ns that can be vectorized with it. Also, because it\\u2019s only ever a single \\nsize in a given process, s\", \"ome data set sizes that fall in between 128 bits and 256 bits might not be \\nprocessed as well as you\", \"\\u2019d hope. You write your Vector<byte> -based algorithm, and you run it on a \\nmachine with support for\", \" 256 -bit vectors, which means it can process 32 bytes at a time, but then you \\nfeed it an input wit\", \"h 31 bytes. Had Vector<T>  mapped to 128 -bit vectors, it could have be en used to \\nimprove the proc\", \"essing of that input, but as its vector size is larger than the input data size, the \\nimplementation\", \" ends up falling back to one that\\u2019s not accelerated. There are also issues related to \\nR2R and Nativ\", \"e AOT, since ahead -of-time comp ilation needs to know in advance what instructions \\nshould be used \", \"for Vector<T>  operations. You already saw this earlier when discussing the output of \\nDOTNET_JitDis\", \"asmSummary ; we saw that the NarrowUtf16ToAscii  method was one of only a few \\nmethods that was  JIT\", \" compiled in a \\u201chello, world\\u201d console app, and that this was because it lacked R2R \\ncode due to its \", \"use of Vector<T> . \\nStarting in .NET Core 3.0, .NET gained literally thousands of new \\u201chardware intr\", \"insics\\u201d methods, most \\nof which are .NET APIs that map d own to one of these SIMD instructions. Thes\", \"e intrinsics enable an \\nexpert to write an implementation tuned to a specific instruction set, and i\", \"f done well, get the best \\npossible performance, but it also requires the developer to understand ea\", \"ch instruction set and to \\nimplement their algorithm for each instruction set that might be relevant\", \", e.g.  an AVX2 \\nimplementation if it\\u2019s supported, or an SSE2 implementation if it\\u2019s supported, or a\", \"n ArmBase \\nimplementation if it\\u2019s supported, and so on.  \\n.NET 7 ha s introduced a middle ground. Pr\", \"evious releases saw the introduction of the Vector128<T>  \\nand Vector256<T>  types, but purely as th\", \"e vehicle by which data moved in and out of the hardware \\nintrinsics, since they\\u2019re all tied to spec\", \"ific width vectors. Now in . NET 7, exposed via  \\n55 CHAPTER 2 | JIT  \\n dotnet/runtime#53450 , dotne\", \"t/runtime#63414 , dotnet/runtime#60094 , and dotnet/runtime#68559 , a \\nvery large set of cross -plat\", \"form operations is defined over these types as well, e.g. \\nVector128<T>.ExtractMostSignificantBits ,\", \" Vector256.ConditionalSelect , and so on. A \\ndeveloper who wants or needs to go beyond what the high\", \" -level Vector<T>  offers can choose to \\ntarget one or more of these two types. Typically this would\", \" amount to a developer writing one code \\npath based on Vector12 8<T> , as that has the broadest reac\", \"h and achieves a significant amount of the \\ngains from vectorization, and then if is motivated to do\", \" so can add a second path for Vector256<T>  in \\norder to potentially double throughput further on pl\", \"atforms that have 256 -bit width vectors. Think of \\nthese types and methods as a platform -abstracti\", \"on layer: you code to these methods, and then the JIT \\ntranslates them into the most appropriate ins\", \"tructions for the underlying platform. Consider this \\nsimple code as an example:  \\nusin g System.Run\", \"time.CompilerServices ; \\nusing System.Runtime.Intrinsics ; \\nusing System.Runtime.Intrinsics .X86; \\n \", \"\\ninternal  class Program \\n{ \\n    private static void Main() \\n    { \\n        Vector128< byte> v = Vec\", \"tor128. Create((byte)123); \\n        while (true) \\n        { \\n            WithIntrinsics (v); \\n      \", \"      WithVector (v); \\n        } \\n    } \\n \\n    [MethodImpl (MethodImplOptions. NoInlining )] \\n    pr\", \"ivate static int WithIntrinsics (Vector128< byte> v) => Sse2. MoveMask (v); \\n \\n    [MethodImpl (Meth\", \"odImplOptions. NoInlining )] \\n    private static uint WithVector (Vector128< byte> v) => v. ExtractM\", \"ostSignificantBits (); \\n} \\nI have two functions: one that directly uses the Sse2.MoveMask  hardware \", \"intrinsic and one that uses \\nthe new Vector128<T>.ExtractMostSignificantBits  method. Using DOTNET_J\", \"itDisasm=Program.* , \\nhere\\u2019s what the optimized tier -1 code for these looks like on my x64 Windows \", \"machine:  \\n; Assembly listing for method Program:WithIntrinsics(Vector128`1):int  \\nG_M000_IG01:     \", \"           ;; offset=0000H  \\n       C5F877               vzeroup per \\n \\nG_M000_IG02:                \", \";; offset=0003H  \\n       C5F91001             vmovupd  xmm0, xmmword ptr [rcx]  \\n       C5F9D7C0    \", \"         vpmovmskb eax, xmm0  \\n \\nG_M000_IG03:                ;; offset=000BH  \\n       C3            \", \"       ret  \\n \\n; Total bytes of cod e 12 \\n \\n; Assembly listing for method Program:WithVector(Vector1\", \"28`1):int  \\nG_M000_IG01:                ;; offset=0000H  \\n       C5F877               vzeroupper  \\n \", \" \\n56 CHAPTER 2 | JIT  \\n G_M000_IG02:                ;; offset=0003H  \\n       C5F91001             vm\", \"ovupd  xmm0, xmmword ptr [ rcx] \\n       C5F9D7C0             vpmovmskb eax, xmm0  \\n \\nG_M000_IG03:   \", \"             ;; offset=000BH  \\n       C3                   ret  \\n \\n; Total bytes of code 12  \\nNotice\", \" anything? The code for the two methods is identical, both resulting in a vpmovmskb  (Move Byte  \\nMa\", \"sk) instruction. Yet the former code will only work on a platform that supports SSE2 whereas the \\nla\", \"tter code will work on any platform with support for 128 -bit vectors, including Arm64 and WASM \\n(an\", \"d any future platforms on -boarded that also support SIMD ); it\\u2019ll just result in different instruct\", \"ions \\nbeing emitted on those platforms.  \\nTo explore this a bit more, let\\u2019s take a simple example an\", \"d vectorize it. We\\u2019ll implement a Contains  \\nmethod, where we want to search a span of bytes for a s\", \"pecific value and r eturn whether it was found:  \\nstatic bool Contains (ReadOnlySpan< byte> haystack\", \", byte needle) \\n{ \\n    for (int i = 0; i < haystack. Length; i++) \\n    { \\n        if (haystack[i] ==\", \" needle)  \\n        { \\n            return true; \\n        } \\n    } \\n \\n    return false; \\n} \\nHow would \", \"we vectorize this with Vector<T> ? First things first, we need to check whether it\\u2019s even \\nsupported\", \", and fall back to our existing implementation if it\\u2019s not ( Vector.IsHardwareAccelerated ). \\nWe als\", \"o need to fall back if the length of the input is l ess than the size of a vector \\n(Vector<byte>.Cou\", \"nt ). \\nstatic bool Contains (ReadOnlySpan< byte> haystack, byte needle) \\n{ \\n    if (Vector. IsHardwa\", \"reAccelerated  && haystack. Length >= Vector< byte>.Count) \\n    { \\n        // ... \\n    } \\n    else \\n\", \"    { \\n        for (int i = 0; i < haystack. Length; i++) \\n        { \\n            if (haystack[i] ==\", \" needle)  \\n            { \\n                return true; \\n            } \\n        } \\n    } \\n \\n    retur\", \"n false; \\n}  \\n57 CHAPTER 2 | JIT  \\n Now that we know we h ave enough data, we can get to coding our \", \"vectorized loop. In this loop, we\\u2019ll \\nbe searching for the needle , which means we need a vector tha\", \"t contains that value for every element; \\nthe Vector<T> \\u2019s constructor provides that ( new Vector<by\", \"te>(needle) ). And w e need to be able to \\nslice off a vector\\u2019s width of data at a time; for a bit m\", \"ore efficiency, I\\u2019ll use pointers. We need a current \\niteration pointer, and we need to iterate unti\", \"l the point where we couldn\\u2019t form another vector \\nbecause we\\u2019re too close to th e end, and a straig\", \"htforward way to do that is to get a pointer that\\u2019s \\nexactly one vector\\u2019s width from the end; that w\", \"ay, we can just iterate until our current pointer is equal \\nto or greater than that threshold. And f\", \"inally, in our loop body, we need to co mpare our current \\nvector with the target vector to see if a\", \"ny elements are the same ( Vector.EqualsAny ), if any is \\nreturning true, and if not bumping our cur\", \"rent pointer to the next location. At this point we have:  \\nstatic unsafe bool Contains (ReadOnlySpa\", \"n< byte> haystack, byte needle) \\n{ \\n    if (Vector. IsHardwareAccelerated  && haystack. Length >= Ve\", \"ctor< byte>.Count) \\n    { \\n        fixed (byte* haystackPtr = &MemoryMarshal. GetReference (haystack\", \"))  \\n        { \\n            Vector<byte> target = new Vector<byte>(needle ); \\n            byte* curr\", \"ent = haystackPtr;  \\n            byte* endMinusOneVector = haystackPtr + haystack. Length - Vector<b\", \"yte>.Count; \\n            do \\n            { \\n                if (Vector. EqualsAny (target, *(Vector<\", \" byte>*)current))  \\n                { \\n                    return true; \\n                } \\n \\n      \", \"          current += Vector< byte>.Count; \\n            } \\n            while (current < endMinusOneVe\", \"ctor);  \\n \\n            // ... \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i < haysta\", \"ck. Length; i++) \\n        { \\n            if (haystack[i] == needle)  \\n            { \\n               \", \" return true; \\n            } \\n        } \\n    } \\n \\n    return false; \\n} \\nAnd we\\u2019re almost done. The l\", \"ast issue to handle is we may still have a few elements at the end we \\nhaven\\u2019t searched. There are a\", \" couple of ways we could handle that. One would be to just continue \\nwith our fall back implementati\", \"on and process each of the remaining elements one at a time. Another \\nwould be to employ a trick tha\", \"t\\u2019s co mmon when vectorizing idempotent operations. Our operation \\nisn\\u2019t mutating anything, which me\", \"ans it doesn\\u2019t matter if we compare the same element multiple \\ntimes, which means we can just do one\", \" final vector compare for the last vector in the search space;  \\n58 CHAPTER 2 | JIT  \\n that might or\", \" might not overlap with elements we\\u2019ve already looked at, but it won\\u2019t hurt anything if it \\ndoes. An\", \"d with that, our implementation is complete:  \\nstatic unsafe bool Contains (ReadOnlySpan< byte> hays\", \"tack, byte needle) \\n{ \\n    if (Vector. IsHardwareAcce lerated && haystack. Length >= Vector< byte>.C\", \"ount) \\n    { \\n        fixed (byte* haystackPtr = &MemoryMarshal. GetReference (haystack))  \\n        \", \"{ \\n            Vector<byte> target = new Vector<byte>(needle);  \\n            byte* current = haystac\", \"kPtr;  \\n            byte* endMinusOneVector = haystackPtr + haystack. Length - Vector<byte>.Count; \\n\", \"            do \\n            { \\n                if (Vector. EqualsAny (target, *(Vector< byte>*)curre\", \"nt))  \\n                { \\n                    return true; \\n                } \\n \\n                cur\", \"rent += Vector< byte>.Count; \\n            } \\n            while (current < endMinusOneVector);  \\n \\n  \", \"          if (Vector. EqualsAny (target, *(Vector< byte>*)endMinusOneVector))  \\n            { \\n     \", \"           return true; \\n            } \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i\", \" < haystack. Length; i++) \\n        { \\n            if (haystack[i] == needle)  \\n            { \\n      \", \"          return true; \\n            } \\n        } \\n    } \\n \\n    return false; \\n} \\nCongratulations, we\", \"\\u2019ve vectorized this operation, and fairly decently at that. We can throw this into \\nbenchmarkdotnet \", \"and see really nice speedups:  \\nprivate byte[] _data = Enumerable. Repeat((byte)123, 999).Append((by\", \"te)42).ToArray(); \\n \\n[Benchmark (Baseline = true)] \\n[Arguments ((byte)42)] \\npublic bool Find(byte va\", \"lue) => Contains (_data, value); // just the fallback path in its \\nown method  \\n \\n[Benchmark]  \\n[Arg\", \"uments ((byte)42)] \\npublic bool FindVectorized (byte value) => Contains_Vectorized (_data, value); /\", \"/ the \\nimplementation we just wr ote \\n   \\n59 CHAPTER 2 | JIT  \\n Method  Mean  Ratio  \\nFind 484.05 ns\", \"  1.00 \\nFindVectorized  20.21 ns  0.04 \\nA 24x speedup! Woo hoo, victory, all your performance are be\", \"long to us!  \\nYou deploy this in your service, and you see Contains  being called on your hot path, \", \"but you don\\u2019t \\nsee the improvements you were expecting. You dig in a little more, and you discover t\", \"hat while you \\ntested this with an input array with 1000 elements, typical inputs had more like 30 e\", \"lements. What \\nhappens if we change our benchmark to have just 30 elements? That\\u2019 s not long enough \", \"to form a \\nvector, so we fall back to the one -at-a-time path, and we don\\u2019t get any speedups at all.\", \"  \\nOne thing we can now do is switch from using Vector<T>  to Vector128<T> . That will then lower th\", \"e \\nthreshold from 32 bytes to 16 bytes, such that inputs in that range will still have some amount o\", \"f \\nvectorization applied. As these Vector128<T>  and Vector256<T>  types have been designed very \\nre\", \"cently, they also utilize all the cool new toys, and thus we can use refs instead of pointers. Other\", \" \\nthan that, we can keep the shape of our implementation almost the same, substituting Vector128  \\nw\", \"here we were using Vector , and using some methods on Unsafe  to manipulate our refs instead of \\npoi\", \"nter arithmetic on the span we fixed.  \\nstatic unsafe bool Contains (ReadOnlySpan< byte> haystack, b\", \"yte needle) \\n{ \\n    if (Vector128. IsHardwareAccelerated  && haystack. Length >= Vector128< byte>.Co\", \"unt) \\n    { \\n        ref byte current = ref MemoryMarshal. GetReference (haystack);  \\n \\n        Vect\", \"or128< byte> target = Vector128. Create(needle); \\n        ref byte endMinusOneVector = ref Unsafe.Ad\", \"d(ref current, haystack. Length - \\nVector128< byte>.Count); \\n        do \\n        { \\n            if (\", \"Vector128. EqualsAny (target, Vector128. LoadUnsafe (ref current)))  \\n            { \\n               \", \" return true; \\n            } \\n \\n            current = ref Unsafe.Add(ref current, Vector128< byte>.C\", \"ount); \\n        } \\n        while (Unsafe. IsAddressLessThan (ref current, ref endMinusOneVector));  \", \"\\n \\n        if (Vector128. EqualsAny (target, Vector128 .LoadUnsafe (ref endMinusOneVector)))  \\n     \", \"   { \\n            return true; \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i < hayst\", \"ack. Length; i++) \\n        { \\n            if (haystack[i] == needle)  \\n            { \\n              \", \"  return true; \\n            } \\n        } \\n    }  \\n60 CHAPTER 2 | JIT  \\n  \\n    return false; \\n} \\nWith\", \" that in hand, we can now try it on our smaller 30 element data set:  \\nprivate byte[] _data = Enumer\", \"able. Repeat((byte)123, 29).Append((byte)42).ToArray(); \\n \\n[Benchmark (Baseline = true)] \\n[Arguments\", \" ((byte)42)] \\npublic bool Find(byte value) => Contains (_data, value);  \\n \\n[Benchmark]  \\n[Arguments \", \"((byte)42)] \\npublic bool FindVectorized (byte value) => Contains_Vectorized (_data, value);  \\nMethod\", \"  Mean  Ratio  \\nFind 15.388 ns  1.00 \\nFindVectorized  1.747 ns  0.11 \\nWoo hoo, victory, all your per\", \"formance are belong to us\\u2026 again!  \\nWhat about on the larger data set again? Previously with Vector<\", \"T>  we had a 24x speedup, but now:  \\nMethod  Mean  Ratio  \\nFind 484.25 ns  1.00 \\nFindVectorized  32.\", \"92 ns  0.07 \\n\\u2026 closer to 15x. Nothing to sneeze at, but it\\u2019s not the 24x we previously saw. What if \", \"we want to have \\nour cake and eat it, too? Let\\u2019s also add a Vector256<T>  path. To do that, we liter\", \"ally copy/paste our \\nVector128<T>  code, search/replace all references to  Vector128  in the copied \", \"code with Vector256 , \\nand just put it into an additional condition that uses the Vector256<T>  path\", \" if it\\u2019s supported and there \\nare enough elements to utilize it.  \\nstatic unsafe bool Contains (Read\", \"OnlySpan< byte> haystack, byte needle) \\n{ \\n    if (Vector128. IsHardwareAccelerated  && haystack. Le\", \"ngth >= Vector128< byte>.Count) \\n    { \\n        ref byte current = ref MemoryMarshal. GetReference (\", \"haystack);  \\n             \\n        if (Vector256. IsHardwareAccelerated  && haystack. Length >= Vect\", \"or256< byte>.Count) \\n        { \\n            Vector256< byte> target = Vector256. Create(needle);  \\n \", \"           ref byte endMinusOneVector = ref Unsafe.Add(ref current, haystack. Length - \\nVector256< b\", \"yte>.Count); \\n            do \\n            { \\n                if (Vector256. EqualsAny (target, Vecto\", \"r256. LoadUnsafe (ref current)))  \\n                { \\n                    return true; \\n            \", \"    } \\n \\n                current = ref Unsafe.Add(ref current, Vector256< byte>.Count); \\n           \", \" } \\n            while (Unsafe. IsAddressLessThan (ref current, ref endMinusOneVector));   \\n61 CHAPTE\", \"R 2 | JIT  \\n  \\n            if (Vector256. EqualsAny (target, Vector256. LoadUnsafe (ref endMinusOneV\", \"ector)))  \\n            { \\n                return true; \\n            } \\n        } \\n        else \\n    \", \"    { \\n            Vector128< byte> target = Vector128. Create(needle);  \\n            ref byte endMi\", \"nusOneVector = ref Unsafe.Add(ref current, haystack. Length - \\nVector128< byte>.Count); \\n           \", \" do \\n            { \\n                if (Vector128. EqualsAny (target, Vector128. LoadUnsafe(ref curr\", \"ent)))  \\n                { \\n                    return true; \\n                } \\n \\n                c\", \"urrent = ref Unsafe.Add(ref current, Vector128< byte>.Count); \\n            } \\n            while (Uns\", \"afe. IsAddressLessThan (ref current, ref endMinusOneVector));  \\n \\n            if (Vector128. EqualsA\", \"ny (target, Vector128. LoadUnsafe (ref endMinusOneVector)))  \\n            { \\n                return \", \"true; \\n            } \\n        } \\n    } \\n    else \\n    { \\n        for (int i = 0; i < haystack. Lengt\", \"h; i++) \\n        { \\n            if (haystack[i] == needle)  \\n            { \\n                return t\", \"rue; \\n            } \\n        } \\n    } \\n \\n    return false; \\n} \\nAnd, boom, we\\u2019re back:  \\nMethod  Mean\", \"  Ratio  \\nFind 484.53 ns  1.00 \\nFindVectorized  20.08 ns  0.04 \\nWe now have an implementation that i\", \"s vectorized on any platform with either 128 -bit or 256 -bit \\nvector instructions (x86, x64, Arm64,\", \" WASM, etc.), that can use either based on the input length, and \\nthat can be included in an R2R ima\", \"ge if that\\u2019s of interest.  \\nThere are many factors that impact which path you go down, and I expect \", \"we\\u2019ll have guidance \\nforthcoming to help navigate all the factors and approaches. But the capabiliti\", \"es are all there, and \\nwhether you choose to use Vector<T> , Vector128<T>  and/or Vector256<T> , or \", \"the hardware \\nintrinsics directly, there are some amazing performance opportunities ready for the ta\", \"king.   \\n62 CHAPTER 2 | JIT  \\n I already mentioned several PRs that exposed the new cross -platform \", \"vector support, but that only \\nscratches the surface of the work done to actually enable these opera\", \"tions and to enable them to \\nproduce high -quality code. As just one example of a category of such w\", \"ork, a set of changes went in \\nto help ensure that zero vector constants are handled well, such as d\", \"otnet/runtime#63821  that \\n\\u201cmorphed\\u201d (changed) Vector128/256<T>.Create(default)  into Vector128/256<\", \"T>.Zero , which then \\nenables subsequent optimizations to focus only on Zero ; dotnet/runtime#65028 \", \" that enabled \\nconstant propagation of Vector128/256<T>.Zero ; dotnet/runtime#68874  and dotnet/ru n\", \"time#70171  \\nthat add first -class knowledge of vector constants to the JIT\\u2019s intermediate represent\", \"ation; and \\ndotnet/runtime#62933 , dotnet/runtime#65632 , dotnet/runtime#55875 , dotnet/runtime#6750\", \"2 , and \\ndotnet/runtime#64783  that all improve the code quality of instructions generated for zero \", \"vector \\ncomparisons.  \\nInlining  \\nInlining is one of the most important optimizations the JIT can do\", \". The con cept is simple: instead of \\nmaking a call to some method, take the code from that method a\", \"nd bake it into the call site. This has \\nthe obvious advantage of avoiding the overhead of a method \", \"call, but except for really small methods \\non really hot paths, that\\u2019 s often on the smaller side of\", \" the wins inlining brings. The bigger wins are \\ndue to the callee\\u2019s code being exposed to the caller\", \"\\u2019s code, and vice versa. So, for example, if the \\ncaller is passing a constant as an argument to the\", \" callee, if the method isn\\u2019t  inlined, the compilation of \\nthe callee has no knowledge of that const\", \"ant, but if the callee is inlined, all of the code in the callee is \\nthen aware of its argument bein\", \"g a constant value, and can do all of the optimizations possible with \\nsuch a constant, like dead co\", \"de elimination, branch elimination, constant folding and propagation, \\nand so on. Of course, if it w\", \"ere all rainbows and unicorns, everything possible to be inlined would be \\ninlined, and that\\u2019s obvio\", \"usly not happening. Inlining brings with it th e cost of potentially increased \\nbinary size. If the \", \"code being inlined would result in the same amount or less assembly code in the \\ncaller than it take\", \"s to call the callee (and if the JIT can quickly determine that), then inlining is a no -\\nbrainer. B\", \"ut if t he code being inlined would increase the size of the callee non -trivially, now the JIT \\nnee\", \"ds to weigh that increase in code size against the throughput benefits that could come from it. \\nTha\", \"t code size increase can itself result in throughput regressions, d ue to increasing the number of \\n\", \"distinct instructions to be executed and thereby putting more pressure on the instruction cache. As \", \"\\nwith any cache, the more times you need to read from memory to populate it, the less effective the \", \"\\ncache will be. If you have  a function that gets inlined into 100 different call sites, every one o\", \"f those \\ncall sites\\u2019 copies of the callee\\u2019s instructions are unique, and calling each of those 100 f\", \"unctions could \\nend up thrashing the instruction cache; in contrast, if all of those 1 00 functions \", \"\\u201cshared\\u201d the same \\ninstructions by simply calling the single instance of the callee, it\\u2019s likely the\", \" instruction cache would be \\nmuch more effective and lead to fewer trips to memory.  \\nAll that is to\", \" say, inlining is really  important, it\\u2019s import ant that the \\u201cright\\u201d things be inlined and that it \", \"\\nnot overinline, and as such every release of .NET in recent memory has seen nice improvements \\narou\", \"nd inlining. .NET 7 is no exception.  \\nOne really interesting improvement around inlining is dotnet/\", \"runtime#64521 , and it might be \\nsurprising. Consider the Boolean.ToString  method; here\\u2019s its full \", \"implementation:  \\npublic override  string ToString () \\n{  \\n63 CHAPTER 2 | JIT  \\n     if (!m_value) r\", \"eturn \\\"False\\\"; \\n    return \\\"True\\\"; \\n} \\nPretty simple, right? You\\u2019d expect something this trivial to \", \"be inlined. Alas, on .NET 6, this benchmark:  \\nprivate bool _value = true; \\n \\n[Benchmark]  \\npublic i\", \"nt BoolStringLength () => _value. ToString ().Length; \\nproduces this assembly code:  \\n; Program.Bool\", \"StringLength()  \\n       sub       rsp,28  \\n       cmp       [rcx],ecx  \\n       add       rcx,8  \\n   \", \"    call      System.Boolean.ToString()  \\n       mov       eax,[rax+8]  \\n       add       rsp,28  \\n \", \"      ret \\n; Total bytes of code 23  \\nNote the call System.Bo olean.ToString() . The reason for this\", \" is, historically, the JIT has been \\nunable to inline methods across assembly boundaries if those me\", \"thods contain string literals (like the \\n\\\"False\\\"  and \\\"True\\\"  in that Boolean.ToString  implementati\", \"on). This restriction ha d to do with string \\ninterning and the possibility that such inlining could\", \" lead to visible behavioral differences. Those \\nconcerns are no longer valid, and so this PR removes\", \" the restriction. As a result, that same benchmark \\non .NET 7 now produces this:  \\n; Program.BoolStr\", \"ingLength()  \\n       cmp       byte ptr [rcx+8],0  \\n       je        short M00_L01  \\n       mov     \", \"  rax,1DB54800D20  \\n       mov       rax,[rax]  \\nM00_L00:  \\n       mov       eax,[rax+8]  \\n       re\", \"t \\nM00_L01:  \\n       mov       rax,1DB54800D18  \\n       mov       rax,[rax]  \\n       jmp       short\", \" M00_L00  \\n; Total bytes of code 38  \\nNo more call System.Boolean.ToString() . \\ndotnet/runtime#61408\", \"  made two changes related to inlining. First, it taught the i nliner how to better \\nsee the what me\", \"thods were being called in an inlining candidate, and in particular when tiered \\ncompilation is disa\", \"bled or when a method would bypass tier -0 (such as a method with loops before \\nOSR existed or with \", \"OSR disabled); by under standing what methods are being called, it can better \\nunderstand the cost o\", \"f the method, e.g.  if those method calls are actually hardware intrinsics with a \\nvery low cost. Se\", \"cond, it enabled CSE in more cases with SIMD vectors.  \\ndotnet/runtime#71778  also impacted inlining\", \", and in particular in situations where a typeof()  could \\nbe propagated to the callee (e.g.  via a \", \"method argument). In previous releases of .NET, various  \\n64 CHAPTER 2 | JIT  \\n members on Type  lik\", \"e IsValueType  were turned into JIT intrinsics, such that the JIT could substitute a \\nconstant value\", \" for calls where it could compute the answer at compile time. For example, this:  \\n[Benchmark]  \\npub\", \"lic bool IsValueType () => IsValueType< int>(); \\n \\nprivate static bool IsValueType<T>() => typeof(T)\", \".IsValueType ; \\nresults in this assembly code on .NET 6:  \\n; Program.IsValueType()  \\n       mov     \", \"  eax,1  \\n       ret \\n; Total bytes of code 6  \\nHowever, change the benchmark slightly:  \\n[Benchmark\", \"]  \\npublic bool IsValueType () => IsValueTyp e(typeof(int)); \\n \\nprivate static bool IsValueType (Typ\", \"e t) => t. IsValueType ; \\nand it\\u2019s no longer as simple:  \\n; Program.IsValueType()  \\n       sub      \", \" rsp,28  \\n       mov       rcx,offset MT_System.Int32  \\n       call      CORINFO_HELP_TYPEHANDLE_TO_\", \"RUNTIMETYPE  \\n       mov       rcx,rax  \\n       mov       rax,[7FFCA47C9560]  \\n       cmp       [rcx\", \"],ecx  \\n       add       rsp,28  \\n       jmp       rax  \\n; Total bytes of code 38  \\nEffectively, as \", \"part of inlining the JIT l oses the notion that the argument is a constant and fails to \\npropagate i\", \"t. This PR fixes that, such that on .NET 7, we now get what we expect:  \\n; Program.IsValueType()  \\n \", \"      mov       eax,1  \\n       ret \\n; Total bytes of code 6  \\nArm64  \\nA huge amount of effort i n .N\", \"ET 7 went into making code gen for Arm64 as good or better than its \\nx64 counterpart. I\\u2019ve already d\", \"iscussed a bunch of PRs that are relevant regardless of architecture, and \\nothers that are specific \", \"to Arm, but there are plenty more. To rattle off some of them:  \\n\\u2022 Addressing modes . \\u201cAddressing mo\", \"de\\u201d is the term used to refer to how the operand of \\ninstructions are specified. It could be the act\", \"ual value, it could be the address from where a value \\nshould be loaded, it could be the register co\", \"ntaining the valu e, and so on. Arm supports a \\n\\u201cscaled\\u201d addressing mode, typically used for indexin\", \"g into an array, where the size of each \\nelement is supplied and the instruction \\u201cscales\\u201d the provid\", \"ed offset by the specified scale. \\ndotnet/runtime#60808  enables the JIT to utilize this addressing \", \"mode. More generally, \\ndotnet/runtime#70749  enables the JIT to use addressing modes when accessing \", \"elements  of  \\n65 CHAPTER 2 | JIT  \\n managed arrays. dotnet/runtime#66902  improves the use of addre\", \"ssing modes when the \\nelement type is byte . dotnet/runtime#6546 8 improves addressing modes used fo\", \"r floating point. \\nAnd dotnet/runtime#67490  implements addressing modes for SIMD vectors, specifica\", \"lly for \\nloads with unscaled indices.  \\n\\u2022 Better instruction selection . Various techniques go into \", \"ensuring that the best instructions are \\nselected to represent input code. dotnet/runtime#61037  tea\", \"ches the JIT how to recognize the \\npattern (a * b) + c  with integers and fold that into a single ma\", \"dd  or msub  instruction, while \\ndotnet/runtime#66621  does the same for a - (b * c)  and msub . dot\", \"net/runtime#61045  \\nenables the JIT to recognize certain constant bit shift operations (either expli\", \"cit in the code or \\nimplicit to various forms of managed array access) and emit sbfiz /ubfiz  instru\", \"ctions. \\ndotnet/runtime#70599 , dotnet/runtime#66407 , and dotnet/runtime#655 35 all handle various \", \"\\nforms of optimizing a % b . dotnet/runtime#61847  from \\n[@SeanWoo](https://github.com/SeanWoo) remo\", \"ves an unnecessary movi  emitted as part of \\nsetting a dereferenced pointer to a constant value. dot\", \"net/runtime#57926  from \\n[@SingleAccretion](https://github.com/SingleAccretion) enables computing a \", \"64 -bit result as the \\nmultiplication of two 32 -bit integers to be done with smull /umull . And dot\", \"net/runtime#61549  \\nfolds adds with sign extension or zero extension into a single add instruction w\", \"ith \\nuxtw /sxtw /lsl, while dotnet/runtime#62630  drops redundant zero extensions after a ldr \\ninstr\", \"uction.  \\n\\u2022 Vectorization . dotnet/runtime#64864  adds new \\nAdvSimd.LoadPairVector64 /AdvSimd.LoadPa\", \"irVector12 8 hardware intrinsics.  \\n\\u2022 Zeroing . Lots of operations require state to be set to zero, \", \"such as initializing all reference locals \\nin a method to zero as part of the method\\u2019s prologue (so \", \"that the GC doesn\\u2019t see and try to \\nfollow garbage references). While such  functionality was previo\", \"usly vectorized, \\ndotnet/runtime#63422  enables this to be implemented using 128 -bit width vector i\", \"nstructions \\non Arm. And dotnet/runtime#64481  changes the instruction sequences used for zeroing in\", \" order \\nto avoid unnecessary zeroing, free up additional registers, and enable the CPU to recognize \", \"\\nvarious instruction sequences and better optimize.  \\n\\u2022 Memory Model . dotnet/runtime#62895  enables\", \" store barriers to be used wherever possible \\ninstead of full barriers, and uses one -way barriers f\", \"or volatile  variables. dotnet/runtime#67384  \\nenables volatile reads/writes to be implemented with \", \"the ldapr  instruction, while \\ndotnet/runtime#64354  uses a  cheaper instruction sequence to handle \", \"volatile indirections. \\nThere\\u2019s dotnet/runtime#70600 , which enables LSE Atomics to be used for Inte\", \"rlocked  \\noperations; dotnet/runtime#71512 , which enables using the atomics  instruction on Unix \\nm\", \"achines; and dotnet/runtime#70921 , which enables the same but on Windows.  \\nJIT helpers  \\nWhile log\", \"ically part of the runtime, the JIT is actually isolated from the rest of the runtime, only \\ninterac\", \"ting with it through an interface that enables communication between the JIT and the rest of \\nthe VM\", \" (Virtual Machine). There\\u2019s a large amount of VM f unctionality then that the JIT relies on for \\ngoo\", \"d performance.  \\ndotnet/runtime#65738  rewrote various \\u201cstubs\\u201d to be more efficient. Stubs are tiny \", \"bits of code that \\nserve to perform some check a nd then redirect execution somewhere else. For exam\", \"ple, when an \\ninterface dispatch call site is expected to only ever be used with a single implementa\", \"tion of that \\ninterface, the JIT might employ a \\u201cdispatch stub\\u201d that compares the type of the object\", \" agains t the  \\n66 CHAPTER 2 | JIT  \\n single one it\\u2019s cached, and if they\\u2019re equal simply jumps to t\", \"he right target. You know you\\u2019re in the \\ncorest of the core areas of the runtime when a PR contains \", \"lots of assembly code for every \\narchitecture the runtime targets. And it paid off; there\\u2019 s a virtu\", \"al group of folks from around .NET that \\nreview performance improvements and regressions in our auto\", \"mated performance test suites, and \\nattribute these back to the PRs likely to be the cause (this is \", \"mostly automated but requires some \\nhuman oversigh t). It\\u2019s always nice then when a few days after a\", \" PR is merged and performance \\ninformation has stabilized that you see a rash of comments like there\", \" were on this PR:  \\n \\nFor anyone familiar with generics and interested in performance, you may have \", \"heard the refrain that \\ngeneric virtual methods are relatively expensive. They are, comparatively. F\", \"or example on .NET 6, this \\ncode:  \\nprivate Example _example = new Example(); \\n \\n[Benchmark (Baselin\", \"e = true)] public void GenericNonVirtual () => \\n_example. GenericNonVirtual <Example>();  \\n[Benchmar\", \"k] public void GenericVirtual () => _example. GenericVirtual <Example>();  \\n \\nclass Example \\n{ \\n    \", \"[MethodImpl (MethodImplOptions. NoInlining )] \\n    public void GenericNonVirtual<T>() { }  \\n \\n    [M\", \"ethodImpl (MethodImplOptions. NoInlining )] \\n    public virtual void GenericVirtual<T>() { }  \\n} \\nre\", \"sults in:  \\n  \\n \\n67 CHAPTER 2 | JIT  \\n Method  Mean  Ratio  \\nGenericNonVirtual  0.4866 \\nns 1.00 \\nGen\", \"ericVirtual  6.4552 \\nns 13.28  \\ndotnet/runtime#65926  eases the pain a tad. Some of the cost comes f\", \"rom looking up some cached \\ninformation in a hash table in the runtime, and as is the case with many\", \" map implementations, this \\none involves computing a hash code and using a mod operation to map to t\", \"he right bucket. Other \\nhash table implementations around dotnet/runtime , including Dictionary<,> ,\", \" HashSet<,> , and \\nConcurrentDictiona ry<,>  previously switched to a \\u201cfastmod\\u201d  implementation; thi\", \"s PR does the same \\nfor this EEHashtable , which is used as part  of the CORINFO_GENERIC_HANDLE  JIT\", \" helper function \\nemployed:  \\nMethod  Runtime  Mean  Ratio  \\nGenericVirtual  .NET 6.0  6.475 ns  1.0\", \"0 \\nGenericVirtual  .NET 7.0  6.119 ns  0.95 \\nNot enough of an improvement for us to start recommendi\", \"ng people use them, but a 5% \\nimprovement takes a bit of the edge off the sting.  \\nGrab Bag  \\nIt\\u2019s n\", \"ear impossible to cover every performance change that goes into the JIT, and I\\u2019m not going to \\ntry. \", \"But there were so many more PRs, I couldn\\u2019t just leave them all unsung, so here\\u2019s a few mor e \\nquick\", \"ies:  \\n\\u2022 dotnet/runtime#58196  from [@benjamin -hodgson](https://github.com/benjamin -hodgson). \\nGiv\", \"en an expression like (byte)x | (byte)y , that can be morphed into (byte)(x | y) , which \\ncan op tim\", \"ize away some movs. \\nprivate int _x, _y; \\n \\n[Benchmark]  \\npublic int Test() => (byte)_x | (byte)_y; \", \"\\n \\n \\n; *** .NET 6 ***  \\n; Program.Test(Int32, Int32)  \\n       movzx     eax,dl  \\n       movzx     ed\", \"x,r8b  \\n       or        eax,edx  \\n       ret \\n; Total bytes of code 10  \\n \\n; *** .NET 7 ***  \\n; Pro\", \"gram.Test(Int32, Int32)  \\n       or        edx,r8d  \\n       movzx     eax,dl  \\n       ret \\n; Total b\", \"ytes of code 7   \\n68 CHAPTER 2 | JIT  \\n \\u2022 dotnet/runtime#67182 . On a machine with support for BMI2,\", \" 64 -bit shifts can be performed with \\nthe shlx , sarx , and shrx  instructions.  \\n[Benchmark]  \\n[Ar\", \"guments (123, 1)] \\npublic ulong Shift(ulong x, int y) => x << y;  \\n \\n \\n; *** .NET 6 ***  \\n; Program.\", \"Shift(UInt64, Int32)  \\n       mov       ecx,r8d  \\n       mov       rax,rdx  \\n       shl       rax,cl\", \"  \\n       ret \\n; Total bytes of code 10  \\n \\n; *** .NET 7 ***  \\n; Program.Shift(UInt64, Int32)  \\n    \", \"   shlx      rax,rdx,r8  \\n       ret \\n; Total bytes of code 6  \\n\\u2022 dotnet/runtime#69003  from [@SkiFo\", \"D](https://github.com/SkiFoD). The pattern ~x + 1  can be \\nchanged into a two\\u2019s -complement negation\", \".  \\n[Benchmark]  \\n[Arguments (42)] \\npublic int Neg(int i) => ~i + 1; \\n \\n \\n; *** .NET 6 ***  \\n; Progr\", \"am.Neg(Int32)  \\n       mov       e ax,edx \\n       not       eax  \\n       inc       eax  \\n       ret \", \"\\n; Total bytes of code 7  \\n \\n; *** .NET 7 ***  \\n; Program.Neg(Int32)  \\n       mov       eax,edx  \\n  \", \"     neg       eax  \\n       ret \\n; Total bytes of code 5  \\n\\u2022 dotnet/runtime#61412  from [@SkiFoD](ht\", \"tps://github.com/SkiFoD). An expression X & 1 == 1  \\nto test whether the bottom bit of a number is s\", \"et can changed to the cheaper X & 1  (which isn\\u2019t \\nactually expressible without a following != 0  in\", \" C#).  \\n[Benchmark] \\n[Arguments (42)] \\npublic bool BitSet(int x) => (x & 1) == 1; \\n \\n \\n; *** .NET 6 \", \"***  \\n; Program.BitSet(Int32)  \\n       test      dl,1  \\n       setne     al   \\n69 CHAPTER 2 | JIT  \\n\", \"        movzx     eax,al  \\n       ret \\n; Total bytes of code 10  \\n \\n; *** .NET 7 ***  \\n; Program.Bit\", \"Set(Int32)  \\n       mov       eax,edx  \\n       and       eax,1  \\n       ret \\n; Total bytes of code 6\", \"  \\n\\u2022 dotnet/runtime#63545  from [@Wraith2](https://github.com/Wraith2). The expression x & (x - \\n1) \", \"can be lowered to the blsr  instruction.  \\n[Benchmark]  \\n[Arguments (42)] \\npublic int ResetLowestSet\", \"Bit (int x) => x & (x - 1); \\n \\n \\n; *** .NET 6 ***  \\n; Program.ResetLowestSetBit(Int32)  \\n       lea \", \"      eax,[rdx+0FFFF]  \\n       and       eax,edx  \\n       ret \\n; Total bytes of code 6  \\n \\n; *** .NE\", \"T 7 ***  \\n; Program.ResetLowestSetBit(Int32)  \\n       blsr      eax,edx  \\n       ret \\n; Total bytes \", \"of code 6  \\n\\u2022 dotnet/runtime#62394 . / and % by a vector\\u2019s .Count  wasn\\u2019t reco gnizing that Count  c\", \"an be \\nunsigned, but doing so leads to better code gen.  \\n[Benchmark]  \\n[Arguments (42u)] \\npublic lo\", \"ng DivideByVectorCount (uint i) => i / Vector< byte>.Count; \\n \\n \\n; *** .NET 6 ***  \\n; Program.Divide\", \"ByVectorCount(UInt32)  \\n       mov       eax,edx  \\n       mov       rdx,rax  \\n       sar       rdx,3\", \"F  \\n       and       rdx,1F  \\n       add       rax,rdx  \\n       sar       rax,5  \\n       ret \\n; Tota\", \"l bytes of code 21  \\n \\n; *** .NET 7 ***  \\n; Program.DivideByVectorCount(UInt32)  \\n       mov       e\", \"ax,edx  \\n       shr       rax, 5 \\n       ret \\n; Total bytes of code 7   \\n70 CHAPTER 2 | JIT  \\n \\u2022 dot\", \"net/runtime#60787 . Loop alignment in .NET 6  provides a very nice exploration of why and \\nhow the J\", \"IT handles loop alignment. This PR extends that further by trying to \\u201chide\\u201d an emitted \\nalign  instr\", \"u ction behind an unconditional jmp that might already exist, in order to minimize the \\nimpact of th\", \"e processor having to fetch and decode nops.  \\n71 CHAPTER 3 | GC  \\n CHAPTER  3 \\nGC \\n\\u201cRegions\\u201d is a f\", \"eature of the garbage collector (GC) that\\u2019s been in the works for multiple years. It\\u2019s \\nenabled by d\", \"efault in 64 -bit processes in .NET 7 as of dotnet/runtime#64688 , but as with other multi -\\nyear fe\", \"atures, a multitude of PRs went into making it a reality. At a 30,000 foot level, \\u201cregions\\u201d replaces\", \" \\nthe current \\u201csegments\\u201d approach to managing memory on the GC heap; rather than having a few \\ngigan\", \"tic segments of memory (e. g. each 1GB), often associated 1:1 with a generation, the GC instead \\nmai\", \"ntains many, many smaller regions (e.g.  each 4MB) as their own entity. This enables the GC to be \\nm\", \"ore agile with regards to operations like repurposing regions of memory from one gener ation to \\nano\", \"ther. For more information on regions, the blog post Put a DPAD on that GC!  from the primary \\ndevel\", \"oper on the GC is still the best resource.   \\n72 CHAPTER 4 | Native AOT  \\n CHAPTER  4 \\nNative AOT  \\n\", \"To many people, the word \\u201cperformance\\u201d in the context of software is about throughput. How fast \\ndoe\", \"s something execute? How much data per second can it process? How many requests per second \\ncan it p\", \"rocess? And so on. But there are many other facets to performance. How much memory does \\nit consume?\", \" How fast does it start up and get to the point of doing something useful? How much  \\nspace does it \", \"consume on disk? How long would it take to download? And then there are related \\nconcerns. In order \", \"to achieve these goals, what dependencies are required? What kinds of operations \\ndoes it need to pe\", \"rform to achieve these goals, and are all o f those operations permitted in the target \\nenvironment?\", \" If any of this paragraph resonates with you, you are the target audience for the Native \\nAOT suppor\", \"t now shipping in .NET 7.  \\n.NET has long had support for AOT code generation. For example, .NET Fra\", \"mewo rk had it in the form \\nof ngen , and .NET Core has it in the form of crossgen . Both of those s\", \"olutions involve a standard .NET \\nexecutable that has some of its IL already compiled to assembly co\", \"de, but not all methods will have \\nassembly code generated for the m, various things can invalidate \", \"the assembly code that was \\ngenerated, external .NET assemblies without any native assembly code can\", \" be loaded, and so on, and \\nin all of those cases, the runtime continues to utilize a JIT compiler. \", \"Native AOT is different. It\\u2019s an \\nevolution of CoreRT, which itself was an evolution of .NET Native,\", \" and it\\u2019s entirely free of a JIT. The \\nbinary that results from publishing a build is a completely s\", \"tandalone executable in the target \\nplatform\\u2019s platform -specific file format (e.g.  COFF on Windows\", \", ELF on Linux, Mach -O on macOS) with \\nno external dependencies other than ones standard to that pl\", \"atform (e.g.  libc). And it\\u2019s entirely native: \\nno IL in sight, no JIT, no nothing. All required cod\", \"e is compiled and/or linked in to the executab le, \\nincluding the same GC that\\u2019s used with standard \", \".NET apps and services, and a minimal runtime that \\nprovides services around threading and the like.\", \" All of that brings great benefits: super fast startup \\ntime, small and entirely -self contained dep\", \"loyment , and ability to run in places JIT compilers aren\\u2019t \\nallowed (e.g.  because memory pages tha\", \"t were writable can\\u2019t then be executable). It also brings \\nlimitations: no JIT means no dynamic load\", \"ing of arbitrary assemblies (e.g. Assembly.LoadFile ) and no \\nreflect ion emit (e.g. DynamicMethod )\", \", everything compiled and linked in to the app means the more \\nfunctionality that\\u2019s used (or might b\", \"e used) the larger is your deployment, etc. Even with those \\nlimitations, for a certain class of app\", \"lication, Native AOT is an in credibly exciting and welcome \\naddition to .NET 7.  \\nToo many PRs to m\", \"ention have gone into bringing up the Native AOT stack, in part because it\\u2019s been \\nin the works for \", \"years (as part of the archived dotnet/ corert  project and then as part of \\ndotnet/runtimelab/featur\", \"e/NativeAOT ) and in part because there have been over a hundred PRs just \\nin dotnet/runtime  that h\", \"ave gone into bringing Native AOT up to a shippable state since the code was \\noriginally brought ove\", \"r from dotnet/runtimelab  in dotnet/runtime#62563  and dotnet/runtime#62563 . \\nBetween that and ther\", \"e not being a previous version to compare its performance to, instead of \\nfocusing PR by PR on impro\", \"vements, let\\u2019s just look at how to use it and the benefits it brings.   \\n73 CHAPTER 4 | Native AOT  \", \"\\n Today, Native AOT is focused on console applications, so let\\u2019s create a console app:  \\ndotnet new \", \"console -o nativeaotexample  \\nWe now have our nativeaot example  directory containing a nativeaotexa\", \"mple.csproj  and a \\u201chello, \\nworld\\u201d Program.cs . To enable publishing the application with Native AOT\", \", edit the .csproj to include \\nthis in the existing <PropertyGroup>...</PropertyGroup> .  \\n<PublishA\", \"ot> true </PublishAot>  \\nAnd then\\u2026 actually, that\\u2019s it. Our app is now fully configured to be able t\", \"o target Native AOT. All that\\u2019s \\nleft is to publish. As I\\u2019m currently writing this on my Windows x64\", \" machine, I\\u2019ll target that:  \\ndotnet publish -r win-x64 -c Release  \\nI now have my generated executa\", \"ble in the output publish directory:  \\n    Directory: C: \\\\nativeaotexample \\\\bin\\\\Release\\\\net7.0\\\\win-x\", \"64\\\\publish \\n \\nMode                 LastWriteTime         Length Name  \\n-a---           8/27/2022  6:\", \"19 PM        206182 4 nativeaotexample.exe  \\n-a---           8/27/2022  6:19 PM       14290944 nativ\", \"eaotexample.pdb  \\nso 2M instead of 3.5MB. Of course, for that significant reduction I\\u2019ve given up so\", \"me things:  \\n\\u2022 Setting InvariantGlobalization  to true means I\\u2019m now not respecting c ulture informa\", \"tion and \\nam instead using a set of invariant data for most globalization operations.  \\n\\u2022 Setting Us\", \"eSystemResourceKeys  to true means nice exception messages are stripped away.  \\n\\u2022 Setting IlcGenerat\", \"eStackTraceData  to false means I\\u2019m going to get fair ly poor stack traces \\nshould I need to debug a\", \"n exception.  \\n\\u2022 Setting DebuggerSupport  to false\\u2026 good luck debugging things.  \\n\\u2022 \\u2026 you get the id\", \"ea.  \\nOne of the potentially mind -boggling aspects of Native AOT for a developer used to .NET is th\", \"at, as it \\nsays on the tin, it really is native. After publishing the app, there is no IL involved, \", \"and there\\u2019s no JIT \\nthat could even process it. This makes some o f the other investments in .NET 7 \", \"all the more valuable, \\nfor example everywhere investments are happening in source generators. Code \", \"that previously relied \\non reflection emit for good performance will need another scheme. We can see\", \" that, for example, with  \\nRegex . Historically for optimal throughput with Regex , it\\u2019s been recomm\", \"ended to use \\nRegexOptions.Compiled , which uses reflection emit at run -time to generate an optimiz\", \"ed \\nimplementation of the specified pattern. But if you look at the implementation of th e Regex  \\nc\", \"onstructor, you\\u2019ll find this nugget:  \\nif (RuntimeFeature. IsDynamicCodeCompiled ) \\n{ \\n    factory =\", \" Compile(pattern, tree, options, matchTimeout != InfiniteMatchTimeout);  \\n} \\nWith the JIT, IsDynamic\", \"CodeCompiled  is true. But with Native AOT, it\\u2019s false. Thus, with Native AOT \\nand Regex , there\\u2019s n\", \"o difference between specifying RegexOptions.Compiled  and not, and another \\nmechanism is required t\", \"o get the throughput benefits promised by RegexOptions.Compiled . Enter \\n[GeneratedRegex(...)] , whi\", \"ch, along with the new regex source generator shipping in the .NET 7  \\n74 CHAPTER 4 | Native AOT  \\n \", \"SDK, emits C# code into the assembly using it. That C# code takes the place of the reflection emit t\", \"hat \\nwould have happened at run -time, and is thus able to work s uccessfully with Native AOT.  \\npri\", \"vate static readonly  string s_haystack = new \\nHttpClient ().GetStringAsync (\\\"https://www.gutenberg.\", \"org/files/1661/1661 -0.txt\\\").Result; \\n     \\nprivate Regex _interpreter = new Regex(@\\\"^.*elementary.*\", \"$\\\" , RegexOptions. Multiline ); \\n \\nprivate Regex _compiled = new Regex(@\\\"^.*elementary.*$\\\" , RegexOp\", \"tions. Compiled  | \\nRegexOptions. Multiline ); \\n \\n[GeneratedRegex (@\\\"^.*elementary.*$\\\" , RegexOption\", \"s. Multiline )] \\nprivate partial Regex SG(); \\n \\n[Benchmark (Baseline = true)] public int Interpreter\", \" () => _i nterpreter. Count(s_haystack);  \\n \\n[Benchmark] public int Compiled () => _compiled. Count(\", \"s_haystack);  \\n \\n[Benchmark] public int SourceGenerator () => SG().Count(s_haystack);  \\nMethod  Mean\", \"  Ratio  \\nInterpreter  9,036.7 us  1.00 \\nCompiled  9,064.8 us  1.00 \\nSourceGenerator  426.1 us  0.05\", \" \\nSo, yes, there are some constraints associated with Native AOT, but there are also solutions for \\n\", \"working with those constraints. And further, those constraints can actually bring further benefits. \", \"\\nConsider dotnet/runtime#64497 . Remember how we talked about \\u201cguarded devirtualization\\u201d in \\ndynamic\", \" PGO, where via instrumentation the JIT can determine the most likely type to be used at a \\ngiven ca\", \"ll site and special -case it? With Native AOT, the entirety of the program is known at compile \\ntime\", \", with no support for Assembly.LoadFrom  or the like. That means at compile time, the compiler \\ncan \", \"do whole -program analysis to determine what types implement what interfaces. If a gi ven \\ninterface\", \" only has a single type that implements it, then every call site through that interface can be \\nunco\", \"nditionally devirtualized, without any type -check guards.  \\nThis is a really exciting space, one we\", \" expect to see flourish in coming releases.   \\n75 CHAPTER 5 | Mono  \\n CHAPTER  5 \\nMono  \\nUp until no\", \"w I\\u2019ve referred to \\u201cthe JIT,\\u201d \\u201cthe GC,\\u201d and \\u201cthe runtime,\\u201d but in reality there are actually \\nmultip\", \"le runtimes in .NET. I\\u2019ve been talking about \\u201ccoreclr,\\u201d which is the runtime that\\u2019s recommended \\nfor\", \" use on Linux, macOS, and Windows. However, there\\u2019s also \\u201cmono,\\u201d which powers Blazor wasm \\napplicati\", \"ons, Android apps, and iOS apps. It\\u2019s also seen sign ificant improvements in .NET 7.  \\nJust as with \", \"coreclr (which can JIT compile, AOT compile partially with JIT fallback, and fully Native \\nAOT compi\", \"le), mono has multiple ways of actually executing code. One of those ways is an interpreter, \\nwhich \", \"enables mono to execute .NET code in environments that don\\u2019t permit JIT\\u2019ing and without \\nrequiring a\", \"head -of-time compilation or incurring any limitations it may bring. Interestingly, though, \\nthe int\", \"erpreter is itself almost a full -fledged compiler, parsing the IL, gener ating its own intermediate\", \" \\nrepresentation (IR) for it, and doing one or more optimization passes over that IR; it\\u2019s just that\", \" at the \\nend of the pipeline when a compiler would normally emit code, the interpreter instead saves\", \" off that \\ndata for it to interpr et when the time comes to run. As such, the interpreter has a very\", \" similar \\nconundrum to the one we discussed with coreclr\\u2019s JIT: the time it takes to optimize vs the\", \" desire to \\nstart up quickly. And in .NET 7, the interpreter employs a similar solution: tie red com\", \"pilation. \\ndotnet/runtime#68823  adds the ability for the interpreter to initially compile with mini\", \"mal \\noptimization of that IR, and then once a certain threshold of call counts has been hit, then ta\", \"ke the \\ntime to do as much optimization on the IR as possible for all future invocations of that met\", \"hod. This \\nyields the same benefits as it does for coreclr: improved startup time while also having \", \"efficient \\nsustained throughput. When this merg ed, we saw improvements in Blazor wasm app startup t\", \"ime \\nimprove by 10 -20%. Here\\u2019s one example from an app being tracked in our benchmarking system:   \", \"\\n76 CHAPTER 5 | Mono  \\n  \\nThe interpreter isn\\u2019t just used for entire apps, though. Just as how corec\", \"lr can use the JIT when an R2R \\nimage doesn\\u2019t contain code for a method, mono can use the interprete\", \"r when there\\u2019s no AOT code \\nfor a method. Once such case that occurred on mono was with generic dele\", \"gate invocation, where the \\npresence of a generic delegate being invoked would trigger fall ing back\", \" to the interpreter; for .NET 7, \\nthat gap was addressed with dotnet/runtime#70653 . A more impactfu\", \"l case, however, is \\ndotnet/runtime#64867 . Previously, any methods with catch  or filter  exception\", \" handling clauses \\ncouldn\\u2019t be AOT compiled and would fall back to being interpreted. With this PR, \", \"the method is now \\nable to be AOT compiled, and it only falls back to using the inte rpreter when an\", \" exception actually \\noccurs, switching over to the interpreter for the remainder of that method call\", \"\\u2019s execution. Since many \\nmethods contain such clauses, this can make a big difference in throughput\", \" and CPU consumption. In \\nthe same vein, dotnet/runtime#63065  enabled methods with finally  excepti\", \"on handling clauses to \\nbe AOT compiled; just the finally  block gets interpreted rather than the en\", \"tire method being \\ninterpreted.  \\nBeyond such backend improvements, another class of improvement cam\", \"e from further unification \\nbetween coreclr and mono. Years ago, coreclr and mono had their own enti\", \"re library stack b uilt on \\ntop of them. Over time, as .NET was open sourced, portions of mono\\u2019s sta\", \"ck got replaced by shared \\ncomponents, bit by bit. Fast forward to today, all of the core .NET libra\", \"ries above \\nSystem.Private.CoreLib  are the same regardless of which runtime is  being employed. In \", \"fact, the \\nsource for CoreLib  itself is almost entirely shared, with ~95% of the source files being\", \" compiled into \\nthe CoreLib  that\\u2019s built for each runtime, and just a few percent of the source spe\", \"cialized for each \\n(these statements mean s that the vast majority of the performance improvements d\", \"iscussed in the \\nrest of this post apply equally whether running on mono and coreclr). Even so, ever\", \"y release now we \\ntry to chip away at that few remaining percent, for reasons of maintainability, bu\", \" t also because the \\nsource used for coreclr\\u2019s CoreLib  has generally had more attention paid to it \", \"from a performance \\nperspective. dotnet/runtime#71325 , for example, moves mono\\u2019s array and span sor\", \"ting generic \\nsorting utility class over to the more efficient implementation used by coreclr.  \\nOne\", \" of the biggest categories of improvements, however, is in vectorization. This comes in two pieces. \", \"\\nFirst, Vector<T>  and Vector128<T>  are now fully accelera ted on both x64 and Arm64, thanks to PRs\", \" \\nlike dotnet/runtime#64961 , dotnet/runtime#65086 , dotnet/runtime#65128 , dotnet/runtime#66317 , \\n\", \" \\n77 CHAPTER 5 | Mono  \\n dotnet/runtime#66391 , dotnet/runtime#66409 , dotnet/runtime#66512 , dotnet\", \"/runtime#66586 , \\ndotnet/runtime#66589 , dotnet/runtime#66597 , dotnet/runtime#66476 , and dotnet/ru\", \"ntime#67125 ; \\nthat significant amount of work means all that code that gets vectorized using these \", \"abstractions will \\nlight-up on mono and coreclr alike. Second, thanks primarily to dotnet/runtime#70\", \"086 , mono now \\nknows how to translate Vector128<T>  operations to WASM\\u2019s SIMD instruction set, such\", \" that code \\nvectorized with Vector128<T>  will also be accelerated when running in Blazor wasm appli\", \"cations and \\nanywhere else WASM might be executed.   \\n78 CHAPTER 6 | Reflection  \\n CHAPTER  6 \\nRefle\", \"ction  \\nReflection is one of those areas you either love or hate (I find it a bit humorous to be wri\", \"ting this \\nsection immediately after writing the Native AOT section). It\\u2019s immensely powerful, provi\", \"ding the \\nability to query all of the metadata for code in your pr ocess and for arbitrary assemblie\", \"s you might \\nencounter, to invoke arbitrary functionality dynamically, and even to emit dynamically \", \"-generated IL at \\nrun-time. It\\u2019s also difficult to handle well in the face of tooling like a linker \", \"or a solution like Native \\nAOT that needs to be able to determine at build time exactly what code wi\", \"ll be executed, and it\\u2019s \\ngenerally quite expensive at run -time; thus it\\u2019s both something we strive\", \" to avoid when possible but \\nalso invest in reducing the costs of, as it\\u2019s so popular in so many dif\", \"ferent kinds of applications \\nbecause it is incredibly useful. As with most releases, it\\u2019s seen some\", \" nice improvements in .NET 7.  \\nOne of the most impacted areas is reflection invoke. Available via M\", \"ethodBase.Invoke , this \\nfunctionality let\\u2019s yo u take a MethodBase  (e.g. MethodInfo ) object that \", \"represents some method for \\nwhich the caller previously queried, and call it, with arbitrary argumen\", \"ts that the runtime needs to \\nmarshal through to the callee, and with an arbitrary return value that\", \" needs t o be marshaled back. If \\nyou know the signature of the method ahead of time, the best way t\", \"o optimize invocation speed is to \\ncreate a delegate from the MethodBase  via CreateDelegate<T>  and\", \" then use that delegate for all \\nfuture invocations. But in some circu mstances, you don\\u2019t know the \", \"signature at compile time, and thus \\ncan\\u2019t easily rely on delegates with known matching signatures. \", \"To address this, some libraries have \\ntaken to using reflection emit to generate code at run -time s\", \"pecific to the target method. This is \\nextremely complicated and it\\u2019s not something we want apps to \", \"have to do. Instead, in .NET 7 via \\ndotnet/runtime#66357 , dotnet/runtime#69575 , and dotnet/runtime\", \"#74614 , Invoke  will itself use \\nreflection emit (in the form of DynamicMethod ) to generate a dele\", \"gate that is customized for invoking \\nthe target, and then future invocation via that MethodInfo  wi\", \"ll utilize that generated method. This \\ngives developers most of the performance benefits of a custo\", \"m reflection emit -based implementation \\nbut without having the complexity or challenges of such an \", \"implementation in their own code base.  \\nprivate MethodInfo _method;  \\n \\n[GlobalSetup]  \\npublic void\", \" Setup() => _method = typeof(Program). GetMethod (\\\"MyMethod\\\" , \\nBindingFlags. NonPublic  | BindingFl\", \"ags. Static); \\n \\n[Benchmark]  \\npublic void MethodInfoInvoke () => _method. Invoke(null, null); \\n \\npr\", \"ivate static void MyMethod () { } \\n   \\n79 CHAPTER 6 | Reflection  \\n Method  Runtime  Mean  Ratio  \\nM\", \"ethodInfoInvoke  .NET 6.0  43.846 ns  1.00 \\nMethodInfoInvoke  .NET 7.0  8.078 ns  0.18 \\nReflection a\", \"lso involves lots of manipulation of objects that represent types, methods, properties, and \\nso on, \", \"and tweaks here and there can add up to a measurable difference when using these APIs. For \\nexample,\", \" I\\u2019ve talked in past performance posts about how, potentially counterin tuitively, one of the \\nways \", \"we\\u2019ve achieved performance boosts is by porting native code from the runtime back into \\nmanaged C#. \", \"There are a variety of ways in which doing so can help performance, but one is that \\nthere is some o\", \"verhead associated with calling  from managed code into the runtime, and eliminating \\nsuch hops avoi\", \"ds that overhead. This can be seen in full effect in dotnet/runtime#71873 , which moves \\nseveral of \", \"th ese \\u201cFCalls\\u201d related to Type , RuntimeType  (the Type -derived class used by the runtime to \\nrepr\", \"esent its types), and Enum  out of native into managed.  \\n[Benchmark]  \\npublic Type GetUnderlyingTyp\", \"e () => Enum. GetUnderlyingType (typeof(DayOfWeek));  \\nMethod  Runtime  Mean Ratio  \\nGetUnderlyingTy\", \"pe  .NET 6.0  27.413 ns  1.00 \\nGetUnderlyingType  .NET 7.0  5.115 ns  0.19 \\nAnother example of this \", \"phenomenon comes in dotnet/runtime#62866 , which moved much of the \\nunderlying support for AssemblyN\", \"ame  out of native runtime code into managed code in CoreLib. That \\nin turn has an impact on anythin\", \"g that uses it, su ch as when using Activator.CreateInstance  \\noverloads that take assembly names th\", \"at need to be parsed.  \\nprivate readonly  string _assemblyName = typeof(MyClass). Assembly .FullName\", \" ; \\nprivate readonly  string _typeName = typeof(MyClass). FullName ; \\npublic class MyClass { }  \\n \\n[\", \"Benchmark]  \\npublic object CreateInstance () => Activator. CreateInstance (_assemblyName, _typeName)\", \";  \\nMethod  Runtime  Mean  Ratio  \\nCreateInstance  .NET 6.0  3.827 us  1.00 \\nCreateInstance  .NET 7.\", \"0  2.276 us  0.60 \\nOther changes contributed to Activator.CreateInstance  improvements as well. \\ndot\", \"net/runtime#67148  removed several array and list allocations from inside of the \\nRuntimeType.Create\", \"InstanceImpl  method that\\u2019s used by CreateInstance  (using Type.EmptyTypes  \\ninstead of allocating a\", \" new Type[0] , avoiding unnecessarily turning a builder into an array, etc.), \\nresulting in less all\", \"ocation and faster throughput.  \\n[Benchmark]  \\npublic void CreateInstance () => Ac tivator. CreateIn\", \"stance (typeof(MyClass), \\nBindingFlags. NonPublic  | BindingFlags. Instance , null, Array. Empty<obj\", \"ect>(), null); \\n \\ninternal  class MyClass \\n{  \\n80 CHAPTER 6 | Reflection  \\n     internal  MyClass() \", \"{ } \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nCreateInstance  .NET 6.0  167.8 ns  1\", \".00 320 B  1.00 \\nCreateInstance  .NET 7.0  143.4 ns  0.85 200 B  0.62 \\nAnd since we were talking abo\", \"ut AssemblyName , other PRs improved it in other ways as well. \\ndotnet/runtime#66750 , for example, \", \"updated the computation of AssemblyName.FullName  to use \\nstack -allocated memory and ArrayPool<char\", \">  instead of using a StringBuilder : \\nprivate AssemblyName[] _names = AppDomain. CurrentDomain .Get\", \"Assemblies ().Select(a => new \\nAssemblyName (a.FullName )).ToArray(); \\n \\n[Benchmark]  \\npublic int Na\", \"mes() \\n{ \\n    int sum = 0; \\n    foreach (AssemblyName name in _names) \\n    { \\n        sum += name. F\", \"ullName .Length; \\n    } \\n    return sum; \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\n\", \"Names  .NET 6.0  3.423 us  1.00 9.14 KB  1.00 \\nNames  .NET 7.0  2.010 us  0.59 2.43 KB  0.27 \\nMore r\", \"eflection -related operations have also been turned into JIT intrinsics, as discussed earlier \\nenabl\", \"ing the JIT to compute answers to various questions at JIT compile time rather than at run -time. \\nT\", \"his was done, for example, for Type.IsByRefLike  in dotnet/runtime#67852 . \\n[Benchmark]  \\npublic boo\", \"l IsByRefLike () => typeof(ReadOnlySpan< char>).IsByRefLike ; \\nMethod  Runtime  Mean  Ratio  Code Si\", \"ze  \\nIsByRefLike  .NET 6.0  2.1322 ns  1.000  31 B \\nIsByRefLike  .NET 7.0  0.0000 ns  0.000  6 B \\nTh\", \"at the .NET 7 version is so close to zero is called out in a warning by benchmarkdotnet:  \\n// * Warn\", \"ings *  \\nZeroMeasurement  \\n  Program.IsByRefLike: Runtime=.NET 7.0, Toolchain=net7.0 -> The method d\", \"uration is \\nindistinguishable from the empty method duration  \\nand it\\u2019s so indistinguishable from an\", \" empty method because that\\u2019s effectively what it is, as we can see \\nfrom the disassembl y: \\n   \\n81 C\", \"HAPTER 6 | Reflection  \\n  \\n; Program.IsByRefLike()  \\n       mov       eax,1  \\n       ret \\n; Total by\", \"tes of code 6  \\nThere are also improvements that are hard to see but that remove overheads as part o\", \"f populating \\nreflection\\u2019s caches, which end up reducing the work done typically on star tup paths, \", \"helping apps to \\nlaunch faster. dotnet/runtime#66825 , dotnet/runtime#66912 , and dotnet/runtime#671\", \"49  all fall into \\nthis category by removing unnecessary or duplicative array allocations as part of\", \" gathering data on \\nparameters, properties, and events.   \\n82 CHAPTER 7 | Interop  \\n CHAPTER  7 \\nInt\", \"erop  \\n.NET has long had great support for interop, enabling .NET applications to consume huge amoun\", \"ts of \\nfunctionality written in other languages and/or exposed  by the underlying operating system. \", \"The \\nbedrock of this support has been \\u201cPlatform Invoke,\\u201d or \\u201cP/Invoke,\\u201d represented in code by \\n[Dll\", \"Import(...)]  applied to methods. The DllImportAttribute  enables declaring a method that \\ncan be ca\", \"lled like any other .NET  method but that actually represents some external method that the \\nruntime\", \" should call when this managed method is invoked. The DllImport specifies details about in \\nwhat lib\", \"rary the function lives, what its actual name is in the exports from that library, high-level \\ndetai\", \"ls about marshalling of input arguments and return values, and so on, and the runtime ensures \\nall t\", \"he right things happen. This mechanism works on all operating systems. For example, Windows \\nhas a m\", \"ethod CreatePipe  for creating an anonymous  pipe:  \\nBOOL CreatePipe(  \\n  [out]          PHANDLE    \", \"           hReadPipe,  \\n  [out]          PHANDLE               hWritePipe,  \\n  [in, optional] LPSECU\", \"RITY_ATTRIBUTES lpPipeAttributes,  \\n  [in]           DWORD                 nSize  \\n); \\nIf I want to \", \"call this fun ction from C#, I can declare a [DllImport(...)]  counterpart to it which I can \\nthen i\", \"nvoke as I can any other managed method:  \\n[DllImport (\\\"kernel32\\\" , SetLastError = true)] \\n[return: \", \"MarshalAs (UnmanagedType. Bool)] \\nprivate static unsafe extern bool CreatePipe ( \\n    out SafeFileHa\", \"ndle hReadPipe,  \\n    out SafeFileHandle hWritePipe,  \\n    void* lpPipeAttributes,  \\n    uint nSize)\", \"; \\nThere are several interesting things to note here. Several of the arguments are directly blittabl\", \"e with \\nthe same representation on  the managed and native side of the equation, e.g. lpPipeAttribut\", \"es  is a \\npointer and nSize  is a 32 -bit integer. But what about the return value? The bool  type i\", \"n C# \\n(System.Boolean ) is a one -byte type, but the BOOL  type in the native signature is four byte\", \" s; thus code \\ncalling this managed method can\\u2019t just directly invoke the native function somehow, a\", \"s there needs to \\nbe some \\u201cmarshalling\\u201d logic that converts the four -byte return BOOL  into the one\", \" -byte return bool . \\nSimiarly, the native function has two out pointers for hReadPipe  and hWritePi\", \"pe , but the managed \\nsignature declares two SafeFileHandle s (a SafeHandle  is a .NET type that wra\", \"ps a pointer and \\nprovides a finalizer and Dispose  method for ensuring that pointer is appropriatel\", \"y cleaned up when \\nit\\u2019s no l onger being used). Some logic needs to take the output handles generate\", \"d by the native \\nfunction and wrap them into these SafeFileHandles  to be output from the managed me\", \"thod. And \\nwhat about that SetLastError = true ? .NET has methods like Marshal.GetLastPIn vokeError(\", \") ,  \\n83 CHAPTER 7 | Interop  \\n and some code somewhere needs to take any error produced by this met\", \"hod and ensure it\\u2019s available \\nfor consumption via a subsequent GetLastPInvokeError() . \\nIf there\\u2019s \", \"no marshalling logic required, such that the managed signature and native sign ature are for \\nall in\", \"tents and purposes the same, all arguments blittable, all return values blittable, no additional \\nlo\", \"gic required around the invocation of the method, etc., then a [DllImport(...)]  ends up being a \\nsi\", \"mple passthrough with the runtime needi ng to do very little work to implement it. If, however, the \", \"\\n[DllImport(...)]  involves any of this marshalling work, the runtime needs to generate a \\u201cstub,\\u201d \\nc\", \"reating a dedicated method that\\u2019s called when the [DllImport(...)]  is called, that handles fixing \\n\", \"up all inputs, that delegates to the actual native function, and that fixes up all of the outputs. T\", \"hat \\nstub is generated at execution time, with the runtime effectively doing reflection emit, genera\", \"ting IL \\ndynamically that\\u2019s then JIT\\u2019d.  \\nThere are a variety  of downsides to this. First, it takes\", \" time to generate all that marshalling code, time \\nwhich can then negatively impact user experience \", \"for things like startup. Second, the nature of its \\nimplementation inhibits various optimizations, s\", \"uch as inlining. Thi rd, there are platforms that don\\u2019t \\nallow for JIT\\u2019ing due to the security expos\", \"ure of allowing for dynamically generated code to then be \\nexecuted (or in the case of Native AOT, w\", \"here there isn\\u2019t a JIT at all). And fourth, it\\u2019s all hidden away \\nmaking it more  challenging for a \", \"developer to really understand what\\u2019s going on.  \\nBut what if that logic could all be generated at b\", \"uild time rather than at run time? The cost of \\ngenerating the code would be incurred only at build \", \"time and not on every execution. The cod e would \\neffectively just end up being user code that has a\", \"ll of the C# compiler\\u2019s and runtime\\u2019s optimizations \\navailable to it. The code, which then would jus\", \"t be part of the app, would be able to be ahead -of-time \\ncompiled using whatever AOT system is desi\", \"r able, whether it be crossgen or Native AOT or some \\nother system. And the code would be inspectabl\", \"e, viewable by users to understand exactly what work \\nis being done on their behalf. Sounds pretty d\", \"esirable. Sounds magical. Sounds like a job for a Roslyn \\nsource generator, mentioned earlier.  \\n.NE\", \"T 6 included several source generators in the .NET SDK, and .NET 7 doubles down on this effort \\nincl\", \"uding several more. One of these is the brand new LibraryImport generator, which provides exactly \\nt\", \"he magical, desirable  solution we were just discussing.  \\nLet\\u2019s return to our previous CreatePipe  \", \"example. We\\u2019ll make two small tweaks. We change the \\nattribute from DllImport  to LibraryImport , an\", \"d we change the extern  keyword to be partial : \\n[LibraryImport (\\\"kernel32\\\" , SetLastError = true)] \", \"\\n[return: MarshalAs (UnmanagedType. Bool)] \\nprivate static unsafe partial bool CreatePipe ( \\n    out\", \" SafeFileHandle hReadPipe,  \\n    out SafeFileHandle hWritePipe,  \\n    void* lpPipeAttributes,  \\n    \", \"uint nSize); \\nNow if you\\u2019re following along a t home in Visual Studio, try right -clicking on Create\", \"Pipe and selecting \\nGo to Definition. That might seem a little strange. \\u201cGo to Definition? Isn\\u2019t thi\", \"s the definition?\\u201d This is a \\npartial method, which is a way of declaring something that another par\", \"tial definition fills in, and in this \\ncase, a source generator in .NET 7 SDK has noticed this metho\", \"d with the [LibraryImport]  attribute \\nand fully generated the entire marshalling stub code in C# th\", \"at\\u2019s built directly into the assembly. \\nWhile by default that cod e isn\\u2019t persisted, Visual Studio s\", \"till enables you to browse it (and you can  \\n84 CHAPTER 7 | Interop  \\n opt-in to having it persisted\", \" on disk by adding a \\n<EmitCompilerGeneratedFiles>true</EmitCompilerGeneratedFiles>  property into y\", \"our .csproj). \\nHere\\u2019s what it currently looks like fo r that method:  \\n[System. CodeDom.Compiler .Ge\", \"neratedCodeAttribute (\\\"Microsoft.Interop.LibraryImportGenerator\\\" , \\n\\\"7.0.6.42316\\\" )] \\n[System. Runti\", \"me.CompilerServices .SkipLocalsInitAttribute ] \\nprivate static unsafe partial bool CreatePipe (out \\n\", \"global::Microsoft. Win32.SafeHandles .SafeFileHandle  hReadPipe, out \\nglobal::Microsoft. Win32.SafeH\", \"andles .SafeFileHandle  hWritePipe, void* lpPipeAttributes, uint \\nnSize) \\n{ \\n    int __lastError;  \\n\", \"    bool __invokeSucceeded = default; \\n    System.Runtime.CompilerServices .Unsafe.SkipInit (out hRe\", \"adPipe);  \\n    System.Runtime.CompilerServices .Unsafe.SkipInit (out hWritePipe);  \\n    System.IntPt\", \"r __hReadPipe_native = default; \\n    System.IntPtr __hWritePipe_native = default; \\n    bool __retVal\", \";  \\n    int __retVal_native = default; \\n     \\n    // Setup - Perform required setup.  \\n    global::M\", \"icrosoft. Win32.SafeHandles .SafeFileHandle  hReadPipe__newHandle = new \\nglobal::Microsoft. Win32.Sa\", \"feHandles .SafeFileHandle (); \\n    global::Microsoft. Win32.SafeHandles .SafeFileHandle  hWritePipe_\", \"_newHandle  = new \\nglobal::Microsoft. Win32.SafeHandles .SafeFileHandle (); \\n    try \\n    { \\n       \", \" { \\n            System.Runtime.InteropServices .Marshal.SetLastSystemError (0); \\n            __retVa\", \"l_native = __PInvoke (&__hReadPipe_native, &__hWritePipe_native, \\nlpPipeAttribut es, nSize);  \\n     \", \"       __lastError = System. Runtime.InteropServices .Marshal.GetLastSystemError (); \\n        } \\n \\n \", \"       __invokeSucceeded = true; \\n     \\n        // Unmarshal - Convert native data to managed data. \", \" \\n        __retVal = __retVal_native != 0; \\n    } \\n    finally \\n    { \\n        if (__invokeSucceeded\", \")  \\n        { \\n            // GuaranteedUnmarshal - Convert native data to managed data even in the \", \"case \\nof an exception during the non -cleanup phases.  \\n            System.Runtime.InteropServices .\", \"Marshal.InitHandle (hWritePipe__newHandle, \\n__hWritePipe_native);  \\n            hWritePipe = hWriteP\", \"ipe__newHandle;  \\n            System.Runtime.InteropServices .Marshal.InitHandle (hReadPipe__newHand\", \"le, \\n__hReadPipe_native);  \\n            hReadPipe = hReadPipe__newHandle;  \\n        } \\n    } \\n \\n    \", \"System.Runtime.InteropServices .Marshal.SetLastPInvokeError (__lastError);  \\n    return __retVal;  \\n\", \"     \\n    // Local P/Invoke  \\n    [System. Runtime.InteropServices .DllImportAttribute (\\\"kernel32\\\" ,\", \" EntryPoint  =  \\n85 CHAPTER 7 | Interop  \\n \\\"CreatePipe\\\" , ExactSpelling = true)] \\n    static extern \", \"unsafe int __PInvoke (System. IntPtr* hReadPipe, System. IntPtr* hWritePipe, \\nvoid* lpPipeAttributes\", \", uint nSize); \\n} \\nWith this, you can read exactly the marshalling work that\\u2019s being performed. Two \", \"SafeHandle  \\ninstances are being allocated and then later after the native function completes, the \\n\", \"Marshal.InitHandle  method is used to store the resulting handles into these in stances (the \\nalloca\", \"tions happen before the native function call, as performing them after the native handles have \\nalre\", \"ady been produced increases the chances of a leak if the SafeHandle  allocation fails due to an \\nout\", \"-of-memory situation). The BOOL  to bool  conversion happens via a != 0  comparison. And the error \\n\", \"information is captured by calling Marshal.GetLastSystemError()  just after the native function call\", \" \\nand then Marshal.SetLastPInvokeError(int)  just prior to returning. The actual native function cal\", \"l \\nis still implemented with a [DllImport(...)] , but now that P/Invoke is blittable and doesn\\u2019t req\", \"uire \\nany stub to be generated by the runtime, as all that work has been handled in this C# code.  \\n\", \"A sheer ton of work went in to enabling this. I touched on some of it last year in Performance \\nImpr\", \"ovements in .NET 6 , but a significant amount of additional effort has gone into .NET 7 to polish \\nt\", \"he design and make the implemen tation robust, roll it out across all of dotnet/runtime  and beyond,\", \" \\nand expose the functionality for all C# developers to use:  \\n\\u2022 The LibraryImport generator started\", \" its life as an experiment in dotnet/runtimelab . When it was \\nready, dotnet/runtime#59579  brought \", \"180 commits spanning years of effort into the \\ndotnet/runtime  main branch.  \\n\\u2022 In .NET 6, there wer\", \"e almost 3000 [DllImport]  uses throughout the core .NET libraries. As of my \\nwriting this, in .NET \", \"7 there are\\u2026 let me search\\u2026 wait for it\\u2026 7 (I was hoping I could say 0, but \\nthere are just a few st\", \"ragglers, mostly related to COM interop, still remaining). That\\u2019s not a \\ntransformation that happens\", \" over night. A multitude of PRs went library by library converting \\nfrom the old to the new, such as\", \" dotnet/runtime#62295  and dotnet/runtime#61640  for \\nSystem.Private.CoreLib, dotnet/runtime#61742  \", \"and dotnet/runtime#62309  for the cryptography \\nlibraries, dotnet/runtime#61765  for networking, dot\", \"net/runtime#61996  and \\ndotnet/runtime#61638  for most of the other I/O -related  libraries, and a l\", \"ong -tail of additional \\nporting in dotnet/runtime#61975 , dotnet/runtime#61389 , dotnet/runtime#623\", \"53 , \\ndotnet/runtime#61990 , dotnet/runtime#61949 , dotnet/runtime#61805 , dotnet/runtime#61741 , \\nd\", \"otnet/runtime#61184 , dotnet/runtime#54290 , dotnet/runtime#62365 , dotnet/runtime#61609 , \\ndotnet/r\", \"untime#61532 , and dotnet/runtime#54236 . \\n\\u2022 Such porting is significantly easier when there\\u2019s a too\", \"l to help automate it. \\ndotnet/runtime#72819  enables the analyzer and fixer for performing these tr\", \"ansformations. \\n:::{custom -style=Figure}  \\n86 CHAPTER 7 | Interop  \\n  ::: \\nThere were plenty of oth\", \"er PRs that went into making the LibraryImport generator a reality for .NET 7. \\nTo highlight just a \", \"few more, dotnet/runtime#63320  introduces a new \\n[DisabledRuntimeMarsh alling]  attribute that can \", \"be specified at the assembly level to disable all of \\nthe runtime\\u2019s built -in marshalling; at that p\", \"oint, the only marshalling performed as part of interop is \\nthe marshaling done in the user\\u2019s code, \", \"e.g.  that which is generated by [LibraryImport] . Other PRs \\nlike dotnet/runtime#67635  and dotnet/\", \"runtime#68173  added new marshaling types that encompass \\ncommon m arshaling logic and can be refere\", \"nced from [LibraryImport(...)]  use to customize how \\nmarshaling is performed (the generator is patt\", \"ern -based and allows for customization of marshalling \\nby providing types that implement the right \", \"shape, which these types do  in support of the most \\ncommon marshalling needs). Really usefully, dot\", \"net/runtime#71989  added support for marshaling \\n{ReadOnly}Span<T> , such that spans can be used dir\", \"ectly in [LibraryImport( ...)]  method \\nsignatures, just as arrays can be (examples in dotnet/runtim\", \"e  are available in dotnet/runtime#73256 ). \\nAnd dotnet/runtime#69043  consolidated logic to be shar\", \"ed between the runtime\\u2019s marshalling \\nsupport in [DllImport]  and the generators support with [Libra\", \"ryImport] . \\nOne more category of interop -related changes that I t hink are worth talking about are\", \" to do with \\nSafeHandle  cleanup. As a reminder, SafeHandle  exists to mitigate various issues aroun\", \"d managing \\nnative handles and file descriptors. A native handle or file descriptor is just a memory\", \" address or \\nnumber that refe rs to some owned resource and which must be cleaned up / closed when d\", \"one with \\nit. A SafeHandle  at its core is just a managed object that wraps such a value and provide\", \"s a Dispose  \\nmethod and a finalizer for closing it. That way, if you neglect to Dispose  of the Saf\", \"eHandle  in order to \\nclose the resource, the resource will still be cleaned up when the SafeHandle \", \" is garbage collected and \\nits finalizer eventually run. SafeHandle  then also provides some synchro\", \"nization around that closure, \\ntrying to minimize the  possibility that the resource is closed while\", \" it\\u2019s still in use. It provides \\nDangerousAddRef  and DangerousRelease  methods that increment and d\", \"ecrement a ref count, \\nrespectively, and if Dispose  is called while the ref count is above zero, th\", \"e actual releas ing of the \\nhandle triggered by Dispose  is delayed until the ref count goes back to\", \" 0. When you pass a \\nSafeHandle  into a P/Invoke, the generated code for that P/Invoke handles calli\", \"ng DangerousAddRef  \\n \\n87 CHAPTER 7 | Interop  \\n and DangerousRelease  (and due to the wonders of Li\", \"braryImport I\\u2019ve already extolled, you can easily \\nsee that being done, such as in the previous gene\", \"rated code example). Our code tries hard to clean \\nup after SafeHandle s deterministically, but it\\u2019s\", \" quite easy to accidentally l eave some for finalization.  \\ndotnet/runtime#71854  added some debug -\", \"only tracking code to SafeHandle  to make it easier for \\ndevelopers working in dotnet/runtime  (or m\", \"ore specifically, developers using a checked build of the \\nruntime) to find such issues. When the Sa\", \"feHandle  is constructed, it captures the current stack trace, \\nand if the SafeHandle  is finalized,\", \" it dumps that stack trace to the co nsole, making it easy to see \\nwhere SafeHandles  that do end up\", \" getting finalized were created, in order to track them down and \\nensure they\\u2019re being disposed of. \", \"As is probably evident from that PR touching over 150 files and \\nalmost 1000 lines of code, there  w\", \"ere quite a few places that benefited from clean up. Now to be fair, \\nmany of these are on exception\", \"al code paths. For example, consider a hypothetical P/Invoke like:  \\n[LibraryImport (\\\"SomeLibrary\\\" ,\", \" SetLastError = true)] \\ninternal  static partial SafeFileHand le CreateFile (); \\nand code that uses \", \"it like:  \\nSafeFileHandle handle = Interop. CreateFile (); \\nif (handle. IsInvalid ) \\n{ \\n    throw ne\", \"w UhOhException (Marshal. GetLastPInvokeError ()); \\n} \\nreturn handle; \\nSeems straightforward enough.\", \" Except this code will actually lea ve a SafeHandle  for finalization on \\nthe failure path. It doesn\", \"\\u2019t matter that SafeHandle  has an invalid handle in it, it\\u2019s still a finalizable \\nobject. To deal wi\", \"th that, this code would have been more robustly written as:  \\nSafeFileHandle handle = Interop. Crea\", \"teFile(); \\nif (handle. IsInvalid ) \\n{ \\n    int lastError = Marshal. GetLastPInvokeError (); \\n    han\", \"dle.Dispose(); // or handle.SetHandleAsInvalid()  \\n    throw new UhOhException (lastError);  \\n} \\nret\", \"urn handle; \\nThat way, this SafeHandle  won\\u2019t create finalization pressure even in the case of failu\", \"re. Note, as well, \\nthat as part of adding in the Dispose  call, I also moved the Marshal.GetLastPIn\", \"vokeError()  up. \\nThat\\u2019s because calling Dispose  on a SafeHandle  may end up invoking the SafeHandl\", \"e \\u2019s \\nReleaseHandle  method, which the developer of the SafeHandle -derived type will have overridde\", \"n to \\nclose the resource, which typically involves making another P/Invoke. And if that P/Invoke has\", \" \\nSetLastError=true  on it, it can overwrite the very error code  for which we\\u2019re about to throw. He\", \"nce, \\nwe access and store the last error immediately after the interop call once we know it failed, \", \"then clean \\nup, and only then throw. All that said, there were a myriad of places in that PR where S\", \"afeHandle s \\nwere being l eft for finalization even on the success path. And that PR wasn\\u2019t alone. \\n\", \"dotnet/runtime#71991 , dotnet/runtime#71854 , dotnet/runtime#72116 , dotnet/runtime#72189 , \\ndotnet/\", \"runtime#72222 , dotnet/runtime#72203 , and dotnet/runtime#72279  all found and fixed many \\noccurrenc\", \"es of SafeHandle s being left for finalization (many thanks to the diagnostics put in place in \\nthe \", \"earlier mentioned PR).   \\n88 CHAPTER 7 | Interop  \\n Other PRs also accrued to improved interop perfo\", \"rmance. dotnet/runtime#70000  from \\n[@huoyaoyuan](https:// github.com/huoyaoyuan) rewrote several de\", \"legate -related \\u201cFCalls\\u201d from being \\nimplemented in native code to instead being managed, resulting \", \"in less overhead when invoking \\nthese operations that are commonly involved in scenarios involving \\n\", \"Marshal.GetDelegate ForFunctionPointer . dotnet/runtime#68694  also moved some trivial \\nfunctionalit\", \"y from native to managed, as part of relaxing argument validation on the use of pinning \\nhandles. Th\", \"is in turn measu rably reduced the overhead involved with using GCHandle.Alloc  for such \\npinning ha\", \"ndles:  \\nprivate byte[] _buffer = new byte[1024]; \\n \\n[Benchmark]  \\npublic void PinUnpin () \\n{ \\n    G\", \"CHandle. Alloc(_buffer, GCHandleType. Pinned).Free(); \\n} \\nMethod  Runtime  Mean  Ratio  Code Size  \\n\", \"PinUnpin  .NET 6.0  37.11 ns  1.00 353 B  \\nPinUnpin  .NET 7.0  32.17 ns  0.87 232 B   \\n89 CHAPTER 8 \", \"| Threading  \\n CHAPTER  8 \\nThreading  \\nThreading is one of those cross -cutting concerns that impact\", \"s every application, such that changes in \\nthe threading space can have a wide -spread impact. This \", \"release sees two very substantial changes to \\nthe ThreadPool  itself; dotnet/runtime#64834  switches\", \" the \\u201cIO pool\\u201d over to using an entirely \\nmanaged implementation (whereas previously the IO pool was\", \" still in native code even though the \\nworker pool had been moved entirely to managed in previo us r\", \"eleases), and dotnet/runtime#71864  \\nsimilarly switches the timer implementation from one based in n\", \"ative to one entirely in managed \\ncode. Those two changes can impact performance, and the f ormer wa\", \"s demonstrated to on larger \\nhardware, but for the most part that wasn\\u2019t their primary goal. Instead\", \", other PRs have been focused \\non improving throughput.  \\nOne in particular is dotnet/ru ntime#69386\", \" . The ThreadPool  has a \\u201cglobal queue\\u201d that any thread can \\nqueue work into, and then each thread i\", \"n the pool has its own \\u201clocal queue\\u201d (which any thread can \\ndequeue from but only the owning thread \", \"can enqueue into). When a worker needs another pi ece of \\nwork to process, it first checks its own l\", \"ocal queue, then it checks the global queue, and then only if it \\ncouldn\\u2019t find work in either of th\", \"ose two places, it goes and checks all of the other threads\\u2019 local \\nqueues to see if it can help lig\", \"hten thei r load. As machines scale up to have more and more cores, and \\nmore and more threads, ther\", \"e\\u2019s more and more contention on these shared queues, and in particular \\non the global queue. This PR\", \" addresses this for such larger machines by introducing additional g lobal \\nqueues once the machine \", \"reaches a certain threshold (32 processors today). This helps to partition \\naccesses across multiple\", \" queues, thereby decreasing contention.  \\nAnother is dotnet/runtime#57885 . In order to coordinate t\", \"hreads, when work items were enqueued \\nand dequeued, the pool was issuing requests to its threads to\", \" let them know that there was work \\navailable to d o. This, however, often resulted in oversubscript\", \"ion, where more threads than necessary \\nwould race to try to get work items, especially when the sys\", \"tem wasn\\u2019t at full load. That in turn would \\nmanifest as a throughput regression. This change overha\", \"uls how t hreads are requested, such that only \\none additional thread is requested at a time, and af\", \"ter that thread has dequeued its first work item, it \\ncan issue a request for an additional thread i\", \"f there\\u2019s work remaining, and then that one can issue an \\nadditional request, and so on. Here\\u2019s one \", \"of our performance tests in our performance test suite (I\\u2019ve \\nsimplified it down to remove a bunch o\", \"f configuration options from the test, but it\\u2019s still accurately \\none of those configurations). At f\", \"irst glance you might think , \\u201chey, this is a performance test about \\nArrayPool , why is it showing \", \"up in a threading discussion?\\u201d And, you\\u2019d be right, this is a performance \\ntest that was written foc\", \"used on ArrayPool . However, as mentioned earlier, threading impacts \\neverything, and in this case, \", \"that await Task.Yield()  in the middle there causes the remainder of \\nthis method to be queued to th\", \"e ThreadPool  for execution. And because of how the test is structured, \\ndoing \\u201creal work\\u201d that comp\", \"etes for CPU cycles with thread pool threads all racing to get their next \\ntask, it shows a measurab\", \"le improvement when moving to .NET 7.   \\n90 CHAPTER 8 | Threading  \\n private readonly  byte[][] _nes\", \"tedArrays = new byte[8][]; \\nprivate const int Iterations = 100_000; \\n \\nprivate static byte IterateAl\", \"l (byte[] arr) \\n{ \\n    byte ret = default; \\n    foreach (byte item in arr) ret = item;  \\n    return \", \"ret; \\n} \\n \\n[Benchmark (OperationsPerInvoke = Iterations)]  \\npublic async Task MultipleSerial () \\n{ \\n\", \"    for (int i = 0; i < Iterations; i++)  \\n    { \\n        for (int j = 0; j < _nestedArrays. Length;\", \" j++) \\n        { \\n            _nestedArrays[j] = ArrayPool< byte>.Shared.Rent(4096); \\n            _n\", \"estedArrays[j]. AsSpan().Clear(); \\n        } \\n \\n        await Task. Yield(); \\n \\n        for (int j =\", \" _nestedArrays. Length - 1; j >= 0; j--) \\n        { \\n            IterateAll (_nestedArrays[j]);  \\n  \", \"          ArrayPool< byte>.Shared.Return(_nestedArrays[j]);  \\n        } \\n    } \\n} \\nMethod  Runtime  \", \"Mean  Ratio  \\nMultipleSerial  .NET 6.0  14.340 us  1.00 \\nMultipleSerial  .NET 7.0  9.262 us  0.65 \\nT\", \"here have been improvements outside of ThreadPool , as well. One notable change is in the handling \\n\", \"of AsyncLocal<T> s, in dotnet/runtime#68790 . AsyncLocal<T>  is integrated tightly with \\nExecutio nC\", \"ontext ; in fact, in .NET Core, ExecutionContext  is entirely  about flowing AsyncLocal<T>  \\ninstanc\", \"es. An ExecutionContext  instance maintains a single field, a map data structure, that stores \\nthe d\", \"ata for all AsyncLocal<T>  with data present in that context. Each AsyncLocal<T>  has an object it \\n\", \"uses as a key, and any gets or sets on that AsyncLocal<T>  manifest as getting the current \\nExecutio\", \"nContext , looking up that AsyncLocal<T> \\u2019s key in the context\\u2019s dictionary, and then either \\nreturn\", \"ing whatever data it find s, or in the case of a setter, creating a new ExecutionContext  with an \\nu\", \"pdated dictionary and publishing that back. This dictionary thus needs to be very efficient for read\", \"s \\nand writes, as developers expect AsyncLocal<T>  access to be as fast as possible, o ften treating\", \" it as if \\nit were any other local. So, to optimize these lookups, the representation of that dictio\", \"nary changes \\nbased on how many AsyncLocal<T> s are represented in this context. For up to three ite\", \"ms, dedicated \\nimplementations with fields for each of the three keys and values were used. Above th\", \"at up to around \\n16 elements, an array of key/value pairs was used. And above that, a Dictionary<,> \", \" was used. For the \\nmost part, this has worked well, with the majority of ExecutionContext s being a\", \"ble to represent \\nmany flows with one of the first three types. However, it turns out that four acti\", \"ve AsyncLocal<T>  \\ninstances is really common, especially in ASP.NET where ASP.NET infrastructure it\", \"self uses a couple.  \\n91 CHAPTER 8 | Threading  \\n So, this PR took the complexity hit to add a d edi\", \"cated type for four key/value pairs, in order to \\noptimize from one to four of them rather than one \", \"to three. While this improves throughput a bit, its \\nmain intent was to improve allocation, which is\", \" does over .NET 6 by ~20%.  \\nprivate AsyncLocal< int> asyncLocal1 = new AsyncLocal< int>(); \\nprivate\", \" AsyncLocal< int> asyncLocal2 = new AsyncLocal< int>(); \\nprivate AsyncLocal< int> asyncLocal3 = new \", \"AsyncLocal< int>(); \\nprivate AsyncLocal< int> asyncLocal4 = new AsyncLocal< int>(); \\n \\n[Benchmark (O\", \"perationsPerInvoke = 4000)] \\npublic void Update() \\n{ \\n    for (int i = 0; i < 1000; i++) \\n    { \\n   \", \"     asyncLocal1. Value++; \\n        asyncLocal2. Value++; \\n        asyncLocal3. Value++; \\n        as\", \"yncLocal4. Value++; \\n    } \\n} \\nMethod  Runtime  Mean  Ratio  Code Size  Allocated  Alloc Ratio  \\nUpd\", \"ate  .NET 6.0  61.96 ns  1.00 1,272 B  176 B  1.00 \\nUpdate  .NET 7.0  61.92 ns  1.00 1,832 B  144 B \", \" 0.82 \\nAnother valuable fix comes for locking in dotnet/runtime#70165 . This particular improvement \", \"is a bit \\nharder to demonstrate with benchmarkdotnet, so just try running this program, first on .NE\", \"T 6 and \\nthen on .NET 7:  \\nusing System.Diagnost ics; \\n \\nvar rwl = new ReaderWriterLockSlim (); \\nvar\", \" tasks = new Task[100]; \\nint count = 0; \\n \\nDateTime end = DateTime. UtcNow + TimeSpan. FromSeconds (\", \"10); \\nwhile (DateTime. UtcNow < end) \\n{ \\n    for (int i = 0; i < 100; ++i) \\n    { \\n        tasks[i] \", \"= Task. Run(() => \\n        { \\n            var sw = Stopwatch. StartNew (); \\n            rwl.EnterRea\", \"dLock (); \\n            rwl.ExitReadLock (); \\n            sw.Stop(); \\n            if (sw.ElapsedMilli\", \"seconds  >= 10) \\n            { \\n                Console. WriteLine (Interlocked. Increment (ref coun\", \"t));  \\n            } \\n        }); \\n    } \\n \\n    Task.WaitAll(tasks);  \\n}  \\n92 CHAPTER 8 | Threading \", \" \\n This is simply spinning up 100 tasks, each of which enters and exits a read -write lock, waits fo\", \"r them \\nall, and then does the process over again, for 10 seconds. It also times how lo ng it takes \", \"to enter and \\nexit the lock, and writes a warning if it had to wait for at least 15ms. When I run th\", \"is on .NET 6, I get \\n~100 occurrences of it taking >= 10 ms to enter/exit the lock. On .NET 7, I get\", \" 0 occurrences. Why the \\ndifference? The implem entation of ReaderWriterLockSlim  has its own spin l\", \"oop implementation, and \\nthat spin loop tries to mix together various things to do as it spins, rang\", \"ing from calling \\nThread.SpinWait  to Thread.Sleep(0)  to Thread.Sleep(1) . The issue lies in the Th\", \"read.Sleep (1). \\nThat\\u2019s saying \\u201cput this thread to sleep for 1 millisecond\\u201d; however, the operating \", \"system has the \\nultimate say on such timings, and on Windows, by default that sleep is going to be c\", \"loser to 15 \\nmilliseconds (on Linux it\\u2019s a bit lower but still quite h igh). Thus, every time there \", \"was enough \\ncontention on the lock to force it to call Thread.Sleep(1) , we\\u2019d incur a delay of at le\", \"ast 15 \\nmilliseconds, if not more. The aforementioned PR fixed this by eliminating use of Thread.Sle\", \"ep(1) . \\nOne final threading -related change to call out: dotnet/runtime#68639 . This one is Windows\", \" specific. \\nWindows has the concept of processor groups, each of which can have up to 64 cores in it\", \", and by \\ndefault when a pro cess runs, it\\u2019s assigned a specific processor group and can only use th\", \"e cores in \\nthat group. With .NET 7, the runtime flips its default so that by default it will try to\", \" use all processor \\ngroups if possible.   \\n93 CHAPTER 9 | Primitive Types and Numerics  \\n CHAPTER  9\", \" \\nPrimitive Types and \\nNumerics  \\nWe\\u2019ve looked at code generation and GC, at threading and vectoriza\", \"tion, at interop\\u2026 let\\u2019s turn our \\nattention to some of the fundamental types in the system. Primitiv\", \"es like int and bool  and double , \\ncore types like Guid  and DateTime , they form the backbone on w\", \"hich everything is built, and every \\nrelease it\\u2019s exciting to see the improvements that find their w\", \"ay into these types.  \\nfloat  and double  got a very nice boost in their implementation of parsing (\", \"e.g. double.Parse , \\nfloat.TryParse , etc.). dotnet/runtime#62301  from [@CarlVerret](https://github\", \".com/CarlVerret) \\nsignificantly improves double.Parse  and float.Parse  for parsing UTF16 text into \", \"floating -point \\nvalues. This is particularly neat because  it\\u2019s based on some relatively recent res\", \"earch  from \\n[@lemire](https://github.com/lemire) and [@CarlVerret](https://github.com/CarlVerret), \", \"who used C# \\nwith .NET 5 to implement a very fast implementation for parsing floating -point numbers\", \", and that \\nimplementation how now found its way into .NET 7!  \\npriv ate string[] _valuesToParse;  \\n\", \" \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    using HttpClient hc = new HttpClient (); \\n    string t\", \"ext = \\nhc.GetStringAsync (\\\"https://raw.githubusercontent.com/CarlVerret/csFastFloat/1d800237275f759\\n\", \"b743b86fcce6680d072c1e834/Benchmark/d ata/canada.txt\\\" ).Result; \\n    var lines = new List<string>();\", \" \\n    foreach (ReadOnlySpan< char> line in text.AsSpan().EnumerateLines ()) \\n    { \\n        ReadOnly\", \"Span< char> trimmed = line. Trim(); \\n        if (!trimmed. IsEmpty) \\n        { \\n            lines.Ad\", \"d(trimmed.ToString ()); \\n        } \\n    } \\n    _valuesToParse = lines. ToArray(); \\n} \\n \\n[Benchmark] \", \" \\npublic double ParseAll () \\n{ \\n    double total = 0; \\n    foreach (string s in _valuesToParse)  \\n  \", \"  { \\n        total += double.Parse(s);  \\n94 CHAPTER 9 | Primitive Types and Numerics  \\n     } \\n    r\", \"eturn total; \\n} \\nMethod  Runtime  Mean  Ratio  \\nParseAll  .NET 6.0  26.84 ms  1.00 \\nParseAll  .NET 7\", \".0  12.63 ms  0.47 \\nbool.TryParse  and bool.TryFormat  were also improved. dotnet/runtime#64782  str\", \"eamlined these \\nimplementations by using BinaryPrimitives  to perform fewer writes and reads. For ex\", \"ample, instead \\nof TryFormat  writing out \\u201cTrue\\u201d by doing:  \\ndestination[ 0] = 'T'; \\ndestination[ 1]\", \" = 'r'; \\ndestination[ 2] = 'u'; \\ndestination[ 3] = 'e'; \\nwhich requires four writes, it can instead \", \"implement the same operation in a single write by doing:  \\nBinaryPrimitives. WriteUInt64LittleEndi a\", \"n(MemoryMarshal. AsBytes(destination), \\n0x65007500720054 ); // \\\"True\\\"  \\nThat 0x65007500720054  is th\", \"e numerical value of the four characters in memory as a single ulong . You \\ncan see the impact of th\", \"ese changes with a microbenchmark:  \\nprivate bool _value = true; \\nprivate char[] _chars = new char[]\", \" { 'T', 'r', 'u', 'e' }; \\n \\n[Benchmark] public bool ParseTrue () => bool.TryParse (_chars, out _); \\n\", \"[Benchmark] public bool FormatTrue () => _value. TryFormat (_chars, out _); \\nMethod  Runtime  Mean  \", \"Ratio  \\nParseTrue  .NET 6.0  7.347 ns  1.00 \\nParseTrue  .NET 7.0  2.327 ns  0.32 \\n    \\nFormatTrue  .\", \"NET 6.0  3.030 ns  1.00 \\nFormatTrue  .NET 7.0  1.997 ns  0.66 \\nEnum  gets several performance boosts\", \", as well. For example, when performing an operation like \\nEnum.IsDefined , Enum.GetName , or Enum.T\", \"oString , the implementation consults a cache of all of the \\nvalues defined on the enum. This cache \", \"includes the string name and the value for every defined \\nenumeration in the Enum . It\\u2019s also sorted\", \" by value in an array, so when one of these operations is \\nperformed, the code uses Array.BinarySear\", \"ch  to find the index of the relevant entry. The issue with \\nthat is one of overheads. Whe n it come\", \"s to algorithmic complexity, a binary search is faster than a \\nlinear search; after all, a binary se\", \"arch is O(log N)  whereas a linear search is O(N) . However, there\\u2019s \\nalso less overhead for every s\", \"tep of the algorithm in a linear search, and so for  smaller values of N, it \\ncan be much faster to \", \"simply do the simple thing. That\\u2019s what dotnet/runtime#57973  does for enums. \\nFor enums with less t\", \"han or equal to 32 defined values, the implemen tation now just does a linear \\nsearch via the intern\", \"al SpanHelpers.IndexOf  (the worker routine behind IndexOf  on spans, strings,  \\n95 CHAPTER 9 | Prim\", \"itive Types and Numerics  \\n and arrays), and for enums with more than that, it does a SpanHelpers.Bi\", \"narySearch  (which is the \\nimplementation for Array.BinarySearch ). \\nprivate DayOfWeek[] _days = Enu\", \"m. GetValues <DayOfWeek>();  \\n \\n[Benchmark]  \\npublic bool AllDefined () \\n{ \\n    foreach (DayOfWeek d\", \"ay in _days) \\n    { \\n        if (!Enum.IsDefined (day)) \\n        { \\n            return false; \\n     \", \"   } \\n    } \\n \\n    return true; \\n} \\nMethod  Runtime  Mean  Ratio  \\nAllDefined  .NET 6.0  159.28 ns  \", \"1.00 \\nAllDefined  .NET 7.0  94.86 ns  0.60 \\nEnum s also get a boost in conjunction with Nullable<T> \", \" and EqualityComparer<T>.Default . \\nEqualityComparer<T>.Default  caches a singleton instance of an E\", \"qualityComparer<T>  instance \\nreturned from all accesses to Default . That singleton is initialized \", \"based on the T in question, with the \\nimplementation choosing from a  multitude of different interna\", \"l implementations, for example a \\nByteArrayComparer  specialized for bytes, a GenericEqualityCompare\", \"r<T>  for Ts that implement \\nIComparable<T> , and so on. The catch -all, for arbitrary types, is an \", \"ObjectEqualityComparer<T> . As i t \\nhappens, nullable enums would end up hitting this catch -all pat\", \"h, which means that every Equals  call \\nwould box the arguments. dotnet/runtime#68077  fixes this by\", \" ensuring nullable enums get m apped \\nto (an existing) specialized comparer for Nullable<T>  and sim\", \"ple tweaks its definition to ensure it can \\nplay nicely with enums. The results highlight just how m\", \"uch unnecessary overhead there was \\npreviously.  \\nprivate DayOfWeek?[] _enums = Enum. GetValue s<Day\", \"OfWeek>(). Select(e => \\n(DayOfWeek?)e). ToArray(); \\n \\n[Benchmark]  \\n[Arguments (DayOfWeek. Saturday \", \")] \\npublic int FindEnum (DayOfWeek value) => IndexOf(_enums, value);  \\n \\nprivate static int IndexOf<\", \"T>(T[] values, T value)  \\n{ \\n    for (int i = 0; i < values. Length; i++) \\n    { \\n        if (Equali\", \"tyComparer<T>. Default.Equals(values[i], value))  \\n        { \\n            return i; \\n        } \\n    \", \"} \\n \\n    return -1; \\n}  \\n96 CHAPTER 9 | Primitive Types and Numerics  \\n Method  Runtime  Mean  Ratio\", \"  \\nFindEnum  .NET 6.0  421.608 ns  1.00 \\nFindEnum  .NET 7.0  5.466 ns  0.01 \\nNot to be left out, Gui\", \"d \\u2019s equality operations also get faster, thanks to dotnet/runtime#66889  from \\n[@madelson](https://\", \"github.com/madelson). The previous implementation of Guid  split the data  into \\nfour 32 -bit values\", \" and performed 4 int comparisons. With this change, if the current hardware has \\n128-bit SIMD suppor\", \"t, the implementation loads the data from the two guids as two vectors and \\nsimply does a single com\", \"parison.  \\nprivate Guid _guid1 = Gui d.Parse(\\\"0aa2511d -251a-4764-b374-4b5e259b6d9a\\\" ); \\nprivate Gui\", \"d _guid2 = Guid. Parse(\\\"0aa2511d -251a-4764-b374-4b5e259b6d9a\\\" ); \\n \\n[Benchmark]  \\npublic bool GuidE\", \"quals () => _guid1 == _guid2;  \\nMethod  Runtime  Mean  Ratio  Code Size  \\nGuidEquals  .NET 6.0  2.11\", \"9 ns  1.00 90 B \\nGuidEquals  .NET 7.0  1.354 ns  0.64 78 B \\nDateTime  equality is also improved. dot\", \"net/runtime#59857  shaves some overhead off of \\nDateTime.Equals . DateTime  is implemented with a si\", \"ngle ulong _dateData  field, where the majority \\nof the bits store a ticks offset from 1/1/0001 12:0\", \"0am and where each tick is 100 nanoseconds, and \\nwhere the top two bits describe the DateTimeKind . \", \"Thus the public Ticks  property returns the value \\nof _dateData  but with the top two bits masked ou\", \"t, e.g. _dateData & 0x3FFFFFFFFFFFFFFF . The \\nequality operators were all then just comparing one Da\", \"teTime \\u2019s Ticks  against the others, such that we \\neffectively get (dt1._dateData & 0x3FFFFFFFFFFFFF\", \"FF) == (dt2._dateData & \\n0x3FFFFFFFF FFFFFFF) . However, as a micro -optimization that can instead b\", \"e expressed more \\nefficiently as ((dt1._dateData ^ dt2._dateData) << 2) == 0 . It\\u2019s difficult to mea\", \"sure the \\ndifference in such tiny operations, but you can see it simply from the number of instruc t\", \"ions involved, \\nwhere on .NET 6 this produces:  \\n; Program.DateTimeEquals()  \\n       mov       rax,[\", \"rcx+8]  \\n       mov       rdx,[rcx+10]  \\n       mov       rcx,0FFFFFFFFFFFF  \\n       and       rax,r\", \"cx  \\n       and       rdx,rcx  \\n       cmp       rax,rdx  \\n       sete      al  \\n       movzx     ea\", \"x,al  \\n       ret \\n; Total bytes of code 34  \\nand on .NET 7 this produces:  \\n; Program.DateTimeEqual\", \"s()  \\n       mov       rax,[rcx+8]  \\n       mov       rdx,[rcx+10]  \\n       xor       rax,rdx  \\n    \", \"   shl       rax,2  \\n97 CHAPTER 9 | Primitive Types and Numerics  \\n        sete      al  \\n       mov\", \"zx     eax,al  \\n       ret \\n; Total bytes of code 22  \\nso instead of a mov, and, and, and cmp, we ge\", \"t just an xor and a shl. \\nOther operations on DateTime  also become more efficient, thanks to dotnet\", \"/runtime#72712  from \\n[@SergeiPavlov](https://github.com/SergeiPavlov) and dotnet/run time#73277  fr\", \"om \\n[@SergeiPavlov](https://github.com/SergeiPavlov). In another case of .NET benefiting from recent\", \" \\nadvancements in research, these PRs implemented the algorithm from Neri and Schneider\\u2019s \\n\\u201cEuclidea\", \"n Affine Functions and Applications to Calendar Algorithms\\u201d  in order to improve \\nDateTime.Day , Dat\", \"eTime.DayOfYear , DateTime.Month , and DateTime.Year , as well as the internal \\nhelper DateTime.GetD\", \"ate()  that\\u2019s used by a bunch of other methods like DateTime.AddMonths , \\nUtf8Formatter.TryFormat(Da\", \"teTime, ...) , DateTime.TryFormat , and DateTime.ToString . \\nprivate DateTime _dt = DateTime. UtcNow\", \"; \\nprivate char[] _dest = new char[100]; \\n \\n[Benchmark] public int Day() => _dt. Day; \\n[Benchmark] p\", \"ublic int Month() => _dt.Month; \\n[Benchmark] public int Year() => _dt. Year; \\n[Benchmark] public boo\", \"l TryFormat () => _dt. TryFormat (_dest, out _, \\\"r\\\"); \\nMethod  Runtime  Mean  Ratio  \\nDay .NET 6.0  \", \"5.2080 ns  1.00 \\nDay .NET 7.0  2.0549 ns  0.39 \\n    \\nMonth  .NET 6.0  4.1186 ns  1.00 \\nMonth  .NET 7\", \".0  2.0945 ns  0.51 \\n    \\nYear .NET 6.0  3.1422 ns  1.00 \\nYear .NET 7.0  0.8200 ns  0.26 \\n    \\nTryFo\", \"rmat  .NET 6.0  27.6259 ns  1.00 \\nTryFormat  .NET 7.0  25.9848 ns  0.94 \\nSo, we\\u2019ve touched on improv\", \"ements to a few types, but the pi\\u00e8ce de r\\u00e9sistance around primitive types \\nin this release is \\u201cgener\", \"ic math,\\u201d which impacts almost every primitive type in .NET. There are \\nsignificant improvements her\", \"e, some which have been in the making for literally over a decade.  \\nThere\\u2019s an excellent blog post \", \"from June dedicated just to generic math , so I won\\u2019t go into much \\ndepth here. At a high level, how\", \"ever, there are now over 30 new interfaces that utilize the new C# 11 \\nstatic ab stract interface me\", \"thods functionality, exposing wide -ranging operations from exponentiation \\nfunctions to trigonometr\", \"ic functions to standard numerical operators, all available via generics, such \\nthat you can write o\", \"ne implementation that operates over the se interfaces generically and have your  \\n98 CHAPTER 9 | Pr\", \"imitive Types and Numerics  \\n code applied to any types that implement the interfaces\\u2026 which all of \", \"the numerical types in .NET 7 \\ndo (including not just the primitives but also, for example, BigInteg\", \"er  and Complex ). A preview \\nversion of this feat ure, including necessary runtime support, languag\", \"e syntax, C# compiler support, \\ngeneric interfaces, and interface implementations all shipped in .NE\", \"T 6 and C# 10, but it wasn\\u2019t \\nsupported for production use, and you had to download an experimental \", \"reference  assembly in order \\nto get access. With dotnet/runtime#65731 , all of this support moved i\", \"nto .NET 7 as supported \\nfunctionality. dotnet/runtime#66748 , dotnet/runtime#67453 , dotnet/runtime\", \"#69391 , \\ndotnet/runtime#69582 , dotnet/runtime#69756 , and dotnet/runtime#71800  all updated the de\", \"sign \\nand implementation based on feedbac k from usage in .NET 6 and .NET 7 previews as well as a pr\", \"oper \\nAPI review with our API review team (a process every new API in .NET goes through before it\\u2019s \", \"\\nshipped publicly). dotnet/runtime#6 7714  added support for user -defined checked  operators, a new\", \" \\nC# 11 feature that enables both unchecked  and checked  variations of operators to be exposed, wit\", \"h \\nthe compiler picking the right one based on the checked  context. dotnet/runtime#68096  also adde\", \"d \\nsupport for the new C# 11 unsigned right shift operator ( >>>). And dotnet/runtime#69651 , \\ndotne\", \"t/runtime#67939 , dotnet/runtime#73274 , dotnet/runtime#71033 , dotnet/runtime#71010 , \\ndotnet/runti\", \"me#68251 , dotnet/runtime#68217 , and dotnet/runtime#68094  all added large swaths of \\nnew public su\", \"rface area for various operations, all with highly -efficient managed implementations, in \\nmany case\", \"s based on the open source AMD Math Library . \\nWhile this support is all primarily intended for exte\", \"rnal consumers, the core libraries do consume \\nsome of it internally. You can see how these APIs cle\", \"an up consuming code even while m aintaining \\nperformance in PRs like dotnet/runtime#68226  and dotn\", \"et/runtime#68183 , which use the interfaces \\nto deduplicate a bunc h of LINQ code in Enumerable .Sum\", \"/Average /Min/Max. There are multiple \\noverloads of these methods for int, long , float , double , a\", \"nd decimal . The GitHub summary of the \\ndiffs tells the story on how much code was able to be delete\", \"d:  \\n \\n \\nAnother simple example c omes from the new System.Formats.Tar  library in .NET 7, which as \", \"the \\nname suggests is used for reading and writing archives in any of multiple tar file formats . Th\", \"e tar file \\nformats include integer values in octal representation, so the TarReader  class needs to\", \" parse octal \\nvalues. Some of these values are 32 -bit integers, and some are 64 -bit integers. Rath\", \"er than have two \\nseparate ParseOctalAsUInt32  and ParseOctalAsUInt64  meth ods, dotnet/runtime#7428\", \"1 ] \\nconsolidated the methods into a single ParseOctal<T>  with the constraint where T : struct, \\nIN\", \"umber<T> . The implementation is then entirely in terms of T and can be used for either of these \\nty\", \"pes (plus any other types meeting the constraints, should that ever be needed). What\\u2019s particularly \", \"\\ninteresting about this example is the ParseOctal<T>  method include s use of checked , e.g. value =\", \" \\nchecked((value * octalFactor) + T.CreateTruncating(digit)); . This is only possible because \\nC# 11\", \" includes the aforementioned support for user-defined checked operators , enabling the generic \\nmath\", \" interfaces to support both the normal and checked varieties, e.g.  the IMultiplyOperators<,,>  \\nint\", \"erface contains these methods:  \\n \\n99 CHAPTER 9 | Primitive Types and Numerics  \\n static abstract  T\", \"Result operator  *(TSelf left, TO ther right);  \\nstatic virtual TResult operator  checked *(TSelf le\", \"ft, TOther right) => left * right;  \\nand the compiler will pick the appropriate one based on the con\", \"text.  \\nIn addition to all the existing types that get these interfaces, there are also new types . \", \"\\ndotnet/runtime#69204  adds the new Int128  and UInt128  types. As these types implement all of the \", \"\\nrelevant generic math interfaces, they come complete with a huge number of methods, over 100 e ach,\", \" \\nall of which are implemented efficiently in managed code. In the future, the aim is that some set \", \"of \\nthese will be optimized further by the JIT and to take advantage of hardware acceleration.  \\nSev\", \"eral PRs moved native implementations of these kinds of math operations to managed code. \\ndotnet/run\", \"time#63881  from [@am11](https://github.com/am11) did so for Math.Abs  and Math.AbsF  \\n(absolute val\", \"ue), and dotnet/runtime#56236  from \\n[@alexcovington](https://github.com/alexcovington) did so for M\", \"ath.ILogB  and MathF.ILogB  (base 2 \\ninteger logarithm). The latter\\u2019s implementation is based on the\", \" MUSL libc implementation of the same \\nalgorithm, a nd in addition to improving performance (in part\", \" by avoiding the transition between \\nmanaged and native code, in part by the actual algorithm employ\", \"ed), it also enabled deleting two \\ndistinct implementations from native code, one from the coreclr s\", \"ide and on e from the mono side, \\nwhich is always a nice win from a maintainability perspective.  \\n[\", \"Benchmark]  \\n[Arguments (12345.6789 )] \\npublic int ILogB(double arg) => Math. ILogB(arg); \\nMethod  R\", \"untime  arg Mean  Ratio  \\nILogB  .NET 6.0  12345.6789  4.056 ns  1.00 \\nILogB  .NET 7.0 12345.6789  1\", \".059 ns  0.26 \\nOther math operations were also improved in various ways. Math{F}.Truncate  was impro\", \"ved in \\ndotnet/runtime#65014  from [@MichalPetryka](https://github.com/MichalPet ryka) by making it \", \"into a \\nJIT intrinsic, such that on Arm64 the JIT could directly emit a frintz  instruction. \\ndotnet\", \"/runtime#65584  did the same for Max and Min so that the Arm -specific fmax  and fmin  \\ninstructions\", \" could be used. And several BitConverter  APIs were also turned into intrinsics in \\ndotnet/runtime#7\", \"1567  in order to enable better code generation in some generic math scenari os. \\ndotnet/runtime#551\", \"21  from [@key -moon](https://github.com/key -moon) also improves parsing, but \\nfor BigInteger , and\", \" more specifically for really, really big BigIntegers . The algorithm previo usly \\nemployed for pars\", \"ing a string into a BigInteger  was O(N^2)  where N is the number of digits, but \\nwhile a larger alg\", \"orithmic complexity than we\\u2019d normally like, it has a low constant overhead and so is \\nstill reasona\", \"ble for reasonably -sized values. In co ntrast, an alternative algorithm is available that runs \\nin \", \"O(N * (log N)^2)  time, but with a much higher constant factor involved. That makes is so that it\\u2019s \", \"\\nreally only worth switching for really big numbers. Which is what this PR does. It implements the \\n\", \"alternative algorithm and switches over to it when the input is at least 20 ,000 digits (so, yes, bi\", \"g). But \\nfor such large numbers, it makes a significant difference.  \\n   \\n100 CHAPTER 9 | Primitive \", \"Types and Numerics  \\n  \\nprivate string _input = string.Concat(Enumerable. Repeat(\\\"1234567890\\\" , 100_\", \"000)); // \\\"One \\nmiiilliiiion digits\\\"  \\n \\n[Benchmark]  \\npublic BigInteger Parse() => BigInteger. Pars\", \"e(_input);  \\nMethod  Runtime  Mean  Ratio  \\nParse  .NET 6.0  3.474 s  1.00 \\nParse  .NET 7.0  1.672 s\", \"  0.48 \\nAlso related to BigInteger  (and not just for really big ones), dotnet/runtime#35565  from \\n\", \"[@sakno](https://github.com/sakno) overhauled much of the internals of BigInteger  to be based on \\ns\", \"pans rather than arrays. That in turn enabled a fair amount of use of stack allocation and slicing t\", \"o \\navoid allocation overheads, while also improving reliability and safety by moving some code away \", \"\\nfrom unsafe pointers to safe spans. The primary performance impact is visible in allocation numbers\", \", \\nand in particular for oper ations related to division.  \\nprivate BigInteger _bi1 = BigInteger. Pa\", \"rse(string.Concat(Enumerable. Repeat(\\\"9876543210\\\" , \\n100))); \\nprivate BigInteger _bi2 = BigInteger. \", \"Parse(string.Concat(Enumerable. Repeat(\\\"1234567890\\\" , \\n100))); \\nprivate BigInteger _bi3 = BigInteger\", \". Parse(string.Concat(Enumerable. Repeat(\\\"12345\\\", 10))); \\n \\n[Benchmark]  \\npublic BigInteger ModPow()\", \" => BigInteger. ModPow(_bi1, _bi2, _bi3);  \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nM\", \"odPow  .NET 6.0  1.527 ms  1.00 706 B  1.00 \\nModPow  .NET 7.0  1.589 ms  1.04 50 B 0.07  \\n101 CHAPTE\", \"R 10 | Arrays, Strings, and Spans  \\n CHAPTER  10 \\nArrays, Strings, and Spans  \\nWhile there are many \", \"forms of computation that can consume resources in applications, some of the \\nmost common include pr\", \"ocessing of data stored in arrays, strings, and now spans. Thus you see a \\nfocus in every .NET relea\", \"se on removing as much overhead as po ssible from such scenarios, while also \\nfinding ways to furthe\", \"r optimize the concrete operations developers are commonly performing.  \\nLet\\u2019s start with some new A\", \"PIs that can help make writing more efficient code easier. When examining \\nstring parsing/processi n\", \"g code, it\\u2019s very common to see characters examined for their inclusion in \\nvarious sets. For exampl\", \"e, you might see a loop looking for characters that are ASCII digits:  \\nwhile (i < str. Length) \\n{ \\n\", \"    if (str[i] >= '0' && str[i] <= '9') \\n    { \\n        i++; \\n    } \\n} \\nor that are ASCII letters:  \", \"\\nwhile (i < str. Length) \\n{ \\n    if ((str[i] >= 'a' && str[i] <= 'z') || (str[i] >= 'A' && str[i] <=\", \" 'Z')) \\n    { \\n        i++; \\n    } \\n} \\nor other such groups. Interestingly, there\\u2019s wide -spread var\", \"iation in how such  checks are coded, often \\ndepending on how much effort a developer put in to opti\", \"mizing them, or in some cases likely not \\neven recognizing that some amount of performance was being\", \" left on the table. For example, that \\nsame ASCII letter check could instead b e written as:  \\nwhile\", \" (i < str. Length) \\n{ \\n    if ((uint)((c | 0x20) - 'a') <= 'z' - 'a') \\n    { \\n        i++; \\n    } \\n}\", \" \\nwhich while more \\u201cintense\\u201d is also much more concise and more efficient. It\\u2019s taking advantage of \", \"a \\nfew tricks. First, rather than having two c omparisons to determine whether the character is grea\", \"ter \\nthan or equal to the lower bound and less than or equal to the upper bound, it\\u2019s doing a single\", \" \\ncomparison based on the distance between the character and the lower bound ( (uint)(c - 'a') ). If\", \" \\n'c' is beyond 'z', then 'c' - 'a' will be larger than 25, and the comparison will fail. If 'c' is \", \"earlier  \\n102 CHAPTER 10 | Arrays, Strings, and Spans  \\n than 'a', then 'c' - 'a' will be negative, \", \"and casting it to uint  will then cause it to wrap around to a \\nmassive number, also larger than 25,\", \" again causing the comparison to fail. Thus, we\\u2019re able to pay a \\nsingle additional subtraction to a\", \"void an entire additional comparison and branch, which is almost  \\nalways a good deal. The second tr\", \"ick is that | 0x20 . The ASCII table has some well -thought -out \\nrelationship s, including that upp\", \"er -case 'A' and lower -case 'a' differ by only a single bit ( 'A' is \\n0b1000001  and 'a' is 0b11000\", \"01 ). To go from any lowercase ASCII letter to its uppercase ASCII \\nequivalent, we thus need only to\", \" & ~0x20  (to turn off that bit), and to go in the opposite direction \\nfrom any uppercase ASCII lett\", \"er to its lowercase ASCII equivalent, we need only to | 0x20  (to turn on \\nthat bit). We can take ad\", \"vantage of t his in our range check, then, by normalizing our char c to be \\nlowercase, such that for\", \" the low cost of a bit twiddle, we can achieve both the lowercase and \\nuppercase range checks. Of co\", \"urse, those tricks aren\\u2019t something we want every developer to have to \\nknow and write on each use. \", \"Instead, .NET 7 exposes a bunch of new helpers on System.Char  to \\nencapsulate these common checks, \", \"done in an efficient manner. char  already had methods like \\nIsDigit  and IsLetter , which provided \", \"the more comprehensive Unicode mea ning of those monikers \\n(e.g. there are ~320 Unicode characters c\", \"ategorized as \\u201cdigits\\u201d). Now in .NET 7, there are also these \\nhelpers:  \\n\\u2022 IsAsciiDigit  \\n\\u2022 IsAsciiH\", \"exDigit  \\n\\u2022 IsAsciiHexDigitLower  \\n\\u2022 IsAsciiHexDigitUpper  \\n\\u2022 IsAsciiLetter  \\n\\u2022 IsAsciiLetterLower  \", \"\\n\\u2022 IsAsciiLetterUpper  \\n\\u2022 IsAsciiLetterOrDigit  \\nThese methods were added by dotnet/runtime#69318 , \", \"which also employed them in dozens of \\nlocations where such checks were being performed across dotne\", \"t/runtime  (many of them using less -\\nefficient approaches).  \\nAnother new API focused on encapsulat\", \"ing a common pattern is the new \\nMemoryExtensions.CommonPrefixLength  method, introduced by dotnet/r\", \"untime#67929 . This accepts \\neither two ReadOnlySpan<T>  instances or a Span<T>  and a ReadOnlySpan<\", \"T> , and an optional \\nIEqualityComparer<T> , and returns the number of elements that are the same at\", \" the beginning of \\neach input span. This is useful when you want to know the first place that two in\", \"puts differ. \\ndotnet/runtime#68210  from [@gfoidl](https://github.com/gfoidl) then utili zed the new\", \" Vector128  \\nfunctionality to provide a basic vectorization of the implementation. As it\\u2019s comparing\", \" two sequences \\nand looking for the first place they differ, this implementation uses a neat trick, \", \"which is to have a \\nsingle method implemented to compare the sequences as bytes. If the T being comp\", \"ared is bitwise -\\nequatable and no custom equality comparer is supplied, then it reinterpret -casts \", \"the refs from the \\nspans as byte  refs, and uses the single shared implementation.  \\nYet another new\", \" set of APIs  are the IndexOfAnyExcept  and LastIndexOfAnyExcept  methods, \\nintroduced by dotnet/run\", \"time#67941  and used in a variety of additional call sites by \\ndotnet/runtime#71146  and dotnet/runt\", \"ime#71278 . While somewhat of a mouthful, t hese methods \\nare quite handy. They do what their name s\", \"uggests: whereas IndexOf(T value)  searches for the first  \\n103 CHAPTER 10 | Arrays, Strings, and Sp\", \"ans  \\n occurrence of value  in the input, and whereas IndexOfAny(T value0, T value1, ...)  searches \", \"for \\nthe first occurrence of any of value0 , value1 , etc. in the input, IndexOfAnyExcept(T value)  \", \"searches \\nfor the first occurrence of something that\\u2019s not equal to value , and similarly IndexOfAny\", \"Except(T \\nvalue0, T value1, ...)  searches for the first occurrence of something that\\u2019s not equal to\", \" value0 , \\nvalue1 , etc. For example, let\\u2019s say you wanted to know whether an array of integers was \", \"entirely 0. \\nYou can now write that as:  \\nbool allZero = array. AsSpan().IndexOfAnyExcept (0) < 0; \\n\", \"dotnet/runtime#734 88 vectorizes this overload, as well.  \\nprivate byte[] _zeros = new byte[1024]; \\n\", \" \\n[Benchmark (Baseline = true)] \\npublic bool OpenCoded () \\n{ \\n    foreach (byte b in _zeros) \\n    { \", \"\\n        if (b != 0) \\n        { \\n            return false; \\n        } \\n    } \\n \\n    return true; \\n} \", \"\\n \\n[Benchmark]  \\npublic bool IndexOfAnyExcept () => _zeros. AsSpan().IndexOfAnyExcept ((byte)0) < 0;\", \" \\nMethod  Mean  Ratio  \\nOpenCoded  370.47 ns  1.00 \\nIndexOfAnyExcept  23.84 ns  0.06 \\nOf course, whi\", \"le new \\u201cindex of\\u201d variations are helpful, we already have a bunch of such methods, and \\nit\\u2019s importa\", \"nt that they are as efficient as possible. These core IndexOf{Any}  methods are used in \\nhuge number\", \"s of places, many of which are performance -sensitive, and so every release th ey get \\nadditional te\", \"nder -loving care. While PRs like dotnet/runtime#67811  got gains by paying very close \\nattention to\", \" the assembly code being generated (in this case, tweaking some of the checks used on \\nArm64 in Inde\", \"xOf  and IndexOfAny  to achieve better utilization), the biggest improvements here come \\nin places w\", \"here either vect orization was added and none was previously employed, or where the \\nvectorization s\", \"cheme was overhauled for significant gain. Let\\u2019s start with dotnet/runtime#63285 , \\nwhich yields hug\", \"e improvemen ts for many uses of IndexOf  and LastIndexOf  for \\u201csubstrings\\u201d of byte s \\nand char s. P\", \"reviously, given a call like str.IndexOf(\\\"hello\\\") , the implementation would essentially \\ndo the equ\", \"ivalent of repeatedly searching for the \\u2018h\\u2019, and when an \\u2018h\\u2019 was found, then  performing a \\nSequence\", \"Equal  to match the remainder. As you can imagine, however, it\\u2019s very easy to run into cases \\nwhere \", \"the first character being searched for is very common, such that you frequently have to break \\nout o\", \"f the vectorized loop in order to do the full string comparison. Instead, the PR implements an \\nalgo\", \"rithm based on SIMD -friendly algorithms for substring searching . Rather than just searching for \\nt\", \"he fir st character, it can instead vectorize a search for both the first and last character at appr\", \"opriate \\ndistances from each other. In our \\u201chello\\u201d example, in any given input, it\\u2019s much more likel\", \"y to find an  \\n104 CHAPTER 10 | Arrays, Strings, and Spans  \\n \\u2018h\\u2019 than it is to find an \\u2018h\\u2019 followed\", \" four charact ers later by an \\u2018o\\u2019, and thus this implementation is able \\nto stay within the vectoriz\", \"ed loop a lot longer, garnering many fewer false positives that force it down \\nthe SequenceEqual  ro\", \"ute. The implementation also handles cases where the two characters selec ted \\nare equal, in which c\", \"ase it\\u2019ll quickly look for another character that\\u2019s not equal in order to maximize \\nthe efficiency o\", \"f the search. We can see the impact of all of this with a couple of examples:  \\nprivate static reado\", \"nly  string s_haystack = new \\nHttpClient().GetStringAsync (\\\"https://www.gutenberg.org/files/1661/166\", \"1 -0.txt\\\").Result; \\n \\n[Benchmark]  \\n[Arguments (\\\"Sherlock\\\" )] \\n[Arguments (\\\"elementary\\\" )] \\npublic i\", \"nt Count(string needle) \\n{ \\n    ReadOnlySpan< char> haystack = s_haystack;  \\n    int count = 0, pos;\", \" \\n    while ((pos = haystack. IndexOf(needle)) >= 0) \\n    { \\n        haystack = haystack. Slice(pos \", \"+ needle. Length); \\n        count++;  \\n    } \\n \\n    return count; \\n} \\nThis is pulling down the text \", \"to \\u201cThe Adventures of Sherlock Holmes\\u201d from Project Gutenberg and \\nthen ben chmarking using IndexOf \", \" to count the occurrences of \\u201cSherlock\\u201d and \\u201celementary\\u201d in the \\ntext. On my machine, I get results \", \"like this:  \\nMethod  Runtime  needle  Mean  Ratio  \\nCount  .NET 6.0  Sherlock  43.68 us  1.00 \\nCount\", \"  .NET 7.0  Sherlock  48.33 us  1.11 \\n     \\nCount  .NET 6.0  elementary  1,063.67 us  1.00 \\nCount  .\", \"NET 7.0  elementary  56.04 us  0.05 \\nFor \\u201cSherlock\\u201d, the performance is actually a bit worse in .NET\", \" 7 than in .NET 6; not much, but a \\nmeasurable 10%. That\\u2019s because there are very few capital 'S' ch\", \"aracters in the source text, 841 to be \\nexact, out of 593,836 characters in the document. At on ly 0\", \".1% density of the starting character, the \\nnew algorithm doesn\\u2019t bring much benefit, as the existin\", \"g algorithm that searched for the first \\ncharacter alone captures pretty much all of the possible ve\", \"ctorization gains to be had, and we do pay \\na bit of ov erhead in doing a search for both the 'S' an\", \"d the 'k', whereas previously we\\u2019d have only \\nsearched for the 'S'. In contrast, though, there are 5\", \"4,614 'e' characters in the document, so almost \\n10% of the source. In that case, .NET 7 is 20x fast\", \"er than .NET 6 , taking 53us on .NET 7 to count all the \\n'e'\\u2019s vs 1084us on .NET 6. In this case, th\", \"e new scheme yields immense gains, by vectorizing a search \\nfor both the 'e' and a 'y' at the specif\", \"ic distance away, a combination that is much, much less \\nfrequent. This is  one of those situations \", \"where overall there are on average huge observed gains even \\nthough we can see small regressions for\", \" some specific inputs.   \\n105 CHAPTER 10 | Arrays, Strings, and Spans  \\n Another example of signific\", \"antly changing the algorithm employed is dotnet/runtime#67758 , which \\nenables some amount of vector\", \"ization to be applied to IndexOf(\\\"...\\\", \\nStringComparison.OrdinalIgnoreCase) . Previously, this oper\", \"ation was implemented with a fairly \\ntypical substring search, walking the in put string and at ever\", \"y location doing an inner loop to \\ncompare the target string, except performing a ToUpper  on every \", \"character in order to do it in a case -\\ninsensitive manner. Now with this PR, which is based on appr\", \"oaches previously used by Regex , if th e \\ntarget string begins with an ASCII character, the impleme\", \"ntation can use IndexOf  (if the character isn\\u2019t \\nan ASCII letter) or IndexOfAny  (if the character \", \"is an ASCII letter) to quickly jump ahead to the first \\npossible location of a match. Let\\u2019s take the\", \" exact same benchmark as we just looked at, but tweaked \\nto use OrdinalIgnoreCase : \\nprivate static \", \"readonly  string s_haystack = new \\nHttpClient ().GetStringAsync (\\\"https://www.gutenberg.org/files/16\", \"61/1661 -0.txt\\\").Result; \\n \\n[Benchmark]  \\n[Arguments (\\\"Sherlock\\\" )] \\n[Arguments(\\\"elementary\\\" )] \\npub\", \"lic int Count(string needle) \\n{ \\n    ReadOnlySpan< char> haystack = s_haystack;  \\n    int count = 0,\", \" pos; \\n    while ((pos = haystack. IndexOf(needle, StringComparison. OrdinalIgnoreCase )) >= 0) \\n   \", \" { \\n        haystack = haystack. Slice(pos + needle. Length); \\n        count++;  \\n    } \\n \\n    retur\", \"n count; \\n} \\nHere, both words are about 4x faster on .NET 7 than they were on .NET 6:  \\nMethod  Runt\", \"ime  needle  Mean  Ratio  \\nCount  .NET 6.0  Sherlock  2,113.1 us  1.00 \\nCount  .NET 7.0  Sherlock  4\", \"67.3 us  0.22 \\n     \\nCount  .NET 6.0  elementary  2,325.6 us  1.00 \\nCount  .NET 7.0  elementary  638\", \".8 us  0.27 \\nas we\\u2019re now doing a vectorized IndexOfAny('S', 's')  or IndexOfAny('E', 'e')  rather t\", \"han \\nmanually walking each character and comparing it. ( dotnet/runtime#73533  uses the same approac\", \"h \\nnow for handling IndexOf(char, StringComparison.OrdinalIgnoreCase). ) \\nAnother example  comes fro\", \"m dotnet/runtime#67492  from [@gfoidl](https://github.com/gfoidl). It \\nupdates MemoryExtensions.Cont\", \"ains  with the approach we discussed earlier for handling the \\nleftover elements at th e end of vect\", \"orized operation: process one last vector\\u2019s worth of data, even if it \\nmeans duplicating some work a\", \"lready done. This particularly helps for smaller inputs where the \\nprocessing time might otherwise b\", \"e dominated by the serial handling of those l eftovers.  \\nprivate byte[] _data = new byte[95]; \\n  \\n1\", \"06 CHAPTER 10 | Arrays, Strings, and Spans  \\n [Benchmark]  \\npublic bool Contains () => _data. AsSpan\", \"().Contains ((byte)1); \\nMethod  Runtime  Mean  Ratio  \\nContains  .NET 6.0  15.115 ns  1.00 \\nContains\", \"  .NET 7.0  2.557 ns  0.17 \\ndotnet/runtime#60974  from [@alexcovington](https://github.com/alexcovin\", \"gton) broadens the \\nimpact of IndexOf . Prior to this PR, IndexOf  was vectorized for one and two -b\", \"yte sized primitive \\ntypes, but this PR extends it as well to four and eight -byte sized primitives.\", \" As with most of the other \\nvectorized implementations, it checks whether the T is bitwise -equatabl\", \"e, which is important for the \\nvectorization as it\\u2019s only looking at the bits in memory and not payi\", \"ng attention to any Equals  \\nimplementation that might be defined on the type. In practice today, th\", \"at means this is limited to just \\na handful of types of which the runtime has intimate knowledge ( B\", \"oolean , Byte , SByte , UInt16 , Int16 , \\nChar , UInt32 , Int32 , UInt64 , Int64 , UIntPtr , IntPtr \", \", Rune , and enums), but in theory it could be \\nextended in the future.  \\nprivate int[] _data = new \", \"int[1000]; \\n \\n[Benchmark]  \\npublic int IndexOf() => _data. AsSpan().IndexOf(42); \\nMethod  Runtime  M\", \"ean  Ratio  \\nIndexOf  .NET 6.0 252.17 ns  1.00 \\nIndexOf  .NET 7.0  78.82 ns  0.31 \\nOne final interes\", \"ting IndexOf -related optimization. string  has long had \\nIndexOf /IndexOfAny /LastIndexOf /LastInde\", \"xOfAny , and obviously for string  it\\u2019s all about \\nprocessing char s. When ReadOnlySpan<T>  and Span\", \"<T>  came on the scene, MemoryExtensions  was \\nadded to provide extension methods for spans and frie\", \"nds, including such \\nIndexOf /IndexOfAny /LastIndexOf /LastIndexOfAny  methods. But for spans, this \", \"is about more than \\njust char , and so MemoryExtensions  grew its  own set of implementations largel\", \"y separate from \\nstring \\u2019s. Over the years, MemoryExtensions  implementations have specialized more \", \"and more types, \\nbut in particular byte  and char , such that over time string \\u2019s implementations ha\", \"ve mostly been \\nreplaced by de legation into the same implementation as MemoryExtensions  uses. Howe\", \"ver, \\nIndexOfAny  and LastIndexOfAny  had been unification holdouts, each in its own direction. \\nstr\", \"ing.IndexOfAny  did delegate to the same implementation as MemoryExtensions.IndexOfAny  for \\n1-5 val\", \"ues being searched for, but for more than 5 values, string.IndexOfAny  used a \\u201cprobabilistic \\nmap,\\u201d \", \"essentially a Bloom filter . It creates a 256 -bit table, and quickly sets bits in that table  based\", \" on \\nthe values being searched for (essentially hashing them, but with a trivial hash function). The\", \"n it \\niterates through the input, and rather than checking every input character against every one o\", \"f the \\ntarget values, it instead first looks up the i nput character in the table. If the correspond\", \"ing bit isn\\u2019t set, \\nit knows the input character doesn\\u2019t match any of the target values. If the corr\", \"esponding bit is set, \\nthen it proceeds to compare the input character against each of the target va\", \"lues, with a  high \\nprobability of it being one of them. MemoryExtensions.IndexOfAny  lacked such a \", \"filter for more than \\n5 values. Conversely, string.LastIndexOfAny  didn\\u2019t provide any vectorization \", \"for multiple target \\nvalues, whereas MemoryExtensions.LastIndexOfAny  vecto rized two and three targ\", \"et values. As of  \\n107 CHAPTER 10 | Arrays, Strings, and Spans  \\n dotnet/runtime#63817 , all of thes\", \"e are now unified, such that both string  and MemoryExtensions  \\nget the best of what the other had.\", \"  \\nprivate readonly  char[] s_target = new[] { 'z', 'q' }; \\nconst string Sonnet = \\\"\\\"\\\" \\n    Shall I c\", \"ompare thee to a summer's day?  \\n    Thou art more lovely and more temperate:  \\n    Rough winds do s\", \"hake the darling buds of May,  \\n    And summer's lease hath all too short a date; \\n    Sometime too \", \"hot the eye of heaven shines,  \\n    And often is his gold complexion dimm'd;  \\n    And every fair fr\", \"om fair sometime declines,  \\n    By chance or nature's changing course untrimm'd;  \\n    But thy eter\", \"nal summer shall not fade,  \\n    Nor lose p ossession of that fair thou ow'st;  \\n    Nor shall death\", \" brag thou wander'st in his shade,  \\n    When in eternal lines to time thou grow'st:  \\n    So long a\", \"s men can breathe or eyes can see,  \\n    So long lives this, and this gives life to thee.  \\n    \\\"\\\"\\\";\", \" \\n \\n[Benchma rk] \\npublic int LastIndexOfAny () => Sonnet. LastIndexOfAny (s_target);  \\n \\n[Benchmark]\", \"  \\npublic int CountLines () \\n{ \\n    int count = 0; \\n    foreach (ReadOnlySpan< char> _ in Sonnet.AsS\", \"pan().EnumerateLines ()) \\n    { \\n        count++;  \\n    } \\n \\n    return count; \\n} \\nMethod  Runtime  \", \"Mean  Ratio  \\nLastIndexOfAny  .NET 6.0  443.29 ns  1.00 \\nLastIndexOfAny  .NET 7.0  31.79 ns  0.07 \\n \", \"   \\nCountLines  .NET 6.0  1,689.66 ns  1.00 \\nCountLines  .NET 7.0  1,461.64 ns  0.86 \\nThat same PR a\", \"lso cleans up uses of the IndexOf  family, and in particular around uses that are \\nchecking for cont\", \"ainment rather than the actual index of a result. The IndexOf  family of methods \\nreturn a non -nega\", \"tive value when an element is found, and otherw ise return -1. That means when \\nchecking whether an \", \"element was found, code can use either >= 0  or != -1, and when checking \\nwhether an element wasn\\u2019t \", \"found, code can use either < 0 or == -1. It turns out that the code \\ngenerated for comparisons again\", \"st 0 is ever so slightly more efficient than comparisons generated \\nagainst -1, and this isn\\u2019t somet\", \"hing the JIT can itself substitute without the IndexOf  methods being \\nintrinsics such that the JIT \", \"can understand the semantics of the return value. Thus , for consistency and \\na small perf gain, all\", \" relevant call sites were switched to compare against 0 instead of against -1.  \\n108 CHAPTER 10 | Ar\", \"rays, Strings, and Spans  \\n Speaking of call sites, one of the great things about having highly opti\", \"mized IndexOf  methods is \\nusing them in all the places that ca n benefit, removing the maintenance \", \"impact of open -coded \\nreplacements while also reaping the perf wins. dotnet/runtime#63913  used Ind\", \"exOf  inside of \\nStringBuilder.Replace  to speed up the search  for the next character to be replace\", \"d:  \\nprivate StringBuilder _builder = new StringBuilder (Sonnet);  \\n \\n[Benchmark]  \\npublic void Repl\", \"ace() \\n{ \\n    _builder. Replace('?', '!'); \\n    _builder. Replace('!', '?'); \\n} \\nMethod  Runtime  Me\", \"an  Ratio  \\nReplace  .NET 6.0  1,563.69 ns  1.00 \\nReplace  .NET 7.0  70.84 ns  0.04 \\ndotnet/runtime#\", \"60463  from [@nietras](https://github.com/nietras) used IndexOfAny  in \\nStringReader.ReadLine  to se\", \"arch for '\\\\r' and '\\\\n' line ending characters, which results in some \\nsubstantial throughput gains e\", \"ven with the allocation and copy that is inherent to the method\\u2019s \\ndesign:  \\n[Benchmark]  \\npublic vo\", \"id ReadAllLines () \\n{ \\n    var reader = new StringReader (Sonnet);  \\n    while (reader. ReadLine() !\", \"= null) ; \\n} \\nMethod  Runtime  Mean  Ratio  \\nReadAllLines  .NET 6.0  947.8 ns  1.00 \\nReadAllLines  .\", \"NET 7.0  385.7 ns  0.41 \\nAnd dotnet/runtime#70176  cleaned up a plethora of additional uses.  \\nFinal\", \"ly on the IndexOf  front, as noted, a lot of time and energy over the years has gone into \\noptimizin\", \"g these methods. In previous releases, some of that energy has been in the form of using \\nhardware i\", \"ntrinsics d irectly, e.g.  having an SSE2 code path and an AVX2 code path and an AdvSimd \\ncode path.\", \" Now that we have Vector128<T>  and Vector256<T> , many such uses can be simplified \\n(e.g. avoiding \", \"the duplication between an SSE2 implementation and an AdvSimd implementation) \\nwhile still maintaini\", \"ng as good or even better performance and while automatically supporting \\nvectorization on other pla\", \"tforms with their own intrinsics, like WebAssembly. dotn et/runtime#73481 , \\ndotnet/runtime#73556 , \", \"dotnet/runtime#73368 , dotnet/runtime#73364 , dotnet/runtime#73064 , and \\ndotnet/runtime#73469  all \", \"contributed here, in some cases incurring meaningful thro ughput gains:  \\n[Benchmark]  \\npublic int I\", \"ndexOfAny () => Sonnet. AsSpan().IndexOfAny (\\\"!.<>\\\"); \\n   \\n109 CHAPTER 10 | Arrays, Strings, and Spa\", \"ns  \\n Method  Runtime  Mean  Ratio  \\nIndexOfAny  .NET 6.0  52.29 ns  1.00 \\nIndexOfAny  .NET 7.0  40.\", \"17 ns  0.77 \\nThe IndexOf  family is just one of many on string /MemoryExtensions  that has seen dram\", \"atic \\nimprovements. Another are the SequenceEquals  family, including Equals , StartsWith , and Ends\", \"With . \\nOne of my favorite changes in the whole release is dotnet/runtime#65288  and is squarely in \", \"this area. \\nIt\\u2019s very common to see calls to methods like StartsWith  with a constant string argumen\", \"t , e.g. \\nvalue.StartsWith(\\\"https://\\\") , value.SequenceEquals(\\\"Key\\\") , etc. These methods are now \\nr\", \"ecognized by the JIT, which can now automatically unroll the comparison and compare more than \\none c\", \"har at a time, e.g.  doing a single read of four chars as a long  and a single comparison of that \\nl\", \"ong  against the expected combination of those four chars. The result is beautiful. Making it even \\n\", \"better is dotnet/runtime#66095 , which adds to this support f or OrdinalIgnoreCase . Remember those \", \"\\nASCII bit twiddling tricks discussed a bit earlier with char.IsAsciiLetter  and friends? The JIT no\", \"w \\nemploys the same trick as part of this unrolling, so if you do that same \\nvalue.StartsWith(\\\"https\", \"://\\\")  but instead as value.StartsWith(\\\"https://\\\", \\nStringComparison.OrdinalIgnoreCase) , it will re\", \"cognize that the whole comparison string is ASCII \\nand will OR in the appropriate mask on both the c\", \"omparison constant and on the read data from the \\ninput in order to perform the comp arison in a cas\", \"e -insensitive manner.  \\nprivate string _value = \\\"https://dot.net\\\" ; \\n \\n[Benchmark]  \\npublic bool Is\", \"Https_Ordinal () => _value. StartsWith (\\\"https://\\\" , StringComparison. Ordinal); \\n \\n[Benchmark]  \\npu\", \"blic bool IsHttps_OrdinalIgnoreCase () => _value. StartsWith (\\\"https://\\\" , \\nStringComparison. Ordina\", \"lIgnoreCase ); \\nMethod  Runtime  Mean  Ratio  \\nIsHttps_Ordinal  .NET 6.0  4.5634 ns  1.00 \\nIsHttps_O\", \"rdinal  .NET 7.0  0.4873 ns  0.11 \\n    \\nIsHttps_OrdinalIgnoreCase  .NET 6.0  6.5654 ns  1.00 \\nIsHttp\", \"s_OrdinalIgnoreCase  .NET 7.0  0.5577 ns  0.08 \\nInterestingly, since .NET 5 the code generated by Re\", \"gexOptions.Compiled  would perform similar \\nunrolling when comparing sequences of multiple character\", \"s, and when the source generator was \\nadded in .NET 7, i t also learned how to do this. However, the\", \" source generator has problems with such \\nan optimization, due to endianness. The constants being co\", \"mpared against are subject to byte \\nordering issues, such that the source generator would need to em\", \"it code that co uld handle running \\non either little -endian or big -endian machines. The JIT has no\", \" such problem, as it\\u2019s generating the \\ncode on the same machine on which the code will execute (and \", \"in scenarios where it\\u2019s being used to \\ngenerate code ahead of time, the entir ety of that code is al\", \"ready tied to a particular architecture). By \\nmoving this optimization into the JIT, the correspondi\", \"ng code could be deleted from \\nRegexOptions.Compiled  and the regex source generator, which then als\", \"o benefits from producing  \\n110 CHAPTER 10 | Arrays, Strings, and Spans  \\n much easier  to read code\", \" utilizing StartsWith  that\\u2019s just as fast ( dotnet/runtime#65222  and \\ndotnet/runtime#66339 ). Wins\", \" all around. (This  could only be removed from RegexOptions.Compiled  \\nafter dotnet/runtime#68055 , \", \"which fixed the ability for the JIT to recognize these string literals in \\nDynamicMethod s, which Re\", \"gexOptions.Compi led uses with reflection emit to spit out the IL for the \\nregex being compiled.)  \\n\", \"StartsWith  and EndsWith  have improved in other ways. dotnet/runtime#63734  (improved further by \\nd\", \"otnet/runtime#64530 ) added another really interesting JIT -based optimization, but to understand it\", \", \\nwe need to understand string \\u2019s internal layout. string  is essentially represented in memory as \", \"an \\nint length  followed by that many char s plus a null terminator char . The actual System.String \", \" class \\nrepresents this in C# as an int _stringLength  field followed by a char _firstChar  field, s\", \"uch that \\n_firstChar  indeed lines up with the first character of the string, or the null terminator\", \" if the string is \\nempty. Internally in System.Private.CoreLib, and in particular in methods on stri\", \"ng  itself, code will \\noften refer to _firstChar  directly when the first charact er needs to be con\", \"sulted, as it\\u2019s typically faster \\nto do that than to use str[0] , in particular because there are no\", \" bounds checks involved and the \\nstring\\u2019s length generally needn\\u2019t be consulted. Now, consider a met\", \"hod like public bool \\nStartsWith(char valu e) on string . In .NET 6, the implementation was:  \\nretur\", \"n Length != 0 && _firstChar == value;  \\nwhich given what I just described makes sense: if the Length\", \"  is 0, then the string doesn\\u2019t begin with \\nthe specified character, and if Length  is not 0, then w\", \"e can j ust compare the value against \\n_firstChar . But, why is that Length  check even needed at al\", \"l? Couldn\\u2019t we just do return \\n_firstChar == value; ? That will avoid the additional comparison and \", \"branch, and it will work just \\nfine\\u2026 unless the target character is it self '\\\\0', in which case we c\", \"ould get false positives on the result. \\nNow to this PR. The PR introduces an internal JIT intrinsin\", \"c RuntimeHelpers.IsKnownConstant , which \\nthe JIT will substitute with true  if the containing metho\", \"d is inlined and the argument p assed to \\nIsKnownConstant  is then seen to be a constant. In such ca\", \"ses, the implementation can rely on other \\nJIT optimizations kicking in and optimizing various code \", \"in the method, effectively enabling a \\ndeveloper to write two different implementations, one  when t\", \"he argument is known to be a constant \\nand one when not. With that in hand, the PR is able to optimi\", \"ze StartsWith  as follows:  \\npublic bool StartsWith (char value) \\n{ \\n    if (RuntimeHelpers. IsKnown\", \"Constant (value) && value != ' \\\\0') \\n        return _firstCh ar == value;  \\n \\n    return Length != 0\", \" && _firstChar == value;  \\n} \\nIf the value  parameter isn\\u2019t a constant, then IsKnownConstant  will b\", \"e substituted with false , the \\nentire starting if block will be eliminated, and the method will be \", \"left exactly was it was before. But, if \\nthis method gets inlined and the value  was actually a cons\", \"tant, then the value != ' \\\\0' condition will \\nalso be evaluatable at JIT -compile -time. If the valu\", \"e  is in fact  '\\\\0', well, again that whole if block will \\nbe eliminated and we\\u2019re no worse off. But\", \" in the common case where the value  isn\\u2019t null, the entire \\nmethod will end up being compiled as if\", \" it were:  \\nreturn _firstChar == ConstantValue;   \\n111 CHAPTER 10 | Arrays, Strings, and Spans  \\n an\", \"d we\\u2019ve saved ourselves a  read of the string\\u2019s length, a comparison, and a branch. \\ndotnet/runtime#\", \"69038  then employs a similar technique for EndsWith . \\nprivate string _value = \\\"https://dot.net\\\" ; \", \"\\n \\n[Benchmark]  \\npublic bool StartsWith () => \\n    _value.StartsWith ('a') || \\n    _value.StartsWith\", \" ('b') || \\n    _value.StartsWith ('c') || \\n    _value.StartsWith ('d') || \\n    _value.StartsWith ('e\", \"') || \\n    _value.StartsWith ('f') || \\n    _value.StartsWith ('g') || \\n    _value.StartsWith ('i') |\", \"| \\n    _value.StartsWith ('j') || \\n    _value.StartsWith ('k') || \\n    _value.StartsWith ('l') || \\n \", \"   _value.StartsWith ('m') || \\n    _value.StartsWith ('n') || \\n    _value.StartsWith ('o') || \\n    _\", \"value.StartsWith ('p'); \\nMethod  Runtime  Mean  Ratio  \\nStartsWith  .NET 6.0  8.130 ns  1.00 \\nStarts\", \"With  .NET 7.0  1.653 ns  0.20 \\n(Another example of IsKnownConstant  being used comes from dotnet/ru\", \"ntime#64016 , which uses it \\nto improve Math.Round  when a MidpointRounding  mode is specified. Call\", \" sites to this almost always \\nexplicitly specify the enum value as a constant, which then allows the\", \" JIT to specialize the code \\ngeneration for the method to the specific mo de being used; that in tur\", \"n, for example, enables a \\nMath.Round(..., MidpointRounding.AwayFromZero)  call on Arm64 to be lower\", \"ed to a single frinta  \\ninstruction.)  \\nEndsWith  was also improved in dotnet/runtime#72750 , and sp\", \"ecifically for when \\nStringComparison.OrdinalIgnoreCase  is specified. This simple PR just switched \", \"which internal \\nhelper method was used to implement this method, taking advantage of one that is suf\", \"ficient for the \\nneeds of this met hod and that has lower overheads.  \\n[Benchmark]  \\n[Arguments (\\\"Sy\", \"stem.Private.CoreLib.dll\\\" , \\\".DLL\\\")] \\npublic bool EndsWith (string haystack, string needle) =>  \\n   \", \" haystack. EndsWith (needle, StringComparison. OrdinalIgnoreCase ); \\nMethod  Runtime  Mean  Ratio  \\n\", \"EndsWith  .NET 6.0  10.861 ns  1.00 \\nEndsWith  .NET 7.0  5.385 ns  0.50 \\nFinally, dotnet/runtime#672\", \"02  and dotnet/runtime#73475  employ Vector128<T>  and Vector256<T>  \\nto replace direct hardware int\", \"rinsics usage, just as was previously shown for various IndexOf  methods, \\nbut here for SequenceEqua\", \"l  and SequenceCompareTo , respectively.   \\n112 CHAPTER 10 | Arrays, Strings, and Spans  \\n Another m\", \"ethod that\\u2019s seem some  attention in .NET 7 is MemoryExtensions.Reverse  (and \\nArray.Reverse  as it \", \"shares the same implementation), which performs an in -place reversal of the \\ntarget span. dotnet/ru\", \"ntime#64412  from [@a lexcovington](https://github.com/alexcovington) \\nprovides a vectorized impleme\", \"ntation via direct use of AVX2 and SSSE3 hardware intrinsics, with \\ndotnet/runtime#72780  from [@Swa\", \"pnilGaikwad](http s://github.com/SwapnilGaikwad) following up to \\nadd an AdvSimd intrinsics implemen\", \"tation for Arm64. (There was an unintended regression \\nintroduced by the original vectorization chan\", \"ge, but that was fixed by dotnet/runtime#70650 .) \\nprivate char[] text = \\\"Free. Cross -platform. Ope\", \"n source. \\\\r\\\\nA developer platform for \\nbuilding all your apps.\\\" .ToCharArray (); \\n \\n[Benchmark]  \\np\", \"ublic void Reverse() => Array. Reverse(text); \\nMethod  Runtime  Mean  Ratio  \\nReverse  .NET 6.0  21.\", \"352 ns  1.00 \\nReverse  .NET 7.0  9.536 ns  0.45 \\nString.Split  also saw vectorization improvements i\", \"n dotnet/runtime#64899  from \\n[@yesmey](https://github.com/yesmey). As with some of the previously d\", \"iscussed PRs, it switched the \\nexisting usage of SSE2 and SSSE3 hardware intrinsics over to the new \", \"Vector128<T>  helpers, which \\nimproved upon the existing implementation while also implicitly adding\", \" vectorization support for \\nArm64.  \\nConverting various formats of strings is something many applica\", \"tions and services do, whether that\\u2019s \\nconverting from UTF8 bytes to and from string  or formatting \", \"and parsing hex values. Such \\noperations have  also improved in a variety of ways in .NET 7. Base64 \", \"-encoding , for example, is a way \\nof representing arbitrary binary data (think byte[] ) across medi\", \"ums that only support text, encoding \\nbytes into on e of 64 different ASCII characters. Multiple API\", \"s in .NET implement this encoding. For \\nconverting between binary data represented as ReadOnlySpan<b\", \"yte>  and UTF8 (actually ASCII) \\nencoded data also represented as ReadOnlySpan<byte> , the System.Bu\", \"ffers.Text.B ase64  type \\nprovides EncodeToUtf8  and DecodeFromUtf8  methods. These were vectorized \", \"several releases ago, \\nbut they were further improved in .NET 7 via dotnet/runtime#70654  from \\n[@a7\", \"4nh](https:/ /github.com/a74nh), which converted the SSSE3 -based implementation to use \\nVector128<T\", \">  (which in turn implicitly enabled vectorization on Arm64). However, for converting \\nbetween arbit\", \"rary binary data represented as ReadOnlySpan<byte> /byte[]  and \\nReadOnlySpa n<char> /char[] /string\", \" , the System.Convert  type exposes multiple methods, e.g. \\nConvert.ToBase64String , and these metho\", \"ds historically were not vectorized. That changes in .NET \\n7, where dotnet/r untime#71795  and dotne\", \"t/runtime#73320  vectorize the ToBase64String , \\nToBase64CharArray , and TryToBase64Chars  methods. \", \"The way they do this is interesting. Rather than \\neffectively duplicating th e vectorization impleme\", \"ntation from Base64.EncodeToUtf8 , they instead \\nlayer on top of EncodeToUtf8 , calling it to encode\", \" the input byte  data into an output Span<byte> . \\nThen, then they \\u201cwiden\\u201d those bytes into chars (r\", \"emember, Base64 -encoded data is a set o f ASCII \\nchars, so going from these bytes to chars entails \", \"adding just a 0 byte onto each element). That \\nwidening can itself easily be done in a vectorized ma\", \"nner. The other interesting thing about this \\nlayering is it doesn\\u2019t actually require separate inter\", \" mediate storage for the encoded bytes. The \\nimplementation can perfectly compute the number of resu\", \"lting characters for encoding X bytes into Y  \\n113 CHAPTER 10 | Arrays, Strings, and Spans  \\n Base64\", \" characters (there\\u2019s a formula), and the implementation can either allocate that final space \\n(e.g. \", \"in the c ase of ToBase64CharArray) or ensure the provided space is sufficient (e.g.  in the case of \", \"\\nTryToBase64Chars). And since we know the initial encoding will require exactly half as many bytes, \", \"we \\ncan encode into that same space (with the destination span reint erpreted as a byte  span rather\", \" than \\nchar  span), and then widen \\u201cin place\\u201d: walk from the end of the bytes and the end of the cha\", \"r space, \\ncopying the bytes into the destination.  \\nprivate byte[] _data = Encoding. UTF8.GetBytes (\", \"\\\"\\\"\\\" \\n    Shall I compare thee to a summer's day?  \\n    Thou art more lovely and more temperate:  \\n  \", \"  Rough winds do shake the darling buds of May,  \\n    And summer's lease hath all too short a date; \", \"\\n    Sometime too hot the eye of heaven shines,  \\n    And often is his gold complexion dimm'd;  \\n   \", \" And every fair from fair sometime declines,  \\n    By chance or nature's changing course untrimm'd; \", \" \\n    But thy eternal summer shall not fade,  \\n    Nor lose possession of that fair thou ow'st;  \\n  \", \"  Nor shall death brag thou wander's t in his shade,  \\n    When in eternal lines to time thou grow's\", \"t:  \\n    So long as men can breathe or eyes can see,  \\n    So long lives this, and this gives life t\", \"o thee.  \\n    \\\"\\\"\\\"); \\nprivate char[] _encoded = new char[1000]; \\n \\n[Benchmark]  \\npublic bool TryToBas\", \"e64Cha rs() => Convert. TryToBase64Chars (_data, _encoded, out _); \\nMethod  Runtime  Mean  Ratio  \\nT\", \"ryToBase64Chars  .NET 6.0  623.25 ns  1.00 \\nTryToBase64Chars  .NET 7.0  81.82 ns  0.13 \\nJust as wide\", \"ning can be used to go from bytes to chars, narrowing can be used to go from chars to \\nbytes, in par\", \"ticular if the chars are actually ASCII and thus have a 0 upper byte. Such narrowing can be \\nvectori\", \"zed, and the internal NarrowUtf16ToAscii  utility helper does exactly that, used as part of \\nmethods\", \" like Encoding.ASCII.GetBytes . While this method was previously vectorized, its primary \\nfast-path \", \"utilized SSE2 and thus didn\\u2019t apply to Arm64; thanks to dotnet/runtime#70080  from \\n[@SwapnilGaikwad\", \"](https://github.com/SwapnilGaikwad), that path was changed over to be based on \\nthe cross -platform\", \" Vector128<T> , enabling the same level of optimization across supported \\nplatforms. Similarly, dotn\", \"et/runtime#71637  from \\n[@SwapnilGaikwad](https://github.com/SwapnilGaikwad) adds Arm64 vectorizatio\", \"n to the \\nGetIndexOfFirstNonAsciiChar  internal helper that\\u2019s used by methods like \\nEncoding.UTF8.Ge\", \"t ByteCount . (And in the same vein, dotnet/runtime#67192  changed the internal \\nHexConverter.Encode\", \"ToUtf16  method from using SSSE3 intrinsics to instead use Vector128<T> , \\nautomatically providing a\", \" n Arm64 implementation.)  \\nEncoding.UTF8  was also improved a bit. In particular, dotnet/runtime#69\", \"910  streamlined the \\nimplementations of GetMaxByteCount  and GetMaxCharCount , making them small en\", \" ough to be \\ncommonly inlined when used directly off of Encoding.UTF8  such that the JIT is able to \", \"devirtualize the \\ncalls.   \\n114 CHAPTER 10 | Arrays, Strings, and Spans  \\n [Benchmark]  \\npublic int \", \"GetMaxByteCount () => Encoding. UTF8.GetMaxByteCount (Sonnet. Length); \\nMethod  Runtime  Mean  Ratio\", \"  \\nGetMaxByteCount  .NET 6.0  1.7442 ns  1.00 \\nGetMaxByteCount  .NET 7.0  0.4746 ns  0.27 \\nArguably \", \"the biggest improvement around UTF8 in .NET 7 is the new C# 11 support for UTF8 literals. \\nInitially\", \" implemented in the C# compiler in dotnet/roslyn#58991 , with follow -on work in \\ndotnet/roslyn#5939\", \"0 , dotnet/roslyn#61532 , and dotnet/roslyn#62044 , UTF8 literals enables the \\ncompiler to perform t\", \"he UTF8 encoding into bytes at compile -time. Rather than writing a normal \\nstring, e.g. \\\"hello\\\" , a\", \" developer simply appends the new u8 suffix onto the string literal, e.g. \\n\\\"hello\\\"u8 . At that point\", \", this is no longer a string. Rather, the natural type of this expression is a \\nReadOnlySpan<byte> .\", \" If you write:  \\npublic static ReadOnlySpan< byte> Text => \\\"hello\\\"u8; \\nthe C# compiler will compile \", \"that equivalent to if you wrote:  \\npublic static ReadOnlySpan< byte> Text =>  \\n    new ReadOnlySpan<\", \" byte>(new byte[] { (byte)'h', (byte)'e', (byte)'l', (byte)'l', \\n(byte)'o', (byte)'\\\\0' }, 0, 5);    \", \" \\nIn other words, the compiler is doing the equivalent of Encoding.UTF8.GetBytes  at compile -time a\", \"nd \\nhardcoding the resulting bytes, saving the cost of performing that encoding at run -time. Of cou\", \"rse, at \\nfirst glance, that array allocation might look terribl y inefficient. However, looks can be\", \" deceiving, and \\nare in this case. For several releases now, when the C# compiler sees a byte[]  (or\", \" sbyte[]  or bool[] ) \\nbeing initialized with a constant length and constant values and immediately \", \"cast to or used to \\nconstr uct a ReadOnlySpan<byte> , it optimizes away the byte[]  allocation. Inst\", \"ead, it blits the data for \\nthat span into the assembly\\u2019s data section, and then constructs a span t\", \"hat points directly to that data \\nin the loaded assembly. This is the actual generated IL for the ab\", \"ove property:  \\nIL_0000: ldsflda valuetype '<PrivateImplementationDetails>'/'__StaticArrayInitTypeSi\", \"ze=6' \\n'<PrivateImplementationDetails>'::F3AEFE62965A91903610F0E23CC8A69D5B87CEA6D28E75489B0D2CA02\\nE\", \"D7993C \\nIL_0005: ldc.i4.5  \\nIL_0006: newobj instan ce void valuetype \\n[System.Runtime]System.ReadOnl\", \"ySpan`1<uint8>::.ctor(void*, int32)  \\nIL_000b: ret  \\nThis means we not only save on the encoding cos\", \"ts at run -time, and we not only avoid whatever \\nmanaged allocations might be required to store the \", \"resulting data , we also benefit from the JIT being \\nable to see information about the encoded data,\", \" like it\\u2019s length, enabling knock -on optimizations. You \\ncan see this clearly by examining the asse\", \"mbly generated for a method like:  \\npublic static int M() => Text. Length; \\nfor which the JIT produc\", \"es:  \\n; Program.M()  \\n       mov       eax,5   \\n115 CHAPTER 10 | Arrays, Strings, and Spans  \\n      \", \"  ret \\n; Total bytes of code 6  \\nThe JIT inlines the property access, sees that the span is being co\", \"nstructed with a length of 5, and so \\nrather than emitting any array allocations or span con structi\", \"ons or anything even resembling that, it \\nsimply outputs mov eax, 5  to return the known length of t\", \"he span.  \\nThanks primarily to dotnet/runtime#70568 , dotnet/runtime#69995 , dotnet/runtime#70894 , \", \"\\ndotnet/runtime#71417  from [@am11](https://github.com/am11), dotnet/runtime#71292 , \\ndotnet/runtime\", \"#70513 , and dotnet/runtime#71992 , u8 is now used more than 2100 times throughout \\ndotnet/runtime .\", \" Hardly a fai r comparison, but the following benchmark demonstrates how little work \\nis actually be\", \"ing performed for u8 at execution time:  \\n[Benchmark (Baseline = true)] \\npublic ReadOnlySpan< byte> \", \"WithEncoding () => Encoding. UTF8.GetBytes (\\\"test\\\"); \\n     \\n[Benchmark]  \\npublic ReadOnlySpan< byte>\", \" Withu8() => \\\"test\\\"u8; \\nMethod  Mean  Ratio  Allocated  Alloc Ratio  \\nWithEncoding  17.3347 ns  1.00\", \"0  32 B 1.00 \\nWithu8  0.0060 ns  0.000  - 0.00 \\nLike I said, not fair, but it proves the point :)  \\n\", \"Encoding  is of course just one mechanism for creating string  instances. Others have also improved \", \"in \\n.NET 7. Take the super common long.ToString , for example. Previous releases improved \\nint.ToStr\", \"ing , but there were enough differences between the 32 -bit and 64 -bit algorithms that long  \\ndidn\\u2019\", \"t see all of the same gains. Now thanks to dotnet/runtime#68795 , the 64 -bit formatting code \\npaths\", \" are made much more similar to the 32 -bit, resulting in faster perfor mance.  \\nYou can also see imp\", \"rovements in string.Format  and StringBuilder.AppendFormat , as well as \\nother helpers that layer on\", \" top of these (like TextWriter.AppendFormat ). dotnet/runtime#69757  \\noverhauls the core routines in\", \"side Format  to avoid unnecessary bounds checking, favor expected \\ncases, and generally clean up the\", \" implementation. It also, however, utilities IndexOfAny  to search for \\nthe next interpolation hole \", \"that needs to be filled in, and  if the non -hole-character to hole ratio is high \\n(e.g. long format\", \" string with few holes), it can be way faster than before.  \\nprivate StringBuilder _sb = new StringB\", \"uilder (); \\n \\n[Benchmark]  \\npublic void AppendFormat () \\n{ \\n    _sb.Clear(); \\n    _sb.AppendFormat (\", \"\\\"There is already one outstanding '{0}' call for this WebSocket \\ninstance.\\\"  + \\n                    \", \" \\\"ReceiveAsync and SendAsync can be called simultaneously, but at most \\none \\\" + \\n                   \", \"  \\\"outstanding operation for each of them is allowed at the same time.\\\" , \\n                     \\\"Rec\", \"eiveAsync\\\" ); \\n} \\n   \\n116 CHAPTER 10 | Arrays, Strings, and Spans  \\n Method  Runtime  Mean  Ratio  \\n\", \"AppendFormat  .NET 6.0  338.23 ns  1.00 \\nAppendFormat  .NET 7.0  49.15 ns  0.15 \\nSpeaking of StringB\", \"uilder , it\\u2019s seen additional improvements beyond the aforementioned changes \\nto AppendFormat . One \", \"interesting change is dotnet/runtime#64405 , which achieved two related \\nthings. The first was to re\", \"mov e pinning as part of formatting operations. As an example, \\nStringBuilder  has an Append(char* v\", \"alue, int valueCount)  overload which copies the specified \\nnumber of characters from the specified \", \"pointer into the StringBuilder , and other APIs were \\nimplemented in terms of this method; for examp\", \"le, the Append(string? value, int startIndex, \\nint count)  method was essentially implemented as:  \\n\", \"fixed (char* ptr = value)  \\n{ \\n    Append(ptr + startIndex, count);  \\n} \\nThat fixed  statement trans\", \"lates into a \\u201cpinning pointer.\\u201d Normally the GC is free to move managed \\nobjects around on the heap,\", \" which it might do in order to compact the heap (to, for example, avoid \\nsmall, unusuable fragments \", \"of memory between objects). But if the GC can move objects around, a \\nnormal native pointer into tha\", \"t memory would be terribly unsafe and unreliable, as without notice the \\ndata being pointed to could\", \" move and your pointer could now be pointing to garbage or to some \\nother object that was shifted to\", \" this location. There are two ways for dealing with this. The first is a \\n\\u201cmanaged pointer,\\u201d otherwi\", \"se known as a \\u201creference\\u201d or \\u201cref,\\u201d as that\\u2019s exactly what you get when you \\nhave the \\u201cref\\u201d keyword \", \"in C#; it\\u2019s a pointer that the runtime will update with the  correct value when it \\nmoves the object\", \" being pointed into. The second is to prevent the pointed -to object from being \\nmoved, \\u201cpinning\\u201d it\", \" in place. And that\\u2019s what the \\u201cfixed\\u201d keyword does, pinning the referenced object \\nfor the duration\", \" of the fixed  block,  during which time it\\u2019s safe to use the supplied pointer. Thankfully, \\npinning\", \" is cheap when no GC occurs; when a GC does occur, however, pinned objects aren\\u2019t able to be \\nmoved \", \"around, and thus pinning can have a global impact on the performance of the appl ication (and \\non GC\", \"s themselves). There are also various optimizations inhibited by pinning. With all of the advents \\ni\", \"n C# around being able to use ref in many more places (e.g.  ref locals, ref returns, and now in C# \", \"11, \\nref fields), and with all of the new  APIs in .NET for manipulating refs (e.g. Unsafe.Add , \\nUn\", \"safe.AreSame ), it\\u2019s now possible to rewrite code that was using pinning pointers to instead use \\nma\", \"naged pointers, thereby avoiding the problems that come from pinning. Which is what this PR did. \\nRa\", \"ther than implementing all of the Append  methods in terms of an Append(char*, int)  helper, \\nthey\\u2019r\", \"e now all implemented in terms of an Append(ref char, int)  helper. So for example instead of \\nthe p\", \"reviously shown Append(string? value, int startIndex, int count)  implementation, it\\u2019s \\nnow akin to \", \" \\nAppend(ref Unsafe.Add(ref value.GetRawStringData (), startIndex), count);  \\nwhere that string.GetR\", \"awStringData  method is just an internal version of the public \\nstring.GetPinnableReference  method,\", \" returning a ref instead of a ref readonly . This means that \\nall of the high -performance code insi\", \"d e of StringBuilder  that had been using pointers to avoid \\nbounds checking and the like can contin\", \"ue to do so, but now also does so without pinning all of the \\ninputs.   \\n117 CHAPTER 10 | Arrays, St\", \"rings, and Spans  \\n The second thing this StringBuilder  change did was unify an optimization that w\", \"as present f or \\nstring  inputs to also apply to char[]  inputs and ReadOnlySpan<char>  inputs. Spec\", \"ifically, because \\nit\\u2019s so common to append string  instances to a StringBuilder , a special code pa\", \"th was long ago \\nput in place to optimize for this input and specifically for  the case where there\\u2019\", \"s already enough room \\nin the StringBuilder  to hold the whole input, at which point an efficient co\", \"py can be used. With a \\nshared Append(ref char, int)  helper, though, this optimization can be moved\", \" down into that \\nhelper, such that it n ot only helps out string  but any other type that also calls\", \" into the same helper. \\nThe effects of this are visible in a simple microbenchmark:  \\nprivate String\", \"Builder _sb = new StringBuilder (); \\n \\n[Benchmark]  \\npublic void AppendSpan () \\n{ \\n    _sb.Clear(); \", \"\\n    _sb.Append(\\\"this\\\".AsSpan()); \\n    _sb.Append(\\\"is\\\".AsSpan()); \\n    _sb.Append(\\\"a\\\".AsSpan()); \\n  \", \"  _sb.Append(\\\"test\\\".AsSpan()); \\n    _sb.Append(\\\".\\\".AsSpan()); \\n} \\nMethod  Runtime  Mean  Ratio  \\nApp\", \"endSpan  .NET 6.0  35.98 ns  1.00 \\nAppendSpan  .NET 7.0  17.59 ns  0.49 \\nOne of the great things abo\", \"ut improving things low in the stack is they have a multiplicative effect; \\nthey not only help impro\", \"ve the performance of user code that directly relies on the improved \\nfunctionality, they can also h\", \"elp improve the performance of other code in the core libraries, which \\nthen further helps dependent\", \" apps and services. You can see this, for example, with \\nDateTimeOffset.ToString , which depends on \", \"StringBuilder : \\nprivate DateTimeOffset _dto = DateTimeOffset. UtcNow; \\n \\n[Benchmark]  \\npublic strin\", \"g DateTimeOffsetToString () => _dto. ToString (); \\nMethod  Runtime  Mean  Ratio  \\nDateTimeOffsetToSt\", \"ring  .NET 6.0  340.4 ns  1.00 \\nDateTimeOffsetToString  .NET 7.0  289.4 ns  0.85 \\nStringBuilder  its\", \"elf was then further updated by dotnet/runtime#64922  from [@teo -\\ntsirpanis](https://github.com/teo\", \" -tsirpanis), which improves the Insert  methods. It used to be that \\nthe Append(primitive)  methods\", \" on StringBuilder  (e.g. Append(in t)) would call ToString  on the \\nvalue and then append the result\", \"ing string. With the advent of ISpanFormattable , as a fast -path \\nthose methods now try to format t\", \"he value directly into the StringBuilder \\u2019s internal buffer, and only \\nif there\\u2019s not enough room re\", \"maining do they then take the old path as a fallback. Insert  wasn\\u2019t \\nimproved in this way at the ti\", \"me, because it can\\u2019t just format into the space at the end of the builder; \\nthe insert location coul\", \"d be anywhere in the builder. This PR addresses that by f ormatting into some \\ntemporary stack space\", \", and then delegating to the existing internal ref -based helper from the  \\n118 CHAPTER 10 | Arrays,\", \" Strings, and Spans  \\n previously discussed PR to insert the resulting characters at the right locat\", \"ion (it also falls back to \\nToString  when there\\u2019s not enough stack  space for the ISpanFormattable.\", \"TryFormat , but that only \\nhappens in incredibly corner cases, like a floating -point value that for\", \"mats to hundreds of digits).  \\nprivate StringBuilder _sb = new StringBuilder (); \\n \\n[Benchmark]  \\npu\", \"blic void Insert() \\n{ \\n    _sb.Clear(); \\n    _sb.Insert(0, 12345); \\n} \\nMethod  Runtime  Mean  Ratio \", \" Allocated  Alloc Ratio  \\nInsert  .NET 6.0  30.02 ns  1.00 32 B 1.00 \\nInsert  .NET 7.0  25.53 ns  0.\", \"85 - 0.00 \\nOther minor improvements to StringBuilder  have also been made, like dotnet/runtime#60406\", \"  which \\nremoved a small int[]  allocation from the Replace  method. Even with all these improvement\", \"s, \\nthough, the fastest use of StringBuilder  is no use; dotnet/runtime#68768  removed a bunch of us\", \"es \\nof StringBuilder  that would have been better served with other string -creation mechanisms. For\", \" \\nexample, the legacy DataView  type had some code that created a sorting spec ification as a string\", \":  \\nprivate static string CreateSortString (PropertyDescriptor property, ListSortDirection \\ndirectio\", \"n)  \\n{ \\n    var resultString = new StringBuilder (); \\n    resultString. Append('['); \\n    resultStri\", \"ng. Append(property. Name); \\n    resultString. Append(']'); \\n    if (ListSortDirection. Descending  \", \"== direction)  \\n    { \\n        resultString. Append(\\\" DESC\\\"); \\n    } \\n    return resultString. ToStr\", \"ing (); \\n} \\nWe don\\u2019t actually need the StringBuilder  here, as in the worst -case we\\u2019re just concate\", \"n ating three \\nstrings, and string.Concat  has a dedicated overload for that exact operation that ha\", \"s the best \\npossible implementation for that operation (and if we ever found a better way, that meth\", \"od would be \\nimproved according). So we can just use that:  \\nprivate static string CreateSortString \", \"(PropertyDescriptor property, ListSortDirection \\ndirection) =>  \\n    direction == ListSortDirection.\", \" Descending  ? \\n        $\\\"[{property.Name}] DESC\\\"  : \\n        $\\\"[{property.Name}]\\\" ; \\nNote that I\\u2019ve\", \" expressed that concatenation v ia an interpolated string, but the C# compiler will \\u201clower\\u201d \\nthis in\", \"terpolated string to a call to string.Concat , so the IL for this is indistinguishable from if I\\u2019d \\n\", \"instead written:  \\nprivate static string CreateSortString (PropertyDescriptor property, ListSortDire\", \"ction \\ndirection) =>   \\n119 CHAPTER 10 | Arrays, Strings, and Spans  \\n     direction == ListSortDire\", \"ction. Descending  ? \\n        string.Concat(\\\"[\\\", property. Name, \\\"] DESC\\\" ) : \\n        string.Concat\", \"(\\\"[\\\", property. Name, \\\"]\\\"); \\nAs an aside, the expanded string.Concat  version highlights that this m\", \"ethod could have been \\nwritten to result in a bit less IL if it were instead written as:  \\nprivate s\", \"tatic string CreateSortString (PropertyDescriptor property, ListSortDirection \\ndirection) =>  \\n    s\", \"tring.Concat(\\\"[\\\", property. Name, direction == ListSortDirection. Descending  ? \\\"] DESC\\\"  \\n: \\\"]\\\");  \", \"\\nbut this doesn\\u2019t meaningfully affect performance and here clarity and maintainability was more \\nimp\", \"ortant than shaving off a few bytes.  \\n[Benchmark (Baseline = true)] \\n[Arguments (\\\"SomeProperty\\\" , L\", \"istSor tDirection. Descending )] \\npublic string WithStringBuilder (string name, ListSortDirection di\", \"rection)  \\n{ \\n    var resultString = new StringBuilder (); \\n    resultString. Append('['); \\n    resu\", \"ltString. Append(name); \\n    resultString. Append(']'); \\n    if (ListSortDirection. Descending  == d\", \"irection)  \\n    { \\n        resultString. Append(\\\" DESC\\\"); \\n    } \\n    return resultString. ToString \", \"(); \\n} \\n \\n[Benchmark]  \\n[Arguments (\\\"SomeProperty\\\" , ListSortDirection. Descending )] \\npublic string\", \" WithConcat (string name, ListSortDirect ion direction) =>  \\n    direction == ListSortDirection. Des\", \"cending ? \\n        $\\\"[{name}] DESC\\\"  : \\n        $\\\"[{name}]\\\" ; \\nMethod  Mean  Ratio  Allocated  Alloc\", \" Ratio  \\nWithStringBuilder  68.34 ns  1.00 272 B  1.00 \\nWithConcat  20.78 ns  0.31 64 B 0.24 \\nThere \", \"are also places where StringBuilder  was still applicable, but it was being used on hot -enough \\npat\", \"hs that previous releases of .NET saw the StringBuilder  instance being cached. Several of the \\ncore\", \" libraries, including System.Private.CoreLib, have an i nternal StringBuilderCache  type which \\ncach\", \"es a StringBuilder  instance in a [ThreadStatic] , meaning every thread could end up having \\nsuch an\", \" instance. There are several issues with this, including that the buffers employed by \\nStringBuilder\", \"  aren\\u2019t usable for  anything else while the StringBuilder  isn\\u2019t in use, and because of \\nthat, Stri\", \"ngBuilderCache  places a limit on the capacity of the StringBuilder  instances that can be \\ncached; \", \"attempts to cache ones longer than that result in them being thrown away. It\\u2019d be  better \\ninstead t\", \"o use cached arrays that aren\\u2019t length -limited and that everyone has access to for sharing. \\nMany o\", \"f the core .NET libraries have an internal ValueStringBuilder  type for this purpose, a ref \\nstruct \", \"-based type that can use stackalloc \\u2019d memory  to start and then if necessary grow into \\nArrayPool<c\", \"har>  arrays. And with dotnet/runtime#64522  and dotnet/runtime#69683 , many o f the  \\n120 CHAPTER 1\", \"0 | Arrays, Strings, and Spans  \\n remaining uses of StringBuilderCache  have been replaced. I\\u2019m hope\", \"ful we can entirely remove \\nStringBuilderCache  in the future.  \\nIn the same vein of not doing unnec\", \"essary work, there\\u2019s a fairly common pattern that shows up with \\nmethods like string.Subst ring  and\", \" span.Slice : \\nspan = span. Slice(offset, str. Length - offset);  \\nThe relevant thing to recognize h\", \"ere is these methods have overloads that take just the starting offset. \\nSince the length being spec\", \"ified is the remainder after the specified offset, the call could instead be \\nsimplified to:  \\nspan \", \"= span. Slice(offset);  \\nwhich is not only more readable and maintainable, it has some small efficie\", \"ncy benefits, e.g.  on 64 -bit \\nthe Slice(int, int)  constructor has an extra addition over Slice(in\", \"t) , and for 32 -bit the \\nSlice(int, int)  constructor incurs an additional comparison and branch. I\", \"t\\u2019s thus beneficial for both \\ncode maintenance and for performance to simplify these calls, which do\", \"tnet/runtime#68937  does for \\nall found occurrences of that pattern. This is then made more impactfu\", \"l by dotnet/runtime#73882 , \\nwhich streamline s string.Substring  to remove unnecessary overheads, e\", \".g.  it condenses four \\nargument validation checks down to a single fast -path comparison (in 64 -bi\", \"t processes).  \\nOk, enough about string . What about spans? One of the coolest features in C# 11 is \", \"the new su pport \\nfor ref fields. What is a ref field? You\\u2019re familiar with refs in C# in general, a\", \"nd we\\u2019ve already \\ndiscussed how they\\u2019re essentially managed pointers, i.e.  pointers that the runtim\", \"e can update at any \\ntime due to the object it references getting moved  on the heap. These referenc\", \"es can point to the \\nbeginning of an object, or they can point somewhere inside the object, in which\", \" case they\\u2019re referred \\nto as \\u201cinterior pointers.\\u201d ref has existed in C# since 1.0, but at that time\", \" it was primarily about passin g \\nby reference to method calls, e.g.  \\nclass Data \\n{ \\n    public int\", \" Value; \\n} \\n... \\nvoid Add(ref int i) \\n{ \\n    i++; \\n} \\n... \\nvar d = new Data { Value = 42 }; \\nAdd(ref\", \" d.Value); \\nDebug.Assert(d.Value == 43); \\nLater versions of C# added the ability to have local refs,\", \" e.g.  \\nvoid Add(ref int i) \\n{ \\n    ref j = ref i; \\n    j++; \\n} \\nand even to have ref returns, e.g. \", \"  \\n121 CHAPTER 10 | Arrays, Strings, and Spans  \\n ref int Add(ref int i) \\n{ \\n    ref j = ref i; \\n   \", \" j++; \\n    return ref j; \\n} \\nThese facilities are more advanc ed, but they\\u2019re used liberally through\", \"out higher -performance code \\nbases, and many of the optimizations in .NET in recent years are possi\", \"ble in large part due to these \\nref-related capabilities.  \\nSpan<T>  and ReadOnlySpan<T>  themselves\", \" are heavily -based on refs. For example, the indexer on \\nmany older collection types is implemented\", \" as a get/set property, e.g.  \\nprivate T[] _items;  \\n... \\npublic T this[int i] \\n{ \\n    get => _items\", \"[i];  \\n    set => _items[i] = value;  \\n} \\nBut not span. Span<T> \\u2019s indexer looks more like this: \\npu\", \"blic ref T this[int index] \\n{ \\n    get \\n    { \\n        if ((uint)index >= ( uint)_length)  \\n        \", \"    ThrowHelper. ThrowIndexOutOfRangeException (); \\n \\n        return ref Unsafe.Add(ref _reference, \", \"index);  \\n    } \\n} \\nNote there\\u2019s only a getter and no setter; t hat\\u2019s because it returns a ref T  to\", \" the actual storage \\nlocation. It\\u2019s a writable ref, so you can assign to it, e.g.  you can write:  \\n\", \"span[i] = value;  \\nbut rather than that being equivalent to calling some setter:  \\nspan.set_Item (i,\", \" value);  \\nit\\u2019s actually equivalent to using the getter to retrieve the ref and then writing a value\", \" through that \\nref, e.g. \\nref T item = ref span.get_Item (i); \\nitem = value;  \\nThat\\u2019s all well and g\", \"ood, but what\\u2019s that _reference  in the getter defin ition? Well, Span<T>  is really \\njust a tuple o\", \"f two fields: a reference (to the start of the memory being referred to) and a length (how \\nmany ele\", \"ments from that reference are included in the span). In the past, the runtime had to hack this \\nwith\", \" an internal type (ByReference<T> ) specially recognized by the runtime to be a reference. But as \\no\", \"f C# 11 and .NET 7, ref structs  can now contain ref fields, which means Span<T>  today is literally\", \" \\ndefined as follows:   \\n122 CHAPTER 10 | Arrays, Strings, and Spans  \\n public readonly  ref struct \", \"Span<T> \\n{ \\n    internal  readonly ref T _reference;  \\n    private readonly  int _length;  \\n    ... \", \"\\n} \\nThe rollout of ref fields throughout dotnet/runtime  was done in dotnet /runtime#71498 , followi\", \"ng the \\nC# language gaining this support primarily in dotnet/roslyn#62155 , which itself was the cul\", \"mination \\nof many PRs first into a feature branch. ref fields alone doesn \\u2019t itself automatically im\", \"prove \\nperformance, but it does simplify code significantly, and it allows for both new custom code \", \"that uses \\nref fields as well as new APIs that take advantage of them, both of which can help with p\", \"erformance \\n(and specifically per formance without sacrificing potential safety). One such example o\", \"f a new API is \\nnew constructors on ReadOnlySpan<T>  and Span<T> : \\npublic Span(ref T reference);  \\n\", \"public ReadOnlySpan (in T reference);  \\nadded in dotnet/runtime#67447  (and then made public and use\", \"d more broadly in \\ndotnet/runtime#71589 ). This may beg the question, why does ref field support ena\", \"ble two new \\nconstructors that take refs, considering spans already were able to store a ref? After \", \"all, the \\nMemoryMarshal.CreateSpan(ref T reference, int length)  and corresponding \\nCreateReadOnlySp\", \"an  methods have existed for as long as spa ns have, and these new constructors are \\nequivalent to c\", \"alling those methods with a length of 1. The answer is: safety.  \\nImagine if you could willy -nilly \", \"call this constructor. You\\u2019d be able to write code like this:  \\npublic Span<int> RuhRoh() \\n{ \\n    in\", \"t i = 42; \\n    return new Span<int>(ref i); \\n} \\nAt this point the caller of this method is handed a \", \"span that refers to garbage; that\\u2019s bad in code \\nthat\\u2019s intended to be safe. You can already accompl\", \"ish the same thing by using pointers:  \\npublic Span<int> RuhRoh() \\n{ \\n    unsafe \\n    { \\n        int\", \" i = 42; \\n        return new Span<int>(&i, 1); \\n    } \\n} \\nbut at that point you\\u2019ve taken on the risk\", \" of using unsafe code and pointers and any resulting \\nproblems are on you. With C# 11, if you now tr\", \"y to write the above code using the ref-based \\nconstructor, you\\u2019ll be greeted with an error like thi\", \"s:  \\nerror CS8347:  Cannot use a result of 'Span<int>.Span(ref int)' in this context because it \\nmay\", \" expose variables referenced by parameter 'reference' outside of their declaration scope  \\nIn other \", \"words, the compiler now understands that Span<int>  as a ref struct  could be st oring the \\npassed i\", \"n ref, and if it does store it (which Span<T>  does), this is akin to passing a ref to a local out  \", \"\\n123 CHAPTER 10 | Arrays, Strings, and Spans  \\n of the method, which is bad. Hence how this relates \", \"to ref fields: because ref fields are now a thing, \\nthe compiler\\u2019s rules for safe -handlin g of refs\", \" have been updated, which in turn enables us to expose \\nthe aforementioned constructors on {ReadOnly\", \"}Span<T> . \\nAs is often the case, addressing one issue kicks the can down the road a bit and exposes\", \" another. The \\ncompiler now believes that a ref passed to a method on a ref struct  could enable tha\", \"t ref struct  \\ninstance to store the ref (note that this was already the case with ref struct s pass\", \"ed to methods on \\nref structs ), but what if we don\\u2019t want that? What if we want to be able to say \\u201c\", \"this ref is not \\nstorable and should not escape the calling scope\\u201d? From a caller\\u2019s perspective, we \", \"want the compiler \\nto allow passing in such refs without it complaining about potential extension of\", \" lifetime, and from a \\ncallee\\u2019s perspective, we want the compiler to pre vent the method from doing \", \"what it\\u2019s not supposed \\nto do. Enter scoped . The new C# keyword does exactly what we just wished fo\", \"r: put it on a ref or ref \\nstruct  parameter, and the compiler both will guarantee (short of using u\", \"nsafe code) that the method \\ncan\\u2019t  stash away the argument and will then enable the caller to write\", \" code that relies on that \\nguarantee. For example, consider this program:  \\nvar writer = new SpanWri\", \"ter (stackalloc  char[128]); \\nAppend(ref writer, 123); \\nwriter.Write(\\\".\\\"); \\nAppend(ref writer, 45); \", \"\\nConsole. WriteLine (writer. AsSpan().ToString ()); \\n \\nstatic void Append(ref SpanWriter builder, by\", \"te value) \\n{ \\n    Span<char> tmp = stackalloc  char[3]; \\n    value.TryFormat (tmp, out int charsWrit\", \"ten);  \\n    builder. Write(tmp.Slice(0, charsWritten));  \\n} \\n \\nref struct SpanWriter  \\n{ \\n    privat\", \"e readonly  Span<char> _chars;  \\n    private int _length;  \\n \\n    public SpanWriter (Span<char> dest\", \"ination) => _chars = destination;  \\n \\n    public Span<char> AsSpan() => _chars. Slice(0, _length);  \", \"\\n \\n    public void Write(ReadOnlySpan< char> value)  \\n    { \\n        if (_length > _chars. Length - \", \"value.Length) \\n        { \\n            throw new InvalidOperationException (\\\"Not enough remaining spa\", \"ce\\\" ); \\n        } \\n \\n        value.CopyTo(_chars. Slice(_length));  \\n        _length += value. Lengt\", \"h; \\n    } \\n} \\nWe have a ref struct SpanWriter  that takes a Span<char>  to its constructor and allow\", \"s for writing \\nto it by copying in additional content and then updating the stored length. The Write\", \"  method accepts \\na ReadOnlySpan<char> . And we then have a h elper Append  method which is formatti\", \"ng a byte  into \\nsome stackalloc \\u2019d temporary space and passing the resulting formatted char s in to\", \" Write . \\nStraightforward. Except, this doesn\\u2019t compile:   \\n124 CHAPTER 10 | Arrays, Strings, and Sp\", \"ans  \\n error CS8350: This combination of arguments to 'SpanWriter.Write(ReadOnlySpan<char>)' is \\ndis\", \"allowed because it may expose variables referenced by parameter 'value' outside of their \\ndeclaratio\", \"n scope  \\nWhat do we do? The Write  method doesn\\u2019t actually store the value  parameter and won\\u2019t eve\", \"r need \\nto, so we  can change the signature of the method to annotate it as scoped : \\npublic void Wr\", \"ite(scoped ReadOnlySpan< char> value)  \\nIf Write  were then to try to store value , the compiler wou\", \"ld balk:  \\nerror CS8352: Cannot use variable 'ReadOnlySpan<char>' in this context b ecause it may \\ne\", \"xpose referenced variables outside of their declaration scope  \\nBut as it\\u2019s not trying to do so, eve\", \"rything now compiles successfully. You can see examples of how this \\nis utilized in the aforemention\", \"ed dotnet/runtime#71589 . \\nThere\\u2019s also the other direction: there are some things that are implicit\", \"ly scoped , like the this  \\nreference on a struct. Consider this code:  \\npublic struct SingleItemLis\", \"t  \\n{ \\n    private int _value; \\n     \\n    public ref int this[int i] \\n    { \\n        get \\n        { \", \"\\n            if (i != 0) throw new IndexOutOfRangeException (); \\n             \\n            return re\", \"f _value; \\n        } \\n    } \\n} \\nThis produces a compiler error:  \\nerror CS8170: Struct members canno\", \"t return 'this' or other instance members by reference  \\nEffectively, that\\u2019s because this  is implic\", \"itly scoped  (even though that keyword wasn\\u2019t previously \\navailable). What if we want to enable such\", \" an item to be returned? Enter [UnscopedRef] . This is rare \\nenough in n eed that it doesn\\u2019t get its\", \" own C# language keyword, but the C# compiler does recognize \\nthe new [UnscopedRef]  attribute. It c\", \"an be put onto relevant parameters but also onto methods and \\nproperties, in which case it applies t\", \"o the this  reference for that me mber. As such, we can modify our \\nprevious code example to be:  \\n[\", \"UnscopedRef]  \\npublic ref int this[int i] \\nand now the code will compile successfully. Of course, th\", \"is also places demands on callers of this \\nmethod. For a call site, the compiler sees the [UnscopedR\", \"ef]  on the member being invoked, and then \\nknows that the returned ref might reference something fr\", \"om that struct, and thus assigns to the \\nreturned ref the same lifetime as that struct. So, if that \", \"struct were a local living on the stack, the ref \\nwould a lso be limited to that same method.   \\n125\", \" CHAPTER 10 | Arrays, Strings, and Spans  \\n Another impactful span -related change comes in dotnet/r\", \"untime#70095  from [@teo -\\ntsirpanis](https://github.com/teo -tsirpanis). System.HashCode \\u2019s goal is\", \" to pr ovide a fast, easy -to-use \\nimplementation for producing high -quality hash codes. In its cur\", \"rent incarnation, it incorporates a \\nrandom process -wide seed and is an implementation of the xxHas\", \"h32 non -cryptographic hash \\nalgorithm. In a previous release, HashCode saw the addition of an AddBy\", \"tes  methods, which accepts a \\nReadOnlySpan<byte>  and is useful for incorporating sequences of data\", \" that should be part of a type\\u2019s \\nhash code, e.g. BigInteger.GetHashCode  includes all the data that\", \" makes up the BigInteger . The \\nxxHash32 algorithm works by accumulating 4 32 -bit unsigned integers\", \" and then combining them \\ntogether into the hash code; thus if you call HashCode.Add(int) , the firs\", \"t three times you  call it you\\u2019re \\njust storing the values separately into the instance, and then th\", \"e fourth time you call it all of those \\nvalues are combined into the hash code (and there\\u2019s a separa\", \"te process that incorporates any \\nremaining values if the number of 32 -bit va lues added wasn\\u2019t an \", \"exact multiple of 4). Thus, previously \\nAddBytes  was simply implemented to repeatedly read the next\", \" 4 bytes from the input span and call \\nAdd(int)  with those bytes as an integer. But those Add calls\", \" have overhead. Instead, this PR skips the \\nAdd calls and directly handles the accumulation and comb\", \"ining of the 16 bytes. Interestingly, it still has \\nto deal with the possibility that previous calls\", \" to Add may have left some state queued, which means \\n(with the current implementation at least), if\", \" there are multiple pieces of state to include in the hash \\ncode, say a ReadOnlySpan<byte>  and an a\", \"dditional int, it\\u2019s more efficient to add the span first and \\nthen the int rather than the other way\", \" around. So for example when dotnet/runtime#71274  from \\n[@huoyaoyuan](https://github.com/huoyaoyuan\", \") changed BigInteger.GetHashCode  to use \\nHashCode.AddBytes , it coded the method to first call AddB\", \"ytes  with the BigInteger \\u2019s _bits  and then \\ncall Add with the _sign . \\nprivate byte[] _data = Enum\", \"erable. Range(0, 256).Select(i => (byte)i).ToArray(); \\n \\n[Benchmark]  \\npublic int AddBytes () \\n{ \\n  \", \"  HashCode hc = default; \\n    hc.AddBytes (_data);  \\n    return hc.ToHashCode (); \\n} \\nMethod  Runtim\", \"e  Mean  Ratio  \\nAddBytes  .NET 6.0 159.11 ns  1.00 \\nAddBytes  .NET 7.0  42.11 ns  0.26 \\nAnother spa\", \"n -related change, dotnet/runtime#72727  refactored a bunch of code paths to eliminate \\nsome cached \", \"arrays. Why avoid cached arrays? After all, isn\\u2019t it desirable to cache an array once and \\nreuse it \", \"over and over again? It is, if that\\u2019s the best option, but sometimes there are better options. For  \", \"\\nexample, one of the changes took code like:  \\nprivate static readonly  char[] s_pathDelims = { ':',\", \" '\\\\\\\\', '/', '?', '#' }; \\n... \\nint index = value. IndexOfAny (s_pathDelims);  \\nand replaced it with c\", \"ode like:  \\nint index = value. AsSpan().IndexOfAny (@\\\":\\\\/?#\\\");  \\n126 CHAPTER 10 | Arrays, Strings, a\", \"nd Spans  \\n This h as a variety of benefits. There\\u2019s the usability benefit of keeping the tokens bei\", \"ng searched close \\nto the use site, and the usability benefit of the list being immutable such that \", \"some code somewhere \\nwon\\u2019t accidentally replace a value in the array. But the re are also performanc\", \"e benefits. We don\\u2019t need \\nan extra field to store the array. We don\\u2019t need to allocate the array as\", \" part of this type\\u2019s static \\nconstructor. And loading/using the string is slightly faster.  \\nprivate\", \" static readonly  char[] s_pathDelims = { ':', '\\\\\\\\', '/', '?', '#' }; \\nprivate static readonly  stri\", \"ng s_value = \\\"abcdefghijklmnopqrstuvwxyz\\\" ; \\n \\n[Benchmark]  \\npublic int WithArray () => s_value. Ind\", \"exOfAny (s_pathDelims);  \\n \\n[Benchmark]  \\npublic int WithString () => s_value. AsSpan().IndexOfAny (\", \"@\\\":\\\\/?#\\\"); \\nMethod  Mean  Ratio  \\nWithArray  8.601 ns  1.00 \\nWithString  6.949 ns  0.81 \\nAnother exa\", \"mple from that PR took code along the lines of:  \\nprivate static readonly  char[] s_whitespaces = ne\", \"w char[] { ' ', '\\\\t', '\\\\n', '\\\\r' }; \\n... \\nswitch (attr.Value.Trim(s_whitespaces))  \\n{ \\n    case \\\"pre\", \"serve\\\" : return Preserve;  \\n    case \\\"default\\\" : return Default;  \\n} \\nand replaced it with code like\", \":  \\nswitch (attr.Value.AsSpan().Trim(\\\" \\\\t\\\\n\\\\r\\\")) \\n{ \\n    case \\\"preserve\\\" : return Preserve;  \\n    ca\", \"se \\\"default\\\" : return Default;  \\n} \\nIn this case, not only have we avoided the char[] , but if the t\", \"ext did require any trimming of \\nwhitespaces, the new version (which trims a span instead of the ori\", \"ginal string) will save an allocation \\nfor the trimmed string. This is taking advantage of the ne w \", \"C# 11 feature that supports switching on \\nReadOnlySpan<char> s just as you can switch on string s, a\", \"dded in dotnet/roslyn#44388  from \\n[@YairHalberstadt](https://github.com/YairHalberstadt). dotnet/ru\", \"ntime#68831  also took advantage \\nof this in several additional places.  \\nOf course, in some cases t\", \"he arrays are entirely un necessary. In that same PR, there were several cases \\nlike this:  \\nprivate\", \" static readonly  char[] WhiteSpaceChecks = new char[] { ' ', '\\\\u00A0' };  \\n... \\nint wsIndex = targe\", \"t. IndexOfAny (WhiteSpaceChecks, targetPosition);  \\nif (wsIndex < 0) \\n{ \\n    return false; \\n}  \\n127 \", \"CHAPTER 10 | Arrays, Strings, and Spans  \\n By switching to use spans, again, we can instead write it\", \" like this:  \\nint wsIndex = target. AsSpan(targetPosition). IndexOfAny (' ', '\\\\u00A0');  \\nif (wsInde\", \"x < 0) \\n{ \\n    return false; \\n} \\nwsIndex += targetPosition;  \\nMemoryExtensions.IndexOfAny  has a ded\", \"icated overload for two and three arguments, at which \\npoint we don\\u2019t need the array at all (these o\", \"verloads also happen to be faster; when passing an array \\nof two chars, the implementation would ext\", \"ract the two chars fr om the array and pass them off to the \\nsame two -argument implementation). Mul\", \"tiple other PRs similarly removed array allocations. \\ndotnet/runtime#60409  removed a single -char a\", \"rray that was cache d to be able to pass it to \\nstring.Split  and replaced it with usage of the Spli\", \"t  overload that directly accepts a single char . \\nFinally, dotnet/runtime#59670  from [@NewellClark\", \"](https://github.c om/NewellClark) got rid of even \\nmore arrays. We saw earlier how the C# compiler \", \"special -cases byte[] s constructed with a constant \\nlength and constant elements and that\\u2019s immedia\", \"tely cast to a ReadOnlySpan<byte> . Thus, it can be \\nbeneficial any time there\\u2019s such a byte[]  bein\", \"g cached to instead expose it as a ReadOnlySpan<byte> . \\nAs I discussed in the .NET 6  post, this av\", \"oids even the one -time array allocation you\\u2019d get for a cached \\narray, results in much more efficie\", \"nt access, and supplies to the JIT compiler more information that \\nenables it to more heavily optimi\", \"ze\\u2026 goodness all around. This PR removed even more arrays in this \\nmanner, as did dotnet/runtime#604\", \"11 , dotnet/runtime#72743 , dotnet/runtime#73115  from \\n[@vcsjones](https://gi thub.com/vcsjones), a\", \"nd dotnet/runtime#70665 .  \\n128 CHAPTER 11 | Regex  \\n CHAPTER  11 \\nRegex  \\nBack in May, I shared a f\", \"airly detailed post about the improvements coming to Regular Expressions in \\n.NET 7 . As a recap, pr\", \"ior to .NET 5, Regex \\u2019s implementation had largely been untouched for quite \\nsome time. In .NET 5, w\", \"e brought it back up to be on par with or better than multiple other industry \\nimplementations from \", \"a performance perspective. .NET 7 takes some si gnificant leaps forward from \\nthat. If you haven\\u2019t r\", \"ead the post yet, please go ahead and do so now; I\\u2019ll wait\\u2026  \\nWelcome back. With that context, I\\u2019ll \", \"avoid duplicating content here, and instead focus on how exactly \\nthese improvements came about and \", \"the PRs that did so.  \\nRegexOptions.NonBacktracking  \\nLet\\u2019s start with one of the larger new feature\", \"s in Regex , the new RegexOptions.NonBacktracking  \\nimplementation. As discussed in the previous pos\", \"t, RegexOptions.NonBacktracking  switches the \\nprocessing of Regex  over to using a new engine based\", \" in finite automata. It has two primary modes of \\nexecution, one that relies on DFAs (deterministic \", \"finite automata) and one that relies on NFAs (non -\\ndeterministic finite automata). Both impl ementa\", \"tions provide a very valuable guarantee: processing \\ntime is linear in the length of the input. Wher\", \"eas a backtracking engine (which is what Regex  uses if \\nNonBacktracking  isn\\u2019t specified) can hit a\", \" situation known as \\u201ccatastrophic backtracking,\\u201d where  \\nproblematic expressions combined with probl\", \"ematic input can result in exponential processing in the \\nlength of the input, NonBacktracking  guar\", \"antees it\\u2019ll only ever do an ammortized -constant amount \\nof work per character in the input. In the\", \" case of a DFA, that constant is very small. With an NFA, that \\nconstant can be much larger, based o\", \"n the complexity of the pattern, but for any given pattern the \\nwork is still linear in the length o\", \"f the input.  \\nA significant number of years of development went into the NonBacktracking  implement\", \"ation, which \\nwas initially added into dotnet/runtime  in dotnet/runtime#60607 . However, the origin\", \"al research and \\nimplementation for it actually came from Microsoft Research (MSR), and was availabl\", \"e as an \\nexperimental package in the form of the Symbolic Regex Matcher (SRM) library published by M\", \"SR. \\nYou can still see vestiges of this in the current code now in .NET 7, but it\\u2019s evolved signific\", \"antly, in \\ntight collaboration between developers on the .NET team and the researchers at MSR (prior\", \" to being \\nintegrated in dotnet/runtime , it was incubated for over a year in dotnet/runtimelab , wh\", \"ere the original \\nSRM code was brought in via dotnet/runtimelab#588  from [@veanes](https://github.c\", \"om/veanes)).  \\nThis i mplementation is based on the notion of regular expression derivatives, a conc\", \"ept that\\u2019s been \\naround for decades (the term was originally coined in a paper by Janusz Brzozowski \", \"in the 1960s) and \\nwhich has been significantly advanced for this implementation . Regex derivatives\", \" form the basis for \\nhow the automata (think \\u201cgraph\\u201d) used to process input are constructed. The ide\", \"a at its core is fairly \\nsimple: take a regex and process a single character\\u2026 what is the new regex \", \"you get to describe what \\nremains after processing that one character? That\\u2019s the derivative. For ex\", \"ample, given the regex \\\\w{3}   \\n129 CHAPTER 11 | Regex  \\n to match three word characters, if you app\", \"ly this to the next input character \\u2018a\\u2019, well, that will strip off \\nthe first \\\\w, leaving us with th\", \"e derivative \\\\w{2} . Simple , right? How about something more \\ncomplicated, like the expression .*(t\", \"he|he) . What happens if the next character is a t? Well, it\\u2019s \\npossible that t could be consumed by\", \" the .* at the beginning of the pattern, in which case the \\nremaining regex would be exa ctly the sa\", \"me as the starting one ( .*(the|he) ), since after matching t \\nwe could still match exactly the same\", \" input as without the t. But, the t could have also been part of \\nmatching the, and applied to the, \", \"we\\u2019d strip off the t and be left with he, so now our derivative is \\n.*(the|he)|he . Then what about \", \"the he in the original alternation? t doesn\\u2019t match h, so the \\nderivative would be nothing, which we\", \"\\u2019ll express here as an empty character class, giving us \\n.*(the|he)|he|[] . Of course, as part of an\", \" alternati on, that \\u201cnothing\\u201d at the end is a nop, and so we \\ncan simplify the whole derivative to j\", \"ust .*(the|he)|he \\u2026 done. That was all when applying the \\noriginal pattern against a next t. What if\", \" it was against an h instead? Following the same logic as for \\nthe t, this time we end up with .*(th\", \"e|he)|e . And so on. What if we instead start with the h \\nderivative and the next character is an e?\", \" Then we\\u2019re taking the pattern .*(the|he)|e  and applying it \\nto e. Against the left side of the alt\", \"ernation, it can be consumed by  the .* (but doesn\\u2019t match either t \\nor h), and so we just end up wi\", \"th that same subexpression. But against the right side of the \\nalternation, e matches e, leaving us \", \"with the empty string (): .*(the|he)|() . At the point where a \\npattern is \\u201cnullable\\u201d (it ca n match\", \" the empty string), that can be considered a match. We can visualize \\nthis whole thing as a graph, w\", \"ith transitions for every input character to the derivative that comes \\nfrom applying it.   \\n130 CHA\", \"PTER 11 | Regex  \\n  \\n \\n131 CHAPTER 11 | Regex  \\n Looks an awful lot like a DFA, doesn\\u2019t it? It shoul\", \"d. And that\\u2019s exactly how NonBacktracking  \\nconstructs the DFAs it uses to process input. For every \", \"regex construct (concatenations, alternations, \\nloops, etc.) the engine knows how to derive the next\", \" regex b ased on the character being evaluated. \\nThis application is done lazily, so we have an init\", \"ial starting state (the original pattern), and then when \\nwe evaluate the next character in the inpu\", \"t, it looks to see whether there\\u2019s already a derivative \\navailable f or that transition: if there is\", \", it follows it, and if there isn\\u2019t, it dynamically/lazily derives the \\nnext node in the graph. At i\", \"ts core, that\\u2019s how it works.  \\nOf course, the devil is in the details and there\\u2019s a ton of complica\", \"tion and engineering smarts that go \\ninto making the engine efficient. One such example is a tradeof\", \"f between memory consumption and \\nthroughput. Given the ability to have any char  as input, you coul\", \"d have effectively ~65K transitions \\nout of every node (e.g.  every node could need a ~65 K element \", \"table); that would significantly increase \\nmemory consumption. However, if you actually had that man\", \"y transitions, it\\u2019s very likely a significant \\nmajority of them would point to the same target node.\", \" Thus, NonBacktracking  maintains its own \\ngroupin gs of characters into what it calls \\u201cminterms.\\u201d I\", \"f two characters will have exactly the same \\ntransition, they\\u2019re part of the same minterm. The trans\", \"itions are then constructed in terms of \\nminterms, with at most one transition per minterm out of a \", \"given nod e. When the next input character \\nis read, it maps that to a minterm ID, and then finds th\", \"e appropriate transition for that ID; one \\nadditional level of indirection in order to save a potent\", \"ially huge amount of memory. That mapping is \\nhandled via an array bi tmap for ASCII and an efficien\", \"t data structure known as a Binary Decision \\nDiagram (BDD)  for everything above 0x7F.  \\nAs noted, t\", \"he non -backtracking engine is linear in the length of the  input. But that doesn\\u2019t mean it \\nalways \", \"looks at each input character exactly once. If you call Regex.IsMatch , it does; after all, IsMatch \", \" \\nonly needs to determine whether there is a match and doesn\\u2019t need to compute any additional \\ninfor\", \"mation, such as wher e the match actual starts or ends, any information on captures, etc. Thus, the \", \"\\nengine can simply employ its automata to walk along the input, transitioning from node to node in \\n\", \"the graph until it comes to a final state or runs out of input. Other operation s, however, do requi\", \"re it \\nto gather more information. Regex.Match  needs to compute everything, and that can actually e\", \"ntail \\nmultiple walks over the input. In the initial implementation, the equivalent of Match  would \", \"always take \\nthree passes: match forwards  to find the end of a match, then match a reversed -copy o\", \"f the pattern in \\nreverse from that ending location in order to find where the match actually starts\", \", and then once more \\nwalk forwards from that known starting position to find the actual ending posi\", \"t ion. However, with \\ndotnet/runtime#68199  from [@olsaarik](https://github.com/olsaarik), unless ca\", \"ptures are required, it \\ncan now be done in only two passes: once forward to find the guaranteed end\", \"ing location of the \\nmatch, and then once in reverse to find its starting location. And dotnet/runti\", \"me#65129  from \\n[@olsaarik](https://github.com/olsaarik) added captures support, which the o riginal\", \" implementation \\nalso didn\\u2019t have. This captures support adds back a third pass, such that once the \", \"bounds of the \\nmatch are known, the engine runs the forward pass one more time, but this time with a\", \"n NFA -based \\n\\u201csimulation\\u201d that is able to record \\u201cca pture effects\\u201d on transitions. All of this ena\", \"bles the non -\\nbacktracking implementation to have the exact same semantics as the backtracking engi\", \"nes, always \\nproducing the same matches in the same order with the same capture information. The onl\", \"y \\ndifference in this regard is, whereas with the backtracking engines capture groups inside of loop\", \"s will \\nstore all values captured in every iteration of the loop, only the last iteration is stored \", \"with the non -\\nbacktracking implementation. On top of that, there are a f ew constructs the non -bac\", \"ktracking  \\n132 CHAPTER 11 | Regex  \\n implementation simply doesn\\u2019t support, such that attempting to\", \" use any of those will fail when trying \\nto construct the Regex , e.g. backreferences and lookaround\", \"s.  \\nEven after its progress as a standalone library from MSR, more than 100 PRs went into making \\nR\", \"egexOptions.NonBacktracking  what it is now in .NET 7, including optimizations like \\ndotnet/runtime#\", \"70217  from [@olsaarik](https://github.com/olsaarik) that t ries to streamline the tight \\ninner matc\", \"hing loop at the heart of the DFA (e.g.  read the next input character, find the appropriate \\ntransi\", \"tion to take, move to the next node, and check information about the node like whether it\\u2019s a \\nfinal\", \" state) and optimiza tions like dotnet/runtime#65637  from [@veanes](https://github.com/veanes) \\ntha\", \"t optimized the NFA mode to avoid superfluous allocations, caching and reusing list and set \\nobjects\", \" to make the han dling of the lists of states ammortized allocation -free. \\nThere\\u2019s one more set of \", \"PRs of performance interest for NonBacktracking . The Regex  implementation \\nfor taking patterns and\", \" turning them into something processable, regardless of which of the multiple \\nengines is being used\", \", is essentially a compiler, and as with many compilers, it naturally lends itself to \\nrecursive alg\", \"orithms. In the case of Regex , those algorithms involve walking around trees of regular \\nexpression\", \" constructs. Recursion ends up being a  very handy way of expressing these algorithms, but \\nrecursio\", \"n also suffers from the possibility of stack overflow; essentially it\\u2019s using stack space as scratch\", \" \\nspace, and if it ends up using too much, things go badly. One common approach to dealing with t hi\", \"s \\nis turning the recursive algorithm into an iterative one, which typically involves using an expli\", \"cit stack \\nof state rather than the implicit one. The nice thing about this is the amount of state y\", \"ou can store is \\nlimited only by how much memory you have , as opposed to being limited by your thre\", \"ad\\u2019s stack \\nspace. The downsides, however, are that it\\u2019s typically much less natural to write the al\", \"gorithms in this \\nmanner, and it typically requires allocating heap space for the stack, which then \", \"leads to additio nal \\ncomplications if you want to avoid that allocation, such as various kinds of p\", \"ooling. \\ndotnet/runtime#60385  introduces a different approach for Regex , which is then used by \\ndo\", \"tnet/runtime#60786  from [@olsaarik](https://github.com/olsaarik) specifically in the \\nNonBacktracki\", \"ng  implementation. It still uses recursion, and thus benefits from the expressiveness of \\nthe recur\", \"sive algor ithm as well as being able to use stack space and thus avoid additional allocation in \\nth\", \"e most common cases, but then to avoid stack overflows, it issues explicit checks to ensure we\\u2019re \\nn\", \"ot too deep on the stack (.NET has long provided the helpers \\nRuntimeH elpers.EnsureSufficientExecut\", \"ionStack  and \\nRuntimeHelpers.TryEnsureSufficientExecutionStack  for this purpose). If it detects it\", \"\\u2019s too deep \\non the stack, it forks off continued execution into another thread. Hitting this condit\", \"ion is expensive, \\nbut it\\u2019s very  rarely if ever actually hit in practice (e.g.  the only time it\\u2019s \", \"hit in our vast functional tests \\nare in the tests explicitly written to stress it), it keeps the co\", \"de simple, and it keeps the typical cases \\nfast. A similar approach is used in other areas o f dotne\", \"t/runtime , such as in System.Linq.Expressions.  \\nAs was mentioned in my previous blog post about re\", \"gular expressions, both the backtracking \\nimplementations and the non -backtracking implementation h\", \"ave their place. The main benefit of the \\nnon-backtracking implementation is predictability: because\", \" of the linear processing guarantee, once \\nyou\\u2019ve constructed the regex, you don\\u2019t need to worry abo\", \"ut malicious inputs causing worst -case \\nbehavior in the processing of your potentially susceptible \", \"expressions. This doesn\\u2019t mean \\nRegexOptions.NonBacktracking  is always the fastest; in fact, it\\u2019s f\", \"requently not. In exchange for \\nreduced best -case performance, it provides the best worst -case per\", \"forma nce, and for some kinds of \\napplications, that\\u2019s a really worthwhile and valuable tradeoff.   \", \"\\n133 CHAPTER 11 | Regex  \\n New APIs  \\nRegex  gets several new methods in .NET 7, all of which enable\", \" improved performance. The simplicity \\nof the new APIs likely also misrepresents how much work w as \", \"necessary to enable them, in particular \\nbecause the new APIs all support ReadOnlySpan<char>  inputs\", \" into the regex engines.  \\ndotnet/runtime#65473  brings Regex  into the span -based era of .NET,  ov\", \"ercoming a significant \\nlimitation in Regex  since spans were introduced back in .NET Core 2.1. Rege\", \"x  has historically been \\nbased on processing System.String  inputs, and that fact pervades the Rege\", \"x  design and \\nimplementation, including the APIs exposed fo r the extensibility model Regex.Compile\", \"ToAssembly  \\nrelied on in .NET Framework ( CompileToAssembly  is now obsoleted and has never been fu\", \"nctional in \\n.NET Core). One subtly that relies on the nature of string  as the input is how match i\", \"nformation is \\nreturned to callers. Regex.Match  returns a Match  object that represents the first m\", \"atch in the input, \\nand that Match  object exposes a NextMatch  method that enables moving to the ne\", \"xt match. That \\nmeans the Match  object needs to store a reference to the input, so tha t it can be \", \"fed back into the \\nmatching engine as part of such a NextMatch  call. If that input is a string , gr\", \"eat, no problem. But if \\nthat input is a ReadOnlySpan<char> , that span as a ref struct  can\\u2019t be st\", \"ored on the class Match  \\nobject, since ref structs  can only live on the stack and not the heap. Th\", \"at alone would make it a \\nchallenge to support spans, but the problem is even more deeply rooted. Al\", \"l of the regex engines rely \\non a RegexRunner , a base class that stores on it all of the state nece\", \"ssary to fee d into the \\nFindFirstChar  and Go methods that compose the actual matching logic for th\", \"e regular expressions \\n(these methods contain all of the core code for performing the match, with Fi\", \"ndFirstChar  being an \\noptimization to skip past input positions that coul dn\\u2019t possibly start a mat\", \"ch and then Go performing \\nthe actual matching logic). If you look at the internal RegexInterpreter \", \" type, which is the engine you \\nget when you construct a new Regex(...)  without the RegexOptions.Co\", \"mpiled  or \\nRegexOptions.NonBacktrack ing flags, it derives from RegexRunner . Similarly, when you u\", \"se \\nRegexOptions.Compiled , it hands off the dynamic methods it reflection emits to a type derived f\", \"rom \\nRegexRunner , RegexOptions.NonBacktracking  has a SymbolicRegexRunnerFactory  that produces \\nty\", \"pes derived from RegexRunner , and so on. Most relevant here, RegexRunner  is public, because the \\nt\", \"ypes generated by the Regex.CompileToAssembly  type (and now the regex source generator) include \\non\", \"es derived from this RegexRunner . Those FindFirstChar  and Go methods are thus abstract  and \\nprote\", \"cted , and parameterless, because they pick up all the state they need from protected members \\non th\", \"e base class. That includes the string  input to process. So what about spans? We could of \\ncourse h\", \"ave just called ToString()  on an input ReadOnlySpan<char> . That would have been \\nfunctionally corr\", \"ect, but would have completely defeated the purpose of accepting spans, and worse, \\nwould have been \", \"so unexpected as to likely cause consuming apps to be worse perf orming than they \\nwould have withou\", \"t the APIs. Instead, we needed a new approach and new APIs.  \\nFirst, we made FindFirstChar  and Go v\", \"irtual instead of abstract. The design that splits these methods \\nis largely antiquated, and in part\", \"icular the forced separati on between a stage of processing where you \\nfind the next possible locati\", \"on of a match and then a stage where you actually perform the match at \\nthat location doesn\\u2019t align \", \"well with all engines, like the one used by NonBacktracking  (which initially \\nimplemen ted FindFirs\", \"tChar  as a nop and had all its logic in Go). Then we added a new virtual Scan  \\nmethod which, impor\", \"tantly, takes a ReadOnlySpan<char>  as a parameter; the span can\\u2019t be exposed \\nfrom the base RegexRu\", \"nner  and must be passed in. We then implemented FindFirstChar  and Go in \\nterms of Scan , and made \", \"them \\u201cjust work.\\u201d Then, all of the engines are implemented in terms of that  \\n134 CHAPTER 11 | Regex\", \"  \\n span; they no longer need to access the protected RegexRunner.runtext , RegexRunner.runtextbeg ,\", \" \\nand RegexRunner.runtextend  members tha t surface the input; they\\u2019re just handed the span, already\", \" \\nsliced to the input region, and process that. One of the neat things about this from a performance\", \" \\nperspective is it enables the JIT to do a better job at shaving off various overheads, in particul\", \" ar \\naround bounds checking. When the logic is implemented in terms of string , in addition to the i\", \"nput \\nstring itself the engine is also handed the beginning and end of the region of the input to pr\", \"ocess \\n(since the developer could have called a method like Regex.Match(string input, int beginning,\", \" \\nint length)  in order to only process a substring). Obviously the engine matching logic is way mor\", \"e \\ncomplicated than this, but simplifying, imagine the entirety of the engine was just a loop over t\", \"he \\ninput. With the i nput, beginning, and length, that would look like:  \\n[Benchmark]  \\n[Arguments \", \"(\\\"abc\\\", 0, 3)] \\npublic void Scan(string input, int beginning, int length) \\n{ \\n    for (int i = begin\", \"ning; i < length; i++)  \\n    { \\n        Check(input[i]);  \\n    } \\n} \\n \\n[MethodImpl (MethodImplOption\", \"s. AggressiveInlining )] \\nprivate void Check(char c) { } \\nThat will result in the JIT generating ass\", \"embly code along the lines of this:  \\n; Program.Scan(System.String, Int32, Int32)  \\n       sub      \", \" rsp,28  \\n       cmp       r8d,r9d  \\n       jge       short M00_L01  \\n       mov       eax,[rdx+8]  \", \"\\nM00_L00:  \\n       cmp       r8d,eax  \\n       jae       short M00_L02  \\n       inc       r8d  \\n     \", \"  cmp       r8d,r9d  \\n       jl        short M00_L00  \\nM00_L01:  \\n       add       rsp,28  \\n       r\", \"et \\nM00_L02:  \\n       call      CORINFO_HELP_RNGCHKFAIL  \\n       int       3  \\n; Total bytes of code\", \" 36  \\nIn contrast, if we\\u2019re dealing with a span, which already factors in the bounds, then we can wr\", \"ite a more \\ncanonical loop like this:  \\n[Benchmark]  \\n[Arguments (\\\"abc\\\")] \\npublic void Scan(ReadOnl \", \"ySpan<char> input)  \\n{ \\n    for (int i = 0; i < input. Length; i++) \\n    { \\n        Check(input[i]);\", \"  \\n    } \\n}  \\n135 CHAPTER 11 | Regex  \\n  \\n[MethodImpl (MethodImplOptions. AggressiveInlining )] \\npri\", \"vate void Check(char c) { } \\nAnd when it comes to compilers, something in a canonical form is really\", \" good, because the more \\ncommon the shape of the code, the more likely it is to be heavily optimized\", \":  \\n; Program.Scan(System.ReadOnlySpan`1<Char>)  \\n       mov       rax,[rdx]  \\n       mov       edx,\", \"[rdx+8]  \\n       xor       ecx,ecx  \\n       test      edx,edx  \\n       jle       short M00_L01  \\nM00\", \"_L00:  \\n       mov       r8d,ecx  \\n       movsx     r8,word ptr [rax+r8*2]  \\n       inc       ecx  \\n\", \"       cmp       ecx,edx  \\n       jl        short M00_L00  \\nM00_L01:  \\n       ret \\n; Total bytes of \", \"code 27  \\nSo even without all the othe r benefits that come from operating in terms of span, we imme\", \"diately get \\nlow-level code generation benefits from performing all the logic in terms of spans. Whi\", \"le the above \\nexample was made up (obviously the matching logic does more than a simple for loop) , \", \"here\\u2019s a real \\nexample. When a regex contains a \\\\b, as part of evaluating the input against that \\\\b \", \"the backtracking \\nengines call a RegexRunner.IsBoundary  helper method which checks whether the char\", \"acter at the \\ncurrent position is a word character and whe ther the character before it is a word ch\", \"aracter (factoring \\nin the bounds of the input as well). Here\\u2019s what the IsBoundary  method based on\", \" string  looked like \\n(the runtext  it\\u2019s using is the name of the string  field on RegexRunner  that\", \" stores the input):  \\n[Benchmark]  \\n[Arguments (0, 0, 26)] \\npublic bool IsBoundary (int index, int s\", \"tartpos, int endpos) \\n{ \\n    return (index > startpos && IsBoundaryWordChar (runtext[index - 1])) !=\", \" \\n           (index < endpos   && IsBoundaryWordChar (runtext[index]));  \\n} \\n \\n[MethodImpl (MethodIm\", \"plOptions. NoInlining )] \\nprivate bool IsBoundaryWordChar (char c) => false; \\nand here\\u2019s what the sp\", \"an version looks like:  \\n[Benchmark]  \\n[Arguments (\\\"abcdefghijklmnopqrstuvwxyz\\\" , 0)] \\npublic bool I\", \"sBoundary (ReadOnlySpan< char> inputSpan, int index) \\n{ \\n    int indexM1 = index - 1; \\n    return ((\", \"uint)indexM1 < ( uint)inputSpan. Length && \\nIsBoundaryWordChar (inputSpan[indexM1])) !=  \\n          \", \"  ((uint)index < ( uint)inputSpan. Length && IsBoundaryWordChar (inputSpan[index]));  \\n} \\n \\n[MethodI\", \"mpl (MethodImplOptions. NoInlining )] \\nprivate bool IsBoundaryWordChar (char c) => false;  \\n136 CHAP\", \"TER 11 | Regex  \\n And here\\u2019s the resulting assembly:  \\n; Program.IsBoundary(Int32, Int32, Int32)  \\n \", \"      push      rdi  \\n       push      rsi  \\n       push      rbp  \\n       push      rbx  \\n       su\", \"b       rsp,28  \\n       mov       rdi ,rcx \\n       mov       esi,edx  \\n       mov       ebx,r9d  \\n  \", \"     cmp       esi,r8d  \\n       jle       short M00_L00  \\n       mov       rcx,rdi  \\n       mov     \", \"  rcx,[rcx+8]  \\n       lea       edx,[rsi -1] \\n       cmp       edx,[rcx+8]  \\n       jae       short\", \" M00_L04  \\n       mov       edx,edx  \\n       movzx     edx,word ptr [rcx+rdx*2+0C]  \\n       mov     \", \"  rcx,rdi  \\n       call      qword ptr [Program.IsBoundaryWordChar(Char)]  \\n       jmp       short M\", \"00_L01  \\nM00_L00:  \\n       xor       eax,eax  \\nM00_L01:  \\n       mov       ebp,eax  \\n       cmp     \", \"  esi,ebx  \\n       jge       short M00_L02  \\n       mov       rcx,rdi  \\n       mov       rcx,[rcx+8]\", \"  \\n       cmp       esi,[rcx+8]  \\n       jae       short M00_L04  \\n       mov       edx,esi  \\n      \", \" movzx     edx,word ptr [rcx+rdx*2+0C]  \\n       mov       r cx,rdi \\n       call      qword ptr [Prog\", \"ram.IsBoundaryWordChar(Char)]  \\n       jmp       short M00_L03  \\nM00_L02:  \\n       xor       eax,eax\", \"  \\nM00_L03:  \\n       cmp       ebp,eax  \\n       setne     al  \\n       movzx     eax,al  \\n       add \", \"      rsp,28  \\n       pop       rbx  \\n       pop       rbp  \\n       pop       rsi  \\n       pop      \", \" rdi  \\n       ret \\nM00_L04:  \\n       call      CORINFO_HELP_RNGCHKFAIL  \\n       int       3  \\n; Tota\", \"l bytes of code 117  \\n \\n; Program.IsBoundary(System.ReadOnlySpan`1<Char>, Int32)  \\n       push      \", \"r14  \\n       push      rdi  \\n       push      rsi  \\n       push      rbp   \\n137 CHAPTER 11 | Regex  \", \"\\n        push      rbx  \\n       sub       rsp,20  \\n       mov       rdi,rcx  \\n       mov       esi,r\", \"8d  \\n       mov       rbx,[rdx]  \\n       mov       ebp,[rdx+8]  \\n       lea       edx,[rsi -1] \\n    \", \"   cmp       edx ,ebp \\n       jae       short M00_L00  \\n       mov       edx,edx  \\n       movzx     \", \"edx,word ptr [rbx+rdx*2]  \\n       mov       rcx,rdi  \\n       call      qword ptr [Program.IsBoundary\", \"WordChar(Char)]  \\n       jmp       short M00_L01  \\nM00_L00:  \\n       xor       eax,eax  \\nM00_L01: \\n \", \"      mov       r14d,eax  \\n       cmp       esi,ebp  \\n       jae       short M00_L02  \\n       mov   \", \"    edx,esi  \\n       movzx     edx,word ptr [rbx+rdx*2]  \\n       mov       rcx,rdi  \\n       call    \", \"  qword ptr [Program.IsBoundaryWordChar(Char)]  \\n       jmp       short M00_L03  \\nM00_L02:  \\n       \", \"xor       eax,eax  \\nM00_L03:  \\n       cmp       r14d,eax  \\n       setne     al  \\n       movzx     ea\", \"x,al  \\n       add       rsp,20  \\n       pop       rbx  \\n       pop       rbp  \\n       pop       rsi \", \" \\n       pop       rdi  \\n       pop       r14 \\n       ret \\n; Total bytes of code 94  \\nThe most inter\", \"esting thing to notice here is the:  \\ncall      CORINFO_HELP_RNGCHKFAIL  \\nint       3  \\nat the end o\", \"f the first version that doesn\\u2019t exist at the end of the second. As we saw earlier, this is \\nwhat th\", \"e generated assembly looks like when the JIT is emitting the code to throw an index out of \\nrange ex\", \"ception for an array, string, or span. It\\u2019s at the end because it\\u2019s considered to be \\u201ccold,\\u201d rarely \", \"\\nexecuted. It exists in the first because the JIT can\\u2019t prov e based on local analysis of that funct\", \"ion that \\nthe runtext[index -1] and runtext[index]  accesses will be in range of the string (it can\\u2019\", \"t know or \\ntrust any implied relationship between startpos , endpos , and the bounds of runtext ). B\", \"ut in the \\nsecond, the JIT can know and trust that the ReadOnlySpan<char> \\u2019s lower bound is 0 and up\", \"per bound \\n(exclusive) is the span\\u2019s Length , and with how the method is constructed, it can then pr\", \"ove that the \\nspan accesses are always in bound. As such, it doesn\\u2019t need to emit any bounds checks \", \"in the method, \\nand the method then lacks the tell -tale signature of the index out of range throw. \", \"You can see more \\nexamples of taking advantage of spans now being at the heart of the all of the eng\", \"ines in  \\n138 CHAPTER 11 | Regex  \\n dotnet/runtime#66129 , dotnet/runtime#66178 , and dotnet/runtime\", \"#72728 , all of which clean up \\nunnecessary checks against the bounds that are then always 0 and spa\", \"n.Length . \\nOk, so the engine s are now able to be handed span inputs and process them, great, what \", \"can we do \\nwith that? Well, Regex.IsMatch  is easy: it\\u2019s not encumbered by needing to perform multip\", \"le matches, \\nand thus doesn\\u2019t need to worry about how to store that input ReadOnlySpan<ch ar> for th\", \"e next \\nmatch. Similarly, the new Regex.Count , which provides an optimized implementation for count\", \"ing \\nhow many matches there are in the input, can bypass using Match  or MatchCollection , and thus \", \"can \\neasily operate over spans as well; dotnet/runtime#64289  added string -based overloads, and \\ndo\", \"tnet/runtime#66026  added span -based overloads. We can optimize Count  further by pas sing \\nadditio\", \"nal information into the engines to let them know how much information they actually need to \\ncomput\", \"e. For example, I noted previously that NonBacktracking  is fairly pay -for-play in how much \\nwork i\", \"t needs to do relative to what information it ne eds to gather. It\\u2019s cheapest to just determine \\nwhe\", \"ther there is a match, as it can do that in a single forward pass through the input. If it also need\", \"s \\nto compute the actual starting and ending bounds, that requires another reverse pass through some\", \" \\nof the  input. And if it then also needs to compute capture information, that requires yet another\", \" \\nforward pass based on an NFA (even if the other two were DFA -based). Count  needs the bounds \\ninf\", \"ormation, as it needs to know where to start looking for the next mat ch, but it doesn\\u2019t need the \\nc\", \"apture information, since none of that capture information is handed back to the caller. \\ndotnet/run\", \"time#68242  updates the engines to receive this additional inform ation, such that methods \\nlike Cou\", \"nt  can be made more efficient.  \\nSo, IsMatch  and Count  can work with spans. But we still don\\u2019t ha\", \"ve a method that lets you actually get \\nback that match information. Enter the new EnumerateMatches \", \" method, added by \\ndotnet/runtime#67794 . EnumerateMatches  is very similar to Match , except instea\", \"d of handing back a \\nMatch  class instance, it hands back a ref struct  enumerator:  \\npublic ref str\", \"uct ValueMatchEnumerator  \\n{ \\n    private readonly  Regex _regex;  \\n    private readonly  ReadOnlySp\", \"an< char> _input;  \\n    private ValueMatch _current;  \\n    private int _startAt;  \\n    private int _\", \"prevLen;  \\n    ... \\n} \\nBeing a ref struct , the enumerator is able to store a reference to the input\", \" span, and is thus able to \\niterate through matches, which are represented by the ValueMatch  ref st\", \"ruct. Notably, today \\nValueMatch  doesn\\u2019t provide capture information, which also enables it to part\", \"ake in the optimizations \\npreviously me ntioned for Count . Even if you have an input string , Enume\", \"rateMatches  is thus a way to \\nhave ammortized allocation -free enumeration of all matches in the in\", \"put. In .NET 7, though, there isn\\u2019t \\na way to have such allocation -free enumeration if you also nee\", \"d a ll the capture data. That\\u2019s something \\nwe\\u2019ll investigate designing in the future if/as needed.  \", \"\\nTryFindNextPossibleStartingPosition  \\nAs noted earlier, the core of all of the engines is a Scan(Re\", \"adOnlySpan<char>)  method that accepts \\nthe input text to match, co mbines that with positional info\", \"rmation from the base instance, and exits  \\n139 CHAPTER 11 | Regex  \\n when it either finds the locat\", \"ion of the next match or exhausts the input without finding another. For \\nthe backtracking engines, \", \"the implementation of that method is logically as fol lows:  \\nprotected  override  void Scan(ReadOnl\", \"ySpan< char> inputSpan)  \\n{ \\n    while (!TryMatchAtCurrentPosition (inputSpan) &&  \\n           base.\", \"runtextpos  != inputSpan. Length) \\n    { \\n        base.runtextpos ++; \\n    } \\n} \\nWe try to match the\", \" input at the current position, and if we\\u2019re successful in doing so, that\\u2019s it, we exit. \\nIf the cur\", \"rent position doesn\\u2019t match, however, then if there\\u2019s any input remaining we \\u201cbump\\u201d the \\nposition an\", \"d start the process over. In regex engine terminology, this is often referred to  as a \\n\\u201cbumpalong l\", \"oop.\\u201d However, if we actually ran the full matching process at every input character, that \\ncould be\", \" unnecessarily slow. For many patterns, there\\u2019s something about the pattern that would \\nenable us to\", \" be more thoughtful about where we perfo rm full matches, quickly skipping past locations \\nthat coul\", \"dn\\u2019t possibly match, and only spending our time and resources on locations that have a real \\nchance \", \"of matching. To elevate that concept to a first -class one, the backtracking engines\\u2019 \\n\\u201cbumpalong lo\", \"o p\\u201d is typically more like the following (I say \\u201ctypically\\u201d because in some cases the \\ncompiled and\", \" source generated regexes are able to generate something even better).  \\nprotected  override  void S\", \"can(ReadOnlySpan< char> inputSpan)  \\n{ \\n    while (TryFindNextPossi bleStartingPosition (inputSpan) \", \"&&  \\n           !TryMatchAtCurrentPosition (inputSpan) &&  \\n           base.runtextpos  != inputSpan\", \". Length) \\n    { \\n        base.runtextpos ++; \\n    } \\n} \\nAs with FindFirstChar  previously, that Try\", \"FindNextPossibleStartingPosition  has th e \\nresponsibility of searching as quickly as possible for t\", \"he next place to match (or determining that \\nnothing else could possibly match, in which case it wou\", \"ld return false  and the loop would exit). As \\nFindFirstChar , and it was embued with multiple ways \", \"of  doing its job. In .NET 7, \\nTryFindNextPossibleStartingPosition  learns many more and improved wa\", \"ys of helping the engine \\nbe fast.  \\nIn .NET 6, the interpreter engine had effectively two ways of i\", \"mplementing \\nTryFindNextPossibleStartingPosition : a Boyer -Moore s ubstring search if the pattern b\", \"egan with a \\nstring (potentially case -insensitive) of at least two characters, and a linear scan fo\", \"r a character class \\nknown to be the set of all possible chars that could begin a match. For the lat\", \"ter case, the interpreter \\nhad eight different implementations for matching, based on a combination \", \"of whether \\nRegexOptions.RightToLeft  was set or not, whether the character class required case -ins\", \"ensitive \\ncomparison or not, and whether the character class contained only a single cha racter or m\", \"ore than \\none character. Some of these were more optimized than others, e.g.  a left -to-right, case\", \" -sensitive, \\nsingle -char search would use an IndexOf(char)  to search for the next location, an op\", \"timization \\nadded in .NET 5. However, every time this  operation was performed, the engine would nee\", \"d to \\nrecompute which case it would be. dotnet/runtime#60822  improved this, introducing an internal\", \"  \\n140 CHAPTER 11 | Regex  \\n enum of the strategies used by TryFindNextPossibleStartingPosition  to \", \"find the next opportunity, \\nadding a switch  to TryFindNextPossibleStartingPosition  to quickly jump\", \" to the right strategy, \\nand precomputing which strategy to use when the interpreter was c onstructe\", \"d. This not only made \\nthe interpreter\\u2019s implementation at match time faster, it made it effectively\", \" free (in terms of runtime \\noverhead at match time) to add additional strategies.  \\ndotnet/runtime#6\", \"0888  then added the first additional strategy. The implementation was already \\ncapable of using Ind\", \"exOf(char) , but as mentioned previously in this post, the implementation of \\nIndexOf(ReadOnlySpan<c\", \"har>)  got way better in .NET 7 in many cases, t o the point where it ends up \\nbeing significantly b\", \"etter than Boyer -Moore in all but the most corner of corner cases. So this PR \\nenables a new IndexO\", \"f(ReadOnlySpan<char>)  strategy to be used to search for a prefix string in the \\ncase where the stri\", \"ng is case -sensitive.  \\nprivate static readonly  string s_haystack = new \\nHttpClient ().GetStringAs\", \"ync (\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\", \"\\\"\\\\belementary \\\\b\\\", RegexOptions. Compiled ); \\n \\n[Benchmark]  \\npublic int Count() => _regex. Matches(\", \"s_haystack). Count; \\nMethod  Runtime  Mean  Ratio  \\nCount  .NET 6.0  377.32 us  1.00 \\nCount  .NET 7.\", \"0  55.44 us  0.15 \\ndotnet/runtime#61490  then removed Boyer -Moore entirely. This wasn\\u2019t done in the\", \" previously \\nmentioned PR because of lack of a good way to handle case -insensitive matches. However\", \", this PR \\nalso special -cased ASCII letters to teach the optimizer how to turn an ASCII case -insen\", \"si tive match \\ninto a set of both casings of that letter (excluding the few known to be a problem, l\", \"ike i and k, which \\ncan both be impacted by the employed culture and which might map case -insensiti\", \"vely to more than \\ntwo values). With enough of the common cases  covered, rather than use Boyer -Moo\", \"re to perform a \\ncase-insensitive search, the implementation just uses IndexOfAny(char, char, ...)  \", \"to search for \\nthe starting set, and the vectorization employed by IndexOfAny  ends up outpacing the\", \" old \\nimplementation handi ly in real -world cases. This PR goes further than that, such that it doe\", \"sn\\u2019t just \\ndiscover the \\u201cstarting set,\\u201d but is able to find all of the character classes that could \", \"match a pattern a \\nfixed -offset from the beginning; that then gives the analyzer the a bility to ch\", \"oose the set that\\u2019s \\nexpected to be least common and issue a search for it instead of whatever happe\", \"ns to be at the \\nbeginning. The PR goes even further, too, motivated in large part by the non -backt\", \"racking engine. The \\nnon-backtracking engine\\u2019s p rototype implementation also used IndexOfAny(char, \", \"char, ...)  when \\nit arrived at a starting state and was thus able to quickly skip through input tex\", \"t that wouldn\\u2019t have a \\nchance of pushing it to the next state. We wanted all of the engines to shar\", \"e as muc h logic as \\npossible, in particular around this speed ahead, and so this PR unified the int\", \"erpreter with the non -\\nbacktracking engine to have them share the exact same TryFindNextPossibleSta\", \"rtingPosition  \\nroutine (which the non -backtracking engine just calls at an appropriate place in it\", \"s graph traversal \\nloop). Since the non -backtracking engine was already using IndexOfAny  in this m\", \"anner, initially not \\ndoing so popped as a significant regression on a variety of patterns we measur\", \"e, and this caused us to \\ninvest  in using it everywhere. This PR also introduced the first special \", \"-casing for case -insensitive \\ncomparisons into the compiled engine, e.g.  if we found a set that wa\", \"s [Ee] , rather than emitting a  \\n141 CHAPTER 11 | Regex  \\n check akin to c == 'E' || c == 'e' , we\\u2019\", \"d instead emit a check akin to (c | 0x20) == 'e'  (those \\nfun ASCII tricks discussed earlier coming \", \"into play again).  \\nprivate static readonly  string s_haystack = new \\nHttpClient ().GetStringAsync (\", \"\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"\\\\bel\", \"ementary \\\\b\\\", RegexOptions. Compiled  | \\nRegexOptions. IgnoreCase ); \\n \\n[Benchmark]  \\npublic int Cou\", \"nt() => _regex. Matches(s_haystack). Count; \\nMethod  Runtime  Mean  Ratio  \\nCount  .NET 6.0  499.3 u\", \"s  1.00 \\nCount  .NET 7.0  177.7 us  0.35 \\nThe previous PR started turning IgnoreCase  pattern text i\", \"nto sets, in particular for ASCII, e.g. (?i)a  \\nwould become [Aa] . That PR hacked in the support fo\", \"r ASCII knowing that something more complete \\nwould be coming along, as it did in dotnet/runtime#671\", \"84 . Rather than hardcoding the case -\\ninsensitive sets that just the ASCII characters map to, this \", \"PR essentially hardcodes the sets for every \\npossible char. Once that\\u2019s done, we no longer need to k\", \"now about case -insensitivity at match time \\nand can instead just double -down on efficiently matchi\", \"ng sets, which we already need to be able to \\ndo well. Now, I said it encodes the sets for every pos\", \"sible char; that\\u2019s not entirely true. If it were true, \\nthat would take up a large amount of memory,\", \" and in fact, most of that memory would be wasted \\nbecause the vast majority of characters don\\u2019t par\", \"ticipate in case conversion\\u2026 there are only ~2,000 \\ncharacters that we need to handle. As such, the \", \"implementation emp loys a three -tier table scheme. \\nThe first table has 64 elements, dividing the f\", \"ull range of chars  into 64 groupings; of those 64 groups, \\n54 of them have no characters that parti\", \"cipate in case conversion, so if we hit one of those entries, we \\ncan immediatel y stop the search. \", \"For the remaining 10 that do have at least one character in their \\nrange participating, the characte\", \"r and the value from the first table are used to compute an index into \\nthe second table; there, too\", \", the majority of entries say that noth ing participates in case conversion. \\nIt\\u2019s only if we get a \", \"legitimate hit in the second table does that give us an index into the third table, at \\nwhich locati\", \"on we can find all of the characters considered case -equivalent with the first.  \\ndotnet/runtime#63\", \"477  (and then later improved in dotnet/runtime#66572 ) proceeded to add another \\nsearching strategy\", \", this one inspired by nim-regex\\u2019s literal optimizations . There are a multitude of \\nregexes we trac\", \"k from a performance perspective to ensure we\\u2019re not regressing in common cases \\nand to help guide i\", \"nve stments. One is the set of patterns in mariomka/regex -benchmark  languages \\nregex benchmark. On\", \"e of those is for URIs: \\n(@\\\"[\\\\w]+://[^/ \\\\s?#]+[^\\\\s?#]+(?: \\\\?[^\\\\s#]*)?(?:#[^ \\\\s]*)?\\\" . This pattern d\", \"efies the thus -far \\nenabled strategies for finding a next good location, as it\\u2019s guaranteed to begi\", \"n with a \\u201cword \\ncharacter\\u201d  (\\\\w), which includes ~50,000 of the ~65,000 possible characters; we don\\u2019\", \"t have a good way \\nof vectorizing a search for such a character class. However, this pattern is inte\", \"resting in that it begins \\nwith a loop, and not only that, it\\u2019s an upper -unbounded lo op which our \", \"analysis will determine is \\natomic, because the character guaranteed to immediately follow the loop \", \"is a ':', which is itself not a \\nword character, and thus there\\u2019s nothing the loop could match and g\", \"ive up as part of backtracking \\nthat would mat ch ':'. That all lends itself to a different approach\", \" to vectorization: rather than trying \\nto search for the \\\\w character class, we can instead search f\", \"or the substring \\\"://\\\" , and then once we  \\n142 CHAPTER 11 | Regex  \\n find it, we can match backward\", \"s through as many [\\\\w]s as we can find; in this case, the only \\nconstraint is we need to match at le\", \"ast one. This PR added that strategy, for a literal after an atomic \\nloop, to all of the engines.  \\n\", \"private static readonly  string s_haystack = new \\nHttpClient ().GetStringAsync (\\\"https://www.gutenbe\", \"rg.org/files/1661/1661 -0.txt\\\").Result; \\nprivate Regex _regex = new Regex(@\\\"[\\\\w]+://[^/ \\\\s?#]+[^\\\\s?#\", \"]+(?: \\\\?[^\\\\s#]*)?(?:#[^ \\\\s]*)?\\\", \\nRegexOptions. Compiled ); \\n \\n[Benchmark]  \\npublic bool IsMatch() =\", \"> _regex.IsMatch(s_haystack); // Uri's in Sherlock Holmes? \\\"Most \\nunlikely.\\\"  \\nMethod  Runtime  Mean\", \"  Ratio  \\nIsMatch  .NET 6.0  4,291.77 us  1.000  \\nIsMatch  .NET 7.0  42.40 us  0.010  \\nOf course, as\", \" has been talked about elsewhere, the best optimizations aren\\u2019t ones that make \\nsomething faster but\", \" rather ones that make something entirely unnecessary. That\\u2019s what \\ndotnet/runtime#64177  does, in p\", \"articular in relation to anchors. The .NET regex implementation has \\nlong had optimizations for patt\", \"erns with a starting anchor: if the pattern begins with ^, for example \\n(and RegexOptions.Multiline \", \" wasn\\u2019t specified), the patt ern is rooted to the beginning, meaning it \\ncan\\u2019t possibly match at any\", \" position other than 0; as such, with such an anchor, \\nTryFindNextPossibleStartingPosition  won\\u2019t do\", \" any searching at all. The key here, though, is being \\nable to detect whether the pattern  begins wi\", \"th such an anchor. In some cases, like ^abc$ , that\\u2019s trivial. \\nIn other cases, like ^abc|^def , the\", \" existing analysis had trouble seeing through that alternation to find \\nthe guaranteed starting ^ an\", \"chor. This PR fixes that. It also adds a new strat egy based on discovering \\nthat a pattern has an e\", \"nding anchor like $. If the analysis engine can determine a maximum number of \\ncharacters for any po\", \"ssible match, and it has such an anchor, then it can simply jump to that distance \\nfrom the end of t\", \"he string,  and bypass even looking at anything before then.  \\nprivate static readonly  string s_hay\", \"stack = new \\nHttpClient ().GetStringAsync (\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Resul\", \"t; \\nprivate Regex _regex = new Regex(@\\\"^abc|^def\\\" , RegexOptions. Compiled ); \\n \\n[Benchmark]  \\npubli\", \"c bool IsMatch() => _regex. IsMatch(s_haystack); // Why search _all_ the text?!  \\nMethod  Runtime  M\", \"ean  Ratio  \\nIsMatch  .NET 6.0  867,890.56 ns  1.000  \\nIsMatch  .NET 7.0  33.55 ns  0.000  \\ndotnet/r\", \"untime#67732  is another PR related to improving anchor handling. It\\u2019s always fun when a bug \\nfix or\", \" code simplification refactoring turns into a performance improvement. The PR\\u2019s primary purpose \\nwas\", \" to simplify some complicated code that was computing the set of characters that could possibly \\nsta\", \"rt a match. It turns out that complication was hiding a logic bug which manifested in it missing \\nso\", \"me opportunities to report valid starting chara cter classes, the impact of which is that some \\nsear\", \"ches which could have been vectorized weren\\u2019t. By simplifying the implementation, the bug was \\nfixed\", \", exposing more performance opportunities.   \\n143 CHAPTER 11 | Regex  \\n By this point, the engines a\", \"re able to use IndexOf(ReadOnlySpan <char>)  to find a substring at the \\nbeginning of a pattern. But\", \" sometimes the most valuable substring isn\\u2019t at the beginning, but \\nsomewhere in the middle or even \", \"at the end. As long as it\\u2019s at a fixed -offset from the beginning of the \\npattern, we can search for\", \" it, and then just back -off by the offset to the position we should actually try \\nrunning the match\", \". dotnet/runtime#67907  does exactly that.  \\nprivate static readonly  string s_haystack = new \\nHttpC\", \"lient ().GetStringAsync (\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Result; \\nprivate Regex \", \"_regex = new Regex(@\\\"looking|feeling\\\" , RegexOptions. Compiled ); \\n \\n[Benchmark]  \\npublic int Count(\", \") => _regex. Matches(s_haystack). Count; // will search for \\\"ing\\\"  \\nMethod  Runtime  Mean  Ratio  \\nC\", \"ount  .NET 6.0  444.2 us  1.00 \\nCount  .NET 7.0  122.6 us  0.28 \\nLoops and Backtracking  \\nLoop handl\", \"ing in the compiled and source generated engines has been significantly improved, both \\nwith respect\", \" to processing them faster and with respect to backtracking less.  \\nWith regular greedy loops (e.g. \", \"c*), there are two directions to be concerned about: how quickly can \\nwe consume all the elements th\", \"at match the loop, and how quickly can we give back elements that \\nmight be necessary as pa rt of ba\", \"cktracking for the remainder of the expression to match. And with \\nlazy loops, we\\u2019re primarily conce\", \"rned with backtracking, which is the forward direction (since lazy \\nloops consume as part of backtra\", \"cking rather than giving back as part of backtrack ing). With PRs \\ndotnet/runtime#63428 , dotnet/run\", \"time#68400 , dotne t/runtime#64254 , and dotnet/runtime#73910 , in \\nboth the compiler and source gen\", \"erator we now make full use of effectively all of the variants of \\nIndexOf , IndexOfAny , LastIndexO\", \"f , LastIndexOfAny , IndexOfAnyExcept , and \\nLastIndexOfAnyExcept  in order to speed along these sea\", \"rches. For example, in a pattern like .*abc , \\nthe forward direction of that loop entails consuming \", \"every character until the next newline, which we \\ncan optimize with an IndexOf(' \\\\n'). Then as part \", \"of backtracking, rather than giving up one \\ncharacter at a time, we can LastIndexOf(\\\"abc\\\")  in order\", \" to find the next viable location that could \\npossibly match the remainder of the pattern. Or for ex\", \"ample, in a pattern like [^a-c]*def , the loop \\nwill initially greedily consume everything other tha\", \"n 'a', 'b', or 'c', so we can use \\nIndexOfAnyExcept('a', 'b', 'c')  to find the initial end of the l\", \"oop. And so on. This can yield huge \\nperformance gains, and with the source generator, also makes th\", \"e generated code more idiomatic \\nand easier to understand.  \\nprivate static readonly  string s_hayst\", \"ack = new \\nHttpClient ().GetStringAsync (\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Result;\", \" \\nprivate Regex _regex = new Regex(@\\\"^.*elementary.*$\\\" , RegexOptions. Compiled  | \\nRegexOptions. Mu\", \"ltiline ); \\n \\n[Benchmark]  \\npublic int Count() => _regex. Matches(s_haystack). Count; \\n   \\n144 CHAPT\", \"ER 11 | Regex  \\n Method  Runtime  Mean  Ratio  \\nCount  .NET 6.0  3,369.5 us  1.00 \\nCount  .NET 7.0  \", \"430.2 us  0.13 \\nSometimes optimizations are well -intended but slightly miss the mark. dotnet/runtim\", \"e#63398  fixes \\nsuch an issue with an optimization introduced in .NET 5; the optimization was valuab\", \"le but only  for a \\nsubset of the scenarios it was intended to cover. While TryFindNextPossibleStart\", \"ingPosition \\u2019s \\nprimary raison d\\u2019\\u00eatre is to update the bumpalong position, it\\u2019s also possible for \\nT\", \"ryMatchAtCurrentPosition  to do so. One of the occasions in which it\\u2019ll d o so is when the pattern \\n\", \"begins with an upper -unbounded single -character greedy loop. Since processing starts with the loop\", \" \\nhaving fully consumed everything it could possibly match, subsequent trips through the scan loop \\n\", \"don\\u2019t need to reconsider any starti ng position within that loop; doing so would just be duplicating\", \" \\nwork done in a previous iteration of the scan loop. And as such, TryMatchAtCurrentPosition  can \\nu\", \"pdate the bumpalong position to the end of the loop. The optimization added in .NET 5 was dutif ully\", \" \\ndoing this, and it did so in a way that fully handled atomic loops. But with greedy loops, the upd\", \"ated \\nposition was getting updated every time we backtracked, meaning it started going backwards, wh\", \"en it \\nshould have remained at the end of the loop. Thi s PR fixes that, yielding significant saving\", \"s in the \\nadditional covered cases.  \\nprivate static readonly  string s_haystack = new \\nHttpClient (\", \").GetStringAsync (\\\"https://www.gutenberg.org/files/1661/1661 -0.txt\\\").Result; \\nprivate Regex _regex \", \"= new Regex(@\\\".*stephen\\\" , RegexOptions. Compiled ); \\n \\n[Benchmark]  \\npublic int Count() => _regex. \", \"Matches(s_haystack). Count; \\nMethod  Runtime  Mean  Ratio  \\nCount  .NET 6.0  103,962.8 us  1.000  \\nC\", \"ount  .NET 7.0  336.9 us  0.003  \\nAs mentioned elsewhere, the best optimizations are those that make\", \" work entirely vanish rather than \\njust making work faster. dotnet/runtime#68989 , dotnet/runtime#63\", \"299 , and dotnet/runtime#63518  \\ndo exactly that by improving the pattern analyzers ability to find \", \"and eliminate more unnecessary \\nbacktracking, a process the analyzer refers to as \\u201cauto -atomicity\\u201d \", \"(automatically making loops atomic). \\nFor example, in the pattern a*?b , we have a lazy loop of 'a's\", \" followed by a b. That loop can only \\nmatch 'a's, and 'a' doesn\\u2019t overlap with 'b'. So let\\u2019s say the\", \" input is \\\"aaaaaaaab\\\" . The loop is lazy, \\nso we\\u2019ll start out by trying to match just 'b'. It won\\u2019t \", \"match, so we\\u2019ll backtrack into the lazy loop and \\ntry to match \\\"ab\\\" . It won\\u2019t match so we\\u2019ll backtr\", \"ack into the lazy loop and try to match \\\"aab\\\". And so \\non, until we\\u2019ve consumed all the 'a's such th\", \"at the rest of the pattern has a chance of matching the \\nrest of the input. That\\u2019s exactly what an a\", \"tomic greedy loop does, so we can transform the pattern \\na*?b  into (?>a*)b , which is much more eff\", \"ici ently processed. In fact, we can see exactly how it\\u2019s \\nprocessed just by looking at the source -\", \"generated implementation of this pattern:  \\nprivate bool TryMatchAtCurrentPosition (ReadOnlySpan< ch\", \"ar> inputSpan)  \\n{ \\n    int pos = base.runtextpos ; \\n    int matchStart  = pos; \\n    ReadOnlySpan< c\", \"har> slice = inputSpan. Slice(pos);  \\n145 CHAPTER 11 | Regex  \\n  \\n    // Match 'a' atomically any nu\", \"mber of times.  \\n    { \\n        int iteration = slice. IndexOfAnyExcept ('a'); \\n        if (iteratio\", \"n < 0) \\n        { \\n            iteration = slice. Length; \\n        } \\n \\n        slice = slice. Slice\", \"(iteration);  \\n        pos += iteration;  \\n    } \\n \\n    // Advance the next matching position.  \\n   \", \" if (base.runtextpos  < pos) \\n    { \\n        base.runtextpos  = pos; \\n    } \\n \\n    // Match 'b'.  \\n \", \"   if (slice.IsEmpty || slice[ 0] != 'b') \\n    { \\n        return false; // The input didn't match.  \", \"\\n    } \\n \\n    // The input matched.  \\n    pos++; \\n    base.runtextpos  = pos; \\n    base.Capture(0, m\", \"atchStart, pos);  \\n    return true; \\n} \\n(Note that those comments aren\\u2019t ones I added for this blog \", \"post; the source g enerator itself is \\nemitting commented code.)  \\nWhen a regular expression is inpu\", \"t, it\\u2019s parsed into a tree -based form. The \\u201cauto -atomicity\\u201d analysis \\ndiscussed in the previous PR\", \" is one form of analysis that walks around this tree looking for \\nopportunities to  transform portio\", \"ns of the tree into a behaviorally equivalent alternative that will be \\nmore efficient to execute. S\", \"everal PRs introduced additional such transformations. \\ndotnet/runtime#63695 , for example, looks fo\", \"r \\u201cempty\\u201d and \\u201cnothing\\u201d nodes in the tree that can be \\nremoved. An \\u201cempty\\u201d node is something that ma\", \"tches the empty string, so for example in the \\nalternation abc|def||ghi , the third branch of that a\", \"lternation is em pty. A \\u201cnothing\\u201d node is \\nsomething that can\\u2019t match anything, so for example in th\", \"e concatenation abc(?!)def , that (?!)  in \\nmiddle is a negative lookahead around an empty, which ca\", \"n\\u2019t possibly match anything, as it\\u2019s saying \\nthe expression won\\u2019t match if it\\u2019 s followed by an empt\", \"y string, which everything is. These constructs \\noften arise as a result of other transformations ra\", \"ther than being something a developer typically \\nwrites by hand, just as there are optimizations in \", \"the JIT where you might look at them and say \\u201cwhy \\non earth is that something a developer would writ\", \"e\\u201d but it ends up being a valuable optimization \\nanyways because inlining might transform perfectly \", \"reasonable code into something that matches the \\ntarget pattern. Thus, for example, if you did h ave\", \" abc(?!)def , since that concatenation requires the \\n(?!)  to match in order to be successful, the c\", \"oncatenation itself can simply be replaced by a \\n\\u201cnothing.\\u201d You can see this easily if you try this \", \"with the source generator:  \\n[GeneratedRegex (@\\\"abc(?!)def\\\" )]  \\n146 CHAPTER 11 | Regex  \\n as it wil\", \"l produce a Scan  method like this (comment and all):  \\nprotected  override  void Scan(ReadOnlySpan<\", \" char> inputSpan)  \\n{ \\n    // The pattern never matches anything.  \\n} \\nAnother set of transformation\", \"s was introduced in dotnet/runtime#59903 , specifically around \\nalternations (which beyond loops are\", \" the other source of backtracking). This introduced two main \\noptimizations. First, it enables rewri\", \"ting alternations into alternations of alternations, e.g.  transforming \\naxy|axz|bxy|bxz  into ax(?:\", \"y|z)|bx(?:y|z) , which is then further reduced into ax[yz]|bx[yz] . This \\ncan enable the backtrackin\", \"g engines to more efficiently process alternations due to fewer branches \\nand thus less potential ba\", \"ck tracking. The PR also enabled limited reordering of branches in an \\nalternation. Generally branch\", \"es can\\u2019t be reordered, as the order can impact exactly what\\u2019s matched \\nand what\\u2019s captured, but if t\", \"he engine can prove there\\u2019s no effect on ordering, then it\\u2019s free to \\nreorder. One key place that or\", \"dering isn\\u2019t a factor is if the alternation is atomic due to it being \\nwrapped in an atomic group (a\", \"nd the auto -atomicity analysis will add such groups implicitly in some \\nsituations). Reordering the\", \" branches then enable s other optimizations, like the one previously \\nmentioned from this PR. And th\", \"en once those optimizations have kicked in, if we\\u2019re left with an atomic \\nalternation where every br\", \"anch begins with a different letter, than can enable further optimizations in \\nterms of how the alte\", \"rnation is lowered; this PR teaches the source generator how to emit a switch  \\nstatement, which lea\", \"ds to both more efficient and more readable code. (The detection of whether \\nnodes in the tree are a\", \"tomic, and other such properties such as  performing captures or introducing \\nbacktracking, turned o\", \"ut to be valuable enough that dotnet/runtime#65734  added dedicated support \\nfor this.)  \\nCode gener\", \"ation  \\nThe .NET 7 regex implementation has no fewer than four engines: the interpreter (what you ge\", \"t if you \\ndon\\u2019t explicitly choose another engine), the compiler (what you get with RegexOptions.Comp\", \"iled ), \\nthe non -backtracking engine (what you get with RegexOptions.NonBacktracking ), and the sou\", \"r ce \\ngenerator (what you get with [GeneratedRegex(...)] ). The interpreter and the non -backtrackin\", \"g \\nengine don\\u2019t require any kind of code generation; they\\u2019re both based on creating in -memory data \", \"\\nstructures that represent how to match input against the patter n. The other two, though, both \\ngen\", \"erate code specific to the pattern; the generated code is code attempting to mimick what you \\nmight \", \"write if you weren\\u2019t using Regex  at all and were instead writing code to perform a similar match \\nd\", \"irectly. The source gener ator spits out C# that\\u2019s compiled directly into your assembly, and the \\nco\", \"mpiler spits out IL at run -time via reflection emit. The fact that these are generating code specif\", \"ic to \\nthe pattern means there\\u2019s a ton of opportunity to optimize.  \\ndotnet/runtime#59186  provided \", \"the initial implementation of the source generator. This was a direct \\nport of the compiler, effecti\", \"vely a line -by-line translation of IL into C#; the result is C# a kin to what \\nyou\\u2019d get if you wer\", \"e to run the generated IL through a decompiler like ILSpy . A bunch of PRs then \\nproceeded to iterat\", \"e on and tweak the source generator, but the biggest improvements came  from \\nchanges that changed t\", \"he compiler and the source generator together. Prior to .NET 5, the compiler \\nspit out IL that was v\", \"ery similar to what the interpreter would do. The interpreter is handed a series of \\ninstructions th\", \"at it walks through one by one  and interprets, and the compiler, handed that same  \\n147 CHAPTER 11 \", \"| Regex  \\n series of instructions, would just emit the IL for processing each. It had some opportuni\", \"ty for being \\nmore efficient, e.g.  loop unrolling, but a lot of value was left on the table. In .NE\", \"T 5, an alternate  path \\nwas added in support of patterns without backtracking; this code path was b\", \"ased on being handed \\nthe parsed node tree rather than being based on the series of instructions, an\", \"d that higher -level form \\nenabled the compiler to derive more insights about the pattern that it co\", \"uld then use to generate \\nmore efficient code. In .NET 7, support for all regex features were increm\", \"entally added in, over the \\ncourse of multiple PRs, in particular dotnet /runtime#60385  for backtra\", \"cking single char loops, \\ndotnet/runtime#61698  for backtracking single char lazy loops, dotnet/runt\", \"ime# 61784  for other \\nbacktracking lazy loops, and dotnet/runtime#61906  for other backtracking loo\", \"ps as well as back \\nreferences and conditionals. At that point, the only features missing were suppo\", \"r t for \\nRegexOptions.RightToLeft  and lookbehinds (which are implemented in terms of right -to-left\", \"), and \\nwe decided based on relatively little use of these features that we needn\\u2019t keep around the \", \"old \\ncompiler code just to enable them. So, dotnet/runtime#62318  deleted the old implementation. Bu\", \"t, \\neven though these features are relatively rare, it\\u2019s a lot easier to tell a story that \\u201call patt\", \"erns are \\nsupported\\u201d than one that requires special callou ts and exceptions, so dotnet/runtime#6612\", \"7  and \\ndotnet/runtime#66280  added full lookbehind and RightToLeft  support such that ther e were n\", \"o \\ntakebacks. At this point, both the compiler and source generator now supported everything the \\nco\", \"mpiler previously did, but now with the more modernized code generation. This code generation is \\nin\", \" turn what enables many of the optimizations previo usly discussed, e.g.  it provides the opportunit\", \"y \\nto use APIs like LastIndexOf  as part of backtracking, which would have been near impossible with\", \" the \\nprevious approach.  \\nOne of the great things about the source generator emitting idiomatic C# \", \"is it makes it  easy to iterate. \\nEvery time you put in a pattern and see what the generator emits, \", \"it\\u2019s like being asked to do a code \\nreview of someone else\\u2019s code, and you very frequently see somet\", \"hing \\u201cnew\\u201d worthy of comment, or \\nin this case, improving the generator to  address the issue. And s\", \"o a bunch of PRs were originated \\nbased on reviewing what the generator emitted and then tweaking th\", \"e generator to do better (and \\nsince the compiler was effectively entirely rewritten along with the \", \"source generator, they maintain t he \\nsame structure, and it\\u2019s easy to port improvements from one to\", \" the other). For example, \\ndotnet/runtime#68846  and dotnet/runti me#69198  tweaked how some compari\", \"sons were being \\nperformed in order for them to convey enough information to the JIT that it can eli\", \"minate some \\nsubsequent bounds checking, and dotnet/runtime#6 8490  recognized a variety of conditio\", \"ns being \\nemitted that could never happen in some situations observable statically and was able to e\", \"lide all that \\ncode gen. It also became obvious that some patterns didn\\u2019t need the full expressivity\", \" of the scan loop, \\nand a more compact and customized Scan  implementation could be used. dotnet/run\", \"time#68560  \\ndoes that, such that, for example, a simple pattern like hello  won\\u2019t emit a loop at al\", \"l and will instead  \\nhave a simpler Scan  implementation like:  \\nprotected  override  void Scan(Read\", \"OnlySpan< char> inputSpan)  \\n{ \\n    if (TryFindNextPossibleStartingPosition (inputSpan))  \\n    { \\n  \", \"      // The search in TryFindNextPossibleStartingPosition performed the entire match.  \\n        int\", \" start = base.runtextpos ; \\n        int end = base.runtextpos  = start + 5; \\n        base.Capture(0,\", \" start, end);  \\n    } \\n}  \\n148 CHAPTER 11 | Regex  \\n The compiler and source generator were also upd\", \"ated to take adv antage of newer features. \\ndotnet/runtime#63277 , for example, teaches the source g\", \"enerator how to determine if unsafe  code is \\nallowed, and if it is, it emits a [SkipLocalsInit]  fo\", \"r the core log ic; the matching routine can result in \\nmany locals being emitted, and SkipLocalsInit\", \"  can make it cheaper to call the function due to less \\nzero\\u2019ing being necessary. Then there\\u2019s the i\", \"ssue of where the code is generated; we want helper \\nfunctions (like the \\\\w IsWordChar  helper intro\", \"duced in dotnet/runtime#62620 ) that can be shared \\namongst multiple generated regexes, and we want \", \"to be able to share the exact same regex \\nimplementation if the same pa ttern/options/timeout combin\", \"ation are used in multiple places in the \\nsame assembly ( dotnet/runtime#66747 ), but doing so then \", \"exposes this implementation detail to user \\ncode in the same assembl y. To still be able to get the \", \"perf benefits of such code sharing while \\navoiding the resulting complications, dotnet/runtime#66432\", \"  and then dotnet/runtime#71765  teaches \\nthe source generator to use the new file-local types  feat\", \"ures in C# 11 ( dotnet/roslyn#62375 ). \\nOne last  and interesting code generation aspect is in optim\", \"izations around character class matching. \\nMatching character classes, whether ones explicitly writt\", \"en by the developer or ones implicitly created \\nby the engine (e.g.  as part of finding the set of a\", \"ll chara cters that can begin the expression), can be \\none of the more time -consuming aspects of ma\", \"tching; if you imagine having to evaluate this logic for \\nevery character in the input, then how man\", \"y instructions needs to be executed as part of matching a \\ncharacter class directly correlates to ho\", \"w long it takes to perform the overall match. We thus spend \\nsome time trying to ensure we generate \", \"optimal matching code for as many categories of character \\nclasses as possible. dotnet/runtime#67365\", \" , for example, improved a bunch of cases found to be \\ncommon in real -world use, like specially -re\", \"cognizing sets like [\\\\d\\\\D], [\\\\s\\\\S], and [\\\\w\\\\W] as meaning \\n\\u201cmatch anything\\u201d (just as is the case for\", \" . in RegexOptions.Singl eline  mode), in which case existing \\noptimizations around the handling of \", \"\\u201cmatch anything\\u201d can kick in.  \\nprivate static readonly  string s_haystack = new string('a', 1_000_0\", \"00); \\nprivate Regex _regex = new Regex(@\\\"([\\\\s\\\\S]*)\\\", RegexOptions. Compiled ); \\n \\n[Benchmar k] \\npubl\", \"ic Match Match() => _regex. Match(s_haystack);  \\nMethod  Runtime  Mean  Ratio  \\nMatch  .NET 6.0  1,9\", \"34,393.69 ns  1.000  \\nMatch  .NET 7.0  91.80 ns  0.000  \\nOr dotnet/runtime#68924 , which taught the \", \"source generator how to use all of the new char  ASCII \\nhelper methods, like char.IsAsciiLetterOrDig\", \"it , as well as some existing helpers it didn\\u2019t yet know \\nabout, in the generated output; for exampl\", \"e this:  \\n[GeneratedRegex (@\\\"[A-Za-z][A-Z][a-z][0-9][A-Za-z0-9][0-9A-F][0-9a-f][0-9A-Fa-\\nf]\\\\p{Cc}\\\\p{\", \"L}[\\\\p{L}\\\\d]\\\\p{Ll}\\\\p{Lu}\\\\p{N}\\\\p{P}\\\\p{Z}\\\\p{S}\\\")] \\nnow produces this in the core matching logic emitted\", \" by the source gener ator: \\nif ((uint)slice.Length < 17 || \\n    !char.IsAsciiLetter (slice[0]) || //\", \" Match a character in the set [A -Za-z]. \\n    !char.IsAsciiLetterUpper (slice[1]) || // Match a char\", \"acter in the set [A -Z]. \\n    !char.IsAsciiLetterLower (slice[2]) || // Match a character in the set\", \" [a -z]. \\n    !char.IsAsciiDigit (slice[3]) || // Match '0' through '9'.  \\n    !char.IsAsciiLetterOr\", \"Digit (slice[4]) || // Match a character in the set [0 -9A-Za-z].  \\n149 CHAPTER 11 | Regex  \\n     !c\", \"har.IsAsciiHexDigitUpper (slice[5]) || // Match a character in the set [ 0-9A-F]. \\n    !char.IsAscii\", \"HexDigitLower (slice[6]) || // Match a character in the set [0 -9a-f]. \\n    !char.IsAsciiHexDigit (s\", \"lice[7]) || // Match a character in the set [0 -9A-Fa-f]. \\n    !char.IsControl (slice[8]) || // Matc\", \"h a character in the set [ \\\\p{Cc}]. \\n    !char.IsLetter (slice[9]) || // Match a character in the se\", \"t [ \\\\p{L}]. \\n    !char.IsLetterOrDigit (slice[10]) || // Match a character in the set [ \\\\p{L}\\\\d]. \\n \", \"   !char.IsLower(slice[11]) || // Match a character in the set [ \\\\p{Ll}]. \\n    !char.IsUpper(slice[1\", \"2]) || // Match a character in the set [ \\\\p{Lu}]. \\n    !char.IsNumber (slice[13]) || // Match a char\", \"acter in the set [ \\\\p{N}]. \\n    !char.IsPunctuation (slice[14]) || // Match a character in the set [\", \" \\\\p{P}]. \\n    !char.IsSeparator (slice[15]) || // Match a  character in the set [ \\\\p{Z}]. \\n    !char\", \".IsSymbol (slice[16])) // Match a character in the set [ \\\\p{S}]. \\n{ \\n    return false; // The input \", \"didn't match.  \\n} \\nOther changes impacting character class code generation included dotnet/runtime#7\", \"2328 , which \\nimproved the handling of character classes that involve character class subtraction; \\n\", \"dotnet/runtime#72317  from [@teo -tsirpanis](https://git hub.com/teo -tsirpanis), which enabled \\nadd\", \"itional cases where the generator could avoid emitting a bitmap lookup; dotnet/runtime#67133 , \\nwhic\", \"h added a tighter bounds check when it does emit such  a lookup table; and \\ndotnet/runtime#61562 , w\", \"hich enables better normalization of character classes in the engine\\u2019s \\ninternal representation, thu\", \"s leading to downstream optimizations better reco gnizing more character \\nclasses.  \\nFinally, with a\", \"ll of these improvements to Regex , a multitude of PRs fixed up regexes being used \\nacross dotnet/ru\", \"ntime , in various ways. dotnet/runtime#66142 , dotnet/runtime#66179  from \\n[@Clockwork -Muse](https\", \"://github.com/Clockwork -Muse), and dotnet/runtime#62325  from \\n[@Clockwork -Muse](https://github.co\", \"m/Clockwork -Muse) all converted Regex  usage over to using \\n[GeneratedRegex(...)] . dotnet/run time\", \"#68961  optimized other usage in various ways. The PR \\nreplaced several regex.Matches(...).Success  \", \"calls with IsMatch(...) , as using IsMatch  has less \\noverhead due to not needing to construct a Mat\", \"ch  instance and due to being able to avoid more \\nexpensive phases in the non -backtracking engine t\", \"o compute exact bounds and capture information. \\nThe PR also replaced some Match /Match.MoveNext  us\", \"age with EnumerateMatches , in order to avoid \\nneeding Match  object allocations. The PR also entire\", \"ly removed at least one  regex usage that was just \\nas doable as a cheaper IndexOf . dotnet/runtime#\", \"68766  also removed a use of \\nRegexOptions.CultureInvariant . Specifying CultureInvariant  changes t\", \"he behavior of \\nIgnoreCase by alternating which casing tables are employed; if IgnoreCase  isn\\u2019t spe\", \"cified and there\\u2019s \\nno inline case -insensitivity options ( (?i) ), then specifying CultureInvariant\", \"  is a nop. But a \\npotentially expensive one. For any code that\\u2019s size conscious, the Regex  impleme\", \"ntation is structured \\nin a way as to try to make it as trimmmer friendly as possible. If you only e\", \"ver do new \\nRegex(pattern) , we\\u2019d really like to be able to statically determine that the compiler a\", \"nd non -\\nbacktracking implementations aren\\u2019t nee ded such that the trimmer can remove it without hav\", \"ing a \\nvisible and meaningful negative impact. However, the trimmer analysis isn\\u2019t yet sophisticated\", \" enough \\nto see exactly which options are used and only keep the additional engines linked in if \\nRe\", \"gexOptio ns.Compiled  or RegexOptions.NonBacktracking  is used; instead, any use of an overload \\ntha\", \"t takes a RegexOptions  will result in that code continuing to be referenced. By getting rid of the \", \"\\noptions, we increase the chances that no code in the app is using thi s constructor, which would in\", \" turn \\nenable this constructor, the compiler, and the non -backtracking implementation to be trimmed\", \" away.   \\n150 CHAPTER 12 | Collections  \\n CHAPTER  12 \\nCollections  \\nSystem.Collections  hasn\\u2019t seen\", \" as much investment in .NET 7 as it has in previous releases, though \\nmany of the lower -level impro\", \"vements have a trickle -up effect into collections as well. For example, \\nDictionary<,> \\u2019s code hasn\", \"\\u2019t  changed between .NET 6 and .NET 7, but even so, this benchmark \\nfocused on dictionary lookups:  \", \"\\nprivate Dictionary< int, int> _dictionary = Enumerable. Range(0, 10_000).ToDictionary (i => \\ni); \\n \", \"\\n[Benchmark]  \\npublic int Sum() \\n{ \\n    Dictionary< int, int> dictionary = _dictionary;  \\n    int su\", \"m = 0; \\n \\n    for (int i = 0; i < 10_000; i++) \\n    { \\n        if (dictionary. TryGetValue (i, out i\", \"nt value)) \\n        { \\n            sum += value;  \\n        } \\n    } \\n \\n    return sum; \\n} \\nshows a m\", \"easurable improvement in throughput  between .NET 6 and .NET 7:  \\nMethod  Runtime  Mean  Ratio  Code\", \" Size  \\nSum .NET 6.0  51.18 us  1.00 431 B  \\nSum .NET 7.0  43.44 us  0.85 413 B  \\nBeyond that, there\", \" have been explicit improvements elsewhere in collections. ImmutableArray<T> , for \\nexample. As a re\", \"minder, ImmutableArray<T>  is a very thin struct -based wrapper around a T[] that \\nhides the mutabil\", \"ity of T[]; unless you\\u2019re using unsafe code , neither the length nor the shallow \\ncontents of an Imm\", \"utableArray<T>  will ever change (by shallow, I mean the data stored directly in \\nthat array can\\u2019t b\", \"e mutated, but if there are mutable reference types stored in the array, those \\ninstances themselves\", \" may  still have their data mutated). As a result, ImmutableArray<T>  also has an \\nassociated \\u201cbuild\", \"er\\u201d type, which does support mutation: you create the builder, populate it, and then \\ntransfer that \", \"contents to an ImmutableArray<T>  which is frozen forevermore. In  \\ndotnet/runtime#70850  from [@grb\", \"ell -ms](https://github.com/grbell -ms), the builder\\u2019s Sort  method is \\nchanged to use a span, which\", \" in turn avoids an IComparer<T>  allocation and a Comparison<T>   \\n151 CHAPTER 12 | Collections  \\n a\", \"llocation, while also speeding up the sort itself by removing several layers of indirection from eve\", \"ry \\ncomparison.  \\nprivate ImmutableArray< int>.Builder _builder = ImmutableArray. CreateBuilder <int\", \">(); \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    _builder. AddRange (Enumerable. Range(0, 1_000))\", \"; \\n} \\n \\n[Benchmark]  \\npublic void Sort() \\n{ \\n    _builder. Sort((left, right) => right. CompareTo (l\", \"eft));  \\n    _builder. Sort((left, right) => left. CompareTo (right));  \\n} \\nMethod  Runtime  Mean  R\", \"atio  \\nSort .NET 6.0  86.28 us  1.00 \\nSort .NET 7.0  67.17 us  0.78 \\ndotnet/runtime#61196  from [@la\", \"teapexearlyspeed](https://github.com/lateapexearlyspeed) brings \\nImmutableArray<T>  into the span -b\", \"ased era, adding around 10 new methods to ImmutableArray<T>  \\nthat interoperate with Span<T>  and Re\", \"adOnlySpan<T> . These are valuable from a performance  \\nperspective because it means if you have you\", \"r data in a span, you can get it into an \\nImmutableArray<T>  without incurring additional allocation\", \"s beyond the one the ImmutableArray<T>  \\nitself will create. dotnet/runtime#66550  from [@RaymondHuy\", \"](https://github.com/RaymondHuy) also \\nadds a bunch of new methods to the immutable collection build\", \"ers, which provide efficient \\nimplementations for operations like replacing elements and adding, ins\", \"erting, an d removing ranges.  \\nSortedSet<T>  also saw some improvements in .NET 7. For example, Sor\", \"tedSet<T>  internally uses a \\nred/black tree  as its internal data structure, and it uses a Log2  op\", \"er ation to determine the maximum \\ndepth the tree could be for a given node count. Previously, that \", \"operation was implemented as a loop. \\nBut thanks to dotnet/runtime#58793  from [@teo -tsirpanis](ht \", \"tps://github.com/teo -tsirpanis) that \\nimplementation is now simply a call to BitOperations.Log2 , w\", \"hich is in turn implemented trivially in \\nterms of one of multiple hardware intrinsics if they\\u2019re su\", \"pported (e.g. Lzcnt.LeadingZeroCount , \\nArmBase.LeadingZeroCou nt, X86Base.BitScanReverse ). And dot\", \"net/runtime#56561  from \\n[@johnthcall](https://github.com/johnthcall) improves SortedSet<T>  copy pe\", \"rformance by \\nstreamlining how the iteration through the nodes in the tree is handled.  \\n[Params(100\", \")] \\npublic int Count { get; set; } \\n \\nprivate static SortedSet< string> _set; \\n \\n[GlobalSetup]  \\npub\", \"lic void GlobalSetup () \\n{ \\n    _set = new SortedSet< string>(StringComparer. OrdinalIgnoreCase ); \\n\", \"    for (int i = 0; i < Count; i++)  \\n    { \\n        _set.Add(Guid.NewGuid().ToString ());  \\n152 CHA\", \"PTER 12 | Collections  \\n     } \\n} \\n \\n[Benchmark]  \\npublic SortedSet< string> SortedSetCopy () \\n{ \\n  \", \"  return new SortedSet< string>(_set, StringComparer. OrdinalIgnoreCase ); \\n} \\nMethod  Runtime  Mean\", \"  Ratio  \\nSortedSetCopy  .NET 6.0  2.397 us  1.00 \\nSortedSetCopy  .NET 7.0  2.090 us  0.87 \\nOne last\", \" PR to look at in collections: dotnet/runtime#67923 . ConditionalWeakTable<TKey, TValue>  \\nis a coll\", \"ection most developers haven\\u2019t used, but when you need it, you need it. It\\u2019s used primarily for \\ntwo\", \" purposes: to associate addit ional state with some object, and to maintain a weak collection of \\nob\", \"jects. Essentially, it\\u2019s a thread -safe dictionary that doesn\\u2019t maintain strong references to anythi\", \"ng it \\nstores but ensures that the value associated with a key will remain rooted as long  as the as\", \"sociated \\nkey is rooted. It exposes many of the same APIs as ConcurrentDictionary<,> , but for addin\", \"g items \\nto the collection, it\\u2019s historically only had an Add method. That means if the design of th\", \"e consuming \\ncode entailed trying to use the colle ction as a set, where duplicates were common, it \", \"would also be \\ncommon to experience exceptions when trying to Add an item that already existed in th\", \"e collection. \\nNow in .NET 7, it has a TryAdd  method, which enables such usage without potentially \", \"incurring the \\ncosts of such exceptions (and without needing to add try/catch  blocks to defend agai\", \"nst them).   \\n153 CHAPTER 13 | LINQ  \\n CHAPTER  13 \\nLINQ  \\nLet\\u2019s move on to Language -Integrated Que\", \"ry (LINQ). LINQ is a productivity feature that practically \\nevery .NET developer uses. It enables ot\", \"herwise complicated operations to be trivially expressed, \\nwhether via language -integrated query co\", \"mprehension syntax or via direct use of methods on \\nSystem.Linq.Enumerable . That productivity and e\", \"xpressivity, however, comes at a bit of an overhead \\ncost. In the vast majority of situations, those\", \" costs (such as delegate and closure allocations, delegate \\ninvocations, use of  interface methods o\", \"n arbitrary enumerables vs direct access to indexers and \\nLength /Count  properties, etc.) don\\u2019t hav\", \"e a significant impact, but for really hot paths, they can and \\ndo show up in a meaningful way. This\", \" leads some folks to declare LINQ as bei ng broadly off -limits in \\ntheir codebases. From my perspec\", \"tive, that\\u2019s misguided; LINQ is extremely useful and has its place. In \\n.NET itself, we use LINQ, we\", \"\\u2019re just practical and thoughtful about where, avoiding it in code paths \\nwe\\u2019ve optimized to be ligh\", \"t weight and fast due to expectations that such code paths could matter to \\nconsumers. And as such, \", \"while LINQ itself may not perform as fast as a hand -rolled solution, we still \\ncare a lot about the\", \" performance of LINQ\\u2019s implementation, so that it can be used  in more and more \\nplaces, and so that\", \" where it\\u2019s used there\\u2019s as little overhead as possible. There are also differences \\nbetween operati\", \"ons in LINQ; with over 200 overloads providing various kinds of functionality, some of \\nthese overlo\", \"ads benefit from more  performance tuning than do others, based on their expected \\nusage.  \\ndotnet/r\", \"untime#64470  is the result of analyzing various real -world code bases for use of \\nEnumerable.Min  \", \"and Enumerable.Max , and seeing that it\\u2019s very common to use these with arrays, \\noften ones that are\", \" quite large. This PR updates the Min<T>(IEnumerable<T>)  and \\nMax<T>(IEnumerable<T>)  overloads whe\", \"n the input is an int[]  or long[]  to vectorize the \\nprocessing, using Vector<T> . The net effect o\", \"f this is significantly faster execution time for larger \\narrays, but still improved performance eve\", \"n for short arrays (because the implementation is now able \\nto access the array directly rather than\", \" going through the enumerable, leading to le ss allocation and \\ninterface dispatch and more applicab\", \"le optimizations like inlining).  \\n[Params(4, 1024)] \\npublic int Length { get; set; } \\n \\nprivate IEn\", \"umerable< int> _source;  \\n \\n[GlobalSetup]  \\npublic void Setup() => _source = Enumerable. Range(1, Le\", \"ngth). ToArray(); \\n \\n[Benchmark]  \\npublic int Min() => _source. Min(); \\n \\n[Benchmark]  \\npublic int M\", \"ax() => _source. Max();  \\n154 CHAPTER 13 | LINQ  \\n Method  Runtime  Length  Mean  Ratio  Allocated  \", \"Alloc Ratio  \\nMin .NET 6.0  4 26.167 ns  1.00 32 B 1.00 \\nMin .NET 7.0  4 4.788 ns  0.18 - 0.00 \\n    \", \"   \\nMax .NET 6.0  4 25.236 ns  1.00 32 B 1.00 \\nMax .NET 7.0  4 4.234 ns  0.17 - 0.00 \\n       \\nMin .N\", \"ET 6.0  1024  3,987.102 ns  1.00 32 B 1.00 \\nMin .NET 7.0  1024  101.830 ns  0.03 - 0.00 \\n       \\nMax\", \" .NET 6.0  1024  3,798.069 ns  1.00 32 B 1.00 \\nMax .NET 7.0  1024  100.279 ns  0.03 - 0.00 \\nOne of t\", \"he more interesting aspects of the PR, however, is one line that\\u2019s meant to help with the non -\\narra\", \"y cases. In performance optimization, and in particular when adding \\u201cfast paths\\u201d to better handle \\nc\", \"ertain cases, there\\u2019s almos t always a winner and a loser: the winner is the case the optimization i\", \"s \\nintended to help, and the loser is every other case that\\u2019s penalized by whatever checks are neces\", \"sary \\nto determine whether to take the improved path. An optimization that special -cases arrays mig\", \"ht \\nnormally look like:  \\nif (source is int[] array)  \\n{ \\n    ProcessArray (array);  \\n} \\nelse \\n{ \\n  \", \"  ProcessEnumerable (source);  \\n} \\nHowever, if you look at the PR, you\\u2019ll see the if condition is ac\", \"tually:  \\nif (source. GetType() == typeof(int[])) \\nHow come? Well at this point in the code flow, we\", \" know that source isn\\u2019t null, so we don\\u2019t need the \\nextra null check that is will bring. However, th\", \"at\\u2019s minor compared to the real impact here, that of \\nsupport for array covariance. It might surpris\", \"e you to learn that there are types beyond int[]  that will \\nsatisfy a source is int  check\\u2026 try run\", \"ning Console.WriteLine((object)new uint[42] is \\nint[]); , and you\\u2019ll find it prints out True . (This\", \" is also a rare case where the .NET runtime and C# the \\nlanguage disagre e on aspects of the type sy\", \"stem. If you change that \\nConsole.WriteLine((object)new uint[42] is int[]);  to instead be Console.W\", \"riteLine(new \\nuint[42] is int[]); , i.e. remove the (object)  cast, you\\u2019ll find it starts printing o\", \"ut False  instead of \\nTrue . That\\u2019s b ecause the C# compiler believes it\\u2019s impossible for a uint[]  \", \"to ever be an int[] , and \\nthus optimizes the check away entirely to be a constant false .) Thus the\", \" runtime is having to do more \\nwork as part of the type check than just a simple comparison against \", \" the known type identity of  \\n155 CHAPTER 13 | LINQ  \\n int[] . We can see this by looking at the ass\", \"embly generated for these two methods (the latter \\nassumes we\\u2019ve already null -checked the input, wh\", \"ich is the case in these LINQ methods):  \\npublic IEnumerable< object> Inputs { get; } = new[] { new \", \"object() }; \\n \\n[Benchmark]  \\n[ArgumentsSource (nameof(Inputs))]  \\npublic bool M1(object o) => o is i\", \"nt[]; \\n \\n[Benchmark]  \\n[ArgumentsSource (nameof(Inputs))]  \\npublic bool M2(object o) => o. GetType()\", \" == typeof(int[]); \\nThis results in:  \\n; Program.M1(System.Object)  \\n       sub       rsp,28  \\n     \", \"  mov       rcx,offset MT_System.Int32[]  \\n       call      qword ptr \\n[System.Runtime.CompilerServi\", \"ces.CastHelpers.IsInstanceOfAny(Void*, System.Object)]  \\n       test      rax,rax  \\n       setne    \", \" al  \\n       movzx     eax,al  \\n       add       rsp,28  \\n       ret \\n; Total bytes of code 34  \\n \\n \", \"\\n; Program.M2(System.Object)  \\n       mov       rax,offset MT_System.Int32[]  \\n       cmp       [rdx\", \"],rax  \\n       sete      al  \\n       movzx     eax,al  \\n       ret \\n; Total bytes of c ode 20 \\nNote \", \"the former involves a method call to the JIT\\u2019s CastHelpers.IsInstanceOfAny  helper method, \\nand that\", \" it\\u2019s not inlined. That in turn impacts performance:  \\nprivate IEnumerable< int> _source = ( int[])(\", \"object)new uint[42]; \\n \\n[Benchmark (Baseline = true)] \\npublic bool WithIs() => _source is int[]; \\n \\n\", \"[Benchmark]  \\npublic bool WithTypeCheck () => _source. GetType() == typeof(int[]); \\nMethod  Mean  Ra\", \"tio  Code Size  \\nWithIs  1.9246 ns  1.000  215 B  \\nWithTypeCheck  0.0013 ns  0.001  24 B \\nOf course,\", \" these two operations aren\\u2019t semantically equivalent, so if this was for something that \\nrequired th\", \"e semantics of the former, we couldn\\u2019t use the latter. But in the case of this LINQ \\nperformance opt\", \"imization, we can choose to only optimize the int[] case, forego the super rare case  \\n156 CHAPTER 1\", \"3 | LINQ  \\n of the int[]  actually being a uint[]  (or e.g. DayOfWeek[] ), and minimize the performa\", \"nce penalty of \\nthe optimization for IEnumerable<int>  inputs other than int[]  to just a few quick \", \"instructions.  \\nThis improvement was bu ilt upon further in dotnet/runtime#64624 , which expands the\", \" input types \\nsupported and the operations that take advantage. First, it introduced a private helpe\", \"r for extracting a \\nReadOnlySpan<T>  from certain types of IEnumerable<T>  inputs, namely today thos\", \"e inputs that are \\nactually either a T[] or a List<T> ; as with the previous PR, it uses the GetType\", \"() == typeof(T[])  \\nform to avoid significantly penalizing other inputs. Both of these types enab le\", \" extracting a \\nReadOnlySpan<T>  for the actual storage, in the case of T[] via a cast and in the cas\", \"e of List<T>  via \\nthe CollectionsMarshal.AsSpan  method that was introduced in .NET 5. Once we have\", \" that span, we \\ncan do a few interesting things. This PR:  \\n\\u2022 Expands the previous Min<T>(IEnumerabl\", \"e<T>)  and Max<T>(IEnumerable<T>)  optimizations to \\nnot only apply to int[]  and long[]  but also t\", \"o List<int>  and List<long> . \\n\\u2022 Uses direct span access for Average<T>(IEnumerable<T>)  and Sum<T>(\", \"IEnumerable<T>)  for T \\nbeing int, long , float , double , or decimal , all for arrays and lists.  \\n\", \"\\u2022 Similarly uses direct span access for Min<T>(IEnumerable<T>)  and Max<T>(IEnumerable<T>)  for \\nT b\", \"eing float , double , and decimal . \\n\\u2022 Vectorizes Average<int>(IEnum erable<int>)  for arrays and li\", \"sts  \\nThe effect of that is evident in microbenchmarks, e.g.  \\nprivate static float[] CreateRandom (\", \") \\n{ \\n    var r = new Random(42); \\n    var results = new float[10_000]; \\n    for (int i = 0; i < res\", \"ults. Length; i++) \\n    { \\n        results[i] = ( float)r.NextDouble (); \\n    } \\n    return results;\", \"  \\n} \\n \\nprivate IEnumerable< float> _floats = CreateRandom (); \\n \\n[Benchmark]  \\npublic float Sum() =\", \"> _floats. Sum(); \\n \\n[Benchmark]  \\npublic float Average() => _floats. Average(); \\n \\n[Benchmark]  \\npu\", \"blic float Min() => _floats. Min(); \\n \\n[Benchmark]  \\npublic float Max() => _floats. Max(); \\nMethod  \", \"Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nSum .NET 6.0  39.067 us  1.00 32 B 1.00 \\nSum .NET 7.0\", \"  14.349 us  0.37 - 0.00 \\n      \\nAverage  .NET 6.0  41.232 us  1.00 32 B 1.00  \\n157 CHAPTER 13 | LIN\", \"Q  \\n Method  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nAverage  .NET 7.0  14.378 us  0.35 - 0.0\", \"0 \\n      \\nMin .NET 6.0  45.522 us  1.00 32 B 1.00 \\nMin .NET 7.0  9.668 us  0.21 - 0.00 \\n      \\nMax .\", \"NET 6.0  41.178 us  1.00 32 B 1.00 \\nMax .NET 7.0  9.210 us  0.22 - 0.00 \\nThe previous LINQ PRs were \", \"examples from making existing operations faster. But sometimes \\nperformance improvements come about \", \"from new APIs that can be used in place of previous ones in \\ncertain situations to further improve p\", \"erformance. One such example of that comes from new APIs \\nintroduced in dotnet/runtime#70525  from [\", \"@deeprobin](https://github.com/deeprobin) which were \\nthen improved in dotnet/runtime#71564 . One of\", \" the most popular methods in LINQ is \\nEnumerable.OrderBy  (and its inverse OrderByDescending ), whic\", \"h enables creating a sorted copy of \\nthe input enumerable. To do so, the caller passes a Func<TSourc\", \"e,TKey>  predicate to OrderBy  which \\nOrderBy  uses to extract the co mparison key for each item. Ho\", \"wever, it\\u2019s relatively common to want to \\nsort items with themselves as the keys; this is, after all\", \", the default for methods like Array.Sort , and in \\nsuch cases callers of OrderBy  end up passing in\", \" an identity function, e.g. OrderBy(x => x) . To \\neliminate that cruft, .NET 7 introduces the new Or\", \"der  and OrderDescending  methods, which, in the \\nspirit of pairs like Distinct  and DistinctBy , pe\", \"rform that same sorting operation, just with an implicit \\nx => x  done on behalf of the caller.  But\", \" beyond performance, a nice benefit of this is the \\nimplementation then knows that the keys will all\", \" be the same as the inputs, and it no longer needs to \\ninvoke the callback for each item to retrieve\", \" its key nor allocate a new array to store those keys.  Thus \\nif you find yourself using LINQ and re\", \"aching for OrderBy(x => x) , consider instead using Order()  \\nand reaping the (primarily allocation)\", \" benefits:  \\n[Params(1024)] \\npublic int Length { get; set; } \\n \\nprivate int[] _arr;  \\n \\n[GlobalSetup\", \"]  \\npublic void Setup() => _arr = Enumerable. Range(1, Length). Reverse().ToArray(); \\n \\n[Benchmark (\", \"Baseline = true)] \\npublic void OrderBy() \\n{ \\n    foreach (int _ in _arr.OrderBy(x => x)) { }  \\n} \\n \\n\", \"[Benchmark]  \\npublic void Order() \\n{ \\n    foreach (int _ in _arr.Order()) { } \\n} \\n   \\n158 CHAPTER 13\", \" | LINQ  \\n Method  Length  Mean  Ratio  Allocated  Alloc Ratio  \\nOrderBy  1024  68.74 us  1.00 12.3 \", \"KB  1.00 \\nOrder  1024  66.24 us  0.96 8.28 KB  0.67  \\n159 CHAPTER 14 | File I/O  \\n CHAPTER  14 \\nFile\", \" I/O  \\n.NET 6 saw some huge file I/O improvements, in particular a complete rewrite of FileStream . \", \"While \\n.NET 7 doesn\\u2019t have any single changes on that scale, it does have a significant number of \\ni\", \"mprovements that measurably \\u201cmove the needle,\\u201d and in variety of ways.  \\nOne form of performance imp\", \"rovement that also masquerades as a reliability improvement is \\nincreasing responsiveness to cancell\", \"ation requests. The faster something can be canceled, the sooner \\nthe system is able to give back va\", \"luable resourc es in use, and the sooner things waiting for that \\noperation to complete are able to \", \"be unblocked. There have been several improvements of this ilk in \\n.NET 7.  \\nIn some cases, it comes\", \" from adding cancelable overloads where things weren\\u2019t previously cancelabl e \\nat all. That\\u2019s the ca\", \"se for dotnet/runtime#61898  from [@bgrainger](https://github.com/bgrainger), \\nwhich added new cance\", \"lable overloads of TextReader.ReadLineAsync  and \\nTextReader.ReadToEndAsy nc, and that includes over\", \"rides of these methods on StreamReader  and \\nStringReader ; dotnet/runtime#64301  from [@bgrainger](\", \"https://github.com/bgrainger) then \\noverrode these methods (and others missing overrides) on the Nul\", \"lStreamReader  type returned from \\nTextReader.Null  and StreamReader.Null  (interestingly, these wer\", \"e defined as two different types, \\nunnecessarily, and so this PR also unified on just having both us\", \"e the StreamReader  variant, as i t \\nsatisfies the required types of both). You can see this put to \", \"good use in dotnet/runtime#66492  from \\n[@lateapexearlyspeed](https://github.com/lateapexearlyspeed)\", \", which adds a new \\nFile.ReadLinesAsync  method. This produces an IAsyncEnumerable<string>  of the l\", \"ines in the file, \\nis based on a simple loop around the new StreamReader.ReadLineAsync  overloa d, a\", \"nd is thus itself \\nfully cancelable.  \\nFrom my perspective, though, a more interesting form of this \", \"is when an existing overload is \\npurportedly cancelable but isn\\u2019t actually. For example, the base St\", \"ream.ReadAsync  method just wraps \\nthe Stream.BeginRead /EndRead  methods, which aren\\u2019t cancelable, \", \"so if a Stream -derived type doesn\\u2019t \\noverride ReadAsync , attempts to cancel a call to its ReadAsyn\", \"c  will be minimally effective. It does an \\nup-front check for cancellation, such that if cancellati\", \"on was requested prio r to the call being made, it \\nwill be immediately canceled, but after that che\", \"ck the supplied CancellationToken  is effectively \\nignored. Over time we\\u2019ve tried to stamp out all r\", \"emaining such cases, but a few stragglers have \\nremained. One pernicious case has been with pipes. F\", \"or this discussion, there are two relevant kinds of \\npipes, anonymous and named, which are represent\", \"ed in .NET as pairs of streams: \\nAnonymousPipeClientStream /AnonymousPipeServerStream  and \\nNamedPip\", \"eClientStream /NamedPipeServerStream . Also, on Windows, the OS makes a distinction \\nbetween handles\", \" opened for synchronous I/O from handles opened for overlapped I/O (aka \\nasynchronous I/O), and this\", \" is reflected in the .NET API: you can open a named pipe for synchronous \\nor overlapped I/O based on\", \" the  PipeOptions.Asynchronous  option specified at construction. And, on  \\n160 CHAPTER 14 | File I/\", \"O  \\n Unix, named pipes, contrary to their naming, are actually implemented on top of Unix domain soc\", \"kets. \\nNow some history:  \\n\\u2022 .NET Framework 4.8: No cancellation support. The pipe Stream -derived t\", \"ypes didn\\u2019t even \\noverride ReadAsync  or WriteAsync , so all they got was the default up -front chec\", \"k for \\ncancellation and then the token was ignored.  \\n\\u2022 .NET Core 1.0: On Windows, with a named pipe\", \" opened for asynchronous I/O, cancellation was \\nfully supported. The implementation would register w\", \"ith the CancellationToken , and upon a \\ncancellation request, would use CancelIoEx  for the NativeOv\", \"erlapped*  associated with the \\nasynchronous operation. On Unix, with named pipes implemented in ter\", \"ms of sockets, if the pipe  \\nwas opened with PipeOptions.Asynchronous , the implementation would sim\", \"ulate cancellation \\nvia polling: rather than simply issuing the Socket.ReceiveAsync /Socket.SendAsyn\", \"c  (which \\nwasn\\u2019t cancelable at the time), it would queue a work item to the ThreadPool , and that w\", \"ork \\nitem would run a polling loop, making Socket.Poll  calls with a small timeout, checking the \\nto\", \"ken, and then looping around to do it again until either the Poll  indicated the operation \\nwould su\", \"cceed or cancellation was requested. On both Window s and Unix, other than a named \\npipe opened with\", \" Asynchronous , after the operation was initated, cancellation was a nop.  \\n\\u2022 .NET Core 2.1: On Unix\", \", the implementation was improved to avoid the polling loop, but it still \\nlacked a truly cancelable\", \" Socket.Receive Async /Socket.SendAsync . Instead, by this point \\nSocket.ReceiveAsync  supported zer\", \"o -byte reads, where a caller could pass a zero -length buffer \\nto ReceiveAsync  and use that as not\", \"ification for data being available to consume without \\nactually consuming it. The  Unix implementati\", \"on for asynchronous named pipe streams then \\nchanged to issue zero -byte reads, and would await  a T\", \"ask.WhenAny  of both that operation\\u2019s \\ntask and a task that would be completed when cancellation was\", \" requested. Better, but still far \\nfrom idea l. \\n\\u2022 .NET Core 3.0: On Unix, Socket  got truly cancela\", \"ble ReceiveAsync  and SendAsync  methods, \\nwhich asynchronous named pipes were updated to utilize. A\", \"t this point, the Windows and Unix \\nimplementations were effectively on par with regards to cancella\", \"tion; bot h good for \\nasynchronous named pipes, and just posing for everything else.  \\n\\u2022 .NET 5: On \", \"Unix, SafeSocketHandle  was exposed and it became possible to create a Socket  for \\nan arbitrary sup\", \"plied SafeSocketHandle , which enabled creating a Socket  that actually referred \\nto an anonymous pi\", \"pe. This in tern enabled every PipeStream  on Unix to be implemented in \\nterms of Socket , which ena\", \"bled ReceiveAsync /SendAsync  to be fully cancelable for both \\nanonymous and named pipe s, regardles\", \"s of how they were opened.  \\nSo by .NET 5, the problem was addressed on Unix, but still an issue on \", \"Windows. Until now. In .NET 7, \\nwe\\u2019ve made the rest of the operations fully cancelable on Windows as\", \" well, thanks to \\ndotnet/runtime#72503  (and a subsequent tweak in dotnet/runtime#72612 ). Windows d\", \"oesn\\u2019t support \\noverlapped I/O for anonymous pipes today, so for anonymous pipe s and for named pipe\", \"s opened for \\nsynchronous I/O, the Windows implementation would just delegate to the base Stream  \\ni\", \"mplementation, which would queue a work item to the ThreadPool  to invoke the synchronous \\ncounterpa\", \"rt, just on another thread. Instead, the implementations now queue that work item, but \\ninstead of j\", \"ust calling the synchronous method, it does some pre - and post - work that registers for \\ncancellat\", \"ion, passing in the thread ID of the thread that\\u2019s about to perform the I/O. If cancellation is \\nreq\", \"ue sted, the implementation then uses CancelSynchronousIo  to interrupt it. There\\u2019s a race \\nconditio\", \"n here, in that the moment the thread registers for cancellation, cancellation could be \\nrequested, \", \"such that CancelSynchronousIo  could be called before the opera tion is actually initiated.  \\n161 CH\", \"APTER 14 | File I/O  \\n So, there\\u2019s a small spin loop employed, where if cancellation is requested be\", \"tween the time \\nregistration occurs and the time the synchronous I/O is actually performed, the canc\", \"ellation thread \\nwill spin until the I/O is initiated , but this condition is expected to be exceedi\", \"ngly rare. There\\u2019s also a \\nrace condition on the other side, that of CancelSynchronousIo  being requ\", \"ested after the I/O has \\nalready completed; to address that race, the implementation relies on the g\", \"uarantees mad e by \\nCancellationTokenRegistration.Dispose , which promises that the associated callb\", \"ack will either \\nnever be invoked or will already have fully completed executing by the time Dispose\", \"  returns. Not only \\ndoes this implementation complete the puzzle such that  all asynchronous read/w\", \"rite operations on \\nboth anonymous and named pipes on both Windows and Unix are cancelable, it also \", \"actually \\nimproves normal throughput.  \\nprivate Stream _server;  \\nprivate Stream _client;  \\nprivate \", \"byte[] _buffer = new byte[1]; \\nprivate CancellationTokenSource _cts = new CancellationTokenSource ()\", \"; \\n \\n[Params(false, true)] \\npublic bool Cancelable { get; set; } \\n \\n[Params(false, true)] \\npublic bo\", \"ol Named { get; set; } \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    if (Named) \\n    { \\n        str\", \"ing name = Guid. NewGuid().ToString (\\\"N\\\"); \\n        var server = new NamedPipeServerStream (name, Pi\", \"peDirection. Out); \\n        var client = new NamedPipeClientStream (\\\".\\\", name, PipeDirection. In); \\n\", \"        Task.WaitAll(server. WaitForConnectionAsync (), client. ConnectAsync()); \\n        _server = \", \"server;  \\n        _client = client;  \\n    } \\n    else \\n    { \\n        var server = new AnonymousPipe\", \"ServerStream (PipeDirection. Out); \\n        var client = new AnonymousPipeClientStream (PipeDirectio\", \"n. In, \\nserver.ClientSafePipeHandle ); \\n        _server = server;  \\n        _client = client;  \\n    \", \"} \\n} \\n \\n[GlobalCleanup]  \\npublic void Cleanup() \\n{ \\n    _server. Dispose(); \\n    _client. Dispose();\", \" \\n} \\n \\n[Benchmark (OperationsPerInvoke = 1000)] \\npublic async Task ReadWriteAsync () \\n{ \\n    Cancell\", \"ationToken ct = Cancelable ? _cts. Token : default; \\n    for (int i = 0; i < 1000; i++) \\n    {  \\n162\", \" CHAPTER 14 | File I/O  \\n         ValueTask< int> read = _client. ReadAsync (_buffer, ct);  \\n       \", \" await _server. WriteAsync (_buffer, ct);  \\n        await read;  \\n    } \\n} \\nMethod  Runtime  Cancela\", \"ble  Named  Mean  Ratio  Allocated  Alloc Ratio  \\nReadWriteAsync  .NET 6.0  False  False  22.08 us  \", \"1.00 400 B  1.00 \\nReadWriteAsync  .NET 7.0  False  False  12.61 us  0.76 192 B  0.48 \\n        \\nReadW\", \"riteAsync  .NET 6.0  False  True 38.45 us  1.00 400 B  1.00 \\nReadWriteAsync  .NET 7.0  False  True 3\", \"2.16 us  0.84 220 B  0.55 \\n        \\nReadWriteAsync  .NET 6.0  True False  27.11 us  1.00 400 B  1.00\", \" \\nReadWriteAsync  .NET 7.0  True False  13.29 us  0.52 193 B  0.48 \\n        \\nReadWriteAsync  .NET 6.\", \"0  True True 38.57 us  1.00 400 B  1.00 \\nReadWriteAsync  .NET 7.0  True True 33.07 us  0.86 214 B  0\", \".54 \\nThe rest of the performance -focused changes around I/O in .NET 7 were primarily focused on one\", \" of \\ntwo things: reducing syscalls, and reducing allocation.  \\nSeveral PRs went into reducing syscal\", \"ls on Unix as part of copying files, e.g. File.Copy  and \\nFileInfo.CopyTo . dotnet/runtime#59695  fr\", \"om [@tmds](https://github.com/tmds) reduced overheads \\nin several ways. The code had been performing\", \" a stat  call in order to determine up front whether the \\nsource was actually a directory, in which \", \"case the operation would error out. Instead, the PR simply \\ntries to open the source file, which it \", \"would need to do an yway for the copy operation, and then it \\nonly performs that stat  if opening th\", \"e file fails. If opening the file succeeds, the code was already \\nperforming an fstat  to gather dat\", \"a on the file, such as whether it was seekable; with this change, it \\nnow also ex tracts from the re\", \"sults of that single fstat  the source file size, which it then threads \\nthrough to the core copy ro\", \"utine, which itself is then able to avoid an fstat  syscall it had been \\nperforming in order to get \", \"the size. Saving those syscalls is great, in particular for very small files \\nwhere the overhead of \", \"setting up the copy can actually be more expensive than the actual copy of the \\nbytes. But the bigge\", \"st benefit of this PR is that it takes advantage of IOCTL-FICLONERANGE  on Linux. \\nSome Linux file s\", \"ys tems, like XFS and Btrfs, support \\u201ccopy -on-write,\\u201d which means that rather than \\ncopying all of \", \"the data to a new file, the file system simply notes that there are two different files \\npointing to\", \" the same data, sharing the underlying storage. This makes the  \\u201ccopy\\u201d super fast, since \\nnothing ac\", \"tually needs to be copied and instead the file system just needs to update some \\nbookkeeping; plus, \", \"less space is consumed on disk, since there\\u2019s just a single store of the data. The file \\nsystem then\", \" only needs to actuall y copy data that\\u2019s overwritten in one of the files. This PR uses ioctl  \\nand \", \"FICLONE  to perform the copy as copy -on-write if the source and destination file system are the \\nsa\", \"me and the file system supports the operation. In a similar vein, dotnet/runtime#64264  from \\n[@tmds\", \"](https://github.com/tmds) further improves File.Copy /FileInfo.CopyTo  by utilizing \\ncopy_file_rang\", \"e  on Linux if it\\u2019s supported (and only if it\\u2019s a new enough kerne l that it addresses  \\n163 CHAPTER\", \" 14 | File I/O  \\n some issues the function had in previous releases). Unlike a typical read/write lo\", \"op that reads the data \\nfrom the source and then writes it to the destination, copy_file_range  is i\", \"mplemented to stay \\nentirely in kernel mode, without havi ng to transition to user space for each re\", \"ad and write.  \\nAnother example of avoiding syscalls comes for the File.WriteXx  and File.AppendXx  \", \"methods when \\non Unix. The implementation of these methods opens a FileStream  or a SafeFileHandle  \", \"directly, \\nand it was specifying FileOptions.SequentialScan . SequentialScan  is primarily relevant \", \"for reading \\ndata from a file, and hints to OS caching to expect data to be read from the file seque\", \"ntially rather \\nthan randomly. However, these write/append methods don\\u2019t read, the y only write, and\", \" the \\nimplementation of FileOptions.SequentialScan  on Unix requires an additional syscall via \\nposi\", \"x_fadvise  (passing in POSIX_FADV_SEQUENTIAL ); thus, we\\u2019re paying for a syscall and not \\nbenefiting\", \" from it. This situation is akin to the famou s Henny Youngman joke: \\u201cThe patient says, \\n\\u2018Doctor, it\", \" hurts when I do this\\u2019; the doctor says, \\u2018Then don\\u2019t do that!\\u2019.\\u201d Here, too, the answer is \\u201cdon\\u2019t \\ndo\", \" that,\\u201d and so dotnet/runtime#59247  from  [@tmds](https://github.com/tmds) simply stops passing \\nSe\", \"quentialScan  in places where it won\\u2019t help but may hurt.  \\nDirectory handling has seen reduced sysc\", \"alls across the directory lifecycle, especially on Unix. \\ndotnet/runtime#58799  from [@tmds](https:/\", \"/github.com/tmds) speeds up directory creation on Unix. \\nPreviously, the implementation of directory\", \" creation would first check to see if the directory already \\nexisted, which involves a syscall. In  \", \"the expected minority case where it already existed the code could \\nearly exit out. But in the expec\", \"ted more common case where the directory didn\\u2019t exist, it would then \\nparse the file path to find al\", \"l of the directories in it, walk up the directory list un til it found one that \\ndid exist, and then\", \" try to create all of the subdirectories back down through the target one. However, \\nthe expected mo\", \"st common case is the parent directories already exist and the child directory doesn\\u2019t, \\nin which ca\", \"se we\\u2019re still pa ying for all that parsing when we could have just created the target \\ndirectory. T\", \"his PR addresses that by changing the up -front existence check to instead simply try to \\nmkdir  the\", \" target directory; if it succeeds, great, we\\u2019re done, and if it fails, the err or code from the \\nfai\", \"lure can be used instead of the existence check to know whether mkdir  failed because it had no \\nwor\", \"k to do. dotnet/runtime#61777  then takes this a step further and avoids st ring allocations while \\n\", \"creating directories by using stack memory for the paths temporarily needed to pass to mkdir . \\ndotn\", \"et/runtime#63675  then improves the performance of moving directories, o n both Unix and \\nWindows, r\", \"emoving several syscalls. The shared code for Directory.Move  and DirectorInfo.MoveTo  \\nwas doing ex\", \"plicit directory existence checks for the source and destination locations, but on \\nWindows the Win3\", \"2 API called to perform the move d oes such checks itself, so they\\u2019re not needed \\npreemptively. On U\", \"nix, we can similarly avoid the existence check for the source directory, as the \\nrename  function c\", \"alled will similarly simply fail if the source doesn\\u2019t exist (with an appropriate error \\nthat l et\\u2019s\", \" us deduce what went wrong so the right exception can be thrown), and for the destination, \\nthe code\", \" had been issuing separate existence checks for whether the destination existed as a directory \\nor a\", \"s a file, but a single stat  call suffices for both.  \\nprivate string _path1; \\nprivate string _path2\", \"; \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    _path1 = Path. GetTempFileName (); \\n    _path2 = Pa\", \"th. GetTempFileName ();  \\n164 CHAPTER 14 | File I/O  \\n     File.Delete(_path1);  \\n    File.Delete(_p\", \"ath2);  \\n    Directory. CreateDirectory (_path1);  \\n} \\n \\n[Benchmark]  \\npublic void Move() \\n{ \\n    Di\", \"rectory. Move(_path1, _path2);  \\n    Directory. Move(_path2, _path1);  \\n} \\nMethod  Runtime  Mean  Ra\", \"tio  Allocated  Alloc Ratio  \\nMove  .NET 6.0  31.70 us  1.00 256 B  1.00 \\nMove  .NET 7.0  26.31 us  \", \"0.83 - 0.00 \\nAnd then also on Unix, dotnet/runtime#59520  from [@tmds](https://github.com/tmds) impr\", \"oves \\ndirectory deletion, and in particular recursive deletion (deleting a directory and everything \", \"it cont ains \\nand everything they contain and so on), by utilizing the information already provided \", \"by the file \\nsystem enumeration to avoid a secondary existence check.  \\nSyscalls were also reduced a\", \"s part of support for memory -mapped files. dotnet/runtime#63754  takes \\nadvantage of special -casin\", \"g to do so while opening a MemoryMappedFile . When \\nMemoryMappedFile.CreateFromFile  was called, one\", \" of the first things it would do is call File.Exists  \\nto determine w hether the specified file alre\", \"ady exists; that\\u2019s because later in the method as part of \\ndealing with errors and exceptions, the i\", \"mplementation needs to know whether to delete the file that \\nmight then exist; the implementation co\", \"nstructs a FileStream , and d oing might will the specified file \\ninto existence. However, that only\", \" happens for some FileMode  values, which is configurable via an \\nargument passed by callers of Crea\", \"teFromFile . The common and default value of FileMode  is \\nFileMode.Open , which requires tha t the \", \"file exist such that constructing the FileStream  will throw if it \\ndoesn\\u2019t. That means we only actu\", \"ally need to call File.Exists  if the FileMode  is something other \\nthan Open  or CreateNew , which \", \"means we can trivially avoid the extra system call in the  majority case. \\ndotnet/runtime#63790  als\", \"o helps here, in two ways. First, throughout the CreateFromFile  operation, \\nthe implementation migh\", \"t access the FileStream \\u2019s Length  multiple times, but e ach call results in a \\nsyscall to read the \", \"underlying length of the file. We can instead read it once and use that one value for \\nall of the va\", \"rious checks performed. Second, .NET 6 introduced the File.OpenHandle  method which \\nenables opening\", \" a file handle / file descriptor directly into a SafeFileHandle , rather than having to go \\nthrough \", \"FileStream  to do so. The use of the FileStream  in MemoryMappedFile  is actually quite \\nminimal, an\", \"d so it makes sense to just use the SafeFileHandle  directly rather than also co nstructing \\nthe sup\", \"erfluous FileStream  and its supporting state. This helps to reduce allocations.  \\nFinally, there\\u2019s \", \"dotnet/runtime#63794 , which recognizes that a MemoryMappedViewAccessor  or \\nMemoryMappedViewStream \", \" opened for read -only access can\\u2019t have been written to. Sounds obvious, \\nbut the practical implica\", \"tion of this is that closing either needn\\u2019t bother flushing, since that view \\ncouldn\\u2019t have changed \", \"any data in the implementation, and flus hing a view can be relatively \\nexpensive, especially for la\", \"rger views. Thus, a simple change to avoid flushing if the view isn\\u2019t writable \\ncan yield a measurab\", \"le improvement to MemoryMappedViewAccessor /MemoryMappedviewStream \\u2019s \\nDispose .  \\n165 CHAPTER 14 | \", \"File I/O  \\n private string _path; \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    _path = Path. GetTe\", \"mpFileName (); \\n    File.WriteAllBytes (_path, Enumerable. Range(0, 10_000_000).Select(i => \\n(byte)i\", \").ToArray()); \\n} \\n \\n[GlobalCleanup]  \\npublic void Cleanup() \\n{ \\n    File.Delete(_path);  \\n} \\n \\n[Benc\", \"hmark]  \\npubli c void MMF() \\n{ \\n    using var mmf = MemoryMappedFile. CreateFromFile (_path, FileMod\", \"e. Open, null); \\n    using var s = mmf. CreateViewStream (0, 10_000_000, MemoryMappedFileAccess. Rea\", \"d); \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nMMF  .NET 6.0  315.7 us  1.00 488 B  \", \"1.00 \\nMMF  .NET 7.0  227.1 us  0.68 336 B  0.69 \\nBeyond system calls, there have also been a plethor\", \"a of improvements around reducing allocation. \\nOne such change is dotnet/runtime#58167 , which impro\", \"ved the performance of the commonly -used \\nFile.WriteAllText{Async}  and File.AppendAllText{Async}  \", \"methods. The PR recognizes two \\nthings: one, that these operations are common enough that it\\u2019s worth\", \" avoiding the small -but-\\nmeasurable overhead of going through a FileStream  and instead just going \", \"directl y to the \\nunderlying SafeFileHandle , and, two, that since the methods are passed the entire\", \"ty of the payload \\nto output, the implementation can use that knowledge (in particular for length) t\", \"o do better than the \\nStreamWriter  that was previously employed. In doing so, the implementation av\", \"oids the overheads \\n(primarily in allocation) of the streams and writers and temporary buffers.  \\npr\", \"ivate string _path; \\n \\n[GlobalSetup]  \\npublic void Setup() => _path = Path. GetRandomFileName (); \\n \", \"\\n[GlobalCleanup]  \\npublic void Cleanup() => File. Delete(_path);  \\n \\n[Benchmark]  \\npublic void Write\", \"AllText () => File. WriteAllText (_path, Sonnet);  \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc R\", \"atio  \\nWriteAllText  .NET 6.0  488.5 us  1.00 9944 B  1.00 \\nWriteAllText  .NET 7.0  482.9 us  0.99 3\", \"92 B  0.04  \\n166 CHAPTER 14 | File I/O  \\n dotnet/runtime#61519  similarly updates File.ReadAllBytes{\", \"Async}  to use SafeFileHandle  (and \\nRandomAccess ) directly rather than going through FileStream , \", \"shaving off some allocation from e ach \\nuse. It also makes the same SequentialScan  change as mentio\", \"ned earlier. While this case is about \\nreading (whereas the previous change saw SequentialScan  bein\", \"g complete overhead with no \\nbenefit), ReadAllBytes{Async}  is very frequently used to read small er\", \" files where the overhead of the \\nadditional syscall can measure up to 10% of the total cost (and fo\", \"r larger files, modern kernels are \\npretty good about caching even without a sequentiality hint, so \", \"there\\u2019s little downside measured \\nthere).  \\nAnother such change is dotnet/runtime#68662 , which impr\", \"oved Path.Join \\u2019s handling of null or \\nempty path segments. Path.Join  has overloads that accept str\", \"ing s and overloads that accept \\nReadOnlyS pan<char> s, but all of the overloads produce string s. T\", \"he string -based overloads just \\nwrapped each string in a span and delegated to the span -based over\", \"loads. However, in the event that \\nthe join operation is a nop (e.g.  there are two path segments an\", \"d the second is empty so the join \\nshould just return the first), the span -based implementation sti\", \"ll needs to create a new string (there\\u2019s \\nno way for the ReadOnlySpan<char> -based overloads to extr\", \"act a string from the span). As such, the \\nstring -based overloads c an do a little bit better in th\", \"e case of one of them being null or empty; they \\ncan do the same thing the Path.Combine  overloads d\", \"o, which is to have the M argument overload \\ndelegate to the M -1 argument overload, filtering out a\", \" null or empty, and in the ba se case of the \\noverload with two arguments, if a segment is null or e\", \"mpty, the other (or empty) can just be returned \\ndirectly.  \\nBeyond that, there are a multitude of a\", \"llocation -focused PRs, such as dotnet/runtime#69335  from \\n[@pedrobsaila](https://github.com/pedrob\", \"saila) which adds a fast -path based on stack allocation to \\nthe internal ReadLink  helper that\\u2019s us\", \"ed on Unix anywhere we need to follow symlinks, or \\ndotnet/runtime#68752  that updates NamedPipeClie\", \"ntStream.ConnectAsync  to remove a delegate \\nallocation (by passing state into a Task.Factory.StartN\", \"ew  call explicitly), or dotnet/runtime#69412  \\nwhich adds an optimized Read(Span<byte>)  override t\", \"o the Stream  returned from \\nAssembly.GetManifestResourceStream . \\nBut my personal favorite improvem\", \"ent in this area come from dotnet/runtime#69272 , which adds a \\nfew new helpers to Stream : \\npublic \", \"void ReadExactly (byte[] buffer, int offset, int count); \\npublic void ReadExactly (Span<byte> buffer\", \");  \\n \\npublic ValueTask ReadExactlyAsync (byte[] buffer, int offset, int count, CancellationToken \\nc\", \"ancellationToken = default); \\npublic ValueTask ReadExactlyAsync (Memory< byte> buffer, CancellationT\", \"oken cancellationToken \\n= default); \\n \\npublic int ReadAtLeast (Span<byte> buffer, int minimumBytes, \", \"bool throwOnEndOfStream = \\ntrue); \\npublic ValueTask< int> ReadAtLeastAsync (Memory< byte> buffer, in\", \"t minimumBytes, bool \\nthrowOnEndOfStream = true, CancellationToken cancellationToken = default); \\nIn\", \" fairness, these are more about usability than they are about performance, but in this case there\\u2019s \", \" a \\ntight correlation between the two. It\\u2019s very common to write these helpers one\\u2019s self (the \\nafor\", \"ementioned PR deleted many open -coded loops for this functionality from across the core \\nlibraries)\", \" as the functionality is greatly needed, and it\\u2019s unfortunat ely easy to get them wrong in ways  \\n16\", \"7 CHAPTER 14 | File I/O  \\n that negatively impact performance, such as by using a Stream.ReadAsync  \", \"overload that needs to \\nallocate a returned Task<int>  or reading fewer bytes than is allowed as par\", \"t of a read call. These \\nimplementations are correct  and efficient.   \\n168 CHAPTER 15 | Compression\", \"  \\n CHAPTER  15 \\nCompression  \\n.NET Core 2.1 added support for the Brotli  compression algorithm, su\", \"rfacing it in two ways: \\nBrotliStream  and the pair of BrotliEncoder /BrotliDecoder  structs that Br\", \"otliStream  is itself built \\non top of. For the most part, these types just provide wrappers around \", \"a native C implementation \\nfrom google/brotli , and so while the .NET layer has the opportunity to i\", \"mprove how data is moved \\naround, managed allocation, and so on, the speed and qual ity of the compr\", \"ession itself are largely at \\nthe mercy of the C implementation and the intricacies of the Brotli al\", \"gorithm.  \\nAs with many compression algorithms, Brotli provides a knob that allows for a quintessent\", \"ial tradeoff \\nto be made between compression  speed (how fast data can be compressed) and compressio\", \"n \\nquality/ratio (how small can the compressed output be made). The hand -wavy idea is the more time\", \" \\nthe algorithm spends looking for opportunity, the more space can be saved. Many algorithms expose \", \"\\nthis as a numerical dial, in Brotli\\u2019s case going from 0 (fastest speed, least compression) to 11 (s\", \"pend as \\nmuch time as is needed to minimize the output size). But while BrotliEncoder  surfaces that\", \" same \\nrange, BrotliStream \\u2019s surface area is simpler: most use j ust specifies that compression sho\", \"uld be \\nperformed (e.g. new BrotliStream(destination, CompressionMode.Compress) ) and the only knob \", \"\\navailable is via the CompressionLevel  enum (e.g. new BrotliStream(destination, \\nCompressionLevel.F\", \"astest) ), which provides ju st a few options: CompressionLevel.NoCompression , \\nCompressionLevel.Fa\", \"stest , CompressionLevel.Optimal , and CompressionLevel.SmallestSize . \\nThis means the BrotliStream \", \" implementation needs to select a default value when no \\nCompressionLevel  is specified and needs to\", \" map CompressionLevel  to an underlying numerical \\nvalue when one is.  \\nFor better or worse (and I\\u2019m\", \" about to argue \\u201cmuch worse\\u201d), the native C implementation its elf defines \\nthe default to be 11 ( g\", \"oogle/brotli#encode.h ), and so that\\u2019s what BrotliStream  has ended up using \\nwhen no CompressionLev\", \"el  is explicitly specified. Further, the CompressionLevel.Optimal  enum \\nvalue is poorly named. It\\u2019\", \"s intended to represent a good default that\\u2019s a balanced tradeoff between \\nspeed and quality; that\\u2019s\", \" exactly what it means for DeflateStream , GZipStream , and ZLibStream . But \\nfor BrotliStream , as \", \"the default it similarly got translated to mean the underlying native library\\u2019s \\ndefault, which is 1\", \"1. This means that when constructing a BrotliStream  with either \\nCompressionMode.Compress  or Compr\", \"essionLevel. Optimal , rather than getting a nice balanced \\ndefault, you\\u2019re getting the dial turned \", \"all the way up to 11.  \\nIs that so bad? Maybe compression quality is the most important thing? For e\", \"xample, reducing the \\nsize of data can make it faster to then transmit it over a wire, and with a sl\", \"ow connection, size then \\nmeaningfully translates into end -to-end throughput.  \\nThe problem is just\", \" how much this extra effort costs. Compression speed and ratio are highly \\ndependent on the data bei\", \"ng compressed, so take this example  with a small grain of salt as it\\u2019s not \\nentirely representative\", \" of all use, but it\\u2019s good enough for our purposes. Consider this code, which  \\n169 CHAPTER 15 | Com\", \"pre ssion  \\n uses BrotliEncoder  to compress the The Comple te Works of William Shakespeare from Pro\", \"ject \\nGutenberg  at varying levels of compression:  \\nusing System.Buffers; \\nusing System.Diagnostics\", \" ; \\nusing System.IO.Compression ; \\nusing System.Text; \\n \\nusing var hc = new HttpClient (); \\nbyte[] d\", \"ata = await hc. GetByteArrayAsync (\\\"https://www.gutenberg.org/ebooks/100.txt.utf -8\\\"); \\nConsole. Wri\", \"teLine (data.Length); \\n \\nvar compressed = new MemoryStream (); \\nvar sw = new Stopwatch (); \\n \\nfor (i\", \"nt level = 0; level <= 11; level++)  \\n{ \\n    const int Trials = 10; \\n \\n    compressed. Position = 0;\", \" \\n    Compress (level, data, compressed);  \\n \\n    sw.Restart(); \\n    for (int i = 0; i < Trials; i++\", \")  \\n    { \\n        compressed. Position  = 0; \\n        Compress (level, data, compressed);  \\n    } \\n\", \"    sw.Stop(); \\n \\n    Console. WriteLine ($\\\"{level},{sw.Elapsed.TotalMilliseconds / \\nTrials},{compre\", \"ssed.Position}\\\" ); \\n \\n    static void Compress (int level, byte[] data, Stream destination)  \\n    { \", \"\\n        var encoder = new BrotliEncoder (quality: level, window: 22); \\n        Write(ref encoder, d\", \"ata, dest ination, false); \\n        Write(ref encoder, Array. Empty<byte>(), destination, true); \\n  \", \"      encoder. Dispose(); \\n \\n        static void Write(ref BrotliEncoder encoder, byte[] data, Strea\", \"m destination, bool \\nisFinalBlock)  \\n        { \\n            byte[] output = ArrayPool< byte>.Shared.\", \"Rent(4096); \\n \\n            OperationStatus lastResult = OperationStatus. DestinationTooSmall ; \\n    \", \"        ReadOnlySpan< byte> buffer = data;  \\n            while (lastResult == OperationStatus. Desti\", \"nationTooSmall ) \\n            { \\n                lastResult = encoder. Compress (buffer, output, out\", \" int bytesConsumed, out \\nint bytesWritten, isFinalBlock);  \\n                if (lastResult == Operat\", \"ionStatus. InvalidData ) throw new \\nInvalidOperationException (); \\n                if (bytesWritten \", \" > 0) destination. Write(output. AsSpan(0, bytesWritten));  \\n                if (bytesConsumed > 0) \", \"buffer = buffer. Slice(bytesConsumed);  \\n            } \\n \\n            ArrayPool< byte>.Shared.Return\", \"(output);  \\n        }  \\n170 CHAPTER 15 | Compre ssion  \\n     } \\n} \\nThe code is measuring how long it\", \" take s to compress the input data at each of the levels (doing a \\nwarmup and then averaging several\", \" iterations), timing how long it takes and capturing the resulting \\ncompressed data size. For the si\", \"ze, I get values like this:  \\nLevel  Size (bytes)  \\n0 2,512,855.00  \\n1 2,315,466.00  \\n2 2,224,638.00\", \"  \\n3 2,218,328.00  \\n4 2,027,153.00  \\n5 1,964,810.00  \\n6 1,923,456.00  \\n7 1,889,927.00  \\n8 1,863,988.\", \"00  \\n9 1,846,685.00  \\n10 1,741,561.00  \\n11 1,702,214.00  \\n \\nThat\\u2019s a fairly liner progression from l\", \"east to most compression. That\\u2019s not the problem. This is the \\nproblem:  \\n  \\n \\n171 CHAPTER 15 | Comp\", \"re ssion  \\n Level  Time \\n(ms)  \\n0 24.11  \\n1 36.67  \\n2 64.13  \\n3 73.72  \\n4 146.41  \\n5 257.12  \\n6 328.\", \"54  \\n7 492.81  \\n8 702.38  \\n9 892.08  \\n10 4,830.32  \\n11 10,634.88  \\n \\nThis chart shows an almost expo\", \"nential increase in processing time as we near the upper end of the \\ndial, with quality level 11 com\", \"pressing ~33% better than quality level 0 but taking ~440x as long to \\nachieve that. If that\\u2019s what \", \"a developer wants, they can specify CompressionLevel.SmallestSize , but \\nthat co st by default and f\", \"or the balanced CompressionLevel.Optimal  is far out of whack.  \\ndotnet/runtime#72266  fixes that. A\", \" very small change, it simply makes CompressMode.Compress  and \\nCompressionLeve l.Optimal  for Brotl\", \"i map to quality level 4, which across many kinds of inputs does \\nrepresent a fairly balanced trade \", \"-off between size and speed.  \\n \\n172 CHAPTER 15 | Compre ssion  \\n private byte[] _data = new \\nHttpCl\", \"ient ().GetByteArrayAsync (\\\"https://www.gutenberg.org/ebooks/100.txt.utf -8\\\").Result; \\nprivate Strea\", \"m _output = new MemoryStream (); \\n \\n[Benchmark]  \\npublic void Compress () \\n{ \\n    _output. Position \", \" = 0; \\n    using var brotli = new BrotliStream (_output, CompressionMode. Compress , leaveOpen: \\ntru\", \"e); \\n    brotli.Write(_data);  \\n} \\nMethod  Runtime  Mean  Ratio  \\nCompress  .NET 6.0  9,807.0 ms  1.\", \"00 \\nCompress  .NET 7.0  133.1 ms  0.01 \\nOther improvements have gone into compression, such as dotne\", \"t/runtime#69439  which updates the \\ninternal ZipHelper.AdvanceToPosition  function used by ZipArchiv\", \"e  to reuse a buffer on every \\niteration of a loop rather than allocating a new buffer for eac h ite\", \"ration, dotnet/runtime#66764  which \\nuses spans judiciously to avoid a bunch of superfluous string  \", \"and string[]  allocations from \\nSystem.IO.Packaging , and dotnet/runtime#73082  updating the zlib im\", \"plementations shipped as part \\nof .NET from v1.2.11 (which was released in January 2017) to v1.2.12 \", \"(which was released in March \\n2022).   \\n173 CHAPTER 16 | Networking  \\n CHAPTER  16 \\nNetworking  \\nNet\", \"working is the life -blood of almost every service, with performance being critical to success. In \\n\", \"previous releases, a lot of effort was focused on the lower layers of the networking stack, e.g. .NE\", \"T 5 \\nsaw a significant investment in improving the performance of sockets on Linux. In .NET 7, much \", \"of the \\neffort is above sockets.  \\nThat said, there were some interesting performance improvements i\", \"n sockets itself for .NET 7. One of \\nthe more interesting is dotnet/runtime#64770 , which revamped h\", \"ow some synchronization is handled \\ninside of SocketsAsyncEventArgs . As background, in the ear ly d\", \"ays of networking in .NET Framework, \\nasynchrony was enabled via Begin /End methods (the \\u201cAPM\\u201d patte\", \"rn). This pattern is not only \\ncomplicated to use well, it\\u2019s relatively inefficient, resulting in al\", \"location for every single operation \\nperformed (at a min imum for the IAsyncResult  object that\\u2019s re\", \"turned from the BeginXx  method). To \\nhelp make networking operations more efficient, SocketsAsyncEv\", \"entArgs  was introduced. \\nSocketsAsyncEventArgs  is a reusable class you allocate to hold all of the\", \" state associated w ith \\nasynchronous operations: allocate one, pass it to various async methods (e.\", \"g. ReceiveAsync ), and \\nthen completion events are raised on the SocketAsyncEventArgs  instance when\", \" the operation \\ncompletes. It can be quite efficient when used correctly, but it\\u2019 s also complicated\", \" to use correctly. In \\nsubsequent releases, Task -based and ValueTask -based APIs were released; the\", \"se have the efficiency \\nof SocketAsyncEventArgs  and the ease -of-use of async/await , and are the r\", \"ecommended starting \\npoint for all Socket -based asynchronous programming today. They have the effic\", \"iency of \\nSocketAsyncEventArgs  becaus e they\\u2019re actually implemented as a thin veneer on top of it \", \"under the \\ncovers, and so while most code these days isn\\u2019t written to use SocketAsyncEventArgs  dire\", \"ctly, it\\u2019s still \\nvery relevant from a performance perspective.  \\nSocketAsyncEventArgs  on Windows i\", \"s  implemented to use winsock and overlapped I/O. When you \\ncall an async method like ValueTask<Sock\", \"et> Socket.AcceptAsync(CancellationToken) , that grabs \\nan internal SocketAsyncEventArgs  and issues\", \" an AcceptAsync  on it, which in turn gets a \\nNativeOverlapped*  from the ThreadPoolBoundHandle  ass\", \"ociated with the socket, and uses it to issue \\nthe native AcceptEx  call. When that handle is initia\", \"lly created, we set the \\nFILE_SKIP_COMPLETION_PORT_ON_SUCCESS  completion notification mode on the s\", \"ocket; use of this \\nwas int roduced in earlier releases of .NET Core, and it enables a significant n\", \"umber of socket \\noperations, in particular sends and receives, to complete synchronously, which in t\", \"urn saves \\nunnecessary trips through the thread pool, unnecessary unwinding of async s tate machines\", \", and so \\non. But it also causes a condundrum. There are some operations we want to perform associat\", \"ed with \\nasynchronous operation but that have additional overhead, such as registering for the cance\", \"llation of \\nthose operations, and we don\\u2019t wan t to pay the cost of doing them if the operation is g\", \"oing to \\ncomplete synchronously. That means we really want to delay performing such registration unt\", \"il after \\nwe\\u2019ve made the native call and discovered the operation didn\\u2019t complete synchronously\\u2026 but\", \" at t hat \\npoint we\\u2019ve already initiated the operation, so if it doesn\\u2019t  complete synchronously, th\", \"en we\\u2019re now in  \\n174 CHAPTER 16 | Networking  \\n a potential race condition, where our code that\\u2019s s\", \"till setting up the asynchronous operation is racing \\nwith it potentially completing in a callback  \", \"on another thread. Fun. SocketAsyncEventArgs  handled \\nthis race condition with a spin lock; the the\", \"ory was that contention would be incredibly rare, as the \\nvast majority cases would either be the op\", \"eration completing synchronously (in which case there\\u2019s no  \\nother thread involved) or asynchronousl\", \"y with enough of a delay that the small amount of additional \\nwork performed by the initiating threa\", \"d would have long ago completed by the time the \\nasynchronous operation completed. And for the most \", \"part, that was tru e. However, it turns out that \\nit\\u2019s actually much more common than expected for c\", \"ertain kinds of operations, like Accepts. Accepts \\nend up almost always completing asynchronously, b\", \"ut if there\\u2019s already a pending connection, \\ncompleting asynchronously almost immediately, which the\", \"n induces this race condition to happen \\nmore frequently and results in more contention on the spin \", \"locks. Contention on a spin lock is \\nsomething you really want to avoid. And in fact, for a particul\", \"ar benchmark, this spin lock showed up \\nas the cause for an almost 300% slowdown in requests -per-se\", \"cond (RPS) for a benchmark that used a \\ndedicated connection per request (e.g.  with every response \", \"setting \\u201cConnection: close\\u201d). \\ndotnet/runtime#64770  changed the synchronization mechanism to no lon\", \"ger involve a spin lock; \\ninstead, it maintains a simple gate implemented as an Interlocked.CompareE\", \"xchange . If the initiating \\nthread gets to the gate first, from that point on the operation is cons\", \"idered asynchronous and any \\nadditional work is handled by the completing callback. Conversely, if t\", \"he callback gets to the gate first, \\nthe initiating thread treats the operation as if it completed s\", \"ynchronously. This not only avoids one of \\nthe threa ds spinning while waiting for the other to make\", \" forward progress, it also increases the \\nnumber of operations that end up being handled as synchron\", \"ous, which in turn reduces other costs \\n(e.g. the code await ing the task returned from this operati\", \"on doesn\\u2019t n eed to hook up a callback and \\nexit, and can instead itself continue executing synchron\", \"ously). The impact of this is difficult to come \\nup with a microbenchmark for, but it can have meani\", \"ngful impact for loaded Windows servers that \\nend up accepting significa nt numbers of connections i\", \"n steady state.  \\nA more -easily quantifiable change around sockets is dotnet/runtime#71090 , which \", \"improves the \\nperformance of SocketAddress.Equals . A SocketAddress  is the serialized form of an En\", \"dPoint , with \\na byte[]  containing the sequence of bytes that represent the address. Its Equals  me\", \"thod, used to \\ndetermine whether to SocketAddress  instances are the same, looped over that byte[]  \", \"byte-by-byte. \\nNot only is such code  gratuitous when there are now helpers available like SequenceE\", \"qual  for \\ncomparing spans, doing it byte -by-byte is also much less efficient than the vectorized i\", \"mplementation \\nin SequenceEqual . Thus, this PR simply replaced the open -coded comparison loop wit \", \"h a call to \\nSequenceEqual . \\nprivate SocketAddress _addr = new IPEndPoint (IPAddress. Parse(\\\"123.12\", \"3.123.123\\\" ), \\n80).Serialize (); \\nprivate SocketAddress _addr_same = new IPEndPoint (IPAddress. Pars\", \"e(\\\"123.123.123.123\\\" ), \\n80).Serialize (); \\n \\n[Benchmark]  \\npublic bool Equals_Same () => _addr. Equa\", \"ls(_addr_same);  \\nMethod  Runtime  Mean  Ratio  \\nEquals_Same  .NET 6.0  57.659 ns  1.00 \\nEquals_Same\", \"  .NET 7.0  4.435 ns  0.08  \\n175 CHAPTER 16 | Networking  \\n Let\\u2019s move up to some more interesting c\", \"hanges in the layers above Sockets , starting with \\nSslStream . \\nOne of the more impactful changes t\", \"o SslStream  on .NET 7 is in support for TLS resumption on Linux. \\nWhen a TLS connection is establis\", \"hed, the client and se rver engage in a handshake protocol where \\nthey collaborate to decide on a TL\", \"S version and cipher suites to use, authenticate and validate each \\nother\\u2019s identity, and create sym\", \"metric encryption keys for use after the handshake. This represents a \\nsignificant  portion of the t\", \"ime required to establish a new connection. For a client that might \\ndisconnect from a server and th\", \"en reconnect later, as is fairly common in distributed applications, TLS \\nresumption allows a client\", \" and server to essentially pick up where they left off, with the client and/or \\nserver storing some \", \"amount of information about recent connections and using that information to \\nresume. Windows SChann\", \"el provides default support for TLS resumption, and thus the Windows \\nimplementation of SslStream  (\", \"which is built on SChannel) has long had support for TLS resumption. \\nBut OpenSSL\\u2019s model requires a\", \"dditional code to enable TLS resumption, and such code wasn\\u2019t \\npresent in the Linux implementation o\", \"f SslStream . With dotnet/runtime#57079  and \\ndotnet/runtime#63030 , .NET 7 adds server -side suppor\", \"t for TLS resumption (using the variant that \\ndoesn\\u2019t  require storing recent connection state  on t\", \"he server), and with dotnet/runtime#64369 , .NET 7 \\nadds client -side support (which does require st\", \"oring additional state). The effect of this is significant, in \\nparticular for a benchmark that open\", \"s and closes lots of connections between clients.  \\nprivate NetworkStream _client, _server;  \\nprivat\", \"e readonly  byte[] _buffer = new byte[1]; \\nprivate readonly SslServerAuthenticationOptions _options \", \"= new \\nSslServerAuthenticationOptions  \\n{ \\n    ServerCertificateContext = SslStreamCertificateContex\", \"t. Create(GetCertificate (), null), \\n}; \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    using var lis\", \"tener = new Socket(AddressFamily. InterNetwork , SocketType. Stream, \\nProtocolType. Tcp); \\n    liste\", \"ner. Bind(new IPEndPoint (IPAddress. Loopback , 0)); \\n    listener. Listen(1); \\n \\n    var client = n\", \"ew Socket(AddressFamily. InterNetwork , SocketType. Stream, \\nProtocolType. Tcp); \\n    client.Connect\", \"(listener. LocalEndPoint ); \\n \\n    _server = new NetworkStream (listener. Accept(), ownsSocket: true\", \"); \\n    _client = new NetworkStream (client, ownsSocket: true); \\n} \\n \\n[GlobalCleanup]  \\npublic void \", \"Cleanup() \\n{ \\n    _client. Dispose(); \\n    _server. Dispose(); \\n} \\n \\n[Benchmark]  \\npublic async Task\", \" Handshake () \\n{ \\n    using var client = new SslStream (_client, leaveInnerStreamOpen: true, delegat\", \"e  { return  \\n176 CHAPTER 16 | Networking  \\n true; }); \\n    using var server = new SslStream (_serve\", \"r, leaveInnerStreamOpen: true, delegate  { return \\ntrue; }); \\n \\n    await Task. WhenAll( \\n        cl\", \"ient.AuthenticateAsClientAsync (\\\"localhost\\\" , null, SslProtocols. None, \\ncheckCertificateRevocation:\", \" false), \\n        server.AuthenticateAsServerAsync (_options));  \\n \\n    await client. WriteAsync (_b\", \"uffer);  \\n    await server. ReadAsync(_buffer);  \\n    await server. WriteAsync (_buffer);  \\n    awai\", \"t client. ReadAsync (_buffer);  \\n} \\n \\nprivate static X509Certificate2 GetCertificate () => \\n    new \", \"X509Certificate2 ( \\n        \\nConvert. FromBase64String (\\\"MIIUmgIBAzCCFFYGCSqGSIb3DQEHAaCCFEcEghRDMII\", \"UPzCCC iAGCSqGSIb3DQEHA\\naCCChEEggoNMIIKCTCCCgUGCyqGSIb3DQEMCgECoIIJfjCCCXowHAYKKoZIhvcNAQwBAzAOBAhCA\", \"auyUWggWwICB9AE\\ngglYefzzX/jx0b+BLU/TkAVj1KBpojf0o6qdTXV42drqIGhX/k1WwF1ypVYdHeeuDfhH2eXHImwPTw+0bACY\", \"0dSiIHK\\nptm0sb/MskoGI8nlOtHWLi+QBirJ9LSUZcBNOLwoMeYLSFEWWBT69k/sWr c6/SpDoVumkfG4pZ02D9bQgs1+k8fpZjZ\", \"\\nGoZp1jput8CQXPE3JpCsrkdSdiAbWdbNNnYAy4C9Ej/vdyXJVdBTEsKzPYajAzo6Phj/oS/J3hMxxbReMtj2Z0QkoBB\\nVMc70d+\", \"DpAK5OY3et872D5bZjvxhjAYh5JoVTCLTLjbtPRn1g7qh2dQsIpfQ5KrdgqdImshHvxgL92ooC1eQVqQffMn\\nZ0/LchWNb2rMDa8\", \"9K9CtAefEIF4ve2bOUZUNFqQ6d vd90SgKq6jNfwQf/1u70WKE86+vChXMMcHFeKso6hTE9+/zuUP\\nNVmbRefYAtDd7ng996S15F\", \"NVdxqyVLlmfcihX1jGhTLi//WuMEaOfXJ9KiwYUyxdUnMp5QJqO8X/tiwnsuhlFe3NKMX\\nY77jUe8F7I+dv5cjb9iKXAT+q8oYx1\", \"LcWu2mj1ER9/b2omnotp2FIaJDwI40Tts6t4QVH3bUNE9gFIfTMK+WMgKBz/J\\nAGvC1vbPSdFsWIqwhl7mEYWx 83HJp/+Uqp5f+\", \"d8m4phSan2rkHEeDjkUaoifLWHWDmL94SZBrgU6yGVK9dU82kr7jCS\\nUTrnga8qDYsHwpQ22QZtu0aOJGepSwZU7NZNMiyX6QR2h\", \"I0CNMjvTK2VusHFB+qnvw+19DzaDT6P0KNPxwBwp07KMQm\\n3HWTRNt9u6gKUmo5FHngoGte+TZdY66dAwCl0Pt+p1v18XlOB2KOQ\", \"ZKLXnhgikjOwYQxFr3oTb2MjsP6YqnSF9EpYpm\\niNySXiYmrYxVinHmK+5JBqoQCN2C3N24slZkYq+AYUTnNST7Ib2We3bBICOFd\", \"VUgtFITRW40T+0XZnIv8G1Kbaq/1av\\nfWI/ieKKxyiYp/ZNXaxc+ycgpsSsAJEuhb83bUkSBpGg9PvFEF0DXm4ah67Ja1SSTmvrC\", \"nrOsWZXIpciexMWRGoKrdv\\nd7Yzj9E8hiu+CGTC4T6+7FxVXJrjCg9zU9G2U6g7uxzoyjGj1wqkhxgvl9pPbz6/KqDRLOHCEwRF4\", \"qlWX hsJy4levxG\\ntifFt6n7DWaNSsOUf8Nwpi+d4fd7LQ7B5tW/y+/vVZziORueruCWO4LnfPhpJ70g18uyN7KyzrWy29rpE46r\", \"fjZGGt0\\nWDZYahObPbw6HjcqSOuzwRoJMxamQb2qsuQnaBS6Bhb5PAnY4SEA045odf/u9uC7mLom2KGNHHz6HrgEPas2UHoJLux\\n\", \"YvY1pza/29akuVQZQUvMA5yMFHHGYZLtTKtCGdVGwX0+QS6ovpV93xux4I/5TrD5 U8z9RmTdAx03R3MUhkHF7Zbv5eg\\nDNsVar+\", \"41YWG4VkV1ZXtsZRKJf0hvKNvrpH0e7fVKBdXljm5PXOSg2VdtkhhOpnKKSMcv6MbGWVi/svWLnc7Qim4A4M\\nDaz+bFVZmh3oGJ7\", \"WHvRQhWIcHUL+YJx+064+4IKXZJ/2a/+b2o7C8mJ3GGSBx831ADogg6MRWZx3UY19OZ8YMvpzmZE\\nBRZZnm4KgNpj+SQnf6pGzD2\", \"cmnRhzG60LSNPb17iKbdoUAE Mkgt2tlMKXpnt1r7qwsIoTt407cAdCEsUH7OU/AjfFmS\\nkKJZ7vC5HweqZPnhgJgZ6LYHlfiRzU\", \"R1xeDg8JG0nb0vb7LUE4nGPy39/TxIGos7WNwGpG1QVL/8pKjFdjwREaR8e5C\\nSTlQ7gxHV+G3FFvFGpA1p8cRFzlgE6khDLrSJI\", \"UkhkHMA3oFwwAzBNIKVXjToyxCogDqxWya0E1Hw5rVCS/zOCS1De2\\nXQbXs//g46TW0wTJwvgNbs0xLShf3X B+23meeEsMTCR0+\", \"igtMMMsh5K/vBUGcJA27ru/KM9qEBcseb/tqCkhhsdj1dn\\nH0HDmpgFf5DfVrjm+P6ickcF2b+Ojr9t7XHgFszap3COpEPGmeJqN\", \"OUTuU53tu/O774IBgqINMWvvG65yQwsEO06jRr\\nFPRUGb0eH6UM4vC7wbKajnfDuI/EXSgvuOSZ9wE8DeoeK/5We4pN7MSWoDl39\", \"gI/LBoNDKFYEYuAw/bhGp8nOwDKki4\\na16aYcBGRClpN 3ymrdurWsi7TjyFHXfgW8fZe4jXLuKRIk19lmL1gWyD+3bT3mkI2cU2\", \"OaY2C0fVHhtiBVaYbxBV8+k\\njK8q0Q70zf0r+xMHnewk9APFqUjguPguTdpCoH0VAQST9Mmriv/J12+Y+fL6H+jrtDY2zHPxTF85\", \"pA4bBBnLA7Qt9TK\\nCe6uuWu5yBqxOV3w2Oa4Pockv1gJzFbVnwlEUWnIjbWVIyo9vo4LBd03uJHPPIQbUp9kCP/Zw+Zblo42/ify\", \"Y+a +scw\\nl1q1dZ7Y0L92yJCKm9Qf6Q+1PBK+uU9pcuVTg/Imqcg5T7jFO5QCi88uwcorgQp+qoeFi0F9tnUecfDl6d0PSgAPnX9\", \"\\nXA0ny3bPwSiWOA8+uW73gesxnGTsNrtc1j85tail8N6m6S2tHXwOmM65J4XRZlzzeM4D/Rzzh13xpRA9kzm9T2cSHsX\\nEYmSW1X\", \"7WovrmYhdOh9K3DPwSyG4tD58cvC7X79UbOB+d17ieo7ZCj+NSLVQO1BqTK0QfE rdoVHGKfQG8Lc/ERQRqj1\\n32Mhi2/r5Ca7AW\", \"dqD7/3wgRdQTJSFXt/akpM44xu5DMTCISEFOLWiseSOBtzT6ssaq2Q35dCkXp5wVbWxkXAD7Gm34F\\nFXXyZrJWAx45Y40wj/0KDJ\", \"oEzXCuS4Cyiskx1EtYNNOtfDC5wngywmINFUnnW0NkdKSxmDJvrT6HkRKN8ftik7tP4Zv\\nTaTS28Z0fDmWJ+RjvZW+vtF6mrIzYg\", \"GOgdpZwG0ZOSKrXKrY3xpMO 16fXyawFfBosLzCty7uA57niPS76UXdbplgPan\\nIGFyceTg1MsNDsd8vszXd4KezN2VMaxvw+93s\", \"0Uk/3Mc+5MAj+UhXPi5UguXMhNo/CU7erzyxYreOlAI7ZzGhPk+oT9\\ng/MqWa5RpA2IBUaK/wgaNaHChfCcDj/J1qEl6YQQboixx\", \"p1IjQxiV9bRQzgwf31Cu2m/FuHTTkPCdxDK156pyFdhcgT\\npTNy7RPLDF0MBMGCSqGSIb3DQEJFTEGBAQBA AAAMF0GCSsGAQQBg\", \"jcRATFQHk4ATQBpAGMAcgBvAHMAbwBmAHQAIABT\\nAHQAcgBvAG4AZwAgAEMAcgB5AHAAdABvAGcAcgBhAHAAaABpAGMAIABQAHIA\", \"bwB2AGkAZABlAHIwggoXBgkqhkiG9w0\\nBBwagggoIMIIKBAIBADCCCf0GCSqGSIb3DQEHATAcBgoqhkiG9w0BDAEGMA4ECH63Q8x\", \"WHKhqAgIH0ICCCdDAo9x82r\\nwRM6s16wMo01glVedah n1COCP1FKmP6lQ3kjcHruIWlcKW+eCUpt41qs0LM3iFcPQj5x7675DeL\", \"L0AC2Ebu7Jhg0FGM\\nJZwHLbmJLyG0VSb1WhX2UfxNSdLrdZv8pmejB7DYdV3xAj8DBCRGfwwnbTQjFH9wUPga5U79Dvpqq+YVvUE\", \"Eci1N6tT\\nPu32LOOEvjoEtpskrHoKyqLGV7sSgM6xMIDcfVWbLb8fDcVS1JQRHbeOdGClFMDjwzr+eGWd+OyOZ6BydUGjIKAZpRp\", \" \\n177 CHAPTER 16 | Networking  \\n 0YTk5jjYUMNRbvBP1VPq9ASIh8pJnt/Kq1nqfj7EPatXJJUZAH35E6bSbLBnP0+5+xi\", \"m1l4HsB8066c4B3aTUXnLepP\\nRyMIn6Xh5ev0pF3aUc4ZlWgar57TzKUFBTkcH5OCbqZloQ7ZCDNc4C3WKVLSUOKLj3QOxJPrb6/\", \"nyXZHjki1tGKisb9\\nRLv4dkeMdRjsSwNRn6Cfdlk2qHWUCiWLlsLXFyMSM12qrSSfIIBRo0wbn1SEJagHqUmlF9UR5A6b 5OODIb\", \"Dq3cXH/q6\\nU09zVX/BxqxyZqEfeSAcvXjqImLWnZzbIgm0QH7jOtti/vEfvdzypdWH9V64PzQj/5B8P4ZpbQyWUgzKEIdx24WhTO\", \"c\\ndwNivkaEkGFTra3qw2dKO0RTVtx3bSgesHCumQDuDf8yafLfchWuqihYV7zvqW9BWrsa0W7yKNXLNqdlSz8KvuTnFff\\nOOHrJQ\", \"wBs+JKdMcKX5IR222RH3fp8Dp17y8hFEaPp4AqpuhHGALXOCwmuPt lUjuHRCUluh3BjaPPLNwLmSGfe0piOVh\\n4rTyJCfN4rlz0\", \"lWBAAfIHi47J9sTnSgEJgkTuemPJXssQ3Z/trcYdfhlYjelOBtS/5DW3wFmjNDilwVBQT66li5xUvc\\nWvZPx/scXgbgpsMThqguJ\", \"WtiPLR1SzusKCN4q7bVQ8D8ErHh5uMb5NmNRIZ/xNeqslqTU9A4bi0TE0FjEu28F0Wg4Cx\\niwqNM58xik9eni85t+S0Uo9wPV1V2\", \"Vdhe9LkO3PeoS TCau4D189DoViL44WPDQ+TCSvlPP7SFEwaBvUlGBWjxJWVb81\\nlkgRsol1bllUvIzN13V0LSiA0Nks9w9H8cQ1\", \"7ZRe2r7SpDDR6Rn5oLb9G98AyvlcgJfyUe1iZCUAUZGEU247KwePtXY\\nAlO47HbAJe0bOtM9zp7KyWxbImKCfxsPWv6CR6PH+ooH\", \"DBO9kXVpKaJCYWeYybSMuPufy/u/rMcIVO4oXVsdnjh4jAx\\npQOXowCAcN2+Q+XnqtiCr9Mzd 0q5ee7jsYuJF6LQRdNP04wIpwj\", \"pdggKyB7zURPeTXlV8vIjUs25+CoCxp+fCXfXKqe\\n2xxdbQ2zFbpKSbJdpbWad3F6MsFBGOKTdyK8EZODGApBtlo71kY6uOxKiBw\", \"JKd76zTMsPEQWOZphi2khpTxIVYONrmP\\nKjSO8zc4dTC8SW+d1kmCt4UYblwoeDCAYp2RiDHpgC+5yuBDCooT/6fG6GQpa1X0PiH\", \"2oUCpltZz2M4+1bH2HdTeBfc\\n1Mtj/hni LL8VdH0qcpS0KYPUxJFEg6IxxrWw1OBreY//6pJLm76nKiflzhz+Mt0RbQZqkPP/K9\", \"BxzQw//bW9Kh4iRQ3\\n7D9HNQG/GtrCEcbH4V4uUjbj34sEo0FC7gVvDob0Bik8l/c901zQZEydqe0DgHtGbY2xIZ2qqsQy4LDVfH\", \"NHqSLiNss\\nL8BJtxUyvnhiwHD7jmyCB6cWyFGtibRBehQzleioS16xvLph88CMGV3IH9By5QtXpDIB4vjhibE6coPkTm pDCB9xl\", \"TE\\n3TV4GBt5JLttkjfOkXAAx0xD523Adcy6FVe5QYuY1O8170O6l88YptozyWi5jVfDh+aDg9pjsw/aZ1hCURe9KDaB4gI\\nlW4ZE\", \"GKsf5e/xU+vuVxw374te/Y2aCChSj93XyC+Fjxe06s4yifVAYA0+HtLMGNHe/X0kPXvRnoa5kIu0yHrzViQrBb\\n/4Sbms617Gg1B\", \"FONks1JO2G0zIt8CouTqVmdtuH7tV0JZV/Nmg7NQ1X59XDC/JH2i 4jOu8OhnmIZFlTysS6e1qnqsGt\\n/0XcUyzPia8+UIAynXmy\", \"i8sWlUjy37w6YqapAfcs7B3TezqIwn7RgRasJpNBi7eQQqg5YLe6EYTxctKNkGpzeTBUiXN\\nXM4Gv3tIaMbzwlhUNbYWuNBsi/7X\", \"JPM5jMycINRbdPwYy19gRBs3pm0FoP2Lhl5mVAJ2R8a40Lo5g73wvt9Th+uB9/y\\nc196RryQe280yfgKiwUoFFcDnL6SoQTRCTl9\", \"5mF8zw1f3Hc7 QImhubgcLntXEndzSNN7ZIDSAB8HiDSR6CGYPNiCNAC\\n4hj+jUswoWIE257h+deWFTUvjTZmXH+XMoN6trqjdeC\", \"H0hePdmrIWVdr1uTIoO16TR6mFNm6Utzc0t5vVrcpnEh3w6a\\nmVHw5xmweW4S75ncN6vSPxGjtfuQ6c2RTG5NXZuWpnhXwOxgoBN\", \"4q/h99zVRvwwsF32Eyzx6GOYLmORgCkzke9eXjjX\\nWY83oysXx/aE9WCqt3en8zzRzzA1aO9 Yi88uv1OOqTvWEoGrf4e7SgjXO6\", \"hNjYE6EEvK+mMz6a9F3xSWsUlMsZPIIBe\\n8CEgNEhXKsa6xw7ljSx8Nz7zYG+u5rgXKFmSNvWvwasZyIfRXkccqODl17BaevbWp/\", \"ir3rJ/b9mOiV0UW8qIJ3zC6b1\\nlXU5pNuOODjqhKkjIHPGXiql+uBPVlfUy8Zbi4AntZAeNIB7HtUavVKX6CF7k9AFtRHIWK70+c\", \"FEw4yMZiQjaWeB3dt\\n16Fz6LZ8+c17ku B2wFuZQqYQkf3quWQVPwKj41gFYoFSwFfJ8L6TBcNHI2u3avtVp9ZbP9zArT8An9Ryr\", \"i/PwTSbPLT\\ncaz549b60/0k4c/qV4XRMuFsi29CXcMnLSCPpPKs71LTvsRXK6QUJd4fX/KnTiWargbS6tT6lR/bBqY/gFU1xWyKQ\", \"8x\\nij97vlQjffSKdcbj5JsnjSr8xAh9idfJ2FWZZUJReR9EU1twK7slyUivNLVY7bqroE6CzYaEDecRqfwIrFrzmH+g JoM\\n88wa\", \"GRC0JTvm8GpBX0eTb5bnMxJKPtH1GIffgyQLERO1jwjApr6SJEB4yV7x48CZPod9wE51OxUY2hEdAA5l7DBTJys\\ng5gn/nhY6ZzL\", \"0llb39yVyDEcZdmrji0ncEMdBDioGBV3mNz1DL398ZLdjG+xkneI3sgyzgm3cZZ1+/A2kloIEmOKJSe\\n0k/B1cyMB5QRnXpObF1v\", \"WXjauMVIKm0wlLY3YQ9I1vfr6y1o2DN+Vy0sumbIQrjDKqMDswH zAHBgUrDgMCGgQUHEWyD\\n7i5PbatVl3k0+S9WV3ZJRAEFFd7\", \"xcvfj1HpkOawyGnJdtcQ0KWPAgIH0A==\\\" ), \\n        \\\"testcertificate\\\" , \\n        X509KeyStorageFlags. Defa\", \"ultKeySet ); \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nHandshake  .NET 6.0  4.647 ms  \", \"1.00 19.27 KB  1.00 \\nHandshake  .NET 7.0  2.314 ms  0.50 9.56 KB  0.50 \\nAnother significant improvem\", \"ent for SslStream  in .NET 7 is support for OCSP stapling. When a client \\nhandshakes with the server\", \" and the server shares its certificate, a client that cares about validating it\\u2019s \\ntalking to exactl\", \"y who it intended to talk to needs to validate that certificate. In the days of yore, such \\nvalidati\", \"on was done with certificate revocation lists (CRL), where periodically the client would \\ndownload a\", \" giant list of certificates known to be revoked. Online Certificate Status Protocol (OCSP) is \\na new\", \"er protocol and mechanism that enabl es a client to get real -time information about a certificate; \", \"\\nwhile the client handshakes with the server and the server sends the client its certificate, the cl\", \"ient \\nthen connects to an \\u201cOCSP responder\\u201d and sends it a request to determine whether the certi fic\", \"ate is \\nconsidered good. OCSP has multiple issues of its own, however. In particular, it places a si\", \"gnificant \\nload on these OCSP responder servers, with every client making a real -time request to it\", \" about every \\ncertificate encountered, and also potential ly significantly increasing the time it ta\", \"kes the client to \\nestablish a connection. OCSP stapling offers a solution to this. Rather than a cl\", \"ient issuing a request to  \\n178 CHAPTER 16 | Networking  \\n the OCSP responder, the server itself con\", \"tacts the OCSP responder and gets a signed ticke t from the \\nOCSP responder stating that the server\\u2019\", \"s certificate is good and will be for some period of time. When \\na client handshakes with the server\", \", the server can then \\u201cstaple\\u201d (include) this signed ticket as part of \\nits response to the client, \", \"giving t he validation to the client directly rather than the client needing to \\nmake a separate rou\", \"ndtrip to the OCSP responder. This reduces overheads for everyone involved. \\ndotnet/runtime#67011  a\", \"dds support for OCSP stapling to SslStream  client usage on Linux, with \\ndotnet/runtime#69833  addin\", \"g the Linux server -side counterpart, and dotnet/runtime#71570  adds \\nclient -side support for Windo\", \"ws.  \\nThe aforementioned changes are primarily about the performance of opening a connection. \\nAddit\", \"ional work has been done to improve that further in other ways. dotnet/runtime#69527  gets rid \\nof a\", \"llocations associated with several SafeHandle  instances that were being created unnecessarily on \\nL\", \"inux as part of establishing a TLS connection. This highlights the benefits of doing profiling  on \\n\", \"multiple platforms, as while these SafeHandle s were necessary in the Windows implementation, they \\n\", \"were fairly meaningless in the Linux implementation (due to differences between SChannel and \\nOpenSS\", \"L), and were only brought along for the ride because of  how the platform -abstraction layer \\n(PAL) \", \"was defined to reuse most of the SslStream  code across platforms. And dotnet/runtime#68188  \\navoids\", \" several collections allocated as part of the TLS han dshake. This one is particularly interesting a\", \"s \\nit\\u2019s come up multiple times in the past in various libraries. Imagine you have a lazily initializ\", \"ed \\nproperty like this:  \\nprivate List<T>? _items;  \\npublic List<T> Items => _items ??= new List<T>(\", \");  \\nAnd then some code in the same implementation comes along and wants to read the contents of \\nth\", \"ese items. That code might look like:  \\nif (Items.Count > 0) { ... }  \\nbut the very act of accessing\", \" Items  just to check its count forces the collection into existence (with a  0 \\nCount ). If the cod\", \"e instead checks:  \\nif (_items is List<T> items && items. Count > 0) { ... }  \\nIt can save that unne\", \"cessary collection allocation. The approach is made even simpler with C# pattern \\nmatching:  \\nif (_i\", \"tems is { Count: > 0 }) items) { ... }  \\nThis is one of those things that\\u2019s incredibly obvious once \", \"you \\u201csee\\u201d it and realize what\\u2019s happening, \\nbut you often miss until it jumps out at you in a profil\", \"er.  \\ndotnet/runtime#69098  is another go od example of how profiling can lead to insights about \\nal\", \"locations that can be removed. Application -Layer Protocol Negotation (ALPN) allows code \\nestablishi\", \"ng a TLS connection to piggy -back on the roundtrips that are being used for the TLS \\nhandshake anyw\", \"ay to negotiate some higher -level protocol that will end up being used as well. A very \\ncommon use \", \"-case, for example, is for an HTTPS client/server to negotiate which version of HTTP \\nshould be used\", \". This information is exposed from SslStream  as an SslApplicati onProtocol  struct \\nreturned from i\", \"ts NegotiatedApplicationProtocol  property, but as the actual negotiated protocol \\ncan be arbitrary \", \"data, SslApplicationProtocol  just wraps a byte[] . The implementation had been  \\n179 CHAPTER 16 | N\", \"etworking  \\n dutifully allocating a byte[]  to hold the bytes  passed around as part of ALPN, since \", \"we need such a \\nbyte[]  to store in the SslApplicationProtocol . But while the byte data can be arbi\", \"trary, in practice \\nby far the most common byte sequences are equivalent to \\u201chttp/1.1\\u201d for HTTP/1.1,\", \" \\u201ch2\\u201d for HTTP/2, \\nand \\u201ch3\\u201d for HTTP/3. Thus, it makes sense to special -case those values and use a\", \" reusable cached \\nbyte[]  singleton when one of those values is needed. If SslApplicationProtocol  e\", \"xposed the \\nunderlying byte[]  directly to consumers, we\\u2019d be hesitant to use such si ngletons, as d\", \"oing so would \\nmean that if code wrote into the byte[]  it would potentially be changing the value f\", \"or other \\nconsumers in the same process. However, SslApplicationProtocol  exposes it as a \\nReadOnlyM\", \"emory<byte> , which is only mutable via unsafe c ode (using the \\nMemoryMarshal.TryGetArray  method),\", \" and once you\\u2019re employing unsafe code to do \\u201cbad\\u201d things,\\\" \\nall bets are off anyway. dotnet/runtime\", \"#63674  also removes allocations related to A LPN, in this case \\navoiding the need for a byte[]  all\", \"ocation on Linux when setting the negotiated protocol on a client \\nSslStream . It uses stack memory \", \"instead of an array allocation for protocols up to 256 bytes in length, \\nwhich is way larger than an\", \"y in known use, and thus doesn\\u2019t bother to do anything fancy for the \\nfallback path, which will neve\", \"r be used in practice. And dotnet/runtime#69103  further avoids ALPN -\\nrelated allocations and work \", \"on Windows by entirely skipping some unnecessary code paths: various \\nmethods can be invoked multipl\", \"e times during a TLS handshake,  but even though the ALPN -related \\nwork only needed to happen once \", \"the first time, the code wasn\\u2019t special -casing it and was instead \\nrepeating the work over and over\", \".  \\nEverything discussed thus far was about establishing connections. What about the performan ce of\", \" \\nreading and writing on that connection? Improvements have been made there, too, in particular \\naro\", \"und memory management and asynchrony. But first we need some context.  \\nWhen async/await  were first\", \" introduced, Task  and Task<TResult>  were the only game i n town; while \\nthe pattern -based mechani\", \"sm the compiler supports for arbitrary \\u201ctask -like\\u201d types enabled async  \\nmethods to return other ty\", \"pes, in practice it was only tasks (which also followed our guidance). We \\nsoon realized, however, t\", \"hat a significant num ber of calls to a significant number of commonly -used \\nasync APIs would actua\", \"lly complete synchronously. Consider, for example, a method like \\nMemoryStream.ReadAsync : MemoryStr\", \"eam  is backed entirely by an in -memory buffer, so even though \\nthe operation is \\u201cas ync,\\u201d every ca\", \"ll to it completes synchronously, as the operation can be performed \\nwithout doing any potentially l\", \"ong -running I/O. Or consider FileStream.ReadAsync . By default \\nFileStream  employs its own interna\", \"l buffer. If you issue a call to FileStream.Rea dAsync  with your \\nown buffer and ask for only, say,\", \" 16 bytes, under the covers FileStream.ReadAsync  will issue the \\nactual native call with its own mu\", \"ch larger buffer, which by default is 4K. The first time you issue your \\n16-byte read, actual I/O wi\", \"ll be req uired and the operation is likely to complete asynchronously. But \\nthe next 255 calls you \", \"make could simply end up draining the remainder of the data read into that 4K \\nbuffer, in which case\", \" 255 of the 256 \\u201casync\\u201d operations actually complete synchronously. If the \\nmethod returns a Task<in\", \"t> , every one of those 255 synchronously -completing calls could still end \\nup allocating a Task<in\", \"t> , just to hand back the int that\\u2019s already known. Various techniques were \\ndevised to minimize th\", \"is, e.g.  if the int is one of a few well -known values (e.g. -1 through 8), then the \\nasync method \", \"infrastructure will hand back a pre -allocated and cached Task<int>  instance for that \\nvalue, and v\", \"arious stream implementations (including FileStream ) would cache the previously -\\nreturned Task<int\", \">  and hand it back for the next call as well if the next call yielded exactly the same \\nnumber of b\", \"ytes. But those optimizations don\\u2019t fully mitigate the issue. Instead, we introduced the \\nValueTask<\", \"TResult>  struct and provided the necessary \\u201cbuilder\\u201d t o allow async  methods to return  \\n180 CHAPT\", \"ER 16 | Networking  \\n them. ValueTask<TResult>  was simply a discrimated union between a TResult  an\", \"d Task<TResult> . If \\nan async method completed asynchronously (or if it failed synchronously), well\", \", it would simply \\nallocate the Task<TResult>  as it otherwise would have and return that task wrapp\", \"ed in a \\nValueTask<TResult> . But if the method actually completed synchronously and successfully, i\", \"t would \\ncreate a ValueTask<TResult>  that just wrapped the resulting TResult , which then eliminate\", \"s all \\nallocat ion overhead for the synchronously -completing case. Yay, everyone\\u2019s happy. Well, alm\", \"ost \\neveryone. For really hot paths, especially those lower down in the stack that many other code p\", \"aths \\nbuild on top of, it can also be beneficial to avoid the allocations even for the asynchronousl\", \"y \\ncompleting case. To address that, .NET Core 2.1 saw the introduction of the \\nIValueTaskSource<TRe\", \"sult>  interface along with enabling ValueTask<TResult>  to wrap an instance \\nof that interface in a\", \"ddition to a TResult  or a Task<TRes ult>  (at which point it also became \\nmeaningful to introduce a\", \" non -generic ValueTask  and the associated IValueTaskSource ). Someone \\ncan implement this interfac\", \"e with whatever behaviors they want, although we codified the typical \\nimplementation of the core as\", \" ync logic into the ManualResetValueTaskSourceCore  helper struct, \\nwhich is typically embedded into\", \" some object, with the interface methods delegating to \\ncorresponding helpers on the struct. Why wou\", \"ld someone want to do this? Most commonly, it\\u2019s to be \\nable t o reuse the same instance implementing\", \" this interface over and over and over. So, for example, \\nSocket  exposes a ValueTask<int> ReceiveAs\", \"ync  method, and it caches a single instance of an \\nIValueTaskSource<int>  implementation for use wi\", \"th such receives. As lo ng as you only ever have \\none receive pending on a given socket at a time (w\", \"hich is the 99.999% case), every ReceiveAsync  call \\nwill either return a ValueTask<int>  wrapped ar\", \"ound an int value or a ValueTask<int>  wrapped \\naround that reusable IValueTaskSource<int> , making \", \"all use of ReceiveAsync  ammortized \\nallocation -free (there is another instance used for SendAsync \", \", such that you can have a concurrent \\nread and write on the socket and still avoid allocations). Ho\", \"wever, implementing this suppor t is still \\nnon-trivial, and can be super hard when dealing with an \", \"operation that\\u2019s composed of multiple \\nsuboperations, which is exactly where async/await  shine. Thu\", \"s, C# 10 added support for overriding \\nthe default builder that\\u2019s used on an individual asyn c metho\", \"d (e.g.  such that someone could provide \\ntheir own builder for a ValueTask<int> -returning method i\", \"nstead of the one that allocates Task<int>  \\ninstances for asynchronous completion) and .NET 6 inclu\", \"ded the new \\nPoolingAsyncValueTaskMethodBuilder  and PoolingAsyncValueTaskMethodBuilder<>  types. Wi\", \"th \\nthose, an async  method like:  \\npublic async ValueTask< int> ReadAsync (Memory< byte> buffer) { \", \"... }  \\ncan be changed to be:  \\n[AsyncMethodBuilder (typeof(PoolingAsyncValueTaskMethodBuilder<>))] \", \" \\npublic async ValueTask< int> ReadAsync (Memory< byte> buffer) { ... }  \\nwhich will cause the C# co\", \"mpiler to emit the implementation of this method using \\nPoolingAsyncValueTaskMethodBuilder<int>  ins\", \"tead of the default \\nAsyncValueTaskMethodBuilder<int> . The implementation of \\nPoolingAsyncVa lueTas\", \"kMethodBuilder<TResult>  is true to its name; it employs pooling to avoid \\nmost  of the allocation a\", \"synchronous completion would otherwise experience (I say \\u201cmost\\u201d because \\nthe pooling by design tries\", \" to balance all the various costs involved and may sti ll sometimes allocate), \\nand makes it easy fo\", \"r methods implemented with async /await  to reap those benefits. So, if this was \\nall introduced in \", \"the last release, why am I talking about it now? Pooling isn\\u2019t free. There are various  \\n181 CHAPTER\", \" 16 | Networking  \\n tradeoffs involved in its us age, and while it can make microbenchmarks look rea\", \"lly good, it can also \\nnegatively impact real -world usage, e.g.  by increasing the cost of garbage \", \"collections that do occur by \\nincreasing the number of Gen2 to Gen0 references that exist. As such, \", \"while the  functionality is \\nvaluable, we\\u2019ve been methodical in where and how we use it, choosing to\", \" do so more slowly and only \\nemploying it after sufficient analysis deems it\\u2019s worthwhile.  \\nSuch is\", \" the case with SslStream . With dotnet/runtime#69418 , two core and hot async  methods on \\nSslStream\", \" \\u2019s read path were annotated to use pooling. A microbenchmark shows what I mean when I \\nwrote this c\", \"an make microbenchmarks look re ally good (focus on the allocation columns). This \\nbenchmark is repe\", \"atedly issuing a read (that will be forced to complete asynchronously because \\nthere\\u2019s no available \", \"data to satisfy it), then issuing a write to enable that read to complete, and then \\nawait ing the r\", \"ead\\u2019s completion; every read thus completes asynchronously.  \\nprivate SslStream _sslClient, _sslServ\", \"er;  \\nprivate readonly  byte[] _buffer = new byte[1]; \\nprivate readonly  SslServerAuthenticationOpti\", \"ons _options = new \\nSslServerAuthenticationOptions  \\n{ \\n    ServerCertificateContext = SslStreamCert\", \"ificateContext. Create(GetCertificate (), null), \\n}; \\n     \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n\", \"    using var listener = new Socket(AddressFamily. InterNetwork , SocketType. Stream, \\nProtocolType.\", \" Tcp); \\n    listener. Bind(new IPEndPoint (IPAddress. Loopback , 0)); \\n    listener. Listen(1); \\n \\n \", \"   var client = new Socket(AddressFamily. InterNetwork , SocketType. Stream, \\nProtocolType. Tcp); \\n \", \"   client.Connect(listener. LocalEndPoint ); \\n \\n    _sslClient = new SslStream (new NetworkStream (c\", \"lient, ownsSocket: true), \\nleaveInnerStreamOpen: true, delegate  { return true; }); \\n    _sslServer \", \"= new SslStream (new NetworkStream (listener. Accept(), ownsSocket:  true), \\nleaveInnerStreamOpen: t\", \"rue, delegate  { return true; }); \\n \\n    Task.WaitAll( \\n        _sslClient. AuthenticateAsClientAsyn\", \"c (\\\"localhost\\\" , null, SslProtocols. None, \\ncheckCertificateRevocation: false), \\n        _sslServer.\", \" AuthenticateAsServerAsync (_options) ); \\n} \\n \\n[GlobalCleanup]  \\npublic void Cleanup() \\n{ \\n    _sslC\", \"lient. Dispose(); \\n    _sslServer. Dispose(); \\n} \\n \\n[Benchmark]  \\npublic async Task ReadWriteAsync (\", \") \\n{ \\n    for (int i = 0; i < 1000; i++) \\n    { \\n        ValueTask< int> read = _sslClient. ReadAsyn\", \"c (_buffer);   \\n182 CHAPTER 16 | Networking  \\n         await _sslServer. WriteAsync (_buffer);  \\n   \", \"     await read;  \\n    } \\n} \\nMethod  Runtime  Mean  Ratio  Code Size  Allocated  Alloc Ratio  \\nReadW\", \"riteAsync  .NET 6.0  68.34 ms  1.00 510 B  336404 B  1.000  \\nReadWriteAsync  .NET 7.0  69.60 ms  1.0\", \"2 514 B  995 B  0.003  \\nOne final change related to reading and writing performance on an SslStream \", \". I find this one \\nparticularly interesting, as it highlights a new and powerful C# 11 and .NET 7 fe\", \"ature: static abstract \\nmembers in interfaces. SslStream , as with every Stream , exposes both synch\", \"ronous and asynchronous \\nmethods for reading and writing. And as you may be aware, the code within S\", \"slStream  for \\nimplementing reads and writes is not particularly small. Thus, we really want to avoi\", \"d having to \\ndupli cate all of the code paths, once for synchronous work and once for asynchronous w\", \"ork, when in \\nreality the only place that bifurcation is needed is at the leaves where calls into th\", \"e underlying Stream  \\nare made to perform the actual I/O. Historically, we\\u2019ve had two different mech\", \"anisms we\\u2019ve employed \\nin dotnet/runtime  for handling such unification. One is to make all methods \", \"async , but with an \\nadditional bool useAsync  parameter that gets fed through the cal l chain, then\", \" branching based on it \\nat the leaves, e.g.  \\npublic static void Work(Stream s) =>  \\n    A(s, useAsy\", \"unc: false).GetAwaiter ().GetResult (); // GetResult() to propagate any \\nexceptions  \\n \\npublic stati\", \"c Task WorkAsync (Stream S) =>  \\n    A(s, useAsync: true); \\n \\ninternal  static async Task A(Stream s\", \", bool useAsync)  \\n{ \\n    ... \\n    await B(s, useAsync);  \\n    ... \\n} \\n \\nprivate static async Task B\", \"(Stream s, bool useAsync)  \\n{ \\n    ... \\n    int bytesRead = useAsync ?  \\n        await s. ReadAsync \", \"(buffer) :  \\n        s.Read(buffer. Span); \\n    ... \\n} \\nThis way most of the logic and code is share\", \"d, and when useAsync is false, everything completes \\nsynchronously and so we don\\u2019t pay for allocatio\", \"n that might otherwise be associated with the async -\\nness. The other approach is similar in spirit,\", \" but instead of a bool  parameter, taking advantage of \\ngeneric specialization and interface -implem\", \"enting structs. Consider an interface like:  \\ninterface  IReader \\n{ \\n    ValueTask< int> ReadAsync (\", \"Stream s, Memory< byte> buffer);  \\n}  \\n183 CHAPTER 16 | Networking  \\n We can then declare tw o imple\", \"mentations of this interface:  \\nstruct SyncReader : IReader  \\n{ \\n    public ValueTask< int> ReadAsyn\", \"c (Stream s, Memory< byte> buffer) =>  \\n        new ValueTask< int>(s.Read(buffer. Span)); \\n} \\n \\nstr\", \"uct AsyncReader : IReader  \\n{ \\n    public ValueTask< int> ReadAsync (Stream s, Memory< byte> buffer)\", \" =>  \\n        s.ReadAsync (buffer);  \\n} \\nThen we can redeclare our earlier example as:  \\npublic stat\", \"ic void Work(Stream s) =>  \\n    A(stream, default(SyncReader)). GetAwaiter ().GetResult (); // to pr\", \"opagate any exceptions  \\n \\npublic static Task WorkAsync (Stream S) =>  \\n    A(s, default(AsyncReader\", \"));  \\n \\ninternal  static async Task A<TReader>(Stream s, TReader reader) where TReader : IReader  \\n{\", \" \\n    ... \\n    await B(s, reader);  \\n    ... \\n} \\n \\nprivate static async Task B<TReader>(Stream s, TR\", \"eader reader)  where TReader : IReader  \\n{ \\n    ... \\n    int bytesRead = await reader. ReadAsync (s,\", \" buffer);  \\n    ... \\n} \\nNote that the generic constraint on the TReader  parameter here allows the i\", \"mplementation to invoke \\nthe interface methods, and passing the structs as a generic avoids boxing. \", \"One code path supporting \\nboth sync and async implementations.  \\nThis latter generic approach is how\", \" SslStream  has historically handled the unification of its sync and \\nasync implementations. It gets\", \" better in .NET 7 with C# 11 now that we have static abstract methods \\nin interfaces. We can instead\", \" declare our interface as (note the static abstract  addition):  \\ninterface  IReader \\n{ \\n    static \", \"abstract  ValueTask< int> ReadAsync (Stream s, Memory< byte> buffer);  \\n} \\nour types as (note the st\", \"atic  addition):  \\nstruct SyncReader : IReader  \\n{ \\n    public static ValueTask< int> ReadAsync (Str\", \"eam s, Memory< byte> buffer) =>  \\n        new ValueTask< int>(s.Read(buffer. Span)); \\n} \\n \\nstruct As\", \"yncReader : IReader   \\n184 CHAPTER 16 | Networking  \\n { \\n    public static ValueTask<int> ReadAsync \", \"(Stream s, Memory< byte> buffer) =>  \\n        s.ReadAsync (buffer);  \\n} \\nand our consuming methods a\", \"s (note the removal of the parameter and the switch to calling static \\nmethods on the type parameter\", \"):  \\npublic static void Work(Stream s) =>  \\n    A<SyncReader>(stream). GetAwaiter ().GetResult (); /\", \"/ to propagate any exceptions  \\n \\npublic static Task WorkAsync (Stream S) =>  \\n    A<AsyncReader>(s)\", \";  \\n \\ninternal  static async Task A<TReader>(Stream s) where TReader : IReader  \\n{ \\n    ... \\n    awa\", \"it B<TReader>(s);  \\n    ... \\n} \\n \\nprivate static async Task B<TReader>(Stream s) where TReader : IRe\", \"ader  \\n{ \\n    ... \\n    int bytesRead = await TReader. ReadAsync (s, buffer);  \\n    ... \\n} \\nNot only \", \"is this cleaner, but from a performance perspective we no longer need to pass around the  \\ndummy gen\", \"eric parameter, which is general goodness, but for an async method it\\u2019s particularly \\nbeneficial bec\", \"ause the state machine type ends up storing all parameters as fields, which means every \\nparameter c\", \"an increase the amount of allocation incurred by  an async method if the method ends up \\ncompleting \", \"asynchronously. dotnet/runtime#65239  flipped SslStream  (and NegotiateStream ) to \\nfollow this appr\", \"oach. It\\u2019s also used in multiple other places now throughout dotnet/runtime. \\ndotnet/runtime#69278  \", \"from [@teo -tsirpanis](https://github.com/teo -tsirpanis) changed the \\nRandomAccess  class\\u2019 implemen\", \"tation for Windows and the ThreadPool \\u2019s mech anism for invoking work \\nitems to use the same approac\", \"h. Further, dotnet/runtime#63546  did the same in the Regex  \\nimplementation, and in particular in t\", \"he new RegexOptions.NonBacktracking  implementation, as a \\nway to abstract over DFA and NFA -based o\", \"perations using the same code (this technique was since \\nfurther utilized in NonBacktracking , such \", \"as by dotnet/runtime#71234  from \\n[@olsaarik](https://github.com/olsaarik)). And potentially most im\", \"pactfully, dotnet/runtime#73768  did \\nso with IndexOfAny  to abstract away the differences between I\", \"ndexOfAny  and IndexOfAnyExcept  \\n(also for the Last  variants). With the introduction of the {Last}\", \"IndexOfAnyExcept  variations \\npreviously mentioned, we now have four different variants of IndexOfAn\", \"y  with essentially the same \\nfunctionality: searching forward or  backwards, and with equality or i\", \"nequality. While more challenging \\nto try to unify the directional aspect, this PR utilized this sam\", \"e kind of generic specialization to hide \\nbehind an interface the ability to negate the comparison; \", \"the core implementations  of these methods \\ncan then be implemented once and passed either a Negate \", \" or DontNegate  implementation of the \\ninterface. The net result is not only that the new Except  va\", \"rieties immediately gained all of the \\noptimizations of the non -Except  varieties, but a lso the go\", \"al of trying to make everything consistent \\nresulted in finding places where we were missing optimiz\", \"ation opportunities in existing methods \\n(gaps that the PR also rectified).   \\n185 CHAPTER 16 | Netw\", \"orking  \\n private static readonly  string s_haystack = new \\nHttpClient ().GetStringAs ync(\\\"https://w\", \"ww.gutenberg.org/files/1661/1661 -0.txt\\\").Result; \\n \\n[Benchmark]  \\npublic int LastIndexOfAny () => s\", \"_haystack. AsSpan().LastIndexOfAny (';', '_'); \\nMethod  Runtime  Mean  Ratio  \\nLastIndexOfAny  .NET \", \"6.0  9.977 us  1.00 \\nLastIndexOfAny  .NET 7.0  1.172 us  0.12 \\nLet\\u2019s move up the stack to HTTP. Most\", \" of the folks focusing on networking in .NET 7 were focused on \\ntaking the preview support for HTTP/\", \"3 that shipped in .NET 6 and making it a first -class supported \\nfeature in .NET 7. That included fu\", \"nctional improve ments, reliability and correctness fixes, and \\nperformance improvements, such that \", \"HTTP/3 can now be used via HttpClient  on both Windows \\nand Linux (it depends on an underlying QUIC \", \"implementation in the msquic component, which isn\\u2019t \\ncurrently available for macOS). However, there \", \"were significant improvements throughout the HTTP \\nstack, beyond HTTP/3.  \\nOne aspect of HttpClient \", \" that cuts across all versions of HTTP is support for handling and \\nrepresenting headers. While sign\", \"ificant improvements went into previou s releases to trim down the \\nsize of the data structures used\", \" to store header information, further work on this front was done for \\n.NET 7. dotnet/runtime#62981 \", \", for example, improves the data s tructure used to store headers. One of \\nthe things HttpHeaders  n\", \"eeds to deal with is that there\\u2019s no defined limit to the number of headers \\nthat can be sent with a\", \"n HTTP request or response (though in order to mitigate possible denial of \\nservice attacks, th e im\", \"plementation has a configurable limit for how many bytes of headers are \\naccepted from the server), \", \"and thus it needs to be able to handle an arbitrary number of them and to \\ndo so with efficient acce\", \"ss. As such, for the longest time HttpHeaders  has used  a Dictionary<,>  to \\nprovide O(1)  lookup i\", \"nto these headers. However, while it\\u2019s valid to have large numbers of headers, \\nit\\u2019s most common to \", \"only have a handful, and for only a few items, the overheads involved in a hash \\ntable like Dictiona\", \"ry<>  can be more than just storing the elements in an array and doing an O(N)  \\nlookup by doing a l\", \"inear search through all the elements (algorithmic complexity ignores the \\n\\u201cconstants\\u201d involved, so \", \"for a small N, an O(N)  algorithm might be much faster and lighterweight than \\nan O(1) ). This PR ta\", \"kes advantage of that and teaches HttpHeaders  how to use either an array or a \\ndictionary; for comm\", \"on numbers of headers (the current threshold is 64), it just uses an array, and in \\nthe rare case wh\", \"ere that threshold is exceeded, it grad uates into a dictionary. This reduces the \\nallocation in Htt\", \"pHeader  in all but the most niche cases while also making it faster for lookups.  \\nAnother header -\", \"related size reduction comes in dotne t/runtime#64105 . The internal representation of \\nheaders invo\", \"lves a HeaderDescriptor  that enables \\u201cknown headers\\u201d (headers defined in the HTTP \\nspecifications o\", \"r that we\\u2019re otherwise aware of and want to optimize) to share common data, e.g.  if a \\nresponse hea\", \" der matches one of these known headers, we can just use the header name string \\nsingleton rather th\", \"an allocating a new string for that header each time we receive it. This \\nHeaderDescriptor  accomoda\", \"ted both known headers and custom headers by having two fiel ds, one \\nfor known header data (which w\", \"ould be null for custom headers) and one for the header name. \\nInstead, this PR employs a relatively\", \" -common technique of having a single object  field that then \\nstores either the known header inform\", \"ation or the name, sin ce the known header information itself \\nincludes the name, and thus we don\\u2019t \", \"need the duplication. At the expense of a type check when we  \\n186 CHAPTER 16 | Networking  \\n need t\", \"o look up information from that field, we cut the number of fields in half. And while this \\nHeaderDe\", \"scriptor  is itself a struct, it\\u2019s stored in header collections, and thus by cutting the size of the\", \" \\nHeaderDescriptor  in half, we can significantly reduce the size of those collections, especially w\", \"hen \\nmany custom headers are involved.  \\nprivate readonly  string[] _strings = new[] { \\\"Access-Contr\", \"ol-Allow-Credentials\\\" , \\\"Access-\\nControl-Allow-Origin\\\", \\\"Cache-Control\\\" , \\\"Connection\\\" , \\\"Date\\\", \\\"Se\", \"rver\\\"  }; \\n \\n[Benchmark]  \\npublic HttpResponseHeaders GetHeaders () \\n{ \\n    var headers = new HttpRe\", \"sponseMessage ().Headers; \\n    foreach (string s in _strings)  \\n    { \\n        headers. TryAddWithou\", \"tValidation (s, s); \\n    } \\n    return headers;  \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc \", \"Ratio  \\nGetHeaders  .NET 6.0  334.4 ns  1.00 664 B  1.00 \\nGetHeaders  .NET 7.0  213.9 ns  0.64 360 B\", \"  0.54 \\nSimilarly focused on allocation, dotnet/runtime#63057  removes two fields from the \\nHttpHead\", \"erValueCollection<T>  collection type, which provides the concrete implementation for \\nICollection<T\", \">  properties like HttpContentHeaders.ContentEncoding , \\nHttpRequestHeaders.UserAgent , and HttpResp\", \"onseHeaders.Server . The initial design and \\nimplementation of this type were overly flexible, with \", \"a mechanism for custom validation of values, \\nwhich entailed multip le fields for storing things lik\", \"e an Action<>  callback to use for validation. But as \\nit turns out in practice, that validation was\", \" only used for one specific consumer, and so rather than \\nmaking everyone pay for the extra space th\", \"at wasn\\u2019t typically used, t he validation was instead \\nextracted out to just the call sites it was r\", \"equired.  \\nA more focused allocation reduction comes in dotnet/runtime#63641 . The shared internal u\", \"tility \\nmethod HttpRulePa rser.GetHostLength  was using string.Substring  in order to hand back the \", \"\\nparsed host information, but only some of the callers needed this. Rather than making everyone pay \", \"\\nfor something that not everyone needed, this logic was moved into only the call sites  that needed \", \"it.  \\nOther small allocation improvements were also made outside of headers. For example, when new \\n\", \"HTTP/1 and HTTP/2 connections are created, the implementation queues a work item to the thread \\npool\", \" to handle the actual creation, primarily to es cape locks that might be held higher in the call \\nst\", \"ack. To do so, it used Task.Run . And while normally Task.Run  is a fine thing to use, in this case \", \"there \\nwere two issues: the resulting Task  was being ignored, such that any unexpected exceptions w\", \"ould \\njust be eaten, and the lambda being passed to Task.Run  was closing over this  and a local, wh\", \"ich \\nmeans the C# compiler will have generated code to allocate both a \\u201cdisplay class\\u201d (an object to\", \" store \\nthe state being passed in) for the closure and then also a del egate to a method on that dis\", \"play class. \\nInstead, dotnet/runtime#68750  switches it to use ThreadPool.QueueUserWorkItem , using \", \"the \\noverload that takes a generic TState , and passing in a tuple o f all required state in order t\", \"o avoid \\nboth superfluous allocations.   \\n187 CHAPTER 16 | Networking  \\n Folks using HTTP often need\", \" to go through a proxy server, and in .NET the ability to go through an \\nHTTP proxy is represented v\", \"ia the IWebProxy  interface; it has three members, GetProxy  for getting the \\nUri of the proxy to us\", \"e for a given destination Uri, the IsBypassed  method which says whether a \\ngiven Uri should go thro\", \"ugh a proxy or not, and then a Credentials  property to be used when \\naccessing the target proxy. Th\", \"e canonical implementati on of IWebProxy  provided in the core libraries \\nis the aptly named WebProx\", \"y . WebProxy  is fairly simple: you give it a proxy Uri, and then calls to \\nGetProxy  return that pr\", \"oxy Uri if the destination isn\\u2019t to be bypassed. Whether a Uri should be \\nbypassed is de termined by\", \" two things (assuming a non -null proxy Uri was provided): did the \\nconstructor of the WebProxy  spe\", \"cify that \\u201clocal\\u201d destinations should be bypassed (and if so, is this \\ndestination local), or does t\", \"his destination address match any of any number o f regular expressions \\nprovided. As it turns out, \", \"this latter aspect has been relatively slow and allocation -heavy in all previous \\nreleases of .NET,\", \" for two reasons: every call to check whether an address was bypassed was recreating \\na Regex  insta\", \"nce for eve ry supplied regular expression, and every call to check whether an address \\nwas bypassed\", \" was deriving a new string  from the Uri to use to match against the Regex . In .NET 7, \\nboth of tho\", \"se issues have been fixed, yielding significant improvements if you rely on this regular \\nexpression\", \" functionality. dotnet/runtime#73803  from \\n[@onehourlate](https://gith ub.com/onehourlate) changed \", \"the handling of the collection of these \\nRegex  instances. The problem was that WebProxy  exposes an\", \" ArrayList  (this type goes back to the \\nbeginning of .NET and was created pre -generics), which the\", \" consumer could modify, and so WebProxy  \\nhad to assume the collection was modified between uses and\", \" addressed that by simply creating new \\nRegex  instances on every use; not good. Instead, this PR cr\", \"eates a custom ArrayList -derived type \\nthat can track all relevant mutations, and then only if the \", \"collection is changed (which is incredibly \\nrare, bordering on never) do the Regex  instances need t\", \"o be recreated. And dotnet/runtime#73807  \\ntakes advantage of stack allocation and the MemoryExtensi\", \"ons.TryWrite  method with string \\ninterpolation to format the text into stack memory, avoiding the s\", \"tring allocation. This, combined with \\nthe new Regex.IsMatch(ReadOnlySpan<char>)  overload that enab\", \"les us to match against that \\nstackalloc \\u2019d span, make s that aspect of the operation allocation -fr\", \"ee as well. Altogether, drastic \\nimprovements:  \\nprivate WebProxy _proxy = new WebProxy (\\\"http://doe\", \"sntexist\\\" , BypassOnLocal: false, new[] { \\n@\\\"\\\\.microsoft.com\\\" , @\\\"\\\\.dot.net\\\" , @\\\"\\\\.bing.com\\\"  }); \\np\", \"rivate Uri _destinatio n = new \\nUri(\\\"https://docs.microsoft.com/dotnet/api/system.net.webproxy\\\" ); \\n\", \" \\n[Benchmark]  \\npublic bool IsBypassed () => _proxy. IsBypassed (_destination);  \\nMethod  Runtime  M\", \"ean  Ratio  Allocated  Alloc Ratio  \\nIsBypassed  .NET 6.0  5,343.2 ns  1.00 7528 B  1.00 \\nIsBypassed\", \"  .NET 7.0  205.5 ns  0.04 - 0.00 \\nAlso related to HTTP, WebUtility \\u2019s HtmlDecode  method has improv\", \"ed for .NET 7. The implementation \\nhad been manually iterating through each character in the input l\", \"ooking for a '&' to be unescaped. \\nAny time you see s uch an open -coded loop looking for one or mor\", \"e specific characters, it\\u2019s a red flag \\nthat IndexOf  should be strongly considered. dotnet/runtime#\", \"70700  deletes the entire searching \\nfunction and r eplaces it with IndexOf , yielding simpler and m\", \"uch faster code (you can see other \\nimprovements to use IndexOf  variants in networking, such as dot\", \"net/runtime#71137 , which used  \\n188 CHAPTER 16 | Networking  \\n IndexOfAny  in HttpListener \\u2019s Handl\", \"eAuthentication  to search a header for certain kinds of \\nwhitespace):  \\nprivate string _encoded = W\", \"ebUtility. HtmlEncode (\\\"\\\"\\\" \\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eius\", \"mod tempor \\nincididunt ut labore et dolore magn a aliqua.  \\n    Condimentum vitae sapien pellentesqu\", \"e habitant. Vitae auctor eu augue ut lectus. Augue \\nlacus viverra vitae congue eu.  \\n    Tempus quam\", \" pellentesque nec nam aliquam sem. Urna nec tincidunt praesent semper \\nfeugiat nibh sed. Amet tellus\", \" cras adip iscing \\n    enim eu. Duis ultricies lacus sed turpis tincidunt. Et sollicitudin ac orci p\", \"hasellus \\negestas tellus rutrum tellus pellentesque.  \\n    \\\"\\\"\\\"); \\n \\n[Benchmark]  \\npublic string Html\", \"Decode () => WebUtility. HtmlDecode (_encoded);  \\nMethod  Runtime  Mean  Ratio  \\nHtmlDecode  .NET 6.\", \"0  245.54 ns  1.00 \\nHtmlDecode  .NET 7.0  19.66 ns  0.08 \\nThere have been a myriad of other performa\", \"nce -related improvements in networking as well, such as \\ndotnet/runtime#67881  which removed the us\", \"e of TcpClient  from FtpWebRequest ; \\ndotnet/runtime#68745  in WebSocket  which removed a parameter \", \"from one of the core async methods \\n(and since parameters end up on the state ma chine, if the async\", \" method yields this results in fewer \\nallocated bytes); and dotnet/runtime#70866  and dotnet/runtime\", \"#70900 , which replaced all remaining \\nuse of Marshal.PtrToStructure  in the core networking code wi\", \"th more efficient marshaling (e.g.  just \\nperforming casts). While Marshal.PtrToStructure  is valuab\", \"le when custom marshaling directives are \\nused and the runtime needs to be  involved in the conversi\", \"on, it\\u2019s also much more heavyweight than \\njust casting, which can be done when the native and manage\", \"d layouts are bit -for-bit compatible. As \\nwith the u8 example earlier, this comparison is hardly fa\", \"ir, but that\\u2019s exactly the point:  \\nprivate IntPtr _mem;  \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \", \"\\n    _mem = Marshal. AllocHGlobal (8); \\n    Marshal. StructureToPtr (new SimpleType { Value1 = 42, V\", \"alue2 = 84 }, _mem, false); \\n} \\n \\n[GlobalCleanup]  \\npublic void Cleanup() => Marshal. FreeHGlobal (_\", \"mem); \\n \\npublic struct SimpleType  \\n{ \\n    public int Value1; \\n    public int Value2; \\n} \\n \\n[Benchma\", \"rk (Baseline = true)] \\npublic SimpleType PtrToStructure () => Marshal. PtrToStructure <SimpleType>(_\", \"mem);  \\n \\n[Benchmark]  \\npublic unsafe SimpleType Cast() => *(SimpleType*) _mem;  \\n189 CHAPTER 16 | N\", \"etworking  \\n Method  Mean  Ratio  \\nPtrToStructure  26.6593 ns  1.000  \\nCast 0.0736 ns  0.003  \\nFor f\", \"olks using NegotiateStream , dotnet/runtime#71280  from \\n[@filipnavara](https://github.com/filipnava\", \"ra) will also be very welcome (this comes as part of a larger \\neffort, primarily in dotnet/runtime#7\", \"1777  from [@filipnavara](https://github.com/ filipnavara) and \\ndotnet/runtime#70720  from [@filipna\", \"vara](https://github.com/filipnavara), to expose the new \\nNegotiateAuthentication  class). It remove\", \"s a significant amount of allocation from a typical NTLM \\nhandshake by reusing a buffer rather than \", \"reallocating a new buffer for each of multiple phases of the \\nhandshake:  \\nprivate NetworkStream _cl\", \"ient, _server;  \\n \\n[GlobalSetup]  \\npublic void Setup() \\n{ \\n    using var listener = new Socket(Addre\", \"ssFamily. InterNetwork , SocketType. Stream, \\nProtocolType. Tcp); \\n    listener. Bind(new IPEndPoint\", \" (IPAddress. Loopback , 0)); \\n    listener. Listen(1); \\n \\n    var client = new Socket(AddressFamily.\", \" InterNetwork , SocketType. Stream, \\nProtocolType. Tcp); \\n    client.Connect(listener. LocalEndPoint\", \" ); \\n \\n    Socket server = listener. Accept(); \\n \\n    _client = new NetworkStream (client, ownsSocke\", \"t: true); \\n    _server = new NetworkStream (server, ownsSocket: true); \\n} \\n \\n[Benchmark]  \\npublic as\", \"ync Task Handshake () \\n{ \\n    using NegotiateStrea m client = new NegotiateStream (_client, leaveInn\", \"erStreamOpen: \\ntrue); \\n    using NegotiateStream server = new NegotiateStream (_server, leaveInnerSt\", \"reamOpen: \\ntrue); \\n    await Task. WhenAll(client. AuthenticateAsClientAsync (), \\nserver.Authenticat\", \"eAsServerAsync ()); \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nHandshake  .NET 6.0  \", \"1.905 ms  1.00 240.5 KB  1.00 \\nHandshake  .NET 7.0  1.913 ms  1.00 99.28 KB  0.41  \\n190 CHAPTER 17 |\", \" JSON  \\n CHAPTER  17 \\nJSON  \\nSystem.Text.Json  was introduced in .NET Core 3.0, and has seen a signi\", \"ficant amount of investment \\nin each release since. .NET 7 is no exception. New features in .NET 7 i\", \"nclude support for customizing \\ncontrac ts, polymorphic serialization , support for required members\", \" , support for DateOnly / TimeOnly , \\nsupport for IAsyncEnumerable<T>  and JsonDocument  in source g\", \"eneration, and support for \\nconfiguring MaxDepth in JsonWriterOptions . However, there have also bee\", \"n new features specifically \\nfocused on performance, and other changes about improving performance o\", \"f JSON handling in a \\nvariety of  scenarios.  \\nOne of the biggest performance pitfalls we\\u2019ve seen de\", \"velopers face with System.Text.Json  has to do \\nwith how the library caches data. In order to achiev\", \"e good serialization and deserialization \\nperformance when the source generator isn\\u2019t used, System.T\", \"ext.Json  uses reflection emit to \\ngenerate custom code for reading/writing members of the types bei\", \"ng processed. Instead of then \\nhaving to pay reflection invoke costs on every access, the library in\", \"curs a much larger one -time cost \\nper type to perform this code generation, but then all subsequent\", \" handling of these types is very \\nfast\\u2026 assuming the generated code is available for use. These gene\", \"rated handlers need to be stored \\nsomewhere, and the location that\\u2019s used for storing them is them i\", \"s JsonSeriali zerOptions . The \\nidea was intended to be that developers would instantiate an options\", \" instance once and pass it \\naround to all of their serialization/deserialization calls; thus, state \", \"like these generated handlers could \\nbe cached on them. And that works wel l when developers follow \", \"the recommended model. But when \\nthey don\\u2019t, performance falls off a cliff, and hard. Instead of \\u201cju\", \"st\\u201d paying for the reflection invoke \\ncosts, each use of a new JsonSerializerOptions  ends up re -ge\", \"nerating via reflection emit those \\nhandlers, skyrocketing the cost of serialization and deserializa\", \"tion. A super simple benchmark makes \\nthis obvious:  \\nprivate JsonSerializerOptions _options = new J\", \"sonSerializerOptions (); \\nprivate MyAmazingClass _instance = new MyAmazingClass (); \\n \\n[Benchmark (B\", \"aseline = true)] \\npublic string ImplicitOptions () => JsonSerializer. Serialize (_instance);  \\n \\n[Be\", \"nchmark]  \\npublic string WithCached () => JsonSerializer. Serialize (_instance, _options);  \\n \\n[Benc\", \"hmark]  \\npublic string WithoutCached () => JsonSerializer. Serialize (_instance, new \\nJsonSerializer\", \"Options ()); \\n \\npublic class MyAmazingClass  \\n{ \\n    public int Value { get; set; } \\n}  \\n191 CHAPTER\", \" 17 | JSON  \\n Method  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nImplicitOptions  .NET 6.0  170.\", \"3 ns  1.00 200 B  1.00 \\nWithCached  .NET 6.0  163.8 ns  0.96 200 B  1.00 \\nWithoutCached  .NET 6.0  1\", \"00,440.6 ns  592.48  7393 B  36.97  \\nIn .NET 7, this was fixed in dotnet/runtime#64646  (and subsequ\", \"ently tweaked in \\ndotnet/runtime#66248 ) by adding a global cache of the type information separate f\", \"rom the options \\ninstances. A JsonSerializerOptions  still has a cache, but when new handlers are ge\", \"nerated via \\nreflection emit, those are also cached at the global level (with appropriate removal wh\", \"en no longer \\nused in order to avoid unbounded leaks).  \\nMethod  Runtime  Mean  Ratio  Allocated  Al\", \"loc Ratio  \\nImplicitOptions  .NET 6.0  170.3 ns  1.00 200 B  1.00 \\nImplicitOptions  .NET 7.0  166.8 \", \"ns  0.98 48 B 0.24 \\nWithCached  .NET 6.0  163.8 ns  0.96 200 B  1.00 \\nWithCached  .NET 7.0  168.3 ns\", \"  0.99 48 B 0.24 \\nWithoutCached  .NET 6.0  100,440.6 ns  592.48  7393 B  36.97  \\nWithoutCached  .NET\", \" 7.0  590.1 ns  3.47 337 B  1.69 \\nAs can be seen here, it\\u2019s still more expensive to create a new Jso\", \"nSerializerOptions  instance on \\neach call, and the recommended approach is \\u201cdon\\u2019t do that.\\u201d But if \", \"someone does do it, in this \\nexample they\\u2019re only paying 3.6x the cost rather than 621x the c ost, a\", \" huge improvement. \\ndotnet/runtime#61434  also now exposes the JsonSerializerOptions.Default  instan\", \"ce that\\u2019s used \\nby default if no options are explicitly provided.  \\nAnother change to JsonSerializer\", \"  came in dotnet/runtime#72510 , which slightly improved the \\nperformance of serialization when usin\", \"g the source generator. The source generator emits helpers for \\nperforming the seriali zation/deseri\", \"alization work, and these are then invoked by JsonSerializer  via \\ndelegates (as part of abstracting\", \" away all the different implementation strategies for how to get and \\nset members on the types being\", \" serialized and deserialized). Previously, the se helpers were being \\nemitted as static methods, whi\", \"ch in turn meant that the delegates were being created to static \\nmethods. Delegates to instance met\", \"hods are a bit faster to invoke than delegates to static methods, \\nso this PR made a simple few -lin\", \"e chang e for the source generator to emit these as instance methods \\ninstead.  \\nYet another for Jso\", \"nSerializer  comes in dotnet/runtime#73338 , which improves allocation with how \\nit utilizes Utf8Jso\", \"nWrite r. Utf8JsonWriter  is a class, and every time JsonSerializer  would write \\nout JSON, it would\", \" allocate a new Utf8JsonWriter  instance. In turn, Utf8JsonWriter  needs \\nsomething to write to, and\", \" although the serializer was using an IBufferWriter  implementation th at \\npooled the underlying byt\", \"e[]  instances employed, the implementation of IBufferWriter  itself is a \\nclass that JsonSerializer\", \"  would allocate. A typical Serialize  call would then end up allocating a \\nfew extra objects and an\", \" extra couple of hundred bytes jus t for these helper data structures. To \\naddress that, this PR tak\", \"es advantage of [ThreadStatic] , which can be put onto static fields to make \\nthem per -thread rathe\", \"r than per -process. From whatever thread is performing the (synchronous)  \\n192 CHAPTER 17 | JSON  \\n\", \" Serialize  operation, i t then ensures the current thread has a Utf8JsonWriter  and IBufferWriter  \", \"\\ninstance it can use, and uses them; for the most part this is straightforward, but it needs to ensu\", \"re that \\nthe serialization operation itself doesn\\u2019t try to recursively serialize, in which case thes\", \"e objects could \\nend up being used erroneously while already in use. It also needs to make sure that\", \" the pooled \\nIBufferWriter  doesn\\u2019t hold on to any of its byte[] s while it\\u2019s not being used. That i\", \"nstance gets its \\narrays from ArrayPool<T> , and we want those arrays to be usable in the meantime b\", \"y anyone else \\nmaking use of the pool, not sequestered off in this cached IBufferWriter  implementat\", \"ion. This \\noptimization is also only really meaningful for small object graphs being serialized, and\", \" only applies to \\nthe synchronous operations (asynchronous operations would require a more complicat\", \"ed pooling \\nmechanism, since the operation isn\\u2019t tied to a specific thread, and the overhead of such\", \" complication \\nwould likely outweigh the modest gain this optimiz ation provides).  \\nprivate byte[] \", \"_data = new byte[] { 1, 2, 3, 4, 5 }; \\n \\n[Benchmark]  \\npublic string SerializeToString () => JsonSer\", \"ializer. Serialize (_data);  \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nSerializeToStri\", \"ng  .NET 6.0  146.4 ns  1.00 200 B  1.00 \\nSerializeToString  .NET 7.0  137.5 ns  0.94 48 B 0.24 \\nUtf\", \"8JsonWriter  and Utf8JsonReader  also saw several improvements directly. dotnet/runtime#69580  \\nadds\", \" a few new performance -focused members, the ValueIsEscaped  property (which exposes already \\ntracke\", \"d information and enables consumers to avoid the expense of re -checking) and the CopyString  \\nmetho\", \"d (which provides a non -allocating mechanism to get acces s to a string value from the reader). \\nIt\", \" then also uses the added support internally to speed up certain operations on Utf8JsonReader . And \", \"\\ndotnet/runtime#63863 , dotnet/runtime#71534 , and dotnet/runtime#61746  fix how some exception \\nche\", \"cks and throws were being handled so as to not slow down the non-exceptional fast paths.   \\n193 CHAP\", \"TER 18 | XML  \\n CHAPTER  18 \\nXML \\nSystem.Xml is used by a huge number of applications and services, \", \"but ever since JSON hit the scene \\nand has been all the rage, XML has taken a back seat and thus has\", \"n\\u2019t seen a lot of investment from \\neither a functionality or performance perspective. Thankf ully, S\", \"ystem.Xml gets a bit of performance \\nlove in .NET 7, in particular around reducing allocation on som\", \"e commonly used code paths.  \\nSometimes a performance fix is as easy as changing a single number. Th\", \"at\\u2019s the case with \\ndotnet/runtime#63459  from [@chrisdcmoore](https://github.com/chrisdcmoore), whi\", \"ch addresses a \\nlong-standing issue with the asynchronous methods on the popular XmlReader . When Xm\", \"lReader  was \\noriginally written, whoever develope d it chose a fairly common buffer size to be used\", \" for read \\noperations, namely 4K or 8K char s depending on various conditions. When XmlReader  later\", \" gained \\nasynchronous reading functionality, for whatever reason a much, much larger buffer size of \", \"64K char s \\nwas selected (presumably in hopes of minimizing the number of asynchronous operations th\", \"at would \\nneed to be employed, but the actual rationale is lost to history). A key problem with such\", \" a buffer size, \\nbeyond it leading to a lot of allocation, is the alloc ation it produces typically \", \"ends up on the Large \\nObject Heap (LOH). By default, under the expectation that really large objects\", \" are long -lived, objects \\ngreater than 85K bytes are allocated into the LOH, which is treated as pa\", \"rt of Gen 2, and that makes \\nsuch allocation if not long-lived even more expensive in terms of overa\", \"ll impact on the system. Well, \\n64K char s is 128K bytes, which puts it squarely above that threshol\", \"d. This PR lowers the size from 64K \\nchar s to 32K char s, putting it below the threshold (and gener\", \"ally reducing allocation pressure, how \\nmuch memory needs to be zero\\u2019d, etc). While it\\u2019s still a ver\", \"y large allocation, and in the future we \\ncould look at pooling the buffer or employing a smaller on\", \"e (e.g.  no different from what\\u2019s done for \\nthe synchronous APIs), this simple one -number change al\", \"one makes a substantial difference for \\nshorter input documents (while not perceivably negatively im\", \"pacting larger ones).  \\nprivate readonly  XmlReaderSettings _settings = new XmlReaderSettings { Asyn\", \"c  = true }; \\nprivate MemoryStream _stream;  \\n \\n[Params(10, 1_000_000)] \\npublic int ItemCount;  \\n \\n[\", \"GlobalSetup]  \\npublic void Setup() \\n{ \\n    _stream = new MemoryStream (); \\n    using XmlWriter write\", \"r = XmlWriter. Create(_stream);  \\n    writer.WriteStartElement (\\\"Items\\\"); \\n    for (var i = 0; i < I\", \"temCount; i++)  \\n    { \\n        writer.WriteStartElement ($\\\"Item{i}\\\" ); \\n        writer.WriteEndElem\", \"ent (); \\n    } \\n    writer.WriteEndElement ();  \\n194 CHAPTER 18 | XML  \\n } \\n \\n[Benchmark]  \\npublic a\", \"sync Task XmlReader_ReadAsync () \\n{ \\n    _stream. Position  = 0; \\n    using XmlReader reader = XmlRe\", \"ader. Create(_stream, _settings);  \\n    while (await reader. ReadAsync ()); \\n} \\nMethod  Runtime  Ite\", \"mCount  Mean  Ratio  Allocated  Alloc \\nRatio  \\nXmlReader_ReadAsync  .NET 6.0  10 42.344 us  1.00 195\", \".94 KB  1.00 \\nXmlReader_ReadAsync  .NET 7.0  10 9.992 us  0.23 99.94 KB  0.51 \\n       \\nXmlReader_Rea\", \"dAsync  .NET 6.0  1000000  340,382.953 \\nus 1.00 101790.34 \\nKB 1.00 \\nXmlReader_ReadAsync  .NET 7.0  1\", \"000000  333,417.347 \\nus 0.98 101804.45 \\nKB 1.00 \\nXmlReader  and XmlWriter  saw other allocation -rel\", \"ated improvements as well. dotnet/runtime#60076  \\nfrom [@kronic](https://github.com/kronic) improved\", \" the ReadOnlyTernaryTree  internal type that\\u2019s \\nused when XmlOutputMeth od.Html  is specified in the\", \" XmlWriterSettings . This included using a \\nReadOnlySpan<byte>  initialized from an RVA static inste\", \"ad of a large byte[]  array that would need to \\nbe allocated. And dotn et/runtime#60057  from [@kron\", \"ic](https://github.com/kronic), which converted \\n~400 string  creations in the System.Private.Xml  a\", \"ssembly to use interpolated strings. Many of \\nthese cases were stylistic, converting something like \", \"string1 + \\\":\\\" + string2  into \\n$\\\"{string1}:{string2}\\\" ; I say stylistic here because the C# compiler\", \" will generate the exact same \\ncode for both of those, a call to string.Concat(string1, \\\":\\\", string2\", \") , given that there\\u2019s a \\nConcat  overload that accepts three strings. However, some of the cha nges\", \" do impact allocation. For \\nexample, the private XmlTextWriter.GeneratePrefix  method had the code: \", \" \\nreturn \\\"d\\\" + _top.ToString (\\\"d\\\", CultureInfo. InvariantCulture ) \\n     + \\\"p\\\" + temp.ToString (\\\"d\\\",\", \" CultureInfo. InvariantCulture ); \\nwhere _top  and temp  are both ints. This will result in allocati\", \"ng two temporary strings and then \\nconcatenating those with the two constant strings. Instead, the P\", \"R changed it to:  \\nreturn string.Create(CultureInfo. InvariantCulture , $\\\"d{_top:d}p{temp:d}\\\" ); \\nwh\", \"ich while shorter i s also more efficient, avoiding the intermediate string allocations, as the cust\", \"om \\ninterpolated string handler used by string.Create  will format those into a pooled buffer rather\", \" than \\nallocating intermediate temporaries.  \\nXmlSerializer  is also quite popular  and also gets a \", \"(small) allocation reduction, in particular for \\ndeserialization. XmlSerializer  has two modes for g\", \"enerating serialization/deserialization routines: \\nusing reflection emit to dynamically generate IL \", \"at run -time that are tuned to the specific  shape of the \\ntypes being serialized/deserialized, and \", \"the XML Serializer Generator Tool  (sgen), which generates a \\n.dll containing the same s upport, jus\", \"t ahead -of-time (a sort -of precursor to the Roslyn source  \\n195 CHAPTER 18 | XML  \\n generators we \", \"love today). In both cases, when deserializing, the generated code wants to track which \\nproperties \", \"of the object being deserialized have already been set, and to do that, it  uses a bool[]  as a \\nbit\", \" array. Every time an object is deserialized, it allocates a bool[]  with enough elements to track \\n\", \"every member of the type. But in common usage, the vast majority of types being deserialized only \\nh\", \"ave a relatively small number of pro perties, which means we can easily use stack memory to track \\nt\", \"his information rather than heap memory. That\\u2019s what dotnet/runtime#66914  does. It updates both \\nof\", \" the code generators to stackall oc into a Span<bool>  for less than or equal to 32 values, and \\noth\", \"erwise fall back to the old approach of heap -allocating the bool[]  (which can also then be stored \", \"\\ninto a Span<bool>  so that the subsequent code paths simply use a span instead of an array). Y ou c\", \"an \\nsee this quite easily in the .NET Object Allocation Tracking tool in Visual Studio. For this con\", \"sole app \\n(which, as an aside, shows how lovely the new raw string literals feature in C# is for wor\", \"king with \\nXML):  \\nusing System.Text; \\nusing System.Xml.Serialization ; \\n \\nvar serializer = new XmlS\", \"erializer (typeof(Release[]));  \\nvar stream = new MemoryStream (Encoding. UTF8.GetBytes ( \\n    \\\"\\\"\\\" \\n\", \"    <?xml version= \\\"1.0\\\" encoding= \\\"utf-8\\\"?> \\n    <ArrayOfRelease xmlns:xsi= \\\"http://www.w3.org/2001\", \"/XMLSchema -instance\\\"  \\nxmlns:xsd= \\\"http://www.w3.org/2001/XMLSchema\\\" > \\n        <Release><Major> 1<\", \"/Major><Minor> 0</Minor></Release>  \\n        <Release><Major> 1</Major><Minor> 1</Minor></Release>  \", \"\\n        <Release><Major> 2</Major><Minor> 0</Minor></Release>  \\n        <Release><Major> 2</Major><\", \"Minor> 1</Minor></Release>  \\n        <Release><Major> 2</Major><Minor> 2</Minor></Release>  \\n       \", \" <Release><Major> 3</Major><Minor> 0</Minor></Release>  \\n        <Release><Major> 3</Major><Minor> 1\", \"</Minor></Release>  \\n        <Release><Major> 5</Major><Minor> 0</Minor></Release>  \\n        <Releas\", \"e><Major> 6</Major><Minor> 0</Minor></Release>  \\n        <Release><Major> 7</Major><Minor> 0</Minor>\", \"</Release>  \\n    </ArrayOfRelease>  \\n    \\\"\\\"\\\")); \\n \\nfor (int i = 0; i < 1000; i++) \\n{ \\n    stream.Pos\", \"ition  = 0; \\n    serializer. Deserialize (stream);  \\n} \\n \\npublic class Release \\n{ \\n    public int Ma\", \"jor; \\n    public int Minor; \\n    public int Build; \\n    public int Revision;  \\n} \\nHere\\u2019s what I see \", \"when I run this under .NET 6:   \\n196 CHAPTER 18 | XML  \\n  \\nWe\\u2019re running a thousand d eserialization\", \"s, each of which will deserialize 10 Release  instances, and so \\nwe expect to see 10,000 Release  ob\", \"jects being allocated, which we do\\u2026 but we also see 10,000 \\nbool[]  being allocated. Now with .NET 7\", \" (note the distinct lack of the per -object bool[]): \\n \\nOther allocation reduction went into the cre\", \"ation of the serializer/deserializer itself, such as with \\ndotnet/runtime#68738  avoiding allocating\", \" strings to escape text that didn\\u2019t actually need escaping, \\ndotnet/runtime#66915  using stack alloc\", \"ation for building up small text instead of using a \\nStringBuilder , dotnet/runtime#66797  avoiding \", \"delegate and closure allocations in accessing the \\ncache of serializers previously created, dotnet/r\", \"untime #67001  from \\n[@TrayanZapryanov](https://github.com/TrayanZapryanov) caching an array used wi\", \"th string.Split , \\nand dotnet/runtime#67002  from [@TrayanZapryanov](https://github.com/TrayanZaprya\", \"nov)  that \\nchanged some parsing code to avoid a string.ToCharArray  invocation.  \\nFor folks using X\", \"ML schema, dotnet/runtime#66908  replaces some Hashtable s in the implementation \\nwhere those collec\", \"tion s were storing ints as the value. Given that Hashtable  is a non -generic \\ncollection, every on\", \"e of those ints was getting boxed, resulting in unnecessary allocation overhead; \\nthese were fixed b\", \"y replacing these Hashtable s with Dictionary<..., int>  instances.  (As an aside, \\nthis is a fairly\", \" common performance -focused replacement to do, but you need to be careful as \\nHashtable  has a few \", \"behavioral differences from Dictionary<,> ; beyond the obvious difference of \\nHashtable  returning n\", \"ull  from its indexer when a key  isn\\u2019t found and Dictionary<,>  throwing in \\nthat same condition, H\", \"ashtable  is thread -safe for use with not only multiple readers but multiple \\nreaders concurrent wi\", \"th a single writer, and Dictionary<,>  is not.) dotnet/runtime#67045  reduces \\nallocation of XmlQual\", \"ifiedName  instances in the implementation of XsdBuilder.ProcessElement  and \\nXsdBuilder.ProcessAttr\", \"ibute . And dotnet/runtime#64 868 from \\n[@TrayanZapryanov](https://github.com/TrayanZapryanov) uses \", \"stack -based memory and pooling to \\n \\n197 CHAPTER 18 | XML  \\n avoid temporary string allocation in t\", \"he implementation of the internal XsdDateTime  and \\nXsdDuration  types, which are used by the public\", \" XmlConvert . \\npriva te TimeSpan _ts = TimeSpan. FromMilliseconds (12345); \\n \\n[Benchmark]  \\npublic s\", \"tring XmlConvertToString () => XmlConvert. ToString (_ts); \\nMethod  Runtime  Mean  Ratio  Allocated \", \" Alloc Ratio  \\nXmlConvertToString  .NET 6.0  90.70 ns  1.00 184 B  1.00 \\nXmlConvertToString  .NET 7.\", \"0  59.21 ns  0.65 40 B 0.22 \\nXML pops up in other areas as well, as in the XmlWriterTraceListener  t\", \"ype. While the \\nSystem.Diagnostics.Trace  type isn\\u2019t the recommended tracing mech anism for new code\", \", it\\u2019s widely \\nused in existing applications, and XmlWriterTraceListener  let\\u2019s you plug in to that \", \"mechanism to \\nwrite out XML logs for traced information. dotnet/runtime#66762  avoids a bunch of str\", \"ing allocation \\noccurring as part of this tracing, by formatting much of the header information into\", \" a span and then \\nwriting that out rather than ToString() \\u2019ing each individual piece of data.  \\n[Glo\", \"balSetup]  \\npublic void Setup() \\n{ \\n    Trace.Listeners .Clear(); \\n    Trace.Listeners .Add(new XmlW\", \"riterTraceListener (Stream. Null)); \\n} \\n \\n[Benchmark]  \\npublic void TraceWrite () \\n{ \\n    Trace.Writ\", \"eLine (\\\"Something important\\\" ); \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nTraceWrit\", \"e  .NET 6.0  961.9 ns  1.00 288 B  1.00 \\nTraceWrite  .NET 7.0  772.2 ns  0.80 64 B 0.22  \\n198 CHAPTE\", \"R 19 | Cryptography  \\n CHAPTER  19 \\nCryptography  \\nSome fairly significant new features came to Syst\", \"em.Security.Cryptography  in .NET 7, including the \\nsupport necessary to enable the previously discu\", \"ssed OCSP stapling and support for building \\ncertificate revocation lists , but there was also a fai\", \"r amount of effort put into making existing support \\nfaster and more lightweight.  \\nOne fairly subst\", \"antial change in .NET 7 is split across dotnet/runtime#61025 , dotnet/runtime#61137 , \\nand dotnet/ru\", \"ntime#64307 . These PRs don\\u2019t change any code materially, but instead cons olidate all of \\nthe vario\", \"us cryptography -related assemblies in the core libraries into a single \\nSystem.Security.Cryptograph\", \"y  assembly. When .NET Core was first envisioned, a goal was to make \\nit extremely modular, and larg\", \"e swaths of code were teased apart t o create many smaller assemblies. \\nFor example, cryptographic f\", \"unctionality was split between \\nSystem.Security.Cryptography.Algorithms.dll , System.Security.Crypto\", \"graphy.Cng.dll , \\nSystem.Security.Cryptography.Csp.dll , System.Security.Cryptography.Encoding.dll ,\", \" \\nSystem.Security.Cryptography.OpenSsl.dll , System.Security.Cryptography.Primitives.dll , \\nand Syst\", \"em.Security.Cryptography.X509Certificates.dll . You can see this if you look in your \\nshared framewo\", \"rk folder for a previous release, e.g.  here\\u2019s mine for .NET 6 : \\n \\nThese PRs move all of that code \", \"into a single System.Security.Cryptography.dll  assembly. This has \\nseveral benefits. First, crypto \", \"is used in a huge number of applications, and most apps would end up \\n \\n199 CHAPTER 19 | Cryptograph\", \"y  \\n requiring multiple (or even most) of these assemblies . Every assembly that\\u2019s loaded adds overh\", \"ead. \\nSecond, a variety of helper files had to be compiled into each assembly, leading to overall la\", \"rger \\namount of compiled code to be distributed. And third, we weren\\u2019t able to implement everything \", \"as \\noptimal as we\\u2019 d have otherwise liked due to functionality in one assembly not exposed to anothe\", \"r \\n(and we avoid using InternalsVisibleTo  as it hampers maintainability and impedes other analysis \", \"\\nand optimizations). Now in .NET 7, the shared framework looks more like this:  \\n \\nInteresting, you \", \"still see a bunch of assemblies there, but all except for \\nSystem.Security.Cryptography.dll  are tin\", \"y; that\\u2019s because these are simple facades. Because we \\nneed to support binaries built for .NET 6 an\", \"d earlier running on .NET 7, we need to  be able to handle \\nbinaries that refer to types in these as\", \"semblies, but in .NET 7, those types actually live in \\nSystem.Security.Cryptography.dll . .NET provi\", \"des a solution for this in the form of the \\n[TypeForwardedTo(...)]  attribute, which enables one ass\", \"e mbly to say \\u201chey, if you\\u2019re looking for type \\nX, it now lives over there.\\u201d And if you crack open o\", \"ne of these assemblies in a tool like ILSpy , you can \\nsee they\\u2019re essentially empty except for a bu\", \"nch o f these attributes:  \\n \\n200 CHAPTER 19 | Cryptography  \\n  \\nIn addition to the startup and main\", \"tenance wins this provides, this has also enabled further \\nsubsequent optimization. For example, the\", \"re\\u2019s a lot of object cloning that goes on in the innards of \\nthis library. Various objects are used \", \"t o wrap native handles to OS cryptographic resources, and to \\nhandle lifetime semantics and ownersh\", \"ip appropriately, there are many cases where a native handle is \\nduplicated and then wrapped in one \", \"or more new managed objects. In some cases, however, the \\noriginal resource is then destroyed becaus\", \"e it\\u2019s no longer needed, and the whole operation could \\nhave been made more efficient if the origina\", \"l resource just had its ownership transferred to the new \\nobjects rather than being duplicated and d\", \"estroyed. This kind  of ownership transfer typically is hard to \\ndo between assemblies as it general\", \"ly requires public API that\\u2019s not focused on such usage patterns, \\nbut with internals access, this c\", \"an be overcome. dotnet/runtime#72120  does this, for example, to \\nreduce allocation of various resou\", \"rces inside the RSACng , DSACng , ECDsaCng , and ECDiffieHellmanCng  \\npublic types.  \\nIn terms of ac\", \"tual code improvements, there are many. One category of improvements is around \\n\\u201cone-shot\\u201d operation\", \"s. With many forms of data processing, all of the data needn\\u2019t be processed in \\none operation. A blo\", \"ck of data can be processed, then another, then another, until finally there\\u2019s no \\nmore data to be p\", \"rocessed. In such usage, there\\u2019s often  some kind of state carried over from the \\nprocessing of one \", \"block to the processing of the next, and then the processing of the last block is \\nspecial as it nee\", \"dn\\u2019t carry over anything and instead needs to perform whatever work is required to \\nend the whole op\", \"eration, e.g.  outputting any final footer or checksum that might be required as part \\nof the format\", \". Thus, APIs that are able to handle arbitrary number of blocks of data are often a bit \\nmore expens\", \"ive in one way, shape, or form than APIs that only suppor t a single input; this latter \\ncategory is\", \" known as \\u201cone shot\\u201d operations, because they do everything in \\u201cone shot.\\u201d In some cases, \\none-shot \", \"operations can be significantly cheaper, and in other cases they merely avoid some \\nallocations that\", \" would have been necessary to transfer state from the processing of one block of data \\nto the next. \", \"dotnet/runtime#58270  from [@vcsjones](https://github.com/vcsjones) and \\ndotnet/runtime#65725  from \", \"[@vcsjones](https://github.com/vcsjones) both improved the \\nperformance of various one -shot operati\", \"ons on \\u201csymmetric\\u201d cryptograhic algorithms (algorithms that \\nuse the same key information to both en\", \"crypt an d decrypt), like AES. The former does so by \\nrefactoring the implementations to avoid some \", \"reset work that\\u2019s not necessary in the case of one -\\nshots because the relevant state is about to go\", \" away, anyway, and that in turns also allows the \\nimplementation to s tore less of certain kinds of \", \"state. The latter does so for decryption one -shots by \\ndecrypting directly into the destination buf\", \"fer whenever possible, using stack space if possible when \\ngoing directly into the user\\u2019s buffer isn\", \"\\u2019t feasible, etc.  \\n \\n201 CHAPTER 19 | Cryptography  \\n private byte[] _plaintext = Encoding. UTF8.Ge\", \"tBytes (\\\"This is a test. This is only a test. \\nNothing to see here.\\\" ); \\nprivate byte[] _iv = Enumer\", \"able. Range(0, 16).Select(i => (byte)i).ToArray(); \\nprivate Aes _aes = Aes. Create(); \\nprivate byte[\", \"] _output = new byte[1000]; \\n \\n[Benchmark]  \\npublic bool OneShot() => _aes. TryEncryptCfb (_plaintex\", \"t, _iv, _output, out _); \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nOneShot  .NET 6.0  \", \"1.828 us  1.00 336 B  1.00 \\nOneShot  .NET 7.0  1.770 us  0.97 184 B  0.55 \\nIn addition to making one\", \" -shots lighterweight, other PRs have then used these one -shot operations in \\nmore places in order \", \"to simplify their code and benefit from the increased performance, e.g. \\ndotnet/runtime#70639  from \", \"[@vcsjones](https://github.com/vcsjones), dotnet/runtime#70857  from \\n[@vcsjones](https://github.com\", \"/vcsjones), dotnet/runtime#64005  from \\n[@vcsjones](https://github.com/vcsjones), and dotnet/runtime\", \"#64174  from \\n[@vcsjones](https://github.com/v csjones).  \\nThere\\u2019s also a large number of PRs that h\", \"ave focused on removing allocations from around the crypto \\nstack:  \\n\\u2022 Stack allocation . As has bee\", \"n seen in many other PRs referenced throughout this post, using \\nstackalloc  is a very effective way\", \" to get rid o f array allocations in many situations. It\\u2019s used \\neffectively in multiple crypto PRs \", \"to avoid either temporary or pooled array allocations, such as \\nin dotnet/runtime#64584  from [@vcsj\", \"ones](htt ps://github.com/vcsjones), dotnet/runtime#69831  \\nfrom [@vcsjones](https://github.com/vcsj\", \"ones), dotnet/runtime#70173  from \\n[@vcsjo nes](https://github.com/vcsjones), dotnet/runtime#69812  \", \"from \\n[@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69448  from \\n[@vcsjones](https://\", \"github.com/vcsjones). Sometimes this is used when calling an API that has \\nmultiple overloads, inclu\", \"ding one taking an array and one taking a span. Othertimes it\\u2019s used \\nwith P/Invokes that often just\", \" pass out a small amount of data.  Sometimes it\\u2019s used to avoid \\ntemporary array allocations, and so\", \"metimes it\\u2019s used in places where pooling was used \\npreviously, but the data is often small enough t\", \"o avoid even the overheads of pooling.  \\n\\u2022 Avoiding double copies . Most of the crypto APIs that acc\", \"ept byte[] s and store them end up \\nmaking defensive copies of those arrays rather than storing the \", \"original. This is fairly common \\nthroughout .NET, but it\\u2019s especially common in the crypto stack, wh\", \"ere the ability to trust the \\ndata is as you expect it (a nd validate it) is paramount. In some case\", \"s, though, code ends up \\nallocating a temporary byte[]  just to pass data into one of these APIs tha\", \"t copies and re -\\nallocates, anyway. dotnet/runtime#71 102 from [@vcsjones](https://github.com/vcsjo\", \"nes), \\ndotnet/runtime#69024  from [@vcsjones](https://github.com/vcsjones), dotnet/ru ntime#71015  \\n\", \"from [@vcsjones](https://github.com/vcsjones), and dotnet/runtime#69534  from \\n[@vcsjones](https://g\", \"ithub.com/vcsjones) deal with that duplication in some cases by extracting \\na span to the original d\", \"ata instead of creating a temporary byte[] ; when that span is passed into \\nthe target API, the targ\", \"et API still makes a copy, but we\\u2019ve avoided the first one and thus cut the \\narray allocation for th\", \"ese operations effectively in half. dotnet/runtime#71888  from \\n[@vcsjones](https://github.com/vcsjo\", \"nes) is a variation on this theme, improving the internals of  \\n202 CHAPTER 19 | Cryptography  \\n Rfc\", \"2898DeriveBytes  to supports spans such that its constructors that accep t spans can then do \\nthe mo\", \"re efficient thing.  \\n\\u2022 Replacing O(1)  data structures . O(1)  lookup data structures like Dictiona\", \"ry<,>  and \\nHashSet<>  are the lifeblood of most applications and services, but sometimes algorithmi\", \"c \\ncomplexity is misleading. Yes, these provide very efficient searching, but there\\u2019s still overhead\", \" \\nassociated with computing a hash code, mapping that hash code to a location in  the data \\nstructur\", \"e, and so on. If there\\u2019s only ever a handful of items (i.e.  the N in the complexity is really, \\nrea\", \"lly small), it can be much faster to just do a linear search, and if N is sufficiently small, a data\", \" \\nstructure may not even be needed at all : the search can just be open -coded as a waterfall of \\nif\", \"/elseif/else constructs. That\\u2019s the case in a PR like dotnet/runtime#71341  from \\n[@vcsjones](https:\", \"//github.com/vcsjones), where the 99.9 99% case involves just five strings \\n(names of hash algorithm\", \"s); it\\u2019s cheaper to just compare against each than it is do a \\nHashSet<>.Contains , especially since\", \" the JIT now unrolls and vectorizes the comparison against \\nthe constant string names.  \\n\\u2022 Simply av\", \"oid ing unnecessary work . The best optimizations are ones where you simply stop \\ndoing work you don\", \"\\u2019t have to do. dotnet/runtime#68553  from \\n[@vcsjones](https://github.com/vcsjones) is a good exampl\", \" e of this. This code was performing a \\nhash of some data in order to determine the length of result\", \"ing hashes for that particular \\nconfiguration, but we actually know ahead of time exactly how long a\", \" hash for a given algorithm \\nis going to be, and we already have in this code a cascading if/elseif/\", \"else that\\u2019s checking for each \\nknown algorithm, so we can instead just hardcode the length for each.\", \" dotnet/runtime#70589  \\nfrom [@vcsjones](https://github .com/vcsjones) is another good example, in t\", \"he same spirit of \\nthe ownership transfer example mentioned earlier (but this one didn\\u2019t previously \", \"span assembly \\nboundaries). Rather than in several places taking an X509Extension , serializing it t\", \"o a byte[] , \\nand passing that temporary byte[]  to something else that in turn makes a defensive co\", \"py, we \\ncan instead provide an internal pathway for ownership transfer, bypassing all of the middle \", \"\\nstages. Another good one is dotnet/runtime#70618  from \\n[@vcsjones](https://github.com/vcsjones), a\", \"s it\\u2019s an example of how it pays to really understand \\nyour dependencies. The implementation of symm\", \"etric encryption on macOS uses the \\nCommonCrypto library. One of the fun ctions it exposes is CCCryp\", \"torFinal , which is used at the \\nend of the encryption/decryption process. However, there are severa\", \"l cases called out in the \\ndocs where it\\u2019s unnecessary (\\u201csuperfluous,\\u201d according to the docs), and s\", \"o our dutifully calling it \\neven in those situations is wasteful. The fix? Stop doing unnecessary wo\", \"rk.  \\n\\u2022 New APIs . A bunch of new APIs were introduced for cryptography in .NET 7. Most are focused \", \"\\non easing scenarios that were difficult to do correctly before, like dotnet/runtime#66509  from \\n[@\", \"vcsjones](https://github.com/vcsjones) that provides an X500DistinguishedNameBuilder . But \\nsome are\", \" focused squarely on performance. dotnet/runtime#57835  from \\n[@vcsjones](https://github.com/vcsjone\", \"s), for example, exposes a new RawDataMemory  property \\non X509Certificate2 . Whereas the existing R\", \"awData  property returns a new byte[]  on every \\ncall (again a defensive copy to avoid havi ng to de\", \"al with the possiblity that the consumer \\nmucked with the raw data), this new RawDataMemory  returns\", \" a ReadOnlyMemory<byte>  around \\nthe internal byte[] . Since the only way to access and mutate that \", \"underlying byte[]  via a \\nReadOnlyMemory<byte>  is via u nsafe interop code (namely via the \\nSystem.\", \"Runtime.InteropServices.MemoryMarshal  type), it doesn\\u2019t create a defensive copy and \\nenables access\", \"ing this data freely without additional allocation.   \\n203 CHAPTER 20 | Diagnostics  \\n CHAPTER  20 \\n\", \"Diagnostics  \\nLet\\u2019s turn our attention to System.Diagnostics, which encompasses types ranging from p\", \"rocess \\nmanagement to tracing.  \\nThe Process  class is used for a variety of purposes, including que\", \"rying information about running \\nprocesses, interacting with other processes (e.g.  being notified o\", \"f their exiting), and launching \\nprocesses. The performance of querying for information in particula\", \"r ha d some notable improvements \\nin .NET 7. Process  provides several APIs for querying for process\", \" information, one of the most \\ncommon being Process.GetProcessesByName : apps that know the name of \", \"the process they\\u2019re \\ninterested in can pass that to GetProcessesBy Name  and get back a Process[]  c\", \"ontaining a Process  \\nfor each. It turns out that previous releases of .NET were loading the full in\", \"formation (e.g.  all of its \\nthreads) about every Process  on the machine in order to filter down to\", \" just those with the target \\nname. dotnet/runtime#68705  fixes that by only loading the name for a p\", \"rocess rather than all of the \\ninformation for it. While this helps a bit with throughput, it helps \", \"a ton with allocation:  \\n[Benchmark]  \\npublic void GetProcessesByName () \\n{ \\n    foreach (Process p \", \"in Process. GetProcessesByName (\\\"dotnet.exe\\\" )) \\n        p.Dispose(); \\n} \\nMethod  Runtime  Mean  Rat\", \"io  Allocated  Alloc Ratio  \\nGetProcessesByName  .NET 6.0  2.287 ms  1.00 447.86 KB  1.000  \\nGetProc\", \"essesByName  .NET 7.0  2.086 ms  0.90 2.14 KB  0.005  \\nAccessing various pieces of information from \", \"a Process  has also improved. If you load a Process  \\nobject via the Process.GetProcesses  or Proces\", \"s.GetProcessesByName  methods, by design they load \\nall information about the Process  being retriev\", \"ed; internally their state will be populated such that \\nsubsequent accesses to members of the Proces\", \"s  instance will be very fast. But, if you access a \\nProcess  via Process.GetProces sById  or Proces\", \"s.GetCurrentProcess  (which is effectively \\nGetProcessById  for the current process\\u2019 id), no informa\", \"tion other than the process\\u2019 ID is \\nprepopulated, and the state for the Process  instance is queried\", \" on -demand. In most cases, accessing \\na single member of one of those lazy -loaded Process  instanc\", \"es triggers loading all of the data for it, \\nas the information is all available as part of the same\", \" native operation, e.g.  on Windows using \\nNtQuerySystemInformation  and on Linux reading from /proc\", \"/pid/stat  and /proc/pid/status . But \\nin some cases we can be more fine -grained about it, using AP\", \"Is that serve up a subset of the data \\nmuch more quickly. dotnet/runtime#59672  from [@SteveD unn](h\", \"ttps://github.com/SteveDunn) \\nprovides one such optimization, using the QueryFullProcessImageName  o\", \"n Windows to read the \\nprocess name in response to Process.ProcessName  being used. If all you care \", \"about reading is the  \\n204 CHAPTER 20 | Diagnostics  \\n process\\u2019 name, it\\u2019s a huge boost in throughpu\", \"t, and even if you subsequently go on to read additional \\nstate from the Process  and force it to lo\", \"ad everything else, accessing the process name is so fast that \\nit doesn\\u2019t add meaningful overhead t\", \"o the all -up operation. This is visible in this  benchmark:  \\n[Benchmark]  \\npublic string GetCurren\", \"tProcessName () \\n{ \\n    using Process current = Process. GetCurrentProcess (); \\n    return current. \", \"ProcessName ; \\n} \\n \\n[Benchmark]  \\npublic string GetCurrentProcessNameAndWorkingSet () \\n{ \\n    using \", \"Process current = Process .GetCurrentProcess (); \\n    return $\\\"{current.ProcessName} {current.Workin\", \"gSet64}\\\" ; \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nGetCurrentProcessName  .NET 6.\", \"0  3,070.54 us  1.00 3954 B  1.00 \\nGetCurrentProcessName  .NET 7.0  32.30 us  0.01 456 B  0.12 \\n    \", \"  \\nGetCurrentProcessNameAndWorkingSet  .NET 6.0  3,055.70 us  1.00 4010 B  1.00 \\nGetCurrentProcessNa\", \"meAndWorkingSet  .NET 7.0  3,149.92 us  1.03 4186 B  1.04 \\nInterestingly, this PR had a small defici\", \"ency we didn\\u2019t initially catch, which is that the \\nQueryFullProcessImageName  API we switched to did\", \"n\\u2019t work in the case of elevated/privileged \\nprocesses. To accomodate those, dotnet/runtime#70073  f\", \"rom \\n[@schuettecarsten](https://github.com/schuettecarsten) updated the code to keep both the new an\", \"d \\nold implementations, starting with the new one and then only falling back to the old if operating\", \" on \\nan incomp atible process.  \\nSeveral additional PRs helped out the Process  class. When launchin\", \"g processes with Process.Start  \\non Unix, the implementation was using Encoding.UTF8.GetBytes  as pa\", \"rt of argument handling, \\nresulting in a temporary array being allocated per a rgument; dotnet/runti\", \"me#71279  removes that \\nper-argument allocation, instead using Encoding.UTF8.GetByteCount  to determ\", \"ine how large a \\nspace is needed and then using the Encoding.UTF8.GetBytes  overload that accepts a \", \"span to encode \\ndirectly into the native memory already being allocated. dotnet/runtime#71136  simpl\", \"ifies and \\nstreamlines the code involved in getting the \\u201cshort name\\u201d of  a process on Windows for us\", \"e in \\ncomparing process names. And dotnet/runtime#45690  replaces a custom cache with use of \\nArrayP\", \"ool  in the Windows implementation of getting all process informatio n, enabling effective reuse \\nof\", \" the array that ends up being used rather than having it sequestered off in the Process  \\nimplementa\", \"tion forever.  \\nAnother area of performance investment has been in DiagnosticSource , and in particu\", \"lar around \\nenumerating through data from Activity  instances. This work translates into faster inte\", \"gration and \\ninteroperability via OpenTelemetry , in order to be able to export data from .NET Activ\", \"ity  information \\nfaster. dotnet/runtime#67 012 from [@CodeBlanch](https://github.com/CodeBlanch), f\", \"or example, \\nimproved the performance of the internal DiagLinkedList<T>.DiagEnumerator  type that\\u2019s \", \"the  \\n205 CHAPTER 20 | Diagnostics  \\n enumerator returned when enumerating Activity.Links  and Activ\", \"ity.Events  by avoiding a copy \\nof each  T value:  \\nprivate readonly  Activity _activity;  \\n \\npublic\", \" Program() \\n{ \\n    using ActivitySource activitySource = new ActivitySource (\\\"Perf7Source\\\" ); \\n    A\", \"ctivitySource. AddActivityListener (new ActivityListener  \\n    { \\n        ShouldListenTo = s => s ==\", \" activitySou rce, \\n        Sample = ( ref ActivityCreationOptions<ActivityContext> o) => \\nActivitySa\", \"mplingResult. AllDataAndRecorded  \\n    }); \\n \\n    _activity = activitySource. StartActivity ( \\n     \", \"   \\\"TestActivity\\\" , \\n        ActivityKind. Internal , \\n        parentContext: default, \\n        link\", \"s: Enumerable. Range(0, 1024).Select(_ => new ActivityLink (default)).ToArray()); \\n    _activity. St\", \"op(); \\n} \\n \\n[Benchmark (Baseline = true)] \\npublic ActivityLink EnumerateActivityLinks () \\n{ \\n    Act\", \"ivityLink last = default; \\n    foreach (ActivityLink link in _activity. Links) last = link;  \\n    re\", \"turn last; \\n} \\nMethod  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nEnumerateActivityLinks  .NET 6\", \".0  19.62 us  1.00 64 B 1.00 \\nEnumerateActivityLinks  .NET 7.0  13.72 us  0.70 32 B 0.50 \\nThen dotne\", \"t/runtime#67920  from [@CodeBlanch](https://github.com/CodeBlanch) and \\ndotnet/runtime#68933  from [\", \"@CodeBlanch](https://github. com/CodeBlanch) added new \\nEnumerateTagObjects , EnumerateEvents , and \", \"EnumerateLinks  enumeration methods that return a \\nstruct -based enumerator that has a ref T -return\", \"ing Current  to avoid yet another layer of copy.  \\nprivate readonly  Activity _activity;  \\n \\npublic \", \"Program() \\n{ \\n    using ActivitySource activitySource = new ActivitySource (\\\"Perf7Source\\\" ); \\n    Ac\", \"tivitySource. AddActivityListener (new ActivityListener  \\n    { \\n        ShouldListenTo = s => s == \", \"activitySource,  \\n        Sample = ( ref ActivityCreationOptions<Act ivityContext> o) => \\nActivitySa\", \"mplingResult. AllDataAndRecorded  \\n    }); \\n \\n    _activity = activitySource. StartActivity ( \\n     \", \"   \\\"TestActivity\\\" , \\n        ActivityKind. Internal , \\n        parentContext: default, \\n        link\", \"s: Enumerable. Range(0, 1024).Select(_ => new ActivityLink (default)).ToArray());  \\n206 CHAPTER 20 |\", \" Diagnostics  \\n     _activity. Stop(); \\n} \\n \\n[Benchmark (Baseline = true)] \\npublic ActivityLink Enum\", \"erateActivityLinks_Old () \\n{ \\n    ActivityLink last = default; \\n    foreach (ActivityLink link in _a\", \"ctivity. Links) last = link;  \\n    return last; \\n} \\n \\n[Benchmark]  \\npublic ActivityLink EnumerateAct\", \"ivityLinks_New () \\n{ \\n    ActivityLink last = default; \\n    foreach (ActivityLink link in _activity.\", \" EnumerateLinks ()) last = link;  \\n    return last; \\n} \\nMethod  Mean  Ratio  Allocated  Alloc Ratio \", \" \\nEnumerateActivityLinks_Old  13.655 us  1.00 32 B 1.00 \\nEnumerateActivityLinks_New  2.380 us  0.17 \", \"- 0.00 \\nOf course, when it comes to diagnostics, anyone who\\u2019s ever done anything with regards to tim\", \"ing and \\nmeasurements is likely familiar with good ol\\u2019 Stopwatch . Stopwatch  is a simple type that\\u2019\", \"s very handy \\nfor getting precise measurements and is thus used all over the place. But for folks th\", \"at are really cost -\\nsensitive, the fact that Stopwatch  is a class can be prohibitive, e.g.  writin\", \"g:  \\nStopwatch sw = Stopwatch. StartNew (); \\n...; \\nTimeSpan elapsed = sw. Elapsed; \\nis easy, but all\", \"ocates a new object just to measure.  To address this, Stopwatch  has for years exposed \\nthe static \", \"GetTimestamp()  method which avoids that allocation, but consuming and translating the \\nresulting lo\", \"ng  value is complicated, requiring a formula involving using Stopwatch.Frequency  and \\nTimeSpan.Tic\", \" ksPerSecond  in the right incantation. To make this pattern easy, dotnet/runtime#66372  \\nadds a sta\", \"tic GetElapsedTime  method that handles that conversion, such that someone who wants \\nthat last mi l\", \"e of performance can write:  \\nlong timestamp = Stopwatch. GetTimestamp (); \\n... \\nTimeSpan elapsed = \", \"Stopwatch. GetElapsedTime (timestamp);  \\nwhich avoids the allocation and saves a few cycles:  \\n[Benc\", \"hmark (Baseline = true)] \\npublic TimeSpan Old() \\n{ \\n    Stopwatch sw = Stopwatch. StartNew (); \\n    \", \"return sw.Elapsed; \\n} \\n \\n[Benchmark]  \\npublic TimeSpan New() \\n{  \\n207 CHAPTER 20 | Diagnostics  \\n   \", \"  long timestamp = Stopwatch. GetTimestamp (); \\n    return Stopwatch. GetElapsedTime (timestamp);  \\n\", \"} \\nMethod  Mean  Ratio  Allocated  Alloc Ratio  \\nOld 32.90 ns  1.00 40 B 1.00 \\nNew 26.30 ns  0.80 - \", \"0.00  \\n208 CHAPTER 21 | Exceptions  \\n CHAPTER  21 \\nExceptions  \\nIt might be odd to see the subject o\", \"f \\u201cexceptions\\u201d in a post on performance improvements. After all, \\nexceptions are by their very natur\", \"e meant to be \\u201cexceptional\\u201d (in the \\u201crare\\u201d sense), and thus wouldn\\u2019t \\ntypically contribute to fast -\", \"path performance. Which  is a good thing, because fast -paths that throw \\nexceptions in the common c\", \"ase are no longer fast: throwing exceptions is quite expensive.  \\nInstead, one of the things we do c\", \"oncern ourselves with is how to minimize the impact of checking for \\nexceptional cond itions: the ac\", \"tual exception throwing may be unexpected and slow, but it\\u2019s super \\ncommon to need to check for thos\", \"e unexpected conditions, and that checking should be very fast. We \\nalso want such checking to minim\", \"ally impact binary size, especially if we\\u2019re  going to have many such \\nchecks all over the place, in\", \" generic code for which we end up with many copies due to generic \\nspecialization, in functions that\", \" might be inlined, and so on. Further, we don\\u2019t want such checks to \\nimpede other optimizations; for\", \" exa mple, if I have a small function that wants to do some argument \\nvalidation and would otherwise\", \" be inlineable, I likely don\\u2019t want the presence of exception throwing to \\ninvalidate the possibilit\", \"y of inlining.  \\nBecause of all of that, high -performance librari es often come up with custom \\u201cthr\", \"ow helpers\\u201d they use \\nto achieve their goals. There are a variety of patterns for this. Sometimes a \", \"library will just define its \\nown static method that handles constructing and throwing an exception,\", \" and then call sites do t he \\ncondition check and delegate to the method if throwing is needed:  \\nif\", \" (arg is null) \\n    ThrowArgumentNullException (nameof(arg)); \\n... \\n[DoesNotReturn]  \\nprivate static\", \" void ThrowArgumentNullException (string arg) => \\n    throw new ArgumentNullException (arg); \\nThis k\", \"eeps the IL associated with the throwing out of the calling function, minimizing the impact of \\nthe \", \"throw. That\\u2019s particularly valuable when additional work is needed to construct the exception, e.g. \", \" \\nprivate static void ThrowArgumentNullException (string arg) => \\n    throw new ArgumentNullExceptio\", \"n (arg, SR. SomeResourceMessage ); \\nOther times, libraries will encapsulate both the checking and th\", \"rowing. This is exactly what the \\nArgumentNullException.ThrowIfNull method that was adde d in .NET 6\", \" does:  \\npublic static void ThrowIfNull ([NotNull] object? argument, \\n[CallerArgumentExpression (\\\"ar\", \"gument\\\" )] string? paramName = null) \\n{ \\n    if (argument is null) \\n        Throw(paramName);  \\n} \\n \", \" \\n209 CHAPTER 21 | Exceptions  \\n [DoesNotReturn]  \\ninternal  static void Throw(string? paramName) =>\", \" throw new \\nArgumentNullException (paramName);  \\nWith that, callers benefit from the concise call si\", \"te:  \\npublic void M(string arg) \\n{ \\n    ArgumentNullException. ThrowIfNull (arg); \\n    ... \\n} \\nthe I\", \"L remains concise, and the assembly generated for the JIT will include the streamlined condition \\nch\", \"eck from the inlined ThrowIfNull  but won\\u2019t inline the Throw  helper, resulting in effectively the s\", \"ame \\ncode as if you\\u2019d written the previously shown manu al version with ThrowArgumentNullException  \", \"\\nyourself. Nice.  \\nWhenever we introduce new public APIs in .NET, I\\u2019m particularly keen on seeing th\", \"em used as widely \\nas possible. Doing so serves multiple purposes, including helping to validate tha\", \"t the new API is \\nusable and fully addresses the intended scenarios, and including the rest of the c\", \"odebase benefiting \\nfrom whatever that API is meant to provide, whether it be a performance improvem\", \"ent or just a \\nreduction in routinely written code. In the case of ArgumentN ullException.ThrowIfNul\", \"l , however, I \\npurposefully put on the brakes. We used it in .NET 6 in several dozen call sites, bu\", \"t primarily just in \\nplace of custom ThrowIfNull -like helpers that had sprung up in various librari\", \"es around the runtime, \\neffectively de duplicating them. What we didn\\u2019t do, however, was replace the\", \" literally thousands of null \\nchecks we have with calls to ArgumentNullException.ThrowIfNull . Why? \", \"Because the new !! C# \\nfeature was right around the corner, destined for C# 11.  \\nFor those unaware,\", \"  the !! feature enabled putting !! onto parameter names in member signatures, \\ne.g. \\npublic void Pr\", \"ocess(string name!!) \\n{ \\n    ... \\n} \\nThe C# compiler then compiled that as equivalent to:  \\npublic v\", \"oid Process(string name) \\n{ \\n    ArgumentNullException. ThrowIfNull (name); \\n} \\n(albeit using its ow\", \"n ThrowIfNull  helper injected as internal into the assembly). Armed with the new \\nfeature, dotnet/r\", \"untime#64720  and dotnet/runtime#65108  rolled out use of !! across \\ndotnet/runtime , replacing ~25,\", \"000 lines of code with ~5000 lines that used !!. But, what\\u2019s t he line \\nfrom Kung Fu Panda, \\u201cOne oft\", \"en meets his destiny on the road he takes to avoid it\\u201d? The presence of \\nthat initial PR kicked off \", \"an unprecedented debate about the !! feature, with many folks liking the \\nconcept but a myriad of di\", \"fferent opinions about  exactly how it should be exposed, and in the end, \\nthe only common ground wa\", \"s to cut the feature. In response, dotnet/runtime#68178  undid all usage \\nof !!, replacing most of i\", \"t with ArgumentNul lException.ThrowIfNull . There are now ~5000 uses of \\nArgumentNullException.Throw\", \"IfNull  across dotnet/runtime , making it one of our most popular  \\n210 CHAPTER 21 | Exceptions  \\n A\", \"PIs internally. Interestingly, while we expected a peanut -buttery effect of slight perf improvement\", \"s in \\nmany places, our performance auto -analysis system flagged several performance improvements (e\", \".g. \\ndotnet/perf -autofiling -issues#3531 ) as stemming from these changes, in particular because it\", \" enabled \\nthe JIT\\u2019s inlining heuristics to flag more methods for inlining.  \\nWith the success of Arg\", \"umentNullException.ThrowIfNull  and along with its significant roll -out in \\n.NET 7, .NET 7 also see\", \"s th e introduction of several more such throw helpers. dotnet/runtime#61633 , \\nfor example, adds an\", \" overload of ArgumentNullException.ThrowIfNull  that works with pointers. \\ndotnet/runtime#64357  add\", \"s the new ArgumentException.ThrowIfNullOrEmpty  helper as well as \\nusing it in several hundred place\", \"s. And dotnet/runtime#58684  from  \\n[@Bibletoon](https://github.com/Bibletoon) adds the new ObjectDi\", \"sposedException.ThrowIf  helper \\n(tweaked by dotnet/runtime#71544  to help ensure it\\u2019s inlineable), \", \"which is then used at over a \\nhundred additional call sites by dotnet/runtime#71546 .  \\n211 CHAPTER \", \"22 | Registry  \\n CHAPTER  22 \\nRegistry  \\nOn Windows, the Registry is a database provided by the OS f\", \"or applications and the system itself to \\nload and store configuration settings. Practically every a\", \"pplication accesses the registry. I just tried a \\nsimple console app : \\nConsole. WriteLine (\\\"Hello, \", \"world\\\" ); \\nbuilt it as release, and then ran the resulting .exe. That execution alone triggered 64 R\", \"egQueryValue  \\noperations (as visible via SysInternals\\u2019 Process Monitor  tool). The core .NET librar\", \"ies even access the \\nregistry for a variety of purposes, such as for gathering data for TimeZoneInfo\", \" , gathering data for \\nvarious calendars like HijriCalendar  and JapaneseCalendar , or for serving u\", \"p environment var iables \\nas part of Environment.GetEnvironmentVariable(EnvironmentVariableTarget)  \", \"with \\nEnvironmentVariableTarget.User  or EnvironmentVariableTarget.Machine . \\nIt\\u2019s thus beneficial t\", \"o streamline access to registry data on Windows, in particular for reducing \\noverheads in startup pa\", \"ths where the registry is frequently accessed. dotnet/runtime#66918  does just \\nthat. Previously, ca\", \"lling RegistryKey.GetValue  would make a call to RegQueryValueEx  with a null \\nbuffer; this tells th\", \"e RegQueryValueEx  method that the caller wants to know how big a buffer is \\nrequired in order to st\", \"ore the value for the key. The imp lementation would then allocate a buffer of \\nthe appropriate size\", \" and call RegQueryValueEx  again, and for values that are to be returned as strings, \\nwould then all\", \"ocate a string based on the data in that buffer. This PR instead recognizes that the vast \\nmajo rity\", \" of data returned from calls to the registry is relatively small. It starts with a stackalloc \\u2019d \\nbu\", \"ffer of 512 bytes, and uses that buffer as part of the initial call to RegQueryValueEx . If the buff\", \"er \\nwas sufficiently large, we no longer have to make a second system call to retrieve the actual da\", \"ta: we \\nalready got it. If the buffer was too small, we rent an ArrayPool  buffer of sufficient size\", \" and use that \\npooled buffer for the subsequent RegQueryValueEx  call. Except in situations where we\", \" actually need \\nto return a byte[]  array to the caller (e.g.  the type of the key is REG_BINARY ), \", \"this avoids the need for \\nthe allocated byte[] . And for keys that return strings (e.g.  the type of\", \" the key is REG_SZ ), previously \\nthe old implementation would have allocated a t emporary char[]  t\", \"o use as the buffer passed to \\nRegQueryValueEx , but we can instead just reinterpret cast (e.g. Memo\", \"ryMarshal.Cast ) the original \\nbuffer (whether a stackalloc \\u2019d span or the rented buffer as a Span<c\", \"har> ), and use that to construct \\nthe resulti ng string.  \\nprivate static readonly  RegistryKey s_n\", \"etFramework = \\nRegistry. LocalMachine .OpenSubKey (@\\\"SOFTWARE \\\\Microsoft \\\\.NETFramework\\\" ); \\n \\n[Benc\", \"hmark] public string RegSz() => (string)s_netFramework. GetValue (\\\"InstallRoot\\\" ); \\n   \\n212 CHAPTER \", \"22 | Registry  \\n Method  Runtime  Mean  Ratio  Allocated  Alloc Ratio  \\nRegSz  .NET 6.0  6.266 us  1\", \".00 200 B  1.00 \\nRegSz  .NET 7.0  3.182 us  0.51 96 B 0.48  \\n213 CHAPTER 23 | Analyzers  \\n CHAPTER  \", \"23 \\nAnalyzers  \\nThe ability to easily plug custom code, whether for analyzers or source generators, \", \"into the Roslyn \\ncompiler is one of my favorite features in all of C#. It means the developers worki\", \"ng on C# don\\u2019t need \\nto be solely responsible for highlighting every possible thing you might want t\", \"o diagnose in your \\ncode. Instead, library authors can write their own analyzers, ship them either i\", \"n dedicated nuget \\npackages or as side -by-side in nuget packages with APIs, and those analyzers aug\", \"ment the compiler\\u2019s \\nown analysis to h elp developers write better code. We ship a large number of a\", \"nalyzer rules in the \\n.NET SDK, many of which are focused on performance, and we augment that set wi\", \"th more and more \\nanalyzers every release. We also work to apply more and more of those rules aga in\", \"st our own \\ncodebases in every release. .NET 7 is no exception.  \\nOne of my favorite new analyzers w\", \"as added in dotnet/roslyn -analyzers#5594  from \\n[@NewellClark](https://github.com/N ewellClark) (an\", \"d tweaked in dotnet/roslyn -analyzers#5972 ). In \\nmy .NET 6 performance  post, I t alked about some \", \"of the overheads possible when types aren\\u2019t sealed:  \\n\\u2022 Virtual calls are more expensive than regula\", \"r non -virtual invocation and generally can\\u2019t be \\ninlined, since the JIT doesn\\u2019t know what is the ac\", \"tual type of the instance and thus the actual  \\ntarget of the invocation (at least not without assis\", \"tance from PGO). But if the JIT can see that a \\nvirtual method is being invoked on a sealed type, it\", \" can devirtualize the call and potentially even \\ninline it.  \\n\\u2022 If a type check (e.g. something is t\", \"ypeof(Som eType) ) is performed where SomeType  is sealed, \\nthat check can be implemented along the \", \"lines of something is not null && \\nsomething.GetType() == typeof(SomeType) . In contrast, if SomeTyp\", \"e  is not sealed, the check is \\ngoing to be more along the lines of CastHelpers.IsInstanceOfClass(ty\", \"peof(SomeType), \\nsomething) , where IsInstanceOfClass  is a non -trivial (and today non -inlined) ca\", \"ll into a JIT \\nhelper method in Corelib that not only checks for null and for direct equality with t\", \"he specified \\ntype, but also linearl y walks the parent hierarchy of the type of the object being te\", \"sted to see if it \\nmight derive from the specified type.  \\n\\u2022 Arrays in .NET are covariant, which mea\", \"ns if types B and C both derive from type A, you can have \\na variable typed as A[] that\\u2019s storing a \", \" B[]. Since C derives from A, it\\u2019s valid to treat a C as an A, \\nbut if the A[] is actually a B[], st\", \"oring a C into that array would mean storing a C into a B[], \\nwhich is invalid. Thus, every time you\", \" store an object reference into an array of reference type s, \\nadditional validation may need to be \", \"performed to ensure the reference being written is \\ncompatible with the concrete type of the array i\", \"n question. But, if A in this example were sealed, \\nnothing could derive from it, so storing objects\", \" into it doesn\\u2019t r equire such covariance checks.  \\n\\u2022 Spans shift this covariance check to their con\", \"structor; rather than performing the covariance \\ncheck on every write into the array, the check is p\", \"erformed when a span is being constructed \\nfrom an array, such that if you try to  create a new Span\", \"<A>(bArray) , the ctor will throw an \\nexception. If A is sealed, the JIT is able to elide such a che\", \"ck as well.   \\n214 CHAPTER 23 | Analyzers  \\n It effectively would be impossible for an analyzer to b\", \"e able to safely recommend sealing public types. \\nAfter all, it has no kno wledge of the type\\u2019s purp\", \"ose, how it\\u2019s intended to be used, and whether anyone \\noutside of the assembly containing the type a\", \"ctually derives from it. But internal and private types are \\nanother story. An analyzer can actually\", \" see every possible type that cou ld be deriving from a private \\ntype, since the analyzer has access\", \" to the whole compilation unit containing that type, and it needn\\u2019t \\nworry about compatibility becau\", \"se anything that could derive from such a type necessarily must also \\nbe non -public and would  be r\", \"ecompiled right along with the base type. Further, with the exception of \\nassemblies annotated as In\", \"ternalsVisibleTo, an analyzer can have the same insight into internal types. \\nThus, this PR adds CA1\", \"852, an analyzer that flags in non -InternalsVisibleTo  assemblies all private and \\ninternal types t\", \"hat aren\\u2019t sealed and that have no types deriving from them and recommends they be \\nsealed. (Due to \", \"some current limitations in the infrastructure around fixers and how this analyzer had \\nto be writte\", \"n in order to be able to see all of the types in the assembly, the analyzer for CA1852 \\ndoesn\\u2019t show\", \" up in Visual Studio. It can, however, be applied using the dotnet format  tool. And if \\nyou bump up\", \" the level of the rule from info to warning or error, it\\u2019ll show up as pa rt of builds as well.)  \\nI\", \"n .NET 6, we sealed over 2300 types, but even with that, this analyzer ended up finding more to seal\", \". \\ndotnet/runtime#59941  from [@NewellClark](https://github.com/Newell Clark) sealed another ~70 \\nty\", \"pes, and dotnet/runtime#68268  which enabled the rule as an warning in dotnet/runtime  (which \\nbuild\", \"s with warning s-as-errors) sealed another ~100 types. As a larger example of the rule in use, \\nASP.\", \"NET hadn\\u2019t done much in the way of sealing types in previous releases, but with CA1852 now in \\nthe .\", \"NET SDK, dotnet/aspnetcore#41457  enabled the analyzer and sealed more than ~1100 types.  \\nAnother n\", \"ew analyzer, CA1854, was added in dotnet/roslyn -analyzers#4851  from \\n[@CollinAlpert](https://githu\", \"b.com/CollinAlpert) and then enabled in dotnet/runtime#70157 . This \\nanalyzer looks for the surprisi\", \"ngly common pattern where a Dictionary<TKey, TValue> \\u2019s \\nContainsKey  is used to determine whether a\", \" dictionary contains a particular entry, and then if it does, \\nthe dictionary\\u2019s indexer is used to r\", \"etrieve the value associated with the key, e.g.  \\nif (_dictionary. ContainsKey (key)) \\n{ \\n    var va\", \"lue = _dictionary[key];  \\n    Use(value);  \\n} \\nDictionary\\u2019s TryGetValue  method already combines bot\", \"h of these operations, both looking up the \\nkey and retrieving its value if it exists, doing so as a\", \" single operation:  \\nif (_dictionary. TryGetValue (key, out var value)) \\n{ \\n     Use(value);  \\n} \\nA \", \"benefit of this, in addition to arguably being simpler, is that it\\u2019s also faster. While Dictionary<T\", \"Key, \\nTValue>  provides very fast lookups, and while the performance of those lookups has gotten fas\", \"ter \\nover time , doing fast work is still more expensive than doing no work, and if we can do one lo\", \"okup \\ninstead of two, that can result in a meaningful performance boost, in particular if it\\u2019s being\", \" performed \\non a fast path. And we can see from this simple benchmark tha t looks up a word in a dic\", \"tionary that, \\nfor this operation, making distinct calls to ContainsKey  and the indexer does indeed\", \" double the cost \\nof using the dictionary, almost exactly:   \\n215 CHAPTER 23 | Analyzers  \\n private \", \"readonly  Dictionary< string, int> _counts = Regex. Matches( \\n    new \\nHttpClient ().GetStringAsync \", \"(\\\"https://www.gutenberg.org/cache/epub/100/pg100.txt\\\" ).Result, \\n@\\\"\\\\b\\\\w+\\\\b\\\") \\n    .Cast<Match>()  \\n \", \"   .GroupBy(word => word. Value, StringComparer. OrdinalIgnoreCase ) \\n    .ToDictionary (word => wor\", \"d. Key, word => word. Count(), \\nStringComparer. OrdinalIgnoreCase ); \\n \\nprivate string _word = \\\"the\\\"\", \"; \\n \\n[Benchmark (Baseline = true)] \\npublic int Lookup1() \\n{ \\n    if (_counts. ContainsKey (_word))  \", \"\\n    { \\n        return _counts[_word];  \\n    } \\n \\n    return -1; \\n} \\n \\n[Benchmark]  \\npublic int Look\", \"up2() \\n{ \\n    if (_counts. TryGetValue (_word, out int count)) \\n    { \\n        return count; \\n    } \", \"\\n \\n    return -1; \\n} \\nMethod  Mean  Ratio  \\nLookup1  28.20 ns  1.00 \\nLookup2  14.12 ns  0.50 \\nSomewh\", \"at ironically, even as I write this example, the analyzer and its auto-fixer are helpfully trying to\", \" \\nget me to change my benchmark code:   \\n216 CHAPTER 23 | Analyzers  \\n  \\nSimilarly, dotnet/roslyn -a\", \"nalyzers#4836  from [@chucker](https://github.com/chucker) added CA1853, \\nwhich looks f or cases whe\", \"re a Remove  call on a dictionary is guarded by a ContainsKey  call. It seems \\nit\\u2019s fairly natural f\", \"or developers to only call Remove  on a dictionary once they\\u2019re sure the dictionary \\ncontains the th\", \"ing being removed; maybe they think Remove  will t hrow an exception if the specified \\nkey doesn\\u2019t e\", \"xist. However, Remove  actually allows this as a first -class scenario, with its return Boolean  \\nva\", \"lue indicating whether the key was in the dictionary (and thus successfully removed) or not. An \\nexa\", \"mple of this comes from dotnet/runtime#68724 , where CA1853 was enabled for dotnet/runtime. \\nThe Eve\", \"ntPipeEventDispatcher  type\\u2019s RemoveEventListener  method had code like this:  \\nif (m_subscriptions.\", \" ContainsKey (listener))  \\n{ \\n    m_subscriptions. Remove(listener);  \\n} \\nwhich the analyzer flagged\", \" and which it\\u2019s auto -fixer replaced with just:  \\nm_subscriptions. Remove(listener);  \\nNice and simp\", \"le. And faster, since as with the TryGetValue case, t his is now doing a single dictionary \\nlookup r\", \"ather than two. :::{custom -style=Figure} \\n \\n217 CHAPTER 23 | Analyzers  \\n  ::: \\nAnother nice analyz\", \"er added in dotnet/roslyn -analyzers#5907  and dotnet/roslyn -analyzers#5910  is \\nCA1851, which look\", \"s for code that iterates through some kinds of enumerables multiple times. \\nEnumerating an enumerato\", \"r, whether directly or via helper methods like those in LINQ, c an have non -\\ntrivial cost. Calling \", \"GetEnumerator typically allocates an enumerator object, and every item yielded \\ntypically involves t\", \"wo interface calls, one to MoveNext and one to Current. If something can be done \\nvia a single pass \", \"over the enumerable rath er than multiple passes, that can save such costs. In some \\ncases, seeing p\", \"laces this analyzer fires can also inspire changes that avoid any use of enumerators. For \\nexample, \", \"dotnet/runtime#6729 2 enabled CA1851 for dotnet/runtime , and in doing so, it fixed several \\ndiagnos\", \"tics issued by the analyzer (even in a code base that\\u2019s already fairly stringent about \\nenumerator a\", \"nd LINQ usage). As an exam ple, this is a function in \\nSystem.ComponentModel.Composition that was fl\", \"agged by the analyzer:  \\nprivate void InitializeTypeCatalog (IEnumerable<Type> types)  \\n{ \\n    forea\", \"ch (Type type in types) \\n    { \\n        if (type == null) \\n        { \\n            throw ExceptionBui\", \"lder. CreateContainsNullElement (nameof(types));  \\n        } \\n        else if (type.Assembly .Reflec\", \"tionOnly ) \\n        { \\n            throw new ArgumentException (SR.Format(SR.Argument_ElementReflect\", \"ionOnlyType , \\nnameof(types)), nameof(types));  \\n        } \\n    } \\n \\n    _types = types. ToArray(); \", \"\\n} \\nThe method\\u2019s purpose is to convert the enumerable into an array to be stored, but also to valida\", \"te \\nthat the contents are all non -null and non -\\u201cReflectionOnly.\\u201d To achieve that, the method is fi\", \"rst using \\na foreach to  iterate through the enumerable, validating each element along the way, and \", \"then once \\nit\\u2019s done so, it calls ToArray() to convert the enumerable into an array. There are multi\", \"ple problems \\n \\n218 CHAPTER 23 | Analyzers  \\n with this. First, it\\u2019s incurring the expense of intera\", \"ting through t he enumerable twice, once for the \\nforeach and once for the ToArray() , which interna\", \"lly needs to enumerate it if it can\\u2019t do something \\nspecial like cast to ICollection<Type>  and Copy\", \"To  the data out of it. Second, it\\u2019s possible the caller\\u2019s \\nIEnumerable<Type>  changes on each itera\", \"tion, so any validation done in the first iteration isn\\u2019t \\nactually ensuring there aren\\u2019t nulls in t\", \"he resulting array, for example. Since the expectation of the \\nmethod is that all inputs are valid a\", \"nd we don\\u2019t need to optimize for the  failure cases, the better \\napproach is to first call ToArray()\", \"  and then validate the contents of that array, which is exactly what \\nthat PR fixes it to do:  \\npri\", \"vate void InitializeTypeCatalog (IEnumerable<Type> types)  \\n{ \\n    Type[] arr = types. ToArray(); \\n \", \"   foreach (Type type in arr) \\n    { \\n        if (type == null) \\n        { \\n            throw Except\", \"ionBuilder. CreateContainsNullElement (nameof(types));  \\n        } \\n \\n        if (type.Assembly .Ref\", \"lectionOnly ) \\n        { \\n            throw new ArgumentException (SR.Format(SR.Argument_ElementRefl\", \"ectionOnlyType , \\nnameof(types)), nameof(types));  \\n        } \\n    } \\n \\n \\n    _types = arr;  \\n} \\nWit\", \"h that, we only ever iterate it once (and possibly 0 times if ToArray  can special -case it, and bon\", \"us, \\nwe validate on  the copy rather than on the mutable original.  \\nYet another helpful analyzer is\", \" the new CA1850 introduced in dotnet/roslyn -analyzers#4797  from \\n[@wzchua](https://github.com/wzch\", \"ua). It u sed to be that if you wanted to cryptographically hash \\nsome data in .NET, you would creat\", \"e an instance of a hash algorithm and call its ComputeHash \\nmethod, e.g.  \\npublic byte[] Hash(byte[]\", \" data)  \\n{ \\n    using (SHA256 h = SHA256. Create()) \\n    { \\n        return h.ComputeHash (data); \\n  \", \"  } \\n} \\nHowever, .NET 5 introduced new \\u201cone -shot\\u201d hashing methods, which obviates the need to creat\", \"e a \\nnew HashAlgorithm  instance, providing a static method that performs the whole operation.  \\npub\", \"lic byte[] Hash(byte[] data)  \\n{ \\n    return SHA256.HashData (data); \\n} \\nCA1850 finds occurrences of\", \" the former pattern and recommends changing them to the latter.   \\n219 CHAPTER 23 | Analyzers  \\n The\", \" result is not only simpler, it\\u2019s also faster:  \\nprivate readonly  byte[] _data = RandomNumberGenera\", \"tor. GetBytes (128); \\n \\n[Benchmark (Baseline = true)] \\npublic byte[] Hash1() \\n{ \\n    using (SHA256 h\", \" = SHA256. Create()) \\n    { \\n        return h.ComputeHash (_data);  \\n    } \\n} \\n \\n[Benchmark]  \\npubli\", \"c byte[] Hash2() \\n{ \\n    return SHA256.HashData (_data);  \\n} \\nMethod  Mean  Ratio  Allocated  Alloc \", \"Ratio  \\nHash1  1,212.9 ns  1.00 240 B  1.00 \\nHash2  950.8 ns  0.78 56 B 0.23 \\n \\nThe .NET 7 SDK also \", \"includes new analyzers around [GeneratedRegex(...)]  (dotnet/runtime#68976 ) \\nand the already mentio\", \"ned ones for LibraryImport, all of which help to move your code forwards to \\nmore modern patterns th\", \"at have better performance characteristics.  \\n \\n220 CHAPTER 23 | Analyzers  \\n  \\nThis release also sa\", \"w dotnet/runtime  turn on a bunch of additional IDEXXXX code style rules and \\nmake a huge number of \", \"code changes in response. Most of the resulting changes are purely about \\nsimplifying the c ode, but\", \" in almost every case some portion of the changes also have a functional and \\nperformance impact.  \\n\", \"Let\\u2019s start with IDE0200, which is about removing unnecessary lambdas. Consider a setup like this:  \", \"\\npublic class C \\n{ \\n    public void CallSite () => M(i => Work(i)); \\n \\n    public void M(Action< int\", \"> action) { }  \\n    private static void Work(int value) { }  \\n} \\nHere we have a method CallSite  tha\", \"t\\u2019s invoking a method M and passing a lambda to it. Method M \\naccepts an Action<int> , and the call \", \"site is pass ing a lambda that takes the supplied Int32  and \\npasses it off to some static functiona\", \"lity. For this code, the C# compiler is going to generate \\nsomething along the lines of this:  \\npubl\", \"ic class C \\n{ \\n    [CompilerGenerated]  \\n    private sealed class <>c \\n    { \\n        public static \", \"readonly  <>c <>9 = new <>c(); \\n \\n        public static Action<int> <>9__0_0; \\n \\n        internal  v\", \"oid <CallSite> b__0_0(int i) => Work(i); \\n    } \\n \\n    public void CallSite () => M(<>c.<>9__0_0 ??=\", \" new \\nAction<int>(<>c.<> 9.<CallSite>b__ 0_0)); \\n \\n    public void M(Action< int> action) { }  \\n    \", \"private static void Work(int value) { }  \\n} \\nThe most important aspect of this is that <>9__0_0  fie\", \"ld the compiler emitted. That field is a cache for \\nthe delegate created in CallSite . The firs t ti\", \"me CallSite  is invoked, it\\u2019ll allocate a new delegate for \\nthe lambda and store it into that field.\", \" For all subsequent invocations, however, it\\u2019ll find the field is \\n \\n221 CHAPTER 23 | Analyzers  \\n n\", \"on-null and will just reuse the same delegate. Thus, this lambda only ever results in a single \\nallo\", \"cat ion for the whole process (ignoring any race conditions on the initial lazy initialization such \", \"that \\nmultiple threads all racing to initialize the field might end up producing a few additional un\", \"necessary \\nallocations). It\\u2019s important to recognize this cach ing only happens because the lambda d\", \"oesn\\u2019t access \\nany instance state and doesn\\u2019t close over any locals; if it did either of those thing\", \"s, such caching \\nwouldn\\u2019t happen. Secondarily, it\\u2019s interesting to note the pattern the compiler use\", \"s for the lambda \\nitself. Note that generated <CallSite>b__0_0  method is generated as an instance m\", \"ethod, and the \\ncall site refers to that method of a singleton instance that\\u2019s used to initialize a \", \"<>9 field. That\\u2019s done \\nbecause delegates to static methods use something called a \\u201cshuffle thunk\\u201d t\", \"o move arguments into \\nthe right place for the target method invocation, making delegates to statics\", \" ever so slightly more \\nexpensive to invoke than delegates to instance methods.  \\nprivate Action _in\", \"stance = new C().InstanceMethod ; \\nprivate Action _static = C. StaticMethod ; \\n \\n[Benchmark (Baselin\", \"e = true)] \\npublic void InvokeInstance () => _instance (); \\n \\n[Benchmark]  \\npublic void InvokeStatic\", \" () => _static();     \\n \\nprivate sealed class C \\n{ \\n    public static void StaticMethod () { } \\n    \", \"public void InstanceMethod () { } \\n} \\nMethod  Mean  Ratio  \\nInvokeInstance  0.8858 ns  1.00 \\nInvokeS\", \"tatic  1.3979 ns  1.58 \\nSo, the compiler is able to cache references to lambdas, great. What about m\", \"ethod groups, i.e.  where \\nyou just name the method directly? Previously, if changed my code to:  \\np\", \"ublic class C \\n{ \\n    public void CallSite () => M(Work); \\n \\n    public void M(Action< int> action) \", \"{ }  \\n    private static void Work(int value) { }  \\n} \\nthe compiler would generate the equivalent of\", \":  \\npublic class C \\n{ \\n    public void CallSite () => M(new Action<int>(Work));  \\n \\n    public void \", \"M(Action< int> action) { }  \\n    private static void Work(int value) { }  \\n}  \\n222 CHAPTER 23 | Anal\", \"yzers  \\n which has the unfortunate effect of allocating a new delegate on every invocation, even tho\", \"ugh we\\u2019re \\nstill dealing with the exact same static method. Thanks to dotnet/roslyn#58288  from \\n[@p\", \"awche n](https://github.com/pawchen), the compiler will now generate the equivalent of:  \\npublic cla\", \"ss C \\n{ \\n    [CompilerGenerated]  \\n    private static class <>O \\n    { \\n        public static Action\", \"<int> <0>__Work;  \\n    } \\n \\n    public void CallSite () => M(<>O.<0>__Work ??= new Action<int>(Work)\", \");  \\n \\n    public void M(Action< int> action) { }  \\n    private static void Work(int value) { }  \\n} \", \"\\nNote we again have a caching field that\\u2019s used to enable allocating the delegate once and caching i\", \"t. \\nThat me ans that places where code was using a lambda to enable this caching can now switch back\", \" to \\nthe cleaner and simpler method group way of expressing the desired functionality. There is the \", \"\\ninteresting difference to be cognizant of that since we don\\u2019t have a lambda which required the \\ncom\", \"piler emitting a new method for, we\\u2019re still creating a delegate directly to the static method. \\nHow\", \"ever, the minor difference in thunk overhead is typically made up for by the fact that we don\\u2019t \\nhav\", \"e a second method to invoke; in the common case where the static helper being invoked isn\\u2019t \\ninlinab\", \"le (because it\\u2019s not super tiny, because it has exception handling, etc.), we previously would \\nhave\", \" incurred the cost of the delegate invocation plus the non -inlinable method call, and n ow we just \", \"\\nhave the cost of an ever -so-slightly more expensive delegate invocation; on the whole, it\\u2019s typica\", \"lly a \\nwash.  \\nAnd that brings us to IDE0200, which recognizes lambda expressions that can be remove\", \"d. \\ndotnet/runtime#71011  enabled the analyzer for dotnet/runtime , resulting in more than 100 call \", \"sites \\nchanging accordingly. However, IDE0200 does more than just this mostly stylistic chang e. It \", \"also \\nrecognizes some patterns that can make a more substantial impact. Consider this code that was \", \"\\nchanged as part of that PR:  \\nAction disposeAction;  \\nIDisposable? disposable = null; \\n... \\nif (dis\", \"posable != null) \\n{ \\n    disposeAction = () => disposable. Dispose(); \\n} \\nThat delegate closes over \", \"the disposable  local, which means this method needs to allocate a display \\nclass. But IDE0200 recog\", \"nizes that instead of closing over disposable , we can create the delegate \\ndirectly to the Dispose \", \"method:  \\nAction disposeA ction; \\nIDisposable? disposable = null; \\n... \\nif (disposable != null) \\n{  \", \"\\n223 CHAPTER 23 | Analyzers  \\n     disposeAction = disposable. Dispose; \\n} \\nWe still get a delegate \", \"allocation, but we avoid the display class allocation, and as a bonus we save on \\nthe additional met\", \"adata required for the  synthesized display class and method generated for the \\nlambda.  \\nIDE0020 is\", \" another good example of an analyzer that is primarily focused on making code cleaner, \\nmore maintai\", \"nable, more modern, but that can also lead to removing overhead from many different  \\nplaces. The an\", \"alyzer looks for code performing unnecessary duplicative casts and recommends using \\nC# pattern matc\", \"hing syntax instead. For example, dotnet/runtime#70523  enabled the analyzer an d \\nswitched more tha\", \"n 250 locations from code like:  \\nif (value is SqlDouble)  \\n{ \\n    SqlDouble i = (SqlDouble)value;  \", \"\\n    return CompareTo (i); \\n} \\nto instead be like:  \\nif (value is SqlDouble i)  \\n{ \\n    return Compa\", \"reTo (i); \\n} \\nIn addition to being cleaner, this ends up saving a cast operation, which can add meas\", \"urable \\noverhead if the JIT is unable to remove it:  \\nprivate object _value = new List<string>(); \\n \", \"\\n[Benchmark (Baseline = true)] \\npublic List<string> WithCast () \\n{ \\n    object value = _value;  \\n   \", \" return value is List<string> ? (List< string>)value : null; \\n} \\n \\n[Benchmark]  \\npublic List<string>\", \" WithPattern () \\n{ \\n    object value = _value;  \\n    return value is List<string> list ? list : null\", \"; \\n} \\nMethod  Mean  Ratio  \\nWithCast  2.602 ns  1.00 \\nWithPattern  1.886 ns  0.73 \\nThen there\\u2019s IDE0\", \"031, which promotes using null propagation features of C#. This analyzer typically \\nmanifests as rec\", \"ommending changing snippets like:  \\nreturn _value != null ? _value. Property  : null; \\ninto code tha\", \"t\\u2019s instead like:   \\n224 CHAPTER 23 | Analyzers  \\n return _value?. Property ; \\nNice, concise, and pr\", \"imarily about cleaning up the code and making it simpler and more maintainable \\nby utilizing newer C\", \"# syntax. However, there is also a small performance advantage in some situations \\nas well. For exam\", \"ple, conside r this snippet:  \\npublic class C \\n{ \\n    private C _value;  \\n     \\n    public int? Get1\", \"() => _value != null ? _value. Prop : null; \\n    public int? Get2() => _value?. Prop; \\n     \\n    pub\", \"lic int Prop => 42; \\n} \\nThe C# compiler lowers these expressions to the equivalent of this:  \\npublic\", \" Nullable< int> Get1() \\n{ \\n    if (_value == null) return null; \\n    return _value.Prop; \\n} \\n \\npubli\", \"c Nullable< int> Get2() \\n{ \\n    C value = _value;  \\n    if (value == null) return null; \\n    return \", \"value.Prop; \\n} \\nfor which the JIT then genera tes: \\n; Program.Get1()  \\n       push      rax  \\n      \", \" mov       rdx,[rcx+8]  \\n       test      rdx,rdx  \\n       jne       short M00_L00  \\n       xor     \", \"  eax,eax  \\n       add       rsp,8  \\n       ret \\nM00_L00:  \\n       cmp       [rdx],dl  \\n       mov  \", \"     dword ptr [rsp+4] ,2A \\n       mov       byte ptr [rsp],1  \\n       mov       rax,[rsp]  \\n       \", \"add       rsp,8  \\n       ret \\n; Total bytes of code 40  \\n \\n; Program.Get2()  \\n       push      rax  \", \"\\n       mov       rax,[rcx+8]  \\n       test      rax,rax  \\n       jne       short M00_L00  \\n       x\", \"or       eax,eax  \\n       add       rsp,8  \\n       ret \\nM00_L00:   \\n225 CHAPTER 23 | Analyzers  \\n   \", \"     mov       dword ptr [rsp+4],2A  \\n       mov       byte ptr [rsp],1  \\n       mov       rax,[rsp]\", \"  \\n       add       rsp,8  \\n       ret \\n; Total bytes of code 38  \\nNote how the Get1  variant has an\", \" extra  cmp instruction ( cmp [rdx],dl ) in the otherwise identical \\nassembly to Get2  (other than r\", \"egister selection). That cmp instruction in Get1  is the JIT forcing a null \\ncheck on the second rea\", \"d of _value  prior to accessing its Prop , whereas in Get2  the null check against \\nthe local means \", \"the JIT doesn\\u2019t need to add an additional null check on the second use of the local, \\nsince nothing \", \"could have changed it. dotnet/runtime#70965  rolled ou t additional use of the null \\npropagation ope\", \"rator via auto -fixing IDE0031, resulting in ~120 uses being improved.  \\nAnother interesting example\", \" is IDE0060, which finds unused parameters and recommends removing \\nthem. This was done for non -pub\", \"lic members in Sy stem.Private.CoreLib in dotnet/runtime#63015 . As \\nwith some of the other mentione\", \"d rules, it\\u2019s primarily about good hygiene. There can be some small \\nadditional cost associated with\", \" passing addi tional parameters (the overhead of reading the values at \\nthe call site, putting them \", \"into the right register or stack location, etc., and also the metadata size \\nassociated with the add\", \"itional parameter information), but the larger benefit comes from auditi ng all \\nof the cited violat\", \"ions and finding places where work is simply being performed unnecessarily. For \\nexample, that PR ma\", \"de some updates to the TimeZoneInfo  type\\u2019s implementation for Unix. In that \\nimplementation is a TZ\", \"if_ParseRaw  method, which is used  to extract some information from a time \\nzone data file. Amongst\", \" many input and output parameters, it had out bool[] StandardTime, out \\nbool[] GmtTime , which the i\", \"mplementation was dutifully filling in by allocating and populating new \\narrays for each. The c all \", \"site for TZif_ParseRaw  was then taking those arrays and feeding them into \\nanother method TZif_Gene\", \"rateAdjustmentRules , which ignored them! Thus, not only was this PR \\nable to remove those parameter\", \"s from TZif_GenerateAdjustmentRules , it was able to upda te \\nTZif_ParseRaw  to no longer need to al\", \"locate and populate those arrays at all, which obviously yields \\na much larger gain.  \\nOne final exa\", \"mple of peanut -buttery performance improvements from applying an analyzer comes \\nfrom dotnet/runtim\", \"e#70896  and dotnet/runtime#71361 , which applied IDE0029 across \\ndotnet/runtime. IDE0029 flags case\", \"s where null coalescing can be used, e.g.  flagging:  \\nreturn message != null ? message : string.Emp\", \"ty; \\nand recommending it be converted to:  \\nreturn message ?? string.Empty; \\nAs with some of the pre\", \"vious rules discussed, that in and of itself doesn\\u2019t make a meaningful \\nperformance improvement, and\", \" rather is about  clarity and simplicity. However, in various cases it can. \\nFor example, the aforem\", \"entioned PRs contained an example like:  \\nnull != foundColumns[i] ? foundColumns[i] : DBNull. Value;\", \" \\nwhich is rewritten to:  \\nfoundColumns[i] ?? DBNull. Value \\nThis avoids an unnece ssary re -access \", \"to an array. Or again from those PRs the expression:   \\n226 CHAPTER 23 | Analyzers  \\n entry.GetKey(_\", \"thisCollection) != null ? entry. GetKey(_thisCollection) : \\\"key\\\" \\nbeing changed to:  \\nentry.GetKey(_\", \"thisCollection) ?? \\\"key\\\" \\nand avoiding an unnecessary table lookup.   \\n227 CHAPTER 24 | What\\u2019s Next?\", \"  \\n CHAPTER  24 \\nWhat\\u2019s Next?  \\nWhew! That was a lot. Congrats on getting through it all.  \\nThe next\", \" step is on you. Download the latest .NET 7 bits and take them for a spin. Upgrade your apps. \\nWrite\", \" and share your own benchmarks. Provide feedback, positive and critical. Find something you \\nthink c\", \"an be better? Open an issue, or better yet, submit a PR with the fix. We\\u2019re excited to w ork with \\ny\", \"ou to polish .NET 7 to be the best .NET release yet; meanwhile, we\\u2019re getting going on .NET 8 :)  \\nU\", \"ntil next time\\u2026  \\nHappy coding!  \"]"