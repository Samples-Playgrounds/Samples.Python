Tidy Data
– A foundation for wrangling in pandas
Data Wrangling
&
Tidy data complements pandas’s vectorized *
with pandas Cheat Sheet
operations. pandas will automatically preserve
In a tidy
http://pandas.pydata.org observations as you manipulate variables. No
data set:
other format works as intuitively with pandas. M A
PandasAPI Reference Pandas User Guide Each variable is saved Each observation is *
in its own column saved in its own row
Creating DataFrames Reshaping Data
– Change layout, sorting, reindexing, renaming
a b c df.sort_values('mpg')
Order rows by values of a column (low to high).
1 4 7 10
2 5 8 11
df.sort_values('mpg', ascending=False)
3 6 9 12
Order rows by values of a column (high to low).
df = pd.DataFrame(
pd.melt(df) df.rename(columns = {'y':'year'})
{"a" : [4, 5, 6], df.pivot(columns='var', values='val')
Gather columns into rows. Rename the columns of a DataFrame
"b" : [7, 8, 9], Spread rows into columns.
"c" : [10, 11, 12]},
df.sort_index()
index = [1, 2, 3])
Sort the index of a DataFrame
Specify values for each column.
df.reset_index()
df = pd.DataFrame( Reset index of DataFrame to row numbers, moving
[[4, 7, 10], index to columns.
[5, 8, 11],
pd.concat([df1,df2]) pd.concat([df1,df2], axis=1)
df.drop(columns=['Length', 'Height'])
[6, 9, 12]],
Append rows of DataFrames Append columns of DataFrames
Drop columns from DataFrame
index=[1, 2, 3],
columns=['a', 'b', 'c'])
Specify values for each row. Subset Observations - rows Subset Variables - columns Subsets - rows and columns
a b c Use df.loc[] and df.iloc[] to select only
rows, only columns or both.
N v
Use df.at[] and df.iat[] to access a single
1 4 7 10
D df[df.Length > 7] df[['width', 'length', 'species']] value by row and column.
2 5 8 11
Extract rows that meet logical criteria. Select multiple columns with specific names. First index selects rows, second index columns.
e 2 6 9 12
df.drop_duplicates() df['width'] or df.width
df.iloc[10:20]
df = pd.DataFrame( Remove duplicate rows (only considers columns). Select single column with specific name.
Select rows 10-20.
{"a" : [4 ,5, 6], df.sample(frac=0.5) df.filter(regex='regex')
df.iloc[:, [1, 2, 5]]
"b" : [7, 8, 9], Randomly select fraction of rows. Select columns whose name matches
Select columns in positions 1, 2 and 5 (first
"c" : [10, 11, 12]}, df.sample(n=10) Randomly select n rows. regular expression regex.
column is 0).
index = pd.MultiIndex.from_tuples( df.nlargest(n, 'value')
Using query df.loc[:, 'x2':'x4']
[('d', 1), ('d', 2), Select and order top n entries.
Select all columns between x2 and x4 (inclusive).
('e', 2)], names=['n', 'v'])) df.nsmallest(n, 'value')
query() allows Boolean expressions for filtering df.loc[df['a'] > 10, ['a', 'c']]
Create DataFrame with a MultiIndex Select and order bottom n entries.
rows. Select rows meeting logical condition, and only
df.head(n)
df.query('Length > 7') the specific columns .
Select first n rows.
Method Chaining
df.query('Length > 7 and Width < 8') df.iat[1, 2] Access single value by index
df.tail(n)
df.query('Name.str.startswith("abc")', df.at[4, 'A'] Access single value by label
Select last n rows.
Most pandas methods return a DataFrame so that engine="python")
another pandas method can be applied to the result. Logic in Python (and pandas) regex (Regular Expressions) Examples
This improves readability of code.
< Less than != Not equal to '\.' Matches strings containing a period '.'
df = (pd.melt(df)
> Greater than df.column.isin(values) Group membership 'Length$' Matches strings ending with word 'Length'
.rename(columns={
'variable':'var', == Equals pd.isnull(obj) Is NaN '^Sepal' Matches strings beginning with the word 'Sepal'
'value':'val'})
<= Less than or equals pd.notnull(obj) Is not NaN '^x[1-5]$' Matches strings beginning with 'x' and ending with 1,2,3,4,5
.query('val >= 200')
>= Greater than or equals &,|,~,^,df.any(),df.all() Logical and, or, not, xor, any, all '^(?!Species$).*' Matches strings except the string 'Species'
)
Cheatsheet for pandas (http://pandas.pydata.org/ originally written by Irv Lustig, Princeton Consultants, inspired by Rstudio Data Wrangling CheatsheetGroup Data
Combine Data Sets
df.groupby(by="col") The examples below can also be applied to groups. In this case, the
adf bdf
Return a GroupBy object, grouped function is applied on a per-group basis, and the returned vectors
x1 x2 x1 x3
by values in column named "col". are of the length of the original DataFrame.
A 1 A T
shift(1) shift(-1) B 2 B F
df.groupby(level="ind")
Copy with values shifted by 1. Copy with values lagged by 1. C 3 D T
Return a GroupBy object, grouped
rank(method='dense') cumsum()
by values in index level named Standard Joins
Ranks with no gaps. Cumulative sum.
"ind".
rank(method='min') cummax() x1 x2 x3 pd.merge(adf, bdf,
Ranks. Ties get min rank. Cumulative max. A 1 T how='left', on='x1')
All of the summary functions listed above can be applied to a group. rank(pct=True) cummin() B 2 F Join matching rows from bdf to adf.
Additional GroupBy functions: Ranks rescaled to interval [0, 1]. Cumulative min. C 3 NaN
size() agg(function) rank(method='first') cumprod()
Size of each group. Aggregate group using function. Ranks. Ties go to first value. Cumulative product. x1 x2 x3 pd.merge(adf, bdf,
A 1.0 T
how='right', on='x1')
Summarize Data Handling Missing Data B 2.0 F Join matching rows from adf to bdf.
D NaN T
df['w'].value_counts() df.dropna()
x1 x2 x3
Count number of rows with each unique value of variable Drop rows with any column having NA/null data. pd.merge(adf, bdf,
A 1 T
len(df) df.fillna(value) how='inner', on='x1')
B 2 F
# of rows in DataFrame. Replace all NA/null data with value. Join data. Retain only rows in both sets.
df.shape
Make New Columns x1 x2 x3
Tuple of # of rows, # of columns in DataFrame. pd.merge(adf, bdf,
df['w'].nunique() A 1 T how='outer', on='x1')
# of distinct values in a column. B 2 F Join data. Retain all values, all rows.
C 3 NaN
df.describe()
D NaN T
Basic descriptive and statistics for each column (or GroupBy).
df.info() Filtering Joins
Prints a concise summary of the DataFrame. df.assign(Area=lambda df: df.Length*df.Height) x1 x2 adf[adf.x1.isin(bdf.x1)]
df.memory_usage() Compute and append one or more new columns. A 1 All rows in adf that have a match in bdf.
Prints the memory usage of each column in the DataFrame. df['Volume'] = df.Length*df.Height*df.Depth B 2
df.dtypes() Add single column.
Prints a Series with the dtype of each column in the DataFrame. pd.qcut(df.col, n, labels=False) x1 x2 adf[~adf.x1.isin(bdf.x1)]
Bin column into n buckets. C 3 All rows in adf that do not have a match in bdf.
ydf zdf
Vector Vector
function function x1 x2 x1 x2
A 1 B 2
pandas provides a large set of summary functions that operate on
B 2 C 3
different kinds of pandas objects (DataFrame columns, Series, pandas provides a large set of vector functions that operate on all
C 3 D 4
GroupBy, Expanding and Rolling (see below)) and produce single columns of a DataFrame or a single selected column (a pandas
values for each of the groups. When applied to a DataFrame, the Series). These functions produce vectors of values for each of the Set-like Operations
result is returned as a pandas Series for each column. Examples: columns, or a single Series for the individual Series. Examples:
x1 x2 pd.merge(ydf, zdf)
sum() min()
max(axis=1) min(axis=1) B 2 Rows that appear in both ydf and zdf
Sum values of each object. Minimum value in each object. Element-wise max. Element-wise min. C 3 (Intersection).
count() max() clip(lower=-10,upper=10) abs()
Count non-NA/null values of Maximum value in each object. Trim values at input thresholds Absolute value. x1 x2 pd.merge(ydf, zdf, how='outer')
each object. mean() A 1
Rows that appear in either or both ydf and zdf
median() Mean value of each object. Windows B 2
(Union).
Median value of each object. var() C 3
quantile([0.25,0.75]) Variance of each object. df.expanding() D 4
pd.merge(ydf, zdf, how='outer',
Quantiles of each object. std() Return an Expanding object allowing summary functions to be
indicator=True)
apply(function) Standard deviation of each applied cumulatively. x1 x2
.query('_merge == "left_only"')
Apply function to each object. object. df.rolling(n) A 1
.drop(columns=['_merge'])
Return a Rolling object allowing summary functions to be
Rows that appear in ydf but not zdf (Setdiff).
applied to windows of length n.
Cheatsheet for pandas (http://pandas.pydata.org/) originally written by Irv Lustig, Princeton Consultants, inspired by Rstudio Data Wrangling CheatsheetPlotting Frequently Used
Options
df.plot() df.plot.scatter(x='w', y='h') df.plot.hist() df.plot.pie()
Plot a line graph for the DataFrame. Plot a scatter graph of the DataFrame. Plot a histogram of the DataFrame. Plot a pie chart of the DataFrame.
Pandas offers some ‘options’ to globally
control how Pandas behaves, display etc.
Options can be queried and set via:
pd.options.option_name (where
df.plot.bar() df.plot.boxplot() df.plot.area() df.plot.hexbin()
option_name is the name of an option). For
Plot a line graph for the DataFrame. Plot a scatter graph of the DataFrame. Plot an area graph of the DataFrame. Plot a hexbin graph of the DataFrame.
example:
pd.options.display.max_rows = 20
Set the display.max_rows option to 20.
df.plot(subplots=True) df.plot(cumulative=True) df.plot(stacked=True) Functions
Separate into different graphs for each column in Creates a cumulative plot Stacks the data for the columns on top of each get_option(option)
the DataFrame. df.plot(bins=30) other. (bar, barh and area only) Fetch the value of the given option.
df.plot(title=“Graph of A against B”) Set the number of bins into which data is grouped df.plot(alpha=0.5) set_option(option)
Sets the title of the graph. (histograms) Sets the transparency of the plot to 50%. Set the value of the given option.
reset_option(options)
df.plot(subplots=True, title=['col1', 'col2', 'col3'])
Reset the values of all given options to
Arguments can be combined for more flexibility when graphing, this would plot a separate line graph for of column of a 3-columned DataFrame. The first string in the
default settings.
list of titles applies to the graph of the left-most column.
describe_option(options)
Changing Type Series String Operations Print descriptions of given options.
option_context(options)
Execute code with temporary option
Similar to python string operations, except these are vectorized to apply to the
settings that revert to prior settings after
pd.to_numeric(data) df.astype(type)
entire Series efficiently.
Convert non-numeric types to Convert data to (almost) any given s.str.count(pattern) s.str.cat() execution.
numeric. type including categorical Returns a series with the integer Concatenate elements into a single Display options
pd.to_datetime(data) df.infer_objects() counts in each element. string display.max_rows
Convert non-datetime types to Attempts to infer a better type for s.str.get(index) s.str.partition(sep) The maximum number of rows displayed
datetime type object type data. Returns a series with the data at the Splits the string on the first instance in pretty-print.
pd.to_timedelta(data) df.convert_dtypes() given index for each element. of the separator display.max_columns
Convert non- timedelta types to Convert columns to best possible s.str.join(sep) s.str.slice(start, stop, The maximum number of columns
timedelta dtypes Returns a series where each element step) displayed in pretty-print.
display.expand_frame_repr
has been concatenated. Slices each string
Datetime s.str.title() s.str.replace(pat, rep) Controls whether the DataFrame
s.dt.day
Converts the first character of each Use regex to replace patterns in each representation stretches across pages.
Extract the day (int) from the date.
word to be a capital. string. display.large_repr
With a Series containing data of type s.dt.quarter
datetime, the dt accessor is used to get s.str.len() s.str.isalnum() Controls whether a DataFrame that
Find which quarter the date lies in.
exceeds maximum rows/columns is
various components of the datetime Returns a series with the lengths of Checks whether each element is
s.dt.hour
values: each element. alpha-numeric truncated or summarized
Extract the hour.
display.precision
s.dt.year
s.dt.minute Input/Output The output display precision in decimal
Extract the year
Extract the minute.
places.
s.dt.month
s.dt.second
Extract the month as an integer. Common file types for data input include CSV, JSON, HTML which are human- display.max_colwidth
Extract the second.
readable, while the common output types are usually more optimized for The maximum width of columns, longer
performance and scalability such as feather, parquet and HDF. cells will be truncated.
Mapping df = pd.read_csv(filepath) df.to_parquet(filepath) display.max_info_columns
Read data from csv file Write data to parquet file The maximum number of columns
Apply a mapping to every element in a DataFrame or Series, useful for df = pd.read_html(filepath) df.to_feather(filepath) displayed after calling info().
recategorizing or transforming data. Read data from html file Write data to feather file display.chop_threshold
df = pd.read_excel(filepath) df.to_hdf(filepath) Sets the rounding threshold to zero when
s.map(lambda x: 2*x)
Read data from xls (and related) files Write data to HDF file displaying a Series/DataFrame.
Returns a copy of the series where every entry is doubled
df = pd.read_sql(filepath) df.to_clipboard() display.colheader_justify
df.apply(lambda s: s.max() - s.min(), axis=1)
Read data from sql file Copy object to the system clipboard Controls how column headers are justified.
Returns a Series with the difference of the maximum and minimum values of
pd.read_clipboard()
each row of the DataFrame
Read text from clipboard