cience Intera

## Python For Data Science Cheat Sheet

Machine learnir

## Python Basics

jupyter

Learn More Python for Data Science Interactively at  www.datacamp.com

Scientific computing

Create and share

Eroo IDE that ic includod

## Variables and Data Types

## Variable Assignment

```
>>> x=5 >>> x 5
```

## Calculations With Variables

```
>>> x+2 7 >>> x-2 3 >>> x*2 10 >>> x**2 25 >>> x%2 1 >>> x/float(2) 2.5
```

Sum of two variables

Subtraction of two variables

Multiplication of two variables

Exponentiation of a variable

Remainder of a variable

Division of a variable

## Types and Type Conversion

Variables to strings

Variables to integers

Variables to floats

Variables to booleans

```
str()     '5', '3.45', 'True' int()     5, 3, 1 float()    5.0, 1.0 bool()    True, True, True
```

## Asking For Help

&gt;&gt;&gt; help(str)

## Strings

```
>>> my_string = 'thisStringIsAwesome' >>> my_string 'thisStringIsAwesome'
```

## String Operations

```
>>> my_string * 2 'thisStringIsAwesomethisStringIsAwesome' >>> my_string + 'Innit' 'thisStringIsAwesomeInnit' >>> 'm' in my_string True
```

## Lists

## Also see NumPy Arrays

```
>>> a = 'is' >>> b = 'nice' >>> my_list = ['my', 'list', a, b] >>> my_list2 = [[4,5,6,7], [3,4,5,6]]
```

## Selecting List Elements

```
Subset >>> my_list[1] >>> my_list[-3] Slice >>> my_list[1:3] >>> my_list[1:] >>> my_list[:3] >>> my_list[:] Subset Lists of Lists >>> my_list2[1][0] >>> my_list2[1][:2]
```

Index starts at 0

Select item at index 1 Select 3rd last item

Select items at index 1 and 2 Select items a/fter index 0 Select items before index 3 Copy my_list my_list[list][itemOfList]

## List Operations

```
>>> my_list + my_list ['my', 'list', 'is', 'nice', 'my', 'list', 'is', 'nice'] >>> my_list * 2 ['my', 'list', 'is', 'nice', 'my', 'list', 'is', 'nice'] >>> my_list2 > 4 True
```

## List Methods

```
>>> my_list.index(a) >>> my_list.count(a) >>> my_list.append('!') >>> my_list.remove('!') >>> del(my_list[0:1]) >>> my_list.reverse() >>> my_list.extend('!') >>> my_list.pop(-1) >>> my_list.insert(0,'!') >>> my_list.sort()
```

```
Get the index of an item Count an item Append an item at a time Remove an item Remove an item Reverse the list Append an item Remove an item Insert an item Sort the list
```

## String Operations

```
>>> my_string[3]
```

```
>>> my_string[4:9]
```

## String Methods

```
>>> my_string.upper() >>> my_string.lower() >>> my_string.count('w') >>> my_string.replace('e', 'i') >>> my_string.strip()
```

## Index starts at 0

```
String to uppercase String to lowercase Count String elements Replace String elements Strip whitespaces
```

## Libraries

## Import libraries

```
>>> import numpy >>> import numpy as np Selective import >>> from math import pi
```

## Install Python

Leading open data science platform powered by Python

Free IDE that is included with Anaconda

Scientific computing

2D plo/tting

Create and share documents with live code, visualizations, text, ...

## Numpy Arrays

## Also see Lists

```
>>> my_list = [1, 2, 3, 4] >>> my_array = np.array(my_list) >>> my_2darray = np.array([[1,2,3],[4,5,6]])
```

## Selecting Numpy Array Elements

```
Subset >>> my_array[1] 2 Slice >>> my_array[0:2] array([1, 2]) Subset 2D Numpy arrays >>> my_2darray[:,0] array([1, 4])
```

## Index starts at 0

Select item at index 1

Select items at index 0 and 1

my_2darray[rows, columns]

## Numpy Array Operations

```
>>> my_array > 3 array([False, False, False,  True], dtype=bool) >>> my_array * 2 array([2, 4, 6, 8]) >>> my_array + np.array([5, 6, 7, 8]) array([6, 8, 10, 12])
```

## Numpy Array Functions

```
>>> my_array.shape >>> np.append(other_array) >>> np.insert(my_array, 1, 5) >>> np.delete(my_array,[1]) >>> np.mean(my_array) >>> np.median(my_array) >>> my_array.corrcoef() >>> np.std(my_array)
```

Get the dimensions of the array

```
Append items to an array Insert items in an array Delete items in an array Mean of the array Median of the array Correlation coefficient Standard deviation
```

## DataCamp

Learn Python for Data Science Interactively

cait Mode:

cience Interal e main ke

commana Mode:

notebooks. Ihere

Python For Data Science

• Insert Cell Above

Open...

• •Restart

IRkernel

Copy Cells

Uulia

Run Cells and Select Below •

Toggle Toolbar

*• Paste Cells Above y linvter Noteno

Restart &amp; Clear Output • • :

Jupyter Notebook

View

Edit

File

Keyboard Shortcuts

• Toggle Line Numbers

• • ... Download Widget State

• • Run Cells and Insert Below

Learn More Python for Data Science Interactively at  www.DataCamp.com

Paste Cells &amp; Replace

• Run All Above

Save and Checkpoint

Notebook Help

• Markdown

4

1

2

• • Shutdown

3

Delete Cells . •

Undo Delete Cells

Run All Below

Change kernel

..•'

Revert to Checkpoint •

Jupyter-contrib

Saving/Loading Notebooks

Download as

....

Create new notebook

• Move Cell Up

Move Cell Down

• NumPy

Close and Halt

Make a copy of the current notebook

• pandas

• Cut Cell Attachments

About

..•°

Save current notebook and record checkpoint

Insert Image .

Preview of the printed notebook

Close notebook &amp; stop running any scripts

Writing Code And Text

Code and text are encapsulated by 3 basic cell types: markdown cells, code cells, and raw NBConvert cells.

Edit Cells

Cut currently selected cells to clipboard

Paste cells from clipboard above

current cell

Paste cells from clipboard on top

of current cel

Revert

'Delete Cells'

invocation

Merge current cell with the one above

Move current cell up

Adjust metadata underlying the

current notebook

Remove cell attachments

Paste attachments of current cell

Insert Cells

Add new cell above the current one

Cheat Sheet

Help

••

5

6

7

8

10

11

12

Open an existing notebook

Rename notebook

Revert notebook to a previous checkpoint

Download notebook as

- IPython notebook

- Python

- HTML

- Markdown

- reST

- La T eX

- PDF

Copy cells from clipboard to current

cursor position

Paste cells from clipboard below

current cell

Delete current cells

Split up a cell from current cursor

position

Merge current cell with the one below

Move current cell down

Find and replace in selected cells

Copy attachments of current cell

Insert image in selected cells

Add new cell below the current one

Working with Different Programming Languages

Kernels provide computation and communication with front-end interfaces like the notebooks. There are three main kernels:

[ Python 3 O

13

14

IJulia

IRkernel

Installing Jupyter Notebook will automatically install the IPython kernel.

Restart kernel

Restart kernel &amp; run all cells

Restart kernel &amp; run all cells

Command Mode:

1

3

4

2

Edit Mode:

Executing Cells

Run selected cell(s)

Run current cells down and create a new one

above

Run all cells above the current cell

Change the cell type of current cell

toggle, toggle scrolling and clear

all output

View Cells

Toggle display of Jupyter logo and filename

Toggle line numbers in cells

Interrupt kernel

Interrupt kernel &amp;

clear all output

Connect back to a remote notebook

Run other installed kernels

11

12

Run current cells down and create a new one

below

Run all cells

Run all cells below the current cell

toggle, toggle scrolling and clear

current outputs

Toggle display of toolbar

Toggle display of cell action icons:

- None

- Edit metadata

- Raw cell format

- Slideshow

- Attachments

- T ags

Trusted

5

6

7

8

9

10

Widgets

Notebook widgets provide the ability to visualize and control changes in your data, often as a control like a slider, textbox, etc.

You can use them to build interactive GUIs for your notebooks or to synchronize stateful and stateless information between Python and

JavaScript.

Download serialized state of all widget

models in use

1

. Save and checkpoint

2

3

4

5

6

7

. Insert cell below

. Cut cell

. Copy cell(s)

. Paste cell(s) below

. Move cell up

. Move cell down

8

. Run current cell

Asking For Help

Walk through a UI tour

Edit the built-in keyboard shortcuts

Description of markdown available

in notebook

Python help topics

NumPy help topics

Matplotlib help topics

Pandas help topics

9

. Interrupt kernel

10

. Restart kernel

11

12

13

14

15

. Display characteristics

. Open command palette

. Current kernel

. Kernel status

. Log out from notebook server

List of built-in keyboard shortcuts

Notebook help topics

Information on unofficial Jupyter

Notebook extensions

IPython help topics

SciPy help topics

SymPy help topics

About Jupyter Notebook

DataCamp

Learn Python for Data Science Interactively

Save notebook with interactive

widgets

Embed current widgets

15

13

14

## Python For Data Science Cheat Sheet

## NumPy Basics

Learn Python for Data Science Interactively at  www.DataCamp.com

## NumPy

2

The NumPy library is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.

Use the following import convention:

```
>>> import numpy as np
```

## NumPy Arrays

## Creating Arrays

```
>>> a = np.array([1,2,3]) >>> b = np.array([(1.5,2,3), (4,5,6)], dtype = float) >>> c = np.array([[(1.5,2,3), (4,5,6)], [(3,2,1), (4,5,6)]], dtype = float)
```

## Initial Placeholders

```
>>> np.zeros((3,4)) >>> np.ones((2,3,4),dtype=np.int16) >>> d = np.arange(10,25,5) >>> np.linspace(0,2,9) >>> e = np.full((2,2),7) >>> f = np.eye(2) >>> np.random.random((2,2)) >>> np.empty((3,2))
```

## I/O

## Saving &amp; Loading On Disk

```
>>> np.save('my_array', a)
```

```
>>> np.savez('array.npz', a, b) >>> np.load('my_array.npy')
```

## Saving &amp; Loading Text Files

```
>>> np.loadtxt("myfile.txt") >>> np.genfromtxt("my_file.csv", delimiter=',') >>> np.savetxt("myarray.txt", a, delimiter=" ")
```

## Data Types

```
>>> np.int64 >>> np.float32 >>> np.complex >>> np.bool >>> np.object >>> np.string_ >>> np.unicode_
```

```
Create an array of zeros Create an array of ones Create an array of evenly spaced values (step value) Create an array of evenly spaced values (number of samples) Create a constant array Create a 2X2 identity matrix Create an array with random values Create an empty array
```

Signed 64-bit integer types Standard double-precision floating point Complex numbers represented by 128 floats Boolean type storing TRUE and FALSE values Python object type Fixed-length string type Fixed-length unicode type

## Inspecting Your Array

```
>>> a.shape >>> len(a) >>> b.ndim >>> e.size >>> b.dtype >>> b.dtype.name >>> b.astype(int)
```

```
Array dimensions Length of array Number of array dimensions Number of array elements Data type of array elements Name of data type Convert an array to a different type
```

## Asking For Help

&gt;&gt;&gt; np.info(np.ndarray.dtype)

## Array Mathematics

## Arithmetic Operations

```
>>> g = a - b array([[-0.5,  0. ,  0. ], [-3. , -3. , -3. ]]) >>> np.subtract(a,b) >>> b + a array([[ 2.5,  4. ,  6. ], [ 5. ,  7. ,  9. ]]) >>> np.add(b,a) >>> a / b array([[ 0.66666667,  1.        ,  1.        ], [ 0.25      ,  0.4       ,  0.5       ]]) >>> np.divide(a,b) >>> a * b array([[  1.5,   4. ,   9. ], [  4. ,  10. ,  18. ]]) >>> np.multiply(a,b) >>> np.exp(b) >>> np.sqrt(b) >>> np.sin(a) >>> np.cos(b) >>> np.log(a) >>> e.dot(f) array([[ 7.,  7.], [ 7.,  7.]])
```

```
Subtraction Subtraction Addition Addition Division Division Multiplication Multiplication Exponentiation Square root Print sines of an array Element-wise cosine Element-wise natural logarithm Dot product
```

## Comparison

```
>>> a == b array([[False,  True,  True], [False, False, False]], dtype=bool) >>> a < 2 array([True, False, False], dtype=bool) >>> np.array_equal(a, b)
```

Element-wise comparison

Element-wise comparison

Array-wise comparison

## Aggregate Functions

```
>>> a.sum() >>> a.min() >>> b.max(axis=0) >>> b.cumsum(axis=1) >>> a.mean() >>> b.median() >>> a.corrcoef() >>> np.std(b)
```

```
Array-wise sum Array-wise minimum value Maximum value of an array row Cumulative sum of the elements Mean Median Correlation coefficient Standard deviation
```

## Copying Arrays

```
>>> h = a.view() >>> np.copy(a) >>> h = a.copy()
```

Create a view of the array with the same data

Create a copy of the array

Create a deep copy of the array

## Sorting Arrays

| >>> a.sort()       | Sort an array                        |
|--------------------|--------------------------------------|
| >>> c.sort(axis=0) | Sort the elements of an array's axis |

## Subse/tting, Slicing, Indexing

```
Subse/tting >>> a[2] 3 >>> b[1,2] 6.0 Slicing >>> a[0:2] array([1, 2]) >>> b[0:2,1] array([ 2.,  5.]) >>> b[:1] array([[1.5, 2., 3.]]) >>> c[1,...] array([[[ 3.,  2.,  1.], [ 4.,  5.,  6.]]]) >>> a[ : :-1] array([3, 2, 1]) Boolean Indexing >>> a[a<2] array([1]) Fancy Indexing >>> b[[1, 0, 1, 0],[0, 1, 2, 0]] array([ 4. , 2. , 6. , 1.5]) >>> b[[1, 0, 1, 0]][:,[0,1,2,0]] array([[ 4. ,5. , 6. , 4. ], [ 1.5, 2. , 3. , 1.5], [ 4. , 5. , 6. , 4. ], [ 1.5, 2. , 3. , 1.5]]) 1 2 3 1.5 2 3 4 5 6 1 2 3 1.5 2 3 4 5 6 1.5 2 3 4 5 6 1 2 3
```

```
Select the element at the 2nd index Select the element at row 0 column 2 (equivalent to b[1][2] ) Select items at index 0 and 1 Select items at rows 0 and 1 in column 1 Select all items at row 0 (equivalent to b[0:1, :] ) Same as [1,:,:] Reversed array a Select elements from a less than 2 Select elements (1,0) , (0,1) , (1,2) and (0,0) Select a subset of the matrix's rows and columns
```

## Array Manipulation

Permute array dimensions Permute array dimensions

Fla/tten the array

Reshape, but don't change data

Return a new array with shape (2,6) Append items to an array Insert items in an array Delete items from an array

Concatenate arrays

Stack arrays vertically (row-wise)

Stack arrays vertically (row-wise) Stack arrays horizontally (column-wise)

Create stacked column-wise arrays

Create stacked column-wise arrays

- Split the array horizontally at the 3rd index

Split the array vertically at the 2nd index

```
T ransposing Array >>> i = np.transpose(b) >>> i.T Changing Array Shape >>> b.ravel() >>> g.reshape(3,-2) Adding/Removing Elements >>> h.resize((2,6)) >>> np.append(h,g) >>> np.insert(a, 1, 5) >>> np.delete(a,[1]) Combining Arrays >>> np.concatenate((a,d),axis=0) array([ 1,  2,  3, 10, 15, 20]) >>> np.vstack((a,b)) array([[ 1. ,  2. ,  3. ], [ 1.5,  2. ,  3. ], [ 4. ,  5. ,  6. ]]) >>> np.r_[e,f] >>> np.hstack((e,f)) array([[ 7.,  7.,  1.,  0.], [ 7.,  7.,  0.,  1.]]) >>> np.column_stack((a,d)) array([[ 1, 10], [ 2, 15], [ 3, 20]]) >>> np.c_[a,d] Spli/tting Arrays >>> np.hsplit(a,3) [array([1]),array([2]),array([3])] >>> np.vsplit(c,2) [array([[[ 1.5,  2. ,  1. ], [ 4. ,  5. ,  6. ]]]), array([[[ 3.,  2.,  3.], [ 4.,  5.,  6.]]])]
```

## DataCamp

## Python For Data Science Cheat Sheet

SciPy - Linear Algebra

Learn More Python for Data Science Interactively at  www.datacamp.com

SciPy

The library is one of the core packages for

SciPy scientific computing that provides mathematical

algorithms and convenience functions built on the

NumPy extension of Python.

Interacting With NumPy

&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; a = np.array([1,2,3])

&gt;&gt;&gt; b = np.array([(1+5j,2j,3j), (4j,5j,6j)])

&gt;&gt;&gt; c = np.array([[(1.5,2,3), (4,5,6)], [(3,2,1), (4,5,6)]])

Index Tricks

&gt;&gt;&gt; np.mgrid[0:5,0:5]

Create a dense meshgrid

&gt;&gt;&gt; np.ogrid[0:2,0:2]

Create an open meshgrid

Stack arrays vertically (row-wise)

&gt;&gt;&gt; np.r_[[3,[0]*5,-1:1:10j]

&gt;&gt;&gt; np.c_[b,c]

Shape Manipulation

&gt;&gt;&gt; np.transpose(b)

&gt;&gt;&gt; b.flatten()

&gt;&gt;&gt; np.hstack((b,c))

&gt;&gt;&gt; np.vstack((a,b))

&gt;&gt;&gt; np.hsplit(c,2)

Create stacked column-wise arrays

Permute array dimensions

Fla/tten the array

Stack arrays horizontally (column-wise)

Stack arrays vertically (row-wise)

Split the array horizontally at the 2nd index

&gt;&gt;&gt; np.vpslit(d,2)

Polynomials

&gt;&gt;&gt; from numpy import poly1d

&gt;&gt;&gt; p = poly1d([3,4,5])

Create a polynomial object

Vectorizing Functions

&gt;&gt;&gt; def myfunc(a):

if a &lt; 0:

return a*2

else:

return a/2

&gt;&gt;&gt; np.vectorize(myfunc)

Vectorize functions

Type Handling

&gt;&gt;&gt; np.real(c)

&gt;&gt;&gt; np.imag(c)

Return the real part of the array elements

Return the imaginary part of the array elements

&gt;&gt;&gt; np.real_if_close(c,tol=1000)

Return a real array if complex parts close to 0

&gt;&gt;&gt; np.cast['f'](np.pi)

Cast object to a data type

Other Useful Functions

&gt;&gt;&gt; np.angle(b,deg=True)

Return the angle of the complex argument

&gt;&gt;&gt; g = np.linspace(0,np.pi,num=5)

Create an array of evenly spaced values

(number of samples)

&gt;&gt;&gt; g [3:] += np.pi

Unwrap

&gt;&gt;&gt; np.unwrap(g)

Create an array of evenly spaced values (log scale)

&gt;&gt;&gt; np.logspace(0,10,3)

Return values from a list of arrays depending on

&gt;&gt;&gt; np.select([c&lt;4],[c*2])

conditions

&gt;&gt;&gt; misc.factorial(a)

Factorial

Combine N things taken at k time

&gt;&gt;&gt; misc.comb(10,3,exact=True)

Weights for Np-point central derivative

&gt;&gt;&gt; misc.central_diff_weights(3)

Find the n-th derivative of a function at a point

&gt;&gt;&gt; misc.derivative(myfunc,1.0)

Split the array vertically at the 2nd index

Also see

NumPy

Linear Algebra

You'll use the linalg

sparse modules. Note that

and

&gt;&gt;&gt; from scipy import linalg, sparse

Creating Matrices

&gt;&gt;&gt; A = np.matrix(np.random.random((2,2)))

&gt;&gt;&gt; B = np.asmatrix(b)

&gt;&gt;&gt; C = np.mat(np.random.random((10,5)))

&gt;&gt;&gt; D = np.mat([[3,4], [5,6]])

Basic Matrix Routines

Inverse

&gt;&gt;&gt; A.I

&gt;&gt;&gt; linalg.inv(A)

&gt;&gt;&gt; A.T

&gt;&gt;&gt; A.H

&gt;&gt;&gt; np.trace(A)

Norm

&gt;&gt;&gt; linalg.norm(A)

&gt;&gt;&gt; linalg.norm(A,1)

&gt;&gt;&gt; linalg.norm(A,np.inf)

Rank

&gt;&gt;&gt; np.linalg.matrix_rank(C)

Determinant

&gt;&gt;&gt; linalg.det(A)

Solving linear problems

&gt;&gt;&gt; linalg.solve(A,b)

&gt;&gt;&gt; E = np.mat(a).T

Inverse

Inverse

Tranpose matrix

Conjugate transposition

Trace

Frobenius norm

L1 norm (max column sum)

L inf norm (max row sum)

Matrix rank

Determinant

Solver for dense matrices

Solver for dense matrices

&gt;&gt;&gt; linalg.lstsq(D,E)

Least-squares solution to linear matrix equation

Generalized inverse

&gt;&gt;&gt; linalg.pinv(C)

Compute the pseudo-inverse of a matrix

(least-squares solver)

&gt;&gt;&gt; linalg.pinv2(C)

Compute the pseudo-inverse of a matrix

(SVD)

Creating Sparse Matrices

&gt;&gt;&gt; F = np.eye(3, k=1)

&gt;&gt;&gt; G = np.mat(np.identity(2))

&gt;&gt;&gt; C[C &gt; 0.5] = 0

&gt;&gt;&gt; H = sparse.csr_matrix(C)

&gt;&gt;&gt; I = sparse.csc_matrix(D)

&gt;&gt;&gt; J = sparse.dok_matrix(A)

&gt;&gt;&gt; E.todense()

&gt;&gt;&gt; sparse.isspmatrix_csc(A)

Sparse Matrix Routines

Inverse

&gt;&gt;&gt; sparse.linalg.inv(I)

Inverse

Norm

&gt;&gt;&gt; sparse.linalg.norm(I)

Solving linear problems

&gt;&gt;&gt; sparse.linalg.spsolve(H,I)

Norm

Solver for sparse matrices

Sparse Matrix Functions

&gt;&gt;&gt; sparse.linalg.expm(I)

Sparse matrix exponential

Asking For Help

&gt;&gt;&gt; help(scipy.linalg.diagsvd)

&gt;&gt;&gt; np.info(np.matrix)

Create a 2X2 identity matrix

Create a 2x2 identity matrix

Compressed Sparse Row matrix

Compressed Sparse Column matrix

Dictionary Of Keys matrix

Sparse matrix to full matrix

Identify sparse matrix scipy.linalg

contains and expands on numpy.linalg

Matrix Functions

Addition

&gt;&gt;&gt; np.add(A,D)

Addition

Subtraction

&gt;&gt;&gt; np.subtract(A,D)

Division

&gt;&gt;&gt; np.divide(A,D)

Multiplication

&gt;&gt;&gt; np.multiply(D,A)

&gt;&gt;&gt; np.dot(A,D)

&gt;&gt;&gt; np.vdot(A,D)

&gt;&gt;&gt; np.inner(A,D)

&gt;&gt;&gt; np.outer(A,D)

&gt;&gt;&gt; np.tensordot(A,D)

&gt;&gt;&gt; np.kron(A,D)

Exponential Functions

&gt;&gt;&gt; linalg.expm(A)

&gt;&gt;&gt; linalg.expm2(A)

&gt;&gt;&gt; linalg.expm3(D)

Subtraction

Division

Multiplication

Dot product

Vector dot product

Inner product

Outer product

Tensor dot product

Kronecker product

Matrix exponential

Matrix exponential (Taylor Series)

Matrix exponential (eigenvalue decomposition)

Logarithm Function

&gt;&gt;&gt; linalg.logm(A)

Matrix logarithm

T rigonometric Tunctions

&gt;&gt;&gt; linalg.sinm(D)

&gt;&gt;&gt; linalg.cosm(D)

&gt;&gt;&gt; linalg.tanm(A)

Hyperbolic Trigonometric Functions

&gt;&gt;&gt; linalg.sinhm(D)

&gt;&gt;&gt; linalg.coshm(D)

&gt;&gt;&gt; linalg.tanhm(A)

Matrix Sign Function

&gt;&gt;&gt; np.sigm(A)

Matrix Square Root

&gt;&gt;&gt; linalg.sqrtm(A)

Arbitrary Functions

&gt;&gt;&gt; linalg.funm(A, lambda x: x*x)

Evaluate matrix function

Decompositions

Eigenvalues and Eigenvectors

&gt;&gt;&gt; la, v = linalg.eig(A)

Solve ordinary or generalized eigenvalue problem for square matrix

&gt;&gt;&gt; l1, l2 = la

&gt;&gt;&gt; v[:,0]

&gt;&gt;&gt; v[:,1]

&gt;&gt;&gt; linalg.eigvals(A)

Singular Value Decomposition

&gt;&gt;&gt; U,s,Vh = linalg.svd(B)

Unpack eigenvalues

First eigenvector

Second eigenvector

Unpack eigenvalues

Singular Value Decomposition (SVD)

&gt;&gt;&gt; M,N = B.shape

&gt;&gt;&gt; Sig = linalg.diagsvd(s,M,N)

LU Decomposition

&gt;&gt;&gt; P,L,U = linalg.lu(C)

Construct sigma matrix in SVD

LU Decomposition

Sparse Matrix Decompositions

&gt;&gt;&gt; la, v = sparse.linalg.eigs(F,1)

&gt;&gt;&gt; sparse.linalg.svds(H, 2)

Eigenvalues and eigenvectors

SVD

DataCamp

Learn Python for Data Science Interactively

.

Also see

Matrix sine

Matrix cosine

Matrix tangent

Hypberbolic matrix sine

Hyperbolic matrix cosine

Hyperbolic matrix tangent

Matrix sign function

Matrix square root

NumPy

## Python For Data Science Cheat Sheet

## Pandas Basics

Learn Python for Data Science Interactively at  www.DataCamp.com

## Pandas

The Pandas library is built on NumPy and provides easy-to-use data structures and data analysis tools for the Python programming language.

Use the following import convention:

```
>>> import pandas as pd
```

## Pandas Data Structures

## Series

A one-dimensional labeled array capable of holding any data type

Index

```
>>> s = pd.Series([3, -5, 7, 4], index=['a', 'b', 'c', 'd'])
```

## DataFrame

1

```
Index Columns A two-dimensional labeled data structure with columns of potentially different types >>> data = {'Country': ['Belgium', 'India', 'Brazil'], 'Capital': ['Brussels', 'New Delhi', 'Brasília'], 'Population': [11190846, 1303171035, 207847528]} >>> df = pd.DataFrame(data, columns=['Country', 'Capital', 'Population']) Belgium Brussels India New Delhi Brazil Brasília 0 2 Country Capital 11190846 1303171035 207847528 Population
```

## I/O

## Read and Write to CSV

```
>>> pd.read_csv('file.csv', header=None, nrows=5) >>> df.to_csv('myDataFrame.csv')
```

## Read and Write to Excel

```
>>> pd.read_excel('file.xlsx') >>> pd.to_excel('dir/myDataFrame.xlsx', sheet_name='Sheet1') Read multiple sheets from the same file >>> xlsx = pd.ExcelFile('file.xls') >>> df = pd.read_excel(xlsx, 'Sheet1')
```

## Asking For Help

&gt;&gt;&gt; help(pd.Series.loc)

## Selection

## Ge/tting

```
>>> s['b'] -5 >>> df[1:] Country    Capital  Population 1   India  New Delhi  1303171035 2  Brazil   Brasília  207847528
```

## Also see NumPy Arrays

Get one element

Get subset of a DataFrame

## Selecting, Boolean Indexing &amp; Se/tting

Series where value is not &gt;1

where value is &lt;-1 or &gt;2

s

Use filter to adjust DataFrame

```
By Position >>> df.iloc([0],[0]) Select single value by row & 'Belgium' column >>> df.iat([0],[0]) 'Belgium' By Label >>> df.loc([0], ['Country']) Select single value by row & 'Belgium' column labels >>> df.at([0], ['Country']) 'Belgium' By Label/Position >>> df.ix[2] Select single row of Country      Brazil subset of rows Capital    Brasília Population  207847528 >>> df.ix[:,'Capital'] Select a single column of 0     Brussels subset of columns 1    New Delhi 2     Brasília >>> df.ix[1,'Capital'] Select rows and columns 'New Delhi' Boolean Indexing >>> s[~(s > 1)] >>> s[(s < -1) | (s > 2)]           s >>> df[df['Population']>1200000000] Se/tting >>> s['a'] = 6 Set index a of Series s to 6
```

## Read and Write to SQL Query or Database Table

```
>>> from sqlalchemy import create_engine >>> engine = create_engine('sqlite:///:memory:') >>> pd.read_sql("SELECT * FROM my_table;", engine) >>> pd.read_sql_table('my_table', engine)
```

```
>>> pd.read_sql_query("SELECT * FROM my_table;", engine) >>> pd.to_sql('myDf', engine) read_sql() is a convenience wrapper around read_sql_table() and read_sql_query()
```

## Dropping

&gt;&gt;&gt; s.drop(['a', 'c']) Drop values from rows (axis=0) &gt;&gt;&gt; df.drop('Country', axis=1) Drop values from columns(axis=1)

## Sort &amp; Rank

&gt;&gt;&gt; df.sort_index() Sort by labels along an axis &gt;&gt;&gt; df.sort_values(by='Country') Sort by the values along an axis &gt;&gt;&gt; df.rank() Assign ranks to entries

## Retrieving Series/DataFrame Information

## Basic Information

```
>>> df.shape (rows,columns) >>> df.index Describe index >>> df.columns Describe DataFrame columns >>> df.info() Info on DataFrame >>> df.count() Number of non-NA values
```

## Summary

```
>>> df.sum() Sum of values >>> df.cumsum() Cummulative sum of values >>> df.min()/df.max() Minimum/maximum values >>> df.idxmin()/df.idxmax() Minimum/Maximum index value >>> df.describe() Summary statistics >>> df.mean() Mean of values >>> df.median() Median of values
```

## Applying Functions

```
>>> f = lambda x: x*2
```

```
>>> df.apply(f) Apply function >>> df.applymap(f) Apply function element-wise
```

## Data Alignment

## Internal Data Alignment

NA values are introduced in the indices that don't overlap:

```
>>> s3 = pd.Series([7, -2, 3], index=['a', 'c', 'd']) >>> s + s3 a     10.0 b NaN c     5.0 d     7.0
```

## Arithmetic Operations with Fill Methods

You can also do the internal data alignment yourself with the help of the fill methods:

```
>>> s.add(s3, fill_value=0) a    10.0 b -5.0 c    5.0 d    7.0 >>> s.sub(s3, fill_value=2) >>> s.div(s3, fill_value=4) >>> s.mul(s3, fill_value=3)
```

## DataCamp

## Python For Data Science Cheat Sheet

## Scikit-Learn

Learn Python for data science Interactively at  www.DataCamp.com

## Scikit-learn

Scikit-learn is an open source Python library that implements a range of machine learning, preprocessing, cross-validation and visualization algorithms using a unified interface.

## A Basic Example

```
>>> from sklearn import neighbors, datasets, preprocessing >>> from sklearn.model_selection import train_test_split >>> from sklearn.metrics import accuracy_score >>> iris = datasets.load_iris() >>> X, y = iris.data[:, :2], iris.target >>> X_train,   X_test,   y_train,   y_test   =   train_test_split(X,   y,   random_state=33) >>> scaler = preprocessing.StandardScaler().fit(X_train) >>> X_train = scaler.transform(X_train) >>> X_test = scaler.transform(X_test) >>> knn = neighbors.KNeighborsClassifier(n_neighbors=5) >>> knn.fit(X_train, y_train) >>> y_pred = knn.predict(X_test) >>> accuracy_score(y_test, y_pred)
```

## Loading The Data

Also see NumPy &amp; Pandas

Your data needs to be numeric and stored as NumPy arrays or SciPy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable.

```
>>> import numpy as np >>> X = np.random.random((10,5)) >>> y = np.array(['M','M','F','F','M','F','M','M','F','F','F']) >>> X[X < 0.7] = 0
```

## T raining And Test Data

```
>>> from sklearn.model_selection import train_test_split >>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
```

## Preprocessing The Data

## Standardization

```
>>> from sklearn.preprocessing import StandardScaler >>> scaler = StandardScaler().fit(X_train) >>> standardized_X = scaler.transform(X_train) >>> standardized_X_test = scaler.transform(X_test)
```

## Normalization

```
>>> from sklearn.preprocessing import Normalizer >>> scaler = Normalizer().fit(X_train) >>> normalized_X = scaler.transform(X_train) >>> normalized_X_test = scaler.transform(X_test)
```

## Binarization

```
>>> from sklearn.preprocessing import Binarizer >>> binarizer = Binarizer(threshold=0.0).fit(X) >>> binary_X = binarizer.transform(X)
```

## Create Your Model

## Supervised Learning Estimators

## Linear Regression

```
>>> from sklearn.linear_model import LinearRegression >>> lr = LinearRegression(normalize=True) Support Vector Machines (SVM) >>> from sklearn.svm import SVC >>> svc = SVC(kernel='linear') Naive Bayes >>> from sklearn.naive_bayes import GaussianNB >>> gnb = GaussianNB() KNN >>> from sklearn import neighbors >>> knn = neighbors.KNeighborsClassifier(n_neighbors=5)
```

## Unsupervised Learning Estimators

## Principal Component Analysis (PCA)

```
>>> from sklearn.decomposition import PCA
```

```
>>> pca = PCA(n_components=0.95) K Means >>> from sklearn.cluster import KMeans >>> k_means = KMeans(n_clusters=3, random_state=0)
```

## Model Fi/tting

## Supervised learning

```
>>> lr.fit(X, y) >>> knn.fit(X_train, y_train) >>> svc.fit(X_train, y_train) Unsupervised Learning >>> k_means.fit(X_train) >>> pca_model = pca.fit_transform(X_train)
```

Fit the model to the data

Fit the model to the data

Fit to data, then transform it

## Prediction

```
Supervised Estimators >>> y_pred = svc.predict(np.random.random((2,5))) >>> y_pred = lr.predict(X_test) >>> y_pred = knn.predict_proba(X_test) Unsupervised Estimators >>> y_pred = k_means.predict(X_test) Predict labels Predict labels Estimate probability of a label Predict labels in clustering algos
```

## Encoding Categorical Features

```
>>> from sklearn.preprocessing import LabelEncoder >>> enc = LabelEncoder() >>> y = enc.fit_transform(y)
```

## Imputing Missing Values

```
>>> from sklearn.preprocessing import Imputer >>> imp = Imputer(missing_values=0, strategy='mean', axis=0) >>> imp.fit_transform(X_train)
```

## Generating Polynomial Features

```
>>> from sklearn.preprocessing import PolynomialFeatures >>> poly = PolynomialFeatures(5) >>> poly.fit_transform(X)
```

## Evaluate Your Model's Performance

## Classification Metrics

## Accuracy Score

&gt;&gt;&gt; knn.score(X_test, y_test)

&gt;&gt;&gt; from sklearn.metrics import accuracy_score &gt;&gt;&gt; accuracy_score(y_test, y_pred)

Estimator score method

Metric scoring functions

## Classification Report

&gt;&gt;&gt; from sklearn.metrics import classification_report Precision, recall, f1-score

&gt;&gt;&gt; print(classification_report(y_test, y_pred) ) and support

## Confusion Matrix

&gt;&gt;&gt; from sklearn.metrics import confusion_matrix &gt;&gt;&gt; print(confusion_matrix(y_test, y_pred))

## Regression Metrics

## Mean Absolute Error

```
>>> from sklearn.metrics import mean_absolute_error >>> y_true = [3, -0.5, 2] >>> mean_absolute_error(y_true, y_pred) Mean Squared Error >>> from sklearn.metrics import mean_squared_error >>> mean_squared_error(y_test, y_pred) R² Score >>> from sklearn.metrics import r2_score >>> r2_score(y_true, y_pred)
```

## Clustering Metrics

## Adjusted Rand Index

&gt;&gt;&gt; from sklearn.metrics import adjusted_rand_score &gt;&gt;&gt; adjusted_rand_score(y_true, y_pred)

## Homogeneity

&gt;&gt;&gt; from sklearn.metrics import homogeneity_score &gt;&gt;&gt; homogeneity_score(y_true, y_pred)

## V-measure

&gt;&gt;&gt; from sklearn.metrics import v_measure_score &gt;&gt;&gt; metrics.v_measure_score(y_true, y_pred)

## Cross-Validation

&gt;&gt;&gt; from sklearn.cross_validation import cross_val_score &gt;&gt;&gt; print(cross_val_score(knn, X_train, y_train, cv=4)) &gt;&gt;&gt; print(cross_val_score(lr, X, y, cv=2))

## T une Your Model

## Grid Search

```
>>> from sklearn.grid_search import GridSearchCV >>> params = {"n_neighbors": np.arange(1,3), "metric": ["euclidean", "cityblock"]} >>> grid = GridSearchCV(estimator=knn, param_grid=params) >>> grid.fit(X_train, y_train) >>> print(grid.best_score_) >>> print(grid.best_estimator_.n_neighbors)
```

## Randomized Parameter Optimization

```
>>> from sklearn.grid_search import RandomizedSearchCV >>> params = {"n_neighbors": range(1,5), "weights": ["uniform", "distance"]} >>> rsearch = RandomizedSearchCV(estimator=knn, param_distributions=params, cv=4, n_iter=8, random_state=5) >>> rsearch.fit(X_train, y_train) >>> print(rsearch.best_score_)
```

## Python For Data Science Cheat Sheet Plot Anatomy cy haccpy rals

25

20

Y-axis

15

## Matplotlib

Matplotlib is a Python 2D plo/tting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.

## Prepare The Data

1

## 1D Data

```
>>> import numpy as np >>> y = np.cos(x)
```

```
>>> x = np.linspace(0, 10, 100) >>> z = np.sin(x)
```

## 2D Data or Images

```
>>> data = 2 * np.random.random((10, 10)) >>> data2 = 3 * np.random.random((10, 10)) >>> Y, X = np.mgrid[-3:3:100j, -3:3:100j] >>> U = -1 - X**2 + Y >>> V = 1 + X - Y**2 >>> from matplotlib.cbook import get_sample_data >>> img = np.load(get_sample_data('axes_grid/bivariate_normal.npy'))
```

## Create Plot

2

&gt;&gt;&gt; import matplotlib.pyplot as plt

```
>>> fig = plt.figure() >>> fig2 = plt.figure(figsize=plt.figaspect(2.0)) Figure
```

## Axes

All plo/tting is done with respect to an Axes . In most cases, a subplot will fit your needs. A subplot is an axes on a grid system.

```
>>> fig.add_axes() >>> ax1 = fig.add_subplot(221) # row-col-num >>> ax3 = fig.add_subplot(212) >>> fig3, axes = plt.subplots(nrows=2,ncols=2) >>> fig4, axes2 = plt.subplots(ncols=3)
```

## Plo/tting Routines 3

## 1D Data

```
>>> fig, ax = plt.subplots()
```

## Plot Anatomy &amp; Workflow

## Customize Plot

4

## Colors, Color Bars &amp; Color Maps

```
>>> plt.plot(x, x, x, x**2, x, x**3) >>> ax.plot(x, y, alpha = 0.4) >>> ax.plot(x, y, c='k') >>> fig.colorbar(im, orientation='horizontal') >>> im = ax.imshow(img, cmap='seismic')
```

## Markers

```
>>> fig, ax = plt.subplots()
```

```
>>> ax.scatter(x,y,marker=".") >>> ax.plot(x,y,marker="o")
```

## Linestyles

```
>>> plt.plot(x,y,linewidth=4.0) >>> plt.plot(x,y,ls='solid') >>> plt.plot(x,y,ls='--') >>> plt.plot(x,y,'--',x**2,y**2,'-.')
```

```
>>> plt.setp(lines,color='r',linewidth=4.0)
```

## Text &amp; Annotations

```
>>> ax.text(1, -2.1, 'Example Graph', style='italic') >>> ax.annotate("Sine", xy=(8, 0), xycoords='data', xytext=(10.5, 0), textcoords='data', arrowprops=dict(arrowstyle="->", connectionstyle="arc3"),)
```

## Vector Fields

```
>>> lines = ax.plot(x,y) Draw points with lines or markers connecting them >>> ax.scatter(x,y) Draw unconnected points, scaled or colored >>> axes[0,0].bar([1,2,3],[3,4,5]) Plot vertical rectangles (constant width) >>> axes[1,0].barh([0.5,1,2.5],[0,1,2]) Plot horiontal rectangles (constant height) >>> axes[1,1].axhline(0.45) Draw a horizontal line across axes >>> axes[0,1].axvline(0.65) Draw a vertical line across axes >>> ax.fill(x,y,color='blue') Draw filled polygons >>> ax.fill_between(x,y,color='yellow') Fill between y-values and 0
```

## 2D Data or Images

```
>>> fig, ax = plt.subplots() >>> im = ax.imshow(img, Colormapped or RGB arrays cmap='gist_earth', interpolation='nearest', vmin=-2, vmax=2)
```

```
>>> axes[0,1].arrow(0,0,0.5,0.5) Add an arrow to the axes >>> axes[1,1].quiver(y,z) Plot a 2D field of arrows >>> axes[0,1].streamplot(X,Y,U,V) Plot a 2D field of arrows
```

## Data Distributions

| >>> ax1.hist(y) >>> ax3.boxplot(y) >>> ax3.violinplot(z)   | Plot a histogram Make a box and whisker plot Make a violin plot   |
|------------------------------------------------------------|-------------------------------------------------------------------|

```
>>> axes2[0].pcolor(data2) Pseudocolor plot of 2D array >>> axes2[0].pcolormesh(data) Pseudocolor plot of 2D array >>> CS = plt.contour(Y,X,U) Plot contours >>> axes2[2].contourf(data1) Plot filled contours >>> axes2[2]= ax.clabel(CS) Label a contour plot
```

Also see Lists &amp; NumPy

## Workflow

The basic steps to creating plots with matplotlib are:

1

```
Prepare data 2 Create plot 3 Plot 4 Customize plot 5 Save plot 6 Show plot >>> import matplotlib.pyplot as plt >>> x = [1,2,3,4] >>> y = [10,20,25,30] >>> fig = plt.figure() >>> ax = fig.add_subplot(111) >>> ax.plot(x, y, color='lightblue', linewidth=3) >>> ax.scatter([2,4,6], [5,15,25], color='darkgreen', marker='^') >>> ax.set_xlim(1, 6.5) >>> plt.savefig('foo.png') >>> plt.show() Step 3, 4 Step 2 Step 1 Step 3 Step 6
```

## Mathtext

&gt;&gt;&gt; plt.title(r'$sigma_i=15$', fontsize=20)

## Limits, Legends &amp; Layouts

```
Limits & Autoscaling >>> ax.margins(x=0.0,y=0.1) Add padding to a plot >>> ax.axis('equal') Set the aspect ratio of the plot to 1 >>> ax.set(xlim=[0,10.5],ylim=[-1.5,1.5]) Set limits for x-and y-axis >>> ax.set_xlim(0,10.5) Set limits for x-axis Legends >>> ax.set(title='An Example Axes', Set a title and x-and y-axis labels ylabel='Y-Axis', xlabel='X-Axis') >>> ax.legend(loc='best') No overlapping plot elements Ticks >>> ax.xaxis.set(ticks=range(1,5), Manually set x-ticks ticklabels=[3,100,-12,"foo"]) >>> ax.tick_params(axis='y', Make y-ticks longer and go in and out direction='inout', length=10) Subplot Spacing >>> fig3.subplots_adjust(wspace=0.5, Adjust the spacing between subplots hspace=0.3, left=0.125, right=0.9, top=0.9, bottom=0.1) >>> fig.tight_layout() Fit subplot(s) in to the figure area Axis Spines >>> ax1.spines['top'].set_visible(False) Make the top axis line for a plot invisible >>> ax1.spines['bottom'].set_position(('outward',10)) Move the bo/ttom axis line outward
```

## Save Plot

5

```
Save figures >>> plt.savefig('foo.png') Save transparent figures >>> plt.savefig('foo.png', transparent=True)
```

## Show Plot

6

&gt;&gt;&gt; plt.show()

## Close &amp; Clear

```
>>> plt.cla() Clear an axis >>> plt.clf() Clear the entire figure >>> plt.close() Close a window
```

## DataCamp

Learn Python for Data Science Interactively

Matplotlib 2.0.0 - Updated on: 02/2017

## Python For Data Science Cheat Sheet

## Seaborn

Learn Data Science Interactively at  www.DataCamp.com

## Statistical Data Visualization With Seaborn

The Python visualization library Seaborn is based on matplotlib and provides a high-level interface for drawing a/ttractive statistical graphics.

Make use of the following aliases to import the libraries:

```
>>> import matplotlib.pyplot as plt >>> import seaborn as sns
```

The basic steps to creating plots with Seaborn are:

1. Prepare some data
2. Control figure aesthetics
3. Plot with Seaborn
4. Further customize your plot

```
>>> import matplotlib.pyplot as plt >>> import seaborn as sns >>> tips = sns.load_dataset("tips") >>> sns.set_style("whitegrid") >>> g = sns.lmplot(x="tip", y="total_bill", data=tips, aspect=2) >>> g = (g.set_axis_labels("Tip","Total bill(USD)"). set(xlim=(0,10),ylim=(0,100))) >>> plt.title("title") >>> plt.show(g) Step 4 Step 2 Step 1 Step 5 Step 3
```

## Data

1

## Also see Lists , NumPy &amp; Pandas

```
>>> import pandas as pd >>> import numpy as np >>> uniform_data = np.random.rand(10, 12) >>> data = pd.DataFrame({'x':np.arange(1,101), 'y':np.random.normal(0,4,100)})
```

Seaborn also offers built-in data sets:

```
>>> titanic = sns.load_dataset("titanic") >>> iris = sns.load_dataset("iris")
```

## Figure Aesthetics

2

```
>>> f, ax = plt.subplots(figsize=(5,6)) Create a figure and one subplot
```

## Seaborn styles

```
>>> sns.set() >>> sns.set_style("whitegrid") >>> sns.set_style("ticks", {"xtick.major.size":8, "ytick.major.size":8}) >>> sns.axes_style("whitegrid")
```

(Re)set the seaborn default Set the matplotlib parameters Set the matplotlib parameters

Return a dict of params or use with with to temporarily set the style

## Plo/tting With Seaborn

## Axis Grids

```
>>> g = sns.FacetGrid(titanic, Subplot grid for plo/tting conditional col="survived", relationships row="sex") >>> g = g.map(plt.hist,"age") >>> sns.factorplot(x="pclass", Draw a categorical plot onto a y="survived", Facetgrid hue="sex", data=titanic) >>> sns.lmplot(x="sepal_width", Plot data and regression model fits y="sepal_length", across a FacetGrid hue="species", data=iris)
```

## Categorical Plots

## Sca/tterplot

```
>>> sns.stripplot(x="species", y="petal_length", data=iris) >>> sns.swarmplot(x="species", y="petal_length", data=iris) Bar Chart >>> sns.barplot(x="sex", y="survived", hue="class", data=titanic) Count Plot >>> sns.countplot(x="deck", data=titanic, palette="Greens_d") Point Plot >>> sns.pointplot(x="class", y="survived", hue="sex", data=titanic, palette={"male":"g", "female":"m"}, markers=["^","o"], linestyles=["-","--"]) Boxplot >>> sns.boxplot(x="alive", y="age", hue="adult_male", data=titanic) >>> sns.boxplot(data=iris,orient="h") Violinplot >>> sns.violinplot(x="age", y="sex", hue="survived", data=titanic)
```

Sca/tterplot with one categorical variable

Categorical sca/tterplot with non-overlapping points

Show point estimates and confidence intervals with sca/tterplot glyphs

Show count of observations

Show point estimates and confidence intervals as rectangular bars

Boxplot

Boxplot with wide-form data

Violin plot

## Also see Matplotlib

## Context Functions

```
>>> sns.set_context("talk") Set context to "talk" >>> sns.set_context("notebook", Set context to "notebook" , font_scale=1.5, scale font elements and rc={"lines.linewidth":2.5}) override param mapping
```

## Color Pale/tte

```
>>> sns.set_palette("husl",3) Define the color pale/tte >>> sns.color_palette("husl") Use with with to temporarily set pale/tte >>> flatui = ["#9b59b6","#3498db","#95a5a6","#e74c3c","#34495e","#2ecc71"] >>> sns.set_palette(flatui) Set your own color pale/tte
```

Subplot grid for plo/tting pairwise relationships

Plot pairwise bivariate distributions Grid for bivariate plot with marginal univariate plots

Plot bivariate distribution

```
>>> h = sns.PairGrid(iris) >>> h = h.map(plt.scatter) >>> sns.pairplot(iris) >>> i = sns.JointGrid(x="x", y="y", data=data) >>> i = i.plot(sns.regplot, sns.distplot) >>> sns.jointplot("sepal_length", "sepal_width", data=iris, kind='kde')
```

## Regression Plots

Plot data and a linear regression

```
>>> sns.regplot(x="sepal_width", y="sepal_length", model fit data=iris, ax=ax)
```

## Distribution Plots

```
>>> plot = sns.distplot(data.y, Plot univariate distribution kde=False, color="b")
```

## Matrix Plots

&gt;&gt;&gt; sns.heatmap(uniform_data,vmin=0,vmax=1)

## Further Customizations

Heatmap

## Also see Matplotlib

## Axisgrid Objects

```
>>> g.despine(left=True) Remove le/ft spine >>> g.set_ylabels("Survived") Set the labels of the y-axis >>> g.set_xticklabels(rotation=45) Set the tick labels for x >>> g.set_axis_labels("Survived", Set the axis labels "Sex") >>> h.set(xlim=(0,5), Set the limit and ticks of the ylim=(0,5), x-and y-axis xticks=[0,2.5,5], yticks=[0,2.5,5])
```

## Plot

```
>>> plt.title("A Title") Add plot title >>> plt.ylabel("Survived") Adjust the label of the y-axis >>> plt.xlabel("Sex") Adjust the label of the x-axis >>> plt.ylim(0,100) Adjust the limits of the y-axis >>> plt.xlim(0,10) Adjust the limits of the x-axis >>> plt.setp(ax,yticks=[0,5]) Adjust a plot property >>> plt.tight_layout() Adjust subplot params
```

## Show or Save Plot

5

## Also see Matplotlib

```
>>> plt.show() Show the plot >>> plt.savefig("foo.png") Save the plot as a figure >>> plt.savefig("foo.png", Save transparent figure transparent=True)
```

## Close &amp; Clear

## Also see Matplotlib

| >>> plt.cla() >>> plt.clf() >>> plt.close()   | Clear an axis Clear an entire figure Close a window   |
|-----------------------------------------------|-------------------------------------------------------|

## DataCamp

Learn Python for Data Science Interactively

## Python For Data Science Cheat Sheet

## Bokeh

Learn Bokeh Interactively at  www.DataCamp.com, taught by Bryan Van de Ven, core contributor

## Plo/tting With Bokeh

The Python interactive visualization library Bokeh enables high-performance visual presentation of large datasets in modern web browsers.

Bokeh's mid-level general purpose bokeh.plotting interface is centered around two main components: data and glyphs.

The basic steps to creating plots with the bokeh.plotting interface are:

1. Prepare some data:

Python lists, NumPy arrays, Pandas DataFrames and other sequences of values

2. Create a new plot
3. Add renderers for your data, with visual customizations
4. Specify where to generate the output
5. Show or save the results

```
>>> from bokeh.plotting import figure >>> from bokeh.io import output_file, show >>> x = [1, 2, 3, 4, 5] >>> y = [6, 7, 2, 4, 5] >>> p = figure(title="simple line example", x_axis_label='x', y_axis_label='y') >>> p.line(x, y, legend="Temp.", line_width=2) >>> output_file("lines.html") >>> show(p) Step 4 Step 2 Step 1 Step 5 Step 3
```

## Data

## Also see Lists , NumPy &amp; Pandas

1

Under the hood, your data is converted to Column Data Sources. You can also do this manually:

```
>>> import numpy as np >>> import pandas as pd >>> df = pd.DataFrame(np.array([[33.9,4,65, 'US'], [32.4,4,66, 'Asia'], [21.4,4,109, 'Europe']]), columns=[ 'mpg','cyl', 'hp', 'origin'], index=['Toyota', 'Fiat', 'Volvo'])
```

```
>>> from bokeh.models import ColumnDataSource >>> cds_df = ColumnDataSource(df)
```

## Plo/tting

2

```
>>> from bokeh.plotting import figure >>> p1 = figure(plot_width=300, tools='pan,box_zoom') >>> p2 = figure(plot_width=300, plot_height=300, x_range=(0, 8), y_range=(0, 8)) >>> p3 = figure()
```

## Renderers &amp; Visual Customizations

## Glyphs

## Sca/tter Markers

```
>>> p1.circle(np.array([1,2,3]), np.array([3,2,1]), fill_color='white') >>> p2.square(np.array([1.5,3.5,5.5]), [1,4,3], color='blue', size=1) Line Glyphs >>> p1.line([1,2,3,4], [3,4,5,6], line_width=2) >>> p2.multi_line(pd.DataFrame([[1,2,3],[5,6,7]]), pd.DataFrame([[3,4,5],[3,2,1]]), color="blue")
```

## Customized Glyphs

## Selection and Non-Selection Glyphs

```
>>> p = figure(tools='box_select') >>> p.circle('mpg', 'cyl', source=cds_df, selection_color='red', nonselection_alpha=0.1)
```

## Hover Glyphs

```
>>> from bokeh.models import HoverTool >>> hover = HoverTool(tooltips=None, mode='vline') >>> p3.add_tools(hover)
```

## Colormapping US

```
>>> from bokeh.models import CategoricalColorMapper >>> color_mapper = CategoricalColorMapper( factors=['US', 'Asia', 'Europe'], palette=['blue', 'red', 'green']) >>> p3.circle('mpg', 'cyl', source=cds_df, color=dict(field='origin', transform=color_mapper), legend='Origin')
```

## Legend Location

## Inside Plot Area

```
>>> p.legend.location = 'bottom_left' Outside Plot Area >>> from bokeh.models import Legend >>> r1 = p2.asterisk(np.array([1,2,3]), np.array([3,2,1]) >>> r2 = p2.line([1,2,3,4], [3,4,5,6]) >>> legend = Legend(items=[("One" ,[p1, r1]),("Two",[r2])], location=(0, -30)) >>> p.add_layout(legend, 'right')
```

## Legend Orientation

```
>>> p.legend.orientation = "horizontal" >>> p.legend.orientation = "vertical"
```

## Legend Background &amp; Border

```
>>> p.legend.border_line_color = "navy" >>> p.legend.background_fill_color = "white"
```

## Rows &amp; Columns Layout

## Rows

```
>>> from bokeh.layouts import row
```

```
>>> layout = row(p1,p2,p3) Columns >>> from bokeh.layouts import columns >>> layout = column(p1,p2,p3) Nesting Rows & Columns >>>layout = row(column(p1,p2), p3)
```

Also see Data

## Grid Layout

```
>>> from bokeh.layouts import gridplot >>> row1 = [p1,p2] >>> row2 = [p3] >>> layout = gridplot([[p1,p2],[p3]])
```

## Tabbed Layout

```
>>> from bokeh.models.widgets import Panel, Tabs >>> tab1 = Panel(child=p1, title="tab1") >>> tab2 = Panel(child=p2, title="tab2") >>> layout = Tabs(tabs=[tab1, tab2])
```

## Linked Plots

## Linked Axes

```
>>> p2.x_range = p1.x_range >>> p2.y_range = p1.y_range Linked Brushing >>> p4 = figure(plot_width = 100, tools='box_select,lasso_select') >>> p4.circle('mpg', 'cyl', source=cds_df) >>> p5 = figure(plot_width = 200, tools='box_select,lasso_select') >>> p5.circle('mpg', 'hp', source=cds_df) >>> layout = row(p4,p5)
```

## Output &amp; Export

## Notebook

&gt;&gt;&gt; from bokeh.io import output_notebook, show &gt;&gt;&gt; output_notebook()

## HTML

## Standalone HTML

```
>>> from bokeh.embed import file_html >>> from bokeh.resources import CDN >>> html = file_html(p, CDN, "my_plot")
```

```
>>> from bokeh.io import output_file, show >>> output_file('my_bar_chart.html', mode='cdn')
```

## Components

```
>>> from bokeh.embed import components >>> script, div = components(p)
```

## PNG

```
>>> from bokeh.io import export_png >>> export_png(p, filename="plot.png")
```

## SVG

```
>>> from bokeh.io import export_svgs >>> p.output_backend = "svg" >>> export_svgs(p, filename="plot.svg")
```

## Show or Save Your Plots

5

```
>>> show(p1)              >>> show(layout) >>> save(p1)              >>> save(layout)
```

## DataCamp

Learn Python for Data Science Interactively